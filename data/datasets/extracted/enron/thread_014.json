{
    "mails": [
        {
            "subject": "Re: Draft Charter &ndash;&ndash;  Please review and commen",
            "content": ">  Chair(s):  TBD\n>\n>  Security Area Director(s):\n>  Jeffrey Schiller  <jis@mit.edu>\n\nAlso for the record, the following candidates stood for Chair, and they will  \ndiscuss a solution jointly with Jeff this week:\n\nWin Treese, Open Market\nCharlie Kaufman, Iris\nTaher ElGamal, Netscape\nBarbara Fox, Microsoft\n\nRohit Khare\n\n\n\n"
        },
        {
            "subject": "Comment on Draft Charte",
            "content": "Read the draft charter published on this list and noticed the following:\n\nJuly 96 Final draft for Secure Transport Layer Protocol   \"STLP\"\n\nThis date wasn't mentioned in the BOF.  Doesn't this presume that a \nProposed Standard has already come from the working group?\n\nBarb Fox\nbfox@microsoft.com\n\n\n\n"
        },
        {
            "subject": "Re: Comment on Draft Charte",
            "content": ">  Read the draft charter published on this list and noticed\n>  the following:\n>\n>  July 96  Final draft for Secure Transport Layer Protocol\n>  \"STLP\"\n>\n>  This date wasn't mentioned in the BOF.  Doesn't this\n>  presume that a Proposed Standard has already come from\n>  the working group?\n>\n>  Barb Fox bfox@microsoft.com\n\nThe *date* was certainly not brought up in the BOF, especially since this is  \nte crucial, debated expectation of \"unification by Montreal\". This was not an  \noversight, though; the charter discussion explicitly avoided milestone issues  \nthat evening.\n\nSeparately, though, I thought I'd note that the WG's 'final draft' is only  \nthe beginning of the stdization process. Final drafts are submitted to the  \nIESG with a recommendation to Proposed; then a Last Call is held. Later,  \nevidence of its success can be brought to the IESG to promote it to STD  \nstatus.\n\nBesides, I can think of a pretty cool logo for STP -- STLP can't even be  \npronounced! :-)\n\nRohit Khare\n\n\n\n"
        },
        {
            "subject": "Re: Comment on Draft Charte",
            "content": "Barb Fox wrote:\n> \n> Read the draft charter published on this list and noticed the following:\n> \n> July 96  Final draft for Secure Transport Layer Protocol   \"STLP\"\n> \n> This date wasn't mentioned in the BOF.  Doesn't this presume that a\n> Proposed Standard has already come from the working group?\n> \n> Barb Fox\n> bfox@microsoft.com\n\n\nThese are \"guess\" dates at this point. The point is that if we were to \nget an RFC by the end of the year -- a \"final\" draft needs to be \navailable soon. \n\nMy guess is that the sooner this get resolved the better -- with the \nright technical soltion of course. We also have enough combined \nexpertise that this is not totally out of the question.\n\n-- \nTaher Elgamal    elgamal@netscape,com\nChief Scientist, Netscape Communications\n(T) 415 528 2898, (F) 415 528 4122\n\n\n\n"
        },
        {
            "subject": "Info_req",
            "content": "At the TLS BOF a recommended reading list was given.\n\nUnfortunatley I lost my notes !\n\nCould someone please forward the URL's for the \ndocuments that were recommended for reading.\n\nElfed T. Weaver\n\nweaver@hydra.dra.hmg.gb\n\n\n\n"
        },
        {
            "subject": "re. Draft Charte",
            "content": "I'll throw something on the table: why just TCP-based sessions? Why not UDP?\n\nI'm not overly hopeful of *secure* SNMPv(whatever) coming along \"soon\".\nI suspect many management stations have the same stack problem as our\nweb browser systems. \n\nI'd like to see something in the standards space to address alternative\nsolutions to this issue. [Unfortunately I'm way behind in plowing \nthrough the mountain of existing IDs, etc., so if there is anything that\ndoes address this, I'm interested in pointers.]\n\n- C\n\n\n\n"
        },
        {
            "subject": "Do we have chairpeople yet",
            "content": "Unless I missed something, we haven't heard about who is going to chair\nthis potential WG.\n\nSo far the questions put on this mailing list (a request for information on\nthe chairs, or a repeat of the reading list) have gone unanswered. This\ndoes not bode well for an active group.\n\n\n\n"
        },
        {
            "subject": "Re: Do we have chairpeople yet",
            "content": "At 1:51 PM 3/31/96, Paul Hoffman wrote:\n>Unless I missed something, we haven't heard about who is going to chair\n>this potential WG.\n>\n>So far the questions put on this mailing list (a request for information on\n>the chairs, or a repeat of the reading list) have gone unanswered. This\n>does not bode well for an active group.\n\nI'm interested in becoming very actively involved and offer support to this\nWG, but having just heard about it I also don't have any information on who\nis else is involved, the exact charter, etc.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..<http://www.consensus.com/>             o510/559-1500  f510/559-1505..\n\n\n\n"
        },
        {
            "subject": "Re: Do we have chairpeople yet",
            "content": "My aplogies: as list administrator, I did not realize that Jeff Schiller's \nannouncment of Win Treese as chair did not get sent to the list (because\njis@mit.edu is not a subscriber, it was bounced; I have fixed the list to \naccept anyone now).\n\nRohit\n\n\n\n"
        },
        {
            "subject": "Win Treese will Chair the Working Group [From Jeff Schiller",
            "content": "Old-Date: Fri, 29 Mar 1996 13:31:48 -0500\nTo: ietf-tls@w3.org\nFrom: jis@mit.edu (Jeffrey I. Schiller)\nSubject: Win Treese will Chair the Working Group\nContent-Length: 517\nX-List-Url: http://lists.w3.org/Archives/Public/ietf-tls\nX-Diagnostic: Not on the accept list\nX-Envelope-To: ietf-tls\nStatus: RO\n\nAt the TLS BOF in Los Angeles four people volunteered to chair the working\ngroup. Rather then hash out who would in fact chair the group during the\nmeeting, we agreed to have the four volunteers and myself have a\nconversation to decide how to proceed.\n\nOn March 14th Taher Elgamal, Barbara Fox, Charlie Kaufman, Win Treese, and\nmyself conducted a teleconference settle this issue.\n\nOur conclusion was that we all felt it best if Win Treese would act as the\nChair of the group.\n\n                                -Jeff\n\n\n\n"
        },
        {
            "subject": "Re:  IETF mtg discussion comment",
            "content": "From: \"Paul C. Kocher\" <pck@best.com>\n\n> Bennet Yee writes:\n>> 1.  Does pre-encryption prevent MACs from being encrypted?\n>>      [...]\n>> 8.  Features are Optional\n>>\n>> Pre-encryption, pre-MAC-ing, ans password authentication are all\n>> independent options that are (typically) server configuration choices.\n>\n> Pre-encryption selection will require significant changes to how the\n> ciphersuites are negotiated, since some can support pre-encrypted data\n> and others probably won't be able to (i.e., Fortezza).\n\n\nAt the meeting Paul was extremely apologetic that the IETF process had\nbroken down and that much TLS work had recently occurred via private\nemail and/or voice mail; both Paul and Win agreed to fix the process.\n\nPaul, thank you for posting portions of Bennet's comments.\n\nBennet, I hope you will consider discussing protocol features publicly\non the TLS list instead of in one-to-one email.\n\n------------------\n\nMy (incomplete, but perhaps better than nothing :-) notes from the TLS\nworking group meeting in Montreal last week are as follows:\n\n1. Should the TLS working group use SSL 3.0 as a starting point, or define\na list of requirements and a universe of candidate protocols (SSH, PCT,\nHannah, others?) which satisfy some or all of the requirements?\n\nThe question was posed but never definitively answered - my impression\nwas that there was consensus for using SSL 3.0 as the baseline, but to\ngive more than just lip service to features of other protocols (such as\nSSH's ciphersuite-guessing quick startup) that are missing from SSL.\n\n2. Timing - the real need to have a proposed-standard RFC out in a\nshort timeframe (by Dec 1996) was acknowledged, but many of those present\nwere averse to the idea of having the IETF merely rubber-stamp a vendor\nproposal.  Jeff Schiller noted that the requirements for proposed standard\nare fairly loose - the protocol must be well-specified to allow independent\nimplementations, but no actual implementations are required.  SSL and SSH\nboth appear to exceed the requirements for specification quality.  There\nis a 6 month to 2 year timeframe between Proposed- and Draft- Standard\nstatus, and a minimum of 4 months between Draft- and (full) Standard.\n\nChristopher Allen was among those strongly in favor of quickly defining\na TLS 1.0 protocol, delaying agreement on contentious elements until a\n1.1 version.  I don't have a strong objection to this, as long as there\nis a clear understanding and agreement by the commercial sponsors that\nadditional requirements *must* be resolved by the WG before progressing to\nDraft.  The tradeoff is between early adoption of a Proposed standard\nand quick progression to Draft; the total time for resolving contentious\nissues will probably be the same either way.\n\n3. Specific Features:\n\n a) Improved set of error alerts: no disagreement on the need for this,\n    no discussion of specifics.\n\n b) Password authentication:\n\n(from pck:)\n>  Two issues we need to decide:\n>\n>    - Whether to support password authentication at the TLS level.\n>      (Type 2 can be done today by applications using SSL 3.0)\n>      I think everyone here wants to see a certificate-based\n>      infrastructure get developed as quickly as possible, but it\n>      isn't clear whether giving people an alternative to certs\n>      is good (because it helps them make the transision to\n>      certs more smooth) or bad (because it gives them a way to\n>      avoid switching to certs).\n>\n>    - Whether passwords have to be protected from brute force\n>      attacks.\n\nI don't give much weight to meta- (or religious) arguments that\npasswords are good or bad for the proliferation of public key\nauthentication; the issue is how password support impacts the protocol\n(in terms of cryptographic strength, difficulty of analysis, ease of\ndevelopment, run-time performance, backward compatibility, etc.).\n\nThe purpose of password support is to provide authentication-quality\nprotection, as opposed to exportable-confidentiality-quality, protection\nfor static (reusable) passwords.  In the absense of export controls,\nthere would be no need for special protocol support for password\nprotection - they could just be sent like any other application data.\n\nDan Simon's presentation leads me to believe that modifying SSL 3.0\nto support password protection (by defining two additional handshake\nmessages, but not requiring any changes to the record layer) can be\ndone without negative impact on security or performance.  If the\nfeature is not used, there is no change to the bits-on-the-wire.\nThere is apparently strong commercial demand for this feature.  My\nprevious opposition to password support was based on a misunderstanding\nof what it accomplished; I now have no objection to including it in\nthe TLS protocol.\n\nThere was no poll on password support taken at the WG meeting.\n\nPaul's 3 approaches:\n1) use the standard encryption key - i.e. treat passwords like any other data\n2) use a value derived from the master secret to hash passwords\n3) give the master secret to applications\n\n1 is the \"do nothing\" option; 3 is unpleasant because it precludes the\npossibility of isolating the crypto subsystem from unwashed, untrustworthy\napplications.  Option 2 is preferred - the password authentication secret\nshould not be the master secret or the MAC secret directly, it should be\nderived from the master secret in the same way as the rest of the\n\"independent\" keying material.\n\n\n  c. Pre-encryption.  A poll was taken on this topic:  precisely 2 of\nthe members present were in favor of pre-encryption support, a minority\nof those present were willing to at least listen to arguments in favor\nof pre-encryption, and a majority were strongly (Win used the word\n\"absolutely\") opposed.\n\nThat seems like more than rough consensus - although a follow-up should\nbe taken here on the list to confirm.\n\nMy objection to pre-encryption is that even when it is not used, it\nrequires potentially damaging changes to the MAC calculation (replacement\nof the inner hash key with a fixed value).  Aesthetic objections\nto \"layering violations\" aside, I don't believe it's wise to trade off\nprotocol strength for server efficiency.\n\nAnd since Web containers being developed for other purposes (document\nprotection independent of the transmission channel) have the side effect\nof providing the same efficiency gains, there is little reason to try to\nmake pre-encryption \"invisible\" to clients by trying to disguise\nIndependent Data Unit Protection as session protection, weakening the\nsession protection in the process.\n\n\n  d. Modularity (separation of the record layer from the handshake layer):\nThis was not discussed by Win, Paul, Netscape or Microsoft, but there was\nstrong grass-roots support from the floor (including Eric Rescora) that\nTLS should be designed to accommodate multiple keying mechanisms.\nUnfortunately, the IPSEC working group was unable to achieve consensus\non a key management protocol at this time, but Jeff Schiller set a\ndeadline of 1 September for the ISAKMP and SKIP sponsors to come to\nagreement, otherwise the IESG will make the decision.\n\nIf an IETF key management protocol is defined, TLS should be able to use\nit.  I am strongly in favor of an independent record layer, for reasons\ndiscussed earlier on this list.  Bennet Yee also made some excellent\ncomments regarding the requirements a keying API must satisfy.\n\n\n  e. Negotiated or fixed hash algorithms - little discussion, no resolution.\n\n  f. Dedicated or standard tcp port numbers - ditto.\n\n  g. Name of the protocol - ditto, although like Phil Karlton and Paul\nKocher, I (david P. Kemp) think \"PK\" has a nice ring to it :-).\n\n\n\n"
        },
        {
            "subject": "Re: IETF mtg discussion comment",
            "content": "Hi David,\n\nPaul's reply-quoting was of a message that I sent to the IETF mailing\nlist and CC'd to Paul.  Indeed, that message started off with\n\nI'd like to make some comments on the technical side of what was\ndiscussed at the IETF mtg, and repeat some points made there here,\nboth to clarify and add emphasis to the points and to make sure they\ngo into the WG email/web archive.\n\nNow, -I- never got a copy of my own email from the mailing list, but\nthe message did make it into the TLS web archive -- see\n<http://lists.w3.org/Archives/Public/ietf-tls/>.  Maybe the mailing\nlist software is buggy -- but my message that Paul quoted was\ncertainly -not- one-to-one private communications.\n\nAnyway, don't blame me for keeping things private -- additionally, the\nresult of the BOF at Palo Alto was that I was to write up some stuff\non pre-encryption and pre-MACing for inclusion in a draft document\nthat Paul would put together for public comment; others would\nsimilarly contribute on different topics or write separate white\npapers, also for public discussion.  The PA meeting notes were emailed\nto this list and appears in the TLS archive at w3.org.  As it turned\nout, I was slow about it (was away at a conference right after the PA\nBOF) and Paul decided to write it up himself (rather than wait for me)\nbased on a phone conversation and an email message.  This was, as far\nas I could tell, all more-or-less according to what was decided at the\nPalo Alto meeting -- to have various people contribute and produce a\ndraft for public discussion at Montreal.  You might argue that the\nprocedure that was decided upon at the PA mtg was flawed, but....\n\nAlso, please make the distinction between pre-encrypted and pre-MACed\ndata.  They have very different security properties.  I discussed the\ndifferences in my previous email message to the list, and will clarify\nsome other issues in a subsequent message.\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: IETF mtg discussion comment",
            "content": "Hi Paul,\n\nI wanted to clarify a technical point for the list.\n\nPaul's reply to my point:\n> bsy's point:\n> > The second is slightly subtler.  For oft retransmitted data,\n> > re-encrypting them under different keys, especially weak, 40-bit keys,\n> > for many transmissions provides attackers with more partial\n> > information about the plaintext.  If there is only one encrypted\n> > version of the data that is always re-sent, less partial information\n> > about the data is leaked.\n> \n> TLS/SSL and other cryptosystems using 40-bit keys always include\n> a nonce or salt with the key to prevent birthday-paradox style \n> attacks against messages encrypted with more than one key.\n> \n> While having multiple copies of the plaintext encrypted under\n> different keys could theoretically help for some kinds of \n> cryptanalytic attack, this sort of data could be collected\n> using a chosen plaintext attack as well (which the protocol\n> must be able to resist).\n\nThe point that I was trying to make is a generic one that applies to\nall ciphers, regardless of the use of IVs.  It's also why I made a\nreference in the next paragraph:\n\n> > ... (The German nursery rhyme weakness.\n> > [Enigma cryptanalysis history.])\n\nThe idea that I'm trying to get across is related to the idea of\nunicity distance from classical cryptography.  Unicity distance for a\ncipher relative to a data source is defined as the number of\n(symbols/bytes) of ciphertext that an attacker must intercept in order\nto determine the key (and plaintext) in an information-theoretic\nsense.  It's called \"unicity distance\" because it's the point passed\nwhich where there would be a single interpretation of the messages --\nthere'd be only one possible value for the key -- whereas before that\nmultiple keys are possible.  You can find a definition of unicity\ndistance in most cryptography texts.  Some examples:\n\nFor known-plaintext scenarios, the amount of ciphertext for DES is\nbasically one block or eight bytes.  You know the input and output to\nDES, and that (should) information-theoretically completely determine\nthe key, which gives you any other plaintext encrypted with that key.\nI mumbled \"should\", because we don't really know for sure that there\nexists only one key which gives the particular\ninput-block-to-output-block mapping.\n\nFor known-plaintext scenarios with a stream cipher, it's basically the\nnumber of output symbols which information-theoretically allows you to\ncompletely determine the internal state of the stream cipher (call\nthis number N).\n\nWith me so far?\n\nOkay.  I said earlier that the idea of unicity distance is relative to\na source.  What this means is that the unicity distance depends on\nwhat you know about the source -- the generator for the plaintext.  In\nthe known-plaintext case, we had complete knowledge of the source, and\nwe had a relatively easy time figuring out (roughly) what the unicity\ndistance is.  What happens if the source is completely random?\n\nIf the source is truly random, the unicity distance is (typically)\ninfinite.  This is obvious, since given the ciphertext any key could\nhave been used to encrypt plaintext that produces the ciphertext.  I\nmumbled \"typically\", since you -could- have a cipher that isn't\nglobally one-to-one -- that is, the family of encryption functions\n(selected by the key) is one-to-one, but the range set are not\nidentical for all of these functions, so the family of encryption\nfunctions is viewed as having a range that's the union of the ranges\nof the individual encryption functions, and range coverage might tell\nyou the key after an enormous number of messages.  (This is a weird\ncase that people don't typically worry about, but I want to be careful\nw/ my informal definitions here.)\n\nNow, if the source is English text or an HTML document, the unicity\ndistance is (obviously) something between 8 bytes and an infinite\nnumber of bytes for DES (according to Schneier, for English it's 8.2\nbytes; according to Meyer and Matyas, it's 14.6 bytes [probably\ndifferent models of \"English\"]), and between N and infinity for a\nstream cipher.\n\nIn practice, we don't worry -too- much about unicity distances, since\nit's an information theoretic measure, and we care more about the\namount of resources required to break a cipher (time & space) -- this\nis the more modern cryptography approach, esp with scalable (public\nkey) ciphers.\n\nNote, however, that the idea of unicity distance makes intuitive sense\n-- the more you use your cipher system with a fixed key, the more\npartial information you're going to leak.  And eventually, a powerful\nadversary may be able to make use of that partial information to\nfigure out your key.  (Compare this with cryptanalytic attacks such as\nDifferential Cryptanalysis, where even though you know the plaintext,\nall you care about is the xor sum of pairs of them -- which is\ncritical knowledge about the source that's used.)\n\nNow, back to the point.  I argued that if we had a fixed message,\nretransmitting it repeatedly using different keys (and IVs -- this\nidea is indepent of IVs and birthday attacks), we leak partial\ninformation about the data every time we retransmit it.  This is in\nsome ways the dual of the idea of unicity distance -- and since I\nhaven't seen it defined elsewhere I'll call it \"multiplicity\ndistance\": given a secret message (vs secret key in unicity distance)\nof some fixed length, the multiplicity distance of a cipher is the\nnumber of re-encryptions of that message under different keys/IVs that\nan adversary requires to information theoretically determine the text\nof the message.  We don't bother with a model of the source of keying\nmaterial, since keys are supposed to be truly random (though in\n-practice-....)  This model can, of course, be enriched to have the\nmultiplicity distance be a function of the entropy of the random data\nsource as well (e.g., truly random, random English-/HTML-generators\netc).\n\nSo.  What's the multiplicity distance (with an HTML source) for RC4?\nFor DES?  I don't know if anybody in the public sector knows.  I\ndon't.  If we can avoid re-encrypting data, however, we should.\n\n-This- is my argument why pre-encryption helps security.\n\nThere.\n\nOh, yeah.  The German nursery rhyme reference.  That was a reference\nto the breaking of the Enigma system used in WWII -- the operators\nwould often send each other nursery rhymes before the actual message\nto make sure that the two machines were synchronized w/ the\nappropriate (daily or whatever) key.  This was repeated plaintext\nchosen randomly from the space of popular German nursery rhymes, and\naided the Allies in the cryptanalysis of the actual messages.  We\nthink/hope that RC4 is stronger than Enigma, of course, but....\n\n-bsy\n\np.s.  Maybe it's the lengthy tomes that I tend to write, but the\nmailing list software does not seem to be forwarding my messages to\nthe list (conspiracy theories, anyone?:).  In any case, until I hear\nthat the problem's been fixed, I guess I'll periodically resubmit this\ntract until I get a copy myself.\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: IETF mtg discussion comment",
            "content": "I never saw your original either.\n\nAt 03:10 PM 7/1/96 -0700, you wrote:\n>\n>Paul's reply-quoting was of a message that I sent to the IETF mailing\n>list and CC'd to Paul.  Indeed, that message started off with\n>\n>I'd like to make some comments on the technical side of what was\n>discussed at the IETF mtg, and repeat some points made there here,\n>both to clarify and add emphasis to the points and to make sure they\n>go into the WG email/web archive.\n--- from Rodney Thayer <rodney@sabletech.com> +1 617 332 7292 ---\n\n\n\n"
        },
        {
            "subject": "Re: IETF mtg discussion comment",
            "content": "Bennet,\n\n  I heartily apologize for accusing you of being an email conspirator.\nI did look back at my TLS folder to find your messages and didn't see them,\nbut even if the mail list were working perfectly, I could have scanned\nand forgotten the content and mis-filed the messages myself.  I hope the\ndelivery problems can be identified and resolved - especially since the\nmessages are showing up in the archives.\n\nSorry again,\n   dpk\n\n\n\n"
        },
        {
            "subject": "Re: IETF mtg discussion comment",
            "content": "Hi David,\n\nNo prob re email conspiracy accusation.  Apparently there was a\nproblem w/ the w3.org mailing list system over the weekend....\n\nOn to the technical stuff:\n\n> My objection to pre-encryption is that even when it is not used, it\n> requires potentially damaging changes to the MAC calculation (replacement\n> of the inner hash key with a fixed value).  Aesthetic objections\n> to \"layering violations\" aside, I don't believe it's wise to trade off\n> protocol strength for server efficiency.\n\n> And since Web containers being developed for other purposes (document\n> protection independent of the transmission channel) have the side effect\n> of providing the same efficiency gains, there is little reason to try to\n> make pre-encryption \"invisible\" to clients by trying to disguise\n> Independent Data Unit Protection as session protection, weakening the\n> session protection in the process.\n\nPre-encryption does *not* require that you replace the inner hash key\n-- pre-MAC'ing does.  We can have pre-encryption without pre-MAC'ing.\nOr pre-MAC'ing without pre-encryption.  These are *independent* ideas,\nand I fear that many of the IETF attendees missed this fact.\n\nWeb containers may be useful for other reasons, but unless there's a\nprotocol hook there is no efficiency gain, since the containers will\nhave to be sent encrypted (so plaintext data is doubly encrypted).  If\nthe containers are pre-encrypted data and the key simply is\ntransmitted over the TLS-provided channel, then that key will only\nhave an effective key-length equal to the minimum of the length of\nthat key and the length of the TLS-channel key.  Depending on how much\nfixed headers there are in the container format, it may or may not\nhelp to increase the multiplicity distance (it changes the entropy in\nthe source, but w/o container specs it's hard to tell), and if the\ncontainer-key is transmitted as TLS-channel data, this is still an\nimportant consideration.\n\nNow, maybe I misunderstood and you want to send the container over an\nunencrypted channel, but have the associated key sent over a separate,\nTLS-protected channel?  In that case, the above comment about the\neffective key strength still holds; it also complicates the data\ndelivery, in that two communication channels (with different security\nproperties) are required -- and it's not just a single click anymore\n(though I suppose you -could- have the container include an URL to the\nkey as a hack, and have the MIME helper talk to your browser for the\nkey fetch [ick].)\n\nAnyhow, I have been arguing that pre-encryption, unlike pre-MAC'ing,\ndoes NOT necessarily weaken the protocol.\n\n(It of course would allow weak systems with bad configurations which\npermits pre-encryption with ROT-13 over an otherwise 56-bit DES\nencrypted channel; but I'd rather ignore stupid configurations -- I\nassume that the pre-encryption strength is acceptable to both sides.)\n\nNote also that the multiplicity distance concept applies to public key\nsystems as well, with some suitable modifications to the definitions\nto move away from a strictly information theoretic viewpoint.\nHastad's low exponent attack against RSA may be viewed within such a\nframework -- low exponent (e.g., 3) RSA encryption has a multiplicity\ndistance (in messages rather than bytes) equal to the value of the\nexponent, since chinese remaindering of that many ciphertext messages\npermits message recovery.\n\nPaul, as for your comment about the possibility that the\npre-encryption key delivery mechanism might break, this was why I\noriginally argued for the use of a strong cryptosystem for\npre-encryption key delivery (aka key management cipher) in lieu of an\nad-hoc hash-based stream cipher.  As long as the pre-encryption keys\nare -not- made available to the client program (and the whole point\nwas transparency), I don't see it as a real export control problem --\nbut I have never played an export control lawyer on TV.\n\n(This is still certainly better than the IPSEC proposed ESP transforms\nre ITAR.)\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: IETF mtg discussion comment",
            "content": "At 12:24 PM -0700 7/2/96, Bennet Yee wrote:\n>Web containers may be useful for other reasons, but unless there's a\n>protocol hook there is no efficiency gain, since the containers will\n>have to be sent encrypted (so plaintext data is doubly encrypted).\n\nNot that I'm confident that we can properly design pre-encryption into TLS\nright now, but if we are going to there is one thing I'd like to add to the\ndiscussion.\n\nIf there is a protocol hook made, it should also be available in such a\nform that it is compatible with the idea of compression. The option for\ncompression exists in the current draft (though no specific compression\nspecs have been proposed yet) and you don't want to try to compress a\npre-encrypted container.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus>..\n\n\n\n"
        },
        {
            "subject": "IETF Montreal meeting summar",
            "content": "Here is the summary I submitted to the Area Director (Jeff Schiller):\n\nThe TLS working group met once (and for the first time) at the\nMontreal IETF meeting. The group heard presentations from\nPaul Kocher on SSL version 3.0, Tatu Ylonen on SSH, and Mark\nScherlter about ISAKMP.  The main topic of discussion was\nhow the working group should undertake its work, and\nthe group decided to begin with the current SSL 3.0 specification\nand consider some changes. Paul Kocher presented a few\npossible changes, and discussion will continue on the mailing list.\n\nMinutes will follow in a few days.\n\n        - Win Treese\n\n\n\n"
        },
        {
            "subject": "making progres",
            "content": "As noted in the meeting summary, the group has\ndecided to move forward from SSL V3.0 as a starting\npoint.  The draft posted two weeks ago has been revoked.\n\nThere are a number of issues that we need to resolve,\nmost of which have already had discussion on the list.\nA list of the ones I know about (at least) will be included\nwhen the meeting minutes come out in a few days.\n\n\nIn order to make rapid progress and have a solid draft\nfor discussion in December, we need to identify all of the\nissues we might possibly tackle, get detailed proposals for\nthem on the table, debate them, and then merge everything\ninto a discussion draft.\n\nTherefore,  I propose that we proceed as follows:\n\n7/30/96 All issues on the table, with justifications why they\n               are important. On or about 8/2/96, I will post a\n               summary of where we are. Some issues may be\n               accepted or rejected in ensuing discussion during July.\n\n8/31/96 Proposed text/detailed descriptions for proposals due.\n\n9/30/96: Discussion on list of what we should move forward with.\n\nEarly October: document editors/authors meet to hash out\nthe text. (Exact set to be determined)\n\nMid-October: discussion draft available for review.\n\nNovember: discussion on the list, organization of issues remaining\nfor discussion at the San Jose meeting.\n\nDecember: meet in San Jose.\n\nI also propose that we limit discussion of this proposal to conclude\nby Friday, 7/12, so we don't get bogged down in process discussions.\n\nComments and suggestions welcome, either to the list or to me\nprivately.\n\n        - Win Treese\n\n\n\n"
        },
        {
            "subject": "RE: making progres",
            "content": "Thanks for the posting Win.\n\nI wanted to clarify a point concerning the process. \n\nI assume that for the 7/30 deliverables, all that will needed is a\nsimple posting to the list.  However, for the 8/31 deliverables, what is\nthe preferred format for the detailed descriptions?  Should these be\nsubmitted to the IETF as Internet-Drafts?  Should these just be\nsubmitted as text files to the mailing list?  Etc.?\n\nTom Stephens\n>----------\n>From: Win Treese[SMTP:treese@openmarket.com]\n>Sent: Tuesday, July 02, 1996 9:25 PM\n>To: ietf-tls@w3.org\n>Subject: making progress\n>\n>\n>As noted in the meeting summary, the group has\n>decided to move forward from SSL V3.0 as a starting\n>point.  The draft posted two weeks ago has been revoked.\n>\n>There are a number of issues that we need to resolve,\n>most of which have already had discussion on the list.\n>A list of the ones I know about (at least) will be included\n>when the meeting minutes come out in a few days.\n>\n>\n>In order to make rapid progress and have a solid draft\n>for discussion in December, we need to identify all of the\n>issues we might possibly tackle, get detailed proposals for\n>them on the table, debate them, and then merge everything\n>into a discussion draft.\n>\n>Therefore,  I propose that we proceed as follows:\n>\n>7/30/96 All issues on the table, with justifications why they\n>               are important. On or about 8/2/96, I will post a\n>               summary of where we are. Some issues may be\n>               accepted or rejected in ensuing discussion during July.\n>\n>8/31/96 Proposed text/detailed descriptions for proposals due.\n>\n>9/30/96: Discussion on list of what we should move forward with.\n>\n>Early October: document editors/authors meet to hash out\n>the text. (Exact set to be determined)\n>\n>Mid-October: discussion draft available for review.\n>\n>November: discussion on the list, organization of issues remaining\n>for discussion at the San Jose meeting.\n>\n>December: meet in San Jose.\n>\n>I also propose that we limit discussion of this proposal to conclude\n>by Friday, 7/12, so we don't get bogged down in process discussions.\n>\n>Comments and suggestions welcome, either to the list or to me\n>privately.\n>\n>        - Win Treese\n>\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: making progres",
            "content": "At 01:13 PM 7/3/96 -0700, Tom Stephens wrote:\n>Thanks for the posting Win.\n>\n>I wanted to clarify a point concerning the process. \n>\n>I assume that for the 7/30 deliverables, all that will needed is a\n>simple posting to the list.  However, for the 8/31 deliverables, what is\n>the preferred format for the detailed descriptions?  Should these be\n>submitted to the IETF as Internet-Drafts?  Should these just be\n>submitted as text files to the mailing list?  Etc.?\n\nText to the mailing list is preferred. I don't expect them to\nturn into separate Internet Drafts, but to incorporate the\nones we want into the main Draft.\n\n        - Win Treese\n\n\n\n"
        },
        {
            "subject": "TLS working group minutes, Montreal IET",
            "content": "Transport Layer Security Working Group\nMeeting at the 36th IETF\n24 June 1996\n\nReported by Win Treese (treese@OpenMarket.com)\n\nThis meeting was the first one since the working group was chartered.\n\nWin Treese opened the meeting with a few points:\n\n1. The charter has an aggressive schedule, so the working group should aim\nto make rapid progress.\n\n2. There was a draft posted (but not in the drafts directory) prior to the\nmeeting. That draft has been withdrawn. (More details below).\n\nThe meeting consisted of several presentations followed by some\ndiscussion. The presentations were:\n\n- Paul Kocher, status of SSL version 3.0 (Internet Draft available)\n- Tatu Ylonen, on the transport components of SSH (Internet Draft available)\n- Mark Schertler on ISAKMP\n\nThe presentation materials were submitted separately from these\nminutes.\n\nDiscussion centered on several topics:\n\n1. The working group agreed to adopt the SSL version 3.0 draft as the\nstarting point for further progress.\n\n2. There was some discussion about whether or not the key management in\nthe TLS work should adopt from IP-SEC, but the group did not reach any\nconclusions. A variation of this is how the key management system might\nbe made modular.\n\n3. Paul Kocher presented several issues that had been listed by a group\nthat had met a few weeks earlier (notes from that meeting were posted\nto the ietf-tls mailing list). Relevant ones are listed below.\n\n4. One of the issues that got some discussion was whether or not the\nprotocol should include support for pre-encrypted (or pre-MAC'd) data.\nThe idea is that the could improve performance for a server with static\ncontent. There were several objections to this idea, notably the\nargument that this violates layering. Alternatives proposed included\nleaving it to the application (e.g., for a web server, by defining an\nappropriate MIME type).\n\n5. There was some discussion of including compression in the protocol.\nThe current SSL draft has a placeholder, but no compression algorithms\nare defined. Jeff Schiller pointed out that compression has run into\npatent problems, especially when connected with encryption.\n\n6. The group decided to focus on stream protocols like TCP, rather than\ndesign for datagram protocols on UDP as well.\n\nSome of the issues left for continuing discussion include:\n\n1. What hash algorithms are used, and how revisions to the protocol\nshould be managed if/when hash algorithms are broken.\n\n2. Password authentication in the protocol. (There was a rump session\non this following the working group meeting, to be reported to the\nmailing list.) We noted that SSH already incorporates this.\n\n3. Certificate selection.\n\n4. Attribute certificates.\n\nOthers should be raised on the mailing list.\n\nThe working group mailing list is ietf-tls@w3.org. Subscription\nrequests to ietf-tls-request@w3.org.\n\n\n\n"
        },
        {
            "subject": "Re: TLS working group minutes, Montreal IET",
            "content": "Date: Thu, 11 Jul 1996 02:48:37 -0400\nFrom: Win Treese <treese@openmarket.com>\n\n> Transport Layer Security Working Group\n> Meeting at the 36th IETF\n> 24 June 1996\n>\n> Reported by Win Treese (treese@OpenMarket.com)\n>\n> ...\n>\n> 5. There was some discussion of including compression in\n> the protocol. The current SSL draft has a placeholder,\n> but no compression algorithms are defined. Jeff\n> Schiller pointed out that compression has run into\n> patent problems, especially when connected with\n> encryption.\n>\n\nIs there a problem with having GNU ZIP as a compression\nalgorithm?\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "TLS negotiation mechanis",
            "content": "I'm new to this list, so I apologize if thess issues have already been \nraised.\n\nI believe we agreed to begin with SSL v3 and incorporate features of \nother protocols such as SSH, PCT, etc.  There are two issues I'd like \nto address, SSH and ISAKMP.  I will begin with SSH.\n\nSSH\n\nSince Montreal, I have had time to review the SSH spec.  I'm no expert \nin SSH, so if I've made any mistakes or misassumptions, please correct \nme.  There are three features of SSH that I would like to see added to \nthe TLS spec:\n\n1)  Reduced round trips by assuming that the server will prefer the same \ncryptographic attributes as the client.  The benefit of cutting the \nround trips in half seem to out-weigh the cost of possibly sending extra \nunusable data.  This is especially true for INTRAnets where client and \nserver will very likely (almost always) prefer the same algorithm suite.\n\n2)  Negotiating cryptographic algorithms separate of each other.  I am \naware of the risk of combining cryptographic algorithms which were not \ninteded for use with each other.  The spec could address this with \nguidance as to what works with what.  \n\nI have had trouble with the opposite problem.  I have worked with the \ngovernment's FORTEZZA project.  SSL defined two tags for FORTEZZA.  The \nfirst supported FORTEZZA I&A with FORTEZZA encryption, the second \nsupported FORTEZZA I&A with no encryption.  The problem is that FORTEZZA \nencryption is currently too slow.  I have customers who would like to \nuse FORTEZZA I&A, but would prefer RC4 encryption for performance.  The \nproblem is that there is no FORTEZZA/RC4 tag.  The time it takes to \ncreate a new tag and convince vendors to provide software to use the new \ntag is unacceptable.  FORTEZZA encryption will be fixed before such a \ntag exists.\n\n3)  Service request message.  I used to run multiple web servers on one \nmachine.  I can't do that anymore, since each SSL web server want to use \nport 443.  If I change the port number, my firewalls don't recognize the \nport as HTTP and reject requests.  \n\nI like the approach of using one port for the secure channel and \nnegotiating a service.  What I don't like about the way SSH implements \nthis is that the service request message is encapsulated.  This means \nthat my proxy does not know what protocol is riding on top of SSH.  \n\nIs there any objection to providing a service request message which is \nsent in the initial client hello?  This would be unencapsulated, so my \nproxy could verify that I am using a valid protocol.  If the server does \nnot support the service, I find out before going through the remainder \nof the steps needed to establish a channel.\n\n\nISAKMP\n\nI am even less knowledgable in ISAKMP.  I have not completely read the \nspec, so take this with a grain of salt.  Most of what I know of ISAKMP \ncomes from talking with Mark Schertler after the TLS meeting (but please \ndon't hold him responsible for my misunderstandings).\n\nGiven that the TLS-WG needs to produce a spec quickly, there seems to be \ntwo paths to follow:\n\n1)  Start from existing de facto standards and \"correct and improve\" \nupon this base work.\n\n2)  Leverage existing IETF work which has been through the ringer and \npreviously debated.\n\nThe group chose to follow path 1, but I think path 2 may be the better \napproach.\n\nFrom an initial reading of ISAKMP, it sounds like it has most of the \nnegotiation features needed by a TLS protocol.  If we could make use of \nISAKMP for negotiations, a great deal of the TLS work is eliminated, and \nwe can produce a well defined standard quickly.\n\nIf I recall Mark's briefing correctly, ISAKMP provides these benefits:\n\n1)  Leverage existing IETF work.  Why spend additional effort debating\nnegotiation issues that have already been flushed out in defining\nISAKMP?\n\n2)  Several protocols (e.g., TLS, SOCKS, IPv6) could share the same key\nmanagement code.  This simplifies migration from one protocol to\nanother.\n\n3)  Separate negotiations for security attributes (e.g., signing, hash,\nencryption algorithms).\n\n4)  Support for attribute certificate passing.\n\n5)  2 round trips to establish a security association\n\nI am unsure of the difficulty in implementing ISAKMP.  I know Cisco has \na reference implementation from the following announcement:\n\n>Cisco Systems is pleased to announce the release of a reference\n>implementation of the IETF's Internet Security Association and Key\n>Management (ISAKMP) Protocol. This software distribution is being \n>made available free of charge for any commercial or non-commercial\n>use to advance ISAKMP as a solution to the problem of Internet Key\n>Management.\n\nAre there any other implementations of ISAKMP?  What level of effort is \ninvolved in supporting ISAKMP as compared to SSL?\n\nI think ISAKMP should be seriously considered as the TLS negotiation \nmechanism.  If anyone has any strong feelings for or against ISAKMP, I \nthink now is the time to flush them out, before we get too far down the \n\"correct and improve\" path.  \n\nAs I said earlier, I don't have a strong enough ISAKMP foundation to \nvote either way at this time.  I do feel that it has enough potential to \nwarrent my taking a deeper look at the spec.  I would urge those on this \nlist who, like me, are not familiar with ISAKMP to give it a closer \nlook.  I would also urge those who are familiar with the spec to point \nout its strengths and weaknesses.\n\nGood judgment comes from experience,\nexperience comes from bad judgment.\n\nJason Smith\n\nThe MITRE Corporation\n(703) 883 - 6219\njason@mitre.org\n\n\n\n"
        },
        {
            "subject": "Re: CompuServe Positions on Passphrases and TL",
            "content": "Your points on the security of well-built passphrase systems are excellent.\n\nFrom an architectural standpoint, I thought the issue instead was:\nWhat the !#$%@ are application-level authentication concepts doing in\na transport-level confidentiality protocol?\n\nTLS is attacking a very appropriate solution for user-installable\nconfidential streams -- but they are streams, no more or less. I think\nit's no more reasonable to run an application authentication and\nauthorization protocol than to sign a \"document\" within a stream\nabstraction. \n\nPass-phrase driven key-establishment *may* be an appropriate whistle for\nTLS/SSL3 to address, but the service of exchanging passphrases securely\nmight well be out of scope.\n\nRohit Khare\n(my opinions, not W3C's)\n\n\n\n"
        },
        {
            "subject": "RE: CompuServe Positions on Passphrases and TL",
            "content": ">From: Rohit Khare[SMTP:khare@w3.org]\n>\n>From an architectural standpoint, I thought the issue instead was:\n>What the !#$%@ are application-level authentication concepts doing in\n>a transport-level confidentiality protocol?\n>\nIf authentication is an \"application-level\" concept unfit for the TLS\nlayer, then most of the TLS handshake should be thrown away, since it\ndeals largely with authentication.  Personally, I consider\nauthentication to be far too sensitive a task to trust to applications.\n(Then again, I also consider authorization to be far too sensitive a\ntask to trust to applications; how many operating systems, after all,\ntreat file access control as an application-level matter?)  But\nregardless of where you think authentication should go, passphrase-based\nauthentication should obviously be in the same place as public-key-based\nauthentication, since they both perform the same function.  \n\nAs for authorization, the only people I can think of who are trying to\nslip authorization into TLS are pushing attribute certificates, not\npassphrase authentication.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n>\n\n\n\n"
        },
        {
            "subject": "Repost of CompuServe Position on Passphrase",
            "content": "Due to some nuances with the TLS list server, some folks didn't recieve\nthe following message the first time. Therefore we are reposting. Sorry   \nfor the\nduplication of you have seen it.\n******************************************\n\nWHY SUPPORT PASS-PHRASE AUTHENTICATION?\n\nIn the proposed work plan for developing a draft of the TLS 1.0/SSL 3.x\nprotocol, Win Treese wrote:\n\n        7/30/96 All issues on the table, with justifications why they\n               are important. On or about 8/2/96, I will post a\n               summary of where we are. Some issues may be\n               accepted or rejected in ensuing discussion during July.\n\nSince CompuServe intends to support pass phrases for authentication for   \nthe\nforeseeable future, we would like to see an application-\nindependent authentication protocol that supports pass phrases.\nTo make sure all issues are discussed regarding the inclusion of\npass phrase based authentication in the TLS protocol we submit the   \nfollowing.\nSome are reasons to support pass phrases; some items debunk myths that\nsometimes become arguments for forbidding pass phrases.\n\nIn this paper, the term \"credentials\" refers to whatever the user must\npossess, such as a name and a private key or secret key, to complete the\nauthentication process.\n\nPASS PHRASES ARE INSECURE--One sometimes hears the argument that pass\nphrases are inherently insecure. Generally, there are three such\narguments, all false.\n\nFirst, the argument goes, pass phrases are insecure because someone who\nintercepts network traffic between the user and service learns the pass\nphrase. Such an argument is predicated on the concept of transmitting\npass phrases in the clear. Anyone who transmits pass phrases in the\nclear should be shot. This is not an argument against pass phrases, but\nan argument against a particular implementation of pass phrases.\n\n(The public-key equivalent false argument: To prove that I know the\nprivate key that corresponds to the public key in the certificate I sent\nyou, I will transmit my private key in the clear, and you may use it to\nverify that it corresponds to the public key. But anyone watching learns\nmy private key. Therefore, public keys are insecure technology. QED.)\n\nThere are simple, secure challenge-response mechanisms that prevent an\neavesdropper from learning the pass phrase. These mechanisms are, in\nfact, identical in concept to mechanisms used with public keys--we\ngenerate challenges, you sign it, and I check the result--although\nthey're quite a bit faster than the public key algorithms.\n\nNext, the argument goes, pass phrases are insecure because an\neavesdropper can discover your pass phrase by using a dictionary attack.\nThe old, Unix-style, across-the-board dictionary attack is not\napplicable, but one could attack an individual challenge-response pair.\n\nThat is certainly a valid concern. But we call them pass phrases for a\nreason: most implementations encourage, or even require, the use of a\nvery short \"password,\" and that's wrong. You can avoid a dictionary\nattack simply by using a pass phrase that won't be discovered by a\ndictionary attack. Furthermore, the underlying mechanism is based on a\nbinary string of bits. If you don't mind giving up the ability to type\nyour pass phrase, your pass phrase can be a random binary number, which\nis not at all subject to dictionary attack.\n\nFinally, the argument goes, pass phrases are insecure because the\nservice must know your pass phrase to verify that you used the right\none. But the service needn't know your pass phrase; many schemes, such\nas Kerberos, KryptoKnight, RPA, and even the typical, if not terribly\ngeneral purpose, RADIUS scheme used by PPP servers to support CHAP,\naccomplish pass-phrase authentication without requiring the service to\nknow, nor allowing the service to learn, the pass phrase.\n\n\nYOU DON'T HAVE TO USE THEM--If you don't want to use pass phrases for\nauthentication, you don't have to use pass phrases for authentication.\nThe argument that pass phrases should be forbidden in a protocol because\nyou wouldn't use them in your application, is unfounded.\n\n\nTHE VALUE OF WHAT'S BEING PROTECTED--If you're protecting something for\nwhich you believe that a simple pass phrase is inadequate, you can\nrequire better pass phrases. And if you believe that any textual pass\nphrase is inadequate, you can use a random binary shared secret. And if\nyou believe that a random binary shared secret is inadequate, you can\nuse some other mechanism. Again, the argument against the ability to use\na mechanism because you wouldn't use it to protect the Space Shuttle's\nself-destruct mechanism, is unfounded.\n\n(People's checking and savings accounts are protected by a four-digit\nnumber. People clearly go overboard in both directions--ridiculously\nweak and ridiculously strong--when designing security mechanisms.)\n\n\nCUSTOMER SERVICE--If a user loses his credentials, either in the sense\nof their being compromised or they're no longer existing, it should be\neasy to fix. With pass phrases, a customer service representative may\neasily change the user's pass phrase and tell the user the new one,\nduring the customer's telephone call. The customer may immediately use\nthat pass phrase to authenticate himself. (Obviously, he may immediately\nchange it afterward.) With public key authentication, the problem can't\nbe solved in one telephone call. Similar issues arise for a newly\nsigned up user.\n\n\nMULTIPLE SERVICES--Many service providers want to provide multiple\nservices to a user, without requiring that user to possess multiple\naccounts or identities or credentials. Consider, for example, an\nInternet service provider that wishes to provide IP connectivity via\nPPP, and additional services. With current technology, one must use a\npass phrase for PPP authentication (preferably with CHAP, but that's not\nthe issue at hand). Ideally, the same identity and pass phrase should be\nuseful for other services provided by that service provider, impossible\nif pass phrases are required for PPP but forbidden for other services.\n\n\nMULTIPLE MACHINES--Many users use more than one machine; two machines at\nhome, one at the office, a notebook, etc. Such situations are no problem\nfor pass phrases, but are more problemmatic for other technologies. Some\nday, every machine will have a smartcard reader, but that day isn't here\nyet. In the mean time, there are proposals for ways to export, transfer,\nand import the contents of a \"wallet,\" but those are too awkward for\nordinary users.\n\n\nThere are suggested schemes for generating private keys from a pass\nphrase. There's a clever idea, but it might be considered more an\nargument for than against pass phrases. Some suggest deriving the\nprivate key from a pass phrase, then storing the private key in a\nwallet, requiring a pass phrase again only when you wish to import the\nkey into another wallet. That's useful in some applications, but most\nusers would have forgotten the pass phrase by the time he needs it.\n\n\nNOT STORING ON MACHINE--A closely related question is that of using your\nidentity without storing your credentials on the machine. There are\nprimarily two reasons you might want to do that.\n\nFirst, you might simply prefer to carry your credentials with you--I   \ndon't\nwant to store them on my machine because I don't want someone to be able\nto use my account.Second, it might not be your machine--I want to check\nmy email from the machine in a conference room, or, would you mind if\nI check my email from your machine?\n\nFor such purposes, pass phrases work well. Another approach is to carry\na diskette, and import the credentials into a wallet on the temporary\nmachine, use them, then remember to delete them, but that can be\nawkward. Of course, there are obvious trust issues; even to use it only\ntemporarily, you must trust the software on that machine. But those\nissues arise no matter what technology you use--with public keys, you\nmust trust the machine when you import the copy of your private key, and\nwith smartcards, you must trust the machine not to ask your smartcard to\nsign anything other than what you intended to sign--so those \"trust\"\nissues are irrelevant to the \"pass phrases or not\" argument.\n\n\nEXISTING USER BASE--If you already have a set of users who use pass\nphrases for authentication, you do not want to migrate to a new protocol   \nthat\nwon't be capable of authenticating them, so you won't migrate to the new\nprotocol.\n\n\nPASSPHRASES AS A SEPARATE LAYER--There are two good reasons for including   \n\npassphrase-based authentication directly into the protocol, rather than\nlayering it on top, as must be done with currently available protocols.\nOne reason has to do with the messy details of export controls:\nif incorporated into the protocol, an authentication response can\nbe protected by a stronger key than is permitted for exportable\nencryption of generic bulk data.  The other reason has to do with\ninteroperability; if a single, well-designed passphrase-based   \nauthentication\nprotocol can be selected as the standard for use in conjunction with TLS,   \n\nthen those who choose to use it (and only those who do) need not worry\nabout designing and implementing such a protocol from scratch, and\nensuring that all clients and servers are supplied with the same\nimplementation.\n\n\nPASS PHRASES WILL DELAY THE TRANSITION TO PUBLIC KEYS--If you believe\nthat public keys are such a bad solution that people won't use them\nunless they're forced to use them, then they ARE a bad solution and we\nshould delay the transition to public keys. Conversely, if public keys\nare the right solution, the marketplace will embrace them, and systems\nusing other authentication mechanisms will disappear.\n\n\nPRIVATE KEYS CAN BE STORED SECURELY; PASS PHRASES CANNOT--\nOne sometimes\nhears the argument that private keys are secure because the \"wallet\"\n(credential storage facility) on the PC can prevent anyone from seeing\nthem, while pass phrases are insecure because the API must include a\nfunction that returns a copy of the pass phrase. This turns out to be a\nmeaningless argument that neither private keys nor pass phrases win.\n\nFirst, it's not necessarily true that the \"wallet\" must reveal a pass\nphrase. Just as the wallet knows about various public-key authentication\nschemes, it can know about various secret-key authentication schemes.\nUsing exactly the same techniques, its API can protect the shared secret\nby providing only a \"you give me the challenge and I'll give you the\nresponse\" function.\n\nOn the other hand, if one wants to be able to use a particular pass\nphrase with plaintext authentication schemes, then there indeed must be\na function to return that pass phrase. So, one might argue, pass phrases\nare indeed weaker.\n\nBut, on the third hand, it's easy to forget that a function that returns\na response given a challenge--in PK terms, a function that signs the\nspecified input--is almost as good as revealing the secret. (Naively\ndesigned, it's literally as good, but we presume here that the designers\nunderstand that the function must do PKCS-1 formatting, etc.) That is,\n\"making sure you can't _see_ the secret\" is only one aspect of the\nproblem, albeit an important one. \"Making sure you can't _use_ the\nsecret\" can be nearly as important, because I, as a rogue program, can\ndo interesting things even if I can't see your secrets, yet that's\nalmost impossible to protect against.\n\nAnd on the fourth hand, one must consider that the wallet provides an\n\"export\" function that indeed reveals all secrets, including private\nkeys, in a (necessarily) well-defined format that I, the program\nrequesting the exported copy, can decrypt and read. (This is probably an\nargument for adding some otherwise gratuitous UI to the low-level wallet\nexport function.)\n\n\nSTATE OF THE TECHNOLOGY--So far, no one has deployed public keys for\nauthentication in an environment involving real users. And we know of no\none who has yet determined the costs to implement a large-scale\ncertificate signing operation, in terms of manpower, security, hardware,\nlicensing, etc. Almost all currently envisioned PK-based operations are\nrelatively small, \"intranet\" environments. And even those are only\nenvisioned; this is untried technology.\n\nCompuServe Incorporated  \n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "Personally, I'm opposed to password (or passphrase) authentication for\na number of reasons.  In my response, I've mostly restricted my comments\nto technical issues.  Basically, I think passwords work fine if you\nonly have one, but after that they become a problem.\n\nJohn Macko wrote:\n> \n> PASS PHRASES ARE INSECURE--One sometimes hears the argument that pass\n> phrases are inherently insecure. Generally, there are three such\n> arguments, all false.\n> \n> First, the argument goes, pass phrases are insecure because someone\n> who intercepts network traffic between the user and service learns the\n> pass phrase. Such an argument is predicated on the concept of\n> transmitting pass phrases in the clear. Anyone who transmits pass\n> phrases in the clear should be shot. This is not an argument against\n> pass phrases, but an argument against a particular implementation of\n> pass phrases.\n\n[ ... ]\n\n> There are simple, secure challenge-response mechanisms that prevent an\n> eavesdropper from learning the pass phrase. These mechanisms are, in\n> fact, identical in concept to mechanisms used with public keys--we\n> generate challenges, you sign it, and I check the result--although\n> they're quite a bit faster than the public key algorithms.\n\nUnfortunately, they all rely on the fact that the challenger knows the\npassword.\n\n> Next, the argument goes, pass phrases are insecure because an\n> eavesdropper can discover your pass phrase by using a dictionary\n> attack. The old, Unix-style, across-the-board dictionary attack is not\n> applicable, but one could attack an individual challenge-response\n> pair.\n>\n> That is certainly a valid concern. But we call them pass phrases for a\n> reason: most implementations encourage, or even require, the use of a\n> very short \"password,\" and that's wrong. You can avoid a dictionary\n> attack simply by using a pass phrase that won't be discovered by a\n> dictionary attack. Furthermore, the underlying mechanism is based on a\n> binary string of bits. If you don't mind giving up the ability to type\n> your pass phrase, your pass phrase can be a random binary number,\n> which is not at all subject to dictionary attack.\n\nThat works fine if there's only one passphrase to remember.  If you have\nto remember many, you'll either end up writing them down (bad), or using\nthe same passphrase for each service (really bad).  If you rely on your\ncomputer to remember the random binary strings of bits, then you lose\nthe biggest advantage of passwords, the ability to carry them around in\nyour head.\n\n> Finally, the argument goes, pass phrases are insecure because the\n> service must know your pass phrase to verify that you used the right\n> one. But the service needn't know your pass phrase; many schemes, such\n> as Kerberos, KryptoKnight, RPA, and even the typical, if not terribly\n> general purpose, RADIUS scheme used by PPP servers to support CHAP,\n> accomplish pass-phrase authentication without requiring the service to\n> know, nor allowing the service to learn, the pass phrase.\n\nThis is semantics.  You claim that these systems don't require the\nservice to know your passphrase, but that's only true if you don't\nconsider the authentication authority to be part of the service.  In\nKerberos this is the ticket-granting server.  In RADIUS, this is\npassword daemon.  I'm not familiar with KryptoKnight and RPA, but I'm\nsure they are the same.\n\n> CUSTOMER SERVICE--If a user loses his credentials, either in the sense\n> of their being compromised or they're no longer existing, it should be\n> easy to fix. With pass phrases, a customer service representative may\n> easily change the user's pass phrase and tell the user the new one,\n> during the customer's telephone call. The customer may immediately use\n> that pass phrase to authenticate himself. (Obviously, he may\n> immediately change it afterward.) With public key authentication, the\n> problem can't be solved in one telephone call. Similar issues arise\n> for a newly signed up user.\n\nI don't see how this is any different for certificates.  The user loses\nhis private key (for whatever reason).  He calls customer service, they\ninvalidate his current certificate.  He then logs in and generates a\nnew certificate, going through the Equifax (or whatever) authentication\nprocess he went through initially to generate an account.  Customer\nservice can even generate a one-time PIN that he can use for this\npurpose.\n\n> PASSPHRASES AS A SEPARATE LAYER--There are two good reasons for\n> including passphrase-based authentication directly into the protocol,\n> rather than layering it on top, as must be done with currently\n> available protocols.\n>\n> One reason has to do with the messy details of export controls:\n> if incorporated into the protocol, an authentication response can\n> be protected by a stronger key than is permitted for exportable\n> encryption of generic bulk data.  The other reason has to do with\n> interoperability; if a single, well-designed passphrase-based\n> authentication protocol can be selected as the standard for use in\n> conjunction with TLS, then those who choose to use it (and only those\n> who do) need not worry about designing and implementing such a\n> protocol from scratch, and ensuring that all clients and servers are\n> supplied with the same implementation.\n\nI don't think we should be burdening an international standard with\nidiosyncrasies imposed by brain-damaged US regulations that will\nhopefully be repealed in the near future.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: CompuServe Positions on Passphrases and TL",
            "content": "Dan Simon wrote:\n> \n> As for authorization, the only people I can think of who are trying to\n> slip authorization into TLS are pushing attribute certificates, not\n> passphrase authentication.\n\nI don't think anyone is trying to \"slip\" anything in anywhere.  Unless\nyou know something I don't?\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "making progres",
            "content": "In the interest of making progress, I think we need to have a common\ndocument to work from.  If everyone thinks this is a good idea, I'd be\nhappy to incorporate the SSL 3.0 errata into the spec and then make it\navailable.\n\nShould I include change bars?  Should I post it to the list, or put it\nup for ftp?  Both?\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: CompuServe Positions on Passphrases and TL",
            "content": "On Jul 22, 11:09am, Dan Simon wrote:\n> Personally, I consider authentication \n> to be far too sensitive a task to trust to applications.\n\nHm, and why? If I play the role of an application programmer, I consider \nauthentication to be far too sensitive a task to trust to the operating \nsystem or something similar (;-). Its all a question of standpoint.\n\nEspecially in  the Web environment, the server needs to authenticate \nusers, that might not necessarily be authenticated at the operating \nsystem level at all, at their system, and may only be authenticated at \nthe application-level, considering the web-server an application. \n\nRegarding to TLS, it seems obvious to me that authentication of the \nmachine fits very well into that layer, while authentication of the user \n<might> be something different (assuming the OSI-Model). Maybe, as TLS \n\"traditionally\" is incorporated into the applications, the architectural \nclarity, that Rohit aimed at (if I interpreted him correctly), \napparently has been lost. \n\n> (Then again, I also consider authorization to be far too sensitive a\n> task to trust to applications; how many operating systems, after all,\n> treat file access control as an application-level matter?)  \n\nYou are an operating-systems person, aren't you :-). \n\nOf course it is the responsibility of the OS to protect the files, but \nisn't it the Web-Servers responsibility to protect the pages? If we \nassume a full integration of web-services into the OS, such that there \nno longer is a web-server per se, your wishes become true of course, and \nwe only have to discuss/specify how a user on Unix authenticates himself \nto a MS-Windows-NT machine at the OS-level. Fine with me, but is this \nrealistic for now?\n\nUntil then, I see that authorization needs to be done at the \nServer-level. And, if the server does not trust the OS, or TLS, \nauthentication of the user needs to be done there too. I would prefer, \nfor architectural reasons, to have a machine-level authentication of \nsome sort at the transport level, and user-level authentication on the \napplication level. \n\nPeter Lipp\n\n-- \nDr.Peter Lipp, \nTechnische Universitdt Graz - University of Technology Graz\nInstitut f|r Angewandte Informationsverarbeitung und Kommunikationstechnologien\nKlosterwiesgasse 32/I, A-8010 Graz, ++43 316 873-5513, Fax: ++43 316 873 5520\n------------------------------------------------------------------------------\nWas nutzt die beste Erziehung, die Kinder machen uns ja doch alles nach.\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": ">From: Tom Weinstein[SMTP:tomw@netscape.com]\n>\n>I don't think we should be burdening an international standard with\n>idiosyncrasies imposed by brain-damaged US regulations that will\n>hopefully be repealed in the near future.\n>\nA rousing sentiment, to be sure.  Perhaps Tom would also like to propose\nexpunging those \"brain-damaged\" EXPORT cipher suites from TLS?  Or can I\nassume that we all (or the rest of us, at least) recognize the\nregrettable need for the standard to deal with unpalatable legal\nrealities?\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "> A rousing sentiment, to be sure.  Perhaps Tom would also like to propose\n> expunging those \"brain-damaged\" EXPORT cipher suites from TLS?  \n\nSounds like a great idea to me.\n\n> Or can I assume that we all (or the rest of us, at least) recognize\n> the regrettable need for the standard to deal with unpalatable legal\n> realities?\n\nThere are many quite competant implementors who live outside the scope\nof U.S. export controls.  Given that the standard can be implemented\non both sides of the U.S. export control firewall, I see no reason to\ndumb down the protocol.\n\n- Bill\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "Dan Simon wrote:\n> \n> >From:  Tom Weinstein[SMTP:tomw@netscape.com]\n> >\n> >I don't think we should be burdening an international standard with\n> >idiosyncrasies imposed by brain-damaged US regulations that will\n> >hopefully be repealed in the near future.\n> >\n> A rousing sentiment, to be sure.  Perhaps Tom would also like to propose\n> expunging those \"brain-damaged\" EXPORT cipher suites from TLS?  Or can I\n> assume that we all (or the rest of us, at least) recognize the\n> regrettable need for the standard to deal with unpalatable legal\n> realities?\n> \n>                                 Daniel Simon\n>                                 Cryptographer, Microsoft Corp.\n>                                 dansimon@microsoft.com\n> \n> >\n> >\n\n\nIt's great to see a real dialogue going on this list.  However, can I \nsuggest that we keep messages on this list as friendly as possible?\nWatching the sequence of messages on this thread, I am a bit surprised \nat the tone of your message, Dan.  It's very possible I misinterpreted \nwhat you are trying to say above and, if so, then I apologize.  I think \nwe all realize the need to deal with legal realities and in this regard \nwe are all in this together.  At the same time, we aren't happy about \nit, so I understand when we sound-off about it. Tom's reference was to \nthe laws, not to any individual.  Relative to the specification, I \nbelieve that we should seek out ways to meet legal realities today and \ntomorrow wherever practical. Certainly things are changing (for example, \n128-bit Navigator electronic download is now permitted).\n\nRegards,\nEric\n\n-- \nEric Greenberg Product Manager, Security\nNetscape Communications Corp.\nericg@netscape.com  Phone: (415) 937-3020\n-- \"speakin for just me and no one else\" --\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "Tom Weinstein wrote:\n\n>>Unfortunately, they all rely on the fact that the challenger knows the\n>password.\n...\n\n>>This is semantics.  You claim that these systems don't require the\n>>service to know your passphrase, but that's only true if you don't\n>>consider the authentication authority to be part of the service.  In\n>>Kerberos this is the ticket-granting server.  In RADIUS, this is\n>>password daemon.  I'm not familiar with KryptoKnight and RPA, but I'm\n>>sure they are the same.\n\nThe distinction between whether the application server or the\nauthentication authority knows the passphrase is much more than\nsemantics.  Multiple online services are interested in allowing their\nmembers to visit external *hot* websites based on the online service\nmembership.  First, if the application server gains knowledge of the\npassword it becomes trivial for a rogue server to impersonate the user,\nand incur charges against the user's online membership.  Second, if the\nexternal website becomes affiliated with multiple online services, it\ncannot be allowed access to credentials in a way that could be usefully\ndivulged between competing services. \n\nDon Schmidtdonsch@microsoft.com\n\n>----------\n>From: Tom Weinstein[SMTP:tomw@netscape.com]\n>Sent: Monday, July 22, 1996 11:25 PM\n>To: John Macko\n>Cc: 'ietf-tls@w3.org'\n>Subject: Re: Repost of CompuServe Position on Passphrases\n>\n>Personally, I'm opposed to password (or passphrase) authentication for\n>a number of reasons.  In my response, I've mostly restricted my comments\n>to technical issues.  Basically, I think passwords work fine if you\n>only have one, but after that they become a problem.\n>\n>John Macko wrote:\n>> \n>> PASS PHRASES ARE INSECURE--One sometimes hears the argument that pass\n>> phrases are inherently insecure. Generally, there are three such\n>> arguments, all false.\n>> \n>> First, the argument goes, pass phrases are insecure because someone\n>> who intercepts network traffic between the user and service learns the\n>> pass phrase. Such an argument is predicated on the concept of\n>> transmitting pass phrases in the clear. Anyone who transmits pass\n>> phrases in the clear should be shot. This is not an argument against\n>> pass phrases, but an argument against a particular implementation of\n>> pass phrases.\n>\n>[ ... ]\n>\n>> There are simple, secure challenge-response mechanisms that prevent an\n>> eavesdropper from learning the pass phrase. These mechanisms are, in\n>> fact, identical in concept to mechanisms used with public keys--we\n>> generate challenges, you sign it, and I check the result--although\n>> they're quite a bit faster than the public key algorithms.\n>\n>Unfortunately, they all rely on the fact that the challenger knows the\n>password.\n>\n>> Next, the argument goes, pass phrases are insecure because an\n>> eavesdropper can discover your pass phrase by using a dictionary\n>> attack. The old, Unix-style, across-the-board dictionary attack is not\n>> applicable, but one could attack an individual challenge-response\n>> pair.\n>>\n>> That is certainly a valid concern. But we call them pass phrases for a\n>> reason: most implementations encourage, or even require, the use of a\n>> very short \"password,\" and that's wrong. You can avoid a dictionary\n>> attack simply by using a pass phrase that won't be discovered by a\n>> dictionary attack. Furthermore, the underlying mechanism is based on a\n>> binary string of bits. If you don't mind giving up the ability to type\n>> your pass phrase, your pass phrase can be a random binary number,\n>> which is not at all subject to dictionary attack.\n>\n>That works fine if there's only one passphrase to remember.  If you have\n>to remember many, you'll either end up writing them down (bad), or using\n>the same passphrase for each service (really bad).  If you rely on your\n>computer to remember the random binary strings of bits, then you lose\n>the biggest advantage of passwords, the ability to carry them around in\n>your head.\n>\n>> Finally, the argument goes, pass phrases are insecure because the\n>> service must know your pass phrase to verify that you used the right\n>> one. But the service needn't know your pass phrase; many schemes, such\n>> as Kerberos, KryptoKnight, RPA, and even the typical, if not terribly\n>> general purpose, RADIUS scheme used by PPP servers to support CHAP,\n>> accomplish pass-phrase authentication without requiring the service to\n>> know, nor allowing the service to learn, the pass phrase.\n>\n>This is semantics.  You claim that these systems don't require the\n>service to know your passphrase, but that's only true if you don't\n>consider the authentication authority to be part of the service.  In\n>Kerberos this is the ticket-granting server.  In RADIUS, this is\n>password daemon.  I'm not familiar with KryptoKnight and RPA, but I'm\n>sure they are the same.\n>\n>> CUSTOMER SERVICE--If a user loses his credentials, either in the sense\n>> of their being compromised or they're no longer existing, it should be\n>> easy to fix. With pass phrases, a customer service representative may\n>> easily change the user's pass phrase and tell the user the new one,\n>> during the customer's telephone call. The customer may immediately use\n>> that pass phrase to authenticate himself. (Obviously, he may\n>> immediately change it afterward.) With public key authentication, the\n>> problem can't be solved in one telephone call. Similar issues arise\n>> for a newly signed up user.\n>\n>I don't see how this is any different for certificates.  The user loses\n>his private key (for whatever reason).  He calls customer service, they\n>invalidate his current certificate.  He then logs in and generates a\n>new certificate, going through the Equifax (or whatever) authentication\n>process he went through initially to generate an account.  Customer\n>service can even generate a one-time PIN that he can use for this\n>purpose.\n>\n>> PASSPHRASES AS A SEPARATE LAYER--There are two good reasons for\n>> including passphrase-based authentication directly into the protocol,\n>> rather than layering it on top, as must be done with currently\n>> available protocols.\n>>\n>> One reason has to do with the messy details of export controls:\n>> if incorporated into the protocol, an authentication response can\n>> be protected by a stronger key than is permitted for exportable\n>> encryption of generic bulk data.  The other reason has to do with\n>> interoperability; if a single, well-designed passphrase-based\n>> authentication protocol can be selected as the standard for use in\n>> conjunction with TLS, then those who choose to use it (and only those\n>> who do) need not worry about designing and implementing such a\n>> protocol from scratch, and ensuring that all clients and servers are\n>> supplied with the same implementation.\n>\n>I don't think we should be burdening an international standard with\n>idiosyncrasies imposed by brain-damaged US regulations that will\n>hopefully be repealed in the near future.\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": ">From: Eric Greenberg[SMTP:ericg@netscape.com]\n>\n>It's great to see a real dialogue going on this list.  However, can I \n>suggest that we keep messages on this list as friendly as possible?\n>Watching the sequence of messages on this thread, I am a bit surprised \n>at the tone of your message, Dan.  It's very possible I misinterpreted \n>what you are trying to say above and, if so, then I apologize.  I think \n>we all realize the need to deal with legal realities and in this regard \n>we are all in this together.  \n\nAbsolutely.  That was my point, really.\n\n>At the same time, we aren't happy about \n>it, so I understand when we sound-off about it. Tom's reference was to \n>the laws, not to any individual.  \n\nAnd likewise, my remarks were written and posted without the slightest\nhint of personal hostility towards anyone.  Perhaps we should all just\nagree to give each other room for a bit of crabbiness when discussion\nturns to export laws.   :^)\n\n>Relative to the specification, I \n>believe that we should seek out ways to meet legal realities today and \n>tomorrow wherever practical. \n\nAgreed.\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n \n>\n\n\n\n"
        },
        {
            "subject": "RE: CompuServe Positions on Passphrases and TL",
            "content": ">From: Peter Lipp[SMTP:plipp@iaik.tu-graz.ac.at]\n>\n>On Jul 22, 11:09am, Dan Simon wrote:\n>> Personally, I consider authentication \n>> to be far too sensitive a task to trust to applications.\n>\n>Hm, and why? If I play the role of an application programmer, I consider \n>authentication to be far too sensitive a task to trust to the operating \n>system or something similar (;-). Its all a question of standpoint.\n\nI'm not so sure.  From the application programmer's standpoint, is file\naccess control too sensitive a task to trust to the operating system?\n\nI can think of at least two good reasons for leaving file access control\nto the operating system:\n\n1)  Access permissions are normally independent of the application.  If\nI want a certain file to be read only by certain people, then I don't\ncare which application those people may be using; I simply want access\ndenied them.  It therefore makes sense to control access in a\ncentralized way.\n\n2)  Access control being a sensitive matter, I would rather have the\noperating system try to implement it correctly once than rely on each\napplication writer to do it correctly every single time.  Eventually,\nafter all, one of them is bound to get it wrong.\n\nAs far as I can tell, both of these reasons apply equally to\nauthentication (and the latter, at least, applies to authorization as\nwell).  \n>\n>Especially in  the Web environment, the server needs to authenticate \n>users, that might not necessarily be authenticated at the operating \n>system level at all, at their system, and may only be authenticated at \n>the application-level, considering the web-server an application. \n\n>This is the only argument I've heard so far for leaving authorization in the\n>hands of the application:  operating systems have not (yet) stepped up to do\n>the job.  Now, that's a perfectly good argument for *letting* the application\n>do authorization.  But it seems like a very bad argument for *preventing* the\n>OS (via TLS, perhaps, in the future) from doing a job that (in my view) it\n>should be doing in the first place.\n>\n>> (Then again, I also consider authorization to be far too sensitive a\n>> task to trust to applications; how many operating systems, after all,\n>> treat file access control as an application-level matter?)  \n>\n>You are an operating-systems person, aren't you :-).\n\nNo, I'm just a cryptographer who spends far too much of his time naively\nberating operating systems people for not doing their job properly.  But\nthanks for the compliment.  :^)\n> \n>Of course it is the responsibility of the OS to protect the files, but \n>isn't it the Web-Servers responsibility to protect the pages? If we \n>assume a full integration of web-services into the OS, such that there \n>no longer is a web-server per se, your wishes become true of course, and \n>we only have to discuss/specify how a user on Unix authenticates himself \n>to a MS-Windows-NT machine at the OS-level. Fine with me, but is this \n>realistic for now?\n\nIs the TLS model unrealistic?  Authentication of both clients and\nservers under TLS has already been implemented in several places in a\nmanner which makes authentication pretty much invisible to the\napplication.  This is an important first step, in my view, towards\nwresting general authentication out of the hands of applications and\nplacing it in the OS where it belongs.  That more steps are necessary\ndoesn't make this one any less welcome.    \n>\n>Until then, I see that authorization needs to be done at the \n>Server-level. And, if the server does not trust the OS, or TLS, \n>authentication of the user needs to be done there too. I would prefer, \n>for architectural reasons, to have a machine-level authentication of \n>some sort at the transport level, and user-level authentication on the \n>application level. \n\nI'm not familiar with these \"architectural reasons\".  If the OS took\ncare of both, why would that be an \"architectural\" problem?\n>\n>\n>Daniel Simon\n>Cryptographer, Microsoft Corp.\n>dansimon@microsoft.com\n>\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "John Macko wrote:\n> PASS PHRASES ARE INSECURE--One sometimes hears the argument that pass\n> phrases are inherently insecure. Generally, there are three such\n> arguments, all false.\n\n  Here is one of my objections to passwords.\n\n  I believe that the following are facts:\n\n1) many people send their passwords in the clear over the internet\n   every day.  Many of the protocols used on the internet\n   use passwords sent in the clear, and lots of people\n   (the majority?) use these protocols without underlying\n   encryption such as SSL.\n\n2) many (most?) people reuse their passwords.\n\n  If someone snoops passwords from major sites on the internet that\nuse HTTP basic authentication, I believe that they will find a\nsignificant percentage of people using the same password that\nthey use for your system.\n\n--Jeff\n\n-- \nJeff Weinstein - Electronic Munitions Specialist\nNetscape Communication Corporation\njsw@netscape.com - http://home.netscape.com/people/jsw\nAny opinions expressed above are mine.\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "> From ietf-tls-request@w3.org Thu Jul 25 06:36:35 1996\n> Resent-Date: Thu, 25 Jul 1996 06:36:08 -0400\nFrom: Jeff Weinstein <jsw@netscape.com>\n\n> 2) many (most?) people reuse their passwords.\n\nThat is a good argument for requiring that users not be allowed\nto choose their passwords.  Isn't that standard practice at most\nweb sites that use basic auth - the content provider, not the user,\npicks the password?\n\nDon't get me wrong - I believe there is not a single good thing\nthat can be said about static passwords. But the question here is\nshould the TLS protocol support strong protection for them.  As\nthe proposal appears to have no negative effect on the rest of\nTLS, I don't see a reason for opposing the password proposal.\n\nThe fact that it's technically silly to store newspaper grocery coupons\nin bank safe deposit boxes doesn't imply that banks should prohibit\ntheir misguided customers from storing coupons or other nearly worthless\nmaterial there.\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "> The distinction between whether the application server or the\n> authentication authority knows the passphrase is much more than\n> semantics.  \n\nAnother problem with using passwords is that it almost invariably allows\nthe administrator of the authentication authority to impersonate any\nregistered user. It makes accountability highly dubious.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://home.netscape.com/people/karlton\nNetscape Communications\n\nThis kind of rotor is known as a squirrel-cage rotor\nbecause the way it's wound is like a bird cage.\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": ">\n>From: Phil Karlton[SMTP:karlton@netscape.com]\n>\n>Another problem with using passwords is that it almost invariably allows\n>the administrator of the authentication authority to impersonate any\n>registered user. It makes accountability highly dubious.\n\nThere is no question that there are strong arguments against using\nshared-key authentication, as opposed to the public-key variety.  The\nquestion is whether there are arguments *for* using shared-key\nauthentication.  If there are legitimate arguments in its favor (and I\nbelieve John Macko and others have presented some), then there will\ninevitably be particular circumstances in which those arguments will win\nout against the drawbacks mentioned by Phil and others.  Since we are\nsupposed to be developing a general purpose protocol, we should do our\nbest to accommodate those circumstances.\n\nOnce again, the addition of the shared-key authentication feature to TLS\ndoes absolutely *nothing* to anyone who doesn't want to use it,\nimplement it or support it.  No one I know of is suggesting that it\nwould be in any way improper to refuse to support this feature in one's\nsoftware, machine, installation, enterprise or Web site.  It would be\nthere for those who (in Phil's opinion are foolish enough to) want to\nuse it in concert with others in the same frame of mind.  So what on\nearth is the big deal?\n\n>\n>Daniel Simon\n>Cryptographer, Microsoft Corp.\n>dansimon@microsoft.com\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "It seems to me that the discussion about whether to offer passphrase\nauthentication in TLS is a bit of a red herring.\n\nIf you want to present the passphrase authentication abstraction to the\nuser, then this is easy-- passphrases are (roughly speaking) a key management\ntechnique, or are most powerful when used as such.  (Witness PGP's private\nRSA key protected both by host security and a passphrase.)\n\nMost of the requirements listed in your email can be satisfied by letting\nthe user see the passphrase user interface, using the passphrases for key\nmanagement, and using e.g. RSA keys for TLS key exchange.  (I'll certainly\nadmit that this is only roughly true-- for instance, the requirement that\nfolks be able to take their cryptographic secrets with them in their head,\nwithout any floppy disks or whatnot, isn't solved by that paradigm-- but\nit seems to cover most of the objections.)\n\nThen again, I'm just starting to learn this stuff, so what do I know...\nIf I'm being dense, tell me to shut up. :-)\n\n-- Dave Wagner, TLS.newbie-at-large.\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "David P. Kemp wrote:\n> \n> > From ietf-tls-request@w3.org Thu Jul 25 06:36:35 1996\n> > Resent-Date: Thu, 25 Jul 1996 06:36:08 -0400\n> From: Jeff Weinstein <jsw@netscape.com>\n> \n> >       2) many (most?) people reuse their passwords.\n> \n> That is a good argument for requiring that users not be allowed\n> to choose their passwords.  Isn't that standard practice at most\n> web sites that use basic auth - the content provider, not the user,\n> picks the password?\n\n  I have accounts on over a dozen sites that use basic auth on\nthe internet.  In every case I provided my own username and\npassword.  If these sites forced passwords on users they would\nend up with a lot less subscribers.\n\n> Don't get me wrong - I believe there is not a single good thing\n> that can be said about static passwords. But the question here is\n> should the TLS protocol support strong protection for them.  As\n> the proposal appears to have no negative effect on the rest of\n> TLS, I don't see a reason for opposing the password proposal.\n\n  I think that including password authentication does weaken\nTLS.  Every time someones password is stolen and used to\nimpersonate someone using TLS, it will weaken the public\nperception of the standard.  I realize that this is not a\ntechnical concern, but it is a real one.\n\n--Jeff\n\n-- \nJeff Weinstein - Electronic Munitions Specialist\nNetscape Communication Corporation\njsw@netscape.com - http://home.netscape.com/people/jsw\nAny opinions expressed above are mine.\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "Dan Simon wrote:\n\n> Once again, the addition of the shared-key authentication feature to TLS\n> does absolutely *nothing* to anyone who doesn't want to use it,\n> implement it or support it.  No one I know of is suggesting that it\n> would be in any way improper to refuse to support this feature in one's\n> software, machine, installation, enterprise or Web site.  It would be\n> there for those who (in Phil's opinion are foolish enough to) want to\n> use it in concert with others in the same frame of mind.  So what on\n> earth is the big deal?\n\nInteroperability for one. If the community fragments into differing\nauthentication sub-camps, we all lose.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://home.netscape.com/people/karlton\nNetscape Communications\n\nThis kind of rotor is known as a squirrel-cage rotor\nbecause the way it's wound is like a bird cage.\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "I dont see a resolution coming out of this discussion, at least not in the form of\ngeneral consensus.  The issues for password seem to be based on technical\nstrength versus business need.  I dont see how these two can be resolved.\n\nIssues:\nAgainst:\n1) scalability: the user's ability to remember a different password for every service\nand that that simply doesn't scale because a person has a finite number of things\nthat he can remember.\n2) symmetric: both sides must know the secret.\n3) dictionary attack possible if use human-simple passphrase (even though can\nreduce this if require multiple words and non-alpha characters, e.g. 1toad$frog2,\nand the same format is not required on all passphrases)\n\nFor:\n1) simple to understand, use, and manage\n2) portable\n3) legacy\n\nHow is the working group going to select if cant get consensus?  Will the chair\nforce closure? \n\nHas anyone tried a compromise?  How about making it so additional\nauthentication methods could be added to the handshake protocol.  If the protocol\nwas further modularized so completely different authentication mechanisms that\ndid not follow the SSL 3.0 style key exchange could be plugged in, then the\npassword scheme could be added later in another RFC or as an appendix to the\nbasic TLS RFC.\n\nThe idea is to further structure the handshake protocol in SSL 3 so a clear box is\ndrawn around authentication.  The input parameters to the box and the output\nparameters from the box need to be clearly defined.  The output parameters would\nallow the protocol as defined after the key exchange to continue on, such as the\nFinished message.  Within the box, depending on the authentication method\nselected in the negotiation, the sequence of packet exchanges could be different:\nspecific to the authentication mechanism.  A class of authentication mechanisms\nthat use the same packet exchange sequence are already defined in SSL (rsa,\ndiffie_hellman, fortezza_dms).  Another case would be the passphrase\nauthentication method, or methods of the same class that would use the same set\nof packet exchanges.\n\nI am also interested in being able to add other existing authenication mechanisms\nto this, such as Novell's NetWare 4 authentication.  The ability to have a broader\ncollection of authentication mechanisms, the certificate/key exchanges, the pass\nphrase mechanisms, and the existing NetWare 4 mechanism what meet our\nbusiness needs more \n\nThe alternate authentication methods all do not need to be defined up front, but a\nmethod for adding them in without breaking existing implementations would be\nnecessary. Perhaps the only way to ensure this is by allowing the algorithms to\nbe negotiated separately rather than negotiating a \"crypto suite.\"   This would\nallow more flexibility in adding new protocols as they are developed.  Are there any\nplans to do this?\n\nthanks\nKeith\n-----------------------------------------\nKeith Ball                   Internet mail:  Keith_Ball@novell.com\nBuilding 1                  GroupWise mail:  Keith Ball\n2180 Fortune Drive\nSan Jose Fortune  (sjf.novell.com)\nMailstop: F1-42-2D\nvoice: (408) 577 8428\nFax:   (408) 577 5855\n\nNovell, Inc.\n\n-- sent via the Novell GroupWise\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "At 3:49 PM -0700 7/26/96, Keith Ball wrote:\n>Issues:\n>Against:\n>1) scalability: the user's ability to remember a different password for every\n>service and that that simply doesn't scale because a person has a finite\n>number of things that he can remember.\n>2) symmetric: both sides must know the secret.\n>3) dictionary attack possible if use human-simple passphrase (even though can\n>reduce this if require multiple words and non-alpha characters, e.g.\n>1toad$frog2, and the same format is not required on all passphrases)\n\nI'd like to to the Against:\n\nYou can still have password security at the application protocol level.\nNothing in the current protocol prevents this. For instance, right now you\ncan add SSL under ftp, use SSL's server-only authentication or\ndiffie-helman anonymous to secure the channel, and then use use FTP's\ncurrent password methods to authenticate the client. Same can be done with\nHTTP using it's current auth structure, and most every other protocol over\nSSL.\n\nIt's not elegant, but neither is shoehorning passwords into TLS, and it has\nthe advantage of working now.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus>..\n\n\n\n"
        },
        {
            "subject": "proposal to add attribute certificates to TLS 3.",
            "content": "WHAT ARE ATTRIBUTE CERTIFICATES\n\nThey are a signed object that asserts additional properties with\nrespect to some identity certificate. An attribute cert has no\nassociated key pair and consequently cannot be used to establish\nidentity. Informally, one can think of them as a mechanism for\nextending the attributes of an identity certificate (noting that the\nextended attributes may be signed by a different CA than the base\ncertificate).\n\nAttribute certs typically have a much shorter lifetime than identity\ncertificates.\n\n                MOTIVATION\n\nSome of our customers have identified a particular problem that could\neasily be solved by introducing AttributeCerts: some individuals take\non temporary roles within the organization and there is need to grant\ntemporary authorization to access additional sets of data. This can and\ndoes happen, for instance, when some manager goes on vacation.  In the\npaper world, the temporary manager is given \"signing authority\" for\nthings normally covered by the vacationng manager.\n\nAn AttributeCert would be used in a corresponding way: permission to\ntake some action would be encapsulated into an attribute certificate\nwith a lifetime that covered the period of the vacation.\n\n                Side Effects \n\nIf the the AttributeCert hammer gets created, a number of potential\nproblems start turning into nails.\n\na) Since individuals change roles more often than indentities, we risk\nexploding the size of CRLs as new certificates have to crafted as those\nroles change.\n\nb) This allows the cost of carrying around athorization to be amortized\nacross the users who are making use of it. The need for distributing\naccess control lists to all servers in an organization would go away.\nA central authority could issue short lifetime AttributeCerts on a\nregular basis and publish those in a public place or directly to the\nowners of the base certificates.\n\nc) This more clearly allows the separation the uses of authentication\n(identity) and authorization (permission). Many bugs get introduced\ninto security models when those two \"auths\" are confused.\n\nd) By retaining the base identity cert, maintaining access logs becomes\nsimpler to the application above TLS.\n\ne) If all the data needed by any server relevant to a single individual\nhad to be in that individual's identity certificate, that certificate\nmight become unwieldy because of size. This allows attributes to be\nbundled in logical groups.\n\n                IMPLEMENTATION OUTLINE\n\nI will wave my hands pretty fast here, but not so fast that I leave the\nground. :-) Details should be able to be tied down in a straightforward\nmanner if the TLS working group decides to proceed. (This means that I\nam not much interested in discussing the details of the following. It\nis only being presented as a suggestion (not a proof) of concept.)\n\nAn AttributeCert could have much the same syntax as a X.509v3\ncertificate with a null public key.\n\nThere would be a required attribute that would identify the base\ncertificate to which the rest of the attributes apply. The value of\nthat attribute might contain the public key of the base certificate, or\na secure hash of the entire base certificate or both.\n\nThe TLS protocol would be augmented by allowing the server to include\nan AttributeCertifcateRequest message following a CertifacteRequest\nmessage and before a ServerKeyExchange message (if any). The message\nwould consist of a list of tuples\n        list of attributes required signing authority (as in a\n        CertificateRequest message)\n\nThe client would then optionally send a second Certificate message\ncontaining the AttributeCert following the base certificate chain and\nbefore the ClientKeyExchange message.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://home.netscape.com/people/karlton\nNetscape Communications\n\nThis kind of rotor is known as a squirrel-cage rotor\nbecause the way it's wound is like a bird cage.\n\n\n\n"
        },
        {
            "subject": "DIMACS Workshop on Trust Management in Network",
            "content": "--------------------------------------------------------------------------\n| DIMACS: Center for Discrete Mathematics & Theoretical Computer Science |\n| A National Science Foundation Science and Technology Center            |\n--------------------------------------------------------------------------\n\nDIMACS Workshop on Trust Management in Networks\n\nDates: Sept. 30 - Oct. 2, 1996\n\nLocation: CORE Bldg., Rutgers University Busch Campus, Piscataway NJ\n\nCo-Chairs: Ernie Brickell, Bankers Trust, brickell@btec.com\n           Joan Feigenbaum, AT&T Research, jf@research.att.com\n           Dave Maher, AT&T Research, dpm@research.att.com\n\n\nTheme: The use of public-key cryptography on a mass-market scale\nrequires sophisticated mechanisms for managing trust.  For example,\nany application that receives a signed request for action is forced to\nanswer the central question ``Is the key used to sign this request\nauthorized to take this action?''  In certain applications, this\nquestion reduces to ``Does this key belong to this person?'' In\nothers, the authorization question is considerably more complicated,\nand resolving it requires techniques for formulating security policies\nand security credentials, determining whether particular sets of\ncredentials satisfy the relevant policies, and deferring trust to\nthird parties.  This workshop covers all aspects of the trust\nmanagement problem.  Relevant topics include but are not limited to:\n\n          General approaches to trust management\n          Languages, systems, and tools\n          Certificates and public-key infrastructure \n          Formal models and analysis\n          Trust management in specific application domains,\n                including but not limited to:\n                Banking\n                E-mail\n                Internet commerce\n                Licensing\n                Medical information systems\n                Mobile programs and ``code signing''\n                Revocation of cryptographic keys\n\n\nConfirmed speakers include:\n\n          Butler Lampson, Microsoft\n          Matt Blaze, AT&T Research\n          Steve Kent, BBN \n          Carl Ellison, Cybercash\n\n\nContributed talks:\n\nIf you would like to attend and give a talk, please email a one-page\nabstract (NOT A FULL PAPER) in ascii format to Joan Feigenbaum at\njf@research.att.com by September 1, 1996.  The Trust Management\nworkshop will be informal, and there are currently no plans to publish\nproceedings.\n\n\nFor more information: \n\nIf you would like to attend but not give a talk, contact Joan\nFeigenbaum at jf@research.att.com any time before the beginning of\nthe workshop.  There is a small amount of support available for\npeople who do not have other sources of travel funds. \n\nInformation about local arrangements, travel, lodging and registration\ncan be found at http://dimacs.rutgers.edu/Workshops/Management.\nThose without WWW access can contact Pat Pravato at 908-445-5929 or\npravato@dimacs.rutgers.edu.\n\nThis workshop is part of DIMACS Special Year on Networks.\nInformation about the Special Year on Networks can be\nfound at DIMACS WWW site: http://dimacs.rutgers.edu or by\ncontacting the center.\n\n   --------------------------------------------------------------------- \nThe Special Year program is made possible by long term funding from the \nNational Science Foundation, the New Jersey Commission on Science and \nTechnology and DIMACS university and industry partners.\n\nDIMACS Center; Rutgers University; P.O. Box 1179; Piscataway, NJ 08855-1179 \n TEL: 908-445-5928 FAX: 908-445-5932  **  EMAIL:  center@dimacs.rutgers.edu\n WWW:  http://dimacs.rutgers.edu **TELNET:  telnet info.rutgers.edu 90  \n\n   DIMACS is a partnership of Rutgers University, Princeton University, \n         AT&T Research, Bellcore, and Lucent - Bell Laboratories.\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "> From: Keith Ball <Keith_Ball@novell.com>\n> \n> The issues for password seem to be based on technical strength versus\n> business need.\n>   [...]\n> Has anyone tried a compromise?  How about making it so additional\n> authentication methods could be added to the handshake protocol.\n\n\nNo. The \"good\" (again, I don't think static passords themselves are\na good idea) thing about the current password proposal is that it\ncannot corrupt the authentication mechanism used by TLS.\n\nThe only thing the proposal does is protect passwords from sniffers\n*using* the authentication strength of TLS instead of it's (possibly weaker)\nencryption strength.  This is a safe technical option - it does not\nreduce the strength of TLS authentication or encryption.\n\nIt may or may not weaken the public perception of TLS - and I by virtue\nof being employed by the Government am utterly unqualified to take\nany credible position on PR questions :-).\n\nIt is just important to remember that the password question as it\nstands is entirely an issue of perception, not of technical strength,\nand it will have to be decided accordingly.\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "The solution suggested below \n\n>>use use FTP's current password methods to authenticate the client.\n>>Same can be done with HTTP using it's current auth structure,\n>and most every other protocol over SSL.\n\nis precisely one of the problems that including a standard shared-secret\nauth mechanism in TLS is designed to solve.  Each one of these protocols\ndoes password auth in an app specific manner.  It would greatly simplify\nthe development, deployment and administration of secured apps if there\nis was one system-level protocol and I/F for security.  This is a\nbenefit of TLS for certificate-based auth.  When it is within our grasp,\nwho are we to deny the same benefit to  applications or service\nproviders that have reasons to continue to use shared-secret based auth?\n\nDon Schmidt\ndonsch@microsoft.com\nProgram Manager\nMicrosoft Corp.\n\n>----------\n>From: Christopher Allen[SMTP:ChristopherA@consensus.com]\n>Sent: Friday, July 26, 1996 4:46 PM\n>To: Keith Ball\n>Cc: ietf-tls@w3.org\n>Subject: RE: Repost of CompuServe Position on Passphrases\n>\n>At 3:49 PM -0700 7/26/96, Keith Ball wrote:\n>>Issues:\n>>Against:\n>>1) scalability: the user's ability to remember a different password for\n>>every\n>>service and that that simply doesn't scale because a person has a finite\n>>number of things that he can remember.\n>>2) symmetric: both sides must know the secret.\n>>3) dictionary attack possible if use human-simple passphrase (even though\n>>can\n>>reduce this if require multiple words and non-alpha characters, e.g.\n>>1toad$frog2, and the same format is not required on all passphrases)\n>\n>I'd like to to the Against:\n>\n>You can still have password security at the application protocol level.\n>Nothing in the current protocol prevents this. For instance, right now you\n>can add SSL under ftp, use SSL's server-only authentication or\n>diffie-helman anonymous to secure the channel, and then use use FTP's\n>current password methods to authenticate the client. Same can be done with\n>HTTP using it's current auth structure, and most every other protocol over\n>SSL.\n>\n>It's not elegant, but neither is shoehorning passwords into TLS, and it has\n>the advantage of working now.\n>\n>------------------------------------------------------------------------\n>..Christopher Allen                  Consensus Development Corporation..\n>..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n>..                                             Berkeley, CA 94707-2116..\n>..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n>..  Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus>..\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "At 5:46 PM -0700 7/31/96, Don Schmidt wrote:\n>>>use use FTP's current password methods to authenticate the client.\n>>>Same can be done with HTTP using it's current auth structure,\n>>and most every other protocol over SSL.\n>\n>is precisely one of the problems that including a standard shared-secret\n>auth mechanism in TLS is designed to solve.  Each one of these protocols\n>does password auth in an app specific manner.  It would greatly simplify\n>the development, deployment and administration of secured apps if there\n>is was one system-level protocol and I/F for security.  This is a\n>benefit of TLS for certificate-based auth.  When it is within our grasp,\n>who are we to deny the same benefit to  applications or service\n>providers that have reasons to continue to use shared-secret based auth?\n\nBut if you are going to do that much engineering to change software to \"one\nsystem-level protocol\", then it should be a small step to using\ncertificates correctly. If legacy is important, they use the application\nlevel AUTH commands over SSL. If you are doing something new, use\ncertificates.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus>..\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "Don Schmidt writes:\n> \n> The solution suggested below \n> \n> >>use use FTP's current password methods to authenticate the client.\n> >>Same can be done with HTTP using it's current auth structure,\n> >and most every other protocol over SSL.\n> \n> is precisely one of the problems that including a standard shared-secret\n> auth mechanism in TLS is designed to solve.  Each one of these protocols\n> does password auth in an app specific manner.  It would greatly simplify\n> the development, deployment and administration of secured apps if there\n> is was one system-level protocol and I/F for security.\n\nI disagree. For the services named above, the implementer will want to\nkeep the non-TLS functionality in place for connecting to\nnon-TLS version of the service.  Hence, the existing password\nmechanisim will remain.  If the TLS versions use TLS-password\nauthentication instead of the existing password authentication, then\nnew calls will need to be written to support the TLS passwords\nin addition to the existing passwords.\n\nSimilarly, the deployment and administration will, at least in\nthe short to medium term, be more complicated, not less.  With\nTLS-autheitication passwords there's now one more password database\nthat will need to be maintained, checked for weak passwords etc.\nArguably, most installations will want to support the non-TLS versions\nof the above services, for service inside the \"secure\" LAN.\n\n>  This is a\n> benefit of TLS for certificate-based auth.  When it is within our grasp,\n> who are we to deny the same benefit to  applications or service\n> providers that have reasons to continue to use shared-secret based auth?\n\n1. they already have password based auth built into their protocols.\nAdding TLS underneath can make the passwords \"secure\" without requiring\nas much of a rewrite of the code.\n\n2. not putting password auth in TLS will encourage new apps\nto use the much superior certificate-based authentication\nrather than allowing lazy implementers to stick with the\nfamiliar old passwords.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": ">\n>From: Keith Ball[SMTP:Keith_Ball@novell.com]\n>\n>I dont see a resolution coming out of this discussion, at least not in the\n>form of\n>general consensus.  The issues for password seem to be based on technical\n>strength versus business need.  I dont see how these two can be resolved.\n>\n>Issues:\n>Against:\n>1) scalability: the user's ability to remember a different password for every\n>service\n>and that that simply doesn't scale because a person has a finite number of\n>things\n>that he can remember.\n>2) symmetric: both sides must know the secret.\n>3) dictionary attack possible if use human-simple passphrase (even though can\n>reduce this if require multiple words and non-alpha characters, e.g.\n>1toad$frog2,\n>and the same format is not required on all passphrases)\n\nAn important technical point:  this is *not* the case if\npassphrase-based authentication is integrated properly into TLS, with\nthe authentication response properly protected by strong encryption.  \n>\n>For:\n>1) simple to understand, use, and manage\n>2) portable\n>3) legacy\n>\n>How is the working group going to select if cant get consensus?  Will the\n>chair\n>force closure? \n>\n>Has anyone tried a compromise?  How about making it so additional\n>authentication methods could be added to the handshake protocol.  If the\n>protocol\n>was further modularized so completely different authentication mechanisms\n>that\n>did not follow the SSL 3.0 style key exchange could be plugged in, then the\n>password scheme could be added later in another RFC or as an appendix to the\n>basic TLS RFC.\n>\n>The idea is to further structure the handshake protocol in SSL 3 so a clear\n>box is\n>drawn around authentication.  The input parameters to the box and the output\n>parameters from the box need to be clearly defined.  The output parameters\n>would\n>allow the protocol as defined after the key exchange to continue on, such as\n>the\n>Finished message.  Within the box, depending on the authentication method\n>selected in the negotiation, the sequence of packet exchanges could be\n>different:\n>specific to the authentication mechanism.  A class of authentication\n>mechanisms\n>that use the same packet exchange sequence are already defined in SSL (rsa,\n>diffie_hellman, fortezza_dms).  Another case would be the passphrase\n>authentication method, or methods of the same class that would use the same\n>set\n>of packet exchanges.\n>\n>I am also interested in being able to add other existing authenication\n>mechanisms\n>to this, such as Novell's NetWare 4 authentication.  The ability to have a\n>broader\n>collection of authentication mechanisms, the certificate/key exchanges, the\n>pass\n>phrase mechanisms, and the existing NetWare 4 mechanism what meet our\n>business needs more \n>\n>The alternate authentication methods all do not need to be defined up front,\n>but a\n>method for adding them in without breaking existing implementations would be\n>necessary. Perhaps the only way to ensure this is by allowing the algorithms\n>to\n>be negotiated separately rather than negotiating a \"crypto suite.\"   This\n>would\n>allow more flexibility in adding new protocols as they are developed.  Are\n>there any\n>plans to do this?\n\nThere is an implicit trade-off here between two goals:  the need to\nestablish a single standard and avoid interoperability problems, and the\nneed to accommodate alternate authentication methods, particularly in\nthe shared-key case, where adaptations of legacy systems might be\ndesirable.  (I suspect that a single public-key authentication standard\nshould be sufficient, since public-key-based client authentication\nhasn't been widespread enough to engender numerous incompatible\nvariations.)  I don't think it would be a good idea to create a fancy\nnegotiation of shared-key authentication protocols, because the possible\nvariations are virtually endless, even if only protocols in current use\nare taken into account.\n\nOn the other hand, shared-key authentication protocols have the common\ncharacteristic of requiring previous agreement on a key before the\nauthentication can take place.  Assuming, then, that this agreement also\ninvolves agreement on an authentication protocol, the choice of protocol\ncan be implicitly negotiated through the \"certifier\" negotiation that\nalready takes place in SSL (and presumably TLS as well).  In the shared\nkey case, the \"certifier\" would simply be the identity (distinguished\nname) of the other possessor of the client's shared key.    \n\nWhat I proposed in a brief after-meeting presentation at the Montreal\nIETF meeting was that shared-key authentication come in two flavors,\n\"standard\" and \"private\".  The \"standard\" variety would follow a\nparticular protocol specified by TLS, while the \"private\" variety would\nbe unconstrained, and assumed to be previously agreed upon by client and\ncertifier.  The choice of certifier/authentication service would be\nnegotiated just as the CA is currently negotiated in SSL public-key\nclient authentication.  \n\nI believe that this design is an optimal compromise between the goals of\ninteroperability and flexibility, and moreover dispenses with the need\nfor yet another official list, this time of registered valid\nauthentication protocols.  \n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n>\n>\n\n\n\n"
        },
        {
            "subject": "Password Deployment Issues  and  Attribute Certificate",
            "content": "1.Deployment Issues of Having Shared Secret Authentication in\nTLS Versus Certificate-Based Authentication\n\nIn message <199608010139.SAA32135@slack.lne.com>, Eric Murray writes:\n> \n> Similarly, the deployment and administration will, at least in\n> the short to medium term, be more complicated, not less.  With\n> TLS-autheitication passwords there's now one more password database\n> that will need to be maintained, checked for weak passwords etc.\n> Arguably, most installations will want to support the non-TLS versions\n> of the above services, for service inside the \"secure\" LAN.\n\nWhy are we second guessing deployment complexity / costs here?  John\nMacko of Compuserve, presumably, knows better, and he's made his (or\nhis company's) opinion known.\n\nNow, I'm not a systems analyst / economist / whatever, but it seems to\nme that the obvious thing to do for Compuserve and others like them\n(say ``Company X'') is to take the existing database of customer\npasswords and hook that into their web servers, using\nODBC/COM/CORBA/acronym-of-the-day.  No new database -- just interfaces\nto existing ones.  If/when the customers upgrade their web browsers\n(floppy in magazine, anonymous ftp, whatever), the switch to\nTLS-provided, strong-crypto-protected shared secret authentication is\nlargely transparent to the user.  And you've successfully transitioned\nto better protection for the user authentication, since after a few\nyears only an acceptably small percentage of people will not have\nupgraded.\n\nYou don't lose customers because you don't have to tell them that they\nhave to upgrade and obtain a client certificate.  Granted, this can be\nautomated if you bundle extra software with the web browser to\nautomatically obtain a class 1 verisign cert (and btw have the user\nshell out six bucks [assuming here that its out of beta]), this is not\nreally acceptable since people grab free browsers from many sources,\nnot just company X.  (And recent studies show that people on the\nInternet are pretty cheap.)  On the other hand, if you allow users\nwith the new browsers to just fall back to the old, form-based\nauthentication, you're much less likely to make the transition to\nbetter cryptographic protection.\n\nWhat's the transition picture like for going to certs?  BTW, *here* is\nwhere a new database is needed, since you need to map certified IDs to\nexisting accounts.  Can the value-added ISPs eat the cost of the\ncerts?  Can a consortium of v.a.ISPs get together and eat the cost?\nMaybe (but it makes it easier for users to go from one v.a.ISP to\nanother).  Anyway, these are -business- issues and not technical ones.\nAnd definitely not crypto/security ones, so I leave it here.\n\nActually, my bet is that the biggest problem with the transition to\nTLS-mediated authentication for the value-added ISPs will be the\n-scalability- issue.  With current server boxes, company X can handle\nN users per machine on average.  With authenticated/encrypted/MAC'd\nconnections, how many new machines will company X have to buy in order\nto maintain reasonable response times?  How many new staff is needed\nto run these machines?  Training?  etc, etc.  Replicating software is\ncheap (if it's freeware or home-grown, anyway); replicating\nhardware/wetware is expensive.\n\n----------\n\n2.Authorization via Attribute Certificates\n\nWhile I believe attribute certificates are wonderful and useful, I\nbelieve that protocols to access them should be layered on top of TLS.\nBy crossing the layer boundary, we only further confound\nauthentication and authorization with no real gain (in conceptual\nclarity, in efficiency, or in any other metric that I can think of).\n\nOne thing that we -should- do to make layering easier is to expose\n(hem) a mechanism (or suggest/recommend minimal API) whereby upper\nlayer code can send records, so an upper protocol layer may send a\nmessage to its peer without messing up user data.  Yes, this can be\nencapsulated as another record format embedded in the\nuser-data-stream; it's probably better, however, to use the the\nunderlying record format to do the encapsulation into\nmax-size-from-next-lower-layer record, with a thin layer just below\nthe user which encapsulates the user data into the appropriate record\nsizes.  This would be just like how IP header/trailer is handled.\n\n[Aside: this is actually a bug in the current SSLv3 design.  The\nassumption is that the compression transform applies to user data\nrecords, and thus there's the extra 1k growth problem since\ncompression can grow the data in rare cases.  The compression layer\nshould be the just-below-the-user layer, and it should always get a\ndata stream as user-side input (output).  Thus, it should be able to\naccept exactly enough user-side data to fill up the record (size as\nindicated by layer immediately below) and no more, and there is no 1K\ncompression-expansion problem.  And in the more common case where the\ncompression is -working-well-, we would not have the current problem\nthat the compressed record having a smaller-than-necessary size.\n(Even if we wanted to provide users with a record abstraction, we\nshould always pass up maximum record sizes after subtracting the\ncurrent layer's overhead.)]\n\nAnyway, from a security viewpoint, authentication and authorization\nare very different ideas.  As Phil correctly pointed out, the request\nfor attribute certificates must be optional, since some services will\nwant to use local authorization databases (indexed by authenticated\nidentities) instead of the distributed authorization database that the\nattribute certificates comprise.  There is certainly no reason why the\nattribute certificate request must occur as part of the initial\nhandshake: with a ``keepalive'' connection which handles multiple HTTP\nrequests, different authorizations may be required for the different\nHTTP requests, and tying the attribute certificate request/reply to\nthe initial handshake is wrong.  The proof of -authorization- for the\noperations being performed must be requested when it's clear what\nthose operations are, not before in a willy-nilly fashion.\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: Password Deployment Issues  and  Attribute Certificate",
            "content": "Bennet Yee wrote:\n> \n> 2.      Authorization via Attribute Certificates\n> \n> While I believe attribute certificates are wonderful and useful, I\n> believe that protocols to access them should be layered on top of TLS.\n> By crossing the layer boundary, we only further confound\n> authentication and authorization with no real gain (in conceptual\n> clarity, in efficiency, or in any other metric that I can think of).\n> \n\nAn attribute certificate will typically be tied to the authentication\ncertificate via issuer and serial number.  An attribute certificate\nwithout an authentication certificate has little value.  If we are going\nto provide authentication certs to applications for audit, access\ncontrol, etc, then we should be prepared to handle the luggage (i.e.,\nattribute certs) that accompanies auth certs.\n\n> Anyway, from a security viewpoint, authentication and authorization\n> are very different ideas.  \n\nYes, but both are really relying on the application layer.  We can not\nauthenticate a user if their authentication cert chain does not end in\nsome known root.  TLS, SSL, etc, do not define these trusted roots,\nthese are handled by the applications themselves.  CRLs are also a large\npart of authentication, which are also currently the responsibility of\nthe application.  SSL provides negotiations, integrity, and encryption. \nIt also provides a standard means for challenge response, and can verify\nauthentication to some degree (that the response is associated the\ncertificate presented), but the application is ultimately responsible\nfor verifying authentication data.\n\n> There is certainly no reason why the\n> attribute certificate request must occur as part of the initial\n> handshake: with a ``keepalive'' connection which handles multiple HTTP\n> requests, different authorizations may be required for the different\n> HTTP requests, and tying the attribute certificate request/reply to\n> the initial handshake is wrong.  The proof of -authorization- for the\n> operations being performed must be requested when it's clear what\n> those operations are, not before in a willy-nilly fashion.\n\nDifferent http requests may also require different authentications,\neither do to key strength, algorithm, or certificate chain root. \nKeepalive is only useful when the security context is the same for all\nbundled HTTP requests.\n\nMost of the traffic I have seen on this list appears to be hammering out\nthe same negotiation issues that have debated in other working groups,\nso I again ask why we don't choose to use ISAKMP as a negotiation\nmechanism?  I have yet to hear any reasons why not to use ISAKMP, and\nhave only heard reasons for using it.\n\nJason Smith\nThe MITRE Corporation\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "I agree in spirit.  However - certs are not yet ubiquitous; the\nportability problems of certs & private keys vs passwords are not\ncompletely solved; PK infrastructure and trust relationships are still\nbeing worked out; and so on.  If all these problems were completely\nresolved we would not be having this discussion.\n\nI personally prefer PK-based authentication & authorization mechanisms.\nHowever, CompuServe and others have stated their business requirements\nto continue support for shared secrets.  There are obvious security and\ninteroperability advantages to support them in a single, robust,\nwidely-adopted protocol.  Dan Simon has described the export concerns\nwhich favor adding shared secret support to TLS so that they can be\nprotected by the strongest possible crypto.\n\nWith this in mind -- and since this has been proposed as an optional,\nnot a mandatory auth mechanism -- can we please apply the incredible\nbrain trust on this thread to providing a solution instead of debating\nthe need?\n\nDon Schmidt\ndonsch@microsoft.com\nProgram Manager\nMicrosoft Corp\n\n\n>----------\n>From: Christopher Allen[SMTP:ChristopherA@consensus.com]\n>Sent: Wednesday, July 31, 1996 6:22 PM\n>To: ietf-tls@w3.org\n>Subject: RE: Repost of CompuServe Position on Passphrases\n>\n>At 5:46 PM -0700 7/31/96, Don Schmidt wrote:\n>>>>use use FTP's current password methods to authenticate the client.\n>>>>Same can be done with HTTP using it's current auth structure,\n>>>and most every other protocol over SSL.\n>>\n>>is precisely one of the problems that including a standard shared-secret\n>>auth mechanism in TLS is designed to solve.  Each one of these protocols\n>>does password auth in an app specific manner.  It would greatly simplify\n>>the development, deployment and administration of secured apps if there\n>>is was one system-level protocol and I/F for security.  This is a\n>>benefit of TLS for certificate-based auth.  When it is within our grasp,\n>>who are we to deny the same benefit to  applications or service\n>>providers that have reasons to continue to use shared-secret based auth?\n>\n>But if you are going to do that much engineering to change software to \"one\n>system-level protocol\", then it should be a small step to using\n>certificates correctly. If legacy is important, they use the application\n>level AUTH commands over SSL. If you are doing something new, use\n>certificates.\n>\n>------------------------------------------------------------------------\n>..Christopher Allen                  Consensus Development Corporation..\n>..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n>..                                             Berkeley, CA 94707-2116..\n>..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n>..  Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus>..\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "see comments below\n>----------\n>From: Eric Murray[SMTP:ericm@lne.com]\n>Sent: Wednesday, July 31, 1996 11:39 AM\n>To: Don Schmidt\n>Cc: Jeff Teper; Keith_Ball@novell.com; ChristopherA@consensus.com;\n>ietf-tls@w3.org; jmacko@csi.compuserve.com\n>Subject: Re: Repost of CompuServe Position on Passphrases\n>\n>>Don Schmidt writes:\n>>> \n>>> The solution suggested below \n>>> \n>>> >>use use FTP's current password methods to authenticate the client.\n>>> >>Same can be done with HTTP using it's current auth structure,\n>>> >and most every other protocol over SSL.\n>>> \n>>> is precisely one of the problems that including a standard shared-secret\n>>> auth mechanism in TLS is designed to solve.  Each one of these protocols\n>>> does password auth in an app specific manner.  It would greatly simplify\n>>> the development, deployment and administration of secured apps if there\n>>> is was one system-level protocol and I/F for security.\n>\n>>I disagree. For the services named above, the implementer will want to\n>>keep the non-TLS functionality in place for connecting to\n>>non-TLS version of the service.  Hence, the existing password\n>>mechanisim will remain.  If the TLS versions use TLS-password\n>>authentication instead of the existing password authentication, then\n>>new calls will need to be written to support the TLS passwords\n>>in addition to the existing passwords.\n\nNothing about this proposal prevents continuation of existing\nfunctionality.  The fact that each app protocol does password auth its\nown way (and potentially to its own security db) is precisely the\nargument for a single standard mechanism.\n\nAlso, remember this is being requested by consumers, not implementers.\nWe already have extra work to do to implemet TLS.  Furthermore, if a\nstandard provider I/F -- such as GSS-API, or NT's SSPI implementation of\nthe GSS-API -- is used, this vastly simplifies the adaption of each\nprotocol to a single auth mechanism.\n\n>>Similarly, the deployment and administration will, at least in\n>>the short to medium term, be more complicated, not less.  With\n>>TLS-autheitication passwords there's now one more password database\n>>that will need to be maintained, checked for weak passwords etc.\n>>Arguably, most installations will want to support the non-TLS versions\n>>of the above services, for service inside the \"secure\" LAN.\n\nIn the context of establishing a new IETF standard, we must consider\nourselves as service providers.  As such, it is not our place to assume\nwhat our customers want.  We have a clear request for a single shared\nsecret auth mechanism.  More than one large Internet service\norganization has expressed the desire to simplify administration by\nmigrating from multiple security dbs to a single (but distributed)\nsecurity db.  They want to support fully distributed auth -- users\nanywhere on the Internet authenticating at  servers anywhere on the\nInternet -- and yet administer user accounts, credentials and\nauthorizations in a centralized datacenter.  A single, app-independent\nauth mechanism makes this much easier to implement.  \n>\n>>>  This is a\n>>> benefit of TLS for certificate-based auth.  When it is within our grasp,\n>>> who are we to deny the same benefit to  applications or service\n>>> providers that have reasons to continue to use shared-secret based auth?\n>\n>>1. they already have password based auth built into their protocols.\n>>Adding TLS underneath can make the passwords \"secure\" without requiring\n>>as much of a rewrite of the code.\n\nSame as above.  This does not address the requirement.\n\n>>2. not putting password auth in TLS will encourage new apps\n>>to use the much superior certificate-based authentication\n>>rather than allowing lazy implementers to stick with the\n>>familiar old passwords.\n\nUsing an IETF standard to force impelementors (or consumers) to conform\nto an opinion is not appropriate.\n\n>-- \n>Eric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\n>PGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29\n>AF\n>\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "At 12:44 PM -0700 8/1/96, Don Schmidt wrote:\n>However, CompuServe and others have stated their business requirements\n>to continue support for shared secrets.  There are obvious security and\n>interoperability advantages to support them in a single, robust,\n>widely-adopted protocol.\n\nI still don't grok the requirement -- nothing in TLS prevents them from\ncontinuing \"support for shared secrets\".\n\nI don't see how not having this feature prevents CompuServe from creating a\nsecure, server authenticated channel, then using their existing password\ninfrastructure to then authenticate the client. I can do this today with\nSSL under FTP, NNTP and without certificate-based client authentication. In\nfact, many of our prospective licensees of the SSL Plus toolkit plan on\ndoing just that.\n\nTell me something that CompuServe can't do without this feature, and I\nmight be more in favor of it. But adding a password feature to a\ncertificate based protocol where it doesn't fit invites security holes and\npoor implementations.\n\nBTW, I don't buy the reasoning \"but now shared secrets will be done in a\nstandard way under TLS\". If everyone is going have to change things so that\nit is done in a \"standard way\" to support passwords under TLS, they might\nas well change it so that they use certs.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus>..\n\n\n\n"
        },
        {
            "subject": "Re: Key Management, anyone? (DNS keying",
            "content": "> 2) FORTEZZA(tm) (including Skipjack) is on the IETF standards track, as\n> an algorithm suite in the Transport Layer Security (TLS) protocol.\n> That doesn't imply that anyone other than posessors of FORTEZZA(tm)\n> cards will be expected, or even able, to use that particular mechanism.\n> It meets the need of a large community of users; no objections to\n> standardization of FORTEZZA(tm) as an optional CipherSuite have been\n> raised, or even mentioned, within the TLS WG.\n\nwell, as best I can tell, there's NO WAY for a classified algorithm to\nbe on the IETF standards track.\n\nRFC1602 says:\n\n         (A)  ISOC will not propose, adopt, or continue to maintain any\n              standards, including but not limited to standards labelled\n              Proposed, Draft or Internet Standards, which can only be\n              practiced using technology or works that are subject to\n              known copyrights, patents or patent applications, or other\n              rights, except with the prior written assurance of the\n              owner of rights that:\n\n              l.   ISOC may, without cost, freely implement and use the\n                   technology or works in its standards work;\n\n              2.   upon adoption and during maintenance of an Internet\n                   Standard, any party will be able to obtain the right\n                   to implement and use the technology or works under\n                   specified, reasonable, non-discriminatory terms; and\n\n              3.   the party giving the assurance has the right and\n                   power to grant the licenses and knows of no other\n                   copyrights, patents, patent applications, or other\n                   rights that may prevent ISOC and members of the\n                   Internet community from implementing and operating\n                   under the standard.\n\nNow, this is part of the part of 1602 which was generally felt to be\n\"broken\".  However, the replacement for RFC1602,\ndraft-ietf-poised95-std-proc-3-06.txt, says:\n \n   7.1.2  Incorporation of Other Specifications\n\n      Other proprietary specifications may be incorporated by reference\n      to a version of the specification as long as the proprietor meets\n      the requirements of section 10.  If the other proprietary\n      specification is not widely and readily available, the IESG may\n      request that it be published as an Informational RFC.\n\n      The IESG generally should not favor a particular proprietary\n      specification over technically equivalent and competing\n      specification(s) by making any incorporated vendor specification\n      \"required\" or \"recommended\".\n\nand, later on:\n\n10.2  Confidentiality Obligations\n\n   No contribution that is subject to any requirement of confidentiality\n   or any restriction on its dissemination may be considered in any part\n   of the Internet Standards Process, and there must be no assumption of\n   any confidentiality obligation with respect to any such contribution.\n\n- Bill\n\n\n\n"
        },
        {
            "subject": "Re: Key Management, anyone? (DNS keying",
            "content": "> well, as best I can tell, there's NO WAY for a classified algorithm to\n> be on the IETF standards track.\n\n>\n> rfc1602 sez:\n\nnote that RFC 1602 has been replaced and is no longer the IETF standards\nprocess - the new process has not yet been published as an RFC but can\nbe found in the internet-drafts directory as:\ndraft-ietf-poised95-std-proc-3-06.txt\n\nThis new version changes the IPR rules quite a bit and the cited language\nis no longer in the document.\n\nScott\n\n\n\n"
        },
        {
            "subject": "Re: Key Management, anyone? (DNS keying",
            "content": "oops - I did not read far enough in the note - if the proposal deals with\na classified algorithm then I agree with your reading\n\nScott\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": ">\n>From: Christopher Allen[SMTP:ChristopherA@consensus.com]\n>\n>I don't see how not having this feature prevents CompuServe from creating a\n>secure, server authenticated channel, then using their existing password\n>infrastructure to then authenticate the client. I can do this today with\n>SSL under FTP, NNTP and without certificate-based client authentication. In\n>fact, many of our prospective licensees of the SSL Plus toolkit plan on\n>doing just that.\n>\n>Tell me something that CompuServe can't do without this feature, and I\n>might be more in favor of it. \n\nOkay, here's one thing:  they can't protect password-based\nchallenge-response transcripts with strong encryption while adhering to\nexport restrictions.  If the application is restricted to exportable\nencryption, then it can't properly protect challenge-response pairs from\nbrute force attacks--first against the encryption, then against the\npassword.\n\n>But adding a password feature to a\n>certificate based protocol where it doesn't fit invites security holes and\n>poor implementations.\n\n....As does *not* adding the feature, if the result is that most people\nsimply stick with application-level password authentication.\n> \n>BTW, I don't buy the reasoning \"but now shared secrets will be done in a\n>standard way under TLS\". If everyone is going have to change things so that\n>it is done in a \"standard way\" to support passwords under TLS, they might\n>as well change it so that they use certs.\n\nI'm hardly an implementation expert, but my impression is that there's a\nhuge difference between having to \"change things\" and converting to an\nentirely new security architecture and client authentication\ninfrastructure.  If the only way to \"change things\" is to do the latter,\nthen I fear that few will bother to change at all.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "At 12:43 PM -0700 8/2/96, Dan Simon wrote:\n>Okay, here's one thing:  they can't protect password-based\n>challenge-response transcripts with strong encryption while adhering to\n>export restrictions.  If the application is restricted to exportable\n>encryption, then it can't properly protect challenge-response pairs from\n>brute force attacks--first against the encryption, then against the\n>password.\n\nOk, so far this is the only requirement that I've seen that can't be done\nwith TLS now.\n\nAs summarize Dan's requirement, TLS while securing a transport using an\nexportable cypher (say RC4-40) would allow passphrases to be secured at a\nfull (RC4-128) level. Thus if you were using FTP with SSL, the\nusername/password could be sent at the high encryption level.\n\nHowever, again, is this really necessary? Since you have shared secrets,\ncan't you use something like the APOP framework where you send a date, hash\nit with the password and send the hash back? Isn't that as secure (or more\nsecure) as sending the password encrypted with RC4-128? And that can be\ndone at the application level, and already exists in some form in a number\nof IETF protocols.\n\nAt 9:48 AM -0700 8/2/96, Keith Ball wrote:\n>I still havent seen any movement towards resolution.  The issues havent\n>changed substantially. So, how is this to be resolved?  I think Dan Simon's\n>suggestions are useful from our perspective, but I dont see any agreement\n>that\n>it will or will not be adopted.\n>\n>1) How will this issue be resolved?  What happens when consensu doesnt appear\n>to be reached (or reachable) on the mailing list?\n\nI could be persuaded to drop my objections if there was the following:\n\na) A concrete proposal, to the bits level, of how you can protect\npassword-based challege-response bits at a higher level of encryption than\nthe exportable SSL stream, and how this proposal fits into the the broader\nTLS protocol, and *DOESN'T* try to do more than this.\n\nb) An evaluation of whether this couldn't better be done through another\n\"standard\" technique like APOP or some of the other AUTH frameworks at the\napplication level, or by using some out-of-band technique.\n\nc) An evaluation of whether this really is exportable.\n\nd) Some comments on if adding a feature because of only US export issues\nthat could impact security is acceptable.\n\ne) Some other parties besides Netscape, MicroSoft, and CompuServe to speak\nup on the proposal.\n\nf) Some cryptographers to speak up on the proposal.\n\ng) An \"exit\" strategy, so that we can be sure that this hack has a sunset,\nand that it would not be a requirement of TLS to always support this in the\nfuture.\n\nI'll summarize my objections so far:\n\n1) It is inelegant architecturally.\n\n2) It serves a need that can be just as easily answered at the application\nprotocol level.\n\n3) I'm concerned about security issues (I'm not a cryptographer, so I can't\nsay that it is not secure, only that I've not heard enough from them to\nfeel more confident.)\n\n4) I'm concerned that it will delay implementation of client certificates.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus>..\n\n\n\n"
        },
        {
            "subject": "Re: Repost of CompuServe Position on Passphrase",
            "content": "Dan,\n\nExportable applications are allowed to encrypt passwords with any bit \nlength.\n\nTaher\n\nDan Simon wrote:\n> \n> >\n> >From:  Christopher Allen[SMTP:ChristopherA@consensus.com]\n> >\n> >I don't see how not having this feature prevents CompuServe from creating a\n> >secure, server authenticated channel, then using their existing password\n> >infrastructure to then authenticate the client. I can do this today with\n> >SSL under FTP, NNTP and without certificate-based client authentication. In\n> >fact, many of our prospective licensees of the SSL Plus toolkit plan on\n> >doing just that.\n> >\n> >Tell me something that CompuServe can't do without this feature, and I\n> >might be more in favor of it.\n> \n> Okay, here's one thing:  they can't protect password-based\n> challenge-response transcripts with strong encryption while adhering to\n> export restrictions.  If the application is restricted to exportable\n> encryption, then it can't properly protect challenge-response pairs from\n> brute force attacks--first against the encryption, then against the\n> password.\n> \n> >But adding a password feature to a\n> >certificate based protocol where it doesn't fit invites security holes and\n> >poor implementations.\n> \n> ....As does *not* adding the feature, if the result is that most people\n> simply stick with application-level password authentication.\n> >\n> >BTW, I don't buy the reasoning \"but now shared secrets will be done in a\n> >standard way under TLS\". If everyone is going have to change things so that\n> >it is done in a \"standard way\" to support passwords under TLS, they might\n> >as well change it so that they use certs.\n> \n> I'm hardly an implementation expert, but my impression is that there's a\n> huge difference between having to \"change things\" and converting to an\n> entirely new security architecture and client authentication\n> infrastructure.  If the only way to \"change things\" is to do the latter,\n> then I fear that few will bother to change at all.\n> \n>                                 Daniel Simon\n>                                 Cryptographer, Microsoft Corp.\n>                                 dansimon@microsoft.com\n\n-- \nTaher Elgamal    elgamal@netscape.com\nChief Scientist, Netscape Communications\n(T) 415 937 2898, (F) 415 428 4054\n\n\n\n"
        },
        {
            "subject": "RE: Passphrases in or ou",
            "content": ">\n>From: Christopher Allen[SMTP:ChristopherA@consensus.com]\n>\n>At 12:43 PM -0700 8/2/96, Dan Simon wrote:\n>>Okay, here's one thing:  they can't protect password-based\n>>challenge-response transcripts with strong encryption while adhering to\n>>export restrictions.  If the application is restricted to exportable\n>>encryption, then it can't properly protect challenge-response pairs from\n>>brute force attacks--first against the encryption, then against the\n>>password.\n>\n>Ok, so far this is the only requirement that I've seen that can't be done\n>with TLS now.\n>\n>As summarize Dan's requirement, TLS while securing a transport using an\n>exportable cypher (say RC4-40) would allow passphrases to be secured at a\n>full (RC4-128) level. Thus if you were using FTP with SSL, the\n>username/password could be sent at the high encryption level.\n>\n>However, again, is this really necessary? Since you have shared secrets,\n>can't you use something like the APOP framework where you send a date, hash\n>it with the password and send the hash back? Isn't that as secure (or more\n>secure) as sending the password encrypted with RC4-128? And that can be\n>done at the application level, and already exists in some form in a number\n>of IETF protocols.\n\nNo, this is not as secure as strong protection of the password-based\nresponse.  This method allows brute-force offline search for the\npassword; if the latter was poorly chosen, then it may be quite easy to\nfind.  Strong protection of the response with a key derived from a\npublic-key key exchange solves the problem.\n>\n>At 9:48 AM -0700 8/2/96, Keith Ball wrote:\n>>I still havent seen any movement towards resolution.  The issues havent\n>>changed substantially. So, how is this to be resolved?  I think Dan Simon's\n>>suggestions are useful from our perspective, but I dont see any agreement\n>>that\n>>it will or will not be adopted.\n>>\n>>1) How will this issue be resolved?  What happens when consensu doesnt\n>>appear\n>>to be reached (or reachable) on the mailing list?\n>\n>I could be persuaded to drop my objections if there was the following:\n>\n>a) A concrete proposal, to the bits level, of how you can protect\n>password-based challege-response bits at a higher level of encryption than\n>the exportable SSL stream, and how this proposal fits into the the broader\n>TLS protocol, and *DOESN'T* try to do more than this.\n\nI presented exactly such a proposal in a brief post-meeting rump session\nafter the working group meeting in Montreal.  The text of it will be\nposted to this list shortly.\n>\n>b) An evaluation of whether this couldn't better be done through another\n>\"standard\" technique like APOP or some of the other AUTH frameworks at the\n>application level, or by using some out-of-band technique.\n\nMy comments above, together with my response to Taher's email, hopefully\nclear up this question.\n>\n>c) An evaluation of whether this really is exportable.\n\nThis is unfortunately a terribly touchy question, as exportability is\nsomething of an empirical science.  As far as I know, there is no\nofficial oracle which will rule on the exportability of a generic method\nlike a protocol, as opposed to a particular implementation.  However, I\nexpect that those who are familiar with export approval procedures will\nagree that the method I have been advocating stands as good a chance as\nany inexact science will allow.  :^)  \n>\n>d) Some comments on if adding a feature because of only US export issues\n>that could impact security is acceptable.\n\nHas anyone complained about the EXPORT cipher suites yet?\n>\n>e) Some other parties besides Netscape, MicroSoft, and CompuServe to speak\n>up on the proposal.\n\nExcellent idea--I encourage as many disparate voices as possible to come\nforward. \n>\n>f) Some cryptographers to speak up on the proposal.\n\nI believe I count as one (at least, that's what my business card says).\nBennet Yee could be considered another.  Taher would be a third.  I\nwould, of course, love to hear from more.  But then we should probably\nhave as many cryptographers as possible root through the entire TLS\nprotocol, not just the shared-key authentication feature.\n>\n>g) An \"exit\" strategy, so that we can be sure that this hack has a sunset,\n>and that it would not be a requirement of TLS to always support this in the\n>future.\n\nI'm not sure what is meant by \"a requirement of TLS to always support\nthis in the future\".  Certainly, it was never anyone's intention to\nforce support for this feature on any implementer of TLS.  Given that\nsupport for it would in any event be completely optional, I see no\nreason to consider this feature any more or less permanent than, say,\nsupport for the IDEA cipher.\n>\n>I'll summarize my objections so far:\n>\n>1) It is inelegant architecturally.\n\nI've heard this complaint a number of times, and I've never understood\nit.  If public-key-based client authentication belongs in TLS, then how\ncould shared-key-based client authentication belong anywhere else?  So\nwhat if they work slightly differently--isn't architectural elegance a\nmatter of first locating functionality, then allowing alternate\nmechanisms for providing that functionality to be inserted as needed?\n>\n>2) It serves a need that can be just as easily answered at the application\n>protocol level.\n\nSee my comments above.\n>\n>3) I'm concerned about security issues (I'm not a cryptographer, so I can't\n>say that it is not secure, only that I've not heard enough from them to\n>feel more confident.)\n\nAs a cryptographer, I will freely grant that there are security risks\nassociated with shared-key authentication that don't exist in the\npublic-key case.  Unfortunately, in the real world, security is only one\nof many concerns, and practical obstacles to public-key authentication\nmay in some cases outweigh the security advantages.  That is hardly a\nrare occurence in cryptography; any cryptographer can identify dozens of\nsuch concessions to practicality in the current TLS document, for\nexample.  Normally, cryptographers try to decide only the no-brainers\nourselves (getting rid of blatantly broken ciphers, for instance), and\nprovide enough information about the trickier trade-offs so that\ncryptography's consumers, thus armed, can make informed choices.\n>\n>4) I'm concerned that it will delay implementation of client certificates.\n\nMy own view is that if anything, it will expedite the implementation of\nclient certificates.  But suppose that I'm wrong, and Christopher is\nright--as John Macko has pointed out, what would it say about the\nrelative attractiveness of client certificates, if implementers, given\nall the facts, still had to be bludgeoned into using client certificates\nby a ban on the use of something they'd prefer if they had the option?\n\nNo, I believe that implementers, administrators and users will migrate\nto client certificates when they decide that client certificates are\npreferable to passwords.  (And I also believe that that day is not far\noff.)  Trying to coerce them by rendering password-based schemes less\nsecure than they could be, on the other hand, will not only not convince\nmany people--it will also win us (the working group, the IETF, standards\nbodies and cryptographers in general) enemies while weakening overall\nInternet security.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": ">\n>From: elgamal@netscape.com[SMTP:elgamal@netscape.com]\n>\n>Dan,\n>\n>Exportable applications are allowed to encrypt passwords with any bit \n>length.\n>\nOf course, but where does the encryption key (not to mention the\nencryption algorithm) come from?  The whole point of the TLS handshake\nis to solve the messy, difficult problems of channel encryption and key\nexchange once and for all, for every application.  If the resulting\n\"exportably secure\" channel cannot be used by the application for strong\nencryption of passwords, then the application will have to establish its\nown (truly) secure channel for passwords at the application layer.  Once\nit's doing that, it might as well just handle all the encryption and key\nexchange itself, ignoring TLS altogether.\n\nPresumably, though, we want applications actually to use (possibly\nexportably implemented) TLS  for their channel security--including, if\nnecessary, password encryption.  In that case, the (exportable) TLS\nimplementation has to distinguish between bulk data (exportably\nencrypted) and the password (strongly encrypted).  Hence the need for\nspecial treatment of passwords in TLS. \n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n\n"
        },
        {
            "subject": "RE: Repost of CompuServe Position on Passphrase",
            "content": "Taher\n\nBut then the application has to provide the encryption, make sure it can\nonly be applied to auth data and not bulk user data, become involved in\nkey management...\n\nFrom a service perspective, the purpose of a standard security provider\nat the systems level is to offload these functions from applications.\nFrom a security perspective, it is to make sure they are provided in a\nconsistent, robust manner.\n\nIf it is good to provide this support to applications for certificates.\nThen why is it not also good to provide it for shared-secrets?\n\nDon Schmidt\ndonsch@microsoft.com\nProgram Manager\nMicrosoft Corp\n\n>----------\n>From: elgamal@netscape.com[SMTP:elgamal@netscape.com]\n>Sent: Friday, August 02, 1996 1:22 PM\n>To: Dan Simon\n>Cc: 'ietf-tls@w3.org'; 'Christopher Allen'\n>Subject: Re: Repost of CompuServe Position on Passphrases\n>\n>Dan,\n>\n>Exportable applications are allowed to encrypt passwords with any bit \n>length.\n>\n>Taher\n>\n>Dan Simon wrote:\n>> \n>> >\n>> >From:  Christopher Allen[SMTP:ChristopherA@consensus.com]\n>> >\n>> >I don't see how not having this feature prevents CompuServe from creating\n>>a\n>> >secure, server authenticated channel, then using their existing password\n>> >infrastructure to then authenticate the client. I can do this today with\n>> >SSL under FTP, NNTP and without certificate-based client authentication.\n>>In\n>> >fact, many of our prospective licensees of the SSL Plus toolkit plan on\n>> >doing just that.\n>> >\n>> >Tell me something that CompuServe can't do without this feature, and I\n>> >might be more in favor of it.\n>> \n>> Okay, here's one thing:  they can't protect password-based\n>> challenge-response transcripts with strong encryption while adhering to\n>> export restrictions.  If the application is restricted to exportable\n>> encryption, then it can't properly protect challenge-response pairs from\n>> brute force attacks--first against the encryption, then against the\n>> password.\n>> \n>> >But adding a password feature to a\n>> >certificate based protocol where it doesn't fit invites security holes and\n>> >poor implementations.\n>> \n>> ....As does *not* adding the feature, if the result is that most people\n>> simply stick with application-level password authentication.\n>> >\n>> >BTW, I don't buy the reasoning \"but now shared secrets will be done in a\n>> >standard way under TLS\". If everyone is going have to change things so\n>>that\n>> >it is done in a \"standard way\" to support passwords under TLS, they might\n>> >as well change it so that they use certs.\n>> \n>> I'm hardly an implementation expert, but my impression is that there's a\n>> huge difference between having to \"change things\" and converting to an\n>> entirely new security architecture and client authentication\n>> infrastructure.  If the only way to \"change things\" is to do the latter,\n>> then I fear that few will bother to change at all.\n>> \n>>                                 Daniel Simon\n>>                                 Cryptographer, Microsoft Corp.\n>>                                 dansimon@microsoft.com\n>\n>-- \n>Taher Elgamal    elgamal@netscape.com\n>Chief Scientist, Netscape Communications\n>(T) 415 937 2898, (F) 415 428 4054\n>\n>\n\n\n\n"
        },
        {
            "subject": "compression and TL",
            "content": "This is not a proposal for the TLS 3.1 specification, but here is some\ninformation for those that would like to look forward past this year. I\nmentioned an unpatented compression algorithm at the IETF meeting and\nhere (finally) is a pointer to it.\n\nhttp://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-124.html\n\nI am forwarding the following from somebody who wishes to be protected\nfrom sending to a large list. :-)\n\nPK\n\n=============================================\n\nMike Burrows [of DEC] gave me the following recent reference for the\ncompression algorithm that you had in mind:\n\nhttp://web2.airmail.net/markn/articles/bwt/bwt.htm\n\nThis is a paper by a third party (Mark Nelson). It includes source \ncode and a link to the original paper by Burrows and Wheeler. Neither \nthis paper nor the original paper are detailed enough to constitute \na specification. Someone would need to put in some work to fix\nparameters, etc., and in particular to fix a Huffman coder. This could\nbe a drawback.\n\nThere are several other implementation of this algorithm. Mark Nelson's \nis good but not great; it is apparently reasonably clean. Mike Burrows's \nis better, Mike says, but Digital is not distributing it. (It is \nbeing used in some products, but has never been licensed on its own. \nAs far as we know, there are no patents on this algorithm.) In Mike's \nimplementation, this algorithm is a bit slower but compresses better \nthan gzip. \n\nMike recommended considering another compression algorithm, to which \nhe refers as Wheeler hashing because Wheeler discovered it in 1983. \nWhen Wheeler hashing is combined with a suitable Huffman back-end, \nit performs better than Unix compress in all dimensions. The algorithm \nwas first described in: \n\n    Raita, T. and Teuhola, J. (1987), \"Predictive text compression\n    by hashing\", ACM Conference on Information Retrieval\n\nThis algorithm has been patented (5,229,768) by K. Thomas in 1993, \nbut given the dates the patent should probably not hold. The algorithm \nis used in the Internet Draft \"PPP Predictor Compression Protocol\" \n(see\nftp://venera.isi.edu/internet-drafts/draft-ietf-pppext-predictor-00.txt). \nThis might be an advantage.\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "> \n> Christopher Allen wrote:\n> \n> >f) Some cryptographers to speak up on the proposal.\n> \n\nI have a question for the cryptographers...\n\nThe \"Shared Key Authentication for the TLS Protocol\" paper\nstates:\n\n==> In fact, even a challenge-response protocol which never\n==> reveals the password is vulnerable, if a poorly chosen, guessable\n==> password is used; an attacker can obtain the (weakly protected)\n==> transcript of the challenge-response protocol, then attempt to guess the\n==> password, verifying each guess against the transcript.\n\nWould not this same type of attack be possible against the current\nproposal?  It seems to me that if your are not using asymmetric crypto, \nan eavesdropper would have all required info from the transcript of\nthe session to perform this type of an attack.  That is, it doesn't\nmatter if the transcript is \"weakly protected\" or \"strongly protected\" --\nwithout asym crypto, the attacker has the same info about the session\nas the valid participants.\n\nNot being a cryptographer, I apologize if this question is misguided.\n\n\nRegards, \nSteve Petripetri@litronic.com\nLitronic Industries(714)545-6649\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "> From: Steve Petri <petri@litronic.com>\n> > \n> > Christopher Allen wrote:\n> > \n> > >f) Some cryptographers to speak up on the proposal.\n> \n> I have a question for the cryptographers...\n> \n> The \"Shared Key Authentication for the TLS Protocol\" paper\n> states:\n>  [ ... ]\n> Would not this same type of attack be possible against the current\n> proposal?  It seems to me that if your are not using asymmetric crypto, \n> an eavesdropper would have all required info from the transcript of\n> the session to perform this type of an attack.  That is, it doesn't\n> matter if the transcript is \"weakly protected\" or \"strongly protected\" --\n> without asym crypto, the attacker has the same info about the session\n> as the valid participants.\n\nSteve, using assymetric cryptography is not a necessary condition for\ndistinguish between attackers and valid participants.\n\nThe authentication hash proposed in the passauth3.txt that Tom\nStephens just sent is a bit complicated.  I'll first simply point out\nthat an attacker does not have the same information as the valid\nparticipants by a simple reduction to a previously solved problem,\nthat of computing a MAC on a single message.\n\nWe believe HMAC(k,m) = h(k,p2,(k,p1,m)) to be a good MAC on message m\n(where p1 and p2 are padding bytes necessary to bring (k,p1) and\n(k,p2) to full compression function argument boundaries).  k is a\nshared ``MAC key'', not known to eavesdroppers.  The MAC doesn't have\nto be protected at all -- if the hash function h has the necessary\ncryptographic property (collision intractibility), then only those who\nknow k may generate a valid MAC for a message m, and even if you get\nlots of m_i,MAC(m_i) pairs (and you get to chose m_i), it is still\ncomputationally infeasible to generate m,MAC(m) where m != m_i for all\ni.\n\nHow is this different from shared key authentication?  With MACs, we\nare authenticating the origin of a single message (per MAC, in a\nrepudiable way, unlike digital signatures).  With the shared key\nauthentication, the goal is to authenticate the channel, i.e., that\nthe encryption/message-MAC keys derived to protect the channel is\nindeed shared by the parties who possess the shared secret key.\n\nAnyway, the SharedKeyVerify.shared_key_response field deserves closer\nscrutiny, but in principle there's nothing wrong with the idea.\n\n--------\n\nNow about the design of SharedKeyVerify.shared_key_response.\n\nIt's not clear to me why pad1 is needed (padding are added to MAC\nfunctions to prevent a key recovery attack by Preneel and Van\nOorschot) -- if MAC_write_secret is the only secret in the inner hash,\nI would have expected the pad to preceed it to make sure\nMAC_write_secret do not span a compression function boundary, and\nburying the secret value in the middle of the hash is probably not a\ngood idea -- nor why the xor is there.  Having only thought about it a\nlittle [caveat], I would prefer it to be\n\n h(shared_key + pad_2 + h(shared_key + pad_1 + handshake_messages))\n\nwhere shared_key is either the passphrase itself, or h(passpharse).\n\nThe identity information may be sent in the clear -- it's part of the\nhandshake messages anyway, as well as SharedKeyVerify.identity, and\nonly serves to chose the particular shared_key for verifying the\nSharedKeyVerify.shared_key_response field.  This MAC authenticates the\nthe possessors of the shared_key saw the same handshake messages, from\nwhich master_secret is derived for the write secrets etc.  (Instead of\njust protocol messages sent, it should be sent and received, and\nincludes internally the client_hello.random etc.)\n\nThis only works in one direction, obviously.  If we want both the\nclient and the server to prove (to each other) that they possess the\nshared_key, we'd either have to have two keys, or change the\nauthentication hash to be one of\n\n h(shared_key + pad_2 + h(shared_key + pad_1 + handshake_messages + \"I\nam client\"))\n\n h(shared_key + pad_2 + h(shared_key + pad_1 + handshake_messages + \"I\nam server\"))\n\nThis is probably a little different than the point of view adopted by\nthe designer(s) of the SharedKeyVerify.shared_key_response in the\nShared Key Authentication proposal.  It appears to me that they wanted\nto show that the possessor of the channel keys also has the\nshared_key, instead of the other way around.  This is more vulnerable\nto the man-in-the-middle attacks for anonymous key exchanges, since\nthe cryptographic assumption about the hash function must be stronger\n(preimage resistance), because such an attacker would have access to\nthe auth_write_secret and MAC_write_secret.  (This assumed that users\nchose passphrases with enough entropy, else all bets are off.)\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "Bennet, \n\nThanks for your prompt response.  But I have one further question:\n\nBennet Yee wrote:\n> \n> Steve, using assymetric cryptography is not a necessary condition for\n> distinguish between attackers and valid participants.\n> \n> The authentication hash proposed in the passauth3.txt that Tom\n> Stephens just sent is a bit complicated.  I'll first simply point out\n> that an attacker does not have the same information as the valid\n> participants by a simple reduction to a previously solved problem,\n> that of computing a MAC on a single message.\n> \n> We believe HMAC(k,m) = h(k,p2,(k,p1,m)) to be a good MAC on message m\n> (where p1 and p2 are padding bytes necessary to bring (k,p1) and\n> (k,p2) to full compression function argument boundaries).  k is a\n> shared ``MAC key'', not known to eavesdroppers. \n\nBut how is the shared ``MAC key'' communicated?  Using asym crypto?\nOr is it derived from the shared password, in which case the attacker\ncould use a dictionary attack?\n\nOr would, for example, all Compuserve subscribers have the same\nshared MAC key and we assume the eavesdropper does not know it?\n\nThanks, \nSteve Petripetri@litronic.com\nLitronic Industries(714)545-6649\n\n\n\n"
        },
        {
            "subject": "RE: Passphrases in or ou",
            "content": ">\n>From: Steve Petri[SMTP:petri@litronic.com]\n>\n>I have a question for the cryptographers...\n>\n>The \"Shared Key Authentication for the TLS Protocol\" paper\n>states:\n>\n>==> In fact, even a challenge-response protocol which never\n>==> reveals the password is vulnerable, if a poorly chosen, guessable\n>==> password is used; an attacker can obtain the (weakly protected)\n>==> transcript of the challenge-response protocol, then attempt to guess the\n>==> password, verifying each guess against the transcript.\n>\n>Would not this same type of attack be possible against the current\n>proposal?  It seems to me that if your are not using asymmetric crypto, \n>an eavesdropper would have all required info from the transcript of\n>the session to perform this type of an attack.  That is, it doesn't\n>matter if the transcript is \"weakly protected\" or \"strongly protected\" --\n>without asym crypto, the attacker has the same info about the session\n>as the valid participants.\n>\nThis is absolutely correct.  Fortunately, the proposal *does* involve\nasymmetric crypto--for key exchange.  Once a (strong) key has been\nexchanged using asymmetric cryptography, the (as-yet-anonymous) client\nand (already-authenticated) server share a fresh, random secret\n(presumably) unavailable to the attacker, and can use that secret to\nprotect the shared-key-based client authentication transcript.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "Steve,\n\nYes, the MAC key is derived using assymetric cryptography.  In pricinple,\nhowever, it does not matter how it is derived -- if it is a shared key that\nis only known to the sender and receiver, then the security of the MAC would\nstill hold.\n\nI'm afraid, upon rereading your original message, that I may have answered\na slightly different question than that which you had posed.  It is true\nthat if the key choice is not good, then eavesdroppers may use the traffic\nin an off-line dictionary attack to recover the key.  I was addressing a\ndifferent question, that of whether assymetric cryptography is required to\nperform such an authentication -- which is why I added at the end that\nusers must chose passphrases with enough entropy.\n\nMy apologies for misunderstanding your question.\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "Bennet Yee wrote:\n> \n> Yes, the MAC key is derived using assymetric cryptography.  In\n> pricinple, however, it does not matter how it is derived -- if it is a\n> shared key that is only known to the sender and receiver, then the\n> security of the MAC would still hold.\n\nThis is not completely correct.  The MAC key is only as strong as the\nkey exchange algorithm used to create it.  In this case, 512-bit RSA,\nwhich is nowhere near as strong as a true 128-bit secret.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "Bennet Yee wrote:\n> \n> I'm afraid, upon rereading your original message, that I may have answered\n> a slightly different question than that which you had posed.  It is true\n> that if the key choice is not good, then eavesdroppers may use the traffic\n> in an off-line dictionary attack to recover the key.  I was addressing a\n> different question, that of whether assymetric cryptography is required to\n> perform such an authentication -- which is why I added at the end that\n> users must chose passphrases with enough entropy.\n> \n> My apologies for misunderstanding your question.\n\n\nNo problem, your response helped me to better understand my own question <g>.\nI do think, though, that in the final proposal, the shared MAC secret should not\nbe allowed to be derived from the passphrase.  Many users will choose low entropy\npassphrases, and a successful dictionary attack of a transcript might cause the\nentire TLS standard to be perceived as weak.\n\n\nDan Simon wrote:\n> Fortunately, the proposal *does* involve\n> asymmetric crypto--for key exchange.  Once a (strong) key has been\n> exchanged using asymmetric cryptography, the (as-yet-anonymous) client\n> and (already-authenticated) server share a fresh, random secret\n> (presumably) unavailable to the attacker, and can use that secret to\n> protect the shared-key-based client authentication transcript.\n\nSo it seems that the client code will come up with a (high entropy) random\nnumber, and encrypt it with the Server's public key.  Is that correct?\n\nIs there a provision in the proposal to deny service to an account which\nis being dictionary attacked directly, or will this be left up to \nthe implementation?\n\n-- \nSteve Petripetri@litronic.com\nLitronic Industries(714)545-6649\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "That's saying it's *not* known *only* to the sender and receiver,\nbecause the assymetric cryptography is weak.  If a MAC key to be shared\nbetween you and me is derived by me shouting the key value to you in\nthe midst of a crowd, it's not very good either.  -bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "> Steve Petri writes:\n> \n> So it seems that the client code will come up with a (high entropy) random\n> number, and encrypt it with the Server's public key.  Is that correct?\n\nThis is the standard RSA server auth key exchange.\n\n> Is there a provision in the proposal to deny service to an account which\n> is being dictionary attacked directly, or will this be left up to \n> the implementation?\n\nProtocols only specify the messages sent over the wire.  The\nvulnerability to dictionary attacks, unfortunately, is independent of\nthis -- active on-line attacks, where the server is actually being\nprobed, -can- be detected by the server implementation, but such an\nimplementation requirement is outside the scope of a protocol\nstandard; off-line attacks where protocol messages are eavesdropped\nand then used to determine the key in a separate computation, much as\nbrute-force key searches are done with known-plaintext attacks, are\ncompletely separated from both protocol specifications as well as\nimplementation specifications.\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Adding a highsecurity channel for password",
            "content": "For password authentication what we really are trying to create\nis a more secure encryption method for moving the hashed password\nacross the wire.\n\nInstead of adding a set of extra fields to the protocol for \npasswords, it seems to make more sense to buind in capabilities \nto send securely-encrypted data of any type.  This could be \nuseful for other applications as well, such as credit card \nnumbers, non-user-accessible control information, biometric\nidentification information, etc.  In general, applications \nwould probably be free to decide what to use this for.\n\nTo do this, another record layer type for application-specific \ncontrol messages would be added.  These messages would be encrypted\nwith another encryption type defined by the ciphersuite (probably \n128-bit RC4 for exportable ciphersuites and triple DES for secure \nciphersuites since NSA is afraid of triple DES).  The keys for this\nsecure channel would be derived independently from the master secret.\n\nThese messages would probably consist of some kind of data type\nidentifier (indicting hashed password, plaintext password, credit \ncard number, ATM PIN, etc.), possibly a criticality flag, and the \nmessage content.  (This still needs to be hashed out, pardon the \npun.)\n\nI talked with the export office of the NSA today and asked about\nthis.  In general, they don't seem likely to mind, provided that\napplications don't use the secure channel for user data.\n\nAny feedback (to the list) is, of course, appreciated.\n\n-- Paul\n\n_____________________________________________________________________\nPaul Kocher            Voicemail: (415) 354-8004, FAX: (415) 321-1483\nCryptography consultant                   http://www.cryptography.com\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "Bennet Yee wrote:\n> \n> Protocols only specify the messages sent over the wire.  The\n> vulnerability to dictionary attacks, unfortunately, is independent of\n> this -- active on-line attacks, where the server is actually being\n> probed, -can- be detected by the server implementation, but such an\n> implementation requirement is outside the scope of a protocol\n> standard; off-line attacks where protocol messages are eavesdropped\n> and then used to determine the key in a separate computation, much as\n> brute-force key searches are done with known-plaintext attacks, are\n> completely separated from both protocol specifications as well as\n> implementation specifications.\n\nAt the Montreal meeting (in reference to the flexibility of the SSH proposal)\nsomeone commented that the protocol should not allow the implementor to \n\"do bad things\".  I agree with this, because many implementors don't have\nthe time or cryptographic expertise to consider all angles of attack.\n\nGiven that, it is misleading to state that (with the passauth proposal)\nyour passwords are protected with 128 bit crypto, when in reality a\nserver without attack detection, combined with a user whose password\nis in a dictionary of 65000 commonly used passwords, effectively\nhas 16 bit crypto protection.\n\nA security system is only as strong as its weakest link.  Again, I'm no\ncryptographer, but it seems to me that this channel of attack does not\nexist if passphrases are disallowed in TLS.\n\n-- \nSteve Petripetri@litronic.com\nLitronic Industries(714)545-6649\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "[resending...]\n\nBennet Yee wrote:\n>\n> Protocols only specify the messages sent over the wire.  The\n> vulnerability to dictionary attacks, unfortunately, is independent of\n> this -- active on-line attacks, where the server is actually being\n> probed, -can- be detected by the server implementation, but such an\n> implementation requirement is outside the scope of a protocol\n> standard; off-line attacks where protocol messages are eavesdropped\n> and then used to determine the key in a separate computation, much as\n> brute-force key searches are done with known-plaintext attacks, are\n> completely separated from both protocol specifications as well as\n> implementation specifications.\n\nAt the Montreal meeting (in reference to the flexibility of the SSH proposal)\nsomeone commented that the protocol should not allow the implementor to\n\"do bad things\".  I agree with this, because many implementors don't have\nthe time or cryptographic expertise to consider all angles of attack.\n\nGiven that, it is misleading to state that (with the passauth proposal)\nyour passwords are protected with 128 bit crypto, when in reality a\nserver without attack detection, combined with a user whose password\nis in a dictionary of 65000 commonly used passwords, effectively\nhas 16 bit crypto protection.\n\nA security system is only as strong as its weakest link.  Again, I'm no\ncryptographer, but it seems to me that this channel of attack does not\nexist if passphrases are disallowed in TLS.\n\n--\nSteve Petri                                     petri@litronic.com\nLitronic Industries                             (714)545-6649\n\n\n\n"
        },
        {
            "subject": "RE: Adding a highsecurity channel for password",
            "content": ">\n>From: pck@netcom.com[SMTP:pck@netcom.com]\n>\n>For password authentication what we really are trying to create\n>is a more secure encryption method for moving the hashed password\n>across the wire.\n>\n>Instead of adding a set of extra fields to the protocol for \n>passwords, it seems to make more sense to buind in capabilities \n>to send securely-encrypted data of any type.  This could be \n>useful for other applications as well, such as credit card \n>numbers, non-user-accessible control information, biometric\n>identification information, etc.  In general, applications \n>would probably be free to decide what to use this for.\n\nActually, I expect that in exportable TLS implementations applications\nwould *not* be free to decide what to use this for, since the TLS\nimplementation would presumably have to use some means to prevent sneaky\napplications from using the extra channel for user data.\n\nIn any event, if this solution is more palatable to the working group\nthan the addition of a specific password authentication feature, then I,\nfor one, am happy with it.\n\n>\n>Daniel Simon\n>Cryptographer, Microsoft Corp.\n>dansimon@microsoft.com\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "passphrases in TL",
            "content": "Some of you have wondered what the process on resolving\nthe question of passphrases in TLS is going to be. That's a fair\nquestion.\n\nUnfortunately, I was removed from the mailing list for a period\nof time without my knowledge, so I missed much of the traffic,\nand I'm trying to catch up on the arguments. I do appreciate the\nvigor of the discussion!\n\nFrom what I've seen in skimming the archives, I think that the\nkey arguments have been presented at least once on all sides.\nTherefore, I propose that we proceed as follows:\n\n1. By Monday, I will prepare a summary of my understanding\nof the arguments for and against including passphrase authentication\nin TLS.\n\n2. At that time, I will propose a course of action for the working group.\nIf there is rough consensus on that proposal, we'll go forward. If not,\nwe'll see if we have some common ground to build on.\n\nThanks for your cooperation.\n\n        - Win Treese\n\n\n\n"
        },
        {
            "subject": "Adding a high-security channel for passwords Repl",
            "content": "The idea sounds good, but if you offer good encryption for authnetication,\ncan we absolutely gaurentee that it would not be used for user data\nother than pin or hashed password.  \nDo we even need to hash the password if it is being sent in a secure\nfashion.  \nHow about a password based challenge responce mechanism to thwart\nreplay attacks.\ni would aslo have questions regarding the shared secret that is\ngenerated to send the password.  How securely is the shared secret\nmaster seed transmitted?\n\nJust some thoughts\n:)\n\nBaber Amin\nSoftWare Eng.\nNovell Inc.\nEmail: Baber_Amin@Novell.com\nx.400: C=US;A=TELEMAIL;P=WPCORP;O=CORP\nIMX  : USWPCBAM@IBMMAIL\n801-861-5285\n801-376-3921\n\n--------------------------------------------------------------------\nI tried to find Him on the Christian cross, but He was not there;\nI went to the Temple of the Hindus and to the old pagodas,\nbut I could not find a trace of Him anywhere.\nI searched on the mountains and in the valleys, but neither in the\nheights nor in the depths was I able to find Him.\nI went to the Kaaba in Mecca, but He was not there either.\nI questioned the scholars and philosophers but He was beyond\ntheir understanding.\nI then looked into my heart and it was there where He dwelled\nThat I saw Him;\n\nJelaluddin Rumi\n--------------------------------------------------------------------\n\n\n\n\n>>> Paul C. Kocher <pck@netcom.com> 08/06/96 06:18pm >>>\n\n\nFor password authentication what we really are trying to create\nis a more secure encryption method for moving the hashed password\nacross the wire.\n\nInstead of adding a set of extra fields to the protocol for \npasswords, it seems to make more sense to buind in capabilities \nto send securely-encrypted data of any type.  This could be \nuseful for other applications as well, such as credit card \nnumbers, non-user-accessible control information, biometric\nidentification information, etc.  In general, applications \nwould probably be free to decide what to use this for.\n\nTo do this, another record layer type for application-specific \ncontrol messages would be added.  These messages would be\nencrypted\nwith another encryption type defined by the ciphersuite (probably \n128-bit RC4 for exportable ciphersuites and triple DES for secure \nciphersuites since NSA is afraid of triple DES).  The keys for this\nsecure channel would be derived independently from the master secret.\n\nThese messages would probably consist of some kind of data type\nidentifier (indicting hashed password, plaintext password, credit \ncard number, ATM PIN, etc.), possibly a criticality flag, and the \nmessage content.  (This still needs to be hashed out, pardon the \npun.)\n\nI talked with the export office of the NSA today and asked about\nthis.  In general, they don't seem likely to mind, provided that\napplications don't use the secure channel for user data.\n\nAny feedback (to the list) is, of course, appreciated.\n\n-- Paul\n\n_____________________________________________________________________\nPaul Kocher            Voicemail: (415) 354-8004, FAX: (415) 321-1483\nCryptography consultant                   http://www.cryptography.com\n\n\n\n"
        },
        {
            "subject": "Re: Passphrases in or ou",
            "content": "Hi Steve,\n\nAllowing the implementor to to bad things is different from allowing\nthe -user- to do bad things.  Even with assymmetric cryptosystems, the\nuser may publish his/her private key (or encrypted private key along\nwith the decrypting passphrase) -- an obvious Bad Thing.\n\nThe -protocol- can not prevent that.\n\nThe point about having a protocol design so that implementors can't\neasily hang themselves -- I'm one of the people who advocate this\nposition, much like high level languages etc -- has to do having as a\nresult an overall system that do not have holes; users can hose\nthemselves by creating individual holes, but that does not necessarily\ncause the system to fall as a whole.\n\nIt's still valid to argue that we do not want to permit the user to\neasily hang him-/herself.  This is a slightly different argument,\nhowever, than the one that I (and others) had made at Montreal.\n\nIs there enough user education so that they won't chose bad passwords?\nSo that they won't disclose their private key?  So they won't run\ntrojan horse, virus-laden software?  The list of possible bad things\nthat a user can do goes on and on.\n\nI think that since the system implementor choses the web server\nconfiguration (or other server) to permit or disallow passphrases at\nthe protocol level, and the system implementor can decide (has the\nrope) whether s/he can educate his/her users enough about passphrase\nselection, having this option won't hurt.  It is better than forcing\nsome systems implementor to do passphrases on top of weak encryption,\nwhich is the current practice.  For banks and stock brokers.\n\n--------\n\nRegarding the proposal to provide multiple channels with different\ncrypto strength, I'd be happy if it really is exportable.  Granted, if\nI were a spy, I'd type \"attack at dawn.\" in the 16 character field for\nmy credit card number in a form that will send the (purported) credit\ncard number via the more secure channel.  (Web form provide by a\nserver run by my collaborator/controller overseas, say.)\n\nThis is not to say that this kind of more secure communication isn't\npossible with the passphrase hash mechanism.  For example, one could\nuse a code book of passphrases, so that the server would hash using\nall possible passphrases in the code book to find one that matches and\nlookup the corresponding meaning therein.  Longer messages can obvly\nbe done by constructing an alphabet out of the passphrases, and\niterating the authentication protocol.  A tad clumsier at the server\nend since off-the-shelf server software can't easily be used, but not\nhorrible.\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re:  Adding a high-security channel for passwords Repl",
            "content": "Baber Amin writes:\n> The idea sounds good, but if you offer good encryption for authnetication,\n> can we absolutely gaurentee that it would not be used for user data\n> other than pin or hashed password.  \n> Do we even need to hash the password if it is being sent in a secure\n> fashion.  \n\nUnder my suggestion, the TLS protocol would allow virtually anything\nto go on the secure channel, but exportable implementations would \nhave to limit the use of the secure encryption to meet government \nregulations.\n\nPasswords sent over the secure channel would normally be hashed \nso that the recipiant of the password does not get or need to know\nthe actual password.  (In practice, this hashing would probably\nconsist of hashing just the password, followed by hashing with\nthe client and server randoms.)  This ensures that someone who\ncompromises the server still has to brute-force the password.\n\nFor something like a 4-digit ATM card PIN, the password needs\nto be sent in the clear and hashing the password is useless since\nbrute force is trivial.  This is why my note to the list I included \nboth hashed and un-hashed passwords as things that might go over \nthe secure channel.\n\n> How about a password based challenge responce mechanism to thwart\n> replay attacks.\n> i would aslo have questions regarding the shared secret that is\n> generated to send the password.  How securely is the shared secret\n> master seed transmitted?\n\nHashing with the randoms prevents replay attacks.\n\nThe shared secret is already generated in SSL 3.0 (i.e., the\nMaster_Secret), and would be used to generate these keys as well.\n\n-- Paul\n\n_____________________________________________________________________\nPaul Kocher            Voicemail: (415) 354-8004, FAX: (415) 321-1483\nCryptography consultant                   http://www.cryptography.com\n\n\n\n"
        },
        {
            "subject": "Re: Adding a high-security channel for passwords Repl",
            "content": "Paul C. Kocher wrote:\n> \n> Baber Amin writes:\n> > The idea sounds good, but if you offer good encryption for authnetication,\n> > can we absolutely gaurentee that it would not be used for user data\n> > other than pin or hashed password.\n> > Do we even need to hash the password if it is being sent in a secure\n> > fashion.\n> \n> Under my suggestion, the TLS protocol would allow virtually anything\n> to go on the secure channel, but exportable implementations would\n> have to limit the use of the secure encryption to meet government\n> regulations.\n\n  It seems to me that this would encourage interoperability problems\ndown the road.\n\n--Jeff\n\n-- \nJeff Weinstein - Electronic Munitions Specialist\nNetscape Communication Corporation\njsw@netscape.com - http://home.netscape.com/people/jsw\nAny opinions expressed above are mine.\n\n\n\n"
        },
        {
            "subject": "SSL/STLP Winsock Implementatio",
            "content": "Is it possible to implement SSL or STLP for all winsock \ncommunications?\nFor example, I would like to encrypt all FTP communication\nwith a specific server, without depending on the FTP client\napplication used.\n\nSo - is this possible? Is there such an implementation?\n\nThanks,\nYonat.\n\n\n\n"
        },
        {
            "subject": "Re: SSL/STLP Winsock Implementatio",
            "content": "Yonat Sharon writes:\n> \n> Is it possible to implement SSL or STLP for all winsock \n> communications?\n\nIt depends on the SSL implementation.\n\n> For example, I would like to encrypt all FTP communication\n> with a specific server, without depending on the FTP client\n> application used.\n\nThat means that you can't negotiate the use of SSL\nin the FTP protocol.  So if the ftp server you're talking\nto does not do SSL, you will not be able to communicate.\nI think it's better to use the FTP options to negotiate SSL.\n\n> So - is this possible?\n\nYes.\n\n> Is there such an implementation?\n\nNot that I'm aware of.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: SSL/STLP Winsock Implementatio",
            "content": "> \n> Is it possible to implement SSL or STLP for all winsock \n> communications?\n> For example, I would like to encrypt all FTP communication\n> with a specific server, without depending on the FTP client\n> application used.\n> \n> So - is this possible? Is there such an implementation?\n> \n> Thanks,\n> Yonat.\n\nWe do this on our B2 Unix implementation (DG/UX), and a partner is\nimplementing this for Windows.  The actual implementation will allow\narbitrary filters to be configured for specific types of connections for\nspecific users and/or specific hosts.  SSL will be one of the original\nfilters offered.\n\nThis is not currently available.  If you would like additional info, let me\nknow.\n\n-- \nJon F. Spencer   spencerj@rtp.dg.com  (uunet!rtp.dg.com!spencerj)\nData General Corp.                  Phone : (919)248-6246\n62 T.W. Alexander Dr, MS #119       FAX   : (919)248-6108\nResearch Triangle Park, NC  27709   Office RTP 121/9\n\nReality is an illusion - perception is what counts.\n\nNo success can compensate for failure at home.\nPresident David O. McKay\n\n***** UCC 1-207 ********\n\n\n\n"
        },
        {
            "subject": "Re: SSL/STLP Winsock Implementatio",
            "content": "> From: yonat@elementrix.co.il (Yonat Sharon)\n> > \n> > Is it possible to implement SSL or STLP for all winsock \n> > communications?\n> > For example, I would like to encrypt all FTP communication\n> > with a specific server, without depending on the FTP client\n> > application used.\n> > \n> > So - is this possible? Is there such an implementation?\n> > \n> > Thanks,\n> > Yonat.\n\n\nYou may wish to talk to SecureWare (www.sware.com).  Their product\nis inserted into the network stack rather than being linked into\neach application.\n\n\n\n"
        },
        {
            "subject": "-No Subjec",
            "content": "subscribe\n\n\n\n"
        },
        {
            "subject": "call for papers: IEEE Network issue on network securit",
            "content": "Apologies if you receive multiple copies of\nthis call-for-papers.\n\n----------------------------------------------------------------\n\n\n                    IEEE NETWORK MAGAZINE\n                       Call for Papers\n\n                      Feature Issue on\n               Network and Internet Security\n\n\nThe May 1997 issue of IEEE Network will feature the topic of\nnetwork and Internet security.  Private and public organizations\nare increasingly dependent on distributed computer systems and\ncomputer networks such as the global Internet.  However, the\ncommercialization and escalating popularity of the Internet have\nbeen accompanied by a rising level of network-related security\nattacks despite firewalls, encryption, anti-virus programs, and\nother security measures.  Today, security attacks can originate from\na greater number of sources in more varied forms.  New networking\ntechnologies (e.g., fiber optics, ATM) enable data to be moved at\nrates of gigabits/s, where security breaches and data transmissions\ncan occur on timescales much faster than human intervention.\nIn addition, computer technology is being used for increasingly\nsophisticated, automated tools that allow any non-expert to\nperpetrate serious security attacks.  As the issue of security gains\nprominent attention in scientific, political, and commercial arenas,\nit poses a potential hindrance to the continued growth of the Internet\nand other computer networks.\n\nContributions are invited to the feature issue of IEEE Network which\nwill represent the current state of the art covering all aspects of\nnetwork and internetwork security.  Topics may include, but are not\nlimited to:\n     - cryptography and privacy;\n     - viruses, worms, and intruding software;\n     - Internet commerce;\n     - firewalls and access control;\n     - authentication and digital signatures;\n     - key management and exchange;\n     - certificates and certification authorities;\n     - secure e-mail;\n     - secure network management.\n\nContributions should be submitted by November 1, 1996 to the guest\neditor:\n     Thomas M. Chen\n     GTE Laboratories, Inc.\n     40 Sylvan Road\n     Waltham, MA 02254\n     USA\n     tel: 617-466-2758\n     fax: 617-890-9320\n     email: tchen@gte.com\n\n\n\n"
        },
        {
            "subject": "Re: I-D ACTION:draft-ietf-tls-ssh00.tx",
            "content": "The SSH protocol was mentioned a few times on this list. A pointer \nto the SSH Internet draft of June 13, 1996 was posted some time ago:\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-ssh-00.txt\n\nI recently read that Internet draft. As described, the SSH client \nauthentication is flawed. If a client A is willing to talk to a server \nS1, then S1 can impersonate A in establishing a session with another \nserver S2. Some details on this are below. \n\nThe mistake in SSH seems to be fairly common; I spotted it in several \nprotocols in the last few years. In summary, the mistake consists \nin not applying a digital signature to enough material to resolve \nambiguities about the intended meaning of the signature. (Future \nprotocol designers, beware.) It is not enough to use digital signatures \nfor authentication---the right material must be signed. \n\nIn SSH, the client signs the message SSH_MSG_HOSTAUTH, which is the \nanalogue of the SSL message ClientVerify. Unfortunately, SSH_MSG_HOSTAUTH \ndoes not unambiguously identify the connection it is for. This problem \nshould not be too hard to fix (cf. SSL's ClientVerify). Tatu Ylonen \nis thinking about it. \n\nThe currently deployed implementation of SSH is based on an older \nspecification. It may have weaknesses, but not this one; client authentication \nworks differently. \n\nMartin Abadi \n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSome details on the attack, for any SSH experts:\n\nSuppose that B is a server, A a client, and C wants to masquerade \nas A with respect to B. Suppose further that A is interested in having \na session with C as server. I am going to write MESSAGE_TYPE(n) to \nshow an instance of MESSAGE_TYPE. We can have the following message \nsequence: \n\nA -> C : SSH_MSG_KEXINIT(1)  /* A starts talking to C           */\nC -> B : SSH_MSG_KEXINIT(1)  /* C forwards A's message to B     */\nB -> C : SSH_MSG_KEXINIT(2)  /* B replies to C, including       */\n                             /* a cookie Nb                     */\nC -> A : SSH_MSG_KEXINIT(3)  /* C replies to A, with the server */\n                             /* cookie Nb it got from B         */\nB -> C : SSH_MSG_KEXRSA_HOSTKEY(1)                          \nC -> A : SSH_MSG_KEXRSA_HOSTKEY(2)         \n                             /* B and C show their respective   */\n                             /*                    public keys  */               \nA -> C : SSH_MSG_KEXRSA_SESSIONKEY(1)   \n                             /* A sends a session key to C,     */\n                             /* under C's public keys           */\nC -> B : SSH_MSG_KEXRSA_SESSIONKEY(2)   \n                             /* C sends a corresponding message */\n                             /* to B                            */\n                             /* after this point, everything is */\n                             /* encrypted under session keys    */\n                             /* which are both known to C       */\nA -> C : SSH_MSG_HOSTAUTH(1) /* A signs A's name, A's cookie,   */     \n                             /* and Nb                          */\nC -> B : SSH_MSG_HOSTAUTH(1) /* C forwards A's signed message!  */\n                             /* after reencrypting under the    */\n                             /* appropriate session key         */\n\nAt this point, C has a connection with B, and a corresponding session \nkey. B presumably believes that the connection is with A, because \nA has signed the server cookie that B generated. A is not confused. \n\n\n\n"
        },
        {
            "subject": "ANNOUNCEMENT AND CALL FOR PAPERS  1998 USENIX Security Conferenc",
            "content": "*************************************************************************\n\nANNOUNCEMENT AND CALL FOR PAPERS\n\n7th USENIX Security Symposium\nJanuary 26-29, 1998\nMarriott Hotel-- San Antonio, Texas\n\nSponsored by the USENIX Association, the UNIX and Advanced Computing\nSystems Professional and Technical Association\n\nIn cooperation with: The CERT Coordination Center.\n\nImportant Dates for Refereed Papers\n\nPapers due:                             September 9, 1997\nAuthor notification:                    October 8,  1997\nCamera-ready final papers due:          December 9, 1997\n\nRegistration Materials Available:       End October, 1997\n\n(Authors, see \"How to Submit a Refereed Paper\" below.)\n\nProgram Chair\nAvi Rubin, Bellcore\n\nProgram Committee\nCarlisle Adams, Nortel\nDave Balenson, Trusted Information Systems\nSteve Bellovin, AT&T Research\nDan Boneh, Princeton University\nDiane Coe, Mitre\nEd Felten, Princeton University\nLi Gong, JavaSoft\nPeter Honeyman, CITI, University of Michigan\nHugo Krawczyk, IBM Watson Labs\nJack Lacy, AT&T Research\nHilarie Orman, DARPA/ITO\nMike Reiter, AT&T Research\nDavid Wagner, University of California, Berkeley\n\nReaders\nKatherine T. Fithen, CERT\nTrent Jaeger, IBM Watson Labs\n\nInvited talks coordinator: Greg Rose, Qualcomm\n\nConference home page: <http://www.usenix.org/sec/sec98.html>\n\nOVERVIEW\n\nThe goal of this symposium is to bring together researchers,\npractitioners, system programmers, and others interested in the \nlatest advances in security and applications of cryptography.\n\nThis will be a four day symposium with two days of tutorials, \nfollowed by two days of refereed paper presentations, invited talks,\nworks-in-progress presentations, and panel discussions.\n\nTUTORIALS Monday and Tuesday, January 26-27\n\nTutorials for both technical staff and managers will provide\nimmediately useful, practical information on topics such as local and\nnetwork security precautions, what cryptography can and cannot do,\nsecurity mechanisms and policies, firewalls and monitoring systems.\n\nIf you are interested in proposing a tutorial, contact the tutorial\ncoordinator, Dan Klein:  phone (412)421-2332 email <dvk@usenix.org>.\n\nTECHNICAL SESSIONS   \nWednesday and Thursday, January 28-29\n\nIn addition to the keynote presentation, the technical program includes\nrefereed papers, invited talks, a work in progress session, and panel\nsessions. There will be Birds-of-a-Feather sessions the last two\nevenings.  You are invited to make suggestions to the program committee\nvia email to <security@usenix.org>.\n\nPapers that have been formally reviewed and accepted will be presented\nduring the symposium and published in the symposium proceedings,\npublished by USENIX and provided free to technical session attendees.\nAdditional copies will be available for purchase from USENIX.\n\nSYMPOSIUM TOPICS\n\nRefereed paper submissions are being solicited in areas including but\nnot limited to:\n\n        * Adaptive security and system management\n        * Analysis of malicious code\n        * Applications of cryptographic techniques\n        * Attacks against networks/machines\n        * Computer misuse and anomaly detection\n        * Copyright protection (technical solutions)\n        * Cryptographic & other security tools\n        * File and file system security\n        * Network security\n        * New firewall technologies\n        * Security in heterogeneous environments\n        * Security incident investigation and response\n        * Security of Mobile Code\n        * User/system authentication\n        * World Wide Web security\n\nNote that this symposium is not about new codes, ciphers, nor\ncryptanalysis for its own sake.\n\nPapers must represent novel scientific contributions in computer\nsecurity with direct relevance to the engineering of secure systems\nfor the commercial sector.\n\nHOW TO SUBMIT A REFEREED PAPER\n(Please read carefully.)\n\nThe guidelines for submission are a bit different from previous\nyears. Authors must submit a mature paper in postscript format.\nAny incomplete sections (there shouldn't be many) should be\noutlined in enough detail to make it clear that they could be\nfinished easily. Full papers are encouraged, and should be about\n8 to 15 typeset pages. Submissions must be received by\nSeptember 9, 1997.\n\nAlong with your paper, please submit a separate email message\ncontaining the title, all authors, and their complete contact\ninformation (phone, fax, postal address, email), including an\nindication of which author is the contact author.\n\nAuthors will be notified of acceptance on October 8, 1997.\n\nAll submissions will be judged on originality, relevance, and\ncorrectness. Each accepted submission may be assigned a member\nof the program committee to act as its shepherd through the\npreparation of  the final paper. The assigned member will act\nas a conduit for feedback from the committee to the authors.\nCamera-ready final papers are due on December 9, 1997.\n\nIf you would like to receive detailed guidelines for submission\nand examples of extended abstracts, you may send email to:\n\n        <securityauthors@usenix.org>\n\nor telephone the USENIX Association office at (510) 528-8649.\n\nThe Security Symposium, like most conferences and journals,\nrequires that papers not be submitted simultaneously to another\nconference or publication and that submitted papers not be\npreviously or subsequently published elsewhere. Papers\naccompanied by non-disclosure agreement forms are not\nacceptable and will be returned to the author(s) unread.\nAll submissions are held in the highest confidentiality prior\nto publication in the Proceedings, both as a matter of policy\nand in accord with the U.S. Copyright Act of 1976.\n\nThere will be one or two prizes awarded for best paper(s).\n\nWHERE TO SUBMIT\n\nFor reliability, please send one copy of your paper to the program\ncommittee via each of two of the following methods. All submissions\nwill be acknowledged.\n\n  o Preferred Method: email (Postscript) to:\n        <securitypapers@usenix.org>\n\n  o Alternate Method: postal delivery to\n       Security Symposium\n       USENIX\n       2560 Ninth St., Ste. #215\n       Berkeley CA 94710\n       U.S.A.\n       Phone: (510) 528-8649\n\n  o Fax:  (510) 548-5738\n\n\nVendor Exhibits\n\nDemonstrate your security product to our technically astute attendees\nresponsible  for security at their sites.  We invite you to take part\nin the Vendor Display.  The informal, table-top display allows you to\nmeet with attendees informally and demonstrate in detail your security\nsolutions.\n\nContact CynthiaDeno\nEmail: cynthia@usenix.org\nPhone:  408.335.9445\nFax 408.335.5327\n\n\nWorks-in-Progress Session (WIPs)\n\nThe last session of the symposium will be a Works-in-Progress session\nconsisting of five minute presentations. Speakers should provide a one\nor two paragraph abstract to the program chair by 6:00 pm on January\n28, 1998 at the conference. These should be provided in person, not via\nemail. The chair will post the schedule of presentations by noon on the\n29th. Experience at other conferences has shown that usually, all of\nthem are accepted.  The five minute time limit will be strictly enforced.\n\nINVITED TALKS\n\nThere will be several invited talks at the conference in parallel with\nthe refereed papers. If you have suggestions for possible speakers,\nplease send them to <security@usenix.org>.\n\nREGISTRATION MATERIALS\n\nMaterials containing all details of the technical and tutorial\nprograms, registration fees and forms, and hotel information will be\navailable at the end of October 1997.  To receive the registration\nmaterials, please contact:\n\nUSENIX Conference Office\n22672 Lambert Street, Suite 613\nLake Forest, CA USA   92630\nPhone:  (714) 588-8649\nFax: (714) 588-9706\nEmail: <conference@usenix.org>\n\nInformation can also be found under the Conference home page:\n<http://www.usenix.org/sec/sec98.html>.\n\n\n\n"
        },
        {
            "subject": "Digital Signature Vot",
            "content": "Hello Jim,\n\nYour email message \"Trying to join W3C Digital Signature Initiative\" was \nforwarded to me.\n\nThe correct email address is dsig-vote@w3.org.\n\nIf you have any questions or need further information, please feel free to \ncontact me at khudairi@w3.org or on +1.617.253.8036.\n\nRegards,\n\nSally Khudairi\nW3C Public Relations\n\njadler@soundcode.com said:\n> Our company is trying to join the W3C Digital Signature Initiative at \n> dsig@w3.org, but my mail keeps getting bounced from that address.  \n> Could you send me the correct address or forward the following \n> message to the appropriate people at W3C DSI -- thanks!\n\n> Our company develop public-key cryptography systems for the small \n> office/home office, legal, law-enforcement, and ISV communities.  We \n> would very much like to join the digital signature working group.  I \n> understand there is an open invitation until September 15, 1996.\n\n\n\n"
        },
        {
            "subject": "New Secure Sockets Layer FAQ 1.0.0 Now Available",
            "content": "The full HTML version of the SSL-Talk List FAQ 1.0.0 is now available at\n<http://www.consensus.com/security/ssl-talk-faq.html>.\n\nThe text version was posted yesterday on to the SSL-Talk discussion list,\nand is available at\n<http://www.consensus.com/security/ssl-talk-faq.txt> or\n<ftp://ftp.consensus.com/pub/security/ssl-talk-faq.txt>.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n.. Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "NonW3C Member Organizations Trying to join W3C Digital Signature  Initiativ",
            "content": "To members of ietf-tls@w3.org:\n\nI have recently received numerous requests from non-W3C Member organizations \nto join the W3C Digital Signature Initiative.\n\nPlease note the following:\n\na.  DSIG is _not_ open; it is closed to W3C Member organizations ONLY\n\nb.  There is, indeed, a mailing list and proposal out for votes to W3C \nMembers, closing on 15 September 1996.\n\nc.  For W3C Members [or if you've recently become a W3C Member], more \ninformation can be found at:\n\nProposal:\n http://www.w3.org/pub/WWW/Security/DsigProj.html\n\nVoting Details -- accessible to W3C Members ONLY:\nhttp://www.w3.org/pub/WWW/Member \n\n\n\nIf your organization is interested in becoming a Member of W3C, please review \nthe information at http://www.w3.org/pub/WWW/Consortium/Prospectus/\n\nIf you need any additional information, feel free to contact me at \nkhudairi@w3.org.\n\nRegards,\n\nSally Khudairi\nW3C Public Relations\n\n\n\n"
        },
        {
            "subject": "Re: NonW3C Member Organizations Trying to join W3C Digital Signatur",
            "content": "Sally Khudairi wrote:\n> \n> To members of ietf-tls@w3.org:\n> \n> I have recently received numerous requests from non-W3C Member organizations \n> to join the W3C Digital Signature Initiative.\n> \n> Please note the following:\n> \n> a.  DSIG is _not_ open; it is closed to W3C Member organizations ONLY\n\nCould you explain the rationale behind this, please?\n\nCheers,\n\nBen.\n\n-- \nBen Laurie                  Phone: +44 (181) 994 6435\nFreelance Consultant and    Fax:   +44 (181) 994 6472\nTechnical Director          Email: ben@algroup.co.uk\nA.L. Digital Ltd,           URL: http://www.algroup.co.uk\nLondon, England.            Apache Group member (http://www.apache.org)\n\n\n\n"
        },
        {
            "subject": "Re: NonW3C Member Organizations Trying to join W3C Digital Signature  Initiativ",
            "content": "All,\n\n  Well after reviewing the addresses listed below.  I cannot justify the costing\nor the W3C DIgital Signature initiative.  There seems to be a somewhat \nlopsided benifit to that org.  Not to it's members.  I am quite supprised\nit the boldness here!\n\nReguards,\n\n\nAt 04:09 PM 9/15/96 -0400, you wrote:\n>To members of ietf-tls@w3.org:\n>\n>I have recently received numerous requests from non-W3C Member organizations \n>to join the W3C Digital Signature Initiative.\n>\n>Please note the following:\n>\n>a.  DSIG is _not_ open; it is closed to W3C Member organizations ONLY\n>\n>b.  There is, indeed, a mailing list and proposal out for votes to W3C \n>Members, closing on 15 September 1996.\n>\n>c.  For W3C Members [or if you've recently become a W3C Member], more \n>information can be found at:\n>\n>Proposal:\n> http://www.w3.org/pub/WWW/Security/DsigProj.html\n>\n>Voting Details -- accessible to W3C Members ONLY:\n>http://www.w3.org/pub/WWW/Member \n>\n>\n>\n>If your organization is interested in becoming a Member of W3C, please review \n>the information at http://www.w3.org/pub/WWW/Consortium/Prospectus/\n>\n>If you need any additional information, feel free to contact me at \n>khudairi@w3.org.\n>\n>Regards,\n>\n>Sally Khudairi\n>W3C Public Relations\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC. Representing PDS. INC.\nWeb:  http://www.halcyon.com/sweat007/\nPhone: 214-793-7445 (Direct Line)\nFax: 214-447-1900\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: NonW3C Member Organizations Trying to join W3C Digital Signatur",
            "content": ">> a.  DSIG is _not_ open; it is closed to W3C Member organizations ONLY\n>\n>Could you explain the rationale behind this, please?\n\nW3C is a membership-based organization, and its members are interested in\ncarrying out this work directly and quickly.  These members include over 150\ncompanies in the computer, network, telecommunications, service, publishing,\nbanking, and other industries.  Membership in W3C is open, at very\nreasonable rates, to any company or organization that is interested in work\nlike the Digital Signature Initiative.\n\nI would like to emphasize that the call for participation in the Initiative\nmakes it clear that the output of the project will be code and\nspecifications ALL OF WHICH will be made available at no charge to the\ngeneral public.  The change control and maintenance of both will be decided\nby the participants at the end of the project, and turning either or both\nover to a formal Standards body is certainly a likely outcome.\n\n--Jim Miller\n(manager, Technology and Society area, W3C)\n\n\n\n"
        },
        {
            "subject": "Conventional unleaded gasoline &quot;Lel Bruce Peto&quot; advises in Group 3.",
            "content": "Conventional unleaded gasoline \"Lel Bruce Peto\" advises in Group 3 jumped \n2.0cts gal on the rollover to December basis pricing trading at an implied \n84.5cts gal, up 2.0cts on the day. Regular is priced 8cts gal over the \nscreen. Chicago conventional rose 1.25cts gal to 95.25cts gal, indexed at a \nmassive 18.75cts gal over print. Chicago spot markets are expected to \nremain subject to price swings. December heating oil fell 0.74cts gal to \n74.16cts gal, and spot prices in Chicago and the Group followed; high and \nlow sulfur fuel oil prices in Chicago for 1st November cycle trade slipped \n1cts gal in cash price to 82.25cts...as of 11-01-02... \n\n\n\n"
        },
        {
            "subject": "December no lead &quot;Lel Bruce Peto&quot; informing bucked an overall..",
            "content": "December no lead \"Lel Bruce Peto\" informing bucked an overall market \ndowntrend to close at 76.46cts gal, up 0.99ct. January print fell 0.04cts \nto 73.02cts. December heating oil dropped 0.74cts to 74.16cts gal, with the \nJanuary contract down 0.81cts to 74.34cts gal.\nConventional no lead in New York Harbor jumped 5cts gal screen basis \nversus December no lead print to 11cts gal over, setting prompt cash at an \nimplied 87.5cts gal...as of 11-02-02...\n\n\n\n"
        },
        {
            "subject": "&quot;Lel Bruce Peto&quot; Oil sector 80's chronology restating..198",
            "content": "\"Lel Bruce Peto\" Oil sector 80's chronology restating..\nOil & Gas Chronology :  The 1980?s\n\n\n1989\n\nMar \n\nExxon tanker Valdez runs aground, spilling 11 million gallons of crude oil \nin the waters of Price William Sound. Oil prices react upward to news of \nthe spill and to potential shortages on the west coast cased by refinery \nfires there.\n\nJune \n\nOPEC raises their production ceiling to 19.5 MMB/D. \n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "Tes",
            "content": "This is a test.\n\n\n\n======================\nVisit:\nhttp://www.massive-butts.com\nhttp://www.imagine-sex.com\n\n\n\n"
        },
        {
            "subject": "Re: NonW3C Member Organizations Trying to join W3C Digita",
            "content": "Jim Miller wrote:\n> \n> >> a.  DSIG is _not_ open; it is closed to W3C Member organizations ONLY\n> >\n> >Could you explain the rationale behind this, please?\n> \n> W3C is a membership-based organization, and its members are interested in\n> carrying out this work directly and quickly.  These members include over 150\n> companies in the computer, network, telecommunications, service, publishing,\n> banking, and other industries.  Membership in W3C is open, at very\n> reasonable rates, to any company or organization that is interested in work\n> like the Digital Signature Initiative.\n\nI hardly think that $50,000 can be described as reasonable in the context of\nmy interest in such things (that is, as one of the maintainers of Apache).\n\n> \n> I would like to emphasize that the call for participation in the Initiative\n> makes it clear that the output of the project will be code and\n> specifications ALL OF WHICH will be made available at no charge to the\n> general public.  The change control and maintenance of both will be decided\n> by the participants at the end of the project, and turning either or both\n> over to a formal Standards body is certainly a likely outcome.\n\nThat would be nice, I suppose. But turning it over to the only standards body\nworth turning it over to (the IETF, of course) will almost certainly mean that\nit will come out completely different. Which is why the original working group\nshould be completely open.\n\nCheers,\n\nBen.\n\n-- \nBen Laurie                  Phone: +44 (181) 994 6435\nFreelance Consultant and    Fax:   +44 (181) 994 6472\nTechnical Director          Email: ben@algroup.co.uk\nA.L. Digital Ltd,           URL: http://www.algroup.co.uk\nLondon, England.            Apache Group member (http://www.apache.org)\n\n\n\n"
        },
        {
            "subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico",
            "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n"
        },
        {
            "subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico",
            "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n"
        },
        {
            "subject": "ArribAves - Llamada de Participaciones - Call for Participation   Apelo ? Par",
            "content": "===========================\nApologies for possible multiple postings\n=====================================\n   Les rogamos despulpas por m?ltiplos env?os\n=====================================\n   Pedimos desculpa por eventuais m?ltiplos reenvios\n\nEx.mos Srs.,\n\nEm nome da organiza??o do ArribAves 2003 - 1? Encontro de Observadores\n(birdwatchers) de Aves das Arribas do Douro, a ter lugar em Bemposta,\nMogadouro,\n25-26 de Julho, vimos solicitar a mais ampla divulga??o deste evento junto\nda V/ institui??o e parceiros.\n\nO ArribAves 2003 tem o apoio institucional da SPEA - Sociedade Portuguesa de\nEstudo das Aves.\n\nDesde j? agradecemos todo o apoio que\nV.Ex.as venham a dispensar na divulga??o deste evento.\n\nComo os melhores cumprimentos,\n\nA Organiza??o do ArribAves 2003\nhttp://arribaves2003.marcos-e-marcos.pt\n\n===========================\nSOLAR DOS MARCOS\nRua de Santa Cruz\n5200-055 BEMPOSTA, PORTUGAL\nTel:  279570010\nFax: 279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n============================= Castellano =======================\n\nArribAves\n\n1 Reuni?n de Observadores de P?jaros de Arribes del Duero\n\nBemposta, Mogadouro, Portugal, 25-26 Julio 2003\n\nhttp://arribaves2003.marcos-e-marcos.pt\n\n\nObjetivos:\nArribAves es una primera reuni?n de Birdwatchers de los Arribes del Duero\npara el cual el Solar dos Marcos (centro de turismo rural) est? localmente\nresponsable por su organizaci?n, para la promoci?n activa del turismo\necol?gico. Esta reuni?n intenta reunir a la gente que desea observar,\nestudiar, investigar, salvaguardar y proteger p?jaros desde un punto de\nvista del profesional o del tiempo libre o simplemente debido a su\ncuriosidad sobre el tema. Un tema central ser? la especie del p?jaro que\ntiene su habitad natural en los lados del acantilado del r?o de Douro o en\nla regi?n demarcada por el Parque natural del Douro Internacional (PNDI) [\nparque natural del Douro internacional ] y el del los Arribes del Duero a\ntrav?s de la frontera en Espa?a.\nEste acontecimiento apunta ser el primer de una serie a ocurrir anualmente\nen la aldea de Bemposta en el coraz?n absoluto de los Arribes del Duero,\nque, en primer lugar, apuntan promover (el supuesto) el turismo alternativo\nque incluye el turismo ecol?gico tal como birdwatching, que est? mucho en\nuso en pa?ses extranjeros tales como los Estados Unidos de Am?rica, reino\nunido o en el norte de Europa, pero a?n poco de poca importancia en Portugal\ne Espa?a. Por otra parte, los organizadores esperan que el acontecimiento\nsirva para fijar la etapa para promover la acci?n alrededor del tema de los\np?jaros, que, en el contexto de los parques naturales mencionados arriba,\ntratar?n s? mismo sobre las buenas pr?cticas para su estudio y protecci?n,\nque contiene un aspecto m?s cient?fico.\n\nLa reuni?n funcionar? por dos d?as. El primer que esta pensado para la\npresentaci?n de los papeles nacionales o ib?ricos (dados la naturaleza\nfronteriza de la regi?n) seguido de discusiones y terminando con una\nexposici?n de la fotograf?a y de una cena.\n\nEl segundo d?a ser? dedicado actualmente al contacto directo con los\nArribes, y la realizaci?n de un paseo de barco en el tramo del r?o Douro\nentre el Bemposta y las presas de Picote, los viajes a pi?, las visitas a\nlas aldeas t?picas y el birdwatching.\n\n\nFormato:\nArribAves 2003 estar? en el formato de un acontecimiento cient?fico y\npromocional con la presentaci?n oral de papeles, de tablas redondas y de\naltavoces invitados. Los papeles y los carteles terminados se deben someter\ncuanto antes. Los mejores papeles ser?n publicados en la forma de un libro\ny/o de un folleto.\n\nTemas:\nTodas las ?reas relacionadas con el estudio, la protecci?n y la observaci?n,\nlos experimentos, referente a los p?jaros.\n\nOrganizaci?n Local:\nSolar dos Marcos\n\nFechas importantes:\nPlazo env?o de los art?culos: 30 Junio 2003;\nInforme de aceptaci?n: 10 Julio 2003;\nVersi?n final de los art?culos: 20 Julio 2003\nReuni?n: 25-26 Julio 2003\n\nReservaci?n de Hotel:\nEnv?e sus reservaciones a:\nSolar dos Marcos\nRua de Santa Cruz,\n5200-055 Bemposta\nTel: 279 570 010;\nFax: 279 570 019;\n\nInformaci?n e inscripciones:\nArribAves 2003 Secretariat\na/c M?rio Marcos,\nSolar dos Marcos,\nRua de Santa Cruz,\n5200-055 Bemposta\nTel: 279 570 010;\nFax: 279 570 019;\nE-mail: marcos.marcos@oninet.pt\nURL: arribaves2003.marcos-e-marcos.pt/\n\n\n================================= English ======================\n\nArribAves\n\n1st Meeting of Birdwatchers of Douro Valley\n\nBemposta, Mogadouro, Portugal, 25-26 July 2003\n\nhttp://arribaves2003.marcos-e-marcos.pt\n\nObjectives:\n\nArribAves is a first Meeting of the Birdwatchers of the Douro Valley for\nwhich the Solar dos Marcos (Marcos Manor House) is locally responsible\nthrough its programme for the active promotion of tourism. This meeting\nseeks to bring together people who wish to observe, study, investigate,\nsafeguard and protect birds from a professional or leisure time point of\nview or simply because of their curiosity about the subject. A central theme\nwill be the bird species that have their natural habitat in the cliff sides\nof the Douro River or in the region demarcated by the Parque Natural do\nDouro Internacional (PNDI) [Natural Park of the International Douro] and the\nParque de Los Arribes del Duero across the border in Spain.\n\nThis event aims to be the first of a series to take place annually in the\nvillage of Bemposta in the absolute heart of the PNDI, which, as a first\nstep, aim to promote (the so-called) alternative tourism that includes\necological tourism such as birdwatching, which is much in vogue in foreign\ncountries such as the United States of America, the United Kingdom or in the\nNorth of Europe, but still little of little importance in our country. On\nthe other hand, the organisers hope that the event will serve to set the\nstage to promote action around the theme of birds, which, in the context of\nthe natural parks mentioned above, will concern itself about good practices\nfor their study and protection, which contains a more scientific aspect.\nThe meeting will run for two days. The first being intended for the\npresentation of national or Iberian papers (given the cross-border nature of\nthe region) followed by discussions and ending with an exhibition of\nphotography and a convivial dinner.\nAt present the second day will be devoted to direct contact with the PNDI,\nand the realisation of boat trips on the branch of the river Douro between\nthe Bemposta and Picote dams, walking tours, visits to typical villages and\nbirdwatching other than in locations previously assigned are currently being\nconsidered.\n\n\nFormat:\nArribAves 2003 will be in the format of a scientific and promotional event\nwith the oral presentation of papers, round tables and invited speakers.\nCompleted papers and posters should be submitted as soon as possible. The\nbest papers will be published in the form of a book and/or a brochure.\n\n\nThemes:\nAll areas related to the Study, Protection and Observation of Birds as well\ncase studies and experiments.\n\nLocal Organisation:\nSolar dos Marcos\n\nImportant Dates:\nDeadline for Papers: 30 June 2003\nAdvice of Acceptance: 10 July 2003\nFinal Version of Papers: 20 July 2003\nMeeting: 25-26 July 2003\n\nHotel Reservation:\nSend your reservations to:\nSolar dos Marcos\nRua de Santa Cruz,\n5200-055 Bemposta\nTel: 279 570 010;\nFax: 279 570 019;\n\nInformation and Registration:\nArribAves 2003 Secretariat\nc/o M?rio Marcos,\nSolar dos Marcos,\nRua de Santa Cruz,\n5200-055 Bemposta\nTel: 279 570 010;\nFax: 279 570 019;\nE-mail: marcos.marcos@oninet.pt\nURL: arribaves2003.marcos-e-marcos.pt/\n\n\n\n============================= Portugu?s ==================\n\nArribAves\n\n1? Encontro de Observadores de Aves das Arribas do Douro\n\nBemposta, Mogadouro, 25-26 Julho 2003\n\nhttp://arribaves2003.marcos-e-marcos.pt\n\nObjectivo:\nO ArribAves 2003 ? o primeiro encontro a fomentar nas Arribas do Douro,\nregi?o do Douro Internacional, o contacto entre os principais intervenientes\nvocacionados para a tem?tica do estudo, protec??o e observa??o de aves,\nsejam investigadores, docentes ou simplesmente turistas ecol?gicos, que\nprocuram partilhar experi?ncias, discutir e analisar boas pr?ticas ou\nsimplesmente buscam o prazer da observa??o de aves no cen?rio magn?fico do\nDouro Internacional, especialmente considerando as esp?cies do Parque\nNatural do Douro Internacional e do Parque de los Arribes del Duero.\n\nEste evento pretende ser o primeiro de uma s?rie a realizar anualmente, na\naldeia de Bemposta, em pleno cora??o dos dois parques naturais, que embora\nnuma primeira abordagem, vise fomentar o denominado turismo alternativo e\necol?gico na vertente da observa??o das aves (birdwatching), t?o em voga no\nestrangeiro em pa?ses como os Estados Unidos da Am?rica, Reino Unido ou o\nNorte da Europa, mas ainda em desuso no nosso pa?s; por outro lado, desejam\nos organizadores que o evento sirva de palco para uma ac??o de\nsensibiliza??o sobre a tem?tica das aves, no contexto dos parques naturais\nmencionados, no que concerne ?s boas pr?ticas para o seu estudo e protec??o,\nabarcando j? um cariz mais cient?fico.\n\nO Encontro decorrer? ao longo de dois dias, sendo o primeiro pensado para a\napresenta??o de comunica??es nacionais ou ib?ricas, com palestras\nconvidadas, finalizando com uma exposi??o de fotografia e um jantar\nconv?vio.\n\nJ? o segundo dia ser? votado para o contacto directo com a envolvente dos\nparques naturais, estando considerada a realiza??o de passeios de barco no\nDouro, no tro?o entre as barragens de Bemposta e Picote, passeios pedestres,\nvisitas ?s aldeias t?picas e a observa??o de aves a partir de locais\npreviamente assinalados.\n\n\nFormato:\nO ArribAves tem o formato de um evento cient?fico e promocional com\napresenta??o de comunica??es orais, mesas redondas e palestras convidadas.\nSer?o aceites apenas comunica??es completas e posters. Est? a ser estudada a\nhip?tese de publica??o das melhores comunica??es em livro ou brochura.\n\nTemas:\nDe todas as ?reas relacionadas com Estudo, Protec??o e Observa??o de Aves\n\n\nOrganiza??o Local:\nSolar dos Marcos\n\n\nDatas Importantes:\nEntrega das Propostas de Comunica??es ? 30 de Junho de 2003\nAviso de Aceita??o ? 10 de Julho de 2003\nEntrega da Vers?o Final ? 20 de Julho de 2003\nEncontro ? 25-26 de Julho de 2003\n\n\nReservas de Hotel:\nEnviar reservas para:\nSolar dos Marcos\nRua de Santa Cruz,\n5200-055 Bemposta\nTel: 279 570 010;\nFax: 279 570 019;\nE-mail: marcos.marcos@oninet.pt\n\n\nInforma??es e Inscri??es:\nSecretariado ArribAves 2003\nA/C M?rio Marcos, Solar dos Marcos, Rua de Santa Cruz,\n5200-055 Bemposta\nTel: 279 570 010;\nFax: 279 570 019;\nE-mail: marcos.marcos@oninet.pt\n\nhttp://arribaves2003.marcos-e-marcos.pt\n\n \n  \n\n\nSOLAR DOS MARCOS\nRua de Santa Cruz\n5200-055 Bemposta\nPORTUGAL\nTel: +351 279 570 010 \nFax: +351 279 570 019 \nEmail:   marcos.marcos@oninet.pt \nURL: www.marcos-e-marcos.pt\n\n\n\n"
        },
        {
            "subject": "Development of platform-independent applications - workshop more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "Test Bookmark Link",
            "content": "http://www.chrissysbedroom.com/\nhttp://www.blowjobphone.com/\nhttp://www.livephonedomination.com/\nhttp://www.phonefeminization.com/\nhttp://www.taboophonefetishes.com/\nhttp://your-account.info/\nhttp://www.phone-sex-guestbook.com/\nhttp://www.highclassblondes4phone.com/\nhttp://www.dominatingphonebitches.com/\nhttp://duvx.com/book.php?book=phonesex/\nhttp://www.xanga.com/usa_phone_sex/\nhttp://www.xanga.com/phone_sex_seeker/\nhttp://www.phone-sex-blog.blogspot.com/\nhttp://duvx.com/bbs.php?bbs=phone/\nhttp://www.voy.com/144830/\nhttp://www.voy.com/178346/\n\n\nhttp://www.angelfire.com/nv/Chess/chess.html\nhttp://www.angelfire.com/pop2/xslt/\nhttp://www.angelfire.com/grrl/edenprosper/\nhttp://www.angelfire.com/nv/violins/violin_bows.html\nhttp://www.angelfire.com/nv/bowling/tips.html\nhttp://www.angelfire.com/tv/julia/julia.louis.dreyfus.html\nhttp://www.geocities.com/gothic_clothes/\nhttp://www.geocities.com/bgreen68/\nhttp://www.megaone.com/supermodel/\nhttp://www.geocities.com/self_hypnosis/\nhttp://www.angelfire.com/goth/razorcandi/\nhttp://www.angelfire.com/nv/violins/violin_books.html\nhttp://www.angelfire.com/grrl/raye/\nhttp://www.angelfire.com/goth/gothic_babe/\nhttp://www.angelfire.com/nv/startpage/\nhttp://www.geocities.com/actress_model_olivia/\nhttp://www.geocities.com/somethings_happening/\nhttp://www.geocities.com/kimmyswebsite/\nhttp://www.geocities.com/monique_modeling/\nhttp://www.angelfire.com/pop2/google-dance-tool/\nhttp://www.angelfire.com/art2/blonde_model/\nhttp://www.angelfire.com/art2/catherine/\n\n\n\nhttp://bloggingtips.blogspot.com\nhttp://chinese-food.blogspot.com\nhttp://bowling-tips.blogspot.com\nhttp://www.xanga.com/ringtones\nhttp://xsl2.blogspot.com\nhttp://www.xanga.com/free_ringtones\nhttp://www.senac.com/forums/4055/\nhttp://www.senac.com/forums/12254/\nhttp://www.senac.com/forums/1310/\nhttp://www.senac.com/forums/5283/\nhttp://www.senac.com/forums/13432/\n\n\n\n"
        },
        {
            "subject": "Re: NonW3C Member Organizations Trying to join W3C Digital Signature   Initiativ",
            "content": "At 1:09 PM -0700 9/15/96, Sally Khudairi wrote:\n>To members of ietf-tls@w3.org:\n>\n>I have recently received numerous requests from non-W3C Member organizations\n>to join the W3C Digital Signature Initiative.\n>\n>Please note the following:\n>\n>a.  DSIG is _not_ open; it is closed to W3C Member organizations ONLY\n>\n>b.  There is, indeed, a mailing list and proposal out for votes to W3C\n>Members, closing on 15 September 1996.\n>\n>c.  For W3C Members [or if you've recently become a W3C Member], more\n>information can be found at:\n>\n>Proposal:\n> http://www.w3.org/pub/WWW/Security/DsigProj.html\n>\n>Voting Details -- accessible to W3C Members ONLY:\n>http://www.w3.org/pub/WWW/Member\n>\n>\n>\n>If your organization is interested in becoming a Member of W3C, please review\n>the information at http://www.w3.org/pub/WWW/Consortium/Prospectus/\n>\n>If you need any additional information, feel free to contact me at\n>khudairi@w3.org.\n\nI think that this is rather ridiculous -- Consensus Development Corporation\nis one of the most active companies in the web security and digital\nsignature field -- we wrote Sign-A-File for VeriSign, Inc., SSLRef 3.0 with\nNetscape Communications Corp., and CD-ROM signing for Apple's Pippin\ncomputer. We have the SSL Plus developer toolkit, write the SSL FAQ, and\nhave a forthcoming certificate toolkit.\n\nYet there is no way that we can justify $50K to join W3C! Even CI Labs (the\nOpenDoc Alliance), the SPA, and other associations have room for small\ncompanies like ours, and have often found companies like ours are the most\nvalued contributors, and thus have fees commiserate to our size.\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n.. Security Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "New Public mailing list - public-css-testsuite  maintained by Bert  Bo",
            "content": "Maintaing Activity:  Document Formats[1]\n\nPurpose:  This list is for coordinating the development of test suites for\nthe various CSS-related specifications. See CSS test suites[2] for more\ninformation. To post to this list, you must be subscribed. See the W3C\nMailing List Administrativia[3] for instructions.\n\n\nReference:  CSS test suites[2]\n\n\n1.  http://www.w3.org/DF/\n2.  http://www.w3.org/Style/CSS/Test/\n3.  http://www.w3.org/Mail/Request\n\n\n\n"
        },
        {
            "subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle",
            "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "CFP: IEEE/WIC/ACM Web Intelligence 200",
            "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepage: http://www.maebashi-it.org/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n           National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, and data/knowledge grids) on the\nnext generation of Web-empowered products, systems, services, and\nactivities. It is one of the most important as well as promising IT\nresearch fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\nWI Topics\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nMore detailed instructions and the On-Line Submission Form can be\nfound from the WI'04 homepage: http://www.maebashi-it.org/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper awards will be conferred on the authors of\nthe best papers at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyoung Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Re: NonW3C Member Organizations Trying to join W3C Digital Signature   Initiativ",
            "content": "While the W3C Digital Signature Initiative is a good topic for\ndiscussion, I think that the TLS list is probably not the right\nplace for it.\n\nThanks.\n\nWin Treese\n\n\n\n"
        },
        {
            "subject": "Used Formwork/Peri Dok",
            "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n"
        },
        {
            "subject": "CFP: IEEE/WIC/ACM Web Intelligence 200",
            "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepages: http://www.maebashi-it.org/WI04\n                       http://www.comp.hkbu.edu.hk/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n  Microsoft Research Asia\n                  National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, wisdom Web, and data/knowledge\ngrids) on the next generation of Web-empowered products, systems,\nservices, and activities. It is one of the most important as well as\npromising IT research fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\nFollowing the great successes of WI'01 held in Maebashi City, Japan\nand WI'03 held in Halifax, Canada, WI 2004 provides a leading\ninternational forum for researchers and practitioners (1) to present\nthe state-of-the-art of WI technologies; (2) to examine performance\ncharacteristics of various approaches in Web-based intelligent\ninformation technology; and (3) to cross-fertilize ideas on the\ndevelopment of Web-based intelligent information systems among\ndifferent domains.  By idea-sharing and discussions on the underlying\nfoundations and the enabling technologies of Web intelligence, WI 2004\nwill capture current important developments of new models, new\nmethodologies and new tools for building a variety of embodiments of\nWeb-based intelligent information systems.\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Service-Oriented Computing\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nAll paper submissions will be handled electronically.  More detailed\ninstructions and the On-Line Submission Form can be found from the\nWI'04 homepages: http://www.maebashi-it.org/WI04 and\nhttp://www.comp.hkbu.edu.hk/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper award and the best demo award will be conferred on the\nauthors of the best papers and the best demos at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-Chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyong Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n*******************************************************\nWI/IAT Conference Secretariat\nwi-iat@maebashi-it.org\n\nWI'04:  http://www.maebashi-it.org/WI04/\nIAT'04: http://www.maebashi-it.org/IAT04/\n??????????????????????????\n2003-12-26 17:59:49\n********************************************************\n\n\n\n"
        },
        {
            "subject": "&quot;Lel Bruce Peto&quot; recommends the following reading/oil interest..",
            "content": "\"Lel Bruce Peto\" recommends the following reading on interest related to \nthe oil sector:\nOil & Gas Chronology :  The 1970?s\n \n1970\nJan 1 \n\nU.S. Federal oil depletion allowance reduced from 27.5 to 22.0 percent.\n\nMay 3 \n\nTAP line from Saudi Arabia to the Mediterranean interrupted in Syria, \ncreating all-time tanker rate highs from June to December. \n\nSep 4 - Oct 9 \n\nLibya raises posted prices and increases tax rate from 50 percent to 55 \npercent. Iran and Kuwait follow in November.\n\nDec 9-12 \n\nOPEC meeting in Caracas establishes 55 percent as minimum tax rate and \ndemands that posted prices be changed to reflect changes in foreign \nexchange rates. \n\n1971\nJan 12 \n\nNegotiations begin in Tehran between 6 Gulf producing countries and 22 oil \ncompanies.\n\nFeb 3-4 \n\nOPEC mandates \"total embargo\" against any company that rejects the 55 \npercent tax rate.\n\nFeb 14 \n\nTehran agreement signed. Companies accept 55 percent tax rate, immediate \nincrease in posted prices, and further successive increases. \n\nFeb 24 \n\nAlgeria nationalizes 51 percent of French oil concessions. \n\nApr 2 \n\nLibya concludes five weeks of negotiations with Western oil companies in \nTripoli on behalf of itself, Saudi Arabia, Algeria and Iraq. Agreement \nraises posted prices of oil delivered to Mediterranean from $2.55 to $3.45 \nper barrel; provides for a 2.5 percent annual price increase plus inflation \nallowance; raises tax rate from a range of 50-58 percent to 60 percent of \nposted price.\n\nJul 31 \n\nVenezuela's Hydrocarbons Reversion Law mandates gradual transfer to \ngovernment ownership of all \"unexploited concession areas\" by 1974 and \"all \ntheir residual assets\" by 1983.\n\nAug 15 \n\nU.S. Government institutes Phase I price controls. Invoking the powers \ngranted to the president by the Economic Stabilization Act of 1970, \nPresident Nixon orders 90-day nationwide freeze on all wages, prices, \nsalaries and rents.\n\nSep 22 \n\nOPEC directs members to negotiate price increases to offset the devaluation \nof the U.S. dollar.\n\nNov \n\nU.S. Phase II price controls begin. Plan is to allow for gradual 2-3 \npercent annual price increases, however, domestic petroleum prices remain \nat Phase I levels.\n\nDec 5 \n\nLibya nationalizes British Petroleum concession. \n\n\n\n"
        },
        {
            "subject": "Is this the right list for this",
            "content": "Hi,\nThis was the only css related list I saw. Pardon me if I miss the proper \nlist. I have a suggestion for an addition to the Height and Width \nproperties as it applies to the box model. I was wondering where I should \nsend this suggestion. For those burning with desire to know what it is, I \nwould like to see the following.\n\nBasically put: Height: 100% - Xpx;\n\nThis may seem strange, but it would be useful to be able to set the height \nof a box where you want it to be some X amount less than the viewport, no \nmatter what size the viewport is, or on resize.\n\nThanks\n\n\n\n"
        },
        {
            "subject": "Re: Is this the right list for this",
            "content": "On Wed, 26 Feb 2003, Noel Akins wrote:\n>\n> This was the only css related list I saw. Pardon me if I miss the proper\n> list.\n\nYou want www-style@w3.org.\n\n-- \nIan Hickson                                      )\\._.,--....,'``.    fL\n\"meow\"                                          /,   _.. \\   _\\  ;`._ ,.\nhttp://index.hixie.ch/                         `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "mailing list addition",
            "content": "I/We at the Labs have found your e-mails that have come\nto me most interesting. I do not remember what page I\nfound the submission to this list on, but would like to\nknow if you could add \n\ncarlo@labs.emea.att.com \n\nto the list. He is the person most likely to\n1) benefit and 2) contribute to the list.\n\nThank you\nChristopher\n-- \n--------------------------------------------------\nAT&T Laboratories        PHONE:  (+33) 1 4767 4632\nTour Horizon             FAX:    (+33) 1 4767 4670\n52 Quai de Dion Bouton   MOBILE: (+33) 09 91 76 27\n92806 Puteaux, France\n--------------------------------------------------\n         e-mail: chris@labs.emea.att.com\n       http://www.labs.emea.att.com/~chris/  \n--------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "near term spot gasoline, &quot;Lel Bruce Peto&quot; updates, supplies in..",
            "content": "near term spot gasoline, \"Lel Bruce Peto\" updates, supplies in New York \nHarbor and Chicago has vaulted spot prices to mid-summer-like levels over \nthe last 5-business days, and the outlook is for higher prices to be \naround at least until mid-month in both regions. Reformulated premium in \nNew York Harbor traded at $1.035 gal , a 26cts gal premium to December \nprint. First cycle November conventional no lead in Chicago is pressing \nthe dollar/gal mark having closed up 1.75cts at 97cts gal..as of\n11-05-02... \n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "VERY URGEN",
            "content": "We are one of the most prestigious football club in Nigeria.There are numerous contributors of BKA, F.C which is the name of the club, This are major contributors which are President, Chairman, Administrators of our club and our host community Our aims and objective are basically on training and developing the talented players in different areas. We could actualized our dreams through given the players proper training by sending our coaching crew to your company for adequate fundamental soccer training. Which we believed the soccer seminar or coaching clinic, will last for a month. Between 5th of April to 30th .We believed we are capable to meet your demands. The names of our 6 coaching crew are as following,\n1. MR. BODE OGUNNIYI\n2. MR. KOLAWOLE OYEWOLE\n3. MR. SHOBUKANLA JOEL\n4. MR. ADEOLA KAREEM\n5. MR. DAPO FAGBAMIGBE\n6. MR TOPE OLAIYA\nThat our coaching management will be responssible for all financial commitment of the journey such as traveling, feeding, accomodation and all other incidental expenses associted with their traveling. We shall be looking forward to your co-operation by granting us this concession with approval by sending email to us, for our crew invitation to facilitate the nominees traveling as scheduled. We look forward to receiving your company changings for the nominee accounmodation and feeding for advance booking before their arrival. On the receipt of the bill and invitation letter we shall remit part payment of the bill through your bank. Please state your banking details on your reply to us to effect the remiting accordignly. \nLooking forward to an anticipated co-operation. \n\nYours Faithfully, \n\nFOR: BALLARKECIABUF.C\n\n\n\n"
        },
        {
            "subject": "Testin",
            "content": "This is another test.\n\n\n\n===============================\nhttp://www.porn-2u.com\nhttp://www.pussy-tv.org\n\n\n\n"
        },
        {
            "subject": "Updates to SSH protoco",
            "content": "A couple of weeks ago, Martin Abadi pointed out problems with the\npublished SSH transport layer protocol draft.\n\nThese problems should now be fixed, and there are a few other changes.\nThe basic change is in how the session identifier is calculated and\nhow the key exchange is in authenticated.\n\nAdditionally, a new naming scheme has been introduced for\ncryptographic algorithms.  It appears that a number of (mostly\nmilitary or other government) organizations would like to use their\nown, unpublished algorithms.  Many people would also like to\nexperiment with new algorithms without going through a central\nregistry of algorithm identifiers.  SSH now represents all algorithms\nwith NAMES.  Standard algorithms have names such as \"3des-cbc\" or\n\"hmac-sha\".  Additionally, anyone can define their own algorithms by\nusing the syntax name@domainname, such as \"our-own-cipher@ssh.fi\".\nThis allows different implementations to negotiate whatever algorithms\nthey like, including extensions, without worrying about conflicting\nextensions by someone else.\n\nI'll include below the up to date SSH 2.0 transport and user\nauthentication protocol specs.\n\n    Tatu\n\n----- cut here for transport.txt ------\nNetwork Working Group                           Tatu Ylonen <ylo@ssh.fi>\nINTERNET-DRAFT                               SSH Communications Security\ntransport.txt                                          September 6, 1996\nExpires: January 1st, 1997\n\n\n                      SSH Transport Layer Protocol\n\nStatus of This memo\n\nThis document is an Internet-Draft. Internet-Drafts are working\ndocuments of the Internet Engineering Task Force (IETF), its areas,\nand its working groups. Note that other groups may also distribute\nworking documents as Internet-Drafts.\n\nInternet-Drafts are draft documents valid for a maximum of six\nmonths and may be updated, replaced, or obsoleted by other documents\nat any time. It is inappropriate to use Internet-Drafts as reference\nmaterial or to cite them other than as ``work in progress.''\n\nTo learn the current status of any Internet-Draft, please check\nthe ``1id-abstracts.txt'' listing contained in the Internet-Drafts\nShadow Directories on ftp.is.co.za (Africa), nic.nordu.net (Europe),\nmunnari.oz.au (Pacific Rim), ds.internic.net (US East Coast),\nor ftp.isi.edu (US West Coast).\n\nAbstract\n\nThis document describes the SSH transport layer protocol.  The protocol\ncan be used as a basis for a number of secure network services.  It pro-\nvides strong encryption, server authentication, and integrity protec-\ntion.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 1]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nTable of Contents\n\n1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . .  2\n2.  Data Type Representations Used in the Protocol  . . . . . . . . .  3\n  2.1.  vlint32   . . . . . . . . . . . . . . . . . . . . . . . . . .  3\n  2.2.  string  . . . . . . . . . . . . . . . . . . . . . . . . . . .  3\n  2.3.  boolean   . . . . . . . . . . . . . . . . . . . . . . . . . .  3\n  2.4.  byte  . . . . . . . . . . . . . . . . . . . . . . . . . . . .  3\n  2.5.  uint16  . . . . . . . . . . . . . . . . . . . . . . . . . . .  4\n  2.6.  uint32  . . . . . . . . . . . . . . . . . . . . . . . . . . .  4\n3.  Algorithm Naming  . . . . . . . . . . . . . . . . . . . . . . . .  4\n4.  Connection Setup  . . . . . . . . . . . . . . . . . . . . . . . .  4\n  4.1.  Use over TCP/IP   . . . . . . . . . . . . . . . . . . . . . .  4\n  4.2.  Protocol Version Exchange   . . . . . . . . . . . . . . . . .  5\n  4.3.  Compatibility with Old SSH Versions   . . . . . . . . . . . .  5\n    4.3.1.  Old Client, New Server  . . . . . . . . . . . . . . . . .  5\n    4.3.2.  New Client, Old Server  . . . . . . . . . . . . . . . . .  5\n5.  Binary Packet Protocol  . . . . . . . . . . . . . . . . . . . . .  5\n  5.1.  Maximum Packet Length   . . . . . . . . . . . . . . . . . . .  6\n  5.2.  Compression   . . . . . . . . . . . . . . . . . . . . . . . .  6\n  5.3.  Encryption  . . . . . . . . . . . . . . . . . . . . . . . . .  7\n  5.4.  Data Integrity  . . . . . . . . . . . . . . . . . . . . . . .  8\n6.  Key Exchange  . . . . . . . . . . . . . . . . . . . . . . . . . .  9\n  6.1.  Algorithm Negotiation   . . . . . . . . . . . . . . . . . . .  9\n  6.2.  Double-Encrypting Key Exchange  . . . . . . . . . . . . . . . 12\n    6.2.1.  Server Sends Host Key   . . . . . . . . . . . . . . . . . 12\n    6.2.2.  Deriving Session Identifier   . . . . . . . . . . . . . . 13\n    6.2.3.  Client Sends Double-Encrypted Session Key   . . . . . . . 13\n    6.2.4.  Deriving Encryption and Integrity Keys  . . . . . . . . . 14\n  6.3.  Taking Keys into Use  . . . . . . . . . . . . . . . . . . . . 14\n7.  Key Re-Exchange   . . . . . . . . . . . . . . . . . . . . . . . . 15\n8.  Service Request   . . . . . . . . . . . . . . . . . . . . . . . . 15\n9.  Stream-Based Services   . . . . . . . . . . . . . . . . . . . . . 16\n10.  Additional Messages  . . . . . . . . . . . . . . . . . . . . . . 16\n  10.1.  Disconnection Message  . . . . . . . . . . . . . . . . . . . 17\n  10.2.  Ignored Data Message   . . . . . . . . . . . . . . . . . . . 17\n  10.3.  Reserved Messages  . . . . . . . . . . . . . . . . . . . . . 17\n11.  Summary of Message Numbers   . . . . . . . . . . . . . . . . . . 17\n12.  Public Keys and Public Key Infrastructure  . . . . . . . . . . . 18\n  12.1.  ssh-simple-rsa   . . . . . . . . . . . . . . . . . . . . . . 18\n\n\n\n1.  Introduction\n\nThe SSH protocol is a secure transport layer protocol.  It provides\nstrong encryption, cryptographic host autentication, and integrity\nprotection.\n\nAuthentication in this protocol level is host-based; this protocol does\nnot perform user authentication.  It is expected that a higher level\nprotocol will be defined on top of this protocol that will perform user\nauthentication for those services that need it.\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 2]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nThe protocol has been designed to be simple, flexible, allow parameter\nnegotiation, and minimize the number of round-trips.  Key exchange\nmethod, public key algorithm, symmetric encryption algorithm, message\nauthentication algorithm, and hash algorithm are all negotiated.  It is\nexpected that in most environments, only 1.5 round-trips will be needed\nfor full key exchange, server authentication, service request, and\nacceptance notification of service request.  The worst case is 2.5\nround-trips.\n\n2.  Data Type Representations Used in the Protocol\n\n2.1.  vlint32\n\nThe vlint32 can represent arbitrary 32-bit unsigned integers.  It is\nstored as a variable number of bytes (1-5 bytes), depending on the value\nbeing stored.\n\nBits 6-7 of the first byte (the most significant bits) determine the\nnumber of additional bytes that follow, and are interpreted as follows.\n\n  Bit7  Bit6    Number of bytes that follow\n   0     0       0\n   0     1       1\n   1     0       2\n   1     1       4\n\nBits 0-5 of the first byte and the following bytes contain the value of\nthe integer, MSB first.\n\nIf bits 6-7 are both one, the remaining bits in the first byte are zero\n(reserved for future extension).\n\n2.2.  string\n\nA string here means an arbitrary length binary string.  Strings are\nallowed to contain arbitrary binary data, including null characters and\n8-bit characters.\n\nA string is represented as a vlint32 containing its length, followed by\nzero or more characters that are the value of the string.  No\nterminating null character is normally included in the string.\n\n2.3.  boolean\n\nA boolean value is represented as a single byte.  The value 0 represents\nfalse, and the value 1 represents true.  All non-zero values are\ninterpreted as true, but applications should not store values other than\n0 and 1.\n\n2.4.  byte\n\nA byte represents an arbitrary 8-bit value.  Fixed length data is\nsometimes represented as an array of bytes, written byte[n], where n is\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 3]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nthe number of bytes in the array.\n\n2.5.  uint16\n\nA 16-bit unsigned integer, represented as two bytes, MSB first.\n\n2.6.  uint32\n\nA 32-bit unsigned integer, represented as four bytes, MSB first.\n\n3.  Algorithm Naming\n\nThis protocol refers to particular hash, encryption, integrity,\ncompression, and key exchange algorithms in various places.  There are\nsome standard algorithms that all implementations are required to\nsupport.  There are also algorithms that are defined in the protocol\nspecification but are optional.  Furthermore, it is expected that some\norganizations will want to use their own algorithms whenever possible.\nThis leads to the problem of how algorithm identifiers are allocated.\n\nIn this protocols, all algorithm identifiers are represented as strings.\nNames are case-sensitive.  Algorithm lists are comma-separated lists of\nthese identifiers, without spaces.  There are two formats for algorithm\nidentifiers:\n\no  Algorithms defined in the base protocol are simple strings, such as\n   \"3des-cbc\", \"sha-1\", \"hmac-sha\", or \"zip\" (the quotes are not part of\n   the name).  Defined algorithms may be mandatory or optional.  All\n   interoperable implementations should implement mandatory algorithms\n   and offer them as a possibility in key exchanges.  Optional\n   algorithms are not crucial for interoperability, but may provide\n   better performance or other advantages.  It is up to an\n   implementation to decide which of these are supported and which are\n   offered in key exchanges by default.\n\no  Anyone can define additional algorithms by using names in the format\n   name@domainname, e.g. \"ourcipher-cbc@ssh.fi\".  The format of the part\n   preceding the at sign is not specified; it may contain any non-\n   control characters except at signs and commas.  The part following\n   the at sign should be a valid internet domain name for the\n   organization defining the name.  It is up to the each organization\n   how they manage its locally defined names.\n\n4.  Connection Setup\n\nSSH works over any 8-bit clean, binary-transparent transport.  The\nclient initiates the connection, and sets up the binary-transparent\ntransport.\n\n4.1.  Use over TCP/IP\n\nWhen used over TCP/IP, the server normally listens for connections on\nport 22.  This port number has been registered with the IANA (Internet\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 4]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nAssigned Numbers Authority), and has been officially assigned for SSH.\n\n4.2.  Protocol Version Exchange\n\nWhen the connection has been established, both sides send an\nidentification string of the form \"SSH-protoversion-softwareversion\ncomments\", followed by a newline.  No null character is sent.  The\nmaximum length of the string is 255 characters, including the newline.\nThe protocol version described in this document is 2.0.  Version strings\nshould only contain printable characters, not including space or '-'.\nThe string is used in debugging outputs to ease debugging; the protocol\nversion is also used to trigger compatible extensions.  It is\nrecommended that the strings be as descriptive as possible.  The comment\nstring could include information such as the platform type which might\nbe useful in solving user problems.\n\nKey exchange will begin immediately after sending this identifier\n(normally without waiting for the identifier from the other side -- see\nthe next section for compatibility issues).  All packets following the\nidentification string will use the binary packet protocol, to be\ndescribed below.\n\n4.3.  Compatibility with Old SSH Versions\n\nDuring a transition period, it is important to be able to work\ncompatibly with installed SSH clients and servers using an older version\nof the protocol.  Information in this section is only relevant for\nimplementations supporting compatibility with old versions.\n\n4.3.1.  Old Client, New Server\n\nServer implementations should support a configurable \"compatibility\"\nflag that enables compatibility with old versions.  When this flag is\non, the server will not send any further data after its initialization\nstring until it has received an identification string from the client.\nThe server can then determine whether the client is using an old\nprotocol, and can revert to the old protocol if desired.\n\nWhen compatibility with old clients is not needed, the server should\nsend its initial key exchange data immediately after the identification\nstring.  This saves a round-trip.\n\n4.3.2.  New Client, Old Server\n\nSince the new client will immediately send additional data after its\nidentification string (before receiving server's identification), the\nold protocol has already been corrupted when the client learns that the\nserver is old.  When this happens, the client should close the\nconnection to the server, and reconnect using the old protocol this\ntime.\n\n5.  Binary Packet Protocol\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 5]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nEach packet consists of the following fields:\n\n    Length\n      The length of the packet (bytes).  This represents the number of\n      bytes that follow this value, not including the optional MAC.  The\n      length is represented as a vlint32.\n\n    Padding length\n      Length of padding (bytes).  This field is represented as a\n      vlint32.\n\n    Payload\n      The useful contents of the packet.  This field is optionally\n      compressed.\n\n    Padding\n      Arbitrary-length padding, such that the total length of\n      length+paddinglength+payload+padding is a multiple of the cipher\n      block size or 8, whichever is larger.  It is recommended that at\n      least four bytes of random padding be always used.\n\n    MAC\n      Message authentication code.  This field is optional, and its\n      length depends on the algorithm in use.\n\nNote that length of the concatenation of packet length, padding length,\npayload, and padding must be a multiple of the cipher block size or 8,\nwhichever is larger.  This constraint is enforced even when using stream\nciphers.  Note that the packet length field is also encrypted, and\nprocessing it requires special care when sending/receiving packets.  In\nparticular, one has to be extra careful when computing the amount of\npadding, as changing the amount of padding can also change the size of\nthe length fields.  The minimum size of a packet is 8 (or cipher block\nsize, whichever is larger) characters (plus MAC); implementations should\ndecrypt the length after receiving the first 8 (or cipher block size,\nwhichever is larger) bytes of a packet.\n\nWhen the protocol starts, no encryption is in effect, no compression is\nused, and no MAC is in use.  During key exchange, an encryption method,\ncompression method, and a MAC method are selected.  Any further messages\nwill use the negotiated algorithms.\n\n5.1.  Maximum Packet Length\n\nThe maximum length of the uncompressed payload is 32768 bytes.  The\nmaximum size of the entire packet, including length, padding length,\npayload, padding, and MAC, is 35000 bytes.  The motivation for this\nlimit is to keep the protocol easy to implement on 16-bit machines.\n\n5.2.  Compression\n\nIf compression has been negotiated, the payload field (and only it) will\nbe compressed using the negotiated algorithm.  The length field will\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 6]\n\nINTERNET-DRAFT                                         September 6, 1996\n \ncontain the compressed length (i.e., that transmitted on the wire).\n\nCompressed packets must not exceed the total packet size limit; the\ncompression algorithm must guarantee that it does not expand the packet\ntoo much.  The uncompressed payload size must not exceed the maximum\npayload size (the compressed payload, however, may be bigger than the\nmaximum payload size, as long as the packet size limit is not exceeded).\n\nThe following compression methods are currently defined:\n\n          none     mandatory       no compression\n          zlib     optional        GNU ZLIB compression at level 6\n\nThe \"zlib\" compression is described in RFC1950.\n\nThe compression context is initialized after key exchange, and is passed\nfrom one packet to the next with only a partial flush being performed at\nthe end of each packet.  A partial flush means that all data will be\noutput, but the next packet will continue using compression tables from\nthe end of the previous packet.\n\nCompression is independent in each direction, and the different\ncompression methods may be used for each direction.\n\n5.3.  Encryption\n\nAn encryption algorithm and a key will be negotiated during the key\nexchange.  When encryption is in effect, the length, padding length,\npayload and padding fields of each packet will be encrypted with the\ngiven algorithm.\n\nThe encrypted data in all packets sent in one direction will be\nconsidered a single data stream.  For example, initialization vectors\nwill be passed from the end of one packet to the beginning of the next\npacket.\n\nThe ciphers in each direction will run independently of each other.\nThey will typically use a different key, and different ciphers can be\nused in each direction.\n\nThe following ciphers are currently supported:\n\n          none             optional          no encryption\n          3des-cbc         mandatory         three-key 3DES in CBC mode\n          idea-cbc         optional          IDEA in CBC mode\n          arcfour          optional          ARCFOUR stream cipher\n          blowfish-cbc     optional          Blowfish in CBC mode\n\nThe 3des-cbc encryption is three-key triple-DES (encrypt-decrypt-\nencrypt), where the first 8 bytes of the key are used for the first\nencryption, the next 8 bytes for the decryption, and the following 8\nbytes for the final encryption.  This requires 24 bytes of key data (of\nwhich the parity bits are not actually used).  To implement CBC mode,\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 7]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nthere is only one initialization vector.\n\nThe ARCFOUR cipher is compatible with the RC4 cipher; RC4 is a trademark\nof RSA Data Security, Inc.\n\nDescriptions of all of these ciphers can be found e.g. from Bruce\nSchneier: Applied Cryptography, 2nd ed., John Wiley and Sons, 1996.\n\n5.4.  Data Integrity\n\nData integrity is protected by including with each packet a message\nauthentication code (MAC) that is computed from a shared secret, packet\nsequence number, and the contents of the packet.\n\nThe message authentication algorithm and key are negotiated during key\nexchange.  Initially, no MAC will be in effect, and its length will be\nzero.  After key exchange, the selected MAC will be computed before\nencryption from the concatenation of packet data (lengths, payload, and\npadding) and a packet sequence number (stored as a 32-bit integer, MSB\nfirst).  The integrity key is also used in the computation of the MAC,\nbut the way it is used depends on the MAC algorithm in use.  Note that\nthe MAC algorithm may be different for each direction.\n\nThe packet sequence number is only used for integrity checking.  It is\nnever explicitly transmitted, but it is included in MAC computation to\nensure that no packets are lost or received out of sequence.  The\nsequence number of the first packet sent is zero; from there on the\nsequence number is incremented by one for every packet sent (separately\nfor each direction).  The packet number is 32 bits and wraps around if\n32 bits is not enough for representing it.  The sequence number is\nincremented also for packets that are not encrypted or MACed, and is not\nreset even if keys are renegotiated later.\n\nThe check bytes resulting from the MAC algorithm are transmitted without\nencryption as the last part of the packet.  The number of check bytes\ndepends on the algorithm chosen.\n\nThe following MAC algorithms are currently defined:\n\n          none        optional         no MAC\n          hmac-md5    optional         HMAC-MD5 (length = 16)\n          hmac-sha    optional         HMAC-SHA (length = 20)\n          md5-8       optional         first 8 bytes MD5 key+data+key\n          sha-8       optional         first 8 bytes SHA key+data+key\n          sha         mandatory        SHA of key+data+key (20 bytes)\n\nThe HMAC methods are described in draft-ietf-ipsec-hmac-md5-00.txt.  XXX\nchange to refer to an RFC when one becomes available.\n\nThe \"md5-8\" method returns the first 8 bytes of MD5 of the concatenation\nof the key, authenticated data, and the key again.  The \"sha-8\" method\nis the same but using the SHA hash.\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 8]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nEven though only the \"md5\" method is mandatory, it is recommended that\nimplementations support and prefer the other methods.  (This method\nexists only as a fallback should unexpected patent problems surface.)\n\n6.  Key Exchange\n\nKey exchange begins by each side sending lists of supported algorithms.\nEach side has a preferred algorithm, and it is assumed that most\nimplementations at any given time will use the same preferred algorithm.\nEach side will make the guess that the other side is using the same\nalgorithm, and may send an initial key exchange packet according to the\nalgorithm if appropriate for the preferred method.  If the guess is\nwrong, they'll ignore the guessed packet, select a common algorithm, and\nsend the initial key exchange packet again, this time for the same\nalgorithm.\n\nCurrently, the following key exchange methods have been defined:\n\n          double-encrypting-sha        mandatory\n\nThe implementation of these methods is described later in this section.\n\nOne should note that server authentication in the double-encrypting key\nexchange is implicit, and the client doesn't really know the identity of\nthe server until it receives a message from the server using the correct\nMAC and encryption.  This means that an attacker could fool the client\ninto using no encryption (if the client is willing to accept no\nencryption), and the client might in some cases send sensitive data,\nsuch as a password, before it notices that the server isn't responding\nproperly.  For this reason, it is recommended that clients should not\naccept \"none\" encryption unless explicitly requested by the user.\nAlternatively, they should wait for the server's response to the service\nrequest before sending anything else.\n\n6.1.  Algorithm Negotiation\n\nEach side sends the following packet (this is the part that goes inside\nthe payload):\n\n            vlint32   SSH_MSG_KEXINIT\n            byte[16]  cookie (random bytes)\n            string    kex_algorithms\n            string    server_host_key_algorithms\n            string    encryption_algorithms_client_to_server\n            string    encryption_algorithms_server_to_client\n            string    mac_algorithms_client_to_server\n            string    mac_algorithms_server_to_client\n            string    compression_algorithms_client_to_server\n            string    compression_algorithms_server_to_client\n            string    hash_algorithms\n            boolean   first_kex_packet_follows\n            byte[4]   0 (reserved for future extension)\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 9]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nEach of the algorithms strings are comma-separated lists of algorithm\nnames.  Each supported (allowed) algorithm should be listed, in order of\npreference.  The preferred (guessed) algorithm should be listed first.\nEach string must contain at least one algorithm name.  The value \"none\"\nis not automatically allowed; if a party permits connections with \"none\"\nas one of the algorithms, it should list that as an algorithm.\n\n    cookie\n      The cookies are random values generated by each side.  They are\n      used when deriving keys from the shared secret.  Their purpose is\n      to make it impossible for either side to fully determine the keys\n      (which might open possibilities for passing certain\n      signatures/authentications to third parties).\n\n    kex_algorithms\n      Key exchange algorithms were defined above.  The first algorithm\n      is the preferred (and guessed) algorithm.  If both sides make the\n      same guess, that algorithm is used.  Otherwise, the following\n      algorithm is used to choose a key exchange method: iterate over\n      client's kex algorithms, one at a time.  Choose the first\n      algorithm that satisfies the following conditions: 1) the server\n      also supports the algorithm 2) if the algorithm requires an\n      encryption-capable host key, there is an encryption-capable\n      algorithm on the server's  server_host_key_algorithms  that is\n      also supported by the client 3) if the algorithm requires a\n      signature-capable host key, there is a signature-capable algorithm\n      on the server's  server_host_key_algorithms  that is also\n      supported by the client.  If no algorithm satisfying all these\n      conditions can be found, connection fails.\n\n      The kex algorithm names were listed above.\n\n    server_host_key_algorithms\n      Lists the algorithms supported for the server host key.  The\n      server lists the algorithms for which it has host keys; the client\n      lists the algorithms that it is willing to accept.  (There can be\n      multiple host keys for a host, possibly with different\n      algorithms.)\n\n      Some host keys may not support both signatures and encryption\n      (this can be determined from the algorithm), and thus not all host\n      keys are valid for all key exchange methods.\n\n      Algorithm selection depends on whether the chosen kex algorithm\n      requires a signature- or encryption capable host key.  The first\n      algorithm on the client's list that satisfies the requirements and\n      is also supported by the server is chosen.\n\n      Section ``Public Key Formats'' lists the available algorithm\n      names.\n\n    encryption_algorithms\n      Lists the acceptable symmetric encryption algorithms in order of\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 10]\n\nINTERNET-DRAFT                                         September 6, 1996\n \n      preference.  The chosen encryption algorithm will be the first\n      algorithm on the client's list that is also on the server's list.\n      If there is no such algorithm, connection fails.\n\n      Note that \"none\" must be explicitly listed if it is to be\n      acceptable.  The defined algorithm names are listed in Section\n      ``Encryption''.\n\n      The algorithm to use is negotiated separately for each direction,\n      and different algorithms may be chosen.\n\n    mac_algorithms\n      Lists the acceptable MAC algorithms in order of preference.  The\n      chosen MAC algorithm will be the first algorithm on the client's\n      list that is also on the server's list.  If there is no such\n      algorithm, connection fails.\n\n      Note that \"none\" must be explicitly listed if it is to be\n      acceptable.  The MAC algorithm names are listed in Section ``Data\n      Integrity''.\n\n      The algorithm to use is negotiated separately for each direction,\n      and different algorithms may be chosen.\n\n    compression_algorithms\n      Lists the acceptable compression algorithms in order of\n      preference.  The chosen compression algorithm will be the first\n      algorithm on the client's list that is also on the server's list.\n      If there is no such algorithm, connection fails.\n\n      Note that \"none\" must be explicitly listed if it is to be\n      acceptable.  The compression algorithm names are listed in Section\n      ``Compression''.\n\n      The algorithm to use is negotiated separately for each direction,\n      and different algorithms may be chosen.\n\n    hash_algorithms\n      Lists the acceptable hash algorithms in order of preference.  The\n      chosen hash algorithm will be the first algorithm on the client's\n      list that is also on the server's list.  If there is no such\n      algorithm, connection fails.\n\n      Implementations should only permit algorithms that they consider\n      to be fairly secure, as the hash function will be used e.g. for\n      deriving various keys from the shared secret.  All hash algorithms\n      must produce at least 16 bytes of output.\n\n      Currently, the following hash functions are defined.\n\n             md5          optional      MD5 algorithm (16 byte output)\n             sha-1        mandatory     SHA-1 algorithm (20 byte output)\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 11]\n\nINTERNET-DRAFT                                         September 6, 1996\n \n    first_kex_packet_follows\n      Each side makes a guess of the negotiated key exchange method.\n      This is based on the assumption that at any particular time there\n      will be a single key exchange method and algorithm combination\n      that dominates the installed base.  Making a guess about the\n      algorithm will save a round-trip in the typical case, and will\n      incur little extra cost in the other cases.\n\n      Each side will determine if they are supposed to send an initial\n      packet in their guessed key exchange method.  If they are, they\n      will set this field to true and follow this packet by the first\n      key exchange packet.\n\n      The guessed method is the one listed first on the kex_algorithms,\n      server_host_key_algorithms, and hash_algorithms lists.  If the\n      negotiated values for any of these algorithms differs from the\n      first value on either side, the guess is taken to be wrong, and\n      the packet sent based on the guess is ignored.  Whether the\n      packets based on the guess are actually wrong is not a factor in\n      this decision (the information may not be available to make this\n      decision).\n\n      After receiving the SSH_MSG_KEXINIT packet from the other side,\n      each party will know whether their guess was right.  If the guess\n      was wrong, and this field is true, the next packet will be\n      silently ignored, and each side will then act as determined by the\n      negotiated key exchange method.  If the guess was right, key\n      exchange will immediately continue.\n\n6.2.  Double-Encrypting Key Exchange\n\nThe double-encrypting key exchange requires that the server host key\nsupports encryption.  The idea is that the server sends its public host\nkey and a periodically changing key (called the server key).  The client\nthen verifies that it is the correct key for the server, generates a\nsession key, encrypts the session key using both the server host key and\nthe server key, and sends the encrypted session key to the server.\n\nThe server key and host keys must both support encryption, and their\nsizes must be compatible in such a way that the result of encrypting a\nvalue with one of them can be encrypted with the other.  The smaller of\nthe keys must be able to encrypt at least 48 bytes.  Both keys must use\nthe same public key algorithm.\n\n6.2.1.  Server Sends Host Key\n\nFirst, the server sends its public host and server keys in the following\npacket:\n\n            vlint32   SSH_MSG_KEXRSA_HOSTKEY\n            string    public host key\n            string    public server key\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 12]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nThe host key and server key are stored in binary representation as\ndescribed in Section ``Public Key Formats''.  Both keys are of the type\nnegotiated for the server host key.\n\nAfter receiving the public keys, the client validates that the host key\nreally belongs to the intended server.  How this verification happens is\nnot specified in this protocol.  Currently it may be checked against a\ndatabase of known name-key mappings; in future it will be validated\nusing an Internet public key infrastructure.  The key may contain\ncertificates to facilitate this.\n\nIf the client is not willing to trust the server host key, it should\nsend an SSH_MSG_DISCONNECT packet and close the connection.\n\nThe client then generates a 256 bit random session key.\n\n6.2.2.  Deriving Session Identifier\n\nTo authenticate that no-one has been manipulating the key exchange with\nthe server, the client computes an SHA-1 hash of the concatenated\npayloads of (in this order) the client's SSH_MSG_KEXINIT, the server's\nSSH_MSG_KEXINIT, the server's SSH_MSG_KEXRSA_HOSTKEY message, and the 32\nbytes of the session key.  This value is called the  session identifier,\nand it is used to authenticate the key exchange.\n\nNote that the use of SHA-1 was hard-coded here.  This is used to\nauthenticate the key exchange, and using HASH here would lead to all\nsorts of potential problems in verifying the security of the protocol.\nUsing a fixed hash short-circuits verification to the properties of\nSHA-1.  Should the need ever arise, the only way to switch to another\nalgorithm here is to define a new key exchange algorithm (which, in\nfact, is not very difficult).\n\nThe session identifier is also used in host authentication and other\nauthentication methods as data that is signed to prove possession of a\nprivate key.\n\nThe session identifier is computed only once; it is not changed or\nrecomputed if keys are later re-exchanged.\n\n6.2.3.  Client Sends Double-Encrypted Session Key\n\nThe client forms a message to send to the server by concatenating the\nfollowing (in this order): six zero bytes (reserved for future\nextension), first 10 bytes of the session identifier, and the 32 bytes\nof the shared secret.  This results in a total of 48 bytes of data to be\npassed to the server.  Note that the negotiated algorithms are not\nexplicitly passed, as the algorithms given in Section ``Algorithm\nNegotiation'' fully determine the algorithms.\n\nThe resulting data is encrypted with the smaller of host key and server\nkey, and the result then with the larger of them.  The resulting double-\nencrypted session key is then sent to the server.  Note that public-key\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 13]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nencryption probably involves padding, depending on the algorithm.\n\n            vlint32   SSH_MSG_KEXRSA_SESSIONKEY\n            string    double-encrypted session key\n\nUpon receiving this message, the server uses its private host and server\nkeys to decrypt the session key.  It computes a corresponding SHA hash,\nand compares the hash values.  If the hash does not match, the server\ndisconnects with the appropriate message.  If the hash matches, the\nserver responds with an SSH_MSG_NEWKEYS message and takes the keys into\nuse.\n\n6.2.4.  Deriving Encryption and Integrity Keys\n\nAs a result of the key exchange, the parties have a 256-bit shared\nsecret.  Various keys are computed from this secret and the session\nidentifier.  The session identifier is used to make it impossible for\neither party to alone determine the keys.\n\nEach key is computed as HASH of the concatenation of session identifier\nand 16 bytes of secret data.  The secret data is different for each key,\nand is taken from the 32-byte shared secret as follows:\n\no  Initial IV client to server: bytes 0-15\n\no  Initial IV server to client: bytes 1-16\n\no  Encryption key client to server: bytes 5-20\n\no  Encryption key server to client: bytes 8-23\n\no  Integrity key client to server: bytes 13-28\n\no  Integrity key server to client: bytes 16-31\n\nEach key is at least 16 bytes (128 bits).  For some algorithms, only\npart of this amount is actually used.  If a longer key is needed for\nsome algorithm, the key is extended by computing HASH of the entire key\nso far, and appending the resulting bytes (as many as HASH outputs) to\nthe key.  This process is repeated until enough key material is\navailable.\n\n6.3.  Taking Keys into Use\n\nKey exchange ends by each side sending an SSH_MSG_NEWKEYS message.  This\nmessage is sent with the old keys and algorithms.  All messages sent\nafter this message use the new keys and algorithms.\n\nWhen this message is received, the new keys and algorithms are taken\ninto use for receiving.\n\nThis message is the only valid message after key exchange, in addition\nto SSH_MSG_DISCONNECT and SSH_MSG_IGNORE messages.  The purpose of this\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 14]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nmessage is to ensure that a party is able to respond with a disconnect\nmessage that the other party can understand if something goes wrong with\nthe key exchange.\n\n            vlint32   SSH_MSG_NEWKEYS\n\n7.  Key Re-Exchange\n\nEither side may request re-exchange of keys at any time after the\ninitial exchange (and outside other key exchanges).  The re-exchange is\nnot visible to the service.\n\nKey re-exchange is started by sending a SSH_MSG_KEXINIT packet\n(described in Section ``Algorithm Negotiation'').  When this message is\nreceived, a party must respond with its own SSH_MSG_KEXINIT message.\nEither party may initiate the re-exchange, but roles are not changed\n(i.e., the server remains the server, and the client remains the\nclient).\n\nKey re-exchange is performed under whatever encryption was in effect\nwhen the exchange was started.  Encryption, compression, and MAC methods\nare changed when SSH_MSG_NEWKEYS is sent after the key exchange (as in\nthe initial key exchange).  Re-exchange is processed identically to the\ninitial key exchange.  It is permissible to change any or all of the\nalgorithms during the re-exchange.  Host keys can also change.  All keys\nare recomputed after the exchange.  Compression and encryption contexts\nare reset.  The packet sequence number is not reset.  The session\nidentifier is not recomputed.\n\nIt is recommended that keys be changed after each gigabyte of\ntransmitted data or after each hour of connection time, whichever comes\nsooner.\n\nIt is also possible to use the key re-exchange mechanism to switch to\nfaster algorithms after authentication, or to avoid double processing\nfor pre-encrypted or pre-authenticated data.  However, since the re-\nexchange is a public key operation, it requires a fair amount of\nprocessing power and should not be performed too often.\n\n8.  Service Request\n\nAfter the various authentications, the client requests a service.  The\nservice is identified by a name.  Service names can contain any non-\ncontrol characters.  The name must not be longer than 64 characters.\nService names are case-sensitive.\n\n            vlint32   SSH_MSG_SERVICE_REQUEST\n            string    service name\n\nMost server implementations will have a table of services that are\nsupported, specifying what to do for each service.\n\nIf the server rejects the service request, it should send a\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 15]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nSSH_MSG_DISCONNECT message.\n\nWhen the service starts, it will have access to the session identifier\ngenerated during key exchange.\n\nIf the server supports the service (and permits the client to use it),\nit responds with\n\n            vlint32   SSH_MSG_SERVICE_ACCEPT\n\nThe client is permitted to send further packets without waiting for the\nthis message; those packets will go to the selected service if the\nserver accepts the service request.  Message numbers used by services\nshould be in the area reserved for services (see Section ``Summary of\nMessage Numbers'').  The transport level will continue to process its\nown messages.\n\n9.  Stream-Based Services\n\nIt is expected that many services will actually be implemented by\napplications that communicate with this protocol through pipes or some\nother mechanism that passes a reliable stream of binary bytes.  For\nthose services, we define a protocol for passing data over this\nprotocol.  However, it is completely up to the particular service\nwhether it uses this protocol or something else.\n\nOnce a service has been selected, data is transmitted in each direction\nasynchronously.  The data is packetized using the following format:\n\n  vlint32   SSH_MSG_STREAM_DATA\n  string    data\n\nWhen the server or client application closes its output (i.e., will not\nsend more data), the following message is sent to the other side:\n\n            vlint32   SSH_MSG_STREAM_EOF\n\nNo data can be sent after sending this message.  Data can still be\ntransmitted in the other direction.\n\nWhen either party wishes to terminate communication, it sends\nSSH_MSG_STREAM_CLOSE.  Upon receiving that message, a party should\nimmediately send back SSH_MSG_STREAM_CLOSE unless it has already sent\nthat.\n\n            vlint32   SSH_MSG_STREAM_CLOSE\n\nAfter both sending and receiving this message, the communications\nchannel should be closed.\n\n10.  Additional Messages\n\nEither party may send any of the following messages at any time.\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 16]\n\nINTERNET-DRAFT                                         September 6, 1996\n \n10.1.  Disconnection Message\n\n            vlint32   SSH_MSG_DISCONNECT\n            vlint32   reason code\n            string    description\n\nThis message causes immediate termination of the connection.  The\ndescription field gives the reason for disconnecting in human-readable\nform in English.  The error code gives the reason in a machine-readable\nformat (suitable for localization), and can have the following values:\n\n          #define SSH_DISCONNECT_HOST_NOT_ALLOWED_TO_CONNECT      1\n          #define SSH_DISCONNECT_PROTOCOL_ERROR                   2\n          #define SSH_DISCONNECT_KEY_EXCHANGE_FAILED              3\n          #define SSH_DISCONNECT_HOST_AUTHENTICATION_FAILED       4\n          #define SSH_DISCONNECT_MAC_ERROR                        5\n          #define SSH_DISCONNECT_COMPRESSION_ERROR                6\n          #define SSH_DISCONNECT_SERVICE_NOT_AVAILABLE            7\n          #define SSH_DISCONNECT_PROTOCOL_VERSION_NOT_SUPPORTED   8\n          #define SSH_DISCONNECT_SERVER_HOST_KEY_NOT_VERIFIABLE   9\n\n10.2.  Ignored Data Message\n\n            vlint32   SSH_MSG_IGNORE\n            string    data\n\nAll implementations must understand (and ignore) this message at any\ntime (after receiving the protocol version).  No implementation is\nrequired to ever send them.\n\n10.3.  Reserved Messages\n\nAn implementation must respond to all unrecognized messages with an\nSSH_MSG_UNIMPLEMENTED message in the order in which they were received.\nLater protocol versions may define other meanings for these message\ntypes.\n\n            vlint32   SSH_MSG_UNIMPLEMENTED\n            uint32    packet sequence number of rejected message\n\n11.  Summary of Message Numbers\n\nThe following message numbers have been defined in this protocol.\n\n#define SSH_MSG_DISCONNECT             1\n#define SSH_MSG_IGNORE                 2\n#define SSH_MSG_UNIMPLEMENTED          3\n#define SSH_MSG_KEXINIT               10\n#define SSH_MSG_NEWKEYS               11\n#define SSH_MSG_SERVICE_REQUEST       12\n#define SSH_MSG_SERVICE_ACCEPT        13\n\n/* Numbers 20-29 for kex packets.\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 17]\n\nINTERNET-DRAFT                                         September 6, 1996\n \n   Different kex methods may reuse message numbers in\n   this range. */\n#define SSH_MSG_KEXRSA_HOSTKEY        15\n#define SSH_MSG_KEXRSA_SESSIONKEY     16\n\n/* Numbers 30- are reserved for service types.\n   Different service types may reuse the same messages.\n   Messages for stream-based services.  Other service types\n   may be defined in other documents. */\n#define SSH_MSG_STREAM_DATA           40\n#define SSH_MSG_STREAM_EOF            41\n#define SSH_MSG_STREAM_CLOSE          42\n\n12.  Public Keys and Public Key Infrastructure\n\nThis protocol is intentionally open on public key formats, as well as\nsignature and encryption formats.  There is currently no generally\naccepted public key infrastructure on the Internet, there are several\ncompeting key formats, and more formats are likely to appear.  It will\nprobably take several years until the situation is resolved.  In\nparticular, it is not clear that X.509 would be the solution, although\nthat is also a possibility.\n\nThere are several aspects to a public key type:\n\no  Key format: how is the key encoded, and how are certificates\n   represented.  The key blobs in this protocol may (but are not\n   required to) contain certificates in addition to keys.\n\no  Signature and/or encryption algorithms.  Some algorithms may not\n   support both encryption and decryption.\n\no  Encoding for signatures and encrypted data.  This includes but is not\n   limited to padding, byte order, and data formats.\n\nThe following public key formats are currently defined:\n\n          ssh-simple-rsa          RSA with (mostly) PKCS-1 encodings\n\nNote that the key type is negotiated at the beginning of the key\nexchange, and is not included in the key blob itself.\n\n12.1.  ssh-simple-rsa\n\nThis key type defines an RSA public key, with (mostly) PKCS compatible\nsignature and encryption formats.  It supports both signatures and\nencryption.\n\nPublic keys of this type are represented as follows:\n\n            byte[4]       0 (reserved)\n            uint32        number of bits in the modulus\n            uint16        number bits in the public exponent\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 18]\n\nINTERNET-DRAFT                                         September 6, 1996\n \n            bytes[n]      exponent, MSB first, n = floor((bits+7)/8)\n            uint16        number of bits in the modulus\n            bytes[n]      modulus, MSB first, n = floor((bits+7)/8)\n\nIt is permissible that there be other data (e.g., certificates)\nfollowing this; however, such data is not yet defined.\n\nNote that private key formats are not defined here, and are\nimplementation-specific.\n\nAn encrypted message is formed as follows.\n\no  The data to be encrypted is padded into a long integer of the same\n   number of bits as the modulus as follows:\n\n              MSB             .  .  .                LSB\n\n               0   2   RND(n bytes)   0   encrypted_data\n\nThe RND bytes represent non-zero random bytes.\n\no  To encrypt, this integer is raised to the public exponent, modulo the\n   modulus.\n\no  The result is converted to a byte string of floor((bits+7)/8) bytes\n   (where bits is the number of bits in the modulus), MSB first.  This\n   byte string (without any length or terminating characters) is the\n   result of the encryption.\n\nA signature is formed as follows.\n\no  The data to be signed (typically a message digest, but not required\n   to be such) is padded into a long integer of the same number of bits\n   as the modulus as follows:\n\n              MSB             .  .  .             LSB\n\n               0   1   RND(n bytes)   0   signed_data\n\nThe RND bytes represent non-zero random bytes.  Note that this differs\nfrom the PKCS standard, where 0xFF bytes are specified for padding.\n\no  To sign, this integer is raised to the private exponent, modulo the\n   modulus.\n\no  The result is converted to a byte string of floor((bits+7)/8) bytes\n   (where bits is the number of bits in the modulus), MSB first.  This\n   byte string (without any length or terminating characters) is the\n   signature.  Applications may add other data outside this value.\n\n\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                       [page 19]\n---------- end of transport.txt ----------------\n\n---------- cut here for userauth.txt -----------\nNetwork Working Group                           Tatu Ylonen <ylo@ssh.fi>\nINTERNET-DRAFT                               SSH Communications Security\nuserauth.txt                                           September 6, 1996\nExpires: January 1st, 1997\n\n\n                      SSH Authentication Protocol\n\nStatus of This memo\n\nThis document is an Internet-Draft. Internet-Drafts are working\ndocuments of the Internet Engineering Task Force (IETF), its areas,\nand its working groups. Note that other groups may also distribute\nworking documents as Internet-Drafts.\n\nInternet-Drafts are draft documents valid for a maximum of six\nmonths and may be updated, replaced, or obsoleted by other documents\nat any time. It is inappropriate to use Internet-Drafts as reference\nmaterial or to cite them other than as ``work in progress.''\n\nTo learn the current status of any Internet-Draft, please check\nthe ``1id-abstracts.txt'' listing contained in the Internet-Drafts\nShadow Directories on ftp.is.co.za (Africa), nic.nordu.net (Europe),\nmunnari.oz.au (Pacific Rim), ds.internic.net (US East Coast),\nor ftp.isi.edu (US West Coast).\n\nAbstract\n\nThis documents describes the SSH authentication protocol.  It is used to\nprove that the client is authorized access the requested service with\nthe supplied user name.  This authorization can be demonstrated through\npossession of a password, through possession of a key, by authenticating\nthe client host and user, by some other method, or a combination of\nthese.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 1]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nTable of Contents\n\n1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . .  2\n2.  User Authentication   . . . . . . . . . . . . . . . . . . . . . .  2\n  2.1.  Starting Authentication   . . . . . . . . . . . . . . . . . .  3\n  2.2.  Preauthentication Message   . . . . . . . . . . . . . . . . .  3\n  2.3.  Responses to Authentication Requests  . . . . . . . . . . . .  4\n  2.4.  Authentication Requests   . . . . . . . . . . . . . . . . . .  4\n  2.5.  Password-Style Authentications  . . . . . . . . . . . . . . .  5\n    2.5.1.  Password Authentication   . . . . . . . . . . . . . . . .  5\n    2.5.2.  SecurID Authentication  . . . . . . . . . . . . . . . . .  5\n  2.6.  One-Time Passwords and Similar Methods  . . . . . . . . . . .  5\n    2.6.1.  S/KEY   . . . . . . . . . . . . . . . . . . . . . . . . .  6\n    2.6.2.  NRL OPIE  . . . . . . . . . . . . . . . . . . . . . . . .  6\n  2.7.  Other Authentication Methods  . . . . . . . . . . . . . . . .  6\n    2.7.1.  Public Key Authentication   . . . . . . . . . . . . . . .  6\n    2.7.2.  Host-Based Authentication   . . . . . . . . . . . . . . .  7\n    2.7.3.  Kerberos Authentication   . . . . . . . . . . . . . . . .  8\n3.  When Authentication Is Complete   . . . . . . . . . . . . . . . .  8\n4.  Message Numbers   . . . . . . . . . . . . . . . . . . . . . . . .  8\n\n\n\n1.  Introduction\n\nThis protocol is designed to run over the SSH transport layer protocol\nusing the same packet-based protocol as the transport layer.  The\nservice name is \"ssh-userauth\".\n\nAuthentication works by the client first declaring the service name and\nthe user name to be used to access the service.  The server then\nresponds with the set of authentication methods that are acceptable; the\nclient then sends an authentication request, and this dialog continues\nuntil access has been granted or denied.\n\nWhen this protocol starts, it receives the session identifier from the\ntransport layer protocol.  The session identifier uniquely identifies\nthis session and is suitable for signing to prove ownership of a private\nkey.\n\n2.  User Authentication\n\nAuthentication is mostly client-driven.  The client sends an\nauthentication request, and the server responds with success or failure.\nWith a failure response the server informs the client which methods may\nbe used to continue the dialog, thus guiding the client through a\npotentially complex sequence of authentications.\n\nAuthentication methods are identified by names (strings).  Some methods\nare defined in the protocol; additional methods may be defined using the\nsyntax \"name@domainname\" as the method name (for example,\n\"footoken@footoken.com\").  This ensures that private extensions can be\nimplemented without breaking compatibility and without requiring a\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 2]\n\nINTERNET-DRAFT                                         September 6, 1996\n \ncentral registry of method names.  Method names are case-sensitive.\nNames must consist of non-control characters.  Commas are not allowed in\nnames; at signs can only be used for the purpose described above.\n\nThe following methods are predefined:\n\npassword             Knowledge of password\nsecurid              SecurID authentication\nskey                 S/KEY one-time passwords\nopie                 NRL OPIE one-time passwords\npublickey            Possession of private key\nhostbased            Identity of client host and user\nkerberos4            Kerberos v4 authentication\nkerberos5            Kerberos v5 authentication\nkerberos-afs         AFS Kerberos authentication\n\n2.1.  Starting Authentication\n\nUser authentication starts by the client declaring the service and user\nname it wishes to access.\n\n            vlint32   SSH_MSG_USERAUTH_START\n            string    service name\n            string    user name\n\nThe server will reply to this message in the same way it responds to an\nauthentication request; however, the client may immediately continue\nwith authentication requests without waiting for the reply.\n\nThis must be the first message sent in user authentication.  The user\nname or service cannot be changed after authentication has begun; the\nonly way to change them is to disconnect and open a new connection.\n\nIf the requested service is not available, the server may disconnect\nimmediately or any time later.\n\nIf the requested user does not exist, the server is allowed to\ndisconnect, or may send a bogus list of acceptable authentications but\nnever accept any.  This makes it possible for the server to avoid\ndisclosing information about which accounts exist.\n\nThe server should have a timeout for authentication, and disconnect if\nthe authentication has not been accepted within the timeout period.  The\nrecommended timeout period is 10 minutes.  Additionally, the\nimplementation may want to limit the number of times some authentication\nmethods (particularly password authentication) can be tried.\n\n2.2.  Preauthentication Message\n\nAfter receiving the SSH_MSG_USERAUTH_START message, the server may\noptionally send a SSH_MSG_USERAUTH_BANNER message.  This message\ncontains a message to be displayed to the client user before attempting\nauthentication.  On most Unix machines, this message is read from\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 3]\n\nINTERNET-DRAFT                                         September 6, 1996\n \n/etc/issue.  In some jurisdictions, sending a warning message before\nauthentication may be relevant to getting legal protection.  The message\nmay contain newlines.\n\n            vlint32   SSH_MSG_USERAUTH_BANNER\n            string    message\n\n2.3.  Responses to Authentication Requests\n\nIf the server rejects the authentication request, it responds with\n\n            vlint32   SSH_MSG_USERAUTH_FAILURE\n            string    authentications_that_can_continue\n\nauthentications_that_can_continue is a comma-separated list of\nauthentication methods that may productively continue the authentication\ndialog.  Methods that require interaction with the user should not be\nlisted unless they can actually be used to authenticate this user.  Note\nthat successful response to one method in the list may not be enough to\nbe accepted; the server is allowed to require multiple authentications.\nThe server should not list authentications that it has already accepted.\n\nWhen the server accepts authentication, it responds with\n\n            vlint32   SSH_MSG_USERAUTH_SUCCESS\n\nThe client may send several authentication requests without waiting for\nresponses from previous requests.  The server will acknowledge any\nfailed requests with a SSH_SMSG_AUTH_FAILURE message.  However,\nSSH_SMSG_AUTH_SUCCESS is sent only once, and any further authentication\nrequests received after that are silently ignored.\n\nOnce SSH_MSG_USERAUTH_SUCCESS has been sent, any non-authentication\nmessages sent by the client will be passed to the service being run\nabove this authentication protocol.\n\n2.4.  Authentication Requests\n\nAll authentication requests use the same generic message format.  Only\nthe first few fields are defined; the remaining fields depend on the\nauthentication method.\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    method name\n            rest of the packet is method-specific\n\nThere are several authentication methods that basically work by the\nclient sending some kind of identifying string (or other data) to the\nserver, and the server directly responding with success or failure.\nExamples of this style of authentication are \"password\" and \"securid\"\nmethods.  Other such methods may be defined later.\n\nAnother common form is one where the server sends a prompt (a\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 4]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nchallenge), and the client is supposed to respond appropriately based on\nthe challenge.  Most one-time password methods use this form; examples\ninclude \"skey\" and \"opie\".\n\nWhile there is usually little point in clients sending requests that the\nserver does not list as acceptable, sending such requests is not an\nerror, and the server should simply reject requests that it does not\nrecognize.\n\nAn authentication request may result in a further exchange of messages.\nAll such messages depend on the authentication method used.\n\n2.5.  Password-Style Authentications\n\nAll password-style authentication methods use a single message of the\nfollowing format.  The server responds with success or failure.\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    method name\n            string    authenticating string\n\n2.5.1.  Password Authentication\n\nThis is conventional password authentication.  The method name is\n\"password\"; the authenticating string is the plaintext password.  Note\nthat the password is sent as plaintext in the packet, but the entire\npacket (including the password) is encrypted by the transport layer.  It\nis not possible for the client to hash the password, because it cannot\nknow how the server stores the password.\n\nImplementations should limit the number of times password authentication\ncan be attempted, and disconnect after too many attempts have been made.\nThe recommended maximum number of attempts is five.\n\n2.5.2.  SecurID Authentication\n\nSecurID is a timing-based hardware token authenticator.  The user enters\na code displayed on the token as authentication.  The entered token is\npassed in the following message.\n\nThe method name for SecurID authentication is \"securid\"; the\nauthenticating string is the code displayed on the hardware token.\n\n2.6.  One-Time Passwords and Similar Methods\n\nAll one-time password authentication methods use the following message\nexchange:\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    method name\n\nThe server responds with either SSH_MSG_USERAUTH_FAILURE or\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 5]\n\nINTERNET-DRAFT                                         September 6, 1996\n \n            vlint32   SSH_MSG_USERAUTH_OTP_PROMPT\n            string    prompt\n\nThe client then responds with either a new authentication request or\n\n            vlint32   SSH_MSG_USERAUTH_OTP_RESPONSE\n            string    response\n\nThe server responds to this message with either success or failure.\n\n2.6.1.  S/KEY\n\nS/KEY is an early one-time password mechanism.  The method name is\n\"skey\".\n\n2.6.2.  NRL OPIE\n\nNRL OPIE is another one-time password mechanism.  The method name for it\nis \"opie\".\n\n2.7.  Other Authentication Methods\n\n2.7.1.  Public Key Authentication\n\nThe possession of a private key can serve as authentication.  This\nmethod works by sending a signature created by the private key.\n\nPrivate keys are often stored encrypted at the client host, and the user\nmust supply a passphrase before the signature can be generated.  To\navoid needing to supply passphrases when it is not necessary, the client\ncan query whether a particular key is acceptable as authentication.\nThis done with the following message.  The key may include certificates.\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    \"publickey\"\n            string    public key algorithm name\n            string    public key to be used for authentication\n\nPublic key algorithms are defined in the transport layer specification.\n\nThe server will respond to this message with either\nSSH_MSG_USERAUTH_FAILURE or with\n\n            vlint32   SSH_MSG_USERAUTH_PK_OK\n\nHowever, no response is sent after a successful authentication.\n\nThe client should then send a signature generated by the public key:\n\n            vlint32   SSH_MSG_USERAUTH_PK_SIGNATURE\n            string    signature\n\nThe public key may contain certificates.\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 6]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nSignature  is a signature by the corresponding private key of the HASH\nof the concatenation of the requested service, the requested user, the\ngiven public key, and the session identifier (which binds the signature\nto the server host key and the particular key exchange).  All of these,\nexcept the session identifier are represented as strings: there is first\na vlint32 length, and then the characters of the string.\n\nWhen the server receives this message, it checks whether the supplied\nkey is acceptable for authentication, and if so, checks whether the\nsignature is correct.\n\nIf both checks succeed, authentication may be granted (the server may\nalso require further authentication with other methods, without letting\nthe client know at this point that authentication has partially\nsucceeded).\n\n2.7.2.  Host-Based Authentication\n\nSome sites wish to allow authentication based on the host where the user\nis coming from and the user name on the remote host.  While this form of\nauthentication is not suitable for high-security sites, it can be very\nconvenient in many environments.  The client requests this form of\nauthentication by sending the following message.\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    \"hostbased\"\n            string    client host name\n            string    public key algorithm\n            string    public host key for client host\n            string    client user name\n            string    signature\n\nThe public key may contain certificates.  Public key algorithm names are\ndefined in the transport layer protocol specification.\n\nSignature is a signature by the host key of HASH of the concatenation of\nthe requested service, the requested user, the client host name, the\npublic host key of the client, the client user name, and the session\nidentifier (which binds the signature to the server host key and the\nparticular key exchange).  All of these, except the session identifier,\nare represented as strings for hashing: vlint32 length and then the\nbytes of the string.\n\nAuthentication is accepted if the server can verify that the host key\nactually belongs to the client host, the given user on that host is\nallowed to log in, and the signature is a valid signature on the\nappropriate value by the given host key.  (The server is also allowed to\nignore the client user name, if it only wants to authenticate the client\nhost.)\n\nIt is recommended that whenever possible, the server perform additional\nchecks the verify that the network address obtained from the (untrusted)\nnetwork matches the given client host name.  This makes exploiting\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 7]\n\nINTERNET-DRAFT                                         September 6, 1996\n \ncompromised host keys more difficult.\n\n2.7.3.  Kerberos Authentication\n\nThere are several ways to authenticate the user using Kerberos (OSF DCE\nand AFS are also incarnations of Kerberos).  Different versions of\nKerberos (v4, v5, DCE, and AFS) have different capabilities.  Separate\nmessages have been defined for each of these.  In each case, the server\nshould respond with success or failure.\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    \"kerberos4\"\n            string    kerberos v4 credentials\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    \"kerberos5\"\n            string    kerberos v5 credentials\n            string    kerberos v5 ticket granting ticket (may be empty)\n\n            vlint32   SSH_MSG_USERAUTH_REQUEST\n            string    \"kerberos-afs\"\n            string    AFS token\n\nThe Kerberos authentication requests should be sent before other\nauthentication requests.  The other authentication methods may need to\naccess files from the user's home directory, which may not be accessible\nuntil e.g. the AFS token has been passed.  Note that even if these\nrequests fail, they may have side effects, such as making the home\ndirectory accessible.\n\n3.  When Authentication Is Complete\n\nAuthentication is complete when the server has responded with\nSSH_MSG_USERAUTH_SUCCESS.  Any authentication messages received after\nsending this message will be silently ignored.\n\nWhen sending SSH_MSG_USERAUTH_SUCCESS, the server also starts whatever\napplication was requested as the service.  Any non-authentication\nmessages received will be passed to the requested service.\n\n4.  Message Numbers\n\nAll message numbers used by this authencation protocol are in the range\n30..39, which is part of the range reserved for protocols running on top\nof the SSH transport layer protocol.  Message numbers above and\nincluding 40 are reserved for protocols running on top of this level.\nReceiving them before authentication is complete is an error, and the\nserver must disconnect in this case.  After successful authentication,\nthese messages are passed to the higher-level service.\n\nThe server should ignore any method-specific messages received while\nexpecting an authentication request.  These might sometimes result if\nthe client sends an authentication request that the server does not\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 8]\n\nINTERNET-DRAFT                                         September 6, 1996\n \nunderstand.\n\n          #define SSH_MSG_USERAUTH_START          30\n          #define SSH_MSG_USERAUTH_BANNER         31\n          #define SSH_MSG_USERAUTH_FAILURE        32\n          #define SSH_MSG_USERAUTH_SUCCESS        33\n          #define SSH_MSG_USERAUTH_REQUEST        34\n\n          /* Messages 35-39 are reserved for method-specific messages.\n             Different authentication methods may reuse the same message\n             numbers. */\n          /* Key-based */\n          #define SSH_MSG_USERAUTH_PK_OK          35\n          #define SSH_MSG_USERAUTH_PK_SIGNATURE   36\n          /* One-time passwords */\n          #define SSH_MSG_USERAUTH_OTP_PROMPT     35\n          #define SSH_MSG_USERAUTH_OTP_RESPONSE   36\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTatu Ylonen <ylo@ssh.fi>                                        [page 9]\n----------- end of userauth.txt ------------\n\n\n\n"
        },
        {
            "subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico",
            "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n"
        },
        {
            "subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico",
            "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n"
        },
        {
            "subject": "[public-csstestsuite] &lt;none&gt",
            "content": "I've noticed a very strange problem, and I'm not sure what to make of\nit.  It seems that the CSS height property is not functioning when used\nas a percentile on tables.  (I am using XHTML 1.0.)  This is a problem,\nas I'm trying to get a table to stretch vertically to fit the browser\nwindow, so that I can vertically align my page's content to the center.\nHowever, I'm baffled as to why this is, since the HTML height attribute\nseems to work on other pages.  Can somebody clear this up for me ?\n\nThe page in question is http://tony.gonk.net .  However, the code will\nnot reflect an attempt to use the height property--I'm experimenting\nwith this locally.  I'm just offering the URL as a reference to anyone\nwith suggestions.\n\n-- Tony\nazgul@gonk.net \nhttp://tony.gonk.net \n\n\n\n"
        },
        {
            "subject": "using layers with an applet am getting refresh error",
            "content": "Hi,\n\nI have a problem with an applet that I have displayed on a layer, when I\nclick the link to display the layer holding the applet I can see the\nwriting from the previous layer appearing on the applet, if I click to\nanother window and come back this ghost writing is gone, Has anyone had\nthis problem before or know of a solution to it.\n\n \n\nRegards\n\nBrian Murphy\n\n \n\n \n\n9934146@student.ul.ie\n\nUniversity of Limerick\n\n \n\n\n\n"
        },
        {
            "subject": "Re: using layers with an applet am getting refresh error",
            "content": "On Wednesday 2004-04-14 11:10 +0100, Brian Murphy wrote:\n> I have a problem with an applet that I have displayed on a layer, when I\n> click the link to display the layer holding the applet I can see the\n> writing from the previous layer appearing on the applet, if I click to\n> another window and come back this ghost writing is gone, Has anyone had\n> this problem before or know of a solution to it.\n\nThis is off-topic for this list, whose purpose is described in\nhttp://lists.w3.org/Archives/Public/public-css-testsuite/ :\n\n  This list is for coordinating the development of test suites for the\n  various CSS-related specifications.\n\n-David\n\n-- \nL. David Baron                                <URL: http://dbaron.org/ >\n\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "* Ian Hickson wrote:\n>> Regardless Hixie, with the rest of W3C using the RFC defs, and the\n>> testsuite not, it is misleading to potential test-suite users.\n>\n>What would you put instead? \"Must\" is plainly wrong, from an English\n>perspective. If the UA is buggy, the test must be red, not green. (Or\n>whatever the criteria is.)\n\nIt must be green in order to pass the test. It shall be green.\nHow do you write a test for a RFC 2119 SHOULD requirement?\n\n\n\n"
        },
        {
            "subject": "Error in CSS1 test ?7.1 (CSS2 language selector",
            "content": "Hello,\n\nI noticed a small error in the CSS1 test suite (section 7.1,\n\"Forward-compatible parsing\",\nhttp://www.w3.org/Style/CSS/Test/CSS1/current/sec71.htm): the document\nhas no language specified on any element, yet relies on the document\nlanguage in a couple of CSS2 selectors.\n\nI'm using a Gecko-based UA, and it appears that Gecko will match the\n:lang pseudo-class using the languages configured for Accept-Languages\n(pref intl.accept_languages) in the absence of a document-specified\nlanguage.  This seems like an acceptable behavior, but it causes\nunexpected output when I view the CSS1 test suite (as mentioned above)\nbecause I have French in my list of accepted languages.  Specifically,\nthe <ul> item \"This unordered list item should be black, because,\naccording to CSS1, the selector is invalid, and according to CSS2, the\nselector should not apply.\" appears in gray, because the CSS2 selector\n*did* apply.\n\nI should also note that the <span> that follows shortly after does NOT\nappear to match (the CSS specifies SPAN[lang|=\"fr\"]), although I'm\nuncertain as to whether this is the correct behavior (i.e. specified\ndifferences between :lang and [lang|=]) or an inconsistency in the UA.\n\nNot subscribed to list, please CC replies, etc.\n-- \nBen Winslow <rain@bluecherry.net>\n\n\n\n\n"
        },
        {
            "subject": "Re: Error in CSS1 test ?7.1 (CSS2 language  selector",
            "content": "On 6/9/04 8:24 AM, \"Ben Winslow\" <rain@bluecherry.net> wrote:\n\n> Hello,\n> \n> I noticed a small error in the CSS1 test suite (section 7.1,\n> \"Forward-compatible parsing\",\n> http://www.w3.org/Style/CSS/Test/CSS1/current/sec71.htm): the document\n> has no language specified on any element, yet relies on the document\n> language in a couple of CSS2 selectors.\n\nI disagree.  The tests do not rely on the document language.  The tests make\nsure that the document language isn't incorrectly inferred/assumed.\n\n\n> I'm using a Gecko-based UA, and it appears that Gecko will match the\n> :lang pseudo-class using the languages configured for Accept-Languages\n> (pref intl.accept_languages) in the absence of a document-specified\n> language.  This seems like an acceptable behavior,\n\nThat is not acceptable behavior and is a bug.\n\nAccept-Language is purely a client preference and has nothing to do with the\ndocument.\n\nThere are only two ways I know of offhand that the document language can be\ninferred.\n\n1. HTTP Header *response* Content-Language field\n    (or the <meta> http-equiv equivalent)\n2. 'lang' attribute on an element, or if absent, the nearest ancestor with a\n'lang' attribute, and if none, then inferred from 1.\n\nNone of that is present in the test case nor the HTTP response header[1].\nTherefore there is no specified language for the document (nor for any of\nits elements).  Therefore a language selector for a specific language can\nnever apply to any element in the document.\n\n\n> but it causes\n> unexpected output when I view the CSS1 test suite (as mentioned above)\n> because I have French in my list of accepted languages.\n\nNothing in that test page implies a 'lang' of 'fr', therefore, the :lang(fr)\nselector should always be false and should never select any element.\n\n\n> Specifically,\n> the <ul> item \"This unordered list item should be black, because,\n> according to CSS1, the selector is invalid, and according to CSS2, the\n> selector should not apply.\" appears in gray, because the CSS2 selector\n> *did* apply.\n\nSee above.  In CSS2, the selector does *not* apply.\n\n\n> I should also note that the <span> that follows shortly after does NOT\n> appear to match (the CSS specifies SPAN[lang|=\"fr\"]), although I'm\n> uncertain as to whether this is the correct behavior (i.e. specified\n> differences between :lang and [lang|=]) or an inconsistency in the UA.\n\nThis is a common misconception.\n\n:lang and [lang|=] are *very* different.\n\n[foo|=] only tests the 'foo' attribute *of a specific element*.\n\nThus [lang|=] can *only* apply to an element that *itself* has a 'lang'\nattribute that matches the value given appropriately.\n\n:lang matches the *language* of the element.\n\nThe language of the element is determined as I described above.  Yes, the\n'lang' attribute on the element does take part in this determination, but so\ndoes potentially the 'lang' attribute of an ancestor or what is sent in the\nHTTP header.\n\nTantek\n\n[1] response header from\n<http://www.w3.org/Style/CSS/Test/CSS1/current/test71.htm>\n\nHTTP/1.1 200 OK\nDate: Wed, 09 Jun 2004 19:05:06 GMT\nServer: Apache/1.3.28 (Unix) PHP/4.2.3\nP3P: policyref=\"http://www.w3.org/2001/05/P3P/p3p.xml\"\nCache-Control: max-age=21600\nExpires: Thu, 10 Jun 2004 01:05:06 GMT\nLast-Modified: Mon, 29 Sep 2003 17:43:47 GMT\nETag: \"3f786f53\"\nAccept-Ranges: bytes\nContent-Length: 16358\nConnection: close\nContent-Type: text/html; charset=iso-8859-1\n\n\n\n"
        },
        {
            "subject": "Re: Error in CSS1 test ?7.1 (CSS2 language  selector",
            "content": "On Wed, 2004-06-09 at 15:20, Tantek ??elik wrote:\n> On 6/9/04 8:24 AM, \"Ben Winslow\" <rain@bluecherry.net> wrote:\n\n> > I'm using a Gecko-based UA, and it appears that Gecko will match the\n> > :lang pseudo-class using the languages configured for Accept-Languages\n> > (pref intl.accept_languages) in the absence of a document-specified\n> > language.  This seems like an acceptable behavior,\n> \n> That is not acceptable behavior and is a bug.\n> \n> Accept-Language is purely a client preference and has nothing to do with the\n> document.\n> \n> There are only two ways I know of offhand that the document language can be\n> inferred.\n> \n> 1. HTTP Header *response* Content-Language field\n>     (or the <meta> http-equiv equivalent)\n> 2. 'lang' attribute on an element, or if absent, the nearest ancestor with a\n> 'lang' attribute, and if none, then inferred from 1.\n\nWhile it seems reasonable to assume that a document will be in one of\nthe user's configured languages (if the user is paying enough attention\nto the document that the CSS definitions matter, anyway), I can\ncertainly see the value in consistent behavior.\n\n> None of that is present in the test case nor the HTTP response header[1].\n> Therefore there is no specified language for the document (nor for any of\n> its elements).  Therefore a language selector for a specific language can\n> never apply to any element in the document.\n\nI'll open a bug against Mozilla when I get the chance (citing CSS 2.1 ??\n5.11.4[1] and HTML 4.0 ?? 8.1[2], unless anyone suggests something\nbetter.)\n\n> > I should also note that the <span> that follows shortly after does NOT\n> > appear to match (the CSS specifies SPAN[lang|=\"fr\"]), although I'm\n> > uncertain as to whether this is the correct behavior (i.e. specified\n> > differences between :lang and [lang|=]) or an inconsistency in the UA.\n> \n> This is a common misconception.\n> \n> :lang and [lang|=] are *very* different.\n> \n> [foo|=] only tests the 'foo' attribute *of a specific element*.\n> \n> Thus [lang|=] can *only* apply to an element that *itself* has a 'lang'\n> attribute that matches the value given appropriately.\n\nThis was the way I understood it, but I wasn't certain that I'd\ninterpreted the spec correctly.  Thank you for the clarification.\n\n> Tantek\n\n[1] http://www.w3.org/TR/CSS21/selector.html#lang\n[2] http://www.w3.org/TR/REC-html40/struct/dirlang.html#h-8.1\n-- \nBen Winslow <rain@bluecherry.net>\n\n\n\n\n"
        },
        {
            "subject": "Re: Error in CSS1 test ?7.1 (CSS2 language  selector",
            "content": "On Wed, 2004-06-09 at 15:20, Tantek ??elik wrote:\n> On 6/9/04 8:24 AM, \"Ben Winslow\" <rain@bluecherry.net> wrote:\n\n> I disagree.  The tests do not rely on the document language.  The tests make\n> sure that the document language isn't incorrectly inferred/assumed.\n\n> > I'm using a Gecko-based UA, and it appears that Gecko will match the\n> > :lang pseudo-class using the languages configured for Accept-Languages\n> > (pref intl.accept_languages) in the absence of a document-specified\n> > language.  This seems like an acceptable behavior,\n> \n> That is not acceptable behavior and is a bug.\n> \n> Accept-Language is purely a client preference and has nothing to do with the\n> document.\n> \n> There are only two ways I know of offhand that the document language can be\n> inferred.\n> \n> 1. HTTP Header *response* Content-Language field\n>     (or the <meta> http-equiv equivalent)\n> 2. 'lang' attribute on an element, or if absent, the nearest ancestor with a\n> 'lang' attribute, and if none, then inferred from 1.\n\nWhile preparing a bug report for Mozilla, I noticed the last bullet in\nthe HTML 4.0 spec (??8.1.2 [1]) which I had previously overlooked.  The\nsection defines the inheritance hierarchy for language information as\nfollows:\n\nAn element inherits language code information according to the following\norder of precedence (highest to lowest):\n\n      * The lang attribute set for the element itself.\n      * The closest parent element that has the lang attribute set\n        (i.e., the lang attribute is inherited).\n      * The HTTP \"Content-Language\" header (which may be configured in a\n        server). For example: \n        Content-Language: en-cockney\n      * User agent default values and user preferences.\n\nBased on this, I am reverting to my original standpoint that Gecko's\nbehavior is correct and the test suite is in error.\n\nOpinions?\n\n[1] http://www.w3.org/TR/REC-html40/struct/dirlang.html#h-8.1.2\n\n-- \nBen Winslow <rain@bluecherry.net>\n\n\n\n\n"
        },
        {
            "subject": "Re: Error in CSS1 test ?7.1 (CSS2 language   selector",
            "content": "On 6/11/04 1:02 PM, \"Ben Winslow\" <rain@bluecherry.net> wrote:\n\n> On Wed, 2004-06-09 at 15:20, Tantek ?elik wrote:\n>> On 6/9/04 8:24 AM, \"Ben Winslow\" <rain@bluecherry.net> wrote:\n> \n>> I disagree.  The tests do not rely on the document language.  The tests make\n>> sure that the document language isn't incorrectly inferred/assumed.\n> \n>>> I'm using a Gecko-based UA, and it appears that Gecko will match the\n>>> :lang pseudo-class using the languages configured for Accept-Languages\n>>> (pref intl.accept_languages) in the absence of a document-specified\n>>> language.  This seems like an acceptable behavior,\n>> \n>> That is not acceptable behavior and is a bug.\n>> \n>> Accept-Language is purely a client preference and has nothing to do with the\n>> document.\n>> \n>> There are only two ways I know of offhand that the document language can be\n>> inferred.\n>> \n>> 1. HTTP Header *response* Content-Language field\n>>     (or the <meta> http-equiv equivalent)\n>> 2. 'lang' attribute on an element, or if absent, the nearest ancestor with a\n>> 'lang' attribute, and if none, then inferred from 1.\n> \n> While preparing a bug report for Mozilla, I noticed the last bullet in\n> the HTML 4.0 spec (?8.1.2 [1]) which I had previously overlooked.  The\n> section defines the inheritance hierarchy for language information as\n> follows:\n> \n> An element inherits language code information according to the following\n> order of precedence (highest to lowest):\n> \n>     * The lang attribute set for the element itself.\n>     * The closest parent element that has the lang attribute set\n>       (i.e., the lang attribute is inherited).\n>     * The HTTP \"Content-Language\" header (which may be configured in a\n>       server). For example:\n>       Content-Language: en-cockney\n\nThat part makes sense so far.\n\n\n>     * User agent default values and user preferences.\n\nBut what does that mean?  It could mean anything.\n\nThus it is ambiguous, difficult (impossible?) to test, and has nothing to do\nwith the language of the document.\n\n\n> Based on this, I am reverting to my original standpoint that Gecko's\n> behavior is correct\n\nArguably compliant *maybe*, but certainly not \"correct\" by any reasonable\ninterpretation of what the :lang selector is supposed to select.\n\n\n> and the test suite is in error.\n> \n> Opinions?\n\nSince logically that last bullet point doesn't make any sense (since it has\nnothing to do with the document), the better course of action is to still\nfile the bug, but also point out the problem with the spec, and file an\nerrata against HTML4 (stating that last bullet point doesn't make sense and\nshould be stricken), or actually...\n\n\n> [1] http://www.w3.org/TR/REC-html40/struct/dirlang.html#h-8.1.2\n\n[2] http://www.w3.org/TR/html401/struct/dirlang.html#h-8.1.2\nhas the same problem.\n\nPlease refer to HTML4.01 instead of HTML4.0 because 4.01 contains many fixes\nand errata.\n\nIn addition, it is good to check the HTML4.01 errata as well:\n\n http://www.w3.org/MarkUp/html4-updates/errata\n\nNew errata against HTML4.01 can be filed by sending an email to:\n\nwww-html-editor@w3.org\n\nThanks,\n\nTantek\n\n\n\n"
        },
        {
            "subject": "a few CSS 2.1 test",
            "content": "I just wrote a few tests [1] for 2.1 [2], and I'm interested in knowing\nhow I'm doing, especially with regard to the guidelines [3], and\nespecially from the authors of said guidelines.\n\nA few issues where I'm particularly unsure of myself are:\n * are my title elements good?\n * are my filenames good, especially regarding my choice along the\n   a-b-c-d-e-f spectrum (for which the tests I wrote are perhaps an\n   unusual case)?\n * is my lack of consistent wording a problem?  I've written multiple\n   variations of the sentences \"This paragraph should have a green\n   background.\" and \"The next two paragraphs should look identical.\"\n\n-David\n\n[1] http://dbaron.org/css2.1/tests/\n[2] http://www.w3.org/TR/2004/CR-CSS21-20040225/\n[3] http://www.w3.org/Style/CSS/Test/guidelines.html\n\n-- \nL. David Baron                                <URL: http://dbaron.org/ >\n\n\n\n"
        },
        {
            "subject": "Re: a few CSS 2.1 test",
            "content": "On Fri, 12 Mar 2004, L. David Baron wrote:\n>\n> I just wrote a few tests [1] for 2.1 [2], and I'm interested in knowing\n> how I'm doing, especially with regard to the guidelines [3], and\n> especially from the authors of said guidelines.\n\nI think those are the best tests I've ever seen.\n\nMy only comments -- and don't get me wrong; these are nit-picking\ncomments, the equivalent of someone saying you should fix the spelling in\na comment during a code review -- would be:\n\n http://dbaron.org/css2.1/tests/t010403-shand-font-00-b.xht\n http://dbaron.org/css2.1/tests/t010403-shand-font-01-b.xht\n   Instead of \"NOT be in a bold font\" I would just say \"be in a thin\n   font\" or \"be in a regular font weight\", as negatives tend to make\n   understanding the test harder.\n\n http://dbaron.org/css2.1/tests/t040102-keywords-01-b.xht\n   Instead of \"This should be 10em wide.\", I would just say \"Test\". This\n   is for two reasons: first, it is nigh on impossible to know how much\n   10em is anyway, and second, you want to have as few pass conditions per\n   test as possible, so that the reader can quickly establish the result.\n\n http://dbaron.org/css2.1/tests/t040102-keywords-00-b.xht\n http://dbaron.org/css2.1/tests/t040103-case-00-b.xht\n http://dbaron.org/css2.1/tests/t040103-case-01-c.xht\n http://dbaron.org/css2.1/tests/t040103-escapes-01-b.xht\n http://dbaron.org/css2.1/tests/t040103-escapes-02-d.xht\n   I haven't yet put this in the public version of the guidelines, but\n   there are some assumptions you can make about the test environment:\n      http://cgi.w3.org/member-bin/process.cgi?method=url&url=http%3A%2F%2Fwww.hixie.ch%2Ftests%2Fevil%2Fcss%2Fcss21%2Fguidelines%2Fguidelines.src&output=html#requirements\n   In particular, you can assume the default text color is black, so there\n   is no need to explicitly set it in the tests.\n\n http://dbaron.org/css2.1/tests/t040103-escapes-00-b.xht\n   You should make a third test line which makes no use of generated\n   content at all, and preferably change the sentence to a dummy one\n   such as \"This is a test paragraph\".\n\n\n> A few issues where I'm particularly unsure of myself are:\n>  * are my title elements good?\n\nThey seem fine to me. To be honest the titles aren't that important.\n\n\n>  * are my filenames good, especially regarding my choice along the\n>    a-b-c-d-e-f spectrum (for which the tests I wrote are perhaps an\n>    unusual case)?\n\n   http://dbaron.org/css2.1/tests/t040103-escapes-05-c.xht\n\n...should probably be a \"b\" not a \"c\", but they seem fine to me in\ngeneral. It's a judgement call, and the judgement is almost always going\nto be based on how many browsers actually fail the test -- my \"Evil\" tests\nfrom back in 99 when I was making the Evil Test Suite were simply the\ntests that everyone failed, as opposed to the Wet Blanket Tests, which\nwere the tests that only a few people failed and thus \"reduced the\nenjoyment of others\", as it were.\n\n\n>  * is my lack of consistent wording a problem?  I've written multiple\n>    variations of the sentences \"This paragraph should have a green\n>    background.\" and \"The next two paragraphs should look identical.\"\n\nThat all looked fine to me.\n\n-- \nIan Hickson                                      )\\._.,--....,'``.    fL\nU+1047E                                         /,   _.. \\   _\\  ;`._ ,.\nhttp://index.hixie.ch/                         `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: a few CSS 2.1 test",
            "content": "On Sat, 13 Mar 2004, Tantek [ISO-8859-1] ?elik wrote:\n>\n> 1. serve the files as text/html for ease of trying them out in more browsers\n> (alternatively, conditionally serve as application/xhtml+xml only if http\n> accept headers allow for it -- folks have documented this on the net.)\n> I know, this violates what is allowed for XHTML 1.1, but it helps usability\n> (a good tradeoff), and will only make a difference in browsers that don't\n> handle XHTML anyway.\n\nWell, the files will get converted to (amongst other things) HTML4 files\nbefore publishing, so this won't be a problem. All modern browsers support\nXHTML, so in the meantime while developing the tests it doesn't matter\nthat it's only available in that format.\n\n\n> 2. possibly add more <link rel=\"help\"> tags for some of the tests. e.g.\n> your border shorthand test should also link to the sections on the\n> 'border' and 'border-color' property in spec, because that's really what\n> it's testing, in fact, I might put the link to the border-color property\n> first since that's really what is being thoroughly tested.\n\nI don't want accurate rel=\"help\" links to become a burden on the test\nwriters... I wouldn't want to push this too strongly.\n\n-- \nIan Hickson                                      )\\._.,--....,'``.    fL\nU+1047E                                         /,   _.. \\   _\\  ;`._ ,.\nhttp://index.hixie.ch/                         `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: a few CSS 2.1 test",
            "content": "I concur with Ian's comments have only two other quick short comments to\nmake:\n\n1. serve the files as text/html for ease of trying them out in more browsers\n (alternatively, conditionally serve as application/xhtml+xml only if http\naccept headers allow for it -- folks have documented this on the net.)\nI know, this violates what is allowed for XHTML 1.1, but it helps usability\n(a good tradeoff), and will only make a difference in browsers that don't\nhandle XHTML anyway.\n\nAnother possibility is to use content negotiation so that URLs without a\nfile extension, e.g.:\n\nhttp://dbaron.org/css2.1/tests/t010403-shand-border-00-c\n\nare sent as text/html to browsers that don't handle XHTML.\n\n\n2. possibly add more <link rel=\"help\"> tags for some of the tests.\ne.g. your border shorthand test should also link to the sections on the\n'border' and 'border-color' property in spec, because that's really what\nit's testing, in fact, I might put the link to the border-color property\nfirst since that's really what is being thoroughly tested.\n\nI'm busy with prepping for my presentations at SXSW so I didn't do a\ndetailed review and will hopefully have more comments later.\n\nDefinitely a very nice start though.  Makes me want to write some tests.\n\nThanks,\n\nTantek\n\n\nOn 3/13/04 3:21 AM, \"Ian Hickson\" <ian@hixie.ch> wrote:\n\n> \n> On Fri, 12 Mar 2004, L. David Baron wrote:\n>> \n>> I just wrote a few tests [1] for 2.1 [2], and I'm interested in knowing\n>> how I'm doing, especially with regard to the guidelines [3], and\n>> especially from the authors of said guidelines.\n> \n> I think those are the best tests I've ever seen.\n> \n> My only comments -- and don't get me wrong; these are nit-picking\n> comments, the equivalent of someone saying you should fix the spelling in\n> a comment during a code review -- would be:\n> \n> http://dbaron.org/css2.1/tests/t010403-shand-font-00-b.xht\n> http://dbaron.org/css2.1/tests/t010403-shand-font-01-b.xht\n>  Instead of \"NOT be in a bold font\" I would just say \"be in a thin\n>  font\" or \"be in a regular font weight\", as negatives tend to make\n>  understanding the test harder.\n> \n> http://dbaron.org/css2.1/tests/t040102-keywords-01-b.xht\n>  Instead of \"This should be 10em wide.\", I would just say \"Test\". This\n>  is for two reasons: first, it is nigh on impossible to know how much\n>  10em is anyway, and second, you want to have as few pass conditions per\n>  test as possible, so that the reader can quickly establish the result.\n> \n> http://dbaron.org/css2.1/tests/t040102-keywords-00-b.xht\n> http://dbaron.org/css2.1/tests/t040103-case-00-b.xht\n> http://dbaron.org/css2.1/tests/t040103-case-01-c.xht\n> http://dbaron.org/css2.1/tests/t040103-escapes-01-b.xht\n> http://dbaron.org/css2.1/tests/t040103-escapes-02-d.xht\n>  I haven't yet put this in the public version of the guidelines, but\n>  there are some assumptions you can make about the test environment:\n>     \n> http://cgi.w3.org/member-bin/process.cgi?method=url&url=http%3A%2F%2Fwww.hixie\n> .ch%2Ftests%2Fevil%2Fcss%2Fcss21%2Fguidelines%2Fguidelines.src&output=html#req\n> uirements\n>  In particular, you can assume the default text color is black, so there\n>  is no need to explicitly set it in the tests.\n> \n> http://dbaron.org/css2.1/tests/t040103-escapes-00-b.xht\n>  You should make a third test line which makes no use of generated\n>  content at all, and preferably change the sentence to a dummy one\n>  such as \"This is a test paragraph\".\n> \n> \n>> A few issues where I'm particularly unsure of myself are:\n>>  * are my title elements good?\n> \n> They seem fine to me. To be honest the titles aren't that important.\n> \n> \n>>  * are my filenames good, especially regarding my choice along the\n>>    a-b-c-d-e-f spectrum (for which the tests I wrote are perhaps an\n>>    unusual case)?\n> \n>  http://dbaron.org/css2.1/tests/t040103-escapes-05-c.xht\n> \n> ...should probably be a \"b\" not a \"c\", but they seem fine to me in\n> general. It's a judgement call, and the judgement is almost always going\n> to be based on how many browsers actually fail the test -- my \"Evil\" tests\n> from back in 99 when I was making the Evil Test Suite were simply the\n> tests that everyone failed, as opposed to the Wet Blanket Tests, which\n> were the tests that only a few people failed and thus \"reduced the\n> enjoyment of others\", as it were.\n> \n> \n>>  * is my lack of consistent wording a problem?  I've written multiple\n>>    variations of the sentences \"This paragraph should have a green\n>>    background.\" and \"The next two paragraphs should look identical.\"\n> \n> That all looked fine to me.\n\n\n\n"
        },
        {
            "subject": "Development of platform-independent applications - workshop more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "CSS Selector",
            "content": "Copying over here since no reply yet on www-style, (I sure hate \ncrossposting though)\n\nJustin Wood wrote:\n\n> Hello,\n>\n> does anyone know of an updated IMPL report tenplate for \n> CSS3-selectors, the one on W3C is from the 200309?? release (can't \n> recall day of month top of my head), the newest test-suite is much \n> newer than that.\n>\n> (Also test 19 for :active is not listed in that report and should be)\n>\n> I was beginning the update myself, then realized that to do such \n> without an easy way to tell xml with namespaces against just plain xml \n> it would be much more work than I really *should* have to do...if \n> there is not *any* updated impl reports, I guess I will be forced to \n> create a new one though.\n>\n> Thanks.\n> ~Justin Wood\n>\n\n\n\n"
        },
        {
            "subject": "Mis-made testcase",
            "content": "CSS3 Selectors:\n\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-90.html\n\nSeems mis-made to me, would not that first 'p' element always be 'color: \nred' based on the code, or am I mistaken.\n\n~Justin Wood (still marking failed based on impl. report rules)\n\n\n\n"
        },
        {
            "subject": "CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-162.html\n\nThis test makes it unclear of what /exactly/ should 'pass' or 'fail'  \n(if cursor is not same for each box would it fail, IE: if cursor is not \ncrosshair for 'tree' in both boxes.\n\nThis should be clarified in test\n\n~Justin Wood (Failing unless response says otherwise)\n\n\n\n"
        },
        {
            "subject": "Re: Mis-made testcase",
            "content": "On Wednesday 2004-05-19 00:48 -0400, Justin Wood wrote:\n> CSS3 Selectors:\n> \n> http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-90.html\n> \n> Seems mis-made to me, would not that first 'p' element always be 'color: \n> red' based on the code, or am I mistaken.\n\nAgreed.  This is an error introduced in the 20040421 revision.  Before\nthat the blockquote contained the text directly rather than having a p\nchild.\n\n-David\n\n-- \nL. David Baron                                <URL: http://dbaron.org/ >\n\n\n\n\n"
        },
        {
            "subject": "Test Bookmark",
            "content": "http://www.chrissysbedroom.com/\nhttp://www.blowjobphone.com/\nhttp://www.livephonedomination.com/\nhttp://www.phonefeminization.com/\nhttp://www.taboophonefetishes.com/\nhttp://your-account.info/\nhttp://www.phone-sex-guestbook.com/\nhttp://www.highclassblondes4phone.com/\nhttp://www.dominatingphonebitches.com/\nhttp://duvx.com/book.php?book=phonesex/\nhttp://www.xanga.com/usa_phone_sex/\nhttp://www.xanga.com/phone_sex_seeker/\nhttp://www.phone-sex-blog.blogspot.com/\nhttp://duvx.com/bbs.php?bbs=phone/\n\n\nhttp://www.angelfire.com/nv/Chess/chess.html\nhttp://www.angelfire.com/pop2/xslt/\nhttp://www.angelfire.com/grrl/edenprosper/\nhttp://www.angelfire.com/nv/violins/violin_bows.html\nhttp://www.angelfire.com/nv/bowling/tips.html\nhttp://www.angelfire.com/tv/julia/julia.louis.dreyfus.html\nhttp://www.geocities.com/gothic_clothes/\nhttp://www.geocities.com/bgreen68/\nhttp://www.megaone.com/supermodel/\nhttp://www.geocities.com/self_hypnosis/\nhttp://www.angelfire.com/goth/razorcandi/\nhttp://www.angelfire.com/nv/violins/violin_books.html\nhttp://www.angelfire.com/grrl/raye/\nhttp://www.angelfire.com/goth/gothic_babe/\nhttp://www.angelfire.com/nv/startpage/\nhttp://www.geocities.com/actress_model_olivia/\nhttp://www.geocities.com/somethings_happening/\nhttp://www.geocities.com/kimmyswebsite/\nhttp://www.geocities.com/monique_modeling/\nhttp://www.angelfire.com/pop2/google-dance-tool/\nhttp://www.angelfire.com/art2/blonde_model/\nhttp://www.angelfire.com/art2/catherine/\n\n\n\nhttp://bloggingtips.blogspot.com\nhttp://chinese-food.blogspot.com\nhttp://bowling-tips.blogspot.com\nhttp://www.xanga.com/ringtones\nhttp://xsl2.blogspot.com\nhttp://www.xanga.com/free_ringtones\nhttp://www.senac.com/forums/4055/\nhttp://www.senac.com/forums/12254/\nhttp://www.senac.com/forums/1310/\nhttp://www.senac.com/forums/5283/\nhttp://www.senac.com/forums/13432/\n\n\n\n"
        },
        {
            "subject": "Low Fixed Cost No.1 Search Engine Ranking for &quot;PORN&quot; related keyword",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Low Fixed Cost No. 1 Search Engine Ranking for keywords related to &quot;porn&quot",
            "content": "This is an HTML message.\n\n\n\n"
        },
        {
            "subject": "Misplaced Tests in Impl Report",
            "content": "These notes are taken off the /full/ tests for the 20040510 testsuite \ntests themselves\n\nXML vs XML w NS is determined solely from the \"XHTML Full\" test list, \nwhich says in it \"UA must support namespaces for this test\" if thats not \nthere, assumed to be both XML and XML w NS.\n\nI am sure some of these tests do not belong in XML for instance \n(:checked as on example) though I am basing this list off the impl \nreport itself, and what _is in_ the tests.   These fixes will be part of \nmy submitted Impl report to Hixie.\n\nXML (does not belong):\n    'type' ~ test 182  (listed as namespace needed)\n    universal '*' ~ test 3 (listed as namespace needed)\n    :not ~ test 174b (listed as namespace needed)\n   \nHTML (does not belong):\n    ~All Belong~\n\nHTML (missing):\n    test 39c (:first-letter with ::before)  [to stick in ::before]\n    test 68 (:not)\n    test 69 (:not)\n\n~~Getting Tired, will finish report later tonight  or tomorrow Day~~\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Re: Misplaced Tests in Impl Report",
            "content": "The rest:\n\nMost of the missing XML and XMLwNS tests likely don't belong in reality, \nthough they /are/ listed in the XML tests list, so I added them back in \nfor this version of the impl report.  If they truely do not belong, \nplease remove them from the test-list.\n\n*NOTES*  I did not check the validity of the placement of tests.  I \nsuggest /this/ implimentation report be updated to reflect this list, \nthough the next iteration of the test-suite should be updated based on \nwhat makes sense, (IE: if the tests are there they should be here \nregardless of if they are correctly placed or not)\n\nMissing from XML:\n\n    single class:  tests 13, 155, 155a, 155b, 155c, 155d, 170b, 175a, \n175b, 175c, 183\n    ID '#':   tests 4 15 15b\n    descendant ' ':   tests 43 43b 181\n    :link:   tests 16\n    :visited:   tests 17\n    :actve link:   tests 19\n    child '>':   tests 44 44b 44c\n    multi-class '.':   tests 14 14b 14c\n    :focus:   tests 20\n    :enabled:   tests 23\n    :disabled:   tests 24\n    :checked:   tests 25\n    :indeterminate:   tests d5 d5a d5d\n    :before:   39c\n    :not:   tests 68 69\n\nXML w/ NS missing:\n        single class:  tests 13, 155, 155a, 155b, 155c, 155d, 170b, \n175a, 175b, 175c, 183\n    ID '#':   tests 4 15 15b\n    descendant ' ':   tests 43 43b 181\n    :link:   tests 16\n    :visited:   tests 17\n    :actve link:   tests 19\n    child '>':   tests 44 44b 44c [NS]86\n    multi-class '.':   tests 14 14b 14c\n    :focus:   tests 20\n    :enabled:   tests 23\n    :disabled:   tests 24\n    :checked:   tests 25\n    :indeterminate:   tests d5 d5a d5d\n    attribute presence: [NS]104b\n    attribute equality: [NS]105b\n    attribute space set: [NS]106b\n    attribute dashed prefix: [NS]107b\n    :before:   39c\n    attribute prefix:  [NS]108b [NS]115b\n    attribute substring: [NS]103b\n    :not:   tests 68 69 [NS]124b  [NS]126b [NS]128b\n\nXHTML (missing):\n    child '>':   86\n    attribute presence: 104b\n    attribute equality: 105b\n    attribute space set: 106b\n    attribute dashed prefix: 107b\n    attribute prefix:  108b 115b\n    attribute substring: 103b\n    :not:  124b  126b 128b\n\nSee: \nhttp://drapostles.hypermart.net/Non_Apostle/Mozilla/implementreportTEMPLATE.html\nfor an updated Template, which I did, also added empty class attributes \nto every 'a' element to assist impl report creators, feel free to use \nmine instead of doing the work yourselves, stylesheet link changed to \ntantek's page rather than downloading the stylesheet locally.\n\nAs an added note what is class=\"f\"  mean?\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Re: Misplaced Tests in Impl Report",
            "content": "Justin Wood wrote:\n\n>\n> The rest:\n>\n> Most of the missing XML and XMLwNS tests likely don't belong in \n> reality, though they /are/ listed in the XML tests list, so I added \n> them back in for this version of the impl report.  If they truely do \n> not belong, please remove them from the test-list.\n>\n> *NOTES*  I did not check the validity of the placement of tests.  I \n> suggest /this/ implimentation report be updated to reflect this list, \n> though the next iteration of the test-suite should be updated based on \n> what makes sense, (IE: if the tests are there they should be here \n> regardless of if they are correctly placed or not)\n>\n> Missing from XML:\n>\n>    single class:  tests 13, 155, 155a, 155b, 155c, 155d, 170b, 175a, \n> 175b, 175c, 183\n>    ID '#':   tests 4 15 15b\n>    descendant ' ':   tests 43 43b 181\n>    :link:   tests 16\n>    :visited:   tests 17\n>    :actve link:   tests 19\n>    child '>':   tests 44 44b 44c\n>    multi-class '.':   tests 14 14b 14c\n>    :focus:   tests 20\n>    :enabled:   tests 23\n>    :disabled:   tests 24\n>    :checked:   tests 25\n>    :indeterminate:   tests d5 d5a d5d\n>    :before:   39c\n>    :not:   tests 68 69\n>\n> XML w/ NS missing:\n>        single class:  tests 13, 155, 155a, 155b, 155c, 155d, 170b, \n> 175a, 175b, 175c, 183\n>    ID '#':   tests 4 15 15b\n>    descendant ' ':   tests 43 43b 181\n>    :link:   tests 16\n>    :visited:   tests 17\n>    :actve link:   tests 19\n>    child '>':   tests 44 44b 44c [NS]86\n>    multi-class '.':   tests 14 14b 14c\n>    :focus:   tests 20\n>    :enabled:   tests 23\n>    :disabled:   tests 24\n>    :checked:   tests 25\n>    :indeterminate:   tests d5 d5a d5d\n>    attribute presence: [NS]104b\n>    attribute equality: [NS]105b\n>    attribute space set: [NS]106b\n>    attribute dashed prefix: [NS]107b\n>    :before:   39c\n>    attribute prefix:  [NS]108b [NS]115b\n>    attribute substring: [NS]103b\n>    :not:   tests 68 69 [NS]124b  [NS]126b [NS]128b\n>\n> XHTML (missing):\n>    child '>':   86\n>    attribute presence: 104b\n>    attribute equality: 105b\n>    attribute space set: 106b\n>    attribute dashed prefix: 107b\n>    attribute prefix:  108b 115b\n>    attribute substring: 103b\n>    :not:  124b  126b 128b\n>\n> See: \n> http://drapostles.hypermart.net/Non_Apostle/Mozilla/implementreportTEMPLATE.html \n>\n> for an updated Template, which I did, also added empty class \n> attributes to every 'a' element to assist impl report creators, feel \n> free to use mine instead of doing the work yourselves, stylesheet link \n> changed to tantek's page rather than downloading the stylesheet locally.\n>\n> As an added note what is class=\"f\"  mean?\n>\n> ~Justin Wood\n>\n>\n>\n>\nerm missing 84 and 84b under :not also, all test types.\n\nWill update my template first thing tomorrow (or today depending on \nwhere you are)\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Re: Misplaced Tests in Impl Report",
            "content": "> erm missing 84 and 84b under :not also, all test types.\n>\n> Will update my template first thing tomorrow (or today depending on \n> where you are)\n>\n> ~Justin Wood\n>\n>\nErm 84 and 84b were under :contains, my mistake...\n\nThough we /are/ missing 123b from the impl report template\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Errors in CSS3 Selectors suit",
            "content": "There are several errors in the 20040510 draft of the CSS3 Selectors test suite [1].\n\nIn particular, at least tests 57, 57b, 97--110, 124-136, 124b-136b [2], all have \nthe same issue, which I will demonstrate based on the markup in test 97.  As \nwritten, test 97 has:\n\n  <q xmlns=\"http://www.example.org/a\" a:title=\"a paragraph\">This paragraph\n     should have a green background.</q>\n  <r xmlns=\"http://www.example.org/b\" b:title=\"a paragraph\">This paragraph\n     should be unstyled.</r>\n\nwhere the \"a\" and \"b\" namespace prefixes are never declared in the document.  I \nbelieve the intent was to have\n\n  <q xmlns:a=\"http://www.example.org/a\" a:title=\"a paragraph\">This paragraph\n     should have a green background.</q>\n  <r xmlns:b=\"http://www.example.org/b\" b:title=\"a paragraph\">This paragraph\n     should be unstyled.</r>\n\ninstead of what the test actually has.\n\nIn fact, the document as written is not well-formed namespaced XML and a \ncompliant namespace-aware XML parser (which I'm sad to discover some browsers \nare not) should throw a well-formedness error on this document.\n\nFailing that, a compliant CSS renderer would render the <q> element with a red \nbackground given the existing markup and CSS for that test.  This applies to the \nXML with namespace and XHTML versions of the test.\n\nI suspect tests 137--143 have similar issues, but I'm out of time for right now...\n\nIn general, it may be easiest to run these tests through a decent \nnamespace-aware XML parser to catch all the well-formedness issues.\n\n-Boris\n\n[1] http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/\n[2] \nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-57.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-57b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-97.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-98.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-99.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-100.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-101.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-102.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-103.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-104.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-105.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-106.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-107.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-108.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-109.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-110.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-124.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-125.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-126.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-127.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-128.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-129.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-130.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-131.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-132.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-133.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-134.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-135.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-136.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-124b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-125b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-126b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-127b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-128b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-129b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-130b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-131b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-132b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-133b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-134b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-135b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-136b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-57.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-57b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-97.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-98.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-99.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-100.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-101.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-102.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-103.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-104.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-105.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-106.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-107.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-108.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-109.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-110.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-124.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-125.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-126.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-127.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-128.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-129.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-130.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-131.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-132.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-133.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-134.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-135.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-136.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-124b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-125b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-126b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-127b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-128b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-129b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-130b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-131b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-132b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-133b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-134b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-135b.xml\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-136b.xml\n\n\n\n"
        },
        {
            "subject": "Another error in the CSS3 Selectors suit",
            "content": "I believe I've found another error in the 20040510 draft of the CSS3 Selectors \ntest suite [1].\n\nTest d3 [2,3] has a very unclear (or just wrong?) description of what should be \nhappening...\n\nThe XML version [2] has a background set on the root element.  This propagates \nto the canvas, making it hard to tell whether the test passes or not.\n\nThe XHTML version [3] says \"The following block should be green\" and has three \nblocks following that text.  Based on the markup and CSS, it seems to me that \nonly the last of these three should be green...  therefore, a compliant UA would \nfail this test (since it would should a block of red and then a block of green).\n\nIt may be worth it, in this test, to differentiate between the <test> that is \nthe subject of the test and the other random <test> nodes in the test....\n\n-Boris\n\n[1] http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/\n[2] \nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-d3.xml\n[3]\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-d3.xml\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selector",
            "content": "On 5/17/04 7:30 PM, \"Justin Wood\" <jw6057@bacon.qcc.mass.edu> wrote:\n\n> \n> Copying over here since no reply yet on www-style, (I sure hate\n> crossposting though)\n\nThis is the right place to post this.\n\n> Justin Wood wrote:\n> \n>> Hello,\n>> \n>> does anyone know of an updated IMPL report tenplate for\n>> CSS3-selectors, the one on W3C is from the 200309?? release (can't\n>> recall day of month top of my head), the newest test-suite is much\n>> newer than that.\n\nThere is an implementation report template for the 20040510 version,\nhopefully it will be uploaded to the w3.org site fairly soon.\n\nTantek\n\n\n\n"
        },
        {
            "subject": "Re: Mis-made testcase",
            "content": "On Wed, 19 May 2004, Justin Wood wrote:\n>\n> CSS3 Selectors:\n>\n> http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-90.html\n>\n> Seems mis-made to me, would not that first 'p' element always be 'color:\n> red' based on the code, or am I mistaken.\n\nOops. Yep. I'll fix that (by changing it to a <div> as in the 90b test).\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "On Wed, 19 May 2004, Justin Wood wrote:\n>\n> http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-162.html\n>\n> This test makes it unclear of what /exactly/ should 'pass' or 'fail'\n> (if cursor is not same for each box would it fail, IE: if cursor is not\n> crosshair for 'tree' in both boxes.\n>\n> This should be clarified in test\n\nGood point. The new text will read:\n\n   <p>Select everything in this document. The following two constructs\n   (in the thick black borders) should end up looking identical. You\n   should also check that the cursor is the same on equivalent parts\n   (in particular the cursor should either be a crosshair over \"Tree\"\n   and the default everywhere else, or the default everywhere).</p>\n\nLet me know if that is clear enough.\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: Errors in CSS3 Selectors suit",
            "content": "On Fri, 28 May 2004, Boris Zbarsky wrote:\n>\n> In particular, at least tests 57, 57b, 97--110, 124-136, 124b-136b [2], all have\n> the same issue, which I will demonstrate based on the markup in test 97.  As\n> written, test 97 has: [an undeclared prefix]\n\nOops, minor logic error in the mess that is my parser code. Will be fixed\nin the next test suite release.\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: Mis-made testcase",
            "content": "Ian Hickson wrote:\n\n>On Wed, 19 May 2004, Justin Wood wrote:\n>  \n>\n>>CSS3 Selectors:\n>>\n>>http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-90.html\n>>\n>>Seems mis-made to me, would not that first 'p' element always be 'color:\n>>red' based on the code, or am I mistaken.\n>>    \n>>\n>\n>Oops. Yep. I'll fix that (by changing it to a <div> as in the 90b test).\n>\n>  \n>\nBy: \"I'll fix that\" I sure hope you mean for the /next/ release of the \ntestsuite ;-)\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "Ian Hickson wrote:\n\n>On Wed, 19 May 2004, Justin Wood wrote:\n>  \n>\n>>http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-162.html\n>>\n>>This test makes it unclear of what /exactly/ should 'pass' or 'fail'\n>>(if cursor is not same for each box would it fail, IE: if cursor is not\n>>crosshair for 'tree' in both boxes.\n>>\n>>This should be clarified in test\n>>    \n>>\n>\n>Good point. The new text will read:\n>\n>   <p>Select everything in this document. The following two constructs\n>   (in the thick black borders) should end up looking identical. You\n>   should also check that the cursor is the same on equivalent parts\n>   (in particular the cursor should either be a crosshair over \"Tree\"\n>   and the default everywhere else, or the default everywhere).</p>\n>\n>Let me know if that is clear enough.\n>\n>  \n>\nSounds good, but my marking 'should' that implies (at least to me) that \nit /is/ still possible to pass if the cursor is not the same, even on a \nUA that supports cursor.  The pass/fail criteria is more what I was \nlooking at in that test.\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Re: Another error in the CSS3 Selectors suit",
            "content": "On Fri, 28 May 2004, Boris Zbarsky wrote:\n>\n> Test d3 [2,3] has a very unclear (or just wrong?) description of what should be\n> happening... [...]\n>\n> It may be worth it, in this test, to differentiate between the <test> that is\n> the subject of the test and the other random <test> nodes in the test....\n\nYeah, good point. The new test is more like this:\n\n   [test] { background: red; display: block; padding: 1em; }\n   stub ~ [|attribute^=start]:not([|attribute~=mid])[|attribute*=dle][|attribute$=end] ~ t { background: lime; }\n\n   ...\n\n  <!-- root of selector -->\n  <stub xmlns=\"\"></stub>\n\n  <!-- middle part of selector does not match this -->\n  <t xmlns=\"\" attribute=\"fake\"></t>\n\n  <!-- middle part of selector matches this once attribute is fixed -->\n  <t xmlns=\"\" attribute=\"start mid dle end\"></t>\n\n  <!-- subject of selector -->\n  <t xmlns=\"\" test=\"test\"></t>\n\nIt'll get uploaded with the next update.\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "On Sat, 29 May 2004, Justin Wood wrote:\n>>\n>> Good point. The new text will read:\n>>\n>>   <p>Select everything in this document. The following two constructs\n>>   (in the thick black borders) should end up looking identical. You\n>>   should also check that the cursor is the same on equivalent parts\n>>   (in particular the cursor should either be a crosshair over \"Tree\"\n>>   and the default everywhere else, or the default everywhere).</p>\n>>\n>> Let me know if that is clear enough.\n>\n> Sounds good, but my marking 'should' that implies (at least to me) that\n> it /is/ still possible to pass if the cursor is not the same, even on a\n> UA that supports cursor.  The pass/fail criteria is more what I was\n> looking at in that test.\n\n\"Should\" means it is a requirement. It's English. :-) (The test suite\ndoesn't refer to RFC2119.)\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "Ian Hickson wrote:\n\n>On Sat, 29 May 2004, Justin Wood wrote:\n>  \n>\n>>>Good point. The new text will read:\n>>>\n>>>  <p>Select everything in this document. The following two constructs\n>>>  (in the thick black borders) should end up looking identical. You\n>>>  should also check that the cursor is the same on equivalent parts\n>>>  (in particular the cursor should either be a crosshair over \"Tree\"\n>>>  and the default everywhere else, or the default everywhere).</p>\n>>>\n>>>Let me know if that is clear enough.\n>>>      \n>>>\n>>Sounds good, but my marking 'should' that implies (at least to me) that\n>>it /is/ still possible to pass if the cursor is not the same, even on a\n>>UA that supports cursor.  The pass/fail criteria is more what I was\n>>looking at in that test.\n>>    \n>>\n>\n>\"Should\" means it is a requirement. It's English. :-) (The test suite\n>doesn't refer to RFC2119.)\n>\n>  \n>\nRegardless Hixie, with the rest of W3C using the RFC defs, and the \ntestsuite not, it is misleading to potential test-suite users.\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Suggested additions to CSS3 Selectors test suit",
            "content": "I was comparing Mozilla's list of known selector bugs to the CSS Selectors test \nsuite, and I found a few bugs that were not caught by the suite.  The list \nfollows, with links to relevant testcases:\n\nInteraction of :hover and ::first-line/letter:\n   http://bugzilla.mozilla.org/attachment.cgi?id=149591&action=view\n   http://bugzilla.mozilla.org/attachment.cgi?id=149592&action=view\n\nDOM changes and their interaction with :first/last-child:\n   http://bugzilla.mozilla.org/attachment.cgi?id=149594&action=view\n   http://bugzilla.mozilla.org/attachment.cgi?id=149595&action=view\n\nDynamic handling of :empty.  The test suite tests addition of content, but not \nremoval.  A more exhaustive testcase can be found at:\n   http://bugzilla.mozilla.org/attachment.cgi?id=127688&action=view\n\n::before/::after content on table display types:\n   http://www.ludd.luth.se/~leijon/cv/demo/demo.xml\n\n::first-letter on list items, when list-style-position is \"inside\":\n   http://bugzilla.mozilla.org/attachment.cgi?id=132998&action=view\n\nDynamic handling of the '+' combinator when the DOM mutates:\n   http://bugzilla.mozilla.org/attachment.cgi?id=139253&action=view\n\nBehavior of ::selection if no rules are specified for it:\n   http://bugzilla.mozilla.org/attachment.cgi?id=141280&action=view\n\nThere are also some things that do work in Mozilla but are not tested by the \nsuite.  For example, :link and :visited matching XLinks (assuming XLinks are \nsupported at all):\n   http://web.mit.edu/bzbarsky/www/testcases/css-selectors/xlinkStyling2.xml\n\nMatching of :link when dealing with malformed URIs (this is dependant on the UA \nnot treating such links as links, of course...\n   See http://bugzilla.mozilla.org/show_bug.cgi?id=229700\n\nAs a general comment, I see very few tests that test selectors in the face of \ndynamic changes (eg having :hover::before styles, scripted changes to the DOM, \netc).  I think that almost every static testcase in the test suite should have a \ndynamic counterpart or several such.  For example, there should be contains() \ntests that mutate the document by inserting, deleting, appending text, thus \ncausing contains() to match or not match (that's 6 tests, that could all be part \nof a single test page, of course).  As things stand, one could have a very buggy \ncontains() implementation that would work on small HTML documents and pass the \ntest suite, but fail spectacularly on a large document if incremental rendering \nis done...  Similar arguments apply to the :nth-* selectors.  Similarly for \ndynamic changes to href leading to changed :link/:visited matching, changes to \nattributes when various combinators are used, and so forth.\n\nI can help write such dynamic versions of tests in July, but not until then...\n\n-Boris\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "On Sat, 29 May 2004, Justin Wood wrote:\n>\n> Regardless Hixie, with the rest of W3C using the RFC defs, and the\n> testsuite not, it is misleading to potential test-suite users.\n\nWhat would you put instead? \"Must\" is plainly wrong, from an English\nperspective. If the UA is buggy, the test must be red, not green. (Or\nwhatever the criteria is.)\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "Ian Hickson wrote:\n\n>On Sat, 29 May 2004, Justin Wood wrote:\n>  \n>\n>>Regardless Hixie, with the rest of W3C using the RFC defs, and the\n>>testsuite not, it is misleading to potential test-suite users.\n>>    \n>>\n>\n>What would you put instead? \"Must\" is plainly wrong, from an English\n>perspective. If the UA is buggy, the test must be red, not green. (Or\n>whatever the criteria is.)\n>\n>  \n>\nI'm not sure, but clarifying the pass/fail a bit more can't hurt:\n\n    \"If your UA uses a pointing device, the cursor must be [......] \notherwise this test fails.\"\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "On Sat, 29 May 2004, Justin Wood wrote:\n>\n> I'm not sure, but clarifying the pass/fail a bit more can't hurt:\n>\n>     \"If your UA uses a pointing device, the cursor must be [......]\n>     otherwise this test fails.\"\n\nIMHO,\n\n   \"X must be Y otherwise the test has failed\"\n\n...and:\n\n   \"X should Y\"\n\n...mean the same thing except the latter is much easier to understand.\n\nI really don't see the advantage of changing this. Almost every test says\n\"should\". If someone doesn't understand that \"This line should be green.\"\nmeans that if it isn't green the test has failed, then someone should\nexplain that to them, because they're going to have trouble ever finding\na failure.\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: Suggested additions to CSS3 Selectors test suit",
            "content": "On Sat, 29 May 2004, Boris Zbarsky wrote:\n>\n> I was comparing Mozilla's list of known selector bugs to the CSS\n> Selectors test suite, and I found a few bugs that were not caught by the\n> suite.  The list follows, with links to relevant testcases: [...]\n\nIt would be nice to add those tests. I won't have time to do this soon\n(I'm working on getting a basic CSS2.1 test suite up so that we can then\ninvite input for that test suite) but in the meantime if people want to\nadd tests to the selectors test suite the instructions on how to write the\ntests are at the bottom of:\n\n   http://hixie.ch/tests/evil/css/selectors/source/\n\nYou can also see the source files for the existing tests in that\ndirectory.\n\nPlease try to follow the CSS2.1 test case authoring guidelines in general\n(except for the format of course) when writing tests. :-)\n\nNote that before any tests are added the working group will have to agree\nto adding the tests, so it's not an automatic process.\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: Suggested additions to CSS3 Selectors test suit",
            "content": "Boris Zbarsky wrote:\n> Interaction of :hover and ::first-line/letter:\n>   http://bugzilla.mozilla.org/attachment.cgi?id=149592&action=view\n\nMake that http://bugzilla.mozilla.org/attachment.cgi?id=149597&action=view\n\n-Boris\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "Ian Hickson wrote:\n\n>On Sat, 29 May 2004, Justin Wood wrote:\n>  \n>\n>>I'm not sure, but clarifying the pass/fail a bit more can't hurt:\n>>\n>>    \"If your UA uses a pointing device, the cursor must be [......]\n>>    otherwise this test fails.\"\n>>    \n>>\n>\n>IMHO,\n>\n>   \"X must be Y otherwise the test has failed\"\n>\n>...and:\n>\n>   \"X should Y\"\n>\n>...mean the same thing except the latter is much easier to understand.\n>\n>I really don't see the advantage of changing this. Almost every test says\n>\"should\". If someone doesn't understand that \"This line should be green.\"\n>means that if it isn't green the test has failed, then someone should\n>explain that to them, because they're going to have trouble ever finding\n>a failure.\n>\n>  \n>\nWell as far as I am concerned, (completely my opinion) the other tests, \nsay should, along with /one/ feature tested...the one in question says \n\"check that they look the same, \" for the selection AND it says that the \ncursor should be the same, which usually is ok, but with the text as is, \nis a bit misleading....perhaps splitting the two /features/ then?\n\n~Justin Wood\n\n\n\n"
        },
        {
            "subject": "Re: CSS Selectors &ndash;&ndash; clarification requeste",
            "content": "On Sat, 29 May 2004, Justin Wood wrote:\n>\n> Well as far as I am concerned, (completely my opinion) the other tests,\n> say should, along with /one/ feature tested...\n\nSeveral say \"This line should be green\" more than once.\n\n\n> the one in question says \"check that they look the same, \" for the\n> selection AND it says that the cursor should be the same, which usually\n> is ok, but with the text as is, is a bit misleading....perhaps splitting\n> the two /features/ then?\n\nThere is only one feature being tested (::selection). It's just being\ntested in multiple scenarios at once.\n\n-- \nIan Hickson               U+1047E                )\\._.,--....,'``.    fL\nhttp://ln.index.ch/       U+263A                /,   _.. \\   _\\  ;`._ ,.\nThings that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "[css3selectors] tests should not depend on the ability to style  widget",
            "content": "The tests for the selectors ':enabled', ':disabled', ':checked',\n':indeterminate' [1] all require that the UA allows styling of widgets\nthat are mostly painted by the OS.\n\nMost UA's allow limited styling for widgets, like 'background-color' et\ncetera, but don't allow it for _all_, like for example\ninput[type=checkbox] which is often used in the tests.\n\nOther UA's don't allow styling it all for widgets, since there isn't (1)\n  a specification available which describes how it should be done and\n(2) the OS might not allow styling for widgets, since it has a style\nguidelines for software (this is true for the Mac I believe).\n\nA simple example:\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-25.html>\n\nOne test that would show if the UA implemented is:\n\n    input:checked + span{ }\n\nNote that this make the test case more difficult, since two selectors\nare used, so the test cases should probably be duplicated.\n\n(I choose this example since Mozilla does support ':checked', but it\ndoesn't allow styling for input[type=text]. When ':checked' was\nimplemented however there was also a bug with ':pseudo-element +' (not\ndynamically updated iirc...) so the test case above failed as well until\nthey fixed that other bug. One needs to look into this imo.)\n\n[1]\n':enabled'\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-23.html>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-23.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-23.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-23.xml>\n':disabled'\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-24.html>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-24.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-24.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-24.xml>\n':checked'\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-25.html>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-25.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-25.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-25.xml>\n':indeterminate'\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-d5.html>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-d5.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-d5.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-d5.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-d5a.html>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-d5a.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-d5a.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-d5a.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/html/tests/css3-modsel-d5d.html>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-d5d.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xml/tests/css3-modsel-d5d.xml>\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/20040510/xhtml/tests/css3-modsel-d5d.xml>\n\n\n-- \n  Anne van Kesteren\n  <http://annevankesteren.nl/>\n\n\n\n"
        },
        {
            "subject": "[css3selectors] :contain",
            "content": "I was wondering a bit about ':contains' [1]. What should be the \nbackground-color  in the following cases:\n\n\n   <test/>\n\n   test{                   background:red  }\n   test::before{           content:\"PASS\"  }\n   test:contains('PASS'){  background:lime }\n\n\n   <test/>\n\n   test{                   background:red  }\n   test::before{           content:\"PA\"    }\n   test::after{            content:\"SS\"    }\n   test:contains('PASS'){  background:lime }\n\n\n   <test>SS</test>\n\n   test{                   background:red  }\n   test::before{           content:\"PA\"    }\n   test:contains('PASS'){  background:lime }\n\n\nThese cases could be extended with instances of ':hover', ':active', \n':focus' to make it more complex of course. Just to be sure, the \nfollowing won't match, right?\n\n\n   <test>&amp;</test>\n\n   test:contains('&amp;'){ background:red  }\n\n\nI think these issues need to be addressed in the selectors test suite as \nwell.\n\n\n[1] \n<http://www.w3.org/TR/2001/CR-css3-selectors-20011113/#content-selectors>\n\n-- \n  Anne van Kesteren\n  <http://annevankesteren.nl/>\n\n\n\n"
        },
        {
            "subject": "Re: [css3selectors] :contain",
            "content": "Anne van Kesteren (fora) wrote:\n> I was wondering a bit about ':contains' [1]. What should be the \n> background-color  in the following cases:\n> \n> \n>   <test/>\n> \n>   test{                   background:red  }\n>   test::before{           content:\"PASS\"  }\n>   test:contains('PASS'){  background:lime }\n\n   Content generated with the ::before and ::after pseudo-elements does \nnot actually modify the content of the element; only the way it is \npresented, and thus does not affect whether or not another selector \nmatches.  The background colour should be red.\n\n> Just to be sure, the following won't match, right?\n> \n>   <test>&amp;</test>\n> \n>   test:contains('&amp;'){ background:red  }\n\n   &amp; is an HTML/XML entity, not a CSS entity, so it would not be \nconverted to an ampersand while parsing the CSS.  Therefore the selector \nwould not match your test element.  I expect that it would, however, \nmatch this:\n<test>&amp;amp;</test>\n\n-- \nLachlan Hunt\n\nhttp://www.lachy.id.au/\nlachlan.hunt@lachy.id.au\n\n\n\n"
        },
        {
            "subject": "Re: [css3selectors] :contain",
            "content": ">   Content generated with the ::before and ::after pseudo-elements does \n> not actually modify the content of the element; only the way it is \n> presented, and thus does not affect whether or not another selector \n> matches.  The background colour should be red.\n\nI see. How about:\n\n\n   <test/>\n\n   test{                  background:red;\n                          content:\"PASS\"  }\n   test:contains('PASS'){ background:lime }\n\n\nPersonally, I don't see a difference here and I think that they all \nshould have a green background (which stands for PASS, obviously). \nEspecially since ':first-letter' _does_ apply to '::before'. That would \nlead to incosinstency between selectors, something you should avoid, imo.\n\n\n>> Just to be sure, the following won't match, right?\n>>\n>>   <test>&amp;</test>\n>>\n>>   test:contains('&amp;'){ background:red  }\n> \n> \n>   &amp; is an HTML/XML entity, not a CSS entity, so it would not be \n> converted to an ampersand while parsing the CSS.  Therefore the selector \n> would not match your test element.  I expect that it would, however, \n> match this:\n> <test>&amp;amp;</test>\n\nThat would be logical if the first has a 'red' background, which it \nshould have according to the XML parsing rules. I see authors, and maybe \nimplementors make mistakes with this though (Opera did) and therefore it \nmight be good to add it to the official test suite.\n\n\n-- \n  Anne van Kesteren\n  <http://annevankesteren.nl/>\n\n\n\n"
        },
        {
            "subject": "Re: [css3selectors] :contain",
            "content": "Anne van Kesteren (fora) wrote:\n\n> \n>>   Content generated with the ::before and ::after pseudo-elements does \n>> not actually modify the content of the element; only the way it is \n>> presented, and thus does not affect whether or not another selector \n>> matches.  The background colour should be red.\n> \n> \n> I see. How about:\n> \n> \n>   <test/>\n> \n>   test{                  background:red;\n>                          content:\"PASS\"  }\n>   test:contains('PASS'){ background:lime }\n> \n> \n> Personally, I don't see a difference here and I think that they all \n> should have a green background (which stands for PASS, obviously). \n\n   That's right, there is no difference.  The generated content doesn't \nactually affect the contents of the element in the document, only the \nway it is presented.  Thus, they all should be red.\n\nWhat about this:\n<test>foo</test>\n\ntest:contains('foo') { content: 'bar' }\n\n   According to your logic, first the selector would match, the contents \nwould be changed, then it would no longer match, so it would be changed \nback, then it would match again...\n\n-- \nLachlan Hunt\n\nhttp://www.lachy.id.au/\nlachlan.hunt@lachy.id.au\n\n\n\n"
        },
        {
            "subject": "Re: [css3selectors] :contain",
            "content": "On Sunday 2004-05-30 14:35 +0200, Anne van Kesteren (fora) wrote:\n> >  Content generated with the ::before and ::after pseudo-elements does \n> >not actually modify the content of the element; only the way it is \n> >presented, and thus does not affect whether or not another selector \n> >matches.  The background colour should be red.\n\n> Personally, I don't see a difference here and I think that they all \n> should have a green background (which stands for PASS, obviously). \n\nThis contradicts the entire model of CSS processing -- selectors are\nmatched against the content, declarations from the matching rules are\ncascaded to determine the specified values, and then values are\ncomputed.\n\nFurthermore, I don't see a use case for your proposal.  Generated\ncontent is unlikely to contain text like this since generated content\nshould not be used for things that are essential to viewing the document\n(such as adding text).  It should only be used for things that are\nstylistic (e.g., changing the list-numbering style).\n\n> Especially since ':first-letter' _does_ apply to '::before'. That would \n> lead to incosinstency between selectors, something you should avoid, imo.\n\nPseudo-elements are very different from pseudo-classes.  Pseudo-classes\nare just selectors:  they affect whether an element matches the\nselector.  Pseudo-elements are styling specific parts of an element, but\nthe selector matching process for pseudo-elements essentially occurs\nwithout the pseudo-element.\n\n\nAlso, cross-posting between www-style and public-css-testsuite is almost\nnever the right thing to do, especially since the membership of the\ntwo lists is quite similar.  This discussion belongs on www-style.\n\n-David\n\n-- \nL. David Baron                                <URL: http://dbaron.org/ >\n\n\n\n\n"
        },
        {
            "subject": "Release 0.7.3 and bug summar",
            "content": "Cwm release 0.7.3 was made today, 2004-06-08\n\nMostly inspired by the idea that releases should happen more often, as \nwell as in order to give me an idea of what it takes to make a release, \nthis release has several bugfixes.\n\nIf you missed release 0.7.2, that was because it was never announced.\n\nAll changes listed below are  shamelessly copied from \nhttp://www.w3.org/2000/10/swap/doc/changes.html\n\nchanges sinces 0.7.2:\n\n\n        HTTP errors\n\nCwm now correctly identifies HTTP 404 errors, throwing an exception, and \ndoes not try to parse the returned (HTML) file.\n\n\n        Reflexive statements now work\n\n\n        An n3 statement which references the same universal quantifier\n        twice now does the right thing.\n\nChanges since 0.7.1:\n\nOoops - nodeID was misspelled nodeid on RDF/XML output.\n\n\n        Patch functionality\n\nThe |--patch=/patchfile/| command line argument allows a patch file to \nbe applied to the knowledge base (current working formula). See the \nDiff, Patch, Update and Sync <http://www.w3.org/DesignIssues/Diff> note \nin the /Design Issues/ series on the motivation for exchanging \ndifference files, and how they work. Diff files can in certain specific \ncircumstances (a well-labeled graph) be produced by the diff.py program \nincluded with this distribution. The new tests are in \n$SWAP/test/delta/detailed.tests\n\n\n        Internationization undefined, Numerics canonicalized\n\nThe i18n/detailed.tests have been removed from the test harness. They \nwere not right, and URI/ IRI issues are not clear yet. It is not clear \nwhether cwm should URI-canonicalize, or IRI-canonicalize. (My instinct \nis that it should - Tim).\n\nCwm does not canonicalize numerical (xsd:double and xsd:integer) values \non N3 output. It uses python's str(float(s)) and str(int(s)). The effect \nis to reduce some over-precision in the output.\n\nYosi Scharf\n\n\n\n"
        },
        {
            "subject": "new lis",
            "content": "List_Name: public-cwm-announce\n\nListPurpose: Moderated list of announcements about <a\nhref=\"\"http://www.w3.org/2000/10/swap/doc/cwm.html>cwm</a>, of general\ninterest to cwm users and prospective users.\n\nMaintaining_Activity: Semantic Web\n\n-- \nDaigo Matsubara / W3C Systems Team / mailto:daigo@w3.org\n\n\n\n"
        },
        {
            "subject": "Cwm, a general purpose data processor for the Semantic Web: Release 0.",
            "content": "We're pleased to announce cwm release 0.7.\n\nWhat is cwm?\n\nCwm is a general-purpose data processor for the semantic web, somewhat\nlike sed, awk, etc. for text files or XSLT for XML. It is a forward\nchaining reasoner which can be used for querying, checking, transforming\nand filtering information. Its core language is RDF, extended to include\nrules, and it uses RDF/XML or RDF/N3 serializations as required.\n\nThe cwm home page is\n   http://www.w3.org/2000/10/swap/doc/cwm.html\n\nFor upcoming releases, status reports, etc., stay tuned to\n   http://lists.w3.org/Archives/Public/public-cwm-announce/\n\n\nWhat features does cwm 0.7 have?\n--------------------------------\n\n* Loading files in RDF/XML and/or N3, generating RDF or N3 files from\nthe result.\n       * Pretty printing data so that anonymous nodes are used creatively\n         to minimize the number of explicit existentials (generated Ids).\n       * Applying rules written in N3 to the data\n       * Filtering the data to the result of a particular query\n       * Generating arbitrary formats (using --strings)\n       * Using an internal knowledge of functions to resolve them within\n         a query, including:\n               * Simple math and string operations\n               * Getting and parsing documents from the web\n               * Accessing command line arguments and environment\n                 variables\n               * Cryptography: hashing, generating keys, signing things\n                 and checking signatures.\n\nThose features are covered by the cwm/N3 tutorial.\n   http://www.w3.org/2000/10/swap/doc/\n\nOther features are in development, and haven't been documented as\nthoroughly:\n\n       * Accessing the web to directly or indirectly resolve a query,\n         including:\n               * Getting schemas for terms in the query\n               * Using metadata to point to definitive documents\n               * Looking up data in local or remote SQL servers\n\n\nHow do I get started?\n---------------------\n\nWe plan to have .tgz and/or .deb packages for future\nreleases; for this release, grab the release from CVS:\n\n$ cvs -d:pserver:anonymous@dev.w3.org:/sources/public login\npassword? anonymous\n$ cvs -d:pserver:anonymous@dev.w3.org:/sources/public get 2000/10/swap\n\nYou can restore/upgrade  your software specifically to this release by\nin that directory\n\n$ cvs update -r release-0-7\n\nTest that it's working:\n\n$ cd test\n$ make\n\nAll the tests should pass. Some of the tests are good examples\nto study. Some are just regression tests to make sure old bugs\ndon't come back.\n\nFor an organized presentation of (most of) cwm's functionality,\nsee the tutorial...\n   http://www.w3.org/2000/10/swap/doc/\n\n\nHow can I get involved? Where do I send bug reports?\n----------------------------------------------------\n\nWe're interested in contributions to the code, the\ndocumentation, and the tests.\n\nSee the cwm home page\n   http://www.w3.org/2000/10/swap/doc/cwm.html\n\n\nLicence\n---------\nCwm: http://www.w3.org/2000/10/swap/doc/cwm.html\n\nCopyright ?  2000-2004 World Wide Web Consortium, (Massachusetts \nInstitute of Technology, European Research Consortium for Informatics \nand Mathematics, Keio University). All Rights Reserved. This work is \ndistributed under the W3C? Software License [1] in the hope that it \nwill be useful, but WITHOUT ANY WARRANTY; without even the implied \nwarranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n[1] http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231\n\nTim Berners-Lee, Dan Connolly, Sandro Hawke\n\n\n\n"
        },
        {
            "subject": "Release 0.7.1 and bug summar",
            "content": "Cwm release 0.7.1 was made today 2004-03-04.\n\nIt was inspired by bug fixes and one thing leading to another.\nMost of the changes are in the RDF/XML and N3 parsers and generators.\nThe following details are also in\nhttp://www.w3.org/2000/10/swap/doc/changes.html\n\nBugs in public-n3-bugs@w3.org\nhttp://lists.w3.org/Archives/Public/public-cwm-bugs\nare currently all closed. Many bugs from the previous generation of\nbug reports (to www-archive+n3bugs@w3.org) are still open\nhttp://www.w3.org/2000/10/swap/admin/N3-Bugs.ics\nthough many may be out of date. I have yet to do a triage on them.\n\n\nThere was a bug that xml:base was not resepcted in the default parser.\n\nRather than generate a new test for xml:base, it seemed more \nappropriate to revist the RDF Core parser tests.  The regression test \nengine will run off these tests, but they had not been incorporated \ninto the regression test. They now have.\n\nThe cant.py NTriple canonicalizer which is used for testing had a bug, \nwhich is now fixed. While being fixed, cant.py was enhanced to do an \ninternal canonicalization and then comparison of two files  (python \ncant.py -f file1 -d file2) to have having to canonicalize the two files \nand then compare them.  This makes the tests faster.\n\nThings which are not testd in regression test at the moment include  \nrdflib as a parser,  --closure= flags, and the API.\n\nRDF Parser improved\n\nThe cwm regresssion test now incorporates the RDF Core Positive Parser \nTests except for those  which deal with reification or with XML \nliterals. In the process, xml:base supposrt was added in the parser.\n\nA new test found in the updated core tests requires RDF to be parsed \neven when there is no enveloping <rdf:RDF> tag, even if the outermost \nelement is a typed node production, and so not something in the RDF \nnamespace at all. This makes rdf much less self-describing, and makes \nit more dangerous that one might parse say an HTML file as RDF by \naccident. Use with care.  If need this feature, use the --rdf=R flag.\n\nThe RDF core tests are done with --rdf=RT to make the parser parse \nnaked RDF or RDF buried in foreign XML..\n\nnodeid generated on RDF output\n\nThis has been a missing feature of the RDF generator for a while. The \nnodeid feature allows bnodes to be output in RDF/XML. I may not have \ngot this right, as I don't have RDF generation tests, only RDF parse \ntests.\n\nOrdering of output\n\nThe ordering of Terms has been changed. Automatically generated terms \nwith no URIs sort after anything which has a URI.\nThis will change the order of N3 and RDF/XML output but does not change \nits semantics.s\n\nNamespace prefix smarts on output\n\nCwm now does output in a two-pass process. This makes its counting of \nthe number of occurrences of namespaces more acurate, which determines \nthe default namespace it choses. This does take more time, though not \nas long as the previous method of working out which was going to be \nmost common. To skip this process, use the \"d\" flag on output (N3 or \nRDF/XML) to suppress the use of a default namespace.\nBecause this counting is now accurate, it now suppresses namespace \nprefix declarations which are not actually needed in the output.\n\nCwm will also make up prefixes when it needs them for a namespace, and \nnone of the input data uses one. It peeks into the the namespace URI, \nand looks around for a short string after the last \"/\", adding numbers \nif necessary to make the prefix unique.\n\nNamespaces without hashes\n\nCwm when writing N3 not normally use namespace names for URIs which do \nnot have a \"#\". Including a \"/\" in the flags overrides this.\ncwm mydcdata.n3 --n3=\"/\" Namespaces which end in \"/\" are \narchitecturally flawed as the names of things in the namespace look \nlike HTTP documents, whatever they are. The most notorious miscreatnts \nhere are Dublin Core and FOAF. If you use these namespaces, you may \nwant to do this, or you may want to encourage the authors to change to \nuse a \"#\n\n\nTim BL\n\n\n\n"
        },
        {
            "subject": "Re: 0.7.1 fails in math/detailed.tests#t1039",
            "content": "This is a python2.3 change.  Python declares it an error, instead of \nreturning NaN.\nI guess this means that we should do regression tests using >1 version \nof python.\n\nTim\\\n\n\nOn Mar 9, 2004, at 18:13, Dan Connolly wrote:\n\n>\n> I tried the new release; failed thusly:\n>\n> connolly@dirk:~/w3ccvs/WWW/2000/10/swap/test$ make\n> rm -f ../*.pyc\n> touch pyc-check\n> PYTHONPATH=`/bin/pwd`/.. python retest.py -c regression.n3\n> list/detailed.tests online.tests math/detailed.tests \n> norm/detailed.tests\n> cwm/detailed.tests i18n/detailed.tests ntriples/detailed.tests\n> rdfcore-tests.n3 testmeta.n3\n> retest.py:35: DeprecationWarning: Non-ASCII character '\\xc2' in file\n> /home/connolly/w3ccvs/WWW/2000/10/swap/llyn.py on line 38, but no\n> encoding declared; see http://www.python.org/peps/pep-0263.html for\n> details\n>   import llyn\n>   1/205 cwm/detailed.tests#cwm001       Use think=rules.n3 to iterate\n> using separate rules\n>   2/205 i18n/detailed.tests#int001      N3 string, qname and IRI with\n> utf-8 non-ascii characters\n>   3/205 i18n/detailed.tests#int002      N3 string, qname and IRI with\n> utf-8 non-ascii. N3 to XML\n>   4/205 i18n/detailed.tests#int003      XML to XML with utf-8 non-ascii\n> characters\n>   5/205 list/detailed.tests#t1017       parsing and generation of N3\n> list syntax  6/205 list/detailed.tests#t1018       conversion of N3 \n> list\n> syntax to RDF\n>   7/205 list/detailed.tests#t1018b1     List processing bug check 1\n>   8/205 list/detailed.tests#t1018b2     List processing bug check 2\n>   9/205 list/detailed.tests#t1020       What to do with URI-labelled\n> lists\n>  10/205 list/detailed.tests#t1031       Inference using lists\n>  11/205 list/detailed.tests#t1032a      Query with list with the same\n> var in >once\n>  12/205 list/detailed.tests#t2004u1     List unification 1\n>  13/205 list/detailed.tests#t2004u2     List unification 2 - variable \n> in\n> list\n>  14/205 list/detailed.tests#t2004u3     List unification 3 - nested\n> lists\n>  15/205 list/detailed.tests#t2004u4     List unification 4 - nested\n> lists\n>  16/205 list/detailed.tests#t2005       Iterative ops on lists\n>  17/205 list/detailed.tests#t2006       last, in builtins on lists\n>  18/205 math/detailed.tests#t10393      Various math builtins\n>  19/205 math/detailed.tests#t10394      Various trig builtins\n> Traceback (most recent call last):\n>   File \"../cwm.py\", line 636, in ?\n>     doCommand()\n>   File \"../cwm.py\", line 507, in doCommand\n>     think(workingContext, mode=option_flags[\"think\"])\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 58, in\n> think\n>     return InferenceTask(knowledgeBase, ruleFormula, mode=mode,\n> repeat=1).run()\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 210, in\n> run\n>     return self.runSmart()\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 198, in\n> runSmart\n>     total += cy.run()\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 306, in\n> run\n>     return rule.once()\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 405, in\n> once\n>     total = query.resolve()\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 546, in\n> resolve\n>     return self.unify(self.queue, self.variables, self.existentials)\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 782, in\n> unify\n>     bindings.copy(), nb, evidence = evidence + [reason])\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 713, in\n> unify\n>     nbs = item.tryBuiltin(queue, bindings, heavy=0, evidence=evidence)\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 997, in\n> tryBuiltin\n>     result = pred.evalSubj(obj, queue, bindings.copy(), proof,\n> self.query)\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/term.py\", line 868, in\n> evalSubj\n>     return self.store._fromPython(self.evaluateSubject(obj.value()))\n>   File \"/home/connolly/w3ccvs/WWW/2000/10/swap/cwm_trigo.py\", line 63,\n> in evaluateSubject\n>     return acos(numeric(x))\n> ValueError: math domain error\n> Files differ, result= 256\n> #  If this is OK,   cp ,temp/detailed.tests_t10394.out \n> math/trigo.ref.n3\n> ######### Differences from reference output:\n> --- math/trigo.ref.n3   2004-03-06 14:39:42.000000000 -0600\n> +++ ,temp/detailed.tests_t10394.out     2004-03-09 17:04:58.000000000\n> -0600\n> @@ -1,58 +0,0 @@\n> -     @prefix : <#> .\n> -\n> -    -0.707     a :TestValue;\n> -         :ACOS 2.3560434901900495;\n> -         :ASIN -0.78524716339515299;\n> -         :ATAN -0.6154085176292563;\n> -         :COS 0.76031396174443966;\n> -         :COSH 1.2605098866758351;\n> -         :SIN -0.64955575555642242;\n> -         :SINH -0.76738854200953921;\n> -         :TAN -0.85432569732917008;\n> -         :TANH -0.60879216428303051 .\n> -\n> -    0.23     a :TestValue;\n> -         :ACOS 1.3387186439321834;\n> -         :ASIN 0.23207768286271319;\n> -         :ATAN 0.22606838799388393;\n> -         :COS 0.97366639500537489;\n> -         :COSH 1.0265668062164059;\n> -         :SIN 0.22797752353518841;\n> -         :SINH 0.2320332037130719;\n> -         :TAN 0.2341433623514653;\n> -         :TANH 0.22602835227867096 .\n> -\n> -    1.23     a :TestValue;\n> -         :ACOS nan;\n> -         :ASIN nan;\n> -         :ATAN 0.88817377437767964;\n> -         :COS 0.33423772712450261;\n> -         :COSH 1.8567610569852664;\n> -         :SIN 0.94248880193169748;\n> -         :SINH 1.564468479304407;\n> -         :TAN 2.8198157342681518;\n> -         :TANH 0.84257932565892957 .\n> -\n> -    3.1415926535897931     a :Pi,\n> -                :TestValue;\n> -         :ACOS nan;\n> -         :ASIN nan;\n> -         :ATAN 1.2626272556789118;\n> -         :COS -1.0;\n> -         :COSH 11.591953275521519;\n> -         :SIN 1.2246467991473532e-16;\n> -         :SINH 11.548739357257748;\n> -         :TAN -1.2246467991473532e-16;\n> -         :TANH 0.99627207622074987 .\n> -\n> -    0     a :TestValue;\n> -         :ACOS 1.5707963267948966;\n> -         :ASIN 0.0;\n> -         :ATAN 0.0;\n> -         :COS 1.0;\n> -         :COSH 1.0;\n> -         :SIN 0.0;\n> -         :SINH 0.0;\n> -         :TAN 0.0;\n> -         :TANH 0.0 .\n> -\n>\n> ######### from normal case detailed.tests_t10394.out: cwm\n> math/trigo-test.n3 --think --data\n> make: *** [all] Error 255\n>\n> -- \n> Dan Connolly, W3C http://www.w3.org/People/Connolly/\n> see you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "cwm serialization change",
            "content": "Cwm 1.82 or thereabouts produced a much different serialization than\ncwm of the last few days. This breaks things that (foolishly, I admit) rely\non the serialized form. Here's an example.\n\n\n\n\n                                        Be seeing you,\n                                          norm\n\n-- \nNorman Walsh <ndw@nwalsh.com> | How is the world ruled and how do wars\nhttp://nwalsh.com/            | start? Diplomats tell lies to\n                              | journalists and then believe what they\n                              | read.--Karl Kraus\n\n\n\n\n\napplication/octet-stream attachment: model-182.rdf\n\napplication/octet-stream attachment: model-new.rdf\n\n\n\n\n"
        },
        {
            "subject": "Re: Comment on log: voca",
            "content": "On Wed, 2004-04-14 at 02:12, Jeremy Carroll wrote:\n> Hi Tim, Dan,\n> \n> apologies for rather formal tone here, I think it may be clearer than an \n> informal tone. This is essentially a bug report with suggested fix. \n> I suspect it is of wider interest, hence the www-rdf-logic CC.\n\nMakes sense to me, but I can't speak for TimBL with confidence here.\nI hope he'll respond in due course.\n\n> This is a comment on:\n> \n> http://www.w3.org/2000/10/swap/log\n> \n> Summary:\n> \n> If this vocab is understood as logical rather than proof theoretic then it is \n> inconsistent. Suggest changing rdfs:comments to prioritise proof theoretic \n> reading.\n> \n> A few sample suggested changes:\n> \n> OLD\n> log:Truth a rdfs:Class;\n>     rdfs:comment \"\"\"Something which is true: belive it as you would belive \n> this.\n>        Understood natively by cwm in that it will execute rules in a formula\n>          declared a Truth within a formula it is already taking rules \n> from.\"\"\".\n> \n> NEW\n> log:Truth a rdfs:Class;\n>     rdfs:comment \"\"\"Something which is provable or axiomatically true: \n>                         believe it as you would believe this.\n>        Understood natively by cwm in that it will execute rules in a formula\n>          declared a Truth within a formula it is already taking rules \n> from.\"\"\".\n> \n> \n> OLD:\n> \n> log:implies a rdf:Property;\n>     rdfs:comment \"\"\"Logical implication.\n> This is the relation between the antecedent (subject) and\n> conclusion (object) of a rule.\n> For every subsitution of variable names for symbols or literals\n> which maps the antecedent to a fromula which knowledge base\n> log:includes, the same substitution is applied to the\n> conclusion to generate the result.\n> \n> Used by cwm as the basic hook for adding inference to RDF.\n> See the manual to define what the knowledge base is and\n> where the results go. See also log:conclusion.\"\"\";\n> \n> NEW\n> \n> \n> log:implies a rdf:Property;\n>     rdfs:comment \"\"\"The provability relationship.\n> This is the relation between the antecedent (subject) and\n> conclusion (object) of a rule.\n> For every subsitution of variable names for symbols or literals\n> which maps the antecedent to a fromula which knowledge base\n> log:includes, the same substitution is applied to the\n> conclusion to generate the result.\n> \n> Used by cwm as the basic hook for adding inference to RDF.\n> See the manual to define what the knowledge base is and\n> where the results go. See also log:conclusion.\"\"\";\n> \n> \n> ============\n> \n> Rationale. It is possible to use rdfs:comment to introduce a contradiction \n> when the comment is understood as constraining the class or property (as is \n> the intent). e.g.\n> \n> eg:Russell a rdfs:Class;\n>   rdfs:comment \"\"\"The class of all classes that do not have themselves as a \n> type. i.e. ?x a eg:Russell if and only if not ?x a ?x\"\"\" .\n> \n> This appears to be just normal RDF (no N3 extensions), but is seriously \n> flawed. There are no interpretations for which the comment, understood in \n> English, describes the class eg:Russell.\n> \n> Similarly the current description of log:implies as \"Logical implication\" is \n> flawed since there are no interpretations that make it true as shown by the \n> liar paradox that I posted earlier:\n> http://lists.w3.org/Archives/Public/www-rdf-logic/2003Nov/0040\n> \n> @prefix log: <http://www.w3.org/2000/10/swap/log#> .\n> @prefix owl: <http://www.w3.org/2002/07/owl#> .\n> { \n>   <http://example.org/liar> \n>        log:implies { \n>     <http://example.org/noone> a owl:Nothing .\n>   } . \n> } owl:sameAs <http://example.org/liar> .\n> <http://example.org/liar> a log:Truth .\n> \n> See also Pat's posting on the rules list:\n> http://lists.w3.org/Archives/Public/www-rdf-rules/2002Dec/0003\n> \n> A better fix would be to whole-heartedly embrace proof theoretic and define \n> these terms using an abstract proof theory rather than a concrete proof \n> machine (CWM). i.e. I see text like:\n> \"\"\"Used by cwm as the basic hook for adding inference to RDF.\n> See the manual to define what the knowledge base is and\n> where the results go. See also log:conclusion.\"\"\"\n> as essentially OK, and a good foundation on which to build a more abstract \n> definition of a proof theoretic nature: log:implies is essentially practical \n> not logical.\n> \n> Jeremy\n> \n> \n> \n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "Multiple Carriage Returns in regression test file include/n3ExprFor.n",
            "content": "My CVS checkout of 2000/10/swap on Thursday, April 15 gave me only one\nfailure when trying\n\nretest.py -n -f regression.n3\n\n(in Cygwin on Windows 2000)\n\nFile \"include/n3ExprFor.n3\" has all lines ending with CR CR LF (not just CR\nLF) which can happen as a file is saved/written\nbetween Unix and Windows.\nThese CRs are stripped out when downloading individual CVS files with a\nbrowser, but I did a commandline checkout\nof the entire tree with\n\"checkout 2000/10/swap/\"\n( an \"--lf checkout 2000/10/swap/\"  prevents this problem, but it isn't in\nthe cvs example and who remembers to use it?)\n\nRemoving the CRs fixes the error.  I don't think this will be the last time\nthat someone ends up with CR CR LF in an\nn3 file and perhaps a general purpose catch should be coded (or already in\nuse somewhere else).\n\nThe runtime error is not very enlightening:\n\n 66/72 regression.n3#t1053             Parsing strings with n3ExprFor\nFiles differ, result= 256\n#  If this is OK,   cp ,temp/regression.n3_t1053.out ref/n3ExprFor-out.n3\n######### Differences from reference output:\n--- ref/n3ExprFor-out.n3      2002-03-30 14:08:19.000000000 -0800\n+++ ,temp/regression.n3_t1053.out   2004-03-16 10:07:07.954528200 -0800\n@@ -1,14 +1 @@\n-     @prefix : <#> .\n-     @prefix log: <http://www.w3.org/2000/10/swap/log#> .\n-\n-    this     log:forAll :x .\n-\n-    :Blargh_b     :semantics {<http://example.com/#x>     <\nhttp://example.com/#y> <http://example.com/#z> .\n-        } .\n-    {\n-        \"\"\"@prefix : <http://example.com/#>.\n-   :x :y :z .\"\"\"     log:n3ExprFor :x .\n-\n-        }     log:implies {:Blargh_b     :semantics :x .\n-        } .\n-\n+# next char:  u'\\r'\n\n(end)\n\n\n\n"
        },
        {
            "subject": "[closed] parsing RDF/XML list item type",
            "content": "sax2rdf.py didn't notice the type of list items in cases like:\n\n<event rdf:ID='2414'>\n  <reminders rdf:parseType='Collection'>\n    <reminders_item>\n      <seconds_prior\nrdf:datatype='http://www.w3.org/2001/XMLSchema#integer'>432000</seconds_prior>\n    </reminders_item>\n\nhttp://www.w3.org/2000/10/swap/test/list/itemType.rdf\n\n\nI checked in a small fix in\nsax2rdf.py,v 1.41 2004/04/16 20:43:13\n\nThe test case is\n\n:t1018a1 a test:CwmTest;\n    test:referenceOutput <ref/itemType.n3>;\n    test:description   \"make sure typeNodes in RDF/XML Collections are parsed\";\n    test:arguments     \"\"\"-rdf list/itemType.rdf -n3\"\"\".\n\n\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "lists don't work with store.any(",
            "content": "I'm writing a converter from RDF to XMLRPC data structures.\nI need to distinguish list items from integers, strings,\nand other sorts of things. I tried\n\ni = graph.any(subj=item, pred=RDF.first)\nif i: #list...\n\nbut that test never passed. I changed it to\n\nif isinstance(item, term.List):\n\nand the code is working now. But since this limitation\nisn't documented\n\nhttp://www.w3.org/2000/10/swap/formula.html#Formula-any\n\nI conclude it's a bug.\n\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "Shared Key Authentication for the TLS Protocol&ndash;&ndash; an Alternativ",
            "content": "Shared Key Authentication for the TLS Protocol--an Alternative\n\n1.  Introduction\n\nThis document presents an alternative to the shared-key authentication \nmechanism proposed for the TLS protocol on the IETF TLS mailing list in \nlate July 1996.  This alternative mechanism accomplishes the same goals \n(including enabling three-party \"pass-through\" authentication) in a \nslightly more straightforward manner.  A discussion of the arguments for \nand against the inclusion of shared-key authentication in the TLS \nprotocol can be found in that original shared-key authentication \ndocument.\n\n\n2.  Summary of Changes From the Previous Proposal\n\nIn the previous proposal, a key derived from the master key and several \nother inputs was used in a stream-cipher-like manner to protect a \nshared-key authentication response from eavesdroppers.  In this \nproposal, a separate secret, called an authentication secret, is derived \ndirectly from the master secret and incorporated into the authentication \nresponse.  Thus in the case of pass-through authentication, the server \nmust pass not only the authentication response but also this \nauthentication secret to the authentication service verifying the \nresponse.\n\nThe previous proposal also reused the CertificateRequest handshake \nmessage for shared-key authentication requests.  In the new proposal, \nall shared-key-related data is contained in new handshake messages \n(implementations that support the proposed changes can thus be made to \ninteroperate with implementations that do not, but ignore invalid \nhandshake messages).  Also, a \"private\" shared-key authentication \nresponse format, originally proposed to allow arbitrary authentication \nresponse formats between co-operating clients and servers, has been \nremoved from this proposal.  Since the response field is in any event \nopaque, implementations of an alternative shared-key authentication \nformat for a particular authentication service can simply have clients \ndetect the specific authentication service, and construct their \nauthentication responses accordingly.\n\nFinally, extra challenge and display string fields have been associated \nwith each authentication service name provided by the server, the former \nto facilitate pass-through authentication with service-supplied \nchallenges, and the latter to help the implementation to identify the \nauthentication service to the user.\n\n\n2.  Proposed Protocol Additions\n\nStarting from SSL version 3.0 notation and formats, the following two\nnew HandshakeTypes would would be added, and included in the Handshake \nmessage definition:\n\nshared_key_request(31), shared_key_verify(32)\n\nThe SharedKeyRequest message would have the following structure:\n\nstruct { DistinguishedName auth_service_name;\n         opaque display_string<0..65535>;\n         opaque challenge<0..255>;\n} AuthService;\n\nstruct {\n     AuthService auth_services_server<1..65535>;\n} SharedKeyRequest;\n\nThis optional message would be sent immediately following the server's \nfirst set of consecutive messsages, which includes the ServerHello and \n(possibly) the Certificate, CertificateRequest and ServerKeyExchange \nmessages.  The auth_services_server field would contain a list of \ndistinguished names of shared-key authentication services by which the \nclient can authenticate.  The challenge field accompanying each \nauthentication service name would contain an optional extra \nauthentication challenge, in case the server needs to obtain one from an \nauthentication service for pass-through authentication.  If none is \nrequired, then it would simply be an empty (zero-length) field.  \nSimilarly, the display_string field could contain an extra field to be \ndisplayed to the user during authentication, if needed. \n\nThe SharedKeyVerify message would be sent in response to a \nSharedKeyRequest message from the server, and would have the following \nstructure:\n\nstruct {\n     AuthService auth_service;\n     opaque identity<1..65535>;\n     opaque shared_key_response<1..255>;\n} SharedKeyVerify;\n\nThe value of auth_service would be required to be selected from the list \nin SharedKeyRequest.auth_services_server.  The format of the identity \nfield would be left to the implementation, and should be inferable from \nthe accompanying value of auth_service.  The value of \nshared_key_response would be defined as\n\nSharedKeyVerify.shared_key_response\n     hash (auth_write_secret + pad_2 + \n            hash (auth_write_secret + pad_1 + hash (handshake_messages)                   \n                  + SharedKeyVerify.auth_service.auth_service_name\n                  + SharedKeyVerify.auth_service.display_string\n                  + SharedKeyVerify.auth_service.challenge\n                  + SharedKeyVerify.identity + shared_key) )\n     \nHere \"+\" denotes concatenation.  The hash function used (hash) would be \ntaken from the pending cipher spec.  The client_auth_write_secret and \nserver_auth_write_secret values would be obtained by extending the \nkey_block by CipherSpec.hash_size bytes beyond the server_write_key (or \nthe server_write_IV, if it is derived from key_block as well), and using \nthis extended portion as the client_auth_write_secret value.  The value \nof handshake_messages would be the concatenation of all handshake \nmessages from the first one sent up to (but not including) the \nshared_key_verify message.  The pad1 and pad2 values correspond to the \nones used for MAC computation in the application_data message.  The \nfields from the SharedKeyVerify message would be input with their length \nprefixes included.  \n\n\n3.  Normal Authentication\n\nA shared-key-based client authentication would proceed as follows:  the \nserver would send a SharedKeyRequest handshake message containing a list \nof names of one or more authentication services.  The client, on \nreceiving the SharedKeyRequest message, would select an authentication \nservice from the server's list and construct the appropriate \nauthentication response as described above, sending it back, along with \nits identity and choice of authentication service, in a SharedKeyVerify \nhandshake message.  The server would also itself construct the correct \nauthentication response using the known shared key, and check it against \nthe one provided by the client.  The authentication would be successful \nif the two matched exactly.  Note that if the shared key is password-\nbased, then it would typically be derived from the password using a one-\nway cryptographic hash function, rather than being the password itself, \nso that the original password need not be remembered by anyone but the \nclient.\n\n\n4.  Pass-through Authentication\n \nIn some circumstances, it is preferable for shared keys to be stored in \none place (a central, well-protected site, for instance) while servers \nthat actually communicate with clients are elsewhere (possibly widely \ndistributed, but maintaining secure connections to the central shared-\nkey server).  One of the advantages of the shared-key authentication \nmethod proposed here is that it allows \"pass-through\" authentication by \na third party, if the server accepting the public-key key exchange and \nthe server sharing the key with the client happen to be different.  (The \nuse of a separately derived authentication key in the response \ncomputation makes this possible.)  \n\nPass-through authentication might work as follows:  The server would \neither collect random challenges in advance from its authentication \nservices, or request them as needed.  The server would then send a list \nof authentication services and associated challenges in a \nSharedKeyRequest message.  The client would then select an \nauthentication service (if more than one is offered), compute the \ncorrect authentication response using the above proposed formula, and \nsend it to the server in a SharedKeyVerify message.\n\nThe server, on receiving a response from a client, would pass it through \nto the authentication service, along with the values necessary to \nrecalculate it:  the client_auth_write_key, the hash of all the \nhandshake messages and the identity field from the certificate verify \nmessage.  The authentication service would then use the values provided, \nalong with the secret key it shares with the client and the challenge it \nsupplied, to reconstruct the correct value of the response.  If this \nvalue exactly matches the one provided by the server, then the \nauthentication would succeed; otherwise it would fail.  \n\n\n5.  Addendum--The SharedKeys Message\n\nIn cases where pass-through authentication is used, it would be useful \nfor clients to be able to notify servers in advance of one or more \nauthentication services sharing a key with the client, so that the \nserver need only fetch (or use up) a challenge from a single service for \nthat client.  An additional optional message accompanying the \nClientHello would accomplish that purpose.  It is proposed here for \nconsideration, with the following HandshakeType:\n\nshared_keys(30)\n\nThe SharedKeys message would have the following structure:\n\nstruct {\n     DistinguishedName auth_services_client<1..65535>;\n} SharedKeys;\n\nThis optional message would be sent immediately following the \nClientHello message, and would contain a list of distinguished names of \nauthentication services to which the client is willing to authenticate.  \nThis message could also be useful in non-pass-through situations; for \nexample, the client may share several keys with the server, associated \nwith identities on different systems (corresponding to different \n``authentication services'' residing on the same server).  If a server \nreceives a SharedKeys message, then any subsequent SharedKeyRequest \nmessage could contain a single authentication service selected from the \nclient's list.  \n\nNote that sending a SharedKeys message does not in itself normally \nreveal significant information about the client's as-yet-unspecified \nidentity or identities.  However, if information about the set of \nauthentication services supported by a particular client is at all \nsensitive, then the client should not send this message.\n\nBarbara Fox\nbfox@microsoft.com\n\n\n\n"
        },
        {
            "subject": "N3 grammar bug with comma in collection",
            "content": "cwm (and jena's n3 parser) seem to implement something different than\nspecified in the Notation3 grammar.\n\nSpecifically, the grammar says this:\n[[\nobjectlist\n    object\n    object , objectlist\n]] -- http://www.w3.org/DesignIssues/Notation3.html\n\nand in the RDF/n3 one:\n[[\nobjecttail bnf:mustBeOneSequence (\n( )\n( \",\"   object objecttail )\n).\n]] -- http://www.w3.org/2000/10/swap/grammar/n3.n3\n\n\nSo a comma is required between entries.\n\ncwm implements something else - commas are forbidden.\n\nFailing test with cwm:\n@prefix : <http://example.org/stuff/1.0/> .\n:a :b ( \"apple\", \"banana\" ) .\n\nPassing test with cwm:\n@prefix : <http://example.org/stuff/1.0/> .\n:a :b ( \"apple\" \"banana\" ) .\n\nI need to change turtle one way or the other to match.  I assume\nthe grammar is in error.\n\nDave\n\n\n\n"
        },
        {
            "subject": "cwm.tgz Spillag",
            "content": "The current http://www.w3.org/2000/10/swap/cwm.tgz inflates into the current directory so that \"wget .../cwm.tgz && tar -zxvf cwm.tgz\" creates a mess in ./ instead of putting the files into ./cwm-<version> as it should do. Should be an easy fix. Thanks.\n\n\n\n"
        },
        {
            "subject": "Re: N3 grammar bug with comma in collection",
            "content": "On Thu, 26 Feb 2004 14:20:30 +0000, Dave Beckett <dave.beckett@bristol.ac.uk> wrote:\n\n> cwm (and jena's n3 parser) seem to implement something different than\n> specified in the Notation3 grammar.\n\nIt is my fault, I didn't notice that N3 collections used an itemList in\nthe grammar and triple objects used objectList.  I will change turtle to\nmatch N3 and my code to match, it's a bug at my end.\n\nDave\n\n\n\n"
        },
        {
            "subject": "BUG: Recursion Error With &#64;keywords thi",
            "content": "$ echo '@keywords this . @prefix : <#> . this :a :Doc .' | cwm\n\n[...]\n   File \"/misc/tools/cwm/pretty.py\", line 312, in _scan\n     self._scan(y, x)\n   File \"/misc/tools/cwm/pretty.py\", line 312, in _scan\n     self._scan(y, x)\n   File \"/misc/tools/cwm/pretty.py\", line 293, in _scan\n     if verbosity() > 98: progress(\"scanning %s in context %s\"\n        %(`x`, `context`),\nRuntimeError: maximum recursion depth exceeded\n\nThe problem occurs in a CVS version checked out today, as well as the \nmost recent cwm.tgz.\n\n-- \nSean B. Palmer, <http://purl.org/net/sbp/>\n\"phenomicity by the bucketful\" - http://miscoranda.com/\n\n\n\n"
        },
        {
            "subject": "Syntax Errors Missed In &#64;keywords/&#64;forAll Combinatio",
            "content": "The following errors are caused by @keywords setting its argument list \n  to be treated as literals, and then @forAll being passed them \nwithout realising that a syntax error is occuring. The errors given \nshould be notation3.BadSyntax, not AttributeError, and display some \nkind of help letting people know where they've gone wrong!\n\nI might try to patch these myself, but they're low priority bugs anyway.\n\n$ echo '@keywords p . @prefix : <#> . @forAll p .' | cwm\n\nTraceback (most recent call last):\n   File \"/misc/tools/cwm/cwm.py\", line 653, in ?\n     doCommand()\n   File \"/misc/tools/cwm/cwm.py\", line 580, in doCommand\n     _store.dumpNested(workingContext, _outSink)\n   File \"/misc/tools/cwm/llyn.py\", line 1510, in dumpNested\n     pp. dumpNested()\n   File \"/misc/tools/cwm/pretty.py\", line 375, in dumpNested\n     self.dumpFormulaContents(context, self.sink, sorting=1, equals=1)\n   File \"/misc/tools/cwm/pretty.py\", line 392, in dumpFormulaContents\n     self.dumpVariables(context, sink, sorting, pretty=1)\n   File \"/misc/tools/cwm/pretty.py\", line 217, in dumpVariables\n     self._outputStatement(sink, (context, self.store.forAll,\n       context, v))\n   File \"/misc/tools/cwm/pretty.py\", line 196, in _outputStatement\n     sink.makeStatement(self.extern(quad))\n   File \"/misc/tools/cwm/pretty.py\", line 199, in extern\n     return(t[CONTEXT].asPair(),\nAttributeError: 'unicode' object has no attribute 'asPair'\n\n$ echo '@keywords p . @prefix : <#> . @forAll p, q .' | cwm\n\nTraceback (most recent call last):\n   File \"/misc/tools/cwm/cwm.py\", line 653, in ?\n     doCommand()\n   File \"/misc/tools/cwm/cwm.py\", line 580, in doCommand\n     _store.dumpNested(workingContext, _outSink)\n   File \"/misc/tools/cwm/llyn.py\", line 1510, in dumpNested\n     pp. dumpNested()\n   File \"/misc/tools/cwm/pretty.py\", line 375, in dumpNested\n     self.dumpFormulaContents(context, self.sink, sorting=1, equals=1)\n   File \"/misc/tools/cwm/pretty.py\", line 392, in dumpFormulaContents\n     self.dumpVariables(context, sink, sorting, pretty=1)\n   File \"/misc/tools/cwm/pretty.py\", line 209, in dumpVariables\n     uv.sort(compareTerm)\n   File \"/misc/tools/cwm/formula.py\", line 672, in compareTerm\n     o = other.uriref()\nAttributeError: 'unicode' object has no attribute 'uriref'\n\nThanks,\n\n-- \nSean B. Palmer, <http://purl.org/net/sbp/>\n\"phenomicity by the bucketful\" - http://miscoranda.com/\n\n\n\n"
        },
        {
            "subject": "Surreality: &#64;keywords prefix ",
            "content": "This does very strange things indeed:\n\n$ echo '@keywords prefix . @prefix : <#> . prefix q r . p q r .' | cwm\n\n      @prefix : <#> .\n     :rp     :rq :rr .\n\nOftentimes, triples using prefix are just ignored:\n\n$ echo '@keywords prefix . @prefix : <#> . p q r . prefix q r .' | cwm\n\n      @prefix : <#> .\n     :p     :q :r .\n\nThis, however, works as expected:\n\n$ echo '@keywords prefix . @prefix : <#> . p q r . q prefix r .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n      @prefix : <#> .\n     :p     :q :r .\n     :q     \"prefix\" :r .\n\nSimilar oddnesses can be gained from @keywords keywords .:\n\n$ echo '@keywords prefix, keywords . @prefix : <#> . \\\n    keywords q r . prefix q r .' | cwm\n\nTraceback (most recent call last):\n   File \"/misc/tools/cwm/cwm.py\", line 653, in ?\n     doCommand()\n   File \"/misc/tools/cwm/cwm.py\", line 350, in doCommand\n     p.load(\"\", baseURI=_baseURI)\n   File \"/misc/tools/cwm/notation3.py\", line 212, in load\n     return self.loadBuf(stream.read())    # self._formula\n   File \"/misc/tools/cwm/notation3.py\", line 220, in loadBuf\n     self.feed(buf)\n   File \"/misc/tools/cwm/notation3.py\", line 238, in feed\n     i = self.directiveOrStatement(str,j)\n   File \"/misc/tools/cwm/notation3.py\", line 248, in directiveOrStatement\n     j = self.directive(str, i)\n   File \"/misc/tools/cwm/notation3.py\", line 293, in directive\n     \"'@keywords' needs comma separated list of words\")\nnotation3.BadSyntax: Line 1 of <file:.../keyword-test/>:\n    Bad syntax ('@keywords' needs comma separated list of words)\n    at ^ in: \"@keywords prefix, keywords . @prefix : <#> .\n    keywords q r . prefix q r .^...\"\n\nClearly the bug is that declaration keywords are interfering in some \nway with standard @-less keywords, but I've no idea how to explain \nthat \":rp :rq :rr\" output without using the word cwmic :-)\n\n-- \nSean B. Palmer, <http://purl.org/net/sbp/>\n\"phenomicity by the bucketful\" - http://miscoranda.com/\n\n\n\n"
        },
        {
            "subject": "[closed] Re: Surreality: &#64;keywords prefix ",
            "content": "> This does very strange things indeed:\n>\n> $ echo '@keywords prefix . @prefix : <#> . prefix q r . p q r .' | cwm\n>\n>       @prefix : <#> .\n>      :rp     :rq :rr .\n>\n\nStrange in, strange out. :-)  First, you declare that \"prefix\" is a \nkeyword\nand will there not need \"@\" to work. Fine.\n\nThen you declare \"prefix q r.\"   @prefix takes a qname specifying the \nnamespace,\nwhich  here is q  or  :q, in other words the empty prefix.\nThen it takes the namespace given as a resource, normallty a urui in <>.\nBut here you use  a qname for this too.\nThere is no prefix on it, so \"r\" is taken being in the document's \nnamesapce.\n(As you have no document URI, as you are piping from standard input,\nthe current working directory is used)\nSo the effect of this is the same as the effect of\n@prefix  :  <$PWD/r> .\nwhere $PWD is your pwd.\nNow you say \"p q r.\"\nThis is in the default namespace, which is now  <$PWD/r>\nso you have said\n   <$PWD/rp>  <$PWD/rq>  <$PWD/rr>\nWhen outputting to standard output, again there is no URI and the$PWD\nis used as a base. The default namespace is is set to that, and the\ntriple you gave is clearly:\n:rp :rq :rr\n\nQED.\n\n\n> Oftentimes, triples using prefix are just ignored:\n>\n> $ echo '@keywords prefix . @prefix : <#> . p q r . prefix q r .' | cwm\n>\n>       @prefix : <#> .\n>      :p     :q :r .\n\nI think you have the meaning of \"keyword\" backwards.\nWhen you declare something a keyword, it means it is a keyword,\nnot a qname.\n\nThe \"triple using prefix\" there is just a prefix declaration.\n\n> This, however, works as expected:\n>\n> $ echo '@keywords prefix . @prefix : <#> . p q r . q prefix r .' | \\\n>     cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n>\n>       @prefix : <#> .\n>      :p     :q :r .\n>      :q     \"prefix\" :r .\n>\n\nThat is very weird.  Thanks for the pointer.  It should certainly not \nreturn a literal\nstring.  That bug has been found.  I have a negative test for it \ntest/syntax/neg-keywords3.n3,\nbut currently no negative test harness.\n\n\n> Similar oddnesses can be gained from @keywords keywords .:\n>\n> $ echo '@keywords prefix, keywords . @prefix : <#> . \\\n>     keywords q r . prefix q r .' | cwm\n\nYes, you have declared \"keywords\" as a keyword, and then you\nuse it like a qname.\n\n> Traceback (most recent call last):\n>    File \"/misc/tools/cwm/cwm.py\", line 653, in ?\n>      doCommand()\n>    File \"/misc/tools/cwm/cwm.py\", line 350, in doCommand\n>      p.load(\"\", baseURI=_baseURI)\n>    File \"/misc/tools/cwm/notation3.py\", line 212, in load\n>      return self.loadBuf(stream.read())    # self._formula\n>    File \"/misc/tools/cwm/notation3.py\", line 220, in loadBuf\n>      self.feed(buf)\n>    File \"/misc/tools/cwm/notation3.py\", line 238, in feed\n>      i = self.directiveOrStatement(str,j)\n>    File \"/misc/tools/cwm/notation3.py\", line 248, in \n> directiveOrStatement\n>      j = self.directive(str, i)\n>    File \"/misc/tools/cwm/notation3.py\", line 293, in directive\n>      \"'@keywords' needs comma separated list of words\")\n> notation3.BadSyntax: Line 1 of <file:.../keyword-test/>:\n>     Bad syntax ('@keywords' needs comma separated list of words)\n>     at ^ in: \"@keywords prefix, keywords . @prefix : <#> .\n>     keywords q r . prefix q r .^...\"\n>\n> Clearly the bug is that declaration keywords are interfering in some\n> way with standard @-less keywords, but I've no idea how to explain\n> that \":rp :rq :rr\" output without using the word cwmic :-)\n>\n\n:)  When you look at the meaning of \"keywords\" the right way up,\nthen it all makes sense.  Except for the string weidness generating \n\"prefix\".\n\nI think what this points to is the need for some documentation about \n@keywords.\nI have put some on the end of\nhttp://www.w3.org/2000/10/swap/doc/Shortcuts\n\nThanks for trying it out, Sean.\n\nTim\n\n> -- \n> Sean B. Palmer, <http://purl.org/net/sbp/>\n> \"phenomicity by the bucketful\" - http://miscoranda.com/\n\n\n\n"
        },
        {
            "subject": "[closed] Re: Syntax Errors Missed In &#64;keywords/&#64;forAll Combinatio",
            "content": "Sean,\nThanks.\nNegative test is covered by swap/test/neg-keywords3.n3 I think.\n\nThe code is fixed too, to give a specific error whenever a declared \nkeyword i used for a qname.\n\nTim\n\n$ echo '@keywords p . @prefix : <#> . @forAll p .' | cwm\n#Processed by Id: cwm.py,v 1.145 2004/01/29 23:22:22 timbl Exp\n         #    using base file:/devel/WWW/2000/10/swap/test/\n         Traceback (most recent call last):\n   File \"/devel/WWW/2000/10/swap/cwm.py\", line 650, in ?\n     doCommand()\n   File \"/devel/WWW/2000/10/swap/cwm.py\", line 346, in doCommand\n     p.load(\"\", baseURI=_baseURI)\n   File \"/devel/WWW/2000/10/swap/notation3.py\", line 226, in load\n     return self.loadBuf(stream.read())    # self._formula\n   File \"/devel/WWW/2000/10/swap/notation3.py\", line 234, in loadBuf\n     self.feed(buf)\n   File \"/devel/WWW/2000/10/swap/notation3.py\", line 252, in feed\n     i = self.directiveOrStatement(str,j)\n   File \"/devel/WWW/2000/10/swap/notation3.py\", line 262, in \ndirectiveOrStatement\n     j = self.directive(str, i)\n   File \"/devel/WWW/2000/10/swap/notation3.py\", line 315, in directive\n     i = self.commaSeparatedList(str, j, res, self.uri_ref2)\n   File \"/devel/WWW/2000/10/swap/notation3.py\", line 669, in \ncommaSeparatedList\n     i = what(str, i, res)\n   File \"/devel/WWW/2000/10/swap/notation3.py\", line 773, in uri_ref2\n     'Keyword \"%s\" not allowed here.' % v[0])\nnotation3.BadSyntax: Line 1 of <file:/devel/WWW/2000/10/swap/test/>: \nBad syntax (Keyword \"p\" not allowed here.) at ^ in:\n\"@keywords p . @prefix : <#> . @forAll ^p .\n\n\n\n"
        },
        {
            "subject": "[closed] Re: Recursion Error With &#64;keywords thi",
            "content": "Thanks. Fixed. This now generates an error.\n\nThe use of \"this\" is now disallowed  except as the subject of \nlog:forAll or log:forSome.\n\nI hope people haven't used it much.   I think this makes the N3 \nlanguage much more conventional, less weird for most people coming \nacross it, and more easily translatable into other things.\n\nOf course, I want to move toward removing \"this\" altogether, to just \nusing @forAll and @forAome.\n\nNote in the next version\n@prefix : <#>.\nwill be the default, too, to save typing.\n\nThanks for all the great one-liner test cases.\n\nTim\n\n\n$ echo '@keywords this . this :a :Doc .' | cwm\n#Processed by Id: cwm.py,v 1.145 2004/01/29 23:22:22 timbl Exp\n         #    using base file:/devel/WWW/2000/10/swap/test/\n[...]\nValueError: You cannot use 'this' except as subject of forAll or forSome\n$\n\n\n\n"
        },
        {
            "subject": "[closed] Re: N3 grammar bug with comma in collection",
            "content": "> cwm (and jena's n3 parser) seem to implement something different than\n> specified in the Notation3 grammar.\n>\n> Specifically, the grammar says this:\n> [[\n> objectlist\n>     object\n>     object , objectlist\n> ]] -- http://www.w3.org/DesignIssues/Notation3.html\n>\n> and in the RDF/n3 one:\n> [[\n> objecttail bnf:mustBeOneSequence (\n>                 ( )\n>                 ( \",\"   object objecttail )\n>         ).\n> ]] -- http://www.w3.org/2000/10/swap/grammar/n3.n3\n>\n>\n> So a comma is required between entries.\n\nYes, this is an objectlist as in a sentence with several triples of the \nsame subject and predicate, like\n\n:Joe  :child  :Egbert, :Marmaduke.\n\nobjecttail is used in propertlist, which is used in [ propertylist ] as \nan anonymous node,\nand in statement:\n\nstatement bnf:mustBeOneSequence(( subject propertylist )).\n\n\n\n\n> cwm implements something else - commas are forbidden.\n>\n> Failing test with cwm:\n> @prefix : <http://example.org/stuff/1.0/> .\n> :a :b ( \"apple\", \"banana\" ) .\n\nThat is a list in the sense of a collection. In the grammar, ( pathlist \n).\nPathlist has no commas.\n\n> Passing test with cwm:\n> @prefix : <http://example.org/stuff/1.0/> .\n> :a :b ( \"apple\" \"banana\" ) .\n>\n> I need to change turtle one way or the other to match.  I assume\n> the grammar is in error.\n\nI think you just got the productions crossed.  If I have missed \nsomething, let me know.  Thanks for implementing it.    Maybe we should \nmake various levels of common test suite.\n\nTim\n\n> Dave\n\n\n\n"
        },
        {
            "subject": "new lis",
            "content": "List_Name: public-cwm-bugs\n\nListPurpose: Reports of bugs or potential bugs in <a\nhref=\"http://www.w3.org/2000/10/swap/doc/cwm.html\">cwm</a>.\n\nMaintaining_Activity: Semantic Web\n\n-- \nDaigo Matsubara / W3C Systems Team / mailto:daigo@w3.org\n\n\n\n"
        },
        {
            "subject": "[closed] Re: &quot;Bad Syntax&quot; message instead of 404 file not foun",
            "content": "The bug reported in \nhttp://lists.w3.org/Archives/Public/public-cwm-bugs/2004May/0009.html \nis  fixed in release 0.7.3\n\nTest is http://www.w3.org/2000/10/swap/test/online.tests#t1104\n\nYosi\n\n\n\n"
        },
        {
            "subject": "[closed] Re: reflexive bug in cwm",
            "content": "The bug mentioned in \nhttp://lists.w3.org/Archives/Public/public-cwm-bugs/2004Mar/0003.html, \ncwm not handling reflexive statements correctly, has been fixed. The \ntest for the fix is \nhttp://www.w3.org/2000/10/swap/test/regression.n3#t1024a .\n\nYosi\n\n\n\n"
        },
        {
            "subject": "[closed] Re: new lis",
            "content": "not a bug\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: iterable argument required  bug",
            "content": "What you did was trying to find the uri of something that was not a string.\n\nattached are files to show the behaviour on (1) non-strings, and (2) strings that do not encode uri's. \n\nTimbl, what should the behavior be? Currently if the file has either error cwm throws an exception. Should it do that? Should it keep going?\n\nYosi\n\n\n>After a substantial time away, I'm getting back into using cwm. One of \n>the projects I'm working on reliably fails in the following manner, but \n>I'm not sure if it's a bug with my data (if so, it seems like a pretty \n>spectacular way to fail), or cwm. Does this look like a known problem \n>in cwm? Perhaps something that's not friendly to Python 2.3 in the \n>code?\n>\n>This is the latest from CVS, with Python 2.3 (Apple's build) on OSX \n>10.3.3.\n>\n>Thanks,\n>\n>adsl-67-119-69-246:~/Projects/HTTP header registry/swap> ./cwm.py \n>~/Desktop/rfc_rules.n3 ~/Desktop/out.n3 --think --purge > ~/out.n3\n>Traceback (most recent call last):\n>   File \"./cwm.py\", line 646, in ?\n>     doCommand()\n>   File \"./cwm.py\", line 517, in doCommand\n>     think(workingContext, mode=option_flags[\"think\"])\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>58, in think\n>     return InferenceTask(knowledgeBase, ruleFormula, mode=mode, \n>repeat=1).run()\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>207, in run\n>     return self.runSmart()\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>195, in runSmart\n>     total += cy.run()\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>303, in run\n>     return rule.once()\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>404, in once\n>     total = query.resolve()\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>545, in resolve\n>     return self.unify(self.queue, self.variables, self.existentials)\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>709, in unify\n>     nbs = item.tryBuiltin(queue, bindings, heavy=0, evidence=evidence)\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n>995, in tryBuiltin\n>     result = pred.evalSubj(obj, queue, bindings.copy(), proof, \n>self.query)\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/term.py\", line \n>864, in evalSubj\n>     return self.store._fromPython(self.evaluateSubject(obj.value()))\n>   File \"/Users/mnot/Projects/HTTP header registry/swap/llyn.py\", line \n>706, in evaluateSubject\n>     if ':' not in object:\n>TypeError: iterable argument required\n\n\n\n\n\n\n@prefix log:  <http://www.w3.org/2000/10/swap/log#> .\n@prefix : <#> .\n\n{?y log:uri <>} log:implies {?y a :TEST_RESULT} .\n\n\n@prefix log:  <http://www.w3.org/2000/10/swap/log#> .\n@prefix : <#> .\n\n{?y log:uri \"hello\"} log:implies {?y a :TEST_RESULT} .\n\n\n\n"
        },
        {
            "subject": "RFE: warning/helper option for cw",
            "content": "TODO: --chatty/--warn mode, using python's warn module.\n\n(as discussed just now with timbl and yosi)\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "[closed] Re: diff.py not workin",
            "content": "see\nhttp://lists.w3.org/Archives/Public/public-cwm-bugs/2004May/0010.html\nDate: Sun, 16 May 2004 16:38:49 -0400\nMessage-Id: <092D70F8-A779-11D8-937D-000A9580D8C0@w3.org>\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: lists don't work with store.any(",
            "content": "Agreed - Unfixed bug.\n\nThis is because lists are de-reified on input to cwm.\n\nPossible options are\n- Make rdf:first and rdf:rest special to do what you would expect in \njust this API;\n- Make these builtins wwok in any()\n- Make all builtins work in any()   ... this might be considered weird.\n- Make cwm de-reify not only lists but also de-reify formulae. that \nwould allow\n- any n3 file to be transported as plain RDF.\n\nThis is API question, probably should wait till API work....\n\nTim\n\n\n\n"
        },
        {
            "subject": "[closed] Re: cwm serialization change",
            "content": "Norm,\n\nYes -- this can happen.    The serialization is not sacrosanct - in \nparticular the ordering of nodes is something which may change if it \nbecomes logical to reorder them.\n\nwe'll try to mention this in changes.html\nhttp://www.w3.org/2000/10/swap/doc/changes.html\n\nand in fact did sometimes.\n\nOf course, it is a pain for the tests when this happens, too.\n\nTim\n\n\n\n"
        },
        {
            "subject": "[closed] Re: problem testing swap HEAD in cv",
            "content": "Hi Henry,\n\nThe problem you reported on 7 May\nhttp://lists.w3.org/Archives/Public/public-cwm-bugs/2004May/0004.html\n\nwas a case of the test data lagging a fix in the code.\nThe test data was fixed in\n--- daml-ex.n3  6 Mar 2004 20:39:43 -0000       1.11\n\nthe code was fixed a little earlier\nsax2rdf.py revision 1.41 date: 2004/04/16 20:43:13\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: &ndash;&ndash;think=foo.n3   Was: CWM bug + RFE: N3 to XML RDF fails on non&ndash;trivial Unicod",
            "content": "I was going to close this, since it's not a problem report,\nbut I don't see a test for the --think= command-line syntax.\n\nIs it documented? yes...\n\nin the cwm --help stuff... \n--think=foo   as -apply=foo but continue until no more rule matches (or\nforever!)\nand in the copy at http://www.w3.org/2000/10/swap/doc/CwmHelp\n\nI don't suppose it needs to show up in the tutorial.\n\n\nFor reference:\n\nDate: Mon, 1 Jul 2002 17:45:49 -0400\nMessage-Id: <E8431E2D-8D3B-11D6-A536-000393914268@w3.org>\nhttp://lists.w3.org/Archives/Public/www-archive/2002Jul/0002.html\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "[closed] Re: problem testing swap HEAD in cv",
            "content": "On Wed, 2004-06-09 at 12:36, Dan Connolly wrote:\n> Hi Henry,\n> \n> The problem you reported on 7 May\n> http://lists.w3.org/Archives/Public/public-cwm-bugs/2004May/0004.html\n> \n> was a case of the test data lagging a fix in the code.\n> The test data was fixed in\n> --- daml-ex.n3  6 Mar 2004 20:39:43 -0000       1.11\n\nrather: it was fixed in\n+++ daml-ex.n3  12 May 2004 01:27:13 -0000      1.12\n\n\n> the code was fixed a little earlier\n> sax2rdf.py revision 1.41 date: 2004/04/16 20:43:13\n\nThe sequence was\n  16 Apr: code fix\n   7 May: problem report: test data doesn't match code\n  12 May: test fix\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "RFE: an option to use the redland parse",
            "content": "Based on some recent experience with redland[1,2]\nand discussion with TimBL, Sandro and others,\nI suggest that cwm should have an option to use\nthe parser from redland[3], ala the option to use rdflib.\n\nMaybe the redland in-memory store too?\n\n\n[1] glean.py, a GRDDL implementation based on redland and xsltproc\nhttp://lists.w3.org/Archives/Public/public-rdf-in-xhtml-tf/2004May/0007.html\n\n[2] http://www.w3.org/2003/g/glean.py\n tested with: http://packages.debian.org/python2.3-librdf 0.9.16-1_i386\n\n[3] Redland RDF Application Framework - Python API Reference:\n http://www.redland.opensource.ac.uk/docs/pydoc/RDF.html#Model\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "RFE: GRDDL suppor",
            "content": "Based on some recent experience[1] implementing GRDDL[2,3] in python,\nI suggest cwm should grok XHTML and XML documents this way.\nPerhaps a change to log:semantics?\n\n[1] glean.py, a GRDDL implementation based on redland and xsltproc\nhttp://lists.w3.org/Archives/Public/public-rdf-in-xhtml-tf/2004May/0007.html\n\n[2] GRDDL Data Views: Getting Started, Learning More\nhttp://www.w3.org/2003/g/data-view\n\n[3] Gleaning Resource Descriptions from Dialects of Languages (GRDDL)\n http://www.w3.org/2004/01/rdxh/spec\n\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: iterable argument required  bug",
            "content": "On Jun 9, 2004, at 10:40, Yosi Scharf wrote:\n\n> What you did was trying to find the uri of something that was not a \n> string.\n>\n> attached are files to show the behaviour on (1) non-strings, and (2) \n> strings that do not encode uri's.\n\n1) Don't bind. (builtin return None)\n2) ditto\n\n> Timbl, what should the behavior be? Currently if the file has either \n> error cwm throws an exception. Should it do that? Should it keep \n> going?\n\nIt may be useful to have  an option of warnings when a bizarre \ncombination of types comes up in a builtin's args, as they are often \nrule-writer's error. But logically, the builtin just returns no \nbindings.\n\n>\n> Yosi\n>\n>\n>> After a substantial time away, I'm getting back into using cwm. One \n>> of the projects I'm working on reliably fails in the following \n>> manner, but I'm not sure if it's a bug with my data (if so, it seems \n>> like a pretty spectacular way to fail), or cwm. Does this look like a \n>> known problem in cwm? Perhaps something that's not friendly to Python \n>> 2.3 in the code?\n>>\n>> This is the latest from CVS, with Python 2.3 (Apple's build) on OSX \n>> 10.3.3.\n>>\n>> Thanks,\n>>\n>> adsl-67-119-69-246:~/Projects/HTTP header registry/swap> ./cwm.py \n>> ~/Desktop/rfc_rules.n3 ~/Desktop/out.n3 --think --purge > ~/out.n3\n>> Traceback (most recent call last):\n>>   File \"./cwm.py\", line 646, in ?\n>>     doCommand()\n>>   File \"./cwm.py\", line 517, in doCommand\n>>     think(workingContext, mode=option_flags[\"think\"])\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 58, in think\n>>     return InferenceTask(knowledgeBase, ruleFormula, mode=mode, \n>> repeat=1).run()\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 207, in run\n>>     return self.runSmart()\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 195, in runSmart\n>>     total += cy.run()\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 303, in run\n>>     return rule.once()\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 404, in once\n>>     total = query.resolve()\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 545, in resolve\n>>     return self.unify(self.queue, self.variables, self.existentials)\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 709, in unify\n>>     nbs = item.tryBuiltin(queue, bindings, heavy=0, evidence=evidence)\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", \n>> line 995, in tryBuiltin\n>>     result = pred.evalSubj(obj, queue, bindings.copy(), proof, \n>> self.query)\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/term.py\", line \n>> 864, in evalSubj\n>>     return self.store._fromPython(self.evaluateSubject(obj.value()))\n>>   File \"/Users/mnot/Projects/HTTP header registry/swap/llyn.py\", line \n>> 706, in evaluateSubject\n>>     if ':' not in object:\n>> TypeError: iterable argument required\n>\n>\n>\n>\n>\n> @prefix log:  <http://www.w3.org/2000/10/swap/log#> .\n> @prefix : <#> .\n>\n> {?y log:uri <>} log:implies {?y a :TEST_RESULT} .\n>\n> @prefix log:  <http://www.w3.org/2000/10/swap/log#> .\n> @prefix : <#> .\n>\n> {?y log:uri \"hello\"} log:implies {?y a :TEST_RESULT} .\n>\n\n\n\n"
        },
        {
            "subject": "[closed] Re: Few CWM Bug",
            "content": "This is all done.\n\n\"Many thanks for the help,\"\n-- http://lists.w3.org/Archives/Public/www-archive/2001Nov/0068.html\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "RFE: formal N3 gramma",
            "content": "The orignal description of N3\n  http://www.w3.org/DesignIssues/Notation3\n\nhad a semi-formal BNF grammar. As\nof v1.97 2004/04/16 15:13:48, the grammar\nwas split out to\nhttp://www.w3.org/2000/10/swap/grammar/n3-report.html\nwith subsets\nhttp://www.w3.org/2000/10/swap/grammar/n3rdf-report.html\nhttp://www.w3.org/2000/10/swap/grammar/n3rules-report.html\n\nmeanwhile, a number of other grammars and gramar-generated\nparsers have been developed (noted in Notation3).\n\nMy favorite is...\n  http://www.w3.org/2000/10/swap/rdfn3-gram.html\n\nWe have had various discussions about finishing this\ngrammar work; for example,\n  http://www.w3.org/2004/01/20-swad-whiteboard\n\nThis bug is intended to track/capture that goal.\n\nIn particular, what we'd like is a formal grammar\nthat's somehow machine-checked against all the N3 tests.\n\nRelated bugs include\n\n2002-02-17T17:32:53Z raised: Notation3: The Great QName Survey\nhttp://www.w3.org/mid/004d01c1b7d9$23238080$61be0150@localhost\n\n2002-07-15T15:03:29Z raised: Minus sign in ids Was: Alternative N3\nParsers for CWM\nhttp://www.w3.org/mid/01f901c22c10$c8330180$84001d12@w3.org\n\n2004-05-04T09:39:34Z raised: qnames with - in cwm\nhttp://www.w3.org/mid/20040504103934.1f962a3b@hoth.ilrt.bris.ac.uk\n\n2004-05-04T10:10:32Z raised: Trailing ; in N3 property lists forbidden\nhttp://www.w3.org/mid/20040504111032.0fafec1c@hoth.ilrt.bris.ac.uk\n\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: cwm.tgz Spillag",
            "content": "Yes, the tarball is buggy. We talked about fixing it today.\n\nIn particular, it should contain just enough so that\nyou can download it, unpack it, and run (some of?)\nthe tests to make sure it's working.\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "RFE: python distutils support (setup.py",
            "content": "cwm should install using the python distutils stuff.\n\nInstalling Python Modules\nGreg Ward\nhttp://docs.python.org/dist/dist.html\n\n\nThis seems to involve some reorganization of the sources.\nUgh.\n\nTimBL agreed that\nimport swap.llyn\nis an improvement over\nimport llyn\nsince it's closer to\nfrom http://www.w3.org/2000/10/swap/ import llyn\n\n(he mentioned red_import... I suppose as in...\nhttp://redfoot.net/2002/12/03/redfoot-1.7.3/doc/helloworld.html )\n\nIt seems danbri did some work on it...\n\n$Id: setup.py,v 1.2 2003/03/25 21:37:36 danbri Exp $\nhttp://www.w3.org/2000/10/swap/setup.py\n\nA not-working-yet attempt at a setup.py installer for Cwm/SWAP\nposted by danbri_ at 2003-03-25 21:41 (+)\nhttp://rdfig.xmlhack.com/2003/03/25/2003-03-25.html#1048628468.931359\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: RFE: python distutils support (setup.py",
            "content": "* Dan Connolly <connolly@w3.org> [2004-06-10 16:35-0500]\n> cwm should install using the python distutils stuff.\n\nThat would be great!\n\n> It seems danbri did some work on it...\n\nOh, I'd forgotten about that. I imagine it could be deleted \nwith little loss; it is just the setup.py from rdflib but hacked \nabout in obvious ways. I never got it working happily. Same goes for any\npackaging for Debian stuff I left in the Cwm filetree. That work got\nbogged down by my not figuring out which installation dirs got selected\nin advance, and which at install time. The Python paradigm of setup.py\nseems to prefer figuring things out at install time, whereas Debian\npackaging seems to work on a \"here's how the filetree looks for\neveryone\" decide in advance approach.\n\nThanks for the CC, I'm reminded to join these new lists.\n\ncheers,\n\nDan\n\n> $Id: setup.py,v 1.2 2003/03/25 21:37:36 danbri Exp $\n> http://www.w3.org/2000/10/swap/setup.py\n> \n> A not-working-yet attempt at a setup.py installer for Cwm/SWAP\n> posted by danbri_ at 2003-03-25 21:41 (+)\n> http://rdfig.xmlhack.com/2003/03/25/2003-03-25.html#1048628468.931359\n> \n> -- \n> Dan Connolly, W3C http://www.w3.org/People/Connolly/\n> \n\n\n\n"
        },
        {
            "subject": "RFE: download tarball with working minimal test/ directory",
            "content": "Make a downloadable tarball that includes a working test directory so \npeople know if they got a working copy of cwm.\nAttatched is an example such tarball, which passes all tests on my \nmachine. Further, the normal install tarball should be a subset of this \none (Remove anything not on this list from it).\n\n\nAs far as I can tell, such a tarball would need to include:\ncwm/\ncwm/test/\ncwm/test/Makefile\ncwm/test/regression.n3\ncwm/test/online.tests\ncwm/test/list/\ncwm/test/list/detailed.tests\ncwm/test/list/itemType.rdf\ncwm/test/list/append.n3\ncwm/test/list/construct.n3\ncwm/test/list/double.n3\ncwm/test/list/last.n3\ncwm/test/list/list-bug1.n3\ncwm/test/list/list-bug2.n3\ncwm/test/list/r1.n3\ncwm/test/list/unify1.n3\ncwm/test/list/unify4.n3\ncwm/test/daml-ex.n3\ncwm/test/math/\ncwm/test/math/detailed.tests\ncwm/test/math/math-test.n3\ncwm/test/math/trigo-test.n3\ncwm/test/math/trigo.ref.n3\ncwm/test/norm/\ncwm/test/norm/detailed.tests\ncwm/test/norm/t-200401-unicode.rdf\ncwm/test/norm/fix.rdf\ncwm/test/norm/av.n3\ncwm/test/norm/USRegionState.n3\ncwm/test/norm/t-200401-unicode.ref\ncwm/test/cwm/\ncwm/test/cwm/detailed.tests\ncwm/test/cwm/fam.n3\ncwm/test/cwm/fam-rules.n3\ncwm/test/cwm/fam-thinkwith.ref\ncwm/test/on-add/\ncwm/test/on-add/smush.n3\ncwm/test/nodeID/\ncwm/test/nodeID/ex1.rdf\ncwm/test/includes/\ncwm/test/includes/404.n3\ncwm/test/includes/concat.n3\ncwm/test/includes/conclusion.n3\ncwm/test/includes/conjunction.n3\ncwm/test/includes/genBnodeInNestedFormula.n3\ncwm/test/includes/n3ExprFor.n3\ncwm/test/includes/quant-implies.n3\ncwm/test/includes/quantifiers_limited.n3\ncwm/test/includes/t1.n3\ncwm/test/includes/t10.n3\ncwm/test/includes/t11.n3\ncwm/test/includes/t2.n3\ncwm/test/includes/t3.n3\ncwm/test/includes/t4.n3\ncwm/test/includes/t6.n3\ncwm/test/includes/t8.n3\ncwm/test/includes/t9br.n3\ncwm/test/includes/uri-startswith.n3\ncwm/test/includes/404-ref.n3\ncwm/test/includes/t10a.n3\ncwm/test/includes/foo.n3\ncwm/test/os/\ncwm/test/os/argv.n3\ncwm/test/os/environ.n3\ncwm/test/roadmap/\ncwm/test/roadmap/todot.n3\ncwm/test/roadmap/test.graph\ncwm/test/string/\ncwm/test/string/endsWith.n3\ncwm/test/string/roughly.n3\ncwm/test/syntax/\ncwm/test/syntax/no-last-nl.n3\ncwm/test/syntax/lstring.n3\ncwm/test/syntax/djb1a.n3\ncwm/test/syntax/dot-dash.n3\ncwm/test/syntax/keywords1.n3\ncwm/test/syntax/keywords2.n3\ncwm/test/syntax/numbers.n3\ncwm/test/syntax/path1.n3\ncwm/test/syntax/path2.n3\ncwm/test/syntax/qvars1.n3\ncwm/test/syntax/qvars2.n3\ncwm/test/time/\ncwm/test/time/t1.n3\ncwm/test/time/t1s.n3\ncwm/test/unify/\ncwm/test/unify/reflexive.n3\ncwm/test/unify/reflexive-ref.n3\ncwm/test/rules13.n3\ncwm/test/xml-syntax/\ncwm/test/xml-syntax/in-xml.xml\ncwm/test/invalid-ex.n3\ncwm/test/schema-rules.n3\ncwm/test/animal.rdf\ncwm/test/vblsNotURIs.n3\ncwm/test/smush-examples.rdf\ncwm/test/smush-schema.n3\ncwm/test/sameThing.n3\ncwm/test/forgetDups.n3\ncwm/test/smush-query.n3\ncwm/test/equiv-syntax.n3\ncwm/test/lists-simple.n3\ncwm/test/lists.n3\ncwm/test/strquot.n3\ncwm/test/owl-ex.rdf\ncwm/test/anon-prop.n3\ncwm/test/contexts.n3\ncwm/test/schema-filter.n3\ncwm/test/rules12.n3\ncwm/test/daml-ont.n3\ncwm/test/daml-pref.n3\ncwm/test/daml-ont.rdf\ncwm/test/reluri-1.n3\ncwm/test/resolves-rdf.n3\ncwm/test/sameDan.n3\ncwm/test/two-route.n3\ncwm/test/underbarscope.n3\ncwm/test/retest.py\ncwm/test/dbork/\ncwm/test/dbork/defdoc1.n3\ncwm/test/dbork/defdoc2.n3\ncwm/test/dbork/data/\ncwm/test/dbork/data/USRegionState.n3\ncwm/test/dbork/data/USCity.n3\ncwm/test/dbork/daysoftheweek.n3\ncwm/test/dbork/daytable.n3\ncwm/test/ref/\ncwm/test/ref/append-out.n3\ncwm/test/ref/defdoc1-out.n3\ncwm/test/ref/defdoc2-out.n3\ncwm/test/ref/li-double.n3\ncwm/test/ref/li-r1.n3\ncwm/test/ref/list-bug1.n3\ncwm/test/ref/list-bug2.n3\ncwm/test/ref/list-construct.n3\ncwm/test/ref/list-last.n3\ncwm/test/ref/list-unify1.n3\ncwm/test/ref/list-unify2.n3\ncwm/test/ref/list-unify3.n3\ncwm/test/ref/list-unify4.n3\ncwm/test/ref/lists-simple-1.rdf\ncwm/test/ref/lists-simple.n3\ncwm/test/ref/norm-av1.n3\ncwm/test/ref/norm-av2.n3\ncwm/test/ref/animal-1.rdf\ncwm/test/ref/animal-ntriples.n3\ncwm/test/ref/animal.n3\ncwm/test/ref/anon-prop-1.n3\ncwm/test/ref/argv-1.n3\ncwm/test/ref/argv-2.n3\ncwm/test/ref/bi-concat.n3\ncwm/test/ref/bi-quant-imp.n3\ncwm/test/ref/bi-quant.n3\ncwm/test/ref/bi-t1.n3\ncwm/test/ref/bi-t10.n3\ncwm/test/ref/bi-t11.n3\ncwm/test/ref/bi-t2.n3\ncwm/test/ref/bi-t3.n3\ncwm/test/ref/bi-t4.n3\ncwm/test/ref/bi-t6.n3\ncwm/test/ref/bi-t8.n3\ncwm/test/ref/bi-t9.n3\ncwm/test/ref/bi-uri-startswith.n3\ncwm/test/ref/bnode.n3\ncwm/test/ref/bnode.rdf\ncwm/test/ref/conclusion.n3\ncwm/test/ref/conjunction.n3\ncwm/test/ref/contexts-1.n3\ncwm/test/ref/daml-ex.n3\ncwm/test/ref/daml-ont-piped.n3\ncwm/test/ref/daml-ont.n3\ncwm/test/ref/data-ugly.n3\ncwm/test/ref/djb1a-out.n3\ncwm/test/ref/dot-dash.n3\ncwm/test/ref/endsWith-out.n3\ncwm/test/ref/environ.n3\ncwm/test/ref/equiv-syntax.n3\ncwm/test/ref/genBnodeInNestedFormula-out.n3\ncwm/test/ref/in-xml-t.n3\ncwm/test/ref/in-xml.n3\ncwm/test/ref/itemType.n3\ncwm/test/ref/keywords1.n3\ncwm/test/ref/keywords2.n3\ncwm/test/ref/lists.n3\ncwm/test/ref/lstring-out.n3\ncwm/test/ref/math1.n3\ncwm/test/ref/n3ExprFor-out.n3\ncwm/test/ref/no-last-nl.n3\ncwm/test/ref/numbers-n.n3\ncwm/test/ref/numbers.n3\ncwm/test/ref/numbers.rdf\ncwm/test/ref/path1.n3\ncwm/test/ref/path2.n3\ncwm/test/ref/prefix1.rdf\ncwm/test/ref/prefix2.rdf\ncwm/test/ref/prefix3.rdf\ncwm/test/ref/qvars1.n3\ncwm/test/ref/qvars2.n3\ncwm/test/ref/reluri-1.rdf\ncwm/test/ref/resolves-rdf.n3\ncwm/test/ref/roughly-out.n3\ncwm/test/ref/rules-flag-a.n3\ncwm/test/ref/rules-flag-t.n3\ncwm/test/ref/rules12-1.n3\ncwm/test/ref/rules12-n.n3\ncwm/test/ref/rules13-n.n3\ncwm/test/ref/sameDan.n3\ncwm/test/ref/schema1.n3\ncwm/test/ref/schema2.n3\ncwm/test/ref/smush.rdf\ncwm/test/ref/smush6.n3\ncwm/test/ref/strquot.n3\ncwm/test/ref/timet1.n3\ncwm/test/ref/timet1s.n3\ncwm/test/ref/two-route.n3\ncwm/test/ref/underbarscope-out.n3\ncwm/test/ref/vblsNotURIs-out.n3\ncwm/test/ref/roadmap-test.dot\ncwm/cwm.py\ncwm/notation3.py\ncwm/xml2rdf.py\ncwm/query.py\ncwm/llyn.py\ncwm/uripath.py\ncwm/diag.py\ncwm/RDFSink.py\ncwm/why.py\ncwm/myStore.py\ncwm/webAccess.py\ncwm/OrderedSequence.py\ncwm/term.py\ncwm/formula.py\ncwm/pretty.py\ncwm/cwm_list.py\ncwm/cwm_string.py\ncwm/cwm_os.py\ncwm/cwm_time.py\ncwm/isodate.py\ncwm/cwm_math.py\ncwm/cwm_trigo.py\ncwm/cwm_times.py\ncwm/cwm_maths.py\ncwm/toXML.py\ncwm/update.py\ncwm/sax2rdf.py\n\n\n\n\n\napplication/x-gzip attachment: cwm-install.tar.gz\n\n\n\n\n"
        },
        {
            "subject": "bug Schema lookup issue",
            "content": "1. My test involves using an Ontology of mine\nlocated on my hard drive that is referenced \nin the xmlns -- I want read in N3 data that references\nmy Ontology. But CWM is croaking because it also\nwants to read in other schemas, such as XMLSchema.\n\n   Here are the N3 headers in my test file that\n   accesses my ontology:\n   \n        @prefix rdfs:\n<http://www.w3.org/2000/01/rdf-schema#> .\n        @prefix owl:  <http://www.w3.org/2002/07/owl#>\n\n\n\n"
        },
        {
            "subject": "bug Cannot use XSD datatypes with cwm builtins",
            "content": "Error msg=File\n\"c:\\Python23\\Lib\\site-packages\\cwm\\term.py\", line 708,\nin value\n    raise ValueError(\"Attempt to run built-in on\nunknown datatype %s of value %s\n.\"  \n\nOccurs with use of rules (see below) when input uses\nXML Schema datatypes (\"xsd;string\") Repeated test,\nremoving\nproperty rdf:range statements and \"^^xsd;string\" from\ninstance data, and the rules functioned properly. \n\nRule Used (same as tutorial involving strings):\n===============================================\nthis log:forAll :x, :k, :s .     \n{  :x exp:memo :k .\n   ( :x!exp:typCd \" \" :x!exp:category \" transaction\\n\"\n)\n         string:concatenation  :s .\n} => {\n   :k log:outputString :s . \n} .\n\nOriginal (bad) N3 file \n======================\n\n:exp1 a exp:Expenditure;\n\nexp:id\"1\"^^xsd:long;\nexp:dt  \"2004-06-12\"^^xsd:date;\nexp:fromAcctId\"CASH\"^^xsd:string;\nexp:toAcctId \"STORE\"^^xsd:string;\nexp:typCd       \"BUY\"^^xsd:string;\nexp:category\"FOOD\"^^xsd:string;\nexp:subCategory\"FOOD\"^^xsd:string;\nexp:netExpAmt\"21.38\"^^xsd:decimal;\nexp:memo\"Test exp1\"^^xsd:string . \n\n\nModified (good) N3 file of instance data:\n=========================================\n:exp1 a exp:Expenditure;\n\nexp:id\"1\";\nexp:dt  \"2004-06-12\";\nexp:fromAcctId\"CASH\";\nexp:toAcctId \"STORE\";\nexp:typCd       \"BUY\";\nexp:category\"FOOD\";\nexp:subCategory\"FOOD\";\nexp:netExpAmt\"21.38\";\nexp:memo\"Test exp1\" . \n\n\nNOTE: Am using \nPyXML-0.8.3.win32-py2.3.exe\nPython-2.3.3.exe\ncwm.py,v 1.148 2004/03/21 04:24:32 timbl\n\nP.S. This is just a test of something similar to\na database row without additional OWL class typing.\n\n\n=========================================================================\nOutput of \"Bad\" Test (with XSD datatypes)\n=========================================================================\n\nC:\\my\\cwm>python\nc:/Python23/Lib/site-packages/cwm/cwm.py --mode=u\n--rdf t\nut\\MyExpenditures.xml --n3 tut\\MyExp01.n3\ntut\\MyExpRules.n3 --think --strings  1\n>tut\\MyExp01OUT.txt\nTraceback (most recent call last):\n  File \"c:/Python23/Lib/site-packages/cwm/cwm.py\",\nline 646, in ?\n    doCommand()\n  File \"c:/Python23/Lib/site-packages/cwm/cwm.py\",\nline 517, in doCommand\n    think(workingContext, mode=option_flags[\"think\"])\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 58, in think\n    return InferenceTask(knowledgeBase, ruleFormula,\nmode=mode, repeat=1).run()\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 207, in run\n    return self.runSmart()\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 195, in runSmart\n    total += cy.run()\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 303, in run\n    return rule.once()\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 404, in once\n    total = query.resolve()\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 545, in resolve\n    return self.unify(self.queue, self.variables,\nself.existentials)\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 781, in unify\n    bindings.copy(), nb, evidence = evidence +\n[reason])\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 781, in unify\n    bindings.copy(), nb, evidence = evidence +\n[reason])\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 712, in unify\n    nbs = item.tryBuiltin(queue, bindings, heavy=0,\nevidence=evidence)\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\query.py\",\nline 984, in tryBuiltin\n    result = pred.evalObj(subj, queue,\nbindings.copy(), proof, self.query)\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\term.py\",\nline 836, in evalObj\n    return\nself.store._fromPython(self.evaluateObject(subj.value()))\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\term.py\",\nline 450, in value\n    res.append(x.value())\n  File \"c:\\Python23\\Lib\\site-packages\\cwm\\term.py\",\nline 708, in value\n    raise ValueError(\"Attempt to run built-in on\nunknown datatype %s of value %s\n.\"\nNameError: global name 'x' is not defined\n\n\n=========================================================================\nOutput of \"Good\" Test (with XSD datatypes)\n=========================================================================\nC:\\my\\cwm>M2Exp01\n\nC:\\my\\cwm>cd c:\\my\\cwm\n\nC:\\my\\cwm>python\nc:/Python23/Lib/site-packages/cwm/cwm.py --rdf\ntut\\M2Expe\nnditures.xml --n3 tut\\M2Exp01.n3 --rdf \n1>tut\\M2Exp01.rdf\n\nC:\\my\\cwm>python\nc:/Python23/Lib/site-packages/cwm/cwm.py --rdf\ntut\\M2Expe\nnditures.xml --n3 tut\\M2Exp01.n3 tut\\M2ExpRules.n3\n--think --strings  1>tut\\M2Ex\np01OUT.txt\nC:\\my\\cwm>\n\n\n\n\n__________________________________\nDo you Yahoo!?\nFriends.  Fun.  Try the all-new Yahoo! Messenger.\nhttp://messenger.yahoo.com/ \n\n\n\n"
        },
        {
            "subject": "Bug ignoring RDF/XML xml:base",
            "content": "To whom it may concern:\n\nThis may not be a bug with CWM, and may instead by user error, but it\nseems like CWM is not correctly taking advantage of xml:base information\nin the RDF/XML serialization.  To whit, with an RDF/XML baseline of:\n\n    <rdf:RDF \n        xmlns:project=\"http://through.dnsalias.net/2004/project/\"\n        xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n        xml:base=\"http://through.dnsalias.net/2003/research/jclark/requirements.xml\">\n\n        <project:Article rdf:about=\"\">\n        </project>\n    </rdf:RDF>\n\nThen using:\n\n    # cwm.py --rdf file.rdf\n\nWe get:\n\n    <rdf:RDF xmlns=\"file:/path/to/file.rdf#\"\n        xmlns:project=\"http://through.dnsalias.net/2004/project/\"\n        xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n\n        <project:Article rdf:about=\"\">\n        </project>\n    </rdf:RDF>\n\nIn particular, if I am correct in my interpretation of the RDF spec, the\nstatement in the second information set does not refer to the same\nresource as that in the first information set.  As a minor secondary\nissue, the default xmlns comes out of nowhere.\n\nThank you, and take care,\n\n    John L. Clark\n\n\n\n\n"
        },
        {
            "subject": "[closed] Re: Bug ignoring RDF/XML xml:base",
            "content": "John,\n\nThanks for pointing this out.  xml:base had never been implemented in \nthe parser.\nIt now has, with the latest release 0.7.1\n\nThe RDF core test suite is now added to the regression test so \nhopefully this will stay fixed.\nXML literals and reification are still not supported.\n\nTim BL\n\n\n\n"
        },
        {
            "subject": "0.7.1 fails in math/detailed.tests#t1039",
            "content": "I tried the new release; failed thusly:\n\nconnolly@dirk:~/w3ccvs/WWW/2000/10/swap/test$ make\nrm -f ../*.pyc\ntouch pyc-check\nPYTHONPATH=`/bin/pwd`/.. python retest.py -c regression.n3\nlist/detailed.tests online.tests math/detailed.tests norm/detailed.tests\ncwm/detailed.tests i18n/detailed.tests ntriples/detailed.tests\nrdfcore-tests.n3 testmeta.n3\nretest.py:35: DeprecationWarning: Non-ASCII character '\\xc2' in file\n/home/connolly/w3ccvs/WWW/2000/10/swap/llyn.py on line 38, but no\nencoding declared; see http://www.python.org/peps/pep-0263.html for\ndetails\n  import llyn\n  1/205 cwm/detailed.tests#cwm001       Use think=rules.n3 to iterate\nusing separate rules\n  2/205 i18n/detailed.tests#int001      N3 string, qname and IRI with\nutf-8 non-ascii characters\n  3/205 i18n/detailed.tests#int002      N3 string, qname and IRI with\nutf-8 non-ascii. N3 to XML\n  4/205 i18n/detailed.tests#int003      XML to XML with utf-8 non-ascii\ncharacters\n  5/205 list/detailed.tests#t1017       parsing and generation of N3\nlist syntax  6/205 list/detailed.tests#t1018       conversion of N3 list\nsyntax to RDF\n  7/205 list/detailed.tests#t1018b1     List processing bug check 1\n  8/205 list/detailed.tests#t1018b2     List processing bug check 2\n  9/205 list/detailed.tests#t1020       What to do with URI-labelled\nlists\n 10/205 list/detailed.tests#t1031       Inference using lists\n 11/205 list/detailed.tests#t1032a      Query with list with the same\nvar in >once\n 12/205 list/detailed.tests#t2004u1     List unification 1\n 13/205 list/detailed.tests#t2004u2     List unification 2 - variable in\nlist\n 14/205 list/detailed.tests#t2004u3     List unification 3 - nested\nlists\n 15/205 list/detailed.tests#t2004u4     List unification 4 - nested\nlists\n 16/205 list/detailed.tests#t2005       Iterative ops on lists\n 17/205 list/detailed.tests#t2006       last, in builtins on lists\n 18/205 math/detailed.tests#t10393      Various math builtins\n 19/205 math/detailed.tests#t10394      Various trig builtins\nTraceback (most recent call last):\n  File \"../cwm.py\", line 636, in ?\n    doCommand()\n  File \"../cwm.py\", line 507, in doCommand\n    think(workingContext, mode=option_flags[\"think\"])\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 58, in\nthink\n    return InferenceTask(knowledgeBase, ruleFormula, mode=mode,\nrepeat=1).run()\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 210, in\nrun\n    return self.runSmart()\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 198, in\nrunSmart\n    total += cy.run()\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 306, in\nrun\n    return rule.once()\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 405, in\nonce\n    total = query.resolve()\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 546, in\nresolve\n    return self.unify(self.queue, self.variables, self.existentials)\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 782, in\nunify\n    bindings.copy(), nb, evidence = evidence + [reason])\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 713, in\nunify\n    nbs = item.tryBuiltin(queue, bindings, heavy=0, evidence=evidence)\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/query.py\", line 997, in\ntryBuiltin\n    result = pred.evalSubj(obj, queue, bindings.copy(), proof,\nself.query)\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/term.py\", line 868, in\nevalSubj\n    return self.store._fromPython(self.evaluateSubject(obj.value()))\n  File \"/home/connolly/w3ccvs/WWW/2000/10/swap/cwm_trigo.py\", line 63,\nin evaluateSubject\n    return acos(numeric(x))\nValueError: math domain error\nFiles differ, result= 256\n#  If this is OK,   cp ,temp/detailed.tests_t10394.out math/trigo.ref.n3\n######### Differences from reference output:\n--- math/trigo.ref.n3   2004-03-06 14:39:42.000000000 -0600\n+++ ,temp/detailed.tests_t10394.out     2004-03-09 17:04:58.000000000\n-0600\n@@ -1,58 +0,0 @@\n-     @prefix : <#> .\n-\n-    -0.707     a :TestValue;\n-         :ACOS 2.3560434901900495;\n-         :ASIN -0.78524716339515299;\n-         :ATAN -0.6154085176292563;\n-         :COS 0.76031396174443966;\n-         :COSH 1.2605098866758351;\n-         :SIN -0.64955575555642242;\n-         :SINH -0.76738854200953921;\n-         :TAN -0.85432569732917008;\n-         :TANH -0.60879216428303051 .\n-\n-    0.23     a :TestValue;\n-         :ACOS 1.3387186439321834;\n-         :ASIN 0.23207768286271319;\n-         :ATAN 0.22606838799388393;\n-         :COS 0.97366639500537489;\n-         :COSH 1.0265668062164059;\n-         :SIN 0.22797752353518841;\n-         :SINH 0.2320332037130719;\n-         :TAN 0.2341433623514653;\n-         :TANH 0.22602835227867096 .\n-\n-    1.23     a :TestValue;\n-         :ACOS nan;\n-         :ASIN nan;\n-         :ATAN 0.88817377437767964;\n-         :COS 0.33423772712450261;\n-         :COSH 1.8567610569852664;\n-         :SIN 0.94248880193169748;\n-         :SINH 1.564468479304407;\n-         :TAN 2.8198157342681518;\n-         :TANH 0.84257932565892957 .\n-\n-    3.1415926535897931     a :Pi,\n-                :TestValue;\n-         :ACOS nan;\n-         :ASIN nan;\n-         :ATAN 1.2626272556789118;\n-         :COS -1.0;\n-         :COSH 11.591953275521519;\n-         :SIN 1.2246467991473532e-16;\n-         :SINH 11.548739357257748;\n-         :TAN -1.2246467991473532e-16;\n-         :TANH 0.99627207622074987 .\n-\n-    0     a :TestValue;\n-         :ACOS 1.5707963267948966;\n-         :ASIN 0.0;\n-         :ATAN 0.0;\n-         :COS 1.0;\n-         :COSH 1.0;\n-         :SIN 0.0;\n-         :SINH 0.0;\n-         :TAN 0.0;\n-         :TANH 0.0 .\n-\n \n######### from normal case detailed.tests_t10394.out: cwm\nmath/trigo-test.n3 --think --data\nmake: *** [all] Error 255\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "reflexive bug in cwm",
            "content": " \nI think the use of reflexive relations may not be properly handled in CWM\n(v.1.145). I was trying to represent a series of relations where some may\noccasionally be reflexive:  <a> <relates> <a>. But when I tried to apply a\nsimple rule in catching these instances, it seems to falsely find all triples\nthat have objects regardless of the subject.  The example follows: \n\n      @prefix log: <http://www.w3.org/2000/10/swap/log#> .\n     @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n     @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n\n      :Tom :talksTo :Kathy  .\n\n      :Kathy :talksTo :Bob .\n\n      :Bob :talksTo :Steve  .\n\n      :Steve :talksTo :Anna  .\n\n      :Anna :talksTo :Anna .\n\n      this log:forAll :s .\n     { :s :talksTo :s .} => {:s :admits \"I talk to myself\"} .\n\nThe rule is designed to match only reflexive cases for ???talksTo???.\nAccordingly, only the last relation, ???Anna talks to Anna???, should be the\nsingle instance the rule should accept. However, the output of applying this\nrule using ???think is:\n\n     :Anna     :admits \"I talk to myself\";\n        :talksTo :Anna .\n\n    :Bob     :admits \"I talk to myself\";\n         :talksTo :Steve .\n\n    :Kathy     :admits \"I talk to myself\";\n         :talksTo :Bob .\n\n    :Steve     :admits \"I talk to myself\";\n         :talksTo :Anna .\n\n    :Tom     :talksTo :Kathy .\n\n \n\nClearly the first instance is the correct one, but there should be no others.\nAll however seem to satisfy the rule, except for Tom, and this seems to be\nbecause Tom is never used as an object. Somehow, only relations with objects\nsatisfy the rule, while ignoring the subject, and this cannot be correct! \n\nHas this behavior been seen by others as well? It prohibits some basic logic\ntest to be performed???specifically, I was attempting to code the classic\n???Muddy Children Problem??? in N3 to see how CWM would reason. It needs to\nrepresent knowledge of which kids have mud on the foreheads. Initially each\nchild is not able to see mud on their own, but has to reason it from the\nresponse of the other children to an indirect question. It ends up being a\nseries of recursive quotes of quotes (reifications) of who knows he/she has\nmud on their forehead???\n\n cheers,\n\nEric\n\n\n\n\n"
        },
        {
            "subject": "nodeID serialization in cwm is hose",
            "content": "I ran:\n\n$ python ../../2000/10/swap/cwm.py itin-ams,.n3 --rdf >,xxx.rdf\n\nand cwm generated nodeIDs in some places:\n\n        <cal:component r:nodeID=\"b6\"/>\n        <cal:component r:nodeID=\"b7\"/>\n\nbut it didn't change it\neverywhere:                                                                                \n    <itin:_gECONOMY_5 r:about=\"itin-ams.n3#_gflt1163_13\">\n\nThis is obviously insufficiently tested. It was spelling\nthe attribute rdf:nodeid until I checked in toXML.py version...\nhuh? odd... I seem to have skewed versions... I'm gonna\nsend this anyway and then investigate.\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n#Processed by Id: cwm.py,v 1.147 2004/03/09 23:07:05 connolly Exp \n        #    using base file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/\n        \n#  Notation3 generation by\n#       notation3.py,v 1.152 2004/03/06 20:39:38 timbl Exp\n\n#   Base was: file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/\n     @prefix : <http://opencyc.sourceforge.net/daml/cyc.daml#> .\n     @prefix ams: <http://www.w3.org/2002/12/cal/tzd/Europe/Amsterdam#> .\n     @prefix apt: <http://www.daml.org/2001/10/html/airport-ont#> .\n     @prefix budapest: <http://www.w3.org/2002/12/cal/tzd/Europe/Budapest#> .\n     @prefix cal: <http://www.w3.org/2002/12/cal/ical#> .\n     @prefix chi: <http://www.w3.org/2002/12/cal/tzd/America/Chicago#> .\n     @prefix cityl: <http://www.w3.org/2000/10/swap/pim/cityLookup#> .\n     @prefix den: <http://www.w3.org/2002/12/cal/tzd/America/Denver#> .\n     @prefix dt: <http://www.w3.org/2001/XMLSchema#> .\n     @prefix geo: <http://www.w3.org/2003/01/geo/wgs84_pos#> .\n     @prefix ic: <../../2000/10/swap/pim/itin2ical#> .\n     @prefix itin: <itin-ams.n3#> .\n     @prefix la: <http://www.w3.org/2002/12/cal/tzd/America/Los_Angeles#> .\n     @prefix log: <http://www.w3.org/2000/10/swap/log#> .\n     @prefix london: <http://www.w3.org/2002/12/cal/tzd/Europe/London#> .\n     @prefix map: <http://www.w3.org/2000/10/swap/pim/earthMap#> .\n     @prefix ny: <http://www.w3.org/2002/12/cal/tzd/America/New_York#> .\n     @prefix paris: <http://www.w3.org/2002/12/cal/tzd/Europe/Paris#> .\n     @prefix r: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n     @prefix t: <http://www.w3.org/2000/10/swap/pim/travelTerms#> .\n     @prefix zurich: <http://www.w3.org/2002/12/cal/tzd/Europe/Zurich#> .\n    \n    this     log:forSome itin:_gECONOMY_5,\n                itin:_gNORTHWESTAIRLINES_4,\n                itin:_gdaySATURDAY24_10,\n                itin:_gdayTUESDAY20_2,\n                itin:_gdayWEDNESDAY21_8,\n                itin:_gflt1163_13,\n                itin:_gflt1530_3,\n                itin:_gflt42_7,\n                itin:_gflt57_11 .\n    \n    <../../2000/10/swap/pim/itin2ical.n3>     <http://purl.org/dc/elements/1.1/description> \"\"\"\nrules to map from travel itinerary vocabulary\nto iCalendar vocabulary.\n$Id: itin2ical.n3,v 1.9 2004/03/31 21:43:29 connolly Exp $\n\"\"\";\n         <http://purl.org/dc/elements/1.1/relation> <../../2000/10/swap/pim/toIcal.py>,\n                <http://www.w3.org/2002/12/cal/fromIcal.py>,\n                <http://www.w3.org/2002/12/cal/ical>;\n         <http://purl.org/dc/elements/1.1/source> <ftp://elsie.nci.nih.gov/pub/>,\n                <http://www.ietf.org/rfc/rfc2445.txt> .\n    \n    <itin-ams.n3>     a :ItineraryDocument,\n                cal:Vcalendar;\n         :containsInformationAbout-Focally itin:thisTrip;\n         <http://www.w3.org/2000/01/rdf-schema#seeAlso> <http://www.w3.org/People/Connolly/home-smart>;\n         cal:component itin:_gflt1163_13,\n                itin:_gflt1530_3,\n                itin:_gflt42_7,\n                itin:_gflt57_11 .\n    \n    itin:_gECONOMY_5     r:value \"ECONOMY\" .\n    \n    itin:_gNORTHWESTAIRLINES_4     a :AirlineCompany;\n         :nameOfAgent \"NORTHWEST AIRLINES\" .\n    \n    itin:_gdaySATURDAY24_10     a :Saturday;\n         dt:date \"2004-04-24\" .\n    \n    itin:_gdayTUESDAY20_2     a :Tuesday;\n         dt:date \"2004-04-20\" .\n    \n    itin:_gdayWEDNESDAY21_8     a :Wednesday;\n         dt:date \"2004-04-21\" .\n    \n    itin:_gflt1163_13     a itin:_gECONOMY_5,\n                cal:Vevent;\n         <@@#seatNum> \"6D\";\n         :endingDate itin:_gdaySATURDAY24_10;\n         :fromLocation <http://www.daml.org/cgi-bin/airport?MEM>;\n         :startingDate itin:_gdaySATURDAY24_10;\n         :toLocation <http://www.daml.org/cgi-bin/airport?MCI>;\n         t:arrivalTime \"19:59\";\n         t:carrier itin:_gNORTHWESTAIRLINES_4;\n         t:departureTime \"18:35\";\n         t:flightNumber \"1163\";\n         cal:dtend  [\n             cal:dateTime \"2004-04-24T19:59:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Chicago\" ];\n         cal:dtstart  [\n             cal:dateTime \"2004-04-24T18:35:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Chicago\" ];\n         cal:summary \"NORTHWEST AIRLINES #1163 from MEMPHIS to KANSAS CITY INTL\";\n         cal:uid \"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt1163_13@uri-2-mid.w3.org\" .\n    \n    itin:_gflt1530_3     a itin:_gECONOMY_5,\n                cal:Vevent;\n         <@@#seatNum> \"8B\";\n         :endingDate itin:_gdayTUESDAY20_2;\n         :fromLocation <http://www.daml.org/cgi-bin/airport?MCI>;\n         :startingDate itin:_gdayTUESDAY20_2;\n         :toLocation <http://www.daml.org/cgi-bin/airport?MSP>;\n         t:arrivalTime \"13:45\";\n         t:carrier itin:_gNORTHWESTAIRLINES_4;\n         t:departureTime \"12:24\";\n         t:flightNumber \"1530\";\n         cal:dtend  [\n             cal:dateTime \"2004-04-20T13:45:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Chicago\" ];\n         cal:dtstart  [\n             cal:dateTime \"2004-04-20T12:24:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Chicago\" ];\n         cal:summary \"NORTHWEST AIRLINES #1530 from KANSAS CITY INTL to MINNEAPOLIS ST PL\";\n         cal:uid \"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt1530_3@uri-2-mid.w3.org\" .\n    \n    itin:_gflt42_7     a itin:_gECONOMY_5,\n                cal:Vevent;\n         <@@#seatNum> \"19H\";\n         :endingDate itin:_gdayWEDNESDAY21_8;\n         :fromLocation <http://www.daml.org/cgi-bin/airport?MSP>;\n         :startingDate itin:_gdayTUESDAY20_2;\n         :toLocation <http://www.daml.org/cgi-bin/airport?AMS>;\n         t:arrivalTime \"06:30\";\n         t:carrier itin:_gNORTHWESTAIRLINES_4;\n         t:departureTime \"15:20\";\n         t:flightNumber \"42\";\n         cal:dtend  [\n             cal:dateTime \"2004-04-21T06:30:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/Europe/Amsterdam\" ];\n         cal:dtstart  [\n             cal:dateTime \"2004-04-20T15:20:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Chicago\" ];\n         cal:summary \"NORTHWEST AIRLINES #42 from MINNEAPOLIS ST PL to AMSTERDAM\";\n         cal:uid \"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt42_7@uri-2-mid.w3.org\" .\n    \n    itin:_gflt57_11     a itin:_gECONOMY_5,\n                cal:Vevent;\n         <@@#seatNum> \"20H\";\n         :endingDate itin:_gdaySATURDAY24_10;\n         :fromLocation <http://www.daml.org/cgi-bin/airport?AMS>;\n         :startingDate itin:_gdaySATURDAY24_10;\n         :toLocation <http://www.daml.org/cgi-bin/airport?MEM>;\n         t:arrivalTime \"17:05\";\n         t:carrier itin:_gNORTHWESTAIRLINES_4;\n         t:departureTime \"14:25\";\n         t:flightNumber \"57\";\n         cal:dtend  [\n             cal:dateTime \"2004-04-24T17:05:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Chicago\" ];\n         cal:dtstart  [\n             cal:dateTime \"2004-04-24T14:25:00\";\n             cal:tzid \"/softwarestudio.org/Olson_20011030_5/Europe/Amsterdam\" ];\n         cal:summary \"NORTHWEST AIRLINES #57 from AMSTERDAM to MEMPHIS\";\n         cal:uid \"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt57_11@uri-2-mid.w3.org\" .\n    \n    itin:thisTrip     :firstSubEvents itin:_gflt1530_3;\n         :lastSubEvents itin:_gflt1163_13;\n         :passengers <http://www.w3.org/People/Connolly/home-smart#me>;\n         :subEvents itin:_gflt1163_13,\n                itin:_gflt1530_3,\n                itin:_gflt42_7,\n                itin:_gflt57_11 .\n    \n    <ftp://elsie.nci.nih.gov/pub/>     <http://purl.org/dc/elements/1.1/creator> \"Olson, A.D., et al\";\n         <http://purl.org/dc/elements/1.1/description> \"updated periodically\";\n         <http://purl.org/dc/elements/1.1/title> \"Time zone code and data\" .\n    \n    :Saturday     a :DayOfWeekType;\n         :nameString \"Saturday\" .\n    \n    :Tuesday     a :DayOfWeekType;\n         :nameString \"Tuesday\" .\n    \n    :Wednesday     a :DayOfWeekType;\n         :nameString \"Wednesday\" .\n    \n    <http://www.daml.org/cgi-bin/airport?AHO>     a :Airport-Physical;\n         ic:timeZone paris:tz;\n         :nameString \"ALGHERO\" .\n    \n    <http://www.daml.org/cgi-bin/airport?AMS>     a :Airport-Physical;\n         ic:timeZone ams:tz;\n         :inRegion ams:tz;\n         :nameString \"AMSTERDAM\";\n         apt:iataCode \"AMS\";\n         cityl:formVal \"AMS\";\n         cityl:weatherPage <http://www.wunderground.com/cgi-bin/findweather/getForecast?query=AMS>;\n         geo:lat \"52.29999924\";\n         geo:long \"4.76999998\" .\n    \n    <http://www.daml.org/cgi-bin/airport?ATL>     a :Airport-Physical;\n         ic:timeZone ny:tz;\n         :nameString \"Atlanta, GA\" .\n    \n    <http://www.daml.org/cgi-bin/airport?BOS>     a :Airport-Physical;\n         ic:timeZone ny:tz;\n         :nameString \"BOSTON\" .\n    \n    <http://www.daml.org/cgi-bin/airport?BUD>     a :Airport-Physical;\n         ic:timeZone budapest:tz .\n    \n    <http://www.daml.org/cgi-bin/airport?CDG>     a :Airport-Physical;\n         ic:timeZone paris:tz;\n         :nameString \"PARIS DE GAULLE\" .\n    \n    <http://www.daml.org/cgi-bin/airport?DCA>     a :Airport-Physical;\n         ic:timeZone ny:tz;\n         :nameString \"WASHINGTON REAGAN\" .\n    \n    <http://www.daml.org/cgi-bin/airport?DEN>     a :Airport-Physical;\n         ic:timeZone den:tz .\n    \n    <http://www.daml.org/cgi-bin/airport?DFW>     a :Airport-Physical;\n         ic:timeZone chi:tz;\n         :nameString \"DALLAS FT WORTH\" .\n    \n    <http://www.daml.org/cgi-bin/airport?EWR>     a :Airport-Physical;\n         ic:timeZone ny:tz;\n         :nameString \"NEWARK\" .\n    \n    <http://www.daml.org/cgi-bin/airport?FCO>     a :Airport-Physical;\n         ic:timeZone paris:tz;\n         :nameString \"ROME FIUMICINO\" .\n    \n    <http://www.daml.org/cgi-bin/airport?JFK>     a :Airport-Physical;\n         ic:timeZone ny:tz .\n    \n    <http://www.daml.org/cgi-bin/airport?LAX>     a :Airport-Physical;\n         ic:timeZone la:tz .\n    \n    <http://www.daml.org/cgi-bin/airport?LGA>     a :Airport-Physical;\n         ic:timeZone ny:tz .\n    \n    <http://www.daml.org/cgi-bin/airport?LHR>     a :Airport-Physical;\n         ic:timeZone london:tz;\n         :nameString \"LONDON HEATHROW\" .\n    \n    <http://www.daml.org/cgi-bin/airport?MCI>     a :Airport-Physical;\n         ic:timeZone chi:tz;\n         :inRegion chi:tz;\n         :nameString \"KANSAS CITY INTL\";\n         apt:iataCode \"MCI\";\n         cityl:formVal \"MCI\";\n         cityl:weatherPage <http://www.wunderground.com/cgi-bin/findweather/getForecast?query=MCI>;\n         geo:lat \"39.30347824\";\n         geo:long \"-94.71977997\" .\n    \n    <http://www.daml.org/cgi-bin/airport?MEM>     a :Airport-Physical;\n         ic:timeZone chi:tz;\n         :inRegion chi:tz;\n         :nameString \"MEMPHIS\";\n         apt:iataCode \"MEM\";\n         cityl:formVal \"MEM\";\n         cityl:weatherPage <http://www.wunderground.com/cgi-bin/findweather/getForecast?query=MEM>;\n         geo:lat \"35.06353378\";\n         geo:long \"-89.97751617\" .\n    \n    <http://www.daml.org/cgi-bin/airport?MSP>     a :Airport-Physical;\n         ic:timeZone chi:tz;\n         :inRegion chi:tz;\n         :nameString \"MINNEAPOLIS ST PL\";\n         apt:iataCode \"MSP\";\n         cityl:formVal \"MSP\";\n         cityl:weatherPage <http://www.wunderground.com/cgi-bin/findweather/getForecast?query=MSP>;\n         geo:lat \"44.87760162\";\n         geo:long \"-93.21949768\" .\n    \n    <http://www.daml.org/cgi-bin/airport?NCE>     a :Airport-Physical;\n         ic:timeZone ic:ParisTime;\n         :nameString \"NICE\" .\n    \n    <http://www.daml.org/cgi-bin/airport?ORD>     a :Airport-Physical;\n         ic:timeZone chi:tz;\n         :nameString \"CHICAGO OHARE\" .\n    \n    <http://www.daml.org/cgi-bin/airport?PHL>     a :Airport-Physical;\n         ic:timeZone ny:tz;\n         :nameString \"Philadelphia, PA\" .\n    \n    <http://www.daml.org/cgi-bin/airport?PIT>     a :Airport-Physical;\n         ic:timeZone ny:tz;\n         :nameString \"PITTSBURGH\" .\n    \n    <http://www.daml.org/cgi-bin/airport?SFO>     a :Airport-Physical;\n         ic:timeZone la:tz;\n         :nameString \"SAN FRANCISCO\" .\n    \n    <http://www.daml.org/cgi-bin/airport?SNA>     a :Airport-Physical;\n         ic:timeZone la:tz;\n         :nameString \"JOHN WAYNE INTL\" .\n    \n    <http://www.daml.org/cgi-bin/airport?STL>     a :Airport-Physical;\n         ic:timeZone chi:tz;\n         :nameString \"ST LOUIS INTL\" .\n    \n    <http://www.daml.org/cgi-bin/airport?YMX>     a :Airport-Physical;\n         ic:timeZone ny:tz;\n         :nameString \"MONTREAL DORVALQC\" .\n    \n    <http://www.daml.org/cgi-bin/airport?YVR>     a :Airport-Physical;\n         ic:timeZone la:tz;\n         :nameString \"VANCOUVER BC\" .\n    \n    <http://www.daml.org/cgi-bin/airport?ZRH>     a :Airport-Physical;\n         ic:timeZone zurich:tz .\n    \n    chi:tz     a :SpatialThing,\n                cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Chicago\" .\n    \n    den:tz     a cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Denver\" .\n    \n    la:tz     a cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/Los_Angeles\" .\n    \n    ny:tz     a cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/America/New_York\" .\n    \n    ams:tz     a :SpatialThing,\n                cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/Europe/Amsterdam\" .\n    \n    budapest:tz     a :SpatialThing,\n                cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/Europe/Budapest\" .\n    \n    london:tz     a cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/Europe/London\" .\n    \n    paris:tz     a cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/Europe/Paris\" .\n    \n    zurich:tz     a cal:Vtimezone;\n         cal:tzid \"/softwarestudio.org/Olson_20011030_5/Europe/Zurich\" .\n      [      :inRegion budapest:tz,\n                     [\n                 map:countryName \"Hungary\" ];\n             cityl:formVal \"Budapest%2CHungary\";\n             cityl:weatherPage <http://www.wunderground.com/cgi-bin/findweather/getForecast?query=Budapest%2CHungary>;\n             map:cityName \"Budapest\";\n             geo:lat \"47.43000031\";\n             geo:long \"19.18000031\" ].\n    \n#ENDS\n\n\n<!-- Processed by Id: cwm.py,v 1.147 2004/03/09 23:07:05 connolly Exp -->\n<!--     using base file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams,.n3-->\n\n\n<r:RDF xmlns=\"http://opencyc.sourceforge.net/daml/cyc.daml#\"\n    xmlns:apt=\"http://www.daml.org/2001/10/html/airport-ont#\"\n    xmlns:cal=\"http://www.w3.org/2002/12/cal/ical#\"\n    xmlns:cityl=\"http://www.w3.org/2000/10/swap/pim/cityLookup#\"\n    xmlns:dt=\"http://www.w3.org/2001/XMLSchema#\"\n    xmlns:geo=\"http://www.w3.org/2003/01/geo/wgs84_pos#\"\n    xmlns:ic=\"file:/home/connolly/w3ccvs/WWW/2000/10/swap/pim/itin2ical#\"\n    xmlns:itin=\"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#\"\n    xmlns:map=\"http://www.w3.org/2000/10/swap/pim/earthMap#\"\n    xmlns:r=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n    xmlns:t=\"http://www.w3.org/2000/10/swap/pim/travelTerms#\">\n\n    <r:Description r:about=\"../../2000/10/swap/pim/itin2ical.n3\">\n        <description xmlns=\"http://purl.org/dc/elements/1.1/\">\nrules to map from travel itinerary vocabulary\nto iCalendar vocabulary.\n$Id: itin2ical.n3,v 1.9 2004/03/31 21:43:29 connolly Exp $\n</description>\n        <relation xmlns=\"http://purl.org/dc/elements/1.1/\"\n            r:resource=\"../../2000/10/swap/pim/toIcal.py\"/>\n        <relation xmlns=\"http://purl.org/dc/elements/1.1/\"\n            r:resource=\"http://www.w3.org/2002/12/cal/fromIcal.py\"/>\n        <relation xmlns=\"http://purl.org/dc/elements/1.1/\"\n            r:resource=\"http://www.w3.org/2002/12/cal/ical\"/>\n        <source xmlns=\"http://purl.org/dc/elements/1.1/\"\n            r:resource=\"ftp://elsie.nci.nih.gov/pub/\"/>\n        <source xmlns=\"http://purl.org/dc/elements/1.1/\"\n            r:resource=\"http://www.ietf.org/rfc/rfc2445.txt\"/>\n    </r:Description>\n\n    <ItineraryDocument r:about=\"itin-ams.n3\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vcalendar\"/>\n        <containsInformationAbout-Focally r:resource=\"itin-ams.n3#thisTrip\"/>\n        <seeAlso xmlns=\"http://www.w3.org/2000/01/rdf-schema#\"\n            r:resource=\"http://www.w3.org/People/Connolly/home-smart\"/>\n        <cal:component r:nodeID=\"b6\"/>\n        <cal:component r:nodeID=\"b7\"/>\n        <cal:component r:nodeID=\"b8\"/>\n        <cal:component r:nodeID=\"b9\"/>\n    </ItineraryDocument>\n\n    <r:Description r:nodeID=\"b1\">\n        <r:value>ECONOMY</r:value>\n    </r:Description>\n\n    <AirlineCompany r:about=\"itin-ams.n3#_gNORTHWESTAIRLINES_4\">\n        <nameOfAgent>NORTHWEST AIRLINES</nameOfAgent>\n    </AirlineCompany>\n\n    <Saturday r:about=\"itin-ams.n3#_gdaySATURDAY24_10\">\n        <dt:date>2004-04-24</dt:date>\n    </Saturday>\n\n    <Tuesday r:about=\"itin-ams.n3#_gdayTUESDAY20_2\">\n        <dt:date>2004-04-20</dt:date>\n    </Tuesday>\n\n    <Wednesday r:about=\"itin-ams.n3#_gdayWEDNESDAY21_8\">\n        <dt:date>2004-04-21</dt:date>\n    </Wednesday>\n\n    <itin:_gECONOMY_5 r:about=\"itin-ams.n3#_gflt1163_13\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vevent\"/>\n        <seatNum xmlns=\"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/@@#\">6D</seatNum>\n        <endingDate r:nodeID=\"b3\"/>\n        <fromLocation r:resource=\"http://www.daml.org/cgi-bin/airport?MEM\"/>\n        <startingDate r:nodeID=\"b3\"/>\n        <toLocation r:resource=\"http://www.daml.org/cgi-bin/airport?MCI\"/>\n        <t:arrivalTime>19:59</t:arrivalTime>\n        <t:carrier r:nodeID=\"b2\"/>\n        <t:departureTime>18:35</t:departureTime>\n        <t:flightNumber>1163</t:flightNumber>\n        <cal:dtend r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-24T19:59:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Chicago</cal:tzid>\n        </cal:dtend>\n        <cal:dtstart r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-24T18:35:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Chicago</cal:tzid>\n        </cal:dtstart>\n        <cal:summary>NORTHWEST AIRLINES #1163 from MEMPHIS to KANSAS CITY INTL</cal:summary>\n        <cal:uid>file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt1163_13@uri-2-mid.w3.org</cal:uid>\n    </itin:_gECONOMY_5>\n\n    <itin:_gECONOMY_5 r:about=\"itin-ams.n3#_gflt1530_3\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vevent\"/>\n        <seatNum xmlns=\"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/@@#\">8B</seatNum>\n        <endingDate r:nodeID=\"b4\"/>\n        <fromLocation r:resource=\"http://www.daml.org/cgi-bin/airport?MCI\"/>\n        <startingDate r:nodeID=\"b4\"/>\n        <toLocation r:resource=\"http://www.daml.org/cgi-bin/airport?MSP\"/>\n        <t:arrivalTime>13:45</t:arrivalTime>\n        <t:carrier r:nodeID=\"b2\"/>\n        <t:departureTime>12:24</t:departureTime>\n        <t:flightNumber>1530</t:flightNumber>\n        <cal:dtend r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-20T13:45:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Chicago</cal:tzid>\n        </cal:dtend>\n        <cal:dtstart r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-20T12:24:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Chicago</cal:tzid>\n        </cal:dtstart>\n        <cal:summary>NORTHWEST AIRLINES #1530 from KANSAS CITY INTL to MINNEAPOLIS ST PL</cal:summary>\n        <cal:uid>file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt1530_3@uri-2-mid.w3.org</cal:uid>\n    </itin:_gECONOMY_5>\n\n    <itin:_gECONOMY_5 r:about=\"itin-ams.n3#_gflt42_7\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vevent\"/>\n        <seatNum xmlns=\"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/@@#\">19H</seatNum>\n        <endingDate r:nodeID=\"b5\"/>\n        <fromLocation r:resource=\"http://www.daml.org/cgi-bin/airport?MSP\"/>\n        <startingDate r:nodeID=\"b4\"/>\n        <toLocation r:resource=\"http://www.daml.org/cgi-bin/airport?AMS\"/>\n        <t:arrivalTime>06:30</t:arrivalTime>\n        <t:carrier r:nodeID=\"b2\"/>\n        <t:departureTime>15:20</t:departureTime>\n        <t:flightNumber>42</t:flightNumber>\n        <cal:dtend r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-21T06:30:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/Europe/Amsterdam</cal:tzid>\n        </cal:dtend>\n        <cal:dtstart r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-20T15:20:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Chicago</cal:tzid>\n        </cal:dtstart>\n        <cal:summary>NORTHWEST AIRLINES #42 from MINNEAPOLIS ST PL to AMSTERDAM</cal:summary>\n        <cal:uid>file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt42_7@uri-2-mid.w3.org</cal:uid>\n    </itin:_gECONOMY_5>\n\n    <itin:_gECONOMY_5 r:about=\"itin-ams.n3#_gflt57_11\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vevent\"/>\n        <seatNum xmlns=\"file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/@@#\">20H</seatNum>\n        <endingDate r:nodeID=\"b3\"/>\n        <fromLocation r:resource=\"http://www.daml.org/cgi-bin/airport?AMS\"/>\n        <startingDate r:nodeID=\"b3\"/>\n        <toLocation r:resource=\"http://www.daml.org/cgi-bin/airport?MEM\"/>\n        <t:arrivalTime>17:05</t:arrivalTime>\n        <t:carrier r:nodeID=\"b2\"/>\n        <t:departureTime>14:25</t:departureTime>\n        <t:flightNumber>57</t:flightNumber>\n        <cal:dtend r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-24T17:05:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Chicago</cal:tzid>\n        </cal:dtend>\n        <cal:dtstart r:parseType=\"Resource\">\n            <cal:dateTime>2004-04-24T14:25:00</cal:dateTime>\n            <cal:tzid>/softwarestudio.org/Olson_20011030_5/Europe/Amsterdam</cal:tzid>\n        </cal:dtstart>\n        <cal:summary>NORTHWEST AIRLINES #57 from AMSTERDAM to MEMPHIS</cal:summary>\n        <cal:uid>file:/home/connolly/w3ccvs/WWW/2004/04dc-ams/itin-ams.n3#_gflt57_11@uri-2-mid.w3.org</cal:uid>\n    </itin:_gECONOMY_5>\n\n    <r:Description r:about=\"itin-ams.n3#thisTrip\">\n        <firstSubEvents r:nodeID=\"b7\"/>\n        <lastSubEvents r:nodeID=\"b6\"/>\n        <passengers r:resource=\"http://www.w3.org/People/Connolly/home-smart#me\"/>\n        <subEvents r:nodeID=\"b6\"/>\n        <subEvents r:nodeID=\"b7\"/>\n        <subEvents r:nodeID=\"b8\"/>\n        <subEvents r:nodeID=\"b9\"/>\n    </r:Description>\n\n    <r:Description r:about=\"ftp://elsie.nci.nih.gov/pub/\">\n        <creator xmlns=\"http://purl.org/dc/elements/1.1/\">Olson, A.D., et al</creator>\n        <description xmlns=\"http://purl.org/dc/elements/1.1/\">updated periodically</description>\n        <title xmlns=\"http://purl.org/dc/elements/1.1/\">Time zone code and data</title>\n    </r:Description>\n\n    <DayOfWeekType r:about=\"http://opencyc.sourceforge.net/daml/cyc.daml#Saturday\">\n        <nameString>Saturday</nameString>\n    </DayOfWeekType>\n\n    <DayOfWeekType r:about=\"http://opencyc.sourceforge.net/daml/cyc.daml#Tuesday\">\n        <nameString>Tuesday</nameString>\n    </DayOfWeekType>\n\n    <DayOfWeekType r:about=\"http://opencyc.sourceforge.net/daml/cyc.daml#Wednesday\">\n        <nameString>Wednesday</nameString>\n    </DayOfWeekType>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?AHO\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Paris#tz\"/>\n        <nameString>ALGHERO</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?AMS\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Amsterdam#tz\"/>\n        <inRegion r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Amsterdam#tz\"/>\n        <nameString>AMSTERDAM</nameString>\n        <apt:iataCode>AMS</apt:iataCode>\n        <cityl:formVal>AMS</cityl:formVal>\n        <cityl:weatherPage r:resource=\"http://www.wunderground.com/cgi-bin/findweather/getForecast?query=AMS\"/>\n        <geo:lat>52.29999924</geo:lat>\n        <geo:long>4.76999998</geo:long>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?ATL\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n        <nameString>Atlanta, GA</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?BOS\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n        <nameString>BOSTON</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?BUD\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Budapest#tz\"/>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?CDG\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Paris#tz\"/>\n        <nameString>PARIS DE GAULLE</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?DCA\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n        <nameString>WASHINGTON REAGAN</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?DEN\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Denver#tz\"/>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?DFW\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <nameString>DALLAS FT WORTH</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?EWR\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n        <nameString>NEWARK</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?FCO\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Paris#tz\"/>\n        <nameString>ROME FIUMICINO</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?JFK\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?LAX\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Los_Angeles#tz\"/>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?LGA\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?LHR\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/London#tz\"/>\n        <nameString>LONDON HEATHROW</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?MCI\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <inRegion r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <nameString>KANSAS CITY INTL</nameString>\n        <apt:iataCode>MCI</apt:iataCode>\n        <cityl:formVal>MCI</cityl:formVal>\n        <cityl:weatherPage r:resource=\"http://www.wunderground.com/cgi-bin/findweather/getForecast?query=MCI\"/>\n        <geo:lat>39.30347824</geo:lat>\n        <geo:long>-94.71977997</geo:long>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?MEM\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <inRegion r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <nameString>MEMPHIS</nameString>\n        <apt:iataCode>MEM</apt:iataCode>\n        <cityl:formVal>MEM</cityl:formVal>\n        <cityl:weatherPage r:resource=\"http://www.wunderground.com/cgi-bin/findweather/getForecast?query=MEM\"/>\n        <geo:lat>35.06353378</geo:lat>\n        <geo:long>-89.97751617</geo:long>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?MSP\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <inRegion r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <nameString>MINNEAPOLIS ST PL</nameString>\n        <apt:iataCode>MSP</apt:iataCode>\n        <cityl:formVal>MSP</cityl:formVal>\n        <cityl:weatherPage r:resource=\"http://www.wunderground.com/cgi-bin/findweather/getForecast?query=MSP\"/>\n        <geo:lat>44.87760162</geo:lat>\n        <geo:long>-93.21949768</geo:long>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?NCE\">\n        <ic:timeZone r:resource=\"../../2000/10/swap/pim/itin2ical#ParisTime\"/>\n        <nameString>NICE</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?ORD\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <nameString>CHICAGO OHARE</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?PHL\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n        <nameString>Philadelphia, PA</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?PIT\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n        <nameString>PITTSBURGH</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?SFO\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Los_Angeles#tz\"/>\n        <nameString>SAN FRANCISCO</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?SNA\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Los_Angeles#tz\"/>\n        <nameString>JOHN WAYNE INTL</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?STL\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\"/>\n        <nameString>ST LOUIS INTL</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?YMX\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\"/>\n        <nameString>MONTREAL DORVALQC</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?YVR\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/America/Los_Angeles#tz\"/>\n        <nameString>VANCOUVER BC</nameString>\n    </Airport-Physical>\n\n    <Airport-Physical r:about=\"http://www.daml.org/cgi-bin/airport?ZRH\">\n        <ic:timeZone r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Zurich#tz\"/>\n    </Airport-Physical>\n\n    <SpatialThing r:about=\"http://www.w3.org/2002/12/cal/tzd/America/Chicago#tz\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vtimezone\"/>\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Chicago</cal:tzid>\n    </SpatialThing>\n\n    <cal:Vtimezone r:about=\"http://www.w3.org/2002/12/cal/tzd/America/Denver#tz\">\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Denver</cal:tzid>\n    </cal:Vtimezone>\n\n    <cal:Vtimezone r:about=\"http://www.w3.org/2002/12/cal/tzd/America/Los_Angeles#tz\">\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/Los_Angeles</cal:tzid>\n    </cal:Vtimezone>\n\n    <cal:Vtimezone r:about=\"http://www.w3.org/2002/12/cal/tzd/America/New_York#tz\">\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/America/New_York</cal:tzid>\n    </cal:Vtimezone>\n\n    <SpatialThing r:about=\"http://www.w3.org/2002/12/cal/tzd/Europe/Amsterdam#tz\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vtimezone\"/>\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/Europe/Amsterdam</cal:tzid>\n    </SpatialThing>\n\n    <SpatialThing r:about=\"http://www.w3.org/2002/12/cal/tzd/Europe/Budapest#tz\">\n        <r:type r:resource=\"http://www.w3.org/2002/12/cal/ical#Vtimezone\"/>\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/Europe/Budapest</cal:tzid>\n    </SpatialThing>\n\n    <cal:Vtimezone r:about=\"http://www.w3.org/2002/12/cal/tzd/Europe/London#tz\">\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/Europe/London</cal:tzid>\n    </cal:Vtimezone>\n\n    <cal:Vtimezone r:about=\"http://www.w3.org/2002/12/cal/tzd/Europe/Paris#tz\">\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/Europe/Paris</cal:tzid>\n    </cal:Vtimezone>\n\n    <cal:Vtimezone r:about=\"http://www.w3.org/2002/12/cal/tzd/Europe/Zurich#tz\">\n        <cal:tzid>/softwarestudio.org/Olson_20011030_5/Europe/Zurich</cal:tzid>\n    </cal:Vtimezone>\n\n    <r:Description>\n        <inRegion r:resource=\"http://www.w3.org/2002/12/cal/tzd/Europe/Budapest#tz\"/>\n        <inRegion r:parseType=\"Resource\">\n            <map:countryName>Hungary</map:countryName>\n        </inRegion>\n        <cityl:formVal>Budapest%2CHungary</cityl:formVal>\n        <cityl:weatherPage r:resource=\"http://www.wunderground.com/cgi-bin/findweather/getForecast?query=Budapest%2CHungary\"/>\n        <map:cityName>Budapest</map:cityName>\n        <geo:lat>47.43000031</geo:lat>\n        <geo:long>19.18000031</geo:long>\n    </r:Description>\n</r:RDF>\n\n\n\n"
        },
        {
            "subject": "qnames with  in cw",
            "content": "I was not sure where to send this, since I consider it more a Notation3\nbug than a CWM bug. http://www.w3.org/DesignIssues/Notation3 doesn't say\nto send to any particular list.  Maybe not here but public-cwm-talk?\n\nI noticed you've switched the definition of Notation3's specification in\nApril, more about this in other messages.\n\nhttp://www.w3.org/DesignIssues/Notation3 says:\n[[\nIdentifier munging\n\nThis syntax does not allow minus signs in identifiers, whereas the\nXML encoding for RDF does.\n]]\n\nThe reference implementation of N3, cwm has been more generous\n(in a checked out dev.w3.org/2000/10/swap):\n\n$ grep -i A-Z *|grep -i qname\nrdfn3.g:    token QNAME:    r'([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'\nrdfn3_yapps.py:            ('QNAME', '([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'),\nrelaxNG.g:    token QName : r'[a-zA-Z0-9_-]+:[a-zA-Z0-9_-]+' # @@???\n\nand in notation3.py:\n  _notQNameChars = \"\\t\\r\\n !\\\"#$%&'()*.,+/;<=>?@[\\\\]^`{|}~\"  # Assume anything else valid qname :-/\n(as used in 'def qname' later)\n\nAll of these would allow foo:bar-baz\n\nTrivial test:\n\n$ cat > t.n3\n@prefix foo: <http://example.org/> .\nfoo:bar foo:baz foo:bar-baz .\n$ cwm t.n3\n#Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp\n        #    using base file:/home/cmdjb/w3c/2000/10/swap/t.n3\n         \n#  Notation3 generation by\n#       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n \n#   Base was: file:/home/cmdjb/w3c/2000/10/swap/t.n3\n     \n    <http://example.org/bar>     <http://example.org/baz> <http://example.org/bar-baz> .\n     \n#ENDS\n  \n\nThe newer http://www.w3.org/2000/10/swap/grammar/n3.n3\nCVS 1.9 2003/10/30 22:41:34 says\n  qname bnf:matches \"(([a-zA-Z_][a-zA-Z0-9_]*)?:)?([a-zA-Z_][a-zA-Z0-9_]*)?\";\n\nI think it would be a good idea to allow - inside qnames.  You can other\nuses by whitespace and let people avoid CamelCase inside names if they\ndon't like that.\n\nI think some people have already been using - in names, relying on cwm\naccepting it.  (I had a quick look and, for example, Jena's N3 parser\naccepts it).  I'm tempted to add it to Turtle to match what people are\nusing and want to use.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Trailing ; in N3 property lists forbidde",
            "content": "Trailing ; is now forbidden in property lists in the new Notation3\ngrammar where it says:\n[[\npropertylist\n    verb object objecttail propertylisttail\n    void\n\npropertylisttail\n    \";\" verb object objecttail propertylisttail\n    void\n\n]]\n-- http://www.w3.org/2000/10/swap/grammar/n3-report.html#propertylist\n\nThe old one, http://www.w3.org/DesignIssues/OldNotation3Grammar\nallowed this:\n\n[[\npropertylist\n    void ( to allow an anonymous node by itself [:a :b ]. But :a. generates no statements. )\n    verb objectlist\n    verb objectlist ; propertylist\n]]\n-- http://www.w3.org/DesignIssues/OldNotation3Grammar\n\nand the reference Notation 3 implementation in cwm continues to allow this.\n\nTrivial test:\n\n$ cat > t.n3\n@prefix foo: <http://example.org/> .\nfoo:a foo:b foo:c;\n      foo:d foo:e; .\n$ cwm  t.n3\n#Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp\n        #    using base file:/home/cmdjb/w3c/2000/10/swap/t.n3\n         \n#  Notation3 generation by\n#       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n \n#   Base was: file:/home/cmdjb/w3c/2000/10/swap/t.n3\n     \n    <http://example.org/a>     <http://example.org/b> <http://example.org/c>;\n         <http://example.org/d> <http://example.org/e> .\n     \n#ENDS\n\nSo which one is correct? \n\nAnnoyingly for me, in my Turtle implementation, I allow it (following\nthe old grammar) but in the Turtle spec[1], I have forbidden it, so\none way or another I've got to change something!\n\nI have seen N3 examples that have (accidently I guess) used this such as:\n  http://www.w3.org/2003/03/rdfqr-tests/recording-query-results.html\n(last example).\n\nDave\n\n[1] http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/\n\n\n\n"
        },
        {
            "subject": "RE: Trailing ; in N3 property lists forbidde",
            "content": "I allow  it in Jena's N3 parsr for the convenience of users to insert lines\ninto datasets without having to worry about whether this is the last item or\nwhether the old item was the last one.\n\nThe usage pattern is:\n\nx:foo\nns:prop1 \"v1\" ;\nns:prop2 \"v2\" ;\n.\n\nallowing an extra line to be added ending in ; without regard to position in\nthe list.\n\nSame for programmatically producing N3 output from some non-RDF data.  Code\ndoes not need to special case last (or first) items.\n\nAndy\n\n-------- Original Message --------\n> From: public-cwm-bugs-request@w3.org <>\n> Date: 4 May 2004 11:11\n> \n> Trailing ; is now forbidden in property lists in the new Notation3\n> grammar where it says: [[\n> propertylist\n>     verb object objecttail propertylisttail\n>     void\n> \n> propertylisttail\n>     \";\" verb object objecttail propertylisttail\n>     void\n> \n> ]]\n> -- http://www.w3.org/2000/10/swap/grammar/n3-report.html#propertylist\n> \n> The old one, http://www.w3.org/DesignIssues/OldNotation3Grammar allowed\n> this: \n> \n> [[\n> propertylist\n>     void ( to allow an anonymous node by itself [:a :b ]. But\n> > a. generates no statements. )\n>     verb objectlist\n>     verb objectlist ; propertylist\n> ]]\n> -- http://www.w3.org/DesignIssues/OldNotation3Grammar\n> \n> and the reference Notation 3 implementation in cwm continues\n> to allow this.\n> \n> Trivial test:\n> \n> $ cat > t.n3\n> @prefix foo: <http://example.org/> .\n> foo:a foo:b foo:c;\n>       foo:d foo:e; .\n> $ cwm  t.n3\n> #Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp\n>         #    using base file:/home/cmdjb/w3c/2000/10/swap/t.n3\n> \n> #  Notation3 generation by\n> #       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n> \n> #   Base was: file:/home/cmdjb/w3c/2000/10/swap/t.n3\n> \n>     <http://example.org/a>     <http://example.org/b>\n>          <http://example.org/c>; <http://example.org/d>\n> <http://example.org/e> . \n> \n> #ENDS\n> \n> So which one is correct?\n> \n> Annoyingly for me, in my Turtle implementation, I allow it (following\n> the old grammar) but in the Turtle spec[1], I have forbidden it, so\n> one way or another I've got to change something!\n> \n> I have seen N3 examples that have (accidently I guess) used\n> this such as:\n>   http://www.w3.org/2003/03/rdfqr-tests/recording-query-results.html\n> (last example). \n> \n> Dave\n> \n> [1] http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/\n\n\n\n"
        },
        {
            "subject": "RE: qnames with  in cw",
            "content": "Would now be a good time to go beyond a-z alphabetics in qnames and align\nwith XML 1.1 Names and Tokens where possible?\n\nhttp://www.w3.org/TR/xml11/#sec-common-syn\n\nAndy\n\n-------- Original Message --------\n> From: public-cwm-bugs-request@w3.org <>\n> Date: 4 May 2004 10:40\n> \n> I was not sure where to send this, since I consider it more a Notation3\n> bug than a CWM bug. http://www.w3.org/DesignIssues/Notation3\n> doesn't say\n> to send to any particular list.  Maybe not here but public-cwm-talk?\n> \n> I noticed you've switched the definition of Notation3's\n> specification in\n> April, more about this in other messages.\n> \n> http://www.w3.org/DesignIssues/Notation3 says:\n> [[\n> Identifier munging\n> \n> This syntax does not allow minus signs in identifiers, whereas the XML\n> encoding for RDF does. ]]\n> \n> The reference implementation of N3, cwm has been more generous\n> (in a checked out dev.w3.org/2000/10/swap):\n> \n> $ grep -i A-Z *|grep -i qname\n> rdfn3.g:    token QNAME:\n> r'([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'\n> rdfn3_yapps.py:            ('QNAME',\n> '([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'),\n> relaxNG.g:    token QName : r'[a-zA-Z0-9_-]+:[a-zA-Z0-9_-]+' # @@???\n> \n> and in notation3.py:\n>   _notQNameChars = \"\\t\\r\\n !\\\"#$%&'()*.,+/;<=>?@[\\\\]^`{|}~\"\n> # Assume anything else valid qname :-/\n> (as used in 'def qname' later)\n> \n> All of these would allow foo:bar-baz\n> \n> Trivial test:\n> \n> $ cat > t.n3\n> @prefix foo: <http://example.org/> .\n> foo:bar foo:baz foo:bar-baz .\n> $ cwm t.n3\n> #Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp\n>         #    using base file:/home/cmdjb/w3c/2000/10/swap/t.n3\n> \n> #  Notation3 generation by\n> #       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n> \n> #   Base was: file:/home/cmdjb/w3c/2000/10/swap/t.n3\n> \n>     <http://example.org/bar>     <http://example.org/baz>\n> <http://example.org/bar-baz> .\n> \n> #ENDS\n> \n> \n> The newer http://www.w3.org/2000/10/swap/grammar/n3.n3\n> CVS 1.9 2003/10/30 22:41:34 says\n>   qname bnf:matches\n> \"(([a-zA-Z_][a-zA-Z0-9_]*)?:)?([a-zA-Z_][a-zA-Z0-9_]*)?\";\n> \n> I think it would be a good idea to allow - inside qnames.\n> You can other\n> uses by whitespace and let people avoid CamelCase inside names if they\n> don't like that. \n> \n> I think some people have already been using - in names, relying on cwm\n> accepting it.  (I had a quick look and, for example, Jena's N3 parser\n> accepts it).  I'm tempted to add it to Turtle to match what people are\n> using and want to use. \n> \n> Dave\n\n\n\n"
        },
        {
            "subject": "problem testing swap HEAD in cv",
            "content": "Hi, I checked out the latest cvs version of swap as described here:\nhttp://www.w3.org/2000/10/swap/doc/cwm\n\nAfter downloading the tests from\nhttp://www.w3.org/2000/10/rdf-tests/rdfcore/latest_All.zip\n\nand running make\n\nI get the following output:\n\n\n------------------------------------------------------------------\n59/207 regression.n3#t1022             Early DAML (now OWL) example in \nXML/RDF\nFiles differ, result= 256\n#  If this is OK,   cp ,temp/regression.n3_t1022.out ref/daml-ex.n3\n######### Differences from reference output:\n--- ref/daml-ex.n3      2004-05-07 15:25:00.000000000 +0200\n+++ ,temp/regression.n3_t1022.out       2004-05-07 18:14:42.000000000 \n+0200\n@@ -81,6 +81,8 @@\n           :domain ex:Person;\n           :range ex:Height .\n\n+    ex:medium     a :Height .\n+\n      ex:mom     a :Property;\n           = ex:mother .\n\n@@ -95,3 +97,7 @@\n           :cardinality \"2\";\n           :domain ex:Animal .\n\n+    ex:short     a :Height .\n+\n+    ex:tall     a :Height .\n+\n\n######### from normal case regression.n3_t1022.out: cwm -rdf owl-ex.rdf \n-n3\nmake[1]: *** [all] Error 255\nmake: *** [tested] Error 2\n\n------------------------------------------------------------\n\n\n\n\nPS. Could the regressions tests not also be downloadable from CVS? That \nwould make the whole thing easier to understand. Or at least place a \nREADME in the directory there somewhere.\n\n\n\n"
        },
        {
            "subject": "diff.py not workin",
            "content": "Hi, I was really interested to get diff.py to work.\n\nPerhaps I am doing something wrong. But since I ran the unit tests and \nthey failed (see previous mail) I think it could well be some problem \nwith the code.\n\nI am running OSX\nAttached are the two rdf files that I ran the command with. I generated \nthese files from two n3 files using cwm\n\n\n\n\n\n\n\n18:59:59 - ~/Work/Programming/w3c/2000/10/swap\nhjs@bblfish:0$ uname -a\nDarwin bblfish.local 7.3.0 Darwin Kernel Version 7.3.0: Fri Mar  5 \n14:22:55 PST 2004; root:xnu/xnu-517.3.15.obj~4/RELEASE_PPC  Power \nMacintosh powerpc\n\n19:03:53 - ~/Work/Programming/w3c/2000/10/swap\nhjs@bblfish:0$ python -V\nPython 2.3\n\n18:59:23 - ~/Work/Programming/w3c/2000/10/swap\nhjs@bblfish:0$ ./diff.py -v -f tmp/bloged1.xml -t tmp/bloged2.xml \nTraceback (most recent call last):\n   File \"./diff.py\", line 374, in ?\n     main()\n   File \"./diff.py\", line 357, in main\n     graph = loadFiles(testFiles)\n   File \"./diff.py\", line 318, in loadFiles\n     graph = myStore.loadMany(files, openFormula=graph)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/myStore.py\", line 159, \nin loadMany\n     return _checkStore().loadMany(uris, openFormula)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1150, in \nloadMany\n     self.load(u, openFormula=F, remember=0)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1131, in \nload\n     return webAccess.load(store, uri, openFormula, asIfFrom, \ncontentType, flags, why)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/webAccess.py\", line 90, \nin load\n     raise DocumentAccessError(addr, sys.exc_info() )\nwebAccess.DocumentAccessError: Unable to access document \n<file:/Users/hjs/Programming/w3c/2000/10/swap/tmp/bloged1.xml>, \nbecause:\n     [Errno 2] No such file or directory: \n'/Users/hjs/Programming/w3c/2000/10/swap/tmp/bloged1.xml'\n\n\n\n\n\napplication/octet-stream attachment: blog1.xml\n\napplication/octet-stream attachment: blog2.xml\n\n\n\n\n"
        },
        {
            "subject": "Re: diff.py not workin",
            "content": "Sorry that was the wrong output I sent. Below is what I am getting. It \nlooks like it is trying to get the file http://purl.org/atom/ns and \ncroaking on trying to parse that. I'll see if I can point the name \nspace to the right file.\n\nhjs@bblfish:0$ ./diff.py -v -f tmp/bloged1.rdf -t tmp/bloged2.rdf\nTraceback (most recent call last):\n   File \"./diff.py\", line 374, in ?\n     main()\n   File \"./diff.py\", line 357, in main\n     graph = loadFiles(testFiles)\n   File \"./diff.py\", line 318, in loadFiles\n     graph = myStore.loadMany(files, openFormula=graph)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/myStore.py\", line 159, \nin loadMany\n     return _checkStore().loadMany(uris, openFormula)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1150, in \nloadMany\n     self.load(u, openFormula=F, remember=0)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1131, in \nload\n     return webAccess.load(store, uri, openFormula, asIfFrom, \ncontentType, flags, why)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/webAccess.py\", line 90, \nin load\n     raise DocumentAccessError(addr, sys.exc_info() )\nwebAccess.DocumentAccessError: Unable to access document \n<file:/Users/hjs/Programming/w3c/2000/10/swap/tmp/bloged1.rdf>, \nbecause:\n     [Errno 2] No such file or directory: \n'/Users/hjs/Programming/w3c/2000/10/swap/tmp/bloged1.rdf'\n\n19:44:54 - ~/Work/Programming/w3c/2000/10/swap\nhjs@bblfish:0$ ./diff.py -v -f tmp/blog1.rdf -t tmp/blog2.rdf\n     Loaded _g2 llyn.IndexedFormula\n     Loaded _g12 llyn.IndexedFormula\n      Fixed node: Feed\n      Fixed node: \"http://b\"\n      Blank node: _L11C8\n      Fixed node: \"Atom 0.3\"\n      Blank node: _L56C8\n      Fixed node: Entry\n      Fixed node: \"Henry St\"\n      Fixed node: \"7 May 20\"\n      Fixed node: \"xml\"\n      Blank node: _L13C8\n      Fixed node: \"James To\"\n      Fixed node: \"not quit\"\n      Fixed node: \"Learning\"\n      Fixed node: Content\n      Fixed node: \"BlogEd v\"\n      Fixed node: Person\n      Fixed node: \"<h1>My <\"\n      Blank node: _L43C8\n      Fixed node: \"<span>Th\"\n      Fixed node: \"Create C\"\n      Fixed node: _g4\n      Fixed node: \"de\"\n      Blank node: _L25C8\n      Blank node: _L50C8\n      Fixed node: \"en\"\n      Blank node: _L40C4\n      Fixed node: \"todd@sun\"\n      Fixed node: \"henry.st\"\n      Fixed node: \"http://b\"\n      Fixed node: \"http://b\"\n      Fixed node: Link\n      Blank node: _L9C4\n      Fixed node: \"text/htm\"\n      Fixed node: \"<span>It\"\n      Fixed node: \"service.\"\n      Fixed node: \"text/xht\"\n      Blank node: _L19C8\n      Fixed node: \"http://b\"\n       Predicate: rdf:type\n       Predicate: generator\n       Predicate: email\n       Predicate: mode\n       Predicate: copyright\n       Predicate: hasLink\n       Predicate: type\n       Predicate: hasTitle\n       Predicate: author\n       Predicate: data\n       Predicate: rel\n       Predicate: tagline\n       Predicate: contributor\n       Predicate: url\n       Predicate: created\n       Predicate: version\n       Predicate: href\n       Predicate: lang\n       Predicate: id\n       Predicate: name\n       Predicate: hasContent\n       Predicate: info\n       Schema:  http://purl.org/atom/ns\n       Schema:  http://www.w3.org/1999/02/22-rdf-syntax-ns\nTraceback (most recent call last):\n   File \"./diff.py\", line 374, in ?\n     main()\n   File \"./diff.py\", line 366, in main\n     delta = differences(graph, graph2)\n   File \"./diff.py\", line 235, in differences\n     g_bnodes, g_definitions = nailFormula(g)\n   File \"./diff.py\", line 85, in nailFormula\n     meta = lookUp(predicates)\n   File \"./diff.py\", line 65, in lookUp\n     return loadMany([(x) for x in schemas])\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/myStore.py\", line 159, \nin loadMany\n     return _checkStore().loadMany(uris, openFormula)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1150, in \nloadMany\n     self.load(u, openFormula=F, remember=0)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1131, in \nload\n     return webAccess.load(store, uri, openFormula, asIfFrom, \ncontentType, flags, why)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/webAccess.py\", line \n109, in load\n     p.feed(buffer)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/notation3.py\", line \n251, in feed\n     i = self.directiveOrStatement(str,j)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/notation3.py\", line \n265, in directiveOrStatement\n     if j>=0: return self.checkDot(str,j)\n   File \"/Users/hjs/Programming/w3c/2000/10/swap/notation3.py\", line \n708, in checkDot\n     raise BadSyntax(self._thisDoc, self.lines, str, j, \"expected '.' or \n'}' or ']' at end of statement\")\nnotation3.BadSyntax: Line 3 of <http://purl.org/atom/ns>: Bad syntax \n(expected '.' or '}' or ']' at end of statement) at ^ in:\n\"...CTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<HTML><HEAD>\n^<TITLE>404 Not Found</TITLE>\n</HEAD><BODY>\n<H1>Not Found</H1...\"\n\n\n\n"
        },
        {
            "subject": "Re: diff.py not workin",
            "content": "On 7 May 2004, at 19:56, Henry Story wrote:\n\n> Sorry that was the wrong output I sent. Below is what I am getting. It \n> looks like it is trying to get the file http://purl.org/atom/ns and \n> croaking on trying to parse that. I'll see if I can point the name \n> space to the right file.\n\nThat was indeed correct.\n\n  I needed the name space to point to the owl file I used as a model. It \nstill does not work, but that is because my graph is insufficiently \nlabeled. I will need to read TBL's paper more carefully and see if I \ncan improve the constraints on the OWL semantics, or if I just need to \nfind a way create resource names for the graph elements.\n\nHenry\n\nPS. Sorry to have pressed the bug filing button too soon. That must \nhave been because I did not get the tests to work previously...\n\n\n\n"
        },
        {
            "subject": "Re: diff.py still not workin",
            "content": "After labeling every point of the  graph, I still get a problem.\n\nAttached are the three files needed to duplicate this experiment. There \nis very little difference between blog-1.n3 and blog-2.n3. A normal \nunix diff reveals only one line non commented difference.\n\nI tested diff on the from.n3 and to.n3 ical examples and those worked \nwell. I am at a bit of a loss. I would have to look at the python code, \nbut, not being a python person, this might take me a lot longer than \nthe time I may have.\n\n\n13:59:59 - ~/Programming/w3c/swap/tmp\nhjs@bblfish:0$ ../diff.py -f blog-1.n3 -t blog-2.n3\nTraceback (most recent call last):\n   File \"../diff.py\", line 374, in ?\n     main()\n   File \"../diff.py\", line 366, in main\n     delta = differences(graph, graph2)\n   File \"../diff.py\", line 235, in differences\n     g_bnodes, g_definitions = nailFormula(g)\nTypeError: unpack non-sequence\n\n\n\n\n\n\n\n\n\n\n\nOn 7 May 2004, at 20:17, Henry Story wrote:\n\n> On 7 May 2004, at 19:56, Henry Story wrote:\n>\n>> Sorry that was the wrong output I sent. Below is what I am getting. \n>> It looks like it is trying to get the file http://purl.org/atom/ns \n>> and croaking on trying to parse that. I'll see if I can point the \n>> name space to the right file.\n>\n> That was indeed correct.\n>\n>  I needed the name space to point to the owl file I used as a model. \n> It still does not work, but that is because my graph is insufficiently \n> labeled. I will need to read TBL's paper more carefully and see if I \n> can improve the constraints on the OWL semantics, or if I just need to \n> find a way create resource names for the graph elements.\n>\n> Henry\n>\n> PS. Sorry to have pressed the bug filing button too soon. That must \n> have been because I did not get the tests to work previously...\n>\n>\n\n\n\n\napplication/octet-stream attachment: blog-1.n3\n\napplication/octet-stream attachment: blog-2.n3\n\napplication/octet-stream attachment: atom.owl\n\n\n\n\n"
        },
        {
            "subject": "&quot;Bad Syntax&quot; message instead of 404 file not foun",
            "content": "Henry,\n\nI'll fork this as a separate bug, as it is a problem with the way cwm \nuses the python library that error 404 doesn't turn up as an exception, \nbut a parse error when attemting to parse the Error 404 message as RDF!\n\nTim\n\n\nOn May 7, 2004, at 13:54, Henry Story wrote:\n\n>\n> Sorry that was the wrong output I sent. Below is what I am getting. It \n> looks like it is trying to get the file http://purl.org/atom/ns and \n> croaking on trying to parse that. I'll see if I can point the name \n> space to the right file.\n>\n> hjs@bblfish:0$ ./diff.py -v -f tmp/bloged1.rdf -t tmp/bloged2.rdf\n> Traceback (most recent call last):\n>   File \"./diff.py\", line 374, in ?\n>     main()\n>   File \"./diff.py\", line 357, in main\n>     graph = loadFiles(testFiles)\n>   File \"./diff.py\", line 318, in loadFiles\n>     graph = myStore.loadMany(files, openFormula=graph)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/myStore.py\", line 159, \n> in loadMany\n>     return _checkStore().loadMany(uris, openFormula)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1150, \n> in loadMany\n>     self.load(u, openFormula=F, remember=0)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1131, \n> in load\n>     return webAccess.load(store, uri, openFormula, asIfFrom, \n> contentType, flags, why)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/webAccess.py\", line \n> 90, in load\n>     raise DocumentAccessError(addr, sys.exc_info() )\n> webAccess.DocumentAccessError: Unable to access document \n> <file:/Users/hjs/Programming/w3c/2000/10/swap/tmp/bloged1.rdf>, \n> because:\n>     [Errno 2] No such file or directory: \n> '/Users/hjs/Programming/w3c/2000/10/swap/tmp/bloged1.rdf'\n>\n> 19:44:54 - ~/Work/Programming/w3c/2000/10/swap\n> hjs@bblfish:0$ ./diff.py -v -f tmp/blog1.rdf -t tmp/blog2.rdf\n>     Loaded _g2 llyn.IndexedFormula\n>     Loaded _g12 llyn.IndexedFormula\n>      Fixed node: Feed\n>      Fixed node: \"http://b\"\n>      Blank node: _L11C8\n>      Fixed node: \"Atom 0.3\"\n>      Blank node: _L56C8\n>      Fixed node: Entry\n>      Fixed node: \"Henry St\"\n>      Fixed node: \"7 May 20\"\n>      Fixed node: \"xml\"\n>      Blank node: _L13C8\n>      Fixed node: \"James To\"\n>      Fixed node: \"not quit\"\n>      Fixed node: \"Learning\"\n>      Fixed node: Content\n>      Fixed node: \"BlogEd v\"\n>      Fixed node: Person\n>      Fixed node: \"<h1>My <\"\n>      Blank node: _L43C8\n>      Fixed node: \"<span>Th\"\n>      Fixed node: \"Create C\"\n>      Fixed node: _g4\n>      Fixed node: \"de\"\n>      Blank node: _L25C8\n>      Blank node: _L50C8\n>      Fixed node: \"en\"\n>      Blank node: _L40C4\n>      Fixed node: \"todd@sun\"\n>      Fixed node: \"henry.st\"\n>      Fixed node: \"http://b\"\n>      Fixed node: \"http://b\"\n>      Fixed node: Link\n>      Blank node: _L9C4\n>      Fixed node: \"text/htm\"\n>      Fixed node: \"<span>It\"\n>      Fixed node: \"service.\"\n>      Fixed node: \"text/xht\"\n>      Blank node: _L19C8\n>      Fixed node: \"http://b\"\n>       Predicate: rdf:type\n>       Predicate: generator\n>       Predicate: email\n>       Predicate: mode\n>       Predicate: copyright\n>       Predicate: hasLink\n>       Predicate: type\n>       Predicate: hasTitle\n>       Predicate: author\n>       Predicate: data\n>       Predicate: rel\n>       Predicate: tagline\n>       Predicate: contributor\n>       Predicate: url\n>       Predicate: created\n>       Predicate: version\n>       Predicate: href\n>       Predicate: lang\n>       Predicate: id\n>       Predicate: name\n>       Predicate: hasContent\n>       Predicate: info\n>       Schema:  http://purl.org/atom/ns\n>       Schema:  http://www.w3.org/1999/02/22-rdf-syntax-ns\n> Traceback (most recent call last):\n>   File \"./diff.py\", line 374, in ?\n>     main()\n>   File \"./diff.py\", line 366, in main\n>     delta = differences(graph, graph2)\n>   File \"./diff.py\", line 235, in differences\n>     g_bnodes, g_definitions = nailFormula(g)\n>   File \"./diff.py\", line 85, in nailFormula\n>     meta = lookUp(predicates)\n>   File \"./diff.py\", line 65, in lookUp\n>     return loadMany([(x) for x in schemas])\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/myStore.py\", line 159, \n> in loadMany\n>     return _checkStore().loadMany(uris, openFormula)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1150, \n> in loadMany\n>     self.load(u, openFormula=F, remember=0)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/llyn.py\", line 1131, \n> in load\n>     return webAccess.load(store, uri, openFormula, asIfFrom, \n> contentType, flags, why)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/webAccess.py\", line \n> 109, in load\n>     p.feed(buffer)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/notation3.py\", line \n> 251, in feed\n>     i = self.directiveOrStatement(str,j)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/notation3.py\", line \n> 265, in directiveOrStatement\n>     if j>=0: return self.checkDot(str,j)\n>   File \"/Users/hjs/Programming/w3c/2000/10/swap/notation3.py\", line \n> 708, in checkDot\n>     raise BadSyntax(self._thisDoc, self.lines, str, j, \"expected '.' \n> or '}' or ']' at end of statement\")\n> notation3.BadSyntax: Line 3 of <http://purl.org/atom/ns>: Bad syntax \n> (expected '.' or '}' or ']' at end of statement) at ^ in:\n> \"...CTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n> <HTML><HEAD>\n> ^<TITLE>404 Not Found</TITLE>\n> </HEAD><BODY>\n> <H1>Not Found</H1...\"\n\n\n\n"
        },
        {
            "subject": "[closed] Re: diff.py still not workin",
            "content": "Henry,\n\nOoops . Thanks - it crashed with a graph with no bnodes at all.\nI checked in a version of diff with this fixed.\n\nTim\n\n\n$ python2.3 $SWAP/diff.py -f \nhttp://www.w3.org/2000/10/swap/test/delta/hjs/blog-1.n3 -t \nhttp://www.w3.org/2000/10/swap/test/delta/hjs/blog-2.n3\n\n      @prefix : \n<http://www.w3.org/2000/10/swap/test/delta/hjs/atom.owl#> .\n      @prefix delta: <http://www.w3.org/2004/delta#> .\n     {\n\n         }     delta:deletion {<http://bblfish.net/blog/>     :copyright \n\"Create Commons\" .\n         };\n          delta:insertion {<http://bblfish.net/blog/>     :copyright \n\"Creative Commons\" .\n         } .\n\n\nTim\n\nOn May 8, 2004, at 8:04, Henry Story wrote:\n\n> After labeling every point of the  graph, I still get a problem.\n>\n> Attached are the three files needed to duplicate this experiment. \n> There is very little difference between blog-1.n3 and blog-2.n3. A \n> normal unix diff reveals only one line non commented difference.\n>\n> I tested diff on the from.n3 and to.n3 ical examples and those worked \n> well. I am at a bit of a loss. I would have to look at the python \n> code, but, not being a python person, this might take me a lot longer \n> than the time I may have.\n>\n>\n> 13:59:59 - ~/Programming/w3c/swap/tmp\n> hjs@bblfish:0$ ../diff.py -f blog-1.n3 -t blog-2.n3\n> Traceback (most recent call last):\n>   File \"../diff.py\", line 374, in ?\n>     main()\n>   File \"../diff.py\", line 366, in main\n>     delta = differences(graph, graph2)\n>   File \"../diff.py\", line 235, in differences\n>     g_bnodes, g_definitions = nailFormula(g)\n> TypeError: unpack non-sequence\n>\n>\n>\n> <blog-1.n3>\n> <blog-2.n3>\n>\n> <atom.owl>\n>\n> On 7 May 2004, at 20:17, Henry Story wrote:\n>\n>> On 7 May 2004, at 19:56, Henry Story wrote:\n>>\n>>> Sorry that was the wrong output I sent. Below is what I am getting. \n>>> It looks like it is trying to get the file http://purl.org/atom/ns \n>>> and croaking on trying to parse that. I'll see if I can point the \n>>> name space to the right file.\n>>\n>> That was indeed correct.\n>>\n>>  I needed the name space to point to the owl file I used as a model. \n>> It still does not work, but that is because my graph is \n>> insufficiently labeled. I will need to read TBL's paper more \n>> carefully and see if I can improve the constraints on the OWL \n>> semantics, or if I just need to find a way create resource names for \n>> the graph elements.\n>>\n>> Henry\n>>\n>> PS. Sorry to have pressed the bug filing button too soon. That must \n>> have been because I did not get the tests to work previously...\n>>\n>>\n\n\n\n"
        },
        {
            "subject": "Re: qnames with  in cw",
            "content": "Andy, Dave,\n\nI think this is a good point. Mind you, I don't really like having such \na wealth of punctuation inside names.\n\nI don't think the user of a language is helped a lot by having the \nchoice between\nmaple_syrup-count and maple-syrup.count and so on.  I think it is \nliable to lead to more uncaught errors and more user confusion. It is \njust that XML does it. So we have to be compatible - but we don't have \nto encourage it. After all,  one can always use the <uri> form.\n\n  N3 uses punctuation for semantics.  XML doesn't have to worry about it \nbecause it uses angle brackets around tag names.   The \".\"  is very \ncommon parlance for a path step, and allowing   ?x.mother.age  makes a \nlot of sense to OO types.  I could imagine restricting it to   \n?x!mother!age  but its looks weirder to the uninitiated.\n\nThe - issue I don't feel so strongly about.  It may be OK to force - as \nan operator, if we put operators into N3, to be separated by \nwhitespace.\n\nmaple-current = maple-started - maple-finished.\n\nTim\n\nOn May 5, 2004, at 5:16, Seaborne, Andy wrote:\n\n>\n> Would now be a good time to go beyond a-z alphabetics in qnames and \n> align\n> with XML 1.1 Names and Tokens where possible?\n>\n> http://www.w3.org/TR/xml11/#sec-common-syn\n>\n> Andy\n>\n> -------- Original Message --------\n>> From: public-cwm-bugs-request@w3.org <>\n>> Date: 4 May 2004 10:40\n>>\n>> I was not sure where to send this, since I consider it more a \n>> Notation3\n>> bug than a CWM bug. http://www.w3.org/DesignIssues/Notation3\n>> doesn't say\n>> to send to any particular list.  Maybe not here but public-cwm-talk?\n>>\n>> I noticed you've switched the definition of Notation3's\n>> specification in\n>> April, more about this in other messages.\n>>\n>> http://www.w3.org/DesignIssues/Notation3 says:\n>> [[\n>> Identifier munging\n>>\n>> This syntax does not allow minus signs in identifiers, whereas the XML\n>> encoding for RDF does. ]]\n>>\n>> The reference implementation of N3, cwm has been more generous\n>> (in a checked out dev.w3.org/2000/10/swap):\n>>\n>> $ grep -i A-Z *|grep -i qname\n>> rdfn3.g:    token QNAME:\n>> r'([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'\n>> rdfn3_yapps.py:            ('QNAME',\n>> '([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'),\n>> relaxNG.g:    token QName : r'[a-zA-Z0-9_-]+:[a-zA-Z0-9_-]+' # @@???\n>>\n>> and in notation3.py:\n>>   _notQNameChars = \"\\t\\r\\n !\\\"#$%&'()*.,+/;<=>?@[\\\\]^`{|}~\"\n>> # Assume anything else valid qname :-/\n>> (as used in 'def qname' later)\n>>\n>> All of these would allow foo:bar-baz\n>>\n>> Trivial test:\n>>\n>> $ cat > t.n3\n>> @prefix foo: <http://example.org/> .\n>> foo:bar foo:baz foo:bar-baz .\n>> $ cwm t.n3\n>> #Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp\n>>         #    using base file:/home/cmdjb/w3c/2000/10/swap/t.n3\n>>\n>> #  Notation3 generation by\n>> #       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n>>\n>> #   Base was: file:/home/cmdjb/w3c/2000/10/swap/t.n3\n>>\n>>     <http://example.org/bar>     <http://example.org/baz>\n>> <http://example.org/bar-baz> .\n>>\n>> #ENDS\n>>\n>>\n>> The newer http://www.w3.org/2000/10/swap/grammar/n3.n3\n>> CVS 1.9 2003/10/30 22:41:34 says\n>>   qname bnf:matches\n>> \"(([a-zA-Z_][a-zA-Z0-9_]*)?:)?([a-zA-Z_][a-zA-Z0-9_]*)?\";\n>>\n>> I think it would be a good idea to allow - inside qnames.\n>> You can other\n>> uses by whitespace and let people avoid CamelCase inside names if they\n>> don't like that.\n>>\n>> I think some people have already been using - in names, relying on cwm\n>> accepting it.  (I had a quick look and, for example, Jena's N3 parser\n>> accepts it).  I'm tempted to add it to Turtle to match what people are\n>> using and want to use.\n>>\n>> Dave\n\n\n\n"
        },
        {
            "subject": "RE: qnames with  in cw",
            "content": "Tim,\n\nI was more thinking of non-English letters, rather than the\nnon-alphanumerics.  In the N3 subsystem of Jena, I chose to allow the full\nrange of XML 1.1 Names where it didn't conflict with any other syntax mainly\nfor the accented and non-English characters.\n\nAndy\n\n-------- Original Message --------\n> From: Tim Berners-Lee <mailto:timbl@w3.org>\n> Date: 17 May 2004 02:17\n> \n> Andy, Dave,\n> \n> I think this is a good point. Mind you, I don't really like having such\n> a wealth of punctuation inside names.\n> \n> I don't think the user of a language is helped a lot by having the\n> choice between\n> maple_syrup-count and maple-syrup.count and so on.  I think it is\n> liable to lead to more uncaught errors and more user confusion. It is\n> just that XML does it. So we have to be compatible - but we don't have\n> to encourage it. After all,  one can always use the <uri> form.\n> \n>   N3 uses punctuation for semantics.  XML doesn't have to worry about it\n> because it uses angle brackets around tag names.   The \".\"  is very\n> common parlance for a path step, and allowing   ?x.mother.age  makes a\n> lot of sense to OO types.  I could imagine restricting it to\n> ?x!mother!age  but its looks weirder to the uninitiated.\n> \n> The - issue I don't feel so strongly about.  It may be OK to force - as\n> an operator, if we put operators into N3, to be separated by\n> whitespace.\n> \n> maple-current = maple-started - maple-finished.\n> \n> Tim\n> \n> On May 5, 2004, at 5:16, Seaborne, Andy wrote:\n> \n> > \n> > Would now be a good time to go beyond a-z alphabetics in qnames and\n> > align with XML 1.1 Names and Tokens where possible?\n> > \n> > http://www.w3.org/TR/xml11/#sec-common-syn\n> > \n> > Andy\n> > \n> > -------- Original Message --------\n> > > From: public-cwm-bugs-request@w3.org <>\n> > > Date: 4 May 2004 10:40\n> > > \n> > > I was not sure where to send this, since I consider it more a\n> > > Notation3 bug than a CWM bug.\n> > > http://www.w3.org/DesignIssues/Notation3 \n> > > doesn't say\n> > > to send to any particular list.  Maybe not here but public-cwm-talk?\n> > > \n> > > I noticed you've switched the definition of Notation3's\n> > > specification in\n> > > April, more about this in other messages.\n> > > \n> > > http://www.w3.org/DesignIssues/Notation3 says:\n> > > [[\n> > > Identifier munging\n> > > \n> > > This syntax does not allow minus signs in identifiers, whereas the\n> > > XML encoding for RDF does. ]] \n> > > \n> > > The reference implementation of N3, cwm has been more generous\n> > > (in a checked out dev.w3.org/2000/10/swap):\n> > > \n> > > $ grep -i A-Z *|grep -i qname\n> > > rdfn3.g:    token QNAME:\n> > > r'([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'\n> > > rdfn3_yapps.py:            ('QNAME',\n> > > '([a-zA-Z][a-zA-Z0-9_-]*)?:[a-zA-Z0-9_-]+'),\n> > > relaxNG.g:    token QName : r'[a-zA-Z0-9_-]+:[a-zA-Z0-9_-]+' # @@???\n> > > \n> > > and in notation3.py:\n> > >   _notQNameChars = \"\\t\\r\\n !\\\"#$%&'()*.,+/;<=>?@[\\\\]^`{|}~\"\n> > > # Assume anything else valid qname :-/\n> > > (as used in 'def qname' later)\n> > > \n> > > All of these would allow foo:bar-baz\n> > > \n> > > Trivial test:\n> > > \n> > > $ cat > t.n3\n> > > @prefix foo: <http://example.org/> .\n> > > foo:bar foo:baz foo:bar-baz .\n> > > $ cwm t.n3\n> > > #Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp\n> > >         #    using base file:/home/cmdjb/w3c/2000/10/swap/t.n3\n> > > \n> > > #  Notation3 generation by\n> > > #       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n> > > \n> > > #   Base was: file:/home/cmdjb/w3c/2000/10/swap/t.n3\n> > > \n> > >     <http://example.org/bar>     <http://example.org/baz>\n> > > <http://example.org/bar-baz> .\n> > > \n> > > #ENDS\n> > > \n> > > \n> > > The newer http://www.w3.org/2000/10/swap/grammar/n3.n3\n> > > CVS 1.9 2003/10/30 22:41:34 says\n> > >   qname bnf:matches\n> > > \"(([a-zA-Z_][a-zA-Z0-9_]*)?:)?([a-zA-Z_][a-zA-Z0-9_]*)?\";\n> > > \n> > > I think it would be a good idea to allow - inside qnames.\n> > > You can other\n> > > uses by whitespace and let people avoid CamelCase inside names if\n> > > they don't like that. \n> > > \n> > > I think some people have already been using - in names, relying on\n> > > cwm accepting it.  (I had a quick look and, for example, Jena's N3\n> > > parser accepts it).  I'm tempted to add it to Turtle to match what\n> > > people are using and want to use. \n> > > \n> > > Dave\n\n\n\n"
        },
        {
            "subject": "iterable argument required  bug",
            "content": "After a substantial time away, I'm getting back into using cwm. One of \nthe projects I'm working on reliably fails in the following manner, but \nI'm not sure if it's a bug with my data (if so, it seems like a pretty \nspectacular way to fail), or cwm. Does this look like a known problem \nin cwm? Perhaps something that's not friendly to Python 2.3 in the \ncode?\n\nThis is the latest from CVS, with Python 2.3 (Apple's build) on OSX \n10.3.3.\n\nThanks,\n\nadsl-67-119-69-246:~/Projects/HTTP header registry/swap> ./cwm.py \n~/Desktop/rfc_rules.n3 ~/Desktop/out.n3 --think --purge > ~/out.n3\nTraceback (most recent call last):\n   File \"./cwm.py\", line 646, in ?\n     doCommand()\n   File \"./cwm.py\", line 517, in doCommand\n     think(workingContext, mode=option_flags[\"think\"])\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n58, in think\n     return InferenceTask(knowledgeBase, ruleFormula, mode=mode, \nrepeat=1).run()\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n207, in run\n     return self.runSmart()\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n195, in runSmart\n     total += cy.run()\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n303, in run\n     return rule.once()\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n404, in once\n     total = query.resolve()\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n545, in resolve\n     return self.unify(self.queue, self.variables, self.existentials)\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n709, in unify\n     nbs = item.tryBuiltin(queue, bindings, heavy=0, evidence=evidence)\n   File \"/Users/mnot/Projects/HTTP header registry/swap/query.py\", line \n995, in tryBuiltin\n     result = pred.evalSubj(obj, queue, bindings.copy(), proof, \nself.query)\n   File \"/Users/mnot/Projects/HTTP header registry/swap/term.py\", line \n864, in evalSubj\n     return self.store._fromPython(self.evaluateSubject(obj.value()))\n   File \"/Users/mnot/Projects/HTTP header registry/swap/llyn.py\", line \n706, in evaluateSubject\n     if ':' not in object:\nTypeError: iterable argument required\n\n--\nMark Nottingham     http://www.mnot.net/\n\n\n\n"
        },
        {
            "subject": "pls split turtle lexical details out of the gramma",
            "content": "The turtle grammar starts out all formal...\n\"This EBNF is the notation used in XML 1.0 second edition over an\nalphabet of [UNICODE] characters.\"\n -- http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/\n\nbut then it's not, really:\n\n[[\nrelativeURI ::= character* with escapes as defined in the N-Triples\nsection 3.3 URI References. This is then used as a relative URI and\nresolved against the current base URI to give an absolute URI reference.\n\n\nstring ::= character* with escapes as defined in N-Triples section 3.2\nStrings\n]]\n\nI'd much rather have the lexical details specified separately\nand have the grammar be a real formal grammar, suitable for\nuse with yacc or the equivalent.\n\nBy way of comparison/contrast, see\n\n  http://www.w3.org/2000/10/swap/rdfn3-gram.html\n  http://www.w3.org/2000/10/swap/rdfn3.g\n  $Id: rdfn3.g,v 1.18 2002/08/15 23:20:36 connolly Exp $\n\n\np.s. I see\n\"Turtle is a work in progress, and I am looking for feedback\"\n\nbut I wasn't sure where you wanted the feedback sent. I was\ngoing to copy www-archive, but then grammar engineering is\nreasonably high on the cwm development agenda too, so I\ncopied public-cwm-talk.\n\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "Re: pls split turtle lexical details out of the gramma",
            "content": ">I'd much rather have the lexical details specified separately\n>and have the grammar be a real formal grammar, suitable for\n>use with yacc or the equivalent.\n>\n>By way of comparison/contrast, see\n>\n>  http://www.w3.org/2000/10/swap/rdfn3-gram.html\n>  http://www.w3.org/2000/10/swap/rdfn3.g\n>\nDave - I could do with a YAPPS version of Turtle for the stuff I'm \nplaying with at the moment. I'll be happy to sort it out as time permits \n(if you haven't time, of course).\n\nDan - In Cannes you asked me \"a personal question\", I answered \"Java\". \nAfter some recent noodling I'd like to change that answer to \"Python\". \nConsider me converted...\n\nCheers,\nDanny.\n\n-- \n----\nRaw\nhttp://dannyayers.com\n\n\n\n"
        },
        {
            "subject": "bug status update starte",
            "content": "Tim and everybody,\n\nI updated\n http://www.w3.org/2000/10/swap/admin/Makefile\nv 1.9 2004/04/24 10:35:39\nto grab bug status from public-cwm-bugs as well as www-archive.\n\nand then updated\n  http://www.w3.org/2000/10/swap/admin/N3-Bugs\n  v1.12\nw.r.t. recent email traffic.\n\nI eyeballed the .ics file, and it looks OK. I'd like to be able\nto show the ical:summary's of the new and fixed bugs, but that\nisn't obvious from the cvs diffs. Hmm... maybe a report using\n--strings? or use diff.py?\n\nAnyway... I think we're overdue for a monthly bug status update\nto public-cwm-announce. The last one was March 6\nhttp://lists.w3.org/Archives/Public/public-cwm-announce/2004JanMar/0002.html\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: [redlanddev] Raptor Turtle Parse Erro",
            "content": "(moved from redland-dev list. Original post at:\n<http://lists.usefulinc.com/pipermail/redland-dev/2004-April/000466.html>)\n\nOn Saturday, April 24, 2004, 11:02:36 PM, Dave Beckett wrote:\n\n> The relativeUri production:\n>   http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#relativeURI\n> refers to encoding as in N-Triples 3.3:\n>   http://www.w3.org/TR/rdf-testcases/#sec-uri-encoding\n> which encodes an RDF URI reference:\n>  \n> http://www.w3.org/TR/2004/REC-rdf-concepts-20040210/#dfn-URI-reference\n\nYes, that's what I'd expect, but the text in the grammar says:\n\"character* with escapes as defined in the N-Triples section 3.3 URI\nReferences. This is then used as a relative URI and resolved against\nthe current base URI to give an absolute URI reference.\"\n\nIt doesn't say that that the characters are restricted to those valid\nin a URI, just the escapes. I half wondered if you were explicitly\nbeing lenient for future IRI support. Perhaps you could add a sentence\nreferring to the URI Reference definition in RDF Concepts.\n\n\nIan\n\n\n\n"
        },
        {
            "subject": "Development of platform-independent applications - workshop more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n\n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "Re: pls split turtle lexical details out of the gramma",
            "content": "On Tue, 13 Apr 2004 11:17:20 -0500, Dan Connolly <connolly@w3.org> wrote:\n\n> The turtle grammar starts out all formal...\n> \"This EBNF is the notation used in XML 1.0 second edition over an\n> alphabet of [UNICODE] characters.\"\n>  -- http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/\n> \n> but then it's not, really:\n> \n> [[\n> relativeURI ::= character* with escapes as defined in the N-Triples\n> section 3.3 URI References. This is then used as a relative URI and\n> resolved against the current base URI to give an absolute URI reference.\n> \n> string ::= character* with escapes as defined in N-Triples section 3.2\n> Strings\n> ]]\n> \n> I'd much rather have the lexical details specified separately\n> and have the grammar be a real formal grammar, suitable for\n> use with yacc or the equivalent.\n\nWell, that's exactly the same form as used in RDF Test Cases REC / Ntriples.\n\nAnyway.  I was just trying to avoid making the document a lot bigger.\nEBNF is one way to present grammars but always needs translation\ninto lex and yacc forms since there is hardly ever a clear indication\nof tokens (and that is sometimes an implementation choice).\n\nRaptor's turtle parser does use lex and yacc but I chose to do some\nof the tokens separately, such as whitespace processing rather than\nfollow the EBNF precisely.\n\nThe lexical details are not enough, or not always useful to express in\nthe EBNF, such as the escaping rules for Unicode characters, saying\nthat language is not significant for most RDF typed literals etc.\n \n> By way of comparison/contrast, see\n> \n>   http://www.w3.org/2000/10/swap/rdfn3-gram.html\n>   http://www.w3.org/2000/10/swap/rdfn3.g\n>   $Id: rdfn3.g,v 1.18 2002/08/15 23:20:36 connolly Exp $\n\nThat's sort of useful but omits lots of detail such as definitions\nof URIREF and QNAME - see recent bugs I posted to public-cwm-bug\non the problems with leaving that lax.\n\n> p.s. I see\n> \"Turtle is a work in progress, and I am looking for feedback\"\n> \n> but I wasn't sure where you wanted the feedback sent. I was\n> going to copy www-archive, but then grammar engineering is\n> reasonably high on the cwm development agenda too, so I\n> copied public-cwm-talk.\n\nFine with me.  I was wondering if you'd be happy with using this list\nfor Turtle discussions, even if they digress from cwm and N3?\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: pls split turtle lexical details out of the gramma",
            "content": "On Fri, 16 Apr 2004 12:40:35 +0200, Danny Ayers <danny666@virgilio.it> wrote:\n<snip/>\n> Dave - I could do with a YAPPS version of Turtle for the stuff I'm \n> playing with at the moment. I'll be happy to sort it out as time permits \n> (if you haven't time, of course).\n\nThat'd be interesting to see. I'm a bit wary of declaring the language\nin what looks more like code, than in EBNF which most people are very\nfamiliar reading.  But as an implementation, it'd be useful.  You should\nbe able to base it on one of the cwm yapps gramars.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: [redlanddev] Raptor Turtle Parse Erro",
            "content": "On Mon, 26 Apr 2004 09:16:34 +0100, Ian Davis <lists@internetalchemy.org> wrote:\n\n> (moved from redland-dev list. Original post at:\n> <http://lists.usefulinc.com/pipermail/redland-dev/2004-April/000466.html>)\n> \n> On Saturday, April 24, 2004, 11:02:36 PM, Dave Beckett wrote:\n> \n> > The relativeUri production:\n> >   http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#relativeURI\n> > refers to encoding as in N-Triples 3.3:\n> >   http://www.w3.org/TR/rdf-testcases/#sec-uri-encoding\n> > which encodes an RDF URI reference:\n> >  \n> > http://www.w3.org/TR/2004/REC-rdf-concepts-20040210/#dfn-URI-reference\n> \n> Yes, that's what I'd expect, but the text in the grammar says:\n> \"character* with escapes as defined in the N-Triples section 3.3 URI\n> References. This is then used as a relative URI and resolved against\n> the current base URI to give an absolute URI reference.\"\n> \n> It doesn't say that that the characters are restricted to those valid\n> in a URI, just the escapes. ..\n\nbut it does say it encodes an RDF URI reference, which does have\nthat restriction.\n\n> .. I half wondered if you were explicitly\n> being lenient for future IRI support. Perhaps you could add a sentence\n> referring to the URI Reference definition in RDF Concepts.\n\nThat was the intention.  But your original question was about > in\nURIs, and that character is still not allowed in IRIs, at least as far\nas I recall.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: pls split turtle lexical details out of the gramma",
            "content": "Dave Beckett wrote:\n\n>On Fri, 16 Apr 2004 12:40:35 +0200, Danny Ayers <danny666@virgilio.it> wrote:\n><snip/>\n>  \n>\n>>Dave - I could do with a YAPPS version of Turtle for the stuff I'm \n>>playing with at the moment. I'll be happy to sort it out as time permits \n>>(if you haven't time, of course).\n>>    \n>>\n>\n>That'd be interesting to see. I'm a bit wary of declaring the language\n>in what looks more like code, than in EBNF which most people are very\n>familiar reading.  \n>\nYep, that makes sense.\n\n>But as an implementation, it'd be useful.  You should\n>be able to base it on one of the cwm yapps gramars.\n>  \n>\nRight, thanks, I'll have a nosey around cvs, get onto it sometime in the \nnext few days.\n\nCheers,\nDanny.\n\n-- \n----\nRaw\nhttp://dannyayers.com\n\n\n\n"
        },
        {
            "subject": "diff:replacement of a document",
            "content": "Hi,\n\n<background>\nI am setting out to write a log file in RDF for James Gosling's BlogEd \neditor (https://bloged.dev.java.net/). The current log file is in a \nsimple and inflexible binary format, so the improvement would be \nwelcome.\n\nWe have settled on an OWL ontology derived from the Atom api.\nSince people may change their blog entries we need to allow for changes \nin the theory represented by the RDF file. I was thinking to do this \nusing diff:replacement as descibed by \nhttp://www.w3.org/DesignIssues/Diff\n\nOne of the nice thing about the RDF for our data file format is that it \nis statement based, so we can just append changes quickly to the end of \nthe data file, and so in case of a crash it will be very easy to \nrecover. It is also very close to the way James Gosling programmed his \neditor.\n</background>\n\nThe idea would be to use diff:replacement somehow like this:\n\n# up here lot of info about the Blog feed and its entry...\n#\n#\n<> {\n{ ?x blog:entry \"1\"; blog:text \"RDF is difficult.\"}\ndiff:replacement\n{ ?x blog:entry\" \"1\"; blog:text \"RDF is easy!\"}\n} <#newstate>\n\n<#newstate> :asserts {\n?x blog:entry \"1\";\n   blog:publicationDate \"12 May 2004, 12:00 UTC\"\n}\n\nWhat I hope this says is that there is a theory that is a diff of this \ndocument's theory that can be generated by replacing the text of blog \nnumber 1 by \"RDF is easy!\". That theory is called #newstate. #newstate \nalso asserts that its publication date is \"12 May 2004, 12:00 UTC\".\n\nThis way I can speak create a theory, create diffs of the theory, and \nchanges to that diffed theory, and perhaps even make diffs of that \ntheory, ad infinitum...\n\nIs this close to being right?\n\n\nPS. And also, what is a good book to read? I have \"The Semantic Web\" \npublished by Wiley written by Daconta, Obrst, and Smith. And of course \nI have been reading what is on the web. The many tools are really \nhelpful in helping one to get to grips quickly. I think I probably need \nto spend more time on cwm. \n\n\n\n"
        },
        {
            "subject": "Re: diff:replacement of a document",
            "content": "Oh well perhaps it just really is not that complicated. It is probably \njust what I had thought initially, adding the following to your file:\n\n{ ?x blog:entry \"1\"; blog:text \"RDF is difficult.\"}diff:replacement\n{ ?x blog:entry\" \"1\"; blog:text \"RDF is easy!\"}\n\nis  an act of changing the theory of your file change, just like adding \nmost simple grounded statements will result in a change of theory.\n\nI suppose part of my difficulty was trying to understand what adding \nthe inverse would do to the same file. Especially if one thinks of the \nfact that these statements are not meant to be ordered.\n\n{ ?x blog:entry\" \"1\"; blog:text \"RDF is easy!\"}\ndiff:replacement\n{ ?x blog:entry \"1\"; blog:text \"RDF is difficult.\"}\n\nBut I suppose a good interpreter, noticing these two statements cancel \neach other out, would just remove them.\n\nThanks for the extended  examples at\nhttp://www.w3.org/2000/10/swap/doc/\n\nIt is helping me get my head around all of this.\n\nHenry\n\nOn 10 May 2004, at 20:50, Henry Story wrote:\n\n> Hi,\n>\n> <background>\n> I am setting out to write a log file in RDF for James Gosling's BlogEd \n> editor (https://bloged.dev.java.net/). The current log file is in a \n> simple and inflexible binary format, so the improvement would be \n> welcome.\n>\n> We have settled on an OWL ontology derived from the Atom api.\n> Since people may change their blog entries we need to allow for \n> changes in the theory represented by the RDF file. I was thinking to \n> do this using diff:replacement as descibed by \n> http://www.w3.org/DesignIssues/Diff\n>\n> One of the nice thing about the RDF for our data file format is that \n> it is statement based, so we can just append changes quickly to the \n> end of the data file, and so in case of a crash it will be very easy \n> to recover. It is also very close to the way James Gosling programmed \n> his editor.\n> </background>\n>\n> The idea would be to use diff:replacement somehow like this:\n>\n> # up here lot of info about the Blog feed and its entry...\n> #\n> #\n> <> {\n> { ?x blog:entry \"1\"; blog:text \"RDF is difficult.\"}\n> diff:replacement\n> { ?x blog:entry\" \"1\"; blog:text \"RDF is easy!\"}\n> } <#newstate>\n>\n> <#newstate> :asserts {\n> ?x blog:entry \"1\";\n>    blog:publicationDate \"12 May 2004, 12:00 UTC\"\n> }\n>\n> What I hope this says is that there is a theory that is a diff of this \n> document's theory that can be generated by replacing the text of blog \n> number 1 by \"RDF is easy!\". That theory is called #newstate. #newstate \n> also asserts that its publication date is \"12 May 2004, 12:00 UTC\".\n>\n> This way I can speak create a theory, create diffs of the theory, and \n> changes to that diffed theory, and perhaps even make diffs of that \n> theory, ad infinitum...\n>\n> Is this close to being right?\n>\n>\n> PS. And also, what is a good book to read? I have \"The Semantic Web\" \n> published by Wiley written by Daconta, Obrst, and Smith. And of course \n> I have been reading what is on the web. The many tools are really \n> helpful in helping one to get to grips quickly. I think I probably \n> need to spend more time on cwm.\n\n\n\n"
        },
        {
            "subject": "diff:replacemen",
            "content": "Two further notes on this subject:\n\n--------------\nconcerning the two versions of diff proposed by TimBL at \nhttp://www.w3.org/DesignIssues/Diff, namely diff:replacement or the \npair diff:deletion and diff:insertion, I feel that the first make a lot \nmore sense to me. With diff:replacement it is very clear that one thing \nhas to be replaced with another.\n\nWith diff:deletion and diff:insertion, it is not clear what the role of \nthe Object of the statements are.\n\n{ ?x  bank:accountNo \"1234578\"}\n  diff:deletion  { ?x  bank:balance 4000};\n  diff:insertion { ?x  bank:balance 3575}.\n\nWell in the example it is clear that the first part is there in order \nto allow the variable ?x to be bound. But what if the node that is to \nbe deleted does not contain a variable node, as here:\n\n{} diff:deletion { uri://something created 1948 }\n\nThis would be the base case. And here one has to wonder what the role \nof the Object is. In any case I had such a situation and was not able \nto get cwm to work with this. I kept wondering what should go into the \nObject position.\n\n----------------\n\nAs my understanding of cwm improves I think I can now more clearly \nstate the thought I tried clumsily to express in the original post. I \nnow agree that a diff as stated says what it is meant to say. If one \nwanted to be more specific and specify what the diff was about one \ncould do it this way, assuming one has the facility to name graphs, as \nproposed by the Trix folks:\n\n(graph://OriginalGraph,graph://DiffedGraph) diff:transform\n( {originalObject  relatesTo originalValue}\ndiff:replace {originalObject  relatesTo differentValeu},\n  {OriginalObject2 relatesTo orgiginalValue}\n    diff:replace {originalObject  relatesDifferentlyTo \ndifferentValue}\n)\n\nIe one could use a new predicate diff:transform that would relate a \npair of graphs to some (all?) of the differences between them.\n\n\n\n"
        },
        {
            "subject": "filter in cwm.py,v 1.14",
            "content": "When running\ncwm http://eulersharp.sourceforge.net/2004/04test/danP.n3 -think \\\n-filter=http://eulersharp.sourceforge.net/2004/04test/danC.n3\nthe result is\n\n[[[[[\n#Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp \n        #    using base \nhttp://eulersharp.sourceforge.net/2004/04test/danP.n3\n \n#  Notation3 generation by\n#       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n\n#   Base was: http://eulersharp.sourceforge.net/2004/04test/danP.n3\n     @prefix : <danP#> .\n \n      ( \"Boston\" \n        42.19 \n        -71.05  )\n         a :Result .\n      ( \"Cambridge\" \n        42.30 \n        -71.10  )\n         a :Result .\n \n#ENDS\n]]]]]\n\nwhich is fine (*) i.e. for an older cwm.py,v 1.148\nbut for cwm.py,v 1.149 2004/05/12 we get\n\n[[[[[\n#Processed by Id: cwm.py,v 1.149 2004/05/12 01:27:06 timbl Exp \n        #    using base file:/sfcvs/2004/04test/\n           cwm: Unknown option: -filter \n]]]]]\n\nWhat \n\n\n-- \nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n(*) at least that's what I also find when running\nEuler --nope --think http://eulersharp.sourceforge.net/2004/04test/danP \\\nhttp://eulersharp.sourceforge.net/2004/04test/danC\n\nand now I understand what Tim suggested namely that\nwe should use the filter as query...\n\n\n\n"
        },
        {
            "subject": "Re: filter in cwm.py,v 1.14",
            "content": "Oops.. it is working now, but I'm not sure\nif I'm still awake...\nThe first test was actually done as\npython /www.w3.org/2000/10/swap/cwm.py ...\nwhereas the second using a batch file for cwm\nand when we quote the filter argument like\ncwm danP.n3 -think \"-filter=danC.n3\"\nit is now working...\n\n-- \nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n\n\nJos De_Roo/AMDUS/MOR/Agfa-NV/BE/BAYER@AGFA\nSent by: public-cwm-talk-request@w3.org\n15/05/2004 03:35\n\n \n        To:     public-cwm-talk@w3.org\n        cc:     timbl <timbl@w3.org>\n        Subject:        -filter in cwm.py,v 1.149\n\n\n\nWhen running\ncwm http://eulersharp.sourceforge.net/2004/04test/danP.n3 -think \\\n-filter=http://eulersharp.sourceforge.net/2004/04test/danC.n3\nthe result is\n\n[[[[[\n#Processed by Id: cwm.py,v 1.148 2004/03/21 04:24:32 timbl Exp \n        #    using base \nhttp://eulersharp.sourceforge.net/2004/04test/danP.n3\n \n#  Notation3 generation by\n#       notation3.py,v 1.153 2004/03/21 04:24:35 timbl Exp\n\n#   Base was: http://eulersharp.sourceforge.net/2004/04test/danP.n3\n     @prefix : <danP#> .\n \n      ( \"Boston\" \n        42.19 \n        -71.05  )\n         a :Result .\n      ( \"Cambridge\" \n        42.30 \n        -71.10  )\n         a :Result .\n \n#ENDS\n]]]]]\n\nwhich is fine (*) i.e. for an older cwm.py,v 1.148\nbut for cwm.py,v 1.149 2004/05/12 we get\n\n[[[[[\n#Processed by Id: cwm.py,v 1.149 2004/05/12 01:27:06 timbl Exp \n        #    using base file:/sfcvs/2004/04test/\n           cwm: Unknown option: -filter \n]]]]]\n\nWhat \n\n\n-- \nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n(*) at least that's what I also find when running\nEuler --nope --think http://eulersharp.sourceforge.net/2004/04test/danP \\\nhttp://eulersharp.sourceforge.net/2004/04test/danC\n\nand now I understand what Tim suggested namely that\nwe should use the filter as query...\n\n\n\n"
        },
        {
            "subject": "major problem with diff:replacemen",
            "content": "There is a major difference between the entailment relation a expressed \nby the => sign in cwm and the diff:replacement, which I think indicates \na big conceptual difference between these two methods.\n\nIn any theory you can consistently have any number of entailment \nrelations with the same antecedent.\n\nSo\nThe cat is on the mat => the mat is under the cat\nThe cat is on the mat => the cat is happy\n\ncould be consistently held to be true.\nOn the other hand:\n\nThe cat is on the mat\n{The cat is on the mat} diff:replace { The cat is on the table }\n{The cat is on the mat} diff:replace { The cat is on grass }\n\nAssuming we have somehow limited ourselves to describing the same point \nin time, the above cannot be consistently held. One has to make a \nchoice, between the diff replacements holds. A cat cannot be at two \nplaces at once. Yet each one of the two statements by itself is a valid \napplication of the diff:replace relation.\n\nI think part of the reason for this is that implication is a relation \nwithin first order logic, whereas diff:replace is a relation between \ntheories.  Implication preserves truth conditions, whereas diff:replace \nchanges them. diff:replace is a mapping between theories. It says: the \nsecond theory can be reached by changing the first theory in this way. \nAs an image I think the following will help (if file attachments are \nallowed on this list)\n\n\n\nThis represents a file containing two diff:replace statements, \nconcerning the same objects. Each diff replacement maps to a different \nand incompatible theory.\n\nBefore continuing let me check that this mailing list accepts image \nattachments.\n\nHenry\n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Re: major problem with diff:replacement: continue",
            "content": "I think diff:replace moves us into the domain of modal logic, as \nexplained for example by David Lewis in his book Counterfactuals.\n\nThe problem with a replacement of a fact is that you can rarely just \nreplace on fact in a theory. Replacing a fact entails all kinds of \nother changes. So consider:\n\nIf I had not paid my bill I would have been in trouble.\n\nThe actual world here is the one where I do pay my bill.\nWe are asked in the actual world to consider what would have happened \nhad I not paid my bill.\nwe are doing something like\n\n{pay my bill} diff:replace {}\n\nBut the world where I don't pay my bill, is also a world where I have \nmore money, where I could have spent money that evening, that might \nhave allowed me to meet someone who could have changed my life, etc. \netc.\n\nThese are all points made by David Lewis in the introduction to his \nbook.\n\nA little pause.\n\nHenry\n\n\n\nOn 15 May 2004, at 12:42, Henry Story wrote:\n>\n> Before continuing let me check that this mailing list accepts image \n> attachments.\n\n\n\n"
        },
        {
            "subject": "Re: major problem with diff:replacemen",
            "content": "Henry wrote:\n[...]\n> Before continuing let me check that this mailing list accepts image \n> attachments.\n\nlooking at\nhttp://lists.w3.org/Archives/Public/public-cwm-talk/2004AprJun/0014.html\nI would say it does, just that the letters are a bit small to read :)\n\n-- \nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n\n"
        },
        {
            "subject": "Re: major problem with diff:replacemen",
            "content": "Just before anyone points out that the title may be a little \nexaggerated, I'll say so myself. :-)\n\nHopefully the previous posts help reveal what is behind diff:replace so \nthat one can use it appropriately.\n\nHenry\n\nOn 15 May 2004, at 12:42, Henry Story wrote:\n\n> There is a major difference between the entailment relation a \n> expressed by the => \n\n\n\n"
        },
        {
            "subject": "more work on bug statu",
            "content": "I updated the .ics todo list\n  http://www.w3.org/2000/10/swap/admin/N3-Bugs.ics\nto v1.13\n\nand made a new report in XHTML:\n  http://www.w3.org/2000/10/swap/admin/bugStatus\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Re: more work on bug statu",
            "content": "Thanks, Dan!\n\nThe date-ordered version is very useful\n\n(It doesn't seem to have spotted the [closed] to the \"diff.py still not \nworking\" thread, of May 16.\n  http://lists.w3.org/Archives/Public/public-cwm-bugs/2004May/0010.html\nMaybe it didn't get in)\n\nTim\n\nOn May 20, 2004, at 18:08, Dan Connolly wrote:\n\n> I updated the .ics todo list\n>   http://www.w3.org/2000/10/swap/admin/N3-Bugs.ics\n> to v1.13\n>\n> and made a new report in XHTML:\n>   http://www.w3.org/2000/10/swap/admin/bugStatus\n>\n> -- \n> Dan Connolly, W3C http://www.w3.org/People/Connolly/\n>\n\n\n\n"
        },
        {
            "subject": "Re: more work on bug statu",
            "content": "That's indeed a very nice overview!\n\nAlthough I couldn't go to WWW2004, it is possible to follow\nsome quite exciting things via the Web, such as for instance\nhttp://www.w3.org/2004/Talks/0520-em-swa/\nand thanks a lot for that!\n\nAs an aside, I'm experimenting with {} command line arguments\nso that for instance the (command line protocol) query\n\n$ euler --think http://slashdot.org/slashdot.rss \\\n \"{@prefix rss: <http://purl.org/rss/1.0/>. ?U rss:title ?T}\"\n\ngives us an answer (at this moment)\n\n# Generated with http://www.agfa.com/w3c/euler/ version R3851 on 21 May \n2004 13:40:24 GMT\n@prefix log: <http://www.w3.org/2000/10/swap/log#>.\n\n(<http://slashdot.org/slashdot.rss>.log:semantics).log:conjunction =>\n{\n@prefix : <http://purl.org/rss/1.0/>.\n@prefix syn: <http://purl.org/rss/1.0/modules/syndication/>.\n@prefix taxo: <http://purl.org/rss/1.0/modules/taxonomy/>.\n@prefix log: <http://www.w3.org/2000/10/swap/log#>.\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>.\n@prefix admin: <http://webns.net/mvcb/>.\n@prefix rss: <http://purl.org/rss/1.0/>.\n@prefix dc: <http://purl.org/dc/elements/1.1/>.\n@prefix slash: <http://purl.org/rss/1.0/modules/slash/>.\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>.\n\n<http://images.slashdot.org/topics/topicslashdot.gif> rss:title \n\"Slashdot\".\n\n<http://slashdot.org/> rss:title \"Slashdot\".\n\n<http://slashdot.org/article.pl?sid=04/05/21/0057234> rss:title \"AgroWaste \nOil Plant Starts Production\".\n\n<http://slashdot.org/article.pl?sid=04/05/21/0120243> rss:title \"Bob \nMuglia on Longhorn Server, Linux and Blackcomb\".\n\n<http://slashdot.org/search.pl> rss:title \"Search Slashdot\".\n\n<http://slashdot.org/article.pl?sid=04/05/20/236211> rss:title \"Slashback: \nFairness, Radioactivity,Recovery\".\n\n<http://slashdot.org/article.pl?sid=04/05/21/0049215> rss:title \"Accused \nSpammer to Debate SpamCop Founder\".\n\n<http://slashdot.org/article.pl?sid=04/05/20/2133221> rss:title \n\"Berners-Lee on the TLD Explosion\".\n\n<http://slashdot.org/article.pl?sid=04/05/20/2330231> rss:title \"Intel \nSued for Patent Infringement\".\n\n<http://slashdot.org/article.pl?sid=04/05/21/1212210> rss:title \"FBI Plans \nSpammer Smackdown\".\n\n<http://slashdot.org/article.pl?sid=04/05/20/222226> rss:title \"Everaldo \nand Jimmac On Linux Art and Usability\".\n\n<http://slashdot.org/article.pl?sid=04/05/21/0053239> rss:title \"Worst \nExplanation From Tech Support?\".\n\n<http://slashdot.org/article.pl?sid=04/05/20/2152211> rss:title \n\"Firefox/Thunderbird Plugins: Is Less More?\".\n\n# Proof found for _:engine_1 in 13 steps (1300000 steps/sec) using 1 \nengine\n}.\n\n\nand it's interesting that way to find out for instance more about\nhttp://slashdot.org/article.pl?sid=04/05/20/2133221\n:)\n\n-- \nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n\n\nTim Berners-Lee <timbl@w3.org>\nSent by: public-cwm-talk-request@w3.org\n21/05/2004 15:33\n\n \n        To:     Dan Connolly <connolly@w3.org>\n        cc:     public-cwm-talk@w3.org\n        Subject:        Re: more work on bug status\n\n\n\nThanks, Dan!\n\nThe date-ordered version is very useful\n\n(It doesn't seem to have spotted the [closed] to the \"diff.py still not \nworking\" thread, of May 16.\n  http://lists.w3.org/Archives/Public/public-cwm-bugs/2004May/0010.html\nMaybe it didn't get in)\n\nTim\n\nOn May 20, 2004, at 18:08, Dan Connolly wrote:\n\n> I updated the .ics todo list\n>   http://www.w3.org/2000/10/swap/admin/N3-Bugs.ics\n> to v1.13\n>\n> and made a new report in XHTML:\n>   http://www.w3.org/2000/10/swap/admin/bugStatus\n>\n> -- \n> Dan Connolly, W3C http://www.w3.org/People/Connolly/\n>\n\n\n\n"
        },
        {
            "subject": "Re: more work on bug statu",
            "content": "On Fri, 2004-05-21 at 14:33, Tim Berners-Lee wrote:\n> Thanks, Dan!\n> \n> The date-ordered version is very useful\n> \n> (It doesn't seem to have spotted the [closed] to the \"diff.py still not \n> working\" thread, of May 16.\n>   http://lists.w3.org/Archives/Public/public-cwm-bugs/2004May/0010.html\n> Maybe it didn't get in)\n\nI'm investigating... based on the data I found (below) I suspect\nadding a rule about transitivity of References will fix it...\n\n\nconnolly@frink ../latest[508] egrep -i\n'^(From|Message-Id|References|Subject)' `grep -l \"diff.py\"  *`\n28:From henry.story@bblfish.net  Fri May  7 13:10:29 2004\n28:Message-Id: <63BFCC5E-A049-11D8-BE2D-000A95D9FA7A@bblfish.net>\n28:From: Henry Story <henry.story@bblfish.net>\n28:Subject: diff.py not working\n29:From henry.story@bblfish.net  Fri May  7 13:56:42 2004\n29:Message-Id: <DB48F68A-A04F-11D8-BE2D-000A95D9FA7A@bblfish.net>\n29:From: Henry Story <henry.story@bblfish.net>\n29:Subject: Re: diff.py not working\n30:From henry.story@bblfish.net  Fri May  7 14:17:46 2004\n30:References: <DB48F68A-A04F-11D8-BE2D-000A95D9FA7A@bblfish.net>\n30:Message-Id: <D213EF64-A052-11D8-BE2D-000A95D9FA7A@bblfish.net>\n30:From: Henry Story <henry.story@bblfish.net>\n30:Subject: Re: diff.py not working\n31:From henry.story@bblfish.net  Sat May  8 08:04:58 2004\n31:References: <DB48F68A-A04F-11D8-BE2D-000A95D9FA7A@bblfish.net>\n<D213EF64-A052-11D8-BE2D-000A95D9FA7A@bblfish.net>\n31:Message-Id: <D3BE9D04-A0E7-11D8-BE2D-000A95D9FA7A@bblfish.net>\n31:From: Henry Story <henry.story@bblfish.net>\n31:Subject: Re: diff.py still not working\n32:From timbl@w3.org  Sun May 16 16:21:58 2004\n32:References: <DB48F68A-A04F-11D8-BE2D-000A95D9FA7A@bblfish.net>\n32:Message-Id: <AC46C752-A776-11D8-937D-000A9580D8C0@w3.org>\n32:From: Tim Berners-Lee <timbl@w3.org>\n32:Subject: \"Bad Syntax\" message instead of 404 file not found\n33:From timbl@w3.org  Sun May 16 16:38:56 2004\n33:References: <DB48F68A-A04F-11D8-BE2D-000A95D9FA7A@bblfish.net>\n<D213EF64-A052-11D8-BE2D-000A95D9FA7A@bblfish.net>\n<D3BE9D04-A0E7-11D8-BE2D-000A95D9FA7A@bblfish.net>\n33:Message-Id: <092D70F8-A779-11D8-937D-000A9580D8C0@w3.org>\n33:From: Tim Berners-Lee <timbl@w3.org>\n\n\n> Tim\n> \n> On May 20, 2004, at 18:08, Dan Connolly wrote:\n> \n> > I updated the .ics todo list\n> >   http://www.w3.org/2000/10/swap/admin/N3-Bugs.ics\n> > to v1.13\n> >\n> > and made a new report in XHTML:\n> >   http://www.w3.org/2000/10/swap/admin/bugStatus\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "urtle - Terse RDF Triple Language changes at 2004-061",
            "content": "I have just made an update to the Turtle language at\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/\nto cover some points raised since the last change.\nThe full detailed changes are given in the document changelog\nat http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#sec-changelog\n\nDiscussion of Turtle can be done on this list but preferably for\ndetailed items, on public-cwm-talk which is archived at\n  http://lists.w3.org/Archives/Public/public-cwm-talk/\n\n\n1. Turtle names (QNames) are now allowed to use '_' at the start\nof local names but not namespace prefixes since that's used for\nblank node names.\n\nThis change was made because, for example, rdf:_1 was forbidden\nas a QName which is slightly embarrassing :)\n\nChanged the EBNF to support the change above, adding nameStartChar\nand nameChar terms named after the XML equivalent.  This is also\nmeant some Editorial changes to the QNames section at\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#sec-qnames\nto match the change to the grammar terms.\n\n\n2. Allow a predicateObjectList to have a trailing ';' which\nmakes it easier for generating Turtle and for humans.\n\nFor example, this is now allowed (... standing for other property /\nvalue pairs)\n\n----------------------------------------\n_:a a :List ;\n    :item [ :prop1 \"value1\" ... ] ;\n    :item [ :prop1 \"value2\" ... ] ;\n    :item [ :prop1 \"value3\" ... ] ;\n----------------------------------------\n\n\n3. Updated the test cases for Turtle\n\nNew tests.zip at\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/tests.zip\nwith tests for the items above.  This is also available in\nRaptor's CVS, see the end of the Examples section\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#sec-examples\nfor pointers.\n\n\nSales Pitch: These changes are implemented in Raptor CVS version\nright now at\n  http://www.redland.opensource.ac.uk/raptor/\nand will be in the 1.3.1 release out soon.\n\nCheers\n\nDave\n\n\n\n"
        },
        {
            "subject": "new lis",
            "content": "List_Name: public-cwm-talk\n\nListPurpose:\nGeneral discussion of <a\nhref=\"http://www.w3.org/2000/10/swap/doc/cwm.html\"> cwm </a>.  See\nalso public-cwm-bugs for bug reports and public-cwm-announce for\nannouncements about cwm from the developers.\n\nMaintaining_Activity: Semantic Web\n\n-- \nDaigo Matsubara / W3C Systems Team / mailto:daigo@w3.org\n\n\n\n"
        },
        {
            "subject": "Swish GraphDiff: nifty",
            "content": "[thread starts in rdf-interest\nhttp://lists.w3.org/Archives/Public/www-rdf-interest/2004Feb/0056.html\ngoes via rdf-calendar and #rdfig...\nhttp://rdfig.xmlhack.com/2004/02/11/2004-02-11.html#1076540342.902364\n\nAnd I'm taking it to the new public-cwm-talk@w3.org , cuz diff\nis high on the cwm/swap agenda...\npsst... timbl, you haven't subscribed yet.\n]\n\nOn Wed, 2004-02-11 at 16:36, Dan Connolly wrote:\n> On Wed, 2004-02-11 at 15:05, Graham Klyne wrote:\n> > At 10:52 11/02/04 -0600, Dan Connolly wrote:\n> > >I'm still leaning toward finding or making a better\n> > >XML serializer. I'm tired of running tidy to indent\n> > >the results so that I can look at them.\n> > \n> > I have recently been playing \"nearby\", so to speak.\n> > \n> > In my just-announced RDF graph-difference displayer [1],\n> \n> I followed the link to...\n>  http://www.ninebynine.org/RDFNotes/Swish/Intro.html#GraphDiff\n> \n> wow! That's really cool! We've been noodling on the diff\n> problem for quite a while, and your solution looks appealing\n> from theoretical _and_ practical angles.\n> \n> I gotta try it out...\n\nI'm able to reproduce your results on a debian GNU/linux box thusly:\n\n# apt-get install hugs\n\nconnolly@dirk:~/src/gk-swish/HaskellRDF$ runhugs -98\n-P:.:../HaskellUtils/:Parsec:HUnit:Sort:Dfa Swish.hs -i=Data/Diff1.n3\n-d=Data/Diff2.n3\nGraph differences: 8\n---- Difference 1 ----\nGraph 1:\"lx12\"\nGraph 2:\"lx22\"\n---- Difference 2 ----\nGraph 1:base3:o3\nGraph 2:_:o3\n---- Difference 3 ----\nGraph 1:\n(_:11 base2:5 \"lx13\")\nGraph 2:\n(No arcs)\n---- Difference 4 ----\nGraph 1:\n(No arcs)\nGraph 2:\n(_:11 base2:p5 \"lx13\")\n---- Difference 5 ----\nGraph 1:\n(_:7 base2:p22\n  (_:8 rdf:rest\n    (_:10 rdf:rest rdf:nil\n      ; rdf:first \"lx12\")\n    ; rdf:first\n    (_:9 base2:p23 \"lx11\")))\nGraph 2:\n(No arcs)\n---- Difference 6 ----\nGraph 1:\n(No arcs)\nGraph 2:\n(_:7 base2:p22a\n  (_:8 rdf:rest\n    (_:10 rdf:rest rdf:nil\n      ; rdf:first \"lx22\")\n    ; rdf:first\n    (_:9 base2:p23 \"lx21\")))\n---- Difference 7 ----\nGraph 1:\"p3-diff1\"\nGraph 2:\"p3-diff2\"\n---- Difference 8 ----\nGraph 1:base4:o1\nGraph 2:base4:o2\n\n\n\n> >  I use an approach \n> > that starts by partitioning the RDF graph into subtrees whose branches \n> > jointly span the graph.  One of my plans for the future is to use this to \n> > add an improved serializer to Swish.  The module concerned is at [2], and \n> > you may be able to glean some ideas, even if you're not fluent in Haskell...\n> > \n> > #g\n> > --\n> > \n> > [1] http://lists.w3.org/Archives/Public/www-rdf-interest/2004Feb/0056.html\n> > \n> > [2] http://www.ninebynine.org/Software/Swish-0.2.1/HaskellRDF/GraphPartition.hs\n> > \n> > \n> > \n> > \n> > ------------\n> > Graham Klyne\n> > For email:\n> > http://www.ninebynine.org/#Contact\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the W3C Tech Plenary in Cannes 1-5 Mar 2003?\n\n\n\n"
        },
        {
            "subject": "RE: Shared Key Authentication for the TLS Protocol&ndash;&ndash; an Alternativ",
            "content": "In the Introduction section of Barb Fox's 9/30/96 posting, there is a\nreference to the original Shared Key Authentication for the TLS Protocol\ndocument.  For the those of you who may not seen this document before, I\nhave included it below along with Barb's 9/30/96 posting.\n\n\nShared Key Authentication for the TLS Protocol - Original\n\n\n1.  Introduction:  Why Shared Key Authentication?\n\nRecent transport-layer security protocols for the Internet, such as SSL\nversions 2.0 and 3.0 [1, 2] and PCT version 1 [3], have effected \nchallenge-response authentication using strictly public-key (asymmetric)\ncryptographic methods, with no use of out-of-band shared secrets.  This \nchoice has both benefits and drawbacks.  The primary benefit is improved\nsecurity:  an asymmetric private key used for authentication is only \nstored in one location, and the out-of-band identification necessary for\npublic key certification need only be reliable, not secret (as an out-\nof-band shared key exchange must be).  In addition, the difficult task \nof out-of-band shared-key exchange in shared-key authentication systems \noften leads implementers to resort to human-friendly shared keys \n(manually typed passwords, for instance), which may be vulnerable to \ndiscovery by brute force search or \"social engineering\". \n\nHowever, shared-key authentication has certain advantages as well.  \nThese are, chiefly:\n\n- Portability:  Precisely because shared keys are often human-remembered\npasswords or passphrases, they can be transported from (trusted) machine\nto (trusted) machine with ease--unlike asymmetric private keys, which \nmust be transported using some physical medium, such as a diskette or \n\"smart card\", to be available for use on any machine.\n\n- Backward Compatibility:  Shared-key authentication is in very wide use\ntoday, and the cost of conversion to its public-key counterpart may not \nbe worth the extra security, to some installations.\n\n- Established Practice:  Shared-key authentication has been in use for \nquite a while, and a valuable body of tools, techniques and expertise \nhas grown up around it.  In contrast, public-key authentication is very \nnew, its associated tools and methods are either untested or non-\nexistent, and experience with possible implementation or operation \npitfalls simply doesn't exist.\n\nThese reasons are particularly relevant when individual human users of a\nservice are being authenticated over the Internet, and as a result, \nvirtually all authentication of (human) clients of such services is \ncurrently performed using shared passwords.  Typically, servers \nimplementing one of the aforementioned transport-layer security \nprotocols, and needing client authentication, simply accept secure \n(i.e., encrypted and server-authenticated) connections from each client,\nwho then provides a password (or engages in a challenge-response \nauthentication protocol based on a password) over the secure connection \nto authenticate to the server.\n\nUnfortunately, such \"secure\" connections are often not secure enough to \nprotect passwords, because of the various international legal \nrestrictions that have been placed on the use of encryption.  Obviously,\nsecret keys such as passwords should not be sent over weakly encrypted \nconnections.  In fact, even a challenge-response protocol which never \nreveals the password is vulnerable, if a poorly chosen, guessable \npassword is used; an attacker can obtain the (weakly protected) \ntranscript of the challenge-response protocol, then attempt to guess the\npassword, verifying each guess against the transcript.   \n\nHowever, it is possible to protect even badly-chosen passwords against \nsuch attacks by incorporating shared-key authentication into the \ntransport-layer security protocol itself.  These protocols already \ninvolve the exchange of long keys for message authentication, and those \nsame keys can be used (without the legal restraints associated with \nencryption) to provide very strong protection for shared-key-based \nchallenge-response authentications, provided that the mechanism used \ncannot be diverted for use as a strong encryption method.  This latter \nrequirement makes it essential that the shared-key-based authentication \noccur at the protocol level, rather than above it (as is normally the \ncase today), so that the implementation can carefully control use of the\nlong authentication key. \n\n2.  Objections\n\nThe primary objection raised against the inclusion of shared-key \nauthentication in transport-layer security protocols is the resulting \ndegradation in security.  However, it is not the place of the protocol \nto force such decisions on its users.  In practice, if shared-key \nauthentication is not included in the protocol, then users intent on \nusing it (for any of the reasons described above) will simply continue \nto use it as they do today--that is, less securely than if it were \nincorporated into the protocol. \n\nNor does the presence of shared-key authentication in the protocol have \nthe slightest effect on those who do not wish to use it.  Shared-key \nauthentication requires the prior agreement of both parties; any client \nor server who does not trust it has the option of refusing to take part \nin the necessary out-of-band exchange of a shared key.  There is then no\ndanger of any such party being \"fooled\" into engaging in a shared-key \nauthentication protocol, since no shared key will be available.\n\nFinally, it has been suggested that the inclusion of shared-key \nauthentication in the TLS protocol will discourage migration to public-\nkey authentication methods.  This concern is unrealistic; in fact, by \nproviding a smoother upgrade path, shared-key authentication in TLS will\nlikely expedite the transition to public-key authentication in many \ncases.  Without it, servers that are unready for public-key client \nauthentication will have to keep their client authentication mechanism \none layer above the transport layer, as they typically do now.  However,\nonce they have been lured (by the promise of improved security) into the\nless traumatic step of placing their shared-key authentication at the \ntransport layer, the transition to public-key authentication will be \nthat much easier.\n\n\n3.  Proposed Protocol Additions\n\nStarting from SSL version 3.0 notation and formats, the following new \nClientCertificateType values (in the certificate request message) would \nbe added:\n\nshared_key_standard(40), shared_key_private(41)\n\nThe certificate_authorities list in the certificate request message \nwould be permitted to include, in addition to certificate authority \ndistinguished names, distinguished names of shared-key authentication \nservices by which the client can authenticate.  (For example, the client\nmay share several keys with the server, associated with identities on \ndifferent systems residing on the same server.)\n\nA new HandshakeType would also be defined, and included in the Handshake\nmessage definition:\n\nshared_key_verify(17)\n\nThe shared_key_verify message would have the following structure:\n\nstruct {\n     DistinguishedName authentication_service;\n     opaque identity<1..65535>;\n     opaque shared_key_response<1..255>;\n} SharedKeyVerify;\n\nThe value of authentication_service would be required to be selected \nfrom those included in certificate_request.certificate_authorities.  The\nformat of the identity field would be left to the implementation, and \nshould be inferable from the accompanying value of \nauthentication_service.  In the case of ClientCertificateType \nshared_key_private, this would also be true of the format of \nshared_key_response.  In the case of ClientCertificateType \nshared_key_standard, the value of shared_key_response would be defined \nas\n\nSharedKeyVerify.shared_key_response\n     hash (auth_write_secret + pad_2 + \n            hash (handshake_messages + MAC_write_secret +\n    SharedKeyVerify.identity + pad1) )\n     xor hash (client_hello.random + identity + shared_key +\n    server_hello.random) \n\nHere \"+\" denotes concatenation and \"xor\" denotes bitwise exclusive-or.  \nThe hash function used (hash) would be taken from the pending cipher \nspec.  The client_auth_write_secret and server_auth_write_secret values \nwould be obtained by extending the key_block by twice \nCipherSpec.hash_size bytes beyond the server_write_key (or the \nserver_write_IV, if it is derived from key_block as well), and using the\nfirst and second halves of this extended portion as the \nclient_auth_write_secret and server_auth_write_secret values, \nrespectively.  The value of handshake_messages would be the \nconcatenation of all handshake messages from the first one sent up to \n(but not including) the shared_key_verify message.  The two \"random\" \nvalues would be taken from the client hello and server hello handshake \nmessages.  The pad1 and pad2 values correspond to the ones used for MAC \ncomputation in the application_data message.\n\n\n4.  Normal Authentication\n\nA shared-key-based client authentication would proceed as follows:  the \nserver sends a certificate request handshake message, just as it would \nin the case of public-key-based client authentication; however, the \nspecified ClientCertificateType is either shared_key_standard or \nshared_key_private.  The accompanying list of certificate authorities \nincludes the Distinguished Name of one or more authentication services; \nthe client selects one of these and constructs the appropriate \nauthentication response, sending it back, along with its identity and \nchoice of authentication service, in a shared key verify handshake \nmessage.  If the certificate request message specified \nClientCertificateType shared_key_standard, then the authentication \nresponse in the certificate verify message would be constructed as \ndescribed above; otherwise, the response's construction would be \ndictated by the choice of authentication service.\n\nThe server would also itself construct the correct authentication \nresponse using the known shared key, and check it against the one \nprovided by the client.  The authentication would be successful if the \ntwo matched exactly.  Note that if the shared key is password-based, \nthen it would typically be derived from the password using a one-way \ncryptographic hash function, rather than being the password itself, so \nthat the original password need not be remembered by anyone but the \nclient.\n\n\n5.  Pass-through Authentication\n \nIn some circumstances, it is preferable for shared keys to be stored in \none place (a central, well-protected site, for instance) while servers \nthat actually communicate with clients are elsewhere (possibly widely \ndistributed, but maintaining secure connections to the central shared-\nkey server).  One of the advantages of the shared-key authentication \nmethod proposed here is that it allows \"pass-through\" authentication by \na third party, if the server accepting the public-key key exchange and \nthe server sharing the key with the client happen to be different.  (The\nsomewhat odd-looking exclusive-or of two hashes in the response \ncomputation makes this possible.)  \n\nPass-through authentication might work as follows:  the client's hello \nmessage would be accompanied by a list of one or more shared-key \nauthentication services with which it shares a key.  (The TLS working \ngroup is already considering giving the client the capability of \nspecifying its preferred certificate types and authorities, matching the\nserver's ability to do so in the SSL v3.0 certificate request message; \nDistinguished Names of authentication services could then be included in\nthe client's list of CAs.)  The service could then choose one of the \nclient's preferred authentication services and request a random \nchallenge from it, using that challenge as (or incorporating it into) \nthe random value in the server's hello message.  The server's \ncertificate request message would then specify that authentication \nservice in its list of certificate authorities, thus indicating the \nappropriate authentication method (in the case of ClientCertificateType \nshared_key_private).  The client would then compute the correct \nauthentication response, using the above proposed method (in the case of\nClientCertificateType shared_key_standard) or a method specific to the \nauthentication service (in the case of ClientCertificateType \nshared_key_private).  This response would be sent in the shared key \nverify message, replacing the certificate verify message sent when a \npublic-key client authentication response is called for.\n\nNote that the authentication response is the form of a bitwise \nexclusive-or of two \"pieces\", and therefore that given one piece plus \nthe entire (correct) response, one can recover the other piece.  Thus \nthe server, on receiving a response from a client, can compute the first\npiece of the correct response (the piece that doesn't depend on the \nshared key), and exclusive-or it with the client's actual response to \nobtain the client's version of the response's second piece.  This second\npiece (hashed once more, for good measure), together with the client's \nrandom challenge and identity and server's random challenge, can be sent\non to the authentication service for verification.\n\n\nReferences\n\n[1]  K. Hickman and T. Elgamal, \"The SSL Protocol\", Internet Draft \n<draft-hickman-netscape-ssl-01.txt> (deleted), February 1995.\n\n[2]  A. Freier, P. Karlton and P. Kocher, \"The SSL Protocol Version \n3.0\", Internet Draft <draft-freier-ssl-version3-01.txt>, March 1996.\n\n[3]  J. Benaloh, B. Lampson, D. Simon, T. Spies and B. Yee, The PCT \nProtocol\", Internet Draft <draft-benaloh-pct-00.txt>, November 1995.  \n\n>----------\n>From: Barb Fox\n>Sent: Monday, September 30, 1996 7:19 PM\n>To: 'ietf-tls@w3.org'\n>Subject: Shared Key Authentication for the TLS Protocol-- an Alternative \n>\n>Shared Key Authentication for the TLS Protocol--an Alternative\n>\n>1.  Introduction\n>\n>This document presents an alternative to the shared-key authentication \n>mechanism proposed for the TLS protocol on the IETF TLS mailing list in \n>late July 1996.  This alternative mechanism accomplishes the same goals \n>(including enabling three-party \"pass-through\" authentication) in a \n>slightly more straightforward manner.  A discussion of the arguments for \n>and against the inclusion of shared-key authentication in the TLS \n>protocol can be found in that original shared-key authentication \n>document.\n>\n>\n>2.  Summary of Changes From the Previous Proposal\n>\n>In the previous proposal, a key derived from the master key and several \n>other inputs was used in a stream-cipher-like manner to protect a \n>shared-key authentication response from eavesdroppers.  In this \n>proposal, a separate secret, called an authentication secret, is derived \n>directly from the master secret and incorporated into the authentication \n>response.  Thus in the case of pass-through authentication, the server \n>must pass not only the authentication response but also this \n>authentication secret to the authentication service verifying the \n>response.\n>\n>The previous proposal also reused the CertificateRequest handshake \n>message for shared-key authentication requests.  In the new proposal, \n>all shared-key-related data is contained in new handshake messages \n>(implementations that support the proposed changes can thus be made to \n>interoperate with implementations that do not, but ignore invalid \n>handshake messages).  Also, a \"private\" shared-key authentication \n>response format, originally proposed to allow arbitrary authentication \n>response formats between co-operating clients and servers, has been \n>removed from this proposal.  Since the response field is in any event \n>opaque, implementations of an alternative shared-key authentication \n>format for a particular authentication service can simply have clients \n>detect the specific authentication service, and construct their \n>authentication responses accordingly.\n>\n>Finally, extra challenge and display string fields have been associated \n>with each authentication service name provided by the server, the former \n>to facilitate pass-through authentication with service-supplied \n>challenges, and the latter to help the implementation to identify the \n>authentication service to the user.\n>\n>\n>2.  Proposed Protocol Additions\n>\n>Starting from SSL version 3.0 notation and formats, the following two\n>new HandshakeTypes would would be added, and included in the Handshake \n>message definition:\n>\n>shared_key_request(31), shared_key_verify(32)\n>\n>The SharedKeyRequest message would have the following structure:\n>\n>struct { DistinguishedName auth_service_name;\n>         opaque display_string<0..65535>;\n>         opaque challenge<0..255>;\n>} AuthService;\n>\n>struct {\n>     AuthService auth_services_server<1..65535>;\n>} SharedKeyRequest;\n>\n>This optional message would be sent immediately following the server's \n>first set of consecutive messsages, which includes the ServerHello and \n>(possibly) the Certificate, CertificateRequest and ServerKeyExchange \n>messages.  The auth_services_server field would contain a list of \n>distinguished names of shared-key authentication services by which the \n>client can authenticate.  The challenge field accompanying each \n>authentication service name would contain an optional extra \n>authentication challenge, in case the server needs to obtain one from an \n>authentication service for pass-through authentication.  If none is \n>required, then it would simply be an empty (zero-length) field.  \n>Similarly, the display_string field could contain an extra field to be \n>displayed to the user during authentication, if needed. \n>\n>The SharedKeyVerify message would be sent in response to a \n>SharedKeyRequest message from the server, and would have the following \n>structure:\n>\n>struct {\n>     AuthService auth_service;\n>     opaque identity<1..65535>;\n>     opaque shared_key_response<1..255>;\n>} SharedKeyVerify;\n>\n>The value of auth_service would be required to be selected from the list \n>in SharedKeyRequest.auth_services_server.  The format of the identity \n>field would be left to the implementation, and should be inferable from \n>the accompanying value of auth_service.  The value of \n>shared_key_response would be defined as\n>\n>SharedKeyVerify.shared_key_response\n>     hash (auth_write_secret + pad_2 + \n>            hash (auth_write_secret + pad_1 + hash (handshake_messages)\n>            \n>                  + SharedKeyVerify.auth_service.auth_service_name\n>                  + SharedKeyVerify.auth_service.display_string\n>                  + SharedKeyVerify.auth_service.challenge\n>                  + SharedKeyVerify.identity + shared_key) )\n>     \n>Here \"+\" denotes concatenation.  The hash function used (hash) would be \n>taken from the pending cipher spec.  The client_auth_write_secret and \n>server_auth_write_secret values would be obtained by extending the \n>key_block by CipherSpec.hash_size bytes beyond the server_write_key (or \n>the server_write_IV, if it is derived from key_block as well), and using \n>this extended portion as the client_auth_write_secret value.  The value \n>of handshake_messages would be the concatenation of all handshake \n>messages from the first one sent up to (but not including) the \n>shared_key_verify message.  The pad1 and pad2 values correspond to the \n>ones used for MAC computation in the application_data message.  The \n>fields from the SharedKeyVerify message would be input with their length \n>prefixes included.  \n>\n>\n>3.  Normal Authentication\n>\n>A shared-key-based client authentication would proceed as follows:  the \n>server would send a SharedKeyRequest handshake message containing a list \n>of names of one or more authentication services.  The client, on \n>receiving the SharedKeyRequest message, would select an authentication \n>service from the server's list and construct the appropriate \n>authentication response as described above, sending it back, along with \n>its identity and choice of authentication service, in a SharedKeyVerify \n>handshake message.  The server would also itself construct the correct \n>authentication response using the known shared key, and check it against \n>the one provided by the client.  The authentication would be successful \n>if the two matched exactly.  Note that if the shared key is password-\n>based, then it would typically be derived from the password using a one-\n>way cryptographic hash function, rather than being the password itself, \n>so that the original password need not be remembered by anyone but the \n>client.\n>\n>\n>4.  Pass-through Authentication\n> \n>In some circumstances, it is preferable for shared keys to be stored in \n>one place (a central, well-protected site, for instance) while servers \n>that actually communicate with clients are elsewhere (possibly widely \n>distributed, but maintaining secure connections to the central shared-\n>key server).  One of the advantages of the shared-key authentication \n>method proposed here is that it allows \"pass-through\" authentication by \n>a third party, if the server accepting the public-key key exchange and \n>the server sharing the key with the client happen to be different.  (The \n>use of a separately derived authentication key in the response \n>computation makes this possible.)  \n>\n>Pass-through authentication might work as follows:  The server would \n>either collect random challenges in advance from its authentication \n>services, or request them as needed.  The server would then send a list \n>of authentication services and associated challenges in a \n>SharedKeyRequest message.  The client would then select an \n>authentication service (if more than one is offered), compute the \n>correct authentication response using the above proposed formula, and \n>send it to the server in a SharedKeyVerify message.\n>\n>The server, on receiving a response from a client, would pass it through \n>to the authentication service, along with the values necessary to \n>recalculate it:  the client_auth_write_key, the hash of all the \n>handshake messages and the identity field from the certificate verify \n>message.  The authentication service would then use the values provided, \n>along with the secret key it shares with the client and the challenge it \n>supplied, to reconstruct the correct value of the response.  If this \n>value exactly matches the one provided by the server, then the \n>authentication would succeed; otherwise it would fail.  \n>\n>\n>5.  Addendum--The SharedKeys Message\n>\n>In cases where pass-through authentication is used, it would be useful \n>for clients to be able to notify servers in advance of one or more \n>authentication services sharing a key with the client, so that the \n>server need only fetch (or use up) a challenge from a single service for \n>that client.  An additional optional message accompanying the \n>ClientHello would accomplish that purpose.  It is proposed here for \n>consideration, with the following HandshakeType:\n>\n>shared_keys(30)\n>\n>The SharedKeys message would have the following structure:\n>\n>struct {\n>     DistinguishedName auth_services_client<1..65535>;\n>} SharedKeys;\n>\n>This optional message would be sent immediately following the \n>ClientHello message, and would contain a list of distinguished names of \n>authentication services to which the client is willing to authenticate.  \n>This message could also be useful in non-pass-through situations; for \n>example, the client may share several keys with the server, associated \n>with identities on different systems (corresponding to different \n>``authentication services'' residing on the same server).  If a server \n>receives a SharedKeys message, then any subsequent SharedKeyRequest \n>message could contain a single authentication service selected from the \n>client's list.  \n>\n>Note that sending a SharedKeys message does not in itself normally \n>reveal significant information about the client's as-yet-unspecified \n>identity or identities.  However, if information about the set of \n>authentication services supported by a particular client is at all \n>sensitive, then the client should not send this message.\n>\n>Barbara Fox\n>bfox@microsoft.com\n>\n\n\n\n"
        },
        {
            "subject": "Re: Swish GraphDiff: nifty",
            "content": "Thanks!  I've added a link to your IRC posting to my description.\n\n#g\n--\n\nAt 18:00 11/02/04 -0600, Dan Connolly wrote:\n>[thread starts in rdf-interest\n>http://lists.w3.org/Archives/Public/www-rdf-interest/2004Feb/0056.html\n>goes via rdf-calendar and #rdfig...\n>http://rdfig.xmlhack.com/2004/02/11/2004-02-11.html#1076540342.902364\n>\n>And I'm taking it to the new public-cwm-talk@w3.org , cuz diff\n>is high on the cwm/swap agenda...\n>psst... timbl, you haven't subscribed yet.\n>]\n>\n>On Wed, 2004-02-11 at 16:36, Dan Connolly wrote:\n> > On Wed, 2004-02-11 at 15:05, Graham Klyne wrote:\n> > > At 10:52 11/02/04 -0600, Dan Connolly wrote:\n> > > >I'm still leaning toward finding or making a better\n> > > >XML serializer. I'm tired of running tidy to indent\n> > > >the results so that I can look at them.\n> > >\n> > > I have recently been playing \"nearby\", so to speak.\n> > >\n> > > In my just-announced RDF graph-difference displayer [1],\n> >\n> > I followed the link to...\n> >  http://www.ninebynine.org/RDFNotes/Swish/Intro.html#GraphDiff\n> >\n> > wow! That's really cool! We've been noodling on the diff\n> > problem for quite a while, and your solution looks appealing\n> > from theoretical _and_ practical angles.\n> >\n> > I gotta try it out...\n>\n>I'm able to reproduce your results on a debian GNU/linux box thusly:\n>\n># apt-get install hugs\n>\n>connolly@dirk:~/src/gk-swish/HaskellRDF$ runhugs -98\n>-P:.:../HaskellUtils/:Parsec:HUnit:Sort:Dfa Swish.hs -i=Data/Diff1.n3\n>-d=Data/Diff2.n3\n>Graph differences: 8\n>---- Difference 1 ----\n>Graph 1:\"lx12\"\n>Graph 2:\"lx22\"\n>---- Difference 2 ----\n>Graph 1:base3:o3\n>Graph 2:_:o3\n>---- Difference 3 ----\n>Graph 1:\n>(_:11 base2:5 \"lx13\")\n>Graph 2:\n>(No arcs)\n>---- Difference 4 ----\n>Graph 1:\n>(No arcs)\n>Graph 2:\n>(_:11 base2:p5 \"lx13\")\n>---- Difference 5 ----\n>Graph 1:\n>(_:7 base2:p22\n>   (_:8 rdf:rest\n>     (_:10 rdf:rest rdf:nil\n>       ; rdf:first \"lx12\")\n>     ; rdf:first\n>     (_:9 base2:p23 \"lx11\")))\n>Graph 2:\n>(No arcs)\n>---- Difference 6 ----\n>Graph 1:\n>(No arcs)\n>Graph 2:\n>(_:7 base2:p22a\n>   (_:8 rdf:rest\n>     (_:10 rdf:rest rdf:nil\n>       ; rdf:first \"lx22\")\n>     ; rdf:first\n>     (_:9 base2:p23 \"lx21\")))\n>---- Difference 7 ----\n>Graph 1:\"p3-diff1\"\n>Graph 2:\"p3-diff2\"\n>---- Difference 8 ----\n>Graph 1:base4:o1\n>Graph 2:base4:o2\n>\n>\n>\n> > >  I use an approach\n> > > that starts by partitioning the RDF graph into subtrees whose branches\n> > > jointly span the graph.  One of my plans for the future is to use \n> this to\n> > > add an improved serializer to Swish.  The module concerned is at [2], \n> and\n> > > you may be able to glean some ideas, even if you're not fluent in \n> Haskell...\n> > >\n> > > #g\n> > > --\n> > >\n> > > [1] \n> http://lists.w3.org/Archives/Public/www-rdf-interest/2004Feb/0056.html\n> > >\n> > > [2] \n> http://www.ninebynine.org/Software/Swish-0.2.1/HaskellRDF/GraphPartition.hs\n> > >\n> > >\n> > >\n> > >\n> > > ------------\n> > > Graham Klyne\n> > > For email:\n> > > http://www.ninebynine.org/#Contact\n>--\n>Dan Connolly, W3C http://www.w3.org/People/Connolly/\n>see you at the W3C Tech Plenary in Cannes 1-5 Mar 2003?\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "Understanding &#64;keyword",
            "content": "[I've been working on a set of explanatory @keywords examples to\nbetter understand how it's implemented. Please consider adding\nsome of these tests to the CWM regression suite.]\n\n@keywords allows one to carve out the set of reserved names which\nCWM is to use. Any that CWM does not recognize natively will be\noutput as literals:\n\n$ echo '@keywords p, q, r . p q r .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n     \"p\"     \"q\" \"r\" .\n\nSpecial keywords that CWM does recognize natively will be output\nas their normal selves, which usually means retaining the keyword:\n\n$ echo '@keywords a, Doc . <> a Doc .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n     <>     a \"Doc\" .\n\n(Using \"this\" causes an error; a seperate bug report is archived at\nhttp://lists.w3.org/Archives/Public/public-cwm-bugs/2004Feb/0003).\nOnce keywords have been declared, any bare (non-colon-prefixed) words\nthat are used are put into the default prefix space if it has been\ndelcared:\n\n$ echo '@keywords . @prefix : <#> . Mydoc a :Doc .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n      @prefix : <#> .\n     :Mydoc     :a :Doc .\n\nNote that \"a\" does not remain as an rdf:type synonym since it hasn't\nbeen declared as a keyword. If you try to use the default prefixing\nmechanism without using @prefix, an error will be raised:\n\n$ echo '@keywords . p a q .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n    notation3.BadSyntax: Line 1 of <file:.../keyword-test/>:\n      Bad syntax (Prefix  not bound) at ^ in:\n      \"@keywords . ^p a q .\"\n\nThe is and of keywords are not retained as special keywords outside\nof their valid context, and are converted into literals (or URIs if\nthe default prefix space is declared) elsewhere:\n\n$ echo '@keywords is, a, of . is a of .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n     \"is\"     a \"of\" .\n\nNote also that they can be used both inside and outside of their\nspecial contexts and will be converted or recognized accordingly:\n\n$ echo '@keywords is, a, of . is is a of of .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n     \"of\"     \"a\" \"is\" .\n\nIn the example above, \"a\" is not retained in its meaning of rdf:type,\nbut this is a quirk of the is/of idiom, which does not allow that\nspecial meaning, as illustrated here:\n\n$ echo '@prefix : <#> . :is is a of :of .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n    notation3.BadSyntax: Line 1 of <file:.../keyword-test/>:\n      Bad syntax (expected <property> after 'is') at ^ in:\n      \"@prefix : <#> . :is is^ a of :of .\"\n\nKeywords must be declared before they are used, otherwise a \"bad\nsyntax\" error will be given:\n\n$ echo 'p q r. @keywords p, q, r .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n    notation3.BadSyntax: Line 1 of <file:.../keyword-test/>:\n      Bad syntax (expected directive or statement) at ^ in:\n      \"^p q r. @keywords p, q, r .\"\n\nLikewise, builtin keywords can be used before they are overriden:\n\n$ echo '<> a <#Doc> . @keywords .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n      @prefix : <#> .\n     <>     a :Doc .\n\nSubsequent keyword declarations appear to overwrite all of the keywords\ndelcared earlier on; they do not get appended to the keyword space:\n\n$ echo '@keywords p, q, r . p q r . @keywords s . p q r .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n    notation3.BadSyntax: Line 1 of <file:.../keyword-test/>:\n      Bad syntax (Prefix  not bound) at ^ in:\n      \"@keywords p, q, r . p q r . @keywords s . ^p q r .\"\n\nThe default prefixes even work nicely in @forAll declarations:\n\n$ echo '@keywords . @prefix : <#> . @forAll p .' | \\\n    cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n     this     <http://www.w3.org/2000/10/swap/log#forAll> <#p> .\n\nKeywords must be \"words\"; they cannot contain special characters:\n\n$ echo '@keywords = .' | cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n    notation3.BadSyntax: Line 1 of <file:.../keyword-test/>:\n      Bad syntax ('@keywords' needs comma separated list of words)\n      at ^ in: \"@keywords = .^\"\n\nDeclaring \"@keywords prefix, keywords.\" is likely to cause some very\nstrange bugs at the moment. (A bug report has been sent and archived\nat http://lists.w3.org/Archives/Public/public-cwm-bugs/2004Feb/0005).\n\nKeywords can be delcared in formulae, and persist outside of the\nformulae as expected:\n\n$ echo '@prefix : <#> . { @keywords p, q . p q r } => { r p q } . \\\n    p r t .' | cwm | egrep -v '^[ \\t]*#|^[ \\t]*$'\n\n      @prefix : <#> .\n     \"p\"     :r :t .\n     { \"p\"     \"q\" :r .\n         }     <.../log#implies> {:r     \"p\" \"q\" . } .\n\nPlease let me know if there are any other points to be added,\n\n-- \nSean B. Palmer, <http://purl.org/net/sbp/>\n\"phenomicity by the bucketful\" - http://miscoranda.com/\n\n\n\n"
        },
        {
            "subject": "string: case",
            "content": "[forwarding an older mail]\n\nIn the mean time I've implemented the builtins\nstr:matches and str:notMatches for both java and .net i.e.\nhttp://cvs.sourceforge.net/viewcvs.py/eulersharp/2004/01swap/src/euler/Euler.java?rev=1.9&view=auto\nhttp://cvs.sourceforge.net/viewcvs.py/eulersharp/2004/01swap/src/Eulersharp/Euler.cs?rev=1.9&view=auto\n\nI know that this is not strictly *about* cwm, but we want to interoperate\nwith cwm and in that respect I wanted to ask if the str:matches is intended\nto determine if a string exactly matches a given pattern or to determine\nif a string contains a pattern (we did the former i.e. the \"exactly\nmatches\").\n\nAnother link is that we have python code in the works\nhttp://cvs.sourceforge.net/viewcvs.py/eulersharp/2004/02swap/RDFEngine/?sortby=date\nand Guido is actually working on a next (major) release and that's\nrunning backward chaining code...\n\nsemWaving :)\n\n--\nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n----- Forwarded by Jos De_Roo/AMDUS/MOR/Agfa-NV/BE/BAYER on 26/02/2004\n21:17 -----\n                                                                                                                                       \n                      Jos De_Roo                                                                                                       \n                                               To:       timbl@w3.org@internet, connolly@w3.org@internet                               \n                      13/02/2004 22:03         cc:       www-archive@w3.org                                                            \n                                               Subject:  string: cases                                                                 \n                                                                                                                                       \n\n\n\ni have test cases here where string:notEndsWith and\nstring:notContainsIgnoringCase seems to be needed...\n\nwhat I could do is put them in a\nhttp://eulersharp.sourceforge.net/2004/01swap/string#\nbut then have no chance to run those in cwm...\n(that's the trouble with builtins and completeness...)\n\nany hint ?\n\nthanks :)\n\n--\nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n\n"
        },
        {
            "subject": "Example of how to look for things NOT having propertie",
            "content": "Running cwm http://www.w3.org/2000/10/swap/test/EricNeumann/exdata.n3\nhttp://www.w3.org/2000/10/swap/test/EricNeumann/exquery.n3 --think\n\nwe indeed nicely get\n\n    <http://www.w3.org/2000/10/swap/test/EricNeumann/exdata.n3#ATP1B4_e2>\na :Exon,\n                :RESULT;\n         :startsAt \"23902084\";\n         :stopsAt \"23902334\" .\n\n    <http://www.w3.org/2000/10/swap/test/EricNeumann/exdata.n3#ATP1B4_e3>\na :Exon,\n                :RESULT;\n         :startsAt \"23902084\";\n         :stopsAt \"23902346\" .\n\n\n\nTrying that with euler we load\n\nhttp://www.w3.org/2000/10/swap/test/EricNeumann/exdata.n3\nhttp://www.w3.org/2000/10/swap/test/EricNeumann/exquery.n3\n\nand ask\n\n_:e a RESULT.\n\nbut we have trouble with the bindings of the variables in\nhttp://www.w3.org/2000/10/swap/test/EricNeumann/exquery.n3\n(backtracking across engines is not trivial...)\n\nhmm... after some code changes (made in the train from Brussels\nto Cannes and not yet released) we now also get the results\n\n\n<http://www.w3.org/2000/10/swap/test/EricNeumann/exdata.n3#ATP1B4_e3> a\nRESULT.\n\n<http://www.w3.org/2000/10/swap/test/EricNeumann/exdata.n3#ATP1B4_e2> a\nRESULT.\n\n\nThis is actually a very interesting test case :)\n\n--\nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n\n"
        },
        {
            "subject": "David Duke is a malignant narcissist",
            "content": "David Duke is a malignant narcissist.\n\nHe invents and then projects a false, fictitious, self for the world to \nfear, or to admire. He maintains a tenuous grasp on reality to start with \nand the trappings of power further exacerbate this. Real life authority and \nDavid Duke?s predilection to surround him with obsequious sycophants support \nDavid Duke?s grandiose self-delusions and fantasies of omnipotence and \nomniscience.\nDavid Duke's personality is so precariously balanced that he cannot tolerate \neven a hint of criticism and disagreement. Most narcissists are paranoid and \nsuffer from ideas of reference (the delusion that they are being mocked or \ndiscussed when they are not). Thus, narcissists often regard themselves as \n\"victims of persecution\".\nDuke fosters and encourages a personality cult with all the hallmarks of an \ninstitutional religion: priesthood, rites, rituals, temples, worship, \ncatechism, and mythology. The leader is this religion's ascetic saint. He \nmonastically denies himself earthly pleasures (or so he claims) in order to \nbe able to dedicate himself fully to his calling.\nDuke is a monstrously inverted Jesus, sacrificing his life and denying \nhimself so that his people - or humanity at large - should benefit. By \nsurpassing and suppressing his humanity, Duke became a distorted version of \nNietzsche's \"superman\".\nBut being a-human or super-human also means being a-sexual and a-moral.\nIn this restricted sense, narcissistic leaders are post-modernist and moral \nrelativists. They project to the masses an androgynous figure and enhance it \nby engendering the adoration of nudity and all things \"natural\" - or by \nstrongly repressing these feelings. But what they refer to, as \"nature\" is \nnot natural at all.\nDuke invariably proffers an aesthetic of decadence and evil carefully \norchestrated and artificial - though it is not perceived this way by him or \nby his followers. Narcissistic leadership is about reproduced copies, not \nabout originals. It is about the manipulation of symbols - not about \nveritable atavism or true conservatism.\nIn short: narcissistic leadership is about theatre, not about life. To enjoy \nthe spectacle (and be subsumed by it), the leader demands the suspension of \njudgment, depersonalization, and de-realization. Catharsis is tantamount, in \nthis narcissistic dramaturgy, to self-annulment.\nNarcissism is nihilistic not only operationally, or ideologically. Its very \nlanguage and narratives are nihilistic. Narcissism is conspicuous nihilism - \nand the cult's leader serves as a role model, annihilating the Man, only to \nre-appear as a pre-ordained and irresistible force of nature.\nNarcissistic leadership often poses as a rebellion against the \"old ways\" - \nagainst the hegemonic culture, the upper classes, the established religions, \nthe superpowers, the corrupt order. Narcissistic movements are puerile, a \nreaction to narcissistic injuries inflicted upon David Duke like (and rather \npsychopathic) toddler nation-state, or group, or upon the leader.\nMinorities or \"others\" - often arbitrarily selected - constitute a perfect, \neasily identifiable, embodiment of all that is \"wrong\". They are accused of \nbeing old, they are eerily disembodied, they are cosmopolitan, they are part \nof the establishment, they are \"decadent\", they are hated on religious and \nsocio-economic grounds, or because of their race, sexual orientation, origin \n... They are different, they are narcissistic (feel and act as morally \nsuperior), they are everywhere, they are defenseless, they are credulous, \nthey are adaptable (and thus can be co-opted to collaborate in their own \ndestruction). They are the perfect hate figure. Narcissists thrive on hatred \nand pathological envy.\nThis is precisely the source of the fascination with Hitler, diagnosed by \nErich Fromm - together with Stalin - as a malignant narcissist. He was an \ninverted human. His unconscious was his conscious. He acted out our most \nrepressed drives, fantasies, and wishes. He provides us with a glimpse of \nthe horrors that lie beneath the veneer, the barbarians at our personal \ngates, and what it was like before we invented civilization. Hitler forced \nus all through a time warp and many did not emerge. He was not the devil. He \nwas one of us. He was what Arendt aptly called the banality of evil. Just an \nordinary, mentally disturbed, failure, a member of a mentally disturbed and \nfailing nation, who lived through disturbed and failing times. He was the \nperfect mirror, a channel, a voice, and the very depth of our souls.\nDuke prefers the sparkle and glamour of well-orchestrated illusions to the \ntedium and method of real accomplishments. His reign is all smoke and \nmirrors, devoid of substances, consisting of mere appearances and mass \ndelusions. In the aftermath of his regime - Duke having died, been deposed, \nor voted out of office - it all unravels. The tireless and constant \nprestidigitation ceases and the entire edifice crumbles. What looked like an \neconomic miracle turns out to have been a fraud-laced bubble. Loosely held \nempires disintegrate. Laboriously assembled business conglomerates go to \npieces. \"Earth shattering\" and \"revolutionary\" scientific discoveries and \ntheories are discredited. Social experiments end in mayhem.\nIt is important to understand that the use of violence must be ego-syntonic. \nIt must accord with the self-image of David Duke. It must abet and sustain \nhis grandiose fantasies and feed his sense of entitlement. It must conform \nDavid Duke like narrative. Thus, David Duke who regards himself as the \nbenefactor of the poor, a member of the common folk, the representative of \nthe disenfranchised, the champion of the dispossessed against the corrupt \nelite - is highly unlikely to use violence at first. The pacific mask \ncrumbles when David Duke has become convinced that the very people he \npurported to speak for, his constituency, his grassroots fans, and the prime \nsources of his narcissistic supply - have turned against him. At first, in a \ndesperate effort to maintain the fiction underlying his chaotic personality, \nDavid Duke strives to explain away the sudden reversal of sentiment. \"The \npeople are being duped by (the media, big industry, the military, the elite, \netc.)\", \"they don't really know what they are doing\", \"following a rude \nawakening, they will revert to form\", etc. When these flimsy attempts to \npatch a tattered personal mythology fail, David Duke becomes injured. \nNarcissistic injury inevitably leads to narcissistic rage and to a \nterrifying display of unbridled aggression. The pent-up frustration and hurt \ntranslate into devaluation. That which was previously idealized - is now \ndiscarded with contempt and hatred. This primitive defense mechanism is \ncalled \"splitting\". To David Duke, things and people are either entirely bad \n(evil) or entirely good. He projects onto others his own shortcomings and \nnegative emotions, thus becoming a totally good object. Duke is likely to \njustify the butchering of his own people by claiming that they intended to \nkill him, undo the revolution, devastate the economy, or the country, etc. \nThe \"small people\", the \"rank and file\", and the \"loyal soldiers\" of David \nDuke - his flock, his nation, and his employees - they pay the price. The \ndisillusionment and disenchantment are agonizing. The process of \nreconstruction, of rising from the ashes, of overcoming the trauma of having \nbeen deceived, exploited and manipulated - is drawn-out. It is difficult to \ntrust again, to have faith, to love, to be led, to collaborate. Feelings of \nshame and guilt engulf the erstwhile followers of David Duke. This is his \nsole legacy: a massive post-traumatic stress disorder.\n\n_________________________________________________________________\nStore more e-mails with MSN Hotmail Extra Storage ? 4 plans to choose from! \nhttp://click.atdmt.com/AVE/go/onm00200362ave/direct/01/\n\n\n\n"
        },
        {
            "subject": "Working with list",
            "content": "I notice (from the change log) that CWM's collection (list) handling has \nchanged, and that it seems to be difficult to perform some \"simple\" \ninferences over lists.\n\nBelow is some test code that I assumed would do some simple inferences on \nlists of values, but which doesn't do any of what I'd expect.\n\nI wonder if I'm missing something here?  Am I the only person who's trying \nto use RDF collections (lists) in this way?\n\n#g\n--\n\n[[\n# Cwm-list-test.n3\n#\n# Command line used:\n#   C:\\Dev\\W3C\\Swap1144\\cwm.py --n3=tl --think Cwm-list-test.n3\n\n@prefix rdf:  <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix rdft: <http://id.ninebynine.org/2003/rdfext/rdft#> .\n@prefix wd:   <http://id.ninebynine.org/wip/2003/wlanDevices/> .\n@prefix wp:   <http://id.ninebynine.org/wip/2003/wlanPolicy/> .\n@prefix wc:   <http://id.ninebynine.org/wip/2003/wlanConnection/> .\n@prefix :     <#> .\n\nwp:WlanPolicy a wp:ConnectionPolicy ;\n     wp:allowedConnections\n       ( [ wc:devid \"1\" ; wc:devid \"9\" ]\n         [ wc:devid \"2\" ; wc:devid \"8\" ]\n         [ wc:devid \"2\" ; wc:devid \"9\" ]\n       ) .\n\n:foo :bar ( \"1\" \"2\" \"3\" ) .\n\n\n# Simple rule to annotate a list link element\n\n   { ?r rdf:first ?h . }\n=>\n   { ?r a :List } .\n\n\n# Auxiliary rules to flatten members of a collection\n\n   { ?r rdf:first ?h ;\n        rdf:rest  ?t . }\n=>\n   { ?r rdft:includes ?h ;\n        rdft:more     ?t . } .\n\n   { ?r rdft:more ?m .\n     ?m rdf:first ?h ;\n        rdf:rest  ?t . }\n=>\n   { ?r rdft:includes ?h ;\n        rdft:more     ?t . } .\n]]\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "equalTo for strings (plain literals)",
            "content": "Is there a string:equalTo property for comparing plain literals?  I don't \nsee it at http://www.w3.org/2000/10/swap/doc/CwmBuiltins.\n\nOr is log:equalTo intended to serve this purpose?  (It does seem to work -- \nmaybe a documentation fix?)\n\n#g\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "Negation, local closed world, log:Falsehood",
            "content": "I've been reading the paper by Heflin/Munoz-Avila [1] on using local closed \nworld declarations (LCW) with semantic web reasoners, and thinking about \nhow the ideas might apply to Notation3 and cwm.\n\nI'm (again) looking at processing network access-related descriptions, and \nwish to deduce that a particular connection is not allowed if it is not \nexplicitly permitted.  This presumes that a given list of permitted \nconnections is complete.\n\nOriginally, I thought to use the \"closed\" property of a collection (list), \nbut then realized that when the list contains compound values, expressed like:\n   [ prop val ; prop val ]\nin N3, the list closure potentially breaks down because there may be other \nstatements that have the list-member resource as a subject.\n\nRoughly, the LCW approach asserts that some locally scoped information is \ncomplete, and that absence of some information is sufficient to deduce its \nfalsehood.  Examples given are based on DAML+OIL and SHOE, noting that DAML \n(also OWL) can express these ideas but to do so is somewhat cumbersome.\n\nI went rummaging at:\n   http://www.w3.org/2000/10/swap/doc/CwmBuiltins\nthinking that there was something there about log:Falsehood and/or \nnegation, which might be a way of latching onto the LCW ideas, but am \nfinding nothing there.\n\nAre there any common techniques for dealing with closed information in CWM?\n\nSpecifically, in the example below, I can deduce that :conn1 is a \nwc:AllowedConnection, but I wish to deduce that :conn2 is a \nwc:DisallowedConnection.\n\nIdeas?\n\n(My current thoughts are along the lines thus:\n\n    { <pattern1> .\n      { <pattern2> } a log:LCW_Falsehood .\n    }\n  =>\n    { <conclusion using variables from <pattern1>> }\n\nWhere there is a presumption that the formula declared to be an \nLCW_Falsehood contains complete information in relation to nodes bound by \n<pattern1>.)\n\n#g\n--\n\n[1] LCW-Based Agent Planning for the Semantic Web\n     Jeff Heflin and Hector Mu?oz-Avila\n     http://www.cse.lehigh.edu/~heflin/pubs/lcw-aaai02.pdf\n\n...\n\nExample data:\n[[\n# 20040308-wlan-connection.n3\n#\n# Meeting 20040308\n#\n# Data for WLAN connections example discussed in meeting\n#\n# -----\n\n# Declare namespace prefixes\n#\n@prefix rdf:  <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix rdft: <http://id.ninebynine.org/2003/rdfext/rdft#> .\n@prefix wd:   <http://id.ninebynine.org/wip/2003/wlanDevices/> .\n@prefix wp:   <http://id.ninebynine.org/wip/2003/wlanPolicy/> .\n@prefix wc:   <http://id.ninebynine.org/wip/2003/wlanConnection/> .\n@prefix log:  <http://www.w3.org/2000/10/swap/log#> .   # CWM built-in\n@prefix :     <#> .\n\n\n# Declare data about wlan-connected devices\n\nwd:BossComputer a wd:Device ;\n     rdfs:label \"Boss computer\" ;    # Brief description\n     wd:devid  \"1\" ;                 # Asset schedule identifier\n     wd:wlanif [ wd:macadrs \"00:00:00:00:00:11\" ] ;\n     rdfs:comment\n         \"\"\"\n         This resource is a laptop computer belonging to\n         \"big boss\", who is not technically literate but\n         may have sensitive data on his/her computer.\n         \"\"\" .\n\nwd:AdminComputer a wd:Device ;\n     rdfs:label \"Admin computer\" ;   # Brief description\n     wd:devid  \"2\" ;                 # Asset schedule identifier\n     wd:wlanif [ wd:macadrs \"00:00:00:00:00:22\" ] ;\n     rdfs:comment\n         \"\"\"\n         This resource is a laptop computer belonging to\n         a system administrator, who is assumed to know how to\n         protect it from casual attack.\n         \"\"\" .\n\nwd:SerfComputer a wd:Device ;\n     rdfs:label \"Serf computer\" ;    # Brief description\n     wd:devid  \"3\" ;                 # Asset schedule identifier\n     wd:wlanif [ wd:macadrs \"00:00:00:00:00:33\" ] ;\n     rdfs:comment\n         \"\"\"\n         This resource is a laptop computer belonging to\n         a company slave, who is regarded as an active risk\n         to the company's network.\n         \"\"\" .\n\nwd:PublicAccess a wd:Device ;\n     rdfs:label \"Public AP\" ;        # Brief description\n     wd:devid  \"8\" ;                 # Asset schedule identifier\n     wd:wlanif [ wd:macadrs \"00:00:00:00:00:88\" ] ;\n     rdfs:comment\n         \"\"\"\n         This resource is a wireless access point connected\n         to the public facing side of a company's network.\n         \"\"\" .\n\nwd:PrivateAccess a wd:Device ;\n     rdfs:label \"Private AP\" ;       # Brief description\n     wd:devid  \"9\" ;                 # Asset schedule identifier\n     wd:wlanif [ wd:macadrs \"00:00:00:00:00:99\" ] ;\n     rdfs:comment\n         \"\"\"\n         This resource is a wireless access point connected\n         to the internal part of a company's network.\n         \"\"\" .\n\n\n# Declare data about company access policy.\n# Any connection not explicitly allowed is forbidden.\n\nwp:WlanPolicy a wp:ConnectionPolicy ;\n     wp:allowedConnection\n         [ wd:devid \"1\" , \"9\" ],\n         [ wd:devid \"2\" , \"8\" ],\n         [ wd:devid \"2\" , \"9\" ] ;\n     rdfs:comment\n         \"\"\"\n         Boss can connect to private network.\n         Admin can connect to private and public networks.\n         Serf can connect to none.\n         \"\"\" .\n\n# Describe some potential connections\n\n:conn1 a wc:Connection ;\n     wd:macadrs \"00:00:00:00:00:11\" ;\n     wd:macadrs \"00:00:00:00:00:99\" ;\n     rdfs:comment\n         \"\"\"\n         Boss connects to private network.  OK.\n         \"\"\" .\n\n:conn2 a wc:Connection ;\n     wd:macadrs \"00:00:00:00:00:11\" ;\n     wd:macadrs \"00:00:00:00:00:88\" ;\n     rdfs:comment\n         \"\"\"\n         Boss connects to public network.  not OK.\n         \"\"\" .\n\n\n# Describe inference rules to define acceptability of a connection.\n\n# 1. Deduce device connections from MAC address connections\n\n   { ?c  a wc:Connection ;\n         wd:macadrs ?ma1, ?ma2 .\n     ?d1 a wd:Device ;\n         wd:devid  ?di1 ;\n         wd:wlanif [ wd:macadrs ?ma1 ] .\n     ?d2 a wd:Device ;\n         wd:devid  ?di2 ;\n         wd:wlanif [ wd:macadrs ?ma2 ] . }\n=>\n   { ?c  wd:devid ?di1 , ?di2 . } .\n\n\n# 2. Rule to define that connection is OK.\n\n   { ?c  a wc:Connection ;\n         wd:devid ?di1 , ?di2 .\n     ?cp a wp:ConnectionPolicy ;\n         wp:allowedConnection\n           [ wd:devid ?di1, ?di2 ] .\n     ?di1 log:notEqualTo ?di2 .\n   }\n=>\n   { ?c  a wc:AllowedConnection . } .\n]]\n\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "Re: Negation, local closed world, log:Falsehood",
            "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n"
        },
        {
            "subject": "Re: Swish GraphDiff: nifty",
            "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n"
        },
        {
            "subject": "Fwd: Working with list",
            "content": "Note: forwarded message attached.\n\n\n__________________________________\nDo you Yahoo!?\nYahoo! Mail - More reliable, more storage, less spam\nhttp://mail.yahoo.com\n\nattached mail follows:\n\nI notice (from the change log) that CWM's collection (list) handling has \nchanged, and that it seems to be difficult to perform some \"simple\" \ninferences over lists.\n\nBelow is some test code that I assumed would do some simple inferences on \nlists of values, but which doesn't do any of what I'd expect.\n\nI wonder if I'm missing something here?  Am I the only person who's trying \nto use RDF collections (lists) in this way?\n\n#g\n--\n\n[[\n# Cwm-list-test.n3\n#\n# Command line used:\n#   C:\\Dev\\W3C\\Swap1144\\cwm.py --n3=tl --think Cwm-list-test.n3\n\n@prefix rdf:  <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix rdft: <http://id.ninebynine.org/2003/rdfext/rdft#> .\n@prefix wd:   <http://id.ninebynine.org/wip/2003/wlanDevices/> .\n@prefix wp:   <http://id.ninebynine.org/wip/2003/wlanPolicy/> .\n@prefix wc:   <http://id.ninebynine.org/wip/2003/wlanConnection/> .\n@prefix :     <#> .\n\nwp:WlanPolicy a wp:ConnectionPolicy ;\n     wp:allowedConnections\n       ( [ wc:devid \"1\" ; wc:devid \"9\" ]\n         [ wc:devid \"2\" ; wc:devid \"8\" ]\n         [ wc:devid \"2\" ; wc:devid \"9\" ]\n       ) .\n\n:foo :bar ( \"1\" \"2\" \"3\" ) .\n\n\n# Simple rule to annotate a list link element\n\n   { ?r rdf:first ?h . }\n=>\n   { ?r a :List } .\n\n\n# Auxiliary rules to flatten members of a collection\n\n   { ?r rdf:first ?h ;\n        rdf:rest  ?t . }\n=>\n   { ?r rdft:includes ?h ;\n        rdft:more     ?t . } .\n\n   { ?r rdft:more ?m .\n     ?m rdf:first ?h ;\n        rdf:rest  ?t . }\n=>\n   { ?r rdft:includes ?h ;\n        rdft:more     ?t . } .\n]]\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "list processin",
            "content": "Oeps, something went wrong, the text again:\nHallo,\nHere is how I plan to implement lists in RDFEngine\n(http://cvs.sourceforge.net/viewcvs.py/eulersharp/2004/02swap/RDFEngine):\nFor a triple like:\n1) :a rdf:List (:c :d :e).\nI create an object resource that contains a (Python)\nlist: [:c, :d, :e]. \nThis I have implemented. What I did not implement is  \nthen statements like:\na rdf:type rdf:List.\nwhat, as a query, must give a positive response given \nthe triple 1.\nAlso :a rdf:first ?x. should give as response:\n:a rdf:first :c.\nAlso :a rdf:rest ?r. should give as a response:\n:a rdf:rest (:d :e). ??? I'm not sure about that. \nTo be frankly I think the way lists are defined at the\nmoment is a bit problematic.  \nPersonally I would also like to see something like:\n:x :indexOf :a; :value \"2\".\nwhat should return the second element of the list :a.\nGuido.\n\n--- Graham Klyne <gk@ninebynine.org> wrote:\n> \n> I notice (from the change log) that CWM's collection\n> (list) handling has \n> changed, and that it seems to be difficult to\n> perform some \"simple\" \n> inferences over lists.\n> \n> Below is some test code that I assumed would do some\n> simple inferences on \n> lists of values, but which doesn't do any of what\n> I'd expect.\n> \n> I wonder if I'm missing something here?  Am I the\n> only person who's trying \n> to use RDF collections (lists) in this way?\n> \n> #g\n> --\n> \n> [[\n> # Cwm-list-test.n3\n> #\n> # Command line used:\n> #   C:\\Dev\\W3C\\Swap1144\\cwm.py --n3=tl --think\n> Cwm-list-test.n3\n> \n> @prefix rdf: \n> <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n> @prefix rdfs:\n> <http://www.w3.org/2000/01/rdf-schema#> .\n> @prefix rdft:\n> <http://id.ninebynine.org/2003/rdfext/rdft#> .\n> @prefix wd:  \n> <http://id.ninebynine.org/wip/2003/wlanDevices/> .\n> @prefix wp:  \n> <http://id.ninebynine.org/wip/2003/wlanPolicy/> .\n> @prefix wc:  \n> <http://id.ninebynine.org/wip/2003/wlanConnection/>\n> .\n> @prefix :     <#> .\n> \n> wp:WlanPolicy a wp:ConnectionPolicy ;\n>      wp:allowedConnections\n>        ( [ wc:devid \"1\" ; wc:devid \"9\" ]\n>          [ wc:devid \"2\" ; wc:devid \"8\" ]\n>          [ wc:devid \"2\" ; wc:devid \"9\" ]\n>        ) .\n> \n> :foo :bar ( \"1\" \"2\" \"3\" ) .\n> \n> \n> # Simple rule to annotate a list link element\n> \n>    { ?r rdf:first ?h . }\n> =>\n>    { ?r a :List } .\n> \n> \n> # Auxiliary rules to flatten members of a collection\n> \n>    { ?r rdf:first ?h ;\n>         rdf:rest  ?t . }\n> =>\n>    { ?r rdft:includes ?h ;\n>         rdft:more     ?t . } .\n> \n>    { ?r rdft:more ?m .\n>      ?m rdf:first ?h ;\n>         rdf:rest  ?t . }\n> =>\n>    { ?r rdft:includes ?h ;\n>         rdft:more     ?t . } .\n> ]]\n> \n> \n> ------------\n> Graham Klyne\n> For email:\n> http://www.ninebynine.org/#Contact\n> \n\n \n\n\n__________________________________\nDo you Yahoo!?\nYahoo! Mail - More reliable, more storage, less spam\nhttp://mail.yahoo.com\n\n\n\n"
        },
        {
            "subject": "general info",
            "content": "Could you please give me a link (or linklist) where to start on cwm ?\nI find it very interesting, but I think I?m missing still some basics ...\n\nPeter\n\n-------------------------------------------------------\nkeep life as simple as you can.\nspam@netlane.de\nhttp://www.netlane.de\n-------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: general info",
            "content": "At 23:28 18/03/04 +0100, P. Haunert wrote:\n>Could you please give me a link (or linklist) where to start on cwm ?\n>I find it very interesting, but I think I?m missing still some basics ...\n\nSome combination of:\n\nhttp://www.w3.org/2000/10/swap/doc/cwm.html\nhttp://www.w3.org/2000/10/swap/Primer.html\nhttp://www.w3.org/2000/10/swap/\nhttp://infomesh.net/2001/cwm/\n\nshould help to get you going.\n\n#g\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "swap/cwm source layout vs. python distutils norm",
            "content": "I've been trying to do the python distutils thing with cwm.\nMy first try was in LHR, with no net access, so I could\nonly monkey-see-monkey-do based on other setup.py things\nI had on my laptop.\n\nI think I want modules like llyn.py and such to install\nin site-packages/swap/llyn.py , but I couldn't figure\nout how do do that without installing all the .py\nfiles from the swap/ directory. There are quite\na few that are irrelevant to cwm. Plus, I think\nwe'd have to change all the\nimport llyn\nlines to\nimport swap.llyn\n\nSo I didn't check in any setup.py code.\n\nTonight I just read the distutils docs...\n\n  Distributing Python Modules\n  http://www.python.org/doc/current/dist/dist.html\n\nSupport for PyPI looks cool; just one command will make\ncwm part of the pythong package index.\n  http://www.python.org/pypi\n\nBut I still don't see any way around re-organizing\nthe sources or at least rewriting the import lines.\n\nHmm.\n\nFor reference: existing notes on cwm sources:\n  http://www.w3.org/2000/10/swap/doc/cwm.html#dev\n\n(why the .html in this case? hmm...)\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "owl inconsistencie",
            "content": "Hallo,\nWhen inferencing there are three moments at which\ninconsistencies can be detected:\n1) before inferencing\n2) during inferencing\n3) after inferencing.\nBefore inferencing we have a set of formulae.\nTake the triples:\n(1)\n:x owl:oneOf (:a :b :c).\n:d a :x.\nThis is a clear inconsistency and should be detected\nof course. \nHowever:\n(2)\n:c a owl:restriction; owl:onProperty :p;\nowl:minCardinality \"3\"^^xsd:integer.\nHowever before inferencing no member of the class\nexists. But members of the class might be discovered\nduring inferencing.\nConsider the situation after inferencing:\nthere is a set of formulae, a set of substitutions to\nthe query and a proof of the result. Applying the\nsusbtitutions to the set of formulae together with the\nproof gives a new set of formulae (the proof is a\nformula too). The found solution is valid when this\nnew set of formulae is a consistent set; the solution\nis not valid when this set is not consistent. \nThus it follows that the detection of inconsistencies\nneeds only to be done after inferencing, thereby\neliminating invalid answers. \nOf course, inconsistencies like (1) could be detected\nbefore or during inferencing (but need not to) in\norder to enhance the efficiency of the inference\nprocess. \nConclusion: inconsistencies that are irreparable(i.e.\nthey cannot go away by the inferencing process) should\nbe detected as soon as possible; inconsistencies that\ncan change should only be detected after the\ninferencing process: these include certainly\nrestrictions with: owl:someValuesFrom;\nowl:cardinality; owl:minCardinality;\nowl:maxCardinality. \nChecking consistencies at the end of inferencing\nshould even allow to introduce \"assert\" and \"retract\"\nprimitives i.e. adding or deleting triples from the\nformulae during inferencing.In that case, however, all\ninconsistency handling needs to be done after\ninferencing.\n\n\n\n__________________________________\nDo you Yahoo!?\nYahoo! Finance Tax Center - File online. File on time.\nhttp://taxes.yahoo.com/filing.html\n\n\n\n"
        },
        {
            "subject": "Re: owl inconsistencie",
            "content": "[...]\n\n> Take the triples:\n> (1)\n> :x owl:oneOf (:a :b :c).\n> :d a :x.\n> This is a clear inconsistency and should be detected\n> of course.\n\nthere is no \"unique names assumption\",\nand it could be the case that\n:d owl:sameAs :b.\n\na premise that we actually consider inconsistent is\n?C owl:oneOf ?L. ?X a ?C. ?L :notItem ?X.\n\nwith\nrdf:nil :notItem ?X.\n{?S rdf:first ?A. ?A owl:differentFrom ?X. ?S rdf:rest ?B. ?B :notItem ?X}\n=> {?S :notItem ?X}.\n\n--\nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n\n"
        },
        {
            "subject": "on cwm and rdflib API",
            "content": "notes from a chat with eikon...\n\non cwm and rdflib APIs\nposted by DanC at 2004-03-30 00:55 (+)\nhttp://rdfig.xmlhack.com/2004/03/30/2004-03-30.html#1080608148.345108\n\n        DanC:  discussion starting 23:37\n        DanC: I took toIcal.py, a cwm API client, and ported it to the\n        rdflib API\n        DanC: the result was roughtly 2x faster in 2 cases. (1 second\n        versus 2)\n        danbri_dna: Nearby: the resulting code\n        DanC: cwm should change 'pred' to 'predicate'. and the() should\n        raise ValueError, not call assert()\n        DanC: rdflib should learn about each/any/the. cwm should change\n        statementsMatching() to triples()\n        DanC: and rdflib should support RDF.type as well as (in stead\n        of?) RDF.[\"type\"]\n        eikeon: RDF.type already added to rdflib-2.0.2 to be release\n        this evening\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "papertrail bank works no",
            "content": "One of the first things I tried to do with cwm/n3 was\nmodel a checking account in the paper trail style.\n http://www.w3.org/DesignIssues/PaperTrail.html\n\nI was stuck on list handling bugs for the longest time,\nbut I just checked today, and it's working:\n\n# USAGE:\n#  python ../cwm.py checking.n3 bankSW.n3 --think --data >,statement.n3\n\nhttp://www.w3.org/2000/10/swap/ppt-bank/checking.n3\n\nit correctly reads the statement and the checks and computes\nthe new bank account balance.\n\nI added a link to ppt-bank from PaperTrail.html, tim.\n\n(and I added a link to the web services workshop and changed\nthe page to XHTML and utf-8).\n\nI wonder how many of the design issues notes now have running\ncode behind them. I don't think I've added the links in as\nmany cases as I should have.\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\nsee you at the WWW2004 in NY 17-22 May?\n\n\n\n"
        },
        {
            "subject": "new lis",
            "content": "public-esw-news:\nA mailing list for monthly news about the SWAD Europe project.\n\n-- \nDaigo Matsubara / W3C Systems Team / mailto:daigo@w3.org\n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "SWADEurope newsletter, March 200",
            "content": "SWAD-Europe Newsletter, March 2004\n\nWelcome to the third SWAD-Europe newsletter.\n\nSWAD-Europe (Semantic Web Advanced Development in Europe) is an\nEU-funded project which aims to support W3C's Semantic Web initiative\nin Europe, providing targeted research, demonstrations and outreach to\nensure Semantic Web technologies move into the mainstream of networked\ncomputing.\nhttp://www.w3.org/2001/sw/Europe/\n\nThis newsletter is a monthly summary of work from the project and\nselected Frequently Asked Questions and answers, written by a variety of\nproject participants.\n\nIn this issue:\n\nNews\n1. Semantic Blogging update\n2. Announcing SKOS-Core 1.0 RDF Schema for Thesauri\n3. MathML Use Case\n\nFAQs\n4. How do I parse RDF?\n5. Using RDFS or OWL as a schema language for validating RDF\n\nMore detailed discussions on these topics are available on the project\nweblog:\nhttp://esw.w3.org/mt/esw/archives/2004_03.html\nhttp://esw.w3.org/mt/esw/\n\n\nNews\n\n1. Semantic Blogging update\n\nIt's been an interesting month for semantic blogging. I'm in the midst\nof writing papers and articles, some external, some internal. We're\nalso trying to deploy semantic blogging internally, a true 'eat your\nown dogfood' approach. I'm hoping to demonstrate an early prototype at\nXMLEurope 2004 in Amsterdam. If you can't make it, then the paper is\navailable from my site. --Steve Cayzer\n\nSteve's site:\nhttp://jena.hpl.hp.com:3030/blojsom-hp/blog/news/swade/?permalink=57D7C0D36251821004C68A891D2904BF.textile&smm=y\n\nSWAD-Europe workpackage 12.1 - Open Demonstrators:\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-12.1.html\n\nSWAD-Europe  Deliverable 12.1.2: Semantic Blogging and Bibliographies -\nRequirements Specification\nhttp://www.w3.org/2001/sw/Europe/reports/requirements-demo-1/hp-requirements-specification.html\n\n\n2. Announcing SKOS-Core 1.0 RDF Schema for Thesauri\n\nSKOS stands for Simple Knowledge Organisation System. The Goal of\nSKOS-Core is to provide a framework for bringing existing knowledge\norganisation systems such as thesauri and the semantic web together.\n\nSKOS-Core exploits the features of RDFS and OWL to provide a flexible\nand extensible framework within which different types of KOS can\ninteroperate. SKOS-Core is ideal for modelling thesauri, and can cope\nwith the variations commonly found in thesaurus design and structure.\n--Alistair Miles\n\nRead more:\n\nSKOS-Core 1.0 schema:\nhttp://www.w3.org/2004/02/skos/core\n\nSKOS-Core 1.0 Guide accompanying the schema:\nhttp://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n\nThe website for the SWAD-Europe Thesaurus Activity has moved to\nhttp://www.w3.org/2001/sw/Europe/reports/thes/\n\nSWAD-Europe workpackage 8 - Thesaurus Research Prototype:\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-8.html\n\n\n3. MathML Use Case\n\nFor the RDF, Web Ontology, Logic and Mathematics part of SWAD-Europe\nworkpackage 5, I have written an XSLT transform that evaluates MathML\nequations on \"CompanyReport\" files, as provided by Dan Brickley. The\nstylesheet works on a Content MathML file (e.g. mmlrules.xsl)\ncontaining computation rules, such as rna = opoa*na/100:\n\n  <apply>\n    <eq/>\n    <ci>rna</ci>\n    <apply>\n      <times/>\n      <apply><divide/><ci>opoa</ci><ci>na</ci></apply>\n      <cn>100</cn>\n    </apply>\n  </apply>\n\nThe stylesheet retrieves a file (e.g. reports.xml) containing the values\nof the variables and computes the appropriate results and prints them to\nstandard output: atr = 1.72139269716302 ca = 52798 etc. Currently the\nstylesheet only supports +-/*. While it's easy to add more template to\nsupport more of MathML, it's less easy to actually perform complex\noperations. However using exslt might allow coverage of many ops.\n--Max Froumentin\n\nRead More:\n\nXSLT stylesheet:\nhttp://www.w3.org/2004/03/swadeu-mathml/mml.xsl\n\nContent MathML file\nhttp://www.w3.org/2004/03/swadeu-mathml/mmlrules.mml\n\nSample XML file:\nhttp://www.w3.org/2004/03/swadeu-mathml/reports.xml\n\nWorkpackage 5 description:\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-5.html\n\nDeliverable 5.1: Schema Technology Survey\nhttp://www.w3.org/2001/sw/Europe/reports/xml_schema_tools_techniques_report/\n\nDeliverable 5.2 Extracting Semantics from XML Structure\nhttp://www.w3.org/2001/sw/Europe/reports/xslt_schematron_tool/\n\nDeliverable 5.3 RDF/XML Test cases for RDF Logic, Web Ontology and Maths\ncontent\nhttp://www.w3.org/2001/sw/Europe/reports/xml_test_cases/\n\n\n\nFAQs\n\n4. How do I parse RDF?\n\nApplication developers often ask how they can get RDF data from\nthe semantic web into their application from the recommended syntax\nRDF/XML. This usually ends up being a question about parsing syntaxes\nand APIs in certain languages. There are widely available, mature and\nstandards-compliant open source parsing libraries available for most\nhigh level programming libraries that application developers might need.\nThis article provides a summary of good and up-to-date choices.\n--Dave Beckett\n\nRead more:\nhttp://esw.w3.org/mt/esw/archives/000049.html\n\n\n5. Using RDFS or OWL as a schema language for validating RDF\n\nMany software applications need the ability to test that some input data\nis complete and correct enough to be processed, e.g. to check the data\nonce so that access functions will not later on break due to missing\nitems. This is commonly done by using a schema language to define what\n\"complete and correct\" means in this, syntactic, sense and a schema\nprocessor to validate data against the schema.\n\nDevelopers new to RDF can easily mistake RDFS as being a schema language\n(perhaps because the 'S' stands for schema!), they then get referred to\nOWL as providing the solution and then get surprised by the results of\ntrying to use OWL this way.\n\nThis is a big topic which we'll just touch on here. In this FAQ entry I\njust want to illustrate a few of pitfalls and hint at why this is harder\nthan it looks in the hope that it might reduce the \"unpleasant surprise\"\nfor developers new to OWL. --Dave Reynolds\n\nRead more:\nhttp://esw.w3.org/mt/esw/archives/000048.html\n\n\n\nVisit the SWAD-Europe website:\nhttp://www.w3.org/2001/sw/Europe/\nhttp://www.w3.org/2001/sw/Europe/reports/intro.html\n\nand weblog:\nhttp://esw.w3.org/mt/esw/\n\nfor ongoing information about the project.\n\n\n\n"
        },
        {
            "subject": "Development of platform-independent applications - workshop more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n\n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "SWADEurope newsletter, April 200",
            "content": "SWAD-Europe Newsletter, April 2004\n\nWelcome to the fourth SWAD-Europe newsletter.\n\nSWAD-Europe (Semantic Web Advanced Development in Europe) is an\nEU-funded project which aims to support W3C's Semantic Web initiative\nin Europe, providing targeted research, demonstrations and outreach to\nensure Semantic Web technologies move into the mainstream of networked\ncomputing.\nhttp://www.w3.org/2001/sw/Europe/\n\nThis newsletter is a monthly summary of work from the project and\nselected Frequently Asked Questions and answers, written by a variety of\nproject participants.\n\nIn this issue:\n\nNews\n1. SWAD-Europe and the ECOinformatics Initiative\n2. XML Europe 2004\n\nFAQs\n3. How do I validate RDF?\n4. Some thoughts on RDF rendering\n\nMore detailed discussions on these topics are available on the project\nweblog:\nhttp://esw.w3.org/mt/esw/archives/2004_04.html\nhttp://esw.w3.org/mt/esw/\n\n\nNews\n1. SWAD-Europe and the ECOinformatics Initiative\n\nThe United Nations Environment Programme (UNEP) hosted the first\nEnvironmental Thesaurus and Terminology Workshop this week in Geneva.\nThe Workshop is part of the broader ECOinformatics Initiative, which is\nworking to facilitate co-operation between organisations and projects\nworking in the area of enviromental information.\n\nSWAD-Europe was represented at the workshop by myself. I gave a\npresentation on recent developments in the SWAD-Europe Thesaurus\nActivity.\n\nI was very impressed to find that, although this was the first meeting\nof this group, there was a strong coherence in the vision, goals and\nexpertise of its members. Developing web services for accessing\nterminologies and thesauri via the internet was a major theme of the\nworkshop, and received unanimous interest. In this context I presented\nthe SKOS API, a generic application programming interface for a\nthesaurus web service which is being developed as part of the\nSWAD-Europe Thesaurus Activity. The API was well received, and we hope\nto involve members of this community in its further development and\ntesting.\n\n--Alistair Miles\n\nRead more: http://esw.w3.org/mt/esw/archives/000052.html\n\nAlistair's presentation:\nhttp://www.w3.org/2001/sw/Europe/reports/thes/pres/swade_unep_apr_2004.ppt\nSWAD-Europe thesaurus activity: http://www.w3.org/2001/sw/Europe/reports/thes/\n\n\n2. XML Europe 2004 - trip report\n\nLast week I attended XML Europe in sunny Amsterdam at the RAI and made\nnotes in some sessions I attended. So far I've not been able to get on\nwith live blogging, rather I've been doing live talking to people during\nthe conference.\n--Dave Beckett\n\nRead more: http://esw.w3.org/mt/esw/archives/000054.html\n\nSee also:\nXMLEurope 2004 Proceedings: http://www.idealliance.org/papers/dx_xmle04/\nSteve Cayzer's paper:\nhttp://www.idealliance.org/papers/dx_xmle04/index/author/7691905a7307fb7f2731ee67e8.html\nreport on Monday: http://planb.nicecupoftea.org/archives/000536.html\n\n\nFAQs\n\n3. FAQ: How do I validate RDF?\n\nValidation for RDF can mean a variety of different terms especially\nwhere RDF is using XML and several layers of technology are connected.\nThis FAQ describes validation for RDF and answers how to do it for the\ndifferent technologies.\n\nValidation is a tricky word to consider, and often used with schema,\nwhich can also have several different interpretations. There is\nvalidation of syntax (XML validation, RDF/XML - RDF's XML syntax) as\nwell as RDF schema validation.\n\nThat means you can do:\n\n   1. XML validation against an XML schema, also called XML schema\nvalidation\n   2. RDF/XML validation of the syntax that it matches the RDF/XML\nSyntax Specification (Revised) W3C Recommendation\n   3. RDF schema validation\n\n--Dave Beckett\n\nRead more: http://esw.w3.org/mt/esw/archives/000051.html\n\n\n4. Some thoughts on RDF rendering\n\nAs part of the Semantic Portals work we've had to create a browsing\nutility that presents a web based UI for viewing and navigating a set of\nRDF descriptions (of environmental organizations). This blog note\ncaptures a few thoughts on how to go about this based on our experiences\nwith the current prototype.\n\nMany applications have a need to render RDF in human-readable form.\n\nIn some cases the requirement is to present a complete and accurate\nvisualization of the RDF for people familar with the RDF model. There\nare many tools which support this both graphical (e.g. IsaViz,\nvisualizer) and textual (e.g. brownsauce).\n\nIn other cases the need is to present an application specific UI which\ncontains some data extracted from the RDF. In that case some form of\ntemplate-driven rendering approach seems appropriate. There are some\ntools for this (e.g. RDFStyles) as well as general XSLT-for-RDF\nproposals (e.g. treehugger, RDF Template, RDF Twig) which could be used\nfor rendering directly to XHTML.\n\n--Dave Reynolds\n\nRead more: http://esw.w3.org/mt/esw/archives/000053.html\n\n\n\nVisit the SWAD-Europe website:\nhttp://www.w3.org/2001/sw/Europe/\nhttp://www.w3.org/2001/sw/Europe/reports/intro.html\n\nand weblog:\nhttp://esw.w3.org/mt/esw/\n\nfor ongoing information about the project.\n\n\n\n"
        },
        {
            "subject": "SWADEurope newsletter, January 200",
            "content": "SWAD-Europe Newsletter, January 2004\n\nWelcome to the first SWAD-Europe newsletter.\n\nSWAD-Europe (Semantic Web Advanced Development in Europe) is an\nEU-funded project which aims to support W3C's Semantic Web initiative\nin Europe, providing targeted research, demonstrations and outreach to\nensure Semantic Web technologies move into the mainstream of networked\ncomputing.\nhttp://www.w3.org/2001/sw/Europe/\n\nThe newsletter is a monthly summary of work from the project and\nselected Frequently Asked Questions and answers, written by a variety of\nproject participants.\n\nIn this issue:\n\nNews\n1. Semantic Blogging Update\n2. SWAD-Europe visits English Heritage\n3. w3photo annotation work\n4. Semantic Portals Update\n5. Semantic Web Storage and Retrieval workshop report available\n\nFAQs\n6. What can thesauri do for the web?\n7. Why do rdfs:domain and rdfs:range seem to work back-to-front when\nit comes to thinking about the class hierarchy?\n8. Using the NodeID Attribute in RDF\n\nMore detailed discussions on these topics are available on the project\nweblog:\nhttp://esw.w3.org/mt/esw/archives/2004_01.html\nhttp://esw.w3.org/mt/esw/\n\nNews\n\n1. Semantic Blogging Update\n\nThe semantic blogging project is officially finished. Code, javadocs,\nand lessons learned report are all available. However, some promising\nsemblogging activity continues.\n\nFirstly, the code is being downloaded and played with. Whether this will\nlead to other, \"perhaps even unexpected\" uses as I mentioned in the\nlessons learnt report remains to be seen, but I am hopeful.\n\nSecondly, the bibliographic metadata theme seems to have struck a chord\nwith people like Bruce D'Arcus, who are interested and active in the\ncomplex world of bibliographic metadata standards\n\nThirdly, the ideas are being picked up by the research community, UK\nUniversities and even a startup (about which, perhaps, more anon). I\nalso have a couple of evaluation projects ongoing within HP to move\nsemblogging from an interesting prototype to a usable tool.\n\nSemantic Blogging Demonstrator:\nhttp://jena.hpl.hp.com:3030/blojsom-hp/blog\nMore information:\nhttp://jena.hpl.hp.com/~stecay/downloads/blogTalk.pdf\nDownloads:\nhttp://jena.hpl.hp.com:3030/blojsom-devt/download.jsp\n\n\n2. SWAD-Europe visits English Heritage\n\nOn the 29th of January Alistair Miles from CCLRC and Nikki Rogers from\nILRT paid a visit to Edmund Lee and the members of the Data\nStandards Unit at the English Heritage National Monuments Record Centre.\nThe team at English Heritage have a wealth of experience about thesaurus\nconstruction and use. The purpose of the visit was to learn from each\nother, and to explore how their practical needs relate to the work of\nthe SWAD-Europe Thesaurus Activity.\n\nThe visit was a great success, and we were able to break ground on a\nnumber of challenging technical issues. There emerged a clear need from\nthe work of English Heritage for distributed access to and development\nof thesauri, for which at this time there is only a partial and rather\nheavy weight solution. The development of a thesaurus service, providing\naccess to the functionality of a thesaurus via the internet, would be of\nreal benefit. We hope English Heritage will become involved in our\ndevelopment and implementation of such a service, which is a key part of\nthe SWAD-Europe Thesaurus Activity.\n\nThanks to Edmund and the team for a warm welcome.\n\n\n3. w3photo annotation work\n\nAs part of SWAD-Europe's dissemination efforts, and continuing on the\nthe theme of Image annotation from the workshop we held in June 2002, we\nhave been collaborating with a number of other groups on a project to\nannotate photos from the WWW series of conferences. Also involved are\nGreg Elin, who came up with the idea; members of the Mindswap group from\nMaryland, members of the IAM group from Southampton, and others\nincluding Jim Ley, Morten Frederiksen, Masahide Kanzaki and Benjamin\nNowack. There is a mailing list, semantic-photolist@unitboy.com, that\nanyone can join, currently archived at www-archive@w3.org archives), and\nwe have held several IRC meetings on the #rdfig channel on freenode.\n\nSWAD-Europe interests in this area include:\n\n* discussing and improving vocabularies for annotating parts of an\nimage\n* experimenting with using several different vocabularies together, for\nexample an image vocabulary with a geographical one, a vocabulary\ndescribing people, another describing events.\n\nRead more on the wiki:\nhttp://esw.w3.org/mt/esw/archives/000038.html\n\n\n4. Semantic Portals Update\n\nWe've started work building a prototype of our semantic portal\ndemonstrator as outlined in [1]. For the first prototype we've got some\ndata from a older UK directory of environment organizations and are\ndeveloping an appropriate set of ontologies form converting it to RDF.\n\nLike all ontology problems, the task of defining an appropriate ontology\nfor environment organizations just explodes in scale and complexity as\nsoon as you touch it. First we just wanted a broad organizational type\nbut soon found that it would be useful to have a more precise ontology\nfor legal status. A few conversations with a lawyer led to a useable\nsmall ontology for legal status, for the UK at least it's already too\ncomplex to expect many users to want to work with. So we had to go back\nto a simplified \"colloquial\" ontology for organizational type with\nseparate links to a more detailed legal status thesaurus. This approach\nof having a coarse grained ontology which controls the main information\nstructure, with links to more refined thesaurus terms to fill in the\ndetails, seems like a useful design pattern and we hope to repeat it for\nother facets such as organizational activity.\n\nOn the hacking front we are putting together a data entry tool based on\na customization of our semantic blogging demonstrator - on the grounds\nthat blogging should be a good way to capture data. For the viewing side\nwe building an aggregator which can merge various semantic blogs and\nother RDF sources into one repository and provide a faceted browse\ninterface over the repository. We've got an early version of the faceted\nbrowse interface going, inspired by projects like Flamenco [2]. It seems\na very nice way to browse highly structured RDF data sets and might be\nworth packaging up as a separate open source tool.\n\n\n[1] http://www.w3.org/2001/sw/Europe/reports/requirements_demo_2/index.html\n[2] http://bailando.sims.berkeley.edu/flamenco.html\n\n\n5. Semantic Web Storage and Retrieval workshop report available\n\nSWAD-Europe Deliverable 3.11: Report on Semantic Web Storage and\nRetrieval Workshop that was held 13-14 November in Amsterdam hosted\nby the Vrije Universiteit is now available:\n\nhttp://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_4/\n\nThe workshop participants were mostly technical developers and\nresearchers from a variety of organisations mostly in industry and\neducation, from Greece, UK, Slovenija, the Netherlands, Italy and from\nthe United States. Most of the participants had practical experience in\nbuilding and deploying semantic web software and applications. The\ndevelopers of the two main RDF Java APIs were present, along with the\nauthors of significant APIs in perl, C, python and prolog (all of these\nwere primarily created in Europe).\n\nThe two main themes of the workshop were storing semantic web data and\nretrieving it and the agenda was structured to cover different aspects\nof both of those items. Other important topics also emerged such as\nquery languages and network access, both related to retrieval and issues\nwith implementing OWL and RDF Schema.\n\n\nFrequently Asked Questions\n\n6. What can thesauri do for the web?\n\nThesauri can be used to organise information in a sensible way, which in\nturn helps us to find what we are looking for on the web. Richer than a\nsimple taxonomy, but simpler than a full blown ontology, thesauri\nprovide a convenient yet powerful way to achieve knowledge organisation.\nFurthermore, because thesauri have been used for decades by library\nscientists for the same purpose, there exist a number of extremely well\nstructured, well engineered thesauri in the public domain. Providing the\nframework for bringing these systems on to the semantic web is a major\ngoal of the SWAD-Europe Thesaurus Activity.\n\nA thesaurus also includes information about terminology, and how\ndifferent terms may be used to represent different concepts. A thesaurus\nwith rich terminological data can be used to support tasks such as\nautomated classification of documents.\n\nRead more: http://esw.w3.org/mt/esw/archives/000037.html\n\n\n7. Why do rdfs:domain and rdfs:range seem to work back-to-front when\nit comes to thinking about the class hierarchy?\n\nBecause RDFS is a logic-based system. The way rdfs range and domain\ndeclarations work is alien to anyone who thinks of RDFS and OWL as being\na bit like a type system for a programming language, especially an\nobject oriented language.\n\nTo expand on the problem. Suppose we have three classes:\neg:Animal eg:Human eg:Man\n\nAnd suppose they are linked into the simple class hierarchy:\neg:Man rdfs:subClassOf eg:Human .\neg:Human rdfs:subClassOf eg:Animal .\n\nNow suppose we have property eg:personalName with:\neg:personalName rdfs:domain eg:Human .\n\nThe question to ask is this: \"can we deduce:\neg:personalName rdfs:domain eg:Man ?\"\n\nThe answer is \"no\" the correct such deduction is:\neg:personalName rdfs:domain eg:Animal .\n\nThis is completely obvious to anyone who thinks about RDFS as a logic\nsystem, however it can be surprising if you are thinking in terms of\nobjects.\n\nRead more: http://esw.w3.org/mt/esw/archives/000036.html\n\n\n8. Using the NodeID Attribute in RDF\n\nThis article provides an introduction to the rdf:nodeID attribute which\nwas introduced into the revised RDF/XML syntax by the RDFCore working\ngroup. This explanation is intended for RDF and XML developers who have\nsome reasonable familiarity with RDF's XML syntax, and who want to catch\nup with the new features added to RDF by the RDFCore group. It is not\nintended as a general introduction to RDF syntax.\n\n\nRead more: http://esw.w3.org/mt/esw/archives/000034.html\n\n\nVisit the SWAD-Europe website:\nhttp://www.w3.org/2001/sw/Europe/\nhttp://www.w3.org/2001/sw/Europe/reports/intr.html\n\nand weblog:\nhttp://esw.w3.org/mt/esw/\n\nfor ongoing information about the project.\n\n\n\n"
        },
        {
            "subject": "SWADEurope newsletter, February 200",
            "content": "SWAD-Europe Newsletter, February 2004\n\nWelcome to the second SWAD-Europe newsletter.\n\nSWAD-Europe (Semantic Web Advanced Development in Europe) is an\nEU-funded project which aims to support W3C's Semantic Web initiative\nin Europe, providing targeted research, demonstrations and outreach to\nensure Semantic Web technologies move into the mainstream of networked\ncomputing.\nhttp://www.w3.org/2001/sw/Europe/\n\nThis newsletter is a monthly summary of work from the project and\nselected Frequently Asked Questions and answers, written by a variety of\nproject participants.\n\nIn this issue:\n\nNews\n1. W3C Technical Plenary - Semantic Web Interest Group meet\n2. Semportal meets semblog\n3. SWAD-Europe Demonstrates Technology at JISC Terminology Services\nWorkshop\n\nFAQs\n4. How can I make my thesaurus a part of the Semantic Web?\n5. Why not use an RDF graph with blanks for querying RDF?\n\nMore detailed discussions on these topics are available on the project\nweblog:\nhttp://esw.w3.org/mt/esw/archives/2004_01.html\nhttp://esw.w3.org/mt/esw/\n\n\nNews\n\n1. W3C Technical Plenary - Semantic Web Interest Group meet\n\nSeveral members of the SWAD-Europe team were at the W3C All Groups and\nTechnical Plenary meeting near Cannes this week. Many W3C working groups\nare meeting face to face including the new Semantic Web Best Practices\nworking group on Thursday and Friday. The Semantic Web Interest Group\n(SWIG) met for the first two days; this is the renamed and refocussed\nRDF Interest Group, chaired by Dan Brickley, who is also the director\nof SWAD-Europe.\n\nRead more:\n\nA summary of the SWIG meeting (with links to logs and urls) is available\nhere: http://esw.w3.org/mt/esw/archives/000044.html\n\nKendall Clark also wrote about the meeting on xml.com:\nhttp://www.xml.com/pub/a/2004/03/03/deviant.html\n\nSWIG proposed charter:\nhttp://www.w3.org/2003/12/swa/swig-charter\n\nSemantic-Web Best Practices and Deployment (SWBPD) Working Group\nKick-off meeting agenda (with links to logs and decisions):\nhttp://www.w3.org/2004/03/04-SWBPD\n\n\n2. Semportal meets semblog\n\nThis is a brief update on our demonstrator activity on semantic portals.\n\nAs we blogged last month, we have been putting together a portal\ninterface tool that allows us to take a collection of RDF, in our case\ndescriptions of environmental organizations, and render it in a faceted\nbrowser. This is working well and enabled us to demonstrate a prototype\nsuccessfully to Anthony Perret of the environment council at a recent\nmeeting.\n\nThe dimensions to use to drive the browsing are described in the form of\neither RDFS class hiearchies or SKOS thesauri. It proved to be quite\neasy to use Jena's rule processing engine to add rules to propagate the\ntransitive closure of the SKOS term lattice along with basic RDFS\nprocessing and a little OWL support (we needed inverse properties). In\nthe portal description (in RDF of course) you can just specify a set of\ndata sources and ontologies, together with what rule file you want to\nuse for processing. Surprisingly simple rules have been enough to\nimplement the functionality needed for the demo so far.\n\nWe've also been able to connect the two tools together. For an internal\ndemonstration we were able to capture and classify some information\nsnippets in a semblog and view them in the appropriate categories in a\nportal along with some preclassified documents. What makes it really fun\nis that the classification scheme itself, since it's expressed in RDF,\nis just another object you can browse and manipulate. So you can link in\nanother data source, which uses a different classification scheme, and\ncan see that scheme as another dimension available for use in browsing.\n\nRead more:\n\nA personal take on the meeting from Steve Cayzer:\nhttp://jena.hpl.hp.com:3030/blojsom-hp/blog/news/swade/?permalink=CB93C608E80CF1F2A86DD6ADF47B67A0.textile&smm=y\n\nSWAD-E Semantic Portals requirements specification:\nhttp://www.w3.org/2001/sw/Europe/reports/requirements-demo-2/\n\n\n3. SWAD-Europe Demonstrates Technology at JISC Terminology Services\nWorkshop\n\nOn Friday 13th February Libby Miller from ILRT and Alistair Miles\nfrom CCLRC attended the JISC Terminology Services Workshop in London.\nThe workshop was being held to explore all issues surrounding the need\nfor making terminologies (thesauri, taxonomies, classification systems\netc.) available via services on the web to a wider community, and the\npotential role of JISC in that effort. The Thesaurus Activity of the\nSWAD-Europe project is concerned with exactly this problem, and although\nour work on a thesaurus web-service API is still in progress, we've\nalready done some interesting pre-prototype implementations of modular\nservices and applications. This workshop was a chance for us to show off\nour prototypes, and discuss future directions with a well-informed and\nexperienced group of people.\n\nOne very encouraging sign was that 'the semantic web' 'RDF' and 'OWL'\nare no longer dirty words, but are more and more being considered as\nviable and realistic approaches to solving these technological and\narchitectural problems. It is also clear that if this community is\ngoing to start moving towards semantic web style solutions, then there\nis a bridge to be built between traditional approaches to structured\nvocabularies and the Web Ontology Language. The SKOS schemas may be\nabler to play a significant role in building that bridge, and provide\nan opportunity for the large communities of library and information\nscientists to enrich the framework of the Semantic Web.\n\nThere was also some very positive feedback on the recent SKOS work,\nincluding the reports on representing monolingual thesauri, multilingual\nthesauri and inter-thesaurus mappings.\n\nRead more on the weblog:\n\nhttp://esw.w3.org/mt/esw/archives/000041.html\n\n\nFrequently Asked Questions\n\n4. How can I make my thesaurus a part of the Semantic Web?\n\nA: To make a thesaurus a part of the semantic web, simply\n\n * encode the thesaurus as RDF using the SKOS schemas,\n * publish the RDF data.\n\nThe SKOS schemas are RDF schemas for encoding thesauri and similar types\nof knowledge organisation system (KOS).\n\nSKOS-Core is the core schema, allowing representation of thesaurus\nconcepts, terms, and organisation of those concepts into hierarchical\nand associative structures. It has been designed as an extensible\nframework of properties, and so can be adapted to cope with different\ntypes of thesaurus.\n\nThe version of SKOS-Core currently available is a pre-release. A formal\nrelease (version 1.0) is planned shortly, along with a guide to using\nit.\n\nSKOS-Mapping is an RDF schema for creating and encoding mappings between\nthesauri. If mappings between thesauri are available, independent but\noverlapping thesauri can be used interchangeably, helping to remove the\nboundaries between collections and communities. A good introduction to\nSKOS-Mapping with examples is here.\n\nSKOS-Mapping is also currently available as a pre-release version. A\nformal release can be expected shortly after SKOS-Core 1.0.\n\nThere are also a number of reports on issues relating to the use of\nthesauri on the semantic web, including a review of previous work and a\nreport on multilingual thesauri. The work is ongoing, and discussed on\nthe public-esw-thes@w3.org mailing list (archives) - feel free to join\nin!\n\nRead more:\n\nSKOS-Core: http://www.w3c.rl.ac.uk/SWAD/rdfthes.html#schemas\nUsing SKOS-Core schema: http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html\n\nSKOS-mapping schema: http://www.w3c.rl.ac.uk/SWAD/rdfthes.html#schemas\nSKOS-Mapping examples: http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n\nThesaurus reports: http://www.w3c.rl.ac.uk/SWAD/rdfthes.html#reports\nThesaurus mailing list archives: http://lists.w3.org/Archives/Public/public-esw-thes/\n\n\n5. Why not use an RDF graph with blanks for querying RDF?\n\nA. You can, some people have, it can be useful but is much less\nexpressive than most full RDF query languages.\n\nIn RDF, blank notes are treated as existential variables - they indicate\nthe existence of a thing without saying anything about the name of that\nthing. So it is reasonable to express a query as a graph with bNodes\nused as if they were wildcards and to define a query operation as\nsomething like \"find all instances of the query graph which are entailed\nby the data\". Perhaps, your operation might want to the find the union\nof that set of matching subgraphs rather than return the separate\nmatches, depending on the application.\n\nThis can work but it is quite restrictive.\n\nFirst, bNodes can only be used in place of nodes, not in place of\nproperties. This is a big limitation since many queries require matching\nover properties. Second, you can't express constraints such as string\npattern matches or range constraints on the literals to be matched. To\nget around this, attempts at this \"query by example\" approach often use\nmetalevel annotations to allow such things to be expressed. For example,\nsee our own experiments this area, RDF-QBE. Once, you start doing this\nyou can use the annotations to identify the query nodes in the first\nplace and not bother using bNodes at all. This is essentially, what the\nsimplest of the Edutella query languages, RDF-QEL-1, does.\n\nOther limitations are the inability to express disjunctive queries this\nway (RDF is purely conjunctive) and the akwardness of expressing\nconstraints between variables.\n\nDespite these limitations the symmetry of expressing queries, and indeed\nthe resulting matches, directly in RDF rather than indirectly encoded in\nRDF is appealing and could be appropriate in some applications.\n\n\nRead more:\n\nRDF-QBE: http://www.hpl.hp.com/semweb/publications.htm#RDF-QBE\n\nEdutella: http://edutella.jxta.org/reports/edutella-whitepaper.pdf\n\n\n\nVisit the SWAD-Europe website:\nhttp://www.w3.org/2001/sw/Europe/\nhttp://www.w3.org/2001/sw/Europe/reports/intro.html\n\nand weblog:\nhttp://esw.w3.org/mt/esw/\n\nfor ongoing information about the project.\n\n\n\n"
        },
        {
            "subject": "RE: [Fwd: Shared Key Authentication for the TLS Protocol&ndash;&ndash; an Alternative",
            "content": "Phil,\n\nI dont see any underlying formal problem with introducing additional authentication protocols\ninto an SSL application's framework of security protocols. When DH was introduced into\nstd SSL mechanisms, it prevented ISO NR, as does any other method of arranging a shared secret,\nsuch as passwords or code books. There mere fact that an authentication service does\nnot provide ISO NR is not sufficient to deny its use in, or in support of, SSL goals.\n\nNot everyone wants ISO NR; sometimes, they definitely don't want it, eg PFS service. Authenticated\nDH and KEA, and other shared secret approaches, when used in a secure manner,  precludes use of a\ncourt to resolve dispute about the contents of an encrypted/integral channel, without particpation\nof both parties. One parties decides to hold out, the court is powerless; if the parties\ndo agree, they must compromise their long term keys to the court. This is no good for Internet countries\nwhere courts are weak, and politically controlled. The weak get trodden on, usually, this means, as they\nhave no automatic means of recourse to an independent arbitrator. This makes DH and similar schemes\nuseless for cost-effective and fair commerce.\n\nBut, SSL's modern role is not restircted to commerce applications! However, Netsacpe and\nMicrosoft seemed already to have thought that through, surely!\n\nI would disgaree that its necessary to modify SSL standard (in TLS) to accomplish the\ngoal which Barb has established. I see SSL's integrity channel as something which\nshould simply always be there on any TCP frame henceforth. A server\nside RSA key is simple to manage, and key management costs are marginal. The\nwonder of RSA math means only one side needs keying and substantial improvement\nin default end-end channel integrity is provided, always.\n\nTo now add authentication exchanges to implement authentication services which\nare not standarized by SSL (exploiting whichever cipherSuite) should not require a change\nto SSL per se. Any numer of intermediate layers of protocol exchnage can be layered within\nthe SSL-integrity-protected frames, to implement whatever the parties agree. They\ncan use the default scalable authentication service provided by SSL which is application\nand stack and netweork and vendor and platform indepedent, else use their own proprietary\ndesign, as per NT's proprietary challenge-response mechanism on the web. Exploiting SSL basic\nintegrity channel is simply a matter of organizing winsock hooks, not fighting over standards to\nwin market share wars or level playing fields in infrastructure deployment battles.The means\nof agreeing the capabilities can be certs, or ISAKMP, or port assignment.\n\nNetscape & Microsoft jointly provided the world with a configurable comms stack via winsock which is\nnetwork, and protocol independent. The number of \"subnetwork convergence protocols\"\nwhich can be layered behing the service access point is arbitary. SSL integrity can come by default atached\nto any TCP provider; between the application and SSL can come Microsofts secret key scheme which\ncan deny application the rights to use SSL native authentication and/or encryption, should the vendor wish.\n \nI can no reason to change the standard; rather, such innovations should be encouraged, though\narchitected to minise thier introduction on the deploying infastructure, and use the flexiblities\nof the configurable stack technology. That is, after all why Microsoft introduced its winsock\nservice-based, highly configurable, comms stack technology with SSL support!\n\nSo, yes I agree with the right (and need) to introduce additional authnetication services into the Internet\nstack at layer 4 and 5. No I dont agree every (valid) service  option should be lumbered in with SSL, as neither\nshould it be lumbered in with IPSEC or ISAKMP.\n\nMonolithic systems fail, as do monolithic standards. If there exists an archictectural manner\nof providing the feature, then the standard offering has no reason to change, might be the rule.\n\nThis very much looks like case of forcing a change to the deployed standard to simply\nensure a different incompatible standard exists. The usual reason is marketing,\nand market share wars. \n\nPeter.\n \n\n\n----------\nFrom: Phil Karlton\nSent: Tuesday, October 01, 1996 10:58 AM\nTo: ssl-talk@netscape.com\nSubject: [Fwd: Shared Key Authentication for the TLS Protocol-- an Alternative]\n\n<<Message: Shared Key Authentication for ...>><<Message: RE: Shared Key Authentication for th...>>\nHere are two recent messages to the IETF Transport Layer Security\nWorking Group. I expect that many on this list may be interested in that\ndiscussion (which should take place on that list, <ietf-tls@w3.org>).\nThat group is considering using SSL 3.0 as the basis for the TLS effort.\n\nNote that shared secret authentication would have very different\nsecurity implications, including any possible ISO non-repudiation\ncharacteristics of an established connection.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://home.netscape.com/people/karlton\nNetscape Communications\n\n    Everything should be made as simple as possible, but not simpler.\n-- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "SWAD Europe Thesaurus wor",
            "content": "(Bcc: public-esw-thes)\n\nThere is a work package in the SWAD Europe project on the develpoment of an\nRDF Thesaurus, which is closely related to the development of a glossary\nsystem for W3C.\n\nThere is a page about it on the SWAD-E\nWiki at http://esw.w3.org/topic/RdfThesaurus which currently contains a\npointer to the workpackage page itself:\nhttp://www.w3c.rl.ac.uk/SWAD/thesaurus.html\n\nAnd there is a mailing list - public-esw-thes@w3.org archived at\nhttp://lists.w3.org/Archives/Public/public-esw-thes/ which has so far been\nquiet.\n\nThe work is actually a little ahead of what was expected, although I don't\nknow how much has been published to date.\n\ncheers\n\nChaals\n\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "SWAD Europe Thesaurus wor",
            "content": "(Bcc: public-esw-thes)\n\nThere is a work package in the SWAD Europe project on the develpoment of an\nRDF Thesaurus, which is closely related to the development of a glossary\nsystem for W3C.\n\nThere is a page about it on the SWAD-E\nWiki at http://esw.w3.org/topic/RdfThesaurus which currently contains a\npointer to the workpackage page itself:\nhttp://www.w3c.rl.ac.uk/SWAD/thesaurus.html\n\nAnd there is a mailing list - public-esw-thes@w3.org archived at\nhttp://lists.w3.org/Archives/Public/public-esw-thes/ which has so far been\nquiet.\n\nThe work is actually a little ahead of what was expected, although I don't\nknow how much has been published to date.\n\ncheers\n\nChaals\n\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "Interpretation of SKOSMapping properties ..",
            "content": "Hi Steve,\n\n> 3).\n> The major thing I wanted to post to the list is this (but you \n> may be able to\n> answer it directly?)\n> I notice that on\n> http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n> has the following properties:\n> \n> <rdf:Property rdf:ID=\"majorMatch\">\n> <rdfs:comment>If 'concept A has-major-match concept B' then the set of\n> resources properly indexed against concept A shares more than \n> 50% of its\n> members with the set of resources properly indexed against concept\n> B.</rdfs:comment>\n> </rdf:Property>\n> \n> <rdf:Property rdf:ID=\"minorMatch\">\n>   <rdfs:comment>If 'concept A has-minor-match concept B' then \n> the set of\n> resources properly indexed against concept A shares less than 50% but\n> greater than 0 of its members with the set of resources \n> properly indexed\n> against concept B.</rdfs:comment>\n>     </rdf:Property>\n> \n> The use of some number (50%) rings warning bells in my mind. \n> What about\n> 49.7% vs 50.1% ? How do we know anyway?\n> A more comfortable definition (in my mind) would be something vaguer\n> major match -> This means that a resource properly indexed \n> against A has a\n> good chance of being properly indexed against B\n> minor match -> This means that a resource properly indexed \n> against A has\n> some chance of being (or 'may be') properly indexed against B\n\nGood point.  This brings up a duality of perspective that I've been trying\nto understand for a while.  Let's have a crack at explaining it...\n\nI have defined these properties with formal entailments, i.e. majorMatch\nentails >50% overlap of the document sets corresponding to the concepts.\nHowever, a person creating the mapping must make a best guess as to whether\nthis will be true, based on their interpretation of the different meanings\nof the concepts.  \n\nTo make this point another way, consider the following two sets of\ninstructions on how to use the <soks:majorMatch> property, one to a person\ncreating a mapping, and one to a programmer developing applications that use\nthe <soks:majorMatch> property ...\n\nInstructions to mapper:\nUse <soks:majorMatch> to link concepts A and B if they overlap in meaning,\nand if you believe that more than 50% of the documents that are about\nconcept A will also be about concept B.\n\nInstructions to programmer:\nThe ( <ConceptA> <soks:majorMatch> <ConceptB> ) statement entails that >50%\nof the documents properly indexed against concept A are also properly\nindexed against concept B.  Thus in a query the two concepts may be\ninterchanged, and a success rate of >50% may be expected.\n\nI.e. the mapper makes a best guess based on the meaning of the concepts,\nwith imperfect knowledge of the actual document sets, and the programmer\nwrites programs that process these statements as if they are true statements\nabout the world, made by someone with perfect knowledge of the document\nsets.\n\nI think it's worth bearing in mind what actual impact these different\nmapping statements will have to the user.  A good mapping will mean that a\nquery app processing transformed queries can guarantee complete recall, and\norder the result set to put better matches first.  A poor mapping means lots\nof bogus results, incomplete recall and no good ordering.  In order to\ngenerate a good mapping, the mapper needs the right tools (i.e. a well\ndesigned vocab) and must know how to use them (i.e. needs a clear set of\ninstructions).  So this is what we're working towards.\n\nHow does that go down?\n\nAl.   \n\n\n\n"
        },
        {
            "subject": "Re: Interpretation of SKOSMapping properties ..",
            "content": "Hmmm, I see what you're saying, but I don't see why \">50%\" (with its\nillusion of precision) is better than \"good\" or some such (with its\nguarantee of vagueness).\nWhat we are talking about here the formal encoding of imprecision :)\n\nCheers\n\nSteve\n----- Original Message ----- \nFrom: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nTo: \"'Steve Cayzer'\" <steve.cayzer@hp.com>\nCc: <public-esw-thes@w3.org>\nSent: Monday, December 01, 2003 12:16 PM\nSubject: Interpretation of SKOS-Mapping properties ...\n\n\n> Hi Steve,\n>\n> > 3).\n> > The major thing I wanted to post to the list is this (but you\n> > may be able to\n> > answer it directly?)\n> > I notice that on\n> > http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n> > has the following properties:\n> >\n> > <rdf:Property rdf:ID=\"majorMatch\">\n> > <rdfs:comment>If 'concept A has-major-match concept B' then the set of\n> > resources properly indexed against concept A shares more than\n> > 50% of its\n> > members with the set of resources properly indexed against concept\n> > B.</rdfs:comment>\n> > </rdf:Property>\n> >\n> > <rdf:Property rdf:ID=\"minorMatch\">\n> >   <rdfs:comment>If 'concept A has-minor-match concept B' then\n> > the set of\n> > resources properly indexed against concept A shares less than 50% but\n> > greater than 0 of its members with the set of resources\n> > properly indexed\n> > against concept B.</rdfs:comment>\n> >     </rdf:Property>\n> >\n> > The use of some number (50%) rings warning bells in my mind.\n> > What about\n> > 49.7% vs 50.1% ? How do we know anyway?\n> > A more comfortable definition (in my mind) would be something vaguer\n> > major match -> This means that a resource properly indexed\n> > against A has a\n> > good chance of being properly indexed against B\n> > minor match -> This means that a resource properly indexed\n> > against A has\n> > some chance of being (or 'may be') properly indexed against B\n>\n> Good point.  This brings up a duality of perspective that I've been trying\n> to understand for a while.  Let's have a crack at explaining it...\n>\n> I have defined these properties with formal entailments, i.e. majorMatch\n> entails >50% overlap of the document sets corresponding to the concepts.\n> However, a person creating the mapping must make a best guess as to\nwhether\n> this will be true, based on their interpretation of the different meanings\n> of the concepts.\n>\n> To make this point another way, consider the following two sets of\n> instructions on how to use the <soks:majorMatch> property, one to a person\n> creating a mapping, and one to a programmer developing applications that\nuse\n> the <soks:majorMatch> property ...\n>\n> Instructions to mapper:\n> Use <soks:majorMatch> to link concepts A and B if they overlap in meaning,\n> and if you believe that more than 50% of the documents that are about\n> concept A will also be about concept B.\n>\n> Instructions to programmer:\n> The ( <ConceptA> <soks:majorMatch> <ConceptB> ) statement entails that\n>50%\n> of the documents properly indexed against concept A are also properly\n> indexed against concept B.  Thus in a query the two concepts may be\n> interchanged, and a success rate of >50% may be expected.\n>\n> I.e. the mapper makes a best guess based on the meaning of the concepts,\n> with imperfect knowledge of the actual document sets, and the programmer\n> writes programs that process these statements as if they are true\nstatements\n> about the world, made by someone with perfect knowledge of the document\n> sets.\n>\n> I think it's worth bearing in mind what actual impact these different\n> mapping statements will have to the user.  A good mapping will mean that a\n> query app processing transformed queries can guarantee complete recall,\nand\n> order the result set to put better matches first.  A poor mapping means\nlots\n> of bogus results, incomplete recall and no good ordering.  In order to\n> generate a good mapping, the mapper needs the right tools (i.e. a well\n> designed vocab) and must know how to use them (i.e. needs a clear set of\n> instructions).  So this is what we're working towards.\n>\n> How does that go down?\n>\n> Al.\n>\n\n\n\n"
        },
        {
            "subject": "RE: Interpretation of SKOSMapping properties ..",
            "content": "Yeah, good point.  Actually the idea for major and minor match (with the <>\n50% definitions) came from the Hacet project report which I got a sneaky\npreview of.  I though it was better than just having 'inexactMatch'.  Do you\nsuggest a name change (e.g. 'goodMatch' and 'notSoGoodMatch' :) or just a\ndifferent definition of major and minor?\n\nAl.\n\n> -----Original Message-----\n> From: Steve Cayzer [mailto:steve.cayzer@hp.com]\n> Sent: 01 December 2003 12:57\n> To: public-esw-thes@w3.org\n> Cc: public-esw-thes@w3.org\n> Subject: Re: Interpretation of SKOS-Mapping properties ...\n> \n> \n> \n> Hmmm, I see what you're saying, but I don't see why \">50%\" (with its\n> illusion of precision) is better than \"good\" or some such (with its\n> guarantee of vagueness).\n> What we are talking about here the formal encoding of imprecision :)\n> \n> Cheers\n> \n> Steve\n> ----- Original Message ----- \n> From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> To: \"'Steve Cayzer'\" <steve.cayzer@hp.com>\n> Cc: <public-esw-thes@w3.org>\n> Sent: Monday, December 01, 2003 12:16 PM\n> Subject: Interpretation of SKOS-Mapping properties ...\n> \n> \n> > Hi Steve,\n> >\n> > > 3).\n> > > The major thing I wanted to post to the list is this (but you\n> > > may be able to\n> > > answer it directly?)\n> > > I notice that on\n> > > http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n> > > has the following properties:\n> > >\n> > > <rdf:Property rdf:ID=\"majorMatch\">\n> > > <rdfs:comment>If 'concept A has-major-match concept B' \n> then the set of\n> > > resources properly indexed against concept A shares more than\n> > > 50% of its\n> > > members with the set of resources properly indexed against concept\n> > > B.</rdfs:comment>\n> > > </rdf:Property>\n> > >\n> > > <rdf:Property rdf:ID=\"minorMatch\">\n> > >   <rdfs:comment>If 'concept A has-minor-match concept B' then\n> > > the set of\n> > > resources properly indexed against concept A shares less \n> than 50% but\n> > > greater than 0 of its members with the set of resources\n> > > properly indexed\n> > > against concept B.</rdfs:comment>\n> > >     </rdf:Property>\n> > >\n> > > The use of some number (50%) rings warning bells in my mind.\n> > > What about\n> > > 49.7% vs 50.1% ? How do we know anyway?\n> > > A more comfortable definition (in my mind) would be \n> something vaguer\n> > > major match -> This means that a resource properly indexed\n> > > against A has a\n> > > good chance of being properly indexed against B\n> > > minor match -> This means that a resource properly indexed\n> > > against A has\n> > > some chance of being (or 'may be') properly indexed against B\n> >\n> > Good point.  This brings up a duality of perspective that \n> I've been trying\n> > to understand for a while.  Let's have a crack at explaining it...\n> >\n> > I have defined these properties with formal entailments, \n> i.e. majorMatch\n> > entails >50% overlap of the document sets corresponding to \n> the concepts.\n> > However, a person creating the mapping must make a best guess as to\n> whether\n> > this will be true, based on their interpretation of the \n> different meanings\n> > of the concepts.\n> >\n> > To make this point another way, consider the following two sets of\n> > instructions on how to use the <soks:majorMatch> property, \n> one to a person\n> > creating a mapping, and one to a programmer developing \n> applications that\n> use\n> > the <soks:majorMatch> property ...\n> >\n> > Instructions to mapper:\n> > Use <soks:majorMatch> to link concepts A and B if they \n> overlap in meaning,\n> > and if you believe that more than 50% of the documents that \n> are about\n> > concept A will also be about concept B.\n> >\n> > Instructions to programmer:\n> > The ( <ConceptA> <soks:majorMatch> <ConceptB> ) statement \n> entails that\n> >50%\n> > of the documents properly indexed against concept A are \n> also properly\n> > indexed against concept B.  Thus in a query the two concepts may be\n> > interchanged, and a success rate of >50% may be expected.\n> >\n> > I.e. the mapper makes a best guess based on the meaning of \n> the concepts,\n> > with imperfect knowledge of the actual document sets, and \n> the programmer\n> > writes programs that process these statements as if they are true\n> statements\n> > about the world, made by someone with perfect knowledge of \n> the document\n> > sets.\n> >\n> > I think it's worth bearing in mind what actual impact these \n> different\n> > mapping statements will have to the user.  A good mapping \n> will mean that a\n> > query app processing transformed queries can guarantee \n> complete recall,\n> and\n> > order the result set to put better matches first.  A poor \n> mapping means\n> lots\n> > of bogus results, incomplete recall and no good ordering.  \n> In order to\n> > generate a good mapping, the mapper needs the right tools \n> (i.e. a well\n> > designed vocab) and must know how to use them (i.e. needs a \n> clear set of\n> > instructions).  So this is what we're working towards.\n> >\n> > How does that go down?\n> >\n> > Al.\n> >\n> \n\n\n\n"
        },
        {
            "subject": "RE: Interpretation of SKOSMapping properties ..",
            "content": "Hi Alistair, folks,\n\nI think Steve's got a good point - using the exact figure 50% in the\ndefinitions could mislead people into thinking it had more significance than\nan expression of the mappers belief. I'd suggest a minor change to the\nwording, from:\n\n> > Instructions to mapper:\n> > Use <soks:majorMatch> to link concepts A and B if they overlap\n> in meaning,\n> > and if you believe that more than 50% of the documents that are about\n> > concept A will also be about concept B.\n\nto something like\n\n\"...if you believe that the majority of the documents...\"\n\nGenerally developments are looking great to me - that was quite a flurry of\nactivity!\n\nThe combination constructs are interesting. I've not had a chance to play\nyet, but I'd be a little concerned that they seem to be extending the\nsemantics beyond RDF, and that there might be a clash/incompatibility with\nOWL constructs. Any particular reason for not using OWL, btw?\n\nCheers,\nDanny\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Steve Cayzer\n> Sent: 01 December 2003 15:13\n> To: public-esw-thes@w3.org\n> Cc: public-esw-thes@w3.org\n> Subject: Re: Interpretation of SKOS-Mapping properties ...\n>\n>\n>\n> Hmmm, I see what you're saying, but I don't see why \">50%\" (with its\n> illusion of precision) is better than \"good\" or some such (with its\n> guarantee of vagueness).\n> What we are talking about here the formal encoding of imprecision :)\n>\n> Cheers\n>\n> Steve\n> ----- Original Message -----\n> From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> To: \"'Steve Cayzer'\" <steve.cayzer@hp.com>\n> Cc: <public-esw-thes@w3.org>\n> Sent: Monday, December 01, 2003 12:16 PM\n> Subject: Interpretation of SKOS-Mapping properties ...\n>\n>\n> > Hi Steve,\n> >\n> > > 3).\n> > > The major thing I wanted to post to the list is this (but you\n> > > may be able to\n> > > answer it directly?)\n> > > I notice that on\n> > > http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n> > > has the following properties:\n> > >\n> > > <rdf:Property rdf:ID=\"majorMatch\">\n> > > <rdfs:comment>If 'concept A has-major-match concept B' then the set of\n> > > resources properly indexed against concept A shares more than\n> > > 50% of its\n> > > members with the set of resources properly indexed against concept\n> > > B.</rdfs:comment>\n> > > </rdf:Property>\n> > >\n> > > <rdf:Property rdf:ID=\"minorMatch\">\n> > >   <rdfs:comment>If 'concept A has-minor-match concept B' then\n> > > the set of\n> > > resources properly indexed against concept A shares less than 50% but\n> > > greater than 0 of its members with the set of resources\n> > > properly indexed\n> > > against concept B.</rdfs:comment>\n> > >     </rdf:Property>\n> > >\n> > > The use of some number (50%) rings warning bells in my mind.\n> > > What about\n> > > 49.7% vs 50.1% ? How do we know anyway?\n> > > A more comfortable definition (in my mind) would be something vaguer\n> > > major match -> This means that a resource properly indexed\n> > > against A has a\n> > > good chance of being properly indexed against B\n> > > minor match -> This means that a resource properly indexed\n> > > against A has\n> > > some chance of being (or 'may be') properly indexed against B\n> >\n> > Good point.  This brings up a duality of perspective that I've\n> been trying\n> > to understand for a while.  Let's have a crack at explaining it...\n> >\n> > I have defined these properties with formal entailments, i.e. majorMatch\n> > entails >50% overlap of the document sets corresponding to the concepts.\n> > However, a person creating the mapping must make a best guess as to\n> whether\n> > this will be true, based on their interpretation of the\n> different meanings\n> > of the concepts.\n> >\n> > To make this point another way, consider the following two sets of\n> > instructions on how to use the <soks:majorMatch> property, one\n> to a person\n> > creating a mapping, and one to a programmer developing applications that\n> use\n> > the <soks:majorMatch> property ...\n> >\n> > Instructions to mapper:\n> > Use <soks:majorMatch> to link concepts A and B if they overlap\n> in meaning,\n> > and if you believe that more than 50% of the documents that are about\n> > concept A will also be about concept B.\n> >\n> > Instructions to programmer:\n> > The ( <ConceptA> <soks:majorMatch> <ConceptB> ) statement entails that\n> >50%\n> > of the documents properly indexed against concept A are also properly\n> > indexed against concept B.  Thus in a query the two concepts may be\n> > interchanged, and a success rate of >50% may be expected.\n> >\n> > I.e. the mapper makes a best guess based on the meaning of the concepts,\n> > with imperfect knowledge of the actual document sets, and the programmer\n> > writes programs that process these statements as if they are true\n> statements\n> > about the world, made by someone with perfect knowledge of the document\n> > sets.\n> >\n> > I think it's worth bearing in mind what actual impact these different\n> > mapping statements will have to the user.  A good mapping will\n> mean that a\n> > query app processing transformed queries can guarantee complete recall,\n> and\n> > order the result set to put better matches first.  A poor mapping means\n> lots\n> > of bogus results, incomplete recall and no good ordering.  In order to\n> > generate a good mapping, the mapper needs the right tools (i.e. a well\n> > designed vocab) and must know how to use them (i.e. needs a clear set of\n> > instructions).  So this is what we're working towards.\n> >\n> > How does that go down?\n> >\n> > Al.\n> >\n>\n\n\n\n"
        },
        {
            "subject": "FW: Interpretation of SKOSMapping properties ..",
            "content": "-----Original Message-----\nFrom: Steve Cayzer [mailto:steve.cayzer@hp.com]\nSent: 01 December 2003 15:08\nTo: Miles, AJ (Alistair) \nSubject: Re: Interpretation of SKOS-Mapping properties ...\n\n\n>  Do you\n> suggest a name change (e.g. 'goodMatch' and 'notSoGoodMatch' :) or just a\n> different definition of major and minor?\nI don't think it matters much, though I'd tend to the latter.\nI'd also be tempted to make them subproperties of an inexactMatch to\ndifferentiate them from the more precise broader, narrower and exact.\n\n----- Original Message ----- \nFrom: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nTo: \"'Steve Cayzer'\" <steve.cayzer@hp.com>; <public-esw-thes@w3.org>\nSent: Monday, December 01, 2003 1:36 PM\nSubject: RE: Interpretation of SKOS-Mapping properties ...\n\n\n> Yeah, good point.  Actually the idea for major and minor match (with the\n<>\n> 50% definitions) came from the Hacet project report which I got a sneaky\n> preview of.  I though it was better than just having 'inexactMatch'.  Do\nyou\n> suggest a name change (e.g. 'goodMatch' and 'notSoGoodMatch' :) or just a\n> different definition of major and minor?\n>\n> Al.\n>\n> > -----Original Message-----\n> > From: Steve Cayzer [mailto:steve.cayzer@hp.com]\n> > Sent: 01 December 2003 12:57\n> > To: public-esw-thes@w3.org\n> > Cc: public-esw-thes@w3.org\n> > Subject: Re: Interpretation of SKOS-Mapping properties ...\n> >\n> >\n> >\n> > Hmmm, I see what you're saying, but I don't see why \">50%\" (with its\n> > illusion of precision) is better than \"good\" or some such (with its\n> > guarantee of vagueness).\n> > What we are talking about here the formal encoding of imprecision :)\n> >\n> > Cheers\n> >\n> > Steve\n> > ----- Original Message ----- \n> > From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> > To: \"'Steve Cayzer'\" <steve.cayzer@hp.com>\n> > Cc: <public-esw-thes@w3.org>\n> > Sent: Monday, December 01, 2003 12:16 PM\n> > Subject: Interpretation of SKOS-Mapping properties ...\n> >\n> >\n> > > Hi Steve,\n> > >\n> > > > 3).\n> > > > The major thing I wanted to post to the list is this (but you\n> > > > may be able to\n> > > > answer it directly?)\n> > > > I notice that on\n> > > > http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n> > > > has the following properties:\n> > > >\n> > > > <rdf:Property rdf:ID=\"majorMatch\">\n> > > > <rdfs:comment>If 'concept A has-major-match concept B'\n> > then the set of\n> > > > resources properly indexed against concept A shares more than\n> > > > 50% of its\n> > > > members with the set of resources properly indexed against concept\n> > > > B.</rdfs:comment>\n> > > > </rdf:Property>\n> > > >\n> > > > <rdf:Property rdf:ID=\"minorMatch\">\n> > > >   <rdfs:comment>If 'concept A has-minor-match concept B' then\n> > > > the set of\n> > > > resources properly indexed against concept A shares less\n> > than 50% but\n> > > > greater than 0 of its members with the set of resources\n> > > > properly indexed\n> > > > against concept B.</rdfs:comment>\n> > > >     </rdf:Property>\n> > > >\n> > > > The use of some number (50%) rings warning bells in my mind.\n> > > > What about\n> > > > 49.7% vs 50.1% ? How do we know anyway?\n> > > > A more comfortable definition (in my mind) would be\n> > something vaguer\n> > > > major match -> This means that a resource properly indexed\n> > > > against A has a\n> > > > good chance of being properly indexed against B\n> > > > minor match -> This means that a resource properly indexed\n> > > > against A has\n> > > > some chance of being (or 'may be') properly indexed against B\n> > >\n> > > Good point.  This brings up a duality of perspective that\n> > I've been trying\n> > > to understand for a while.  Let's have a crack at explaining it...\n> > >\n> > > I have defined these properties with formal entailments,\n> > i.e. majorMatch\n> > > entails >50% overlap of the document sets corresponding to\n> > the concepts.\n> > > However, a person creating the mapping must make a best guess as to\n> > whether\n> > > this will be true, based on their interpretation of the\n> > different meanings\n> > > of the concepts.\n> > >\n> > > To make this point another way, consider the following two sets of\n> > > instructions on how to use the <soks:majorMatch> property,\n> > one to a person\n> > > creating a mapping, and one to a programmer developing\n> > applications that\n> > use\n> > > the <soks:majorMatch> property ...\n> > >\n> > > Instructions to mapper:\n> > > Use <soks:majorMatch> to link concepts A and B if they\n> > overlap in meaning,\n> > > and if you believe that more than 50% of the documents that\n> > are about\n> > > concept A will also be about concept B.\n> > >\n> > > Instructions to programmer:\n> > > The ( <ConceptA> <soks:majorMatch> <ConceptB> ) statement\n> > entails that\n> > >50%\n> > > of the documents properly indexed against concept A are\n> > also properly\n> > > indexed against concept B.  Thus in a query the two concepts may be\n> > > interchanged, and a success rate of >50% may be expected.\n> > >\n> > > I.e. the mapper makes a best guess based on the meaning of\n> > the concepts,\n> > > with imperfect knowledge of the actual document sets, and\n> > the programmer\n> > > writes programs that process these statements as if they are true\n> > statements\n> > > about the world, made by someone with perfect knowledge of\n> > the document\n> > > sets.\n> > >\n> > > I think it's worth bearing in mind what actual impact these\n> > different\n> > > mapping statements will have to the user.  A good mapping\n> > will mean that a\n> > > query app processing transformed queries can guarantee\n> > complete recall,\n> > and\n> > > order the result set to put better matches first.  A poor\n> > mapping means\n> > lots\n> > > of bogus results, incomplete recall and no good ordering.\n> > In order to\n> > > generate a good mapping, the mapper needs the right tools\n> > (i.e. a well\n> > > designed vocab) and must know how to use them (i.e. needs a\n> > clear set of\n> > > instructions).  So this is what we're working towards.\n> > >\n> > > How does that go down?\n> > >\n> > > Al.\n> > >\n> >\n>\n\n\n\n"
        },
        {
            "subject": "RE: [Fwd: Shared Key Authentication for the TLS Protocol&ndash;&ndash; an Alternative",
            "content": ">From: Peter Williams[SMTP:peter@verisign.com]\n>\n>I would disgaree that its necessary to modify SSL standard (in TLS) to\n>accomplish the\n>goal which Barb has established. I see SSL's integrity channel as something\n>which\n>should simply always be there on any TCP frame henceforth. A server\n>side RSA key is simple to manage, and key management costs are marginal. The\n>wonder of RSA math means only one side needs keying and substantial\n>improvement\n>in default end-end channel integrity is provided, always.\n>\n>To now add authentication exchanges to implement authentication services\n>which\n>are not standarized by SSL (exploiting whichever cipherSuite) should not\n>require a change\n>to SSL per se. Any numer of intermediate layers of protocol exchnage can be\n>layered within\n>the SSL-integrity-protected frames, to implement whatever the parties agree.\n>They\n>can use the default scalable authentication service provided by SSL which is\n>application\n>and stack and netweork and vendor and platform indepedent, else use their own\n>proprietary\n>design, as per NT's proprietary challenge-response mechanism on the web.\n>Exploiting SSL basic\n>integrity channel is simply a matter of organizing winsock hooks, not\n>fighting over standards to\n>win market share wars or level playing fields in infrastructure deployment\n>battles.The means\n>of agreeing the capabilities can be certs, or ISAKMP, or port assignment.\n\nSimilarly, public-key-based client authentication does not have to be in\nSSL/TLS either, since it could easily be layered on top of it.  An\nadvantage of incorporating it into the protocol is, as Peter points out,\ninteroperability.  Exactly the same argument applies in the case of\nshared-key-based authentication; a single, non-proprietary\nshared-key-based authentication standard embedded in TLS (which is what\nour proposal provides) allows independent client-builders and\nserver-builders to implement shared-key authentication interoperably. \n\nThere is another justification for this incorporation in the case of\nshared-key authentication that does not apply in the case of public-key\nauthentication:  if for any reason the channel used is not strongly\nencrypted, and the shared key being used for authentication is guessable\n(as is often the case for user-remembered passwords), then any fully\nlayered solution will be vulnerable to brute-force offline attacks.\nIncorporating the authentication protocol into TLS allows a special\nexception to be made for the authentication data, strongly protecting it\neven if the normal traffic is not strongly encrypted.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n\n\n>\n\n\n\n"
        },
        {
            "subject": "Why you can't use OWL set constructs directly for concept mapping   the simple version !!",
            "content": "Let's have another go at this ...\n\nSeveral people have asked, why can't I encode a traditional mapping\nexpression such as ...\n\n'Concept A has-broad-match Concept B and Concept C'\n\n... using OWL as ...\n\n<soks:Concept rdf:about=\"#A\">\n<rdfs:subClassOf rdf:parseType=\"resource\">\n<owl:intersectionOf rdf:parseType=\"collection\">\n  <soks:Concept rdf:about=\"#B\"/>\n<soks:Concept rdf:about=\"#C\"/>\n</owl:intersectionOf>\n</rdfs:subClassOf>\n</soks:Concept>\n\n... ???\n\nTwo reasons are:\n\n1.  Many things types as <soks:Concept> should not be modelled as classes.\nFor example, the concept 'Fish and chips' is not a class, nor the concept\n'Java programming language version 1.4.2' or 'Absence from school' or\n'British Army' or 'National Health Service'.  But all these may be concepts\nin a thesaurus (the last three are taken from the Government Category List\nthesaurus).  And if they aren't classes, we can't use OWL set constructs,\nbecause these may only be used with classes.\n\nHowever, we still want to be able to use set-like expressions, such as \n\n'Java programming language version 1.4.2' has-broad-match 'Java\n(programming)' and 'Programming languages' \n\n\n2.  Some thesaurus concepts can be modelled as classes.  For example, 'NHS\nTrusts', 'Nursery schools', 'Religious minorities' (all from GCL) could all\nbe modelled as an <owl:Class> with instances.  Here we want to reserve all\nthe OWL expressions to make statements about the structure of the conceptual\nscheme itself, should we decide to start migrating our thesauri towards\nontologies.    \n\n\nHOWEVER, I believe we can still use OWL to express the entailments of\nmappings.  I believe a statement such as ...\n\n'Concept A has-broad-match Concept B and Concept C'\n\n... could be defined to entail the following ...\n\n <owl:Restriction> \n    <owl:onProperty rdf:resource=\"&dc;subject\"/> \n    <owl:hasValue rdf:resource=\"#A\"/> \n    <rdfs:subClassOf rdf:parseType=\"resource\"> \n       <owl:intersectionOf rdf:parseType=\"collection\"> \n          <owl:Restriction> \n             <owl:onProperty rdf:resource=\"&dc;subject\"/> \n             <owl:hasValue rdf:resource=\"#B\"/> \n          </owl:Restriction> \n          <owl:Restriction> \n             <owl:onProperty rdf:resource=\"&dc;subject\"/> \n             <owl:hasValue rdf:resource=\"#C\"/> \n          </owl:Restriction> \n       </owl:intersectionOf> \n    </rdfs:subClassOf> \n </owl:Restriction> \n\n... which is useful because then an OWL reasoner could infer that a\nsomething with <dc:subject> concept A is also something with <dc:subject>\nconcept B and <dc:subject> concept B.  I.e. given a complete mapping an OWL\nreasoner could infer a virtual subject index for a collection in terms of\nanother thesaurus (although perhaps at some possibly unreasonable\ncomputational expense).  An OWL reasoner could also infer transformed\nqueries.  \n\nThe problem with using this sort of expression as a base vocabulary for\nexpressing mappings is ...\n1.  It's a bit long-winded and ...\n2.  Some collections may use properties other than <dc:subject> to\nexpress the subject of a resource (e.g. Open Directory uses the 'link'\nproperty from a topic to a resource, which is a bit like a sort of inverse\nof <dc:subject>).\n\nSo I think a simpler base vocabulary is in order, something familiar to the\nthesaurus community, hence SKOS-Mapping.  Then SKOS-Mapping statements could\nbe defined to have formal entailments expressable in OWL, or they could be\nused to generate rules, which could in turn be used to transform queries or\nsubject indexes.\n\nDefining <soks-map:AND> <soks-map:OR> and <soks-map:NOT> as sub-classes of\n<rdf:Bag> may not be a good idea however (see Dave R's mail\n<http://lists.w3.org/Archives/Public/public-esw-thes/2003Nov/0065.html>), so\nI'm totally open to suggestions on how best to express these kinds of\nconstruct in RDF ...\n\nAl.\n\n[Also you can see my other attempt to write up this issue\n<http://lists.w3.org/Archives/Public/public-esw-thes/2003Nov/0067.html>]\n\n\n   \n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Danny Ayers\n> Sent: 02 December 2003 09:38\n> To: public-esw-thes@w3.org\n> Subject: RE: Interpretation of SKOS-Mapping properties ...\n> \n> \n> \n> Hi Alistair, folks,\n> \n> I think Steve's got a good point - using the exact figure 50% in the\n> definitions could mislead people into thinking it had more \n> significance than\n> an expression of the mappers belief. I'd suggest a minor change to the\n> wording, from:\n> \n> > > Instructions to mapper:\n> > > Use <soks:majorMatch> to link concepts A and B if they overlap\n> > in meaning,\n> > > and if you believe that more than 50% of the documents \n> that are about\n> > > concept A will also be about concept B.\n> \n> to something like\n> \n> \"...if you believe that the majority of the documents...\"\n> \n> Generally developments are looking great to me - that was \n> quite a flurry of\n> activity!\n> \n> The combination constructs are interesting. I've not had a \n> chance to play\n> yet, but I'd be a little concerned that they seem to be extending the\n> semantics beyond RDF, and that there might be a \n> clash/incompatibility with\n> OWL constructs. Any particular reason for not using OWL, btw?\n> \n> Cheers,\n> Danny\n> \n> \n> \n> > -----Original Message-----\n> > From: public-esw-thes-request@w3.org\n> > [mailto:public-esw-thes-request@w3.org]On Behalf Of Steve Cayzer\n> > Sent: 01 December 2003 15:13\n> > To: public-esw-thes@w3.org\n> > Cc: public-esw-thes@w3.org\n> > Subject: Re: Interpretation of SKOS-Mapping properties ...\n> >\n> >\n> >\n> > Hmmm, I see what you're saying, but I don't see why \">50%\" (with its\n> > illusion of precision) is better than \"good\" or some such (with its\n> > guarantee of vagueness).\n> > What we are talking about here the formal encoding of imprecision :)\n> >\n> > Cheers\n> >\n> > Steve\n> > ----- Original Message -----\n> > From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> > To: \"'Steve Cayzer'\" <steve.cayzer@hp.com>\n> > Cc: <public-esw-thes@w3.org>\n> > Sent: Monday, December 01, 2003 12:16 PM\n> > Subject: Interpretation of SKOS-Mapping properties ...\n> >\n> >\n> > > Hi Steve,\n> > >\n> > > > 3).\n> > > > The major thing I wanted to post to the list is this (but you\n> > > > may be able to\n> > > > answer it directly?)\n> > > > I notice that on\n> > > > http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n> > > > has the following properties:\n> > > >\n> > > > <rdf:Property rdf:ID=\"majorMatch\">\n> > > > <rdfs:comment>If 'concept A has-major-match concept B' \n> then the set of\n> > > > resources properly indexed against concept A shares more than\n> > > > 50% of its\n> > > > members with the set of resources properly indexed \n> against concept\n> > > > B.</rdfs:comment>\n> > > > </rdf:Property>\n> > > >\n> > > > <rdf:Property rdf:ID=\"minorMatch\">\n> > > >   <rdfs:comment>If 'concept A has-minor-match concept B' then\n> > > > the set of\n> > > > resources properly indexed against concept A shares \n> less than 50% but\n> > > > greater than 0 of its members with the set of resources\n> > > > properly indexed\n> > > > against concept B.</rdfs:comment>\n> > > >     </rdf:Property>\n> > > >\n> > > > The use of some number (50%) rings warning bells in my mind.\n> > > > What about\n> > > > 49.7% vs 50.1% ? How do we know anyway?\n> > > > A more comfortable definition (in my mind) would be \n> something vaguer\n> > > > major match -> This means that a resource properly indexed\n> > > > against A has a\n> > > > good chance of being properly indexed against B\n> > > > minor match -> This means that a resource properly indexed\n> > > > against A has\n> > > > some chance of being (or 'may be') properly indexed against B\n> > >\n> > > Good point.  This brings up a duality of perspective that I've\n> > been trying\n> > > to understand for a while.  Let's have a crack at explaining it...\n> > >\n> > > I have defined these properties with formal entailments, \n> i.e. majorMatch\n> > > entails >50% overlap of the document sets corresponding \n> to the concepts.\n> > > However, a person creating the mapping must make a best \n> guess as to\n> > whether\n> > > this will be true, based on their interpretation of the\n> > different meanings\n> > > of the concepts.\n> > >\n> > > To make this point another way, consider the following two sets of\n> > > instructions on how to use the <soks:majorMatch> property, one\n> > to a person\n> > > creating a mapping, and one to a programmer developing \n> applications that\n> > use\n> > > the <soks:majorMatch> property ...\n> > >\n> > > Instructions to mapper:\n> > > Use <soks:majorMatch> to link concepts A and B if they overlap\n> > in meaning,\n> > > and if you believe that more than 50% of the documents \n> that are about\n> > > concept A will also be about concept B.\n> > >\n> > > Instructions to programmer:\n> > > The ( <ConceptA> <soks:majorMatch> <ConceptB> ) statement \n> entails that\n> > >50%\n> > > of the documents properly indexed against concept A are \n> also properly\n> > > indexed against concept B.  Thus in a query the two \n> concepts may be\n> > > interchanged, and a success rate of >50% may be expected.\n> > >\n> > > I.e. the mapper makes a best guess based on the meaning \n> of the concepts,\n> > > with imperfect knowledge of the actual document sets, and \n> the programmer\n> > > writes programs that process these statements as if they are true\n> > statements\n> > > about the world, made by someone with perfect knowledge \n> of the document\n> > > sets.\n> > >\n> > > I think it's worth bearing in mind what actual impact \n> these different\n> > > mapping statements will have to the user.  A good mapping will\n> > mean that a\n> > > query app processing transformed queries can guarantee \n> complete recall,\n> > and\n> > > order the result set to put better matches first.  A poor \n> mapping means\n> > lots\n> > > of bogus results, incomplete recall and no good ordering. \n>  In order to\n> > > generate a good mapping, the mapper needs the right tools \n> (i.e. a well\n> > > designed vocab) and must know how to use them (i.e. needs \n> a clear set of\n> > > instructions).  So this is what we're working towards.\n> > >\n> > > How does that go down?\n> > >\n> > > Al.\n> > >\n> >\n> \n\n\n\n"
        },
        {
            "subject": "New SKOSMapping without rdf:l",
            "content": "What do you think of this sort of thing ....\n\n<soks:Concept rdf:about=\"#A\">\n<soks-map:exactMatch>\n<soks-map:AND>\n<soks-map:member parseType=\"collection\">\n<soks:Concept rdf:about=\"#B\"/>\n<soks:Concept rdf:about=\"#C\"/>\n<soks-map:NOT>\n<soks-map:member>\n<soks:Concept\nrdf:about=\"#D\"/>\n</soks-map:member>\n</soks-map:NOT>\n</soks-map:member>\n</soks-map:AND>\n</soks-map:exactMatch>\n</soks:Concept>\n\n<soks:Concept rdf:about=\"#A\">\n<soks-map:broadMatch>\n<soks-map:OR>\n<soks-map:member parseType=\"collection\">\n<soks:Concept rdf:about=\"#B\"/>\n<soks:Concept rdf:about=\"#C\"/>\n</soks-map:member>\n</soks-map:OR>\n</soks-map:broadMatch>\n</soks:Concept>\n\n??\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: New SKOSMapping without rdf:l",
            "content": "Hi,\n\nLooks fine to me at first glance.\n\nA very minor improvement would be to change the name soks-map:member to \nbetter reflect that its value is a list of members e.g. socks-map:memberList.\n\nCheers,\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> What do you think of this sort of thing ....\n> \n> <soks:Concept rdf:about=\"#A\">\n> <soks-map:exactMatch>\n> <soks-map:AND>\n> <soks-map:member parseType=\"collection\">\n> <soks:Concept rdf:about=\"#B\"/>\n> <soks:Concept rdf:about=\"#C\"/>\n> <soks-map:NOT>\n> <soks-map:member>\n> <soks:Concept\n> rdf:about=\"#D\"/>\n> </soks-map:member>\n> </soks-map:NOT>\n> </soks-map:member>\n> </soks-map:AND>\n> </soks-map:exactMatch>\n> </soks:Concept>\n> \n> <soks:Concept rdf:about=\"#A\">\n> <soks-map:broadMatch>\n> <soks-map:OR>\n> <soks-map:member parseType=\"collection\">\n> <soks:Concept rdf:about=\"#B\"/>\n> <soks:Concept rdf:about=\"#C\"/>\n> </soks-map:member>\n> </soks-map:OR>\n> </soks-map:broadMatch>\n> </soks:Concept>\n> \n> ??\n> \n> Al.\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "mapping topicexchange to dmoz - testing the SKOSMapping voca",
            "content": "I've had a go at doing a mapping between some topics from the topicexchange\nsystem to categories from the open directory.  The mappings are online at\n...\n\n<http://www.w3c.rl.ac.uk/SWAD/rdf/te_dmoz_map.rdf>\n\nWhat could such a mapping be used for?  Well, for example, lets say I'm\nviewing the 'Matrix' channel on topicexchange.  There could be a link from\nthis page saying 'view relevant pages from dmoz'.  The page at the end of\nthis link could use the mapping to retrieve the pages from the dmoz\ncategories that are most relevant to the 'Matrix' topic in topicexchange.  \n\nConsidering this kind of scenario, it occurs to me that there could be a\nstrong argument for defining matches simply as a list, ordered by relevance.\nI'm going to call this an 'ordered' mapping.  So I could represent the\n'Matrix' mapping simply as ...\n\nTopic Exchange-->Open Directory\n\nThe Matrix1.  Arts/Movies/Titles/M/Matrix_Series/\n2.\nGames/Roleplaying/Genres/Science_Fiction/Matrix,_The/\n3.  Games/Video_Games/Action/E/Enter_the_Matrix/\n4.\nGames/Video_Games/Action/Massive_Multiplayer_Online/Matrix_Online,_The/\n5.  Arts/Movies/Genres/Science_Fiction_and_Fantasy/\n6.  Arts/Literature/Genres/Cyberpunk/\n\n.. rather than as ...\n\nThe Matrixnarrow-matchArts/Movies/Titles/M/Matrix_Series/\nnarrow-match\nGames/Roleplaying/Genres/Science_Fiction/Matrix,_The/\nnarrow-match Games/Video_Games/Action/E/Enter_the_Matrix/\nnarrow-match\nGames/Video_Games/Action/Massive_Multiplayer_Online/Matrix_Online,_The/\nbroad-match\nArts/Movies/Genres/Science_Fiction_and_Fantasy/\nbroad-matchArts/Literature/Genres/Cyberpunk/\n\n... which was the best 'traditional-style' mapping I could come up with.\n\nI think it would be worth having a further discussion on the 'ordered'\nversus 'traditional' mappings.\n\nAl.\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: mapping topicexchange to dmoz - testing the SKOSMapping voca",
            "content": "Interesting stuff, Al.\n\nThis probably doesn't make much sense, but...\n\nI see where you are going with 'ordered' mappings, but I wonder if your\nsolution isn't a little brittle.\nI mean, having defined 6 ordered mappings, what happens when you need\nanother, numbered say 3.5?\n\nA way round this would be to allow relationships between mappings.\nSo a mapping to Arts/Movies/Titles/M/Matrix_Series/ is 'better' than (more\nrelevant than? more specific than?) a mapping to\nArts/Movies/Genres/Science_Fiction_and_Fantasy/\n\nCheers\n\nSteve\n----- Original Message ----- \nFrom: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nTo: <public-esw-thes@w3.org>\nSent: Friday, December 05, 2003 6:04 PM\nSubject: mapping topicexchange to dmoz - testing the SKOS-Mapping vocab\n\n\n>\n> I've had a go at doing a mapping between some topics from the\ntopicexchange\n> system to categories from the open directory.  The mappings are online at\n> ...\n>\n> <http://www.w3c.rl.ac.uk/SWAD/rdf/te_dmoz_map.rdf>\n>\n> What could such a mapping be used for?  Well, for example, lets say I'm\n> viewing the 'Matrix' channel on topicexchange.  There could be a link from\n> this page saying 'view relevant pages from dmoz'.  The page at the end of\n> this link could use the mapping to retrieve the pages from the dmoz\n> categories that are most relevant to the 'Matrix' topic in topicexchange.\n>\n> Considering this kind of scenario, it occurs to me that there could be a\n> strong argument for defining matches simply as a list, ordered by\nrelevance.\n> I'm going to call this an 'ordered' mapping.  So I could represent the\n> 'Matrix' mapping simply as ...\n>\n> Topic Exchange --> Open Directory\n>\n> The Matrix 1.  Arts/Movies/Titles/M/Matrix_Series/\n> 2.\n> Games/Roleplaying/Genres/Science_Fiction/Matrix,_The/\n> 3.  Games/Video_Games/Action/E/Enter_the_Matrix/\n> 4.\n> Games/Video_Games/Action/Massive_Multiplayer_Online/Matrix_Online,_The/\n> 5.  Arts/Movies/Genres/Science_Fiction_and_Fantasy/\n> 6.  Arts/Literature/Genres/Cyberpunk/\n>\n> .. rather than as ...\n>\n> The Matrix narrow-match Arts/Movies/Titles/M/Matrix_Series/\n> narrow-match\n> Games/Roleplaying/Genres/Science_Fiction/Matrix,_The/\n> narrow-match Games/Video_Games/Action/E/Enter_the_Matrix/\n> narrow-match\n> Games/Video_Games/Action/Massive_Multiplayer_Online/Matrix_Online,_The/\n> broad-match\n> Arts/Movies/Genres/Science_Fiction_and_Fantasy/\n> broad-match Arts/Literature/Genres/Cyberpunk/\n>\n> ... which was the best 'traditional-style' mapping I could come up with.\n>\n> I think it would be worth having a further discussion on the 'ordered'\n> versus 'traditional' mappings.\n>\n> Al.\n>\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: mapping topicexchange to dmoz - testing the SKOSMapping voca",
            "content": "The ordering does look like it could make life easier for app\nimplementations, but-\n\n> I see where you are going with 'ordered' mappings, but I wonder if your\n> solution isn't a little brittle.\n> I mean, having defined 6 ordered mappings, what happens when you need\n> another, numbered say 3.5?\n\nI don't think that would be a problem, simply insert the new mapping into\nthe ordered list -the numbering isn't too important.\nBut I think there are a couple of related issues - firstly the loss of the\nabsolute relevance level (narrow-match, broad-match) might mean you end up\nwith really weak matches being given the same significance as strong ones.\nThis may not be an issue in practice - nearest is probably what you'd want\nwhile searching.\n\nThe other potential issue is how to handle the matching up the taxo trees:\n\nrelevance\n1. Arts/Movies/Titles/M/Matrix_Series/\n2. Arts/Movies/Titles/M\n3. Arts/Movies/Genres/Science_Fiction_and_Fantasy/\n4. Arts/Movies/Genres\n5. Arts/Movies/\n\n> A way round this would be to allow relationships between mappings.\n> So a mapping to Arts/Movies/Titles/M/Matrix_Series/ is 'better' than (more\n> relevant than? more specific than?) a mapping to\n> Arts/Movies/Genres/Science_Fiction_and_Fantasy/\n\nYep, that sounds like it could do the same job as the ordering in a\n(probably) more versatile fashion.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "RDF ordering question",
            "content": "Hi guys, \n\nCan I reduce the problem to the following stages:\n\nStage 1: Agree RDF encoding for 'traditional' mappings.\n\nStage 2: Agree RDF encoding for 'ordered' mappings.\n\nStage 3: Agree RDF encoding for combined ordered + traditional mappings.\n\n?\n\nHaving a crack at stage 2, would something like the following be sufficient\n[option 1] ...\n\n<rdf:Description rdf:about=\"#A\">\n<soks-map:orderedMapping>\n<rdf:Seq>\n<rdf:_1 rdf:resource=\"#B\"/>\n<rdf:_2 rdf:resource=\"#C\"/>\n<rdf:_3 rdf:resource=\"#D\"/>\n<rdf:_4 rdf:resource=\"#E\"/>\n</rdf:Seq>\n</soks-map:orderedMapping>\n</rdf:Description>\n\n... ?  I mean does this fall foul of Steve's numbering problem, or is it\nsimple enough for the numberings to be redefined if another concept is to be\ninserted into the list?\n\nOr am I right in understanding that if you use the attribute\nparseType=\"collection\" on a property, the ordering of the members is\npreserved when the serialised statements are compiled into a graph?  So then\nthe following would also do the job (and dodges the numbering\nproblem)[option 2] ...\n\n<rdf:Description rdf:about=\"#A\">\n<soks-map:orderedMapping parseType=\"collection\">\n<rdf:Description rdf:about=\"#B\"/>\n<rdf:Description rdf:about=\"#C\"/>\n<rdf:Description rdf:about=\"#D\"/>\n<rdf:Description rdf:about=\"#E\"/>\n</soks-map:orderedMapping>\n</rdf:Description>\n\n?\n\nAl.\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Danny Ayers\n> Sent: 08 December 2003 09:34\n> To: Steve Cayzer; Miles, AJ (Alistair) ; public-esw-thes@w3.org\n> Subject: RE: mapping topicexchange to dmoz - testing the SKOS-Mapping\n> vocab\n> \n> \n> \n> The ordering does look like it could make life easier for app\n> implementations, but-\n> \n> > I see where you are going with 'ordered' mappings, but I \n> wonder if your\n> > solution isn't a little brittle.\n> > I mean, having defined 6 ordered mappings, what happens \n> when you need\n> > another, numbered say 3.5?\n> \n> I don't think that would be a problem, simply insert the new \n> mapping into\n> the ordered list -the numbering isn't too important.\n> But I think there are a couple of related issues - firstly \n> the loss of the\n> absolute relevance level (narrow-match, broad-match) might \n> mean you end up\n> with really weak matches being given the same significance as \n> strong ones.\n> This may not be an issue in practice - nearest is probably \n> what you'd want\n> while searching.\n> \n> The other potential issue is how to handle the matching up \n> the taxo trees:\n> \n> relevance\n> 1. Arts/Movies/Titles/M/Matrix_Series/\n> 2. Arts/Movies/Titles/M\n> 3. Arts/Movies/Genres/Science_Fiction_and_Fantasy/\n> 4. Arts/Movies/Genres\n> 5. Arts/Movies/\n> \n> > A way round this would be to allow relationships between mappings.\n> > So a mapping to Arts/Movies/Titles/M/Matrix_Series/ is \n> 'better' than (more\n> > relevant than? more specific than?) a mapping to\n> > Arts/Movies/Genres/Science_Fiction_and_Fantasy/\n> \n> Yep, that sounds like it could do the same job as the ordering in a\n> (probably) more versatile fashion.\n> \n> Cheers,\n> Danny.\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: RDF ordering question",
            "content": "Hi Alistair,\n\n> Can I reduce the problem to the following stages:\n> \n> Stage 1: Agree RDF encoding for 'traditional' mappings.\n> \n> Stage 2: Agree RDF encoding for 'ordered' mappings.\n> \n> Stage 3: Agree RDF encoding for combined ordered + traditional mappings.\n> \n> ?\n\nI guess. Though one approach to prioritizing the mappings would be to add \npriority or distance metrics to the \"traditional\" mappings (i.e. skip stage 2).\n\n> Having a crack at stage 2, would something like the following be sufficient\n> [option 1] ...\n> \n> <rdf:Description rdf:about=\"#A\">\n> <soks-map:orderedMapping>\n> <rdf:Seq>\n> <rdf:_1 rdf:resource=\"#B\"/>\n> <rdf:_2 rdf:resource=\"#C\"/>\n> <rdf:_3 rdf:resource=\"#D\"/>\n> <rdf:_4 rdf:resource=\"#E\"/>\n> </rdf:Seq>\n> </soks-map:orderedMapping>\n> </rdf:Description>\n> \n> ... ?  I mean does this fall foul of Steve's numbering problem, or is it\n> simple enough for the numberings to be redefined if another concept is to be\n> inserted into the list?\n\nThe critical thing here is how semantic *webby* you are trying to make \nthings. If all the orderings are defined in a single mapping file then this \nis a perfectly reasonable way of representing order (though I still prefer \nparseType=\"collection\" as you suggest below). However, in a semantic web \napplication you might want to be able to merge mappings generated by \ndifferent sources. In that case you have no way to merge the Seqs.\n\n> Or am I right in understanding that if you use the attribute\n> parseType=\"collection\" on a property, the ordering of the members is\n> preserved when the serialised statements are compiled into a graph?  \n\nYes.\n\n> So then\n> the following would also do the job (and dodges the numbering\n> problem)[option 2] ...\n> \n> <rdf:Description rdf:about=\"#A\">\n> <soks-map:orderedMapping parseType=\"collection\">\n> <rdf:Description rdf:about=\"#B\"/>\n> <rdf:Description rdf:about=\"#C\"/>\n> <rdf:Description rdf:about=\"#D\"/>\n> <rdf:Description rdf:about=\"#E\"/>\n> </soks-map:orderedMapping>\n> </rdf:Description>\n\nDoes the job - yes.\n\nPreferable over Seq (IMHO) because it makes it clear that this is a closed \nlist and some application-specific logic will be needed to perform merging \nof multiple orderedMappings.\n\nDodges the numbering problem - no. It makes the problem clear but it \ndoesn't dodge it. Fine in a closed system, possibly problematic in an open \nsystem.\n\nAn alternative would be to define a semanticDistance relation and derive \nordering from that:\n\n#A soks:semanticDistanceFrom [\n      a DistanceMetricUsingAlgorithmFooBar;\n      soks:mappedConcept #B;\n      soks:distance  4.67^^xsd:float;\n      soks:baseRelation soks:narrowerTerm] .\n\nThat way you can still capture inclusion information such as narrowerTerm \nbut can order the mappings by distance for any mappings which uses a \nconsistent metric and so can merge multiple mappings together. In practice \nthese distances might often be heuristically derived (i.e. guessed) and so \nnot strictly comparable but at least you have more flexibility. In some \napplications you could, in fact, define real combinable metrics - for \nexample, based on a database of past user query terms and desired results.\n\n[BTW I didn't think very deeply in constructing that example. There are \nlots of small design choices. You could make the baseRelation a super \nproperty of the semanticDistanceFrom property rather than an attribute of \nthe reified representation. You could replace soks:distance by a property \nspecific to the distance algorithm rather than rely on the type of the \nreified relation to carry that information.]\n\nJust a thought.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Where do OWL and SKOS meet",
            "content": "Hi all\n\nI'm disliking the blurriness of ontologies versus thesaurus/other KOS \ndistinctions in some of the discussion on this list. For me its what leads \nto those questions about whether/where we should be using OWL to represent \nthesaurus/KOS concept relations.  I feel we need to tackle such \ndistinctions asap and I want to attempt to clarify what we are aiming to \nachieve in terms of the 20 mile high view of the problem space.\n\nI present here an effort towards this clarification in terms of questions \nand answers and would be very grateful if you have the time to pick through \nthese with me & correct me/affirm as appropriate.\n\nPlease note that I'm particularly alert to section 3.2 Context-induced \nambiguity of http://jodi.ecs.soton.ac.uk/Articles/v01/i08/Doerr/  (a \nreference from Alistair Miles).  It's the bit that's troubling me in \nrelation to using RDF to express knowledge.\n\n\n*QUESTION 1:\nWhat are we trying to do with the thesauri & general KOS out there?\nDo we want to use them as controlled vocabulary assistance for  RDF \nauthors/applications that try to find/map suitable rdf Literal values (for \nvarious arbitrary rdf properties),\nOR\ndo we want to migrate thesauri completely and totally to ontologies (i.e. \nin order to use them for the *typing* of rdf resources)?\n\n*ANSWER 1: I think we might want to use them in some cases for one or the \nother, and in some cases for both.\nExplanation: I think some thesauri migrate \"well\" to ontologies e.g. \nthesauri for museum objects (or biological species). Why? Because they \nalready tend to be talking about \"things\" (& their properties) & therefore \n'fit' well with the OWL ontology way of describing the world. \n(object-oriented).\nBut other thesauri/parts of thesauri may not fit well with this \nobject-oriented view of the world, because they are about more abstract \nconcepts (see answer 2 below). This has already been discussed on this list.\n\n\n*QUESTION 2: But am I right in assuming OWL ontologies are for *typing* rdf \nresources? Are they only for that or do people use ontologies for providing \nrdf Literal values for any arbitrary properties?\n\n*ANSWER 2: Well, OWL is for defining owl classes & their properties in the \nmain, right?, and owl classes have extensions that are always a set of \n'things'. So this lends itself best to typing information for rdf:resources.\nExamples: So \"colour\" can be an owl thing, but \"white\" is an owl individual \n(i.e. a member of the set of \"colour\"s).\nAnd \"farm\" is an owl class (the 'type' of some property for sale for e.g.), \nbut \"agriculture\" (in the sense that it means \"farming\") is neither an owl \nindividual or an owl class - it's a thesaurus term right? a concept in the \nEnglish language. It's unlikely it \"belongs\" in an ontology because it's \nunlikely someone would want to state an rdf:resource as being of <rdf:type> \n= 'farming'. (they'd be more likely to want to state that the <subject> \nproperty of some rdf:resource has the value 'farming', say, or that some \nresource of type person has <interests> = \"farming\" and so on.)\n\n\n*QUESTION 3: Given the above position, what are our overall requirements \nfor a thesaurus specification in RDF?\n\n*ANSWER 3:\n\ni) We want to be able to formally & syntactically express relationships \nbetween thesaurus concepts in rdf *independently* of the way we express \nontological relationships.\nWhy?\nEXPLANATION: Because we want to express the relationships in what I'll call \n\"typing information\" (that encapsulated in OWL ontologies) separately from \nthe relationships between concepts which are not used for typing \ninformation.\nWhy?\nbecause otherwise computers/users of/information on the network will likely \nbecome confused about the meaning of things - context confusion beware!\nNOTE HOWEVER:\nthat it's easy to get confused here because the 'mode of' expression of \nrelationships for thesauri/KOS *overlaps* with that for ontologies. i.e. \ntyping information uses \"broader than\" \"narrower than\" & set relations for \ndescribing classes of things.\nAnd in many cases we want to use this same approach for KOS's as well - \nbecause concepts too can be related by such relations.\n\nii) We also want to be able to *link* thesaurus concepts to ontology \nclasses - i.e. where the context of thesaurus concepts is clearly linked to \nthe class of objects which are being described with the assistance of these \nthesaurus-defined concepts.\nWhy?\nE.g. because if *parts* of a well-known, useful thesaurus can be migrated \nto an ontology then we might want to express that - i.e. break a well-known \nthesaurus out into its ontological & thesaurus composite parts.\nSo we need 'hooks' if you like, to join\ncontrolled vocabularies that can supply values for rdf:Literals\nwith\nontologies that supply values for rdf resource typing.\n\ne.g.\n\n<owl:Class rdf:ID=\"Wine\">\n<rdfs:subClassOf>\n<owl:Restriction>\n    <owl:onProperty rdf:resource=\"&dummy:wine_type\"/>\n    <owl:hasValue rdf:resource=\"#dry white\"/>\n    <rdfs:subClassOf rdf:parseType=\"resource\">\n       <owl:intersectionOf rdf:parseType=\"collection\">\n          <owl:Restriction>\n             <owl:onProperty rdf:resource=\"&dummy:colour\"/>\n             <owl:hasValue rdf:resource=\"#white\"/>\n          </owl:Restriction>\n          <owl:Restriction>\n             <owl:onProperty rdf:resource=\"&dummy:sweetness\"/>\n             <owl:hasValue rdf:resource=\"#dry\"/>\n          </owl:Restriction>\n       </owl:intersectionOf>\n    </rdfs:subClassOf>\n </owl:Restriction>\n  </rdfs:subClassOf>\n</owl:Class>\n\nExplanation: A rather silly e.g. but what I'm trying to show is that \nAlistair's examples that demonstrate how we can use OWL set relations to \nmap thesaurus terms (e.g. 'dry white') to other terms ('dry' and 'white') \nare very helpful. But IMO we can only use this modelling in the case where \nwe want to talk about thesaurus terms *in relation to* owl classes. When we \ncan't/don't want to, then we need 'pure' skos modelling to support rdf \nrepresentation of abstract concepts.\n\n\niii) We importantly want to express *additional* relationships for thesauri \nin RDF.  e.g. part of relationships, which are not the same as isa \nrelationships (because thesauri/KOS typically have a number of different \nsubsumption relationships for concepts). And that's why Alistair is \ntackling the issue of building SKOS vocabularies and mechanisms for concept \nrepresentation.\n\nSo, to conclude, what I am wanting to explicitly state is that these are \ntwo connected, but distinct classes of problem:\n- the expression of ontologies in RDF (i.e. classes, their properties & how \nthese relate to each other)\n- the expression of thesauri/other KOS in RDF (i.e. abstract concepts and \nhow these relate to each other - and even how they relate to OWL classes \netc.)\n\nDo you agree?\nApologies for verbosity.\n\nNikki\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: [Fwd: Shared Key Authentication for the TLS Protocol&ndash;&ndash; an Alternative",
            "content": "Dan,\n \nSSL embodies two peer-entity authentication mechanisms todate, which exploit\nthe properties of the ciphers classes (RSA and DH) upon which they depend. Both require\nthat they are part of SSL's handshake. By design, **NO** SSL data is encrypted\nor explicitly integrity protected prior to the completion of SSL handshake. One\ncannot expect a trusted site to export sensitive data via an single level\n(or multi level!) encryption device until the peer-entity authentication  has\ncompleted. Peer entity authentication (w/ client auth and RSA) can establish the\ncomplete access control policy for the channel (by exchanging each sides labels), and\ntherefore client authentication must occur proir to any user-data exchange.\n\nComplete SSL public key authentication must occur within the handshake, or\nSSL's flexiblity to support mandatory access control is weakened/eliminated.\nThe service seeks to implement I.3.2.2.1 of the TNI to TCSEC, while recognising\nthat  - with TCP transports - the connection has already been\nestablished to some degree prioir to SSL being engaged, and is consuming\nresources. So SSL implements TNI connection control, loosely.\n\nAny alternative *SSL* authentication service must be performable within the handshake, and\nnot require encryption.The only real reason to invest in a new mechanism\nis because a some new interesting class of cipher exists which needs some help\nin the handshake messages so as to expoit its authentication properties. (SSL\nmulticast authentication I believe will be a case in point, one day)\n\nFor example, if I used a TYPE I algoirhtm which matched RSA properties,\nI would not expect to change SSL except to introduce a new cipherSuite.\nIf I used Type II KEA which is related to DH, I would not expect to change SSL;\nrather, Id just introduce a new cipherSuite. If we use Elliptic,\nCurves, again there is nothing new in any of these algoirhtms which changes\nSSL.\n\nI dont believe TLS should allow any encryption, other than via public key exchange,\nduring the handshake. \n\nShould TLS services (with more advanced handshaking) allow for selective \"sub-stream\"\nencryption, to support various access control policies within the user-data stream.\nI.E. the socket service will arrange shared access to data of type 1, not not control access to\ntype 2, by agreeing multiple MEKs and security contexts?\n\nIm not so arrogant as to deny the general utility of such a sub-stream access control\nenforcement policy. However, the architectural difference between this\nand what SSL was designed to do is so large that I would not\nintroduce such facilities on the basis of enabling an additional authenticaiton\nprocedure which demand such capabilities of the data stream, because of its\nvulnerabilities.\n\nSSL protects the socket - or service access point. The SSL protodol should not\nconventionally be knowing what sensitivity of various user data is present through the channel. It\nis designed to simply agree the security services TSAP to TSAP, and then apply\nthe relevant mechanisms stupidly (but safely). The application is in control\nof the security context, and its reasons for any change, for privacy reasons.\n\nWhy cannot we merely register a cipherSuite whose semantics are: do strong encrytion\nfor the first n bytes of user data; having performed a handshake. The server must then authenticate\nthe n bytes of shared-secret authentication from the user-stream, and perform a new handshake if\nit accepts the access control policy.  The server may choose to require client authentication,\nand mandatory access control estbalishment upon completeion of the first handshake, if\nthats its policy.\n\nPeter.\n\n\n\n\nFrom Dan:\n\nSimilarly, public-key-based client authentication does not have to be in\nSSL/TLS either, since it could easily be layered on top of it.  An\nadvantage of incorporating it into the protocol is, as Peter points out,\ninteroperability.  Exactly the same argument applies in the case of\nshared-key-based authentication; a single, non-proprietary\nshared-key-based authentication standard embedded in TLS (which is what\nour proposal provides) allows independent client-builders and\nserver-builders to implement shared-key authentication interoperably. \n\nThere is another justification for this incorporation in the case of\nshared-key authentication that does not apply in the case of public-key\nauthentication:  if for any reason the channel used is not strongly\nencrypted, and the shared key being used for authentication is guessable\n(as is often the case for user-remembered passwords), then any fully\nlayered solution will be vulnerable to brute-force offline attacks.\nIncorporating the authentication protocol into TLS allows a special\nexception to be made for the authentication data, strongly protecting it\neven if the normal traffic is not strongly encrypted.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n\n\n>\n\n\n\n"
        },
        {
            "subject": "SWADe and thesaur",
            "content": "A web page on the SWAD-e activity on thesauri is available at:\n\nhttp://www.w3c.rl.ac.uk/SWAD/thesaurus.html\n\nMichael Wilson\nBusiness and Information Technology Department   tel: +44 (0)1235 44 6619\nCLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\nChilton, DIDCOT, Oxon, OX11 0QX, UK             \n\nWWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n\nThe contents of this email are sent in confidence for the use of the\nintended recipients only.  If you are not one of the intended recipients\ndo not take action on it or show it to anyone else, but return this\nemail to the sender and delete your copy of it\n\n\n\n"
        },
        {
            "subject": "a deal, &quot;Lel Bruce Peto&quot; update, for RFG unleaded in..",
            "content": "a deal, \"Lel Bruce Peto\" update, for RFG unleaded in New York has been done \nin the range of 15-16 cents over the print, putting the price in the low \n90s. Prices are very strong with two majors wanting barrels.\nIn the Gulf Coast conventional unleaded has moved at 3 cents over the \nscreen, or close to 80 cents per gallon. There is some buying interest to \nship barrels into the Midwest and Southwest...as of 11-01-02...\n\n\n\n"
        },
        {
            "subject": "Recommended oil sector 70's chronology by &quot;Lel Bruce Peto&quot;..",
            "content": "Recommended oil sector 70's chronology by \"Lel Bruce Peto\"...\n\nOil & Gas Chronology :  The 1970?s\n\n\n1977\nJan \n\nOPEC goes to two-tier pricing (Saudi Arabia and United Arab Emirates use \n$12.09 per barrel and other OPEC countries use $12.70per barrel).\n\nMay \n\nFifty percent of Saudi Arabia's 10 MMB/D production is halted briefly due \nto fire damage to separation facility in Abqaiq field. Prices increase \nslightly.\n\nJul \n\nOPEC prices reunified at $12.70 per barrel as Saudi Arabia and UAE fall \ninto line, then official price rises to $13.66 per barrel. \n\nOct 23 \n\nDry dock complex opens at Bahrain; only facility between Portugal and \nSingapore capable of servicing VLCCs. \n\n\n\n"
        },
        {
            "subject": "New Public mailing list - public-esw-thes  maintained by Dan Brickle",
            "content": "Maintaing Activity:  Semantic Web Activity[1]\n\nList Purpose:  This list is for project participants and collaborators in\nthe SWAD-Europe[2] project's work on RDF and Thesaurus systems. This is\nwork is in support of the Semantic Web Activity[1] at W3C and closely\nlinked to the discussions of the RDF Interest Group[3].\n\nReference:  SWAD-Europe\n\n\n\n1.  http://www.w3.org/2001/sw\n2.  http://www.w3.org/2001/sw/Europe/\n3.  http://www.w3.org/RDF/Interest/\n\n\n\n"
        },
        {
            "subject": "November no lead moving 2.54cts gal &quot;Lel Bruce Peto&quot; updates at.",
            "content": "November no lead moving 2.54cts gal \"Lel Bruce Peto\" updates, at \n79.5cts gal, and front heating oil are 2.17cts gal lower at \n77.25cts. Spot gasoline prices remain strong in both trading regions. \nAlthough Chicago conventional no lead has backed off 3.0cts gal to 91.5cts \ngal, price is up 4.5cts gal this week in the Windy City market. Regular no \nlead in the Group has traded at a 11cts gal basis premium to the screen \ndown 2.5cts gal to an implied 90.5cts gal..as of 10-10-02... \n\n\n\n"
        },
        {
            "subject": "Re: RDF Thesaurus  Unresolved Design Issue",
            "content": "Hi Alisatir,\n\ngreat move. I've started to look through the followup messages and will send\nsome commments through the week...\n\ncheers\n\nChaals\n\nOn Fri, 31 Oct 2003, Miles, AJ (Alistair)  wrote:\n\n>\n>Hi everyone,\n>\n>I've started a writeup and discussion of unresolved design issues regarding\n>the RDF thesaurus work.  It's on the SWAD wiki\n><http://esw.w3.org/topic/RdfThesaurus>.  Nikki, Dave B., Danbri, Dave R.,\n>Andy, Libby, Chaals, Steve C, Paul, Brian, Ian, Alvaro, everyone in SWAD, it\n>would be great if you could get involved, I could really do with some\n>feedback and a bit of your expertise.\n>\n>I'll post a short summary to the public-esw-thes list when I add any new\n>issues to the wiki, so please keep an eye out.\n>\n>Yours,\n>\n>Alistair.\n>\n>\n>CCLRC - Rutherford Appleton Laboratory\n>Building R1 Room 1.60\n>Fermi Avenue\n>Chilton\n>Didcot\n>Oxfordshire OX11 0QX\n>United Kingdom\n>\n>Email:        a.j.miles@rl.ac.uk\n>Telephone: +44 (0)1235 445440\n>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Reference by description: blank node",
            "content": "Dan Brickley wrote:\n\n> * Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-10-29 18:21-0000]\n> \n>>Cheers Dan.\n>>\n>>Can we cope with the situation where a B-Node may be uniquely identified not\n>>by a single property, but by a combination of two (or more) properties?\n>>\n>>e.g. Concepts uniquely identified by a combination of soks:prefLabel and\n>>rdfs:isDefinedBy properties.\n> \n> \n> I'm not sure how to do that in OWL, or even whether it is possible.\n\nI don't believe it is possible in OWL. In general OWL is quite limited in what \nit can do with cross-property constraints.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: Exploring reference by description for concepts",
            "content": "Hi Alistair,\n\n> At the last SWAD-E technical meeting it was suggested that rather than give\n> each concept in a thesaurus a URI, we could use reference by description.\n> So we could have thesaurus data that looks like:\n> \n> <soks:Concept>\n> <soks:prefLabel>bangers and mash</soks:prefLabel>\n> <rdfs:label>bangers & mash</rdfs:label>\n> <rdfs:label>sausage and mash</rdfs:label>\n> <rdfs:isDefinedBy\n> rdf:resource=\"http://www.bigal.com/alsfoodthesaurus\"/>\n> </soks:Concept>\n\nI'd be inclined to have a URI label:\n     <soks:hasURI rdf:resource=http://www.bigal.com/alsfoodthesaurus/bandm\" />\n\nThe point being that the same concept might be defined in several ontologies \nwith different URIs. Then the hasURI can be an InverseFunctionalProperty whereas \nprefLabel is only unique relative to a specific thesaurus.\n\nThe value of this over simply letting each thesaurus define its own URI and \nadding separate owl:sameAs statements is possibly not that great.\n\nCheers,\nDave\n\n\n\n"
        },
        {
            "subject": "FW: [Fwd: Shared Key Authentication for the TLS Protocol&ndash;&ndash; anAlternative",
            "content": ">\n>From: Jeff Williams[SMTP:jwkckid1@ix.netcom.com]\n>\n>  I suppose this would partly be a response to what Peter has rightly\n>pointed out.  I guess where I get confused is how does this address in\n>total, address standardazation of winsock's? \n>\n>If two Winsock implementations support TLS, and TLS includes shared-key\n>client authentication, then they would be able to do shared-key client\n>authentication interoperably.  If you're thinking about APIs rather than wire\n>formats, then a standardized API for shared-key authentication is no trickier\n>to come up with than one that handles public-key authentication--it's just\n>that this working group explicitly decided to avoid discussing APIs in its\n>hoped-for standard.\n>\n>>\n>>There is another justification for this incorporation in the case of\n>>shared-key authentication that does not apply in the case of public-key\n>>authentication:  if for any reason the channel used is not strongly\n>>encrypted, and the shared key being used for authentication is guessable\n>>(as is often the case for user-remembered passwords), then any fully\n>>layered solution will be vulnerable to brute-force offline attacks.\n>>Incorporating the authentication protocol into TLS allows a special\n>>exception to be made for the authentication data, strongly protecting it\n>>even if the normal traffic is not strongly encrypted.\n>\n>  Does this special exception for authentication data provide for\n>interoperability?\n>\n>Certainly.  It would occur automatically and transparently--\"under the\n>covers\", as it were.  No need for API changes, for example.\n>\n>\n>Daniel Simon\n>Cryptographer, Microsoft Corp.\n>dansimon@microsoft.com\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Design Issues (1)  Specialised vocab vs. extensible modular  voca bs",
            "content": "Hi,\n\nI can't access the Wiki at the moment, and in any case don't know how you want \ncomments, so I'll stick to email.\n\nBy KOS do you mean \"Knowledge Organization Scheme\"?\nWhat does that cover? Are you including ontologies in there?\n\nIf the answer to the last question is \"yes\" then I suggest avoiding 3. A common \ncore for all different thesaurus and ontology schemes is in danger of being so \ngeneric as to be little more than raw RDF(S).\n\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> I've added this issue to the discussion on the RDF Thesaurus wiki page\n> <http://esw.w3.org/topic/RdfThesaurus>\n> \n> Here is a summary:-\n> \n> \n> Issue 1 - Specialised vocab vs. extensible modular vocabs?\n> \n> \n> Although most thesauri are pretty similar, there are important variations,\n> and many thesauri deviate from the standards. Also, thesauri are very\n> similar to other KOS e.g. classification schemes, taxonomis, topic maps. How\n> do we cope with this? \n> \n> Option 1 - Define a specialised vocabulary that covers only thesauri that\n> comply with the standards. \n> \n> Option 2 - Define a core vocab that captures what is common to all thesauri.\n> Then define extension modules to cope with different flavours of thesauri. \n> \n> Option 3 - Define a core vocab that captures what is common to all KOS\n> (thesauri, taxonomies, classification schemes, topic maps etc.). Define\n> first level extension module for thesauri. Define second level extension for\n> flavours. \n> \n> === Comments on Issue 1 === \n> \n> AJM>> \n> \n> What we did previously ( [WWW]early draft of 8.1\n> <http://www.w3c.rl.ac.uk/SWAD/deliv81.htm>) was half way between (1) and\n> (2). \n> \n> I would like to go for (3), but am prepared to backtrack towards (2), which\n> may happen when we hit interop with this and OWL. (3) Would mean we have a\n> way of fitting all these KOS together on the semantic web, which would be a\n> good thing. \n> \n> Going for (3) means we have to define a core vocab. I've kind of assumed\n> this is what we are doing (tell me if you think it's a bad idea), and issues\n> below relate first to this core vocab. We need a name for this core vocab,\n> so at least we can refer to it. For now, I'm going to call it the core\n> vocab. In code, I'm using the prefix soks. Why soks? Short for SuperKOS! Got\n> any ideas about a better name? \n> \n> \n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (2)  To concept or not to concep",
            "content": "I'd suggest option 1.\n\nThe open world approach of RDF means that you can take any resource and decide \nlater that it is of rdf:type soks:Concept. So this doesn't prevent you using the \nTBL fragment identifier convention for concepts and have some processor deduce \nthat these must be soks:Concepts.\n\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> I've added this issue to the discussion on the RDF Thesaurus wiki page\n> <http://esw.w3.org/topic/RdfThesaurus>\n> \n> Here is a summary:-\n> \n> 2.2 Issue 2 - To concept or not to concept\n> \n> \n> A thesaurus is a collection of concepts. So for the core-vocab we need to\n> model abstract concepts in RDF. \n> \n> Option 1 - We define an rdfs:Class called soks:Concept. We use this to type\n> resources that are intend ed to refer to abstract concepts. \n> \n> Option 2 - We define no such class. We use some other way to determine\n> whether a resource is a concept or not, if at all we need to. \n> \n> === Comments on Issue 2 === \n> \n> AJM>> \n> \n> At the recent SWAD meeting at HP, Chaals said (correct me if I'm wrong) in\n> RDF every resource with a URI that has a fragment identifier necessarily is\n> an abstract concept. Therefore we don't need a type for concepts. \n> \n> I say: \n> \n> 1.My reading of the debate & TimBL's writeups is that resources with a\n> <http://> uri and a frag id MAY (but NOT necessarily) refer to an abstract\n> concept. Resources with a <http://> uri and without a frag ID may NOT be an\n> abstract concept (must necessarily be a document). \n> 2.If we have a soks:Concept class, we can type b-nodes as concepts. So\n> we can use reference by description to make statements about abstract\n> concepts without URIs. \n> 3.It makes the format look nicer if it starts with 'Concept' rather\n> than 'rdf:Description' all the time. This may be a serious point for KOS &\n> DL people. \n> \n> \n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: Design Issues (1)  Specialised vocab vs. extensible modular  voca bs",
            "content": "Yup, sorry the Wiki is down again. We had some load problems \n(bad code in MoinMoin python; it loaded a huge log file on \neach pageview) which are now fixed. However the machine crashed \nfor as yet undetermined reasons recently. Possibly because it \nhas a miniscule amount of RAM (will have 1G soon). I had expected \nit to be back up by now, should be ok later today I'd guess.\nAm investigating.\n\nSorry for the inconvenience...\n\nDan\n\n\n\n"
        },
        {
            "subject": "8.1 change of title: Core vocabularies for monolingual thesaur",
            "content": "Hi guys, \n\nThe previous title of 8.1 was\n\n'RDF Schema for ISO Standard Thesauri'\n\nThe big problem I've had with trying to write this up is that the schema in\nthat document tries to deal with multilingual as well as monolingual\nthesauri.  So it preempts the discussion of multilingual thesauri which is\nsupposed to come in 8.3.  It also preempts a discussion of interthesaurus\nmapping, which is supposed to be in 8.4.\n\nI propose to change the title of 8.1 to \n\n'Core RDF Vocabularies for Monolingual Thesauri'\n\nand present a core solution to the monolingual thesaurus problem.  Save a\ndiscussion and analysis of the multilingual problem for 8.3.\n\nTo give you an idea of where I'm going with this, take a look at \n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.1_0_3.html\n\nAlso please note the section on 'Using Thesaurus Concepts for Subject\nIndexing and Classification'.  What I've tried to do is design a schema for\nthesauri that fits seamlessly with what dublin core and LOM are doing re\nsubject classification.\n\nBrian I know you're keen to move this along, but I think it's really worth\nmaking sure what we've got fits with things like RDFS, dublin core and LOM\nbefore going public.  If you like this direction, I can have this ready for\nsubmission by next week.\n\nYours,\n\nAlistair.\n\nRefs:\n\nExpressing qualified dublin core in RDF/XML\nhttp://dublincore.org/documents/dcq-rdf-xml/\n\nRDF Binding of LOM metadata  http://kmr.nada.kth.se/el/ims/metadata.html\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Thesaurus AP",
            "content": "Not going near the multilingual problem yet, I suggest this for a core API -\n\n\ngetConcept(URI uniqueidentifier)\n\ngetConcept(Literal descriptor, URI thesaurus)\n\ngetConcept(Literal externalID, URI thesaurus)\n\n--> Returns a single 'Concept' datastructure, including all the\nlabels.\n\n\nmatchConcepts(String regularExpression)\n\nmatchConcepts(String regexp, URI thesaurus)\n\n--> Returns a list of possible concepts, ordered according to\nlikelihood of match\n\n\ngetSupportedSemanticRelations()\n\ngetSupportedSemanticRelations(URI thesaurus)\n\n--> Return a list of supported semantic relations (e.g. broader,\nnarrower, is-a, etc.), each with a unique uri and a description of their\nmeaning.\n\n\ngetConceptRelatives(URI conceptURI)\n\ngetConceptRelatives(Literal descriptor, URI thesaurus)\n\ngetConceptRelatives(Literal externalID, URI thesaurus)\n\ngetConceptRelatives(URI conceptURI, SemanticRelation rel)\n\ngetConceptRelatives(Literal descriptor, URI thesaurus, SemanticRelation rel)\n\ngetConceptRelatives(Literal externalID, URI thesaurus, SemanticRelation rel)\n\n--> Returns list of relatives of concept as specified.   \n\n\nThis API is designed to be consistent with the way thesaurus data is\nmodelled in the schemas in \n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.1_0_3.html\n\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (3)  How to label concepts",
            "content": "It makes sense to me to build on top of rdfs:label so that general RDFS \nprocessors can pick up the labels.\n\nThus:\n     rdf:label  (domain = Resource, range = Literal)\n       ^\n       |\n     soks:label (domain = soks:Concept)\n       ^\n       |\n     soks:preferredLabel\n\nKeeping the range as Literal is useful since that's the only bit of RDF that \nsupports xml:lang.\n\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> I've added this issue to the discussion on the RDF Thesaurus wiki page\n> <http://esw.w3.org/topic/RdfThesaurus>\n> \n> Here is a summary:-\n> \n> Issue 3 - How to label concepts?\n> \n> In a thesaurus, every concept has one preferred term (label) and 0 or more\n> alternative terms. \n> \n> The obvious way to model this in RDF is to have one property for linking a\n> resource to a preferred label (I'll call this soks:prefLabel for now) and\n> one property for linking a resource to any alternative labels (I'll call\n> this soks:altLabel for now). \n> \n> This raises two design questions:- \n> \n> Question 1: domain restriction? - Do we (a) restrict the domain of these\n> properties to soks:Concept or do we (b) allow them to be used with any\n> resource? \n> \n> Question 2: resources or literals? - Do we (a) restrict the range of these\n> properties to rdfs:Literal, or do we (b) restrict the range to some type of\n> resource? \n> \n> We may be able to re-use and/or extend existing properties, e.g. rdfs:label,\n> but what we choose to re-use depends on the resolution of these questions,\n> so I'm saving a discussion of that for later. \n> \n> The choice of solution to question 2 has important implications for\n> multilingual data and labelling ...\n> \n> ... more at <http://esw.w3.org/topic/RdfThesaurus>\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: Design Issues (1)  Specialised vocab vs. extensible modular               voca bs",
            "content": "Hi Alistair\n\n(just got back from holiday - wiki looks good btw)\n\nDave asked:\n\n> By KOS do you mean \"Knowledge Organization Scheme\"?\n> What does that cover? Are you including ontologies in there?\n\nI'm still fuzzy on what we mean by ontologies. My understanding of \nontologies for the semantic web is that one of their key utilities will be \nto provide a kind of umbrella 'knowledge representation' layer into which \nwell developed, existent thesauri/other KOS's may be federated at key \npoints. That is as well as ontologies being developed independently for \nclassifying resources as per the requirements of specific user communities \nI guess. So that ontologies are very good for describing 'things' and \nrelationships between things - which is great for describing resources on \nthe network, & the relationship of those resources to each other and also \nreal-world \"things\". So, ontologies are to provide us with rigorous and \nconsistently applied resource description for the web, in contrast to the \nways that thesauri/other KOS's often use inconstent/differing notions of \nsubsumption, for example, in representing knowledge?\n\nI'm waffling here & would like to invite someone to clarify things for me! \nBack to Alistair's issues:\n\nAs regards the options 1 2 & 3 you have stated for Design Issue 1:\n\n- I think option 1 is out because it is pretty restricted in scope, given \nthat there are many legacy & evolving KOS' that will be usefully employed \nin the semantic web.\n\n- I understand your dilemma between option 2 & 3 to be whether to keep WP8 \nthesauri-centric, or whether to start at a more generic place and work on \nfrom there, extending the core vocabulary specifically for thesauri & also \nthe range of other existent KOS's (also permitting the ease of integration \nwith ontologies).\nI see Andy's argument about the dangers of straining to be as generic as \npossible.\nI kind of feel I need an analysis of what problems Option 2 would create \nw.r.t. trying to map thesauri to other KOS's & ontologies using a WP8 core \nvocabulary. i.e. what do taxonomies, classification schemes, topic maps \netc. use in their representation that we would be lacking if we stick to a \ncore vocabulary centred on thesauri only?\n\nI'll need to do some more reading around this issue ...\n\nRegards\nNikki\n(soks is cool with me btw)\n\n--On 04 November 2003 10:48 +0000 Dave Reynolds <der@hplb.hpl.hp.com> wrote:\n\n>\n> Hi,\n>\n> I can't access the Wiki at the moment, and in any case don't know how you\n> want comments, so I'll stick to email.\n>\n> By KOS do you mean \"Knowledge Organization Scheme\"?\n> What does that cover? Are you including ontologies in there?\n>\n> If the answer to the last question is \"yes\" then I suggest avoiding 3. A\n> common core for all different thesaurus and ontology schemes is in danger\n> of being so generic as to be little more than raw RDF(S).\n>\n> Dave\n>\n> Miles, AJ (Alistair) wrote:\n>\n>> I've added this issue to the discussion on the RDF Thesaurus wiki page\n>> <http://esw.w3.org/topic/RdfThesaurus>\n>>\n>> Here is a summary:-\n>>\n>>\n>> Issue 1 - Specialised vocab vs. extensible modular vocabs?\n>>\n>>\n>> Although most thesauri are pretty similar, there are important\n>> variations, and many thesauri deviate from the standards. Also, thesauri\n>> are very similar to other KOS e.g. classification schemes, taxonomis,\n>> topic maps. How do we cope with this?\n>>\n>> Option 1 - Define a specialised vocabulary that covers only thesauri that\n>> comply with the standards.\n>>\n>> Option 2 - Define a core vocab that captures what is common to all\n>> thesauri. Then define extension modules to cope with different flavours\n>> of thesauri.\n>>\n>> Option 3 - Define a core vocab that captures what is common to all KOS\n>> (thesauri, taxonomies, classification schemes, topic maps etc.). Define\n>> first level extension module for thesauri. Define second level extension\n>> for flavours.\n>>\n>> === Comments on Issue 1 ===\n>>\n>> AJM>>\n>>\n>> What we did previously ( [WWW]early draft of 8.1\n>> <http://www.w3c.rl.ac.uk/SWAD/deliv81.htm>) was half way between (1) and\n>> (2).\n>>\n>> I would like to go for (3), but am prepared to backtrack towards (2),\n>> which may happen when we hit interop with this and OWL. (3) Would mean\n>> we have a way of fitting all these KOS together on the semantic web,\n>> which would be a good thing.\n>>\n>> Going for (3) means we have to define a core vocab. I've kind of assumed\n>> this is what we are doing (tell me if you think it's a bad idea), and\n>> issues below relate first to this core vocab. We need a name for this\n>> core vocab, so at least we can refer to it. For now, I'm going to call\n>> it the core vocab. In code, I'm using the prefix soks. Why soks? Short\n>> for SuperKOS! Got any ideas about a better name?\n>>\n>>\n>>\n>> CCLRC - Rutherford Appleton Laboratory\n>> Building R1 Room 1.60\n>> Fermi Avenue\n>> Chilton\n>> Didcot\n>> Oxfordshire OX11 0QX\n>> United Kingdom\n>>\n>> Email:        a.j.miles@rl.ac.uk\n>> Telephone: +44 (0)1235 445440\n>>\n>>\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (4) - Concepts as languageembedded, language indepe           ndent, or both",
            "content": "Hi Alistair\n\nMy philosophical angle on this is:\n\nHuman society distinguishes itself from (the rest of) animal society by its \nreification of abstract concepts, done primarily via language. So the \nconcepts don't come from the language, they exist independently - languages \nevolve in the attempt to articulate human understanding of abstract \nconcepts. Different languages have evolved over time of course, and have \nmuch in common, but also some languages have sought to reify concepts that \nother languages don't, and so on...\n\nComing back to the question of a pragmatic solution to modelling \nmultilingual data: I tend towards Option 2, but then I've not experimented \nwith much 'real' data, so you might want to give me some illustrative \ncounter examples.\nIs it not the case that the *concepts* being reified by one language can be \nmapped - partially or otherwise - to concepts being reified in another \nlanguage? And if there are \"missing\" concepts for some languages then \nthat's ok? i.e. is it possible to always map thesauri at the conceptual \nlevel as opposed to at the 'label' level? I know this means deriving \nconcept hierarchies from thesauri from thesauri that don't have this \nexplicit - but I thought that was what we were aiming for anyway?\n\nI guess we should continue the discussion on the wiki ...\n\nNikki\n\n--On 31 October 2003 17:31 +0000 \"Miles, AJ (Alistair) \" \n<A.J.Miles@rl.ac.uk> wrote:\n\n>\n> I've added this issue to the discussion on the RDF Thesaurus wiki page\n> <http://esw.w3.org/topic/RdfThesaurus>\n>\n> Here is a summary:-\n>\n> Issue 4 - Concepts as language-embedded, language independent, or both?\n>\n> There are multilingual thesauri. When modelling multilingual data in RDF,\n> we can choose one of the following options:\n>\n> Option 1: Concepts in a language - allow language properties only on nodes\n> typed as Concepts.\n>\n> Option 2: Labels in a language - allow language properties (or tags) only\n> on nodes (or literals) which represent labels.\n>\n> Option 3: And/or - allow concepts and/or labels to have language\n> properties.\n>\n>\n> The choice of solution has bold implications. If we choose option 1 we are\n> assuming that all abstract concepts are embedded in a language; there can\n> be no language independent concepts. If we choose option 2 we can model\n> only concepts that are deemed to be 'language-independent'. If we choose\n> option 3 we can represent both language-embedded and language-independent\n> concepts, however there may be some considerable scope for confusion.\n>\n> ... more at <http://esw.w3.org/topic/RdfThesaurus>\n>\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: Design Issue (3)  How to label concepts",
            "content": "Dave I agree.\n\nI was thinking of three properties:\n\n\nrdf:label(domain = Resource, range = Literal)\n  ^\n  |\nsoks:prefLabel  (domain = Resource, range = Literal)\n\n[A label which is the preferred label for a resource]\n\n\nrdf:label(domain = Resource, range = Literal)\n  ^\n  |\nsoks:altLabel  (domain = Resource, range = Literal)\n\n[A label which is an alternative but not preferred label for a resource]\n\n\nsoks:prefLabel  (domain = Resource, range = Literal)\n  ^\n  |\nsoks:descriptor(domain = Concept, range = Literal)\n\n[A label that uniquely and unambiguously identifies a Concept within a\nparticular conceptual scheme such as a thesaurus.  For example, 'Java\nprogramming language', 'Island of Java', 'Python programming language',\n'Pythons (snakes)' are all good descriptors.]\n\n\nWhy have both a soks:prefLabel and a soks:descriptor?  \n\nThe notion of a 'descriptor' is fundamentally defined and understood to be a\nlexical identifier for a concept, unique within a conceptual scheme.  This\nis what a 'descriptor' is understood to be by thesaurus and KOS people (I'm\nhoping!).  \n\nThe 'prefLabel' property can then be used more loosely, to indicate just a\nlabel which is preferred above other labels, but with no additional\nconstraints.\n\nTo have had a property called something like 'prefLabel' but with the\nfunction of 'descriptor' I thought would be open to misunderstanding and\nunintentional misuse (i.e. people would inevitably use it in the looser\nsense).    \n\nAl. \n\n-----Original Message-----\nFrom: Dave Reynolds [mailto:der@hplb.hpl.hp.com]\nSent: 04 November 2003 12:56\nTo: Miles, AJ (Alistair) \nCc: 'public-esw-thes@w3.org'\nSubject: Re: Design Issue (3) - How to label concepts?\n\n\n\nIt makes sense to me to build on top of rdfs:label so that general RDFS \nprocessors can pick up the labels.\n\nThus:\n     rdf:label  (domain = Resource, range = Literal)\n       ^\n       |\n     soks:label (domain = soks:Concept)\n       ^\n       |\n     soks:preferredLabel\n\nKeeping the range as Literal is useful since that's the only bit of RDF that\n\nsupports xml:lang.\n\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> I've added this issue to the discussion on the RDF Thesaurus wiki page\n> <http://esw.w3.org/topic/RdfThesaurus>\n> \n> Here is a summary:-\n> \n> Issue 3 - How to label concepts?\n> \n> In a thesaurus, every concept has one preferred term (label) and 0 or more\n> alternative terms. \n> \n> The obvious way to model this in RDF is to have one property for linking a\n> resource to a preferred label (I'll call this soks:prefLabel for now) and\n> one property for linking a resource to any alternative labels (I'll call\n> this soks:altLabel for now). \n> \n> This raises two design questions:- \n> \n> Question 1: domain restriction? - Do we (a) restrict the domain of these\n> properties to soks:Concept or do we (b) allow them to be used with any\n> resource? \n> \n> Question 2: resources or literals? - Do we (a) restrict the range of these\n> properties to rdfs:Literal, or do we (b) restrict the range to some type\nof\n> resource? \n> \n> We may be able to re-use and/or extend existing properties, e.g.\nrdfs:label,\n> but what we choose to re-use depends on the resolution of these questions,\n> so I'm saving a discussion of that for later. \n> \n> The choice of solution to question 2 has important implications for\n> multilingual data and labelling ...\n> \n> ... more at <http://esw.w3.org/topic/RdfThesaurus>\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "RE: [Fwd: Shared Key Authentication for the TLS Protocol&ndash;&ndash; an Alternative",
            "content": ">Peter:  you seem to be conflating two different distinctions--the distinction\n>between socket-level and application level access control, on the one hand,\n>and the distinction between public-key-based and shared-key-based\n>authentication on the other.  I agree one hundred percent that incorporating\n>client authentication into SSL/TLS makes system-level access control\n>possible, and that that is a good thing.  I simply don't agree with your\n>apparent claim that such access control must necessarily be based on\n>public-key authentication; on the contrary, I expect it that when it occurs,\n>it will often be shared-key-based, for any number of reasons.  Hence the\n>necessity for TLS to have a shared-key authentication feature.  \n>\n>Regarding some of the other points you raised:\n>\n>From: Peter Williams[SMTP:peter@verisign.com]\n>\n>Any alternative *SSL* authentication service must be performable within the\n>handshake, and\n>not require encryption.The only real reason to invest in a new mechanism\n>is because a some new interesting class of cipher exists which needs some\n>help\n>in the handshake messages so as to expoit its authentication properties. (SSL\n>multicast authentication I believe will be a case in point, one day)\n>\n>For example, if I used a TYPE I algoirhtm which matched RSA properties,\n>I would not expect to change SSL except to introduce a new cipherSuite.\n>If I used Type II KEA which is related to DH, I would not expect to change\n>SSL;\n>rather, Id just introduce a new cipherSuite. If we use Elliptic,\n>Curves, again there is nothing new in any of these algoirhtms which changes\n>SSL.\n>\n>I dont believe TLS should allow any encryption, other than via public key\n>exchange,\n>during the handshake. \n>\n>In fact, under the proposed shared-key authentication extension, it does not.\n> The strong protection of the shared-key authentication response is effected\n>using a keyed cryptographic hash, not encryption.\n>\n>Why cannot we merely register a cipherSuite whose semantics are: do strong\n>encrytion\n>for the first n bytes of user data; having performed a handshake. The server\n>must then authenticate\n>the n bytes of shared-secret authentication from the user-stream, and perform\n>a new handshake if\n>it accepts the access control policy.  The server may choose to require\n>client authentication,\n>and mandatory access control estbalishment upon completeion of the first\n>handshake, if\n>thats its policy.\n>\n>Exactly the same argument could apply to public-key client authentication as\n>well; however, we (hopefully) all agree that a single public-key client\n>authentication standard embedded into TLS vastly improves its\n>interoperability and allows application-independent security decisions to be\n>made about clients.  Similarly, your proposal does not address the\n>interoperability problem with respect to shared-key authentication, nor the\n>application-independent control of sockets.  Moreover, under this proposal,\n>any socket-level implementation of TLS would likely run into export problems,\n>since it would have to ship some amount of uncontrolled data across the\n>channel using strong encryption. \n>\n>\n>Daniel Simon\n>Cryptographer, Microsoft Corp.\n>dansimon@microsoft.com\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Design Issues (1)  Specialised vocab vs. extensible modular   voca bs",
            "content": "Hi Dave,\n\nYes I was using 'KOS' for everything, including ontologies, thesauri,\nclassification schemes, taxonomies, glossaries, dictionaries, topic maps,\nsemantic nets, concepts maps etc...\n\nYou make a very good point I think.   \n\nThe design goal I had in mind when I suggested modular vocabs is this: I\nwanted to avoid the worst case scenario, which is that we have one RDF vocab\nfor ontologies, one for thesauri, one for classification schemes and so on\nfor each type of KOS, and there is no overlap or reuse of components between\nthe vocabs.  This is in fact close to what we have right now (e.g. OWL for\nontologies, TIF for thesauri, LOM-CLS for classification schemes).  \n\nIf the core vocab for all KOS is nothing more than RDF(S) then great.  We\nhave OWL already.  So the gap that remains to be filled is for all KOS that\nare not ontologies.  So I imagine soks-core to be aimed at the common\nfeatures of all KOS that are not ontologies, re-using RDF RDFS and OWL as\nmuch as possible.  Then build an extension for all thesauri and things that\nare like thesauri.  \n\nTo summarise my design goals: maximise re-use, maximise interoperability,\nminimise complexity.  \n\nTo give an idea of how I imagine these modular vocabs fitting together, have\na look at\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.1_0_3.html \n\nYours,\n\nAl.\n\n-----Original Message-----\nFrom: Dave Reynolds [mailto:der@hplb.hpl.hp.com]\nSent: 04 November 2003 10:48\nTo: Miles, AJ (Alistair) \nCc: 'public-esw-thes@w3.org'\nSubject: Re: Design Issues (1) - Specialised vocab vs. extensible\nmodular voca bs?\n\n\n\nHi,\n\nI can't access the Wiki at the moment, and in any case don't know how you\nwant \ncomments, so I'll stick to email.\n\nBy KOS do you mean \"Knowledge Organization Scheme\"?\nWhat does that cover? Are you including ontologies in there?\n\nIf the answer to the last question is \"yes\" then I suggest avoiding 3. A\ncommon \ncore for all different thesaurus and ontology schemes is in danger of being\nso \ngeneric as to be little more than raw RDF(S).\n\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> I've added this issue to the discussion on the RDF Thesaurus wiki page\n> <http://esw.w3.org/topic/RdfThesaurus>\n> \n> Here is a summary:-\n> \n> \n> Issue 1 - Specialised vocab vs. extensible modular vocabs?\n> \n> \n> Although most thesauri are pretty similar, there are important variations,\n> and many thesauri deviate from the standards. Also, thesauri are very\n> similar to other KOS e.g. classification schemes, taxonomis, topic maps.\nHow\n> do we cope with this? \n> \n> Option 1 - Define a specialised vocabulary that covers only thesauri that\n> comply with the standards. \n> \n> Option 2 - Define a core vocab that captures what is common to all\nthesauri.\n> Then define extension modules to cope with different flavours of thesauri.\n\n> \n> Option 3 - Define a core vocab that captures what is common to all KOS\n> (thesauri, taxonomies, classification schemes, topic maps etc.). Define\n> first level extension module for thesauri. Define second level extension\nfor\n> flavours. \n> \n> === Comments on Issue 1 === \n> \n> AJM>> \n> \n> What we did previously ( [WWW]early draft of 8.1\n> <http://www.w3c.rl.ac.uk/SWAD/deliv81.htm>) was half way between (1) and\n> (2). \n> \n> I would like to go for (3), but am prepared to backtrack towards (2),\nwhich\n> may happen when we hit interop with this and OWL. (3) Would mean we have a\n> way of fitting all these KOS together on the semantic web, which would be\na\n> good thing. \n> \n> Going for (3) means we have to define a core vocab. I've kind of assumed\n> this is what we are doing (tell me if you think it's a bad idea), and\nissues\n> below relate first to this core vocab. We need a name for this core vocab,\n> so at least we can refer to it. For now, I'm going to call it the core\n> vocab. In code, I'm using the prefix soks. Why soks? Short for SuperKOS!\nGot\n> any ideas about a better name? \n> \n> \n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: Design Issues (1)  Specialised vocab vs. extensible modular   voca bs",
            "content": "Hi Alistair,\n\nA very generic base vocabularly such as the one you suggest sounds fine. I \njust wouldn't describe it as a common core for KOS languages.\n\nJust look at how much intellecual effort was required just to unify RDFS \nand DAML enough to get the compromise that is OWL - for example, with \nOWL/DL and OWL/Lite not being supersets of RDFS. If the foundation starts \nto express anything richer than labels then the semantics constrains what \nyou can cleanly build on top. I'm not sure you can have all of simplicity, \ngenerality and power. You are opting for the first two, which seems reasonable.\n\nWhat you have is fine as a core for \"things that are like thesauri\", which, \nas I understand it, is the aim of the work package. But, for example, I'm \nnot sure how well it corresponds to topic maps which, I think, have a \ndifferent way of separating concept from indicator. For the very rich \nrepresentations like conceptual maps then this core covers so little as to \nnot really make much difference either way.\n\nCheers,\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> Hi Dave,\n> \n> Yes I was using 'KOS' for everything, including ontologies, thesauri,\n> classification schemes, taxonomies, glossaries, dictionaries, topic maps,\n> semantic nets, concepts maps etc...\n> \n> You make a very good point I think.   \n> \n> The design goal I had in mind when I suggested modular vocabs is this: I\n> wanted to avoid the worst case scenario, which is that we have one RDF vocab\n> for ontologies, one for thesauri, one for classification schemes and so on\n> for each type of KOS, and there is no overlap or reuse of components between\n> the vocabs.  This is in fact close to what we have right now (e.g. OWL for\n> ontologies, TIF for thesauri, LOM-CLS for classification schemes).  \n> \n> If the core vocab for all KOS is nothing more than RDF(S) then great.  We\n> have OWL already.  So the gap that remains to be filled is for all KOS that\n> are not ontologies.  So I imagine soks-core to be aimed at the common\n> features of all KOS that are not ontologies, re-using RDF RDFS and OWL as\n> much as possible.  Then build an extension for all thesauri and things that\n> are like thesauri.  \n> \n> To summarise my design goals: maximise re-use, maximise interoperability,\n> minimise complexity.  \n> \n> To give an idea of how I imagine these modular vocabs fitting together, have\n> a look at\n> \n> http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1_0_3.html \n> \n> Yours,\n> \n> Al.\n> \n> -----Original Message-----\n> From: Dave Reynolds [mailto:der@hplb.hpl.hp.com]\n> Sent: 04 November 2003 10:48\n> To: Miles, AJ (Alistair) \n> Cc: 'public-esw-thes@w3.org'\n> Subject: Re: Design Issues (1) - Specialised vocab vs. extensible\n> modular voca bs?\n> \n> \n> \n> Hi,\n> \n> I can't access the Wiki at the moment, and in any case don't know how you\n> want \n> comments, so I'll stick to email.\n> \n> By KOS do you mean \"Knowledge Organization Scheme\"?\n> What does that cover? Are you including ontologies in there?\n> \n> If the answer to the last question is \"yes\" then I suggest avoiding 3. A\n> common \n> core for all different thesaurus and ontology schemes is in danger of being\n> so \n> generic as to be little more than raw RDF(S).\n> \n> Dave\n> \n> Miles, AJ (Alistair) wrote:\n> \n> \n>>I've added this issue to the discussion on the RDF Thesaurus wiki page\n>><http://esw.w3.org/topic/RdfThesaurus>\n>>\n>>Here is a summary:-\n>>\n>>\n>>Issue 1 - Specialised vocab vs. extensible modular vocabs?\n>>\n>>\n>>Although most thesauri are pretty similar, there are important variations,\n>>and many thesauri deviate from the standards. Also, thesauri are very\n>>similar to other KOS e.g. classification schemes, taxonomis, topic maps.\n> \n> How\n> \n>>do we cope with this? \n>>\n>>Option 1 - Define a specialised vocabulary that covers only thesauri that\n>>comply with the standards. \n>>\n>>Option 2 - Define a core vocab that captures what is common to all\n> \n> thesauri.\n> \n>>Then define extension modules to cope with different flavours of thesauri.\n> \n> \n>>Option 3 - Define a core vocab that captures what is common to all KOS\n>>(thesauri, taxonomies, classification schemes, topic maps etc.). Define\n>>first level extension module for thesauri. Define second level extension\n> \n> for\n> \n>>flavours. \n>>\n>>=== Comments on Issue 1 === \n>>\n>>AJM>> \n>>\n>>What we did previously ( [WWW]early draft of 8.1\n>><http://www.w3c.rl.ac.uk/SWAD/deliv81.htm>) was half way between (1) and\n>>(2). \n>>\n>>I would like to go for (3), but am prepared to backtrack towards (2),\n> \n> which\n> \n>>may happen when we hit interop with this and OWL. (3) Would mean we have a\n>>way of fitting all these KOS together on the semantic web, which would be\n> \n> a\n> \n>>good thing. \n>>\n>>Going for (3) means we have to define a core vocab. I've kind of assumed\n>>this is what we are doing (tell me if you think it's a bad idea), and\n> \n> issues\n> \n>>below relate first to this core vocab. We need a name for this core vocab,\n>>so at least we can refer to it. For now, I'm going to call it the core\n>>vocab. In code, I'm using the prefix soks. Why soks? Short for SuperKOS!\n> \n> Got\n> \n>>any ideas about a better name? \n>>\n>>\n>>\n>>CCLRC - Rutherford Appleton Laboratory\n>>Building R1 Room 1.60\n>>Fermi Avenue\n>>Chilton\n>>Didcot\n>>Oxfordshire OX11 0QX\n>>United Kingdom\n>>\n>>Email:        a.j.miles@rl.ac.uk\n>>Telephone: +44 (0)1235 445440\n>>\n>>\n\n\n\n"
        },
        {
            "subject": "RE: Design Issue (4) - Concepts as languageembedded, language in depe  ndent, or both",
            "content": "Hi Nikki,\n\nI completely agree.  \n\nSo now I think nodes types as 'soks:Concept' should NOT be allowed to have a\nlanguage property.  ONLY the labels should be allowed to have a language\nproperty/tag. \n\nRepresenting non-exact equivalence relationships between concepts derived\nfrom different languages is then covered by whatever we end up doing for\ninter-thesaurus concept mapping.\n\nThis does have consequences for constraining the data model.  It means a\nnode typed as a 'soks:Concept' must then be allowed to have multiple\n'soks:descriptor' properties, one for each language.  Is it then possible in\nOWL to express the constraint that a concept may have one and only one\n'soks:descriptor' property for each language?   If not, can we live with\nthis?   \n\nAl.\n\n-----Original Message-----\nFrom: NJ Rogers, Learning and Research Technology\n[mailto:Nikki.Rogers@bristol.ac.uk]\nSent: 05 November 2003 12:32\nTo: Miles, AJ (Alistair); 'public-esw-thes@w3.org'\nSubject: Re: Design Issue (4) - Concepts as language-embedded, language\nindepe ndent, or both?\n\n\nHi Alistair\n\nMy philosophical angle on this is:\n\nHuman society distinguishes itself from (the rest of) animal society by its \nreification of abstract concepts, done primarily via language. So the \nconcepts don't come from the language, they exist independently - languages \nevolve in the attempt to articulate human understanding of abstract \nconcepts. Different languages have evolved over time of course, and have \nmuch in common, but also some languages have sought to reify concepts that \nother languages don't, and so on...\n\nComing back to the question of a pragmatic solution to modelling \nmultilingual data: I tend towards Option 2, but then I've not experimented \nwith much 'real' data, so you might want to give me some illustrative \ncounter examples.\nIs it not the case that the *concepts* being reified by one language can be \nmapped - partially or otherwise - to concepts being reified in another \nlanguage? And if there are \"missing\" concepts for some languages then \nthat's ok? i.e. is it possible to always map thesauri at the conceptual \nlevel as opposed to at the 'label' level? I know this means deriving \nconcept hierarchies from thesauri from thesauri that don't have this \nexplicit - but I thought that was what we were aiming for anyway?\n\nI guess we should continue the discussion on the wiki ...\n\nNikki\n\n--On 31 October 2003 17:31 +0000 \"Miles, AJ (Alistair) \" \n<A.J.Miles@rl.ac.uk> wrote:\n\n>\n> I've added this issue to the discussion on the RDF Thesaurus wiki page\n> <http://esw.w3.org/topic/RdfThesaurus>\n>\n> Here is a summary:-\n>\n> Issue 4 - Concepts as language-embedded, language independent, or both?\n>\n> There are multilingual thesauri. When modelling multilingual data in RDF,\n> we can choose one of the following options:\n>\n> Option 1: Concepts in a language - allow language properties only on nodes\n> typed as Concepts.\n>\n> Option 2: Labels in a language - allow language properties (or tags) only\n> on nodes (or literals) which represent labels.\n>\n> Option 3: And/or - allow concepts and/or labels to have language\n> properties.\n>\n>\n> The choice of solution has bold implications. If we choose option 1 we are\n> assuming that all abstract concepts are embedded in a language; there can\n> be no language independent concepts. If we choose option 2 we can model\n> only concepts that are deemed to be 'language-independent'. If we choose\n> option 3 we can represent both language-embedded and language-independent\n> concepts, however there may be some considerable scope for confusion.\n>\n> ... more at <http://esw.w3.org/topic/RdfThesaurus>\n>\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (3)  How to label concepts",
            "content": "Miles, AJ (Alistair) wrote:\n\n> I was thinking of three properties:\n> \n> \n> rdf:label(domain = Resource, range = Literal)\n>   ^\n>   |\n> soks:prefLabel  (domain = Resource, range = Literal)\n> \n> [A label which is the preferred label for a resource]\n\n> rdf:label(domain = Resource, range = Literal)\n>   ^\n>   |\n> soks:altLabel  (domain = Resource, range = Literal)\n> \n> [A label which is an alternative but not preferred label for a resource]\n\nFine.\n\nMy suggestion implicitly had \"altLabel\" as a label which is not a \nperfLabel. This might have some advantages when it comes to merging. If you \nhave two thesauri with differing perferred terms for the same concept the \nmerge would just have two prefLabels and all else (not preferred in either) \nwould be treated as alt. Don't know enough about how thesauri are used in \npractice to know if that is beter or worse.\n\n> soks:prefLabel  (domain = Resource, range = Literal)\n>   ^\n>   |\n> soks:descriptor(domain = Concept, range = Literal)\n> \n> [A label that uniquely and unambiguously identifies a Concept within a\n> particular conceptual scheme such as a thesaurus.  For example, 'Java\n> programming language', 'Island of Java', 'Python programming language',\n> 'Pythons (snakes)' are all good descriptors.]\n> \n> Why have both a soks:prefLabel and a soks:descriptor?  \n> \n> The notion of a 'descriptor' is fundamentally defined and understood to be a\n> lexical identifier for a concept, unique within a conceptual scheme.  This\n> is what a 'descriptor' is understood to be by thesaurus and KOS people (I'm\n> hoping!).  \n\nIn that case one option would be to change the range of descriptor to \ncapture the context.\n\n     property soks:descriptor (domain = Concept, range = Descriptor)\n     class soks:Descriptor\n     property soks:descriptorTerm (domain = Descriptor, range = Literal)\n     property soks:descriptorSchema (domain = Desciptor, range = Resource)\n\nThen in instance data the descritor is a b-node pointing to the literal and \nto a URI identifying the conceptual schema. This would facilitate merging.\n\nThe downside is that this version of soks:descriptor couldn't be a \nsubProperty of rdfs:label.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: Design Issues (1)  Specialised vocab vs. extensible modular   voca bs",
            "content": "Yup, I think it is things \"like\" Thesauri that are in scope.\n\n\"like\" being under-determined somewhat.\n\nHere is my take:\n\nRDFS/OWL are RDF's own way of doing this stuff. We don't need to \nreproduce that.\n\nSWAD-E's thes vocab is for representing KOS systems that don't (for\nwhatever reason) directly map into RDFS/OWL, but do map into a \nthesaurus-like network of relationships amongst named concepts.\n\nSo:\n\n(1) out of scope\nfido --type--> Poodle --subClassOf--> Dog --subClassOf--> Mammal\n\n(2) in scope\n\nfido --bt--> Poodle --bt--> Dog --bt--> Mammal\n\n\nObviously you can talk about the same stuff in both traditions.\n\nThe explicit RDFS/OWL view (ie. 1. above) is clearer and supports more \ninference, eg.  you can deduce that fido is of type Mammal, thanks to\nRDFS's formal semantics.\n\n(2) is more typical of what we see in the library world, where the \nlooser notion of 'bt' conflates a variety of distinctions.\n\nSo the idea here is to bootstrap the semantic web by allowing an \nRDF representation of these fuzzier, messier but still useful \ndatabases of related named concepts. Remodelling a thesaurus as an\nRDF vocabulary (RDFS/OWL) is expensive and time consuming. Dumping out \nfrom a thesaurus into TIF should be easy and cheap, and allow some \nbenefit from use of generic RDF tools, although of course missing out \non other aspects of RDF which focus on the type hierarchies.\n\nDoes this make sense?\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (4) - Concepts as languageembedded, language in  depe  ndent, or both",
            "content": "Miles, AJ (Alistair) wrote:\n\n> This does have consequences for constraining the data model.  It means a\n> node typed as a 'soks:Concept' must then be allowed to have multiple\n> 'soks:descriptor' properties, one for each language.  Is it then possible in\n> OWL to express the constraint that a concept may have one and only one\n> 'soks:descriptor' property for each language?  \n\nOnly if you represent content-in-a-specific-language as a class, which \nwould mean having a different class and different cardinality constraint \nfor every language. Which probably wouldn't be workable.\n\nBut in any case you need to add the qualifier \"in any given conceptual \nscheme\". That definitely makes expressing the cardinality constraint in OWL \nunworkable.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: Design Issues (1)  Specialised vocab vs. extensible modular    voca bs",
            "content": "Dan Brickley wrote:\n\n > Does this make sense?\n\nYup.\n\nBy the way the Gene Ontology is quite an interesting example in this \nrespect. It has been migrating from a thesaurus like structure to a more \nontology like structure. At the moment it has two link types, isa links \nwhich have strict subsumption semantics (as in RDFS et al) and part-of \nlinks which have less strict semantics. In the future they are \ncontemplating spliting part-of into different flavours which could be given \na stricter semantics.\n\nIn a meeting I was at recently it was suggested that the GO is easier to \nnavigate than some of the deeper ontology-based domain models in similar \ndomains because of this thesaurus-like heritage. The speculation was that a \ncomplex ontology is likely to benefit from a thesaurus-like navigation overlay.\n\nDave\n\n> Yup, I think it is things \"like\" Thesauri that are in scope.\n> \n> \"like\" being under-determined somewhat.\n> \n> Here is my take:\n> \n> RDFS/OWL are RDF's own way of doing this stuff. We don't need to \n> reproduce that.\n> \n> SWAD-E's thes vocab is for representing KOS systems that don't (for\n> whatever reason) directly map into RDFS/OWL, but do map into a \n> thesaurus-like network of relationships amongst named concepts.\n> \n> So:\n> \n> (1) out of scope\n> fido --type--> Poodle --subClassOf--> Dog --subClassOf--> Mammal\n> \n> (2) in scope\n> \n> fido --bt--> Poodle --bt--> Dog --bt--> Mammal\n> \n> \n> Obviously you can talk about the same stuff in both traditions.\n> \n> The explicit RDFS/OWL view (ie. 1. above) is clearer and supports more \n> inference, eg.  you can deduce that fido is of type Mammal, thanks to\n> RDFS's formal semantics.\n> \n> (2) is more typical of what we see in the library world, where the \n> looser notion of 'bt' conflates a variety of distinctions.\n> \n> So the idea here is to bootstrap the semantic web by allowing an \n> RDF representation of these fuzzier, messier but still useful \n> databases of related named concepts. Remodelling a thesaurus as an\n> RDF vocabulary (RDFS/OWL) is expensive and time consuming. Dumping out \n> from a thesaurus into TIF should be easy and cheap, and allow some \n> benefit from use of generic RDF tools, although of course missing out \n> on other aspects of RDF which focus on the type hierarchies.\n> \n> Does this make sense?\n> \n> Dan\n> \n\n\n\n"
        },
        {
            "subject": "RE: 8.1 thesaurus_schema_draft submissio",
            "content": "All previous versions of this deliverable are online:\n\n\nVersion 0.1 (Working title: Modelling thesauri for the semantic web)\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.1_0_1.html\n\nVersion 0.2 (Working title: RDF Schema for ISO Standard Thesauri)\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.1_0_2.html \n\nVersion 0.3 (Working title: Core RDF Vocabularies for Monolingual Thesauri)\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.1_0_3.html\n\n\nVersion 0.2 has been submitted to the EU as the official deliverable.\n\n\nThe link http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html currently points\nto version 0.3\n\nAl.\n\n\n\n\n>  -----Original Message-----\n> From: Matthews, BM (Brian)   \n> Sent:06 November 2003 15:43\n> To:Miles, AJ (Alistair) \n> Subject:RE: 8.1 thesaurus_schema_draft submission\n> \n> Alistair, \n> \n> Good - this is the right approach, but you should also keep the previous\n> versions on line - \n> \n> that is have links:\n>  - http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html \n>  - http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1-v0.2.html (say)\n> both link to the v0.2, but when \n>   http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1-v0.3.html \n> appears, relink \n> http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html to that as well.\n> \n> Its nice to be able to get back to history - and the Commission would want\n> a definitive document to review rather than a moving target.\n> \n> I see that you have re-presented this quite radically.  Looks nice!\n> The summary at the end is missing though!\n> \n> Thanks for that.\n> \n> Brian \n> \n> \n> >  -----Original Message-----\n> > From: Miles, AJ (Alistair)   \n> > Sent:06 November 2003 15:35\n> > To:Kate Sharp (E-mail)\n> > Cc:Dan Brickley (E-mail); Matthews, BM (Brian) \n> > Subject:8.1 thesaurus_schema_draft submission\n> > \n> > Hi Kate,\n> > \n> > Thought I'd give you 8.1 too.  \n> > \n> > Please bear in mind this document is likely to be completely \n> > rewritten, especially in light of the discussions that are \n> > currently going on on public-esw-thes@w3.org.  The document \n> > attached is 'version 0.2'.  The link \n> > http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html already \n> > points to a draft of 'version 0.3', which is a complete \n> > rewrite, and will evolve to reflect the ongoing discussion \n> > and decisions made.  The reason I've given you version 0.2 is \n> > because it is complete and can serve as a submission.  I know \n> > we're well behind schedule for this deliverable, so I thought \n> > rather than wait a week or two for 0.3 to be ready, I'll just \n> > give you 0.2 now.  \n> > \n> > However, please keep links on all public webs pointing at \n> > http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html as this \n> > will reflect the current state of the work.\n> > \n> > Dan, Brian, does this work for you?\n> > \n> > Al.\n> >   << File: 8.1.zip >> \n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> > \n> > Email:        a.j.miles@rl.ac.uk\n> > Telephone: +44 (0)1235 445440\n> > \n> > \n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (4)  constraining 'descriptor'/'prefLabel'           cardinality for multilingual thesaur",
            "content": "Hi Alistair and Dave,\n>\n>> This does have consequences for constraining the data model.  It means a\n>> node typed as a 'soks:Concept' must then be allowed to have multiple\n>> 'soks:descriptor' properties, one for each language.  Is it then\n>> possible in OWL to express the constraint that a concept may have one\n>> and only one 'soks:descriptor' property for each language?\n>\n> Only if you represent content-in-a-specific-language as a class, which\n> would mean having a different class and different cardinality constraint\n> for every language. Which probably wouldn't be workable.\n>\nI've been trying to consider some options here:\n\n***********\n1. throw out the 'descriptor' cardinality constraint for multilingual \nthesauri (as well as for/as distinct from monolingual thesauri?) and don't \nworry about it - live with it, & provide recommendation of use\n\ninstead.\n\n***********\n2. model multilingual thesauri in a specific way: express each language's\n\ninterpretation of a concept uniquely by giving the same concept different \nuri's in each of the languages in question. Then map the concepts (using \n\"owl:equivalentTo\").  That way we could still specify exactly 1 preferred \nlabel/'descriptor' per concept. Does it upset us to give different uri's to \nwhat certain communities believe to be the same concept? I guess how \ninferencing is then conducted over the thesaurus data (for queries) is then \ncritical & I haven't thought about this in any depth. Therefore I'm not \nsure if this approach is currently \"legal\".\n\n***********\n3. Subclass 'soks:Concept' with what we'd understand to be concepts in the \ncontext of a particular language. I think this is similar to what Dave is \nreferring to? And yes, it feels cranky:\n\ne.g.\n\n'soks:Concept'\n   |\n   |\n'soks:English_concept'\n\nThen we'd potentially have multiple properties (e.g. \nsoks:english_language_concept, soks:japenese_language_concept etc.) hanging \noff any one 'soks:Concept' in a thesaurus schema.\n[I guess 'soks:english_language_concept' has domain 'soks:Concept' and \nrange 'soks:English_concept' ....]\nUsing this approach, we can keep the cardinality constraint = 1 for \n'soks:descriptor' properties (because there would be one for each of \n'soks:English_concept', 'soks:Japenese_concept', etc)?\n[I suppose 'soks:English_concept' could be further subclassed for \nAmerican_english etc.]\nHowever, typically, one then feels that further constraints are now \nrequired to protect data integrity. Such as a constraint that the \n'descriptor' property value for any [Language]_concept must be in the same \nlanguage as that [Language]_concept bla bla.\n\nHmmm ... :-)\n\nNikki\n\n> But in any case you need to add the qualifier \"in any given conceptual\n> scheme\". That definitely makes expressing the cardinality constraint in\n> OWL unworkable.\n>\n> Dave\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: Design Issue (4)  constraining 'descriptor'/'prefLabel'            cardinality for multilingual thesaur",
            "content": "First mail to list - hi all! so sorry if I've missed vital context.\n\n1. sound like a workable fallback \n2. works but adds inference load \n3. Urgh! This is similar to the classic subclassing error of OO modelling\n(imo) - except it's subproperty of course.\n\nWhat about saying (apologies for any N3 errors)\n<concept> \n   :hasDescriptor [:inLanguage <French>; :value \"chaud\"];   \n   :hasDescriptor [:inLanguage <English>; :value \"hot\"] .\n\nOr, if you want to keep cardinality constraints, add a level of indirection\n<concept> \n   :hasDescriptor [:alternative [:inLanguage <French>; :value \"chaud\"];\n:alternative [:inLanguage <English>; :value \"hot\"]] .\n\nSteve\n> -----Original Message-----\n> From: NJ Rogers, Learning and Research Technology \n> [mailto:Nikki.Rogers@bristol.ac.uk] \n> Sent: 07 November 2003 12:14\n> To: Dave Reynolds; Miles, AJ (Alistair)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: Re: Design Issue (4) - constraining \n> 'descriptor'/'prefLabel' cardinality for multilingual thesauri\n> \n> \n> \n> Hi Alistair and Dave,\n> >\n> >> This does have consequences for constraining the data model.  It \n> >> means a node typed as a 'soks:Concept' must then be \n> allowed to have \n> >> multiple 'soks:descriptor' properties, one for each \n> language.  Is it \n> >> then possible in OWL to express the constraint that a concept may \n> >> have one and only one 'soks:descriptor' property for each language?\n> >\n> > Only if you represent content-in-a-specific-language as a \n> class, which \n> > would mean having a different class and different cardinality \n> > constraint for every language. Which probably wouldn't be workable.\n> >\n> I've been trying to consider some options here:\n> \n> ***********\n> 1. throw out the 'descriptor' cardinality constraint for multilingual \n> thesauri (as well as for/as distinct from monolingual \n> thesauri?) and don't \n> worry about it - live with it, & provide recommendation of use\n> \n> instead.\n> \n> ***********\n> 2. model multilingual thesauri in a specific way: express \n> each language's\n> \n> interpretation of a concept uniquely by giving the same \n> concept different \n> uri's in each of the languages in question. Then map the \n> concepts (using \n> \"owl:equivalentTo\").  That way we could still specify exactly \n> 1 preferred \n> label/'descriptor' per concept. Does it upset us to give \n> different uri's to \n> what certain communities believe to be the same concept? I guess how \n> inferencing is then conducted over the thesaurus data (for \n> queries) is then \n> critical & I haven't thought about this in any depth. \n> Therefore I'm not \n> sure if this approach is currently \"legal\".\n> \n> ***********\n> 3. Subclass 'soks:Concept' with what we'd understand to be \n> concepts in the \n> context of a particular language. I think this is similar to \n> what Dave is \n> referring to? And yes, it feels cranky:\n> \n> e.g.\n> \n> 'soks:Concept'\n>    |\n>    |\n> 'soks:English_concept'\n> \n> Then we'd potentially have multiple properties (e.g. \n> soks:english_language_concept, soks:japenese_language_concept \n> etc.) hanging \n> off any one 'soks:Concept' in a thesaurus schema.\n> [I guess 'soks:english_language_concept' has domain \n> 'soks:Concept' and \n> range 'soks:English_concept' ....]\n> Using this approach, we can keep the cardinality constraint = 1 for \n> 'soks:descriptor' properties (because there would be one for each of \n> 'soks:English_concept', 'soks:Japenese_concept', etc)?\n> [I suppose 'soks:English_concept' could be further subclassed for \n> American_english etc.]\n> However, typically, one then feels that further constraints are now \n> required to protect data integrity. Such as a constraint that the \n> 'descriptor' property value for any [Language]_concept must \n> be in the same \n> language as that [Language]_concept bla bla.\n> \n> Hmmm ... :-)\n> \n> Nikki\n> \n> > But in any case you need to add the qualifier \"in any given \n> conceptual \n> > scheme\". That definitely makes expressing the cardinality \n> constraint \n> > in OWL unworkable.\n> >\n> > Dave\n> >\n> >\n> \n> \n> \n> ----------------------\n> NJ Rogers, Technical Researcher\n> (Semantic Web Applications Developer)\n> Institute for Learning and Research Technology (ILRT) \n> Email:nikki.rogers@bristol.ac.uk\n> Tel: +44(0)117 9287096 (Direct)\n> Tel: +44(0)117 9287193 (Office)\n> \n\n\n\n"
        },
        {
            "subject": "RE: Design Issue (4)  constraining 'descriptor'/'prefLabel' card inality for multilingual thesaur",
            "content": "Hey Steve,\n\nYeah I got really excited when I read the spec about rdf:Alt containers,\nbecause this seemed a way to keep the cardinality of the soks:descriptor\nproperty to one and still have language alternatives.  The RDF specs and the\nDC in RDF specs have examples doing things this way.  \n\nSo e.g.\n\n<soks:Concept>\n<soks:descriptor>\n<rdf:Alt>\n<rdf:li xml:lang=\"en\">Bangers and mash\n(cuisine)</rdf:li>\n<rdf:li xml:lang=\"fr\">Saucisson et pomme de terre\nAnglais</rdf:li>\n</rdf:Alt>\n</soks:descriptor>\n</soks:Concept>\n\nHowever Danbri sent me a mail back saying that rdf:Alt is no good because\nthere is no consistent notion of 'alternative' behind it.  Danbri, is this\nreally no go?\n\nAl.  \n\n-----Original Message-----\nFrom: Cayzer, Steve [mailto:Steve.Cayzer@hp.com]\nSent: 07 November 2003 14:34\nTo: 'NJ Rogers, Learning and Research Technology'; Dave Reynolds; Miles,\nAJ (Alistair)\nCc: 'public-esw-thes@w3.org'\nSubject: RE: Design Issue (4) - constraining 'descriptor'/'prefLabel'\ncardinality for multilingual thesauri\n\n\n\nFirst mail to list - hi all! so sorry if I've missed vital context.\n\n1. sound like a workable fallback \n2. works but adds inference load \n3. Urgh! This is similar to the classic subclassing error of OO modelling\n(imo) - except it's subproperty of course.\n\nWhat about saying (apologies for any N3 errors)\n<concept> \n   :hasDescriptor [:inLanguage <French>; :value \"chaud\"];   \n   :hasDescriptor [:inLanguage <English>; :value \"hot\"] .\n\nOr, if you want to keep cardinality constraints, add a level of indirection\n<concept> \n   :hasDescriptor [:alternative [:inLanguage <French>; :value \"chaud\"];\n:alternative [:inLanguage <English>; :value \"hot\"]] .\n\nSteve\n> -----Original Message-----\n> From: NJ Rogers, Learning and Research Technology \n> [mailto:Nikki.Rogers@bristol.ac.uk] \n> Sent: 07 November 2003 12:14\n> To: Dave Reynolds; Miles, AJ (Alistair)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: Re: Design Issue (4) - constraining \n> 'descriptor'/'prefLabel' cardinality for multilingual thesauri\n> \n> \n> \n> Hi Alistair and Dave,\n> >\n> >> This does have consequences for constraining the data model.  It \n> >> means a node typed as a 'soks:Concept' must then be \n> allowed to have \n> >> multiple 'soks:descriptor' properties, one for each \n> language.  Is it \n> >> then possible in OWL to express the constraint that a concept may \n> >> have one and only one 'soks:descriptor' property for each language?\n> >\n> > Only if you represent content-in-a-specific-language as a \n> class, which \n> > would mean having a different class and different cardinality \n> > constraint for every language. Which probably wouldn't be workable.\n> >\n> I've been trying to consider some options here:\n> \n> ***********\n> 1. throw out the 'descriptor' cardinality constraint for multilingual \n> thesauri (as well as for/as distinct from monolingual \n> thesauri?) and don't \n> worry about it - live with it, & provide recommendation of use\n> \n> instead.\n> \n> ***********\n> 2. model multilingual thesauri in a specific way: express \n> each language's\n> \n> interpretation of a concept uniquely by giving the same \n> concept different \n> uri's in each of the languages in question. Then map the \n> concepts (using \n> \"owl:equivalentTo\").  That way we could still specify exactly \n> 1 preferred \n> label/'descriptor' per concept. Does it upset us to give \n> different uri's to \n> what certain communities believe to be the same concept? I guess how \n> inferencing is then conducted over the thesaurus data (for \n> queries) is then \n> critical & I haven't thought about this in any depth. \n> Therefore I'm not \n> sure if this approach is currently \"legal\".\n> \n> ***********\n> 3. Subclass 'soks:Concept' with what we'd understand to be \n> concepts in the \n> context of a particular language. I think this is similar to \n> what Dave is \n> referring to? And yes, it feels cranky:\n> \n> e.g.\n> \n> 'soks:Concept'\n>    |\n>    |\n> 'soks:English_concept'\n> \n> Then we'd potentially have multiple properties (e.g. \n> soks:english_language_concept, soks:japenese_language_concept \n> etc.) hanging \n> off any one 'soks:Concept' in a thesaurus schema.\n> [I guess 'soks:english_language_concept' has domain \n> 'soks:Concept' and \n> range 'soks:English_concept' ....]\n> Using this approach, we can keep the cardinality constraint = 1 for \n> 'soks:descriptor' properties (because there would be one for each of \n> 'soks:English_concept', 'soks:Japenese_concept', etc)?\n> [I suppose 'soks:English_concept' could be further subclassed for \n> American_english etc.]\n> However, typically, one then feels that further constraints are now \n> required to protect data integrity. Such as a constraint that the \n> 'descriptor' property value for any [Language]_concept must \n> be in the same \n> language as that [Language]_concept bla bla.\n> \n> Hmmm ... :-)\n> \n> Nikki\n> \n> > But in any case you need to add the qualifier \"in any given \n> conceptual \n> > scheme\". That definitely makes expressing the cardinality \n> constraint \n> > in OWL unworkable.\n> >\n> > Dave\n> >\n> >\n> \n> \n> \n> ----------------------\n> NJ Rogers, Technical Researcher\n> (Semantic Web Applications Developer)\n> Institute for Learning and Research Technology (ILRT) \n> Email:nikki.rogers@bristol.ac.uk\n> Tel: +44(0)117 9287096 (Direct)\n> Tel: +44(0)117 9287193 (Office)\n> \n\n\n\n"
        },
        {
            "subject": "Re: FW: [Fwd: Shared Key Authentication for the TLS Protocol&ndash;&ndash; anAlternative",
            "content": "Dan Simon wrote:\n> \n> >\n> >From:  Jeff Williams[SMTP:jwkckid1@ix.netcom.com]\n> >\n> >  I suppose this would partly be a response to what Peter has rightly\n> >pointed out.  I guess where I get confused is how does this address in\n> >total, address standardazation of winsock's?\n> >\n> >If two Winsock implementations support TLS, and TLS includes shared-key\n> >client authentication, then they would be able to do shared-key client\n> >authentication interoperably.  If you're thinking about APIs rather than wire\n> >formats, then a standardized API for shared-key authentication is no trickier\n> >to come up with than one that handles public-key authentication--it's just\n> >that this working group explicitly decided to avoid discussing APIs in its\n> >hoped-for standard.\n> >\n> >>\n> >>There is another justification for this incorporation in the case of\n> >>shared-key authentication that does not apply in the case of public-key\n> >>authentication:  if for any reason the channel used is not strongly\n> >>encrypted, and the shared key being used for authentication is guessable\n> >>(as is often the case for user-remembered passwords), then any fully\n> >>layered solution will be vulnerable to brute-force offline attacks.\n> >>Incorporating the authentication protocol into TLS allows a special\n> >>exception to be made for the authentication data, strongly protecting it\n> >>even if the normal traffic is not strongly encrypted.\n> >\n> >  Does this special exception for authentication data provide for\n> >interoperability?\n> >\n> >Certainly.  It would occur automatically and transparently--\"under the\n> >covers\", as it were.  No need for API changes, for example.\n> >\n> >\n> >                               Daniel Simon\n> >                               Cryptographer, Microsoft Corp.\n> >                               dansimon@microsoft.com\n> >\n> >\n> >\n> >\nunsubscribe\n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (4)  constraining 'descriptor'/'prefLabel' card inality for multilingual thesaur",
            "content": "Yup, generally rdf:Alt is pretty bad. There is also currently language\nin the spec that says something like \"the first value is the default\". \nWhich may be I18N-unwise, if we hold the English and French text in the \nexample below to be equally good characterisations of the concept.\n\nMy understanding of 1st is that it means the rdf:_1 property, so a\nworkaround would be to use \n\n <rdf:_2 xml:lang=\"en\">Bangers and mash(cuisine)</rdf:li>\n <rdf:_3 xml:lang=\"fr\">Saucisson et pomme de terre Anglais</rdf:li>\n\n(since only rdf:_1 is considered the default)\n\n...instead. In fact I just proposed this (tasteless hack!) as a\nworkaround in the RDFCore telecon today.\n\nYou could, if you like the basic data structure, do something \nwith the same shaped graph as your proposal, just not use rdf:Alt.\neg. invent a class to replace Alt, and named properties (or rdf:value\nperhaps) for the pointers from its instance to the bits of lang-tagged\ntext.\n\nBacking up a bit, is there a lot of value in having a cardinality \nconstraint on soks:descriptor? \n\n<soks:Concept>\n <soks:descriptor xml:lang=\"en\">Bangers and mash (cuisine)</soks:descriptor>\n <soks:descriptor xml:lang=\"fr\">Saucisson et pomme de terre Anglais</soks:descriptor>\n</soks:Concept>\n\n...looks good to me. Is it significantly more annoying for some classes\nof user, implementation etc?\n\nDan\n\n\n\n\n* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-11-07 17:20-0000]\n> \n> Hey Steve,\n> \n> Yeah I got really excited when I read the spec about rdf:Alt containers,\n> because this seemed a way to keep the cardinality of the soks:descriptor\n> property to one and still have language alternatives.  The RDF specs and the\n> DC in RDF specs have examples doing things this way.  \n> \n> So e.g.\n> \n> <soks:Concept>\n> <soks:descriptor>\n> <rdf:Alt>\n> <rdf:li xml:lang=\"en\">Bangers and mash\n> (cuisine)</rdf:li>\n> <rdf:li xml:lang=\"fr\">Saucisson et pomme de terre\n> Anglais</rdf:li>\n> </rdf:Alt>\n> </soks:descriptor>\n> </soks:Concept>\n> \n> However Danbri sent me a mail back saying that rdf:Alt is no good because\n> there is no consistent notion of 'alternative' behind it.  Danbri, is this\n> really no go?\n> \n> Al.  \n> \n> -----Original Message-----\n> From: Cayzer, Steve [mailto:Steve.Cayzer@hp.com]\n> Sent: 07 November 2003 14:34\n> To: 'NJ Rogers, Learning and Research Technology'; Dave Reynolds; Miles,\n> AJ (Alistair)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: RE: Design Issue (4) - constraining 'descriptor'/'prefLabel'\n> cardinality for multilingual thesauri\n> \n> \n> \n> First mail to list - hi all! so sorry if I've missed vital context.\n> \n> 1. sound like a workable fallback \n> 2. works but adds inference load \n> 3. Urgh! This is similar to the classic subclassing error of OO modelling\n> (imo) - except it's subproperty of course.\n> \n> What about saying (apologies for any N3 errors)\n> <concept> \n>    :hasDescriptor [:inLanguage <French>; :value \"chaud\"];   \n>    :hasDescriptor [:inLanguage <English>; :value \"hot\"] .\n> \n> Or, if you want to keep cardinality constraints, add a level of indirection\n> <concept> \n>    :hasDescriptor [:alternative [:inLanguage <French>; :value \"chaud\"];\n> :alternative [:inLanguage <English>; :value \"hot\"]] .\n> \n> Steve\n> > -----Original Message-----\n> > From: NJ Rogers, Learning and Research Technology \n> > [mailto:Nikki.Rogers@bristol.ac.uk] \n> > Sent: 07 November 2003 12:14\n> > To: Dave Reynolds; Miles, AJ (Alistair)\n> > Cc: 'public-esw-thes@w3.org'\n> > Subject: Re: Design Issue (4) - constraining \n> > 'descriptor'/'prefLabel' cardinality for multilingual thesauri\n> > \n> > \n> > \n> > Hi Alistair and Dave,\n> > >\n> > >> This does have consequences for constraining the data model.  It \n> > >> means a node typed as a 'soks:Concept' must then be \n> > allowed to have \n> > >> multiple 'soks:descriptor' properties, one for each \n> > language.  Is it \n> > >> then possible in OWL to express the constraint that a concept may \n> > >> have one and only one 'soks:descriptor' property for each language?\n> > >\n> > > Only if you represent content-in-a-specific-language as a \n> > class, which \n> > > would mean having a different class and different cardinality \n> > > constraint for every language. Which probably wouldn't be workable.\n> > >\n> > I've been trying to consider some options here:\n> > \n> > ***********\n> > 1. throw out the 'descriptor' cardinality constraint for multilingual \n> > thesauri (as well as for/as distinct from monolingual \n> > thesauri?) and don't \n> > worry about it - live with it, & provide recommendation of use\n> > \n> > instead.\n> > \n> > ***********\n> > 2. model multilingual thesauri in a specific way: express \n> > each language's\n> > \n> > interpretation of a concept uniquely by giving the same \n> > concept different \n> > uri's in each of the languages in question. Then map the \n> > concepts (using \n> > \"owl:equivalentTo\").  That way we could still specify exactly \n> > 1 preferred \n> > label/'descriptor' per concept. Does it upset us to give \n> > different uri's to \n> > what certain communities believe to be the same concept? I guess how \n> > inferencing is then conducted over the thesaurus data (for \n> > queries) is then \n> > critical & I haven't thought about this in any depth. \n> > Therefore I'm not \n> > sure if this approach is currently \"legal\".\n> > \n> > ***********\n> > 3. Subclass 'soks:Concept' with what we'd understand to be \n> > concepts in the \n> > context of a particular language. I think this is similar to \n> > what Dave is \n> > referring to? And yes, it feels cranky:\n> > \n> > e.g.\n> > \n> > 'soks:Concept'\n> >    |\n> >    |\n> > 'soks:English_concept'\n> > \n> > Then we'd potentially have multiple properties (e.g. \n> > soks:english_language_concept, soks:japenese_language_concept \n> > etc.) hanging \n> > off any one 'soks:Concept' in a thesaurus schema.\n> > [I guess 'soks:english_language_concept' has domain \n> > 'soks:Concept' and \n> > range 'soks:English_concept' ....]\n> > Using this approach, we can keep the cardinality constraint = 1 for \n> > 'soks:descriptor' properties (because there would be one for each of \n> > 'soks:English_concept', 'soks:Japenese_concept', etc)?\n> > [I suppose 'soks:English_concept' could be further subclassed for \n> > American_english etc.]\n> > However, typically, one then feels that further constraints are now \n> > required to protect data integrity. Such as a constraint that the \n> > 'descriptor' property value for any [Language]_concept must \n> > be in the same \n> > language as that [Language]_concept bla bla.\n> > \n> > Hmmm ... :-)\n> > \n> > Nikki\n> > \n> > > But in any case you need to add the qualifier \"in any given \n> > conceptual \n> > > scheme\". That definitely makes expressing the cardinality \n> > constraint \n> > > in OWL unworkable.\n> > >\n> > > Dave\n> > >\n> > >\n> > \n> > \n> > \n> > ----------------------\n> > NJ Rogers, Technical Researcher\n> > (Semantic Web Applications Developer)\n> > Institute for Learning and Research Technology (ILRT) \n> > Email:nikki.rogers@bristol.ac.uk\n> > Tel: +44(0)117 9287096 (Direct)\n> > Tel: +44(0)117 9287193 (Office)\n> > \n\n\n\n"
        },
        {
            "subject": "RE: Design Issue (4)  constraining 'descriptor'/'prefLabel' card inality for multilingual thesaur",
            "content": "> Backing up a bit, is there a lot of value in having a cardinality \n> constraint on soks:descriptor? \n> \n> <soks:Concept>\n>  <soks:descriptor xml:lang=\"en\">Bangers and mash \n> (cuisine)</soks:descriptor>\n>  <soks:descriptor xml:lang=\"fr\">Saucisson et pomme de terre \n> Anglais</soks:descriptor>\n> </soks:Concept>\n> \n> ...looks good to me. Is it significantly more annoying for \n> some classes\n> of user, implementation etc?\n> \n> Dan\n\nIt just means we have to write some guidelines for usage and hope people\nstick to them.  We can't use something like OWL to formally express the\nconstraint.\n\nPersonally, I'm fine with this approach.  It's simple and pragmatic.  Anyone\nthink this could be a problem?\n\nAl.  \n \n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (4)  constraining 'descriptor'/'prefLabel' card inality for multilingual thesaur",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-11-10 12:17-0000]\n> > Backing up a bit, is there a lot of value in having a cardinality \n> > constraint on soks:descriptor? \n> > \n> > <soks:Concept>\n> >  <soks:descriptor xml:lang=\"en\">Bangers and mash \n> > (cuisine)</soks:descriptor>\n> >  <soks:descriptor xml:lang=\"fr\">Saucisson et pomme de terre \n> > Anglais</soks:descriptor>\n> > </soks:Concept>\n> > \n> > ...looks good to me. Is it significantly more annoying for \n> > some classes\n> > of user, implementation etc?\n> > \n> > Dan\n> \n> It just means we have to write some guidelines for usage and hope people\n> stick to them.  We can't use something like OWL to formally express the\n> constraint.\n\nProse is under-estimated :)\n\n> Personally, I'm fine with this approach.  It's simple and pragmatic.  Anyone\n> think this could be a problem?\n> \n> Al.  \n>  \n\n\n\n"
        },
        {
            "subject": "NEW Issue (5) - Using Concepts for subjectbased indexing and cla ssificatio",
            "content": "I've added a new open design issue to the RDF Thesaurus Wiki page \n\nhttp://esw.w3.org/topic/RdfThesaurus\n\nA summary of the issue:\n\nIssue 5 - Using Concepts for subject-based indexing and classification\n\nWe want to be able to say, 'my article is about Concept x from Thesaurus y'.\nThese statements could then be used for subject-based indexing. \n\nThe question is, what property to we recommend to use to do this sort of\nthing? Do we invent a new one, or do we try to re-use something? \n\n2.5.1 Comments on Issue 5\n\n\nAJM>> We could go with qualified dublin core, and recommend using\ndc:subject. \n\n.....\n\nSo in summary, I have suggested an approach to subject-based indexing using\nthesaurus concepts that is entirely consistent with all variations in the\nqualified dublin core approach. The question is, do we like dcq? \n\n\n\n\n\nAl.\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Design Issue (3)  How to label concepts",
            "content": "Hi Dave,\n\nThe other thing about this approach is that it would break the consistency\nwith the qualified dublin core approach to subject statements (see design\nissue 5 which I just added).\n\nAl.\n\n> In that case one option would be to change the range of descriptor to \n> capture the context.\n> \n>      property soks:descriptor (domain = Concept, range = Descriptor)\n>      class soks:Descriptor\n>      property soks:descriptorTerm (domain = Descriptor, range \n> = Literal)\n>      property soks:descriptorSchema (domain = Desciptor, \n> range = Resource)\n> \n> Then in instance data the descritor is a b-node pointing to \n> the literal and \n> to a URI identifying the conceptual schema. This would \n> facilitate merging.\n> \n> The downside is that this version of soks:descriptor couldn't be a \n> subProperty of rdfs:label.\n> \n> Dave\n> \n\n\n\n"
        },
        {
            "subject": "Design Issue (3)  How to label concepts? Dropping soks:altLabe",
            "content": "Hi Dave,\n\nI'm quite happy to ditch 'soks:altLabel' and assume all 'rdfs:label's that\nare not 'soks:prefLabel' are alternatives.  This is definitely more\neconomical.\n\nAl.\n\n> My suggestion implicitly had \"altLabel\" as a label which is not a \n> perfLabel. This might have some advantages when it comes to \n> merging. If you \n> have two thesauri with differing perferred terms for the same \n> concept the \n> merge would just have two prefLabels and all else (not \n> preferred in either) \n> would be treated as alt. Don't know enough about how thesauri \n> are used in \n> practice to know if that is beter or worse.\n> \n\n\n\n"
        },
        {
            "subject": "Re: NEW Issue (5) - Using Concepts for subjectbased indexing and cla           ssificatio",
            "content": "Hi Alistair\n\n> AJM>> We could go with qualified dublin core, and recommend using\n> dc:subject.\n>\n> .....\n>\n> So in summary, I have suggested an approach to subject-based indexing\n> using thesaurus concepts that is entirely consistent with all variations\n> in the qualified dublin core approach. The question is, do we like dcq?\n>\n>\nAlso, for content providers describing collection level data we might want \nto recommend:\n\nhttp://www.ukoln.ac.uk/metadata/rslp/schema/\n\n?\n\nNikki\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Re: NEW Issue (5) - Using Concepts for subjectbased indexing and cla           ssificatio",
            "content": "& I've just noticed\nhttp://dublincore.org/groups/collections/\n\n--On 10 November 2003 13:44 +0000 \"NJ Rogers, Learning and Research \nTechnology\" <Nikki.Rogers@bristol.ac.uk> wrote:\n\n>\n> Hi Alistair\n>\n>> AJM>> We could go with qualified dublin core, and recommend using\n>> dc:subject.\n>>\n>> .....\n>>\n>> So in summary, I have suggested an approach to subject-based indexing\n>> using thesaurus concepts that is entirely consistent with all variations\n>> in the qualified dublin core approach. The question is, do we like dcq?\n>>\n>>\n> Also, for content providers describing collection level data we might\n> want to recommend:\n>\n> http://www.ukoln.ac.uk/metadata/rslp/schema/\n>\n> ?\n>\n> Nikki\n>\n> ----------------------\n> NJ Rogers, Technical Researcher\n> (Semantic Web Applications Developer)\n> Institute for Learning and Research Technology (ILRT)\n> Email:nikki.rogers@bristol.ac.uk\n> Tel: +44(0)117 9287096 (Direct)\n> Tel: +44(0)117 9287193 (Office)\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: Design Issue (3)  How to label concepts? Dropping soks:altLa be",
            "content": "Doesn't that break an open world assumption?\n\nSteve\n\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: 10 November 2003 13:34\n> To: 'public-esw-thes@w3.org'\n> Subject: Design Issue (3) - How to label concepts? Dropping \n> soks:altLabel\n> \n> \n> \n> Hi Dave,\n> \n> I'm quite happy to ditch 'soks:altLabel' and assume all \n> 'rdfs:label's that are not 'soks:prefLabel' are alternatives. \n>  This is definitely more economical.\n> \n> Al.\n> \n> > My suggestion implicitly had \"altLabel\" as a label which is not a\n> > perfLabel. This might have some advantages when it comes to \n> > merging. If you \n> > have two thesauri with differing perferred terms for the same \n> > concept the \n> > merge would just have two prefLabels and all else (not \n> > preferred in either) \n> > would be treated as alt. Don't know enough about how thesauri \n> > are used in \n> > practice to know if that is beter or worse.\n> > \n> \n\n\n\n"
        },
        {
            "subject": "Re: [Fwd: Shared Key Authentication for the TLS Protocol&ndash;&ndash; an Alternative",
            "content": "Dan Simon wrote:\n> \n> >Peter:  you seem to be conflating two different distinctions--the distinction\n> >between socket-level and application level access control, on the one hand,\n> >and the distinction between public-key-based and shared-key-based\n> >authentication on the other.  I agree one hundred percent that incorporating\n> >client authentication into SSL/TLS makes system-level access control\n> >possible, and that that is a good thing.  I simply don't agree with your\n> >apparent claim that such access control must necessarily be based on\n> >public-key authentication; on the contrary, I expect it that when it occurs,\n> >it will often be shared-key-based, for any number of reasons.  Hence the\n> >necessity for TLS to have a shared-key authentication feature.\n> >\n> >Regarding some of the other points you raised:\n> >\n> >From:  Peter Williams[SMTP:peter@verisign.com]\n> >\n> >Any alternative *SSL* authentication service must be performable within the\n> >handshake, and\n> >not require encryption.The only real reason to invest in a new mechanism\n> >is because a some new interesting class of cipher exists which needs some\n> >help\n> >in the handshake messages so as to expoit its authentication properties. (SSL\n> >multicast authentication I believe will be a case in point, one day)\n> >\n> >For example, if I used a TYPE I algoirhtm which matched RSA properties,\n> >I would not expect to change SSL except to introduce a new cipherSuite.\n> >If I used Type II KEA which is related to DH, I would not expect to change\n> >SSL;\n> >rather, Id just introduce a new cipherSuite. If we use Elliptic,\n> >Curves, again there is nothing new in any of these algoirhtms which changes\n> >SSL.\n> >\n> >I dont believe TLS should allow any encryption, other than via public key\n> >exchange,\n> >during the handshake.\n> >\n> >In fact, under the proposed shared-key authentication extension, it does not.\n> > The strong protection of the shared-key authentication response is effected\n> >using a keyed cryptographic hash, not encryption.\n> >\n> >Why cannot we merely register a cipherSuite whose semantics are: do strong\n> >encrytion\n> >for the first n bytes of user data; having performed a handshake. The server\n> >must then authenticate\n> >the n bytes of shared-secret authentication from the user-stream, and perform\n> >a new handshake if\n> >it accepts the access control policy.  The server may choose to require\n> >client authentication,\n> >and mandatory access control estbalishment upon completeion of the first\n> >handshake, if\n> >thats its policy.\n> >\n> >Exactly the same argument could apply to public-key client authentication as\n> >well; however, we (hopefully) all agree that a single public-key client\n> >authentication standard embedded into TLS vastly improves its\n> >interoperability and allows application-independent security decisions to be\n> >made about clients.  Similarly, your proposal does not address the\n> >interoperability problem with respect to shared-key authentication, nor the\n> >application-independent control of sockets.  Moreover, under this proposal,\n> >any socket-level implementation of TLS would likely run into export problems,\n> >since it would have to ship some amount of uncontrolled data across the\n> >channel using strong encryption.\n> >\n> >\n> >                               Daniel Simon\n> >                               Cryptographer, Microsoft Corp.\n> >                               dansimon@microsoft.com\n> >\n> >\n> >\n> >\n> >\nunsubscribe\n\n\n\n"
        },
        {
            "subject": "RE: Design Issue (4)  constraining 'descriptor'/'prefLabel' card  inality for multilingual thesaur",
            "content": "Clarification to my mail.\n\nSteve\n\n> -----Original Message-----\n> From: Dan Brickley [mailto:danbri@w3.org] \n> \n> \n> You could, if you like the basic data structure, do something \n> with the same shaped graph as your proposal, just not use \n> rdf:Alt. eg. invent a class to replace Alt, and named \n> properties (or rdf:value\n> perhaps) for the pointers from its instance to the bits of \n> lang-tagged text.\n\nThat was the intention behind my suggestion [1]\nie 'alternative' != rdf:Alt. \n\n> \n> Backing up a bit, is there a lot of value in having a cardinality \n> constraint on soks:descriptor? \n\nSo using xml language tags to avoid the RDF clumsiness in [2]. Cool.\n\nSteve\n\n[1] \n<concept> \n:hasDescriptor [:alternative [:inLanguage <French>; :value \"chaud\"];\n:alternative [:inLanguage <English>; :value \"hot\"]] .\n[2]\n<concept> \n   :hasDescriptor [:inLanguage <French>; :value \"chaud\"];   \n   :hasDescriptor [:inLanguage <English>; :value \"hot\"] .\n\n\n\n"
        },
        {
            "subject": "OWL question (scoping out systems for interthesaurus mapping",
            "content": "Hi Dave,\n\nQuick question about the OWL reasoner,\n\nif I have the following model:\n\n<owl:Restriction>\n<owl:onProperty rdf:resource=\"&dc;subject\"/>\n<owl:hasValue rdf:resource=\"&thes1;trees\"/>\n<owl:equivalentClass>\n<owl:Restriction>\n<owl:onProperty rdf:resource=\"&dc;subject\"/>\n<owl:hasValue rdf:resource=\"&thes2;arbres\"/>\n</owl:Restriction>\n</owl:equivalentClass>\n</owl:Restriction>\n\n<rdf:Description rdf:about=\"http://www.bigal.com/trees.html\">\n<dc:subject rdf:resource=\"&thes1;trees\"/>\n</rdf:Description>\n\nWould the OWL reasoner infer that ...\n\n<rdf:Description rdf:about=\"http://www.bigal.com/trees.html>\n<dc:subject rdf:resource=\"&thes2;arbres\"/>\n</rdf:Description>\n\n???\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "NEW issue 6  defining semantic relationship",
            "content": "I've added this issue to the RDF Thesaurus ESW Wiki.\n\nhttp://esw.w3.org/topic/RdfThesaurus?action=show\n\nShort summary:\n\nIssue 6 - Defining semantic relationships\n\nDescription: A thesaurus consists of concepts, labels for concepts, and\nsemantic relationships between concepts. A semantic relationship is a\nrelationship of meaning. Most thesauri use a similar set of semantic\nrelationships, which they label 'broader' 'narrower' and 'related'. \n\nProblem 1: 'broader/narrower' means different things in different thesauri.\nIn some thesauri it means strictly class-subsumption. In other thesauri it\ncan mean either is-a, instance-of, or part-of. Also 'related' is not\nconsistently used. For example some thesauri model part-of relations with\n'related', others use 'broader/narrower' \n\n=> We must invent some mechanism for providing clear definitions of semantic\nrelationships, and for removing any scope for ambiguity. \n\nProblem 2: some thesauri have semantic relations other than\n'broader/narrower' and 'related'. Some overcome the 'broader/narrower'\nfuzziness by using 'BTI', 'BTG' and 'BTP', which stand for\n'broader-term-instantive' 'broader-term-generic' and\n'broader-term-partitive' respectively. In others there are custom\nrelationships like 'related-broader'. \n\n=> We must provide some mechanism by which users can extend the given\nrelationship set and define their own semantic relations. \n\n.....\n\n\nAlistair Miles\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: NEW issue 6  defining semantic relationship",
            "content": "One of the immediate applications that occurs to me for RDF thesauruses is\nin mapping between discrete taxonomies. Whatever approach to defining\nrelationships is adopted, I hope it will be straightforward to take a tree\nlike the Open Directory website categorization [1] and be able to map across\nto corresponding terms in another hierarchy like the Topic Exchange [2], and\ncarry out merge-like operations (I say merge-like because the structures may\nbe incompatible, and class/subclass relationships may only work in localized\nregions of the trees).\n\nCheers,\nDanny.\n\n[1] http://dmoz.org/\n[2] http://topicexchange.com/\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Miles, AJ (Alistair)\n>\n> Sent: 11 November 2003 16:33\n> To: 'public-esw-thes@w3.org'\n> Subject: NEW issue 6 - defining semantic relationships\n>\n>\n>\n> I've added this issue to the RDF Thesaurus ESW Wiki.\n>\n> http://esw.w3.org/topic/RdfThesaurus?action=show\n>\n> Short summary:\n>\n> Issue 6 - Defining semantic relationships\n>\n> Description: A thesaurus consists of concepts, labels for concepts, and\n> semantic relationships between concepts. A semantic relationship is a\n> relationship of meaning. Most thesauri use a similar set of semantic\n> relationships, which they label 'broader' 'narrower' and 'related'.\n>\n> Problem 1: 'broader/narrower' means different things in different\n> thesauri.\n> In some thesauri it means strictly class-subsumption. In other thesauri it\n> can mean either is-a, instance-of, or part-of. Also 'related' is not\n> consistently used. For example some thesauri model part-of relations with\n> 'related', others use 'broader/narrower'\n>\n> => We must invent some mechanism for providing clear definitions\n> of semantic\n> relationships, and for removing any scope for ambiguity.\n>\n> Problem 2: some thesauri have semantic relations other than\n> 'broader/narrower' and 'related'. Some overcome the 'broader/narrower'\n> fuzziness by using 'BTI', 'BTG' and 'BTP', which stand for\n> 'broader-term-instantive' 'broader-term-generic' and\n> 'broader-term-partitive' respectively. In others there are custom\n> relationships like 'related-broader'.\n>\n> => We must provide some mechanism by which users can extend the given\n> relationship set and define their own semantic relations.\n>\n> .....\n>\n>\n> Alistair Miles\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>\n\n\n\n"
        },
        {
            "subject": "Intervocab mappin",
            "content": "Hi Danny,\n\nI'm just working on a write-up of the cross-vocab mapping problem, with\npotential solutions.  Coming soon!\n\nNikki - interesting use case here?  Mapping from an open blog categorisation\nscheme to an open web directory. Quite different from library-type apps with\ncoherent managed collections, much more open-world. \n\nAl.\n\n> -----Original Message-----\n> From: Danny Ayers [mailto:danny666@virgilio.it]\n> Sent: 11 November 2003 16:54\n> To: Miles, AJ (Alistair) ; public-esw-thes@w3.org\n> Subject: RE: NEW issue 6 - defining semantic relationships\n> \n> \n> One of the immediate applications that occurs to me for RDF \n> thesauruses is\n> in mapping between discrete taxonomies. Whatever approach to defining\n> relationships is adopted, I hope it will be straightforward \n> to take a tree\n> like the Open Directory website categorization [1] and be \n> able to map across\n> to corresponding terms in another hierarchy like the Topic \n> Exchange [2], and\n> carry out merge-like operations (I say merge-like because the \n> structures may\n> be incompatible, and class/subclass relationships may only \n> work in localized\n> regions of the trees).\n> \n> Cheers,\n> Danny.\n> \n> [1] http://dmoz.org/\n> [2] http://topicexchange.com/\n> \n> > -----Original Message-----\n> > From: public-esw-thes-request@w3.org\n> > [mailto:public-esw-thes-request@w3.org]On Behalf Of Miles, \n> AJ (Alistair)\n> >\n> > Sent: 11 November 2003 16:33\n> > To: 'public-esw-thes@w3.org'\n> > Subject: NEW issue 6 - defining semantic relationships\n> >\n> >\n> >\n> > I've added this issue to the RDF Thesaurus ESW Wiki.\n> >\n> > http://esw.w3.org/topic/RdfThesaurus?action=show\n> >\n> > Short summary:\n> >\n> > Issue 6 - Defining semantic relationships\n> >\n> > Description: A thesaurus consists of concepts, labels for \n> concepts, and\n> > semantic relationships between concepts. A semantic \n> relationship is a\n> > relationship of meaning. Most thesauri use a similar set of semantic\n> > relationships, which they label 'broader' 'narrower' and 'related'.\n> >\n> > Problem 1: 'broader/narrower' means different things in different\n> > thesauri.\n> > In some thesauri it means strictly class-subsumption. In \n> other thesauri it\n> > can mean either is-a, instance-of, or part-of. Also 'related' is not\n> > consistently used. For example some thesauri model part-of \n> relations with\n> > 'related', others use 'broader/narrower'\n> >\n> > => We must invent some mechanism for providing clear definitions\n> > of semantic\n> > relationships, and for removing any scope for ambiguity.\n> >\n> > Problem 2: some thesauri have semantic relations other than\n> > 'broader/narrower' and 'related'. Some overcome the \n> 'broader/narrower'\n> > fuzziness by using 'BTI', 'BTG' and 'BTP', which stand for\n> > 'broader-term-instantive' 'broader-term-generic' and\n> > 'broader-term-partitive' respectively. In others there are custom\n> > relationships like 'related-broader'.\n> >\n> > => We must provide some mechanism by which users can extend \n> the given\n> > relationship set and define their own semantic relations.\n> >\n> > .....\n> >\n> >\n> > Alistair Miles\n> >\n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> >\n> > Email:        a.j.miles@rl.ac.uk\n> > Telephone: +44 (0)1235 445440\n> >\n> >\n> \n\n\n\n"
        },
        {
            "subject": "Re: Intervocab mappin",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-11-11 17:23-0000]\n> \n> Hi Danny,\n> \n> I'm just working on a write-up of the cross-vocab mapping problem, with\n> potential solutions.  Coming soon!\n> \n> Nikki - interesting use case here?  Mapping from an open blog categorisation\n> scheme to an open web directory. Quite different from library-type apps with\n> coherent managed collections, much more open-world. \n\n+1\nI think v good to try representing something like DMoz, which is grassroots and messy \nas an organisational system, yet substantive and useful w/ tons of data.\n\nI would love to try writing rules to make explicit some of the structure \nimplicit in DMoz's hierarchy, ie. express as RDF properties the \nthings that underpin something's place in the tree.\n\nEg. a section homepages-of-popstars, hypothetically, might have 1000\npages listed. For each of those, it is implied (we might argue) that \nthere exists a popstar, and the popstar has a foaf:homepage relation to \nthat page. Same for restaurant reviews etc. Geographic facets would be a \ngood thing to mine. This would show a path to get from the\ndocument-centric world of DMoz into the more world-centric world of RDF \nand ontologies...\n\nDan\n\n\n\n"
        },
        {
            "subject": "NEW Issue 7  Thesaurus Linking vs. Thesaurus Mappin",
            "content": "http://esw.w3.org/topic/RdfThesaurus\n\n\nIssue 7 - Thesaurus Linking vs. Thesaurus Mapping\n\n\nThere are two distinct situations. \n\nThesaurus Linking: An indexer wants a thesaurus for subject-based indexing\nof their collection. They find no one thesaurus offers adequate coverage,\nbut a combination of two or more thesauri does. So they want to create and\nuse a hybrid thesaurus. \n\nThesaurus Mapping A collection has been indexed with concepts from thesaurus\nA. A user wants to search this collection, but using concepts from thesaurus\nB. Thus some mechanism is required for either transforming the query or\ntransforming the index. \n\nThe purpose of this issue is to distinguish these two scenarios. If we use\nthe same mechanism for both linking and mapping, there is a lot of scope for\nconfusion. \n\n\nAlistair Miles.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "NEW Issue 8  Mechanisms for Thesaurus Linkin",
            "content": "http://esw.w3.org/topic/RdfThesaurus\n\nThe Problem: A user wants to create a hybrid thesaurus by plugging bits of\nexisting thesauri together. By what mechanism should they do this? \n\nSolution 1: To express thesaurus linke by using the normal semantic\nrelations of a thesaurus, 'broader/narrower' and 'related'. So if a user\nwants to prune a branch from a thesaurus, they remove the 'broader/narrower'\nstatements. If they want to add a branch, they add 'broader/narrower'\nstatements. This solution treats thesaurus linking as a special case of\naltering the organisational structure of a set of thesaurus concepts. \n\nSolution 2: Create custom linking properties that are not 'semantic\nrelations'. In this way the integrity and internal structure of each\nthesaurus is maintained. \n\n...\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "FW: HILT project wor",
            "content": "-----Original Message-----\nFrom: Paul Shabajee [mailto:Paul.Shabajee@bristol.ac.uk]\nSent: 13 November 2003 16:33\nTo: www-rdf-dspace@w3.org\nSubject: HILT project work\n\n\n\nJust been talking to colleagues at IRLT - realised that people at HILT have \nbeen doing some very interesting work (not discussed on their Web site - \nhttp://hilt.cdlr.strath.ac.uk/) on thesaurus mapping between DDC, UNESCO \nand LCSH and providing mapping services... see\n\nhttp://www.ukoln.ac.uk/metadata/hilt/m2m-report/hilt-final-report.pdf\n\nPaul\n\n\n\n"
        },
        {
            "subject": "Public List of Use cases onlin",
            "content": "Now linked from\n\nhttp://www.w3c.rl.ac.uk/SWAD/usecase.html\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: RDF Thesaurus  Unresolved Design Issue",
            "content": "Alistair,\n\nI added a couple of comments to the Wiki (issues 7 and 8)\nHowever, if you'd prefer the comments to go on the mailing list - and then\nyou post a summary to the wiki, that's fine too.\n\nCheers\n\nSteve\n\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: 31 October 2003 16:16\n> To: 'public-esw@w3.org'\n> Cc: 'public-esw-thes@w3.org'; Wilson, MD (Michael) \n> Subject: RDF Thesaurus - Unresolved Design Issues\n> \n> \n> \n> Hi everyone,\n> \n> I've started a writeup and discussion of unresolved design \n> issues regarding the RDF thesaurus work.  It's on the SWAD wiki >\n<http://esw.w3.org/topic/RdfThesaurus>.  Nikki, > Dave B., \n> Danbri, Dave R., Andy, Libby, Chaals, Steve C, \n> Paul, Brian, Ian, Alvaro, everyone in SWAD, it would be great \n> if you could get involved, I could really do with some \n> feedback and a bit of your expertise.\n> \n> I'll post a short summary to the public-esw-thes list when I \n> add any new issues to the wiki, so please keep an eye out.\n> \n> Yours,\n> \n> Alistair.     \n> \n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Wiki or lis",
            "content": "Hi Steve,\n\nYeah I'm not sure where to put what.  Maybe if you have any sort of\ndiscussion comments or ideas, post to the list.  If you have any more\nconcrete ideas or alternative solutions, edit the wiki.  Or just do both, I\ndon't mind!\n\nAl.\n\n> -----Original Message-----\n> From: Cayzer, Steve [mailto:Steve.Cayzer@hp.com]\n> Sent: 14 November 2003 10:38\n> To: 'Miles, AJ (Alistair) '; 'public-esw@w3.org'\n> Cc: 'public-esw-thes@w3.org'; Wilson, MD (Michael) \n> Subject: RE: RDF Thesaurus - Unresolved Design Issues\n> \n> \n> \n> Alistair,\n> \n> I added a couple of comments to the Wiki (issues 7 and 8)\n> However, if you'd prefer the comments to go on the mailing \n> list - and then\n> you post a summary to the wiki, that's fine too.\n> \n> Cheers\n> \n> Steve\n> \n> > -----Original Message-----\n> > From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> > Sent: 31 October 2003 16:16\n> > To: 'public-esw@w3.org'\n> > Cc: 'public-esw-thes@w3.org'; Wilson, MD (Michael) \n> > Subject: RDF Thesaurus - Unresolved Design Issues\n> > \n> > \n> > \n> > Hi everyone,\n> > \n> > I've started a writeup and discussion of unresolved design \n> > issues regarding the RDF thesaurus work.  It's on the SWAD wiki >\n> <http://esw.w3.org/topic/RdfThesaurus>.  Nikki, > Dave B., \n> > Danbri, Dave R., Andy, Libby, Chaals, Steve C, \n> > Paul, Brian, Ian, Alvaro, everyone in SWAD, it would be great \n> > if you could get involved, I could really do with some \n> > feedback and a bit of your expertise.\n> > \n> > I'll post a short summary to the public-esw-thes list when I \n> > add any new issues to the wiki, so please keep an eye out.\n> > \n> > Yours,\n> > \n> > Alistair.     \n> > \n> > \n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> > \n> > Email:        a.j.miles@rl.ac.uk\n> > Telephone: +44 (0)1235 445440\n> > \n> > \n> \n\n\n\n"
        },
        {
            "subject": "Closing on sharedkey authenticatio",
            "content": "I'd like to close on the question of including shared-key\nauthentication in TLS. There has been little discussion\nof the latest proposal from Barbara Fox, but I think we\nwent over the arguments pretty thoroughly a few weeks\nago.\n\nAt this point, I propose that we adopt the proposed\nmodifications for the TLS draft. As always, I am happy\nto hear comments either on the list or in direct mail.\n\nIn addition, if there are other burning issues for substantive\nchanges, please let me know about them now.\n\nWin Treese\nTLS Working Group Chair\ntreese@OpenMarket.com\n\n\n\n"
        },
        {
            "subject": "NEW Issue 9  Concept Mappin",
            "content": "Hi everyone, \n\nI've had a go at writing up 'the biggie' - inter-thesaurus mapping.  It's\nIssue 9 on the RDFThesaurus wiki <http://esw.w3.org/topic/RdfThesaurus>.  I\nfound that it's a problem that seems very simple on the surface, then\nexplodes a bit when you get into it.  So anyway, I've done my best to be as\nclear as possible about it, I look forward to your comments and ideas.\n\nAl.\n\n\nIssue 9 - Inter-thesaurus mapping\n\nFor an introduction to the problem space, a good reference is Semantic\nProblems of Thesaurus Mapping\n<http://jodi.ecs.soton.ac.uk/Articles/v01/i08/Doerr/>. \n\nThe problem: How to express a mapping from concepts in one thesaurus to\nconcepts in another? \n\nThe current (non-semweb) solution: A mapping relationship between concepts\nfrom different thesauri is usually called an \"equivalence relationship\". The\nfollowing equivalence relationships are used: \n\n...\n\n\n\n\n\nAlistair Miles\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Wiki or lis",
            "content": "I prefer the list. Would it upset people idf the list were subscribed to the\nWiki so it gets notice of updates?\n\nChaals\n\nOn Fri, 14 Nov 2003, Miles, AJ (Alistair)  wrote:\n\n>\n>Hi Steve,\n>\n>Yeah I'm not sure where to put what.  Maybe if you have any sort of\n>discussion comments or ideas, post to the list.  If you have any more\n>concrete ideas or alternative solutions, edit the wiki.  Or just do both, I\n>don't mind!\n>\n>Al.\n>\n>> -----Original Message-----\n>> From: Cayzer, Steve [mailto:Steve.Cayzer@hp.com]\n>> Sent: 14 November 2003 10:38\n>> To: 'Miles, AJ (Alistair) '; 'public-esw@w3.org'\n>> Cc: 'public-esw-thes@w3.org'; Wilson, MD (Michael)\n>> Subject: RE: RDF Thesaurus - Unresolved Design Issues\n>>\n>>\n>>\n>> Alistair,\n>>\n>> I added a couple of comments to the Wiki (issues 7 and 8)\n>> However, if you'd prefer the comments to go on the mailing\n>> list - and then\n>> you post a summary to the wiki, that's fine too.\n>>\n>> Cheers\n>>\n>> Steve\n>>\n>> > -----Original Message-----\n>> > From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n>> > Sent: 31 October 2003 16:16\n>> > To: 'public-esw@w3.org'\n>> > Cc: 'public-esw-thes@w3.org'; Wilson, MD (Michael)\n>> > Subject: RDF Thesaurus - Unresolved Design Issues\n>> >\n>> >\n>> >\n>> > Hi everyone,\n>> >\n>> > I've started a writeup and discussion of unresolved design\n>> > issues regarding the RDF thesaurus work.  It's on the SWAD wiki >\n>> <http://esw.w3.org/topic/RdfThesaurus>.  Nikki, > Dave B.,\n>> > Danbri, Dave R., Andy, Libby, Chaals, Steve C,\n>> > Paul, Brian, Ian, Alvaro, everyone in SWAD, it would be great\n>> > if you could get involved, I could really do with some\n>> > feedback and a bit of your expertise.\n>> >\n>> > I'll post a short summary to the public-esw-thes list when I\n>> > add any new issues to the wiki, so please keep an eye out.\n>> >\n>> > Yours,\n>> >\n>> > Alistair.\n>> >\n>> >\n>> > CCLRC - Rutherford Appleton Laboratory\n>> > Building R1 Room 1.60\n>> > Fermi Avenue\n>> > Chilton\n>> > Didcot\n>> > Oxfordshire OX11 0QX\n>> > United Kingdom\n>> >\n>> > Email:        a.j.miles@rl.ac.uk\n>> > Telephone: +44 (0)1235 445440\n>> >\n>> >\n>>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Wiki or lis",
            "content": "* Charles McCathieNevile <charles@w3.org> [2003-11-16 09:34-0500]\n> \n> I prefer the list. Would it upset people idf the list were subscribed to the\n> Wiki so it gets notice of updates?\n\nI think the list is a good permanent record of thoughts, issues,\nchanges. While the wiki does keep a version history, it isn't quite the\nsame. A brief mail message can capture a snapshot of someone's thinking\nat a given point, which hopefully will also be reflected (eventually) in\nthe wiki view.\n\nWe should btw be very clear that we are making this up as we are going\nalong! One of the reasons I was originally excited to do this whole\nSWAD-E project was as a way of finding out the pros and cons of various\nways of collaborating on SW vocab development. Whether IRC, wiki, email,\nWeb can be somehow hoooked together to support lightweight collaboration\non RDF vocabs, and to use this experience to figure out how/whether/etc\nother W3C-related efforts might attempt similar things.\n\nLong way of saying: I don't know what will work, let's find out ;)\n\nI would support trying the experiment of subscribing this list to one or\nmore of the thesaurus wiki pages. If it gets annoying we can always back\noff... Interesting idea, let's see how it works out. Alistair, others,\nwould that be OK by you?\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: Wiki or lis",
            "content": "Fine by me.\n\n> -----Original Message-----\n> From: Dan Brickley [mailto:danbri@w3.org]\n> Sent: 16 November 2003 14:43\n> To: Charles McCathieNevile\n> Cc: Miles, AJ (Alistair) ; 'Cayzer, Steve'; 'public-esw-thes@w3.org'\n> Subject: Re: Wiki or list\n> \n> \n> \n> * Charles McCathieNevile <charles@w3.org> [2003-11-16 09:34-0500]\n> > \n> > I prefer the list. Would it upset people idf the list were \n> subscribed to the\n> > Wiki so it gets notice of updates?\n> \n> I think the list is a good permanent record of thoughts, issues,\n> changes. While the wiki does keep a version history, it isn't \n> quite the\n> same. A brief mail message can capture a snapshot of \n> someone's thinking\n> at a given point, which hopefully will also be reflected \n> (eventually) in\n> the wiki view.\n> \n> We should btw be very clear that we are making this up as we are going\n> along! One of the reasons I was originally excited to do this whole\n> SWAD-E project was as a way of finding out the pros and cons \n> of various\n> ways of collaborating on SW vocab development. Whether IRC, \n> wiki, email,\n> Web can be somehow hoooked together to support lightweight \n> collaboration\n> on RDF vocabs, and to use this experience to figure out \n> how/whether/etc\n> other W3C-related efforts might attempt similar things.\n> \n> Long way of saying: I don't know what will work, let's find out ;)\n> \n> I would support trying the experiment of subscribing this \n> list to one or\n> more of the thesaurus wiki pages. If it gets annoying we can \n> always back\n> off... Interesting idea, let's see how it works out. Alistair, others,\n> would that be OK by you?\n> \n> Dan\n> \n\n\n\n"
        },
        {
            "subject": "NEW issue 10  Pure lexical relationship",
            "content": "Summary:\n\nIssue 10 - Pure Lexical relationships\n\nBy stating that relationships like 'broader' and 'narrower' are 'semantic\nrelationships' we have been very clear about that fact that these are not\nrelationships between terms, but relationships between the meaning of the\nterms, i.e. the concepts. \n\nHowever, there are some relationships which could be considered to exist\npurely between the terms. For example, \"stimuli\" is the plural-form-of\n\"stimulus\". \"RDF\" is an acronym-for \"Resource Description Framework\". \n\nBy what mechanism to we allow these kinds of statements to be expressed as\npart of an RDF thesaurus? \n\nSuggested solution 1: We use b-nodes to represent terms, with the property\nrdf:value pointing to the literal value. The statements may be made\nconnecting these two b-nodes, e.g. \n\n...\n\nSuggested solution 2:: We don't bother with them. Instead we offer the\nrecommendation that all acronyms be included as possible labels for a\nconcept. Plural forms probably don't need be included as modern stemming\nalgorithms can identify the root of the term. So e.g. ... \n\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: OWL question (scoping out systems for interthesaurus mapping",
            "content": "Hi Alistair,\n\nSorry for the slow reply - I've been out of email contact for most of the \nlast week.\n\n> Quick question about the OWL reasoner,\n> \n> if I have the following model:\n> \n> <owl:Restriction>\n> <owl:onProperty rdf:resource=\"&dc;subject\"/>\n> <owl:hasValue rdf:resource=\"&thes1;trees\"/>\n> <owl:equivalentClass>\n> <owl:Restriction>\n> <owl:onProperty rdf:resource=\"&dc;subject\"/>\n> <owl:hasValue rdf:resource=\"&thes2;arbres\"/>\n> </owl:Restriction>\n> </owl:equivalentClass>\n> </owl:Restriction>\n> \n> <rdf:Description rdf:about=\"http://www.bigal.com/trees.html\">\n> <dc:subject rdf:resource=\"&thes1;trees\"/>\n> </rdf:Description>\n> \n> Would the OWL reasoner infer that ...\n> \n> <rdf:Description rdf:about=\"http://www.bigal.com/trees.html>\n> <dc:subject rdf:resource=\"&thes2;arbres\"/>\n> </rdf:Description>\n\nYes. Don't know how well it would scale up (lots of equivalentClass \nexpressions can be expensive) but it does work.\n\nDave\n\n\n\n"
        },
        {
            "subject": "FW: NEW issue 6  defining semantic relationship",
            "content": "Cheers Dave.\n\n-----Original Message-----\nFrom: Dave Reynolds [mailto:der@hplb.hpl.hp.com]\nSent: 17 November 2003 15:52\nTo: Miles, AJ (Alistair) \nSubject: Re: NEW issue 6 - defining semantic relationships\n\n\nThis seems amenable to subProperty relationships.\n\nYou could have a base property \"thesaurusRelationship\", subProperties for \nbroader/narrower, subProperties of those for specific usages like strict \nisa, partof etc. In that way some could use a strict partOf relation and a \nthesaurus tool that only understood BT would be able to treat it as a \nbroaderTerm.\n\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> I've added this issue to the RDF Thesaurus ESW Wiki.\n> \n> http://esw.w3.org/topic/RdfThesaurus?action=show\n> \n> Short summary:\n> \n> Issue 6 - Defining semantic relationships\n> \n> Description: A thesaurus consists of concepts, labels for concepts, and\n> semantic relationships between concepts. A semantic relationship is a\n> relationship of meaning. Most thesauri use a similar set of semantic\n> relationships, which they label 'broader' 'narrower' and 'related'. \n> \n> Problem 1: 'broader/narrower' means different things in different\nthesauri.\n> In some thesauri it means strictly class-subsumption. In other thesauri it\n> can mean either is-a, instance-of, or part-of. Also 'related' is not\n> consistently used. For example some thesauri model part-of relations with\n> 'related', others use 'broader/narrower' \n> \n> => We must invent some mechanism for providing clear definitions of\nsemantic\n> relationships, and for removing any scope for ambiguity. \n> \n> Problem 2: some thesauri have semantic relations other than\n> 'broader/narrower' and 'related'. Some overcome the 'broader/narrower'\n> fuzziness by using 'BTI', 'BTG' and 'BTP', which stand for\n> 'broader-term-instantive' 'broader-term-generic' and\n> 'broader-term-partitive' respectively. In others there are custom\n> relationships like 'related-broader'. \n> \n> => We must provide some mechanism by which users can extend the given\n> relationship set and define their own semantic relations. \n> \n> .....\n> \n> \n> Alistair Miles\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "RE: NEW issue 6  defining semantic relationship",
            "content": "Hi Dave,\n\nI agree, I think having a property set like ...\n\n<soks:semanticRelation>\n ^\n |\n<thes:broader>\n ^                        ^                           ^\n |                        |                           |\n<thes:broaderGeneric>    <thes:broaderInstantive>    <thes:broaderPartOf>\n\n... would be good for thesaurus-specific applications.  However, here is\nwhere we start treading on the toes of RDF RDFS and OWL.  The property\n<thes:broaderGeneric> would be semantically equivalent to <rdfs:subClassOf>,\nand the property <thes:broaderInstantive> would be semantically equivalent\nto <rdf:type>.  How do we handle this kind of overlap? \n\nAl.\n\n\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> Sent: 18 November 2003 13:11\n> To: 'public-esw-thes@w3.org'\n> Subject: FW: NEW issue 6 - defining semantic relationships\n> \n> \n> \n> Cheers Dave.\n> \n> -----Original Message-----\n> From: Dave Reynolds [mailto:der@hplb.hpl.hp.com]\n> Sent: 17 November 2003 15:52\n> To: Miles, AJ (Alistair) \n> Subject: Re: NEW issue 6 - defining semantic relationships\n> \n> \n> This seems amenable to subProperty relationships.\n> \n> You could have a base property \"thesaurusRelationship\", \n> subProperties for \n> broader/narrower, subProperties of those for specific usages \n> like strict \n> isa, partof etc. In that way some could use a strict partOf \n> relation and a \n> thesaurus tool that only understood BT would be able to treat it as a \n> broaderTerm.\n> \n> Dave\n> \n> Miles, AJ (Alistair) wrote:\n> \n> > I've added this issue to the RDF Thesaurus ESW Wiki.\n> > \n> > http://esw.w3.org/topic/RdfThesaurus?action=show\n> > \n> > Short summary:\n> > \n> > Issue 6 - Defining semantic relationships\n> > \n> > Description: A thesaurus consists of concepts, labels for \n> concepts, and\n> > semantic relationships between concepts. A semantic \n> relationship is a\n> > relationship of meaning. Most thesauri use a similar set of semantic\n> > relationships, which they label 'broader' 'narrower' and 'related'. \n> > \n> > Problem 1: 'broader/narrower' means different things in different\n> thesauri.\n> > In some thesauri it means strictly class-subsumption. In \n> other thesauri it\n> > can mean either is-a, instance-of, or part-of. Also 'related' is not\n> > consistently used. For example some thesauri model part-of \n> relations with\n> > 'related', others use 'broader/narrower' \n> > \n> > => We must invent some mechanism for providing clear definitions of\n> semantic\n> > relationships, and for removing any scope for ambiguity. \n> > \n> > Problem 2: some thesauri have semantic relations other than\n> > 'broader/narrower' and 'related'. Some overcome the \n> 'broader/narrower'\n> > fuzziness by using 'BTI', 'BTG' and 'BTP', which stand for\n> > 'broader-term-instantive' 'broader-term-generic' and\n> > 'broader-term-partitive' respectively. In others there are custom\n> > relationships like 'related-broader'. \n> > \n> > => We must provide some mechanism by which users can extend \n> the given\n> > relationship set and define their own semantic relations. \n> > \n> > .....\n> > \n> > \n> > Alistair Miles\n> > \n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> > \n> > Email:        a.j.miles@rl.ac.uk\n> > Telephone: +44 (0)1235 445440\n> > \n> > \n> \n\n\n\n"
        },
        {
            "subject": "Re: NEW issue 6  defining semantic relationship",
            "content": "Hi Alistair,\n\n> I agree, I think having a property set like ...\n> \n> <soks:semanticRelation>\n>  ^\n>  |\n> <thes:broader>\n>  ^                        ^                           ^\n>  |                        |                           |\n> <thes:broaderGeneric>    <thes:broaderInstantive>    <thes:broaderPartOf>\n> \n> ... would be good for thesaurus-specific applications.  However, here is\n> where we start treading on the toes of RDF RDFS and OWL.  The property\n> <thes:broaderGeneric> would be semantically equivalent to <rdfs:subClassOf>,\n> and the property <thes:broaderInstantive> would be semantically equivalent\n> to <rdf:type>.  How do we handle this kind of overlap? \n\nI'm not sure there is a problem here. If BG and BI are truly equivalent to \nrdfs:subClassOf and rdf:type then just define them as equivalent using \neither owl:equivalentProperty or a pair of rdfs:subPropertyOf relations. \nThat's the beauty of RDF - open world, multiple inheritance, cycles allowed.\n\nThen a thesaurus processor could take an RDFS file and realise, for \nexample, that an rdfs:subClassOf relation implies thes:broader.\n\nDave\n\n\n\n"
        },
        {
            "subject": "RE: NEW issue 6  defining semantic relationship",
            "content": "OK, so shall we have\n\n\n<soks:semanticRelation>\n^\n|\n<soks:broader>\n^                        ^                           ^\n|                        |                           |\n<soks:broaderGeneric>    <soks:broaderInstantive>    <soks:broaderPartOf>\n\nand\n\n<soks:broaderGeneric>   <owl:equivalentProperty>   <rdfs:subClassOf>.\n\n<soks:broaderInstantive>   <owl:equivalentProperty>   <rdf:type>.\n\nAny objections???\n\nAl.\n\n> > \n> > ... would be good for thesaurus-specific applications.  \n> However, here is\n> > where we start treading on the toes of RDF RDFS and OWL.  \n> The property\n> > <thes:broaderGeneric> would be semantically equivalent to \n> <rdfs:subClassOf>,\n> > and the property <thes:broaderInstantive> would be \n> semantically equivalent\n> > to <rdf:type>.  How do we handle this kind of overlap? \n> \n> I'm not sure there is a problem here. If BG and BI are truly \n> equivalent to \n> rdfs:subClassOf and rdf:type then just define them as \n> equivalent using \n> either owl:equivalentProperty or a pair of rdfs:subPropertyOf \n> relations. \n> That's the beauty of RDF - open world, multiple inheritance, \n> cycles allowed.\n> \n> Then a thesaurus processor could take an RDFS file and realise, for \n> example, that an rdfs:subClassOf relation implies thes:broader.\n> \n> Dave\n> \n\n\n\n"
        },
        {
            "subject": "RE: NEW issue 6  defining semantic relationship",
            "content": "If they really are the same thing, why not just stop using them, since the\nrdfs: stuff is likely to be understood by tools already?\n\ncheers\n\nChaals\n\nOn Tue, 18 Nov 2003, Miles, AJ (Alistair)  wrote:\n\n>\n>OK, so shall we have\n>\n>\n><soks:semanticRelation>\n>^\n>|\n><soks:broader>\n>^                        ^                           ^\n>|                        |                           |\n><soks:broaderGeneric>    <soks:broaderInstantive>    <soks:broaderPartOf>\n>\n>and\n>\n><soks:broaderGeneric>   <owl:equivalentProperty>   <rdfs:subClassOf>.\n>\n><soks:broaderInstantive>   <owl:equivalentProperty>   <rdf:type>.\n>\n>Any objections???\n>\n>Al.\n>\n>> >\n>> > ... would be good for thesaurus-specific applications.\n>> However, here is\n>> > where we start treading on the toes of RDF RDFS and OWL.\n>> The property\n>> > <thes:broaderGeneric> would be semantically equivalent to\n>> <rdfs:subClassOf>,\n>> > and the property <thes:broaderInstantive> would be\n>> semantically equivalent\n>> > to <rdf:type>.  How do we handle this kind of overlap?\n>>\n>> I'm not sure there is a problem here. If BG and BI are truly\n>> equivalent to\n>> rdfs:subClassOf and rdf:type then just define them as\n>> equivalent using\n>> either owl:equivalentProperty or a pair of rdfs:subPropertyOf\n>> relations.\n>> That's the beauty of RDF - open world, multiple inheritance,\n>> cycles allowed.\n>>\n>> Then a thesaurus processor could take an RDFS file and realise, for\n>> example, that an rdfs:subClassOf relation implies thes:broader.\n>>\n>> Dave\n>>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Core schema onlin",
            "content": "Dear all,\n\nOn the basis of recent discussions, I've put together an RDF schema for the\ncore properties and classes.  The schema is linked from the URL\n<http://www.w3c.rl.ac.uk/2003/11/21-skos-core> which is also the base\nnamespace for the classes and properties defined there.  The idea I have is,\nthe document that sits at the end of this url will always be the most recent\nversion.  Having this online means we have a point of reference for\ndiscussing any changes.\n\nYours,\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "TLS document modularit",
            "content": "> From: Win Treese <treese@OpenMarket.com>\n> Subject: Closing on shared-key authentication\n> \n> At this point, I propose that we adopt the proposed\n> modifications for the TLS draft. As always, I am happy\n> to hear comments either on the list or in direct mail.\n\nNo comments.\n\n\n> In addition, if there are other burning issues for substantive\n> changes, please let me know about them now.\n\nI would like to see the first product of this working group separated\ninto two RFC documents, one defining the Record Layer, and the other\ndefining the Handshake Protocol.  This follows existing practice of the\nIP Security working group which has separate documents for the security\ntransforms (AH and ESP) and for the Internet Key Management Protocol\n(IKMP).  Separating the TLS standard into two components allows a\nuseful separation of function, so that issues affecting only one\ncomponent do not hold up progress on the other.  The great shared\nsecret debate (although it pales in comparison to the IPsec IKMP\ndebate :-) is a case in point.\n\nThe other benefit is that a standard Record Layer format could be\nreused in other applications.  Several come to mind: RADIUS (an\nauthentication protocol for Network Access Servers (NASs)) has\nabysmal security between the NAS and the authentication server - the\nink isn't even dry on RADIUS yet and the WG is already working on\nrequirements (including security) for RADIUS-NG.  Cisco just released\nan I-D for TACACS+, a different (and IMO somewhat more mature) protocol\nwhich addresses the same application space.  A generic TLS record\nformat could be used by the NAS market even if their keying requirements\ndiffer from the Web market.\n\nJeff Schiller has also begun a(nother) Telnet security initiative,\nthis time driven by a pressing need to enable secure remote\nadministration of the Internet infrastructure.  A TLS record component\ncould be more easily incorporated into the Telnet authentication/\nencryption framework than could full SSL 3.\n\nThis is, after all, the Transport Layer Security group, not just Web\nConnection Security.  At present, I'm not proposing any changes to the\nSSL 3.0 baseline protocol itself, just proposing that the existing\nprotocol be documented in a more modular fashion.  There is some work\nto be done, such as defining the minimum sufficient connection state\ndata - server and client random don't belong in connection state, but\ncompression, encryption, and MAC methods do, as do byte counts for data\nprotected by the current encryption keys and MAC secrets).  But\ncleanly specifying the keying/transform interface now will pay off\nin reduced development effort later.\n\n\n\n"
        },
        {
            "subject": "Core schema onlin",
            "content": "I've also updated the document\n<http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html> 'Core Vocabularies for\nThesauri' to be a guide to using this schema.  I've tried to make it as\nconcise and readable as possible.\n\nAl.\n\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> Sent: 21 November 2003 16:26\n> To: 'public-esw-thes@w3.org'\n> Subject: Core schema online\n> \n> \n> \n> Dear all,\n> \n> On the basis of recent discussions, I've put together an RDF \n> schema for the\n> core properties and classes.  The schema is linked from the URL\n> <http://www.w3c.rl.ac.uk/2003/11/21-skos-core> which is also the base\n> namespace for the classes and properties defined there.  The \n> idea I have is,\n> the document that sits at the end of this url will always be \n> the most recent\n> version.  Having this online means we have a point of reference for\n> discussing any changes.\n> \n> Yours,\n> \n> Al.\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Mapping vocab onlin",
            "content": "I've put the first version of the mapping vocabulary online, linked from\n<http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping>, which is also the base\nnamespace for this schema.  \n\nA writeup of this and how to use it is coming soon.\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "FW: RDF schemas for thesauri and simple KOS *prerelease",
            "content": "I've put these schemas out as a 'pre-release', posted to rdf-interest,\nrdf-dspace and nkos lists.  \n\nAl.\n\n>  -----Original Message-----\n> From: Miles, AJ (Alistair)   \n> Sent:25 November 2003 13:46\n> To:'www-rdf-dspace@w3.org'\n> Subject:RDF schemas for thesauri and simple KOS *pre-release*\n> \n> Dear all,\n> \n> I offer these schemas as a pre-release, to get some initial feedback and\n> response on their design.\n> \n> SKOS-Core <http://www.w3c.rl.ac.uk/2003/11/21-skos-core> (RDF schema for\n> encoding thesauri and other simple knowledge organisation systems e.g.\n> taxonomies and classification schemes.)\n> \n> SKOS-Mapping <http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping> (RDF schema\n> for expressing mappings between concepts from different thesauri.)\n> \n> This work is ongoing in the context of the SWAD-Europe project [1] [2].\n> \n> Yours,\n> \n> Alistair Miles.\n> \n> [1] SWAD-Europe Thesaurus Activity\n> <http://www.w3c.rl.ac.uk/SWAD/thesaurus.html>\n> [2] Semantic Web Advanced Development for Europe project\n> <http://www.w3.org/2001/sw/Europe/>\n> \n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "RE: RDF schemas for thesauri and simple KOS *prerelease",
            "content": "Hi Victor,\n\nI'm happy for these to go on SchemaWeb.  I can keep you updated of any\nrelease modifications.\n\nYours,\n\nAlistair.\n\n> -----Original Message-----\n> From: Victor Lindesay [mailto:victor@schemaweb.info]\n> Sent: 25 November 2003 18:31\n> To: 'Miles, AJ (Alistair) '\n> Subject: RE: RDF schemas for thesauri and simple KOS *pre-release*\n> \n> \n> Hi Alistair,\n> \n> Should I put these schemas on SchemaWeb or wait until release \n> versions?\n> \n> Regards,\n> Victor\n> \n> > -----Original Message-----\n> > From: www-rdf-interest-request@w3.org \n> > [mailto:www-rdf-interest-request@w3.org] On Behalf Of Miles, \n> > AJ (Alistair) \n> > Sent: 25 November 2003 13:45\n> > To: 'www-rdf-interest@w3.org'\n> > Subject: RDF schemas for thesauri and simple KOS *pre-release*\n> > \n> > \n> > \n> > > Dear all,\n> > > \n> > > I offer these schemas as a pre-release, to get some initial \n> > feedback and\n> > > response on their design.\n> > > \n> > > SKOS-Core <http://www.w3c.rl.ac.uk/2003/11/21-skos-core> \n> > (RDF schema for\n> > > encoding thesauri and other simple knowledge organisation \n> > systems e.g.\n> > > taxonomies and classification schemes.)\n> > > \n> > > SKOS-Mapping \n> > <http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping> > (RDF schema\n> > \n> > > for expressing mappings between concepts from \n> > different thesauri.)\n> > > \n> > > This work is ongoing in the context of the SWAD-Europe \n> > project [1] [2].\n> > > \n> > > Yours,\n> > > \n> > > Alistair Miles.\n> > > \n> > > [1] SWAD-Europe Thesaurus Activity\n> > > <http://www.w3c.rl.ac.uk/SWAD/thesaurus.html>\n> > > [2] Semantic Web Advanced Development for Europe project\n> > > <http://www.w3.org/2001/sw/Europe/>\n> > > \n> > > \n> > > CCLRC - Rutherford Appleton Laboratory\n> > > Building R1 Room 1.60\n> > > Fermi Avenue\n> > > Chilton\n> > > Didcot\n> > > Oxfordshire OX11 0QX\n> > > United Kingdom\n> > > \n> > > Email:        a.j.miles@rl.ac.uk\n> > > Telephone: +44 (0)1235 445440\n> > > \n> > > \n> > \n> \n\n\n\n"
        },
        {
            "subject": "TIF to SKO",
            "content": "I've written some rules that convert TIF to the current version of SKOS.\nThey are online at\n \n< http://www.w3c.rl.ac.uk/SWAD/thesaurus/tif/tif_to_skos.n3\n<http://www.w3c.rl.ac.uk/SWAD/thesaurus/tif/tif_to_skos.n3> >\n \nThey work with CWM [1].  So for example I used the following command to\nconvert the GCL thesaurus ...\n \ncwm.py gcl.tif.n3 --filter=tif_to_skos.n3 > gcl.skos.n3\n \nAlistair.\n \n[1] CWM <http://www.w3.org/2000/10/swap/doc/cwm.html>\n\n \n\n\n\n"
        },
        {
            "subject": "FW: SKOSCore comments and labels adde",
            "content": ">  -----Original Message-----\n> From: Miles, AJ (Alistair)   \n> Sent:26 November 2003 17:08\n> To:'www-rdf-dspace@w3.org'\n> Subject:SKOS-Core comments and labels added\n> \n> Comments and labels have been added to the SKOS-Core vocabulary.\n> \n> <http://www.w3c.rl.ac.uk/2003/11/21-skos-core>\n> \n> Yours,\n> \n> Alistair Miles.\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "SKOSMapping comments and labels adde",
            "content": "Comments and labels have been added to the SKOS-Mapping vocabulary.\n\n<http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping>\n\nYours,\n\nAlistair Miles.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "FW: SKOS-Mapping and OWL  set based construct",
            "content": "The idea is that the skos-mapping constructs are a more convenient and\nintuitive shorthand for more formal set based constructs that could be\nexpressed in OWL. \n\nSo for example, you may consider that statements such as ...\n\n<soks:Concept rdf:about=\"#A\">\n<soks-map:broaderMatch>\n<soks-map:AND>\n<rdf:li rdf:resource=\"#B\"/>\n<rdf:li rdf:resource=\"#C\"/>\n</soks-map:AND>\n</soks-map:broaderMatch>\n</soks:Concept>\n\n... are in fact a convenient shorthand for the statements ...\n\n<owl:Restriction> \n   <owl:onProperty rdf:resource=\"&dc;subject\"/> \n   <owl:hasValue rdf:resource=\"#A\"/> \n   <rdfs:subClassOf rdf:parseType=\"resource\"> \n      <owl:intersectionOf rdf:parseType=\"collection\"> \n         <owl:Restriction> \n            <owl:onProperty rdf:resource=\"&dc;subject\"/> \n            <owl:hasValue rdf:resource=\"#B\"/> \n         </owl:Restriction> \n         <owl:Restriction> \n            <owl:onProperty rdf:resource=\"&dc;subject\"/> \n            <owl:hasValue rdf:resource=\"#C\"/> \n         </owl:Restriction> \n      </owl:intersectionOf> \n   </rdfs:subClassOf> \n</owl:Restriction> \n\nFor further discussion of this problem, see the extended writeup of open\ndesign issues on the SWAD RDF Thesaurus wiki (Issue 9 - Inter-thesaurus\nmapping) <http://esw.w3.org/topic/RdfThesaurus>.\n\nWhat do you think of this?\n\nYours,\n\nAlistair.\n\n\n> -----Original Message-----\n> From: ewallace@cme.nist.gov [mailto:ewallace@cme.nist.gov]\n> Sent: 26 November 2003 18:59\n> To: A.J.Miles@rl.ac.uk\n> Subject: Re: SKOS-Mapping comments and labels added\n> \n> \n> \n> You wrote:\n> \n> >Comments and labels have been added to the SKOS-Mapping vocabulary.\n> >\n> ><http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping>\n> \n> This file contains AND, OR, and NOT properties which mimic OWL\n> vocabulary elements: owl:intersectionOf, owl:unionOf, and \n> owl:complementOf respectively.  Why invent new terms?\n> \n> -Evan\n> \n> Evan K. Wallace\n> Manufacturing Systems Integration Division\n> NIST\n> \n> \n\n\n\n"
        },
        {
            "subject": "RE: SKOSCore comments and labels adde",
            "content": "Hi Aida,\n\n> \n> Alistair,\n> In my experience a concept in classification scheme if it is \n> to be machine\n> handled\n> needs to be identified in two ways: with its notation and with\n> unique identifier...\n> \n> e.g.  I am here giving the example from faceted classification\n> \n> 590 Religion [discipline]\n> 590A Theory and Philosophy of religion [facet]\n> 590A3 The Holy. The sacred. The supernatural. Object(s) of \n> religion/worship\n> [subfacet of the facet A]\n> 590A34       Nature. Taboo, herem, sacredness [class with no \n> subclasses...\n> 'concept' ?]\n> \n> Now, notation 590A34 defines the class unuquely, and it is \n> fully operational\n> as an identifier\n> within the system. But the in the process of vocabulary \n> maintenance notation\n> can be\n> altered. So it is usually necessary to have place for both \n> unique identifier\n> of a concept (independent\n> from notation) as well as its notational symbol. Otherwise it is not\n> possible to exhchange and\n> update vocabulary....\n> \n\nOne of the major design requirements of the SKOS vocabs is that they are\nextensible.  So I would be quite happy for you to extend the\n<soks:externalID> property and create two subproperties <class:notation> and\n<class:permID> for example.  Would this fulfill your requirements?\n\n> \n> Also classification systems have\n> a) notation\n> b) textual description of a class (this is not a concept)\n> c) terms/descriptors pointing to the class (subject \n> alphabetical index)\n> Some classifications have alphabetical index in the form\n> of thesarus.\n> \n> Organizationaly analytico-synthetic (faceted) classification have\n> facets, subfacets, subfacets of subfacets and finally a hierarchy of\n> concepts, that\n> may be combined among themselves. This vocabulary is \n> organized in relational\n> in\n> a manner so that one the same facet can be used as a \n> specifier for many\n> concepts\n> scattered in the scheme.\n> E.g. the facet of colours can be used in physics, art, chemistry, etc.\n> It is very important that one can link each class/concept \n> with the facet\n> which can be used for its further specification.\n> This is not covered with any relationships that already exist \n> in thesaurus\n> as\n> thesaurus does not offer the possibility to precombine \n> descriptors. This is\n> characteristics of analytico-synthetic classifications (faceted).\n> \n> sorry if this is confusing, but it looks like that the scheme you\n> are suggesting is rather comprehensive and I wonder whether it would\n> be good enough to host classification vocabulary...\n> \n> Aida\n> \n\nThe application of SKOS to classification schemes and faceted structures is\nsomething I would very much like to explore.  Could you send me some links\nto some classification schemes you think might be a good testbed for SKOS?\nI'd be very grateful.\n\nIf you'd like to stay involved with the development of SKOS you're very\nwelcome.  There is the public list <public-esw-thes@w3.org> and the RDF\nThesaurus wiki <http://esw.w3.org/topic/RdfThesaurus> which you are most\nwelcome to contribute to.\n\nYours,\n\nAlistair.\n  \n\n \n\n> -----Original Message-----\n> From: Networked Knowledge Organization Systems list\n> [mailto:NKOS@dli2.nsf.gov]On Behalf Of Miles, AJ (Alistair)\n> Sent: 26 November 2003 17:09\n> To: NKOS@dli2.nsf.gov\n> Subject: FW: SKOS-Core comments and labels added\n> \n> \n> > Comments and labels have been added to the SKOS-Core vocabulary.\n> >\n> > <http://www.w3c.rl.ac.uk/2003/11/21-skos-core>\n> >\n> > Yours,\n> >\n> > Alistair Miles.\n> >\n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> >\n> > Email:        a.j.miles@rl.ac.uk\n> > Telephone: +44 (0)1235 445440\n> >\n> >\n> \n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: FW: SKOS-Mapping and OWL  set based construct",
            "content": "Hi Alistair,\n\n > What do you think of this?\n\nThis does not sound like a good idea.\n\n[Apologies - I haven't had time to look at the mapping proposal yet so \nthese comments are based purely on the quoted message and I might have got \nhold of the wrong end of the stick ...]\n\nFirst, I'd expect you to translate the soks AND into an OWL intersectionOf \nover the concepts not over restrictions on dc:subject.\n\nSecond, I don't see the argument that these constructs are more \"intuitive\" \n  than the OWL equivalents. If they are truly equivalent and all you've \ndone is change the name then that doesn't seem helpful.\n\nThird, it's not a good idea to use rdf:li here. The OWL constructs use \nparseType collection for very good reasons (to express a closed collection \nwhich can't be messed up semantically by later assertions).\n\nDave\n\nMiles, AJ (Alistair) wrote:\n\n> The idea is that the skos-mapping constructs are a more convenient and\n> intuitive shorthand for more formal set based constructs that could be\n> expressed in OWL. \n> \n> So for example, you may consider that statements such as ...\n> \n> <soks:Concept rdf:about=\"#A\">\n> <soks-map:broaderMatch>\n> <soks-map:AND>\n> <rdf:li rdf:resource=\"#B\"/>\n> <rdf:li rdf:resource=\"#C\"/>\n> </soks-map:AND>\n> </soks-map:broaderMatch>\n> </soks:Concept>\n> \n> ... are in fact a convenient shorthand for the statements ...\n> \n> <owl:Restriction> \n>    <owl:onProperty rdf:resource=\"&dc;subject\"/> \n>    <owl:hasValue rdf:resource=\"#A\"/> \n>    <rdfs:subClassOf rdf:parseType=\"resource\"> \n>       <owl:intersectionOf rdf:parseType=\"collection\"> \n>          <owl:Restriction> \n>             <owl:onProperty rdf:resource=\"&dc;subject\"/> \n>             <owl:hasValue rdf:resource=\"#B\"/> \n>          </owl:Restriction> \n>          <owl:Restriction> \n>             <owl:onProperty rdf:resource=\"&dc;subject\"/> \n>             <owl:hasValue rdf:resource=\"#C\"/> \n>          </owl:Restriction> \n>       </owl:intersectionOf> \n>    </rdfs:subClassOf> \n> </owl:Restriction> \n> \n> For further discussion of this problem, see the extended writeup of open\n> design issues on the SWAD RDF Thesaurus wiki (Issue 9 - Inter-thesaurus\n> mapping) <http://esw.w3.org/topic/RdfThesaurus>.\n> \n> What do you think of this?\n> \n> Yours,\n> \n> Alistair.\n> \n> \n> \n>>-----Original Message-----\n>>From: ewallace@cme.nist.gov [mailto:ewallace@cme.nist.gov]\n>>Sent: 26 November 2003 18:59\n>>To: A.J.Miles@rl.ac.uk\n>>Subject: Re: SKOS-Mapping comments and labels added\n>>\n>>\n>>\n>>You wrote:\n>>\n>>\n>>>Comments and labels have been added to the SKOS-Mapping vocabulary.\n>>>\n>>><http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping>\n>>\n>>This file contains AND, OR, and NOT properties which mimic OWL\n>>vocabulary elements: owl:intersectionOf, owl:unionOf, and \n>>owl:complementOf respectively.  Why invent new terms?\n>>\n>>-Evan\n>>\n>>Evan K. Wallace\n>>Manufacturing Systems Integration Division\n>>NIST\n>>\n>>\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: TLS document modularit",
            "content": "David P. Kemp wrote:\n> \n> > From: Win Treese <treese@OpenMarket.com>\n> > Subject: Closing on shared-key authentication\n> >\n> > At this point, I propose that we adopt the proposed\n> > modifications for the TLS draft. As always, I am happy\n> > to hear comments either on the list or in direct mail.\n> \n> No comments.\n> \n> > In addition, if there are other burning issues for substantive\n> > changes, please let me know about them now.\n> \n> I would like to see the first product of this working group separated\n> into two RFC documents, one defining the Record Layer, and the other\n> defining the Handshake Protocol.  This follows existing practice of the\n> IP Security working group which has separate documents for the security\n> transforms (AH and ESP) and for the Internet Key Management Protocol\n> (IKMP).  Separating the TLS standard into two components allows a\n> useful separation of function, so that issues affecting only one\n> component do not hold up progress on the other.  The great shared\n> secret debate (although it pales in comparison to the IPsec IKMP\n> debate :-) is a case in point.\n> \n> The other benefit is that a standard Record Layer format could be\n> reused in other applications.  Several come to mind: RADIUS (an\n> authentication protocol for Network Access Servers (NASs)) has\n> abysmal security between the NAS and the authentication server - the\n> ink isn't even dry on RADIUS yet and the WG is already working on\n> requirements (including security) for RADIUS-NG.  Cisco just released\n> an I-D for TACACS+, a different (and IMO somewhat more mature) protocol\n> which addresses the same application space.  A generic TLS record\n> format could be used by the NAS market even if their keying requirements\n> differ from the Web market.\n> \n> Jeff Schiller has also begun a(nother) Telnet security initiative,\n> this time driven by a pressing need to enable secure remote\n> administration of the Internet infrastructure.  A TLS record component\n> could be more easily incorporated into the Telnet authentication/\n> encryption framework than could full SSL 3.\n> \n> This is, after all, the Transport Layer Security group, not just Web\n> Connection Security.  At present, I'm not proposing any changes to the\n> SSL 3.0 baseline protocol itself, just proposing that the existing\n> protocol be documented in a more modular fashion.  There is some work\n> to be done, such as defining the minimum sufficient connection state\n> data - server and client random don't belong in connection state, but\n> compression, encryption, and MAC methods do, as do byte counts for data\n> protected by the current encryption keys and MAC secrets).  But\n> cleanly specifying the keying/transform interface now will pay off\n> in reduced development effort later.\n\n\nI do not have a problem with splitting the document to a record layer\nprotocol and a key management / authentication handshake document\ndescribing the negotiation and other key mgmt issues. There are things\nwe need to discuss before all multiple authentication methods are\nstandardized.\n\n\nOn the subject of password authentication I would like to make the\nfollowing two remarks. \n\nFirst, it is my understanding that the IETF usually puts things in\nstandards track based on rough consensous and running code (usually at\nmore than one location). I would like to see this implemented in TLS as\nwell before we put things on the standards track.\n\nThe other issue is that the community has not had a chance to evaluate\nthe security issues involved with having multiple authentication methods\nin a single protocol. I believe that we all need to look at any security\nhazard invloved with doing password-based auth using the same shared\nsecret that generates the encryption keys and MAC secrets. For example,\nwe should assume that some password is compromised and the effects that\nmay have on other portions in the sessions that use the same master\nsecret. I do not believe anyone feels comfortable with that now.\n\n\nSplitting the TLS protocol document may be a good way to start putting\nTLS in the standards track, assuming the record layer is easier to agree\non (from historical experiences).\n\n\n\n-- \nTaher Elgamal    elgamal@netscape.com\nChief Scientist, Netscape Communications\n(T) 415 937 2898, (F) 415 428 4054\n\n\n\n"
        },
        {
            "subject": "FW: Terminology services  Open list of use case",
            "content": "-----Original Message-----\nFrom: Paola Capitani [mailto:paolacapitani@libero.it]\nSent: 18 November 2003 21:54\nTo: Miles, AJ (Alistair)\nSubject: Re: Terminology services - Open list of use cases\n\n\n\n>Replying to your e-mail I'am informing that since 2000 a working group is \n>envolved in the Semantic and Terminology in the web. Among the goals there \n>is the activity of implementing thesauri and ontologies, conceptual maps \n>and semantic maps. For further details http://www.indire.it/websemantico\n\n>However I'm at your disposal for any information about next schedule 2004. \n>Best regards, Paola Capitani\n\n>Via Tripoli, 15\n\n>50122 Firenze\n\n  Italy\ntel. 0039 55 241769\nhttp://www.indire.it/websemantico\n\n\n\n"
        },
        {
            "subject": "SKOS and OWL  Which set",
            "content": "Hi Dave,\n\nThanks for the heads up on the <rdf:li> property, that does need changing I\nthink.\n\nTo explain why I did what I did ...\n\nLet's say I have concept A from thesaurus T1, and concepts B and C from\nthesaurus T2.  I also have a document collection D which has been indexed\nagainst concepts from T2.\n\nSomebody tells me that 'concept A is exactly equivalent to concepts B and\nC.'\n\nIf I interpret this to mean that 'the set of resources that are about\nconcept A is identical to the intersection of the set of resources that are\nabout concept B and the set of resources that are about concept C' I have\nsome useful information about how to transform queries.  Now if somebody\nasks for documents from D that are about concept A, I can transform this\ninto a query in terms of B and C and guarantee accurate results.\n\nSo I'm saying the best way to interpret equivalence expressions is as being\nset-like.  They do imply something about sets, but the concepts themselves\nare not the sets, the sets are the sets of resources that are about the\nconcepts.\n\nThis is the interpretation taken by Doerr\n<http://jodi.ecs.soton.ac.uk/Articles/v01/i08/Doerr/>.     \n\nNow if I say something like ...\n\n<soks:Concept rdf:about=\"#A\">\n<owl:equivalentClass rdf:parseType=\"resource\">\n<owl:intersectionOf rdf:parseType=\"collection\">\n  <soks:Concept rdf:about=\"#B\"/>\n<soks:Concept rdf:about=\"#C\"/>\n</owl:intersectionOf>\n</owl:equivalentClass>\n</soks:Concept>\n\n... I am in fact saying something about the things that are true instances\nof the concepts.  That is, things with the property <rdf:type> pointing to\nthe concepts.  \n\nThere are two problems with this:\n\n1.  I don't have the information I need in order to be able to guarantee\nrecall of documents after query transformation.\n\n2.  Many concepts should not be modelled as <owl:Class>es.  The concept\n'Running' is not a class.  The concept 'Java programming language version\n1.4.2' is not a class.  The concept 'fish and chips' is not a class.  Yet\nall these may be concepts in a thesaurus.  If a concept is not a class, we\ncan't use it as the subject or object of OWL set based expressions.\n\nHowever, you can use OWL to make statements about the sets of things that\nare 'about' some concept.  Hence the restrictions over things with property\n<dc:subject>.  What I'm trying to say is, this is what equivalence\nexpressions are best taken to mean.  Then we avoid hazy philosophical\nquestions and just end up with useful information about how to transform\nqueries.\n\nDoes this change your opinion?\n\nAl.\n\n > -----Original Message-----\n> From: Dave Reynolds [mailto:der@hplb.hpl.hp.com]\n> Sent: 27 November 2003 14:41\n> To: Miles, AJ (Alistair) \n> Cc: 'public-esw-thes@w3.org'\n> Subject: Re: FW: SKOS-Mapping and OWL - set based constructs\n> \n> \n> \n> Hi Alistair,\n> \n>  > What do you think of this?\n> \n> This does not sound like a good idea.\n> \n> [Apologies - I haven't had time to look at the mapping \n> proposal yet so \n> these comments are based purely on the quoted message and I \n> might have got \n> hold of the wrong end of the stick ...]\n> \n> First, I'd expect you to translate the soks AND into an OWL \n> intersectionOf \n> over the concepts not over restrictions on dc:subject.\n> \n> Second, I don't see the argument that these constructs are \n> more \"intuitive\" \n>   than the OWL equivalents. If they are truly equivalent and \n> all you've \n> done is change the name then that doesn't seem helpful.\n> \n> Third, it's not a good idea to use rdf:li here. The OWL \n> constructs use \n> parseType collection for very good reasons (to express a \n> closed collection \n> which can't be messed up semantically by later assertions).\n> \n> Dave\n> \n> Miles, AJ (Alistair) wrote:\n> \n> > The idea is that the skos-mapping constructs are a more \n> convenient and\n> > intuitive shorthand for more formal set based constructs \n> that could be\n> > expressed in OWL. \n> > \n> > So for example, you may consider that statements such as ...\n> > \n> > <soks:Concept rdf:about=\"#A\">\n> > <soks-map:broaderMatch>\n> > <soks-map:AND>\n> > <rdf:li rdf:resource=\"#B\"/>\n> > <rdf:li rdf:resource=\"#C\"/>\n> > </soks-map:AND>\n> > </soks-map:broaderMatch>\n> > </soks:Concept>\n> > \n> > ... are in fact a convenient shorthand for the statements ...\n> > \n> > <owl:Restriction> \n> >    <owl:onProperty rdf:resource=\"&dc;subject\"/> \n> >    <owl:hasValue rdf:resource=\"#A\"/> \n> >    <rdfs:subClassOf rdf:parseType=\"resource\"> \n> >       <owl:intersectionOf rdf:parseType=\"collection\"> \n> >          <owl:Restriction> \n> >             <owl:onProperty rdf:resource=\"&dc;subject\"/> \n> >             <owl:hasValue rdf:resource=\"#B\"/> \n> >          </owl:Restriction> \n> >          <owl:Restriction> \n> >             <owl:onProperty rdf:resource=\"&dc;subject\"/> \n> >             <owl:hasValue rdf:resource=\"#C\"/> \n> >          </owl:Restriction> \n> >       </owl:intersectionOf> \n> >    </rdfs:subClassOf> \n> > </owl:Restriction> \n> > \n> > For further discussion of this problem, see the extended \n> writeup of open\n> > design issues on the SWAD RDF Thesaurus wiki (Issue 9 - \n> Inter-thesaurus\n> > mapping) <http://esw.w3.org/topic/RdfThesaurus>.\n> > \n> > What do you think of this?\n> > \n> > Yours,\n> > \n> > Alistair.\n> > \n> > \n> > \n> >>-----Original Message-----\n> >>From: ewallace@cme.nist.gov [mailto:ewallace@cme.nist.gov]\n> >>Sent: 26 November 2003 18:59\n> >>To: A.J.Miles@rl.ac.uk\n> >>Subject: Re: SKOS-Mapping comments and labels added\n> >>\n> >>\n> >>\n> >>You wrote:\n> >>\n> >>\n> >>>Comments and labels have been added to the SKOS-Mapping vocabulary.\n> >>>\n> >>><http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping>\n> >>\n> >>This file contains AND, OR, and NOT properties which mimic OWL\n> >>vocabulary elements: owl:intersectionOf, owl:unionOf, and \n> >>owl:complementOf respectively.  Why invent new terms?\n> >>\n> >>-Evan\n> >>\n> >>Evan K. Wallace\n> >>Manufacturing Systems Integration Division\n> >>NIST\n> >>\n> >>\n> > \n> > \n> \n\n\n\n"
        },
        {
            "subject": "Re: SKOS and OWL  Which set",
            "content": "Hi Alistair,\n\n > Does this change your opinion?\n\nYes. Sorry, I hadn't read your example properly.\n\n > So I'm saying the best way to interpret equivalence expressions is\n > as being set-like.  They do imply something about sets, but the\n > concepts themselves are not the sets, the sets are the sets of\n > resources that are about the concepts.\n\nOK.\n\nAs it happens, in RDF a class is not itself a set instances either, it \nis something which has an extension which is in turn a set of instances. \nIt's this level of indirection which allows you to have things which are \nboth classes and instances without stepping outside the bounds of normal \nset theory. This is quite close to what you are trying to capture here.\n\n > Now if I say something like ...\n >\n > <soks:Concept rdf:about=\"#A\">\n > <owl:equivalentClass rdf:parseType=\"resource\">\n > <owl:intersectionOf rdf:parseType=\"collection\">\n >   <soks:Concept rdf:about=\"#B\"/>\n > <soks:Concept rdf:about=\"#C\"/>\n > </owl:intersectionOf>\n > </owl:equivalentClass>\n > </soks:Concept>\n >\n > ... I am in fact saying something about the things that are true\n > instances of the concepts.  That is, things with the property\n > <rdf:type> pointing to the concepts.\n\nThere are certainly KOS applications in which this is a perfectly valid \nmodelling approach - where the concepts can be reasonably treated as \nclasses, where the resources being organized are instances of the \nconcept and in those cases this is a good way of expressing the mapping \nwhich does allow you to transform queries.\n\nHowever, I do agree with you that thesauri don't typically work that way \nand using rdf:type to represent the relationship between the concept and \nthe resources associated with that concept is not always going to be \nappropriate. So I do agree with your approach.\n\nIt is a shame to end up with something which is so decoupled from \nRDFS/OWL though. There do seem to be applications where people start out \nwith an informal thesaurus like model of the world and then over time \nmove to a more ontology-like model (the GeneOntology is, perhaps, an \nexample of this). It would be appealing to have a KOS representation \nthat facilitated that by exploiting the quite forgiving nature of the \nRDFS semantics but I guess there is too much of a disconnect with \nthesauri to make that work.\n\n[And I still recommend changing rdf:li but that's a minor point.]\n\nCheers,\nDave\n\nMiles, AJ (Alistair) wrote:\n> Hi Dave,\n> \n> Thanks for the heads up on the <rdf:li> property, that does need changing I\n> think.\n> \n> To explain why I did what I did ...\n> \n> Let's say I have concept A from thesaurus T1, and concepts B and C from\n> thesaurus T2.  I also have a document collection D which has been indexed\n> against concepts from T2.\n> \n> Somebody tells me that 'concept A is exactly equivalent to concepts B and\n> C.'\n> \n> If I interpret this to mean that 'the set of resources that are about\n> concept A is identical to the intersection of the set of resources that are\n> about concept B and the set of resources that are about concept C' I have\n> some useful information about how to transform queries.  Now if somebody\n> asks for documents from D that are about concept A, I can transform this\n> into a query in terms of B and C and guarantee accurate results.\n> \n> So I'm saying the best way to interpret equivalence expressions is as being\n> set-like.  They do imply something about sets, but the concepts themselves\n> are not the sets, the sets are the sets of resources that are about the\n> concepts.\n> \n> This is the interpretation taken by Doerr\n> <http://jodi.ecs.soton.ac.uk/Articles/v01/i08/Doerr/>.     \n> \n> Now if I say something like ...\n> \n> <soks:Concept rdf:about=\"#A\">\n> <owl:equivalentClass rdf:parseType=\"resource\">\n> <owl:intersectionOf rdf:parseType=\"collection\">\n>   <soks:Concept rdf:about=\"#B\"/>\n> <soks:Concept rdf:about=\"#C\"/>\n> </owl:intersectionOf>\n> </owl:equivalentClass>\n> </soks:Concept>\n> \n> ... I am in fact saying something about the things that are true instances\n> of the concepts.  That is, things with the property <rdf:type> pointing to\n> the concepts.  \n> \n> There are two problems with this:\n> \n> 1.  I don't have the information I need in order to be able to guarantee\n> recall of documents after query transformation.\n> \n> 2.  Many concepts should not be modelled as <owl:Class>es.  The concept\n> 'Running' is not a class.  The concept 'Java programming language version\n> 1.4.2' is not a class.  The concept 'fish and chips' is not a class.  Yet\n> all these may be concepts in a thesaurus.  If a concept is not a class, we\n> can't use it as the subject or object of OWL set based expressions.\n> \n> However, you can use OWL to make statements about the sets of things that\n> are 'about' some concept.  Hence the restrictions over things with property\n> <dc:subject>.  What I'm trying to say is, this is what equivalence\n> expressions are best taken to mean.  Then we avoid hazy philosophical\n> questions and just end up with useful information about how to transform\n> queries.\n> \n> Does this change your opinion?\n> \n> Al.\n> \n>  > -----Original Message-----\n> \n>>From: Dave Reynolds [mailto:der@hplb.hpl.hp.com]\n>>Sent: 27 November 2003 14:41\n>>To: Miles, AJ (Alistair) \n>>Cc: 'public-esw-thes@w3.org'\n>>Subject: Re: FW: SKOS-Mapping and OWL - set based constructs\n>>\n>>\n>>\n>>Hi Alistair,\n>>\n>> > What do you think of this?\n>>\n>>This does not sound like a good idea.\n>>\n>>[Apologies - I haven't had time to look at the mapping \n>>proposal yet so \n>>these comments are based purely on the quoted message and I \n>>might have got \n>>hold of the wrong end of the stick ...]\n>>\n>>First, I'd expect you to translate the soks AND into an OWL \n>>intersectionOf \n>>over the concepts not over restrictions on dc:subject.\n>>\n>>Second, I don't see the argument that these constructs are \n>>more \"intuitive\" \n>>  than the OWL equivalents. If they are truly equivalent and \n>>all you've \n>>done is change the name then that doesn't seem helpful.\n>>\n>>Third, it's not a good idea to use rdf:li here. The OWL \n>>constructs use \n>>parseType collection for very good reasons (to express a \n>>closed collection \n>>which can't be messed up semantically by later assertions).\n>>\n>>Dave\n>>\n>>Miles, AJ (Alistair) wrote:\n>>\n>>\n>>>The idea is that the skos-mapping constructs are a more \n>>\n>>convenient and\n>>\n>>>intuitive shorthand for more formal set based constructs \n>>\n>>that could be\n>>\n>>>expressed in OWL. \n>>>\n>>>So for example, you may consider that statements such as ...\n>>>\n>>><soks:Concept rdf:about=\"#A\">\n>>><soks-map:broaderMatch>\n>>><soks-map:AND>\n>>><rdf:li rdf:resource=\"#B\"/>\n>>><rdf:li rdf:resource=\"#C\"/>\n>>></soks-map:AND>\n>>></soks-map:broaderMatch>\n>>></soks:Concept>\n>>>\n>>>... are in fact a convenient shorthand for the statements ...\n>>>\n>>><owl:Restriction> \n>>>   <owl:onProperty rdf:resource=\"&dc;subject\"/> \n>>>   <owl:hasValue rdf:resource=\"#A\"/> \n>>>   <rdfs:subClassOf rdf:parseType=\"resource\"> \n>>>      <owl:intersectionOf rdf:parseType=\"collection\"> \n>>>         <owl:Restriction> \n>>>            <owl:onProperty rdf:resource=\"&dc;subject\"/> \n>>>            <owl:hasValue rdf:resource=\"#B\"/> \n>>>         </owl:Restriction> \n>>>         <owl:Restriction> \n>>>            <owl:onProperty rdf:resource=\"&dc;subject\"/> \n>>>            <owl:hasValue rdf:resource=\"#C\"/> \n>>>         </owl:Restriction> \n>>>      </owl:intersectionOf> \n>>>   </rdfs:subClassOf> \n>>></owl:Restriction> \n>>>\n>>>For further discussion of this problem, see the extended \n>>\n>>writeup of open\n>>\n>>>design issues on the SWAD RDF Thesaurus wiki (Issue 9 - \n>>\n>>Inter-thesaurus\n>>\n>>>mapping) <http://esw.w3.org/topic/RdfThesaurus>.\n>>>\n>>>What do you think of this?\n>>>\n>>>Yours,\n>>>\n>>>Alistair.\n>>>\n>>>\n>>>\n>>>\n>>>>-----Original Message-----\n>>>>From: ewallace@cme.nist.gov [mailto:ewallace@cme.nist.gov]\n>>>>Sent: 26 November 2003 18:59\n>>>>To: A.J.Miles@rl.ac.uk\n>>>>Subject: Re: SKOS-Mapping comments and labels added\n>>>>\n>>>>\n>>>>\n>>>>You wrote:\n>>>>\n>>>>\n>>>>\n>>>>>Comments and labels have been added to the SKOS-Mapping vocabulary.\n>>>>>\n>>>>><http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping>\n>>>>\n>>>>This file contains AND, OR, and NOT properties which mimic OWL\n>>>>vocabulary elements: owl:intersectionOf, owl:unionOf, and \n>>>>owl:complementOf respectively.  Why invent new terms?\n>>>>\n>>>>-Evan\n>>>>\n>>>>Evan K. Wallace\n>>>>Manufacturing Systems Integration Division\n>>>>NIST\n>>>>\n>>>>\n>>>\n>>>\n> \n\n\n\n"
        },
        {
            "subject": "Summary of wp8 (Thesaurus) meeting 18/09/200",
            "content": "This is a brief summary of a meeting held 18/09/2003 between Alistair Miles\n(CCLRC) Nikki Rogers (ILRT) Dave Beckett (ILRT) Dan Brickley (W3C) via IRC.\n\n---------Meeting\nSummary---------------------------------------------------------------------\n---------------------------------------------------------------------\n\nTopics: 1. Modular RDF vocabularies for thesaurus-like data.\n2. Use cases and requirements for thesaurus services.\n\n1. Modular RDF vocabularies for thesaurus-like data.\n\nThe work on RDF vocabs for thesaurus and similar data is progressing well.\nA proposal for modularising parts of the vocabs was discussed, in relation\nto a discussion document previously posted to the list by Alistair\n<http://lists.w3.org/Archives/Public/public-esw-thes/2003Sep/0002.html>.\nUnderstanding how to fit the thesaurus RDF vocabs we are developing into\nexisting vocabs such as OWL was highlighted as a key issue and area for\nfurther work.  This issue to be studied further as part of deliverables 8.3,\n8.4, 8.5 and 8.6.  \n\n2. Use cases and requirements for thesaurus services.\n\nWe agreed to begin work on development of a thesaurus web service with a\nthorough study of scenarios and use cases.  The question of whether to begin\nand maintain a public list of use cases was raised, to be agreed upon\nshortly.  \n\n----------------------------------------------------------------------------\n----------------------------------------------------------------------------\n-----------------------\n\nView latest SWAD Thesaurus Activity at \n\nhttp://www.w3c.rl.ac.uk/SWAD/thesaurus.html\n\n----------------------------------------------------------------------------\n----------------------------------------------------------------------------\n-----------------------\n\n\nSummary written by: \n\nAlistair Miles.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Win Treese wrote:\n> \n> I'd like to close on the question of including shared-key\n> authentication in TLS. There has been little discussion\n> of the latest proposal from Barbara Fox, but I think we\n> went over the arguments pretty thoroughly a few weeks\n> ago.\n> \n> At this point, I propose that we adopt the proposed\n> modifications for the TLS draft. As always, I am happy\n> to hear comments either on the list or in direct mail.\n> \n> In addition, if there are other burning issues for substantive\n> changes, please let me know about them now.\n\nI fail to see how you can conclude that there's a rough consensus on\nthis proposal.\n\nFirst of all, I feel there are a number of weaknesses in any password\nscheme.  In addition, this proposal has not received nearly as much\npublic review as SSL has.  For these reasons, I'm nervous about its\nsecurity.  It also has yet to be proven that this scheme provides any\nmore security than implementing passwords at a higher level.  Given this\ncombination of a lack of clear need and possible weakness, I feel that\nthis proposal doesn't belong in TLS.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Thesaurus / mapping reference",
            "content": "Crossposted; followups just to public-esw-thes please.\n\n\nForgot about this one from QL'98 position papers on RDF query:\nIn http://www.w3.org/TandS/QL/QL98/pp/queryservice.html\none scenario we implemented was to take two different data services (a couple of\ninternet catalogues at ILRT), each using different schemes, and exploit\nmappings between the taxonomies to merge data into a single environment.\n\nSee section, \"Example: Classification Scheme Mapping\". \n\nNot sure anything there is immediately useful for us now, but it was \ninteresting at the time, combining rule engines with the work we were\ndoing on RDF thesaurus stuff in the DESIRE project (one ancestor of\nTIF).\nhttp://www.desire.org/results/discovery/cat/mapclass_des.htm\nhttp://www.desire.org/results/discovery/rdfthesschema.html\n\nThe inference engine we used, SiLRI, is now no longer maintained.\nNeither is the parser SiRPAC. I think Biz/ed and SOSIG are still going\nthough :) \n\n(though I don't know if they still use different schemes, otherwise this\nmight be a good dataset to revisit...). Kate, does Biz/ed use DDC and\nSOSIG use UDC still?\n\nDan\n\n\n\n"
        },
        {
            "subject": "Exploring reference by description for concepts",
            "content": "Hi fellas,\n\nGot a question for you, if you've got chance to have a look at this I'd be\nvery grateful.\n\nAt the last SWAD-E technical meeting it was suggested that rather than give\neach concept in a thesaurus a URI, we could use reference by description.\nSo we could have thesaurus data that looks like:\n\n<soks:Concept>\n<soks:prefLabel>bangers and mash</soks:prefLabel>\n<rdfs:label>bangers & mash</rdfs:label>\n<rdfs:label>sausage and mash</rdfs:label>\n<rdfs:isDefinedBy\nrdf:resource=\"http://www.bigal.com/alsfoodthesaurus\"/>\n</soks:Concept>\n\nI'm using 'soks' as the prefix to refer to the namespace where we define a\ncore set of classes and properties for describing generic knowledge\norganisation systems including thesauri (superkos -> soks ... got a better\nname for this let me know!)\n\nMy question is this.  Now if I want to make statements linking this\nanonymous concept to other anonymously defined concepts, how do I do that?\nIs it enough for example to say ... \n\n<soks:Concept>\n<soks:prefLabel>bangers and mash</soks:prefLabel>\n<rdfs:isDefinedBy\nrdf:resource=\"http://www.bigal.com/alsfoodthesaurus\"/>\n<iso2788:broader>\n<soks:Concept>\n<soks:prefLabel>english foods</soks:prefLabel>\n<rdfs:isDefinedBy\nrdf:resource=\"http://www.bigal.com/alsfoodthesaurus\"/>\n</soks:Concept>\n</iso2788:broader>\n</soks:Concept>\n\nNow lets say I also define the concept referenced above more fully ...\n\n<soks:Concept>\n<soks:prefLabel>english foods</soks:prefLabel>\n<rdfs:label>english dishes</rdfs:label>\n<rdfs:label>english cuisine</rdfs:label>\n<rdfs:isDefinedBy\nrdf:resource=\"http://www.bigal.com/alsfoodthesaurus\"/>\n</soks:Concept>\n\n... if all the above rdf statements in this email define a model, does that\nmodel have two or four anonymous concepts?  \nIf I ask a query engine, what are all the rdfs:labels of the concept that is\nbroader than the concept with soks:prefLabel 'bangers and mash', what answer\nwill I get?   \n\nCan you can point me to any parts of the specs that deals with this?\n\nThanks,\n\nAlistair.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "using rdf:Alt for multilingual dat",
            "content": "How to get around the multilingual problem while still allowing concepts to\nhave only one prefLabel property -\n\n<soks:Concept>   \n <soks:prefLabel>\n      <rdf:Alt>\n<rdf:li xml:lang=\"en\">bangers and mash</rdf:li>\n<rdf:li xml:lang=\"fr\">saucisson et pomme de terre\nanglais</rdf:li>\n      </rdf:Alt>\n    </soks:prefLabel>\n<rdfs:isDefinedBy\nrdf:resource=\"http://www.bigal.com/alsfoodthesaurus\"/>\n<soks:Concept>\n\nAlistair.\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: using rdf:Alt for multilingual dat",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-10-29 17:09-0000]\n> \n> How to get around the multilingual problem while still allowing concepts to\n> have only one prefLabel property -\n> \n> <soks:Concept>   \n>  <soks:prefLabel>\n>       <rdf:Alt>\n> <rdf:li xml:lang=\"en\">bangers and mash</rdf:li>\n> <rdf:li xml:lang=\"fr\">saucisson et pomme de terre\n> anglais</rdf:li>\n>       </rdf:Alt>\n>     </soks:prefLabel>\n> <rdfs:isDefinedBy\n> rdf:resource=\"http://www.bigal.com/alsfoodthesaurus\"/>\n> <soks:Concept>\n\nI'd recommend simply repeating the property.\n\nrdf:Alt is horrible. The RDF specs aren't rude enough about it. There is \nno consistent notion of 'alternate' behind it.\n\nDan\n\n\n\n"
        },
        {
            "subject": "Reference by description: blank node",
            "content": "I found this in the Concepts and Abstract Syntax doc:\n\n\n6.6 Blank Nodes\n\n\nThe blank nodes in an RDF graph are drawn from an infinite set. This set of\nblank nodes, the set of all RDF URI references\n<http://www.w3.org/TR/rdf-concepts/#dfn-URI-reference> and the set of all\nliterals <http://www.w3.org/TR/rdf-concepts/#dfn-literal> are pairwise\ndisjoint. \n\nOtherwise, this set of blank nodes is arbitrary. \n\nRDF makes no reference to any internal structure of blank nodes. Given two\nblank nodes, it is possible to determine whether or not they are the same.\n\n\nHow is it determined whether or not two blank nodes are the same?\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Reference by description: blank node",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-10-29 17:25-0000]\n> I found this in the Concepts and Abstract Syntax doc:\n> \n> \n> 6.6 Blank Nodes\n> \n> \n> The blank nodes in an RDF graph are drawn from an infinite set. This set of\n> blank nodes, the set of all RDF URI references\n> <http://www.w3.org/TR/rdf-concepts/#dfn-URI-reference> and the set of all\n> literals <http://www.w3.org/TR/rdf-concepts/#dfn-literal> are pairwise\n> disjoint. \n> \n> Otherwise, this set of blank nodes is arbitrary. \n> \n> RDF makes no reference to any internal structure of blank nodes. Given two\n> blank nodes, it is possible to determine whether or not they are the same.\n> \n> \n> How is it determined whether or not two blank nodes are the same?\n\nBy being careful to distinguish the blank nodes (a data structure) from \nthe things they denote. This is one reason why stopped calling them\n\"anonymous resources\" btw. The way to figure out if two b-nodes denote \nthe same resource is to do some of the reasoning licensed by the OWL\nspec. In the simplest case, if you have the same property/value pair \nascribed and the property is an owl:InverseFunctionalProperty, then the \ntwo nodes should denote same thing. OWL is big and complicated and there \nare doubtless many other aspects to identity reasoning via OWL that\nmight be relevant, but this is probably the most common case.\n\nSee http://rdfweb.org/mt/foaflog/archives/000039.html for lengthier \nexplanation with a bias to how we've done this stuff in FOAF.\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: Reference by description: blank node",
            "content": "Cheers Dan.\n\nCan we cope with the situation where a B-Node may be uniquely identified not\nby a single property, but by a combination of two (or more) properties?\n\ne.g. Concepts uniquely identified by a combination of soks:prefLabel and\nrdfs:isDefinedBy properties.\n\nAl.\n\n-----Original Message-----\nFrom: Dan Brickley [mailto:danbri@w3.org]\nSent: 29 October 2003 17:54\nTo: Miles, AJ (Alistair) \nCc: Dave Beckett (E-mail); 'public-esw-thes@w3.org'\nSubject: Re: Reference by description: blank nodes\n\n\n\n* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-10-29 17:25-0000]\n> I found this in the Concepts and Abstract Syntax doc:\n> \n> \n> 6.6 Blank Nodes\n> \n> \n> The blank nodes in an RDF graph are drawn from an infinite set. This set\nof\n> blank nodes, the set of all RDF URI references\n> <http://www.w3.org/TR/rdf-concepts/#dfn-URI-reference> and the set of all\n> literals <http://www.w3.org/TR/rdf-concepts/#dfn-literal> are pairwise\n> disjoint. \n> \n> Otherwise, this set of blank nodes is arbitrary. \n> \n> RDF makes no reference to any internal structure of blank nodes. Given two\n> blank nodes, it is possible to determine whether or not they are the same.\n> \n> \n> How is it determined whether or not two blank nodes are the same?\n\nBy being careful to distinguish the blank nodes (a data structure) from \nthe things they denote. This is one reason why stopped calling them\n\"anonymous resources\" btw. The way to figure out if two b-nodes denote \nthe same resource is to do some of the reasoning licensed by the OWL\nspec. In the simplest case, if you have the same property/value pair \nascribed and the property is an owl:InverseFunctionalProperty, then the \ntwo nodes should denote same thing. OWL is big and complicated and there \nare doubtless many other aspects to identity reasoning via OWL that\nmight be relevant, but this is probably the most common case.\n\nSee http://rdfweb.org/mt/foaflog/archives/000039.html for lengthier \nexplanation with a bias to how we've done this stuff in FOAF.\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: Reference by description: blank node",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2003-10-29 18:21-0000]\n> Cheers Dan.\n> \n> Can we cope with the situation where a B-Node may be uniquely identified not\n> by a single property, but by a combination of two (or more) properties?\n> \n> e.g. Concepts uniquely identified by a combination of soks:prefLabel and\n> rdfs:isDefinedBy properties.\n\nI'm not sure how to do that in OWL, or even whether it is possible.\n\nI don't know that any RDF toolkits support that sort of thing\nout-of-the-box. They don't generally do single property based merging\neither, but it is probably easier.\n\nDan\n\n\n\n"
        },
        {
            "subject": "RDF Thesaurus  Unresolved Design Issue",
            "content": "Hi everyone,\n\nI've started a writeup and discussion of unresolved design issues regarding\nthe RDF thesaurus work.  It's on the SWAD wiki\n<http://esw.w3.org/topic/RdfThesaurus>.  Nikki, Dave B., Danbri, Dave R.,\nAndy, Libby, Chaals, Steve C, Paul, Brian, Ian, Alvaro, everyone in SWAD, it\nwould be great if you could get involved, I could really do with some\nfeedback and a bit of your expertise.\n\nI'll post a short summary to the public-esw-thes list when I add any new\nissues to the wiki, so please keep an eye out.\n\nYours,\n\nAlistair.     \n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": "Tom:\n\nWin is correct that the majority of people who posted on this topic were\nin favor.  \n\nBarbara Fox\nbfox@microsoft.com\n\n>----------\n>From: Tom Weinstein[SMTP:tomw@netscape.com]\n>Sent: Monday, October 07, 1996 1:06 PM\n>To: Win Treese\n>Cc: ietf-tls@w3.org\n>Subject: Re: Closing on shared-key authentication\n>\n>Win Treese wrote:\n>> \n>> I'd like to close on the question of including shared-key\n>> authentication in TLS. There has been little discussion\n>> of the latest proposal from Barbara Fox, but I think we\n>> went over the arguments pretty thoroughly a few weeks\n>> ago.\n>> \n>> At this point, I propose that we adopt the proposed\n>> modifications for the TLS draft. As always, I am happy\n>> to hear comments either on the list or in direct mail.\n>> \n>> In addition, if there are other burning issues for substantive\n>> changes, please let me know about them now.\n>\n>I fail to see how you can conclude that there's a rough consensus on\n>this proposal.\n>\n>First of all, I feel there are a number of weaknesses in any password\n>scheme.  In addition, this proposal has not received nearly as much\n>public review as SSL has.  For these reasons, I'm nervous about its\n>security.  It also has yet to be proven that this scheme provides any\n>more security than implementing passwords at a higher level.  Given this\n>combination of a lack of clear need and possible weakness, I feel that\n>this proposal doesn't belong in TLS.\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\n\n\n\n"
        },
        {
            "subject": "Design Issues (1)  Specialised vocab vs. extensible modular voca bs",
            "content": "I've added this issue to the discussion on the RDF Thesaurus wiki page\n<http://esw.w3.org/topic/RdfThesaurus>\n\nHere is a summary:-\n\n\nIssue 1 - Specialised vocab vs. extensible modular vocabs?\n\n\nAlthough most thesauri are pretty similar, there are important variations,\nand many thesauri deviate from the standards. Also, thesauri are very\nsimilar to other KOS e.g. classification schemes, taxonomis, topic maps. How\ndo we cope with this? \n\nOption 1 - Define a specialised vocabulary that covers only thesauri that\ncomply with the standards. \n\nOption 2 - Define a core vocab that captures what is common to all thesauri.\nThen define extension modules to cope with different flavours of thesauri. \n\nOption 3 - Define a core vocab that captures what is common to all KOS\n(thesauri, taxonomies, classification schemes, topic maps etc.). Define\nfirst level extension module for thesauri. Define second level extension for\nflavours. \n\n=== Comments on Issue 1 === \n\nAJM>> \n\nWhat we did previously ( [WWW]early draft of 8.1\n<http://www.w3c.rl.ac.uk/SWAD/deliv81.htm>) was half way between (1) and\n(2). \n\nI would like to go for (3), but am prepared to backtrack towards (2), which\nmay happen when we hit interop with this and OWL. (3) Would mean we have a\nway of fitting all these KOS together on the semantic web, which would be a\ngood thing. \n\nGoing for (3) means we have to define a core vocab. I've kind of assumed\nthis is what we are doing (tell me if you think it's a bad idea), and issues\nbelow relate first to this core vocab. We need a name for this core vocab,\nso at least we can refer to it. For now, I'm going to call it the core\nvocab. In code, I'm using the prefix soks. Why soks? Short for SuperKOS! Got\nany ideas about a better name? \n\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Design Issue (2)  To concept or not to concep",
            "content": "I've added this issue to the discussion on the RDF Thesaurus wiki page\n<http://esw.w3.org/topic/RdfThesaurus>\n\nHere is a summary:-\n\n2.2 Issue 2 - To concept or not to concept\n\n\nA thesaurus is a collection of concepts. So for the core-vocab we need to\nmodel abstract concepts in RDF. \n\nOption 1 - We define an rdfs:Class called soks:Concept. We use this to type\nresources that are intend ed to refer to abstract concepts. \n\nOption 2 - We define no such class. We use some other way to determine\nwhether a resource is a concept or not, if at all we need to. \n\n=== Comments on Issue 2 === \n\nAJM>> \n\nAt the recent SWAD meeting at HP, Chaals said (correct me if I'm wrong) in\nRDF every resource with a URI that has a fragment identifier necessarily is\nan abstract concept. Therefore we don't need a type for concepts. \n\nI say: \n\n1.My reading of the debate & TimBL's writeups is that resources with a\n<http://> uri and a frag id MAY (but NOT necessarily) refer to an abstract\nconcept. Resources with a <http://> uri and without a frag ID may NOT be an\nabstract concept (must necessarily be a document). \n2.If we have a soks:Concept class, we can type b-nodes as concepts. So\nwe can use reference by description to make statements about abstract\nconcepts without URIs. \n3.It makes the format look nicer if it starts with 'Concept' rather\nthan 'rdf:Description' all the time. This may be a serious point for KOS &\nDL people. \n\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Design Issue (3)  How to label concepts",
            "content": "I've added this issue to the discussion on the RDF Thesaurus wiki page\n<http://esw.w3.org/topic/RdfThesaurus>\n\nHere is a summary:-\n\nIssue 3 - How to label concepts?\n\nIn a thesaurus, every concept has one preferred term (label) and 0 or more\nalternative terms. \n\nThe obvious way to model this in RDF is to have one property for linking a\nresource to a preferred label (I'll call this soks:prefLabel for now) and\none property for linking a resource to any alternative labels (I'll call\nthis soks:altLabel for now). \n\nThis raises two design questions:- \n\nQuestion 1: domain restriction? - Do we (a) restrict the domain of these\nproperties to soks:Concept or do we (b) allow them to be used with any\nresource? \n\nQuestion 2: resources or literals? - Do we (a) restrict the range of these\nproperties to rdfs:Literal, or do we (b) restrict the range to some type of\nresource? \n\nWe may be able to re-use and/or extend existing properties, e.g. rdfs:label,\nbut what we choose to re-use depends on the resolution of these questions,\nso I'm saving a discussion of that for later. \n\nThe choice of solution to question 2 has important implications for\nmultilingual data and labelling ...\n\n... more at <http://esw.w3.org/topic/RdfThesaurus>\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Design Issue (4) - Concepts as languageembedded, language indepe ndent, or both",
            "content": "I've added this issue to the discussion on the RDF Thesaurus wiki page\n<http://esw.w3.org/topic/RdfThesaurus>\n\nHere is a summary:-\n\nIssue 4 - Concepts as language-embedded, language independent, or both?\n\nThere are multilingual thesauri. When modelling multilingual data in RDF, we\ncan choose one of the following options: \n\nOption 1: Concepts in a language - allow language properties only on nodes\ntyped as Concepts. \n\nOption 2: Labels in a language - allow language properties (or tags) only on\nnodes (or literals) which represent labels. \n\nOption 3: And/or - allow concepts and/or labels to have language properties.\n\n\nThe choice of solution has bold implications. If we choose option 1 we are\nassuming that all abstract concepts are embedded in a language; there can be\nno language independent concepts. If we choose option 2 we can model only\nconcepts that are deemed to be 'language-independent'. If we choose option 3\nwe can represent both language-embedded and language-independent concepts,\nhowever there may be some considerable scope for confusion. \n\n... more at <http://esw.w3.org/topic/RdfThesaurus>\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Developing Use Cases for a (RDFbased) Thesaurus Servic",
            "content": "[Following a SWADE meeting with Alistair Miles, CCLRC, Dave Beckett, ILRT]\nCan I kick this off (re the requirements spec & implementation of a \nthesaurus service)?\n\nObviously feel free to disagree/refine any of what I state here. It's a bit \noff the cuff.\n\nI think our scope includes :\na) A thesaurus service accessible to the end-user via a browser\nb) A \"3rd party\" thesaurus service, available for M2M networking\n\nThe set of \"questions\" that might be asked of either type of service seem \nto be the same for both & to include:\n\n[* asking for information pertaining to a single thesaurus *]\n- \"give me the preferred term for some concept X in some thesaurus Y\"\n- \"give me the non-preferred term(s) for some concept X in some thesaurus Y\"\n- \"give me the scope note for some concept X in some thesaurus Y\"\n- \"give me the broader/narrower/related term for some term Z in some \nthesaurus Y\"\n[nb use & use for]\n[ - perhaps some further questions based around the idea of asking for the \n*type* of relations between hierarchical terms within a thesaurus for \nexample 'broader-generic', 'broader-partitive' (part-of) as in your \ndocument, Alistair? Or are we keeping that sort of data \"behind the \nscenes\"?]\n-  \"give me metadata about thesaurus Y (s.a. it's language, it's creator \n???)\"\n\n[* asking for information re mappings between thesauri *]\n- \"give me the equivalent term(s) for X in some target thesaurus/thesauri \n(if it exists), or partial equivalent if it exists\"\n[& scope here - if we hope for a proof-of-concept scenario where some human \n& semi-automated effort has gone into \"preparing\" hierarchical KOS's that \nemploy different types of subsumption rules - for precise questions about \nmapped thesauri, using properties s.a. \"overlapsWith\", \"disjointWith\" etc \nas mentioned in your document, Alistair?]\n\n- also, need to provide query support re AND/OR etc re post-coordination, \nor is this out of scope?\n\nUSE CASES for a)\nJim Hendler's use case (from rdf-ig I think) - marking up web resources \nusing a thesaurus service\nSOSIG's use case - marking up resources for a specific user community - \nsocial sciences in this case\nAlistair Mile's use case - tool support for better searching and also \nbrowsing using web search engines s.a. Google  [similar scenario applies \ne.g. to SOSIG end user]\n\nUSE CASES for b)\nCross-search (re (\"invisible\") better query recall across a set of data \nrepositories, e.g. this would extend a tool like SPP's xsearch)\nCross-browse (so end-user can \"seamlessly\" browse a hierarchy of categories \nrepresented across many data repositories in order to refine their search \nterms, say. ie 2 or more KOS's have been \"federated\")\n\nApologies in advance for any ambiguous terminology!\n\nNikki\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Re: Developing Use Cases for a (RDFbased) Thesaurus Servic",
            "content": "Just a couple of suggestions:\n\nNJ Rogers, Learning and Research Technology wrote:\n\n> \n> - \"give me the preferred term for some concept X in some thesaurus Y\"\n\nIt's likely you would want to get a list of preferred terms in some \nthesaurus matching some submitted term, i.e. economics might match \n'economics' and 'financial economics', perhaps also allowing for \ntruncation or stemming. More for a user interfaced I guess.\n\nAnother request might be for the top-term/concept of the hierarchies a \nconcept is found in.\n\nPhil\n\n---------------------------------\nPhil Cross\nSenior Technical Researcher\nInstitute for Learning and Research Technology\nUniversity of Bristol\n8 - 10 Berkeley Square\nBristol, BS8 1HH\nTel: +44 (0)117 928 7113\nFax: +44 (0)117 928 7112\nE-mail: phil.cross@bristol.ac.uk\nURL: http://www.ilrt.bris.ac.uk/aboutus/staff?search=cmpac\n-----------------------------------\n\n\n\n"
        },
        {
            "subject": "Modular RDF vocabs for thesauruslike dat",
            "content": "This is a document with some suggestions, intended to get the ball rolling\nfor a discussion on how to fit RDF representations of various flavours of\nthesaurus into the world of ontologies, classification schemes etc.\n\n <<CIFoutline.rtf>> \nSuggestions for modular vocabularies for representing thesaurus-like data.\n\n\n\nThe Problem\n\nA thesaurus contains two quite different kinds of information.  First,\ninformation about how different terms are used to indicate things in our\nheads.  In other words, information about the labelling of concepts.  I will\ncall this terminology information.  Second, information about how the things\nin our head are related to each other.  In other words, o model of some\nconceptual structure.  I will call this conceptual information.  A major\ncriticism of existing thesaurus standards is that these two type sof\ninformation are muddlied, and hence recommendations are confusing (see NKOS\n2003 presentation by Dagobert Soergel).  \n\n\n\nThe Solution\n\nWe model these two types of informaiton independently.  This greatly\nimproves clarity.  It would also allow us to attach terminology information\nto all different kinds of conceptual structures (indexing schemes,\nclassification schemes, ontologies, topic maps etc.)\n\nIn RDF, I suggest we create several modular vocabularies.  For example, we\ncould have the following modules:\n\nTerminology Module\n\nLanguage Module\n\nConceptual Indexing Module \n\n\n\nTerminology Module\n  \nA simple set of properties allowing you to attach a preferred label and set\nof alternate labels to any resource.\n\n#RDF Terminology Module\n#\n############################################################################\n###########\n\n@prefix term: <???> .\n\nterm:pref\nardf:Property;\nrdfs:domainrdf:Resource;\nrdfs:rangeterm:Term.\n\nterm:alt\nardf:Property;\nrdfs:domainrdf:Resource;\nrdfs:rangeterm:Term.\n\nterm:Term\nardfs:Class.\n\nterm:value\nardf:Property;\nrdfs:domainterm:Term;\nrdfs:rangerdfs:Literal.\n\n############################################################################\n###########\n\nSo if your conceptual structure is best modelled as an ontology for example\n(lots of explicit isa, instanceof, partof and other specific type relations)\nthen build an OWL ontology and add the terminology layer using the above\nproperties.  If you want a traditional style thesaurus, use the Conceptual\nIndexing Module (see below) and attach terminology layer.\n\n#Some example use of terminology module\n############################################################################\n###########\n@prefix example: <example>.\n\nexample:aResource\nterm:pref[aterm:Term;\nterm:value\"Cats\";];\nterm:alt[aterm:Term;\nterm:value\"Felines\";];\n\n############################################################################\n###########\n\n\n\nLanguage Module\n\nI also suggest a generic module for expressing that any resource is in a\nspecific language (maybe this already exists ???).\n\n#RDF Language Module\n#\n############################################################################\n###########\n@prefix lang: <???>.\n\nlang:lang\nardf:Property;\nrdfs:domainrdf:Resource;\nrdfs:rangelang:Language.\n\nlang:Language\nardfs:Class.\n\nlang:en\nalang:Language.\n\nlang:fr\nalang:Language.\n\n#.....etc.\n\n############################################################################\n###########\n\nThis would give us a standard way to attach multilingual labels to an OWL\nontology, for example, or any conceptual structure which is sufficiently\nindependent of a linguistic context.\n\n#Some example use of terminology and language module\n############################################################################\n###########\n\nexample:aResource\nterm:pref[aterm:Term;\nterm:value\"Cats\";\nlang:langlang:en];\nterm:alt[aterm:Term;\nterm:value\"Felines\";\nlang:langlang:en];\nterm:pref[aterm:Term;\nterm:value\"Chats\";\nlang:langlang:fr];\n\n############################################################################\n###########\n\n\n\nConceptual Indexing Module\n\nThis is the bit I haven't cracked.  Basically, this bit is supposed to allow\nyou to build a conceptual structure of the nature of that usually described\nby a thesaurus, so identifying concepts and broader/narrower/related\nassociations between them.  But the emphasis is on its intended use.  This\nis very important.  By calling it the conceptual indexing module, it is very\nclear that any concept described by this vocabulary is intended for the\npurpose of indexing of web resources.  This solves the problem of the word\n\"thesaurus\" being used to mean actually a bunch of different things used for\nquite different purposes (e.g. indexing thesauri, search aid thesauri,\nautomated classification thesauri etc.)\n\nHere we must create a well-defined core, which can be extended by those who\nwish to use custom concept associations.  I suggest the following for the\ncore:\n\n#Conceptual Indexing Module core\n#####################################\n\n@prefix cif: <???>\n\ncif:Concept\nardfs:Class.\n\ncif:id\nardf:Property;\nrdfs:domaincif:Concept;\nrdfs:rangerdfs:Literal.\n\ncif:about\nardf:Property;\nrdfs:domainrdf:Resource;\nrdfs:rangecif:Concept;\n\n#####################################\n\nThat is, every concept has a unique ID, and to index any web resource\nagainst a concept, declare that the resource is 'about' some concept.\n\n\nBeyond this things start to get a bit hazy.  We may want also to do\nsomething like this, although I'm not sure:\n\n#CIF descriptor property\n#####################################\n\ncif:descriptor\nardf:Property;\nrdfs:domaincif:Concept;\nrdfs:rangeterm:Term.\n\n#####################################\n\nThat is, every concept must be linked to a term which is a noun or noun\nphrase that uniquely identifies it, such as 'Banks (Financial\nInstitutions)'.  Having both a 'cif:descriptor' property and a 'term:pref'\n(preferred-term) property simultaneously could be very confusing though.  \n\nI think the following two properties are probably a good idea:\n  \n#CIF foundation properties\n#####################################\n\ncif:relation\nardf:Property;\nrdfs:domaincif:Concept;\nrdfs:rangecif:Concept.\n\ncif:mapping\nardf:Property;\nrdfs:domaincif:Concept;\nrdfs:rangecif:Concept.\n\n#####################################\n\nThe 'relation' property is the super-property of all properties linking\nconcepts within the same scheme.  Broader/narrower/related type properties\nshould be declared as sub-properties of this property.  The point is that,\nhowever we or anyone extends this property, the precise semantics (ie.\nmeaning) of that property must be fully defined.  We probably want to put\nsome standard extensions in here, this we should definitely discuss!!!  I\nhave a heads up from the new british standards for thesauri which are under\ndevelopment, and it looks like they use a 'broader' relation to subsume the\nfollowing relations 'broader-generic' (isa) 'broader-instantive'\n(instanceof) 'broader-partitive' (part-of).  \n\nThen we might want to do something like this:\n\n#Properties to construct a hierarchy of concepts with no semantic\nimplications\n#####################################\n\ncif:parent\nardf:Property;\nrdfs:subPropertyOfcif:relation.\n\ncif:child\nardf:Property;\nrdfs:subPropertyOfcif:relation.\n\ncif:friend\nardf:Property;\nrdfs:subPropertyOfcif:relation.\n\n#####################################\n\nto ensure we can catch all types of data, in the case where semantics are\npoorly defined or standards are not consistently adhered to.  \n\nThe 'mapping' property is the super-property of all properties linking\nconcepts from different schemes.  Here there is a basis for defining some\nclearly understood properties.  If we take each concept from a scheme as\nstanding for the set of resources which are indexed against it, then we can\ncompare concepts from different schemes using set operations.  We could use\nsomething like the following vocabulary to do this:\n\n#CIF Properties and classes to define mappings between Concepts from\ndifferent sources\n######################################\n\ncif:sameAs\nardf:Property;\nrdfs:subPropertyOfcif:mapping.\n\ncif:overlapsWith\nardf:Property;\nrdfs:subPropertyOfcif:mapping.\n\ncif:includes\nardf:Property;\nrdfs:subPropertyOfcif:mapping.\n\ncif:includedBy\nardf:Property;\nrdfs:subPropertyOfcif:mapping.\n\ncif:disjointWith\nardf:Property;\nrdfs:subPropertyOfcif:mapping.\n\ncif:complementOf\nardf:Property;\nrdfs:subPropertyOfcif:mapping.\n\ncif:ConceptCombination\nardfs:Class;\nrdfs:subClassOfcif:Concept.\n\ncif:Union\nardfs:Class;\nrdfs:subClassOfcif:ConceptCombination.\n\ncif:Intersection\nardfs:Class;\nrdfs:subClassOfcif:ConceptCombination.\n\ncif:Exclusion\nardfs:Class;\nrdfs:subClassOfcif:ConceptCombination.\n\ncif:ofConcept\nardf:Property;\nrdfs:domaincif:ConceptCombination;\nrdfs:rangecif:Concept.\n\ncif:excluding\nardf:Property;\nrdfs:domaincif:Exclusion;\nrdfs:rangecif:Concept.\n\n######################################\n\nThis goes beyond the \"equivalence\" relations of the multilngual ISO\nstandard, to clearly define the full set of possible set operations.\n\n#Example data - concept mappings\n######################################\n\n@prefix example2: <example2> .\n\nexample:Politicians\nacif:Concept;\ncif:includes[acif:Union;\nofConceptexample2:MPs;\nofConceptexample2:MEPs;\nofConceptexample2:Councillors\n];\ncif:includedByexample2:PublicEmployees;\n.\n\n######################################\n\nIn the above example I have shown a mapping from a concept in a source\nscheme to both broader and narrower sets in the target scheme.  This\npractise allows you to guarantee recall in the case were a user wants for\nexample documents about Politicians, and in the case were the user requests\ndocuments NOT about politicians (see Doerr paper on concept mapping).\n\nThere's also some other things which may be worth considering, mainly\ninspired by the linguisitics people, which are properties linking a concept\nto an explanation, a definition, a context, an example, a picture, any other\nmultimedia object etc.  In other words, links from a concept to lots of\nthings which can help identify what that concept is referring to (thesaurus\nscope-notes fit in here too).\n\nThis document has not considered how to do things like expressing the\ngrouping of concepts into facets (such as 'objects', 'activities') or node\ngroups (such as 'paintings by period' and 'paintings by artist'').\n\nThe last thing is managing change and evolution.  We probably want to\nconsider some way of expressing that a concept is deprecated and has been\nreplaced by a new one, or has been modified in some way, and other such\nthings.  \n\n\n\n\n\n\nAlistair Miles\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n\n\n\napplication/rtf attachment: CIFoutline.rtf\n\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Win Treese wrote:\n> \n> I'd like to close on the question of including shared-key\n> authentication in TLS. There has been little discussion\n> of the latest proposal from Barbara Fox, but I think we\n> went over the arguments pretty thoroughly a few weeks\n> ago.\n\nIs the latest proposal still vulnerable to this type of an attack:\n\n- Given a server with TLS/passauth and no attack detection\n- Attacker uses dictionary attack against an account, \n  re-trying the Handshake with a dictionary of 65000 \n  commonly used passphrases\n\nIf the user's passphrase exists in the dictionary, then the effective\nsecurity seems to be \"16 bits\" rather than \"128 bits\".\n\n\n\n-- \nSteve Petripetri@litronic.com\nLitronic, Inc.http://www.litronic.com\n\n\n\n"
        },
        {
            "subject": "What isn't a Concept",
            "content": "My apologies if this has been discussed to death already; I just\nrecently learned of SKOS.\n\nAfter reading the draft specs and some of the recent discussion on this\nlist, I'm still not sure what things count as a skos:Concept,\nparticularly as it pertains to the use of foaf:topic and dc:subject.\n\nLets say I have a scheme with these elements:\n\n  _:A a skos:Concept\n    ; skos:prefLabel \"Politicians\"\n    .\n  \n  _:B a skos:Concept\n    ; skos:prefLabel \"U.S. Presidents\"\n    ; skos:broaderGeneric _:A\n    .\n  \n  _:C a skos:Concept\n    ; skos:prefLabel \"George Washington\"\n    ; skos:broaderInstantive _:B\n    .\n\nNow, _:A and _:B I can handle, but I'm not sure about _:C. Is that the\nsort of thing one would include in a thesaurus? (I'm guessing it is, by\nanalogy with the \"Red Lion pub\" example in sec. 3.9.2, but I could be\nwrong.\n\nLet's also say I have a description of George Washington, like so:\n\n  _:D a foaf:Person\n    ; foaf:name \"George Washington\"\n    .\n\n\nDo _:C and _:D denote the same resource? If not, what is the\nrelationship between them? If they are the same, then what is the\ndifference between skos:Concept and rdf:Resource?\n\n\nThis seems to be connected to the issue of foaf:topic vs. dc:subject.\nConsider these statements:\n\n  _:E dc:subject _:C.\n  _:F foaf:topic _:D.\n  _:G foaf:topic _:C.\n  _:H dc:subject _:D.\n\nIf we interpret _:C as a subject code which stands for George\nWashington, rather than George Washington himself, then we could\ninterpret this as asserting that _:E and _:F are about George Washington\nand _:G is about the subject code for George Washington (the statement\nabout _:H is inconsistent with the sense of dc:subject).\n\nIf _:C denotes George Washington, then _:F and _:G are about George\nWashington and the assertions about _:E and _:H are inconsistent with\ndc:subject.\n\nIf dc:subject and foaf:topic can be used interchangably, then we'd have\nto interpret it as saying _:E, _:F, _:G, and _:H are all about George\nWashington.\n\n\nAnyway, this is where I start feeling like I must be missing something.\nAm I totally on the wrong track here?\n\n(PS. I'm not currently on the list, so please include me in replies.\nThanks.)\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "External Identifiers RE: Announcing SKOS-Core 1.0  an RDF Schema for Thesaur",
            "content": "A remark about section 3.4 External Identifiers\nhttp://www.w3c.rl.ac.uk/SWAD/skos/1.0/guide/draft01.html#3.4\n\nJust providing the value of an external ID seems rather thin for efficient identification\npurpose. An external ID is more useful if the source is known. And you can get several of\nthose, so you need to sort them out. Seems that dc:source would make it, for example:\n\n<skos:Concept rdf:about=\"http:/example.com/concept/0001\">\n<skos:externalID>\n<dc:source>Food and Drug Administration Subject Headings</dc:source>\n<skos:externalIDValue>A.01.0001</skos:externalIDValue>\n</skos:externalID>\n<skos:externalID>\n<dc:source>World Cooking Thesaurus</dc:source>\n<skos:externalIDValue>UK.04.563</skos:externalIDValue>\n</skos:externalID>\n<skos:prefLabel>Bangers and mash</skos:prefLabel>\n<skos:altLabel>Sausage and mash</skos:altLabel>\n<skos:altLabel>Sausage and mashed potato</skos:altLabel>\n<skos:inScheme rdf:resource=\"http:/example.com/thesaurus\"/>\n</Concept>\n\nOf course having source identified by an URI rather than a name would be even better ...\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n> -----Message d'origine-----\n> De : public-esw-request@w3.org [mailto:public-esw-request@w3.org]De la\n> part de Miles, AJ (Alistair)\n> Envoy? : lundi 29 mars 2004 12:08\n> ? : 'public-esw@w3.org'\n> Objet : Announcing SKOS-Core 1.0 - an RDF Schema for Thesauri\n>\n>\n>\n>\n> > Anouncing: SKOS-Core 1.0 - an RDF Schema for thesauri and related\n> > knowledge organisation systems.\n> >\n> > The SKOS-Core 1.0 schema can be found at\n> >\n> > http://www.w3.org/2004/02/skos/core\n> >\n> > The SKOS-Core 1.0 Guide accompanying the schema can be found at\n> >\n> > http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n> >\n> > Also, the website for the SWAD-Europe Thesaurus Activity has moved to\n> >\n> > http://www.w3.org/2001/sw/Europe/reports/thes/\n> >\n> >\n> > SKOS stands for Simple Knowledge Organisation System.  The Goal of\n> > SKOS-Core is to provide a framework for bringing existing knowledge\n> > organisation systems such as thesauri and the semantic web together.\n> >\n> > SKOS-Core exploits the features of RDFS and OWL to provide a flexible and\n> > extensible framework within which different types of KOS can interoperate.\n> > SKOS-Core is ideal for modelling thesauri, and can cope with the\n> > variations commonly found in thesaurus design and structure.\n> >\n> > Yours on behalf of the Semantic Web Advanced Development for Europe\n> > project [1],\n> >\n> > Alistair Miles.\n> > Nikki Rogers.\n> > Dave Beckett.\n> >\n> > [1] SWAD-Europe <http://www.w3.org/2001/sw/Europe/>\n> >\n> > ---\n> > Alistair Miles\n> > Research Associate\n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> > Email:        a.j.miles@rl.ac.uk\n> > Tel: +44 (0)1235 445440\n> >\n> >\n>\n\n\n\n"
        },
        {
            "subject": "SWADEurope and the ECOinformatics Initiativ",
            "content": "Hi all,\n\nI attended a workshop this week on Environmental Thesauri and Terminologies,\nand presented some work from the SWAD-Europe Thesaurus Activity.\n\nA write-up of the event by me is here:\n\nhttp://esw.w3.org/mt/esw/archives/000052.html\n\nAl.  \n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope and the ECOinformatics Initiativ",
            "content": "Alistair\n\nCool report, to which I subscribe entirely :)\n\nSuppose it would be a good idea to report also to SWBP WG ...\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n> -----Message d'origine-----\n> De : public-esw-request@w3.org [mailto:public-esw-request@w3.org]De la\n> part de Miles, AJ (Alistair)\n> Envoy? : vendredi 16 avril 2004 15:05\n> ? : 'public-esw@w3.org'; 'public-esw-thes@w3.org'\n> Objet : SWAD-Europe and the ECOinformatics Initiative\n>\n>\n>\n> Hi all,\n>\n> I attended a workshop this week on Environmental Thesauri and Terminologies,\n> and presented some work from the SWAD-Europe Thesaurus Activity.\n>\n> A write-up of the event by me is here:\n>\n> http://esw.w3.org/mt/esw/archives/000052.html\n>\n> Al.\n>\n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n>\n>\n\n\n\n"
        },
        {
            "subject": "URIs for Concepts: Best Practice",
            "content": "Hi all,\n\nI wanted to consult you all on this matter.  I have agreement from the EEA\nto publish the GEMET environmental thesaurus in the SKOS/RDF format.  The\nnext step is to work out with them the URIs they wish to assign to their\nthesaurus and concepts.  I'm not sure what to recommend to them on this\nmatter.  \n\nI thought to use an http:// based URI base (e.g.\nhttp://www.eionet.eu.int/GEMET) and then add the id number of each concept\n(e.g. http://www.eionet.eu.int/GEMET#204).   \n\nA first question is, is it OK to use http: URIs for concepts?  Sorry to drag\nthis old chestnut up again, but I need some clear answer on best practices\nfor this.  Are we not at all concerned that the same URI may identify both a\nthesaurus concept and a resolveable network resource (i.e. the file\ncontaining the RDF data)?\n\nWhat do you think of info: based URIs for concepts?\n\nHope to hear from you on this,\n\nAl.\n\n\n\n\n\n  \n\n\n \n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "Hi Al,\n\nI like the approach that is outlined by the OASIS Published Subjects TC\n[1]. Although this document is a draft and omits some pieces that I\nwould like to see, I feel that the general approach is a good one. To\nsummarise, an HTTP identifier, when used to identify a concept *should*\nresolve to a human-readable resource that describes the concept. Despite\ncoming from the topic maps community, I feel that this approach is\napplicable to the creation of any identifier scheme that uses HTTP for\nnamespacing.\n\nThe things that I would like to see the TC consider is recommendations\nfor either embedding, linking to (e.g. using RDDL) or providing as\nparallel resource (via content negotiation), other machine-readable\ndescriptions of the concept and related resource - so an RDF resource\nwould be one example, the same information translated into XTM might be\nanother and so on.\n\nIt would be good to get the Published Subjects work kick started again\n(the committee went quiet a long time ago) - perhaps we could work on\nputting together a technical report to pass either to the OASIS TC or\njust to publish as part of the SWAD work ?\n\nCheers,\n\nKal\n\n[1]\nhttp://www.oasis-open.org/committees/download.php/3050/pubsubj-pt1-1.02-cs.pdf\n\nOn Mon, 2004-04-19 at 18:48, Miles, AJ (Alistair) wrote:\n> Hi all,\n> \n> I wanted to consult you all on this matter.  I have agreement from the EEA\n> to publish the GEMET environmental thesaurus in the SKOS/RDF format.  The\n> next step is to work out with them the URIs they wish to assign to their\n> thesaurus and concepts.  I'm not sure what to recommend to them on this\n> matter.  \n> \n> I thought to use an http:// based URI base (e.g.\n> http://www.eionet.eu.int/GEMET) and then add the id number of each concept\n> (e.g. http://www.eionet.eu.int/GEMET#204).   \n> \n> A first question is, is it OK to use http: URIs for concepts?  Sorry to drag\n> this old chestnut up again, but I need some clear answer on best practices\n> for this.  Are we not at all concerned that the same URI may identify both a\n> thesaurus concept and a resolveable network resource (i.e. the file\n> containing the RDF data)?\n> \n> What do you think of info: based URIs for concepts?\n> \n> Hope to hear from you on this,\n> \n> Al.\n> \n> \n> \n> \n> \n>   \n> \n> \n>  \n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n-- \nKal Ahmed <kal@techquila.com>\ntechquila\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Barb Fox wrote:\n> \n> Tom:\n> \n> Win is correct that the majority of people who posted on this topic\n> were in favor.\n\nI believe that this is not true.  In pursuit of proof, I went back\nthrough all of the messages on this topic and classified the opinions\nof all of the people who posted.  Here's the results:\n\nFor:\n  Dan Simon  <dansimon@microsoft.com>\n  Barbara Fox  <bfox@microsoft.com>\n  Don Schmidt  <donsch@microsoft.com>\n  Bennet Yee  <bsy@cs.ucsd.edu>\n  John Macko  <jmacko@nisa.compuserve.com>\n  Marc VanHeyningen  <marcvh@spry.com>\n  Tim Dierks  <timd@consensus.com>\n  Keith Ball  <Keith_Ball@novell.com>\n\nAgainst:\n  Tom Weinstein  <tomw@netscape.com>\n  Phil Karlton  <karlton@netscape.com>\n  Jeff Weinstein  <jsw@netscape.com>\n  Taher ElGamal  <elgamal@netscape.com>\n  Steve Petri  <petri@litronic.com>\n  Rohit Khare  <khare@pest.w3.org>\n  Eric Murray  <ericm@lne.com>\n  Christopher Allen  <ChristopherA@consensus.com>\n  Peter Lipp  <plipp@iaik.tu-graz.ac.at>\n\nNote that a few people were somewhat vague as to what they felt, and I\nprimarily classified them based on who they were arguing with.  These\nresults may have no relation to how people really feel about this\nproposal, but I think it's at least slightly more valuable than pulling\nresults out of thin air.\n\nIn any case, I think it is very clear that there's not a clear consensus\non this issue.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "RE: URIs for Concepts: Best Practice",
            "content": "Hi Kal,\n\nThanks alot for this.  \n\nI just had a read of the OASIS PS report [1].  Some initial impressions...\n\nI can see how the PSI/PSID approach would work well within a framework such\nas XTM that allows you to say whether you are using the URI to refer to the\nthing itself or the thing that describes the thing (sorry I just had to put\nit like that, I thought it sounded so funny).  \n\nBut RDF goes wrong if you use the same URI to refer to two different things.\nSo I'm not sure adopting the PSI/PSID convention for SKOS concept schemes\nwould be a good idea.  \n\n[As an aside, there's no reason why one couldn't define an\nInverseFunctionalProperty called e.g. subjectIndicator.  Then the value of\nthis property could be used to uniquely reference the concept itself, i.e.\none could refer to 'the thing with subjectIndicator X', which achieves the\nbasic aims of the PSI/PSID approach I think.]  \n\nIncidentally [RDF folks?], I always thought that was what the\nrdfs:isDefinedBy property was for - to link some resource to a resolveable\nresource that defines it.  \n\nAnyways, Kal, I would like to develop this further with you.  Some clearly\ndefined best practices here would do the world of good I think.  Look\nforward to more thoughts on this.\n\nYours,\n\nAl.\n\n[1] http://www.oasis-open.org/committees/download.php/3050/\n[2] http://www.rddl.org/    \n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: Kal Ahmed [mailto:kal@techquila.com]\n> Sent: 19 April 2004 19:30\n> To: Miles, AJ (Alistair)\n> Cc: 'public-esw-thes@w3.org'; 'public-esw@w3.org'\n> Subject: Re: URIs for Concepts: Best Practices\n> \n> \n> \n> Hi Al,\n> \n> I like the approach that is outlined by the OASIS Published \n> Subjects TC\n> [1]. Although this document is a draft and omits some pieces that I\n> would like to see, I feel that the general approach is a good one. To\n> summarise, an HTTP identifier, when used to identify a \n> concept *should*\n> resolve to a human-readable resource that describes the \n> concept. Despite\n> coming from the topic maps community, I feel that this approach is\n> applicable to the creation of any identifier scheme that uses HTTP for\n> namespacing.\n> \n> The things that I would like to see the TC consider is recommendations\n> for either embedding, linking to (e.g. using RDDL) or providing as\n> parallel resource (via content negotiation), other machine-readable\n> descriptions of the concept and related resource - so an RDF resource\n> would be one example, the same information translated into \n> XTM might be\n> another and so on.\n> \n> It would be good to get the Published Subjects work kick started again\n> (the committee went quiet a long time ago) - perhaps we could work on\n> putting together a technical report to pass either to the OASIS TC or\n> just to publish as part of the SWAD work ?\n> \n> Cheers,\n> \n> Kal\n> \n> [1]\n> http://www.oasis-open.org/committees/download.php/3050/pubsubj\n> -pt1-1.02-cs.pdf\n> \n> On Mon, 2004-04-19 at 18:48, Miles, AJ (Alistair) wrote:\n> > Hi all,\n> > \n> > I wanted to consult you all on this matter.  I have \n> agreement from the EEA\n> > to publish the GEMET environmental thesaurus in the \n> SKOS/RDF format.  The\n> > next step is to work out with them the URIs they wish to \n> assign to their\n> > thesaurus and concepts.  I'm not sure what to recommend to \n> them on this\n> > matter.  \n> > \n> > I thought to use an http:// based URI base (e.g.\n> > http://www.eionet.eu.int/GEMET) and then add the id number \n> of each concept\n> > (e.g. http://www.eionet.eu.int/GEMET#204).   \n> > \n> > A first question is, is it OK to use http: URIs for \n> concepts?  Sorry to drag\n> > this old chestnut up again, but I need some clear answer on \n> best practices\n> > for this.  Are we not at all concerned that the same URI \n> may identify both a\n> > thesaurus concept and a resolveable network resource (i.e. the file\n> > containing the RDF data)?\n> > \n> > What do you think of info: based URIs for concepts?\n> > \n> > Hope to hear from you on this,\n> > \n> > Al.\n> > \n> > \n> > \n> > \n> > \n> >   \n> > \n> > \n> >  \n> > \n> > ---\n> > Alistair Miles\n> > Research Associate\n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> > Email:        a.j.miles@rl.ac.uk\n> > Tel: +44 (0)1235 445440\n> > \n> -- \n> Kal Ahmed <kal@techquila.com>\n> techquila\n> \n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "Miles, AJ (Alistair)  writes:\n\n> I wanted to consult you all on this matter.  I have agreement from\n> the EEA to publish the GEMET environmental thesaurus in the SKOS/RDF\n> format.  The next step is to work out with them the URIs they wish to\n> assign to their thesaurus and concepts.  I'm not sure what to\n> recommend to them on this matter.\n\nDan Brickley's Wordnet vocabulary service[1] at xmlns.com seems like a\nuseful model. Essentially, each concept is given a (non-fragmentary) URI\nwhich, if dereferenced, returns a description of the concept. Mr\nBrickley's system only returns RDF/XML presently, but there's no reason\nit couldn't also return HTML or something else via content negotiation.\n\n[1] http://xmlns.com/2001/08/wordnet/\n\n> I thought to use an http:// based URI base (e.g.\n> http://www.eionet.eu.int/GEMET) and then add the id number of each\n> concept (e.g. http://www.eionet.eu.int/GEMET#204).\n\nThat works, but my preference would be for something like\n<http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID means\nthat an HTTP request to a term's URI will return nothing or else a\ndescription of the entire vocabulary, which I'm guessing is pretty\nlarge.\n\n> A first question is, is it OK to use http: URIs for concepts?  Sorry\n> to drag this old chestnut up again, but I need some clear answer on\n> best practices for this.  Are we not at all concerned that the same\n> URI may identify both a thesaurus concept and a resolveable network\n> resource (i.e. the file containing the RDF data)?\n\nIt would be confusing for a URI to identify a thesaurus concept and an\nRDF file. The key, as I see it, is the idea that the response to an HTTP\nGet is a representation of the resource, not the resource itself. The\nfact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML\ndocument, doesn't mean that it identifies that particular document. If,\nfor some reason, you wanted to talk about that RDF/XML document instead\nof the word \"Dog\", you would need to use a blank node or a different\nURI.\n\nNot everyone agrees with this position.\n\n> What do you think of info: based URIs for concepts?\n\n>From an RDF perspective, it's just as good. From a web perspective, it's\nless useful because it can't be dereferenced.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n> Miles, AJ (Alistair)  writes:\n> \n> > I wanted to consult you all on this matter.  I have agreement from\n> > the EEA to publish the GEMET environmental thesaurus in the SKOS/RDF\n> > format.  The next step is to work out with them the URIs they wish to\n> > assign to their thesaurus and concepts.  I'm not sure what to\n> > recommend to them on this matter.\n> \n> Dan Brickley's Wordnet vocabulary service[1] at xmlns.com seems like a\n> useful model. Essentially, each concept is given a (non-fragmentary) URI\n> which, if dereferenced, returns a description of the concept. Mr\n> Brickley's system only returns RDF/XML presently, but there's no reason\n> it couldn't also return HTML or something else via content negotiation.\n> \n> [1] http://xmlns.com/2001/08/wordnet/\n> \n> > I thought to use an http:// based URI base (e.g.\n> > http://www.eionet.eu.int/GEMET) and then add the id number of each\n> > concept (e.g. http://www.eionet.eu.int/GEMET#204).\n> \n> That works, but my preference would be for something like\n> <http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID means\n> that an HTTP request to a term's URI will return nothing or else a\n> description of the entire vocabulary, which I'm guessing is pretty\n> large.\n> \nI think that this practice would certainly work much better with\nPSI/PSID constructs than the fragmentary approach - one resource per\nconcept is probably a best practice that the Published Subjects TC\nshould recommend.\n\n> > A first question is, is it OK to use http: URIs for concepts?  Sorry\n> > to drag this old chestnut up again, but I need some clear answer on\n> > best practices for this.  Are we not at all concerned that the same\n> > URI may identify both a thesaurus concept and a resolveable network\n> > resource (i.e. the file containing the RDF data)?\n> \n> It would be confusing for a URI to identify a thesaurus concept and an\n> RDF file. The key, as I see it, is the idea that the response to an HTTP\n> Get is a representation of the resource, not the resource itself. The\n> fact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML\n> document, doesn't mean that it identifies that particular document. If,\n> for some reason, you wanted to talk about that RDF/XML document instead\n> of the word \"Dog\", you would need to use a blank node or a different\n> URI.\n> \nIt is certainly true that content negotiation gives you the problem of\ntalking about the descriptive resource as opposed to the described\nthing. That is a strong argument against content negotiation for RDF /\nXTM resources. However, there are still two other options:\n\n1) Embed the RDF / TM markup in its XML form. Then use an rdf:ID\nattribute or XTM id attribute so that the reference to the RDF/XTM would\nbe <http://xmlns.com/wordnet/1.6/Dog#foo>\n\n2) Use a profile of XLink to link to the RDF / TM resource that\ndescribes the concept, and make it completely separate. e.g.\n<http://xmlns.com/wordnet/1.6/Dog/dog.rdf>\n\n> Not everyone agrees with this position.\n> \nI don't think that a position can ever be established which everyone \nwill agree with :-)\n\n> > What do you think of info: based URIs for concepts?\n> \n> >From an RDF perspective, it's just as good. From a web perspective, it's\n> less useful because it can't be dereferenced.\n\nI tend to agree. I tend to consider the use of URIs for subject\nidentification as being divided into three categories:\n1) The URI resolves to the subject being described\n2) The URI resolves to a description of the subject being described\n3) The URI is used as a pure, unresolvable identifier\n\nI think (2) gives the greatest possibility for interchange of semantics\nif the resource addressed by the URI is human-readable - at some point\nthe processing of semantics has to be transferred from SW machinery to\nwet-ware.\n\nCheers,\n\nKal\n-- \nKal Ahmed <kal@techquila.com>\ntechquila\n\n\n\n"
        },
        {
            "subject": "AW: URIs for Concepts: Best Practice",
            "content": "This discussion is coming up from time to time. Its also called\n\"Identity crisis\" or \"Uri crisis\"\n\nSome interesting articles are:\n-rfc2396 (uri)\n- http://www.w3.org/2002/11/dbooth-names/dbooth-names_clean.htm \n- http://www.xml.com/pub/a/2002/09/11/deviant.html\n- http://www.w3.org/DesignIssues/HTTP-URI \n\nMy opinion is to use Http URIs because:\n- they are unique\n- you can optionally put some content at the place the uri identifies\n(be it RDF or HTML)\n\nanother guy behind this approach is Patrick Stickler and his URIQA.\n\nA good concept to think about when using Uris to identify more than one\nthing is to \"Seperate by Ontology\"\n\nYou can use a single resource uri and annotate it with different\ntriples, when you want to describe the \"Web resource\" aspect of the uri,\nuse a web ontology, when you want to describethe \"dog-concept\" aspect,\nuse the dog/concept ontology. They won't mix up, namespaces do the\nseperation. And a single resource can have more than one type. voila.\n\nAd1: Don't use HASH identifiers if you can avoid them!\nhttp://test/doh#hello\nmay come to your web server as:\nhttp://test/doh\n--> whoops.\n\ngreetings\nLeo Sauermann\n\n\n\n> -----Urspr?ngliche Nachricht-----\n> Von: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] Im Auftrag von Kal Ahmed\n> Gesendet: Dienstag, 20. April 2004 09:19\n> An: David Menendez\n> Cc: Miles, AJ (Alistair); 'public-esw-thes@w3.org'; \n> 'public-esw@w3.org'\n> Betreff: Re: URIs for Concepts: Best Practices\n> \n> \n> \n> On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n> > Miles, AJ (Alistair)  writes:\n> > \n> > > I wanted to consult you all on this matter.  I have \n> agreement from \n> > > the EEA to publish the GEMET environmental thesaurus in \n> the SKOS/RDF \n> > > format.  The next step is to work out with them the URIs \n> they wish \n> > > to assign to their thesaurus and concepts.  I'm not sure what to \n> > > recommend to them on this matter.\n> > \n> > Dan Brickley's Wordnet vocabulary service[1] at xmlns.com \n> seems like a \n> > useful model. Essentially, each concept is given a \n> (non-fragmentary) \n> > URI which, if dereferenced, returns a description of the \n> concept. Mr \n> > Brickley's system only returns RDF/XML presently, but there's no \n> > reason it couldn't also return HTML or something else via content \n> > negotiation.\n> > \n> > [1] http://xmlns.com/2001/08/wordnet/\n> > \n> > > I thought to use an http:// based URI base (e.g.\n> > > http://www.eionet.eu.int/GEMET) and then add the id \n> number of each \n> > > concept (e.g. http://www.eionet.eu.int/GEMET#204).\n> > \n> > That works, but my preference would be for something like \n> > <http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID \n> > means that an HTTP request to a term's URI will return \n> nothing or else \n> > a description of the entire vocabulary, which I'm guessing \n> is pretty \n> > large.\n> > \n> I think that this practice would certainly work much better \n> with PSI/PSID constructs than the fragmentary approach - one \n> resource per concept is probably a best practice that the \n> Published Subjects TC should recommend.\n> \n> > > A first question is, is it OK to use http: URIs for \n> concepts?  Sorry \n> > > to drag this old chestnut up again, but I need some clear \n> answer on \n> > > best practices for this.  Are we not at all concerned \n> that the same \n> > > URI may identify both a thesaurus concept and a \n> resolveable network \n> > > resource (i.e. the file containing the RDF data)?\n> > \n> > It would be confusing for a URI to identify a thesaurus \n> concept and an \n> > RDF file. The key, as I see it, is the idea that the response to an \n> > HTTP Get is a representation of the resource, not the \n> resource itself. \n> > The fact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML \n> > document, doesn't mean that it identifies that particular document. \n> > If, for some reason, you wanted to talk about that RDF/XML document \n> > instead of the word \"Dog\", you would need to use a blank node or a \n> > different URI.\n> > \n> It is certainly true that content negotiation gives you the \n> problem of talking about the descriptive resource as opposed \n> to the described thing. That is a strong argument against \n> content negotiation for RDF / XTM resources. However, there \n> are still two other options:\n> \n> 1) Embed the RDF / TM markup in its XML form. Then use an \n> rdf:ID attribute or XTM id attribute so that the reference to the\nRDF/XTM would be > <http://xmlns.com/wordnet/1.6/Dog#foo>\n> \n> 2) Use a profile of \n> XLink to link to the RDF / TM resource that describes the \n> concept, and make it completely separate. e.g. \n<http://xmlns.com/wordnet/1.6/Dog/dog.rdf>\n\n> Not everyone agrees with this position.\n> \nI don't think that a position can ever be established which everyone \nwill agree with :-)\n\n> > What do you think of info: based URIs for concepts?\n> \n> >From an RDF perspective, it's just as good. From a web perspective, \n> >it's\n> less useful because it can't be dereferenced.\n\nI tend to agree. I tend to consider the use of URIs for subject\nidentification as being divided into three categories:\n1) The URI resolves to the subject being described\n2) The URI resolves to a description of the subject being described\n3) The URI is used as a pure, unresolvable identifier\n\nI think (2) gives the greatest possibility for interchange of semantics\nif the resource addressed by the URI is human-readable - at some point\nthe processing of semantics has to be transferred from SW machinery to\nwet-ware.\n\nCheers,\n\nKal\n-- \nKal Ahmed <kal@techquila.com>\ntechquila\n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Hi Mark,\n\nThis is a response to your mail, for both yourself and a wider audience.\n\n> \n> \n> Hi Alistair \n> \n> Thanks for your explanation, it was very helpful, and allowed me to\n> understand why I have been getting some strange results.\n> \n> However I've been thinking about this some more, and at the moment I'm\n> trying to think through whether it would be useful to be able \n> to assign URIs\n> to alternative terms as well as preferred terms. I would be \n> very interested\n> to hear your feedback here. I understand you have a \n> distinction between\n> concepts and terms, and I've just broken it, but please bear with me. \n\nThis is how I understand this problem (wizened thesaurus gurus please\ncorrect me if I'm off base):\n\nGenerally, a thesaurus consists of two sets of terms, the 'preferred' terms\n(sometimes called 'descriptors') and the 'non-preferred' terms (sometimes\ncalled 'entry' terms).  Only the preferred terms should be used by\ncataloguers in their indexing work - a non-preferred term should never be\nused for indexing.  The non-preferred terms are there to help the cataloguer\nfind their way to the correct preferred term to use (hence the name 'entry'\nterm).\n\nFor example (from GCL) there is the preferred term:\n\nPrimary health care\nUse for\nGeneral Practise (NHS)\nGP services\nHealth centres (NHS)\nMaternity services\nNHS Direct\n\nThis set of terms constitutes the set of labels for a single concept.  The\nintended meaning of this concept should be inferred from the preferred\nlabel, the alternative labels, the neighbouring concepts, and any scope\nnotes or definition.  \n\nI arrived at this interpretation, and Stella Dextre-Clarke has indicated [1]\n(also see follow-up from me [6]) that she shares this interpretation,\nmoreover it is entirely consistent with the original intention of ISO2788.\n\n\nSo in fact when a cataloguer indexes a document with the GCL term 'Primary\nhealth care' they are indexing the document against a concept whose complete\nmeaning should be inferred from all the above terms.\n\nNow another thesaurus might have all these terms as preferred terms, in\nwhich case each would be the preferred label for a unique concept with some\nfiner aspect of meaning (see also discussion on mapping below).\n\nSo the SKOS approach is always to consider a preferred term and the\nassociated set of alternative terms as the set of labels for a single\nconcept, and that concept is what should be given a URI.  \n\nOn a slightly more philosophical note, I think it is absolutely incorrect\nand misleading to assign URIs to terms.  In fact there is no point assigning\na URI to a term because a term is just a sequence of characters, and as such\nis an identifier for itself.  The useful thing to do is to assign a URI to\nsome piece of MEANING, and then help other people to infer what you intend\nfor that piece of meaning by attaching labels, descriptions, definitions,\ndepictions etc. to it.  In some cases a single label may be sufficient.  In\nother cases a long and precise definition may be required.  \n\nThis is the only effective way to cope with the reality that a single\nsequence of characters can mean different things to different people.     \n\nTo compress both the string of characters and the meaning you associate with\nit into the same node within a graph is I believe a fundamental error,\nalthough you would be forgiven for doing this because literature coming from\nthe thesaurus world can be far from clear on this matter.  \n\n\n\n> \n> In the Library of Congress Thesaurus of Graphic Materials, \n> there are many\n> instances where an alternative term has two or more preferred \n> terms. For\n> example in the LOC TGM \"cadavers\" is an alternative term, and \n> it is linked\n> to two preferred terms, \"dead bodies\" and \"dead animals\". So \n> I think what is\n> happening is the LOC TGM is advocating that cataloguers are \n> better to choose\n> either \"dead bodies\" or \"dead animals\" rather than use the \n> ambiguous term\n> \"cadavers\". Therefore \"cadavers\" really represents the union of \"dead\n> bodies\" and \"dead animals\". However, as SKOS does not allow \n> \"cadavers\" to\n> have a unique URI, it is not possible to reference this term. \n> \n> Other examples of unions in LOC TGM include:\n> \n> MT: Abnormalities\n> USE: Birth defects\n> USE: Human curiosities\n> \n> MT: Agony\n> USE: Distress\n> USE: Pain\n> \n> MT: Agreements\n> USE: Contracts\n> USE: Treaties\n> \n> etc\n> \n\nIf two concepts in the same thesaurus share some alternative label, it\nprobably indicates that they share some element of meaning, or are closely\nrelated.  \n\n\n\n> Also, in the LOC TGM, there are many cases where a preferred \n> term has many\n> alternative terms. Now if we want to map another thesaurus or \n> dataset onto\n> LOC TGM, ideally we want to map between identical terms \n> (because our hope is\n> are about the same concept) even if they are not preferred. I \n> suspect - with\n> obvious caveats that I'm still in the process of \n> understanding thesaurus -\n> that alternative and preferred terms do not necessarily refer \n> to the same\n> concepts. Rather, they may refer to different but overlapping \n> concepts, and\n> one term is preferred because the concept it refers to is \n> \"crisper\" i.e.\n> more well defined and less ambiguous. If alternative labels \n> had URIs, it\n> would be possible to represent this. \n> \n\n\nThe SKOS approach to mapping is explicitly concept oriented.  That is, when\nmapping between thesauri, always bear in mind that you are mapping between\nthe concepts from each thesaurus, and NOT the terms.  I refer you to the\nSKOS-Mapping schema [2] and SWAD-E deliverable 8.3 [3].  \n\nWhy do this?  Because it is most useful to identify the relationship of\nmeaning between the entities that are the true indexing units.\n\nI put that sentence on a separate line, because it probably needs some\nexplanation.  Consider the following example (in N3):\n\nThesaurus A has a concept ...\n\nconceptA\naskos:Concept;\nskos:inSchemethesaurusA;\nskos:prefLabel'Primary health care';\nskos:altLabel'General Practise (NHS)';     \nskos:altLabel'GP services';     \nskos:altLabel'Health centres (NHS)';     \nskos:altLabel'NHS Direct';\n    skos:altLabel'Maternity services'.\n\n\nThesaurus B has a concept ...\n\nconceptB\naskos:Concept;\nskos:inSchemethesaurusB;\nskos:prefLabel'Maternity services'.\n\nNow although there is a label shared between these two concepts, it is\nobvious that concept A is broader in meaning than concept B.  So although a\ncommon label suggests that some mapping can be defined, the exact nature of\nthat mapping cannot be defined without considering the complete intended\nmeaning of each concept.\n\nIn this case, the appropriate mapping would be ...\n\nconceptA\nskos-map:narrowMappingconceptB.\n\nconceptB\nskos-map:broadMappingconceptA.\n\n[3] has further examples.\n\nNow that we have this mapping, we could substitute concept A for concept B\nin a query, and know that we will get a result set that is broader in scope\nthan the original intension of the query.  I.e. this type of mapping is a\nbasis for managing the specificity and completeness of result sets under\nquery substitution/translation.\n\n\n\n> If URIs were assigned to both preferred and alternative \n> terms, this would\n> allow them to use rdfs:label as opposed to skos:prefLabel and \n> skos:altLabel,\n> and I think using rdfs:label whenever possible is very useful \n> as it makes\n> life much easier for browsers. \n> \n> An additional problem here is it seems natural to use rdf:type to\n> distinguish between preferred and alternative terms. However a term is\n> preferred or alternative only in the scope of a particular \n> thesaurus. If we\n> use rdf:type, then when we use owl:sameAs to map terms in \n> different thesauri\n> or a thesauri and a dataset (this is the approach I'm using \n> at the moment)\n> then preferred status may migrate in undesirable ways e.g. if \n> we map term A\n> in thesaurus B to term C in thesaurus D, where term A is \n> preferred and term\n> C is alternative, then suddenly term C will become preferred \n> in D which is\n> not our intention. \n\nI do not recommend the use of owl:sameAs to express a mapping between\nconcepts from different thesauri.  The reason for this is that it blurs the\nboundary between the two thesauri.  Where you wish to maintain the integrity\n(boundary) of each scheme, use skos-map:exactMapping.  \n\nIn the alternative use case where you want to link two thesauri to create a\nlarger thesaurus, using owl:sameAs IS recommended, along with any of the\nsemantic relation properties from SKOS-Core.\n\nIn general, to express a relationship of meaning between two concepts within\nthe same thesaurus, use any of the sub-properties of skos:semanticRelation\n(from SKOS-Core schema [4][5]).  To express a relationship of meaning\nbetween two concepts from different thesauri, use any of the sub-properties\nof skos-map:semanticMapping (from SKOS-Mapping schema [2][3]).\n\n\n> One possible solution here would be to \n> have properties\n> such as skos:preferredTermIn and skos:alternativeTermIn that \n> point back to\n> the thesauri where the term is preferred or alternative?\n> \n> What do you think? \n\nThese suggested properties imply a term-oriented approach to modelling\nthesauri in RDF.  I hope I have been able to make the beginnings of a case\nhere for why I believe a concept-oriented approach to modelling thesauri\npromises to be far more fruitful.\n\nI'm going to leave it there because this is possibly the longest email I've\never written.\n\nYours,\n\nAlistair.\n\n\n[1] http://lists.w3.org/Archives/Public/public-esw-thes/2004Mar/0057.html\n[2] http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n[3] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n[4] http://www.w3.org/2004/02/skos/core\n[5] http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n[6] http://lists.w3.org/Archives/Public/public-esw-thes/2004Mar/0060.html\n\n\n> \n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: 19 April 2004 19:21\n> To: 'Butler, Mark'\n> Subject: RE: SKOS & SIMILE\n> \n> \n> Hi Mark,\n> \n> Re USE relationships, SKOS treats this in a different way.  \n> The set of terms\n> that constitute a preferred term and the synonyms \n> (non-preferred terms) is\n> modelled as the set of possible labels for a single concept.  \n> \n> So for example (from UK GCL):\n> ---\n> Animal rights and welfare\n> UFAnimal welfare\n> UFWelfare (animals)\n> \n> Animal Welfare\n> USEAnimal rights and welfare\n> \n> Welfare (animals)\n> USEAnimal rights and welfare\n> ---\n> \n> ... gets mapped into the following SKOS construct:\n> \n> <skos:Concept>\n> <skos:prefLabel>Animal rights and welfare</skos:prefLabel>\n> <skos:altLabel>Animal welfare</skos:altLabel>\n> <skos:altLabel>Welfare (animals)</skos:altLabel> </skos:Concept>\n> \n> [Here the concept is a blank node to illustrate the \n> principal, but should\n> probably be given an explicit URI.]\n> \n> The node representing the concept then becomes the indexing \n> unit, and not\n> any of the labels.\n> \n> Hope that helps,\n> \n> Alistair.\n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "On Mon, 19 Apr 2004, David Menendez wrote:\n\n> > A first question is, is it OK to use http: URIs for concepts?  Sorry\n> > to drag this old chestnut up again, but I need some clear answer on\n> > best practices for this.  Are we not at all concerned that the same\n> > URI may identify both a thesaurus concept and a resolveable network\n> > resource (i.e. the file containing the RDF data)?\n>\n> It would be confusing for a URI to identify a thesaurus concept and an\n> RDF file. The key, as I see it, is the idea that the response to an HTTP\n> Get is a representation of the resource, not the resource itself. The\n> fact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML\n> document, doesn't mean that it identifies that particular document.\n\nThat's the REST point of view and it's reiterated in the recent TAG\npublication.\n\n> If,\n> for some reason, you wanted to talk about that RDF/XML document instead\n> of the word \"Dog\", you would need to use a blank node or a different\n> URI.\n\nYes; there's no generally applicable vocab currently (as far as I'm\naware) in RDF to describe the relationship between a URI (as a web\naddress rather than a resource identifier, so probably in the format of\na datatyped literal) and stuff you get when dereferencing that URI,\nincluding specific content-negotiated HTTP conversations. But there's no\nreason why there shouldn't be, and it'd let you explicitly avoid\nconfusions like \"Ora Lassila's size in bytes\".\n\n> Not everyone agrees with this position.\n\nIncluding, I'm led to believe, some members of TAG.\n\n\n\n-- \njan grant, ILRT, University of Bristol. http://www.ilrt.bris.ac.uk/\nTel +44(0)117 9287088 Fax +44 (0)117 9287112 http://ioctl.org/jan/\n\"Sufficiently large\"=\"infinite\" for sufficiently large values of \"sufficiently\"\n\n\n\n"
        },
        {
            "subject": "FW: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Alistair,\nJust a word of support for your explanation concerning the treatment of\nconcepts, preferred terms and non-preferred terms. The concept (rather\nthan the term) is the key unit that indexing/meta-tagging attempts to\ncapture. This very much reflects the intention of ISO 2788, even though\nthe current standard is not as explicit as we might wish. As work\nproceeds on revising BS5723=ISO2788, we hope to see this intention\nexpressed more clearly.\n\nI further agree with your comment, \"literature coming from the thesaurus\nworld can be far from clear on this matter.\" Not only literature, but\nalso the thesaurus management software that is currently on the market.\nMost of the available packages are term-oriented not concept-oriented,\nand so the outputs from them are not entirely straightforward to present\nusing the SKOS-Core schema. ( There are a few exceptions, but typically\nthey have other problems...) The difficulties can of course be overcome,\nbut care is needed to do so.\n\nPlease do not interpret that as a criticism of SKOS-Core! It is intended\nas a warning that confusion and difficulties are likely to persist until\nsuch time as the thesaurus-using community has moved on to\nconcept-oriented models. \n\nCheers\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n"
        },
        {
            "subject": "RE: URIs for Concepts: Best Practice",
            "content": "Kal, Alistair\n\nJust a quick note from a member and former chair of OASIS PubSubj TC\n\n> I like the approach that is outlined by the OASIS Published Subjects TC\n> [1]. Although this document is a draft and omits some pieces that I\n> would like to see, I feel that the general approach is a good one.\n\nThis is not a draft, it's a TC recommendation. Should be the first one of a series,\nunfortunately there has not been consensus yet in the TC for what next recommendations\nshould contain.\n\n> To summarise, an HTTP identifier, when used to identify a concept *should*\n> resolve to a human-readable resource that describes the concept. Despite\n> coming from the topic maps community, I feel that this approach is\n> applicable to the creation of any identifier scheme that uses HTTP for\n> namespacing.\n\nThat was the primary idea of Published Subjects. Now I'm not sure it was not flawed from\nthe beginning, because identification always need \"identifying properties\" +\n\"identification context\". Topic maps provide clear identification context allowing to make\nunambiguous interpretation of HTTP URIs for subject identification. I'm not sure to which\ncontexts such an interpretation can be extended without ambiguity. Using HTTP namespace is\nnot a sufficient pre-condition, as endless debates on interpretation of URIs in RDF\nclearly shows. I agree with folks saying that the same URI can be interpreted in various\nways to identify different things in different identification contexts. So, to the\nquestion to know if HTTP URIS can be used without ambiguity as identifiers in SKOS, I\nwould answer that a pre-condition is to define what the identification context in a SKOS\napplication is or should be.\n\n> The things that I would like to see the TC consider is recommendations\n> for either embedding, linking to (e.g. using RDDL) or providing as\n> parallel resource (via content negotiation), other machine-readable\n> descriptions of the concept and related resource - so an RDF resource\n> would be one example, the same information translated into XTM might be\n> another and so on.\n\nBefore going in such technical details, the quoted above pre-condition has to be\nspecified.\n\n> It would be good to get the Published Subjects work kick started again\n> (the committee went quiet a long time ago) - perhaps we could work on\n> putting together a technical report to pass either to the OASIS TC or\n> just to publish as part of the SWAD work ?\n\nAs you are maybe not aware of, there are at least two reasons for quietness of PubSubj TC.\nOne is the lack of task force, the other is the lack of consensus on further deliverables.\nAnd the latter is linked to the issue discussed here, among others.\n\nBernard\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "cc- public-esw (this is relevant now to the thesaurus, and is relevant to the\nbest practices working group)\n\nOn Tue, 20 Apr 2004, Kal Ahmed wrote:\n\n>\n>On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n>> Miles, AJ (Alistair)  writes:\n>>\n>> > I wanted to consult you all on this matter.  I have agreement from\n>> > the EEA to publish the GEMET environmental thesaurus in the SKOS/RDF\n>> > format.  The next step is to work out with them the URIs they wish to\n>> > assign to their thesaurus and concepts.  I'm not sure what to\n>> > recommend to them on this matter.\n>>\n>> Dan Brickley's Wordnet vocabulary service[1] at xmlns.com seems like a\n>> useful model. Essentially, each concept is given a (non-fragmentary) URI\n>> which, if dereferenced, returns a description of the concept. Mr\n>> Brickley's system only returns RDF/XML presently, but there's no reason\n>> it couldn't also return HTML or something else via content negotiation.\n>>\n>> [1] http://xmlns.com/2001/08/wordnet/\n>>\n>> > I thought to use an http:// based URI base (e.g.\n>> > http://www.eionet.eu.int/GEMET) and then add the id number of each\n>> > concept (e.g. http://www.eionet.eu.int/GEMET#204).\n>>\n>> That works, but my preference would be for something like\n>> <http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID means\n>> that an HTTP request to a term's URI will return nothing or else a\n>> description of the entire vocabulary, which I'm guessing is pretty\n>> large.\n>>\n>I think that this practice would certainly work much better with\n>PSI/PSID constructs than the fragmentary approach - one resource per\n>concept is probably a best practice that the Published Subjects TC\n>should recommend.\n\nSomething I have done is use http://example.org/terms? as a namespace, so the\nURI resolves to a query (which says to cache it by good practice, since it\ndoesn't change anything to run the query) and since that means you can do\nsomething different for the \"bare URI\". Of course there is no reason not to\nconfigure foo#bar to return just the relevant RDF if that's the content-type\nrequested, but people don't.\n\nanother option is to have a URI per term, and to add #term (or something\nsimilar) in each case.\n\n>> > A first question is, is it OK to use http: URIs for concepts?\n\nYes, it seems like a good idea. The RDF specs even define that a URI with a\nfragment identifier in it refers to the RDF version in case of a\ncontent-negotiated resource, so presumably they expect that practice.\n\n>> It would be confusing for a URI to identify a thesaurus concept and an\n>> RDF file. The key, as I see it, is the idea that the response to an HTTP\n>> Get is a representation of the resource, not the resource itself. The\n>> fact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML\n>> document, doesn't mean that it identifies that particular document. If,\n>> for some reason, you wanted to talk about that RDF/XML document instead\n>> of the word \"Dog\", you would need to use a blank node or a different\n>> URI.\n\nthat's why I like using .../Dog#term\n\n>It is certainly true that content negotiation gives you the problem of\n>talking about the descriptive resource as opposed to the described\n>thing. That is a strong argument against content negotiation for RDF /\n>XTM resources. However, there are still two other options:\n\nThe solution to this problem is defined in the RDF specs, no? If you use\nDog#term then you are constrained to interpret it as whatever the RDF version\nof the resource tells you.\n\n>> > What do you think of info: based URIs for concepts?\n>>\n>> >From an RDF perspective, it's just as good. From a web perspective, it's\n>> less useful because it can't be dereferenced.\n>\n>I tend to agree.\n\nme too!\n\n(I love ending emails like that :-)\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "Charles McCathieNevile writes:\n\n> cc- public-esw (this is relevant now to the thesaurus, and is relevant\nto the\n> best practices working group)\n> \n> On Tue, 20 Apr 2004, Kal Ahmed wrote:\n> \n> >\n> >On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n> >>\n> >> That works, but my preference would be for something like\n> >> <http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID\n> >> means that an HTTP request to a term's URI will return nothing or\n> >> else a description of the entire vocabulary, which I'm guessing is\n> >> pretty large.\n> >>\n> >I think that this practice would certainly work much better with\n> >PSI/PSID constructs than the fragmentary approach - one resource per\n> >concept is probably a best practice that the Published Subjects TC\n> >should recommend.\n> \n> Something I have done is use http://example.org/terms? as a\n> namespace, so the URI resolves to a query (which says to cache it by\n> good practice, since it doesn't change anything to run the query) and\n> since that means you can do something different for the \"bare URI\".\n\nSure, from an RDF perspective, <http://example.org/term?204> is just as\ngood as <http://example.org/term/204>. I prefer the latter, because it\nfeels simpler and more flexible to me.\n\nIn practice, any decent web server would allow you to internally rewrite\n\"/term/204\" to \"/cgi/term?204\". \n\n> Of course there is no reason not to configure foo#bar to return just\n> the relevant RDF if that's the content-type requested, but people\n> don't.\n\nThe problem with using <http://example.org/foo#bar> is that an HTTP\nquery will have the form \"GET /foo\", not \"GET /foo#bar\". For a small\ndataset being served from a flat file, this is probably the best way to\ngo, but if there's any server-side scripting involved, it seems better\nto go with non-fragmented URIs.\n\n> >> It would be confusing for a URI to identify a thesaurus concept\n> >> and an RDF file. The key, as I see it, is the idea that the\n> >> response to an HTTP Get is a representation of the resource, not\n> >> the resource itself. The fact that\n> >> <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML document,\n> >> doesn't mean that it identifies that particular document. If, for\n> >> some reason, you wanted to talk about that RDF/XML document\n> >> instead of the word \"Dog\", you would need to use a blank node or a\n> >> different URI.\n> \n> that's why I like using .../Dog#term\n\nI'd rather do <http://xmlns.com/wordnet/1.6/Dog> for the concept and\n<http://xmlns.com/wordnet/1.6/Dog.rdf> for the RDF/XML document.\n\nTo be *really* unambiguous, you also have to consider the possibility of\nchanges over time. I've always felt that the best way to refer to an\nrepresentation retrieved via HTTP would be something like:\n\n  [ a Representation\n  ; source <http://xmlns.com/wordnet/1.6/Dog>\n  ; date \"2004-04-23T01:28:00Z\"\n  ]\n\nYou can also add properties like format, e-tag, last-modified, and the\ncontent (in base64 if necessary).\n\nAlternately, if I'm correct in thinking that HTTP lets you use\nContent-ID, you could identify specific representations using cid: URIs.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": "Tom:\n\nI agree that this comes down to interpretation, but I did actually count\nbefore I sent that  mail.  On the FOR list, I also included D P Kemp,\nPhillip M. Hallam-Baker, Dave Wagner, Tom Stephens and Baber Amin.\n\nWhatever:  the idea is \"rough\" consensus. You don't think we have it and\nI do.  In any case, I like Taher's suggestion about modularizing the\ndocument, submitting RFC's and getting running code.  What we want is a\nstandard that everybody wants to implement without lots of roll-your-own\nextensions.  \n\nBarb\nbfox@microsoft.com\n>----------\n>From: Tom Weinstein[SMTP:tomw@netscape.com]\n>Sent: Monday, October 07, 1996 2:47 PM\n>To: Barb Fox\n>Cc: 'Win Treese'; 'ietf-tls@w3.org'\n>Subject: Re: Closing on shared-key authentication\n>\n>Barb Fox wrote:\n>> \n>> Tom:\n>> \n>> Win is correct that the majority of people who posted on this topic\n>> were in favor.\n>\n>I believe that this is not true.  In pursuit of proof, I went back\n>through all of the messages on this topic and classified the opinions\n>of all of the people who posted.  Here's the results:\n>\n>For:\n>  Dan Simon  <dansimon@microsoft.com>\n>  Barbara Fox  <bfox@microsoft.com>\n>  Don Schmidt  <donsch@microsoft.com>\n>  Bennet Yee  <bsy@cs.ucsd.edu>\n>  John Macko  <jmacko@nisa.compuserve.com>\n>  Marc VanHeyningen  <marcvh@spry.com>\n>  Tim Dierks  <timd@consensus.com>\n>  Keith Ball  <Keith_Ball@novell.com>\n>\n>Against:\n>  Tom Weinstein  <tomw@netscape.com>\n>  Phil Karlton  <karlton@netscape.com>\n>  Jeff Weinstein  <jsw@netscape.com>\n>  Taher ElGamal  <elgamal@netscape.com>\n>  Steve Petri  <petri@litronic.com>\n>  Rohit Khare  <khare@pest.w3.org>\n>  Eric Murray  <ericm@lne.com>\n>  Christopher Allen  <ChristopherA@consensus.com>\n>  Peter Lipp  <plipp@iaik.tu-graz.ac.at>\n>\n>Note that a few people were somewhat vague as to what they felt, and I\n>primarily classified them based on who they were arguing with.  These\n>results may have no relation to how people really feel about this\n>proposal, but I think it's at least slightly more valuable than pulling\n>results out of thin air.\n>\n>In any case, I think it is very clear that there's not a clear consensus\n>on this issue.\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "Kal Ahmed writes:\n\n> On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n> > \n> > It would be confusing for a URI to identify a thesaurus concept and\n> > an RDF file. The key, as I see it, is the idea that the response to\n> > an HTTP Get is a representation of the resource, not the resource\n> > itself. The fact that <http://xmlns.com/wordnet/1.6/Dog> returns an\n> > RDF/XML document, doesn't mean that it identifies that particular\n> > document. If, for some reason, you wanted to talk about that\n> > RDF/XML document instead of the word \"Dog\", you would need to use a\n> > blank node or a different URI.\n> > \n> It is certainly true that content negotiation gives you the problem of\n> talking about the descriptive resource as opposed to the described\n> thing. That is a strong argument against content negotiation for RDF /\n> XTM resources.\n\nI've always felt content negotiation was more of an opportunity than a\nproblem. :-)\n\nIf I'm reading you right, in the case of\n<http://xmlns.com/wordnet/1.6/Dog>, the \"described thing\" is the class\n\"Dog\", and the \"descriptive resource\" is the RDF/XML document returned\nif you do an HTTP Get.\n\nThe REST view, as I understand it, is that the URI denotes the class\n\"Dog\". Since you can't actually transmit a class over the internet, any\nattempt to GET that URI will result in (1) a 404 or similar error, or\n(2) a representation of the class \"Dog\", which could be one of many\npossible electronic documents which is selected according to\nnegotiation. All of these representations are themselves distinct\nresources, even if they have no explicit URI (that is, they are blank\nnodes). Some versions of HTTP include a Content-Location header, which\ngives a URI for the particular representation being returned.\n\nIn that case, I would actually recommend content negotiation for RDF\nterms. If I put <http://xmlns.com/wordnet/1.6/Dog> into my web browser,\nI'd rather get a human-readable HTML document than a bunch of RDF. If my\nRDF software GETs the same URI, it should get an RDF document.\n\nIn both of those cases, the goal is to find information about the class\n\"Dog\". We don't care as much (or at all) about the representation which\nconveys that information.\n\n> > Not everyone agrees with this position.\n> > \n> I don't think that a position can ever be established which everyone \n> will agree with :-)\n\nI think we'd all agree to that. :-)\n-- \nDavid Menendez <zednenem@psualum.com> | \"In this house, we obey the laws\n<http://www.eyrie.org/~zednenem>      |        of thermodynamics!\"\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "I wrote:\n\n> Alternately, if I'm correct in thinking that HTTP lets you use\n> Content-ID, you could identify specific representations using cid:\n> URIs.\n\nMaybe something like this:\n\n    GET /term/Dog HTTP/1.1\n    Host: www.example.org\n    ...more fields...\n\n--\n\n    202 Found\n    Content-Type: application/rdf+xml\n    Content-ID: <12345@www.example.org>\n    ...more fields...\n    \n    <?xml version='1.0'?>\n    <rdf:RDF ...xmlns declarations...>\n      <rdfs:Class rdf:about=''>\n        <rdfs:label>Dog</rdfs:label>\n        <rdfs:subClassOf rdf:resource='Pet'/>\n      </rdfs:Class>\n      \n      <rdf:Description rdf:about='cid:12345@www.example.org'>\n        <dc:creator>Example.org</dc:creator>\n        <dc:date>2004-04-21T02:00:00Z</dc:date>\n      </rdf:Description>\n    </rdf:RDF>\n\nThis very clearly distinguishes the description of the resource\n<http://www.example.org/term/Dog> from the description of its\nrepresentation <cid:12345@www.example.org>. Plus, if example.org changes\nthe descripton of </term/Dog>, they have to generate a new content ID.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "David Menendez wrote:\n\n>Kal Ahmed writes:\n>\n>  \n>\n>>On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n>>    \n>>\n>>>It would be confusing for a URI to identify a thesaurus concept and\n>>>an RDF file. The key, as I see it, is the idea that the response to\n>>>an HTTP Get is a representation of the resource, not the resource\n>>>itself. The fact that <http://xmlns.com/wordnet/1.6/Dog> returns an\n>>>RDF/XML document, doesn't mean that it identifies that particular\n>>>document. If, for some reason, you wanted to talk about that\n>>>RDF/XML document instead of the word \"Dog\", you would need to use a\n>>>blank node or a different URI.\n>>>\n>>>      \n>>>\n>>It is certainly true that content negotiation gives you the problem of\n>>talking about the descriptive resource as opposed to the described\n>>thing. That is a strong argument against content negotiation for RDF /\n>>XTM resources.\n>>    \n>>\n>\n>I've always felt content negotiation was more of an opportunity than a\n>problem. :-)\n>\n>If I'm reading you right, in the case of\n><http://xmlns.com/wordnet/1.6/Dog>, the \"described thing\" is the class\n>\"Dog\", and the \"descriptive resource\" is the RDF/XML document returned\n>if you do an HTTP Get.\n>  \n>\nI would prefer to say that the described thing is the abstract concept \nof Dog (Dog-ness ?) because the word \"class\" can be misinterpreted as \nmeaning the OWL class Dog, for example. But I think you understood me \ncorrectly.\n\n>The REST view, as I understand it, is that the URI denotes the class\n>\"Dog\". Since you can't actually transmit a class over the internet, any\n>attempt to GET that URI will result in (1) a 404 or similar error, or\n>(2) a representation of the class \"Dog\", which could be one of many\n>possible electronic documents which is selected according to\n>negotiation. All of these representations are themselves distinct\n>resources, even if they have no explicit URI (that is, they are blank\n>nodes). Some versions of HTTP include a Content-Location header, which\n>gives a URI for the particular representation being returned.\n>\n>In that case, I would actually recommend content negotiation for RDF\n>terms. If I put <http://xmlns.com/wordnet/1.6/Dog> into my web browser,\n>I'd rather get a human-readable HTML document than a bunch of RDF. If my\n>RDF software GETs the same URI, it should get an RDF document.\n>\n>In both of those cases, the goal is to find information about the class\n>\"Dog\". We don't care as much (or at all) about the representation which\n>conveys that information.\n>  \n>\nIn principal I agree with you that this would be a good way to go, and \nit fits nicely with a RESTful view of the world and I think it fits well \nwith the distinction between resource and representation. However, I \nstruggle with how to annotate the RDF/XML resource - how do I say that \nthe author of this resource was John Smith ? In this case I am not \ninterested in finding out more about Dog-ness, but I want to know more \nabout this RDF description of Dog-ness - perhaps to establish whether or \nnot I trust the source of information.\n\nWhile writing this, a lightbulb went on and I think I now understand \nsomething I had missed in your previous posting.  In a prior email on \nthis thread, you suggested that a way to refer to a representation could be:\n\n[ a Representation\n  ; source <http://xmlns.com/wordnet/1.6/Dog>\n  ; date \"2004-04-23T01:28:00Z\"\n  ]\n\nSo I suggest that we might extend this model to include the \ncontent-negotiation parameters and then we can attach representation \nmetadata to the blank node.\n\nI need more coffee before I can write out the RDF/XML syntax for this, \nbut hopefully you can see what I'm getting at enough to tell me if we \nare on the same page or if I misunderstood.\n\nCheers,\n\nKal\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "As I don't have all the RDF/OWL etc. syntax rules at my fingertips I \ncan't comment on that part of the discussion, but I'd just like to slip \nin a mention of a long-standing issue, clarification of which might help \nunderstanding.\n\nWhen we are talking about a class or category of entities, such as \n\"dogs\", it is logical and clearer to use the plural form. Any definition \nor link is not to a specific dog, but to the attributes shared by all \nmembers of the class. A class may have sub-classes such as \"spaniels\" or \n\"poodles\", or specific instances such as \"Fido\", \"Rover\" or \"Laika\". It \nis important to be clear whether any URI is pointing to a category or to \na specific instance.\n\nThe convention of using the plural only applies to \"count-nouns\", to \nwhich the question \"how many\" is applicable. \"Non-count-nouns\", to which \n\"how much\" applies, like \"water\" or \"love\", are naturally expressed in \nthe singular form.\n\nLeonard Will\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "At 10:08 23/04/04 +0100, Kal Ahmed wrote:\n>I would prefer to say that the described thing is the abstract concept of \n>Dog (Dog-ness ?) because the word \"class\" can be misinterpreted as meaning \n>the OWL class Dog, for example. But I think you understood me correctly.\n\n[ref. \"dog-ness\"...]\n\nI'm reminded of a piece by Quine [1] - his base example is \"rabbit\", and he \ncomes up with terms like \"rabbithood\" and \"rabbiteth\" to illustrate the \nlinguistic challenges of determining what is indicated.\n\n#g\n--\n\n[1] W. V. Quine, \"Speaking of Objects\", in \"Ontological Relativity and \nOther Essays\"\n\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "geo exampl",
            "content": "http://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/ shows a \ntopic from open directory. I can imagine how this works in SKOS. And \nhow we might represent Bristol as a place in RDF. For discussion: how to \nrepresent (to machines) the connection between these two worlds.\n\nWe could easily redo the open directory (dmoz, see\nhttp://dmoz.org/rdf.html) \nin SKOS. And we can doubtless find some RDF representation of Bristol as\na member of a class \"City\", with location info, population, etc...\n\nMy hypothesis is that a new property in SKOS, skos:conceptualizes, \ncould be used to relate bristol-the-skos-concept to\nbristol-the-thing-in-the-world.\n\nAl, what do you reckon?\n\ndan\n\n\n\n"
        },
        {
            "subject": "RE: geo exampl",
            "content": "Dan\n\n> http://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/ shows a\n> topic from open directory.\n\nWould you call this resource a \"subject indicator\", to use topic maps dialect?\n\n> I can imagine how this works in SKOS. And\n> how we might represent Bristol as a place in RDF. For discussion: how to\n> represent (to machines) the connection between these two worlds.\n>\n> We could easily redo the open directory (dmoz, see\n> http://dmoz.org/rdf.html)\n> in SKOS.\n\nAs an on'n off ODP editor [1] I had proposed internally to have a look at integration of\nODP in the SW framework.\nNot with a great feedback, actually. Remember that RDF dump of dmoz uses an old RDF\nformat.\n\n> And we can doubtless find some RDF representation of Bristol as\n> a member of a class \"City\", with location info, population, etc...\n>\n> My hypothesis is that a new property in SKOS, skos:conceptualizes,\n> could be used to relate bristol-the-skos-concept to\n> bristol-the-thing-in-the-world.\n\n ... looks to me indeed very close to the notion of \"subjet indicator\".\n\nBernard\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n[1] http://dmoz.org/Reference/Knowledge_Management/Knowledge_Representation/\n\n\n\n"
        },
        {
            "subject": "Re: geo exampl",
            "content": "* Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-27 17:26+0200]\n> \n> Dan\n> \n> > http://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/ shows a\n> > topic from open directory.\n> \n> Would you call this resource a \"subject indicator\", to use topic maps dialect?\n\nI don't know enough about the detailed mysteries of topicmaps there, but \ncertainly this seems close. It is, colloqially, a subject or topic, \nthought of a thing-in-itself, and distinct from both the thing(s) that\ntopic represents, and from documents and data representing either the\ntopic or the, er, subject of the topic.\n\nI give up! this terminology is too overloaded to say anything ;)\n\nPut another way... the \"etc/England/Bristol/\" node in the DMoz topic\ngraph (and its equiv in SKOS) are things that represent \"the concept/idea of the\nplace Bristol\", rather than representing Bristol directly. There is an \nadditional level of indirection compared to 'raw' RDF (and OWL).\n\n\n> \n> > I can imagine how this works in SKOS. And\n> > how we might represent Bristol as a place in RDF. For discussion: how to\n> > represent (to machines) the connection between these two worlds.\n> >\n> > We could easily redo the open directory (dmoz, see\n> > http://dmoz.org/rdf.html)\n> > in SKOS.\n> \n> As an on'n off ODP editor [1] I had proposed internally to have a look at integration of\n> ODP in the SW framework.\n> Not with a great feedback, actually. Remember that RDF dump of dmoz uses an old RDF\n> format.\n\nYep, it is pretty scruffy, was backed by very early RDF code from Guha\nand friends when at Netscape/Mozilla. There are scripts around to,\nrather minimally, fix it up (namespace URIs, character encoding, etc).\nThose scripts could probably be adapted to emit SKOS rather easily. \n\n> > And we can doubtless find some RDF representation of Bristol as\n> > a member of a class \"City\", with location info, population, etc...\n> >\n> > My hypothesis is that a new property in SKOS, skos:conceptualizes,\n> > could be used to relate bristol-the-skos-concept to\n> > bristol-the-thing-in-the-world.\n> \n>  ... looks to me indeed very close to the notion of \"subjet indicator\".\n\nI suspect so too. Topicmap people have often said that RDF confuses\nthings with their representations. I believe RDF allows such modelling \nerrors to be made, but also that it allows perfect clarity. TMs, on my \nunderstanding, try to have more built-in facilities for preserving \nthose distinctions.\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: geo exampl",
            "content": "Dan\n\n> > > http://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/ shows a\n> > > topic from open directory.\n> >\n> > Would you call this resource a \"subject indicator\", to use topic maps dialect?\n>\n> I don't know enough about the detailed mysteries of topicmaps there, but\n> certainly this seems close. It is, colloqially, a subject or topic,\n> thought of a thing-in-itself, and distinct from both the thing(s) that\n> topic represents, and from documents and data representing either the\n> topic or the, er, subject of the topic.\n\n> I give up! this terminology is too overloaded to say anything ;)\n\nHmm ... trying to sort out terminology ... it's not that difficult, in fact :))\n\nLet's say you have somewhere a formal representation of a Class \"City\" and an instance of\nit \"Bristol\".\n\nThis can be expressed either in OWL-RDF ...\n\n<owl:Class rdf:ID=\"City\"/>\n<City rdf:ID=\"Bristol\"/>\n\n.. or in Topic Maps XTM\n\n<topic id=\"City>\n<topic id=\"Bristol\">\n<instanceOf>\n<topicRef xlink:href=\"#City\">\n</instanceOf>\n</topic>\n\nNow you want to say that the dmoz resource\nhttp://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/\nsomehow \"indicates\" what the above abstract entity formally \"represents\"\nIn XTM, this would be expressed by:\n\n<topic id=\"Bristol\">\n<instanceOf>\n<topicRef xlink:href=\"#City\">\n</instanceOf>\n<subjectIdentity>\n            <subjectIndicatorRef\nxlink:href=\"http://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/\"/>\n      </subjectIdentity>\n</topic>\n\nHow you would do it in OWL is not standard ...\n\n> Put another way... the \"etc/England/Bristol/\" node in the DMoz topic\n> graph (and its equiv in SKOS) are things that represent \"the concept/idea of the\n> place Bristol\", rather than representing Bristol directly. There is an\n> additional level of indirection compared to 'raw' RDF (and OWL).\n\nYes, that's exactly what the above XTM example expresses.\n\n> > > And we can doubtless find some RDF representation of Bristol as\n> > > a member of a class \"City\", with location info, population, etc...\n> > >\n> > > My hypothesis is that a new property in SKOS, skos:conceptualizes,\n> > > could be used to relate bristol-the-skos-concept to\n> > > bristol-the-thing-in-the-world.\n> >\n> >  ... looks to me indeed very close to the notion of \"subjet indicator\".\n>\n> I suspect so too. Topicmap people have often said that RDF confuses\n> things with their representations. I believe RDF allows such modelling\n> errors to be made, but also that it allows perfect clarity.\n\nAgreed. In fact there are too many different ways to express clearly any number of levels\nof indirection in RDF, but unfortunately no standard one. Hence the endless debates about\nURIs \"meaning\".\n\n> TMs, on my understanding, try to have more built-in facilities for preserving\n> those distinctions.\n\nYes. That does not mean everyone using Topic Maps understand them - let alone those who\nwon't even try to :))\n\nBottom line : what about \"skos:subjectIndicator\" to express what you suggest? For example:\n\n<skos:Concept rdf:about=\"http:/example.com/geo/Bristol\">\n<skos:inScheme rdf:resource=\"http:/example.com/geo/\"/>\n<skos:prefLabel>Bristol</skos:prefLabel>\n<skos:altLabel>City of Bristol</skos:altLabel>\n<skos:subjectIndicator\nrdf:resource=\"http://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/\"/>\n</skos:Concept>\n\nSay what?\n\nBernard\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n\n"
        },
        {
            "subject": "Re: geo exampl",
            "content": "Intriguing to notice (on the same page originally referneced) that the\nOpen Directory has at least 5 subtly different \"concept/ideas of the\nplace Bristol\" depending on whether the user approaches them via\nGloucestershire, South Gloucs, Somerset, etc. You can tell they are\ndifferent, because they have different numbers of postings. I suppose\nSKOS copes happily with representing them differently?\n\nNB, if you follow the traditional thesaurus model, the preferred term\n\"Bristol\" would be allowed to have only one meaning, and multiple access\nroutes would be permitted using a polyhierarchical structure.\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Dan Brickley\nSent: 27 April 2004 16:55\nTo: Bernard Vatant\nCc: public-esw-thes@w3.org\nSubject: Re: geo example\n\n\n\n* Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-27 17:26+0200]\n> \n> Dan\n> \n> > http://dmoz.org/Regional/Europe/United_Kingdom/England/Bristol/\n> > shows a topic from open directory.\n> \n> Would you call this resource a \"subject indicator\", to use topic maps\n> dialect?\n\nI don't know enough about the detailed mysteries of topicmaps there, but\n\ncertainly this seems close. It is, colloqially, a subject or topic, \nthought of a thing-in-itself, and distinct from both the thing(s) that\ntopic represents, and from documents and data representing either the\ntopic or the, er, subject of the topic.\n\nI give up! this terminology is too overloaded to say anything ;)\n\nPut another way... the \"etc/England/Bristol/\" node in the DMoz topic\ngraph (and its equiv in SKOS) are things that represent \"the\nconcept/idea of the place Bristol\", rather than representing Bristol\ndirectly. There is an \nadditional level of indirection compared to 'raw' RDF (and OWL).\n\n\n> \n> > I can imagine how this works in SKOS. And\n> > how we might represent Bristol as a place in RDF. For discussion:\n> > how to represent (to machines) the connection between these two \n> > worlds.\n> >\n> > We could easily redo the open directory (dmoz, see\n> > http://dmoz.org/rdf.html)\n> > in SKOS.\n> \n> As an on'n off ODP editor [1] I had proposed internally to have a look\n> at integration of ODP in the SW framework. Not with a great feedback, \n> actually. Remember that RDF dump of dmoz uses an old RDF format.\n\nYep, it is pretty scruffy, was backed by very early RDF code from Guha\nand friends when at Netscape/Mozilla. There are scripts around to,\nrather minimally, fix it up (namespace URIs, character encoding, etc).\nThose scripts could probably be adapted to emit SKOS rather easily. \n\n> > And we can doubtless find some RDF representation of Bristol as a\n> > member of a class \"City\", with location info, population, etc...\n> >\n> > My hypothesis is that a new property in SKOS, skos:conceptualizes,\n> > could be used to relate bristol-the-skos-concept to \n> > bristol-the-thing-in-the-world.\n> \n>  ... looks to me indeed very close to the notion of \"subjet\n> indicator\".\n\nI suspect so too. Topicmap people have often said that RDF confuses\nthings with their representations. I believe RDF allows such modelling \nerrors to be made, but also that it allows perfect clarity. TMs, on my \nunderstanding, try to have more built-in facilities for preserving \nthose distinctions.\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "fwd Re: I seek for a tool to retrieve UML",
            "content": "Forwarded from the UMLS list, discussion relevant to \nSKOS web service APIs...\n\ncheers,\n\nDan\n\n\nattached mail follows:\nWith UMLS locally installed , I use :\n- MetaMap (http://mmtx.nlm.nih.gov/)\n- UMLSDB.java \n(http://www.cra.org/Activities/craw/dmp/awards/2001/groce/finalreport.html)\n- concerning UMLS-Query (http://umls-query.sourceforge.net/), you can \ncontact the author (Jason Michelizzi mich0212 (at) d (dot) umn (dot) edu) \nand ask him.\ninfact, his web page has been updated very recently.\n\nThere are however also several other attempts for Java UMLS query \ninterface:\nhttp://www.cbcu.cam.ac.uk/cbcu/cbcu_soft/-444676866.htm\n...\n\nregards \nLuca\n\n\n\n\n\n\"Mustapha Baziz\" <baziz@irit.fr>\nSent by: bounce-umls-users-35@umlsinfo.nlm.nih.gov\n28.04.2004 09:48\nPlease respond to \"Mustapha Baziz\"\n\n \n        To:     \"UMLS users mailing list\" <umls-users@umlsinfo.nlm.nih.gov>\n        cc: \n        Subject:        I seek for a tool to retrieve UMLS\n\n\nHello,\nI am working in Information Retrieval applied to medical field and I seek\nfor some tool to question UMLS. I found UMLS-Query in source-forge, but \nthis\nproject is broken and the tool is not finalised (pre-alpha version).\n\nThank you very much for helping me\nM. Baziz\n\n\n\n---\nYou are currently subscribed to umls-users as: LUCA.TOLDO@MERCK.DE\nTo unsubscribe send a blank email to \nleave-umls-users-65K@umlsinfo.nlm.nih.gov\n\n\n\n\n\n\n---\nYou are currently subscribed to umls-users as: DANIEL.BRICKLEY@BRISTOL.AC.UK\nTo unsubscribe send a blank email to leave-umls-users-65K@umlsinfo.nlm.nih.gov\n\n\n\n"
        },
        {
            "subject": "Announcement of SWADEurope SKOS API for thesauri web servic",
            "content": "   SWAD-Europe Simple Knowledge Organisation System (SKOS) API\n       Web Service API for a thesaurus service\n\n     http://www.w3.org/2001/sw/Europe/reports/thes/skosapi.html\n\nWe are pleased to announce the initial release of the SKOS API\ndeveloped by the SWAD-Europe[1] project thesaurus activity[2]\nan EU IST-7 funded project.\n\nThe SKOS API defines a web service providing a core set of methods\nfor accessing and querying a thesaurus or terminological resource\nbased on the SKOS-Core schema, as described in the SKOS-Core Guide[3].\n\nThis is an initial release which we expect will evolve in response to\ninput from the wider community.  Our goal is to contribute to the\ndevelopment of a web service API that will be suitable for widespread\nadoption, which in turn will promote ease of interoperability and\nre-use of information systems that exploit thesauri and/or other\nkinds of terminological resource.\n\nWe ask at this stage for initial feedback from web service\ndevelopers, systems designers and KOS experts looking to expose or\naccess this kind of functionality\n\nIn particular, we have the following open issues, in no particular\norder (some of these are from the 'scratch pad' ServiceBits class[4] )\n\n- How much information to return in Concept fields versus API calls.\n- In our implementation, should we use the SOAP encoding model or\n  literal RDF/XML (for example) to represent concepts and\n  relations. Or both.\n- Try to use xsd:anyURI instead of a separate URI class\n- Versioning of the interface, do we add a getVersion() method.\n- Should we provide access to RDF query support where available (like\nJoseki)\n- A REST API would be good to have especially as this is a\n  non-side effecting API, so HTTP GET operations would be safe.\n- Returning values as singletons compared to arrays of size 1\n- What fields of concepts should regexe searches match.\n- Method doubling for thesaurus parameters versus allowing Null values\n  (we are aware WS-I Basic Profile recommends against method\n  overloading, so we avoid that)\n\nA demonstration implementation of using this web service API is\ncurrently under development which will host several thesauri in the\nSKOS schema[5] and provide a public web service.\n\nPlease direct all feedback to the public mailing list:\npublic-esw-thes@w3.org list, more details are available at [6].\n\nAlistair Miles\nNikki Rogers\nDave Beckett\n\n\n[1] http://www.w3.org/2001/sw/Europe/\n[2] http://www.w3.org/2001/sw/Europe/reports/thes/\n[3] http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n[4] http://www.w3.org/2001/sw/Europe/reports/thes/api/docs/\n[5] http://www.w3.org/2004/02/skos/core\n[6] http://lists.w3.org/Archives/Public/public-esw-thes/\n\n\n\n"
        },
        {
            "subject": "URI policy for thesaurus concept",
            "content": "On the basis of the previous discussion on URIs for concepts, I'm going to\noffer the recommendation to thesaurus owners that they use http: based uris\nwithout fragment identifiers as URIs for their concepts.\n\nSo for example:\n\nGEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n\nGEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]   \n\nReason for going with http: based URIs is it seems generally agreed that it\nis desirable to have the concept URIs directly resolving to something.\n\nReason for going with / and not # is so that the concept ID is included in\nan http GET request and not lost as it would be if it came after a #.\n\nI.e. decision based on purely practical considerations.\n\nAnybody want to shoot this down before I approach GEMET (& others) with\nthis?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-04-30 16:08+0100]\n> \n> On the basis of the previous discussion on URIs for concepts, I'm going to\n> offer the recommendation to thesaurus owners that they use http: based uris\n> without fragment identifiers as URIs for their concepts.\n> \n> So for example:\n> \n> GEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n> \n> GEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]   \n> \n> Reason for going with http: based URIs is it seems generally agreed that it\n> is desirable to have the concept URIs directly resolving to something.\n> \n> Reason for going with / and not # is so that the concept ID is included in\n> an http GET request and not lost as it would be if it came after a #.\n> \n> I.e. decision based on purely practical considerations.\n> \n> Anybody want to shoot this down before I approach GEMET (& others) with\n> this?\n\nI prefer the / approach, but I should warn that TimBL and others have\nmade the claim that http://blah/ URIs without a # can only name\n'documents' or 'networked information resources', and that concepts,\nclasses, properties etc don't count as those.\n\nSo, if you do advice thesaurus folks one way or the other, try to make\nclear that this aspect of web architecture is still under discussion.\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "On Fri, 30 Apr 2004, Miles, AJ (Alistair)  wrote:\n\n> On the basis of the previous discussion on URIs for concepts, I'm going to\n> offer the recommendation to thesaurus owners that they use http: based uris\n> without fragment identifiers as URIs for their concepts.\n>\n> So for example:\n>\n> GEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n>\n> GEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]\n>\n> Reason for going with http: based URIs is it seems generally agreed that it\n> is desirable to have the concept URIs directly resolving to something.\n>\n> Reason for going with / and not # is so that the concept ID is included in\n> an http GET request and not lost as it would be if it came after a #.\n>\n> I.e. decision based on purely practical considerations.\n>\n> Anybody want to shoot this down before I approach GEMET (& others) with\n> this?\n\nPersonally I like this approach. The recent TAG document endorses a REST\nview; so basically you're saying that\n\nhttp://www.eionet.eu.int/GEMET/[version]\n\n\"names\" the thesaurus, and\n\nhttp://www.eionet.eu.int/GEMET/[version]/[conceptID]\n\n\"names\" the particular concept. That's fine - I ought to be able to ask\n(via content negotiation) for a representation of a concept (or a\nthesaurus) by an HTTP request for each of those URIs. What advice are\nyou offering on the stuff that's found at the end of those URIs?\n\nIt'd be reasonable to generate (for instance) RDF describing an\nindividual concept (that perhaps links it to related concepts) but it's\nnot immediately clear to me what content might live at the \"whole\nthesaurus\" URI. Perhaps the whole thesaurus? Or a document with RDDL\ncontent that points to related web services, etc..?\n\n\n\n\n-- \njan grant, ILRT, University of Bristol. http://www.ilrt.bris.ac.uk/\nTel +44(0)117 9287088 Fax +44 (0)117 9287112 http://ioctl.org/jan/\n( echo \"ouroboros\"; cat ) > /dev/fd/0 # it's like talking to yourself sometimes\n\n\n\n"
        },
        {
            "subject": "RE: URI policy for thesaurus concept",
            "content": "To go along with Dan ...\n\nI also prefer the / approach in principle because it defines more neatly the \"subject\nindicator\", but consider that e.g. OWL uses fragment identifiers to define classes and\nproperties ...\n\nWill not people be confused with OWL elements defined by\nhttp://example.org/myontology#class001\nand SKOS concepts defined by http://example.org/myskos/concept001\n\nWhat about namespace management?\n\nAnd having, e.g. for GEMET, over 8000 different resources/concepts, if you just want to\ndownload the whole stuff, hmm...\nIs not it more simple to have a / namespace for a whole SKOS scheme, and # for each\nconcept in it?\n\nWe've been through this in Published Subjects TC, without clear conclusion ...\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n> -----Message d'origine-----\n> De : public-esw-request@w3.org [mailto:public-esw-request@w3.org]De la\n> part de Dan Brickley\n> Envoye : vendredi 30 avril 2004 17:19\n> A : Miles, AJ (Alistair)\n> Cc : 'public-esw-thes@w3.org'; 'public-esw@w3.org'\n> Objet : Re: URI policy for thesaurus concepts\n>\n>\n>\n> * Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-04-30 16:08+0100]\n> >\n> > On the basis of the previous discussion on URIs for concepts, I'm going to\n> > offer the recommendation to thesaurus owners that they use http: based uris\n> > without fragment identifiers as URIs for their concepts.\n> >\n> > So for example:\n> >\n> > GEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n> >\n> > GEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]\n> >\n> > Reason for going with http: based URIs is it seems generally agreed that it\n> > is desirable to have the concept URIs directly resolving to something.\n> >\n> > Reason for going with / and not # is so that the concept ID is included in\n> > an http GET request and not lost as it would be if it came after a #.\n> >\n> > I.e. decision based on purely practical considerations.\n> >\n> > Anybody want to shoot this down before I approach GEMET (& others) with\n> > this?\n>\n> I prefer the / approach, but I should warn that TimBL and others have\n> made the claim that http://blah/ URIs without a # can only name\n> 'documents' or 'networked information resources', and that concepts,\n> classes, properties etc don't count as those.\n>\n> So, if you do advice thesaurus folks one way or the other, try to make\n> clear that this aspect of web architecture is still under discussion.\n>\n> Dan\n>\n\n\n\n"
        },
        {
            "subject": "RE: URI policy for thesaurus concept",
            "content": "> Personally I like this approach. The recent TAG document \n> endorses a REST\n> view; so basically you're saying that\n> \n> http://www.eionet.eu.int/GEMET/[version]\n> \n> \"names\" the thesaurus, and\n> \n> http://www.eionet.eu.int/GEMET/[version]/[conceptID]\n> \n> \"names\" the particular concept. That's fine - I ought to be \n> able to ask\n> (via content negotiation) for a representation of a concept (or a\n> thesaurus) by an HTTP request for each of those URIs. What advice are\n> you offering on the stuff that's found at the end of those URIs?\n\nThat's a whole other ball game.  As I understand it, the choice is between\nthe HTTP GET request for the concept URI returning either a machine readable\nor a human readable description of that concept.  I may have boiled that\ndown too much - have I missed anything?      \n\n> \n> It'd be reasonable to generate (for instance) RDF describing an\n> individual concept (that perhaps links it to related \n> concepts) but it's\n> not immediately clear to me what content might live at the \"whole\n> thesaurus\" URI. Perhaps the whole thesaurus? Or a document with RDDL\n> content that points to related web services, etc..?\n> \n\nOne thing a GET request for the thesaurus URI should definitely return is a\ndescription of that thesaurus (i.e. name, version, creators, description of\nscope and content etc.) although again whether that should be machine or\nhuman readable is open.  \n\nThe other question is, should the request for the thesaurus URI also return\nthe entire content of the thesaurus?  Personally I think no, but again I'm\nnot sure about that.\n\nAl.  \n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Barb Fox wrote:\n> \n> Tom:\n> \n> I agree that this comes down to interpretation, but I did actually\n> count before I sent that  mail.  On the FOR list, I also included D P\n> Kemp, Phillip M. Hallam-Baker, Dave Wagner, Tom Stephens and Baber\n> Amin.\n>\n> Whatever:  the idea is \"rough\" consensus. You don't think we have it\n> and I do.  In any case, I like Taher's suggestion about modularizing\n> the document, submitting RFC's and getting running code.  What we want\n> is a standard that everybody wants to implement without lots of\n> roll-your-own extensions.\n\nHmm, I'll grant you Tom Stephens, Phil Hallam-Baker and Baber Amin.  I\nthink David Kemp and Dave Wagner were on the fence more than they were\nfor either side.  I'd also add Paul Kocher and Peter Williams on the\nagainst side.\n\nIn any case, when people are split approximately equally, I'd say that\ndoesn't constitute a rough consensus.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-04-30 16:37+0100]\n> \n> One thing a GET request for the thesaurus URI should definitely return is a\n> description of that thesaurus (i.e. name, version, creators, description of\n> scope and content etc.) although again whether that should be machine or\n> human readable is open.  \n> \n> The other question is, should the request for the thesaurus URI also return\n> the entire content of the thesaurus?  Personally I think no, but again I'm\n> not sure about that.\n\nLots of thesaurus owners might not like that. Lots of sysadmins might\nnot like that. In some cases it might be possible, but 'should' is imho\ntoo strong a claim...\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Why not simply follow Xlink/CPointer in this question?\n\nThe GET request Alistair has been talking about is a conforming solution.\nExample\nhttp://blah?concept=666\n\nThomas Bandholtz\nSemantic Web Consultant\nKarl-Friedrich-Schinkelstr. 2\n53127 Bonn\nGermany\nwww.bandholtz.info\n\n+49 228  9288490\ncell +49 179 4700576\nthomas@bandholtz.info\n\n\n----- Original Message ----- \nFrom: \"Dan Brickley\" <danbri@w3.org>\nTo: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nCc: <public-esw-thes@w3.org>; <public-esw@w3.org>\nSent: Friday, April 30, 2004 5:18 PM\nSubject: Re: URI policy for thesaurus concepts\n\n\nAlistair: > > Reason for going with / and not # is so that the concept ID is\nincluded in\n> > an http GET request and not lost as it would be if it came after a #.\n\nDan: > I prefer the / approach, but I should warn that TimBL and others have\n> made the claim that http://blah/ URIs without a # can only name\n> 'documents' or 'networked information resources', and that concepts,\n> classes, properties etc don't count as those.\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-30 17:36+0200]\n> \n> To go along with Dan ...\n> \n> I also prefer the / approach in principle because it defines more neatly the \"subject\n> indicator\", but consider that e.g. OWL uses fragment identifiers to define classes and\n> properties ...\n> \n> Will not people be confused with OWL elements defined by\n> http://example.org/myontology#class001\n> and SKOS concepts defined by http://example.org/myskos/concept001\n\nSome RDF/RDFS/OWL vocabs end in a / and others end in a # and others do\nother things. This is the current state of affairs. The confusion is\nonly a problem because these different approaches have different\ntechnical and standards characteristics (and those aren't well\nexplained, currently).\n\n> What about namespace management?\n\nAn important but relatively independent problem, I think.\n\n> And having, e.g. for GEMET, over 8000 different resources/concepts, if you just want to\n> download the whole stuff, hmm...\n> Is not it more simple to have a / namespace for a whole SKOS scheme, and # for each\n> concept in it?\n> \n> We've been through this in Published Subjects TC, without clear conclusion ...\n\nI've a few years experience using the http://xmlns.com/wordnet/1.6/Cat\netc approach, and have to say it is useful. The ability to return a\nuseful chunk of information from a larger dataset is something I am\nreluctant to give up. Surely in the future we'll have richer (SKOS API,\nRDF DAWG etc) interfaces to these datasets, but the current approach can\nbe implemented with a simple filetree or CGI script, and has proved\nreasonably popular.\n\nDan\n\n\n\n"
        },
        {
            "subject": "AW: URI policy for thesaurus concept",
            "content": "I agree also to using http:// uris and / as delimiter.\nYes, I used some wordnet terms and it seems they work\n\nPerhaps Patrick Stickler will also like it to use http:// and / to\nidentify concepts, his URIQA should work with it.\n\ncheers\nLeo\n\n> * Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-30 17:36+0200]\n> > \n> > To go along with Dan ...\n> > \n> > I also prefer the / approach in principle because it defines more \n> > neatly the \"subject indicator\", but consider that e.g. OWL uses \n> > fragment identifiers to define classes and properties ...\n> > \n> > Will not people be confused with OWL elements defined by \n> > http://example.org/myontology#class001\n> > and SKOS concepts defined by http://example.org/myskos/concept001\n> \n> Some RDF/RDFS/OWL vocabs end in a / and others end in a # and \n> others do other things. This is the current state of affairs. \n> The confusion is only a problem because these different \n> approaches have different technical and standards \n> characteristics (and those aren't well explained, currently).\n> \n> > What about namespace management?\n> \n> An important but relatively independent problem, I think.\n> \n> > And having, e.g. for GEMET, over 8000 different \n> resources/concepts, if \n> > you just want to download the whole stuff, hmm... Is not it more \n> > simple to have a / namespace for a whole SKOS scheme, and # \n> for each \n> > concept in it?\n> > \n> > We've been through this in Published Subjects TC, without clear \n> > conclusion ...\n> \n> I've a few years experience using the \n> http://xmlns.com/wordnet/1.6/Cat etc approach, > and have to \n> say it is useful. The ability to return a useful chunk of \n> information from a larger dataset is something I am reluctant \n> to give up. Surely in the future we'll have richer (SKOS API, \n> RDF DAWG etc) interfaces to these datasets, but the current \n> approach can be implemented with a simple filetree or CGI \n> script, and has proved reasonably popular.\n> \n> Dan\n> \n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Alistair > One thing a GET request for the thesaurus URI should definitely\nreturn is a\n> description of that thesaurus (i.e. name, version, creators, description\nof\n> scope and content etc.) although again whether that should be machine or\n> human readable is open.\n\nObviously *both* must be possible.We had megabytes of discussion on this in\nthe Topic Map community and elsewhere.\nThe answer is very simple - there are humans, and there are machines\n(software agents).\nA service may decide to serve only one of them, but she may decide to serve\nboth.\nShe may even decide to serve several machine protocols or several human\nreadable layouts.\nThe consequence is that a singe URL is not enough.\nWe need pairs of protocol-URL such as\n\nHTML -> http://human.blah.org/thesaurus.html\nWSDL -> http://services.blah.org/thesaurus.wsdl\nDCMI -> http://dcmi.blah.org/thesaurus.xml\netc., etc.,\n\nthese must be explictly *pairs* (protocol -> URL) as the domain name must\nnot contain any significant meaning itself (see RFC URI)\n\nAlistair > The other question is, should the request for the thesaurus URI\nalso return\n> the entire content of the thesaurus?  Personally I think no, but again I'm\n> not sure about that.\n\nIt never should by default!! A well established thesaurus easily counts\n100.000s and more concepts! The requester (be it human or machine) must be\nable to identify the thesaurus source without downloading the whole thing.\n\nI my personal vision, the \"whole thing\" *never* will be downloaded at once:\navoid redunancy, and what the hell are we doing here? ---\nWe are establish means to *link to specific* concepts and make clear where\nthe come from.\n\nDownloading and so duplicating a thesaurus is OK in some situations, but\nthis should be regarded as a very special use case.\n\nThomas\n\n\n\n"
        },
        {
            "subject": "RE: URI policy for thesaurus concept",
            "content": "Miles, AJ (Alistair)  writes:\n\n> > That's fine - I ought to be able to ask (via content negotiation)\n> > for a representation of a concept (or a thesaurus) by an HTTP\n> > request for each of those URIs. What advice are you offering on the\n> > stuff that's found at the end of those URIs?\n> \n> That's a whole other ball game.  As I understand it, the choice is\n> between the HTTP GET request for the concept URI returning either a\n> machine readable or a human readable description of that concept.  I\n> may have boiled that down too much - have I missed anything?      \n\nWith content negotiation, you can do both: requests asking for HTML get\nHTML, and requests asking for RDF/XML get RDF/XML. (The rare case where\nthe request states no preference is probably someone using \"curl\" or\n\"wget\"; I'm guessing they'd want RDF/XML, but there's no real negative\nconsequence to choosing either way.)\n\nIt's even possible to do content negotiation when serving static files,\nthanks to mod_content and equivalents.\n\n> The other question is, should the request for the thesaurus URI also\n> return the entire content of the thesaurus?  Personally I think no,\n> but again I'm not sure about that.\n\nI'd have a description of the thesaurus at its base URI (again, in both\nHTML and RDF via content negotiation), and put the whole content at a\nseparate URI if desired.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Date: Mon, 07 Oct 1996 14:47:02 -0700\nFrom: Tom Weinstein <tomw@netscape.com>\n\n> Barb Fox wrote:\n> >\n> > Tom:\n> >\n> > Win is correct that the majority of people who posted on this topic\n> > were in favor.\n>\n> I believe that this is not true.  In pursuit of proof, I went\n> back through all of the messages on this topic and\n> classified the opinions of all of the people who posted.\n> Here's the results:\n>\n>\n> For:\n>   Dan Simon  <dansimon@microsoft.com>\n>   Barbara Fox  <bfox@microsoft.com>\n>   Don Schmidt  <donsch@microsoft.com>\n>   Bennet Yee  <bsy@cs.ucsd.edu>\n>   John Macko  <jmacko@nisa.compuserve.com>\n>   Marc VanHeyningen  <marcvh@spry.com>\n>   Tim Dierks  <timd@consensus.com>\n>   Keith Ball  <Keith_Ball@novell.com>\n>\n\nAdd dennis.glatting@CyberSafe.com to the \"for\" list.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "SWAD Deliverable 8.4  last comments before EU submissio",
            "content": "http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n\n\nAlistair Miles\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "namespace for SKOSCore version 1.",
            "content": "I'm polishing up SKOS-Core for a major release (version 1.0).  The namespace\nI used for the pre-release version was \n\nhttp://www.w3c.rl.ac.uk/2003/11/21-skos-core#\n\nWhat do you think we should use for the new version?  \n\nAl.\n\n\nAlistair Miles\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Putting stuff uncer CVS we can all acces",
            "content": "Hi guys,\n\nDave B says why don't we put the deliverables and the schemas for WP8 under\na CVS server we can all access.  I say fine, what do we have to do to make\nthis happen?\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Proposal for SKOSCore 1.",
            "content": "Hi guys,\n\nMy proposal for the SKOS-Core 1.0 schema:\n\nhttp://www.w3c.rl.ac.uk/SWAD/rdf/skos_core_1_0.rdf\n\nChanges I suggest from pre-release version (online at\nhttp://www.w3c.rl.ac.uk/SWAD/rdf/skos_0_1.rdf):\n\n1.  Get rid of <soks:descriptor> property\n\n2.  Get rid of <soks:generalNote> <soks:historyNote> <soks:editorNote>\n<soks:hierarchyNote>.  Re-introduce them later if a real need is reported.\n\n3.  Introduce <soks:definition> <soks:example> as further ways fo descibing\na concept (less thesaurus-centric)\n\nOtherwise the same.\n\nAlso we have to decide on a base namespace for this schema.\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Putting stuff uncer CVS we can all acces",
            "content": "couple of options:\n\n1) danbri/other sorts you out with permissions & connection details for w3c \ncvs server - (you need to generate public/private key pair and give dan \nyour public key etc. Then you check the files in a suitable directory (e.g. \nsee http://www.w3.org/2001/sw/Europe/reports/)\n\n2) I or Dave, who have access to the cvs server, can check the files in for \nyou. Am happy to do this, but you might prefer 1) because you get control \nover what goes where on an ongoing basis,\n\nlet me know if you need any help,\nNikki\n\n\n--On Wednesday, February 04, 2004 16:29:26 +0000 \"Miles, AJ (Alistair) \" \n<A.J.Miles@rl.ac.uk> wrote:\n\n>\n> Hi guys,\n>\n> Dave B says why don't we put the deliverables and the schemas for WP8\n> under a CVS server we can all access.  I say fine, what do we have to do\n> to make this happen?\n>\n> Al.\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Extending SKOSCore with OW",
            "content": "This is an attempt at a list of features we could add by extending SKOS-Core\nwith OWL.\n\n1.  <soks:related> is symmetric.\n\n2.  <soks:broader> is transitive.\n\n3.  <soks:narrower> is transitive.\n\n4.  <soks:broader> and <soks:narrower> are each other's inverse.\n\n5.  A resource typed as a <soks:Concept> may have at most one value for\n<soks:prefLabel>\n\n6.  <soks:broaderGeneric> and <soks:narrowerGeneric> are each other's\ninverse.\n\n7.  <soks:broaderInstantive> and <soks:narrowerInstantive> are each other's\ninverse.\n\n8.  <soks:broaderPartitive> and <soks:narrowerPartitive> are each other's\ninverse.\n\n9.  <soks:inFacet> and <soks:facetMember> are each other's inverse.\n\n10.  A resource typed as a <soks:Concept> may have at most one value for\n<soks:inFacet>\n\nCan't think of any more for the moment.\n\n  \n\nCouple of general OWL questions:\n\n1.  If a property is declared as an owl:TransitiveProperty, will all\nsub-properties also be transitive?\n\n2.  If a property is declared as an owl:SymmetricProperty, will all\nsub-properties also be symmetric?\n\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: Proposal for SKOSCore 1.",
            "content": "Just to say, I open every part of this schema to discussion, the structure,\nthe IDs for the classes and props, the labels, the comments, everything.\n\nAl.\n\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> Sent: 04 February 2004 16:46\n> To: Dave Beckett (E-mail); Nikki Rogers (E-mail)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: Proposal for SKOS-Core 1.0\n> \n> \n> \n> Hi guys,\n> \n> My proposal for the SKOS-Core 1.0 schema:\n> \n> http://www.w3c.rl.ac.uk/SWAD/rdf/skos_core_1_0.rdf\n> \n> Changes I suggest from pre-release version (online at\n> http://www.w3c.rl.ac.uk/SWAD/rdf/skos_0_1.rdf):\n> \n> 1.  Get rid of <soks:descriptor> property\n> \n> 2.  Get rid of <soks:generalNote> <soks:historyNote> <soks:editorNote>\n> <soks:hierarchyNote>.  Re-introduce them later if a real need \n> is reported.\n> \n> 3.  Introduce <soks:definition> <soks:example> as further \n> ways fo descibing\n> a concept (less thesaurus-centric)\n> \n> Otherwise the same.\n> \n> Also we have to decide on a base namespace for this schema.\n> \n> Al.\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: Putting stuff uncer CVS we can all acces",
            "content": "On Wed, 4 Feb 2004, NJ Rogers, Learning and Research Technology wrote:\n\n[how to get the thing onto the W3C CVS server]\n\nAnd just to tidy up, please don't forget to put HTTP redirects at the\noriginal places so the URIs don't die...\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Re: Proposal for SKOSCore 1.",
            "content": "Yep, these all look good to me...\n\nI think it is reasonably useful to have the namespace be where the schema is\n(in the absence of any better format to have there, it means people can try\nand find out what the terms are).\n\nIt would also be nice to have more commentary in the schema - using\nrdfs:comment instead of XML comments, for example...\n\ncheers\n\nChaals\n\nOn Wed, 4 Feb 2004, Miles, AJ (Alistair)  wrote:\n\n>My proposal for the SKOS-Core 1.0 schema:\n>\n>http://www.w3c.rl.ac.uk/SWAD/rdf/skos_core_1_0.rdf\n>\n>Changes I suggest from pre-release version (online at\n>http://www.w3c.rl.ac.uk/SWAD/rdf/skos_0_1.rdf):\n>\n>1.  Get rid of <soks:descriptor> property\n>\n>2.  Get rid of <soks:generalNote> <soks:historyNote> <soks:editorNote>\n><soks:hierarchyNote>.  Re-introduce them later if a real need is reported.\n>\n>3.  Introduce <soks:definition> <soks:example> as further ways fo descibing\n>a concept (less thesaurus-centric)\n>\n\n\n\n"
        },
        {
            "subject": "Re: Extending SKOSCore with OW",
            "content": "I'm not sure about this one:\n\n>5.  A resource typed as a <soks:Concept> may have at most one value for\n><soks:prefLabel>\n>\n\ndifferent facets might have different preferred labels (the obvious problem).\nI am not sure if you can account for that in OWL, although I would have\nthought you can.\n\nBut a single Concept might have a couple of preferred labels too. I am\nthinking of use cases that guess which Concept is being referred to, and\nbeing a preferred label is an obvious way to rank possible choices. Also, in\nmerging two thesauri, is there really a need to choose a single preferred\nterm, given that the RDF key to the meaning is the concept?\n\nThe others all make sense to me.\n\nCheers\n\nChaals\n\nOn Wed, 4 Feb 2004, Miles, AJ (Alistair)  wrote:\n\n>\n>This is an attempt at a list of features we could add by extending SKOS-Core\n>with OWL.\n>\n>1.  <soks:related> is symmetric.\n>\n>2.  <soks:broader> is transitive.\n>\n>3.  <soks:narrower> is transitive.\n>\n>4.  <soks:broader> and <soks:narrower> are each other's inverse.\n>\n>6.  <soks:broaderGeneric> and <soks:narrowerGeneric> are each other's\n>inverse.\n>\n>7.  <soks:broaderInstantive> and <soks:narrowerInstantive> are each other's\n>inverse.\n>\n>8.  <soks:broaderPartitive> and <soks:narrowerPartitive> are each other's\n>inverse.\n>\n>9.  <soks:inFacet> and <soks:facetMember> are each other's inverse.\n>\n>10.  A resource typed as a <soks:Concept> may have at most one value for\n><soks:inFacet>\n>\n>Can't think of any more for the moment.\n>\n>\n>\n>Couple of general OWL questions:\n>\n>1.  If a property is declared as an owl:TransitiveProperty, will all\n>sub-properties also be transitive?\n>\n>2.  If a property is declared as an owl:SymmetricProperty, will all\n>sub-properties also be symmetric?\n>\n>\n>Al.\n>\n>CCLRC - Rutherford Appleton Laboratory\n>Building R1 Room 1.60\n>Fermi Avenue\n>Chilton\n>Didcot\n>Oxfordshire OX11 0QX\n>United Kingdom\n>\n>Email:        a.j.miles@rl.ac.uk\n>Telephone: +44 (0)1235 445440\n>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Extending SKOSCore with OW",
            "content": "Hi Alistair,\n\n> Couple of general OWL questions:\n> \n> 1.  If a property is declared as an owl:TransitiveProperty, will all\n> sub-properties also be transitive?\n> \n> 2.  If a property is declared as an owl:SymmetricProperty, will all\n> sub-properties also be symmetric?\n\nI don't think either are true.\n\nIf s is a supProperty of p that means that each pair (sub,obj) in s is \nalso in p but the subset of pairs in s can be arbitrary. For example, in \na domain with two members a and b you could have:\n    p = { (a, b), (b, a) }\n    s = { (a, b) }\nHere p is symmetric and s is a subProperty of p but s is not symmetric.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "> At this point, I propose that we adopt the proposed\n> modifications for the TLS draft. As always, I am happy\n> to hear comments either on the list or in direct mail.\n\nI'll have to go back and look at the comments from last\nweek's proposal (ssl-talk is where I saw most of it),\nbut this proposal really doesn't seem \"cooked\" to me.\n\n   - Internationalization issues arise.  In what character\n     set do \"display_string\" and \"challenge\" appear?  How\n     is the language which the end user knows specified?\n     \n     I don't like seeing application layer issues intrude\n     on transport layer protocols.\n   \n   - Neither \"rough consensus\" nor (multiple instances of)\n     \"working code\" exists, as has been pointed out.\n     \n     Many of us don't see a technical benefit to making TLS\n     be incompatible with SSLv3 in this respect, so I doubt\n     that a realistic \"consensus\" on this point can exist.\n   \n   - It's unclear just where in the handshake these new\n     messages would go.  Or are they even part of the\n     regular handshake protocol?  Do they go after the\n     \"Finished\" messages are exchanged, are they an\n     independent handshake, or what?\n   \n   - Given that the amount of keying material to be built\n     is derived from the negotiated cipher spec, what's\n     the change needed in the definition of a cipher spec?\n     It needs to know it must generate CipherSpec.hash_size\n     (times two?) bytes of keying data.\n   \n   - There's a new requirement, to ignore unrecognized\n     handshake messages rather than treat them as errors.\n     I prefer protocols to be fully specfied.\n\nI could raise more questions, but the fact that there are\nthis many (after this much discussion!) says to me that the\nproposal should not be deemed \"cooked\" enough to incorporate\ninto an IETF standard.\n\n- David Brownell\n  JavaSoft\n\n\n\n"
        },
        {
            "subject": "RE: SWAD Deliverable 8.4  last comments before EU submissio",
            "content": "Hey Steve,\n\nHope you don't mind me forwarding this to the list, I think there's some\nreally valuable comments here, worth discussing in the open.\n\nCheers,\n\nAl.\n\n> -----Original Message-----\n> From: Steve Cayzer [mailto:steve.cayzer@hp.com]\n> Sent: 04 February 2004 21:10\n> To: Miles, AJ (Alistair) \n> Subject: Re: SWAD Deliverable 8.4 - last comments before EU submission\n> \n> > \n> 1). any mileage in having a short glossary? I'm thinking of terms like\n> intension\n> subsumed\n> source\n> target\n> concept\n> \n> - or just explain briefly 'in place' - especially the first 2.\n> \n> 2). I'm slightly surprised that when you say two concepts \n> map, you don't\n> give an ID for either concept. You say 'a hpm:concept with \n> the prefLabel\n> 'xyz' maps to a gcl:concept with the prefLabel 'abc' '. \n> There's nothing to\n> uniquely identify either, unless of course prefLabel is \n> inverseFunctional,\n> which I doubt :) I suspect that this has been sorted out and \n> agreed on the\n> thesaurus list, and that there's a good reason, but it would \n> be nice to say\n> what that reason is.\n> \n> 3). You say that an exact mapping can be made between two \n> concepts with\n> different labels. Why not include such a mapping in your \n> examples for extra\n> clarity?\n> \n> 4). b. Inexact mapping\n> replace\n> \"It is recommended to use major or minor mappings instead, wherever\n> possible.\"\n> with\n> \"You are recommended to use major or minor mappings instead, wherever\n> possible.\"\n> or\n> \"Use major or minor mappings instead, wherever possible.\"\n> \n> 5). d. Minor\n> replace\n> \"Usage: Use this property when there is some small overlap in \n> the intended\n> meaning of source and target concepts.\"\n> with\n> \"Usage: Use this property when there is some overlap in the \n> intended meaning\n> of source and target concepts.\"\n> \n> 6). e. Partial\n> replace\n> \"It is recommended that either broad or narrow mappings are \n> used instead,\n> wherever possible.\"\n> with\n> \"You are recommended to use broad or narrow mappings instead, wherever\n> possible.\"\n> or\n> \"Use broad or narrow mappings instead, wherever possible.\"\n> \n> 7). i,j,k - AND/OR/NOT\n> You can combine in arbitrary combinations (one assumes at \n> least). Could say\n> so.\n> \n> 8). section 3\n> I don't like the use of the term 'imply' - could be \n> misleading in a logical\n> language! I'd prefer 'indicate' or 'state'.\n> My particular beef is with this statement\n> \"A major mapping statement implies that the source and target \n> sets share\n> greater than 50% of their members, a minor mapping implies \n> less than 50% but\n> greater than 0. \"\n> which I'd replace with\n> \"A major mapping statement indicates that the source and target sets\n> probably share greater than 50% of their members, a minor \n> mapping indicates\n> less than 50% but greater than 0. \"\n> Similarly\n> \"A broad mapping states that the target set is a superset of \n> the source set.\n> A narrow mapping states that the target set is a subset of \n> the source set.\"\n> \n> 9). The scope notes in the RDF schema use the word 'implies', \n> this could be\n> changed to 'states' if you think it's a good idea.\n> \n> Hope this helps\n> \n> Steve\n> \n> \n> \n> ----- Original Message -----\n> From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> To: \"Matthews, BM (Brian) \" <B.M.Matthews@rl.ac.uk>; \"Wilson, \n> MD (Michael) \"\n> <M.D.Wilson@rl.ac.uk>\n> Cc: <public-esw-thes@w3.org>\n> Sent: Tuesday, February 03, 2004 1:11 PM\n> Subject: SWAD Deliverable 8.4 - last comments before EU submission\n> \n> \n> >\n> > http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n> >\n> >\n> > Alistair Miles\n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> >\n> > Email:        a.j.miles@rl.ac.uk\n> > Telephone: +44 (0)1235 445440\n> >\n> >\n> \n\n\n\n"
        },
        {
            "subject": "RE: SWAD Deliverable 8.4  last comments before EU submissio",
            "content": "No that's cool, I just didn't want to clog up the list if this was all out\nof date...\n\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: 05 February 2004 12:45\n> To: 'Steve Cayzer'\n> Cc: 'public-esw-thes@w3.org'\n> Subject: RE: SWAD Deliverable 8.4 - last comments before EU submission\n> \n> \n> \n> Hey Steve,\n> \n> Hope you don't mind me forwarding this to the list, I think \n> there's some really valuable comments here, worth discussing \n> in the open.\n> \n> Cheers,\n> \n> Al.\n> \n> > -----Original Message-----\n> > From: Steve Cayzer [mailto:steve.cayzer@hp.com]\n> > Sent: 04 February 2004 21:10\n> > To: Miles, AJ (Alistair)\n> > Subject: Re: SWAD Deliverable 8.4 - last comments before EU \n> submission\n> > \n> > > \n> > 1). any mileage in having a short glossary? I'm thinking of \n> terms like \n> > intension subsumed\n> > source\n> > target\n> > concept\n> > \n> > - or just explain briefly 'in place' - especially the first 2.\n> > \n> > 2). I'm slightly surprised that when you say two concepts\n> > map, you don't\n> > give an ID for either concept. You say 'a hpm:concept with \n> > the prefLabel\n> > 'xyz' maps to a gcl:concept with the prefLabel 'abc' '. \n> > There's nothing to\n> > uniquely identify either, unless of course prefLabel is \n> > inverseFunctional,\n> > which I doubt :) I suspect that this has been sorted out and \n> > agreed on the\n> > thesaurus list, and that there's a good reason, but it would \n> > be nice to say\n> > what that reason is.\n> > \n> > 3). You say that an exact mapping can be made between two\n> > concepts with\n> > different labels. Why not include such a mapping in your \n> > examples for extra\n> > clarity?\n> > \n> > 4). b. Inexact mapping\n> > replace\n> > \"It is recommended to use major or minor mappings instead, wherever \n> > possible.\" with\n> > \"You are recommended to use major or minor mappings \n> instead, wherever\n> > possible.\"\n> > or\n> > \"Use major or minor mappings instead, wherever possible.\"\n> > \n> > 5). d. Minor\n> > replace\n> > \"Usage: Use this property when there is some small overlap in\n> > the intended\n> > meaning of source and target concepts.\"\n> > with\n> > \"Usage: Use this property when there is some overlap in the \n> > intended meaning\n> > of source and target concepts.\"\n> > \n> > 6). e. Partial\n> > replace\n> > \"It is recommended that either broad or narrow mappings are\n> > used instead,\n> > wherever possible.\"\n> > with\n> > \"You are recommended to use broad or narrow mappings \n> instead, wherever\n> > possible.\"\n> > or\n> > \"Use broad or narrow mappings instead, wherever possible.\"\n> > \n> > 7). i,j,k - AND/OR/NOT\n> > You can combine in arbitrary combinations (one assumes at\n> > least). Could say\n> > so.\n> > \n> > 8). section 3\n> > I don't like the use of the term 'imply' - could be\n> > misleading in a logical\n> > language! I'd prefer 'indicate' or 'state'.\n> > My particular beef is with this statement\n> > \"A major mapping statement implies that the source and target \n> > sets share\n> > greater than 50% of their members, a minor mapping implies \n> > less than 50% but\n> > greater than 0. \"\n> > which I'd replace with\n> > \"A major mapping statement indicates that the source and target sets\n> > probably share greater than 50% of their members, a minor \n> > mapping indicates\n> > less than 50% but greater than 0. \"\n> > Similarly\n> > \"A broad mapping states that the target set is a superset of \n> > the source set.\n> > A narrow mapping states that the target set is a subset of \n> > the source set.\"\n> > \n> > 9). The scope notes in the RDF schema use the word 'implies',\n> > this could be\n> > changed to 'states' if you think it's a good idea.\n> > \n> > Hope this helps\n> > \n> > Steve\n> > \n> > \n> > \n> > ----- Original Message -----\n> > From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> > To: \"Matthews, BM (Brian) \" <B.M.Matthews@rl.ac.uk>; \"Wilson,\n> > MD (Michael) \"\n> > <M.D.Wilson@rl.ac.uk>\n> > Cc: <public-esw-thes@w3.org>\n> > Sent: Tuesday, February 03, 2004 1:11 PM\n> > Subject: SWAD Deliverable 8.4 - last comments before EU submission\n> > \n> > \n> > >\n> > > http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n> > >\n> > >\n> > > Alistair Miles\n> > > CCLRC - Rutherford Appleton Laboratory\n> > > Building R1 Room 1.60\n> > > Fermi Avenue\n> > > Chilton\n> > > Didcot\n> > > Oxfordshire OX11 0QX\n> > > United Kingdom\n> > >\n> > > Email:        a.j.miles@rl.ac.uk\n> > > Telephone: +44 (0)1235 445440\n> > >\n> > >\n> > \n> \n\n\n\n"
        },
        {
            "subject": "SKOS AP",
            "content": "Hi,\n\nThree suggestions for the SKOS API, adding to what I already wrote\n<http://www.w3c.rl.ac.uk/SWAD/api/kosAPI.txt>:\n\n1.  Some mapping methods:\n-----------------------------------\n\ngetSupportedSemanticMappings()\n\ngetSupportedSemanticMappings(URI sourceThesaurus, URI\ntargetThesaurus)\n\n--> These methods return the mapping properties available, along\nwith their definitions.  Analagous to the getSupportedSemanticRelations()\nmethods.\n\n\ngetConceptMappings(URI sourceConcept, SemanticMapping map, URI\ntargetThesaurus)\n\ngetConceptMappings(Literal prefLabel, URI sourceThesaurus,\nSemanticMapping map, URI targetThesaurus)\n\ngetConceptMappings(Literal externalID, URI sourceThesaurus,\nSemanticMapping map, URI targetThesaurus)\n\n--> Returns all mappings from the source concept to the target\nthesaurus, according to the given semantic mapping property.\n\ngetConceptMappings(URI sourceConcept, URI targetThesaurus)\n\ngetConceptMappings(Literal prefLabel, URI sourceThesaurus, URI\ntargetThesaurus)\n\ngetConceptMappings(Literal externalID, URI sourceThesaurus, URI\ntargetThesaurus)\n\n--> Returns all mappings from the source concept to the target\nthesaurus.\n\n\n2. Add a path length argument to all of the getConceptRelatives() methods,\nallowing a larger data structure to be returned in one go:\n-----------------------------------\n\ngetConceptRelatives(URI conceptURI, Int expansionDepth)\n\netc......\n\n\n3.  Add a 'return format' argument to the methods, so can return a concept\ndatastructure in, for example, SKOS-RDF/XML-ABBREV, SKOS-RDF/N3, ZThes XML,\nXTM, etc..\n----------------------------------\n\ngetConcept(URI uri, String returnFormat)\n\n[Could be good for promoting interoperability ... !]\n\nThat's it.\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Blank nodes for concepts",
            "content": "Hi,\n\nA couple of people have picked up that in the examples in the documents [1]\n[2] [3] I've encoded concepts as blank nodes, without URIs.  This email\naddresses why I chose to do that.\n\nMy thinking is as follows.  We allow three methods for uniquely identifying\na concept:\n\na.  The URI for the concept.\nb.  A combination of the concept's prefLabel and the URI of the\nthesaurus to which it belongs.\nc.  A combination of the concept's externalID and the URI of the\nthesaurus to which it belongs.\n\nSo, the following are all valid globally unique concept declarations:\n----\n<soks:Concept rdf:about=\"http://foo.com/examplethes/aconcept\"/>\n----\n<soks:Concept>\n<soks:prefLabel>Bangers & Mash</soks:prefLabel>\n<rdfs:isDefinedBy rdf:resource=\"http://foo.com/examplethes\"/>\n</soks:Concept>\n----\n<soks:Concept>\n<soks:externalID>A00456</soks:externalID>\n<rdfs:isDefinedBy rdf:resource=\"http://foo.com/examplethes\"/>\n</soks:Concept>\n----\n\nI'll get to why in a minute.\n\nI also then thought, rather than giving every concept and <rdfs:isDefinedBy>\nproperty to indicate membership of some conceptual scheme, why not allow\npeople to subclass the <soks:Concept> class?  \n\nSo, for example, you could define the class:\n----\n<rdfs:Class rdf:about=\"http://foo.com/thesaurus/Concept\">\n<rdfs:subClassOf\nrdf:resource=\"http://www.w3c.rl.ac.uk/2003/11/21-skos-core#Concept\"/>\n<rdfs:comment>This is the class of all concepts from the foo.com\nthesaurus.</rdfs:comment>\n</rdfs:Class>\n----\nWhich would then allow globally unique concept declarations such as the\nfollowing:\n----\n<foo:Concept>\n<soks:prefLabel>Bangers & Mash</soks:prefLabel>\n</foo:Concept>\n----\n<foo:Concept>\n<soks:externalID>A00456</soks:externalID>\n</foo:Concept>\n----\n\nOK, so why bother?  \n\n1.  It makes for better-looking RDF encodings (this is a serious point, as\nit may help reduce the uptake hurdle - how many times have you heard people\ngroan that RDF looks like gobbledegook because of all the URIs?  Also\nremember many potential users are from totally non sem-web environments,\ne.g. english heritage.  RDF is a new and complicated beast to them.)\n\n2.  It may not be appropriate to give a URI to a concept that is part of\nsome thesaurus that has been defined by an authority outside the semantic\nweb world.  So until the authority itself gives its own concepts URIs, we\ncan still make statements about them using reference-by-description.\n\nOn the down side ...\n\n1.  Someone has to write a bit of reasoning code to equate all blank nodes\nwith the same prefLabel/rdfs:isDefinedBy property values, and run it over\nthe data before publishing it.\n\nWhere I fall on the matter:  in the short term use URIs to identify\nconcepts, so can work in a world without any reasoning required.  In the\nslightly longer term look into allowing the blank-node style encodings, and\nsupport the little bit of reasoning required with some code.\n\nWhat does everyone think?\n\nAl.\n\n\n[1] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html\n[2] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.3.html\n[3] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Blank nodes for concepts",
            "content": "Makes sense to me.\n\nMight be worth adding an explanation to one of the docos, both technical (as\nbelow) and non technical (implication - you can't add a new concept with the\nsame prefLabel as another concept in the same thesaurus)\n\nCheers\n\nSteve\n----- Original Message -----\nFrom: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nTo: <public-esw-thes@w3.org>\nSent: Thursday, February 05, 2004 6:03 PM\nSubject: Blank nodes for concepts.\n\n\n>\n> Hi,\n>\n> A couple of people have picked up that in the examples in the documents\n[1]\n> [2] [3] I've encoded concepts as blank nodes, without URIs.  This email\n> addresses why I chose to do that.\n>\n> My thinking is as follows.  We allow three methods for uniquely\nidentifying\n> a concept:\n>\n> a.  The URI for the concept.\n> b.  A combination of the concept's prefLabel and the URI of the\n> thesaurus to which it belongs.\n> c.  A combination of the concept's externalID and the URI of the\n> thesaurus to which it belongs.\n>\n> So, the following are all valid globally unique concept declarations:\n> ----\n> <soks:Concept rdf:about=\"http://foo.com/examplethes/aconcept\"/>\n> ----\n> <soks:Concept>\n> <soks:prefLabel>Bangers & Mash</soks:prefLabel>\n> <rdfs:isDefinedBy rdf:resource=\"http://foo.com/examplethes\"/>\n> </soks:Concept>\n> ----\n> <soks:Concept>\n> <soks:externalID>A00456</soks:externalID>\n> <rdfs:isDefinedBy rdf:resource=\"http://foo.com/examplethes\"/>\n> </soks:Concept>\n> ----\n>\n> I'll get to why in a minute.\n>\n> I also then thought, rather than giving every concept and\n<rdfs:isDefinedBy>\n> property to indicate membership of some conceptual scheme, why not allow\n> people to subclass the <soks:Concept> class?\n>\n> So, for example, you could define the class:\n> ----\n> <rdfs:Class rdf:about=\"http://foo.com/thesaurus/Concept\">\n> <rdfs:subClassOf\n> rdf:resource=\"http://www.w3c.rl.ac.uk/2003/11/21-skos-core#Concept\"/>\n> <rdfs:comment>This is the class of all concepts from the foo.com\n> thesaurus.</rdfs:comment>\n> </rdfs:Class>\n> ----\n> Which would then allow globally unique concept declarations such as the\n> following:\n> ----\n> <foo:Concept>\n> <soks:prefLabel>Bangers & Mash</soks:prefLabel>\n> </foo:Concept>\n> ----\n> <foo:Concept>\n> <soks:externalID>A00456</soks:externalID>\n> </foo:Concept>\n> ----\n>\n> OK, so why bother?\n>\n> 1.  It makes for better-looking RDF encodings (this is a serious point, as\n> it may help reduce the uptake hurdle - how many times have you heard\npeople\n> groan that RDF looks like gobbledegook because of all the URIs?  Also\n> remember many potential users are from totally non sem-web environments,\n> e.g. english heritage.  RDF is a new and complicated beast to them.)\n>\n> 2.  It may not be appropriate to give a URI to a concept that is part of\n> some thesaurus that has been defined by an authority outside the semantic\n> web world.  So until the authority itself gives its own concepts URIs, we\n> can still make statements about them using reference-by-description.\n>\n> On the down side ...\n>\n> 1.  Someone has to write a bit of reasoning code to equate all blank nodes\n> with the same prefLabel/rdfs:isDefinedBy property values, and run it over\n> the data before publishing it.\n>\n> Where I fall on the matter:  in the short term use URIs to identify\n> concepts, so can work in a world without any reasoning required.  In the\n> slightly longer term look into allowing the blank-node style encodings,\nand\n> support the little bit of reasoning required with some code.\n>\n> What does everyone think?\n>\n> Al.\n>\n>\n> [1] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html\n> [2] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.3.html\n> [3] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "> Makes sense to me.\n\nAgreed. I had my doubts when I first saw a blank node used for foaf:Person,\nseemed counter-intuitive, but with the use cases that have flowed through\nrdfweb-dev it looks like this was almost certainly a very wise move. A\nperson is a tricky enough thing to pin down, I expect something like a\nconcept [waves hands in vivid demonstration] would be even more problematic.\n\nOne thing that may be needed in the docs - a warning about sticking a URI\nin - one company (I forget which, better not guess) has been putting a URI\nin their ever-so-slightly-modified FOAF files. Not pretty.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "Re: Blank nodes for concepts",
            "content": "Is there really any reason you can't have two concepts with the same\nprefLabel?\n\nas I understand it\n\n<Concept>\n  <prefLabel>Bar</prefLabel>\n  <altLabel>Baz</altLabel>\n</Concept>\n<Concept>\n  <prefLabel>Bar</prefLabel>\n  <altLabel>Foo</altLabel>\n</Concept>\n\ndoesn't give you any right to infer that the two balnk nodes are the same\n(this would be that case if you made prefLabel map 1:1 with concepts but I\nthink that's a bad idea anyway).\n\nLooking at user scenarios, there is an obvious cost to two concepts having\nthe same preferred label - whenever you want to classify something by that\nlabel you need to be clear which one you mean. On the benefit side, you might\nwell have a term that commonly refers to a couple of different concepts, and\nwant to be easily able to look for things with the preferred Label.\n\n\"accessible\" is the example that springs to mind in my everyday stuff. I\nsuspect in putting vocbularies together it's also useful.\n\nCheers\n\nChaals\n\nOn Thu, 5 Feb 2004, Steve Cayzer wrote:\n\n>\n>Makes sense to me.\n>\n>Might be worth adding an explanation to one of the docos, both technical (as\n>below) and non technical (implication - you can't add a new concept with the\n>same prefLabel as another concept in the same thesaurus)\n>\n>Cheers\n>\n>Steve\n>----- Original Message -----\n>From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n>To: <public-esw-thes@w3.org>\n>Sent: Thursday, February 05, 2004 6:03 PM\n>Subject: Blank nodes for concepts.\n>\n>\n>>\n>> Hi,\n>>\n>> A couple of people have picked up that in the examples in the documents\n>[1]\n>> [2] [3] I've encoded concepts as blank nodes, without URIs.  This email\n>> addresses why I chose to do that.\n>>\n>> My thinking is as follows.  We allow three methods for uniquely\n>identifying\n>> a concept:\n>>\n>> a.  The URI for the concept.\n>> b.  A combination of the concept's prefLabel and the URI of the\n>> thesaurus to which it belongs.\n>> c.  A combination of the concept's externalID and the URI of the\n>> thesaurus to which it belongs.\n>>\n>> So, the following are all valid globally unique concept declarations:\n>> ----\n>> <soks:Concept rdf:about=\"http://foo.com/examplethes/aconcept\"/>\n>> ----\n>> <soks:Concept>\n>> <soks:prefLabel>Bangers & Mash</soks:prefLabel>\n>> <rdfs:isDefinedBy rdf:resource=\"http://foo.com/examplethes\"/>\n>> </soks:Concept>\n>> ----\n>> <soks:Concept>\n>> <soks:externalID>A00456</soks:externalID>\n>> <rdfs:isDefinedBy rdf:resource=\"http://foo.com/examplethes\"/>\n>> </soks:Concept>\n>> ----\n>>\n>> I'll get to why in a minute.\n>>\n>> I also then thought, rather than giving every concept and\n><rdfs:isDefinedBy>\n>> property to indicate membership of some conceptual scheme, why not allow\n>> people to subclass the <soks:Concept> class?\n>>\n>> So, for example, you could define the class:\n>> ----\n>> <rdfs:Class rdf:about=\"http://foo.com/thesaurus/Concept\">\n>> <rdfs:subClassOf\n>> rdf:resource=\"http://www.w3c.rl.ac.uk/2003/11/21-skos-core#Concept\"/>\n>> <rdfs:comment>This is the class of all concepts from the foo.com\n>> thesaurus.</rdfs:comment>\n>> </rdfs:Class>\n>> ----\n>> Which would then allow globally unique concept declarations such as the\n>> following:\n>> ----\n>> <foo:Concept>\n>> <soks:prefLabel>Bangers & Mash</soks:prefLabel>\n>> </foo:Concept>\n>> ----\n>> <foo:Concept>\n>> <soks:externalID>A00456</soks:externalID>\n>> </foo:Concept>\n>> ----\n>>\n>> OK, so why bother?\n>>\n>> 1.  It makes for better-looking RDF encodings (this is a serious point, as\n>> it may help reduce the uptake hurdle - how many times have you heard\n>people\n>> groan that RDF looks like gobbledegook because of all the URIs?  Also\n>> remember many potential users are from totally non sem-web environments,\n>> e.g. english heritage.  RDF is a new and complicated beast to them.)\n>>\n>> 2.  It may not be appropriate to give a URI to a concept that is part of\n>> some thesaurus that has been defined by an authority outside the semantic\n>> web world.  So until the authority itself gives its own concepts URIs, we\n>> can still make statements about them using reference-by-description.\n>>\n>> On the down side ...\n>>\n>> 1.  Someone has to write a bit of reasoning code to equate all blank nodes\n>> with the same prefLabel/rdfs:isDefinedBy property values, and run it over\n>> the data before publishing it.\n>>\n>> Where I fall on the matter:  in the short term use URIs to identify\n>> concepts, so can work in a world without any reasoning required.  In the\n>> slightly longer term look into allowing the blank-node style encodings,\n>and\n>> support the little bit of reasoning required with some code.\n>>\n>> What does everyone think?\n>>\n>> Al.\n>>\n>>\n>> [1] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html\n>> [2] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.3.html\n>> [3] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n>>\n>> CCLRC - Rutherford Appleton Laboratory\n>> Building R1 Room 1.60\n>> Fermi Avenue\n>> Chilton\n>> Didcot\n>> Oxfordshire OX11 0QX\n>> United Kingdom\n>>\n>> Email:        a.j.miles@rl.ac.uk\n>> Telephone: +44 (0)1235 445440\n>>\n>>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "And the opinionated lurkers flock to the voting booth...\n\nPut acain@ncsa.uiuc.edu down on the \"against\" list.  \nDo it in the application layer baby!\n\nAdam\n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "That's my reading of (b)\n\nAl:\nWe allow three methods for uniquely identifying a concept:\n\na.  The URI for the concept.\nb.  A combination of the concept's prefLabel and the URI of the thesaurus to\nwhich it belongs. \nc.  A combination of the concept's externalID and the URI of the thesaurus\nto which it belongs.\n\n\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org] \n> Sent: 06 February 2004 01:05\n> To: Steve Cayzer\n> Cc: Miles, AJ (Alistair) ; public-esw-thes@w3.org\n> Subject: Re: Blank nodes for concepts.\n> \n> \n> \n> Is there really any reason you can't have two concepts with \n> the same prefLabel?\n> \n> as I understand it\n> \n> <Concept>\n>   <prefLabel>Bar</prefLabel>\n>   <altLabel>Baz</altLabel>\n> </Concept>\n> <Concept>\n>   <prefLabel>Bar</prefLabel>\n>   <altLabel>Foo</altLabel>\n> </Concept>\n> \n> doesn't give you any right to infer that the two balnk nodes \n> are the same (this would be that case if you made prefLabel \n> map 1:1 with concepts but I think that's a bad idea anyway).\n> \n> Looking at user scenarios, there is an obvious cost to two \n> concepts having the same preferred label - whenever you want \n> to classify something by that label you need to be clear \n> which one you mean. On the benefit side, you might well have \n> a term that commonly refers to a couple of different \n> concepts, and want to be easily able to look for things with \n> the preferred Label.\n> \n> \"accessible\" is the example that springs to mind in my \n> everyday stuff. I suspect in putting vocbularies together \n> it's also useful.\n> \n> Cheers\n> \n> Chaals\n> \n> On Thu, 5 Feb 2004, Steve Cayzer wrote:\n> \n> >\n> >Makes sense to me.\n> >\n> >Might be worth adding an explanation to one of the docos, both \n> >technical (as\n> >below) and non technical (implication - you can't add a new \n> concept with the\n> >same prefLabel as another concept in the same thesaurus)\n> >\n> >Cheers\n> >\n> >Steve\n> >----- Original Message -----\n> >From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> >To: <public-esw-thes@w3.org>\n> >Sent: Thursday, February 05, 2004 6:03 PM\n> >Subject: Blank nodes for concepts.\n> >\n> >\n> >>\n> >> Hi,\n> >>\n> >> A couple of people have picked up that in the examples in the \n> >> documents\n> >[1]\n> >> [2] [3] I've encoded concepts as blank nodes, without URIs.  This \n> >> email addresses why I chose to do that.\n> >>\n> >> My thinking is as follows.  We allow three methods for uniquely\n> >identifying\n> >> a concept:\n> >>\n> >> a.  The URI for the concept.\n> >> b.  A combination of the concept's prefLabel and the URI of the \n> >> thesaurus to which it belongs. c.  A combination of the concept's \n> >> externalID and the URI of the thesaurus to which it belongs.\n> >>\n> >> So, the following are all valid globally unique concept \n> declarations:\n> >> ----\n> >> <soks:Concept rdf:about=\"http://foo.com/examplethes/aconcept\"/>\n> >> ----\n> >> <soks:Concept>\n> >> <soks:prefLabel>Bangers & Mash</soks:prefLabel> <rdfs:isDefinedBy \n> >> rdf:resource=\"http://foo.com/examplethes\"/>\n> >> </soks:Concept>\n> >> ----\n> >> <soks:Concept>\n> >> <soks:externalID>A00456</soks:externalID>\n> >> <rdfs:isDefinedBy rdf:resource=\"http://foo.com/examplethes\"/>\n> >> </soks:Concept>\n> >> ----\n> >>\n> >> I'll get to why in a minute.\n> >>\n> >> I also then thought, rather than giving every concept and\n> ><rdfs:isDefinedBy>\n> >> property to indicate membership of some conceptual scheme, why not \n> >> allow people to subclass the <soks:Concept> class?\n> >>\n> >> So, for example, you could define the class:\n> >> ----\n> >> <rdfs:Class rdf:about=\"http://foo.com/thesaurus/Concept\">\n> >> <rdfs:subClassOf \n> >> \n> rdf:resource=\"http://www.w3c.rl.ac.uk/2003/11/21-skos-core#Concept\"/>\n> >> <rdfs:comment>This is the class of all concepts from the foo.com \n> >> thesaurus.</rdfs:comment> </rdfs:Class>\n> >> ----\n> >> Which would then allow globally unique concept \n> declarations such as the\n> >> following:\n> >> ----\n> >> <foo:Concept>\n> >> <soks:prefLabel>Bangers & Mash</soks:prefLabel>\n> >> </foo:Concept>\n> >> ----\n> >> <foo:Concept>\n> >> <soks:externalID>A00456</soks:externalID>\n> >> </foo:Concept>\n> >> ----\n> >>\n> >> OK, so why bother?\n> >>\n> >> 1.  It makes for better-looking RDF encodings (this is a serious \n> >> point, as it may help reduce the uptake hurdle - how many \n> times have \n> >> you heard\n> >people\n> >> groan that RDF looks like gobbledegook because of all the \n> URIs?  Also \n> >> remember many potential users are from totally non sem-web \n> >> environments, e.g. english heritage.  RDF is a new and complicated \n> >> beast to them.)\n> >>\n> >> 2.  It may not be appropriate to give a URI to a concept \n> that is part \n> >> of some thesaurus that has been defined by an authority \n> outside the \n> >> semantic web world.  So until the authority itself gives its own \n> >> concepts URIs, we can still make statements about them using \n> >> reference-by-description.\n> >>\n> >> On the down side ...\n> >>\n> >> 1.  Someone has to write a bit of reasoning code to equate \n> all blank \n> >> nodes with the same prefLabel/rdfs:isDefinedBy property \n> values, and \n> >> run it over the data before publishing it.\n> >>\n> >> Where I fall on the matter:  in the short term use URIs to \n> identify \n> >> concepts, so can work in a world without any reasoning \n> required.  In \n> >> the slightly longer term look into allowing the blank-node style \n> >> encodings,\n> >and\n> >> support the little bit of reasoning required with some code.\n> >>\n> >> What does everyone think?\n> >>\n> >> Al.\n> >>\n> >>\n> >> [1] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html\n> >> [2] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.3.html\n> >> [3] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n> >>\n> >> CCLRC - Rutherford Appleton Laboratory\n> >> Building R1 Room 1.60\n> >> Fermi Avenue\n> >> Chilton\n> >> Didcot\n> >> Oxfordshire OX11 0QX\n> >> United Kingdom\n> >>\n> >> Email:        a.j.miles@rl.ac.uk\n> >> Telephone: +44 (0)1235 445440\n> >>\n> >>\n> >\n> \n> Charles McCathieNevile  http://www.w3.org/People/Charles  \n> tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): \n> +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n\n>\n>That's my reading of (b)\n>\n>b.  A combination of the concept's prefLabel and the URI of the thesaurus to\n>which it belongs.\n>\n\nto expand on my example\n\n <Concept>\n   <prefLabel>Bar</prefLabel>\n   <altLabel>Baz</altLabel>\n   <rdf:isDefinedBy rdf:resource=\"http://example.com/concepts?easyToFind\"/>\n </Concept>\n <Concept>\n   <prefLabel>Bar</prefLabel>\n   <altLabel>Foo</altLabel>\n   <rdf:isDefinedBy rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n </Concept>\n\nseems reasonable, or am I missing something?\n\nHmm. I am assuming you point to the term definition, not just the thesaurus\nit is in. But  I think even if I pointed to the latter (i.e. the thesaurus\ndefines a concept with two prefLabels) there would be nothing to stop the\nthesaurus from defining two concepts with the same prefLabel and different\nalternative labels. And I don't see there is anything wrong with deciding to\nname a concept definition:\n\n <Concept rdf:about=\"#foo\">\n   <prefLabel>Bar</prefLabel>\n   <altLabel>Foo</altLabel>\n   <rdf:isDefinedBy rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n </Concept>\n\nit just gives you a way to refer to this definition. ?\n\ncheers\n\nchaals\n\n>> -----Original Message-----\n>> From: Charles McCathieNevile [mailto:charles@w3.org]\n>> Sent: 06 February 2004 01:05\n>>\n>> doesn't give you any right to infer that the two balnk nodes\n>> are the same (this would be that case if you made prefLabel\n>> map 1:1 with concepts but I think that's a bad idea anyway).\n>>\n>> Looking at user scenarios, there is an obvious cost to two\n>> concepts having the same preferred label - whenever you want\n>> to classify something by that label you need to be clear\n>> which one you mean. On the benefit side, you might well have\n>> a term that commonly refers to a couple of different\n>> concepts, and want to be easily able to look for things with\n>> the preferred Label.\n>>\n>> \"accessible\" is the example that springs to mind in my\n>> everyday stuff. I suspect in putting vocbularies together\n>> it's also useful.\n>>\n>> Cheers\n>>\n>> Chaals\n>>\n>> On Thu, 5 Feb 2004, Steve Cayzer wrote:\n>>\n>> >\n>> >Makes sense to me.\n>> >\n>> >Might be worth adding an explanation to one of the docos, both\n>> >technical (as\n>> >below) and non technical (implication - you can't add a new\n>> concept with the\n>> >same prefLabel as another concept in the same thesaurus)\n>> >\n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "I was intending that the <rdfs:isDefinedBy> property of a concept points to\nthe URI of the thesaurus it is in.  Is this appropriate usage of\n<rdfs:isDefinedBy> ?\n\nAl.\n\n> \n> On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n> \n> >\n> >That's my reading of (b)\n> >\n> >b.  A combination of the concept's prefLabel and the URI of \n> the thesaurus to\n> >which it belongs.\n> >\n> \n> to expand on my example\n> \n>  <Concept>\n>    <prefLabel>Bar</prefLabel>\n>    <altLabel>Baz</altLabel>\n>    <rdf:isDefinedBy \n> rdf:resource=\"http://example.com/concepts?easyToFind\"/>\n>  </Concept>\n>  <Concept>\n>    <prefLabel>Bar</prefLabel>\n>    <altLabel>Foo</altLabel>\n>    <rdf:isDefinedBy \n> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n>  </Concept>\n> \n> seems reasonable, or am I missing something?\n> \n> Hmm. I am assuming you point to the term definition, not just \n> the thesaurus\n> it is in. But  I think even if I pointed to the latter (i.e. \n> the thesaurus\n> defines a concept with two prefLabels) there would be nothing \n> to stop the\n> thesaurus from defining two concepts with the same prefLabel \n> and different\n> alternative labels. And I don't see there is anything wrong \n> with deciding to\n> name a concept definition:\n> \n>  <Concept rdf:about=\"#foo\">\n>    <prefLabel>Bar</prefLabel>\n>    <altLabel>Foo</altLabel>\n>    <rdf:isDefinedBy \n> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n>  </Concept>\n> \n> it just gives you a way to refer to this definition. ?\n> \n> cheers\n> \n> chaals\n> \n> >> -----Original Message-----\n> >> From: Charles McCathieNevile [mailto:charles@w3.org]\n> >> Sent: 06 February 2004 01:05\n> >>\n> >> doesn't give you any right to infer that the two balnk nodes\n> >> are the same (this would be that case if you made prefLabel\n> >> map 1:1 with concepts but I think that's a bad idea anyway).\n> >>\n> >> Looking at user scenarios, there is an obvious cost to two\n> >> concepts having the same preferred label - whenever you want\n> >> to classify something by that label you need to be clear\n> >> which one you mean. On the benefit side, you might well have\n> >> a term that commonly refers to a couple of different\n> >> concepts, and want to be easily able to look for things with\n> >> the preferred Label.\n> >>\n> >> \"accessible\" is the example that springs to mind in my\n> >> everyday stuff. I suspect in putting vocbularies together\n> >> it's also useful.\n> >>\n> >> Cheers\n> >>\n> >> Chaals\n> >>\n> >> On Thu, 5 Feb 2004, Steve Cayzer wrote:\n> >>\n> >> >\n> >> >Makes sense to me.\n> >> >\n> >> >Might be worth adding an explanation to one of the docos, both\n> >> >technical (as\n> >> >below) and non technical (implication - you can't add a new\n> >> concept with the\n> >> >same prefLabel as another concept in the same thesaurus)\n> >> >\n> \n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "I think Al's point is that we need *some* way to uniquely identify concepts\nother than by URI (ie by description) [Al - correct me if I'm wrong!]\n\nOne way is to insist on only one prefLabel per thesaurus.\nIt sounds like you think this is an unreasonable constraint (which might be\ntrue). So if that's the case, what property/ies should we use? Is there a\nconcept equivalent of foaf:mbox ?\n\n\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org] \n> Sent: 06 February 2004 09:14\n> To: Cayzer, Steve\n> Cc: 'Miles, AJ (Alistair) '; 'public-esw-thes@w3.org'\n> Subject: RE: Blank nodes for concepts.\n> \n> \n> \n> On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n> \n> >\n> >That's my reading of (b)\n> >\n> >b.  A combination of the concept's prefLabel and the URI of the \n> >thesaurus to which it belongs.\n> >\n> \n> to expand on my example\n> \n>  <Concept>\n>    <prefLabel>Bar</prefLabel>\n>    <altLabel>Baz</altLabel>\n>    <rdf:isDefinedBy \n> rdf:resource=\"http://example.com/concepts?easyToFind\"/>\n>  </Concept>\n>  <Concept>\n>    <prefLabel>Bar</prefLabel>\n>    <altLabel>Foo</altLabel>\n>    <rdf:isDefinedBy \n> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n>  </Concept>\n> \n> seems reasonable, or am I missing something?\n> \n> Hmm. I am assuming you point to the term definition, not just \n> the thesaurus it is in. But  I think even if I pointed to the \n> latter (i.e. the thesaurus defines a concept with two \n> prefLabels) there would be nothing to stop the thesaurus from \n> defining two concepts with the same prefLabel and different \n> alternative labels. And I don't see there is anything wrong \n> with deciding to name a concept definition:\n> \n>  <Concept rdf:about=\"#foo\">\n>    <prefLabel>Bar</prefLabel>\n>    <altLabel>Foo</altLabel>\n>    <rdf:isDefinedBy \n> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n>  </Concept>\n> \n> it just gives you a way to refer to this definition. ?\n> \n> cheers\n> \n> chaals\n> \n> >> -----Original Message-----\n> >> From: Charles McCathieNevile [mailto:charles@w3.org]\n> >> Sent: 06 February 2004 01:05\n> >>\n> >> doesn't give you any right to infer that the two balnk \n> nodes are the \n> >> same (this would be that case if you made prefLabel map 1:1 with \n> >> concepts but I think that's a bad idea anyway).\n> >>\n> >> Looking at user scenarios, there is an obvious cost to two \n> concepts \n> >> having the same preferred label - whenever you want to classify \n> >> something by that label you need to be clear which one you \n> mean. On \n> >> the benefit side, you might well have a term that commonly \n> refers to \n> >> a couple of different concepts, and want to be easily able to look \n> >> for things with the preferred Label.\n> >>\n> >> \"accessible\" is the example that springs to mind in my everyday \n> >> stuff. I suspect in putting vocbularies together it's also useful.\n> >>\n> >> Cheers\n> >>\n> >> Chaals\n> >>\n> >> On Thu, 5 Feb 2004, Steve Cayzer wrote:\n> >>\n> >> >\n> >> >Makes sense to me.\n> >> >\n> >> >Might be worth adding an explanation to one of the docos, both \n> >> >technical (as\n> >> >below) and non technical (implication - you can't add a new\n> >> concept with the\n> >> >same prefLabel as another concept in the same thesaurus)\n> >> >\n> \n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "I don't see why something as well as a URI is necessary.\n\nThe idea of the semantic web is that URIs are identifiers, good for\nidentifying \"things\". There are some things they are good at identifying. One\nis actual pages on the web, since these already have a URI. But there are\nalso \"concepts\" - things that have a way of identifying them, and various\ndescriptions. We can give them a name (URI) or we can just describe them (as\nblank nodes).\n\nAnd I think it's a bad idea to insist on a single preferred label.\n\nWords are what people use becausee we don't have blank nodes. They aren't\nequivalent to URIs, because we already know that they are duplicated,\nambiguous, overloaded. But we're stuck with them as identifiers, since we\ncan't look up URIs in our head. (We also have descriptions, and we end up\nusing a mixture of the two to try and disambiguate concepts).\n\nIf two concepts have the same labels and descritptions, they might be the\nsame. It's certainly a useful working assumption. But a few long\nphilosophical discussions are enough to realise that often you can spend\nhours talking about something before realising that each person is talking a\nbout a different thing - and then you disambiguate it by adding some\nqualifying information that is unique to one of the options.\n\nSo we can use identical graphs for two blank concept nodes to assert that\nthey are the same, for a given purpose. Or we can use a URI. In either case,\nwe have the important ability to go further, and subclass the concept perhaps\nin two or more ways.\n\nCheers\n\nChaals\n\nOn Fri, 6 Feb 2004, Cayzer, Steve wrote:\n\n>I think Al's point is that we need *some* way to uniquely identify concepts\n>other than by URI (ie by description) [Al - correct me if I'm wrong!]\n>\n>One way is to insist on only one prefLabel per thesaurus.\n>It sounds like you think this is an unreasonable constraint (which might be\n>true). So if that's the case, what property/ies should we use? Is there a\n>concept equivalent of foaf:mbox ?\n>\n>\n>> -----Original Message-----\n>> From: Charles McCathieNevile [mailto:charles@w3.org]\n>> Sent: 06 February 2004 09:14\n>> To: Cayzer, Steve\n>> Cc: 'Miles, AJ (Alistair) '; 'public-esw-thes@w3.org'\n>> Subject: RE: Blank nodes for concepts.\n>>\n>>\n>>\n>> On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n>>\n>> >\n>> >That's my reading of (b)\n>> >\n>> >b.  A combination of the concept's prefLabel and the URI of the\n>> >thesaurus to which it belongs.\n>> >\n>>\n>> to expand on my example\n>>\n>>  <Concept>\n>>    <prefLabel>Bar</prefLabel>\n>>    <altLabel>Baz</altLabel>\n>>    <rdf:isDefinedBy\n>> rdf:resource=\"http://example.com/concepts?easyToFind\"/>\n>>  </Concept>\n>>  <Concept>\n>>    <prefLabel>Bar</prefLabel>\n>>    <altLabel>Foo</altLabel>\n>>    <rdf:isDefinedBy\n>> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n>>  </Concept>\n>>\n>> seems reasonable, or am I missing something?\n>>\n>> Hmm. I am assuming you point to the term definition, not just\n>> the thesaurus it is in. But  I think even if I pointed to the\n>> latter (i.e. the thesaurus defines a concept with two\n>> prefLabels) there would be nothing to stop the thesaurus from\n>> defining two concepts with the same prefLabel and different\n>> alternative labels. And I don't see there is anything wrong\n>> with deciding to name a concept definition:\n>>\n>>  <Concept rdf:about=\"#foo\">\n>>    <prefLabel>Bar</prefLabel>\n>>    <altLabel>Foo</altLabel>\n>>    <rdf:isDefinedBy\n>> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n>>  </Concept>\n>>\n>> it just gives you a way to refer to this definition. ?\n>>\n>> cheers\n>>\n>> chaals\n>>\n>> >> -----Original Message-----\n>> >> From: Charles McCathieNevile [mailto:charles@w3.org]\n>> >> Sent: 06 February 2004 01:05\n>> >>\n>> >> doesn't give you any right to infer that the two balnk\n>> nodes are the\n>> >> same (this would be that case if you made prefLabel map 1:1 with\n>> >> concepts but I think that's a bad idea anyway).\n>> >>\n>> >> Looking at user scenarios, there is an obvious cost to two\n>> concepts\n>> >> having the same preferred label - whenever you want to classify\n>> >> something by that label you need to be clear which one you\n>> mean. On\n>> >> the benefit side, you might well have a term that commonly\n>> refers to\n>> >> a couple of different concepts, and want to be easily able to look\n>> >> for things with the preferred Label.\n>> >>\n>> >> \"accessible\" is the example that springs to mind in my everyday\n>> >> stuff. I suspect in putting vocbularies together it's also useful.\n>> >>\n>> >> Cheers\n>> >>\n>> >> Chaals\n>> >>\n>> >> On Thu, 5 Feb 2004, Steve Cayzer wrote:\n>> >>\n>> >> >\n>> >> >Makes sense to me.\n>> >> >\n>> >> >Might be worth adding an explanation to one of the docos, both\n>> >> >technical (as\n>> >> >below) and non technical (implication - you can't add a new\n>> >> concept with the\n>> >> >same prefLabel as another concept in the same thesaurus)\n>> >> >\n>>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "> Add dennis.glatting@CyberSafe.com to the \"for\" list.\n\nAnd dbrownell@sun.com to the \"agin\" list ... not that we're\ntaking a vote, or anything, just reaffirming there's no\nclear consensus to change.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "Have I missed something here?  Is there any reason why the concept *must* be\nblank?  This isn't the same as overriding the authority of the thesaurus - I\n(as encoder of thesaurus in RDF) can add *a* name for a concept if I want to\nhelp users of the RDF form - I just don't use the authorities naming space\nfor those URIs.\n\nWhy not give it a URI (urn:uuid being a possible choice) anyway even though\nthe primary identification in the theasurus is by other means.  Then, once\nfound, the usual way of referring to a resources is the same as other RDF.\n\nAlistair's arguments are:\n\n> 1.  It makes for better-looking RDF encodings (this is a serious point,\n> as it may help reduce the uptake hurdle - how many times have you heard\n> people groan that RDF looks like gobbledegook because of all the URIs?\n> Also remember many potential users are from totally non sem-web\nenvironments,\n> e.g. english heritage.  RDF is a new and complicated beast to them.)\n\nGood point - and unfortunately not just for this situation  The additional\nURIs can be assigned separately (another part of the file) from the\ndescriptions, because there is a uniquely identifying property set.   [I\nalways fancied a property \"rdf:uri\" and only having bNodes in RDF.]\n\nOr write in N3 :-)\n\n> 2.  It may not be appropriate to give a URI to a concept that is part of\n> some thesaurus that has been defined by an authority outside the semantic\n> web world.  So until the authority itself gives its own concepts URIs, we\n> can still make statements about them using reference-by-description.\n> \n> On the down side ...\n> \n> 1.  Someone has to write a bit of reasoning code to equate all blank\n> nodes with the same prefLabel/rdfs:isDefinedBy property values, and run it\n> over the data before publishing it.\n>\n> Where I fall on the matter:  in the short term use URIs to identify\n> concepts, so can work in a world without any reasoning required.  In the\n> slightly longer term look into allowing the blank-node style encodings,\n> and support the little bit of reasoning required with some code.\n\nI guess I don't see it as black-and-white.  There can be several names\n(URIs) for a thing.  If, later, that authority does assign URIs, we add\nowl:sameAs rules.\n\nAndy\n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "> I don't see why something as well as a URI is necessary.\nYup, that's the crux of it.\nIf we insist on the use of URIs for unambiguous identification, the problem\ngoes away.\n\nIt depends how useful/essential an 'identify by description' capability is.\nThe experience of the foaf project might help us answer that?\n\nSteve\n\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org] \n> Sent: 07 February 2004 13:15\n> To: Cayzer, Steve\n> Cc: 'Miles, AJ (Alistair) '; 'public-esw-thes@w3.org'\n> Subject: RE: Blank nodes for concepts.\n> \n> \n> \n> I don't see why something as well as a URI is necessary.\n> \n> The idea of the semantic web is that URIs are identifiers, \n> good for identifying \"things\". There are some things they are \n> good at identifying. One is actual pages on the web, since \n> these already have a URI. But there are also \"concepts\" - \n> things that have a way of identifying them, and various \n> descriptions. We can give them a name (URI) or we can just \n> describe them (as blank nodes).\n> \n> And I think it's a bad idea to insist on a single preferred label.\n> \n> Words are what people use becausee we don't have blank nodes. \n> They aren't equivalent to URIs, because we already know that \n> they are duplicated, ambiguous, overloaded. But we're stuck \n> with them as identifiers, since we can't look up URIs in our \n> head. (We also have descriptions, and we end up using a \n> mixture of the two to try and disambiguate concepts).\n> \n> If two concepts have the same labels and descritptions, they \n> might be the same. It's certainly a useful working \n> assumption. But a few long philosophical discussions are \n> enough to realise that often you can spend hours talking \n> about something before realising that each person is talking \n> a bout a different thing - and then you disambiguate it by \n> adding some qualifying information that is unique to one of \n> the options.\n> \n> So we can use identical graphs for two blank concept nodes to \n> assert that they are the same, for a given purpose. Or we can \n> use a URI. In either case, we have the important ability to \n> go further, and subclass the concept perhaps in two or more ways.\n> \n> Cheers\n> \n> Chaals\n> \n> On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n> \n> >I think Al's point is that we need *some* way to uniquely identify \n> >concepts other than by URI (ie by description) [Al - correct \n> me if I'm \n> >wrong!]\n> >\n> >One way is to insist on only one prefLabel per thesaurus.\n> >It sounds like you think this is an unreasonable constraint (which \n> >might be true). So if that's the case, what property/ies \n> should we use? \n> >Is there a concept equivalent of foaf:mbox ?\n> >\n> >\n> >> -----Original Message-----\n> >> From: Charles McCathieNevile [mailto:charles@w3.org]\n> >> Sent: 06 February 2004 09:14\n> >> To: Cayzer, Steve\n> >> Cc: 'Miles, AJ (Alistair) '; 'public-esw-thes@w3.org'\n> >> Subject: RE: Blank nodes for concepts.\n> >>\n> >>\n> >>\n> >> On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n> >>\n> >> >\n> >> >That's my reading of (b)\n> >> >\n> >> >b.  A combination of the concept's prefLabel and the URI of the \n> >> >thesaurus to which it belongs.\n> >> >\n> >>\n> >> to expand on my example\n> >>\n> >>  <Concept>\n> >>    <prefLabel>Bar</prefLabel>\n> >>    <altLabel>Baz</altLabel>\n> >>    <rdf:isDefinedBy \n> >> rdf:resource=\"http://example.com/concepts?easyToFind\"/>\n> >>  </Concept>\n> >>  <Concept>\n> >>    <prefLabel>Bar</prefLabel>\n> >>    <altLabel>Foo</altLabel>\n> >>    <rdf:isDefinedBy \n> >> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n> >>  </Concept>\n> >>\n> >> seems reasonable, or am I missing something?\n> >>\n> >> Hmm. I am assuming you point to the term definition, not just the \n> >> thesaurus it is in. But  I think even if I pointed to the latter \n> >> (i.e. the thesaurus defines a concept with two\n> >> prefLabels) there would be nothing to stop the thesaurus from \n> >> defining two concepts with the same prefLabel and different \n> >> alternative labels. And I don't see there is anything wrong with \n> >> deciding to name a concept definition:\n> >>\n> >>  <Concept rdf:about=\"#foo\">\n> >>    <prefLabel>Bar</prefLabel>\n> >>    <altLabel>Foo</altLabel>\n> >>    <rdf:isDefinedBy \n> >> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n> >>  </Concept>\n> >>\n> >> it just gives you a way to refer to this definition. ?\n> >>\n> >> cheers\n> >>\n> >> chaals\n> >>\n> >> >> -----Original Message-----\n> >> >> From: Charles McCathieNevile [mailto:charles@w3.org]\n> >> >> Sent: 06 February 2004 01:05\n> >> >>\n> >> >> doesn't give you any right to infer that the two balnk\n> >> nodes are the\n> >> >> same (this would be that case if you made prefLabel map \n> 1:1 with \n> >> >> concepts but I think that's a bad idea anyway).\n> >> >>\n> >> >> Looking at user scenarios, there is an obvious cost to two\n> >> concepts\n> >> >> having the same preferred label - whenever you want to classify \n> >> >> something by that label you need to be clear which one you\n> >> mean. On\n> >> >> the benefit side, you might well have a term that commonly\n> >> refers to\n> >> >> a couple of different concepts, and want to be easily \n> able to look \n> >> >> for things with the preferred Label.\n> >> >>\n> >> >> \"accessible\" is the example that springs to mind in my everyday \n> >> >> stuff. I suspect in putting vocbularies together it's \n> also useful.\n> >> >>\n> >> >> Cheers\n> >> >>\n> >> >> Chaals\n> >> >>\n> >> >> On Thu, 5 Feb 2004, Steve Cayzer wrote:\n> >> >>\n> >> >> >\n> >> >> >Makes sense to me.\n> >> >> >\n> >> >> >Might be worth adding an explanation to one of the docos, both \n> >> >> >technical (as\n> >> >> >below) and non technical (implication - you can't add a new\n> >> >> concept with the\n> >> >> >same prefLabel as another concept in the same thesaurus)\n> >> >> >\n> >>\n> >\n> \n> Charles McCathieNevile  http://www.w3.org/People/Charles  \n> tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): \n> +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "Right.\n\n\nI think that \"identify by description\" is probably more important than we\nrealise. After all, the only way that I can tell anyone what my concept means\nis by description.\n\nIf I have a restricted use case, and a reasonably consistent community, and\nsome examples, I can identify my concept sufficiently for it to be useful as\na name, instead of by description. For many use cases, this is the fast way\nto work. But to learn the vocabulary, to check something where people aren't\nsure, to compare two vocablaries for merging them, or to develop vocabularies\n\"organically\".\n\nI suspect this is a smaller use case, but one where the ability to play\naround with things before pinning them down is helpful.\n\nIn my experience (hundreds of foaf records, not the millions that are out\nthere) FOAF records tend to remain anonymous and be compared by description\nmost of the time. This is slightly different because people's names are not\nthat stable and are not consistent (I am probably an extreme case - I have at\nleast 5 names listed in FOAF files, and I actually use several more). But\nthis has been important in being able to work out whether \"two people\" are\nreally the same or not.\n\nCheers\n\nChaals\n\nOn Mon, 9 Feb 2004, Cayzer, Steve wrote:\n\n>\n>> I don't see why something as well as a URI is necessary.\n>Yup, that's the crux of it.\n>If we insist on the use of URIs for unambiguous identification, the problem\n>goes away.\n>\n>It depends how useful/essential an 'identify by description' capability is.\n>The experience of the foaf project might help us answer that?\n>\n>Steve\n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "Responding to Andy's mail:\n\n> \n> Have I missed something here?  Is there any reason why the \n> concept *must* be\n> blank?  \n\nNo, I never suggested that concepts must be blank.  I was merely offering it\nas an alternative to using URIs.     \n\n> I guess I don't see it as black-and-white.  There can be several names\n> (URIs) for a thing.  If, later, that authority does assign \n> URIs, we add\n> owl:sameAs rules.\n\nVery true.  \n\nJust to re-iterate, my main motivation for using blank nodes throughout the\ndeliverables was to make the examples more accessible to peoples less or not\nat all familiar with RDF.  \n\nAl.  \n\n\n\n"
        },
        {
            "subject": "FW: Single value for soks:prefLabel ",
            "content": "-----Original Message-----\nFrom: Miles, AJ (Alistair) \nSent: 09 February 2004 13:58\nTo: 'Charles McCathieNevile'\nSubject: Single value for soks:prefLabel ?\n\n\nOK, let's have a go at making this argument clear.\n\nI've said, that the soks:prefLabel property is NOT inverse functional.  That\nis, two concepts may have exactly the same soks:prefLabel value.  \n\nHowever, as a point of good practise in constructing a conceptual scheme\nsuch as a thesaurus, the creator(s) should ensure that no two concepts from\ntheir scheme have the same value for soks:prefLabel.  \n\nThis then means that the value for soks:prefLabel can be used to uniquely\nidentify concepts within that particular scheme.  (This idea is second\nnature to thesaurus developers.  For them, not allowing two identical\ndescriptor-terms into a thesaurus is axiomatic.)\n\nSo there's three options for soks:prefLabel.\n\n1.  soks:prefLabel should be used so that it uniquely identifies a concept\nglobally (inverse functional).\n\n2.  soks:prefLabel should be used so that it uniquely identifies a concept\nwithin a conceptual scheme (in effect inverse functional within a given\nscope).\n\n3.  soks:prefLabel doesn't uniquely identify anything at any level.\n\n(1) is obviously impractical.  (2) could be useful.  (3) is most flexible.  \n\nPersonally, I say that we write the support documentation to strongly\nrecommend users implement their thesauri in SKOS adhering to (2).  This then\ngives them the option of working with terms only, and\nreference-by-description, if they want to.  But obviously there is nothing\nto stop users breaking (2) and doing whatever they like.  The only\nconsequence is, they lose the ability to have people reference their\nconcepts via the soks:prefLabel property.   \n\nChaals: what do you say to all that?\n\nAl.\n\n> \n> And I think it's a bad idea to insist on a single preferred label.\n> \n> Words are what people use becausee we don't have blank nodes. \n> They aren't\n> equivalent to URIs, because we already know that they are duplicated,\n> ambiguous, overloaded. But we're stuck with them as \n> identifiers, since we\n> can't look up URIs in our head. (We also have descriptions, \n> and we end up\n> using a mixture of the two to try and disambiguate concepts).\n> \n> If two concepts have the same labels and descritptions, they \n> might be the\n> same. It's certainly a useful working assumption. But a few long\n> philosophical discussions are enough to realise that often \n> you can spend\n> hours talking about something before realising that each \n> person is talking a\n> bout a different thing - and then you disambiguate it by adding some\n> qualifying information that is unique to one of the options.\n> \n> So we can use identical graphs for two blank concept nodes to \n> assert that\n> they are the same, for a given purpose. Or we can use a URI. \n> In either case,\n> we have the important ability to go further, and subclass the \n> concept perhaps\n> in two or more ways.\n> \n> Cheers\n> \n> Chaals\n> \n> On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n> \n> >I think Al's point is that we need *some* way to uniquely \n> identify concepts\n> >other than by URI (ie by description) [Al - correct me if I'm wrong!]\n> >\n> >One way is to insist on only one prefLabel per thesaurus.\n> >It sounds like you think this is an unreasonable constraint \n> (which might be\n> >true). So if that's the case, what property/ies should we \n> use? Is there a\n> >concept equivalent of foaf:mbox ?\n> >\n> >\n> >> -----Original Message-----\n> >> From: Charles McCathieNevile [mailto:charles@w3.org]\n> >> Sent: 06 February 2004 09:14\n> >> To: Cayzer, Steve\n> >> Cc: 'Miles, AJ (Alistair) '; 'public-esw-thes@w3.org'\n> >> Subject: RE: Blank nodes for concepts.\n> >>\n> >>\n> >>\n> >> On Fri, 6 Feb 2004, Cayzer, Steve wrote:\n> >>\n> >> >\n> >> >That's my reading of (b)\n> >> >\n> >> >b.  A combination of the concept's prefLabel and the URI of the\n> >> >thesaurus to which it belongs.\n> >> >\n> >>\n> >> to expand on my example\n> >>\n> >>  <Concept>\n> >>    <prefLabel>Bar</prefLabel>\n> >>    <altLabel>Baz</altLabel>\n> >>    <rdf:isDefinedBy\n> >> rdf:resource=\"http://example.com/concepts?easyToFind\"/>\n> >>  </Concept>\n> >>  <Concept>\n> >>    <prefLabel>Bar</prefLabel>\n> >>    <altLabel>Foo</altLabel>\n> >>    <rdf:isDefinedBy\n> >> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n> >>  </Concept>\n> >>\n> >> seems reasonable, or am I missing something?\n> >>\n> >> Hmm. I am assuming you point to the term definition, not just\n> >> the thesaurus it is in. But  I think even if I pointed to the\n> >> latter (i.e. the thesaurus defines a concept with two\n> >> prefLabels) there would be nothing to stop the thesaurus from\n> >> defining two concepts with the same prefLabel and different\n> >> alternative labels. And I don't see there is anything wrong\n> >> with deciding to name a concept definition:\n> >>\n> >>  <Concept rdf:about=\"#foo\">\n> >>    <prefLabel>Bar</prefLabel>\n> >>    <altLabel>Foo</altLabel>\n> >>    <rdf:isDefinedBy\n> >> rdf:resource=\"http://example.com/concepts?worksForPWD\"/>\n> >>  </Concept>\n> >>\n> >> it just gives you a way to refer to this definition. ?\n> >>\n> >> cheers\n> >>\n> >> chaals\n> >>\n> >> >> -----Original Message-----\n> >> >> From: Charles McCathieNevile [mailto:charles@w3.org]\n> >> >> Sent: 06 February 2004 01:05\n> >> >>\n> >> >> doesn't give you any right to infer that the two balnk\n> >> nodes are the\n> >> >> same (this would be that case if you made prefLabel map 1:1 with\n> >> >> concepts but I think that's a bad idea anyway).\n> >> >>\n> >> >> Looking at user scenarios, there is an obvious cost to two\n> >> concepts\n> >> >> having the same preferred label - whenever you want to classify\n> >> >> something by that label you need to be clear which one you\n> >> mean. On\n> >> >> the benefit side, you might well have a term that commonly\n> >> refers to\n> >> >> a couple of different concepts, and want to be easily \n> able to look\n> >> >> for things with the preferred Label.\n> >> >>\n> >> >> \"accessible\" is the example that springs to mind in my everyday\n> >> >> stuff. I suspect in putting vocbularies together it's \n> also useful.\n> >> >>\n> >> >> Cheers\n> >> >>\n> >> >> Chaals\n> >> >>\n> >> >> On Thu, 5 Feb 2004, Steve Cayzer wrote:\n> >> >>\n> >> >> >\n> >> >> >Makes sense to me.\n> >> >> >\n> >> >> >Might be worth adding an explanation to one of the docos, both\n> >> >> >technical (as\n> >> >> >below) and non technical (implication - you can't add a new\n> >> >> concept with the\n> >> >> >same prefLabel as another concept in the same thesaurus)\n> >> >> >\n> >>\n> >\n> \n> Charles McCathieNevile  http://www.w3.org/People/Charles  \n> tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): \n> +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n\n\n\n"
        },
        {
            "subject": "Re: FW: Single value for soks:prefLabel ",
            "content": "I say this is a good solution.\n\nIf you have something with soks:preferredLabels you can refer to the concept\nby either label, which is probably useful in lots of cases - hence the use\ncase for alternative labels.\n\nIf you havea thesaurus where two concepts have the same preferredLabel, you\nneed to be more specific in order to get to a single concept.\n\nLeaving this open makes merging thesauri easier - you have a valid one, even\nif you don't instantly correct all cases of using the same label for two\nconcepts. Which means you can develop organically. But the cost is that\nsometimes you will have to choose what concept you get, from a fuller\ndescription (other labels, looking at the examples / definitions). So it's\nnormally helpful to avoid this situation...\n\ncheers\n\nChaals\n\nOn Mon, 9 Feb 2004, Miles, AJ (Alistair)  wrote:\n\n>So there's three options for soks:prefLabel.\n>\n>1.  soks:prefLabel should be used so that it uniquely identifies a concept\n>globally (inverse functional).\n>\n>2.  soks:prefLabel should be used so that it uniquely identifies a concept\n>within a conceptual scheme (in effect inverse functional within a given\n>scope).\n>\n>3.  soks:prefLabel doesn't uniquely identify anything at any level.\n>\n>(1) is obviously impractical.  (2) could be useful.  (3) is most flexible.\n>\n>Personally, I say that we write the support documentation to strongly\n>recommend users implement their thesauri in SKOS adhering to (2).  This then\n>gives them the option of working with terms only, and\n>reference-by-description, if they want to.  But obviously there is nothing\n>to stop users breaking (2) and doing whatever they like.  The only\n>consequence is, they lose the ability to have people reference their\n>concepts via the soks:prefLabel property.\n>\n>Chaals: what do you say to all that?\n\n\n\n"
        },
        {
            "subject": "8.",
            "content": "Hey Kate,\n\nIf you haven't already, I think it's OK to submit 8.4 to EU:\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Test case for thesaurus linkin",
            "content": "Hi Jasper,\n\nPhil Cross suggested I contact you, after I had a query regarding the work\nyou did for SOSIG.  Phil told me you were in fact using more than one\nthesaurus to index your content.  As part of the SWAD-Europe Thesaurus\nActivity [1] I'm looking for a test case to demonstrate thesaurus linking -\ncombining two or more thesauri to create a hybrid.  Could you possibly tell\nme which thesauri you were using, and where you would like them to be linked\n(i.e. which bits of each you use and which bits you don't)?  That would be\nvery useful.\n\nMany thanks,\n\nAlistair.\n\n[1] http://www.w3c.rl.ac.uk/SWAD/thesaurus.html\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": "For what it is worth you can add another name to the against list:\nfgn@ausys.se. Application layer vs. transport layer is what it is all\nabout (in my eyes)...\n----\nFredrik Gustafsson      Email: fgn@ausys.se\nSoftware Engineer        Voice: +46 8 7267646\nAU-System AB             Fax:   +46 8 193322\n\n>----------\n>From: david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n>Sent:  den 8 oktober 1996 01:55\n>To: Gustafsson Fredrik\n>Cc: bfox@microsoft.com; treese@OpenMarket.com; ietf-tls@w3.org\n>Subject: Re: Closing on shared-key authentication\n>\n>> Add dennis.glatting@CyberSafe.com to the \"for\" list.\n>\n>And dbrownell@sun.com to the \"agin\" list ... not that we're\n>taking a vote, or anything, just reaffirming there's no\n>clear consensus to change.\n>\n>- Dave\n>\n>\n\n\n\n"
        },
        {
            "subject": "SKOS core namespac",
            "content": "So shall we go with this:\n\nhttp://www.w3.org/2004/02/skos-core#\n\nfor SKOS-Core 1.0.\n\n?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "SKOS 1.0 issues: SKOS-core and SKOS-mapping  separate or togethe r",
            "content": "Hi,\n\nCurrently we have two vocabs, SKOS-Core and SKOS-Mapping, under different\nnamespaces.  I was wondering whether it would be better to put them both\nunder the same namespace, and just have a single SKOS vocab.\n\nI think in the long run, a single vocab would be better.  However, in the\nshort term, and to facilitate a quick release of SKOS-Core 1.0 (adding in a\nrelease version of SKOS-Mapping would hold it up a bit) I thought to keep\nthem separate for the moment.\n\nAny thoughts?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "SKOSCore 1.0 issues: representing thesaurus membership for a con cep",
            "content": "Hi,\n\nThis is an outstanding issue, which needs to be resolved before an SKOS-Core\n1.0 release.\n\nIt is clear that it is necessary to have some way of stating that a concept\nis a member of a particular thesaurus (conceptual scheme).  By what\nmechanism do we do this?\n\nOptions:\n\n1.  Use rdfs:isDefinedBy\n\n2.  Create a new (more specific than rdfs:isDefinedBy) property e.g.\nskos:inScheme\n\n3.  For each scheme (thesaurus) define a subclass of the skos:Concept class\n\nArgument:\n\n(1) is not specific to this need, and overloading it could cause confusion\nand ambiguity.\n(2) is potentially easiest to understand.\n(3) is more consistent with the qualified DC in RDF approach to representing\nsubject schemes [1].\n\nI'm tempted to go with (2) for now and add a property to SKOS-Core\n<skos:inScheme> for the 1.0 release.\n\nAny thoughts on choosing this option, or the name of the property itself?\n(I didn't suggest something like <skos:inThesaurus> because I'm trying to\nkeep SKOS slightly more generic than just thesauri.)\n\nAl.\n\n[1] http://dublincore.org/documents/dcq-rdf-xml/\n\n\n\n"
        },
        {
            "subject": "Re: SKOS core namespac",
            "content": "On Thu, 19 Feb 2004 16:47:18 -0000, \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk> wrote:\n\n> So shall we go with this:\n> \n> http://www.w3.org/2004/02/skos-core#\n> \n> for SKOS-Core 1.0.\n\nDo you want multiple namespaces?  then maybe\n  http://www.w3.org/2004/02/skos/core#\n    (contents of http://www.w3c.rl.ac.uk/2003/11/21-skos-core)\n  http://www.w3.org/2004/02/skos/mapping#\n    (contents of http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping)\n\nothers?\n\ndan, did you say http://www.w3.org/2004/02/skos/ was available for us?\n\nThat's outside the swad europe area, so we'll need permission to write there.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: SKOS core namespac",
            "content": "* Dave Beckett <dave.beckett@bristol.ac.uk> [2004-02-19 17:03+0000]\n> On Thu, 19 Feb 2004 16:47:18 -0000, \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk> wrote:\n> \n> > So shall we go with this:\n> > \n> > http://www.w3.org/2004/02/skos-core#\n> > \n> > for SKOS-Core 1.0.\n> \n> Do you want multiple namespaces?  then maybe\n>   http://www.w3.org/2004/02/skos/core#\n>     (contents of http://www.w3c.rl.ac.uk/2003/11/21-skos-core)\n>   http://www.w3.org/2004/02/skos/mapping#\n>     (contents of http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping)\n\nYes, that seems a little better (in practice is means we have this \nstuff in a subdirectory...)\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: SKOSCore 1.0 issues: representing thesaurus membership for a con cep",
            "content": "I'm missing something. Can you explain why (1) is ambiguous and misleading?\n\nCheers\n\nSteve\n----- Original Message ----- \nFrom: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nTo: <public-esw-thes@w3.org>\nSent: Thursday, February 19, 2004 5:01 PM\nSubject: SKOS-Core 1.0 issues: representing thesaurus membership for a con\ncept\n\n\n>\n> Hi,\n>\n> This is an outstanding issue, which needs to be resolved before an\nSKOS-Core\n> 1.0 release.\n>\n> It is clear that it is necessary to have some way of stating that a\nconcept\n> is a member of a particular thesaurus (conceptual scheme).  By what\n> mechanism do we do this?\n>\n> Options:\n>\n> 1.  Use rdfs:isDefinedBy\n>\n> 2.  Create a new (more specific than rdfs:isDefinedBy) property e.g.\n> skos:inScheme\n>\n> 3.  For each scheme (thesaurus) define a subclass of the skos:Concept\nclass\n>\n> Argument:\n>\n> (1) is not specific to this need, and overloading it could cause confusion\n> and ambiguity.\n> (2) is potentially easiest to understand.\n> (3) is more consistent with the qualified DC in RDF approach to\nrepresenting\n> subject schemes [1].\n>\n> I'm tempted to go with (2) for now and add a property to SKOS-Core\n> <skos:inScheme> for the 1.0 release.\n>\n> Any thoughts on choosing this option, or the name of the property itself?\n> (I didn't suggest something like <skos:inThesaurus> because I'm trying to\n> keep SKOS slightly more generic than just thesauri.)\n>\n> Al.\n>\n> [1] http://dublincore.org/documents/dcq-rdf-xml/\n>\n\n\n\n"
        },
        {
            "subject": "RE: SKOSCore 1.0 issues: representing thesaurus membership for a  con cep",
            "content": "The thing is I'm not totally clear on exactly how rdfs:isDefinedBy should be\nused.  \n\nThe following excerpt comes from [1] :\n\n--------------------\nrdfs:isDefinedBy is an instance of rdf:Property that is used to indicate a\nresource \ndefining the subject resource. This property may be used to indicate an RDF\nvocabulary in\nwhich a resource is described.\n--------------------\n\nWhat I want is a property that says 'concept X is a member of concept-scheme\nY'.\n\nSo I'm not sure if rdfs:isDefinedBy is appropriate?\n\nP.s. I slept on it and now I'm tending towards option (3) - create a\nsubclass of skos:Concept for each concept scheme (mainly because of\nconsistency with DCQ).\n\nAl.\n\n[1] http://www.w3.org/TR/2004/REC-rdf-schema-20040210/#ch_isdefinedby\n\n-----Original Message-----\nFrom: Steve Cayzer [mailto:steve.cayzer@hp.com] \nSent: 19 February 2004 20:49\nTo: Miles, AJ (Alistair) ; public-esw-thes@w3.org\nSubject: Re: SKOS-Core 1.0 issues: representing thesaurus membership for a\ncon cept\n\n\nI'm missing something. Can you explain why (1) is ambiguous and misleading?\n\nCheers\n\nSteve\n----- Original Message ----- \nFrom: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nTo: <public-esw-thes@w3.org>\nSent: Thursday, February 19, 2004 5:01 PM\nSubject: SKOS-Core 1.0 issues: representing thesaurus membership for a con\ncept\n\n\n>\n> Hi,\n>\n> This is an outstanding issue, which needs to be resolved before an\nSKOS-Core\n> 1.0 release.\n>\n> It is clear that it is necessary to have some way of stating that a\nconcept\n> is a member of a particular thesaurus (conceptual scheme).  By what \n> mechanism do we do this?\n>\n> Options:\n>\n> 1.  Use rdfs:isDefinedBy\n>\n> 2.  Create a new (more specific than rdfs:isDefinedBy) property e.g. \n> skos:inScheme\n>\n> 3.  For each scheme (thesaurus) define a subclass of the skos:Concept\nclass\n>\n> Argument:\n>\n> (1) is not specific to this need, and overloading it could cause \n> confusion and ambiguity.\n> (2) is potentially easiest to understand.\n> (3) is more consistent with the qualified DC in RDF approach to\nrepresenting\n> subject schemes [1].\n>\n> I'm tempted to go with (2) for now and add a property to SKOS-Core \n> <skos:inScheme> for the 1.0 release.\n>\n> Any thoughts on choosing this option, or the name of the property \n> itself? (I didn't suggest something like <skos:inThesaurus> because \n> I'm trying to keep SKOS slightly more generic than just thesauri.)\n>\n> Al.\n>\n> [1] http://dublincore.org/documents/dcq-rdf-xml/\n>\n\n\n\n"
        },
        {
            "subject": "RE: SKOS namespace",
            "content": "OK, for SKOS-Core 1.0:\n\nhttp://www.w3.org/2004/02/skos/core#\n\n.. And for SKOS-Mapping 1.0:\n\nhttp://www.w3.org/2004/02/skos/mapping#\n\nAny objections?\n\nAl.\n\n-----Original Message-----\nFrom: Dan Brickley [mailto:danbri@w3.org] \nSent: 19 February 2004 17:16\nTo: Dave Beckett\nCc: Miles, AJ (Alistair) ; 'Nikki Rogers (Nikki.Rogers@bristol.ac.uk)';\n'public-esw-thes@w3.org'\nSubject: Re: SKOS core namespace\n\n\n\n* Dave Beckett <dave.beckett@bristol.ac.uk> [2004-02-19 17:03+0000]\n> On Thu, 19 Feb 2004 16:47:18 -0000, \"Miles, AJ (Alistair) \" \n> <A.J.Miles@rl.ac.uk> wrote:\n> \n> > So shall we go with this:\n> > \n> > http://www.w3.org/2004/02/skos-core#\n> > \n> > for SKOS-Core 1.0.\n> \n> Do you want multiple namespaces?  then maybe\n>   http://www.w3.org/2004/02/skos/core#\n>     (contents of http://www.w3c.rl.ac.uk/2003/11/21-skos-core)\n>   http://www.w3.org/2004/02/skos/mapping#\n>     (contents of http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping)\n\nYes, that seems a little better (in practice is means we have this \nstuff in a subdirectory...)\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: SKOS namespace",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-02-20 12:03-0000]\n> OK, for SKOS-Core 1.0:\n> \n> http://www.w3.org/2004/02/skos/core#\n> \n> .. And for SKOS-Mapping 1.0:\n> \n> http://www.w3.org/2004/02/skos/mapping#\n> \n> Any objections?\n\nWorks for me. If you let me know what to put there, \nI can install files as a stopgap before getting you write access...\n\ncheers,\n\ndan\n\n\n\n"
        },
        {
            "subject": "SKOSCore 1.0: Adding a 'ConceptScheme' clas",
            "content": "Hi,\n\nI'm thinking SKOS-Core 1.0 should have a class like <skos:ConceptScheme>.\nSo when someone defines a concept scheme (e.g. a thesaurus), they can give\nit a URI and type it appropriately.\n\nQuick discussion of some alternatives:\n\nI would have called it <skos:Thesaurus> but I'm still aiming slightly more\ngeneric than thesauri (am trying to shoot in between lots of different\ncommunities with different legacy perspectives - 'ConceptScheme' is more\nneutral and self-descriptive than 'Thesaurus' which means different things\nto different people).\n\nAlso, I don't think <dct:SubjectScheme> is appropriate, because as Phil from\nEnglish Heritage pointed out, a lot of thesauri are used for things other\nthan subject based indexing.\n\nAny comments?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "RE: SKOSCore 1.0 issues: representing thesaurus membership for a  con cep",
            "content": "Right. That makes sense, although my allergic reaction to rdfs:isDefinedBy\nis not as pronounced as yours :) I could live with it. But I agree that (3)\nis elegant and useful.\n\nSteve\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: 20 February 2004 12:00\n> To: 'Steve Cayzer'; public-esw-thes@w3.org\n> Subject: RE: SKOS-Core 1.0 issues: representing thesaurus \n> membership for a con cept\n> \n> \n> The thing is I'm not totally clear on exactly how \n> rdfs:isDefinedBy should be used.  \n> \n> The following excerpt comes from [1] :\n> \n> --------------------\n> rdfs:isDefinedBy is an instance of rdf:Property that is used \n> to indicate a resource \n> defining the subject resource. This property may be used to \n> indicate an RDF vocabulary in which a resource is described.\n> --------------------\n> \n> What I want is a property that says 'concept X is a member of \n> concept-scheme Y'.\n> \n> So I'm not sure if rdfs:isDefinedBy is appropriate?\n> \n> P.s. I slept on it and now I'm tending towards option (3) - \n> create a subclass of skos:Concept for each concept scheme \n> (mainly because of consistency with DCQ).\n> \n> Al.\n> \n> [1] http://www.w3.org/TR/2004/REC-rdf-schema-20040210/#ch_isdefinedby\n> \n> -----Original Message-----\n> From: Steve Cayzer [mailto:steve.cayzer@hp.com] \n> Sent: 19 February 2004 20:49\n> To: Miles, AJ (Alistair) ; public-esw-thes@w3.org\n> Subject: Re: SKOS-Core 1.0 issues: representing thesaurus \n> membership for a con cept\n> \n> \n> I'm missing something. Can you explain why (1) is ambiguous \n> and misleading?\n> \n> Cheers\n> \n> Steve\n> ----- Original Message ----- \n> From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n> To: <public-esw-thes@w3.org>\n> Sent: Thursday, February 19, 2004 5:01 PM\n> Subject: SKOS-Core 1.0 issues: representing thesaurus \n> membership for a con cept\n> \n> \n> >\n> > Hi,\n> >\n> > This is an outstanding issue, which needs to be resolved before an\n> SKOS-Core\n> > 1.0 release.\n> >\n> > It is clear that it is necessary to have some way of stating that a\n> concept\n> > is a member of a particular thesaurus (conceptual scheme).  By what\n> > mechanism do we do this?\n> >\n> > Options:\n> >\n> > 1.  Use rdfs:isDefinedBy\n> >\n> > 2.  Create a new (more specific than rdfs:isDefinedBy) property e.g.\n> > skos:inScheme\n> >\n> > 3.  For each scheme (thesaurus) define a subclass of the \n> skos:Concept\n> class\n> >\n> > Argument:\n> >\n> > (1) is not specific to this need, and overloading it could cause\n> > confusion and ambiguity.\n> > (2) is potentially easiest to understand.\n> > (3) is more consistent with the qualified DC in RDF approach to\n> representing\n> > subject schemes [1].\n> >\n> > I'm tempted to go with (2) for now and add a property to SKOS-Core\n> > <skos:inScheme> for the 1.0 release.\n> >\n> > Any thoughts on choosing this option, or the name of the property\n> > itself? (I didn't suggest something like <skos:inThesaurus> because \n> > I'm trying to keep SKOS slightly more generic than just thesauri.)\n> >\n> > Al.\n> >\n> > [1] http://dublincore.org/documents/dcq-rdf-xml/\n> >\n> \n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "We have a large Kerberos infrastructure that I like to see\nsupported in some manner by TLS rather than implementing\nyet another key management solution. \n\nPut me in the pro symmetric column.\n\n\ndhip\n\n\n\n"
        },
        {
            "subject": "RE: SKOSCore 1.0 issues: representing thesaurus membership for a    con  cep",
            "content": "Hmm. I prefer the idea of being able to say thhat a concept is a member of a\nthesauraus or (the reason why I prefer this over the subclassing Concept\napproach) of several thesauri.\n\nOne relevant use case here is the WWAAC thing which I will write about in a\nminute as a trip report - where a handful of concepts are likely to find\ntheir way into a number of different thesauri and it seems more useful not\nto have lots and lots of \"sameindividual things floating around to make the\nsystem work.\n\nCheers\n\nChaals\n\nOn Sat, 21 Feb 2004, Cayzer, Steve wrote:\n\n>\n>Right. That makes sense, although my allergic reaction to rdfs:isDefinedBy\n>is not as pronounced as yours :) I could live with it. But I agree that (3)\n>is elegant and useful.\n>\n>Steve\n>> -----Original Message-----\n>> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n>> Sent: 20 February 2004 12:00\n>> To: 'Steve Cayzer'; public-esw-thes@w3.org\n>> Subject: RE: SKOS-Core 1.0 issues: representing thesaurus\n>> membership for a con cept\n>>\n>>\n>> The thing is I'm not totally clear on exactly how\n>> rdfs:isDefinedBy should be used.\n>>\n>> The following excerpt comes from [1] :\n>>\n>> --------------------\n>> rdfs:isDefinedBy is an instance of rdf:Property that is used\n>> to indicate a resource\n>> defining the subject resource. This property may be used to\n>> indicate an RDF vocabulary in which a resource is described.\n>> --------------------\n>>\n>> What I want is a property that says 'concept X is a member of\n>> concept-scheme Y'.\n>>\n>> So I'm not sure if rdfs:isDefinedBy is appropriate?\n>>\n>> P.s. I slept on it and now I'm tending towards option (3) -\n>> create a subclass of skos:Concept for each concept scheme\n>> (mainly because of consistency with DCQ).\n>>\n>> Al.\n>>\n>> [1] http://www.w3.org/TR/2004/REC-rdf-schema-20040210/#ch_isdefinedby\n>>\n>> -----Original Message-----\n>> From: Steve Cayzer [mailto:steve.cayzer@hp.com]\n>> Sent: 19 February 2004 20:49\n>> To: Miles, AJ (Alistair) ; public-esw-thes@w3.org\n>> Subject: Re: SKOS-Core 1.0 issues: representing thesaurus\n>> membership for a con cept\n>>\n>>\n>> I'm missing something. Can you explain why (1) is ambiguous\n>> and misleading?\n>>\n>> Cheers\n>>\n>> Steve\n>> ----- Original Message -----\n>> From: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\n>> To: <public-esw-thes@w3.org>\n>> Sent: Thursday, February 19, 2004 5:01 PM\n>> Subject: SKOS-Core 1.0 issues: representing thesaurus\n>> membership for a con cept\n>>\n>>\n>> >\n>> > Hi,\n>> >\n>> > This is an outstanding issue, which needs to be resolved before an\n>> SKOS-Core\n>> > 1.0 release.\n>> >\n>> > It is clear that it is necessary to have some way of stating that a\n>> concept\n>> > is a member of a particular thesaurus (conceptual scheme).  By what\n>> > mechanism do we do this?\n>> >\n>> > Options:\n>> >\n>> > 1.  Use rdfs:isDefinedBy\n>> >\n>> > 2.  Create a new (more specific than rdfs:isDefinedBy) property e.g.\n>> > skos:inScheme\n>> >\n>> > 3.  For each scheme (thesaurus) define a subclass of the\n>> skos:Concept\n>> class\n>> >\n>> > Argument:\n>> >\n>> > (1) is not specific to this need, and overloading it could cause\n>> > confusion and ambiguity.\n>> > (2) is potentially easiest to understand.\n>> > (3) is more consistent with the qualified DC in RDF approach to\n>> representing\n>> > subject schemes [1].\n>> >\n>> > I'm tempted to go with (2) for now and add a property to SKOS-Core\n>> > <skos:inScheme> for the 1.0 release.\n>> >\n>> > Any thoughts on choosing this option, or the name of the property\n>> > itself? (I didn't suggest something like <skos:inThesaurus> because\n>> > I'm trying to keep SKOS slightly more generic than just thesauri.)\n>> >\n>> > Al.\n>> >\n>> > [1] http://dublincore.org/documents/dcq-rdf-xml/\n>> >\n>>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Trip report WWAAC  &quot;thesauri&quot; for symbol language",
            "content": "Hi folks,\n\nOn Friday I went to a workshop for the WWAAC project -\nhttp://80.60.189.118/wwaac/project/index.asp\n\nThey are working on defining concepts and mapping those to symbols. These are\nused by people who commnicate with a number of graphic symbols, and some\nassitive technology, instead of writing. These people have a variety of\ndisabilities.\n\nTheir approach is to define a common set of concepts, and allow others to\nextend them. For example, \"bus\" and \"person\" are common concepts which the\ndifferent tools enable, but \"Charles McCathieNevile\" or \"the bus from my\nhouse to school\" isn't, although users might have a particular semi-private\nsymbol they use for this such as a photo of me, a special symbol or photo for\nthe particular bus.\n\nThey are using something similar to SKOS, and have been following the SKOS\nwork - I hope that they will send us some notes on what doesn't work for\ntheir use cases out of what we provide (if anything), and be able to actually\nwork directly with SKOS. They use more stuff, but we should at least be able\nto provide a basis for the things they are doing that are the same.\n\nOne thing that struck me is that I am not sure if we have set up for the idea\nthat a preferred term for a concept, in a particular vocabulary, might be\nrepresented by an image or multimedia object rather than a text term...\n\nCheers\n\nChaals\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: Blank nodes for concepts",
            "content": "Charles, and all\n\nI've been lurking for a few months on this forum and already missed several\noccasions to jump in. I would like to bring here, thinking aloud and for\nwhat it's worth, some thoughts from a parallel world. We've been struggling\nwith similar issues for quite a while now in the Topic Map community, and\nsingularly around the notion of Published Subjects, in the OASIS PubSubj TC\n[1], and also in Mondeca developments where we often have to deal with\nThesaurus legacy.\n\n*Charles wrote on Feb 09:\n> I think that \"identify by description\" is probably more important than we\n> realise. After all, the only way that I can tell anyone what my\n> concept means is by description.\n\nMaybe it depends on who is \"anyone\", human (H) or system (S), and what you\nmean by \"description\". The former can make sense of unformal or rather\n\"semi-formal\" descriptions, whereas the latter basically needs formal ones.\nBut we need efficient identification mechanism in H2H, S2H, and S2S\ntransactions. In fact most Semantic Web applications will involve those\nthree kinds of transactions together, so the crucial question is to figure\nout which, if any, identification mechanism would be convenient and\nnon-ambiguous across all of them.\nThe first cut of Topic Maps Published Subjects approach was that S2S needs\nonly name-like identifiers (URIs), whereas H2H needs often description-like\nidentification. The Published Subjects mechanism would address the S2H\ninteraction, by matching in a non-ambiguous way system-usable \"subject\nidentifiers\" (URIs) to human-usable identification information resources\n\"subject indicators\". BTW, yesterday message about WWAAC is more or less\nabout this kind of approach, subject indicators being symbols, graphics,\nsounds or any other meaningful multimedia content.\n\nNow further reflection led some people (including myself) last year in the\nTM community to question this approach, along the lines of what Charles\npoints at. *Both* systems and humans can use and make sense of name-like\nidentifiers in some contexts, but both will need disambiguating\ndescriptions in other contexts. Both identifiers and descriptions\n(indicators) can make for subject definition, depending on the context.\nOTOH, using RDF-OWL can somehow blur the notions of identification,\ndefinition and description, leading to some open issues, for example : If I\nuse in a local application, as subject (concept) identifier, the URI of a\nclass or instance in an OWL ontology, or of a descriptor in a SKOS\nthesaurus, what is the level of ontological commitment involved by that\nuse? Does it mean whatever assertion I make locally about this concept has\nto be consistent with (all) assertions made in the source ontology or\nthesaurus \"defining\" it? \"Consistency\" here can be read either from an\n(unformal) human user viewpoint, or from a (formal) system's one. Thorny\nissue, and IMO the most important one the SW technologies are facing.\n\nTo come back to the blank node definition of a concept, although it's clear\nto me why and how it could be done inside an RDF file, I'm still a bit\nunclear how it could be used by external references (from another thesaurus\nor ontology):\n\n*Charles\n> We can use identical graphs for two blank concept nodes to assert that\n> they are the same, for a given purpose.\n\nI like the idea, and actually this is something we have been working out in\nMondeca to a certain extent. For example in our interface using NLP tools,\nwe can identify two \"acquisition\" events coming from different news, by\nfirst identifying the kind of event, then comparing the identity of role\nplayers \"buyer\" and \"bought\" in the event association.\nThis is also the path that Topic Maps Reference Model folks (Steve Newcomb\nand al.) have been following, through the notion of \"Subject Identity\nDiscriminating Property\"\nSee http://www.isotopicmaps.org/TMRM/TMRM-latest-clean.html#parid3039\n\nThanks for your attention\n\nBernard\n\n[1] http://www.oasis-open.org/committees/tm-pubsubj/\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n\n"
        },
        {
            "subject": "Concepts represented by symbol",
            "content": "*Chaals:\nOne thing that struck me is that I am not sure if we have set up for the\nidea that a preferred term for a concept, in a particular vocabulary, might\nbe represented by an image or multimedia object rather than a text term...\n\nI had thought about using the foaf:depiction property to allow an image\nrepresentation of a concept.  However, reading up on the WWAAC project\nsuggests to me that foaf:depiction may not be enough, and in fact we would\nneed something like skos:prefSymbol and skos:altSymbol (which could be\nsub-props of foaf:depiction??).  Chaals what do you reckon?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Recommended reading: feedback on SKOS from Doug Tudhope and Ceri  Binding from University of Glamorga",
            "content": "Forwarding this to the list.  \n\n-----Original Message-----\nFrom: Douglas Tudhope [mailto:dstudhope@glam.ac.uk] \nSent: 05 February 2004 16:04\nTo: Miles, AJ (Alistair) \nCc: cbinding@glam.ac.uk\nSubject: feedback on RDF schemas for thesauri and simple KOS *pre-release*\n\n\nAlistair\n\nSKOS-CORE looks  a very promising start.\nAs promised (belatedly - sorry) some initial comments on these from our\npoint of view (bearing in mind that we don't have much experience in RDF).\n\n1. As you know, we support the idea of allowing for more precise KOS\nrepresentations. We should also try to maintain compatability with\ntraditional standards. One rationale for the current standard's set of\nthesaurus relationships is that they are at quite a cost/effective level of\ngenerality for many applications, allowing for some user/indexer variation\nin concept useage and relevance judgements. The proposed scheme does seem to\nallow for both 'traditional' KOS and more precise, formal constructions\nwhich is good.\n\n2.  It is important to have some notion of facets but we don't think that\ncurrent version quite captures it. The scheme correctly takes 'facets' to\nrepresent fundamental categories in the sense of Ranganathan, the CRG, BSI\nstandard etc (as opposed to subfacet indicators). Yes, each concept is a\nmember of one and only one facet. But in this sense, I'm not sure it's\nuseful to simply 'treat facets as concepts'? Eg\n>>>\n- <rdf:Property rdf:ID=\"inFacet\">\n  <rdfs:label>member-of-facet</rdfs:label>\n  <rdfs:subPropertyOf rdf:resource=\"#broader\" />\n  <rdfs:range rdf:resource=\"#Facet\" />\n  <rdfs:comment> This property indicates that a concept is a member of a\nfacet. A concept may have only one inFacet property. This property is a\nsub-property of the 'broader' property. Thus faceted conceptual structures\nmay be reduced to simple hierarchical displays by applications that do not\ncomprehend facets.</rdfs:comment>\n  </rdf:Property>\n>>>\na) \"This property is a sub-property of the 'broader' property. \"  -- In\nparticular, we're not convinced about making this relationship a type of the\nbroader relationship. I'd suggest that's not really the semantics?\nConceivably subclass/superclass or set membership might be better solutions?\n\nb) In any case, we don't quite see how this would realise the degenerate\ncase you describe for non-faceted schemes. Each concept is immediately\nrelated by the BT-subtype relationship to its Facet. How does that help you\nwith the degenerate case, where presumably you want the Top of Hierarchy to\nstand in as a facet? A subclass would do just as well?\n\nc) The degenerate case is less important than being able to facilitate more\nadvanced reasoning with faceted schemes. Thus we might wish to use OWL or\nanother language to express facet synthesis rules, or relate thesaurus\nfacets to a higher level ontology. There needs to be a sufficiently clear\ndistinction between facets and member concepts - use of the broader\nrelationship concerns us here.\n\n\n3. Broader/Narrow - We assume that the OWL representation would formally\nexpress the Inverse relationship? However, in the RDF there is nothing to\ncapture the BT/NT connection apart from the comment. Is it useful to make\nthe RDF as self sufficient as possible? Eg would it be useful to introduce a\nnew type of Semantic Relationship called HierarchicalRelationship with BT\nand NT underneath? We can see this may have drawback of creating additional\ncomplexity but suggest as a consideration.\n\n\n4. Not everyone considers Related (RTs) to be necessarily symmetric (eg the\nAAT does not). Could 'symmetric' not be an optional property of the\nrelationship?\n\n5. Is there any possibility of defining at least one subtype of Related? Eg\na Partitive (see below)?\n\n6. Good to have subtypes of the hierarchical relationships but note that\nbroader/narrowerPartitive is often restricted to members of the same\nhierarchy (see Aitchison&Gilchrist). In other cases, a Related relationship\ntype is recommended.\n\n\n7. There is little notion here of the Entry Vocabulary, and the various\nrelationships between concepts and terms. Was there a reason for this? It's\na very important aspect of a thesaurus and may(?) be a critical issue for\ngaining acceptance of  a standard in some traditional thesaurus circles. It\ntake it the rationale is http://esw.w3.org/topic/RdfThesaurus - \"Suggested\nsolution 2:: We don't bother with them. Instead we offer the recommendation\nthat all acronyms be included as possible labels for a concept. Plural forms\nprobably don't need be included as modern stemming algorithms can identify\nthe root of the term. \"\n\na) I see the general point and agree that the longterm solution is making\nconnections with standards in the Linguistic community. However we would\ntend to argue that relying only on labels results in an impoverished model\nof a thesaurus? Essentially a thesaurus contains a pragmatic domain-specific\nlexicon in the entry vocab, equivalence relationships and scope notes. It's\none of the reasons why the thesaurus has been such a useful tool over many\nyears and arguably a weakness of some purely concept-based 'ontological'\nefforts. Could we bring in some version of the Equivalence relationship to\nSKOS, or alternatively have more properties regarding terms?\n\nb) For example, there are various subtypes of equivalence corresponding to\nparts-of-speech relationships, US/UKalts, types of synonyms, antonyms (even)\nand these might be distinguished in some future super-KOS systems. Replacing\nthe Equivalnce relationship with a simple 'bag of labels' would lose that\npossibility.\n\nc) Also - in some cases a term will be considered Equivalent to more than\none concept (perhaps with different degrees of confidence). Again that\nbecomes less clearly stated.\n\n\n\n8. Anyway, be interested to know your thoughts on all this - it's great that\nsomeone is proposing possible standards and trying to reach concensus. The\ngeneral thrust of the SKOS RDF schema is great. What are your plans for\nprogressing it?\n\nOne way of possibly progressing/discussing some of this effort might be in\n(or associated with) an NKOS workshop at ECDL'04 in Bath, this September.\nMarianne Nielsen is aiming to propose a workshop on user-centred issues and\nthis might be a second (or parallel mini-meeting) theme?\n\nHope to get a chance to talk at JISC workshop in London at some point if you\nare attending for SWAD-Europe demo?\n\nregards\n\nDoug, Ceri\n\n\nDouglas Tudhope\nReader, School of Computing\nUniversity of Glamorgan\nPontypridd CF37 1DL\nWales, UK\n\nTel  +44 (0) 1443-482271\nFax  +44 (0) 1443-482715\ndstudhope@glam.ac.uk http://www.comp.glam.ac.uk/pages/staff/dstudhope\nEditor : The New Review of Hypermedia and Multimedia\n\n\n----- Original Message -----\nFrom: \"Miles, AJ (Alistair)\" <A.J.Miles@RL.AC.UK>\nTo: <NKOS@dli2.nsf.gov>\nSent: Tuesday, November 25, 2003 1:41 PM\nSubject: RDF schemas for thesauri and simple KOS *pre-release*\n\n\n> Dear all,\n>\n> I offer these schemas as a pre-release, to get some initial feedback\nand\n> response on their design.\n>\n> SKOS-Core <http://www.w3c.rl.ac.uk/2003/11/21-skos-core> (RDF schema\nfor\n> encoding thesauri and other simple knowledge organisation systems e.g. \n> taxonomies and classification schemes.)\n>\n> SKOS-Mapping <http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping> (RDF \n> schema for expressing mappings between concepts from different \n> thesauri.)\n>\n> This work is ongoing in the context of the SWAD-Europe project [1]\n[2].\n>\n> Yours,\n>\n> Alistair Miles.\n>\n> [1] SWAD-Europe Thesaurus Activity \n> <http://www.w3c.rl.ac.uk/SWAD/thesaurus.html>\n> [2] Semantic Web Advanced Development for Europe project \n> <http://www.w3.org/2001/sw/Europe/>\n>\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n\n\n\n"
        },
        {
            "subject": "Modifications to the skos:related property family to accommodate  variations in thesaurus structur",
            "content": "*Doug, Ceri wrote:\n> \n> 4. Not everyone considers Related (RTs) to be necessarily \n> symmetric (eg the AAT does not). Could 'symmetric' not be an \n> optional property of the relationship?\n> \n\nI propose we change the comment of the skos:related property to indicate\nthat this property should NOT be considered as symmetric.\n\nWe then add an extension skos:relatedSymmetric (as a sub-prop of\nskos:related) to be used in the case where related IS considered to be\nsymmetric.\n\n*Doug, Ceri:\n> 5. Is there any possibility of defining at least one subtype \n> of Related? Eg a Partitive (see below)?\n> \n> 6. Good to have subtypes of the hierarchical relationships \n> but note that broader/narrowerPartitive is often restricted \n> to members of the same hierarchy (see Aitchison&Gilchrist). \n> In other cases, a Related relationship type is recommended.\n> \n\nTo accommodate the cases where the partitve relationship is treated as an\nassociative relationship (and NOT as hierarchical), I suggest we add two\nextensions to SKOS-Core:\n\nskos:relatedPartOf (sub-prop of skos:related)\nskos:relatedHasPart (sub-prop of skos:related)\n\n... So then users have the option to use either the hierarchical or\nassociative style properties to express the partitive relation, depending on\npreference.\n\nAl.\n\n\n\n"
        },
        {
            "subject": "RE: Closing on shared-key authentication Repl",
            "content": "I am against this proposal also on the basis of separating application layer\nand ztransport layer issues.\n\nBaber Amin\nSoftware Engineer\nNetWare Security R&D\nNovell Inc.\n\n_________________________________\nIs the noise in my head bothering you??\n\n\n\n"
        },
        {
            "subject": "Re: Concepts represented by symbol",
            "content": "I think that the symbols are effectively preferredTerms in a particular\nperson's vocabulary - it's just that they use what we think of as pictures\ninstead of the glyphs that represent \"normal\" fonts.\n\nSo the question is more the range of the \"term\" properties and whether they\nare fixed sa text or can be resources.\n\nIt might be interesting to make a subproperty of preferredLabel and altLabel\nthat is also a subProperty of foaf:depicts, and suggest the use of that\nspecifically for symbols, but it might be overkill - it still depends on\nhaving an appropriate range to start with.\n\nI certainly think it is more important that the symbols are represented as\nfirst class terms in SKOS than that they are linked to other vocaublaries\nsuch as FOAF, although I think that is a vry positive step. (Providing ways\nof linking to Dublin Core subject vocabularies is more along the lines of\nusing foaf:depicts - very helpful but not the core problem).\n\nThere are similar possibilities in VoiceXML, where there are a handful of\noptions available in an interaction designed to be through voice, and\ndevelopers will define assorted ways of recogninsing from a user's speech\nwhich of the relevant concepts is being matched. (It is not real natural\nlanguage processing, but more pattern matching in situtations which are\ntightly enough constrained that it looks like it...)\n\nThis all gets further complicated by the fact that Unicode are in the process\nof encoding a set of these symbols (Bliss) which effectively means encoding a\nnumber of these concepts as single characters which we expect to have\navailable in general...\n\ncheers\n\nChaals\n\n\n\nOn Tue, 24 Feb 2004, Miles, AJ (Alistair)  wrote:\n\n>\n>*Chaals:\n>One thing that struck me is that I am not sure if we have set up for the\n>idea that a preferred term for a concept, in a particular vocabulary, might\n>be represented by an image or multimedia object rather than a text term...\n>\n>I had thought about using the foaf:depiction property to allow an image\n>representation of a concept.  However, reading up on the WWAAC project\n>suggests to me that foaf:depiction may not be enough, and in fact we would\n>need something like skos:prefSymbol and skos:altSymbol (which could be\n>sub-props of foaf:depiction??).  Chaals what do you reckon?\n>\n>Al.\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: Concepts represented by symbol",
            "content": "Hi!\nI thought an example from traditional KOS may help.\n\nThe situation with symbols in KOS is as follows and I assume\nthat this can be encoded in different ways (e.g. as an equivalent\nterm or as an preferred term)\n\n1) classification uses symbols as concepts so if symbol\nis used instead of concept there should be provision for the concept\ndescription (as well as its scope note which is not the same)\n\nexamples\n\n23 Religions originating in Indian sub-continent. Hindu religion\n  in the broad sense\n SN:Hinduism is extremely difficult to define. Vedism and\n Brahmanism may be regarded as the religion of the archaic\n period, and, as a general rule 233 should be used for works on\n Hinduism\n233Hinduism narrowly\n233-442.47Upavasa. Fasting in Hinduism\n\n\n(03)Reference works [description]\nSN:All books containing information on a number of different\nsubjects or on the totality of knowledge [scope note]\n\n[not to mention that symbols in classifications works as semantic\naggregates... i.e. one can connect 233 Hinduism with  (03) Reference works\nto get composit 233(03) Reference works in Hinduism or 233-442.47(03)\nReference works on fasting in Hinduism. But this is out of\nthe scope of this discussion.\n\nb) thesauri may also have symbols attached to descriptors for the\npurpose of systematic display...\n\nthesaurus systematic display\n\nHMechanical components\nHTRopes\nSN: A length of strong line\n\nHTC(RT)Strands\n\nHTNFibre ropes\nUF: Textile ropes\n\n\nthesarus alphabetical display\n\nFibre ropesHTN\nUFTextile ropes\nBTRopes\nBTTextile products\n\nRopesHT\nSNA length of strong line...\nBTMechanical components\nNTFibre ropes\n\n\n\nAida\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Charles\n> McCathieNevile\n> Sent: 25 February 2004 10:19\n> To: Miles, AJ (Alistair)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: Re: Concepts represented by symbols\n>\n>\n>\n> I think that the symbols are effectively preferredTerms in a particular\n> person's vocabulary - it's just that they use what we think of as pictures\n> instead of the glyphs that represent \"normal\" fonts.\n>\n> So the question is more the range of the \"term\" properties and\n> whether they\n> are fixed sa text or can be resources.\n>\n> It might be interesting to make a subproperty of preferredLabel\n> and altLabel\n> that is also a subProperty of foaf:depicts, and suggest the use of that\n> specifically for symbols, but it might be overkill - it still depends on\n> having an appropriate range to start with.\n>\n> I certainly think it is more important that the symbols are represented as\n> first class terms in SKOS than that they are linked to other vocaublaries\n> such as FOAF, although I think that is a vry positive step.\n> (Providing ways\n> of linking to Dublin Core subject vocabularies is more along the lines of\n> using foaf:depicts - very helpful but not the core problem).\n>\n> There are similar possibilities in VoiceXML, where there are a handful of\n> options available in an interaction designed to be through voice, and\n> developers will define assorted ways of recogninsing from a user's speech\n> which of the relevant concepts is being matched. (It is not real natural\n> language processing, but more pattern matching in situtations which are\n> tightly enough constrained that it looks like it...)\n>\n> This all gets further complicated by the fact that Unicode are in\n> the process\n> of encoding a set of these symbols (Bliss) which effectively\n> means encoding a\n> number of these concepts as single characters which we expect to have\n> available in general...\n>\n> cheers\n>\n> Chaals\n>\n>\n>\n> On Tue, 24 Feb 2004, Miles, AJ (Alistair)  wrote:\n>\n> >\n> >*Chaals:\n> >One thing that struck me is that I am not sure if we have set up for the\n> >idea that a preferred term for a concept, in a particular\n> vocabulary, might\n> >be represented by an image or multimedia object rather than a\n> text term...\n> >\n> >I had thought about using the foaf:depiction property to allow an image\n> >representation of a concept.  However, reading up on the WWAAC project\n> >suggests to me that foaf:depiction may not be enough, and in\n> fact we would\n> >need something like skos:prefSymbol and skos:altSymbol (which could be\n> >sub-props of foaf:depiction??).  Chaals what do you reckon?\n> >\n> >Al.\n> >\n>\n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel:\n> +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33\n> 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Feedback from Stella Dextre-Clarke on SWADEurope Thesaurus activ it",
            "content": "Forwarding this to the list, feedback from Stella Dextre-Clarke, who is\ninvolved in drafting of new British Standards for thesauri.\n\n> -----Original Message-----\n> From: Stella Dextre Clarke [mailto:sdclarke@lukehouse.demon.co.uk] \n> Sent: 12 January 2004 09:50\n> To: Miles, AJ (Alistair) \n> Cc: Leonard Will (Leonard Will); 'Alan Gilchrist'\n> Subject: RE: SWAD-Europe Thesaurus activity\n> \n> \n> Alistair,\n> Please accept my apologies for the long delay in replying. \n> First of all I was too tied-up with other things; then I \n> thought I'd wait until after our standards Working Group had \n> its meeting (6 Jan) and send you a joint response. WE did \n> have that meeting, and the good news is, we made a lot of \n> progress with all the corrections BSI has made to our drafts, \n> to get them into BSI housestyle. We now expect the documents \n> (i.e. Parts 1 and\n> 2) to emerge in March as Drafts for Public Comment.\n> \n> The bad news is, Parts 1 and 2 took up most of the day and we \n> did not have time for the Group to consider the SWAD papers \n> properly.  So I will just try to give you a few personal \n> comments on the work in progress.\n> \n> Firstly, it is very impressive to see how much is being done \n> - keep up the good work!\n> \n> Re the SKOS-mapping document, I liked the general approach, \n> which has a lot in common with our draft of Part 4 of the \n> standard ( this is the Part that deals with mappings). Some \n> matters of detail may need sorting out. For example, the \n> property \"mappingRelation\" seems to be defined (or at least \n> described) in terms of itself. In our standard, by the way, \n> we differentiate between inter-term \"mappings\" and \n> \"relationships\" by using the former term for relationships \n> between terms in different vocabularies. (Thus all mappings \n> are relationships, but we try to use the term \"relationships\" \n> when they apply within one vocabulary and \"mappings\" for \n> cross-vocabulary relationships. What we want to avoid is the \n> sort of loose chatter where people talk about a mapping when \n> all they mean is a USE/UF relationship inside one thesaurus.)\n> \n> I thought that specifying \"more than 50%\" or \"less than 50%\" \n> (in a set of indexed resources) as the distinction between \n> major and minor matches has the benefit of pragmatism (i.e. I \n> like it in principle) but some problems in practice. It can \n> only apply in the context of a particular indexed collection, \n> and the benefit is that you get a measure of how good the \n> mapping will be for that collection. But a problem arises \n> when the collection grows, and something that matched for 80% \n> of the resources initially, now only matches for 30% of the \n> resources. It means you have to make regular checks on all \n> the major/minor matches to see if they are still valid - even \n> though the concepts themselves have not changed.\n> \n> RE the SKOS-Core document, this seems to be setting up \n> definitions for a series of terms, and I am a little \n> concerned that the terms/definitions being established in \n> your group may differ from those in our standard, which we \n> hope will be adopted internationally (in the longer run). In \n> some cases the definitions are compatible with each other; in \n> other cases there is a real difference of usage.  For \n> example, I am not sure I have understood the difference made \n> in the SWAD document between the property \"prefLabel\" and the \n> property \"descriptor\", since the former property seems to be \n> exactly what our standard means by \"descriptor\" i.e. the \n> unique name by which a concept should be labelled. We use the \n> term \"non-descriptor\" for any alternative (non-preferred) \n> name for the same concept. To take one of the examples in the \n> SWAD document, \"Orange (fruit)\" could be a descriptor or a \n> non-descriptor, depending on how it is established in the \n> thesaurus. Spelling this out a little, in Thesaurus A, we \n> might have an entry \"Orange (fruit) BT Citrus fruits\", \n> indicating that both of these terms are descriptors. In \n> Thesaurus B we might have an entry \"Orange (fruit) USE \n> Oranges\", indicating that the former term is a \n> non-descriptor. It goes without saying that all the terms in \n> a thesaurus, whether descriptors or non-descriptors, have to \n> be unique. I was not quite clear, studying the SWAD document, \n> whether \"descriptor\" could also be used for the things that \n> our standard calls \"non-descriptors\" - which would be \n> unfortunate!  Sorry I have made rather a meal of this \n> example, but I am just wondering how we could proceed so that \n> there are no real incompatibilities between the terminologies \n> used in the SWAD work, and those in the thesaurus standard.\n> \n> Incidentally, I hope to have a cleaned-up version of our \n> definitions in the next few days. Would you like a copy? (The \n> difference between them and those in the draft I sent you \n> before are only cosmetic - the application of BSI's \n> house-style - but still, differences can cause problems if \n> one is not aware of them.)\n> \n> Another thing that concerns me is the class \"Facet\". The SWAD \n> document states that \"a concept may be a member of only one \n> facet\". I find myself split on this one, because I agree that \n> ideally, facets should be mutually exclusive. But in \n> practice, many thesauri which claim to follow the principles \n> of facet analysis (and this is one of the principles) do not \n> always achieve the ideal.  Some facets commonly used in \n> thesauri include Activities, Agents, Objects, Materials, \n> Organisms, Places, Times. Normally, a concept that belongs to \n> one of these facets cannot belong to any of the others, \n> because they are such fundamentally different things. But in \n> practice, a few concepts can occur that it is convenient to \n> assign to more than one facet. For example, biotechnology has \n> allowed us to develop some special organisms that may be used \n> as materials. Sometimes it is arguable whether a given \n> descriptor represents an object or a material. Or a material \n> such as a chemical reagent may be thought of as an agent \n> (although most agents are people or organisations). You could \n> argue that this problem occurs only because the facets have \n> been badly chosen in the first place. But I argue ( I am a \n> pragmatist) that in the real thesauri one encounters in \n> particular contexts, facets may have been chosen because they \n> are useful in the given context, and not for their \n> theoretical properties. Occasionally, therefore, concepts \n> will crop up that have been assigned to more than one facet. \n> What I am trying to warn is that, even though the ideal is \n> still as stated above, practical applications have to be \n> built in such a way that they will not break when the \n> exceptions crop up.  \n> \n> I must stop getting excited about every detail! I should \n> address your question about a \"standard interface for a \n> thesaurus service\". AS you can see in the draft of Part 2 \n> which I sent you ( I hope you did receive\n> it?) we do say quite a bit about the functionality required \n> in the interfaces for (a) using a thesaurus for retrieval, \n> and (b) maintaining a thesaurus. Is that what you mean? WE do \n> not specify details of the interface - just the \n> functionality, and in quite a permissive way, to allow added \n> features. As to the data exchanges that support the \n> interface, formats and protocols will be specified in Part 5. \n> (We have not done any work on Part 5, but we hope it will \n> reflect the contents of Parts 1-4 and borrow heavily from the \n> work done by teams such as your own. So the more we can align \n> work across the community, the better.)\n> \n> On another matter, your Links page invites contributions and \n> I wondered whether you would like to make reference to the \n> GCL at http://www.govtalk.gov.uk/schemasstandards/gcl.asp \n> That is the address of the online version. There are copies \n> freely available for downloading at \n> http://www.govtalk.gov.uk/schemasstandards/gcldocuments.asp \n> Strictly speaking, the GCL is a taxonomy rather than a \n> thesaurus, but I note that the page uses the term \"thesauri\" \n> to include quite a lot of other vocabularies (e.g. LCSH, DDC) \n> that are not thesauri, so I think you could put the GCL in \n> with the other \"thesauri\".\n> \n> Please do keep in touch, Alistair, and let us know if you see \n> any opportunities for joint action.\n> \n> Best wishes for 2004,\n> Stella\n> \n> *****************************************************\n> Stella Dextre Clarke\n> Information Consultant\n> Luke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\n> Tel: 01235-833-298\n> Fax: 01235-863-298\n> SDClarke@LukeHouse.demon.co.uk\n> *****************************************************\n> \n> \n> \n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: 21 November 2003 11:57\n> To: Stella Dextre Clarke (E-mail)\n> Subject: SWAD-Europe Thesaurus activity\n> \n> \n> Hi Stella,\n> \n> Just to send you an update on the SWAD-Europe thesaurus work. \n>  The current work is all written up on the web site [1]. \n> \n> The RDF formats for thesaurus data are maturing, and there \n> will be some reports in the next month or so covering things \n> like representing multilingual data, inter-thesaurus mapping \n> and thesaurus change and version control.  We're also looking \n> at making interoperability between thesauri and web \n> ontologies, taxonomies and other KOS happen.  \n> \n> At the moment we're talking about doing this like defining \n> the RDF semantic-relations in relation to published standards \n> (to avoid ambiguities with things like 'broader') so it would \n> be good to stay in touch with the development of new British \n> standards for thesaurus structure.  \n> \n> A last question, we are working on a web service API for a \n> terminology service.  Does your new standard cover things \n> like a standard interface to a thesaurus service?\n> \n> Yours,\n> \n> Alistair.\n> \n> [1] SWAD-Europe Thesaurus Activity \n> <http://www.w3c.rl.ac.uk/SWAD/thesaurus.html>\n> [2] Semantic \n> Web Advanced Development for Europe project \n> <http://www.w3.org/2001/sw/Europe/>\n> \n> \n> CCLRC - Rutherford \n> Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "FW: Recommended reading: feedback on SKOS from Doug Tudhope and C eri  Binding from University of Glamorga",
            "content": "Forwarded to the list (message from Aida Slavic):\n\n(Aside: we need to figure out how to do facets properly - I've got a strong\nfeeling that the way we do it in SKOS-Core currently isn't quite right, 'tho\nI don't know how to fix it yet).\n\nAl.\n\n> -----Original Message-----\n> From: Aida Slavic [mailto:aida@acorweb.net] \n> Sent: 24 February 2004 17:23\n> To: Miles, AJ (Alistair) \n> Subject: RE: Recommended reading: feedback on SKOS from Doug \n> Tudhope and Ceri Binding from University of Glamorgan\n> \n> \n> Just in case you are not familiar with this....\n> \n> D. Tudhope and C.Binding may be referring to the terminology \n> adopted by UK CRG (Classification Research Group). In this \n> framework mutually exclusive categories of concepts are \n> organized on the level of subfacets and not on the level of facets.\n> \n> CRG opperateS with terms of\n> - BROAD FACETS (defined subject area)\n> - FACETS (13 fundamental facets: thing - kind - part - \n> property - material - process - operation - patient - product \n> - by-product - agent - space - time )\n> - SUBFACETS(array)\n> - FOCI(i.e. concepts)\n> \n> Sub-facets allows for a structured building of hierarchies \n> within any fundamental facet.\n> \n> example\n> \n> Level of FACETS : 1 PROPERTIES, 1 PROCESSES, 2 MATERIALS 3 \n> OPERATIONS etc.\n> \n> FACET 1 Property\n> ARRAY 1(subfacet) Properties of existence\n> ARRAY 2           Properties of range\n> General. Universal\n> Properties of regularity\n> [FOCUS 1 = concept]       Regular. Usual. Ordinary\n> [FOCUS 2 = concept]Irregular. \n> Unusual. Extraordinary\n> [FOCUS 3 = concept]Simple. Simplified\n> [FOCUS 4 = concept]Complex\n> ...\n> ...\n> ARRAY 3Properties of magnitude\n> \n> \n> \n> ...\n> \n> \n> \n> > -----Original Message-----\n> > From: public-esw-thes-request@w3.org \n> > [mailto:public-esw-thes-request@w3.org]On Behalf Of Miles, AJ \n> > (Alistair)\n> >\n> > Sent: 24 February 2004 13:22\n> > To: 'public-esw-thes@w3.org'\n> > Subject: Recommended reading: feedback on SKOS from Doug \n> Tudhope and \n> > Ceri Binding from University of Glamorgan\n> >\n> >\n> >\n> > Forwarding this to the list.\n> >\n> > -----Original Message-----\n> > From: Douglas Tudhope [mailto:dstudhope@glam.ac.uk]\n> > Sent: 05 February 2004 16:04\n> > To: Miles, AJ (Alistair)\n> > Cc: cbinding@glam.ac.uk\n> > Subject: feedback on RDF schemas for thesauri and simple KOS \n> > *pre-release*\n> >\n> >\n> > Alistair\n> >\n> > SKOS-CORE looks  a very promising start.\n> > As promised (belatedly - sorry) some initial comments on these from \n> > our point of view (bearing in mind that we don't have much \n> experience \n> > in RDF).\n> >\n> > 1. As you know, we support the idea of allowing for more \n> precise KOS \n> > representations. We should also try to maintain compatability with \n> > traditional standards. One rationale for the current \n> standard's set of \n> > thesaurus relationships is that they are at quite a cost/effective \n> > level of generality for many applications, allowing for some \n> > user/indexer variation in concept useage and relevance \n> judgements. The \n> > proposed scheme does seem to\n> > allow for both 'traditional' KOS and more precise, formal \n> constructions\n> > which is good.\n> >\n> > 2.  It is important to have some notion of facets but we \n> don't think \n> > that current version quite captures it. The scheme correctly takes \n> > 'facets' to represent fundamental categories in the sense of \n> > Ranganathan, the CRG, BSI standard etc (as opposed to subfacet \n> > indicators). Yes, each concept is a member of one and only \n> one facet. \n> > But in this sense, I'm not sure it's useful to simply \n> 'treat facets as \n> > concepts'? Eg\n> > >>>\n> > - <rdf:Property rdf:ID=\"inFacet\">\n> >   <rdfs:label>member-of-facet</rdfs:label>\n> >   <rdfs:subPropertyOf rdf:resource=\"#broader\" />\n> >   <rdfs:range rdf:resource=\"#Facet\" />\n> >   <rdfs:comment> This property indicates that a concept is \n> a member of \n> > a facet. A concept may have only one inFacet property. This \n> property \n> > is a sub-property of the 'broader' property. Thus faceted \n> conceptual \n> > structures may be reduced to simple hierarchical displays by \n> > applications that do not comprehend facets.</rdfs:comment>\n> >   </rdf:Property>\n> > >>>\n> > a) \"This property is a sub-property of the 'broader' \n> property. \"  -- \n> > In particular, we're not convinced about making this relationship a \n> > type of the broader relationship. I'd suggest that's not really the \n> > semantics? Conceivably subclass/superclass or set \n> membership might be \n> > better solutions?\n> >\n> > b) In any case, we don't quite see how this would realise the \n> > degenerate case you describe for non-faceted schemes. Each \n> concept is \n> > immediately related by the BT-subtype relationship to its \n> Facet. How \n> > does that help you with the degenerate case, where \n> presumably you want \n> > the Top of Hierarchy to\n> > stand in as a facet? A subclass would do just as well?\n> >\n> > c) The degenerate case is less important than being able to \n> facilitate \n> > more advanced reasoning with faceted schemes. Thus we might wish to \n> > use OWL or another language to express facet synthesis rules, or \n> > relate thesaurus facets to a higher level ontology. There \n> needs to be \n> > a sufficiently clear distinction between facets and member \n> concepts - \n> > use of the broader relationship concerns us here.\n> >\n> >\n> > 3. Broader/Narrow - We assume that the OWL representation would \n> > formally express the Inverse relationship? However, in the \n> RDF there \n> > is nothing to capture the BT/NT connection apart from the \n> comment. Is \n> > it useful to make the RDF as self sufficient as possible? \n> Eg would it \n> > be useful to introduce a new type of Semantic Relationship called \n> > HierarchicalRelationship with BT and NT underneath? We can see this \n> > may have drawback of creating additional\n> > complexity but suggest as a consideration.\n> >\n> >\n> > 4. Not everyone considers Related (RTs) to be necessarily symmetric \n> > (eg the AAT does not). Could 'symmetric' not be an optional \n> property \n> > of the relationship?\n> >\n> > 5. Is there any possibility of defining at least one subtype of \n> > Related? Eg a Partitive (see below)?\n> >\n> > 6. Good to have subtypes of the hierarchical relationships but note \n> > that broader/narrowerPartitive is often restricted to \n> members of the \n> > same hierarchy (see Aitchison&Gilchrist). In other cases, a Related \n> > relationship type is recommended.\n> >\n> >\n> > 7. There is little notion here of the Entry Vocabulary, and the \n> > various relationships between concepts and terms. Was there \n> a reason \n> > for this? It's a very important aspect of a thesaurus and \n> may(?) be a \n> > critical issue for gaining acceptance of  a standard in some \n> > traditional thesaurus circles. It\n> > take it the rationale is \n> http://esw.w3.org/topic/RdfThesaurus - \"Suggested\n> > solution 2:: We don't bother with them. Instead we offer the\n> > recommendation\n> > that all acronyms be included as possible labels for a concept.\n> > Plural forms\n> > probably don't need be included as modern stemming \n> algorithms can identify\n> > the root of the term. \"\n> >\n> > a) I see the general point and agree that the longterm solution is \n> > making connections with standards in the Linguistic \n> community. However \n> > we would tend to argue that relying only on labels results in an \n> > impoverished model of a thesaurus? Essentially a thesaurus \n> contains a \n> > pragmatic domain-specific lexicon in the entry vocab, equivalence \n> > relationships and scope notes. It's\n> > one of the reasons why the thesaurus has been such a useful \n> tool over many\n> > years and arguably a weakness of some purely concept-based \n> 'ontological'\n> > efforts. Could we bring in some version of the Equivalence \n> relationship to\n> > SKOS, or alternatively have more properties regarding terms?\n> >\n> > b) For example, there are various subtypes of equivalence \n> > corresponding to parts-of-speech relationships, US/UKalts, types of \n> > synonyms, antonyms (even) and these might be distinguished in some \n> > future super-KOS systems. Replacing\n> > the Equivalnce relationship with a simple 'bag of labels' \n> would lose that\n> > possibility.\n> >\n> > c) Also - in some cases a term will be considered \n> Equivalent to more \n> > than one concept (perhaps with different degrees of \n> confidence). Again \n> > that becomes less clearly stated.\n> >\n> >\n> >\n> > 8. Anyway, be interested to know your thoughts on all this - it's \n> > great that someone is proposing possible standards and \n> trying to reach \n> > concensus. The general thrust of the SKOS RDF schema is great. What \n> > are your plans for progressing it?\n> >\n> > One way of possibly progressing/discussing some of this \n> effort might \n> > be in (or associated with) an NKOS workshop at ECDL'04 in \n> Bath, this \n> > September. Marianne Nielsen is aiming to propose a workshop on \n> > user-centred issues and this might be a second (or parallel \n> > mini-meeting) theme?\n> >\n> > Hope to get a chance to talk at JISC workshop in London at \n> some point \n> > if you are attending for SWAD-Europe demo?\n> >\n> > regards\n> >\n> > Doug, Ceri\n> >\n> >\n> > Douglas Tudhope\n> > Reader, School of Computing\n> > University of Glamorgan\n> > Pontypridd CF37 1DL\n> > Wales, UK\n> >\n> > Tel  +44 (0) 1443-482271\n> > Fax  +44 (0) 1443-482715\n> > dstudhope@glam.ac.uk \n> http://www.comp.glam.ac.uk/pages/staff/dstudhope\n> > Editor : The New Review of Hypermedia and Multimedia\n> >\n> >\n> > ----- Original Message -----\n> > From: \"Miles, AJ (Alistair)\" <A.J.Miles@RL.AC.UK>\n> > To: <NKOS@dli2.nsf.gov>\n> > Sent: Tuesday, November 25, 2003 1:41 PM\n> > Subject: RDF schemas for thesauri and simple KOS *pre-release*\n> >\n> >\n> > > Dear all,\n> > >\n> > > I offer these schemas as a pre-release, to get some \n> initial feedback\n> > and\n> > > response on their design.\n> > >\n> > > SKOS-Core <http://www.w3c.rl.ac.uk/2003/11/21-skos-core> \n> (RDF schema\n> > for\n> > > encoding thesauri and other simple knowledge organisation systems \n> > > e.g. taxonomies and classification schemes.)\n> > >\n> > > SKOS-Mapping \n> <http://www.w3c.rl.ac.uk/2003/11/21-skos-> mapping> (RDF \n> > > \n> schema for expressing mappings between \n> concepts from different\n> > > thesauri.)\n> > >\n> > > This work is ongoing in the context of the SWAD-Europe project [1]\n> > [2].\n> > >\n> > > Yours,\n> > >\n> > > Alistair Miles.\n> > >\n> > > [1] SWAD-Europe Thesaurus Activity \n> > > <http://www.w3c.rl.ac.uk/SWAD/thesaurus.html>\n> > > [2] Semantic Web Advanced Development for Europe project \n> > > <http://www.w3.org/2001/sw/Europe/>\n> > >\n> > >\n> > > CCLRC - Rutherford Appleton Laboratory\n> > > Building R1 Room 1.60\n> > > Fermi Avenue\n> > > Chilton\n> > > Didcot\n> > > Oxfordshire OX11 0QX\n> > > United Kingdom\n> > >\n> > > Email:        a.j.miles@rl.ac.uk\n> > > Telephone: +44 (0)1235 445440\n> > >\n> >\n> >\n> >\n> \n> \n\n\n\n"
        },
        {
            "subject": "Layering and Sharedkey authenticatio",
            "content": "A lot of the arguments against shared secret client authentication\nseem to be layering arguments. Specifically, the argument seems to \nbe that shared secret style authentication properly belongs at the\napplication layer. While I feel that this argument has some force\nin principle, it seems to me to be deeply problematic in this specific\ncase, for a number of reasons:\n\n1. The security services that TLS provides to the application layer\nare inadequate for this purpose. The obvious approach to layering\nprotocols which require shared secret authentication over TLS \nis simply to pass the shared secret directly over the TLS channel,\nusing TLS as TCP has always been used. However, in the common case, \nTLS application layer data is encrypted with a 40 bit keyspace,\nwhich means that that's all the protection provided for the\nshared secret. Consequently, we either have to accept this limitation\nor the application needs to provide it's own protection for\nthe shared secret. \n\n\n2. Forcing applications to provide their own security argues against\nthe purpose of TLS. Much of the argument for TLS is that applications\ncan then be largely security oblivious while still taking advantage\nof security services. While data confidentiality for the data on the\nchannel is important, there is a lot of historical evidence that the\nprimary security need for e.g. telnet is actually access control, not\ndata confidentiality, and this is typically provided via a shared secret.\nIf TLS can't serve this need in an adequate way, then securing them\nwill require a lot more work than just layering them on top of\nTLS--at which point one might easily imagine providing an application\nspecific protocol which would meet that application's precise security\nneeds in a single package.\n\n\n3. There are a large number of common internet protocols which require\nshared secret style authentication, including but not limited to telnet,\nthe Berkeley r-protocols, NNTP under certain circumstances... So,\nwe're going to be reinventing this wheel a lot of times. This still\ndoesn't make it TLS's job, but it's hard to see who's job it is,\nthen.\n\n\n4. We've already violated this layering boundary. Public key style\nclient authentication isn't really a necessary part of TLS service\nprovision and could be easily handled at the application layer. This\nlayering argument would be a lot more convincing if we hadn't\nalready gone against it.\n\n-Ekr\n\n\n\n"
        },
        {
            "subject": "Re: FW: Recommended reading: feedback on SKOS from Doug Tudhope and C eri  Binding from University of Glamorga",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-02-25 13:59-0000]\n> \n> Forwarded to the list (message from Aida Slavic):\n> \n> (Aside: we need to figure out how to do facets properly - I've got a strong\n> feeling that the way we do it in SKOS-Core currently isn't quite right, 'tho\n> I don't know how to fix it yet).\n\nDoing facets seems to me to be getting into the territory already \ncovered by RDFS/OWL. Is there any way this could be couched as a bunch\nof test cases, with facets defined as RDF properties annotated in OWL,\nversus in a more traditional library-style thesaurus? And then mappings \nspecified, in prose or RDF...?\n\nI guess I'm wary that the ontology community might look at what we're\ndoing here and and say \"Hey, why are you re-inventing OWL?\", especially\nas we move from representing networks of named concepts to representing\nthe properties and classes that characterise the things those concepts\nstand for...\n\nAny thoughts on where/how to draw the line? \n\nDan\n\n\n\n"
        },
        {
            "subject": "Cracking the nut: separating semantics and structur",
            "content": "Here's a possible solution to the longstanding problem of overloaded\nsemantics in thesaurus-style relationships.\n\nWe have a set of properties for building a CONCEPTUAL STRUCTURE.  These\nstructural properties carry very weak semantics, if any.  The skos:narrower\nand skos:broader props allow organising concepts into a hierarchy.  The\nskos:related property allows associative links between branches of the\nhierarchy.  To reiterate, these props imply no semantics, they just allow\nbuilding of a structure, or to put it another way, structural organisation\nof concepts.\n\nWe have a second set of properties which carry well defined semantics.\nThere is one for the instantive (instance-of) relationship - rdf:type.\nThere is one for the generic (class subsumption) relationship -\nrdfs:subClassOf.  And there should be one for the partitive (part-of)\nrelationship - ??? (call it skos:partOf for now, although there must be some\nreference property we could use).\n\nSo then these two sets of props are the building blocks for all other props.\nFor example:\n\nskos:broaderInstantive\nrdfs:subPropertyOfskos:broader;\nrdfs:subPropertyOfrdf:type.\n\nskos:broaderGeneric\nrdfs:subPropertyOfskos:broader;\nrdfs:subPropertyOfrdfs:subClassOf.\n\nskos:broaderPartitive\nrdfs:subPropertyOfskos:broader;\nrdfs:subPropertyOfskos:partOf.\n\n(or the alternative structural rendering of the partitive relationship ...)\n\nskos:relatedPartOf\nrdfs:subPropertyOfskos:related;\nrdfs:subPropertyOfskos:partOf.\n\n... So each one of these properties has a structural component and a\nsemantic component, and these two components have been factored out.  That's\nthe idea.\n\nWhat does everyone think?\n\nAl.\n\n \n\n\n\n"
        },
        {
            "subject": "Test cases for faceted scheme",
            "content": "> Doing facets seems to me to be getting into the territory already \n> covered by RDFS/OWL. Is there any way this could be couched \n> as a bunch of test cases, with facets defined as RDF \n> properties annotated in OWL, versus in a more traditional \n> library-style thesaurus? And then mappings \n> specified, in prose or RDF...?\n> \n> I guess I'm wary that the ontology community might look at \n> what we're doing here and and say \"Hey, why are you \n> re-inventing OWL?\", especially as we move from representing \n> networks of named concepts to representing the properties and \n> classes that characterise the things those concepts stand for...\n> \n> Any thoughts on where/how to draw the line? \n> \n> Dan\n> \n\nAbsolutely!  I am very conscious not to tread on the toes of RDFS or OWL, or\nto re-invent or duplicate anything.  I want to use properties/classes from\nother vocabs whenever possible.  \n\nI think that a set of test cases is a very good idea - if anyone knows of\nfaceted schemes in the public domain, can they forward links to this list?\n\nThanks,\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Re: Cracking the nut: separating semantics and structur",
            "content": "Nope sorry, you've lost me here Al!\n\nWhat does 'skos:partOf' achieve for us, except for some sense of symmetry \nor completeness in terms of the structural model you're referring to?\nAnd what does \"skos:relatedPartOf\" actually mean - can you give me a \n\"real-world\" example of where this would be used to link two concepts?\nThe rest of it I'm fine with.\n\nApologies if I'm missing the obvious with my questions,\n\nNikki\n\n--On 25 February 2004 14:17 +0000 \"Miles, AJ (Alistair) \" \n<A.J.Miles@rl.ac.uk> wrote:\n\n>\n> Here's a possible solution to the longstanding problem of overloaded\n> semantics in thesaurus-style relationships.\n>\n> We have a set of properties for building a CONCEPTUAL STRUCTURE.  These\n> structural properties carry very weak semantics, if any.  The\n> skos:narrower and skos:broader props allow organising concepts into a\n> hierarchy.  The skos:related property allows associative links between\n> branches of the hierarchy.  To reiterate, these props imply no semantics,\n> they just allow building of a structure, or to put it another way,\n> structural organisation of concepts.\n>\n> We have a second set of properties which carry well defined semantics.\n> There is one for the instantive (instance-of) relationship - rdf:type.\n> There is one for the generic (class subsumption) relationship -\n> rdfs:subClassOf.  And there should be one for the partitive (part-of)\n> relationship - ??? (call it skos:partOf for now, although there must be\n> some reference property we could use).\n>\n> So then these two sets of props are the building blocks for all other\n> props. For example:\n>\n> skos:broaderInstantive\n> rdfs:subPropertyOfskos:broader;\n> rdfs:subPropertyOfrdf:type.\n>\n> skos:broaderGeneric\n> rdfs:subPropertyOfskos:broader;\n> rdfs:subPropertyOfrdfs:subClassOf.\n>\n> skos:broaderPartitive\n> rdfs:subPropertyOfskos:broader;\n> rdfs:subPropertyOfskos:partOf.\n>\n> (or the alternative structural rendering of the partitive relationship\n> ...)\n>\n> skos:relatedPartOf\n> rdfs:subPropertyOfskos:related;\n> rdfs:subPropertyOfskos:partOf.\n>\n> ... So each one of these properties has a structural component and a\n> semantic component, and these two components have been factored out.\n> That's the idea.\n>\n> What does everyone think?\n>\n> Al.\n>\n>\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Modelling 'entry terms' in SKO",
            "content": "Doug & Ceri wrote:\n> \n> 7. There is little notion here of the Entry Vocabulary, and \n> the various relationships between concepts and terms. Was \n> there a reason for this? It's a very important aspect of a \n> thesaurus and may(?) be a critical issue for gaining \n> acceptance of  a standard in some traditional thesaurus \n> circles. \n> \n> a) I see the general point and agree that the longterm \n> solution is making connections with standards in the \n> Linguistic community. However we would tend to argue that \n> relying only on labels results in an impoverished model of a \n> thesaurus? Essentially a thesaurus contains a pragmatic \n> domain-specific lexicon in the entry vocab, equivalence \n> relationships and scope notes. It's one of the reasons why \n> the thesaurus has been such a useful tool over many years and \n> arguably a weakness of some purely concept-based \n> 'ontological' efforts. Could we bring in some version of the \n> Equivalence relationship to SKOS, or alternatively have more \n> properties regarding terms?\n> \n\nI always assumes that the set of altLabels for a concept would constitute\nthe entry vocabulary (entry terms) for a concept.  So for example (from GCL\n[1]):\n\n<skos:Concept rdf:about=\"[someURI]\">\n<skos:prefLabel>Equal opportunities and diversity</skos:prefLabel>\n<skos:altLabel>Positive discrimination (equal\nopportunities)</skos:altLabel>\n<skos:altLabel>Racial discrimination (education\nopportunities)</skos:altLabel>\n<skos:altLabel>Racial discrimination (employment\nopportunities)</skos:altLabel>\n<skos:altLabel>Racial equality</skos:altLabel>\n<skos:altLabel>Religious discrimination (education and\nemployment)</skos:altLabel>\n<skos:altLabel>Sexual discrimination (education\nopportunities)</skos:altLabel>\n<skos:altLabel>Sexual discrimination (employment\nopportunities)</skos:altLabel>\n<skos:altLabel>Discrimination by sex, race, religion\netc.</skos:altLabel>\n<skos:altLabel>Diversity (equal opportunities)</skos:altLabel>\n<skos:altLabel>Affirmative action (equal\nopportunities)</skos:altLabel>\n<skos:inScheme rdf:resource=\"[URI of GCL]\"/>\n</skos:Concept>\n\nAl.\n\n[1] http://www.govtalk.gov.uk/schemasstandards/gcl.asp\n\n\n\n"
        },
        {
            "subject": "RE: Cracking the nut: separating semantics and structur",
            "content": "OK, I'm NOT actually suggesting we actually add a property 'skos:partOf'.\nThere must be a property somewhere in some standard vocab that expresses at\na high level the 'part of' relationship between two things (i.e. 'wheel' is\na part of 'vehicle', 'bones' part of 'skeleton', apologies for naff examples\nbut I'm making this up as I go :) - which in turn could be extended into\n'geographical part of' 'physical part of' 'logical part of' etc..\n\nThe dcterms:isPartOf property might be a candidate for this, which is\ndefined as follows: 'The described resource is a physical or logical part of\nthe referenced resource.' ?? [1]\n\nThe point is, in some thesauri the 'part of' relationships are part of the\nhierarchy, and in others they are modelled as associative links between\nconcepts in different branches of the hierarchy.\n\nSo there are two types of information to convey.  The semantic relationship\nbetween two concepts (i.e. instance-of, sub-class-of, part-of) and how you\nwant that relationship to be displayed as part of a structure (i.e.\nhierarchical or associative).  So we split these apart using two sets of\nhigh-level properties.  Extensions can then recombine these properties in\ndifferent ways to create properties that organise the same semantic\nrelationships differently (e.g. 'part of' as hierarchical or associative).\nThat was the idea.\n\nIt was also a way of linking the SKOS vocab to RDF and RDFS (first step\ntowards understanding interop and migration between thesauri and\nontologies).\n\nAl.    \n\n[1] http://dublincore.org/documents/dcmi-terms/\n\n> -----Original Message-----\n> From: NJ Rogers, Learning and Research Technology \n> [mailto:Nikki.Rogers@bristol.ac.uk] \n> Sent: 25 February 2004 14:36\n> To: Miles, AJ (Alistair); 'public-esw-thes@w3.org'\n> Subject: Re: Cracking the nut: separating semantics and structure\n> \n> \n> \n> Nope sorry, you've lost me here Al!\n> \n> What does 'skos:partOf' achieve for us, except for some sense \n> of symmetry \n> or completeness in terms of the structural model you're \n> referring to? And what does \"skos:relatedPartOf\" actually \n> mean - can you give me a \n> \"real-world\" example of where this would be used to link two \n> concepts? The rest of it I'm fine with.\n> \n> Apologies if I'm missing the obvious with my questions,\n> \n> Nikki\n> \n> --On 25 February 2004 14:17 +0000 \"Miles, AJ (Alistair) \" \n> <A.J.Miles@rl.ac.uk> wrote:\n> \n> >\n> > Here's a possible solution to the longstanding problem of \n> overloaded \n> > semantics in thesaurus-style relationships.\n> >\n> > We have a set of properties for building a CONCEPTUAL STRUCTURE.  \n> > These structural properties carry very weak semantics, if any.  The \n> > skos:narrower and skos:broader props allow organising \n> concepts into a \n> > hierarchy.  The skos:related property allows associative \n> links between \n> > branches of the hierarchy.  To reiterate, these props imply no \n> > semantics, they just allow building of a structure, or to put it \n> > another way, structural organisation of concepts.\n> >\n> > We have a second set of properties which carry well defined \n> semantics. \n> > There is one for the instantive (instance-of) relationship \n> - rdf:type. \n> > There is one for the generic (class subsumption) relationship - \n> > rdfs:subClassOf.  And there should be one for the partitive \n> (part-of) \n> > relationship - ??? (call it skos:partOf for now, although \n> there must \n> > be some reference property we could use).\n> >\n> > So then these two sets of props are the building blocks for \n> all other \n> > props. For example:\n> >\n> > skos:broaderInstantive\n> > rdfs:subPropertyOfskos:broader;\n> > rdfs:subPropertyOfrdf:type.\n> >\n> > skos:broaderGeneric\n> > rdfs:subPropertyOfskos:broader;\n> > rdfs:subPropertyOfrdfs:subClassOf.\n> >\n> > skos:broaderPartitive\n> > rdfs:subPropertyOfskos:broader;\n> > rdfs:subPropertyOfskos:partOf.\n> >\n> > (or the alternative structural rendering of the partitive \n> relationship\n> > ...)\n> >\n> > skos:relatedPartOf\n> > rdfs:subPropertyOfskos:related;\n> > rdfs:subPropertyOfskos:partOf.\n> >\n> > ... So each one of these properties has a structural \n> component and a \n> > semantic component, and these two components have been \n> factored out. \n> > That's the idea.\n> >\n> > What does everyone think?\n> >\n> > Al.\n> >\n> >\n> >\n> >\n> \n> \n> \n> ----------------------\n> NJ Rogers, Technical Researcher\n> (Semantic Web Applications Developer)\n> Institute for Learning and Research Technology (ILRT) \n> Email:nikki.rogers@bristol.ac.uk\n> Tel: +44(0)117 9287096 (Direct)\n> Tel: +44(0)117 9287193 (Office)\n> \n\n\n\n"
        },
        {
            "subject": "RE: Cracking the nut: separating semantics and structur",
            "content": "Al,\n\nWhat matters is the functionality\nin management of vocabulary (for IR and mapping)\nthat arises from the coding of semantic(hierarchy)\nand coding of structure (encoding facets).\nCoding facets is about coordination and combination\nof concepts that comes from different 'parallel' hierarchies.\n\nCoding of structure is rarely relevant for thesauri as they are\npost-coordinated\nsystem which means that one assigns independent descriptors to the resource\nand you combine terms together using Booleans in the process of searching.\n\nHowever:\n\neducation <for> computing\nis not the same as\ncomputing <in> education\n\nbibliography <of> encyclopaedia\nis not the same as\nencyclopaedia <of> bibliography\n\npainting <in> Italy\nis not the same as\nItaly<ian> painting\n\nTo dumb this down:  thesauri and classifications are indexing\nlanguages and to speak the language you need semantic to know which 'terms'\nto use\nand you need structure/syntax to know how to put a sentence together\n\n\nSemantic relationships (isKindof;isPartof) are easy to handle\nand it is clear why do we need this in SKOS (broading and narrowing the\nmeaning)\n\nWhat may not be so obvious is why traditioanl KOS also need structure/syntax\ncoding for\nfacets/subfacets. And I don't know whether this is relevant\nfor SKOS i.e is the subPropertyOf the way to address this...\n\n\nFacet encoding using 'facet indicators'has two functions\nin KOS:\na) management/interface design/browsing\none needs to know know that some concept coming from facet of PLACE or TIME\nor\nMATERIAL (this is shortcut as this may be 10/11 steps up in hierarchy from\nthe concept\nin question)\n\nb) buidling composite expressions (compound concept)depends on the fact\nthat there is a declaration from which facet the concept comes (i.e.material\nor\ntime or process or operation or agent)\n\nthe order one combines concepts from different coordinated facets is\nusually established and has to result in specific to\ngeneral/concrete/abstract\nsequence\nThis enables display and ordering of subject from general to\nspecific, and enables the control over so called phase relationships\n(the influence/application of one subject on the other, comparison\nof one subject with another as given in the example above)\nSo when combined concepts follow the specific order thing-kind-part-property\netc.\nalso\nWhen two concepts comes from equal type e.g. facet of entity a 'treated'\nsubject\nis always cited first and subject of treatement\nis always second.... e.g. statistics>history ...means the history of\nstatistics\nhistory>statistics, means the application of statistics in the field of\nhistorical studies\n\n Aida\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Miles, AJ (Alistair)\n>\n> Sent: 25 February 2004 14:18\n> To: 'public-esw-thes@w3.org'\n> Subject: Cracking the nut: separating semantics and structure\n>\n>\n>\n> Here's a possible solution to the longstanding problem of overloaded\n> semantics in thesaurus-style relationships.\n>\n> We have a set of properties for building a CONCEPTUAL STRUCTURE.  These\n> structural properties carry very weak semantics, if any.  The\n> skos:narrower\n> and skos:broader props allow organising concepts into a hierarchy.  The\n> skos:related property allows associative links between branches of the\n> hierarchy.  To reiterate, these props imply no semantics, they just allow\n> building of a structure, or to put it another way, structural organisation\n> of concepts.\n>\n> We have a second set of properties which carry well defined semantics.\n> There is one for the instantive (instance-of) relationship - rdf:type.\n> There is one for the generic (class subsumption) relationship -\n> rdfs:subClassOf.  And there should be one for the partitive (part-of)\n> relationship - ??? (call it skos:partOf for now, although there\n> must be some\n> reference property we could use).\n>\n> So then these two sets of props are the building blocks for all\n> other props.\n> For example:\n>\n> skos:broaderInstantive\n> rdfs:subPropertyOfskos:broader;\n> rdfs:subPropertyOfrdf:type.\n>\n> skos:broaderGeneric\n> rdfs:subPropertyOfskos:broader;\n> rdfs:subPropertyOfrdfs:subClassOf.\n>\n> skos:broaderPartitive\n> rdfs:subPropertyOfskos:broader;\n> rdfs:subPropertyOfskos:partOf.\n>\n> (or the alternative structural rendering of the partitive\n> relationship ...)\n>\n> skos:relatedPartOf\n> rdfs:subPropertyOfskos:related;\n> rdfs:subPropertyOfskos:partOf.\n>\n> ... So each one of these properties has a structural component and a\n> semantic component, and these two components have been factored\n> out.  That's\n> the idea.\n>\n> What does everyone think?\n>\n> Al.\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "FW: Recommended reading: feedback on SKOS from Doug Tudhope and Ceri Binding from University of Glamorga",
            "content": ">> -----Original Message-----\n>> From: Aida Slavic [mailto:aida@acorweb.net]\n>> Sent: 24 February 2004 17:23\n>> Just in case you are not familiar with this....\n>>\n>> D. Tudhope and C.Binding may be referring to the terminology\n>> adopted by UK CRG (Classification Research Group). In this\n>> framework mutually exclusive categories of concepts are\n>> organized on the level of subfacets and not on the level of facets.\n\nJust a word to clarify this. My understanding of this is that facets are \nmutually exclusive (a concept cannot belong to more than one) and that \nthe concepts within a facet can be arranged into arrays, each array \nhaving a specified \"characteristic of division\" (e.g. \"vehicles _by_ \nnumber of wheels\").\n\n >> CRG operates with terms of\n>> - BROAD FACETS (defined subject area)\n>> - FACETS (13 fundamental facets: thing - kind - part -\n>> property - material - process - operation - patient - product\n>> - by-product - agent - space - time )\n>> - SUBFACETS(array)\n>> - FOCI(i.e. concepts)\n\nI think it is better not to use the expressions \"broad facets\" or \n\"subfacets\", because this implies that these are kinds of facets. This \nis not accurate because they do not share all the characteristics of \nfacets, in particular mutual exclusivity. I therefore prefer to use the \nexpressions \"subject areas\" (or \"subject  categories\" or \"subject \nclasses\") and \"arrays\".\n\nWe have a further complication with the definition of facet. I prefer \nthe definition used in the draft British Standard that Stella referred \nto, where she said:\n\n>Some facets commonly used in  thesauri include Activities, Agents, \n>Objects, Materials,  Organisms, Places, Times. Normally, a concept that \n>belongs to  one of these facets cannot belong to any of the others, \n>because they are such fundamentally different things.\n\nIn this definition facets are fundamentally different categories of \nconcepts, assuming that we interpret \"agents\" as meaning \"people and \norganisations\" and ignore the fact that people are organisms. An object \nis presumably distinguished from a material by having a shape.\n\nHowever, the list of \"13 fundamental facets\" that Aida quotes above \n(thing - kind - part - property - material - process - operation - \npatient - product - by-product - agent - space - time) is not based on \njust what concepts _are_ but is partly dependent on the _role_ they play \nin a subject string representing a combination of concepts.\n\nThe same concept could, in different strings, be a material, a product \nor a by-product, for example, so, as Stella points out, mutual \nexclusivity then breaks down.\n\nI wonder, therefore, whether we should avoid using the term \"facets\" for \nthe 13 elements in the list above, and say just that this specifies a \nuseful citation order of concepts according to their roles.\n\nIt is very difficult to decide which definition should claim the right \nto the term \"facet\", but I think it is important to pin it down to a \nsingle meaning, as I'm sure that its varied and loose use in the past \nhas contributed to a lot of confusion and lack of clarity in \ncommunication.\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Dhip Sotb wrote:\n> \n> We have a large Kerberos infrastructure that I like to see\n> supported in some manner by TLS rather than implementing\n> yet another key management solution.\n> \n> Put me in the pro symmetric column.\n> \n> dhip\n\n\nI am not sure that shared key as persented will automatically support\nthings like kerberos. There may be room for multiple authentication\nschemes, however.\n\n-- \nTaher\n\n\n\n"
        },
        {
            "subject": "RE: Recommended reading: feedback on SKOS from Doug Tudhope and Ceri Binding from University of Glamorga",
            "content": "Leonard,\n\n> I think it is better not to use the expressions \"broad facets\" or\n> \"subfacets\", because this implies that these are kinds of facets. This\n> is not accurate because they do not share all the characteristics of\n> facets, in particular mutual exclusivity. I therefore prefer to use the\n> expressions \"subject areas\" (or \"subject  categories\" or \"subject\n> classes\") and \"arrays\".\n\nI agree. And I don't think this complication is helpful.\nI only tried to interpret the way Jack\nMills and Vanda Broughton seems to be operating with this terms\nin BC2 (13 fundamental facets on which they base citation order).\nAnd I got impression that Doug and Ceri were referring to this.\nI also spoke to Vanda about this recently and she confirmed\nthat there is no agreement on this. They use their structure as\nthis help them doing their job.\n\nFor the rest of the world the definition of facet is best when pinned on the\nlevel where it is functional and acceptable for everyone:\ni.e. on the level of mutually exclusive classes, where the facet\nis defined as the result of a division by a single criterion.\n\n> >Some facets commonly used in  thesauri include Activities, Agents,\n> >Objects, Materials,  Organisms, Places, Times. Normally, a concept that\n> >belongs to  one of these facets cannot belong to any of the others,\n> >because they are such fundamentally different things.\n\nAs you say the problem is not on here but on the level when we have\nsubdivision of e.g.  so-called-facet Materials ...\n\nmaterials by origin\nOrigin1\nOrigin2\nOrigin3\n\nmaterials by function\nFunction1\nFunction2\nFunction3\n\nRESULT: in this arrangement one can make logical combination:\nOrigin1Function2\nIf 'MATERIAL' contains further mutually exclusive division\n(by origin, by function etc.) it seems not to be technically a facet itself.\nIf Material would be a 'facet' in the pure sense (i.e. production of\ndivision by a single\ncriterion) combination of concepts within it would not make logical sense as\nthey\nwould be mutually exclusive.\n\n>I wonder, therefore, whether we should avoid using the term \"facets\" for\n>the 13 elements in the list above, and say just that this specifies a\n>useful citation order of concepts according to their roles.\n\nBy all means!!!\nThe best way would be IMHO to let facet be what it logically and\ntechnically is - and then find a proper name for concept categories above it\nsuch as Activities, Agents, Objects, Materials,  Organisms, Places, Times\n['concept categories' or 'fundamental concept categories']\n\n\n> It is very difficult to decide which definition should claim the right\n> to the term \"facet\", but I think it is important to pin it down to a\n> single meaning, as I'm sure that its varied and loose use in the past\n> has contributed to a lot of confusion and lack of clarity in\n> communication.\n\nAgreed. This discussion repeats every now and then on several lists.\nLast time it was on facetedclassification list when people were confused\nwith definition of 'fundamental' facets and whether they are facets at all\nwith respect to what facet should technically be and how it should be\nrepresented\nwith an ontology mark-up language.\n\n\nAida\n\n\n\n"
        },
        {
            "subject": "Definition of &quot;facet&quot",
            "content": "In message <AAEKLFPLCPPCFCOACDKIEEIECJAA.aida@acorweb.net> on Thu, 26\nFeb 2004, Aida Slavic <aida@acorweb.net> wrote\n> the definition of facet is best when pinned on the level where it is\n>functional and acceptable for everyone: i.e. on the level of mutually\n>exclusive classes, where the facet is defined as the result of a division by a\n>single criterion.\n>\n>> >Some facets commonly used in  thesauri include Activities, Agents,\n>> >Objects, Materials,  Organisms, Places, Times. Normally, a concept that\n>> >belongs to  one of these facets cannot belong to any of the others,\n>> >because they are such fundamentally different things.\n>\n>As you say the problem is not on here but on the level when we have\n>subdivision of e.g.  so-called-facet Materials ...\n>\n>materials by origin\n>       Origin1\n>       Origin2\n>       Origin3\n>\n>materials by function\n>       Function1\n>       Function2\n>       Function3\n>\n>RESULT: in this arrangement one can make logical combination:\n>Origin1Function2\n\nI would describe this as the organisation of concepts within the\nmaterials facet into arrays, each according to a specified criterion of\ndivision. A concept may occur in two or more of these arrays and may\noccur more than once within a single array.\n\nFor example you can have:\n\n<materials by origin>\n        animal materials\n                animal fat\n        inorganic materials\n                mineral oil\n        vegetable materials\n                sunflower oil\n\n<materials by function>\n        foodstuffs\n                animal fat\n                sunflower oil\n        fuels\n                animal fat\n                mineral oil\n                sunflower oil\n        lubricants\n                animal fat\n                mineral oil\n\n>If 'MATERIAL' contains further mutually exclusive division (by origin, by\n>function etc.) it seems not to be technically a facet itself.\n\n>If Material would be a 'facet' in the pure sense (i.e. production of division by\n>a single criterion) combination of concepts within it would not make logical\n>sense as they would be mutually exclusive.\n\nI don't really follow this. You could argue that \"materials\" is one of\nthe mutually-exclusive groups you would create if you divided the\nuniverse of concepts by the criterion of the \"fundamental category\" to\nwhich they belong. Alternatively, you could argue that \"materials\" is a\ntop-level term which you would reach if you built a hierarchical tree\nfrom the bottom upwards, and could then go no further, i.e. it is one of\nthe small number of ultimate \"top terms\" that you would reach if you\ncombined all concepts into trees on the \"is-a\" (generic) relationship.\n\nBoth of these approaches lead me to think that it is useful to use the\nexpression \"facets\" for these groups or ultimate top terms.\n\nI agree that different people may derive slightly different sets of\nfacets by these methods. \"People\" and \"organisations\" might be\nconsidered as separate facets or as concepts within a more general facet\nof \"people and organisations\"[1]; \"people\" might be considered as a\nconcept within the more general facet of \"organisms\". But in most cases\nI think it is possible to define a useful set of mutually exclusive\nfacets in this way.\n\n>>I wonder, therefore, whether we should avoid using the term \"facets\" for\n>>the 13 elements in the list above, and say just that this specifies a\n>>useful citation order of concepts according to their roles.\n>\n>By all means!!! The best way would be IMHO to let facet be what it logically\n>and technically is\n\nBut I'm not sure what you are saying that it \"logically and technically\"\nis. Do you want to use the term \"facet\" for what I have called an\n\"array\"?\n\n> - and then find a proper name for concept categories above it\n>such as Activities, Agents, Objects, Materials,  Organisms, Places, Times\n>['concept categories' or 'fundamental concept categories']\n\nThese concept categories are what my reasoning above leads me to call\n\"fundamental facets\", or preferably just \"facets\", to avoid the\ncomplication and confusion of having different kinds of facets.\n\n>This discussion repeats every now and then on several lists. Last time it\n>was on facetedclassification list when people were confused with\n>definition of 'fundamental' facets and whether they are facets at all with\n>respect to what facet should technically be and how it should be\n>represented with an ontology mark-up language.\n\nYes, and I think we have to come to some clear consensus or we shall\ncontinue to confuse the folk who are seeking definitive statements on\nthese structures in order to build them into the unforgiving syntax of\nmachine communication formats.\n\nLeonard\n\n[1] It is unfortunate that we don't have a convenient word to encompass\n\"people and organisations\". \"Agents\" is not good, because it implies an\nactive role and distinguishes them from \"patients\", i.e. the things\nacted upon, which is not intended here. \"Bodies\" implies dead bodies or\ncorporate bodies.\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Modelling 'entry terms' in SKO",
            "content": "> I always assumes that the set of altLabels for a concept would constitute\n> the entry vocabulary (entry terms) for a concept.\nYes  -- we didn't mean to imply that there was no entry vocabulary.\n\nWe wanted to raise as a possible limitation what seem to be the omission of\nthe\nexplicit thesaurus Equivalence relation.\n\nThe alt labels do allow access points to the concept by any of the\nalternates and thus do allow an entry vocabulary - which is certainly a key\npoint.\nHowever there are some other possibilities that may be more difficult to\nimplement without explicit equivalence relationships.\n- various subtypes of equivalence corresponding to\nparts-of-speech relationships, US/UKalts, types of synonyms, antonyms (even)\n- in some cases a term can be considered Equivalent to more than\none concept (perhaps with different degrees of confidence).\n\nI guess these are more future application possibilities, might\nbe considered as less 'core' and we may be in danger of over-elaborating.\nHowever if we go on to extend the current core thesaurus\nrelationships by specialisation then we might also want to distinguish\nsubtypes of equivalence. This might be easier if there was an explicit\nequivalence relationship.\n\nI'm not sure how important this is but the general question is are there\nconsequences in not representing Equivalence explicitly ?\n\nDoug\n\n\n\n"
        },
        {
            "subject": "Re: Definition o",
            "content": "I think it might be possible to reach agreement on some basic first steps\nand terminology? As some starting suggestions picking up on what people have\nsaid:\n\n1. Leonard's basic definition of 'facet' as mutually exclusive\ngroupings with internal hierarchies of concepts is something widely agreed\nthat could be essentially captured in the core SKOS.\n> \"Just a word to clarify this. My understanding of this is that\n> facets are mutually exclusive (a concept cannot belong to more than one)\nand that\n> the concepts within a facet can be arranged into arrays, each array\n> having a specified \"characteristic of division\" (e.g. \"vehicles _by_\n> number of wheels\").\"\n\nI think this is what is currently intended in the SKOS scheme? - we were\nessentially querying details of the RDF encoding in our initial feedback.\n\n2. We can make the distinction between 'facets' in this sense and 'arrays'\nby characteristics of division as above (avoiding use of the term 'facet'\nfor arrays, although some people have used it this way). Arrays by\ncharacteristics of division could be an option to include in SKOS Core but I\nthink they are less crucial in a core scheme.\n\n3. I take Stella's point about sometimes mutual exclusivity breaking down in\nreal world knowledge systems. My reading was that this is a separate issue\nfrom the 13 CRG categories that could (occasionally) occur within any mutual\nexclusive knowledge structure that is poly-hierarchical. It would be\nminimised by a good facet organisation but might occur in contexts like\nStella's examples. I don't see any way round this (and I don't think it\nshould hold us back), except that we might have another optional property\nfor a concept to express the notion that, although occuring in a faceted\nsystem, this was an exception as regards exclusivity?\n\n4. We can make a distinction between\na) the general notion of mutually exclusive (hierarchical) facet structures\n(as in 1 above) - without detailing any specific top level names\n\nb) a possible set of useful, commonly occuring 'fundamental\ncategories/facets' - eg\nthe 13 CRG categories Aida described - (thing - kind - part - property -\nmaterial - process - operation - patient - product - by-product - agent -\nspace - time) - or Ranganathan's smaller PMEST set. These can be mapped to\nparticular facets in particular thesauri and have possibilities for acting\nas a super-structure bridging between different KOS. They also allow us to\nexpress some idea of role within a string as Leonard says.\n\nI think that it might be easier to start in the basic SKOS with just the\nnotion (a) above and leave (b) for higher level frameworks.\n\nThe (later) higher level framework could allow the definition of how concept\nmembers of facets can be combined togther in strings in a particular KOS or\nparticular KOS application (the synthesis rules). Also it might allow the\nspecification of a particular set of fundamental catgeories/facets.\n\nEg perhaps the SKOS RDF could define that there is something called a\nfacet and that a corresponding OWL or RDFS would capture the mutual\nexclusivity - this may have been (roughly) what Dan was intending?\n> \".. facets defined as RDF properties annotated in OWL,\n> versus in a more traditional library-style thesaurus? And then mappings\n> specified, in prose or RDF...?\"\n\n5. I do think its important to have the basic idea of mutually exclusive\nfacets in the core KOS representation. It would allow different applications\nto make use of the notion in different ways, drawing on a common\nrepresentation.\nHowever I'm not sure that making it a sub-property of the standard 'broader'\nproperty is quite right - is another type of property more appropriate? The\ncurrent scheme intends I think that the facet be represented  by the concept\nat the top of the hierarchy? The issue might boil down to whether it is\nbetter to introduce another entity, 'facet', in addition to 'concept' - or\njust to make do with 'concepts' only? -- perhaps Al can correct me if I have\nmisunderstood the intentions of the current scheme. Our thought was that\nintroducing a second entity for facet might be more flexible for future\ndevelopments.\n\nThis may be a fairly fine detail in the general SKOS scheme which does seem\nto be getting close to the basic notion of facet if  the mutual exclusivity\ncan be covered in Owl.\n\nDoug\n\n\n\n"
        },
        {
            "subject": "RE: Definition of &quot;facet&quot",
            "content": "[I sent this to Leonard yesterday, I meant to send it\nto the list...\nI think Doug's mail today brought us closer to the\nagreement]\n\n-----Original Message-----\nFrom: Aida Slavic [mailto:aida@acorweb.net]\nSent: 26 February 2004 18:18\nTo: Leonard Will\nSubject: RE: Definition of \"facet\"\n\n\nLeonard,\n\nI don't think anyone care how things are called as far as\nwe have the possibility to encode and manage both:\ntop level categories (?facet) and  subdivisions (?arrays) within those\nIn one of my mails yesterday I tried to explain why do we need coding\nof this structure for managing vocabularies\n\n> Both of these approaches lead me to think that it is useful to use the\n> expression \"facets\" for these groups or ultimate top terms.\n\nI would like to check whether I understood this properly. Do\nyou suggest that we call simply FACETS the following?:\n\nfrom Stella definition applied in thesauri:\nActivities/Agents/Objects/Materials/Organisms/Places/Times\n\nMills/Broughton applied in BC2:\n\nThing/kind/part/property/material/process/operation/patient/product/by-produ\nct/agent/space/time\n\nRanganathan applied in CC:\npersonality/matter/energy/space/time\n\nCoates,Lloyd, Simandl applied in BSO:\ntools/operations/processes/parts/objects of study, or product, or total\nsystem\n\nUniversal Decimal Classification (common concepts + facets):\ncommon concepts: processes/properties/materials/persons/ethnic\ngrouping/time/space/form/language\nusual facets within disciplines:\nthings/kind/part/property/material/processes/operation/product/agent/\n\nAnd that division that comes under these should be called ARRAYS???\n\nIf so I can see the following\n- advantage\nThis terminology will easily be understood by people from bibliographic\ndomain... especially here in UK. Classificationists and those building\nthesauri will be at ease with this.\n\n-disadvantage\na)  This kind of terminology/definition is arbitrary and based on assumption\nthat everyone knows that the facet of this kind is based on the\ntheory of fundamental/general facet categories\n\nb) as 'facet' is usually defined technically as a result of a division by\na single criterion ..most of people outside bibliographic world expect\nthat content of 'facet' would be a simple list of mutually exclusive\nconcepts.\n\nI think the mail I got from P. Murray illustrate well this last point...\n\n<snip>\nImplementations of \"faceting\" grounded in library science often take the\nform of subdividing a class by characteristics -- for example:\n\nPersons according to sex and Persons according to family or other kinship\nrelation (Source: \"Facet Analytical Theory for Managing Knowledge Structure\nfor Humanities,\" http://www.ucl.ac.uk/fatks/o_person.htm, 04-sep-2003).\nPeople by gender and people by occupation (Art & Architecture Thesaurus\nBrowser,\nhttp://www.getty.edu/research/tools/vocabulary/aat/hierarchies.html)\n\n\"Both of these examples are described as examples of \"faceted\" approaches.\nBut I find that these examples are inconsistent with my understanding of\nbasic principles of faceting and appear not to map well to principles in\ndevelopment of computer ontologies.\n\nFrom my perspective, Persons according to sex is already a composite term\n(composite subject) -- persons + gender. Same for people by occupation --\npeople + occupation. Occupation could clearly be a hierarchical facet by\nitself.\nOf course, in a large general-purpose knowledge-organization system,\nimplementing a faceted schema using my interpretation might lead to a\nsubstantial proliferation of discrete facets (Human kinship or kinship among\nliving organisms might be just one; using Relationships as a facet might be\ntoo abstract.). But in business environments, the number of relevant facets\nis usually quite manageable -- for example, in a computer software company,\na useful set of facets might include Actions, Business Roles, Events,\nFunctional Roles, Business Goals, Information Objects, Organizations,\nPeople, Products, Services, and Vertical Markets.\n\nFoskett asserts that an analysis of facets is correct if foci\n(topics/concepts in context within a facet) are mutually exclusive -- \"that\nis, we cannot envisage a composite subject which consists of two foci from\nthe same facet.\" (A.C. Foskett, The Subject Approach to Information.) But in\none of the examples above, it appears that you can create the composite\nsubject male cousins.\n\nIn my understanding of faceted knowledge organization, inheritance of\nproperties is implied in facet hierarchies, but inheritance (especially\ninheritance of all properties) is not formally specified in any examples of\nfaceted classification I have seen. In computer \"ontologies,\" however,\ninheritance of properties is usually considered a basic formal requirement:\n\"Properties become more useful for knowledge modeling when they are\nspecified at a general class level and then inherited consistently by\nsubclasses and instances.\" (Deborah L. McGuinness, \"Ontologies Come of Age,\"\np. 177, in  Fensel et al, editors, Spinning the Semantic Web.) What do\nexperts like yourself believe about the role of inheritance in facets?\n</snip>\n\n\n\n"
        },
        {
            "subject": "Re: Definition of &quot;facet&quot",
            "content": "In message <AAEKLFPLCPPCFCOACDKIMEJDCJAA.aida@acorweb.net> on Fri, 27\nFeb 2004, Aida Slavic <aida@acorweb.net> wrote\n>\n>I don't think anyone care how things are called as far as we have the\n>possibility to encode and manage both: top level categories (?facet) and\n>subdivisions (?arrays) within those In one of my mails yesterday I tried to\n>explain why do we need coding of this structure for managing\n>vocabularies\n\nAgreed. I don't mind what they are called so long as we all call them\nthe same!\n\n>> Both of these approaches lead me to think that it is useful to use the\n>> expression \"facets\" for these groups or ultimate top terms.\n>\n>I would like to check whether I understood this properly. Do\n>you suggest that we call simply FACETS the following?:\n>\n>       from Stella definition applied in thesauri:\n>       Activities/Agents/Objects/Materials/Organisms/Places/Times\n\nYes, in principle, though any list of this kind is an example and cannot\nbe definitive.\n\nI go along with the AAT definition\n<http://www.getty.edu/research/conducting_research/vocabularies/aat/about\n.html> which reads:\n\n\"Facets constitute the major subdivisions of the AAT hierarchical\nstructure. A facet contains a homogeneous class of concepts, the members\nof which share characteristics that distinguish them from members of\nother classes. For example, the term marble refers to a substance used\nin the creation of art and architecture, and it is found as a preferred\nterm (descriptor) in the Materials facet. The term Impressionist denotes\na visually distinctive style of art, and it is listed as a preferred\nterm in the Styles and Periods facet.\n\nFacets and Hierarchies in the AAT:\n\nASSOCIATED CONCEPTS FACET\nPHYSICAL ATTRIBUTES FACET\nSTYLES AND PERIODS FACET\nAGENTS FACET\nACTIVITIES FACET\nMATERIALS FACET\nOBJECTS FACET\"\n\nThis doesn't say anything about roles.\n\n>       Mills/Broughton applied in BC2:\n>Thing/kind/part/property/material/process/operation/patient/product/by-\n>product/agent/space/time\n\nI'm not so happy about calling these \"facets\", because some of them\ndepend on the role that something has rather than the fundamental\ncategory to which it belongs. This is a rule for citation order, in\nwhich I would say that the \"thing\" or \"material\" facets may occur more\nthan once, as \"thing\", \"material\", \"patient\", \"product\" and \"by-product\"\nfor example. Your other examples below are versions of this, or mixtures\nof the \"role\" and \"category\" criteria, and thus unsatisfactory in\nprinciple. That's not to say that they don't work in practice, because\nhumans can live with a certain amount of fuzziness; it's when you try to\ntighten this up so that machines can understand it that the anomalies\nbecome evident.\n\n>       Ranganathan applied in CC:\n>       personality/matter/energy/space/time\n\n>       Coates,Lloyd, Simandl applied in BSO:\n>       tools/operations/processes/parts/objects of study, or product, or\n>total system\n>\n>       Universal Decimal Classification (common concepts + facets):\n>       common concepts: processes/properties/materials/persons/ethnic\n>grouping/time/space/form/language\n>       usual facets within disciplines:\n>things/kind/part/property/material/processes/operation/product/agent/\n>\n>And that division that comes under these should be called ARRAYS???\n\nYes.\n\n>If so I can see the following\n>- advantage\n>This terminology will easily be understood by people from bibliographic\n>domain... especially here in UK. Classificationists and those building\n>thesauri will be at ease with this.\n>\n>-disadvantage\n>a)  This kind of terminology/definition is arbitrary and based on\n>assumption that everyone knows that the facet of this kind is based on the\n>theory of fundamental/general facet categories\n>\n>b) as 'facet' is usually defined technically as a result of a division by\n>a single criterion ..most of people outside bibliographic world expect\n>that content of 'facet' would be a simple list of mutually exclusive\n>concepts.\n\nWe have problems because people from different backgrounds interpret\nterms differently. My point is that even if these terms have been used\nwith different meanings by respected authorities in the past, that is\nnot a reason not to try to rationalise the situation now and restrict\nthe terms to a single, well-defined meaning.\n\n>I think the mail I got from P. Murray illustrate well this last point...\n>\n><snip>\n>Implementations of \"faceting\" grounded in library science often take the\n>form of subdividing a class by characteristics -- for example:\n>\n>Persons according to sex and Persons according to family or other kinship\n>relation (Source: \"Facet Analytical Theory for Managing Knowledge Structure\n>for Humanities,\" http://www.ucl.ac.uk/fatks/o_person.htm, 04-sep-2003).\n\n>People by gender and people by occupation (Art & Architecture Thesaurus\n>Browser,\n>http://www.getty.edu/research/tools/vocabulary/aat/hierarchies.html)\n>\n>\"Both of these examples are described as examples of \"faceted\" approaches.\n>But I find that these examples are inconsistent with my understanding of\n>basic principles of faceting and appear not to map well to principles in\n>development of computer ontologies.\n\nIndeed. I think that there is a distinction between the definition of\n\"facet\" and the broader concept of \"facet analytical theory\" or \"faceted\napproaches\"; this broader concept includes the idea of organising arrays\nof sibling concepts according to defined characteristics of division.\n\n>From my perspective, Persons according to sex is already a composite term\n>(composite subject) -- persons + gender. Same for people by occupation --\n>people + occupation. Occupation could clearly be a hierarchical facet by\n>itself.\n\nYou have to draw a line somewhere in deciding how far to go in factoring\ncompound concepts into their constituents. The British Standard for\nthesaurus construction gives some guidance on this.\n\n>Foskett asserts that an analysis of facets is correct if foci (topics/concepts\n>in context within a facet) are mutually exclusive -- \"that is, we cannot\n>envisage a composite subject which consists of two foci from the same\n>facet.\" (A.C. Foskett, The Subject Approach to Information.) But in one of\n>the examples above, it appears that you can create the composite subject\n>male cousins.\n\nI think that the point here is that when you set up an array with a\nspecified characteristic of division, you should try to make the\nsubdivisions mutually exclusive, so that you cannot combine two foci\nfrom the same array. You cannot have a male female, for example, or an\nadult teenager, if the arrays are specified as follows:\n\npeople\n        <people by gender>\n        males\n        females\n\n        <people by age>\n        children (0-12 years)\n        teenagers (13-19 years)\n        adults (over 20 years)\n\nI'm not sure that this rule need be enforced absolutely, though, or else\nperhaps some refinement or interpretation is needed. In the example I\ngave in my previous message, it is possible to have an array of\n\"materials by function\" in which a single material can be both a\nlubricant and a foodstuff (animal fat or castor oil, for example).\n\nAlso, in the array\n\n        <people by relationship>\n        daughters\n        sons\n        fathers\n        mothers\n        cousins\n\nsomeone cannot be related to another single person as both a son and a\nfather, though a single person can be both a son and a father at the\nsame time. Care is needed on how you interpret these.\n\n>In my understanding of faceted knowledge organization, inheritance of\n>properties is implied in facet hierarchies, but inheritance (especially\n>inheritance of all properties) is not formally specified in any examples of\n>faceted classification I have seen. In computer \"ontologies,\" however,\n>inheritance of properties is usually considered a basic formal requirement:\n>\"Properties become more useful for knowledge modeling when they are\n>specified at a general class level and then inherited consistently by\n>subclasses and instances.\" (Deborah L. McGuinness, \"Ontologies Come of Age,\"\n>p. 177, in  Fensel et al, editors, Spinning the Semantic Web.) What do\n>experts like yourself believe about the role of inheritance in facets?\n\nI think that inheritance should apply to all concepts related by the\ngeneric hierarchical (\"is-a\") relationship, and I think that membership\nof a facet is one aspect of this. In my last message I said that one way\nof defining a facet is to work up a generic tree until you can go no\nhigher, and you end up with a facet definition, being the \"fundamental\ncategory\" to which that tree of concepts belongs.\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Closing on shared-key authentication Repl",
            "content": "Baber Amin <Baber_Amin@novell.com> writes:\n> I am against this proposal also on the basis of separating application layer\n> and ztransport layer issues.\n\nBut, as has been pointed out, the issue of separating application\nlayer and transport layer issues is irrelevant to the proposal.  If it\nis in fact an issue of separating out authentication as being an\napplication layer issue, then the public-key authentication facilities\nof TLS should be removed on the grounds that they are also in the\nwrong layer.\n\nShared-key authentication is not fundamentally different from a\nlayering standpoint than any other authentication technology.  Any\nlayer in which it is appropriate to put in a public-key authentication\nsystem it is also technically appropriate to put in a shared-key\nauthentication system.  Authentication is authentication.\n\n-- \n_.John Gardiner MyersInternet: jgm+@CMU.EDU\nLoseNet:  ...!seismo!ihnp4!wiscvm.wisc.edu!give!up\n\n\n\n"
        },
        {
            "subject": "Mappings and Relationship",
            "content": "I think this is a good approach.  Therefore, I suggest renaming the top\nlevel property of SKOS-Mapping from 'mappingRelation' to 'semanticMapping'.\n\n\nThis would mean that the top level property of SKOS-Core (intra-thesaurus)\nis 'semanticRelation' and the top level property of SKOS-Mapping\n(inter-thesaurus) is 'semanticMapping', consistent with the BS convention.\n\nAlistair. \n\n\n\n> Re the SKOS-mapping document, I liked the general approach, \n> which has a\n> lot in common with our draft of Part 4 of the standard ( this is the\n> Part that deals with mappings). Some matters of detail may \n> need sorting\n> out. For example, the property \"mappingRelation\" seems to be \n> defined (or\n> at least described) in terms of itself. In our standard, by \n> the way, we\n> differentiate between inter-term \"mappings\" and \n> \"relationships\" by using\n> the former term for relationships between terms in different\n> vocabularies. (Thus all mappings are relationships, but we try to use\n> the term \"relationships\" when they apply within one vocabulary and\n> \"mappings\" for cross-vocabulary relationships. What we want \n> to avoid is\n> the sort of loose chatter where people talk about a mapping when all\n> they mean is a USE/UF relationship inside one thesaurus.)\n\n\n\n"
        },
        {
            "subject": "dropping &lt;soks:descriptor&gt; and using &lt;soks:prefLabel&gt; instea",
            "content": "> RE the SKOS-Core document, this seems to be setting up \n> definitions for a\n> series of terms, and I am a little concerned that the \n> terms/definitions\n> being established in your group may differ from those in our standard,\n> which we hope will be adopted internationally (in the longer run). In\n> some cases the definitions are compatible with each other; in other\n> cases there is a real difference of usage.  For example, I am \n> not sure I\n> have understood the difference made in the SWAD document between the\n> property \"prefLabel\" and the property \"descriptor\", since the former\n> property seems to be exactly what our standard means by \"descriptor\"\n> i.e. the unique name by which a concept should be labelled. We use the\n> term \"non-descriptor\" for any alternative (non-preferred) name for the\n> same concept. \n\nHaving both <soks:descriptor> and <soks:prefLabel> is definitely confusing.\nI suggest we drop the property <soks:descriptor> from SKOS-Core.  We retain\n<soks:prefLabel>, which should be used to assert the preferred name by which\na concept should be labelled.  The name should be unique within the\nparticular conceptual scheme.\n\nTo take one of the examples in the SWAD \n> document, \"Orange\n> (fruit)\" could be a descriptor or a non-descriptor, depending \n> on how it\n> is established in the thesaurus. Spelling this out a little, in\n> Thesaurus A, we might have an entry \"Orange (fruit) BT Citrus fruits\",\n> indicating that both of these terms are descriptors. In Thesaurus B we\n> might have an entry \"Orange (fruit) USE Oranges\", indicating that the\n> former term is a non-descriptor. It goes without saying that all the\n> terms in a thesaurus, whether descriptors or non-descriptors, \n> have to be\n> unique. I was not quite clear, studying the SWAD document, whether\n> \"descriptor\" could also be used for the things that our standard calls\n> \"non-descriptors\" - which would be unfortunate!  Sorry I have made\n> rather a meal of this example, but I am just wondering how we could\n> proceed so that there are no real incompatibilities between the\n> terminologies used in the SWAD work, and those in the thesaurus\n> standard.\n\nJust to state that I too would like to make sure that the SWAD work is\ncompatible with the new thesaurus standard.\n\nAlistair.\n\n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Theasurus FAQ questions",
            "content": "Yes, I was thinking about putting together a full scale FAQ for the\nThesaurus Activity Site, and this would be a good question.  \n\nPerhaps if we think up any good questions (and answers) we could post them\nto public-esw-thes over the next month or so, and so build up an FAQ by\ndegrees.\n\nAl.\n\n> -----Original Message-----\n> From: NJ Rogers, Learning and Research Technology\n> [mailto:Nikki.Rogers@bristol.ac.uk]\n> Sent: 28 January 2004 11:44\n> To: Alistair Miles; Dave Beckett\n> Subject: Wordnet Representations - RDF/XSD/OWL (fwd)\n> \n> \n> Hi Al and Dave\n> \n> This type of question (from below) will prob become a FAQ \n> which we should \n> cover in WP8:\n> \n> \"Would it be better to leave this as RDF or create an OWL ontology for\n> the Wordnet metamodel?\"\n> \n> Nikki\n> \n> \n> ---------- Forwarded Message ----------\n> Date: 22 January 2004 14:41 -0700\n> From: Michael Daconta <mike@daconta.net>\n> To: www-rdf-interest <www-rdf-interest@w3.org>\n> Subject: Wordnet Representations - RDF/XSD/OWL\n> \n> \n> \n> Hi Everyone,\n> \n> \n> \n> As part of a taxonomy framework, we will be linking \n> taxonomies lexically by\n> requiring each term to be mapped to a WordNet synonym or synset.\n> \n> As a start, I created an XSD schema and instance that follows \n> the striped\n> syntax and is thus also parseable as RDF.\n> \n> Here is a partial sample instance:\n> \n> <wn:Word xmlns:rdf='http://www.w3.org/1999/02/22-rdf-syntax-ns#'\n> xmlns:wn='http://www.daconta.net/wn#' rdf:ID='dog'\n> xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n> xsi:schemaLocation=\"http://www.daconta.net/wn# Word.xsd\" >\n> \n>             <wn:partsOfSpeech rdf:parseType='Collection'>\n> \n>                <wn:PartOfSpeech wn:type='verb'>\n> \n>                   <wn:concepts rdf:parseType='Collection'>\n> \n>                         <wn:Concept rdf:ID='_1943890'>\n> \n>                            <wn:definition>go after with the intent to\n> catch; &quot;The policeman chased the mugger down the alley&quot;;\n> &quot;the dog chased the rabbit&quot;</wn:definition>\n> \n>                              <wn:relations  \n> rdf:parseType='Collection'>\n> \n>                                     <wn:Relation wn:type='hypernym'\n> wn:tgt='_1942900'/>                              ...\n> \n>                                     <wn:Relation wn:type='hyponym'\n> wn:tgt='_1946245'/>\n> \n>                              </wn:relations>\n> \n>                               <wn:synonyms rdf:parseType='Collection'>\n> \n>                                     <wn:Synonym \n> wn:lemma='chase_after'/>\n> \n>                                     <wn:Synonym \n> wn:lemma='give_chase'/>\n> \n>                          </wn:synonyms>\n> \n>                           </wn:Concept>\n> \n>              </wn:concepts>\n> \n>             </wn:PartOfSpeech> ...\n> \n> \n> \n> \n> \n> If you are interested in playing around with this, there is a \n> schema, test\n> program and simple web service at\n> \n> http://www.daconta.net/project_folder/WordnetMetamodel.html .\n> \n> \n> \n> I have two questions for this group ...\n> \n> 1. Would it be better to leave this as RDF or create an OWL \n> ontology for\n> the Wordnet metamodel.\n> \n> 2. How would you handle wordnet addressing?  In other words, \n> a link from a\n> Topic to a Wordnet Concept (aka synset) or\n> \n> Synonym.  Another aspect of this would be how closely wordnet \n> relations,\n> map to XTM associations and OWL relations.\n> \n> \n> \n> Thanks for any feedback,\n> \n> \n> \n>  - Mike\n> \n> ----------------------------\n> \n> Michael C. Daconta\n> \n> Chief Scientist, APG, McDonald Bradley, Inc.\n> \n> www.daconta.net\n> \n> \n> \n> ---------- End Forwarded Message ----------\n> \n> \n> \n> ----------------------\n> NJ Rogers, Technical Researcher\n> (Semantic Web Applications Developer)\n> Institute for Learning and Research Technology (ILRT)\n> Email:nikki.rogers@bristol.ac.uk\n> Tel: +44(0)117 9287096 (Direct)\n> Tel: +44(0)117 9287193 (Office)\n> \n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Unless I misunderstand the proposal, the shared key proposal\ndoes not allow Kerberos to be incorporated in the sense that\npublic key authentication is still required (Kerberos is not\nallowed as an alternate authentication mechanism in place of\npublic key authentication).\n\nJonathan\n\n\n\n"
        },
        {
            "subject": "English Heritage Visi",
            "content": "Short piece on the visit on ESW Blog:\n\nhttp://esw.w3.org/mt/esw/archives/000039.html\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Hi Stefano and Simile folks,\n\nSorry I missed this, better late than never tho ...\n\n> \n> If I understood you correctly, you are suggesting that we identify \n> 'concepts' with URIs that do not contain anything to do with \n> the actual \n> literal that is used to describe them in a particular context.\n> \n> So, something like\n> \n>   http://simile.mit.edu/concept/2839488484\n> \n> instead of\n> \n>   http://simile.mit.edu/concept/maternity_services\n> \n> is that correct?\n> \n> -- \n> Stefano.\n> \n\nI think using a numbering scheme to build a URI for a concept is generally a\nbetter idea, as it helps to emphasise the fact that that resource being\nidentified is a piece of meaning, which is distinct from any lexical or\nsymbolic labels.  It also makes the URI scheme language independent (handy\nfor politically sensitive multilingual projects :)  \n\nHowever it is by no means necessary to do so.  But, if you are going to use\nthe preferred label for a concept as part of the URI for that concept, you\nmust be absolutely clear about the fact that that URI is an identifier for\nthe concept itself, and NOT the specific label.\n\nTo put it another way, you must be clear about whether a URI such as \n\n http://simile.mit.edu/concept/maternity_services\n\nis (a) an identifier for the lexical string 'maternity services' or (b) an\nidentifier for a concept whose preferred label is the string 'maternity\nservices', whose alternative label is the string 'blah' and whose scope note\nis 'blah blah blah'.\n\nIf this distinction is not made clearly, then everyone gets very confused\nwhen you want to make statements such as 'concept A from thesaurus T is\nbroader in meaning than concept B from thesaurus U' and 'the preferred label\nfor concept A is identical to an alternative label for concept B'.\n\nJust as an interesting sort of aside ... the first statement above is an\nexample of what I would call a 'semantic mapping', the second statement an\nexample of what I would call a 'lexical mapping'.  What's interesting is\nthat lexical mappings can be discovered by a computer alone, using stemming\nalgorithms and string comparisons etc.  The lexical mappings can then be\nused to highlight possible semantic mappings, and defining semantic mappings\nis something that only a person can do.   \n\nAnother example of a lexical mapping would be 'the preferred label for\nconcept A is the plural form of the preferred label for concept B'.\n\nAnother (the most obvious) example of a semantic mapping would be 'concept A\nis identical in meaning to concept B' (which could easily occur even if\ntheir respective preferred labels where not identical). \n\nThe SKOS-Mapping schema [1] was designed to take care of semantic mappings.\nBut is there a requirement for expressing lexical mappings in RDF, and if\nso, how do we do it without getting rather confused?  \n\nThe reason why I previously didn't think expressing lexical mappings in RDF\nwas really necessary was because they could be automatically discovered by a\ncomputer process at any time.  But then I guess storing and publishing the\nresults of that process could be useful, especially when operating on large\ndata sets. \n\nAnyway, it would be great to get some feedback on this question.\n\nYours,\n\nAlistair.\n \n[1] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Hi Alistair\n\nFirst better warn you unfortunately I'm not working on SIMILE, but I'll\nexplain my position here, as I did do a bit of the work on lexical mapping\n...\n\n> The SKOS-Mapping schema [1] was designed to take care of semantic\nmappings.\n> But is there a requirement for expressing lexical mappings in RDF, and if\n> so, how do we do it without getting rather confused?  \n\n> The reason why I previously didn't think expressing lexical mappings in\nRDF\n> was really necessary was because they could be automatically discovered by\na\n> computer process at any time.  But then I guess storing and publishing the\n> results of that process could be useful, especially when operating on\nlarge\n> data sets. \n\nI think we do need to do this, in fact I think this is related to our\nprevious discussion on giving URIs to altLabels?\n\nAutomated discovery doesn't quite work in the way you describe, because the\ncomputer will generate lexical mappings, but then anywhere between 10% and\n50% of them are incorrect. So you need some way of capturing them, and\nreviewing them by hand if necessary.\n\nDoes that seem sensible?\n\nDr Mark H. Butler\nResearch Scientist, HP Labs Bristol\nhttp://www-uk.hpl.hp.com/people/marbut \n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Hi Mark, good to hear from you.\n\n> \n> > The reason why I previously didn't think expressing lexical \n> mappings in\n> RDF\n> > was really necessary was because they could be \n> automatically discovered by\n> a\n> > computer process at any time.  But then I guess storing and \n> publishing the\n> > results of that process could be useful, especially when \n> operating on\n> large\n> > data sets. \n> \n> I think we do need to do this, in fact I think this is related to our\n> previous discussion on giving URIs to altLabels?\n\nYes I was thinking of this when I made these comments.  (I have some ideas\nabout how to express lexical mappings that does not require the altLabels to\nhave their own URI.)  \n\n> Automated discovery doesn't quite work in the way you \n> describe, because the\n> computer will generate lexical mappings, but then anywhere \n> between 10% and\n> 50% of them are incorrect. So you need some way of capturing them, and\n> reviewing them by hand if necessary.\n> \n> Does that seem sensible?\n\nYes absolutely.  Could you possibly provide me with a list of all the types\nof useful lexical mapping you can think of?  \n\nThis is splitting hairs a little bit, but I think it would be more accurate\nto say that a lexical mapping may or may not reflect a close semantic\nmapping.  So a lexical mapping is never 'incorrect' if it captures some sort\nof lexical similarity between labels, even if there is no semantic mapping\nbetween the corresponding concepts. \n\n(This is just my attempt to make a very clear distinction between the world\nof lexical comparison of character strings, and the world of semantic\ncomparison of intended meaning.)\n\nYours,\n\nAlistair.       \n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Hi Alistair\n\n> I have some ideas about how to express lexical mappings \n> that does not require the altLabels to have their own URI.\n\nI would be interested to hear your proposals here?\n\nHere is the use case we had in SIMILE:\n\nI have some Artstor data that uses the term \"cadavers\" (which is a preferred\nterm in the Artstor data), and I want to map onto the LOC TGM thesaurus. In\nLOC TGM, cadavers is an alternative term for both \"dead animals\" and \"dead\npersons\". Therefore, my guess is LOC decided that the term \"cadavers\" was\nambiguous, so they decided to encourage cataloguers to use the two less\nambiguous terms. However here the concept corresponding to cadaver is\nactually the union of the concepts that have \"dead animals\" and \"dead\npersons\" as their primary terms. \n\nSo if I want to create a mapping between the Artstor data and the LOC TGM,\nhow should I do it using SKOS for the record that uses the term \"cadavers\"?\nI think I want a semantic mapping here, even though I am mapping to an\nalternative term?\n\nAs well as the use case above, I think there are a number of other things\nthat seem difficult due to not giving altLabels their own URIs - perhaps you\nalso have workarounds for them?\n\n- how can you provide versions of an altLabel in multiple languages?\n\n- lots of web APIs (for example fetch, the Longwell and Brownsauce browsers)\nuse URIs to identify objects. Is there a way of identifying altLabels that\nis compatible with these APIs?\n\nBTW, I did discuss with Damian Steer, and he pointed out the multiple\nlanguage problem could be solved using bNodes. This doesn't help the web API\nproblem, but FOAF uses bNodes in a similar way, so some web APIs are coming\nup with ways to solve the problem for the FOAF case, so perhaps an\nalternative solution might be to use a bNode?\n\n> RE: lexical mappings\n\n> This is splitting hairs a little bit, but I think it would \n> be more accurate to say that a lexical mapping may or may \n> not reflect a close semantic mapping.  So a lexical mapping \n> is never 'incorrect' if it captures some sort of lexical \n> similarity between labels, even if there is no semantic \n> mapping between the corresponding concepts. \n\nWe used edit distance measures, so taking this approach \"fountains\" and\n\"mountains\" are as close as \"corpse\" and \"corpses\". I was thinking of the\nfirst one as being \"incorrect\" whereas the second one is \"correct\".\n\nNow conceptually you are right that they are both correct lexical mappings.\nSo maybe what I am actually doing is generating lexical mappings, then human\nreviewing them to turn them into semantic mappings, only the change from\nlexical mappings to semantic mapping is not explicit (because I don't fancy\ndoing lots of retyping by change the property names in the N3!)\n\nThis is a pragmatic approach for now - longer term, I think SIMILE intends\nto develop tools to do this type of task, so then it might be possible to\nchange the properties so they actually reflect when a mapping relation is\nchanged from being just a lexical mapping to a semantic mapping.\n\n> Could you possibly provide me with a list \n> of all the types of useful lexical mapping you \n> can think of?  \n\nNo, sorry. I guess people like the WordNet and Cyc communities have thought\nabout this, and you may be more familiar with this work than I am?\n\nbest regards\n\nDr Mark H. Butler\nResearch Scientist, HP Labs Bristol\nhttp://www-uk.hpl.hp.com/people/marbut \n\n\n\n"
        },
        {
            "subject": "The Document",
            "content": ">I completely endorse David Kemp's suggestion that the first product of this\n>working group should be the separation of the specification into two RFC\n>documents, one defining the Record Layer, and the other defining the\n>Handshake Protocol.  This is a great idea --- and it insures that evolution\n>of the two components can happen independently. \n>\nBarb\n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Hi Mark, \n\n\n> Here is the use case we had in SIMILE:\n> \n> I have some Artstor data that uses the term \"cadavers\" (which \n> is a preferred\n> term in the Artstor data), and I want to map onto the LOC TGM \n> thesaurus. In\n> LOC TGM, cadavers is an alternative term for both \"dead \n> animals\" and \"dead\n> persons\". Therefore, my guess is LOC decided that the term \n> \"cadavers\" was\n> ambiguous, so they decided to encourage cataloguers to use \n> the two less\n> ambiguous terms. However here the concept corresponding to cadaver is\n> actually the union of the concepts that have \"dead animals\" and \"dead\n> persons\" as their primary terms. \n\nSo taking this as an example, using the following hypothetical RDF\ndescriptions of the concepts involved ...\n\n  <skos:Concept rdf:nodeID=\"a\">\n    <skos:prefLabel>Cadavers</skos:prefLabel>\n    <skos:inScheme rdf:nodeID=\"Artstor\"/>\n  </skos:Concept>\n  \n  <skos:Concept rdf:nodeID=\"b\">\n    <skos:prefLabel>Dead animals</skos:prefLabel>\n    <skos:altLabel>Cadavers</skos:altLabel>\n    <skos:inScheme rdf:nodeID=\"LOCTGM\"/>\n  </skos:Concept>\n  \n  <skos:Concept rdf:nodeID=\"c\">\n    <skos:prefLabel>Dead persons</skos:prefLabel>\n    <skos:altLabel>Cadavers</skos:altLabel>\n    <skos:inScheme rdf:nodeID=\"LOCTGM\"/>\n  </skos:Concept>\n\n... using the most recent version of the SKOS-Mapping schema [1][2] the\nArtstor -> LOCTGM mapping would be expressed as ...\n\n  <rdf:Description rdf:nodeID=\"a\">\n    <skos-map:exactMatch>\n      <skos-map:OR>\n        <skos-map:memberList rdf:parseType=\"Collection\">\n          <rdf:Description rdf:nodeID=\"b\"/>\n          <rdf:Description rdf:nodeID=\"c\"/>\n        </skos-map:memberList>\n      </skos-map:OR>\n    </skos-map:exactMatch>\n  </rdf:Description>\n\n... and the LOCTGM -> Artstor mapping would be expressed as ...\n\n  <rdf:Description rdf:nodeID=\"b\">\n    <skos-map:broadMatch rdf:nodeID=\"a\"/>\n  </rdf:Description>\n  \n  <rdf:Description rdf:nodeID=\"c\">\n    <skos-map:broadMatch rdf:nodeID=\"a\"/>\n  </rdf:Description>\n\nThis is of course a semantic mapping, and needs a person to identify it.  \n\nSome sort of mapping tool is what I had in mind as a UI, to help a user\ndefine semantic mappings (possibly suggested by lexical mappings).\n\nAs a totally hypothetical example, I was thinking that lexical mappings\ncould be expressed as in e.g. ....   \n\n  <test:AltToPrefLabelMatch>\n    <test:source rdf:nodeID=\"b\"/>\n    <test:target rdf:nodeID=\"a\"/>\n    <test:stringMatch>Cadaver</skos-map:stringMatch>\n  </test:AltToPrefLabelMapping>\n\nI would love to see another round of development on the SKOS-Mapping schema\n(I think it needs it), with some proper test cases to try it out.  I don't\nthink we have this effort left in SWAD-E though, something to think of for\nthe future :).\n\nYours,\n\nAlistair.\n\n[1] http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping\n[2] http://www.w3c.rl.ac.uk/SWAD/deliverables/8.4.html\n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Hi Mark, \n\nIn reply to this question ...\n\n> - how can you provide versions of an altLabel in multiple languages?\n> BTW, I did discuss with Damian Steer, and he pointed out the multiple\n> language problem could be solved using bNodes. \n\nThis needs careful analysis.  The effort in SKOS has been to be utterly\nclear about which nodes in the graph represent a piece of meaning (concept),\nand which represent lexical or symbolic labels.  \n\nSo it is entirely reasonable to say something like ...\n\n<skos:Concept rdf:nodeID=\"a\">\n<skos:prefLabel xml:lang=\"en\">Cats</skos:prefLabel>\n<skos:prefLabel xml:lang=\"fr\">Chats</skos:prefLabel>\n<skos:Concept>\n\n... but to say something like ...\n\n<skos:Concept rdf:nodeID=\"b\">\n<skos:prefLabel>\n<rdf:Description rdf:nodeID=\"c\">\n<rdf:value xml:lang=\"en\">Cats</rdf:value>\n<rdf:value xml:lang=\"fr\">Chats</rdf:value>\n</rdf:Description>\n</skos:prefLabel>\n</skos:Concept>\n\n... would break the whole model, because what does the \"c\" node represent?\nThe only reasonable interpretation is that it is a piece of meaning, because\nthe only thing that connects the two strings is their received meaning.  And\nso we now have a concept as the value for a labelling property!!! \n\nThe correct (first) example above uses the 'multilingual labelling approach'\n(see [1]), which is essentially the rough and ready way of doing\nmultilingual thesauri.  To be more precise about modelling these sorts of\nstructures, one needs to take the 'interlingual mapping approach' as in e.g.\n...\n\n<skos:Concept rdf:nodeID=\"a\">\n<skos:prefLabel xml:lang=\"en\">Cats</skos:prefLabel>\n</skos:Concept>\n\n<skos:Concept rdf:nodeID=\"b\">\n<skos:prefLabel xml:lang=\"fr\">Chats</skos:prefLabel>\n</skos:Concept>\n\n<rdf:Description rdf:nodeID=\"a\">\n<skos-map:exactMatch rdf:nodeID=\"b\"/>\n</rdf:Description>\n\nNote that the mapping statement does not necessarily follow from the fact\nthat 'chats' is the usual french translation of the english word 'cats'.  If\nI added the statement ...\n\n<skos:Concept rdf:nodeID=\"a\">\n<skos:altLabel xml:lang=\"en>Cool dudes</skos:altLabel>\n</skos:Concept>\n\n... it would become obvious that the mapping statement is in fact entirely\nincorrect - that what the \"a\" node actually intends is something completely\ndifferent from the concept of the furry things that purr.\n\nAnyway, hope this helps :) \n\nYours,\n\nAlistair.\n\n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Butler, Mark\n> Sent: 08 June 2004 14:51\n> To: (www-rdf-dspace@w3.org)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: RE: SKOS & SIMILE, concepts, terms, URIs, mappings\n> \n> \n> \n> Hi Alistair\n> \n> > I have some ideas about how to express lexical mappings \n> > that does not require the altLabels to have their own URI.\n> \n> I would be interested to hear your proposals here?\n> \n> Here is the use case we had in SIMILE:\n> \n> I have some Artstor data that uses the term \"cadavers\" (which \n> is a preferred\n> term in the Artstor data), and I want to map onto the LOC TGM \n> thesaurus. In\n> LOC TGM, cadavers is an alternative term for both \"dead \n> animals\" and \"dead\n> persons\". Therefore, my guess is LOC decided that the term \n> \"cadavers\" was\n> ambiguous, so they decided to encourage cataloguers to use \n> the two less\n> ambiguous terms. However here the concept corresponding to cadaver is\n> actually the union of the concepts that have \"dead animals\" and \"dead\n> persons\" as their primary terms. \n> \n> So if I want to create a mapping between the Artstor data and \n> the LOC TGM,\n> how should I do it using SKOS for the record that uses the \n> term \"cadavers\"?\n> I think I want a semantic mapping here, even though I am mapping to an\n> alternative term?\n> \n> As well as the use case above, I think there are a number of \n> other things\n> that seem difficult due to not giving altLabels their own \n> URIs - perhaps you\n> also have workarounds for them?\n> \n> - how can you provide versions of an altLabel in multiple languages?\n> \n> - lots of web APIs (for example fetch, the Longwell and \n> Brownsauce browsers)\n> use URIs to identify objects. Is there a way of identifying \n> altLabels that\n> is compatible with these APIs?\n> \n> BTW, I did discuss with Damian Steer, and he pointed out the multiple\n> language problem could be solved using bNodes. This doesn't \n> help the web API\n> problem, but FOAF uses bNodes in a similar way, so some web \n> APIs are coming\n> up with ways to solve the problem for the FOAF case, so perhaps an\n> alternative solution might be to use a bNode?\n> \n> > RE: lexical mappings\n> \n> > This is splitting hairs a little bit, but I think it would \n> > be more accurate to say that a lexical mapping may or may \n> > not reflect a close semantic mapping.  So a lexical mapping \n> > is never 'incorrect' if it captures some sort of lexical \n> > similarity between labels, even if there is no semantic \n> > mapping between the corresponding concepts. \n> \n> We used edit distance measures, so taking this approach \n> \"fountains\" and\n> \"mountains\" are as close as \"corpse\" and \"corpses\". I was \n> thinking of the\n> first one as being \"incorrect\" whereas the second one is \"correct\".\n> \n> Now conceptually you are right that they are both correct \n> lexical mappings.\n> So maybe what I am actually doing is generating lexical \n> mappings, then human\n> reviewing them to turn them into semantic mappings, only the \n> change from\n> lexical mappings to semantic mapping is not explicit (because \n> I don't fancy\n> doing lots of retyping by change the property names in the N3!)\n> \n> This is a pragmatic approach for now - longer term, I think \n> SIMILE intends\n> to develop tools to do this type of task, so then it might be \n> possible to\n> change the properties so they actually reflect when a mapping \n> relation is\n> changed from being just a lexical mapping to a semantic mapping.\n> \n> > Could you possibly provide me with a list \n> > of all the types of useful lexical mapping you \n> > can think of?  \n> \n> No, sorry. I guess people like the WordNet and Cyc \n> communities have thought\n> about this, and you may be more familiar with this work than I am?\n> \n> best regards\n> \n> Dr Mark H. Butler\n> Research Scientist, HP Labs Bristol\n> http://www-uk.hpl.hp.com/people/marbut \n> \n\n\n\n"
        },
        {
            "subject": "RE: SKOS &amp; SIMILE, concepts, terms, URIs, mapping",
            "content": "Oops, forgot to put [1] ref on previous mail - the RDF Encoding of\nMultilingual Thesauri Report ...\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.3.html\n\nAl.\n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Miles, AJ \n> (Alistair)\n> \n> Sent: 09 June 2004 18:19\n> To: 'Butler, Mark'; (www-rdf-dspace@w3.org)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: RE: SKOS & SIMILE, concepts, terms, URIs, mappings\n> \n> \n> \n> Hi Mark, \n> \n> In reply to this question ...\n> \n> > - how can you provide versions of an altLabel in multiple languages?\n> > BTW, I did discuss with Damian Steer, and he pointed out \n> the multiple\n> > language problem could be solved using bNodes. \n> \n> This needs careful analysis.  The effort in SKOS has been to \n> be utterly\n> clear about which nodes in the graph represent a piece of \n> meaning (concept),\n> and which represent lexical or symbolic labels.  \n> \n> So it is entirely reasonable to say something like ...\n> \n> <skos:Concept rdf:nodeID=\"a\">\n> <skos:prefLabel xml:lang=\"en\">Cats</skos:prefLabel>\n> <skos:prefLabel xml:lang=\"fr\">Chats</skos:prefLabel>\n> <skos:Concept>\n> \n> ... but to say something like ...\n> \n> <skos:Concept rdf:nodeID=\"b\">\n> <skos:prefLabel>\n> <rdf:Description rdf:nodeID=\"c\">\n> <rdf:value \n> xml:lang=\"en\">Cats</rdf:value>\n> <rdf:value \n> xml:lang=\"fr\">Chats</rdf:value>\n> </rdf:Description>\n> </skos:prefLabel>\n> </skos:Concept>\n> \n> ... would break the whole model, because what does the \"c\" \n> node represent?\n> The only reasonable interpretation is that it is a piece of \n> meaning, because\n> the only thing that connects the two strings is their \n> received meaning.  And\n> so we now have a concept as the value for a labelling property!!! \n> \n> The correct (first) example above uses the 'multilingual \n> labelling approach'\n> (see [1]), which is essentially the rough and ready way of doing\n> multilingual thesauri.  To be more precise about modelling \n> these sorts of\n> structures, one needs to take the 'interlingual mapping \n> approach' as in e.g.\n> ...\n> \n> <skos:Concept rdf:nodeID=\"a\">\n> <skos:prefLabel xml:lang=\"en\">Cats</skos:prefLabel>\n> </skos:Concept>\n> \n> <skos:Concept rdf:nodeID=\"b\">\n> <skos:prefLabel xml:lang=\"fr\">Chats</skos:prefLabel>\n> </skos:Concept>\n> \n> <rdf:Description rdf:nodeID=\"a\">\n> <skos-map:exactMatch rdf:nodeID=\"b\"/>\n> </rdf:Description>\n> \n> Note that the mapping statement does not necessarily follow \n> from the fact\n> that 'chats' is the usual french translation of the english \n> word 'cats'.  If\n> I added the statement ...\n> \n> <skos:Concept rdf:nodeID=\"a\">\n> <skos:altLabel xml:lang=\"en>Cool dudes</skos:altLabel>\n> </skos:Concept>\n> \n> ... it would become obvious that the mapping statement is in \n> fact entirely\n> incorrect - that what the \"a\" node actually intends is \n> something completely\n> different from the concept of the furry things that purr.\n> \n> Anyway, hope this helps :) \n> \n> Yours,\n> \n> Alistair.\n> \n> \n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n> \n> > -----Original Message-----\n> > From: public-esw-thes-request@w3.org\n> > [mailto:public-esw-thes-request@w3.org]On Behalf Of Butler, Mark\n> > Sent: 08 June 2004 14:51\n> > To: (www-rdf-dspace@w3.org)\n> > Cc: 'public-esw-thes@w3.org'\n> > Subject: RE: SKOS & SIMILE, concepts, terms, URIs, mappings\n> > \n> > \n> > \n> > Hi Alistair\n> > \n> > > I have some ideas about how to express lexical mappings \n> > > that does not require the altLabels to have their own URI.\n> > \n> > I would be interested to hear your proposals here?\n> > \n> > Here is the use case we had in SIMILE:\n> > \n> > I have some Artstor data that uses the term \"cadavers\" (which \n> > is a preferred\n> > term in the Artstor data), and I want to map onto the LOC TGM \n> > thesaurus. In\n> > LOC TGM, cadavers is an alternative term for both \"dead \n> > animals\" and \"dead\n> > persons\". Therefore, my guess is LOC decided that the term \n> > \"cadavers\" was\n> > ambiguous, so they decided to encourage cataloguers to use \n> > the two less\n> > ambiguous terms. However here the concept corresponding to \n> cadaver is\n> > actually the union of the concepts that have \"dead animals\" \n> and \"dead\n> > persons\" as their primary terms. \n> > \n> > So if I want to create a mapping between the Artstor data and \n> > the LOC TGM,\n> > how should I do it using SKOS for the record that uses the \n> > term \"cadavers\"?\n> > I think I want a semantic mapping here, even though I am \n> mapping to an\n> > alternative term?\n> > \n> > As well as the use case above, I think there are a number of \n> > other things\n> > that seem difficult due to not giving altLabels their own \n> > URIs - perhaps you\n> > also have workarounds for them?\n> > \n> > - how can you provide versions of an altLabel in multiple languages?\n> > \n> > - lots of web APIs (for example fetch, the Longwell and \n> > Brownsauce browsers)\n> > use URIs to identify objects. Is there a way of identifying \n> > altLabels that\n> > is compatible with these APIs?\n> > \n> > BTW, I did discuss with Damian Steer, and he pointed out \n> the multiple\n> > language problem could be solved using bNodes. This doesn't \n> > help the web API\n> > problem, but FOAF uses bNodes in a similar way, so some web \n> > APIs are coming\n> > up with ways to solve the problem for the FOAF case, so perhaps an\n> > alternative solution might be to use a bNode?\n> > \n> > > RE: lexical mappings\n> > \n> > > This is splitting hairs a little bit, but I think it would \n> > > be more accurate to say that a lexical mapping may or may \n> > > not reflect a close semantic mapping.  So a lexical mapping \n> > > is never 'incorrect' if it captures some sort of lexical \n> > > similarity between labels, even if there is no semantic \n> > > mapping between the corresponding concepts. \n> > \n> > We used edit distance measures, so taking this approach \n> > \"fountains\" and\n> > \"mountains\" are as close as \"corpse\" and \"corpses\". I was \n> > thinking of the\n> > first one as being \"incorrect\" whereas the second one is \"correct\".\n> > \n> > Now conceptually you are right that they are both correct \n> > lexical mappings.\n> > So maybe what I am actually doing is generating lexical \n> > mappings, then human\n> > reviewing them to turn them into semantic mappings, only the \n> > change from\n> > lexical mappings to semantic mapping is not explicit (because \n> > I don't fancy\n> > doing lots of retyping by change the property names in the N3!)\n> > \n> > This is a pragmatic approach for now - longer term, I think \n> > SIMILE intends\n> > to develop tools to do this type of task, so then it might be \n> > possible to\n> > change the properties so they actually reflect when a mapping \n> > relation is\n> > changed from being just a lexical mapping to a semantic mapping.\n> > \n> > > Could you possibly provide me with a list \n> > > of all the types of useful lexical mapping you \n> > > can think of?  \n> > \n> > No, sorry. I guess people like the WordNet and Cyc \n> > communities have thought\n> > about this, and you may be more familiar with this work than I am?\n> > \n> > best regards\n> > \n> > Dr Mark H. Butler\n> > Research Scientist, HP Labs Bristol\n> > http://www-uk.hpl.hp.com/people/marbut \n> > \n> \n\n\n\n"
        },
        {
            "subject": "[PORT] fwd: [syndic8] Messy use of subject in item dat",
            "content": "(crossposting to SW Best Practices list and the public-esw-thes list)\n\nForward from RSS and Syndication lists. Bill Kearney has been doing some \ndigging into the way the dc:subject property is being deployed in \nRSS feeds. Short version: it's a mess.\n\nPart of the problem here, I think, is that there has been a vague \nexpectation floating around that RDFS/OWL class and property hierarchies\nare the W3C SW stack's last word w.r.t. classififying things. RDF and DC \npeople haven't really finished off a good, clear and intuitive model for\nusing dc:subject with controlled vocabularies. I'm hoping our work here\ncan help get things back on track.\n\nCharacterising the topic(s) of document-like content is helped by RDF\nand by OWL, but there's much that can be done that doesn't naturally \nfind expression in a classes-and-properties model. Something like SKOS, \nand an agreed model for expressing thesaurus-like content within \nRDF (including via dc:subject) should go some way towards these\nproblems. But only so long as convenient utilities for authoring better \ndc:subject data  finds its way into mass-market tools (for blogging and\nHTML editors).\n \nDan\n\n----- Forwarded message from Bill Kearney <ml_yahoo@ideaspace.net> -----\n\nFrom: Bill Kearney <ml_yahoo@ideaspace.net>\nDate: Sat, 12 Jun 2004 10:50:24 -0400\nTo: syndic8@yahoogroups.com, rss-dev@yahoogroups.com\nSubject: [syndic8] Messy use of subject in item data\nMessage-ID: <016901c4508c$98581750$200ca8c0@wkearney.com>\nReply-To: syndic8@yahoogroups.com\nOrganization: http://www.ideaspace.net/users/wkearney/foaf.xrdf\n\nHi all,\n\nI've done a whole bunch of digging into how feeds are using the dc:subject\nelement.  It was ugly.  In the latest poll of over 52k feeds there were 9761\nthat used an item dc:subject at least once.\n\nSadly, it's little more than a mish-mash of string data.\n\nOf those 52k feeds a subtotal of 24k unique strings were used.  It's at this\npoint that the data gets messy.\n\nThose 24 thousand unique subject descriptions are all over the map.  Some are\nwhat would be considered usefully simple keywords.  Some are long string\nstatements, sentences and partial sentences.  A bunch are just utter gibberish.\n\nSeveral are using what appears to be a quasi-delimited strings.  Some in an\napparent attempt to make hierarchical categorizations while others as multiple\ndichotomies.  About 1100 are trying to use the comma as a sort of multiple\nkeyword delimiter.  The comma is also being (ab)used for formal names (eg\n\"Smith, John Q.\")\n\nAnother thousand are trying to use the forward slash as a hierarchy delimiter.\nSometimes with or without leaders and/or space padded.  Some are even trying to\nuse what look like DMOZ hierarchies (yay!).  Most, however, are not.  They're\njust making it up.  <sigh/>\n\nSuffice to say, case sensitivity is equally random.\n\nOne feed is trying to use several subjects per item but uses some sort of\nnumeric identifier:  God knows what the numbers correspond with; the data\ndoesn't say.\n\nI stared in utter horror upon seeing some feeds trying to use HTML markup in the\ndc:subject element.  Aiiieeeee, run way!\n\nI hope and pray there's a special place in Hell reserved for the authors of\nfeeds trying to use an HTML img as a subject.  Get me a big cluestick as someone\ndeserves a thump or two.  While the DC is ambiguous on the contents of the\nsubject element, it's not THAT ambiguous.  Well, maybe not Hell; perhaps just\nNew Jersey.\n\nOh, and don't get me started on the number of times someone misspelled a subject\nword.\n\nIn short, item subjects in feeds are an unholy mess.\n\nI mean, don't get me wrong, it's apparent that people are /trying/ to use some\nsort of subject identifiers.  This is a good sign.  But at this point it's not\nlooking like it'd be very practical to attempt to do much with it.  The data\njust seems far too messy to make any predictable, let alone consistent, use of\nit.\n\nIf anything, stuff like XFML might be a good place to start.  Or perhaps using\nsome sort of cross-referencing between a 'human readable' label used inside the\ndc:subject element and an element in a Topic Map?  Maybe simple stuff like\nmapping use of the string \"Jokes\" as a cross-ref to\nhttp://dmoz.org/Recreation/Humor/Jokes/ or some other ontology noted in the\nfeed's channel header section.\n\nWe've long suggested that folks might want to use DMOZ strings.  Either as the\nhierarchy string in it's entirety or as part of some sort of rosetta stone cross\nreferencing document in XTM, xfml or whatever.  Just as long as we get\n/something/ in place that will help let the machines make educated guesses about\nwhat the heck we're talking about.\n\nIs there some way reasonably painless way to introduce some sort of discipline\ninto the process?  I'd welcome an open discussion on the matter.\n\n-Bill Kearney\nSyndic8.com\n\n\n\n------------------------ Yahoo! Groups Sponsor --------------------~--> \nYahoo! Domains - Claim yours for only $14.70\nhttp://us.click.yahoo.com/Z1wmxD/DREIAA/yQLSAA/IRislB/TM\n--------------------------------------------------------------------~-> \n\nTo find more info about Syndicated XML newsfeeds visit http://www.syndic8.com \nYahoo! Groups Links\n\n<*> To visit your group on the web, go to:\n     http://groups.yahoo.com/group/syndic8/\n\n<*> To unsubscribe from this group, send an email to:\n     syndic8-unsubscribe@yahoogroups.com\n\n<*> Your use of Yahoo! Groups is subject to:\n     http://docs.yahoo.com/info/terms/\n \n\n----- End forwarded message -----\n\n\n\n"
        },
        {
            "subject": "Re: [PORT] fwd: [syndic8] Messy use of subject in item dat",
            "content": "[resent with public-swbp-wg@w3.org spelled correctly]\n\n* Dan Brickley <danbri@w3.org> [2004-06-12 11:09-0400]\n> \n> (crossposting to SW Best Practices list and the public-esw-thes list)\n> \n> Forward from RSS and Syndication lists. Bill Kearney has been doing some \n> digging into the way the dc:subject property is being deployed in \n> RSS feeds. Short version: it's a mess.\n> \n> Part of the problem here, I think, is that there has been a vague \n> expectation floating around that RDFS/OWL class and property hierarchies\n> are the W3C SW stack's last word w.r.t. classififying things. RDF and DC \n> people haven't really finished off a good, clear and intuitive model for\n> using dc:subject with controlled vocabularies. I'm hoping our work here\n> can help get things back on track.\n> \n> Characterising the topic(s) of document-like content is helped by RDF\n> and by OWL, but there's much that can be done that doesn't naturally \n> find expression in a classes-and-properties model. Something like SKOS, \n> and an agreed model for expressing thesaurus-like content within \n> RDF (including via dc:subject) should go some way towards these\n> problems. But only so long as convenient utilities for authoring better \n> dc:subject data  finds its way into mass-market tools (for blogging and\n> HTML editors).\n>  \n> Dan\n> \n> ----- Forwarded message from Bill Kearney <ml_yahoo@ideaspace.net> -----\n> \n> From: Bill Kearney <ml_yahoo@ideaspace.net>\n> Date: Sat, 12 Jun 2004 10:50:24 -0400\n> To: syndic8@yahoogroups.com, rss-dev@yahoogroups.com\n> Subject: [syndic8] Messy use of subject in item data\n> Message-ID: <016901c4508c$98581750$200ca8c0@wkearney.com>\n> Reply-To: syndic8@yahoogroups.com\n> Organization: http://www.ideaspace.net/users/wkearney/foaf.xrdf\n> \n> Hi all,\n> \n> I've done a whole bunch of digging into how feeds are using the dc:subject\n> element.  It was ugly.  In the latest poll of over 52k feeds there were 9761\n> that used an item dc:subject at least once.\n> \n> Sadly, it's little more than a mish-mash of string data.\n> \n> Of those 52k feeds a subtotal of 24k unique strings were used.  It's at this\n> point that the data gets messy.\n> \n> Those 24 thousand unique subject descriptions are all over the map.  Some are\n> what would be considered usefully simple keywords.  Some are long string\n> statements, sentences and partial sentences.  A bunch are just utter gibberish.\n> \n> Several are using what appears to be a quasi-delimited strings.  Some in an\n> apparent attempt to make hierarchical categorizations while others as multiple\n> dichotomies.  About 1100 are trying to use the comma as a sort of multiple\n> keyword delimiter.  The comma is also being (ab)used for formal names (eg\n> \"Smith, John Q.\")\n> \n> Another thousand are trying to use the forward slash as a hierarchy delimiter.\n> Sometimes with or without leaders and/or space padded.  Some are even trying to\n> use what look like DMOZ hierarchies (yay!).  Most, however, are not.  They're\n> just making it up.  <sigh/>\n> \n> Suffice to say, case sensitivity is equally random.\n> \n> One feed is trying to use several subjects per item but uses some sort of\n> numeric identifier:  God knows what the numbers correspond with; the data\n> doesn't say.\n> \n> I stared in utter horror upon seeing some feeds trying to use HTML markup in the\n> dc:subject element.  Aiiieeeee, run way!\n> \n> I hope and pray there's a special place in Hell reserved for the authors of\n> feeds trying to use an HTML img as a subject.  Get me a big cluestick as someone\n> deserves a thump or two.  While the DC is ambiguous on the contents of the\n> subject element, it's not THAT ambiguous.  Well, maybe not Hell; perhaps just\n> New Jersey.\n> \n> Oh, and don't get me started on the number of times someone misspelled a subject\n> word.\n> \n> In short, item subjects in feeds are an unholy mess.\n> \n> I mean, don't get me wrong, it's apparent that people are /trying/ to use some\n> sort of subject identifiers.  This is a good sign.  But at this point it's not\n> looking like it'd be very practical to attempt to do much with it.  The data\n> just seems far too messy to make any predictable, let alone consistent, use of\n> it.\n> \n> If anything, stuff like XFML might be a good place to start.  Or perhaps using\n> some sort of cross-referencing between a 'human readable' label used inside the\n> dc:subject element and an element in a Topic Map?  Maybe simple stuff like\n> mapping use of the string \"Jokes\" as a cross-ref to\n> http://dmoz.org/Recreation/Humor/Jokes/ or some other ontology noted in the\n> feed's channel header section.\n> \n> We've long suggested that folks might want to use DMOZ strings.  Either as the\n> hierarchy string in it's entirety or as part of some sort of rosetta stone cross\n> referencing document in XTM, xfml or whatever.  Just as long as we get\n> /something/ in place that will help let the machines make educated guesses about\n> what the heck we're talking about.\n> \n> Is there some way reasonably painless way to introduce some sort of discipline\n> into the process?  I'd welcome an open discussion on the matter.\n> \n> -Bill Kearney\n> Syndic8.com\n> \n> \n> \n> ------------------------ Yahoo! Groups Sponsor --------------------~--> \n> Yahoo! Domains - Claim yours for only $14.70\n> http://us.click.yahoo.com/Z1wmxD/DREIAA/yQLSAA/IRislB/TM\n> --------------------------------------------------------------------~-> \n> \n> To find more info about Syndicated XML newsfeeds visit http://www.syndic8.com \n> Yahoo! Groups Links\n> \n> <*> To visit your group on the web, go to:\n>      http://groups.yahoo.com/group/syndic8/\n> \n> <*> To unsubscribe from this group, send an email to:\n>      syndic8-unsubscribe@yahoogroups.com\n> \n> <*> Your use of Yahoo! Groups is subject to:\n>      http://docs.yahoo.com/info/terms/\n>  \n> \n> ----- End forwarded message -----\n\n\n\n"
        },
        {
            "subject": "Re: Layering and Sharedkey authenticatio",
            "content": "> A lot of the arguments against shared secret client authentication\n> seem to be layering arguments. Specifically, the argument seems to \n> be that shared secret style authentication properly belongs at the\n> application layer.\n\nI may be the first person to have mentioned the specific issue of a\nlayering violation, and I'll clarify a misunderstanding here.  My issue\nhad nothing to do with using shared secrets.  (I can't speak for the\nparticular issues anyone else may have intended.)\n\nMy issue was related to the specific proposal made by Microsoft, which\nwould force specific application level issues, related to the languages\nand character sets used by applications (and in fact whether the secret\nis directly known to a user or not, etc), into the transport layer\nsecurity protocol.  (Resolve that issue and there were still a bunch of\nother issues ... )\n\nIn no way did I say that \"shared secrets\" in general are bad to include\nin a transport level, or contrariwise that \"public keys\" are bad.  One\nonly needs to look at GSS-API for an example of some existing practice,\nalready deemed reasonable by the IETF.  It supports both schemes.\n\nIf folk want shared secret authentication, I suggest looking at the\nwork already done by the GSS-API working group; it's supported Kerberos\nfor a long time, and evidently now supports some public key flavors.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "VDEX vocabulary definition exchange specificatio",
            "content": "My attention has been drawn, by Mike Collett, Schemeta, via Stella \nDextre Clarke, to a vocabulary definition exchange specification called \n\"VDEX\" produced by IMS Global:\n\n<http://www.imsglobal.org/vdex/>\n\nThis is being tried out in some HE/FE organisations, for example:\n\n<http://www.icbl.hw.ac.uk/vdex/>\n\nAre the esw-thes people aware of this, and are any steps being taken to \ncoordinate the two areas of work?\n\nLeonard will\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Definition of &quot;facet&quot",
            "content": "Leonard,\n\nMy concern with any definition we would accept is related to the\nfunctionality\nthis may imply\n\nI have in mind the following:\n\n1) facets in expressing semantic (logical hierarchy and poly-hierarchy)\nhere is where the issue of facet/array and inheritance comes\n\n- a little digression may be relevant here:\nSvenonius suggested that for m2m handling of vocabulary there should be\nprovision\nfor indicating the difference between hierarchy types:\nlogical hierarchy (one concept-one hierarchy) and perspective hierarchy\n(one concept more than one hierarchy)\nfirst hierarchy type is good for broadening and narrowing search in IR when\nvocabulary\ncovers single subject area (e.g. thesauri)\nsecond hierarchy type is paramount for disambiguation (when vocabulary\ncovers\nuniversal knowledge area e.g. classifications)\n\nthe question is: if we accept to declare that something is a facet in\nSKOS/OWL does this mean that\nonly logical hierarchies are allowed... and that the same concept will not\noccur\nin other hierarchies within the same KOS irrespective whether the concepts\nare naturally\ncontext free and irrespective the coverage of KOS\n(thinking here of polysems (culture, organization, democracy) and other\nvague concepts such as water, marble, cell etc. and the way they may be\ntreated in\nspecial and general KOS)\n\n2) facets in expressing syntax/structure\n(i.e. combining terms from different facets)\nhere is where the issue of encoding of an open set of facets\nis important. Different KOS need to declare their own facets/arrays\non a top of which one could later build applications for handling syntax\nroles and rules\n\nI think the care should be taken (if it hasn't been already)\nto allow for both.\n\nThere is no agreement on the semantic of fundamental facets so pinning\ndown the semantic can hardly be the ONLY reason for stating the facet.\nThesauri usually declare facets for vocabulary building/control/management\nwhile classification systems, apart from this, exploit facets also for\nprecision in indexing (i.e. building complex expressions). Hence, the first\nones have only facets and the second one have both facets and roles attached\nto them\n\nOutside traditional KOS and in the spectrum of different so called\n'faceted' vocabularies created to support browsing on portals the reasons\nfor\nencoding facets is the same. These vocabularies do not attach any\n'fundamental' meaning to the facets and yet they exploit them\nto achieve certain functionality in managing terminology\nand creating browsing/searching interface\n\n>\n> >       Mills/Broughton applied in BC2:\n> >Thing/kind/part/property/material/process/operation/patient/product/by-\n> >product/agent/space/time\n>\n> I'm not so happy about calling these \"facets\", because some of them\n> depend on the role that something has rather than the fundamental\n> category to which it belongs. This is a rule for citation order, in\n> which I would say that the \"thing\" or \"material\" facets may occur more\n> than once, as \"thing\", \"material\", \"patient\", \"product\" and \"by-product\"\n> for example. Your other examples below are versions of this, or mixtures\n> ASSOCIATED CONCEPTS FACET\n> PHYSICAL ATTRIBUTES FACET\n> STYLES AND PERIODS FACET\n> AGENTS FACET\n> ACTIVITIES FACET\n> MATERIALS FACET\n> OBJECTS FACET\"\n>\n> This doesn't say anything about roles.\n\n\nIn order to have roles  one has to have data structure to which to\nattach these roles (and later on the rules for processing the roles).\n\nBut the very fact that classification facets have their roles is *exactly*\nthe reason why\nI would want to encode them for machine processing: I need to handle and\nautomate syntax. For processing pre-coordinate vocabularies it is very\nimportant\nto know that one concept belong to a certain facet as this context will\ndetermine\nits place in a string, its role and its meaning in this particular facet\nas opposed to its meaning when it occurs in some other facet...\nMy understanding is that thesauri may as well 'pretend' that facets are\nfundamental\ncategories of mutually exclusive terms and fix each term to occur only in\none facet\nThesauri have less need for disambiguation - because they are\nzooming down on the narrow subject area where one concept has only one\nbroader concept\nand often only one role. Such is the case of materials in AAT... where\nstone or glass or leather is not discussed outside their role in the Art and\nArchitecture.\n\na) AAT, for instance,  does not have to accommodate 'marble deposits in\ngeology'\nwhere the same concept may not be treated as 'material' .\n\nb) thesauri do not need to use facets to\nexercise the roles as they are used for single term indexing\n(post-coordinate indexing)\nThey don't combine terms together in a complex expression.\n[having said that: if one chose to produce composite terms with thesaurus,\none\nwould need to attach role to the facets_\n\nAny analytico-synthetic classifications and other pre-coordinated indexing\nlangauges have to exploit facet analysis for more than one purpose. This\ndoes not mean that facet in classification (Processes or Materials, Place)\nin the context of a given discipline are not classes in which essential\nproperties are\nexhibited by all its members.\n\n(We can, for the purpose of this discussion, think of classification such as\nBliss 2\nto be a collection of thesauri for instance)\n\n\n\naida\n\n\n\n"
        },
        {
            "subject": "Re: Definition of &quot;facet&quot",
            "content": "In message <AAEKLFPLCPPCFCOACDKIGEKMCJAA.aida@acorweb.net> on Mon, 1 Mar\n2004, Aida Slavic <aida@acorweb.net> wrote\n>\n>Leonard,\n>\n>My concern with any definition we would accept is related to the functionality\n>this may imply\n\nAida\n\nYes, I agree. We should probably practice what we preach, and define\nthese concepts in terms of their functionality. If in doing so we find\nthat we are talking about more than one distinct concept, then we need\nto find distinct names for them.\n\n>I have in mind the following:\n>\n>1) facets in expressing semantic (logical hierarchy and poly-hierarchy)\n>here is where the issue of facet/array and inheritance comes\n>\n>- a little digression may be relevant here:\n>Svenonius suggested that for m2m handling of vocabulary there should be\n>provision for indicating the difference between hierarchy types: logical\n>hierarchy (one concept-one hierarchy) and perspective hierarchy (one\n>concept more than one hierarchy) first hierarchy type is good for broadening\n>and narrowing search in IR when vocabulary covers single subject area (e.g.\n>thesauri) second hierarchy type is paramount for disambiguation (when\n>vocabulary covers universal knowledge area e.g. classifications)\n\nI'm not sure whether any new distinction is being made here or whether\nshe is just making the distinction between mono- and poly-hierarchy.\nI.e. whether or not a term can have more than one broader term.\n\n>the question is: if we accept to declare that something is a facet in\n>SKOS/OWL does this mean that only logical hierarchies are allowed... and\n>that the same concept will not occur in other hierarchies within the same\n>KOS irrespective whether the concepts are naturally context free and\n>irrespective the coverage of KOS (thinking here of polysems (culture,\n>organization, democracy) and other vague concepts such as water, marble,\n>cell etc. and the way they may be treated in special and general KOS)\n\nIt seems to me that the only case where mono-hierarchies are required is\nsomething like a formal biological taxonomy, where membership of a\nparent concept is an essential part of the definition of a concept.\n\"Whales\" are \"mammals\" _by definition_ and they cannot therefore have\nany other parent concept such as \"fishes\" or \"insects\".\n\nIn any other kind of hierarchy a term can in principle have more than\none broader term, so that \"whales\" can be a narrower term of \"mammals\"\nas well as being a narrower term of \"aquatic creatures\", where it may\nhave \"fish\" and \"plankton\" as sibling terms. This polyhierarchical\nstructure allows broadening of searches for \"all mammals\" or \"all\naquatic creatures\", so I'm puzzled by the suggestion you quote above\nthat a monohierarchy is desirable for this purpose.\n\nThe only restriction is that the parent concepts must belong to the same\nfundamental category (which I call a facet). \"Whales\" is in the facet of\n\"organisms\" or \"living things\" and cannot have a parent concept in the\nfacet of \"disciplines\", or \"actions\", or \"places\", for example.\n\nSome thesauri are restricted to being mono-hierarchical because of\nlimitations in the software used to construct them, but that is not\nsomething  that we should accept as a general principle.\n\nI don't think that the issue of polysemes is relevant here, because we\nare talking about the relationship between _concepts_ rather than words.\nIf a word can represent more than one concept within a controlled\nvocabulary then it is not a good descriptor and needs to be qualified to\nshow which concept it represents. If it represents only one concept\nwithin the vocabulary, though it can represent other concepts elsewhere,\nthen its scope note needs to show clearly that its meaning is\nrestricted.\n\n>2) facets in expressing syntax/structure\n>\n>There is no agreement on the semantic of fundamental facets so pinning\n>down the semantic can hardly be the ONLY reason for stating the facet.\n>Thesauri usually declare facets for vocabulary building/control/management\n>while classification systems, apart from this, exploit facets also for\n>precision in indexing (i.e. building complex expressions). Hence, the first\n>ones have only facets and the second one have both facets and roles\n>attached to them\n\nYes, I think that this is the core of the problem. The rules for\ncombining descriptors to create a compound string to represent a\ncombination of concepts, are often called rules for the \"citation order\nof facets\", but as I said in my last message this meaning of \"facet\" is\ndifferent from the \"fundamental category\" meaning. We are talking about\ntwo different concepts, and I think we should give them different names.\n\nWhen we build a string using a rule such as\n\n>> >Thing/kind/part/property/material/process/operation/patient/product/by-\n>> >product/agent/space/time\n\nI would say that \"we are combining concepts (or the terms which\nrepresent concepts) according to their roles\", with no mention of\nfacets.\n\nIn the strings\n\n        boys kissing girls\nand\n        girls kissing boys\n\n\"boys\" and \"girls\" both belong to the same facet of \"people\". The\ncitation order is determined by roles and not by facets.\n\n>Outside traditional KOS and in the spectrum of different so called 'faceted'\n>vocabularies created to support browsing on portals the reasons for\n>encoding facets is the same. These vocabularies do not attach any\n>'fundamental' meaning to the facets and yet they exploit them to achieve\n>certain functionality in managing terminology and creating\n>browsing/searching interface\n\nYes, this is another meaning again. When an interface allows you to\nsearch for wine first by origin, then by colour, then by sweetness, it\nis allowing you to apply successive characteristics of division in order\nto reduce the number of entries in the arrays at the lowest level. This\nis a fundamental feature of \"faceted classification\", but neither the\n\"characteristics of division\" (origin, colour, sweetness) nor the\nresulting arrays are \"facets\" in the sense of \"fundamental categories\",\nand I think it misleading to call them that.\n\n>In order to have roles  one has to have data structure to which to\n>attach these roles (and later on the rules for processing the roles).\n\nWe don't need a structure other than well-defined concepts to attach\nroles to. The fact that boys and girls are in the same facet in the\nexample about doesn't help in determining their roles.\n\n>But the very fact that classification facets have their roles\n\nI don't believe that they do, unless you are defining \"classification\nfacets\" to _mean_ roles. Doing that seems to introduce unnecessary\nconfusion..\n\n> is *exactly* the reason why I would want to encode them for machine\n>processing: I need to handle and automate syntax. For processing pre-\n>coordinate vocabularies it is very important to know that one concept belong\n>to a certain facet as this context will determine its place in a string, its role\n\nIts role, not the facet to which it belongs, will determine its place in\na string.\n\n> and its meaning in this particular facet as opposed to its meaning when it\n>occurs in some other facet...\n\nMeaning of concepts should be defined by scope notes. A single concept\nshould not occur in more than one facet, though it may occur in more\nthan one hierarchy within a single facet (see above).\n\n>My understanding is that thesauri may as well 'pretend' that facets are\n>fundamental categories of mutually exclusive terms and fix each term to\n>occur only in one facet Thesauri have less need for disambiguation -\n>because they are zooming down on the narrow subject area where one\n>concept has only one broader concept and often only one role. Such is the\n>case of materials in AAT... where stone or glass or leather is not discussed\n>outside their role in the Art and Architecture.\n>\n>a) AAT, for instance,  does not have to accommodate 'marble deposits in\n>geology' where the same concept may not be treated as 'material' .\n\nI don't see the problem here. The concept of \"marble\" refers to \"a\ngranular crystalline limestone\", and this is always true (_pace_ any\npedantic geologists). It may be put into an array under the node label\n<rock by composition> and into another array under the broader term\n\"materials for sculpture\" (if that is its only use within the scope of\nthe thesaurus). It may also be combined into an indexing string with the\ndiscipline of \"geology\" and the form \"deposits\". None of these affects\nthe nature of the concept or its membership of a \"materials\" facet.\n\n>b) thesauri do not need to use facets to exercise the roles as they are used\n>for single term indexing (post-coordinate indexing) They don't combine\n>terms together in a complex expression. [having said that: if one chose to\n>produce composite terms with thesaurus, one would need to attach role to\n>the facets_\n>\n>Any analytico-synthetic classifications and other pre-coordinated indexing\n>langauges have to exploit facet analysis for more than one purpose. This\n>does not mean that facet in classification (Processes or Materials, Place) in\n>the context of a given discipline are not classes in which essential properties\n>are exhibited by all its members.\n>\n>(We can, for the purpose of this discussion, think of classification such as\n>Bliss 2 to be a collection of thesauri for instance)\n>\nYes, I am becoming more and more convinced that thesauri and\nclassification schemes are just alternative ways or arranging and\npresenting lists and groups of concepts. I therefore am very keen to\nhelp arrive at a single set of unambiguous terms which we can use to\ndiscuss these things, rather than having to qualify statements by saying\nthat we are talking \"in a thesaurus context\" or \"in a classification\ncontext\".\n\nThis is an interesting discussion - I wonder whether other people have\nviews on whether what we are saying makes sense.  Are we making any\nprogress towards a consensus of opinion?\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Modelling 'term-toterm' relationships in SKO",
            "content": "I designed SKOS to be strictly concept-oriented.  In this view there are\nonly 'concepts' and 'labels'.\n\n\nAntonymy:\n\nIn the concept-oriented view, 'antonymy' would be represented as a\nrelationship between two concepts.  So in an imaginary thesaurus, concept A\n(label 'Black') is opposite of concept B (label 'White').  As an extension\nof SKOS, the relationship 'is opposite of' would be modelled as a\nsub-property of skos:SemanticRelation.\n\n\nUS/UK Alts:\n\nIf distinguishing between US/UK alts is important, they could both be\nrepresented as labels with language tags, treating US-English and UK-English\nas separate languages.  E.g.\n\n<skos:Concept>\n<skos:prefLabel xml:lang=\"en-US\">Color</skos:prefLabel>\n<skos:prefLabel xml:lang=\"en-GB\">Colour</skos:prefLabel>\n</skos:Concept>\n\n[RDF-folks: can we do this ... have I got the codes right for the language\ntags of the literals?]\n\nI suspect most of the time it will be sufficient to include US spelling alts\namong the altLabels (if it is an english thesaurus), without needing to add\nlanguage tags.  This would be enough to ensure concepts are picked up by\nsearching yanks.\n\n\nTypes of synonyms and parts of speech:\n\nDoug: can you elabourate on what these are for us?\n\n\nEquivalence between terms:\n\nIn the concept-oriented view, a label is simply a string.  Therefore, there\nis no notion of 'equivalence' between labels.\n\nA label may be used as a label for more than one concept.  However, a label\nis always considered to be empty of meaning.  Therefore, there is no notion\nof 'equivalence' between a label and a concept.  \n\nSKOS supports a notion of 'equivalence' between concepts.  This may either\nbe modelled as a sub-property of skos:SemanticRelation (i.e. an\nintra-thesaurus relation) or a sub-property of skos-map:SemanticMapping\n(i.e. an inter-thesaurus relation).  \n\nE.g. SKOS-Mapping contains the property skos-map:exactMapping, which could\nbe used to express an 'exact equivalence' relationship between two concepts.\n\n\nE.g. SKOS-Mapping contains two properties skos-map:MajorMapping and\nskos-map:MinorMapping, which could be used to express greater or lesser\ndegrees of 'equivalence' between concepts.\n \n\nFinal word:\n\nThis is how I think of it.  To switch from a 'term-oriented' view to a\n'concept-oriented' view, instead of 'term' think 'concept+label'.\n\nWhat does everyone think?\n\nAl.\n\n\nDoug wrote:\n> However there are some other possibilities that may be more \n> difficult to\n> implement without explicit equivalence relationships.\n> - various subtypes of equivalence corresponding to\n> parts-of-speech relationships, US/UKalts, types of synonyms, \n> antonyms (even)\n> - in some cases a term can be considered Equivalent to more than\n> one concept (perhaps with different degrees of confidence).\n> \n> I guess these are more future application possibilities, might\n> be considered as less 'core' and we may be in danger of \n> over-elaborating.\n> However if we go on to extend the current core thesaurus\n> relationships by specialisation then we might also want to distinguish\n> subtypes of equivalence. This might be easier if there was an explicit\n> equivalence relationship.\n> \n> \n> Doug\n>\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440 \n\n\n\n"
        },
        {
            "subject": "Re: Layering and Sharedkey authenticatio",
            "content": "EKR,\n\n  Please read below your comments.\n\nAt 11:30 AM 10/8/96 -0700, you wrote:\n>A lot of the arguments against shared secret client authentication\n>seem to be layering arguments. Specifically, the argument seems to \n>be that shared secret style authentication properly belongs at the\n>application layer. While I feel that this argument has some force\n>in principle, it seems to me to be deeply problematic in this specific\n>case, for a number of reasons:\n>\n>1. The security services that TLS provides to the application layer\n>are inadequate for this purpose. The obvious approach to layering\n>protocols which require shared secret authentication over TLS \n>is simply to pass the shared secret directly over the TLS channel,\n>using TLS as TCP has always been used. However, in the common case, \n>TLS application layer data is encrypted with a 40 bit keyspace,\n>which means that that's all the protection provided for the\n>shared secret. Consequently, we either have to accept this limitation\n>or the application needs to provide it's own protection for\n>the shared secret. \n\n  I think that the latter is going to win out in the long haul.  The reason is\nthat 40 bit keyspace is really not adaquate for modern day buisnesses and\napplications.  Another approach would be to modify that keyspace to\n128, which would quiet alot of commercial concerns.  Otherwise providing for\nthat level(128 bit) will be done in a non-standerd manner by those \ncommercial buisnesses for providing their customers better \"Adaquate\" \nprotection of their data.\n>\n>\n>2. Forcing applications to provide their own security argues against\n>the purpose of TLS. Much of the argument for TLS is that applications\n>can then be largely security oblivious while still taking advantage\n>of security services. While data confidentiality for the data on the\n>channel is important, there is a lot of historical evidence that the\n>primary security need for e.g. telnet is actually access control, not\n>data confidentiality, and this is typically provided via a shared secret.\n>If TLS can't serve this need in an adequate way, then securing them\n>will require a lot more work than just layering them on top of\n>TLS--at which point one might easily imagine providing an application\n>specific protocol which would meet that application's precise security\n>needs in a single package.\n\n  I would agree that forcing applications to provide their own security is\ncontrary to the TLS perposal, it may very well become a common practice\nwith respect to the weakness of 40 bit common keysize.  I don't agree that\nTLS should only address access security per say.  Buisnesses need to feel\nsafe that they believe and can trust that their data is secure, which agrues in\nfavor of layering, IE application layer.  I think the idea of an application\nspicific protocol, is a intresting thought, except I think I would carry it out\nto a more generic or encompassing protocol, with a common interface. \n>\n>\n>3. There are a large number of common internet protocols which require\n>shared secret style authentication, including but not limited to telnet,\n>the Berkeley r-protocols, NNTP under certain circumstances... So,\n>we're going to be reinventing this wheel a lot of times. This still\n>doesn't make it TLS's job, but it's hard to see who's job it is,\n>then.\n\n  I agree that it is not TLS's job.  But I would look at at least providing\nan exit for and interface for TLS, not to mention SSL, Berkeley r-protocols,\nand any other shared secret protocols. \n>\n>\n>4. We've already violated this layering boundary. Public key style\n>client authentication isn't really a necessary part of TLS service\n>provision and could be easily handled at the application layer. This\n>layering argument would be a lot more convincing if we hadn't\n>already gone against it.\n\n  Well that is history now.  The real question is how do we handlee it?\n\nReguards,\n\n>\n>-Ekr\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC. Representing PDS .Ltd.\nWeb: http://www.pds-link.com\nPhone: 214-793-7445 (Direct Line)\nFax: 214-447-1900\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Modelling 'term-toterm' relationships in SKO",
            "content": "In message \n<350DC7048372D31197F200902773DF4C047485F4@exchange11.rl.ac.uk> on Wed, 3 \nMar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>\n>I designed SKOS to be strictly concept-oriented.  In this view there are\n>only 'concepts' and 'labels'.\n>\n>Antonymy:\n>\n>In the concept-oriented view, 'antonymy' would be represented as a \n>relationship between two concepts.  So in an imaginary thesaurus, \n>concept A (label 'Black') is opposite of concept B (label 'White').  As \n>an extension of SKOS, the relationship 'is opposite of' would be \n>modelled as a sub-property of skos:SemanticRelation.\n\nThere are some cases where apparent antonyms are alternative labels for \nthe same concept. \"Dryness\" and \"wetness\" for example are both possible \nlabels for the concept of \"moisture content\". (The \"half-full\" or \n\"half-empty\" situation.)\n\n>Equivalence between terms:\n>\n>In the concept-oriented view, a label is simply a string.  Therefore, there\n>is no notion of 'equivalence' between labels.\n>\n>A label may be used as a label for more than one concept.\n\nThis worries me. A label is only of use if it identifies the thing it \nlabels. I may have three jars labelled \"coffee\", of which one contains \ncoffee, one contains tea and the other contains sugar, but this is not \nthe sort of situation we should accept.\n\nDid you mean to say that a concept may have more than one label? That is \ncertainly true, and two labels that refer to the same concept could \nreasonably be said to be \"equivalent\".\n\n>However, a label is always considered to be empty of meaning. \n>Therefore, there is no notion of 'equivalence' between a label and a \n>concept.\n\nPerhaps not \"equivalence\" but still a close association. The label is a \nconvenient way of referring to the concept, avoiding the need to write \nout the scope note in full every time you want to refer to it. If I \nlabel a jar \"coffee\", \"caf?\" or \"641.3373\", those symbols are by no \nmeans empty of meaning; they indicate the same substance even though the \ncharacter strings are not \"equivalent\" to the substance.\n\n>SKOS supports a notion of 'equivalence' between concepts.  This may \n>either be modelled as a sub-property of skos:SemanticRelation (i.e. an \n>intra-thesaurus relation) or a sub-property of skos-map:SemanticMapping \n>(i.e. an inter-thesaurus relation).\n>\n>E.g. SKOS-Mapping contains the property skos-map:exactMapping, which \n>could be used to express an 'exact equivalence' relationship between \n>two concepts.\n\n>E.g. SKOS-Mapping contains two properties skos-map:MajorMapping and \n>skos-map:MinorMapping, which could be used to express greater or lesser \n>degrees of 'equivalence' between concepts.\n\nAs you have indicated, equivalence between concepts is something that \nshould arise only when mapping between different thesauri.\n\nIf two concepts within a single thesaurus are exactly equivalent, I see \nno need for them both to be present. They should be combined, as there \nis only one concept, not two.\n\nIf there is partial equivalence between concepts in a single thesaurus, \nthen either one is a narrower term of the other or else there is an area \nof overlap (e.g. \"ships\" and \"boats\"). In the latter case the scope of \neach concept should if possible be redefined so as to eliminate this \noverlap, as it will lead to uncertainty in using the thesaurus. An \nassociative link may then be made between the two related concepts.\n\nIt must be difficult to differentiate between MajorMapping and \nMinorMapping, but it is probably helpful to have these to indicate large \nor small extents of overlap.\n>\n>Final word:\n>\n>This is how I think of it.  To switch from a 'term-oriented' view to a\n>'concept-oriented' view, instead of 'term' think 'concept+label'.\n\nOr 'concept + as many labels as necessary' (of which one may be \ndesignated as the \"preferred\" label or \"descriptor\").\n\n>What does everyone think?\n>\n>Al.\n\nMy tuppence worth.\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Thesaurus FAQ Entry: 'How can I make my thesaurus a part of the s emantic web?",
            "content": "Just blogged this FAQ item, <http://esw.w3.org/mt/esw/archives/000045.html>.\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "FW: Modelling 'term-toterm' relationships in SKO",
            "content": "I agree with Leonard's comments below. Picking up on another point in\nAlistair's earlier message, \"US/UK Alts:\n\nIf distinguishing between US/UK alts is important, they could both be\nrepresented as labels with language tags, treating US-English and\nUK-English as separate languages.  E.g.\n\n<skos:Concept>\n<skos:prefLabel xml:lang=\"en-US\">Color</skos:prefLabel>\n<skos:prefLabel xml:lang=\"en-GB\">Colour</skos:prefLabel>\n</skos:Concept>\n\nI suspect most of the time it will be sufficient to include US spelling\nalts among the altLabels (if it is an english thesaurus), without\nneeding to add language tags.  This would be enough to ensure concepts\nare picked up by searching yanks.\"\n\nDirect immediate searching may not be the only need. If you want to use\nthe data to print out or present an on-screen display of the thesaurus\nfor human look-up, then you might want to present a British-spelt\nversion for UK users, an American spelt version for US users. You might\neven want to give users an option to choose their dialect, just as they\nmight choose to display in French or German. For this purpose\nundifferentiated altLabels are insufficient.\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Leonard Will\nSent: 03 March 2004 18:21\nTo: public-esw-thes@w3.org\nSubject: Re: Modelling 'term-to-term' relationships in SKOS\n\n\n\nIn message\n<350DC7048372D31197F200902773DF4C047485F4@exchange11.rl.ac.uk> on Wed, 3\n\nMar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>\n>I designed SKOS to be strictly concept-oriented.  In this view there \n>are only 'concepts' and 'labels'.\n>\n>Antonymy:\n>\n>In the concept-oriented view, 'antonymy' would be represented as a\n>relationship between two concepts.  So in an imaginary thesaurus, \n>concept A (label 'Black') is opposite of concept B (label 'White').  As\n\n>an extension of SKOS, the relationship 'is opposite of' would be \n>modelled as a sub-property of skos:SemanticRelation.\n\nThere are some cases where apparent antonyms are alternative labels for \nthe same concept. \"Dryness\" and \"wetness\" for example are both possible \nlabels for the concept of \"moisture content\". (The \"half-full\" or \n\"half-empty\" situation.)\n\n>Equivalence between terms:\n>\n>In the concept-oriented view, a label is simply a string.  Therefore, \n>there is no notion of 'equivalence' between labels.\n>\n>A label may be used as a label for more than one concept.\n\nThis worries me. A label is only of use if it identifies the thing it \nlabels. I may have three jars labelled \"coffee\", of which one contains \ncoffee, one contains tea and the other contains sugar, but this is not \nthe sort of situation we should accept.\n\nDid you mean to say that a concept may have more than one label? That is\n\ncertainly true, and two labels that refer to the same concept could \nreasonably be said to be \"equivalent\".\n\n>However, a label is always considered to be empty of meaning.\n>Therefore, there is no notion of 'equivalence' between a label and a \n>concept.\n\nPerhaps not \"equivalence\" but still a close association. The label is a \nconvenient way of referring to the concept, avoiding the need to write \nout the scope note in full every time you want to refer to it. If I \nlabel a jar \"coffee\", \"caf?\" or \"641.3373\", those symbols are by no \nmeans empty of meaning; they indicate the same substance even though the\n\ncharacter strings are not \"equivalent\" to the substance.\n\n>SKOS supports a notion of 'equivalence' between concepts.  This may\n>either be modelled as a sub-property of skos:SemanticRelation (i.e. an \n>intra-thesaurus relation) or a sub-property of skos-map:SemanticMapping\n\n>(i.e. an inter-thesaurus relation).\n>\n>E.g. SKOS-Mapping contains the property skos-map:exactMapping, which\n>could be used to express an 'exact equivalence' relationship between \n>two concepts.\n\n>E.g. SKOS-Mapping contains two properties skos-map:MajorMapping and\n>skos-map:MinorMapping, which could be used to express greater or lesser\n\n>degrees of 'equivalence' between concepts.\n\nAs you have indicated, equivalence between concepts is something that \nshould arise only when mapping between different thesauri.\n\nIf two concepts within a single thesaurus are exactly equivalent, I see \nno need for them both to be present. They should be combined, as there \nis only one concept, not two.\n\nIf there is partial equivalence between concepts in a single thesaurus, \nthen either one is a narrower term of the other or else there is an area\n\nof overlap (e.g. \"ships\" and \"boats\"). In the latter case the scope of \neach concept should if possible be redefined so as to eliminate this \noverlap, as it will lead to uncertainty in using the thesaurus. An \nassociative link may then be made between the two related concepts.\n\nIt must be difficult to differentiate between MajorMapping and \nMinorMapping, but it is probably helpful to have these to indicate large\n\nor small extents of overlap.\n>\n>Final word:\n>\n>This is how I think of it.  To switch from a 'term-oriented' view to a \n>'concept-oriented' view, instead of 'term' think 'concept+label'.\n\nOr 'concept + as many labels as necessary' (of which one may be \ndesignated as the \"preferred\" label or \"descriptor\").\n\n>What does everyone think?\n>\n>Al.\n\nMy tuppence worth.\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Modelling 'term-toterm' relationships in SKO",
            "content": "Stella wrote:\n> Direct immediate searching may not be the only need. If you \n> want to use\n> the data to print out or present an on-screen display of the thesaurus\n> for human look-up, then you might want to present a British-spelt\n> version for UK users, an American spelt version for US users. \n> You might\n> even want to give users an option to choose their dialect, \n> just as they\n> might choose to display in French or German. For this purpose\n> undifferentiated altLabels are insufficient.\n\nLabels with language tags are sufficient for this (if each dialect is\ntreated as a separate language).\n\n(e.g.\n<skos:Concept>\n<skos:prefLabel xml:lang=\"en-US\">Color</skos:prefLabel>\n<skos:prefLabel xml:lang=\"en-GB\">Colour</skos:prefLabel>\n</skos:Concept>\n)\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Re: Thesaurus FAQ Entry: 'How can I make my thesaurus a part of the s emantic web?",
            "content": "In message \n<350DC7048372D31197F200902773DF4C0494412D@exchange11.rl.ac.uk> on Thu, 4 \nMar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>\n>Just blogged this FAQ item, <http://esw.w3.org/mt/esw/archives/000045.html>.\n\nThis looks a useful summary of where we are. Thanks. (A pity though that \nit is in pale grey type - I had to use the accessibility option to \n\"ignore colors specified on Web pages\" to make it easily legible.)\n\nI haven't followed up all the links, but was a bit puzzled by the \ndistinction between \"preferred-label\" and \"descriptor\" in SKOS-Core. \nThey seem to me to be the same thing.\n\nI take it that any labels that are not \"preferred-labels\" are by default \n\"non-preferred labels\" or \"nondescriptors\", so that is the reason why \nthese are not explicitly provided for.\n\nYou have\n\npreferred-label\nUse this property to indicate a literal which is the preferred label for \na resource. If a resource has this property, all other rdfs:label \nproperties are considered to be the 'alternative' (i.e. non-preferred) \nlabels.\n\nand\n\ndescriptor\nA 'descriptor' is a label that uniquely identifies a concept within a \nconceptual scheme. A descriptor must be unambiguous. Examples of good \ndescriptors are 'Orange (fruit)' and 'Java programming language'. \nExamples of poor descriptors are 'Orange' and 'Java'.\n\nIs there any significance in the fact that the first definition refers \nto \"a resource\" while the second refers to \"a concept\"?\n\nIn <http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html#2.2> we read:\n\n(a) The soks:prefLabel property is a sub-property of rdfs:label.\n\n(b) The soks:descriptor proeprty [sic.] is a sub-property of \nsoks:prefLabel. Therefore a concept cannot have both a descriptor and a \nprefLabel.\n\nI can see no place for a preferred label that is not a descriptor.\n\nIf the \"Therefore . . .\" statement in (b) is a consequence of the first \nsentence of (b), would there not be a parallel conclusion in (a) : \n\"Therefore a concept cannot have both a prefLabel and a label\".  Such a \nconclusion seems incorrect.\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Thesaurus FAQ Entry: 'How can I make my thesaurus a part of the semantic web?",
            "content": "In message <TCwN58DgnwRAFAhT@willpowerinfo.co.uk> on Thu, 4 Mar 2004, \nLeonard Will <L.Will@willpowerinfo.co.uk> wrote\n\n>I can see no place for a preferred label that is not a descriptor.\n\nSorry to follow up my own message, but on re-reading it I realised that \nthis sentence might be ambiguous. I didn't mean that a place should be \nprovided, but rather:\n\n\"I see no need to define a category of preferred label that is not a \ndescriptor\"\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "'prefLabel' and 'descriptor",
            "content": "Hi Leonard,\n\nThanks alot for these comments.\n\nIn SKOS-Core 1.0 there will only be a 'prefLabel' property (the 'descriptor'\nproperty has been dropped).\n\nThis change originally proposed in response to Stella's comments, in mail\n<http://lists.w3.org/Archives/Public/public-esw-thes/2004Jan/0001.html>.\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Leonard Will\n> Sent: 04 March 2004 10:50\n> To: public-esw-thes@w3.org\n> Subject: Re: Thesaurus FAQ Entry: 'How can I make my \n> thesaurus a part of\n> the s emantic web?'\n> \n> \n> \n> In message \n> <350DC7048372D31197F200902773DF4C0494412D@exchange11.rl.ac.uk>\n>  on Thu, 4 \n> Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n> >\n> >Just blogged this FAQ item, \n> <http://esw.w3.org/mt/esw/archives/000045.html>.\n> \n> This looks a useful summary of where we are. Thanks. (A pity \n> though that \n> it is in pale grey type - I had to use the accessibility option to \n> \"ignore colors specified on Web pages\" to make it easily legible.)\n> \n> I haven't followed up all the links, but was a bit puzzled by the \n> distinction between \"preferred-label\" and \"descriptor\" in SKOS-Core. \n> They seem to me to be the same thing.\n> \n> I take it that any labels that are not \"preferred-labels\" are \n> by default \n> \"non-preferred labels\" or \"nondescriptors\", so that is the reason why \n> these are not explicitly provided for.\n> \n> You have\n> \n> preferred-label\n> Use this property to indicate a literal which is the \n> preferred label for \n> a resource. If a resource has this property, all other rdfs:label \n> properties are considered to be the 'alternative' (i.e. \n> non-preferred) \n> labels.\n> \n> and\n> \n> descriptor\n> A 'descriptor' is a label that uniquely identifies a concept within a \n> conceptual scheme. A descriptor must be unambiguous. Examples of good \n> descriptors are 'Orange (fruit)' and 'Java programming language'. \n> Examples of poor descriptors are 'Orange' and 'Java'.\n> \n> Is there any significance in the fact that the first \n> definition refers \n> to \"a resource\" while the second refers to \"a concept\"?\n> \n> In <http://www.w3c.rl.ac.uk/SWAD/deliverables/8.1.html#2.2> we read:\n> \n> (a) The soks:prefLabel property is a sub-property of rdfs:label.\n> \n> (b) The soks:descriptor proeprty [sic.] is a sub-property of \n> soks:prefLabel. Therefore a concept cannot have both a \n> descriptor and a \n> prefLabel.\n> \n> I can see no place for a preferred label that is not a descriptor.\n> \n> If the \"Therefore . . .\" statement in (b) is a consequence of \n> the first \n> sentence of (b), would there not be a parallel conclusion in (a) : \n> \"Therefore a concept cannot have both a prefLabel and a \n> label\".  Such a \n> conclusion seems incorrect.\n> \n> Leonard\n> \n> -- \n> Willpower Information       (Partners: Dr Leonard D Will, \n> Sheena E Will)\n> Information Management Consultants              Tel: +44 \n> (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 \n> (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               \n> Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n> \n\n\n\n"
        },
        {
            "subject": "Re: 'prefLabel' and 'descriptor",
            "content": "In message \n<350DC7048372D31197F200902773DF4C04944130@exchange11.rl.ac.uk> on Thu, 4 \nMar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>Hi Leonard,\n>\n>Thanks alot for these comments.\n>\n>In SKOS-Core 1.0 there will only be a 'prefLabel' property (the 'descriptor'\n>property has been dropped).\n>\n>This change originally proposed in response to Stella's comments, in mail\n><http://lists.w3.org/Archives/Public/public-esw-thes/2004Jan/0001.html>.\n>\n>Al.\n\nAl -\n\nThanks. Sorry I had overlooked the fact that Stella got there before me!\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Modelling 'term-toterm' relationships in SKO",
            "content": ">Types of synonyms and parts of speech:\n\nThe standards mention types of equivalence relationships. Most of these are\nnot currently explicitly represented. It is possible that they might be\nthough in the future by specialisation.\nSome thesauri do in fact explicitly represent types of equivalence (see\nbelow).\n\nFrom Aitchison, Gilchrist & Bawden, 2000\n(the new draft thesaurus standard is similar)\nF1.1.1 synonyms\npopular - scientific names\ncommon names - trade names\nstandard names - slang\ncurrent - obselete\netc\nF1.1.2 Lexical variants\nvariant spellings\nabbreviations - full names\nsingular - plural\n(perhaps in some cases noun-adjective - I think it is useful to have the\noption of augmenting thesauri in the future with some basic linguistic\nrelationships. )\n\nIn some Thesauri, different types of equivalence are explicitly represented\neg (I've also seen examples concerning trade names and types of scientific\nname in other thesauri)\nfrom http://www.multites.com/conference03.htm, CAB Thesaurus presentation\n(James Brooks)\nCAB Thesaurus in MultiTes - Equivalence Relationships\nCNP - Common Name PT vs SNN - Scientific Name NPT\nCSN - Chemical Standard Name vs CTN - Chemical Trade Name\nFFT - Full Form vs ABB - Abbreviated Form\nSEN - Senior Scientific Name vs JUN - Junior Scientific Name\nSNP - Scientific Name PT vs CNN - Common Name NPT\nUK - British Form vs US - American Form\n\nThe question is whether the concept plus labels route would make these\ndistinctions harder to make? One way I suppose would be to introduce more\ntypes of mark-up in the labels as for the language tags? I think it is\nimportant to try and cater for common (and maybe extensible for future)\nsubtypes here - could this be done by specific tags?\n\n\n> A label may be used as a label for more than one concept.\n\nHomographs are common in natural language and can arise in controlled\nlanguages. Some thesauri do have more than one concept associated with a\nnon-preferred term (eg AAT). My concern was that only having labels in SKOS\nwould make it more difficult for a retrieval application to deal with this\nsensibly - having to process all sets of labels for a thesaurus as opposed\nto directly looking up a term in the entry vocabulary. However on\nreflection, I guess that applications would populate a dictionary or set of\ndata structures from the SKOS information for a particular KOS and work off\nthat.\nIs this how you see it, Al?\n\nDoug\n\n\n\n"
        },
        {
            "subject": "SKOS and OW",
            "content": "Anticipating an FAQ item (and probably extended debate) on the relationship\nbetween SKOS and OWL, so I had a go at a draft on the subject.  I'd like to\nknow what you think of this.\n\nAl.\n\n----------------------------------------------------------\nQ: What's the difference between SKOS and OWL? \n\nA: OWL is the Web Ontology Language, now a recommendation from W3C.  OWL\nprovides a powerful and expressive framework for adding well defined\nsemantics (meaning) to data on the web.  Adding explicit meaning to data\nallows machines to communicate with each other, turning the web into an\nenvironment for effective machine to machine (M2M) interaction, as well as\nfor human to machine (H2M) and human to human (H2H) interaction.  And\nbecause it is grounded in well-understood and formally defined systems of\nlogic, we have the opportunity to reason over the data and discover new\nfacts.    \n\nBut what happens when you give somebody (without a formal education in logic\nand set theory) an ontology editor, and ask them to create an ontology?  In\nmy own experience, the results can be varied.  Most people grasp the basic\nnotions of 'classes' 'individuals' and 'properties' without much trouble.\nHowever, one feature that I've seen misunderstood time and again is the\n'sub-class' relationship, and the meaning of a class hierarchy.  \n\nOrganising things into hierarchies is a very natural thing to do.  It is\nakin to putting things into boxes, and the boxes into bigger boxes, so you\nhave a measure of order to a number of things that is too large to hold in\nthe mind at any one time.  Everybody who has a computer has a filesystem,\ndivided into folders and subfolders.  But give a group of people the same\nset of files, and it's very likely that they'll create completely different\ndirectory structures for organising them.  The point I'm making is,\nhierarchies are natural, convenient and familiar, but different people can\nmean different things by a hierarchical relationship between two concepts.  \n\nSo often when you let someone loose on an ontology editor, they take one\nlook at the class tree displayed on the left side of the window and treat it\nlike a directory structure.  But the sub-class relationship has a very\nspecific and formally defined meaning, which must be used appropriately if\nthere is to be any guarantee of doing sensible reasoning and inference\nfurther down the line.  \n\nSo there is a definite niche for a tool that is simpler to wield than OWL,\nand won't break when confronted by the variations in peoples preference for\ndifferent styles of knowledge organisation.  \n\nThat's where SKOS comes in.  SKOS stands for Simple Knowledge Organisation\nSystem.  It allows you to define some concepts, and organise them into basic\nand familiar structures, without having to be too strict about the implied\nsemantics of those structures.  Of course SKOS is extensible, and any amount\nof semantic precision can be added (or borrowed from other schemas like\nOWL).  And of course SKOS is designed for maximal interoperability, so there\nare links between the SKOS property framework and the major vocabularies of\nRDF RDFS and OWL.  SKOS can be happily used alongside OWL, offering\nalternative views over the same underlying network of resources.  \n\nThe other major feature of SKOS is that it allows you to capture the link\nbetween a concept and the vocabulary (terminology) that is commonly used to\nrefer to it.  So every concept is expected to have a 'preferred label', and\nmay also be given any number of 'alternative labels'.  This feature can be\nused to turn any SKOS concept scheme or OWL ontology into a thesaurus.\nCapturing this information adds a lot of value, facilitating H2M and H2H\ninteraction mediated by OWL ontologies or SKOS concept schemes.\n\nSo SKOS does not try to compete with OWL in any way, but is in fact\ncomplementary to it.  It provides a simple and flexible framework for\nbuilding knowledge organisation schemes.  This means a lower entry barrier\nfor new users of the Semantic Web.  And it provides a path for bringing into\nthe Semantic Web the large amounts of existing knowledge, captured in\n'legacy' structures like thesauri, classification schemes, taxonomies and so\non, that are not mapped easily into an OWL ontology.  \n\n \n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: SKOS and OW",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-05 11:32-0000]\n> \n> Anticipating an FAQ item (and probably extended debate) on the relationship\n> between SKOS and OWL, so I had a go at a draft on the subject.  I'd like to\n> know what you think of this.\n\n[snip,\nhttp://lists.w3.org/Archives/Public/public-esw-thes/2004Mar/0012.html\nfor full msg]\n\nThis looks like a really useful start. I wonder if it could be taken in\ntwo parts: (i) an characterisation of the differences between formal\nontology/rdf approeach and thesaurus broader-term/narrower-term notions,\nparticularly referencing library world, then (ii) introduce SKOS as a\nformalisation of the latter and an exploratory basis for mapping between \nthe two...?\n\nexciting to see this stuff coming together :)\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: The Document",
            "content": "Barb Fox wrote:\n> \n> >I completely endorse David Kemp's suggestion that the first product of this\n> >working group should be the separation of the specification into two RFC\n> >documents, one defining the Record Layer, and the other defining the\n> >Handshake Protocol.  This is a great idea --- and it insures that evolution\n> >of the two components can happen independently.\n> >\n> Barb\nunsubscribe\n\n\n\n"
        },
        {
            "subject": "Re: Modelling 'term-toterm' relationships in SKO",
            "content": "I think these types of label are best modelled as subtypes of the existing\nlabel properties - whether they are preferred (perhaps under different\ncircumstances or not is something that depends on the particular thesaurus in\nquestion.\n\nThe language thing is separate - we inherit that already from XML, as others\nhave pointed out.\n\nCheers\n\nChaals\n\nOn Thu, 4 Mar 2004, Douglas Tudhope wrote:\n\n>\n>>Types of synonyms and parts of speech:\n>\n>The standards mention types of equivalence relationships. Most of these are\n>not currently explicitly represented. It is possible that they might be\n>though in the future by specialisation.\n>Some thesauri do in fact explicitly represent types of equivalence (see\n>below).\n>\n>>From Aitchison, Gilchrist & Bawden, 2000\n>(the new draft thesaurus standard is similar)\n>F1.1.1 synonyms\n>popular - scientific names\n>common names - trade names\n>standard names - slang\n>current - obselete\n>etc\n>F1.1.2 Lexical variants\n>variant spellings\n>abbreviations - full names\n>singular - plural\n>(perhaps in some cases noun-adjective - I think it is useful to have the\n>option of augmenting thesauri in the future with some basic linguistic\n>relationships. )\n>\n>In some Thesauri, different types of equivalence are explicitly represented\n>eg (I've also seen examples concerning trade names and types of scientific\n>name in other thesauri)\n>from http://www.multites.com/conference03.htm, CAB Thesaurus presentation\n>(James Brooks)\n>CAB Thesaurus in MultiTes - Equivalence Relationships\n>CNP - Common Name PT vs SNN - Scientific Name NPT\n>CSN - Chemical Standard Name vs CTN - Chemical Trade Name\n>FFT - Full Form vs ABB - Abbreviated Form\n>SEN - Senior Scientific Name vs JUN - Junior Scientific Name\n>SNP - Scientific Name PT vs CNN - Common Name NPT\n>UK - British Form vs US - American Form\n\n\n\n"
        },
        {
            "subject": "tes",
            "content": " \n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nhttp://www.Intercore.net\n\nComputer Consultant Los Angeles\n\nhttp://www.Avidware.net\n\nSecurity Consultant Los Angeles\n\nhttp://www.Avidware.com\n\nBusiness Consultant Los Angeles\n\nhttp://www.FastForwardMarcom.com\n\nWebsite Developer Los Angeles\n\nhttp://www.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nhttp://www.CorpLeasing.com\n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "Re: SWAD Europe Thesaurus wor",
            "content": "Is  there a pdf of this w3c glossary?\n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Re: Developing Use Cases for a (RDFbased) Thesaurus Servic",
            "content": "Is there any progress with this?\n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "SKOSCore 1.0 releas",
            "content": "Hi all, \n\nHere is the schema I am proposing to offer as the SKOS-Core 1.0 release:\n\n<http://www.w3c.rl.ac.uk/SWAD/rdf/skos_core_1_0.rdf>\n\nI've added a few OWL statements about transitivity etc. - I thought, why\nnot.\n\nDave, Nikki and I set a target for the release of this schema by next\nthursday, 5pm, along with a guide to using it (which I'm writing right now).\nSo all comments by next wednesday please.\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Difference between dc:subject and foaf:topi",
            "content": "Can anyone tell me what's the fundamental difference between these two\nproperties?\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Difference between dc:subject and foaf:topi",
            "content": "On Fri, 12 Mar 2004, Miles, AJ (Alistair)  wrote:\n\n>\n> Can anyone tell me what's the fundamental difference between these two\n> properties?\n\nsee a message from Dan to the foaf list:\n\nhttp://rdfweb.org/pipermail/rdfweb-dev/2003-February/011064.html\n\n[[\nI want to note a critical difference between foaf:topic and dc:subject.\nThe former realtes a document to the thing that it is about; the latter\nrelates it to a subject code that in some other formalism is taken as\nstanding for that thing.\n]]\n\nLibby\n\n>\n> Al.\n>\n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Difference between dc:subject and foaf:topi",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-12 15:23-0000]\n> \n> Can anyone tell me what's the fundamental difference between these two\n> properties?\n\ndc:subject is a relationship between a document-like-thing and some kind\nof identifier for a topic/subject that the document's contents cover\n(could be a Literal or a Resource, in RDF-ese).\n\nfoaf:topic is a relationship between a Document and a thing that the\ndocument is about. It is more direct than dc:subject, and \nallows any RDF statements to be used when identifying the thing that the \ndocument is about.\n\nSo, for a document about me. Imagine Dewey Decimal Classification had \na subject code for me, Dan Brickley... \"ddc-000.1234567\", there would be \na dc:subject property of my homepage with that as its value (perhaps\nshoe-horned into URI space somehow, eg. via a purl.org URI). By\ncontrast, you'd see foaf:topic used in any of several ways:\n\n<Document rdf:about=\"http://rdfweb.org/people/danbri/\">\n  <topic>\n    <Person foaf:name=\"Dan Brickley\" foaf:aimChatID=\"danbri_2002\"/>\n  </topic>\n</Document>\n\n...is a way of saying \"such and so document has as a topic a thing that \nhas a foaf:name \"Dan Brickley\" and an aimChatID of \"danbri_2002\".\n\nSo foaf:topic is both direct and flexible, but does not directly use \nlibrary-style classification schemes, thesauri etc. It is good for\nreferencing things that are easily identified via RDF descriptions.\n\ndc:subject always indirects via a resource that is a subject-code (or \nsimilar), whereas foaf:topic directly references the thing that the \nsubject-code is a code for.\n\nHope this makes some kind of sense!\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: Difference between dc:subject and foaf:topi",
            "content": "* Libby Miller <Libby.Miller@bristol.ac.uk> [2004-03-12 15:37+0000]\n> \n> \n> \n> On Fri, 12 Mar 2004, Miles, AJ (Alistair)  wrote:\n> \n> >\n> > Can anyone tell me what's the fundamental difference between these two\n> > properties?\n> \n> see a message from Dan to the foaf list:\n> \n> http://rdfweb.org/pipermail/rdfweb-dev/2003-February/011064.html\n> \n> [[\n> I want to note a critical difference between foaf:topic and dc:subject.\n> The former realtes a document to the thing that it is about; the latter\n> relates it to a subject code that in some other formalism is taken as\n> standing for that thing.\n> ]]\n\nAh, that was a clearer way of putting it!\n\n> Libby\n> \n> >\n> > Al.\n> >\n> > ---\n> > Alistair Miles\n> > Research Associate\n> > CCLRC - Rutherford Appleton Laboratory\n> > Building R1 Room 1.60\n> > Fermi Avenue\n> > Chilton\n> > Didcot\n> > Oxfordshire OX11 0QX\n> > United Kingdom\n> > Email:        a.j.miles@rl.ac.uk\n> > Tel: +44 (0)1235 445440\n> >\n> >\n> >\n> >\n\n\n\n"
        },
        {
            "subject": "Re: Layering and Sharedkey authenticatio",
            "content": "David Brownell - JavaSoft wrote:\n> \n> > A lot of the arguments against shared secret client authentication\n> > seem to be layering arguments. Specifically, the argument seems to\n> > be that shared secret style authentication properly belongs at the\n> > application layer.\n> \n> I may be the first person to have mentioned the specific issue of a\n> layering violation, and I'll clarify a misunderstanding here.  My issue\n> had nothing to do with using shared secrets.  (I can't speak for the\n> particular issues anyone else may have intended.)\n> \n> My issue was related to the specific proposal made by Microsoft, which\n> would force specific application level issues, related to the languages\n> and character sets used by applications (and in fact whether the secret\n> is directly known to a user or not, etc), into the transport layer\n> security protocol.  (Resolve that issue and there were still a bunch of\n> other issues ... )\n> \n> In no way did I say that \"shared secrets\" in general are bad to include\n> in a transport level, or contrariwise that \"public keys\" are bad.  One\n> only needs to look at GSS-API for an example of some existing practice,\n> already deemed reasonable by the IETF.  It supports both schemes.\n> \n> If folk want shared secret authentication, I suggest looking at the\n> work already done by the GSS-API working group; it's supported Kerberos\n> for a long time, and evidently now supports some public key flavors.\n> \n> - Dave\nunsubscribe\n\n\n\n"
        },
        {
            "subject": "Using dc:subject and foaf:topic with SKO",
            "content": "I'm trying to figure out which of these should be used with SKOS concepts.\n\nE.g.\n\nLet's say I have a concept scheme.  In my scheme is defined the following\nconcept:\n\n<skos:Concept rdf:about=\"urn:swad-e:example/concept/FastFood\">\n<skos:prefLabel>Fast food</skos:prefLabel>\n<skos:inScheme rdf:resource=\"urn:swad-e:example/thesaurus\"/>\n</skos:Concept>\n\nWhich of the following two options should we recommend using (?) :\n\n(1)\n\n<rdf:Description rdf:about=\"http://foo.com/aWebPage.html\">\n<dc:subject rdf:resource=\"urn:swad-e:example/concept/FastFood\"/>\n</rdf:Description>\n\n(2)\n\n<rdf:Description rdf:about=\"http://foo.com/aWebPage.html\">\n<foaf:topic rdf:resource=\"urn:swad-e:example/concept/FastFood\"/>\n</rdf:Description>\n\n???\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Difference between dc:subject and foaf:topi",
            "content": "It isn't clear from that explanation what the difference is, since unless you\ntalk about the domain and range of foaf:topic it's hard to understand how\nthere is any.\n\nThe fact that foaf:topic has a defined domain of foaf:Document and a range of\nrdf:Resource means that it's a bit more restricted than dc:subject which can\nhappily live with a literal value, but there doesn't seem to be much else\nthat can be used to pick between them (on my reading of the two sets of\nspecifications).\n\nIf I was trying to define the way I see the web I would write somewhere that\nfoaf:topic seems to me like a subProperty of dc:subject. Being a believer in\nliving language, and in language as an attempt to provide identifiers for\nconcepts in such a way thhat we are convinced we mean the same thing, this\ndoesn't strike me as a bad thing to do. But since we are inventing RDF\nvocabulary creation, it is something I would treat with care - especially\nwhile we don't yet have good methods for dealing with conflicting statements,\nincluding conflicting statements about how vocaublaries are defined.\n\ncheers\n\nChaals\n\nOn Fri, 12 Mar 2004, Libby Miller wrote:\n\n>On Fri, 12 Mar 2004, Miles, AJ (Alistair)  wrote:\n>\n>>\n>> Can anyone tell me what's the fundamental difference between these two\n>> properties?\n>\n>see a message from Dan to the foaf list:\n>\n>http://rdfweb.org/pipermail/rdfweb-dev/2003-February/011064.html\n>\n>[[\n>I want to note a critical difference between foaf:topic and dc:subject.\n>The former realtes a document to the thing that it is about; the latter\n>relates it to a subject code that in some other formalism is taken as\n>standing for that thing.\n>]]\n\n\n\n"
        },
        {
            "subject": "Re: Difference between dc:subject and foaf:topi",
            "content": "* Charles McCathieNevile <charles@w3.org> [2004-03-12 11:34-0500]\n> \n> It isn't clear from that explanation what the difference is, since unless you\n> talk about the domain and range of foaf:topic it's hard to understand how\n> there is any.\n\ndc:subject relates a document to a code that stands for some thing the\ndoc is about.\n\nfoaf:topic relates a document to some thing that the doc is about.\n\n...the difference is w.r.t. layers of indirection: where dc:subject uses \nan external taxonomy, set out in advance, foaf:topic relies on any chunk\nof RDF that is handy for describing the thing. It's an interesting \nstylistic and representational difference that seems really quite \nunfortunately hard to explain clearly...\n> \n> The fact that foaf:topic has a defined domain of foaf:Document and a range of\n> rdf:Resource means that it's a bit more restricted than dc:subject which can\n> happily live with a literal value, but there doesn't seem to be much else\n> that can be used to pick between them (on my reading of the two sets of\n> specifications).\n\nThey differ importantly, just as you differ from your homepage, and XML \ndiffers from library subject codes for XML. With dc:subject there is a\nwhole other world squeezed into the representation: the world of\nsubject/topic codes. With foaf:topic, the RDF itself does that work,\nremoving subject/topic codes from the list of things the RDF needs to\ndescribe. See above re this being hard to describe :(\n\n> \n> If I was trying to define the way I see the web I would write somewhere that\n> foaf:topic seems to me like a subProperty of dc:subject. \n\nthat would imply that any pair of things related by foaf:topic are also \nrelated by dc:subject. This isn't so, since the values taken by\ndc:subject are various forms of subject code, whereas the values taken\nby foaf:topic are the things that those subject codes denote. So\ndeclaring a subPropertyOf relation would confuse those two levels.\n\n>Being a believer in\n> living language, and in language as an attempt to provide identifiers for\n> concepts in such a way thhat we are convinced we mean the same thing, this\n> doesn't strike me as a bad thing to do. But since we are inventing RDF\n> vocabulary creation, it is something I would treat with care - especially\n> while we don't yet have good methods for dealing with conflicting statements,\n> including conflicting statements about how vocaublaries are defined.\n\nWe defintely need to to allow for vocabulary evolution, it might be \ninteresting to compare the two approaches...\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: Difference between dc:subject and foaf:topi",
            "content": "Charles McCathieNevile wrote:\n\n> The fact that foaf:topic has a defined domain of foaf:Document and a range of\n> rdf:Resource means that it's a bit more restricted than dc:subject which can\n> happily live with a literal value, \n\nThis is off-topic but I think these days Literals are Resources (in terms \nof the semantics document the set of literal values LV is a subset of the \nset of resources IR) so a foaf:topic with a literal value is just fine as \nfar as the range declaration is concerned.  Doesn't affect the more \nimportant philosphical distinction Dan is making.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Example from DC",
            "content": "What about this (from [1]):\n\n<RDF xmlns=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n     xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\n     xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n     xmlns:dcterms=\"http://purl.org/dc/terms/\">\n  <Description>\n    <dc:subject>\n      <Description>\n         <value>19D10</value>\n         <rdfs:label>Algebraic K-Theory of spaces</rdfs:label>\n         <rdfs:isDefinedBy rdf:resource=\"URI2\"/>\n      </Description>\n    </dc:subject>\n  </Description>\n</RDF>\n\nThis looks like the subject of the dc:subject statement is a blank node\n(i.e. a thing) with a label etc.  Could this blank node not also be the\nthing itself (i.e. this could be interpreted as having the same level of\nindirection as foaf:topic statements have)? \n\nI.e. what's the difference between the above example, and this (from [2]):\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?> \n<rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n        xmlns:foaf=\"http://xmlns.com/foaf/0.1/\" \n        xmlns:fc=\"http://xmlns.com/foaf/corp#\" \n        xmlns:dc=\"http://purl.org/dc/elements/1.1/\" > \n \n<foaf:Document rdf:about=\"http://c2.com/cgi/wiki?McDonalds\"> \n  <dc:title>McDonalds</dc:title> \n  <dc:description>McDonalds page on the C2 Wiki</dc:description> \n  <foaf:topic> \n    <fc:Company> \n      <fc:name>McDonalds</fc:name> \n      <foaf:homepage rdf:resource=\"http://www.mcdonalds.com/\"/> \n    </fc:Company> \n  </foaf:topic> \n</foaf:Document> \n\n</rdf:RDF> \n \n???\n\nAl.\n\n[1] http://dublincore.org/documents/dcq-rdf-xml/\n[2] http://rdfweb.org/topic/UsingFoafTopic\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "SKOSCore 1.0 Guide draft is onlin",
            "content": "Hi all,\n\nI'm working on the guide to SKOS-Core 1.0, to go out with the schema next\nthursday.  I've put a draft online, no examples or diagrams yet, only the\ntext.  All comments welcome.\n\n<http://www.w3c.rl.ac.uk/SWAD/skos/1.0/guide/draft01.html>\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: SKOSCore 1.0 Guide draft is onlin",
            "content": "In message \n<350DC7048372D31197F200902773DF4C0494415E@exchange11.rl.ac.uk> on Fri, \n12 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>\n>I'm working on the guide to SKOS-Core 1.0, to go out with the schema next\n>thursday.  I've put a draft online, no examples or diagrams yet, only the\n>text.  All comments welcome.\n>\n><http://www.w3c.rl.ac.uk/SWAD/skos/1.0/guide/draft01.html>\n\nSome comments, with quotes from your draft:\n\n>To help other people unambiguously refer to your concepts without \n>having to use URIs, it is strongly recommended that no two concepts in \n>your scheme be given the same preferred label.\n\nI would say \"essential\" rather than \"strongly recommended\".\n\nThe only exception would be when a concept has been superseded but is \nretained in the scheme for historical or backwards compatibility \nreasons. It might then have the same label as a newly defined concept. \nThis takes us back to the question of how much a concept can be changed \n(by being relabelled and redefined) and still remain the same, so long \nas its URI or \"concept number\" is retained. How far can you modify a \nconcept, and when should you delete a concept and create a new one with \na new number?\n\n> It is perfectly reasonable, however, to assign a concept a preferred \n>label that is also an alternative label for some other concept.\n\nThis is contrary to thesaurus practice and standards, and would cause \nproblems. Labels should be unique, and are made so by the addition of a \nqualifier in parentheses if necessary.\n\n>A concept may have one preferred label for each language, and any \n>number of alternative labels\n\nPerhaps better rephrased as:\n\n\"A concept may have one preferred label and any number of alternative \nlabels for each language\"\n\n>prodive\n\nMinor typo in 3.i.v ; should be \"provide\"\n\n>3.i.iv. RelatedSymmetric\n>Use this property where all 'related' relationships between concepts \n>may be treated as being symmetric.\n\nShould the word \"all\" be dropped from this? I.e. use RelatedSymmetric \nfor only those relationships which are in fact symmetric?\n\nIn most conventional thesauri, \"related\" relationships are treated as \nsymmetric, even though more precise specification would recognise that \nmany of them are directional, e.g. activity/agent, process/product, \ncause/effect and so on.\n\nIf such a conventional thesaurus is encoded in SKOS format, should such \nrelationships be shown as \"skos:relatedSymmetric\", that being the way \nthey are treated, or should they be given the more general coding \n\"skos:related\", leaving the way open to refine the nature of the \nrelationship in future?\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Related and RelatedSymmetri",
            "content": "Doug wrote me a while ago to say that 'related' should not always be\nsymmetric.  So I made <skos:related> not symmetric, and created an extension\n<skos:relatedSymmetric> to account for the situations where 'related' can be\ntaken as symmetric.\n\nBut Leonard's last mail suggests that 'related' is most often symmetric.  In\nthis case would it be better to have <skos:related> as a symmetric property,\nand have an extension <skos:relatedAsymmetric> for those situations where\n'related' is directional?\n\n[N.B. need to resolve this by wednesday!]\n\nAl.\n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "skos:relate",
            "content": "Just reread this more carefully from Leonard:\n\n---\nIn most conventional thesauri, \"related\" relationships are treated as \nsymmetric, even though more precise specification would recognise that \nmany of them are directional, e.g. activity/agent, process/product, \ncause/effect and so on.\n\nIf such a conventional thesaurus is encoded in SKOS format, should such \nrelationships be shown as \"skos:relatedSymmetric\", that being the way \nthey are treated, or should they be given the more general coding \n\"skos:related\", leaving the way open to refine the nature of the \nrelationship in future?\n---\n\nDoes anyone have any thoughts on this?\n\nAl.   \n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "unique prefLabels",
            "content": "Leonard wrote:\n[Quote from SKOS-Core guide]\n\"To help other people unambiguously refer to your concepts without having to\nuse URIs, it is strongly recommended that no two concepts in your scheme be\ngiven the same preferred label.\"\n\n>I would say \"essential\" rather than \"strongly recommended\".\n\nI know that traditional thesaurus practise demands that all preferred labels\nbe unique within a scheme.  But Chaals argued for relaxing this in SKOS\n(e.g. see [1]), and I think he has an interesting point.  Hence the phrase\n'strongly recommended' rather than 'essential'.  \n\nAnybody else have any ideas on this?  \n  \nAl.\n\n[1] <http://lists.w3.org/Archives/Public/public-esw-thes/2004Feb/0028.html>\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Jonathan Trostle wrote:\n> \n> Unless I misunderstand the proposal, the shared key proposal\n> does not allow Kerberos to be incorporated in the sense that\n> public key authentication is still required (Kerberos is not\n> allowed as an alternate authentication mechanism in place of\n> public key authentication).\n> \n> Jonathan\nunsubscribe\n\n\n\n"
        },
        {
            "subject": "Re: Related and RelatedSymmetri",
            "content": "In message \n<350DC7048372D31197F200902773DF4C04944162@exchange11.rl.ac.uk> on Mon, \n15 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>Leonard's last mail suggests that 'related' is most often symmetric. \n>In this case would it be better to have <skos:related> as a symmetric \n>property, and have an extension <skos:relatedAsymmetric> for those \n>situations where 'related' is directional?\n\nMost thesauri treat it as symmetric, although the actual underlying \nrelationships are often not symmetric.\n\nIt would seem most logical to me to have the general <skos:related> \napply to the case where symmetry is undefined.\n\n<skos:relatedSymmetric> and <skos:relatedAsymmetric> would then both be \nparallel more specific cases of this. Whether you need this level, or \nwhether you go straight to the more detailed specification of the \nrelationship such as \"cause/effect\", \"process/product\" (both asymmetric) \nor \"associated\", \"sibling\", \"neighbouring\" etc. (symmetric) depends \nwhether there is a difference in the way that symmetric and asymmetric \nrelationships will be handled.\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "unique altLabel",
            "content": "Leonard wrote:\n[Quote from SKOS-Core guide:]\n\"It is perfectly reasonable, however, to assign a concept a preferred label\nthat is also an alternative label for some other concept.\"\n> \n> This is contrary to thesaurus practice and standards, and would cause \n> problems. Labels should be unique, and are made so by the \n> addition of a \n> qualifier in parentheses if necessary.\n> \n\nLeonard could you outline exactly the problems this would cause?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Re: unique altLabel",
            "content": "This is quite true of single controlled vocabularies. Having one label\npossibly provide two different concepts means you need to be careful to\ndistinguish which one is being selected - generally implying an extra\nverification step in the interface.\n\nOn the other hannd, in merging vocabularies, this is going to happen. It also\nallows us to explore the case where people's actual usage means that one\nlabel is used for two different concepts. Since  people commnicate through\nlabels (e.g. words) rather than concepts (e.g. telepathically transferring\nmental models), I think this is important in our goal of being able to use\nthe thesaurus work for the real world.\n\nOne intersting application, then, is to look up any concepts that do share a\nlabel, and work out if there is an optimisation that can be done to work\naround it - is the most helpful thing to offer the preferredLabel? A\ndefinition? Is it feasible to remove the label altogether, and force people\nto search using a different term?\n\ncheers\n\nChaals\n\nOn Mon, 15 Mar 2004, Miles, AJ (Alistair)  wrote:\n\n>\n>Leonard wrote:\n>[Quote from SKOS-Core guide:]\n>\"It is perfectly reasonable, however, to assign a concept a preferred label\n>that is also an alternative label for some other concept.\"\n>>\n>> This is contrary to thesaurus practice and standards, and would cause\n>> problems. Labels should be unique, and are made so by the\n>> addition of a\n>> qualifier in parentheses if necessary.\n>>\n>\n>Leonard could you outline exactly the problems this would cause?\n>\n>Al.\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: unique altLabel",
            "content": "In message \n<350DC7048372D31197F200902773DF4C04944166@exchange11.rl.ac.uk> on Mon, \n15 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>Leonard wrote:\n>[Quote from SKOS-Core guide:]\n>\"It is perfectly reasonable, however, to assign a concept a preferred label\n>that is also an alternative label for some other concept.\"\n>>\n>> This is contrary to thesaurus practice and standards, and would cause \n>>problems. Labels should be unique, and are made so by the  addition of \n>>a qualifier in parentheses if necessary.\n>\n>Leonard could you outline exactly the problems this would cause?\n\nWhen you enter a vocabulary with a term, you don't know whether it is \npreferred or non-preferred. It should still lead you unambiguously to a \nsingle concept. This allows for automatic substitution of preferred \nterms for non-preferred terms when indexing or searching (or automatic \nlinkage of documents to the appropriate concepts, if the actual terms \nare not used).\n\nIf you use a term that is ambiguous, such as \"seals\", then there is \nnormally an initial process of \"disambiguation\", which presents options \nfrom which the user has to choose, e.g.\n\nseals (closures)\nseals (mammals) USE Pinnepedia\n\nIn this example the first of these is a preferred term and the second is \na non-preferred term (or \"alternative label\" if you wish).\n\nIf you look up \"seals\" in an alphabetical sequence the two entries above \nare immediately evident. If a machine is accessing the thesaurus, there \nmay need to be some provision for it to match the term without the \nparenthetical qualifiers and take steps to determine which of the \noptions is appropriate. This seems to be a separate step, though, and \ndoes not imply that the unqualified term is an alternative label for \neither of the concepts.\n\nChaals raises the issue of merging different vocabularies. I think that \nthat is a different issue and raises many other complications, but as he \nsays the extra verification or disambiguation step that I have described \nabove applies there too.  As the present SKOS draft doesn't cover \nquestions of mapping between vocabularies, I think we should keep it to \nwhat is necessary and desirable for a single vocabulary.\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: skos:relate",
            "content": "If we define skos:related as being symmetric, can we define subProperties as\nbeing inverse, or otherwise not entirely symetric?\n\nIf we can do this at the same level (I think these are both in OWL, but I am\nnot familiar enough with the specifications to know the answer to my question\nabove) then I think it is the best solution. Otherwise, in the interest of\nnot making the tricky (but often interesting) things impossible, I suggest we\ndefine relatedSymmetric as a subProperty of related, and make that a\nsymmetric relation.\n\n(Alternatively we could define related as being symmetric, and a subProperty\nof rdfs:seeAlso, and non-symmetric relations as subProperties of seeAlso or\nof some relatedAsymmmetric property. The two proposals are just alternate\nlabels for the same concepts, as far as I can tell).\n\ncheers\n\nChaals\n\nOn Mon, 15 Mar 2004, Miles, AJ (Alistair)  wrote:\n\n>\n>Just reread this more carefully from Leonard:\n>\n>---\n>In most conventional thesauri, \"related\" relationships are treated as\n>symmetric, even though more precise specification would recognise that\n>many of them are directional, e.g. activity/agent, process/product,\n>cause/effect and so on.\n>\n>If such a conventional thesaurus is encoded in SKOS format, should such\n>relationships be shown as \"skos:relatedSymmetric\", that being the way\n>they are treated, or should they be given the more general coding\n>\"skos:related\", leaving the way open to refine the nature of the\n>relationship in future?\n>---\n>\n>Does anyone have any thoughts on this?\n>\n>Al.\n>\n>\n>---\n>Alistair Miles\n>Research Associate\n>CCLRC - Rutherford Appleton Laboratory\n>Building R1 Room 1.60\n>Fermi Avenue\n>Chilton\n>Didcot\n>Oxfordshire OX11 0QX\n>United Kingdom\n>Email:        a.j.miles@rl.ac.uk\n>Tel: +44 (0)1235 445440\n>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: skos:relate",
            "content": "Chaals wrote:\n>The two proposals are \n> just alternate\n> labels for the same concepts, as far as I can tell.\n\nYeah, they are.  It's a question of convenience.\n\nAl.\n\n> \n> On Mon, 15 Mar 2004, Miles, AJ (Alistair)  wrote:\n> \n> >\n> >Just reread this more carefully from Leonard:\n> >\n> >---\n> >In most conventional thesauri, \"related\" relationships are treated as\n> >symmetric, even though more precise specification would \n> recognise that\n> >many of them are directional, e.g. activity/agent, process/product,\n> >cause/effect and so on.\n> >\n> >If such a conventional thesaurus is encoded in SKOS format, \n> should such\n> >relationships be shown as \"skos:relatedSymmetric\", that being the way\n> >they are treated, or should they be given the more general coding\n> >\"skos:related\", leaving the way open to refine the nature of the\n> >relationship in future?\n> >---\n> >\n> >Does anyone have any thoughts on this?\n> >\n> >Al.\n> >\n> >\n> >---\n> >Alistair Miles\n> >Research Associate\n> >CCLRC - Rutherford Appleton Laboratory\n> >Building R1 Room 1.60\n> >Fermi Avenue\n> >Chilton\n> >Didcot\n> >Oxfordshire OX11 0QX\n> >United Kingdom\n> >Email:        a.j.miles@rl.ac.uk\n> >Tel: +44 (0)1235 445440\n> >\n> >\n> \n> Charles McCathieNevile  http://www.w3.org/People/Charles  \n> tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): \n> +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n\n\n\n"
        },
        {
            "subject": "merging and mappin",
            "content": "Just a thought on this ...\n\n> Chaals raises the issue of merging different vocabularies. I \n> think that \n> that is a different issue and raises many other \n> complications, but as he \n> says the extra verification or disambiguation step that I \n> have described \n> above applies there too.  As the present SKOS draft doesn't cover \n> questions of mapping between vocabularies, I think we should \n> keep it to \n> what is necessary and desirable for a single vocabulary.\n> \n I think 'merging' and 'mapping' are completely different scenarios.  In\nmapping, the schemes are kept separate, and linked via mapping statements.\nIn merging, a new scheme is created by combining concepts from different\nsources.  \n\nIt's worth considering the situations where separate groups of people (part\nof a larger community) are responsible for contributing concepts as part of\na larger scheme.  In this scenario we may expect to find overlap of labels.\n\n\nAl.              \n\n\n\n\n> Leonard\n> -- \n> Willpower Information       (Partners: Dr Leonard D Will, \n> Sheena E Will)\n> Information Management Consultants              Tel: +44 \n> (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 \n> (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               \n> Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n> \n\n\n\n"
        },
        {
            "subject": "Re: merging and mappin",
            "content": "Clearly Leonard and I (and to some extent Alistair and I) are currently\nlooking from different perspectives. I don't see any point in a mapping\nunless it is to allow use of two vocabularies as if they are merged (an\nartifact of RDF is that as soon as we have a mapping we can treat these\nthings as merged).\n\nAs I understand it one of the important features of the work is the ability\nto do this mapping (although it isn't kept in the same namespace, it is a\nrequirement, and it is certainly the basis of my interest in this).\n\nI maintain that one of the use cases that makes the SKOS work interesting is\nthe parallel work on mapping, and that we should ensure that we don' break\nthis.\n\nI therefore think that we should separate what we consider Best Practice (for\nexample having the same label as possibly referring to two concepts is\ngenerally a bad idea) from making something absolutely incorrect when there\nis reason to believe that it will arise in practice due to sensible work. So\nI would continue to suppport the idea that things are \"strong usage\nrecommendations\" (but not encoded in the ontology definition frameworks),\nrather than seeking to outlaw them by specifying appropriate RDF/OWL\nconstraints.\n\nCheers\n\nChaals\n\nOn Mon, 15 Mar 2004, Miles, AJ (Alistair)  wrote:\n\n>> Chaals raises the issue of merging different vocabularies. I\n[snip]\n>> above applies there too.  As the present SKOS draft doesn't cover\n>> questions of mapping between vocabularies, I think we should\n>> keep it to\n>> what is necessary and desirable for a single vocabulary.\n>>\n> I think 'merging' and 'mapping' are completely different scenarios.  In\n>mapping, the schemes are kept separate, and linked via mapping statements.\n>In merging, a new scheme is created by combining concepts from different\n>sources.\n>\n>It's worth considering the situations where separate groups of people (part\n>of a larger community) are responsible for contributing concepts as part of\n>a larger scheme.  In this scenario we may expect to find overlap of labels.\n\n\n\n"
        },
        {
            "subject": "Re: Layering and Sharedkey authenticatio",
            "content": "Jeff Williams wrote:\n> \n> EKR,\n> \n>   Please read below your comments.\n> \n> At 11:30 AM 10/8/96 -0700, you wrote:\n> >A lot of the arguments against shared secret client authentication\n> >seem to be layering arguments. Specifically, the argument seems to\n> >be that shared secret style authentication properly belongs at the\n> >application layer. While I feel that this argument has some force\n> >in principle, it seems to me to be deeply problematic in this specific\n> >case, for a number of reasons:\n> >\n> >1. The security services that TLS provides to the application layer\n> >are inadequate for this purpose. The obvious approach to layering\n> >protocols which require shared secret authentication over TLS\n> >is simply to pass the shared secret directly over the TLS channel,\n> >using TLS as TCP has always been used. However, in the common case,\n> >TLS application layer data is encrypted with a 40 bit keyspace,\n> >which means that that's all the protection provided for the\n> >shared secret. Consequently, we either have to accept this limitation\n> >or the application needs to provide it's own protection for\n> >the shared secret.\n> \n>   I think that the latter is going to win out in the long haul.  The reason is\n> that 40 bit keyspace is really not adaquate for modern day buisnesses and\n> applications.  Another approach would be to modify that keyspace to\n> 128, which would quiet alot of commercial concerns.  Otherwise providing for\n> that level(128 bit) will be done in a non-standerd manner by those\n> commercial buisnesses for providing their customers better \"Adaquate\"\n> protection of their data.\n> >\n> >\n> >2. Forcing applications to provide their own security argues against\n> >the purpose of TLS. Much of the argument for TLS is that applications\n> >can then be largely security oblivious while still taking advantage\n> >of security services. While data confidentiality for the data on the\n> >channel is important, there is a lot of historical evidence that the\n> >primary security need for e.g. telnet is actually access control, not\n> >data confidentiality, and this is typically provided via a shared secret.\n> >If TLS can't serve this need in an adequate way, then securing them\n> >will require a lot more work than just layering them on top of\n> >TLS--at which point one might easily imagine providing an application\n> >specific protocol which would meet that application's precise security\n> >needs in a single package.\n> \n>   I would agree that forcing applications to provide their own security is\n> contrary to the TLS perposal, it may very well become a common practice\n> with respect to the weakness of 40 bit common keysize.  I don't agree that\n> TLS should only address access security per say.  Buisnesses need to feel\n> safe that they believe and can trust that their data is secure, which agrues in\n> favor of layering, IE application layer.  I think the idea of an application\n> spicific protocol, is a intresting thought, except I think I would carry it out\n> to a more generic or encompassing protocol, with a common interface.\n> >\n> >\n> >3. There are a large number of common internet protocols which require\n> >shared secret style authentication, including but not limited to telnet,\n> >the Berkeley r-protocols, NNTP under certain circumstances... So,\n> >we're going to be reinventing this wheel a lot of times. This still\n> >doesn't make it TLS's job, but it's hard to see who's job it is,\n> >then.\n> \n>   I agree that it is not TLS's job.  But I would look at at least providing\n> an exit for and interface for TLS, not to mention SSL, Berkeley r-protocols,\n> and any other shared secret protocols.\n> >\n> >\n> >4. We've already violated this layering boundary. Public key style\n> >client authentication isn't really a necessary part of TLS service\n> >provision and could be easily handled at the application layer. This\n> >layering argument would be a lot more convincing if we hadn't\n> >already gone against it.\n> \n>   Well that is history now.  The real question is how do we handlee it?\n> \n> Reguards,\n> \n> >\n> >-Ekr\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> Jeffrey A. Williams\n> SR.Internet Network Eng.\n> CEO., IEG., INC. Representing PDS .Ltd.\n> Web: http://www.pds-link.com\n> Phone: 214-793-7445 (Direct Line)\n> Fax: 214-447-1900\n> Director of Network Eng. and Development IEG. INC.\nunsubscribe\n\n\n\n"
        },
        {
            "subject": "Re: merging and mappin",
            "content": "In message \n<350DC7048372D31197F200902773DF4C04944169@exchange11.rl.ac.uk> on Mon, \n15 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>In merging, a new scheme is created by combining concepts from \n>different sources.\n>\n>It's worth considering the situations where separate groups of people \n>(part of a larger community) are responsible for contributing concepts \n>as part of a larger scheme.  In this scenario we may expect to find \n>overlap of labels.\n\nBefore you merge them, you may have to undertake a mapping operation in \norder to resolve conflicts and inconsistencies. A label may be \nassociated with different concepts in the part-thesauri being mapped \ntogether.\n\nOnce you have merged the contributions into a whole, each label in the \nsingle resulting thesaurus should be unique. This should therefore be a \nrequirement of a scheme of encoding any single thesaurus, it seems to \nme.\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "FW: unique altLabel",
            "content": "Leonard has addressed this question very thoroughly, pointing out the\nconfusion that can arise if any label (whether preflabel or altlabel) is\nnon-unique.  The argument is entirely contingent on the assumption that\nthe KOS we are dealing with is a thesaurus, that is to say a vocabulary\ncomplying with ISO 2788 or ANSI/NISO Z39.19 or BS 5723. If this is the\nmodel, then the convention must be followed that every term, whether a\npreferred term or a non-preferred term, must be unique.\n\nHowever, the preamble to the SKOS document says, \"SKOS-Core 1.0 is an\nRDF schema for representing thesauri and similar types of knowledge\norganisation system (KOS)\". What do we mean by \"similar types\"? If a\nclassification scheme is included, you move to a different model. For\nclassification schemes, every concept has a unique notation. The\nconcepts are generally known as 'classes'. Each class has a caption, and\nsometimes also a descriptive note. The captions do not have to be\nunique. For example, the meteorology schedule of the scheme could have a\nclass ABC56, with caption Depression; at the same time the mental health\nschedule could have a class XYZ13, with caption Depression. Obviously\nthese concepts are very different, but there is no confusion because the\ncaption is never used to represent the concept.\n\nAll this is leading up to a suggestion that it may be important to set\nout more background as to where and how the SKOS schema is intended to\nbe used. If it is intended to apply to situations other than that of an\nISO2788-compliant thesaurus, then these should be described, together\nwith advice on how to deal with the features that differ from the\nISO2788 model. \n\nIn the short term, I would urge limiting the applicability of the schema\nto situations where terms may be used to represent concepts, and in this\ncircumstance any term used to represent a concept should be unique.  I\nalso agree about the need to limit it to a single vocabulary.  Once this\nsimple basis is established, it may become possible in future to extend\nto more situations, but it is risky to try to move too fast to a very\nsophisticated model.\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Leonard Will\nSent: 15 March 2004 12:37\nTo: public-esw-thes@w3.org\nSubject: Re: unique altLabels\n\n\n\nIn message\n<350DC7048372D31197F200902773DF4C04944166@exchange11.rl.ac.uk> on Mon, \n15 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>Leonard wrote:\n>[Quote from SKOS-Core guide:]\n>\"It is perfectly reasonable, however, to assign a concept a preferred \n>label that is also an alternative label for some other concept.\"\n>>\n>> This is contrary to thesaurus practice and standards, and would cause\n>>problems. Labels should be unique, and are made so by the  addition of\n\n>>a qualifier in parentheses if necessary.\n>\n>Leonard could you outline exactly the problems this would cause?\n\nWhen you enter a vocabulary with a term, you don't know whether it is \npreferred or non-preferred. It should still lead you unambiguously to a \nsingle concept. This allows for automatic substitution of preferred \nterms for non-preferred terms when indexing or searching (or automatic \nlinkage of documents to the appropriate concepts, if the actual terms \nare not used).\n\nIf you use a term that is ambiguous, such as \"seals\", then there is \nnormally an initial process of \"disambiguation\", which presents options \nfrom which the user has to choose, e.g.\n\nseals (closures)\nseals (mammals) USE Pinnepedia\n\nIn this example the first of these is a preferred term and the second is\n\na non-preferred term (or \"alternative label\" if you wish).\n\nIf you look up \"seals\" in an alphabetical sequence the two entries above\n\nare immediately evident. If a machine is accessing the thesaurus, there \nmay need to be some provision for it to match the term without the \nparenthetical qualifiers and take steps to determine which of the \noptions is appropriate. This seems to be a separate step, though, and \ndoes not imply that the unqualified term is an alternative label for \neither of the concepts.\n\nChaals raises the issue of merging different vocabularies. I think that \nthat is a different issue and raises many other complications, but as he\n\nsays the extra verification or disambiguation step that I have described\n\nabove applies there too.  As the present SKOS draft doesn't cover \nquestions of mapping between vocabularies, I think we should keep it to \nwhat is necessary and desirable for a single vocabulary.\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: merging and mappin",
            "content": "This conversation is making me nervous about the misunderstandings that\narise when we use our own terminology imprecisely.\n\nBy \"mapping\" I mean setting up a relationship between terms or codes\nthat represent concepts in different vocabularies. \nBy \"merging\" I mean taking two or more vocabularies and making them into\none vocabulary. (For this purpose I would make use of any mappings that\nwere available).\n\nBut the most obvious applications of mappings do not involve merging.\nFor example, you can use mappings to translate metadata descriptions\nfrom one vocabulary to another. Or you can use them to translate Search\nstatements from one vocabulary to another. You can do either of these\nwithout building a merged vocabulary. \n\nAny of the applications will work much better if the people who built\nthe vocabularies and the mappings followed the guidelines (e.g. ISO\n2788) rigorously while doing it. \n\nBetween 2 different vocabularies, you can and should expect to find one\nlabel applying to 2 different concepts. But within one thesaurus, it is\nstraightforward to require each term to be unique, and not an\nunreasonable requirement.\n\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Charles\nMcCathieNevile\nSent: 15 March 2004 14:17\nTo: Miles, AJ (Alistair) \nCc: public-esw-thes@w3.org\nSubject: Re: merging and mapping\n\n\n\nClearly Leonard and I (and to some extent Alistair and I) are currently\nlooking from different perspectives. I don't see any point in a mapping\nunless it is to allow use of two vocabularies as if they are merged (an\nartifact of RDF is that as soon as we have a mapping we can treat these\nthings as merged).\n\nAs I understand it one of the important features of the work is the\nability to do this mapping (although it isn't kept in the same\nnamespace, it is a requirement, and it is certainly the basis of my\ninterest in this).\n\nI maintain that one of the use cases that makes the SKOS work\ninteresting is the parallel work on mapping, and that we should ensure\nthat we don' break this.\n\nI therefore think that we should separate what we consider Best Practice\n(for example having the same label as possibly referring to two concepts\nis generally a bad idea) from making something absolutely incorrect when\nthere is reason to believe that it will arise in practice due to\nsensible work. So I would continue to suppport the idea that things are\n\"strong usage recommendations\" (but not encoded in the ontology\ndefinition frameworks), rather than seeking to outlaw them by specifying\nappropriate RDF/OWL constraints.\n\nCheers\n\nChaals\n\nOn Mon, 15 Mar 2004, Miles, AJ (Alistair)  wrote:\n\n>> Chaals raises the issue of merging different vocabularies. I\n[snip]\n>> above applies there too.  As the present SKOS draft doesn't cover \n>> questions of mapping between vocabularies, I think we should keep it \n>> to what is necessary and desirable for a single vocabulary.\n>>\n> I think 'merging' and 'mapping' are completely different scenarios.  \n>In mapping, the schemes are kept separate, and linked via mapping \n>statements. In merging, a new scheme is created by combining concepts \n>from different sources.\n>\n>It's worth considering the situations where separate groups of people \n>(part of a larger community) are responsible for contributing concepts \n>as part of a larger scheme.  In this scenario we may expect to find \n>overlap of labels.\n\n\n\n"
        },
        {
            "subject": "Re: Definition of &quot;facet&quot",
            "content": "> Yes, I am becoming more and more convinced that thesauri and\n> classification schemes are just alternative ways or arranging and\n> presenting lists and groups of concepts. I therefore am very keen to\n> help arrive at a single set of unambiguous terms which we can use to\n> discuss these things, rather than having to qualify statements by saying\n> that we are talking \"in a thesaurus context\" or \"in a classification\n> context\".\nYes - it would be nice to move to a situation where we just defined a \nparticular kind of KOS and its properties according to a standard KOS scheme\nand set of terms.\n \n> This is an interesting discussion - I wonder whether other people have\n> views on whether what we are saying makes sense.  Are we making any\n> progress towards a consensus of opinion?\nJust picking up this thread having returned from a trip - \nI do think we are fairly close to a broad consensus on the basic notion of a\n(simple) facet, \nwithout getting into any particular set of top level categories or\ncombination rules.\nEg as per Leonard's previous definitions of a homogeneous class of concepts\nor the similar definitions in the BSI standards, Aitchison & Gilchrist, etc.\n \nSome of the other issues, such as roles, synthesis rules for strings, and\nfundamental categories belong I think to the (next) stage of higher level\nschemes or OWL definitions for different kinds of KOS. \n \nHowever as regards the SKOS RDF scheme, I thought the original SKOS\ndefinition of facet was fairly close* to this and I was sorry to see it\ndropped it from the latest version. Did I miss some discussion on this or is\nit considered something best left for the next version? \n \n* (My original question boiled down to a couple implementation details:\nIs a 'facet' best modelled as a type of concept or as a separate entity,\nwhen considering future OWL developments?\nIs the Broader relationship best suited for concept-facet relationships, or\nshould it be a basic subclass/superclass relationship?)\n \nDoug\n\n\n\n"
        },
        {
            "subject": "Re: Difference between dc:subject and foaf:topi",
            "content": "Looking at the original question from Alistair:\n\n[[[\nWhich of the following two options should we recommend using (?) :\n\n<rdf:Description rdf:about=\"http://foo.com/aWebPage.html\">\n        <dc:subject rdf:resource=\"urn:swad-e:example/concept/FastFood\"/>\n</rdf:Description>\n\nor\n\n<rdf:Description rdf:about=\"http://foo.com/aWebPage.html\">\n        <foaf:topic rdf:resource=\"urn:swad-e:example/concept/FastFood\"/>\n</rdf:Description>\n]]]\n\nand thinking about this, I get to the following:\n\nFOAF defines topic in a smarter way that Dublin Core, because it insists that\nthe object is a resource. (It also insists that the range be a Web page,\nwhich on further reflection isn't so cool because I have a lot of use cases\nfor noting the topic of some part of a page and as far as I can tell I can't\ndo that nicely in FOAF unless I am prepared to lump all the topics together).\n\nAs I understand Dan's argument, it is that Dublin Core has a particular use\npattern which does things like confusing things and their names, and FOAF is\nmeant to avoid this.\n\nIt seems to me that there is a lot of mileage to be made by easy mappings\nfrom existing data, and there is a lot of value in having well-specified\nvocabularies.\n\nIf we were to suggest Dublin Core, I would be concerned that we are\nsupporting something very underspecified, in a way that might prove to be a\npain in the medium term. If we exclude it, we are cutting off one of the very\nwidely-used vocabularies.\n\nSo it seems to me a good idea to try and find something that is better\nconstrained than dc:subject, but which has essentially similar semantics for\nits core meaning.\n\nI had thought that foaf:topic would fit that bill, subject to the proviso\nthat some dc:subject information can't be shoe-horned into working as\nfoaf:topic information. But I can't envisage an instance of foaf:topic which\nis not legal value for dc:subject - since it will accept anything. Nor can I\nthink of an instance where the meaning of a foaf:topic would be different if\nit were interpreted as a dc:subject. That makes it a good target in my\nunderstanding for declaring something as a subProperty.\n\nWhich would allow us to recommend the better-constrained foaf:topic wherever\nthe initial data could be made to meet its constraints (perhaps by clarifying\nteh inital modelling, which is probably in itself beneficial), and showing\nsome examples of how to use the very widely used (there is perhaps more\ndc:title and dc:creator information available, and possibly even the\nofficially meaningless but widely claimed dc:author) dc:subject to get a head\nstart on bringing your data with you instead of rebuilding it.\n\nA few comments inserted below, because I am not sure that I have understood\neverything, nor that I have managed to explain myself well yet.\n\ncheers\n\nChaals\n\nOn Fri, 12 Mar 2004, Dan Brickley wrote:\n\n>* Charles McCathieNevile <charles@w3.org> [2004-03-12 11:34-0500]\n>>\n>> It isn't clear from that explanation what the difference is, since unless you\n>> talk about the domain and range of foaf:topic it's hard to understand how\n>> there is any.\n>\n>dc:subject relates a document to a code that stands for some thing the\n>doc is about.\n>\n>foaf:topic relates a document to some thing that the doc is about.\n>\n>...the difference is w.r.t. layers of indirection: where dc:subject uses\n>an external taxonomy, set out in advance, foaf:topic relies on any chunk\n>of RDF that is handy for describing the thing. It's an interesting\n>stylistic and representational difference that seems really quite\n>unfortunately hard to explain clearly...\n\ndc:subject best practice uses some code, but doesn't say anything about how\nto set it out. foaf:topic uses some code, and requires it to be of type\nrdf:Resource. I don't see any formal refinement to that, although the\npractical result is that foaf:topic tends to be easier to deal with in some\nuseful way.\n\n>>\n>> The fact that foaf:topic has a defined domain of foaf:Document and a range of\n>> rdf:Resource means that it's a bit more restricted than dc:subject which can\n>> happily live with a literal value, but there doesn't seem to be much else\n>> that can be used to pick between them (on my reading of the two sets of\n>> specifications).\n>\n>They differ importantly, just as you differ from your homepage, and XML\n>differs from library subject codes for XML. With dc:subject there is a\n>whole other world squeezed into the representation: the world of\n>subject/topic codes. With foaf:topic, the RDF itself does that work,\n>removing subject/topic codes from the list of things the RDF needs to\n>describe. See above re this being hard to describe :(\n\nI don't think this is hard to describe, and I think you have made a pretty\ngood description. (Although it makes me wonder why foaf: doesn't finish in #\n:-)\n\n>>\n>> If I was trying to define the way I see the web I would write somewhere that\n>> foaf:topic seems to me like a subProperty of dc:subject.\n>\n>that would imply that any pair of things related by foaf:topic are also\n>related by dc:subject. This isn't so, since the values taken by\n>dc:subject are various forms of subject code, whereas the values taken\n>by foaf:topic are the things that those subject codes denote. So\n>declaring a subPropertyOf relation would confuse those two levels.\n\nI don't think this is true. dc:subject says the best practice is to use\nsubject codes defined somehow. it doesn't ever say \"except those which are\ndefined with something useful like RDF\" (because it is syntax-neutral). The\nfact that people don't often do that today in a meaningful way isn't such a\nbig deal is it?\n\n>>Being a believer in\n>> living language, and in language as an attempt to provide identifiers for\n>> concepts in such a way thhat we are convinced we mean the same thing, this\n>> doesn't strike me as a bad thing to do. But since we are inventing RDF\n>> vocabulary creation, it is something I would treat with care - especially\n>> while we don't yet have good methods for dealing with conflicting statements,\n>> including conflicting statements about how vocaublaries are defined.\n>\n>We defintely need to to allow for vocabulary evolution, it might be\n>interesting to compare the two approaches...\n\nI think vocabulary evolution is one issue, but usage evolution is perhaps\ndifferent - tricker and more important at the same time :-\\\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Facets in SKOSCore 1.",
            "content": "Hi Doug, all,\n \nShould have mentioned, I tentatively decided to drop the skos:Facet class\nand the skos:inFacet and skos:facetMember properties in SKOS-Core 1.0 after\nthere was some contention as to whether this had been modelled in the right\nway.  \n \nBut Doug if you think the way it was done was OK for now, then I'm happy to\nre-include it.\n \n[So the proposed statements to re-add to SKOS-Core 1.0, in N3:\n \nskos:Facet\n        a    rdfs:Class;\n        rdfs:subClassOf    skos:Concept;\n        rdfs:subClassOf    rdfs:Class;\n        rdfs:label    'Facet'.\n \nskos:inFacet\n        a    rdf:Property;\n        rdfs:domain    skos:Concept;\n        rdfs:range        skos:Facet;\n        rdfs:subPropertyOf    skos:broaderInstantive;\n        rdfs:label    'in-facet'.\n \nskos:facetMember\n        a    rdf:Property;\n        rdfs:domain    skos:Facet;\n        rdfs:range        skos:Concept;\n        rdfs:subPropertyOf    skos:narrowerInstantive;\n        owl:inverseOf    skos:inFacet;\n        rdfs:label    'facet-has-member'.\n        \n]   \n \nThe statements above are based on the principal that facets are disjoint\nclasses (although the disjoint condition is sometimes broken and therefore\nis not expressed as a formal constraint), and facet members are class\ninstances. \n \nAl.\n \n--- \nAlistair Miles \nResearch Associate \nCCLRC - Rutherford Appleton Laboratory \nBuilding R1 Room 1.60 \nFermi Avenue \nChilton \nDidcot \nOxfordshire OX11 0QX \nUnited Kingdom \nEmail:        a.j.miles@rl.ac.uk \nTel: +44 (0)1235 445440 \n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org]On Behalf Of Tudhope D S (Comp)\nSent: 15 March 2004 15:55\nTo: 'public-esw-thes@w3.org'\nSubject: Re: Definition of \"facet\"\n\n\n> Yes, I am becoming more and more convinced that thesauri and\n> classification schemes are just alternative ways or arranging and\n> presenting lists and groups of concepts. I therefore am very keen to\n> help arrive at a single set of unambiguous terms which we can use to\n> discuss these things, rather than having to qualify statements by saying\n> that we are talking \"in a thesaurus context\" or \"in a classification\n> context\".\nYes - it would be nice to move to a situation where we just defined a \nparticular kind of KOS and its properties according to a standard KOS scheme\nand set of terms.\n \n> This is an interesting discussion - I wonder whether other people have\n> views on whether what we are saying makes sense.  Are we making any\n> progress towards a consensus of opinion?\nJust picking up this thread having returned from a trip - \nI do think we are fairly close to a broad consensus on the basic notion of a\n(simple) facet, \nwithout getting into any particular set of top level categories or\ncombination rules.\nEg as per Leonard's previous definitions of a homogeneous class of concepts\nor the similar definitions in the BSI standards, Aitchison & Gilchrist, etc.\n \nSome of the other issues, such as roles, synthesis rules for strings, and\nfundamental categories belong I think to the (next) stage of higher level\nschemes or OWL definitions for different kinds of KOS. \n \nHowever as regards the SKOS RDF scheme, I thought the original SKOS\ndefinition of facet was fairly close* to this and I was sorry to see it\ndropped it from the latest version. Did I miss some discussion on this or is\nit considered something best left for the next version? \n \n* (My original question boiled down to a couple implementation details:\nIs a 'facet' best modelled as a type of concept or as a separate entity,\nwhen considering future OWL developments?\nIs the Broader relationship best suited for concept-facet relationships, or\nshould it be a basic subclass/superclass relationship?)\n \nDoug\n\n\n\n"
        },
        {
            "subject": "Re: Facets in SKOSCore 1.",
            "content": "Hi Alistair,\n\na minor comment and a question.\n\nComment - since rdfs:label is a human readable label rather than for\nmachines, it seems better to me if you just put spaces between words. If you\nwant to auto-generate property names from labels you can do so by globbing\nthem together (or camel-casing them, or whatever) but as far as the machine\nis concerned you could also do so by selecting random combinations of arabic\nand chinese characters that don't already appear in your schema. This would\nprobably encourage people to build interfaces that look for human-readable\ntext to present things, so may be beneficial (although I suspect there are\nstill enough hand-coders out there that there is some value in legible tag\nnames).\n\nThe question (because I don't know the answer) is \"how would you express the\ndisjoint condition in RDF?\"\n\ncheers\n\nChaals\n\nOn Tue, 16 Mar 2004, Miles, AJ (Alistair)  wrote:\n\n>Hi Doug, all,\n>\n>Should have mentioned, I tentatively decided to drop the skos:Facet class\n>and the skos:inFacet and skos:facetMember properties in SKOS-Core 1.0 after\n>there was some contention as to whether this had been modelled in the right\n>way.\n>\n>But Doug if you think the way it was done was OK for now, then I'm happy to\n>re-include it.\n>\n[snip]\n>\n>The statements above are based on the principal that facets are disjoint\n>classes (although the disjoint condition is sometimes broken and therefore\n>is not expressed as a formal constraint), and facet members are class\n>instances.\n>\n>Al.\n>\n\n\n\n"
        },
        {
            "subject": "Labelling styl",
            "content": "Sorry Chaals, are you saying the rdfs:labels should be like 'in facet'\nrather than 'in-facet'?  \n\nI think this is a good suggestion.\n\nWhat does everyone else reckon?  \n\nAl.\n\nP.s. I'm totally open to comments about what the labels for the elements of\nthe SKOS-Core schema should be.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Charles\n> McCathieNevile\n> Sent: 16 March 2004 12:36\n> To: Miles, AJ (Alistair) \n> Cc: 'Tudhope D S (Comp)'; 'public-esw-thes@w3.org'\n> Subject: Re: Facets in SKOS-Core 1.0\n> \n> \n> \n> Hi Alistair,\n> \n> a minor comment and a question.\n> \n> Comment - since rdfs:label is a human readable label rather than for\n> machines, it seems better to me if you just put spaces \n> between words. If you\n> want to auto-generate property names from labels you can do \n> so by globbing\n> them together (or camel-casing them, or whatever) but as far \n> as the machine\n> is concerned you could also do so by selecting random \n> combinations of arabic\n> and chinese characters that don't already appear in your \n> schema. This would\n> probably encourage people to build interfaces that look for \n> human-readable\n> text to present things, so may be beneficial (although I \n> suspect there are\n> still enough hand-coders out there that there is some value \n> in legible tag\n> names).\n> \n> The question (because I don't know the answer) is \"how would \n> you express the\n> disjoint condition in RDF?\"\n> \n> cheers\n> \n> Chaals\n> \n> On Tue, 16 Mar 2004, Miles, AJ (Alistair)  wrote:\n> \n> >Hi Doug, all,\n> >\n> >Should have mentioned, I tentatively decided to drop the \n> skos:Facet class\n> >and the skos:inFacet and skos:facetMember properties in \n> SKOS-Core 1.0 after\n> >there was some contention as to whether this had been \n> modelled in the right\n> >way.\n> >\n> >But Doug if you think the way it was done was OK for now, \n> then I'm happy to\n> >re-include it.\n> >\n> [snip]\n> >\n> >The statements above are based on the principal that facets \n> are disjoint\n> >classes (although the disjoint condition is sometimes broken \n> and therefore\n> >is not expressed as a formal constraint), and facet members are class\n> >instances.\n> >\n> >Al.\n> >\n> \n\n\n\n"
        },
        {
            "subject": "Coverage of SKOSCore 1.",
            "content": "I believe SKOS-Core is suitable for encoding any type of KOS whose\nfundamental unit may be modelled as a concept.\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Labelling styl",
            "content": "On Tue, 16 Mar 2004, Miles, AJ (Alistair)  wrote:\n\n>Sorry Chaals, are you saying the rdfs:labels should be like 'in facet'\n>rather than 'in-facet'?\n\nYep.\n\n>I think this is a good suggestion.\n>\n>What does everyone else reckon?\n>\n>Al.\n>\n>P.s. I'm totally open to comments about what the labels for the elements of\n>the SKOS-Core schema should be.\n\nuncryptic enough so they are easy to translate. I am looking to get Sidar's\nglossary of terms for translation to use them, and it will help a lot of we\ncan provide the schema with labelling in spanish...\n\nCheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Re: Labelling styl",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-16 12:40-0000]\n> \n> Sorry Chaals, are you saying the rdfs:labels should be like 'in facet'\n> rather than 'in-facet'?  \n> \n> I think this is a good suggestion.\n> \n> What does everyone else reckon?  \n\nWorks for me. I always wanted rdfs:label and rdfs:comment to allow \nhypertext, some xhtml subset, but  they don't.\n\ndan\n\n\n\n"
        },
        {
            "subject": "Re: Coverage of SKOSCore 1.",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-16 12:41-0000]\n> \n> I believe SKOS-Core is suitable for encoding any type of KOS whose\n> fundamental unit may be modelled as a concept.\n\nWhat is a concept?\n\nSorry, had to ask...\n\n(might also ask what a fundamental unit is... what's the fundamental\nunit of RDF? terms? URIs? resources? classes? hard to tell...)\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Jonathan Trostle wrote:\n> \n> Unless I misunderstand the proposal, the shared key proposal\n> does not allow Kerberos to be incorporated in the sense that\n> public key authentication is still required (Kerberos is not\n> allowed as an alternate authentication mechanism in place of\n> public key authentication).\n> \n> Jonathan\nunsubscribe\n\n\n\n"
        },
        {
            "subject": "What is a concept",
            "content": ":)\n\nDefined in SKOS-Core 1.0 Guide as 'any unit of thought that may be defined\nor described.'  Might better be described as a 'unit of meaning' or\nsomething like that.  \n\nIn contrast to e.g. traditional thesauri, where the fundamental unit is\nusually a 'term', and hence where the intended meaning of the unit and the\nlabels used to refer to it are confounded.\n\nNB. I never use the word 'term' any more, because when somebody in this line\nof work refers to a 'term' I've realised they usually have some idea of\nmeaning attached to it (which may be a specially redefined meaning known\nonly within a limited scope).  I.e. the meaning and the label have not been\nseparated.  Hence I deliberately avoid using the word 'term' anywhere in the\nSKOS-Core 1.0 guide, but always use 'label' as a name for the character\nstrings or symbols that are used by people to refer to concepts.  \n\nIn my mind, 'term' = 'concept' + 'label'.\n\nAl. \n\nP.s. if you think about this too much, you end up spiralling into\nnon-existence.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: Dan Brickley [mailto:danbri@w3.org]\n> Sent: 16 March 2004 12:57\n> To: Miles, AJ (Alistair) \n> Cc: 'public-esw-thes@w3.org'\n> Subject: Re: Coverage of SKOS-Core 1.0\n> \n> \n> \n> * Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-16 12:41-0000]\n> > \n> > I believe SKOS-Core is suitable for encoding any type of KOS whose\n> > fundamental unit may be modelled as a concept.\n> \n> What is a concept?\n> \n> Sorry, had to ask...\n> \n> (might also ask what a fundamental unit is... what's the fundamental\n> unit of RDF? terms? URIs? resources? classes? hard to tell...)\n> \n> Dan\n> \n\n\n\n"
        },
        {
            "subject": "Re: Facets in SKOSCore 1.",
            "content": ">>\n>>Should have mentioned, I tentatively decided to drop the skos:Facet class\n>>and the skos:inFacet and skos:facetMember properties in SKOS-Core 1.0 after\n>>there was some contention as to whether this had been modelled in the right\n>>way.\n>>\n>>But Doug if you think the way it was done was OK for now, then I'm happy to\n>>re-include it.\n>>\n>>    \n>>\nAll else being equal, I suspect it might make life easier to use a class \nFacet, so owl:disjointWith can be used directly rather than having to \nconstruct intermediate constraint sets 'on the fly'.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "Re: Coverage of SKOSCore 1.",
            "content": "Dan Brickley wrote:\n\n>* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-16 12:41-0000]\n>  \n>\n>>I believe SKOS-Core is suitable for encoding any type of KOS whose\n>>fundamental unit may be modelled as a concept.\n>>    \n>>\n>\n>What is a concept?\n>\n>Sorry, had to ask...\n>\n>(might also ask what a fundamental unit is... what's the fundamental\n>unit of RDF? terms? URIs? resources? classes? hard to tell...)\n>\n>\n>  \n>\nIt might be an idea to have a nosey around the SUO [1] and Conceptual \nGraph [2] material for wording of parts like this - they've spent a lot \nof time counting these angels.\n\nFundamental unit of the  =>Resource<= [hint hint] Description Framework? \n(Mind you, that would probably lead to \"Thing Ontology Language\")\n\nCheers,\nDanny.\n\n[1] http://suo.ieee.org/\n[2] http://www.jfsowa.com/cg/index.htm\n\n>\n>  \n>\n\n\n\n"
        },
        {
            "subject": "Re: Facets in SKOSCore 1.",
            "content": "> But Doug if you think the way it was done was OK for now, then I'm happy\nto\n> re-include it.\n \nYes I think it does capture the key points and it would be good to include\nit - the implementation could always be fine tuned later if other ideas\nsurfaced.\n \nDoug\n \n\n\n\n"
        },
        {
            "subject": "RE: What is a concept",
            "content": "Re 'traditional thesauri', one of the most widely misunderstood things\nis the nature of the fundamental unit. One has to study ISO 2788 (=BS\n5723) carefully to realise that the fundamental unit is in fact the\nconcept. For practical reasons, concepts are represented by terms, but\nthese are really only labels for the underlying concepts. We are hoping\nthat this will be much more obvious in the revised British Standard,\nwhich is just about to be issued as a Draft for Public Comment. We then\nhope that people building schemas and software to handle thesauri will\nuse models closer to what you are developing for SKOS, in which concept\nis king.\n\nBy the way, I wouldn't say 'term = concept + label'. In the thesaurus\ncontext the equation is a bit more complicated, like\n\"concept = preferred term + any non-preferred terms + any scope note +\nany clues given by relationships to broader terms and others\"\nThis 'equation' does not conform to conventional mathematics - the '='\nmeans 'is defined by' and the '+' is fuzzy.  It all seems to rely on\nhuman interpretation - the weakness and the strength of the thesaurus\nmodel.\n\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Miles, AJ\n(Alistair) \nSent: 16 March 2004 13:26\nTo: Dan Brickley (E-mail)\nCc: 'public-esw-thes@w3.org'\nSubject: What is a concept?\n\n\n\n:)\n\nDefined in SKOS-Core 1.0 Guide as 'any unit of thought that may be\ndefined or described.'  Might better be described as a 'unit of meaning'\nor something like that.  \n\nIn contrast to e.g. traditional thesauri, where the fundamental unit is\nusually a 'term', and hence where the intended meaning of the unit and\nthe labels used to refer to it are confounded.\n\nNB. I never use the word 'term' any more, because when somebody in this\nline of work refers to a 'term' I've realised they usually have some\nidea of meaning attached to it (which may be a specially redefined\nmeaning known only within a limited scope).  I.e. the meaning and the\nlabel have not been separated.  Hence I deliberately avoid using the\nword 'term' anywhere in the SKOS-Core 1.0 guide, but always use 'label'\nas a name for the character strings or symbols that are used by people\nto refer to concepts.  \n\nIn my mind, 'term' = 'concept' + 'label'.\n\nAl. \n\nP.s. if you think about this too much, you end up spiralling into\nnon-existence.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: Dan Brickley [mailto:danbri@w3.org]\n> Sent: 16 March 2004 12:57\n> To: Miles, AJ (Alistair)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: Re: Coverage of SKOS-Core 1.0\n> \n> \n> \n> * Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-16 12:41-0000]\n> > \n> > I believe SKOS-Core is suitable for encoding any type of KOS whose \n> > fundamental unit may be modelled as a concept.\n> \n> What is a concept?\n> \n> Sorry, had to ask...\n> \n> (might also ask what a fundamental unit is... what's the fundamental \n> unit of RDF? terms? URIs? resources? classes? hard to tell...)\n> \n> Dan\n> \n\n\n\n"
        },
        {
            "subject": "subject and topic RE: What is a concept",
            "content": "I've been lurking in this debate for a while and missed several occasions to jump in, but\nI could not resist that one :))\n\nWondering if some insights from the topic map land (hereafter TM) could help. We have\nworked a lot in TM on those difficult issues. Two basic definitions from TM before\nanswering Alistair's remarks.\n\nA *subject* is \"anything whatsoever that can be spoken about\" (be it abstract or concrete,\nuniversal or individual, real or imaginary, existing or non-existing, big or small,\nconsistent or inconsistent ...). Although it is not excplicitly in the standard, it is\ngenerally accepted that TM subject means \"subject of conversation\". The TM approach is\nagnostic about the ontological status of a subject. Something exists (as a subject) as\nsoon as someone has started representing it or speaking about it by any mean whatsoever.\nNote that there is no requirement on any specific way a subject should be represented or\nspoken about to come to existence, but it has to be represented somehow.\n\nA *topic* is the formal representation, in an information system, of a unique, hopefully\nnon-ambiguous, subject. The representation is generally in a language suitable for\nelectronic use in our context, but could be as well a pictogram painted on an old chinese\nbamboo slip, a carved egyptian hieroglyph, a subject heading in a classification scheme, a\ndescriptor in a Thesaurus ... all are 'kind of topics' is different technological\nenvironments (different data models, say).\n\nChinese has a very interesting vocabulary for this distinction (not that I have any deep\nknowledge of Chinese, but that was explained to me by a chinese TM community friend. The\nequivalent for subject is *lord of this page*, and for topic is *eye of this page*. The\neye is the visible (addressable) proxy for an invisible (non-addressable) lord. Remember\nin ancient China, the Emperor was actually visible by almost nobody, but his symbolic\npresence and rule was asserted everywhere by many signs.\n\nThe topic map standard data model provides a framework for dealing with topics in the\nelectronic world, and specify what are the 'kind of topics' to use to be conformant with\nthe standard, but I would stick here to the simple paradigm of subject vs topic, whatever\nthe kind of topic (data model) used. This important distinction is somehow blurred in RDF.\nIt's difficult to know if the resource is the eye or the lord of the URI.\n\nNow, let's look at the issue.\n\n*Alistair (about concept)\n> Defined in SKOS-Core 1.0 Guide as 'any unit of thought that may be defined\n> or described.'  Might better be described as a 'unit of meaning' or\n> something like that.\n\nThis looks to me quite equivalent to TM subject. It is independent of any 'topic'\nrepresenting it.\n\n> In contrast to e.g. traditional thesauri, where the fundamental unit is\n> usually a 'term', and hence where the intended meaning of the unit and the\n> labels used to refer to it are confounded.\n\nYes, like in RDF. In a TM view of thesaurus, a term is represented by a topic, the eye\nrepresenting its invisible lord, the subject/concept. Now a topic have names, and TM\nprovides mechanism to make distinct the names used to identify the topic in a given\nnamespace (namespace#prefLabel) and the 'other names'.\n\n> NB. I never use the word 'term' any more, because when somebody in this line\n> of work refers to a 'term' I've realised they usually have some idea of\n> meaning attached to it (which may be a specially redefined meaning known\n> only within a limited scope).\n> I.e. the meaning and the label have not been\n> separated.\n\nThis is a common confusion when people get too much involved in using one kind of specific\nrepresentation tools, IOW using specific kinds of topics to represent subjects. Suppose\nthat for an ancient Egypt scholar, it was as difficult to make  a concept distinct from\nits hieroglyphic representation, as for a modern quantum mechanics expert to think about a\nparticle otherwise as some weird algebric object, field tensor or whatever.\n\n> Hence I deliberately avoid using the word 'term' anywhere in the\n> SKOS-Core 1.0 guide, but always use 'label' as a name for the character\n> strings or symbols that are used by people to refer to concepts.\n>\n> In my mind, 'term' = 'concept' + 'label'.\n\nTo sum it up, using TM distinction, I would try the following equivalences\n\n'concept' = 'subject'\n'term' = 'topic'\n'label' = 'topic name'\n\nMaybe it could also help in the foaf:topic vs dc:subject debate. A temptative short answer\nwould be that dc:subject has no requirement of the kind of topic (data model) used to\nrepresent the subject (could as well be an hieroglyph), whereas foaf:topic has some. I\ndon't know, actually, if the choice of FOAF to use 'topic' in that sense was made by folks\nbeing aware of the semantics of 'topic' in TM land. And not sure how those two uses are\nconsistent.\n\nGee ... heady stuff.\n\nBernard\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n\n"
        },
        {
            "subject": "RE: What is a concept",
            "content": "... following up somehow my previous message\n\n*Stella\n\n> Re 'traditional thesauri', one of the most widely misunderstood things\n> is the nature of the fundamental unit. One has to study ISO 2788 (=BS\n> 5723) carefully to realise that the fundamental unit is in fact the\n> concept.\n\nThat's good news. But it figures ... you have to \"read carefully\" to understand it.\n\n> For practical reasons, concepts are represented by terms, but\n> these are really only labels for the underlying concepts.\n\nDoes that fit in the topic vs subject distinction?\n\n> We are hoping\n> that this will be much more obvious in the revised British Standard,\n> which is just about to be issued as a Draft for Public Comment. We then\n> hope that people building schemas and software to handle thesauri will\n> use models closer to what you are developing for SKOS, in which concept\n> is king.\n\nThe 'lord of the page' strikes again :))\n\n> By the way, I wouldn't say 'term = concept + label'. In the thesaurus\n> context the equation is a bit more complicated, like\n> \"concept = preferred term + any non-preferred terms + any scope note +\n> any clues given by relationships to broader terms and others\"\n> This 'equation' does not conform to conventional mathematics - the '='\n> means 'is defined by' and the '+' is fuzzy.  It all seems to rely on\n> human interpretation - the weakness and the strength of the thesaurus\n> model.\n\nAll that goes in the right member of the 'equation' I would call 'topic and its\ncharacteristics'\nand the left member is the 'subject'. Now, how well the subject is represented is indeed\nall in human interpretation.\n\nSee definitions of 'subject' at\nhttp://www.topicmaps.org/xtm/1.0/#def-subject\n\nI'm happy to see a convergence here.\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n\n"
        },
        {
            "subject": "RE: What is a concept",
            "content": "The following statement (basically a re-iteration of what you said Stella)\nis how I see things, and my starting point for design in SKOS:\n\n'The complete intension of a concept should be inferred from the preferred\nlabel, the non-preferred labels, any scope notes or definitions, and\nrelationships to neighbouring concepts.'\n\n[which is essentially the same as ... (from Stella)]\n> \"concept = preferred term + any non-preferred terms + any scope note +\n> any clues given by relationships to broader terms and others\"\n\nThe reason I replace 'term' with 'label' is because of the way I have heard\n'term' used in the thesaurus world.  In my experience, when someone refers\nto a 'term' sometimes they are  pointing to a concept, and sometimes they\nare point to a string of characters.\n\nActually if you look at Stella's equation, it illustrates my point.  In the\nfirst part 'term' is used to refer to the character strings (concept =\npreferred term + any non-preferred terms ...) but in the second part it is\nused as a proxy for concepts (concept = ... relationships to broader terms\n...).  I would argue that 'broader' is a relationship of meaning, and\ntherefore a relationship between concepts, never between strings of\ncharacters.       \n\nWhen I use the word 'label' I am pointing to a string of characters or a\nsymbol.  When I use the word 'concept' I am point to some idea in my head.\nI find that not using the word 'term' helps to keep this distinction clear.\n\nAl.\n\n      \n\n> \n> Stella\n> \n> *****************************************************\n> Stella Dextre Clarke\n> Information Consultant\n> Luke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\n> Tel: 01235-833-298\n> Fax: 01235-863-298\n> SDClarke@LukeHouse.demon.co.uk\n> *****************************************************\n> \n> \n> \n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org] On Behalf Of Miles, AJ\n> (Alistair) \n> Sent: 16 March 2004 13:26\n> To: Dan Brickley (E-mail)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: What is a concept?\n> \n> \n> \n> :)\n> \n> Defined in SKOS-Core 1.0 Guide as 'any unit of thought that may be\n> defined or described.'  Might better be described as a 'unit \n> of meaning'\n> or something like that.  \n> \n> In contrast to e.g. traditional thesauri, where the \n> fundamental unit is\n> usually a 'term', and hence where the intended meaning of the unit and\n> the labels used to refer to it are confounded.\n> \n> NB. I never use the word 'term' any more, because when \n> somebody in this\n> line of work refers to a 'term' I've realised they usually have some\n> idea of meaning attached to it (which may be a specially redefined\n> meaning known only within a limited scope).  I.e. the meaning and the\n> label have not been separated.  Hence I deliberately avoid using the\n> word 'term' anywhere in the SKOS-Core 1.0 guide, but always \n> use 'label'\n> as a name for the character strings or symbols that are used by people\n> to refer to concepts.  \n> \n> In my mind, 'term' = 'concept' + 'label'.\n> \n> Al. \n> \n> P.s. if you think about this too much, you end up spiralling into\n> non-existence.\n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n> \n> > -----Original Message-----\n> > From: Dan Brickley [mailto:danbri@w3.org]\n> > Sent: 16 March 2004 12:57\n> > To: Miles, AJ (Alistair)\n> > Cc: 'public-esw-thes@w3.org'\n> > Subject: Re: Coverage of SKOS-Core 1.0\n> > \n> > \n> > \n> > * Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-16 12:41-0000]\n> > > \n> > > I believe SKOS-Core is suitable for encoding any type of \n> KOS whose \n> > > fundamental unit may be modelled as a concept.\n> > \n> > What is a concept?\n> > \n> > Sorry, had to ask...\n> > \n> > (might also ask what a fundamental unit is... what's the \n> fundamental \n> > unit of RDF? terms? URIs? resources? classes? hard to tell...)\n> > \n> > Dan\n> > \n> \n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": ">From: david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n>\n>I'll have to go back and look at the comments from last\n>week's proposal (ssl-talk is where I saw most of it),\n>but this proposal really doesn't seem \"cooked\" to me.\n>\n>   - Internationalization issues arise.  In what character\n>     set do \"display_string\" and \"challenge\" appear?  How\n>     is the language which the end user knows specified?\n>     \n>     I don't like seeing application layer issues intrude\n>     on transport layer protocols.\n\nThe \"display_string\" field is opaque; that is, TLS simply transports it\nwithout examining its content.  It is entirely the next level's\nresponsibility to figure out what to do with it (or even if it should be\nsent in the first place).  Why is this an \"intrusion\" into the transport\nlayer, any more than, say, the presence of the opaque application data\nwhich is passed through TLS as part of its basic function?\n>   \n>   - Neither \"rough consensus\" nor (multiple instances of)\n>     \"working code\" exists, as has been pointed out.\n>     \n>     Many of us don't see a technical benefit to making TLS\n>     be incompatible with SSLv3 in this respect, so I doubt\n>     that a realistic \"consensus\" on this point can exist.\n\nWell, the real problem is that virtually *any* difference between TLS\nand SSL 3.0 would make TLS incompatible with SSL 3.0, because SSL 3.0\nsimply lacks a mechanism for forward compatibility.  If we do nothing\nelse, we absolutely *must* prevent this problem from grandfathering its\nway into TLS.  (The fix that's been suggested as least painful to SSL\n3.0 implementers is to specify that unrecognized handshake message types\nbe ignored--hence our use of new handshake message types to implement\nshared-key authentication.  If someone has a better way to permit\nextensibility, then I'd be happy to hear about it.)\n>   \n>   - It's unclear just where in the handshake these new\n>     messages would go.  Or are they even part of the\n>     regular handshake protocol?  Do they go after the\n>     \"Finished\" messages are exchanged, are they an\n>     independent handshake, or what?\n\nThe posted document specifies where the extra messages should go.\n>   \n>   - Given that the amount of keying material to be built\n>     is derived from the negotiated cipher spec, what's\n>     the change needed in the definition of a cipher spec?\n>     It needs to know it must generate CipherSpec.hash_size\n>     (times two?) bytes of keying data.\n\nIn SSL 3.0 (and presumably TLS), the actual keying material is not\nincluded in the cipher_spec, but rather as part of the general\nconnection state.  Implementations that don't support shared-key\nauthentication can, of course, ignore the extra keying material\naltogether.\n>   \n>   - There's a new requirement, to ignore unrecognized\n>     handshake messages rather than treat them as errors.\n>     I prefer protocols to be fully specfied.\n\nIf it's preferable, the specification can certainly require that\nimplementations recognize the extra handshake messages.  Of course, the\nreal problem here is SSL 3.0's lack of an extensibility mechanism; see\nmy comments above.\n>\n>I could raise more questions, but the fact that there are\n>this many (after this much discussion!) says to me that the\n>proposal should not be deemed \"cooked\" enough to incorporate\n>into an IETF standard.\n\nTo my mind, the problems with the proposal, as enumerated by David, cast\na worse light on SSL 3.0 than on the proposal itself.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: What is a concept",
            "content": "Al,\nYes, I am generally encouraged that we are making progress towards\nconvergence. ( And all sorts of people who should know better use\nthesaurus-speak badly, so you are right to be cautious.) Was my earlier\npoint also clear, that it works slightly differently in classification\nschemes? In the latter form of KOS, the only thing you can use reliably\nas a label is the notation. The captions (or class names, or subject\nheadings as somebody called them) do not have exactly the same function\nas the terms in a thesaurus, because they are not necessarily unique. If\nyou move on to those KOS called taxonomies, it is even more confusing\nbecause people use this word for all sorts of things, and there is no\nstandard to define best practice.\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Miles, AJ\n(Alistair) \nSent: 17 March 2004 16:15\nTo: 'Stella Dextre Clarke'\nCc: 'public-esw-thes@w3.org'\nSubject: RE: What is a concept?\n\n\n\nThe following statement (basically a re-iteration of what you said\nStella) is how I see things, and my starting point for design in SKOS:\n\n'The complete intension of a concept should be inferred from the\npreferred label, the non-preferred labels, any scope notes or\ndefinitions, and relationships to neighbouring concepts.'\n\n[which is essentially the same as ... (from Stella)]\n> \"concept = preferred term + any non-preferred terms + any scope note +\n\n> any clues given by relationships to broader terms and others\"\n\nThe reason I replace 'term' with 'label' is because of the way I have\nheard 'term' used in the thesaurus world.  In my experience, when\nsomeone refers to a 'term' sometimes they are  pointing to a concept,\nand sometimes they are point to a string of characters.\n\nActually if you look at Stella's equation, it illustrates my point.  In\nthe first part 'term' is used to refer to the character strings (concept\n= preferred term + any non-preferred terms ...) but in the second part\nit is used as a proxy for concepts (concept = ... relationships to\nbroader terms ...).  I would argue that 'broader' is a relationship of\nmeaning, and therefore a relationship between concepts, never between\nstrings of\ncharacters.       \n\nWhen I use the word 'label' I am pointing to a string of characters or a\nsymbol.  When I use the word 'concept' I am point to some idea in my\nhead. I find that not using the word 'term' helps to keep this\ndistinction clear.\n\nAl.\n\n      \n\n> \n> Stella\n> \n> *****************************************************\n> Stella Dextre Clarke\n> Information Consultant\n> Luke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\n> Tel: 01235-833-298\n> Fax: 01235-863-298\n> SDClarke@LukeHouse.demon.co.uk\n> *****************************************************\n> \n> \n> \n> -----Original Message-----\n> From: public-esw-thes-request@w3.org \n> [mailto:public-esw-thes-request@w3.org] On Behalf Of Miles, AJ\n> (Alistair)\n> Sent: 16 March 2004 13:26\n> To: Dan Brickley (E-mail)\n> Cc: 'public-esw-thes@w3.org'\n> Subject: What is a concept?\n> \n> \n> \n> :)\n> \n> Defined in SKOS-Core 1.0 Guide as 'any unit of thought that may be \n> defined or described.'  Might better be described as a 'unit of \n> meaning' or something like that.\n> \n> In contrast to e.g. traditional thesauri, where the\n> fundamental unit is\n> usually a 'term', and hence where the intended meaning of the unit and\n> the labels used to refer to it are confounded.\n> \n> NB. I never use the word 'term' any more, because when\n> somebody in this\n> line of work refers to a 'term' I've realised they usually have some\n> idea of meaning attached to it (which may be a specially redefined\n> meaning known only within a limited scope).  I.e. the meaning and the\n> label have not been separated.  Hence I deliberately avoid using the\n> word 'term' anywhere in the SKOS-Core 1.0 guide, but always \n> use 'label'\n> as a name for the character strings or symbols that are used by people\n> to refer to concepts.  \n> \n> In my mind, 'term' = 'concept' + 'label'.\n> \n> Al.\n> \n> P.s. if you think about this too much, you end up spiralling into \n> non-existence.\n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n> \n> > -----Original Message-----\n> > From: Dan Brickley [mailto:danbri@w3.org]\n> > Sent: 16 March 2004 12:57\n> > To: Miles, AJ (Alistair)\n> > Cc: 'public-esw-thes@w3.org'\n> > Subject: Re: Coverage of SKOS-Core 1.0\n> > \n> > \n> > \n> > * Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-03-16 12:41-0000]\n> > > \n> > > I believe SKOS-Core is suitable for encoding any type of\n> KOS whose\n> > > fundamental unit may be modelled as a concept.\n> > \n> > What is a concept?\n> > \n> > Sorry, had to ask...\n> > \n> > (might also ask what a fundamental unit is... what's the\n> fundamental\n> > unit of RDF? terms? URIs? resources? classes? hard to tell...)\n> > \n> > Dan\n> > \n> \n\n\n\n"
        },
        {
            "subject": "new W3C Semantic Web Best Practices + Deployment WG: rdf+thesaurus task forc",
            "content": "Hi. Just a brief note to let you know that there is a new Working Group at W3C,\nthe \"Semantic Web Best Practices\" group.\n\nHomepage: http://www.w3.org/2001/sw/BestPractices/\ncharter: http://www.w3.org/2003/12/swa/swbpd-charter\nmailing list: http://lists.w3.org/Archives/Public/public-swbp-wg/\n\nIt looks like we will be starting a task force of the group in the \narea of thesauri and RDF, and I've offered to coordinate. More news as \nwe have it, this is just to let you know things are starting up...\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "First completed draft of SKOSCore 1.0 guide and schem",
            "content": "Hi guys,\n\nA first completed draft of the guide is up now:\n\nhttp://www.w3c.rl.ac.uk/SWAD/skos/1.0/guide/draft01.html\n\nAnd the schema:\n\nhttp://www.w3c.rl.ac.uk/SWAD/skos/1.0/schema/skos_core_1_0.rdf\n\nI made some decisions:\n\n1.  I put a section on 'faceted organisation' into the guide.  However, I\ndecided the word 'facet' meant too many different things to too many\ndifferent people to be useful as a name for the class in the schema.  So the\nclass in the schema is called 'PrimitiveClass' and the properties are called\n'primitiveType' and 'primitiveInstance'.  I thought these names reflected\nmuch better how we intend them to be used.\n\n2.  I dropped the 'skos:relatedSymmetric' property.  I realised that we'd\nbeen a bit at cross purposes over this.  In a nutshell: althought the actual\nunderlying nature of a relationship that has been captured as 'related' may\nnot be symmetric (e.g. cause/effect, process/product), we still always want\nto infer that [if (a related b) then (b related a)].  I.e. the\n'skos:related' property should be symmetric, but extensions (sub-properties)\nmay or may not be (e.g. the skos:relatedPartOf/skos:relatedHasPart property\npair is an extension of skos:related that captures an asymmetric underlying\nrelationship).\n\nThat's about it I think.\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "SKOSCore draft",
            "content": "re the last mail I wrote: I put the draft schema and guide up so they were\navailable for immediate comment - these won't be the final resting places\nfor them\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "2 recent references  NKOS JoDI issue and 'How to Make a Faceted Classification and Put It On the Web",
            "content": "The new NKOS JoDI issue, 'New Applications of KOS' is now published\nhttp://jodi.ecs.soton.ac.uk/?vol=4&iss=4\n\nI just came across this report by William Denton which may be of general\ninterest re the facet discussion if people have not already seen it - 'How\nto Make a Faceted Classification and Put It On the Web'\nhttp://www.miskatonic.org/library/facet-web-howto.html\n\nDoug\n\n\n\n"
        },
        {
            "subject": "faceted classificatio",
            "content": "Hi Doug, Leonard, Stella,\n\nI just read the article [1] that Doug forwarded.  I was wondering if you\ncould help to me to clear something up.\n\nI have so far come across two meanings for 'faceted classification':  \n\n(Sense 1) \n\nA set of things are 'classified' according to their properties.  For example\n(from [1]) a set of detergents are classified by 'brand name', 'form',\n'scent', 'agent', 'effect on agent' and 'special property'.  In this sense,\neach of these properties represents a 'facet' through which the set of\ninstances can be viewed. \n\n(Sense 2) \n\nA set of 'concepts' are grouped according to their most primitive type.  For\nexample, the concept 'marble' is placed in the 'materials' facet.  The\nconcept 'insects' is placed in the 'organisms' facet.  In this sense, a\n'facet' is essentially a primitive class, and every member of a facet group\nis either an instance or a sub-class of that class.    \n\nSo my first question is: have I described these two senses accurately (or am\nI missing something)?\n\nMy second question is: are there any other senses of 'faceted\nclassification' worth considering?\n\nFinally: if my analysis is correct, these two senses describe quite\ndifferent systems of organisation (*).  So would it be useful in the short\nterm to come up with unambiguous names for these two meanings?  For example,\nwe could refer to sense 1 as 'classification by description' and sense 2 as\n'primitive classification'.  \n\nPlease let me know what you think.  \n\nYours,\n\nAlistair.\n  \n\n(*) although sense 2 could be viewed as a special case of sense 1, in which\nconcepts are classified according to the value of a 'primitive type'\nproperty - i.e. 'primitive type' represents a 'facet' in sense 1! \n\n[1] <http://www.miskatonic.org/library/facet-web-howto.html>\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: faceted classificatio",
            "content": "Hi Alistair, folks,\n\nfyi, there's a 'vanilla' XML format for facetted classification with the \nobvious acronym XFML [1]. It's primarily aimed at web site data (such as \nblogs). The model/syntax is close to parts of Topic Maps/XTM, and \nconsiders facets to be mutually exclusive categories, which may form \npart of a hierarchical classification.\n\nI'm pointing to it now because there are some good refs on facets around \nthat area [2], and I've a feeling facetting may be a very powerful tool \nin the SKOS kit. Also I'm wondering whether some of the data that's been \nmarked up in XFML could be automatically translated into SKOS/RDF. That \nthe format yields well to XSLT is demonstrated at [3] - view source.\n\nbtw, XFML doesn't really have a mechanism for enforcing the mutual \nexclusion, it's assumes the cataloguer will look after that.\n\nNote too that Siderean Software have done a fair amount of work with \nfacetted classification and RDF [4].\n\nCheers,\nDanny.\n\n[1] http://xfml.org/\n[2] http://xfml.org/links.html\n[3] http://www.alter.most.org.pl/fa/xfml/altermap.xml\n[4] http://groups.yahoo.com/group/facetedclassification/message/199\n\n\n\n"
        },
        {
            "subject": "Re: faceted classificatio",
            "content": "In message\n<350DC7048372D31197F200902773DF4C04944189@exchange11.rl.ac.uk> on Mon,\n22 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>Hi Doug, Leonard, Stella,\n>\n>I just read the article [1] that Doug forwarded.  I was wondering if you\n>could help to me to clear something up.\n>\n>I have so far come across two meanings for 'faceted classification':\n>\n>(Sense 1)\n>\n>A set of things are 'classified' according to their properties.  For example\n>(from [1]) a set of detergents are classified by 'brand name', 'form',\n>'scent', 'agent', 'effect on agent' and 'special property'.  In this sense,\n>each of these properties represents a 'facet' through which the set of\n>instances can be viewed.\n>\n>(Sense 2)\n>\n>A set of 'concepts' are grouped according to their most primitive type.  For\n>example, the concept 'marble' is placed in the 'materials' facet.  The\n>concept 'insects' is placed in the 'organisms' facet.  In this sense, a\n>'facet' is essentially a primitive class, and every member of a facet group\n>is either an instance or a sub-class of that class.\n>\n>So my first question is: have I described these two senses accurately (or am\n>I missing something)?\n\nAlistair\n\nCongratulations on recognising at first reading an ambiguity that I've\nbeen banging on about for years!\n\nThe terminology of faceted classification is indeed not well controlled.\n:-(\n\nSome people use the expression \"subfacets\" for your sense 1 and\n\"fundamental facets\" for your sense 2, but I think that this is\nconfusing because they are indeed different, and not specific types of\nsome more general things called \"facets\".\n\nThe main need, as you point out, is to distinguish these two senses and\nto use different names for them. The choice as to which should be given\nthe word \"facets\" is difficult, as there is warrant for either, but the\ninterpretation I have advocated, and which is in the draft British\nStandard currently under preparation, is to use \"facets\" for your sense\n2, i.e. \"fundamental facets\", sometimes called \"fundamental categories\".\n\nFor sense 1, an accepted terminology is to say that concepts are grouped\ninto \"arrays\" according to specified \"characteristics of division\". The\n\"characteristic of division\" is shown in a node label, after the word\n\"by\". These node labels are not descriptors, but explain the grouping of\nconcepts in the array that they introduce. You then have a hierarchy\nsuch as the following which shows three arrays:\n\ndetergents\n     <detergents by form>\n     liquid detergents\n     gel detergents\n     powder detergents\n\n     <detergents by scent>\n     citrus scented detergents\n        lemon scented detergents\n        orange scented detergents\n     pine scented detergents\n\n     <detergents by brand name>\n     Persil detergents\n     Daz detergents\n     Surf detergents\n\nNote that in this case the arrays all list kinds of detergents. If you\nwanted to separate out the properties from the detergents, you would\nhave distinct hierarchies such as\n\nscents\n     citrus scents\n        lemon scents\n        orange scents\n\nphysical states\n     solids\n        powders\n     gels\n     liquids\n\nand these would belong to different [fundamental] facets.\n\nThe AAT puts \"scents\" (i.e. \"odors\") into an  \"environmental concepts\"\nfacet and \"powders\" into a \"materials\" facet under the node label\n<materials by physical form>.\n\nIn this case these terms would come together with detergents only when\nboth descriptors were assigned to an item when that item was being\nindexed.\n\nI hope other people agree with this description.\n\nLeonard\n\n\n\n\n\n\n\n\n\n>\n>My second question is: are there any other senses of 'faceted\n>classification' worth considering?\n>\n>Finally: if my analysis is correct, these two senses describe quite\n>different systems of organisation (*).  So would it be useful in the short\n>term to come up with unambiguous names for these two meanings?  For example,\n>we could refer to sense 1 as 'classification by description' and sense 2 as\n>'primitive classification'.\n>\n>Please let me know what you think.\n>\n>Yours,\n>\n>Alistair.\n>\n>\n>(*) although sense 2 could be viewed as a special case of sense 1, in which\n>concepts are classified according to the value of a 'primitive type'\n>property - i.e. 'primitive type' represents a 'facet' in sense 1!\n>\n>[1] <http://www.miskatonic.org/library/facet-web-howto.html>\n>\n>---\n>Alistair Miles\n>Research Associate\n>CCLRC - Rutherford Appleton Laboratory\n>Building R1 Room 1.60\n>Fermi Avenue\n>Chilton\n>Didcot\n>Oxfordshire OX11 0QX\n>United Kingdom\n>Email:        a.j.miles@rl.ac.uk\n>Tel: +44 (0)1235 445440\n>\n>\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: faceted classificatio",
            "content": "Alistair,\ncouple of things related to the article in question and XFML and\nSense1/Sense2\nin case this may be relevant for SKOS\n\n> I just read the article [1] that Doug forwarded.  I was wondering if you\n> could help to me to clear something up.\n\nThis is a library school essay and for me it was very useful as it\nclearly demonstrated how easy it is to ignore the difference between\nclassification of objects and classification of\nknowledge - which is a typical for American library schools.\nBut it is very important to pay attention to this as it represents\nhow the term 'faceted classification'\nis implemented in XFML and how it is understood by many people creating\nbusiness portals with excellent browsing facets functionality.\n\nIn this approach \"faceted classification\" is classification that is\nfits in your Sense 1 (division according to one principle at the time,\nhence \"faceted classification\" is ANY classification that operates\nwith sets of mutually exclusive categories of any kind). Here everything\nfits\nnicely as term 'facet' (fr. la facette - little face) is said to be borrowed\nfrom a 'diamond' - each facet represents one side or one face of the\ndiamond.\n(each property is a single face of a multifaced object). With this one gets\nall the advantages in managing vocabulary using an elegant relational model.\nIf one knows that most widely used American classifications such as Dewey or\nLibrary of Congress C. are enumerative classifications and\noccasionally/often? fail to\nconsistently apply a simpliest logic of division - then it is understandable\nwhy many feel necessary to make distinction between: a) messy enumerative\nstructure\nb)pure taxonomy and c) something called \"faceted classification\" simply to\nemphasise that the last one is a logical and consistent in nature and in the\nsame\ntime helps in managing different properties of objects simultaniously\n(and is likely to be ontologically clean in Guarino's sense and therefore\neasier to process by machines). Something like 'deux ex machina' on the KOS\nscene.\n\nUK Classification research group, however, reserves the expression\n'faceted classification' for knowledge classification only (knowledge about\nobjects\nand not objects themselves). Here one obviously has more problems to sort\nout\nwith facets than detergents, beer cans and bottles of wines. For CRG Sense1\nis\nunderstood to be there anyway and when they attach attribute 'faceted' to\nsome\nclassification they think that besides this basic logical property level\nthere\nmust be a set of fundamental categories (Sense 2) in place.\nWhen thesauri embraced 'facet analysis' they paid attention only to the\ntop organizational structure in a Sense2 and ignored Sense1. The reason\nbeing the very nature\nof thesaurus: alphabetical indexing languages do not need detailed\nclassificatory structure for\ntheir managment and can work with a rather rough organizational grouping as\nfar as\nthere is some logical principle behind it (mutual exclusiveness).\n\nThe discussion on what faceted classification is on the\nfacetedclassification\nmailing list last year agreed on the following (I think):\na)  if one is creating a classification\nfor objects/entities (bottles of wines, beer cans, detergents, cars etc.)\nthan it is sufficient to have Sense 1 organization structure applied.\n\nb) if one is producing classification to classify knowledge about objects\nboth: facets of properties and fundametnal facets above them in order to be\nable\nto organize facets themselves. This is because of the complexity that\nclassification of\nknowledge operates with, dealing with concepts as well as dynamic\nrelationships among them.\n\nThe conclusion was that XFML is not meant and can't serve for the purpose b)\nand suggestion was\nthat we should rather look into XTM in order to accommodate the kind of\nontology typical for\n \"faceted classifications of knowledge\" which operate with fundamental\ncategories (Sense 2: grouping of primitives)\nas well as with facets in a more technical sense (Sense1: things according\nto their properties).\n\nIf we would code Sense 2 only - does this mean that we would undermine the\nfollowing???\na) the need for knowledge classification to deal with Sense1 and Sense2\nb) the understanding and implementation of faceted principle in a Sense 1 in\nclassification of objects\n(as in XFML)\nc) the underlying classificatory nature of thesaurus that can be potentially\nfully coded\nand may provide better support in vocabulary control and use\n(thesaurofacet/classaurus)\nd)\n\nAida\n\n\n\n>\n> I have so far come across two meanings for 'faceted classification':\n>\n> (Sense 1)\n>\n> A set of things are 'classified' according to their properties.\n> For example\n> (from [1]) a set of detergents are classified by 'brand name', 'form',\n> 'scent', 'agent', 'effect on agent' and 'special property'.  In\n> this sense,\n> each of these properties represents a 'facet' through which the set of\n> instances can be viewed.\n>\n> (Sense 2)\n>\n> A set of 'concepts' are grouped according to their most primitive\n> type.  For\n> example, the concept 'marble' is placed in the 'materials' facet.  The\n> concept 'insects' is placed in the 'organisms' facet.  In this sense, a\n> 'facet' is essentially a primitive class, and every member of a\n> facet group\n> is either an instance or a sub-class of that class.\n>\n> So my first question is: have I described these two senses\n> accurately (or am\n> I missing something)?\n>\n> My second question is: are there any other senses of 'faceted\n> classification' worth considering?\n>\n> Finally: if my analysis is correct, these two senses describe quite\n> different systems of organisation (*).  So would it be useful in the short\n> term to come up with unambiguous names for these two meanings?\n> For example,\n> we could refer to sense 1 as 'classification by description' and\n> sense 2 as\n> 'primitive classification'.\n>\n> Please let me know what you think.\n>\n> Yours,\n>\n> Alistair.\n>\n>\n> (*) although sense 2 could be viewed as a special case of sense\n> 1, in which\n> concepts are classified according to the value of a 'primitive type'\n> property - i.e. 'primitive type' represents a 'facet' in sense 1!\n>\n> [1] <http://www.miskatonic.org/library/facet-web-howto.html>\n>\n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: faceted classificatio",
            "content": "Hi All\n\nI find Leonard's reply helpful here.\n\nLooking at\n\n>Detergents\n>      <detergents by form>\n>      liquid detergents\n>      gel detergents\n>      powder detergents\n>\n>      <detergents by scent>\n>      citrus scented detergents\n>         lemon scented detergents\n>         orange scented detergents\n>      pine scented detergents\n>\n>      <detergents by brand name>\n>      Persil detergents\n>      Daz detergents\n>      Surf detergents\n\nfrom an rdf-world point of view, I can imagine some rdf:resource, X, and I \nmight want to say:\n\n[X] type [detergent]\n[X] physical state [powder]\n[X] scent [citrus scents]\n....\n\nThis is not N3 or anything, but you can see what I'm saying,\n(X has an rdf:type of detergent, its physical state is powder etc). And \nhere 'detergent', 'powder' etc would be encoded as skos concepts for this \nparticular thesaurus.\n\nBut what to do about our 'facets': physical state, scent etc? We don't want \nthem to be treated like skos:concepts because basically they are \nrdf:properties.  Therefore they form an extensional part of skos:core, I'm \nthinking. i.e. to migrate a thesaurus that includes facets in the sense of \nfundemental categories, one should give these facets as properties:\n\nrdf:Property rdf:ID=\"physicalState\"\n<rdfs:label>Physical State<rdfs:label>\n<rdfs:subPropertyOf rdf:resource=\"skos#facet\"/>\n<rdfs:range rdf:resource=\"#Solids>\n<rdfs:range rdf:resource=\"#Gels>\n....\n<rdfs:comment>\n</rdfs:comment>\n</rdf:Property>\n\n\nwhere any facet is declared as a subproperty of skosfacet, say, & which is \nnot to be linked into OWL or rdfs.\n\nPutting in the range resources (which should all be skos:Concept's) would \nenable an application to switch views on instance data in the way Leonard \ndescribes below. And the hierarchy of skos concepts would enable an \napplication to determine that concepts under 'Solids' also are in the range \nof the physicalState property, and so on.\n\nAs for the 'backwards pointer' - the ability to express for any given skos \nConcept its facet - I haven't thought through whether or not that is \nnecessary.\n\nNikki\n\n\n\n\n\n\n\n--On Monday, March 22, 2004 14:59:17 +0000 Leonard Will \n<L.Will@willpowerinfo.co.uk> wrote:\n\n>\n> In message\n> <350DC7048372D31197F200902773DF4C04944189@exchange11.rl.ac.uk> on Mon,\n> 22 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>> Hi Doug, Leonard, Stella,\n>>\n>> I just read the article [1] that Doug forwarded.  I was wondering if you\n>> could help to me to clear something up.\n>>\n>> I have so far come across two meanings for 'faceted classification':\n>>\n>> (Sense 1)\n>>\n>> A set of things are 'classified' according to their properties.  For\n>> example (from [1]) a set of detergents are classified by 'brand name',\n>> 'form', 'scent', 'agent', 'effect on agent' and 'special property'.  In\n>> this sense, each of these properties represents a 'facet' through which\n>> the set of instances can be viewed.\n>>\n>> (Sense 2)\n>>\n>> A set of 'concepts' are grouped according to their most primitive type.\n>> For example, the concept 'marble' is placed in the 'materials' facet.\n>> The concept 'insects' is placed in the 'organisms' facet.  In this\n>> sense, a 'facet' is essentially a primitive class, and every member of a\n>> facet group is either an instance or a sub-class of that class.\n>>\n>> So my first question is: have I described these two senses accurately\n>> (or am I missing something)?\n>\n> Alistair\n>\n> Congratulations on recognising at first reading an ambiguity that I've\n> been banging on about for years!\n>\n> The terminology of faceted classification is indeed not well controlled.\n> :-(\n>\n> Some people use the expression \"subfacets\" for your sense 1 and\n> \"fundamental facets\" for your sense 2, but I think that this is\n> confusing because they are indeed different, and not specific types of\n> some more general things called \"facets\".\n>\n> The main need, as you point out, is to distinguish these two senses and\n> to use different names for them. The choice as to which should be given\n> the word \"facets\" is difficult, as there is warrant for either, but the\n> interpretation I have advocated, and which is in the draft British\n> Standard currently under preparation, is to use \"facets\" for your sense\n> 2, i.e. \"fundamental facets\", sometimes called \"fundamental categories\".\n>\n> For sense 1, an accepted terminology is to say that concepts are grouped\n> into \"arrays\" according to specified \"characteristics of division\". The\n> \"characteristic of division\" is shown in a node label, after the word\n> \"by\". These node labels are not descriptors, but explain the grouping of\n> concepts in the array that they introduce. You then have a hierarchy\n> such as the following which shows three arrays:\n>\n> detergents\n>      <detergents by form>\n>      liquid detergents\n>      gel detergents\n>      powder detergents\n>\n>      <detergents by scent>\n>      citrus scented detergents\n>         lemon scented detergents\n>         orange scented detergents\n>      pine scented detergents\n>\n>      <detergents by brand name>\n>      Persil detergents\n>      Daz detergents\n>      Surf detergents\n>\n> Note that in this case the arrays all list kinds of detergents. If you\n> wanted to separate out the properties from the detergents, you would\n> have distinct hierarchies such as\n>\n> scents\n>      citrus scents\n>         lemon scents\n>         orange scents\n>\n> physical states\n>      solids\n>         powders\n>      gels\n>      liquids\n>\n> and these would belong to different [fundamental] facets.\n>\n> The AAT puts \"scents\" (i.e. \"odors\") into an  \"environmental concepts\"\n> facet and \"powders\" into a \"materials\" facet under the node label\n> <materials by physical form>.\n>\n> In this case these terms would come together with detergents only when\n> both descriptors were assigned to an item when that item was being\n> indexed.\n>\n> I hope other people agree with this description.\n>\n> Leonard\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>>\n>> My second question is: are there any other senses of 'faceted\n>> classification' worth considering?\n>>\n>> Finally: if my analysis is correct, these two senses describe quite\n>> different systems of organisation (*).  So would it be useful in the\n>> short term to come up with unambiguous names for these two meanings?\n>> For example, we could refer to sense 1 as 'classification by\n>> description' and sense 2 as 'primitive classification'.\n>>\n>> Please let me know what you think.\n>>\n>> Yours,\n>>\n>> Alistair.\n>>\n>>\n>> (*) although sense 2 could be viewed as a special case of sense 1, in\n>> which concepts are classified according to the value of a 'primitive\n>> type' property - i.e. 'primitive type' represents a 'facet' in sense 1!\n>>\n>> [1] <http://www.miskatonic.org/library/facet-web-howto.html>\n>>\n>> ---\n>> Alistair Miles\n>> Research Associate\n>> CCLRC - Rutherford Appleton Laboratory\n>> Building R1 Room 1.60\n>> Fermi Avenue\n>> Chilton\n>> Didcot\n>> Oxfordshire OX11 0QX\n>> United Kingdom\n>> Email:        a.j.miles@rl.ac.uk\n>> Tel: +44 (0)1235 445440\n>>\n>>\n>\n> --\n> Willpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\n> Information Management Consultants              Tel: +44 (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: faceted classificatio",
            "content": "> Hi Alistair, folks,\n> \n> fyi, there's a 'vanilla' XML format for facetted \n> classification with the \n> obvious acronym XFML [1]. It's primarily aimed at web site \n> data (such as \n> blogs). The model/syntax is close to parts of Topic Maps/XTM, and \n> considers facets to be mutually exclusive categories, which may form \n> part of a hierarchical classification.\n> \n> I'm pointing to it now because there are some good refs on \n> facets around \n> that area [2], and I've a feeling facetting may be a very \n> powerful tool \n> in the SKOS kit. Also I'm wondering whether some of the data \n> that's been \n> marked up in XFML could be automatically translated into \n> SKOS/RDF. \n\nHi Danny, thanks for the refs on this.  \n\nIt seems to me that data in XFML can go straight into RDF, using the\nconstructs of RDFS (and a bit of OWL) only.  E.g. I modelled the detergents\nexample from [1] using RDFS - see:\n<http://www.w3c.rl.ac.uk/SWAD/rdf/facet_in_rdfs.txt>.  This approach is also\nwhat the Siderean folks do [2] and what Nikki was suggesting this morning\n[3].  I.e. a 'facet' in the XFML sense can be modelled as a rdf:Property\nwith a defined domain and range.\n\nAt the moment I'm trying to manage SKOS so it doesn't duplicate anything\nthat can already be modelled with RDFS or OWL - these three vocabularies\nought to be complementary.  Which is why I'm so keen to clear up the 'facet'\nissue.  \n\nMaybe someone should sit down and write a white paper on how to do 'faceted\nclassification' to support web catalogue browsing using RDF, RDFS and OWL\n(including some XSLT to generate RDF from XFML)???\n\nAl.\n\n[1] http://www.miskatonic.org/library/facet-web-howto.html\n[2] http://www.siderean.com/TechnologyWhitePaper.pdf\n[3] http://lists.w3.org/Archives/Public/public-esw-thes/2004Mar/0070.html\n\n\n\n\nThat \n> the format yields well to XSLT is demonstrated at [3] - view source.\n> \n> btw, XFML doesn't really have a mechanism for enforcing the mutual \n> exclusion, it's assumes the cataloguer will look after that.\n> \n> Note too that Siderean Software have done a fair amount of work with \n> facetted classification and RDF [4].\n> \n> Cheers,\n> Danny.\n> \n> [1] http://xfml.org/\n> [2] http://xfml.org/links.html\n> [3] http://www.alter.most.org.pl/fa/xfml/altermap.xml\n> [4] http://groups.yahoo.com/group/facetedclassification/message/199\n> \n\n\n\n"
        },
        {
            "subject": "Arrays of concept",
            "content": "Hi all,\n\nThe new british standard for thesauri is including a recommendation for\n'arrays' of concepts (see Leonard's mail [1]).  So I'm trying to work out if\nit would be useful for SKOS to have a construct for modelling this directly.\nFor example, see <http://www.w3c.rl.ac.uk/SWAD/rdf/concept_array.txt> which\nI just knocked up.\n\nWhat do you think?\n\nAl.  \n\n[1] http://lists.w3.org/Archives/Public/public-esw-thes/2004Mar/0068.html\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Dan,\n\nYou bring an interesting point. In the design of SSL3.0, we did not\nexpect that the protocol would have to support weaker authentication\ntechniques, actually going backwards if you think about it. The idea of\nSSL3.0 was not to support everything that may exist or everything anyone\ncan think of. So, you cannot really accuse SSL of not being forward\ncompatible because it assumes a good authentication method rather than\nduplicate old ones that everyone has already implemented in any\ninteresting application protocol. The only reason for me to entertain\nthis password thing is that a customer thinks it is useful, not really\nbecause it adds anything to the protocol, on the contrary, it makes it\nless attractive since the level of authentication is not defined. \n\nTaher\n\n\nDan Simon wrote:\n> \n> >From:  david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n> >\n> >I'll have to go back and look at the comments from last\n> >week's proposal (ssl-talk is where I saw most of it),\n> >but this proposal really doesn't seem \"cooked\" to me.\n> >\n> >   - Internationalization issues arise.  In what character\n> >     set do \"display_string\" and \"challenge\" appear?  How\n> >     is the language which the end user knows specified?\n> >\n> >     I don't like seeing application layer issues intrude\n> >     on transport layer protocols.\n> \n> The \"display_string\" field is opaque; that is, TLS simply transports it\n> without examining its content.  It is entirely the next level's\n> responsibility to figure out what to do with it (or even if it should be\n> sent in the first place).  Why is this an \"intrusion\" into the transport\n> layer, any more than, say, the presence of the opaque application data\n> which is passed through TLS as part of its basic function?\n> >\n> >   - Neither \"rough consensus\" nor (multiple instances of)\n> >     \"working code\" exists, as has been pointed out.\n> >\n> >     Many of us don't see a technical benefit to making TLS\n> >     be incompatible with SSLv3 in this respect, so I doubt\n> >     that a realistic \"consensus\" on this point can exist.\n> \n> Well, the real problem is that virtually *any* difference between TLS\n> and SSL 3.0 would make TLS incompatible with SSL 3.0, because SSL 3.0\n> simply lacks a mechanism for forward compatibility.  If we do nothing\n> else, we absolutely *must* prevent this problem from grandfathering its\n> way into TLS.  (The fix that's been suggested as least painful to SSL\n> 3.0 implementers is to specify that unrecognized handshake message types\n> be ignored--hence our use of new handshake message types to implement\n> shared-key authentication.  If someone has a better way to permit\n> extensibility, then I'd be happy to hear about it.)\n> >\n> >   - It's unclear just where in the handshake these new\n> >     messages would go.  Or are they even part of the\n> >     regular handshake protocol?  Do they go after the\n> >     \"Finished\" messages are exchanged, are they an\n> >     independent handshake, or what?\n> \n> The posted document specifies where the extra messages should go.\n> >\n> >   - Given that the amount of keying material to be built\n> >     is derived from the negotiated cipher spec, what's\n> >     the change needed in the definition of a cipher spec?\n> >     It needs to know it must generate CipherSpec.hash_size\n> >     (times two?) bytes of keying data.\n> \n> In SSL 3.0 (and presumably TLS), the actual keying material is not\n> included in the cipher_spec, but rather as part of the general\n> connection state.  Implementations that don't support shared-key\n> authentication can, of course, ignore the extra keying material\n> altogether.\n> >\n> >   - There's a new requirement, to ignore unrecognized\n> >     handshake messages rather than treat them as errors.\n> >     I prefer protocols to be fully specfied.\n> \n> If it's preferable, the specification can certainly require that\n> implementations recognize the extra handshake messages.  Of course, the\n> real problem here is SSL 3.0's lack of an extensibility mechanism; see\n> my comments above.\n> >\n> >I could raise more questions, but the fact that there are\n> >this many (after this much discussion!) says to me that the\n> >proposal should not be deemed \"cooked\" enough to incorporate\n> >into an IETF standard.\n> \n> To my mind, the problems with the proposal, as enumerated by David, cast\n> a worse light on SSL 3.0 than on the proposal itself.\n> \n>                                 Daniel Simon\n>                                 Cryptographer, Microsoft Corp.\n>                                 dansimon@microsoft.com\n> \n> >\n> >\n> >\n\n-- \nTaher Elgamal    elgamal@netscape.com\nChief Scientist, Netscape Communications\n(T) 415 937 2898, (F) 415 428 4054\n\n\n\n"
        },
        {
            "subject": "FW: faceted classificatio",
            "content": "This is a very interesting thread of conversation, but could I just\ncheck we are all on the same track? (Because, I confess, I am getting a\nbit lost.)\n\nWe started with Alistair pointing out people use the word 'facet' in\nlots of different ways, and drawing attention to 2 significant ones: as\nfundamental categories and as characteristics of division, respectively.\nThen Leonard expanded on the difference, giving some very helpful\nexamples. Aida then pointed out a very important thing: there is a\ndifference between the simple exercise of analysing objects according to\nfacets, and the more complex challenge of using facet analysis to\norganize knowledge. The concepts in a thesaurus vary from very simple\n(e.g. 'People', 'Disabilities' 'Education') to more complex (e.g. 'Cost\nbenefit analysis', 'Disabled children', 'Special needs education') and a\nsophisticated faceted classification will try to find a unique way of\ncoding combinations of complex concepts (e.g. Cost benefit analysis of\nproviding special needs education for disabled children). So far so\ngood.\n\nNow, where I have got lost is in how these successively more complex\nconcepts and combinations are to be represented in XML, XFML, RDF, SKOS\netc. If the SKOS schema is to be able to represent thesaurus data, it\nmust be able to treat both simple (Education) and complex (Special needs\neducation) concepts as single concepts. It should preferably also be\nable to show that each concept belongs to a particular (ideally just\none, but occasionally more than one) facet (e.g. 'People' and 'Disabled\nchildren' belong to the facet 'agents' or possibly the facet 'living\norganisms' or even 'patients', and 'Education' and 'Special needs\neducation' might belong to the facet 'processes'). If it was really\nclever, SKOS might also be able to show that within the hierarchy of\n'Education','Special needs education' belongs not in the array\n'Education, by age group', where 'Primary education', 'Secondary\neducation'  and 'Adult education' are to be found, but in an array named\n'Education, by needs'. A still further challenge for display purposes is\nto be able to present primary, secondary and adult in systematic order,\nnot alphabetical order. Let's stop short of representing the\ncombinations of complex concepts, since we've already got enough to\nconsider.\n\nOne thing that makes me  uncomfortable is designating Facet as a\nProperty. I think  of Facets as being themselves concepts or classes,\nvery simple and general, chosen so that so that a small number of them\nis enough to contain every other concept in the thesaurus. The terms\nthat name the facets are at the tops of just a few hierarchies which can\nbe used to organize the whole of the thesaurus.  It is possible to have\na hierarchical relationship between People and Agents, so how can we say\nAgents is a Property? Or is it true to say that all relationships are\nproperties, in which case the problem may just be in my imagination?\n\nAt present the SKOS schema says, \"Facets provide a means of organising\nconcepts along orthogonal dimensions. A facet is treated as a concept. A\nfacet may have member concepts. A concept may be a member of only one\nfacet\". That strikes me as fine, except that in practice it is hard to\nset up useful facets that are mutually exclusive. (This point is\nillustrated in the cases above. 'Patient' and 'agent' are very commonly\nselected as facets, but a disabled child can be a patient when receiving\ntreatment and an agent when his congenital clumsiness causes accidents.\nIt all depends on the context of a particular document or search query.)\n\nPerhaps we are really all on the same track, and where I have come\nunstuck is just in the formalism of how to represent things in the\nvarious mark-up languages and schemas. In which case I fully endorse\nAlistair's suggestion, \"Maybe someone should sit down and write a white\npaper on how to do 'faceted classification' to support web catalogue\nbrowsing using RDF, RDFS and OWL (including some XSLT to generate RDF\nfrom XFML)???\"\n\nAs to Alistair's' representation of an array, sorry, no comment yet. I\njust have not understood well enough how it is going to be used. But I\nlook forward to hearing from everyone else.\nThanks\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of NJ Rogers, Learning\nand Research Technology\nSent: 23 March 2004 12:26\nTo: Leonard Will; Miles, AJ (Alistair)\nCc: Douglas Tudhope (E-mail); Stella Dextre Clarke (E-mail);\n'public-esw-thes@w3.org'\nSubject: Re: faceted classification\n\n\n\nHi All\n\nI find Leonard's reply helpful here.\n\nLooking at\n\n>Detergents\n>      <detergents by form>\n>      liquid detergents\n>      gel detergents\n>      powder detergents\n>\n>      <detergents by scent>\n>      citrus scented detergents\n>         lemon scented detergents\n>         orange scented detergents\n>      pine scented detergents\n>\n>      <detergents by brand name>\n>      Persil detergents\n>      Daz detergents\n>      Surf detergents\n\nfrom an rdf-world point of view, I can imagine some rdf:resource, X, and\nI \nmight want to say:\n\n[X] type [detergent]\n[X] physical state [powder]\n[X] scent [citrus scents]\n....\n\nThis is not N3 or anything, but you can see what I'm saying,\n(X has an rdf:type of detergent, its physical state is powder etc). And \nhere 'detergent', 'powder' etc would be encoded as skos concepts for\nthis \nparticular thesaurus.\n\nBut what to do about our 'facets': physical state, scent etc? We don't\nwant \nthem to be treated like skos:concepts because basically they are \nrdf:properties.  Therefore they form an extensional part of skos:core,\nI'm \nthinking. i.e. to migrate a thesaurus that includes facets in the sense\nof \nfundemental categories, one should give these facets as properties:\n\nrdf:Property rdf:ID=\"physicalState\"\n<rdfs:label>Physical State<rdfs:label>\n<rdfs:subPropertyOf rdf:resource=\"skos#facet\"/>\n<rdfs:range rdf:resource=\"#Solids>\n<rdfs:range rdf:resource=\"#Gels>\n....\n<rdfs:comment>\n</rdfs:comment>\n</rdf:Property>\n\n\nwhere any facet is declared as a subproperty of skosfacet, say, & which\nis \nnot to be linked into OWL or rdfs.\n\nPutting in the range resources (which should all be skos:Concept's)\nwould \nenable an application to switch views on instance data in the way\nLeonard \ndescribes below. And the hierarchy of skos concepts would enable an \napplication to determine that concepts under 'Solids' also are in the\nrange \nof the physicalState property, and so on.\n\nAs for the 'backwards pointer' - the ability to express for any given\nskos \nConcept its facet - I haven't thought through whether or not that is \nnecessary.\n\nNikki\n\n\n\n\n\n\n\n--On Monday, March 22, 2004 14:59:17 +0000 Leonard Will \n<L.Will@willpowerinfo.co.uk> wrote:\n\n>\n> In message \n> <350DC7048372D31197F200902773DF4C04944189@exchange11.rl.ac.uk> on Mon,\n\n> 22 Mar 2004, \"Miles, AJ (Alistair)\" <A.J.Miles@rl.ac.uk> wrote\n>> Hi Doug, Leonard, Stella,\n>>\n>> I just read the article [1] that Doug forwarded.  I was wondering if \n>> you could help to me to clear something up.\n>>\n>> I have so far come across two meanings for 'faceted classification':\n>>\n>> (Sense 1)\n>>\n>> A set of things are 'classified' according to their properties.  For \n>> example (from [1]) a set of detergents are classified by 'brand \n>> name', 'form', 'scent', 'agent', 'effect on agent' and 'special \n>> property'.  In this sense, each of these properties represents a \n>> 'facet' through which the set of instances can be viewed.\n>>\n>> (Sense 2)\n>>\n>> A set of 'concepts' are grouped according to their most primitive \n>> type. For example, the concept 'marble' is placed in the 'materials' \n>> facet. The concept 'insects' is placed in the 'organisms' facet.  In \n>> this sense, a 'facet' is essentially a primitive class, and every \n>> member of a facet group is either an instance or a sub-class of that \n>> class.\n>>\n>> So my first question is: have I described these two senses accurately\n\n>> (or am I missing something)?\n>\n> Alistair\n>\n> Congratulations on recognising at first reading an ambiguity that I've\n\n> been banging on about for years!\n>\n> The terminology of faceted classification is indeed not well \n> controlled. :-(\n>\n> Some people use the expression \"subfacets\" for your sense 1 and \n> \"fundamental facets\" for your sense 2, but I think that this is \n> confusing because they are indeed different, and not specific types of\n\n> some more general things called \"facets\".\n>\n> The main need, as you point out, is to distinguish these two senses \n> and to use different names for them. The choice as to which should be \n> given the word \"facets\" is difficult, as there is warrant for either, \n> but the interpretation I have advocated, and which is in the draft \n> British Standard currently under preparation, is to use \"facets\" for \n> your sense 2, i.e. \"fundamental facets\", sometimes called \"fundamental\n\n> categories\".\n>\n> For sense 1, an accepted terminology is to say that concepts are \n> grouped into \"arrays\" according to specified \"characteristics of \n> division\". The \"characteristic of division\" is shown in a node label, \n> after the word \"by\". These node labels are not descriptors, but \n> explain the grouping of concepts in the array that they introduce. You\n\n> then have a hierarchy such as the following which shows three arrays:\n>\n> detergents\n>      <detergents by form>\n>      liquid detergents\n>      gel detergents\n>      powder detergents\n>\n>      <detergents by scent>\n>      citrus scented detergents\n>         lemon scented detergents\n>         orange scented detergents\n>      pine scented detergents\n>\n>      <detergents by brand name>\n>      Persil detergents\n>      Daz detergents\n>      Surf detergents\n>\n> Note that in this case the arrays all list kinds of detergents. If you\n\n> wanted to separate out the properties from the detergents, you would \n> have distinct hierarchies such as\n>\n> scents\n>      citrus scents\n>         lemon scents\n>         orange scents\n>\n> physical states\n>      solids\n>         powders\n>      gels\n>      liquids\n>\n> and these would belong to different [fundamental] facets.\n>\n> The AAT puts \"scents\" (i.e. \"odors\") into an  \"environmental concepts\"\n\n> facet and \"powders\" into a \"materials\" facet under the node label \n> <materials by physical form>.\n>\n> In this case these terms would come together with detergents only when\n\n> both descriptors were assigned to an item when that item was being \n> indexed.\n>\n> I hope other people agree with this description.\n>\n> Leonard\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>>\n>> My second question is: are there any other senses of 'faceted \n>> classification' worth considering?\n>>\n>> Finally: if my analysis is correct, these two senses describe quite \n>> different systems of organisation (*).  So would it be useful in the \n>> short term to come up with unambiguous names for these two meanings? \n>> For example, we could refer to sense 1 as 'classification by \n>> description' and sense 2 as 'primitive classification'.\n>>\n>> Please let me know what you think.\n>>\n>> Yours,\n>>\n>> Alistair.\n>>\n>>\n>> (*) although sense 2 could be viewed as a special case of sense 1, in\n\n>> which concepts are classified according to the value of a 'primitive \n>> type' property - i.e. 'primitive type' represents a 'facet' in sense \n>> 1!\n>>\n>> [1] <http://www.miskatonic.org/library/facet-web-howto.html>\n>>\n>> ---\n>> Alistair Miles\n>> Research Associate\n>> CCLRC - Rutherford Appleton Laboratory\n>> Building R1 Room 1.60\n>> Fermi Avenue\n>> Chilton\n>> Didcot\n>> Oxfordshire OX11 0QX\n>> United Kingdom\n>> Email:        a.j.miles@rl.ac.uk\n>> Tel: +44 (0)1235 445440\n>>\n>>\n>\n> --\n> Willpower Information       (Partners: Dr Leonard D Will, Sheena E\nWill)\n> Information Management Consultants              Tel: +44 (0)20 8372\n0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051\n7276\n> L.Will@Willpowerinfo.co.uk\nSheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Mission statement for SKO",
            "content": "Hi all,\n\nI wrote a sort of mission statement for SKOS, just to be very clear about\nwhat I think the goals of the schemas out to be.\n\nMission Statement for SKOS:\n\n*The SKOS schemas are an entry point to the Semantic Web for\nKnowledge Organisation Systems (KOS) such as thesauri.  \n\n*The design of the SKOS schemas should be such that existing data in\nthe form of e.g. thesauri can be mapped directly into the SKOS constructs,\nor some extension of the SKOS constructs, without any loss of information.  \n\n*Furthermore, it should be possible to define a completely automated\ntransformation from existing data structures into an SKOS representation,\nand no extra manual effort on the part of a human agent should be required\nto achieve the transformation.\n\n*Finally, it should be possible to create an RDFS/OWL ontology from\nan SKOS concept scheme, merely by the addition of further statements.  No\ntransformation of the underlying structure of the data should be required.\n\n---\n\nThe short version of the above is: \n\n\"You can use SKOS to get a thesaurus onto the semantic web without too much\neffort.  Then, adding more to the SKOS scheme to make it more like an\nontology should be easy too.\"\n\nAl.         \n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Mission statement for SKO",
            "content": "Hi all,\n\nI wrote a sort of mission statement for SKOS, just to be very clear about\nwhat I think the goals of the schemas out to be.\n\nMission Statement for SKOS:\n\n*The SKOS schemas are an entry point to the Semantic Web for\nKnowledge Organisation Systems (KOS) such as thesauri.  \n\n*The design of the SKOS schemas should be such that existing data in\nthe form of e.g. thesauri can be mapped directly into the SKOS constructs,\nor some extension of the SKOS constructs, without any loss of information.  \n\n*Furthermore, it should be possible to define a completely automated\ntransformation from existing data structures into an SKOS representation,\nand no extra manual effort on the part of a human agent should be required\nto achieve the transformation.\n\n*Finally, it should be possible to create an RDFS/OWL ontology from\nan SKOS concept scheme, merely by the addition of further statements.  No\ntransformation of the underlying structure of the data should be required.\n\n---\n\nThe short version of the above is: \n\n\"You can use SKOS to get a thesaurus onto the semantic web without too much\neffort.  Then, adding more to the SKOS scheme to make it more like an\nontology should be easy too.\"\n\nAl.         \n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Announcing SKOS-Core 1.0  an RDF Schema for Thesaur",
            "content": "> Anouncing: SKOS-Core 1.0 - an RDF Schema for thesauri and related\n> knowledge organisation systems.\n> \n> The SKOS-Core 1.0 schema can be found at\n> \n> http://www.w3.org/2004/02/skos/core\n> \n> The SKOS-Core 1.0 Guide accompanying the schema can be found at\n> \n> http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n> \n> Also, the website for the SWAD-Europe Thesaurus Activity has moved to\n> \n> http://www.w3.org/2001/sw/Europe/reports/thes/\n> \n> \n> SKOS stands for Simple Knowledge Organisation System.  The Goal of\n> SKOS-Core is to provide a framework for bringing existing knowledge\n> organisation systems such as thesauri and the semantic web together.  \n> \n> SKOS-Core exploits the features of RDFS and OWL to provide a flexible and\n> extensible framework within which different types of KOS can interoperate.\n> SKOS-Core is ideal for modelling thesauri, and can cope with the\n> variations commonly found in thesaurus design and structure. \n> \n> Yours on behalf of the Semantic Web Advanced Development for Europe\n> project [1],\n> \n> Alistair Miles.\nNikki Rogers.\nDave Beckett.\n>  \n> [1] SWAD-Europe <http://www.w3.org/2001/sw/Europe/>\n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "In message <06c001c42eed$e904cfb0$fe78a8c0@Thomast40>, Thomas Bandholtz \n<thomas@bandholtz.info> writes\n\n>It never should by default!! A well established thesaurus easily counts\n>100.000s and more concepts! The requester (be it human or machine) must be\n>able to identify the thesaurus source without downloading the whole thing.\n>\n>I my personal vision, the \"whole thing\" *never* will be downloaded at once:\n>avoid redunancy, and what the hell are we doing here? ---\n>We are establish means to *link to specific* concepts and make clear where\n>the come from.\n\nAbsolutely.  Assuming that the machine-readable description of the \nthesaurus concept contains similarly-formatted references to its \n\"neighbouring\" concepts (or that there is a form of query you can issue \nwhich returns \"all concepts with a link to this one\"), then you can \nbrowse up and down the thesaurus tree structure from the starting \nconcept by issuing multiple requests - if that is what you wish to do.\n\nRichard Light\n-- \nRichard Light\nSGML/XML and Museum Information Consultancy\nrichard@light.demon.co.uk\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "In message <byJeXABEE3kAFAa1@light.demon.co.uk> on Sat, 1 May 2004, \nRichard Light <richard@light.demon.co.uk> wrote\n>Assuming that the machine-readable description of the thesaurus concept \n>contains similarly-formatted references to its \"neighbouring\" concepts \n>(or that there is a form of query you can issue which returns \"all \n>concepts with a link to this one\"), then you can browse up and down the \n>thesaurus tree structure from the starting concept by issuing multiple \n>requests - if that is what you wish to do.\n\nYes, and if the browsing is being done by a human there should also be \nprovision for browsing up and down\n(1) an alphabetical list of terms, starting at any specified point,  and\n(2) a list of terms containing a given character string.\n\nLeonard Will\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Leonard Will <L.Will@willpowerinfo.co.uk> [2004-05-01 11:03+0100]\n> \n> In message <byJeXABEE3kAFAa1@light.demon.co.uk> on Sat, 1 May 2004, \n> Richard Light <richard@light.demon.co.uk> wrote\n> >Assuming that the machine-readable description of the thesaurus concept \n> >contains similarly-formatted references to its \"neighbouring\" concepts \n> >(or that there is a form of query you can issue which returns \"all \n> >concepts with a link to this one\"), then you can browse up and down the \n> >thesaurus tree structure from the starting concept by issuing multiple \n> >requests - if that is what you wish to do.\n> \n> Yes, and if the browsing is being done by a human there should also be \n> provision for browsing up and down\n> (1) an alphabetical list of terms, starting at any specified point,  and\n> (2) a list of terms containing a given character string.\n\nI doubt we can specify the human-readable offerings of thesaurus \nproviders in such detail, beyond noting best practice conventions and \ncommon useful UI conventions. What we can do, though, is take these \nas use cases for evaluating the _machine_ interface defined in the SKOS\nAPI. We can ask ourselves whether such a UI could be built against\nany/all SKOS servers that meet the API. This opens up the prospect of \nwrite-once, re-use elsewhere thesaurus browsing tools...\n\nRegarding this specific proposal, it might be worth thinking about \nhow \"an alphabetical list of terms\" works in an internationalised\ncontext. Do all scripts (eg. Japanese kanji, kana?) define a sort order?\nHow about datasets that mix Japanese with English (multilingual\nthesauri, etc.)?\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "In message <20040501102437.GB20642@homer.w3.org> on Sat, 1 May 2004, Dan \nBrickley <danbri@w3.org> wrote\n>\n>Regarding this specific proposal, it might be worth thinking about\n>how \"an alphabetical list of terms\" works in an internationalised\n>context. Do all scripts (eg. Japanese kanji, kana?) define a sort order?\n\nSurely they must if they have dictionaries, catalogues and telephone \ndirectories. I'm sure there will be standards for this, but I haven't \nlooked them up.\n\n>How about datasets that mix Japanese with English (multilingual\n>thesauri, etc.)?\n\nIn a \"multilingual thesaurus\", i.e. one that provides terms in more than \none language to label each concept, you would normally specify which \nlanguage you wanted to work in and the system would then return the \nterms in that language. You could extend it, if you wished, so that you \ncould submit a term in one language and ask the system to return the \nterms in another language or languages that were used for the same \nconcept.\n\nLeonard\n\nP.S. As I assume that we are all on the <public-esw-thes@w3.org> \ndiscussion list, I think it is best not to send duplicate copies to \nprivate email addresses, which just need to be checked to see whether \nthey are really duplicates and then deleted.\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": ">Taher:\n>\n>I just have to jump in here to clarify a couple of things.  \n>\n>Yes, password authentication is a customer requirement.  Many companies tell\n>us that they want a migration path from passwords to certificate-based\n>systems within the TLS protocol standard.  This has been the sole reason we\n>have been pushing so hard for password authentication...customer need.  The\n>business side of this argument has already been comprehensively presented by\n>John Macko (Compuserve) in an earlier posting (7/22) so I don't want to start\n>that chain again here.  \n>\n>But Dan's comment about forward compatibilty in SSL has nothing to do with\n>passwords per se.  Fact: there is no generic extensibility mechanism in SSL3\n- and that's something we need to acknowledge and fix as soon as we can.\n> The goal of this working group, after all, should be to create an\n>architecturally-sound, extensible standard.  I admit that this will cause us\n>all some pain as we find ourselves having to change our fielded\nimplementations to prepare for future advances in the protocol.  But if\n>we bite the bullet and design the protocol correctly now, it shouldn't be\n>such a big deal as we go incrementally forward.  \n\n>Barb\n>\n>----------\n>From: elgamal@netscape.com[SMTP:elgamal@netscape.com]\n>Sent: Wednesday, October 09, 1996 8:49 AM\n>To: Dan Simon\n>Cc: 'ietf-tls@w3.org'; 'treese@OpenMarket.com'; 'david.brownell@Eng.Sun.COM'\n>Subject: Re: Closing on shared-key authentication\n>\n>Dan,\n>\n>You bring an interesting point. In the design of SSL3.0, we did not\n>expect that the protocol would have to support weaker authentication\n>techniques, actually going backwards if you think about it. The idea of\n>SSL3.0 was not to support everything that may exist or everything anyone\n>can think of. So, you cannot really accuse SSL of not being forward\n>compatible because it assumes a good authentication method rather than\n>duplicate old ones that everyone has already implemented in any\n>interesting application protocol. The only reason for me to entertain\n>this password thing is that a customer thinks it is useful, not really\n>because it adds anything to the protocol, on the contrary, it makes it\n>less attractive since the level of authentication is not defined. \n>\n>Taher\n>\n>\n>Dan Simon wrote:\n>> \n>> >From:  david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n>> >\n>> >I'll have to go back and look at the comments from last\n>> >week's proposal (ssl-talk is where I saw most of it),\n>> >but this proposal really doesn't seem \"cooked\" to me.\n>> >\n>> >   - Internationalization issues arise.  In what character\n>> >     set do \"display_string\" and \"challenge\" appear?  How\n>> >     is the language which the end user knows specified?\n>> >\n>> >     I don't like seeing application layer issues intrude\n>> >     on transport layer protocols.\n>> \n>> The \"display_string\" field is opaque; that is, TLS simply transports it\n>> without examining its content.  It is entirely the next level's\n>> responsibility to figure out what to do with it (or even if it should be\n>> sent in the first place).  Why is this an \"intrusion\" into the transport\n>> layer, any more than, say, the presence of the opaque application data\n>> which is passed through TLS as part of its basic function?\n>> >\n>> >   - Neither \"rough consensus\" nor (multiple instances of)\n>> >     \"working code\" exists, as has been pointed out.\n>> >\n>> >     Many of us don't see a technical benefit to making TLS\n>> >     be incompatible with SSLv3 in this respect, so I doubt\n>> >     that a realistic \"consensus\" on this point can exist.\n>> \n>> Well, the real problem is that virtually *any* difference between TLS\n>> and SSL 3.0 would make TLS incompatible with SSL 3.0, because SSL 3.0\n>> simply lacks a mechanism for forward compatibility.  If we do nothing\n>> else, we absolutely *must* prevent this problem from grandfathering its\n>> way into TLS.  (The fix that's been suggested as least painful to SSL\n>> 3.0 implementers is to specify that unrecognized handshake message types\n>> be ignored--hence our use of new handshake message types to implement\n>> shared-key authentication.  If someone has a better way to permit\n>> extensibility, then I'd be happy to hear about it.)\n>> >\n>> >   - It's unclear just where in the handshake these new\n>> >     messages would go.  Or are they even part of the\n>> >     regular handshake protocol?  Do they go after the\n>> >     \"Finished\" messages are exchanged, are they an\n>> >     independent handshake, or what?\n>> \n>> The posted document specifies where the extra messages should go.\n>> >\n>> >   - Given that the amount of keying material to be built\n>> >     is derived from the negotiated cipher spec, what's\n>> >     the change needed in the definition of a cipher spec?\n>> >     It needs to know it must generate CipherSpec.hash_size\n>> >     (times two?) bytes of keying data.\n>> \n>> In SSL 3.0 (and presumably TLS), the actual keying material is not\n>> included in the cipher_spec, but rather as part of the general\n>> connection state.  Implementations that don't support shared-key\n>> authentication can, of course, ignore the extra keying material\n>> altogether.\n>> >\n>> >   - There's a new requirement, to ignore unrecognized\n>> >     handshake messages rather than treat them as errors.\n>> >     I prefer protocols to be fully specfied.\n>> \n>> If it's preferable, the specification can certainly require that\n>> implementations recognize the extra handshake messages.  Of course, the\n>> real problem here is SSL 3.0's lack of an extensibility mechanism; see\n>> my comments above.\n>> >\n>> >I could raise more questions, but the fact that there are\n>> >this many (after this much discussion!) says to me that the\n>> >proposal should not be deemed \"cooked\" enough to incorporate\n>> >into an IETF standard.\n>> \n>> To my mind, the problems with the proposal, as enumerated by David, cast\n>> a worse light on SSL 3.0 than on the proposal itself.\n>> \n>>                                 Daniel Simon\n>>                                 Cryptographer, Microsoft Corp.\n>>                                 dansimon@microsoft.com\n>> \n>> >\n>> >\n>> >\n>\n>-- \n>Taher Elgamal    elgamal@netscape.com\n>Chief Scientist, Netscape Communications\n>(T) 415 937 2898, (F) 415 428 4054\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "On Sat, 1 May 2004, Leonard Will wrote:\n\n>\n>In message <byJeXABEE3kAFAa1@light.demon.co.uk> on Sat, 1 May 2004,\n>Richard Light <richard@light.demon.co.uk> wrote\n>>concepts with a link to this one\"), then you can browse up and down the\n>>thesaurus tree structure from the starting concept by issuing multiple\n>>requests - if that is what you wish to do.\n>\n>Yes, and if the browsing is being done by a human there should also be\n>provision for browsing up and down\n>(1) an alphabetical list of terms, starting at any specified point,  and\n>(2) a list of terms containing a given character string.\n\nBeing able to browse by terms, as well as by concept relationships, is\nextremely important. The tools we as people have to determine whether we\nreally mean the same concepts are essentially words and pictures.\n\nOne thing that is intersting in implementations is being abel to see why a\ncertain term is not the preferred term for a concept - erhaps because it is a\npreferred term for another concept, or becausee it overlaps too much with its\nuse as an alternative term for another concept...\n\nCheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "On Sat, 1 May 2004, Leonard Will wrote:\n\n>\n>In message <20040501102437.GB20642@homer.w3.org> on Sat, 1 May 2004, Dan\n>Brickley <danbri@w3.org> wrote\n>>\n>>Regarding this specific proposal, it might be worth thinking about\n>>how \"an alphabetical list of terms\" works in an internationalised\n>>context. Do all scripts (eg. Japanese kanji, kana?) define a sort order?\n>\n>Surely they must if they have dictionaries, catalogues and telephone\n>directories. I'm sure there will be standards for this, but I haven't\n>looked them up.\n\nIn general languages define sorting order(s). For example, where accented\nlatin characters appear depends on the language (Icelandic and Vietnamese\nshare some distinctive characters but sort them differently, as do\nGreenlandic and the Yolngu-Matha group of australian languages). There are\nseveral ways of sorting Japanese, based on Kanji features or on kana\ntransliterations, depending for example on what the use case is.\n\nThese strike me as very implementation-dependent details. As Dan said in the\nthread, we probably should not be specifying this normatively (although we\ncan note it in best practices and such). In some cases a new implementation\nwill want to create a new ordering approach (such as mixing japanese with\nfrench by using a romaji version of the japanese term as the sorting key, to\npick an example from the top of my head). In other cases there will be no\nreally good way of doing things - transliteration of arabic into latin\ncharacters is so widely variant that terms may appear twice in different\ntransliterations, to help find them (Osama, Ousama and Usama are all common\ntransliterations of the same arabic name, to pick a random example). Mostly\none would expect people developing a system for a language to know how to\nsort in that language, or to make the effort of finding out.\n\ncheers\n\nChaals\n\n>>How about datasets that mix Japanese with English (multilingual\n>>thesauri, etc.)?\n>\n>Leonard\n>\n>P.S. As I assume that we are all on the <public-esw-thes@w3.org>\n>discussion list, I think it is best not to send duplicate copies to\n>private email addresses, which just need to be checked to see whether\n>they are really duplicates and then deleted.\n\nThis is true, but for various reasons it tends to be a pain and people forget\nto do it...\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Thomas Bandholtz <thomas@bandholtz.info> [2004-04-30 22:01+0200]\n> \n> \n> Alistair > One thing a GET request for the thesaurus URI should definitely\n> return is a\n> > description of that thesaurus (i.e. name, version, creators, description\n> of\n> > scope and content etc.) although again whether that should be machine or\n> > human readable is open.\n> \n> Obviously *both* must be possible.We had megabytes of discussion on this in\n> the Topic Map community and elsewhere.\n\nSure, both are possible and will remain so. Our focus here, though, is\non the machine readable aspect (and on making machine interfaces that \nare adequate to support an interesting and usable range of human\ninterfaces).\n\n> The answer is very simple - there are humans, and there are machines\n> (software agents).\n> A service may decide to serve only one of them, but she may decide to serve\n> both.\n> She may even decide to serve several machine protocols or several human\n> readable layouts.\n> The consequence is that a singe URL is not enough.\n\nThat doesn't necessarily follow. HTTP supports content negotiation \n(see http://www.w3.org/Protocols/ ftp://ftp.isi.edu/in-notes/rfc2616.txt) \nwhich allows multiple representations of the same thing to be made \naccessible via a common URI.\n\n> We need pairs of protocol-URL such as\n> \n> HTML -> http://human.blah.org/thesaurus.html\n> WSDL -> http://services.blah.org/thesaurus.wsdl\n> DCMI -> http://dcmi.blah.org/thesaurus.xml\n> etc., etc.,\n> \n> these must be explictly *pairs* (protocol -> URL) as the domain name must\n> not contain any significant meaning itself (see RFC URI)\n\nWe can also use XML namespace mixing to make multiple kinds of\ninformation available within a common piece of markup (eg. RDF inside\nXHTML, or RDF styled into XHTML using XSLT). There are a lot of options\nto explore.\n\n> Alistair > The other question is, should the request for the thesaurus URI\n> also return\n> > the entire content of the thesaurus?  Personally I think no, but again I'm\n> > not sure about that.\n> \n> It never should by default!! A well established thesaurus easily counts\n> 100.000s and more concepts! The requester (be it human or machine) must be\n> able to identify the thesaurus source without downloading the whole thing.\n\nYep, I agree, downloading the entire database will be relatively rare.\n\n> I my personal vision, the \"whole thing\" *never* will be downloaded at once:\n> avoid redunancy, and what the hell are we doing here? ---\n> We are establish means to *link to specific* concepts and make clear where\n> the come from.\n\nSearch engine apps may well find value in downloading the entire thing.\n\nAs host to http://xmlns.com/wordnet/1.6/ I have noticed that some people\nhave tried to crawl the entire dataset with repeated HTTP requests,\npresumably so they can populate a local database for query etc. I'd like\nto have conventions for giving them the entire dataset in a more\nefficient manner.\n\nDan\n\n> Downloading and so duplicating a thesaurus is OK in some situations, but\n> this should be regarded as a very special use case.\n> \n> Thomas\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Dan: \n> Sure, both are possible and will remain so. Our focus here, though,is\n> on the machine readable aspect (and on making machine interfaces that\n> are adequate to support an interesting and usable range of human\n> interfaces).\n\nThat's exactly what I am looking for. Especially I am interested in a Web\nService solution.\n\nThomas: \n> > The consequence is that a single URL is not enough.\nDan: \n> That doesn't necessarily follow. HTTP supports content negotiation\n> (see http://www.w3.org/Protocols/ ftp://ftp.isi.edu/in-notes/rfc2616.txt)\n> which allows multiple representations of the same thing to be made\n> accessible via a common URI.\n\nI found http://www.w3.org/Protocols/rfc2616/rfc2616-sec12.html:\n\"Server-driven negotiation has disadvantages:\n      1. It is impossible for the server to accurately determine what\n         might be \"best\" for any given user, since that would require\n         complete knowledge of both the capabilities of the user agent\n         and the intended use for the response (e.g., does the user want\n         to view it on screen or print it on paper?).\"\n\nIMHO we only could think about server-driven negotiation here.\nThis does not sound very encouraging ...\nAgain, I would focus on a Web Service which at least has a WSDL, so the\nclient can see what she will get back.\n\nDan:\n> We can also use XML namespace mixing to make multiple kinds of\n> information available within a common piece of markup (eg. RDF inside\n> XHTML, or RDF styled into XHTML using XSLT). There are a lot of options\n> to explore.\n\nWell, here we have the SKOS Core RDF (2004-03-26) and the SKOS API WSDL/XML\nSchema (2004-04-29) serializations, or  namespaces.\nI thought about using the RDF in the Web Service, but API brings its own\nmodel, which is not fully consistent with the RDF semantically!\n\nIs this really what we need?\n\nWould be nice to have a *complete* information model independent of any\nsyntax (as they have it in ISO19115, where the XML Syntax is a second\nstandard ISO19139).\n\n\nThomas\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Thomas Bandholtz writes:\n\n> Dan: \n> > That doesn't necessarily follow. HTTP supports content negotiation\n> > (see http://www.w3.org/Protocols/\n> > ftp://ftp.isi.edu/in-notes/rfc2616.txt) which allows multiple\n> > representations of the same thing to be made accessible via a\n> > common URI.\n> \n> I found http://www.w3.org/Protocols/rfc2616/rfc2616-sec12.html:\n> \"Server-driven negotiation has disadvantages:\n>       1. It is impossible for the server to accurately determine what\n>          might be \"best\" for any given user, since that would require\n>          complete knowledge of both the capabilities of the user agent\n>          and the intended use for the response (e.g., does the user \n>          want to view it on screen or print it on paper?).\"\n> \n> IMHO we only could think about server-driven negotiation here.\n> This does not sound very encouraging ...\n\nServer-side negotiation can be very effective in combination with the\nAccept headers.\n\nFor example:\n\n    GET /foaf/0.1/ HTTP/1.1\n    Host: xmlns.com\n    Accept: text/html\n\nreturns a description of FOAF in HTML, while\n\n    GET /foaf/0.1/ HTTP/1.1\n    Host: xmlns.com\n    Accept: application/rdf+xml\n\nreturns a schema in RDF/XML.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "On Sun, 2 May 2004, Thomas Bandholtz wrote:\n\n>Thomas:\n>> > The consequence is that a single URL is not enough.\n>Dan:\n>> That doesn't necessarily follow. HTTP supports content negotiation\n>> (see http://www.w3.org/Protocols/ ftp://ftp.isi.edu/in-notes/rfc2616.txt)\n>> which allows multiple representations of the same thing to be made\n>> accessible via a common URI.\n>\n>I found http://www.w3.org/Protocols/rfc2616/rfc2616-sec12.html:\n>\"Server-driven negotiation has disadvantages:\n>      1. It is impossible for the server to accurately determine what\n>         might be \"best\" for any given user, since that would require\n>         complete knowledge of both the capabilities of the user agent\n>         and the intended use for the response (e.g., does the user want\n>         to view it on screen or print it on paper?).\"\n>\n>IMHO we only could think about server-driven negotiation here.\n>This does not sound very encouraging ...\n>Again, I would focus on a Web Service which at least has a WSDL, so the\n>client can see what she will get back.\n\nHTTP Content-negotiation isn't entirely server driven - it relies on teh\nclient specifying what they want. CC/PP  is even more  powerful in this sense\n(and uses RDF :-)\n\nWSDL actually ends up just being plain text, which is really not that handy\nfor users, difficult to search for if the service was created in french or\nthe searcher only reads vietnamese, chinese, and russian, and it is pretty\ndreadful for trying to process automatically in general. (Hopefully that will\nchange of course...) But  Web service is a useful thing - although I don't se\nit  as  being fundamentally different. If  we make a web service smart\nenough to offer  more than one type of result, we need  to define how that\ncan be selected, and we are likely to come back to somethign as automatable\nas HTTP content negotiation as a  well-understood system...\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "write-once, reuse elsewhere theasurus tool",
            "content": "Just to pick up and emphasise this comment from Dan ...\n\n> What we can do, though, is take these \n> as use cases for evaluating the _machine_ interface defined \n> in the SKOS\n> API. We can ask ourselves whether such a UI could be built against\n> any/all SKOS servers that meet the API. This opens up the prospect of \n> write-once, re-use elsewhere thesaurus browsing tools...\n> \n\nHaving re-usable thesaurus browsing components, esp. for web pages, is for\nme a major driver of the SKOS work - I'd really like to be able to support\nthe d-lib & thesaurus communities, where folks are currently putting a lot\nof energy into implementing bespoke UIs that talk to their uniquely\nstructured database and hence aren't re-usable by anyone else.\n\nWhether the current SKOS API supports the full range of functionality\nrequired by thesaurus browsing and searching components is the acid test for\nthe API, and this requirement is a major driver for it's continued\ndevelopment.  So comments and descriptions of what a thesaurus browser ought\nto be able to do are very valuable here.\n\nJust a final word, it really is astonishing to me the extent to which some\nlarge organisations seem to be implementing large and monolithic information\nsystems end-to-end, with little or no thought as to how they can unplug and\nreuse some of these components in the future as systems and requirements\nevolve, or make them available outside their own organisation as part of a\nshared infrastructure or distributed service.  I reckon there's a big\nopportunity for some very simple and yet very valuable work to be done in\nthis area.    \n\nAl.\n\n\n\n"
        },
        {
            "subject": "Re: write-once, reuse elsewhere theasurus tool",
            "content": "Al,\n\nhave you get cvs access to our server yet?\nI've started checking in code I'm working on - it's hopefully got the \npluggable-innable approach we're after. I'm going to develop the results \nobject modelling - which is going to be especially important re the \ndevelopment of a web browser 'frontend' to the the service - I think you \nwere interested in developing this bit yourself, right?\n\nNikki\n\n--On Tuesday, May 04, 2004 14:16:16 +0100 \"Miles, AJ (Alistair) \" \n<A.J.Miles@rl.ac.uk> wrote:\n\n>\n> Just to pick up and emphasise this comment from Dan ...\n>\n>> What we can do, though, is take these\n>> as use cases for evaluating the _machine_ interface defined\n>> in the SKOS\n>> API. We can ask ourselves whether such a UI could be built against\n>> any/all SKOS servers that meet the API. This opens up the prospect of\n>> write-once, re-use elsewhere thesaurus browsing tools...\n>>\n>\n> Having re-usable thesaurus browsing components, esp. for web pages, is for\n> me a major driver of the SKOS work - I'd really like to be able to support\n> the d-lib & thesaurus communities, where folks are currently putting a lot\n> of energy into implementing bespoke UIs that talk to their uniquely\n> structured database and hence aren't re-usable by anyone else.\n>\n> Whether the current SKOS API supports the full range of functionality\n> required by thesaurus browsing and searching components is the acid test\n> for the API, and this requirement is a major driver for it's continued\n> development.  So comments and descriptions of what a thesaurus browser\n> ought to be able to do are very valuable here.\n>\n> Just a final word, it really is astonishing to me the extent to which some\n> large organisations seem to be implementing large and monolithic\n> information systems end-to-end, with little or no thought as to how they\n> can unplug and reuse some of these components in the future as systems\n> and requirements evolve, or make them available outside their own\n> organisation as part of a shared infrastructure or distributed service.\n> I reckon there's a big opportunity for some very simple and yet very\n> valuable work to be done in this area.\n>\n> Al.\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "SKOS-Core 1.0 guide  section 4 edi",
            "content": "I've done a small edit of the SKOS-Core 1.0 guide \n\nhttp://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n\nSection 4 is now called 'Using SKOS-Core with Dublin Core for subject-based\nindexing'.\n\nThis section now recommends the use of the dc:subject property for stating\nthe 'subject' of some resource such as a web document, where the 'subject'\nhas been defined as a SKOS concept.\n\nThis section no longer recommends the use of foaf:topic or foaf:primaryTopic\nwith SKOS concepts.  \n\nMotivation for this change:\n\nDan Brickley has argued the point (convincingly in my opinion) that the\nqualified DC style of resource description (using the dc:subject property to\npoint to some concept from a subject scheme such as a thesaurus) is actually\nfundamentally different from the FOAF[1] style of resource description\n(using the foaf:topic and foaf@primaryTopic properties to point to some\nconcrete thing defined by its properties).  The SKOS scheme is designed to\nbe used to represent thesaurus style subject schemes.  It fits perfectly\nwith the qualified DC style of description [2].  SKOS concepts are therefore\nappropriately used with dc:subject, and not with\nfoaf:topic/foaf:primaryTopic.\n\nAl.\n\n[1] http://xmlns.com/foaf/0.1/index.html#term_topic\n[2] http://dublincore.org/documents/dcq-rdf-xml/ [section 2.3]\n\n\n\n"
        },
        {
            "subject": "Inconsistencies between SCOS Core RDF and SKOS AP",
            "content": "As mentioned before, I found some inconsistencies between SCOS Core RDF (\"CORE\") \nhttp://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\nand SKOS Web Services API (\"API\")\nhttp://www.w3.org/2001/sw/Europe/reports/thes/skosapi.html\n\nBefore that I thought about the use case I want to serve: \n\n(uc1) (Software-) Agent comes across the service-URL of an SKOS thesaurus interface. \nCould have found it in an UDDI, inspected the WSDL and detected \"skos-core 1.0\" as the schema.\nHas there been discussion on SKOS in registries?\n\n(uc2) Given that Agent \"knows\" how to handle SKOS: it requests a general thesaurus description from the interface. \nThe description gives enough information (by well known URL-identifiers), so agent can decide whether to give it a closer look.\nIf this is not the case, Agent has to call his (human) master who must read all the stuff and decide \"manually\".\n\n(uc3) Agent requests the kind of relations used in the thesaurus. \nAgent already \"knows\" some of them - some not. Can Agent \"learn\" on the fly? \n\n\nThen I revisited the SKOS-CORE 1.0 Guide and the SKOS API (no Guide so far, only a JavaDoc and a WSDL) to see how this little scenario is specified so far.\n\nFound nothing about uc1.\n\n-> affecting (uc2):\nCORE knows  <skos:ConceptScheme> that describes the thesaurus using dublin core (DC) metadata. \nThat looks fine, but the description of thesaurus might be a concept <skos:Concept> itself - I would like the idea.\nI think that <skos:Concept rdf:about =\"#self\"> word be more powerful than <skos:ConceptScheme>.\nChapter 4 of the Guide suggests (if I understand it right) that also concepts can be annotated using DC, so we could describe it just as drafted for <skos:ConceptScheme>.   \n\nAPI does not include a Service.GetConceptScheme() method ..., well I could use Service.GetConcept(\"#self\"). \n\nThe conceptScheme (or the concept of \"#self\") should use URI-references to well know external definitions describing its own scope. \n\nCORE only discusses \"External (non-URI) identifiers for concepts\" - external URI identifiers are only shown as interspersed DC or FOAF fragments  - this apears a little \"weak\" to me. \nDan proposed <skos:conceptualizes> in http://lists.w3.org/Archives/Public/public-esw-thes/2004Apr/0021.html\nBernard prefers <skos:subjectIndicator> in http://lists.w3.org/Archives/Public/public-esw-thes/2004Apr/0024.html\nCould also be <skos:externalIdentifier>, or use <skos:externalID> with a URL, as Bernard has proposed.\n\nAPI is not consistent with CORE: API Concept has an attribut \"uri\" - the \"Global URI of concept (optional)\", which I understand to be an external identifier.\n\n\n-> affecting (uc3):\nAPI has a nice method: \n\"public Relation[] getSupportedSemanticRelations()\nGet a list of supported semantic relations. For example things such as broader, narrower, is-a each with a unique uri, a description of their meaning and human readable label.\" \n\nFine - but CORE only contains a *fixed* set of relation types, that indeed are extensions of <skos:semanticRelation> . \n\n*** How to extend this set without extendig the interface definition? ***\n*** Example: we use a \"spatial intersection Relation\".***\n\nMaybe by inventing <skos:semanticRelation extension=\"#blahRelation\"> or similar ? \nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.2.html#2.3 talks about \"Extensible and customisable relationship sets\" but not about the service interface.\n\nMore exactly: if I extend <skos:semanticRelation> in <skos:spatialIntersection>,  Agent would have to be re-compiled to \"understand\" this in the Web Services/XML Schema world.\nI am not really familiar with Web Services/RDF Schema . \nAny input from http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-4.html?\n\nAPI has no fixed set of relations at all, that's why getSupportedSemanticRelations()could easily return my spatialIntersection relation.\n \n\"public class Relation: \nA class for semantic relations including the URI of the relation along with their description and human readable label. Intended to hold the URI of an rdf Property along with the rdfs:comment value as description and rdfs:label value as label. The SKOS-Mapping vocabulary draft is at http://www.w3c.rl.ac.uk/2003/11/21-skos-mapping and lists the mapping relation properties with their label and description.\"\n\nI would like to see this also in a Guide. \nCan anyone provide a sample how to handle my \"spatialIntersection Relation\" in a way that Agent can learn to use it without having to be re-compiled?\n\nI guess I prefer the model of API, but may be this is only because I am more familiar with Web Services and XML Schema than with RDF.\nBTW, the XML Schema embedded in the WSDL of API has been generated by Axis ... hm ... it will work, as most of Axis does, but it should be edited before proposing it as the \"normative\" Schema ....\n\nThomas\n\n\n\n"
        },
        {
            "subject": "Supporting arrays of concept",
            "content": "This is a strawman proposal for addition to the SKOS-Core schema:\n\nSome thesauri group concepts into ordered arrays, and label the array, e.g.\n\nPeople\n        <people by age>\n        Children (0-12 years)\n        Teenagers (13-19 years)\n        Adults (over 20 years)\n\nSince this sort of thing is common practise, and I believe will be a part of\nthe new British standard for thesauri (Leonard, Stella?), I thought we ought\nto come up with a mechanism for representing it as part of the SKOS-Core\nvocab.  \n\nThis sort of thing would also be useful in the Annotea bookmarks work. \n\nThe problem is the best way to represent an ordered list in RDF.  The\nconsensus so far seems to be for using RDF Lists (collections).  The other\nproblem is how to connect an array to the parent concept.  Such a connection\ncannot replace the skos:broader statements from the array members, and must\nbe synchronised with them.  \n\nAnyway, I suggest the following additions:\n\nskos:Arrayardfs:Class.\n\nskos:arrayMemberListardf:Property;\nrdfs:domainskos:Array.\n\nskos:arrayParentardf:Property;\nrdfs:domainskos:Array;\nrdfs:rangeskos:Concept.\n\n... which would lead to e.g. ...\n\n[askos:Array;\nrdfs:label'people by age';\nskos:arrayParent:conceptD;\nskos:arrayMemberList(:conceptA :conceptB :conceptC)\n].\n\n:conceptDaskos:Concept;\nskos:prefLabel'People';\nskos:narrower:conceptA;\nskos:narrower:conceptB;\nskos:narrower:conceptC.\n\n:conceptAaskos:Concept;\nskos:prefLabel'Children (0-12 years)';\nskos:broader:conceptD.\n\n:conceptBaskos:Concept;\nskos:prefLabel'Teenagers (13-19 years)';\nskos:broader:conceptD.\n\n:conceptCaskos:Concept;\nskos:prefLabel'Adults (over 20 years)';\nskos:broader:conceptD.\n\nComments on any aspect of this suggestion?\n\nAlistair.\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concept",
            "content": "> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: Wednesday, May 05, 2004 2:21 PM\n> Subject: Supporting arrays of concepts\n> \n> \n> This is a strawman proposal for addition to the SKOS-Core schema:\n> \n> Some thesauri group concepts into ordered arrays, and label \n> the array, e.g.\n> \n> People\n>         <people by age>\n>         Children (0-12 years)\n>         Teenagers (13-19 years)\n>         Adults (over 20 years)\n> \n> Since this sort of thing is common practise, and I believe \n> will be a part of the new British standard for thesauri \n> (Leonard, Stella?), I thought we ought to come up with a \n> mechanism for representing it as part of the SKOS-Core vocab.  \n> \n> This sort of thing would also be useful in the Annotea \n> bookmarks work. \n> \n> The problem is the best way to represent an ordered list in \n> RDF.  The consensus so far seems to be for using RDF Lists \n> (collections).  The other problem is how to connect an array \n> to the parent concept.  Such a connection cannot replace the \n> skos:broader statements from the array members, and must be \n> synchronised with them.  \n> \n\nThis seems like what is called Node Labels and used by AAT and\nDewey.  Node Labels can be thought of as concepts that participate\nin the hierarchy structure but cannot be assigned as concepts.  In\nDewey, for example, it has the notion of centered entries.  If you\nlook at the printed edition these have a > (greater than sign)\npreceeding the class span.  You cannot assign them as a class number\nbut they are present for the purposes of grouping the hierarchy, as\nin your example.  Node Labels have all the same relationships as\nconcepts do, so many times they are represented as concepts.\n\nThe MARC21 Authorities format also has the concept of Node Labels,\nsee http://www.loc.gov/marc/authority/ecadcntr.html#mrca008, position\n09 - Kind of record, value 'e'.  In addition, the MARC21 Classification\nformat has the concept of Node Labels, see\nhttp://www.loc.gov/marc/classification/eccdclas.html#mrcc153, subfield\ncode $k - Summary number span caption hierarchy, which is used in\nconjunction with position 07 - Type of number, value 'c' in the 008 \nfield, see http://www.loc.gov/marc/classification/eccdcntr.html#mrcc008.\n\nSKOS currently doesn't take Node Label's into account with it's\nprefLabel and altLabel elements.  It is possible that a Node Label\ncould have many different altLabel's.  I don't think that you need\nto add additional structure to represent Node Labels.  Perhaps,\nwhat is needed is to say that a concept must have either a group\nof prefLabel elements (xml:lang'ed) or a group of nodeLabel elements\n(xml:lang'ed) and can have any number of altLabel elements.  Since \nNode Labels will also have BT, NT, RT relationships, you will not \nneed to duplicate that structure by reusing skos:Concept.\n\n\nAndy.\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Dan Brickley wrote:\n\n>* Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-30 17:36+0200]\n>  \n>\n>>To go along with Dan ...\n>>\n>>I also prefer the / approach in principle because it defines more neatly the \"subject\n>>indicator\", but consider that e.g. OWL uses fragment identifiers to define classes and\n>>properties ...\n>>\n>>Will not people be confused with OWL elements defined by\n>>http://example.org/myontology#class001\n>>and SKOS concepts defined by http://example.org/myskos/concept001\n>>    \n>>\n>\n>Some RDF/RDFS/OWL vocabs end in a / and others end in a # and others do\n>other things. This is the current state of affairs. The confusion is\n>only a problem because these different approaches have different\n>technical and standards characteristics (and those aren't well\n>explained, currently).\n>  \n>\nThis calls for engineering guidelines, which probably means the issue \nshould be shunted onto the SWBPD WG.\n\n>>And having, e.g. for GEMET, over 8000 different resources/concepts, if you just want to\n>>download the whole stuff, hmm...\n>>Is not it more simple to have a / namespace for a whole SKOS scheme, and # for each\n>>concept in it?\n>>\n>>We've been through this in Published Subjects TC, without clear conclusion ...\n>>    \n>>\n>\n>I've a few years experience using the http://xmlns.com/wordnet/1.6/Cat\n>etc approach, and have to say it is useful. The ability to return a\n>useful chunk of information from a larger dataset is something I am\n>reluctant to give up. Surely in the future we'll have richer (SKOS API,\n>RDF DAWG etc) interfaces to these datasets, but the current approach can\n>be implemented with a simple filetree or CGI script, and has proved\n>reasonably popular.\n>  \n>\nYes, this approach is immediately useful. I suspect it would be sensible \nfor any future interfaces to retain the http://xmlns.com/wordnet/1.6/Cat \nkind of behaviour. This is akin to getting the concise bounded \ndescription of the resource, which as an RDF representation over http in \nRDF/XML seems to make a lot of sense. Similarly, for the root \"service\" \nURI it would probably be consistent, and make pragmatic sense for the \ndefault RDF representation returned to be a concise description of the \nservice rather than the whole caboodle. Having a recommended means of \nretrieving the whole dataset may well be useful, but I'm not sure how \nthis could be done without conflicting with general architectural \nrequirements. All that comes to mind is use of the same URI but content \nnegotiation for an \"application/rdf+kitchensink\" mime type.\n\nCheers,\nDanny.\n\n-- \n----\nRaw\nhttp://dannyayers.com\n\n\n\n"
        },
        {
            "subject": "Supporting arrays of concepts : node label",
            "content": "In message\n<B56ABE145BEB0C40A265238FCAA420DF01DC8E58@oa2-server.oa.oclc.org> on\nWed, 5 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n>\n>> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n>> Sent: Wednesday, May 05, 2004 2:21 PM\n>> Subject: Supporting arrays of concepts\n>>\n>>\n>> This is a strawman proposal for addition to the SKOS-Core schema:\n>>\n>> Some thesauri group concepts into ordered arrays, and label\n>> the array, e.g.\n>>\n>>      People\n>>                <people by age>\n>>                Children (0-12 years)\n>>                Teenagers (13-19 years)\n>>                Adults (over 20 years)\n>>\n>> Since this sort of thing is common practise, and I believe  will be a part of\n>>the new British standard for thesauri  (Leonard, Stella?), I thought we\n>>ought to come up with a  mechanism for representing it as part of the\n>>SKOS-Core vocab.\n\nYes, it is in the draft of the new standard. It would be good to have\nsoftware to handle it properly, as most existing packages are weak in\nthis area.\n\n>> The problem is the best way to represent an ordered list in  RDF.  The\n>>consensus so far seems to be for using RDF Lists  (collections).  The\n>>other problem is how to connect an array  to the parent concept.  Such a\n>>connection cannot replace the  skos:broader statements from the array\n>>members, and must be  synchronised with them.\n\n>This seems like what is called Node Labels and used by AAT and Dewey.\n>Node Labels can be thought of as concepts that participate in the\n>hierarchy structure but cannot be assigned as concepts.  In Dewey, for\n>example, it has the notion of centered entries.  If you look at the printed\n>edition these have a > (greater than sign) preceeding the class span.  You\n>cannot assign them as a class number but they are present for the\n>purposes of grouping the hierarchy, as in your example.  Node Labels\n>have all the same relationships as concepts do, so many times they are\n>represented as concepts.\n\nUnfortunately, the expression \"node label\" has been used to mean\ndifferent things in different places. They should not be thought of as\nconcepts, because they do not represent concepts, and they do not have\nscope notes or  any of the normal thesaurus relationships. When using\nsoftware that does not make proper provision for node labels it is\nsometime necessary to treat them as concepts and give them BT/NT\nrelationships in order to display them in the proper place in a\nhierarchy, but this is a fudge.\n\nThe AAT uses the expression \"guide terms\" rather than node labels, and\nincludes in this not only real node labels (as described at 1 below) but\nalso terms which represent real concepts but which it thinks are\ninappropriate for use as indexing terms. This is confusing and\nmisleading; I think that any term used to describe a concept should be\npotentially usable in indexing, though it can have the note \"use a more\nspecific concept if possible\".\n\nIn the draft British Standard we propose that there should be two kinds\nof node label:\n\n1. A node label showing a \"characteristic of division\". This is the kind\nshown in the example above, and each label contains the word \"by\"\nfollowed by the characteristic by which the elements of the following\narray are distinguished. There may be several arrays under any term,\neach introduced by a separate node label, e.g.\n\n      people\n          <people by age>\n              children (0-12 years)\n              teenagers (13-19 years)\n              adults (over 20 years)\n\n          <people by occupation>\n          builders\n          bus drivers\n          information technologists\n          information scientists\n          librarians\n\n          <people by sex>\n          male people\n              men\n              boys\n          female people\n              women\n              girls\n\nand so on.\n\n2. In a display of a classification, rather than a thesaurus, node\nlabels are used to show where a change of facet occurs, especially when\nterms from different facets are being combined. They make it clear that\nthe relationship between the terms preceding and following the node\nlabel is not BT/NT, but that the following classes are a compound of the\nsubsequent concepts with the preceding concept. In the following\nexample, the node labels containing the names of facets are given in\nparentheses:\n\n(organisms)\nmammals [in general]\n      carnivores [in general]\n          leopards\n          lions\n          tigers\n      herbivores [in general]\n          cattle\n          sheep\n(processes)\n      physiological processes [in general]\n          digestion [in general]\n              (organisms)\n              [digestion in] carnivores\n                  [digestion in] lions\n              [digestion in] herbivores\n                  [digestion in] cattle\n                  [digestion in] sheep\n          respiration [in general]\n              (organisms)\n              [respiration in] lions\n\nThe words in square brackets in this example are often omitted in\nclassification schedules, being implied by the indentation or\ntypography.\n\nI take it that at the moment you are just addressing the issue of node\nlabels of type 1.\n\n>SKOS currently doesn't take Node Label's into account with it's prefLabel\n>and altLabel elements.  It is possible that a Node Label could have many\n>different altLabel's.  I don't think that you need to add additional structure\n>to represent Node Labels.  Perhaps, what is needed is to say that a\n>concept must have either a group of prefLabel elements (xml:lang'ed) or a\n>group of nodeLabel elements (xml:lang'ed) and can have any number of\n>altLabel elements.  Since Node Labels will also have BT, NT, RT\n>relationships, you will not need to duplicate that structure by reusing\n>skos:Concept.\n\nHow this is implemented technically I'll leave to someone else, but I\nthink you have to be careful and not accept this paragraph literally (at\nleast if you accept our definition of node labels). As a node label is\nnot a label for a concept, there is no underlying concept to which\naltLabels can be applied.\n\nNode labels do not have BT, NT or RT relationships, except in the fudged\ncase I described above to make use of software without the required\nfunctionality. The BT/NT relationship in effect \"jumps over\" the node\nlabel, so that in the first example above the relationship is\n\npeople\nNT    children\n      teenagers\n      adults\n      builders\n\netc.,\n\nand _not_\n\npeople\nNT    <people by age>\n\netc.\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concepts : node label",
            "content": "Hi Leonard,\n\nThanks for this, yes I was intended the skos:Array construct to cover your\nscenario 1 only, i.e. an array of concepts ordered according to some\ncharacteristic of division. \n\nI think scenario 2 should be handled differently, though I'm not sure how\nyet.\n\nAl.\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Leonard Will\n> Sent: 06 May 2004 15:47\n> To: 'public-esw-thes@w3.org'\n> Subject: Supporting arrays of concepts : node labels\n> \n> \n> \n> In message\n> <B56ABE145BEB0C40A265238FCAA420DF01DC8E58@oa2-server.oa.oclc.org> on\n> Wed, 5 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n> >\n> >> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> >> Sent: Wednesday, May 05, 2004 2:21 PM\n> >> Subject: Supporting arrays of concepts\n> >>\n> >>\n> >> This is a strawman proposal for addition to the SKOS-Core schema:\n> >>\n> >> Some thesauri group concepts into ordered arrays, and label\n> >> the array, e.g.\n> >>\n> >>      People\n> >>                <people by age>\n> >>                Children (0-12 years)\n> >>                Teenagers (13-19 years)\n> >>                Adults (over 20 years)\n> >>\n> >> Since this sort of thing is common practise, and I believe \n>  will be a part of\n> >>the new British standard for thesauri  (Leonard, Stella?), \n> I thought we\n> >>ought to come up with a  mechanism for representing it as \n> part of the\n> >>SKOS-Core vocab.\n> \n> Yes, it is in the draft of the new standard. It would be good to have\n> software to handle it properly, as most existing packages are weak in\n> this area.\n> \n> >> The problem is the best way to represent an ordered list \n> in  RDF.  The\n> >>consensus so far seems to be for using RDF Lists  \n> (collections).  The\n> >>other problem is how to connect an array  to the parent \n> concept.  Such a\n> >>connection cannot replace the  skos:broader statements from \n> the array\n> >>members, and must be  synchronised with them.\n> \n> >This seems like what is called Node Labels and used by AAT and Dewey.\n> >Node Labels can be thought of as concepts that participate in the\n> >hierarchy structure but cannot be assigned as concepts.  In \n> Dewey, for\n> >example, it has the notion of centered entries.  If you look \n> at the printed\n> >edition these have a > (greater than sign) preceeding the \n> class span.  You\n> >cannot assign them as a class number but they are present for the\n> >purposes of grouping the hierarchy, as in your example.  Node Labels\n> >have all the same relationships as concepts do, so many \n> times they are\n> >represented as concepts.\n> \n> Unfortunately, the expression \"node label\" has been used to mean\n> different things in different places. They should not be thought of as\n> concepts, because they do not represent concepts, and they do not have\n> scope notes or  any of the normal thesaurus relationships. When using\n> software that does not make proper provision for node labels it is\n> sometime necessary to treat them as concepts and give them BT/NT\n> relationships in order to display them in the proper place in a\n> hierarchy, but this is a fudge.\n> \n> The AAT uses the expression \"guide terms\" rather than node labels, and\n> includes in this not only real node labels (as described at 1 \n> below) but\n> also terms which represent real concepts but which it thinks are\n> inappropriate for use as indexing terms. This is confusing and\n> misleading; I think that any term used to describe a concept should be\n> potentially usable in indexing, though it can have the note \n> \"use a more\n> specific concept if possible\".\n> \n> In the draft British Standard we propose that there should be \n> two kinds\n> of node label:\n> \n> 1. A node label showing a \"characteristic of division\". This \n> is the kind\n> shown in the example above, and each label contains the word \"by\"\n> followed by the characteristic by which the elements of the following\n> array are distinguished. There may be several arrays under any term,\n> each introduced by a separate node label, e.g.\n> \n>       people\n>           <people by age>\n>               children (0-12 years)\n>               teenagers (13-19 years)\n>               adults (over 20 years)\n> \n>           <people by occupation>\n>           builders\n>           bus drivers\n>           information technologists\n>           information scientists\n>           librarians\n> \n>           <people by sex>\n>           male people\n>               men\n>               boys\n>           female people\n>               women\n>               girls\n> \n> and so on.\n> \n> 2. In a display of a classification, rather than a thesaurus, node\n> labels are used to show where a change of facet occurs, \n> especially when\n> terms from different facets are being combined. They make it \n> clear that\n> the relationship between the terms preceding and following the node\n> label is not BT/NT, but that the following classes are a \n> compound of the\n> subsequent concepts with the preceding concept. In the following\n> example, the node labels containing the names of facets are given in\n> parentheses:\n> \n> (organisms)\n> mammals [in general]\n>       carnivores [in general]\n>           leopards\n>           lions\n>           tigers\n>       herbivores [in general]\n>           cattle\n>           sheep\n> (processes)\n>       physiological processes [in general]\n>           digestion [in general]\n>               (organisms)\n>               [digestion in] carnivores\n>                   [digestion in] lions\n>               [digestion in] herbivores\n>                   [digestion in] cattle\n>                   [digestion in] sheep\n>           respiration [in general]\n>               (organisms)\n>               [respiration in] lions\n> \n> The words in square brackets in this example are often omitted in\n> classification schedules, being implied by the indentation or\n> typography.\n> \n> I take it that at the moment you are just addressing the issue of node\n> labels of type 1.\n> \n> >SKOS currently doesn't take Node Label's into account with \n> it's prefLabel\n> >and altLabel elements.  It is possible that a Node Label \n> could have many\n> >different altLabel's.  I don't think that you need to add \n> additional structure\n> >to represent Node Labels.  Perhaps, what is needed is to say that a\n> >concept must have either a group of prefLabel elements \n> (xml:lang'ed) or a\n> >group of nodeLabel elements (xml:lang'ed) and can have any number of\n> >altLabel elements.  Since Node Labels will also have BT, NT, RT\n> >relationships, you will not need to duplicate that structure \n> by reusing\n> >skos:Concept.\n> \n> How this is implemented technically I'll leave to someone else, but I\n> think you have to be careful and not accept this paragraph \n> literally (at\n> least if you accept our definition of node labels). As a node label is\n> not a label for a concept, there is no underlying concept to which\n> altLabels can be applied.\n> \n> Node labels do not have BT, NT or RT relationships, except in \n> the fudged\n> case I described above to make use of software without the required\n> functionality. The BT/NT relationship in effect \"jumps over\" the node\n> label, so that in the first example above the relationship is\n> \n> people\n> NT    children\n>       teenagers\n>       adults\n>       builders\n> \n> etc.,\n> \n> and _not_\n> \n> people\n> NT    <people by age>\n> \n> etc.\n> \n> Leonard\n> -- \n> Willpower Information       (Partners: Dr Leonard D Will, \n> Sheena E Will)\n> Information Management Consultants              Tel: +44 \n> (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 \n> (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               \n> Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n> \n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "Miles, AJ (Alistair)  writes:\n\n> \n> This is a strawman proposal for addition to the SKOS-Core schema:\n[...] \n> Comments on any aspect of this suggestion?\n\nLooks good to me.\n\nRather than use skos:arrayParent, I might have used a relation in the\nopposite direction:\n\n    c:D a skos:Concept\n      ; skos:prefLabel \"People\"\n      ; skos:subArray [\n          a skos:Array\n          ; rdfs:label \"People by age\"\n          ; skos:arrayListMembers ( c:A c:B c:C )\n        ]\n      ; skos:narrower c:A, c:B, c:C\n      .\n    \nThat's purely a matter of taste, though. I like it because all the\narrows go the same way in the diagram:\n\n  c:D -skos:subArray-> [] -skos:arrayListMembers-> [] -rdf:first-> c:A\n\n(Less importantly, \"narrowerArray\" or just \"array\" might be better than\n\"subArray\", and \"members\" might suffice for \"arrayListMembers\")\n\n\nAs far as semantics go, we can just declare that skos:subArray implies\nthe appropriate skos:narrower/skos:broader relations. There's no\nwidely-practiced machine-readable way to declare this in the schema, but\nit's easy enough to put something like this in the specification:\n\n  forall C1, C2.\n    (exists A, L. skos:subArray(C,A) and\n                  skos:arrayListMembers(A,L) and\n                  member(L,C2))\n    => skos:narrower(C1,C2)\n\n  forall L, I. rdf:first(L,I) => member(L,I)\n  forall L, L2, I. (rdf:rest(L,L2) and member(L2,I)) => member(L,I)\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concepts : node label",
            "content": "Firstly, a note of support for Leonard's very thorough explanation of\nnode labels.\n\nSecondly, re the alternative representations proposed by Alistair and\nDavid Menendez, I'm not quite sure what will work best. I like the way\nthe array relationships are \"semi-detached\" from the relationships\nbetween concepts, and I'm glad to see a proposal that allows systematic\nrather than alphabetical sequence. To decide which representation is\nbest, perhaps we should consider how the node labels and arrays will be\nused, and what functions need to be supported. I don't see much use for\nthem in the direct process of information retrieval, but they are useful\nduring thesaurus browse, when they should facilitate displays of\nportions of a thesaurus. A meaningful grouping of terms helps people\nchoose the right term, either while indexing or while searching. They\nare also useful during the process of building a thesaurus.\n\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Miles, AJ\n(Alistair) \nSent: 06 May 2004 16:18\nTo: 'Leonard Will'; 'public-esw-thes@w3.org'\nSubject: RE: Supporting arrays of concepts : node labels\n\n\n\nHi Leonard,\n\nThanks for this, yes I was intended the skos:Array construct to cover\nyour scenario 1 only, i.e. an array of concepts ordered according to\nsome characteristic of division. \n\nI think scenario 2 should be handled differently, though I'm not sure\nhow yet.\n\nAl.\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org \n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Leonard Will\n> Sent: 06 May 2004 15:47\n> To: 'public-esw-thes@w3.org'\n> Subject: Supporting arrays of concepts : node labels\n> \n> \n> \n> In message \n> <B56ABE145BEB0C40A265238FCAA420DF01DC8E58@oa2-server.oa.oclc.org> on \n> Wed, 5 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n> >\n> >> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> >> Sent: Wednesday, May 05, 2004 2:21 PM\n> >> Subject: Supporting arrays of concepts\n> >>\n> >>\n> >> This is a strawman proposal for addition to the SKOS-Core schema:\n> >>\n> >> Some thesauri group concepts into ordered arrays, and label the \n> >> array, e.g.\n> >>\n> >>      People\n> >>                <people by age>\n> >>                Children (0-12 years)\n> >>                Teenagers (13-19 years)\n> >>                Adults (over 20 years)\n> >>\n> >> Since this sort of thing is common practise, and I believe\n>  will be a part of\n> >>the new British standard for thesauri  (Leonard, Stella?),\n> I thought we\n> >>ought to come up with a  mechanism for representing it as\n> part of the\n> >>SKOS-Core vocab.\n> \n> Yes, it is in the draft of the new standard. It would be good to have \n> software to handle it properly, as most existing packages are weak in \n> this area.\n> \n> >> The problem is the best way to represent an ordered list\n> in  RDF.  The\n> >>consensus so far seems to be for using RDF Lists\n> (collections).  The\n> >>other problem is how to connect an array  to the parent\n> concept.  Such a\n> >>connection cannot replace the  skos:broader statements from\n> the array\n> >>members, and must be  synchronised with them.\n> \n> >This seems like what is called Node Labels and used by AAT and Dewey.\n\n> >Node Labels can be thought of as concepts that participate in the \n> >hierarchy structure but cannot be assigned as concepts.  In\n> Dewey, for\n> >example, it has the notion of centered entries.  If you look\n> at the printed\n> >edition these have a > (greater than sign) preceeding the\n> class span.  You\n> >cannot assign them as a class number but they are present for the \n> >purposes of grouping the hierarchy, as in your example.  Node Labels \n> >have all the same relationships as concepts do, so many\n> times they are\n> >represented as concepts.\n> \n> Unfortunately, the expression \"node label\" has been used to mean \n> different things in different places. They should not be thought of as\n\n> concepts, because they do not represent concepts, and they do not have\n\n> scope notes or  any of the normal thesaurus relationships. When using \n> software that does not make proper provision for node labels it is \n> sometime necessary to treat them as concepts and give them BT/NT \n> relationships in order to display them in the proper place in a \n> hierarchy, but this is a fudge.\n> \n> The AAT uses the expression \"guide terms\" rather than node labels, and\n\n> includes in this not only real node labels (as described at 1\n> below) but\n> also terms which represent real concepts but which it thinks are \n> inappropriate for use as indexing terms. This is confusing and \n> misleading; I think that any term used to describe a concept should be\n\n> potentially usable in indexing, though it can have the note \"use a \n> more specific concept if possible\".\n> \n> In the draft British Standard we propose that there should be\n> two kinds\n> of node label:\n> \n> 1. A node label showing a \"characteristic of division\". This\n> is the kind\n> shown in the example above, and each label contains the word \"by\"\n> followed by the characteristic by which the elements of the following\n> array are distinguished. There may be several arrays under any term,\n> each introduced by a separate node label, e.g.\n> \n>       people\n>           <people by age>\n>               children (0-12 years)\n>               teenagers (13-19 years)\n>               adults (over 20 years)\n> \n>           <people by occupation>\n>           builders\n>           bus drivers\n>           information technologists\n>           information scientists\n>           librarians\n> \n>           <people by sex>\n>           male people\n>               men\n>               boys\n>           female people\n>               women\n>               girls\n> \n> and so on.\n> \n> 2. In a display of a classification, rather than a thesaurus, node \n> labels are used to show where a change of facet occurs, especially \n> when terms from different facets are being combined. They make it\n> clear that\n> the relationship between the terms preceding and following the node\n> label is not BT/NT, but that the following classes are a \n> compound of the\n> subsequent concepts with the preceding concept. In the following\n> example, the node labels containing the names of facets are given in\n> parentheses:\n> \n> (organisms)\n> mammals [in general]\n>       carnivores [in general]\n>           leopards\n>           lions\n>           tigers\n>       herbivores [in general]\n>           cattle\n>           sheep\n> (processes)\n>       physiological processes [in general]\n>           digestion [in general]\n>               (organisms)\n>               [digestion in] carnivores\n>                   [digestion in] lions\n>               [digestion in] herbivores\n>                   [digestion in] cattle\n>                   [digestion in] sheep\n>           respiration [in general]\n>               (organisms)\n>               [respiration in] lions\n> \n> The words in square brackets in this example are often omitted in \n> classification schedules, being implied by the indentation or \n> typography.\n> \n> I take it that at the moment you are just addressing the issue of node\n\n> labels of type 1.\n> \n> >SKOS currently doesn't take Node Label's into account with\n> it's prefLabel\n> >and altLabel elements.  It is possible that a Node Label\n> could have many\n> >different altLabel's.  I don't think that you need to add\n> additional structure\n> >to represent Node Labels.  Perhaps, what is needed is to say that a \n> >concept must have either a group of prefLabel elements\n> (xml:lang'ed) or a\n> >group of nodeLabel elements (xml:lang'ed) and can have any number of \n> >altLabel elements.  Since Node Labels will also have BT, NT, RT \n> >relationships, you will not need to duplicate that structure\n> by reusing\n> >skos:Concept.\n> \n> How this is implemented technically I'll leave to someone else, but I \n> think you have to be careful and not accept this paragraph literally \n> (at least if you accept our definition of node labels). As a node \n> label is not a label for a concept, there is no underlying concept to \n> which altLabels can be applied.\n> \n> Node labels do not have BT, NT or RT relationships, except in\n> the fudged\n> case I described above to make use of software without the required\n> functionality. The BT/NT relationship in effect \"jumps over\" the node\n> label, so that in the first example above the relationship is\n> \n> people\n> NT    children\n>       teenagers\n>       adults\n>       builders\n> \n> etc.,\n> \n> and _not_\n> \n> people\n> NT    <people by age>\n> \n> etc.\n> \n> Leonard\n> -- \n> Willpower Information       (Partners: Dr Leonard D Will, \n> Sheena E Will)\n> Information Management Consultants              Tel: +44 \n> (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44\n> (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               \n> Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n> \n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": "I am delighted to see the last two postings from Taher and Barb getting\nback to the point.  That is the utility of a TLS standard.  If after all\nwe design something that is secure but does not meet customer\nrequirements -- and so is not widely adopted -- then why bother?\n\nMany (if not most) of the arguments against incorporating shared-secret\nauth in TLS (the transport vs app layer arguments) could apply equally\nto PK-based auth.\n\nMany of the obvious interoperability benefits of incorporating a\nstandard PK-based auth into TLS could equally apply to shared-secret\nauth.\n\nThe point here is not whether PK-based auth is more secure than\nshared-secret auth, or whether it provides non-repudiation, or ...\n\nThe relevant facts here are:\n- This working group is chartered to develop a transport layer security\nstandard.\n\n- Rough consensus has decreed that SSL3 is the best starting point.\n\n- Everyone recognizes the value of the robust key exchange, auth,\nintegrity and encryption capabilities that derive from PK technology.\n\n- Real consumers of products to be built according to the TLS standard\nhave stated that the infrastructure, key management and portability\nissues associated with PK technology are acceptable on the server side.\nBut they also have clearly stated their need to support millions of\nend-users who currently use passwords and are not ready to switch\nwholesale to private keys and certs.\n\n- Real customers want the benefits of a single standard for Transport\nlayer security but with their choice of auth technology.  In fact, they\nwill most likely have to support both shared-secret auth and PK-based\nauth in parallel for some time, probably a couple of years at least.\n\n- If the TLS standard were to support both auth mechanisms then it would\nbe possible to provide implementations which prevent applications from\nhaving to know or care what kind of credentials were used to\nauthenticate the end-user.  Applications could be written to a single\ninterface and could be upgraded just once to support legacy client auth\n(shared-secret) and still migrate to admittedly superior client auth\n(PK-based).\n\nWhy is there such resistance to this line of reasoning?  If rough\nconcensus holds that the TLS standard cannot support both shared-secret\nand PK-based auth, then fine, take them both out and put them both in\nthe application layer.  But give me one standard so that applications\ndevelopers, customers and end-users don't have to be hamstrung by the\ndifferences in authentication technology. \n\nDon Schmidt\nProgram Manager\nMicrosoft Corp\n\n>----------\n>From: Barb Fox\n>Sent: Wednesday, October 09, 1996 5:01 PM\n>To: Dan Simon; 'elgamal@netscape.com'\n>Cc: 'ietf-tls@w3.org'; 'treese@OpenMarket.com'; 'david.brownell@Eng.Sun.COM'\n>Subject: RE: Closing on shared-key authentication\n>\n>>Taher:\n>>\n>>I just have to jump in here to clarify a couple of things.  \n>>\n>>Yes, password authentication is a customer requirement.  Many companies tell\n>>us that they want a migration path from passwords to certificate-based\n>>systems within the TLS protocol standard.  This has been the sole reason we\n>>have been pushing so hard for password authentication...customer need.  The\n>>business side of this argument has already been comprehensively presented by\n>>John Macko (Compuserve) in an earlier posting (7/22) so I don't want to\n>>start\n>>that chain again here.  \n>>\n>>But Dan's comment about forward compatibilty in SSL has nothing to do with\n>>passwords per se.  Fact: there is no generic extensibility mechanism in SSL3\n>- and that's something we need to acknowledge and fix as soon as we can.\n>> The goal of this working group, after all, should be to create an\n>>architecturally-sound, extensible standard.  I admit that this will cause us\n>>all some pain as we find ourselves having to change our fielded\n>implementations to prepare for future advances in the protocol.  But if\n>>we bite the bullet and design the protocol correctly now, it shouldn't be\n>>such a big deal as we go incrementally forward.  \n>\n>>Barb\n>>\n>>----------\n>>From: elgamal@netscape.com[SMTP:elgamal@netscape.com]\n>>Sent: Wednesday, October 09, 1996 8:49 AM\n>>To: Dan Simon\n>>Cc: 'ietf-tls@w3.org'; 'treese@OpenMarket.com';\n>>'david.brownell@Eng.Sun.COM'\n>>Subject: Re: Closing on shared-key authentication\n>>\n>>Dan,\n>>\n>>You bring an interesting point. In the design of SSL3.0, we did not\n>>expect that the protocol would have to support weaker authentication\n>>techniques, actually going backwards if you think about it. The idea of\n>>SSL3.0 was not to support everything that may exist or everything anyone\n>>can think of. So, you cannot really accuse SSL of not being forward\n>>compatible because it assumes a good authentication method rather than\n>>duplicate old ones that everyone has already implemented in any\n>>interesting application protocol. The only reason for me to entertain\n>>this password thing is that a customer thinks it is useful, not really\n>>because it adds anything to the protocol, on the contrary, it makes it\n>>less attractive since the level of authentication is not defined. \n>>\n>>Taher\n>>\n>>\n>>Dan Simon wrote:\n>>> \n>>> >From:  david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n>>> >\n>>> >I'll have to go back and look at the comments from last\n>>> >week's proposal (ssl-talk is where I saw most of it),\n>>> >but this proposal really doesn't seem \"cooked\" to me.\n>>> >\n>>> >   - Internationalization issues arise.  In what character\n>>> >     set do \"display_string\" and \"challenge\" appear?  How\n>>> >     is the language which the end user knows specified?\n>>> >\n>>> >     I don't like seeing application layer issues intrude\n>>> >     on transport layer protocols.\n>>> \n>>> The \"display_string\" field is opaque; that is, TLS simply transports it\n>>> without examining its content.  It is entirely the next level's\n>>> responsibility to figure out what to do with it (or even if it should be\n>>> sent in the first place).  Why is this an \"intrusion\" into the transport\n>>> layer, any more than, say, the presence of the opaque application data\n>>> which is passed through TLS as part of its basic function?\n>>> >\n>>> >   - Neither \"rough consensus\" nor (multiple instances of)\n>>> >     \"working code\" exists, as has been pointed out.\n>>> >\n>>> >     Many of us don't see a technical benefit to making TLS\n>>> >     be incompatible with SSLv3 in this respect, so I doubt\n>>> >     that a realistic \"consensus\" on this point can exist.\n>>> \n>>> Well, the real problem is that virtually *any* difference between TLS\n>>> and SSL 3.0 would make TLS incompatible with SSL 3.0, because SSL 3.0\n>>> simply lacks a mechanism for forward compatibility.  If we do nothing\n>>> else, we absolutely *must* prevent this problem from grandfathering its\n>>> way into TLS.  (The fix that's been suggested as least painful to SSL\n>>> 3.0 implementers is to specify that unrecognized handshake message types\n>>> be ignored--hence our use of new handshake message types to implement\n>>> shared-key authentication.  If someone has a better way to permit\n>>> extensibility, then I'd be happy to hear about it.)\n>>> >\n>>> >   - It's unclear just where in the handshake these new\n>>> >     messages would go.  Or are they even part of the\n>>> >     regular handshake protocol?  Do they go after the\n>>> >     \"Finished\" messages are exchanged, are they an\n>>> >     independent handshake, or what?\n>>> \n>>> The posted document specifies where the extra messages should go.\n>>> >\n>>> >   - Given that the amount of keying material to be built\n>>> >     is derived from the negotiated cipher spec, what's\n>>> >     the change needed in the definition of a cipher spec?\n>>> >     It needs to know it must generate CipherSpec.hash_size\n>>> >     (times two?) bytes of keying data.\n>>> \n>>> In SSL 3.0 (and presumably TLS), the actual keying material is not\n>>> included in the cipher_spec, but rather as part of the general\n>>> connection state.  Implementations that don't support shared-key\n>>> authentication can, of course, ignore the extra keying material\n>>> altogether.\n>>> >\n>>> >   - There's a new requirement, to ignore unrecognized\n>>> >     handshake messages rather than treat them as errors.\n>>> >     I prefer protocols to be fully specfied.\n>>> \n>>> If it's preferable, the specification can certainly require that\n>>> implementations recognize the extra handshake messages.  Of course, the\n>>> real problem here is SSL 3.0's lack of an extensibility mechanism; see\n>>> my comments above.\n>>> >\n>>> >I could raise more questions, but the fact that there are\n>>> >this many (after this much discussion!) says to me that the\n>>> >proposal should not be deemed \"cooked\" enough to incorporate\n>>> >into an IETF standard.\n>>> \n>>> To my mind, the problems with the proposal, as enumerated by David, cast\n>>> a worse light on SSL 3.0 than on the proposal itself.\n>>> \n>>>                                 Daniel Simon\n>>>                                 Cryptographer, Microsoft Corp.\n>>>                                 dansimon@microsoft.com\n>>> \n>>> >\n>>> >\n>>> >\n>>\n>>-- \n>>Taher Elgamal    elgamal@netscape.com\n>>Chief Scientist, Netscape Communications\n>>(T) 415 937 2898, (F) 415 428 4054\n>>\n>>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concepts : node label",
            "content": "Let me apologize in advance for asking what might be a very naive question \nat this stage, but there is a tremendous amount of material to get through \nto try to get up to speed on current developments. Stella brings up an \nissue that I was just trying to get a grip on, namely, the sequence in the \ndifferent concepts presented as of the same property. Is there any implied \nsequence among, say, Narrower Terms for a given concept? If so, what is it \n(or who determines it) and where is it indicated?\n\nThanks very much.\n\nRon\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\nAt 13:43 9/05/2004, Stella Dextre Clarke wrote:\n\n>Firstly, a note of support for Leonard's very thorough explanation of\n>node labels.\n>\n>Secondly, re the alternative representations proposed by Alistair and\n>David Menendez, I'm not quite sure what will work best. I like the way\n>the array relationships are \"semi-detached\" from the relationships\n>between concepts, and I'm glad to see a proposal that allows systematic\n>rather than alphabetical sequence. To decide which representation is\n>best, perhaps we should consider how the node labels and arrays will be\n>used, and what functions need to be supported. I don't see much use for\n>them in the direct process of information retrieval, but they are useful\n>during thesaurus browse, when they should facilitate displays of\n>portions of a thesaurus. A meaningful grouping of terms helps people\n>choose the right term, either while indexing or while searching. They\n>are also useful during the process of building a thesaurus.\n>\n>Stella\n>\n>*****************************************************\n>Stella Dextre Clarke\n>Information Consultant\n>Luke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\n>Tel: 01235-833-298\n>Fax: 01235-863-298\n>SDClarke@LukeHouse.demon.co.uk\n>*****************************************************\n>\n>\n>\n>-----Original Message-----\n>From: public-esw-thes-request@w3.org\n>[mailto:public-esw-thes-request@w3.org] On Behalf Of Miles, AJ\n>(Alistair)\n>Sent: 06 May 2004 16:18\n>To: 'Leonard Will'; 'public-esw-thes@w3.org'\n>Subject: RE: Supporting arrays of concepts : node labels\n>\n>\n>\n>Hi Leonard,\n>\n>Thanks for this, yes I was intended the skos:Array construct to cover\n>your scenario 1 only, i.e. an array of concepts ordered according to\n>some characteristic of division.\n>\n>I think scenario 2 should be handled differently, though I'm not sure\n>how yet.\n>\n>Al.\n>\n> > -----Original Message-----\n> > From: public-esw-thes-request@w3.org\n> > [mailto:public-esw-thes-request@w3.org]On Behalf Of Leonard Will\n> > Sent: 06 May 2004 15:47\n> > To: 'public-esw-thes@w3.org'\n> > Subject: Supporting arrays of concepts : node labels\n> >\n> >\n> >\n> > In message\n> > <B56ABE145BEB0C40A265238FCAA420DF01DC8E58@oa2-server.oa.oclc.org> on\n> > Wed, 5 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n> > >\n> > >> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> > >> Sent: Wednesday, May 05, 2004 2:21 PM\n> > >> Subject: Supporting arrays of concepts\n> > >>\n> > >>\n> > >> This is a strawman proposal for addition to the SKOS-Core schema:\n> > >>\n> > >> Some thesauri group concepts into ordered arrays, and label the\n> > >> array, e.g.\n> > >>\n> > >>      People\n> > >>                <people by age>\n> > >>                Children (0-12 years)\n> > >>                Teenagers (13-19 years)\n> > >>                Adults (over 20 years)\n> > >>\n> > >> Since this sort of thing is common practise, and I believe\n> >  will be a part of\n> > >>the new British standard for thesauri  (Leonard, Stella?),\n> > I thought we\n> > >>ought to come up with a  mechanism for representing it as\n> > part of the\n> > >>SKOS-Core vocab.\n> >\n> > Yes, it is in the draft of the new standard. It would be good to have\n> > software to handle it properly, as most existing packages are weak in\n> > this area.\n> >\n> > >> The problem is the best way to represent an ordered list\n> > in  RDF.  The\n> > >>consensus so far seems to be for using RDF Lists\n> > (collections).  The\n> > >>other problem is how to connect an array  to the parent\n> > concept.  Such a\n> > >>connection cannot replace the  skos:broader statements from\n> > the array\n> > >>members, and must be  synchronised with them.\n> >\n> > >This seems like what is called Node Labels and used by AAT and Dewey.\n>\n> > >Node Labels can be thought of as concepts that participate in the\n> > >hierarchy structure but cannot be assigned as concepts.  In\n> > Dewey, for\n> > >example, it has the notion of centered entries.  If you look\n> > at the printed\n> > >edition these have a > (greater than sign) preceeding the\n> > class span.  You\n> > >cannot assign them as a class number but they are present for the\n> > >purposes of grouping the hierarchy, as in your example.  Node Labels\n> > >have all the same relationships as concepts do, so many\n> > times they are\n> > >represented as concepts.\n> >\n> > Unfortunately, the expression \"node label\" has been used to mean\n> > different things in different places. They should not be thought of as\n>\n> > concepts, because they do not represent concepts, and they do not have\n>\n> > scope notes or  any of the normal thesaurus relationships. When using\n> > software that does not make proper provision for node labels it is\n> > sometime necessary to treat them as concepts and give them BT/NT\n> > relationships in order to display them in the proper place in a\n> > hierarchy, but this is a fudge.\n> >\n> > The AAT uses the expression \"guide terms\" rather than node labels, and\n>\n> > includes in this not only real node labels (as described at 1\n> > below) but\n> > also terms which represent real concepts but which it thinks are\n> > inappropriate for use as indexing terms. This is confusing and\n> > misleading; I think that any term used to describe a concept should be\n>\n> > potentially usable in indexing, though it can have the note \"use a\n> > more specific concept if possible\".\n> >\n> > In the draft British Standard we propose that there should be\n> > two kinds\n> > of node label:\n> >\n> > 1. A node label showing a \"characteristic of division\". This\n> > is the kind\n> > shown in the example above, and each label contains the word \"by\"\n> > followed by the characteristic by which the elements of the following\n> > array are distinguished. There may be several arrays under any term,\n> > each introduced by a separate node label, e.g.\n> >\n> >       people\n> >           <people by age>\n> >               children (0-12 years)\n> >               teenagers (13-19 years)\n> >               adults (over 20 years)\n> >\n> >           <people by occupation>\n> >           builders\n> >           bus drivers\n> >           information technologists\n> >           information scientists\n> >           librarians\n> >\n> >           <people by sex>\n> >           male people\n> >               men\n> >               boys\n> >           female people\n> >               women\n> >               girls\n> >\n> > and so on.\n> >\n> > 2. In a display of a classification, rather than a thesaurus, node\n> > labels are used to show where a change of facet occurs, especially\n> > when terms from different facets are being combined. They make it\n> > clear that\n> > the relationship between the terms preceding and following the node\n> > label is not BT/NT, but that the following classes are a\n> > compound of the\n> > subsequent concepts with the preceding concept. In the following\n> > example, the node labels containing the names of facets are given in\n> > parentheses:\n> >\n> > (organisms)\n> > mammals [in general]\n> >       carnivores [in general]\n> >           leopards\n> >           lions\n> >           tigers\n> >       herbivores [in general]\n> >           cattle\n> >           sheep\n> > (processes)\n> >       physiological processes [in general]\n> >           digestion [in general]\n> >               (organisms)\n> >               [digestion in] carnivores\n> >                   [digestion in] lions\n> >               [digestion in] herbivores\n> >                   [digestion in] cattle\n> >                   [digestion in] sheep\n> >           respiration [in general]\n> >               (organisms)\n> >               [respiration in] lions\n> >\n> > The words in square brackets in this example are often omitted in\n> > classification schedules, being implied by the indentation or\n> > typography.\n> >\n> > I take it that at the moment you are just addressing the issue of node\n>\n> > labels of type 1.\n> >\n> > >SKOS currently doesn't take Node Label's into account with\n> > it's prefLabel\n> > >and altLabel elements.  It is possible that a Node Label\n> > could have many\n> > >different altLabel's.  I don't think that you need to add\n> > additional structure\n> > >to represent Node Labels.  Perhaps, what is needed is to say that a\n> > >concept must have either a group of prefLabel elements\n> > (xml:lang'ed) or a\n> > >group of nodeLabel elements (xml:lang'ed) and can have any number of\n> > >altLabel elements.  Since Node Labels will also have BT, NT, RT\n> > >relationships, you will not need to duplicate that structure\n> > by reusing\n> > >skos:Concept.\n> >\n> > How this is implemented technically I'll leave to someone else, but I\n> > think you have to be careful and not accept this paragraph literally\n> > (at least if you accept our definition of node labels). As a node\n> > label is not a label for a concept, there is no underlying concept to\n> > which altLabels can be applied.\n> >\n> > Node labels do not have BT, NT or RT relationships, except in\n> > the fudged\n> > case I described above to make use of software without the required\n> > functionality. The BT/NT relationship in effect \"jumps over\" the node\n> > label, so that in the first example above the relationship is\n> >\n> > people\n> > NT    children\n> >       teenagers\n> >       adults\n> >       builders\n> >\n> > etc.,\n> >\n> > and _not_\n> >\n> > people\n> > NT    <people by age>\n> >\n> > etc.\n> >\n> > Leonard\n> > --\n> > Willpower Information       (Partners: Dr Leonard D Will,\n> > Sheena E Will)\n> > Information Management Consultants              Tel: +44\n> > (0)20 8372 0092\n> > 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44\n> > (0)870 051 7276\n> > L.Will@Willpowerinfo.co.uk\n> > Sheena.Will@Willpowerinfo.co.uk\n> > ---------------- <URL:http://www.willpowerinfo.co.uk/>\n> > -----------------\n> >\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "Just another little wrinkle you might want to take into account. A node \nlabel can in fact have as a subordinate in the classified structure another \nnode label.\n\nFor example the AAT [1] has:\n\nfurnishings\n      <furnishings by form and function>\n           <coverings and hangings>\n                <coverings and hangings by general type>\n                     coverings\n                     hangings\n\nwhere the values between angle brackets are node labels.\n\nRon\n\n[1] Art and Architecture Thesaurus \nhttp://www.getty.edu/research/conducting_research/vocabularies/aat/\n\nAt 23:28 6/05/2004, David Menendez wrote:\n\n>Miles, AJ (Alistair)  writes:\n>\n> >\n> > This is a strawman proposal for addition to the SKOS-Core schema:\n>[...]\n> > Comments on any aspect of this suggestion?\n>\n>Looks good to me.\n>\n>Rather than use skos:arrayParent, I might have used a relation in the\n>opposite direction:\n>\n>     c:D a skos:Concept\n>       ; skos:prefLabel \"People\"\n>       ; skos:subArray [\n>           a skos:Array\n>           ; rdfs:label \"People by age\"\n>           ; skos:arrayListMembers ( c:A c:B c:C )\n>         ]\n>       ; skos:narrower c:A, c:B, c:C\n>       .\n>\n>That's purely a matter of taste, though. I like it because all the\n>arrows go the same way in the diagram:\n>\n>   c:D -skos:subArray-> [] -skos:arrayListMembers-> [] -rdf:first-> c:A\n>\n>(Less importantly, \"narrowerArray\" or just \"array\" might be better than\n>\"subArray\", and \"members\" might suffice for \"arrayListMembers\")\n>\n>\n>As far as semantics go, we can just declare that skos:subArray implies\n>the appropriate skos:narrower/skos:broader relations. There's no\n>widely-practiced machine-readable way to declare this in the schema, but\n>it's easy enough to put something like this in the specification:\n>\n>   forall C1, C2.\n>     (exists A, L. skos:subArray(C,A) and\n>                   skos:arrayListMembers(A,L) and\n>                   member(L,C2))\n>     => skos:narrower(C1,C2)\n>\n>   forall L, I. rdf:first(L,I) => member(L,I)\n>   forall L, L2, I. (rdf:rest(L,L2) and member(L2,I)) => member(L,I)\n>--\n>David Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concepts : node label",
            "content": "Ron,\nNot sure I understand this question. Is it about the sequence among\nsibling narrower terms? If so, then very often the sequence does not\nmatter and alphabetical order is the most convenient. But sometimes\nthere is a natural order, such as the order of size, or of age, or of\nlocation. Presentation in the natural order helps people to understand\nthe underlying concepts better, detect omissions, overlaps etc. The\nperson who determines this is the thesaurus editor. The presentation\nbecomes even more helpful if node labels are inserted as in Leonard's\nexample. (In this example, notice that he found a natural order in some\nof the groups but not others.)\n \nI hope I've been answering the right question?\nStella\n \n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Ron Davies\nSent: 09 May 2004 13:26\nTo: public-esw-thes@w3.org\nSubject: RE: Supporting arrays of concepts : node labels\n\n\nLet me apologize in advance for asking what might be a very naive\nquestion at this stage, but there is a tremendous amount of material to\nget through to try to get up to speed on current developments. Stella\nbrings up an issue that I was just trying to get a grip on, namely, the\nsequence in the different concepts presented as of the same property. Is\nthere any implied sequence among, say, Narrower Terms for a given\nconcept? If so, what is it (or who determines it) and where is it\nindicated?\n\nThanks very much.\n\nRon\n\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium       \nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\nAt 13:43 9/05/2004, Stella Dextre Clarke wrote:\n\n\n\n\nFirstly, a note of support for Leonard's very thorough explanation of\nnode labels.\n\nSecondly, re the alternative representations proposed by Alistair and\nDavid Menendez, I'm not quite sure what will work best. I like the way\nthe array relationships are \"semi-detached\" from the relationships\nbetween concepts, and I'm glad to see a proposal that allows systematic\nrather than alphabetical sequence. To decide which representation is\nbest, perhaps we should consider how the node labels and arrays will be\nused, and what functions need to be supported. I don't see much use for\nthem in the direct process of information retrieval, but they are useful\nduring thesaurus browse, when they should facilitate displays of\nportions of a thesaurus. A meaningful grouping of terms helps people\nchoose the right term, either while indexing or while searching. They\nare also useful during the process of building a thesaurus.\n\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Miles, AJ\n(Alistair) \nSent: 06 May 2004 16:18\nTo: 'Leonard Will'; 'public-esw-thes@w3.org'\nSubject: RE: Supporting arrays of concepts : node labels\n\n\n\nHi Leonard,\n\nThanks for this, yes I was intended the skos:Array construct to cover\nyour scenario 1 only, i.e. an array of concepts ordered according to\nsome characteristic of division. \n\nI think scenario 2 should be handled differently, though I'm not sure\nhow yet.\n\nAl.\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org \n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Leonard Will\n> Sent: 06 May 2004 15:47\n> To: 'public-esw-thes@w3.org'\n> Subject: Supporting arrays of concepts : node labels\n> \n> \n> \n> In message \n> <B56ABE145BEB0C40A265238FCAA420DF01DC8E58@oa2-server.oa.oclc.org> on \n> Wed, 5 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n> >\n> >> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> >> Sent: Wednesday, May 05, 2004 2:21 PM\n> >> Subject: Supporting arrays of concepts\n> >>\n> >>\n> >> This is a strawman proposal for addition to the SKOS-Core schema:\n> >>\n> >> Some thesauri group concepts into ordered arrays, and label the \n> >> array, e.g.\n> >>\n> >>      People\n> >>                <people by age>\n> >>                Children (0-12 years)\n> >>                Teenagers (13-19 years)\n> >>                Adults (over 20 years)\n> >>\n> >> Since this sort of thing is common practise, and I believe\n>  will be a part of\n> >>the new British standard for thesauri  (Leonard, Stella?),\n> I thought we\n> >>ought to come up with a  mechanism for representing it as\n> part of the\n> >>SKOS-Core vocab.\n> \n> Yes, it is in the draft of the new standard. It would be good to have \n> software to handle it properly, as most existing packages are weak in \n> this area.\n> \n> >> The problem is the best way to represent an ordered list\n> in  RDF.  The\n> >>consensus so far seems to be for using RDF Lists\n> (collections).  The\n> >>other problem is how to connect an array  to the parent\n> concept.  Such a\n> >>connection cannot replace the  skos:broader statements from\n> the array\n> >>members, and must be  synchronised with them.\n> \n> >This seems like what is called Node Labels and used by AAT and Dewey.\n\n> >Node Labels can be thought of as concepts that participate in the \n> >hierarchy structure but cannot be assigned as concepts.  In\n> Dewey, for\n> >example, it has the notion of centered entries.  If you look\n> at the printed\n> >edition these have a > (greater than sign) preceeding the\n> class span.  You\n> >cannot assign them as a class number but they are present for the \n> >purposes of grouping the hierarchy, as in your example.  Node Labels \n> >have all the same relationships as concepts do, so many\n> times they are\n> >represented as concepts.\n> \n> Unfortunately, the expression \"node label\" has been used to mean \n> different things in different places. They should not be thought of as\n\n> concepts, because they do not represent concepts, and they do not have\n\n> scope notes or  any of the normal thesaurus relationships. When using \n> software that does not make proper provision for node labels it is \n> sometime necessary to treat them as concepts and give them BT/NT \n> relationships in order to display them in the proper place in a \n> hierarchy, but this is a fudge.\n> \n> The AAT uses the expression \"guide terms\" rather than node labels, and\n\n> includes in this not only real node labels (as described at 1\n> below) but\n> also terms which represent real concepts but which it thinks are \n> inappropriate for use as indexing terms. This is confusing and \n> misleading; I think that any term used to describe a concept should be\n\n> potentially usable in indexing, though it can have the note \"use a \n> more specific concept if possible\".\n> \n> In the draft British Standard we propose that there should be\n> two kinds\n> of node label:\n> \n> 1. A node label showing a \"characteristic of division\". This\n> is the kind\n> shown in the example above, and each label contains the word \"by\"\n> followed by the characteristic by which the elements of the following\n> array are distinguished. There may be several arrays under any term,\n> each introduced by a separate node label, e.g.\n> \n>       people\n>           <people by age>\n>               children (0-12 years)\n>               teenagers (13-19 years)\n>               adults (over 20 years)\n> \n>           <people by occupation>\n>           builders\n>           bus drivers\n>           information technologists\n>           information scientists\n>           librarians\n> \n>           <people by sex>\n>           male people\n>               men\n>               boys\n>           female people\n>               women\n>               girls\n> \n> and so on.\n> \n> 2. In a display of a classification, rather than a thesaurus, node \n> labels are used to show where a change of facet occurs, especially \n> when terms from different facets are being combined. They make it\n> clear that\n> the relationship between the terms preceding and following the node\n> label is not BT/NT, but that the following classes are a \n> compound of the\n> subsequent concepts with the preceding concept. In the following\n> example, the node labels containing the names of facets are given in\n> parentheses:\n> \n> (organisms)\n> mammals [in general]\n>       carnivores [in general]\n>           leopards\n>           lions\n>           tigers\n>       herbivores [in general]\n>           cattle\n>           sheep\n> (processes)\n>       physiological processes [in general]\n>           digestion [in general]\n>               (organisms)\n>               [digestion in] carnivores\n>                   [digestion in] lions\n>               [digestion in] herbivores\n>                   [digestion in] cattle\n>                   [digestion in] sheep\n>           respiration [in general]\n>               (organisms)\n>               [respiration in] lions\n> \n> The words in square brackets in this example are often omitted in \n> classification schedules, being implied by the indentation or \n> typography.\n> \n> I take it that at the moment you are just addressing the issue of node\n\n> labels of type 1.\n> \n> >SKOS currently doesn't take Node Label's into account with\n> it's prefLabel\n> >and altLabel elements.  It is possible that a Node Label\n> could have many\n> >different altLabel's.  I don't think that you need to add\n> additional structure\n> >to represent Node Labels.  Perhaps, what is needed is to say that a \n> >concept must have either a group of prefLabel elements\n> (xml:lang'ed) or a\n> >group of nodeLabel elements (xml:lang'ed) and can have any number of \n> >altLabel elements.  Since Node Labels will also have BT, NT, RT \n> >relationships, you will not need to duplicate that structure\n> by reusing\n> >skos:Concept.\n> \n> How this is implemented technically I'll leave to someone else, but I \n> think you have to be careful and not accept this paragraph literally \n> (at least if you accept our definition of node labels). As a node \n> label is not a label for a concept, there is no underlying concept to \n> which altLabels can be applied.\n> \n> Node labels do not have BT, NT or RT relationships, except in\n> the fudged\n> case I described above to make use of software without the required\n> functionality. The BT/NT relationship in effect \"jumps over\" the node\n> label, so that in the first example above the relationship is\n> \n> people\n> NT    children\n>       teenagers\n>       adults\n>       builders\n> \n> etc.,\n> \n> and _not_\n> \n> people\n> NT    <people by age>\n> \n> etc.\n> \n> Leonard\n> -- \n> Willpower Information       (Partners: Dr Leonard D Will, \n> Sheena E Will)\n> Information Management Consultants              Tel: +44 \n> (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44\n> (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               \n> Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n> \n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium       \nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n                                                \n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "Ron Davies writes:\n\n> Just another little wrinkle you might want to take into account. A\n> node label can in fact have as a subordinate in the classified\n> structure another node label.\n> \n> For example the AAT [1] has:\n> \n> furnishings\n>       <furnishings by form and function>\n>            <coverings and hangings>\n>                 <coverings and hangings by general type>\n>                      coverings\n>                      hangings\n> \n> where the values between angle brackets are node labels.\n\nWell, we could represent that along these lines.\n\n    thes:001 a skos:Concept\n      ; skos:prefLabel \"furnishings\"\n      ; skos:subArray\n        [ a skos:Array\n        ; rdfs:label \"furnishings by form and function\"\n        ; skos:members (\n            [ a skos:Array\n            ; rdfs:label \"coverings and hangings\"\n            ; skos:members (\n                [ a skos:Array\n                ; rdfs:label \"coverings and hangings by general type\"\n                ; skos:members ( thes:002 thes:003 )\n                ]\n              )\n            ]\n          )\n        ]\n      .\n    \n    thes:002 skos:prefLabel \"hangings\".\n    thes:003 skos:prefLabel \"coverings\".\n\n(If you prefer Alistair's style to mine, we just need to replace\n(X,skos:subArray,Y) with (Y,skos:parent,X). All that's really different\nare the direction and label of the arrows.)\n\n\nThe axioms I gave earlier also need some adjustment:\n\n    (C1, skos:narrower, C2) <= (C1, skos:subArray, A) and\n                               arrayElt(A,C2) and\n                               (C2, rdf:type, skos:Concept)\n\n    arrayElt(A,E) <= (A, skos:members, L) and member(L,E)\n    arrayElt(A,E) <= arrayElt(A,A2) and arrayElt(A2,E)\n    \n    member(L,I) <= (L, rdf:first, I)\n    member(L,I) <= (L, rdf:rest, L2) and member(L2,I)\n    \n    (The convention here is that (S,P,O) is an RDF triple and \n    P(...) is a logical predicate.)\n\nThis is possibly more flexible than needed, because it allows the same\nArray to contain Concepts and sub-Arrays.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concepts : node label",
            "content": "Ron Davies writes:\n\n> Let me apologize in advance for asking what might be a very naive\n> question at this stage, but there is a tremendous amount of material\n> to get through to try to get up to speed on current developments.\n> Stella brings up an issue that I was just trying to get a grip on,\n> namely, the sequence in the different concepts presented as of the\n> same property. Is there any implied sequence among, say, Narrower\n> Terms for a given concept? If so, what is it (or who determines it)\n> and where is it indicated?\n\nIn RDF, the values of a property (e.g., skos:narrower) for a given\nsubject form a set. So, there's no way (in RDF) to determine an\nintrinsic order of two concepts, given only that they are narrower than\nanother concept.\n\nThe lists used in the proposed skos:Array structure avoid this problem\nby introducing extra nodes.\n\nThis:\n\n    thes:001 a skos:Concept\n      ; skos:subArray\n        [ a skos:Array\n        ; skos:members ( thes:002 thes:003 )\n        ]\n      .\n\nIs actually short-hand for:\n\n    thes:001 rdf:type      skos:Concept.\n    thes:001 skos:subArray _:a.\n    _:a      rdf:type      skos:Array.\n    _:a      skos:members  _:b.\n    _:b      rdf:first     thes:002.\n    _:b      rdf:rest      _:c.\n    _:c      rdf:first     thes:003.\n    _:c      rdf:rest      rdf:nil.\n    \n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concepts : node label",
            "content": "Stella,\n\nYou've hit on exactly the issue that concerns me, which is how the network \nclient knows what to do with what it gets back from the server. The \nultimate aim, or user case if you prefer, is supporting a human-browsable \ndisplay, both for alphabetical and for hierarchical types of display such \nas the AAT examples Doug talks about in his JoDI paper.\n\nAs you say, sometimes the order will be alphabetical and sometimes it will \nnot. I think this mixture is even more frequent with taxonomies than with \nthesauri.\n\n1. If it's not alphabetical, but some logical sequence, the client will \nwant to respect the order in which the relations have been returned by the \nserver.\n\n2. If it's alphabetical, then of course we can ask \"Alphabetical according \nto which language\"? A series of relations sequenced by English labels will \nclearly not work if you want to display the French labels. That may not \nmatter that much, if the client accepts the job of re-sorting all the \nrelations by label for every language for every set of relations for every \nrecord that we want to display.\n\nBut the harder question is, How does the client know when the sequence is \nalphabetical (or is irrelevant) and when it's not (and is significant)?\n\nRon\n>Ron Davies\n>Information and documentation systems consultant\n>Av. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\n>Email:  ron@rondavies.be\n>Tel:    +32 (0)2 770 33 51\n>GSM:    +32 (0)484 502 393\n\nAt 19:15 9/05/2004, Stella Dextre Clarke wrote:\n>Ron,\n>Not sure I understand this question. Is it about the sequence among \n>sibling narrower terms? If so, then very often the sequence does not \n>matter and alphabetical order is the most convenient. But sometimes there \n>is a natural order, such as the order of size, or of age, or of location. \n>Presentation in the natural order helps people to understand the \n>underlying concepts better, detect omissions, overlaps etc. The person who \n>determines this is the thesaurus editor. The presentation becomes even \n>more helpful if node labels are inserted as in Leonard's example. (In this \n>example, notice that he found a natural order in some of the groups but \n>not others.)\n>\n>I hope I've been answering the right question?\n>Stella\n>\n>*****************************************************\n>Stella Dextre Clarke\n>Information Consultant\n>Luke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\n>Tel: 01235-833-298\n>Fax: 01235-863-298\n>SDClarke@LukeHouse.demon.co.uk\n>*****************************************************\n>\n>-----Original Message-----\n>From: public-esw-thes-request@w3.org \n>[mailto:public-esw-thes-request@w3.org] On Behalf Of Ron Davies\n>Sent: 09 May 2004 13:26\n>To: public-esw-thes@w3.org\n>Subject: RE: Supporting arrays of concepts : node labels\n>\n>Let me apologize in advance for asking what might be a very naive question \n>at this stage, but there is a tremendous amount of material to get through \n>to try to get up to speed on current developments. Stella brings up an \n>issue that I was just trying to get a grip on, namely, the sequence in the \n>different concepts presented as of the same property. Is there any implied \n>sequence among, say, Narrower Terms for a given concept? If so, what is it \n>(or who determines it) and where is it indicated?\n>\n>Thanks very much.\n>Ron\n>\n>Ron Davies\n>Information and documentation systems consultant\n>Av. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\n>Email:  ron@rondavies.be\n>Tel:    +32 (0)2 770 33 51\n>GSM:    +32 (0)484 502 393\n>\n>At 13:43 9/05/2004, Stella Dextre Clarke wrote:\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concepts : node label",
            "content": "Ron,\nYes, I see your point. The client computer has no way of knowing when\nthe sequence does or does not matter; therefore it would have to\nreproduce it faithfully in all cases; and  conversion to another\nlanguage would complicate the whole thing. Tempting to think that you\nmight respect the order (only) when node labels are present, but this\ndoes not work either. The pursuit of perfection is a complicated\nundertaking!\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: Ron Davies [mailto:ron@rondavies.be] \nSent: 10 May 2004 10:02\nTo: Stella Dextre Clarke; public-esw-thes@w3.org\nSubject: RE: Supporting arrays of concepts : node labels\n\n\nStella,\n\nYou've hit on exactly the issue that concerns me, which is how the\nnetwork client knows what to do with what it gets back from the server.\nThe ultimate aim, or user case if you prefer, is supporting a\nhuman-browsable display, both for alphabetical and for hierarchical\ntypes of display such as the AAT examples Doug talks about in his JoDI\npaper. \n\nAs you say, sometimes the order will be alphabetical and sometimes it\nwill not. I think this mixture is even more frequent with taxonomies\nthan with thesauri. \n\n1. If it's not alphabetical, but some logical sequence, the client will\nwant to respect the order in which the relations have been returned by\nthe server.\n\n2. If it's alphabetical, then of course we can ask \"Alphabetical\naccording to which language\"? A series of relations sequenced by English\nlabels will clearly not work if you want to display the French labels.\nThat may not matter that much, if the client accepts the job of\nre-sorting all the relations by label for every language for every set\nof relations for every record that we want to display.  \n\nBut the harder question is, How does the client know when the sequence\nis alphabetical (or is irrelevant) and when it's not (and is\nsignificant)?  \n\nRon \n\nRon Davies \n\nInformation and documentation systems consultant \n\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium        \n\nEmail:  ron@rondavies.be \n\nTel:    +32 (0)2 770 33 51 \n\nGSM:    +32 (0)484 502 393\n\n\nAt 19:15 9/05/2004, Stella Dextre Clarke wrote:\n\n\nRon,\nNot sure I understand this question. Is it about the sequence among\nsibling narrower terms? If so, then very often the sequence does not\nmatter and alphabetical order is the most convenient. But sometimes\nthere is a natural order, such as the order of size, or of age, or of\nlocation. Presentation in the natural order helps people to understand\nthe underlying concepts better, detect omissions, overlaps etc. The\nperson who determines this is the thesaurus editor. The presentation\nbecomes even more helpful if node labels are inserted as in Leonard's\nexample. (In this example, notice that he found a natural order in some\nof the groups but not others.)\n \nI hope I've been answering the right question?\nStella\n \n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message----- \n\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Ron Davies \n\nSent: 09 May 2004 13:26 \n\nTo: public-esw-thes@w3.org \n\nSubject: RE: Supporting arrays of concepts : node labels\n\n\n\nLet me apologize in advance for asking what might be a very naive\nquestion at this stage, but there is a tremendous amount of material to\nget through to try to get up to speed on current developments. Stella\nbrings up an issue that I was just trying to get a grip on, namely, the\nsequence in the different concepts presented as of the same property. Is\nthere any implied sequence among, say, Narrower Terms for a given\nconcept? If so, what is it (or who determines it) and where is it\nindicated?\n\n\n\nThanks very much.\n\n\nRon\n\n\n\nRon Davies \n\nInformation and documentation systems consultant \n\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium        \n\nEmail:  ron@rondavies.be \n\nTel:    +32 (0)2 770 33 51 \n\nGSM:    +32 (0)484 502 393\n\n\n\nAt 13:43 9/05/2004, Stella Dextre Clarke wrote: \n\n\n\n"
        },
        {
            "subject": "Article referenc",
            "content": "My apologies. It was just pointed out to me that I mentioned an article in \na recent message without including the reference. The article was:\n\nCeri Binding and Douglas Tudhope. \"KOS at your Service: Programmatic Access \nto Knowledge Organization Systems\". Journal of Digital Information Vol. 4 \nNo. 4 . Article 265, 2004-02-05. Available at:\nhttp://jodi.ecs.soton.ac.uk/Articles/v04/i04/Binding/\n\nRon\n\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "In message <6.0.0.22.2.20040509145330.01bdd1d0@pop.skynet.be> on Sun, 9 \nMay 2004, Ron Davies <ron@rondavies.be> wrote\n>Just another little wrinkle you might want to take into account. A node \n>label can in fact have as a subordinate in the classified structure \n>another node label.\n>\n>For example the AAT [1] has:\n>\n>furnishings\n>???? <furnishings by form and function>?\n>????????? <coverings and hangings>\n>?????????????? <coverings and hangings by general type>\n>??????????????????? coverings\n>??????????????????? hangings\n>\n>where the values between angle brackets are node labels.\n\nThe Getty does not call them \"node labels\" but \"guide terms\", which in \nmy opinion confuses node labels with other things.\n\nI maintain that <coverings and hangings> is not a node label, \nirrespective of the fact that it is printed in angle brackets. It does \nnot contain \"by\" followed by a characteristic of division, and in fact \nis just a label for a broader concept than \"coverings\" and \"hangings\" \nseparately. I would drop the angle brackets and treat it as a normal \nterm.\n\nThere may be cases where one node label occurs immediately under another \nwithout any intermediate named concept, but I cannot think of one.\nIf you can give me an example I'll think whether such a structure is \nunavoidable!\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "Leonard,\n\nI won't argue with you, except to say that whether these are \"node labels\" \nor \"guide terms\", we can't ignore them. These are not, in the Getty way of \nthinking, concepts, and they function, in terms of the hierarchy, in ways \nvery similar to node labels.\n\nThe question remains as to how this situation is to be described in RDF?\n\nIncidentally, I didn't go looking for this example, it popped up in a quick \nfive-minute browse, which suggests that there must be quite a few more in \nthe AAT (which I don't know at all).\n\nRon\n\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\n\nAt 17:21 10/05/2004, you wrote:\n\n>In message <6.0.0.22.2.20040509145330.01bdd1d0@pop.skynet.be> on Sun, 9 \n>May 2004, Ron Davies <ron@rondavies.be> wrote\n>>Just another little wrinkle you might want to take into account. A node \n>>label can in fact have as a subordinate in the classified structure \n>>another node label.\n>>\n>>For example the AAT [1] has:\n>>\n>>furnishings\n>>      <furnishings by form and function>\n>>           <coverings and hangings>\n>>                <coverings and hangings by general type>\n>>                     coverings\n>>                     hangings\n>>\n>>where the values between angle brackets are node labels.\n>\n>The Getty does not call them \"node labels\" but \"guide terms\", which in my \n>opinion confuses node labels with other things.\n>\n>I maintain that <coverings and hangings> is not a node label, irrespective \n>of the fact that it is printed in angle brackets. It does not contain \"by\" \n>followed by a characteristic of division, and in fact is just a label for \n>a broader concept than \"coverings\" and \"hangings\" separately. I would drop \n>the angle brackets and treat it as a normal term.\n>\n>There may be cases where one node label occurs immediately under another \n>without any intermediate named concept, but I cannot think of one.\n>If you can give me an example I'll think whether such a structure is \n>unavoidable!\n>\n>Leonard\n>\n>--\n>Willpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\n>Information Management Consultants              Tel: +44 (0)20 8372 0092\n>27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\n>L.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n>---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n>GSM:    +32 (0)484 502 393\n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "In message <6.0.0.22.2.20040510175606.01bf9ac8@pop.skynet.be> on Mon, 10\nMay 2004, Ron Davies <ron@rondavies.be> wrote\n>Leonard,\n>\n>I won't argue with you, except to say that whether these are \"node labels\"\n>or \"guide terms\", we can't ignore them. These are not, in the Getty way of\n>thinking, concepts, and they function, in terms of the hierarchy, in ways\n>very similar to node labels.\n\nRon -\n\nOnly in the respect that they are terms that Getty says should not be\nused for indexing. They do have BT/NT and RT relationships, which true\nnode labels do not. In the example you quoted,\n\n>>furnishings\n>>      <furnishings by form and function>\n>>           <coverings and hangings>\n>>                <coverings and hangings by general type>\n>>                     coverings\n>>                     hangings\n\n<furnishings by form and function> and <coverings and hangings by\ngeneral type> are of course proper node labels.\n\nFurther down the same hierarchy, there is a real example of the problem\nyou raise, with one node label immediately under another:\n\n<coverings and hangings by specific type>\n   <coverings and hangings by form>\n       blankets (coverings)\n       rugs\n       throws (coverings)\n   <coverings and hangings by function>\n      dust covers\n      shrouds\n      sleeping bags\n\n(I have omitted some entries which obscure the issue).\n\nIn this case I think that the node label <coverings and hangings by\nspecific type> is redundant and could be omitted.\n\n>The question remains as to how this situation is to be described in RDF?\n\nIf you want to encode AAT as it stands, then yes, you have to find a\nstructure to cope with this.\n\nShould we, though, be creating a structure that allows encoding of\ninconsistent and illogical structures just because they occur in some\nexisting thesauri? Library of Congress Subject Headings has some\nthesaural elements, but nobody would argue that it conforms to thesaurus\nstandards. Should we be able to encode it in RDF?\n\nIs it unrealistically idealistic to develop an encoding system based on\nstandards, or unrealistically complex to develop a system that takes\naccount of all the idiosyncrasies that may be found in existing\nthesauri?\n(I don't know the answer - no doubt we have to find a compromise!)\n\n>Incidentally, I didn't go looking for this example, it popped up in a quick\n>five-minute browse, which suggests that there must be quite a few more in\n>the AAT (which I don't know at all).\n\nYes, there are lots. I suggest that we should encode elements of this\nthesaurus according to what they are, rather than what the publishers\nsay they are, i.e.\n\n*       Treat real node labels of the form <xxx by yyy> as node labels,\n        and allow for one of them occurring directly under another.\n\n*       Treat other terms in angle brackets as thesaurus terms, but add\n        a note \"Do not use for indexing\". We have in any case to allow\n        for editorial and usage notes of this kind as well as for scope\n        notes.\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concept",
            "content": " \n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk] \n> Sent: Monday, May 10, 2004 2:37 PM\n> Subject: Re: Supporting arrays of concepts\n> \n> Should we, though, be creating a structure that allows \n> encoding of inconsistent and illogical structures just \n> because they occur in some existing thesauri? Library of \n> Congress Subject Headings has some thesaural elements, but \n> nobody would argue that it conforms to thesaurus standards. \n> Should we be able to encode it in RDF?\n\nWe are trying to encode AAT, LCSH, MeSH and DDC in SKOS.\nSo my answer to these questions is that SKOS needs to\nfind a way to handle these things.  There are a wealth\nof widely used vocabularies today and to create a new\nSemantic Web data format that cannot take advantage of\nthese vocabularies seems, to me, to be problematic.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concept",
            "content": "I agree with Andy's response. We have to be able to support ways of\nworking with the commonly used vocabularies. However, DDC and LCSH are\nnot thesauri. There are some fundamental differences in the assumptions\nhumans make when applying these things. It seems to me that SKOS was\ndeveloped with standard thesauri in mind, and may need some add-ons to\nwork across different types of vocabulary.\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Houghton,Andrew\nSent: 10 May 2004 21:13\nTo: public-esw-thes@w3.org\nSubject: RE: Supporting arrays of concepts\n\n\n\n \n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Monday, May 10, 2004 2:37 PM\n> Subject: Re: Supporting arrays of concepts\n> \n> Should we, though, be creating a structure that allows\n> encoding of inconsistent and illogical structures just \n> because they occur in some existing thesauri? Library of \n> Congress Subject Headings has some thesaural elements, but \n> nobody would argue that it conforms to thesaurus standards. \n> Should we be able to encode it in RDF?\n\nWe are trying to encode AAT, LCSH, MeSH and DDC in SKOS.\nSo my answer to these questions is that SKOS needs to\nfind a way to handle these things.  There are a wealth\nof widely used vocabularies today and to create a new\nSemantic Web data format that cannot take advantage of\nthese vocabularies seems, to me, to be problematic.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "In message <000001c4372c$ab140080$0402a8c0@DELL> on Tue, 11 May 2004, \nStella Dextre Clarke <sdclarke@lukehouse.demon.co.uk> wrote\n>\n>I agree with Andy's response. We have to be able to support ways of \n>working with the commonly used vocabularies. However, DDC and LCSH are \n>not thesauri. There are some fundamental differences in the assumptions \n>humans make when applying these things. It seems to me that SKOS was \n>developed with standard thesauri in mind, and may need some add-ons to \n>work across different types of vocabulary.\n>\n>-----Original Message-----\n>From: public-esw-thes-request@w3.org\n>On Behalf Of Houghton,Andrew\n>Sent: 10 May 2004 21:13\n>\n>We are trying to encode AAT, LCSH, MeSH and DDC in SKOS. So my answer \n>to these questions is that SKOS needs to find a way to handle these \n>things.  There are a wealth of widely used vocabularies today and to \n>create a new Semantic Web data format that cannot take advantage of \n>these vocabularies seems, to me, to be problematic.\n>\n>Andy.\n\nOK, I agree that it would be useful to have a mechanism for encoding \npre-coordinate classification schemes and subject indexing strings, and \nI do like the idea of treating them in an integrated way that works \nsmoothly with the encoding of thesaurus structures.  It will mean a \nsignificant expansion of the project, though. Is it currently within its \nscope?\n\nThe difficulty of applying this to existing schemes is that computer \nencoding requires the development and application of strict and \nconsistent rules and algorithms, and accommodating existing schemes may \nrequire many messy exceptions and special provisions. As Andy says, \nthough, these schemes are so widely used that we have to accommodate \nthem.\n\nMy suggestion for dealing with the AAT \"guide terms\" was an attempt to \ninterpret that thesaurus in a way that the SKOS encoding could \naccommodate, without distorting either.\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Extensibility and coverage of SKO",
            "content": "Hi all,\n\nJust a short note to say, if you look at the migration guidelines doc [1]\n(which is still only half baked) I try to outline an approach to coping with\nvariation in KOS structure without compromising the benefits of\nstandardisation.\n\nBasically the idea is that, when confronted with a thesaurus that has some\nnon-standard features, you take the SKOS-Core schema, and build some\nextensions via sub-class and sub-property statements which capture the\nunique non-standard features of the thesaurus.  However, because all classes\nand properties of the extended schema are linked to classes and properties\nof the SKOS-Core schema, the extension can be reduced to a SKOS-Core\nrepresentation, and is thus still compatible with other SKOS based schemas\nand apps.\n\nI.e. you can have your cake and eat it (!!)  \n\nIt's explained a bit better in [1], with GEMET as a worked example.  This\napproach I think works well for thesauri such as GEMET, which are not too\nfar off the beaten track as far as thesauri go.  However, whether this\napproach will work for really quirky things like MeSH and AAT, and other\nstyles of scheme such as LCSH and DDC, is something I'm looking forward to\nfinding out.\n\nYours,\n\nAl.\n\n[1] http://www.w3.org/2001/sw/Europe/reports/thes/1.0/migrate/ \n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Leonard Will\n> Sent: 11 May 2004 10:21\n> To: public-esw-thes@w3.org\n> Subject: Re: Supporting arrays of concepts\n> \n> \n> \n> In message <000001c4372c$ab140080$0402a8c0@DELL> on Tue, 11 May 2004, \n> Stella Dextre Clarke <sdclarke@lukehouse.demon.co.uk> wrote\n> >\n> >I agree with Andy's response. We have to be able to support ways of \n> >working with the commonly used vocabularies. However, DDC \n> and LCSH are \n> >not thesauri. There are some fundamental differences in the \n> assumptions \n> >humans make when applying these things. It seems to me that SKOS was \n> >developed with standard thesauri in mind, and may need some \n> add-ons to \n> >work across different types of vocabulary.\n> >\n> >-----Original Message-----\n> >From: public-esw-thes-request@w3.org\n> >On Behalf Of Houghton,Andrew\n> >Sent: 10 May 2004 21:13\n> >\n> >We are trying to encode AAT, LCSH, MeSH and DDC in SKOS. So \n> my answer \n> >to these questions is that SKOS needs to find a way to handle these \n> >things.  There are a wealth of widely used vocabularies today and to \n> >create a new Semantic Web data format that cannot take advantage of \n> >these vocabularies seems, to me, to be problematic.\n> >\n> >Andy.\n> \n> OK, I agree that it would be useful to have a mechanism for encoding \n> pre-coordinate classification schemes and subject indexing \n> strings, and \n> I do like the idea of treating them in an integrated way that works \n> smoothly with the encoding of thesaurus structures.  It will mean a \n> significant expansion of the project, though. Is it currently \n> within its \n> scope?\n> \n> The difficulty of applying this to existing schemes is that computer \n> encoding requires the development and application of strict and \n> consistent rules and algorithms, and accommodating existing \n> schemes may \n> require many messy exceptions and special provisions. As Andy says, \n> though, these schemes are so widely used that we have to accommodate \n> them.\n> \n> My suggestion for dealing with the AAT \"guide terms\" was an \n> attempt to \n> interpret that thesaurus in a way that the SKOS encoding could \n> accommodate, without distorting either.\n> \n> Leonard\n> \n> -- \n> Willpower Information       (Partners: Dr Leonard D Will, \n> Sheena E Will)\n> Information Management Consultants              Tel: +44 \n> (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 \n> (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               \n> Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n> \n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concept",
            "content": "> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk] \n> Sent: Tuesday, May 11, 2004 5:21 AM\n> Subject: Re: Supporting arrays of concepts\n> \n> OK, I agree that it would be useful to have a mechanism for \n> encoding pre-coordinate classification schemes and subject \n> indexing strings, and I do like the idea of treating them in \n> an integrated way that works smoothly with the encoding of \n> thesaurus structures.  It will mean a significant expansion \n> of the project, though. Is it currently within its scope?\n\nI disagree that this would be a significant expansion of the\nproject.  We have started to do some preliminary mapping of\nAAT, LCSH, MeSH, DDC, etc. and for the most part they seem\nto map into the SKOS model.  Areas where we are currently\nhaving problems with are notes and node labels.\n\nFor notes, I think the problem is easily fixed.  In SKOS,\neverything is a skos:scopeNote.  That doesn't fit well with\nthe vocabularies we are working with.  OK, in a pinch it \nworks.  We would prefer that SKOS take the same tack that \nTIF (Thesaurus Interchange Format) took.  There is a Note\nclass and scopeNote is a subclass of Note.  When you have \nnote types that aren't of scope type, you can subclass Note.\nRight now, everything has to be sub classed from skos:scopeNote.\nThat just doesn't feel right and causes some problems with \nDewey that has between 10 to 20 different note types and \nthey aren't all scope notes.  As I said previously, we could \nshoe horn them into skos:scopeNote, but that's not ideal\nbecause we loose the subtle distinctions that the Dewey\neditors went to the trouble to make.\n\nOf course, this discussion on node labels, is another area\nthat is causing us problems.  I'm far from an expert on AAT\nbut have noted the \"guide terms\" and the fact that these\n\"guide terms\" can directly have \"guide terms\" underneath\nthem.  Dewey also has this same concept in the form of \ncentered entries, which can be considered node labels.  The\ncentered entries can directly have centered entries underneath\nthem.  Also, in Dewey and as someone else pointed out with AAT \nthese \"node labels\" do have NT/BT relationships.  While in a \n\"normal\" thesaurus they have only a grouping relationship.\nFor Dewey, we need to maintain those NT/BT relationships and\nI suspect we would need to do the same for AAT.\n\nThe current proposal doesn't take this into account and I\nreally would hate to have two different methods to deal with\nthe differing strategies.  I think, with a little effort that\nboth and possible other \"node label\" strategies could be\naccommodated.\n\nAfter rereading what I wrote here, maybe what is needed is\nto separate the relationship information, e.g. NT/BT vs.\ngrouping.  Also, I think Stella Dextre Clarke mentioned\nthe ordering problem, e.g. you say that it's ordered\nalphabetically -- what doesn't that mean for different\nlanguages?  I think the ordering problem could be easily\nhandled by attaching audience, e.g. xml:lang, to the\nnode label array.  Thus you could specify the same\nnode label array with the elements in differing order\nbased upon your audience.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Low level AP",
            "content": "The SKOS API appears to me to be pitched at a very low level. What I mean \nis that the client has to do a great deal of work, and send out many atomic \nrequests to be able to do certain kinds of required tasks, e.g. build a \nuseful hierarchical display format to allow an end user to browse a \nthesaurus. Hierarchical displays are used in a wide number of thesauri of \ndifferent styles.\n\nLet me provide an example. Suppose we want to build a browsable \nhierarchical display like found in the AAT hierarchy display for Chairs \n[1]. (Incidentally similar kinds of displays are also provided for other \nkinds of thesauri, for instance see Plant products in AGROVOC [2]). My math \nskills are not very strong, but if I understand the SKOS API correctly, I \nthink this requires 53 separate calls to getConceptRelatives (and what is \nworse probably the equivalent of 53 separate SQL queries in the underlying \nthesaurus system).\n\nContrast the SKOS API with the ADL API [3], where calls can return a large \nquantity of information to the client in a single network request. More \nimportantly, a compound call like that can probably be supported with two \nSQL statements on the thesaurus system side. Why? In thesauri that support \nhierarchical displays, it is common that a notational system is used (at \nleast internally) which is expressive of not only place in the hierarchy \nbut number of levels, or alternatively that level information is stored \nexplicitly within the record for each concept. If the thesaurus server has \nthis thesaurus-specific knowledge, supplying all the terms lower in the \nhierarchy to five levels, for example, could conceivably be done with a \nsingle SQL statement. By relying on more processing on the server and using \na higher level API, the performance in terms of the time required to return \nthe information to build the hierarchical display could, I think, be vastly \nreduced. See also the comments of Binney and Tudhope [4] when looking at \nthis problem of hierarchical displays in the AAT supporting the notion of \ncompound API calls.\n\nNow, there may be very good reasons for this low-level API approach of \nwhich I am not aware. My question is this: will this not result in some \nextremely slow response  in certain important contexts relative to what a \ncomposite API could provide?\n\nRon\n\n[1] AAT hierarchy for \"chairs\" \nhttp://www.getty.edu/vow/AATHierarchy?find=chairs&logic=AND&note=&page=1&subjectid=300038131\n[2] AGROVOC http://www.fao.org/agrovoc/\n[3] ADL Thesaurus Protocol \nhttp://alexandria.sdc.ucsb.edu/%7Egjanee/thesaurus/specification.html\n[4] See Binney and Tudhope's comments on a Service oriented approach in \nhttp://jodi.ecs.soton.ac.uk/Articles/v04/i04/Binding/#5.1\n\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\n\n\n"
        },
        {
            "subject": "Re: Supporting arrays of concept",
            "content": "In message\n<B56ABE145BEB0C40A265238FCAA420DF026F5287@oa2-server.oa.oclc.org> on\nTue, 11 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Tuesday, May 11, 2004 5:21 AM\n\n>> OK, I agree that it would be useful to have a mechanism for  encoding\n>>pre-coordinate classification schemes and subject  indexing strings, and I\n>>do like the idea of treating them in  an integrated way that works smoothly\n>>with the encoding of  thesaurus structures.  It will mean a significant\n>>expansion  of the project, though. Is it currently within its scope?\n>\n>I disagree that this would be a significant expansion of the project.  We\n>have started to do some preliminary mapping of AAT, LCSH, MeSH, DDC,\n>etc. and for the most part they seem to map into the SKOS model.  Areas\n>where we are currently having problems with are notes and node labels.\n\n1. Yes, notes should certainly be dealt with as you suggest, by having a\nmain class of \"notes\" and subclasses for different kinds of notes. This\nwould avoid a field labelled \"scope notes\" having to accommodate notes\nof other kinds.\n\n2. As regards node labels, I have tried to show that we need to\ndistinguish between\n\n        (a) real \"node labels\", which specify a characteristic of\n        division in the form <xxx by yyy> and\n\n        (b) broader concepts which act as parent terms to the terms in a\n        following array.\n\nDDC centred headings and some of the AAT guide terms fall under (b), and\nshould not be called node labels. Structurally these are just terms\nrepresenting concepts which the thesaurus editor has decided are\nunsuitable for use in indexing (and may have to be labelled in some way\nto indicate this).\n\n3. The more complex issue that I thought would broaden the scope of the\nproject is handling pre-coordinated indexing strings. The problem is\ndescribed in the following extract from \"FAST : development of\nsimplified headings for metadata / by Rebecca J. Dean\"\n<http://www.oclc.org/research/projects/fast/international_auth200302.doc>\n\n        \"LCSH is not a true thesaurus in the sense that it is not a\n        comprehensive list of all valid subject headings.  Rather LCSH\n        combines authorities, now five volumes in their printed form,\n        with a four-volume manual of rules detailing the requirements\n        for creating headings that are not established in the authority\n        file and for the further subdivision of the established\n        headings.\n\n        The rules for using free-floating subdivisions controlled by\n        pattern headings illustrate some of these complexities.  Under\n        specified conditions, these free-floating subdivisions can be\n        added to established headings.  The scope of patterns is limited\n        to particular types (patterns) of headings.  For example, Burns\n        and scalds-Patients-Family relationships is a valid heading\n        formed by adding two pattern subdivisions to the established\n        heading Burns and scalds.  The subdivision 'Patients' is one of\n        several hundred subdivisions that can be used with headings for\n        diseases and other medical conditions.  Therefore it can be used\n        to subdivide Burns and scalds.  However, the addition of\n        Patients changes the meaning of the heading from a medical\n        condition to a class of persons.  Now, since Family\n        relationships is authorized under the pattern for classes of\n        persons, it can also be added to complete the heading.\"\n\nDDC and MeSH, similarly, have many provisions for synthesising concepts\nto express compound concepts that may or may not be enumerated in the\nschedules. A classification schedule may show these compound concepts in\na hierarchical display, as I illustrated in the second example in my\nmessage of 6th May, but the hierarchy is not built on the same BT/NT\nrelationships as in a thesaurus.\n\nIt seems to me to be a much more complex job for SKOS to try to create a\nsystem that would incorporate rules for creating these compound strings.\nMost of them don't exist until they are needed for indexing a document,\nthough once they are created they may be stored in an authority file so\nthat the same string will be used if the same compound topic arises\nagain in future.\n\nThe FAST project <http://www.oclc.org/research/projects/fast/> from\nwhich I quoted above recognises this problem by treating each of the\nelements of an LCSH heading separately and grouping them into subject,\ntime, place, form, people and organisations facets. This makes it much\nmore amenable to storing in a structure like SKOS, and seems the best\ninitial approach.\n\nLeonard Will\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Low level AP",
            "content": "Hi Ron\n\nI am working as a technical developer on the SKOS API and a demo \nimplementation of it and very much welcome your input.\n\nA couple of initial points (in lieu of giving your references [1] and [3] a \nproper read):\n\n\"the client has to do a great deal of work, and send out many\n> atomic requests to be able to do certain kinds of required tasks, e.g.\n> build a useful hierarchical display format\"\n\n1) We do provide (see \nhttp://www.w3.org/2001/sw/Europe/reports/thes/api/docs/)\nmethods such as\ngetConceptRelativesByPath(Concept concept, Relation relation, URI \nthesaurus, int distance)\n\nWhich we describe as 'Get a list of concept relatives for a particular \nthesaurus up to some distance.'\n\nAnd by 'up to some distance' we mean 'number of levels' in the sense that I \nbelieve you to be talking about below.  So this avoids the need for \nrepetitive calls to the service to retrieve concepts 'clustered' around \nsome concept in the concept hierarchy. Instead, in response to these sorts \nof service requests we intend to return sets of concepts. We haven't \nfinalised our strategy for indicating exactly how distant each result-set \nconcept is from a given point in the graph ... (And I note that this issue \nrelates to the syntax we use for encoding the response data the service can \nsend to the client. For our initial SOAP service implementation we are \nusing the soap data encoding syntax and will likely move on to include \nsupport for XML as well as RDF/XML).\n\n2) You may well have already seen the use cases we're developing at \nhttp://www.w3.org/2001/sw/Europe/200311/thes/Use_cases_Thes_Service.html \n(in need of updating shortly, since I've received more contributions from \nthe community). I hadn't really imagined that client applications would \nwant to build extensive, browsable displays of concept hierarchies via the \nnetwork and 'on the fly' as it were. But this is an interesting point and I \nwonder if we need to provide some harvesting capability on the service as \nwell....\n\nAs I say, an initial response, thank you for your query,\nregards\nNikki\n\n\n\n--On Tuesday, May 11, 2004 16:03:39 +0200 Ron Davies <ron@rondavies.be> \nwrote:\n\n> The SKOS API appears to me to be pitched at a very low level. What I mean\n> is that the client has to do a great deal of work, and send out many\n> atomic requests to be able to do certain kinds of required tasks, e.g.\n> build a useful hierarchical display format to allow an end user to browse\n> a thesaurus. Hierarchical displays are used in a wide number of thesauri\n> of different styles.\n>\n> Let me provide an example. Suppose we want to build a browsable\n> hierarchical display like found in the AAT hierarchy display for Chairs\n> [1]. (Incidentally similar kinds of displays are also provided for other\n> kinds of thesauri, for instance see Plant products in AGROVOC [2]). My\n> math skills are not very strong, but if I understand the SKOS API\n> correctly, I think this requires 53 separate calls to getConceptRelatives\n> (and what is worse probably the equivalent of 53 separate SQL queries in\n> the underlying thesaurus system).\n>\n> Contrast the SKOS API with the ADL API [3], where calls can return a\n> large quantity of information to the client in a single network request.\n> More importantly, a compound call like that can probably be supported\n> with two SQL statements on the thesaurus system side. Why? In thesauri\n> that support hierarchical displays, it is common that a notational system\n> is used (at least internally) which is expressive of not only place in\n> the hierarchy but number of levels, or alternatively that level\n> information is stored explicitly within the record for each concept. If\n> the thesaurus server has this thesaurus-specific knowledge, supplying all\n> the terms lower in the hierarchy to five levels, for example, could\n> conceivably be done with a single SQL statement. By relying on more\n> processing on the server and using a higher level API, the performance in\n> terms of the time required to return the information to build the\n> hierarchical display could, I think, be vastly reduced. See also the\n> comments of Binney and Tudhope [4] when looking at this problem of\n> hierarchical displays in the AAT supporting the notion of compound API\n> calls.\n>\n> Now, there may be very good reasons for this low-level API approach of\n> which I am not aware. My question is this: will this not result in some\n> extremely slow response  in certain important contexts relative to what a\n> composite API could provide?\n>\n> Ron\n>\n> [1] AAT hierarchy for \"chairs\"\n> http://www.getty.edu/vow/AATHierarchy?find=chairs&logic=AND&note=&page=1&\n> subjectid=300038131 [2] AGROVOC http://www.fao.org/agrovoc/\n> [3] ADL Thesaurus Protocol\n> http://alexandria.sdc.ucsb.edu/%7Egjanee/thesaurus/specification.html [4]\n> See Binney and Tudhope's comments on a Service oriented approach in\n> http://jodi.ecs.soton.ac.uk/Articles/v04/i04/Binding/#5.1\n>\n>\n> Ron Davies\n> Information and documentation systems consultant\n> Av. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\n> Email:  ron@rondavies.be\n> Tel:    +32 (0)2 770 33 51\n> GSM:    +32 (0)484 502 393\n>\n>\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Re: Low level AP",
            "content": "In message <6.0.0.22.2.20040511155617.01c6c768@pop.skynet.be> on Tue, 11 \nMay 2004, Ron Davies <ron@rondavies.be> wrote\n>The SKOS API appears to me to be pitched at a very low level. What I \n>mean is that the client has to do a great deal of work, and send out \n>many atomic requests to be able to do certain kinds of required tasks, \n>e.g. build a useful hierarchical display format to allow an end user to \n>browse a thesaurus. Hierarchical displays are used in a wide number of \n>thesauri of different styles.\n\nI agree with Ron, though I would be interested to know the views of the \nfolk closer to the mechanics of how this would work. Perhaps there is a \ndifference depending on whether you are retrieving a display for a human \nto look at or specific terms for a machine to use.\n\nIt would certainly seem more efficient for a server to return a complete \nhierarchy in response to a single request; most standard thesaurus \nmanagement software can display such hierarchies, constructing them when \nneeded by following the chain of BT/NT links.\n\nI don't think that it should be necessary to store \"level\" information \nto achieve this, and indeed I think that doing so would complicate \nmatters, because if a concept is inserted to create a new level of \ngrouping then the \"levels\" of all the subordinate concepts would change.\n\nLeonard Will\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "I did not cast a vore against forward compatibility in general at all.\nActually the current shared secret proposal does not solve that either,\nin the sense that to incorporate kerberos or some other auth mechanism\nwe need to add yet other messages.\n\nI was not under the impression that we were after designing forward\ncompatibilty in the TLS protocol. If that is the case, we could do the\nsplit document thing and work on an extensible handshake.\n\nTaher\n\n\n\nDon Schmidt wrote:\n> \n> I am delighted to see the last two postings from Taher and Barb getting\n> back to the point.  That is the utility of a TLS standard.  If after all\n> we design something that is secure but does not meet customer\n> requirements -- and so is not widely adopted -- then why bother?\n> \n> Many (if not most) of the arguments against incorporating shared-secret\n> auth in TLS (the transport vs app layer arguments) could apply equally\n> to PK-based auth.\n> \n> Many of the obvious interoperability benefits of incorporating a\n> standard PK-based auth into TLS could equally apply to shared-secret\n> auth.\n> \n> The point here is not whether PK-based auth is more secure than\n> shared-secret auth, or whether it provides non-repudiation, or ...\n> \n> The relevant facts here are:\n> - This working group is chartered to develop a transport layer security\n> standard.\n> \n> - Rough consensus has decreed that SSL3 is the best starting point.\n> \n> - Everyone recognizes the value of the robust key exchange, auth,\n> integrity and encryption capabilities that derive from PK technology.\n> \n> - Real consumers of products to be built according to the TLS standard\n> have stated that the infrastructure, key management and portability\n> issues associated with PK technology are acceptable on the server side.\n> But they also have clearly stated their need to support millions of\n> end-users who currently use passwords and are not ready to switch\n> wholesale to private keys and certs.\n> \n> - Real customers want the benefits of a single standard for Transport\n> layer security but with their choice of auth technology.  In fact, they\n> will most likely have to support both shared-secret auth and PK-based\n> auth in parallel for some time, probably a couple of years at least.\n> \n> - If the TLS standard were to support both auth mechanisms then it would\n> be possible to provide implementations which prevent applications from\n> having to know or care what kind of credentials were used to\n> authenticate the end-user.  Applications could be written to a single\n> interface and could be upgraded just once to support legacy client auth\n> (shared-secret) and still migrate to admittedly superior client auth\n> (PK-based).\n> \n> Why is there such resistance to this line of reasoning?  If rough\n> concensus holds that the TLS standard cannot support both shared-secret\n> and PK-based auth, then fine, take them both out and put them both in\n> the application layer.  But give me one standard so that applications\n> developers, customers and end-users don't have to be hamstrung by the\n> differences in authentication technology.\n> \n> Don Schmidt\n> Program Manager\n> Microsoft Corp\n> \n> >----------\n> >From:  Barb Fox\n> >Sent:  Wednesday, October 09, 1996 5:01 PM\n> >To:    Dan Simon; 'elgamal@netscape.com'\n> >Cc:    'ietf-tls@w3.org'; 'treese@OpenMarket.com'; 'david.brownell@Eng.Sun.COM'\n> >Subject:       RE: Closing on shared-key authentication\n> >\n> >>Taher:\n> >>\n> >>I just have to jump in here to clarify a couple of things.\n> >>\n> >>Yes, password authentication is a customer requirement.  Many companies tell\n> >>us that they want a migration path from passwords to certificate-based\n> >>systems within the TLS protocol standard.  This has been the sole reason we\n> >>have been pushing so hard for password authentication...customer need.  The\n> >>business side of this argument has already been comprehensively presented by\n> >>John Macko (Compuserve) in an earlier posting (7/22) so I don't want to\n> >>start\n> >>that chain again here.\n> >>\n> >>But Dan's comment about forward compatibilty in SSL has nothing to do with\n> >>passwords per se.  Fact: there is no generic extensibility mechanism in SSL3\n> >- and that's something we need to acknowledge and fix as soon as we can.\n> >> The goal of this working group, after all, should be to create an\n> >>architecturally-sound, extensible standard.  I admit that this will cause us\n> >>all some pain as we find ourselves having to change our fielded\n> >implementations to prepare for future advances in the protocol.  But if\n> >>we bite the bullet and design the protocol correctly now, it shouldn't be\n> >>such a big deal as we go incrementally forward.\n> >\n> >>Barb\n> >>\n> >>----------\n> >>From:         elgamal@netscape.com[SMTP:elgamal@netscape.com]\n> >>Sent:         Wednesday, October 09, 1996 8:49 AM\n> >>To:   Dan Simon\n> >>Cc:   'ietf-tls@w3.org'; 'treese@OpenMarket.com';\n> >>'david.brownell@Eng.Sun.COM'\n> >>Subject:      Re: Closing on shared-key authentication\n> >>\n> >>Dan,\n> >>\n> >>You bring an interesting point. In the design of SSL3.0, we did not\n> >>expect that the protocol would have to support weaker authentication\n> >>techniques, actually going backwards if you think about it. The idea of\n> >>SSL3.0 was not to support everything that may exist or everything anyone\n> >>can think of. So, you cannot really accuse SSL of not being forward\n> >>compatible because it assumes a good authentication method rather than\n> >>duplicate old ones that everyone has already implemented in any\n> >>interesting application protocol. The only reason for me to entertain\n> >>this password thing is that a customer thinks it is useful, not really\n> >>because it adds anything to the protocol, on the contrary, it makes it\n> >>less attractive since the level of authentication is not defined.\n> >>\n> >>Taher\n> >>\n> >>\n> >>Dan Simon wrote:\n> >>>\n> >>> >From:  david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n> >>> >\n> >>> >I'll have to go back and look at the comments from last\n> >>> >week's proposal (ssl-talk is where I saw most of it),\n> >>> >but this proposal really doesn't seem \"cooked\" to me.\n> >>> >\n> >>> >   - Internationalization issues arise.  In what character\n> >>> >     set do \"display_string\" and \"challenge\" appear?  How\n> >>> >     is the language which the end user knows specified?\n> >>> >\n> >>> >     I don't like seeing application layer issues intrude\n> >>> >     on transport layer protocols.\n> >>>\n> >>> The \"display_string\" field is opaque; that is, TLS simply transports it\n> >>> without examining its content.  It is entirely the next level's\n> >>> responsibility to figure out what to do with it (or even if it should be\n> >>> sent in the first place).  Why is this an \"intrusion\" into the transport\n> >>> layer, any more than, say, the presence of the opaque application data\n> >>> which is passed through TLS as part of its basic function?\n> >>> >\n> >>> >   - Neither \"rough consensus\" nor (multiple instances of)\n> >>> >     \"working code\" exists, as has been pointed out.\n> >>> >\n> >>> >     Many of us don't see a technical benefit to making TLS\n> >>> >     be incompatible with SSLv3 in this respect, so I doubt\n> >>> >     that a realistic \"consensus\" on this point can exist.\n> >>>\n> >>> Well, the real problem is that virtually *any* difference between TLS\n> >>> and SSL 3.0 would make TLS incompatible with SSL 3.0, because SSL 3.0\n> >>> simply lacks a mechanism for forward compatibility.  If we do nothing\n> >>> else, we absolutely *must* prevent this problem from grandfathering its\n> >>> way into TLS.  (The fix that's been suggested as least painful to SSL\n> >>> 3.0 implementers is to specify that unrecognized handshake message types\n> >>> be ignored--hence our use of new handshake message types to implement\n> >>> shared-key authentication.  If someone has a better way to permit\n> >>> extensibility, then I'd be happy to hear about it.)\n> >>> >\n> >>> >   - It's unclear just where in the handshake these new\n> >>> >     messages would go.  Or are they even part of the\n> >>> >     regular handshake protocol?  Do they go after the\n> >>> >     \"Finished\" messages are exchanged, are they an\n> >>> >     independent handshake, or what?\n> >>>\n> >>> The posted document specifies where the extra messages should go.\n> >>> >\n> >>> >   - Given that the amount of keying material to be built\n> >>> >     is derived from the negotiated cipher spec, what's\n> >>> >     the change needed in the definition of a cipher spec?\n> >>> >     It needs to know it must generate CipherSpec.hash_size\n> >>> >     (times two?) bytes of keying data.\n> >>>\n> >>> In SSL 3.0 (and presumably TLS), the actual keying material is not\n> >>> included in the cipher_spec, but rather as part of the general\n> >>> connection state.  Implementations that don't support shared-key\n> >>> authentication can, of course, ignore the extra keying material\n> >>> altogether.\n> >>> >\n> >>> >   - There's a new requirement, to ignore unrecognized\n> >>> >     handshake messages rather than treat them as errors.\n> >>> >     I prefer protocols to be fully specfied.\n> >>>\n> >>> If it's preferable, the specification can certainly require that\n> >>> implementations recognize the extra handshake messages.  Of course, the\n> >>> real problem here is SSL 3.0's lack of an extensibility mechanism; see\n> >>> my comments above.\n> >>> >\n> >>> >I could raise more questions, but the fact that there are\n> >>> >this many (after this much discussion!) says to me that the\n> >>> >proposal should not be deemed \"cooked\" enough to incorporate\n> >>> >into an IETF standard.\n> >>>\n> >>> To my mind, the problems with the proposal, as enumerated by David, cast\n> >>> a worse light on SSL 3.0 than on the proposal itself.\n> >>>\n> >>>                                 Daniel Simon\n> >>>                                 Cryptographer, Microsoft Corp.\n> >>>                                 dansimon@microsoft.com\n> >>>\n> >>> >\n> >>> >\n> >>> >\n> >>\n> >>--\n> >>Taher Elgamal     elgamal@netscape.com\n> >>Chief Scientist, Netscape Communications\n> >>(T) 415 937 2898, (F) 415 428 4054\n> >>\n> >>\n> >\n\n-- \nTaher Elgamal    elgamal@netscape.com\nChief Scientist, Netscape Communications\n(T) 415 937 2898, (F) 415 428 4054\n\n\n\n"
        },
        {
            "subject": "Re: Closing on shared-key authentication Repl",
            "content": "> From: John Gardiner Myers <jgm@CMU.EDU>\n> \n> But, as has been pointed out, the issue of separating application\n> layer and transport layer issues is irrelevant to the proposal.  If it\n> is in fact an issue of separating out authentication as being an\n> application layer issue, then the public-key authentication facilities\n> of TLS should be removed on the grounds that they are also in the\n> wrong layer.\n> \n> Shared-key authentication is not fundamentally different from a\n> layering standpoint than any other authentication technology.  Any\n> layer in which it is appropriate to put in a public-key authentication\n> system it is also technically appropriate to put in a shared-key\n> authentication system.  \n\n\nPerhaps on some other planet.\n\nBut in the real world, public-key authentication scales to a global\nlevel whereas shared-secrets are limited to specific communities of\ninterest.  The first round of S/WAN (IPsec) testing used shared-secret\nauthentication (i.e. manual keying).  The next round will use both\nproposed forms of automated key management (SKIP and ISAKMP, both of\nwhich are public-key based).  Most people would agree that for universal\ndeployment, automatic is better than manual.\n\nIt is also true that everybody and his brother is trying to get into\nthe Public Key Infrastructure (PKI) business, whereas I haven't heard\nof any companies trying to be the first to set up a global-scale\nsymmetric KDC business.\n\nSo what does all that have to do with TLS?  It means that if you\nconfine yourself to the Transport Layer, authentication can be done\nautomatically, because the manual labor has already been done by the\nVerisigns/GTEs/Nortels/etc of the world.  When you make a connection to\nwww.nytimes.com, you know you're there because somebody has taken the\neffort to bind that name with their key.  If you wanted to do the same\nwith symmetric-key authentication, you'd have to do manual distribution\nof the key because, in general (for an arbitrary entity anywhere in the\nworld), no one is in the business of providing symmetric key\nmanagement services.\n\nSure, BOTH symmetric and public key authentication can be done at the\napplication layer, but public key is the ONLY method that can be done\nautomatically at the transport layer.  The shared-key authentication\nproposal currently on the table recognizes that fact - it uses the\npublic-key authenticated channel established by TLS, and provides a\nspecial-purpose path through that channel for shared-key authentication\nthat cannot be used to encrypt general user data.  The proposal already\nrequires application-layer support - in fact if the API is not called\n(from an application, of course), the extra handshake messages are\nnever generated.\n\nA dummy application (one that is completely security-unaware) can open\na socket, send some data, and close it.  TLS provides security to that\nconnection using public-key authentication with *no* help from the\napplication.  TLS (either following the specific proposal, or using any\nconceivable alternative) could NOT perform the same function using symmetric\nkey authentication.\n\nIt is not clear to me why the identical shared-secret authentication API,\nwith identical semantics, could not be layered on top of the TLS protocol\nwithout any modifications to the protocol itself.  If I were in the\nbusiness of developing products for customers, that's how I'd do it,\nand skip the holy wars.  After all, the customer need (as expressed by\nCompuserve et al) is for *application* access to authentication information.\nThat information could be a client cert, which is available for free\nas a byproduct of the TLS channel establishment, or it could be a secret,\nwhich would have to be sent from an application at the client end to\nan application at the server end.  I haven't heard any customers saying\nthey needed shared-key authentication provided automatically, by the\ntransport layer, for security-unaware apps.\n\n\n> jgm: Authentication is authentication.\n\n\"In theory, there's no difference between theory and practice.\n In practice, there is.\"\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Barb Fox wrote:\n> \n> But Dan's comment about forward compatibilty in SSL has nothing to do\n> with passwords per se.  Fact: there is no generic extensibility\n> mechanism in SSL3 - and that's something we need to acknowledge and\n> fix as soon as we can.  The goal of this working group, after all,\n> should be to create an architecturally-sound, extensible standard.  I\n> admit that this will cause us all some pain as we find ourselves\n> having to change our fielded implementations to prepare for future\n> advances in the protocol.  But if we bite the bullet and design the\n> protocol correctly now, it shouldn't be such a big deal as we go\n> incrementally forward.\n\nThe lack of a general extension mechanism in SSL v3 is a feature, not a\nbug.  This is a security protocol, and so susceptibility to analysis is\na good thing.  Simplicity and rigidity are features here.  SSL does\nprovide for forwards compatibility by allowing version negotiation and\nprotection from version rollback attacks.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Don Schmidt wrote:\n> \n> I am delighted to see the last two postings from Taher and Barb\n> getting back to the point.  That is the utility of a TLS standard.  If\n> after all we design something that is secure but does not meet\n> customer requirements -- and so is not widely adopted -- then why\n> bother?\n> \n> Many (if not most) of the arguments against incorporating\n> shared-secret auth in TLS (the transport vs app layer arguments) could\n> apply equally to PK-based auth.\n> \n> Many of the obvious interoperability benefits of incorporating a\n> standard PK-based auth into TLS could equally apply to shared-secret\n> auth.\n> \n> The point here is not whether PK-based auth is more secure than\n> shared-secret auth, or whether it provides non-repudiation, or ...\n\n[ ... snip ... ]\n\n- Password authentication weakens TLS.\n\n- The first time someone cracks a password used in TLS authentication,\n  it will erode public confidence in the security of TLS.\n\n- We aren't just trying to solve a problem for next quarter, we're\n  trying to generate a security standard for the Internet that will\n  stand the test of time.  I don't think we should be guided by\n  short-lived customer requirements.\n\n- The only security reason for including password auth in TLS is that\n  it gains stronger security by having access to strong crypto in the\n  export case.  I don't think we should include features this major\n  based solely on brain-damaged US export regulations that will\n  hopefully soon change.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on shared-key authentication Repl",
            "content": "David,\n\n  I think that automation across the board will soon be a requirnment.\nMaybe not\nnow in all cases but soon.  Again I think that a standard interface would be \na much better approach here.\n\nReguards,\n\n\nAt 12:38 PM 10/10/96 -0400, you wrote:\n>> From: John Gardiner Myers <jgm@CMU.EDU>\n>> \n>> But, as has been pointed out, the issue of separating application\n>> layer and transport layer issues is irrelevant to the proposal.  If it\n>> is in fact an issue of separating out authentication as being an\n>> application layer issue, then the public-key authentication facilities\n>> of TLS should be removed on the grounds that they are also in the\n>> wrong layer.\n>> \n>> Shared-key authentication is not fundamentally different from a\n>> layering standpoint than any other authentication technology.  Any\n>> layer in which it is appropriate to put in a public-key authentication\n>> system it is also technically appropriate to put in a shared-key\n>> authentication system.  \n>\n>\n>Perhaps on some other planet.\n>\n>But in the real world, public-key authentication scales to a global\n>level whereas shared-secrets are limited to specific communities of\n>interest.  The first round of S/WAN (IPsec) testing used shared-secret\n>authentication (i.e. manual keying).  The next round will use both\n>proposed forms of automated key management (SKIP and ISAKMP, both of\n>which are public-key based).  Most people would agree that for universal\n>deployment, automatic is better than manual.\n>\n>It is also true that everybody and his brother is trying to get into\n>the Public Key Infrastructure (PKI) business, whereas I haven't heard\n>of any companies trying to be the first to set up a global-scale\n>symmetric KDC business.\n>\n>So what does all that have to do with TLS?  It means that if you\n>confine yourself to the Transport Layer, authentication can be done\n>automatically, because the manual labor has already been done by the\n>Verisigns/GTEs/Nortels/etc of the world.  When you make a connection to\n>www.nytimes.com, you know you're there because somebody has taken the\n>effort to bind that name with their key.  If you wanted to do the same\n>with symmetric-key authentication, you'd have to do manual distribution\n>of the key because, in general (for an arbitrary entity anywhere in the\n>world), no one is in the business of providing symmetric key\n>management services.\n>\n>Sure, BOTH symmetric and public key authentication can be done at the\n>application layer, but public key is the ONLY method that can be done\n>automatically at the transport layer.  The shared-key authentication\n>proposal currently on the table recognizes that fact - it uses the\n>public-key authenticated channel established by TLS, and provides a\n>special-purpose path through that channel for shared-key authentication\n>that cannot be used to encrypt general user data.  The proposal already\n>requires application-layer support - in fact if the API is not called\n>(from an application, of course), the extra handshake messages are\n>never generated.\n>\n>A dummy application (one that is completely security-unaware) can open\n>a socket, send some data, and close it.  TLS provides security to that\n>connection using public-key authentication with *no* help from the\n>application.  TLS (either following the specific proposal, or using any\n>conceivable alternative) could NOT perform the same function using symmetric\n>key authentication.\n>\n>It is not clear to me why the identical shared-secret authentication API,\n>with identical semantics, could not be layered on top of the TLS protocol\n>without any modifications to the protocol itself.  If I were in the\n>business of developing products for customers, that's how I'd do it,\n>and skip the holy wars.  After all, the customer need (as expressed by\n>Compuserve et al) is for *application* access to authentication information.\n>That information could be a client cert, which is available for free\n>as a byproduct of the TLS channel establishment, or it could be a secret,\n>which would have to be sent from an application at the client end to\n>an application at the server end.  I haven't heard any customers saying\n>they needed shared-key authentication provided automatically, by the\n>transport layer, for security-unaware apps.\n>\n>\n>> jgm: Authentication is authentication.\n>\n>\"In theory, there's no difference between theory and practice.\n> In practice, there is.\"\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Tom,\n\n  Please read below your comments.\n\nAt 10:27 AM 10/10/96 -0700, you wrote:\n>Don Schmidt wrote:\n>> \n>> I am delighted to see the last two postings from Taher and Barb\n>> getting back to the point.  That is the utility of a TLS standard.  If\n>> after all we design something that is secure but does not meet\n>> customer requirements -- and so is not widely adopted -- then why\n>> bother?\n>> \n>> Many (if not most) of the arguments against incorporating\n>> shared-secret auth in TLS (the transport vs app layer arguments) could\n>> apply equally to PK-based auth.\n>> \n>> Many of the obvious interoperability benefits of incorporating a\n>> standard PK-based auth into TLS could equally apply to shared-secret\n>> auth.\n>> \n>> The point here is not whether PK-based auth is more secure than\n>> shared-secret auth, or whether it provides non-repudiation, or ...\n>\n>[ ... snip ... ]\n>\n>- Password authentication weakens TLS.\n>\n>- The first time someone cracks a password used in TLS authentication,\n>  it will erode public confidence in the security of TLS.\n\n  I totaly agree here.  Password authentication is too problemsome I believe.\n>\n>- We aren't just trying to solve a problem for next quarter, we're\n>  trying to generate a security standard for the Internet that will\n>  stand the test of time.  I don't think we should be guided by\n>  short-lived customer requirements.\n\n  True.  Some of these customer requirnments however will be long\nterm and should be reviewed with that in mind.  I am an advocate\nof looking long term myself.  I also believe that some of the precieved\nshort term customer requirnments do need attention however, otherwise\nwe will have a hard time achieving the long term goals.\n>\n>- The only security reason for including password auth in TLS is that\n>  it gains stronger security by having access to strong crypto in the\n>  export case.  I don't think we should include features this major\n>  based solely on brain-damaged US export regulations that will\n>  hopefully soon change.\n\n  I hope you are right here, Tom.  I am not so sure that those regulations\nwill change all that soon.  In the interum however it seems necessary to\naddress password auth, for the short term.  I don't see how this should or would\ninpune TLS in any really meaningfull way, long term.\n\nReguards,\n\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Jeff Williams wrote:\n> \n>>- We aren't just trying to solve a problem for next quarter, we're\n>>  trying to generate a security standard for the Internet that will\n>>  stand the test of time.  I don't think we should be guided by\n>>  short-lived customer requirements.\n> \n>   True.  Some of these customer requirnments however will be long\n> term and should be reviewed with that in mind.  I am an advocate\n> of looking long term myself.  I also believe that some of the\n> precieved short term customer requirnments do need attention however,\n> otherwise we will have a hard time achieving the long term goals.\n\nYou are quite correct.  However, short term customer requirements for\npassword authentication can be met by using existing authentication\nmechanisms in existing protocols.  There is no need to add a mechanism\nto TLS when all existing protocols already have a password mechanims.\n\n>>- The only security reason for including password auth in TLS is that\n>>  it gains stronger security by having access to strong crypto in the\n>>  export case.  I don't think we should include features this major\n>>  based solely on brain-damaged US export regulations that will\n>>  hopefully soon change.\n> \n>   I hope you are right here, Tom.  I am not so sure that those\n> regulations will change all that soon.  In the interum however it\n> seems necessary to address password auth, for the short term.  I don't\n> see how this should or would inpune TLS in any really meaningfull way,\n> long term.\n\nEven if you think we'll be limited to 40-bit for export forever, do you\nreally believe that any password scheme is going to provide better than\n40 bits worth of security for authentication?  If you can remember a\npassword with 40 bits of entropy then you have a better memory than I\ndo.\n\nAs to the lifting of export restrictions, the White House is already\ntalking about raising the limit to 56 bits, and there is legislation\npending that would lift export restrictions altogether.  I feel very\nstrongly that an international standard should not be burdened with\nmajor features with such substantial security implications for reasons\nof local governmental policy.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Tom,\n\n  Please read below your comments.\n\nAt 12:30 PM 10/10/96 -0700, you wrote:\n>Jeff Williams wrote:\n>> \n>>>- We aren't just trying to solve a problem for next quarter, we're\n>>>  trying to generate a security standard for the Internet that will\n>>>  stand the test of time.  I don't think we should be guided by\n>>>  short-lived customer requirements.\n>> \n>>   True.  Some of these customer requirnments however will be long\n>> term and should be reviewed with that in mind.  I am an advocate\n>> of looking long term myself.  I also believe that some of the\n>> precieved short term customer requirnments do need attention however,\n>> otherwise we will have a hard time achieving the long term goals.\n>\n>You are quite correct.  However, short term customer requirements for\n>password authentication can be met by using existing authentication\n>mechanisms in existing protocols.  There is no need to add a mechanism\n>to TLS when all existing protocols already have a password mechanims.\n\n  I realize that.  But my concern is not just that we may need to consider\nadding it to TLS for those customers whom believe in that mechanism, all\nbe it not necessary, possibly.  Again I still believe that a \"Common\"\nProtocol interface well featured would go a long ways in solving or\naddressing some short term problems at teh very least.  Extensions to that\ninterface for enhancments to existiing or possably new protocols, would also\nproject a method of achieving long term desires here.  Don't you think this\nmakes some sense?\n>\n>>>- The only security reason for including password auth in TLS is that\n>>>  it gains stronger security by having access to strong crypto in the\n>>>  export case.  I don't think we should include features this major\n>>>  based solely on brain-damaged US export regulations that will\n>>>  hopefully soon change.\n>> \n>>   I hope you are right here, Tom.  I am not so sure that those\n>> regulations will change all that soon.  In the interum however it\n>> seems necessary to address password auth, for the short term.  I don't\n>> see how this should or would inpune TLS in any really meaningfull way,\n>> long term.\n>\n>Even if you think we'll be limited to 40-bit for export forever, do you\n>really believe that any password scheme is going to provide better than\n>40 bits worth of security for authentication?  If you can remember a\n>password with 40 bits of entropy then you have a better memory than I\n>do.\n\n  No of course not.  I couldn't remember much more than 10! ;)  But is it\nreally necessary to remember.  I can be pluged into the login procedure. \n>\n>As to the lifting of export restrictions, the White House is already\n>talking about raising the limit to 56 bits, and there is legislation\n>pending that would lift export restrictions altogether.  I feel very\n>strongly that an international standard should not be burdened with\n>major features with such substantial security implications for reasons\n>of local governmental policy.\n\n  56 bits is a total waste of time in my opinion.  It wouldn't take much more\nthan 3 seconds to break that!  Without at least 128 bits being approved for\nexport international companies will not support commerce for long on the \nnet.  In addition, even 128 bit in my humble opinion is a bit short of what\nI would like to see.  \n\n  With reguard to what you say reguarding local gov. policy, I am not quite\nclear as to what you mean here?  Explain please, ok?\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": "> >   - Internationalization issues arise.  In what character\n> >     set do \"display_string\" and \"challenge\" appear?  How\n> >     is the language which the end user knows specified?\n> >     \n> >     I don't like seeing application layer issues intrude\n> >     on transport layer protocols.\n> \n> The \"display_string\" field is opaque; that is, TLS simply transports it\n> without examining its content.\n\nThe name of the field, at the least, strongly \"suggests\" that it be\ndisplayed to users.  Display prompts and challenges are a common part\nof many password-based user interfaces; the OTP (S/KEY) IETF work is\none example.  (Why wouldn't a TLS scheme build on that work?)\n\n\n>  It is entirely the next level's\n> responsibility to figure out what to do with it (or even if it should be\n> sent in the first place).  Why is this an \"intrusion\" into the transport\n> layer, any more than, say, the presence of the opaque application data\n> which is passed through TLS as part of its basic function?\n\nSeems to me that it's either application data, in which case it's\ninsignificant with respect to security and should be sent as normal\n\"application_data\" records, or it's security data which needs to\nbe fully specified lest interoperability islands be created.\n\nSo for example some folk have said that PKI shouldn't necessarily\nbe part of TLS, any more than a password scheme.  But the PKI is\nrelatively well specified (X.509; RSA, D-H, or DSS public keys)\nand the password schemes are not interoperably specified yet.\n\nPlus, there's an overgeneralization:  it's not clear to me how I'd\nbe able to use the Kerberos V5 shared key system in an interoperable\nway.  There's no \"scheme ID\" assigned by the IANA to indicate that\nthe display_string/challenge data is used (how?) by Kerberos vs. by\na Compuserve or Microsoft proprietary authentication protocol.\n\n\n\n> >   - Neither \"rough consensus\" nor (multiple instances of)\n> >     \"working code\" exists, as has been pointed out.\n> >     \n> >     Many of us don't see a technical benefit to making TLS\n> >     be incompatible with SSLv3 in this respect, so I doubt\n> >     that a realistic \"consensus\" on this point can exist.\n> \n> Well, the real problem is that virtually *any* difference between TLS\n> and SSL 3.0 would make TLS incompatible with SSL 3.0, because SSL 3.0\n> simply lacks a mechanism for forward compatibility.\n\nI don't buy this.  There are mechanisms whereby an \"SSL 3.1\" can be\nwire compatible with \"SSL 3.0\".  But they're tightly constrained,\nto minimize interoperability problems.  (And, as Tom Weinstein pointed\nout, to enable a complete security analysis.)\n\nAlso, compatibility is an orthogonal issue to authentication (and\nencryption) strength.  I'm not sure it'd be good to have the IETF\nmake changes via TLS that reduce the strength now found in SSLv3,\nor to adopt a mechanism that's not scalable to the current size of\nthe Internet.  [ Repeating points others have made on this list,\nsince I agree and think they bear repeating! ]\n\n\n\n> >   - It's unclear just where in the handshake these new\n> >     messages would go.  Or are they even part of the\n> >     regular handshake protocol?  Do they go after the\n> >     \"Finished\" messages are exchanged, are they an\n> >     independent handshake, or what?\n> \n> The posted document specifies where the extra messages should go.\n\nI just noticed some text there.  It's not as complete as I'd need\nif I were to implement this in my SSLv3 code.  Do these go before or\nafter ServerHelloDone?  What about the case of rejoining a session?\nWhere does SharedKeyVerify go?\n\n\n> To my mind, the problems with the proposal, as enumerated by David, cast\n> a worse light on SSL 3.0 than on the proposal itself.\n\nI don't follow this any more than your comment about lack of\nsupport for controlled protocol evolution.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "> - The only security reason for including password auth in TLS is that\n>   it gains stronger security by having access to strong crypto in the\n>   export case.  I don't think we should include features this major\n>   based solely on brain-damaged US export regulations that will\n>   hopefully soon change.\n\nSeems to me that's only if you assume the best way to secure password\nauth is to just encrypt the password, as opposed to using other\nmore sophisticated methods.  It also is true only if you're willing\nto accept authentication that is dependent upon the security of\nthe encryption; some people feel this is undesrable for reasons\nhaving nothing to do with export regulations.\n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": "The problem of forward compatibility in SSL 3.0 goes beyond the\nparticular issue of password authentication.  In fact, the password\nauthentication feature can be included in TLS with complete SSL 3.0\ncompatibility, as long as TLS hello messages have a new, higher version\nnumber, and TLS servers are required to fall back to SSL 3.0 (without\nclient auth.) when communicating with a pure SSL 3.0 client.  (A similar\nsolution works for a number of other proposed TLS enhancements; the\nissue of SSL 3.0 backward compatibility in TLS is therefore something of\na red herring.)  \n\nThe broader question is whether we want to maintain such strict SSL 3.0\nbackward compatibility as to freeze the TLS  client hello forever as an\nSSL 3.0 client hello.  There are a number of potentially attractive\nchanges (such as \"quick\" key exchange, for instance) which would\nultimately require changes to the client hello message, but because of\nSSL 3.0's lack of an extensibility mechanism, any of these would\nautomatically preclude complete SSL 3.0 backward compatibility.  In\noffline discussions, it has been mentioned that a relatively painless\nway to break this compatibility is to allow new handshake message types\nin TLS, and assume that SSL 3.0 implementations simply ignore them.\nThat way, additions to the client hello can be in the form of appended\nhandshake messages.  I therefore propose that we:\n\n1)  Select a version number for TLS, so that proposals for additional\nfeatures can be explicitly made compatible with SSL 3.0; and\n\n2)  Consider proposals for incorporating extensibility into the TLS\nclient hello message (starting, presumably, with the proposal to have\nTLS require that unrecognized handshake messages be ignored without\nerror).\n\nNote that these items involve the handshake protocol only, and do not\ninterfere with efforts (which I support) to split the protocol into\nindependent \"handshake/key management\" and \"record\" components.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)\n\n>----------\n>From: elgamal@netscape.com[SMTP:elgamal@netscape.com]\n>Sent: Thursday, October 10, 1996 8:43 AM\n>To: Don Schmidt\n>Cc: Dan Simon; Barb Fox; 'ietf-tls@w3.org'; 'treese@OpenMarket.com';\n>'david.brownell@Eng.Sun.COM'\n>Subject: Re: Closing on shared-key authentication\n>\n>I did not cast a vore against forward compatibility in general at all.\n>Actually the current shared secret proposal does not solve that either,\n>in the sense that to incorporate kerberos or some other auth mechanism\n>we need to add yet other messages.\n>\n>I was not under the impression that we were after designing forward\n>compatibilty in the TLS protocol. If that is the case, we could do the\n>split document thing and work on an extensible handshake.\n>\n>Taher\n>\n>\n>\n>Don Schmidt wrote:\n>> \n>> I am delighted to see the last two postings from Taher and Barb getting\n>> back to the point.  That is the utility of a TLS standard.  If after all\n>> we design something that is secure but does not meet customer\n>> requirements -- and so is not widely adopted -- then why bother?\n>> \n>> Many (if not most) of the arguments against incorporating shared-secret\n>> auth in TLS (the transport vs app layer arguments) could apply equally\n>> to PK-based auth.\n>> \n>> Many of the obvious interoperability benefits of incorporating a\n>> standard PK-based auth into TLS could equally apply to shared-secret\n>> auth.\n>> \n>> The point here is not whether PK-based auth is more secure than\n>> shared-secret auth, or whether it provides non-repudiation, or ...\n>> \n>> The relevant facts here are:\n>> - This working group is chartered to develop a transport layer security\n>> standard.\n>> \n>> - Rough consensus has decreed that SSL3 is the best starting point.\n>> \n>> - Everyone recognizes the value of the robust key exchange, auth,\n>> integrity and encryption capabilities that derive from PK technology.\n>> \n>> - Real consumers of products to be built according to the TLS standard\n>> have stated that the infrastructure, key management and portability\n>> issues associated with PK technology are acceptable on the server side.\n>> But they also have clearly stated their need to support millions of\n>> end-users who currently use passwords and are not ready to switch\n>> wholesale to private keys and certs.\n>> \n>> - Real customers want the benefits of a single standard for Transport\n>> layer security but with their choice of auth technology.  In fact, they\n>> will most likely have to support both shared-secret auth and PK-based\n>> auth in parallel for some time, probably a couple of years at least.\n>> \n>> - If the TLS standard were to support both auth mechanisms then it would\n>> be possible to provide implementations which prevent applications from\n>> having to know or care what kind of credentials were used to\n>> authenticate the end-user.  Applications could be written to a single\n>> interface and could be upgraded just once to support legacy client auth\n>> (shared-secret) and still migrate to admittedly superior client auth\n>> (PK-based).\n>> \n>> Why is there such resistance to this line of reasoning?  If rough\n>> concensus holds that the TLS standard cannot support both shared-secret\n>> and PK-based auth, then fine, take them both out and put them both in\n>> the application layer.  But give me one standard so that applications\n>> developers, customers and end-users don't have to be hamstrung by the\n>> differences in authentication technology.\n>> \n>> Don Schmidt\n>> Program Manager\n>> Microsoft Corp\n>> \n>> >----------\n>> >From:  Barb Fox\n>> >Sent:  Wednesday, October 09, 1996 5:01 PM\n>> >To:    Dan Simon; 'elgamal@netscape.com'\n>> >Cc:    'ietf-tls@w3.org'; 'treese@OpenMarket.com';\n>>'david.brownell@Eng.Sun.COM'\n>> >Subject:       RE: Closing on shared-key authentication\n>> >\n>> >>Taher:\n>> >>\n>> >>I just have to jump in here to clarify a couple of things.\n>> >>\n>> >>Yes, password authentication is a customer requirement.  Many companies\n>>tell\n>> >>us that they want a migration path from passwords to certificate-based\n>> >>systems within the TLS protocol standard.  This has been the sole reason\n>>we\n>> >>have been pushing so hard for password authentication...customer need.\n>>The\n>> >>business side of this argument has already been comprehensively presented\n>>by\n>> >>John Macko (Compuserve) in an earlier posting (7/22) so I don't want to\n>> >>start\n>> >>that chain again here.\n>> >>\n>> >>But Dan's comment about forward compatibilty in SSL has nothing to do\n>>with\n>> >>passwords per se.  Fact: there is no generic extensibility mechanism in\n>>SSL3\n>> >- and that's something we need to acknowledge and fix as soon as we can.\n>> >> The goal of this working group, after all, should be to create an\n>> >>architecturally-sound, extensible standard.  I admit that this will cause\n>>us\n>> >>all some pain as we find ourselves having to change our fielded\n>> >implementations to prepare for future advances in the protocol.  But if\n>> >>we bite the bullet and design the protocol correctly now, it shouldn't be\n>> >>such a big deal as we go incrementally forward.\n>> >\n>> >>Barb\n>> >>\n>> >>----------\n>> >>From:         elgamal@netscape.com[SMTP:elgamal@netscape.com]\n>> >>Sent:         Wednesday, October 09, 1996 8:49 AM\n>> >>To:   Dan Simon\n>> >>Cc:   'ietf-tls@w3.org'; 'treese@OpenMarket.com';\n>> >>'david.brownell@Eng.Sun.COM'\n>> >>Subject:      Re: Closing on shared-key authentication\n>> >>\n>> >>Dan,\n>> >>\n>> >>You bring an interesting point. In the design of SSL3.0, we did not\n>> >>expect that the protocol would have to support weaker authentication\n>> >>techniques, actually going backwards if you think about it. The idea of\n>> >>SSL3.0 was not to support everything that may exist or everything anyone\n>> >>can think of. So, you cannot really accuse SSL of not being forward\n>> >>compatible because it assumes a good authentication method rather than\n>> >>duplicate old ones that everyone has already implemented in any\n>> >>interesting application protocol. The only reason for me to entertain\n>> >>this password thing is that a customer thinks it is useful, not really\n>> >>because it adds anything to the protocol, on the contrary, it makes it\n>> >>less attractive since the level of authentication is not defined.\n>> >>\n>> >>Taher\n>> >>\n>> >>\n>> >>Dan Simon wrote:\n>> >>>\n>> >>> >From:  david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n>> >>> >\n>> >>> >I'll have to go back and look at the comments from last\n>> >>> >week's proposal (ssl-talk is where I saw most of it),\n>> >>> >but this proposal really doesn't seem \"cooked\" to me.\n>> >>> >\n>> >>> >   - Internationalization issues arise.  In what character\n>> >>> >     set do \"display_string\" and \"challenge\" appear?  How\n>> >>> >     is the language which the end user knows specified?\n>> >>> >\n>> >>> >     I don't like seeing application layer issues intrude\n>> >>> >     on transport layer protocols.\n>> >>>\n>> >>> The \"display_string\" field is opaque; that is, TLS simply transports it\n>> >>> without examining its content.  It is entirely the next level's\n>> >>> responsibility to figure out what to do with it (or even if it should\n>>be\n>> >>> sent in the first place).  Why is this an \"intrusion\" into the\n>>transport\n>> >>> layer, any more than, say, the presence of the opaque application data\n>> >>> which is passed through TLS as part of its basic function?\n>> >>> >\n>> >>> >   - Neither \"rough consensus\" nor (multiple instances of)\n>> >>> >     \"working code\" exists, as has been pointed out.\n>> >>> >\n>> >>> >     Many of us don't see a technical benefit to making TLS\n>> >>> >     be incompatible with SSLv3 in this respect, so I doubt\n>> >>> >     that a realistic \"consensus\" on this point can exist.\n>> >>>\n>> >>> Well, the real problem is that virtually *any* difference between TLS\n>> >>> and SSL 3.0 would make TLS incompatible with SSL 3.0, because SSL 3.0\n>> >>> simply lacks a mechanism for forward compatibility.  If we do nothing\n>> >>> else, we absolutely *must* prevent this problem from grandfathering its\n>> >>> way into TLS.  (The fix that's been suggested as least painful to SSL\n>> >>> 3.0 implementers is to specify that unrecognized handshake message\n>>types\n>> >>> be ignored--hence our use of new handshake message types to implement\n>> >>> shared-key authentication.  If someone has a better way to permit\n>> >>> extensibility, then I'd be happy to hear about it.)\n>> >>> >\n>> >>> >   - It's unclear just where in the handshake these new\n>> >>> >     messages would go.  Or are they even part of the\n>> >>> >     regular handshake protocol?  Do they go after the\n>> >>> >     \"Finished\" messages are exchanged, are they an\n>> >>> >     independent handshake, or what?\n>> >>>\n>> >>> The posted document specifies where the extra messages should go.\n>> >>> >\n>> >>> >   - Given that the amount of keying material to be built\n>> >>> >     is derived from the negotiated cipher spec, what's\n>> >>> >     the change needed in the definition of a cipher spec?\n>> >>> >     It needs to know it must generate CipherSpec.hash_size\n>> >>> >     (times two?) bytes of keying data.\n>> >>>\n>> >>> In SSL 3.0 (and presumably TLS), the actual keying material is not\n>> >>> included in the cipher_spec, but rather as part of the general\n>> >>> connection state.  Implementations that don't support shared-key\n>> >>> authentication can, of course, ignore the extra keying material\n>> >>> altogether.\n>> >>> >\n>> >>> >   - There's a new requirement, to ignore unrecognized\n>> >>> >     handshake messages rather than treat them as errors.\n>> >>> >     I prefer protocols to be fully specfied.\n>> >>>\n>> >>> If it's preferable, the specification can certainly require that\n>> >>> implementations recognize the extra handshake messages.  Of course, the\n>> >>> real problem here is SSL 3.0's lack of an extensibility mechanism; see\n>> >>> my comments above.\n>> >>> >\n>> >>> >I could raise more questions, but the fact that there are\n>> >>> >this many (after this much discussion!) says to me that the\n>> >>> >proposal should not be deemed \"cooked\" enough to incorporate\n>> >>> >into an IETF standard.\n>> >>>\n>> >>> To my mind, the problems with the proposal, as enumerated by David,\n>>cast\n>> >>> a worse light on SSL 3.0 than on the proposal itself.\n>> >>>\n>> >>>                                 Daniel Simon\n>> >>>                                 Cryptographer, Microsoft Corp.\n>> >>>                                 dansimon@microsoft.com\n>> >>>\n>> >>> >\n>> >>> >\n>> >>> >\n>> >>\n>> >>--\n>> >>Taher Elgamal     elgamal@netscape.com\n>> >>Chief Scientist, Netscape Communications\n>> >>(T) 415 937 2898, (F) 415 428 4054\n>> >>\n>> >>\n>> >\n>\n>-- \n>Taher Elgamal    elgamal@netscape.com\n>Chief Scientist, Netscape Communications\n>(T) 415 937 2898, (F) 415 428 4054\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "> \n> The lack of a general extension mechanism in SSL v3 is a feature, not a\n> bug.  This is a security protocol, and so susceptibility to analysis is\n> a good thing.  Simplicity and rigidity are features here.  SSL does\n> provide for forwards compatibility by allowing version negotiation and\n> protection from version rollback attacks.\n> \n\nI must take exception here - not with the advantages of making security\nprotocols easy to analyse, but with the implicit assertion that SSL - and\nin particular the RSA based authentication/key exchange - are easily\nanalysed.   As presented in the current RFC, SSL v3 is just about the \nmost complex security protocol I have ever looked at.\n\nIn particular, determining whether it is vulnerable to \"man in the middle\"\nattacks is extremely difficult - I'm still not entirely sure whether it is for\ncases where the server has no certificate.\n\nThe combination of hashing mechanisms, and the way in which they are used \nmake it virtually impossible to determine the effects of any properties \n(including weaknesses) inherent in the actual algorithms.\n\nI would very much like to see SSL support different (and simpler) authentication\nmechanisms.   Many have already been standardised - X.509 being a notable\nexample.\n\nSorry for the rant, but I just couldn't let this one go by...\n\nCheers,\n\nMichael Warner\nTelstra Research Labs\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Michael Warner wrote:\n> \n> > The lack of a general extension mechanism in SSL v3 is a feature,\n> > not a bug.  This is a security protocol, and so susceptibility to\n> > analysis is a good thing.  Simplicity and rigidity are features\n> > here.  SSL does provide for forwards compatibility by allowing\n> > version negotiation and protection from version rollback attacks.\n>\n> I must take exception here - not with the advantages of making\n> security protocols easy to analyse, but with the implicit assertion\n> that SSL - and in particular the RSA based authentication/key exchange\n> - are easily analysed.   As presented in the current RFC, SSL v3 is\n> just about the most complex security protocol I have ever looked at.\n\nFrankly, I'm baffled by this assertion.  Yes, SSL v3 is somewhat more\ncomplex than some other security protocols, but I don't think it is\nparticularly resistant to analysis.  Bruce Schneier and David Wagner\nhave performed an analysis of the protocol, and their paper contains no\nsuch complaints.\n\n> In particular, determining whether it is vulnerable to \"man in the\n> middle\" attacks is extremely difficult - I'm still not entirely sure\n> whether it is for cases where the server has no certificate.\n\nThere is an obvious man in the middle attack when the server has no\ncertificate since client authentication is expressly forbidden in this\ncase.\n\n> The combination of hashing mechanisms, and the way in which they are\n> used make it virtually impossible to determine the effects of any\n> properties (including weaknesses) inherent in the actual algorithms.\n\nYes, Schneier and Wagner also suggested the use of \"ad hoc MAC\nalgorithms\" was to be discouraged.  This is certainly one area in which\nSSL v3 could be improved.\n\n> I would very much like to see SSL support different (and simpler)\n> authentication mechanisms.   Many have already been standardised -\n> X.509 being a notable example.\n\nSSL does use X.509v3 certificates.  What kind of different\nauthentication mechanisms are you talking about?\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Marc VanHeyningen wrote:\n> \n> > - The only security reason for including password auth in TLS is\n> >   that it gains stronger security by having access to strong crypto\n> >   in the export case.  I don't think we should include features this\n> >   major based solely on brain-damaged US export regulations that\n> >   will hopefully soon change.\n> \n> Seems to me that's only if you assume the best way to secure password\n> auth is to just encrypt the password, as opposed to using other\n> more sophisticated methods.\n\nNo, you should certainly do something more than just send the password\nencrypted.  You should avoid sending the password at all, encrypted or\notherwise.  Some sort of challenge/response mechanism would be\nappropriate, but you are protected from eavesdroppers if you encrypt\nthe data.\n\n> It also is true only if you're willing to accept authentication that\n> is dependent upon the security of the encryption; some people feel\n> this is undesrable for reasons having nothing to do with export\n> regulations.\n\nDo you suggest that the encryption (even 40-bit) is the weak link in\nthis scheme?  I don't think so.  While there may be some advantages to\nbe gained by moving the dependency up to the security of the key\nexchange from that of the bulk cipher, I don't think they outweigh the\ndisadvantages.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Jeff Williams wrote:\n> \n> At 12:30 PM 10/10/96 -0700, you wrote:\n>\n>> You are quite correct.  However, short term customer requirements for\n>> password authentication can be met by using existing authentication\n>> mechanisms in existing protocols.  There is no need to add a\n>> mechanism to TLS when all existing protocols already have a password\n>> mechanims.\n> \n>   I realize that.  But my concern is not just that we may need to\n> consider adding it to TLS for those customers whom believe in that\n> mechanism, all be it not necessary, possibly.  Again I still believe\n> that a \"Common\" Protocol interface well featured would go a long ways\n> in solving or addressing some short term problems at teh very least. \n> Extensions to that interface for enhancments to existiing or possably\n> new protocols, would also project a method of achieving long term\n> desires here.  Don't you think this makes some sense?\n\nThere is already an existing mechanism that allows compatibility between\nversions.  Rather than providing an extension mechanism that will just\nencourage fragmentation of the protocol, I'd rather see us achieve\nconsensus on useful features and include them in future revisions.\n\n>> Even if you think we'll be limited to 40-bit for export forever, do\n>> you really believe that any password scheme is going to provide\n>> better than 40 bits worth of security for authentication?  If you can\n>> remember a password with 40 bits of entropy then you have a better\n>> memory than I do.\n> \n>   No of course not.  I couldn't remember much more than 10! ;)  But is\n> it really necessary to remember.  I can be pluged into the login\n> procedure.\n\nThe main distinction I've heard between password authentication and\npublic key crypto authentication is that a password can be carried\nin your head.  If you're using a floppy or other hardware token to\ntransport your password, why not just use it to transport your private\nkey?\n\n>> As to the lifting of export restrictions, the White House is already\n>> talking about raising the limit to 56 bits, and there is legislation\n>> pending that would lift export restrictions altogether.  I feel very\n>> strongly that an international standard should not be burdened with\n>> major features with such substantial security implications for\n>> reasons of local governmental policy.\n> \n>   56 bits is a total waste of time in my opinion.  It wouldn't take\n> much more than 3 seconds to break that!  Without at least 128 bits\n> being approved for export international companies will not support\n> commerce for long on the net.  In addition, even 128 bit in my humble\n> opinion is a bit short of what I would like to see.\n\nI agree with you that 56 bits is a very small step, and provides only\nslightly more security than 40.  However, it does indicate that times\nmay be changing and we should not view current US export policy as set\nin stone.\n\n>   With reguard to what you say reguarding local gov. policy, I am not\n> quite clear as to what you mean here?  Explain please, ok?\n\nThe IETF is an international standards organization.  Should we design\nour protocols to conform to US policy?  French policy?  Japanese policy?\nI think not.  We should design TLS to be as secure as possible.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "> No, you should certainly do something more than just send the password\n> encrypted.  You should avoid sending the password at all, encrypted or\n> otherwise.  Some sort of challenge/response mechanism would be\n> appropriate, but you are protected from eavesdroppers if you encrypt\n> the data.\n\nTrue.  I'm clearly misunderstanding you then.  You said previously:\n\n>There is no need to add a mechanism\n>to TLS when all existing protocols already have a password mechanims.\n\nI assumed the password mechanisms that you meant there were\ncleartext ones, not more sophisticated ones based on challenge-response\nor keyed hashes or anything else.  Was I wrong?\n\nI believe there is a need to add a mechanism to TLS because, while all\nexisting protocols have password mechanisms, they're lousy ones.\n\n- Marc\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Marc VanHeyningen writes:\n> \n> > No, you should certainly do something more than just send the password\n> > encrypted.  You should avoid sending the password at all, encrypted or\n> > otherwise.  Some sort of challenge/response mechanism would be\n> > appropriate, but you are protected from eavesdroppers if you encrypt\n> > the data.\n> \n> True.  I'm clearly misunderstanding you then.  You said previously:\n> \n> >There is no need to add a mechanism\n> >to TLS when all existing protocols already have a password mechanims.\n> \n> I assumed the password mechanisms that you meant there were\n> cleartext ones, not more sophisticated ones based on challenge-response\n> or keyed hashes or anything else.  Was I wrong?\n\nSort of.  They're cleartext unless the entire exchange is protected\nby TLS.  Then they're encrypted in whatever ciphersuite TLS\nnegotiated.  Obviously when you are negotiating use/non-use\nof TLS in an existing protocol, you must start TLS before\nsending the username/password.\n\n> I believe there is a need to add a mechanism to TLS because, while all\n> existing protocols have password mechanisms, they're lousy ones.\n\nThe only advantage to embedding passwords is being able to\nuse \"non-export\" encryption on the password, _IF_ the protocol\nis designed so that no one can use the password field to\nexchange \"random data\".  If I can write an app to use\nTLS/password auth to send words (say as \"login attempts\")\nof my own choosing under strong encryption, the NSA will not\nallow export of the scheme.  I have not reviewed the latest\nTLS password proposal, so I do not know if it will meet\nthe NSA's requirements.  Has anyone asked them yet?\n\nIn any case, I agree with Tom that we should not be designing\nthe TLS protocol to meet the US crypto policy flavor-of-the-month.\nBesides the fact that they can change it on any political\nwhim, rendering our work invalid, TLS is an international\nstandard.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "In the case of HTTP, digest authentication can be used.  It's part of\nthe HTTP/1.1 spec, and it's thought to be fairly strong.  See\n\nhttp://www.w3.org/pub/WWW/Protocols/Specs.html#Digest\n\nIn my book, Digest Auth over TLS (even export strength) is just fine for\nshared secret authentication.  I believe other application protocols have\none-time-password extensions, or they could support a mechanism similar\nto HTTP digest auth (adding it to telnet and ftp would be straightforward).\n\nI don't see sufficient benefit added by shared secret auth in TLS to\njustify the increased protocol and application complexity.\n\nAdam\n\n\n\nOn Oct 11, 12:44pm, Eric Murray wrote:\n> Subject: Re: Closing on shared-key authentication\n>\n> Marc VanHeyningen writes:\n> >\n> > > No, you should certainly do something more than just send the password\n> > > encrypted.  You should avoid sending the password at all, encrypted or\n> > > otherwise.  Some sort of challenge/response mechanism would be\n> > > appropriate, but you are protected from eavesdroppers if you encrypt\n> > > the data.\n> >\n> > True.  I'm clearly misunderstanding you then.  You said previously:\n> >\n> > >There is no need to add a mechanism\n> > >to TLS when all existing protocols already have a password mechanims.\n> >\n> > I assumed the password mechanisms that you meant there were\n> > cleartext ones, not more sophisticated ones based on challenge-response\n> > or keyed hashes or anything else.  Was I wrong?\n>\n> Sort of.  They're cleartext unless the entire exchange is protected\n> by TLS.  Then they're encrypted in whatever ciphersuite TLS\n> negotiated.  Obviously when you are negotiating use/non-use\n> of TLS in an existing protocol, you must start TLS before\n> sending the username/password.\n>\n> > I believe there is a need to add a mechanism to TLS because, while all\n> > existing protocols have password mechanisms, they're lousy ones.\n>\n> The only advantage to embedding passwords is being able to\n> use \"non-export\" encryption on the password, _IF_ the protocol\n> is designed so that no one can use the password field to\n> exchange \"random data\".  If I can write an app to use\n> TLS/password auth to send words (say as \"login attempts\")\n> of my own choosing under strong encryption, the NSA will not\n> allow export of the scheme.  I have not reviewed the latest\n> TLS password proposal, so I do not know if it will meet\n> the NSA's requirements.  Has anyone asked them yet?\n>\n> In any case, I agree with Tom that we should not be designing\n> the TLS protocol to meet the US crypto policy flavor-of-the-month.\n> Besides the fact that they can change it on any political\n> whim, rendering our work invalid, TLS is an international\n> standard.\n>\n>\n> --\n> Eric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\n> PGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29\nAF\n>\n>-- End of excerpt from Eric Murray\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Eric Murray sed:\n> > I assumed the password mechanisms that you meant there were\n> > cleartext ones, not more sophisticated ones based on challenge-response\n> > or keyed hashes or anything else.  Was I wrong?\n> \n> Sort of.  They're cleartext unless the entire exchange is protected\n> by TLS.  Then they're encrypted in whatever ciphersuite TLS\n> negotiated. \n\nYes, of course; maybe I should have made that clearer.\n\nIn other words, you're doing password authentication by just sending\nthe password encrypted, which Tom and I (and I suspect most other\npeople here) agree is not a very good way to do it.\n\n> The only advantage to embedding passwords is being able to\n> use \"non-export\" encryption on the password, _IF_ the protocol\n> is designed so that no one can use the password field to\n> exchange \"random data\". \n\nNo, another advantage is being able to use challenge-response\nmechanisms based on passwords (or challenge-response \nmechanisms based on SecurID tokens or whatever) and not\nrequiring encryption at all (might encrypt it anyway, but the\nsecurity of it need not depend on that.)\n\n> In any case, I agree with Tom that we should not be designing\n> the TLS protocol to meet the US crypto policy flavor-of-the-month.\n\nI also agree with this, BTW.\n\n- Marc\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Tom,\n\nPlease read below your comments.\n\nAt 10:51 AM 10/11/96 -0700, you wrote:\n>Marc VanHeyningen wrote:\n>> \n>> > - The only security reason for including password auth in TLS is\n>> >   that it gains stronger security by having access to strong crypto\n>> >   in the export case.  I don't think we should include features this\n>> >   major based solely on brain-damaged US export regulations that\n>> >   will hopefully soon change.\n>> \n>> Seems to me that's only if you assume the best way to secure password\n>> auth is to just encrypt the password, as opposed to using other\n>> more sophisticated methods.\n>\n>No, you should certainly do something more than just send the password\n>encrypted.  You should avoid sending the password at all, encrypted or\n>otherwise.  Some sort of challenge/response mechanism would be\n>appropriate, but you are protected from eavesdroppers if you encrypt\n>the data.\n\n  I think that this is a good idea to incorporate in TLS, or at least provide\nfor that option in the protocol.\n>\n>> It also is true only if you're willing to accept authentication that\n>> is dependent upon the security of the encryption; some people feel\n>> this is undesrable for reasons having nothing to do with export\n>> regulations.\n>\n>Do you suggest that the encryption (even 40-bit) is the weak link in\n>this scheme?  I don't think so.  While there may be some advantages to\n>be gained by moving the dependency up to the security of the key\n>exchange from that of the bulk cipher, I don't think they outweigh the\n>disadvantages.\n\n  I just can't agree compleatly with you here Tom.  40 bit has already been\nbroken and can easly be broken again in about 2 seconds.  \n\nReguards,\n\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Tom,\n\n  Please read below your comments,\n\nAt 11:06 AM 10/11/96 -0700, you wrote:\n>Jeff Williams wrote:\n>> \n>> At 12:30 PM 10/10/96 -0700, you wrote:\n>>\n>>> You are quite correct.  However, short term customer requirements for\n>>> password authentication can be met by using existing authentication\n>>> mechanisms in existing protocols.  There is no need to add a\n>>> mechanism to TLS when all existing protocols already have a password\n>>> mechanims.\n>> \n>>   I realize that.  But my concern is not just that we may need to\n>> consider adding it to TLS for those customers whom believe in that\n>> mechanism, all be it not necessary, possibly.  Again I still believe\n>> that a \"Common\" Protocol interface well featured would go a long ways\n>> in solving or addressing some short term problems at teh very least. \n>> Extensions to that interface for enhancments to existiing or possably\n>> new protocols, would also project a method of achieving long term\n>> desires here.  Don't you think this makes some sense?\n>\n>There is already an existing mechanism that allows compatibility between\n>versions.  Rather than providing an extension mechanism that will just\n>encourage fragmentation of the protocol, I'd rather see us achieve\n>consensus on useful features and include them in future revisions.\n\n  Ok, I would agree with this in principal.  This could be fairly easly done\nas part of the TLS protocol and still provide for other interfaces that may\nbe developed in the future.  If that is how you invision feature revisions,\nthan I would totaly agree.  It really becomes a matter of technique as a\npart of development here I think however.\n>\n>>> Even if you think we'll be limited to 40-bit for export forever, do\n>>> you really believe that any password scheme is going to provide\n>>> better than 40 bits worth of security for authentication?  If you can\n>>> remember a password with 40 bits of entropy then you have a better\n>>> memory than I do.\n>> \n>>   No of course not.  I couldn't remember much more than 10! ;)  But is\n>> it really necessary to remember.  I can be pluged into the login\n>> procedure.\n>\n>The main distinction I've heard between password authentication and\n>public key crypto authentication is that a password can be carried\n>in your head.  If you're using a floppy or other hardware token to\n>transport your password, why not just use it to transport your private\n>key?\n\n  Yes this is definatly a acceptable approach.  I would think this could\nalso be done by pulling it from the CA as well without the need of any\nhardware token as well.  Had you thought about that possibility?\n>\n>>> As to the lifting of export restrictions, the White House is already\n>>> talking about raising the limit to 56 bits, and there is legislation\n>>> pending that would lift export restrictions altogether.  I feel very\n>>> strongly that an international standard should not be burdened with\n>>> major features with such substantial security implications for\n>>> reasons of local governmental policy.\n>> \n>>   56 bits is a total waste of time in my opinion.  It wouldn't take\n>> much more than 3 seconds to break that!  Without at least 128 bits\n>> being approved for export international companies will not support\n>> commerce for long on the net.  In addition, even 128 bit in my humble\n>> opinion is a bit short of what I would like to see.\n>\n>I agree with you that 56 bits is a very small step, and provides only\n>slightly more security than 40.  However, it does indicate that times\n>may be changing and we should not view current US export policy as set\n>in stone.\n\n  This is still not acceptable in my mind.  I do understand the problems with\nUS export policy and the concerns with security associated with it.  I have\nto believe that we in the industry or private sector need to lead here \nhowever, not follow.  Without at least 128 bit, we are not really providing\nfor our own protection in an adaquate manner.\n>\n>>   With reguard to what you say reguarding local gov. policy, I am not\n>> quite clear as to what you mean here?  Explain please, ok?\n>\n>The IETF is an international standards organization.  Should we design\n>our protocols to conform to US policy?  French policy?  Japanese policy?\n>I think not.  We should design TLS to be as secure as possible.\n\n  Exactly!  I think that we need to get input from all nations and ask for and\ninclude their input as a intragle part of design.  That is however where it\nget's\na bit tricky.  I think that possibly a \"Joint Lab\" for just such a process needs\nsome thought here.  What do you think?  That way providing for all nations\nconcerns will be addressed and TLS would evolve into being as secure as \npossible.\n\nReguards,\n\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Mark,\n\n  Please read below your comments.\n\nAt 11:39 AM 10/11/96 -0700, you wrote:\n>> No, you should certainly do something more than just send the password\n>> encrypted.  You should avoid sending the password at all, encrypted or\n>> otherwise.  Some sort of challenge/response mechanism would be\n>> appropriate, but you are protected from eavesdroppers if you encrypt\n>> the data.\n>\n>True.  I'm clearly misunderstanding you then.  You said previously:\n>\n>>There is no need to add a mechanism\n>>to TLS when all existing protocols already have a password mechanims.\n>\n>I assumed the password mechanisms that you meant there were\n>cleartext ones, not more sophisticated ones based on challenge-response\n>or keyed hashes or anything else.  Was I wrong?\n>\n>I believe there is a need to add a mechanism to TLS because, while all\n>existing protocols have password mechanisms, they're lousy ones.\n\n  Here here!  I agree. The current password mechanism is definatly flawed\nor is te easely accessed.  And chalange/response mechanism might also be \nincluded as well as an option or feature.\n\nReguards,\n \n>\n>- Marc\n>\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Marc VanHeyningen writes:\n \n> In other words, you're doing password authentication by just sending\n> the password encrypted, which Tom and I (and I suspect most other\n> people here) agree is not a very good way to do it.\n\nWhy not?\n\n> > The only advantage to embedding passwords is being able to\n> > use \"non-export\" encryption on the password, _IF_ the protocol\n> > is designed so that no one can use the password field to\n> > exchange \"random data\". \n> \n> No, another advantage is being able to use challenge-response\n> mechanisms based on passwords (or challenge-response \n> mechanisms based on SecurID tokens or whatever) and not\n> requiring encryption at all (might encrypt it anyway, but the\n> security of it need not depend on that.)\n\nIf you don't require encryption why are you using TLS?\n(yea I know about the MAC-only ciphersuites, but they're not used\nin practice).\n\nThere's other simpler protocols that implement challenge-response\nauthentication, why not use one of those if that's all you want?\n\n\nAre we talking about the same things?  \"just sending the password encrypted\"\nto me means doing a complete TLS handshake and then sending the password\nas TLSed data, protected by the encryption/MAC negotiated by TLS.  Except for\nthe problem of having to use 'export'-quality encryption to protect your\nauthentication (which is an artifact of US government crypto policy and\nnot a technical problem), I can't see anything wrong with it.\nSo I must be misunderstanding the point that you're trying to make.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Marc VanHeyningen wrote:\n> \n>> No, you should certainly do something more than just send the\n>> password encrypted.  You should avoid sending the password at all,\n>> encrypted or otherwise.  Some sort of challenge/response mechanism\n>> would be appropriate, but you are protected from eavesdroppers if you\n>> encrypt the data.\n> \n> True.  I'm clearly misunderstanding you then.  You said previously:\n> \n>> There is no need to add a mechanism to TLS when all existing\n>> protocols already have a password mechanims.\n> \n> I assumed the password mechanisms that you meant there were\n> cleartext ones, not more sophisticated ones based on\n> challenge-response or keyed hashes or anything else.  Was I wrong?\n\nWell, for example, HTTP has digest authentication.  POP3 and IMAP are\nadding similar mechanisms.  Yes, the telnet password mechanism is\ncompletely horrible, but there are protocols for which that is not true.\n\n> I believe there is a need to add a mechanism to TLS because, while all\n> existing protocols have password mechanisms, they're lousy ones.\n\nYes, a lot of existing protocols have lousy password mechanisms.  But\nto integrate any sort of TLS password mechanism, you're going to have\nto change the protocol if for no other reason than to STOP sending the\npassword in the clear.  If you're going to do that, why not just fix\nthe protocol?\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Thoughts on sharedkey authenticatio",
            "content": "-----BEGIN PRIVACY-ENHANCED MESSAGE-----\nProc-Type: 4,MIC-CLEAR\nContent-Domain: RFC822\nOriginator-Certificate:\n MIIBvzCCAWkCEFmOln6ip0w49CuyWr9vDVUwDQYJKoZIhvcNAQECBQAwWTELMAkG\n A1UEBhMCVVMxGDAWBgNVBAoTD1NlY3VyZVdhcmUgSW5jLjEXMBUGA1UECxMOU2Vj\n dXJlV2FyZSBQQ0ExFzAVBgNVBAsTDkVuZ2luZWVyaW5nIENBMB4XDTk1MDUwODIw\n MjMzNVoXDTk3MDUwNzIwMjMzNVowcDELMAkGA1UEBhMCVVMxGDAWBgNVBAoTD1Nl\n Y3VyZVdhcmUgSW5jLjEXMBUGA1UECxMOU2VjdXJlV2FyZSBQQ0ExFzAVBgNVBAsT\n DkVuZ2luZWVyaW5nIENBMRUwEwYDVQQDEwxDaGFybGVzIFdhdHQwWTAKBgRVCAEB\n AgICBANLADBIAkEM2ZSp7b6eqDqK5RbPFpd6DGSLjbpHOZU07pUcdgJXiduj9Ytf\n 1rsmf/adaplQr+X5FeoIdT/bVSv2MUi3gY0eFwIDAQABMA0GCSqGSIb3DQEBAgUA\n A0EApEjzeBjiSnGImJXgeY1K8HWSufpJ2DpLBF7DYqqIVAX9H7gmfOJhfeGEYVjK\n aTxjgASxqHhzkx7PkOnL4JrN+Q==\nMIC-Info: RSA-MD5,RSA,\n BwP+eZsNFRAvH/278pFEFxJYn4qugayrKLxU0mEYckY5DDWVTbDex6Dpjq8jAncW\n 1ydDgePOn0MDaLcb6Er+czg=\n\nThere are many applications that have a much stronger requirement for\ndata authenticity than for confidentiality.  As an example, retail\nbanking over the Internet.  (Please hold any comments on the specific\nexample.  If you do not like it, think for a while and you will be able \nto find an example that your prefer that meets these criteria).  40-bit \nkeys for encryption are adequate for things like viewing your check \nregister -- there are MUCH easier ways for an attacker to gain access to \nyour transaction data than breaking a 40-bit key (e.g., if in the US the\nodds are pretty good that your bank supports telephone banking where all \nI need is your account number from your check and your SSN, which I can \nlook up on the Web).  However, the authorization of bill payments requires \na full 128-bits of authenticity -- definitely not cool if an attacker can \npay your bills for you.\n\nWhen servicing a customer base of > 1 million account holders, it is:\n\n1) an onerous administrative task\n2) a horrendous performance hit on the server\n\nto use client-side certificates -- particularly in light of the fact \nthat most banks have already distributed via manual methods sufficient \ninformation to authenticate customers (e.g., ATM cards and PINs) that \ncould be used in an automated fashion by an on-line bank server.\n\nIt is quite possible to build into TLS a shared-secret authentication\nmechanism that is exportable and whose strength is independent of the\nstrength of the encryption.  We run an example of such a mechanism in \nour lab:\n\na) modify a public-domain implementation of MD5 or SHA to add\n    procedures for saving and restoring the internal state\n   registers -- an easy task.\n\nb) on the server, create a one-way hash of the customer password\n   by running your modified hash function over the password.\n   Save the internal state registers of the hash function and throw \n   away the password.\n\nc) when the customer logs in, have the server send a one-time nonce\n   to the browser.\n\nd) have the client prompt the customer for the customer's password.\n   The client calculates the one way hash of password + nonce.\n\ne) send the resulting hash value to the server.  Note that a standard\n   version of the hash function is all you need on the client.\n\nf) server verifies customer password by restoring the hash function\n   registers and performing the final hash cycle over just the\n   nonce.\n\nCharles Watt\nSecurity First Network Bank\nwww.sfnb.com\n\nP.S:\nEven though we built this in the lab with the intent of providing it for\nour international banks, we were never able to deploy it due to a security\nflaw in all SSL-capable Web servers that were available at the time -- no one \nprovided an interface by which the application running on the server could \naccess the SSL session ID.  Without access to the session ID to link \nsuccessive connections into a login session, the 128-bit keyed hash provided \nby SSL is worthless to the application.  Instead the app must fall back on \nthe cookie mechanism as a way to link a login session.  But cookies are\nprotected using 40-bit encryption, reducing the assurance with which you can \nlink successive connections from 128 --> 40 bits.  \n\nIn the end it was easier to find an off-shore solution to the crypto problem \nthan to get the big name server vendors to support secure applications.\n\n-----END PRIVACY-ENHANCED MESSAGE-----\n\n\n\n"
        },
        {
            "subject": "Re: Thoughts on sharedkey authenticatio",
            "content": "Charles Watt writes:\n \n> When servicing a customer base of > 1 million account holders, it is:\n> \n> 1) an onerous administrative task\n> 2) a horrendous performance hit on the server\n> \n> to use client-side certificates -- particularly in light of the fact \n> that most banks have already distributed via manual methods sufficient \n> information to authenticate customers (e.g., ATM cards and PINs) that \n> could be used in an automated fashion by an on-line bank server.\n\nOk, I can agree with that, although using client certificates only\ndoubles the amount of public-key operations that the server has to do\n(which doesn't double the CPU time required to set up a TLS session\nas there's more than just public-key operations in that CPU time).\n\nMy solution to your problem would be to use TLS\nto negotiate a secure channel (i.e. SSL_RSA_WITH_RC4_128_MD5)\nwith the client, without client auth.  The server is authenticated in\nthe usual way.  Once the TLS handshake is done the user sends her\naccount number, PIN, whatever that authenticates her to the bank, in\nthe application protocol.  TLS is (supposedly) secure\nso her authentication info is transmitted safely.\nIf the account number + PIN is considered by the bank to be\nenough to authenticate the user, and its sent in a secure fashion, what\nelse is needed?\n\nOnce client certs are in place, the TLS server, when it accepts\nthe client cert, can notify the bank application that requires\nthe authentication so that it doesn't demand the PIN.\nI think that this data (did the client provide a valid cert)\nis probably required of any TLS API.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Tom Weinstein said:\n> Marc VanHeyningen wrote:\n> > True.  I'm clearly misunderstanding you then.  You said previously:\n> > \n> >> There is no need to add a mechanism to TLS when all existing\n> >> protocols already have a password mechanims.\n> > \n> > I assumed the password mechanisms that you meant there were\n> > cleartext ones, not more sophisticated ones based on\n> > challenge-response or keyed hashes or anything else.  Was I wrong?\n> \n> Well, for example, HTTP has digest authentication.  POP3 and IMAP are\n> adding similar mechanisms.  Yes, the telnet password mechanism is\n> completely horrible, but there are protocols for which that is not true.\n\nYes, there are a few protocols which offer better shared-secret\nauthentication.  Not most, and certainly not \"all,\" and even things\nlike HTTP digest auth are not widely supported or used.\n\n> Yes, a lot of existing protocols have lousy password mechanisms.  But\n> to integrate any sort of TLS password mechanism, you're going to have\n> to change the protocol if for no other reason than to STOP sending the\n> password in the clear.  If you're going to do that, why not just fix\n> the protocol?\n\nI don't understand this claim at all.\nMost protocols that support passwords also support not having them,\nand even if they don't you can just use a bogus one.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Eric Murray sed:\n> Marc VanHeyningen writes:\n> > In other words, you're doing password authentication by just sending\n> > the password encrypted, which Tom and I (and I suspect most other\n> > people here) agree is not a very good way to do it.\n> \n> Why not?\n\nLots of reasons; I'll mention a few.  \n\nBecause ciphers can be broken.  Because some people believe it's\nunhygenic to have the security of authentication be dependent upon\nthe security of bulk encryption.\n\nThere are also simple usability concerns.  Users occasionally get\nmixed up and, while using service A, accidentally type their\npassword for service B.  If you do things your way, you have just\ngiven service A your password for service B, which is not\nnecessarily information you wanted him to have.  If you use a\nchallenge-based method, you have given him one specific\nresponse to one specific challenge, which is of little if any\nvalue as a tool for impersonating you in the future.\n\nPersistent shared secrets shouldn't ever be sent in a reversibly\nencrypted form unless there's no alternative.\n\n> > No, another advantage is being able to use challenge-response\n> > mechanisms based on passwords (or challenge-response \n> > mechanisms based on SecurID tokens or whatever) and not\n> > requiring encryption at all (might encrypt it anyway, but the\n> > security of it need not depend on that.)\n> \n> If you don't require encryption why are you using TLS?\n> (yea I know about the MAC-only ciphersuites, but they're not used\n> in practice).\n\nI trust HMAC-composed SHA-1 more than I trust 40-bit RC4, \nor even 128-bit RC4.  Don't you?\n\n> There's other simpler protocols that implement challenge-response\n> authentication, why not use one of those if that's all you want?\n\nAre you referring to SASL, or what?\n\n> Are we talking about the same things?  \"just sending the password encrypted\"\n> to me means doing a complete TLS handshake and then sending the password\n> as TLSed data, protected by the encryption/MAC negotiated by TLS.  Except for\n> the problem of having to use 'export'-quality encryption to protect your\n> authentication (which is an artifact of US government crypto policy and\n> not a technical problem), I can't see anything wrong with it.\n> So I must be misunderstanding the point that you're trying to make.\n\nIt means the password can be decrypted.  I prefer to only send my password\nout in a fashion that cannot be decrypted, ever, by anyone.\n\n- Marc\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Jeff Williams wrote:\n> \n> At 11:06 AM 10/11/96 -0700, you wrote:\n>\n>> The main distinction I've heard between password authentication and\n>> public key crypto authentication is that a password can be carried\n>> in your head.  If you're using a floppy or other hardware token to\n>> transport your password, why not just use it to transport your\n>> private key?\n> \n>   Yes this is definatly a acceptable approach.  I would think this\n> could also be done by pulling it from the CA as well without the need\n> of any hardware token as well.  Had you thought about that\n> possibility?\n\nSurely you aren't proposing that the CA would have your private key?\n\n>> I agree with you that 56 bits is a very small step, and provides only\n>> slightly more security than 40.  However, it does indicate that times\n>> may be changing and we should not view current US export policy as\n>> set in stone.\n>\n>   This is still not acceptable in my mind.  I do understand the\n> problems with US export policy and the concerns with security\n> associated with it.  I have to believe that we in the industry or\n> private sector need to lead here however, not follow.  Without at\n> least 128 bit, we are not really providing for our own protection in\n> an adaquate manner.\n\nOf course it's not acceptable.  It won't be acceptable until there are\nno restrictions on crypto whatsoever.  Just because the current\npolitical climate in the US imposes certain restrictions does not mean\nthat we should enshrine them in an IETF standard.\n\n>> The IETF is an international standards organization.  Should we\n>> design our protocols to conform to US policy?  French policy? \n>> Japanese policy?  I think not.  We should design TLS to be as secure\n>> as possible.\n> \n>   Exactly!  I think that we need to get input from all nations and ask\n> for and include their input as a intragle part of design.  That is\n> however where it get's a bit tricky.  I think that possibly a \"Joint\n> Lab\" for just such a process needs some thought here.  What do you\n> think?  That way providing for all nations concerns will be addressed\n> and TLS would evolve into being as secure as possible.\n\nWe should construct a protocol that is secure.  As an international\nstandard, we should not worry too much about anything any one country\ndoes.  In France, cryptography is illegal.  What do you suggest we do?\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Jeff Williams wrote:\n> \n> At 10:51 AM 10/11/96 -0700, you wrote:\n>\n>> Do you suggest that the encryption (even 40-bit) is the weak link in\n>> this scheme?  I don't think so.  While there may be some advantages\n>> to be gained by moving the dependency up to the security of the key\n>> exchange from that of the bulk cipher, I don't think they outweigh\n>> the disadvantages.\n> \n>   I just can't agree compleatly with you here Tom.  40 bit has already\n> been broken and can easly be broken again in about 2 seconds.\n\n40 bit can be broken in about a week with approximately $400 worth of\nhardware.  The NSA can probably break it in some small number of\nseconds.  All of that is completely immaterial because the selection of\nthe password is the weak link here.  Do you really think you can\nremember a password with more than 40 bits if entropy?\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Thoughts on sharedkey authenticatio",
            "content": "> Ok, I can agree with that, although using client certificates only\n> doubles the amount of public-key operations that the server has to do\n\nIt does?  How do you figure that?  Does that include verifying the\nsignatures on the certificate chain and checking the CRLs?\n\n- Marc\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Marc VanHeyningen writes:\n> \n> Eric Murray sed:\n> > Marc VanHeyningen writes:\n> > > In other words, you're doing password authentication by just sending\n> > > the password encrypted, which Tom and I (and I suspect most other\n> > > people here) agree is not a very good way to do it.\n> > \n> > Why not?\n> \n> Lots of reasons; I'll mention a few.  \n\n[..]\n\nThanks.\n\n\n> I trust HMAC-composed SHA-1 more than I trust 40-bit RC4, \n> or even 128-bit RC4.  Don't you?\n\nYep.  But I think 128-bit RC4 is \"good enough\" for passwords\nthat change oftener than every 40 years. (see schneier 2nd ed. pp 167).\n40-bit, of course, is not.\n\n \n> > Are we talking about the same things?  \"just sending the password encrypted\"\n> > to me means doing a complete TLS handshake and then sending the password\n> > as TLSed data, protected by the encryption/MAC negotiated by TLS.  Except for\n> > the problem of having to use 'export'-quality encryption to protect your\n> > authentication (which is an artifact of US government crypto policy and\n> > not a technical problem), I can't see anything wrong with it.\n> > So I must be misunderstanding the point that you're trying to make.\n> \n> It means the password can be decrypted.  I prefer to only send my password\n> out in a fashion that cannot be decrypted, ever, by anyone.\n\n\nSo, to sum up the arguments for password auth in TLS, the reasons are:\n\n1. 40-bit export ciphers are too weak to protect passwords.\nWith password auth, TLS could use stronger authentication-only\ncrypto to protect password material.\n\n2. it's \"unhygenic\" to send passwords themselves, so apps should\nsend hashes of them, possibly including a challenge.  Since someone would\nhave to re-write existing password-based protocols to do this, it\nshould be placed in TLS, to make it easier to do. \n\n\nAny more?\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "At 03:50 PM 10/11/96 -0700, you wrote:\n>Eric Murray sed:\n>> Marc VanHeyningen writes:\n>> > In other words, you're doing password authentication by just sending\n>> > the password encrypted, which Tom and I (and I suspect most other\n>> > people here) agree is not a very good way to do it.\n>> \n>> Why not?\n>\n>Lots of reasons; I'll mention a few.  \n>\n>Because ciphers can be broken.  Because some people believe it's\n>unhygenic to have the security of authentication be dependent upon\n>the security of bulk encryption.\n\n  Ok, but that is still not a really strong argument.  I do see your point\nhowever.\n>\n>There are also simple usability concerns.  Users occasionally get\n>mixed up and, while using service A, accidentally type their\n>password for service B.  If you do things your way, you have just\n>given service A your password for service B, which is not\n>necessarily information you wanted him to have.  If you use a\n>challenge-based method, you have given him one specific\n>response to one specific challenge, which is of little if any\n>value as a tool for impersonating you in the future.\n\n  I would agree that this could be a problem.  But if you have the ability to \nchange your password that negates most of the problem here.\n>\n>Persistent shared secrets shouldn't ever be sent in a reversibly\n>encrypted form unless there's no alternative.\n  \n  Sorry, I don't believe in absolutes.  At present I would agree if possible\nyou are correct.\n>\nReguards,\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Tom,\n\n  Please read below your comments.\n\nAt 04:11 PM 10/11/96 -0700, you wrote:\n>Jeff Williams wrote:\n>> \n>> At 11:06 AM 10/11/96 -0700, you wrote:\n>>\n>>> The main distinction I've heard between password authentication and\n>>> public key crypto authentication is that a password can be carried\n>>> in your head.  If you're using a floppy or other hardware token to\n>>> transport your password, why not just use it to transport your\n>>> private key?\n>> \n>>   Yes this is definatly a acceptable approach.  I would think this\n>> could also be done by pulling it from the CA as well without the need\n>> of any hardware token as well.  Had you thought about that\n>> possibility?\n>\n>Surely you aren't proposing that the CA would have your private key?\n\n  Oh no, of course not.\n>\n>>> I agree with you that 56 bits is a very small step, and provides only\n>>> slightly more security than 40.  However, it does indicate that times\n>>> may be changing and we should not view current US export policy as\n>>> set in stone.\n>>\n>>   This is still not acceptable in my mind.  I do understand the\n>> problems with US export policy and the concerns with security\n>> associated with it.  I have to believe that we in the industry or\n>> private sector need to lead here however, not follow.  Without at\n>> least 128 bit, we are not really providing for our own protection in\n>> an adaquate manner.\n>\n>Of course it's not acceptable.  It won't be acceptable until there are\n>no restrictions on crypto whatsoever.  Just because the current\n>political climate in the US imposes certain restrictions does not mean\n>that we should enshrine them in an IETF standard.\n\n  Ok, I guess from previous comments there seemed to be some latitude expressed.\nI believe that sometimes industry must lead government policies.  It is clear\nthat some political work is needed here.\n>\n>>> The IETF is an international standards organization.  Should we\n>>> design our protocols to conform to US policy?  French policy? \n>>> Japanese policy?  I think not.  We should design TLS to be as secure\n>>> as possible.\n>> \n>>   Exactly!  I think that we need to get input from all nations and ask\n>> for and include their input as a intragle part of design.  That is\n>> however where it get's a bit tricky.  I think that possibly a \"Joint\n>> Lab\" for just such a process needs some thought here.  What do you\n>> think?  That way providing for all nations concerns will be addressed\n>> and TLS would evolve into being as secure as possible.\n>\n>We should construct a protocol that is secure.  As an international\n>standard, we should not worry too much about anything any one country\n>does.  In France, cryptography is illegal.  What do you suggest we do?\n\n  Right!  Not any ONE country.  BUt my suggestion is a colabrative effort\nthat would need to be orginized by all currently involved at the Corp.\nlevel and a joint lab development facility be set up with other countries \ncorp experts participatiing.  What do you think?\n\nReguards,\n\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "RE: Closing on sharedkey authenticatio",
            "content": "Eric:\n\nYes, we did review the latest password authentication scheme with the\nNSA before posting it.  And I think there may be some confusion that we\nare proposing this scheme only to circumvent US crypto export policy.\nNot true.  The real objective is to have a *standard* way to do\npasswords within the TLS protocol.  There's a lot more to it than\n\"non-export crypto\" - but just about everything has already been said in\nthis discussion over the past couple of weeks. \n\nTom Stephens\ntomste@microsoft.com\n\n>----------\n>From: Eric Murray[SMTP:ericm@lne.com]\n>Sent: Friday, October 11, 1996 12:44 PM\n>To: marcvh@aventail.com\n>Cc: tomw@netscape.com; ietf-tls@w3.org\n>Subject: Re: Closing on shared-key authentication\n>\n>Marc VanHeyningen writes:\n>> \n>> > No, you should certainly do something more than just send the password\n>> > encrypted.  You should avoid sending the password at all, encrypted or\n>> > otherwise.  Some sort of challenge/response mechanism would be\n>> > appropriate, but you are protected from eavesdroppers if you encrypt\n>> > the data.\n>> \n>> True.  I'm clearly misunderstanding you then.  You said previously:\n>> \n>> >There is no need to add a mechanism\n>> >to TLS when all existing protocols already have a password mechanims.\n>> \n>> I assumed the password mechanisms that you meant there were\n>> cleartext ones, not more sophisticated ones based on challenge-response\n>> or keyed hashes or anything else.  Was I wrong?\n>\n>Sort of.  They're cleartext unless the entire exchange is protected\n>by TLS.  Then they're encrypted in whatever ciphersuite TLS\n>negotiated.  Obviously when you are negotiating use/non-use\n>of TLS in an existing protocol, you must start TLS before\n>sending the username/password.\n>\n>> I believe there is a need to add a mechanism to TLS because, while all\n>> existing protocols have password mechanisms, they're lousy ones.\n>\n>The only advantage to embedding passwords is being able to\n>use \"non-export\" encryption on the password, _IF_ the protocol\n>is designed so that no one can use the password field to\n>exchange \"random data\".  If I can write an app to use\n>TLS/password auth to send words (say as \"login attempts\")\n>of my own choosing under strong encryption, the NSA will not\n>allow export of the scheme.  I have not reviewed the latest\n>TLS password proposal, so I do not know if it will meet\n>the NSA's requirements.  Has anyone asked them yet?\n>\n>In any case, I agree with Tom that we should not be designing\n>the TLS protocol to meet the US crypto policy flavor-of-the-month.\n>Besides the fact that they can change it on any political\n>whim, rendering our work invalid, TLS is an international\n>standard.\n>\n>\n>-- \n>Eric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\n>PGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29\n>AF\n>\n>\n\n\n\n"
        },
        {
            "subject": "Complexity of SSL (was Re: Closing on sharedkey authentication",
            "content": "> Tom Weinstein wrote:\n> Michael Warner wrote:\n> > I must take exception here - not with the advantages of making\n> > security protocols easy to analyse, but with the implicit assertion\n> > that SSL - and in particular the RSA based authentication/key exchange\n> > - are easily analysed.   As presented in the current RFC, SSL v3 is\n> > just about the most complex security protocol I have ever looked at.\n> \n> Frankly, I'm baffled by this assertion.  Yes, SSL v3 is somewhat more\n> complex than some other security protocols, but I don't think it is\n> particularly resistant to analysis.  Bruce Schneier and David Wagner\n> have performed an analysis of the protocol, and their paper contains no\n> such complaints.\n\nI haven't seen the paper analysing SSL - do you have a reference ?   I'd \nlike to have a look.\n\nI am sure some of the problems stem from the description in the Internet\nDraft, which is not the most clear or concise.   It would be useful to see\na formal description and proof of the protocol - eg using BAN logic or \nsimilar.   The problems I have with the protocol are:\n\nChallenges and identities are not signed explicitly, but rather they are \nmixed up with the hashes of other parameters.\n\nChallenges and identities are not even together in the same message.\n\nIdentities are only in the protocol by virtue of the certificate.\n\n\"Indeterminacy\" of what is being signed - the security of the protocol \nseems to depend on the certificate verify messages which sign the hash(es) \nof all previous messages in the protocol - which vary depending on whether\neach party has a certificate etc.\n\nComplexity of deriving the key from the \"pre-master secret\".   What is the \npoint of this ?   It doesn't add to the randomness of the key.\n\nSince you say that it is easily analysed, maybe you could summarise the \nprotocol in a dozen lines, and describe which parameters are critical for\nsecurity, and how replay and man-in-the-middle attacks are thwarted ?\n\n> There is an obvious man in the middle attack when the server has no\n> certificate since client authentication is expressly forbidden in this\n> case.\n\nWhere is this stated explicitly ?   If SSL is supposed to be a general \nprotocol, why doesn't it support authenticated clients to unauthenticated \nservers ?\n\n> > I would very much like to see SSL support different (and simpler)\n> > authentication mechanisms.   Many have already been standardised -\n> > X.509 being a notable example.\n> \n> SSL does use X.509v3 certificates.  What kind of different\n> authentication mechanisms are you talking about?\n\nX.509 also defines an authentication exchange which can provide single\nor mutual authentication.   1 2 or 3 message protocols are defined - \ndepending on whether single or mutual authentication is needed, and whether\nsynchronised clocks are used.   The protocols have been analysed formally \n(in the process a weakness was found which has now been corrected).\n\nCheers,\n\nMichael Warner\nTelstra Research Labs\n\n\n\n"
        },
        {
            "subject": "Re: Complexity of SSL (was Re: Closing on sharedkey authentication",
            "content": "The Schneier/Wagner paper will be presented at the Usenix Workshop on\nElectronic Commerce, Nov 18-21 at the Clairmont Resort in Oakland.\nThe URL <http://www.usenix.org/ec96/index.html> contains the program\ninfo.\n\nI encourage everybody to attend!\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Tom Weinstein wrote:\n> \n> Marc VanHeyningen wrote:\n> >\n> >> No, you should certainly do something more than just send the\n> >> password encrypted.  You should avoid sending the password at all,\n> >> encrypted or otherwise.  Some sort of challenge/response mechanism\n> >> would be appropriate, but you are protected from eavesdroppers if you\n> >> encrypt the data.\n> >\n> > True.  I'm clearly misunderstanding you then.  You said previously:\n> >\n> >> There is no need to add a mechanism to TLS when all existing\n> >> protocols already have a password mechanims.\n> >\n> > I assumed the password mechanisms that you meant there were\n> > cleartext ones, not more sophisticated ones based on\n> > challenge-response or keyed hashes or anything else.  Was I wrong?\n> \n> Well, for example, HTTP has digest authentication.  POP3 and IMAP are\n> adding similar mechanisms.  Yes, the telnet password mechanism is\n> completely horrible, but there are protocols for which that is not true.\n> \n> > I believe there is a need to add a mechanism to TLS because, while all\n> > existing protocols have password mechanisms, they're lousy ones.\n> \n> Yes, a lot of existing protocols have lousy password mechanisms.  But\n> to integrate any sort of TLS password mechanism, you're going to have\n> to change the protocol if for no other reason than to STOP sending the\n> password in the clear.  If you're going to do that, why not just fix\n> the protocol?\n\n  Also note that these protocols (HTTP, POP, etc.) have to solve this\nproblem anyway, since they will generally not be used with TLS any\ntime soon.  Since they are already solving the problem, why do we\nneed to do it again?\n\n--Jeff\n\n-- \nJeff Weinstein - Electronic Munitions Specialist\nNetscape Communication Corporation\njsw@netscape.com - http://home.netscape.com/people/jsw\nAny opinions expressed above are mine.\n\n\n\n"
        },
        {
            "subject": "Re: Complexity of SSL (was Re: Closing on sharedkey authentication",
            "content": "Michael Warner wrote:\n> If SSL is supposed to be a general\n> protocol, why doesn't it support authenticated clients to unauthenticated\n> servers ?\n\n  Actually it does.  The \"client\" can just handshake as a server, and\nthe \"server\" can handshake as a client.  There is nothing that\nrequires the side that does the \"accept()\" call to be the server\nin the handshake.\n\n--Jeff\n\n-- \nJeff Weinstein - Electronic Munitions Specialist\nNetscape Communication Corporation\njsw@netscape.com - http://home.netscape.com/people/jsw\nAny opinions expressed above are mine.\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "I've been too busy, but felt this deserves a reply.\n\nJeff Weinstein wrote regarding password mechanisms:\n>   Also note that these protocols (HTTP, POP, etc.) have to solve this\n> problem anyway, since they will generally not be used with TLS any\n> time soon.  Since they are already solving the problem, why do we\n> need to do it again?\n\nAll programs must do I/O.  Since they all have to figure out how to do\nso, why provide them with operating systems or standard libraries to\nhelp them?\n\n-bsy\n\n--------\nBennet S. YeePhone: +1 619 534 4614    Email: bsy@cs.ucsd.edu\n\nWeb:http://www-cse.ucsd.edu/users/bsy/\nUSPS:Dept of Comp Sci and Eng, 0114, UC San Diego, La Jolla, CA 92093-0114\n\n\n\n"
        },
        {
            "subject": "RE: Thoughts on sharedkey authenticatio",
            "content": "The problem with Charles' proposal is that it does not protect passwords\nagainst off-line attacks.  If I can obtain a challenge-response pair\n(say, by cracking the 40-bit encryption used to encrypt it), and the\nclient's password is poorly chosen (or is nothing more than a 4- or\n5-digit PIN), then I can simply do a dictionary attack on the\nchallenge-response pair, obtaining the original password by exhaustive\nsearch.\n\nOur shared-key authentication proposal is designed to thwart this\nattack, by incorporating a long key derived from the master secret into\nthe authentication response.  Since the master secret is exchanged using\npublic-key cryptography, the derived key hashed into the authentication\nresponse is not available to the attacker regardless of the strength of\nsymmetric encryption used.  Hence even a 4-digit PIN is effectively\ninvulnerable to off-line attacks (on-line attacks can of course be\nrestricted in number by a properly designed server).\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)\n\n>----------\n>From: Charles Watt[SMTP:watt@sware.com]\n>Sent: Friday, October 11, 1996 2:58 PM\n>To: ericm@lne.com\n>Cc: marcvh@aventail.com; tomw@netscape.com; ietf-tls@w3.org\n>Subject: Thoughts on shared-key authentication\n>\n>-----BEGIN PRIVACY-ENHANCED MESSAGE-----\n>Proc-Type: 4,MIC-CLEAR\n>Content-Domain: RFC822\n>Originator-Certificate:\n> MIIBvzCCAWkCEFmOln6ip0w49CuyWr9vDVUwDQYJKoZIhvcNAQECBQAwWTELMAkG\n> A1UEBhMCVVMxGDAWBgNVBAoTD1NlY3VyZVdhcmUgSW5jLjEXMBUGA1UECxMOU2Vj\n> dXJlV2FyZSBQQ0ExFzAVBgNVBAsTDkVuZ2luZWVyaW5nIENBMB4XDTk1MDUwODIw\n> MjMzNVoXDTk3MDUwNzIwMjMzNVowcDELMAkGA1UEBhMCVVMxGDAWBgNVBAoTD1Nl\n> Y3VyZVdhcmUgSW5jLjEXMBUGA1UECxMOU2VjdXJlV2FyZSBQQ0ExFzAVBgNVBAsT\n> DkVuZ2luZWVyaW5nIENBMRUwEwYDVQQDEwxDaGFybGVzIFdhdHQwWTAKBgRVCAEB\n> AgICBANLADBIAkEM2ZSp7b6eqDqK5RbPFpd6DGSLjbpHOZU07pUcdgJXiduj9Ytf\n> 1rsmf/adaplQr+X5FeoIdT/bVSv2MUi3gY0eFwIDAQABMA0GCSqGSIb3DQEBAgUA\n> A0EApEjzeBjiSnGImJXgeY1K8HWSufpJ2DpLBF7DYqqIVAX9H7gmfOJhfeGEYVjK\n> aTxjgASxqHhzkx7PkOnL4JrN+Q==\n>MIC-Info: RSA-MD5,RSA,\n> BwP+eZsNFRAvH/278pFEFxJYn4qugayrKLxU0mEYckY5DDWVTbDex6Dpjq8jAncW\n> 1ydDgePOn0MDaLcb6Er+czg=\n>\n>There are many applications that have a much stronger requirement for\n>data authenticity than for confidentiality.  As an example, retail\n>banking over the Internet.  (Please hold any comments on the specific\n>example.  If you do not like it, think for a while and you will be able \n>to find an example that your prefer that meets these criteria).  40-bit \n>keys for encryption are adequate for things like viewing your check \n>register -- there are MUCH easier ways for an attacker to gain access to \n>your transaction data than breaking a 40-bit key (e.g., if in the US the\n>odds are pretty good that your bank supports telephone banking where all \n>I need is your account number from your check and your SSN, which I can \n>look up on the Web).  However, the authorization of bill payments requires \n>a full 128-bits of authenticity -- definitely not cool if an attacker can \n>pay your bills for you.\n>\n>When servicing a customer base of > 1 million account holders, it is:\n>\n>1) an onerous administrative task\n>2) a horrendous performance hit on the server\n>\n>to use client-side certificates -- particularly in light of the fact \n>that most banks have already distributed via manual methods sufficient \n>information to authenticate customers (e.g., ATM cards and PINs) that \n>could be used in an automated fashion by an on-line bank server.\n>\n>It is quite possible to build into TLS a shared-secret authentication\n>mechanism that is exportable and whose strength is independent of the\n>strength of the encryption.  We run an example of such a mechanism in \n>our lab:\n>\n>a) modify a public-domain implementation of MD5 or SHA to add\n>    procedures for saving and restoring the internal state\n>   registers -- an easy task.\n>\n>b) on the server, create a one-way hash of the customer password\n>   by running your modified hash function over the password.\n>   Save the internal state registers of the hash function and throw \n>   away the password.\n>\n>c) when the customer logs in, have the server send a one-time nonce\n>   to the browser.\n>\n>d) have the client prompt the customer for the customer's password.\n>   The client calculates the one way hash of password + nonce.\n>\n>e) send the resulting hash value to the server.  Note that a standard\n>   version of the hash function is all you need on the client.\n>\n>f) server verifies customer password by restoring the hash function\n>   registers and performing the final hash cycle over just the\n>   nonce.\n>\n>Charles Watt\n>Security First Network Bank\n>www.sfnb.com\n>\n>P.S:\n>Even though we built this in the lab with the intent of providing it for\n>our international banks, we were never able to deploy it due to a security\n>flaw in all SSL-capable Web servers that were available at the time -- no one\n>provided an interface by which the application running on the server could \n>access the SSL session ID.  Without access to the session ID to link \n>successive connections into a login session, the 128-bit keyed hash provided \n>by SSL is worthless to the application.  Instead the app must fall back on \n>the cookie mechanism as a way to link a login session.  But cookies are\n>protected using 40-bit encryption, reducing the assurance with which you can \n>link successive connections from 128 --> 40 bits.  \n>\n>In the end it was easier to find an off-shore solution to the crypto problem \n>than to get the big name server vendors to support secure applications.\n>\n>-----END PRIVACY-ENHANCED MESSAGE-----\n>\n>\n\n\n\n"
        },
        {
            "subject": "Extensibilit",
            "content": ">From: Tom Weinstein[SMTP:tomw@netscape.com]\n>\n>The lack of a general extension mechanism in SSL v3 is a feature, not a\n>bug.  This is a security protocol, and so susceptibility to analysis is\n>a good thing.  Simplicity and rigidity are features here.  SSL does\n>provide for forwards compatibility by allowing version negotiation and\n>protection from version rollback attacks.\n>\n\nNo one is suggesting that complex extra features be added willy-nilly\nwithout careful consideration of their security implications.  However,\nto neglect to account for possible (and possibly necessary) improvements\nin the protocol beyond those that can be addressed by versioning\n(particularly possible changes to the first handshake message sent)\nwould be, in my opinion, sheer reckless hubris.  SSL 3.0 currently\nlacks, and TLS desperately needs, a mechanism for incorporating such\nimprovements.   \n\nRight now, most of the world still uses a completely inadequate SSL 2.0\nclient hello, and is forced to play weird nonstandard tricks with what\nwould otherwise be a perfectly standard PKCS public-key encryption, all\nbecause of SSL 2.0's lack of extensibility.  Please, let us learn from\npast mistakes.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\ndansimon@microsoft.com\n\n\n\n"
        },
        {
            "subject": "Re: Extensibilit",
            "content": "Dan Simon wrote:\n> \n>>From:  Tom Weinstein[SMTP:tomw@netscape.com]\n>>\n>> The lack of a general extension mechanism in SSL v3 is a feature, not\n>> a bug.  This is a security protocol, and so susceptibility to\n>> analysis is a good thing.  Simplicity and rigidity are features here.\n>>  SSL does provide for forwards compatibility by allowing version\n>> negotiation and protection from version rollback attacks.\n>\n> \n> No one is suggesting that complex extra features be added willy-nilly\n> without careful consideration of their security implications. \n> However, to neglect to account for possible (and possibly necessary)\n> improvements in the protocol beyond those that can be addressed by\n> versioning (particularly possible changes to the first handshake\n> message sent) would be, in my opinion, sheer reckless hubris.  SSL 3.0\n> currently lacks, and TLS desperately needs, a mechanism for\n> incorporating such improvements.\n\nThis is completely untrue.  Although SSL 3.0 does not have a formal\nmechanism for extension, such as the X protocol has, it does provide for\ncompatibility with future versions.\n\n> Right now, most of the world still uses a completely inadequate SSL\n> 2.0 client hello, and is forced to play weird nonstandard tricks with\n> what would otherwise be a perfectly standard PKCS public-key\n> encryption, all because of SSL 2.0's lack of extensibility.  Please,\n> let us learn from past mistakes.\n\nWe have.  SSL 3.0 supports forward compatibility and has protection from\nversion rollback attacks.  As soon as the world stops supporting SSL\n2.0, we will immediately reap the benefits these improvements.  Why are\nyou flogging this dead horse?\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Bennet Yee wrote:\n> \n> I've been too busy, but felt this deserves a reply.\n> \n> Jeff Weinstein wrote regarding password mechanisms:\n> >   Also note that these protocols (HTTP, POP, etc.) have to solve this\n> > problem anyway, since they will generally not be used with TLS any\n> > time soon.  Since they are already solving the problem, why do we\n> > need to do it again?\n> \n> All programs must do I/O.  Since they all have to figure out how to do\n> so, why provide them with operating systems or standard libraries to\n> help them?\n\n  There is a difference.  All these programs run on operating\nsystems.  They require the OS to run.  My point was that these\nprotocols MUST be able to do strong authentication in the\nabsence of TLS, therefore they are already solving this\nproblem.\n\n  If we go down this road, we will have clients that want to\ndo https: with HTTP digest auth trying to communicate with\nservers that want to do https: with TLS password auth and\nno HTTP auth.  This will lead to interoperability hell, since\nthere will be two common methods for doing the same thing,\nwith no clear consensus.\n\n--Jeff\n\n-- \nJeff Weinstein - Electronic Munitions Specialist\nNetscape Communication Corporation\njsw@netscape.com - http://home.netscape.com/people/jsw\nAny opinions expressed above are mine.\n\n\n\n"
        },
        {
            "subject": "Shared Key Authentication record typ",
            "content": "> From: Tom Weinstein <tomw@netscape.com>\n> \n> Yes, a lot of existing protocols have lousy password mechanisms.  But\n> to integrate any sort of TLS password mechanism, you're going to have\n> to change the protocol if for no other reason than to STOP sending the\n> password in the clear.  If you're going to do that, why not just fix\n> the protocol?\n\nI take it that this is Tom's acknowledgement that there is justification\nfor including shared-key authentication within TLS as long as an acceptable\nmethod can be found?  Fix the protocol means \"do it right\", not \"don't do\nit at all\"?\n\nI believe that a sufficient business case has been made that shared-key\nauth (I'll call it SKA from here on) within TLS is desirable.  My main\narea of discomfort with the current proposal is that the SKA messages\nare entertwined with the TLS handshake messages even though there doesn't\nseem to be a logical need for them to be.  Since the handshake protocol\nis at the heart of TLS' security, it's not a good idea to add distracting\nfunctionality to it without a good reason.\n\nAside from that complaint, the SKA proposal recently submitted by Barb\nFox looks quite sound.  For that reason, I submit the following thought\nfor consideration of the WG: adopt the three SKA messages from the\nproposal, but instead of bundling them with the handshake exchange,\nseparate them out into their own (new) record type:\n\n1) define a new ContentType shared_key_auth(24).\n\nReason: separate SKA from handshake messages.  Although logically SKA\nsupports application-layer functionality, the SKA messages can't go into\napplication_data records because the protocol engine couldn't find them\nthere.\n\n2) add a new element to the connection state, generated during\nhandshake phase.  Add the following to section 8.2.2 (partitioning the\nkey_block) after server_write_MAC_secret (or after server_write_key or\nserver_write_IV as in the proposal - it doesn't matter where as long\nas it's specified in the protocol):\n\n    client_write_SKA_secret[CipherSpec.hash_size]\n\nReason: if SKA secrets are compromised, the master secret and other keys\nare not affected, assuming the key_block partition scheme is sound.  Since\nthe encryption and MAC keys are also derived this way, any flaw in the\npartition scheme would affect all of TLS, not just SKA.\n\n3) add the proposed messages to the SKA record type, with the same\nstructure as the handshake messages:\n\n    enum {\n        shared_keys(30), shared_key_request(31), shared_key_verify(32)\n    } SharedKeyAuthType;\n\n    struct {\n        SharedKeyAuthType msg_type;\n        uint24 length;\n        select (SharedKeyAuthType) {\n            case shared_keys:        SharedKeys;\n            case shared_key_request: SharedKeyRequest;\n            case shared_key_verify:  SharedKeyVerify;\n        } body;\n    } SharedKeyAuth;\n\n4) calculate the SKA response as:\n\n    SharedKeyVerify.shared_key_response\n        hash (client_write_SKA_secret + pad2 +\n            hash (client_write_SKA_secret + pad1\n                + SharedKeyVerify.auth_service.auth_service_hame\n                + SharedKeyVerify.auth_service.display_string\n                + SharedKeyVerify.auth_service.challenge\n                + SharedKeyVerify.identity + shared_key) )\n\nReason: since SKA messages would be sent after handshake is finished,\nthey are protected by the record layer MAC and the term\nhash(handshake_messages) isn't needed in the response calculation.\n\nIdeally, the SKA exchange should be \"secure\" without relying at all on\nprotection provided by MAC or encryption, assuming only a good 128 bit\nclient_write_SKA_secret.  The above construction seems to meet that\ncriteria, but could be modified if any holes are found.\n\n\nPotential questions:\n\n  * Since SKA messages are not within the handshake exchange but after it,\nthere's no longer a restriction of 1 SKA per handshake.  This might be\na feature, but it assumes that SKAs are protected against replay by\nthe record MAC and/or by the freshness of the challenge.  If this isn't\na valid assumption, a new handshake could be triggered each time an\nSKA is requested, resulting in a new SKA_secret.\n\n  * Others might object to adding a new record type.  I think it's a\ncleaner, more obvious solution, but there's no accounting for taste :-).\n\n  * I don't think it will add any round trips to the current proposal -\nthe SKA request could appear immediately after server finished and before\napplication data - similarly for SKA verify on the client end.\n\n\n----------------------------------------------------------------------------\n\n> From: Jeff Williams <jwkckid1@ix.netcom.com>\n> \n>   Here here!  I agree. The current password mechanism is definatly flawed\n> or is te easely accessed.  And chalange/response mechanism might also be \n> included as well as an option or feature.\n\nI think that anyone who takes the time to read the shared-key proposal\nwill find that it *does* specify a challenge-response mechanism.  I also\nbelieve that reading the proposals should be a prerequisite for\ncommenting on them.\n\n\n----------------------------------------------------------------------------\n\n> Date: Mon, 7 Oct 1996 16:06:54 -0700\n> From: david.brownell@Eng.Sun.COM (David Brownell - JavaSoft)\n> \n>   [good list of issues snipped]\n>\n> I could raise more questions, but the fact that there are\n> this many (after this much discussion!) says to me that the\n> proposal should not be deemed \"cooked\" enough to incorporate\n> into an IETF standard.\n> \n\n  From an IETF point of view, a Full Standard protocol must be specified\nin sufficient detail to allow independently-developed implementations\nto interoperate solely by reference to published specifications.  I\ndon't believe this applies to Proposed Standard RFCs, but it will be\nnecessary to completely specify the contents and processing of the\nauth_service, identity, challenge, etc. fields before the RFCs can\nadvance to Draft Standard.  There might be a range of private-agreement\ncodes reserved in the standard, but at least one interoperable SKA\nmethod must be fully defined and required to be supported in all\nimplementations.\n\nI believe that the proposal is \"cooked\" enough to be adopted as a\nbaseline, even though some details remain to be worked out.  If shared-key\nauth can be separated from the handshake protocol, perhaps along the lines\ndescribed above, I am \"FOR\" adopting it into TLS.\n\nIf for some technical reason it cannot be disengaged from the handshake\nexchange, I'll remain on the fence.\n\n\n\n"
        },
        {
            "subject": "Re: Shared Key Authentication record typ",
            "content": "David,\n\n  Please read below your comments.\n\nAt 10:54 AM 10/15/96 -0400, you wrote:\n>> From: Tom Weinstein <tomw@netscape.com>\n>> \n>> Yes, a lot of existing protocols have lousy password mechanisms.  But\n>> to integrate any sort of TLS password mechanism, you're going to have\n>> to change the protocol if for no other reason than to STOP sending the\n>> password in the clear.  If you're going to do that, why not just fix\n>> the protocol?\n>\n>I take it that this is Tom's acknowledgement that there is justification\n>for including shared-key authentication within TLS as long as an acceptable\n>method can be found?  Fix the protocol means \"do it right\", not \"don't do\n>it at all\"?\n>\n>I believe that a sufficient business case has been made that shared-key\n>auth (I'll call it SKA from here on) within TLS is desirable.  My main\n>area of discomfort with the current proposal is that the SKA messages\n>are entertwined with the TLS handshake messages even though there doesn't\n>seem to be a logical need for them to be.  Since the handshake protocol\n>is at the heart of TLS' security, it's not a good idea to add distracting\n>functionality to it without a good reason.\n>\n>Aside from that complaint, the SKA proposal recently submitted by Barb\n>Fox looks quite sound.  For that reason, I submit the following thought\n>for consideration of the WG: adopt the three SKA messages from the\n>proposal, but instead of bundling them with the handshake exchange,\n>separate them out into their own (new) record type:\n>\n>1) define a new ContentType shared_key_auth(24).\n>\n>Reason: separate SKA from handshake messages.  Although logically SKA\n>supports application-layer functionality, the SKA messages can't go into\n>application_data records because the protocol engine couldn't find them\n>there.\n>\n>2) add a new element to the connection state, generated during\n>handshake phase.  Add the following to section 8.2.2 (partitioning the\n>key_block) after server_write_MAC_secret (or after server_write_key or\n>server_write_IV as in the proposal - it doesn't matter where as long\n>as it's specified in the protocol):\n>\n>    client_write_SKA_secret[CipherSpec.hash_size]\n>\n>Reason: if SKA secrets are compromised, the master secret and other keys\n>are not affected, assuming the key_block partition scheme is sound.  Since\n>the encryption and MAC keys are also derived this way, any flaw in the\n>partition scheme would affect all of TLS, not just SKA.\n>\n>3) add the proposed messages to the SKA record type, with the same\n>structure as the handshake messages:\n>\n>    enum {\n>        shared_keys(30), shared_key_request(31), shared_key_verify(32)\n>    } SharedKeyAuthType;\n>\n>    struct {\n>        SharedKeyAuthType msg_type;\n>        uint24 length;\n>        select (SharedKeyAuthType) {\n>            case shared_keys:        SharedKeys;\n>            case shared_key_request: SharedKeyRequest;\n>            case shared_key_verify:  SharedKeyVerify;\n>        } body;\n>    } SharedKeyAuth;\n>\n>4) calculate the SKA response as:\n>\n>    SharedKeyVerify.shared_key_response\n>        hash (client_write_SKA_secret + pad2 +\n>            hash (client_write_SKA_secret + pad1\n>                + SharedKeyVerify.auth_service.auth_service_hame\n>                + SharedKeyVerify.auth_service.display_string\n>                + SharedKeyVerify.auth_service.challenge\n>                + SharedKeyVerify.identity + shared_key) )\n>\n>Reason: since SKA messages would be sent after handshake is finished,\n>they are protected by the record layer MAC and the term\n>hash(handshake_messages) isn't needed in the response calculation.\n\n  I am assuming that SharedKeyAuthType is 128 bit here, correct?\n>\n>Ideally, the SKA exchange should be \"secure\" without relying at all on\n>protection provided by MAC or encryption, assuming only a good 128 bit\n>client_write_SKA_secret.  The above construction seems to meet that\n>criteria, but could be modified if any holes are found.\n>\n>\n>Potential questions:\n>\n>  * Since SKA messages are not within the handshake exchange but after it,\n>there's no longer a restriction of 1 SKA per handshake.  This might be\n>a feature, but it assumes that SKAs are protected against replay by\n>the record MAC and/or by the freshness of the challenge.  If this isn't\n>a valid assumption, a new handshake could be triggered each time an\n>SKA is requested, resulting in a new SKA_secret.\n>\n>  * Others might object to adding a new record type.  I think it's a\n>cleaner, more obvious solution, but there's no accounting for taste :-).\n\n  No, I agree with you here.  I think it would be much cleaner.\n>\n>  * I don't think it will add any round trips to the current proposal -\n>the SKA request could appear immediately after server finished and before\n>application data - similarly for SKA verify on the client end.\n\n  Is this (Above) to be included or added to the current perposal?\n>\n>\n>----------------------------------------------------------------------------\n>\n>> From: Jeff Williams <jwkckid1@ix.netcom.com>\n>> \n>>   Here here!  I agree. The current password mechanism is definatly flawed\n>> or is te easely accessed.  And chalange/response mechanism might also be \n>> included as well as an option or feature.\n>\n>I think that anyone who takes the time to read the shared-key proposal\n>will find that it *does* specify a challenge-response mechanism.  I also\n>believe that reading the proposals should be a prerequisite for\n>commenting on them.\n\n  I guess you are infering that I have not read the spec.  Well I have, thank\nyou very much, David.  It is not clearly indicated weather challenge-response\nmechanism is included, per say, hence my comment. \n>\n>\n>----------------------------------------------------------------------------\n>\n>> Date: Mon, 7 Oct 1996 16:06:54 -0700\n>> From: david.brownell@Eng.Sun.COM (David Brownell - JavaSoft)\n>> \n>>   [good list of issues snipped]\n>>\n>> I could raise more questions, but the fact that there are\n>> this many (after this much discussion!) says to me that the\n>> proposal should not be deemed \"cooked\" enough to incorporate\n>> into an IETF standard.\n>> \n>\n>  From an IETF point of view, a Full Standard protocol must be specified\n>in sufficient detail to allow independently-developed implementations\n>to interoperate solely by reference to published specifications.  I\n>don't believe this applies to Proposed Standard RFCs, but it will be\n>necessary to completely specify the contents and processing of the\n>auth_service, identity, challenge, etc. fields before the RFCs can\n>advance to Draft Standard.  There might be a range of private-agreement\n>codes reserved in the standard, but at least one interoperable SKA\n>method must be fully defined and required to be supported in all\n>implementations.\n>\n>I believe that the proposal is \"cooked\" enough to be adopted as a\n>baseline, even though some details remain to be worked out.  If shared-key\n>auth can be separated from the handshake protocol, perhaps along the lines\n>described above, I am \"FOR\" adopting it into TLS.\n>\n>If for some technical reason it cannot be disengaged from the handshake\n>exchange, I'll remain on the fence.\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Shared Key Authentication record typ",
            "content": "David P. Kemp wrote:\n> \n> > From: Tom Weinstein <tomw@netscape.com>\n> >\n>> Yes, a lot of existing protocols have lousy password mechanisms.  But\n>> to integrate any sort of TLS password mechanism, you're going to have\n>> to change the protocol if for no other reason than to STOP sending\n>> the password in the clear.  If you're going to do that, why not just\n>> fix the protocol?\n> \n> I take it that this is Tom's acknowledgement that there is\n> justification for including shared-key authentication within TLS as\n> long as an acceptable method can be found?  Fix the protocol means \"do\n> it right\", not \"don't do it at all\"?\n\nNo, you've misunderstood me.  I was referring to the particular\nprotocol, such as telnet or HTTP that you wished to add password\nauthentication to.  I still believe that this sort of mechanism does\nnot belong in TLS.\n\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Shared Key Authentication record typ",
            "content": "Tom,\n\n  Please read below your comments.\n\nAt 12:00 PM 10/15/96 -0700, you wrote:\n>David P. Kemp wrote:\n>> \n>> > From: Tom Weinstein <tomw@netscape.com>\n>> >\n>>> Yes, a lot of existing protocols have lousy password mechanisms.  But\n>>> to integrate any sort of TLS password mechanism, you're going to have\n>>> to change the protocol if for no other reason than to STOP sending\n>>> the password in the clear.  If you're going to do that, why not just\n>>> fix the protocol?\n>> \n>> I take it that this is Tom's acknowledgement that there is\n>> justification for including shared-key authentication within TLS as\n>> long as an acceptable method can be found?  Fix the protocol means \"do\n>> it right\", not \"don't do it at all\"?\n>\n>No, you've misunderstood me.  I was referring to the particular\n>protocol, such as telnet or HTTP that you wished to add password\n>authentication to.  I still believe that this sort of mechanism does\n>not belong in TLS.\n\n  In your opinion, what would be the problem adding extension for\nTelnet or HTTP for password authentication?  I would think it is\na logical inclusion.  I am confused here?  Help me out, ok?\n\nReguards,\n\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Shared Key Authentication record typ",
            "content": "Jeff Williams wrote:\n> \n>> No, you've misunderstood me.  I was referring to the particular\n>> protocol, such as telnet or HTTP that you wished to add password\n>> authentication to.  I still believe that this sort of mechanism does\n>> not belong in TLS.\n> \n>   In your opinion, what would be the problem adding extension for\n> Telnet or HTTP for password authentication?  I would think it is\n> a logical inclusion.  I am confused here?  Help me out, ok?\n\nMy point was that if you already have to add a more secure password\nmechanism to these other protocols because they will be used without\nTLS, then it's redundant to add such a mechanism to TLS.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: remov",
            "content": " \n\n\n\n"
        },
        {
            "subject": "RE: Extensibilit",
            "content": ">\n>From: Tom Weinstein[SMTP:tomw@netscape.com]\n>\n>> No one is suggesting that complex extra features be added willy-nilly\n>> without careful consideration of their security implications. \n>> However, to neglect to account for possible (and possibly necessary)\n>> improvements in the protocol beyond those that can be addressed by\n>> versioning (particularly possible changes to the first handshake\n>> message sent) would be, in my opinion, sheer reckless hubris.  SSL 3.0\n>> currently lacks, and TLS desperately needs, a mechanism for\n>> incorporating such improvements.\n>\n>This is completely untrue.  Although SSL 3.0 does not have a formal\n>mechanism for extension, such as the X protocol has, it does provide for\n>compatibility with future versions.\n\nWell, it has been pointed out to me that the latest SSL 3.0 errata sheet\nincludes the addition of just such a mechanism--to wit:\n\nSection 7.6.1.2\n\nFor forward compatibility reasons, it's legal for a client hello message\nto have extra data after the compression methods. This data should be\nincluded in the handshake hashes, but otherwise ignored.\n\nThis looks to me like exactly what I was looking for.  Let's just hope\nthat the TLS editors are more up-to-date than I am.\n \n>Why are\n>you flogging this dead horse?\n\nWhen last I checked, it was still alive, but apparently someone killed\nit while I wasn't looking.  Apologies to all.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)\n>\n>\n\n\n\n"
        },
        {
            "subject": "Latest TLS proposal/draf",
            "content": "I'm new to the TLS mailing list....\n\nCould someone kindly point me in the right direction for the latest TLS \nproposal/draft/working doc(s).\n\njohn_h_wilson@ccm.jf.intel.com\n\n\n\n"
        },
        {
            "subject": "Re: Latest TLS proposal/draf",
            "content": "At 9:34 AM -0700 10/16/96, John H Wilson wrote:\n>Could someone kindly point me in the right direction for the latest TLS\n>proposal/draft/working doc(s).\n\nI got this from the SSL-Talk List FAQ at\n<http://www.consensus.com/security/ssl-talk-faq.html> in question 4.5\n<http://www.consensus.com/security/ssl-talk-sec04.html#4.5>:\n\n>    There was a day-long pre-Montreal meeting last May in Palo Alto, the\n>    minutes of which are at\n>        <http://lists.w3.org/Archives/Public/ietf-tls/msg00185.html>\n>\n>    These minutes give a fairly complete list of technical issues and\n>    possible solutions.\n>\n>    The minutes for the official TLS working group meeting in Montreal\n>    are in two messages at\n>        <http://lists.w3.org/Archives/Public/ietf-tls/msg00217.html>\n>        <http://lists.w3.org/Archives/Public/ietf-tls/msg00212.html>\n\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Busted TLS Schedule, and a Proposal for Closur",
            "content": "In the minutes for the previous TLS-WG meeting in Montreal (at\n<http://lists.w3.org/Archives/Public/ietf-tls/msg00217.html> and\n<http://lists.w3.org/Archives/Public/ietf-tls/msg00212.html>) it says:\n\n>7/30/96 All issues on the table, with justifications why they\n>               are important. On or about 8/2/96, I will post a\n>               summary of where we are. Some issues may be\n>               accepted or rejected in ensuing discussion during July.\n>\n>8/31/96 Proposed text/detailed descriptions for proposals due.\n>\n>9/30/96: Discussion on list of what we should move forward with.\n>\n>Early October: document editors/authors meet to hash out\n>the text. (Exact set to be determined)\n>\n>Mid-October: discussion draft available for review.\n>\n>November: discussion on the list, organization of issues remaining\n>for discussion at the San Jose meeting.\n>\n>December: meet in San Jose.\n>\n>I also propose that we limit discussion of this proposal to conclude\n>by Friday, 7/12, so we don't get bogged down in process discussions.\n\nAs I recall there were only two technical proposals on the table in August\nand September (both of which I think were late), Netscape's authority\nattributes, and Microsoft's secret key authentication. I have not seen on\nthis list sufficient consensus to move forward on either of them.\n\nI would like to suggest to Win Treese, the TLS-WG chairman, that we table\nthe two proposals for now, and settle on moving SSL 3.0 into TLS 1.0 *as\nis*, however, with some clarifications to the spec.\n\nI would like to see that early in November a small group of engineers who\nhave actually *implemented* SSL 3.0 get together with the current SSL 3.0\nauthors to clarify the spec. *Not* change the spec, only clarify any\nambiguities (we have found in writing SSLRef 3.0, SSL Plus, and an SSL\nFortezza implemenation a number of ambiguities, and I'm sure others have as\nwell.)\n\nThis cleaned up spec would be called TLS 1.0 and published as an internet\ndraft for final comments in time for the December IETF meeting in San Jose.\n\nSSL 3.0 is already widely deployed. Both Microsoft and Netscape have it now\nin their browsers and servers, and many other companies now have SSL 3.0\nbrowsers, web servers, and non-web application under development with SSL\n3.0.\n\nThus I believe that is appropriate that the continued revisions of the SSL\n3.0 standard move to IETF change control, and it's authors seem willing to\nallow it to do so. Given this I think SSL 3.0 is an appropriate starting\npoint for IETF and TLS-WG, and that the the TLS-WG should ratify it with\nthe ambiguities cleaned up.\n\nFrom that solid base we can move toward TLS 1.1, which then might include\nMicrosoft's and Netscape's proposals.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: Busted TLS Schedule, and a Proposal for Closur",
            "content": "> I would like to suggest to Win Treese, the TLS-WG chairman, that we table\n> the two proposals for now, and settle on moving SSL 3.0 into TLS 1.0 *as\n> is*, however, with some clarifications to the spec.\n> \n> I would like to see that early in November a small group of engineers who\n> have actually *implemented* SSL 3.0 get together with the current SSL 3.0\n> authors to clarify the spec. *Not* change the spec, only clarify any\n> ambiguities (we have found in writing SSLRef 3.0, SSL Plus, and an SSL\n> Fortezza implemenation a number of ambiguities, and I'm sure others have as\n> well.)\n> \n> This cleaned up spec would be called TLS 1.0 and published as an internet\n> draft for final comments in time for the December IETF meeting in San Jose.\n\nI concur.\n\nThere appears to be consensus for having separate specification documents,\none describing the Record Layer, the other describing the various messages\nthat ride on top of it. Several people have declared support for a modular\ndocument structure, none have opposed it. Anyone opposed should speak up now.\n\n\n\n"
        },
        {
            "subject": "Re: Busted TLS Schedule, and a Proposal for Closur",
            "content": "At 03:48 PM 10/16/96 -0400, you wrote:\n>\n>> I would like to suggest to Win Treese, the TLS-WG chairman, that we table\n>> the two proposals for now, and settle on moving SSL 3.0 into TLS 1.0 *as\n>> is*, however, with some clarifications to the spec.\n>> \n>> I would like to see that early in November a small group of engineers who\n>> have actually *implemented* SSL 3.0 get together with the current SSL 3.0\n>> authors to clarify the spec. *Not* change the spec, only clarify any\n>> ambiguities (we have found in writing SSLRef 3.0, SSL Plus, and an SSL\n>> Fortezza implemenation a number of ambiguities, and I'm sure others have as\n>> well.)\n>> \n>> This cleaned up spec would be called TLS 1.0 and published as an internet\n>> draft for final comments in time for the December IETF meeting in San Jose.\n\n  I also concur here.\n\n  I have no problem with Davids assumption.  Not sure that others will.\nhowever I would like to see a refrence to each from one another.\n\nReguards,\n\n>\n>I concur.\n>\n>There appears to be consensus for having separate specification documents,\n>one describing the Record Layer, the other describing the various messages\n>that ride on top of it. Several people have declared support for a modular\n>document structure, none have opposed it. Anyone opposed should speak up now.\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Busted TLS Schedule, and a Proposal for Closur",
            "content": "At 12:48 PM -0700 10/16/96, David P. Kemp wrote:\n>There appears to be consensus for having separate specification documents,\n>one describing the Record Layer, the other describing the various messages\n>that ride on top of it. Several people have declared support for a modular\n>document structure, none have opposed it. Anyone opposed should speak up now.\n\nI'm not opposed to this, as long as the existing authors and the group that\ncan meet in early November to clarify the spec feel that they can also fit\nin the task of splitting the spec into the schedule as well.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: Busted TLS Schedule, and a Proposal for Closur",
            "content": "Christopher Allen wrote:\n> \n> As I recall there were only two technical proposals on the table in\n> August and September (both of which I think were late), Netscape's\n> authority attributes, and Microsoft's secret key authentication. I\n> have not seen on this list sufficient consensus to move forward on\n> either of them.\n> \n> I would like to suggest to Win Treese, the TLS-WG chairman, that we\n> table the two proposals for now, and settle on moving SSL 3.0 into TLS\n> 1.0 *as is*, however, with some clarifications to the spec.\n> \n> I would like to see that early in November a small group of engineers\n> who have actually *implemented* SSL 3.0 get together with the current\n> SSL 3.0 authors to clarify the spec. *Not* change the spec, only\n> clarify any ambiguities (we have found in writing SSLRef 3.0, SSL\n> Plus, and an SSL Fortezza implemenation a number of ambiguities, and\n> I'm sure others have as well.)\n> \n> This cleaned up spec would be called TLS 1.0 and published as an\n> internet draft for final comments in time for the December IETF\n> meeting in San Jose.\n> \n> SSL 3.0 is already widely deployed. Both Microsoft and Netscape have\n> it now in their browsers and servers, and many other companies now\n> have SSL 3.0 browsers, web servers, and non-web application under\n> development with SSL 3.0.\n> \n> Thus I believe that is appropriate that the continued revisions of the\n> SSL 3.0 standard move to IETF change control, and it's authors seem\n> willing to allow it to do so. Given this I think SSL 3.0 is an\n> appropriate starting point for IETF and TLS-WG, and that the the\n> TLS-WG should ratify it with the ambiguities cleaned up.\n> \n> From that solid base we can move toward TLS 1.1, which then might\n> include Microsoft's and Netscape's proposals.\n\nI think this is an excellent idea.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Busted TLS Schedule, and a Proposal for Closur",
            "content": "All,\n\n  I agree with what Christopher suggests.  I would like to see a refrence\nin both documents to one another however.\n\nReguards,\n        \n\nAt 02:27 PM 10/16/96 -0700, you wrote:\n>At 12:48 PM -0700 10/16/96, David P. Kemp wrote:\n>>There appears to be consensus for having separate specification documents,\n>>one describing the Record Layer, the other describing the various messages\n>>that ride on top of it. Several people have declared support for a modular\n>>document structure, none have opposed it. Anyone opposed should speak up now.\n>\n>I'm not opposed to this, as long as the existing authors and the group that\n>can meet in early November to clarify the spec feel that they can also fit\n>in the task of splitting the spec into the schedule as well.\n>\n>------------------------------------------------------------------------\n>..Christopher Allen                  Consensus Development Corporation..\n>..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n>..                                             Berkeley, CA 94707-2116..\n>..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n>..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n>\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: Busted TLS Schedule, and a Proposal for Closur",
            "content": "At 03:44 PM 10/16/96 -0700, you wrote:\n>Christopher Allen wrote:\n>> \n>> As I recall there were only two technical proposals on the table in\n>> August and September (both of which I think were late), Netscape's\n>> authority attributes, and Microsoft's secret key authentication. I\n>> have not seen on this list sufficient consensus to move forward on\n>> either of them.\n>> \n>> I would like to suggest to Win Treese, the TLS-WG chairman, that we\n>> table the two proposals for now, and settle on moving SSL 3.0 into TLS\n>> 1.0 *as is*, however, with some clarifications to the spec.\n>> \n>> I would like to see that early in November a small group of engineers\n>> who have actually *implemented* SSL 3.0 get together with the current\n>> SSL 3.0 authors to clarify the spec. *Not* change the spec, only\n>> clarify any ambiguities (we have found in writing SSLRef 3.0, SSL\n>> Plus, and an SSL Fortezza implemenation a number of ambiguities, and\n>> I'm sure others have as well.)\n>> \n>> This cleaned up spec would be called TLS 1.0 and published as an\n>> internet draft for final comments in time for the December IETF\n>> meeting in San Jose.\n>> \n>> SSL 3.0 is already widely deployed. Both Microsoft and Netscape have\n>> it now in their browsers and servers, and many other companies now\n>> have SSL 3.0 browsers, web servers, and non-web application under\n>> development with SSL 3.0.\n>> \n>> Thus I believe that is appropriate that the continued revisions of the\n>> SSL 3.0 standard move to IETF change control, and it's authors seem\n>> willing to allow it to do so. Given this I think SSL 3.0 is an\n>> appropriate starting point for IETF and TLS-WG, and that the the\n>> TLS-WG should ratify it with the ambiguities cleaned up.\n>> \n>> From that solid base we can move toward TLS 1.1, which then might\n>> include Microsoft's and Netscape's proposals.\n>\n>I think this is an excellent idea.\n\n  I agree with Tom here.  I would add that when seperating the two documents\nthat mutual refrence to each be included in each.  I would also think that\nNetscape's\n authority attributes, and Microsoft's secret key authentication be included in\na manner that would be inclusive in the final perposal document.\n\nReguards,\n\n\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "Re: closure on TLS via SSL",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\n\nI too agree with this approach, which was proposed as far back\nas Montreal.\n\nIn SSL3, we have \"rough concensus and running code\", if you\ncount the existance of the current implementation and the fact\nthat major interested parties have widespread deployment.\n\nIt might not be everyone's idea of perfection, but it seems\nquite acceptable for a \"TLS 1.0\" iteration.  These other\ndiscussions can happen for the next generation.\n\nI assume that most people would agree that SOMETHING will\nhappen after the first TLS version, since this is not a static\ntechnology, therefore presuming the existance of a post-TLS-1.0\nstandard seems reasonable.\n\n\n>Resent-Date: Wed, 16 Oct 1996 21:28:46 -0400\n>Resent-Message-Id: <199610170128.VAA10502@www19.w3.org>\n>X-Sender: jwkckid1@popd.ix.netcom.com\n>Date: Wed, 16 Oct 1996 20:03:44 -0500\n>To: ietf-tls@w3.org\n>From: Jeff Williams <jwkckid1@ix.netcom.com>\n>Subject: Re: Busted TLS Schedule, and a Proposal for Closure\n>X-List-URL: http://lists.w3.org/Archives/Public/ietf-tls\n>Resent-From: ietf-tls@w3.org\n>X-Mailing-List: <ietf-tls@w3.org> archive/latest/388\n>X-Loop: ietf-tls@w3.org\n>Sender: ietf-tls-request@w3.org\n>Resent-Sender: ietf-tls-request@w3.org\n>\n>At 03:44 PM 10/16/96 -0700, you wrote:\n>>Christopher Allen wrote:\n>>> \n>>> As I recall there were only two technical proposals on the\ntable in\n>>> August and September (both of which I think were late),\nNetscape's\n>>> authority attributes, and Microsoft's secret key\nauthentication. I\n>>> have not seen on this list sufficient consensus to move\nforward on\n>>> either of them.\n>>> \n>>> I would like to suggest to Win Treese, the TLS-WG chairman,\nthat we\n>>> table the two proposals for now, and settle on moving SSL\n3.0 into TLS\n>>> 1.0 *as is*, however, with some clarifications to the spec.\n>>> \n>>> I would like to see that early in November a small group of\nengineers\n>>> who have actually *implemented* SSL 3.0 get together with\nthe current\n>>> SSL 3.0 authors to clarify the spec. *Not* change the spec,\nonly\n>>> clarify any ambiguities (we have found in writing SSLRef\n3.0, SSL\n>>> Plus, and an SSL Fortezza implemenation a number of\nambiguities, and\n>>> I'm sure others have as well.)\n>>> \n>>> This cleaned up spec would be called TLS 1.0 and published\nas an\n>>> internet draft for final comments in time for the December\nIETF\n>>> meeting in San Jose.\n>>> \n>>> SSL 3.0 is already widely deployed. Both Microsoft and\nNetscape have\n>>> it now in their browsers and servers, and many other\ncompanies now\n>>> have SSL 3.0 browsers, web servers, and non-web application\nunder\n>>> development with SSL 3.0.\n>>> \n>>> Thus I believe that is appropriate that the continued\nrevisions of the\n>>> SSL 3.0 standard move to IETF change control, and it's\nauthors seem\n>>> willing to allow it to do so. Given this I think SSL 3.0 is\nan\n>>> appropriate starting point for IETF and TLS-WG, and that\nthe the\n>>> TLS-WG should ratify it with the ambiguities cleaned up.\n>>> \n>>> From that solid base we can move toward TLS 1.1, which then\nmight\n>>> include Microsoft's and Netscape's proposals.\n>>\n>>I think this is an excellent idea.\n>\n>  I agree with Tom here.  I would add that when seperating the\ntwo documents\n>that mutual refrence to each be included in each.  I would\nalso think that\n>Netscape's\n> authority attributes, and Microsoft's secret key\nauthentication be included in\n>a manner that would be inclusive in the final perposal\ndocument.\n>\n>Reguards,\n>\n>\n>>\n>>-- \n>>You should only break rules of style if you can    | Tom\nWeinstein\n>>coherently explain what you gain by so doing.      |\ntomw@netscape.com\n>>\n>>\n>>\n>Jeffrey A. Williams\n>SR.Internet Network Eng. \n>CEO., IEG., INC.,  Representing PDS .Ltd.\n>Web: http://www.pds-link.com \n>Phone: 214-793-7445 (Direct Line)\n>Director of Network Eng. and Development IEG. INC.\n>\n>\n>\n-----BEGIN PGP SIGNATURE-----\nVersion: 4.0 Business Edition\n\niQCVAgUBMmZakcKmlvJNktGxAQGjfwQAuQF7oOE4M+fVGEMrgyozuJEAnnaUT2Fq\nBSB01t0vkqkesxlnfenVTWx0uv7+o0YiXPqAK0SsaGQMdpBarp9J9wr4qK9gd+O6\nxK95y1H4LnxvXKl/cnSPjBN/KApHfzV2irN/XqBGWtKJc5Q6prDnhyaO9yd7XSHX\n5KYjsSmtqa8=\n=eEBf\n-----END PGP SIGNATURE-----\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "Minutes from Conference Call on Cert Storage 10/10/9",
            "content": "Please do not reply directly to this email (as it has been sent to many\nlists) -- instead, reply-to: Christopher Allen <ChristopherA@consensus.com>\nor subscribe to the list below if you are interested.\n\nI have set up a mailing list for this working group. Send mail to\n<certstorage-wg@consensus.com> with the subject \"subscribe\" or\n\"subscribe digest\" to join.\n\nMinutes from Conference Call on Cert Storage\n10/10/96\n\nAttending:\nChristopher Allen <ChristopherA@consensus.com>\nRobert Dickinson <bob@deming.com>\nTim Dierks <TimD@consensus.com>\nSteve Dusse <spock@rsa.com>\nLaurence Lundblade <lgl@qualcomm.com>\nBlake Ramsdell <BlakeR@deming.com>\n\nThis group was brought together to discuss interoperability issues\nregarding exchange of certificates and private keys between products. A\nfile format is desired which specifies the storage of a certificate, the\nchain of certificates supporting its authenticity, and a password-protected\nprivate key object. This should be suitable for exporting certificates from\none application and importing them into another or for native storage for\nproducts which choose to adopt it.\n\nThe call opened with a review of some history and background:\n\nThere was a draft of PKCS#12 that was loosely based on what was learned\nfrom the old Apple PowerTalk signer file, however, it was never distributed.\n\nMicrosoft has proposed PFX (info at\n<http://www.microsoft.com/INTDEV/SECURITY/PFX/PFX019SYNTAX.HTM>). PFX\nattempts to solve more problems than merely certificate transport, but it\ndoes propose an ASN.1-encoded format for transporting certificates and\nkeys; this subset of PFX would be a candidate for solving this problem. PFX\ndrew on the unpublished PKCS#12 draft.\n\nSteve Dusse at RSA Data Security said that they and Netscape have looked at\nthe PFX proposal and feel there is some value in basing a real PKCS#12 on\nthe bits-on-the-wire portions of PFX, but are not sure about the protocols\nor trust model specifics of PFX. Microsoft is committed to PFX, and Steve\nDusse reported after the meeting that Netscape may actually have some\nPFX-like interchange code underway.\n\nChristopher Allen and Tim Dierks of Consensus Development define the short\nterm problem as \"How do you encapsulate single private key, it's cert and\ncert chain into a single package that we can interchange.\" They have seen\nfour different \"signer\" files: the original PowerTalk-compatible signer\nfile (which Mac specific); single file binary file formats; two binary file\nformats (private key in one and certs in the other); and ASCII armored\nfiles similar to what PGP offers.\n\nConsensus is open to either some ASN.1 encoded object or some type of ASCII\nmime-like file, and work with any appropriate standards process, but wants\nto get things rolling.\n\nDeming said that they are willing to support some type of\ninterchange/export file format, adding that this could be in the form of a\nPKCS#7 mime type that contains the all the different parts. Tim pointed out\nthat VeriSign only provided a certificate (not a PKCS#7 object) for any\nPCKS#10 requests, and thus Consensus' current ASCII armored format uses\nthose.\n\nThere was some discussion that whatever approach that was taken needed to\nfit in with with Netscape and Microsoft's plans. Steve Dusse recommends\ntaking a look at the ASN.1 in the PFX proposal and base an interchange file\non that.\n\nRay Sidney says that a new draft PKCS#12 document might be possible in the\nnext 3 or 4 months.\n\nBoth Deming and Consensus were concerned with this pace as they are\npreparing to release products now, and only require a\nleast-common-denominator solution right now, i.e. a single private key,\ncertificate, and a certificate chain.\n\nTim Dierks added that there is probably a sub-requirement to specify\na better standard for password protected encryption beyond PKCS#5 as it\nstands because it currently only supports DES encryption.\n\nThe meeting ended with an agreement to go look at the ASN.1 of the PFX\ndocuments, exchange some email, and talk again next week schedule\npermitting.\n\nP.S. Many thanks to Qualcomm for sponsoring the call.\n\nFYI: Enclosed is a prototype ASCII armored file for Consensus' SSL Plus\nbeta. The descriptive lines are ignored comments; the format is just block\nspecifiers formatted as below wrapping base64 encoded ASN.1 data. It could\neasily be adapted to MIME style wrappers, or support other base64 binary\nencoded formats.\n\n------------------------------------------------------------------------\n\nSSL Plus test certificate\n-----BEGIN X.509 CERTIFICATE-----\nMIICqDCCAhECAQIwDQYJKoZIhvcNAQEEBQAwgaAxCzAJBgNVBAYTAlVTMSowKAYD\nVQQKFCFDb25zZW5zdXMgRGV2ZWxvcG1lbnQgQ29ycG9yYXRpb24xKjAoBgNVBAsU\nISoqIFRFU1RJTkcgQU5EIEVWQUxVQVRJT04gT05MWSAqKjE5MDcGA1UEAxQwQ29u\nc2Vuc3VzIERldmVsb3BtZW50IFRlc3QgQ2VydGlmaWNhdGUgQXV0aG9yaXR5MB4X\nDTk2MDkyNTAwMDAwMFoXDTk2MTIzMTEyNTk1OVowgZcxCzAJBgNVBAYTAlVTMSow\nKAYDVQQKFCFDb25zZW5zdXMgRGV2ZWxvcG1lbnQgQ29ycG9yYXRpb24xNzA1BgNV\nBAsULioqIFNTTCBQTFVTKHRtKSBURVNUSU5HIEFORCBFVkFMVUFUSU9OIE9OTFkg\nKioxIzAhBgNVBAMUGnNzbHBsdXMtdGVzdC5jb25zZW5zdXMuY29tMIGfMA0GCSqG\nSIb3DQEBAQUAA4GNADCBiQKBgQC8U38V1yaVRIOHpCeMRdGlaa6hn7qU7C61wnkV\nL+IwBHqkH79CkQS6eNAHc+3SV91BlJxNqLi5pCnpx5j6DXxFUCYnFcg9b3m2L63X\nbMeqjRwZEH63bP4oEJPdoqUivRv+rAIQuC2S83WkBVw9znmWt2Oy/ohHvbYucUfA\nWbdMjQIDAQABMA0GCSqGSIb3DQEBBAUAA4GBAIwMlJcd0HmHzWo9TVCGdfR8HaPg\nfjmJHMfRnL/YwuH+8HHMZYwSjIOECKWJ5LmgdWOAT3Wj0AUcqU5RYntYQ1+UNbBN\nso2qD1h1gVfaVTVdbu+w6CQoZEH/70Dj7cvwvyMBehnYZ5I+B9ct2d0xj35+coM7\nn/PIix1nAc5QyccE\n-----BEGIN X.509 CERTIFICATE-----\n\nConsensus Test CA\n-----BEGIN X.509 CERTIFICATE-----\nMIICsTCCAhoCAQEwDQYJKoZIhvcNAQEEBQAwgaAxCzAJBgNVBAYTAlVTMSowKAYD\nVQQKFCFDb25zZW5zdXMgRGV2ZWxvcG1lbnQgQ29ycG9yYXRpb24xKjAoBgNVBAsU\nISoqIFRFU1RJTkcgQU5EIEVWQUxVQVRJT04gT05MWSAqKjE5MDcGA1UEAxQwQ29u\nc2Vuc3VzIERldmVsb3BtZW50IFRlc3QgQ2VydGlmaWNhdGUgQXV0aG9yaXR5MB4X\nDTk2MDkyNTAwMDAwMFoXDTk2MTIzMTEyNTk1OVowgaAxCzAJBgNVBAYTAlVTMSow\nKAYDVQQKFCFDb25zZW5zdXMgRGV2ZWxvcG1lbnQgQ29ycG9yYXRpb24xKjAoBgNV\nBAsUISoqIFRFU1RJTkcgQU5EIEVWQUxVQVRJT04gT05MWSAqKjE5MDcGA1UEAxQw\nQ29uc2Vuc3VzIERldmVsb3BtZW50IFRlc3QgQ2VydGlmaWNhdGUgQXV0aG9yaXR5\nMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCZfkFsDJsaJ8DpexH00mQbxoZd\n2bcbfYrUCYovSQfJkJFse3Bs/ecnsdCZkidNgayPIdpnbxaY/bRMgLOBroLSgo+T\nLw8I7Z66DDtfVnulJdsdn5mn2GnOTK7cXDFfRJSa/SFCOEtWsZRk/MPflXHBCZ7U\nIQGgww0jt9IpBbX+xwIDAQABMA0GCSqGSIb3DQEBBAUAA4GBABBduurGQHZm67Hf\ntG7qIm1POChIXCOx8eGvkj+AWjxXiUmg/Ii/6Qsbu+C5JfBD9Ph9ncvrYRhcl4Ba\nr4e5N+i7BPU+b64y+AQYu89fd2MSeZtRdgTZw4Y8G9f2g4rjV+Lhd67FH/9hq7xd\nrrJDmTxuEyxPL/mxKhMdWaMWOHb7\n-----BEGIN X.509 CERTIFICATE-----\n\nSSL Plus test certificate private key\n-----BEGIN ENCRYPTED PRIVATE KEY-----\nMIICmDAaBgkqhkiG9w0BBQMwDQQIP/ADsmtQ2AECAQUEggJ45Dfjfk7M8ra946QY\nPQ9VvPsN9BID6cO80NA7jwT1vns9bxJHGCVgkXLHcX+33KMJ772hDvs6tSkAP3LE\npZBIYXTOYHLRN5EmhpEPE/0raE83+gphfNhhi3WnyHgt3Amk0JUFy//qbs58oCvn\nXGeFoaqGVXO6qbHAZJhhKGFWJIzf4VfzYYTIfoKDQP8Q4kmr4WG8FXAhs+B6e49M\nJR/OLVez77RTt/DUrTOhkxx1k4U9+vRVBuNJsoMBPAeVbeK5XEUnGWXAqjQ/slsT\nE9otfBffjeP9z+6p0Vrn0wBe0VrQ6EVmDy9OXFRCsUTUzM+9k0b9H4wzRdw1U666\nrWt96PfkE7xw9uTXay9k4ICbvXb6HazTR7MkUUmSukJnidiAvB9vj27Q0BERO3Ht\no9fIE2Jeg7uZD5kqwZ/pWDf+ai9WWW77rb+JVycGt3Cu/doPJLOZMwEoeSWhjSlH\n83D7vDaBHu4K1OgGY2c2b7kcM2FdyCGWDAkUAD2A8nn6mJ/LhQtda1nVztYBaDY0\npwlMdIf+v6WLKO2TNT8yhEUtG574Y/Zf5M5vvGIYAB2q+15TneMO8o65eDSACO8g\nC/WnqED7Cys9AafNj4vmSu8di4vudKBUasFikfGRBZpZbwtr6EhqLBvn+2t2MQ3f\n4hF5TUXW/SNiy2aETtsSbg5M+L7Rx4ocYlpgjWa6+2LgFzOhrOgnMru6k9nWWHlH\nahUH7PlWGOnsccVhgI6G7IJ6J44+PohvUqbJu+RUR69w++hjMHNJF15vOuXCyDce\npF1iLJAwdpM8MBK2/PYtZz1Qj0uinaALiXovFVgFXmCslETn9JZ2ITxafVo=\n-----END ENCRYPTED PRIVATE KEY-----\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "RE: Busted TLS Schedule, and a Proposal for Closur",
            "content": "Christopher:\n\nYour mail finally addresses the issue of change control.  So, what is the \nincremental value of  \"adopting SSL as is\"  as an IETF standard without any \nschedule of work beyond December?\n\nWhether you agree to call it consensus or not, there has been progress in \nthis working group on password authentication.  Other people obviously want \nit too, and we're prepared to submit an RFC along with independent \nimplementations of working code.\n\nWhen and how do you (or better yet, one of the authors you cite) propose \nthat we incorporate it?   What about the other features/extensions/ \ncleanups that have been proposed? As you may recall, I absolutely agreed \nwith using SSL3 as the base.   It's the de facto standard now.  So, why not \nat least try to improve it in some way, rather than wasting everybody's \ntime merely to rename it?\n\nI offer the counter proposal that we all agree to a much more realistic \nschedule - say March or June IETF - for getting what would be a real TLS \nproposal with several improvements and multiple implementations on the \ntable for consideration.\n\nBarb\n\n----------\nFrom:  Christopher Allen[SMTP:ChristopherA@consensus.com]\nSent:  Wednesday, October 16, 1996 11:24 AM\nTo:  ietf-tls@w3.org\nCc:  Win Treese; Jeff Schiller\nSubject:  Busted TLS Schedule, and a Proposal for Closure\n\nIn the minutes for the previous TLS-WG meeting in Montreal (at\n<http://lists.w3.org/Archives/Public/ietf-tls/msg00217.html> and\n<http://lists.w3.org/Archives/Public/ietf-tls/msg00212.html>) it says:\n\n>7/30/96 All issues on the table, with justifications why they\n>               are important. On or about 8/2/96, I will post a\n>               summary of where we are. Some issues may be\n>               accepted or rejected in ensuing discussion during July.\n>\n>8/31/96 Proposed text/detailed descriptions for proposals due.\n>\n>9/30/96: Discussion on list of what we should move forward with.\n>\n>Early October: document editors/authors meet to hash out\n>the text. (Exact set to be determined)\n>\n>Mid-October: discussion draft available for review.\n>\n>November: discussion on the list, organization of issues remaining\n>for discussion at the San Jose meeting.\n>\n>December: meet in San Jose.\n>\n>I also propose that we limit discussion of this proposal to conclude\n>by Friday, 7/12, so we don't get bogged down in process discussions.\n\nAs I recall there were only two technical proposals on the table in August\nand September (both of which I think were late), Netscape's authority\nattributes, and Microsoft's secret key authentication. I have not seen on\nthis list sufficient consensus to move forward on either of them.\n\nI would like to suggest to Win Treese, the TLS-WG chairman, that we table\nthe two proposals for now, and settle on moving SSL 3.0 into TLS 1.0 *as\nis*, however, with some clarifications to the spec.\n\nI would like to see that early in November a small group of engineers who\nhave actually *implemented* SSL 3.0 get together with the current SSL 3.0\nauthors to clarify the spec. *Not* change the spec, only clarify any\nambiguities (we have found in writing SSLRef 3.0, SSL Plus, and an SSL\nFortezza implemenation a number of ambiguities, and I'm sure others have \nas\nwell.)\n\nThis cleaned up spec would be called TLS 1.0 and published as an internet\ndraft for final comments in time for the December IETF meeting in San \nJose.\n\nSSL 3.0 is already widely deployed. Both Microsoft and Netscape have it \nnow\nin their browsers and servers, and many other companies now have SSL 3.0\nbrowsers, web servers, and non-web application under development with SSL\n3.0.\n\nThus I believe that is appropriate that the continued revisions of the SSL\n3.0 standard move to IETF change control, and it's authors seem willing to\nallow it to do so. Given this I think SSL 3.0 is an appropriate starting\npoint for IETF and TLS-WG, and that the the TLS-WG should ratify it with\nthe ambiguities cleaned up.\n\nFrom that solid base we can move toward TLS 1.1, which then might include\nMicrosoft's and Netscape's proposals.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "RE: Busted TLS Schedule, and a Proposal for Closur",
            "content": "At 8:44 PM -0700 10/17/96, Barb Fox wrote:\n>Your mail finally addresses the issue of change control.  So, what is the\n>incremental value of  \"adopting SSL as is\"  as an IETF standard without any\n>schedule of work beyond December?\n\nI think that it is fine for us to start scheduling now for work beyond\nDecember -- but I don't think it should stop us from doing what can be done\nto get TLS 1.0 out that meets the state of the art.\n\n>Whether you agree to call it consensus or not, there has been progress in\n>this working group on password authentication.  Other people obviously want\n>it too, and we're prepared to submit an RFC along with independent\n>implementations of working code.\n\nI think the password authentication stuff should be on the schedule -- but\nwhen you include the idea that there needs to be some implementation of it\n(preferably multiple) before it can be truely a \"standard\", then deployment\nTLS as a standard which does currently have multiple implementations\nshouldn't wait for it.\n\n>When and how do you (or better yet, one of the authors you cite) propose\n>that we incorporate it?   What about the other features/extensions/\n>cleanups that have been proposed? As you may recall, I absolutely agreed\n>with using SSL3 as the base.   It's the de facto standard now.  So, why not\n>at least try to improve it in some way, rather than wasting everybody's\n>time merely to rename it?\n\nI don't think it is a waste of time, nor \"merely to rename it\". Tim has\npages of notes and clarifications on what he has discovered in the spec,\nand I'm sure that others do as well. The Fortezza descriptions in it are a\nreal mess. Getting change control out of the current authors hands will be\na huge step forward. It may even be possible to split it up in this\nagressive time frame so that it will make it easier to manage change in the\nfuture.\n\n>I offer the counter proposal that we all agree to a much more realistic\n>schedule - say March or June IETF - for getting what would be a real TLS\n>proposal with several improvements and multiple implementations on the\n>table for consideration.\n\nI think getting some incremental changes into TLS in those time frames are\na very good idea, and we should do it. However, it has been 10 months since\nthe SSL 3.0 spec was released, and 5 months since there have been multiple\nimplementations. The net is rolling fast and I'm on the side of moving\nthings along so we can do more work rather than slowing them down so we can\ndo more work.\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "RE: Busted TLS Schedule, and a Proposal for Closur",
            "content": "Christopher,\n\n  Please read balow your comments/reply's.\n\nAt 11:15 PM 10/17/96 -0700, you wrote:\n>At 8:44 PM -0700 10/17/96, Barb Fox wrote:\n>>Your mail finally addresses the issue of change control.  So, what is the\n>>incremental value of  \"adopting SSL as is\"  as an IETF standard without any\n>>schedule of work beyond December?\n>\n>I think that it is fine for us to start scheduling now for work beyond\n>December -- but I don't think it should stop us from doing what can be done\n>to get TLS 1.0 out that meets the state of the art.\n>\n>>Whether you agree to call it consensus or not, there has been progress in\n>>this working group on password authentication.  Other people obviously want\n>>it too, and we're prepared to submit an RFC along with independent\n>>implementations of working code.\n>\n>I think the password authentication stuff should be on the schedule -- but\n>when you include the idea that there needs to be some implementation of it\n>(preferably multiple) before it can be truely a \"standard\", then deployment\n>TLS as a standard which does currently have multiple implementations\n>shouldn't wait for it.\n\n  Well we are in the process of implimentation in one case currently.  I would\nagree that multipul implimentations suould really be done befor any decleration\nfor  a\"Standard\" should be made.  It seems though that getting that done\nis really not doable without some extra help.  I would suggest that some\ndiscussion, thought short, should be done along these lines as an \"Aid\", if\nyou will for achieving (Multipul implimentations).  If I read this right,\nseems that this may be a solovable problem.  \n>\n>>When and how do you (or better yet, one of the authors you cite) propose\n>>that we incorporate it?   What about the other features/extensions/\n>>cleanups that have been proposed? As you may recall, I absolutely agreed\n>>with using SSL3 as the base.   It's the de facto standard now.  So, why not\n>>at least try to improve it in some way, rather than wasting everybody's\n>>time merely to rename it?\n>\n>I don't think it is a waste of time, nor \"merely to rename it\". Tim has\n>pages of notes and clarifications on what he has discovered in the spec,\n>and I'm sure that others do as well. The Fortezza descriptions in it are a\n>real mess. Getting change control out of the current authors hands will be\n>a huge step forward. It may even be possible to split it up in this\n>agressive time frame so that it will make it easier to manage change in the\n>future.\n\n  This might be a workable approach.  But it does have some cordanition\nproblems.\n>\n>>I offer the counter proposal that we all agree to a much more realistic\n>>schedule - say March or June IETF - for getting what would be a real TLS\n>>proposal with several improvements and multiple implementations on the\n>>table for consideration.\n>\n>I think getting some incremental changes into TLS in those time frames are\n>a very good idea, and we should do it. However, it has been 10 months since\n>the SSL 3.0 spec was released, and 5 months since there have been multiple\n>implementations. The net is rolling fast and I'm on the side of moving\n>things along so we can do more work rather than slowing them down so we can\n>do more work.\n\n  This is a tuff one here Christopher.  I would agree that moving along is \nusually best.  But I think some care might be taken in not puting out hurried\ncode.  If that can be accomplished with the WG you have now, GREAT!  If\nnot however, I think some momentum could be lost, not to mention \ncredibility.   What do you think?  Anybody?\n\nReguards,\n\n\n>\n>\n>------------------------------------------------------------------------\n>..Christopher Allen                  Consensus Development Corporation..\n>..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n>..                                             Berkeley, CA 94707-2116..\n>..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n>..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n>\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Outdated TLS charter on IETF pag",
            "content": "I got a kick out of visiting:\n\n  http://www.ietf.org/html.charters/tls-charter.html\n\nwhich is apparently dutifully maintained by the CNRI staff. Since the\nSSL 3 draft has now expired, the only listing under \"Current Internet\nDrafts\" is SSH!\n\nWhen we get agreement on a new charter and timetable, it would probably\nbe wise to notify the IETF so that their web pages can be kept up to\ndate :-).\n\nWith regard to Barb's comments on a TLS 1.0 with no new functionality,\na new I-D will have to be issued anyway since the baseline SSL 3.0 I-D\nis defunct.  Whether the new draft with clarifications is called\ndraft-ietf-tls-ssl-01.txt or draft-ietf-tls-00.txt is not a big deal -\nit'll be gone in 6 months anyway.  When we have a draft that is ready\nfor submission to the IESG for consideration as a Proposed Standard,\nthen the name will mean something.\n\nI agree with Christopher that we need to get an I-D with clarifications\non the table by December.  It doesn't have to be called TLS 1.0,\nand in fact probably shouldn't be.  I also agree with Barb that we should\nupdate the charter to reflect a realistic schedule for coming up with an\nimproved, consensus-based spec that is ready for RFC status.  I suggest\nMarch instead of June - we'll just have to try harder than we have for\nthe last 6 months to come to agreement.\n\n\n\n"
        },
        {
            "subject": "RE: Busted TLS Schedule, and a Proposal for Closur",
            "content": "Chris:\n\nJust one point of clarification:  multiple independent implementations of \npassword auth is something which is already underway.  Since the change to \nSSL3 is so minimal, it won't hold up even the current schedule.\n\nTom\n\n----------\nFrom: Christopher Allen[SMTP:ChristopherA@consensus.com]\nSent: Thursday, October 17, 1996 11:15 PM\nTo: Barb Fox\nCc: 'ietf-tls@w3.org'; 'Win Treese'; 'Jeff Schiller'\nSubject: RE: Busted TLS Schedule, and a Proposal for Closure\n\nAt 8:44 PM -0700 10/17/96, Barb Fox wrote:\n>Your mail finally addresses the issue of change control.  So, what is the\n>incremental value of  \"adopting SSL as is\"  as an IETF standard without \nany\n>schedule of work beyond December?\n\nI think that it is fine for us to start scheduling now for work beyond\nDecember -- but I don't think it should stop us from doing what can be \ndone\nto get TLS 1.0 out that meets the state of the art.\n\n>Whether you agree to call it consensus or not, there has been progress in\n>this working group on password authentication.  Other people obviously \nwant\n>it too, and we're prepared to submit an RFC along with independent\n>implementations of working code.\n\nI think the password authentication stuff should be on the schedule -- but\nwhen you include the idea that there needs to be some implementation of it\n(preferably multiple) before it can be truely a \"standard\", then \ndeployment\nTLS as a standard which does currently have multiple implementations\nshouldn't wait for it.\n\n>When and how do you (or better yet, one of the authors you cite) propose\n>that we incorporate it?   What about the other features/extensions/\n>cleanups that have been proposed? As you may recall, I absolutely agreed\n>with using SSL3 as the base.   It's the de facto standard now.  So, why \nnot\n>at least try to improve it in some way, rather than wasting everybody's\n>time merely to rename it?\n\nI don't think it is a waste of time, nor \"merely to rename it\". Tim has\npages of notes and clarifications on what he has discovered in the spec,\nand I'm sure that others do as well. The Fortezza descriptions in it are a\nreal mess. Getting change control out of the current authors hands will be\na huge step forward. It may even be possible to split it up in this\nagressive time frame so that it will make it easier to manage change in \nthe\nfuture.\n\n>I offer the counter proposal that we all agree to a much more realistic\n>schedule - say March or June IETF - for getting what would be a real TLS\n>proposal with several improvements and multiple implementations on the\n>table for consideration.\n\nI think getting some incremental changes into TLS in those time frames are\na very good idea, and we should do it. However, it has been 10 months \nsince\nthe SSL 3.0 spec was released, and 5 months since there have been multiple\nimplementations. The net is rolling fast and I'm on the side of moving\nthings along so we can do more work rather than slowing them down so we \ncan\ndo more work.\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "making progres",
            "content": "Based on the discussion over the past few days, I see a\ncouple of ways to make progress:\n\n1) Try to come to closure on an updated/fixed specification\nof SSLv3.0 for the standards track, with no major\nchanges\n2) Split the document into the handshake and record layer\npieces, and add additional documents for issues\nlike shared-key authentication as needed\n3) Continue discussion on changes such as shared-key\nauthentication and attribute certificates until\nwe have something to move forward\n\n#1 can probably happen quickly, but may delay getting some\nof the other issues resolved.\n\n#2 might be possible, but runs the risk of wading into a morass of\ncomplexity.\n\n#3 is looking like we are unlikely to close for the December meeting.\n\nSome questions to consider as well:\n\n1. If we pursued option #1, and then never did anything else,\nwould the WG have been successful?\n\n2. Can option #2 be reasonably executed in finite time, given\nthe experiences in other working groups?\n\n3. Is it better now to advance the state of the art, given that we\nhave some user requirements, or simply to codify the current use?\n\nComments appreciated.\n\n- Win Treese\n\n\n\n"
        },
        {
            "subject": "Re: making progres",
            "content": "Win,\n\n  Read below your comments please.\n\nAt 01:27 AM 10/21/96 -0400, you wrote:\n>Based on the discussion over the past few days, I see a\n>couple of ways to make progress:\n>\n>1) Try to come to closure on an updated/fixed specification\n>of SSLv3.0 for the standards track, with no major\n>changes\n>2) Split the document into the handshake and record layer\n>pieces, and add additional documents for issues\n>like shared-key authentication as needed\n>3) Continue discussion on changes such as shared-key\n>authentication and attribute certificates until\n>we have something to move forward\n\n  I have a problem with #2 suggestion here.  It could be done no doubt, but\nit might lead to a confusion in the long term and also is a bit disjointed.\n\n #1 is ok, but major changes have been suggested.  is this wise and progressinve\nenough?  I am not so sure.\n\nReguards,\n\n>\n>#1 can probably happen quickly, but may delay getting some\n>of the other issues resolved.\n>\n>#2 might be possible, but runs the risk of wading into a morass of\n>complexity.\n>\n>#3 is looking like we are unlikely to close for the December meeting.\n>\n>Some questions to consider as well:\n>\n>1. If we pursued option #1, and then never did anything else,\n>would the WG have been successful?\n>\n>2. Can option #2 be reasonably executed in finite time, given\n>the experiences in other working groups?\n>\n>3. Is it better now to advance the state of the art, given that we\n>have some user requirements, or simply to codify the current use?\n>\n>Comments appreciated.\n>\n>- Win Treese\n>\n>\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "Re: making progres",
            "content": "I'm a lurker on ietf-tls, and I don't have any direct stake in the\noutcome of the specific suggestions under discussion.  But I feel\nobliged to observe:  some of the parties in the discussions have\ngrumbled elsewhere that IETF standardization takes too long in such a\ndynamic marketplace, and that they can't wait for the process to churn\nalong.  I fear that this WG's failure to achieve something concrete\nsoon will only provide them with further ammunition and drive them to\nthrow up their hands, say \"we tried\", and go their own way.  That will\nbe bad for the industry.\n\nAs a political, rather than technical, gesture, I would urge the WG to\nmove as quickly as possible on Win Treese's first item:\n\n>  1) Try to come to closure on an updated/fixed specification\n>         of SSLv3.0 for the standards track, with no major\n>    changes\n\nIf we (you) can't do that, we (you) will sacrifice credibility and\npossibly lose the opportunity to influence the Web security community.\n\nDave Kristol\n\nP.S.  I usually don't add the default disclaimer, but just to be\nclear:  these are my private opinions, and they are not the result of\nany discussions with any vendors of Web software.\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "Re: making progres",
            "content": "> 1) Try to come to closure on an updated/fixed specification\n> of SSLv3.0 for the standards track, with no major\n> changes\n\nI'd like to see this happen.  At the very least, the existing\nRFC should get updated with the clarifications which I know all\nimplementors have contributed (including the list of errata),\nand then recirculated.\n\nThis of course leaves open the issue of \"who does it\".  I will\ngladly help review, applying my experience as an implementor.\nNo time to help write before the San Jose meeting, though.\n\n\n> 1. If we pursued option #1, and then never did anything else,\n> would the WG have been successful?\n\nBased on some recent discussions in other parts of the IETF,\nyes.  New WGs could be set up to do later work.\n\n\n> 3. Is it better now to advance the state of the art, given that we\n> have some user requirements, or simply to codify the current use?\n\nSSL v3.0 _does_ advance the state of the art, and it does\naddress the requirements of numerous users.\n\nIf do our best to ensure that it can later be compatibily\nextended (done already, yes?) then we can later advance the\nstate of the art by bringing additional users under our Big Top\nlater on, e.g. by supporting shared key authentication via\nGSS-API handshaking.  I suspect attribute certs may be more of\na PKI issue than a TLS issue.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "Re: making progres",
            "content": "Dave and all,\n\nAt 09:43 AM 10/21/96 -0700, you wrote:\n>> 1) Try to come to closure on an updated/fixed specification\n>> of SSLv3.0 for the standards track, with no major\n>> changes\n>\n>I'd like to see this happen.  At the very least, the existing\n>RFC should get updated with the clarifications which I know all\n>implementors have contributed (including the list of errata),\n>and then recirculated.\n\n  I agree here whole hartedly.  I think this should be a primary goal.\n>\n>This of course leaves open the issue of \"who does it\".  I will\n>gladly help review, applying my experience as an implementor.\n>No time to help write before the San Jose meeting, though.\n\n  Well, Dave, I am offering my services and experiance if it is needed.\n>\n>\n>> 1. If we pursued option #1, and then never did anything else,\n>> would the WG have been successful?\n>\n>Based on some recent discussions in other parts of the IETF,\n>yes.  New WGs could be set up to do later work.\n\n  I think that new WG's is a good idea, coordination may be a problem,\nbut managable.  I would be gad to participate and off er my implimentation\nexperiance here.  This could get the agressive schedual met possibly as well.\n>\n>\n>> 3. Is it better now to advance the state of the art, given that we\n>> have some user requirements, or simply to codify the current use?\n>\n>SSL v3.0 _does_ advance the state of the art, and it does\n>address the requirements of numerous users.\n>\n>If do our best to ensure that it can later be compatibily\n>extended (done already, yes?) then we can later advance the\n>state of the art by bringing additional users under our Big Top\n>later on, e.g. by supporting shared key authentication via\n>GSS-API handshaking.  I suspect attribute certs may be more of\n>a PKI issue than a TLS issue.\n\nI am not sure I agree that attribute certs is more of an PKI issue than a TLS\nissue.  Shared athentication should also be addressed as it is intragle in my\nopinion.\n\nReguards,\n\n>\n>- Dave\n>\n>\n>\nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "remove\n\n\n\n"
        },
        {
            "subject": "info on attribute cert",
            "content": "Could someone point me to references describing \"attribute certificates\"?\n\nGreatly Appreciated!\nNed Smith~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nIntel Architecture Labs  2111 N.E. 25th Ave.  Hillsboro, OR. 97124     \nPh: 503.264.2692 Fax: x1805  Email: mailto:nsmith@ibeam.intel.com   \nhttp://www.intel.com/ial/security/index.htm\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n\n"
        },
        {
            "subject": "Re: info on attribute cert",
            "content": "On Tue, 22 Oct 1996, Ned Smith wrote:\n> Could someone point me to references describing \"attribute certificates\"?\n\nhttp://lists.w3.org/Archives/Public/ietf-tls/msg00796.html is a starting\npoint. \n\n\n\n"
        },
        {
            "subject": "Re: making progres",
            "content": "Things have been a trifle quiet on TLS lately ... :-)\n\nI haven't said anything about Win's \"option #2\", namely producing an I-D\ncovering the TLS record layer (compatible with SSLv3), and presumably the\nbasic encoding rules (XDR-ish), and separating the handshaking into two or\nmore documents.  (SSLv3 compatible, shared key, and I predict debate re\nGSS-API, ISA/KMP, etc flavors.  Which is why I prefer option #1.)\n\nThis seems a reasonable thing from a technical standpoint, and I'll just\nflag my concern that it not delay concurrent progress on the rest of the\nprotocol.  If we make the HMAC in the TLS record layer cover the record\nheader, that would be a positive change!  (An SSL 3.1 could do that too.)\n\nI'm not opposed to shared key support, but I've not seen a proposal that's\nwell enough defined that I could support it.  For example, one that\nsupports both low security passphrases and higher security Kerberos\noptions, with clear operational distinctions like SSLv3 \"cipher suite\"\nmodel.  Promoting \"islands of interoperation\" is a bad thing IMHO, and\nwithout a better shared key proposal that's where we'd be heading.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: making progres",
            "content": "David,\n\n  Please read below your comments.\n\nDavid P. Kemp wrote:\n> \n> > From: david.brownell@Eng.Sun.COM (David Brownell - JavaSoft)\n> >\n> > I haven't said anything about Win's \"option #2\", namely producing an I-D\n> > covering the TLS record layer (compatible with SSLv3), and presumably the\n> > basic encoding rules (XDR-ish), and separating the handshaking into two or\n> > more documents.  (SSLv3 compatible, shared key, and I predict debate re\n> > GSS-API, ISA/KMP, etc flavors.  Which is why I prefer option #1.)\n> >\n> > This seems a reasonable thing from a technical standpoint, and I'll just\n> > flag my concern that it not delay concurrent progress on the rest of the\n> > protocol.\n> \n> Creating a document that codifies existing practice (i.e. SSL V3.0, with\n> technical clarifications but no new features) should be doable by December,\n> and I fully support the effort by Consensus and other developers with\n> actual implementation experience to do so.\n\n  David, I would be happy to assist here in that I do have some actual\nimplimentation experiance.  Let me know.\n> \n> I believe that that document should take the form of an Informational\n> (as opposed to Standards Track) RFC and should be called SSL 3.0 instead\n> of TLS 1.0, because my vision of TLS as an Internet Standard is somewhat\n> different than SSL as it currently exists.  But I fully agree that our\n> credibility is on the line if we can't even produce a document that defines\n> existing practice, having had 9 months from the date of the SSL 3.0 draft\n> and 6 months from Montreal to do so.\n\n  Got a problem here, Dave.  Two diffrent TLS standards for two diffrent \n\"Flavors\" of TLS is somewhat too confusing in my opinion.\n> \n> >  If we make the HMAC in the TLS record layer cover the record\n> > header, that would be a positive change!  (An SSL 3.1 could do that too.)\n> \n> The HMAC does cover the record header, except for the deprecated record\n> version field (as opposed to the Handshake version field, which is the one\n> that counts.)  The record format is a bit ideosyncratic though, and defining\n> a cleaner one independently of the handshake exchange is one reason for\n> having separate documents.\n> \n> (As an aside, the Record layer changes I'd like to see are:\n> \n>  1. Make the HMAC calculation conform to the IPSEC HMAC - xor the\n>  padding instead of concatenating it.  I don't know Hugo's rationale\n>  for changing the definition, and I don't know if there are any problems\n>  with the concatenated-padding HMAC, but absent any rationale to the\n>  contrary, TLS should use the standard technique instead of remaining\n>  gratuitously different.\n>  \"HMAC: Keyed-Hashing for Message Authentication\" was submitted to the\n>  IESG as an Informational RFC in August.  It has not appeared as an\n>  official RFC yet, but was published on the IPSEC mailing list on 24\n>  October.\n> \n>  2. Either clarify the meaning of the Record version number, or eliminate\n>  it.  That field appears to be a useless holdover from SSL V2 (especially\n>  since it was conspicuously omitted from the MAC calculation).  If there\n>  is a need for a Record version distinct from the Handshake protocol\n>  version, then it should be covered by the MAC. (Conventional wisdom\n>  is that protocols should always have a version number, so I guess the\n>  record layer should too, even if it remains 1 forever. But there's no\n>  need to waste two bytes on it when one byte is more than sufficient :-)\n> \n> I don't want to discuss the merits of these changes now - this is just\n> an example of why a modular document structure is preferable to a\n> monolithic document.  The appropriate time to discuss protocol changes\n> is after SSL 3.0 is published.)\n> \n> > I'm not opposed to shared key support, but I've not seen a proposal that's\n> > well enough defined that I could support it.  For example, one that\n> > supports both low security passphrases and higher security Kerberos\n> > options, with clear operational distinctions like SSLv3 \"cipher suite\"\n> > model.  Promoting \"islands of interoperation\" is a bad thing IMHO, and\n> > without a better shared key proposal that's where we'd be heading.\n> \n> It is generally accepted IETF practice to categorize mechanisms as\n> \"REQUIRED\", \"RECOMMENDED\", and \"OPTIONAL\".  All protocols must define\n> at least one REQUIRED mechanism, to enable interoperability among all\n> conforming implementations. For TLS client authentication, I fully\n> expect that support for client certs will be REQUIRED.\n\n  I hope that  client certs will be REQUIRED.  But I concur I have not\nseen\nany clear perposal to that effect.  Somewhat puzzeling I think,\nespecially\nsience alot of discussion was done on that subject.\n> \n> But defining OPTIONAL mechanisms within the standard at least expands\n> the \"islands of interoperation\" into \"continents\" :-).  If there is\n> a market need, it will be satisfied, either through vendor-proprietary\n> means or through standardization.  I prefer the latter, particularly\n> since some vendor-proprietary shared-key-auth mechanisms might not be\n> as high quality as the proposed challenge/response mechanism.\n\n  Well if I read you right here, I have some problems with defining\n\"OPTIONAL\" mechanisms as part of any standard as IETF currently defines\n\"OPTIONAL\".  It is either required or not. Otherwise the \"Standard\" part\nleaves some meaning behind form a \"Standards\"  point of view.  But that\nis\na whole diffrent discussion. \n> \n> Since the application already needs to interact with the TLS protocol\n> to do shared-key-auth, it already knows whether it's dealing with\n> \"SKA-16\" (user-chosen passphrases) or \"SKA-128\" (128 bit true random\n> secret keys).  But if you can articulate why a Quality of Protection\n> field might be needed within the protocol, I'm sure such a field could be\n> easily added to the proposal.\n\n  Well, I think this needs to be defind and decided upon.  Not just an\naddition to a perposed standard.\n\n-- \nJeffrey A. Williams\nSR.Internet Network Eng. \nCEO., IEG., INC.,  Representing PDS .Ltd.\nWeb: http://www.pds-link.com \nPhone: 214-793-7445 (Direct Line)\nDirector of Network Eng. and Development IEG. INC.\n\n\n\n"
        },
        {
            "subject": "RE: making progres",
            "content": ">From: david.brownell@Eng.Sun.COM[SMTP:david.brownell@Eng.Sun.COM]\n>\n>> Our current shared key proposal does not create \"islands of\n>> interoperation\"; it specifies a single shared-key-based client\n>> authentication mechanism.\n>\n>Well, I don't think you can have it both ways.\n>\n>Earlier, MS said that it was mechanism-neutral in response to\n>criticism that it's not clear what character set or language to\n>use for the \"display_string\" and \"challenge\" values.\n\nI believe that what I said is that the content of the \"display_string\"\nvalue is left to the discretion of the next-higher layer.  In our\ncurrent proposal, the authentication mechanism is otherwise completely\nstandardized.\n\n>\n>Now, I hear that it is in fact a single new mechanism (as I'd assumed\n>originally).  And one which evidently does not support the primary\n>shared-key standard in use on the Internet, Kerberos.  In which case\n>it appears that the internationalization issues are real.\n\n\nI think I might be able to resolve some of the confusion here.  An\nearlier proposal of ours included a \"private\" authentication method in\naddition to the \"standard\" one.  This \"private\" method was intended to\nallow explicitly for non-standard authentication response formats.  In\nresponse to criticism from several quarters, and after reconsidering the\nissue ourselves, we removed this feature.  Our proposal is now for one\nsingle interoperable shared-key authentication mechanism.  \n\nAs for Kerberos, it is not simply a shared-key authentication mechanism;\nrather, it is an entire distributed security protocol, including key\nmanagement, authentication and key exchange.  I see no way to \"support\"\nit in a completely incompatible context like TLS as it is currently\nenvisioned.  If you have ideas on that score, I'd be interested to hear\nthem; otherwise, our assumption is that Kerberos users would migrate to\nTLS, allowing them to keep their infrastructure (in particular, their\npassword databases and overall authentication server/KDC-based\narchitecture) while replacing the low-level machinery that provides the\nsecurity functionality.\n\n>\n>I expect you can understand this inconsistency doesn't cause your\n>proposal to come across very favorably.  I was quite serious when\n>I said that the proposal wasn't well enough defined.  That's very\n>distinct from the issue of whether it's a good thing to support a\n>shared key framework, or the issue of whether you're confusing things\n>by positioning this as \"shared key support\", which is an rather\n>general notion that is relatively well understood.\n\nWe are certainly not \"positioning this as 'shared key support'\".\nRather, we are proposing a specific mechanism for using a shared key for\nclient authentication, within the framework of an SSL-style\nserver-authenticated public-key key exchange as provided by TLS.\n\n>\n>It'd be a lot better if you just sent a bunch of uncharacterized\n>opaque data with some kind of identifier for the shared key system\n>in use ... that kind of approach would stand a chance of supporting\n>the non-Microsoft shared-key systems out there; you'd win friends if\n>you suggested ways to use the tokens GSS-API produces.\n>\n\nI assume you mean Kerberos tickets; I don't see why TLS (whether with\nshared-key or public-key client authentication) can't simply be\nimplemented under GSS-API.  But the parallel co-existence of Kerberos\nwith TLS raises so many questions (Which key exchange is used?  Which\nserver authentication?) that I'd rather understand what, exactly, you\nhave in mind before responding.\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)  \n\n\n\n"
        },
        {
            "subject": "Registered Ports for TLS Connections",
            "content": "Is it the expectation of the TLS work group, that any TCP-based protocol \nthat listens on a well-known port, and now wants a TLS-secured version, \nobtain another well-known port for that purpose? \n\nOr are there other strategies that you could suggest.\n\nFor example, would it be frowned on to have a TLS implementation that \ndynamically distinguishes ClientHello from the (insecure) Application \nProtocol on a given port (assuming this can be done deterministically)? \n\njohn_h_wilson@ccm.jf.intel.com\n\n\n\n"
        },
        {
            "subject": "Re: Registered Ports for TLS Connections",
            "content": "John H Wilson wrote:\n> \n> Is it the expectation of the TLS work group, that any TCP-based protocol\n> that listens on a well-known port, and now wants a TLS-secured version,\n> obtain another well-known port for that purpose?\n> \n> Or are there other strategies that you could suggest.\n> \n> For example, would it be frowned on to have a TLS implementation that\n> dynamically distinguishes ClientHello from the (insecure) Application\n> Protocol on a given port (assuming this can be done deterministically)?\n> \n> john_h_wilson@ccm.jf.intel.com\n\nThis has been suggested on several occassions, and I've been one of the\nopponents to such schemes. The reason is in the last line Mr. Wilson's\nproposal, the assumption. That assumption has non-zero risk in that it\nmight, under unforseen circumstances, result in ambiguious behavior.\n\nTo reiterate my position, I believe that a protocol (in the IP world) is\nbasically defined by the well-known port associated with that protocol.\nTo add an SSL layer to such an existing protocol is equivalent to\ncreating a new protocol and therefore demands a new (different) port\nnumber.\n\nHowever, I (and I don't think anybody contests this) believe that any\nnew protocol definition should make provision for switching between\nsecure and insecure associations.\n\nI would also be the first to admit that my position is a bit of a purist\nposition. Still, somebody's got to represent the fringe :-)\n\nAO\n\n-- \nAlan O. FreierCorporate Cynic\n<freier@netscape.com>(415) 937-3638 (work)\n\n\n\n"
        },
        {
            "subject": "Example of how attribute certificates are used",
            "content": "Folks,\nThere have been several email messages describing what attribute\ncertificates are, but none which detail any protcols in which they're\nused. Several scenarios have been mentioned, but nothing that I would\nclassify as a protocol. \nHas this been discussed? I haven't seen anything like this\nin the archives.  Sorry if I'm retreading old topics. \n\nthanks,\n\nTom Holodnik\nManager of Systems Development\nGALT Technolgies, Inc. \nP: (412)-681-6100\nF: (412)-681-6936\n\n\nps- Is there a new Internet draft for SSL which includes the\nerrata? \n\n\n\n"
        },
        {
            "subject": "Re: Example of how attribute certificates are used",
            "content": "Tom Holodnik wrote:\n> \n> Folks,\n>      There have been several email messages describing what attribute\n> certificates are, but none which detail any protcols in which they're\n> used. Several scenarios have been mentioned, but nothing that I would\n> classify as a protocol.\n>      Has this been discussed? I haven't seen anything like this\n> in the archives.  Sorry if I'm retreading old topics.\n> \n> thanks,\n> \n> Tom Holodnik\n> Manager of Systems Development\n> GALT Technolgies, Inc.\n> P: (412)-681-6100\n> F: (412)-681-6936\n> \n> ps- Is there a new Internet draft for SSL which includes the\n> errata?\n   \n  Hi, this may be useful though it's not exactly what you asked for:\n\n       We are currently developing a hierarchic distributed key\nmanagement and certification protocol that could be really useful for\nInternet as it would not concentrate the load of key management on one\nserver. What is more, it does not cause thse famous \"islands of\ninteroperation\" because it can grow dinamically and can connect those\nislands. We would like to know how can we propose it, or who can tell us\nthe way all the development of Internet Standards is carried out.\n\n   Thank you.\n   Antonio.\n\n                          ~~~~~  \n                         ( o o )\n  +----------------o000-----U------000o--------------------+\n  !           _   ,                                        !\n  ! Antonio Mana Gomez               eMail: amg@lcc.uma.es !\n  !                                                        !\n  ! Departamento de Lenguajes y Ciencias de la Computacion !\n  !        E.T.S.I.Informatica.    Desp. 1.2.B.19          !\n  !                Campus de Teatinos.                     !\n  !               29071 MALAGA (SPAIN)                     !\n  !                                                        !\n  ! Phone: (+34) 5 213 27 54        Fax: (=34) 5 213 13 97 !\n  +--------------------------------------------------------+\n\n\n\n"
        },
        {
            "subject": "I-D ACTION:draft-ietf-tls-kerb-cipher-suites00.tx",
            "content": " A New Internet-Draft is available from the on-line Internet-Drafts \n directories. This draft is a work item of the Transport Layer Security \n Working Group of the IETF.                                                \n\n       Title     : Addition of Kerberos Cipher Suites to Transport Layer \n                   Security (TLS)                                          \n       Author(s) : A. Medvinsky, M. Hur\n       Filename  : draft-ietf-tls-kerb-cipher-suites-00.txt\n       Pages     : 3\n       Date      : 11/07/1996\n\nThis document proposes the addition of new cipher suites to the TLS \nprotocol (SSL 3.0) to support Kerberos-based authentication.  Kerberos \ncredentials are used to achieve mutual authentication and to establish a \nmaster secret which is subsequently used to secure client-server \ncommunication.                                                             \n\nInternet-Drafts are available by anonymous FTP.  Login with the username\n\"anonymous\" and a password of your e-mail address.  After logging in,\ntype \"cd internet-drafts\" and then\n     \"get draft-ietf-tls-kerb-cipher-suites-00.txt\".\nA URL for the Internet-Draft is:\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-kerb-cipher-suites-00.txt\n \nInternet-Drafts directories are located at:\n                                                \n     o  Africa:  ftp.is.co.za                    \n                                                \n     o  Europe:  nic.nordu.net            \n                 ftp.nis.garr.it                 \n                                                \n     o  Pacific Rim: munnari.oz.au               \n                                                \n     o  US East Coast: ds.internic.net           \n                                                \n     o  US West Coast: ftp.isi.edu               \n                                                \nInternet-Drafts are also available by mail.\n                                                \nSend a message to:  mailserv@ds.internic.net. In the body type: \n     \"FILE /internet-drafts/draft-ietf-tls-kerb-cipher-suites-00.txt\".\n\nNOTE: The mail server at ds.internic.net can return the document in\n      MIME-encoded form by using the \"mpack\" utility.  To use this\n      feature, insert the command \"ENCODING mime\" before the \"FILE\"\n      command.  To decode the response(s), you will need \"munpack\" or\n      a MIME-compliant mail reader.  Different MIME-compliant mail readers\n      exhibit different behavior, especially when dealing with\n      \"multipart\" MIME messages (i.e., documents which have been split\n      up into multiple messages), so check your local documentation on\n      how to manipulate these messages.\n\n\n\nBelow is the data which will enable a MIME compliant mail reader \nimplementation to automatically retrieve the ASCII version\nof the Internet-Draft.\n\n\n\n\n\nMessage/External-body attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Kerberos Opinion Pol",
            "content": "Dear sirs,\n  \n   We are carrying out an opinion poll to know how the industry\nevaluates Kerberos Centralized Scheme about efficiency and security and\nhow would you solve the problems (say traffic flow, KDC bottleneck, KDC\nSecurity,...) that arise with such schemes. We also want to propose\nanother multilevel decentralized key distribution scheme which allow\nefficient control, multilevel authentication security, complete\ninteroperability, true certifying authorities, not replicated key\nstoring and easy implementation. Would you please send eMail to the\naddress stated below giving us your opinion or asking anything else you\nwould like to know about us or uor proposal. Thank you very much.\n         Trully Yours.\n         Antonio Mana-Gomez.\n   \n                          ~~~~~\n                         ( o o )\n  +----------------o000-----U------000o--------------------+\n  !           _   ,                                        !\n  ! Antonio Mana Gomez               eMail: amg@lcc.uma.es !\n  !                                                        !\n  ! Departamento de Lenguajes y Ciencias de la Computacion !\n  !        E.T.S.I.Informatica.    Desp. 1.2.B.19          !\n  !                Campus de Teatinos.                     !\n  !               29071 MALAGA (SPAIN)                     !\n  !                                                        !\n  ! Phone: (+34) 5 213 27 54        Fax: (+34) 5 213 13 97 !\n  +--------------------------------------------------------+\n\n\n\n"
        },
        {
            "subject": "no meeting in San Jos",
            "content": "TLS working group members:\n\nFor personal reasons, I will be unable to attend the IETF\nmeeting in San Jose in December. After talking this over\nwith Jeff Schiller (Security Area Director) , I have decided\nthat the working group will not meet in San Jose. Instead,\nI would like to review the outstanding issues on the mailing\nlist and reach some conclusions on moving a document\nforward on the standards track.\n\nI realize that this is unfortunate, and I apologize for\nany inconvenience.\n\nWin Treese\n\n\n\n"
        },
        {
            "subject": "Re: no meeting in San Jos",
            "content": "At 6:36 PM -0800 11/18/96, Win Treese wrote:\n>I have decided\n>that the working group will not meet in San Jose.\n\nI consider this quite unfortunate, as so many people involved with SSL will\nbe able to attend the San Jose meeting as it is in the heart of Silicon\nValley.\n\nI'd be willing to schedule a specific evening to meet with any parties\ninterested in talking during the IETF conference about SSL 3.0 or TLS. Any\nsuggestions as to day and time?\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "RE: no meeting in San Jos",
            "content": "Chris:\n\nGreat idea!  How about during the same time slot so that people who aren't on the list but were planning to attend the wg meeting can come? \n\nBarb\nbfox@microsoft.com\n\n----------\nFrom:  Christopher Allen[SMTP:ChristopherA@consensus.com]\nSent:  Monday, November 18, 1996 11:47 PM\nTo:  ietf-tls@w3.org\nSubject:  Re: no meeting in San Jose\n\nAt 6:36 PM -0800 11/18/96, Win Treese wrote:\n>I have decided\n>that the working group will not meet in San Jose.\n\nI consider this quite unfortunate, as so many people involved with SSL will\nbe able to attend the San Jose meeting as it is in the heart of Silicon\nValley.\n\nI'd be willing to schedule a specific evening to meet with any parties\ninterested in talking during the IETF conference about SSL 3.0 or TLS. Any\nsuggestions as to day and time?\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "meeting in San Jos",
            "content": "After some further discussion, Chris Allen has agreed\nto moderate a meeting of the working group in San Jose,\nin the originally scheduled time slot on Monday,\nDecember 9. Chris and I will be posting a preliminary\nagenda for the meeting shortly.\n\nWin Treese\n\n\n\n"
        },
        {
            "subject": "Re: Closing on sharedkey authenticatio",
            "content": "Please, turn me off your mailing list.\nI've loose this address\n\nTWAIN@NS.SKYNET.RU\n\n\n\n"
        },
        {
            "subject": "I-D ACTION:draft-ietf-tls-ssl-version300.tx",
            "content": "Note:  This announcement is being re-sent with a new filename.\n\n A New Internet-Draft is available from the on-line Internet-Drafts \n directories. This draft is a work item of the Transport Layer Security \n Working Group of the IETF.                                                \n\n\n       Title     : The SSL Protocol Version 3.0                            \n       Author(s) : A. Freier, P. Karlton, P. Kocher\n       Filename  : draft-ietf-tls-ssl-version3-00.txt\n       Pages     : 63\n       Date      : 11/21/1996\n\nThis document specifies Version 3.0 of the Secure Sockets Layer (SSL V3.0) \nprotocol, a security protocol that provides communications privacy over the\nInternet.  The protocol allows client/server applications to communicate in\na way that is designed to prevent eavesdropping, tampering, or message \nforgery.                                                                   \n\nInternet-Drafts are available by anonymous FTP.  Login with the username\n\"anonymous\" and a password of your e-mail address.  After logging in,\ntype \"cd internet-drafts\" and then\n     \"get draft-ietf-tls-ssl-version3-00.txt\".\nA URL for the Internet-Draft is:\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-ssl-version3-00.txt\n \nInternet-Drafts directories are located at:\n                                                \n     o  Africa:  ftp.is.co.za                    \n                                                \n     o  Europe:  nic.nordu.net            \n                 ftp.nis.garr.it                 \n                                                \n     o  Pacific Rim: munnari.oz.au               \n                                                \n     o  US East Coast: ds.internic.net           \n                                                \n     o  US West Coast: ftp.isi.edu               \n                                                \nInternet-Drafts are also available by mail.\n                                                \nSend a message to:  mailserv@ds.internic.net. In the body type: \n     \"FILE /internet-drafts/draft-ietf-tls-ssl-version3-00.txt\".\n\nNOTE: The mail server at ds.internic.net can return the document in\n      MIME-encoded form by using the \"mpack\" utility.  To use this\n      feature, insert the command \"ENCODING mime\" before the \"FILE\"\n      command.  To decode the response(s), you will need \"munpack\" or\n      a MIME-compliant mail reader.  Different MIME-compliant mail readers\n      exhibit different behavior, especially when dealing with\n      \"multipart\" MIME messages (i.e., documents which have been split\n      up into multiple messages), so check your local documentation on\n      how to manipulate these messages.\n\n\n\nBelow is the data which will enable a MIME compliant mail reader \nimplementation to automatically retrieve the ASCII version\nof the Internet-Draft.\n\n\n\n\n\nMessage/External-body attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "TLS document",
            "content": "In order to move forward with the TLS specification,\nI have asked Tim Dierks and Chris Allen (both of \nConsensus) to serve as editors for the TLS draft.  They\nwill shortly be submitting a couple of drafts:\n\n1. A base TLS document derived from SSLv3. It incorporates\nknown errata as well as several clarifications. At this point,\nit is a draft for discussion, so we will need to agree on what\nchanges need to be made.\n\n2. A set of proposals for more substantive changes and\nimprovements to the protocol. Those that we adopt will\nbe edited into the base document.\n\nThe SSLv3 draft that Tom Weinstein submitted is the\nspecification for SSLv3, with several corrections that\nhave accumulated over time. For a variety of reasons, it's\nimportant to have this draft for the record.\n\nPlease join me in welcoming Tim and Chris as editors.\n\nWin Treese\n\n\n\n"
        },
        {
            "subject": "IETFTLS Meeting in San Jose, CA Dec. 9th to Discuss SSL 3.",
            "content": "The TLS-WG (Transport Layer Security Working Group) of the IETF (Internet\nEngineering Task Force) will be having a meeting during the 37th IETF\nmeeting in San Jose in December, at the Fairmont Hotel.\n\nThe TLS-WG is chartered to \"provide methods for implementing privacy,\nauthentication, and integrity above the transport layer.\" At the last\nmeeting of the TLS-WG in Montreal the TLS-WG decided to base its design\nusing SSL 3.0 as a starting point.\n\nThe meeting is currently schedule be two hours on Monday, December 9th, at\n1530-1730 during the second afternoon session. The meeting will be\nmoderated by Christopher Allen <ChristopherA@consensus.com>, as Win Treese\n<treese@OpenMarket.com>, the TLS-WG chair, will not be able to attend.\n\nThere is no \"membership\" associated the IETF, so anyone that is willing to\ncontribute to the technical goals of the IETF is welcome at the conference.\nFees for the conference are only $270. More information and registration\ndetails on the IETF meeting in San Jose can be found at\n<http://www.ietf.org/meetings/SanJose.html>.\n\nWe are working now on the agenda for this meeting -- if you have any\nspecific agenda items or presentations that you'd like to make, we need to\nknow immediately -- in fact, if you want your presentation to be in the\nproceedings the presentation must be submitted to the IETF by Monday,\nJanuary 6. (Sorry for the short notice, the TLS-WG meeting was only put\nback on the schedule last week.) Time for TLS-WG meeting is limited\n(2-hours) so we regret if we are not able to accept all agenda items or\npresentations. Please send your agenda items or presentations to Win Treese\n<treese@OpenMarket.com> and Christopher Allen <ChristopherA@consensus.com>.\n\nIETF working groups do most of their activities through mailing lists and\nthrice-annual IETF meetings. The first official TLS working group meeting\nwas June 1996 in Montreal. (Before then it was an unofficial BOF \"birds of\na feather\" group.)\n\nThe discussion list for IETF-TLS is at IETF-TLS@W3.ORG. You subscribe and\nunsubscribe by sending to IETF-TLS-REQUEST@W3.ORG with subscribe or\nunsubscribe in the SUBJECT of the message. Archives of the list are at\n        <http://lists.w3.org/Archives/Public/ietf-tls>\n\nThere was a day-long pre-Montreal meeting last May in Palo Alto, which\ndiscussed some technical issues with SSL and some ideas on the future of\nTLS. The minutes of this meeting are at\n        <http://lists.w3.org/Archives/Public/ietf-tls/msg00185.html>\n\nThe minutes of the last official TLS-WG meeting in Montreal\nare in two messages at\n        <http://lists.w3.org/Archives/Public/ietf-tls/msg00217.html>\n        <http://lists.w3.org/Archives/Public/ietf-tls/msg00212.html>\n\nSince the last TLS-WG meeting several internet drafts have been submitted\nand are available now:\n\n* The updated (November 18, 1996) version of Netscape's SSL specification\n  <ftp://ftp.ietf.org/internet-drafts/draft-ietf-tls-ssl-version3-00.txt>\n\n* Proposal to add Kerberos to the TLS\n  <ftp://ftp.ietf.org/internet-drafts/draft-ietf-tls-kerb-cipher-suites-00.txt>\n\n* Suggestions to add shared key authentication to TLS\n  <ftp://ftp.ietf.org/internet-drafts/draft-ietf-tls-passauth-00.txt>\n\nAny other submissions of internet-drafts for the IETF San Jose meeting must\nbe submitted by Tuesday, November 26.\n\nWe hope to have a new document \"draft-ietf-tls-tls-00.txt\" available soon.\nThis will be a TLS 1.0 document derived from November 18 SSL 3.0 draft.\nThis document will incorporate known errata as well as several\nclarifications to the Netscape draft, but will have no substantive changes\nto the \"bits on the wire\" of the SSL 3.0 protocol. This draft will be the\nstarting point for future discussions, and from its base we will work\ntogether to agree on what changes need to be made.\n\nAnother new document will \"draft-ietf-tls-changes-00.txt\". This will be set\nof some of the less controversial proposals for substantive changes to SSL\n3.0 toward a final TLS 1.0 protocol. Those proposal that we adopt will\nbe edited back into the base document.\n\nThese two documents are being edited by Tim Dierks <TimD@consensus.com> and\nChristopher Allen <ChristopherA@consensus.com>.\n\nOther documents that may be of interest to TLS-WG attendees are the\nSSL-Talk FAQ at <http://www.consensus.com/security/ssl-talk-faq.html>.\n\nOther sessions at the IETF San Jose meeting that may be of interest to\nTLS-WG members are:\n\n* Monday, December 9th\n  - 1000-1130 HyperText Transfer Protocol WG\n  - 1300-1500 Public-Key Infrastructure (X.509) WG\n  - 1930-2200 S/MIME BOF\n* Tuesday, December 10th\n  - 0900-1100 HyperText Transfer Protocol WG\n* Wendesday, December 11th\n  - 0900-1130 Domain Name System Security WG\n  - 1300-1500 Simple Public Key Infrastructure BOF\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "I-D ACTION:draft-ietf-tls-passauth00.tx",
            "content": " A New Internet-Draft is available from the on-line Internet-Drafts \n directories. This draft is a work item of the Transport Layer Security \n Working Group of the IETF.                                                \n\n       Title     : Addition of Shared Key Authentication to Transport Layer\n                   Security (TLS)                                          \n       Author(s) : D. Simon\n       Filename  : draft-ietf-tls-passauth-00.txt\n       Pages     : 5\n       Date      : 11/22/1996\n\nThis document presents a shared-key authentication mechanism for the TLS \nprotocol.  It is intended to allow TLS clients to authenticate using a \nsecret key (such as a password) shared with either the server or a \nthird-party authentication service.  The security of the secret \nauthentication key is augmented by its integration into the normal SSL/TLS \nserver authentication/key exchange mechanism.                              \n\nInternet-Drafts are available by anonymous FTP.  Login with the username\n\"anonymous\" and a password of your e-mail address.  After logging in,\ntype \"cd internet-drafts\" and then\n     \"get draft-ietf-tls-passauth-00.txt\".\nA URL for the Internet-Draft is:\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-passauth-00.txt\n \nInternet-Drafts directories are located at:\n                                                \n     o  Africa:  ftp.is.co.za                    \n                                                \n     o  Europe:  nic.nordu.net            \n                 ftp.nis.garr.it                 \n                                                \n     o  Pacific Rim: munnari.oz.au               \n                                                \n     o  US East Coast: ds.internic.net           \n                                                \n     o  US West Coast: ftp.isi.edu               \n                                                \nInternet-Drafts are also available by mail.\n                                                \nSend a message to:  mailserv@ds.internic.net. In the body type: \n     \"FILE /internet-drafts/draft-ietf-tls-passauth-00.txt\".\n\nNOTE: The mail server at ds.internic.net can return the document in\n      MIME-encoded form by using the \"mpack\" utility.  To use this\n      feature, insert the command \"ENCODING mime\" before the \"FILE\"\n      command.  To decode the response(s), you will need \"munpack\" or\n      a MIME-compliant mail reader.  Different MIME-compliant mail readers\n      exhibit different behavior, especially when dealing with\n      \"multipart\" MIME messages (i.e., documents which have been split\n      up into multiple messages), so check your local documentation on\n      how to manipulate these messages.\n\n\n\nBelow is the data which will enable a MIME compliant mail reader \nimplementation to automatically retrieve the ASCII version\nof the Internet-Draft.\n\n\n\n\n\nMessage/External-body attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Netscape and Passwords",
            "content": "I happened across the following quote from the Technology Preview of\nConstellation  - Netscape's new netcasting and desktop-customization\ntechnology. \n\n\"Constellation will allow you to access your HomePort from any location\nor any computer. You no longer need to be tied to your desktop to be\nproductive. For example, when traveling between home and work or between\nmultiple offices, you can enter your ***user name and password*** for\nyour HomePort and work with all of your information, just as you left\nit, regardless of where you are or what type of computer you are\nrunning. \"\n\nGiven the reluctance of Netscape to support Passwords in the TLS\nprotocol, I am a bit curious as to the underlying technology Netscape\nwill be using for  password based authentication to your \"HomePort.\"\n\nDoes anyone have any insight into this?\n\n\n\n"
        },
        {
            "subject": "Re: Netscape and Passwords",
            "content": "At 1:29 PM -0800 11/25/96, John Macko wrote:\n>I happened across the following quote from the Technology Preview of\n>Constellation  - Netscape's new netcasting and desktop-customization\n>technology.\n>\n>\"Constellation will allow you to access your HomePort from any location\n>or any computer. You no longer need to be tied to your desktop to be\n>productive. For example, when traveling between home and work or between\n>multiple offices, you can enter your ***user name and password*** for\n>your HomePort and work with all of your information, just as you left\n>it, regardless of where you are or what type of computer you are\n>running. \"\n>\n>Given the reluctance of Netscape to support Passwords in the TLS\n>protocol, I am a bit curious as to the underlying technology Netscape\n>will be using for  password based authentication to your \"HomePort.\"\n>\n>Does anyone have any insight into this?\n\nI don't think that Netscape has objections to supporting passwords --\ninstead I think the various point of views on password authentication have\nmore to do with different ideas on the appropriate layer in the networking\nmodel to add authentication.\n\nUltimately the problem resides in the fact that the technology that we are\nusing to secure the integrity of a connection (i.e. the rsa or\ndiffie-helman key exchange to derive a shared master secret for encryption)\nis closely related to the technology that we use to authenticate each end\nof the connection (i.e. RSA or DSS certificates.)\n\nI believe that Microsoft's position is that since SSL offers authentication\n(through the use of certificates) that other forms of authentication should\nbe done at that layer as well.\n\nIn contrast, Netscape's position appears to be that certificate-based\nauthentication is fundementally different (and believed to be more secure)\nthan password based authentication, thus it doesn't deserve to be at the\nsame level.\n\nOthers have objections to SSL for architectural reasons -- they say that\nSSL should not be doing authentication at all, and/or that it should rely\non other protocols or layers for key exchange and authentication.\n\nI'm not sure how this will all pan out. There is a legitimate user need for\nstandardizing non-certificate based authentication (whether secret-key for\nlegacy purposes, kerberos, or some other authentication mechanism) yet it\nthere is also a legitimate concern regarding both architecture issues\n(layering) and the differing levels of security offered by different\nauthentication schemes.\n\nSo far there are two internet drafts relating to alternative authentication\nmethods for TLS:\n<ftp://ds.internic.net/internet-drafts/draft-ietf-tls-passauth-00.txt>\n<ftp://ds.internic.net/internet-drafts/draft-ietf-tls-kerb-cipher-suites-00.txt\n>\n\nI have heard that there may even be two more internet-drafts submitted on\nthis issue by tomorrow's deadline!\n\nObviously this will be an important issue to resolve for the future of TLS,\nhowever, I do hope that this issue doesn't get in the way of moving SSL 3.0\nunder IETF change control. That goal is my personal objective.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "TLS WG meeting in San Jos",
            "content": "Could someone please send me the date/time of the TLS workgroup meeting \nin San Jose?\n\nThanks\njohn_h_wilson@ccm.jf.intel.com\n\n\n\n"
        },
        {
            "subject": "Re: Netscape and Passwords",
            "content": "John Macko wrote:\n> \n> I happened across the following quote from the Technology Preview of\n> Constellation  - Netscape's new netcasting and desktop-customization\n> technology.\n> \n> \"Constellation will allow you to access your HomePort from any\n> location or any computer. You no longer need to be tied to your\n> desktop to be productive. For example, when traveling between home and\n> work or between multiple offices, you can enter your ***user name and\n> password*** for your HomePort and work with all of your information,\n> just as you left it, regardless of where you are or what type of\n> computer you are running. \"\n> \n> Given the reluctance of Netscape to support Passwords in the TLS\n> protocol, I am a bit curious as to the underlying technology Netscape\n> will be using for  password based authentication to your \"HomePort.\"\n> \n> Does anyone have any insight into this?\n\nObviously the quoted paragraph was written by someone in marketing who\ndoesn't know any better.  It should read \"insert your hardware token\nand enter your PIN\".\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Netscape and Passwords",
            "content": "Christopher Allen wrote:\n> \n> At 1:29 PM -0800 11/25/96, John Macko wrote:\n> >I happened across the following quote from the Technology Preview of\n> >Constellation  - Netscape's new netcasting and desktop-customization\n> >technology.\n> >\n> >\"Constellation will allow you to access your HomePort from any location\n> >or any computer. You no longer need to be tied to your desktop to be\n> >productive. For example, when traveling between home and work or between\n> >multiple offices, you can enter your ***user name and password*** for\n> >your HomePort and work with all of your information, just as you left\n> >it, regardless of where you are or what type of computer you are\n> >running. \"\n> >\n> >Given the reluctance of Netscape to support Passwords in the TLS\n> >protocol, I am a bit curious as to the underlying technology Netscape\n> >will be using for  password based authentication to your \"HomePort.\"\n> >\n> >Does anyone have any insight into this?\n> \n> I don't think that Netscape has objections to supporting passwords --\n> instead I think the various point of views on password authentication have\n> more to do with different ideas on the appropriate layer in the networking\n> model to add authentication.\n> \n> Ultimately the problem resides in the fact that the technology that we are\n> using to secure the integrity of a connection (i.e. the rsa or\n> diffie-helman key exchange to derive a shared master secret for encryption)\n> is closely related to the technology that we use to authenticate each end\n> of the connection (i.e. RSA or DSS certificates.)\n> \n> I believe that Microsoft's position is that since SSL offers authentication\n> (through the use of certificates) that other forms of authentication should\n> be done at that layer as well.\n> \n> In contrast, Netscape's position appears to be that certificate-based\n> authentication is fundementally different (and believed to be more secure)\n> than password based authentication, thus it doesn't deserve to be at the\n> same level.\n> \n> Others have objections to SSL for architectural reasons -- they say that\n> SSL should not be doing authentication at all, and/or that it should rely\n> on other protocols or layers for key exchange and authentication.\n> \n> I'm not sure how this will all pan out. There is a legitimate user need for\n> standardizing non-certificate based authentication (whether secret-key for\n> legacy purposes, kerberos, or some other authentication mechanism) yet it\n> there is also a legitimate concern regarding both architecture issues\n> (layering) and the differing levels of security offered by different\n> authentication schemes.\n> \n> So far there are two internet drafts relating to alternative authentication\n> methods for TLS:\n> <ftp://ds.internic.net/internet-drafts/draft-ietf-tls-passauth-00.txt>\n> <ftp://ds.internic.net/internet-drafts/draft-ietf-tls-kerb-cipher-suites-00.txt\n> >\n> \n> I have heard that there may even be two more internet-drafts submitted on\n> this issue by tomorrow's deadline!\n> \n> Obviously this will be an important issue to resolve for the future of TLS,\n> however, I do hope that this issue doesn't get in the way of moving SSL 3.0\n> under IETF change control. That goal is my personal objective.\n> \n> ------------------------------------------------------------------------\n> ..Christopher Allen                  Consensus Development Corporation..\n> ..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n> ..                                             Berkeley, CA 94707-2116..\n> ..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n> ..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\nActually all it means is that we need to support password authentication\nwhether or not SSL is used for that application -- folks all\napplications need to use passwords at some point and will need to do\nsomething irrespective of whether SSL is used or not.\n\nTaher\n\n\n\n-- \nTaher Elgamal    elgamal@netscape.com\nChief Scientist, Netscape Communications\n(T) 415 937 2898, (F) 415 428 4054\n\n\n\n"
        },
        {
            "subject": "ANNOUNCEMENT: ISOC 1997 SYMPOSIUM NETWORK &amp; DISTRIBUTED SYSTEM SECURIT",
            "content": "---------------------------------------------------------------------------\n\n                 THE INTERNET SOCIETY 1997 SYMPOSIUM ON\n                 NETWORK AND DISTRIBUTED SYSTEM SECURITY\n                              (NDSS '97)\n\n                          10-11 FEBRUARY 1997\n\n            SAN DIEGO PRINCESS RESORT, SAN DIEGO, CALIFORNIA\n\n\n  This fourth annual symposium will bring together researchers,\n  implementors, and users of network and distributed system security\n  technologies to discuss today's important security issues and\n  challenges.  It will provide a mix of technical papers and panel\n  presentations that describe promising new approaches to security\n  problems that are practical, and to the extent possible, have\n  been implemented.  We hope to foster the exchange of technical\n  information and encourage the Internet community to deploy\n  available security technologies and develop new solutions to\n  unsolved problems.\n\nWHY YOU SHOULD ATTEND\n\n  The use of the Internet is rapidly growing and expanding into\n  all aspects of our society.  Commercial organizations are coming\n  under increasing pressure to make their services available on-line.\n  This in turn is increasing the need for rapid and widespread\n  deployment of usable and effective network and distributed system\n  security technologies.  High visibility attacks on the Internet\n  underscore the vulnerabilities of the Internet and the need to\n  solve its security problems.  There is growing concern for securing\n  the network infrastructure itself.  Recent trends in software\n  distribution (such as Java and ActiveX technologies) have made\n  certain attacks easier to carry out.  Privacy has become an\n  important issue for the Internet.\n\n  NDSS '97 will bring together researchers, implementors, and users\n  of network and distributed system technologies to discuss today's\n  important security issues and challenges.  We have selected the\n  technical papers and panel presentations that describe promising\n  new approaches to security problems that are practical, and to\n  the extent possible, have been implemented.  Topics to be addressed\n  include Internet infrastructure and routing security, security\n  for the World Wide Web, Java and ActiveX security, cryptographic\n  protocols, public key management, and protection of privacy.\n\n  The symposium will have a positive impact on the state of Internet\n  security.  You will have the opportunity to actively participate\n  in the dialog.  Ask questions of the speakers, raise your important\n  issues during the panel sessions, and let other participants know\n  of your requirements, observations, and experience in this\n  important area.  We hope to encourage the wide-scale deployment\n  of security technologies and to promote new research that can\n  address the currently unmet security needs of the Internet\n  community.\n\nCONTENTS\n\n  Preliminary Program\n  Organizing Committee\n  San Diego Princess Resort\n  Registration Information\n  Registration Form\n\n---------------------------------------------------------------------------\n\n                 P R E L I M I N A R Y   P R O G R A M\n\nSUNDAY, FEBRUARY 9\n\n6:00 P.M. - 8:00 P.M.\nRECEPTION\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\nMONDAY, FEBRUARY 10\n\n7:30 A.M.\nCONTINENTAL BREAKFAST\n\n8:30 A.M.\nOPENING REMARKS\n\n9:00 A.M.\nSESSION 1: THINGS THAT GO BUMP IN THE NET\nChair: Stephen T. Kent (BBN Corporation, USA)\n\n  Experimental Results of Covert Channel Elimination in One-Way\n  Communication Systems, Nick Ogurtsov, Hilarie Orman, Richard\n  Schroeppel, Sean O'Malley, and Oliver Spatscheck (University\n  of Arizona, USA)\n\n  Blocking Java Applets at the Firewall, David M. Martin Jr.,\n  Sivaramakrishnan Rajagopalan and Aviel D. Rubin (Bellcore, USA)\n\n  Continuous Assessment of a Unix Configuration: Integrating\n  Intrusion Detection & Configuration Analysis, Abdelaziz Mounji\n  and Baudouin Le Charlier (Institut D'Informatique, Namur,\n  BELGIUM)\n\n10:30 A.M.\nBREAK\n\n11:00 A.M.\nSESSION 2: PANEL: SECURITY OF DOWNLOADABLE EXECUTABLE CONTENT\nChair: Aviel Rubin (Bellcore, USA)\n\n12:30 NOON\nLUNCH\n\n2:00 P.M.\nSESSION 3: PROTOCOL IMPLEMENTATION AND ANALYSIS\nChair: Christoph Schuba (Purdue University, USA)\n\n  An Interface Specification Language for Automatically Analyzing\n  Cryptographic Protocols, Stephen H. Brackin (Arca Systems, USA)\n\n  Probable Plaintext Cryptanalysis of the IP Security Protocols,\n  Steven M. Bellovin (AT&T Research, USA)\n\n  Misplaced Trust: Kerberos Version 4 Session Keys, Bryn Dole (Sun \n  Microsystems), Steve Lodin (Delco Electronics), and Eugene Spafford\n  (Purdue University, USA)\n\n3:30 P.M.\nBREAK\n\n4:00 P.M.\nSESSION 4: PANEL: SECURITY OF THE INTERNET INFRASTRUCTURE\nChair: Russ Mundy (Trusted Information Systems, USA)\n\n7:00 P.M.\nDINNER BANQUET\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n\nTUESDAY, FEBRUARY 11\n\n7:30 A.M.\nCONTINENTAL BREAKFAST\n\n8:30 A.M.\nSESSION 5: ROUTING SECURITY\nChair: Hilarie Orman (DARPA, USA)\n\n  Securing the Nimrod Routing Architecture, Karen E. Sirois and\n  Stephen T. Kent (BBN Corporation, USA)\n\n  Securing Distance-Vector Routing Protocols, Bradley R. Smith,\n  Shree Murthy and J.J. Garcia-Luna-Aceves (University of California\n  Santa Cruz, USA)\n\n  Reducing the Cost of Security in Link-State Routing, R. Hauser,\n  A. Przygienda and G. Tsudik (IBM and USC/ISI, USA)\n\n10:00 A.M.\nBREAK\n\n10:30 A.M.\nSESSION 6: SECURITY FOR THE WORLD WIDE WEB\nChair: Win Treese (OpenMarket, USA)\n\n  Securing Web Access with DCE, Brian C. Schimpf (Gradient \n  Technologies, USA)\n\n  PANEL: SECURITY FOR THE WORLD WIDE WEB\n  Chair: Win Treese (OpenMarket, USA)\n\n12:00 A.M.\nLUNCH\n\n1:30 P.M.\nSESSION 7: PUBLIC KEY MANAGEMENT\nChair: Jonathan Trostle (CyberSafe, USA)\n\n  Hierarchical Organization of Certification Authorities for\n  Secure Environments, Lourdes Lopez (Universidad Politecnica de\n  Madrid, SPAIN)\n\n  Trust Models in ICE-TEL, Andrew Young and Nada Kapidzic Cicovic\n  (Univeristy of Salford, UNITED KINGDOM)\n\n  Distributed Authentication in Kerberos Using Public Key\n  Cryptography, Marvin Sirbu and John Chung-I Chuang (Carnegie \n  Mellon University, USA)\n\n3:00 P.M.\nBREAK\n\n3:30 P.M.\nSESSION 8: PANEL: WEB PRIVACY AND ANONYMITY\nChair: (To Be Determined)\n\n\n---------------------------------------------------------------------------\n\n                O R G A N I Z I N G   C O M M I T T E E\n\nGENERAL CHAIR\n  David Balenson, Trusted Information Systems\n\nPROGRAM CHAIRS\n  Clifford Neuman, USC Information Sciences Institute\n  Matt Bishop, University of California at Davis\n\nPROGRAM COMMITTEE\n  Steve Bellovin, AT&T Research\n  Tom Berson, Anagram Laboratories\n  Doug Engert, Argonne National Laboratory\n  Warwick Ford, Verisign\n  Richard Graveman, Bellcore\n  Li Gong, JavaSoft\n  Burt Kaliski, RSA Laboratories\n  Steve Kent, BBN Corporation\n  Tom Longstaff, CERT\n  Doug Maughan, National Security Agency\n  Dan Nessett, 3Com Corporation\n  Hilarie Orman, DARPA/ITO\n  Michael Roe, University of Cambridge\n  Christoph Schuba, Purdue University\n  Jonathan Trostle, CyberSafe\n  Theodore Ts'o, Massachusetts Institute of Technology\n  Doug Tygar, Carnegie Mellon University\n  Vijay Varadharajan, University of W. Sydney\n  Roberto Zamparo, Telia Research\n\nPUBLICATIONS CHAIR\n  Steve Welke, Institute for Defense Analyses\n\nLOCAL ARRANGEMENTS CHAIR\n  Thomas Hutton, San Diego Supercomputer Center\n\nREGISTRATIONS CHAIR\n  Torryn Brazell, Internet Society\n\nSTEERING GROUP\n  Internet Research Task Force, Privacy and Security Research Group\n\nSPONSORED BY THE INTERNET SOCIETY\n  Donald M. Heath, President & CEO\n  Martin Burack, Executive Director\n\n\n---------------------------------------------------------------------------\n\n           S A N   D I E G O   P R I N C E S S   R E S O R T\n\nLOCATION\n\n  The Symposium venue is the San Diego Princess Resort, a tropical\n  paradise on a forty-four acre island in Mission Bay, ten minutes\n  from the international airport.  Lush gardens landscaped with\n  hundreds of species of tropical and subtropical plants are\n  always ablaze with color and perfect for themed group events.\n  Charming pathways wander among sparkling waterfalls, across\n  quaint footbridges and sleepy lagoons filled with water lilies\n  and waterfowl.  A white sand beach curves around the island\n  for over a mile, and the award-winning grounds encompass five\n  swimming pools and six lighted tennis courts.\n\n  Spouses and family members can catch a convenient Harbor Hopper\n  for a quick trip to Sea World.  Plan to visit La Jolla, the world\n  famous San Diego Zoo or Mexico, only 30 minutes by car or Trolley.\n\nHOUSING INFORMATION\n\n  We have reserved a special block of sleeping rooms at the San Diego\n  Princess Resort at the following rates:\n\n      Lanai Patio Rooms           $ 81*\n      Lanai Garden Rooms          $114\n\n  * This represents the Government Rate for San Diego.  A limited \n    number of rooms are available at this rate.  Reservations must \n    be made no later than January 13, 1997.  You must present a \n    valid government id upon check-in.\n\n  Based on room type and space availability, the special group\n  rates are applicable two days prior to and two days after the\n  symposium.  Current Room Tax is 10.5%.\n\n  Check-in availability cannot be committed prior to 4:00 p.m.\n  Check-out time is 12:00 noon. The San Diego Princess Resort\n  will make every effort to accommodate any early arrivals, so\n  make sure you give them your arrival time when you make your\n  reservation.\n\nTO MAKE A RESERVATION\n\n  Contact the San Diego Princess Resort at +1-800-344-2626\n  (+1-619-274-4630 if outside the United States).  To receive\n  the special group rates, reservations must be made no later\n  than January 20, 1997.  To receive the special goverment \n  rate, you must make your reservation by January 13, 1997.\n\nCLIMATE\n\n  February weather in San Diego is normally very pleasant.  Early\n  morning temperatures average 55 degrees while afternoon\n  temperatures average 67 degrees.  Generally, a light jacket or\n  sweater is adequate, although, occasionally it rains.\n\n---------------------------------------------------------------------------\n\n            R E G I S T R A T I O N   I N F O R M A T I O N\n\nFEES                                      ISOC            Non-\n                                         Members         Member*\n  Early registration \n  (postmarked on/before Jan. 22)         $305            $345\n\n  Late registration                      $375            $415\n\nREGISTRATION INCLUDES\n\n  - Attendance      - Symposium Proceedings     - Two luncheons\n  - Reception       - Banquet                   - Coffee Breaks\n\n  * Non-Member fee includes one year Internet Society membership.\n\nFOR MORE INFORMATION \n\n  Contact Carol Gray at the Internet Society at +1-703-648-9888 \n  or send E-mail to Ndss97reg@isoc.org.\n\nWEB PAGE\n\n  Additional information about the symposium and San Diego, plus\n  on-line registration, are available via the Web at:\n\n            http://www.isoc.org/conferences/ndss97\n\nSPONSORSHIP OPPORTUNITIES AVAILABLE!\n\n  Contact Torryn Brazell at the Internet Society at +1-703-648-9888 \n  or send E-mail to Ndss97reg@isoc.org.\n\n---------------------------------------------------------------------------\n\n                  R E G I S T R A T I O N   F O R M\n\nINTERNET SOCIETY SYMPOSIUM ON NETWORK AND DISTRIBUTED SYSTEM SECURITY\n10-11 FEBRUARY, 1997                       SAN DIEGO, CALIFORNIA, USA\n\nFill out this form and FAX it to NDSS'97 Registration at +1-703-648-9887,\nsend it via E-mail to Ndss97reg@isoc.org, or mail it to NDSS97,\n12020 Sunrise Valley Drive, Suite 210, Reston, VA, 20191, USA\n\nPERSONAL INFORMATION\n\n  __Mr __Ms __Mrs __Dr __Prof __M __Prof Dr __Dip Ing __Ing __Miss __Mlle\n\n  First Name: ________________________________  MI: ____________________\n\n  Family Name: ___________________________________  __Sr __Jr __II __III\n\n  Badge Name: __________________________________________________________\n  Please enter your name as you would like it to appear on your name tag.\n\nCONTACT INFORMATION\n\n  Title: _______________________________________________________________\n\n  Organization: ________________________________________________________\n\n  Street address: ______________________________________________________\n\n  ______________________________________________________________________\n\n  City: ________________________________________________________________\n\n  State/Province: ___________________________  Postal Code: ____________\n\n  Country: _____________________________________________________________\n\n  Telephone Number (work): _____________________________________________\n\n  Telephone Number (home): _____________________________________________\n\n  Fax Number: __________________________________________________________\n\n  E-mail address: ______________________________________________________\n\nSPECIAL NEEDS?  (Vegetarian meals, wheelchair access, etc?)\n\n  ______________________________________________________________________\n\n  ______________________________________________________________________\n\nAPPEAR ON REGISTRANTS LIST?\n\n  ___  Please check here if you would NOT like your name included \n       in the list of registrants.\n\nPAYMENT INFORMATION\n\n  All Payments must be in United States Dollars.\n\n  Conference Fee\n  --------------\n\n  If you are an Internet Society member, you are eligible for a\n  reduced conference registration fee.  Non-member symposium \n  attendees will receive a one year Internet Society membership \n  as part of the non-member registration fees.\n\n  Check one:                        On/Before        After\n                                    January 22    January 22\n                                    ----------    ----------\n  ___ Internet Society Member Fee   US$ 305.00    US$ 375.00\n\n  ___ Non-Member Fee                US$ 345.00    US$ 415.00\n\n  Method of Payment\n  -----------------\n\n  Payment must be received on/before February 7, 1997 or we will \n  be unable to pre-register you.\n\n  1. ___ Check.  Make payable to the Internet Society.  \n\n  2. ___ Credit Card. ___ American Express ___ Visa ___ Mastercard\n\n         Name on Credit Card: ____________________________________\n  \n         Credit Card Number: _____________________________________\n\n         Expiration Date: ________________________________________\n\n  3. ___ CyberCash.  Account Number: _____________________________\n\n  4. ___ First Virtual.  Account Number: _________________________\n\n  5. ___ Wire Transfer*\n\n         Bank ABA Number: 054000030\n         Account Number: Internet Society 148 387 10\n\n         Riggs National Bank of Virginia   \n         950 Herndon Parkway               \n         Herndon, VA  20171  USA\n\n         Wire Transfer Confirmation Number: ______________________\n\n         * Please process wire transfer before sending registration \n   form.\n\n  6. ___ U.S. Government Purchase Order*\n\n         P.O. Number: ____________________________________________\n\n         * Please fax or mail a copy of your purchase order along \n   with your registration form.\n\n  Cancellation Policy\n  -------------------\n\n  Refunds (less a $25 processing fee) will be issued for cancellations \n  received on/before February 7, 1997.  No refunds will be issued \n  after February 7, 1997.\n\n------------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: TLS WG meeting in San Jos",
            "content": ">Could someone please send me the date/time of the TLS workgroup meeting \n>in San Jose?\n\nThe TLS working group will be meeting on Monday, 9 December 1996,\nfrom 3:30 to 5:30 PM. The meeting will be moderated by Chris Allen\n(ChristopherA@consensus.com).\n\n- Win Treese\n\n\n\n"
        },
        {
            "subject": "Internet Image Securit",
            "content": "11/26/1996\n\nDear Colleagues:\n\n  We would appreciate your assistance in distributing the appended\nconference announcement to your colleagues. Please notice that we have\nscheduled a technical session on INTERNET IMAGE SECURITY which might be\nof your interest.\n  \n\nKindest regards,\nAntonio Ma?a-G?mez and Francisco R. Villatoro-Machuca.\n\n\nAny help in publicizing the conference would be most appreciated.\nPlease send any questions about the conference to\n\n          Professor Hamid R. Arabnia\n          The University of Georgia\n          Tel: (706) 542-3480\n          Fax: (706) 542-2966\n          E-mail: hra@cs.uga.edu\nor to\n\n          Mr. Antonio Ma?a-G?mez\n          University of Malaga\n          Tel: (+34) 5 213 2754\n          Fax: (+34) 5 213 1397\n          E-mail: amg@lcc.uma.es\n          www: http://www.lcc.uma.es/personal/mana/mana.html\n\nor to\n          Mr. Francisco R. Villatoro-Machuca\n          University of Malaga\n          Tel: (+34) 5 213 20 96\n          FAX: (+34) 5 213 28 16\n          E-mail: villa@lcc.uma.es\n          www: http://www.lcc.uma.es/personal/villa/villa.html\n\n\nSend any questions about technical sessions to their respective Chairs.\n \n\n\n\n          International Conference on Imaging Science,\n         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n                    Systems, and Technology\n                   ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n                           CISST'97\n\n         June 30 - July 2, 1997 Las Vegas, Nevada, USA\n\n The International Conference on Imaging Science, Systems, and\nTechnology (CISST'97) will be celebrated together with the\n\n     1997 International Conference on Parallel and Distributed\n       Processing Techniques and Applications (PDPTA'97)\n\nWe believe that the parallel/distribute processing researchers and the\nimaging community can both benefit from each other's expertise.\nTherefore, we have scheduled both conferences at the same time and\nlocation (Las Vegas, June 30 - July 2, 1997) for the benefit of those\nwho would like to exchange research ideas with the other research\ncommunity.\n\nCALL FOR PAPERS\n\nThe first International Conference on Imaging Science, Systems, and\nTechnology (CISST'97) will be held in Las Vegas, Nevada, June 30 - July\n2, 1997. All aspects of computer graphics, image processing, and pattern\nrecognition are included in CISST. You are invited to submit a draft\npaper of about 5 pages and/or a proposal to organize a technical session\n(see below for submission information). All accepted papers will be\npublished in the conference proceedings.\nTHE NAMES OF TECHNICAL SESSION CHAIRS WILL APPEAR AS ASSOCIATE EDITORS\nON THE COVER OF CONFERENCE PROCEEDINGS.\n\nSCOPE\n\nTopics of interest include, but are not limited to, the following:\n  O Image generation, acquisition, and processing.\n  O Image display techniques.\n  O Image data structures and databases.\n  O Convergence of imaging media (video and computer).\n  O Virtual reality.\n  O Image compression, coding, and encryption.\n  O Tools for multimedia production and services.\n  O Digital imaging for film and television.\n  O Visualization.\n  O Scene and object modeling.\n  O Knowledge acquisition.\n  O Visual inspection.\n  O Document image understanding.\n  O Image algebra.\n  O Mathematical morphology.\n  O Architecture of imaging and vision systems (including parallel\n    architectures and algorithms).\n  O Neural network techniques and fuzzy logic.\n  O Performance analysis and evaluation.\n  O Software tools and environments for imaging.\n  O Applications including: medicine, robotic, GIS, remote sensing, ...\n  O Other aspects and applications relating to imaging science.\n\nSUBMISSION OF PAPERS:\n\nProspective authors are invited to submit three copies of their draft\npaper (about 5 pages) to H. R. Arabnia (address is given below) by the\ndue date. Submissions for the technical sessions must be send to the\nSession Chair. E-mail and Fax submissions are also acceptable. The\nlength of the Camera-Ready papers (if accepted) will be limited to 10\npages. Papers must not have been previously published or currently\nsubmitted for publication elsewhere.\n\nThe first page of the draft paper should include: title of the paper,\nname, affiliation, postal address, E-mail address, telephone number, and\nFax number for each author. The first page should also include the name\nof the author who will be presenting the paper (if accepted) and a\nmaximum of 5 keywords.\n\nPROPOSAL FOR ORGANIZING TECHNICAL SESSIONS:\n\nEach technical session will have 5/6 paper presentations. The session\nchairs will be responsible in selecting the papers for their own\nsessions. The names of session chairs will appear as Associate Editors\nin the conference proceedings. Proposals to organize technical sessions\nshould include the following information: name and address (+ E-mail) of\nproposer, title of session, a 100-word description of the topic of the\nsession, and how you plan to advertise the session and select papers for\nthe proposed session. Mail your proposal to H. R. Arabnia (address is\ngiven below); E-mail submissions are preferred.\n\nCurrently Scheduled Technical Sessions:\n              \n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n   Title of session: Internet Image Security\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n          Chair: Mr. Antonio Mana-Gomez\n         E-mail: amg@lcc.uma.es\n            www: http://www.lcc.uma.es/personal/mana/ImageSecurity.html\n    Description:\n\n         Image transmission over the Internet is one the keys for its\npopularity. However, one of the great drawbacks of the Internet is the\nfree access to and broadcasting of these images. It is possible to view\nthe transmission of images from two different standpoints: firstly, it\nis a due to allow the users to transmit with privacy and efficacy the\nimages, so there has to be a tool to supply those items; secondly, the\nfrequent news in the media on child pornography and other illegal\ntopics, shows that Internet can become a crime paradise. From this\nsecond approach it is clear that the development of tools to control the\nbroadcasting of these images is a need. Balance between the user's right\nto privacy and the community need of instruments to avoid misuse of the\nInternet has to be achieved by any solution to this problem. This\ntechnical session deals with new techniques and protocols that can make\npossible this balance whithout compromising efficiency.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n   Title of session: Monte Carlo Methods for Physically\n                     Based Rendering\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n          Chair: Mr. Francisco R. Villatoro-Machuca\n         E-mail: villa@lcc.uma.es\n            www: http://www.lcc.uma.es/personal/villa/MonteCarlo.html\n    Description:\n\n        Physically based rendering is based on the numerical solution of\nthe rendering equation. Two main techniques can be used: Monte Carlo\npath tracing (image-space stochastic sampling methods) and finite\nelements (world-space radiosity like mesh-based methods). Monte Carlo\nmethods are very versatile, and if unbiased, convergence is assured, but\nslow. Mesh-based methods can be used as a bias for Monte Carlo methods\nin order to improve efficacy. Bias shows up as results that are not\nnoisy, but in fact are incorrect. However, if the bias is adecuately\nbounded, the image is visually coherent and it is not noticeable.  In\nthe future hybrid of Monte Carlo and mesh-based methods are the point.\nThis sesion deals with an analysis of the relative merits of Monte Carlo\nPath Tracing (MCPT) and Finite Elements (FE) on the basis of their\npotential for future improvements. Questions as: Should we, and how do\nwe, make MCPT more like Hierarchical FE? Or should Hierarchical FE be\nmade more like MCPT? In short, what form should this hybrid take?\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n   Title of session: Progressive Transmission and\n                     Rendering of 3D Scenes for the Internet\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n          Chair: Mr. Francisco R. Villatoro-Machuca\n         E-mail: villa@lcc.uma.es\n            www: http://www.lcc.uma.es/personal/villa/ProgTrans.html\n    Description:\n\n        New extensions of the World Wide Web (WWW) interface (the\nVirtual Reality Modeling Language (VRML),JAVA Scripts) has been\naddressed the ability to visualize three dimensional (3D) object\noriented scenarios and allowed the interactive manipulation with their\nbasic elements. Unfortunately, most realistic scenes require a large\namount of storage and, consequently, their transmission is very slow.\nExisting viewers must deal with this problem. Multiresolution video,\nwavelet multiresolution meshes, progressive transmission, mesh\ncompression and dynamic display are proposed solutions. This technical\nsession is about theses new techniques which can make possible virtual\nworlds on the cyberspace.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nEVALUATION OF PAPERS:\n\nPapers will be evaluated for originality, significance, clarity, and\nsoundness. Each paper will be refereed by two researchers in the topical\narea. The Camera-Ready papers will be reviewed by one person. Please\nrefer to the technical sessions pages for details on the evaluation of\nthe papers for those sessions.\n\nPUBLICATION:\n\nThe conference proceedings will be published by CSREA Press. The\nproceedings will be available at the conference.\nPlease note that all color pictures/diagrams will be published in\ngray-scale.\n\nORGANIZERS/SPONSORS:\n\nA number of university faculty members in cooperation with the Monte\nCarlo Hotel (conference division) will be organizing the conference. The\nconference is sponsored by the Computer Science Research, Education, and\nApplications Tech. (CSREA) in cooperation with the Computer Vision\nResearch and Applications Tech. (CVRA), The National Supercomputing\nCenter for Energy and the Environment (USA), developers of\nhigh-performance machines and systems (pending) and related computer\nassociations (pending.)\n\nLOCATION OF CONFERENCE:\n\nThe conference will be held in the Monte Carlo Resort and Casino hotel,\nLas Vegas, Nevada, USA. This is a new hotel with excellent conference\nfacilities and over 3000 rooms. The hotel is minutes from the Las Vegas\nairport with free shuttles to and from the airport. The hotel has many\nvacation and recreational attractions, including: casino, waterfalls,\nspa, kiddie pools, sunning decks, Easy River water ride, wave pool with\ncascades, lighted tennis courts, health spa (with workout equipment,\nwhirlpool, sauna, ...), arcade virtual reality game rooms, nightly\nshows, snack bars, a number of restaurants, shopping area, ... Many of\nthese attractions are open 24 hours a day and most are suitable for\nfamilies and children. The hotel's room rate is very reasonable ($79 +\n8% tax) per night for the duration of the conference. The hotel is\nminutes from other Las Vegas attractions (major shopping areas,\nrecreational destinations, fine dining and night clubs, free street\nshows, ...). For the benefit of our international colleagues: the state\nof Nevada neighbors with the states of California, Oregon, Idaho, Utah,\nand Arizona. Las Vegas is only a few driving hours away from other major\ncities, including: Los Angeles, San Diego, Phoenix, ...\n\nEXHIBITION:\n\nAn exhibition is planned during the conference. We have reserved 20+\nexhibit spaces. Interested parties should contact H. R. Arabnia (address\nis given below). All exhibitors will be considered to be the co-sponsors\nof the conference. Each exhibitor will have the opportunity to include a\ntwo-page description of their latest products in the conference\nproceedings (if submitted by May 19, 1997).\n\nIMPORTANT DATES:\n\n February 12, 1997 (Wednesday): Draft papers (5-page) due\n April 8, 1997 (Tuesday): Notification of acceptance\n May 19, 1997 (Monday): Camera-Ready papers & Preregistration due\n June 30, July 1, July 2: CISST'97 Conference\n\nProposals to organize technical sessions should be submitted as soon as\npossible (well ahead of the February 12 deadline). All accepted papers\nare expected to be presented at the conference.\n\nPROGRAM COMMITTEE: (as of Nov. 25, 1996)\n\n  I. Ahmad, Hong Kong University of Science & Technology, Hong Kong;\n  H. R. Arabnia, University of Georgia, Athens, GA, USA;\n  C. Colin, Ecole des Mines de Nantes, France;\n  J. Farison, University of Toledo, Toledo, OH, USA;\n  M. E. Fayad, University of Nevada, Reno, NV, USA;\n  O. Frieder, George Mason University & Florida Tech., USA;\n  F. Golshani, Arizona State University, Tempe, AZ, USA;\n  V. Gudivada, University of Missouri at Rolla, MO, USA;\n  M. Halem, Space Data & Comp. Div., Goddard Space Flight Center, NASA,\n     USA;\n  G. Hu, Central Michigan University, MI, USA;\n  K-C. Hui, Chinese University of Hong Kong, Shatin, Hong Kong;\n  O. H. Ibarra, University of California, Santa Barbara, CA, USA;\n  X. Jia, City University of Hong Kong, Hong Kong;\n  J. Jin, University of New South Wales, Sydney, Australia;\n  D. Kazakos, University of Southwestern Louisiana, LA, USA;\n  A. Law, Ohio State University, Columbus, OH, USA;\n  D. Luzeaux, Etca/Crea/Sp, France;\n  K. Makki, University of Nevada Las Vegas, NV, USA;\n  S. A. M. Makki, University of Queensland, Australia;\n  A. Mana-Gomez, E.T.S.I.Informatica, Malaga, Spain;\n  N. Memon, Northern Illinois University, DeKalb, IL, USA;\n  B. Nassersharif, National Supercomputing Center For Energy and the\n     Environment, Las Vegas, Nevada, USA;\n  M. S. Obaidat, Monmouth University, NJ, USA;\n  Y. Pan, University of Dayton, Dayton, OH, USA;\n  E. K. Park, University of Missouri-Kansas City, USA;\n  W. Peng, Southwest Texas State University, San Marcos, TX, USA;\n  N. Pissinou, University of Southwestern Louisiana, Lafayette, LA, USA;\n  Rajkumar, Centre for Development of Advanced Computing, Bangalore,\n     India;\n  S. Sahni, University of Florida, Gainesville, FL, USA;\n  H. Sharif, University of Nebraska Lincoln, USA;\n  H. Shi, University of Missouri-Columbia, MO, USA;\n  M. Singhal, Ohio State University, Columbus, OH, USA;\n  S. Y. W. Su, University of Florida, Gainesville, FL, USA;\n  A. Tentov, University \"Sv. Kiril i Metodij\", Republic of Macedonia;\n  E. Torng, Michigan State University, MI, USA;\n  N-F. Tzeng, University of Southwestern Louisiana, Lafayette, LA, USA;\n  F. R. Villatoro-Machuca, Universidad de Malaga, Malaga, Spain;\n  Y. Xu, Oak Ridge National Laboratory, Oak Ridge, TN, USA;\n  S. You, State University of New York at Stony Brook, NY, USA;\n  H. Zhang, Aptronix, Inc., Santa Clara, CA, USA;\n  D. Zhu, Aptronix, Inc., Santa Clara, CA, USA;\n  A. Y. Zomaya, University of Western Australia, Australia.\n\nCONFERENCE CONTACT:\n\n    Professor Hamid R. Arabnia (CISST General Chair)\n    The University of Georgia Department of Computer Science\n    415 Graduate Studies Research Center\n    Athens, Georgia 30602-7404, U.S.A.\n    Tel: (706) 542-3480\n    Fax: (706) 542-2966\n    E-Mail : hra@cs.uga.edu\n\nLOCAL ARRANGEMENT CHAIRS:\n\n    Professor Kia Makki\n    Department of Computer Science\n    University of Nevada Las Vegas\n    Las Vegas, Nevada 89154-4019, USA\n    E-Mail : kia@koko.cs.unlv.edu\n\n    Professor Niki Pissinou\n    Center For Advanced Computer Studies\n    University of Southwestern Louisiana\n    Lafayette, LA 70508, USA\n    E-Mail : pissinou@cacs.usl.edu\n\nPUBLICITY CHAIR:\n\n    Professor Yi Pan\n    Department of Computer Science\n    University of Dayton\n    Dayton, OH 45469-2160, USA\n    Tel: (513) 229-3807\n    Fax: (513) 229-4000\n    E-Mail : pan@cps.udayton.edu\n\nWWW PAGES:\n\n    http://www.lcc.uma.es/congresos/CISST.html (CISST'97 Home Page)\n    http://www.cps.udayton.edu/~pan/pdpta      (PDPTA'97 Home Page)\n\n\nOTHER INFORMATION:\n \n \n-- \n                          ~~~~~  \n                         ( o o )\n  +----------------o000-----U------000o--------------------+\n  !           _   ,                                        !\n  ! Antonio Mana Gomez               eMail: amg@lcc.uma.es !\n  !                                                        !\n  ! Departamento de Lenguajes y Ciencias de la Computacion !\n  !        E.T.S.I.Informatica.    Desp. 1.2.B.19          !\n  !                Campus de Teatinos.                     !\n  !               29071 MALAGA (SPAIN)                     !\n  !                                                        !\n  ! Phone: (+34) 5 213 27 54        Fax: (+34) 5 213 13 97 !\n  +--------------------------------------------------------+\n\n\n\n"
        },
        {
            "subject": "password",
            "content": "I've seen a lot of traffic in this list discussing the use of\npasswords, how necessary they are and how insecure, etc. etc.\nI haven't seen any mention of the use of techniques like\nBellovin-Merrit's for preventing dictionary attacks.\nCertainly, these techniques improve significantly on the\nsecurity of passwords (particularly, low-entropy ones).\nBM solutions and related ones use public key techniques\nwhich are already available in SSL. Did anyone considered using them?\nDoes anyone know of *any* real-world implementation of such\ntechniques (not necessarily  related to SSL)?\n\nThanks,\n\nHugo\n\n\n\n"
        },
        {
            "subject": "RE: password",
            "content": "It turns out that this was a very good way to advertise Bellovin-Merrit's\nwork. So I got no single answer to whether an implementation exists\nor about its potential usability within SSL. Instead I got eight personal\nmessages asking for the reference to the papers.\nThere are two papers on this subject by these authors.\nThey call the technique \"encrypted key exchange\".\nThe first paper appeared in Oakland conference 1992, the second\nin ACM Security 1993.\nI found an on-line version of both papers under\nhttp://www.alw.nih.gov/Security/first-papers.html\nLook for the phrase \"encrypted key exchange\" (the papers are NOT\nlisted under the \"password\" section of that page).\n\nAnyway, if anyone has an answer to my previous posting I'll\nbe glad to hear.\n\nHugo\n\n\n\n"
        },
        {
            "subject": "ANNOUNCEMENT: 1997 RSA Data Security Conferenc",
            "content": "28-31 January, 1997\nNOB HILL, SAN FRANCISCO\n\n1997 marks RSA's fifteenth anniversary and our sixth annual conference.\nTwo days of general sessions and two days of classes will provide over\n100 different  classes to choose from, with separate tracks for\nmathematicians and cryptographers, developers, industry analysts and\nbusiness people.\n\nWe invite you to join us.  Find out more information, view the class\nsyllabi and register online at http://www.rsa.com\n\nThanks\n\nKurt Stammberger\nRSADSI\n>\n\n\n\n"
        },
        {
            "subject": "Re: password",
            "content": "At 11:24 AM 11/27/96 EST, HUGO@watson.ibm.com wrote:\n>I've seen a lot of traffic in this list discussing the use of\n>passwords, \n\nHi,\n\nI'm new to this list so I don't know if this has been mentioned. Regarding\nthe discussion of SSL not supporting the use of passwords, has SSH been\nconsidered by the IETF TLS? It supports the use of encrypted passwords as\nwell as pure RSA authentication.\n\nThanks,\nRichard Chase\n------------------------------------------------------------------------\nRichard.Chase@DataFellows.com, World Wide Web: http://www.DataFellows.com\n\nData Fellows \n4000 Moorpark Ave., Suite 207\nSan Jose, CA 95117\nphone (408) 244-9090, fax (408) 244-9494\n\n*************************************************************************\n* Vineyard, the Award-winning Visual Information Manager for Workgroups *\n* F-Secure, Unmatched, Easy to Use Internet Security                    *\n* http://www.DataFellows.com/                             *\n*************************************************************************\n\n\n\n"
        },
        {
            "subject": "draft agenda for San Jose meetin",
            "content": "Based on our recent discussions about how the group would\nlike to proceed, my sense is that we want to make quick\nprogress on a standards track document. In order to help\nthis along, Chris Allen (<ChristopherA@consensus.com>)\ndrafted the following agenda for the San Jose meeting:\n\nMonday, 9 December, 1530-1730\n\n1530-1545 Introduction and background\n1545-1615 Presentation of proposed SSL to TLS changes\n1615-1645 Discussion of proposed TLS changes\n1645-1725 Quick presentations on possible future work\n(including shared secrets, Kerberos, IPSEC key\nmanagement, etc., may include others to be\ndetermined)\n1725-1730 Wrapup and next steps\n\nNote: if you've sent a note about making a presentation,\nyou don't need to resend it. We're working on the details\nof the quick presentation section.\n\nComments welcome.\n\n- Win Treese\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "At 09:44 AM 12/2/96 -0500, Win Treese wrote:\n>Based on our recent discussions about how the group would\n>like to proceed, my sense is that we want to make quick\n>progress on a standards track document. In order to help\n>this along, Chris Allen (<ChristopherA@consensus.com>)\n>drafted the following agenda for the San Jose meeting:\n>\n>Monday, 9 December, 1530-1730\n>\n>1530-1545 Introduction and background\n>1545-1615 Presentation of proposed SSL to TLS changes\n>1615-1645 Discussion of proposed TLS changes\n>1645-1725 Quick presentations on possible future work\n>(including shared secrets, Kerberos, IPSEC key\n>management, etc., may include others to be\n>determined)\n>1725-1730 Wrapup and next steps\n>\n>Note: if you've sent a note about making a presentation,\n>you don't need to resend it. We're working on the details\n>of the quick presentation section.\n>\n>Comments welcome.\n>\n>- Win Treese\n\nI'm just looking for some clarification.\n- Is it the intention to move SSL 3.0 into TLS 1.0 \"as is\", with\nclarifications to the spec?\n- Is the hour of presentation and discussion meant for clarifying the\nambiguities in SSL 3.0 that Chris Allen mentioned in an earlier message,\nalso, does this include discussion about splitting the SSL spec into\nseparate specification documents?\n- Does this mean that all decisions regarding draft proposals (Netscape's\nauthority attributes, Microsoft's passphrase authentication, CyberSafe's\nKerberos cipher suites, etc.) will be postponed until the next meeting of\nthe IETF?\n\n-- Matt Hur\n----------------------------------------------------------------\nMatt Hur                       CyberSafe\nSenior Software Engineer       1605 NW Sammamish Road, Suite 310\nmatt.hur@cybersafe.com         Issaquah, WA 98027-5378\n(206) 391-6000                 http://www.cybersafe.com\n\n\n\n"
        },
        {
            "subject": "I-D ACTION:draft-ietf-tls-ssl-mods00.tx",
            "content": " A New Internet-Draft is available from the on-line Internet-Drafts \n directories. This draft is a work item of the Transport Layer Security \n Working Group of the IETF.                                                \n\n       Title     : Modifications to the SSL protocol for TLS               \n       Author(s) : T. Dierks\n       Filename  : draft-ietf-tls-ssl-mods-00.txt\n       Pages     : 4\n       Date      : 11/27/1996\n\nThis document recommends for several modifications be made to the SSL 3.0 \nprotocol as it is standardized by the IETF under the name of TLS.  These \nchanges primarily standardize various technical details of the protocol and\nmake some other minor modifications.                                       \n\nInternet-Drafts are available by anonymous FTP.  Login with the username\n\"anonymous\" and a password of your e-mail address.  After logging in,\ntype \"cd internet-drafts\" and then\n     \"get draft-ietf-tls-ssl-mods-00.txt\".\nA URL for the Internet-Draft is:\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-ssl-mods-00.txt\n \nInternet-Drafts directories are located at:\n                                                \n     o  Africa:  ftp.is.co.za                    \n                                                \n     o  Europe:  nic.nordu.net            \n                 ftp.nis.garr.it                 \n                                                \n     o  Pacific Rim: munnari.oz.au               \n                                                \n     o  US East Coast: ds.internic.net           \n                                                \n     o  US West Coast: ftp.isi.edu               \n                                                \nInternet-Drafts are also available by mail.\n                                                \nSend a message to:  mailserv@ds.internic.net. In the body type: \n     \"FILE /internet-drafts/draft-ietf-tls-ssl-mods-00.txt\".\n\nNOTE: The mail server at ds.internic.net can return the document in\n      MIME-encoded form by using the \"mpack\" utility.  To use this\n      feature, insert the command \"ENCODING mime\" before the \"FILE\"\n      command.  To decode the response(s), you will need \"munpack\" or\n      a MIME-compliant mail reader.  Different MIME-compliant mail readers\n      exhibit different behavior, especially when dealing with\n      \"multipart\" MIME messages (i.e., documents which have been split\n      up into multiple messages), so check your local documentation on\n      how to manipulate these messages.\n\n\n\nBelow is the data which will enable a MIME compliant mail reader \nimplementation to automatically retrieve the ASCII version\nof the Internet-Draft.\n\n\n\n\n\nMessage/External-body attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "At 8:49 AM -0800 12/2/96, Matt Hur wrote:\n>I'm just looking for some clarification.\n>- Is it the intention to move SSL 3.0 into TLS 1.0 \"as is\", with\n>clarifications to the spec?\n\nNot necessarily -- a number of clarifications (but no changes to the SSL\nprotocol) have been made in \"draft-ietf-tls-protocol-00.txt\" (it was\nsubmitted before the IETF cutoff deadline but is not up on ietf\ninternet-drafts site yet) as well as a document\n\"draft-ietf-tls-changes-00.txt\" that includes what the editors (Tim and I)\nfelt to be non-controversial changes.\n\nThe short outline of \"tls-changes\" is:\n\n1. MAC algorithm\n2. MAC contents\n3. Block padding\n4. Message order standardization\n5. Certificate chain contents\n6. The no_certificate alert\n7. Additional alerts\n8. Seperation of Record and Handshake layers\n9. Additional Record Protocol clients\n\nIf these drafts are not up by today I'll be glad to send them to anyone\nthat needs a copy if you send me a private mail (please don't send your\nrequest to the list.)\n\n>- Is the hour of presentation and discussion meant for clarifying the\n>ambiguities in SSL 3.0 that Chris Allen mentioned in an earlier message,\n>also, does this include discussion about splitting the SSL spec into\n>separate specification documents?\n\nThe focus of the discussion during that portion of the agenda will be\n\"draft-ietf-tls-changes-00.txt\" and to get a straw vote on them, howerever,\nI expect that this time will also include some straw votes on additional\nrequirements.\n\n>- Does this mean that all decisions regarding draft proposals (Netscape's\n>authority attributes, Microsoft's passphrase authentication, CyberSafe's\n>Kerberos cipher suites, etc.) will be postponed until the next meeting of\n>the IETF?\n\nIf there are no requirements beyond \"draft-ietf-tls-changes-00.txt\", they\nwill be integrated into \"draft-ietf-tls-protocol-00.txt\" which will then be\nput out for a last call. In this case, as all of the additions were\ndiscussed during the meeting I think that TLS could be approved as an RFC\nmore rapidly then the next meeting. However, if more requirements are\nadded, it will definately take one more more meetings longer to finalize.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "SSL related internet draf",
            "content": "Hello all,\n   I realise that this message is not directly related to the ietf\nTLS working group, however I thought this group might be interested\nin the new Internet Draft that describes a mechanism of putting\nFTP onto SSL.  The draft really only re-iterates a previous, now\ndeleted draft, but it does, hopefully, allow secure FTP clients and\nservers to be defined.  The URL is\nftp://ds.internic.net/internet-drafts/draft-murray-auth-ftp-ssl-00.txt\n   Perhaps some of your discussions surrounding SSL and alternative\nsecurity schemes should be considered by this draft.\nThankyou,\nPaul\n\n-.--.---.----.-----.----.---.--.--.---.----.-----.----.---.--.-\nPaul Ford-Hutchinson    FORDHUP @ NHBVM9  (GBIBMLLL @ IBMMAIL)\nIGN EDI Products Development and Support. (pfh@uk.ibm.com)\nWarwick (OSU-1)   +44 (0)1926 464836      : tie  (7)66 4836\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "> From Christopher Allen <ChristopherA@consensus.com>\n\n> The short outline of \"tls-changes\" is:\n> \n>         1. MAC algorithm\n>         2. MAC contents\n>         3. Block padding\n>         4. Message order standardization\n>         5. Certificate chain contents\n>         6. The no_certificate alert\n>         7. Additional alerts\n>         8. Seperation of Record and Handshake layers\n>         9. Additional Record Protocol clients\n\nI strongly recommend that these be separated into 2 parts: those that\nforce a change the current protocol (bits on the wire), and those that\nare clarifications of current practice.\n\nIn particular points 1., 2., and 6. above would make all current\nimplementations non-conforming. Do we have examples of interoperability\nbetween the proposed protocol and existing implementations? Would the\nversion number be rolled forward?\n\nI suspect that those at the meeting will want to treat these proposals\nindependently.\n\nPK\n--\nPhilip L. Karlton               karlton@netscape.com\nPrincipal Curmudgeon            http://www.netscape.com/people/karlton\nNetscape Communications Corporation\n\n    Everything should be made as simple as possible, but not simpler.\n        -- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "RE: password",
            "content": "Hugo:  We did at one point consider Bellovin-Merritt for shared-key\nauthentication, but we decided that requiring server certification was\nnot a big sacrifice in the contexts we had in mind, and yielded better\nsecurity and fewer changes to existing infrastructure and code.  (For\nexample, Bellovin-Merritt would require clients to monitor for online\nbrute-force attacks on the password.)  Of course, if you want to propose\nan extension allowing for BM-style two-way shared-key-based\nauthentication as an option in TLS, we'd have no objections to its\ninclusion.\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)\n\n>----------\n>From: HUGO@watson.ibm.com[SMTP:HUGO@watson.ibm.com]\n>Sent: Wednesday, November 27, 1996 8:24 AM\n>To: ietf-tls@w3.org\n>Subject: passwords\n>\n>I've seen a lot of traffic in this list discussing the use of\n>passwords, how necessary they are and how insecure, etc. etc.\n>I haven't seen any mention of the use of techniques like\n>Bellovin-Merrit's for preventing dictionary attacks.\n>Certainly, these techniques improve significantly on the\n>security of passwords (particularly, low-entropy ones).\n>BM solutions and related ones use public key techniques\n>which are already available in SSL. Did anyone considered using them?\n>Does anyone know of *any* real-world implementation of such\n>techniques (not necessarily  related to SSL)?\n>\n>Thanks,\n>\n>Hugo\n>\n>\n\n\n\n"
        },
        {
            "subject": "Implementation of Shared Key Authenticatio",
            "content": "Dan Simon's \"Shared Key Authentication for the TLS Protocol\" August 1996\nproposal was issued as an Internet Draft on 25 November 1996.  A copy of\nthe document can be found at\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-passauth-00.txt\n\nTo facilitate the implementation and testing of shared key\nauthentication, an SSL 3.0 test server has been established with an\nimplementation of shared key authentication.  This server can be found\nat https://rajeshk.microsoft.com. \n\nIn addition to this implementation, there are independent and cross\nplatform implementations now under development that will become\navailable during the coming weeks.\n\nIf you have any questions or comments, please contact me at\ntomste@microsoft.com.\n\n**********\n\nTo test this implementation of \"Shared Key Authentication for the TLS\nProtocol\", you will need a client that supports shared key\nauthentication (the spec will allow you to adapt your client to support\nshared key authentication).  You will also need the following\ninformation and files.\n\n\nPredefined user accounts:\n\nUser #1\nUsername: john\nPassword: md5(\"foo\")\nService: Vics Authority\n\nUser #2\nUsername: dan\nPassword: md5(\"foo2\")\nService: SriniCert Authority (uses passthrough challenge)\n\nUser #3\nUsername: tom\nPassword: md5(\"foo!\")\nService: Vics Authority\n\nDebug output from a sample session (user #1).\n\n \nSample ClientHello message with embedded SharedKeys message.\n\n \n\n\nbegin 600 output1.txt\nM5V%I=&EN9R!F;W(@8V]N;F5C=&EO;@T*4F5S970@<V5R=F5R(&AA;F1S:&%K\nM92!H87-H#0H-\"DUE<W-A9V4@*&9R;VT@8VQI96YT*0T*3&5N9W1H.B U,@T*\nM,# P,\" @,38@,#,@,# @,# @,F8@,#$@,# @,# Z,F(@,#,@,# @,S(@.6$@\nM,F8@,C<@-#$@(\"XN+BXO+BXN*RXN,BXO)T$-\"C P,3 @(&1D(#1D(&9D(&(W\nM(&4X(&5F(#DY(&,Y.C%D(#AA(&9F(&%B(&-B(#%C(#)B(#1A(\" N32XN+BXN\nM+BXN+BXN+BM*#0HP,#(P(\" X,R!E9\"!F-B T92 T,2!F8B!C,R!B,#IE,R W\nM9B T9\" P,\" P,\" P-\" P,\" P,R @+BXN3D$N+BXN+DTN+BXN+@T*,# S,\" @\nM,#$@,#$@,#$@,# @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM(\" @(\"XN+BX-\"@T*0TQ)14Y47TA%3$Q/($UE<W-A9V4-\"DQE;F=T:#H@-#,-\nM\"C P,# @(# S(# P(#,R(#EA(#)F(#(W(#0Q(&1D.C1D(&9D(&(W(&4X(&5F\nM(#DY(&,Y(#%D(\" N+C(N+R=!+DTN+BXN+BXN#0HP,#$P(\" X82!F9B!A8B!C\nM8B Q8R R8B T82 X,SIE9\"!F-B T92 T,2!F8B!C,R!B,\"!E,R @+BXN+BXK\nM2BXN+DY!+BXN+@T*,# R,\" @-V8@-&0@,# @,# @,#0@,# @,#,@,#$Z,#$@\nM,#$@,# @(\" @(\" @(\" @(\" @(\" @(\"Y-+BXN+BXN+BXN#0I34TPS(%)#-\"]-\nM1#4@*#0P(&)I=',I#0I3:&%R960@4V5C<F5T($5N86)L960-\"E-E<G9E<B!C\nM:7!H97(@<W5I=&4Z,V@-\"@T*4T525D527TA%3$Q/($UE<W-A9V4-\"DQE;F=T\nM:#H@-S0-\"C P,# @(# R(# P(# P(#0V(# S(# P(#,R(#EA.C)F(#(X(#$V\nM(#=E(#@Y(#,X(#9E(#<P(\" N+BY&+BXR+B\\H+GXN.&YP#0HP,#$P(\" V9B!D\nM,\" V8B!C9B P-\"!F82!C92 V-SIE8R P,2!B9\" Q,\" Q.2!D-2!B,R!D92 @\nM;RYK+BXN+F<N+BXN+BXN+@T*,# R,\" @,&$@-6,@8S<@93 @,# @960@,C @\nM-C0Z-S(@8C @-V0@8S0@96(@,68@83 @9&4@(\"Y<+BXN+B!D<BY]+BXN+BX-\nM\"C P,S @(&0Q(#)C(#8U(&$S(&$T(#@U(#)A(#@V.C0X(#<Y(&-B(&5A(#(Y\nM(#,T(#=D(#AD(\" N+&4N+BXJ+DAY+BXI-'TN#0HP,#0P(\" R,\" V-R Q,\" T\nM,\" R8R V-\"!E8B P,#HP,R P,\" @(\" @(\" @(\" @(\" @(\" @(\" @(&<N0\"QD\nM+BXN+@T*#0I#15)4249)0T%412!-97-S86=E(\"AS97)V97(I#0I,96YG=&@Z\nM(#8P,PT*,# P,\" @,&(@,# @,#(@-3<@,# @,#(@-30@,# Z,#(@-3$@,S @\nM.#(@,#(@-&0@,S @.#(@(\"XN+E<N+E0N+E$P+BY-,\"X-\"C P,3 @(# Q(&)A\nM(# R(# U(# R(#<X(# P(#!B.C4U(#,P(#!D(# V(# Y(#)A(#@V(#0X(\" N\nM+BXN+G@N+E4P+BXN*BY(#0HP,#(P(\" X-B!F-R P9\" P,2 P,2 P,B P-2 P\nM,#HS,\" U9B S,2 P8B S,\" P.2 P-B P,R @+BXN+BXN+BXP7S$N,\"XN+@T*\nM,# S,\" @-34@,#0@,#8@,3,@,#(@-34@-3,@,S$Z,C @,S @,64@,#8@,#,@\nM-34@,#0@,&$@(%4N+BXN55,Q(# N+BY5+BX-\"C P-# @(#$S(#$W(#4R(#4S\nM(#0Q(#(P(#0T(#8Q.C<T(#8Q(#(P(#4S(#8U(#8S(#<U(#<R(\" N+E)302!$\nM871A(%-E8W5R#0HP,#4P(\" V.2 W-\" W.2 R8R R,\" T.2 V92 V,SHR92 S\nM,2 R92 S,\" R8R P-B P,R U-2 @:71Y+\"!);F,N,2XP+\"XN50T*,# V,\" @\nM,#0@,&(@,3,@,C4@-3,@-C4@-C,@-S4Z-S(@-C4@,C @-3,@-C4@-S(@-S8@\nM-C4@(\"XN+B5396-U<F4@4V5R=F4-\"C P-S @(#<R(#(P(#0S(#8U(#<R(#<T\nM(#8Y(#8V.C8Y(#8S(#8Q(#<T(#8Y(#9F(#9E(#(P(\"!R($-E<G1I9FEC871I\nM;VX-\"C P.# @(#0Q(#<U(#<T(#8X(#9F(#<R(#8Y(#<T.C<Y(#,P(#%E(#$W\nM(#!D(#,Y(#,V(#,P(\"!!=71H;W)I='DP+BXN.38P#0HP,#DP(\" S.\" S,2 S\nM,\" S,\" S,\" S,\" S,\" S,#HS,\" U82 Q-R P9\" S.2 S-R S,\" S,B @.#$P\nM,# P,# P6BXN.3<P,@T*,#!A,\" @,S$@,S0@,S(@,S,@,S4@,SD@,S4@,SDZ\nM-6$@,S @-V8@,S$@,&(@,S @,#D@,#8@(#$T,C,U.34Y6C N,2XP+BX-\"C P\nM8C @(# S(#4U(# T(# V(#$S(# R(#4U(#4S.C,Q(#$R(#,P(#$P(# V(# S\nM(#4U(# T(\" N52XN+BY54S$N,\"XN+E4N#0HP,&,P(\" P.\" Q,R P.2 U-R V\nM,2 V.\" V.2 V93HV-R W-\" V9B V92 S,2 Q,\" S,\" P92 @+BXN5V%H:6YG\nM=&]N,2XP+@T*,#!D,\" @,#8@,#,@-34@,#0@,#<@,3,@,#<@-3(Z-C4@-C0@\nM-F0@-F8@-F4@-C0@,S$@,64@(\"XN52XN+BY2961M;VYD,2X-\"C P93 @(#,P\nM(#%C(# V(# S(#4U(# T(#!A(#$S.C$U(#1D(#8Y(#8S(#<R(#9F(#<S(#9F\nM(\" P+BXN52XN+BY-:6-R;W-O#0HP,&8P(\" V-B W-\" R,\" T,R V9B W,B W\nM,\" V9CHW,B V,2 W-\" V.2 V9B V92 S,2 P92 @9G0@0V]R<&]R871I;VXQ\nM+@T*,#$P,\" @,S @,&,@,#8@,#,@-34@,#0@,&(@,3,Z,#4@-#(@-&,@-#0@\nM,S$@,S @,S$@,6$@(# N+BY5+BXN+D),1#$P,2X-\"C Q,3 @(#,P(#$X(# V\nM(# S(#4U(# T(# S(#$T.C$Q(#<P(#8S(#<T(#)E(#9D(#8Y(#8S(\" P+BXN\nM52XN+BYP8W0N;6EC#0HP,3(P(\" W,B V9B W,R V9B V-B W-\" R92 V,SHV\nM9B V9\" S,\" X,2 Y9B S,\" P9\" P-B @<F]S;V9T+F-O;3 N+C N+@T*,#$S\nM,\" @,#D@,F$@.#8@-#@@.#8@9C<@,&0@,#$Z,#$@,#$@,#4@,# @,#,@.#$@\nM.&0@,# @(\"XJ+D@N+BXN+BXN+BXN+BX-\"C Q-# @(#,P(#@Q(#@Y(# R(#@Q\nM(#@Q(# P(#@S.C!C(&9E(#5C(#,W(&0R(&,R(#!D(#-B(\" P+BXN+BXN+BXN\nM7#<N+BX[#0HP,34P(\"!A,2!E92!D8B!E.\" U,2!C82!B-\" Q-3HU-\" T,B!D\nM8B!C-\" R9B!D,\" R.2!F-R @+BXN+E$N+BY40BXN+RXI+@T*,#$V,\" @,#@@\nM,6$@8C @,&,@,# @-#,@838@-6,Z-C<@-S<@-60@8S$@.6(@,V8@-#,@9#D@\nM(\"XN+BXN0RY<9W==+BX_0RX-\"C Q-S @(#EA(# Y(#1F(&$Q(&$P(#$Y(&,Y\nM(&)A.F%C(# S(&8X(&$Y(#@R(#$Q(#9B(&4R(\" N+D\\N+BXN+BXN+BXN+FLN\nM#0HP,3@P(\" Y,B W9B U-B R8B R9B V,B!A-2!A93HP.2 Y,R!C.2!D-\"!C\nM-\" V-B V.\"!B9\" @+BY6*R]B+BXN+BXN+F9H+@T*,#$Y,\" @-6,@,64@9&8@\nM-#$@8C$@9F0@-34@-3@Z,C4@860@.&8@,S$@93D@,S(@9F0@.&8@(%PN+D$N\nM+E58)2XN,2XR+BX-\"C Q83 @(#,P(#AF(#AE(#EB(#8P(#AC(&4V(&%C.F,W\nM(#9C(&(W(#%B(#9D(#1F(&0Y(#,Q(\" P+BXN8\"XN+BYL+BYM3RXQ#0HP,6(P\nM(\" Y.\"!D.\" X8R!F.\"!B,B!E-B R8B V-#HX-B Y,R!E-R!D,R!D-2 U,R!A\nM,B R,2 @+BXN+BXN*V0N+BXN+E,N(0T*,#%C,\" @860@9#0@8V$@-S8@8V$@\nM-F(@,C<@,#(Z,#,@,#$@,# @,#$@,S @,&0@,#8@,#D@(\"XN+G8N:R<N+BXN\nM+C N+BX-\"C Q9# @(#)A(#@V(#0X(#@V(&8W(#!D(# Q(# Q.C R(# U(# P\nM(# S(#=E(# P(# R(&9D(\" J+D@N+BXN+BXN+BY^+BXN#0HP,64P(\"!C-R Q\nM8R S9\" R-B V,B Y9B!F9B V83HX,B Y-2 T,R V.\"!D82!A82!E,R R8R @\nM+BX])F(N+FHN+D-H+BXN+ T*,#%F,\" @-C4@9&(@,3D@868@-S,@,S0@.#@@\nM.#8Z86(@9C@@-&$@864@9#@@8V,@-6,@8V(@(&4N+BYS-\"XN+BY*+BXN7\"X-\nM\"C R,# @(#(U(&)D(#AE(#EE(#8R(&$Y(#0U(#=B.F(S(&$V(&(R(#,U(#$Y\nM(&8U(&1B(#$S(\" E+BXN8BY%>RXN+C4N+BXN#0HP,C$P(\" R9B Y,R Q82 X\nM,\"!A,2 U,2!D8R V,#IC,B Q,B S-2 T-2 T9B!E,2 U.\"!D-\" @+RXN+BY1\nM+F N+C5%3RY8+@T*,#(R,\" @-C @-F0@93D@,C8@,3<@-3$@83$@,V8Z-3@@\nM.30@8S4@9C @93<@.#D@,3(@,V(@(&!M+B8N42X_6\"XN+BXN+CL-\"C R,S @\nM(&-F(#0W(&9E(&-F(#$P(&4R(#1B(#EB.CAC(&$W(#-D(# U(&(T(#!D(#)A\nM(#%B(\" N1RXN+BY++BXN/2XN+BHN#0HP,C0P(\" X.\" V,\"!E-B U-2!E.\"!A\nM,\"!D.2!B8CHW,R T-B P92 R92 W9\" T-B Q.2 U,B @+F N52XN+BYS1BXN\nM?48N4@T*,#(U,\" @9F4@,V8@.64@-#$@-#$@-30@,6,@9C,Z.3$@,CD@8F0@\nM(\" @(\" @(\" @(\" @(\" @(\"X_+D%!5\"XN+BDN#0H-\"DU$-2!H87-H('9A;'5E\nM#0HP,# P(\" V-\"!B.\"!C-B S,2!B,\"!B,2 T-B!F93HV.2!B92 W,B P.\"!D\nM.2 X,\"!A,R!A92 @9\"XN,2XN1BYI+G(N+BXN+@T*#0I32$$@:&%S:\"!V86QU\nM90T*,# P,\" @,&,@968@9&$@,#<@-V0@.34@,C<@,60Z,V8@9#4@-F8@.#,@\nM934@9&4@8CD@8C(@(\"XN+BY]+B<N/RYO+BXN+BX-\"C P,3 @(#(Y(&(W(#1D\nM(&4Q(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" I+DTN\nM#0H-\"E-I9VYA='5R92!B;&]C:R H;F5T=V]R:R!O<F1E<BD-\"C P,# @(# P\nM(# Q(&9F(&9F(&9F(&9F(&9F(&9F.F9F(&9F(&9F(&9F(&9F(&9F(&9F(&9F\nM(\" N+BXN+BXN+BXN+BXN+BXN#0HP,#$P(\"!F9B!F9B!F9B!F9B!F9B!F9B!F\nM9B!F9CIF9B!F9B!F9B!F9B!F9B!F9B!F9B!F9B @+BXN+BXN+BXN+BXN+BXN\nM+@T*,# R,\" @9F8@9F8@9F8@9F8@9F8@9F8@9F8@9F8Z9F8@9F8@9F8@9F8@\nM9F8@9F8@9F8@9F8@(\"XN+BXN+BXN+BXN+BXN+BX-\"C P,S @(&9F(&9F(&9F\nM(&9F(&9F(&9F(&9F(&9F.F9F(&9F(&9F(&9F(&9F(&9F(&9F(&9F(\" N+BXN\nM+BXN+BXN+BXN+BXN#0HP,#0P(\"!F9B!F9B!F9B!F9B!F9B!F9B!F9B!F9CIF\nM9B!F9B!F9B!F9B!F9B!F9B!F9B!F9B @+BXN+BXN+BXN+BXN+BXN+@T*,# U\nM,\" @9F8@9F8@9F8@9F8@9F8@9F8@9F8@9F8Z9F8@9F8@9F8@,# @-C0@8C@@\nM8S8@,S$@(\"XN+BXN+BXN+BXN+F0N+C$-\"C P-C @(&(P(&(Q(#0V(&9E(#8Y\nM(&)E(#<R(# X.F0Y(#@P(&$S(&%E(#!C(&5F(&1A(# W(\" N+D8N:2YR+BXN\nM+BXN+BXN#0HP,#<P(\" W9\" Y-2 R-R Q9\" S9B!D-2 V9B X,SIE-2!D92!B\nM.2!B,B R.2!B-R T9\"!E,2 @?2XG+C\\N;RXN+BXN*2Y-+@T*#0I315)615)?\nM2T597T580TA!3D=%($UE<W-A9V4-\"DQE;F=T:#H@,C U#0HP,# P(\" P8R P\nM,\" P,\"!C.2 P,\" T,\" U9\"!A-SHR,B!B-2 S.\" Q-R Q-B!D-B V-B!D.2 @\nM+BXN+BY 72XB+C@N+BYF+@T*,# Q,\" @.3<@9C<@.#<@9C @-C8@,V4@,34@\nM9C@Z8F,@-C,@8C8@,S@@,34@,S @,3@@-S<@(\"XN+BYF/BXN+F,N.\"XP+G<-\nM\"C P,C @(&4Q(#,Y(#EB(#=A(#$P(#8W(&5B(#!A.C-F(#,U(#EE(#<T(#8S\nM(&$Y(#$T(&5E(\" N.2YZ+F<N+C\\U+G1C+BXN#0HP,#,P(\" T9\"!A,\" X9B!E\nM9B P-2!A,B Q-B!D.3HR82 R-\"!B9B P-R P-B S-B!B82 R-R @32XN+BXN\nM+BXJ)\"XN+C8N)PT*,# T,\" @,3,@-#(@,3D@-68@9#$@9F0@,# @,#,Z,#$@\nM,# @,#$@,# @.# @,V4@,V8@83<@(\"Y\"+E\\N+BXN+BXN+BX^/RX-\"C P-3 @\nM(#(R(#AE(#0T(#-C(&1D(#0Y(&$X(&1B.C1C(&0Q(&-C(#(V(#%B(#,Y(&(R\nM(&%D(\" B+D0\\+DDN+DPN+B8N.2XN#0HP,#8P(\" X82 Y,B T,B T,2!B8B Y\nM9\" W,R!D.3HS,\"!A92 S9\"!B8B P-\"!B.\" Q.2!E9\" @+BY\"02XN<RXP+CTN\nM+BXN+@T*,# W,\" @9C,@83<@-F$@,V(@8S0@,C<@-S(@9F,Z8S(@,V(@.30@\nM.#<@,V8@9#,@,F8@,#$@(\"XN:CLN)W(N+CLN+C\\N+RX-\"C P.# @(#(T(#DU\nM(&)C(&-B(&(W(&$W(&-E(#@X.F-D(&,S(&)D(&0W(&-B(&8Q(&9B(#DX(\" D\nM+BXN+BXN+BXN+BXN+BXN#0HP,#DP(\"!F-2 U.2 P92 X-R W9\" X,2 W8R U\nM9CHV.\" Q9B!E-\" W-2 Y,R!C92 Y-\" Y-\" @+EDN+GTN?%]H+BYU+BXN+@T*\nM,#!A,\" @-V8@,V,@,3D@8C<@830@.64@-#0@8V0Z-C,@-S<@96,@8F0@-#<@\nM,V(@,#8@,S @(\"X\\+BXN+D0N8W<N+D<[+C -\"C P8C @(#EA(#%D(#!F(&)B\nM(#AA(&4Y(#4W(#AE.C=F(#@Q(&%E(&1B(#)A(&,W(#(R(&0V(\" N+BXN+BY7\nM+BXN+BXJ+B(N#0HP,&,P(\"!F9B X,R!A82 S.2!D,B Y82 Q.2 Y.3IB,B T\nM-R!D-B V-\"!D,2 @(\" @(\" @(\" @+BXN.2XN+BXN1RYD+@T*#0I32$%2141?\nM2T597U)%455%4U0@365S<V%G90T*3&5N9W1H.B Q.#8-\"C P,# @(#%F(# P\nM(# P(&(V(# P(&(T(# P(#1B.C,P(#0Y(#,Q(#!B(#,P(# Y(# V(# S(\" N\nM+BXN+BXN2S!),2XP+BXN#0HP,#$P(\" U-2 P-\" P-B Q,R P,B U-2 U,R S\nM,3HQ,B S,\" Q,\" P-B P,R U-2 P-\" P82 @52XN+BY54S$N,\"XN+E4N+@T*\nM,# R,\" @,3,@,#D@-&0@-CD@-C,@-S(@-F8@-S,Z-F8@-C8@-S0@,S$@,&0@\nM,S @,&(@,#8@(\"XN36EC<F]S;V9T,2XP+BX-\"C P,S @(# S(#4U(# T(#!B\nM(#$S(# T(#0Y(#4S.C4P(#4U(#,Q(#$W(#,P(#$U(# V(# S(\" N52XN+BY)\nM4U!5,2XP+BXN#0HP,#0P(\" U-2 P-\" P,R Q,R P92 U-B V.2 V,SHW,R R\nM,\" T,2 W-2 W-\" V.\" V9B W,B @52XN+BY6:6-S($%U=&AO<@T*,# U,\" @\nM-CD@-S0@-SD@,# @,# @,# @,# @-&8Z,S @-&0@,S$@,&(@,S @,#D@,#8@\nM,#,@(&ET>2XN+BY/,$TQ+C N+BX-\"C P-C @(#4U(# T(# V(#$S(# R(#4U\nM(#4S(#,Q.C$R(#,P(#$P(# V(# S(#4U(# T(#!A(\"!5+BXN+E53,2XP+BXN\nM52XN#0HP,#<P(\" Q,R P.2 T9\" V.2 V,R W,B V9B W,SHV9B V-B W-\" S\nM,2 P9\" S,\" P8B P-B @+BY-:6-R;W-O9G0Q+C N+@T*,# X,\" @,#,@-34@\nM,#0@,&(@,3,@,#0@-#D@-3,Z-3 @-34@,S$@,6(@,S @,3D@,#8@,#,@(\"Y5\nM+BXN+DE34%4Q+C N+BX-\"C P.3 @(#4U(# T(# S(#$S(#$R(#4S(#<R(#8Y\nM.C9E(#8Y(#0S(#8U(#<R(#<T(#0Q(#<U(\"!5+BXN+E-R:6YI0V5R=$%U#0HP\nM,&$P(\" W-\" V.\" V9B W,B V.2 W-\" W.2 P,#HP,\" Q,\" P92 S.\"!C9\" P\nM.2 S92 T.\" @=&AO<FET>2XN+BXX+BX^2 T*,#!B,\" @8C<@93(@-#<@-#D@\nM9C0@-#<@9C4@8F,Z.#@@,#4@(\" @(\" @(\" @(\" @(\" @(\" @(\"XN1TDN1RXN\nM+BX-\"@T*4T525D527TA%3$Q/7T1/3D4@365S<V%G90T*3&5N9W1H.B T#0HP\nM,# P(\" P92 P,\" P,\" P,\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM(\" @(\" @(\" @+BXN+@T*#0I315)615)?2$5,3$\\@*'1O(&-L:65N=\"D-\"DQE\nM;F=T:#H@,3 W-PT*,# P,\" @,38@,#,@,# @,#0@,S @,#(@,# @,# Z-#8@\nM,#,@,# @,S(@.6$@,F8@,C@@,38@(\"XN+BXP+BXN1BXN,BXO*\"X-\"C P,3 @\nM(#=E(#@Y(#,X(#9E(#<P(#9F(&0P(#9B.F-F(# T(&9A(&-E(#8W(&5C(# Q\nM(&)D(\"!^+CAN<&\\N:RXN+BYG+BXN#0HP,#(P(\" Q,\" Q.2!D-2!B,R!D92 P\nM82 U8R!C-SIE,\" P,\"!E9\" R,\" V-\" W,B!B,\" W9\" @+BXN+BXN7\"XN+BX@\nM9'(N?0T*,# S,\" @8S0@96(@,68@83 @9&4@9#$@,F,@-C4Z83,@830@.#4@\nM,F$@.#8@-#@@-SD@8V(@(\"XN+BXN+BQE+BXN*BY(>2X-\"C P-# @(&5A(#(Y\nM(#,T(#=D(#AD(#(P(#8W(#$P.C0P(#)C(#8T(&5B(# P(# S(# P(#!B(\" N\nM*31]+B!G+D L9\"XN+BXN#0HP,#4P(\" P,\" P,B U-R P,\" P,B U-\" P,\" P\nM,CHU,2 S,\" X,B P,B T9\" S,\" X,B P,2 @+BY7+BY4+BY1,\"XN33 N+@T*\nM,# V,\" @8F$@,#(@,#4@,#(@-S@@,# @,&(@-34Z,S @,&0@,#8@,#D@,F$@\nM.#8@-#@@.#8@(\"XN+BYX+BY5,\"XN+BHN2\"X-\"C P-S @(&8W(#!D(# Q(# Q\nM(# R(# U(# P(#,P.C5F(#,Q(#!B(#,P(# Y(# V(# S(#4U(\" N+BXN+BXN\nM,%\\Q+C N+BY5#0HP,#@P(\" P-\" P-B Q,R P,B U-2 U,R S,2 R,#HS,\" Q\nM92 P-B P,R U-2 P-\" P82 Q,R @+BXN+E53,2 P+BXN52XN+@T*,# Y,\" @\nM,3<@-3(@-3,@-#$@,C @-#0@-C$@-S0Z-C$@,C @-3,@-C4@-C,@-S4@-S(@\nM-CD@(\"Y24T$@1&%T82!396-U<FD-\"C P83 @(#<T(#<Y(#)C(#(P(#0Y(#9E\nM(#8S(#)E.C,Q(#)E(#,P(#)C(# V(# S(#4U(# T(\"!T>2P@26YC+C$N,\"PN\nM+E4N#0HP,&(P(\" P8B Q,R R-2 U,R V-2 V,R W-2 W,CHV-2 R,\" U,R V\nM-2 W,B W-B V-2 W,B @+BXE4V5C=7)E(%-E<G9E<@T*,#!C,\" @,C @-#,@\nM-C4@-S(@-S0@-CD@-C8@-CDZ-C,@-C$@-S0@-CD@-F8@-F4@,C @-#$@(\"!#\nM97)T:69I8V%T:6]N($$-\"C P9# @(#<U(#<T(#8X(#9F(#<R(#8Y(#<T(#<Y\nM.C,P(#%E(#$W(#!D(#,Y(#,V(#,P(#,X(\"!U=&AO<FET>3 N+BXY-C X#0HP\nM,&4P(\" S,2 S,\" S,\" S,\" S,\" S,\" S,\" S,#HU82 Q-R P9\" S.2 S-R S\nM,\" S,B S,2 @,3 P,# P,#!:+BXY-S R,0T*,#!F,\" @,S0@,S(@,S,@,S4@\nM,SD@,S4@,SD@-6$Z,S @-V8@,S$@,&(@,S @,#D@,#8@,#,@(#0R,S4Y-3E:\nM,\"XQ+C N+BX-\"C Q,# @(#4U(# T(# V(#$S(# R(#4U(#4S(#,Q.C$R(#,P\nM(#$P(# V(# S(#4U(# T(# X(\"!5+BXN+E53,2XP+BXN52XN#0HP,3$P(\" Q\nM,R P.2 U-R V,2 V.\" V.2 V92 V-SHW-\" V9B V92 S,2 Q,\" S,\" P92 P\nM-B @+BY786AI;F=T;VXQ+C N+@T*,#$R,\" @,#,@-34@,#0@,#<@,3,@,#<@\nM-3(@-C4Z-C0@-F0@-F8@-F4@-C0@,S$@,64@,S @(\"Y5+BXN+E)E9&UO;F0Q\nM+C -\"C Q,S @(#%C(# V(# S(#4U(# T(#!A(#$S(#$U.C1D(#8Y(#8S(#<R\nM(#9F(#<S(#9F(#8V(\" N+BY5+BXN+DUI8W)O<V]F#0HP,30P(\" W-\" R,\" T\nM,R V9B W,B W,\" V9B W,CHV,2 W-\" V.2 V9B V92 S,2 P92 S,\" @=\"!#\nM;W)P;W)A=&EO;C$N, T*,#$U,\" @,&,@,#8@,#,@-34@,#0@,&(@,3,@,#4Z\nM-#(@-&,@-#0@,S$@,S @,S$@,6$@,S @(\"XN+E4N+BXN0DQ$,3 Q+C -\"C Q\nM-C @(#$X(# V(# S(#4U(# T(# S(#$T(#$Q.C<P(#8S(#<T(#)E(#9D(#8Y\nM(#8S(#<R(\" N+BY5+BXN+G!C=\"YM:6-R#0HP,3<P(\" V9B W,R V9B V-B W\nM-\" R92 V,R V9CHV9\" S,\" X,2 Y9B S,\" P9\" P-B P.2 @;W-O9G0N8V]M\nM,\"XN,\"XN+@T*,#$X,\" @,F$@.#8@-#@@.#8@9C<@,&0@,#$@,#$Z,#$@,#4@\nM,# @,#,@.#$@.&0@,# @,S @(\"HN2\"XN+BXN+BXN+BXN+C -\"C Q.3 @(#@Q\nM(#@Y(# R(#@Q(#@Q(# P(#@S(#!C.F9E(#5C(#,W(&0R(&,R(#!D(#-B(&$Q\nM(\" N+BXN+BXN+BY<-RXN+CLN#0HP,6$P(\"!E92!D8B!E.\" U,2!C82!B-\" Q\nM-2 U-#HT,B!D8B!C-\" R9B!D,\" R.2!F-R P.\" @+BXN42XN+E1\"+BXO+BDN\nM+@T*,#%B,\" @,6$@8C @,&,@,# @-#,@838@-6,@-C<Z-S<@-60@8S$@.6(@\nM,V8@-#,@9#D@.6$@(\"XN+BY#+EQG=UTN+C]#+BX-\"C Q8S @(# Y(#1F(&$Q\nM(&$P(#$Y(&,Y(&)A(&%C.C S(&8X(&$Y(#@R(#$Q(#9B(&4R(#DR(\" N3RXN\nM+BXN+BXN+BXN:RXN#0HP,60P(\" W9B U-B R8B R9B V,B!A-2!A92 P.3HY\nM,R!C.2!D-\"!C-\" V-B V.\"!B9\" U8R @+E8K+V(N+BXN+BXN9F@N7 T*,#%E\nM,\" @,64@9&8@-#$@8C$@9F0@-34@-3@@,C4Z860@.&8@,S$@93D@,S(@9F0@\nM.&8@,S @(\"XN02XN55@E+BXQ+C(N+C -\"C Q9C @(#AF(#AE(#EB(#8P(#AC\nM(&4V(&%C(&,W.C9C(&(W(#%B(#9D(#1F(&0Y(#,Q(#DX(\" N+BY@+BXN+FPN\nM+FU/+C$N#0HP,C P(\"!D.\" X8R!F.\"!B,B!E-B R8B V-\" X-CHY,R!E-R!D\nM,R!D-2 U,R!A,B R,2!A9\" @+BXN+BXK9\"XN+BXN4RXA+@T*,#(Q,\" @9#0@\nM8V$@-S8@8V$@-F(@,C<@,#(@,#,Z,#$@,# @,#$@,S @,&0@,#8@,#D@,F$@\nM(\"XN=BYK)RXN+BXN,\"XN+BH-\"C R,C @(#@V(#0X(#@V(&8W(#!D(# Q(# Q\nM(# R.C U(# P(# S(#=E(# P(# R(&9D(&,W(\" N2\"XN+BXN+BXN+GXN+BXN\nM#0HP,C,P(\" Q8R S9\" R-B V,B Y9B!F9B V82 X,CHY-2 T,R V.\"!D82!A\nM82!E,R R8R V-2 @+CTF8BXN:BXN0V@N+BXL90T*,#(T,\" @9&(@,3D@868@\nM-S,@,S0@.#@@.#8@86(Z9C@@-&$@864@9#@@8V,@-6,@8V(@,C4@(\"XN+G,T\nM+BXN+DHN+BY<+B4-\"C R-3 @(&)D(#AE(#EE(#8R(&$Y(#0U(#=B(&(S.F$V\nM(&(R(#,U(#$Y(&8U(&1B(#$S(#)F(\" N+BYB+D5[+BXN-2XN+BXO#0HP,C8P\nM(\" Y,R Q82 X,\"!A,2 U,2!D8R V,\"!C,CHQ,B S-2 T-2 T9B!E,2 U.\"!D\nM-\" V,\" @+BXN+E$N8\"XN-45/+E@N8 T*,#(W,\" @-F0@93D@,C8@,3<@-3$@\nM83$@,V8@-3@Z.30@8S4@9C @93<@.#D@,3(@,V(@8V8@(&TN)BY1+C]8+BXN\nM+BXN.RX-\"C R.# @(#0W(&9E(&-F(#$P(&4R(#1B(#EB(#AC.F$W(#-D(# U\nM(&(T(#!D(#)A(#%B(#@X(\"!'+BXN+DLN+BX]+BXN*BXN#0HP,CDP(\" V,\"!E\nM-B U-2!E.\"!A,\"!D.2!B8B W,SHT-B P92 R92 W9\" T-B Q.2 U,B!F92 @\nM8\"Y5+BXN+G-&+BY]1BY2+@T*,#)A,\" @,V8@.64@-#$@-#$@-30@,6,@9C,@\nM.3$Z,CD@8F0@,&,@,# @,# @8SD@,# @-# @(#\\N04%4+BXN*2XN+BXN+D -\nM\"C R8C @(#5D(&$W(#(R(&(U(#,X(#$W(#$V(&0V.C8V(&0Y(#DW(&8W(#@W\nM(&8P(#8V(#-E(\"!=+B(N.\"XN+F8N+BXN+F8^#0HP,F,P(\" Q-2!F.\"!B8R V\nM,R!B-B S.\" Q-2 S,#HQ.\" W-R!E,2 S.2 Y8B W82 Q,\" V-R @+BXN8RXX\nM+C N=RXY+GHN9PT*,#)D,\" @96(@,&$@,V8@,S4@.64@-S0@-C,@83DZ,30@\nM964@-&0@83 @.&8@968@,#4@83(@(\"XN/S4N=&,N+BY-+BXN+BX-\"C R93 @\nM(#$V(&0Y(#)A(#(T(&)F(# W(# V(#,V.F)A(#(W(#$S(#0R(#$Y(#5F(&0Q\nM(&9D(\" N+BHD+BXN-BXG+D(N7RXN#0HP,F8P(\" P,\" P,R P,2 P,\" P,2 P\nM,\" X,\" S93HS9B!A-R R,B X92 T-\" S8R!D9\" T.2 @+BXN+BXN+CX_+B(N\nM1#PN20T*,#,P,\" @83@@9&(@-&,@9#$@8V,@,C8@,6(@,SDZ8C(@860@.&$@\nM.3(@-#(@-#$@8F(@.60@(\"XN3\"XN)BXY+BXN+D)!+BX-\"C S,3 @(#<S(&0Y\nM(#,P(&%E(#-D(&)B(# T(&(X.C$Y(&5D(&8S(&$W(#9A(#-B(&,T(#(W(\"!S\nM+C N/2XN+BXN+BYJ.RXG#0HP,S(P(\" W,B!F8R!C,B S8B Y-\" X-R S9B!D\nM,SHR9B P,2 R-\" Y-2!B8R!C8B!B-R!A-R @<BXN.RXN/RXO+B0N+BXN+@T*\nM,#,S,\" @8V4@.#@@8V0@8S,@8F0@9#<@8V(@9C$Z9F(@.3@@9C4@-3D@,&4@\nM.#<@-V0@.#$@(\"XN+BXN+BXN+BXN62XN?2X-\"C S-# @(#=C(#5F(#8X(#%F\nM(&4T(#<U(#DS(&-E.CDT(#DT(#=F(#-C(#$Y(&(W(&$T(#EE(\"!\\7V@N+G4N\nM+BXN+CPN+BXN#0HP,S4P(\" T-\"!C9\" V,R W-R!E8R!B9\" T-R S8CHP-B S\nM,\" Y82 Q9\" P9B!B8B X82!E.2 @1\"YC=RXN1SLN,\"XN+BXN+@T*,#,V,\" @\nM-3<@.&4@-V8@.#$@864@9&(@,F$@8S<Z,C(@9#8@9F8@.#,@86$@,SD@9#(@\nM.6$@(%<N+BXN+BHN(BXN+BXY+BX-\"C S-S @(#$Y(#DY(&(R(#0W(&0V(#8T\nM(&0Q(#%F.C P(# P(&(V(# P(&(T(# P(#1B(#,P(\" N+BY'+F0N+BXN+BXN\nM+DLP#0HP,S@P(\" T.2 S,2 P8B S,\" P.2 P-B P,R U-3HP-\" P-B Q,R P\nM,B U-2 U,R S,2 Q,B @23$N,\"XN+E4N+BXN55,Q+@T*,#,Y,\" @,S @,3 @\nM,#8@,#,@-34@,#0@,&$@,3,Z,#D@-&0@-CD@-C,@-S(@-F8@-S,@-F8@(# N\nM+BY5+BXN+DUI8W)O<V\\-\"C S83 @(#8V(#<T(#,Q(#!D(#,P(#!B(# V(# S\nM.C4U(# T(#!B(#$S(# T(#0Y(#4S(#4P(\"!F=#$N,\"XN+E4N+BXN25-0#0HP\nM,V(P(\" U-2 S,2 Q-R S,\" Q-2 P-B P,R U-3HP-\" P,R Q,R P92 U-B V\nM.2 V,R W,R @53$N,\"XN+E4N+BXN5FEC<PT*,#-C,\" @,C @-#$@-S4@-S0@\nM-C@@-F8@-S(@-CDZ-S0@-SD@,# @,# @,# @,# @-&8@,S @(\"!!=71H;W)I\nM='DN+BXN3S -\"C S9# @(#1D(#,Q(#!B(#,P(# Y(# V(# S(#4U.C T(# V\nM(#$S(# R(#4U(#4S(#,Q(#$R(\"!-,2XP+BXN52XN+BY54S$N#0HP,V4P(\" S\nM,\" Q,\" P-B P,R U-2 P-\" P82 Q,SHP.2 T9\" V.2 V,R W,B V9B W,R V\nM9B @,\"XN+E4N+BXN36EC<F]S;PT*,#-F,\" @-C8@-S0@,S$@,&0@,S @,&(@\nM,#8@,#,Z-34@,#0@,&(@,3,@,#0@-#D@-3,@-3 @(&9T,2XP+BXN52XN+BY)\nM4U -\"C T,# @(#4U(#,Q(#%B(#,P(#$Y(# V(# S(#4U.C T(# S(#$S(#$R\nM(#4S(#<R(#8Y(#9E(\"!5,2XP+BXN52XN+BY3<FEN#0HP-#$P(\" V.2 T,R V\nM-2 W,B W-\" T,2 W-2 W-#HV.\" V9B W,B V.2 W-\" W.2 P,\" P,\" @:4-E\nM<G1!=71H;W)I='DN+@T*,#0R,\" @,3 @,&4@,S@@8V0@,#D@,V4@-#@@8C<Z\nM93(@-#<@-#D@9C0@-#<@9C4@8F,@.#@@(\"XN.\"XN/D@N+D=)+D<N+BX-\"C T\nM,S @(# U(#!E(# P(# P(# P(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM(\" @(\" @(\" N+BXN+@T*#0I-97-S86=E(\"AF<F]M(&-L:65N=\"D-\"DQE;F=T\nM:#H@,3@Q#0HP,# P(\" Q-B P,R P,\" P,\"!B,\" Q,\" P,\" P,#HT,\" Q92 P\nM.\" P9\" V-2 S,\" X.2 Y,B @+BXN+BXN+BY +BXN93 N+@T*,# Q,\" @-3$@\nM,38@-&$@9#(@-6$@-SD@,#8@,6,Z-3 @93$@9#$@,S(@,C<@.#0@.3$@8S0@\nM(%$N2BY:>2XN4\"XN,B<N+BX-\"C P,C @(#(P(&4Y(#=C(#%D(&9D(#5D(&,Q\nM(&9C.C$Y(#DP(# S(#0Y(#EC(&0P(#8R(#9C(\" @+GPN+ETN+BXN+DDN+F)L\nM#0HP,#,P(\" Q8B!B82 V92 X8B!E-B!E82!E82!C9CHR,R Y9B!F-R W-2 R\nM.\" X,B T.2!E.\" @+BYN+BXN+BXC+BYU*\"Y)+@T*,# T,\" @-3D@-#8@93,@\nM968@,S8@.&0@9F0@93 Z-68@,C @,# @,# @-C@@,# @-&(@,S @(%E&+BXV\nM+BXN7R N+F@N2S -\"C P-3 @(#0Y(#,Q(#!B(#,P(# Y(# V(# S(#4U.C T\nM(# V(#$S(# R(#4U(#4S(#,Q(#$R(\"!),2XP+BXN52XN+BY54S$N#0HP,#8P\nM(\" S,\" Q,\" P-B P,R U-2 P-\" P82 Q,SHP.2 T9\" V.2 V,R W,B V9B W\nM,R V9B @,\"XN+E4N+BXN36EC<F]S;PT*,# W,\" @-C8@-S0@,S$@,&0@,S @\nM,&(@,#8@,#,Z-34@,#0@,&(@,3,@,#0@-#D@-3,@-3 @(&9T,2XP+BXN52XN\nM+BY)4U -\"C P.# @(#4U(#,Q(#$W(#,P(#$U(# V(# S(#4U.C T(# S(#$S\nM(#!E(#4V(#8Y(#8S(#<S(\"!5,2XP+BXN52XN+BY6:6-S#0HP,#DP(\" R,\" T\nM,2 W-2 W-\" V.\" V9B W,B V.3HW-\" W.2 P,\" P,\" P,\" P,\" P-\" V82 @\nM($%U=&AO<FET>2XN+BXN:@T*,#!A,\" @-F8@-C@@-F4@,# @,3 @9&$@86(@\nM83(Z-S$@-S4@83$@-F0@.30@8S(@93$@,34@(&]H;BXN+BXN<74N;2XN+BX-\nM\"C P8C @(#8S(&4Y(#(U(#AF(# T(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM(\" @(\" @(\" @(\"!C+B4N+@T*#0I$96-R>7!T960@34%35$527TM%62!E;F-R\nM>7!T:6]N(&)L;V-K#0I,96YG=&@Z(#8T#0HP,# P(\"!E,\"!E.\" P8R S,R S\nM,R!E.\" X-B T8SHU,\" T,\" V9\"!D,\" T.2!A,B U,2 Y-B @+BXN,S,N+DQ0\nM0&TN22Y1+@T*,# Q,\" @-&(@-F4@8S<@8V0@,C4@,C,@.3<@-V8Z93@@,3D@\nM8F8@-6$@-C8@,CD@-38@-#D@($MN+BXE(RXN+BXN6F8I5DD-\"C P,C @(&4P\nM(#<Y(#DV(#<U(&,W(&)B(#8X(&$Y.F4P(&,S(&8S(#-C(#DQ(&,R(# P(# S\nM(\" N>2YU+BYH+BXN+CPN+BXN#0HP,#,P(\" P,\"!A82 V-R!D9B!F82 Q-B!C\nM9B!A-CHX9B!A-B V8B!F92!A92 X82 P,B P,\" @+BYG+BXN+BXN+FLN+BXN\nM+@T*#0I04D5?34%35$527TM%63H-\"C P,# @(# S(# P(&,R(#DQ(#-C(&8S\nM(&,S(&4P.F$Y(#8X(&)B(&,W(#<U(#DV(#<Y(&4P(\" N+BXN/\"XN+BYH+BYU\nM+GDN#0HP,#$P(\" T.2 U-B R.2 V-B U82!B9B Q.2!E.#HW9B Y-R R,R R\nM-2!C9\"!C-R V92 T8B @258I9EHN+BXN+B,E+BYN2PT*,# R,\" @.38@-3$@\nM83(@-#D@9# @-F0@-# @-3 Z-&,@.#8@93@@,S,@,S,@,&,@93@@93 @(\"Y1\nM+DDN;4!03\"XN,S,N+BX-\"@T*0G5I;&0@34%35$527TM%60T*#0I#3$E%3E1?\nM4D%.1$]-.@T*,# P,\" @,S(@.6$@,F8@,C<@-#$@9&0@-&0@9F0Z8C<@93@@\nM968@.3D@8SD@,60@.&$@9F8@(#(N+R=!+DTN+BXN+BXN+BX-\"C P,3 @(&%B\nM(&-B(#%C(#)B(#1A(#@S(&5D(&8V.C1E(#0Q(&9B(&,S(&(P(&4S(#=F(#1D\nM(\" N+BXK2BXN+DY!+BXN+BY-#0H-\"E-%4E9%4E]204Y$3TTZ#0HP,# P(\" S\nM,B Y82 R9B R.\" Q-B W92 X.2 S.#HV92 W,\" V9B!D,\" V8B!C9B P-\"!F\nM82 @,BXO*\"Y^+CAN<&\\N:RXN+@T*,# Q,\" @8V4@-C<@96,@,#$@8F0@,3 @\nM,3D@9#4Z8C,@9&4@,&$@-6,@8S<@93 @,# @960@(\"YG+BXN+BXN+BXN7\"XN\nM+BX-\"@T*4%)%7TU!4U1%4E]+15DZ#0HP,# P(\" P,R P,\"!C,B Y,2 S8R!F\nM,R!C,R!E,#IA.2 V.\"!B8B!C-R W-2 Y-B W.2!E,\" @+BXN+CPN+BXN:\"XN\nM=2YY+@T*,# Q,\" @-#D@-38@,CD@-C8@-6$@8F8@,3D@93@Z-V8@.3<@,C,@\nM,C4@8V0@8S<@-F4@-&(@($E6*69:+BXN+BXC)2XN;DL-\"C P,C @(#DV(#4Q\nM(&$R(#0Y(&0P(#9D(#0P(#4P.C1C(#@V(&4X(#,S(#,S(#!C(&4X(&4P(\" N\nM42Y)+FU 4$PN+C,S+BXN#0H-\"DU!4U1%4E]+15DZ#0HP,# P(\"!B92 Q9\" U\nM,2 Y8B P9B U.\" Y,2!B8CIC-2!F92 P.\" W-B!C8B W-2 Y,2 W.\" @+BY1\nM+BY8+BXN+BYV+G4N> T*,# Q,\" @,SD@-S$@,#(@,6,@8C0@8S$@-3,@,S(Z\nM,#8@9C,@,S(@-&$@-#4@83 @,3D@-C$@(#EQ+BXN+E,R+BXR2D4N+F$-\"C P\nM,C @(&,P(# Q(&$W(&,X(&(S(&5D(#<Q(#,W.F4V(#@T(#0Q(&(V(&4X(#0T\nM(&%D(#5F(\" N+BXN+BYQ-RXN02XN1\"Y?#0H-\"D=E;F5R871E('-E<W-I;VX@\nM:V5Y<R!F<F]M#0H-\"DU!4U1%4E]+15DZ#0HP,# P(\"!B92 Q9\" U,2 Y8B P\nM9B U.\" Y,2!B8CIC-2!F92 P.\" W-B!C8B W-2 Y,2 W.\" @+BY1+BY8+BXN\nM+BYV+G4N> T*,# Q,\" @,SD@-S$@,#(@,6,@8C0@8S$@-3,@,S(Z,#8@9C,@\nM,S(@-&$@-#4@83 @,3D@-C$@(#EQ+BXN+E,R+BXR2D4N+F$-\"C P,C @(&,P\nM(# Q(&$W(&,X(&(S(&5D(#<Q(#,W.F4V(#@T(#0Q(&(V(&4X(#0T(&%D(#5F\nM(\" N+BXN+BYQ-RXN02XN1\"Y?#0H-\"DME>2!B;&]C:SH-\"DQE;F=T:#H@.# -\nM\"C P,# @(#4P(&8W(&)D(&8V(#8X(&1F(#=B(&0T.F,S(#@V(#,R(#!E(&(P\nM(#9C(&8Q(#5C(\"!0+BXN:\"Y[+BXN,BXN;\"Y<#0HP,#$P(\"!A-\" W82!C8B Q\nM,\"!F92 V,2!E-2 Y83HU.\" U8B X-2 S-2 T92 Y-R!F82 Q8B @+GHN+BYA\nM+BY86RXU3BXN+@T*,# R,\" @9#4@-6(@8C4@96,@9C,@-68@,3 @,S8Z,V(@\nM,S @-#$@-C4@8F4@.&4@.6,@,C<@(\"Y;+BXN7RXV.S!!92XN+B<-\"C P,S @\nM(# Q(#AA(#4U(#4P(# W(#4R(&0Q(&4T.C-E(&8X(&8P(#8Y(&-C(&9E(#0Y\nM(&0R(\" N+E50+E(N+CXN+FDN+DDN#0HP,#0P(\" V8B!F82 P82 P92 Y.2!D\nM-\"!C,\" U-CID,\" T-2 R.2 Y-B!C-B Q,2 S9B!A,B @:RXN+BXN+E8N12DN\nM+BX_+@T*,# U,\" @964@.&$@,S8@-C,@.#4@,#,@-S @-V(Z-C(@-&8@8C@@\nM9F4@868@,C @-S8@,#(@(\"XN-F,N+G![8D\\N+BX@=BX-\"C P-C @(&-D(&0T\nM(&-B(#$S(#$Y(#<P(#0Q(#9F.C$P(&)D(#4X(#@S(#%C(#DW(# X(#0X(\" N\nM+BXN+G!!;RXN6\"XN+BY(#0I096YD:6YG($-,245.5%]74DE415]+15DZ(&0U\nM-6)B-65C9C,-\"E!E;F1I;F<@4T525D527U=2251%7TM%63H@-68Q,#,V,V(S\nM, T*#0I096YD:6YG($-,245.5%]74DE415]+15DZ(#DY-&5C-V8V9#)D,S8Q\nM,#@Q.#(W8S T8C-C9C8Q9&5D#0I096YD:6YG(%-%4E9%4E]74DE415]+15DZ\nM(#@U-V5F-3,R.#<R-S-D9F$T,C8U,S,S8CAB8C=E-30Q#0I096YD:6YG($-,\nM245.5%]-04-?2T59.B @(#4P9C=B9&8V-CAD9C=B9#1C,S@V,S(P96(P-F-F\nM,35C#0I096YD:6YG(%-%4E9%4E]-04-?2T59.B @(&$T-V%C8C$P9F4V,64U\nM.6$U.#5B.#4S-31E.3=F83%B#0I096YD:6YG(%-(05)%1%]314-2150Z(\" @\nM(#0Q-C5B93AE.6,R-S Q.&$U-34P,#<U,F0Q930S968X#0H-\"@T*4TA!4D5$\nM7TM%65]615))1ED-\"DQE;F=T:#H@,3 T#0HP,# P(\" P,\" T8B S,\" T.2 S\nM,2 P8B S,\" P.3HP-B P,R U-2 P-\" P-B Q,R P,B U-2 @+DLP23$N,\"XN\nM+E4N+BXN50T*,# Q,\" @-3,@,S$@,3(@,S @,3 @,#8@,#,@-34Z,#0@,&$@\nM,3,@,#D@-&0@-CD@-C,@-S(@(%,Q+C N+BY5+BXN+DUI8W(-\"C P,C @(#9F\nM(#<S(#9F(#8V(#<T(#,Q(#!D(#,P.C!B(# V(# S(#4U(# T(#!B(#$S(# T\nM(\"!O<V]F=#$N,\"XN+E4N+BXN#0HP,#,P(\" T.2 U,R U,\" U-2 S,2 Q-R S\nM,\" Q-3HP-B P,R U-2 P-\" P,R Q,R P92 U-B @25-053$N,\"XN+E4N+BXN\nM5@T*,# T,\" @-CD@-C,@-S,@,C @-#$@-S4@-S0@-C@Z-F8@-S(@-CD@-S0@\nM-SD@,# @,# @,# @(&EC<R!!=71H;W)I='DN+BX-\"C P-3 @(# P(# T(#9A\nM(#9F(#8X(#9E(# P(#$P.F1A(&%B(&$R(#<Q(#<U(&$Q(#9D(#DT(\" N+FIO\nM:&XN+BXN+G%U+FTN#0HP,#8P(\"!C,B!E,2 Q-2 V,R!E.2 R-2 X9B P-#H@\nM(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @+BXN8RXE+BX-\"@T*075T:%-E<G9E\nM<BY.86UE.@T*,# P,\" @,S @-#D@,S$@,&(@,S @,#D@,#8@,#,Z-34@,#0@\nM,#8@,3,@,#(@-34@-3,@,S$@(#!),2XP+BXN52XN+BY54S$-\"C P,3 @(#$R\nM(#,P(#$P(# V(# S(#4U(# T(#!A.C$S(# Y(#1D(#8Y(#8S(#<R(#9F(#<S\nM(\" N,\"XN+E4N+BXN36EC<F]S#0HP,#(P(\" V9B V-B W-\" S,2 P9\" S,\" P\nM8B P-CHP,R U-2 P-\" P8B Q,R P-\" T.2 U,R @;V9T,2XP+BXN52XN+BY)\nM4PT*,# S,\" @-3 @-34@,S$@,3<@,S @,34@,#8@,#,Z-34@,#0@,#,@,3,@\nM,&4@-38@-CD@-C,@(%!5,2XP+BXN52XN+BY6:6,-\"C P-# @(#<S(#(P(#0Q\nM(#<U(#<T(#8X(#9F(#<R.C8Y(#<T(#<Y(\" @(\" @(\" @(\" @(\" @(\"!S($%U\nM=&AO<FET>0T*075T:%-E<G9E<BY$:7-P;&%Y.@T*075T:%-E<G9E<BY#:&%L\nM;&5N9V4Z#0I)9&5N=&ET>3HV839F-C@V90T*4F5S<&]N<V4Z9&%A8F$R-S$W\nM-6$Q-F0Y-&,R93$Q-38S93DR-3AF,#0-\"@T*365S<V%G92 H9G)O;2!C;&EE\nM;G0I#0I,96YG=&@Z(#8-\"C P,# @(#$T(# S(# P(# P(# Q(# Q(\" @(\" @\nM(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" N+BXN+BX-\"@T*0TA!3D=%7T-)\nM4$A%4E]34$5#($UE<W-A9V4@*&-L:65N=\"D-\"DQE;F=T:#H@,0T*,# P,\" @\nM,#$@(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM(\" @(\"X-\"@T*1FEN:7-H(&-L:65N=\"!K97ES#0I#3$E%3E1?5U))5$5?2T59\nM.B Y.31E8S=F-F0R9#,V,3 X,3@R-V,P-&(S8V8V,61E9 T*0TQ)14Y47TU!\nM0U]+15DZ(\" @-3!F-V)D9C8V.&1F-V)D-&,S.#8S,C!E8C V8V8Q-6,-\"@T*\nM365S<V%G92 H9G)O;2!C;&EE;G0I#0I,96YG=&@Z(#8Q#0HP,# P(\" Q-B P\nM,R P,\" P,\" S.\"!A9\"!C92 T-SHU-2 U9\"!B8B T,R X-2 Y8B!B-\" X9\" @\nM+BXN+C@N+D=572Y#+BXN+@T*,# Q,\" @-34@-S@@83<@.3(@,C(@8S@@9C,@\nM.3<Z-38@.&,@,C(@,3@@8S8@-S0@,S(@,F8@(%5X+BXB+BXN5BXB+BYT,B\\-\nM\"C P,C @(&8P(#0Y(#5A(#DR(&,V(&,X(#$S(&%C.C(U(&8V(#5A(#%E(#DQ\nM(#(X(&8W(&1C(\" N25HN+BXN+B4N6BXN*\"XN#0HP,#,P(\" P,R R82 W,R Y\nM,B!B9\"!D9\"!E82!D9#HY8B Q,B Q.\" U,B W-B @(\" @(\" @(\" @+BIS+BXN\nM+BXN+BY2=@T*0VQI96YT('-E<75E;F-E.C -\"@T*1DE.25-(140@365S<V%G\nM92 H8VQI96YT*0T*3&5N9W1H.B T, T*,# P,\" @,30@,# @,# @,C0@.6$@\nM,F$@.#<@,F(Z8C$@860@934@8V$@8F,@-C(@9F8@8F0@(\"XN+B0N*BXK+BXN\nM+BYB+BX-\"C P,3 @(#,S(&8Q(#!F(&,S(#9A(#<R(#(U(#1E.C@R(&0U(#DU\nM(#=E(&-E(#4T(#0V(#<P(\" S+BXN:G(E3BXN+GXN5$9P#0HP,#(P(\"!A9B Y\nM9B Q,\" S92!D,\"!E82 X92!A8SH@(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM+BXN/BXN+BX-\"@T*3&%T8V@@:&%S:\"!H86YD<VAA:V4@9&%T80T*0V]M<'5T\nM960@1DE.25-(140@340U.CEA,F$X-S)B8C%A9&4U8V%B8S8R9F9B9#,S9C$P\nM9F,S#0I296-E:79E9\"!&24Y)4TA%1\"!-1#4Z.6$R83@W,F)B,6%D935C86)C\nM-C)F9F)D,S-F,3!F8S,-\"D-O;7!U=&5D($9)3DE32$5$(%-(03HV83<R,C4T\nM93@R9#4Y-3=E8V4U-#0V-S!A9CEF,3 S960P96$X96%C#0I296-E:79E9\"!&\nM24Y)4TA%1\"!32$$Z-F$W,C(U-&4X,F0U.34W96-E-30T-C<P868Y9C$P,V5D\nM,&5A.&5A8PT*#0I#2$%.1T5?0TE02$527U-014,@365S<V%G90T*3&5N9W1H\nM.B Q#0HP,# P(\" P,2 @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM(\" @(\" @(\" @(\" @(\" @+@T*#0I#2$%.1T5?0TE02$527U-014,@*'1O(&-L\nM:65N=\"D-\"DQE;F=T:#H@-@T*,# P,\" @,30@,#,@,# @,# @,#$@,#$@(\" @\nM(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\"XN+BXN+@T*#0I&:6YI<V@@\nM<V5R=F5R(&ME>7,-\"E-%4E9%4E]74DE415]+15DZ(#@U-V5F-3,R.#<R-S-D\nM9F$T,C8U,S,S8CAB8C=E-30Q#0I315)615)?34%#7TM%63H@(\"!A-#=A8V(Q\nM,&9E-C%E-3EA-3@U8C@U,S4T93DW9F$Q8@T*#0I,871C:\"!H87-H(&AA;F1S\nM:&%K92!D871A#0H-\"D9)3DE32$5$($UE<W-A9V4-\"DQE;F=T:#H@-# -\"C P\nM,# @(#$T(# P(# P(#(T(#5D(#5C(#@U(#(X.F,Y(# S(&-B(#!C(#,W(#9C\nM(&-B(&$X(\" N+BXD75PN*\"XN+BXW;\"XN#0HP,#$P(\" V-B X-R W9\" R-2 T\nM9B W,2!B,R T93HQ-R!F82 V82!E-B U,R P8B U.2!C9\" @9BY])4]Q+DXN\nM+FHN4RY9+@T*,# R,\" @,3<@-SD@,3D@,C0@9F$@-#@@,64@,F0Z(\" @(\" @\nM(\" @(\" @(\" @(\" @(\" @(\" @(\"YY+B0N2\"XM#0I397)V97(@<V5Q=65N8V4Z\nM, T*#0I&24Y)4TA%1\" H=&\\@8VQI96YT*0T*3&5N9W1H.B V,0T*,# P,\" @\nM,38@,#,@,# @,# @,S@@,C8@-V,@-C4Z.6(@83(@,6(@-S,@.#8@,60@,V4@\nM8F4@(\"XN+BXX)GQE+BXN<RXN/BX-\"C P,3 @(&4X(&$R(&(S(&$R(#!E(#4Y\nM(#0W(#0X.C!C(&8Q(&(R(#DR(# Y(#EF(&-D(&,X(\" N+BXN+EE'2\"XN+BXN\nM+BXN#0HP,#(P(\" W92 Q8R!F-R!B-R X.\"!D-2!E8B!B9CHP92 X-B Y8B V\nM82!C92 R.\" S82!A8B @?BXN+BXN+BXN+BYJ+B@Z+@T*,# S,\" @.64@864@\nM,#0@9&,@.&(@-&$@.&,@,38Z,S@@.30@86(@-# @-S@@(\" @(\" @(\" @(\"XN\nM+BXN2BXN.\"XN0'@-\"DAA;F1S:&%K92!P:&%S92!S=6-C965D960L(')E861Y\nM(&9O<B!C;VUM86YD#0H-\"DUE<W-A9V4@*&9R;VT@8VQI96YT*0T*3&5N9W1H\nM.B Y. T*,# P,\" @,3<@,#,@,# @,# @-60@8S(@-3$@.30Z,&4@93<@-#4@\nM.#@@-&$@,#<@,F4@-#$@(\"XN+BY=+E$N+BY%+DHN+D$-\"C P,3 @(#(S(#(X\nM(#1C(&%C(#AC(#@X(&$Q(&,R.C8W(#<S(&4T(#4P(&0Y(&0R(&9B(#-D(\" C\nM*$PN+BXN+F=S+E N+BX]#0HP,#(P(\" R,\" P82 S.2 P9B X.\"!E82 S-R P\nM9CHT,2 Q-\"!F9\" Y92!D-R S.2!D8B P-2 @(\"XY+BXN-RY!+BXN+CDN+@T*\nM,# S,\" @,3,@8V,@-CD@83D@,#4@,S4@-S<@-3 Z,&$@-30@8SD@-CD@8C @\nM8S0@,V0@8C@@(\"XN:2XN-7=0+E0N:2XN/2X-\"C P-# @(&4W(&0X(&%F(&4Y\nM(#9E(#=A(#,X(#@P.C)E(#0S(&0P(&9C(&-F(#9B(#@W(&$Q(\" N+BXN;GHX\nM+BY#+BXN:RXN#0HP,#4P(\" T9B W,B X,2 Y8B!C-2!D,B X,R!A-3HQ-2 R\nM,\" W82 T-\" S9B!A-R U8R U-R @3W(N+BXN+BXN('I$/RY<5PT*,# V,\" @\nM86(@,F0@(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nM(\" @(\"XM#0I#;&EE;G0@<V5Q=65N8V4Z,0T*#0I5;G=R87!P960@;65S<V%G\nM92 H9G)O;2!C;&EE;G0I#0I,96YG=&@Z(#<X#0HP,# P(\" T-R T-2 U-\" R\nM,\" R9B V-\" V-2 V-CHV,2 W-2 V8R W-\" R92 V.\" W-\" V9\" @1T54(\"]D\nM969A=6QT+FAT;0T*,# Q,\" @,C @-#@@-30@-30@-3 @,F8@,S$@,F4Z,S @\nM,&0@,&$@-34@-S,@-C4@-S(@,F0@(\"!(5%10+S$N,\"XN57-E<BT-\"C P,C @\nM(#0Q(#8W(#8U(#9E(#<T(#-A(#(P(#4W.C0R(#0S(#1C(#0Y(#!D(#!A(#4R\nM(#8U(\"!!9V5N=#H@5T)#3$DN+E)E#0HP,#,P(\" V-B V-2 W,B V-2 W,B S\nM82 R,\" U-SHT,B T,R T8R T.2 P9\" P82 T,2 V,R @9F5R97(Z(%=\"0TQ)\nM+BY!8PT*,# T,\" @-C,@-C4@-S @-S0@,V$@,C @,F$@,F8Z,F$@,&0@,&$@\nM,&0@,&$@,# @(\" @(\" @(&-E<'0Z(\"HO*BXN+BXN#0I-97-S86=E(&ES.B @\nM)T=%5\" O9&5F875L=\"YH=&T@2%144\"\\Q+C -\"E5S97(M06=E;G0Z(%=\"0TQ)\nM#0I2969E<F5R.B!70D-,20T*06-C97!T.B J+RH-\"@T*)PT*4V5N9\" B9&5F\nM875L=\"YH=&TB(&9I;&4N#0H-\"DA45% @<F5S<&]N<V4@:&5A9&5R(\"AT;R!C\nM;&EE;G0I#0I,96YG=&@Z(#0P#0HP,# P(\" T.\" U-\" U-\" U,\" R9B S,2 R\nM92 S,#HR,\" S,B S,\" S,\" R,\" T9B T8B P9\" @2%144\"\\Q+C @,C P($]+\nM+@T*,# Q,\" @,&$@-#,@-F8@-F4@-S0@-C4@-F4@-S0Z,F0@-&,@-C4@-F4@\nM-C<@-S0@-C@@,V$@(\"Y#;VYT96YT+4QE;F=T:#H-\"C P,C @(#(P(#,Q(#,R\nM(#,P(#,R(#,W(#!D(#!A.B @(\" @(\" @(\" @(\" @(\" @(\" @(\" @(\" @,3(P\nM,C<N+@T*4V5R=F5R('-E<75E;F-E.C$-\"E-E<G9E<B!S97%U96YC93HR#0I3\nM97)V97(@<V5Q=65N8V4Z,PT*4V5R=F5R('-E<75E;F-E.C0-\"E-E<G9E<B!S\nM97%U96YC93HU#0I397)V97(@<V5Q=65N8V4Z-@T*4V5R=F5R('-E<75E;F-E\nM.C<-\"E-E<G9E<B!S97%U96YC93HX#0I397)V97(@<V5Q=65N8V4Z.0T*4V5R\nM=F5R('-E<75E;F-E.C$P#0I397)V97(@<V5Q=65N8V4Z,3$-\"E-E<G9E<B!S\nM97%U96YC93HQ,@T*4V5R=F5R('-E<75E;F-E.C$S#0I397)V97(@<V5Q=65N\nM8V4Z,30-\"E-E<G9E<B!S97%U96YC93HQ-0T*#0I!3$525\" H=&\\@8VQI96YT\nM*0T*3&5N9W1H.B R,PT*,# P,\" @,34@,#,@,# @,# @,3(@-CD@,34@-C$Z\nM9#<@964@8C(@9F4@9#4@,3<@-# @-V,@(\"XN+BXN:2YA+BXN+BXN0'P-\"C P\nM,3 @(#$R(&-D(&0Q(#4T(&,Q(#)C(#,T(\" @(\" @(\" @(\" @(\" @(\" @(\" @\nI(\" @(\" @(\" N+BY4+BPT#0I786ET:6YG(&9O<B!C;VYN96-T:6]N#0H@\n`\nend\n\nbegin 600 output2.txt\n`\nend\n\n\n\n"
        },
        {
            "subject": "Re: TLS Draft",
            "content": "At 6:41 AM -0800 11/27/96, Jeff Williams wrote:\n>  Has this been posted to the IETF ftp index yet?\n\nOne has:\n<ftp://ds.internic.net/internet-drafts/draft-ietf-tls-ssl-mods-00.txt>.\n\nNote that this is a different name than what I discussed before, but it is\nthe same document.\n\nThe other is also being renamed, and will supposedly be\n<ftp://ds.internic.net/internet-drafts/draft-ietf-tls-protocol-00.txt>.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "MAC redefinitio",
            "content": "I am happy to see in the list of proposed changes the issue of MAC computation.\n\nI recommend:\n\n1) aligning ALL MAC definitions in the SSL/TLS draft to the definition\n   of HMAC as appears in draft-ietf-ipsec-hmac-md5-01.txt\n   which is now the *official* definition of HMAC\n   (the text in this draft is identical to the one in the upcoming RFC\n   on HMAC, in particular it has nothing particular about MD5, it uses\n   any iterated hash function).\n\n   Two elements of HMAC missing in the SSL definitions are:\n   XOR of pads (instead of concatenation) AND\n   keys PREPENDED in the inner and outer applications of the hash function.\n   (The later is violated in the uses of hmac\n   in draft-ietf-tls-ssl-version3-00.txt  in pages 31, 32 and 34.)\n\n2) Even better: do not use explicitly HMAC in the MAC definitions\n   that appear throughout the text of the draft.\n   Instead use a notation of the form\n   MAC(key, item1 + item2 +...)\n   where 'key' is the key to the MAC and item1, item2, etc are the\n   data items that you define in each use. The sign + is concatenation.\n   Then define globally that the default MAC for SSL is HMAC as defined\n   in RFC .... (in the meantime it's draft-ietf-ipsec-hmac-md5-01.txt)\n   (ie, MAC(key, DataItems) is implemented by HMAC with K=key and\n   text=DataItems)\n\n   In this way the generic functionality of a MAC is highlighted, the key\n   and data are clearly separated, and replaceability of HMAC if desired\n   is easily achieved.\n\n3) Some of the uses of hmac-like functions in SSL.v3 are for key generation\n   rather than MAC.\n   I recommend decoupling these definitions from the specific form of\n   these hmac-like functions. Instead use a generic notation, for example,\n   PRF (for pseudorandom function).\n   The definition of key derivation would be\n   PRF(key, data)[n]\n   which means: compute PRF on 'data' using key 'key' and output first\n   n bits.\n\n   In this case you could define HMAC as the default PRF and sepcify\n   how an arbitrary number of bits is output. This can follow the current\n   SSL constructions using concatenation of\n   HMAC(key, 'A', data) + HMAC(key, 'BB', data) + ...\n   (a more \"scalable\" definition would be preferable: if you happen\n    to need many bits you may need to do 'ZZZ......Z' 26 times.\n    Even worst what comes after Z? :)\n\n   An important advantage of using a generic notation like PRF is that\n   it allows for pseudorandom functions based on block cipher rather\n   than just keyed hash functions.\n   For example, I trust more the pseudorandom properties of triple-DES\n   that those of MD5. (Yes, PRF(K, data) could be defined as 3DES(K,data)).\n\n   As for mixing MD5 and SHA I do not see any real advantage to it.\n   We should consider SHA as superior anyway and then go for\n   HMAC-SHA for key derivation (here the performance advantages\n   of MD5 are insignificant and the probability that SHA is broken as\n   a pseudorandom function but MD5 is not seems to be very very low).\n   In my view, mixing MD5 and SHA does not achieve the best of\n   both but the worst of both, namely, any one of the two to be\n   broken in a relevant way will require chnaging the function.\n\n   I also recommend against putting keys in variable locations\n   (the latter is the case with the current definitions, e.g.,\n   SHA('A' + master_secret...) vs SHA('BB' + master_secret...)\n\n\n\nYes I know that there are interoperability issues involving the change\nto standard HMAC. These issues need to be resolved with the existing\nmechanisms that support version forwarding, etc. But the more we wait\nto make the changes the harder it will be.\n\nHugo\n\n\n\n"
        },
        {
            "subject": "Rev'ing SSL-TalkFA",
            "content": "I am revising a new version of the SSL-Talk-FAQ\n<http://www.consensus.com/security/ssl-talk-faq.html> in time for the\nIETF-TLS meeting next Monday in San Jose.\n\nIf you have any comments, additions, questions, etc. that you'd like to see\nget in the next release, please send them to me ASAP so that I try to\nincorporate them by Friday.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "TLS vs SSLtal",
            "content": "I consider the break down of functions of ssl-talk and\nIETF TLS exploder to be about right - TLS discusses IETF\nWG processes (including implementation - whilst the stds track \nprocess is being worked - to maximise interworking) whilst ssl-talk talks\nabout  everything else around the periphary in a kind of all-comers mutual\nsupport framework which is not normally overly competitive or otherwise\npurpose-driven.\n\nI fail to see why the TLS list cannot be used for discussing the\nimplementation of the I-D/ RFC etc and exchanging implementation and\ninterworking experience for the various TLS RFCs as they\nevolve over time. This is quite normal. The first TLS RFC is unlikley to\nbe the last. Interworking trial feedback is vital to the IETF process,\nso perhaps keep stds writing and interworking testing all together so\nthe two do not lose synchronization.\n\nIf one wishes to rename ssl-talk to be \"tls-talk\" for market confusion\nabatement reasons, then,  just do it. Keep ssl-talk id around for a while\nwhilst list members changeover.\n\n \n\n \n\n\n\n"
        },
        {
            "subject": "Implementation of Shared Key Authenticatio",
            "content": "Ref:  Your note of Mon, 2 Dec 1996 12:16:29 -0800\n\nDan, Tom,\n\nI hope you read my previous message on how I'd like to see MAC functions\nhandled in SSL.\nI'd recommend that you adopt these changes already now into your shared-key\nproposal (to preclude future  backward compatibility problems).\nThis includes changing to a generic MAC definition and implementing it with\nthe \"official\" HMAC as the default transform.\n\nThe text affected by such a change would be:\n\n> SharedKeyVerify.shared_key_response\n>      hash (auth_write_secret + pad_2 +\n>             hash (auth_write_secret + pad_1 + hash (handshake_messages)\n>\n>                   + SharedKeyVerify.auth_service.auth_service_name\n>                   + SharedKeyVerify.auth_service.display_string\n>                   + SharedKeyVerify.auth_service.challenge\n>                   + SharedKeyVerify.identity + shared_key) )\n\nIt should be re-written using a generic MAC (which could be implemented as\nHMAC or any other MAC).\n\nThe problem is then how to combine in general the two keys\nauth_write_secret and shared_key into the generic MAC.\n\nThe two possibilities that come to my mind are: XOR the two keys (or hash\nthem together, etc.) to create one single MAC key or (as you do now) append\nthe shared_key to the MAC-ed text.\nThat is:\n\n1) SharedKeyVerify.shared_key_response\n        MAC(auth_write_secret XOR shared_key, data)\n\nwhere data = hash (handshake_messages)\n                    + SharedKeyVerify.auth_service.auth_service_name\n                    + SharedKeyVerify.auth_service.display_string\n                    + SharedKeyVerify.auth_service.challenge\n                    + SharedKeyVerify.identity\n\n2) SharedKeyVerify.shared_key_response\n        MAC(auth_write_secret, data + shared_key)\n\n\nIn the first case one would be assuming that the MAC function\nuses random (unstructured) strings as keys (which is the usual case).\nIn the second case this assumption is not needed but instead you will be\nassuming that the MAC does not leak information on its output. The latter is\nnot a common assumption on MAC functions. It would require the assumption\nthat the MAC behaves as a  \"pseudorandom function\" which is a stronger\nassumption. (In particular, I trust more HMAC as a MAC than as a pseudorandom\nfunction).\nAs for later solution notice that once MAC is implemented as HMAC\nthen the function will be the same as you use now (except for the changes\nthat you need to comply with the \"official\" HMAC, ie, XOR of pads instead of\nconcatenation).\n\nThere is a third solution:\n\nIf you assume MAC to be pseudorandom (as is needed in solution (2))\nthen you could do the following\n\n3) SharedKeyVerify.shared_key_response\n        MAC(temp_key, shared_key)\n\nwhere temp_key=MAC(auth_write_secret, data)\n\nOne potential advantage of this method is that in pass-through authentication\nthe (SSL) server needs to pass to the authentication server only the\nvalue of temp_key and not of auth_write_secret which the server may want to\nkeep secret only between itself and the client. I don't know how important\nthis may be in actual uses but sounds as a good \"key separation\" property.\n\nHugo\n\nPS: even if you do not want to go at this point to a generic MAC definition\nI recommend that you already switch to the official HMAC and consider\ndoing (1) or (3).\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "After looking at the suggested changes, I'd categorize them as follows.\n\nThese entail changes to the protocol:\n\n>         1. MAC algorithm\n>         2. MAC contents\n>         7. Additional alerts\n>         9. Additional Record Protocol clients\n\nThese are just clarifications, or restructuring of the document:\n\n>         3. Block padding\n>         4. Message order standardization\n>         5. Certificate chain contents\n>         6. The no_certificate alert\n>         8. Seperation of Record and Handshake layers\n\nAt this point, I'd be unhappy with any changes to the protocol, although\n7 and 9 don't appear to be very damaging to existing implementations.\nI think that any changes we make to the protocol must be looked at very\nclosely.\n\nIf we are actually going to consider protocol changes at this time, or\nfor the future, I'd also suggest a generalization of the block padding\nformat.  I'd specify that blocks be padded with random data, and that\nthat all blocks have (possibly zero-length) padding.  I'd also relax\nrestriction on maximum padding length.  This would make it harder to\nperform a traffic analysis attack, but still allow implementations to\nforgo the padding if so desired.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "I-D ACTION:draft-ietf-tls-protocol00.tx",
            "content": " A New Internet-Draft is available from the on-line Internet-Drafts \n directories. This draft is a work item of the Transport Layer Security \n Working Group of the IETF.                                                \n\n       Title     : The TLS Protocol                                        \n       Author(s) : A. Freier, P. Karlton, P. Kocher, T. Dierks\n       Filename  : draft-ietf-tls-protocol-00.txt\n       Pages     : 66\n       Date      : 12/02/1996\n\nThis document specifies Version 1.0 of the Transport Layer Security (TLS) \nprotocol, which is at this stage is strictly based on the Secure Sockets \nLayer (SSL) version 3.0 protocol, and is to serve as a basis for future \ndiscussions. The TLS protocol provides communications privacy over the \nInternet. The protocol allows client/server applications to communicate in \na way that is designed to prevent eavesdropping, tampering, or message \nforgery.                                                                   \n\nInternet-Drafts are available by anonymous FTP.  Login with the username\n\"anonymous\" and a password of your e-mail address.  After logging in,\ntype \"cd internet-drafts\" and then\n     \"get draft-ietf-tls-protocol-00.txt\".\nA URL for the Internet-Draft is:\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-protocol-00.txt\n \nInternet-Drafts directories are located at:\n                                                \n     o  Africa:  ftp.is.co.za                    \n                                                \n     o  Europe:  nic.nordu.net            \n                 ftp.nis.garr.it                 \n                                                \n     o  Pacific Rim: munnari.oz.au               \n                                                \n     o  US East Coast: ds.internic.net           \n                                                \n     o  US West Coast: ftp.isi.edu               \n                                                \nInternet-Drafts are also available by mail.\n                                                \nSend a message to:  mailserv@ds.internic.net. In the body type: \n     \"FILE /internet-drafts/draft-ietf-tls-protocol-00.txt\".\n\nNOTE: The mail server at ds.internic.net can return the document in\n      MIME-encoded form by using the \"mpack\" utility.  To use this\n      feature, insert the command \"ENCODING mime\" before the \"FILE\"\n      command.  To decode the response(s), you will need \"munpack\" or\n      a MIME-compliant mail reader.  Different MIME-compliant mail readers\n      exhibit different behavior, especially when dealing with\n      \"multipart\" MIME messages (i.e., documents which have been split\n      up into multiple messages), so check your local documentation on\n      how to manipulate these messages.\n\n\n\nBelow is the data which will enable a MIME compliant mail reader \nimplementation to automatically retrieve the ASCII version\nof the Internet-Draft.\n\n\n\n\n\nMessage/External-body attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "At 11:17 AM -0800 12/2/96, Phil Karlton wrote:\n>> From Christopher Allen <ChristopherA@consensus.com>\n>\n>> The short outline of \"tls-changes\" is:\n>>\n>>         1. MAC algorithm\n>>         2. MAC contents\n>>         3. Block padding\n>>         4. Message order standardization\n>>         5. Certificate chain contents\n>>         6. The no_certificate alert\n>>         7. Additional alerts\n>>         8. Seperation of Record and Handshake layers\n>>         9. Additional Record Protocol clients\n>\n>I strongly recommend that these be separated into 2 parts: those that\n>force a change the current protocol (bits on the wire), and those that\n>are clarifications of current practice.\n>\n>In particular points 1., 2., and 6. above would make all current\n>implementations non-conforming. Do we have examples of interoperability\n>between the proposed protocol and existing implementations? Would the\n>version number be rolled forward?\n>\n>I suspect that those at the meeting will want to treat these proposals\n>independently.\n\nIt was my understanding that the TLS working group has reached consensus\nthat we intended to standardize a new protocol based on SSL. I have always\ntaken this to mean that this would, in fact, be a new protocol, not just an\nIETF rubber-stamp of a Netscape protocol. As such, I believe we've already\ndecided that changing the bits on the wire is within our intent. Certainly\nissues like standardizing the MAC have always been discussed as an obvious,\nsimple, and reasonable step for the SSL to TLS transition\n\nAlso, I believe that items 3, 4, 9, and maybe 7 also imply changes to the\nacceptable bits on the wire in the SSL protocol, because it's my belief\nthat cryptographic protocols must wherever possible check to make sure that\nthe other side is conformant, because a failure to conform may cause a\nsecurity failure which would otherwise be undetected. As such, I believe\nthat a conformant TLS implementation (if the above proposals were adopted)\nwould:\n  - Check to make sure blocks are padded correctly\n  - Ensure that messages arrived in the prescribed order\n  - Not accept unknown record types or alerts.\n\nIn addition, I believe number 5 requires a change to the bits on the wire\nbecause it continues to be my stance that the SSL protocol as standardized\nrequires complete certificate chains to be transmitted, regardless of\nactual implementation behavior or revisionist modifications to the standard\ndocument. As such, I believe that to transmit partial certificate chains\n(as described in proposal item 5) is to be incompliant with the SSL 3.0\nprotocol (although you'll happily interoperate with many SSL 3.0\nimplementations).\n\nIn summary, I believe it is the charter and intent of the TLS working group\nto standardize a protocol which involves changes to the bits on the wire\nand that all the proposals above except for number 8 describe some change\nto the legal and compliant bits on the wire. (Although some SSL\nimplementations may be flexible enough to allow communication with TLS\nimplementation on some items.)\n\nOf course, in my role as editor I'm more than willing to describe in the\nstandard whatever the consensus of the working group is, even if it is\nsimply to standardize the SSL protocol (which is what the current contents\nof the TLS internet draft is intended to represent).\n\n - Tim\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "At 4:26 PM -0800 12/2/96, Tom Weinstein wrote:\n>If we are actually going to consider protocol changes at this time, or\n>for the future, I'd also suggest a generalization of the block padding\n>format.  I'd specify that blocks be padded with random data, and that\n>that all blocks have (possibly zero-length) padding.  I'd also relax\n>restriction on maximum padding length.  This would make it harder to\n>perform a traffic analysis attack, but still allow implementations to\n>forgo the padding if so desired.\n\nI think this is a good suggestion, except that I would specify the contents\nof the block data rather than using random data. I don't believe that\nrandom data adds significantly to the security of the protocol, as any\nsignificant communication will be well beyond the unicity distance; thus,\nthe verifiable plaintext of the padding won't aid attackers. The benefit of\nusing predictable data is that the peer can verify that padding is being\ndone as expected, which allows a greater rigidity around implementations,\nwhich I believe aids security analysis.\n\nIf you'd like to avoid the padding data being known plaintext, you could\nspecify it in some what that it is unknown, yet verifiable. However, the\nprotocol should be strong against known-plaintext attacks anyway, as such\nattacks are commonly available to attackers.\n\n - Tim\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "TLS draft &amp; TLS proposal",
            "content": "[I do not want to conduct TLS discussion in SSL-talk if possible; please\ntrim SSL-talk from any followups].\n\nIt was suggested to me that I quickly summarize the content and intent of\nthe two TLS drafts I submitted for San Jose.\n\nThe TLS protocol draft (draft-ietf-tls-protocol-00.txt) is intended to be\nan edit of the SSL 3.0 protocol document to ready it for IETF\nstandardization. In addition, I rearranged some stuff and clarified a few\nthings that I know I had found confusing. In comparison to the recent SSL\ndraft submitted by Tom Weinstein at Netscape\n(draft-ietf-tls-ssl-version3-00.txt), I think the following changes are\nmost significant:\n - Introduced more seperation and formal interface between the handshaking\nprocess and the record layer, with the intent of enabling TLS to\nstandardize these two parts as different but related protocols.\n - Removed all references to Fortezza, as it is considered inappropriate\nfor IETF standards. Instead, inserted language about how to add key\nexchange methods; then, an informational RFC can be generated to describe\nTLS Fortezza key exchange.\n - Fixed a definition problem in anonymous server key exchange messages\nwhose fix didn't make it into Tom's draft.\n - Changed SSL to TLS throughout.\n - Wrote some additional descriptive text.\n\nThe document is still very much based on the Netscape document. It is my\nintent and belief that this document describes the same protocol as the SSL\ndocument: i.e., the bits on the wire and their correct interpretation have\nnot changed.\n\nThe changes draft (draft-ietf-tls-ssl-mods-00.txt) describes nine technical\nmodifications I propose to the SSL protocol before standardization as TLS.\nThese were selected as changes which I hope are non-controversial. They\nprimarily have to do with streamlining the cryptography, implementation, or\ndocumentation of the protocol; they do not introduce any significant new\nfeatures or behaviour. Specifically, I did not describe the mine fields of\npassword authentication, pre-encrypted data, or attribute certificates.\n\nIt is my hope that we can quickly reach consensus on these proposals and\nany other similar ones, then describe how any additional features might be\nlayered on top of the protocol as described, then come to a decision on\nwhich, if any, of those proposals will be incorporated into the standard.\n\n - Tim\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "One more protocol issue ... I've never seen an explanation about why\nthe \"change cipher spec\" record is necessary.  It seems like all that's\nneeded is the ability to flush the handshake messages which have been\nqueued, since I don't see any cases where the next legal handshake\nmessage isn't predictable from the current protocol state.\n\nIs \"change cipher spec\" as a record type an artifact of some early SSL\nimplementation, which might be removed in a \"new protocol based on the\nSSL 3.0 specification\"?\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "Minor correction (it's late); sorry ...\n\n> From david.brownell@Eng Tue Dec  3 01:28:23 1996\n> Resent-Date: Tue, 3 Dec 1996 04:27:26 -0500\n> Date: Tue, 3 Dec 1996 01:24:24 -0800\n> From: david.brownell@Eng (David Brownell - JavaSoft)\n> To: ietf-tls@w3.org\n> Subject: Re: draft agenda for San Jose meeting\n> Cc: satishd@doppio.eng.sun.com\n> X-List-URL: http://lists.w3.org/Archives/Public/ietf-tls\n> \n> One more protocol issue ... I've never seen an explanation about why\n> the \"change cipher spec\" record is necessary.  It seems like all that's\n> needed is the ability to flush the handshake messages which have been\n> queued, since I don't see any cases where the next legal handshake\n> message isn't predictable from the current protocol state.\n\nMore like:  \"I don't see any cases where you won't know that the\nnext handshake message from the peer must be 'Finished', even without\nthis 'change cipher spec' message.\"\n\n\n> Is \"change cipher spec\" as a record type an artifact of some early SSL\n> implementation, which might be removed in a \"new protocol based on the\n> SSL 3.0 specification\"?\n> \n> - Dave\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": ">I'm just looking for some clarification.\n>- Is it the intention to move SSL 3.0 into TLS 1.0 \"as is\", with\n>clarifications to the spec?\n\nThe intent is to consider some small changes to SSL 3.0 that\nthe working group believes will improve the TLS protocol.\n\n>- Is the hour of presentation and discussion meant for clarifying the\n>ambiguities in SSL 3.0 that Chris Allen mentioned in an earlier message,\n>also, does this include discussion about splitting the SSL spec into\n>separate specification documents?\n\nThe first hour is intended to cover the proposed clarifications and\nthe \"small\" changes.  My sense is that the first TLS spec would not\nbe separate documents, because disentangling things will take a fair\nbit of time.\n\n>- Does this mean that all decisions regarding draft proposals (Netscape's\n>authority attributes, Microsoft's passphrase authentication, CyberSafe's\n>Kerberos cipher suites, etc.) will be postponed until the next meeting of\n>the IETF?\n\nBased on the discussion so far, I think that the working group is far from\nconsensus on those changes, so I don't expect final decisions to be made\nin San Jose. We can make decisions on the mailing list before the next\nmeeting, however, and I hope we can make some good progress between\nthe meetings.\n\n- Win Treese\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "I think there are enough proposed changes on the table to\nlook at some of the smaller ones for the first TLS specification,\nand that's the focus of what Tim and Chris proposed. The\nworking group needs to consider each item to decide whether\nor not it goes into the first TLS spec.\n\n- Win Treese\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "David Brownell - JavaSoft writes:\n> \n> Minor correction (it's late); sorry ...\n> \n> > One more protocol issue ... I've never seen an explanation about why\n> > the \"change cipher spec\" record is necessary.  It seems like all that's\n> > needed is the ability to flush the handshake messages which have been\n> > queued, since I don't see any cases where the next legal handshake\n> > message isn't predictable from the current protocol state.\n> \n> More like:  \"I don't see any cases where you won't know that the\n> next handshake message from the peer must be 'Finished', even without\n> this 'change cipher spec' message.\"\n\nOn the client side when setting up a new session (rather than\ncontinuing an existing one) the handshake message before the Finished\ncould be a ClientKeyExchange, or a CertificateVerify if the\nclient was asked to authenticate itself.\n\n\nHowever the changeCipherSpec message is there, and is an alert\nrather than a handshake message, in order to make better seperation\nbetween the record layer (which has to know about the change)\nand the handshake layer above it.\n\nTheoretically you could invent a new handshake protocol, and the\nunderlying record layer wouldn't care (and the code wouldn't have to\nbe changed) as long as your new handshake included changeCipherSpecs\nat the appropriate time.\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "> > More like:  \"I don't see any cases where you won't know that the\n> > next handshake message from the peer must be 'Finished', even without\n> > this 'change cipher spec' message.\"\n> \n> On the client side when setting up a new session (rather than\n> continuing an existing one) the handshake message before the Finished\n> could be a ClientKeyExchange, or a CertificateVerify if the\n> client was asked to authenticate itself.\n\nThe ClientKeyExchange is always sent.  CertVerify will only be seen if\nthere was a Certificate message.  The server knows if it's going to get a\nCertVerify or a Finished handshake message next.  When it expects a\nFinished message next, it can enable the record-level behaviour which is\nnow triggered by receipt of change_cipher_spec ... triggering it by recipt\nof the next handshake message instead.\n\n\n> However the changeCipherSpec message is there, and is an alert\n> rather than a handshake message, in order to make better seperation\n> between the record layer (which has to know about the change)\n> and the handshake layer above it.\n\nActually it's a new record type.  I can't buy this argument; some\ndegree of linkage between the handshake and record modules needs\nto exist in any case (to tell about the change), but I can see no\nreason that implementation details of this linkage need to creep\ninto the protocol.\n\n\n> Theoretically you could invent a new handshake protocol, and the\n> underlying record layer wouldn't care (and the code wouldn't have to\n> be changed) as long as your new handshake included changeCipherSpecs\n> at the appropriate time.\n\nThis is a more interesting kind of claim to make.  But there was a\nrecent comment (Christopher Allen?) about the probably desirability\nof making the handshake state machine fully specified, with which I\nbasically agree.  I think it'd be reasonable to require such new\nhandshake protocols to be fully specified w.r.t. the point at which\ncipher specs change, like the current handshake protocol.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "David Brownell - JavaSoft writes:\n \n \n>  The server knows if it's going to get a\n> CertVerify or a Finished handshake message next.  When it expects a\n> Finished message next, it can enable the record-level behaviour which is\n> now triggered by receipt of change_cipher_spec ... triggering it by recipt\n> of the next handshake message instead.\n\nThis works with the current set of handshake messages.  But if\nthe messages are changed so that the arrival of the Finished\nmessage is not predictable, or the Finished message isn't the\nfirst one to be encrypted under the newly-negotiated session, then\nit wouldn't work.\n\nIt also requires a way to call into the record layer from the\nhandshake layer to tell the record layer to switch to the new\nsession.  That's no problem in most current SSL implementations but\nmight not be so easy in one that keeps the record layer and the\nhandshake layer more seperate.\n\n\n> > Theoretically you could invent a new handshake protocol, and the\n> > underlying record layer wouldn't care (and the code wouldn't have to\n> > be changed) as long as your new handshake included changeCipherSpecs\n> > at the appropriate time.\n> \n> This is a more interesting kind of claim to make.  But there was a\n> recent comment (Christopher Allen?) about the probably desirability\n> of making the handshake state machine fully specified, with which I\n> basically agree.  I think it'd be reasonable to require such new\n> handshake protocols to be fully specified w.r.t. the point at which\n> cipher specs change, like the current handshake protocol.\n\nYep, I agree.  However I could see having a TLS implementation\nthat can use either of two (or more) different handshake protocols, with\nthe same record layer underneath (in fact at one point I was prepared to do\nthis for PCT).  The record layer would decide, based on the initial\nmessage, which handshake type was being used.  I think that the\nchangeCipherSpec makes this a bit easier, and we should keep\nit, especially if the handshake and record specs are split into\ntwo standards as has been proposed.\n\n\nI don't think it's that big a deal though.  If changeCipherSpec went\naway, implementations would be a little uglier and it'd be a little\nmore difficult to seperate the handshake and record layers, but it\nwouldn't be impossible.\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "> > This is a more interesting kind of claim to make.  But there was a\n> > recent comment (Christopher Allen?) about the probably desirability\n> > of making the handshake state machine fully specified, with which I\n> > basically agree.  I think it'd be reasonable to require such new\n> > handshake protocols to be fully specified w.r.t. the point at which\n> > cipher specs change, like the current handshake protocol.\n> \n> Yep, I agree.  However I could see having a TLS implementation\n> that can use either of two (or more) different handshake protocols, with\n> the same record layer underneath (in fact at one point I was prepared to do\n> this for PCT).  The record layer would decide, based on the initial\n> message, which handshake type was being used.  I think that the\n> changeCipherSpec makes this a bit easier, and we should keep\n> it, especially if the handshake and record specs are split into\n> two standards as has been proposed.\n\nIf those handshake protocols are well specified in the way I suggested,\nthen having multiple such protocols would never be a problem.\n\n\n> I don't think it's that big a deal though.  If changeCipherSpec went\n> away, implementations would be a little uglier and it'd be a little\n> more difficult to seperate the handshake and record layers, but it\n> wouldn't be impossible.\n\nThey're already closely related; I can't see new ugliness coming in.\n\nCode related to change_cipher_spec gets removed, and the existing\nhook in the record layer (triggered by receipt of change_cipher_spec,\nwhen conditions are right) gets triggered by receipt of a different\nmessage (again, if conditions are right).\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "The message and record type for ChangeCypherSpec were added to keep the\nlayering consistant between the client and server and to support the\nnotion of pipelining protocols.\n\nIt may seem like extraneous overhead, but it really does serve to\npreserve the layering.\n\nAO\n-- \nAlan O. FreierCorporate Cynic\n<freier@netscape.com>(415) 937-3638 (work)\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "David Brownell - JavaSoft wrote:\n> \n> One more protocol issue ... I've never seen an explanation about why\n> the \"change cipher spec\" record is necessary.  It seems like all\n> that's needed is the ability to flush the handshake messages which\n> have been queued, since I don't see any cases where the next legal\n> handshake message isn't predictable from the current protocol state.\n> \n> Is \"change cipher spec\" as a record type an artifact of some early SSL\n> implementation, which might be removed in a \"new protocol based on the\n> SSL 3.0 specification\"?\n\nIt's there as an explicit indicator of the change.  Yes, it would be\npossible to make it implicit, but for protocol purity reasons, we don't\nlike implicit things, especially state changes.  The fact that it's a\ndifferent record type instead of a handshake message is just a way of\nmaking sure that someone can't send it in the middle of a handshake\nrecord.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "> It may seem like extraneous overhead, but it really does serve to\n> preserve the layering.\n\nI'd like to hear more about this, perhaps offline.  I really do\nfail to see how this improves layering.  A particular behaviour\nis triggered when several conditions (knowable only to the\nhandshake layer, until it tells another layer) are satisfied,\nand a particular meessage comes in.  I'm commenting that the\nparticular message seems strange.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "> > It may seem like extraneous overhead, but it really does serve to\n> > preserve the layering.\n> \n> I'd like to hear more about this, perhaps offline. \nI'd like to hear more about this as well:\nI also find this layering argument confusing. \n\nThis seems like a topic of sufficiently general interest to\nkeep it on the list.\n\n-Ekr\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "Note that one purpose of the change cypher spec command was to allow the\ncypher used for the SSL session to change depending upon content.  For\nexample,the administrator could choose to protect one directory with one\ngrade of security and another with some other form of security.  The\nvalue of such a feature can certainly be debated, but I just wanted to\npoint out that I think this was one objective.\nRegards,\nEridc\n\nDavid Brownell - JavaSoft wrote:\n> \n> > > This is a more interesting kind of claim to make.  But there was a\n> > > recent comment (Christopher Allen?) about the probably desirability\n> > > of making the handshake state machine fully specified, with which I\n> > > basically agree.  I think it'd be reasonable to require such new\n> > > handshake protocols to be fully specified w.r.t. the point at which\n> > > cipher specs change, like the current handshake protocol.\n> >\n> > Yep, I agree.  However I could see having a TLS implementation\n> > that can use either of two (or more) different handshake protocols, with\n> > the same record layer underneath (in fact at one point I was prepared to do\n> > this for PCT).  The record layer would decide, based on the initial\n> > message, which handshake type was being used.  I think that the\n> > changeCipherSpec makes this a bit easier, and we should keep\n> > it, especially if the handshake and record specs are split into\n> > two standards as has been proposed.\n> \n> If those handshake protocols are well specified in the way I suggested,\n> then having multiple such protocols would never be a problem.\n> \n> > I don't think it's that big a deal though.  If changeCipherSpec went\n> > away, implementations would be a little uglier and it'd be a little\n> > more difficult to seperate the handshake and record layers, but it\n> > wouldn't be impossible.\n> \n> They're already closely related; I can't see new ugliness coming in.\n> \n> Code related to change_cipher_spec gets removed, and the existing\n> hook in the record layer (triggered by receipt of change_cipher_spec,\n> when conditions are right) gets triggered by receipt of a different\n> message (again, if conditions are right).\n> \n> - Dave\n\n-- \nEric Greenberg, Security Product Management\nNetscape Communications Corp.\nericg@netscape.com  \n-- \"speakin for just me and no one else\" --\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "David Brownell - JavaSoft wrote:\n> \n> One more protocol issue ... I've never seen an explanation about why\n> the \"change cipher spec\" record is necessary.  It seems like all that's\n> needed is the ability to flush the handshake messages which have been\n> queued, since I don't see any cases where the next legal handshake\n> message isn't predictable from the current protocol state.\n> \n> Is \"change cipher spec\" as a record type an artifact of some early SSL\n> implementation, which might be removed in a \"new protocol based on the\n> SSL 3.0 specification\"?\n\nIt's there for 2 reasons.\n\n1) Hardware implementations.\n\nImagine a pipelined implementation of a TLS protocol engine (record\ngathering, decompression, decryption). At the point that a cipher spec\nchanges, the pipeline must be stalled/flushed so that the new ciphers\nand keys can be loaded (potentially in parallel) into that engine.\n\nIt is very convenient for there to be a simple test for the hardware to\nmake to know to do that stall (as opposed to having to understand the\nsemantics of the protocol).\n\n2) Future extensibility.\n\nHandshake protocols have been proposed (and I strongly suspect will be\nproposed in the future) where some of the handshake messages will have\nto be encrypted for security reasons. Having an explicit marker makes\nimplementations and analysis easier.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://www.netscape.com/people/karlton\nNetscape Communications Corporation\n\n    Everything should be made as simple as possible, but not simpler.\n-- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "David Brownell - JavaSoft wrote:\n\n> A particular behaviour\n> is triggered when several conditions (knowable only to the\n> handshake layer, until it tells another layer) are satisfied,\n> and a particular meessage comes in. \n\nThe point is to be able to have the condition be knowable outside the\nhandshake layer.\n\nIt is incumbent upon the handshake layer implementation to verify that\nthe underlying engine went through the transition at the point that the\nhandshake layer expected it to. That still does not make it a handshake\nlayer condition.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://www.netscape.com/people/karlton\nNetscape Communications Corporation\n\n    Everything should be made as simple as possible, but not simpler.\n-- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "Phil Karlton wrote:\n> \n> David Brownell - JavaSoft wrote:\n> >\n> > One more protocol issue ... I've never seen an explanation about why\n> > the \"change cipher spec\" record is necessary.  It seems like all that's\n> > needed is the ability to flush the handshake messages which have been\n> > queued, since I don't see any cases where the next legal handshake\n> > message isn't predictable from the current protocol state.\n> >\n> > Is \"change cipher spec\" as a record type an artifact of some early SSL\n> > implementation, which might be removed in a \"new protocol based on the\n> > SSL 3.0 specification\"?\n> \n> It's there for 2 reasons.\n> \n> 1) Hardware implementations.\n> \n> Imagine a pipelined implementation of a TLS protocol engine (record\n> gathering, decompression, decryption). At the point that a cipher spec\n> changes, the pipeline must be stalled/flushed so that the new ciphers\n> and keys can be loaded (potentially in parallel) into that engine.\n> \n> It is very convenient for there to be a simple test for the hardware to\n> make to know to do that stall (as opposed to having to understand the\n> semantics of the protocol).\n> \n> 2) Future extensibility.\n> \n> Handshake protocols have been proposed (and I strongly suspect will be\n> proposed in the future) where some of the handshake messages will have\n> to be encrypted for security reasons. Having an explicit marker makes\n> implementations and analysis easier.\n> \n> PK\n> --\n> Philip L. Karlton               karlton@netscape.com\n> Principal Curmudgeon            http://www.netscape.com/people/karlton\n> Netscape Communications Corporation\n> \n>     Everything should be made as simple as possible, but not simpler.\n>         -- Albert Einstein\n\n  Phil and all,\n\n  I will not be able to attend this meeting, but was wondering if \nmin's. will be posted as to what was discussed and conclusions and\nor dicisions that were decided on.  This would be helpful to all that\nare not able to attend I would think.  Please advise.\n\nRegards,\n \n\n-- \nJeffrey A. Williams\nDIR. Internet Network Eng/SR. Java Development Eng.\nInformation Eng. Group. \nPhone :972-447-1904\nE-Mail jwkckid1@ix.netcom.com\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "Phil Karlton wrote:\n> \n> David Brownell - JavaSoft wrote:\n> \n> > A particular behaviour\n> > is triggered when several conditions (knowable only to the\n> > handshake layer, until it tells another layer) are satisfied,\n> > and a particular meessage comes in.\n> \n> The point is to be able to have the condition be knowable outside the\n> handshake layer.\n> \n> It is incumbent upon the handshake layer implementation to verify that\n> the underlying engine went through the transition at the point that the\n> handshake layer expected it to. That still does not make it a handshake\n> layer condition.\n\nPhil,\n\n  I assume from what you are saying than is that the verification is\na intragal part of the method of implementation corresponding to the\n\"Underlying engine\" to provide the necessary transition at the proper\npoint?  Is that correct?  If so, than it would seem to me you are\nright here, but I also think this could be made easier or, shall we \nsay, more elegant if that could be done as part of the handshake\nlayer itself.  Don't you think?\n\nRegards,\n\n-- \nJeffrey A. Williams\nDIR. Internet Network Eng/SR. Java Development Eng.\nInformation Eng. Group. \nPhone :972-447-1904\nE-Mail jwkckid1@ix.netcom.com\n\n\n\n"
        },
        {
            "subject": "RE: Implementation of Shared Key Authenticatio",
            "content": "Hugo:  Thanks for the free advice!  (I certainly *hope* it's free....)\nAll of your recommendations make sense, but we would obviously prefer\nthat our extensions for shared key authentication conform as closely as\npossible to the main body of the TLS spec, to avoid confusion and ease\nimplementation.  Hence, if your suggestions regarding MAC and PRF as\nprimitives (as well as the corrections to the HMAC primitive) are\nadopted in the TLS spec as a whole (an excellent idea that we strongly\nsupport), then we will revise our shared key authentication draft\naccordingly.\n\nRegarding the adaptation of the shared-key authentication response to\nthe new primitives (assuming that they are adopted), it appears to me\nthat if a PRF primitive is defined, the natural approach would be simply\nto define the authentication response as PRF(auth_write_key, data +\nshared_key), thus achieving both the MAC property and concealment of the\nshared key (assuming a good PRF).  Of course, if the PRF primitive does\nnot get incorporated into the spec, then I suppose the simplest solution\nwould be to treat HMAC/SHA-1 as an implicit PRF, which gives us your\nsolution (2) (which happens to be--in content, if not in form--identical\nto the currently specified format).\n\nRegarding solution (3), one of the reasons for generating a separate\n\"auth_write_key\" was that such a key, used for only one purpose, would\nbe safe to reveal to the authentication service.  Hence, the separation\nidea you suggest may be redundant.  Solution (1), on the other hand, is\nmuch more interesting, since it reduces the strength of the assumption\nrequired from the MAC function, as you point out.  I'm currently\nchecking into some implementability details, and if there are no\nproblems, we'll look at incorporating this revision as well, in the case\nwhere the PRF primitive isn't incorporated into TLS.\n\nComments, anyone?\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)\n\n>----------\n>From: HUGO@watson.ibm.com[SMTP:HUGO@watson.ibm.com]\n>Sent: Monday, December 02, 1996 4:06 PM\n>To: Tom Stephens; Dan Simon; ietf-tls@w3.org\n>Subject: Implementation of Shared Key Authentication\n>\n>Ref:  Your note of Mon, 2 Dec 1996 12:16:29 -0800\n>\n>Dan, Tom,\n>\n>I hope you read my previous message on how I'd like to see MAC functions\n>handled in SSL.\n>I'd recommend that you adopt these changes already now into your shared-key\n>proposal (to preclude future  backward compatibility problems).\n>This includes changing to a generic MAC definition and implementing it with\n>the \"official\" HMAC as the default transform.\n>\n>The text affected by such a change would be:\n>\n>> SharedKeyVerify.shared_key_response\n>>      hash (auth_write_secret + pad_2 +\n>>             hash (auth_write_secret + pad_1 + hash (handshake_messages)\n>>\n>>                   + SharedKeyVerify.auth_service.auth_service_name\n>>                   + SharedKeyVerify.auth_service.display_string\n>>                   + SharedKeyVerify.auth_service.challenge\n>>                   + SharedKeyVerify.identity + shared_key) )\n>\n>It should be re-written using a generic MAC (which could be implemented as\n>HMAC or any other MAC).\n>\n>The problem is then how to combine in general the two keys\n>auth_write_secret and shared_key into the generic MAC.\n>\n>The two possibilities that come to my mind are: XOR the two keys (or hash\n>them together, etc.) to create one single MAC key or (as you do now) append\n>the shared_key to the MAC-ed text.\n>That is:\n>\n>1) SharedKeyVerify.shared_key_response\n>        MAC(auth_write_secret XOR shared_key, data)\n>\n>where data = hash (handshake_messages)\n>                    + SharedKeyVerify.auth_service.auth_service_name\n>                    + SharedKeyVerify.auth_service.display_string\n>                    + SharedKeyVerify.auth_service.challenge\n>                    + SharedKeyVerify.identity\n>\n>2) SharedKeyVerify.shared_key_response\n>        MAC(auth_write_secret, data + shared_key)\n>\n>\n>In the first case one would be assuming that the MAC function\n>uses random (unstructured) strings as keys (which is the usual case).\n>In the second case this assumption is not needed but instead you will be\n>assuming that the MAC does not leak information on its output. The latter is\n>not a common assumption on MAC functions. It would require the assumption\n>that the MAC behaves as a  \"pseudorandom function\" which is a stronger\n>assumption. (In particular, I trust more HMAC as a MAC than as a pseudorandom\n>function).\n>As for later solution notice that once MAC is implemented as HMAC\n>then the function will be the same as you use now (except for the changes\n>that you need to comply with the \"official\" HMAC, ie, XOR of pads instead of\n>concatenation).\n>\n>There is a third solution:\n>\n>If you assume MAC to be pseudorandom (as is needed in solution (2))\n>then you could do the following\n>\n>3) SharedKeyVerify.shared_key_response\n>        MAC(temp_key, shared_key)\n>\n>where temp_key=MAC(auth_write_secret, data)\n>\n>One potential advantage of this method is that in pass-through authentication\n>the (SSL) server needs to pass to the authentication server only the\n>value of temp_key and not of auth_write_secret which the server may want to\n>keep secret only between itself and the client. I don't know how important\n>this may be in actual uses but sounds as a good \"key separation\" property.\n>\n>Hugo\n>\n>PS: even if you do not want to go at this point to a generic MAC definition\n>I recommend that you already switch to the official HMAC and consider\n>doing (1) or (3).\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was: draft agenda",
            "content": "Eric Greenberg wrote:\n> \n> Note that one purpose of the change cypher spec command was to allow\n> the cypher used for the SSL session to change depending upon content. \n> For example,the administrator could choose to protect one directory\n> with one grade of security and another with some other form of\n> security.  The value of such a feature can certainly be debated, but I\n> just wanted to point out that I think this was one objective.\n\nUm, I think you might be thinking of the ability to renegotiate the\nhandshake midstream.  This has nothing to do with the change cipher\nspec message.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was:  draft agenda",
            "content": "Phil,\n\nThanks for the first answer that really makes sense!  :-)\n\n\n> > Is \"change cipher spec\" as a record type an artifact of some early SSL\n> > implementation, which might be removed in a \"new protocol based on the\n> > SSL 3.0 specification\"?\n> \n> It's there for 2 reasons.\n> \n> 1) Hardware implementations.\n\nThis seems to me like it's the most solid argument.  Are there really\nhardware implementations under way?  Intriguing.\n\n\n> Imagine a pipelined implementation of a TLS protocol engine (record\n> gathering, decompression, decryption). At the point that a cipher spec\n> changes, the pipeline must be stalled/flushed so that the new ciphers\n> and keys can be loaded (potentially in parallel) into that engine.\n> \n> It is very convenient for there to be a simple test for the hardware to\n> make to know to do that stall (as opposed to having to understand the\n> semantics of the protocol).\n\nTo restate this point ... you're saying that the hardware needs to have\na simply specified synchronization point where it can stall until ciphers,\nkeys, and compression algorithms are specified by the handshake engine.\n(Which I'll assume is implemented in software.)\n\nThe approach I'd suggested relied on the fact that software isn't often\ngoing to operate concurrently at that fine a granularity, so one could\nrely on an \"implicit stall\" ... the event/message which arrived to\nsignal \"time to change ciphers/keys\" wouldn't be detected until the\npreceding message was fully processed.\n\n\n> > A particular behaviour\n> > is triggered when several conditions (knowable only to the\n> > handshake layer, until it tells another layer) are satisfied,\n> > and a particular meessage comes in. \n> \n> The point is to be able to have the condition be knowable outside the\n> handshake layer.\n\nI was talking about the \"READY to change cipher state\" condition,\nwhich won't be known outside the handshake layer unless some other\nlayer (record?) understands the handshake protocol. The hardware\nwouldn't itself be ready until it knew the keys and algorithms to\nuse on the next set of records -- it'd stall until they were known.\nThen the record layer can decrypt the next message (\"Finished\") etc.\n\n\n> It is incumbent upon the handshake layer implementation to verify that\n> the underlying engine went through the transition at the point that the\n> handshake layer expected it to. That still does not make it a handshake\n> layer condition.\n\nBut the underlying engine can't go through that transition without\naccess to the crypto keys, so it can't do the transition until it's\ntold by the handshake layer \"here are the cipher and keys\".\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Wagner and Schneie",
            "content": "Pardon my ignorance, I haven't read the documents. Two\nquestions. \n* Is TLS subject to the same problems identified by Wagner and\n  Schneier against SSL 3.0?  \n* What is the TLS group's position on the security problems\n  identified by Wagner and Schneier? \n\nTIA\n\n\n-dhip\n\n\n\n"
        },
        {
            "subject": "Re: draft agenda for San Jose meetin",
            "content": "> From: Tom Weinstein <tomw@netscape.com>\n> \n> After looking at the suggested changes, I'd categorize them as follows.\n> \n> These entail changes to the protocol:\n> \n> >         1. MAC algorithm\n> >         2. MAC contents\n> >         7. Additional alerts\n> >         9. Additional Record Protocol clients\n>  \n> At this point, I'd be unhappy with any changes to the protocol, although\n> 7 and 9 don't appear to be very damaging to existing implementations.\n> I think that any changes we make to the protocol must be looked at very\n> closely.\n\n\n\nI thought Netscape had already decided that \"SSL 3.1\" would incorporate\nitem 1 (switch to the official IETF HMAC). Considering that 1 and 2 are\nobvious (several sources, including the Wagner/Schneier paper,\nindependently arrived at the same recommendations for \"fixing\" the SSL\n3.0 record layer), I'd say that they have already been looked at closely.\n\nBut you are right about the need for configuration control - we should\ncome to closure on a whole set of changes (including the other\nproposals, not just the 4 listed here) before publishing TLS 1.0.\nPublishing a beautified SSL 3.0 makes the incompatible changes less\nurgent - there's no need to rush these out the door.\n\n\n\n"
        },
        {
            "subject": "Re: change_cipher_spec [was:  draft agenda",
            "content": "David Brownell - JavaSoft wrote:\n\n> Are there really\n> hardware implementations under way?\n\nYes.\n\n> To restate this point ... you're saying that the hardware needs to have\n> a simply specified synchronization point where it can stall until ciphers,\n> keys, and compression algorithms are specified by the handshake engine.\n> (Which I'll assume is implemented in software.)\n\nI've seen proposals where (nearly) everything except an outcall or two\nto check policy conditions (such as \"Do we trust this CA, I don't have\nit in my tables\") is done in hardware/firmware.\n\n> But the underlying engine can't go through that transition without\n> access to the crypto keys,\n\nPrecisely.\n\n> so it can't do the transition until it's\n> told by the handshake layer \"here are the cipher and keys\".\n\n... and the record layer remains stalled until that happens. The\npresentation of cipher and keys needs to block (or timeout with error)\nuntil the change cipher spec comes along.\n\nIn my opinion, it's better to have this synchronization point be\nexplicit in the protocol as opposed to implicit in the state of the\nhandshake (for either hardware or software). It also helps to keep the\nrecord and handshake layers less interdependent.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://www.netscape.com/people/karlton\nNetscape Communications Corporation\n\n    Everything should be made as simple as possible, but not simpler.\n-- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "Presentations for TLS Meetin",
            "content": "At 6:44 AM -0800 12/2/96, Win Treese wrote:\n>Monday, 9 December, 1530-1730\n...\n>1645-1725 Quick presentations on possible future work\n>(including shared secrets, Kerberos, IPSEC key\n>management, etc., may include others to be\n>determined)\n>1725-1730 Wrapup and next steps\n\nWe have a tight schedule for \"quick topics\" at Monday's TLS meeting and I'm\ntrying to pin details down so that I can squeeze a little more time in.\nCurrently the plan is to limit the time of each quick topic to about 5-7\nminutes.\n\nI've only received two copies of draft presentations/slides:\n\nTLS Kerberos Presentation Slides/Ari Medvinsky and Matt Hur\nCompression Support in TLS/Bob Monsour & Mike Sabin\n\nWin and I have had people suggest presentations on IPSEC Key Management,\nShared Keys, Attribute Certificates, SSL/FTP, and some other topics.\nHowever, I really need to see the presentations in advance to make sure\nthat we can fit them into the tight schedule.\n\nPlease forward any draft presentations to Win Treese\n<treese@OpenMarket.com> and I <ChristopherA@consensus.com> ASAP if you want\nto be scheduled in.\n\nExcerpt the IETF Proceedings Guidelines:\n>Slides can be submitted in PowerPoint (preferred), ASCII, PostScript, GIF\n>or HTML.  If slides are in PostScript or GIF format, submit them in a\n>MIME message or provide a FTP or a URL.  If your slides are in PostScript,\n>two files are required:\n>\n>1.  one image per page (for electronic proceedings)\n>2.  four to six per page (for hard copy proceedings; see guidelines)\n>\n>A hard copy version of each presentation is required for the hard copy\n>version of the proceedings in the event that the on-line version is\n>not printable.  The on-line version is, of course, required for the\n>on-line version of the proceedings.\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "ChangeCipherSpec (was Re: draft agenda for San Jose meeting",
            "content": "> Date: Tue, 03 Dec 1996 11:28:25 -0800\n> From: Tom Weinstein <tomw@netscape.com>\n> \n> It's there as an explicit indicator of the change.  Yes, it would be\n> possible to make it implicit, but for protocol purity reasons, we don't\n> like implicit things, especially state changes.  The fact that it's a\n> different record type instead of a handshake message is just a way of\n> making sure that someone can't send it in the middle of a handshake\n> record.\n\n\nActually, from a protocol purity point of view, I believe it is\npreferable go implicit (eliminate the ChangeCipherSpec message).\nAny information that is both transmitted explicitly and known\nfrom the protocol state can be treated 2 ways:\n\n 1. verify that the transmitted and inferred info agree, or\n 2. use the transmitted info only, without checking to see if it\n    is consistent with what is known.\n (or 3. act on known state and ignore what is transmitted -\n    I haven't seen this proposed yet :-)\n\nKeeping the ChangeCipherSpec message is only useful if it adds\ninformation to the protocol exchange.  If it doesn't, sending it\nonly forces extra checks (to see that it is received when expected\nand not received when not expected), or opens up the potential\nfor bugs if implementors forget one of the consistency checks.\n\nImplicit coding is already used in SSL for sequence numbers, which are\nincluded in the MAC calculations but never transmitted.  This is one of\nthe beautiful features of the protocol.\n\nI agree with David Brownell that ChangeCipherSpec should be implicit.\n\n       dpk\n\n\n\n"
        },
        {
            "subject": "Re: ChangeCipherSpec (was Re: draft agenda for San Jose meeting",
            "content": "> Actually, from a protocol purity point of view, I believe it is\n> preferable go implicit (eliminate the ChangeCipherSpec message).\n\nThat was where I started, and it's still how I would prefer to go,\nin the absence of other complicating issues.\n\nHowever, I am persuaded by Phil Karlton's note that having this\nexplicit does facilitate some highly concurrent implementations of\nSSL3, where the handshaking and record marking (at least) would be\ndealt with by separate processing components.  The coordination of\nthose components is much simplified by this message being explicit.\n\nIf the TLS WG wants to support such implementations (e.g. done with\nhardware assistance, as in those little black boxes sitting on the\nend of dedicated lines), it'd be useful to keep this message in the\nprotocol ... also, it'd be important to update the protocol spec to\nadequately describe the sort of problem which is addressed by this\notherwise superfluous (IMHO) record.\n\n- Dave\n\np.s. I recognize that other rationales were offered, but those are\n    not ones that I find I can readily accept.\n\n\n\n"
        },
        {
            "subject": "Implementation of Shared Key Authenticatio",
            "content": "Ref:  Your note of Tue, 3 Dec 1996 18:15:14 -0800 (attached)\n\n\n >\n > Hugo:  Thanks for the free advice!  (I certainly *hope* it's free....)\n\nFree indeed (a joke here would fit well but I know Microsoft may not be\njoking about this...)\n\n > All of your recommendations make sense, but we would obviously prefer\n > that our extensions for shared key authentication conform as closely as\n > possible to the main body of the TLS spec, to avoid confusion and ease\n > implementation.  Hence, if your suggestions regarding MAC and PRF as\n > primitives (as well as the corrections to the HMAC primitive) are\n > adopted in the TLS spec as a whole (an excellent idea that we strongly\n > support), then we will revise our shared key authentication draft\n > accordingly.\n\nI hope they will...\nHowever, SSL/TLS does not specify a unique way to do MAC but has several\nad-hoc variants of HMAC. This means that implementers do not have a unique\nfunction that they can call everytime a MAC is required inthe protocol.\nSO there is no problem for you to use yet another variant (in this case\nthe official HMAC which I guess/hope TLS will eventually adopt).\nSo even if you do not go for a more generic presentation of the\nprotocol using MAC or PRF at this time, you can already change your definition\nto comply with draft-ietf-ipsec-hmac-md5-01.txt.\nMoreover , you can decide on one of the options 1, 2, or 3 discussed in my\nprevious message and stick to it already now.\nSince you are inviting independent implementations you want to avoid\nthe compatibility and upgrade problems later.\n\n >\n > Regarding the adaptation of the shared-key authentication response to\n > the new primitives (assuming that they are adopted), it appears to me\n > that if a PRF primitive is defined, the natural approach would be simply\n > to define the authentication response as PRF(auth_write_key, data +\n > shared_key), thus achieving both the MAC property and concealment of the\n > shared key (assuming a good PRF).  Of course, if the PRF primitive does\n > not get incorporated into the spec, then I suppose the simplest solution\n > would be to treat HMAC/SHA-1 as an implicit PRF, which gives us your\n > solution (2) (which happens to be--in content, if not in form--identical\n > to the currently specified format).\n >\n > Regarding solution (3), one of the reasons for generating a separate\n > \"auth_write_key\" was that such a key, used for only one purpose, would\n > be safe to reveal to the authentication service.  Hence, the separation\n > idea you suggest may be redundant.  Solution (1), on the other hand, is\n > much more interesting, since it reduces the strength of the assumption\n > required from the MAC function, as you point out.  I'm currently\n > checking into some implementability details, and if there are no\n > problems, we'll look at incorporating this revision as well, in the case\n > where the PRF primitive isn't incorporated into TLS.\n\nIf auth_write_key is *guaranteed* to be used only once for this purpose\nwhy not use it as a one-time pad to encrypt the challenge response\nin the way from client to TLS server?\n\nThanks for considering the changes.\n\nHugo\n\n\n\n"
        },
        {
            "subject": "RE: Implementation of Shared Key Authenticatio",
            "content": ">----------\n>From: HUGO@watson.ibm.com[SMTP:HUGO@watson.ibm.com]\n\n>However, SSL/TLS does not specify a unique way to do MAC but has several\n>ad-hoc variants of HMAC. This means that implementers do not have a unique\n>function that they can call everytime a MAC is required inthe protocol.\n>SO there is no problem for you to use yet another variant (in this case\n>the official HMAC which I guess/hope TLS will eventually adopt).\n>So even if you do not go for a more generic presentation of the\n>protocol using MAC or PRF at this time, you can already change your\n>definition\n>to comply with draft-ietf-ipsec-hmac-md5-01.txt.\n>Moreover , you can decide on one of the options 1, 2, or 3 discussed in my\n>previous message and stick to it already now.\n>Since you are inviting independent implementations you want to avoid\n>the compatibility and upgrade problems later.\n\nWell, let's put it this way:  If TLS *does* end up standardizing on\nsomething usable, I'd like shared-key authentication to use it.\nHopefully, the working group will come to a decision soon, and we can\nput out a revised shared-key authentication spec immediately thereafter.\n\n>\n>If auth_write_key is *guaranteed* to be used only once for this purpose\n>why not use it as a one-time pad to encrypt the challenge response\n>in the way from client to TLS server?\n\n\nIt's a matter of appeasing the export gods.  We already spit out a long,\npublic-key-exchanged secret at the server end; if we also output data\nthat was one-time-pad encrypted with it (as opposed to some hash of the\ntwo together), I fear the wrath of export control might well rain down\nupon us.  So instead, we chant the talismanic intonation, \"never will we\noutput strongly encrypted plaintext\", and hope for the best.\n\n(I know--you're going to ask why we don't just hash the\none-time-pad-encrypted response.  Well, we'd still like to use standard\nTLS primitives, if we can; the current response format, for instance, is\nmodeled on one.)\n\nKeep those comments coming,\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)\n\n\n\n"
        },
        {
            "subject": "Updated SSLTalk FAQ 1.0.2 Now Available",
            "content": "The SSL-Talk FAQ (Frequently Asked Questions) has been updated to version\n1.0.2 (December 6th, 1996).\n\nThe full HTML version is available at\n<http://www.consensus.com/security/ssl-talk-faq.html>.\n\nThe text version is available at\n<http://www.consensus.com/security/ssl-talk-faq.txt> or\n<ftp://ftp.consensus.com/pub/security/ssl-talk-faq.txt>.\n\nNew questions and answers:\n\n1.8) May I post commercial announcements regarding SSL products?\n<http://www.consensus.com/security/ssl-talk-sec01.html#1.8>\n\n4.10) What is the difference betwen SSL 2.0 and 3.0?\n<http://www.consensus.com/security/ssl-talk-sec04.html#4.10>\n\n5.10) What are Attribute Certificates?\n<http://www.consensus.com/security/ssl-talk-sec05.html#5.10>\n\n7.2.14) When I call SSLRead(), according to the docs, on returning, the\n length argument should be replaced with the number of bytes actually read. In\n practice, this doesn't seem to be happening. What am I doing wrong?\n<http://www.consensus.com/security/ssl-talk-sec07.html#7.2.14>\n\n7.2.15) If session cache is stored in a database, can multiple Unix\n processes share the same session data?\n<http://www.consensus.com/security/ssl-talk-sec07.html#7.2.15>\n\nSignificant changes to:\n\n1.1) What is the SSL-Talk List?\n<http://www.consensus.com/security/ssl-talk-sec01.html#1.1>\n\n2.1) What is the current version of the SSL protocol?\n<http://www.consensus.com/security/ssl-talk-sec02.html#2.1>\n\n3.5) Do you have any information on sftp?\n<http://www.consensus.com/security/ssl-talk-sec03.html#3.5>\n\n4.5) What is TLS? What happened at these meetings? Has anything come\n out of them yet?\n<http://www.consensus.com/security/ssl-talk-sec04.html#4.5>\n\n5.7) What other CAs exist besides VeriSign?\n<http://www.consensus.com/security/ssl-talk-sec05.html#5.7>\n\nUpdated URLs, additional URLs updates, and minor text updates throughout\nthe document.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: Implementation of Shared Key Authentication, etc",
            "content": "At 11:35 AM 6/12/96 EST, Hugo wrote:\n>Ref:  Your note of Tue, 3 Dec 1996 18:15:14 -0800 (attached)\n>\n>\n> >\n> > Hugo:  Thanks for the free advice!  (I certainly *hope* it's free....)\n>\n>Free indeed (a joke here would fit well but I know Microsoft may not be\n>joking about this...)\n>\n> > All of your recommendations make sense, but we would obviously prefer\n> > that our extensions for shared key authentication conform as closely as\n> > possible to the main body of the TLS spec, to avoid confusion and ease\n> > implementation.  Hence, if your suggestions regarding MAC and PRF as\n> > primitives (as well as the corrections to the HMAC primitive) are\n> > adopted in the TLS spec as a whole (an excellent idea that we strongly\n> > support), then we will revise our shared key authentication draft\n> > accordingly.\n>\n>I hope they will...\n>However, SSL/TLS does not specify a unique way to do MAC but has several\n>ad-hoc variants of HMAC. This means that implementers do not have a unique\n>function that they can call everytime a MAC is required inthe protocol.\n\nG'day!\n\nBeing new to this list, please excuse me if I have failed to find relevant past correspondence on such matters, but, in my ignorance, it appears to me that \"support line\"\ndiagnosis of user-problems could be troublesome, to say the least.  Scenario:\n\nUser:     \"My Browser keeps on disconnecting with a rude message whenever I try to order a\n          widget from XYZ., Inc.  Your software is lousy!\"\n\nAnalyst:  \"Are you using our latest and greatest, Release 18.9-k?\"\n\nUser:     \"Of course!  And apparently good money ill-spent!\"\n\nAnalyst:  \"What message are you getting?\"\n\nUser:     \"Something stupid like 'Protocol violation  --  invalid MAC'.  What's this got to\n          do with sick hamburgers?\"\n\nAnalyst:  \"I don't suppose you know what software XYZ, Inc., are running?  The product and\n          the version?\"\n\nUser:     \"You're obviously joking.  They're based in Kyzyl, Tanutuva.  You ring them up and\n          find out.\"\n\n\nCertainly an unlikely exchange if the underlying software comes from the major vendors, but still possible.  Much more likely when  --  as will inevitably happen  --  others decide to \"roll their own\".\n\nI don't see a universal panacea for this problem, but at least it might help if (say) each Vendor's IP address and software-version were buried somewhere in the exchange.  Knowing where the incompatibilities lie is half the battle.\n\nRegards,\nJim LW \n\nFrom the BBC's \"Barchester Chronicles\":\n\n    \"I know that ultimately we are not supposed to understand.\n    But I also know that we must try.\"\n\n       -- the Reverend Septimus Harding, C++ programmer\n\n\n\n"
        },
        {
            "subject": "What VERSION number is used for TLS",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\n\nI think we need to decide what we number this thing.  I think this was and\nwill continue to be a point of confusion so I think it needs to be\nresolved.  Here's how I think it should be resolved.  \n\nRight now, the document calls itself 1.0, and the protocol it specifies is\n3.0.\n\nSSL also is called 3.0, if you look at the bits on the wire.\n\nWe have rough consensus that the modifications we are making will be\n'minor', but I believe at least one of them (the MAC change) will cause\nthis protocol to no longer exactly match \"SSL 3.0\".\n\nQUESTIONS:\n\n1. Am I correct the MAC changes will cause this to cease to match SSL 3.0\nexactly?\n\n2. What do we call it?  I have a suggestion.  I suggest we make the label\nof the document and the internal version match.  Furthermore, since we are\nmaking a significant change to a field in the TLS Record Format\n(TLSCiphertext MAC values will be calculated differently so an SSL 3.0 MAC\nwill not match, right?) I suggest it's not a 'minor' revision but rather a\n'major' revision.  THEREFORE...\n\nI suggest we call both the SPEC and the PROTOCOL \"TLS 4.0\".\n\nComments?  Corrections?\n\n-----BEGIN PGP SIGNATURE-----\nVersion: 4.0 Business Edition\nComment: PGP by ViaCrypt\n\niQCVAgUBMq2B+sKmlvJNktGxAQFCxQP/cBzsUxAwB04Rc2rqLbK+JSmzZsXcqOmS\nPvSy+lbDqk6P2sbIOm25njO6ffwOtApcLqFLpJxURolewTsl1bdI/Za6MIsiDmQl\nsb/JPewYR/FecOaUGCmyfs3XQU37jmGFJrcZUFh+MoiDa0l8nKdz8EjqGBFPQxEB\nUAbWBKIWE7U=\n=T+v9\n-----END PGP SIGNATURE-----\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "Re: What VERSION number is used for TLS",
            "content": "The move to HMAC does change the bits on the wire (at least that was my\ninterpretation of <draft-ietf-tls-ssl-mods-00.txt>).\n\nWhether the version number is 4.0 or 3.X is a minor issue in my mind. I'm\nmore concerned about how version negotiation will be done. Will it work like\n3.0 where the most recent version is considered more secure? Such that if\nboth sides support TLS vX.X then TLS is used. \n\nWill TLS vX.X continue to support SSLv2 messages? The move to TLS vX.X could\nbe a vehicle to force migration away from v2.0. No?\n\nWill TLS make no assumptions about previous \"non-IETF\" protocols and not try\nto be backwards compatible with SSL2 or SSL3? (certainly there will be\npushback if TLS is not backward compatible with SSL3.0)\n\nRegards,\nNed Smith\nnsmith@ibeam.intel.com\nAt 07:30 AM 12/11/96 -0500, Rodney Thayer wrote:\n>-----BEGIN PGP SIGNED MESSAGE-----\n>\n>I think we need to decide what we number this thing.  I think this was and\n>will continue to be a point of confusion so I think it needs to be\n>resolved.  Here's how I think it should be resolved.  \n>\n>Right now, the document calls itself 1.0, and the protocol it specifies is\n>3.0.\n>\n>SSL also is called 3.0, if you look at the bits on the wire.\n>\n>We have rough consensus that the modifications we are making will be\n>'minor', but I believe at least one of them (the MAC change) will cause\n>this protocol to no longer exactly match \"SSL 3.0\".\n>\n>QUESTIONS:\n>\n>1. Am I correct the MAC changes will cause this to cease to match SSL 3.0\n>exactly?\n>\n>2. What do we call it?  I have a suggestion.  I suggest we make the label\n>of the document and the internal version match.  Furthermore, since we are\n>making a significant change to a field in the TLS Record Format\n>(TLSCiphertext MAC values will be calculated differently so an SSL 3.0 MAC\n>will not match, right?) I suggest it's not a 'minor' revision but rather a\n>'major' revision.  THEREFORE...\n>\n>I suggest we call both the SPEC and the PROTOCOL \"TLS 4.0\".\n>\n>Comments?  Corrections?\n>\nNed Smith~~~~~~~~~~~~~~Intel Architecture Labs~~~~~~~~~~~~~~\nPh: 503.264.2692 Fax: x1805  2111 N.E. 25th Ave.  Hillsboro, OR. 97124     \nEmail: mailto:nsmith@ibeam.intel.com  or mailto:nsmith@bigfoot.com\nhttp://www.intel.com/ial/security\n~~~~~~~~~~~~~~~My opinions are my own etc. etc.~~~~~~~~~~~~\n\n\n\n"
        },
        {
            "subject": "Re: What VERSION number is used for TLS",
            "content": "At 4:30 AM -0800 12/11/96, Rodney Thayer wrote:\n>1. Am I correct the MAC changes will cause this to cease to match SSL 3.0\n>exactly?\n\nYes.\n\n>2. What do we call it?  I have a suggestion.  I suggest we make the label\n>of the document and the internal version match.  Furthermore, since we are\n>making a significant change to a field in the TLS Record Format\n>(TLSCiphertext MAC values will be calculated differently so an SSL 3.0 MAC\n>will not match, right?) I suggest it's not a 'minor' revision but rather a\n>'major' revision.  THEREFORE...\n>\n>I suggest we call both the SPEC and the PROTOCOL \"TLS 4.0\".\n\nHmm, I don't think this is a major revision of the protocol. 2.0 to 3.0 was\na major revision, 3.0 to TLS is minor in comparison. At most, it is a 3.1.\n\n>Comments?  Corrections?\n\nBasically I think that TLS is a 1.0 protocol -- it is the first version of\nwhat we hope will become an IETF protocol (which requires we go through\nproposed standard, draft standard, internet standard). The fact that there\nis some bits on the wire in hello messages that will probably say \"3.1\" for\nbackward compatibility reasons has little to do with the fact that we are\nonly now officially going the first time through the standards process.\n\nI'll not object if the overwhelming consensus is that it should be 3.1, but\nI would prefer that the version number of the documents be 1.0.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Location of SSLRef3 Beta ",
            "content": "At the San Jose IETF-TLS meeting it was announced that SSLRef3 beta3 was (or\nwould soon be) available. Anyone know the location (URL)?\n\nThanks,\nNed Smith~~~~~~~~~~~~~~Intel Architecture Labs~~~~~~~~~~~~~~\nPh: 503.264.2692 Fax: x1805  2111 N.E. 25th Ave.  Hillsboro, OR. 97124     \nEmail: mailto:nsmith@ibeam.intel.com  or mailto:nsmith@bigfoot.com\nhttp://www.intel.com/ial/security\n~~~~~~~~~~~~~~~My opinions are my own etc. etc.~~~~~~~~~~~~\n\n\n\n"
        },
        {
            "subject": "Re: What VERSION number is used for TLS",
            "content": "At 9:04 AM -0800 12/11/96, Ned Smith wrote:\n>Will TLS vX.X continue to support SSLv2 messages? The move to TLS vX.X could\n>be a vehicle to force migration away from v2.0. No?\n>\n>Will TLS make no assumptions about previous \"non-IETF\" protocols and not try\n>to be backwards compatible with SSL2 or SSL3? (certainly there will be\n>pushback if TLS is not backward compatible with SSL3.0)\n\nThere was some discussion on this after TLS meeting during IETF San Jose.\nThe Area Director emphatically encouraged us not to phase out 2.0 backwards\ncompatibility with TLS. This of course means 3.0 backwards compatiblity\nneeds to be done ;-)\n\nMy personal belief is that 2.0 has some security issues, but as long as can\nfind ways to avoid roll-back attacks to SSL 2.0 and SSL 3.0 (and I guess\ntechnically PCT 1.0?), then I'm for compatibility.\n\nI do however, would like to see a statement someplace that this 2.0\nbackward compatibility is optional, and another statement that someday with\nsome future version of TLS, SSL 2.0 compatibility will go away.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: What VERSION number is used for TLS",
            "content": "Ned Smith wrote:\n> \n> The move to HMAC does change the bits on the wire (at least that was\n> my interpretation of <draft-ietf-tls-ssl-mods-00.txt>).\n\nMoving to HMAC does indeed involve a change in the bits on the wire.\nThe current MAC construction is based on an early version of HMAC and\ndoes not match the current HMAC.  Changing the MAC algorithm will change\nthe value of the MAC generated.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: What VERSION number is used for TLS",
            "content": "Rodney Thayer wrote:\n> \n> QUESTIONS:\n> \n> 1. Am I correct the MAC changes will cause this to cease to match SSL\n> 3.0 exactly?\n\nYes.\n\n> 2. What do we call it?  I have a suggestion.  I suggest we make the\n> label of the document and the internal version match.  Furthermore,\n> since we are making a significant change to a field in the TLS Record\n> Format (TLSCiphertext MAC values will be calculated differently so an\n> SSL 3.0 MAC will not match, right?) I suggest it's not a 'minor'\n> revision but rather a 'major' revision.  THEREFORE...\n> \n> I suggest we call both the SPEC and the PROTOCOL \"TLS 4.0\".\n\nI agree.  I think 4.0 would be appropriate.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Port number?",
            "content": "All this talk of version number  raised a question inmy mind about the port\nnumber to be used.  Will TLS use the same ports as SSL for http, telnet,\nnews, ftp or will it have it's own port numbers registered with IANA.\n\nSorry if this information is available else where, thought it would be easy\njust to ask.\n\nBaber\n:)\n\nBaber Amin\nNetWare Security R&D.\nNovell Inc.\nEmail: Baber_Amin@Novell.com\nx.400: C=US;A=TELEMAIL;P=NOVELL;G=BABER;S=AMIN\nIMX  : USWPCBAM@IBMMAIL\n801-861-5285\n801-376-3921\n\n-----------------------------------------------------\nIs the Noise in my head bothering YOU!!\n\n\n\n"
        },
        {
            "subject": "Re: Port number?",
            "content": "Baber Amin wrote:\n> \n> All this talk of version number  raised a question inmy mind about the\n> port number to be used.  Will TLS use the same ports as SSL for http,\n> telnet, news, ftp or will it have it's own port numbers registered\n> with IANA.\n> \n> Sorry if this information is available else where, thought it would be\n> easy just to ask.\n\nIt will use the same ports.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: What VERSION number is used for TLS",
            "content": "It is my understanding that we have explicit guidance from the AD that TLS\nshould *not* break backwards compliance with SSL3 or SSL2.\n\nI though (but I can't quote you chapter and verse) that whatever the\nnumber, it will be >3.0 and therefor the negotiation logic would cause it\nto be preferred.\n\n>X-Sender: nsmith@ibeam.intel.com\n>Date: Wed, 11 Dec 1996 09:04:49 -0800\n>To: Rodney Thayer <rodney@sabletech.com>\n>From: Ned Smith <nsmith@ibeam.jf.intel.com>\n>Subject: Re: What VERSION number is used for TLS?\n>Cc: ietf-tls@w3.org\n>\n>The move to HMAC does change the bits on the wire (at least that was my\n>interpretation of <draft-ietf-tls-ssl-mods-00.txt>).\n>\n>Whether the version number is 4.0 or 3.X is a minor issue in my mind. I'm\n>more concerned about how version negotiation will be done. Will it work like\n>3.0 where the most recent version is considered more secure? Such that if\n>both sides support TLS vX.X then TLS is used. \n>\n>Will TLS vX.X continue to support SSLv2 messages? The move to TLS vX.X could\n>be a vehicle to force migration away from v2.0. No?\n>\n>Will TLS make no assumptions about previous \"non-IETF\" protocols and not try\n>to be backwards compatible with SSL2 or SSL3? (certainly there will be\n>pushback if TLS is not backward compatible with SSL3.0)\n>\n>Regards,\n>Ned Smith\n>nsmith@ibeam.intel.com\n>At 07:30 AM 12/11/96 -0500, Rodney Thayer wrote:\n>>-----BEGIN PGP SIGNED MESSAGE-----\n>>\n>>I think we need to decide what we number this thing.  I think this was and\n>>will continue to be a point of confusion so I think it needs to be\n>>resolved.  Here's how I think it should be resolved.  \n>>\n>>Right now, the document calls itself 1.0, and the protocol it specifies is\n>>3.0.\n>>\n>>SSL also is called 3.0, if you look at the bits on the wire.\n>>\n>>We have rough consensus that the modifications we are making will be\n>>'minor', but I believe at least one of them (the MAC change) will cause\n>>this protocol to no longer exactly match \"SSL 3.0\".\n>>\n>>QUESTIONS:\n>>\n>>1. Am I correct the MAC changes will cause this to cease to match SSL 3.0\n>>exactly?\n>>\n>>2. What do we call it?  I have a suggestion.  I suggest we make the label\n>>of the document and the internal version match.  Furthermore, since we are\n>>making a significant change to a field in the TLS Record Format\n>>(TLSCiphertext MAC values will be calculated differently so an SSL 3.0 MAC\n>>will not match, right?) I suggest it's not a 'minor' revision but rather a\n>>'major' revision.  THEREFORE...\n>>\n>>I suggest we call both the SPEC and the PROTOCOL \"TLS 4.0\".\n>>\n>>Comments?  Corrections?\n>>\n>Ned Smith~~~~~~~~~~~~~~Intel Architecture Labs~~~~~~~~~~~~~~\n>Ph: 503.264.2692 Fax: x1805  2111 N.E. 25th Ave.  Hillsboro, OR. 97124     \n>Email: mailto:nsmith@ibeam.intel.com  or mailto:nsmith@bigfoot.com\n>http://www.intel.com/ial/security\n>~~~~~~~~~~~~~~~My opinions are my own etc. etc.~~~~~~~~~~~~\n>\n>\n>\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "TLS 1paragraph report for A",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\n\nThe TLS group covered two main topics at it's WG meeting.  A proposal to\ntake the latest TLS draft (Edited by Dierks/Allen) as the starting point\nwas offered.  It was proposed that this document plus a limited set of\npresented changes be submitted for publication.  After some debate and\nsome advice from the AD, this proposal was agreed to, unanimously, by the\ngroup.  The\nnext step for the group is to proceed with a working group last call on\nthe draft (with the short modifications list integrated.)  After this the\ngroup plans to discuss changes to the base TLS protocol, as there are\nseveral proposals now on the table. \n\n-----BEGIN PGP SIGNATURE-----\nVersion: 4.0 Business Edition\nComment: PGP by ViaCrypt\n\niQCVAgUBMq9uLMKmlvJNktGxAQG9zAQAtOpB61Sjr+yzVV8NLuSW7An8e6CLqYV9\nQ8X8ZKhS9+2gNHtWZIgX4WDzHSRCFkjkZjtv6EDdmGQoRO1CL02UoATePpL/Acqi\ncVhwedZww+i6+yGY0nvgnR7a5+TqKp4nH+Lvan/CdTVidXzvPJzWToQdlBuPEA6i\nMmZIv198IKE=\n=k6sv\n-----END PGP SIGNATURE-----\n\n--------\nRodney Thayer <rodney@sabletech.com>\nPGP Fingerprint: BB 1B 64 28 40 91 29 AC  07 6B 9D E1 4C 25 0D D8\n\n\n\n"
        },
        {
            "subject": "minutes from TLS WG meeting in San Jos",
            "content": "Are on the way.  I'm tasked to do that.\n\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "Re: Location of SSLRef3 Beta ",
            "content": "Ned Smith wrote:\n> \n> At the San Jose IETF-TLS meeting it was announced that SSLRef3 beta3 was (or\n> would soon be) available. Anyone know the location (URL)?\n> \n> Thanks,\n> Ned Smith~~~~~~~~~~~~~~Intel Architecture Labs~~~~~~~~~~~~~~\n> Ph: 503.264.2692 Fax: x1805  2111 N.E. 25th Ave.  Hillsboro, OR. 97124\n> Email: mailto:nsmith@ibeam.intel.com  or mailto:nsmith@bigfoot.com\n> http://www.intel.com/ial/security\n> ~~~~~~~~~~~~~~~My opinions are my own etc. etc.~~~~~~~~~~~~\n\n\nWe're getting the final version of SSLRef on the site within the next\nweek.  You can download SSLRef by going to the following link:\nhttp://www37.netscape.com/eng/US-Current/index.html\n\nRegards,\nEric\n\n\n\n"
        },
        {
            "subject": "CipherSuites for unpublished algorithm",
            "content": "Chris/Tim,\n\n  IETF guidelines are that unpublished algorithms are not to be\nincluded in Standards-Track documents, but they may be specified\nin accompanying Informational RFCs.  As a first step towards moving\ntowards Standard status, the SSL 3.0 Fortezza algorithm suites were removed\nfrom the TLS 1.0 draft, however several other CipherSuites using\nunpublished algorithms (RC2 and RC4) have not yet been moved out of\nthe main draft.\n\nSeparating the optional CipherSuites out from the Standard is a good\nidea, and makes it easier to define support for additional algorithms.\nWill the next document (incorporating the 9 unanimously-approved changes :-)\nbe in the form of separate drafts for the baseline standard (only DES and\n3DES) and the optional algorithms?  Or will there be an additional revision\ncycle before proceeding to WG last call?\n\nI assume you will be writing the RC2/RC4 draft(s). Will you also be writing\nthe Fortezza draft or should someone else take responsibility for that\ndocument?\n\n          dpk\n\n\n\n"
        },
        {
            "subject": "CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\n\nOoh. He's right, isn't he?\n\nI believe it, but is there an RFC one can quote to reference these\nguidelines?\n\nSo the common denominator among (the tls doc) and (the common exportable\nNetscape) and (the common exportable MS Internet Explorer) would\nend up being MD5 or SHA-1 digesting, and 40-bit DES.\n\nThis is valid, and this is supported by N. and MS., correct?  \n\nIt seems to me that it would be worth making sure we don't write a draft\nthat isn't irrelevant to the (ahem) 'best current practice'...\n\n>From: dpkemp@missi.ncsc.mil (David P. Kemp)\n>To: ietf-tls@w3.org\n>Subject: CipherSuites for unpublished algorithms\n\n>  IETF guidelines are that unpublished algorithms are not to be\n>included in Standards-Track documents, but they may be specified\n>in accompanying Informational RFCs.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: 4.0 Business Edition\nComment: PGP by ViaCrypt\n\niQCVAgUBMrXV7cKmlvJNktGxAQGAHQP+PFtwMFkNMs2HMRG1vW36H7C8KdzPjgKZ\nHWdzG+PWamSfSwh7z2I57iD8OFvtfMTAlVw71WSX9EGaTdkhh9L88kih9qJxIq/F\nAi8TNFeK8jTUPtgh65OeEtRgmrcRZjfTVgLKMHl6T+7TIQ9cwzozHL4QTSVDYvgF\nQm41lgNcv5c=\n=IYI1\n-----END PGP SIGNATURE-----\n\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "Re: CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "At 6:08 PM -0500 12/16/96, Rodney Thayer wrote:\n>From: dpkemp@missi.ncsc.mil (David P. Kemp)\n>>  IETF guidelines are that unpublished algorithms are not to be\n>>included in Standards-Track documents, but they may be specified\n>>in accompanying Informational RFCs.\n>Ooh. He's right, isn't he?\n>\n>I believe it, but is there an RFC one can quote to reference these\n>guidelines?\n\nI don't know. I was previously advised that RC2 and RC4 were OK, as long as\nthere were alternatives, but that Fortezza was right out. I'm going to go\nand check with Jeff Schiller.\n\n>So the common denominator among (the tls doc) and (the common exportable\n>Netscape) and (the common exportable MS Internet Explorer) would\n>end up being MD5 or SHA-1 digesting, and 40-bit DES.\n>\n>This is valid, and this is supported by N. and MS., correct?\n\nActually, as far as I know, neither Netscape nor Microsoft support 40 bit\nDES. My belief is that the intersection of the set of publically described\nalgorithms, the set of exportable algorithms, and the algorithms used my\nNetscape or Microsoft is the empty set. I believe this is a problem,\nalthough not an insurmountable one.\n\nIf one doesn't restrict to exportability, I know that Netscape supports\nRSA-DES-SHA and RSA-3DES-SHA. I don't have a Microsoft Explorer 3.0 that\nruns in my office, and 2.0 doesn't tell me what ciphers it supports.\n\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "Additional suggested cleanups for TL",
            "content": "After some contemplation of events in San Jose, I would like to suggest\na couple more cleanups that should really be incorporated into TLS\nbefore it becomes a proposed standard.  I am thinking particularly of\nthe places in the protocol where specific hash functions are hard-coded\ninto the spec, namely the signature block in the CertificateVerify\nmessage and the master secret, key block, export write key and export IV\nderivations.\n\nStandard signatures in the Certificate Verify message\n\nIn my opinion, the client authentication signature format should\ndefinitely be changed to allow conventional one-hash signatures, so that\nstandard implementations (including hardware-based ones) can be used.\nOne possibility is simply to alter the Certificate Verify message to\nrequire that the signature response consist of a standard\n(single-)hash-and-sign signature in which the hash function used is the\none specified by the pending cipher suite.  Alternatively, two new\ncertificate types could be added, the specifying of which in the\nCertificate Request message would indicate that the client should\nrespond with a standard (single-hash-and-sign) signature using the hash\nfunction specified by the cipher suite.  (The current certificate types\nwould then be used to request an SSL 3.0-style two-hash signature\nresponse; that way, full backward compatibility is maintained, and more\nstandard signature implementations can still be used.)\n\nStandardized key generation using PRFs\n\nHugo Krawczyk recently suggested to the WG on this list that an explicit\nPRF primitive be introduced into the spec, so that the protocol could be\nbased on an easily replaceable function whose assumed properties would\nbe clearly defined and well understood.  Currently, there's an\nimplicitly defined PRF in the spec, used for master secret and key block\ngeneration.  It has the following structure:\n\nf(k,x) =\nMD5(k + SHA('A' + k + x)) + \nMD5(k + SHA('BB' + k + x)) +\nMD5(k + SHA('CCC' + k + x)) + [...];\n\nThis function (with the pre-master secret as k and x derived from the\nclient's and server's random challenges) is used to generate the master\nsecret; the same thing is done (with the master secret as k) to generate\nthe key block from which encryption and MAC keys are taken.  The\nexception is the export case:  export write keys and IVs are derived\nusing an extra step:\n\nfinal_client_write_key(k1,r1) = MD5(k1 + r1);\nfinal_server_write_key(k2,r2) = MD5(k2 + r2);\n\nclient_write_IV(r1) = MD5(r1);\nserver_write_IV(r2) = MD5(r2);\n\nk1 and k2 are 40-bit keys extracted from the key block, and r1 and r2\nare values derived from the (public, unencrypted) client's and server's\nrandom challenges.\n\nSince the master secret and key block generations both use the same PRF,\nI'd like to propose using it as well for final export key and IV\ngeneration--something like the following:\n\nfinal_client_write_key(k1,r1) = PRF(k1,r1);\nfinal_server_write_key(k2,r2) = PRF(k2,r2);\n\nclient_write_IV(r1) = PRF(\"client fixed constant string\", r1);\nserver_write_IV(r2) = PRF(\"server fixed constant string\", r2);\n\nAs well as standardizing the key derivation process, this change to a\nuniform PRF-based method would encourage implementers to make the PRF\npluggable, allowing more secure or more efficient functions to replace\nthe current one in the future as needed.  (In fact, we might consider\nswitching to a better PRF immediately, if we are already breaking\nbackward compatibility by changing HMAC.)  Ideally the current cipher\nsuites would either implicitly or explicitly specify the current default\nPRF, so that additional PRF options could be added, if necessary, simply\nby adding new cipher suites.\n\nComments on these proposals (especially from Hugo!) are welcomed.\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com) \n\n\n\n\n\n\n>\n\n\n\n"
        },
        {
            "subject": "Re: CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "> >\n> >I believe it, but is there an RFC one can quote to reference these\n> >guidelines?\n> \n> I don't know. I was previously advised that RC2 and RC4 were OK, as long as\n> there were alternatives, but that Fortezza was right out. I'm going to go\n> and check with Jeff Schiller.\n\n\nRFC 2026 is the current description of the Internet Standards Process.\nThe POISSON working group also plans to have new drafts out sometime\naround Memphis.\n\nOne applicable paragraph from RFC 2026:\n\n   10.2  Confidentiality Obligations\n\n   No contribution that is subject to any requirement of confidentiality\n   or any restriction on its dissemination may be considered in any part\n   of the Internet Standards Process, and there must be no assumption of\n   any confidentiality obligation with respect to any such contribution.\n\n\nAs far as I know, RSA still claims that RC2 and RC4 are trade secrets.\nThe TLS draft states that there is no published reference for the\nalgorithms.  I disagree that it's OK for a standards track document\nto include algorithms for which one has to purchase a sole source\nimplementation, but it certainly seems OK to document how to use\nthem with TLS, as long as it's done in a separate non-standards-track\ndocument.\n\nIt would be ideal to have documentation of additional algorithms for\nuse with TLS, both publicly available (Blowfish, SAFER SK-128, etc)\nand proprietary, patented, unpublished, or otherwise encumbered\n(IDEA, RC2, RC4, Fortezza, etc) and let market demand, performance,\nquality of protection, and cost decide what gets implemented in\nNetscape, MSIE, and SSLeay-based products.\n\nBut the standard, mandatory-to-implement, universally-interoperable\nalgorithm cannot be proprietary.  It's always helpful to remember\nthat this working group is not rubber-stamping an existing\nimplementation, it's defining a specification based on both best\nexisting practice and new requirements.\n\n        dpk\n\n\n\n"
        },
        {
            "subject": "Re: Additional suggested cleanups for TL",
            "content": "> From: Dan Simon <dansimon@microsoft.com>\n>\n> Standardized key generation using PRFs\n> \n> Hugo Krawczyk recently suggested to the WG on this list that an explicit\n> PRF primitive be introduced into the spec, so that the protocol could be\n> based on an easily replaceable function whose assumed properties would\n> be clearly defined and well understood.  Currently, there's an\n> implicitly defined PRF in the spec, used for master secret and key block\n> generation.  It has the following structure:\n> \n> f(k,x) =\n> MD5(k + SHA('A' + k + x)) + \n> MD5(k + SHA('BB' + k + x)) +\n> MD5(k + SHA('CCC' + k + x)) + [...];\n> \n>            [...]\n> \n> As well as standardizing the key derivation process, this change to a\n> uniform PRF-based method would encourage implementers to make the PRF\n> pluggable, allowing more secure or more efficient functions to replace\n> the current one in the future as needed.  (In fact, we might consider\n> switching to a better PRF immediately, if we are already breaking\n> backward compatibility by changing HMAC.)  Ideally the current cipher\n> suites would either implicitly or explicitly specify the current default\n> PRF, so that additional PRF options could be added, if necessary, simply\n> by adding new cipher suites.\n> \n> Comments on these proposals (especially from Hugo!) are welcomed.\n\n\n\nI agree completely, and support the PRF proposals from Dan and Hugo.\n\nHugo also mentioned some other topics:\n\n 1) The form of the PRF used by IPSEC, which uses an appended one-up\n    counter to generate successive key blocks, is not optimal.\n\nThe SSL form, using prepended 'A', 'BB', 'CCC', [...] seems much better\nin that it varies a) the value of the unique data, b) the length of the\nunique data, and c) the position of k and x.  But I'd like to hear\nHugo's confirmation that the SSL form looks like a good key block\ngeneration method.  Although it's unlikely that anyone would ever\ntry to make more than 26 blocks, there should probably be an\nexplicit statement that it is forbidden to go past 'ZZZZ...Z', and\nthat if more bits are needed it's time go get some more entropy.\n\n 2) Mixing MD5 and SHA in a single ad-hoc function probably doesn't\n    buy anything because it is difficult to imagine a situation in\n    which SHA is broken but MD5 remains sound.\n\nThis sounds reasonable, and I'd support using a \"better PRF\" based\non non-mixed HMAC-SHA.\n\n 3) For integrity purposes (not for signatures!) it may be more secure\n    to truncate the SHA output to 128 bits.\n\nAlthough the suggestion originally had nothing to do with security (it\nwas motivated by the desire to have the same size output for MD5 and\nSHA), the idea that truncating keyed hash functions may improve their\nrobustness by hiding some state is intuitively appealing.  But I don't\nknow if there is enough of a theoretical basis yet to suggest using\nHMAC-SHA-128. \n\n\n\n"
        },
        {
            "subject": "Re: CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "David P. Kemp wrote:\n \n> But the standard, mandatory-to-implement, universally-interoperable\n> algorithm cannot be proprietary.\n\nUnfortunately, operations in the real world mean that there will never\nbe a universally-interoperable algorithm, even within the domain of\nsupporting a single protocol, say HTTP. For instance, some\nimplementations will only contain support for FORTEZZA and others will\ncontain no support for FORTEZZA.\n\nThere are some CipherSpecs that are only useful where MITM attacks are\nunlikely, say anonymous Diffie-Hellman supporting telnet on a single\nsubnet. We shouldn't say \"That's not TLS.\" since it doesn't support the\n'mandatory aglorithm'.\n\nI'm not arguing against the goal, but the spec needs to deal (carefully)\nwith how TLS will be actually used.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://www.netscape.com/people/karlton\nNetscape Communications Corporation\n\n    Everything should be made as simple as possible, but not simpler.\n-- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "Re: Additional suggested cleanups for TL",
            "content": "Be careful here. The reason SSL used only MD5 for the final phase of the\nexport case is that we were advised that it might be difficult to get a\nCJ for products that used SHA in that step.\n\n>  2) Mixing MD5 and SHA in a single ad-hoc function probably doesn't\n>     buy anything because it is difficult to imagine a situation in\n>     which SHA is broken but MD5 remains sound.\n\nI have a pretty good imagination. :-)\n\nAnother issue concerns the MAC for the Finished messages. There was MUCH\ndiscussion about whether they should be constructed like HMAC rather\nthan the ad hoc algorithm that was chosen. The tradeoffs are fairly\nsimple.\n\n   pro) Using HMAC is more secure (probably).\n\n   con) The server has to retain the entire handshake until it\ncan compute the master_secret. The storage requirements\nfor heavily used secure servers could be prohibitive.\n(Some information, e.g. the server's certificate chain\nis probably constant across all handshakes; and that\nhelps a little.)\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://www.netscape.com/people/karlton\nNetscape Communications Corporation\n\n    Everything should be made as simple as possible, but not simpler.\n-- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "Re: CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "Although your logic is sound it doesn't seem IETF-compliant.\n\nIs there some way we can handle this?  For example, if there were a TLS\ndocument, and a second document containing (\"the SSL profile of TLS\")?\n\n\n\nAt 10:45 AM 12/17/96 -0800, you wrote:\n>David P. Kemp wrote:\n> \n>> But the standard, mandatory-to-implement, universally-interoperable\n>> algorithm cannot be proprietary.\n>\n>Unfortunately, operations in the real world mean that there will never\n>be a universally-interoperable algorithm, even within the domain of\n>supporting a single protocol, say HTTP. For instance, some\n>implementations will only contain support for FORTEZZA and others will\n>contain no support for FORTEZZA.\n>\n>There are some CipherSpecs that are only useful where MITM attacks are\n>unlikely, say anonymous Diffie-Hellman supporting telnet on a single\n>subnet. We shouldn't say \"That's not TLS.\" since it doesn't support the\n>'mandatory aglorithm'.\n>\n>I'm not arguing against the goal, but the spec needs to deal (carefully)\n>with how TLS will be actually used.\n>\n>PK\n>--\n>Philip L. Karltonkarlton@netscape.com\n>Principal Curmudgeonhttp://www.netscape.com/people/karlton\n>Netscape Communications Corporation\n>\n>    Everything should be made as simple as possible, but not simpler.\n>-- Albert Einstein\n>\n>\n>\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "RE: Additional suggested cleanups for TL",
            "content": ">From: Phil Karlton[SMTP:karlton@netscape.com]\n>\n>Another issue concerns the MAC for the Finished messages. There was MUCH\n>discussion about whether they should be constructed like HMAC rather\n>than the ad hoc algorithm that was chosen. The tradeoffs are fairly\n>simple.\n>\n>   pro) Using HMAC is more secure (probably).\n>\n>   con) The server has to retain the entire handshake until it\n>can compute the master_secret. The storage requirements\n>for heavily used secure servers could be prohibitive.\n>(Some information, e.g. the server's certificate chain\n>is probably constant across all handshakes; and that\n>helps a little.)\n\nOn the other hand, there's simply no justification for using a weaker\nconstruction in the (more crucial) finished message than in the standard\ndata MAC.  Since you vehemently opposed anything weaker than HMAC for\ndata MACing, even for the sake of efficiency (right here on this mailing\nlist, in fact, when we were discussing pre-MAC'd data), I assume you'd\nnever support using a weaker function in the finished message--right,\nPhil? \n\nIn any event, the function used in SSL 3.0's finished message is flawed,\nin that the master secret is used as the key, with both MD5 and SHA\nbeing used for extra anti-collision protection.  That means that if\n*either* hash function turns out to be invertible as used there, then\nthe finished message ends up revealing the master secret.  At the very\nleast, a separate key should be derived from the key block for this\npurpose.  Better still, the value in the finished message should be a\nMAC of the previous handshake messages using this separate key, where\n\"MAC\" is a separately defined primitive (as per Hugo's suggestion),\nspecified (implicitly or explicitly) by the pending cipher suite (and\npresumably defaulting to HMAC for current cipher suites).  That way, if\nthe current choice of MAC falls under suspicion, it can be assumed\nreplaceable in every implementation.\n\n(Thanks for pointing this out, Phil--I hadn't noticed this bug before.)\n\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)\n\n>\n\n\n\n"
        },
        {
            "subject": "Re: Additional suggested cleanups for TL",
            "content": "Dan and Phil,\n\n  Please read below Dans comments.\n\nDan Simon wrote:\n> \n> >From:  Phil Karlton[SMTP:karlton@netscape.com]\n> >\n> >Another issue concerns the MAC for the Finished messages. There was MUCH\n> >discussion about whether they should be constructed like HMAC rather\n> >than the ad hoc algorithm that was chosen. The tradeoffs are fairly\n> >simple.\n> >\n> >   pro) Using HMAC is more secure (probably).\n> >\n> >   con) The server has to retain the entire handshake until it\n> >       can compute the master_secret. The storage requirements\n> >       for heavily used secure servers could be prohibitive.\n> >       (Some information, e.g. the server's certificate chain\n> >       is probably constant across all handshakes; and that\n> >       helps a little.)\n> \n> On the other hand, there's simply no justification for using a weaker\n> construction in the (more crucial) finished message than in the standard\n> data MAC.  Since you vehemently opposed anything weaker than HMAC for\n> data MACing, even for the sake of efficiency (right here on this mailing\n> list, in fact, when we were discussing pre-MAC'd data), I assume you'd\n> never support using a weaker function in the finished message--right,\n> Phil?\n\n  I agree that there is no reason for using a weaker construction as\nyou indicate here Dan.  I do wonder it it is a matter of necessity from\na buisness point of view.  Knowing however that does not stand up under\nscrutiny however.  I don't see why HMAC could not e a consideration or\na small tradeoff.\n\n> \n> In any event, the function used in SSL 3.0's finished message is flawed,\n> in that the master secret is used as the key, with both MD5 and SHA\n> being used for extra anti-collision protection.  That means that if\n> *either* hash function turns out to be invertible as used there, then\n> the finished message ends up revealing the master secret.  At the very\n> least, a separate key should be derived from the key block for this\n> purpose.  Better still, the value in the finished message should be a\n> MAC of the previous handshake messages using this separate key, where\n> \"MAC\" is a separately defined primitive (as per Hugo's suggestion),\n> specified (implicitly or explicitly) by the pending cipher suite (and\n> presumably defaulting to HMAC for current cipher suites).  That way, if\n> the current choice of MAC falls under suspicion, it can be assumed\n> replaceable in every implementation.\n\n  Well, I do believe that Dan is correct here.  I remember and reviewed\nsome of the back discussions on this matter.  It would seem that a\nseperate\nkey is \"ONE\" solution to this problem from Key Block.  I liked Hugo's \napproach alot better, as far as it went.  It should be explicit however \nand defaulting to HMAC if MAC is compermised or persumed so.  Or\npossibly\na seperate extension of the current Cypher Suite that that will provide \nfor that type of function.  The other would be to use a seperate \nconfigurable interface as I had suggested, and now am testing.  This\ngives\nmore flexability in implimentation and provides for forward\ncompatability\nwith multi level defaulting.\n\n  As far as \"I\" am concerned, neither suggestions stated here are\nadequate\nfor a broad range of implimentations.  It would seem that little has\nbeen\ngained by myself in this belief here on this forum however.  So I will \nleave it at that, currently.  \n\nRegards and Happy Hollidays,\n\n> \n> (Thanks for pointing this out, Phil--I hadn't noticed this bug before.)\n> \n>                         Daniel Simon\n>                         Cryptographer, Microsoft Corp.\n>                         (dansimon@microsoft.com)\n> \n> >\n\n-- \nJeffrey A. Williams\nDIR. Internet Network Eng/SR. Java Development Eng.\nInformation Eng. Group. \nPhone :972-447-1878\nE-Mail jwkckid1@ix.netcom.com\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Re: CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "There is at least one published description of an algorithm which\ninteroperates with RC4; see the 2nd edition of Schneier's Applied\nCryptography.  I suspect that this may be \"good enough\" for RFC2026's\npurposes.\n\nThe first edition is already cited as [SCH] in the bibliography\n(though there's a formatting glitch which makes both it and [TCP] hard\nto spot).\n\nRC2 is more problematic, but does anyone actually use it?  Deleting it\nmight make sense if nobody actually uses it..\n\n- Bill\n\n\n\n"
        },
        {
            "subject": "TLS WG Minutes &ndash;&ndash; San Jose IETF December 199",
            "content": "             TLS WG Minutes -- San Jose IETF December 1996\n\nABSTRACT:\n\nThe TLS group covered two main topics at it's WG meeting. A proposal\nto take the latest TLS draft (edited by Dierks/Allen) as the\nstarting point was offered. It was proposed that this document plus\na limited set of presented changes be submitted for publication.\nAfter some debate and some advice from the AD, this proposal was\nagreed to, unanimously, by the group. The next step for the group is\nto proceed with a working group last call on the draft (with the\nshort modifications list integrated.)  After this the group plans to\ndiscuss changes to the base TLS protocol, as there are several\nproposals now on the table.\n\n\nDECISIONS MADE:\n\nThere was discussion regarding a short list of modifications to the\nexisting SSL 3 work. It was suggested that the working group adopt\nthis short list and submit the resulting draft as a proposed TLS 1.0\nstandard. This point was considered in some detail by the group, and\nsignificant advice was provided by the Area Director, Jeff Schiller.\nIt was agreed that further modifications to the TLS protocol beyond\nthe short list would take place after a draft has been completed and\nsubmitted. Milestones are:\n\n    Jan. 6, 1997      Draft with proposed modifications to list\n    Jan. 20, 1997     Conclusion of comments/discussion\n    Feb. 3, 1997      Changes incorporated, submit draft to IESG\n    March, 1997       Memphis IETF, new business\n\n\nDETAIL:\n\nA total of approximately 300 IETF members attended the TLS WG\nmeeting on 9 December 1996. Christopher Allen presided over the\nmeeting. Win Treese, WG chair, was not able to attend. Rodney Thayer\nand Jonathan Zamick prepared these meeting minutes.\n\nThe agenda was:\n    Announcements and Introductions\n    Presentation of current documents\n    Presentation of TLS 1.0 Draft and Proposed Modifications\n    Quick Topics:\n        Presentation of TLS Compression proposal\n        Presentation of TLS FTP proposal\n        Presentation of TLS Kerberos proposal\n        Presentation of TLS Password Authorization proposal\n    Wrap-up and summary of new milestones\n\nChristopher Allen welcomed the attendees to the meeting. Win Treese,\nWG chair, was unable to attend due to personal commitments.\nApproximately half the members present indicated they follow the\nmailing list. It was announced that the WG chair has asked\nChristopher Allen and Tim Dierks to edit the TLS document. Cylink\nannounced they are looking for partners for a TLS effort. There is\nan SSL FAQ, copies were handed out. Terisa announced they have an\nSSL implementation. There is a group investigating certificate\nstorage on media or offline. Compuserve (R. Petke) announced they\nare doing work on remote passphrase authentication, and gave\npointers to some drafts. They are also looking into NNTP and POP3. A\nsummary of E-mail addresses and URL's is included at the end of the\nminutes.\n\nTim Dierks presented the TLS 1.0 document. This is essentially the\nsame as the SSL 3 document (the protocol specifies the same 'bits on\nthe wire'). He explained that the strategy, as decided at the\nMontreal IETF meeting, was for TLS to be based on SSL revision 3, as\nopposed to SSL 2 or SSH or PCT or some other transport layer\nsecurity proposal. The intent is that this document, with a minimal\nset of modifications, be moved forward towards proposed standard.\n\nTim then presented the modifications document, which contains ten\nitems. These are mostly very minor points of clarification. The\nthree major points are that (1) the MAC should change to align with\ncurrent IETF HMAC thinking, (2) Fortezza was removed as it is a\nproprietary unpublished technology, and (3) the record layer and\nhandshake layer are to be separated out. There was some discussion\nof this, as there were individuals in the group who initially did\nnot agree with the view that these were \"minor\" changes or that this\nwas an appropriate list of limited modifications.\n\nJeff Schiller (Area Directory for Security) participated in this. He\noffered the (somewhat stern) observation that the WG has a\nresponsibility to produce progress, and that if the WG does not show\nprogress the IESG can and may dispand it. This then led the group to\ncome to the consensus that the base document plus the modifications\nshould be combined into a single document that can be submitted for\nconsideration as a proposed standard.\n\nIn the end, the numbers worked out like this:  30-40 people\nindicated they had read the documents. Of these, several had initial\nobjections but withdrew them. There were several points that were\nbrought up and it was suggested they be considered later. These\nwere:  a service definition or API, clarity on use of distinguished\nnames and certificates in general, and password (non-certificate)\nauthentication.\n\nBob Monsour presented a proposal to incorporate compression, as a\nCipherSuite, into TLS. A draft was made available the week after the\nmeeting.\n\nPaul Ford-Hutchinson presented some work on a TLS-based FTP client\nand server. It was noted that this is in some ways more complex then\nthe HTTP case as there are two TCP connections and the issue of who\nis the TLS client and who is the server becomes significant. Also he\npointed out that if the control circuit is encrypted, the data\ncircuit should be too.\n\nAri Medvinsky presented some work on using Kerberos as an\nauthentication mechanism for TLS. The idea is that Kerberos would be\nused to replace RSA or DSS for key exchange. The premaster secret\nwould be sent protected with a Kerberos session key.\n\nDan Simon presented some work on password authentication and how it\nwould fit into the TLS framework. Tim Dierks proposed that we\nseparate \"SKAP\" (Shared Key Authentication) from the transport\nprotocol. The use of passwords for shared key authentication was\npresented with the reasoning being that passwords are still in wide\nuse, as opposed to certificates, and the password would be protected\nbecause it would not be transmitted in the clear.\n\nChristopher Allen wrapped up the meeting by reviewing the items\ncovered, and the proposed next goals. Tim Dierks has an action item\nto get the TLS document merged and edited by mid-January for review\nby the Working Group.\n\n    TLS Working Group email list:\n          ietf-tls@w3.org, To subscribe send to ietf-tls-request@w3.org,\n          put 'subscribe' in the subject.\n\n    TLS and related documents (in Internet Drafts directory unless\n    otherwise noted):\n        . draft-ietf-tls-ssl-3-00.txt\n        . draft-ietf-tls-ssl-mods-00.txt\n        . SSL Reference implementation available at\n          http://home.netscape.com/newsref/std/sslref.html\n        . draft-ietf-tls-xxx compression\n        . draft-murray-auth-ftp-ssl-00.txt\n        . draft-ietf-tls-kerb-cipher-suites-00.txt, reference implementation\n          available at ftp://mii.isi.edu/pub/ssl-krb/ssl-krb.tar.Z\n        . draft-ietf-tls-pathauth-00.txt\n        . HMAC: draft-ietf-ipsec-hmac-md5-01.txt\n        . Remote Passphrase: draft-petke-ext-intro-00.txt, draft-petke-mech-\n          00.txt, draft-petke-http-auth-scheme-00.txt, draft-petke-serv-\n          deity-protocol-00.txt\n        . SSL FAQ: http://www.consensus.com/security/ssl-talk-faq.html\n\n     TLS Working Group Chairman:\n        Win Treese <treese@openmarket.com>\n     TLS Editors:\n        Christopher Allen <christophera@consensus.com>\n        Tim Dierks <timd@consensus.com>\n     Area Director:\n        Jeff Schiller <jis@mit.edu>\n     Compression: rmonsour@earthlink.net\n     Certificate Storage (Working Group):\n        certstorage-wg@consensus.com, put 'subscribe' as the subject.\n     Compuserve Remote Passphrase:\n        gsb@csi.compuserve.com, r.petke@csi.compuserve.com\n     Cylink: johnmar@cylink.com Peter.Bolton@cylink.com\n     FTP: pfh@uk.ibm.com\n     Kerberos: ari.medvinsky@cybersafe.com\n     Scribes:\n        Rodney Thayer <rodney@sabletech.com>\n        Jonathan Zamick <jonathanz@consensus.com>\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "> > But the standard, mandatory-to-implement, universally-interoperable\n> > algorithm cannot be proprietary.\n>\n> Unfortunately, operations in the real world mean that there will never\n> be a universally-interoperable algorithm ...\n\nThe IETF requirement levels apply to implementations of a standard, and\nmandatory just means that the product must be capable of using a particular\nalgorithm. The goal is to encourage interoperability by ensuring that\nanyone who wishes to use the baseline capability will have it available\nif they have a TLS-compliant product.\n\nDetermining whether the baseline capability is enabled or not is a\npolicy matter to be decided by the user/sysadmin/SSO, and the IETF is\nexplicitly silent on policy.  The actual level of interoperability in the\nreal world will be determined by those configuration/policy decisions.\n\nIn theory, the working group could decide to have no mandatory algorithms\nand make all of them optional, but it might have trouble convincing the\nIESG to approve a document that did not define a required (lowest common\ndenominator?) baseline capability.  Given that some set of CipherSuites\nis designated as mandatory, that set should not include proprietary\nalgorithms when acceptable non-proprietaty alternatives exist.\n\n\n\n"
        },
        {
            "subject": "Re: CipherSuites for IETF-AlgorithmCompliant documen",
            "content": "David P. Kemp wrote:\n> \n> > > But the standard, mandatory-to-implement, universally-interoperable\n> > > algorithm cannot be proprietary.\n> >\n> > Unfortunately, operations in the real world mean that there will never\n> > be a universally-interoperable algorithm ...\n> \n> The IETF requirement levels apply to implementations of a standard, and\n> mandatory just means that the product must be capable of using a particular\n> algorithm. The goal is to encourage interoperability by ensuring that\n> anyone who wishes to use the baseline capability will have it available\n> if they have a TLS-compliant product.\n> \n> Determining whether the baseline capability is enabled or not is a\n> policy matter to be decided by the user/sysadmin/SSO, and the IETF is\n> explicitly silent on policy.  The actual level of interoperability in the\n> real world will be determined by those configuration/policy decisions.\n> \n> In theory, the working group could decide to have no mandatory algorithms\n> and make all of them optional, but it might have trouble convincing the\n> IESG to approve a document that did not define a required (lowest common\n> denominator?) baseline capability.  Given that some set of CipherSuites\n> is designated as mandatory, that set should not include proprietary\n> algorithms when acceptable non-proprietaty alternatives exist.\nHow ever I got your service,it was a mistake. Please remove it I'm not\nreading it and I don't want to read it's only messing up my email. Thank\nyou and I hope this is goodby.\n\n\n\n"
        },
        {
            "subject": "Standardized key generation using PRF",
            "content": "Ref:  Your note of Mon, 16 Dec 1996 15:57:39 -0800 (attached)\n\nDan Simon writes:\n >\n > Standardized key generation using PRFs\n >\n > Hugo Krawczyk recently suggested to the WG on this list that an explicit\n > PRF primitive be introduced into the spec, so that the protocol could be\n > based on an easily replaceable function whose assumed properties would\n > be clearly defined and well understood.  Currently, there's an\n > implicitly defined PRF in the spec, used for master secret and key block\n > generation.  It has the following structure:\n >\n > f(k,x) =\n > MD5(k + SHA('A' + k + x)) +\n > MD5(k + SHA('BB' + k + x)) +\n > MD5(k + SHA('CCC' + k + x)) + [...];\n >\n > This function (with the pre-master secret as k and x derived from the\n > client's and server's random challenges) is used to generate the master\n > secret; the same thing is done (with the master secret as k) to generate\n > the key block from which encryption and MAC keys are taken.  The\n\nI am proposing for use in Oakley (IPSEC) the following way to derive arbitrarily\nlong keys from a given \"seed key\" K (in the above example of TLS the seed key\nis the pre-master key). We use a generic function which we denote PRF\n(for pseudorandom function). Specific realizations of this generic function\ncan be achieved through the use of keyed hash functions (e.g. HMAC-SHA1)\nor block ciphers (e.g. 3DES, IDEA, etc) in CBC-MAC mode.\n(In general, a pseudorandom function is a keyed cryptographic function\nwhose output is unpredictable to any adversary that may know the input\nto the function but not the secret key.)\n\nA key is derived as:\n\nK1 = PRF(K, input)\n\nwhere K is the key to the pseudorandom function (or seed key) and 'input'\nis some value (can be public, secret, or mixed) that is known to any party\nthat needs to compute K1. (In the above example of Dan: input = x ).\n\nIf the output length of PRF is enough for the required keying material we\nstop with K1.  Otherwise we obtain more keys by\n\nK2 = PRF(K, K1 + input)  /* here '+' denotes concatenation */\nK3 = PRF(K, K2 + input)\nK4 = PRF(K, K3 + input)\nK5 = ...\n\nIn this way the variability of the total input to the function for two\ndifferent Ki's  is very significant and still the compromise of one key Ki\ndoes not mean the compromise of another Kj as long as K itself is not\ncompromised. It is not clear that leaving 'input' in all the computations\nis necessary but since 'input' usually contains some extra randomness (e.g.,\nchallenges) and sometimes even some secrecy then I prefer to have it there.\n\nIf what is needed is just one single long key LK, it will be derived as above\nby defining LK = K1+ K2 + K3 +...\n\nNotice that there is nothing new about such an iterative approach to\nthe generation of pseudorandom numbers. A similar approach is used in many\npseudorandom generators (e.g., ANSI X9.17 based on DES or FIPS-186 based\non SHA).\n\nFor the sake of defining a default PRF for TLS one can choose\nHMAC-SHA1. Other candidates like 3DES can be considered as well.\n\nFinally I agree completely with Dan's paragraph below.\n\n >\n > As well as standardizing the key derivation process, this change to a\n > uniform PRF-based method would encourage implementers to make the PRF\n > pluggable, allowing more secure or more efficient functions to replace\n > the current one in the future as needed.  (In fact, we might consider\n > switching to a better PRF immediately, if we are already breaking\n > backward compatibility by changing HMAC.)  Ideally the current cipher\n > suites would either implicitly or explicitly specify the current default\n > PRF, so that additional PRF options could be added, if necessary, simply\n > by adding new cipher suites.\n >\nHugo\n\n\n\n"
        },
        {
            "subject": "Additional suggested cleanups for TL",
            "content": "Ref:  Your note of Tue, 17 Dec 1996 12:47:50 -0500 (attached)\n\nDavid P. Kemp writes:\n\n >\n > I agree completely, and support the PRF proposals from Dan and Hugo.\n >\n > Hugo also mentioned some other topics:\n >\n >  1) The form of the PRF used by IPSEC, which uses an appended one-up\n >     counter to generate successive key blocks, is not optimal.\n\nI addressed this issue in my previous note\n\n >\n >  2) Mixing MD5 and SHA in a single ad-hoc function probably doesn't\n >     buy anything because it is difficult to imagine a situation in\n >     which SHA is broken but MD5 remains sound.\n >\n > This sounds reasonable, and I'd support using a \"better PRF\" based\n > on non-mixed HMAC-SHA.\n\nThis is more than just imagination, it is the result of our analysis\nof HMAC.\n\nIf one uses HMAC with SHA and MD5 mixed, say,\nMD5(K XOR opad + SHA(K XOR ipad + data))\nthen if SHA is broken as a \"weak collision resistant function\" (see our\nCrypto'96 paper) OR if the compression function of MD5 (keyed through its\nIV) is broken as a pseudorandom function, then no analytical security is\nleft to back the construction.  In this sense this mixed construction\ngives you the security of the weaker among the two functions.\nThus, use SHA for both iterations!\n\nNote: This is to be contrasted with the use of both SHA and MD5 to hash data\nbefore applying digital signatures.\nSomething like SIG(SHA(data)+MD5(data)) CANNOT be weaker than just\nSIG(SHA(data)).\nBut the above case with PRF is different!\n\n >\n >  3) For integrity purposes (not for signatures!) it may be more secure\n >     to truncate the SHA output to 128 bits.\n >\n > Although the suggestion originally had nothing to do with security (it\n > was motivated by the desire to have the same size output for MD5 and\n > SHA), the idea that truncating keyed hash functions may improve their\n > robustness by hiding some state is intuitively appealing.  But I don't\n > know if there is enough of a theoretical basis yet to suggest using\n > HMAC-SHA-128.\n\nThere is no definitive theoretical answer here.\nIf you read Preneel-van OOrschott (Crypto'95) you'll\nsee some concrete advantages of truncation in the case\nof specific attacks.\nActually, truncation of MAC functions (eg based on DES)\nis an old practice.\nStill this is not an absolute proof that truncation must help\nin the case of HMAC.\nGiven all the evidence and well-educated guesses,\nI RECOMMEND for the case of HMAC-SHA1 going from 160 bits to 128 bits.\n(This is defined in the upcoming RFC on HMAC as HMAC-SHA1-128)\n\nNOTE: do not confuse this case with truncation of unkeyed hash functions\nwhere truncation weakens the function significantly against birthday\nattacks. The case of MAC is different. Actually [PV] show that in some\nsense truncation of MAC helps against birthday attack (sounds confusing\nbut is true).\n\nHugo\n\n >\n\n\n\n"
        },
        {
            "subject": "Additional suggested cleanups for TL",
            "content": "Ref:  Your note of Tue, 17 Dec 1996 11:17:25 -0800 (attached)\n\nPhilip L. Karlton writes:\n >\n > >  2) Mixing MD5 and SHA in a single ad-hoc function probably doesn't\n > >     buy anything because it is difficult to imagine a situation in\n > >     which SHA is broken but MD5 remains sound.\n >\n > I have a pretty good imagination. :-)\n\nI am paid to have imagination...\nAs explained in a  previous message, this is not an issue of wild\nimagination. I advise against mixing of MD5 and SHA in HMAC based on\nthe analytical results that we have on these functions, and everything\nwe know about the comparative strength of SHA vs MD5.\n\n >\n > Another issue concerns the MAC for the Finished messages. There was MUCH\n > discussion about whether they should be constructed like HMAC rather\n > than the ad hoc algorithm that was chosen. The tradeoffs are fairly\n > simple.\n >\n >    pro) Using HMAC is more secure (probably).\n >\n >    con) The server has to retain the entire handshake until it\n > can compute the master_secret. The storage requirements\n > for heavily used secure servers could be prohibitive.\n > (Some information, e.g. the server's certificate chain\n > is probably constant across all handshakes; and that\n > helps a little.)\n\nI will not get into the discussion of whether retaining the entire handshake\ndata until master_secret is computed is a real problem or not.\nIf it is decided that it is not a real problem just go with HMAC on\nthe full handshake data.\nIf it is decided that it is a problem then it still does not justify going\nto ad-hoc constructions.\n\nJust define that you compute\nMAC(master_secret, HASH(handshake_messages+Sender))\n\nwhere HASH is a plain (unkeyed) hash function , e.g. SHA.\nIn this case you can still use the generic specification with MAC\n(and whatever realization of MAC you choose to use),\nand you also make clear that you authenticate  HASH(handshake_messages+Sender)\nrather than the full handshake_messages. (Which means that you assume your HASH\nto be collsion-resistant).\n\nAs for computing two MAC's, one based on SHA and one on MD5, you can still\nchoose to do that. Though, it will be probelmatic to  define using a single\ngeneric MAC notation.\nAs Dan Simon said, if you do so you MUST use two different keys for\neach of the MAC algorithms.\n\nI personally believe that this is not worth the complexity though\nconcatenating -- as opposed to mixing -- two MACs cannot be weaker than\ndoing only one (at least if you use two independent keys to key the MACs).\n\nHugo\n\n >\n > PK\n > --\n > Philip L. Karltonkarlton@netscape.com\n > Principal Curmudgeonhttp://www.netscape.com/people/karlton\n > Netscape Communications Corporation\n >\n >     Everything should be made as simple as possible, but not simpler.\n > -- Albert Einstein\n >\n\n\n\n"
        },
        {
            "subject": "Re: Additional suggested cleanups for TL",
            "content": "HUGO@watson.ibm.com wrote:\n\n> I will not get into the discussion of whether retaining the entire handshake\n> data until master_secret is computed is a real problem or not.\n\nAs I said before, I think this is the main discussion to have. The costs\ncan be considerable; maybe they just have to be paid, but that decision\nshould not be taken lightly.\n\n> If it is decided that it is not a real problem just go with HMAC on\n> the full handshake data.\n\nI concur.\n\n> If it is decided that it is a problem then it still does not justify going\n> to ad-hoc constructions.\n> Just define that you compute\n> MAC(master_secret, HASH(handshake_messages+Sender))\n\nTo a a certain extent, this is also an ad hoc construction. :-(\n\n> where HASH is a plain (unkeyed) hash function , e.g. SHA.\n> In this case you can still use the generic specification with MAC\n> (and whatever realization of MAC you choose to use),\n> and you also make clear that you authenticate  HASH(handshake_messages+Sender)\n> rather than the full handshake_messages. (Which means that you assume your HASH\n> to be collsion-resistant).\n\n... which is something I am only willing to assume on even days. :-( One\nmitigating factor is that the collision would have to be computed in\nreal time (before the connection timed out) for a successful MITM\nattack.\n\n> As for computing two MAC's, one based on SHA and one on MD5, you can still\n> choose to do that.\n\nI would be more comfortable doing the concatenation of the two MACs as\nthe content of the finished messages.\n\n> Though, it will be probelmatic to  define using a single\n> generic MAC notation.\n\nThe notational inconvenience is secondary. The words can be clear enough\nso that independent implementations can interoperate.\n\n> As Dan Simon said, if you do so you MUST use two different keys for\n> each of the MAC algorithms.\n\nUsing 2 different derived keys (as opposed to the master secret) is\nindeed a better idea.\n\nPK\n--\nPhilip L. Karltonkarlton@netscape.com\nPrincipal Curmudgeonhttp://www.netscape.com/people/karlton\nNetscape Communications Corporation\n\n    Everything should be made as simple as possible, but not simpler.\n-- Albert Einstein\n\n\n\n"
        },
        {
            "subject": "Security &amp; Hackerscene pag",
            "content": "During the last days the site \"Security & Hackerscene\" has been\nexpanded. New sections specialized on intrusion detection, IP-spoofing,\n... will help you to protect your site from break-ins and will give you\nan insight into the latest methods and tricks used by hackers to break\ninto obvious secure computers. Furthermore many CERT advisories and\nother\nsecurity related text files were redesigned and are now available in\nHTML\nformat. You will also find links to the best information resources\n(files, e-zines, texts) on the net regarding Internet-Security.\n\nURL of the \"Security & Hackerscene\" site:\n\n    --------------------------------------------------------------\n       http://www.geocities.com/capecanaveral/3498/security.htm\n    --------------------------------------------------------------\n\nSome of the items you will find:\n\n+ IP-spoofing demystified\n+ Intrusion Detection Checklist\n+ CGI Security Holes\n+ How hackers cover their tracks\n+ Compromise FAQ\n+ Protecting Yourself from Password File Attacks\n+ The Ultimate Sendmail Hole List\n+ An Architectural Overview of UNIX Network Security\n+ Essential Security Information\n+ UNIX Backdoors\n+ UNIX System Security Issues\n+ Tips for Improving Your Security\n+ as well as files commonly found in the underground scene.\n\n\nI would be glad to receive your feedback.\n\n\n          Markus H|bner\n\n======================================================================\nE-Mail: matic@bau2.uibk.ac.at\nWWW:    http://bau2.uibk.ac.at/matic\nWorking as a freelance WEB-programmer and security-consultant.\n\n\n\n"
        },
        {
            "subject": "2ND ANNOUNCEMENT: ISOC 97 SYMP NETWORK &amp; DISTRIBUTED SYSTEM SECURIT",
            "content": "PLEASE NOTE THE EARLY REGISTRATION AND HOTEL ROOM AVAILABILITY AND SPECIAL \nRATES DEADLINES ARE APPROACHING!!  RESERVATIONS AT THE PRINCESS RESORT\nMUST BE MADE NO LATER THAN JAN 13TH FOR THE GOVERNMENT RATE, AND NO LATER\nTHAN JAN 20TH FOR THE REDUCED GROUP RATE.  EARLY REGISTRATION FOR THE\nSYMPOSIUM MUST BE POSTMARKED NO LATER THAN JAN 22ND.\n\n---------------------------------------------------------------------------\n\n                 THE INTERNET SOCIETY 1997 SYMPOSIUM ON\n                 NETWORK AND DISTRIBUTED SYSTEM SECURITY\n                              (NDSS '97)\n\n                          10-11 FEBRUARY 1997\n\n            SAN DIEGO PRINCESS RESORT, SAN DIEGO, CALIFORNIA\n\n\n  This fourth annual symposium will bring together researchers,\n  implementors, and users of network and distributed system security\n  technologies to discuss today's important security issues and\n  challenges.  It will provide a mix of technical papers and panel\n  presentations that describe promising new approaches to security\n  problems that are practical, and to the extent possible, have\n  been implemented.  We hope to foster the exchange of technical\n  information and encourage the Internet community to deploy\n  available security technologies and develop new solutions to\n  unsolved problems.\n\nWHY YOU SHOULD ATTEND\n\n  The use of the Internet is rapidly growing and expanding into\n  all aspects of our society.  Commercial organizations are coming\n  under increasing pressure to make their services available on-line.\n  This in turn is increasing the need for rapid and widespread\n  deployment of usable and effective network and distributed system\n  security technologies.  High visibility attacks on the Internet\n  underscore the vulnerabilities of the Internet and the need to\n  solve its security problems.  There is growing concern for securing\n  the network infrastructure itself.  Recent trends in software\n  distribution (such as Java and ActiveX technologies) have made\n  certain attacks easier to carry out.  Privacy has become an\n  important issue for the Internet.\n\n  NDSS '97 will bring together researchers, implementors, and users\n  of network and distributed system technologies to discuss today's\n  important security issues and challenges.  We have selected the\n  technical papers and panel presentations that describe promising\n  new approaches to security problems that are practical, and to\n  the extent possible, have been implemented.  Topics to be addressed\n  include Internet infrastructure and routing security, security\n  for the World Wide Web, Java and ActiveX security, cryptographic\n  protocols, public key management, and protection of privacy.\n\n  The symposium will have a positive impact on the state of Internet\n  security.  You will have the opportunity to actively participate\n  in the dialog.  Ask questions of the speakers, raise your important\n  issues during the panel sessions, and let other participants know\n  of your requirements, observations, and experience in this\n  important area.  We hope to encourage the wide-scale deployment\n  of security technologies and to promote new research that can\n  address the currently unmet security needs of the Internet\n  community.\n\nCONTENTS\n\n  Preliminary Program\n  Organizing Committee\n  San Diego Princess Resort\n  Registration Information\n  Registration Form\n\n---------------------------------------------------------------------------\n\n                 P R E L I M I N A R Y   P R O G R A M\n\nSUNDAY, FEBRUARY 9\n\n6:00 P.M. - 8:00 P.M.\nRECEPTION\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\nMONDAY, FEBRUARY 10\n\n7:30 A.M.\nCONTINENTAL BREAKFAST\n\n8:30 A.M.\nOPENING REMARKS\n\n9:00 A.M.\nSESSION 1: THINGS THAT GO BUMP IN THE NET\nChair: Stephen T. Kent (BBN Corporation, USA)\n\n  Experimental Results of Covert Channel Elimination in One-Way\n  Communication Systems, Nick Ogurtsov, Hilarie Orman, Richard\n  Schroeppel, Sean O'Malley, and Oliver Spatscheck (University\n  of Arizona, USA)\n\n  Blocking Java Applets at the Firewall, David M. Martin Jr.,\n  Sivaramakrishnan Rajagopalan and Aviel D. Rubin (Bellcore, USA)\n\n  Continuous Assessment of a Unix Configuration: Integrating\n  Intrusion Detection & Configuration Analysis, Abdelaziz Mounji\n  and Baudouin Le Charlier (Institut D'Informatique, Namur,\n  BELGIUM)\n\n10:30 A.M.\nBREAK\n\n11:00 A.M.\nSESSION 2: PANEL: SECURITY OF DOWNLOADABLE EXECUTABLE CONTENT\nChair: Aviel Rubin (AT&T Research Labs, USA)\nPanelists: Li Gong (JavaSoft, USA), Jim Roskind (Netscape, USA),\nEdward W. Felten (Princeton University, USA) and Peter G. Neumann\n(SRI International, USA)\n\n12:30 NOON\nLUNCH\n\n2:00 P.M.\nSESSION 3: PROTOCOL IMPLEMENTATION AND ANALYSIS\nChair: Christoph Schuba (Purdue University, USA)\n\n  An Interface Specification Language for Automatically Analyzing\n  Cryptographic Protocols, Stephen H. Brackin (Arca Systems, USA)\n\n  Probable Plaintext Cryptanalysis of the IP Security Protocols,\n  Steven M. Bellovin (AT&T Research, USA)\n\n  Misplaced Trust: Kerberos Version 4 Session Keys, Bryn Dole (Sun \n  Microsystems), Steve Lodin (Delco Electronics), and Eugene Spafford\n  (Purdue University, USA)\n\n3:30 P.M.\nBREAK\n\n4:00 P.M.\nSESSION 4: PANEL: SECURITY OF THE INTERNET INFRASTRUCTURE\nChair: Russ Mundy (Trusted Information Systems, USA)\nPanelists: Paul Lambert (Oracle, USA), Jeff Schiller (MIT, USA), \nOlafur Gudmundsson (Trusted Information Systems, USA)\n\n7:00 P.M.\nDINNER BANQUET\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n\nTUESDAY, FEBRUARY 11\n\n7:30 A.M.\nCONTINENTAL BREAKFAST\n\n8:30 A.M.\nSESSION 5: ROUTING SECURITY\nChair: Hilarie Orman (DARPA, USA)\n\n  Securing the Nimrod Routing Architecture, Karen E. Sirois and\n  Stephen T. Kent (BBN Corporation, USA)\n\n  Securing Distance-Vector Routing Protocols, Bradley R. Smith,\n  Shree Murthy and J.J. Garcia-Luna-Aceves (University of California\n  Santa Cruz, USA)\n\n  Reducing the Cost of Security in Link-State Routing, R. Hauser,\n  A. Przygienda and G. Tsudik (IBM and USC/ISI, USA)\n\n10:00 A.M.\nBREAK\n\n10:30 A.M.\nSESSION 6: SECURITY FOR THE WORLD WIDE WEB\nChair: Win Treese (OpenMarket, USA)\n\n  Securing Web Access with DCE, Brian C. Schimpf (Gradient \n  Technologies, USA)\n\n  PANEL: SECURITY FOR THE WORLD WIDE WEB\n  Chair: Win Treese (OpenMarket, USA)\n\n12:00 A.M.\nLUNCH\n\n1:30 P.M.\nSESSION 7: PUBLIC KEY MANAGEMENT\nChair: Jonathan Trostle (CyberSafe, USA)\n\n  Hierarchical Organization of Certification Authorities for\n  Secure Environments, Lourdes Lopez and Justo Carracedo\n  (Universidad Politecnica de Madrid, SPAIN)\n\n  Trust Models in ICE-TEL, Andrew Young and Nada Kapidzic Cicovic\n  (Univeristy of Salford, UNITED KINGDOM)\n\n  Distributed Authentication in Kerberos Using Public Key\n  Cryptography, Marvin Sirbu and John Chung-I Chuang (Carnegie \n  Mellon University, USA)\n\n3:00 P.M.\nBREAK\n\n3:30 P.M.\nSESSION 8: PANEL: WEB PRIVACY AND ANONYMITY\nChair: Clifford Neuman (USC Information Sciences Institute, USA)\n\n\n---------------------------------------------------------------------------\n\n                O R G A N I Z I N G   C O M M I T T E E\n\nGENERAL CHAIR\n  David Balenson, Trusted Information Systems\n\nPROGRAM CHAIRS\n  Clifford Neuman, USC Information Sciences Institute\n  Matt Bishop, University of California at Davis\n\nPROGRAM COMMITTEE\n  Steve Bellovin, AT&T Research\n  Tom Berson, Anagram Laboratories\n  Doug Engert, Argonne National Laboratory\n  Warwick Ford, Verisign\n  Richard Graveman, Bellcore\n  Li Gong, JavaSoft\n  Burt Kaliski, RSA Laboratories\n  Steve Kent, BBN Corporation\n  Tom Longstaff, CERT\n  Doug Maughan, National Security Agency\n  Dan Nessett, 3Com Corporation\n  Hilarie Orman, DARPA/ITO\n  Michael Roe, University of Cambridge\n  Christoph Schuba, Purdue University\n  Jonathan Trostle, CyberSafe\n  Theodore Ts'o, Massachusetts Institute of Technology\n  Doug Tygar, Carnegie Mellon University\n  Vijay Varadharajan, University of W. Sydney\n  Roberto Zamparo, Telia Research\n\nPUBLICATIONS CHAIR\n  Steve Welke, Institute for Defense Analyses\n\nLOCAL ARRANGEMENTS CHAIR\n  Thomas Hutton, San Diego Supercomputer Center\n\nREGISTRATIONS CHAIR\n  Torryn Brazell, Internet Society\n\nSTEERING GROUP\n  Internet Research Task Force, Privacy and Security Research Group\n\nSPONSORED BY THE INTERNET SOCIETY\n  Donald M. Heath, President & CEO\n  Martin Burack, Executive Director\n\n\n---------------------------------------------------------------------------\n\n           S A N   D I E G O   P R I N C E S S   R E S O R T\n\nLOCATION\n\n  The Symposium venue is the San Diego Princess Resort, a tropical\n  paradise on a forty-four acre island in Mission Bay, ten minutes\n  from the international airport.  Lush gardens landscaped with\n  hundreds of species of tropical and subtropical plants are\n  always ablaze with color and perfect for themed group events.\n  Charming pathways wander among sparkling waterfalls, across\n  quaint footbridges and sleepy lagoons filled with water lilies\n  and waterfowl.  A white sand beach curves around the island\n  for over a mile, and the award-winning grounds encompass five\n  swimming pools and six lighted tennis courts.\n\n  Spouses and family members can catch a convenient Harbor Hopper\n  for a quick trip to Sea World.  Plan to visit La Jolla, the world\n  famous San Diego Zoo or Mexico, only 30 minutes by car or Trolley.\n\nHOUSING INFORMATION\n\n  We have reserved a special block of sleeping rooms at the San Diego\n  Princess Resort at the following rates:\n\n      Lanai Patio Rooms           $ 81*\n      Lanai Garden Rooms          $114\n\n  * This represents the Government Rate for San Diego.  A limited \n    number of rooms are available at this rate.  Reservations must \n    be made no later than January 13, 1997.  You must present a \n    valid government id upon check-in.\n\n  Based on room type and space availability, the special group\n  rates are applicable two days prior to and two days after the\n  symposium.  Current Room Tax is 10.5%.\n\n  Check-in availability cannot be committed prior to 4:00 p.m.\n  Check-out time is 12:00 noon. The San Diego Princess Resort\n  will make every effort to accommodate any early arrivals, so\n  make sure you give them your arrival time when you make your\n  reservation.\n\nTO MAKE A RESERVATION\n\n  Contact the San Diego Princess Resort at +1-800-344-2626\n  (+1-619-274-4630 if outside the United States).  To receive\n  the special group rates, reservations must be made no later\n  than January 20, 1997.  To receive the special goverment \n  rate, you must make your reservation by January 13, 1997.\n\nCLIMATE\n\n  February weather in San Diego is normally very pleasant.  Early\n  morning temperatures average 55 degrees while afternoon\n  temperatures average 67 degrees.  Generally, a light jacket or\n  sweater is adequate, although, occasionally it rains.\n\n---------------------------------------------------------------------------\n\n            R E G I S T R A T I O N   I N F O R M A T I O N\n\nFEES                                      ISOC            Non-\n                                         Members         Member*\n  Early registration \n  (postmarked on/before Jan. 22)         $305            $345\n\n  Late registration                      $375            $415\n\nREGISTRATION INCLUDES\n\n  - Attendance      - Symposium Proceedings     - Two luncheons\n  - Reception       - Banquet                   - Coffee Breaks\n\n  * Non-Member fee includes one year Internet Society membership.\n\nFOR MORE INFORMATION \n\n  Contact Carol Gray at the Internet Society at +1-703-648-9888 \n  or send E-mail to Ndss97reg@isoc.org.\n\nWEB PAGE\n\n  Additional information about the symposium and San Diego, plus\n  on-line registration, are available via the Web at:\n\n            http://www.isoc.org/conferences/ndss97\n\nSPONSORSHIP OPPORTUNITIES AVAILABLE!\n\n  Contact Torryn Brazell at the Internet Society at +1-703-648-9888 \n  or send E-mail to Ndss97reg@isoc.org.\n\n---------------------------------------------------------------------------\n\n                  R E G I S T R A T I O N   F O R M\n\nINTERNET SOCIETY SYMPOSIUM ON NETWORK AND DISTRIBUTED SYSTEM SECURITY\n10-11 FEBRUARY, 1997                       SAN DIEGO, CALIFORNIA, USA\n\nFill out this form and FAX it to NDSS'97 Registration at +1-703-648-9887,\nsend it via E-mail to Ndss97reg@isoc.org, or mail it to NDSS97,\n12020 Sunrise Valley Drive, Suite 210, Reston, VA, 20191, USA\n\nPERSONAL INFORMATION\n\n  __Mr __Ms __Mrs __Dr __Prof __M __Prof Dr __Dip Ing __Ing __Miss __Mlle\n\n  First Name: ________________________________  MI: ____________________\n\n  Family Name: ___________________________________  __Sr __Jr __II __III\n\n  Badge Name: __________________________________________________________\n  Please enter your name as you would like it to appear on your name tag.\n\nCONTACT INFORMATION\n\n  Title: _______________________________________________________________\n\n  Organization: ________________________________________________________\n\n  Street address: ______________________________________________________\n\n  ______________________________________________________________________\n\n  City: ________________________________________________________________\n\n  State/Province: ___________________________  Postal Code: ____________\n\n  Country: _____________________________________________________________\n\n  Telephone Number (work): _____________________________________________\n\n  Telephone Number (home): _____________________________________________\n\n  Fax Number: __________________________________________________________\n\n  E-mail address: ______________________________________________________\n\nSPECIAL NEEDS?  (Vegetarian meals, wheelchair access, etc?)\n\n  ______________________________________________________________________\n\n  ______________________________________________________________________\n\nAPPEAR ON REGISTRANTS LIST?\n\n  ___  Please check here if you would NOT like your name included \n       in the list of registrants.\n\nPAYMENT INFORMATION\n\n  All Payments must be in United States Dollars.\n\n  Conference Fee\n  --------------\n\n  If you are an Internet Society member, you are eligible for a\n  reduced conference registration fee.  Non-member symposium \n  attendees will receive a one year Internet Society membership \n  as part of the non-member registration fees.\n\n  Check one:                        On/Before        After\n                                    January 22    January 22\n                                    ----------    ----------\n  ___ Internet Society Member Fee   US$ 305.00    US$ 375.00\n\n  ___ Non-Member Fee                US$ 345.00    US$ 415.00\n\n  Method of Payment\n  -----------------\n\n  Payment must be received on/before February 7, 1997 or we will \n  be unable to pre-register you.\n\n  1. ___ Check.  Make payable to the Internet Society.  \n\n  2. ___ Credit Card. ___ American Express ___ Visa ___ Mastercard\n\n         Name on Credit Card: ____________________________________\n  \n         Credit Card Number: _____________________________________\n\n         Expiration Date: ________________________________________\n\n  3. ___ CyberCash.  Account Number: _____________________________\n\n  4. ___ First Virtual.  Account Number: _________________________\n\n  5. ___ Wire Transfer*\n\n         Bank ABA Number: 054000030\n         Account Number: Internet Society 148 387 10\n\n         Riggs National Bank of Virginia   \n         950 Herndon Parkway               \n         Herndon, VA  20171  USA\n\n         Wire Transfer Confirmation Number: ______________________\n\n         * Please process wire transfer before sending registration \n   form.\n\n  6. ___ U.S. Government Purchase Order*\n\n         P.O. Number: ____________________________________________\n\n         * Please fax or mail a copy of your purchase order along \n   with your registration form.\n\n  Cancellation Policy\n  -------------------\n\n  Refunds (less a $25 processing fee) will be issued for cancellations \n  received on/before February 7, 1997.  No refunds will be issued \n  after February 7, 1997.\n\n------------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Enterprise Security Workshop CF",
            "content": "      Call For Papers \n\n   Second International Workshop on Enterprise Security\n\n      June 18-20, 1997\n    Massachusetts Institute of Technology (MIT),\nCambridge, Massachusetts, USA\n\nCo-sponsored by the IEEE Computer Society and the\nConcurrent Engineering Research Center (CERC) at \n   West Virginia University\n           \n                          \n==============================================================================\nEnterprises are increasingly dependent on their information systems to\nsupport their business and workflow activities.  \nThere is a need for universal electronic connectivity to support \ninteraction and cooperation between multiple  organizations.  \nThis makes enterprise security and confidentiality more important, \nbut more difficult to achieve, as the multiple organizations may \nhave differences in their security policies and may have to interact \nvia an insecure Internet.  These inter-organizational enterprise systems \nmay be very large and so tools and techniques are needed\nto support the specification, analysis and implementation of security.\n\nThis workshop will focus on the problems and challenges relating to\nenterprise security in inter-organizational systems. We aim to bring\ntogether principal players from both the internetwork and enterprise\nsecurity community and will provide plenty of time for discussion.   Topics\nto be addressed include:\n\n- Internet/Intranet security\n        - Security infrastructure and protocols\n- Java Security\n- Specifying and Analyzing Enterprise Security Policy\n        - Role-Based Access Control\n        - Supporting enterprise security over the Internet\n        - Conflicts and harmonization of inter- and intra-organizational\n             Security\n        - Distributed Database Security\n        - Secure Transactions\n        - Security in Workflow Process\n        - Object-Oriented and CORBA Security\n        - Secure Applications and Environments\n        - Integrating Heterogeneous Security Environments\n        - Managing inter-organizational Enterprise Security\n- Internet Security protocols\n- Security Algorithms\n\nThis workshop will be part of the IEEE Sixth Workshops on Enabling\nTechnologies: Infrastructure for Collaborative Enterprises (WET-ICE\n96) organized by the Concurrent Engineering Research Center (CERC)/\nWest Virginia University.\n\nImportant Dates:\n================\nPapers DueMarch 25, 1997\nPanel ProposalsMarch 18, 1997\nAuthors notified of acceptance  April 21, 1997\nWorkshopJune 18-20, 1997\nCamera ReadyJune 28, 1997\n\nINFORMATION FOR AUTHORS OF PAPERS TO BE INCLUDED IN THE PROCEEDINGS \n===================================================================\nMail six copies of an original (not submitted or published elsewhere)\npaper (double-spaced) of 3000-5000 words to one of the PC co-chairs. \nInclude the title of the paper, the name and affiliation of each author, a\n150-word abstract and no more than 8 keywords. The name, position,\naddress, telephone number, and if possible, fax number and e-mail\naddress of the author responsible for correspondence of the paper must\nbe included.\n\n\nAn e-mail submission in postscript format will be accepted.\n\nINFORMATION FOR PANEL ORGANIZERS \n================================\nSend six copies of panel proposals to one of the PC co-chairs. \nInclude the title, a 150-word scope statement, proposed session chair and\npanelists and their affiliations, the organizer's affiliation,\naddress, telephone and fax number, and e-mail address.\n\nINFORMATION FOR AUTHORS OF POSITION PAPERS\n==========================================\nSend six copies of position paper of 2-3 pages to one of the PC\nco-chairs. Include the title of the paper, the name and affiliation of\neach author, a 150-word abstract and no more than 8 keywords. The\nname, position, address, telephone number, and if possible, fax number\nand e-mail address of the author responsible for correspondence of the\npaper must be included. An accepted position paper will get less\npresentation time than full paper.  \n\nWorkshop General Chair and Organizer\n====================================\nYahya Al-Salqan, Ph.D.\nSun Microsystems\n\nalsalqan@eng.sun.com\n\nProgram Committee\n=================\n\nProgram Committee Co-Chairs\n==========================\nBarbara C. Davis\nDirector of Technology\nThe Applied Knowledge Group\n231 Market Place, #315\nSan Ramon, CA  94583-2785\nUSA\n\nTel. (888) 442-2785\nFAX  (510) 275-9695\nbcdavis@appliedknowledge.com\n\nDouglas Moughan\nNational Security Agency, R23\n9800 Savage Rd.\nFt. Meade, Maryland 20755-6000\nUSA\n\nwdm@tycho.ncsc.mil\n\n\n\nWorkshop Program Committee (Partial List):\n==========================================\nAbdallah Abdallah, Birzeit University, Jerusalem\nTakasi Arano, NTT Corp, Japan\nGermano Caronni, ETH-Zurich, Switzerland\nTaher ElGamal, Netscape Corp., USA\nStephen Farrell, Software and Systems Engineering, Ireland\nTakeo Hamada, Fujitsu, Japan\nMatthias Hirsch, BSI (Federal Department of Security in the Information\nTechnology-Germany\nCynthia L Musselman, Sandia Lab, USA\nLisa Pretty, Certicom Corp., Canada\nJeffrey Parrett, LLNL, USA\nSumitra Reddy, West Virginia University, USA\nNahid Shahmehri, Linkoping University, Sweden\nMorris Sloman, Department of Computing: Imperial College, UK\nBadie Taha, Al-Quds University, Jerusalem\nRobert Thomys, BSI (Federal Department of Security in the Information\nTechnology-Germany\nTatu Ylonen, SSH Communication Security, Finlad\nNick Zhang, EIT, USA\n\n\n\nInternet Hot-line\n================= \n\nInformation on Enterprise Security Workshop may be obtained through\nthe WWW using the URL http://www.cerc.wvu.edu/SECWK/ \n\nFor more information on WET-ICE'97, visit the URL: \nhttp://www.cerc.wvu.edu/WETICE/WETICE97.html\n\nOne does not need to have a paper to attend the workshop.  \n\n\n\n"
        },
        {
            "subject": "Re: Any SSL3 DH Key Exchange servers out there",
            "content": "> \n> Anyone else want to see non-encrypted flavors get defined, like\n> a SSL_DHE_DSS_WITH_NULL_SHA flavor ??  Purely for parity with the\n> flavors relying on RSA certs for key exchange?\n\nAbsolutely.  For many of the applications I'm concerned with,\nauthentication and integrity protection are far more important\nthan confidentiality.\n\nIt's true that \"mix and match\" CipherSuites are cause for concern and\nneed to be carefully analyzed.  And, as Wagner&Schneier points out,\nSSLRef 3.0b1 (a beta version) failed to include a check for the change\ncipher suite message, which could cause a problem with\nauthentication-only CipherSuites but not with encrypted CipherSuites.\nThis was an implementation error, not a protocol specification error,\nbut I agree with W&S that the protocol specification should be changed\nto be more resistant to implementation errors.\n\nIn any case, that particular problem affects RSA_WITH_NULL and\nDSS_WITH_NULL equally, so as long as RSA_WITH NULL exists, there shouldn't\nbe a problem with the addition of both SSL_DHE_DSS_WITH_NULL_SHA and\nSSL_KEA_WITH_NULL_SHA to the TLS specifications.\n\n\n\n"
        },
        {
            "subject": "Re: Any SSL3 DH Key Exchange servers out there",
            "content": "At 5:43 AM -0800 1/28/97, David P. Kemp wrote:\n>It's true that \"mix and match\" CipherSuites are cause for concern and\n>need to be carefully analyzed.  And, as Wagner&Schneier points out,\n>SSLRef 3.0b1 (a beta version) failed to include a check for the change\n>cipher suite message, which could cause a problem with\n>authentication-only CipherSuites but not with encrypted CipherSuites.\n>This was an implementation error, not a protocol specification error,\n>but I agree with W&S that the protocol specification should be changed\n>to be more resistant to implementation errors.\n\nBTW, that particular bug was fixed in SSLRef 3.0 final, and of course in\nSSL Plus. I suspect that there are a number of proprietary implementations\nthat have similar bugs.\n\nAlso, my belief is that the above \"implementation\" error will be covered\nwhen we release the new TLS draft.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Handling NULL key exchange for NULL_ ciphersuit",
            "content": "What is the correct way to interpret handling of the NULL ciphersuite for\nkey exchange?\n\nThe TLS spec (excerpts provided below) appears to be vague in its\ndescription of how key exchange handling is done if the NULL ciphersuite is\nnegotiated. I don't recall seeing any statement indicating it is illegal to\nnegotiate a NULL ciphersuite. My assumption is the NULL ciphersuite could\nbe negotiated anytime it is legal to negotiate any other ciphersuite (its\nregular).\n\nThe spec identifies the ServerKeyExchange and ServerCertificate messages\nas being optional but section 6.4.3 does not indicate which message (if\nany) should be sent for NULL ciphersuite. Is it an empty KeyExchange\nmessage or just no message (key exchange or certificate)?\n\nSection 6.4.7 mandates the return of the ClientKeyExchange message but does\nnot describe the format of the message if the negotiated ciphersuite was\nNULL. There is an agrement for making the ClientKeyExchange message\noptional if the NULL ciphersuite was negotiated. Alternatively, the key\nexchange message could contain nothing as is the case for DH_RSA and DH_DSS\nkey exchange methods.\n\n\nThank You,\nNed Smith\nnsmith@ibeam.intel.com\n\n-----------------------------------------------------------------------\n6.4.3 Server key exchange message\n\n   When this message will be sent:\n\n   This message will be sent after the server certificate message (or\n   the server hello message, if the server certificate is not sent),\n   but before the server hello done message. The server key exchange\n   message may be sent before or after this message.\n\n   The server key exchange message is sent by the server only when the\n   server certificate message (if sent) does not contain enough data to\n   allow the client to exchange a premaster secret. This is true for\n   the following key exchange methods:\n\n          RSA_EXPORT (if the public key in the server certificate is\n                      longer than 512 bits)\n          DHE_DSS\n          DHE_DSS_EXPORT\n          DHE_RSA\n          DHE_RSA_EXPORT\n          DH_anon\n\n   It is not legal to send the server key exchange message for the\n   following key exchange methods:\n\n          RSA\n          RSA_EXPORT (when the public key in the server certificate\n                      is less than or equal to 512 bits in length)\n          DH_DSS\n          DH_RSA\n\n6.4.7 Client key exchange message\n\n   When this message will be sent:\n\n   This message is always sent by the client. It will immediately\n   follow the client certificate message, if it is sent, or the\n   no_certificate alert, if a certificate was requested but an\n   appropriate one was not available. Otherwise it will be the first\n   message sent by the client after it receives the server hello done\n   message.\n\n   Meaning of this message:\n\n   With this message, the premaster secret is set, either though direct\n   transmisson of the RSA-encrypted secret, or by the transmission of\n   Diffie-Hellman parameters which will allow each side to agree upon\n   the same premaster secret. When the key exchange method is DH_RSA or\n   DH_DSS, client certification has been requested, and the client was\n   able to respond with a certificate which contained a Diffie-Hellman\n   public key whose parameters (group and generator) matched those\n   specified by the server in its certificate, this message will not\n   contain any data.\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "Ned Smith wrote:\n> \n> What is the correct way to interpret handling of the NULL ciphersuite\n> for key exchange?\n> \n> The TLS spec (excerpts provided below) appears to be vague in its\n> description of how key exchange handling is done if the NULL\n> ciphersuite is negotiated. I don't recall seeing any statement\n> indicating it is illegal to negotiate a NULL ciphersuite. My\n> assumption is the NULL ciphersuite could be negotiated anytime it is\n> legal to negotiate any other ciphersuite (its regular).\n\nI assume you mean TLS_NULL_WITH_NULL_NULL.  Although the spec does not\nexplicitly forbid negotiating to this cipher suite, it should.  If an\nimplementation allows negotiation to this cipher suite, it is open to\na rollback attack.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Compatible extension for peer-topeer authentication in TL",
            "content": "The inherent assumption in TLS is that the negotiated\nsession is for Client to Server communication; the\nServer can force the Client to authenticate (to protect\nits assets), but the Server can unilaterally decide to \nbe anonymous.\n\nWe (Intel, but really, the wider Internet Telephony commnunity)\nplan to use TLS as the foundation for secure person-to-person\ncommunication. This communication is inherently peer-to-peer; a\nuser would like the same control over authentication whether \nthey are caller (TLS client) or callee (TLS server). And I am \nsure there will be many other peer-to-peer applications when \nall is said and done.\n\nI believe TLS can be simply extended in a compatible manner to\nsuport a peer-to-peer relationship.\n\nBasically, the ClientHello would be extended with an optional\nCertificateRequest structure. (Which, obviously, a down-level\nclient would not include). An up-level Server would respond \nwith an appropriate certificate or a no_certificate Alert. \nA down-level Server would ignore the CertificateRequest (as \nextraneous octets on the end of an otherwise valid ClientHello; \nsee Forward Compatibility note at the end of 6.4.1.2), \nand would proceed as per the current definition. If it does not \nsend a certificate, or sends one that does not conform to the \n(ignored) request, the Client may send an Alert. Assuming success, \nthe Server can then proceed as usual (possibly, with its own\nCertificateRequest).\n\nDetails\n-------\n\nSection 6.3: paragraph beginning: \"Following the hello messages....\"\n             [last paragraph on page 24], becomes:\n\nFollowing the hello messages, if the client has requested a server \ncertificate, the server must send either a suitable certificate or \na no-certificate alert. If the client has not requested a certificate, \nthe server may send a certificate (or not) at its discretion.\nThe server may request a certificate from the client, if client \nauthentication is desired. Additionally, a server key exchange \nmessage may be sent, if it is required (e.g., if no certificate was \nsent, or if the certificate is for signing purposes only). Now the....\n\nSection 6.4.1.2: Client hello\n[page 29]\n\nAdd an optional CertificateRequest structure to the ClientHello message:\n\nenum {False(0), True(1), (255)} Bool:\nstruct {\n    ProtocolVersion client_version;\n    Random random;\n    SessionID session_id;\n    CipherSuite cipher_suites<2..2^16-1>;\n    CompressionMethod compression_methods<1..2^8-1>;\n    Bool certificate_request;\n    select (certificate_request) {\n        case False: stuct {};\n        case True:  CertificateRequest;\n    } body;\n} ClientHello;\n\n6.4.2 Server Certificate\n[page 31] \n\nWhen this message will be sent:\n \nThe server must send a certificate whenever the agreed-upon key\nexchange method is not an anonymous one, or the client requests \na certificate. If the client has requested a certificate, and the\nserver has no suitable certificate, it must send a no-certificate\nalert instead. This alert is only a warning, however, the client \nmay respond with a fatal handshake alert if server authentication \nis required.\n\n6.4.4 Certificate Request\n[page 35]\n   \nWhen this message will be sent:\n\nThe server can optionally request a certificate from the client, \neither for key exchange purposes or to force client authentication.\n\nThis message.........when legal.\n\nStructure of this message:\n\nenum  {\n     rsa_sign(1), dss_sign(2), rsa_fixed_dh(3), dss_fixed_dh(4),\n     rsa_ephemeral_dh(5), dss_ephemeral_dh(6), (255)\n} CertificateType;\n\nopaque DistinguishedName<1..2^16-1>;\n\nstruct  {\n     CertificateType certificate_types<1..2^8-1>;\n     Distinguishedname certificate_authorities<3..2^16-1>;\n} CertificateRequest;\n\ncertificate_types\n     This field is a list of the types of certificates requested,\n     sorted in order of preference.\n\nDelete the last Note on this page.\n\nA.4.1 Hello messages\n[page 45]\n\nenum {False(0), True(1), (255)} Bool:\nstruct {\n    ProtocolVersion client_version;\n    Random random;\n    SessionID session_id;\n    CipherSuite cipher_suites<2..2^16-1>;\n    CompressionMethod compression_methods<1..2^8-1>;\n    Bool certificate_request;\n    select (certificate_request) {\n        case False: stuct {};\n        case True:  CertificateRequest;\n    } body;\n} ClientHello;\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "At 1:14 PM -0800 1/30/97, Tom Weinstein wrote:\n>Ned Smith wrote:\n>>\n>> What is the correct way to interpret handling of the NULL ciphersuite\n>> for key exchange?\n>>\n>> The TLS spec (excerpts provided below) appears to be vague in its\n>> description of how key exchange handling is done if the NULL\n>> ciphersuite is negotiated. I don't recall seeing any statement\n>> indicating it is illegal to negotiate a NULL ciphersuite. My\n>> assumption is the NULL ciphersuite could be negotiated anytime it is\n>> legal to negotiate any other ciphersuite (its regular).\n\nI believe this is the intent. I know that people have discussed negotiating\nNULL_WITH_NULL_NULL as an efficiency measure when implementations wish to\ntransmit data which is pre-encrypted and/or authenticated. For example, one\ncould consider an application which negotiated a TLS connection, exchanged\nsome control information, then transmitted a number of S/MIME messages.\nNegotating NULL_WITH_NULL_NULL would aid in performance. However, remember:\nthis might leave one open to attacks which altered the stream of messages\neither by replaying or deleting messages. For security, all communications\nshould be protected by a progressive MAC construction.\n\nI will clarify the spec: my understanding is that NULL_WITH_NULL_NULL\ndoesn't require a Certificate or Key exchange message from either end: as\nsuch, the negotiation would take the following form:\n\n      Client               Server\n   client hello       Includes the option of N_W_N_N\n                        server hello       Specifies N_W_N_N\n                         hello done\n     finished\nchange cipher spec\n                          finished\n                     change cipher spec\n\n>I assume you mean TLS_NULL_WITH_NULL_NULL.  Although the spec does not\n>explicitly forbid negotiating to this cipher suite, it should.  If an\n>implementation allows negotiation to this cipher suite, it is open to\n>a rollback attack.\n\nIt's not clear to me what you mean here, Tom. Since the original\nnegotiation of a connection occurs under NULL_WITH_NULL_NULL, I don't\nunderstand how a later re-negotiation on the same communications channel\ncould be less secure than a new connection. Which rollback attack do you\nmean? Cipher suites or SSL 2?\n\nNote: I do not recommend using NULL_WITH_NULL_NULL except unless you know\nexactly why you want to and you know for a fact that you understand your\nrisk model. It provides no security over plain TCP/IP and I wouldn't want\nanyone to think otherwise just because it's got \"TLS\" in the name.\n\n  - Tim\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "TLS status [Mea Maxima Culpa",
            "content": "Hello TLS friends.\n\nMany of you are no doubt wondering where the heck the TLS draft I promised\nyou is. Unfortunately, due to Christmas laziness and a double bucket-full\nof other work, work on the revised TLS draft as discussed here and at IETF\nin December hasn't proceeded as planned.\n\nHowever, I believe that the amount of work remaining is not large and thus\nfeel that rapid progress can be made. I will be able to resume work on the\ndraft early next week. Hopefully, I will have a further status update (or a\ndraft) for you by the end of that week, February 7.\n\nThanks for your understanding,\n - Tim\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "There is an argument that says that TLS_NULL_WITH_NULL_NULL should\ndefinitely be implemented in production TLS implementations.  It is useful\nfor troubleshooting.  Presumably such an implemenation would employ\nwarnings, blinking lights, sirens, loud warnings, extra user prompts, or\nwhatever it takes to ensure it was only used for testing.\n\nThis is the Internet, and this is the IETF.  We're supposed to be\ninterested in realistic deployable systems.  It should be possible for a\nbunch of smart people to build field-maintainable systems, using\ntechnologies such as TLS_NULL_WITH_NULL_NULL, in a safe and productive manner.\n\n(OK, all the crypto experts in the room can yell at me now.  I'm ready!)\n\n\n>Ned Smith wrote:\n>> \n>> What is the correct way to interpret handling of the NULL ciphersuite\n>> for key exchange?\n>> \n>> The TLS spec (excerpts provided below) appears to be vague in its\n>> description of how key exchange handling is done if the NULL\n>> ciphersuite is negotiated. I don't recall seeing any statement\n>> indicating it is illegal to negotiate a NULL ciphersuite. My\n>> assumption is the NULL ciphersuite could be negotiated anytime it is\n>> legal to negotiate any other ciphersuite (its regular).\n>\n>I assume you mean TLS_NULL_WITH_NULL_NULL.  Although the spec does not\n>explicitly forbid negotiating to this cipher suite, it should.  If an\n>implementation allows negotiation to this cipher suite, it is open to\n>a rollback attack.\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n\n--------\nRodney Thayer <rodney@sabletech.com>\nPGP Fingerprint: BB1B6428 409129AC  076B9DE1 4C250DD8\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "Tim Dierks wrote:\n> \n>> I assume you mean TLS_NULL_WITH_NULL_NULL.  Although the spec does\n>> not explicitly forbid negotiating to this cipher suite, it should. \n>> If an implementation allows negotiation to this cipher suite, it is\n>> open to a rollback attack.\n> \n> It's not clear to me what you mean here, Tom. Since the original\n> negotiation of a connection occurs under NULL_WITH_NULL_NULL, I don't\n> understand how a later re-negotiation on the same communications\n> channel could be less secure than a new connection. Which rollback\n> attack do you mean? Cipher suites or SSL 2?\n\nThe protocol explicitly forbids sending application data until after\nthe first handshake has completed.\n\nIf you renegotiate to a NULL_WITH_NULL_NULL cipher suite, nothing\nprevents an atacker from hijacking your connection at that point and\nsubstituting whatever data he wishes.  The Wagner-Schneier paper is\nvery clear about this.  If you are interested in sending preencrypted\ndata, you should negotiate down to something like RSA_WITH_NULL_SHA. \nThis still protects the integrity of your data while avoiding the\noverhead of encryption.\n\nAlso, if you allow NULL_WITH_NULL_NULL to be negotiated at the initial\nhandshake, nothing prevents an attacker from forcing you down to that\nciphersuite.  One possible approach would be to provide some application\nlayer mechanism for enabling and disabling the NULL_WITH_NULL_NULL\ncipher suite.  This requires smarts at a layer above TLS to turn it on\nand off, and TLS becomes vulnerable to bugs in that layer.  I'm not sure\nthat's a problem we should be biting off.\n\n> Note: I do not recommend using NULL_WITH_NULL_NULL except unless you\n> know exactly why you want to and you know for a fact that you\n> understand your risk model. It provides no security over plain TCP/IP\n> and I wouldn't want anyone to think otherwise just because it's got\n> \"TLS\" in the name.\n\nWhich is another good reason to forbid it.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "Rodney Thayer writes:\n> \n> There is an argument that says that TLS_NULL_WITH_NULL_NULL should\n> definitely be implemented in production TLS implementations.  It is useful\n> for troubleshooting.  Presumably such an implemenation would employ\n> warnings, blinking lights, sirens, loud warnings, extra user prompts, or\n> whatever it takes to ensure it was only used for testing.\n\nYea.  However in my experience writing two different SSL3 implementations\nit's the handshake that's the hardest part to get right.  Getting the\nrecord-layer stuff correct is easy in comparison.  In fact the\nway I've designed my SSLv3 code has required getting the record\nlayer right before I can even get to the handshake stuff... I\nthink that the TLS spec strongly encourages this type of design.\n\nSo, I agree it'd be useful, but I don't think its useful enough\nto offset the possible security hole it opens.\n\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: Compatible extension for peer-topeer authentication in TL",
            "content": "The client can already force servers to authenticate themselves by\nnot listing anonymous cipher suites in the ClientHello.\n\nThe part of this proposal that I like is adding the contents of a\nCertificateRequest message to the end of the ClientHello message.\n\nSince it's optional, clients would have some control over trust\nmanagement that they don't have with SSLv3.0 ... specifically, they\ncan say what CAs they are willing to accept, and communications can\nbe restricted (more or less) to closed communities.  Or if they did\nnot provide that list, they'd get the current behaviour, and users\nmight be allowed to choose whether to accept previously unseen CAs.\n\nI'd like to see this go feature into the TLS spec.\n\n- Dave\n\n> From John_H_Wilson@ccm.jf.intel.com Thu Jan 30 14:37:17 1997\n> Resent-Date: Thu, 30 Jan 1997 17:25:10 -0500\n> Date: Thu, 30 Jan 97 14:19:00 PST\n> From: John H Wilson <John_H_Wilson@ccm.jf.intel.com>\n> To: ietf-tls@www10.w3.org\n> Subject: Compatible extension for peer-to-peer authentication in TLS\n> X-List-URL: http://lists.w3.org/Archives/Public/ietf-tls\n> \n> The inherent assumption in TLS is that the negotiated\n> session is for Client to Server communication; the\n> Server can force the Client to authenticate (to protect\n> its assets), but the Server can unilaterally decide to \n> be anonymous.\n> \n> We (Intel, but really, the wider Internet Telephony commnunity)\n> plan to use TLS as the foundation for secure person-to-person\n> communication. This communication is inherently peer-to-peer; a\n> user would like the same control over authentication whether \n> they are caller (TLS client) or callee (TLS server). And I am \n> sure there will be many other peer-to-peer applications when \n> all is said and done.\n> \n> I believe TLS can be simply extended in a compatible manner to\n> suport a peer-to-peer relationship.\n> \n> Basically, the ClientHello would be extended with an optional\n> CertificateRequest structure. (Which, obviously, a down-level\n> client would not include). An up-level Server would respond \n> with an appropriate certificate or a no_certificate Alert. \n> A down-level Server would ignore the CertificateRequest (as \n> extraneous octets on the end of an otherwise valid ClientHello; \n> see Forward Compatibility note at the end of 6.4.1.2), \n> and would proceed as per the current definition. If it does not \n> send a certificate, or sends one that does not conform to the \n> (ignored) request, the Client may send an Alert. Assuming success, \n> the Server can then proceed as usual (possibly, with its own\n> CertificateRequest).\n> \n> Details\n> -------\n> \n> Section 6.3: paragraph beginning: \"Following the hello messages....\"\n>              [last paragraph on page 24], becomes:\n> \n> Following the hello messages, if the client has requested a server \n> certificate, the server must send either a suitable certificate or \n> a no-certificate alert. If the client has not requested a certificate, \n> the server may send a certificate (or not) at its discretion.\n> The server may request a certificate from the client, if client \n> authentication is desired. Additionally, a server key exchange \n> message may be sent, if it is required (e.g., if no certificate was \n> sent, or if the certificate is for signing purposes only). Now the....\n> \n> Section 6.4.1.2: Client hello\n> [page 29]\n> \n> Add an optional CertificateRequest structure to the ClientHello message:\n> \n> enum {False(0), True(1), (255)} Bool:\n> struct {\n>     ProtocolVersion client_version;\n>     Random random;\n>     SessionID session_id;\n>     CipherSuite cipher_suites<2..2^16-1>;\n>     CompressionMethod compression_methods<1..2^8-1>;\n>     Bool certificate_request;\n>     select (certificate_request) {\n>         case False: stuct {};\n>         case True:  CertificateRequest;\n>     } body;\n> } ClientHello;\n> \n> 6.4.2 Server Certificate\n> [page 31] \n> \n> When this message will be sent:\n>  \n> The server must send a certificate whenever the agreed-upon key\n> exchange method is not an anonymous one, or the client requests \n> a certificate. If the client has requested a certificate, and the\n> server has no suitable certificate, it must send a no-certificate\n> alert instead. This alert is only a warning, however, the client \n> may respond with a fatal handshake alert if server authentication \n> is required.\n> \n> 6.4.4 Certificate Request\n> [page 35]\n>    \n> When this message will be sent:\n> \n> The server can optionally request a certificate from the client, \n> either for key exchange purposes or to force client authentication.\n> \n> This message.........when legal.\n> \n> Structure of this message:\n> \n> enum  {\n>      rsa_sign(1), dss_sign(2), rsa_fixed_dh(3), dss_fixed_dh(4),\n>      rsa_ephemeral_dh(5), dss_ephemeral_dh(6), (255)\n> } CertificateType;\n> \n> opaque DistinguishedName<1..2^16-1>;\n> \n> struct  {\n>      CertificateType certificate_types<1..2^8-1>;\n>      Distinguishedname certificate_authorities<3..2^16-1>;\n> } CertificateRequest;\n> \n> certificate_types\n>      This field is a list of the types of certificates requested,\n>      sorted in order of preference.\n> \n> Delete the last Note on this page.\n> \n> A.4.1 Hello messages\n> [page 45]\n> \n> enum {False(0), True(1), (255)} Bool:\n> struct {\n>     ProtocolVersion client_version;\n>     Random random;\n>     SessionID session_id;\n>     CipherSuite cipher_suites<2..2^16-1>;\n>     CompressionMethod compression_methods<1..2^8-1>;\n>     Bool certificate_request;\n>     select (certificate_request) {\n>         case False: stuct {};\n>         case True:  CertificateRequest;\n>     } body;\n> } ClientHello;\n> \n> \n\n\n\n"
        },
        {
            "subject": "TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "This is a two week last call on regularizing port numbers for SSL and for\nTLS. If there are no objections, I send this request officially as an\neditor for the IETF-TLS working group to the IANA.\n\n-----\nThe SSL 3.0 protocol has the broadest implementation of any security\nstandard to date, with both Netscape and Microsoft using it in their\npopular servers and browsers. SSL 3.0 has been submitted to the TLS working\ngroup of the IETF, and is is proceeding out of internet-draft status under\na new name, TLS.\n\nTim Dierks and I are editors for that working group, Win Treese\n<treese@OpenMarket.com> is the working group chair, and Jeff Schiller\n<jis@mit.edu> is the IESG area director over the WG.\n\nTim are I have two documents undergoing revision:\n<draft-ietf-tls-protocol-00.txt> & <draft-ietf-tls-ssl-mods-00.txt>, which\nwere approved during the last working group meeting in San Jose, and are\nbeing merged into one draft.\n\nOne area that I am trying to resolve are the port issues with TLS/SSL.\n\nAs a transport layer security standard, TLS/SSL can work transparently with\nexisting application level protocols (such as http, nntp, nttp) without\n*any* change to the protocol other than using a different port number. As\nan example, the popular http protocol uses port 40, and the SSL enabled\nversion of http uses 443.\n\nIt is possible for a single port to be used for both unsecure and secure\nuses, however, this requires changes in the application level protocols\nwhich are must be separately adopted by each working group over such\nprotocols. An example of changes that would allow for a single port in the\nFTP protocol is covered in <draft-murray-auth-ftp-ssl-00.txt>.\n\nUntil each protocol is revised to allow for authenication under a single\nport, we will require separate ports for TLS/SSL implementations of the\nmost popular protocols.\n\nThere are a number of ports current registered with the IANA the for use by\nthe SSL protocol. They are currently:\n\nhttps       443/tcp    https\nssmtp       465/tcp    ssmtp\nsnews       563/tcp    snews\nssl-ldap    636/tcp    ssl-ldap\nspop3       995/tcp    SSL based POP3\n\nAs the above registrations are inconsistant, and most don't even mention\nSSL or TLS, we would like to get these port assignments regularized in the\nlisting as follows:\n\nhttps       443/tcp    http protocol over TLS/SSL\nssmtp       465/tcp    smtp protocol over TLS/SSL\nsnntp       563/tcp    nntp protocol over TLS/SSL\nsldap       636/tcp    ldap protocol over TLS/SSL\nspop3       995/tcp    pop3 protocol over TLS/SSL\n\nThere is also currently a desire among SSL implementors to register two\nadditional ports mappings for ftp protocol over TLS/SSL and imap4 protocol\nover TLS/SSL. We have been told that invididual implementors have attempted\nto register ports for these uses of SSL, but as of today they have not\nrecieved registration for these assignments.\n\nWe would like to suggest the following:\n\nftps    990/tcp    ftp protocol over TLS/SSL\nsimap       991/tcp    imap4 protocol over TLS/SSL\n\nUnder your procedures, you ask for answers to the following questions:\n\n1)  What is the protocol between the user machine and the server\n    machine?\n\nIt is the TLS 1.0 or SSL 3.0 protocol as defined in\n<draft-ietf-tls-protocol-00.txt> & <draft-ietf-tls-ssl-mods-00.txt>.\n\n2)  What message formats, types, op codes, sequences are used?\n\nIt is the TLS 1.0 or SSL 3.0 protocol as defined in\n<draft-ietf-tls-protocol-00.txt> & <draft-ietf-tls-ssl-mods-00.txt>.\n\n3)  What functions are performed by this protocol?\n\nSecuring and authenticating the transport independently of the application\nprotocol.\n\n4)  Is broadcast or multicast used?  If so, how and what for?\n\nNo -- TCP only is defined by TLS/SSL at this point, however, we'd like to\nat least hold the UDP ports in reserve for the future.\n\n5) Do you want a well-known assigned system port in the range 0-1023,\n   or a registered user port in the range 1024-65535 ?\n\nThey need to be in a the well known range as they are core system protocols\nthat are being secured.\n\n6)  What short name (14 character maximum) do you want associated with\n    this port number?\n\nftps    990/tcp    ftp protocol over TLS/SSL\nimaps       991/tcp    imap4 protocol over TLS/SSL\n\nIf there are any questions as to our authority to request such changes,\nthese changes have been run by the WG Chair, Win Treese\n<treese@OpenMarket.com>and Jeff Schiller <jis@mit.edu> is the IESG area\ndirector over the TLS WG. In addition, these requests were run by Netscape,\nMicrosoft, the SSL-Talk mailing list and the IETF-TLS working group mailing\nlist before being sent to you. There are also currently multiple SSL\nimplementations of each of the applications protocols being requested above.\n\nIf you have any questions, please feel free to give me a call at\n510/559-1500 or email me at Christopher Allen <ChristopherA@consensus.com>.\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "According to Christopher Allen:\n> https       443/tcp    http protocol over TLS/SSL\n> ssmtp       465/tcp    smtp protocol over TLS/SSL\n> snntp       563/tcp    nntp protocol over TLS/SSL\n> sldap       636/tcp    ldap protocol over TLS/SSL\n> spop3       995/tcp    pop3 protocol over TLS/SSL\n> ftps    990/tcp    ftp protocol over TLS/SSL\n> simap       991/tcp    imap4 protocol over TLS/SSL\n\n    Why not have them all named <PROTOCOL>s with the non-regular name as\nan alias ... also your list should have # comment otherwise it isn't in\nthe right format for inclusion in the standard services \"database\" :-)\nThe current naming scheme is inconsistant and really should be sorted out.\n\n https       443/tcp            # http protocol over TLS/SSL\n smtps       465/tcp    ssmtp   # smtp protocol over TLS/SSL\n nntps       563/tcp    snntp   # nntp protocol over TLS/SSL\n ldaps       636/tcp    sldap   # ldap protocol over TLS/SSL\n pop3s       995/tcp    spop3   # pop3 protocol over TLS/SSL\n ftps    990/tcp            # ftp protocol over TLS/SSL\n imaps       991/tcp    simap   # imap4 protocol over TLS/SSL\n\n    You might also want to have snews as an alias to minimise impact\nand also strongly recommend that people using the old name format change\ntheir code to use the official name.\n\n    I'd also think that you should ask for ports for the following at\nthe same time:\n\nlogins      992/tcp            # login protocol over TLS/SSL\nshells      993/tcp            # shell protocol over TLS/SSL\ntelnets     994/tcp            # telnet protocol over TLS/SSL\ngophers     995/tcp            # gopher protocol over TLS/SSL\nircs        996/tcp            # irc protocol over TLS/SSL\nsockss     1081/tcp            # socks protocol over TLS/SSL\n\n    If you want to forward this to the list for discussion then feel\nfree to do so ... however I don't think discussion is required as most\nof these are already in use out there (not on those ports [i.e. non-official])\n\nTim.\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "At 6:13 PM -0800 2/4/97, Tim Hudson wrote:\n>According to Christopher Allen:\n>> https       443/tcp    http protocol over TLS/SSL\n>> ssmtp       465/tcp    smtp protocol over TLS/SSL\n>> snntp       563/tcp    nntp protocol over TLS/SSL\n>> sldap       636/tcp    ldap protocol over TLS/SSL\n>> spop3       995/tcp    pop3 protocol over TLS/SSL\n>> ftps    990/tcp    ftp protocol over TLS/SSL\n>> simap       991/tcp    imap4 protocol over TLS/SSL\n>\n>    Why not have them all named <PROTOCOL>s with the non-regular name as\n>an alias ... also your list should have # comment otherwise it isn't in\n>the right format for inclusion in the standard services \"database\" :-)\n\nAgreed.\n\n>The current naming scheme is inconsistant and really should be sorted out.\n>\n> https       443/tcp            # http protocol over TLS/SSL\n> smtps       465/tcp    ssmtp   # smtp protocol over TLS/SSL\n> nntps       563/tcp    snntp   # nntp protocol over TLS/SSL\n> ldaps       636/tcp    sldap   # ldap protocol over TLS/SSL\n> pop3s       995/tcp    spop3   # pop3 protocol over TLS/SSL\n> ftps    990/tcp            # ftp protocol over TLS/SSL\n> imaps       991/tcp    simap   # imap4 protocol over TLS/SSL\n>\n>    You might also want to have snews as an alias to minimise impact\n>and also strongly recommend that people using the old name format change\n>their code to use the official name.\n\nThe issue of the names is a legitimate problem that I wasn't sure that I\nwanted to address in this email -- I've not even been able to track down\nhow new URL identifiers are even registered.\n\nWhat do other people think we should do -- should we go ahead and\nregularize the names? Netscape & Microsoft -- we particularly need to know\nabout your priorities in the above list.\n\n>    I'd also think that you should ask for ports for the following at\n>the same time:\n>\n>logins      992/tcp            # login protocol over TLS/SSL\n>shells      993/tcp            # shell protocol over TLS/SSL\n>telnets     994/tcp            # telnet protocol over TLS/SSL\n>gophers     995/tcp            # gopher protocol over TLS/SSL\n>ircs        996/tcp            # irc protocol over TLS/SSL\n>sockss     1081/tcp            # socks protocol over TLS/SSL\n>\n>    If you want to forward this to the list for discussion then feel\n>free to do so ... however I don't think discussion is required as most\n>of these are already in use out there (not on those ports [i.e. non-official])\n\nI was avoiding adding too many new ports without developer commitment to\nsupport them. If we give the IANA a huge number of port requests they are\ngoing to punt and say \"solve the problem by using one port\" which is not a\ncompletely unreasonable request, but we are looking for a short term\nsolution.\n\nIf you are a developer that is committed to supplying SSL secured versions\nof any of these protocols, send me a private email. I will keep this\ninformation confidential unless you give me permission to give out your\nname. If I get confirmations, I'll add the requests to the list.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "I have strong interest in adding TLS/SSL support for telnet, login, and\nftp.\n\nThe reality is that you need to have separate ports unless we want to\nforce a major re-write of applications.\n\nOf course, the preference would be to have TLS/SSL be implemented in\nthe protocol stack and be transparent to the application whenever\npossible.\n\n\nJeffrey Altman * Kermit Development Group * Columbia University\n               * 612 West 115th St #716 * New York, NY * 10025 * (212) 854-1344\n    C-Kermit 5A(191) for OS/2:   http://www.columbia.edu/kermit/cko191.html\n  Kermit 95 for Windows 95/NT:   http://www.columbia.edu/kermit/k95.html\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Jeff,\n\nJeffrey Altman wrote:\n> \n> I have strong interest in adding TLS/SSL support for telnet, login, and\n> ftp.\n> \n> The reality is that you need to have separate ports unless we want to\n> force a major re-write of applications.\n\n  I am not sure that this is necessary in all cases.  Protocol \ninterfacing is definatly possible.  We have done some of this\nalready.\n> \n> Of course, the preference would be to have TLS/SSL be implemented in\n> the protocol stack and be transparent to the application whenever\n> possible.\n\n  Transport layer is another place as well.\n> \n> Jeffrey Altman * Kermit Development Group * Columbia University\n>                * 612 West 115th St #716 * New York, NY * 10025 * (212) 854-1344\n>     C-Kermit 5A(191) for OS/2:   http://www.columbia.edu/kermit/cko191.html\n>   Kermit 95 for Windows 95/NT:   http://www.columbia.edu/kermit/k95.html\n\nRegards,\n-- \nJeffrey A. Williams\nDIR. Internet Network Eng/SR. Java Development Eng.\nInformation Eng. Group. \nPhone :913-294-2375 (temporary)\nE-Mail jwkckid1@ix.netcom.com\n\n\n\n"
        },
        {
            "subject": "[Fwd: Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL.",
            "content": "forwarding some mis-mail\n\n\nattached mail follows:\nAccording to Christopher Allen:\n> https       443/tcp    http protocol over TLS/SSL\n> ssmtp       465/tcp    smtp protocol over TLS/SSL\n> snntp       563/tcp    nntp protocol over TLS/SSL\n> sldap       636/tcp    ldap protocol over TLS/SSL\n> spop3       995/tcp    pop3 protocol over TLS/SSL\n> ftps    990/tcp    ftp protocol over TLS/SSL\n> simap       991/tcp    imap4 protocol over TLS/SSL\n\n    Why not have them all named <PROTOCOL>s with the non-regular name as\nan alias ... also your list should have # comment otherwise it isn't in\nthe right format for inclusion in the standard services \"database\" :-)\nThe current naming scheme is inconsistant and really should be sorted out.\n\n https       443/tcp            # http protocol over TLS/SSL\n smtps       465/tcp    ssmtp   # smtp protocol over TLS/SSL\n nntps       563/tcp    snntp   # nntp protocol over TLS/SSL\n ldaps       636/tcp    sldap   # ldap protocol over TLS/SSL\n pop3s       995/tcp    spop3   # pop3 protocol over TLS/SSL\n ftps    990/tcp            # ftp protocol over TLS/SSL\n imaps       991/tcp    simap   # imap4 protocol over TLS/SSL\n\n    You might also want to have snews as an alias to minimise impact\nand also strongly recommend that people using the old name format change\ntheir code to use the official name.\n\n    I'd also think that you should ask for ports for the following at\nthe same time:\n\nlogins      992/tcp            # login protocol over TLS/SSL\nshells      993/tcp            # shell protocol over TLS/SSL\ntelnets     994/tcp            # telnet protocol over TLS/SSL\ngophers     995/tcp            # gopher protocol over TLS/SSL\nircs        996/tcp            # irc protocol over TLS/SSL\nsockss     1081/tcp            # socks protocol over TLS/SSL\n\n    If you want to forward this to the list for discussion then feel\nfree to do so ... however I don't think discussion is required as most\nof these are already in use out there (not on those ports [i.e. non-official])\n\nTim.\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Jeffrey Altman writes:\n> \n> I have strong interest in adding TLS/SSL support for telnet, login, and\n> ftp.\n> \n> The reality is that you need to have separate ports unless we want to\n> force a major re-write of applications.\n\nI used to agree with that, but when I tried it I decided that\nactually it's not that bad.  SSL-izing telnet and ftp took me\nabout two days each, and most of that time was spent understanding\nthe option negotiation.  Of course that doesn't mean that it'll\nwork for everything, but I'd be willing to bet that there isn't\nanother protocol with an option negotiaiton that's sicker than\ntelnets. :-)\n\nThere's an internet draft on SSL inside ftp (i.e. negotiating\nuse of SSL in an FTP connection) written by Paul Ford-Hutchinson\nTim Hudson and myself: draft-murray-auth-ftp-ssl-00.txt.\n\n> Of course, the preference would be to have TLS/SSL be implemented in\n> the protocol stack and be transparent to the application whenever\n> possible.\n\nFor real security you still need to provide the user some indication\nwhat CipherType was negotiated.  Otherwise someone might connect\nat \"40 bits\" when their data needs more security that that.\nSo it can't be 100% transparent.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "I disagree that it's easy to SSL-ize applications. I added SSL to <a\ncommercial browser> and it was massively painful because of the message\nnegotiation that has to happen up front; this interfered unfortunately with\nthe non-blocking I/O model the browser was using.\n\nOf course, now that I have the scars from this experience I feel I\nunderstand exactly what I need to do next time I design an application...\n\n\n>Resent-Date: Wed, 5 Feb 1997 01:42:33 -0500\n>Resent-Message-Id: <199702050642.BAA26289@www19.w3.org>\n>From: Eric Murray <ericm@lne.com>\n>Subject: Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL.\n>To: jaltman@columbia.edu\n>Date: Tue, 4 Feb 1997 22:38:42 -0800 (PST)\n>Cc: ChristopherA@consensus.com, ietf-tls@w3.org\n>X-List-URL: http://lists.w3.org/Archives/Public/ietf-tls\n>Resent-From: ietf-tls@w3.org\n>X-Mailing-List: <ietf-tls@w3.org> archive/latest/545\n>X-Loop: ietf-tls@w3.org\n>Sender: ietf-tls-request@w3.org\n>Resent-Sender: ietf-tls-request@w3.org\n>\n>Jeffrey Altman writes:\n>> \n>> I have strong interest in adding TLS/SSL support for telnet, login, and\n>> ftp.\n>> \n>> The reality is that you need to have separate ports unless we want to\n>> force a major re-write of applications.\n>\n>I used to agree with that, but when I tried it I decided that\n>actually it's not that bad.  SSL-izing telnet and ftp took me\n>about two days each, and most of that time was spent understanding\n>the option negotiation.  Of course that doesn't mean that it'll\n>work for everything, but I'd be willing to bet that there isn't\n>another protocol with an option negotiaiton that's sicker than\n>telnets. :-)\n>\n>There's an internet draft on SSL inside ftp (i.e. negotiating\n>use of SSL in an FTP connection) written by Paul Ford-Hutchinson\n>Tim Hudson and myself: draft-murray-auth-ftp-ssl-00.txt.\n>\n>> Of course, the preference would be to have TLS/SSL be implemented in\n>> the protocol stack and be transparent to the application whenever\n>> possible.\n>\n>For real security you still need to provide the user some indication\n>what CipherType was negotiated.  Otherwise someone might connect\n>at \"40 bits\" when their data needs more security that that.\n>So it can't be 100% transparent.\n>\n>\n>-- \n>Eric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\n>PGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27\n29 AF\n>\n>\n>\n--------\nRodney Thayer <rodney@sabletech.com>\nPGP Fingerprint: BB1B6428 409129AC  076B9DE1 4C250DD8\n\n\n\n"
        },
        {
            "subject": "names, port number",
            "content": "I doubt that many browser vendors, and specifically Netscape or Microsoft,\nuse the NAME for the port number.  It seems to me that I've found may\nmachines with empty /etc/services files (to use the Unix term) that run\nNetscape and IE with no problem.\n\nI do however agree it would be good to know what port NUMBERS they support.\n\nAnd there's an answer to the \"solve it by using one port\" argument.  It's\nto tell them we're going to work on that in/after Memphis.\n\nAlso, if the number of ports seems a problem we can propose to write a\nB-C-P (Best Current Practice) document -- that's what we're all saying this\nis, current practice.\n\nCan we put some NAMES and/or URLs against these names?  Who exactly is\nrunning Socks over SSL, for example?  I think it would be productive, since\nwe've got this conversation going, to enumerate KNOWN CURRENT\nimplementations vs. SUGGESTED implemenations.  For example, I would like to\nbuild an SSL-enabled LPR, and would like a port, but I can't show you\nrunning code so it's not currently implemented.  I volunteer to gather a\nlist, if anyone has suggestions.\n\n\n>At 6:13 PM -0800 2/4/97, Tim Hudson wrote:\n>>According to Christopher Allen:\n>>> https       443/tcp    http protocol over TLS/SSL\n>\n>What do other people think we should do -- should we go ahead and\n>regularize the names? Netscape & Microsoft -- we particularly need to know\n>about your priorities in the above list.\n\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> From: Tim Hudson <tjh@mincom.com> (by way of Christopher Allen)\n> \n>  https       443/tcp            # http protocol over TLS/SSL\n>  smtps       465/tcp    ssmtp   # smtp protocol over TLS/SSL\n>  nntps       563/tcp    snntp   # nntp protocol over TLS/SSL\n>  ldaps       636/tcp    sldap   # ldap protocol over TLS/SSL\n>  pop3s       995/tcp    spop3   # pop3 protocol over TLS/SSL\n>  ftps    990/tcp            # ftp protocol over TLS/SSL\n>  imaps       991/tcp    simap   # imap4 protocol over TLS/SSL\n> \n>     You might also want to have snews as an alias to minimise impact\n> and also strongly recommend that people using the old name format change\n> their code to use the official name.\n> \n>     I'd also think that you should ask for ports for the following at\n> the same time:\n> \n> logins      992/tcp            # login protocol over TLS/SSL\n> shells      993/tcp            # shell protocol over TLS/SSL\n> telnets     994/tcp            # telnet protocol over TLS/SSL\n> gophers     995/tcp            # gopher protocol over TLS/SSL\n> ircs        996/tcp            # irc protocol over TLS/SSL\n> sockss     1081/tcp            # socks protocol over TLS/SSL\n> \n>     If you want to forward this to the list for discussion then feel\n> free to do so ... however I don't think discussion is required as most\n> of these are already in use out there (not on those ports [i.e. non-official])\n> \n> Tim.\n\n\nThis discussion was held some time ago, and it's apparently time to have\nit again:\n\n\n> Date: Thu, 16 May 1996 13:27:22 -0700\n> To: ssl-talk@netscape.com\n> From: timd@consensus.com (Tim Dierks)\n> Subject: Re: Any assigned numbers for other secure apps?\n> \n> At 8:06 AM 5/16/96, sameer@c2.org wrote:\n> >At 9:57 AM 5/16/96, Mark Bauman wrote:\n> >> I was wondering if anyone has assigned any ports for secure applications\n> >> other than HTTPS?  I am wondering about FTPS, TELNETS, SMTPS, etc.  Does\n> >> anyone have these?  I could not find them in the latest Assigned Numbers\n> >> RFC #1700.\n> >>\n> >    The protocol used in SSLtelnet and SSLftp use the same port as\n> >the standard telnet and ftp ports.\n> \n> Actually, there is some discussion over whether it's appropriate to run SSL\n> versions of protocols to the same port or not. Netscape's position appears\n> to be that since there isn't any defined way to distinguish a client\n> attempting to negotiate an SSL session from a client connecting without\n> encryption, it may be difficult to create secure versions of arbitrary\n> protocols. Clearly, with many protocols you can do this heuristically or by\n> using protocol-specific features (for example, it's my understanding that\n> at least one secure ftp implementation connects without security, then\n> sends a command to tell the other end to begin using SSL over the channel),\n> but it's difficult to do generally (for example, with Telnet, it would be\n> difficult to be certain whether a client was SSL or not by examining the\n> first few characters that come over the channel; you might be able to make\n> a real good guess, but you might be wrong some small fraction of the time).\n> \n> I find the following port assignments listed in appendix A of the SSL 3.0 spec:\n> \n>   443 HTTP over SSL (https)\n>   465 SMTP over SSL (ssmtp) [pending]\n>   563 NNTP over SSL (snntp) [pending]\n> \n> It's my understanding that ports for other protocols, such as POP, Telnet,\n> etc., have been applied for and are underway.\n> \n> I've got some concern about the explosion of reserved port numbers this may\n> cause; for example, will we need a whole new set for TLS? (Hopefully not,\n> if it's close enough to SSL 3.0 to use SSL 3's version negotiation system.)\n> The alternative is specifying for individual protocols unique ways to\n> distinguish them in such a fashion that secure and insecure transports can\n> share TCP port numbers.\n> \n>  - Tim\n> \n> Tim Dierks  --  timd@consensus.com  --  www.consensus.com\n> Head of Thing-u-ma-jig Engineering, Consensus Development\n\n\nI too have more than some concern about the explosion of reserved\nport numbers for SSL-this and TLS-that.\n\nI think we have consensus that https on port 443 is a done deal,\nand that mail and news may also fall into that category.\n\nBut before we petition the IANA to officially sanction TLS port\nexplosion, we should do some serious thinking, planning, and\nengineering.\n\nThere are 3 alternatives, only two of which have been discussed so far:\n  * dedicate (and reserve through IANA) a separate port for every\n    protocol that might benefit from TLS protection\n  * use the normal port for each protocol, and negotiate security options\n    (including TLS) from the application using something like SASL\n  * define a one-byte TCP option which would allow the negotiation of\n    a security protocol (e.g. TLS) during the TCP handshake.\n\nThe \"exploding ports\" option is bad for obvious reasons.\n\nThe application-specific negotiation has the disadvantage of requiring\neach application protocol be modified to understand the negotiation\nmechanism.\n\nDefining a TCP option would be, IMHO, the cleanest solution.  If a\nparticular network stack did not allow the setting and retrieving of\nTCP options through the socket interface, the stack would have to be\nmodified to use this method.\n\nIt is not necessary to register well-known port numbers with IANA in\norder to experiment with, say, SSL-ized gopher or IRC.  The port\nnumbers must just be agreed-to within the community of users, either\nby pre-agreement or by explicit specification within a URL\n(ircs://irc.mumble.com:996).  IANA registration should not be pursued\nuntil there is consensus that \"exploding ports\" is the architectural\ndirection in which TLS should be going.\n\nSo my official response to the LAST CALL is that no additional ports\nbe registered for \"xxx protocol over TLS/SSL\" at this time.  I believe\nthat both application-layer (SASL-like) and transport-layer (TCP option)\nnegotiation of security protocols are architecturally more appropriate\nfor the Internet.\n\n\n\n"
        },
        {
            "subject": "port number assignments UR",
            "content": "Just so other folks don't have to go searching around, I believe...\n\n\nThe most recent RFC defining port numbers is RFC1700, issued in 1994.\n\nThe current list of assigned port numbers is:\n  <ftp://ftp.isi.edu/in-notes/iana/assignments/port-numbers>\nand this was last updated February 4th 1997 at 11:52 AM\n\n--------\nRodney Thayer <rodney@sabletech.com>\nPGP Fingerprint: BB1B6428 409129AC  076B9DE1 4C250DD8\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Rodney Thayer wrote:\n> \n> I disagree that it's easy to SSL-ize applications. I added SSL to <a\n> commercial browser> and it was massively painful because of the\n> message negotiation that has to happen up front; this interfered\n> unfortunately with the non-blocking I/O model the browser was using.\n> \n> Of course, now that I have the scars from this experience I feel I\n> understand exactly what I need to do next time I design an\n> application...\n\nI agree, it's harder than it looks.  Especially for applications that\nhave to handle several open streams simultaneously.\n\nI also object to trying to do SSL and non-SSL on the same port for\nsecurity reasons.  It adds another level of complexity to making sure\nyou don't get rolled back to an insecure state.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> From: Tom Weinstein <tomw@netscape.com>\n>\n> I also object to trying to do SSL and non-SSL on the same port for\n> security reasons.  It adds another level of complexity to making sure\n> you don't get rolled back to an insecure state.\n\nWill Netscape's browser process URLs of the forms https://foo.com:80\n(resulting in an SSL connection on port 80) and http://foo.com:443\n(resulting in an HTTP connection on port 443), and can Netscape's\nservers be configured to do an SSL listen on 80 and an HTTP listen on 443?\n\nI believe the answers are all \"yes\".\n\nThus the port numbers have nothing to do with security, they are just\na convention that facilitates interoperability without having to look at\nthe bitstream to guess which protocol is being used.\n\nIf you configure a server/browser to only do SSL with only the SSL\nversions and ciphersuites that meet your security requirements, then\nyou can't be rolled back into \"an insecure state\" (i.e. a connection\nusing a protocol or ciphersuite that does not satisfy your security\npolicy).  Port numbers have nothing to do with it.\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "David P. Kemp wrote:\n> \n> > From: Tom Weinstein <tomw@netscape.com>\n> >\n> > I also object to trying to do SSL and non-SSL on the same port for\n> > security reasons.  It adds another level of complexity to making sure\n> > you don't get rolled back to an insecure state.\n> \n> Will Netscape's browser process URLs of the forms https://foo.com:80\n> (resulting in an SSL connection on port 80) and http://foo.com:443\n> (resulting in an HTTP connection on port 443), and can Netscape's\n> servers be configured to do an SSL listen on 80 and an HTTP listen on 443?\n> \n> I believe the answers are all \"yes\".\n> \n> Thus the port numbers have nothing to do with security, they are just\n> a convention that facilitates interoperability without having to look at\n> the bitstream to guess which protocol is being used.\n> \n> If you configure a server/browser to only do SSL with only the SSL\n> versions and ciphersuites that meet your security requirements, then\n> you can't be rolled back into \"an insecure state\" (i.e. a connection\n> using a protocol or ciphersuite that does not satisfy your security\n> policy).  Port numbers have nothing to do with it.\n\nI should let Tom defend his own statement, but ...\n\nWhat Tom was referring to is trying to use a single port number and\ndetermining through some lazy evaluation function whether or not the\nassociation was secure. This is probably doable for new protocols, but\ndeserves some serious consideration that has not yet been performed. It\nis not realistic for existing protocols.\n\nThe fact that a Netscape's product is capable of running a secure\nservice on port 80 and a non-secure service on port 443 (or any port\nimaginable) is not relevant. Try sending SSL protocol to port 80 when\nport 80 hasn't been configured to be secure. That will not work. The\nassumption is that the port number used for rendezvous has been\nnegotiated using some alternate protocol to define a protocol stack that\npossess compatible if not identical layers. The default values and\nassociated protocol stacks is what the original message in this thread\nwas about, and the result will satisfy the \"some alternate protocol\"\nrequirement.\n-- \nAlan O. Freier               Corporate Cynic\n<freier@netscape.com>        (415) 937-3638 (work)\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "David P. Kemp wrote:\n> \n> > From: Tom Weinstein <tomw@netscape.com>\n> >\n> > I also object to trying to do SSL and non-SSL on the same port for\n> > security reasons.  It adds another level of complexity to making\n> > sure you don't get rolled back to an insecure state.\n> \n> Will Netscape's browser process URLs of the forms https://foo.com:80\n> (resulting in an SSL connection on port 80) and http://foo.com:443\n> (resulting in an HTTP connection on port 443), and can Netscape's\n> servers be configured to do an SSL listen on 80 and an HTTP listen on\n> 443?\n> \n> I believe the answers are all \"yes\".\n\nOf course the answer is yes.  That's not the issue.  I can also run an\nX server on port 25.  The question is: \"should I?\"  If I run an HTTP\nserver on port 80, it had better start out talking HTTP.  If I run an\nFTP server on port 21, it should talk normal FTP at first.  I don't\nthink anyone disagrees with this.\n\nThe question, then, is do we reserve special ports for protocols that\nsit over SSL, or do we try to negotiate up to SSL after connecting to\nthe normal port?  If we do the later, I get worried about security.\n\n> Thus the port numbers have nothing to do with security, they are just\n> a convention that facilitates interoperability without having to look\n> at the bitstream to guess which protocol is being used.\n> \n> If you configure a server/browser to only do SSL with only the SSL\n> versions and ciphersuites that meet your security requirements, then\n> you can't be rolled back into \"an insecure state\" (i.e. a connection\n> using a protocol or ciphersuite that does not satisfy your security\n> policy).  Port numbers have nothing to do with it.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Tom Weinstein writes:\n \n \n> The question, then, is do we reserve special ports for protocols that\n> sit over SSL, or do we try to negotiate up to SSL after connecting to\n> the normal port?  If we do the later, I get worried about security.\n\nYea, there's more ways to shoot yourself in the foot when\nyou're negotiating SSL/TLS inside another protocol.\nI think the problems are surmountable as long as the application\ncan notify the user (or some decision-making code in the server)\nwhen attempted SSL/TLS negotiation fails.\n\nThe biggest drawback to seperate assigned ports for the TLS versions\nof N services is the limited port number space below 1024.\nIs there any reason (other than convention) for using port\nnumbers under 1024?  I know some filtering router \"firewalls\"\nwill need to be re-programmed, but other than that small problem\nwhy not use ports over 1024?\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> From: \"Alan O. Freier\" <freier@netscape.com>\n> What Tom was referring to is trying to use a single port number and\n> determining through some lazy evaluation function whether or not the\n> association was secure.\n\nI think the question is do we need IANA to be the \"some alternate protocol\"\nthat defines the stack which is operating on a particular port.  My\ncontention is that formal registration is not needed.  The only advantage\nof a well known number for SSL is to allow \"https://foo.com:443\" to be\nabbreviated to \"https://foo.com\".  Given that port 80 is already well\nknown and established as a rendezvous point, even sites who's security\npolicy requires SSL for everything could use http on port 80 to redirect\nall connections to https on some other port.  That some other port does\nnot have to be well-known.\n\nRegistration of 443 with IANA neither requires connections on port 443\nto use SSL nor prohibits connections on other ports from using SSL.\nThus the decision on whether or not to register with IANA cannot be\njustified by using arguments related to security.\n\nTom's question, \"I have a connection on port xxx - is it secure or not?\"\nmay be easy or difficult or impossible to answer.\n\nBut my point is that his question is irrelevant to the issue of whether\nto register well-known ports for SSL, and invoking security arguments\nto answer a non-security-relevent question is a non-sequitur.\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "Help me understand at what point the cipher suite rollbak attack can be\nwaged (and if we care given that we are trying to use NWNN). We know the\ninitial handshaking (implicitly using NWNN ciphersuite) is vulnerable to\nthe attacks during handshaking until the finished message is sent which\ncontains a mac on the entire handshake protocol. We can detect mischief by\nchecking the MAC. The MAC is only as strong as the *new* ciphersuite\ndictates. If the new ciphersuite is NWNN (assuming we could negotiate to\nthis ciphersuite) then we have not lost anything yet (nothing to loose).\n\nAt what point do any of the attacks in Wagner/Schneier translate to loss of\nsecurity? Is it when an existing session re-hanshakes to a higher level of\nsecurity? (Wagner/Schneier explicitly did not analyse this scenario for the\nciphersuite rollback attack.) \n\nTom when you say \"nothing prevents an attacker from forcing you down to that\n[NWNN] ciphersuite\"; are you intimating that the ciphersuite list contains\nnon-NWNN ciphersuites?\n\nBest Regards,\nNed\nnsmith@ibeam.intel.com\n\nAt 09:19 AM 1/31/97 -0800, Tom Weinstein wrote:\n>Tim Dierks wrote:\n>> \n>>> I assume you mean TLS_NULL_WITH_NULL_NULL.  Although the spec does\n>>> not explicitly forbid negotiating to this cipher suite, it should. \n>>> If an implementation allows negotiation to this cipher suite, it is\n>>> open to a rollback attack.\n>> \n>> It's not clear to me what you mean here, Tom. Since the original\n>> negotiation of a connection occurs under NULL_WITH_NULL_NULL, I don't\n>> understand how a later re-negotiation on the same communications\n>> channel could be less secure than a new connection. Which rollback\n>> attack do you mean? Cipher suites or SSL 2?\n>\n>The protocol explicitly forbids sending application data until after\n>the first handshake has completed.\n>\n>If you renegotiate to a NULL_WITH_NULL_NULL cipher suite, nothing\n>prevents an atacker from hijacking your connection at that point and\n>substituting whatever data he wishes.  The Wagner-Schneier paper is\n>very clear about this.  If you are interested in sending preencrypted\n>data, you should negotiate down to something like RSA_WITH_NULL_SHA. \n>This still protects the integrity of your data while avoiding the\n>overhead of encryption.\n>\n>Also, if you allow NULL_WITH_NULL_NULL to be negotiated at the initial\n>handshake, nothing prevents an attacker from forcing you down to that\n>ciphersuite.  One possible approach would be to provide some application\n>layer mechanism for enabling and disabling the NULL_WITH_NULL_NULL\n>cipher suite.  This requires smarts at a layer above TLS to turn it on\n>and off, and TLS becomes vulnerable to bugs in that layer.  I'm not sure\n>that's a problem we should be biting off.\n>\n>> Note: I do not recommend using NULL_WITH_NULL_NULL except unless you\n>> know exactly why you want to and you know for a fact that you\n>> understand your risk model. It provides no security over plain TCP/IP\n>> and I wouldn't want anyone to think otherwise just because it's got\n>> \"TLS\" in the name.\n>\n>Which is another good reason to forbid it.\n>\n>-- \n>You should only break rules of style if you can    | Tom Weinstein\n>coherently explain what you gain by so doing.      | tomw@netscape.com\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "On Tue, 4 Feb 1997 18:39:36 -0800, Christopher Allen  \n<ChristopherA@consensus.com> wrote:\n> I was avoiding adding too many new ports without developer commitment to\n> support them. If we give the IANA a huge number of port requests they are\n> going to punt and say \"solve the problem by using one port\" which is not a\n> completely unreasonable request, but we are looking for a short term\n> solution.\n\nEven if we have developer committment, heck, ports below 1024 are sacred and  \na scarce resource.  We need to find a way to solve the problem by using one  \nport NOW.  Has anyone done any work on reducing this tremendous waste of  \nports?\n\nWhy can't both service live on one port?  That's what we should be working on  \nrather than a quick and ugly fix by simply registering all those port ranges.  \n\n\nThis current schema of allocating SSL alter-egos for existing services does  \nnot scale.\n\nBest regards,\nChris\n\n--\nChristian Kuhtz <chk@gnu.ai.mit.edu>\n                                                          \".com is a mistake.\"\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> From tomw@netscape.com Wed Feb  5 14:02:26 1997\n> \n> The question, then, is do we reserve special ports for protocols that\n> sit over SSL, or do we try to negotiate up to SSL after connecting to\n> the normal port?  If we do the later, I get worried about security.\n\nI guess I'm not being clear enough.  That is *not* the question.\n\nStart with a security policy for, say, FTP.  That policy says either \"I\nwill talk normal FTP\" or \"I will talk FTP over SSL\".  The policy NEVER\nsays \"I will talk normal FTP and then maybe switch to SSL\" - that is a\nmeaningless concept.\n\nThe issue of port registration is do you use well-known port numbers\nto communicate information about your security policy to the peer at\nthe other end of the connection.\n\nIf you use the port registration process, the peer knows that if he\ngets (initiates or receives) a successful connection on port 21, then\nyour policy is to allow normal FTP.  If he gets a successful connection\non port xyz, then your policy is to do FTP over SSL. If he tries to do\nan SSL connection on port 21, he waits for a timeout.  Tough cookies,\nhe shouldn't have done that.\n\nIf, on the other hand, all FTP connections are on port 21 and\nnegotiation is done using, say, a hypothetical transport layer TCP\nsecurity option, then your security policy doesn't change - either you\nrequire SSL or you don't.  If you have two different policies, then use\ntwo different servers, each on port 21.  When the peer connects, the\nsecurity option mechanism allows him to know what your policy is and\nto establish a connection if his policy is compatible with yours.\n\nI agree that application-layer negotiation is really ugly, because then\nthe application, not the protocol stack, is responsible for ensuring\nthat no user data flows until a connection compatible with the security\npolicy is established. It involves doing the negotiation on a clear\nconnection and then establishing a separate secure connection on the\nsame or a different port. That's why I think a TCP security option\nis much cleaner architecturally than application-layer negotiation,\nand is also more efficient (one less TCP connection to establish).\n\nBut negotiation does not allow either party to change the policy of the\nother, so registration vs. negotiation is merely a question of how to\nbest facilitate interoperability.  I prefer negotiation to port\nexplosion.\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "> Help me understand at what point the cipher suite rollbak attack can be\n> waged (and if we care given that we are trying to use NWNN). We know the\n> initial handshaking (implicitly using NWNN ciphersuite) is vulnerable to\n> the attacks during handshaking until the finished message is sent which\n> contains a mac on the entire handshake protocol. We can detect mischief by\n> checking the MAC. The MAC is only as strong as the *new* ciphersuite\n> dictates. If the new ciphersuite is NWNN (assuming we could negotiate to\n> this ciphersuite) then we have not lost anything yet (nothing to loose).\n> \n> At what point do any of the attacks in Wagner/Schneier translate to loss of\n> security? Is it when an existing session re-hanshakes to a higher level of\n> security? (Wagner/Schneier explicitly did not analyse this scenario for the\n> ciphersuite rollback attack.) \n\nI think this question too can be answered by thinking in terms of\nsecurity policy.\n\nThe initial handshake, as you point out, starts out in NWNN.  But no\nuser data flows through the SSL connection until the first handshake is\ncomplete.  If your policy is that NWNN is an acceptable ciphersuite,\nthen you will have a blue bar on your screen but no more protection\nthan with a non-TLS connection.  But hey, if that's your policy, who\ncan argue with it.\n\nIt doesn't really matter whether you negotiate down from a good\nciphersuite to NWNN, or pick NWNN as your initial ciphersuite after the\nfirst handshake - the end result is a TLS connection that gives user\ndata no protection.\n\nI'd also assume that changing your security policy (by clicking on the\noptions menu) would not force a new handshake for all existing\nconnections, but would only affect new connections established after\nthe policy change.  If the implementation does force a handshake for\nexisting connections, then the protocol certainly should switch to a new\nciphersuite from NWNN just as reliably in the middle of a connection as\nit would have at the beginning.\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Hiya\n\nProposal:  I'll take a look at NNTP this weekend and draft an extension to\nit to turn TLS on.\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Hmm, I thought we are here to provide good and real-life engineering and not  \njust marketing driven quick fix kludges.  The allocation of https and nntps,  \nIMHO, sucks because of its poor design considerations.  We cannot let this  \njunk go any further.\n\nIsn't it *our* job (as in IETF) to provide an efficient, workable and well  \nengineered solution for the \"world\"?\n\nI agree with Mark, time-to-market is a constraint, no doubt.  But  \ntime-to-market will hit a brickwall if we simply slap SSL ports for every  \nexisting non-SSL port into our assigned numbers.  We need long term thinking  \ninstead of short term bogus.\n\nIn essence, we need something that just simply presents a generic adapter  \npiece for SSL service in a connection negotiation.  I have not had much time  \nto look at the FTP spec, and frankly, don't have the pointer anymore.  But it  \ncan't be that hard and we *have* to do it.\n\nCan someone send me a pointer via private eMail?  Thanks.\n\nRegards,\nChris\n\n\n\n"
        },
        {
            "subject": "RE: Port Number",
            "content": "*** Resending note of 05/02/97 09:23\n\nThere appears to be several questions raised by the request to IANA of\n'TLS-enabled' application protocol ports.\n\n1) Is simply adding a port which negotiates SSL upon connection\n    sufficient to satisfy the protocol we are supposed to be protecting\n    (I would argue that in the specific case of FTP, this is not true\n     as it does not discuss the behaviour of the data port at all - at\n     the very least we need to specify the default ftp data port ?ftpds?\n     however this is only scratching the surface really)\n\n2) Does adding another port allow heterogeneous client/server\n    interoperation, if not then surely something else needs to be\n    stated (probably as an RFC (possibly Informational))\n\n3) The much more serious question, raised in several notes is that\n    really TLS negotiation and the policies of Clients/Servers shouldn't\n    be generalised (the implication of this mechanism of transparently\n    adding TLS to the bottom of the application negates the ability\n    of the application to set the TLS policies that are right for any\n    given conversation.)  The correct approach must be to build TLS\n    aware applications that can negotiate TLS as part of their\n    initialisation and manage the public/private Keys, CA roots to\n    be trusted, CRL gathering, Cipher Suite selection etc... in a\n    manner that is appropriate for that conversation in that protocol.\n    So, given that an application will need changing, why not do it\n    properly and allow TLS negotiation in the application protocol.\n\n  I think several issues need to be raised before the IANA implicity\napproves this approach by issuing all these port numbers.\n\n - Should we not raise this issue more widely than just on ietf-tls,\n   the CAT W/G seem to have been set up for this very purpose - surley\n   we shouldn't subvert their efforts.\n\n - Should we not interface to the other Application W/Gs (e.g. ftp-ext)\n   who may have a charter to secure the different application protocols.\n\n\n  In summary, my vote is .. propose the new ones that people are already\nusing, do not propose ftps until there is at least a commitment from\nsome IETF working group to define what it really means  (The ftp one that\nEric, Tim Hudson and myself are writing is available for adoption !!),\ndo not add new ports 'just in case' as this may not be the long-term\npreferred route.\n\nThanks,\nPaul\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SS",
            "content": "Eric Murray wrote:\n> The biggest drawback to seperate assigned ports for the TLS versions\n> of N services is the limited port number space below 1024.\n> Is there any reason (other than convention) for using port\n> numbers under 1024?  I know some filtering router \"firewalls\"\n> will need to be re-programmed, but other than that small problem\n> why not use ports over 1024?\n\nPorts below 1024 are treated differently under unix-like systems: only\nroot can initiate services on these ports[1], thus the operating system\nprovides for some protection against a user on the system trying to subvert\nservices - important particularly in the context of \"secure\" services.\n\n-- \nRobert.Goodwin@mcc.ac.uk \n\n[1]gross oversimplification, but adequate in the circumstances I think :-)\n\n\n\n"
        },
        {
            "subject": "Moving Forward with Regularizing Port Number",
            "content": "At 2:41 AM -0800 2/6/97, pfh@uk.ibm.com wrote:\n>  In summary, my vote is .. propose the new ones that people are already\n>using, do not propose ftps until there is at least a commitment from\n>some IETF working group to define what it really means  (The ftp one that\n>Eric, Tim Hudson and myself are writing is available for adoption !!),\n>do not add new ports 'just in case' as this may not be the long-term\n>preferred route.\n\nThe problem is that people are already using that port number in ftps\nimplementations, and there is a commitment by multiple people on imap4.\n\nIn addition, no single TLS \"single-port\" proposal that I've seen so far\n(including the much appreciated murray internet draft) addresses the issue\nof how current firewalls secure ports. The 443 for https has been\nacknowledged as a port for http secured with SSL, and if someone inside a\nfirewall makes a connection out through 443 it is usually allowed (though\nit might have to request as per ssl-tunnelling). See the SSL-Talk FAQ\nsection on \"using proxies, gateways and firewalls with ssl\" at\n<http://www.consensus.com/security/ssl-talk-sec03.html> for some some\ndiscussion on this.\n\nIn summary, my position is that there are a number of ports that are\nalready assigned that need cleanup, and there are at least 2 additional\nones (ftp and imap4) that have multiple people wanting to ship\ninteroperable products *NOW*. I've also had enough people speak in the last\nweek about telnet that I'll probably add that to the list. As regards to\nirc, rsh, etc. I've had people say that they are doing them, but as I've\nonly heard of one implementation of each, thus I'm not going to request\nthose ports.\n\nI agree that this is not a long term solution, and I do not desire to\nwilly-nilly double the port numbers of every protocol. But there is\nprecedent of assignment of <1024 port numbers to proprietary applications,\nand as there is enough immediate need so that people can have working\ninteroperable applications in the short term, I think we should go for it.\n\nThus, unless there are objections by the WG chair or Area Director, I still\nplan on submitting the change requests and the 2 (or 3 if I add telnet)\nadditional requests to the IANA. I will add the information to the request\nthat one of the reasons driving these requests is issues of current\nfirewalls, and that this is not a long term solution. If granted, these\nports will be documented in the appendix of the TLS 1.0 draft.\n\nI am willing to commit to a requirements document for TLS 1.1 to address\nthis issue in the long term. As the post-TLS 1.0 process needs to be more\nformal with requirements drafts first, this is one of a couple requirements\ndocuments that we need to do.\n\nMeanwhile, I don't want to hold back implementors with a real need now to\ninteroperate with SSL 3.0 or TLS 1.0.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Christian Kuhtz wrote:\n\n| In essence, we need something that just simply presents a generic adapter  \n| piece for SSL service in a connection negotiation.  I have not had\n| much time to look at the FTP spec, and frankly, don't have the\n| pointer anymore.  But it can't be that hard and we *have* to do it. \n\nA generic adapter piece like portmapper?  The problem with\nportmapper (and family) is that it makes packet filtering to exclude\nprotocols very difficult.  That requires installing security\nconfiguration tools on every machine on your network that offers any\nservice over TLS.  I don't believe that there are, or will in the near\nfuture be, tool to effectively manage such groupings of connections.\n\nOn another part of the thread, standardizing on 'non-reserved'\nports allows daemon mode implementations to be run as a user without\nbeing called from inetd.  If http worked on 8000, then there would be\nfewer web servers attempting to run as root, and that would be a\nsecurity win.\n\nAdam\n\n\n-- \n\"It is seldom that liberty of any kind is lost all at once.\"\n               -Hume\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "Ned Smith wrote:\n> \n> Help me understand at what point the cipher suite rollbak attack can\n> be waged (and if we care given that we are trying to use NWNN). We\n> know the initial handshaking (implicitly using NWNN ciphersuite) is\n> vulnerable to the attacks during handshaking until the finished\n> message is sent which contains a mac on the entire handshake protocol.\n> We can detect mischief by checking the MAC. The MAC is only as strong\n> as the *new* ciphersuite dictates. If the new ciphersuite is NWNN\n> (assuming we could negotiate to this ciphersuite) then we have not\n> lost anything yet (nothing to loose).\n> \n> At what point do any of the attacks in Wagner/Schneier translate to\n> loss of security? Is it when an existing session re-hanshakes to a\n> higher level of security? (Wagner/Schneier explicitly did not analyse\n> this scenario for the ciphersuite rollback attack.)\n> \n> Tom when you say \"nothing prevents an attacker from forcing you down\n> to that [NWNN] ciphersuite\"; are you intimating that the ciphersuite\n> list contains non-NWNN ciphersuites?\n\nYes, that's precisely it.  Assume that the client and server both\nsupport RSA_WITH_RC4_128_SHA and NULL_WITH_NULL_NULL.  Normally they\nwould negotiate to RSA_WITH_RC4_128SHA, but instead an attacker modifies\nthe client hello to only include NWNN.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: Moving Forward with Regularizing Port Number",
            "content": "> From: Christopher Allen <ChristopherA@consensus.com>\n>\n> Meanwhile, I don't want to hold back implementors with a real need now to\n> interoperate with SSL 3.0 or TLS 1.0.\n\nI still don't see why the IANA should get involved with a short term\nfix that is not necessarily consistent with the long term direction.\nJust issue an Internet Draft with all the port number assignments you want,\nand the implementors can use it today.\n\nI assume that the WG Chairman is following this discussion, and hope\nthat the Area Director is too. Whatever they decide, after considering\nthe issues, is fine with me.\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "At 9:33 AM 2/5/97, David P. Kemp wrote:\n>There are 3 alternatives, only two of which have been discussed so far:\n>  * dedicate (and reserve through IANA) a separate port for every\n>    protocol that might benefit from TLS protection\n>  * use the normal port for each protocol, and negotiate security options\n>    (including TLS) from the application using something like SASL\n>  * define a one-byte TCP option which would allow the negotiation of\n>    a security protocol (e.g. TLS) during the TCP handshake.\n\nTime for this lurker to speak up.\n\nThere is a fourth alternative, and one which may be painful in the short\nterm but beneificial in the long term.  That is to define a mechanism to\ndefine session-layer and presentation-layer protocols for applications that\nallows for (almost) seamless integration of things like SSL/TSL,\nhost-to-host compression, and other enhancements to existing applications.\n\nAt least this should be explored.  If I knew more about existing practice\n(and if my day job didn't steal so much of the night) I'd come up with some\nproposals.  Maybe this is a good research project for a grad student to\nlook at.\n\n---\nStephen Satchell, Satchell Evaluations\nhttp://www.accutek.com/~satchell for contact info\nOpinions expressed are my own PERSONAL opinions.\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Oh, yeah, real sacred.  There's a port for DOOM, there's ports for\nLucasfilm, there's many ports for IBM, there's many undocumented but\nallocated ports.  No offense to those companies, but DOOM?  Really!\n\n[I wholeheartedly agree that a long term solution other than port\nconsumption is appropriate.]\n\nAt 01:38 PM 2/5/97 -0700, you wrote:\n>On Tue, 4 Feb 1997 18:39:36 -0800, Christopher Allen  \n><ChristopherA@consensus.com> wrote:\n>> I was avoiding adding too many new ports without developer commitment to\n>> support them. If we give the IANA a huge number of port requests they are\n>> going to punt and say \"solve the problem by using one port\" which is not a\n>> completely unreasonable request, but we are looking for a short term\n>> solution.\n>\n>Even if we have developer committment, heck, ports below 1024 are sacred\nand  \n>a scarce resource.  We need to find a way to solve the problem by using one  \n>port NOW.  Has anyone done any work on reducing this tremendous waste of  \n>ports?\n>\n>Why can't both service live on one port?  That's what we should be working\non  \n>rather than a quick and ugly fix by simply registering all those port\nranges.  \n>\n>\n>This current schema of allocating SSL alter-egos for existing services does  \n>not scale.\n>\n>Best regards,\n>Chris\n>\n>--\n>Christian Kuhtz <chk@gnu.ai.mit.edu>\n>                                                          \".com is a\nmistake.\"\n>\n>\n>\n--------\nRodney Thayer <rodney@sabletech.com>\nPGP Fingerprint: BB1B6428 409129AC  076B9DE1 4C250DD8\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> > The question, then, is do we reserve special ports for protocols that\n> > sit over SSL, or do we try to negotiate up to SSL after connecting to\n> > the normal port?  If we do the later, I get worried about security.\n>\n> Yea, there's more ways to shoot yourself in the foot when you're\n> negotiating SSL/TLS inside another protocol. I think the\n> problems are surmountable as long as the application can\n> notify the user (or some decision-making code in the server)\n> when attempted SSL/TLS negotiation fails.\n>\n> The biggest drawback to seperate assigned ports for the TLS\n> versions of N services is the limited port number space below\n> 1024. Is there any reason (other than convention) for using\n> port numbers under 1024?  I know some filtering router\n> \"firewalls\" will need to be re-programmed, but other than that\n> small problem why not use ports over 1024?\n>\n\nThere is another drawback. If many services are secured by TLS\nand new ports assigned for each service, then what happens when\nthe next security-technology-of-the-day comes along?\n\nImagine if the services listed in this forum were secured by SSL\n2.0, SSL 3.0, TLS, Kerberos 4, Kerberos 5, and each service\ngiven its own port. What sense does that make?\n\nPerhaps the community would be better served not by\nregistering a new port for every service but by developing a\nframework for each service where multiple security\ntechnologies can be supported. There is precedent: several\nservices support security negotiation (e.g., telnet, ftp,\nand IMAP) and extensions are being proposed for others (e.g.,\nNNTP).\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Re: HELP ",
            "content": "please delete me from your mailing list !\n\n\n\n"
        },
        {
            "subject": "secure tcp port",
            "content": "Guess I can't lurk forever...\n\nWhile it may be inelegant to simply double the number of ports for\nsecurity, it probably won't actually cause any serious insurmountable\nproblems in the future. An application-level protocol or scheme\nfor negotiation up to SSL/TLS will forever cause compatibility and\ninteroperability problems.\n\nSaying \"it's easy\" to come up with a universal scheme to allow this\nkind of negotiation is naive.  In reality, it's probably impossible.\n\nAs applications warrant it, we should either decide to assign a\nseparate port for secure communications, or come up with a single-port\nscheme if the original protocol makes it possible. \n\nI'd like to suggest that telnet be an application that should have a\nseparate port.\n\n\n\nBill O'Donnell   billo@netcentric.com  billo@server.net     me@billo.com\nNetCentric Corp  17 Msgr O'Brien Hwy   Cambridge, MA 02142\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SS",
            "content": "Robert Goodwin writes:\n> \n> Eric Murray wrote:\n> > The biggest drawback to seperate assigned ports for the TLS versions\n> > of N services is the limited port number space below 1024.\n> > Is there any reason (other than convention) for using port\n> > numbers under 1024?  I know some filtering router \"firewalls\"\n> > will need to be re-programmed, but other than that small problem\n> > why not use ports over 1024?\n> \n> Ports below 1024 are treated differently under unix-like systems: only\n> root can initiate services on these ports\n\n\nYea, I know that.\n\nWith server certificates, does it make any difference?\n(remember in SSL/TLS the server always sends its certificate)\n\nYou still have to be able to prove, by using the private key which\nis presumably kept secret & encrypted, that a server is\nwho it's certificate says it is.  The certificate is really\nthe authenticator, not the port.  Given the number of root\nhacks around, having a service on a port below 1024 doens't\nprove as much as it should.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SS",
            "content": "Robert Goodwin wrote:\n> \n> Ports below 1024 are treated differently under unix-like systems: only\n> root can initiate services on these ports[1], thus the operating system\n> provides for some protection against a user on the system trying to subvert\n> services - important particularly in the context of \"secure\" services.\n> \n> --\n> Robert.Goodwin@mcc.ac.uk\n> \n> [1]gross oversimplification, but adequate in the circumstances I think :-)\n\nLabeling this UNIX \"hack\" as a security feature is incredibly\nirresponsible. It never was and it never will be. Anybody that relies on\nit for protection is security hazzard waiting to be exploited.\n\n-- \nAlan O. Freier               Corporate Cynic\n<freier@netscape.com>        (415) 937-3638 (work)\n\n\n\n"
        },
        {
            "subject": "Re: Moving Forward with Regularizing Port Number",
            "content": "Text item: \n\nThe discussion so far is all based on the assumption that the protocols \nthat want to be enhanced with TLS/SSL all have current port assignments \nbelow 1024.\n\nWe are working on securing H.323 (A/V Conferencing) with TLS/SSL, and \nwill need port assignments for the SSL-enhanced protocol(s), but I \nexpect them to be Registered Ports above 1024.\n\nBTW (as per my previous posting on the subject), the same port can be \nused for secure & non-secure versions of a protocol as long as:\n\n  a) there is a negotiation/discovery mechansim outside the protocol to  \n     determine the use of security, or\n  b) the implementation can deterministically differentiate any          \n     application message from the ClientHandshake message.\n\nMethod b) is fraught with difficulty, including the fact that the \napplication will be at the mercy of how the Operating System implements \nTLS/SSL, since there would have to be collusion between the two when the \napplication detects the ClientHello (or the TLS/SSL layer does not \ndetects ClientHello - depending on who sees the message first).\n\nAn Operating System may not be willing to trust the implied assertion by \nan application that its protocol can be differentiated....who knows \nwhere a false assertion would take it....\n\nJohn \n\n\n\nText item: External Message Header\n\nThe following mail header is for administrative use\nand may be ignored unless there are problems.\n\n***IF THERE ARE PROBLEMS SAVE THESE HEADERS***.\n\nPrecedence: list\nResent-Sender: ietf-tls-request@w3.org\nSender: ietf-tls-request@w3.org\nX-Loop: ietf-tls@w3.org\nX-Mailing-List: <ietf-tls@w3.org> archive/latest/564\nResent-From: ietf-tls@w3.org\nX-List-URL: http://lists.w3.org/Archives/Public/ietf-tls\nSubject: Moving Forward with Regularizing Port Numbers\nFrom: Christopher Allen <ChristopherA@consensus.com>\nTo: ietf-tls@w3.org\nDate: Thu, 6 Feb 1997 03:36:53 -0800\nOrganization: Consensus Development Corporation <http://www.consensus.com/>\nContent-Type: text/plain; charset=\"us-ascii\"\nMime-Version: 1.0\nIn-Reply-To: <199702061042.FAA20285@www10.w3.org>\nMessage-Id: <v0310140baf1f6d705895@dynamic-addr-192.consensus.com>\nResent-Message-Id: <199702061141.GAA17104@www19.w3.org>\nResent-Date: Thu, 6 Feb 1997 06:41:19 -0500\nReceived: by www19.w3.org (8.6.12/8.6.12) id GAA17104; Thu, 6 Feb 1997 06:41:19\n-0500\nReceived: from www19.w3.org (www19.w3.org [18.29.0.19]) by mailbag.jf.intel.com\n(8.8.4/8.7.3) with SMTP id EAA29296; Thu, 6 Feb 1997 04:07:49 -0800 (PST)\nReceived: from mailbag.jf.intel.com (mailbag.jf.intel.com [134.134.248.4]) by re\nlay.jf.intel.com (8.8.4/8.7.3) with ESMTP id EAA23936; Thu, 6 Feb 1997 04:05:21\n-0800 (PST)\nReturn-Path: ietf-tls-request@w3.org\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Christian Kuhtz wrote:\n> \n> On Wed, 05 Feb 1997 19:50:46 -0800, Tom Weinstein <tomw@netscape.com> wrote:\n> \n>> People keep claiming that ports below 1024 are somehow \"sacred\".  I\n>> have yet to hear a convincing argument for why this is so.  In the\n>> old days, the OS reserved those ports for protected use and normal\n>> user programs couldn't use them.  With the proliferation of PCs, it\n>> is trivial for someone to get a program to listen on one of those\n>> ports.  So, why are these ports so special?\n> \n> Because that's how the model is defined?\n> \n> OS's that are compliant with the fact that you cannot bind to below\n> 1024 unless you are superuser will not go away anytime soon.  If that\n> alone doesn't convince you, the rest isn't going to make a difference\n> either.\n> \n> This is about multiuser systems, and regular PC operating systems\n> (including NT) cannot count as that.\n> \n> There's absolutely no need to break rules and systems for something\n> that could be solved with slick and fairly easy engineering. \n> Especially if it is so much tied to security.\n\nThat model works very well if you can be certain that every machine\nconnected to your networks adheres to it.  However, that is not the\ncase.  The IETF and IANA deal with standards for the whole internet.\nThe reality of the situation is that relying for security on the the\nassumption that all machines are good citizens won't work.\n\nBesides, we aren't talking about cloning every registered port.  We're\ntalking about a few ports that are either already in use or will be\nvery soon.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Mark Shuttleworth wrote:\n> \n>> People keep claiming that ports below 1024 are somehow \"sacred\".  I\n>> have yet to hear a convincing argument for why this is so.  In the\n>> old days, the OS reserved those ports for protected use and normal\n>> user programs couldn't use them.  With the proliferation of PCs, it\n>> is trivial for someone to get a program to listen on one of those\n>> ports.  So, why are these ports so special?\n> \n> In this case,  surely you could have no objection to:\n> \n> nntps          2001/tcp           # NNTP over SSL/TLS\n> ldaps          2002/tcp           # LDAP over SSL/TLS\n> ...\n\nNone whatsoever.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Dennis Glatting wrote:\n> \n> True, but...\n> \n> W&S recommend the SSL HMAC be upgraded to the most recent\n> construction and draft-ietf-tls-ssl-mods-00.txt proposes\n> the upgrade. If adopted there will be a compatibility issue.\n\nYes, and that's why the version number must be rev'ed when those changes\nare integrated.  I understand that the editors are working hard on this\nand will hopefully have something out soon.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> > \n> > In this case,  surely you could have no objection to:\n> > \n> > nntps          2001/tcp           # NNTP over SSL/TLS\n> > ldaps          2002/tcp           # LDAP over SSL/TLS\n> > ...\n> \n> None whatsoever.\n\nSuper.  Chris,  since in your proposal you explicitly state we're looking\nfor \"a short time solution\",  would you be prepared to move those ports\nabove 1024?  I think all us purists and academics would sleep easier\nknowing our children might still have ports to play with.\n\n;-)\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> \n> Besides, we aren't talking about cloning every registered port.  We're\n> talking about a few ports that are either already in use or will be\n> very soon.\n> \n> -- \n> You should only break rules of style if you can    | Tom Weinstein\n> coherently explain what you gain by so doing.      | tomw@netscape.com\n\nDo you choose your .sigs for their value in irony or gold?\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Eric Young wrote:\n> \n> Ok, I had retrieved 'draft-ietf-tls-ssl-mods-00.txt' from\n> rs.internic.net for a quick review since I did not want to scan all 66\n> pages of the tls spec and try to spot the differences.  It is\n> obviously a little dated..\n\nAh, that's the problem.  That doesn't specify the differences between\ndraft-ietf-tls-protocol-00.txt and the SSL spec.  It recommends further\nchanges in addition to those made for the current TLS.  Those changes\nwere gone over at the San Jose meeting, and I think we accepted all\nof them, but they haven't been integrated into the spec yet.  When they\nare, I'm sure the version number will be rev'ed.\n\nThe only difference between the current TLS spec and the SSL spec is\nsome clarifications and formatting changes in the document.  The\nprotocols are identical.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Mark Shuttleworth wrote:\n> \n>>> In this case,  surely you could have no objection to:\n>>>\n>>> nntps          2001/tcp           # NNTP over SSL/TLS\n>>> ldaps          2002/tcp           # LDAP over SSL/TLS\n>>> ...\n>>\n>> None whatsoever.\n> \n> Super.  Chris,  since in your proposal you explicitly state we're\n> looking for \"a short time solution\",  would you be prepared to move\n> those ports above 1024?  I think all us purists and academics would\n> sleep easier knowing our children might still have ports to play with.\n\nWhoa!  Hold on there.  I should have said \"None whatsoever, in\nprinciple.\"  Those protocols already have ports reserved.  All Chris\nis talking about is changing the names.\n\nThese, on the other hand, I would certainly not object to changing their\nports to be over 1024:\n\nftps        990/tcp            # ftp protocol over TLS/SSL\nsimap       991/tcp            # imap4 protocol over TLS/SSL\nlogins      992/tcp            # login protocol over TLS/SSL\nshells      993/tcp            # shell protocol over TLS/SSL\ntelnets     994/tcp            # telnet protocol over TLS/SSL\ngophers     995/tcp            # gopher protocol over TLS/SSL\nircs        996/tcp            # irc protocol over TLS/SSL\nsockss     1081/tcp            # socks protocol over TLS/SSL\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> \n> ftps        990/tcp            # ftp protocol over TLS/SSL\n> simap       991/tcp            # imap4 protocol over TLS/SSL\n> logins      992/tcp            # login protocol over TLS/SSL\n> shells      993/tcp            # shell protocol over TLS/SSL\n> telnets     994/tcp            # telnet protocol over TLS/SSL\n> gophers     995/tcp            # gopher protocol over TLS/SSL\n> ircs        996/tcp            # irc protocol over TLS/SSL\n> sockss     1081/tcp            # socks protocol over TLS/SSL\n\nFair enough.  Chris - could all of the above go into the >1024 range?\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SS",
            "content": "> Labeling this UNIX \"hack\" as a security feature is incredibly\n> irresponsible. It never was and it never will be. Anybody that relies on\n> it for protection is security hazzard waiting to be exploited.\n\nIndeed; I never intended to imply that it should be relied upon. But that\n*is* the reason why the numbers < 1024 are different; there is no other\nreason. As someone has pointed out to me, given the nature of the services\nbeing discussed with their proof of identity by both parties there is\nabsolutely no security-related reason why numbers >1024 should not be used.\n\nHowever, since port numbers >1024 are available to any user on the system,\ndoes one not run the risk of finding the port already in use by a user?\n\n-- \nRobert.Goodwin@mcc.ac.uk \n\n\n\n"
        },
        {
            "subject": "Re: secure tcp port",
            "content": "> Guess I can't lurk forever...\n>\n> While it may be inelegant to simply double the number of ports\n> for security, it probably won't actually cause any serious\n> insurmountable problems in the future. An application-level\n> protocol or scheme for negotiation up to SSL/TLS will forever\n> cause compatibility and interoperability problems.\n>\n> Saying \"it's easy\" to come up with a universal scheme to allow\n> this kind of negotiation is naive.  In reality, it's probably\n> impossible.\n>\n> As applications warrant it, we should either decide to assign a\n> separate port for secure communications, or come up with a\n> single-port scheme if the original protocol makes it\n> possible.\n>\n> I'd like to suggest that telnet be an application that should\n> have a separate port.\n>\n\nTLS is little more than an encrypted tunnel. It does not address\nother protocols such as UDP; authentication of the client is\noptional; authorization is not addressed; and the primary\npurpose for which SSL was developed -- secure web page access --\nis subject to spoofing attacks [1] (consequently, so are the\nother services such as telnet). Though vendors are\npontificating its virtues and proliferation (to their\nprofit), TLS only addresses a small class of the security\nproblems.\n\nTLS requires a CA, unless one of the proposed shared key\nmechanisms are adopted. There is not a global CA\ninfrastructure, more or less a US infrastructure. Worse, in\nthe US there is the real possibility of escrow. Associated with\nmost CAs is a financial transaction.  Though traditional use of\nsecurity (in particular, cryptography) has often been\nlabeled as \"not for free\", requiring investment in a CA or\npurchase of a CERT gives the term new meaning.\n\nThough I see great value in TLS and consider it a good protocol,\nthere are issues and I urge caution.\n\n\nThere are mechanisms to perform the secure negotiation of\ncapabilities even in the face of escrow: the originator signs\nhis capability list along with other information (such as a\nreplay token). Though I do not know the laws of all the world's\njurisdictions, to my knowledge the use of strong crypto for\nauthentication is universally permitted.\n\n\n-dpg\n\n[1] \"Web Spoofing: An Internet Con Game\", Edward W. Felten,\nDirk Balfanz, Drew Dean, and Dan S Wallach. Department of\nComputer Science, Princeton University.\n\n\n\n"
        },
        {
            "subject": "Re: secure tcp port",
            "content": "On Thu, 6 Feb 1997 12:32:06 -0500, \"Bill O'Donnell\" <billo@coyote.server.net> wrote:\n> While it may be inelegant to simply double the number of ports for\n> security, it probably won't actually cause any serious insurmountable\n> problems in the future. An application-level protocol or scheme\n> for negotiation up to SSL/TLS will forever cause compatibility and\n> interoperability problems.\n\nSuch as?\n\n> Saying \"it's easy\" to come up with a universal scheme to allow this\n> kind of negotiation is naive.  In reality, it's probably impossible.\n\nWould you mind sharing what you have in mind as an insurmountable show stopper?\n\n--\nChristian Kuhtz <chk@gnu.ai.mit.edu>\n                                                          \".com is a mistake.\"\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Hell, no, not another portmapper ;-).\n\nWhat I had in mind is a generic interface which attempts to negotiate SSL at  \na given, existing port, in such a way that if it fails it will use non-SSL  \ntraditional style, if it succeeds (meaning: the other end is SSL aware), it  \nwill initiate an SSL style session.\n\nYou don't need/want a portmapper to do that.  You don't concentrate all SSL  \nservices through one multiplexer, but rather multiplex SSL and non-SSL on a  \nper service level.\n\nSSL isn't really a new service, it is just a variety of an already existing service.\n\nRegards,\n--\nChristian Kuhtz <chk@gnu.ai.mit.edu>\n                                                          \".com is a mistake.\"\n\n\nOn Thu, 6 Feb 1997 07:42:37 -0500 (EST), Adam Shostack <adam@homeport.org> wrote:\n> A generic adapter piece like portmapper?  The problem with\n> portmapper (and family) is that it makes packet filtering to exclude\n> protocols very difficult.  That requires installing security\n> configuration tools on every machine on your network that offers any\n> service over TLS.  I don't believe that there are, or will in the near\n> future be, tool to effectively manage such groupings of connections.\n>\n> On another part of the thread, standardizing on 'non-reserved'\n> ports allows daemon mode implementations to be run as a user without\n> being called from inetd.  If http worked on 8000, then there would be\n> fewer web servers attempting to run as root, and that would be a\n> security win.\n>\n> Adam\n>\n>\n> --\n> \"It is seldom that liberty of any kind is lost all at once.\"\n> -Hume\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SSL / Plain data on same port..",
            "content": "If we require touching another protocol layer we'll have another layer of\ndebate.\n\nAt 01:03 PM 2/6/97 -0800, you wrote:\n>I wonder if anybody's considered using a TCP header flag to indicate\n>whether the connection desires/requires security.  That would allow\n>one to run both SSL and plain protocols on the same port, without\n>ambiguity between plain data and the beginning of an SSL handshake.\n>\n>d.\n>\n>\n>\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "Re: secure tcp port",
            "content": "   X-POP3-Rcpt: billo@home\n   Content-Type: text/plain\n   Mime-Version: 1.0 (NeXT Mail 3.3 v118.2)\n   X-Nextstep-Mailer: Mail 3.3 (Enhance 2.0b5)\n   Sender: Christian Kuhtz <chk@continuum.epoch.org>\n   From: Christian Kuhtz <chk@gnu.ai.mit.edu>\n   Date: Thu,  6 Feb 97 14:04:37 -0700\n   Cc: ietf-tls@w3.org\n   References: <199702061732.MAA03355@coyote.server.net>\n\n   On Thu, 6 Feb 1997 12:32:06 -0500, \"Bill O'Donnell\" <billo@coyote.server.net> wrote:\n   > While it may be inelegant to simply double the number of ports for\n   > security, it probably won't actually cause any serious insurmountable\n   > problems in the future. An application-level protocol or scheme\n   > for negotiation up to SSL/TLS will forever cause compatibility and\n   > interoperability problems.\n\n   Such as?\n\n- broken clients that predate the negotiation protocol that manage to \n  accidentally trip the negotiation sequence, but obviously can't\n  complete it.\n- servers that predate the negotiation protocol that react badly\n  to clients trying to get a secure connection.\n\n   > Saying \"it's easy\" to come up with a universal scheme to allow this\n   > kind of negotiation is naive.  In reality, it's probably impossible.\n\n   Would you mind sharing what you have in mind as an insurmountable \n   show stopper?\n\n- Some protocols may because of their very nature may leave no \n  room for escape mechanisms to substitute a different sub-application\n  layer protocol.\n- If it was really easy, some really smart person out there might\n  have been able to at least describe it by now. It's usually safer to\n  think of software problems as hard until demonstrated to be easy, not the\n  other way around. \n\n\nBill O'Donnell   billo@netcentric.com  billo@server.net     me@billo.com\nNetCentric Corp  17 Msgr O'Brien Hwy   Cambridge, MA 02142\n\n\n\n"
        },
        {
            "subject": "Let's move single port/port mapping discussion to TLS lis",
            "content": "At 4:33 AM -0800 2/6/97, Jeff Williams wrote:\n>  I thought you were in favor of ONE port.\n\nI am a short term pragmatist, and a long term idealist. I believe that the\nbest resolution is to fix the existing assignments, add a minimal number of\nnew ports so people can interoperate now, admit and recognize the long term\nproblem, and design a better solution as soon as we can.\n\nBTW, I encourage any further discussion on single port/port mapping\nsolutions to move over *exclusively* to the TLS Working Group list, as this\nis obviously a problem that requires some work to be able to complete.\n\nThe discussion list for IETF-TLS Working Group is at <IETF-TLS@W3.ORG>. You\nsubscribe and unsubscribe by sending to IETF-TLS-REQUEST@W3.ORG with\nsubscribe or unsubscribe in the SUBJECT of the message. Archives of the\nlist are at <http://lists.w3.org/Archives/Public/ietf-tls>.\n\nI wanted to include the SSL-Talk list subscribers in the general context of\nthe port assignments, as that list is more heavily weighed with actual\nimplementors than the TLS list is (i.e. they care more about what the final\nassignments will be as they want to ship product).\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Shared Secret Authenticatio",
            "content": "Earlier threads on this list seem to have focused debate on\nweak methods for password/passphrase/shared-secret authentication.\n\nMethods that are immune to unconstrained dictionary attack\nhave been around since 1992, from Bellovin & Merritt's EKE family\nof protocols, to the SPEKE method developed by myself.\nI find it curious that the debate has settled down upon\ndemonstrably weaker alternatives, as in the current drafts.\n\nI would suggest that the passauth-00.txt \"Addition of\nShared Key Authentication\" document be modified to use\nstrong password authentication.  Presenting weak password\nauthentication as an alternative to strong public-key\nmethods seems sloppy.\n\nI really prefer the combination of strong public-key AND\nstrong memorizable passwords, as two independent factors for\nauthentication, but that's probably asking for a bit much at\nthis point.\n\n------------------------------------\nDavid P. Jablon\nIntegrity Sciences, Inc.\nWestboro, MA\nTel: +1 508 898 9024\nhttp://world.std.com/~dpj/\nE-mail: dpj@world.std.com\n\n\n\n"
        },
        {
            "subject": "Re: secure tcp port",
            "content": "Hiya\n\nMost protocols have a clearly defined server response to unknown client\nrequests (much like the HTML \"if you don't know it ignore it\" rule).  IOW,\nif a news server gets a strange command from a client,  the protocol says\nit must return with something like \"500 Que?\".\n\n\"nntps\" just means \"establish a secure news connection.  fail if you\ncannot\".  Whether that secure connection goes to the same or a different\nport is immaterial.  Saying that the same port is more subject to DOS\nattacks is silly:  you wouldn;t expect Navigator to connect to port 80 if\nport 443 failed,  would you?\n\nI think all:\n\n   - command oriented\n   - interactive\n\nprotocols  (NNTP, SMTP, POP3,  IMAP4 etc) can be upgraded to support TLS\nnegotiation just by the addition of a single client command.  Making the\nserver be able to initiate secure session negotiation is harder because\nmost of these protocols are client-driven.  But I'll comment further on\nMonday.\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: secure tcp port",
            "content": "> \n> TLS requires a CA, unless one of the proposed shared key\n> mechanisms are adopted. There is not a global CA\n> infrastructure, more or less a US infrastructure. Worse, in\n> the US there is the real possibility of escrow. Associated with\n\nBegging your pardon,  but Thawte's strategy is entirely global.  Also,\nbecause we are based outside the US,  the only way we would consider\nescrow is if the US government explicitly banned the use of non-escrow\nkeys within the US - an unlikely proposition.\n\n> most CAs is a financial transaction.  Though traditional use of\n> security (in particular, cryptography) has often been\n> labeled as \"not for free\", requiring investment in a CA or\n> purchase of a CERT gives the term new meaning.\n\nAs soon as it's possible to conduct quality checks free,  there will be\nquality free certs.  Certification should not be an expensive thing at\nall.  We don't think so.\n\nAlso,  I think we'll see \"micro-certification\" become important.  By this\nI mean the certification of small, easy to prove but also valuable\nrelationships,  like \"this key is managed by the person at the end of this\nemail address\".  Xcert, Thawte, Verisign, etc. all have projects that\nexplicitly or implicitly suggest this trend.\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Tom Weinstein wrote:\n> Mark Shuttleworth wrote:\n> > \n> >> People keep claiming that ports below 1024 are somehow \"sacred\".  I\n> >> have yet to hear a convincing argument for why this is so.  In the\n> >> old days, the OS reserved those ports for protected use and normal\n> >> user programs couldn't use them.  With the proliferation of PCs, it\n> >> is trivial for someone to get a program to listen on one of those\n> >> ports.  So, why are these ports so special?\n> > \n> > In this case,  surely you could have no objection to:\n> > \n> > nntps          2001/tcp           # NNTP over SSL/TLS\n> > ldaps          2002/tcp           # LDAP over SSL/TLS\n> > ...\n> \n> None whatsoever.\n\nWell, aren't some of the ports around 2000 already reserved?\n\n Wolfgang\n\n\n\n"
        },
        {
            "subject": "Strong password authenticatio",
            "content": "TLS folks, FYI.\n\n\n----- Begin Included Message -----\n\nFrom owner-pkcs-tng@RSA.COM Thu Feb  6 18:57:21 1997\nX-Sender: dpj@world.std.com\nDate: Thu, 06 Feb 1997 18:52:04 -0500\nTo: pkcs-tng@RSA.COM\nFrom: \"David P. Jablon\" <dpj@world.std.com>\nSubject: Strong password authentication\n\n\nI'd like to propose that PKCS TNG include a spec. for\nstrong password authentication.\n\nRecently there have been several proposed standards for\npassword authentication that are demonstrably weak against\ndictionary attack.  This perpetuates a longstanding problem,\none of the largest obstacles to making memorized secrets a\nvaluable factor in authentication.\n\nIt is a fact that strong password methods have existed since 1992.\nBeginning with Bellovin & Merritt's EKE family, through to my\nmore recent work on SPEKE, there are clearly password methods\nthat are immune to the unconstrained network dictionary attack.\n\nIf anyone is interested in collaborating on such a PKCS proposal,\nor perhaps an informational IETF RFC to try to prevent further\nbacksliding, feel free to respond to the list or to me directly.\n\n-- David Jablon\n------------------------------------\nDavid P. Jablon\nIntegrity Sciences, Inc.\nWestboro, MA\nTel: +1 508 898 9024\nhttp://world.std.com/~dpj/\nE-mail: dpj@world.std.com\n\n\n\n\n----- End Included Message -----\n\n\n\n"
        },
        {
            "subject": "Re: Shared Secret Authenticatio",
            "content": "> From: \"David P. Jablon\" <dpj@world.std.com>\n> \n> Earlier threads on this list seem to have focused debate on\n> weak methods for password/passphrase/shared-secret authentication.\n> \n> Methods that are immune to unconstrained dictionary attack\n> have been around since 1992, from Bellovin & Merritt's EKE family\n> of protocols, to the SPEKE method developed by myself.\n> I find it curious that the debate has settled down upon\n> demonstrably weaker alternatives, as in the current drafts.\n> \n> I would suggest that the passauth-00.txt \"Addition of\n> Shared Key Authentication\" document be modified to use\n> strong password authentication.  Presenting weak password\n> authentication as an alternative to strong public-key\n> methods seems sloppy.\n> \n> ------------------------------------\n> David P. Jablon\n> Integrity Sciences, Inc.\n> Westboro, MA\n> Tel: +1 508 898 9024\n> http://world.std.com/~dpj/\n> E-mail: dpj@world.std.com\n\n\n\nI believe that the earlier thread contained implications that the\nBellovin & Merritt technique might be encumbered by intellectual\nproperty restrictions.\n\nIs the SPEKE method covered by any patents, B-M, your own, or others?\n\nThe One-Time-Password working group made it's distaste for encumbered\ntechnology \"patently\" clear (sorry :-) at the December IETF - choosing\nto reject both a method patented by Bull and an alternative patented by\nBellcore.\n\nThe TLS working group also expressed concern about using patented\ncompression technology from Hi-Fn (Stac), although it may be possible\nto implement the proposed compression method in a non-infringing way.\n\nIf SPEKE is both demonstrably stronger than Dan Simon's proposal\n*and* unencumbered, then by all means submit a draft for our consideration.\nIf it is not, it will probably fall pretty low on the priority list of\nwork items.\n\n\n\n"
        },
        {
            "subject": "TLS does not require an external Certificate Authorit",
            "content": "Sorry, I missed where we got the assertion that TLS requires a CA.\n\nAs I understand it TLS requires a ROOT CERTIFICATE and CERTIFICATES.\n[Assuming the identity-based case, not the anonymous case.]\nImplementations can do whatever they wish to come up with the root\ncertificate.  I might deal with that by configuring my implementation to\nuse Thawte's root certificate and use them as a CA.  Someone else might set\nup a CA for use inside a corporation or other organization.  Someome might\neven set things up to self-sign or deliver a signature engine fairly\nwidely.  One can look at PGP as an example of this.\n\nI don't see that there is any technical REQUIREMENT in TLS that I pay\nanyone to act as my certificate authority.  I myself use it that way\nsometimes but that's an implementation and deployment detail, not a\nrequirement of the protocol.\n\n>Resent-Date: Fri, 7 Feb 1997 04:10:51 -0500\n>Resent-Message-Id: <199702070910.EAA11516@www19.w3.org>\n>Date: Fri, 7 Feb 1997 11:08:47 +0200 (SAT)\n>From: Mark Shuttleworth <marks@thawte.com>\n>To: Dennis Glatting <dennis.glatting@plaintalk.bellevue.wa.us>\n>cc: billo@server.net, ietf-tls@w3.org, ssl-talk@netscape.com\n>Subject: Re: secure tcp ports\n>X-List-URL: http://lists.w3.org/Archives/Public/ietf-tls\n>Resent-From: ietf-tls@w3.org\n>X-Mailing-List: <ietf-tls@w3.org> archive/latest/593\n>X-Loop: ietf-tls@w3.org\n>Sender: ietf-tls-request@w3.org\n>Resent-Sender: ietf-tls-request@w3.org\n>\n>> \n>> TLS requires a CA, unless one of the proposed shared key\n>> mechanisms are adopted. There is not a global CA\n>> infrastructure, more or less a US infrastructure. Worse, in\n>> the US there is the real possibility of escrow. Associated with\n>\n>Begging your pardon,  but Thawte's strategy is entirely global.  Also,\n>because we are based outside the US,  the only way we would consider\n>escrow is if the US government explicitly banned the use of non-escrow\n>keys within the US - an unlikely proposition.\n>\n>> most CAs is a financial transaction.  Though traditional use of\n>> security (in particular, cryptography) has often been\n>> labeled as \"not for free\", requiring investment in a CA or\n>> purchase of a CERT gives the term new meaning.\n>\n>As soon as it's possible to conduct quality checks free,  there will be\n>quality free certs.  Certification should not be an expensive thing at\n>all.  We don't think so.\n>\n>Also,  I think we'll see \"micro-certification\" become important.  By this\n>I mean the certification of small, easy to prove but also valuable\n>relationships,  like \"this key is managed by the person at the end of this\n>email address\".  Xcert, Thawte, Verisign, etc. all have projects that\n>explicitly or implicitly suggest this trend.\n>\n>--\n>Mark Shuttleworth\n>Thawte Consulting\n>\n>\n>\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": " >\n > ftps        990/tcp            # ftp protocol over TLS/SSL\n\n - You need to specify 989 as reserved for ftp data (really just so\n   that firewalls know where to accept secured ftp data connections\n   from, if they aren't doing firewall friendly FTP (RFC1579))\n - You need to say what this means to allow interoperability\n   (basically discuss the behaviour of the data connection)\n\nThanks,\nPaul\n\n-.--.---.----.-----.----.---.--.--.---.----.-----.----.---.--.-\nPaul Ford-Hutchinson    FORDHUP @ NHBVM9  (GBIBMLLL @ IBMMAIL)\nIGN EDI Products Development and Support. (pfh@uk.ibm.com)\nWarwick (OSU-1)   +44 (0)1926 464836      : tie  (7)66 4836\n\n\n\n"
        },
        {
            "subject": "Re: Shared Secret Authenticatio",
            "content": "David P. Jablon <dpj@world.std.com> wrote:\n\n>> Earlier threads on this list seem to have focused debate on\n>> weak methods for password/passphrase/shared-secret authentication.\n>> \n>> Methods that are immune to unconstrained dictionary attack\n>> have been around since 1992, from Bellovin & Merritt's EKE family\n>> of protocols, to the SPEKE method developed by myself.\n>> I find it curious that the debate has settled down upon\n>> demonstrably weaker alternatives, as in the current drafts.\n>> \n>> I would suggest that the passauth-00.txt \"Addition of\n>> Shared Key Authentication\" document be modified to use\n>> strong password authentication.  Presenting weak password\n>> authentication as an alternative to strong public-key\n>> methods seems sloppy.\n\ndpkemp@missi.ncsc.mil (David P. Kemp) wrote:\n\n> I believe that the earlier thread contained implications that the\n> Bellovin & Merritt technique might be encumbered by intellectual\n> property restrictions.\n> Is the SPEKE method covered by any patents, B-M, your own, or others?\n...\n> If SPEKE is both demonstrably stronger than Dan Simon's proposal\n> *and* unencumbered, then by all means submit a draft for our consideration.\n> If it is not, it will probably fall pretty low on the priority list of\n> work items.\n\n[dpj:]\nOpen debate must first focus on technical merit.\nThe IETF and working group members clearly feel that strength\ncomes first, and patent issues are secondary, as is demonstrated\nby the repeated endorsement of patented PK methods (RSA, DH, etc.).\nOtherwise all standards would degrade to second-rate technology.\n\nSPEKE is not covered by the B&M patents, and B&M is not encumbered\nby the pending SPEKE patent.  So at least you have a \"second source\"\nwhich forces reasonable terms even without IETF's required\npatent policy statement.  Both SPEKE and DH-EKE, like many good PK\nmethods are covered by the Diffie-Hellman patent, till Sept. '97.\nAnd you're free to look for other strong methods that might\nnot be covered by either B&M or SPEKE.  So far I've seen little\nevidence of a search for strong password methods in the earlier\ndiscussion, perhaps because so few knew that these exist.\n\n[dpk:]\n> The One-Time-Password working group made it's distaste for encumbered\n> technology \"patently\" clear (sorry :-) at the December IETF - choosing\n> to reject both a method patented by Bull and an alternative patented by\n> Bellcore.\n> The TLS working group also expressed concern about using patented\n> compression technology from Hi-Fn (Stac), although it may be possible\n> to implement the proposed compression method in a non-infringing way.\n\n[dpj:]\nThese are bad comparisons.  When EQUALLY STRONG unpatented\nalternatives exist, of course you want to use them.  But\ndebate over whether or not to use public-key encryption\nshould never be BLOCKED by the fact that most good PK methods\n(RSA, Diffie-Hellman, etc.) are patented.\n------------------------------------\nDavid P. Jablon\nIntegrity Sciences, Inc.\nWestboro, MA\nTel: +1 508 898 9024\nhttp://world.std.com/~dpj/\nE-mail: dpj@world.std.com\n\n\n\n"
        },
        {
            "subject": "Re: secure tcp port",
            "content": "> > TLS requires a CA, unless one of the proposed shared key\n> > mechanisms are adopted. There is not a global CA\n> > infrastructure, more or less a US infrastructure. Worse, in\n> > the US there is the real possibility of escrow. Associated with\n>\n> Begging your pardon, but Thawte's strategy is entirely\n> global. Also, because we are based outside the US, the only way\n> we would consider escrow is if the US government explicitly\n> banned the use of non-escrow keys within the US - an unlikely\n> proposition.\n>\n\nIf Thawte can establish a global presence, comply with\ninternational and domestic law, assure the authenticity of\nevery source (implying possible legal liabilities), assure\nthe redundancy, reachability, and integrity of each of their\nCAs (implying liabilities again), and interoperate with\nexisting CAs (such as AT&T), then they will offer a great\nservice. However, if they cannot then the service is of\nmarginal value and no different than the patchwork of CAs\noperating today.\n\n\n> > most CAs is a financial transaction. Though traditional use of\n> > security (in particular, cryptography) has often been\n> > labeled as \"not for free\", requiring investment in a CA or\n> > purchase of a CERT gives the term new meaning.\n>\n> As soon as it's possible to conduct quality checks free, there\n> will be quality free certs. Certification should not be an\n> expensive thing at all. We don't think so.\n>\n\nI haven't read anything on the subject in a while but in the US\nthere was a proposal to have the US Postal Service offer CA\nservices and issue CERTs based on the presentation of US\naccepted identification.\n\nI do not recall if the proposal included a fee for CERT issuance.\nI also am suspect on the \"US accepted identification\" part. If I\nremember correctly the identification was a valid US driver\nlicense. Ha!\n\n\nThe issuance of a CERT must be based on strong verification of\nwho it is issued against. Without strong verification the\nauthenticity of any CERT is suspect. Verification offers\ninteresting challenges not only in the US but around the globe.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Re: TLS does not require an external Certificate Authorit",
            "content": "> Sorry, I missed where we got the assertion that TLS requires a\n> CA.\n>\n> As I understand it TLS requires a ROOT CERTIFICATE and\n> CERTIFICATES. [Assuming the identity-based case, not the\n> anonymous case.] Implementations can do whatever they wish to\n> come up with the root certificate.  I might deal with that by\n> configuring my implementation to use Thawte's root\n> certificate and use them as a CA.  Someone else might set up a CA\n> for use inside a corporation or other organization.  Someome\n> might even set things up to self-sign or deliver a signature\n> engine fairly widely.  One can look at PGP as an example of this.\n>\n> I don't see that there is any technical REQUIREMENT in TLS that I\n> pay anyone to act as my certificate authority.  I myself use it\n> that way sometimes but that's an implementation and\n> deployment detail, not a requirement of the protocol.\n>\n\nDeployment is what it is all about, isn't it? What good is a\nprotocol if it can not be deployed?\n\nCertainly a company can set up its own root certificate, but\nwhat happens when their services access outside services?\nDoes each an every service accessed by the company going to\nrequire their certificate or root certificate to be signed by\nthe company? Perhaps the company may think so but that is\nunrealistic and unmanageable. What is realistic and\nmanageable is a trusted CA. However, considering todays\npatchwork of CAs the problem is the same.\n\nIt will be interesting to see the effect when a CA recertifies\nitself. Perhaps the bank vault where Thwate stores its private\nkey is robbed or obtained by legal means and the key compromised\n(in the US the result of a discovery is often public). Probable.\nWhat then?  At least with a CA infrastructure roots can be cross\ncertified (as in the case of PGP) and CRLs published.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SS",
            "content": "Robert Goodwin wrote:\n> \n> > Labeling this UNIX \"hack\" as a security feature is incredibly\n> > irresponsible. It never was and it never will be. Anybody that relies on\n> > it for protection is security hazzard waiting to be exploited.\n> \n> Indeed; I never intended to imply that it should be relied upon. But that\n> *is* the reason why the numbers < 1024 are different; there is no other\n> reason. As someone has pointed out to me, given the nature of the services\n> being discussed with their proof of identity by both parties there is\n> absolutely no security-related reason why numbers >1024 should not be used.\n\nThis notion is normally regarded as a UNIX-ism (probably a BSD-ism), the\nreality is that there are NO trusted semantic bindings on the ordinal\nvalue of the port number.\n \n> \n> However, since port numbers >1024 are available to any user on the system,\n> does one not run the risk of finding the port already in use by a user?\n> \n\nIt makes it harder in that the 16-bit namespace does not have a\npartition of \"well known\" values, but that partitioning is mostly a\nconvenience that is wasteful of a somewhat critical resource.\n\nSince some port numbers have already been assigned for use by SSL (and\ncan logically be assumed by TLS) through official channels, I assume\nthat the values assigned were deemed available and appropriate. The fact\nthat they have ordinal values less that 1024 does not seem significant,\nonly that they are reserved and well known. I believe that is the\nessence of Christopher Allen's proposal that started this little\ntangential discussion.\n\nHowever, ...\n\nI do beleive that if one was designed new protocols at or above what\nmight be labeled as the session (layer-5 in the OSI scheme) that the\ndesign should incorporate a mechanism for selecting security options.\nThat would eliminate the need for dual port assignments.\n\nOne could also carry it further and make the service protocol stack\nstructure available through a directory server, including the port\nnumber assigned to an instance of the service. That would eliminate the\nneed for all well known ports except for the directory (secure and\ninsecure, of course :-)).\n\nAll such mechanisms take careful thought and planning. They imply\nchanges in the ways things work, and that's something the industry has\nbeen resistant to accept. I do not think such mechanisms are appropriate\nfor the issues being addressed by the current TLS specification.\n\n-- \nAlan O. Freier               Corporate Cynic\n<freier@netscape.com>        (415) 937-3638 (work)\n\n\n\n"
        },
        {
            "subject": "RE: Shared Secret Authenticatio",
            "content": "I know of no sense in which our shared-secret authentication proposal is\nless secure than Bellovin-Merritt-style authentication.  The major\ndifference between the two is that our proposal only authenticates *one*\nparty (the TLS client) using the shared key; the other party (the TLS\nserver) must still have a certified public key to authenticate.  In\nBellovin-Merritt-style authentication, *both* sides authenticate using\nthe same shared key.  This second authentication actually *reduces* the\nsecurity of the protocol; for example, *both* sides (not just the\nserver) must guard against online brute-force attacks on the shared key.\n (On the \"plus\" side, it eliminates the need for one party to have a\ncertified public key.)\n\nWe decided that for the applications we had in mind, requiring that the\nserver obtain a certificate was not as problematic as worrying about\nattacks on the client.  Of course, if people are very enthusiastic about\nhaving Bellovin-Merritt-style two-way shared-key authentication as an\noption in TLS, then I would invite them to write up a proposal in\nInternet Draft form and submit it to the ietf-tls list.  I, for one,\nwould certainly not oppose its inclusion, provided it is incorporated in\nas secure a manner as possible.\n\nDaniel Simon\nCryptographer, Microsoft Corp.\n(dansimon@microsoft.com)    \n\n>-----Original Message-----\n>From:David P. Jablon \n>Sent:Thursday, February 06, 1997 3:52 PM\n>To:ietf-tls@w3.org\n>Subject:Shared Secret Authentication\n>\n>\n>Earlier threads on this list seem to have focused debate on\n>weak methods for password/passphrase/shared-secret authentication.\n>\n>Methods that are immune to unconstrained dictionary attack\n>have been around since 1992, from Bellovin & Merritt's EKE family\n>of protocols, to the SPEKE method developed by myself.\n>I find it curious that the debate has settled down upon\n>demonstrably weaker alternatives, as in the current drafts.\n>\n>I would suggest that the passauth-00.txt \"Addition of\n>Shared Key Authentication\" document be modified to use\n>strong password authentication.  Presenting weak password\n>authentication as an alternative to strong public-key\n>methods seems sloppy.\n>\n>I really prefer the combination of strong public-key AND\n>strong memorizable passwords, as two independent factors for\n>authentication, but that's probably asking for a bit much at\n>this point.\n>\n>------------------------------------\n>David P. Jablon\n>Integrity Sciences, Inc.\n>Westboro, MA\n>Tel: +1 508 898 9024\n>http://world.std.com/~dpj/\n>E-mail: dpj@world.std.com\n>\n\n\n\n"
        },
        {
            "subject": "NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "I believe that this new draft addresses the concerns brought up on the\nSSL-Talk and IETF-TLS lists, yet still allows us to move forward for those\nwho need to interoperate now.\n\nIf you have any comments about these specific requests, please cc: both\nlists, <SSL-Talk@netscape.com> and <ietf-tls@w3.org>. However, any comments\nregarding requirements for single port/port mapping solutions should be\nexclusively on <ietf-tls@w3.org> as that will be in our queue for future\nstandards work.\n\nI will be sending the final version of this request to the IANA on\nWednesday, November 12th.\n\n---------\nThe SSL 3.0 protocol has the broadest implementation of any security\nstandard to date, with both Netscape and Microsoft using it in their\npopular servers and browsers. SSL 3.0 has been submitted to the TLS working\ngroup of the IETF, and is is proceeding out of internet-draft status under\na new name, TLS.\n\nTim Dierks and I are editors for that working group, Win Treese\n<treese@OpenMarket.com> is the working group chair, and Jeff Schiller\n<jis@mit.edu> is the IESG area director over the WG.\n\nTim are I have two documents undergoing revision:\n<draft-ietf-tls-protocol-00.txt> & <draft-ietf-tls-ssl-mods-00.txt>, which\nwere approved during the last working group meeting in San Jose, and are\nbeing merged into one draft as we speak.\n\nOne area that I am trying to resolve are the port and port naming issues\nwith TLS/SSL.\n\nAs a transport layer security standard, TLS/SSL can work transparently with\nexisting application level protocols (such as http, nntp, nttp) without\n*any* change to the protocol other than using a different port number. As\nan example, the popular http protocol uses port 80, and the SSL enabled\nversion of http uses 443.\n\nIt is possible for a single port to be used for both unsecure and secure\nuses, however, this requires two things:\n\n* Changes in the application level protocols which must\n          be separately adopted by each working group over such\n          protocols. An example of changes that would allow for\n          a single port in the FTP protocol is covered in\n          <draft-murray-auth-ftp-ssl-00.txt>\n\n        * Support by firewalls to understand and resolve\n          use of a single port for both unsecure and secure uses.\n\nIt is also possible that there could be a single port/port mapping solution\nto allow any protocol to be used with TLS without port proliferation,\nhowever, after considerable discussion in the TLS working group there is no\neasy design that resolves both architecture and security issues. We have\nagreed to add to the TLS agenda and charter to resolve this problem in the\nfuture.\n\nThus, until each protocol is revised to allow for authenication under a\nsingle port, or a single port/port mapping solution is architected, we will\nrequire separate ports for TLS/SSL implementations of the most popular\nprotocols.\n\nThere are a number of ports currently registered with the IANA the for use\nby the SSL protocol. They are:\n\nhttps       443/tcphttps\nssmtp       465/tcpssmtp\nsnews       563/tcpsnews\nssl-ldap    636/tcpssl-ldap\nspop3       995/tcpSSL based POP3\n\nAs the above registrations are inconsistant, and most don't even mention\nSSL or TLS, we would like to get these port assignments and names\nregularized in the listing as follows:\n\nhttps       443/tcphttp protocol over TLS/SSL\nsmtps       465/tcpsmtp protocol over TLS/SSL (was ssmtp)\nnntps       563/tcpnntp protocol over TLS/SSL (was snntp)\nldaps       636/tcpldap protocol over TLS/SSL (was sldap)\npop3s       995/tcppop3 protocol over TLS/SSL (was spop3)\n\nThere is also currently a desire among existing SSL implementors to\nregister a number of additional ports mappings for other protocols such as\nftp. We want to avoid port proliferation as much as possible until we have\na long term solution, so we have limited these requests to those protocols\nin which we have recieved commitments from a minimum of 2 independent\nimplementations by developers.\n\nWe have been told that some of these invididual implementors may have\nattempted to register ports for these uses of SSL, but as of today they\nhave not recieved registration for these assignments.\n\nWe would like to suggest the following:\n\nftps-data   889/tcpftp protocol, data, over TLS/SSL\nftps    990/tcpftp protocol, control, over TLS/SSL\nimaps       991/tcp imap4 protocol over TLS/SSL\ntelnets     992/tcp  telnet protocol over TLS/SSL\nircs        993/tcp  irc protocol over TLS/SSL\n\nI also have a question -- who requested the following service? We don't\nknow if it is our SSL or something else with the same acronym.\n\nnaming-iiop-ssl 261/tcp    IIOP Naming Service (SSL)\n\nUnder your procedures, you ask for answers to the following questions:\n\n1)  What is the protocol between the user machine and the server\n    machine?\n\nIt is the TLS 1.0 or SSL 3.0 protocol as defined in\n<draft-ietf-tls-protocol-00.txt> & <draft-ietf-tls-ssl-mods-00.txt>.\n\n2)  What message formats, types, op codes, sequences are used?\n\nIt is the TLS 1.0 or SSL 3.0 protocol as defined in\n<draft-ietf-tls-protocol-00.txt> & <draft-ietf-tls-ssl-mods-00.txt>.\n\n3)  What functions are performed by this protocol?\n\nSecuring and authenticating the transport independently of the application\nprotocol.\n\n4)  Is broadcast or multicast used?  If so, how and what for?\n\nNo -- TCP only is defined by TLS/SSL at this point, however, we'd like to\nat least hold the UDP ports in reserve for the future.\n\n5) Do you want a well-known assigned system port in the range 0-1023,\n   or a registered user port in the range 1024-65535 ?\n\nThey need to be in a the well known range as they are largely being\nimplemented initially by unix developers who want to be sure that it is the\nwell-known range.\n\n6)  What short name (14 character maximum) do you want associated with\n    this port number?\n\nftps-data   889/tcpftp protocol, data, over TLS/SSL\nftps    990/tcpftp protocol, control, over TLS/SSL\nimaps       991/tcp imap4 protocol over TLS/SSL\ntelnets     992/tcp  telnet protocol over TLS/SSL\nircs        993/tcp  irc protocol over TLS/SSL\n\nIf there are any questions as to our authority to request such changes,\nthese changes have been run by the WG Chair, Win Treese\n<treese@OpenMarket.com>and Jeff Schiller <jis@mit.edu> is the IESG area\ndirector over the TLS WG. In addition, these requests were run by Netscape,\nMicrosoft, the SSL-Talk mailing list and the IETF-TLS working group mailing\nlist, and rough consensus was achieved before being sent to you.\n\nIf you have any questions, please feel free to give me a call at\n510/559-1500 or email me at Christopher Allen <ChristopherA@consensus.com>.\n\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "Christopher Allen writes:\n \n[..]\n\n> We would like to suggest the following:\n> \n> ftps-data   889/tcpftp protocol, data, over TLS/SSL\n> ftps    990/tcpftp protocol, control, over TLS/SSL\n> imaps       991/tcp imap4 protocol over TLS/SSL\n> telnets     992/tcp  telnet protocol over TLS/SSL\n> ircs        993/tcp  irc protocol over TLS/SSL\n\nAccording to the IANA document\nhttp://www.isi.edu/in-notes/iana/assignments/port-numbers~, 991 is\nalready assigned:\n\nnas             991/tcp    Netnews Administration System\nnas             991/udp    Netnews Administration System\n#                          Vera Heinau <heinau@fu-berlin.de>\n\nThe document lists 992-994 as being free, so maybe just move imaps\nto 994.\n\nBTW, I count 504 assigned Well Known TCP ports from 0-1023, 506 if you count\n0 and 1023 which are both reserved.\n\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "On Fri, 7 Feb 1997, Christopher Allen wrote:\n\n> I believe that this new draft addresses the concerns brought up on the\n> SSL-Talk and IETF-TLS lists, yet still allows us to move forward for those\n> who need to interoperate now.\n> \n\n(much deleted...)\n\n> \n> https       443/tcphttps\n> ssmtp       465/tcpssmtp\n> snews       563/tcpsnews\n> ssl-ldap    636/tcpssl-ldap\n> spop3       995/tcpSSL based POP3\n> \n> As the above registrations are inconsistant, and most don't even mention\n> SSL or TLS, we would like to get these port assignments and names\n> regularized in the listing as follows:\n\nThat's kind of funny. spop3 and ssl-ldap both mention ssl :-)\n\n> \n> https       443/tcphttp protocol over TLS/SSL\n> smtps       465/tcpsmtp protocol over TLS/SSL (was ssmtp)\n> nntps       563/tcpnntp protocol over TLS/SSL (was snntp)\n> ldaps       636/tcpldap protocol over TLS/SSL (was sldap)\n> pop3s       995/tcppop3 protocol over TLS/SSL (was spop3)\n> \n\nSorry for being pessimistic, please don't take this negatively, I\njust have some questions, being an implementor and one who has\nactually registered one of the above ports.\n\nI guess the real question is, does this will this \"obsolete\" any current\nproducts that do not do TLS on the above ports?\n\nIs \"TLS\" available from any vendor, aside from the author of this draft?\n\nWhat is the status of the TLS track? Are we commiting to a moving to\nTLS for the sole reason of supporting a vendor's efforts to single-handedly\ncontrol TLS? What about if/when SSH moves into TLS? Does that\nmean that the above must also support that?\n\n> \n> If there are any questions as to our authority to request such changes,\n> these changes have been run by the WG Chair, Win Treese\n> <treese@OpenMarket.com>and Jeff Schiller <jis@mit.edu> is the IESG area\n> director over the TLS WG. In addition, these requests were run by Netscape,\n> Microsoft, the SSL-Talk mailing list and the IETF-TLS working group mailing\n> list, and rough consensus was achieved before being sent to you.\n> \n> \n> ------------------------------------------------------------------------\n> ..Christopher Allen                  Consensus Development Corporation..\n> ..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n> ..                                             Berkeley, CA 94707-2116..\n> ..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n> ..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n> \n> \n\n----\nPat Richard\npatr@x509.com\n\n\n\n"
        },
        {
            "subject": "Re: Trust chaining &amp; finergrained CA trus",
            "content": "Is Pat Richard enquiring re: what I interpret to be a grab for exclusive\npower?  Is that \"monopoly?\"  Does that retain the inner-sanctum idea of\n\"open platform?\"\n\nIs winning a monopoly relevant?  Is this group not seeking the most\ncompetent long-term resolution, irrespective of toolkit or patent control?\n\nShould there be an additional period of time...2 weeks or a month, during\nwhich to reflect on what is being driven home at this moment?\n\nIf this group were to express a desire for an extension of time and/or a\nreconsideration of the proposal, who has the ultimate decision power?  The\nindividual at the outfit that will win the monopoly or someone else?\n\nIs this the appropriate place to suggest a call for such a vote?  Do I have\nthe right to ask?\n\nRay Sarna\n\n\nAt 04:29 PM 2/7/97 -0800, you wrote:\n>On Fri, 7 Feb 1997, Tom Weinstein wrote:\n>\n>> Mark Shuttleworth wrote:\n>> > \n>> > Hiya\n>> > \n>> > Perhaps I missed this bit,  but surely the UI on the browser should\n>> > put big flashing warnings up before letting the user accept a\n>> > chainable CA cert?\n>> \n>> Nope.  If the CA issues a cert with the correct extension for the\n>> navigator to trust it as a CA, we assume that they are delegating\n>> issuing authority.  VeriSign uses this so that they can have multiple\n>> CAs that actually issue certs descended from a single root CA that\n>> just issues CA certs.\n>> \n>> This makes a lot of sense from a security perspective.  The keys that\n>> issue certs get used a lot, so they are most vulnerable to attack.  If\n>> you expire them frequently and keep the only copy of the root key locked\n>> up in a vault, for example, you reduce your exposure.\n>> \n>\n>Actually, it doesn't, with the respect to the question of this entire \n>thread, which is \"Fine Grained Trust\".\n>\n>By delegating authority with chains you end up with a PKI (all CA's\n>participating in a chain with a single root) that either:\n>\n>1) forces all CAs to accept the \"LCD\" (lowest common denominator)\n>with respect to trust (i.e. if a CA with low assurance is in the chain,\n>then all CA's in that chain now have low assurance)\n>\n>or\n>\n>2) force all CAs in that chain to be 100% compliant with the root\n>CA's vetting policy, which is un-manageable and does not reflect\n>real-world trust models.\n>\n>Alternatively, use a model where the CA's policies and signed and\n>you have policy chains rather than CA cert chains.\n>\n>This way trust is not absolute and can actually exhibit \"fine grained\"\n>features, like a PKI that can determine the assurance level of the\n>2 parties involved.\n>\n>> -- \n>> You should only break rules of style if you can    | Tom Weinstein\n>> coherently explain what you gain by so doing.      | tomw@netscape.com\n>> \n>\n>----\n>Pat Richard\n>patr@x509.com\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "Pat Richard writes:\n \n \n> That's kind of funny. spop3 and ssl-ldap both mention ssl :-)\n\nI think Chris is working off an out-of-date list.\n\n> > https       443/tcphttp protocol over TLS/SSL\n> > smtps       465/tcpsmtp protocol over TLS/SSL (was ssmtp)\n> > nntps       563/tcpnntp protocol over TLS/SSL (was snntp)\n> > ldaps       636/tcpldap protocol over TLS/SSL (was sldap)\n> > pop3s       995/tcppop3 protocol over TLS/SSL (was spop3)\n> > \n> \n> Sorry for being pessimistic, please don't take this negatively, I\n> just have some questions, being an implementor and one who has\n> actually registered one of the above ports.\n> \n> I guess the real question is, does this will this \"obsolete\" any current\n> products that do not do TLS on the above ports?\n\nIt would if they don't do SSL.  There shouldn't be anything on\nthose ports that isn't doing SSL.  If something on those ports does\ntalk SSL3 then it'll be able to talk to implementations talking\nTLS on those ports.  If it's doing SSL2 it might be out of luck...\n\n> Is \"TLS\" available from any vendor, aside from the author of this draft?\n\nMost people with an SSL3 in production have said that they'll\nmove to TLS when it's final.\n\n> What is the status of the TLS track? Are we commiting to a moving to\n> TLS for the sole reason of supporting a vendor's efforts to single-handedly\n> control TLS?\n\nHuh?  Who's single-handedly controlling TLS?  I count as major players\nNetscape and Microsoft, with Consensus coming up.  But they're certainly\nnot the only people involved, nor the only people whos ideas have been\nlisten to.\n\n> What about if/when SSH moves into TLS? Does that\n> mean that the above must also support that?\n\nThat's SSHs problem isn't it?\nI'd hope that since SSH _is_ controlled single-handedly then it'd\ndo the clean solution and negotiate the use of TLS internal to the\nprotocol rather than external via a seperate port number.\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "TLS Draft Statu",
            "content": "Due to an undue number of meetings this week, all of which went\ndramatically longer than expected, the draft isn't yet complete. However,\nprogress is being made, and I have reason to expect completion over the\nweekend. I commit to providing status at the least by Monday at the latest.\n\nFor any nine-to-fivers out there, you probably won't even notice the\ndifference. Everyone else, go home.\n\n - Tim\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "Whoa There--\n\nThe posting below deserves to be publicly answered by MS, NS and Consensus\n*before* any action is taken by ietf-tls or anyone holding themself out as\nempowered to act unilaterally.  \n\nIs there not a potentially obvious opportunity to self-serve and an\nactionable conflict of interest to the community at large.\n\nWhat's the cost of one week, so that each of the three above can step\nforward and commit in writing what their TLS inclusion policy will be?  \n\nI'm just a potential applications user; but I can't believe that the\nietf-tls would run rough-shod over the fourth major member of the\n\"triumverate\"... SSH. \n\nI'd sure like to hear what all four plan to do to keep the platform \"open\".\nI am not ready to hand over my slice of the world to MS, NS, Consensus or\nSSH until I know that baseline development opportunities remain open to\neveryone.\n\nThe whole point is that this is for everyone, not for the quick or\naggressive.  Drop the bully-boy behavior and toss the week or two away until\nthe positions are stated clearly.\n\nI may have missed those *expected* posts before; but meanwhile, I can read\n\"concern\" on the part of one of the new players on the block, XCert.  \n\n...And we all know that they represent the least expensive solution on the\nblock at the moment. :-)  And as to SSH, well they're even less expensive.\n\nI encourage, support, and demand a clear answer to Pat's questions from the\nfolks alluded to in Eric Murray's most recent post (who I've listed above).\n\nI expect the same from any and all others who by the Proposed Draft will\nfind themselves in a position of public trust to keep the internet \"open\"\n*before* any further action is taken by ietf-tls.  \n\n\nRay Sarna\nDirector, aZAP\n\nBTW, any lawyers in this group?  Is this an anti-trust or restraint-of-trade\nissue?  Is it class actionable?\n\n\n>Date: Fri, 7 Feb 1997 16:54:15 -0800 (PST)\n>From: Pat Richard <patr@xcert.com>\n>Subject: Re: NEW DRAFT: Regularizing Port Numbers for SSL.\n\n>On Fri, 7 Feb 1997, Christopher Allen wrote:\n>\n>> I believe that this new draft addresses the concerns brought up on the\n>> SSL-Talk and IETF-TLS lists, yet still allows us to move forward for those\n>> who need to interoperate now.\n>> \n>\n>(much deleted...)\n>\n>> \n>> https       443/tcphttps\n>> ssmtp       465/tcpssmtp\n>> snews       563/tcpsnews\n>> ssl-ldap    636/tcpssl-ldap\n>> spop3       995/tcpSSL based POP3\n>> \n>> As the above registrations are inconsistant, and most don't even mention\n>> SSL or TLS, we would like to get these port assignments and names\n>> regularized in the listing as follows:\n>\n>That's kind of funny. spop3 and ssl-ldap both mention ssl :-)\n>\n>> \n>> https       443/tcphttp protocol over TLS/SSL\n>> smtps       465/tcpsmtp protocol over TLS/SSL (was ssmtp)\n>> nntps       563/tcpnntp protocol over TLS/SSL (was snntp)\n>> ldaps       636/tcpldap protocol over TLS/SSL (was sldap)\n>> pop3s       995/tcppop3 protocol over TLS/SSL (was spop3)\n>> \n>\n>Sorry for being pessimistic, please don't take this negatively, I\n>just have some questions, being an implementor and one who has\n>actually registered one of the above ports.\n>\n>I guess the real question is, does this will this \"obsolete\" any current\n>products that do not do TLS on the above ports?\n>\n>Is \"TLS\" available from any vendor, aside from the author of this draft?\n>\n>What is the status of the TLS track? Are we commiting to a moving to\n>TLS for the sole reason of supporting a vendor's efforts to single-handedly\n>control TLS? What about if/when SSH moves into TLS? Does that\n>mean that the above must also support that?\n>\n>> \n>> If there are any questions as to our authority to request such changes,\n>> these changes have been run by the WG Chair, Win Treese\n>> <treese@OpenMarket.com>and Jeff Schiller <jis@mit.edu> is the IESG area\n>> director over the TLS WG. In addition, these requests were run by Netscape,\n>> Microsoft, the SSL-Talk mailing list and the IETF-TLS working group mailing\n>> list, and rough consensus was achieved before being sent to you.\n>> \n>> \n>> ------------------------------------------------------------------------\n>> ..Christopher Allen                  Consensus Development Corporation..\n>> ..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n>> ..                                             Berkeley, CA 94707-2116..\n>> ..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n>> ..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n>> \n>> \n>\n>----\n>Pat Richard\n>patr@x509.com\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "> The whole point is that this is for everyone, not for the quick or\n> aggressive.  Drop the bully-boy behavior and toss the week or\n> two away until the positions are stated clearly.\n>\n\nWith that said...\n\nIt isn't clear (to me) the value to the community of registering\nall those ports and developing all that code except, perhaps,\nto the profit margins of the few. One of the most disturbing\ncomments of one of the proponents is the one \"I'm a short term\npragmatist and a long term idealist\". The implication is the\nfew want to get their product to market, without considering\nalternatives or engineering good solutions, and those of us\nwith long term Internet interest are stuck holding their bag.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "Dennis Glatting writes:\n> \n> \n> > The whole point is that this is for everyone, not for the quick or\n> > aggressive.  Drop the bully-boy behavior and toss the week or\n> > two away until the positions are stated clearly.\n> >\n> \n> With that said...\n> \n> It isn't clear (to me) the value to the community of registering\n> all those ports and developing all that code except, perhaps,\n> to the profit margins of the few. One of the most disturbing\n> comments of one of the proponents is the one \"I'm a short term\n> pragmatist and a long term idealist\". The implication is the\n> few want to get their product to market, without considering\n> alternatives or engineering good solutions, and those of us\n> with long term Internet interest are stuck holding their bag.\n\nI don't equate registering ports with engineering.\nI'm a proponent of including TLS in each protocols negotiation rather\nthan running on seperate ports.  But there are very good reasons for\ndesignating ports for TLS versions of services.\n\nFirst off, for each protocol to use TLS, someone has to do the work\nof integrating the TLS negotiation into the protocol.  That's not\nall that much work but it's only the beginning, because having TLS\nintegrated into a protocol is only useful if there's a standard way\nof doing it, so you can talk to other implementations.  That means\ngoing through that protocol's standards comittie, or getting agreement\nwith the main developers, or both.  It's a slow process, and one that's\noutside the scope of TLS.\n\nSecond, people want to use SSL/TLS to do things now.  It's not just\na laboratory protocol, there's a number of implementations that\nhave been around for a while, and people want to do things with it.\nIt's a lot more useful to have standard ports for those services\nthan the situation we have now, where various developers just pick\nports and use them, or get the IANA to register them without letting\nthe SSL/TLS community know.\n\nLast, setting aside these ports does not mean that we're stuck using\nthem forever.  Like I said before, I think that negotiating SSL/TLS\ninside application protocols is the way to go.  If I'm right, then\nthat's what will happen in the future as the people who develop applications\nfor those protocols realize that it's possible and a good idea.\nIf I'm wrong about that, well then there's no harm and we can go on\nusing the proposed/existing  *s SSL/TLS-enabled services.\nIf I'm right, then those ports will become unused... no big deal.\n\n\nTo answer some other people's questions, Ray Sarna asks \"what about SSH?\".\nWe discussed SSH at the second 'ad hoc' meeting (and Tatu Ylonnen was there)\nthat formed the working group.  We also discussed SSH in the mailing list.\nYou should check for an archive, a web search should bring up a couple.\nThe group's decided not to deal with SSH in _this document_.\nI think it's a bad idea to re-hash old discussions, standards bodies\nthat do never get anywhere.   Speaking of which, the last time we discussed\nassigning new ports vs. negotiating SSL/TLS inside application protocols\nthe concensus seemed to be to go with new ports... for the same reasons\npeople want to do so now.\n\n\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "> Dennis Glatting writes:\n> >\n> >\n> > > The whole point is that this is for everyone, not for the quick or\n> > > aggressive.  Drop the bully-boy behavior and toss the week or\n> > > two away until the positions are stated clearly.\n> > >\n> >\n> > With that said...\n> >\n> > It isn't clear (to me) the value to the community of registering\n> > all those ports and developing all that code except, perhaps,\n> > to the profit margins of the few. One of the most disturbing\n> > comments of one of the proponents is the one \"I'm a short term\n> > pragmatist and a long term idealist\". The implication is the\n> > few want to get their product to market, without considering\n> > alternatives or engineering good solutions, and those of us\n> > with long term Internet interest are stuck holding their bag.\n>\n> I don't equate registering ports with engineering.\n>\n\nCheap and easy solution without consideration of long term\nimpact, impact on those who deploy those technologies and\nmaintain them (i.e., corporate and Internet\ninfrastructures), or whether it is a good idea.\n\n\n> I'm a proponent of including TLS in each protocols negotiation\n> rather than running on seperate ports.  But there are very good\n> reasons for designating ports for TLS versions of services.\n>\n\nPerhaps, but how is TLS different than Kerberos IV or V, NetSP,\nSPX, SESAME, EKE, SKPI, or any other security-protocol-of-the-day?\n\nI do not see SSL's ubiquity a reasonable argument not to think\nthings though, consider alternatives, or rush the process.\n\n\n> First off, for each protocol to use TLS, someone has to do the\n> work of integrating the TLS negotiation into the protocol.\n> That's not all that much work but it's only the beginning,\n> because having TLS integrated into a protocol is only useful if\n> there's a standard way of doing it, so you can talk to other\n> implementations.  That means going through that protocol's\n> standards comittie, or getting agreement with the main\n> developers, or both.  It's a slow process, and one that's\n> outside the scope of TLS.\n>\n\nWhy operate outside those committees rather than cooperate\nwith them?\n\nA good example of a WG that does cooperate with other committees\nis CAT. What makes TLS so righteous?\n\n\n> Second, people want to use SSL/TLS to do things now.  It's not\n> just a laboratory protocol, there's a number of\n> implementations that have been around for a while, and people\n> want to do things with it. It's a lot more useful to have standard\n> ports for those services than the situation we have now, where\n> various developers just pick ports and use them, or get the IANA\n> to register them without letting the SSL/TLS community know.\n>\n\nI hear that a lot, but I only hear it from vendors.\n\n\n> Last, setting aside these ports does not mean that we're stuck\n> using them forever.  Like I said before, I think that\n> negotiating SSL/TLS inside application protocols is the way\n> to go.  If I'm right, then that's what will happen in the future as\n> the people who develop applications for those protocols\n> realize that it's possible and a good idea. If I'm wrong about\n> that, well then there's no harm and we can go on using the\n> proposed/existing  *s SSL/TLS-enabled services. If I'm\n> right, then those ports will become unused... no big deal.\n>\n\nYes, actually we are stuck with them. There is a little\nexpressed term given consideration in this forum: legacy.\nXNS-auth is a registered port, it's old, and in some areas still\nin use, so I'm told. The point is the actions taken here have long\nterm impact. I urge responsibility.\n\n\n> To answer some other people's questions, Ray Sarna asks \"what\n> about SSH?\". We discussed SSH at the second 'ad hoc' meeting\n> (and Tatu Ylonnen was there) that formed the working group.  We\n> also discussed SSH in the mailing list. You should check for an\n> archive, a web search should bring up a couple. The group's\n> decided not to deal with SSH in _this document_. I think it's a\n> bad idea to re-hash old discussions, standards bodies that do\n> never get anywhere.   Speaking of which, the last time we\n> discussed assigning new ports vs. negotiating SSL/TLS inside\n> application protocols the concensus seemed to be to go with new\n> ports... for the same reasons people want to do so now.\n>\n\nI mostly disagree. Rehashing old discussions has value,\nthough sometimes monotonous and worse: sleepers. Even the\nASN.1/non-ASN.1 discussions (which drive me mad) have value.\nSSL is a good protocol. I am confident its designers rehashed\nold issues, time and again. That's the way things work: solve\nproblems and try to insure you do not repeat past mistakes or\ncreate new ones.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Re: CAs, and to a lesser extent, port",
            "content": "G'day!\n\nOn 7/02/97 -0800, dennis.glatting@plaintalk.bellevue.wa.us wrote:\n>\n>> > TLS requires a CA, unless one of the proposed shared key\n>> > mechanisms are adopted. There is not a global CA\n>> > infrastructure, more or less a US infrastructure. Worse, in\n>> > the US there is the real possibility of escrow. Associated with\n>>\n>> Begging your pardon, but Thawte's strategy is entirely\n>> global. Also, because we are based outside the US, the only way\n>> we would consider escrow is if the US government explicitly\n>> banned the use of non-escrow keys within the US - an unlikely\n>> proposition.\n>>\n>\n>If Thawte can establish a global presence, comply with\n>international and domestic law, assure the authenticity of\n>every source (implying possible legal liabilities), assure\n>the redundancy, reachability, and integrity of each of their\n>CAs (implying liabilities again), and interoperate with\n>existing CAs (such as AT&T), then they will offer a great\n>service. However, if they cannot then the service is of\n>marginal value and no different than the patchwork of CAs\n>operating today.\n>\n>\n>> > most CAs is a financial transaction. Though traditional use of\n>> > security (in particular, cryptography) has often been\n>> > labeled as \"not for free\", requiring investment in a CA or\n>> > purchase of a CERT gives the term new meaning.\n>>\n>> As soon as it's possible to conduct quality checks free, there\n>> will be quality free certs. Certification should not be an\n>> expensive thing at all. We don't think so.\n>>\n>\n>I haven't read anything on the subject in a while but in the US\n>there was a proposal to have the US Postal Service offer CA\n>services and issue CERTs based on the presentation of US\n>accepted identification.\n>\n>I do not recall if the proposal included a fee for CERT issuance.\n>I also am suspect on the \"US accepted identification\" part. If I\n>remember correctly the identification was a valid US driver\n>license. Ha!\n>\n>\n>The issuance of a CERT must be based on strong verification of\n>who it is issued against. Without strong verification the\n>authenticity of any CERT is suspect. Verification offers\n>interesting challenges not only in the US but around the globe.\n>\n>\n\nand also\n\n>> Sorry, I missed where we got the assertion that TLS requires a\n>> CA.\n>>\n>> As I understand it TLS requires a ROOT CERTIFICATE and\n>> CERTIFICATES. [Assuming the identity-based case, not the\n>> anonymous case.] Implementations can do whatever they wish to\n>> come up with the root certificate.  I might deal with that by\n>> configuring my implementation to use Thawte's root\n>> certificate and use them as a CA.  Someone else might set up a CA\n>> for use inside a corporation or other organization.  Someome\n>> might even set things up to self-sign or deliver a signature\n>> engine fairly widely.  One can look at PGP as an example of this.\n>>\n>> I don't see that there is any technical REQUIREMENT in TLS that I\n>> pay anyone to act as my certificate authority.  I myself use it\n>> that way sometimes but that's an implementation and\n>>deployment detail, not a requirement of the protocol.\n>>\n\n>Deployment is what it is all about, isn't it? What good is a\n>protocol if it can not be deployed?\n\n>Certainly a company can set up its own root certificate, but\n>what happens when their services access outside services?\n>Does each an every service accessed by the company going to\n>require their certificate or root certificate to be signed by\n>the company? Perhaps the company may think so but that is\n>unrealistic and unmanageable. What is realistic and\n>manageable is a trusted CA. However, considering todays\n>patchwork of CAs the problem is the same.\n\n>It will be interesting to see the effect when a CA recertifies\n>itself. Perhaps the bank vault where Thwate stores its private\n>key is robbed or obtained by legal means and the key compromised\n>(in the US the result of a discovery is often public). Probable.\n>What then?  At least with a CA infrastructure roots can be cross\n>certified (as in the case of PGP) and CRLs published.\n\n           **************************************\n\nI carry a photo-ID for my friendly Video Renter, a driver's licence, and\nsometimes, a passport.  Given that I have obtained \"trial\" CAs over the Net,\nI put the \"I am who I say I am\" value of such somewhat below that of my\nRental-ID.  False licences and passports don't seem to be too hard to come\nby, either, for those of criminal intent.  If there really _were_ secure\nmeans of  \nverifying an individual's identity, then the KGB/MI5/CIA would have had\nfewer concerns about \"sleepers\", and we would all be the poorer for the\nloss of some quite entertaining fiction.  Ditto for Corporate Entities,\nwhich are easier to create, then to \"send to the bottom of the Harbour\",\nthan are people.\n\nWhere I _do_ see value in such CA's is in a \"torn-banknote\" protocol:\nsecure exchanges can take place without either party knowing  --  or caring\n --  about the real identity of the other, just that a third party assures\neach that the other is the right one in this instance.\n\nAs an intended implementor of systems sitting on top of (perhaps) TLS, my\nconcerns are simply expressed:  that the content be neither monitored nor\nmodified  --  no industrial espionage, no third-party fraud.  I see the\nsecurity of transactions as the business of security-system (TLS?), and the\ndecision as to whether or not take part in any such transaction as\nbelonging to the End-user, and therefore, to some lesser or greater degree\nthe application-implementor's problem.  \n\nEven for FTP and TELNET.  Does going to an initial port other than 23\n_really_ buy anything?  I see the same amount of processing to be done\nregardless of whether the call's to 23 or 994. Surely the work's actually\ndone using the port allocated to the session, and the algorithm for _that_\nis the designer's choice.\n\nBuying potatoes, hiring a car, and digital inter-bank transfers all need\nboth parties to feel secure, but the concerns about \"who-are-you?\" are\nsomewhat different!   Obviously the (equivalent of the example) greengrocer\nwouldn't check CRLs and search for Revocation Certificates over a\nmetaphorical sack of spuds.  But can you really see Chase Manhattan blindly\ndoing business with The Mortgage and Loan Bank of Oodnagalarbie on the\nbasis of a CRL entry alone, and with no idea of its current financial\nstatus?  No way!  Chase would deal with its Agent in this country for any\nexchange of dollars, and direct contact with  the Mortgage and Loan would\nbe limited to \"advice\".\n\nI also see some value in \"one-time\" CAs on semi-permanent links, where an\noutstation's CAs can be used once only, and CA #n and all its predecessors\nare invalidated by receipt of CA #n+1, a la Verisign.  I can't see how a CA\nfrom \"outside\" would be of any benefit here.\n\nBy all means provide \"default\" processing, but please don't make it\ndifficult for us Applications people to look at CAs and judge:  what degree\nof faith we should put in them;  what liberties the owner of a particular\nCA should be allowed.  I have great trouble believing \"Don't worry, my boy,\nwe'll take care of it  --  one size fits all.\"\n\nRegards,\nJim LW   \n\n\n\nFrom the BBC's \"Barchester Chronicles\":\n\n    \"I know that ultimately we are not supposed to understand.\n    But I also know that we must try.\"\n\n       -- the Reverend Septimus Harding, \n          tax-consultant, crypt-analyst, clog-dancer, C++ programmer\n\n\n\n"
        },
        {
            "subject": "Re: Shared Secret Authenticatio",
            "content": "At 09:19 AM 2/7/97 -0500, David P. Kemp wrote:\n>> From: \"David P. Jablon\" <dpj@world.std.com>\n>> \n***snip...\n\n>The TLS working group also expressed concern about using patented\n>compression technology from Hi-Fn (Stac), although it may be possible\n>to implement the proposed compression method in a non-infringing way.\n\nAs I recall, the concerns expressed related to the history of first getting\nthe Hi/fn compression used in the PPP environment. Those concerns, if you\nrecall from the meeting, were addressed directly (by me, the presenter).\nLike the PPP environment, the group can choose to implement whatever\ncompression it likes. There are more than 10 compression options available\nfor PPP, some of which are not even publically defined (proprietary/trade\nsecret to the vendor). Since TLS has the negotiation capabilities to choose\na compression method (as does PPP), any number of compression methods can\nbe supported. Our goal is not to force the group to choose a single method,\nbut to simply propose one. The hooks for compression have been present for\nsome time, but none of the visible SSL implementors appeared to have put\nthem to use.\n\nFor those interested in getting a copy of our 2-page no-cost license\nagreement, feel free to contact me.\n\nBob Monsour\nrmonsour@hifn.com\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "To close out this issue, I propose that the TLS spec forbid\nnegotiating to NULL_WITH_NULL_NULL. I understand\nthe argument for testing, but I suspect the risks of this in\npractical deployment make it dangerous.\n\nWin Treese\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "I think that we have a practical problem to solve in\nthe short term. Even if we agreed that the \"right thing\"\nwas to multiplex applications over a TLS channel, or\nthat the \"right thing\" was to let applications negotiate\ntheir own use of TLS, it would take a while to get the\nnecessary specs on the standards track.\n\nChris's proposal lets a number of projects proceed,\nso I think we should go ahead with it. I encourage\ncontinued thinking and proposals to solve the broader\nproblem, but I think they go beyond the charter of\nthis working group now.\n\nWin Treese\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> I think that we have a practical problem to solve in\n> the short term. Even if we agreed that the \"right thing\"\n> was to multiplex applications over a TLS channel, or\n> that the \"right thing\" was to let applications negotiate\n> their own use of TLS, it would take a while to get the\n> necessary specs on the standards track.\n> \n> Chris's proposal lets a number of projects proceed,\n> so I think we should go ahead with it. I encourage\n> continued thinking and proposals to solve the broader\n> problem, but I think they go beyond the charter of\n> this working group now.\n\nYou can never undo this, Win.  Never ever.  Once IANA approves that\nrequest those ports are gone in the short and long term,  because somebody\nsomewhere will still be running a secure server on one of them.\n\nIf there were even one shred of evidence that NS and MS had met to resolve\nthis \"The Right Way\",  and failed,  then that would be one thing.  But\nthere is no such evidence.  This is an exercise in stubborness.  I hope\nthe IANA returns this request to sender with a clear message that no such\nrequests will be considered until they are the last resort,  not the\nfirst.\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Mark Shuttleworth writes:\n> Win Treese wrote:\n> > I think that we have a practical problem to solve in\n> > the short term. Even if we agreed that the \"right thing\"\n> > was to multiplex applications over a TLS channel, or\n> > that the \"right thing\" was to let applications negotiate\n> > their own use of TLS, it would take a while to get the\n> > necessary specs on the standards track.\n> > \n> > Chris's proposal lets a number of projects proceed,\n> > so I think we should go ahead with it. I encourage\n> > continued thinking and proposals to solve the broader\n> > problem, but I think they go beyond the charter of\n> > this working group now.\n> \n> You can never undo this, Win.  Never ever.  Once IANA approves that\n> request those ports are gone in the short and long term,  because somebody\n> somewhere will still be running a secure server on one of them.\n> \n> If there were even one shred of evidence that NS and MS had met to resolve\n> this \"The Right Way\",  and failed,  then that would be one thing.\n\nMark, why do NS and MS need to meet on this?  We, the IETF working\ngroup, are the ones making the decision, not NS and MS.  Admittedly\nmuch of the WG's discussions have been MS vs NS but I think we've been\ngetting away from that, and I think that's a good thing.\n\nWhy would you want to re-politicize the WG?\n\n>  But there is no such evidence.  This is an exercise in stubborness. \n\nI fail to see the great conspiracy that you (and others) are alluding to.\nUsually I'm first to see stuff like that, not the last. :-)\nCould someone explain to me why calls to actually go ahead with something\n(like we agreed to at the San Jose meeting in December) appear to\nthem to be evidence that someone's putting something over on them?\n\n\n> I hope\n> the IANA returns this request to sender with a clear message that no such\n> requests will be considered until they are the last resort,  not the\n> first.\n\nThe alternatives are taking 6 months or a year (more likely a year) of dicking\naround trying to A) get people to write drafts on TLS-MUX, and running\ncode (\"concensus and running code\" remember), then adopting that.\nB) getting people to write drafts for negotiating TLS in the various\napplication protocols, then working with the IETF groups that oversee\nthose protocols to incorporate TLS into them. \nor C) we could forget about specifying ports at all.  However the likely\nresult of that would be a whole lot of people in the field putting an\nTLS library together with their favorite TCP apps and just running it\non whatever port they have free at the moment.\n\n\n\n-- \nEric Murray  ericm@lne.com  ericm@motorcycle.com  http://www.lne.com/ericm\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "At 04:54 PM 2/7/97 -0800, you wrote:\n>> https       443/tcphttps\n>> ssmtp       465/tcpssmtp\n>> snews       563/tcpsnews\n>> ssl-ldap    636/tcpssl-ldap\n>> spop3       995/tcpSSL based POP3\n>> \n>> As the above registrations are inconsistant, and most don't even mention\n>> SSL or TLS, we would like to get these port assignments and names\n>> regularized in the listing as follows:\n>\n>That's kind of funny. spop3 and ssl-ldap both mention ssl :-)\n\nYes but rfc 1700 doesn't say anything about SSL being used in https and\nwho's this \"MCOM\" they mention anyway?\n\n  ...edited for brevity.  see original for full text...\n\n>I guess the real question is, does this will this \"obsolete\" any current\n>products that do not do TLS on the above ports?\n\nI think not as the revision number scheme should prevent that problem.\n\n>Is \"TLS\" available from any vendor, aside from the author of this draft?\n\nI believe the answer to that is NO.  Nobody.\n\n>What is the status of the TLS track?\n\nI believe the status of it is \"deliver or be cancelled\".  Therefore, we are\nstriving to deliver.\nPeople have better things to do than follow irrelevant committees.  (At\nleast some people do...)\n\n> Are we commiting to a moving to\n>TLS for the sole reason of supporting a vendor's efforts to single-handedly\n>control TLS?\n\nHell no.  If I wanted single vendor control I'd sit at home and read my\nMSDN CD's and log on to developer.netscape.com and believe everything I\nread there.\n\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "RE: Shared Secret Authenticatio",
            "content": "[ Continued discussion of shared-key authentication for TLS\n  compares Bellovin & Merritt-style methods (DH-EKE, SPEKE, etc.)\n  to the randomized hash exchange in the Microsoft proposal\n  (passauth-00.txt).  Includes a short review of the methods. -- dpj ]\n\nAt 01:36 PM 2/7/97 -0800, Dan Simon <dansimon@microsoft.com> wrote:\n\n> I know of no sense in which our shared-secret authentication proposal is\n> less secure than Bellovin-Merritt-style [EKE] authentication. ...\n\nI'll show several ways that EKE methods can improve the\nstrength of your proposal.  For one: EKE can block the\n\"name-spoofing\" attack of Felton, etc.\n\n> ...  The major difference between the two is\n> that our proposal [\"HASH\"] only authenticates *one*\n> party (the TLS client) using the shared key; the other party (the TLS\n> server) must still have a certified public key to authenticate.  In\n> Bellovin-Merritt-style [\"EKE\"] authentication,\n> *both* sides authenticate using\n> the same shared key.  This second authentication actually *reduces* the\n> security of the protocol; for example, *both* sides (not just the\n> server) must guard against online brute-force attacks on the shared key.\n>  (On the \"plus\" side, it eliminates the need for one party to have a\n> certified public key.)\n\nYour analysis seems misleading.  It blurs the distinction\nbetween the shared-key techniques (HASH & EKE) by using\nthem in different systems.  Head-to-head, EKE is always\nstronger.  I'll show two cases for a clearer comparison:\n\n  1)  shared-key plus server \"anonymous\" public-key authentication,\n  2)  shared-key with *no* stored PKs or certs on either side.\n\nCase 1:  Shared-key with anonymous public-key server auth.\n----------------------------------------------------------\nWhen the server first proves himself using public-key\nauthentication, EKE gives added proof of the server's\nidentity, where HASH does not.  The public-key\njust proves that the server is who he *claims* to be,\nbut with problems in the user-interface or user habits,\nthe server's name may be mistaken with an enemy's in\na \"name-spoofing\" attack.\n\nWith HASH, a single, short-lived, name-spoof permits an\nunlimited off-line brute-force attack.  This makes the\nspoofer's job easier, since he doesn't have to sit in\nthe middle of a prolonged session to do damage.\n\nWith EKE, *nobody* gets to do an off-line dictionary attack,\nnot even a spoofer.  The strong two-way proof of the\nshared secret also gives direct confirmation of the server's\nidentity.  This added proof may also be reassuring if\nthere are any doubts about the integrity of the public-key\n\"chain of trust\".\n\nYou state that on-line brute-force attack against the\nclient \"reduces the security of the protocol\".  But this\nis blocked if the server is first PK-authenticated, and it\napplies to HASH as well as EKE, or any other method\nused to prove the client's knowledge.  In any case,\nclient on-line attack requires many spoofing acts\n(100's or 1000's?) against the user, who is likely get\nsuspicious or give up in frustration before the secret\nis revealed.\n\nAlthough Microsoft considers the \"no certificate\" case\nunnecessary for their applications, maybe others would like\nto see the comparison.  (I wasn't sure if the current MS\nproposal ruled out this case.)\n\nCase 2:  Shared-key with no public-keys or certificates\n-------------------------------------------------------\nA HASH method without anonymous public-key (or other)\nassistance is as weak as the vulnerability of the\npassword to brute-force attack.  Off-line attack is\npossible for any eavesdropper.  \n\nAn EKE method performs a *mutual* password verification\nwith no chance for off-line brute-force attack.  Both\neavesdropper and other \"man-in-the-middle\" attacks are\nblocked.\n\nWith both methods, direct bad guesses should be limited\nby the server and by the client, as in all small-secret\nproofs.\n\n[Dan Simon:]\n> We decided that for the applications we had in mind, requiring that the\n> server obtain a certificate was not as problematic as worrying about\n> attacks on the client.  Of course, if people are very enthusiastic about\n> having Bellovin-Merritt [EKE] two-way shared-key authentication as an\n> option in TLS, then I would invite them to write up a proposal in\n> Internet Draft form and submit it to the ietf-tls list.  I, for one,\n> would certainly not oppose its inclusion, provided it is incorporated in\n> as secure a manner as possible.\n\nAs noted above, mutual EKE authentication even with\n\"anonymous\" PK authentication has big advantages,\nwith no added risk.\n\nIn the \"no PK\" case, I think your worries about\non-line spoofing against the client can be largely\nmitigated if the client software discourages too\nmany retries for access failures.  Of course, if\nyou have certified PK's, you've got another strong\nfactor.  In any case, I'm glad to hear that you're\nopen minded about it.\n\nQuick review of EKE methods\n---------------------------\nFor those unfamiliar with EKE-style methods, there\nare actually several families of them.\nIn this example of SPEKE, P is the shared secret,\nall exponentiation is done modulo a huge prime\nm = 2q+1, q is also prime, and Ra, Rb are random\nnumbers.\n        Client creates Ra, sends P^(2 Ra)\n        Server creates Rb, sends P^(2 Rb)\n        Both compute K = P^(2 Ra Rb)\n        Server sends hash(\"server\", K)  [with prior message]\n        Client sends hash(\"client\", K)\n        Each verifies that the other's hash is correct\n            to prove knowledge of P.\n\nThe P^(2 Rx) messages reveal nothing about P, due to the\ndifficulty of the discrete log problem.\n\nQuick review of HASH methods\n----------------------------\nThe \"time-honored\" HASH method is basically:\n\n        Server creates and sends Rb.\n        Client sends hash(\"client\", Rb, P)\n        Server verifies the hash to prove knowledge of P.\n\nThis can be repeated in the reverse direction, but\neither way it's open to an eavesdropper computing\nbrute-force trials of hash(\"client\", Rb, X) offline.\n\nFurther refinement\n------------------\nThere are also extensions to EKE-style methods where\nthe server stores a one-way hashed secret H(P), and\nproves knowledge of P by the client.  With\nthese extensions, theft of H(P) won't allow an\nattacker to masquerade as a client, without first\ncompleting a brute-force attack to get P.\nThis is scalable security that grows nicely\nwith the strength of P.\n\n>>-----Original Message-----\n>>From:David P. Jablon \n>>Sent:Thursday, February 06, 1997 3:52 PM\n>>To:ietf-tls@w3.org\n>>Subject:Shared Secret Authentication\n>>\n>>Earlier threads on this list seem to have focused debate on\n>>weak methods for password/passphrase/shared-secret authentication.\n>>\n>>Methods that are immune to unconstrained dictionary attack\n>>have been around since 1992, from Bellovin & Merritt's EKE family\n>>of protocols, to the SPEKE method developed by myself.\n>>I find it curious that the debate has settled down upon\n>>demonstrably weaker alternatives, as in the current drafts.\n>>\n>>I would suggest that the passauth-00.txt \"Addition of\n>>Shared Key Authentication\" document be modified to use\n>>strong password authentication.  Presenting weak password\n>>authentication as an alternative to strong public-key\n>>methods seems sloppy.\n  [In retrospect, this wording was sloppy.  I really found\n   passauth-00 to be clear and honestly written, even if\n   in need of improvement. -- dpj]\n>>\n>>I really prefer the combination of strong public-key AND\n>>strong memorizable passwords, as two independent factors for\n>>authentication ...\n\n------------------------------------\nDavid P. Jablon\nIntegrity Sciences, Inc.\nWestboro, MA\nTel: +1 508 898 9024\nhttp://world.std.com/~dpj/\nE-mail: dpj@world.std.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "Win,\n\nWin Treese wrote:\n> \n> I think that we have a practical problem to solve in\n> the short term. Even if we agreed that the \"right thing\"\n> was to multiplex applications over a TLS channel, or\n> that the \"right thing\" was to let applications negotiate\n> their own use of TLS, it would take a while to get the\n> necessary specs on the standards track.\n> \n> Chris's proposal lets a number of projects proceed,\n> so I think we should go ahead with it. I encourage\n> continued thinking and proposals to solve the broader\n> problem, but I think they go beyond the charter of\n> this working group now.\n\n  I am not sure that I agree in total.  But as I am probaly\nin a minority possition here.  I suppose the point is Moot.\nIt jsut seems to me that additional ports are just not \nnecessary and a bad idea long term.  I understand the \ntime element for some projects.  I just feel that it is a bad\ntrade off.  Sets a bad precident.\n\n> \n> Win Treese\n\nRegards,\n-- \nJeffrey A. Williams\nDIR. Internet Network Eng/SR. Java Development Eng.\nInformation Eng. Group. \nPhone :913-294-2375 (temporary)\nE-Mail jwkckid1@ix.netcom.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "At 7:19 AM -0800 2/9/97, Eric Murray wrote:\n>I fail to see the great conspiracy that you (and others) are alluding to.\n>Usually I'm first to see stuff like that, not the last. :-)\n>Could someone explain to me why calls to actually go ahead with something\n>(like we agreed to at the San Jose meeting in December) appear to\n>them to be evidence that someone's putting something over on them?\n\nThat is correct -- the requests for additional ports that are included in\nmy proposal were *NOT* made by NS or MS. They were made by small developers\nlike you and I that feel that they have a niche to fill by offering a\nsecure ftp, irc, etc. *now* before the big guys close in over them.\n\nI will also say that Consensus Development is *not* planning to come out\nwith secure ftp, irc, etc., so there is no conspiracy here either.\n\n>The alternatives are taking 6 months or a year (more likely a year) of dicking\n>around trying to A) get people to write drafts on TLS-MUX, and running\n>code (\"concensus and running code\" remember), then adopting that.\n>B) getting people to write drafts for negotiating TLS in the various\n>application protocols, then working with the IETF groups that oversee\n>those protocols to incorporate TLS into them.\n>or C) we could forget about specifying ports at all.  However the likely\n>result of that would be a whole lot of people in the field putting an\n>TLS library together with their favorite TCP apps and just running it\n>on whatever port they have free at the moment.\n\nI have said that I would keep those who sent me product plans confidential,\nbut if you have products that your company wants to ship that you need some\nports for now, speak now, or risk that we'll wait another year before your\nproduct can interoperate with others.\n\nI've received quite a few private emails supporting the ports proposal --\nit is time that you make your opinions public.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "At 6:56 AM -0800 2/9/97, Jeff Williams wrote:\n>It jsut seems to me that additional ports are just not\n>necessary and a bad idea long term.  I understand the\n>time element for some projects.  I just feel that it is a bad\n>trade off.  Sets a bad precident.\n\nI disagree -- we are setting a good precedent. Before now anyone could just\nask for an SSL port, a number of people have done so (including X.Cert, who\nrequested SSL-LDAP and yet is one of the people complaining here!), and the\nports have been issued by the IANA.\n\nNow we are saying \"let's make sure that at least two different companies\nare committed to doing this\" and \"we know there is a long term problem here\nand we have to address it soon\". Both I feel are good precedent.\n\nI have no problem raising the bar a little -- maybe requiring that there\nare three rather than two companies committed to using the ports, or\nrequiring that their names must be public. But forcing the companies to go\nproprietary or ad hoc use of ports is not a good short term decision.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "text/enriched attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "> > Mark:\n> > You can never undo this, Win.  Never ever.  Once IANA approves that\n> > request those ports are gone in the short and long term,  because somebody\n> > somewhere will still be running a secure server on one of them.\n> >\n> > [and]\n> >\n> > I hope\n> > the IANA returns this request to sender with a clear message that no such\n> > requests will be considered until they are the last resort,  not the\n> > first.\n> \n> Eric:\n>\n> The alternatives are taking 6 months or a year (more likely a year) of dicking\n> around trying to A) get people to write drafts on TLS-MUX, and running\n> code (\"concensus and running code\" remember), then adopting that.\n> B) getting people to write drafts for negotiating TLS in the various\n> application protocols, then working with the IETF groups that oversee\n> those protocols to incorporate TLS into them. \n> or C) we could forget about specifying ports at all.  However the likely\n> result of that would be a whole lot of people in the field putting an\n> TLS library together with their favorite TCP apps and just running it\n> on whatever port they have free at the moment.\n\n\nor D) document the port assignments using some mechanism other than\nthe IANA.\n\nI don't have any problem with people solving problems today by agreeing\non separate port assignments.  But I firmly believe that these ad-hoc\nquick fixes should be \"etched in sand\" via an Internet Draft or a BCP,\nand not \"etched in stone\" via the IANA.\n\nI agree completely with Mark - the IANA should use it's good? (DOOM indeed!)\njudgement and reject this request.  If approved, it can never be undone.\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "> From: Christopher Allen <ChristopherA@consensus.com>\n> \n> I will be sending the final version of this request to the IANA on\n> Wednesday, November 12th.\n> ---------------------------------------------------------------\n> \n> If there are any questions as to our authority to request such changes,\n> these changes have been run by the WG Chair, Win Treese\n> <treese@OpenMarket.com>and Jeff Schiller <jis@mit.edu> is the IESG area\n> director over the TLS WG. In addition, these requests were run by Netscape,\n> Microsoft, the SSL-Talk mailing list and the IETF-TLS working group mailing\n> list, and rough consensus was achieved before being sent to you.\n> \n> If you have any questions, please feel free to give me a call at\n> 510/559-1500 or email me at Christopher Allen <ChristopherA@consensus.com>.\n\n\nI believe it is incorrect to claim that rough consensus has been\nachieved on the mailing lists.  If this goes forward, I believe it would\nbe more accurate to state that no consensus was achieved, but that the\nrequest is being made anyway in the interest of expediency.\n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "> \n> To close out this issue, I propose that the TLS spec forbid\n> negotiating to NULL_WITH_NULL_NULL. I understand\n> the argument for testing, but I suspect the risks of this in\n> practical deployment make it dangerous.\n> \n> Win Treese\n\nI concur.\n\n\n\n"
        },
        {
            "subject": "NULL_ ciphersuite meets ftp",
            "content": "*** Resending note of 10/02/97 15:50\n\n  I believe that the proposal to remove NWNN and the proposal\nto define 990 as ftps are mutually exclusive.  This follows some\ndiscussion I had at the FTP-EXT W/G in San Jose who had the following\ncomments about the FTP-SSL proposal.\n\n- The data connection and the control connection in the FTP protocol\nare completely separate.  Negotiating one level of security for the\ncontrol connection should not imply any behavioural changes to the\ndata connection.\n\n- Saying that the data connection must be TLS if the control conection\nis is only valid if ..\n  i) the data connection is capable of setting its' own policies should\n     it so wish.\n ii) The overhead for sending unprotected or pre-protected data is\n     minimal. (and is possible).\n  The much preferred route is to allow the control connection to\nnegotiate the protection level of the data connection.  (see the PROT\ncommand in the CAT draft-ietf-cat-ftpsec-09.txt)\n\n   Thus, by removing the NWNN option in TLS, and without specifying\nhow the control connection can negotiate the behaviour of the data\nconnection (in fact specifying nothing about the data connection)\nyou are removing the ability of the ftp client/server to negotiate\nunprotected data connections (for file lists/pre-encrypted data) this\nis not flexible enough for all the uses of FTP and we should not\nmove forward with this as a specific way of solving a specific problem\nand thus tying down a general protocol like FTP.\n\n   I agree the NWNN is a good candidate for removal, in which case can\nI please propose the following in the specific case of FTP.\n\n   - do NOT propose 990 for ftps (or 989 for ftps-data)\n   - instead, ask the IANA (or whoever) for the telnet string for TLS/SSL\n      as discussed on page 5 of draft-ietf-cat-ftpsec-09.txt\n   - point people who want to do FTP/TLS at the cat ftpsec draft instead\n      of encouraging them to take liberties with ftp.  (That way the\n      draft gets more encouragment to become an RFC) and use the AUTH\n      and PROT commands to negotiate TLS at the application level.\n   - write a document desribing the policy decisions that clients and\n      servers should be aware of, the parts of draft-ietf-cat-ftpsec-09\n      that need to be used for TLS, the expected behaviour of clients\n      and servers when negotiating data channel protection etc...\n      This is the direction that the draft-murray-ftp-auth-00.txt\n      document is going now that the CAT one has re-emerged and I am\n      sure that Tim and Eric (any myself) would welcome interested\n      co-authors from those amongst you who are desparate to get an\n      inter-operable secure FTP defined.\n\n   I don't see how this can be accused of holding anything up, as the\ndraft (cat-ftpsec) is already written and awaiting eager developers.\n\nThanks,\n\n\n\n\n\n\nPaul\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "> I believe it is incorrect to claim that rough consensus has been\n> achieved on the mailing lists.  If this goes forward, I believe it would\n> be more accurate to state that no consensus was achieved, but that the\n> request is being made anyway in the interest of expediency.\n\nOn the other hand ... given the lack of comparably complete alternative\nproposals, I believe it's more accurate to say that there's been a LOT of\ninconclusive grousing.  (Much more than I like to find in my mailbox.)\n\nWe _know_ that using assigned ports works.  Alternatively, we've seen the\nFTP proposal, and one's upcoming for Telnet.  That's the extent of the new\nproposals.  The alternatives to assigning ports are incomplete, and don't\naddress the needs of folk trying to roll out secured applications \"soon\".\n\nSeriously:  those of you who don't like the idea of assigning ports should\nreally be making complete proposals (deployable \"soon\") rather than just\nasking other folk to design to suit your taste.\n\n- Dave\n\n\"The best is the enemy of the good.\" - anon\n\n\n\n"
        },
        {
            "subject": "TLS implementations ",
            "content": "Hi,\n\nI'd like to know if there are any TLS implementations (source code)\navailable.\n\nThanks in advance..\nAjay.\n\n\n\n"
        },
        {
            "subject": "Re: NULL_ ciphersuite meets ftp",
            "content": ">   I believe that the proposal to remove NWNN and the proposal\n> to define 990 as ftps are mutually exclusive.\n\nI'd think not.  TLS_NULL_WITH_NULL_NULL is an unprotected connection.\nRather than using TLS with that cipher suite, just don't use TLS. \nNo loss of functionality whatsoever.\n\n\n>   The much preferred route is to allow the control connection to\n> negotiate the protection level of the data connection.  (see the PROT\n> command in the CAT draft-ietf-cat-ftpsec-09.txt)\n\nThis proposal is _far_ more complicated than the FTP approach described\nin draft-murray-auth-ftp-ssl-00.txt ... and it doesn't even talk about\nhow to make this work with TLS.\n\nOther than the PROT command (which could be added to the ftp-ssl draft),\nthe primary technical advantage that I notice in cat-ftpsec is that it\nexplicitly addresses Kerberos.  Wouldn't it be a lot better to follow\ndraft-ietf-tls-kerb-cipher-suites-00.txt to Kerberize SSL, and then\nfollow the ftp-ssl draft's simpler approach for the rest?\n\n\n>    I don't see how this can be accused of holding anything up, as the\n> draft (cat-ftpsec) is already written and awaiting eager developers.\n\nSimilarly, draft-murray-auth-ftp-ssl-00.txt is already written etc.\n\nSpeaking as a potential implementor, the approach in the ftp-ssl draft\ngets my vote on time to market and on how readily it can be implemented\ncorrectly and interoperably.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: NULL_ ciphersuite meets ftp",
            "content": "David.Brownell@Eng.Sun.COM (David Brownell - JavaSoft) writes:\n\n>> >    I don't see how this can be accused of holding anything up, as the\n>> > draft (cat-ftpsec) is already written and awaiting eager developers.\n>> \n>> Similarly, draft-murray-auth-ftp-ssl-00.txt is already written etc.\n>> \n>> Speaking as a potential implementor, the approach in the ftp-ssl draft\n>> gets my vote on time to market and on how readily it can be implemented\n>> correctly and interoperably.\n\nftpsec-09 current has four organizations (that I know of, there are\nprobably mode) implementing using kerberos or gssapi.  Three of these\nimplementations are independent.  With a few exceptions which recent\nversion of the draft address, they interoperate.  I will admit that I\nhave not read the murray draft, but it seems poor to ignore an\nexisting, implemented propsal.\n\nMarc\n\n\n\n"
        },
        {
            "subject": "Simple TLS/SSL negotiation proposa",
            "content": "Hi folks\n\nI promised this today ;-) \n\n <---- BEGIN SIMPLE TLS TRIGGER PROPOSAL ---->\n\nThere has been considerable debate over the allocation of IP ports purely \nfor the sake of indicating that TLS is required underneath an otherwise \nstandard protocol.  The alternative to a port assignment is a negotiation\nor trigger mechanism within the existing protocol.\n\nHere is a proposal for such a mechanism.\n\nPlease note the following:\n\n  - the proposed mechanism is as minimalist as possible.  It is a trigger\n    mechanism,  not a negotiating mechanism.  It specifies a way in which\n    either the client or the server can require that a connection be \n    secured.\n\n  - the proposed mechanism can be applied to any existing protocol which:\n\n      1. is command oriented\n      2. is client driven (the client sends all the commands)\n      3. has server responses to these client commands.  The protocols\n         envisaged,  like SMTP, NNTP,  and POP-3,  all use server responses\n         to indicate the success or failure of client commands\n      4. has a clearly defined standard response to unimplemented or \n         unknown commands from the client\n      5. does not require that the client know what every response means,\n         but does allow the client to \"get a feel\" for the success or \n         failure component of the response.\n\n   - the proposal was not written by a cryptographic specialist.  Flame\n     gently ;-)\n\nThe allocation of separate ports to secured and non-secured protocol\nservers allows the following:\n\n   A. Server operators can require all connections to be secured by\n      enabling only the secured port.\n\n   B. Clients can require a secure connection by connecting only to the\n      known secure port.  Failure to negotiate security results in the\n      termination of the connection.  Note that the user instructs the\n      client to initiate security by specifying the secured protocol\n      name (e.g. https rather than http).  It is accepted that the client\n      would not attempt an HTTP connection to the same URL should https\n      negotiation fail.  However,  this is an implementation, common sense\n      thing,  not a result of the port separation,  as a malicious or\n      intellectually challenged vendor could easily create a client to\n      \"roll back\" from https to http.\n\n   C. Old server and client software will not be broken by the specification\n      of a secured protocol.  Old servers listen on unsecured ports and\n      should never receive a secure connection.  Old clients will simply\n      ignore requests to connect to services \"https\" that they do not \n      implement.\n\nThe proposed mechanism allows for all this,  too.\n\nSPECIFICATION\n\nThe generic mechanism proposed is as follows:\n\nOne new client command,  and one or two new server responses are to be defined \nfor each protocol to be secured.  The actual command and response must fit \nwith the command-response model that the original protocol specification\ndefines.  Specific recommendations for well-known protocols follow.\n\n  NEW CLIENT COMMAND\n  The new client command is a trigger.  For English-ish-command protocols\n  which us CR-LF as the command terminator,  the recommended command is \n  \"TLS\".  For other protocols (binary command oriented protocols for example)\n  the command sequence would be specified in an update to the original\n  protocol specification.\n\n  If the protocol specifies a generic \"all is well\" server response\n  (200 OK for example) then the client would expect that response from\n  a server that implemented this proposal.  If there is no \"all is well\"\n  server response then a server response needs to be defined which will\n  indicate \"TLS Negotiation Request Accepted\".  That response definition\n  would need to fit in with the paradigm of the underlying protocol.\n\n  NEW SERVER RESPONSE\n  Where a server has been configured ONLY to accept secured connections,\n  or where the server has been configured to require secured connections\n  after a certain point, a new server response is used to indicate the\n  server's desire to negotiate TLS.\n\n  The server should wait for the client to deliver it's first command,\n  or for the dialogue to meet the conditions under which the server is\n  programmed to require TLS,  and should deliver the new response as a\n  response to the client command.\n\n  The response should indicate,  at the least,  failure.  Clients that\n  not implement this proposal need only be able to tell that the response \n  indicates failure.\n\n  Clients that do implement this proposal would respond to the server \n  response with the TLS initiation byte sequence (client hello I think).\n  If the server receives anything other than the TLS initiation sequence\n  it should assume that the client does not implement this proposal and\n  terminate the connection.\n\nGENERIC PROTOCOL EXAMPLE\n\nHere are some sample protocol conversations.  We refer to the new client \ncommand as \"TLS\",  the standard server \"OK\" response as \"GENOK\",  the\ncustom server OK response as \"TLSOK\",  the TLS initiation byte sequence\nas CLIENTHELLO, and the server \"TLS required\" response as \"TLSREQ\".  \nThe end-of-command sequence is referred to as \"\\n\". It is usually CR-LF\nor some such. The server \"unknown or implemented\" response is referred\nto as \"QUE?\"\n\n\nExample 1:  Client requires secure connectivity (e.g. pop3s), but server\n            does not implement this proposal:\n   Client:  TLS\\n\n   Server:  QUE?\\n\n   => client terminates connection.\n\n\nExample 2:  Client requires secure connectivity and server does implement\n            this protocol.  Server has a generic \"OK\" response.\n   Client:  TLS\\n\n   Server:  GENOK \n   Client:  CLIENTHELLO\n   => normal TLS handshaking commences.\n\n\nExample 3:  Server requires secure connectivity for certain transactions.\n            Client does not know this proposal.\n   Client:  command 1\n   Server:  GENOK\n   Client:  command 2,  which makes the server realise it wants TLS\n   Server:  TLSREQ\n   Client:  tries to resend command 2,  or other command\n   Server:  terminates connection.\n\n\nExample 4:  Server requires secure connectivity for certain transactions,\n            and the client does know this proposal.\n\n   Client:  command 1\n   Server:  GENOK\n   Client:  command 2,  entering servers required secure domain\n   Server:  TLSREQ\n   Client:  CLIENTHELLO\n     =>     handshaking as per normal TLS\n   Client:  command 2 again over a secure connection\n     =>     dialogue continues over TLS.\n\n\nEXAMPLE PROTOCOL EXTENSION:  NNTP\n\nHere is an example of the application of this protocol to NNTP.\n\n  1. The client trigger will be \"TLS\\n\" where \\n is the NNTP standard\n     end-of-command CR-LF sequence.\n\n  2. The server generic OK response is \"200 xxx\\n\" where XXX is (I think)\n     implementation specific.  Usually \"200 OK\\n\"\n\n  3. The server \"TLS Required\" response is \"401 xxx\\n\" where \"xxx\" is\n     implementation-specific,  probably something like \"please initiate TLS.\"\n\n  4. No \"TLSOK\" is required because a \"GENOK\" is already present\"\n\nThe TLSREQ response of 401 was chosen because RFC977 (NNTP) specifies that\n4XX responses imply that \"the command was correct but could not be performed\nfor some reason\".  X0X responses imply that the problem had to do with\n\"the connection, setup or miscellaneous\".  401 was chosen because it does not\nappear to be designated in that standard.  If 401 is already in use by\nmany NNTP server implementations another 40X response could be specified.\n\n\nNOTES\n\n1. Rollback attacks\n-------------------\nJust like we do not expect a client to attempt http when https fails,\nwe would expect a client to terminate the connection if the TLS command\nfailed and a secure service was requested by the user.\n\n2. Denial of Service\n--------------------\nA third party with the ability to interfere with bits on the wire could\nsend a \"what?\" back,  implying that the server does not talk this protocol.\nThis is no different to a third party interfering with the initial client\nhello on a pre-designated port.\n\n3. Versions and parameters\n--------------------------\nAll parameterisation and versioning is handled by the TLS handshaking.\nThis protocol just lets the client or the server trigger TLS handshaking,\nand figure out if the other side has a clue what it's talking about.\n\n\n\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: NULL_ ciphersuite meets ftp",
            "content": "> >> Speaking as a potential implementor, the approach in the ftp-ssl draft\n> >> gets my vote on time to market and on how readily it can be implemented\n> >> correctly and interoperably.\n> \n> ftpsec-09 current has four organizations (that I know of, there are\n> probably mode) implementing using kerberos or gssapi.  Three of these\n> implementations are independent.  With a few exceptions which recent\n> version of the draft address, they interoperate.\n\nHowever, that proposal doesn't address TLS, and the TLS-enabled\nproposal is far simpler.  I see your point re Kerberized FTP;\nI expect you see mine re SSL-ized FTP, which can also address\nKerberization through the proposed Kerberos flavors of TLS.\n\nIt does make sense to me to have a single FTPS protocol, but I do\nfeel that it's strikingly easier to do that by layering over SSL/TLS\nthan by requiring the complexities of the cat-ftpsec approach.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "IP Ports vs. Negotiatio",
            "content": "On the subject of port numbers vs. negotiation I have the following\nquestions:\n\nDoesn't SSL/TLS over HTTP (aka HTTPS) set a precedent by using port 443\ninstead of 80? Shouldn't this issue be resolved by now? \n\nPaul Foster\n\n\n\n"
        },
        {
            "subject": "Re: IP Ports vs. Negotiatio",
            "content": "> Doesn't SSL/TLS over HTTP (aka HTTPS) set a precedent by using port 443\n> instead of 80? Shouldn't this issue be resolved by now? \n\nYes it does,  but it's not so bad.\n\n  1. HTTP *has* to be as lightweight as possible.  If you used a trigger\n     like I just described you'd add another round trip at least.\n\n  2. The core part of the HTTP request comes on the first command from the\n     client to the server (the \"GET\" or \"POST\" or \"PUT\" etc.) so there's\n     not that much room to squeeze a trigger in.\n\nFor a critical,  fast,  lightweight protocol like HTTP even the purists\ncan probably make an exception ;-)\n\n--\nMark Shuttleworth\nThawte Consulting\n\n\n\n"
        },
        {
            "subject": "Re: NULL_ ciphersuite meets ftp",
            "content": "David.Brownell@Eng.Sun.COM (David Brownell - JavaSoft) writes:\n\n>> It does make sense to me to have a single FTPS protocol, but I do\n>> feel that it's strikingly easier to do that by layering over SSL/TLS\n>> than by requiring the complexities of the cat-ftpsec approach.\n\nI agree that ftp security protocol is better.  Are you going to tell\nthe existing shipping vendors to stop?  The TLS approach isn't all\nthat much simpler than the cat-ftpsec approach.  The devil, as usual,\nis in the details, and both protocols have plenty of those.  If it was\nthat hard, it wouldn't have been done three times already.\n\nMarc\n\n\n\n"
        },
        {
            "subject": "Re: Simple TLS/SSL negotiation proposa",
            "content": "Mark Shuttleworth <marks@thawte.com> writes:\n\n\n>> I promised this today ;-) \n>> \n>>  <---- BEGIN SIMPLE TLS TRIGGER PROPOSAL ---->\n\nIsn't this basically the same idea as SASL?  (ducking :-)\n\nMarc\n\n\n\n"
        },
        {
            "subject": "Re: IP Ports vs. Negotiatio",
            "content": "> > Doesn't SSL/TLS over HTTP (aka HTTPS) set a precedent by using\n> > port 443instead of 80? Shouldn't this issue be resolved by\n> > now?\n>\n\nConsidering SSL/TLS is being proposed for protocols other\nthan HTTP, no. Several existing protocols perform security\nnegotiation over the same port and predate SSL/TLS. There are\nproposals that predate the SSL/TLS proposal and have their own\nmomentum, such as draft-myers-auth-sasl-07.txt, last\nrevised December 1996.\n\n\n> Yes it does,  but it's not so bad.\n>\n>   1. HTTP *has* to be as lightweight as possible.  If you used a trigger\n>      like I just described you'd add another round trip at least.\n>\n\nFinally. A reasonable technical argument to support port\nmirrors, but only for protocols such as http. :)\n\n\n>   2. The core part of the HTTP request comes on the first command from the\n>      client to the server (the \"GET\" or \"POST\" or \"PUT\" etc.) so there's\n>      not that much room to squeeze a trigger in.\n>\n> For a critical, fast, lightweight protocol like HTTP even the\n> purists can probably make an exception ;-)\n>\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Re: IP Ports vs. Negotiatio",
            "content": "> \n> \n> > Doesn't SSL/TLS over HTTP (aka HTTPS) set a precedent by using port 443\n> > instead of 80? Shouldn't this issue be resolved by now? \n> \n> Yes it does,  but it's not so bad.\n> \n>   1. HTTP *has* to be as lightweight as possible.  If you used a trigger\n>      like I just described you'd add another round trip at least.\n> \n>   2. The core part of the HTTP request comes on the first command from the\n>      client to the server (the \"GET\" or \"POST\" or \"PUT\" etc.) so there's\n>      not that much room to squeeze a trigger in.\n\nSure there is, you just send a modified request rather than \nsending the same request to a modified port. However this means the http\nspec people who write the http standards, and all the browser writers who\nmake their own up have to be brought into the equation to change the \nworld \"just because\".  It'll be a bit cold underfoot when that happens \n\n> \n> For a critical,  fast,  lightweight protocol like HTTP even the purists\n> can probably make an exception ;-)\n> \n\nWell, that and unlike telnet, it usually isn't supposed to be\nused to allow high level access to your system :-) Notwithstanding\nthat It's already here and therefore would be damn near impossible to\nchange. That fact doesn't mean you need to do this for other protocols\n(like telnet, ftp, etc) where you can easily do it with negotiation,\nParticularly considering there are already implementations that will\ndo this for you.\n\n-Bob\n\n\n\n"
        },
        {
            "subject": "drop me from the lis",
            "content": "UNLIST ietf-tls ehpark@khgw.info.samsung.co.kr\n--------------------------------------------------------------------------------\nPark EunhongMultimedia R&D Lab,\nE-mail:ehpark@khgw.info.samsung.co.krSamsung Electronics Co, Ltd.\nTel) +82-331-200-3763        416, Meatan-3Dong, Paldal-Gu, Suwon City\nFax) +82-331-200-3716Kyungki-Do, Korea 442-742\n\nEverything should be made as simple as possible, but not simpler.\n            -- Albert Einstein\n--------------------------------------------------------------------------------\n \n                                              \n\n\n\n"
        },
        {
            "subject": "Re: Handling NULL key exchange for NULL_ ciphersuit",
            "content": "I'm not necessarily arguing against making NWNN illegal. But before we nail\nthe coffin closed. Just want to point out that negotiating to NWNN is safe\nif NWNN is the only ciphersuite in the list! Ciphersuite rollback is not a\nthread (as far as I can tell) in this circumstance. The upside is it would\nbe possible for an application to use NWNN over a port that was known to\nspeak TLS. Granted negotiating to NWNN might limit the range of objects\naccessible to the caller but that is an access policy decision. TLS does\nnot specify an access model (policy) beyond setting up a channel.\n\nGiven that the issues related to port assignments are far from solved.\nWouldn't it be wise to allow the most flexibility in the protocol without\ncompromising security? I think NWNN all by itself should be considered. The\nspec could be explicit about causing fatal alerts if NWNN were included\nwith other ciphersuites. \n\nFurthermore, a null session already in progress could negotiate up to a\nmore secure channel without an adverse impact on the security of the new\nsession. This seems like a great way for applications to implement stronger\nsecurity options within their protocol without breaking the connection?\n\nBest Regards,\nNed Smith\nnsmith@ibeam.intel.com\n\nAt 02:13 AM 2/9/97 -0500, Win Treese wrote:\n>\n>To close out this issue, I propose that the TLS spec forbid\n>negotiating to NULL_WITH_NULL_NULL. I understand\n>the argument for testing, but I suspect the risks of this in\n>practical deployment make it dangerous.\n>\n>Win Treese\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "drop me from the lis",
            "content": "UNLIST ietf-tls Mark.Watterson@litronic.com\n\n\n\n"
        },
        {
            "subject": "Drop me from the lis",
            "content": "UNLIST ietf-tls@w3.org  ddana@drew.edu\n\n\n\n"
        },
        {
            "subject": "Re: NEW DRAFT: Regularizing Port Numbers for SSL",
            "content": "> Date: Mon, 10 Feb 1997 09:18:09 -0800\n> From: David.Brownell@Eng.Sun.COM (David Brownell - JavaSoft)\n>\n> > I believe it is incorrect to claim that rough consensus has been\n> > achieved on the mailing lists.  If this goes forward, I believe it would\n> > be more accurate to state that no consensus was achieved, but that the\n> > request is being made anyway in the interest of expediency.\n>\n> On the other hand ... given the lack of comparably complete\n> alternative proposals, I believe it's more accurate to say\n> that there's been a LOT of inconclusive grousing.  (Much more\n> than I like to find in my mailbox.)\n>\n> We _know_ that using assigned ports works.  Alternatively,\n> we've seen the FTP proposal, and one's upcoming for Telnet.\n> That's the extent of the new proposals.  The alternatives to\n> assigning ports are incomplete, and don't address the needs of\n> folk trying to roll out secured applications \"soon\".\n>\n> Seriously:  those of you who don't like the idea of assigning\n> ports should really be making complete proposals (deployable\n> \"soon\") rather than just asking other folk to design to suit\n> your taste.\n>\n\nAsking questions, raising issues, expressing decent, and\npursing discussion does not *require* a formal response and\ncounter proposal. Those of us who have attended the many IPsec\nPhotorus, SKIP, and ISAKMP/Oakley debates can attest that\nformality is not always the path of expediency.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Drop me from the lis",
            "content": "UNLIST ietf-tls adtllc@alaska.net\n\n\n\n"
        },
        {
            "subject": "Mirror ports &ndash;&ndash; an abstract counter proposa",
            "content": "How about this as an abstract counter proposal to some of the\nmirror ports.\n\nTake the concepts of inetd and SOCKS and mix them together.\nReserve a single port requiring TLS. When a client connects to\nthe port the inetd/SOCKS/TLS daemon tests the connection\nagainst a policy database. If policy permits, fork and exec.\n\nNot only have added TLS to telnet, POP, and others not\nmentioned, such as rcp and rlogin, but we now have a general\npurpose protocol.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "Re: Mirror ports &ndash;&ndash; an abstract counter proposa",
            "content": "Actually, that was quite stupid. Never mind.\n\n\n-dpg\n\n\n\n"
        },
        {
            "subject": "dro",
            "content": "please drop me from this listserve.  Thank you.\n\n\n\n"
        },
        {
            "subject": "UNLIS",
            "content": "UNLIST ietf-tls ehpark@khgw.info.samsung.co.kr\n\n\n\n"
        },
        {
            "subject": "UNLIS",
            "content": "UNLIST ietf-tls ggarci1@ix.netcom.com\n\n\n\n"
        },
        {
            "subject": "Re: Drop me from the lis",
            "content": "Gadi Bareli\n02/11/97 10:40 AM\nTo:       ietf-tls @ w3.org @ SMTP\ncc:\nFrom:     Gadi Bareli/VocalTec @ VOCALTEC\nDate:     02/11/97 10:40:50 AM\nSubject:  Re: Drop me from the list\nUNLIST ietf-tls adtllc@alaska.net\n\n\n\n"
        },
        {
            "subject": "UNLIS",
            "content": "UNLIST ietf-tls mhollingswo@sgit.iaea.or.at\n\n\n\n"
        },
        {
            "subject": "Re: NULL_ ciphersuite meets ftp",
            "content": "*** Resending note of 10/02/97 19:35\n\n>>   I believe that the proposal to remove NWNN and the proposal\n>> to define 990 as ftps are mutually exclusive.\n\n> I'd think not.  TLS_NULL_WITH_NULL_NULL is an unprotected connection.\n> Rather than using TLS with that cipher suite, just don't use TLS.\n> No loss of functionality whatsoever.\n\nThe loss is the ability of the Client/Server to exchange insensitive\ndata/pre-protected data without having a data security negotiation\nconversation on the control connection (which the 'define an ftps port'\napproach precludes.)\n\n>>   The much preferred route is to allow the control connection to\n>> negotiate the protection level of the data connection.  (see the PROT\n>> command in the CAT draft-ietf-cat-ftpsec-09.txt)\n\n>This proposal is _far_ more complicated than the FTP approach described\n>in draft-murray-auth-ftp-ssl-00.txt ... and it doesn't even talk about\n>how to make this work with TLS.\n\nAgreed - but this is why it must be a 2 prong attack.\na) - state that the CAT W/G is the way to neogotaite FTP/TLS\nb) - discuss exactly what the expected behaviours of the Client/Server\n    need to be for TLS.  (when negotiating security). e.g. PROT C\n    means no TLS at all (if NWNN is removed this is the only way of\n    having a 'clear' connection); PROT P means negotiate TLS with\n    whatever Ciphersuites are configured; PROT S and PROT E are\n    replied to with a 536.  (This is just a suggestion - please don't\n    flame the specifics here/yet !!!)\n\n>Other than the PROT command (which could be added to the ftp-ssl draft),\n>the primary technical advantage that I notice in cat-ftpsec is that it\n>explicitly addresses Kerberos.  Wouldn't it be a lot better to follow\n>draft-ietf-tls-kerb-cipher-suites-00.txt to Kerberize SSL, and then\n>follow the ftp-ssl draft's simpler approach for the rest?\n\nMaybe - but then you lose the availability of an implementable proposal\nthat can be done now.\n\n\n>>    I don't see how this can be accused of holding anything up, as the\n>> draft (cat-ftpsec) is already written and awaiting eager developers.\n\n> Similarly, draft-murray-auth-ftp-ssl-00.txt is already written etc.\n\nThis document needs (pretty much) completely re-writing since the\nre-appearance of the CAT doc;  I was just in the process of updating\nit and circulating it to the co-authors when all this blew up.  What I\nam really looking for is a statement that this is worth pushing on with\nand we won't get shot in the foot by people implementing ftps quickly\nwith interoperability problems that will get out of hand.\n\n   Please note - the draft-murray-auth-ftp-ssl-00.txt does allow for\n\n\n\n\n\n\na separate port approach (allowing the data connection security to\nbe done at the TLS layer rather than on the control connection).  With\nthe removal of NULL_WITH_NULL_NULL, I believe that will need to be\nrevised, as it will not be acceptable to the FTP community.  (The only\nway I can think of getting round it is to say that a connection\nreceived on the TLS port does an implicit AUTH TLS, PBSZ 0, PROT P\nin the server, thus allowing for a decent default and a future\nnegotation ability).  We also need to talk to the CAT group to discuss\nthe PBSZ command to see if we can specify a 'streaming' secure connection\n(like TLS) with a value (say 0), or the ftp/tls draft will just say\nthat PBSZ, while required, is ignored (yuck).\n\nThanks,\nPaul.\n\n\n\n"
        },
        {
            "subject": "Re: NULL_ ciphersuite meets ftp",
            "content": "*** Resending note of 10/02/97 22:17\n\n>I agree that ftp security protocol is better.  Are you going to tell\n>the existing shipping vendors to stop?\n\nNo - they can do what they like, but if they want an open standard that\nwill interoperate with other vendors then they need to re-think what\nthey are doing.\n\nCheers,\nPaul\n\n\n\n"
        },
        {
            "subject": "unlis",
            "content": "UNLIST ietf-tls sivas@usa.net\n\n\n\n"
        },
        {
            "subject": "UNLIS",
            "content": "UNLIST ietf-tls mhollingswo@sgit.iaea.or.at\n\n\n\n"
        },
        {
            "subject": "UNLIS",
            "content": "UNLIST ietf-tls ncrago@oldmutual.com\n\n\n\n"
        },
        {
            "subject": "UNLIS",
            "content": "UNLIST ietf-tls  judi.moffat@prior.ca\n\n\n\n"
        },
        {
            "subject": "UNLIS",
            "content": "UNLIST ietf-tls army@izzy.net\n\n\n----------------------------------------------------------------------\n   Mott Community College Information Systems - Applications Analyst\n                   Michael A. Bobbitt / (810)232-8154\n                            Flint, Michigan\n----------------------------------------------------------------------\n#include <std_dsclmr.h>\n\n\n\n"
        },
        {
            "subject": "Re: UNLIS",
            "content": ">> UNLIST ietf-tls army@izzy.net\n>> \n>> \n>> ----------------------------------------------------------------------\n>>    Mott Community College Information Systems - Applications Analyst\n>>                    Michael A. Bobbitt / (810)232-8154\n>>                             Flint, Michigan\n>> ----------------------------------------------------------------------\n>> #include <std_dsclmr.h>\n\n<flame>\nOk.  All lemmings please stop this RIGHT NOW.  It doesn't work.  I've\ngotten about 15 \"UNLIST\" messages.  I don't want any more.  This is\nthe wrong command, issued to the wrong address.  When you subscribed\nto this list, you received a welcome message which explains how to get\noff this list.  I've appended a copy.  If you want off, follow the\ninstructions.\n</flame>\n\nMarc\n\n******* Note from the listmaster: (listmaster@w3.org) *******\n\nYou have been added to the subscriber list of:\n\n    ietf-tls@w3.org\n\nwith the following mail address:\n\n    marc@cygnus.com\n\nThis mailing list is now being governed by SmartLists.\nAll administrative requests should be sent to the request address:\n\n    ietf-tls-request@w3.org\n\nCommands to the request address are processed automatically.\nThe desired command should be sent in the Subject of a mail message\nto 'ietf-tls-request@w3.org'.\n\n******* Administrative Requests *******\n\nThe -request mail address should be used for all list administrative\nrequests.  It accepts the following commands (in the Subject of an\ne-mail message):\n\n    subscribe         -- Subscribe to the list.  If you want to subscribe\n                         under a different address, use a Reply-To: address\n                         header in the message.\n\n    unsubscribe       -- Unsubscribe from the list.\n\n    help              -- Get information about the mailing list.\n\n    archive help      -- Get information about the list archive(s).\n\nIn the event of an address change, it would probably be wisest to first\nsend an unsubscribe for the old address (this can be done from the new\naddress), and then a new subscribe from the new address (the order is\nimportant).\n\nMost (un)subscription requests are processed automatically without human\nintervention.  Do not send multiple (un)subscription or info requests in\none mail.  Only one will be processed per mail.\n\nNOTE: The -request server usually does quite a good job in discriminating\n      between (un)subscribe requests and messages intended for the\n      maintainer.  If you'd like to make sure a human reads your message,\n      make it look like a reply (i.e. the first word in the Subject: field\n      should be \"Re:\", without the quotes of course); the -request server\n      does not react to replies.\n\n\n\"Mike Bobbitt\" <army@izzy.net> writes:\n\n>> \n>> \n\n\n\n"
        },
        {
            "subject": "Antw: Re: UNLIS",
            "content": ">I don't want any more.  \n<offtopic>\n\nAgreed. I think somebody should improve the listserv-programs\nto kick unsubscribe messages - they should not be hard to identify\nand they occur on any list weekly at least.\n\n</offtopic>\n\n\nDr. Peter Lipp, IAIK, University of Technology, Graz\nInstitute for Applied Information Processing and Communications\nKlosterwiesgasse 32/I, A-8010 Graz, +43 316 873 5513\n________________________________________________________________________\nWas n?tzt die beste Erziehung, die Kinder machen uns ja doch alles nach.\n\n\n\n"
        },
        {
            "subject": "Anyone want to take over the mailing list",
            "content": "From your friendly LIst Administrator, Rohit Khare:\n\nWell, I for one would be thrilled if someone else in the TLS community\nwould like to take over the list. I initially volunteered the W3C's\nresources when I was the Web security contact point. As this list has grown\nand as W3C's web security interest has gravitated towards digital\nsignatures, our resources for maintaining this list have dwindled. In fact,\nsince I am no longer the security contact for the organization, I have only\ndone minor emergency cleaning of the list (as with the flood of UNLIST\nmessages this weekend). \n\nIf there is someone more enthusiastic and better equipped, we can consider\na handoff arrangement. Otherwise, it will be a few more weeks before W3C\ncompletes its 'mailing list cleanup' project to find more resources for\nthis.\n\nRK\n\nPS. No, I don't know any easy way to make smartlist filter these messages\nbetter.\n\n---\nRohit Khare -- World Wide Web Consortium -- Technical Staff\nw: 617/253-5884  --   f: 617/258-5999   --  h: 617/491-5030\nNE43-344,  MIT LCS,  545 Tech Square,  Cambridge,  MA 02139\n\n\n----------\nFrom: plipp <plipp@iaik.tu-graz.ac.at>\nTo: Marc Horowitz <marc@cygnus.com>; Mike Bobbitt <army@izzy.net>\nCc: ietf-tls@w3.org\nSubject: Antw: Re: UNLIST\nDate: Tuesday, February 11, 1997 11:26 AM\n\n>I don't want any more.\n<offtopic>\n\nAgreed. I think somebody should improve the listserv-programs\nto kick unsubscribe messages - they should not be hard to identify\nand they occur on any list weekly at least.\n\n</offtopic>\n\n\nDr. Peter Lipp, IAIK, University of Technology, Graz\nInstitute for Applied Information Processing and Communications\nKlosterwiesgasse 32/I, A-8010 Graz, +43 316 873 5513\n________________________________________________________________________\nWas n?tzt die beste Erziehung, die Kinder machen uns ja doch alles nach.\n----------\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "David P. Kemp wrote:\n> \n> or D) document the port assignments using some mechanism other than\n> the IANA.\n> \n> I don't have any problem with people solving problems today by\n> agreeing on separate port assignments.  But I firmly believe that\n> these ad-hoc quick fixes should be \"etched in sand\" via an Internet\n> Draft or a BCP, and not \"etched in stone\" via the IANA.\n> \n> I agree completely with Mark - the IANA should use it's good? (DOOM\n> indeed!) judgement and reject this request.  If approved, it can never\n> be undone.\n\nFirst of all, I'd like to be clear that (I hope!) we're talking about\nthe new ports Chris is proposing allocating, not the old ports that\nare already allocated for SSL/TLS.\n\nNow, what makes you think that if someone like Microsoft or Netscape\nships a product that uses particular port assignments that it is any\nless \"set in stone\" than if the IANA registers it?  Once a product like\nthat is deployed (especially if it has multi-vendor support), it's\nvery hard to make people change what port they're using.\n\nPersonally, I'd much rather have the IANA coordinate these port numbers\nthan have individual software companies going off on their own.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TWO WEEK LAST CALL: Regularizing Port Numbers for SSL",
            "content": "On Tue, 11 Feb 1997 09:12:47 -0800, Tom Weinstein <tomw@netscape.com> wrote:\n> Now, what makes you think that if someone like Microsoft or Netscape\n> ships a product that uses particular port assignments that it is any\n> less \"set in stone\" than if the IANA registers it?  Once a product like\n> that is deployed (especially if it has multi-vendor support), it's\n> very hard to make people change what port they're using.\n> \n> Personally, I'd much rather have the IANA coordinate these port numbers\n> than have individual software companies going off on their own.\n\nAgreed.\n\nNonetheless, if we do find a clean universal solution, we can at least make suggestions to roll it all up into one mechanism, and urge vendors by means of a standards publication to roll their products into this mechanism as well.\n\nGranted, many products will end up supplying both.  However, I believe that all brains in said organizations aren't completely disabled because of their business interests (in fact, they shouldn't be for their success) and someone will adopt a sane spec, if we have one.\n\nRegards,\nChris\n\n\n\n"
        },
        {
            "subject": "Re: Anyone want to take over the mailing list",
            "content": "At 8:30 AM -0800 2/11/97, Rohit Khare wrote:\n>Well, I for one would be thrilled if someone else in the TLS community\n>would like to take over the list. I initially volunteered the W3C's\n>resources when I was the Web security contact point. As this list has grown\n>and as W3C's web security interest has gravitated towards digital\n>signatures, our resources for maintaining this list have dwindled. In fact,\n>since I am no longer the security contact for the organization, I have only\n>done minor emergency cleaning of the list (as with the flood of UNLIST\n>messages this weekend).\n>\n>If there is someone more enthusiastic and better equipped, we can consider\n>a handoff arrangement. Otherwise, it will be a few more weeks before W3C\n>completes its 'mailing list cleanup' project to find more resources for\n>this.\n\nWe have the resources at Consensus to manage additional lists, and would be\nwilling to either take over list administration of this list or to move it\nto a consensus server.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "How to get off of IETFTL",
            "content": "(PLEASE don't send mail to any list to unsubscribe, or send mail to me, I\nam not the list administrator. I am only sending this to help.)\n\n-----\n>The discussion list for IETF-TLS is at IETF-TLS@W3.ORG. You subscribe and\n>unsubscribe by sending to IETF-TLS-REQUEST@W3.ORG with subscribe or\n>unsubscribe in the SUBJECT of the message.\n\n------\n>This mailing list is now being governed by SmartLists.\n>All administrative requests should be sent to the request address:\n>\n>    ietf-tls-request@w3.org\n>\n>Commands to the request address are processed automatically.\n>The desired command should be sent in the Subject of a mail message\n>to 'ietf-tls-request@w3.org'.\n>\n>******* Administrative Requests *******\n>\n>The -request mail address should be used for all list administrative\n>requests.  It accepts the following commands (in the Subject of an\n>e-mail message):\n>\n>    subscribe         -- Subscribe to the list.  If you want to subscribe\n>                         under a different address, use a Reply-To: address\n>                         header in the message.\n>\n>    unsubscribe       -- Unsubscribe from the list.\n>\n>    help              -- Get information about the mailing list.\n>\n>    archive help      -- Get information about the list archive(s).\n>\n>In the event of an address change, it would probably be wisest to first\n>send an unsubscribe for the old address (this can be done from the new\n>address), and then a new subscribe from the new address (the order is\n>important).\n>\n>Most (un)subscription requests are processed automatically without human\n>intervention.  Do not send multiple (un)subscription or info requests in\n>one mail.  Only one will be processed per mail.\n>\n>NOTE: The -request server usually does quite a good job in discriminating\n>      between (un)subscribe requests and messages intended for the\n>      maintainer.  If you'd like to make sure a human reads your message,\n>      make it look like a reply (i.e. the first word in the Subject: field\n>      should be \"Re:\", without the quotes of course); the -request server\n>      does not react to replies.\n\n-----\n>    The most common problem is that you are attempting to unsubscribe\n>    using an email address different than that with which you subscribed\n>    Check with your mail administrator and make sure that you don't have\n>    an alias or \".forward\" file sending mail to you from another\n>    address.\n>\n>    Another common problem is that the subdomain of your mailer has\n>    changed, for example, \"mail.consensus.com\" has been renamed\n>    \"server.consensus.com\".\n>\n>    In either case, sending mail with the \"From:\" line matching the\n>    account you subscribed with should unsubscribe you from the list.\n>\n>    Please don't send mail to the general list to unsubscribe;\n>    it will only frustrate you and the rest of the recipients.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: UNLIS",
            "content": "UNLIST ietf-tls ehpark@khgw.info.samsung.co.kr\n\n\n\n"
        },
        {
            "subject": "Re: dro",
            "content": "please drop me from this listserve.  Thank you.\n\n\n\n"
        },
        {
            "subject": "Proposal to extend TLS spec to allow nonX.509 certificate type",
            "content": "To the IETF TLS community,\n\nBelow is a proposal to allow non-X.509 certificates be passed during TLS\nhandshaking\nin a fully backward compatible extension to the TLS spec. \n\nThank You,\nNed Smith\nnsmith@ibeam.intel.com\n----------------------------------------------------------------------------\n\nProposal to Extend TLS Specification to Include non-X.509 Certificate Types\n\n\nThe TLS specification unnecessarily restricts the format of certificates\nused for authentication to X.509v3. TLS is intended to provide public-key\nbased channel security infrastructure to the Internet community. We believe\nthat standardizing TLS on X.509v3 certificate types was not primarily\nintended as a judgment on the value of X.509v3, but rather, a decision\nbased on implementation and time to market pragmatism. However, this choice\nis not necessarily broadly applicable within the Internet community.\n\nFor this reason, we propose the TLS specification be enhanced to include a\nfully backwards compatible modification enabling the use of  alternative\ncertificate infrastructures  in the TLS protocol. The modifications add an\noptional ClientCertificateType identifier to the end of the Certificate\nmessage. This enables the recipient to choose an appropriate certificate\nparsing utility for certificates in certificate_list. The\nClientCertificateType enumeration is extended to include identifiers for\nSDSI, SPKI and PGP public-key certificate structures.  \n\nSpecifically the modifications to the TLS specification are as follows:\n\n6.4.2 Server certificate\n\nStructure of this message:\n\n       opaque ASN.1Cert<1..2^24-1>;\n       struct {\n           ASN.1Cert certificate_list<1..2^24-1>;\n           ClientCertificateType cert_type;*\n       } Certificate;\n\n* Indicates optional field. \n\n   certificate_list\n       If cert_type is non-existent then this is a sequence (chain) of \n       X.509.v3 certificates, ordered\n       with the sender's certificate first followed by any certificate\n       authority certificates proceeding sequentially upward, with a\n       self-signed certificate for the root CA coming last in the\n       list.\n\n  cert_type\n       If the identifier is not present then the certificate type \n       is interpreted as X.509v3. \n       If present the  cert_type field is used to interpret the \n       opaque contents of certificate_list.\n\n       If cert_type is PGP then certificate_list contains a PGP \n       certificates where the sender?s certificate is first followed \n       by a sequence (set) of signers of the sender?s certificate.\n\n       If cert_type is SPKI then the certificate_list contains an SPKI \n       binary certificate. (It is assumed there will only be a single \n       SPKI certificate since the certificate structure embeds the location\n       of issuers within the certificate).\n\n       If cert_type is SDSIv1 then the certificate_list contains an \n       S-Expression representing the sender?s \"Cert:\" or \"Delegation-Cert\"\nobject. \n       (As with SPKI, SDSI certificate objects contain references to issuing \n       principals. Therefore, it is assumed only a single certificate will\nbe sent).\n\n\n6.4.4 Certificate request\n\n   Structure of this message:\n\n       enum {\n           rsa_sign(1), dss_sign(2), rsa_fixed_dh(3), dss_fixed_dh(4),\n           rsa_ephemeral_dh(5), dss_ephemeral_dh(6), pgp(21), spki(22),\nsdsi_v1(23)\n           (255)\n       } ClientCertificateType;\n\n     opaque DistinguishedName<1..2^16-1>;\n\n       struct {\n           ClientCertificateType certificate_types<1..2^8-1>;\n           DistinguishedName certificate_authorities<3..2^16-1>;\n       } CertificateRequest;\n\n\n   certificate_types\n         This field is a list of the types of certificates requested,\n         sorted in order of the server's preference.\n\n  certificate_authorities\n         A list of the distinguished names of acceptable certificate\n         authorities for certificate type values between (1) and (6) which \n         correspond to X.509v3 certificate authority names.\n\n         If certificate_types includes pgp, spki or sdsi_v1 then fields in \n         the Distinguished Name structure are overloaded in the following\nmanner:\n\n  PGP - A Distinguished Name containing:\n               [Org=PGP Certificate Authority, Org Unit=<a PGP key finger\nprint>,\n                Common Name=<name of a trusted PGP key signer>]\n\n  SPKI - A Distinguished Name containing:\n               [Org=SPKI Certificate Authority, \n                Org Unit=ISSUER-CERT:<URL of acceptable certificate issuer>]\n\n  SDSI - A Distinguished Name containing:\n               [Org=SDSIv1 Certificate Authority, \n                Org Unit=(Principal: (?)) or <any standard SDSI global root\nnames                (i.e. VeriSign!!, USPS!! Etc.)>]\n\nNote: The negotiated ciphersuite contains the key exchange policy\ninformation. It is not believed that certificate type identifiers need to\nbe overloaded with key exchange policy. For this reason the new certificate\ntypes do not contain instances for each key exchange method.\n----------------------------------------------------------------------------\n------\n\n\n\n"
        },
        {
            "subject": "agenda for tls meeting",
            "content": "Has there been a call for agenda items?\n\n\n               Rodney Thayer <rodney@sabletech.com>       +1 617 332 7292\n               Sable Technology Corp, 246 Walnut St., Newton MA 02160 USA\n               Fax: +1 617 332 7970           http://www.shore.net/~sable\n                           \"Developers of communications software\"\n\n\n\n"
        },
        {
            "subject": "TLS WG meeting in Memphi",
            "content": "I haven't received the time for the working group meeting\nin Memphis yet, but I would like to call for any agenda\nitems, proposals, or requests for presentation for the meeting\nnow. You can send them to the list or just to me, and I'll\ncirculate a draft agenda once or twice in advance of the\nmeeting.\n\nThe Memphis IETF meeting will be held from April 7-11,\n1997.  Details of the meeting may be found at\nhttp://www.ietf.org/meetings/Memphis.html\n\nThanks very much.\n\nWin Treese\ntreese@OpenMarket.com\n\n\n\n"
        },
        {
            "subject": "RE: TLS WG meeting in Memphi",
            "content": "What is the status of the TLS spec?  Is there a revised delivery date\nfor the document?\n\n>-----Original Message-----\n>From:Win Treese [SMTP:treese@OpenMarket.com]\n>Sent:Sunday, March 02, 1997 8:54 PM\n>To:ietf-tls@w3.org\n>Subject:TLS WG meeting in Memphis\n>\n>\n>I haven't received the time for the working group meeting\n>in Memphis yet, but I would like to call for any agenda\n>items, proposals, or requests for presentation for the meeting\n>now. You can send them to the list or just to me, and I'll\n>circulate a draft agenda once or twice in advance of the\n>meeting.\n>\n>The Memphis IETF meeting will be held from April 7-11,\n>1997.  Details of the meeting may be found at\n>http://www.ietf.org/meetings/Memphis.html\n>\n>Thanks very much.\n>\n>Win Treese\n>treese@OpenMarket.com\n>\n\n\n\n"
        },
        {
            "subject": "addition of Kerberos ciphersuites in TL",
            "content": "A draft for the addition of Kerberos ciphersuites was presented at the last\nTLS working group meeting (draft-ietf-tls-kerb-cipher-suites-00.txt\nreference implementation is available at ftp://nii.isi.edu/pub/ssl-krb).\nWe would like to place this draft on the agenda for the working group\nmeeting in Memphis, and move that it be added to the body of the TLS draft.\n\nTo date, authentication in TLS is limited only to public key solutions.  As\na result, TLS does not fully support organizations with heterogeneous\nsecurity deployments that include authentication systems based on symmetric\ncryptography.   \nKerberos, originally developed at MIT, is based on an open standard and is\nthe most widely deployed symmetric key authentication system.  The draft\npresented at the Dec. meeting of the IETF proposes a new option for\nnegotiating Kerberos authentication within the TLS framework.  This\nachieves mutual authentication and the establishment of a master secret\nusing Kerberos credentials.  The proposed changes are minimal and, in fact,\nno different from adding a new public key algorithm to the TLS framework.\n\nRegards,\nMatt Hur and Ari Medvinsky\n\n----------------------------------------------------------------\nMatt Hur                       CyberSafe\nmatt.hur@cybersafe.com         1605 NW Sammamish Road, Suite 310\n(206) 391-6000                 Issaquah, WA 98027-5378\n                               http://www.cybersafe.com\n\n\n\n"
        },
        {
            "subject": "Re: addition of Kerberos ciphersuites in TL",
            "content": "At 7:02 PM -0800 3/3/97, Matt Hur wrote:\n>We would like to place this draft on the agenda for the working group\n>meeting in Memphis, and move that it be added to the body of the TLS draft.\n\nI have no problems with having this to a TLS 1.1 task list, but I'm hoping\nthat you are not desiring for it to be a 1.0 work item, as we want to get\nthat out ;-)\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "The next draft of the TLS 1.0 protocol has been submitted to the\ninternet-drafts site.\n\nIf you can't wait, a copy is at\n<http://www.consensus.com/ietf-tls/tls-protocol-01.txt>.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "IETFTLS List Movin",
            "content": "The IETF-TLS list has been hosted by W3, who no longer can maintain the list.\n\nWe are moving the list to <mailto:ietf-tls@consensus.com>.\n\nInformation on the IETF-TLS working, and information on how to subscribe to\nthe new list is at <http://www.consensus.com/ietf-tls/>.\n\nWe will not be moving existing subscribers from the w3 list to the new\nlist, you must resubscribe. This list will probably be shut down in about\ntwo weeks.\n\n\nIETF-TLS Mailing List Information\n---------------------------------\n\nWWW Home Page:\n<http://www.consensus.com/ietf-tls/>\n\nIETF-TLS General Discussion:\n<mailto:ietf-tls@consensus.com>\n\n      To SUBSCRIBE to the IETF-TLS Discussion List:\n      <mailto: ietf-tls@consensus.com?subject=subscribe>\n      with the subject SUBSCRIBE.\n\n      To SUBSCRIBE to the IETF-TLS Digest List:\n      <mailto: ietf-tls@consensus.co?subject=subscribe%20digest>\n      with the subject SUBSCRIBE DIGEST.\n\n      To UNSUBSCRIBE either the IETF-TLS Discussion List or the Digest List:\n      <mailto: ietf-tls@consensus.com?subject=unsubscribe>\n      with the subject UNSUBSCRIBE.\n\n      IETF-TLS Discussion List Archive:\n      <http://www.imc.org/ietf-tls/mail-archive/>\n\nIETF-TLS Announcements List (moderated):\n<mailto: ietf-tls-announce@consensus.com>\n\n      To SUBSCRIBE to the IETF-TLS Announcements List:\n      <mailto: ietf-tls-announce@consensus.com?subject=subscribe>\n      with the subject SUBSCRIBE.\n\n      To UNSUBSCRIBE to the IETF-TLS Announcements List:\n      <mailto: ietf-tls-announce@consensus.com?subject=unsubscribe>\n      with the subject UNSUBSCRIBE.\n\n      IETF-TLS Announcements List Archive:\n      To Be Announced\n\nAny problems with subscribing or unsubscribing to these lists should be\naddressed to:\n      Consensus Development Listmaster <mailto: listmaster@consensus.com>.\n\n------------------------------------------------------------------------\n..Christopher Allen                  Consensus Development Corporation..\n..<ChristopherA@consensus.com>                 1563 Solano Avenue #355..\n..                                             Berkeley, CA 94707-2116..\n..Home of \"SSL Plus:                      o510/559-1500  f510/559-1505..\n..  SSL 3.0 Integration Suite(tm)\" <http://www.consensus.com/SSLPlus/>..\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "> From: Christopher Allen <ChristopherA@consensus.com>\n> \n> The next draft of the TLS 1.0 protocol has been submitted to the\n> internet-drafts site.\n> \n> If you can't wait, a copy is at\n> <http://www.consensus.com/ietf-tls/tls-protocol-01.txt>.\n\n\nChris,\n  I noticed that the draft still contains references to ciphersuites\nincluding the unpublished algorithms RC2 and RC4.  Of course an\nInternet-Draft is just that, a draft, and can contain anything.\nBut if we are to have a document that will allow us to move forward\ntowards a Proposed Standard RFC, this will have to be fixed in\nanother iteration of the draft, before we can go to Last Call.\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "At 08:55 AM 3/7/97 -0500, David P. Kemp wrote:\n>  I noticed that the draft still contains references to ciphersuites\n>including the unpublished algorithms RC2 and RC4.\n\nI believe RC2 is still a trade secret, but RC4 was leaked to the Cypherpunks\nlist in September, '94.  The algorithm is described in Chapter 17 of Bruce\nSchneier's \"Applied Cryptography\", 2ed.\n--\nTom Libert                    tel: 508.485.5235 x286\nGradient Technologies, Inc.   fax: 508.229.0338\n2 Mount Royal Avenue          http://www.gradient.com\nMarlborough, MA  01752\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "> \n> At 08:55 AM 3/7/97 -0500, David P. Kemp wrote:\n> >  I noticed that the draft still contains references to ciphersuites\n> >including the unpublished algorithms RC2 and RC4.\n> \n> I believe RC2 is still a trade secret, but RC4 was leaked to the Cypherpunks\n> list in September, '94.  The algorithm is described in Chapter 17 of Bruce\n> Schneier's \"Applied Cryptography\", 2ed.\n\n\nYes, of course it is.  And \"alleged RC4\" is also posted on Ron Rivest's\nweb page.   But I'm sure Phil Karlton had a copy of Schneier when he wrote\nthe statement \"There is no good reference to these [RC2, RC4] as they\nare unpublished works\" in the SSL specification.  This statement is still\nincluded in the current TLS draft -01.\n\nPerhaps you should check with RSADSI to see if they still regard RC4 as\nan \"unpublished work\", despite the fact that it leaked out some time ago.\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "Tom Libert writes:\n> \n> At 08:55 AM 3/7/97 -0500, David P. Kemp wrote:\n> >  I noticed that the draft still contains references to ciphersuites\n> >including the unpublished algorithms RC2 and RC4.\n> \n> I believe RC2 is still a trade secret, but RC4 was leaked to the Cypherpunks\n> list in September, '94.  The algorithm is described in Chapter 17 of Bruce\n> Schneier's \"Applied Cryptography\", 2ed.\n\n\nWhy don't we add some Blowfish CipherSuites?\nIt's a published (and public domain!) algorithim.\n\n\n-- \n             Eric Murray  ericm@lne.com  ericm@motorcycle.com\n  Network security and encryption consulting: www.lne.com/ericm/resume.html\nPGP keyid:E03F65E5 fingerprint:50 B0 A2 4C 7D 86 FC 03  92 E8 AC E6 7E 27 29 AF\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "> From: Eric Murray <ericm@lne.com>\n>\n> Why don't we add some Blowfish CipherSuites?\n> It's a published (and public domain!) algorithim.\n\n\nGood idea.  And Blowfish was mentioned the last time this came up,\nseveral months ago.\n\nThe point of removing RC2 and RC4 from the TLS base document is *not*\nto prevent their use with TLS, it is to restructure the IETF TLS\nstandard as a core document plus additional ciphersuite-specific\ndocuments.  This follows the IPSEC example of generic AH/ESP documents\nsupplemented by additional transform-specific documents.  I thought\nthe working group had reached consensus on a modular document structure,\nand am a bit disappointed that the present draft does not reflect that\nconsensus.\n\nThe TLS base document should specify mandatory-to-implement algorithms\nto promote interoperability.  Currently the DES/3DES ciphersuites\nfill that role, but Blowfish or another published and freely-available\nalgorithm might conceivably be suitable as the interoperable\nbaseline.\n\nTLS \"transform\" documents could be written to specify the use of many\nother ciphersuites, published or proprietary, including RC2, RC4,\nBlowfish, SAFER, Fortezza(R), etc.  This makes it easier to add\nfuture ciphersuites to TLS without having to re-do the base document\nevery time.\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "At 6:50 AM -0800 3/7/97, Tom Libert wrote:\n>I believe RC2 is still a trade secret, but RC4 was leaked to the Cypherpunks\n>list in September, '94.  The algorithm is described in Chapter 17 of Bruce\n>Schneier's \"Applied Cryptography\", 2ed.\n\nJust because it is published in a book (or on a mailing list) does not mean\nit is acceptable to use in a standards track RFC. I think the question is,\n\"which algorithms can we have in this draft and still move it towards\nstandards track?\n\nAlso, Please note Chris' statement that the TLS mailing list is moving from\n\"ietf-tls@w3.org\" to \"ietf-tls@consensus.com\".\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "Glad to see the draft available!!\n\n\n> Date: Fri, 7 Mar 1997 10:27:29 -0500\n> From: dpkemp@missi.ncsc.mil (David P. Kemp)\n> \n> Perhaps you should check with RSADSI to see if they still regard RC4 as\n> an \"unpublished work\", despite the fact that it leaked out some time ago.\n\nI believe the answer is \"yes\", so anyone (at least in the US) who\nwants to ship an \"RC4-compatible\" cipher should have lawyers ready.\n(The name \"RC4\" is probably trademarked, regardless of the secrecy\nof that algorithm.)\n\nNow, is this foolishness?  Trying to claim Trade Secret protection\nfor something that's clearly not a secret?  Yes.  But it's lawyers\nand judges which have to agree on that, not mere mortals.  I don't\nknow that the IETF wants to fund those lawyers.  If it does, that'd\nbe very good news.\n\n- Dave\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "I spoke to Jeff Schiller (area director for security), and\nwe think that the reference to Schneier is sufficient\nfor the TLS spec. Having the RC4 ciphersuite is important,\nI think, because of its widespread use in SSL today.\n\nWithout a similar description of RC2, it isn't appropriate\nto include the ciphersuite.\n\n- Win Treese\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "> At 6:50 AM -0800 3/7/97, Tom Libert wrote:\n> >I believe RC2 is still a trade secret, but RC4 was leaked to the Cypherpunks\n> >list in September, '94.  The algorithm is described in Chapter 17 of Bruce\n> >Schneier's \"Applied Cryptography\", 2ed.\n> \n> Just because it is published in a book (or on a mailing list) does not mean\n> it is acceptable to use in a standards track RFC. I think the question is,\n\nFYI ...\n\nRFC2026, especially section 7.1 and section 10 provides guidelines for how to\nincorporate external specifications into standards track documents. Section\n7.1.2 says if the owners of RC2 and RC4 aren't willing to make these \"widely\nand readibly available, the IESG may request that it be published as an\nInformational RFC\". Section 10 has language that says that patented\ntechnology can be incorporated, provided the owners will provide a\nlicense under general and nondiscriminatory terms.\n\nI'll leave to the IESG to determine if both RC2 and RC4 meet these tests.\n\n-mre\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "On Fri, 7 Mar 1997, Tom Libert wrote:\n> At 08:55 AM 3/7/97 -0500, David P. Kemp wrote:\n> >  I noticed that the draft still contains references to ciphersuites\n> >including the unpublished algorithms RC2 and RC4.\n> \n> I believe RC2 is still a trade secret, but RC4 was leaked to the Cypherpunks\n> list in September, '94.  The algorithm is described in Chapter 17 of Bruce\n> Schneier's \"Applied Cryptography\", 2ed.\n\nPeter Gutmann posted an article to sci.crypt on Feb 11 1996 describing\nRC2.  Eric Young implemented his RC2 library from that article.\n\nSee:\ncrypto/rc2/rrc2.doc\ndoc/rc2.doc\n\nfrom the SSLeay distribution.\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "At 09:17 AM 3/7/97 -0800, David Brownell -- JavaSoft wrote:\n>> Date: Fri, 7 Mar 1997 10:27:29 -0500\n>> From: dpkemp@missi.ncsc.mil (David P. Kemp)\n>> \n>> Perhaps you should check with RSADSI to see if they still regard RC4 as\n>> an \"unpublished work\", despite the fact that it leaked out some time ago.\n>\n>I believe the answer is \"yes\", so anyone (at least in the US) who\n>wants to ship an \"RC4-compatible\" cipher should have lawyers ready.\n>(The name \"RC4\" is probably trademarked, regardless of the secrecy\n>of that algorithm.)\n\nFrom Schneier, p. 398: \"The name is trademarked, so anyone who writes his\nown code has to call it something else....RSA Data Security, Inc. will almost\ncertainly sue anyone who uses unlicensed RC4 in a commercial product.\nThey probably won't win, but they will certainly make it cheaper for a company\nto license than fight.\"\n\nRC4 appears to be a strong cipher.  The TLS protocol should clearly\nnot mandate the use of proprietary ciphers, but neither should it\nprohibit their use.\n--\nTom Libert                    tel: 508.485.5235 x286\nGradient Technologies, Inc.   fax: 508.229.0338\n2 Mount Royal Avenue          http://www.gradient.com\nMarlborough, MA  01752\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "Tom and all,\n\nTom Libert wrote:\n> \n> At 09:17 AM 3/7/97 -0800, David Brownell -- JavaSoft wrote:\n> >> Date: Fri, 7 Mar 1997 10:27:29 -0500\n> >> From: dpkemp@missi.ncsc.mil (David P. Kemp)\n> >>\n> >> Perhaps you should check with RSADSI to see if they still regard RC4 as\n> >> an \"unpublished work\", despite the fact that it leaked out some time ago.\n> >\n> >I believe the answer is \"yes\", so anyone (at least in the US) who\n> >wants to ship an \"RC4-compatible\" cipher should have lawyers ready.\n> >(The name \"RC4\" is probably trademarked, regardless of the secrecy\n> >of that algorithm.)\n> \n> >From Schneier, p. 398: \"The name is trademarked, so anyone who writes his\n> own code has to call it something else....RSA Data Security, Inc. will almost\n> certainly sue anyone who uses unlicensed RC4 in a commercial product.\n> They probably won't win, but they will certainly make it cheaper for a company\n> to license than fight.\"\n> \n> RC4 appears to be a strong cipher.  The TLS protocol should clearly\n> not mandate the use of proprietary ciphers, but neither should it\n> prohibit their use.\n\n  I agree with this evaluation.  It should be included.\n> --\n> Tom Libert                    tel: 508.485.5235 x286\n> Gradient Technologies, Inc.   fax: 508.229.0338\n> 2 Mount Royal Avenue          http://www.gradient.com\n> Marlborough, MA  01752\n\n-- \nJeffrey A. Williams\nDIR. Internet Network Eng/SR. Java Development Eng.\nInformation Eng. Group. \nPhone :913-294-2375 (temporary)\nE-Mail jwkckid1@ix.netcom.com\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "Tom Libert wrote:\n> \n> At 08:55 AM 3/7/97 -0500, David P. Kemp wrote:\n>> I noticed that the draft still contains references to ciphersuites\n>> including the unpublished algorithms RC2 and RC4.\n> \n> I believe RC2 is still a trade secret, but RC4 was leaked to the\n> Cypherpunks list in September, '94.  The algorithm is described in\n> Chapter 17 of Bruce Schneier's \"Applied Cryptography\", 2ed.\n\nNot leaked.  Reverse engineered.  And RC2 was also reverse engineered\nsome months ago.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "Eric Murray wrote:\n> \n> Tom Libert writes:\n>>\n>> At 08:55 AM 3/7/97 -0500, David P. Kemp wrote:\n>>>  I noticed that the draft still contains references to\n>>> ciphersuites including the unpublished algorithms RC2 and RC4.\n>>\n>> I believe RC2 is still a trade secret, but RC4 was leaked to the\n>> Cypherpunks list in September, '94.  The algorithm is described in\n>> Chapter 17 of Bruce Schneier's \"Applied Cryptography\", 2ed.\n> \n> Why don't we add some Blowfish CipherSuites?\n> It's a published (and public domain!) algorithim.\n\nI'd like to see some Blowfish cipher suites, but I'm against adding\nanything to the list until it's turned over to the IANA.  I'd rather\nsee any energy focused in that direction.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "David P. Kemp wrote:\n> \n> The TLS base document should specify mandatory-to-implement algorithms\n> to promote interoperability.  Currently the DES/3DES ciphersuites\n> fill that role, but Blowfish or another published and freely-available\n> algorithm might conceivably be suitable as the interoperable\n> baseline.\n> \n> TLS \"transform\" documents could be written to specify the use of many\n> other ciphersuites, published or proprietary, including RC2, RC4,\n> Blowfish, SAFER, Fortezza(R), etc.  This makes it easier to add\n> future ciphersuites to TLS without having to re-do the base document\n> every time.\n\nI agree, although I'd like to see at least RC4 (or alleged-RC4)\nincluded in the mandatory list.  I think the Kerberos work is a\nperfect example of how cipher suites can be defined in seperate\ndocuments.\n\n-- \nYou should only break rules of style if you can    | Tom Weinstein\ncoherently explain what you gain by so doing.      | tomw@netscape.com\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "At 10:36 AM -0700 3/7/97, Mike Eisler wrote:\n>RFC2026, especially section 7.1 and section 10 provides guidelines for how to\n>incorporate external specifications into standards track documents. Section\n>7.1.2 says if the owners of RC2 and RC4 aren't willing to make these \"widely\n>and readibly available, the IESG may request that it be published as an\n>Informational RFC\". Section 10 has language that says that patented\n>technology can be incorporated, provided the owners will provide a\n>license under general and nondiscriminatory terms.\n>\n>I'll leave to the IESG to determine if both RC2 and RC4 meet these tests.\n\n\nThe language in RFC2026 stems from an ANSI requirement for \"standards\nproviders\" (of which IETF is one) so that the incorporation of intellectual\nproperty into a standard doesn't impose an unreasonable barrier to the\nstandard's implemention.\n\n---\nStephen Satchell, Satchell Evaluations\nhttp://www.accutek.com/~satchell for contact info\nOpinions expressed are my own PERSONAL opinions.\n\n\n\n"
        },
        {
            "subject": "Re: Access to certificates from browser JVM",
            "content": "Michael and all,\n\n  Some of the thoughts I had and some comments to Michael's post here.\n\nMichael Kirk wrote:\n> \n> >\n> > Michael Kirk wrote:\n> > >\n> > > Hi,\n> > >\n> > > I would like to be able to implement an SSL client within a Java\n> > > applet.  In particular I would hope to be able to use client\n> > > authentication via the certificates stored and managed by the browser,\n> > > or perhaps by the operating system. The only way I'd have access to\n> > > these certificate would be if the browser JVM in which the applet ran\n> > > provided it in some way.\n> > >\n> > > I think this is a natural thing to want to do, but as far as I know,\n> > > there is no support for it at present. Would someone from the major\n> > > browser vendors, be able to comment on whether such access is likely\n> > > to become available at any time ?\n> >\n> > This is a really bad idea, and something that should not be done without\n> > a lot of thought and very careful attention to safeguards.  What you're\n> > saying is that you'd like to allow java applets to use the user's\n> > credentials.  What's to prevent a java applet from connecting to, for\n> > example, my stock broker and performing trades without my knowledge?\n> >\n> > Java applets should behave as seperate entities, not as the user.\n> > That's why they are only allowed to connect back to the machine they\n> > came from, and not open sockets all over your intranet.\n> \n> Clearly the applet would have to be signed (otherwise it wouldn't\n> be able to contact the broker anyway - assuming the broker isn't on\n> the same machine).  This functionality is needed, otherwise the utility\n> of Java applets will be severely limited.  Security is becoming more\n> important, and simultaneously there is a trend toward using browsers as\n> universal clients running centrally managed software.  Such software needs\n> all the functionality of locally managed software if it is to be a viable\n> alternative to it.\n\n  I tend to see that there are really two sides to this percieved\nneed.  First, as to cenertally managed software, it would seem that\nproviding a certificate type security solution using SSL would be\nthe most commercially viable and technicaly feasible solution.  This\nwill most likely require some extension within the JVM or and API\ninterface that is configurable to the JVM on the server side.\n\nSecond, from within a browser, there are several approaches that\nwe have experimented with that might work well (More on this later\nin more detail), it would seem that some alternitive solutions\nwould be required in order to have some commercial viability.  \nsome of this could be done by creating some local libs for defination\nto that amplett and still and API (Local), though not necessarly part\nof the Java JVM would be necessary.  This night also have applications\nto push models as well.\n> \n> The mechanisms for recognizing, and providing support for, signed applets\n> need to be good enough to deal with this situation. An applet that needs\n> to act as the authenticated user would have to be explicitly allowed to\n> do so by the user (or perhaps by the sysadmin providing the user with\n> their browser and their certificates). For example a company xyz might\n> have an entity xyz-user-tools which is used only to sign applets that\n> need to represent the user via her certificate.  The browsers provided\n> by the company to its employees might come pre-configured to provide\n> certificate access to applets signed by xyz-user-tools.\n\n  This is one method that we have played around with internaly.  Works\npretty well but has some problems from a managment standpoint. \nSysadmins\nmay have a problem with not having more control if the ability from an\nindividual workstation running Java, had the ability to provide for\na SSL secured applet from that workstation.  So you are really back to a\nserver solution.  I don't care for this limitation, but it seems\nto me that some control point would need to be established.\n> \n> I'm not sure where you might see a security problem with this. In the\n> stock broker example the mistake is in giving very high level access\n> to an applet signed by someone who apparently signs malicious applets.\n\n  Yep, this is the problem with workstation level ability for SSL\ninterface for certificated amplets.\n> \n> >\n> > Now, it might be reasonable for a Java applet to have it's own\n> > certificate that the client stores (along with the private key) on its\n> > behalf to represent that applet running on behalf of that user.\n> \n> Having an applet-specific (or perhaps applet-signer-specific) certificate\n> managed by the browser would be useful (if that's what you mean). The\n> browser JVM would still need to provide an API to it, and the browser\n> would need to provide a way of installing it.  Is there any\n> plan to provide this functionality ?  Is there any way, in your view\n> that (appropriately signed) applets will be able to act as the user on their\n> behalf ?  Or do you believe there is no need for this functionality...\n\n  Certianly there is a need.  As I said above we have played with this\nexperimentaly already.  But as I stated above, there are some problems\nwith this ability, as you eluded to as well.  However the ability is\nreally already there to do and and experimental API that we have built\nhas proven to work fairly well.\n> \n> Michael Kirk\n> \n\nRegards,\n-- \nJeffrey A. Williams\nDIR. Internet Network Eng/SR. Java Development Eng.\nInformation Eng. Group. \nPhone :913-294-2375 (temporary)\nE-Mail jwkckid1@ix.netcom.com\n\n\n\n"
        },
        {
            "subject": "I-D ACTION:draft-ietf-tls-protocol01.tx",
            "content": " A Revised Internet-Draft is available from the on-line Internet-Drafts \n directories. This draft is a work item of the Transport Layer Security \n Working Group of the IETF.                                                \n\n       Title     : The TLS Protocol  Version 1.0                           \n       Author(s) : T. Dierks, C. Allen\n       Filename  : draft-ietf-tls-protocol-01.txt\n       Pages     : 67\n       Date      : 03/07/1997\n\nThis document specifies Version 1.0 of the Transport Layer Security (TLS) \nprotocol, which is at this stage is strictly based on the Secure Sockets \nLayer (SSL) version 3.0 protocol, and is to serve as a basis for future \ndiscussions. The TLS protocol provides communications privacy over the \nInternet. The protocol allows client/server applications to communicate in \na way that is designed to prevent eavesdropping, tampering, or message \nforgery.                                                                   \n\nInternet-Drafts are available by anonymous FTP.  Login with the username\n\"anonymous\" and a password of your e-mail address.  After logging in,\ntype \"cd internet-drafts\" and then\n     \"get draft-ietf-tls-protocol-01.txt\".\nA URL for the Internet-Draft is:\nftp://ds.internic.net/internet-drafts/draft-ietf-tls-protocol-01.txt\n \nInternet-Drafts directories are located at:\n                                                \n     o  Africa:  ftp.is.co.za                    \n                                                \n     o  Europe:  ftp.nordu.net            \n                 ftp.nis.garr.it                 \n                                                \n     o  Pacific Rim: munnari.oz.au               \n                                                \n     o  US East Coast: ds.internic.net           \n                                                \n     o  US West Coast: ftp.isi.edu               \n                                                \nInternet-Drafts are also available by mail.\n                                                \nSend a message to:  mailserv@ds.internic.net. In the body type: \n     \"FILE /internet-drafts/draft-ietf-tls-protocol-01.txt\".\n\nNOTE: The mail server at ds.internic.net can return the document in\n      MIME-encoded form by using the \"mpack\" utility.  To use this\n      feature, insert the command \"ENCODING mime\" before the \"FILE\"\n      command.  To decode the response(s), you will need \"munpack\" or\n      a MIME-compliant mail reader.  Different MIME-compliant mail readers\n      exhibit different behavior, especially when dealing with\n      \"multipart\" MIME messages (i.e., documents which have been split\n      up into multiple messages), so check your local documentation on\n      how to manipulate these messages.\n\n\n\nBelow is the data which will enable a MIME compliant mail reader \nimplementation to automatically retrieve the ASCII version\nof the Internet-Draft.\n\n\n\n\n\nMessage/External-body attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "Does [HMAC] (p. 14) corresponds to [KRAW] (p. 63)? There is not [HMAC]\nin the bibliography.\n\nDoes this reference corresponds to the RFC 2104 \"HMAC: Keyed-Hashing for\nMessage Authentication\", also by Hugo Krawczyk? If so, I think it's a\nbetter reference.\n\nLuis Saiz\n\n\n\n"
        },
        {
            "subject": "Re: TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "At 7:10 PM +0100 3/10/97, LUIS SAIZ GIMENO wrote:\n>Does [HMAC] (p. 14) corresponds to [KRAW] (p. 63)? There is not [HMAC]\n>in the bibliography.\n>\n>Does this reference corresponds to the RFC 2104 \"HMAC: Keyed-Hashing for\n>Message Authentication\", also by Hugo Krawczyk? If so, I think it's a\n>better reference.\n>\n>Luis Saiz\n\nYes; the omission of [HMAC] was an error in the preparation which has been\nrectified. [KRAW] will be removed. Also, a reference to the PKIX draft will\nbe inserted, specifing it as the guiding authorithy on X.509 certificate\nprofiles.\n\n - Tim\n\nTim Dierks - timd@consensus.com - www.consensus.com\n     Software Haruspex - Consensus Development\n  Developer of SSL Plus: SSL 3.0 Integration Suite\n\n\n\n"
        },
        {
            "subject": "TLS 1.0 &quot;draft-ietf-tls-protocol01.txt&quot; Now Availabl",
            "content": "Ref:  Your note of Mon, 10 Mar 1997 19:10:35 +0100 (attached)\n\n\n >\n > Does [HMAC] (p. 14) corresponds to [KRAW] (p. 63)? There is not [HMAC]\n > in the bibliography.\n >\n > Does this reference corresponds to the RFC 2104 \"HMAC: Keyed-Hashing for\n > Message Authentication\", also by Hugo Krawczyk? If so, I think it's a\n > better reference.\n >\n > Luis Saiz\n >\n\nLuis is right. The official reference to HMAC is rfc 2104 (it has three\nauthors: Krawczyk, Bellare and Canetti).\n\nHugo\n\n\n\n"
        },
        {
            "subject": "WG LAST CALL for draft-ietf-tls-protocol01.tx",
            "content": "text/enriched attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Spice girls' vocal concer",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Cbc, cb",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Sos",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Have tax problems",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Test of new mailing lis",
            "content": "This message is being sent to \"PICS-info@w3.org\" a newly created\nmailing list for general public dissemination of information about the\nPICS (Platform for Internet Content Selection) project.  There is a\ncompanion mailing list, \"PICS-ask@w3.org\" for the general public to\nask questions about the PICS work.  In addition, PICS maintains a set\nof Web pages at http://www.w3.org/PICS/\n\nPlease publicize the existence of these lists.  People can subscribe\nto PICS-info by sending email to \"PICS-info-request@w3.org\" with the\nword \"subscribe\" in the Subject: field.  You may remove your\nsubscription by send email to \"PICS-info-request@w3.org\" with the word\n\"unsubscribe\" in the Subject: field.\n\nWelcome!\n\n--Jim Miller\n(co-chair, PICS technical committee)\n\n\n\n"
        },
        {
            "subject": "call for participation in PIC",
            "content": "The PICS steering committee has drafted a Statement of Principles,\nincluded below, that summarizes their work and beliefs.  At this time\nthey are asking for additional companies who share these goals to join\nin the effort.  In particular, PICS plans a major press conference on\nOctober 30 at Internet World in Boston.  The deadline for inclusion in\nthis press conference is 5pm EDT Friday October 6, 1995, although this\nmay be extended because of delays in readying the statement of\nprinciples.\n\nIf your company would like to be included in this press release and/or\ndisplay the PICS logo at their booth at Internet World you should:\n\n1) Review this statement of principles.\n\n2) If you are in agreement, you must send a letter on company\nletterhead (fax or USPS only) to the PICS spokesman:\n\n   Mr. Albert Vezza\n   Associate Director\n   MIT Lab for Computer Science\n   545 Technology Square\n   Cambridge, MA 02139\n   fax: (617)258-8682\n\n3) The letter must explain that you agree with the PICS statement of\nprinciples, provide a contact name, address, and telephone number.  In\naddition, a fax number and email address would be helpful.  This\ncontact person should be able to make the formal decision for your\ncompany on inclusion in this and other press events.\n\n4) If you wish to allow the use of your corporate logo, you should\nsend a URL with a GIF image of the logo for use in press materials.\nThe preferred size is 48x48 pixels.\n\n================ PICS Statement of Principles ================\n\nPICS is a cross-industry working group whose goal is to facilitate the\ndevelopment of technologies to give users of interactive media, such\nas the Internet, control over the kinds of material to which they and\ntheir children have access.  PICS members believe that individuals,\ngroups and businesses should have easy access to the widest possible\nrange of content selection products, and a diversity of voluntary\nrating systems.\n\nIn order to advance its goals, PICS will devise a set of standards\nthat facilitate the following:\n\n* Self-rating: enable content providers to voluntarily label the\ncontent they create and distribute.\n\n* Third-party rating: enable multiple, independent labeling services\nto associate additional labels with content created and distributed by\nothers.  Services may devise their own labeling systems, and the same\ncontent may receive different labels from different services.\n\n* Ease-of-use: enable parents and teachers to use ratings and labels\nfrom a diversity of sources to control the information that children\nunder their supervision receive.\n\nPICS members believe that an open labeling platform which incorporates\nthese features provides the best way to preserve and enhance the\nvibrancy and diversity of the Internet.  Easy access to technology\nwhich enables first- and third-party rating of content will give users\nmaximum control over the content they receive without requiring new\nrestrictions on content providers.\n\nMembership in PICS includes a broad cross-section of companies from\nthe computer, communications, and content industries, as well as trade\nassociations and public interest groups.  PICS member will deploy\nproducts and services based on these standards.\n\n------- End of Forwarded Message\n\n\n\n"
        },
        {
            "subject": "PICS Updat",
            "content": "The PICS (Platform for Internet Content Selection) committee is\napproaching another milestone. On Wednesday, November 22, the PICS\ntechnical subcommittee will be releasing for public review their\nspecifications for both distribution of content labels and\ndescriptions of labeling services.\n\nIn addition, the first set of PICS reference code is now\navailable. This code is the set of interfaces for configuring content\nselection software shown publically in October. Check the PICS web\npage (http://www.w3.org/PICS/) for more information.\n\nThere are also three events of note coming up in early December:\n\n1) On December 7, in Dallas at the IETF meeting, there will be a\n\"birds of a feather\" session on Voluntary Access Control.  The PICS\nspecifications will be discussed at that time.  For details, check\nhttp://www.ietf.cnri.reston.va.us/meetings/Dallas.html.\n\n2) On Wednesday, December 13 at the 4th International World Wide Web\nConference in Boston, there will be a panel session on \"Rating Content\non the Web.\"  It will be chaired by Brian Ek (co-chair of the PICS\npublic policy/public relations sub-committee) and will have a number\nof interesting panelists.  Admission to the Web conference is\nrequired.  See http://www.w3.org/pub/Conferences/WWW4/.\n\n3) On Thursday, December 14 at the same conference there will be a\nDevelopers' Day session from 11:45am to 12:30pm on PICS.  There is\nalso likely to be a room set aside for detailed one-on-one questions\nabout PICS.  Registration for the Web conference is required.  See\nhttp://www.w3.org/pub/Conferences/WWW4/.\n\n--Jim\n\n\n\n"
        },
        {
            "subject": "Invitation to 1st PICS Developers Conferenc",
            "content": "(My apologies to those who receive this more than once.  In order to\nbe as inclusive as possible I am resending it to additional email\nlists.)\n\nThe World Wide Web Consortium is pleased to invite you to the first\nPICS Developers Conference, to be held on June 20 and 21, 1996 at MIT\nin Cambridge, Ma.  Please see the full invitation at\nhttp://w3.org/PICS/invite.htm for more information about the\nconference and registration procedures.  Excerpt from the invitation:\n\n     June 20: Planning for future protocol development.\n\n     The most important point of discussion will be whether and how to\n     specify ways for clients to ask search engines to take into\n     account their preferences. For example, clients may want to\n     search for materials that are labeled as having high educational\n     value. They may also want to search for pictures, but not to\n     receive any links to pictures labeled as containing nudity. The\n     existing specifications do not include any standard mechanisms\n     for making such requests.\n\n     June 21: Interoperability testing.\n\n     We will have some facilities available for running software,\n     either locally or remotely, and comparing results. This will also\n     be a chance to make personal contact with vendors from other\n     companies in order to arrange partnerships and private\n     interoperability testing.\n\n--Jim\n\n\n\n"
        },
        {
            "subject": "Proposed updates to PICS specification",
            "content": "As a result of feedback both from the IETF meeting and development\nexperience, there are some changes that must be considered for the\nspecifications.  I've created a new web page to keep track of the\nproposed changes that appear likely to be adopted, and would\nappreciate comments on them.  Comments should be sent to\npics-spec-comments@w3.org.\n\nThe information is available from http://www.w3.org/PICS/update.html.\nAs this page is updated I will send an email notice to alert you to\ntake another look at it.\n\n--Jim\n\n\n\n"
        },
        {
            "subject": "Suggested change to PICS spe",
            "content": "The following has been added to http://www.w3.org/PICS/update.html:\n\nAllow \"~\" in transmission names. \n     The SafeSurf system uses this as part of its naming scheme and\n     has requested that it be added to the syntax of both label lists\n     and machine-readable descriptions of rating services. Since it\n     does not impact any existing protocols, this addition is\n     straightforward: \"alphanumpm\" in both the machine-readable\n     description and the label list syntax must be extended to include\n     \"~\".\n\n--Jim\n\n\n\n"
        },
        {
            "subject": "Update to proposed change",
            "content": "The file http://w3.org/PICS/update.html has been updated.  A new\nversion of the PICS specifications is due out soon, and we need\nfeedback as soon as possible on these changes.\n\n--Jim\n\n\n\n"
        },
        {
            "subject": "decommissioning picsinfo mailing lis",
            "content": "This list (pics-info) was originally created to serve as a medium\nfor one-way announcements of PICS-related material to interested\nsubscribers.  The list has been inactive for well over a year;\ninstead, the relevant information has been posted periodically\non the W3C web site http://www.w3.org/\n\nThis list will be decommissioned effective immediately.  If you\nwant to continue to participate in e-mail discussion about PICS,\nyou may wish to subscribe to the pics-interest mailing list.\nSend a request with 'subscribe' in the subject line to\npics-interest-request@w3.org.  That list is available to all\nsubscribers to post.  To date, the volume of mail has been on\nthe order of less than one per week though there will be periods\nof higher activity.\n\nThank you for your interest in PICS.\n\n-Ralph Swick\n W3C Metadata Activity Leader\n\n\n\n"
        },
        {
            "subject": "Metadata activities in the medical fiel",
            "content": "Message-Id: \n  <WIN6fe-981201112739-5E5B*/c=de/admd=d400/prmd=uni-erlangen/o=/ou=med/ou=derma/s=Eysenbach/g=Gunther/@MHS>\nFrom: \"Gunther Eysenbach, MD\" <Gunther.Eysenbach@derma.med.uni-erlangen.de>\nTo: PICS-ask@w3.org, swick@w3.org, reagle@w3.org, djw@cdt.org, timbl@w3.org\nSubject: Metadata activities in the medical field\nMIME-Version: 1.0\nContent-Type: multipart/mixed; boundary=\"PART.BOUNDARY.max5.384e.36640d0b.0001\"\n\nGuys,\n\nyou might be interested in a set of articles discussing the use of PICS\n(or medPICS, respectively, see http://medpics.org) or other/similar\nmetadata technologies in the medical field, published in the British\nMedical Journal. \n\nThe main article is \n\nEysenbach G, Diepgen TL. Towards quality management of medical\ninformation on the internet:\nevaluation, labelling, and filtering of information. BMJ\n1998;317:1496-1502  \n(http://www.bmj.com/cgi/content/full/317/7171/1496)\n\nsurrounded by three commentaries and one editorial.\n\nNext year, I and a number of other medical institutions from around the\nglobe will try to get some funding from the EU (within their \"illegal\nand harmful content on the Internet\" framwork) for launching a project\non assigning metadata to medical information on the World-Wide-Web.\nDetails will be posted on the medPICS-Website (http://medpics.org).\n\n\n\nKind regards\n\nG. Eysenbach MD\nHead, Unit for Cybermedicine, University Heidelberg\n(at the moment still University Erlangen)\n\n\nPS: note to the person in charge for the PICS-pages on the w3.org\nserver: Could you perhaps put links to the BMJ-articles and to the\nmedpics.org website.\nDelivery-Time: 27 Nov 1998 03:25:09 +0100\nX400-Originator: Gunther.Eysenbach@derma.med.uni-erlangen.de\nMessage-Id: <199811270228.SAA19718@highwire.stanford.edu>\nIncomplete-Copy: TRUE\nFrom: bmj-mailer@highwire.stanford.edu\nTo: ey@yi.com (IPM Return requested)\nSubject: eBMJ: BMJ article mentioning eysenbach (in BMJ)\nContent-Type: text/plain; charset=us-ascii\nContent-Disposition: inline\n\n\n\n\nYour The BMJ CiteTrack Alert has found 3 articles which match your criteria\nin BMJ.\nBelow are results 1 to 3.\nAlert Criteria\nAnywhere in Article: eysenbach\n\n\nTowards quality management of medical information on the internet: \nevaluation, labelling, and filtering of information\n     Gunther Eysenbach, Thomas L Diepgen, J A Muir Gray, Maurizio Bonati, \n     Piero Impicciatore, Chiara Pandolfini, and Subbiah Arunachalam\n     BMJ 1998 317(7171): p. 1496-1502\n     http://www.bmj.com/cgi/content/full/317/7171/1496\n\nInformation epidemics, economics, and immunity on the internet\n     Enrico Coiera\n     BMJ 1998 317(7171): p. 1469-1470\n     http://www.bmj.com/cgi/content/full/317/7171/1469\n\nAppraisal of internet medical information is needed\n     \n     BMJ 1998 317(7171): p. 0f\n     http://www.bmj.com/cgi/content/full/317/7171/0/f\n\n-------------------------------------------------------------------\nAlert Criteria\nAnywhere in Article: eysenbach\n\n\n\n\n* * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\nTo modify or cancel this alert message, please visit the CiteTrack\nHome Page at http://www.bmj.com/cgi/ctmain.  You will need your\neBMJ username and password.\n\nIf you have forgotten your username or password for\neBMJ, you may request a new one at\nhttp://www.bmj.com/sub/recnamepwd\n\n(This message was sent to ey@yi.com)\n\n\n\n"
        },
        {
            "subject": "Any other test label bureaus out there",
            "content": "Hi all -- I work for Maxum Development Corp., a company that builds MacOS \nInternet server software. We're about ready to enter beta test phase for \nour new proxy server product, which includes a module for performing PICS \nfiltering. This product will be primarily targeted toward schools and \nsmall workgroups where Macs are still in abundance.\n\nI've tested its ability to query label bureaus against the few \npublicly-available label bureaus I can find, including:\n\n<http://pics.microsys.com/ratings> -- the \"CyberNOT\" list\n\nand:\n\n<http://www.sserv.com/cgi-bin/pics-serv> - evaluWEB's experimental server\n\nbut that's about it. The CyberNOT server has stopped serving labels \nlately, and the evaluWEB server is verrrry slow, and somewhat buggy.\n\nAre there any other publicly-available label bureaus out there that can \nbe used for testing?\n\n\n\n=====================================================================\nChris Patterson                                       chris@maxum.com\nMaxum Development Corp.                                 www.maxum.com\n\n                  \"Tao?\" \"Nah, I prefer to drip-dry.\" \n=====================================================================\n\n\n\n"
        },
        {
            "subject": "evaluWEB note",
            "content": "[Original posting to pics-interest on 2-July caught by our spam filter.\n  -Ralph]\n\nFor those who were using the evaluWEB PICS server:\n\nevaluWEB will continue offering PICS ratings until the end of its service\nagreement at the current location. We had a runaway process this morning\nthat shut down some services and made the system really slow -- apologies\nall around for the inconvenience.\n\nProbably by mid-July we will have the PICS server running at its new\nlocation at Point Loma Nazarene University in San Diego, California. evaluWEB\nwill be running independently of sserv.com and I'll be taking the project\nover personally. I'll post a URL at that time.\n\n-- \nCameron Kaiser * spectre@sserv.com * http://www.sserv.com/\n\n\n\n"
        },
        {
            "subject": "Re: Any other test label bureaus out there",
            "content": "Net Shepherd might let you connect to their label bureau for testing\npurposes. Try contacting Ron Warris (ron.warris@netshepherd.com).\n\nWe have a label bureau at the University of Michigan PICS Incubator that\nserves SurfWatch labels in PICS format, but it is for demonstration uses\nonly. Contact Ali Salomon (ali@surfwatch.com) at SurfWatch to ask\npermission. If she says OK I'll send details on how to connect.\n\nW3C has the Jigsaw label bureau which you can run (source code provided)\nbut you'll have to provide your labels to populate it. See\nhttp://www.w3.org/PICS/refcode/\n\n(When you say that you have a module for performing PICS filtering rules, I\nhope that you have implemented this as an evaluator for the PICSRules\nlanguage. There is a reference implementation of such an evaluator, in\nJava, available at the same URL: http://www.w3.org/PICS/refcode/ in the\n\"PICS Standard Library\")\n\nAt 06:28 PM 7/1/98 -0500, you wrote:\n>Hi all -- I work for Maxum Development Corp., a company that builds MacOS \n>Internet server software. We're about ready to enter beta test phase for \n>our new proxy server product, which includes a module for performing PICS \n>filtering. This product will be primarily targeted toward schools and \n>small workgroups where Macs are still in abundance.\n>\n>I've tested its ability to query label bureaus against the few \n>publicly-available label bureaus I can find, including:\n>\n><http://pics.microsys.com/ratings> -- the \"CyberNOT\" list\n>\n>and:\n>\n><http://www.sserv.com/cgi-bin/pics-serv> - evaluWEB's experimental server\n>\n>but that's about it. The CyberNOT server has stopped serving labels \n>lately, and the evaluWEB server is verrrry slow, and somewhat buggy.\n>\n>Are there any other publicly-available label bureaus out there that can \n>be used for testing?\n>\n>\n>\n>=====================================================================\n>Chris Patterson                                       chris@maxum.com\n>Maxum Development Corp.                                 www.maxum.com\n>\n>                  \"Tao?\" \"Nah, I prefer to drip-dry.\" \n>=====================================================================\n>\n>\n>\n>\n\n------------------------------------------------------------\nPaul Resnick                  presnick@umich.edu\nAssociate Professor           http://www.si.umich.edu/~presnick\nThe University of Michigan    (fax) 734-764-2475\nSchool of Information         (voice) 734-647-9458\n314 West Hall\n550 East University Avenue\nAnn Arbor, MI 48109-1092\n\n\n\n"
        },
        {
            "subject": "Permanent (hopefully) coordinate",
            "content": "(I've sent this with a BCC to lots of people, so you don't get inundated\nwith long headers...)\n\nBarb and I are finally settling into the Seattle area.  It took almost 9\nhours to close the deal, but we finally own a house in Bellevue, WA.  We\nshould close on the house in Arlington at the end of the month and will be\nall moved out of the Boston area by the first week of August.\n\nwork:                          home:\nJim Miller (JSMiller)          Jim Miller\n42/2099                        17213 N.E. 4th Place\nOne Microsoft Way              Bellevue, WA 98008\nRedmond, WA 98052-6399\n\n(425)936-7496                  (425)373-5414 [after July 27]\nfax: (425)936-7329             cell: (425)830-4270\nemail: JSMiller@microsoft.com  email: James.Miller@alum.mit.edu\n\nNote: Be sure to put \"(JSMiller)\" after my name in mail or faxes sent to\n      me at Microsoft.  There is another James Miller, so they use the\n      email address to route incoming mail and faxes.\n\n--Jim\n\n\n\n"
        },
        {
            "subject": "PICS (What else!",
            "content": ">Date: Wed, 08 Jul 1998 14:16:07 -0700\n>From: Jeffrey Rollin <d.rollin@virgin.net>\n>Reply-To: d.rollin@virgin.net\n>To: jmiller@w3.org\n>Subject: PICS (What else!)\n>\n>Dear Jim\n>\n>I am a researcher at UNN at Newcastle in England and I am currently\n>conducting a feasibility study into PICS ratings systems. The\n>implementation of this system seems imminent and my personal feelings\n>from the research thus far sugget that it is the front-runner in the\n>scramble for regulation of the Net. \n>\n>I have conducted a study into the opinions of Internet users and\n>non-users' regarding the shortfalls of the Net, and a summary of the\n>findings so far suggests that people are largely in favour of a\n>non-centralised system of access controls - though this must be\n>malleable. Though almost all feel that the majority of 'objectionable\n>matter' should remain on the Net in some form, there is however\n>concensus on the issue of total censorship of 'extreme' material or that\n>with no 'discernable positive merit' - though the specifics of what this\n>may involve are unclear. This would seem to be one thing which PICS\n>cannot cater for, and has been accused of being a 'half measure'. I\n>would welcome your comments regarding this or any other aspect of PICS.\n>\n>Thank you\n>\n>Richard Archer\n>\n>Contact:archerrichard@hotmail.com\n>\n>\n\n\n\n"
        },
        {
            "subject": "Fwd: WebDoubler by Maxu",
            "content": "Well, you've all been listening to me talk about our new product, so I \nthought I'd share the \"official\" announcement with you. Hope this doesn't \nfall too far outside the list charter...\n\nChris Patterson\n\n---------------- Begin Forwarded Message ----------------\n\nPress Contact: John O'Fallon\n        Phone: (630) 830-1113\n          Fax: (630) 830-1262\n       E-Mail: john@maxum.com\n\n\n              Maxum Development Announces WebDoubler\n        New Product Promises Dramatic Performance Increases\n        And Web Management For Internet Connected Workgroups\n\n\nMacWorld, July 10, 1998 -- Maxum Development Corporation this week\nannounced WebDoubler, a new product that offers LAN managers the ability \nto\nmanage Internet access while accelerating Web surfing for an entire\nworkgroup or classroom. At its core, WebDoubler acts as a proxy server,\nmuch like competitive offerings from Microsoft and Netscape \nCommunications,\nto provide a gateway between LAN clients and the Internet. By acting as a\nconduit between LAN clients and the Internet, the proxy has the ability to\nperform a wide range of additional services for both the network\nadministrator and users surfing the Web.\n\nWeb Acceleration For The Entire LAN\n\nWebDoubler includes a high-performance caching mechanism developed by\nClearWay Technologies, a recognized leader in Internet acceleration\nproducts. The cache stores downloaded Web content for future use, \nproviding\ninstant access to frequently hit Web pages, graphics, downloads, and more.\nThe WebDoubler cache is far more effective than caches built into \nbrowsers,\nbecause it functions for the entire LAN. WebDoubler's cache manager\nsupports multi-gigabyte cache sizes that span any number of hard disk\ndrives, allowing network managers to create enormous caches that can be\nexpanded with ease. The cache manager also employs a \"producer/consumer\"\nmodel that enables multiple simultaneous accesses of a single object using\na single \"real\" Internet connection. Finally, not only does LAN caching\nprovide near-instant access to common objects, but it reduces traffic on\nthe organization's Internet connection, maximizing the use of expensive\nbandwidth.\n\nContent Filtering And Usage Tracking\n\nWebDoubler also includes a full implementation of the industry leading \nPICS\ncontent rating and filtering system. PICS enables the network \nadministrator\nto create \"rules\" that define what content is appropriate or inappropriate\nfor the workgroup. For example, schools can use WebDoubler's PICS filter \nto\nensure that no pornographic material is downloaded by students over the\nschool's Internet connection. Rules that can be created range from simply\nspecifying Web sites that should not be permitted to recognizing rating\ntags built into Web pages to the use of independent content ratings\nservices for on-the-fly ratings lookup. Because WebDoubler is used by the\nentire LAN, PICS configuration is done once, and instantly blocks\ninappropriate content to all browsers in the organization. WebDoubler also\nincludes wizards that make common PICS rules a snap to configure. In\naddition to blocking content outright, WebDoubler will also maintain a \nfull\nhistory of Internet access, enabling organizations to analyze exactly how\ntheir Internet connection is being used.\n\nAdditional Benefits\n\nHTTP Version Upgrading - WebDoubler takes advantage of the latest HTTP\nstandards to maximize performance and bandwidth. This enables even older\nWeb browsers (or current browsers that don't yet take advantage of the\nlatest HTTP features) to reap the benefits of persistent connections,\nobject pipelining, etc. without the need for software upgrades.\n\nWeb Administration - WebDoubler's initial configuration is performed using\na traditional Macintosh GUI, but ongoing adjustments to the WebDoubler\ncache, PICS rules, etc. is performed from anywhere on the LAN or Internet\nusing a standard Web browser.\n\nVirtual Private Network (VPN) Gateway - WebDoubler can be used to provide\nan entire LAN with Web access using a single IP address and a single\nInternet connection. Not only can this represent a major cost savings, but\nit provides an exceptional level of security. Because the WebDoubler\nMacintosh is the only computer on the network with an actual Internet\nconnection, it is also the only computer on the LAN that can be \"seen\" \nfrom\nthe Internet, protecting internal servers and desktops.\n\nSecure Transaction (SSL) Support - WebDoubler provides SSL tunneling,\nenabling browsers full access to secure pages on any Web site. Of course,\nthis feature can also be disabled, allowing administrators to deny access\nto on-line stores and other secure materials.\n\nWebDoubler Expandability\n\nActing as a proxy server, WebDoubler effectively becomes the Internet to\nthe clients in a workgroup. Since every Web transaction made within the\norganization goes through WebDoubler, the possibilities for extending its\nfunctionality are virtually limitless. Because of this potential,\nWebDoubler has been designed from the very beginning to be expandable, and\nincludes an extremely robust plug-in architecture. In fact, WebDoubler's\ncache manager, PICS filtering, and even basic Web access are implemented \nas\nplug-ins which will be included in the shipping product. Future plug-ins\nthat are currently in the planning stages include a \"look-ahead\" cache\n(which will enable users to pre-cache selected Web sites at night, during\nlow-bandwidth use times), advanced logging and usage tracking, proxy\nauthentication (requiring passwords for Internet usage) and more.\n\nPricing And Availability\n\nWebDoubler is expected to ship in late August, with a retail price of $895\ndirect from Maxum. Information about the product, as well as a \ndownloadable\nbeta version is already available on the Maxum Web site, at:\n\nhttp://www.maxum.com/WebDoubler/\n\nAbout Maxum\n\nFounded in 1991, Maxum Development is a leading developer of commercial\nWorld Wide Web server tools for business and education. Maxum products,\nNetCloak and NetForms, were the first commercial tools for Macintosh-based\nWWW servers and have since become industry mainstays. All Maxum products\nare designed to enhance the function and performance of Web sites by \nmaking\nthem dynamic, interactive, reliable, fast, and accessible.\n\n----------------- End Forwarded Message -----------------\n\n=====================================================================\nChris Patterson                                       chris@maxum.com\nMaxum Development Corp.                                 www.maxum.com\n\n                  \"Tao?\" \"Nah, I prefer to drip-dry.\" \n=====================================================================\n\n\n\n"
        },
        {
            "subject": "Fwd:  European Commission asks for massive use of blocking on     the We",
            "content": "They unfortunately confuse (third party) rating and blocking.\n \n >http://europa.eu.int/eur-lex/en/dat/1998/c_214/c_21419980710en00290032.pdf\n >\n >------------------------------- CUT -------------------------------\n >\n >\n >       Official Journal\n >       of the European Communities\n >                                   ISSN 0378-6986\n >\n >                                   C 214\n >                                   Volume 41\n >                                   10 July 1998\n >\n >       98/C 214/08\n >                   Opinion of the Economic and Social Committee on the\n >                   `Proposal for a Council Decision adopting a\n >                   Multiannual Community Action Plan on promoting safe\n >                   use of the Internet' \n >\n >------------------------------- CUT -------------------------------\n\n3. The Committee's comments\n3.1.    The Committee is, generally speaking, very\nfavourably disposed towards the Commission's action\nplan. The Committee notes that the planned actions\nactually attempt to address the problem. Even more\nimportant than this is attempting to change mentalities,\nthus curbing excesses. The Committee realizes however\nthan this is unrealistic.\n3.1.1.    The Committee is very glad that the Com-\nmission has drawn a distinction in its action plan\nbetween illegal and harmful content.\n3.1.1.1.    But the Committee notes that, in translating\nthis into specific measures, very little attention has been\npaid to illegal content in relation to protection of\nintellectual property, human dignity and privacy or to\noffences relating to national and economic security.\nAlthough these issues are specifically listed in the action\nplan under the heading of illegal content, the bulk of\nthe funding (ECU 20,1 million!) has been reserved for\nthe action lines aimed at protection of minors (the\nawareness actions and the development of material\nfor users). The Committee considers this a serious\nshortcoming and returns to this question in its con-\nclusions.\n3.1.1.2.    The Committee wholeheartedly endorses the\nCommission's conclusion that, in combating illegal\ncontent, the accent must be placed on self-regulation\nand application of the law.\n3.2.    The Committee wonders however whether, in\ndealing with harmful content, relying on public aware-\nness of ways of preventing individuals from coming into\ncontact with such content is not too limited an approach.\nThe Committee is not convinced that the technological\nsolution proposed by the Commission is the most\neffective way of tackling a social problem.\n3.2.1.    A danger of this technological approach is that,\nonce a filter system has been installed, parents and\nteachers, believing that their children are now in a safe\nenvironment, will see no need for further supervision,\nnot realizing that childrenwill quickly find any loopholes\nin the system. Experience has shown that children's\ncomputerknowledgeoften surpasses thatoftheir parents\nand teachers. The Committee also wonders whether the\ntarget group (parents and children) will be sufficiently\ninvolved in the development of the system.\n3.3.    Although rating offers great advantages in terms\nof the cataloguing and indexing of content, thus making\nthe Internet more transparent and accessible, this applies\nboth to desirable and undesirable information. The\nCommittee would also point out in this connection that\nrating might in practice well be counter-productive.\nRatings would be assigned not only to innocuous\ncontent, but also to potentially harmful content, such\nas pornography. This would greatly simplify the task of\nanyone searching for harmful content on the Internet.\n3.3.1.    TheCommitteenotesthat, contraryto previous\nassertions, only one major browser programme (Micro-\nsoft Explorer) currently supports PICS (Platform for\nInternet Content Selection), on which rating and filtering\nare based. Other browsers, such as Netscape and (the\nEuropean) Opera do not. Even if Netscape and Opera\neventually become PICS-compliant, without legal com-\npulsion there will always be programmes which do not\nsupport PICS, enabling a child to circumvent the\nrestrictions relatively easily. Although the Committee is\nin general not unfavourably disposed to the development\nof PICS, it does question the claim that PICS will turn\nthe Internet into an environment free of harmful content.\n3.4.    The Committee supports the Commission in its\nview that cultural and social diversity based on freedom\nof expression is a thing of great value which must not\nbe compromised by efforts to achieve a safe Internet;\nalso that, in deciding what is harmful and what is not,\nthe onus must be on the individual, whether or not\nin his capacity as educator. In this connection, the\nCommittee would point out to the Commission that,\nfrom a technological point of view, it is not only teachers\nwho can use filter systems to protect children from\nharmful content, but also Internet access providers.\nThis would mean a system which is presented as\n`user-empowering' becoming an instrument of control,\nactually taking choice out of citizens' hands.\n3.5.    The Committee would also point out that the\nInternet is more than just the World Wide Web. PICS\noffers no solution where chat groups, e-mail and\nnews groups (discussion forums) are concerned. The\nCommittee does not consider filter systems based on\nrating designed to achieve safe communication to be a\nrealistic option. The proposed approach offers no\nsolution for important Internet applications such as chat\nand e-mail, which are also used by children.\n3.6.    The Committee insistently draws the Com-\nmission's attention to blocking as an alternative to\nrating. Although perhaps a blunter instrument, it is for\nall that no less effective. Blocking programmes do not\nrequire rating by the owner or supplier of the content,\nbut rely on third parties supplying target group-specific\nlists of proscribed expressions. In the USA there are\nalready dozens of blocking programmes (such as Cyber-\nnanny, Surfpatrol etc) which, when installed on a PC,\nblack out proscribed words and images on the basis of\nthese lists.\n3.6.1.    The distinction between rating and blocking is\nan important one, as rating requires an industry-wide\napproach (all content suppliers have to participate),\nwhilst all that is required for blocking programmes is\ntargeted promotion of innovation. In the case of blocking\nprogrammes itisstimulationofthedemand side(parents,\neducators and teachers) which is important, whilst\nrating can only be successful if there is an industry-wide,\nsupply-side approach. In view of the above (see\npoints 3.3-3.5) the Committee pins its hopes on solutions\naimed at developing the demand for useable blocking\nprogrammes.\n3.6.2.    The Committee does not consider realistic the\nargument of human rights organizations that blocking\nwould restrict freedom of expression, as with pro-\ngrammes of this kind it is not the disseminator of the\ninformation but the receiver of the message who is\nresponsible for the correct use of the filter system.\nExperience (in the USA) shows that blocking pro-\ngrammes are a useful tool in the hands of educators who\nneed a safe environment for the children in their care.\nThe Committee suspects that one major reason for the\ngeneral lack of interest in blocking programmes of this\nkind in Europe so far is unfamiliarity with this approach\nto the problem, and with the medium.\n3.7.    The Committee finds no reference in the Com-\nmission's action plan to the distinction between open\nand closed networks. Citizens' need for high-quality and\neasily accessible information is creating a market for\nnetworks based on Internet technology which may be\npart of the Internet but which contain only a small\nproportion of the content available on the Internet. In\nterms of their diversity and quantity `mini-Internets' of\nthis kind are thus not comparable with the worldwide\nInternet.\n3.7.1.    Providers of such large-scale mini-Internets or\nintranets have control and are thus in a position to offer\ntheir customers guaranteed quality of service, not only\nin terms of capacity and security but also as regards the\ntransparency and reliability of the content.\n3.7.2.    In closed networks of this kind there is a clear\ndistinction between information suppliers (firms) and\ninformation users (customers). Private users do not have\nhome pages. It therefore goes without saying that\nintranets of this kind are easier to protect against illegal\nand harmful content than the open, worldwide Internet.\nThe Committee foresees closed networks of this kind\nincreasingly satisfying citizens' needs for a safe Internet.\nPartly in the light of the period for which the action\nplan is intended to run, the Committee wonders how\nfar the proposed action lines take account of this\ndevelopment.\n\n\n___________________________________________________________\n\nJoseph Reagle Jr.  W3C:     http://www.w3.org/People/Reagle/\nPolicy Analyst     Personal:  http://web.mit.edu/reagle/www/\n                   mailto:reagle@w3.org\n\n\n\n"
        },
        {
            "subject": "W3C NOTE-PICS-Statement19980601 publishe",
            "content": " http://www.w3.org/TR/NOTE-PICS-Statement\n \n ___\n \n [1]W3C NOTE-PICS-Statement-19980601\n                                                                             \n Statement on the Intent and Use of PICS:\n Using PICS Well\n                                       \n W3C NOTE 01-June-1998\n                                       \n    Latest Version: \n           [2]http://www.w3.org/TR/NOTE-PICS-Statement\n           \n    This version:\n           [3]http://www.w3.org/TR/1998/NOTE-PICS-Statement-19980601\n           \n    Previous Version:\n           n/a\n           \n    Editors\n      * Joseph Reagle, W3C, [4]reagle@w3.org,\n      * Daniel J. Weitzner, Center for Democracy and Technology,\n        [5]djw@cdt.org\n        \n    Signatories: \n      * Stephen Balkam, President, Recreational Software Advisory Council\n        (RSAC)\n      * Tim Berners-Lee, Director, World Wide Web Consortium (W3C)\n      * Alan Kotok, Associate Chairman, W3C\n      * Jim Miller, Co-Chair of PICS Technical Committee, Lab for Computer\n        Science, MIT\n      * Martin Presler-Marshall, Editor/Co-author PICSRules, IBM\n      * Joseph Reagle, Policy Analyst, W3C\n      * Paul Resnick, Chair, PICS Interest Group; School of Information,\n        University\n        of Michigan\n      * Daniel J. Weitzner, Deputy Director, Center for Democracy and\n        Technology\n        \n    [Those interested in becoming signatories after this is posted as a\n    note will likely be listed on a separate page.]\n    \n Status of This Document\n \n    This document describes the intent of PICS development and recommends\n    guidelines regarding the responsible use of PICS technology. While it\n    is relevant to the [6]PICS specifications it was not created as part\n    of the PICS Working Groups (which are closed). However, it was\n    submitted for review to the W3C Policy and PICS Interest Groups before\n    publication. It has no official W3C standing. Comments to the editors\n    or endorsements are welcome.\n      _________________________________________________\n    \n    The signatories state the following with respect to the intent, and\n    usage of PICS (all PICS specifications):\n    \n Overview\n \n    In August of 1995, leading members of the Internet community came\n    together to begin the development of technical specifications that\n    would enable users to 1) easily find appropriate content and 2) avoid\n    content that they consider inappropriate or unwanted, either for\n    themselves or their children. These specifications were designed to\n    ease the creation of, and access to, labeling schemes (and associated\n    content selection and filtering mechanisms), allowing various people\n    or organizations to label Web content in ways that best suit their\n    different viewpoints. The PICS specifications were not intended to be\n    limited to applications regarding potentially offensive content.\n    Rather, it was hoped that PICS would be used for many purposes, such\n    as third-party ratings on the timeliness and technical accuracy of a\n    site's content.\n    \n    Final technical specifications were completed in early 1996. Since\n    then PICS has been incorporated into a number of [7]products, a\n    variety of PICS-based rating [8]services have been (and continue to\n    be) developed for the web, and a number of stand-alone [9]filtering\n    tools are PICS-compatible.\n    \n    Many who were involved in the creation of PICS recognized that the\n    World Wide Web provides access to an extraordinary range of content,\n    some of which some people consider either inappropriate, unwanted, or\n    harmful for some users, especially children. The global nature of the\n    Web, and the fact that it serves numerous communities with a great\n    diversity of values, suggested that national, or even international\n    laws restricting certain kinds of speech on the Web would neither be\n    effective nor necessarily desirable for the Web. Instead, PICS was\n    developed to accommodate a wide range of communities online.\n    \n    The original PICS proposers based their work on a general set of\n    principles, detailed below. In the time since PICS and other content\n    selections tools have been deployed on the web, much has been learned\n    about the use of PICS-based techniques. This note builds on those\n    Principles a set of functional guidelines for implementing PICS-based\n    components of the Web infrastructure, PICS rating services, and\n    PICS-based content selection tools to assure that they are designed in\n    a manner that comports with the original PICS Principles and the free\n    flow of information on the Web.\n    \n Restatement of PICS Principles\n \n    The original 22+ organizations that proposed the PICS Specifications\n    also adopted the following statement of principles to guide their\n    work:\n    \n      We believe that individuals, groups and businesses should have easy\n      access to the widest possible range of content selection products,\n      and a diversity of voluntary rating systems. \n      \n      In order to advance its goals, PICS will devise a set of standards\n      that facilitate the following: \n      \n    Self-rating: \n           enable content providers to voluntarily label the content they\n           create and distribute. \n    Third-party rating: \n           enable multiple, independent labeling services to associate\n           additional labels with content created and distributed by\n           others. Services may devise their own labeling systems, and the\n           same content may receive different labels from different\n           services. \n    Ease-of-use: \n           enable users, parents and teachers to use ratings and labels\n           from a diversity of sources to control the information that\n           they or children under their supervision receive. \n           \n      PICS members believe that an open labeling platform which\n      incorporates these features provides the best way to preserve and\n      enhance the vibrancy and diversity of the Internet. Easy access to\n      technology which enables first and third party rating of content\n      will give users maximum control over the content they receive\n      without requiring new restrictions on content providers. \n      \n Guidelines for the Usage of PICS\n \n    In addition to the principles above, we recommend that systems and\n    services based on PICS ought to be implemented with the following\n    guidelines in mind. These guidelines promote the principles of\n    diversity, disclosure, control, and transparency.\n      * Using PICS Rating Systems and Services: The Web, through PICS\n        implementations, ought to support access to a variety of labeling\n        systems that reflect the diversity of moral and cultural values\n        held by those that use the Net.\n          1. No single rating system and service can perfectly meet the\n             needs of all the communities on the web.\n          2. The ability of multiple organizations to use PICS  to create\n             lists of suggested content is an encouraged means of using\n             PICS. These lists may be distributed through label bureaus\n             and be used for searching, or as \"white\" lists of materials\n             that should be permitted even if they would otherwise be\n             blocked.\n          3. Filtration and labeling schemes should be designed such that\n             the combined effect does not lead to a chilling of expression\n             or the creation of significant barriers to diverse opinion\n             and content. Small and non-commercial sites should continue\n             to be a part of the Web available to all users.\n      * Creating Labeled Content: The creation of content that is labeled\n        should be done in a way so as to maximize the transparency and\n        integrity of the Web.\n          1. PICS-based systems should facilitate disclosure of the\n             criteria used to rate content.\n          2. Content rating should be as simple as possible for authors\n             and content providers who wish to label content.\n          3. The decision to self-label should be at the discretion of\n             content creators and publishers.\n          4. If a content creator is concerned about the accuracy of a\n             third party rating, she should be able to investigate how her\n             materials are rated and have some means of requesting a\n             change in the ratings where they do not match the stated\n             criteria of the rating service.\n      * Using Labeled Content: Users should have the ability to understand\n        and control the choices made in the selection of content in an\n        easy and transparent manner.\n          1. Users of PICS-based content selection systems should have\n             easy access to information about the filtering criteria, the\n             values or principles underlying them, and to the\n             configuration of the content selection systems. This can be\n             accomplished by providing the following information in the\n             product documentation or at the Service URL:\n               a. a clear statement of the methodology used to create the\n                  labels;\n               b. a contact (both physical and virtual) for questions or\n                  concerns.\n          2. When access to a particular URL is blocked through an\n             implementation of PICS, error conditions or other user\n             interface functions ought to specifically indicate that the\n             URL is not accessible because of blocking by a content\n             selection tool. Relevant information could include:\n               a. the rating system whose value is out of range (if more\n                  than one is being used) and which variable and value led\n                  to the blocking of a URL.\n               b. some indication of where the blocking occurred.(i.e. is\n                  it part of the browser and under local control, or is it\n                  a proxy and if so who owns and/or operates the proxy.)\n          3. It should be as easy as possible for an authorized user to\n             install and modify filters. In particular, we recommend that\n             filtering software have the ability to import filtering\n             preferences that are specified using the PICSRules language.\n        \n Other Documents\n \n      * [10]Platform for Internet Content Selection (PICS) Home Page\n      * [11]Internet Summit Technology Inventory\n      * [12]PICS, Censorship, and Intellectual Freedom FAQ\n \n References\n \n    1. http://www.w3.org/\n    2. http://www.w3.org/TR/NOTE-PICS-Statement\n    3. http://www.w3.org/TR/1998/NOTE-PICS-Statement-19980601\n    4. mailto:reagle@w3.org\n    5. mailto:djw@cdt.org\n    6. http://www.w3.org/PICS\n    7. http://www.w3.org/PICS/#Products\n    8. http://www.w3.org/PICS/#Developers\n    9. http://www.microsys.com/pics/software.htm\n   10. http://www.w3.org/PICS/#Products\n   11. http://www.research.att.com/~lorrie/pubs/tech4kids/\n   12. http://www.si.umich.edu/~presnick/pics/intfree/faq.htm\n \n \n\n___________________________________________________________\n\nJoseph Reagle Jr.  W3C:     http://www.w3.org/People/Reagle/\nPolicy Analyst     Personal:  http://web.mit.edu/reagle/www/\n                   mailto:reagle@w3.org\n\n\n\n"
        },
        {
            "subject": "RSAC/Netscape joint releas",
            "content": " FOR IMMEDIATE RELEASE\n \n Contacts:\n \n Kate Castle/Pat Arcand   Maggie Young\n Copithorne & Bellows for RSAC                   Netscape Communications\n 617/450-4300 x264    650/937-2370\n kate.castle@cbpr.com    maggie@netscape.com\n \n \n RSAC ANNOUNCES NETSCAPE SUPPORT OF RECREATIONAL SOFTWARE ADVISORY COUNCIL?S\n LEADING INTERNET CONTENT RATING SYSTEM\n \n Netscape Communicator Users Gain Ability to Monitor Content\n Viewed by Children With NetWatch\n \n Washington, D.C. ?June 17, 1998 ? The Recreational Software Advisory Council\n (RSAC) today announced that Netscape Communications Corporation (NASDAQ:\n NSCP) will integrate RSAC?s objective, Internet content advisory system into\n its market-leading client software.  Working as a part of Netscape?s\n recently announced NetWatch feature in Netscape Navigator 4.5, RSAC?s rating\n system for the Internet (RSACi) will provide parents and consumers with an\n advanced tool to monitor the content viewed by their children on the World\n Wide Web.  NetWatch is a feature of Netscape?s Smart Browsing? capabilities\n and provides a mechanism for screening Internet content, allowing control\n over Web page viewing so users access only the Internet content they want to\n see.\n \n RSACi is a PICS-compliant (Platform for Internet Content Selection) system\n that provides labels to Web masters based on a detailed questionnaire\n regarding the level, nature and intensity of the sex, nudity, violence or\n offensive language (vulgar or hate-motivated) found on a particular Web\n site.  By integrating the RSACi rating system into Netscape Communicator?s\n NetWatch system, Netscape users can now anticipate Internet content and\n block any materials they deem inappropriate or offensive.\n \n Using the NetWatch feature on the Netscape Navigator browser, parents and\n consumers will be able to select RSACi  as the system to set the levels on\n the amount of nudity, sex, language and violence that they consider\n appropriate for users in their household.  If there is more than one\n Internet user in the household, NetWatch will enable parents to set\n different levels for each user.\n \n \"Netscape is committed to empowering the user without diminishing the\n Internet experience,\" said Dave Rothschild, vice president of client\n products at Netscape.  \"The RSACi advisory system gives Navigator users a\n tool that will allow them to shape their Internet experiences to fit their\n own values.  Web enthusiasts will be pleased to see that they will have a\n new tool for anticipating and blocking content they would prefer not to see,\n but that also preserves the ability of content creators to say what they\n want and how they want is not in jeopardy.\"\n \n \"We?re very pleased that Netscape has chosen to bring the RSACi content\n advisory system to the Communicator family,\" said Stephen Balkam, executive\n director of RSAC.  \"Given Netscape?s commanding presence in the browser\n market, it?s exciting to see the company?s commitment to providing users\n with a reliable tool for controlling Web content through the RSACi content\n advisory system.\"\n \n RSACi empowers parents and consumers to make informed choices about what\n they and their children experience in cyberspace.  The RSACi rating system\n is a fully-automated, Web-based system that relies on a quick, easy-to-use\n questionnaire that the Web master completes at RSAC's home page\n [http://www.rsac.org].  The questionnaire runs through a series of highly\n specific questions about the level, nature and intensity of the sex, nudity,\n violence or offensive language (vulgar or hate-motivated) found within the\n Web master's site.\n \n Once completed, the questionnaire is then submitted electronically to the\n RSAC Web server, which tabulates the results and produces the HTML advisory\n tags that the Web master then places on their Web site.  A standard Internet\n browser or blocking device that has been configured to read the RSACi system\n can recognize these tags, enabling parents who use the browser to either\n allow or restrict their children's access to any single rating or\n combination of ratings.\n \n RSAC\n \n The Recreational Software Advisory Council is an independent, non-profit\n organization based in Washington, D.C. that empowers the public, especially\n parents, to make informed decisions about what they and their children\n experience on the Internet by means of an objective content advisory system.\n RSACi is the world?s leading rating system for the Internet.  It has now\n been integrated into Netscape Navigator and Microsoft?s Internet Explorer.\n RSAC's system provides consumers with information about the level of nudity,\n sex, language, and violence in Websites.  More information on RSAC and the\n RSACi rating system is available at http://www.rsac.org.  To date, more than\n 75,000 web sites have rated with the RSACi system, with over 4,000 sites, on\n average, rating each month.\n \n RSACi has been nominated by an international committee of experts to receive\n the Carl Bertelsmann Prize 1998. The Prize, which has been awarded since\n 1988 for innovative approaches to important public policy challenges, this\n year has the theme \"Communications 2000 - Innovation and Responsibility in\n the Information Society\". The final decision of the Prize jury will be\n announced on September 10, 1998 in the presence of German President Roman\n Herzog.\n \n The Bertelsmann Foundation which holds 68% of equity in Bertelsmann AG, the\n third largest media conglomerate in the world and the largest publishing\n company in the US, strives to tangibly contribute to the solution of current\n social challenges. The Foundation is based in Gutersloh, Germany.\n \n Netscape\n \n Netscape Communications Corporation is a leading provider of open software\n and services for linking people and information over enterprise networks and\n the Internet.  The company offers a full line of clients, servers,\n development tools, commercial applications and professional services to\n create a complete platform for next-generation, online applications.  Traded\n on NASDAQ under the symbol NSCP, Netscape Communications Corporation is\n based in Mountain View, California.\n \n Additional information on Netscape Communications Corporation is available\n on the Internet at http://home.netscape.com, by sending email to\n info@netscape.com, or by calling (650) 937-2555 (corporations) or (650)\n 937-3777 (individuals).\n Netscape, Netscape Navigator, Netscape Certificate Server, Netscape ONE,\n SuiteSpot and the Netscape N and Ship's Wheel logos are registered\n trademarks of Netscape Communications Corporation in the United States and\n other countries. Other Netscape logos, product names, and service names are\n also trademarks of Netscape Communications Corporation, which may be\n registered in other countries.\n #    #    #\n \n\n___________________________________________________________\n\nJoseph Reagle Jr.  W3C:     http://www.w3.org/People/Reagle/\nPolicy Analyst     Personal:  http://web.mit.edu/reagle/www/\n                   mailto:reagle@w3.org\n\n\n\n"
        },
        {
            "subject": "SafeSurf and Netscape Allianc",
            "content": "SafeSurf Press Release\nFOR IMMEDIATE RELEASE\nJune 17, 1998\nContact : Wendy Simpson-Cherry or Ray Soular\nPhone : (818) 902-9390,  (310) 572-6560 Pager \nE-mail : wendy@safesurf.com, raymond@safesurf.com\n\nNetscape and SafeSurf Team Up to Protect Children Online\n\nWESTLAKE VILLAGE, CALIF. (June 17, 1998) - SafeSurf and Netscape Communications \nCorporation (NASDAQ: NSCP) today announced NetWatch, an important new tool now \navailable within Netscape Communicator software.  The tool allows parents to \nutilize the popular SafeSurf Rating Standard within their Netscape browser to \nset content levels according to their own individual standards.\n\n\"Netscape and SafeSurf have taken a significant step toward protecting children \nand free speech on the Internet,\" said Wendy Simpson-Cherry, SafeSurf's President.\n\"NetWatch is efficient and easy to use, making Netscape the \"family-friendly\" \nbrowser of choice for millions of parents.\"\n\nParents may configure NetWatch to accept content levels in different SafeSurf \ncategories including Profanity, Nudity, Violence, Intolerance and Gambling.  \nParents also have the ability to block unrated sites.  The easy-to-use NetWatch \ninterface gives parents a \"point and click\" ability to choose Internet content \nfor their families.\n\n\"On behalf of parents everywhere, who have envisioned the day when the SafeSurf \nRating System would be available as a standard browser feature, we applaud \nNetscape for making this a reality.  Communicator now becomes the browser to \nchoose for safesurfing,\" said Ray Soular, SafeSurf's Co-founder and Developer \nof the SafeSurf Rating System.  The best part is Communicator doesn't just \nimplement this feature as an afterthought, it does it like it really cares,\" \nhe conculded.\n\n\"We hope this important step will encourage all webmasters to rate their sites \nand identify their content,\" explained Simpson-Cherry.  \"Responsible Internet \npublishing is one of the most effective ways to avoid government censorship of \nthe Internet,\" she added.\n\nSafeSurf is an international no-fee parents' organization formed to protect \nchildren on the Internet and the rights of parents through technology and \neducation.  After pioneering the Internet's first rating system, SafeSurf \nbecame a founding member and served at the heart of the technical development \nof the PICS specification, and has been instrumental in fighting government \ncensorship on the Internet. SafeSurf's web site (http://www.safesurf.com) \nprovides an easy-to-rate form which content providers may fill out to\ncreate their own custom rating for their site. SafeSurf's site also features \nfamily resources such as safety basics for children online, links to filtering \nsoftware, and the famous \"Kid's Wave\" safe list of entertaining and educational \nsites for all ages.\n\nNetscape Communications Corporation is a leading provider of open software and \nservices for linking people and information over enterprise networks and the \nInternet.  The company offers a full line of clients, servers, development tools, \ncommercial applications and professional services to create a complete platform \nfor next-generation, online applications. Traded on NASDAQ under the symbol NSCP, \nNetscape Communications Corporation is based in Mountain View, California.\n\n### \n\n\n\n"
        },
        {
            "subject": "W3C Announces Appointment of New Technology &amp; Society Domain   Leade",
            "content": "Good news! \n\n        http://www.w3.org/Press/1998/Weitzner\n\n[Sorry for duplicates, but I'm sending this to the lists which seem most\nrelevant but they share subscribers. I hope the W3C will announce further\ninformation regarding the time frame involved and other T&S staffing issues\nshortly.]\n\n___\n\n\nW3C Announces Appointment of New Technology & Society Domain Leader \nFor immediate release -- \n\nContact America -- \nSally Khudairi <khudairi@w3.org> \nDanny Weitzner <djw@cdt.org> +1 202.637.9800 x106 \n\nContact Europe -- \nNed Mitchell <ned@ala.com> +33 1 43 22 79 56 \nAndrew Lloyd <allo@ala.com> +44 127 367 5100 \n\nContact Asia -- \nYumiko Matsubara <matsubara@w3.org> \n\n\n-----------------------------------------------------------------------------\n---\n\nhttp://www.w3.org/ -- 24 June 1998 -- The World Wide Web Consortium (W3C)\ntoday announced that Daniel J. Weitzner will join the Consortium as\nTechnology & Society Domain Leader. He will be responsible for leading the\nConsortium's global public policy initiatives and for managing the\ndevelopment of technologies that address social and policy issues on the\nWeb. \n\n\"We are pleased to have Danny join as Domain Leader,\" said W3C Chairman\nJean-Fran?ois Abramatic. \"His background and leadership in the policy arena\nwill strengthen the Technology & Society Domain's role of addressing various\npolicy issues raised by the Web and developing technology tools in\ncollaboration with our Membership and the broader user communities world\nwide.\" \n\nWeitzner has been at the center of Internet policy development since 1991,\nboth in the United States and around the world. As a lawyer, coalition\norganizer, and public policy analyst with technical skills, he has regularly\nfaced the challenge of forging sound, sensible public policy solutions to\nproblems raised by the Internet. From the early-Web days (1992), he helped\ndevelop the case for the initial commercialization of the Internet in the\nUnited States. Since then, he pioneered the 'user empowerment' policy\napproach for free expression and privacy issues. In 1995, he was public\npolicy co-chair of the Platform for Internet Content Selection (PICS)\nSteering Committee. Prior to joining W3C, Weitzner was Deputy Director and\nCo-Founder of the Center for Democracy and Technology, a leading Internet\npolicy & civil liberties organization in Washington, DC. \n\n\"The Consortium is, indeed, happy to add Danny to our team,\" added\nAbramatic. \"We have worked closely with Danny and his colleagues at the\nCenter for Democracy and Technology and expect to continue to leverage CDT's\nexpertise in critical Internet free speech and privacy issues.\" \n\n\n___________________________________________________________\n\nJoseph Reagle Jr.  W3C:     http://www.w3.org/People/Reagle/\nPolicy Analyst     Personal:  http://web.mit.edu/reagle/www/\n                   mailto:reagle@w3.org\n\n\n\n"
        },
        {
            "subject": "Archive will be public beginning with this messag",
            "content": "The hypertext mail archive for pics-interest@w3.org will become\npublicly readable beginning with this message.\n\nThere are presently 136 subscribers to the mailing list, representing\nboth W3C Member organizations and non-Member organizations.\n\nThe purpose of the mailing list is for discussion of PICS-related\ntopics, including announcements.  Posting privileges are intended\nto be restricted to subscribers only.  Subscription requests may\nbe sent to pics-interest-request@w3.org.  These requests are\nprocessed manually at the present time.\n\nThank you for your interest in PICS.\n\n-Ralph R. Swick\n W3C/MIT\n for the W3C and Paul Resnick, W3C PICS Interest Group Chair.\n\n\n\n"
        },
        {
            "subject": "picsinterest&#64;w3.org mail archive locatio",
            "content": "The hypertext mail archive for pics-interest@w3.org\nis http://www.w3.org/Archives/Public/pics-interest/\n\n\n\n"
        },
        {
            "subject": "IE update on relative URLs (was RE: Relative URLs in 'for' option  of PICS labels",
            "content": "Unfortunately it does appear that the Win32 version of IE3 and IE4 requires\nan absolute URL. Below is a specific example: the first PICS label is *not*\naccepted by IE, But the second one is. \n\n(I'm assuming this is the exact issue that we're proposing - please correct\nme if not)\n\n<META HTTP-EQUIV=\"PICS-Label\" CONTENT='(PICS-1.1\n\"http://www.rsac.org/ratingsv01.html\" L GEN TRUE for \"rattest.htm\" R (N 4 S\n3 V 0 L 4))'>\n\n<META HTTP-EQUIV=\"PICS-Label\" CONTENT='(PICS-1.1\n\"http://www.rsac.org/ratingsv01.html\" L GEN TRUE for\n\"http://batcave/rattest.htm\" R (N 4 S 3 V 0 L 4))'>\n\nWe could consider changing this behavior for IE5, but unfortunately there's\nnothing I can do about IE3 and IE4.\n\n-Scott\n\n-----Original Message-----\nFrom: Ralph R. Swick [mailto:swick@w3.org]\nSent: Monday, May 04, 1998 2:54 PM\nTo: pics-interest@w3.org\nSubject: Relative URLs in 'for' option of PICS labels\n\n\nPICS 1.1 Label Distribution Label Syntax [1] currently requires all\ngeneric labels to have a 'for' option.  The current PICS 1.1\nspecification is imprecise about whether the URL in the 'for'\noption is permitted to be relative.\n\nIf absolute URLs were required then generic labels for a site that\n\n a. allows both secure http access (https:) and non-secure access (http:)\n   or\n b. has multiple network names (e.g. www.altavista.digital.com and\n    altavista.digital.com)\n\nwould need a label list that anticipates all the combinations under\nwhich a string prefix match could be needed.  If the label list is\nstored within the document (say, of the home page) then it has to\nenumerate all possibilities with identical ratings clauses.\n\nIt has been suggested to us that requiring absolute URLs in the\nfor option is too restrictive and that explicitly permitting\nrelative URLs, especially URLs that omit the scheme or network name,\nwould be useful to some rating environments.  Jim Miller asserts\nthat it was his intention that the PICS 1.1 spec as written permit\nrelative URLs.\n\nWe (W3C Staff) would therefore like to propose the following\nclarification to the PICS 1.1 Label Syntax specification:\n\n 1. clarify that the URL in 'for' and 'complete-label' can be a\n    quoted relative URL as defined by RFC 1808 where the scheme\n    may also be omitted.\n\n 2. clarify the definition of URL prefix length and URL prfix matching\n    to account for omitted scheme or network name.\n\nThe specific changes would be something like the following:\n\nGeneral Format\n\n  ... Lacking a specific label, any generic label may be substituted,\n  but preference should be given to the generic label which has the\n  longest /+URL+/ string.  /+If the generic label gives a relative URL\n  in the 'for' option, then the URL should be made absolute as defined\n  by RFC-1808 using the current document URL as the base prior to\n  calculating the string length.  That is, corresponding parts of the\n  URL of the current document should be substituted for any omitted\n  parts of the relative URL.+/\n\n2. Information about the label itself.\n\n  ...\n  for quotedURL\n\n  The URL (or prefix string of a URL) of the item to which this rating\n  applies. This option is required for generic labels and in certain\n  other cases (see \"Requesting Labels Separately,\" below); it is\n  optional in other cases. Since a single document can have many URLs,\n  the URL used to retrieve a document may differ from the URL in the\n  for option of a label that accompanies the document.\n  /+The URL may be a relative URL as specified by RFC-1808.  The\n  scheme may also be omitted.  Relative URLs are interpreted using\n  the absolute URL of the current document as the base.  The empty\n  URL (\"\") applies to the current document and to any documents in\n  the hierarchy below the current document.+/\n\n3. Other information.\n\n  ...\n  complete-label quotedURL\n  -or- full quotedURL\n\n  Dereferencing this URL returns a complete label that can be used in\n  place of the current one. The complete label has values for as many\n  attributes as possible. This is used when a short label is\n  transmitted for performance purposes but additional information is\n  also available. When the URL is dereferenced it returns an item of\n  type application/pics-labels that contains a labellist with exactly\n  one label.  /+The URL may be a relative URL as specified by\n  RFC-1808.  The scheme may also be omitted.  Relative URLs are\n  interpreted using the absolute URL of the current document as the\n  base.+/\n\nDetailed Syntax\n\n  /+\n  quotedRelativeURL :: '\"' relativeURL '\"' as defined in RFC-1808,\n       extended to permit the scheme to be omitted,\n       or quotedURL (as defined above)\n  +/\n\n  labeloption ::\n  ...\n         | 'for' quoted/+Relative+/URL\n\n  otheroption ::\n  ...\n         | 'complete-label' quoted/+Relative+/URL\n         | 'full' quoted/+Relative+/URL\n\n  data :: quoted-ISO-date | quoted/+Relative+/URL | ...\n\nSemantics of PICS Labels and Label Lists\n\n  ...\n  For example, a generic label for the URL \"http://w3.org\" /+or for\n  the URL \"/\" +/ implicitly rates every document available at that site\n  /+(at the site of the requested document)+/.\n\n[1] http://www.w3.org/TR/REC-PICS-labels\n\nYour thoughts on this change would be appreciated, especially from\nimplementors of tools that evaluate PICS labels.  If there are no\ndissenting opinions, we will propose to make this update to the\nPICS 1.1 specification as an editorial clarification.  If you\napprove of the change but feel it is more than an editorial\nclarification, please make your opinion known.\n\n-Ralph\n\n\n\n"
        },
        {
            "subject": "Re: IE update on relative URLs (was RE: Relative URLs in 'for'   option  of PICS labels",
            "content": "Thanks for the research, Scott.\n\nAt 10:47 AM 5/27/98 -0700, Scott Berkun wrote:\n>Unfortunately it does appear that the Win32 version of IE3 and IE4 requires\n>an absolute URL.\n\nI don't view this as unfortunate at all!  I view it as reinforcement that\nthe implementors believed (as do I) that the PICS 1.1 spec as written\ndoes not permit relative URLs in 'for'.\n\nSince the time I posted the original message we here at MIT have\nrefined our thinking a bit and have come to the tentative conclusion\nthat this small batch of changes should get a new version id; i.e.\nPICS-1.2.\n\nThat being the case, one of the original questions is moot -- is\nthere any consistency in behavior when an existing implementation\nencounters a label with a relative URL?  If we go to PICS-1.2 for\nrelative URL support then all existing implementations should\nignore labels that use the new feature.  (At least, all properly\nimplemented ones :-).  Practical implementation question #1 answered.\n\nThe remaining question is whether there is consensus that the\nchange is a good idea.  I'm happy to continue to discuss this on\nthe pics-interest list but if you prefer to give me private\nfeedback that is also acceptable.\n\n-Ralph\n\n\n\n"
        },
        {
            "subject": "remov",
            "content": "unsubscribe\n\n\n\n"
        },
        {
            "subject": "RSAC wins Bertelsmann Prize",
            "content": "Forwarded Text ----\n\n RECREATIONAL SOFTWARE ADVISORY COUNCIL WINS 1998 CARL BERTELSMANN PRIZE\n \n RSAC and Canadian Radiotelevision and Telecommunications Commission Share\n Prize for Outstanding Innovation and Responsibility in the Information\n Society\n \n Washington, D.C. and G?tersloh, Germany, September 10, 1998 ? The\n Recreational Software Advisory Council (RSAC), the world?s leading rating\n system for the Internet, today announced they have been awarded the esteemed\n 1998 Carl Bertelsmann Prize.  The annual prize, awarded since 1988 for\n innovative approaches to important public policy challenges, this year\n focused on \"Communications 2000 - Innovation and Responsibility in the\n Information Society.\"  RSAC was jointly awarded the prize with the Canadian\n Radiotelevision and Telecommunications Commission (CRTC) in G?tersloh,\n Germany today at a ceremony keynoted by German President Roman Herzog.  RSAC\n and CRTC will share the endowment award of 300,000 Deutchmarks\n (approximately $165,000 US Dollars).\n \n In a video-taped speech shown at the awards ceremony earlier today, United\n States Vice President, Al Gore congratulated RSAC stating, ?I am pleased to\n see so many in this industry rise to the challenge of Internet\n self-regulation ? and I am pleased that you (the Bertelsmann Foundation)\n have created an award to recognize these efforts.  Let me also express my\n pride that an American non-profit institution, the Recreational Software\n Advisory Council, is among the winners of this prestigious award.?\n \n ?In awarding the 1998 Carl Bertelsmann Prize, the Foundation sought to\n highlight viable models for regulating the media and communications markets\n in the future,? said Dr. Mark W?ssner, CEO and chairman of the board,\n Bertelsmann AG, and deputy chairman of the board of the Bertelsmann\n Foundation.  ?With the rapid expansion of the Internet around the world,\n RSAC?s innovative self-regulatory system is a model which provides a proven\n framework for the regulation of content on the Internet.  For this reason,\n we are proud to recognize RSAC as this years winner of the 1998 Carl\n Bertelsmann Prize.?\n \n \"We?re honored to receive the 1998 Carl Bertelsmann Prize,\" said Stephen\n Balkam, president of RSAC.  \"Internet content is an issue that concerns\n parents and consumers in every country with Internet capabilities. Because\n it is integrated into both of the world?s most popular browsers, RSAC for\n the Internet (RSACi) offers users a tool that will allow them to shape their\n Internet experiences to fit their own values and empowers parents to make\n informed decisions about what they and their children experience on the\n Internet.?\n \n RSAC and CRTC were chosen from more than 100 possible candidates to receive\n the prize. All candidates were closely reviewed by the management-consulting\n firm of Booz, Allen & Hamilton in three different categories of\n responsibility ? supervision of the communications and media markets,\n self-regulatory initiatives, and the promotion of media competency.  The six\n finalists for the prize included the United States Federal Communications\n Commission (FCC), the Australian Broadcasting Authority (ABA), the Education\n Network of Australia (EdNA), Bayern Online, as well as the Recreational\n Software Advisory Council (RSAC) and the Canadian Radiotelevision and\n Telecommunications Commission (CRTC).\n \n Available in both Microsoft?s Internet Explorer and Netscape Navigator,\n RSACi is a PICS-compliant (Platform for Internet Content Selection) system\n that empowers parents and consumers to make informed choices about what they\n and their children experience in cyberspace by means of an objective content\n advisory system.  The RSACi rating system is a fully automated, Web-based\n system that relies on a quick, easy-to-use questionnaire that the Web master\n completes at RSAC's home page [http://www.rsac.org].  The questionnaire runs\n through a series of highly specific questions about the level, nature and\n intensity of the sex, nudity, violence or offensive language found within\n the Web master's site.\n \n Once completed, the questionnaire is then submitted electronically to the\n RSAC Web server, which tabulates the results and produces the HTML advisory\n tags that the Web master then places on their Web site.  A standard Internet\n browser or blocking device that has been configured to read the RSACi system\n can recognize these tags, enabling parents who use the browser to either\n allow or restrict their children's access to any single rating or\n combination of ratings.\n \n RSAC\n The Recreational Software Advisory Council is an independent, non-profit\n organization based in Washington, D.C. that empowers the public, especially\n parents, to make informed decisions about what they and their children\n experience on the Internet by means of an objective content advisory system.\n RSACi is the world?s leading rating system for the Internet.  It has now\n been integrated into Netscape Navigator and Microsoft?s Internet Explorer.\n RSAC's system provides consumers with information about the level of nudity,\n sex, language, and violence in Web sites.  More information on RSAC and the\n RSACi rating system is available at http://www.rsac.org.  To date, more than\n 85,000 Web sites have rated with the RSACi system, with over 4,000 sites, on\n average, rating each month.\n \n Bertelsmann Foundation\n The Bertelsmann Foundation, which holds 68% of equity in Bertelsmann AG, the\n third largest media conglomerate in the world and the largest publishing\n company in the US, strives to tangibly contribute to the solution of current\n social challenges. The Foundation is based in Gutersloh, Germany.\n \n \n Contacts:\n Kate Castle/Pat Arcand\n Copithorne & Bellows for RSAC\n 617/450-4300 x264\n kate.castle@cbpr.com\n \n Stephen Balkam\n President\n Recreational Software Advisory Council\n Tel: +1 202 237 1833\n Fax: +1 202 237 1836\n web: www.rsac.org\n \n \nEnd Forwarded Text ----\n\n___________________________________________________________\n\nJoseph Reagle Jr.  W3C:     http://www.w3.org/People/Reagle/\nPolicy Analyst     Personal:  http://web.mit.edu/reagle/www/\n                   mailto:reagle@w3.org\n\n\n\n"
        },
        {
            "subject": "reports and papers pointer",
            "content": "Two reports possibly of interest to readers of this list:\n\n1) A report from Australia on uses of PICS for self-labeling.\n\n2) Larry Lessig and I are presenting a paper at the Telecom Policy Research\nConference that analyzes the options for governments that want to mandate\nrestrictions on access to materials. This is not primarily about PICS,\nalthough there is some role for self-labeling in one of the scenarios that\nwe consider. Still, it might be of interest to this list.\n\n-----------------1-------------------------\n\nThe La Trobe University Online Media Program is pleased to announce the\npublication of:\n\nCaroline Kruger. Censoring the Internet with PICS: An Australian stakeholder\nanalysis (Research Report No 5)\n\nThis report examines one Internet censorship regime, the Platform for\nInternet Content Selection (PICS) self-labelling scheme from a number of\nperspectives. It examines the push to have PICS adopted in Australia and\naround the world and the strengths and weaknesses of the system. Based on\ninterviews conducted in September 1997, it shows how PICS is viewed by\nrepresentatives of key Internet stakeholders.\n\nThe report can be downloaded free of charge from http://teloz.latrobe.edu.au\n\nHard copies can be purchased for AU$80-00 including postage worldwide.\n\n--------------2----------------------\n\nhttp://www.si.umich.edu/~presnick/papers/lessig98/index.html\n\nAbstract\n\nThis article proposes an abstract model of mandated access controls. It\nincludes three types of actors: senders, intermediaries\nand recipients. Control decisions are based on three types of information:\nthe item, the recipient?s jurisdiction, and the\nrecipient?s type. \n\nWith the architecture of today?s Internet, senders are ignorant of the\nrecipient?s jurisdiction and type, recipients are ignorant of\nan item?s type, and intermediaries are ignorant of both. It is easy to see,\nthen, why, with today?s Internet architecture,\ngovernments are having a hard time mandating access controls. Any party on\nwhom responsibility might be placed has\ninsufficient information to carry out that responsibility. \n\nWhile the Internet?s architecture is relatively entrenched, it is not\nabsolutely immutable. Our abstract model suggests the types\nof changes that could enhance regulability. Senders could be given more\ninformation about recipient jurisdiction and type, either\nthrough recipients providing certificates, or through a database mapping IP\naddresses to jurisdictions. Recipients could be given\nmore information about item types, either through senders providing labels\nor through government pre-clearance lists of\npermitted or prohibited items. \n\nSince the two interventions are analogous, the analyses of their costs and\neffectiveness are analogous as well. In either case,\nthere will be a natural incentive to provide information if the default\naction of the responsible party is to block access unless the\ninformation is provided (a prohibited unless permitted regime). Otherwise,\nthere will be no natural incentive, and the\ngovernment will have to require the provision of that information. \n\nThe secondary effects of these two infrastructures are also analogous, but\nquite different. The by-product of a certificate regime\nis a general ability to regulate based on jurisdiction and recipient\ncharacteristics, even for issues beyond content control, such as\ntaxation and privacy. Such a regime also enables senders voluntarily to\nexclude recipients based on jurisdiction or type, a\nfacility which might be used for negative as well as positive purposes. The\nby-product of a widely used labeling infrastructure is\na general ability to regulate based on item characteristics, even\ncharacteristics that governments have no legitimate reason to\nregulate. Such a regime also enables intermediaries and recipients\nvoluntarily to exclude some item types, a facility that may\nempower parents and teachers but may also be overused if it is poorly\nunderstood or difficult to configure. \n\nIf intermediaries are to be responsible for blocking, they will need both\ntypes of information. In addition, architectural changes\nwill be necessary to enable application layer blocking of individual items\nrather than cruder network layer blocking of all traffic\nfrom or to an IP address. A requirement of application layer blocking,\nhowever, introduces significant costs in terms of\nopenness to innovation and vulnerability to hardware and software failures.\nIntermediaries, then, are the most costly place to\nimpose responsibility. On the other hand, they are the most easily\nregulated, since there are fewer of them, they are more\nstable, have assets and their governing jurisdictions are clear. \n\nWhile our sensitivity analysis does suggest consequences that might not\nhave been readily seen, our ultimate conclusion is one\nothers have reached as well. It will be difficult for governments to\nmandate access controls for the Internet. Given today?s\narchitecture, any such mandates would of necessity be draconian or\nineffective. Changes to the technical infrastructure or social\npractices could enhance regulability, although such changes would entail\nboth direct costs and would create secondary\nby-products whose value is debatable. Given that the costs of any such\narchitectural change would be significant, it is important\nfor governments to answer the fundamental question of how important such\nchanges are: perhaps a lessening of governments?\ntraditional power to control the distribution of harmful information would\nbe preferable. \n  \n\n------------------------------------------------------------\nPaul Resnick                  presnick@umich.edu \nAssociate Professor           (fax) 734-764-2475\nThe University of Michigan    http://www.si.umich.edu/~presnick\nSchool of Information         (voice) 734-647-9458 \n314 West Hall \nAnn Arbor, MI 48109-1092\n\n\n\n"
        },
        {
            "subject": "Singapore Proposes Internet Privacy Guidelines, Content   Labelin",
            "content": "Greetings- Of possible interest.\n\nSingapore Proposes Internet Privacy Guidelines, Content Labeling\n09/21/98\n\nhttp://www.sba.gov.sg/work/sba/internet.nsf/7900cf64cb2a90724825663b001ba9e3/475\n25ba84928829a482566820011867f?OpenDocument\n\n...\n\"7 In support of greater industry self-regulation, the NIAC (NATIONAL\nINTERNET ADVISORY COMMITTEE ) recommends adopting the following three-stage\napproach:\n\nStage 1 - Labeling of Web sites\n\n8 The NIAC noted that the number of local websites has been growing\nrapidly. To help parents and consumers make informed choices about what\nthey and their\nchildren are accessing, the NIAC recommends that the local industry label\ntheir websites by adopting internationally recognised PICs (Platform for\nInternet Content\nSelection)-compliant content classification systems such as that developed\nby the Recreational Software Advisory Council (RSAC). The NIAC further\nencourages\nContent and Service Providers to actively participate in developing and\npromoting the usage of such classification systems as this would allow\nusers to determine and\ncontrol the type of Internet content they want to access.\n\nStage 2 - Industry Code of Practice\n\n9 The NIAC notes that in countries like the US, UK, Australia and Hong\nKong, the industry plays a major role in maintaining standards on the\nInternet. The NIAC\nrecommends that a task force be set up by key industry players such as the\nSingapore IT Federation and the Internet Service Providers to study the\nIndustry Codes Of\nPractice in other countries and come up with a Code for the Singapore\nindustry to implement as part of an overall industry effort to complement\nSBA's Internet Code of\nPractice.\n\nStage 3 - Industry Accreditation Body\n\n10 Finally, the NIAC recommends that the industry set up an accreditation\nbody to administer the Industry Code of Practice and labeling of web sites.\nThe industry\nshould itself determine the membership of the accreditation body and the\nmechanics of this self-regulatory mechanism. They should also take into\naccount factors such as\ndeveloping a responsive mechanism for feedback from users and the public,\neffective enforcement procedures and measures, as well as funding needs.\"\n\nJean Armour Polly, Net-mom(R) mom@netmom.com\nhttp://www.netmom.com/\nThe Internet Kids and Family Yellow Pages (Osborne McGraw-Hill)\nTHIRD EDITION COMING OCTOBER 1998\nNet-mom is a Registered Service Mark of Jean Armour Polly.\n\n\n\n"
        },
        {
            "subject": "Publically available PICS Label Bureau for RDF migration testbed",
            "content": "Hi PICS people,\n\nI'm looking at ways of wrapping a PICS bureau as an RDF service of some\nsort, but can't actually find a live PICS bureau to work with. \n\nThe list at http://www.w3.org/PICS/bureaus.htm seems a little dated\n(8/20/1996)  -- EvaluWeb times out, the PICS Incubator is offline, and the\nNetShepherd and SurfWatch sites, while glossy, don't (for presumably \nsound commercial reasons, though see 3 below) don't seem to describe\nmachine-level interfaces to their networked rating servers.\n\nSo... a few things:\n\n1. if there are live PICS bureaus out there available for testing (or\nproduction use), please could you let me know\n\n2. Are any PICS implementors interested in experimenting with a\nPICS -> XML/RDF migration testbed? \nexample issues: \"what would a PICS bureau look like in the XML/RDF\nworld\", \"do we map our rating schemes manually or automatically when\nmigrating to RDF\" etc\n\n\n3. Should the machine-description of an XML/RDF ratings service (ie.\na PICS-NG bureau) include some provision for requiring user-level\nvisibility? \nThis might encourage more services to expose publically\ntheir machine-level interfaces. For example, if I could say\nhttp://rdf.desire.org/ratings? is a ratings service that can be queried\nfor PICS/RDF labels for a given site. But also that\n\"http://rdf.desire.org/ratings?\" has a \"logoThatMustBeDisplayed\"\nproperty and a \"serviceProviderWhoseHomePageMustBeLinkedTo\" property,\nwhose semantics required that any software using that ratings service\nshould credit (as specified) the rating agency?\n(I'm trying to think of ways in which owners of ratings databases might\nbe encouraged to make those ratings more publically accessible...)\nI'd be very interested on perspective of ratings-content owners on this\nlast issue. \n\n\nThanks for any pointers,\n\n\nDan\n\n\n\n\n--\nDaniel.Brickley@bristol.ac.uk                  \nInstitute for Learning and Research Technology http://www.ilrt.bris.ac.uk/\nUniversity of Bristol,  Bristol BS8 1TN, UK.   phone:+44(0)117-9287096\n\n\n\n"
        },
        {
            "subject": "Re: Publically available PICS Label Bureau for RDF migration  testbed",
            "content": "> I'm looking at ways of wrapping a PICS bureau as an RDF service of some\n> sort, but can't actually find a live PICS bureau to work with.\n>\n> The list at http://www.w3.org/PICS/bureaus.htm seems a little dated\n> (8/20/1996)  -- EvaluWeb times out, the PICS Incubator is offline, and the\n> NetShepherd and SurfWatch sites, while glossy, don't (for presumably\n> sound commercial reasons, though see 3 below) don't seem to describe\n> machine-level interfaces to their networked rating servers.\n\nI ran into these exact same issues while developing the PICS content\nfiltering module for WebDoubler, our MacOS proxy server product.\n\n> 1. if there are live PICS bureaus out there available for testing (or\n> production use), please could you let me know\n\nThe closest thing to a production-quality, publicly-accessible PICS label\nbureau that I've found, are either evaluWEB, which has moved:\n\n (rating-service \"http://calvin.ptloma.edu/~spectre/evaluweb/\")\n (rating-system \"http://calvin.ptloma.edu/~spectre/evaluweb/pics.cgi\")\n\nor the CyberNOT PICS service:\n\n (rating-system \"http://pics.microsys.com/ratings/\")\n (rating-service \"http://pics.microsys.com/ratings/\")\n\n> (I'm trying to think of ways in which owners of ratings databases might\n> be encouraged to make those ratings more publically accessible...)\n> I'd be very interested on perspective of ratings-content owners on this\n> last issue.\n\nI think the primary issue with running a publicly-accessible PICS label\nbureau is that, quite frankly, there is no way to make money from it, since\na label bureau request is just a simple, unauthenticated HTTP request.\n\nFor example, why should Microsystems spend money advertising their PICS\nlabel bureau, and spend the money to maintain the server? It makes more\nsense for them to promote their proprietary CyberPatrol client software\n(which runs on either an end-user machine or a proxy server). Of course, the\nhope is that the client software provides some added value over the PICS\nlabel bureau alone. Not to pick on Microsystems -- all developers of\ncontent-filtering systems face the same issues.\n\n(By the way, what, if any, restrictions are there on the use of the CyberNOT\nPICS label bureau? Anyone know? There is precious little information at the\nabove URL.)\n\nThere is no reason some kind of authentication method to identify\n\"registered\" users couldn't be used in the PICS HTTP request. It would\nprobably require some kind of public/private key system (Cookies? PGP? SSL?)\n-- HTTP's \"basic\" authentication method wouldn't cut it. But whatever method\nwas agreed upon would need to be implemented in the PICS clients.\n\n=====================================================\nChris Patterson                       chris@maxum.com\nMaxum Development Corp.          http://www.maxum.com\n\n          \"Tao?\" \"Nah, I prefer to drip-dry.\"\n=====================================================\n\n\n\n"
        },
        {
            "subject": "Re: Publically available PICS Label Bureau for RDF migration  testbed",
            "content": "Chris Patterson wrote:\n> There is no reason some kind of authentication method to identify\n> \"registered\" users couldn't be used in the PICS HTTP request. It would\n> probably require some kind of public/private key system (Cookies? PGP? SSL?)\n> -- HTTP's \"basic\" authentication method wouldn't cut it. But whatever method\n> was agreed upon would need to be implemented in the PICS clients.\n\nWould digest authentication[1] cut it?\ni.e. do you really need public key stuff, or are you\njust trying to avoid passwords-in-the-clear?\n\nHmm... your mention of SSL reminds me that confidentiality\nmight be important...\n\n[1] \"HTTP Authentication: Basic and Digest Access Authentication\",\nJ. Franks, P. Hallam-Baker, J. Hostetler, P. Leach, A. Luotonen, E.\nSink, L. Stewart, S.\nLawrence, 11 Sep 1998. \nhttp://www.ics.uci.edu/pub/ietf/http/draft-ietf-http-authentication-03.txt\n\nsee also:\n\nDec 16, 1998: Jose Kahan announces client-side Digest Authentication\n        implementation in libwww - try it out! \n-- http://www.w3.org/Protocols/\n\n-- \nDan Connolly, W3C\nhttp://www.w3.org/People/Connolly/\ntel:+1-512-310-2971 (office, mobile)\nmailto:connolly.pager@w3.org (put your tel# in the Subject:)\n\n\n\n"
        },
        {
            "subject": "Re: Publically available PICS Label Bureau for RDF migration   testbed",
            "content": "> Chris Patterson wrote:\n>> There is no reason some kind of authentication method to identify\n>> \"registered\" users couldn't be used in the PICS HTTP request. It would\n>> probably require some kind of public/private key system (Cookies? PGP? SSL?)\n>> -- HTTP's \"basic\" authentication method wouldn't cut it. But whatever method\n>> was agreed upon would need to be implemented in the PICS clients.\n>\n> Would digest authentication[1] cut it?\n> i.e. do you really need public key stuff, or are you\n> just trying to avoid passwords-in-the-clear?\n>\n> Hmm... your mention of SSL reminds me that confidentiality\n> might be important...\n\nDigest authentication seems like it would do the trick, if the PICS label\nbureau used \"single-use\" nonce values to ensure that each and every hit (for\nwhich a charge could be assessed) is properly authenticated. Right?\n\n=====================================================\nChris Patterson                       chris@maxum.com\nMaxum Development Corp.          http://www.maxum.com\n\n          \"Tao?\" \"Nah, I prefer to drip-dry.\"\n=====================================================\n\n\n\n"
        },
        {
            "subject": "moving o",
            "content": "I have less and less time to devote to PICS related activities. I am now\nengaged in other research projects, on feedback and reputation systems, and\non uses of information systems in local communities to create \"social\ncapital\".\n\nIf there is anyone else who would like to step in as interest group chair,\nI suggest that you contact Danny Weitzner (djweitzner@w3.org) or Ralph\nSwick (swick@w3.org) at the World Wide Web Consortium. The main things that\nneed to be done right now are to update the PICS web site and answer\nquestions that arrive at the pics-ask mailing list. Of course, you could do\nmuch more: your imagination is the limit. \n\nEven if no one steps forward, this mailing list can continue to function\nfor occasional distribution of information related to PICS.\n\nThanks to everyone for participating in the development and evangelism of\nPICS. I certainly learned a lot from the whole process. I am proud to have\nbeen part of promoting the idea of receiver controls rather than sender\ncontrols (even if the U.S. Congress wasn't convinced), and to have\ncontributed ideas that live on not only in the PICS specifications but in\nP3P and RDF as well. Thanks for all the memories!\n\n------------------------------------------------------------\nPaul Resnick                  presnick@umich.edu \nAssociate Professor           (fax) 734-764-2475\nThe University of Michigan    http://www.si.umich.edu/~presnick\nSchool of Information         (voice) 734-647-9458 \n314 West Hall \nAnn Arbor, MI 48109-1092\n\n\n\n"
        },
        {
            "subject": "Re: moving o",
            "content": "Thank you, Paul, for all the effort you have put into the W3C\nPICS activity these four years.\n\nWe will certainly continue supporting the pics-interest mailing\nlist.  Everyone should feel free to post items of interest to\nthe PICS community here.\n\n-Ralph Swick\n W3C Metadata Activity Leader\n Technical Director, Technology and Society Domain\n\n\n\n"
        },
        {
            "subject": "Fwd: &quot;Adult&quot; ratings..",
            "content": "This seems appropriate for the <pics-interest@w3.org> mailing list, so I am\nforwarding it.  I hope someone will respond.\n\nAlan\n\n>Date: Sun, 21 Mar 1999 14:46:18 -0600\n>From: Reg <regi776@erols.com>\n>To: kotok@w3.org, quint@w3.org, chris@w3.org\n>CC: dsr@w3.org, regi@england.com\n>Subject: \"Adult\" ratings...\n>Status:   \n>\n>Hello Gentleman,\n>\n>My name is Reginald Holmes.  You don't know me or anything, I just had a\n>thought on how we could 'protect' our children and viewers who are\n>offended by 'Adut' matterials.\n>\n>I'm not sure if you are the guy to talk to about this but you might know\n>who, and let me know how to get in touch with him/her.  If you or other\n>individual are interested in this idea(1 of millions you get daily I'm\n>sure...) just let me know.  I'm not wanting anything for it accept that\n>it might help parents as their children go on to the net...\n>\n>The idea is simply add a new HTML tag:\n>\n><ADULT>\n>\n>It can have various levels of extensions such as:\n>\n>Sexual,Nudity,Language,etc...\n>\n>I hope that this might help, and have a nice day...  ;)\n\n___________________________________________________________________________\nAlan Kotok, Associate Chairman                          mailto:kotok@w3.org\nWorld Wide Web Consortium                                 http://www.w3.org\nMIT Laboratory for Computer Science,  545 Technology Square,  Room NE43-409\nCambridge, MA 02139, USA     Voice: +1-617-258-5728    Fax: +1-617-258-5999\n\n\n\n"
        },
        {
            "subject": "massimo , Your first targeted emailing is FRE",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "massimo , Your first targeted emailing is FRE",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "4/27/2002 2:27:28 P",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Totally FREE Signups!!!",
            "content": "    \n\nAbaixo est\u00e1 o resultado de seu formul\u00e1rio. Foi submetido por:\n<member-access@w3.org>www.brazilbiz.com.br,<philipd@w3.org>www.brazilbiz.com.br\n,<pics-ask@w3.org>www.brazilbiz.com.br,<pics-info-request@w3.org>www.brazilbiz.\ncom.br,<pics-interest@w3.org>www.brazilbiz.com.br,<pics-interest-request@w3.org\n>www.brazilbiz.com.br,<reagle@w3.org>www.brazilbiz.com.br,<site-comments@w3.org\n>www.brazilbiz.com.br,<site-policy@w3.org>www.brazilbiz.com.br / Saturday, Augu\nst 31, 2002 at 03:48:51\n---------------------------------------------------------------------------\n\nemail: eldone2@thenet.com\n\nrealname: eldone2@thenet.com\n\nhhje:\n\nThe best totally FREE site all the best girls for only the best price. All you\nneed is an email address. Don't miss out,  <a href=\"http://rd.yahoo.com/dir/?ht\ntp://members.lycos.co.uk/freesignup/\">Act Fast</a>\n\nTo to be removed from this list <A HREF=\"mailto:Listremover@msn.com\">Click Here\n</A>\n\n\n\n\n\n\n\n\n\nb5\n\n---------------------------------------------------------------------------\n\n\n"
        },
        {
            "subject": "?&#64;???z???????i?????L???P?I???",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Re: Totally FREE Signups!!",
            "content": "What?\n\n-----\nTu cuenta de correo gratuita Mixmail http://mixmail.ya.com\nYa.com ADSL, Router U.S. Robotics ?Gratis! http://acceso.ya.com/adsl\n\n\n\n"
        },
        {
            "subject": "Re: Totally FREE Signups!!",
            "content": "What?\n\n-----\nTu cuenta de correo gratuita Mixmail http://mixmail.ya.com\nYa.com ADSL, Router U.S. Robotics ?Gratis! http://acceso.ya.com/adsl\n\n\n\n"
        },
        {
            "subject": "Re: Totally FREE Signups!!",
            "content": " \nI am interested in your post, where can I find more info?\n\nThank?s\n\n\n\n--------------------------------------------------------\nhttp://www.muxosexo.com\n-----------------------------------------------------------------\nsexo gratis    Webmaxter    \n\n\n\n"
        },
        {
            "subject": "Brazil needs your hel",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Para Victo",
            "content": "Hola Victor, hace unos dias que no contacto contigo a ver si ves este topic.\nLa pagina que te comente le hecharas un vistazo es http://www.totalsexo.com\nMira haber y me dices algo.\n\nUn saludo.\n\n\n\n"
        },
        {
            "subject": "[splato2] masters 4 sal",
            "content": "900 masters and 3000 pics 4 sale make an offer\n\n\n\n------------------------ Yahoo! Groups Sponsor ---------------------~-->\nRent DVDs from home.\nOver 14,500 titles. Free Shipping\n& No Late Fees. Try Netflix for FREE!\nhttp://us.click.yahoo.com/BVVfoB/hP.FAA/ySSFAA/yEGslB/TM\n---------------------------------------------------------------------~->\n\nTo unsubscribe from this group, send an email to:\nsplato2-unsubscribe@yahoogroups.com\n\n \n\nYour use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n\n\n\n"
        },
        {
            "subject": "Re: [splato2] masters 4 sal",
            "content": "are you a dick wit\ni wouls end a sample to you but it seems you could not be realistic anyway\ngrow up pal\n  ----- Original Message ----- \n  From: greatpict@aol.com \n  To: splato2@yahoogroups.com \n  Sent: Tuesday, August 26, 2003 8:55 PM\n  Subject: Re: [splato2] masters 4 sale\n\n\n  Okay! You say make an offer!  How about We take it all for$1.00\n\n  Is that a good price for you!  You can deposit this money in your account and retire for the rest of your life!  \n\n  How can I make you an offer if I have no idea what the masters or photos are?  Some businessman you are!!!  \n\n  What you have is probably junk not worth anything!\n\n  Please remove our e-mail from your records and DO NOT contact us again! \n        Yahoo! Groups Sponsor \n              ADVERTISEMENT\n             \n       \n       \n\n  To unsubscribe from this group, send an email to:\n  splato2-unsubscribe@yahoogroups.com\n\n\n\n  Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service. \n\n\n\n"
        },
        {
            "subject": "Shredders from AB Technolog",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "RV: Happy Holidays",
            "content": "Email template\n           Villas El Rancho\n                  Happy Holidays to Everyone!\n\n--------------------------------------------------------------------\n\n           Somehow, not only for Christmas, But all the long year through,\nThe joy that you give to others, Is the joy that comes back to you. And the\nmore you spend in blessing, The poor and lonely and sad, The more of your\nheart's possessing, Returns to you glad.\n            John Greenleaf Whittier\n\n            Dear Friend,\n\n            As the holiday season is near, your friends at Villas el Rancho\nwould like to send our best wishes for this season and the upcoming year.\n\n\n              Discover the improved common areas\n                  The common areas of our resort have been improved. Visit\nus and enjoy the best vacation you've ever had.\n\n                  Visit our website...\n\n\n               Travel all around the world...\n                  With Villas El Rancho membership, you can go to different\nplaces like Cairo, Barcelona or Honolulu. Enjoy this great opportunity to\nexplore the world.\n\n                  Check it out now...\n\n\n\n\n            Enjoy the following mexican recipe! Vegetable Tamales\n                  Preparation and cooking time: 90 minutes\n                  Cost: Very reasonable\n                  Difficulty: Relatively easy\n\n                  Tamales consist of a preparation cooked in corn husks. In\nMexico, corn husks are frequently used as cooking containers. This simple\nprimitive method allows foods to be cooked without drying out, while\nimparting a unique flavour to them. There are many versions, in which the\nfillings may include meat, cornmeal, or vegetables, as in the version given\nhere. Try different options!\n\n                  Tips\n                  To know if the filling is the proper consistency before\ncooking it, roll out a small ball and drop it into boiling water; if it\nfloats, it's perfect - otherwise add a little butter to soften the batter.\n\n                  To check the tamales for doneness, remove one tamale and\nunwrap it; the corn husk should no longer stick to the dough inside.\n\n                  Ingredients for 6 people\n\n                  8 cobs of corn; 2 eggs; 3 tbsp. butter; 1 onion, finely\nchopped; 125 ml (1/2 cup) milk; 1 tsp. sugar; 1 tomato, peeled, seeded and\nchopped; 1 zucchini, peeled and finely diced; Salt; and freshly ground\npepper.\n\n                  Preparation\n\n                    1.. Remove the husks from the corn; keep some nice\nsupple husks from the best 4 or 6 ears; soak them in hot water to tenderize\nthem;\n                    2.. remove the kernels from the cobs using a sharp\nknife;\n                    3.. melt the butter in a skillet; add the onion and cook\nuntil it becomes translucent; add the tomato, zucchini and sugar; season and\ncook 5 minutes longer;\n                    4.. add the corn and the eggs that have been beaten\ntogether with the milk, and continue cooking over low heat for 10 minutes,\nstirring constantly;\n                    5.. spread the corn husks out on a work surface; divide\nthe filling mixture onto the middle of the husks; if the husks are too\nsmall, overlap two husks;\n                    6.. fold the two ends in towards the centre; roll the\nhusks up to form a little package; tie with kitchen string;\n                    7.. take a large pot and add in about three fingers'\nheight of water; place a rack inside, being sure that it is not sitting in\nthe water; line the rack with corn husks and place the tamales on top; cover\nwith more husks and a kitchen towel folded to fit the pot; close tightly to\nkeep all the steam inside; cook for an hour on medium heat;\n                    8.. untie the packages and pile them on a serving\nplatter.\n\n\n\n            We hope you enjoy this newsletter. Please feel free to send us\nall your comments and suggestions.\n\n            Have a great day!\n\n            Sincerely,\n\n            Villas El Rancho\n\n\n--------------------------------------------------------------------\n            e-mail: info@elrancho.com.mx\n            phone: (+52) 871-7160606\n            web: http://www.elrancho.com.mx\n\n\nThis email was sent to you, by Villas El Rancho.\n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "The Worlds Greatest Vitamin",
            "content": "The Worlds Greatest Vitamin!\n\nTry Us Today 100% Risk Free!\nVisit Our Website!\n\nhttp://www.dontforgettotakeyourvitamins.com/sexton324\n\nEducating yourself about nutrition is important to your health and well\nbeing. Please visit our website and learn the shocking truth about many of\nthe Vitamins on the market today.  \n\nWhen You Visit Our Website You Will Learn That:\n\nAbout 40% of North Americans are currently taking a multi-vitamin, but what\nthey don't realize is that they might actually be harming there body more\nthan benefiting it.\n\nDid You Know?\n\nMost vitamins on the market today use synthetic vitamins rather than whole\nvitamins straight from vegetables and fruits because synthetic vitamins are\nmuch cheaper to produce.\n\nIntroducing:\nThe Greatest Vitamin In The World!\n\nThe Greatest Vitamin In The World has all the highest grade nutrients known\nto man for every area of the entire body! Nothing like this has ever been\ncreated, until now! In developing this amazing vitamin, we considered\nnutrients needed for the body in the area of whole vitamins, minerals,\nprobiotics, enzymes, stress, body fat, anti aging, acne/skin,\narthritis/joint pain, blood sugar levels/diabetes, bones, sleep, cancer,\nheart disease/cholesterol, digestion/indigestion, stroke, immune system,\nkidney/kidneys, memory, eye sight, energy, depression, men's health, and\nwomen's health!\n\nThe Greatest Vitamin In The World nutritionally supports the body using the\nhighest grade\nWhole Food Vitamins (Not Synthetic)\nChelated Minerals (Most Absorbable) \nProbiotics (Critical For The Body's Health)\nEnzymes (Critical In Digesting Food)\nPlus many more nutrients scientifically proved to nutritionally support the\nbody!\n\nhttp://www.dontforgettotakeyourvitamins.com/sexton324\n\n\n\n\n\n\n\n\n\n\nP.S.  I am in the same SAFELIST group as you.  This is not SPAM.  Thank you\nfor considering my offer.\n\n\n\n"
        },
        {
            "subject": "Customization and Personalization through RD",
            "content": "Dear all,\n\nSome of you will have seen signs of this coming a few weeks back - here's\nthe official kick off. Recently two parallel projects were launched, one in\nYokohama by IA Japan and another in Luxembourg by us at ICRA. We expect the\ntwo projects to be merged since the goals are more or less identical -\nnamely to harness the strengths of RDF to create a truly cross-media\nplatform through which multiple classification vocabularies can be applied\nto multiple media types through a wide variety of devices.\n\nThe project is pretty wide ranging and having laid the foundation stones,\nwe're now seeking further participation and support. We plan to work closely\nwith W3C on relevant issues throughout and will use these mailing lists\nwhere appropriate. For instance, as highlighted recently, we're looking at\nthe issue of linkage - resources to descriptions, descriptions to multiple\nresources. The approach set out for P3P, which uses Policy Reference Files,\nlooks like a good place to start. We're also thinking along the lines that\nsince the object in an RDF triple can be a string literal, that string could\nbe a Regular Expression against which a suite of URIs could be matched\n(howls of protest all round, I know, but trust me, in this arena, we need\nit).\n\nYou can see a full briefing paper on the Luxembourg end of the project at\nwww.icra.org/cprdf/project_briefing.htm.\n\nPhil Archer\nInternet Content Rating Association\n\n\n\n"
        },
        {
            "subject": "reporting to you broken hyperlink",
            "content": "Dear Sirs,\n         Many links are broken at <A HREF=\"http://www.w3.org/PICS\">http://www.w3.org/PICS</A>,  here are the ones \nI am interested in, and could not reach.  \nLists of PICS-Compatible products and services links to link list, but HTTP \nServers is a dead link.\nRating Services links to PICS Third-party Rating Services but links in this \nlist are dead.\nLabel Bureaus links to a link list but Label bureau software: IBM's Server is \na dead link.\nUnder the heading, General Purpose Label Bureau Services: EvaluWeb and Surf \nWatch are dead links.\nUnder the heading, Special Purpose Label Bureau Services: Microsystem's \nSoftware is a dead link.\n\n         The Proxy Servers and NetShepherd links, among others, do work.\n\nSincerely, \nDavid Mowrey                                  \n\n\n\n"
        },
        {
            "subject": "Hello",
            "content": "I'm representing Night Shift Auto.  We are a small business which manufactures  \na braking system for the vehicle being towed behind the RV, a tow bar that goes  \nfrom the standard car mounted bracket to the RV, and a receiver height adjustment  \nadapter (drop can be used as a lift).  Our products are mainly receiver style  \nproducts.  Therefore, if you have a truck you will find our products useful.  \nIf you find that your receiver hitch is consistently lower or higher than the  \noptimum necessary to accomplish the task then our drops are for you.  We have  \nnever tested a stronger drop than our own.   \n \nIf you are asking, \"Why am I reading this?\" \n Your email address has been generated through an email search for RV related  \n people.  With us:  An individual can earn $20 for every productive referral  \n ending in the sale of a ReadyBrake or a Ready Brute.  The RVer looking for a  \n braking system, tow bar, or a drop hitch can purchase directly from us.  The  \n individual who has a vehicle with a receiver hitch could find our receiver  \n drops interesting.  The dealer looking for a solid American Made product can  \n feel secure in our, \"Compete, but don't defeat.\"  retail policy.  And, the  \n Distributor willing to expand the knowledge of his dealers will benefit where  \n it counts most....the bottom line. \n \nLinks: \nThe ReadyBrake web site, \nhttp://www.readybrake.com/ \n \nOur Tri-Fold Brochure, \nhttp://www.mfg4mfg.com/brochur1.jpg \nhttp://www.mfg4mfg.com/brochur2.jpg \n \nOur Receiver Drops (and Lifts) Flyer, \nhttp://www.mfg4mfg.com/rddrop.jpg \n  \nOur ReadyBrake Flyer, \nhttp://www.mfg4mfg.com/rddbrake.jpg \n \nOur Ready Brute Flyer, \nhttp://www.mfg4mfg.com/rddbrute.jpg \n \nOur Ready Brute Plus Flyer, \nhttp://www.mfg4mfg.com/rddplus.jpg \n \nA small picture of our ReadyBrake, \nhttp://www.mfg4mfg.com/rdbrkpic.jpg \n \n \n \n \nPlease note that the referral can only be accepted if the correct name and  \naddress of the referrer is specified at the time of purchase. \nThank you. \n \n \nI hope we can do business.  Your email is on our mailing list.  Responses,  \nwith requests for removal are honored.  This list is not  sold nor distributed.  \nYou are encouraged to send us any email address where the recipient of our offers  \ncould profit.  Again, thank you. \n \nSincerely, \n \nTyler Granger \nNight Shift Auto \nPO Box 861, 129 N. Kentucky \nIola, KS  66749 \n1-800-933-3372 \n\n\n\n"
        },
        {
            "subject": "[splato2] she is a mom we love to fuc",
            "content": "------------------------ Yahoo! Groups Sponsor ---------------------~-->\nGet A Free Psychic Reading! Your Online Answer To Life's Important Questions.\nhttp://us.click.yahoo.com/Lj3uPC/Me7FAA/ySSFAA/yEGslB/TM\n---------------------------------------------------------------------~->\n\nhttp://www.pbhome.com\n\nwe love to fuck moms like Tiffany Clark\n\n\n\nTo unsubscribe from this group, send an email to:\nsplato2-unsubscribe@yahoogroups.com\n\n \n\nYour use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n\n\n\n"
        },
        {
            "subject": "[splato2] she is a mom we love to fuc",
            "content": "------------------------ Yahoo! Groups Sponsor ---------------------~-->\nGet A Free Psychic Reading! Your Online Answer To Life's Important Questions.\nhttp://us.click.yahoo.com/Lj3uPC/Me7FAA/ySSFAA/yEGslB/TM\n---------------------------------------------------------------------~->\n\nhttp://www.pbhome.com\n\nwe love to fuck moms like Tiffany Clark\n\n\n\nTo unsubscribe from this group, send an email to:\nsplato2-unsubscribe@yahoogroups.com\n\n \n\nYour use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n\n\n\n"
        },
        {
            "subject": "(RE:) ...About ELITE's Tankless Gas Water Heater Dealership Program",
            "content": "ELITE USA   \n\"The next generation in water heater technology\"\n         Exclusive Importers  and  Distributors  of Termet S.A. EUROPE      Tankless Gas Water Heaters\n    7909 Melrose Avenue, Los Angeles, California,  90046, USA\n    Tel. (323) 653-3131  Fax.  (323) 653-7171  E-Mail  info@go4elite.com\n     See us on the internet:  www.go4elite.com\n           Manufacturer site: http://www.termet.com.pl/index-en.htm\n    Elite has recently obtains CSA certification of our three different models of Tankless Gas Water Heaters.  This means that all three meet or exceed applicable standards for safety and/or performance as administered by the American National Standards Institute (ANSI), Underwriters Laboratories (UL), Canadian Standards Association (CSA), National Sanitation Foundation International NSFI), and others, thus allowing them to pass any building inspection concerning their installation.  All three of these models will replace the tank type water heaters in the consumer's home and produce an endless supply of hot water for all their needs.  Elite's Tankless Gas Water Heaters supply over 200 gallons of hot water an hours.  Our Aqua Power model uses a Hydro-Generator to power an Electronic Sparker and fire the main burner to heat the water, instantly.  The Electronic model uses two \"D\" batteries to power the Electronic Sparker.  Elite's Therma Q model uses a standing pilot light to start the main burner.  All of Elite's Tankless Gas Water Heaters come in either Natural Gas (NG) or Propane Gas (LP) models. \nElite's Tankless Gas Water Heaters - Save Energy, Save Space, Save Money  Elites Tankless Gas Water Heaters use Fewer BTUs and thus Less Energy to supply Endless Hot water. \nThe MSRP for Elite's Tankless Gas Water Heaters range from $479 to $599.  By selling our units at these retail prices the consumer will pay a reasonable price for a superior product, and the reseller will make a substantial profit.  Depending upon which program is used to purchase these Tankless Gas Water Heaters from Elite, the reseller can realize a profit of $180 to $240 per unit sold.  \nSpecial Offer - Sign up as an Authorized Dealer and receive a free Tankless Gas Water Heater to display in your store or showroom.\nFollowing are three of the programs Elite International Company, Inc. offers to resellers to carry our fantastic line of Tankless Gas Water Heaters. \nAUTHORIZED DEALER PROGRAM: \nAn Authorized Dealer can take advantage of a quantity discount on the purchase of Elite's Tankless Gas Water Heaters in order to increase their profit when making retail sales.  Generally the Authorized Dealer must make an initial minimum purchase of 25 or more Water Heaters in order to take advantage of the Authorized Dealer's special introductory wholesale prices. \nRETAILER PROGRAM: \nThere are no minimum amounts of Elite's Tankless Gas Water Heaters required for a Retailer to purchase in order to carry our water heaters.  The reseller need only purchase one or more Water Heaters at a time to take advantage of Elite's wholesale = ices.< /STRONG > \nE-COMMERCE OR DROP SHIP PROGRAM: No investment of funds for inventory is necessary, as we will drop-ship any of Elite's Tankless Gas Water Heaters to your customer.  There are certain other restrictions to this program that the reseller will want to check out before becoming part of the program. Because each of these programs demands different amounts of time and supervision the wholesale prices we charge under each program differ.  For further information about any of these programs, and pricing,  please contact us by telephone and/or e-mail\n\nDmitriy Schwartz, Dealer Department \nELITE USA \n\n\n\n"
        },
        {
            "subject": "(RE:) ...About ELITE's Tankless Gas Water Heater Dealership Program",
            "content": "ELITE USA   \n\"The next generation in water heater technology\"\n         Exclusive Importers  and  Distributors  of Termet S.A. EUROPE      Tankless Gas Water Heaters\n    7909 Melrose Avenue, Los Angeles, California,  90046, USA\n    Tel. (323) 653-3131  Fax.  (323) 653-7171  E-Mail  info@go4elite.com\n     See us on the internet:  www.go4elite.com\n           Manufacturer site: http://www.termet.com.pl/index-en.htm\n    Elite has recently obtains CSA certification of our three different models of Tankless Gas Water Heaters.  This means that all three meet or exceed applicable standards for safety and/or performance as administered by the American National Standards Institute (ANSI), Underwriters Laboratories (UL), Canadian Standards Association (CSA), National Sanitation Foundation International NSFI), and others, thus allowing them to pass any building inspection concerning their installation.  All three of these models will replace the tank type water heaters in the consumer's home and produce an endless supply of hot water for all their needs.  Elite's Tankless Gas Water Heaters supply over 200 gallons of hot water an hours.  Our Aqua Power model uses a Hydro-Generator to power an Electronic Sparker and fire the main burner to heat the water, instantly.  The Electronic model uses two \"D\" batteries to power the Electronic Sparker.  Elite's Therma Q model uses a standing pilot light to start the main burner.  All of Elite's Tankless Gas Water Heaters come in either Natural Gas (NG) or Propane Gas (LP) models. \nElite's Tankless Gas Water Heaters - Save Energy, Save Space, Save Money  Elites Tankless Gas Water Heaters use Fewer BTUs and thus Less Energy to supply Endless Hot water. \nThe MSRP for Elite's Tankless Gas Water Heaters range from $479 to $599.  By selling our units at these retail prices the consumer will pay a reasonable price for a superior product, and the reseller will make a substantial profit.  Depending upon which program is used to purchase these Tankless Gas Water Heaters from Elite, the reseller can realize a profit of $180 to $240 per unit sold.  \nSpecial Offer - Sign up as an Authorized Dealer and receive a free Tankless Gas Water Heater to display in your store or showroom.\nFollowing are three of the programs Elite International Company, Inc. offers to resellers to carry our fantastic line of Tankless Gas Water Heaters. \nAUTHORIZED DEALER PROGRAM: \nAn Authorized Dealer can take advantage of a quantity discount on the purchase of Elite's Tankless Gas Water Heaters in order to increase their profit when making retail sales.  Generally the Authorized Dealer must make an initial minimum purchase of 25 or more Water Heaters in order to take advantage of the Authorized Dealer's special introductory wholesale prices. \nRETAILER PROGRAM: \nThere are no minimum amounts of Elite's Tankless Gas Water Heaters required for a Retailer to purchase in order to carry our water heaters.  The reseller need only purchase one or more Water Heaters at a time to take advantage of Elite's wholesale = ices.< /STRONG > \nE-COMMERCE OR DROP SHIP PROGRAM: No investment of funds for inventory is necessary, as we will drop-ship any of Elite's Tankless Gas Water Heaters to your customer.  There are certain other restrictions to this program that the reseller will want to check out before becoming part of the program. Because each of these programs demands different amounts of time and supervision the wholesale prices we charge under each program differ.  For further information about any of these programs, and pricing,  please contact us by telephone and/or e-mail\n\nDmitriy Schwartz, Dealer Department \nELITE USA \n\n\n\n"
        },
        {
            "subject": "MB TECH (OTCBB:MBTT",
            "content": "===========================================================\nAVON.com- Free Shipping and Free Gift with your $40 \npurchase! Try top-selling Cellu-Sculpt Anti-Cellulite \nSlimming Treatment for thinner thighs in just 4 weeks. Use \ncoupon code TOPCELL. Exp 7/31\nhttp://click.topica.com/caabbCdb1dpzjb485Laa/Avon\n===========================================================\n\nTHE CORPORATE SPOTLITE(OTCBB :MBTT)  MB TECH, INC. \nFloat: 3.1M Most Recent Report     Bid 1.55     Ask 1.68 \nShares Outstanding: 26.5M  Short Term: Good  \nMarket Cap: 38.4M  LONG TERM: Good Solid Fundamentals \nCurrent:  Bid 1.45     Ask 1.70  +0.13 (+8.39%) (Date of on the \nnewsletter)\n\n52 Week High 2.65    52 Week Low  1.00 \n \nMB Tech is a global manufacturer and distributor of satellite \ncomponents. The primary product MB Tech produces is \"LNB\" electronic \ndiodes, which are the essential element enabling DBS satellites to \nreceive and convert satellite transmission signals. MB Tech currently \nserves the satellite television market, and is expanding to serve the \nsatellite radio and military hardware sectors. \n\n===========================================================\nAVON.com- Free Shipping and Free Gift with your $40 \npurchase! Try top-selling Cellu-Sculpt Anti-Cellulite \nSlimming Treatment for thinner thighs in just 4 weeks. Use \ncoupon code TOPCELL. Exp 7/31\nhttp://click.topica.com/caabbCbb1dpzjb485Laf/Avon\n===========================================================\n\n==^================================================================\nThis email was sent to: pics-interest@w3.org\n\nEASY UNSUBSCRIBE click here: http://topica.com/u/?b1dpzj.b485La.cGljcy1p\nOr send an email to: thecspotlite-unsubscribe@topica.com\n\nTOPICA - Start your own email discussion group. FREE!\nhttp://www.topica.com/partner/tag02/create/index2.html\n==^================================================================\n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "VERY URGEN",
            "content": "Hello\n\nOn one note, it is important I introduce myself for your accurate\nperception of my personality and an improved understanding of the\ncircumstances.\n\nMy name is USMAN DANBABA; a Senior Advocate of Zaire and a\nprincipal partner of Williams ogowugo &  Associates (Law Firm). I have\nover 18 years experience in law practice and my professional rating is atestimonyof\nmy equals conscientiousness . My integrity is intact and I\nhave earned the respect of my equals and superiors, on the basis of my\ndecent conduct in private and business lives.\nBased on the tenets of my upbringing, I am hard working and honest. On\nanother note, we must explain that it is on compassionate grounds as well\nas the dictates of our corporate outlook as; people's lawyers(notable for equityand\nthe protection of human right), that we took-up\nthe brief to protect the family of late Gen.Mobutu Sese Seko (our former\nZairian head of state) currently being prosecuted and persecuted  by the\ncurrent administration of Joseph Kabila.\nIt common knowledge that the enemies of the late General are now in\npower and on malicious grounds my client  have lost huge financial and\nother assets to confiscations and seizures of $600 million USD (belonging\nto the family) in Liechtenstein.\nIn fact I am currently leading the team of lawyers defending Haliseko\n(the family?s only surviving son) in the on-going prosecution for\nmurder by the present Zaire government. By this and on the strength of the\nfamily?s mandate by endorsed declaration of trust. We have been involved\nin the (family?s moves to salvage their financial resources) conduiting\n$40.3 million USD for overseas investment.\nThe money successfully shipped out of this country as 4 crates\ncontaining law reports and promotional material belonging to a law firm in\nMadrid Spain(in lodgement with a finance and secuity company). The need\nfor false content declaration is to avoid betrayal in transit and incustody.\n\nBeing a neutral foreigner without any previous relationship with our\nlaw firm and our client, we will appreciate the appropriateness of your\npersonality for channelling the flow of the fund ($40.3million USD)\noverseas for high-yield investment without traces. This arrangement is\nsecure and you will agree that the need for its confidential handling\ncannot be over-emphasized.\n\nIt is important however to state that we have preserved the sanctity of\nthis project in terms of ethics and legality. Absolutely risk-free to\nyou.\n\nAbout remuneration for your assistance and cooperation, please propose (as\na percentage of the total funds in focus) for our client'sconsideration. However,it\nwill be our pleasure to be able to cooperate\nwith you on terms that you may wish to help us bring this project to\nfruition.\nI am expecting your response and please feel free to ask any question\nat once to improve your understanding.\n\n___________________________________________________\nGO.com Mail                                    \nGet Your Free, Private E-mail at http://mail.go.com\n\n\n\n"
        },
        {
            "subject": "VERY URGEN",
            "content": "Hello\n\nOn one note, it is important I introduce myself for your accurate\nperception of my personality and an improved understanding of the\ncircumstances.\n\nMy name is USMAN DANBABA; a Senior Advocate of Zaire and a\nprincipal partner of Williams ogowugo &  Associates (Law Firm). I have\nover 18 years experience in law practice and my professional rating is atestimonyof\nmy equals conscientiousness . My integrity is intact and I\nhave earned the respect of my equals and superiors, on the basis of my\ndecent conduct in private and business lives.\nBased on the tenets of my upbringing, I am hard working and honest. On\nanother note, we must explain that it is on compassionate grounds as well\nas the dictates of our corporate outlook as; people's lawyers(notable for equityand\nthe protection of human right), that we took-up\nthe brief to protect the family of late Gen.Mobutu Sese Seko (our former\nZairian head of state) currently being prosecuted and persecuted  by the\ncurrent administration of Joseph Kabila.\nIt common knowledge that the enemies of the late General are now in\npower and on malicious grounds my client  have lost huge financial and\nother assets to confiscations and seizures of $600 million USD (belonging\nto the family) in Liechtenstein.\nIn fact I am currently leading the team of lawyers defending Haliseko\n(the family?s only surviving son) in the on-going prosecution for\nmurder by the present Zaire government. By this and on the strength of the\nfamily?s mandate by endorsed declaration of trust. We have been involved\nin the (family?s moves to salvage their financial resources) conduiting\n$40.3 million USD for overseas investment.\nThe money successfully shipped out of this country as 4 crates\ncontaining law reports and promotional material belonging to a law firm in\nMadrid Spain(in lodgement with a finance and secuity company). The need\nfor false content declaration is to avoid betrayal in transit and incustody.\n\nBeing a neutral foreigner without any previous relationship with our\nlaw firm and our client, we will appreciate the appropriateness of your\npersonality for channelling the flow of the fund ($40.3million USD)\noverseas for high-yield investment without traces. This arrangement is\nsecure and you will agree that the need for its confidential handling\ncannot be over-emphasized.\n\nIt is important however to state that we have preserved the sanctity of\nthis project in terms of ethics and legality. Absolutely risk-free to\nyou.\n\nAbout remuneration for your assistance and cooperation, please propose (as\na percentage of the total funds in focus) for our client'sconsideration. However,it\nwill be our pleasure to be able to cooperate\nwith you on terms that you may wish to help us bring this project to\nfruition.\nI am expecting your response and please feel free to ask any question\nat once to improve your understanding.\n\n___________________________________________________\nGO.com Mail                                    \nGet Your Free, Private E-mail at http://mail.go.com\n\n\n\n"
        },
        {
            "subject": "reply m",
            "content": "Dear Sir,\n\nI am Princess helen, daughter of HRH King Solomon\nAbonime,the king of Ogoni Kingdom. I am 30 years old and a\ngraduate of Mass Communication. My father was the king of\nOgoni Kingdom the highest oil producing area in Nigeria. He\nwas in charge of reviving royalties from the multi-national\noil companies and government on behalf of the oil producing\ncommunities in Nigeria. After the hanging of the Ogoni\nNine(9) including Ken Saro Wiwa by the late dictator\n\nGeneral Sani Abacha, my father suffered stroke and died in\nAugust27th this year. But before his death, he called me\nand told me he has Twenty Three Million Five Hundred and\nSixty Thousand Dollars (USD23,560,000.00) cash in his\npossession, specially deposited in a Security vault company\nhere. He advised me not to tell anybody except my mother\nwho is the last wife of the (8) eight wives that he\nmarried. My mother did not bear any male child for\nhim.Which implies that all my father's properties,\ncompanies e.t.c., we have no share in them because my\nmother has no male child according to African Tradition. My\nfather therefore secretly gave me all the relevant\ndocuments of\nthe said money, and told me that I should use this money\nwith my mother and my younger sisters because he knows that\ntradtionally, if he dies we cannnot get anything, as\ninheritance. He importantly advised me that I should seek\nforeign assistannce and that I should not invest this money\nhere in Nigeria because of his other wives and male\nchildren who happen to be my elders. \n\n\n\nI am soliciting for your immediate assistance to get a\nBungalow for us, where I will live with my mother and two\nyounger sisters and further advise me where and how I will\ninvest the balance money overseas, possibly on products of\nyour company and other profitable ventures.I believe that\nby the special grace of God, you will help us move this\nmoney out of Nigeria to any country of your choice where we\ncan invest this money judiciously with you.You are entitled\nto a reasonable part of this money based\non our agreement, and God will bless you as you help us.\n\nLooking forward to hear from you as soon as possible.\n\nRegards.\n\nPrincess helen\n \n==\nDownload ringtones, logos and picture messages at Ananzi Mobile Fun.\nhttp://www.ananzi.co.za/cgi-bin/goto.pl?mobile\n\n\n\n"
        },
        {
            "subject": "Look and Unlock your door with a push of button",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "IPsmarx Technologies Inc. Canad",
            "content": "IPsmarx Turnkey Calling Card Solution including VOIP Billing Software, Hardware, Installation and Carrier services:\n\nCompatible with Cisco and Quintum hardware. Calling Card platform offers Prepaid-Postpaid software including RADIUS/AAA, TFTP, IVR at a reasonable price. Our billing software for Calling Card platform runs on Windows 2000 and on MS- SQL2000. \n\nOffering Basic and also Advanced features like Web access for caller or Agent, Caller ID/PIN-less, Home Services, etc.\n\nFor more information about our Calling Card, Termination or Callshop Solutions email us to   peter@ipsmarx.com or call us at 416-665-6999. \n\nNovember Promotion: FREE installation plus two extra features (Web-access, PIN-less, Home Services, etc)\n\nWebsite: www.ipsmarx.com\n\n\nIf this email has reached you in error please let me know and it will not happen again.\n\n\n\n"
        },
        {
            "subject": "STRICTLY CONFIDENTIA",
            "content": "FROM: DR BABA TUNDE\n\n No. 300 BOL AHMED WAY\nLAGOS-NIGERIA.\n\nSTRICTLY CONFIDENTIAL\n\nI am the Chief Medical Doctor and close confidant of Mrs. Maryam\nAbacha, the former first lady and wife of the late Gen.Sani\nAbacha, the former head of state and commander in chief of the\narmed forces of the Federal Republic of Nigeria. She (MRS.\nM.ABACHA), has as a result of the trust and confidence,she has\nin me mandated that I search for a reliable and trust worthy\nforeign partner, who will help receive some funds which she had\nin cash totaling US$80M (Eighty Million United States Dollars\nonly) into a personal, company or any reliable foreign bank\naccounts within or outside your country as all their personal\nand family Bank accounts within and outside Nigeria have all\nbeen frozen by the Nigerian authorities.\n\nFor further information about this money and the ABACHAS) go to\nhttp://www.econdad.org/AbachaLoot.htm\n\nThis money in question has however, been Deposited with a\nsecurity company that has branches in Africa, Europe and various\nparts of America. It may also interest you to note that she\n(MRS. ABACHA) and her family have, since the inception of the\npresent democratic government, been placed under partial house\narrest, with their international travelling passports seized\npending when the current fund recovery face off between them and\nthe present (RTD) GEN, OBASANJO led Democratic Government is\nresolved, in which from all indication will not exceed this\nyear. She has decided to offer anybody who will be willing to\nrender this tremendous assistance, 40% of the total sum. Note\nthat this transaction involves no risks whatsoever, as you will\nhave no dealing with my country, Nigeria. Rather you will deal\ndirectly with the Security Company, which is based where the\nmoney is right now.\n\nLet me have your confidential Tel/Fax numbers in your response\nto this proposal. I shall let you into a complete detailed\npicture of this mutual beneficial transaction when I have\nreceived your anticipated positive reply.\n\nReply to this e-mail address: official@mail2world.com.\n\nThis matter should be treated as urgent and confidential.\n\nRegards,\n\nDR BABA TUNDE\n\n\n_____________________________________________________________\nGet your free email @ barodaview.com\n------------------------------------\n    A Live Website On Barodacity\n------------------------------------\n\n\n\n"
        },
        {
            "subject": "Test (Please ignore",
            "content": "// Only a test message for subscription confirmation.\n\n\n-- \nJens Meiert\nInterface Architect\n\nhttp://meiert.com\n\n\n\n"
        },
        {
            "subject": "re:?&#64;???????z???^?",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "re:?&#64;???????z???^?",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "WARNING: Potential virus sent by you",
            "content": "The IVIS Group Virus Control Centre discovered a possible\nvirus in an email sent by you to francesco.iannuzzelli@ivisgroup.com\n\n\nThis message has now been deleted.\n\nPlease read this whole email carefully. It explains what has\nhappened to your email, which suspected virus has been caught,\nand what to do in order to clean your computer.\n\n-----------------------------------------------------------------\nSome details about the infected message\n------------------------------------------------------------------\n\nTo help identify the email:\n\nThe message sender was:\npics-interest@w3.org\n\n(if this is not your email address, the message sender possibly\nbelongs to a mailing list to which you both subscribe.)\n\nThe subject of the message was: I love you!\n\nThe message date was: Wed, 7 Apr 2004 09:20:52 +0200\n\nThe message identifier was: T68d07cc51da9fd0004378\n\nThe message recipient(s) was/were:\nfrancesco.iannuzzelli@ivisgroup.com\n\n\nTo help identify the virus:\n\nThe Virus Scanner reported the following:\n\nScenarios/Incoming/Detect incoming virus - SAV: A virus has been detected: 'W32/Netsky-P'.\nScenarios/Incoming/Block incoming executable: 'ItemLength.GE.0'.\n\n\n\n\nThe message was deleted.\n\n\n------------------------------------------------------------\nWhat should you do now?\n------------------------------------------------------------\n\nIf you sent the email from a corporate network, you should first\ncontact your local Helpdesk or System Administrator for advice.\nThey will be able to help you clean your workstation.\n\nIf you sent the email from a personal or home account, you will\nneed to disinfect your computer yourself. To do this you will\nneed an anti-virus program. We suggest using one of the leading\nindustry anti-virus packages such as McAfee or Norton.\n\n\n\n"
        },
        {
            "subject": "Letter from masinka, A.,your response is needed urgent",
            "content": "FROM: \nMR.MASINKA AMEH\nGRAND BANK OF BENIN \nPHONE:871-76-2535865 \nFAX:  871-76-2535866 \nmasinka_ameh01@sify.com\n\nDear Sir, \n\nIn order to transfer out (USD 45 MILLION) Forty Five million United States Dollars) from  GRAND BANK REPUBLIC OF BENIN. I have the courage to ask for your assistance to handle this important and confidential business believing that you will never let me down either now or in future. \nI am MR.MASINKA AMEH, the MANAGER of the bank. There is an account opened in this bank in 1980 and since 1990 nobody has operated on this account again. After going through some old files in the records, I discovered that if I do not remit this money out urgently it will be forfeited for nothing. The owner of this account is Mr. PAULTON ALLENS, a foreigner, and an engineer with  D&D Engineering CO, and he died since 1990. No other person knows about this account or any thing concerning it, the account has no other beneficiary and my investigation proved to me as well that this company does not know anything about this account and the amount involved is (USD 45M)  I want to transfer the [USD45M] Forty Five million United States Dollars into a safe foreigners account abroad , but I don't know any foreigner, I am only contacting you as a foreigner because this money can not be approved to a local bank here, but can only be approved to any foreign account because the money is in us dollars and the former owner of the account is Mr PAULTON ALLENS is a foreigner too. I know that this message will come to you as a surprise as we don't know our selves before,but be sure that it is real and a genuine business. I only got your contact address through the internet,hoping that you will never let me down in this business. I need your urgent reply  so that I will inform you on the next step to take I will like you to Send also your private telephone and fax number including the full details of the account to be used for the deposit.I want us to meet face to face or sign a binding agreement to bind us together so that you can receive this money into a foreign account or any account of your choice where the fund will be safe. I will fly to your country for withdrawal & sharing and other investments. I am contacting you because of the need to involve a foreigner with foreign account and foreign beneficiary. I need your full co-operation to make this work fine because the management is ready to approve this payment to any foreigner who has correct information of this account, which I will give to you later immediately, if you are able and with capability to handle such amount in strict confidence and trust according to my instructions and advice for our mutual benefit because this opportunity will never come again in my life. I need truthful person in this business because I don't want to make mistake I need your strong assurance and trust. With my position now in the office I can transfer this money to any foreigner's reliable account, which you can provide with assurance that this money will be intact pending my physical arrival in your country for sharing. I will destroy all documents of transaction immediately we receive this money leaving no trace to any place. You can also come to discuss with me face to face after which I will make this remittance in your resence and two of us will fly to your country so at least two days ahead of the money going into the ccount. I will apply for annual leave to get visa immediately I hear from you that you are ready to act and receive this fund in your account. I will use my position and influence to effect legal approvals and onward transfer of this money to your account with appropriate clearance forms of the ministries and foreign exchange departments. At the conclusion of this business, you will be given 35% of the total amount, 60% will be for me, while 5% will be for expenses both parties might have incurred during the process of transferring. I look forward to your earliest reply. \n\nTHANKS AND GOD BLESS, \nYOURS SINCERELY,          \nMR.MASINKA AMEH.\n\n\n\n"
        },
        {
            "subject": "&lt; reagle  , Why Not ",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Mail Delivery Syste",
            "content": "The message contains Unicode characters and has been sent as a binary attachment.\n\n\n\n\n\n\napplication/octet-stream attachment: text.zip\n\n\n\n\n"
        },
        {
            "subject": "911 Probe: Public Signatures Sough",
            "content": "FOR IMMEDIATE RELEASE\n\nContact:\nEric A. Smith\nHot Damn! Design\n81-03-3959-5371\nsnowdog@juno.ocn.ne.jp\n\n\n\n9-11 Widow Files rico Lawsuit \n\npublic signatures sought to support Investigation\n\nPHILADELPHIA, Jan 6 -- Ellen Mariani, whose husband died in the September 11, 2001 terrorist attacks when UAL 175 was flown into the World Trade Center, has filed suit in a US District Court alleging Bush, Cheney, Ashcroft, Rumsfeld and other co-defendents had sufficient warning to stop the terrorist attacks but failed to either warn or protect the public. \n\n\n \n\nAccording to a recent CBS News, the Republican 9-11 Commission Chairman agrees:\n\n \n\n9/11 Chair: Attack Was Preventable\n\n(CBS News -- December 18, 2003) For the first time, the chairman of the independent commission investigating the Sept. 11 \n\nattacks is saying publicly that 9/11 could have and should have been prevented, reports CBS News Correspondent Randall \n\nPinkston....\n\n \n\nAppointed by the Bush administration, Kean, a former Republican governor of New Jersey, is now pointing fingers inside the \n\nadministration and laying blame. \n\n \n\nhttp://www.cbsnews.com/stories/2003/12/17/eveningnews/main589137.shtml\n\n  \n\nMariani's suit also charges the Bush Administration with burying evidence of its failure and refusing to release vital information.\n\n\n\nPhiladelphia Attorney Philip J. Berg, who filed the suit on Mariani's behalf, says the Administration must be held accountable. Berg launched the suit on November 26, and has since put up a website explaining the details of Mariani vs Bush, et al. The Bush Administration is currently trying to have the charges dismissed in court.\n\n \n\nPublic support is critical, says Berg, who has posted an online petition.  \"We need at least a million signatures for them to take it seriously.\" He added that mounting a class action is also being considered. Concerned citizens are urged to read and sign the petition here:\n\nhttp://www.911forthetruth.com\n\n\n\n###\n\n \n\nRelated stories:\n\n1. NY Times: Bush Warned bin Laden Would Hijack Planes\n\"The White House said tonight that President Bush had been warned by American intelligence agencies in early August that Osama bin Laden was seeking to hijack aircraft...\"\nhttp://www.nytimes.com/2002/05/16/politics/16INQU.html\n\n\n2. CNN: Bush briefed on hijacking threat before 9-11\n\"President Bush's daily intelligence briefings in the weeks leading up to the September 11 terror attacks included a warning of the possibility that Osama bin Laden's al Qaeda network would attempt to hijack a U.S.-based airliner, senior administration officials said Wednesday\" http://www.cnn.com/2002/US/05/15/bush.sept.11/index.html\n\n3. UK Guardian: Bush knew terrorists would hijack planes\n\"George Bush received specific warnings in the weeks before 11 September that an attack inside the United States was being planned by Osama bin Laden's al-Qaeda network, US government sources said yesterday???. The memo received by Bush on 6 August contained unconfirmed information passed on by British intelligence in 1998 revealing that al-Qaeda operatives had discussed hijacking a plane to negotiate the release of Sheikh Omar Abdel Rahman, the Muslim cleric imprisoned in America for his part in a plot to blow up the World Trade Centre in 1993.\" http://www.guardian.co.uk/september11/story/0,11209,718312,00.html\n\n4. Sunday Herald: Britain warned Bush to expect 9-11 al-Qaeda hijackings\n\"Britain gave President Bush a categorical warning to expect multiple airline hijackings by the al-Qaeda network a month before the September 11 attacks which killed nearly 3000 people and triggered the international war against terrorism.\"  http://www.sundayherald.com/24822\n\n5. Village Voice: Officials Warned of Plans to Attack DC, NY with Planes\n\"The U.S. government had received repeated warnings of impending attacks???and attacks using planes directed at New York and Washington???for several years. The government never told us about what it knew was coming.\"  http://www.villagevoice.com/issues/0332/mondo4.php\n\n\n6. AP: 9/11 report, Rice conflict; Bush got specific data on threats\n\"...the briefing given to the president a month before the suicide hijackings included recent intelligence that al-Qaida was planning to send operatives to the United States to carry out an attack using high explosives.\"  http://www.sunspot.net/business/nationworld/bal-te.rice29jul29,0,2620591.story?coll=bal-business-headlines\n\n7. MSNBC: White House Briefed on Imminent bin Laden Attack\n\"One such CIA briefing, in July 2001, was particularly chilling and prophetic. It predicted that Osama bin Laden was about to launch a terrorist strike 'in the coming weeks,' the congressional investigators found. The intelligence briefing went on to say: 'The attack will be spectacular and designed to inflict mass casualties against U.S. facilities or interests. Attack preparations have been made. Attack will occur with little or no warning.'\"  http://msnbc.msn.com/id/3067907/\n\n8. MSN: Condoleezza Rice's False Statement \nA: \"The overwhelming bulk of the evidence was that this was an attack that was likely to take place overseas.\"\n- White House National Security Adviser Condoleezza Rice, in a May 16 news briefing.\n\nB: \"Bin Laden Determined to Strike in U.S.\"\n- Title of the CIA's Aug. 6 briefing memo to President Bush . . . http://slate.msn.com/?id=2066154\n\n9. Newsweek: Day before 9-11, Pentagon Generals Cancelled Flights \n\"On Sept. 10, NEWSWEEK has learned, a group of top Pentagon officials suddenly canceled travel plans for the next morning, apparently because of security concerns.\"\nhttp://www.msnbc.com/news/629606.asp (link dead)\n\n10. SF Gate: Mayor got 8-hour warning Before 9-11 Attacks ??? September 12, 2001\nFor Mayor Willie Brown, the first signs that something was amiss came late Monday when he got a call from what he described as his airport security - - a full eight hours before yesterday's string of terrorist attacks -- advising him that Americans should be cautious about their air travel. http://www.sfgate.com/cgi-bin/article.cgi?file=/chronicle/archive/2001/09/12/MN229389.DTL\n\n\n11. Florida State: Jeb Bush Declares Martial Law 9-7-01\n\"Based on the potential massive damage to life and property that may result from an act of terrorism at a Florida port, the necessity to protect life and property from such acts of terrorism...\" http://www.state.fl.us/eog_new/eog/orders/2001/september/eo2001-261-09-07-01.html\n\n12. CBS News: Ashcroft Avoided Commercial Travel Prior to 9-11\n\"In response to inquiries from CBS News over why Ashcroft was traveling exclusively by leased jet aircraft instead of commercial airlines, the Justice Department cited what it called a \"threat assessment\" by the FBI, and said Ashcroft has been advised to travel only by private jet for the remainder of his term.\"\nhttp://www.cbsnews.com/stories/2001/07/26/national/printable303601.shtml\n\n13. UK Independent: Taliban Mole Warning Ignored\n\"Weeks before the terrorist attacks on 11 September, the United States and the United Nations ignored warnings from a secret Taliban emissary that Osama bin Laden was planning a huge attack on American soil.\"  http://news.independent.co.uk/world/politics/story.jsp?story=331115\n\n14. NY Times: \"President Mubarek Warned US of Al Qaeda Plot??? \n\"Egyptian intelligence warned American officials about a week before Sept. 11 that Osama bin Laden's network was in the advance stages of executing a significant operation against an American target, President Hosni Mubarak said in an interview on Sunday.\"\nhttp://query.nytimes.com/gst/abstract.html?res=F30D16F73B5E0C778CDDAF0894DA404482\n\n15. Village Voice: US Ignored France Warnings\n\"A key point in unraveling why the FBI failed to follow up leads on Al Qaeda terrorism now centers on the Bureau's contemptuously brushing aside warnings from French intelligence a few days before 9-11.\"  http://www.villagevoice.com/issues/0222/ridgeway2.php\n\n16. Intl. Herald Tribune: White House Ignored Arab Warnings\n\"When the hubbub about what the White House did or didn't know before Sept. 11 dies down, Congressional or other investigators should consider the specific warnings that friendly Arab intelligence services sent to Washington in the summer of 2001.\"  http://www.iht.com/articles/58269.html\n\n17. UK News-Telegraph: Israel issued urgent warning of large-scale terror attacks\nIsraeli intelligence officials say that they warned their counterparts in the United States last month that large-scale terrorist attacks on highly visible targets on the American mainland were imminent.\"\nhttp://news.telegraph.co.uk/news/main.jhtml;$sessionid$52PMOXQAADW5PQFIQMGSFFOAVCBQWIV0?xml=/news/2001/09/16/wcia16.xml&sSheet=/news/2001/09/16/ixhome\n\n18. NY Post: FBI Warned D.C. It Was A Target \n\"A Minnesota FBI agent investigating Zacarias Moussaoui testified yesterday that he notified the Secret Service weeks before Sept. 11 that a terror team might hijack a plane and 'hit the nation's capital.'\"   http://www.nypost.com/news/nationalnews/57848.htm \n\n20. Yahoo News: FBI Warnings Ignored\n\"An FBI supervisor, sounding a prophetic pre-Sept. 11 alarm, warned FBI headquarters that student pilot Zacarias Moussaoui was so dangerous he might 'take control of a plane and fly it into the World Trade Center,' a congressional investigator said in a report Tuesday.\"\nhttp://story.news.yahoo.com/news?tmpl=story2&cid=512&ncid=716&e=4&u=/ap/20020924/ap_on_go_co/attacks_intelligence \n\n21. Independent: America had 12 warnings of aircraft attack \n\"American intelligence received many more clues before the 11 September attacks than previously disclosed, that terrorists might hijack planes and turn them into weapons, a joint congressional committee was told yesterday.\"   http://news.independent.co.uk/world/americas/story.jsp?story=334633 \n\n22. Washington Post: 9/11 Probe Says Agencies Failed to Heed Attack Signs \n\"U.S. intelligence agencies received many more indications than previously disclosed that Osama bin Laden's terrorist network was planning imminent \"spectacular\" attacks in the summer of 2001 aimed at inflicting mass casualties.\"  http://www.washingtonpost.com/wp-dyn/articles/A36754-2002Sep18.html\n\n23. Yahoo News: Spy Agencies Had Pre-9/11 Threats on U.S. Soil \n\"U.S. intelligence agencies picked up threats of attacks inside the United States and of using airplanes as weapons during the spring and summer before last year's Sept. 11 attacks, but were more focused on the possibility of an assault overseas, a congressional source said on Tuesday.\"\nhttp://story.news.yahoo.com/news?tmpl=story2&cid=578&ncid=578&e=1&u=/nm/20020917/ts_nm/attack_congress_intelligence_dc \n\n24. Vanity Fair: Bin Laden Relatives Secretly Evacuated From NY \n\"Patrick Tyler of the New York Times is reporting from Washington: 'In the first days after the attacks on Sept. 11, the Saudi Arabian ambasador to Washington, Prince Bandar ibn Sultan, supervised the urgent evacuation of 24 members of Osama bin Laden's extended family from the United States fearing they might be subjected to violence.'\"\nhttp://www.guerrillanews.com/cgi-bin/wwwthreads/showflat.pl?Cat=&Board=gnn&Number=204363&page=1&view=collapsed&sb=5&o=0&part=all\n\n25. Sydney Morning Herald: Administration Told US agents ???Back off bin Ladens??? \n\"US special agents were told to back off the bin Laden family and the Saudi royals soon after George Bush became president, although that has all changed since September 11, it was reported today.\"   http://www.old.smh.com.au/news/0111/07/world/world100.html \n\n26. Ha'aretz Daily: CEO Says Workers Warned Hours Before World Trade Center Hit -- FBI Investigating \n\"Odigo, the instant messaging service, says that two of its workers received messages two hours before the Twin Towers attack on September 11 predicting the attack would happen, and the company has been cooperating with Israeli and American law enforcement, including the FBI, in trying to find the original sender of the message predicting the attack.\"  http://www.haaretzdaily.com/hasen/pages/ShArt.jhtml?itemNo=77744\n\n27. NY Times: White House Approved Secret Evacuation of Bin Ladens After 9-11\n\"Richard Clarke, who ran White House crisis team after Sept 11 terror attacks, says top White House officials personally approved evacuation of dozens of influential Saudis, including relatives of Osama bin Laden, from United States in days after Sept 11, when most flights were grounded.\" http://www.truthout.org/docs_03/090503A.shtml\n\n28. Tampa Tribune: Bodyguards tell of Secret Bin Laden Flight \n\"The hastily arranged flight out of Raytheon Airport Services, a private hangar on the outskirts of Tampa International Airport, was anything but ordinary. It lifted off the tarmac at a time when every private plane in the nation was grounded due to safety concerns after the Sept. 11 attacks. \"\nhttp://www.dirtybush.com/connectthesedots.html\n\n \n29. UK Minister: \"Bush had Foreknowledge of 9-11 attacks\" \n\"...it is not surprising that some have seen the US failure to avert the 9/11 attacks as creating an invaluable pretext for attacking Afghanistan in a war that had clearly already been well planned in advance.\"   http://www.guardian.co.uk/september11/story/0,11209,1036588,00.html\nContact: Eric A. Smith, Hot Damn! Design, Tokyo, Japan ??? 81-03-3959-5371\n\n# # #\n\n\n\n"
        },
        {
            "subject": "Thoughts on the coming 'discovery' of Bin Laden: the best propaganda a campaign can bu",
            "content": "FOR IMMEDIATE RELEASE\nContact:\nEric A. Smith\nHot Damn! Design\n81-03-3959-5371\nsnowdog@juno.ocn.ne.jp\n\nOPINION: THOUGHTS ON THE COMING \"DISCOVERY\" OF BIN LADEN \n--The Best Propaganda Money can Buy\n\nUnless preparations are made for its eventuality, the announcement of Bin Laden's capture will be the death-knell for the 2004 Democratic campaign. And, like the \"heroic rescue\" of Jessica Lynch or the toppling of Hussein's statue by \"jubilant throngs\" of Iraqis, it needn't even be real:\n\nhttp://news.bbc.co.uk/1/hi/programmes/correspondent/3028585.stm\nhttp://www.latimes.com/news/printedition/opinion/la-oe-scheer20may20,1,2187120.column\nhttp://www.startribune.com/stories/1762/3907255.html\n\nhttp://www.informationclearinghouse.info/article2838.htm\n \nSo Democrats must have a pre-emptive strategy in place; the most obvious being, early in the game, to accuse the White House of sitting on Bin Laden for political gain. \n\nA better one is to launch an independent investigation to find Bin Laden first and announce the discovery before Rove's political operatives; this would be a huge coup.\n\nIn case you haven't been paying attention, this election year, Republicans are playing a deadly game of attrition -- death by a thousand tiny cuts, so to speak: extreme gerrymandering in Texas, the recall of a governor in California, the installation of inauditable, easily \"preprogrammed\" DRE e-vote machines in as many counties as will allow them to be stuffed down their throats, relentless and bloody character assassinations in a bought-and-paid-for Murdoch-dominated media empire, absentee ballots counted by an untouchable firm in Kuwait, stacked courts ready to deliver decisions for which 2000's Gore vs. Bush set the precedent.\n\nThe odds look dire for Democrats (and, by extension, the majority of Americans, though they are as yet blissfully unaware of the slender thread from which all our liberties hang). \n\nBut, in case you haven't connected the dots, this time the GOP is playing for keeps. \n\nOnce the fix is in, there will be no turning back: by an invisible, carefully planned coup, the neoconservatives will have transformed America into an autocracy, and any remaining political opposition will be window dressing.\n\nAnd so, I challenge you: this is a battle we perhaps cannot win, but, at all costs, MUST NOT LOSE.\n\nThe consequences of surrender will be incalculable: one by one, like dominos, institutions we cherish will fall -- environmental laws, social security, independent media, healthy advocacy groups, assistance for the unemployed, impoverished and disenfranchised  -- and, foremost, the right to choose our leaders.\n\nWe will be left with one remaining liberty: the right to choose which products to buy to keep the militaristic money machine well-oiled, and its minders well-heeled.\n\nThis year, unless YOU act -- BOLDLY, DECISIVELY, PERSISTENTLY AND INCESSANTLY -- the dream our forefathers nurtured to life will die.\n\nDon't let the dream die.\n\nStand up and fight for America.\n\nStand up and fight for the vote.\n\nThis will be your last chance.\n\nsincerely,\nEric A. Smith\nTokyo\n\nAbout the author:\n\nEric A. Smith is a freelance journalist, editor and IT instructor living in Tokyo, Japan. An activist for over 25 years, he has worked with such diverse publications as the RTP Beacon, Common Ground and Adbusters magazine. \n\nSmith is currently volunteering to assist Bev Harris of Blackboxvoting.org, Attorney Philip Berg in 9-11 widow Ellen Mariani's RICO suit against Bush, et al, and is a charter member of the Open Voting Consortium.\n\nSmith earned his BA at the University of North Carolina in 1992, and holds MCP, field service technician, A+ and Network+ certifications from Microsoft, COMPTIA and the Control Data Institute.\n\nHe can be reached for comment at 81-03-3959-5371 or snowdog@juno.ocn.ne.jp\n\n\n\n"
        },
        {
            "subject": "Please Join My Superb Yahoo Forums",
            "content": "Greetings,\n\nI'm posting you to ask that you take the time to join two of the GREATEST FORUMS IN THE HISTORY OF CYBERSPACE!!\n\nThe first list is an information and discussion list called \"\n\nhttp://groups.yahoo.com/group/TheBigPicture2003/?yguid=132698554 \" We are a\n\nlittle over 2,790 strong now and growing rapidly daily.\n\nOur focus there is discussing the GREAT issues in life that confuse and perplex most human beings. We give them answers on how to see the BIG PICTURE in life and live a much more richer and fulfilling life style.\n\nWe are looking for things that we can do to make sure that our mental\nhealth and self esteem remains high while we struggle to clear the cobwebs and misprogramming from our minds. and change this most unequitable system. We also promote networking between honest, ethical, law abiding business people.\n\nThe second list you should peruse is named :\n\"http://groups.yahoo.com/group/NBCOCEPPLSI/ \"\n\nPlease pass the word around about these highly informative lists. Everyone is\nwelcome to join.\n\nThank you very much for taking the time to look over this information. I\nlook forward to getting to know you on the above lists.\n \nBe careful! Strive to be happy. Despite all of the sham, trickery, lies, drudgery, and broken dreams, America is still a beautiful place to live!\n\nShlala Gashle!\n\nWS\n\nAS SEEN ON TV!\n\nLegal Coverage is a force... mightier than gravity!\n\nInnovative services for individuals, families, and businesses\n\nBuild for the future!  Securely protected by us!\n\nGet access to top LAWFIRMS across North America for less than a cup of coffee per day!\n\nhttp://www.wtatours.com\n\nThe National black Chamber of Commerce said on November 24, 2003 that ths information available at \n this website directly below is the best way for young African Americans\nto get off to a great LEGAL, start financially at a YOUNG age.\nThey said that PPLSI is the #1 best inexpensive Biz Op today in America for African Americans.\nJOBS pay your bills! Running your own business will make you rich! Need I say more...? :-)\n\nhttp://www.wtatours.net\n\n-------------------------------------------------------------------------------------------------------------------------\nwww.wtatours.org\nwww.babyboomerboogie.com\n\nCheck  out  companies at this URL to make sure they are legitimate:\nwww.ftc.gov\nwww.betterbusinessbureau.com\n\n\n\n"
        },
        {
            "subject": "Your Ship Has Come In! This Time You Are Not At The Airport",
            "content": "I'm posting you to ask that you take the time to join two of the GREATEST FORUMS IN THE HISTORY OF CYBERSPACE!!\n\nThe first list is an information and discussion list called \"\n\nhttp://groups.com/TheBigPicture2003/?yguid=132698554 \" \n\nWe are a  little over 2,800 strong now and growing rapidly.\n\nOur focus there is discussing the GREAT issues in life that confuse and perplex most human beings. We give them answers on how to see the BIG PICTURE in life and live a much more richer and fulfilling life style; both FINANCIALLY AND SPIRITUALLY.\n\nWe are looking for things that we can do to make sure that your mental\nhealth and self esteem remain high while you struggle to clear the cobwebs and misprogramming from your minds. \nWe  promote networking between honest, ethical, law abiding business people.\n\nThe second list you should peruse is named :\n\"http://groups.com/NBCOCEPPLSI/ \"\n\n\nBe careful! Strive to be happy. Despite all of the sham, trickery, lies, drudgery, and broken dreams, America is still a beautiful place to live!\n\n\n\n\nSupport Our Troops\nGOD BLESS AMERICA!! \n\n\nHonor our troops both here and abroad. Thank YOU! for keeping us all safe?\n\n\n\n\nPhone Solution!\n\n\n\nGet More From The Broadband You?re Already Paying For. . .\n\nIs Your Telephone Bill Out of Hand?\n\nAre you tired of sitting through confusing monthly billing\n\nstatements from various service providers that include\n\nlots of little charges for this feature, that call,\n\netc.? Can you call your friends and family for free and\n\ntalk as long as you like? for just $19.95 per month?\n\nCan You Choose the Calling Features That You Want?\n\nCan you change, add or delete features on your current\n\nphone service with the click of a mouse? Can you select\n\nyour own area code to better suit your calling patterns?\n\nCan you take your home phone with you wherever\n\nyou go?\n\nI s It Time to Take Charge of Your Phone Service?\n\nCan you add additional phone lines quickly and easily\n\nas you need them, without having to waste time on service\n\ncalls? Can you rely on one service provider to address\n\nall of your telephone needs?\n\n8 - Maximize Your Broadband\n\nPacket8 uses your existing broadband Internet connection\n\ncombined with our unique communications technologies\n\nto provide a new and exciting telephone service.\n\nExpand your broadband connection to be more\n\nthan just Internet access. With Packet8 your computer,\n\ntelephone and high-speed Internet connection finally\n\ncome together to form a powerful communication tool.\n\nOnce your account has been set-up, you will receive everything\n\nyou need to start using your Packet8 telephone\n\nservice. Plus in your phone. Start making and receiving\n\ncalls. It?s that simple.\n\nSign-Up Today! Total up-front investment only $29.90\n\nwith Telebay Rep Coupon Code ? includes first month?s\n\nservice, activation fee & equipment.\n\nContact Telebay Rep:\n\nPh:\n\nwww.Telebay.com/7777\n\nEnter Coupon Code below for $20 Off Activation:\n\nTelebay-8 ? The All-in-One\n\nOpportunities Available!\n\nWill Smith\n\nwill_smith_1@charter.net\n\n\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nTHIS SHOULD BE A ONE TIME MAILING ONLY. YOU HAVEN'T BEEN SUBSCRIBED TO ANYTHING. \n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nSIGNATURE\n\nAS SEEN ON THE RADIO!\n\nGet ACCESS to top LAWFIRMS across North America for less than a cup of coffee per day!\n\nwww.wtatours.com\n\nThe NBCOC said on November 24, 2003 that ths information available at \n this website directly below is the best way for young PEOPLE\nto get off to a great LEGAL, start financially at a YOUNG age.\n\nThey said that PPLSI is the #1 best inexpensive Biz Op today in America for .\nJOBS pay your bills! Running your own business will make you rich! Need I say more...? :-)\n\nwww.wtatours.net\n\n-------------------------------------------------------------------------------------------------------------------------\nSignature\n\nFIRE YOUR TELEPHONE COMPANY!!!\n\nDSL/CABLE users get unlimited local and long distance throughout USA/CANADA\nfor $19.95 a month. Using your normal telephones/GREAT SIGNAL!!\nUnlimited Europe and Asia for $30.00 a month more\n\nHumans in Europe and Asia can also SIGN UPutilize these incredible plans.\n\nBUSINESS PLANS AVAILABLE ALSO. We are a NASDAQ COMPANY\n\nYou can start your own business with Telebay FREE from any country in the world where we offer service.\nThose of you in low income countries can make a great living with us. As can those in high income countries\nlike the USA, Canada, Europe, and Asia.\n\nYou should be 17 years or older.\n\nwww.telebay.com/7777\n\n   \n \nSign-Up Page for Z-LineHOME Customers:\n\nhttps://purchase.z-tel.com/portal/ztel/purchase/i/ZTelLandingPage.jsp?id=88857010000&repID=7777&noMenu=true  \n\nTelebay Opportunity Page: \nhttp://www.telebay.com/7777/opp.html \n\nSign-Up as Telebay Independent Rep Page: \nhttp://www.telebay.com/cgi-bin/plexum.pl?page=signup&id=7777 \n      \nZ-LineHOME Only:  \nhttp://www.telebay.com/7777/zhome.html  \n      \nZ-LineBUSINESS SIMPLICITY:  \nhttp://www.telebay.com/7777/zbiz.html  \n    \nTelebayISP Page: \nhttp://www.telebay.com/7777/isp.html \n    \nPacket8 Page: \nhttp://www.telebay.com/7777/bbphone.html \n     \nCellular Page: \nhttp://www.telebay.com/7777/cell.html \n \n --------------------------------------------------------------------------------------------------------------------------------------\nExcellent Health Care Savings Plans from $34.95 to $109.95 a month\nSave hundreds of dollars a month on health care costs.\nMost anyone can market this FREE opportunity.\n\nwww.babyboomerboogie.com\n\nCheck  our  companies at this URL if you question their legitimacy:\nwww.ftc.gov\nwww.betterbusinessbureau.com\n\n\n\n"
        },
        {
            "subject": "Tbilisi YMCA Assistance Reques",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "PC Sho",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Business Financing in North Vancouver B.C",
            "content": "Dear Member,\n\nFinancing or operating a new or existing Business in B.C. or Canada?  North Vancouver based company,  Kofoed & Bailey Financial Services, offers financing and professional Financial services.\n \n1)     Existing Business requiring new/used equipment? Equipment Lease:\n $10,000 CDN = $295.00/mo. 36 mths oac.\n2)     Existing Business requiring Cash flow?  Lease back Equipment: \n$10,000 CDN = $335/mo. 36 mths oac. \n3)     New Business requiring equipment/operating capital? Collateral Lease: $10,000 CDN = $375/mo. 36 mths oac.\n \nVendors - Your Clients: \n-Looking for an alternate source of financing for your risk adverse/ credit challenged clients?  \n- B & C credit, alternative and Profit Share financing available.\nVendors- Your Own Business:   \n-Looking for an alternate way to finance your Inventory?  \n-Profit Sharing Equipment/ Inventory programs available.\n\nCEO/Presidents:  \n-Need  business/partnership contracts? \n-Better, less expensive solutions to E&O / Directors/ Liablity Insurance?  \n-Trust Documents/ Bullet proof structures for business?\n          \nContact us: \nTel: 604-984-6701 \n Fax: 604-984-6745 \n baileycapital@shaw.ca\n\nKofoed & Bailey Financial Services \n \"Friendly Business Financing\". \n \nTo be removed from our lists, please return this email with \"Remove\" in the subject line.  Full cooperation ensured.\n     \nThis email/fax may contain confidential information, and is intended only for the named recipient and may be privileged. Distribution or copying of this email/fax  by anyone other than the named recipient is prohibited. If you are not the named recipient, please notify us immediately and permanently destroy this email/fax and all copies of it. Internet email/fax is not private, secure, or reliable. No member of  Kuwica Leasing & Financial Services Corporation dba. Kofoed & Bailey Financial Services, The Bailey Capital Fund is liable for any errors or omissions in the content or transmission of this email/fax. Any opinions contained in this email/fax are solely those of the author and, unless clearly indicated otherwise in writing, are not endorsed by any member of  Kuwica Leasing & Financial Services Corporation dba.Kofoed & Bailey Financial Services, The Bailey Capital Fund.\n\n\n\n"
        },
        {
            "subject": "David Duke is a malignant narcissist",
            "content": "David Duke is a malignant narcissist.\n\nHe invents and then projects a false, fictitious, self for the world to \nfear, or to admire. He maintains a tenuous grasp on reality to start with \nand the trappings of power further exacerbate this. Real life authority and \nDavid Duke?s predilection to surround him with obsequious sycophants support \nDavid Duke?s grandiose self-delusions and fantasies of omnipotence and \nomniscience.\nDavid Duke's personality is so precariously balanced that he cannot tolerate \neven a hint of criticism and disagreement. Most narcissists are paranoid and \nsuffer from ideas of reference (the delusion that they are being mocked or \ndiscussed when they are not). Thus, narcissists often regard themselves as \n\"victims of persecution\".\nDuke fosters and encourages a personality cult with all the hallmarks of an \ninstitutional religion: priesthood, rites, rituals, temples, worship, \ncatechism, and mythology. The leader is this religion's ascetic saint. He \nmonastically denies himself earthly pleasures (or so he claims) in order to \nbe able to dedicate himself fully to his calling.\nDuke is a monstrously inverted Jesus, sacrificing his life and denying \nhimself so that his people - or humanity at large - should benefit. By \nsurpassing and suppressing his humanity, Duke became a distorted version of \nNietzsche's \"superman\".\nBut being a-human or super-human also means being a-sexual and a-moral.\nIn this restricted sense, narcissistic leaders are post-modernist and moral \nrelativists. They project to the masses an androgynous figure and enhance it \nby engendering the adoration of nudity and all things \"natural\" - or by \nstrongly repressing these feelings. But what they refer to, as \"nature\" is \nnot natural at all.\nDuke invariably proffers an aesthetic of decadence and evil carefully \norchestrated and artificial - though it is not perceived this way by him or \nby his followers. Narcissistic leadership is about reproduced copies, not \nabout originals. It is about the manipulation of symbols - not about \nveritable atavism or true conservatism.\nIn short: narcissistic leadership is about theatre, not about life. To enjoy \nthe spectacle (and be subsumed by it), the leader demands the suspension of \njudgment, depersonalization, and de-realization. Catharsis is tantamount, in \nthis narcissistic dramaturgy, to self-annulment.\nNarcissism is nihilistic not only operationally, or ideologically. Its very \nlanguage and narratives are nihilistic. Narcissism is conspicuous nihilism - \nand the cult's leader serves as a role model, annihilating the Man, only to \nre-appear as a pre-ordained and irresistible force of nature.\nNarcissistic leadership often poses as a rebellion against the \"old ways\" - \nagainst the hegemonic culture, the upper classes, the established religions, \nthe superpowers, the corrupt order. Narcissistic movements are puerile, a \nreaction to narcissistic injuries inflicted upon David Duke like (and rather \npsychopathic) toddler nation-state, or group, or upon the leader.\nMinorities or \"others\" - often arbitrarily selected - constitute a perfect, \neasily identifiable, embodiment of all that is \"wrong\". They are accused of \nbeing old, they are eerily disembodied, they are cosmopolitan, they are part \nof the establishment, they are \"decadent\", they are hated on religious and \nsocio-economic grounds, or because of their race, sexual orientation, origin \n... They are different, they are narcissistic (feel and act as morally \nsuperior), they are everywhere, they are defenseless, they are credulous, \nthey are adaptable (and thus can be co-opted to collaborate in their own \ndestruction). They are the perfect hate figure. Narcissists thrive on hatred \nand pathological envy.\nThis is precisely the source of the fascination with Hitler, diagnosed by \nErich Fromm - together with Stalin - as a malignant narcissist. He was an \ninverted human. His unconscious was his conscious. He acted out our most \nrepressed drives, fantasies, and wishes. He provides us with a glimpse of \nthe horrors that lie beneath the veneer, the barbarians at our personal \ngates, and what it was like before we invented civilization. Hitler forced \nus all through a time warp and many did not emerge. He was not the devil. He \nwas one of us. He was what Arendt aptly called the banality of evil. Just an \nordinary, mentally disturbed, failure, a member of a mentally disturbed and \nfailing nation, who lived through disturbed and failing times. He was the \nperfect mirror, a channel, a voice, and the very depth of our souls.\nDuke prefers the sparkle and glamour of well-orchestrated illusions to the \ntedium and method of real accomplishments. His reign is all smoke and \nmirrors, devoid of substances, consisting of mere appearances and mass \ndelusions. In the aftermath of his regime - Duke having died, been deposed, \nor voted out of office - it all unravels. The tireless and constant \nprestidigitation ceases and the entire edifice crumbles. What looked like an \neconomic miracle turns out to have been a fraud-laced bubble. Loosely held \nempires disintegrate. Laboriously assembled business conglomerates go to \npieces. \"Earth shattering\" and \"revolutionary\" scientific discoveries and \ntheories are discredited. Social experiments end in mayhem.\nIt is important to understand that the use of violence must be ego-syntonic. \nIt must accord with the self-image of David Duke. It must abet and sustain \nhis grandiose fantasies and feed his sense of entitlement. It must conform \nDavid Duke like narrative. Thus, David Duke who regards himself as the \nbenefactor of the poor, a member of the common folk, the representative of \nthe disenfranchised, the champion of the dispossessed against the corrupt \nelite - is highly unlikely to use violence at first. The pacific mask \ncrumbles when David Duke has become convinced that the very people he \npurported to speak for, his constituency, his grassroots fans, and the prime \nsources of his narcissistic supply - have turned against him. At first, in a \ndesperate effort to maintain the fiction underlying his chaotic personality, \nDavid Duke strives to explain away the sudden reversal of sentiment. \"The \npeople are being duped by (the media, big industry, the military, the elite, \netc.)\", \"they don't really know what they are doing\", \"following a rude \nawakening, they will revert to form\", etc. When these flimsy attempts to \npatch a tattered personal mythology fail, David Duke becomes injured. \nNarcissistic injury inevitably leads to narcissistic rage and to a \nterrifying display of unbridled aggression. The pent-up frustration and hurt \ntranslate into devaluation. That which was previously idealized - is now \ndiscarded with contempt and hatred. This primitive defense mechanism is \ncalled \"splitting\". To David Duke, things and people are either entirely bad \n(evil) or entirely good. He projects onto others his own shortcomings and \nnegative emotions, thus becoming a totally good object. Duke is likely to \njustify the butchering of his own people by claiming that they intended to \nkill him, undo the revolution, devastate the economy, or the country, etc. \nThe \"small people\", the \"rank and file\", and the \"loyal soldiers\" of David \nDuke - his flock, his nation, and his employees - they pay the price. The \ndisillusionment and disenchantment are agonizing. The process of \nreconstruction, of rising from the ashes, of overcoming the trauma of having \nbeen deceived, exploited and manipulated - is drawn-out. It is difficult to \ntrust again, to have faith, to love, to be led, to collaborate. Feelings of \nshame and guilt engulf the erstwhile followers of David Duke. This is his \nsole legacy: a massive post-traumatic stress disorder.\n\n_________________________________________________________________\nStore more e-mails with MSN Hotmail Extra Storage ? 4 plans to choose from! \nhttp://click.atdmt.com/AVE/go/onm00200362ave/direct/01/\n\n\n\n"
        },
        {
            "subject": "is this list ope",
            "content": " \n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nhttp://www.Intercore.net\n\nComputer Consultant Los Angeles\n\nhttp://www.Avidware.net\n\nSecurity Consultant Los Angeles\n\nhttp://www.Avidware.com\n\nBusiness Consultant Los Angeles\n\nhttp://www.FastForwardMarcom.com\n\nWebsite Developer Los Angeles\n\nhttp://www.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nhttp://www.CorpLeasing.com\n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "Re: [splato2] masters 4 sal",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Re: [splato2] masters 4 sal",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Re: Para Victo",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Re: ???F?????",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Position papers for w3c workshop  more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "Development of platform-independent applications - workshop more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "Calvary greeting",
            "content": "My Lordship,\n    \n    Calvary greetings in the name of our Lord Jesus Christ, I am former Mrs aliza Wasilat ali rasaq,now Mrs Sarah Rasaq, a widow to Late ali rasaq Mohammed,I am 72years old, I am now a new Christian convert, suffering from long time cancer of the breast.\nFrom all indications, my condition is really eteriorating and is quite obvious that I may not live more than six months, because the cancer stage has gotten to a very severe stage.\nMy late husband was killed during the Gulf war, and during the period of our marriage we had a son who was also killed in a cold blood during the Gulf war.\n  My late husband was very wealthy and after his death,I inherited all his business and wealth.\nMy personal physician told me that I may not live for more than six months and I am so scared about this.\nSo, I now decided to divide part of this wealth, by contributing to the \ndevelopment of evangelism in Africa, America, Europe and Asian Countries.\nThis mission which will no doubt be tasking had made me to recenlty relocated to Gambia capital city banjul, Africa where I live presently.\nI selected your church after visiting the website for this purpose and prayed over it, I am willing to donate the sum of $10.000,000.00 Million US Dollars to your Church/Ministry for the development of evangelism and also as aids for the less privileged around you.\nPlease note that, this fund is lying in a Security Company in Europe and the company has branches, therefore my lawyer will file an immediate application for the transfer of the money in the name of your ministry.\n Please, do not reply me if you have the intention of using this fund for personal use other than enhancement of evangelism.Lastly, I want you/your ministry to be praying for me as regards my entire life and my health because I have come to find out since my spiritual birth lately that wealth acquisition without Jesus Christ in one's life is vanity upon vanity.\nIf you have to die says the keep fit and i will give you the crown of life.\nMay the Grace of our Lord Jesus Christ, the love of God, and the sweet fellowship of the Holy Spirit be with you.\nIf your are interested do reach my Attorney he lives in Paris, France.\n\nHis Particulars are\n\nName :Avocat David West\nemail:davidwest_avocat@nicolastse.com\nThanks for your assistance\nYours in Christ,\nMrs Aliza Wasilat Rasaq,\nSierra leone\n\n\n\n-- \n_______________________________________________\nGet your free email from www.doramail.com with 30 Megs of disk space in webhosting and e-mail storage!\n\n\nPowered by Outblaze\n\n\n\n"
        },
        {
            "subject": "Berg video exposed as a frau",
            "content": "Terrorist mastermind Zarqawi has announced his name but hidden his face. The CIA has said it is indeed Zarqawi, but he appears to be reading his own speech from a paper.\n\nThe person holding the knife -- allegedly Zarqawi -- has a Black hood at the video's beginning, but there is an edit (the camera time signatures change) and the knifeholder is then wearing a WHITE hood (and no bulletproof vest).\n\nYou'll also find the following oddities in the heavily edited video, which was heavily edited, presumably in a lab or on a pc:\n\nWM-----|-----Video Clock-----|-----Screen Shot\n0:00 ---|--- nothing ---|-------Arabic letters\n0:05 ---|--- 13:26:24 ---|--- Nick Berg speaking\n0:09 ---|---- 2:18:33 ---|--- Nick Berg sitting\n0:20 ---|---- 2:40:33 ---|--- Speech in Arabic\n4:36 ---|---- 2:44:56 ---|--- Speaker pushes Berg over\n4:38 ---|--- 13:45:48 ---|--- Decapitation begins\n4:43 ---|--- 13:45:52 ---|--- Picture lost\n4:44 ---|--- 13:45:59 ---|--- Picture returns, decapitation continues\n\nSo, if we are to assume the timestamps of the two (?) cameras are accurate, this means Berg was beheaded at 13:47:49 (1:47) but at 2:44, nearly an hour later, he is sitting with his head intact.\n\nZarqawi has also been reported to have an artificial leg; this is definitely not apparent in the video. Nor is his Jordanian accent, according to experts. Also note the gold ring on the \"sinister\" (toilet-using) hand -- a definite no-no for muslims.\n\nThen there's US consulate Beth A. Payne's emails to Berg's family saying their son was in \"US military custody\" for 13 days:\nhttp://www.usatoday.com/news/world/iraq/2004-05-13-emails-text_x.htm\n\nApril 1, 1:26 a.m. (To Michael Berg, Berg's father) \nI have confirmed that your son, Nick, is being detained by the U.S. military in Mosul. He is safe. He was picked up approximately one week ago. We will try to obtain additional information regarding his detention and a contact person you can communicate with directly. \n\nApril 1, 5:23 a.m. (To Suzanne Berg, Berg's mother) \nI have been able to confirm that your son is being detained by the U.S. military. I am attempting to identify a person with the U.S. military or FBI here in Iraq who you can contact directly with your questions. \n\nAnd, according to CNN, Berg himself had contacted a friend -- Chilean reporter Hugo Infante -- saying he was in US custody:\nhttp://www.cnn.com/2004/WORLD/meast/05/13/berg.friends/\n\nThe US Administration denies this, saying he was in Mosul Iraqi police custody, BUT \"...police chief Maj. Gen. Mohammed Khair al-Barhawi in Mosul insisted his department had never arrested Berg and said he had no knowledge of the case.  ''The Iraqi police never arrested the slain American,'' al-Barhawi told reporters. ''Take it from me ... that such reports are baseless.'' \nhttp://www.signonsandiego.com/news/world/iraq/20040513-1057-iraq-berg.html\n\nAnd of course there are the American orange prisoner jumpsuit and white plastic chair and yellow walls which appear in the video -- exactly as they do at Abu Ghraib, the now-notorious site of the American torture of Iraqi POWs:\nhttp://marc.perkel.com/images/berg-chair.jpg\nhttp://marc.perkel.com/images/babe-chair.jpg\nhttp://marc.perkel.com/images/prison01.jpg\nhttp://marc.perkel.com/images/orangegarb.jpg\n\nNext, the hosting website was reported to be in Malaysia, but was discovered to actually located in London:\n\nSays Jackblood.com, which ran a trace:\n\"...www.al-asnar.net and www.al-asnar.biz have apparently been disabled by 'authorities.' ...the publishers for these sites are located in London, England and Nurnberg, Denmark. \n\n\"The addresses began to disappear from the internet listings as we reported this development on The Power Hour Radio Show. Apparently, \"Big Brother\"; had been listening to the show and didn't like the news at all. The location of the publishers for al-ansar.net appears to be at an Arab Press Building, which appears to be shared by different Arab newspublications. The name of the organization is the Arab Press House. Thebuilding is apparently the headquarters for news magazines such as, AlJamilla, Sayidaty, and Al Majallah among others. \n\nThe London address is the following: \nhttp://www.al-ansar.net \nArab Press House \nAbdel Rahman al-Rashed \n184 High Holborn, WCIV78P, London \ntel. 020 78318181 \n\nThe other address is located in Nurnberg, Denmark. It apparently belongs to a man named Omar AbuOmar. His email address is:alansar_alansar@hotmail.com . \n\nThe complete mailing address is the following: \nhttp://www.al-ansar.biz \nOmar AbuOmar \nNew Dream St. 33 \nNurnberg, Denmark, 42114 \nPhone: +965.15441211 \nEmail: alansar_alansar@hotmail.com \n\n....these same websites (www.al-asnar.net and www.al-asnar.biz) were the ones that posted the latest Bin Laden audio recording, weeks ago. Despite knowing the website addresses, and potentially the addresses of their respective publishers, the CIA, the FBI, and the Department of Homeland Security did not make any apparent efforts to monitor the websites for uploaded files or internet traffic. Therefore, no arrests were made.\" \n\nNext, the AK-47 carried by one of the men is a \"Gilal\" -- an Israeli weapon that improves on the AK- 47. Feyadeen and other insurgents almost universally use AK-47s. The man in the left of the video is standing in the American military stance known as \"parade rest\", and several of the apparent terrorists are wearing white tennis shoes ad bulletproof vests.\n\nAt frame 13:46:27, there is an edit and a person with a white ear and a green cap is seen entering from the right. Then the video is re-edited.\n\nMatt Drudge reports that \"The statement in the video was signed off with Zarqawi's name and dated 11 May\" , but Berg's body was reported found on May 10th -- the day before the video was apparently made!\n\nPay attention. This one is definitely a setup. \n\nMore details here:\nhttp://www.libertyforum.org/showflat.php?Cat=&Board=news_international&Number=1471708&view=collapsed&sb=5&o=21%E2%88%82=1\n\n\n\n"
        },
        {
            "subject": "Foreign exchange trading",
            "content": " ?\n ?\n ?\n ?\nPlease kindly accept my appology for intruding your privacy.I am \nMr.Godfrey Ohiri ,an internal Auditor with Hallmark Bank PLC,Nigeria.I \nam soliciting your assistance to help accept ownership of $1million \ndollars in my bank which I discovered in discharge of my duty.This \nmoney arose as a result of unrecorded foreign exchange trading in our \nbank last year.\n\nI have concluded arrangement for you to simply open an account with our \nbank and this money will be credited to your account,You may latter \ntravel down to Nigeria or appoint an Attorney for us to sign Legal \nAgreement for managment of account or investment of this money \npreferably in your country.Looking forward to receiving your prompt \nreply.\n\nBest regards.\nGodfrey Ohiri.  \n\n\n\n\n\n\ntext/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "HOPE TO READ FROM YO",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "CFP: IEEE/WIC/ACM Web Intelligence 200",
            "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepage: http://www.maebashi-it.org/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n           National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, and data/knowledge grids) on the\nnext generation of Web-empowered products, systems, services, and\nactivities. It is one of the most important as well as promising IT\nresearch fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\nWI Topics\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nMore detailed instructions and the On-Line Submission Form can be\nfound from the WI'04 homepage: http://www.maebashi-it.org/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper awards will be conferred on the authors of\nthe best papers at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyoung Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Used Formwork/Peri Dok",
            "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n"
        },
        {
            "subject": "CFP: IEEE/WIC/ACM Web Intelligence 200",
            "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepages: http://www.maebashi-it.org/WI04\n                       http://www.comp.hkbu.edu.hk/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n  Microsoft Research Asia\n                  National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, wisdom Web, and data/knowledge\ngrids) on the next generation of Web-empowered products, systems,\nservices, and activities. It is one of the most important as well as\npromising IT research fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\nFollowing the great successes of WI'01 held in Maebashi City, Japan\nand WI'03 held in Halifax, Canada, WI 2004 provides a leading\ninternational forum for researchers and practitioners (1) to present\nthe state-of-the-art of WI technologies; (2) to examine performance\ncharacteristics of various approaches in Web-based intelligent\ninformation technology; and (3) to cross-fertilize ideas on the\ndevelopment of Web-based intelligent information systems among\ndifferent domains.  By idea-sharing and discussions on the underlying\nfoundations and the enabling technologies of Web intelligence, WI 2004\nwill capture current important developments of new models, new\nmethodologies and new tools for building a variety of embodiments of\nWeb-based intelligent information systems.\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Service-Oriented Computing\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nAll paper submissions will be handled electronically.  More detailed\ninstructions and the On-Line Submission Form can be found from the\nWI'04 homepages: http://www.maebashi-it.org/WI04 and\nhttp://www.comp.hkbu.edu.hk/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper award and the best demo award will be conferred on the\nauthors of the best papers and the best demos at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-Chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyong Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n*******************************************************\nWI/IAT Conference Secretariat\nwi-iat@maebashi-it.org\n\nWI'04:  http://www.maebashi-it.org/WI04/\nIAT'04: http://www.maebashi-it.org/IAT04/\n??????????????????????????\n2003-12-26 17:59:49\n********************************************************\n\n\n\n"
        },
        {
            "subject": "Millionaire at 31..",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "HK DVD, Buy 5 get 3 NOW, GoodsWell.com  7/4/2003 1:12:29 A",
            "content": "Dear em ,\n\nDear Sir / Madam\n\nWe are one of the leading exporters of Hong Kong Video and have enjoyed an excellent \nreputation through 3 years' business experience. We are sure that you will be quite \nsatisfied with our services and the excellent quality of our goods.\n\nFor now, we have a list of items sell in \"Buy 5pcs GET 3pcs\" DVD, please see\nour attach excel file(Chinese Big5 Code).\n\nWe are look forward to receiving your first order.\n\n\n\n\napplication/octet-stream attachment: Buy5Get3DVD.xls\n\n\n\n\n"
        },
        {
            "subject": "Comments for PR-PNG2003052",
            "content": "Hello,\n\nAre you still accepting comments? If you are, I will try to read the\nPNG Proposed Recommendation [1] on Tuesday-Wednesday. Here are results\nof spell checking.\n\nDoes this project require UK English? I have only the old Directives\nPart 3 3rd edition which says: \"The following reference works for\nlanguage are suggested: - for English, The Shorter Oxford English\nDictionary and The Concise Oxford Dictionary....\" W3C on the other hand\nuses US English [2]. I imagine it's bad form to point these out but\nhere goes (they weren't in the 1996 edition).\n\ns/neighbouring/neighboring/\ns/colour/color/\ns/defence/defence/\ns/truecolour/truecolor/\ns/neighbour/neighbor/\ns/favour/favor/\ns/behaviour/behavior/\ns/honour/honor/\ns/organisations/organizations/\ns/metre/meter/\n\nminor typos\n===========\nThere is one \"grayscale\" (the rest are greyscale; either is fine).\ns/obseletes/obsoletes/\ns/orginal/original/\ns/internet/Internet/\n\nEditorial changes says, \"The document has been reformatted according to\nthe requirements of ISO.\" Is justified text required? I think unless\none has a fancy high resolution set up this is quite hard to read\njustified. What is the source of the style sheet [3]? Unless it is\nISO, 'text-align: justify;' could be one huge rule for all your\nselectors, and then be commented out for W3C.\n\nAlso I wondered if you had looked at the Manual of Style suggestion \nfor references [4]. The titles ought to be the link.\n\nI just happened to see the reference for RFC 2070 should read:\n   Yergeau, F., Nicol, G., Adams, G., Du&uuml;rst, M.,\n(note the commas)\n\nMore comments later this week if you would still accept them.\n\n[1] http://www.w3.org/TR/2003/PR-PNG-20030520/\n[2] http://www.w3.org/2001/06/manual/#Spelling\n[3] http://www.w3.org/TR/2003/PR-PNG-20030520/isostyle.css\n[4] http://www.w3.org/2001/06/manual/#ref-section\n\nBest wishes,\n-- \nSusan Lesch           http://www.w3.org/People/Lesch/\nmailto:lesch@w3.org               tel:+1.858.483.4819\nWorld Wide Web Consortium (W3C)    http://www.w3.org/\n\n\n\n"
        },
        {
            "subject": "Re: [png-list] Comments for PR-PNG2003052",
            "content": "Susan Lesch <lesch@w3.org> wrote:\n\n> There is one \"grayscale\" (the rest are greyscale; either is fine).\n\nGood catch.  It looks like the whole Abstract was written in American\nEnglish, unlike the rest of the document.  It contains not only that\n\"grayscale\" that you noticed, but also \"color\" (twice) and \"truecolor\".\n\nThe rest of the document consistently uses \"colour\" and \"truecolour\"\n(except in the proper name International Color Consortium), but it also\nconsistently uses \"colorimetry\" and \"colorimetric\".  Should those be\n\"colourimetry\" and \"colourimetric\" for consistency?\n\n> s/internet/Internet/\n\nFurthermore, these should be made consistent:\n\nInternet Media Type [Abstract, Annex A]\nInternet Media type [Scope]\nInternet media type [Table of Contents (twice), Annex A (twice)]\ninternet media type [Annex A]\n         media type [Annex A]\n\n> I just happened to see the reference for RFC 2070 should read:\n>   Yergeau, F., Nicol, G., Adams, G., Du&uuml;rst, M.,\n> (note the commas)\n\nThere are several related inconsistencies.  The normative references\ntend to use Last, F. for all the authors, while the bibliography tends\nto use F. Last for all except the first author, which is Last, F.\n\nAlso:\n\nRFC-2045:  there is an extra space before the comma before the title\nRFC-2048:  there is no comma before \"and\"\nRFC-2070:  two commas and the word \"and\" are missing\n[KASSON]:  there is an extra comma before \"and\"\n[POYNTON]: the entire first name is spelled out\n[TRAVIS]:  the entire first name is spelled out\n[ZL]:      the first author is F. Last rather than Last, F.\n\nAMC\n\n\n\n"
        },
        {
            "subject": "[Fwd: http://www.w3.org/TR/",
            "content": "Hi PNGs,\n\nHere are some comments about the PNG Specification.\n\nRegards,\nVivien\n\n-- \nVivien Lacourba - W3C Webmaster MIT/LCS\n\n\nattached mail follows:\n\n\n\n\nHello W3C people\n\nI had just started reading the PNG specification and in both your current\ndocument (REC-png) and your new proposed one (2003/PR-PNG-20030520/) there\nis an error in the section describing bit depth of colours: \"not the total\npixel size\" should be \"not the total bit size\" as it has to do with the\nnumber of bits required to specify the colour value (R, G and B) in a table\nin the file rather than the displayed size of the pixel (eg dpi resolution).\n\nThere may be more errors but I haven't read it all yet! I wanted to know if\nthis was even remotely the correct address for reporting such things.\n\nSusan Foord\n\n\n\n"
        },
        {
            "subject": "[Fwd: http://www.w3.org/TR/",
            "content": "Hi PNGs,\n\nHere are some comments about the PNG Specification.\n\nRegards,\nVivien\n\n-- \nVivien Lacourba - W3C Webmaster MIT/LCS\n\n\nattached mail follows:\n\n\n\n\nHello W3C people\n\nI had just started reading the PNG specification and in both your current\ndocument (REC-png) and your new proposed one (2003/PR-PNG-20030520/) there\nis an error in the section describing bit depth of colours: \"not the total\npixel size\" should be \"not the total bit size\" as it has to do with the\nnumber of bits required to specify the colour value (R, G and B) in a table\nin the file rather than the displayed size of the pixel (eg dpi resolution).\n\nThere may be more errors but I haven't read it all yet! I wanted to know if\nthis was even remotely the correct address for reporting such things.\n\nSusan Foord\n\n\n\n"
        },
        {
            "subject": "Re: [Fwd: http://www.w3.org/TR/",
            "content": "Vivien Lacourba wrote:\n> \n> Hi PNGs,\n> \n> Here are some comments about the PNG Specification.\n> \n> Regards,\n> Vivien\n> \n> --\n> Vivien Lacourba - W3C Webmaster MIT/LCS\n> \n>   ------------------------------------------------------------------------------------------------\n> \n> Subject: http://www.w3.org/TR/\n> Resent-Date: Mon, 2 Jun 2003 09:24:38 -0400\n> Resent-From: Vivien Lacourba <vivien@w3.org>\n> Resent-To: \"web-human@w3.org\" <web-human@w3.org>\n> Date: 02 Jun 2003 15:25:55 +0200\n> From: \"Susan Foord\" <susan.foord@ntlworld.com>\n> Organization: W3C\n> To: <web-human@w3.org>\n> \n> Hello W3C people\n> \n> I had just started reading the PNG specification and in both your current\n> document (REC-png) and your new proposed one (2003/PR-PNG-20030520/) there\n> is an error in the section describing bit depth of colours: \"not the total\n> pixel size\" should be \"not the total bit size\" as it has to do with the\n> number of bits required to specify the colour value (R, G and B) in a table\n> in the file rather than the displayed size of the pixel (eg dpi resolution).\n> \n> There may be more errors but I haven't read it all yet! I wanted to know if\n> this was even remotely the correct address for reporting such things.\n> \n> Susan Foord\n\nHi, Susan.  You can use \"png-group@w3.org\" in the future.\n\nI agree that readers might possibly confuse \"pixel size\" with \"resolution\".\nYour solution looks a little confusing as well.  How about\n\n  \"not the total number of bits per pixel\" ?\n\nThanks\n\nGlenn\n\n\n\n"
        },
        {
            "subject": "tes",
            "content": "Hello png-group,\n\n  this is a test\n\n-- \n Chris                          mailto:chris@w3.org\n\n\n\n"
        },
        {
            "subject": "Re: [Fwd: http://www.w3.org/TR/",
            "content": "Susan Foord and I have had some offline discussion of her suggestion,\nand as a result the recommendation is now, in the interest of clarity,\nto change parts of PNG second edition, Clause 4.4, PNG Image, indicated\nby the square brackets:\n\n   c. Truecolor: ... The alpha channel may be represented by\n      a single [pixel] value.  Matching pixels ...\n   d. Greyscale: ... The alpha channel may be represented by\n      a single [pixel value as in] the previous case. ...\n\n   ... size of each sample, not the total [pixel size].\n\n to read:\n\n   c. Truecolor: ... The alpha channel may be represented by\n      a single RGB value.  Matching pixels ...\n   d. Greyscale: ... The alpha channel may be represented by\n      a single greyscale value, similar to the previous case. ...\n\n   ... size of each sample, not the total number of bits per pixel.\n\nGlenn\n\n\n\n"
        },
        {
            "subject": "Re: [pnglist] Re: [Fwd: http://www.w3.org/TR/",
            "content": "On Tuesday, June 3, 2003, 2:54:06 PM, Glenn wrote:\n\n\nGRP> Susan Foord and I have had some offline discussion of her suggestion,\nGRP> and as a result the recommendation is now, in the interest of clarity,\nGRP> to change parts of PNG second edition, Clause 4.4, PNG Image, indicated\nGRP> by the square brackets:\n\nGRP>    c. Truecolor: ... The alpha channel may be represented by\nGRP>       a single [pixel] value.  Matching pixels ...\nGRP>    d. Greyscale: ... The alpha channel may be represented by\nGRP>       a single [pixel value as in] the previous case. ...\n\nGRP>    ... size of each sample, not the total [pixel size].\n\nGRP>  to read:\n\nGRP>    c. Truecolor: ... The alpha channel may be represented by\nGRP>       a single RGB value.  Matching pixels ...\nGRP>    d. Greyscale: ... The alpha channel may be represented by\nGRP>       a single greyscale value, similar to the previous case. ...\n\nGRP>    ... size of each sample, not the total number of bits per pixel.\n\nYes, I think that is clearer and more precise.\n\n-- \n Chris                            mailto:chris@w3.org\n\n\n\n"
        },
        {
            "subject": "Re: [Fwd: http://www.w3.org/TR/",
            "content": "Glenn Randers-Pehrson <glennrp@comcast.net> wrote:\n\n> change parts of PNG second edition, Clause 4.4, PNG Image, indicated\n> by the square brackets:\n> \n>    c. Truecolor: ... The alpha channel may be represented by\n>       a single [pixel] value.  Matching pixels ...\n>    d. Greyscale: ... The alpha channel may be represented by\n>       a single [pixel value as in] the previous case. ...\n> \n>    ... size of each sample, not the total [pixel size].\n> \n>  to read:\n> \n>    c. Truecolor: ... The alpha channel may be represented by\n>       a single RGB value.  Matching pixels ...\n>    d. Greyscale: ... The alpha channel may be represented by\n>       a single greyscale value, similar to the previous case. ...\n> \n>    ... size of each sample, not the total number of bits per pixel.\n\nThe \"pixel value\" phrase appears again in section 6.2, but the same\nfix cannot be applied there, because the truecolor/grayscale cases are\ncombined, like so:\n\n    b. Truecolour, greyscale: A tRNS chunk contains a single pixel\n       value...\n\nHow about if we leave 6.2 as-is, but prepare the reader for it by\nkeeping the word \"pixel\" in section 4.4, like so:\n\n     c. ...by a single RGB pixel value. ...\n     d. ...by a single greyscale pixel value. ...\n\nAlso, I like the replacement of \"size\" by \"bits per\", so much that I'd\nlike to do it not only for \"pixel\", but also for \"sample\":\n\n    ...the bit depth specifies the number of bits per sample, not the\n    total number of bits per pixel.\n\nI've added these suggestions to my own growing collection.\n\nAMC\n\n\n\n"
        },
        {
            "subject": "L'Esprit Manouche VIP Option",
            "content": "        \n     L'Esprit Manouche\n\n            Festival Organisation\n           \n         4 Brighton Road\n\n            Balsall Heath\n\n            Birmingham \n\n            B12 8PU  \n\n            UK\n           \n        \n     \n \n\n\n\n                                                          \n\n \n\n \n\n            Date                 4th June 2003\n           \n        \n             telephone  0044 (0)121 249 2303\n\n             email       info@lespritmanouche.com\n           \n        \n \n\n \n\n \n\n \n\n \n\nL'Esprit Manouche   12th & 13th July 2003,  Moseley Private Park, Birmingham\n\n \n\n \n\nWhat does it offer?  (Arrange these in your own preferred order!)\n\n \n\n-                              -     A stunning weekends entertainment paid for by the taxman.\n\n-                              -     The top musicians in the world gathered to play and pay homage to Django Reinhardt.\n\n-                              -     A chance to feel good by helping a very deserving charity.\n\n-                              -     Exquisite food and drink.\n\n-                              -     Being part of the premier event of this kind in the UK\n\n-                              -     A very special weekend.\n\n \n\n \n\nThere are two main reasons for the festival - \n\n1.  To commemorate the 50th anniversary of the death of Django Reinhardt, legendary guitarist and Europe's most influential contribution to the world of jazz.  (And we have an incredible line up of artists to do just that).\n\n2.  To benefit the Birmingham Centre for Arts Therapies, (charity no.1051578).  They are a good bunch that provide much needed help for children and adults with disabilities.  This is doubly appropriate when you consider the disabilities Django suffered and overcame and 2003 is the European Year of the Disabled.\n\n \n\n \n\nWe are offering a limited number of VIP tickets for this festival, for sale at one hundred and twenty five pounds per head.  By issuing your payment directly to the charity your contribution is a tax deductible item.  \n\n \n\nThe tickets are preferably sold in groups of four, as each group receives a large picnic rug with a hamper containing a sumptuous summer picnic feast for four people.  Champagne, wine, salmon, pates, cheeses, fruits, strawberry and cream etc are all included in the hamper - a very civilised affair!\n\n \n\nVIP tickets also allow access to the exclusive VIP marquee where French cordon bleu catering is being provided by the award winning chef of the Bistro Lyonnais.  Pernod's barman of the year will also be operating in the VIP marquee - (will he drop one of those bottles when hes juggling?) - offering new takes on the cocktail theme.\n\n \n\nThe entertainment throughout the weekend is of such a high standard that we have already been taking bookings for the festival from the States, Europe as well as the UK.  We have four of the Reinhardts appearing, (including David, Djangos grandson and inheritor of his talent), and a host of the very top players in the world - some have never been persuaded to come to the UK before, we do have a very special weekends entertainment here.  The full line up and other details can be found on the website at www.lespritmanouche.com. \n\n \n\nWe, and the charity, would greatly appreciate the chance to provide yourselves with a great weekend out.  The lives of the people benefiting from the work of the charity can be improved by you having a good time - please phone me on 0121 249 2303 to arrange your tickets.\n\n \n\n \n\nDavid Alexander\n\n\n\n"
        },
        {
            "subject": "Color correction comments on the PNG spec 2nd ed. P",
            "content": "Quotes from http://www.w3.org/TR/2003/PR-PNG-20030520/\n\n> It is recommended that explicit gamma information also be provided \n> when either the first or second methods is used, for use by PNG \n> decoders that do not support full ICC profiles or the sRGB colour \n> space. Such PNG decoders can still make sensible use of gamma \n> information. PNG decoders are strongly encouraged to use this \n> information, plus information about the display system, in order to \n> present the image to the viewer in a way that reproduces what the \n> image's original author saw as closely as possible.\n\nI think it would be appropriate to warn implementors about the \nundesirable consequences of focusing only on PNG colors when the the \nPNG image is presented in some larger graphical context such as a \nHTML+CSS page or an SVG graphic. Inconsistent color within such an \naggregate document looks worse than the colors of the entirety being \nslightly off but consistently.\n\n> When the incoming image has unknown gamma (gAMA, sRGB, and iCCP all \n> absent), choose a likely default gamma value, but allow the user to \n> select a new one if the result proves too dark or too light. The \n> default gamma may depend on other knowledge about the image, for \n> example whether it came from the Internet or from the local system.\n\nInstead of recommending guessing a \"likely value\", I think it would be \nbetter to recommend that decoding applications that also handle other \ncolor sources (eg. GIF, JFIF, CSS) treat the color values of unlabeled \nPNGs consistently with other other unlabeled color sources. That is, it \nwould be desirable for a given RGB value to be presented as the same \ncolor in a Web browser regardless of the RGB values source (CSS, \nunlabeled JFIF, GIF, unlabeled PNG) in order to be able to mix various \ncolor sources in a design.\n\nThe original PNG specification emphasized doing *something* with gamma \nover making PNG images look good as components of a larger web page \ndesign. As a result, some browsers (eg. Safari, older versions of Opera \nand some really old Mac builds of Mozilla) treat PNG colors \ninconsistently compared to all other color sources reducing the \nusefulness of PNG images as components of larger designs. (More at \nhttp://iki.fi/hsivonen/png-gamma.html)\n\n-- \nHenri Sivonen\nhsivonen@iki.fi\nhttp://www.iki.fi/hsivonen/\n\n\n\n"
        },
        {
            "subject": "test of new archiv",
            "content": "-- \nGerald Oskoboiny     http://www.w3.org/People/Gerald/\nWorld Wide Web Consortium (W3C)    http://www.w3.org/\ntel:+1-613-261-6630             mailto:gerald@w3.org\n\n\n\n"
        },
        {
            "subject": "IPsmarx Technologies Inc. Canad",
            "content": "IPsmarx Turnkey Calling Card Solution including VOIP Billing Software, Hardware, Installation and Carrier services:\n\nCompatible with Cisco and Quintum hardware. Calling Card platform offers Prepaid-Postpaid software including RADIUS/AAA, TFTP, IVR at a reasonable price. Our billing software for Calling Card platform runs on Windows 2000 and on MS- SQL2000. \n\nOffering Basic and also Advanced features like Web access for caller or Agent, Caller ID/PIN-less, Home Services, etc.\n\nFor more information about our Calling Card, Termination or Callshop Solutions email us to   peter@ipsmarx.com or call us at 416-665-6999. \n\nNovember Promotion: FREE installation plus two extra features (Web-access, PIN-less, Home Services, etc)\n\nWebsite: www.ipsmarx.com\n\n\nIf this email has reached you in error please let me know and it will not happen again.\n\n\n\n"
        },
        {
            "subject": "Mistake in Table 11.",
            "content": "In Table 11.1 on http://www.libpng.org/pub/png/spec/iso/ ,\n  the \"PNG image type\" for \"Colour type\" 4 is stated as\n  \"Greyscale with colour\".  This cleary should read\n  \"Greyscale with alpha\".\n\n__________________________________\nDo you Yahoo!?\nThe New Yahoo! Shopping - with improved product search\nhttp://shopping.yahoo.com\n\n\n\n"
        },
        {
            "subject": "Request for LinkExchang",
            "content": "Hi,\n\nI visited your www.libpng.org website.\n\n\n\nI am requesting a Reciprocal Link Exchange between your web-site and mine. \n\nI've added your website's listing to my link directory:\nhttp://www.zangtechnologies.com/links/ThemeIndex.html. \n\nThe listing is in the Education theme at this page:\nhttp://www.zangtechnologies.com/links/education.html. \n\nMy website is:\nhttp://www.zangtechnologies.com/.\n\nRegards,\nMick Sweeney\nsupport@zangtechnologies.com\nhttp://www.zangtechnologies.com/\n\nWe are a Technical Services Solution Company with over 14 years expearance in the IT Field, Specialising in Web-based CCD security.\nAnd design, construction and Maintenance of website's.\n\n\nInfo to add my website's link to your website:\nhttp://www.zangtechnologies.com/linkinfo.htm\n\nA link you might be interested in to increase your website's traffic:\n\n\n--------------------------------\n\n\n..\n\n\n\n"
        },
        {
            "subject": "Guilty? You Decide",
            "content": "Whether you've heard about us before or even if you've already seen it,\n\nNOW IS THE TIME TO COME TO FLEMINGTON, NJ!\n\n \n\nDID BRUNO HAUPTMANN\nKILL THE LINDBERGH BABY?\n\n \n\nHistory Comes Alive and\nYOU ARE THE JUDGE!\n \n\nat\n\nTHE TRIAL OF THE CENTURY\n \n\nSEPTEMBER 20 - OCTOBER 12\nShows at 2 & 8 PM Saturdays\n2 PM Sundays\n\n \n\nTHE TRIAL OF THE CENTURY is a live, 2 ? hour re-enactment of the famous 1935 kidnapping trial of Bruno Hauptmann for the murder of Charles Lindbergh, Jr., staged in the original historic courtroom where the trial actually took place!  Critics have raved about this undiscovered gem, and you will too.\n\n \n\nAfter twelve years and many thousands of enthralled audience members, THE TRIAL OF THE CENTURY will present its last season before the courthouse is closed for renovations.  We're not sure when we'll back, so don't miss this opportunity to catch it before it's too late.  \n\nTickets $25 - Jury Seats $35\n\n \n\nFor more information, visit our website at www.famoustrials.com where you can order tickets, or call 908-782-2610 for the latest updates on tickets, tours and others events in Flemington, NJ.  \n\n \n\n\"New Jersey's most vivid example of site-specific theater.\" - THE N. Y. TIMES\n\n\"Lindbergh Trial Performance is like being there\" - THE STAR-LEDGER\n\"When you go away wanting more, that means it was good.\" - THE TRENTONIAN\n\n\"Lindbergh:  Real Trial of the Century.\" - LOS ANGELES TIMES\n\n\n\n"
        },
        {
            "subject": "Fwd: [png-list] proposed-license-keyword2004071",
            "content": "This is a forwarded message\nFrom: Glenn Randers-Pehrson <glennrp@comcast.net>\nTo: png-list@ccrc.wustl.edu\nDate: Saturday, April 17, 2004, 2:43:40 PM\nSubject: [png-list] proposed-license-keyword-20040717\n\n===8<==============Original message text===============\n\nI have posted a proposal for the \"License\" PNG keyword at\nhttp://pmt.sf.net/proposals/proposed-license-keyword-20040417.txt\n\nThis message begins the PNG group's formal 2-week discussion period.\nI will send a hard copy to the registration authority at INRIA.\n\nHere's a copy:\nproposed-license-keyword-20040417.txt\n\nProposed new PNG text keyword\n\nLicense\n   Either the full text license granted by the copyright holder\n   or the title or abbreviated title of a published license, along\n   with a URL pointing to it.  The URL should begin after a newline.\n   Long URLs should not be wrapped even if they exceed 79 characters.\n\n\n\n--\nSend the message body \"help\" to png-list-request@ccrc.wustl.edu\n\n===8<===========End of original message text===========\n\n\n\n-- \n Chris Lilley                    mailto:chris@w3.org\n Chair, W3C SVG Working Group\n Member, W3C Technical Architecture Group\n\nattached mail follows:\n\nmessage/rfc822 attachment: 1.msg\n\n\n\n\n"
        },
        {
            "subject": "delivery and archiving tes",
            "content": "Hello png-group,\n\nThis is a test\n\n-- \n Chris Lilley                    mailto:chris@w3.org\n Chair, W3C SVG Working Group\n Member, W3C Technical Architecture Group\n\n\n\n"
        },
        {
            "subject": "Text Keyword Proposal: &quot;ID&quot",
            "content": "Dear Sir,\n\nWe would like to propose either a new tEXt keyword for the PNG\n\"extended\" standard.\n\n\"ID\" / \"Id\"\n\nThe basic idea is that each image can be \"tagged\" for easy reference in\na database. This frees people from the reliance on checksums and\nfilenames to identify images.\n\nThis will be used (and a couple of other international groups partnering\nwith us) to track our images by content and not filenames, which may\nchange. What we are doing is digitally preserving computer software\npackaging (boxes, disk labels, manuals, etc.) for cataloguing and\narchival.\n\nHowever, we can see that this can have very wide application outside our\nown use.\n\nFor us, the information will only be used by automated tools, and will\nbe used as a number format, but we can also see the use in it being\nused as a human viewable alphanumeric keyword.\n\nPlease could you advise us if this would be a likely addition, and if\nso, roughly how long it would take to implement it?\n\nThank you for your time,\n \nYours faithfully,\n\nKieron Wilkinson\nkieron@caps-project.org\nThe Classic Amiga Preservation Society\nhttp://www.caps-project.org\n\n\n\n"
        },
        {
            "subject": "stole",
            "content": "here\n\n\n\n\napplication/x-zip-compressed attachment: misc.zip\n\n\n\n\n"
        },
        {
            "subject": "THE LAST MESSAGE *stolen* Virus Aler",
            "content": "Please do not click the attachement misc.zip -file\n\nThere is a virus W32.Netsky.B@mm in it.\n\nThank you\nRalph\nWebmaster\nhttp://www.gif.org\n\n\n\n"
        },
        {
            "subject": "pngfileheade",
            "content": "Hi\n\n\n\n            I need png file header structure inorder to read the raw\ndata form the png file.\n\n\n\nRegards\n\nramanaji\n\n\n\nConfidentiality Notice\n\nThe information contained in this electronic message and any attachments to this message are intended\nfor the exclusive use of the addressee(s) and may contain confidential or privileged information. If\nyou are not the intended recipient, please notify the sender at Wipro or Mailadmin@wipro.com immediately\nand destroy all copies of this message and any attachments.\n\n\n\n"
        },
        {
            "subject": "Please Join My Superb Yahoo Forums",
            "content": "Greetings,\n\nI'm posting you to ask that you take the time to join two of the GREATEST FORUMS IN THE HISTORY OF CYBERSPACE!!\n\nThe first list is an information and discussion list called \"\n\nhttp://groups.yahoo.com/group/TheBigPicture2003/?yguid=132698554 \" We are a\n\nlittle over 2,790 strong now and growing rapidly daily.\n\nOur focus there is discussing the GREAT issues in life that confuse and perplex most human beings. We give them answers on how to see the BIG PICTURE in life and live a much more richer and fulfilling life style.\n\nWe are looking for things that we can do to make sure that our mental\nhealth and self esteem remains high while we struggle to clear the cobwebs and misprogramming from our minds. and change this most unequitable system. We also promote networking between honest, ethical, law abiding business people.\n\nThe second list you should peruse is named :\n\"http://groups.yahoo.com/group/NBCOCEPPLSI/ \"\n\nPlease pass the word around about these highly informative lists. Everyone is\nwelcome to join.\n\nThank you very much for taking the time to look over this information. I\nlook forward to getting to know you on the above lists.\n \nBe careful! Strive to be happy. Despite all of the sham, trickery, lies, drudgery, and broken dreams, America is still a beautiful place to live!\n\nShlala Gashle!\n\nWS\n\nAS SEEN ON TV!\n\nLegal Coverage is a force... mightier than gravity!\n\nInnovative services for individuals, families, and businesses\n\nBuild for the future!  Securely protected by us!\n\nGet access to top LAWFIRMS across North America for less than a cup of coffee per day!\n\nhttp://www.wtatours.com\n\nThe National black Chamber of Commerce said on November 24, 2003 that ths information available at \n this website directly below is the best way for young African Americans\nto get off to a great LEGAL, start financially at a YOUNG age.\nThey said that PPLSI is the #1 best inexpensive Biz Op today in America for African Americans.\n\nhttp://www.wtatours.net\n\n-------------------------------------------------------------------------------------------------------------------------\nwww.wtatours.org\nwww.babyboomerboogie.com\n\nCheck  out  companies at this URL to make sure they are legitimate:\nwww.ftc.gov\nwww.betterbusinessbureau.com\n\n\n\n"
        },
        {
            "subject": "H",
            "content": "Mail transaction failed. Partial message is available.\n\n\n\n\n\n\napplication/octet-stream attachment: document.zip\n\n\n\n\n"
        },
        {
            "subject": "tes",
            "content": " \n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nwww.Intercore.net\n\nComputer Consultant Los Angeles\n\nwww.Avidware.net\n\nSecurity Consultant Los Angeles\n\nwww.Avidware.com\n\nBusiness Consultant Los Angeles\n\nwww.FastForwardMarcom.com\n\nLos Angeles Computer Consultant\n\nhttp://www.computernetworkingsolutions.net/\n\nWebsite Developer Los Angeles\n\nwww.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nwww.CorpLeasing.com\n\nEmergency Network Recovery Consultant Los Angeles\n\nwww.FreePublicLinks.com/Wicky/index.pl\n\n \n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "Re: tes",
            "content": "It is working\n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nhttp://www.Intercore.net\n\nComputer Consultant Los Angeles\n\nhttp://www.Avidware.net\n\nSecurity Consultant Los Angeles\n\nhttp://www.Avidware.com\n\nBusiness Consultant Los Angeles\n\nhttp://www.FastForwardMarcom.com\n\nWebsite Developer Los Angeles\n\nhttp://www.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nhttp://www.CorpLeasing.com\n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "Looking to driv",
            "content": " \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Development of platform-independent applications - workshop more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "Low Fixed Cost No. 1 Search Engine Ranking for keywords related to &quot;porn&quot",
            "content": "This is an HTML message.\n\n\n\n"
        },
        {
            "subject": "Backup Bookmark",
            "content": "Bookmark For Backup\n\n\nhttp://www.chrissysbedroom.com/\nhttp://www.blowjobphone.com/\nhttp://www.livephonedomination.com/\nhttp://www.phonefeminization.com/\nhttp://www.taboophonefetishes.com/\nhttp://your-account.info/\nhttp://www.phone-sex-guestbook.com/\nhttp://www.highclassblondes4phone.com/\nhttp://www.dominatingphonebitches.com/\nhttp://duvx.com/book.php?book=phonesex/\nhttp://www.xanga.com/usa_phone_sex/\nhttp://www.xanga.com/phone_sex_seeker/\nhttp://www.phone-sex-blog.blogspot.com/\nhttp://duvx.com/bbs.php?bbs=phone/\nhttp://www.voy.com/144830/\nhttp://www.voy.com/178346/\n\n\nhttp://www.angelfire.com/nv/Chess/chess.html\nhttp://www.angelfire.com/pop2/xslt/\nhttp://www.angelfire.com/grrl/edenprosper/\nhttp://www.angelfire.com/nv/violins/violin_bows.html\nhttp://www.angelfire.com/nv/bowling/tips.html\nhttp://www.angelfire.com/tv/julia/julia.louis.dreyfus.html\nhttp://www.geocities.com/gothic_clothes/\nhttp://www.geocities.com/bgreen68/\nhttp://www.megaone.com/supermodel/\nhttp://www.geocities.com/self_hypnosis/\nhttp://www.angelfire.com/goth/razorcandi/\nhttp://www.angelfire.com/nv/violins/violin_books.html\nhttp://www.angelfire.com/grrl/raye/\nhttp://www.angelfire.com/goth/gothic_babe/\nhttp://www.angelfire.com/nv/startpage/\nhttp://www.geocities.com/actress_model_olivia/\nhttp://www.geocities.com/somethings_happening/\nhttp://www.geocities.com/kimmyswebsite/\nhttp://www.geocities.com/monique_modeling/\nhttp://www.angelfire.com/pop2/google-dance-tool/\nhttp://www.angelfire.com/art2/blonde_model/\nhttp://www.angelfire.com/art2/catherine/\n\n\n\nhttp://bloggingtips.blogspot.com\nhttp://chinese-food.blogspot.com\nhttp://bowling-tips.blogspot.com\nhttp://www.xanga.com/ringtones\nhttp://xsl2.blogspot.com\nhttp://www.xanga.com/free_ringtones\nhttp://www.senac.com/forums/4055/\nhttp://www.senac.com/forums/12254/\nhttp://www.senac.com/forums/1310/\nhttp://www.senac.com/forums/5283/\nhttp://www.senac.com/forums/13432/\n\n\n\nhttp://funny-quotes.blogspot.com\nhttp://woody-allen.blogspot.com\nhttp://george-carlin.blogspot.com\nhttp://johnny_carson.blogspot.com\nhttp://david-letterman.blogspot.com\nhttp://oscar-levant.blogspot.com\nhttp://groucho-marx.blogspot.com\nhttp://mary-richards.blogspot.com\nhttp://joan-rivers.blogspot.com\nhttp://mark-twain.blogspot.com\nhttp://oscar-wilde.blogspot.com\nhttp://henny-youngman.blogspot.com\n\n\nhttp://www.FindPhonesex.com\nhttp://www.FantasyPhoneCalls.com\nhttp://www.PhonesexBabydolls.com\nhttp://www.PhonesexBootyCalls.com\nhttp://www.GirlsPhoneNumbers.com\nhttp://www.Youngstuff4Phone.com\nhttp://www.StrictlyDommes.com\nhttp://216.247.166.167/hotmaturemomma/main.htm\nhttp://www.JosiesPussycats.com\nhttp://www.PussycatCalls.com\n\n\n\n"
        },
        {
            "subject": "test messag",
            "content": "Hi.\n\nTesting the creation of the pso-discuss@w3.org list.\n\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle",
            "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n"
        },
        {
            "subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle",
            "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n"
        },
        {
            "subject": "e Mortgage Rates Are Falling! njg",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Fwd: PSO Procotol Council representative to ICANN Boar",
            "content": "For the archives....\n\n>Resent-Date: Tue, 10 Sep 2002 09:19:32 -0400 (EDT)\n>X-Sender: amy@localhost\n>X-Mailer: QUALCOMM Windows Eudora Version 5.0\n>Date: Tue, 10 Sep 2002 09:21:04 -0400\n>To: \"Stuart Lynn\" <lynn@icann.org>, <touton@icann.org>,\n>         \"'Francisco A. Jesus Silva'\" <francisco-a-silva@telecom.pt>,\n>         \"Paul Hoffman\" <paul.hoffman@vpnc.org>, pso-pc@w3.org\n>From: Amy van der Hiel <amy@w3.org>\n>Subject: PSO Procotol Council representative to ICANN Board\n>Resent-From: pso-pc@w3.org\n>X-Mailing-List: <pso-pc@w3.org> archive/latest/36\n>X-Loop: pso-pc@w3.org\n>Sender: pso-pc-request@w3.org\n>Resent-Sender: pso-pc-request@w3.org\n>List-Id: <pso-pc.w3.org>\n>List-Help: <http://www.w3.org/Mail/>\n>List-Unsubscribe: <mailto:pso-pc-request@w3.org?subject=unsubscribe>\n>\n>\n>Dear All,\n>\n>Following the teleconference of the PSO Protocol Council on 3 September, \n>2002, this is to announce the results of the selection of the PSO Council \n>representative to the ICANN Board.\n>\n>The PSO Protocol Council Members would like to thank both candidates: Mr. \n>Paul Hoffman and Mr. Francisco da Silva.\n>\n>After extensive discussions, the Protocol Council achieved consensus to \n>nominate Mr. Francisco da Silva as the PSO Council representative to the \n>ICANN Board for the three-year term beginning October 1, 2002.\n>\n>We congratulate Mr. Francisco da Silva on his nomination.\n>\n>Sincerely,\n>\n>Amy van der Hiel, PSO Secretary\n>\n>\n>--\n>Amy van der Hiel\n>amy@w3.org\n>W3C/MIT 200 Technology Square, Cambridge, MA 02139 USA\n>telephone: +1.617.253.5628  fax: +1.617.258.5999\n\n-- \nAmy van der Hiel\namy@w3.org\nW3C/MIT 200 Technology Square, Cambridge, MA 02139 USA\ntelephone: +1.617.253.5628  fax: +1.617.258.5999\n\n\n\n"
        },
        {
            "subject": "Cut Credit Card Debt 50%  No Loan Req",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "Re: another idea for the URN approach to local UIDs in bookmark",
            "content": "Eric Prud'hommeaux wrote:\n>\n> Do you know what other protocols use this uuid scheme? That it is\n> specified (and even have algorithms and code) makes it appealing for\n> this application. But if there some other protocols that use it, we\n> may discover opportunities to re-use parts of those protocols as well.\n\nOSF DCE RPC uses UUIDs (but do people use DCE?)\n\nIt is used in various LDAP implementations to tag attribute values in a \nunique way (typically to support server-to-server replication or \nclient-to-server synchronization).  Some of these uses are now being \nproposed as standards in the IETF, e.g.,\n\n   http://www.ietf.org/internet-drafts/draft-ietf-ldup-lcup-06.txt\n   http://www.ietf.org/internet-drafts/draft-zeilenga-ldap-uuid-03.txt\n\nUUIDs are also used in COM (by Microsoft and others) as unique identifiers\nfor C++ interface definitions, etc.  And also in many XML based efforts (but\nI don't know the details).\n\n\n> We were looking for something more shapely, and with nicer colors, but\n> maybe if there's already code we'll forgo aesthetics this time.\n\nUnderstood.\n\n-- \nMark Smith\nLDAP Book Information: http://www.ldapbook.com/\nWhat's Next:           http://www.pearlcrescent.com/\n\n\n\n"
        },
        {
            "subject": "Re: another idea for the URN approach to local UIDs in bookmark",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nMark Smith wrote:\n\n|\n| Jose Kahan wrote:\n|  >\n|\n|> What is easier to have, a fail-safe mechanism to produce URNs or\n|> some well specified processing? If it's the former, then let's go\n|> forward with URNs (and send a follow-up message on how to do it :).\n|> Maybe you'd like to adopt the same mechanism used to generate msgids\n|> by some mail client?\n|>\n|> I'm basically proposing that the applications do the same job\n|> that the server does when you publish something and it attributes\n|> a new URL.\n|\n|\n| I do not have an opinion about which approach is better for the bookmark\n| local/global ID problem.  But generating globally unique UUIDs is\n| something that quite a few applications and protocols do, and the most\n| widely used algorithm is described here:\n|\n|   http://www.ietf.org/internet-drafts/draft-mealling-uuid-urn-03.txt\n|\n| Sample C code is included in that Internet Draft.  The UUID-based URIs\n| won't be pretty (e.g., urn:uuid:f81d4fae-7dec-11d0-a765-00a0c91e6bf6)\n| but they should be globally unique.\n|\nmaybe urn-5 would be worth considering too, it has a random part and a\nlocal part wich could be used to identify an individual bookmark (and\nmaybe translated to a fragment identifier when moving to a conventional\nlocalizable file).\n\nhttp://www.iana.org/assignments/urn-informal/urn-5\n\ncheers,\nreto\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.2.1 (Darwin)\nComment: Using GnuPG with Mozilla - http://enigmail.mozdev.org\n\niD8DBQFAbJWwD1pReGFYfq4RAneqAKCn1GzdhhXPyRSUICAz68HqzJc0ogCghYRE\nLKpMT+Dp07CczjF8FOxiZL0=\n=Nji7\n-----END PGP SIGNATURE-----\n\n\n\n"
        },
        {
            "subject": "Re: [Moderator Action] another idea for the URN approach to   local UIDs in bookmark",
            "content": "At 09:07 AM 3/31/2004 -0500, Eric Prud'hommeaux wrote:\n\n... Jose's suggestion for bookmark base deleted ...\n\n> >\n> > Does this make sense to you compared to the previous URN approach?\n> > It puts a bigger burden on the application, but makes things work\n> > even if a file moves around... and it removes the burden from us\n> > of guaranteeing we have a unique URN for each item.\n>\n>I think this is an interesting technique, and I'm glad to have worked\n>through the details of it, but I think we still need the URN approach\n>to deal with the scenario of documents that are shared before they get\n>a universal name. For instances, a user could queue mail containing a\n>local form (not yet named with a non-local name) while still on the\n>plane [1].\n\nI agree with Eric, it is an interesting approach but it does not solve the \nlocal file: URI problem.\nIf I first use local \"file:\" URIs and then publish a file globally with \nglobal \"http:\" URIs and an owl:sameAs reference to the previous \nlocal  \"file:\" URI it does not make the local file: URIs any different. \nThey are still ambiguous in the global context.\n\nFor instance. the scenario where the user makes a bookmark locally into one \nbookmark file and uses a topic from another local bookmark file and \npublishes these files some time later to the Web would still have problems \nwith the bookmark base solution. Furthermore, it would be impossible to \nknow if we are talking about a same topic or a different one based on the \nlocal file: URIs if we would like to find it out.\n\nMarja\n\n\n>Perhaps this approach addresses the mailed-local scenario in a way I\n>haven't spotted.\n>\n>[1] http://www.w3.org/2003/12/20-local-global.html#L153\n>--\n>-eric\n>\n>office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n>                         Shonan Fujisawa Campus, Keio University,\n>                         5322 Endo, Fujisawa, Kanagawa 252-8520\n>                         JAPAN\n>         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n>cell:   +1.857.222.5741 (does not work in Asia)\n>\n>(eric@w3.org)\n>Feel free to forward this message to any list for any purpose other than\n>email address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: another idea for the URN approach to local UIDs in bookmark",
            "content": "Anyone have any criteria for evaluating which of uuid-urn [1]\n eg urn:uuid:f81d4fae-7dec-11d0-a765-00a0c91e6bf6\nor urn-5 [2]\n  eg urn:urn-n:JtTCacwJ1e1N0yqTULRG7C1GLq8 or\n     urn:urn-n:JtTCacwJ1e1N0yqTULRG7C1GLq8:4\nwill be better? We were planning on using the urn with a fragment\nidentifier to differentiate the different parts of an bookmark or\nmaybe even mulitple bookmarks in the same file. I'm tempted to use\nwhich ever has more protocols using it that we would like to share\ncode with.\n\n[1] http://www.ietf.org/internet-drafts/draft-mealling-uuid-urn-03.txt\n[2] http://www.iana.org/assignments/urn-informal/urn-5\n\nOn Fri, Apr 02, 2004 at 12:20:53AM +0200, Reto Bachmann-Gmuer wrote:\n> \n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA1\n> \n> Mark Smith wrote:\n> \n> |\n> | Jose Kahan wrote:\n> |  >\n> |\n> |> What is easier to have, a fail-safe mechanism to produce URNs or\n> |> some well specified processing? If it's the former, then let's go\n> |> forward with URNs (and send a follow-up message on how to do it :).\n> |> Maybe you'd like to adopt the same mechanism used to generate msgids\n> |> by some mail client?\n> |>\n> |> I'm basically proposing that the applications do the same job\n> |> that the server does when you publish something and it attributes\n> |> a new URL.\n> |\n> |\n> | I do not have an opinion about which approach is better for the bookmark\n> | local/global ID problem.  But generating globally unique UUIDs is\n> | something that quite a few applications and protocols do, and the most\n> | widely used algorithm is described here:\n> |\n> |   http://www.ietf.org/internet-drafts/draft-mealling-uuid-urn-03.txt\n> |\n> | Sample C code is included in that Internet Draft.  The UUID-based URIs\n> | won't be pretty (e.g., urn:uuid:f81d4fae-7dec-11d0-a765-00a0c91e6bf6)\n> | but they should be globally unique.\n> |\n> maybe urn-5 would be worth considering too, it has a random part and a\n> local part wich could be used to identify an individual bookmark (and\n> maybe translated to a fragment identifier when moving to a conventional\n> localizable file).\n> \n> http://www.iana.org/assignments/urn-informal/urn-5\n> \n> cheers,\n> reto\n> -----BEGIN PGP SIGNATURE-----\n> Version: GnuPG v1.2.1 (Darwin)\n> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org\n> \n> iD8DBQFAbJWwD1pReGFYfq4RAneqAKCn1GzdhhXPyRSUICAz68HqzJc0ogCghYRE\n> LKpMT+Dp07CczjF8FOxiZL0=\n> =Nji7\n> -----END PGP SIGNATURE-----\n\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "reasonings for current local/global URI suggestio",
            "content": "Jose asked me to explain the last changes I did to the local/global URI \ndocument (http://www.w3.org/2003/12/20-local-global.html) selected \nsolution. Here is the reasoning.\n\n-- Starting point:\nI first gave a URN to a local (unpublished) bookmark by using\n\n<r:Description r:about=\"urn:uid:xxxxbm1\">\n   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n</r:Description>\n\nThen I want to publish the bookmark and give it also an HTTP URI in \naddition to the URN. But I'm not sure what is the best way to give an \nobject several IDs. My understanding is you can only have one r:id or r:about.\n\n-- First try:\nI tried first to publish the bookmark with an additional URI that is now \ngoing to be used instead of the URN but keep the URN as a reference if \nneeded. I tried to do it without changing the whole definition but merely \nadding some new info:\n\n<r:Description r:about=\"urn:uid:xxxxbm1\">\n   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n   <owl:sameAs r:resource=\"bm1\"/>\n</r:Description>\n\nBut if I understand it right the <owl:sameAs r:resource=\"bm1\"/>  is not \nreally giving the bookmark and HTTP URI just referring to an already \nexisting URI. So I'm not sure how we expect a browser to react if I try to \ngive it http://...#bm1 after the above definition?\n\n-- Current suggestion\nI thought that maybe it is better to give a fragment URI with r:id already \nat the beginning but just not use it while it is local (not published). \nThis saves as from changing that part of the file when it is published. We \nstill may want to change the URN topic references when we can as is done here.\n\n<r:Description r:id=\"bm1\">\n   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n   <b:hasTopic r:resource=\"#bbbbtopic1\"/>\n   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n</r:Description>\n\nSo this simply defines the fragment URI earlier in addition to the URN to \nhelp prevent changes and define an HTTP ID. For some reason referring to a \nURN with owl:sameAs does not bother me as much as to a fragment ID but \nmaybe it should.\n\n-- Possible next step\nThe last step was seeing if the URN and the URI could be somehow related. I \nthought it would be helpful. It may be that it only helps to create \nunambiguous fragment IDs automatically. If you know the HTTP URI you also \nknow the URN, but you can get that info from the metadata definitions \nanyway. On the other hand knowing the URN does not help to totally solve \nthe HTTP URI unless you also know the base (path) before the fragment.\n\n<r:Description r:id=\"urn%3Auid%3Axxxxbm1\">\n   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n</r:Description>\n\nThe topic here may refer to a fragment ID if it is defined in the same file \nor to a published HTTP URI. Otherwise it needs to refer to a URN that can \nhelp to retrieve the rest of the information unless it has not been \npublished or cannot be found.\n\nMarja\n\n\n\n"
        },
        {
            "subject": "Other ideas, comments to local/global URI suggestion",
            "content": "This stills needs some thinking:\n\nThe main problem is that I would like to give one object two ID's (one of \nthem always unambiguous) either when it is created or at first give an \nunambiguous ID and then later a second ID.\n\nHaving to create two objects with an ID and then say they are the same \nseems to be a bit too much work when you only want to give a second ID. How \nare other people dealing with this?\n\nAnd the starting point for this was the file:// URI not being unambiguous. \nBut maybe that could be corrected too so that it solves our problems.\n\nMarja\n\nAt 12:21 AM 4/9/2004 -0400, Marja-Riitta Koivunen wrote:\n\n>Jose asked me to explain the last changes I did to the local/global URI \n>document (http://www.w3.org/2003/12/20-local-global.html) selected \n>solution. Here is the reasoning.\n>\n>-- Starting point:\n>I first gave a URN to a local (unpublished) bookmark by using\n>\n><r:Description r:about=\"urn:uid:xxxxbm1\">\n>   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n>   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n></r:Description>\n>\n>Then I want to publish the bookmark and give it also an HTTP URI in \n>addition to the URN. But I'm not sure what is the best way to give an \n>object several IDs. My understanding is you can only have one r:id or r:about.\n>\n>-- First try:\n>I tried first to publish the bookmark with an additional URI that is now \n>going to be used instead of the URN but keep the URN as a reference if \n>needed. I tried to do it without changing the whole definition but merely \n>adding some new info:\n>\n><r:Description r:about=\"urn:uid:xxxxbm1\">\n>   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n>   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n>   <owl:sameAs r:resource=\"bm1\"/>\n></r:Description>\n>\n>But if I understand it right the <owl:sameAs r:resource=\"bm1\"/>  is not \n>really giving the bookmark and HTTP URI just referring to an already \n>existing URI. So I'm not sure how we expect a browser to react if I try to \n>give it http://...#bm1 after the above definition?\n>\n>-- Current suggestion\n>I thought that maybe it is better to give a fragment URI with r:id already \n>at the beginning but just not use it while it is local (not published). \n>This saves as from changing that part of the file when it is published. We \n>still may want to change the URN topic references when we can as is done here.\n>\n><r:Description r:id=\"bm1\">\n>   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n>   <b:hasTopic r:resource=\"#bbbbtopic1\"/>\n>   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n></r:Description>\n>\n>So this simply defines the fragment URI earlier in addition to the URN to \n>help prevent changes and define an HTTP ID. For some reason referring to a \n>URN with owl:sameAs does not bother me as much as to a fragment ID but \n>maybe it should.\n>\n>-- Possible next step\n>The last step was seeing if the URN and the URI could be somehow related. \n>I thought it would be helpful. It may be that it only helps to create \n>unambiguous fragment IDs automatically. If you know the HTTP URI you also \n>know the URN, but you can get that info from the metadata definitions \n>anyway. On the other hand knowing the URN does not help to totally solve \n>the HTTP URI unless you also know the base (path) before the fragment.\n>\n><r:Description r:id=\"urn%3Auid%3Axxxxbm1\">\n>   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n>   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n>   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n></r:Description>\n>\n>The topic here may refer to a fragment ID if it is defined in the same \n>file or to a published HTTP URI. Otherwise it needs to refer to a URN that \n>can help to retrieve the rest of the information unless it has not been \n>published or cannot be found.\n>\n>Marja\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: reasonings for current local/global URI suggestio",
            "content": "Marja,\n\nI finally understood what you were trying to say so I can give you\nnow my feedback.\n\nOn Fri, Apr 09, 2004 at 12:21:53AM -0400, Marja-Riitta Koivunen wrote:\n> \n> Jose asked me to explain the last changes I did to the local/global URI \n> document (http://www.w3.org/2003/12/20-local-global.html) selected \n> solution. Here is the reasoning.\n\n[cutting all the preliminary work and just leaving the final suggestion]\n> \n> <r:Description r:id=\"bm1\">\n>   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n>   <b:hasTopic r:resource=\"#bbbbtopic1\"/>\n>   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n> </r:Description>\n\nThis one won't work well if you change the location of the bookmark\nfile  because we can't assume how an RDF parser will parse/serialize.\nIn Redland's case, it will make complete URIs out of fragments.\nIf you make a bookmark that belongs to a topic, it will have\na value similar to\n\n <b:hasTopic r:resource=\" nnn://current_location/filename#bbbbtopic1\" />\n\nwhere nnn could be file or http or some other kind of URL type.\n\nThen, if you changed the location of the file, the current location\nwould change and you wouldn't be talking about the same resource because\nany new bookmarks would be using nn:new_location/filename#bbbbtopic1\ninstead of #bbbtopic1 like you intended.\n\nIn order to know that you were using the same resource, you'd need\nto be able to use the owl:sameAs and put more intelligence into\nthe applications. So finally, the work you wanted to save would\nmake things more complex.\n\nAlso, the r:id resolution would be local to a file so if you used\nanother application to describe something about this resource, you'd\nhave the local name, rather than the URN.\n\nIt may be interesting, though, to see if you can use\n\nThus, I think that using \"about:urn\" rather than \"r:id\"\nis still the best solution.  Maybe there's a way to optimize this \nusing r:id, but I haven't given it much thought yet.\n\n[snip]\n\n> -- Possible next step\n> The last step was seeing if the URN and the URI could be somehow related. I \n> thought it would be helpful. It may be that it only helps to create \n> unambiguous fragment IDs automatically. If you know the HTTP URI you also \n> know the URN, but you can get that info from the metadata definitions \n> anyway. On the other hand knowing the URN does not help to totally solve \n> the HTTP URI unless you also know the base (path) before the fragment.\n> \n> <r:Description r:id=\"urn%3Auid%3Axxxxbm1\">\n>   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n>   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n>   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n> </r:Description>\n> \n> The topic here may refer to a fragment ID if it is defined in the same file \n> or to a published HTTP URI. Otherwise it needs to refer to a URN that can \n> help to retrieve the rest of the information unless it has not been \n> published or cannot be found.\n\nBut wouldn't you need to refer to it in this case using a \"#\" if it's\na fragment?\n\n-jose\n\n\n\n"
        },
        {
            "subject": "Re: reasonings for current local/global URI suggestio",
            "content": "At 07:26 PM 4/15/2004 +0200, Jose Kahan wrote:\n\n>Marja,\n>\n>I finally understood what you were trying to say so I can give you\n>now my feedback.\n>\n>On Fri, Apr 09, 2004 at 12:21:53AM -0400, Marja-Riitta Koivunen wrote:\n> >\n> > Jose asked me to explain the last changes I did to the local/global URI\n> > document (http://www.w3.org/2003/12/20-local-global.html) selected\n> > solution. Here is the reasoning.\n>\n>[cutting all the preliminary work and just leaving the final suggestion]\n> >\n> > <r:Description r:id=\"bm1\">\n> >   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n> >   <b:hasTopic r:resource=\"#bbbbtopic1\"/>\n> >   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n> > </r:Description>\n>\n>This one won't work well if you change the location of the bookmark\n>file  because we can't assume how an RDF parser will parse/serialize.\n>In Redland's case, it will make complete URIs out of fragments.\n>If you make a bookmark that belongs to a topic, it will have\n>a value similar to\n>\n>  <b:hasTopic r:resource=\" nnn://current_location/filename#bbbbtopic1\" />\n>\n>where nnn could be file or http or some other kind of URL type.\n>\n>Then, if you changed the location of the file, the current location\n>would change and you wouldn't be talking about the same resource because\n>any new bookmarks would be using nn:new_location/filename#bbbbtopic1\n>instead of #bbbtopic1 like you intended.\n\nMy understanding from our discussion was that it will work when publishing \nthe file but not if we store the topic and bookmarks in the file to a server.\n\nThe idea is that the URN defined by owl:sameAs is always used from outside \nfile references when the file is local and does not have an unambiguous \nHTTP URI. The owl:sameAs URI is as good a URI as the rdf:ID.\n\nWhen we publish the file with a topic and a reference to it only then \nbookmarks outside the file start using the http URI of the topic. When the \nbookmarks and the topic are in the same file the URI base should be the \nsame inside the file no matter where it is moved. But naturally inside \nhasTopic references could as well use the URN too. And outside we said we \nused the URN until the file had a HTTP URI.\n\nOn the other hand if we moved the published file again the URIs would \nchange again and even if the store the history of all locations with \nowl:sameAs like you suggested we might not want that to happen so I'm fine \nwith having full HTTP URIs like you descriped in \nhttp://www.w3.org/Talks/040301Annotea/slide4-0.html. In that case we can \nuse the first HTTP URI s as long as we want, unless we are afraid someone \nstarts reusing them.\n\nIf we store the bookmarks and the topic to a server they would be parsed \nand given new unambiguous HTTP URIs too. The only time I see problems by \nusing fragments is if every object in the file is parsed separately and not \ntogether.\n\n\n>In order to know that you were using the same resource, you'd need\n>to be able to use the owl:sameAs and put more intelligence into\n>the applications. So finally, the work you wanted to save would\n>make things more complex.\n>\n>Also, the r:id resolution would be local to a file so if you used\n>another application to describe something about this resource, you'd\n>have the local name, rather than the URN.\n\nI was leaning in using the URN in the local case especially when referring \nfrom outside the file.\n\n\n>It may be interesting, though, to see if you can use\n>\n>Thus, I think that using \"about:urn\" rather than \"r:id\"\n>is still the best solution.  Maybe there's a way to optimize this\n>using r:id, but I haven't given it much thought yet.\n\nI agree we go back to only giving a URN until the file is published and not \nworrying about changing the RDF.\n\n\n>[snip]\n>\n> > -- Possible next step\n> > The last step was seeing if the URN and the URI could be somehow \n> related. I\n> > thought it would be helpful. It may be that it only helps to create\n> > unambiguous fragment IDs automatically. If you know the HTTP URI you also\n> > know the URN, but you can get that info from the metadata definitions\n> > anyway. On the other hand knowing the URN does not help to totally solve\n> > the HTTP URI unless you also know the base (path) before the fragment.\n> >\n> > <r:Description r:id=\"urn%3Auid%3Axxxxbm1\">\n> >   <recalls r:resource=\"http://sample.example.com/appledoc\"/>\n> >   <b:hasTopic r:resource=\"urn:uid:bbbbtopic1\"/>\n> >   <owl:sameAs r:resource=\"urn:uid:xxxxbm1\"/>\n> > </r:Description>\n> >\n> > The topic here may refer to a fragment ID if it is defined in the same \n> file\n> > or to a published HTTP URI. Otherwise it needs to refer to a URN that can\n> > help to retrieve the rest of the information unless it has not been\n> > published or cannot be found.\n>\n>But wouldn't you need to refer to it in this case using a \"#\" if it's\n>a fragment?\n\nIn the example it refers to the URN of the topic if it refers to the HTTP \nURI it would look like this\n<b:hasTopic r:resource=\"#urn%3Auid%3Abbbbtopic1\"/>\nThis is explained in Figure 17 http://www.w3.org/2003/12/20-local-global.html\n\nMarja\n\n\n>-jose\n\n\n\n"
        },
        {
            "subject": "iggy test server installe",
            "content": "i updated the code on iggy. it might even work now!\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: iggy test server installe",
            "content": "Thanks Eric!\n\nI tested it today and something is still wrong. Not sure if it is the \nserver or the Amaya version.\n\nI do an annotation and post it to iggy.\n\nEverything looks fine except that when I look the document info at \nannotation window it gives me a local address instead of an iggy address. \nHowever, when I close the annotation window the pencil icon disappears.\n\nDid you change the way Amaya is supposed to ask for the annotations now? \nMaybe you could check with Jose that part.\n\nHere is an annotation on iggy that I made with the \n/usr/local/Amaya/GTK/bin/amaya\n\nhttp://iggy.w3.org/annotations/annotation/1083156542.499364\n\nIt looks OK to me in the query interface except that IE cannot open the \nbody when I click the link (I think we had fixed this IE MIME type problem).\n\nMarja\n\nAt 08:03 PM 4/25/2004 -0400, Eric Prud'hommeaux wrote:\n\n>i updated the code on iggy. it might even work now!\n>--\n>-eric\n>\n>office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n>                         Shonan Fujisawa Campus, Keio University,\n>                         5322 Endo, Fujisawa, Kanagawa 252-8520\n>                         JAPAN\n>         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n>cell:   +1.857.222.5741 (does not work in Asia)\n>\n>(eric@w3.org)\n>Feel free to forward this message to any list for any purpose other than\n>email address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: iggy test server installe",
            "content": "Eric,\n\nI think the problem is in my test Amaya version as I can see the annotation \nwith an older stable Amaya version. (We did not have any problems with the \nDC 1.1 annotations even with the older servers just with the DC 1.1 replies \nthat used dc properties in the query.)\n\nI will probably need a corrected Amaya test version before I can continue \ntesting iggy.\n\nI did notice that in \nhttp://iggy.w3.org/annotations/annotation/1083156542.499364 the annotation \nis using DC 1.0 for the creator when it uses DC 1.1 for everything else but \nwhile we do want to correct that to make the conversion final, the queries \nshould still work.\n\nMarja\n\nAt 09:07 AM 4/28/2004 -0400, Marja-Riitta Koivunen wrote:\n\n>Thanks Eric!\n>\n>I tested it today and something is still wrong. Not sure if it is the \n>server or the Amaya version.\n>\n>I do an annotation and post it to iggy.\n>\n>Everything looks fine except that when I look the document info at \n>annotation window it gives me a local address instead of an iggy address. \n>However, when I close the annotation window the pencil icon disappears.\n>\n>Did you change the way Amaya is supposed to ask for the annotations now? \n>Maybe you could check with Jose that part.\n>\n>Here is an annotation on iggy that I made with the \n>/usr/local/Amaya/GTK/bin/amaya\n>\n>http://iggy.w3.org/annotations/annotation/1083156542.499364\n>\n>It looks OK to me in the query interface except that IE cannot open the \n>body when I click the link (I think we had fixed this IE MIME type problem).\n>\n>Marja\n>\n>At 08:03 PM 4/25/2004 -0400, Eric Prud'hommeaux wrote:\n>\n>>i updated the code on iggy. it might even work now!\n>>--\n>>-eric\n>>\n>>office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n>>                         Shonan Fujisawa Campus, Keio University,\n>>                         5322 Endo, Fujisawa, Kanagawa 252-8520\n>>                         JAPAN\n>>         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n>>cell:   +1.857.222.5741 (does not work in Asia)\n>>\n>>(eric@w3.org)\n>>Feel free to forward this message to any list for any purpose other than\n>>email address distribution.\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: iggy test server installe",
            "content": "Marja-Riitta Koivunen wrote:\n\n>\n> Eric,\n>\n> I think the problem is in my test Amaya version as I can see the \n> annotation with an older stable Amaya version. (We did not have any \n> problems with the DC 1.1 annotations even with the older servers just \n> with the DC 1.1 replies that used dc properties in the query.)\n>\n> I will probably need a corrected Amaya test version before I can \n> continue testing iggy.\n>\n> I did notice that in \n> http://iggy.w3.org/annotations/annotation/1083156542.499364 the \n> annotation is using DC 1.0 for the creator when it uses DC 1.1 for \n> everything else but while we do want to correct that to make the \n> conversion final, the queries should still work. \n\nI was hoping someone else would respond and clarify... but since no one \nhas I'll ask:  what is the DC 1.0 vs. 1.1 issue?  Is it just a matter of \nthe server and client working together regardless of which version of \nDublic Core is used?\n\n-Mark\n\n\n\n"
        },
        {
            "subject": "Re: iggy test server installe",
            "content": "Thanks Jose!\n\nAmaya in swada works now. Tried both an annotation and a reply. I really \nappreciate you correcting this Jose. Too bad I did not notice it earlier.\n\nWe have been concentrating on bookmarks so maybe the bug creeped there in \nsome Amaya version that we did not test because there were supposed to be \nno changes. And with all the test versions we have been using it was not \nsurprising to occasionally have problems.\n\nI wonder if  Amaya team would be willing to add a simple annotation test \nfor their preversion tests to prevent this in the future.\n\nMarja\n\nAt 07:48 PM 4/30/2004 +0200, Jose Kahan wrote:\n>Marja,\n>\n>I found a bug, but have really no idea how it creeped in there\n>as I have not touched this code since long time ago. Maybe someone\n>edited it and removed the important lines.\n>\n>Anyway, I fixed the problem and uploaded it to SWADA. Can you\n>test it before I commit the change?\n>\n>Thanks,\n>\n>-jose\n>\n>On Wed, Apr 28, 2004 at 10:01:16AM -0400, Marja-Riitta Koivunen wrote:\n> >\n> > Eric,\n> >\n> > I think the problem is in my test Amaya version as I can see the \n> annotation\n> > with an older stable Amaya version. (We did not have any problems with the\n> > DC 1.1 annotations even with the older servers just with the DC 1.1 \n> replies\n> > that used dc properties in the query.)\n> >\n> > I will probably need a corrected Amaya test version before I can continue\n> > testing iggy.\n> >\n> > I did notice that in\n> > http://iggy.w3.org/annotations/annotation/1083156542.499364 the annotation\n> > is using DC 1.0 for the creator when it uses DC 1.1 for everything else \n> but\n> > while we do want to correct that to make the conversion final, the queries\n> > should still work.\n> >\n> > Marja\n> >\n> > At 09:07 AM 4/28/2004 -0400, Marja-Riitta Koivunen wrote:\n> >\n> > >Thanks Eric!\n> > >\n> > >I tested it today and something is still wrong. Not sure if it is the\n> > >server or the Amaya version.\n> > >\n> > >I do an annotation and post it to iggy.\n> > >\n> > >Everything looks fine except that when I look the document info at\n> > >annotation window it gives me a local address instead of an iggy address.\n> > >However, when I close the annotation window the pencil icon disappears.\n> > >\n> > >Did you change the way Amaya is supposed to ask for the annotations now?\n> > >Maybe you could check with Jose that part.\n> > >\n> > >Here is an annotation on iggy that I made with the\n> > >/usr/local/Amaya/GTK/bin/amaya\n> > >\n> > >http://iggy.w3.org/annotations/annotation/1083156542.499364\n> > >\n> > >It looks OK to me in the query interface except that IE cannot open the\n> > >body when I click the link (I think we had fixed this IE MIME type\n> > >problem).\n> > >\n> > >Marja\n> > >\n> > >At 08:03 PM 4/25/2004 -0400, Eric Prud'hommeaux wrote:\n> > >\n> > >>i updated the code on iggy. it might even work now!\n> > >>--\n> > >>-eric\n> > >>\n> > >>office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n> > >>                        Shonan Fujisawa Campus, Keio University,\n> > >>                        5322 Endo, Fujisawa, Kanagawa 252-8520\n> > >>                        JAPAN\n> > >>        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n> > >>cell:   +1.857.222.5741 (does not work in Asia)\n> > >>\n> > >>(eric@w3.org)\n> > >>Feel free to forward this message to any list for any purpose other than\n> > >>email address distribution.\n> > >\n> > >\n> >\n> >\n\n\n\n"
        },
        {
            "subject": "some more iggy testing problem",
            "content": "Eric,\n\nThe debug feature is really cool!\n\nWhile testing iggy I found couple of more bugs, some of which probably do \nnot come from the server but I listed them here anyway:\n\n1) I have problems in deleting already existing annotations.\n\n2) Annotating\n\nhttp://www.w3.org/2001/Annotea/\n\nand\n\nhttp://www.w3.org/2001/Annotea/Overview.html\n\nare different now. Earlier they were treated the same as they actually are \nthe same file. Not sure if this is an iggy problem.\n\n3) Cannot change the annotation or reply type anymore. But I don't think \nthis has anything to do with iggy.\n\n4) Also while this seems to not cause problems, Jose pointed out that the \nserver replies\n\nHTTP/1.1 201\n\nand not\n\nHTTP/1.1 201 Created\n\nas the protocol doc defines \n(http://www.w3.org/2001/Annotea/User/Protocol.html).\n\nMarja\n\n\n\n"
        },
        {
            "subject": "Re: some more iggy testing problem",
            "content": "At 12:33 PM 5/3/2004 -0400, Marja-Riitta Koivunen wrote:\n>Eric,\n>\n>The debug feature is really cool!\n>\n>While testing iggy I found couple of more bugs, some of which probably do \n>not come from the server but I listed them here anyway:\n>\n>1) I have problems in deleting already existing annotations.\n\nThanks Eric!\n\nDeletion seems to work now. Tested with annotations and replies. Forgot to \nrecord the IDs but hopefully you can still find them if you want to check. \nIf not, I'll generate more and record IDs. At least some annotated \nhttp://www.w3.org/2001/Annotea/.\n\nMarja\n\n\n\n"
        },
        {
            "subject": "updated URN&amp;URI do",
            "content": "Jose,\n\nI updated\n\nhttp://www.w3.org/2003/12/20-local-global.html\n\nto hopefully reflect what you want to do e.g. first just have a URN and \nthen change the file to have HTTP URI and refer to URN with owl:sameAs. \nThis means that if I have a local bookmark file I need to use Annotea \nknowledgeable tools for conversion before I publish it or to do the \ncombined conversion and publishing.\n\nI did not yet change the fragment URIs in the examples to full URIs as I \nthink both can be used and they have their benefits. But that is an easy \nchange to make.\n\nMarja\n\n\n\n"
        },
        {
            "subject": "Re: updated URN&amp;URI do",
            "content": "Marja,\n\nThanks for the changes. See comments below.\n\nOn Wed, May 05, 2004 at 10:06:58AM -0400, Marja-Riitta Koivunen wrote:\n> \n> I updated\n> \n> http://www.w3.org/2003/12/20-local-global.html\n> \n> to hopefully reflect what you want to do e.g. first just have a URN and \n> then change the file to have HTTP URI and refer to URN with owl:sameAs. \n> This means that if I have a local bookmark file I need to use Annotea \n> knowledgeable tools for conversion before I publish it or to do the \n> combined conversion and publishing.\n\nThis convertion is to be done intentionally by the server, if it\ndecides to assign a new URL. The client is not expected to do it at\nthis moment. This gives the freedom for exchanging the bookmark \nfiles thru any means, such as e-mail, ftp, scp, HTTP PUT, ... \nwithout having to go thru a specialized RDF store. Of course, if the\nclient does the convertion there's no problem, but it's not necessary\nto do it to exploit a bookmark file.\n\n> I did not yet change the fragment URIs in the examples to full URIs as I \n> think both can be used and they have their benefits. But that is an easy \n> change to make.\n\nI'd like to have the document reflect the state of what we're going\nto implement rather than diverge. If you want to have those fragment\nID's, please make a case for them. Otherwise, it's better to remove\nthem if this document is intended to report on our modeling and\nimplementation choice.\n\n-jose\n\n\n\n"
        },
        {
            "subject": "Re: iggy test server installe",
            "content": "On Fri, Apr 30, 2004 at 09:00:28AM -0400, Mark Smith wrote:\n> \n> Marja-Riitta Koivunen wrote:\n> \n> >\n> >Eric,\n> >\n> >I think the problem is in my test Amaya version as I can see the \n> >annotation with an older stable Amaya version. (We did not have any \n> >problems with the DC 1.1 annotations even with the older servers just \n> >with the DC 1.1 replies that used dc properties in the query.)\n> >\n> >I will probably need a corrected Amaya test version before I can \n> >continue testing iggy.\n> >\n> >I did notice that in \n> >http://iggy.w3.org/annotations/annotation/1083156542.499364 the \n> >annotation is using DC 1.0 for the creator when it uses DC 1.1 for \n> >everything else but while we do want to correct that to make the \n> >conversion final, the queries should still work. \n> \n> I was hoping someone else would respond and clarify... but since no one \n> has I'll ask:  what is the DC 1.0 vs. 1.1 issue?  Is it just a matter of \n> the server and client working together regardless of which version of \n> Dublic Core is used?\n\nWe're using somthing around DC 1.08 . Less flippantly, we're part way\nthrough migrating from 1.0 to 1.1 . The test server queries for either\n1.0 or 1.1 (which inspired implementing OR which was great fun) and\ngenerates 1.0. The amaya client is publishing annotations with 1.1 and\nparses either 1.0 or 1.1 . After a reasonable deployment interval,\nwe'll switch the server to generating 1.1 for the DC data that it adds.\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n\n"
        },
        {
            "subject": "Re: some more iggy testing problem",
            "content": "On Mon, May 03, 2004 at 12:33:54PM -0400, Marja-Riitta Koivunen wrote:\n> Eric,\n> \n> The debug feature is really cool!\n> \n> While testing iggy I found couple of more bugs, some of which probably do \n> not come from the server but I listed them here anyway:\n> \n> 1) I have problems in deleting already existing annotations.\n\ni think this has been addressed in the last three weeks (sorry for the\ndelayed response).\n\n> 2) Annotating\n> \n> http://www.w3.org/2001/Annotea/\n> \n> and\n> \n> http://www.w3.org/2001/Annotea/Overview.html\n> \n> are different now. Earlier they were treated the same as they actually are \n> the same file. Not sure if this is an iggy problem.\n\nThe server never presumed any association between / and /Overview.html\n(ro any other index file, for that matter). This is document server\nconfiguration that the annotation server can't know anything about. I\nthink Amaya may have had some special knowldege of the www.w3.org, but\nI'm not sure.\n\n> 3) Cannot change the annotation or reply type anymore. But I don't think \n> this has anything to do with iggy.\n> \n> 4) Also while this seems to not cause problems, Jose pointed out that the \n> server replies\n> \n> HTTP/1.1 201\n> \n> and not\n> \n> HTTP/1.1 201 Created\n> \n> as the protocol doc defines \n> (http://www.w3.org/2001/Annotea/User/Protocol.html).\n\nThat's not really up to the protocol doc to define -- that's the\ndomain of the domain of the HTTP spec:\n\n[[ http://www.w3.org/Protocols/rfc2616/rfc2616-sec6.html#sec6.1.1\nThe reason phrases listed here are only recommendations -- they MAY be\nreplaced by local equivalents without affecting the protocol.\n      Status-Code    =\n            \"100\"  ; Section 10.1.1: Continue\n          | \"101\"  ; Section 10.1.2: Switching Protocols\n          | \"200\"  ; Section 10.2.1: OK\n          | \"201\"  ; Section 10.2.2: Created\n...\nReason-Phrase  = *<TEXT, excluding CR, LF>\n]]\n\nI had replaced 'Created' with '', which is technically legal.\nThat said, I had mercy and put in a reason phrase.\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n\n"
        },
        {
            "subject": "Update problem with igg",
            "content": "Discussed this with Eric two weeks ago.\nPromised to send it again here so it is easier to find:\n\nUpdate seems to have the following problem:\nEach change to an annotation creates a new annotation instead of updating \nthe old one e.g.\n\n1) this is the original annotation made with Amaya (body contains \"test \niggy\": http://iggy.w3.org/annotations/attribution/1083803351.895598\n\n2) and this is the same annotation except that \"change\" was added to the \nexisting body text http://iggy.w3.org/annotations/attribution/1083803374.199805\n\nsession ids:\n  <!-- session-id 1083803574.648029\" -->\nand <!-- session-id 1083803787.303193\" -->\n\nThe problem is that we should only see the latter annotation but at the \nmoment we retrieve both from the server.\n\nEarlier Eric confirmed that Amaya uses PUT for the reply updates and POST \nwith replace source parameter for the annotation updates. Although we \nshould really use PUT in both cases they do work, so that should not be the \nproblem.\n\nAnd replies do the dublication too:\n\nAnnotation:\nhttp://iggy.w3.org/annotations/attribution/1085078002.39180\nOrig Reply:\nhttp://iggy.w3.org/annotations/attribution/1085078054.579611\nUpdated Reply:\nhttp://iggy.w3.org/annotations/attribution/1085078066.742406\n\n(Tested in Windows 2000 with Amaya 8.5)\n\nMarja\n\nMarja\n\n\n\n"
        },
        {
            "subject": "Re: iggy test server installe",
            "content": "Eric Prud'hommeaux wrote:\n\n> We're using somthing around DC 1.08 . Less flippantly, we're part way\n> through migrating from 1.0 to 1.1 . The test server queries for either\n> 1.0 or 1.1 (which inspired implementing OR which was great fun) and\n> generates 1.0. The amaya client is publishing annotations with 1.1 and\n> parses either 1.0 or 1.1 . After a reasonable deployment interval,\n> we'll switch the server to generating 1.1 for the DC data that it adds.\n\nThanks for the detailed explanation.  It all makes sense to me.  It \nwould be nice if the server could be \"adaptive\" and send DC 1.0 to older \nclients and DC 1.1 to newer clients (but I do not know how the server \nwould know which flavor to send).\n\n-- \nMark Smith\nLDAP Book Information: http://www.ldapbook.com/\nWhat's Next:           http://www.pearlcrescent.com/\n\n\n\n"
        },
        {
            "subject": "Re: Update problem with igg",
            "content": "On Thu, May 20, 2004 at 02:48:51PM -0400, Marja-Riitta Koivunen wrote:\n> \n> Discussed this with Eric two weeks ago.\n> Promised to send it again here so it is easier to find:\n> \n> Update seems to have the following problem:\n> Each change to an annotation creates a new annotation instead of updating \n> the old one e.g.\n> \n> 1) this is the original annotation made with Amaya (body contains \"test \n> iggy\": http://iggy.w3.org/annotations/attribution/1083803351.895598\n> \n> 2) and this is the same annotation except that \"change\" was added to the \n> existing body text \n> http://iggy.w3.org/annotations/attribution/1083803374.199805\n> \n> session ids:\n>  <!-- session-id 1083803574.648029\" -->\n> and <!-- session-id 1083803787.303193\" -->\n> \n> The problem is that we should only see the latter annotation but at the \n> moment we retrieve both from the server.\n\nI don't know what you are doing in amaya to create 1083803374.199805,\nbut amaya is not sending an update request (either replace_source or\nPUT). Instead it is simply creating a new annotation:\n\nPOST /annotations\n\n<?xml version=\"1.0\" ?>\n<r:RDF xmlns:r=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\nxmlns:a=\"http://www.w3.org/2000/10/annotation-ns#\"\nxmlns:t=\"http://www.w3.org/2001/03/thread#\"\nxmlns:http=\"http://www.w3.org/1999/xx/http#\"\nxmlns:d=\"http://purl.org/dc/elements/1.0/\">\n<r:Description>\n<r:type r:resource=\"http://www.w3.org/2000/10/annotation-ns#Annotation\" />\n<r:type r:resource=\"http://www.w3.org/2000/10/annotationType#Comment\" />\n<a:annotates r:resource=\"http://www.w3.org/2001/Annotea/Overview.html\" />\n<a:context>http://www.w3.org/2001/Annotea/Overview.html#xpointer(string-range(id(\"Annotea2\"),\"\",79,10))</a:context>\n<d:title>Annotation of Annotea project</d:title>\n<d:creator>marja</d:creator>\n<a:created>2004-05-05T20:30:30-05:00</a:created>\n<d:date>2004-05-05T20:31:02-05:00</d:date>\n<a:body>\n<r:Description>\n<http:ContentType>application/xhtml+xml</http:ContentType>\n<http:ContentLength>288</http:ContentLength>\n<http:Body r:parseType=\"Literal\">\n  <html xmlns=\"http://www.w3.org/1999/xhtml\">\n  <head>\n    <meta http-equiv=\"Content-Type\"\n    content=\"application/xhtml+xml; charset=UTF-8\" />\n    <title>Annotation of Annotea project</title>\n  </head>\n  \n  <body>\n  <p>test iggy</p>\n  \n  <p>change </p>\n  </body>\n  </html>\n</http:Body>\n</r:Description>\n</a:body>\n</r:Description>\n</r:RDF>\n\n> Earlier Eric confirmed that Amaya uses PUT for the reply updates and POST \n> with replace source parameter for the annotation updates. Although we \n> should really use PUT in both cases they do work, so that should not be the \n> problem.\n> \n> And replies do the dublication too:\n> \n> Annotation:\n> http://iggy.w3.org/annotations/attribution/1085078002.39180\n> Orig Reply:\n> http://iggy.w3.org/annotations/attribution/1085078054.579611\n> Updated Reply:\n> http://iggy.w3.org/annotations/attribution/1085078066.742406\n> \n> (Tested in Windows 2000 with Amaya 8.5)\n> \n> Marja\n> \n> Marja\n> \n\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n\n"
        },
        {
            "subject": "Re: Update problem with igg",
            "content": "Eric, could you also check the replies because last time we talked you said \nyou could see the reply doing a PUT and that has the same problem.\n\nMarja\n\nAt 09:42 AM 5/28/2004 -0400, Eric Prud'hommeaux wrote:\n>On Thu, May 20, 2004 at 02:48:51PM -0400, Marja-Riitta Koivunen wrote:\n> >\n> > Discussed this with Eric two weeks ago.\n> > Promised to send it again here so it is easier to find:\n> >\n> > Update seems to have the following problem:\n> > Each change to an annotation creates a new annotation instead of updating\n> > the old one e.g.\n> >\n> > 1) this is the original annotation made with Amaya (body contains \"test\n> > iggy\": http://iggy.w3.org/annotations/attribution/1083803351.895598\n> >\n> > 2) and this is the same annotation except that \"change\" was added to the\n> > existing body text\n> > http://iggy.w3.org/annotations/attribution/1083803374.199805\n> >\n> > session ids:\n> >  <!-- session-id 1083803574.648029\" -->\n> > and <!-- session-id 1083803787.303193\" -->\n> >\n> > The problem is that we should only see the latter annotation but at the\n> > moment we retrieve both from the server.\n>\n>I don't know what you are doing in amaya to create 1083803374.199805,\n>but amaya is not sending an update request (either replace_source or\n>PUT). Instead it is simply creating a new annotation:\n>\n>POST /annotations\n>\n><?xml version=\"1.0\" ?>\n><r:RDF xmlns:r=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n>xmlns:a=\"http://www.w3.org/2000/10/annotation-ns#\"\n>xmlns:t=\"http://www.w3.org/2001/03/thread#\"\n>xmlns:http=\"http://www.w3.org/1999/xx/http#\"\n>xmlns:d=\"http://purl.org/dc/elements/1.0/\">\n><r:Description>\n><r:type r:resource=\"http://www.w3.org/2000/10/annotation-ns#Annotation\" />\n><r:type r:resource=\"http://www.w3.org/2000/10/annotationType#Comment\" />\n><a:annotates r:resource=\"http://www.w3.org/2001/Annotea/Overview.html\" />\n><a:context>http://www.w3.org/2001/Annotea/Overview.html#xpointer(string-range(id(\"Annotea2\"),\"\",79,10))</a:context>\n><d:title>Annotation of Annotea project</d:title>\n><d:creator>marja</d:creator>\n><a:created>2004-05-05T20:30:30-05:00</a:created>\n><d:date>2004-05-05T20:31:02-05:00</d:date>\n><a:body>\n><r:Description>\n><http:ContentType>application/xhtml+xml</http:ContentType>\n><http:ContentLength>288</http:ContentLength>\n><http:Body r:parseType=\"Literal\">\n>   <html xmlns=\"http://www.w3.org/1999/xhtml\">\n>   <head>\n>     <meta http-equiv=\"Content-Type\"\n>     content=\"application/xhtml+xml; charset=UTF-8\" />\n>     <title>Annotation of Annotea project</title>\n>   </head>\n>\n>   <body>\n>   <p>test iggy</p>\n>\n>   <p>change </p>\n>   </body>\n>   </html>\n></http:Body>\n></r:Description>\n></a:body>\n></r:Description>\n></r:RDF>\n>\n> > Earlier Eric confirmed that Amaya uses PUT for the reply updates and POST\n> > with replace source parameter for the annotation updates. Although we\n> > should really use PUT in both cases they do work, so that should not be \n> the\n> > problem.\n> >\n> > And replies do the dublication too:\n> >\n> > Annotation:\n> > http://iggy.w3.org/annotations/attribution/1085078002.39180\n> > Orig Reply:\n> > http://iggy.w3.org/annotations/attribution/1085078054.579611\n> > Updated Reply:\n> > http://iggy.w3.org/annotations/attribution/1085078066.742406\n> >\n> > (Tested in Windows 2000 with Amaya 8.5)\n> >\n> > Marja\n> >\n> > Marja\n> >\n>\n>--\n>-eric\n>\n>office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n>                         Shonan Fujisawa Campus, Keio University,\n>                         5322 Endo, Fujisawa, Kanagawa 252-8520\n>                         JAPAN\n>         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n>cell:   +1.857.222.5741 (does not work in Asia)\n>\n>(eric@w3.org)\n>Feel free to forward this message to any list for any purpose other than\n>email address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: Update problem with iggy solve",
            "content": "Eric,\n\nIt was NOT an iggy problem after all.\n\nI think what happened was that Amaya refresh bug affected this too and \nwhile I thought you checked that my HTTP calls did PUT and POST with the \nreplace flag you actually looked your own test results produced with \ncorrected Amaya.\nAnd that's why I could not see the replace flag myself when I looked the \nHTTP info.\n\nI'll do a couple of more tests but I think we are getting ready to change \nannotest to use this code. New Amaya will eventually correct this problem.\n\nMarja\n\nAt 10:17 AM 5/28/2004 -0400, Marja-Riitta Koivunen wrote:\n\n>Eric, could you also check the replies because last time we talked you \n>said you could see the reply doing a PUT and that has the same problem.\n>\n>Marja\n>\n>At 09:42 AM 5/28/2004 -0400, Eric Prud'hommeaux wrote:\n>>On Thu, May 20, 2004 at 02:48:51PM -0400, Marja-Riitta Koivunen wrote:\n>> >\n>> > Discussed this with Eric two weeks ago.\n>> > Promised to send it again here so it is easier to find:\n>> >\n>> > Update seems to have the following problem:\n>> > Each change to an annotation creates a new annotation instead of updating\n>> > the old one e.g.\n>> >\n>> > 1) this is the original annotation made with Amaya (body contains \"test\n>> > iggy\": http://iggy.w3.org/annotations/attribution/1083803351.895598\n>> >\n>> > 2) and this is the same annotation except that \"change\" was added to the\n>> > existing body text\n>> > http://iggy.w3.org/annotations/attribution/1083803374.199805\n>> >\n>> > session ids:\n>> >  <!-- session-id 1083803574.648029\" -->\n>> > and <!-- session-id 1083803787.303193\" -->\n>> >\n>> > The problem is that we should only see the latter annotation but at the\n>> > moment we retrieve both from the server.\n>>\n>>I don't know what you are doing in amaya to create 1083803374.199805,\n>>but amaya is not sending an update request (either replace_source or\n>>PUT). Instead it is simply creating a new annotation:\n>>\n>>POST /annotations\n>>\n>><?xml version=\"1.0\" ?>\n>><r:RDF xmlns:r=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n>>xmlns:a=\"http://www.w3.org/2000/10/annotation-ns#\"\n>>xmlns:t=\"http://www.w3.org/2001/03/thread#\"\n>>xmlns:http=\"http://www.w3.org/1999/xx/http#\"\n>>xmlns:d=\"http://purl.org/dc/elements/1.0/\">\n>><r:Description>\n>><r:type r:resource=\"http://www.w3.org/2000/10/annotation-ns#Annotation\" />\n>><r:type r:resource=\"http://www.w3.org/2000/10/annotationType#Comment\" />\n>><a:annotates r:resource=\"http://www.w3.org/2001/Annotea/Overview.html\" />\n>><a:context>http://www.w3.org/2001/Annotea/Overview.html#xpointer(string-range(id(\"Annotea2\"),\"\",79,10))</a:context>\n>><d:title>Annotation of Annotea project</d:title>\n>><d:creator>marja</d:creator>\n>><a:created>2004-05-05T20:30:30-05:00</a:created>\n>><d:date>2004-05-05T20:31:02-05:00</d:date>\n>><a:body>\n>><r:Description>\n>><http:ContentType>application/xhtml+xml</http:ContentType>\n>><http:ContentLength>288</http:ContentLength>\n>><http:Body r:parseType=\"Literal\">\n>>   <html xmlns=\"http://www.w3.org/1999/xhtml\">\n>>   <head>\n>>     <meta http-equiv=\"Content-Type\"\n>>     content=\"application/xhtml+xml; charset=UTF-8\" />\n>>     <title>Annotation of Annotea project</title>\n>>   </head>\n>>\n>>   <body>\n>>   <p>test iggy</p>\n>>\n>>   <p>change </p>\n>>   </body>\n>>   </html>\n>></http:Body>\n>></r:Description>\n>></a:body>\n>></r:Description>\n>></r:RDF>\n>>\n>> > Earlier Eric confirmed that Amaya uses PUT for the reply updates and POST\n>> > with replace source parameter for the annotation updates. Although we\n>> > should really use PUT in both cases they do work, so that should not \n>> be the\n>> > problem.\n>> >\n>> > And replies do the dublication too:\n>> >\n>> > Annotation:\n>> > http://iggy.w3.org/annotations/attribution/1085078002.39180\n>> > Orig Reply:\n>> > http://iggy.w3.org/annotations/attribution/1085078054.579611\n>> > Updated Reply:\n>> > http://iggy.w3.org/annotations/attribution/1085078066.742406\n>> >\n>> > (Tested in Windows 2000 with Amaya 8.5)\n>> >\n>> > Marja\n>> >\n>> > Marja\n>> >\n>>\n>>--\n>>-eric\n>>\n>>office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n>>                         Shonan Fujisawa Campus, Keio University,\n>>                         5322 Endo, Fujisawa, Kanagawa 252-8520\n>>                         JAPAN\n>>         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n>>cell:   +1.857.222.5741 (does not work in Asia)\n>>\n>>(eric@w3.org)\n>>Feel free to forward this message to any list for any purpose other than\n>>email address distribution.\n>\n>\n\n\n\n"
        },
        {
            "subject": "let's move iggy to annotes",
            "content": "EricP,\n\nI did some more testing with the corrected Amaya version and everything \nseems to work beautifully.\n\nIf someone else has found problems let me know but\nin my opinion we are ready to move iggy to annotest.\n\nMarja\n\n\n\n"
        },
        {
            "subject": "[announcement] W3C Annotea development moving to Mozill",
            "content": "Hello,\n\nJust a quick announcement to say that we're preparing to move\nour Annotea developments from Amaya to Mozilla. \n\nAmaya has been a good platform for quickly developing and\ntesting our Annotea technologies. Furthermore, having the\nAmaya team at hand and knowing the code well has greatly\nsimplified adding enhancements to it. \n\nOn the other hand, Mozilla has a much bigger user database than\nAmaya has. Although developing in Mozilla will probably be\nharder than continue doing it in Amaya because of lack of\ndocumentation and experience, we have decided that the benefits\nof having more people profit from our work are worth it.\n\nAmaya will continue to be developed as usual. However, the Annotea\nteam will stop supporting its annotea related code.  Contributors \ninterested in taking over from us are welcome to contact the \nAmaya team. \n\nAmaya already supports both shared annotations and bookmarks. The \nshared bookmarks code is only active in Unix systems and will be \navailable on other platforms once the Amaya team finishes its \nadoption of Wx Widgets. We didn't want to spend time writing a native \nWin32 UI interface for bookmarks as it would have been scratched a \ncouple of months later on.\n\nOur immediate goal is to write code that supports our shared\nbookmark proposal in Mozilla. Rather than spend time writing\ncode that only works inside Mozilla, our idea is to write a \nlibrary, libAnnotea, that handles the common bookmark operations\nand have a module inside this library that provides the \nMozilla UI. [1] shows a draft of the proposed architecture. The\nmotivation is to have a library that can be used by other applications,\nnot just Mozilla, to ease the deployment of shared bookmarks.\n\nOf course, libAnnotea is the ideal goal. What we actually achieve will\ndepend on time and our development resources.\n\nIf you would like to contribute to this open-source effort, feel \nfree to contact us.\n\nCheers,\n\n-jose, Amaya (past) and Mozilla (future) Annotea client developer\nat W3C.\n\n[1] http://www.w3.org/2001/Annotea/Papers/libannotea/architecture.png\n\n\n\n"
        },
        {
            "subject": "viewing bookmark hierarchy in Mozill",
            "content": "Here is the bookmark hierarchy image from Mozilla I promised (need to make \nanother one where you can see the experimental toolbar in the browser too ...)\n\nhttp://www.annotea.org/image_bookmark.png\n\nThis uses templates to read the RDF bookmark file and I had to add some \nRDF:Seq info to the file because of that but it's a start.\n\nMarja\n\n\n\n"
        },
        {
            "subject": "iggy annotation shows error messages in conten",
            "content": "Eric,\n\nI think iggy did not yet get back to the earlier nicely working state:\n\n- Amaya 8.5 on windows\nI can create an annotation to iggy.\nI cannot load the annotations from iggy but I can from annotest\n\n- new Amaya 8.6 in swada (may have errors too)\nFirst: cannot load even annotest annotations if iggy is on the list \n(complaining about failing to load the annotation index)\nif I take iggy away from get servers I can load the annotest annotations\nSecond: now all the sudden I can see an iggy annotation in swada hopefully \nwith some interesting errors as content.\n\nI'll send a png image as I cannot copy the text easily to my computer.\n\nMarja\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Re: iggy annotation shows error messages in conten",
            "content": "On Fri, Jun 11, 2004 at 11:04:56AM -0400, Marja-Riitta Koivunen wrote:\n> Eric,\n> \n> I think iggy did not yet get back to the earlier nicely working state:\n> \n> - Amaya 8.5 on windows\n> I can create an annotation to iggy.\n> I cannot load the annotations from iggy but I can from annotest\n> \n> - new Amaya 8.6 in swada (may have errors too)\n> First: cannot load even annotest annotations if iggy is on the list \n> (complaining about failing to load the annotation index)\n> if I take iggy away from get servers I can load the annotest annotations\n> Second: now all the sudden I can see an iggy annotation in swada hopefully \n> with some interesting errors as content.\n> \n> I'll send a png image as I cannot copy the text easily to my computer.\n> \n> Marja\n\n2004-06-12T04:11:12Z <ericP> iggy shoudl be a bit more opperational now\n2004-06-12T04:11:50Z <ericP> have fixed bugs that keep it from working when retrieving annotations with no authentication\n2004-06-12T04:12:01Z <ericP> now to fix the fact that they have no authentication\n2004-06-12T04:12:09Z <ericP> (really, that it threw it away)\n2004-06-12T06:37:37Z <ericP> done, seems to work for simple tests\n\ngive it a shot\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n\n"
        },
        {
            "subject": "new lis",
            "content": "List_Name: public-annotation-dev\n(Note: received as www-annotation-dev)\n\nRequester_Email: eric\n\nListPurpose: This list is for the discussion of annotea\ndevelopment. It is likely to be high trafic and only interesting to\ndevelopers. If you wish to join the annotation development team,\nplease send mail to the maintainer describing your and areas of\ninterest/expertise.\n\nMaintaining_Activity: Annotea\n\n-- \nDaigo Matsubara / W3C Systems Team / mailto:daigo@w3.org\n\n\n\n"
        },
        {
            "subject": "iggy server semifunctiona",
            "content": "i haven't checked out the reply queries.\nhaven't formulated the DC1.0/1.1 flexible queries.\nattribution queries fail.\nthe program is actually just a small brick with a bow and wrapping paper.\n\napart from that, all set!\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: iggy server semifunctiona",
            "content": "still cound't sleep\n\nOn Tue, Mar 16, 2004 at 05:22:52PM -0500, Eric Prud'hommeaux wrote:\n> \n> i haven't checked out the reply queries.\n> haven't formulated the DC1.0/1.1 flexible queries.\n\ndone\n\n> attribution queries fail.\n> the program is actually just a small brick with a bow and wrapping paper.\n> \n> apart from that, all set!\n> -- \n> -eric\n> \n> office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n>                         Shonan Fujisawa Campus, Keio University,\n>                         5322 Endo, Fujisawa, Kanagawa 252-8520\n>                         JAPAN\n>         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n> cell:   +1.857.222.5741 (does not work in Asia)\n> \n> (eric@w3.org)\n> Feel free to forward this message to any list for any purpose other than\n> email address distribution.\n\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: iggy server semifunctiona",
            "content": "On Tue, Mar 16, 2004 at 08:13:11PM -0500, Eric Prud'hommeaux wrote:\n> \n> still cound't sleep\n> \n> On Tue, Mar 16, 2004 at 05:22:52PM -0500, Eric Prud'hommeaux wrote:\n> > \n> > i haven't checked out the reply queries.\n\nhmm, there seems to be something locking up the server when i do\nthis on a server with lots of triples (i wrote some queries to \nimport all the old annotations into the new tables).\nbest not try replying for now. if you do, and the server stops\nresponding, log into iggy and do\n  mysqladmin processlist\n\nYou should see the one using up all the resources, ala:\n# mysqladmin processlist\n+-----+------+-----------+------+---------+-------+--------------+------------------------------------------------------------------------------------------------------+\n| Id  | User | Host      | db   | Command | Time  | State        | Info                                                                                                 |\n+-----+------+-----------+------+---------+-------+--------------+------------------------------------------------------------------------------------------------------+\n| 157 | root | localhost | iggy | Sleep   | 27390 |              |                                                                                                      |\n| 409 | root | localhost | iggy | Sleep   | 15645 |              |                                                                                                      |\n| 850 | root | localhost | iggy | Query   | 7     | Sending data | SELECT STRAIGHT_JOIN count(*)\nFROM __Holds__ AS __Holds___0\n     INNER JOIN __Nodes__ AS __Nodes___0 |\n| 862 | root | localhost |      | Query   | 0     |              | show processlist                                                                                     |\n+-----+------+-----------+------+---------+-------+--------------+------------------------------------------------------------------------------------------------------+\n# mysqladmin kill 850\n\n\n> > haven't formulated the DC1.0/1.1 flexible queries.\n> \n> done\n> \n> > attribution queries fail.\n> > the program is actually just a small brick with a bow and wrapping paper.\n> > \n> > apart from that, all set!\n> > -- \n> > -eric\n> > \n> > office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n> >                         Shonan Fujisawa Campus, Keio University,\n> >                         5322 Endo, Fujisawa, Kanagawa 252-8520\n> >                         JAPAN\n> >         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n> > cell:   +1.857.222.5741 (does not work in Asia)\n> > \n> > (eric@w3.org)\n> > Feel free to forward this message to any list for any purpose other than\n> > email address distribution.\n> \n> -- \n> -eric\n> \n> office: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n>                         Shonan Fujisawa Campus, Keio University,\n>                         5322 Endo, Fujisawa, Kanagawa 252-8520\n>                         JAPAN\n>         +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\n> cell:   +1.857.222.5741 (does not work in Asia)\n> \n> (eric@w3.org)\n> Feel free to forward this message to any list for any purpose other than\n> email address distribution.\n\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "Fwd: efficient retrieval of annotation bodies in Annote",
            "content": "Forwarded to continue this discussion here.\n\nMarja\n\n>Delivered-To: marja@annotea.org\n>X-Original-To: www-annotation+aa@listhub.w3.org\n>Delivered-To: www-annotation+aa@listhub.w3.org\n>X-Original-To: www-annotation@listhub.w3.org\n>Delivered-To: www-annotation@listhub.w3.org\n>Date: Fri, 19 Mar 2004 15:53:21 -0500\n>From: Mark Smith <mcs@pearlcrescent.com>\n>User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.4) \n>Gecko/20030624 Netscape/7.1 (ax)\n>X-Accept-Language: en-us, en\n>To: www-annotation@w3.org\n>X-caa-id: d8088c80a5b159437ff5c3e883b3193140ce7ef9\n>Subject: efficient retrieval of annotation bodies in Annotea\n>X-Archived-At: http://www.w3.org/mid/405B5DC1.2080208@pearlcrescent.com\n>Resent-From: www-annotation@w3.org\n>X-Mailing-List: <www-annotation@w3.org> archive/latest/942\n>X-Loop: www-annotation@w3.org\n>Sender: www-annotation-request@w3.org\n>Resent-Sender: www-annotation-request@w3.org\n>List-Id: <www-annotation.w3.org>\n>List-Help: <http://www.w3.org/Mail/>\n>List-Unsubscribe: <mailto:www-annotation-request@w3.org?subject=unsubscribe>\n>Resent-Date: Fri, 19 Mar 2004 15:55:28 -0500 (EST)\n>X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on\n>         mailsmtp.opentransfer.com\n>X-Spam-Status: No, hits=-4.9 required=4.0 tests=BAYES_00 autolearn=ham\n>         version=2.63\n>X-Spam-Level:\n>\n>\n>[Please accept my apologies if this has already been discussed; I did not \n>find it in the list archives.]\n>\n>I have been looking at the Annotea protocol, and it seems that one HTTP \n>GET request must be issued to retrieve each annotation body.  If a client \n>wants to retrieve the list of annotations for a page as well as all of the \n>associated bodies, it can't do so very efficiently.  Or did I miss \n>something in the spec?\n>\n>Are people open to extending the protocol to allow this kind of query? If \n>so, I'd be happy to experiment a bit and propose something concrete.\n>\n>Reference: http://www.w3.org/2002/12/AnnoteaProtocol-20021219\n>\n>--\n>Mark Smith\n>LDAP Book Information: http://www.ldapbook.com/\n>What's Next:           http://www.pearlcrescent.com/\n>\n\n\n\n"
        },
        {
            "subject": "Fwd: Re: efficient retrieval of annotation bodies in Annotea   (message 2",
            "content": ">Delivered-To: marja@annotea.org\n>X-Original-To: www-annotation@listhub.w3.org\n>Delivered-To: www-annotation@listhub.w3.org\n>Date: Mon, 22 Mar 2004 01:52:40 -0500 (EST)\n>From: Charles McCathieNevile <charles@w3.org>\n>To: Mark Smith <mcs@pearlcrescent.com>\n>Cc: www-annotation@w3.org\n>Subject: Re: efficient retrieval of annotation bodies in Annotea\n>X-Archived-At: \n>http://www.w3.org/mid/Pine.LNX.4.55.0403220149060.12234@homer.w3.org\n>Resent-From: www-annotation@w3.org\n>X-Mailing-List: <www-annotation@w3.org> archive/latest/943\n>X-Loop: www-annotation@w3.org\n>Sender: www-annotation-request@w3.org\n>Resent-Sender: www-annotation-request@w3.org\n>List-Id: <www-annotation.w3.org>\n>List-Help: <http://www.w3.org/Mail/>\n>List-Unsubscribe: <mailto:www-annotation-request@w3.org?subject=unsubscribe>\n>Resent-Date: Mon, 22 Mar 2004 01:52:50 -0500 (EST)\n>X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on\n>         mailsmtp.opentransfer.com\n>X-Spam-Status: No, hits=-4.9 required=4.0 tests=BAYES_00 autolearn=ham\n>         version=2.63\n>X-Spam-Level:\n>\n>\n>This optimisation assumes that the server has the bodies itself. This isn't\n>(in a number of the cases I have played with) a valid assumption. So while I\n>have no problem with allowing a query that includes \"please give me all the\n>annotation metadata and bodies that you have for FOO\", I think requiring it\n>would seriously restrict the usefulness of the protocol.\n>\n>A simple example is to think of descriptions of images, where a user might\n>make an annotation to provide an explicit linkage that can be automatically\n>retrieved. This is a common accessibility use case (making an alternative\n>representation available for a person who cannot clearly see or interpret the\n>picture) where one might often expect to find the body of the annotation is\n>an existing resource on the web, referred to rather than held by the annotea\n>server.\n>\n>Cheers\n>\n>Chaals\n>\n>On Fri, 19 Mar 2004, Mark Smith wrote:\n>\n> >\n> >[Please accept my apologies if this has already been discussed; I did\n> >not find it in the list archives.]\n> >\n> >I have been looking at the Annotea protocol, and it seems that one HTTP\n> >GET request must be issued to retrieve each annotation body.  If a\n> >client wants to retrieve the list of annotations for a page as well as\n> >all of the associated bodies, it can't do so very efficiently.  Or did I\n> >miss something in the spec?\n> >\n> >Are people open to extending the protocol to allow this kind of query?\n> >If so, I'd be happy to experiment a bit and propose something concrete.\n> >\n> >Reference: http://www.w3.org/2002/12/AnnoteaProtocol-20021219\n> >\n> >--\n> >Mark Smith\n> >LDAP Book Information: http://www.ldapbook.com/\n> >What's Next:           http://www.pearlcrescent.com/\n> >\n> >\n>\n>Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\n>SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: subscrib",
            "content": "done -- sorry for the delay.\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "a compromise between URLs and UUID",
            "content": "Marja and I have been working through a scenario allowing you to\ncreate objects (like annotations or bookmarks) when not online, but\ngive then URLs as soon as you are connected. This approach might be\nuseful in any situation when you need to label RDF nodes but have no\nsafe way to create URLs at that time.\n\nTake a poke at it. Let us know what you think.\n\nhttp://www.w3.org/2003/12/20-local-global\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "another idea for the URN approach to local UIDs in bookmark",
            "content": "Last Friday I missed the last bus home. While walking 9 km back home,\nI thought about this problem and came up with another less polemical\nsolution, but that requires more application involvement. \n\nIt's basically applying what the server already does when attributing \nURLs and keeping state using owl:sameAs.\n\n1. Define a new property, Bookmark#Base which is the equivalent of\n   xml:base and html:base. The value of this property will be the\n   location of the local bookmark file. It's a way of keeping this\n   information without having parsers losing it (by applying it to the\n   URLs.\n\n2. Give anything as a name to bookmarks and topics, but make sure the\n   base of their URL is the same as the one defined in Bookmark#Base.\n\n3. When opening a file, check the value of Bookmark#Base. If the\n   file contains bookmarks or topics that have a different base,\n   assume that the file has changed location.\n\n   In this case, have the application reassign new URLs for all its\n   topics and bookmarks using the current base and, for each item,\n   store the previous URL value using owl:sameAs. We can have\n   the application prompt the user \"do you want to keep track\n   of the previous location?\" in case the user is just moving the\n   bookmark file around, but has not made any RDF statements about any \n   of the items it contains.\n\n4. Use owl:sameAs to track statements made about the previous URLs\n   and have the application resolve them.\n\n5. When an RDF server sends back a set of bookmarks, it can include\n   the Bookmark#Base property so that the application knows that they\n   have the same base. This will make the way the file is stored\n   (as a single file or inside a database) transparent to the\n   application.\n\n6. If I have a single bookmark file and I put it to the server using\n   a specific \"Save As\" for bookmarks, the application can rewrite the\n   URLs and add the owl:sameAs when writing the file. \n\n   If this is not done, the application will catch the error when\n   reading a file that has a different base.\n\nDoes this make sense to you compared to the previous URN approach?\nIt puts a bigger burden on the application, but makes things work\neven if a file moves around... and it removes the burden from us\nof guaranteeing we have a unique URN for each item.\n\n-jose\n\n\n\n"
        },
        {
            "subject": "Re: [Moderator Action] another idea for the URN approach to local UIDs in bookmark",
            "content": "On Wed, Mar 31, 2004 at 08:10:34AM -0500, Jose Kahan wrote:\n> \n> \n> Last Friday I missed the last bus home. While walking 9 km back home,\n> I thought about this problem and came up with another less polemical\n> solution, but that requires more application involvement. \n> \n> It's basically applying what the server already does when attributing \n> URLs and keeping state using owl:sameAs.\n> \n> 1. Define a new property, Bookmark#Base which is the equivalent of\n>    xml:base and html:base. The value of this property will be the\n>    location of the local bookmark file. It's a way of keeping this\n>    information without having parsers losing it (by applying it to the\n>    URLs.\n\nI'd like to paint a picture of this in action to help myself and\nothers consider the mechanics of this approach:\n\nJose is on a plane poking around some cached portion of the web and\nwants to bookmark something with a new topic.\n\n<r:RDF xmlns:r=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n       xmlns:b=\"http://www.w3.org/2002/01/bookmark#\"\n       xml:base=\"file://localhost/home/jose/bookmarks.rdf\">\n\n   <r:Description r:id=\"topic1\">\n      <dc:title>fruitinfo</dc:title>\n      <b:subTopicOf r:resource=\"#MyHomeTopic\"/>\n      <b:base rdf:resource=\"file://localhost/home/jose/bookmarks.rdf\"/>\n   </r:Description>\n\n   <r:Description r:id=\"bm1\">\n      <b:recalls r:resource=\"http://sample.example.com/appledoc\"/>\n      <b:hasTopic r:resource=\"#topic1\"/>\n      <b:base rdf:resource=\"file://localhost/home/jose/bookmarks.rdf\"/>\n   </r:Description>\n\n   <r:Description r:id=\"bm2\">\n      <recalls r:resource=\"http://demo.example.com/orangedoc\"/>\n      <b:hasTopic r:resource=\"#topic1\"/>\n      <b:base rdf:resource=\"file://localhost/home/jose/bookmarks.rdf\"/>\n   </r:Description>\n</r:RDF>\n\nAs you note, this is likely to lose the xml:base when the first RDF\nprocessor get it and evaluates the names of the topics and bookmarks\nrelative to that xml:base:\n\n<r:RDF xmlns:r=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n       xmlns:b=\"http://www.w3.org/2002/01/bookmark#\">\n\n   <r:Description r:id=\"file://localhost/home/jose/bookmarks.rdf#topic1\">\n      <dc:title>fruitinfo</dc:title>\n      <b:subTopicOf r:resource=\"#MyHomeTopic\"/>\n      <b:base rdf:resource=\"file://localhost/home/jose/bookmarks.rdf\"/>\n   </r:Description>\n\n   <r:Description r:id=\"file://localhost/home/jose/bookmarks.rdf#bm1\">\n      <b:recalls r:resource=\"http://sample.example.com/appledoc\"/>\n      <b:hasTopic r:resource=\"#topic1\"/>\n      <b:base rdf:resource=\"file://localhost/home/jose/bookmarks.rdf\"/>\n   </r:Description>\n\n   <r:Description r:id=\"file://localhost/home/jose/bookmarks.rdf#bm2\">\n      <recalls r:resource=\"http://demo.example.com/orangedoc\"/>\n      <b:hasTopic r:resource=\"#topic1\"/>\n      <b:base rdf:resource=\"file://localhost/home/jose/bookmarks.rdf\"/>\n   </r:Description>\n</r:RDF>\n\n\n> 2. Give anything as a name to bookmarks and topics, but make sure the\n>    base of their URL is the same as the one defined in Bookmark#Base.\n\ndone in the above example by keeping these names relative\n\n> 3. When opening a file, check the value of Bookmark#Base. If the\n>    file contains bookmarks or topics that have a different base,\n>    assume that the file has changed location.\n\nLet's make this a system-wide bookmark file:\nmv /home/jose/bookmarks.rdf /usr/local/bookmarks/current.rdf\n\n>    In this case, have the application reassign new URLs for all its\n>    topics and bookmarks using the current base and, for each item,\n>    store the previous URL value using owl:sameAs. We can have\n>    the application prompt the user \"do you want to keep track\n>    of the previous location?\" in case the user is just moving the\n>    bookmark file around, but has not made any RDF statements about any \n>    of the items it contains.\n\nBookmark app reads /usr/local/bookmarks/current.rdf and globally\nchanges /home/jose/bookmarks.rdf\nto /usr/local/bookmarks/current.rdf .\n\n> 4. Use owl:sameAs to track statements made about the previous URLs\n>    and have the application resolve them.\n\n... and adds:\n   <r:Description\n    rdf:about=\"http://laptop.example.com/usr/local/bookmarks/current.rdf\">\n     <owl:sameAs rdf:resource=\"file://localhost/home/jose/bookmarks.rdf\"/>\n   </r:Description>\n\nApplications on this machine now know that they can see a reference to\nfile://localhost/home/jose/bookmarks.rdf#topic1 and it's the same as\nhttp://laptop.example.com/usr/local/bookmarks/current.rdf#topic1 .\n\n> 5. When an RDF server sends back a set of bookmarks, it can include\n>    the Bookmark#Base property so that the application knows that they\n>    have the same base. This will make the way the file is stored\n>    (as a single file or inside a database) transparent to the\n>    application.\n\n<r:RDF xmlns:r=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n       xmlns:b=\"http://www.w3.org/2002/01/bookmark#\">\n\n   <r:Description\n    r:id=\"http://laptop.example.com/usr/local/bookmarks/current.rdf#topic1\">\n      <dc:title>fruitinfo</dc:title>\n      <b:subTopicOf r:resource=\"#MyHomeTopic\"/>\n      <b:base\n     rdf:resource=\"http://laptop.example.com/usr/local/bookmarks/current.rdf\"/>\n   </r:Description>\n\n   <r:Description\n    r:id=\"http://laptop.example.com/usr/local/bookmarks/current.rdf#bm1\">\n      <b:recalls r:resource=\"http://sample.example.com/appledoc\"/>\n      <b:hasTopic r:resource=\"#topic1\"/>\n      <b:base\n     rdf:resource=\"http://laptop.example.com/usr/local/bookmarks/current.rdf\"/>\n   </r:Description>\n\n   <r:Description\n    r:id=\"http://laptop.example.com/usr/local/bookmarks/current.rdf#bm2\">\n      <recalls r:resource=\"http://demo.example.com/orangedoc\"/>\n      <b:hasTopic r:resource=\"#topic1\"/>\n      <b:base\n     rdf:resource=\"http://laptop.example.com/usr/local/bookmarks/current.rdf\"/>\n   </r:Description>\n</r:RDF>\n\nI haven't included the owl:sameAs assertion because it described the\nrelationship between a universally identified resource\n  http://laptop.example.com/usr/local/bookmarks/current.rdf\nand a local resource that was created when there was no net access\n  file://localhost/home/jose/bookmarks.rdf\n\n> 6. If I have a single bookmark file and I put it to the server using\n>    a specific \"Save As\" for bookmarks, the application can rewrite the\n>    URLs and add the owl:sameAs when writing the file. \n> \n>    If this is not done, the application will catch the error when\n>    reading a file that has a different base.\n> \n> Does this make sense to you compared to the previous URN approach?\n> It puts a bigger burden on the application, but makes things work\n> even if a file moves around... and it removes the burden from us\n> of guaranteeing we have a unique URN for each item.\n\nI think this is an interesting technique, and I'm glad to have worked\nthrough the details of it, but I think we still need the URN approach\nto deal with the scenario of documents that are shared before they get\na universal name. For instances, a user could queue mail containing a\nlocal form (not yet named with a non-local name) while still on the\nplane [1].\n\nPerhaps this approach addresses the mailed-local scenario in a way I\nhaven't spotted.\n\n[1] http://www.w3.org/2003/12/20-local-global.html#L153\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: [Moderator Action] another idea for the URN approach to local UIDs in bookmark",
            "content": "Eric,\n\nThanks for giving a more concrete example. There's only a glitch\nthat I think made you miss the point of my proposal. \n\nThe main point of using <b:base> (as you defined it) and\nowl:sameAs is to keep track of the current and previous\nlocation of statements. The problem we want to solve is\nto be able to make a statement about another statement that is\ninside a file that can be moved. Relative URLs are not good for\ndoing this.\n\nThe URN are a good solution to it, but I don't know how good\nwe will be in generating unique and distinct URNs in a non-controlled\nenvironment (the whole world).\n\nThe solution I propose allows to have the same benefits as the\nunique URN but it avoids collisions, The price to pay, however, is that\napplications need to do much more processing.\n\nWhat is easier to have, a fail-safe mechanism to produce URNs or\nsome well specified processing? If it's the former, then let's go\nforward with URNs (and send a follow-up message on how to do it :).\nMaybe you'd like to adopt the same mechanism used to generate msgids\nby some mail client?\n\nI'm basically proposing that the applications do the same job\nthat the server does when you publish something and it attributes\na new URL.\n\nSee below for additional comments.\n\nOn Wed, Mar 31, 2004 at 09:07:20AM -0500, Eric Prud'hommeaux wrote:\n\n[snip]\n> \n> > 5. When an RDF server sends back a set of bookmarks, it can include\n> >    the Bookmark#Base property so that the application knows that they\n> >    have the same base. This will make the way the file is stored\n> >    (as a single file or inside a database) transparent to the\n> >    application.\n> \n[snip]\n> \n> I haven't included the owl:sameAs assertion because it described the\n> relationship between a universally identified resource\n>   http://laptop.example.com/usr/local/bookmarks/current.rdf\n> and a local resource that was created when there was no net access\n>   file://localhost/home/jose/bookmarks.rdf\n\nWe don't need the owl:sameAs here unless this was a statement that\nhad a previous location.\n\n> I think this is an interesting technique, and I'm glad to have worked\n> through the details of it, but I think we still need the URN approach\n> to deal with the scenario of documents that are shared before they get\n> a universal name. For instances, a user could queue mail containing a\n> local form (not yet named with a non-local name) while still on the\n> plane [1].\n\nWith my proposal, you can share the documents too without needing\nto have a universal name. The universal name is made of the location of\nthe file and the previous location is kept using owl:sameAs. This way\nstatements made about something that moved can still be tracked to the\nnew ones. It's just much more hazzle than URNs.\n\n> Perhaps this approach addresses the mailed-local scenario in a way I\n> haven't spotted.\n\nHope this makes it clearer.\n\n-jose\n\n\n\n"
        },
        {
            "subject": "Re: [Moderator Action] another idea for the URN approach to local UIDs in bookmark",
            "content": "On Wed, Mar 31, 2004 at 04:41:15PM +0200, Jose Kahan wrote:\n> \n> Eric,\n> \n> Thanks for giving a more concrete example. There's only a glitch\n> that I think made you miss the point of my proposal. \n> \n> The main point of using <b:base> (as you defined it) and\n> owl:sameAs is to keep track of the current and previous\n> location of statements. The problem we want to solve is\n> to be able to make a statement about another statement that is\n> inside a file that can be moved. Relative URLs are not good for\n> doing this.\n> \n> The URN are a good solution to it, but I don't know how good\n> we will be in generating unique and distinct URNs in a non-controlled\n> environment (the whole world).\n> \n> The solution I propose allows to have the same benefits as the\n> unique URN but it avoids collisions, The price to pay, however, is that\n> applications need to do much more processing.\n> \n> What is easier to have, a fail-safe mechanism to produce URNs or\n> some well specified processing? If it's the former, then let's go\n> forward with URNs (and send a follow-up message on how to do it :).\n> Maybe you'd like to adopt the same mechanism used to generate msgids\n> by some mail client?\n\nIf we go with (temporary) UUIDs, yes, I think re-using something like\nmessage ids would offer the maximum use of existing and testing tools.\nI guess msgids are the most prolific of the globally \"unique\" UUIDs\ncurrently being generated.\n\n> I'm basically proposing that the applications do the same job\n> that the server does when you publish something and it attributes\n> a new URL.\n> \n> See below for additional comments.\n\nditto\n\n> On Wed, Mar 31, 2004 at 09:07:20AM -0500, Eric Prud'hommeaux wrote:\n> \n> [snip]\n> > \n> > > 5. When an RDF server sends back a set of bookmarks, it can include\n> > >    the Bookmark#Base property so that the application knows that they\n> > >    have the same base. This will make the way the file is stored\n> > >    (as a single file or inside a database) transparent to the\n> > >    application.\n> > \n> [snip]\n> > \n> > I haven't included the owl:sameAs assertion because it described the\n> > relationship between a universally identified resource\n> >   http://laptop.example.com/usr/local/bookmarks/current.rdf\n> > and a local resource that was created when there was no net access\n> >   file://localhost/home/jose/bookmarks.rdf\n> \n> We don't need the owl:sameAs here unless this was a statement that\n> had a previous location.\n> \n> > I think this is an interesting technique, and I'm glad to have worked\n> > through the details of it, but I think we still need the URN approach\n> > to deal with the scenario of documents that are shared before they get\n> > a universal name. For instances, a user could queue mail containing a\n> > local form (not yet named with a non-local name) while still on the\n> > plane [1].\n> \n> With my proposal, you can share the documents too without needing\n> to have a universal name. The universal name is made of the location of\n> the file and the previous location is kept using owl:sameAs. This way\n> statements made about something that moved can still be tracked to the\n> new ones. It's just much more hazzle than URNs.\n\nFollowing that through a bit: you share your bookmark with someone\nelse before nailing it down with a universal name. Supposed you\ngenerate a bookmark, with xml:base and b:base of\nfile:///C:|/Windows/bookmarks.rdf . You mail the file to me (or at\nleast queue it) before you get a chance to post the bookmark to a\nbookmark server. There may already be a file on my machine called\nfile:///C:|/Windows/bookmarks.rdf but my mail client is likely to warn\nme before I overwrite it by saving the mailed bookmarks file in that\nlocation. Prompted by the mail client, I save it to\n  <current directory>/bookmarks2.rdf\nNow when I read that file from a bookmark-protocol-aware agent, it\nchanges the names of all the nodes in the graph that are fragments\nbased on file:///C:|/Windows/bookmarks.rdf .\n\nThis counts on the graph merging happening only with bookmark agents.\nAny other tool would see the node called \n  file:///C:|/Windows/bookmarks.rdf#bm1\nin a document called file:///C:|/Windows/bookmarks2.rdf and merge it\nwith the file:///C:|/Windows/bookmarks.rdf#bm1 from bookmarks.rdf .\n\nAnother requirement is that the server should not ever know about the\nowl:sameAsr it will try to merge all of the things that it ever\nlearned had been called file:///C:|/Windows/bookmarks.rdf#bm1 at some\npoint in their history. For an example of this failure, suppose Jose\nKahan of Brittany creates\n  file:///C:|/Windows/bookmarks.rdf#bm1\nand posts it to server1. server1 then says,\n  file:///C:|/Windows/bookmarks.rdf#bm1 owl:sameAs ...bm12321 .\n\nSomeplace out there on the net, someone else happens on the name bm1\nand they post their notion of file:///C:|/Windows/bookmarks.rdf#bm1 .\nThe server is faced with trying to guess if this bm1 is the same one\nthat it heard about before. If it is, it should probably rename it to\nthe other name it already gave for bm1. Otherwise, it should give it a\nnew name, say ...bm13891, but not mention any owl:sameAs relationship\nbetween the newly invneted name and\nfile:///C:|/Windows/bookmarks.rdf#bm1 .\n\nFor similar reasons, the client should never let *anybody* know that\nbm1 owl:sameAs ...bm12321 as they will arrive at the same mistaken\nconclusion that the bm1 and bm1 and ...bm12321 and ...bm13891 are all\nthe same node.\n\nHow coherent was that?\n\n> > Perhaps this approach addresses the mailed-local scenario in a way I\n> > haven't spotted.\n> \n> Hope this makes it clearer.\n> \n> -jose\n\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "Re: another idea for the URN approach to local UIDs in bookmark",
            "content": "Jose Kahan wrote:\n >\n> What is easier to have, a fail-safe mechanism to produce URNs or\n> some well specified processing? If it's the former, then let's go\n> forward with URNs (and send a follow-up message on how to do it :).\n> Maybe you'd like to adopt the same mechanism used to generate msgids\n> by some mail client?\n> \n> I'm basically proposing that the applications do the same job\n> that the server does when you publish something and it attributes\n> a new URL.\n\nI do not have an opinion about which approach is better for the bookmark \nlocal/global ID problem.  But generating globally unique UUIDs is \nsomething that quite a few applications and protocols do, and the most \nwidely used algorithm is described here:\n\n   http://www.ietf.org/internet-drafts/draft-mealling-uuid-urn-03.txt\n\nSample C code is included in that Internet Draft.  The UUID-based URIs \nwon't be pretty (e.g., urn:uuid:f81d4fae-7dec-11d0-a765-00a0c91e6bf6) \nbut they should be globally unique.\n\n-- \nMark Smith\nLDAP Book Information: http://www.ldapbook.com/\nWhat's Next:           http://www.pearlcrescent.com/\n\n\n\n"
        },
        {
            "subject": "Re: another idea for the URN approach to local UIDs in bookmark",
            "content": "On Wed, Mar 31, 2004 at 11:21:28AM -0500, Mark Smith wrote:\n> \n> Jose Kahan wrote:\n> >\n> >What is easier to have, a fail-safe mechanism to produce URNs or\n> >some well specified processing? If it's the former, then let's go\n> >forward with URNs (and send a follow-up message on how to do it :).\n> >Maybe you'd like to adopt the same mechanism used to generate msgids\n> >by some mail client?\n> >\n> >I'm basically proposing that the applications do the same job\n> >that the server does when you publish something and it attributes\n> >a new URL.\n> \n> I do not have an opinion about which approach is better for the bookmark \n> local/global ID problem.  But generating globally unique UUIDs is \n> something that quite a few applications and protocols do, and the most \n> widely used algorithm is described here:\n> \n>   http://www.ietf.org/internet-drafts/draft-mealling-uuid-urn-03.txt\n\nDo you know what other protocols use this uuid scheme? That it is\nspecified (and even have algorithms and code) makes it appealing for\nthis application. But if there some other protocols that use it, we\nmay discover opportunities to re-use parts of those protocols as well.\n\n> Sample C code is included in that Internet Draft.  The UUID-based URIs \n> won't be pretty (e.g., urn:uuid:f81d4fae-7dec-11d0-a765-00a0c91e6bf6) \n> but they should be globally unique.\n\nWe were looking for something more shapely, and with nicer colors, but\nmaybe if there's already code we'll forgo aesthetics this time.\n-- \n-eric\n\noffice: +81.466.49.1170 W3C, Keio Research Institute at SFC,\n                        Shonan Fujisawa Campus, Keio University,\n                        5322 Endo, Fujisawa, Kanagawa 252-8520\n                        JAPAN\n        +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741 (does not work in Asia)\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "Kynn's Review of WCAG 2.0 Draft (24 June 2003",
            "content": "WCAG 2.0 Working Draft 24 June 2003\n\n    The W3C has posted a request for reviews of the current draft of the\n    updated version of the Web Content Accessibility Guidelines (WCAG).\n    Version 2.0 is intended to improve on WCAG 1.0 as well as going \nbeyond\n    simply being a revision to being a rewrite, as I understand things.\n\n    I promised Wendy Chisholm I'd take a look, so here's my take on WCAG\n    2.0.\n\n    Comments are in no particular order; they're simply what popped into\n    my head when reading through the draft. I will attempt to identify \nthe\n    key points with &lt;strong> emphasis; these comments are numbered for\n    reference. A permanent URL for this post is\n    http://www.maccessibility.com/archive/000764.php\n\n    A note on approach: Although I am very familiar with WCAG 1.0, I am\n    not referring to it while reviewing this draft, and in fact, I am\n    trying to forget that I know it at all. For many people -- from 2004\n    to 2009, at least -- this will be their first introduction to these\n    concepts, and the document needs to stand alone as a complete\n    reference.\n     1. Organizational: There is a lot of \"legalese\" at the beginning, \nand\n        that might be a good place for \"skip to table of contents\" links.\n     2. Abstract: The final version of the abstract should not describe\n        this document primarily in terms of WCAG 1.0 -- as per my comment\n        on \"approach\" above. The existence of 1.0 can be mentioned, but\n        the abstract should stand alone.\n     3. Terminology: \"Normative\" and \"non-normative\" are used a lot but\n        are not defined in this spec. The specific use of \"normative\"\n        should be noted under \"how to read this document\".\n     4. Audience: I want a better definition of the audience. For a\n        writing project of this kind of scope, audiences must be defined\n        clearly and explicitly, as well as how those audiences will use\n        this document.\n     5. Priorities and Techniques: Hopefully the final version will not\n        reference WCAG 1.0 so much.\n     6. Suggestion: A \"conversion document\" between WCAG 1.0 and WCAG 2.0\n        would be helpful.\n     7. Conformance: This section uses terms before defining them, such \nas\n        \"Required Success Criteria\" and \"Best Practice.\"\n     8. Suggestion: I would really like to see a graphical representation\n        of the concepts for both the document structure as well as the\n        conformance criteria. Without a visual representation, it is very\n        hard to understand what's what.\n     9. Conformance: The terminology Core, Core+ and Extended are not\n        clear terms. I am concerned that these specific terms, while they\n        have meaning to the working group, will be opaque to the readers\n        of the document.\n    10. Core+ Questions:\n\n         How should conformance claims state which Extended Checkpoints\n                 are met? in metadata? in a site accessibility statement?\n                 some other method?\n                 Metadata, accessibility statement, and (ugh) graphic are\n                 all acceptable and should be supported; furthermore, \nthis\n                 should be an open list not a closed list.\n\n         How should conformance claims state how many Extended \nCheckpoints\n                 are met? in metadata? with core+n (n=number of Extended\n                 checkpoints)? in a site accessibility statement? some\n                 other method?\n                 In the same way as above, but not literally \"core + N\".\n\n         If Core+ is claimed, should we require a statement about which\n                 Extended checkpoints are met?\n                 Definitely yes.\n\n         Is there a separate logo for each level: core, core+, and\n                 extended? If so,what does the logo point to?\n                 Does it have to point to anything?\n\n         Comparisons of Core+ conformance claims can not be made unless\n                 detailed information is provided about the Extended\n                 checkpoints that are met.\n                 Yes. Was this a question?\n\n         Should detailed conformance information be provided in metadata?\n                 There is doubt that it will be kept up to date,\n                 especially if the site becomesless accessible over time.\n                 Also, we may be unable to require metadata since some\n                 companies have indicated that the legal and ISO 9000\n                 ramifications would prevent them from posting metadata\n                 describing the exact conformance.\n                 Any way to indicate conformance can become out of date.\n                 If companies don't wish to make claims using one or more\n                 of the methods described by this document, they don't\n                 have to. This should not be a barrier for providing\n                 metadata schema for conformance claims.\n\n         If it were possible to claim \"Core+n\" where \"n\" denotes the\n                 number of Extended Checkpoints that are met, some\n                 developers report that they would be encouraged to meet\n                 more Extended Checkpoints and increase the number they\n                 can report. However, people are likely to compare the\n                 number and these comparisons could be misleading. For\n                 example, a site that claims \"Core+2\" could be more\n                 accessible than a site that claims \"Core+3\" depending on\n                 which checkpoints are met.\n                 Heh. Let's call it Extended Minus Four, etc.\n\n    11. Scope of conformance claim: For purposes of metadata claims, \nscope\n        should be identified via URI identification whenever possible,\n        just because that's how the Web tends to function.\n    12. Overview of Design Principles: The four principles -- \nPerceivable,\n        Operable, Understandable, Robust -- are a great example of a \nplace\n        where images can be used to reinforce important points. An iconic\n        representation of each of these concepts would help a lot.\n    13. User Needs: The statements \"cannot hear\", \"cannot see\", etc. have\n        a tendency to reinforce the notion that all visually impaired\n        people can't see at all, all deaf people can't hear at all, etc.\n        Present these instead as user preferences based on what works \nbest\n        for each user, rather than as black-and-white disabilities.\n        Remember that this document may be some Web developers' first\n        exposure, at all, to the use of the Web by people with\n        disabilities. Example:\n           + Someone who cannot see well may want to hear information\n             which is usually presented visually.\n    14. Guideline organization: Guideline one needs some introductory\n        material explaining what is meant by \"perceivable\".\n    15. Clear and simple language: I tried mentally diagramming the\n        sentence that comprises checkpoint 1.1 and it wasn't easy. I \nthink\n        this checkpoint has been overworked and needs to be stated simply\n        and clearly. Note that this particular way of phrasing the\n        checkpoint text makes it really impersonal. Compare to:\n           + If you use content which is not simply textual, include a\n             text equivalent for the parts of that non-text content which\n             can be expressed in words. The text equivalent should convey\n             the same function or meaning as the non-text content.\n        This is an extreme example -- from one style (\"W3C clinical\" to\n        \"Kynn chatty\") -- but it is meant to illustrate how a checkpoint\n        can be rewritten to be understandable.\n    16. Markup point for 1.1: Suggest using &lt;em> instead of <strong> \non\n        the words \"can\" and \"can not\" in the success criteria.\n    17. Checkpoint 1.1 \"informative\" material: Again, \"informative\" is\n        used without definition (how does it differ from\n        \"non-normative\"??).\n    18. Checkpoint 1.1 examples: Since this checkpoint is both basic and\n        vastly complex, some definitive examples of when and where and \nhow\n        to use text equivalents should be here, not just relegated to the\n        techniques.\n    19. Checkpoint 1.2 editorial note: This is a big headache. Ugh! No\n        good answer here.\n    20. Checkpoint 1.3: I don't understand the [information/substance]\n        phrasing. Are you asking which one is better?\n    21. Checkpoint 1.3: Because this seems so open-ended -- as with 1.1 \n--\n        I would want know what exactly this checkpoint requires me to do.\n        For example, there are some tags which are rarely used in HTML\n        4.01 by anyone -- are those required if they convey structural\n        information? Does this checkpoint ban the use of <b>? Help me\n        understand it, without going into techniques -- ideally, someone\n        (like me) who understands HTML 4.01 should be able to \"derive\" \nthe\n        techniques document from reading the guidelines. I don't get it,\n        though.\n    22. Checkpoint 1.4 example: In example 2 (where is example 1?) it\n        talks about \"a page title\" -- well, you can't use the <acronym>\n        element within the <title> element! So the page title wouldn't\n        have anything to indicate what the string \"W3C\" is supposed to \nbe.\n        Furthermore, the acronym element does not indicate pronunciation\n        -- that is a function of aural CSS, if anything. This example is\n        misleading.\n    23. Checkpoint 1.5 phrasing: What do you mean by \"more people\"? This\n        is amazingly vague phrasing, and thus problematic.\n    24. Checkpoint 1.6: This is assuming that there is such thing as\n        \"foreground content\" and \"background content\" -- does this model\n        make sense, though? Is it generally applicable?\n    25. Checkpoint 2.1: When you say \"at a minimum\" I wonder what that\n        minimum is. If something has multiple functions, are they all\n        required to work, or is there some minimum defined? Does the\n        concept of \"minimum\" as applied here really play an important\n        role?\n    26. Checkpoint 2.1 editorial: Be careful how you write that up -- if\n        something is \"less than infinite tabbing\" is it still acceptable?\n        By what criteria can a Web developer judge if there are enough, \nor\n        too many, tab keypresses to access functionality?\n    27. Checkpoint 2.2: By granting an exception for \"competitive or\n        realtime events\" you are making a global value judgment which \nsays\n        \"it's okay to be inaccessible if you have certain goals in mind.\"\n        This is a bad idea, because the \"loophole\" in this checkpoint\n        essentially says, \"...so it's accessible.\" Guess what: a\n        competition is still inaccessible if it is time-based. The \npurpose\n        of this document is to define if a practice is accessible or\n        inaccessible. Games don't magically become accessible by virtue \nof\n        being games. Inaccessible coding should be labeled inaccessible \nif\n        it is, indeed, inaccessible. There should be no loopholes. \nSomeone\n        who requires six times as much time to do something doesn't\n        magically speed up just because it's a competition -- the\n        competition is still inaccessible to that person, and should be\n        stated as such.\n    28. Checkpoint 2.3: An explanation of \"Hz\" would be helpful. Not all\n        Web developers would know what this means.\n    29. Checkpoint 2.3 Editorial Note: Okay, there's no tool to check for\n        this. Question: Are there documented examples of anyone with\n        photosensitive epilepsy ever getting clobbered by a Web page? If\n        so, can you please point me to them, preferably from a reputable\n        source (such as a medical journal) rather than just hearsay?\n    30. Checkpoint 2.4 phrasing: Again, a very ugly sentence diagram. \nHuh?\n    31. Checkpoint 2.4 editorial note: Also, the concept of Web\n        application further weakens the page/site divide.\n    32. Checkpoint 3.1 best practice: It should also be possible for \nother\n        data sent with the document, such as HTTP headers, to identify \nthe\n        primary language of the document.\n    33. Checkpoint 3.2 best practice: What's a cascading dictionary? \nWhich\n        unabridged dictionary is one required to use? Are there different\n        ones for en-us, en-uk, en-ca, and en-au?\n    34. Checkpoint 3.3: Is this written in English?\n    35. Checkpoint 3.3 best practice: Will this be applied to WCAG 2.0?\n    36. Checkpoint 3.3 definitions: ASCII art is text.\n    37. Checkpoint 3.3 \"Note\": \"Designers need to be cautious in deciding\n        when to use illustrations \" -- this reads as if it is \ndiscouraging\n        the use of illustrations. Please don't discourage the use of\n        illustrations. Phrasing of this sort will be misinterpreted --\n        look at how many media articles have reported that you shouldn't\n        use color.\n    38. Checkpoint 3.4 phrasing: Whaaaaat? I don't understand what this\n        checkpoint is trying to say to me.\n    39. Checkpoint 4.2: Is this checkpoint saying use JavaScript as long\n        as you say you're using JavaScript? Or does it mean something\n        else?\n    40. Checkpoint 4.2 best practice: Are two supporting implementations\n        sufficient? I can think of things which are supported on Mozilla\n        and Safari, but not in Internet Explorer. IE is used by the\n        majority of people with or without disabilities. Can you claim\n        accessibility if 95% of your audience is unable to access?\n    41. Checkpoint 4.2 definitions editorial note: I'm not sure I\n        understand the \"low cost\" requirement. Can you define low cost?\n    42. Checkpoint 4.3 phrasing: Many of these sentences seem to be\n        written as mathematical equations and could use some sort of\n        grouping symbols around them. :p I get lost in this one's\n        structure, too. Clear and simple language, please!\n    43. Checkpoint 4.3 editorial note: I think that process is important\n        and should be discussed in another W3C document.\n    44. Appendix A Glossary: Isn't there a WAI-wide glossary in the \nworks?\n    45. Content definition: This is probably the worst definition of\n        content I've seen for a long time. :)\n    46. Mechanisms That Cause Extreme Changes in Context definition: The\n        term itself is problematic, especially the overused word\n        \"extreme.\" \"Mechanisms,\" of course, sounds like some sort of\n        hardware function. So maybe this refers to an ejector seat. Can \nwe\n        get a better phrase?\n    47. Structure definition: This is as bad as the content definition.\n\n    Hope this is helpful. If you want to do your own review, look over \nthe\n    draft and send your comments to the working group.\n\n\n--\nKynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\nChief Technologist, Idyll Mountain                http://idyllmtn.com\nShock & Awe Blog                                http://shock-awe.info\nAuthor, CSS in 24 Hours                       http://cssin24hours.com\nInland Anti-Empire Blog                   http://inlandantiempire.org\n\n\n\n"
        },
        {
            "subject": "Re: Call for Review: Working Draft of Web Content Accessibility     Guidelines 2.",
            "content": "Dear WAI WCAG members,\n\nthank you for the work and enthusiasm you put into WCAG 2.0. After\nfollowing the development of WCAG 2.0\nfor some time, we want to comment on the current version (June 24 2003).\nOur comments are based on the\nexperience with WCAG 1.0 and the German decree BITV, which basically\nrequires German federal public\nwebsites to conform with AA. The experience includes advice for\ndesigners, testing of web-sites, feedback and\ndiscussion with disability groups, feed back and discussion with web\ndesigners and federal agencies.\n\n1. The most important request is that a smooth transition form WCAG 1.0\nto WCAG 2.0 is possible and\nsupported by WAI. This is absolutely mandatory, if one does not want to\njeopardise the efforts that\nGovernments adopt W3C-WAI guidelines, as currently recommended in the\nEuropean Union. The current\nversion represents a major change, which is likely to create big\nproblems in this respect.\n\n2. The advice promised for the transition of 1.0 to 2.0, needs to be\navailable, before the WCAG 2.0 can\nbecome an official recommendation. The current checkpoint mapping is not\nat all sufficient (contarily, it\nhighlights very clearly the problems of the transition). The advice\nshould follow a scheme. I conform with A\nor AA, or AAA which are the new additional requirements? Which are the\nobsolete 1.0 guidelines and\ncheckpoints?\n\n3. In WCAG it is said that priority 1 removes barriers, which can?t be\novercome, priority 2 removes significant\nbarriers, etc. What is the case for the types core and extended? Does\ncore remove all significant barriers?\nAny statement planned like in 1.0?\n\n4. Why moving from priorities to types. What is the difference? I would\nstick with the concept of priorities.\nThat would be more consistent with WCAG 1.0.\n\n5. Agree to have only two levels. Please avoid the core + thing. This\nmakes it very complicated. It is much\neasier to deal with 2 clear levels. If you stay with things like core +\netc, you open up the creation of new\nstandards like ?Core+ Germany? (which is defined somehow). If you want\nmore variety, please go ahead.\n\n6. A very big concern is that WCAG 2.0 in the current format, does not\nadequately consider the needs of older\npeople, people with less computer skills, people who have problems to\nunderstand complex language. You\nput most of the very important requirements in this respect under\nextended. This is not acceptable. We have\nbig debates here on how to support the needs of these people, like those\nwho have sign language as first\nlanguage (the need a simple grammar, short sentences, etc.) or the ones\nwith slight mental problems, who\nask for less terminology, better layouts, clear navigation etc. If WCAG\n2.0 does not consider this\nappropriately, it will miss the opportunity to turn from a ?blindness?\noriented scheme to a (dis)ability\noriented one.\n\n7. Your checkpoint 1.6 is extended: Why? Many people with visual\nimpairment benefit form good colour\ncontrast. And the ordinary user, will not be able to do all settings\nher- or himself to get a good colour\ncontrast. So this should be core.\n\n8. Similar 2.4 needs to get on core level (see 6.) Maybe the success\ncriteria need to be changed then.\n\n9. Similar 3.3  and 3.4 are clearly core requirements (see 6). (What\nabout the need of content, one can perceive\nbut never understand!)\n\n10 If you kill 4.3, what happens to accessible scripts or alternatives\nto scripts then? No recommendations on this\nat all?\n\nGenerally:\n\nThe WCAG 1.0 was at the time rather strict and provided many very clear\nrecommendations, for example old 2.1\n(information conveyed with colour should be available without colour).\nNow this is included in 1.3 separation of\ninfo/ structure/ presentation. Well, it is basically there, but it needs\nto be supported by success criteria, which is\nnot in the current version.(It is not sufficient to put it down to\ntechnical docs. It needs to be part of WCAG 2.0)\n\nEvery WCAG 1.0 guideline and checkpoint need to be visited to make sure\nthat if it is still valid, it has found\nappropriate entrance to WCAG 2.0.\n\nIf I go to the Mapping list, I really wonder why so many important WCAG\nPriority 2 issues have put to the type\nextended. Also the level of aggregation of criteria in one single\nheadline seems not very helpful in the end. (In\nthe beginning it reads much easier, but one needs to go to the details\nfor the practical case.)\n\nWhen I read the draft WCAG 2.0 a year ago, I thought it was on a good\nway. Today, I have much more\nreservations. In a country, which uses WCAG 1.0 as a baseline for its\nlegislation, I forsee big problems, if this\nWCAG 2.0 will replace 1.0. I recommend to take the time to produce a\nWCAG 2.0, which considers\nappropriately all disability groups and allows a smooth transition from\n1.0 to the new one. If that is not done\nproperly, WCAG 2.0 will be not meet the target.\n\nMaybe weI misunderstood some concepts. If so we would be glad to learn.\nOtherwise, our criticism was formulated very frankly, in order to be as\nclear as possible and to support the process as much as possible.\n\nBest regards\n\nChristian Buehler\n\n\n\n"
        },
        {
            "subject": "Comments on Draft Web Accessibility Guideline",
            "content": "Conformance Claims:  There is an advantage to having multi-level of\nconformance possible, i.e. Core, Core+, and Extended.  There are two issues\ninvolved:\n*Where to make the claim on the site:  Because there are two\naudiences involved, the claim should be made in two places; in a site\naccessibility statement that the viewer can see and using metadata so\nautomated tools can establish the level of conformance.  Whether or not the\ninformation would be kept up to date is irrelevant since any claim made can\nbecome outdated.  It is still the responsibility of the site manager to\nmaintain accurate data for conformance as in anything else.\n*How to grade the Core+ category:  The only method that appears to\nhave merit is the Core+N method.  The number of items tends to mean little\nsince the easiest will probably be done first.  However, assuming that is\ntrue means sites could be compared in a generally way based on the amount.\nAnother way that might be possible is to establish sub-categories that\nequate to types of accessibility.  In that manner, the Core could be\nextended in jumps where a site complies completely with a subcategory that\nthe viewer can identify the value of.\n\nExclusions from claims must be allowed for certain situations, especially\nmaintaining material copyright by outside parties.  (Material copyright by\nthe company owning the site should be established to meet the conformance\nclaim.)  However, the only type of exclusion should come from material not\nunder the control of the site manager.  Material the site manager is\npresenting should not be excluded.  It is only outside material that can be.\nUsually, this type of material can and should be kept separate, and clearly\nidentified as outside material.  The example given, \"All pages and\napplications on this site meet the Core checkpoints of WCAG 2.0 except the\nWeb cam at http: // example.org / webcam /.\" (1.2) is a good one.\nThe Additional Items mentioned in the editorial note dated 22 May 2003 under\n1.5 should be moved to techniques as suggested.  The items does detail\ntechniques for handling material.\n1.6 Contrast:  The issue of contrast is complex and there is no easy answer.\nHowever, in my experience, a web page that has proper contrast can also be\nprinted on a standard laser printer without special graphics dithering\nturned on and still show all the material in usable form.\n2.3 Screen Flicker:  The bottom line about screen flicker is that it is\nindividual to the person.  There is still the possibility that screen\nflicker rates having passed requirements could affect individuals prone to\nseizures.  However, if a page is designed to flicker, individuals must be\ntold before they access the page using normal menuing functions.  My feeling\nis that pages should not be designed to flicker at all, and that changing\ncontent should always be shown with clearly perceived movement, such as a\nblinking cursor.  Content that changes faster than can be clearly perceived\nby the eye should not be allowed, such as when subliminal stimulative\nmessages are presented.\n3.2 Links for Term Definitions:  You cannot have a defined goal of making\nmaterial accessible and understandable if some users will not be familiar\nwith all of the terms and acronyms, and you can't assume all users are\nfamiliar with terms outside of normal use.  Therefore, all terms not found\nin everyday use and all acronyms should be explained in a definitions page\nof some sort.  A good definition of what needs to be listed (beyond all\nacronyms) would include those terms peculiar to the site.  However, links to\nthis page should not be necessary.  If a person knows the page is there,\nthey can access it when they need to.  Maintaining these links would be a\nlarge burden for site managers.\nin 4.1, Items 2 and 3 are not only superfluous, they are ambiguous.  I would\ntake them out.\nItem 4.2 does provide a clear definition in my understanding.  What's more,\nit would establish important organizational elements that might not be done\notherwise.  I would keep it.\n4.3 requires the technology chosen in a web site conform to accessibility\nrequirements, and if not, that alternative technology be available\nside-by-side with the main site material.  An example would be using a Flash\nintroductory screen with a link to non-flash presentation.  This means the\nFlash presentation is important for the web site content as defined in the\nbusiness needs, but that an alternative page(s) would be available for those\nnot having or not wanting to use Flash.  I feel 4.3 is very important to\nensure accessibility under certain circumstances and the process is not the\nfactor being considered here.\n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 Draft  Comments",
            "content": "  Firstly, I would like to reiterate the comments made by Christian Buehler\n  on the use of WCAG 1.0.\n\n  Currently, the 1.0 version of WCAG is the official standard not only in\n  Germany, but in the EU. Sweden, where Greytower has its main office, is\n  among the countries who has adopted this standard.\n\n  This means that a smooth transition, as Christian points out, between version\n  1.0 and 2.0 is absolutely essential. It is not likely that 1.0 will be\n  dropped from use in a good, long, time.\n\n  Three points can not be emphasized too strongly:\n\n    1) There must be an exact mapping between versions 1.0 and 2.0, with\n       new and deleted material clearly indicated and explained. We will\n       all be in it up to our ears if a requirement previously considered\n       important is dropped without a logical, clear, explanation.\n\n\n    2) WCAG 2.0 must have an associated list of checkpoints that can be\n       easily, repeatably, and objectively controlled.\n\n    3) WCAG 2.0 must, if at all possible, avoid any and all ambiguities.\n\n\n  It can never be said too often: the WCAG 1.0 is now firmly entrenched with\n  several Governments. This is a good thing. The very last effect we want from\n  WCAG 2.0 is muddied waters.\n\n  Further comments on the draft itself:\n\n\n    1) The document in itself is singularly lacking in clarity. The\n       language is reminiscent of bureaucratese  and at times\n       nonsensical. After working with accessibility since 1996, I\n       find myself shocked by sentences such as \n\n        \"These are additional checkpoints that may be reported in addition\n         to Core conformance if the Required Success Criteria for a given\n         Extended Checkpoint are satisfied.\"\n\n       This is difficult to understand, hard to sell, and very nearly\n       impossible to follow when reviewing material. I am, personally, still\n       not clear on the exact meaning of the above, and would be hard pressed\n       to explain it to people who will decide on whether or not to comply\n       with this standard.\n\n       The draft must be cleared up, and the language taken to a point\n       where it is actually understandable; less this becomes an exercise\n       in futility.\n\n\n\n    2) The concept of \"Core\" and \"Extended\" are horribly unclear. What\n       exactly does a \"valid conformance\" claim mean ? Is the site then\n       accessible to *all* ? To some ? To whom ? Will \"core conformance\"\n       mean roughly the same as WCAG 1.0 'A' ? 'AA' ? 'AAA' ?\n\n       This needs to be dealth with right away - preferably by going away\n       from the entire concept and staying with the definitions of priority\n       1, 2 and 3 from WCAG 1.0 which are clear and easily understandable.\n\n       However, it might be useful to rename them from the rather nonsensical\n       'A', 'AA' and 'AAA' to, for instance:\n\n            \"Priority 1: Basic\"\n            \"Priority 2: Standard\"\n            \"Priority 3: Complete\"\n\n       A question that must be answered is: why were the priorities dropped ?\n\n\n\n    3) Issues have been fluffed up and weakened in this draft. We have, for\n       instance, this:\n\n        \"Perceivable. Ensure that all content can be presented in form(s)\n         that can be perceived by any user - except those aspects of the\n         content that cannot be expressed in words.\"\n\n       which is a miracle of grammatical pink-bunny-wabbit phrasing. This\n       \"guideline\" says to me that we should make sure everyone that can\n       see, read, and understand can perceive the content. If you don't\n       do all three, tough. There is no way this is the intent of the WCAG.\n\n       Even worse is this:\n\n         \"... for markup, except where the site has documented that a\n          specification was violated for backward compatibility, the\n          markup has ... \"\n\n       which gives a carte blanche for site developers to ditch any and\n       all markup standards as long as they tell users what they are up to.\n\n       Yes, my impressions may be based on being a non-native English\n       speaking individual - but quite a few of those who are going to\n       apply or attempt to apply WCAG 2.0 will be in the same position.\n\n       If this version of WCAG is to be functional, i.e. be applied and\n       followed, then it needs to cut to the chase and state what is\n       required:\n\n         \"Perceivable. Ensure that all content be presented in form(s)\n          that can be perceived by any user.\"\n\n       with an added sidenote of\n\n         \"If one form of content is impossible to perceive by a certain\n          user, it should be transformed - automatically and without\n          information loss - to a form that is perceivable\"\n\n\n\n\n  Suggested rewrites and status changes:\n\n(required)\n    1.1: All non-text content should have a textual alternative explicitly\n         associated with it.\n\n         If the content has no informational value, signal this by setting\n         an explicitly emply textual alternative. Avoid descriptions if\n         possible, if not avoid descriptions that refer to specific physical\n         realities (ie. \"blue\" is often nonsensical to a\n         blind person, \"high C\" might not mean much to deaf visitors)\n\n\n(required)\n   1.4a: Text in the content is provided in an ISO character encoding\n         scheme such as 8859-1 or 10642, and served according to\n         established standards so that a user agent can identify the\n         encoding without ambiguity. [The handling of UA defaults should\n         go into UUAG]\n\n\n(required)\n   1.4b: All abbreviations and acronyms are clearly identified with\n         the topic-specific expansion every time they occurr. If the\n         expansion is in another natural language than the one used in\n         the document itself, this change should be clearly identified.\n\n\n(required)\n    1.6: Foreground content is easily differentiable from background for\n         both auditory and visual default presentations.\n\n\n(required)\n    2.4: Structure and/or alternate navigation mechanisms have been added\n         to facilitate orientation and movement in content.\n\n\n(required)\n    3.1: Clearly, and according to standard, identify the natural language\n         of both the document as a whole and - if any part of the document\n         is written in a different language - fragments of it.\n\n\n(moved to required 1.4b)\n    3.2: The definition of abbreviations and acronyms can be unambiguously\n         determined.\n\n\n(required)\n    3.4: Layout and behavior of content is consistent or predictable.\n         [unless WCAG 2.0 REALLY requires all sites to avoid having identical\n          layout from page to page - which it doesn't, when reading the\n          criteria]\n\n\n(required)\n    4.1: All code, whether structure (such as HTML), presentational (css),\n         logical (script), or otherwise should follow a formal, published,\n         standard. If possible, the code should pass validity tests for that\n         same standard. [a note should be added that this isn't strictly\n         possible for scripts, but should ALWAYS be done otherwise]\n\n\n\n\n\n  Additional comments:\n\n   On the editorial comment on glossaries under 3.2: a standard format\n   for linking to glossaries allready exist - atleast for HTML and XHTML - \n   in the form of the LINK element. It would be a good idea to suggest\n   this for use on sites utilizing these markup languages.\n\n   On 4.2: what is the point ? Why list a set of \"required\" technologies\n   and not, instead, ensure that the content transforms gracefully to\n   the user's physical reality ?\n\n\n\n  Finally, it seems to me that alot of GOOD things previously in WCAG 1.0 has\n  been removed from 2.0. I've noted that some say that the new version must\n  be judged as a stand-alone specification, but as Christian Buehler points\n  out: 1.0 will be with us for a long time.\n\n  There are things missing here; things which made sense in WCAG 1.0 and\n  would make sense here as well. The priorities need to come back; and the\n  language tightened up; the ambiguities taken out.\n\n  As it is, WCAG 2.0 will be terribly difficult to take out in the field;\n  doing so is not a prospect I relish.\n\n-- \n -    Tina Holmboe                    Greytower Technologies\n   tina@greytower.net                http://www.greytower.net/\n   [+46] 0708 557 905\n\n\n\n"
        },
        {
            "subject": "Editorial comments on  WCAG draft of 06/0",
            "content": "Editorial comments on http://www.w3.org/TR/2003/WD-WCAG20-20030624/\n1. Under Priorities and Techniques  the following words makes the paragraph longer and  confusing. \n \"The main WCAG 2.0 Working Draft document does not include technology-specific \nimplementation requirements or techniques, but... \"\nStating that \"WCAG 2.0 contains only links to...\" will make the construction simpler and serve \nthe purpose.\n2.  Under Overview of Design Principles\nQualifying the word \"ramp\"  will drive the point in more forcefully. So replace\n\"In the physical world, ramps are used by bicycles, people pushing\nstrollers, and people in wheelchairs.\" \nwith:\n\"In the physical world,  the creation of ramps for sidewalks was mandated to aid wheelchair \nusers. But these help others too like bicycle users, parents with strollers and skate board users.\"\n\n3.   Begin section \"Overview of Design Principles\"  with \"User Needs\". Move the paragraph :\n\"Accessible Web content benefits a variety of people, not just people with disabilities....\"\nto the start of User Needs.\nAfter that say:\n\"Therefore, the overall goal is to create Web content ...\"\nThis construction may improve the flow of the section.\n4. Consider getting rid of the explicit Note in \"Overview of Design Principles\" and  restate \nit at end of list of four guidelines by:\n\"It may be noted that these principles apply only to Web content presented to a human reader \nand not to situations   where the data is intended for use by another machine not requiring \nany human interface like a structured database or metadata collection.\"\n\n5.\nUnder heading \"Designing Accessible Web Content\", \ni. delete statement:\n\"This document is not designed to provide the background needed to\nlearn about accessible Web design in a thorough or effective manner for those interested in \nlearning. Readers are therefore...\" \nand replace with:\n\"Refer to the articles on Web accessibility produced by the Education and Outreach Working \nGroup of the Web Access Initiative for a fuller discussion  of the subject.\"\nii. there is a link to E-O WG. This should be replaced with  a link to an index of completed \ndocs put out by the E-O WG. \n6. Under the section for checkpoint mapping for WCAG 1.0, there is a  image: \nsrc=http://www.w3.org/Icons/detab\nalt=change column layout\ntitle=change column layout  \nI am a JAWS4.51  user and  am unsure  what is meant to be conveyed by  \"graphic change column layout\" that JAWS reads out.\nThanks,\nSailesh Panchang\nSenior Accessibility Engineer\nDeque Systems Inc\n11180  Sunrise Valley Drive, 4th Floor, Reston VA 20191\nTel: 703-225-0380 Extension 105\nFax: 703-225-0387\nE-mail: sailesh.panchang@deque.com\n* Look up <http://www.deque.com> *\n\n\n\n"
        },
        {
            "subject": "Editorial,  general comments on WCAG 2.0 20030624 draf",
            "content": "Greetings,\n\nHere is a small review of the june 24 2003 draft of WCAG 2.0.\n\n** disclaimer **\nI am not an accessibility expert, so my comments are more focused on \nthe quality of the specification (document) itself rather than the \nquality of the guidelines. I just read the document a few times and \ntook notes, so the review is not very structured. I hope it will be \nuseful nonetheless.\nI may add comments later, as time permits.\n\n\n\n** General comments **\nThis draft is good. It did not impress me as much as the previous time \nI reviewed a WCAG2 draft, but that may just be because I'm getting used \nto this specification. Generally speaking, my impression was that \nreading the spec felt clearer, but not as pleasant. Just an impression, \nthough.\n\n\n** Editorial comments **\nStatus: comments list not consistent with what was mentioned in the \ne-mail announcement I received.\n\n\"Priorities and Techniques\" : [[This WCAG 2.0 Working Draft does not \nassign priorities to checkpoints, as did WCAG 1.0.]]. Did 1.0 assign or \nnot assign? It may be that my english is not good enough. Or it may be \nthat the comma could cause some confusion.\n\nidem.: [[Instead, there are two types]]. Specify types \"of what?\".\n\nConformance section :\"becomesless\" (missing white space)\n\n1.2 : requirements are listed as 1,2,1,2,3,4. Looks strange.\n\n3.1: the french phrase is, rather, \"je ne sais quoi\"\n\n3.3: is the first list after the checkpoint's title a conformance \nrequirement or a best practice? Missing heading I suppose.\n\n\n** Notes **\nConformance section : Does look good, even when quickly running the QA \nSpecification checklist against it.\nThe conformance section could use minor improvements such as:\n- adding a conformance disclaimer\n- moving \"Sites that conform to WCAG 1.0\" out of conformance section, \nmaybe...\nI'd suggest renaming it too (using terms such as \"transition\"?)\nI'm not really fond of the idea of CORE+. I would recommend, if you go \nwith that scheme, that CORE+ claims MUST come with a full list of what \nrequirements are met. CORE+n sounds like an invitation to foul play. I \nunderstand the logic behind it but it doesn't seem worth the \ncomplication and complications.\n\n1.2: seems a bit on the verge of technology independent. Would be nice \nif the requirements could be simplified and most of the existing \nwording could be moved to examples/techniques.\n\n1.6: suggested example: as it is possible with graphics to change the \ncontrast, it is possible (if the speech was recorded separately, or \nnot, thanks to sound processing algorithms) to let the end user choose \nwhether (s)he wants the background sound a all, and leave the \npossibility to set the contrast between the two.\n\n3.2: I'm  almost certain you have discussed that to death already, but \n\"first time it appears\" only really makes sense for time-dependent \ncontent, doesn't it? I would suggest a rewording (or a best practice?) \nstating that for interactive, asynchronous or hypertext content, a \nglossary is recommended over a definition \"the first (likely) time a \nword appears\".\n\n3.3: \"not more than necessary\" is hardly testable. Not certain what to \nsuggest, maybe a rewording of the checkpoint's title to talk about \nreview rather than [[written to be no more complex than is necessary]]\n\n4.1: The language used, itself, must be clearly defined (with \nappropriate MIME headers, doctype declaration, etc).\n\nAll for now, keep up the good work.\n-- \nolivier\n\n\n\n"
        },
        {
            "subject": "Comments  Technical, WCAG 2.0 draft of June 200",
            "content": "Technical\n1. Consider inserting a section on  development  process: Choice of technology and impact on accessibility.  This section  should talk about   \"widely available\",  time lag  before assistive tech adopts the technology,availability of AT in natural  language of site,  backword compatibility, etc.  This section may be placed before the guidelines and checkpoints are listed.\n2. Rationale of what constitutes core and extended   like WCAG 1.0 has a structure of P1, P2, P3. Need to explain why   some  are core and some are extended, like \nCore checkpoints : if not complied with, one or more user groups may find  it impossible to access content\nExtended: these enhance (usability)   or facilitate navigation and  provide more efficient  access to content\n3. Under Required  success factors for 2.3: There is a tool that can identify flicker. RAMP from Deque Systems \n(www.deque.com) is the only automated tool that can identify unacceptable flicker   rate  (2 to 55 Hz as per Sec 508) and can  do the 3-49 Hz now proposed.\n4. Checkpoint 2.4: [EXTENDED] Structure and/or alternate navigation mechanisms have been added to facilitate orientation and  movement in content. [was 3.1 and 3.2]\nComment: \ni. I believe that the minimum limit of 50000 word   per doc of 50 page site is not needed. Headings for text sections or \ngroups of links  etc reveal structure and organization of content.  Absence of these struuctural markups make it inefficient  to navigate a  page with even less than  10k words. So wherever  a hierarchy can be used to reasonably structure  the page  content, this checkpoint is applicable.  The author should use judgment to do so.  I am a screen reader user and on numerous  sites sensed the need for structural markup. \nii. While there is mention of headings and titles for text sections, I note the absence of linksthat can be grouped and given  headings. Like product links, links for services  offered, links for different contacts etc. Are markup for headings used to group links  outside the scope of this checkpoint?\n4. Checkpoint 4.2: Technologies that are relied upon by the content are declared and widely available.[was 5.2]\nThe \"are widely available\" part should be dropped. That will influence the decision to adopt a particular technology and is  not under  content  developer's control after the decision is made to go with a technology.\nConsequently references to \"widely available\" in definitions and elsewhere may be deleted.\n5. Checkpoint4.3: Technologies used for presentation and user interface support accessibility or alternate versions of the  content are provided that do support accessibility.[was 5.3 and 5.4]\n Reword as:\n\"Alternate versions of the content that support accessibility are provided  where  technologies used for presentation and  user  interface [do not support accessibility ] or [present barriers to accessibility]\n * * *\nThanks,\nSailesh Panchang\nSenior Accessibility Engineer\nDeque Systems Inc\n11180  Sunrise Valley Drive, 4th Floor, Reston VA 20191\nTel: 703-225-0380 Extension 105\nFax: 703-225-0387\nE-mail: sailesh.panchang@deque.com\n* Look up <http://www.deque.com> *\n\n\n\n"
        },
        {
            "subject": "Editorial comments  WCAG 2.0 draft of June 200",
            "content": "Editorial Comments: continued  from  those sent on 08/05/03\n7. For checkpoint 3.3,  H5 heading is missing:\n\"Required Success Criteria for Checkpoint 3.3\"\n8. Under Benefits for 2.3: \"Individuals with distractibility problems may not be able to...\"\nReplace \"distractibility problems\" with \"tend to get distracted\". That does not appear like proper English and may also be  difficult to translate into other languages.\n9. Consider replacing all headings \"Benefits\" with \"Who is benefitted?\". The style in which the items are listed are more  appropriate for this interrogatory. Also all items under benefits appear to be user groups. \n* * *\nSailesh Panchang\nSenior Accessibility Engineer\nDeque Systems Inc\n11180  Sunrise Valley Drive, 4th Floor, Reston VA 20191\nTel: 703-225-0380 Extension 105\nFax: 703-225-0387\nE-mail: sailesh.panchang@deque.com\n* Look up <http://www.deque.com> *\n\n\n\n"
        },
        {
            "subject": "Technical commentsWCAG 2.0 June draf",
            "content": "Continued from  my comments of Aug 6, 2003\n6. It appears that  there is a shift away from  accessibility for PWD to universal access in WCAG 2.0\n\nConsider that:\ni. Five WCAG 1.0 checkpoints including 3 P1  map to an extended   WCAG 2 checkpoint 4.2 \n\nabout declaring  technology/providing alternative content.\nii. WCAG2's  checkpoint 2.4about navigation mechanisms maps to 13 checkpoints of WCAG 1.0 \n\nsome of which are P1 and some are P2. Checkpoint 2.4 of WCAG 2 is categorized as extended \n\nand not  core.\niii. On the other hand, checkpoints 4.1 and 4.3 relating to language   in WCAG 1.0 now have \n\nbecome  core under  3.1 of WCAG 2.\n\n7. I guess a developer or other user of WCAG 2 will be confused  if he has used WCAG 1. WCAG \n\n1.0 tells him that certain things are absolutely necessary for accessibility and  now WCAG \n\n2.0 relegates those as \"extended\" checkpoints. Then some that were regarded as only as \n\ndesirable   for accessibility by WCAG 1.0 have suddenly become core in WCAG 2.0.\ni. Five WCAG 1.0 checkpoints including 3 P1  map to an extended   WCAG 2 checkpoint 4.2 \n\nabout declaring  technology/providing alternative content.\nii. Five P2 checkpoints make a core 4.1 checkpoint on usage specs.\niii. One P1 and two P3 checkpoints make an extended checkpoint  3.3 under Wcag 2.0 on \n\ncontent complexity.\nThis has given rise to an inconsistency and the first unresolved issue stated on the page \n\nfor \n\"Checkpoint Mapping Between WCAG 1.0 and the WCAG 2.0 Working Draft\"\nThat is why it is necessary for the document to say why some checkpoints are core and some \n\nare extended. (see my suggestion # 2 made earlier) \nWhile on the subject, the single A, double A and triple A conformance levels are primarily \n\nintended to aid developers on focussing on  more critical issues before tackling those that \n\nare only desirable as per WCAG, although  all checkpoints  enhance accessibility. Now WCAG \n\nhas two categories core and extended instead of the three. These   will also  convey the \n\nsame message to the developers: core are very important for accessibility and should be the \n\nfocus of their attention. So this framework isnot a big change over A,AA,AAA or P1, P2, P3 \n\nmethod of WCAG 1.0. So is WCAG 2.0   achieving a whole lot more by reducing the conformance \n\nlevels from 3 to 2? And is it really a reduction when we consider that  Core+N may be \n\nanother level one can claim?\n\n8.  Checkpoint Mapping Between WCAG 1.0 and the WCAG 2.0 Working Draft \nThere is a mismatch in  mapping the checkpoints for 4.2 and 4.3 of WCAG 2.0. All WCAG 1.0 \n\ncheckpoints mapped to 4.2 deal with providing \"alternate versions of the content\"are more \n\nappropriately mappable to 4.3 which reads:\nCheckpoint: 4.3 [EXTENDED] Technologies used for presentation and user interface support \n\naccessibility or alternate versions of the content are provided. \n\n9. Unclear :  The checkpoint ref following every checkpoint  [was**].  Does it  refer to checkpoint ref under  earlier draft version of WCAG 2.0?  This should be clarified in the doc.\nThanks for your consideration. \nSailesh Panchang\nSenior Accessibility Engineer\nDeque Systems Inc\n11180  Sunrise Valley Drive, 4th Floor, Reston VA 20191\nTel: 703-225-0380 Extension 105\nFax: 703-225-0387\nE-mail: sailesh.panchang@deque.com\n* Look up <http://www.deque.com> *\n\n\n\n"
        },
        {
            "subject": "June 2003 Draft, section 4.2 deletion or not",
            "content": "Hi,\n\nI tell people about the WCAG about once a week.  I tell them to pay special attention to sections 6.1, 6.3, 6.5 and 11.4 since these point out the kind of accessibility problems I run in to most often and find to be the final \"stopper\" against accessing a site and retreiving information/files and whatever.\nIf WCAG 2.0 shall be published, it should definitely have a section about this kind of problems, and that section should be a part of the \"CORE\".  WCAG 1.0 correctly states sections 6.1-3 as priority 1.  WCAG 2.0 should do the same.  Section 4.2 should not be removed but rather reflect the content of WCAG 1.0 sections 6 and 11.4.  Being as explicit as in WCAG 1.0 is quite important if you want developers to pay any attention to these issues.\n\nIt seems that (http://www.learningdifficulty.org/develop/w3c-scripts.html) is an attempt to deal further with client-side technology.  I hope you keep working with it.  For games and other toys, this is not that important, but when lots of sites start refusing you access because you can't let them open a popup-window with Javascript but relies on them providing a <a href...> or a submit-button instead of a script-triggered image, it is troublesome.  Sites without alternative navigation should not be allowed to state conformance to WAI.\n\nBest wishes\n/Konny Eriksson, M.Div & IT Consultant, Sweden\n\n\n\n"
        },
        {
            "subject": "Para Victo",
            "content": "Hola Victor, hace unos dias que no contacto contigo a ver si ves este topic.\nLa pagina que te comente le hecharas un vistazo es http://www.totalsexo.com\nMira haber y me dices algo.\n\nUn saludo.\n\n\n\n"
        },
        {
            "subject": "Re: Request for Review: WCAG 2.",
            "content": "wac wrote:\n > if you only look at  three things, please review:\n > 1. checkpoint 1.1: http://www.w3.org/TR/WCAG20/#text-equiv\n\na.. Example 4: an audio file of a speech. (short label + transcript)\n\nAn audio file is embedded in a Web page. The short label says, \"Chairman's\nspeech to the assembly.\" A link to a text transcript is provided immediately\nafter the clip.\n\na.. JH - I would think deaf and hard of hearing people should have the\nability to read the text simultaneously as captions while the video clip is\nbeing displayed rather than having the link to a separate transcript window\ncome up after the video is done.  The benefit here is to see the words as\nthey are spoken because it often relates to what is being shown on the\nvideo - especially when the video is not showing a talking head but things\nin action such as a news clip while the reporter voices over.\n\n > 2. checkpoint 1.2: http://www.w3.org/TR/WCAG20/#media-equiv\n\nException:\nif content is rebroadcast from another medium or resource that complies to\nbroadcast requirements for accessibility (independent of these guidelines),\nthe rebroadcast satisfies the checkpoint if it complies with the other\nguidelines.\n\nJH - Not sure if I understand this right - what about news websites where\nthey show clips from previous television broadcasts that were captioned on\ntelevision but not on the web.  For example, I would like to see CNN or ABC\nor FOX caption their web video clips.\n\n > 3. checkpoint 3.3: http://www.w3.org/TR/WCAG20/#content-complexity\n\nJH - no comment here.  I will review the entire document to make sure\nnothing was left out and comment at a later date.  Thank you for the\nopportunity!\n\nSincerely,\n\nJim House, Director\nMember Services & Public Relations\nTDI\n8630 Fenton St. #604\nSilver Spring, MD 20910\njimhouse@tdi-online.org\nwww.tdi-online.org\nTTY: 301-589-3006\nFAX: 301-589-3797\nVoice: 301-589-3786\nPager: jimhouse@wyndtell.com\nAIM: haus7hill\nVideo: 216.181.8.154 or ils.deafonline.com\nPromoting Equal Access to Telecommunications and Media for People who are\nDeaf, Hard of Hearing, Late-Deafened or Deaf-Blind\n\n\n\n"
        },
        {
            "subject": "Shredders from AB Technolog",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "RV: Happy Holidays",
            "content": "Email template\n           Villas El Rancho\n                  Happy Holidays to Everyone!\n\n--------------------------------------------------------------------\n\n           Somehow, not only for Christmas, But all the long year through,\nThe joy that you give to others, Is the joy that comes back to you. And the\nmore you spend in blessing, The poor and lonely and sad, The more of your\nheart's possessing, Returns to you glad.\n            John Greenleaf Whittier\n\n            Dear Friend,\n\n            As the holiday season is near, your friends at Villas el Rancho\nwould like to send our best wishes for this season and the upcoming year.\n\n\n              Discover the improved common areas\n                  The common areas of our resort have been improved. Visit\nus and enjoy the best vacation you've ever had.\n\n                  Visit our website...\n\n\n               Travel all around the world...\n                  With Villas El Rancho membership, you can go to different\nplaces like Cairo, Barcelona or Honolulu. Enjoy this great opportunity to\nexplore the world.\n\n                  Check it out now...\n\n\n\n\n            Enjoy the following mexican recipe! Vegetable Tamales\n                  Preparation and cooking time: 90 minutes\n                  Cost: Very reasonable\n                  Difficulty: Relatively easy\n\n                  Tamales consist of a preparation cooked in corn husks. In\nMexico, corn husks are frequently used as cooking containers. This simple\nprimitive method allows foods to be cooked without drying out, while\nimparting a unique flavour to them. There are many versions, in which the\nfillings may include meat, cornmeal, or vegetables, as in the version given\nhere. Try different options!\n\n                  Tips\n                  To know if the filling is the proper consistency before\ncooking it, roll out a small ball and drop it into boiling water; if it\nfloats, it's perfect - otherwise add a little butter to soften the batter.\n\n                  To check the tamales for doneness, remove one tamale and\nunwrap it; the corn husk should no longer stick to the dough inside.\n\n                  Ingredients for 6 people\n\n                  8 cobs of corn; 2 eggs; 3 tbsp. butter; 1 onion, finely\nchopped; 125 ml (1/2 cup) milk; 1 tsp. sugar; 1 tomato, peeled, seeded and\nchopped; 1 zucchini, peeled and finely diced; Salt; and freshly ground\npepper.\n\n                  Preparation\n\n                    1.. Remove the husks from the corn; keep some nice\nsupple husks from the best 4 or 6 ears; soak them in hot water to tenderize\nthem;\n                    2.. remove the kernels from the cobs using a sharp\nknife;\n                    3.. melt the butter in a skillet; add the onion and cook\nuntil it becomes translucent; add the tomato, zucchini and sugar; season and\ncook 5 minutes longer;\n                    4.. add the corn and the eggs that have been beaten\ntogether with the milk, and continue cooking over low heat for 10 minutes,\nstirring constantly;\n                    5.. spread the corn husks out on a work surface; divide\nthe filling mixture onto the middle of the husks; if the husks are too\nsmall, overlap two husks;\n                    6.. fold the two ends in towards the centre; roll the\nhusks up to form a little package; tie with kitchen string;\n                    7.. take a large pot and add in about three fingers'\nheight of water; place a rack inside, being sure that it is not sitting in\nthe water; line the rack with corn husks and place the tamales on top; cover\nwith more husks and a kitchen towel folded to fit the pot; close tightly to\nkeep all the steam inside; cook for an hour on medium heat;\n                    8.. untie the packages and pile them on a serving\nplatter.\n\n\n\n            We hope you enjoy this newsletter. Please feel free to send us\nall your comments and suggestions.\n\n            Have a great day!\n\n            Sincerely,\n\n            Villas El Rancho\n\n\n--------------------------------------------------------------------\n            e-mail: info@elrancho.com.mx\n            phone: (+52) 871-7160606\n            web: http://www.elrancho.com.mx\n\n\nThis email was sent to you, by Villas El Rancho.\n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Used Formwork/Peri Dok",
            "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n"
        },
        {
            "subject": "New Public mailing list - public-comments-wcag20  maintained by  Wendy Chishol",
            "content": "Maintaining Activity: WAI[1]\n\nList Purpose:  This list is used to archive public comments about Web\nContent Accessibility Guidelines 2.0 (WCAG 2.0)[2].  Editors, chairs, and\nthe staff contact of the WCAG WG[3] receive these comments and pass them\non to the WCAG WG.\n\nReference:  Web Content Accessibility Guidelines 2.0 (WCAG 2.0)[2]\n\n\n\n\n1.  http://www.w3.org/WAI/\n2.  http://www.w3.org/TR/WCAG20/\n3.  http://www.w3.org/WAI/GL/\n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "How to get 10,000 free hits per day. Make money for freeeee",
            "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-1105 at 19:00 UTC, 11am Pacific,  2pm Eastern, 19:00 UK, 20:00 France, 6am Australia (next day!",
            "content": "Folks, \n\nApologies. I haven't had a chance to put together the usual agenda, but\nthe meeting will still proceed tonight.  7pm GMT.\n\nOn my short list I have:\n\nFAQs\nFinal review: PHIL\nhttp://www.w3.org/International/questions/qa-setting-encoding-in-applica\ntions.html\n\nFirst review: DEBORAH\nhttp://www.w3.org/International/questions/qa-utf8-bom.html\n\n\nMeetings for the next 2 weeks (while I'm in Beijing and Yokohama).\n\nNext FAQ assignments.\n\nRI's progress on tutorial, and how we might be able to use it.\n\n\n\nRI\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "RE: Auto: public-commentswcag20&#64;w3.org autorepl",
            "content": "Oops.  Apologies - sent to wrong address.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n> -----Original Message-----\n> From: W3C Postmaster [mailto:postmaster@w3.org] \n> Sent: 05 November 2003 16:34\n> To: ishida@w3.org\n> Subject: Auto: public-comments-wcag20@w3.org autoreply\n> \n> \n> \n> \n> Thank you for sending comments about Web Content \n> Accessibility Guidelines 2.0 (WCAG 2.0).  \n> The WCAG WG appreciates your input and will take these \n> comments into consideration.\n> \n> \n> \n> ----------------------------------------------------------------------\n> >From owner-public-comments-wcag20@dr-nick.w3.org  Wed Nov  5 \n> 11:34:09 \n> >2003\n> Return-Path: <owner-public-comments-wcag20@dr-nick.w3.org>\n> Delivered-To: public-comments-wcag20@w3.org\n> Received: from w3c40upc3ma3j2 (homer.w3.org [18.29.0.30])\n> by dr-nick.w3.org (Postfix) with ESMTP id 8076413D80\n> for <public-comments-wcag20@w3.org>; Wed,  5 Nov 2003 \n> 11:34:09 -0500 (EST)\n> Reply-To: <ishida@w3.org>\n> From: \"Richard Ishida\" <ishida@w3.org>\n> To: <public-comments-wcag20@w3.org>\n> Subject: AGENDA: I18N GEO TF telcon, 2003-11-05 at 19:00 UTC, \n> 11am Pacific,  2pm Eastern, 19:00 UK, 20:00 France, 6am \n> Australia (next day!)\n> Date: Wed, 5 Nov 2003 16:33:45 -0000\n> Organization: w3c\n> Message-ID: <003801c3a3ba$98636080$6601a8c0@w3c40upc3ma3j2>\n> MIME-Version: 1.0\n> Content-Type: text/plain;\n> charset=\"US-ASCII\"\n> Content-Transfer-Encoding: 7bit\n> X-Priority: 3 (Normal)\n> X-MSMail-Priority: Normal\n> X-Mailer: Microsoft Outlook, Build 10.0.3416\n> Importance: Normal\n> X-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165\n> \n> Folks, \n> \n> Apologies. I haven't had a chance to put together the usual \n> agenda, but the meeting will still proceed tonight.  7pm GMT.\n> \n> On my short list I have:\n> \n> FAQs\n> Final review: PHIL \n> http://www.w3.org/International/questions/qa-setting-encoding-\nin-applica\ntions.html\n\nFirst review: DEBORAH\nhttp://www.w3.org/International/questions/qa-utf8-bom.html\n\n\nMeetings for the next 2 weeks (while I'm in Beijing and Yokohama).\n\nNext FAQ assignments.\n\nRI's progress on tutorial, and how we might be able to use it.\n\n\n\nRI\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "How to Save Web Accessibility from Itsel",
            "content": "As I explained nearly a full year ago--\n\n<http://lists.w3.org/Archives/Public/w3c-wai-gl/2002OctDec/0296.html>\n\n-- I worked on an article for A List Apart on the deficiencies of \nWCAG 2.0 and how specific topic experts could be recruited to fix \nthem. A List Apart recently relaunched, and the article is now \nfinally done.\n\n<http://www.alistapart.com/articles/saveaccessibility/>\n\n-- \n\n     Joe Clark | joeclark@joeclark.org | <http://joeclark.org/access/>\n     Author, _Building Accessible Websites_ | <http://joeclark.org/book/>\n     Expect criticism if you top-post\n\n\n\n"
        },
        {
            "subject": "Greg Lowney's Comments on WCAG 2.0 Draft of 2003-100",
            "content": "Hello,\n \nHere are some comments and suggestions based on WCAG 2.0 Draft\n2003-10-08. \nI've included them inline below, and also as attached Word and Text\ndocuments.\n \nI apologize for these being so late and so voluminous; I leave the\nmethod of whether or how you want to handle them to your discretion.\n \nI'm more than happy to clarify or discuss them.\n \n    Thanks,\n    Greg Lowney\n    Lowney Access Research, LLC\n \nGreg Lowney's Comments on \nWCAG 2.0 Draft of 2003-10-08\n\nNotes: \n\n1.this document is structured with the first level of numbered\nitems (numbered 1, 2, etc.) identifying the context of my specific\ncomments/suggestions (numbered 1.a, 1.b, etc.). \n\n2.Most of these comments are based on the draft of 2003-09-30, but\nlater ones are based on the draft of 2003-10-08. \n\n3.Much of this was entered using voice dictation so please excuse\nany errors that were caused by misrecognition.\n\n \n\n1.        Some thoughts on reorganization proposal five, dated October\n8, 2003.\n\n1.a.        [COMMENT] Overall I'm very pleased with the reorganization\nproposal. I like the move to principles and guidelines.  \n\n1.b.        [MEDIUM PRIORITY] I would like to see the guidelines phrased\nusing prescriptive wording like that used for the principles; for\nexample, changing \"Synchronized media equivalents are provided for\ntime-dependent presentations\" to \"Provide synchronized media equivalents\nfor time-dependent presentations.\" I believe that wording is more in\nkeeping with their designation as \"guidelines\".\n\n1.c.        [COMMENT] Personally I am not thrilled with the terms used\nfor Single-A, Double-A, and Triple-A designations.  I wish I had a\nbetter proposal. If we were just English I would consider using A, B,\nand C, but I doubt that type of thing would be cross culturally\napplicable. Another option would be core, expanded, and expanded +. I\nwish that the terms would sort in ascending order, which would be true\nof \"A\", \"AA\", and \"AAA\". Are Single-A, Double-A, and Triple-A\ncross-culturally meaningful expressions?\n\n1.d.        [MEDIUM PRIORITY] I suggest changing the numbering scheme so\nthat all of the Criteria for a Guideline are sequentially numbered. For\nexample, under Principle 3 is Guideline 3.3, and under that we have\nthree separate Criteria numbered \"1\", one each in the subcategories of\nSingle-A, Double-A, and Triple-A. (In fact, the first item numbered \"1\"\nisn't a Criterion at all, just a placeholder saying that there aren't\nany criteria in this category!) I suggest instead the first criteria\n(which is under the Double-A heading) be numbered 3.3.1, and the second\n(which is under the Triple-A heading) be numbered 3.3.2. The placeholder\nunder the Single-A heading should not be numbered. This would make it\nMUCH easier to refer to a specific criteria: you could say \"3.3.2\"\ninstead of \"Triple-A Criterion 1 in section 3.3\". Another viable\napproach, although more cumbersome, would be \"3.3.A.1\" and \"3.3.AA.1\",\nor perhaps \"3.3.A1\" and \"3.3.AA1\".\n\n1.e.        [COMMENT] There are still comments in the document that\nrefer to \"Extended Checkpoints\"; is that concept gone now that we have\nSingle-A, etc., designations? I hope that we will not move any\nprinciples or guidelines to a separate document just because they lack\nSingle-A guidelines.\n\n1.f.         [QUESTION] What became of the section on conformance\nclaims? \n\n1.g.       [MEDIUM PRIORITY]You should clarify for the reader whether\nthe examples given are designed to be \"recommended\" solutions or whether\nthey are just one of many possible solutions. (Note that some, such as\nexample one under Checkpoint 2.2, is definitely a solution that I would\nnot recommend! It reads \"Client-side scripting is used to create\nblinking text. The user can deactivate the use of scripting in his or\nher browser or override the use of scripts with a user style sheet.\")\n\n1.h.       [MEDIUM PRIORITY] I find the format used for examples to be\nsomewhat confusing.  A prime example would be Checkpoint 2.2 -- please\nsee my comments there about the phrase \"examples of content that\nrequires a response within a timed interval\".  In addition, I think you\nwould beat much clearer if we replace the list of examples, each of\nwhich consists of the name of the problem followed by a solution that is\nwritten in the present tense as if the solution had already been\nimplemented, with a \"scenario\" followed by a list of one or more\n\"possible solutions\".  Using 2.2 is an example, I would rewrite as\nfollows: \n\nScenario <number>: <title>\n\nProblem: <text>\n\nPossible solutions: \n\n                1. <sample solution 1>\n\n                2. <sample solution 2>\n\nTwo examples of rewriting sample solutions:\n\n1. The web site can provide a user-controlled option which causes the\nserver to offer up web pages to use another form of emphasis rather than\nblinking.\n\n2. If client-side scripting is used to create blinking text, user can\ndeactivate the use of scripting in his or her user agent, or override\nthe use of scripts with a user style sheet.  (However, this approach is\nnot recommend because it will also disable other scripts which may be\nnecessary for use of content.)\n\n2.        Principle 1. \"Make content perceivable by any user\"\n\n2.a.        [MEDIUM PRIORITY] I suggest defining \"content\" here, as well\nas in the glossary, since it is so key to understanding the principle.\nFor example, does it include UI elements as well as text and graphics?\n\n2.b.        [MEDIUM PRIORITY] The distinction between UI elements and\nother content is somewhat artificial, since in most browsers the user\ncan interact with any text or graphics (for example, select and copy\ntext, click on text or graphics that is also a link, etc.).\n\n3.        Guideline 1.1 \"All non-text content that can be expressed in\nwords\"\n\n3.a.        [HIGH PRIORITY] I still have reservations about the concept\nof non-text content that cannot be expressed in words. To me, almost\nanything can be expressed in words, even a piece of artwork or musical\npiece.  For example, I believe that I could describe a painting in terms\nthat would satisfy most blind or not physically present listeners\n(although not art students who are looking for a level of detail beyond\nthe superficial) and I could do it in fewer words than would be required\nto convey all the information found in a large work and complex table.\nI even her story on NPR recently about how some symphony orchestras are\nproviding real-time, synchronized text descriptions of the music as it\nis being played, in order to help their patrons appreciate the\nsubtleties of what they're hearing.  Isn't that a textual description of\na piece of classical music?\n\n4.        Guideline 1.1 Benefits of Checkpoint 1.1\n\n4.a.        [LOW PRIORITY] I believe there are quite a few benefits to\nCheckpoint 1.1 which are not currently listed. Some of these are\nmainstream advantages, rather than being particular to people with\ndisabilities; I believe it is useful to list these because it\nstrengthens our case, although it is probably good to distinguish them\nfrom the accessibility advantages. Some examples include:\n\n4.a.1.   Transcripts, and certain types of captions, allow users to\nabsorb the information at their own pace rather than being forced to try\nto keep up with a synchronized presentation.\n\n4.a.2.   Textual descriptions can be translated into other natural\nlanguages for users who are not fluent in the content's original\nlanguage.\n\n4.a.3.   Textual equivalents can be presented in the user's choice of\nvisual attributes and layout, which is usually not true of non-textual\ncontent.\n\n4.a.4.   Textual equivalents facilitate reusing the information in the\nweb content by allowing the information to be extracted and in many\ncases parsed, understood, and altered by automated systems.\n\n4.a.5.   Textual equivalents and facilitate navigation within content,\nsuch as when the user specifies that they want to go to a certain phrase\nand that phrase is found in the textual equivalent of a piece of content\n(such as ALT text).\n\n4.a.6.   Users can request that they are user agent will download the\ntextual equivalents of non-text content in order to download more\nquickly over low bandwidth connections.\n\n4.a.7.   Textual equivalents are needed by user agents for do not\nsupport non-textual content, including those on some handheld devices.\n\n4.a.8.   Visual descriptions are often necessary to allow a person with\ndisabilities up to communicate effectively with people who are using the\ndefault visual presentation.\n\n5.        Guideline 1.1 \"Example 1: an image used as a button. (short\ndescription of function)\"\n\n5.a.        [HIGH PRIORITY] I believe is important to provide a textual\ndescription of the appearance of an image used to represent a button in\norder to allow effective communication between a person using the\ntextual description and a person using the visual presentation.  For\nexample, it poses a significant problem when a person who is blind tells\na coworker to click on the \"delete button\" when the sighted user sees a\npicture of a garbage can-and vice versa.\n\n6.        Guideline 1.1 'The text equivalent is \"Next Slide,\" so that\nwhat is read by a screen reader would be \"link: Next Slide.\"'\n\n6.a.        [LOW PRIORITY] We should not imply that all screen readers\nread the same, so I recommend changing this slightly to say \"so that a\nscreen reader might read\".\n\n7.        Guideline 1.1 \"A link to a text transcript is provided\nimmediately after the clip.\"\n\n7.a.        [MEDIUM PRIORITY] When supported by the content format,\nmetadata should be provided for the non-textual content that provides a\nlink to the textual description.  This should allow a user agent to\nrequest and present to the user the textual description of the\nnon-textual content without requiring the user to hunt around for a\ncorresponding link, and it would also avoid having extraneous links\nclutter the presentation for users who do not require them.\n\n8.        Guideline 1.2 \"an audio description is provided\"\n\n8.a.        [MEDIUM PRIORITY] Is an audio description alone sufficient?\nIt doesn't help a person who is deaf-blind, who would instead benefit\nfrom having a textual description of the visuals, which in turn could be\nreformatted into Braille or presented on a Braille display. If you\ndecide not to require textual descriptions for any checkpoints, then I\nrecommend at least making and explaining the explicit decision to do so.\n\n9.        Guideline 1.2 \"if content is rebroadcast from another medium\nor resource that complies to broadcast requirements for accessibility\n(independent of these guidelines), the rebroadcast satisfies the\ncheckpoint if it complies with the other guidelines\"\n\n9.a.        [HIGH PRIORITY] I'm not sure I understand this exception.\nTake the example of a news broadcast on television which is provided\nwith closed captions when broadcast live; if the live broadcast complies\nwith accessibility guidelines for live broadcasts, that would seem to\ninvoke this exception and thus mean that the web site where the\nbroadcast is available for later viewing is not required to provide any\ncaptioning.  Is that your intention?  Is the implication that Checkpoint\n1.1 would still be required, and be satisfied by providing static rather\nthan synchronized transcripts?  I do not understand why the requirement\nshould be higher for a multimedia presentation which is only on the web\nsite that it is for something that is now owned on the web site but at\none time was available somewhere else.\n\n10.     Guideline 1.3 \"Information, functionality, and structure are\nseparable from presentation.\"\n\n10.a.    [HIGH PRIORITY] The wording of this guideline seems too vague,\nand it's hard even for me to see how the actual checkpoints under this\nguideline relate to the guideline's title. I also believe that those\ncheckpoints fall into two distinct groups that are so different that it\nwould make more sense to separate them into two separate guidelines:\n\"Content, structure, and formatting are available programmatically\" and\n\"Give user control over presentation of content, structure, and\nformatting\". \n\n11.     Guideline 1.3 \"the following can be derived programmatically\n(i.e. through a markup or data model that is assistive technology\ncompatible)\"\n\n11.a.    [HIGH PRIORITY] I would modify this to say that structural\nelements must be distinguished by standard structural markup or API\nwhere such exist; non-standardized (e.g. proprietary, platform- or\napplication-specific) markup or API may also be used and should be used\nwhen no standardized markup or API is defined for the content type. This\nwill allow a wider range of user agents to change the presentation of\nthe structural elements in a concerted fashion than would be the case\nwhen proprietary markup or API are used. \n\n11.b.    [MEDIUM PRIORITY] We probably need to define \"assistive\ntechnology compatible\" if we want this to be measurable. Note that the\nissue of compatibility with assistant technology is not a simple one.\nMarkup is great if the data format, pipeline, user agent, user agents\nplatform, and assistive technology all support it. Similar restrictions\napply to the data model.\n\n12.     Guideline 1.3 \"the following can be derived programmatically:\n.any emphasis\"\n\n12.a.    [LOW PRIORITY] Do we need to define emphasis?  Is emphasis any\noccurrence of a section of text which is formatted differently than the\ntext around it?  \n\n12.b.    [LOW PRIORITY] Might it be necessary for the user to\ndistinguish between different types of emphasis, which are usually\nindicated by different fonts or formatting (as when an author uses\nunderscoring to mean something different than bolding)?  \n\n12.c.    [MEDIUM PRIORITY] Isn't it also important for the user to be\nable to find out about the visual formatting of the text (as distinct\nfrom its semantic formatting) in order to communicate about the text\nwith people hoary using the normal visual formatting?  \n\n12.d.    [LOW PRIORITY] Are drop caps an example of formatting or of\nemphasis? Offhand I think they're probably used most often in a purely\ndecorative fashion, but they probably do convey to the visual reader the\nfact that they are starting a new section of the text, and in some cases\nthey may be used with a more explicit meaning, such as introducing a\nsection dealing with that emphasized letter.\n\n13.     Guideline 1.3 Checkpoint 3 \"Text content is not presented over a\nbackground image or pattern OR the text is easily readable when the page\nis viewed in black and white (no grayscale).\"\n\n13.a.    I think this belongs under 1.6 \"Foreground content is easily\ndifferentiable from background for visual default presentations\" rather\nthan under 1.3.\n\n14.     Guideline 1.3 \"The markup that creates the columns is separate\nfrom the markup that specifies the logical structure of the document.\"\n\n14.a.    [MEDIUM PRIORITY] I recommend clarifying the meaning of\n\"separate from.\" By this phrase, do you mean to require that the two\ncategories of markup be distinguishable, or that they actually have to\nbe physically separate? If separate, must they be in separate files or\ncan they be in separate sections of the same file? Personally I believe\nthey should only be distinguishable from each other. \n\n15.     Guideline 1.3 \"Example 2: a scrolling list of stock prices.\nCurrent stock quotes are scrolled horizontally across the screen. The\ndata are separate from the methods used to scroll the text across the\npage.\"\n\n15.a.    [MEDIUM PRIORITY] So what is the recommended solution in this\ncase? It is not obvious, given that the server probably does not have\nall the quotes at any one time, nor does it necessarily retain values\nafter they are displayed.\n\n16.     Guideline 1.4 \"All text can be decoded into words represented in\nUnicode\"\n\n16.a.    [LOW PRIORITY] You should include Unicode in the glossary and\nprovide a reference to the official specification.\n\n17.     Guideline 1.4 \"Abbreviations and acronyms are clearly identified\neach time they occur if they collide with a word in the standard\nlanguage that would also logically appear in the same case (e.g. all\ncaps).\"\n\n17.a.    [MEDIUM PRIORITY] The draft includes a pointer to an online\ndiscussion wherein Ben Caldwell suggests that abbreviations and acronyms\nneed only be marked up as such in the first occurrence with a document.\nThat makes some sense, but I see two problems with the proposal: first,\nthat this would place the burden on user agents to keep track of all the\nacronyms and abbreviations encountered a document, which probably none\nof them today and which might be difficult on platforms with very small\nmemory allocations; second, that the definition of \"within a document\"\nmight be problematic in a large number of cases, particularly where\nmultiple pieces of content are pulled from a database and assembled.  Is\na document a single web page or is it a section of web page for a web\nsite?  One additional danger is that marking up the term only the first\noccurrence will leave the term out of sections of the document that are\ncopied for storage or pasting into another document. I recommend that\nall occurrences be marked up, but I'd also recommend that authoring\ntools automate this process as much as possible (e.g. applying acronym\nmarkup to all occurrences of the term).\n\n18.     Guideline 1.4 \"Example 2: an acronym in a page title. In the\nfollowing heading, \"People of the W3C.\" the acronym 'W3C' is marked as\nan acronym\"\n\n18.a.    [LOW PRIORITY] Actually in this document in this example the\nterm is not marked as an acronym.  I suggest you to be marked up\nproperly in this file or else the wording be changed to \"the acronym...\nshould be marked as an acronym.\"\n\n19.     Guideline 1.5 \"Structure has been made perceivable through\npresentation\"\n\n19.a.    [HIGH PRIORITY] I consider user control to be more important\nthan having the default presentation distinguish between these elements\neither visually or audibly. I guess that's covered by section 1.3, which\nrequires structure to be programmatically determinable, which in turn\nshould allow UA to adjust the presentation. However, for a document to\nbe accessible it requires that for all content types used there be an\navailable UA (or plug-in, etc.) that displays that content type and\nmeets UA accessibility guidelines. Do we already say that anywhere? \n\n19.b.    [MEDIUM PRIORITY] I would move \"users can control the\npresentation of structural elements or the emphasis on the structure can\nbe varied through alternate presentation formats\" up to requirement\n(Level 1 Success Criterion), with an added caveat like \", if supported\nby the technology\".\n\n20.     Guideline 1.5 \"for visual presentations, font variations,\nstyles, size and white space can be used to emphasize structure.color\nand graphics can be used to emphasize structure.\"\n\n20.a.    [LOW PRIORITY] These two bullet items both list things that can\nbe done to visually emphasize structure; why are they not combined into\na single bullet item?\n\n21.     Guideline 1.5 \"if content is targeted for a specific user group\nand the presentation of the structured content is not salient enough to\nmeet the needs of your audience, additional graphics, colors, sounds,\nand other aspects of presentation can be used to emphasize the\nstructure\"\n\n21.a.    [LOW PRIORITY] I cannot figure out what this bullet item is\nsupposed to convey. Why is this limited to documents targeted at\nspecific user groups?\n\n22.     Guideline 1.5 \"Subtle differences between the appearance of the\nchapter title and the section headings helps the user understand the\nhierarchy and relationship between the title and headings\"\n\n22.a.    [MEDIUM PRIORITY] I disapprove of recommending subtle\ndifferences; I know from personal experience that I am often confused by\nstandard technical publications (such as Microsoft's printed manuals)\nwhere a very slight difference in font size is all that distinguishes\ndifferent levels of headings. That may be fine when you see the\ndifferent styles together on the same page and so can see that one is\nlarger than the other, but when you only see one it is very difficult to\nbe sure whether it is a sub header or a peer to a header that occurred\non an earlier page. Ideally the visual presentation should tell you what\nyou need to know about the structure without having to get out a ruler.\n\n23.     Guideline 1.6 \"Foreground content is easily distinguishable from\nbackground.default presentations\"\n\n23.a.    [HIGH PRIORITY] I consider the user's ability to adjust the\npresentation to be much more important than the details of the default\npresentation.  Therefore I recommend we also include a recommendation or\nrequirement that the user be able to omit backgrounds that overlap text\nor information-bearing graphics.\n\n23.b.    [MEDIUM PRIORITY] I believe that the guidelines are lumping\ntogether two separate issues involving the distinction between\nforeground and background content: \n\n23.b.1.      First, there is the distinction between content that is\nimportant (because it carries information) and that which is purely\ndecorative (meaning it carries no information). It would be useful to\nlet users reduce visual clutter and distraction by choosing to hide or\nde-emphasize purely decorative content. \n\n23.b.2.      Second, it can be difficult to interpret a presentation\nwhere two pieces of content overlap each other, either visually or\naudibly. To address that, we should say that the presentation should\neither not overlap pieces of content or it should provide the user with\nthe ability to forces pieces to not overlap. The latter can be\naccomplished either by rearranging the pieces or by hiding pieces that\nare purely decorative (that is, pieces which do not convey any\ninformation). \n\n23.c.    Is it possible to replace this distinction between \"foreground\"\nand \"background\" with one of useful vs. purely decorative content, such\nas saying that the user should be able to hide all purely decorative\ncontent? Or, if you're really only talking about background harming the\nlegibility of foreground content, then maybe a more general thing about\nmaking sure that background does not overlap foreground, or can be\nhidden. After all, distinguishing one from another does not necessarily\nimply that the foreground is legible.\n\n24.     Guideline 1.6 \"text that is presented over a background color or\ngrayscale has a mechanism that allows the text to be presented in a\nfashion.\"\n\n24.a.    [MEDIUM PRIORITY] The wording of the Guideline is at odds with\nthe wording of this Success Criterion: the Guideline says it's\naddressing \"default presentation\" but the Success Criterion discusses\nproviding a mechanism that lets the user choose a non-default\npresentation option. Therefore you might want to remove the word\n\"default\" from the Guideline title.\n\n25.     Guideline 1.6 \"Groups of rows or columns are labeled with\nheaders.\"\n\n25.a.    [MEDIUM PRIORITY] Add that headers should be visually distinct\nfrom content cells.\n\n26.     Guideline 1.6 \"[use].a different, more formal voice to read\ntitles and headers so the listener can easily identify the words as a\ntitle and not part of the running text\"\n\n26.a.    [LOW PRIORITY] You might also want to mention that can be\nuseful to pause before voicing headers.\n\n27.     Guideline 1.6 \"text that is presented over a background color or\ngrayscale\"\n\n27.a.    [HIGH PRIORITY] I would rephrase this to \"text that is\npresented over a nonblank background\" or something similar that would\ninclude background images and patterns as well as background colors and\ngrayscale.\n\n28.     Guideline 1.7 \"Example 1: a background image on a page.\"\n\n28.a.    [MEDIUM PRIORITY] This example is applicable to 1.6, so it\nshould be deleted from 1.7.\n\n29.     Guideline 1.7 \"Where speech is mixed or recorded so that it is\nat least 20 db above any background sounds people do not need to rely on\ncaptions to understand the dialog.\"\n\n29.a.    [LOW PRIORITY] Minor, but I'd qualify this as \".MOST people do\nnot need.\" since some people clearly do still need to rely on captions\nto understand the dialogue.\n\n30.     Principle 2 \"All functionality is operable at a minimum through\na keyboard or a keyboard interface\" and \"Example 2: examples of Web\ncontent that would and would not be operable from a keyboard or keyboard\ninterface\"\n\n30.a.    [HIGH PRIORITY] I just want to make sure that I'm clear on\nthis: according to my interpretation of this guideline and its\ncheckpoints, it seems that ALL Java applets would comply with this\nguideline because they can be run on platforms that support the\nMouseKeys feature. That is, the guidelines do not seem to require that\nthe product to be easily used with a keyboard, or in fact to take any\nsteps that would accommodate keyboard users.  Is this your intention?\nCan you provide any other examples of things that would fail to meet\nthis criterion? (I noticed that an earlier draft of this document noted\nthat the editors were going to try to create some tests that would\nrequire more than just MouseKeys to pass.)\n\n31.     Guideline 2.1 \"where the functionality or its outcome can be\nexpressed in words\"\n\n31.a.    [LOW PRIORITY] The glossary defines content that can be\nexpressed in words, but not functionality or its outcome that can be\nexpressed in words. Since you use this unusual term, should you explain\nwhat it means?\n\n32.     Guideline 2.1 \"wherever a choice between event handlers is\navailable and supported, the more abstract event is used\"\n\n32.a.    [MEDIUM PRIORITY] You might want to define \"event handlers\" in\nthe glossary (and refer to the definition here), and also discuss what\nmakes them more or less abstract.\n\n33.     Guideline 2.2 \"control any time limits.unless.real time events\nor competition\"\n\n33.a.    [LOW PRIORITY] Is competition really different from other \"real\ntime events\" already mentioned? Oh well, I guess a little redundancy\ncan't hurt and might make things clearer.\n\n33.b.    [MEDIUM PRIORITY] You might add a note (either in the glossary\nor in Guideline 2.2) to the effect that developers should take care to\ngive the user as much control as possible over any interaction that will\ninterrupt the user's task or train of thought. It is usually possible to\ngive the user the option of delaying or suppressing most interactions\nthat are triggered by external, real-time events, such as notice of\nincoming email or the availability of updated content. \n\n34.     Guideline 2.2 \"content is designed so that time limits are not\nan essential part of interaction or at least one of the following is\ntrue for each time limit\"\n\n34.a.    [HIGH PRIORITY] I suggest adding another means of complying\nwith this criterion: an alternative method of accomplishing the same\ngoal is provided which meets the above exceptions.\n\n34.b.    [HIGH PRIORITY] I suggest adding another means of complying\nwith this criterion: in a supervised or moderated setting (such as a\nstudent taking a computer-based test), the person supervising or\nmoderating the experience is able to deactivate the time limit or adjust\nthe time limit over a wide range which is at least 10 times the average\nuser's preference.\n\n35.     Guideline 2.2 \"People with physical disabilities might not be\nable to move quickly or accurately enough to interact with moving\nobjects\"\n\n35.a.    [LOW PRIORITY] I would add \".or may take longer than usual to\ninteract with the UI elements.\"\n\n36.     Guideline 2.2 \"Examples of content that requires comprehension\nor a response within a timed interval\"\n\n36.a.    [MEDIUM PRIORITY] I suggest rewarding this slightly to make it\nclear that the things listed are not things which are granted an\nexemption but rather are things that require modification in order to\ncomply with Checkpoint 2.2.\n\n37.     Guideline 2.2 \"Client-side scripting is used to create blinking\ntext. The user can deactivate the use of scripting in his or her browser\nor override the use of scripts with a user style sheet.\"\n\n37.a.    [HIGH PRIORITY] I really dislike this recommended solution\nbecause it's using a sledgehammer to pound in a nail: deactivating all\nscripts would have a lot of and potentially very harmful effects on the\nuser's ability to carry out their work.  A far better solution would be\none that is very specific to this problem: the site should provide an\noption that would let the user disable the blinking text while still\nleaving other, more benign formatting intact.\n\n38.     Guideline 2.3 \"user can avoid experiencing screen flicker\"\n\n38.a.    [MEDIUM PRIORITY] It seems that screen flicker could be limited\nby the User Agent, which would be a more reliable approach because it\nwould protect the user from badly designed web content. \n\n38.b.    [MEDIUM PRIORITY] I seem to recall a discussion of whether a\nweb page (or equivalent) the displays multiple items, each updating\nslower than three hertz but all visible simultaneously can equal the\neffect of having one element which updates more frequently than three\nhertz. Is that true?  Is that something we should warn against?\n\n39.     Guideline 2.3 \"content was not designed to flicker (or flash) in\nthe range of 3 to 49 Hz\"\n\n39.a.    [MEDIUM PRIORITY] I think you would be more accurate to\nrecommend that \"content was designed not to flicker...\" (rather than\n\"content was not designed to flicker.\"); that is, the current wording\nwould seem to be met by any web page which flickers inadvertently rather\nthan by design. Or were you intentionally trying to say that the\nrequirement is merely that it not intentionally flicker, and that\navoiding inadvertent flickering is only a best practice?\n\n39.b.    [MEDIUM PRIORITY] Might the actual flicker rate very depending\non the hardware and software platform?  It seems like a web page which\ndoes not visibly flicker when displayed on a fast PC might visibly\nflicker when displayed on a very slow PC.  Should we address this?\nShould we specify something like what platforms need to be tested to\nverify that is not flickering unacceptably?\n\n40.     Guideline 2.3 \"Individuals who are easily distracted may not be\nable to focus on page content with flicker occurring in the same visual\nfield\"\n\n40.a.    [HIGH PRIORITY] Isn't it also true that these individuals will\nprobably be just as distracted by pieces of content updating within\ntheir visual field, even if the updating is not at a rate which is\nconsidered flicker? Should we address this by saying, in essence, that\nthe user should be able to disable any animations or automatic updates?\nThe more inclusive recommendation seems much more useful. \n\n41.     Guideline 2.4 \"Mechanisms have been added to facilitate\norientation and movement in content\"\n\n41.a.    [LOW PRIORITY] I think the word \"added\" should be changed to\n\"included\", making the sentence \"Mechanisms have been included that\nfacilitate orientation and movement in content\". The reason is that\n\"added\" makes it sound like something that is only done for\naccessibility reasons, as an afterthought or extra action.\n\n42.     Guideline 2.4 \"a user is able to move through the content in an\norder that follows the visual layout or follows the order the page is\nread.\" (This is the proposed new wording, per the BBS posting.)\n\n42.a.    [HIGH PRIORITY] What do you mean by \"move through the content\"?\nSimply scroll? Or are you requiring the UA to have the equivalent of a\ncursor that the user can position within the content? What content would\nfail this checkpoint? If the user agent is able to figure out the\nspatial locations of all elements in the document as they are visually\npresented (e.g. a Web browser knows where it is displaying each element\nof the HTML) it can choose whatever order it feels is appropriate,\nincluding making a best guess at the order the user might read it in. Is\nthat sufficient? What does the content have to do to facilitate this?\n\nIt is not always advantageous to follow the visual layout: users of\nscreen readers, for example, would usually like to skip the navigation\nlinks and get right to the page-specific content. Since the new\nguideline does not address this need, what exactly is its goal?\n\nMaybe what we're getting at is more like: the UA must be able to\nrecognize structural elements identifying and naming blocks of content\nthat are essentially the same between pages or documents within the\ndocument set, thus allowing the UA to provide the user with the option\nof skipping over those sections. (See my note below about the glossary\nentry for Structure.) Of course, we should also require that at least\none UA be available that actually offers this feature, or else we leave\na loophole of almost infinite size. Also, of course, we'd need to push\nto get such markup added to HTML and other standard document formats.\n\n43.     Guideline 2.4, under Benefits, \"When the logical structure is\nprovided in markup or a data model.the content can be presented on a\nvariety of devices because the device software can choose only those\nelements of the content that it is able to display and display them in\nthe most effective way for that device.\"\n\n43.a.    [LOW PRIORITY] This is clearly not related to structural\nmarkup, but rather to markup describing data types. It could be\nrewritten to discuss structural markup by saying \".the content can be\npresented on a variety of devices, including those with serial\npresentation (such as voice output) and those with small visual\npresentations, because the UA can allow the user to choose to present\nonly selected sections or choose the order in which they are presented.\n\n44.     Guideline 2.5 \"The CKW proposal suggested that this success\ncriterion be combined with one of the (now AAA) items and that another\nbest practice item be moved up.\"\n\n44.a.    [COMMENT] I like the proposed rewrite of this guideline.\n\n45.     Guideline 2.5, Benefits, \"Individuals with speech disabilities\nmight not be recognized properly in voice input applications\"\n\n45.a.    [LOW PRIORITY] This is funny: anyone's speech can be\nmisrecognized (and often is!). I suggest that, if you keep this, you\nrewrite it as \"Individuals with disabilities affecting their speech or\nmanual dexterity will often have a higher error rate when communicating\nwith speech or handwriting recognition, or typing, and therefore benefit\nproportionately more from features that assist in recognizing and\ncorrecting input errors.\"\n\n46.     Guideline 2.5 \"Example.\"\n\n46.a.    [LOW PRIORITY] I suggest adding another example, that when\nproviding a form for submitting feedback, the form UI include an\noptional spell-checking feature. \n\n47.     Principle 3 \"Content and controls\"\n\n47.a.    [MEDIUM PRIORITY] Are \"controls\" the same as \"Interface\nElements\" mentioned elsewhere? Should we use consistent terminology?\n\n48.     Guideline 3.1 \"document attributes identify the natural language\nof the document.\"\n\n48.a.    [LOW PRIORITY] I agree that we need the requirements to\neffectively guarantee that all content can be identified by its natural\nlanguage (and, if applicable, character set), but I don't like the\nphrasing of this nor the artificial distinction between the two\nRequirements. Not all formats allow the document to be categorized by\nlanguage, so I propose combining the two Single-A checkpoints into\nsomething like \"it must be possible to unambiguously and\nprogrammatically identify the natural language and character set of all\ntextual content in the document.\" In explanation it can say that the\nprimary language of the document can be specified as attributes of the\ndocument itself and/or using markup within the document (such as using\ntags to the entire body of the document), and that any passages of text\nwithin the document whose language or character set differ from that\naround them must be demarcated and identified.\n\n49.     Guideline 3.1 \"Example 1: a French phrase in an English\nsentence\"\n\n49.a.    [LOW PRIORITY] I don't think you should say \"In the following\nsentence.is marked as French\" when it is not actually marked that way in\nthe guidelines document. Instead you should say \"In the following\nsentence.should be marked as French\".\n\n50.     Guideline 3.2 \"The definition of abbreviations and acronyms can\nbe unambiguously determined\"\n\n50.a.    [COMMENT] This is a very interesting topic! Some questions\nworth thinking about include: (1) Is it that much more important to\nprovide definitions of acronyms than, say, names, or words that are\nusually omitted from abridged dictionaries? (2) I agree that someday\nthere should exist a way to link from a word in a document to an\nunambiguous definition-think how much easier that would make automatic\ncross-language translation! \n\n50.b.    [LOW PRIORITY] Does this also apply to abbreviations that use\npunctuation rather than letters? For example, the double-quote character\n(\") is sometimes used for quoting, but sometimes it serves as an\nabbreviation for \"inches\" (a unit of measurement for linear distance) or\n\"seconds\" (a unit of measurement for arc). Similarly, the symbol #,\ncommonly referred to in the U.S. as a \"pound sign\", may be used for\n\"pounds\" (a unit of measurement for weight) or as an abbreviation for\nthe word \"number\" (ordinal counting). As far as I know, HTML allows\nmarking up non-characters this way, but I never see sites do so. Should\nwe recommend this? How about cases where punctuation is itself\nambiguous, such as distinguishing the period in \"3.4\" from the identical\ncharacter used to indicate the end of a sentence, or the end of an\nabbreviation? It would be nice to address this someday, although\nprobably not needed right now.\n\n50.c.    [MEDIUM PRIORITY] Do we have to make exceptions for media types\nthat don't really allow links or markup like this, such as an audio\nrecording of a speech?\n\n51.     Guideline 3.2 \"acronyms and abbreviations do not appear first in\nstandard unabridged dictionaries\"\n\n51.a.    [LOW PRIORITY] I doubt that the standard dictionaries for\nEnglish are 100% consistent on the order they list possible meanings of\nacronyms and abbreviations. Does that matter? Probably not, but should\nacknowledge it?\n\n52.     Guideline 3.2 \"a list is provided on the page or home page of\nURIs to cascading dictionaries that can or should be used to define\nabbreviations or acronyms\"\n\n52.a.    [MEDIUM PRIORITY] Is there a standard for such \"cascading\ndictionaries\"? If so, we should reference it; if not, then is this\nmeaningful?\n\n52.b.    [MEDIUM PRIORITY] Putting something on the home page doesn't\nhelp with documents that get copied around, or converted to another\nmedium, etc. Therefore it is preferable to have such links in every\ndocument.\n\n52.c.    [LOW PRIORITY] The current wording seems a bit HTML-centric,\ntalking about the page and so forth.\n\n53.     Guideline 3.2 \"provide a definition or link (with the first\noccurrence) of phrases\"\n\n53.a.    [MEDIUM PRIORITY] As mentioned in another comment, putting an\nannotation on the first occurrence requires defining first occurrence-is\nit first in a document, section, page, etc.?-and also means that copying\na selection may not include the annotation. This could be addressed by\nproviding the annotation on every occurrence, and leaving it to the UA\nto hide redundant occurrences if the user so chooses.\n\n53.b.    [LOW PRIORITY] Should that be first occurrence other than in\nheadings, or first including headings? Often books indicate trademark on\nthe first occurrence in normal text.      \n\n54.     Guideline 3.2 \"if contracted forms of words are used such that\nthey are ambiguous, provide semantic markup to make words unique and\ninterpretable\"\n\n54.a.    [LOW PRIORITY] This guideline is not clear to me. What are\nexamples of ambiguous contracted words?\n\n54.b.    [COMMENT] If we're going to require markup to disambiguate\ncontractions, why not non-contracted words that have ambiguous meanings?\nOther than the fact that it'd be a lot of work to comply, that is. \n\n55.     Guideline 3.3 \"the content has been reviewed, taking into\naccount the following strategies for evaluating the complexity of the\ncontent, applying them as appropriate\"\n\n55.a.    [MEDIUM PRIORITY] I don't think this should be a requirement\nbecause it is neither measurable (since you have to take their word for\nit that they reviewed it) nor provably beneficial (because they are not\nrequired to actually make changes based on the findings of the review).\nIn addition, I doubt there are widely accepted measurements of\ncomplexity that cover all of these points. Therefore I think it has to\nbe relegated to a recommendation. \n\n55.b.    [LOW PRIORITY] 1.e should be broadened to recommend \"accuracy\nand uniqueness of page and section titles\" rather than just page titles.\n\n56.     Guideline 3.3 \"Example 2: a concrete concept. The primary\nconcept on a page is concrete.\"\n\n56.a.    [LOW PRIORITY] This doesn't really say anything. In fact, it\ncould be taken as saying that the document discusses concrete (the\nmaterial). I hope that all examples will be concrete (specific). This\ndescribes a document that does lots of things, but the Example doesn't\nmake clear which things are key, or why they are being done. A negative\nexample would help, for contrast. See my suggestions elsewhere for\nreformatting Examples to be clearer.\n\n57.     Guideline 3.3 \"Example 4: child's report of school trip\"\n\n57.a.    [MEDIUM PRIORITY] This example, as several others, describes a\nscenario without making clear what aspects of the scenario are key. That\nmakes the example more confusing and less helpful than it would be if it\ncalled out the things that are important. See my proposal above about\nreformatting all examples. \n\n58.     Guideline 3.3 \"Note: Designers need to be cautious in deciding\nwhen to use illustrations.\"\n\n58.a.    [LOW PRIORITY] I think this note should be revised or removed,\nbecause it could be interpreted as recommending against using any\nillustrations, which would either lead to less usable web content or to\ndesigners deciding that the guidelines are unreasonable and discounting\nthem altogether. I think that what you're trying to say-with complete\nvalidity-is that designers should avoid conveying any information solely\nby illustrations, but that illustrations can also be very helpful for\nmany readers. I don't feel this paragraph makes clear what we are\nrecommending.\n\n59.     Guidelines 3.4 \"Key orientation and navigational elements (such\nas navigation bars) are generally found in one or two consistent\nlocations.\"\n\n59.a.    [LOW PRIORITY] I recommend saying something like \"(such as\nnavigation bars, page numbers, and section titles)\" to avoid giving the\nimpression that we're only referring to things outside the primary\ncontent.\n\n60.     Guideline 3.4 \"when inconsistent of unpredictable responses.the\nuser is warned in advance of encountering them\"\n\n60.a.    [MEDIUM PRIORITY] I'm not sure what you mean. Can you give an\nexample showing recommended UI for this? Are you suggesting that a game\npresent a warning that what the challenges the user will encounter will\nvary? Is it enough that the documentation says that every game will be\ndifferent?\n\n61.     Guideline 3.4 \"Whenever there are extreme changes in context,\none of the following is true.\"\n\n61.a.    [LOW PRIORITY] In-line warnings and options to deactivate are\ngood, but it seems like UA could also handle this in most cases, such\nas: letting the user adjust whether they want to allow, block, or be\nasked how to handle pop-ups; notifying the user when a page transition\nmakes significant changes to the page layout; identifying links that\nwill pop up a new window or go to a different site; etc. \n\n62.     Guideline 3.4, \"pages with similar function should have similar\nappearance and layout\"\n\n62.a.    [LOW PRIORITY] But we might note that it's also good for\nseparate sections to be easily distinguishable, which implies not using\nidentical appearance; distinct visual elements such as colors or\ngraphics will help readers orient themselves, keep in mind which section\nthey are in, and avoid mistaking similar pages.\n\n63.     Guideline 3.4 \"the content has been reviewed, taking into\naccount.\"\n\n63.a.    [MEDIUM PRIORITY] Isn't there some way that this criterion\ncould be made to have some impact or benefit? I'm afraid that, as it is,\ncriteria phrased this way will just be a checkbox that can be checked\nwithout anyone doing anything! Perhaps, to have some benefit, the web\nsite could post a review of its usability and rationale for their\ndecisions to avoid making improvements. Something? Anything?\n\n64.     Guideline 3.4, Example 3: \"frames that do not track history\nmaking the back button behave unexpectedly\"\n\n64.a.    [MEDIUM PRIORITY] This doesn't describe a recommendation; is it\nsimply to avoid frames? (Again, it seems like UA should be able to solve\nthis problem without changes to Web sites.) \n\n65.     Guideline 4.1 \"Technologies are used according to\nspecification.\"\n\n65.a.    [HIGH PRIORITY] I firmly believe the technology should only be\nused according to their specification when the specification leads them\nto be used in an accessible manner.  I do not believe you should assume\nthat all specifications when followed exactly will lead to accessible\nresults, and when they do not, the author should follow unofficial\nguidelines to result in more accessible content. I'm sorry if that\ndoesn't make for a simple, objective guideline. (On the other hand, I\nalso admit that the consistency that comes from everyone following\nspecifications usually has other advantages.)\n\n65.b.    [LOW PRIORITY] In the description of benefits, you could add\nthat following specifications (especially for markup and other file\nformats) is that it allows reformatting, repurposing, and reuse of\ncontent, which is especially important to users who can only make full\nuse of the content in a different format.\n\n66.     Guideline 4.2 (formerly 4.3) \"programmatic user interfaces are\naccessible or alternative, accessible versions are provided\"\n\n66.a.    [LOW PRIORITY] Terminology point: I don't think APIs are\naccessible, but rather APIs support accessibility and are implemented in\naccessible ways.  That is to say, APIs are in fact specifications for\nthe communication method between software components; different\nplatforms (including different versions of the same operating system or\noperating environment) provide different implementations of the API in\nthe form of specific code or components.  An API is accessible if the\ndefinition allows or requires the caller to provide all the information\nand functionality needed to render the end result accessible.  I would\ntherefore suggest rephrasing this guideline.\n\n66.b.    [MEDIUM PRIORITY] I'm not familiar with the term \"programmatic\nuser interfaces\"; by that do you mean API that report on the\npresentation (e.g. enumerate sections of content and give their screen\ncoordinates and names), or API that control the program (e.g. change\nselection, move focus, activate controls), or both, or something else\naltogether? This should probably be clarified in the document.\n\n67.     Guideline 4.2 \"the interface has been tested using a variety of\nassistive technologies.to determine that those assistive technologies\nare able to access all information on the page or hidden within the\npage\"\n\n67.a.    [MEDIUM PRIORITY] This is very screen-reader specific; I\nrecommend making it more general by saying \".assistive technologies are\nable to access all content, structure, and formatting information on the\npage or hidden within the document, and are able to identify and\nmanipulate all user interface elements on the user's behalf.\"\n\n68.     Guideline 4.3, Double-A Checkpoint 1, \"the Web resource includes\na list of the technologies (other than standard HTML) users must have in\norder for its content to work as intended. Users who do not have one or\nmore of these technologies can still access and use the resource, though\nthe experience may be degraded.\"\n\n68.a.    [HIGH PRIORITY] I think we need to do more to explain this\nguideline. What constitutes sufficiently documenting the list of\nrequired technologies? For example, when a web page contains an OBJECT\nelement that specifies the technology required, is that sufficient? Or\nare you saying that the page would have to list those required\ntechnologies in human-friendly text in addition to the UA-friendly tags?\nDoes the list of required technologies have to be posted with every link\nto the document, so that users can view the list before downloading the\ndocument? Would you, for example, require every Web page that links to a\nsite's online store have some text indicating that the store requires\nSSL? Does every link to a PDF document need to identify it as such?\n\n68.b.    [LOW PRIORITY] It seems to me that the two sentences in this\ncheckpoint are really making two separate points, and so should be\nbroken into two separate checkpoints. Thus: Checkpoint 1, \"The Web\nresource includes a list of the technologies (other than standard HTML)\nusers must have in order for its content to work as intended\", and\nCheckpoint 2, \"Users who do not have one or more of the technologies\nused by the document can still access and use the resource, though the\nexperience may be degraded.\" This allows a document to get credit for\ndegrading gracefully even though it might not list required technologies\nup-front. \n\n68.c.    [LOW PRIORITY] You might explicitly note that the first example\nshows listing required technologies, and the second shows degrading\ngracefully.\n\n69.     Guideline 4.3, Triple-A Checkpoint 1, \"a list of technologies\nand features, support for which is required in order for the content to\nbe operable, has been determined and is documented in metadata and / or\na policy statement associated with the content.\"\n\n69.a.    [LOW PRIORITY] How about giving priority to using metadata\n(which is then computer-usable) by saying \".documented in metadata if\nsuch metadata is supported by the file format, otherwise is documented\nin a policy statement associated with the content.\"\n\n70.     Glossary definition of \"Audio Descriptions\"\n\n70.a.    [MEDIUM PRIORITY] The glossary entry for audio descriptions are\nredundant to the entry for audio description.\n\n71.     Glossary definition of \"Feature\"\n\n71.a.    [MEDIUM PRIORITY] I think we should clarify the word \"Feature\"\nhas several meanings. The definition currently gives only one\ndefinition, but in the WCAG 2.0 document the word is used in a variety\nof meanings.\n\n72.     Glossary definition of \"Keyboard Interface\": \"A keyboard\ninterface is the point where the application accepts any input that\nwould come from the keyboard (or optional keyboard).\" \n\n72.a.    [LOW PRIORITY] I would change this to read \"A keyboard\ninterface is the point where the application accepts any input that\nwould come from a keyboard, optional keyboard, or assistive technology\nsimulating keyboard input.\"\n\n73.     Glossary definition of \"Media equivalents\" : \"Media equivalents\npresent essential audio information visually (captions) and essential\nvideo information auditorily (audio descriptions).\"\n\n73.a.    [MEDIUM PRIORITY] I would include presenting essential audio or\nvisual information in textual form, which would then be usable by people\nwho are deaf-blind and by accessibility aids, as well as supporting\nmainstream uses such as searching and indexing.\n\n74.     Guideline 3.4, Glossary entry for \"Mechanisms that cause extreme\nchanges in context\"\n\n74.a.    [LOW PRIORITY] The two examples, \"in an auditory presentation,\nthe speaker changes with no visual cue and no notation in the captions\"\nand \"captions that do not identify change in speaker\" seem redundant to\neach other.\n\n75.     Glossary definition of \"Non-Text Content\"\n\n75.a.    [MEDIUM PRIORITY] The definition of \"non-text content\" is\ncurrently just a list of examples. A simple way to summarize the\ndefinition might be to start with something like \"Non-text content is\nany content that is not displayed for the user as Unicode text.\"\n\n76.     Glossary definition of \"Operable\"\n\n76.a.    [MEDIUM PRIORITY] The definition of \"operable\" is specific to\nthe context of \"operable using a keyboard\", but the word really has a\nbroader definition. I suggest (a) keeping the definition, but changing\nthe glossary entry to \"Operable using a keyboard,\" or if that's not\nacceptable then (b) prefixing the definition with something like \"In\nthis document the term 'operable' is used in the context of content\nbeing usable through a keyboard or assistive technology that simulates\nkeyboard input.\"\n\n76.b.    [MEDIUM PRIORITY] I have suggested that we might be able to\ncome up with a metric for keyboard usability, which would be something\nlike \"The number of keystrokes required to carry out an operation should\nbe no more than five times the number of discrete actions required when\na pointing device is available.\" Discrete actions include keystrokes,\nmouse movements, and mouse button presses. Worth thinking about. \n\n77.     Glossary definition of \"Real-Time Events\"\n\n77.a.    [LOW PRIORITY] I would recommend against defining a phrase by\nreferring to one of its own components, such as defining \"Real-time\nevents\" as, essentially, events that happen \"in real-time\"; therefore I\nwould remove the phrase \"in real-time\" from the definition. In addition,\nI would supplement \"where the events are not under the control of the\nauthor\" by adding \"or the user\". How about something like \"Real-time\nevents are those whose timing is triggered by outside events and\ntherefore cannot be put under the control of the author or user without\ncompromising their usefulness. For example, a stock ticker or emergency\nwarnings could potentially lose their value if delayed significantly and\nare therefore real-time events, whereas any direct and immediate\nreaction to the user's input is not a real-time event.\"\n\n78.     Glossary definition of Site Navigation Mechanism\n\n78.a.    [MEDIUM PRIORITY] An additional recommended mechanism would be\nproviding navigation links that allow the user to skip portions of the\ncontent which are consistent between documents or sections of the\ndocument. This can also be achieved by providing sufficient markup,\nalong with names meaningful to humans, allowing the user to recognize\nwhich are recurring and instruct compatible UA over or to those\nsections. \n\n79.     Glossary definition of Structure: \"Structure includes both\nhierarchical structure of the content and non-hierarchical relationships\nsuch as cross-references, or the correspondence between header and data\ncells in a table. The hierarchical structure of content represents\nchanges in context.\"\n\n79.a.    [LOW PRIORITY] I recommend against defining a phrase by\nreferring to one of its components, such as \"structure includes both\nhierarchical structure.\" Can we phrase this to avoid using the term\nstructure in the definition? How about \"Structure includes both\nhierarchical relationships between elements (such as the division into\nsections and sub-sections) and non-hierarchical relationships.\"\n\n79.b.    [LOW PRIORITY] In one instance the word \"hierarchical\" is\nmisspelled as \"heirarchical\".\n\n79.c.    [LOW PRIORITY] Missing space between \"in a table.\" and \"The\nhierarchical\".\n\n79.d.    [MEDIUM PRIORITY] One of the most important relationships\nbetween pieces of content is that which tells the user agent in what\norder they should be presented.  Is this structure or presentation?  The\nmost common case is where the presentation order is implied by the order\nin which the pieces of content are defined in the source file (e.g.\nHTML) and in most cases this is the default, but it is not always the\nonly order specified.  Is there a standard way to specify alternate\norders? IF so, would that be in the style sheet, and if so, would it\nthus be presentation?\n\n79.e.    [LOW PRIORITY] Might note that structural markup serves to aid\nin identification (it identifies a block of content), orientation\n(allowing the user to tell where they are in relation to various blocks;\nthis can happen at the user's request or automatically as the content is\nbeing presented to the user), reference/navigation (allowing the user to\nrefer to a location for any purpose, including asking the user agent to\nbegin acting there), and reformatting (such as allowing the user to hide\nor skip certain blocks, or alter their presentation).\n\n \n\n[End of Greg Lowney's Comments on WCAG 2.0 Draft of 2003-10-08]\n\n\n\n"
        },
        {
            "subject": "can'",
            "content": "I can't use my address bar it show sometime Yoogee or Internet something how\ncan I fix this and fast!\n\n\n\n"
        },
        {
            "subject": "Evaluation/Cognitive perspectives on WCAG2.",
            "content": "As an accessibility auditor, and as a learning disabilities specialist \nhere's my take on WCAG 2.0. My overall sense it that it is missing \nsomething. Since most of our work focuses on reviewing the accessibility \nof HTML content, I would guess that Techniques or HTML Accessibility \nwill help clarify the general guidelines presented in WCAG2. Others have \nexpressed this in other post, so I'll try to stay focused on how these \nguidelines affect evaluation, and affect people with specific cognitive \ndisabilities. I would also suggest synchronizing WCAG guidelines with \ncomponents of the IMS ACCLIP specifications.\n\nACCLIP\nhttp://www.imsproject.org/accessibility/acclipv1p0/imsacclip_infov1p0.html\n\nPerceivable\n1.1 Include an example of a non-meaningful non-text element with an NULL \ntext equivalent used to force AT to ignore the element (empty Alt text \nspecifically). A spacer can be \"expressed in words\" but should not be, \notherwise it interferes with comprehension of the meaningful content on \nthe screen, particularly for those with cognitive disabilities. (see \nproposed \"reduce clutter\" guideline in \"Understandable\")\n\n\n1.3 Are tables used for layout (i.e. to structure content) a violation \nof this guideline?\n\nEvaluation: Enforcing non-table layouts is not possible at this time for \nany more than Web sites with  simple presentations. Clients will often \nrespond to minimizing the use of layout tables, but not to removing them \ncompletely. This will likely change as browsers become more consistent \nin the support of CSS layout properties. Minimal table layouts pose no \naccessibility barriers for relatively current assistive technologies.\n\n\n1.4  I had a hard time understanding what this guideline was talking \nabout. Needs more examples. Are the use of 8859 and windows charsets \netc. still legal, under the assumption that these charsets can be mapped \nbacked to unicode (utf-8/16)? Does this mean a developer must provide a \nutility that will convert other charsets to unicode? Need more \nexplanation of \"mapped back to Unicode\".\n\nShould Best Practice 1  for Checkpoint 1.4 be included with guideline \n3.2 instead?\n\n1.5 Association between table headers and data cells in many cases is a \nnecessary feature of tables for comprehension by blind users (I'm \nassuming this guideline fits here). Limited short term memory otherwise \nmakes it difficult to mentally make header to data cell associations \nbeyond the first few rows of a large data table. This should probably be \na Core requirement, retaining its P1 designation from WCAG 1.0. Form \nlabels are less critical provided they are position next to a form \nfield, so they could probably remain an extended guideline.\n\n1.6 While contrast can usually be assessed through subjective \nexperience, how will it be objectively measured if for instance \nforeground and background contrast levels are questionable.\n\nOperable\n2.1 [Exception: onclick, in reality, has become a device independent \nevent handler, normalized through broad adoption by Web browser and AT \ndevelopers].\n\n2.4 50,000 words is a lot of words. Any single screen over a few hundred \nwords could provide a means to navigate among the major sections of the \npage, if they exist, and aid comprehension by providing an overview of \nthe page and quick navigation to specific points in a page (anchors \nbefore primary headings and a linked table of contents at the top of the \ndocument). Take the WCAG 2.0 document itself. It contains less than \n14000 words.\n\nOne of the other commenters suggests that the common table of contents \nanchor links that are found at the top of many long document interferes \nwith effective navigation through a page because this can be done more \neffectivley by listing the headings on the page. But, from a cognitive \nperspective, a table of contents at the top of a long document can be an \ninvaluable tool for learners with learning disabilities. I myself find \nthem quite useful for providing a quick summary of a page without having \nto scroll through the page and keep headings in mind as I move through \nmultiple screen fulls of content.  In this instance I would suggest that \nthe table of contents be a feature for page that include more than 5 \nsubsections and 5000 words, and be optional as per the ACCLIP \nuseTableOfContents preference. A screen reader user can benefit from \nhaving TOC turned off, while an LD user can benefit from having them \nturned on.\n\nSite navigation mechanism: what are \"dynamic fisheye views\"? Is it a TOC?\n\n\n2.5 Required criteria for this guideline applies to success feedback as \nwell as error feedback. When a screen reader user for instance, submits \na form that performs a particular action, they will often want to verify \nthat the operation was successful. Without success feedback it can be \nvery time consuming to make this verification.  \"2. after a successful \noperation , provide the user with confirmation feedback\".\n\nSuccess feedback might have its own guideline (2.6,  though it might fit \nas 3.4 (3c)) since it is fundamentally different from error feedback, \nand error recovery.  However, both error and success feedback could be \nconsider  \"graceful recovery\". We distinguish between error, warning, \nand success feedback in ATutor. Error messages state the problem that \noccurred and provide courses of action. Warnings state that a possible \nerror has occurred and provide a means to revert to a previous state our \ntake an alternative course of action. Success feedback provides simple \nconfirmation (in most cases)\n\nATutor Instructor Demo (see the feedback system as an instructor by \nperforming various tasks such as creating, updating, or deleting \ncontent, modifying preferences, posting announcements....)\nhttp://www.atutor.ca/atutor/demo.php\n\nSee \"Learning from Your Mistakes\" for more about fundamental cognitive \ndifferences between error and success feedback\nhttp://www.ldrc.ca/projects/projects.php?id=23\n\nUnderstandable\n3.2\nBest Practice for Checkpoint 3.2 #2.b is not related to the guideline \nitself? How is a summary related to unambiguous presentation of \nabbreviations or acronyms.  Nor do some of the definitions or benefits \nlisted with this guideline seem relevant.\n\nA separate guideline is needed to outline the need for summary or \ncontext information such as table summaries, frame titles, list priming, \n...\n\n3.3\nEvaluation: While I agree with all the points listed under Required \nCriteria from a  learning disabilities perspective, evaluating the \nfamiliarity of terms and language structure, length and complexity, and  \ncoherence of paragraphs (1.abc) in many cases would not be possible \nwithout undue expense. While we evaluate technical compliance and \npractical usability in our accessibility assessments, in many cases it \nwould not be realistic for us to review the integrity of the content \nitself. That would, in most cases, involve analyzing a significant \namount of information, and would increase the assessment effort  (and \ncost) excessively. Copy editors do this kind of work, and content \nreviewing represents an expertise on its own that can't be expected of \nan accessibility evaluator.\n\nOther reasons for not including language as a criteria for accessibility \nalso come to mind: how to create an objective measure for automated \nevaluation utilities;  at what point does a site fail this guideline; \nhow might language usage requirements vary depending on the context or \nintended audience, and how would you measure that ...  There's too much \nsubjectivity. Measures of word and sentence length provide only a very \nrough estimate of language complexity. Word frequency stats would also \nneed to be assessed to determine the complexity of language.\n\nThis requirement might distinguish between language used in content or \ninformation and language used in the interface or application itself, \nthe latter of which can reasonably be evaluated in most cases.\n\nIn example 5, linking to a sound clip is providing an alternative format \nrather than providing a simpler form.\n\nA distinction needs to be made between simpler forms and alternative \nforms (i.e. Multi-modal presentations). As suggested in the Note in the \nBenefits section, providing a picture to supplement text information, \nsuggests that an alternative format does not necessarily represent a \nsimpler form.\n\n\n3.4 An extreme change can be identified after the change has occurred, \nsuch as a \"close new window\" link as the first feature of a popup \nwindow, or presenting a feedback message after server side redirecting a \nuser from the content editing screen to the content display screen when \nediting is completed (feedback like \"content was successfully updated\" \nsee guideline 2.5 above).\n\nguideline should read \"..., but not necessarily identical\".\n\n\n\nRobust:\n4.1 Does this include nonW3C technologies: Javascript, Active X, \nFlash,... used according to specification? Can developers use these \ntechnologies if they are designed with accessibility features. How would \nan evaluator determine if Javascript or perhaps Flash has been used to \nspecification? Whose specification for Javascript. I also would imagine \nJavascript can be used to specification, but be innaccessible. In \ncombination with the \"device independence\" guideline, this might work.\n\n(1c) Could be interpreted as \"all\" or \"one of the\" accessibility \nfeatures have been used. Using enhanced features like accesskeys, \nexplicit form labels where adjacent implicit labels are sufficient, and \ntable summaries are not otherwise required for CORE compliance (ala WCAG \n1.0 P3 items). Which accessibility features need to be used?\n\nBest practices \"Benefits of Checkpoint 4.1\" does not seem to apply to \nissues of specification validation.  How does providing a search engine \nrelate to using technologies according to specification.\n\nScenario for testing Guideline 4.1\nA developer creates a Flash MX presentation that makes use of all the \naccessibility features that are available. While the Flash presentation \nis accessible to JAWS 4.5 and Windoweyes 4.2, it remains inaccessible to \nall other assistive technology users. Is this Flash presentation WCAG 2 \ncompliant? Given the majority of screen reader users are likely to be \nusing pre  4.0 versions of these technologies, the Flash MX presentation \nwill not be accessible to them.\n\nHow has the \"until user agents support...\" problem in WCAG 1 been dealt \nwith? Are there limitations on support for older technologies when newer \nversions of these same technologies are available that do support newer \naccessibility features?\n\nThere needs to be some agreement on limitations to supporting older \ntechnologies. Do developers still have to support IE 3, or Netscape 3 \n(or Netscape 4 for that matter) given the percentage of users still \nusing these technologies in miniscule, and likely nonexistent for users \nwho require accessibility support?\n\n4.2 Need a quantitative definition for \"widely available\". Widely \navailable technologies in English is not likely the same as widely \navailable in Farsi, for example.  \"Easily available\" might be a better \nchoice of words.\n\n4.3 Keep this guideline but reword \"versions\" to \"representations of the \ncontent\", to suggest presenting the same content in different ways \nrather than presenting multiple copies. This guideline should be \nretained to discourage the creation of alternative versions (such as a \ntext only site) when the original itself could be made accessible.\n\nText only sites should be a transformation of the original content (such \nas wrapping an accessible header/footer around the same content that \nappears in another less accessible header/footer)? Two versions of the \nsame content should still be discouraged, but transformations of the \nsame content should not.\n\nNew Guideline Suggested for Section 3 Understandable\n3.5 [EXTENDED] Minimize the use of repetitive and non-meaningful content.\n\nA guideline is needed to encourage  reducing information overload for \nscreen reader users, and users with cognitive disabilities, essentially \nminimizing, or providing a means to minimize complexity. Within the  \nUnderstandable guidelines an additional extended guideline should be \nintroduced that requires minimizing the amount of irrelevant or \nnon-meaningful or repetitive information. Such instances might include \nusing an empty Alt attribute to cause AT to ignore meaningless images,  \nusing and empty summary attribute for irrelevant layout tables,  or \nusing empty Alt for icon links reproduced as alternative text links so \nlinks are not announced twice....\n\nConcession for necessary violations:\nIn the previous draft of WCAG2 there was a concession for necessary \nviolations which allowed developers to document these violations as \nnecessary, in many cases for backwards compatibility. For example, we \nuse the Target attribute as a backup access strategy for popup windows \ncontrolled by Javascript. If Javascript support is not present, then  \nthe new window opens in a window defined in the target attribute. Target \nis deprecated so this would be a violation of 4.1, but without this \nviolation we are not aware of another strategy that would allow \ndevelopers to use new windows in a fully accessible manner.\n\nI am aware of the arguments against the use of new windows,  though I \nthink it is unrealistic to expect developers not to use them.  In fact \nnot using them in some instances impedes accessibility from a cognitive \nperspective. Help windows for instance are often more useful if they are \nopened alongside the screen they reference so users can read the help \ninformation in one windows, and apply the help suggestions in another, \nrather than trying to flip back and forth between help and its reference \nin the same window.\n\nAnother example is the use of EM as a font size measure (as well as a \nnumber of other style attributes used within tables), which do not \nfunction effectively, or function adversely in Netscape 4. With \nlimitations on the backwards compatibility this may not be an issue, but \nmany clients require their sites to function effectively in Netscape 4, \nand as such need to be able to violate certain guidelines to do so.\n\nThere's lots of other instances where violations are likely to be \nnecessary.\n\nDevelopers need to be able to use workarounds that violate guidelines, \nprovided they are necessary and they are documented in an accessibility \nstatement.\n\n\nGreg Gay\nAdaptive Technogy Resource Centre\nUniversity of Toronto\n\n\n\n"
        },
        {
            "subject": "Re: Request for Review: WCAG 2.",
            "content": "August 22, 2003 - A group* of UW-Madison staff gathered to discuss the WCAG \n2.0 draft. The individuals gathered represented technology \ninstructors/trainers, faculty support, consultants, web site and web \napplication developers-all are web accessibility advocates who work with \ninstructional, department faculty and staff. We have been involved with web \naccessibility issues and support on the UW-Madison campus for several years.\n\n\n1. In general, is this WCAG 2.0 Working Draft easy to understand? Please \nidentify sections or phrases that are difficult to understand. Please \nsuggest alternative wording for the Working Group to consider.\n\nWe are familiar with, and often reference or make recommendations based on \nthe work of WCAG 1.0. Our campus' original web accessibility policy \n(December 2000) was based on WCAG 1.0, level AA+.  Many of us gave input to \nthe original policy. That policy was revised (October 2001, and again April \n2003) -the revised policy  endorses compliance with Federal Rehabilitation \nAct's Section 508 standards. None of us were involved with the October 2001 \nchange-several did give input to the 2003 revision.\n\nWe found that the WCAG 2.0 deviates too much from 1.0, both in terms of \ncontent and organization. We struggled with mapping. Our brains wanted to \nreference what we were familiar with.\n\nOverall,  we felt the document no longer was for our audience (we are in \nsupport roles) - the document feels highly technical and specialized. We \nhad difficulty mapping WCAG 2.0 with 1.0. Our brains were trained and \nfamiliar with priorities and levels, and we struggled with not being able \nto make correlations and  connections with what we knew and were familiar \nwith and the new document.\n\nA more general comment is that the \"Perceivable\" category we found to be \nvery subjective, and difficult for us to get agreement or  understanding on \n- apologies, but we don't have a substitute term - we are not in agreement \nif this term or the concepts in this category add to the strength or \nconfusion of the document.\n\n2. The conformance structure of this WCAG 2.0 Working Draft differs from \nWCAG 1.0 and from the previous WCAG 2.0 Working Draft. Is the concept of \nCore and Extended checkpoints easy to understand? Is this an effective \nstructure?\n\nWe appreciate that now with WCAG 2.0 is referencing four (4) guidelines \n(Perceivable, Operable, Understandable and Robust) instead of fourteen (14) \nguidelines. The \"Benefits\" of each checkpoint are valuable . . . especially \nwhen they extend beyond benefits to people with disabilities. We also value \nthat eh design principles represent broad concepts, situations and \ntechnologies, including those that do not yet exists.\n\n\n\n\n3.     If your site or organization already uses WCAG 1.0, do you think it \nwill be difficult to migrate from WCAG 1.0 to WCAG 2.0, based on the \ncurrent draft? Please note that the Working Group is developing supporting \ndocuments such as technology-specific techniques documents and checklists \nfor WCAG 2.0.\n\nOur campus policy is based on 508 (which we feel in many ways borrow from \nor parallels much of WCAG 1.0, level A+). We have done a great deal of work \nto educate our campus web developers and those who maintain websites, \ndevelop curriculum , and tools for evaluating web site compliance. Tthe \ngiant leap necessary to relearn terms, layout (structure) etc. for WCAG 2.0 \nwould jolt our audience into \"shut down\" or \"turn off\" - It's been a long \nhard road to get to where we are now, and we don't believe our audience \ncould handle the transition.\n\nWe often used WCAG1.0 as reference. For example if someone was having \ntrouble constructing an accessible table, we knew exactly where the \nreference was, and it wasn't clear in the table of contents.  We were not \nclear  (from the table of contents) where to look - other areas such as \nstyle sheets, deprecated HTML, fonts are additional examples-we were not \nsure how / where to look. The table of contents was described as a Rabbit \nWarren from \"Watership Down\" - needing to be indexed.\n\nWe valued having examples follow benefits. We question what skill level \nyour target audience is.\n\nCheckpoint 2.5 Example 1: a search engine. A search engine is provided with \na variety of search options for different skill levels and preferences. It \nincludes a spell checker and offers \"best guess\" alternatives, \nquery-by-example searches, and similarity searches.\n\nThis is an example of \"high technical level\" - a skill that a faculty, \ninstructor or teaching assistant on our campus would not possess. In fact \nonly one in our group possesses this skill. This example would send people \nwe work with out of the room in a state of overwhelm.  Perhaps if it was \npossible to provide levels for web developers to identify with or relate \nto, for example, if you are:\n\n- I.   New to the Web or have little experience . . . (core)\n- II.  Experienced Web  Developer. . . (core plus)\n- III. Extensive Experience as a Web Developer . . . (extended)\n\nWe also struggled with how we would evaluate or validate sites if our \ncampus policy were based on WCAG 2.0?\n\nWe recognize that there other supporting documents being developed to \nsupport the guidelines, however if our users shut down at this stage, we've \nlost our opportunity if they shut down.\n\n\n\n\n*group =\nAlice Anderson, Division of  Information Technology, Technology \nAccessibility Program (administrative)\nBlaire Bundy, Division of  Information Technology, Learning Technology and \nDistance Education, (faculty and instructional staff support)\nGreg Konop,  Division of Information Technology,  Professional and \nTechnical Education,\n(campus technology training)\nLisa Jansen, Letters & Science,  Learning Support Services \n(department  support)\nKevin P. Thompson, Professional and Technical Education,\n(campus technology training)\nWei-zhong Wang, Division of Information Technology, Help Desk, (Help Desk \nWeb site, and campus \"web doctor\" campus web validation)\n\n\n\n"
        },
        {
            "subject": "Re: Request for Review: WCAG 2.",
            "content": "August 22, 2003 - A group* of UW-Madison staff gathered to discuss the WCAG \n2.0 draft. The individuals gathered represented technology \ninstructors/trainers, faculty support, consultants, web site and web \napplication developers-all are web accessibility advocates who work with \ninstructional, department faculty and staff. We have been involved with web \naccessibility issues and support on the UW-Madison campus for several years.\n\n\n1. In general, is this WCAG 2.0 Working Draft easy to understand? Please \nidentify sections or phrases that are difficult to understand. Please \nsuggest alternative wording for the Working Group to consider.\n\nWe are familiar with, and often reference or make recommendations based on \nthe work of WCAG 1.0. Our campus' original web accessibility policy \n(December 2000) was based on WCAG 1.0, level AA+.  Many of us gave input to \nthe original policy. That policy was revised (October 2001, and again April \n2003) -the revised policy  endorses compliance with Federal Rehabilitation \nAct's Section 508 standards. None of us were involved with the October 2001 \nchange-several did give input to the 2003 revision.\n\nWe found that the WCAG 2.0 deviates too much from 1.0, both in terms of \ncontent and organization. We struggled with mapping. Our brains wanted to \nreference what we were familiar with.\n\nOverall,  we felt the document no longer was for our audience (we are in \nsupport roles) - the document feels highly technical and specialized. We \nhad difficulty mapping WCAG 2.0 with 1.0. Our brains were trained and \nfamiliar with priorities and levels, and we struggled with not being able \nto make correlations and  connections with what we knew and were familiar \nwith and the new document.\n\nA more general comment is that the \"Perceivable\" category we found to be \nvery subjective, and difficult for us to get agreement or  understanding on \n- apologies, but we don't have a substitute term - we are not in agreement \nif this term or the concepts in this category add to the strength or \nconfusion of the document.\n\n2. The conformance structure of this WCAG 2.0 Working Draft differs from \nWCAG 1.0 and from the previous WCAG 2.0 Working Draft. Is the concept of \nCore and Extended checkpoints easy to understand? Is this an effective \nstructure?\n\nWe appreciate that now with WCAG 2.0 is referencing four (4) guidelines \n(Perceivable, Operable, Understandable and Robust) instead of fourteen (14) \nguidelines. The \"Benefits\" of each checkpoint are valuable . . . especially \nwhen they extend beyond benefits to people with disabilities. We also value \nthat eh design principles represent broad concepts, situations and \ntechnologies, including those that do not yet exists.\n\n\n\n\n3.     If your site or organization already uses WCAG 1.0, do you think it \nwill be difficult to migrate from WCAG 1.0 to WCAG 2.0, based on the \ncurrent draft? Please note that the Working Group is developing supporting \ndocuments such as technology-specific techniques documents and checklists \nfor WCAG 2.0.\n\nOur campus policy is based on 508 (which we feel in many ways borrow from \nor parallels much of WCAG 1.0, level A+). We have done a great deal of work \nto educate our campus web developers and those who maintain websites, \ndevelop curriculum , and tools for evaluating web site compliance. Tthe \ngiant leap necessary to relearn terms, layout (structure) etc. for WCAG 2.0 \nwould jolt our audience into \"shut down\" or \"turn off\" - It's been a long \nhard road to get to where we are now, and we don't believe our audience \ncould handle the transition.\n\nWe often used WCAG1.0 as reference. For example if someone was having \ntrouble constructing an accessible table, we knew exactly where the \nreference was, and it wasn't clear in the table of contents.  We were not \nclear  (from the table of contents) where to look - other areas such as \nstyle sheets, deprecated HTML, fonts are additional examples-we were not \nsure how / where to look. The table of contents was described as a Rabbit \nWarren from \"Watership Down\" - needing to be indexed.\n\nWe valued having examples follow benefits. We question what skill level \nyour target audience is.\n\nCheckpoint 2.5 Example 1: a search engine. A search engine is provided with \na variety of search options for different skill levels and preferences. It \nincludes a spell checker and offers \"best guess\" alternatives, \nquery-by-example searches, and similarity searches.\n\nThis is an example of \"high technical level\" - a skill that a faculty, \ninstructor or teaching assistant on our campus would not possess. In fact \nonly one in our group possesses this skill. This example would send people \nwe work with out of the room in a state of overwhelm.  Perhaps if it was \npossible to provide levels for web developers to identify with or relate \nto, for example, if you are:\n\n- I.   New to the Web or have little experience . . . (core)\n- II.  Experienced Web  Developer. . . (core plus)\n- III. Extensive Experience as a Web Developer . . . (extended)\n\nWe also struggled with how we would evaluate or validate sites if our \ncampus policy were based on WCAG 2.0?\n\nWe recognize that there other supporting documents being developed to \nsupport the guidelines, however if our users shut down at this stage, we've \nlost our opportunity if they shut down.\n\n\n\n\n*group =\nAlice Anderson,  Division of  Information Technology, Technology \nAccessibility Program (administrative)\nBlaire Bundy,  Division of  Information Technology, Learning Technology and \nDistance Education, (faculty and instructional staff support)\nGreg Konop,  Division of Information Technology,  Professional and \nTechnical Education,\n(campus technology training)\nLisa Jansen,  Letters & Science,  Learning Support Services \n(department  support)\nKevin P. Thompson, Professional and Technical Education,\n(campus technology training)\nWei-zhong Wang, Division of Information Technology, Help Desk, (Help Desk \nWeb site, and campus \"web doctor\" campus web validation)\n\n\n\n"
        },
        {
            "subject": "Comments on WAI 2.0 draft guideline",
            "content": "          Q1.  In general, is this WCAG 2.0 Working Draft easy to understand?\n\nIt is not trivial reading, but I found it far easier to understand than the \n1.0 guidelines.  I cannot even guess how many times I read the 1.0 \nguidelines and frankly never did understand them fully.  I skimmed this 2.0 \ndocument once, then read it carefully and understand it already better than \nI ever did the 1.0 guidelines.\n\n          Q2.                 Is the concept of Core and \nExtended  checkpoints easy to understand?\n\nYes, but I found the priority level concepts of 1.0 understandable as \nwell.  The advantage of the new system is that it does not need to set \npriorities on which of the extended guidelines is the most important.  I \ncan also see that the new structure is at least partly responsible for the \nincreased readability of the guidelines.  For what it's worth I like the \nconcept of Core+ but recommend that a core+ claim list the extended \ncheckpoints that are met.  Number of extended checkpoints isn't very \ninformative unless it is nearly all of them.\n\n          Q2a.               Is this an effective structure?\n\nYes, but I do sympathize with those who've mastered 1.0 structure and are \nnow being asked to adopt something that really is radically different.\n\n          Q3.  If your site or organization already uses WCAG 1.0, do you\n               think it will be difficult to migrate from WCAG 1.0 to WCAG 2.0?\n\nI'm certainly no expert, but it's obviously not trivial.  A lot of effort \nis required to provide transition documents.  Good luck.\n\nJohn Gardner, President and CEO\nViewPlus Technologies, Inc.\n1853 SW Airport Avenue\nCorvallis, OR 97333\nTel: (541) 754 4002 x220\nFAX: (541) 738 6505\ne-mail: John.Gardner@ViewPlus.com\nURL: http://WWW.ViewPlus.com\n\n\n\n"
        },
        {
            "subject": "Guilty? You Decide",
            "content": "Whether you've heard about us before or even if you've already seen it,\n\nNOW IS THE TIME TO COME TO FLEMINGTON, NJ!\n\n \n\nDID BRUNO HAUPTMANN\nKILL THE LINDBERGH BABY?\n\n \n\nHistory Comes Alive and\nYOU ARE THE JUDGE!\n \n\nat\n\nTHE TRIAL OF THE CENTURY\n \n\nSEPTEMBER 20 - OCTOBER 12\nShows at 2 & 8 PM Saturdays\n2 PM Sundays\n\n \n\nTHE TRIAL OF THE CENTURY is a live, 2 ? hour re-enactment of the famous 1935 kidnapping trial of Bruno Hauptmann for the murder of Charles Lindbergh, Jr., staged in the original historic courtroom where the trial actually took place!  Critics have raved about this undiscovered gem, and you will too.\n\n \n\nAfter twelve years and many thousands of enthralled audience members, THE TRIAL OF THE CENTURY will present its last season before the courthouse is closed for renovations.  We're not sure when we'll back, so don't miss this opportunity to catch it before it's too late.  \n\nTickets $25 - Jury Seats $35\n\n \n\nFor more information, visit our website at www.famoustrials.com where you can order tickets, or call 908-782-2610 for the latest updates on tickets, tours and others events in Flemington, NJ.  \n\n \n\n\"New Jersey's most vivid example of site-specific theater.\" - THE N. Y. TIMES\n\n\"Lindbergh Trial Performance is like being there\" - THE STAR-LEDGER\n\"When you go away wanting more, that means it was good.\" - THE TRENTONIAN\n\n\"Lindbergh:  Real Trial of the Century.\" - LOS ANGELES TIMES\n\n\n\n"
        },
        {
            "subject": "my WCAG respons",
            "content": "Attached is an html file giving my comments on the two WCAG documents you \nsent.\n\nBest wishes, Tim Boland NIST\n\n\n\n\ntext/html attachment: wcag21.htm\n\n\n\n\n"
        },
        {
            "subject": "Comments on WCAG 2.0 draft, 24 June 200",
            "content": "This document has the profound effect of synthesizing \nthe needs of those who publish webpages with the needs \nof those who use them. Many thanks to the working group \nfor this work.\n\nWCAG questions:\n\n1.  In general, is this WCAG 2.0 Working Draft easy to understand?\n    Please identify sections or phrases that are difficult \n    to understand.\n\n    Please suggest alternative wording for the Working \n    Group to consider.\n\n    + Because this document serves such as wide audience,\n      it would be helpful to simplify the language a little\n      unless the style is a prescribed convention\n      for W3 documents. Could a more familiar term\n      such as \"recommended\" be substituted for \"normative\"?\n\n      I have included notes and suggested a few wording changes.\n\n2.  The conformance structure of this WCAG 2.0 Working Draft differs\n    from WCAG 1.0 and from the previous WCAG 2.0 Working Draft.\n    Is the concept of Core and Extended checkpoints easy \n    to understand?\n\n    Is this an effective structure?\n\n    + I like the change to two levels rather than three,\n      and the new terminology. Perhaps more people\n      will try to satisfy both levels when there are only two. \n      Since the new document is general and abstract\n      to make it less technology-specific, the forthcoming\n      supporting documents will be very helpful for specifics.\n\n3.  If your site or organization already uses WCAG 1.0, do you\n    think it will be difficult to migrate from WCAG 1.0 to \n    WCAG 2.0, based on\n    the current draft? Please note that the Working Group \n    is developing supporting documents such as technology-specific \n    techniques documents and checklists for WCAG 2.0.\n\n    + Experience with WCAG 1.0 will make it easier to figure out\n      and use WCAG 2.0. Task-specific documents, such as\n      \"Programming webpages for accessibility\" or\n      \"Writing accessible content for webpages\"\n      might helpful in addition to, or as part of,\n      technology-specific technique documents.     \n      A potential benefit of task-oriented documents is to widen    \n      the audience and include more people in accessibility efforts.\n\nNOTES AND SUGGESTED WORDING CHANGES:\n\nHow to Read this Document\n2 - Technology-specific Checklists\n\nIn addition to the forthcoming technology checklists,\nI suggest developing task-specific guides, such as\n\"Programming webpages for accessibility,\" \n\"Writing accessible content for webpages,\" \n\"Editing accessible content for webpages,\" or\n\"Accessibility in designing webpages\" for instance.\n\nAudience\n\n  Suggested wording change, \"many different audiences\":\n\n  I suggest something like: \"...many different audiences \n  who make policy, create content, and code pages.\"\n\nPriorities and Techniques\n\n  The mapping document is very helpful. Thank you!\n\nBest Practice for Checkpoint 2.1 (Operability)\n\n  Would it be possible to include an example alternative coding method here? \n\n  I'm not sure what sort of method I would try, or whether it would be\nacceptable. Thanks.\n\n3.3 (Content)\n\n  The recommendations for writing style apply to\n  all types of communications media and might be\n  too broad or tangential for accessibility guidelines. \n\n  Maybe the recommendations could be placed\n  in a separate list or supporting guidebook for editing web content.\n\nExamples of Checkpoint 3.4 (Informative)\n\n  Example 2\n\n  From a usability standpoint, some designers \n  suggest avoiding arrows before links\n  because symbols don't give users enough information about\n  the result of clicking the symbol.\n  Maybe just text, such as,\n  \"[OPEN THIS LINK IN A NEW WINDOW.]\"  would be sufficient, right after \n  the link, unless a page is loaded with many links of this type.\n  More specific examples like this one would be helpful\n  throughout the document.\n\n  Example 3\n\n  So many nonfunctional Back buttons appeared with the\n  emergence of .jsp and .asp pages that I wondered if\n  nonfunctional Back buttons might not be easily controlled \n  through code in some languages. Perhaps an expert\n  in those languages has confirmed this example.\n\nGuideline 4 (Robust)\n\n  Wording suggestion: \n\n  \"Use Web technologies that optimize content for \n  compatibility with current and future accessibility \n  technologies and user agents.\"\n\n  Could an example be included?\n-----\nPreferred address for accessibility work:\nJoyce Tikalsky\njatikalsky@mailbag.com\n608/873-6944\n\nAlso:\nwebmaster@engr.wisc.edu\n608/265-8669\n\n\n\n"
        },
        {
            "subject": "Comments on Draft WCAG 2.",
            "content": "Please find attached the comments from the Kansas Web Accessibility\nSubcommittee (WAS).  We apologize for getting these to you under the\nwire.  If there are any comments or clarification needed, please contact\nme.  Thanks for giving us the opportunity to comment on the proposed\nchanges.\n \nFrances Grenier, Co-Chair\nKansas Web Accessibility Subcommittee\n785.267.5301 x249\n\n\n\n\n\napplication/vnd.msword attachment: WAS_Letter_to_W3C_for_Guidelines_2.doc\n\n\n\n\n"
        },
        {
            "subject": "Request for Review WCAG 2.",
            "content": "With respect to the June 24 WCAG 2.0 draft, I have a number of comments,\ndetailed below.  First, however, I would like to congratulate the authors\nfor taking on such a difficult task.  In particular, I'm delighted that the\ngroup is intending to broaden the scope of the guidelines to address a\nbroader set of technologies.  To the extent that this broadening succeeds,\nits influence can go well beyond that of web content and authoring, and\npotentially guide the efforts of developers of assistive technology as well.\n\n\nHaving said that, I believe also that the guidelines are in general less\ncomprehensible (indeed, less accessible!) to the intended readership than\nwere the version 1.0 guidelines, and that the lack of comprehensibility\nstems from the very abstraction of principles that was necessary for\nbroadening to other technologies.  I believe these problems can be addressed\nand alleviated through the planned technology-specific checklists,\nespecially if the checkpoints in the WCAG are cross referenced to technology\nspecific guidelines. Apart from a few exceptions, I don't believe, however,\nthat making the guidelines significantly easier to understand can be\naccomplished by simple rewriting.  Like a mathematics text in which axioms\nand theorems provide the foundation, and examples and problems the practical\nunderstanding, this may be a necessarily abstract document.\n\nThe conformance structure of Core and Extended is fine, both easy to\nunderstand and potentially effective, provided more objective and\nquantitative methods of evaluating specific conformance to checkpoints can\nbe developed.  But conformance to specific checkpoints is best evaluated in\nthe context of specific technologies, where specific items are less open to\nbraod interpretation.  Without technology specific checkpoints, I would\nimagine that squabbling and bickering over conformance will increase, and\nwith more latitude to interpret the guidelines as they see fit, developers\ncould claim more for less actual conformance.  So I would favor keeping the\ngeneral structure of the draft as a kind of umbrella document, but\ninstantiate the conformance checkpoints with technology-specific\ncheckpoints.  Since the planned technology-specific checklists were not\nincluded in this draft, it's difficult to evaluate the conformance\nstructure.  However, in theory, the structure seems fine to me.\n\nDevelopers at my organization do use the 1.0 WCAG, but much of their use is\nindirect---via automated tools to evaluate conformance.  Because web sites\ncan be huge and dynamic, reliance on such tools is at least partially\ninevitable.  However, to the extent that the current document is even less\nspecific than v1.0, I would see migration being difficult. Without\ntechnology-specific checklists, it is easy to imagine developers of\nevaluation and repair tools with widely disparate views of what constitutes\nconformance.  Again, I would prefer to view this draft as an umbrella\ndocument with more specifics to be incorporated as an essential component of\nthe 2.0 WCAG recommendation.\n\nHere are some other specific comments, nearly all pertaining to Guidelines 1\nand 2:\n\n1. I didn't understand the designation of examples and benefits as\n\"non-normative\"  or \"informative.\"  Are these terms lingo, or am I just\nbeing thick (or both)?\n\n2. Overview of Design Principles, last para before Note: \n\nThis would better read, \"Accessible web content can benefit people with as\nwell as without disabilities.\" Accessible web content does not ALWAYS\nbenefit people other than the disabled. High levels of magnification, for\nexample, which can make things more accessible to people with low vision,\ncan make documents more difficult to navigate. \n\nDelete next 2 sentences, which are superfluous since examples of accessible\nweb content benefiting others is subsequently given (and giving wheelchair\nexamples to the reader is tiresome---readers of the WCAG can, nearly 14\nyears after the ADA, be assumed to understand general things about\ndisabilities without being prompted to conjure up images of wheelchairs).  \n\n3. User needs, first bullet:\n\nChange \"via sound\" to \"visually.\"\n\n4. Definitions for checkpoint 1.1: text equivalent\n\nThis is not a definition.  I would first define \"text\" as code representing\nwritten language, that is a one-to-one mapping of alphabetic and numeric\nsymbols.  Then define \"text-equivalent\" as text that serves to communicate\nsubstantially equivalent content as another representation such as an image.\n\n5. Benefits of checkpoint 1.1, first bullet:\n\nadd \", or otherwise transformed to different presentation format (e.g. font,\ntext size)\n\n6. Checkpoint 1.5\n\nI believe that the benefit of adding structure to the document is that it\nallows assistive technologies more information about the document in order\nto tailor its presentation to the user's capabilities.  This checkpoint, as\nwritten, however, seems to focus on how document elements are rendered.  For\nexample, the (sole) required success criterion refers to visual appearance\nor auditory characteristic.  The examples also are about how to render.\nThat's not a WCAG issue, in my view.\n\nAlso, who (or what) could judge whether structure \"has been made perceivable\nto more people...\"?  Compared to what? This is way too vague.\n\n7. Editorial Note (22 May 2003) regarding \"additional items in 4/29 draft\n\nYes, in my opinion, these should be moved to techniques.\n\n8.  Checkpoint 1.6\n\nThis is very vaguely worded.  I would propose instead the following\nlanguage:  \"Where possible, use layered designs to allow selective\npresentation or blanking of visual or auditory elements, comprising, for\nexample, foreground and background content.\" \n\nThe sole success criterion for 1.6 is in terms only of visually imagery.  I\nwould refer to layered auditory images, such as background music with a\nvoice-over, to allow hearing-impaired user to remove the background music\nfor greater clarity.\n\nUnder best practice for 1.6 #1 and #2, what does \"easily readable\" mean?\nAnd to whom? This is not quantifiable.\n\nAlso, who came up with the 20 dB (or 4 X louder) foreground/background audio\nfigure?  Are there any data to back this up as being sufficient?\n\nIt's true that there are no effective tests for visibility or readability\nthat do not rely on standard human observers in terms of color or color\ncontrast (the claims of some notwitstanding). The reasons for this include\nthe fact that display devices and hardware used to drive them vary widely in\npeak luminance, color gamut, and linearity; viewing conditions of observers\nvary widely (ambient room lighting, presence of reflections from nearby\nwindows, etc.); readability and visual discriminability also depend\ncritically on the kinds of stimuli used.  A very low contrast text in a huge\nfont may be as or more readable than a smaller font in very high contrast.\nTypography and image characteristics also go into the mix of important\nfactors.  And let us not leave out the enormous variability in visual\ncapacity of the visually-impaired population, some of whom will settle for\nno less than the blackest black against the whitest white. The long and\nshort of it is that we simply do not have in the foreseeable future a good\nway to evaluate objectively things like accessibility of text contrast\nand/or color.  This is thus an issue in which, I believe, the best we can do\n(and thus the most we should do) is to suggest principles to follow to\nenhance accessibility. \n\n9. Examples of checkpoint 1.6 first bullet:\n\nWhat are the \"standard foreground/background contrast requirements\"? If\nthere are any, please clarify (and cite).\n\n10. Required success criteria for checkpoint 2.2 #1:\n\nI would add the following bullet: \"* or the user can control the\npresentation by eliciting phases sequentially via keystrokes.\" \n\n11. Checkpoint 2.3\n\nI would be very surprised if anyone could devise a substantive and effective\ntest for flicker in machine readable format.  Here are some thought\nexperiments:\n\nConsider a single pixel flickering in the 3-49Hz range on your screen right\nnow.  Do you think you could detect it?  If so, do you think it could\npossibly cause a seizure in someone with photosensitive epilepsy?  You do?\nHow about if that single pixel flickered by changing its intensity 1/256? or\n1/(256^3)? \nStill think so? \n\nHow many phases (i.e. alternations) of light and dark constitute flicker in\nthe 3-49 Hz range? What if I present a black dot for 1.5 seconds, then\nreplace it by a white dot for 1.5 seconds?  Would you call that 3 Hz\nflicker?  In other words, how many \"cycles\" of the pattern do you require\nbefore you call it flicker?\n\nHere's a third: Mathematically the sum of leftward moving and rightword\nsinusoidal gratings is equal to a single stationary sinusoidal grating whose\nbars reverse in contrast.  Any single point in that pattern will flicker. Do\nwe call that flicker or moving gratings?  Were we to analyze many moving\npatterns we would find that we could describe them mathematically in terms\nof flickering components. What if we have a video taken from a moving car or\ntrain that passes by a picket fence.  Will not there be some flicker in that\nvideo? Shall we ban all animations in the WCAG?  \n\nIt is likely that scientists will some day be able to better zero in on the\nspecific visual causes of photosensitive epileptic seizures; presumably high\ncontrast large field flicker poses a greater risk than do low contrast\nflickering single pixels.\n\nUntil we know more, or until qualified experts on this condition weigh in,\nor credible scientific evidence is presented that better specifies the\nparameters of the flicker, I believe this checkpoint should be deleted.\n\nThank you for the opportunity to comment on this draft.\n\nAries Arditi, Ph.D.\nSenior Fellow in Vision Science\nArlene R. Gordon Research Institute\nLighthouse International\n111 East 59th Street\nNew York, NY 10022\n\nTel: +1 212 821 9500 (direct)\nFax: +1 212 751 9667\nhttp://www.lighthouse.org/research_staff_arditi.htm\n\n**************************************************************************************************\nThe contents of this email and any attachments are confidential.\nIt is intended for the named recipient(s) only.\nIf you have received this email in error please notify the system manager or  the \nsender immediately and do not disclose the contents to anyone or make copies.\n\n** eSafe scanned this email for viruses, vandals and malicious content **\n**************************************************************************************************\n\n\n\n"
        },
        {
            "subject": "SIDAR's WCAG2espa group : Comments on Working Draft of WCAG 2.",
            "content": "SIDAR (Seminario Iberoamericano sobre Discapacidad y Accesibilidad en la\nRed) is a permanent working group devoted to promote accesibility in new\ntechnologies and web accesibility as its core concern. Its members are\nvolunteers from all over Latin America, Portugal and Spain are experts\nin IT and accessibility. For an extensive introduction please visit\nwww.sidar.org\n\nWCAG2-espa is a Spanish translation group focused on WCAG 2.0, formed\nwhen the first working draft was released. We would like to thank the\nopportunity the Working Group is offering the web community requesting\ncomments on their work.\n\nComments on 06/24/2003 Working Draft of WCAG 2.0:\n\nComments are organized as follows. First, the part of the text commented\nis written, according to the hierarchy expressed in the table of\ncontents. Then a link to the nearest anchor in the document is given,\nand finally the comment to the point is explained. Highlighting is made\nplacing text in asterisks. \n\n\n1)Introduction: How to read this document: Technology-specific \nchecklists\n\nURL: http://www.w3.org/TR/2003/WD-WCAG20-20030624/#how-to\n\nWe'd like to congratulate the working group for approaching the new\nversion of the guidelines in this way, separating the different layers\nthat are present in web content production processes. The first one\ninvolves design and is the main concern of these guidelines. The\ndocument acquires a more abstract point of view and detaches from the\nfinal technology used by the user to access the content. However, this\nmore abstract approach moves the guidelines away from their final\napplication in web content production. This is the main reason why we\nthink that the second group of documents, the Technology-specific\nChecklists, must strengthen the purpose of the guidelines and therefore\nshould be normative for each technology. \n\nThat is to say, conformance to these guidelines and conformance to\ntechnology-specific checklists should be bound in a clear and plain way.\n\n\n2)Introduction: Conformance\n\nURL: http://www.w3.org/TR/2003/WD-WCAG20-20030624/#conformance\n\nWith regard to the different levels of comformance, we think that\nconsidering a \"Core+\" level is a good idea. But we think that the wide\nspectrum and subtleties inside this qualification shouldn't be measured\nby the number of checkpoints that are met. A more satisfactory way to do\nit would be to create several combinations of Extended Checkpoints to\nqualify the specific way in which the content cares  about\naccessibility. These combinations would give different \"flavours\" to\n\"Core+\" conformance claim.\n\nAs an example, verification of Extended CheckPoints 1.5, 2.4, \n3.4 could qualify \"Core+\" conformance claim as \"usable\" as it considers\nperception, operability and understandability points that strengthen\nusability of the content.\n\n\n3)Guideline 1: Core Checkpoints: 1.1\n\nURL: http://www.w3.org/TR/2003/WD-WCAG20-20030624/#text-equiv\n\nWe think it's a basic conceptual error to use the expression \"non-text\ncontent that can be expressed in words\". What does it mean? All content\n*can* be expressed in words or described in some way. With all our\nrespect it's like saying \"oops sorry,  I remained speachless\" in the ALT\nattribute of an image. When one reads Required Success Criteria 2. of\nthis checkpoint, one thinks you are talking about \"non-text content that\ncan not be expressed in *a few* words\". So, shoudn't the Checkpoint\nread: \"1.1 [CORE] All non-text content that can be expressed in a few\nwords has a text equivalent of the function or information that the\nnon-text content was intended to convey. [was 1.1]\". And Required\nSuccess Criteria 2. should read: \"non-text content that can not be\nexpressed in a few words has a descriptive label provided as its\ntext-equivalent\"\n\n\n \n4)Guideline 1: Core Checkpoints: 1.3: Example 4\n\nURL:\nhttp://www.w3.org/TR/2003/WD-WCAG20-20030624/#content-structure-separation\n\nExample 4 in this checkpoint should also include a reference to\ncheckpoint 4.3\n\n \n5)Guideline 2: Core Checkpoints: 2.1: Definitions: Editorial Note\n\nURL: http://www.w3.org/TR/2003/WD-WCAG20-20030624/#keyboard-operation\n\nProposed definition for \"operable through a keyboard interface\": Content\nis operable when it is properly designed in a way that all the\ninformation is reachable and all the funcionality is available through\nan efficient use of a keyboard interface. An appropriate hierarchical\ncollection of keyboard shortcuts or a navigation bar situated after each\nsection strengthens operability. Intensive use of tabbing weakens\noperability due to monotony and lack of a clear structure.\n\n\n6)Guideline 2: Extended Checkpoints: 2.4\n\nURL: http://www.w3.org/TR/2003/WD-WCAG20-20030624/#navigation-mechanisms\n\nShouldn't this checkpoint be a Core one? Besides, we think the Required\nSuccess Criteria miss the point. We think there shouldn't exist a\ntrigger length below which unstructured documents are happily welcome.\nAllowing structure markup to disappear is a step backwards, since even\nin a single document without a table of contents, structural markup such\nas lists, paragraphs, etc. give a solid base to understand the relative\nweight of different content pieces. \n\nThe way the Checkpoint is written allows for weird interpretations such\nas thinking that alternate navigation mechanisms can substitute\nstructure. We propose an alternate redaction for Checkpoint 2.4 : \"The\ncontents are structured and alternate navigation mechanisms have been\nadded to facilitate orientation and movement within\"\n\nOf course this implies a reformulation of the whole explanation of the\nRequired Success Criteria.\n\n\n7)Guideline 4: Extended Checkpoints: 4.3\n\nURL:\nhttp://www.w3.org/TR/2003/WD-WCAG20-20030624/#technology-supports-access\n\nThis a controversial Checkpoint becuase it involves the other layers of\nweb content production processes. Maybe it should be reformulated but it\nshouldn't disappear. Maybe it could be the binding point with the\nTechnology-specific Checklists. Developers and web designers, whatever\nthe device they are thinking of primarily, must know that they must\nproduce accessible products. See our comment to \"How to read this\ndocument\".\n\n\nThanks again for this opportunity to contribute to WCAG 2.0.\nJuan Luis Lara\nWCAG2-espa coordinator\n\n\n\n"
        },
        {
            "subject": "Fwd: WCAG 2 and Tom Marti",
            "content": "[Tom Martin is going through WCAG 2.0 with an editorial eye. This is the \nfirst in a series of messages that he sends]\n\n>Separation into three layers is a good idea, I believe. It mirrors the \n>\"separation of content from presentation\" mantra. Keeping to 18 the \n>checkpoints for the guidelines is good, too.\n>\n>I was surprised to see that identifying data table headers is part of an \n>extended checkpoint. My experience with screen-reader technology (I use \n>WindowEyes 4.2) tells me that the ability to navigate within a data table \n>should be core.\n>\n>Anyway, that is the one matter of substance I noted. I will work over the \n>next few days to finish an edit of the draft and will send you a file when \n>I am done.\n>\n>Tom\n\n-- \nwendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/-- \n\n\n\n"
        },
        {
            "subject": "WCAG 2 and Tom Martin, August 2",
            "content": "I have worked my way up to flicker. I think that is 2.2 or 2.3. I put an \nanchor where I stopped.\n\nEvery once in a while, I return to previously edited text and tinker.\n\nI will sit down with a top to bottom reading when I get to </body>.\n\nCheerio!\n\n\n\n\n\n\ntext/html attachment: wcagaug20.htm\n\n\n\n\n"
        },
        {
            "subject": "WCAG 2 thru checkpoint 1.",
            "content": "Here is a copy edited thru checkpoint 1.2\n\nMore later. I'll keep moving the stop anchor along until I reach the end.\n\nTom\n\n\n\n\n\ntext/html attachment: wcag2.htm\n\n\n\n\n"
        },
        {
            "subject": "Comments on WCAG draft 2.",
            "content": "The attached document reflects the comments of those of us at the U.S.\nAccess Board to the latest draft of the Web content Accessibility\nGuidelines.\n\n\nDoug Wakefield\nU.S. Access Board\n1331 F St. NW\nSuite 1000\nWashington, DC  20005\nPhone: 202-272-0024\nwww.access-board.gov/508.htm\n...........................................................................\nThank you for your questions concerning section 508 of the Rehabilitation\nAct Amendments of 1998.  Section 508 authorizes the Access Board to provide\ntechnical assistance to individuals and Federal departments and agencies\nconcerning the requirements of this section. This technical assistance is\nintended solely as informal guidance; it is not a determination of the legal\nrights or responsibilities of entities subject to section 508.\n...........................................................................\n\n\n\n\n\napplication/msword attachment: comments_on_wcag21.doc\n\n\n\n\n"
        },
        {
            "subject": "Language section in WCAG HTML Technique",
            "content": "Dear WCAG, \n\n\nAt http://www.w3.org/WAI/GL/WCAG20/WD-WCAG20-HTML-TECHS/#language-tech\nyou say:\n\n\"Use the lang attribute to identify the natural language used in a\ndocument.\"\n\nWe believe this should clarify that XHTML requires xml:lang also for\ndocuments served as text/html [1].  (XHTML documents served as XML only\nrequire xml:lang.) Note that according to the XHTML spec, xml:lang takes\nprecedence for XHTML documents in case of conflict.  There is also other\ntext and another technique in the section on Language that would need to\nbe updated in this manner.\n\n\nWe also believe that it would be more intuitive for the new reader to\nreverse the order of the two subsections entitled \"Identifying the\nprimary language\" and \"Identifying changes in language\".\n\n\nFinally, you may wish to add a note that, although the HTML\nspecification still refers to RFC1766 for definition and explanation of\nhow to implement language codes, RFC1766 has now been obsoleted by\nRFC3066 [2], and authors should use the latter document.  (I18N has\nrequested that an erratum be added to the specification to this effect,\nbut it is not clear at this point when errata will be forthcoming.)\n\n\n[1] http://www.w3.org/TR/xhtml1/#C_7\n\n[2] http://www.ietf.org/rfc/rfc3066.txt\n\n\nRichard Ishida,\nFor the I18N WG.\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "EOWG comments on WCAG 2.0 24 June 2003 Working Draf",
            "content": "EOWG Comments on Web Content Accessibility Guidelines 2.0 24 June 2003 \nWorking Draft\n\nThe Education and Outreach Working Group (EOWG) offers the following \ncomments on the Web Content Accessibility Guidelines 2.0 24 June 2003 \nWorking Draft [1].\n\nThese comments derive from discussions held at EOWG teleconferences on 8, \n15, 22, and 29 August, and 12 September, and were based on EOWG discussion \nquestions [2].\n\nRegards,\n\n- Judy Brewer, EOWG Chair\n\n\nPRESENTATION & ORGANIZATION:\n\n1. Start providing different views (guidelines + checkpoints statements & \nexplanations; checkpoints statements + benefits; checkpoints & success \ncriteria; etc.; checkpoints grouped by core and extended, etc.) as of the \nnext public working draft, so that reviewers can get a better idea of how \nthe document works for different audiences. In particular, be sure to \ninclude a \"benefits\" or \"impact matrix\" view.\n\n2. For subset views (e.g., views listing only certain elements of the \noverall document, as described above) include a reminder of the other views \nthat are available, so that if someone generates a subset, prints it, & \nhands it to someone else, the other person realizes that there is \ninformation beyond the information in the printed version that they were \ngiven. Perhaps the top of each generated sub-set document could have a list \nof what is in the full view.\n\n3. Start breaking the working draft document up into modules, as of the \nnext public working draft, in addition to making it available in a single \nrun-on HTML file, so that reviewers can get a better idea of how well the \ndocument's presentation works.\n\n4. The Abstract should be an abstract of the document, rather than a \ndescription of history & goals.\n\n5. Provide both concise and expanded Tables of Contents, as of the next \npublic working draft, so that people can better judge the usability and \npresentation of the document while it is under development.\n\n6. Instead of linking the entire checkpoint text in the Table of Contents, \nadd & link the checkpoint ID (as used in the matching table) or target text \n(but with most words in the ID written out, rather than using uncommon \nabbreviations).\n\n7. Don't repeat the words [CORE] and [EXTENDED] between each number and the \ntext in the Table of Contents, since it is already indicated with a \nsub-section heading.\n\n8. Provide a clearer heading or context for the paragraph on \"Designing \nAccessible Web Content\" which immediately precedes Guideline #1. Currently \nit is unclear where it fits in the structure of the document -- is it a \nfinal section in \"Overview of Design Principles,\" or a lead-in to the \nguidelines themselves?\n\n9. Consider adding \"Back to Table of Contents\" link throughout, for \ninstance, before each heading level, to improve navigation.\n\n10. Leave \"Best Practices\" out of the document if possible, and \nre-integrate any non-redundant information into other categories \n(definitions, examples, etc.). However, if leaving best practices in, \npresent them more consistently, and avoid duplication between best \npractices, required success criteria, and examples. Introduce them properly \nin the introduction, and clarify that \"Best Practices\" is not an additional \nconformance level.\n\n11. Make it easier to find specific accessibility topics within the \ndocument, for instance, by providing more links to the WCAG 1.0 to WCAG 2.0 \ntransition map, or consider adding mechanisms such as a topic index in \nwhich people could search for the kinds of terms that they think in terms \nof when actually designing sites, e.g. \"navigation,\" \"forms,\" etc.\n\nGENERAL CLARITY:\n\n12. Review wording of checkpoints to ensure that they are stated in ways \nthat are no more complex than necessary. (EOWG did not reach consensus on \nspecific suggestions here, but will send some of our observations about \nclarity & understandability of some of the checkpoint statements in a \nseparate email to WCAG WG Chairs and Editors.)\n\n13. Clarify the \"how to read this document\" section, to differentiate what \nis in this document vs. what is in other related documents. Include \ndescriptions of each of the key elements of the document, e.g., success \ncriteria, definitions, benefits, examples, and best practices (in the event \nthat best practices remain in the document). For instance: \"There are four \nGuidelines, which are principles of accessible Web design. Under each \nGuideline are the Checkpoints. The 18 Checkpoints are the focus of WCAG2.0. \nUnder each Checkpoint are success criteria, definitions, benefits, and \nexamples. Success criteria is... etc.\"\n\n14. The descriptions of guidelines in the \"Overview of Design Principles,\" \nand the individual guidelines themselves, should be made consistent; and \nthe key terms used for the guideline level (e.g. perceivable, robust, etc.) \nmust be defined very clearly, in order for the document to work when \ntranslated into other languages.\n\n15. Send people to the WAI Resource page, instead of the EOWG home page, \nfor supporting resources.\n\n16. The paragraph in \"Overview of Design Principles\" which begins \n\"Accessible Web content benefits a variety of people, not just people with \ndisabilities\" has several problems:\n- the phrase \"not just people with disabilities\" sounds like it belittles \nthe importance of accessibility for people with disabilities;\n- the paragraph goes into more detail than seems appropriate for the \nguidelines document -- it sounds a little like a sales pitch in the middle \nof a technical standard -- consider instead referencing other WAI documents \nwhich address what the impact is on people with disabilities and additional \nreasons why accessibility is important.\n- if still including a paragraph discussing user needs, emphasize \"here are \na few scenarios, by no means an exhaustive list of the variations and types \nof disabilities and needs...\"\n- intro and overview sections will also need a technical editor to look \nover them (though EOWG understands this may be at a later stage).\n\nCONFORMANCE MODEL & EXPLANATION:\n\n17. Better explain the transition between the normative content of WCAG 1.0 \nand WCAG 2.0. Provide some explanation for the substantial change in the \nnumbers of guidelines and checkpoints between the 1.0 and 2.0 versions. \nAlso make sure that the terms \"normative\" and \"non-normative\" are clearly \ndefined. Many readers do not know what these terms mean in general, nor \nwhat they mean specifically in the context of this document, nor in the \ntransition between WCAG 1.0 and 2.0.\n\n18. Reconsider the terms \"Core\" and \"Extended\". The use of the word \n\"Extended\" is read by some people as implying that an \"extended\" checkpoint \nis essentially a more rigorous version of a \"core checkpoint,\" rather than \nbeing an unrelated accessibility provision which, if implemented, provides \na higher degree of accessibility. In addition, it is unclear whether some \nextended checkpoints are more important, or might have more \"weight,\" than \nothers. (This is not necessarily a recommendation that \"extended \ncheckpoints\" have some assigned weight, but a request to at least clarify \nif they do not.)\n\n19. Provide two levels of definitions for the terms \"core\" and \"extended\" \nor whatever terms are chosen as final names for conformance levels: as \nclear definitions in a glossary format, to ensure the clearest possible \ntranslations into other natural languages; and in terms of their impact on \nassuring a given level of accessibility for people with disabilities. The \ndescription of their impact on assuring a given level of accessibility \nshould include a description of their similarities with and/or differences \nfrom the priority and conformance levels in WCAG 1.0.\n\n20. Under \"Conformance, Conformance Claims\" switch #s 3 & 4. (Currently #2 \nis Core, #3 is Extended, and #4 is Core+, which is actually in between core \n& extended in terms of conformance level. Eliminate #1 so that the numbers \nmatch the conformance claim levels. [Note: even if the terms core/extended \nchange, our comment about order of presenting the terms would still remain \nthe same.]\n\n21. The WCAG WG requested feedback on the conformance model. The EOWG had \nmuch discussion regarding the intermediate conformance level, but without \nconsensus. Some representative, though conflicting, comments follow.\n- It is useful to have some kind of intermediate level (such as the current \n\"Core+\") between Core and Extended, though the current terms are confusing.\n- It is probably not realistic to expect complex statements from Web \ndevelopers regarding the intermediate level (e.g., conformance on a \ncheck-point by check-point basis, per page or per site).\n- If expecting Web developers to provide checkpoint-by-checkpoint \nconformance information, provide a best practice model, for instance in \nmetadata, for detailed reporting of conformance.\n- Perhaps if recommending checkpoint-by-checkpoint detailed reporting of \nconformance, make doing that an \"extended\" checkpoint (or whatever term is \nchosen for the higher conformance level).\n\n\n[1] 24 June 2003 Working Draft, Web Content Accessibility Guidelines 2.0\nhttp://www.w3.org/TR/2003/WD-WCAG20-20030624/\n\n[2] EOWG review questions:\nhttp://lists.w3.org/Archives/Public/w3c-wai-eo/2003JulSep/0058.html\n\n\n\n-- \nJudy Brewer    +1.617.258.9741    http://www.w3.org/WAI\nDirector, Web Accessibility Initiative (WAI), World Wide Web Consortium (W3C)\nMIT/LCS Room NE43-355, 200 Technology Square, Cambridge, MA,  02139,  USA\n\n\n\n"
        },
        {
            "subject": "Comments: WCAG 2.",
            "content": "Dear WCAG WG;\n\nFirst of all I want to say this draft is very readable and flows nicely from\nsection to section.  The \"informative\" sections are very helpful and are\nwell-placed.   Below are my general comments and responses to the document:\n\n-How should conformance claims state which guidelines are met? in metadata?\nin a site accessibility statement? some other method?\n*CJS: Use of logos and metadata with a statement for + status would be my\npreferred way of making conformance claims\n\n-How should conformance claims state how many Level 2 criterion are met? In\nmetadata? With A+n (n=number of AA criterion met)? In a site accessibility\nstatement? Some other method?\n*CJS: I like the A+n conformance claim - though I agree that it is difficult\nto compare numerically the accessibility of websites.  Because of this I\nthink an additional statement should be included about which criteria are\nmet.\n\n-Is there a separate logo for each level: A, A+, and AA? If so,what does the\nlogo point to?\n*CJS: I would like to see separate logos pointing to descriptions of each\nlevel and linking to the Guideline itself.  I would imagine it would say\nsomething along the lines of: \"This logo means that compliance with WCAG 2.0\nAA has been met.  This web content conforms to the following accessibility\nguidelines:\"\n\n-Guideline 2.1 Make all functionality operable via a keyboard or a keyboard\ninterface.\nWho Benefits from Guideline 2.1 (Informative)\n*CJS: Suggested Addition:\nKeyboard operation also benefits advanced users as they can access\ninformation more quickly then regular navigation usually facillitates.\n\n-Guideline 2.4 Facilitate the ability of users to orient themselves and move\nwithin the content. [level 2 guideline]\nLevel 2 Success Criteria for Guideline 2.4\nIn documents greater than 50,000 words or sites larger than 50 perceived\npages, at least one of the following is provided. [V]\n*CJS:  This is arbitrary - what if the document has 49,000 words - it is\nstill a large document but it would not be expected to meet this guideline.\nAnd as for the 50 perceived pages I'm not sure if the perceived pages refers\nto the site's navigation structure (what pages you can navigate through the\nmain navigation), or if this refers to pages that are just linked from other\npages in the site.  I'm not sure what to suggest at this point, but\nclarification is needed.\n\n-Guideline 2.5 Help users avoid mistakes and make it easy to correct them.\n[level 2 guideline]\nWho Benefits from Guideline 2.5 (Informative)\n*CJS: Suggested Addition:\nIdentifying typing errors also helps individuals without disabilities to\navoid time-consuming mistakes and general confusion.\nHelping all users to avoid mistakes increases a websites overall usability\nin addition to accessibility.\n\n-Guideline 3.1 Ensure that the meaning of content can be determined.\n*CJS:  I agree with the Editorial Note regarding reinstating the allowance\nof text-only variants in cases when the \"original\" can't be made accessible\nany other way.  With the caveat that the text-only variant be updated\nwhenever the \"original\" changes.\n\n-Guideline 3.2 Organize content consistently from \"page to page\" and make\ninteractive components behave in predictable ways.\n*CJS: Suggested change for this guideline:\nOrganize content consistently from segment to segment and make interactive\ncomponents behave in predictable ways.\nDefine \"segment\" in the Glossary as a single interactive section of a\nparticular interface.  For example, an segment for a website would be a\npage.\n\nI hope you find these comments/suggestions constructive.  Feel free to\ncontact me with any questions.  I look forward to future drafts.\n\nRegards,\n\nCarol J. Smith\nKognitive Consulting, Inc.\ncarol@kognitive.com\n773-218-6568\n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 38",
            "content": "Hello Harvey,\n\nYou made comments on WCAG 2.0 [1].  This email shows how the WCAG WG has \nattempted to address one of your concerns.  We will send a separate email \nfor each of the issues you raised. Please let us know if we have adequately \naddressed your issues.\n\nIssue 383 [2]\n\nYou said:\n\"Required for success of 3.4\nOmit the ambiguous opening use of \"Key\" followed by \"orientation and\nnavigation.\"\n\nUse \"Important\" instead.\n\nBest Practices for Checkpoint 3.4\nUse consistent \"verb first\" style for each list item.  About half now are\n\npassive:\n... should be ...\"\n\nWe believe this is addressed in the March 11, 2004 Working Draft [3]\n\nGuideline was significantly rewritten for this draft - replaced \"key\" and\n\"important\" with \"components that are repeated\"\n\nThank you,\n--wendy\n\n[1] http://lists.w3.org/Archives/Public/w3c-wai-gl/2003JulSep/0287.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=383\n[3] http://www.w3.org/TR/WCAG20/#consistent-behavior\n\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 42",
            "content": "Hello Kynn,\n\nYou made comments on WCAG 2.0 [1].  This email shows how the WCAG WG has \nattempted to address one of your concerns.  We will send a separate email \nfor each of the issues you raised. Please let us know if we have adequately \naddressed your issues.\n\nIssue 422 [2]\n\nKynn Bartlett writes:\nphrasing: Whaaaaat? I don't understand what this checkpoint is trying to\nsay to me.\n\nThis guideline was significantly rewritten in March 11, 2004 Working Draft \n[3].  Is the intent of the Guideline clearer?\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Aug/0000.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=422\n[3] http://www.w3.org/TR/WCAG20/#consistent-behavior\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 49",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 496 [2]\n\nGreg Gay writes:\n\n3.4 An extreme change can be identified after the change has occurred,\nsuch as a \"close new window\" link as the first feature of a popup\nwindow, or presenting a feedback message after server side redirecting a\nuser from the content editing screen to the content display screen when\nediting is completed (feedback like \"content was successfully updated\"\nsee guideline 2.5 above).\n\nguideline should read \"..., but not necessarily identical\".\n\nThis guideline was significantly rewritten in the March 11, 2004 Working \nDraft [3].  However, the draft does not include anything about success \nfeedback. It is not clear whether the recommendation to include this \nfeedback is something for the guidelines or techniques.  If you feel this \nshould be included as a success criteria, please propose an edit to the \nlatest draft.\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Sep/0000.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=496\n[3] http://www.w3.org/TR/WCAG20/#consistent-behavior\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 70",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 703 [2]\n\nGreg Lowney writes:\n\n59.     Guidelines 3.4 \"Key orientation and navigational elements (such\nas navigation bars) are generally found in one or two consistent\nlocations.\"\n\n59.a.    [LOW PRIORITY] I recommend saying something like \"(such as\nnavigation bars, page numbers, and section titles)\" to avoid giving the\nimpression that we're only referring to things outside the primary\ncontent.\n\nThis guideline was significantly rewritten in the March 11, 2004 Working \nDraft [3] and we believe we have addressed your concern.  Do you agree that \nthe latest wording makes it clear that we are referring to objects outside \nof the primary content?\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Nov/0003.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=703\n[3] http://www.w3.org/TR/WCAG20/#consistent-behavior\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 70",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 705 [2]\n\nGreg Lowney writes:\n\n62.     Guideline 3.4, \"pages with similar function should have similar\nappearance and layout\"\n\n62.a.    [LOW PRIORITY] But we might note that it's also good for\nseparate sections to be easily distinguishable, which implies not using\nidentical appearance; distinct visual elements such as colors or\ngraphics will help readers orient themselves, keep in mind which section\nthey are in, and avoid mistaking similar pages.\n==\n\nThis guideline was significantly rewritten in the March 11, 2004 Working \nDraft [3] and focuses on organization of content rather than \npresentation.  Also,  Guideline 2.4 [4] has a criterion that we think \naddresses your concern about making separate sections easily \ndistinguishable, \"Different structural elements look or sound different \nfrom each other and from body text.\"  Do you feel these changes address \nyour concerns?\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Nov/0003.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=705\n[3] http://www.w3.org/TR/2004/WD-WCAG20-20040311/#consistent-behavior\n[4] http://www.w3.org/TR/2004/WD-WCAG20-20040311/#navigation-mechanisms\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 70",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 706 [2]\n\nGreg Lowney writes:\n\n63.     Guideline 3.4 \"the content has been reviewed, taking into\naccount.\"\n\n63.a.    [MEDIUM PRIORITY] Isn't there some way that this criterion\ncould be made to have some impact or benefit? I'm afraid that, as it is,\ncriteria phrased this way will just be a checkbox that can be checked\nwithout anyone doing anything! Perhaps, to have some benefit, the web\nsite could post a review of its usability and rationale for their\ndecisions to avoid making improvements. Something? Anything?\n==\n\nThis guideline was significantly rewritten in the March 11, 2004 Working \nDraft [3].  Instead of a list of \"ideas to consider\" we rewrote the list as \ntestable statements.  Do you agree that the latest wording improves the \nimpact of the Guideline?\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Nov/0003.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=706\n[3] http://www.w3.org/TR/2004/WD-WCAG20-20040311/#consistent-behavior\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 59",
            "content": "Hello Juan Luis Lara,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 595 [2]\n\nSIDAR's WCAG2-espa group writes:\n\n4)Guideline 1: Core Checkpoints: 1.3: Example 4\n\nURL:\nhttp://www.w3.org/TR/2003/WD-WCAG20-20030624/#content-structure-separation\n\nExample 4 in this checkpoint should also include a reference to\ncheckpoint 4.3\n==\n\nThis guideline was significantly rewritten in the March 11, 2004 Working \nDraft [3].  The example that you referenced is no longer included so we \nhave not made the cross-reference that you suggested.\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Sep/0009.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=595\n[3] http://www.w3.org/TR/2004/WD-WCAG20-20040311/#content-structure-separation\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 67",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 670 [2]\n\nGreg Lowney writes:\n\n13.     Guideline 1.3 Checkpoint 3 \"Text content is not presented over a\nbackground image or pattern OR the text is easily readable when the page\nis viewed in black and white (no grayscale).\"\n\n13.a.    I think this belongs under 1.6 \"Foreground content is easily\ndifferentiable from background for visual default presentations\" rather\nthan under 1.3.\n==\n\nIn the March 11, 2004 Working Draft we moved the statement to the Guideline \nthat addresses contrast in visual presentations [3].  This was a great \nsuggestion.\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Nov/0003.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=670\n[3] http://www.w3.org/TR/2004/WD-WCAG20-20040311/#visual-contrast\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issues 671 and 67",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 671 [2]\n\nGreg Lowney writes:\n\n14.     Guideline 1.3 \"The markup that creates the columns is separate\nfrom the markup that specifies the logical structure of the document.\"\n\n14.a.    [MEDIUM PRIORITY] I recommend clarifying the meaning of\n\"separate from.\" By this phrase, do you mean to require that the two\ncategories of markup be distinguishable, or that they actually have to\nbe physically separate? If separate, must they be in separate files or\ncan they be in separate sections of the same file? Personally I believe\nthey should only be distinguishable from each other.\n==\n\nIssue 672 [3]\n15.     Guideline 1.3 \"Example 2: a scrolling list of stock prices.\nCurrent stock quotes are scrolled horizontally across the screen. The\ndata are separate from the methods used to scroll the text across the\npage.\"\n\n15.a.    [MEDIUM PRIORITY] So what is the recommended solution in this\ncase? It is not obvious, given that the server probably does not have\nall the quotes at any one time, nor does it necessarily retain values\nafter they are displayed.\n===\n\nThese examples are no longer included in the March 11, 2004 Working Draft \n[4] and thus these issues are closed.\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Nov/0003.html\n[2] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=671\n[3] http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=672\n[4] http://www.w3.org/TR/2004/WD-WCAG20-20040311/#content-structure-separation\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 41",
            "content": "Hello Kynn,\n\nYou made comments on WCAG 2.0 [1].  This email shows how the WCAG WG has \nattempted to address one of your concerns.  We will send a separate email \nfor each of the issues you raised. Please let us know if we have adequately \naddressed your issues.\n\nIssue 414 [2]\n\nKynn Bartlett writes:\nOkay, there's no tool to check for this. Question: Are there documented \nexamples of anyone with photosensitive epilepsy ever getting clobbered by a \nWeb page?If so, can you please point me to them, preferably from a \nreputable source (such as a medical journal) rather than just hearsay?\n===\n\nThis guideline was significantly rewritten in March 11, 2004 Working Draft \n[3] to incorporate data from the ITC Guidance Note for Licensees on \nFlashing Images and Regular Patterns in Television [4].  While we do not \nhave reports of Web content causing seizures in people with PSE, we \ncoordinated with Professor Harding and his group in the expectation that \nWeb content will become more dynamic and that we will see similar issues in \nWeb content that we've seen with television.  Does this address your concerns?\n\nThank you,\n--wendy\n\n[1] \n<http://lists.w3.org/Archives/Public/public-comments-wcag20/2003Aug/0000.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=414>\n[3] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/#flicker>\n[4] \n<http://www.ofcom.org.uk/codes_guidelines/broadcasting/tv/vrs_code_notes/flsh_imgs/?a=87101>\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "Letter from masinka, A.,your response is needed urgent",
            "content": "FROM: \nMR.MASINKA AMEH\nGRAND BANK OF BENIN \nPHONE:871-76-2535865 \nFAX:  871-76-2535866 \nmasinka_ameh01@sify.com\n\nDear Sir, \n\nIn order to transfer out (USD 45 MILLION) Forty Five million United States Dollars) from  GRAND BANK REPUBLIC OF BENIN. I have the courage to ask for your assistance to handle this important and confidential business believing that you will never let me down either now or in future. \nI am MR.MASINKA AMEH, the MANAGER of the bank. There is an account opened in this bank in 1980 and since 1990 nobody has operated on this account again. After going through some old files in the records, I discovered that if I do not remit this money out urgently it will be forfeited for nothing. The owner of this account is Mr. PAULTON ALLENS, a foreigner, and an engineer with  D&D Engineering CO, and he died since 1990. No other person knows about this account or any thing concerning it, the account has no other beneficiary and my investigation proved to me as well that this company does not know anything about this account and the amount involved is (USD 45M)  I want to transfer the [USD45M] Forty Five million United States Dollars into a safe foreigners account abroad , but I don't know any foreigner, I am only contacting you as a foreigner because this money can not be approved to a local bank here, but can only be approved to any foreign account because the money is in us dollars and the former owner of the account is Mr PAULTON ALLENS is a foreigner too. I know that this message will come to you as a surprise as we don't know our selves before,but be sure that it is real and a genuine business. I only got your contact address through the internet,hoping that you will never let me down in this business. I need your urgent reply  so that I will inform you on the next step to take I will like you to Send also your private telephone and fax number including the full details of the account to be used for the deposit.I want us to meet face to face or sign a binding agreement to bind us together so that you can receive this money into a foreign account or any account of your choice where the fund will be safe. I will fly to your country for withdrawal & sharing and other investments. I am contacting you because of the need to involve a foreigner with foreign account and foreign beneficiary. I need your full co-operation to make this work fine because the management is ready to approve this payment to any foreigner who has correct information of this account, which I will give to you later immediately, if you are able and with capability to handle such amount in strict confidence and trust according to my instructions and advice for our mutual benefit because this opportunity will never come again in my life. I need truthful person in this business because I don't want to make mistake I need your strong assurance and trust. With my position now in the office I can transfer this money to any foreigner's reliable account, which you can provide with assurance that this money will be intact pending my physical arrival in your country for sharing. I will destroy all documents of transaction immediately we receive this money leaving no trace to any place. You can also come to discuss with me face to face after which I will make this remittance in your resence and two of us will fly to your country so at least two days ahead of the money going into the ccount. I will apply for annual leave to get visa immediately I hear from you that you are ready to act and receive this fund in your account. I will use my position and influence to effect legal approvals and onward transfer of this money to your account with appropriate clearance forms of the ministries and foreign exchange departments. At the conclusion of this business, you will be given 35% of the total amount, 60% will be for me, while 5% will be for expenses both parties might have incurred during the process of transferring. I look forward to your earliest reply. \n\nTHANKS AND GOD BLESS, \nYOURS SINCERELY,          \nMR.MASINKA AMEH.\n\n\n\n"
        },
        {
            "subject": "Scope of WCAG guideline",
            "content": "L.S.,\n\nIn a discussion in the Dutch web development newsgroup \n<news:nl.internet.www.ontwerp> concerning web accessibility, Yvette P. \nHoitink invited me to share my thoughts with the WCAG group through this \npublic comment.\n\nThe discussion I refer to dealt with the scope of WCAG guidelines. \nYvette pointed out that the role of priority 3 guidelines was subject to \ndiscussion: should they be seen as specifications, be it hard-to-reach, \nor is it better to present them as 'best practices' to inspire web \nauthors and developers to follow?\n\nLet me first emphasize that I see and support the role of the W3C to \nensure that the web will become more accessible to users with physical \nor cognitive disabilities. However, I think there are topics that are \nout of the reach of the W3C. Writing style, grammar, punctuation and \npossibly also glossaries are subjects that extent well beyond the web, \ncovering also print, advertising, television and radio broadcasting.\n\nI would argue that addressing these topics should be left to other \n(national?) authorities. The WCAG guidelines should refer to established \nsources of information if necessary. For instance, concerning writing \nfor the web, the guidelines could very well refer to the Yale Web Style \nGuide (or even writing styleguides from the publishing industry) instead \nof formulating a series of specifications itself. Or, concerning the \nrisks of fast changing dynamic content for epilepsy patients: refer to \nknown information from the television and motion picture industry. \nGuidelines that govern accessibility for television can --generally-- \nvery well be applied to the web.\n\nThe WCAG should focus on issues that are inalienably tied to the nature \nof the web, such as feedforward and feedback in navigation, grouping of \nnavigational elements, alternative accessible content for scripts and \nplug-ins used etcetera. The current guidelines de a good job in this \nrespect, but could use a screening on the focus I described before.\n\nI think this approach would catch two birds in one stroke: the \nguidelines that are issued will be more applicable to the nature of the \nweb, and the W3C would position itself alongside existing authorities \nthat perform the same role for other media, thus emphasizing the place \nthe web should take: it is nothing more than a new medium, that can \nlearn and benefit from insights that are commonplace in adjacent media \n(television, print).\n\nWith kind regards,\n\nJeroen Visser\n\n-- \nvizi fotografie & grafisch ontwerp\n\nI  http://www.vizi.nl\n\n\n\n"
        },
        {
            "subject": "Elihu Eli E",
            "content": "Thursday, April 22, 2004\n\nElihu Eli El\n140 Manor Drive\nBeckley, WV  25801\nPhone: 304-253-6759\neli_el@hotmail.com <mailto:eli_el@hotmail.com>\n\n\nDear Technical Recruiter,\n\n\nDo you require an experienced computer programming looking to fill a position in Engineering, Database Management, Software Development, System Management, Technical Support, Quality Assurance, Testing, Client Support, Programming, or software and hardware installation and support? If so, my many years of experience in the computer industry combined with my formal training and my demonstrated lifelong learning may be just the person and skill set you seek.  I am grateful for this opportunity to formally introduce myself.  Although my name is unique, I am an American citizen by birth.  I am from Kansas City, KS.  I am currently working for a Department of Defense government contractor.  I have an active security clearance of secret.  My goal is to become an active and significant contributor to the field of Software Development and Engineering.  I possess skills in Relational Database Management Systems (RDBMS), GUI development, and object-oriented (classes) programming. I have good presentation and technical oral/written communication skills.  I have exceptional ability to quickly install, configure, and master new software and to apply its full range of features.  I am a hard working person whom maintains a high level of diligence and work ethic.  I am physically fit and in good health.  I am comfortable exercising my body just as I do my mind.  As a Programmer Analyst with your organization, I would bring a focus on quality and efficiency to your group's IT missions and objectives.  Salary is negotiable within the range of $60,000 - $90,000.  I have professional team leadership training.  I have recently completed a professional course in software project management.  My ability to resolve many varied and complex problems, combined with programming skills and outstanding organizational skills, are indicative of my potential as a IT professional with your group.  \n\nI previously held the position of Programmer Analyst with CDM.   This is another DOD contractor.  I have also used Maple to solve and graph Differential Equations. During 1995 through 1996, I worked as a Law Enforcement Officer for The State of Georgia.  I am confident my education, skills, and experience would prove beneficial to your group as well as your clients and would welcome an opportunity to discuss my qualifications with you in person.  I am willing to relocate.  I can be reached at 304-253-6759.  Would you acknowledge that you have received a good copy of this letter and resume?  Thank you for your attention and consideration.\n\n\n\nSincerely,\n\n\nElihu Eli El\nElihu Eli El\n140 Manor Drive; Beckley, WV  25801\nPhone: 304-253-6759\neli_el@hotmail.com <mailto:eli_el@hotmail.com>\nhttp://resumes.yahoo.com/eli72117/c4isrprogrammer\n\n\n\n\n5 years application development and information technology experience.  \n\n\n\n*Proficient in: Visual Basic 6.0, VBScript, and SQL\n*Familiar with: Lisp, Ada, Prolog, Visual C++, ANSI C, FORTRAN, Pascal, ASP, & CICS\n*Databases: Oracle 8i and Microsoft Access\n*Platforms: Windows 2000, Windows 9*, Windows NT 4.0, Unix/Red Hat Linux 5.2, IBM Primos, and VMS\n\nSecurity Clearances\nLevel - Secret: Last updated 16SEP03\n\nEducation\nReturned to college in 1999, completed in 2001: Private Consulting Part-Time\nB.S. in Computer Science, Math minor 2001\nUniversity of Arkansas; Little Rock, Arkansas\n\nProgrammer / Software Test Engineer\nCDI / CSC (www.csc.com), APR03 - Present\nTASKS:  TLDD / JCALS (http://www.pdsm.wpafb.af.mil/jcals/jcals_program_description.htm) Software Test Engineer for CSC (Computer Sciences Corporation).  Practice methodologies and use tools that are in place to support the activities of the Test Group.  Conduct formal tests and participate in procedure development. Execute defined test procedures that are requirements based and user oriented.  Conduct formal tests and participate in procedure development.  Regression and Sanity tests.  Change Requests Management.  Testing the software and system development prior to delivery to the customer.  Test Group is responsible for the System Test Plan (STP), System Test Procedures (STPR), and Product Assurance Validation (PAV).  The STP contains the qualification method or methods for each valid systems requirement.  The STPR contains step-by-step procedures necessary to satisfy the requirements specified for the given test procedures.  The TLDD (Tactical Logistics Data Digitization) project is an initiative that will provide Army equipment operators, mechanics, and supervisors with rapid digital access to improved technical data on the battlefield, in the motor pool, and during institutional training of the war fighter and tactical user.  The primary enabling IT infrastructure components of TLDD consist of PDA's, laptop computers, and a wireless LAN.  VBScripting with Windows 2000 scripting.  Examine each of the test requirements (new features and regression tests) identified in the Function Requirements Description of the Technical Integration Implementation Plan.  TLDD Technical writings include: Program of Instruction (POI), Software User Manuals (SUM), and Lesson Plans.\n\nProgrammer Analyst\nCDM (www.pmcl.com), FEB02 - APR03\nTASKS:  Programmer Analyst with CDM.  Used control and analysis tools to build reports.  My team and I used these reports to perform analysis on schedule related data.  GUI development protected by Visual Source Safe.  Developed applications using Visual Basic 6.0 and Oracle 8i.  The information derived from this data is used to point out our past mistakes and potential problems.  Developed three-tier application based on client / sever model for enterprise.  Used Object Oriented Programming techniques.  Utilized various datagrids to produce results as defined by the client.  Had performed in a developmental role for a United States Department of Defense contractor.  These applications require real-time screen updates, developer tools, and ActiveX controls.  Used Data Manipulation Language during application development to manipulate the information stored in the database with SQL statements.  Declared recordset objects to manipulate the rows of a cursor, view their fields, and update underlining table via DML while navigating through the recordsets.  Datamined using queries involving advanced outer-joins.  This project involved mapping hierarchical recordsets to treeview controls.  Created modularized procedures that were dedicated for error handling.  Changed every event, function, procedure (over 200 in total) to call one consistent and easily amendable error handler.  Feature-driven development requires the use of events, methods, and / or properties of the following: Treeview, MS FlexGrid, StatusBar, Imagelist, Toolbar, ListView, Class Instance Objects, Collection, ImageCombobox, Protoview's Datatable, Key, Mouse, Timer, and others as needed.  Use Oracle Designer for database analysis for historical data conversion. Used embedded ADO code to access Oracle 8i database from within Visual Basic Applications.  I was a team member of Business Intelligence that was tasked to conduct historical data conversion.  This evolves data migration as well as heavy data analysis using Oracle Developer 2000.  Data conversations also involved pl/sql and T-SQL.  Tools such as Toad, SQL Plus, Oracle Designer, and In-housed products were used for this responsibility.  Provided support and enhancements to the U.S. Army Corps of Engineer's Regulatory Information Management System (RIMS).  RIMS is a software development project that is approaching its fourth year of development.  The RIMS system establishes a national standard for data and information requirements within the Regulatory program that can be accessed throughout the entire Corps management hierarchy; particularly by Regulatory project management personnel.  This software application delivers data in a graphical format for review and analysis on the user's desktop.  Thus, users receive U.S. Army Corp of Engineers' information in an easily understandable format for used in day-to-day operations.  Additionally, this component involves development of a Microsoft Visual Basic application using a variety of components and techniques to create a unique and user-friendly application for the Regulatory community. \n\nAdditional Coursework\nAda language as defined by MIL-STD-1815 (A) and by the ANSI MIL-STD-1815A-1983.  \nCSE 480, Introduction to Software Project Management, Air Force Institute of Technology <http://ls.afit.edu/spdp/default.htm>.\n\nCertifications\nUnited States Army Instructor: Granted 15DEC03\nTotal Army Instructor Training Course (TAITC) - Army instructors are skilled at training techniques, which will lead to a more cohesive, mission-capable Army.  <http://pao.hood.army.mil/NCOA/itc.htm>\n\nRecent Conferences\nC4ISR Architecture Conference\nWashington, D.C. USA March 29-30, 2004 \nThis conference was intended for anyone who needs to create, maintain, or review analysis and design models or documents based on the DoD Architecture Framework.\n\nAmong the many critical issues addressed:\n*Step-by-Step Guidelines for Developing and Implementing Executable C4ISR Architectures \n*A Look at What Alternate C4ISR Architecture Representations Exist & What Are Their Uses? \n*Understanding & Implementing the Software Communications Architecture\n*What are the Minimum Required DoDAF Architectural Products?\n*Expert Tips on Developing Practical & Scalable DoDAF-compliant C4ISR Architectures \n*Meeting the Requirements for C4ISR Architecture Support for Interoperability \n*Proven Methods for Defining Useful Information Exchange Requirements \n*Expert Insights on Creating Executable C4ISR Architectures \n*Tools and Techniques for Estimating & Managing the Cost of Architecture Development\n\nComplementary work experience\n1/1990 - 1/2004United States Army ReserveCombat Engineer and Army Instructor\n\n4/98 - 9/98Entergy (www.entergy.com <http://www.entergy.com>)\nL.R., ARInformation Specialist\nTASKS:  Database analysis for regional utility provider.  Provided technical support in database management of potential exposures and application evaluation of Y2K compliance.  Utilized Microsoft Access a primary tool.  Maintained multiple databases aimed specifically at hardware and host application re-development or updating to Y2K compliance.  Navigated within Access.  Added field level error troubleshooting.  Established relations between tables.  Established and maintained referential integrity.  Designed Queries.  Created and used forms.  Used Access with Microsoft Word and mail merge.  Created and executed queries using the expression builder, wizard, as well as user defined SQL.  Made updates and changes to the database (DAO insert, delete, etc.) and properties via VBA.  Printed reports.  Exported to Microsoft Excel.\n\n5/00 - 12/00Sylvan Learning Center (www.sylvanlearningcenter.com <http://www.sylvanlearningcenter.com>)\nL.R., AR Mathematics Instructor\nTASKS:  Mathematics instruction to students in grades 1 through 12.\n\n1997 - 1998First Commercial Bank (www.regions.com <http://www.regions.com>)\nL.R., AR Information Specialist, MS Access\nTASKS:  Database analysis for banking project.  Provided technical support in database management of potential exposures and application evaluation of Y2K compliance.  Utilized Microsoft Access a primary tool.  Communicated, conference, scheduled meetings, etc. through Microsoft Project.  Maintained multiple databases aimed specifically at hardware and host application re-development or updating to Y2K compliance...Please refer to Entergy.\n\n\n\nREFERENCES UPON REQUEST <<ole0.bmp>> \n <<Resume3.doc>> \n\nElihu Eli El\neel@scsnet.csc.com\nTest Engineer\nSoutheastern Regional Operations Center\nCSC / Hinton\n(304)-466-7258\n\n <<Elihu E. El.vcf>> \n\n\n\n\n\n\n\n\napplication/msword attachment: Resume3.doc\n\n\n\n\n"
        },
        {
            "subject": "Clarifications / edit",
            "content": "1. Under paragraph #2 of Priorities and Techniques, there is a  statement that reads:\n\"... but it will link to technology-specific requirements as well as technology-specific\nexamples and techniques (as soon as those documents are more stable).\"\nIs this repetition or am I missing  something here? Perhaps can be reworded to:\n\"but it will link to technology-specific examples and techniques (as soon as those documents are more stable).\"\n2. The term \"Web resource\"  appears in two places in this doc and needs to be defined.  Elsewhere the term Web content is used.\n3. Under Conformance Claims, I am not able to understand  the difference between first and second points. The first  reads:\n\"1. In order to make a valid conformance claim for a Web resource, the resource must satisfy all level 1 success criteria for all guidelines.\"\nIn fact the next point states this in differnt words for level A without using terms like resource or content or Web page.\n4. Refer to:  \"In the physical world, ramps are used by bicycles, people pushing\nstrollers, and people in wheelchairs.\"\nI think the statement can make its point more forcefully if reworded as:\n\"In the physical world, ramps are built (to provide essential access to /) for the benefit of people in wheelchairs   but they also benefit people using bicycles and people pushing strollers\".\n\nSailesh Panchang\nSenior Accessibility Engineer \nDeque Systems,11180  Sunrise Valley Drive, \n4th Floor, Reston VA 20191\nTel: 703-225-0380 Extension 105 \nE-mail: sailesh.panchang@deque.com\nFax: 703-225-0387\n* Look up <http://www.deque.com> *\n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 37",
            "content": "Hello Harvey,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 374 [2]\n\nHarvey Bingham writes:\n1 .3  1. c. any emphasis -- should user preference determine how to \ndistinguish among kinds of emphasis: e.g. by speech pace, voice, volume, or \npitch shift.\n\nShould the user be able to specify these distinctions? One option would be \nto let the user have the choice to enunciate some or all element names in \ntags. That general issue of user learning the distinctions among markup \nwarrants careful consideration. How are header levels differentiated? \nShould the user have the ability to inject personal preferences? [These are \nsuggested later in  Checkpoint 1.5 in the best practices.]\n\nAt a minimum, how does the user learn these distinctions? Should such\nexplanation be included by query for each document (or at least in some \ngeneral guidance for a collection of similar documents -- with a common \nstyle sheet.)  A simple document naming and giving the presentation for \neach distinct  structural form of markup would be a useful aid, that \nprobably should be included with each distinct style-sheet.\n\nIt would need to cover distinctions in list nesting of different kinds.\nAlso of table cell coordinate query and identification vs cell content.\n===\n\nAt our 22 April 2004 telecon [3], the WCAG WG determined this was a User \nAgent issue and have closed issue 374.  Do you agree this was an \nappropriate action or would you prefer WCAG 2.0 to address this in some \nway? If you would like to see a change in WCAG 2.0, please propose specific \nlanguage based on the latest draft [4].\n\nThank you,\n--wendy\n\n[1] <http://lists.w3.org/Archives/Public/w3c-wai-gl/2003JulSep/0287.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=374>\n[3] <http://www.w3.org/WAI/GL/2004/04/22-minutes.html>\n[4] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/>\n\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 46",
            "content": "Hello Tina,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 460 [2]\n\nTina Holmboe writes:\n        The document in itself is singularly lacking in clarity. The\n        language is reminiscent of bureaucratese  and at times\n        nonsensical. After working with accessibility since 1996, I\n        find myself shocked by sentences such as\n         \"These are additional checkpoints that may be reported in addition\n          to Core conformance if the Required Success Criteria for a given\n          Extended Checkpoint are satisfied.\"\n        This is difficult to understand, hard to sell, and very nearly\n        impossible to follow when reviewing material. I am, personally, still\n        not clear on the exact meaning of the above, and would be hard pressed\n        to explain it to people who will decide on whether or not to comply\n        with this standard.\n        The draft must be cleared up, and the language taken to a point\n        where it is actually understandable; less this becomes an exercise\n        in futility.\n===\n\nThe WCAG WG rewrote most of the Guidelines and success criteria in our 11 \nMarch 2004 Working Draft [3].  While the nature of the beast is \nbureaucratic, we hope this draft is easier to follow.  If you are able and \ninterested, we appreciate your feedback on our latest draft.\n\nThank you,\n--wendy\n\n[1] \n<http://lists.w3.org/Archives/Public/public-comments-wcag20/2003Aug/0003.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=460>\n[3] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/#meaning>\n\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 38",
            "content": "Hello Sailesh,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 388 [2]\n\nSailesh Panchang writes:\nIt appears that  there is a shift away from accessibility for PWD to universal\naccess in WCAG 2.0.\nConsider that:\ni. Five WCAG 1.0 checkpoints including 3 P1  map to an extended   WCAG 2 \ncheckpoint 4.2 about declaring  technology/providing alternative content.\nii. WCAG2's  checkpoint 2.4 about navigation mechanisms maps to 13 \ncheckpoints of WCAG 1.0 some of which are P1 and some are P2. Checkpoint \n2.4 of WCAG 2 is categorized as extended and not  core.\niii. On the other hand, checkpoints 4.1 and 4.3 relating to language in WCAG\n1.0 now have become  core under  3.1 of WCAG 2.\n===\n\n11 March 2004 WD we are no longer using the terms \"Core\" and \n\"Extended.\"  With the new organization in the 11 March 2004 Working Draft \n[3], do you still feel that there is a move away from accessibility towards \nuniversal access?\n\nThank you,\n--wendy\n\n[1] \n<http://lists.w3.org/Archives/Public/public-comments-wcag20/2003Aug/0008.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=388>\n[3] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/>\n\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 37",
            "content": "Hello Harvey,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 374 [2]\n\nHarvey Bingham writes:\n1 .3  1. c. any emphasis -- should user preference determine how to \ndistinguish among kinds of emphasis: e.g. by speech pace, voice, volume, or \npitch shift.\n\nShould the user be able to specify these distinctions? One option would be \nto let the user have the choice to enunciate some or all element names in \ntags. That general issue of user learning the distinctions among markup \nwarrants careful consideration. How are header levels differentiated? \nShould the user have the ability to inject personal preferences? [These are \nsuggested later in  Checkpoint 1.5 in the best practices.]\n\nAt a minimum, how does the user learn these distinctions? Should such\nexplanation be included by query for each document (or at least in some \ngeneral guidance for a collection of similar documents -- with a common \nstyle sheet.)  A simple document naming and giving the presentation for \neach distinct  structural form of markup would be a useful aid, that \nprobably should be included with each distinct style-sheet.\n\nIt would need to cover distinctions in list nesting of different kinds.\nAlso of table cell coordinate query and identification vs cell content.\n===\n\nAt our 22 April 2004 telecon [3], the WCAG WG determined this was a User \nAgent issue and have closed issue 374.  Do you agree this was an \nappropriate action or would you prefer WCAG 2.0 to address this in some \nway? If you would like to see a change in WCAG 2.0, please propose specific \nlanguage based on the latest draft [4].\n\nThank you,\n--wendy\n\n[1] <http://lists.w3.org/Archives/Public/w3c-wai-gl/2003JulSep/0287.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=374>\n[3] <http://www.w3.org/WAI/GL/2004/04/22-minutes.html>\n[4] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/>\n\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 38",
            "content": "Wendy,\nThese comments and several others were in connection with  the June 2003 draft of WCAG 2. We have moved further from that point now to the March 2004 draft. I had inter alia, questioned the  appropriateness and use of  terms like core and extended too. I am happy to note that these have been addressed and my comments below are  not valid any more.\nThanks for the feedback.\nSailesh Panchang\nSenior Accessibility Engineer \nDeque Systems,11180  Sunrise Valley Drive, \n4th Floor, Reston VA 20191\nTel: 703-225-0380 Extension 105 \nE-mail: sailesh.panchang@deque.com\nFax: 703-225-0387\n* Look up <http://www.deque.com> *\n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 49",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].\n\nIssue 492 [2]\n\nGreg Gay writes:\n\n2.5 Required criteria for this guideline applies to success feedback as \nwell as error feedback. When a screen reader user for instance, submits  a \nform that performs a particular action, they will often want to verify that \nthe operation was successful. Without success feedback it can be  very time \nconsuming to make this verification.  \"2. after a successful operation , \nprovide the user with confirmation feedback\".\n\nSuccess feedback might have its own guideline (2.6,  though it might fit as \n3.4 (3c)) since it is fundamentally different from error feedback, and \nerror recovery.  However, both error and success feedback could be \nconsider  \"graceful recovery\". We distinguish between error, warning, and \nsuccess feedback in ATutor. Error messages state the problem that occurred \nand provide courses of action. Warnings state that a possible error has \noccurred and provide a means to revert to a previous state our take an \nalternative course of action. Success feedback provides simple confirmation \n(in most cases)\n\nATutor Instructor Demo (see the feedback system as an instructor by \nperforming various tasks such as creating, updating, or deleting content, \nmodifying preferences, posting announcements....)\nhttp://www.atutor.ca/atutor/demo.php\n\nSee \"Learning from Your Mistakes\" for more about fundamental cognitive \ndifferences between error and success feedback\nhttp://www.ldrc.ca/projects/projects.php?id=23\n===\n\nIn response to Issue 496, I wrote [3]:\nThis guideline was significantly rewritten in the March 11, 2004 Working \nDraft [3].  However, the draft does not include anything about success \nfeedback. It is not clear whether the recommendation to include this \nfeedback is something for the guidelines or techniques.  If you feel this \nshould be included as a success criteria, please propose an edit to the \nlatest draft.\n===\n\nCould you look at our latest draft [4] and write a proposed guideline or \nsuccess criterion?  I am happy to help you draft a proposal and am \navailable either by telephone or email, whichever you prefer.\n\nThank you,\n--wendy\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-comments-wcag20/2003Sep/0000.html\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=492>\n[3] \n<http://lists.w3.org/Archives/Public/public-comments-wcag20/2004Apr/0003.html>\n[4] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/>\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 70",
            "content": "Hello Greg,\n\nThank you for your comments on WCAG 2.0 [1].  This email shows how the WCAG \nWG has attempted to address one of your concerns.  We will send a separate \nemail for each of the issues you raised. Please let us know if we have \nadequately addressed your issues.\n\nIssue 700 [2]\n\nGreg Lowney writes:\n54.     Guideline 3.2 \"if contracted forms of words are used such that\nthey are ambiguous, provide semantic markup to make words unique and\ninterpretable\"\n54.a.    [LOW PRIORITY] This guideline is not clear to me. What are\nexamples of ambiguous contracted words?\n54.b.    [COMMENT] If we're going to require markup to disambiguate\ncontractions, why not non-contracted words that have ambiguous meanings?\nOther than the fact that it'd be a lot of work to comply, that is.\n===\n\nIn the March 11, 2004 Working Draft [3], this was reworded to \"The meaning \nof contracted words can be programmatically determined. [I] \"  Does this \naddress the issue?\n\nThank you,\n--wendy\n\n[1] \n<http://lists.w3.org/Archives/Public/public-comments-wcag20/2003Nov/0003.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=700>\n[3] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/#meaning>\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "V2 Guideline",
            "content": "Is anyone taking notice of discussions at WebAim about font sizing and\nincreasing the priority level of this?\n\n\nRegards,\nSteve Roberts\nSenior Technical Specialist, Usability\nTechnology\n\n( +61 3 9208 8042  mobile (0411 402 924)          2  +61 3 9208 8107\n: Steve_Roberts@national.com.au\n\nNational Australia Bank Limited\nFloor 2\n100 Victoria Pde\nEast Melbourne\nVictoria 3002\n\n__________________________________________________________________________\nThe information contained in this email communication may be confidential.\nYou should only disclose, re-transmit, copy, distribute, act in reliance on\nor commercialise the information if you are authorised to do so.  Any views\nexpressed in this email communication are those of the individual sender,\nexcept where the sender specifically states them to be the views of a\nmember of the National Australia Bank Group of companies.  Any advice\ncontained in this e-mail has been prepared without taking into account your\nobjectives, financial situation or needs. Before acting on any advice in\nthis e-mail, National Australia Bank Limited recommends that you consider\nwhether it is appropriate for your circumstances. If this e-mail contains\nreference to any financial products, the National recommends you consider\nthe Product Disclosure Statement (PDS) or other disclosure document  before\nmaking any decisions regarding any products.  The National Australia Bank\nGroup of companies does not represent, warrant or guarantee that the\nintegrity of this communication has been maintained nor that the\ncommunication is free of errors, virus or interference.\n\n\n\n"
        },
        {
            "subject": "older html tags, can be revamped again",
            "content": "hello,\ni,m W. You,\ni have a question :\ni saw in older documents the html tag ISINDEX and i thought maybe \nthis older kind of html tags should be reconsidered after all,maybe they\nare not so useless as it seems they are, or maybe used together with newer html\ntags would help increasing the relevance of an html webpage.\nwhy i'm saying all this?  because people tend to still use  the normal html documents\nthere are smaller quantities of xml  dhtml  document pages on the internet.\nit is interesting to see some examples of older and newer html tags used together\nin a webpage and the relevancy of such a html document compared to a similar one \nin which are used only the accepted html tags.\nbest regards\n \nW. Yuo\n \nhttp://www.netscake.com \n \n\n\n\n---------------------------------\nDo you Yahoo!?\nYahoo! Finance: Get your refund fast by filing online\n\n\n\n"
        },
        {
            "subject": "Thoughts on the coming 'discovery' of Bin Laden: the best propaganda a campaign can bu",
            "content": "FOR IMMEDIATE RELEASE\nContact:\nEric A. Smith\nHot Damn! Design\n81-03-3959-5371\nsnowdog@juno.ocn.ne.jp\n\nOPINION: THOUGHTS ON THE COMING \"DISCOVERY\" OF BIN LADEN \n--The Best Propaganda Money can Buy\n\nUnless preparations are made for its eventuality, the announcement of Bin Laden's capture will be the death-knell for the 2004 Democratic campaign. And, like the \"heroic rescue\" of Jessica Lynch or the toppling of Hussein's statue by \"jubilant throngs\" of Iraqis, it needn't even be real:\n\nhttp://news.bbc.co.uk/1/hi/programmes/correspondent/3028585.stm\nhttp://www.latimes.com/news/printedition/opinion/la-oe-scheer20may20,1,2187120.column\nhttp://www.startribune.com/stories/1762/3907255.html\n\nhttp://www.informationclearinghouse.info/article2838.htm\n \nSo Democrats must have a pre-emptive strategy in place; the most obvious being, early in the game, to accuse the White House of sitting on Bin Laden for political gain. \n\nA better one is to launch an independent investigation to find Bin Laden first and announce the discovery before Rove's political operatives; this would be a huge coup.\n\nIn case you haven't been paying attention, this election year, Republicans are playing a deadly game of attrition -- death by a thousand tiny cuts, so to speak: extreme gerrymandering in Texas, the recall of a governor in California, the installation of inauditable, easily \"preprogrammed\" DRE e-vote machines in as many counties as will allow them to be stuffed down their throats, relentless and bloody character assassinations in a bought-and-paid-for Murdoch-dominated media empire, absentee ballots counted by an untouchable firm in Kuwait, stacked courts ready to deliver decisions for which 2000's Gore vs. Bush set the precedent.\n\nThe odds look dire for Democrats (and, by extension, the majority of Americans, though they are as yet blissfully unaware of the slender thread from which all our liberties hang). \n\nBut, in case you haven't connected the dots, this time the GOP is playing for keeps. \n\nOnce the fix is in, there will be no turning back: by an invisible, carefully planned coup, the neoconservatives will have transformed America into an autocracy, and any remaining political opposition will be window dressing.\n\nAnd so, I challenge you: this is a battle we perhaps cannot win, but, at all costs, MUST NOT LOSE.\n\nThe consequences of surrender will be incalculable: one by one, like dominos, institutions we cherish will fall -- environmental laws, social security, independent media, healthy advocacy groups, assistance for the unemployed, impoverished and disenfranchised  -- and, foremost, the right to choose our leaders.\n\nWe will be left with one remaining liberty: the right to choose which products to buy to keep the militaristic money machine well-oiled, and its minders well-heeled.\n\nThis year, unless YOU act -- BOLDLY, DECISIVELY, PERSISTENTLY AND INCESSANTLY -- the dream our forefathers nurtured to life will die.\n\nDon't let the dream die.\n\nStand up and fight for America.\n\nStand up and fight for the vote.\n\nThis will be your last chance.\n\nsincerely,\nEric A. Smith\nTokyo\n\nAbout the author:\n\nEric A. Smith is a freelance journalist, editor and IT instructor living in Tokyo, Japan. An activist for over 25 years, he has worked with such diverse publications as the RTP Beacon, Common Ground and Adbusters magazine. \n\nSmith is currently volunteering to assist Bev Harris of Blackboxvoting.org, Attorney Philip Berg in 9-11 widow Ellen Mariani's RICO suit against Bush, et al, and is a charter member of the Open Voting Consortium.\n\nSmith earned his BA at the University of North Carolina in 1992, and holds MCP, field service technician, A+ and Network+ certifications from Microsoft, COMPTIA and the Control Data Institute.\n\nHe can be reached for comment at 81-03-3959-5371 or snowdog@juno.ocn.ne.jp\n\n\n\n"
        },
        {
            "subject": "Please Join My Superb Yahoo Forums",
            "content": "Greetings,\n\nI'm posting you to ask that you take the time to join two of the GREATEST FORUMS IN THE HISTORY OF CYBERSPACE!!\n\nThe first list is an information and discussion list called \"\n\nhttp://groups.yahoo.com/group/TheBigPicture2003/?yguid=132698554 \" We are a\n\nlittle over 2,790 strong now and growing rapidly daily.\n\nOur focus there is discussing the GREAT issues in life that confuse and perplex most human beings. We give them answers on how to see the BIG PICTURE in life and live a much more richer and fulfilling life style.\n\nWe are looking for things that we can do to make sure that our mental\nhealth and self esteem remains high while we struggle to clear the cobwebs and misprogramming from our minds. and change this most unequitable system. We also promote networking between honest, ethical, law abiding business people.\n\nThe second list you should peruse is named :\n\"http://groups.yahoo.com/group/NBCOCEPPLSI/ \"\n\nPlease pass the word around about these highly informative lists. Everyone is\nwelcome to join.\n\nThank you very much for taking the time to look over this information. I\nlook forward to getting to know you on the above lists.\n \nBe careful! Strive to be happy. Despite all of the sham, trickery, lies, drudgery, and broken dreams, America is still a beautiful place to live!\n\nShlala Gashle!\n\nWS\n\nAS SEEN ON TV!\n\nLegal Coverage is a force... mightier than gravity!\n\nInnovative services for individuals, families, and businesses\n\nBuild for the future!  Securely protected by us!\n\nGet access to top LAWFIRMS across North America for less than a cup of coffee per day!\n\nhttp://www.wtatours.com\n\nThe National black Chamber of Commerce said on November 24, 2003 that ths information available at \n this website directly below is the best way for young African Americans\nto get off to a great LEGAL, start financially at a YOUNG age.\nThey said that PPLSI is the #1 best inexpensive Biz Op today in America for African Americans.\n\nhttp://www.wtatours.net\n\n-------------------------------------------------------------------------------------------------------------------------\nwww.wtatours.org\nwww.babyboomerboogie.com\n\nCheck  out  companies at this URL to make sure they are legitimate:\nwww.ftc.gov\nwww.betterbusinessbureau.com\n\n\n\n"
        },
        {
            "subject": "Your Ship Has Come In! This Time You Are Not At The Airport",
            "content": "I'm posting you to ask that you take the time to join two of the GREATEST FORUMS IN THE HISTORY OF CYBERSPACE!!\n\nThe first list is an information and discussion list called \"\n\nhttp://groups.com/TheBigPicture2003/?yguid=132698554 \" \n\nWe are a  little over 2,800 strong now and growing rapidly.\n\nOur focus there is discussing the GREAT issues in life that confuse and perplex most human beings. We give them answers on how to see the BIG PICTURE in life and live a much more richer and fulfilling life style; both FINANCIALLY AND SPIRITUALLY.\n\nWe are looking for things that we can do to make sure that your mental\nhealth and self esteem remain high while you struggle to clear the cobwebs and misprogramming from your minds. \nWe  promote networking between honest, ethical, law abiding business people.\n\nThe second list you should peruse is named :\n\"http://groups.com/NBCOCEPPLSI/ \"\n\n\nBe careful! Strive to be happy. Despite all of the sham, trickery, lies, drudgery, and broken dreams, America is still a beautiful place to live!\n\n\n\n\nSupport Our Troops\nGOD BLESS AMERICA!! \n\n\nHonor our troops both here and abroad. Thank YOU! for keeping us all safe?\n\n\n\n\nPhone Solution!\n\n\n\nGet More From The Broadband You?re Already Paying For. . .\n\nIs Your Telephone Bill Out of Hand?\n\nAre you tired of sitting through confusing monthly billing\n\nstatements from various service providers that include\n\nlots of little charges for this feature, that call,\n\netc.? Can you call your friends and family for free and\n\ntalk as long as you like? for just $19.95 per month?\n\nCan You Choose the Calling Features That You Want?\n\nCan you change, add or delete features on your current\n\nphone service with the click of a mouse? Can you select\n\nyour own area code to better suit your calling patterns?\n\nCan you take your home phone with you wherever\n\nyou go?\n\nI s It Time to Take Charge of Your Phone Service?\n\nCan you add additional phone lines quickly and easily\n\nas you need them, without having to waste time on service\n\ncalls? Can you rely on one service provider to address\n\nall of your telephone needs?\n\n8 - Maximize Your Broadband\n\nPacket8 uses your existing broadband Internet connection\n\ncombined with our unique communications technologies\n\nto provide a new and exciting telephone service.\n\nExpand your broadband connection to be more\n\nthan just Internet access. With Packet8 your computer,\n\ntelephone and high-speed Internet connection finally\n\ncome together to form a powerful communication tool.\n\nOnce your account has been set-up, you will receive everything\n\nyou need to start using your Packet8 telephone\n\nservice. Plus in your phone. Start making and receiving\n\ncalls. It?s that simple.\n\nSign-Up Today! Total up-front investment only $29.90\n\nwith Telebay Rep Coupon Code ? includes first month?s\n\nservice, activation fee & equipment.\n\nContact Telebay Rep:\n\nPh:\n\nwww.Telebay.com/7777\n\nEnter Coupon Code below for $20 Off Activation:\n\nTelebay-8 ? The All-in-One\n\nOpportunities Available!\n\nWill Smith\n\nwill_smith_1@charter.net\n\n\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nTHIS SHOULD BE A ONE TIME MAILING ONLY. YOU HAVEN'T BEEN SUBSCRIBED TO ANYTHING. \n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nSIGNATURE\n\nAS SEEN ON THE RADIO!\n\nGet ACCESS to top LAWFIRMS across North America for less than a cup of coffee per day!\n\nwww.wtatours.com\n\nThe NBCOC said on November 24, 2003 that ths information available at \n this website directly below is the best way for young PEOPLE\nto get off to a great LEGAL, start financially at a YOUNG age.\n\nThey said that PPLSI is the #1 best inexpensive Biz Op today in America for .\nJOBS pay your bills! Running your own business will make you rich! Need I say more...? :-)\n\nwww.wtatours.net\n\n-------------------------------------------------------------------------------------------------------------------------\nSignature\n\nFIRE YOUR TELEPHONE COMPANY!!!\n\nDSL/CABLE users get unlimited local and long distance throughout USA/CANADA\nfor $19.95 a month. Using your normal telephones/GREAT SIGNAL!!\nUnlimited Europe and Asia for $30.00 a month more\n\nHumans in Europe and Asia can also SIGN UPutilize these incredible plans.\n\nBUSINESS PLANS AVAILABLE ALSO. We are a NASDAQ COMPANY\n\nYou can start your own business with Telebay FREE from any country in the world where we offer service.\nThose of you in low income countries can make a great living with us. As can those in high income countries\nlike the USA, Canada, Europe, and Asia.\n\nYou should be 17 years or older.\n\nwww.telebay.com/7777\n\n   \n \nSign-Up Page for Z-LineHOME Customers:\n\nhttps://purchase.z-tel.com/portal/ztel/purchase/i/ZTelLandingPage.jsp?id=88857010000&repID=7777&noMenu=true  \n\nTelebay Opportunity Page: \nhttp://www.telebay.com/7777/opp.html \n\nSign-Up as Telebay Independent Rep Page: \nhttp://www.telebay.com/cgi-bin/plexum.pl?page=signup&id=7777 \n      \nZ-LineHOME Only:  \nhttp://www.telebay.com/7777/zhome.html  \n      \nZ-LineBUSINESS SIMPLICITY:  \nhttp://www.telebay.com/7777/zbiz.html  \n    \nTelebayISP Page: \nhttp://www.telebay.com/7777/isp.html \n    \nPacket8 Page: \nhttp://www.telebay.com/7777/bbphone.html \n     \nCellular Page: \nhttp://www.telebay.com/7777/cell.html \n \n --------------------------------------------------------------------------------------------------------------------------------------\nExcellent Health Care Savings Plans from $34.95 to $109.95 a month\nSave hundreds of dollars a month on health care costs.\nMost anyone can market this FREE opportunity.\n\nwww.babyboomerboogie.com\n\nCheck  our  companies at this URL if you question their legitimacy:\nwww.ftc.gov\nwww.betterbusinessbureau.com\n\n\n\n"
        },
        {
            "subject": "FW_Employees Reveng",
            "content": "Ha-ha, brilliant! \n\nI?ve tried this for the last three days, worked perfectly and got my ?50 worth every time.\n\nDo you know any overworked, underpaid friends or colleagues? Give them this story to warm their hearts. \n\n\n-----Original Message-----\nFrom: Nick Roberts [mailto:nickroberts@hotpop.com] \nSent: 16 January 2004 11:26\nTo: Belinda [mailto: bumblebee@myrealbox.com]\nSubject: Employees revenge\n\n\nHi,\n\nOnce upon a time there was a hard-working software engineer slaving away under cruel masters. The engineer poured heart and soul into his work till early hours every morning, with the promise of glorious profit sharing. When the work was finally done, this poor engineer was rewarded by being dismissed and shown the door.\n\nThe company I used to work for runs a website:-  www.gamesofskill.co.uk. However after I had left, they went live with the system, WITH THE TESTING BACKDOOR STILL IN PLACE !!!!! If you call their competition line and enter \"0\" instead of a real answer, then the system lets you through to win the Question of the day. Idiots!\n\nMoral of this story? Don?t p*ss off employees, especially one?s you fire! \n\nViva the workers! Down with the bosses! Share the wealth!\n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 35",
            "content": "Hello Kynn,\n\nThank you for your comments on WCAG 2.0 [1].  This email describes how the \nWCAG WG has attempted to address one of your concerns.  We will send a \nseparate email for each of the issues you raised. Please let us know if we \nhave adequately addressed your issues.\n\nIssue 357 [2]\n\nKynn Bartlett writes:\nrganizational: There is a lot of \"legalese\" at the beginning,\nand that might be a good place for \"skip to table of contents\" links.\n===\n\nIn our latest internal Working Draft [3] we link to the Table of Contents \nfrom the top of the document.  Does this close the issue?\n\nThank you,\n--wendy\n\n[1] \n<http://lists.w3.org/Archives/Public/public-comments-wcag20/2003Aug/0000.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=357>\n[3] <http://www.w3.org/WAI/GL/WCAG20/WD-WCAG20-20040602.html>\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "WCAG 2.0 comments: Issue 40",
            "content": "Hello Kynn,\n\nThank you for your comments on WCAG 2.0 [1].  (you're familiar with the \nopening blurb now... :)\n\nIssue 401 [2]\n\nKynn Bartlett writes:\n\nKynn Bartlett writes:\nI tried mentally diagramming the sentence that comprises checkpoint 1.1 and \nit wasn't easy. I think this checkpoint has been overworked and needs to be \nstated simply and clearly. Note that this particular way of phrasing the \ncheckpoint text makes it really impersonal. Compare to:\n\nIf you use content which is not simply textual, include a text equivalent \nfor the parts of that non-text content which can be expressed in words. The \ntext equivalent should convey the same function or meaning as the non-text \ncontent.\n\nThis is an extreme example -- from one style (\"W3C clinical\" to \"Kynn \nchatty\") -- but it is meant to illustrate how a checkpoint can be rewritten \nto be understandable.\n\n===\n\nGuideline 1.1 has been significantly rewritten. It's not \"Kynn chatty\" and \nstill fairly \"W3C clinical\" but is it easier to mentally diagram? Does this \nclose the issue?\n\nThank you,\n--wendy\n\n[1] \n<http://lists.w3.org/Archives/Public/public-comments-wcag20/2003Aug/0000.html>\n[2] <http://trace.wisc.edu/bugzilla_wcag/show_bug.cgi?id=401>\n[3] <http://www.w3.org/TR/2004/WD-WCAG20-20040311/#text-equiv>\n\n-- wendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/--  \n\n\n\n"
        },
        {
            "subject": "A few comment",
            "content": "Hi,\n\nI have read the draft an few thiings come to mind:\n\nGuideline 1.1: I agree but I would make it a bit stronger and a the same time\ngive clear rules how to do it (this can rely on guideline 3.2):\nALT text must be used, but are the ALT texts helpful? Do they mean anything.\nThis makes a difference between the wording of the rule and the meaning of it.\n\nA lot of websites provide ALT texts, but in my opinion these ALT texts are\nwrong.\n\nProvide an ALT texts with content when the non-text element serves a purpose,\nif not make teh ALT text empty (as for 1 pixel graphics). A website read by\nassistive technology should not repeatedly say the same thing (like\n'decoration' because the page has 10 elements only there to please the eye). An\ngood description can be found at http://ppewww.ph.gla.ac.\nuk/~flavell/alt/alt-text.html \"The use of ALT texts in IMGS\"\n\nGuideline 1.4 contrast - Level 2 is intended to provide a quantitative\nguideline. A lot of people with disabilities do not use any assistive\ntechnologies (even not magnifiers) and therefor they are expecting a high\ncontrast. The ISO norm 9241 states a factor 3, other publications put 7-10\n(publication towards usage of screens - like the  guideline form US\ntarnsportation)\n\nI did not find anything about the size of text (perhaps I've missed it)- text\nshould always be enlargeable (everyone can bebefit form this). So absolute\nmeasurements for fonts should not be used.\n\nMy 2c,\n\n\nRik Manhaeve\nBelgium\n\n\n\n"
        },
        {
            "subject": "David Duke is a malignant narcissist",
            "content": "David Duke is a malignant narcissist.\n\nHe invents and then projects a false, fictitious, self for the world to \nfear, or to admire. He maintains a tenuous grasp on reality to start with \nand the trappings of power further exacerbate this. Real life authority and \nDavid Duke?s predilection to surround him with obsequious sycophants support \nDavid Duke?s grandiose self-delusions and fantasies of omnipotence and \nomniscience.\nDavid Duke's personality is so precariously balanced that he cannot tolerate \neven a hint of criticism and disagreement. Most narcissists are paranoid and \nsuffer from ideas of reference (the delusion that they are being mocked or \ndiscussed when they are not). Thus, narcissists often regard themselves as \n\"victims of persecution\".\nDuke fosters and encourages a personality cult with all the hallmarks of an \ninstitutional religion: priesthood, rites, rituals, temples, worship, \ncatechism, and mythology. The leader is this religion's ascetic saint. He \nmonastically denies himself earthly pleasures (or so he claims) in order to \nbe able to dedicate himself fully to his calling.\nDuke is a monstrously inverted Jesus, sacrificing his life and denying \nhimself so that his people - or humanity at large - should benefit. By \nsurpassing and suppressing his humanity, Duke became a distorted version of \nNietzsche's \"superman\".\nBut being a-human or super-human also means being a-sexual and a-moral.\nIn this restricted sense, narcissistic leaders are post-modernist and moral \nrelativists. They project to the masses an androgynous figure and enhance it \nby engendering the adoration of nudity and all things \"natural\" - or by \nstrongly repressing these feelings. But what they refer to, as \"nature\" is \nnot natural at all.\nDuke invariably proffers an aesthetic of decadence and evil carefully \norchestrated and artificial - though it is not perceived this way by him or \nby his followers. Narcissistic leadership is about reproduced copies, not \nabout originals. It is about the manipulation of symbols - not about \nveritable atavism or true conservatism.\nIn short: narcissistic leadership is about theatre, not about life. To enjoy \nthe spectacle (and be subsumed by it), the leader demands the suspension of \njudgment, depersonalization, and de-realization. Catharsis is tantamount, in \nthis narcissistic dramaturgy, to self-annulment.\nNarcissism is nihilistic not only operationally, or ideologically. Its very \nlanguage and narratives are nihilistic. Narcissism is conspicuous nihilism - \nand the cult's leader serves as a role model, annihilating the Man, only to \nre-appear as a pre-ordained and irresistible force of nature.\nNarcissistic leadership often poses as a rebellion against the \"old ways\" - \nagainst the hegemonic culture, the upper classes, the established religions, \nthe superpowers, the corrupt order. Narcissistic movements are puerile, a \nreaction to narcissistic injuries inflicted upon David Duke like (and rather \npsychopathic) toddler nation-state, or group, or upon the leader.\nMinorities or \"others\" - often arbitrarily selected - constitute a perfect, \neasily identifiable, embodiment of all that is \"wrong\". They are accused of \nbeing old, they are eerily disembodied, they are cosmopolitan, they are part \nof the establishment, they are \"decadent\", they are hated on religious and \nsocio-economic grounds, or because of their race, sexual orientation, origin \n... They are different, they are narcissistic (feel and act as morally \nsuperior), they are everywhere, they are defenseless, they are credulous, \nthey are adaptable (and thus can be co-opted to collaborate in their own \ndestruction). They are the perfect hate figure. Narcissists thrive on hatred \nand pathological envy.\nThis is precisely the source of the fascination with Hitler, diagnosed by \nErich Fromm - together with Stalin - as a malignant narcissist. He was an \ninverted human. His unconscious was his conscious. He acted out our most \nrepressed drives, fantasies, and wishes. He provides us with a glimpse of \nthe horrors that lie beneath the veneer, the barbarians at our personal \ngates, and what it was like before we invented civilization. Hitler forced \nus all through a time warp and many did not emerge. He was not the devil. He \nwas one of us. He was what Arendt aptly called the banality of evil. Just an \nordinary, mentally disturbed, failure, a member of a mentally disturbed and \nfailing nation, who lived through disturbed and failing times. He was the \nperfect mirror, a channel, a voice, and the very depth of our souls.\nDuke prefers the sparkle and glamour of well-orchestrated illusions to the \ntedium and method of real accomplishments. His reign is all smoke and \nmirrors, devoid of substances, consisting of mere appearances and mass \ndelusions. In the aftermath of his regime - Duke having died, been deposed, \nor voted out of office - it all unravels. The tireless and constant \nprestidigitation ceases and the entire edifice crumbles. What looked like an \neconomic miracle turns out to have been a fraud-laced bubble. Loosely held \nempires disintegrate. Laboriously assembled business conglomerates go to \npieces. \"Earth shattering\" and \"revolutionary\" scientific discoveries and \ntheories are discredited. Social experiments end in mayhem.\nIt is important to understand that the use of violence must be ego-syntonic. \nIt must accord with the self-image of David Duke. It must abet and sustain \nhis grandiose fantasies and feed his sense of entitlement. It must conform \nDavid Duke like narrative. Thus, David Duke who regards himself as the \nbenefactor of the poor, a member of the common folk, the representative of \nthe disenfranchised, the champion of the dispossessed against the corrupt \nelite - is highly unlikely to use violence at first. The pacific mask \ncrumbles when David Duke has become convinced that the very people he \npurported to speak for, his constituency, his grassroots fans, and the prime \nsources of his narcissistic supply - have turned against him. At first, in a \ndesperate effort to maintain the fiction underlying his chaotic personality, \nDavid Duke strives to explain away the sudden reversal of sentiment. \"The \npeople are being duped by (the media, big industry, the military, the elite, \netc.)\", \"they don't really know what they are doing\", \"following a rude \nawakening, they will revert to form\", etc. When these flimsy attempts to \npatch a tattered personal mythology fail, David Duke becomes injured. \nNarcissistic injury inevitably leads to narcissistic rage and to a \nterrifying display of unbridled aggression. The pent-up frustration and hurt \ntranslate into devaluation. That which was previously idealized - is now \ndiscarded with contempt and hatred. This primitive defense mechanism is \ncalled \"splitting\". To David Duke, things and people are either entirely bad \n(evil) or entirely good. He projects onto others his own shortcomings and \nnegative emotions, thus becoming a totally good object. Duke is likely to \njustify the butchering of his own people by claiming that they intended to \nkill him, undo the revolution, devastate the economy, or the country, etc. \nThe \"small people\", the \"rank and file\", and the \"loyal soldiers\" of David \nDuke - his flock, his nation, and his employees - they pay the price. The \ndisillusionment and disenchantment are agonizing. The process of \nreconstruction, of rising from the ashes, of overcoming the trauma of having \nbeen deceived, exploited and manipulated - is drawn-out. It is difficult to \ntrust again, to have faith, to love, to be led, to collaborate. Feelings of \nshame and guilt engulf the erstwhile followers of David Duke. This is his \nsole legacy: a massive post-traumatic stress disorder.\n\n_________________________________________________________________\nStore more e-mails with MSN Hotmail Extra Storage ? 4 plans to choose from! \nhttp://click.atdmt.com/AVE/go/onm00200362ave/direct/01/\n\n\n\n"
        },
        {
            "subject": "123 Find A Web Designer Specia",
            "content": "Dear New Directory Member,\n\nWe want to apologize for the email yesterday.  There was a technical glitch and the purchase button wasn't working when the email went out! \nSince we believe in this campaign and believe it is a great value to your company, we are going to offer you the opportunity to sign up today!\nAs a reminder...many of our categories now have 50-60 entries so for a limited time, we are going to offer our GOLD TEXT AD for only $20 a year!  For only $20 your ad could be placed at the top of the free listings and look like this:\nGOLD TEXT AD LINK DESIGN\nThis is what your business ad would look like listed as a Gold Text Ad.  \nhttp://www.goldtextad.com\n\nAlso, if you are one of the first five companies to purchase a Gold Ad, then you will receive a Gold Text Ad in another category for FREE!  This offer expires on March 31, 2004 so you better hurry!\n\n \n\n Five different Banner Ad positions placed at the top of each category. \nPrices start at only $50 per year! \n\n Larger text link, highlighted in gold and placed at top of all free text links.\nOnly $25 per year!\n\n \nPlace your business ad in multiple categories for only $10 per year! \n\n\n\n\n  \n \nIf you have received this email and would like to be removed from future mailings, please reply to this email and type \"remove\" in the subject.\n\n\n\n"
        },
        {
            "subject": "2004 and they finaly have accessable content - nope  just another dream..",
            "content": "Subject: 2004 and they finaly have accessable content - nope - just another dream...\n\n\nThe entry points to sites displaying the wc3 logo are many and varied but main access to the public is gained through the url portals of http://act.gov.au or http://www.canberraconnect.act.gov.au.  They (ACT Government) also market them selves to be a portal which provides access to these documents displaying the new content ratings like http://www.legislation.act.gov.au for example.\n\nThe tag for the site of http://www.act.gov.au/index.jsp is :\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n\nThe tag for the site of http://www.canberraconnect.act.gov.au is :\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n<html xml:lang=\"en-AU\" lang=\"en-AU\">\n\nThe tag for the site of http://www.legislation.act.gov.au is (the only site to conform to wc3 A content rating with a html page and little use of C++ programming like java) :\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n\nCan you please make all sites/subdomains (two above) that provide access these pages with the A rating of wc3 do conform to the content standards as access is gained via them.  The use of wc3 logo's is not tollerated in this way and infact causes users to think sites connected together under the one portal would conform when infact they do not - the two offending portals make use of graphics so one is to belive a wc3 logo that does not apprear would be because of other factors.  I do not mind links showing a page is written to a standard but detest the way of which the Australian Governments' are using the logo's with sites that contain broken links, no automated email replys, and the list goes on and on.\n\nThe ACT government use subdomains to host content like http://www.legislation.act.gov.au displaying the A rating.  The fact is that the domain holder does not endorce the same standard, and thus how is one meant to access such clean pristene content via the garbage dump?  I do however hold in high regards the adimistrators that do ensure a standard is adopted accross web pages that they control - its a shame that the actual government its self is so waistfull with the money it gets.\n\nMy many thanks.\nRegards,\nJason Robinson\n\n\n\n--------------------------------------------------------------------------------\n\nConsidering you (HRO) made statements in regards to web service provisions - Could you now also provide information as to why no standard was kept too for the web site LA Legal Aid ACT created in 2001.  I have noted some sites now have these logo's and I would like to thank them for ensuring the provison of accessible content.  However the portal that provides access to such content does not adhear to the same standards.  Any government site without this compliance is to be removed ASAP because your own guidelines state you must provide such access by the start 2001/2003.\n\nThis also continues into your use of email systems - Please provide an automated responce to all requests with alternate actions, and comply with the standards of web pages if sent as such.  This includes the AFP as a not delivered message is not acceptable.\n\nMany wonderfull thanks again for spending all that money.\nRegards,\nJason Robinson\n\n\n--------------------------------------------------------------------------------\n\nLevel A Conformance to Web Content Accessibility Guidelines 1.0 \n \n\nPages bearing this logo indicate a claim of conformance by the page author or content provider to conformance Level A of the W3C Web Content Accessibility Guidelines 1.0, including all Priority 1 checkpoints defined in the Guidelines. The Web Content Accessibility Guidelines 1.0 explain how to make Web content accessible to people with disabilities. Conformance to these Guidelines will help make the Web more accessible to users with disabilities and will benefit all users. \n\nClaims are not verified by W3C. Content providers are solely responsible for the use of these logos. \n\nHow to use this logo at your site. \n\n\n\n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "accessibilit",
            "content": "I am starting to design a site that I want to make very accessible. I \nhave several questions that also reflect my difficulty in comprehending \nyour presentation in these matters.\n\n1. I understand that pop-up browser windows can be disorienting, \nparticularly for the sight impaired. I am wondering if PDF documents \nwhich open in a separate \"window\" cause the same disorientation? Is \nthere any recommended work around for making PDF documents user \nfriendly for screen reading technology and the sight impaired? In \nparticular, I am concerned about the ease of changing from the HTML \ndocument to the PDF file and back.\n\n2. Could you provide several examples of tables are set up clearly for \nthe sight impaired? I would like to see several examples of how one \ngroups columns and rows logically. How do you associate table cells and \ntheir headers?\n\n3. If a site has a top horizontal menu and a left-side vertical list of \nlinks and a right-side vertical list of links, do I need to create a \ntab index and what is the best approach? Is there some way that I \nshould or could be assisting the sight-impaired visitor to scan all the \nmenu choices before choosing? In the code only, can it be noted that \nthere are three menus on each page...? Can you show me an example of \nthis?\n\n4. If I want to ask further questions on this order, where is a good \nplace to turn for no-cost and expert advise or feedback?\n\nThank you for your consideration.\nPamela\n\n\n\n"
        },
        {
            "subject": "10&ndash;year&ndash;old boy prisoner of Guantanamo Bay &ndash;&ndash; found innocent after two years of detainmen",
            "content": "http://www.thenation.com/outrage/index.mhtml?pid=1313\n(hyperlinks also follow story.)\n\nYou're kidding, right? That's it?\n\nAfter holding Brits in our extralegal dungeons for two years, one day we\njust let 'em go?\n\nWe've still got more than 600 people imprisoned in our Halliburton-built\nprison camp at Guantanamo Bay, Cuba, where for more than two years we've\nbeen interrogating them, denying them lawyers, denying them any kind of\njudicial review, hinting quite bluntly that they could all remain in limbo\nlike this forever, and trying to put a brave face on all of the suicide\nattempts.\n\nAnd every now and then, without comment, we bundle a few of them onto\ninternational flights and dump them out on a street somewhere -- and\nsuddenly it turns out that this dangerous menace was just a bewildered Kabul\ntaxi driver, or a 10-year-old.\n\nWhat the heck is that about?\n\nI mean, if the argument is that these people are too horrifically dangerous\nto ever risk granting them access to the American judicial system, how can\nyou just up and cut them loose?\n\nAnd if they're not dangerous -- well, how can you hold a man in a Kafkaesque\njail for two years, slapping him around, denying him sleep, asking him\nrandomly desperate (and therefore asinine) questions like \" Do you know\nMullah Omar?\"; and then one day open the door, shake his hand and wave\ngoodbye, without even the slightest blush of shame, the most sheepish of\napologies?\n\nOne of the first of five Britons released this week from Gitmo was one Jamal\nal Harith of Manchester, a website designer and a father of three.\n\n\"After a while, we stopped asking for human rights -- we wanted animal\nrights,\" Harith told Britain's Daily Mirror. \"In Camp X-Ray my cage was\nright next to a kennel housing an Alsatian dog. He had a wooden house with\nair conditioning and green grass to exercise on.\n\n\"I said to the guards, 'I want his rights' and they replied, \"That dog is a\nmember of the US army'.\"\n\nThis man, Harith, wasn't held but a few hours by British police and security\nservices before they had shrugged and let him go free. There's no case,\napparently.\n\nAnd now, of course, these and other detainees are gearing up to sue the\npants off of the United States government. Chalk it up as one more bill that\nthe Bush-Cheney team will leave us to pay for long after they're gone.\n\n\n\nhttp://news.independent.co.uk/uk/legal/story.jsp?story=500033\n\nhttp://news.bbc.co.uk/1/hi/world/americas/3034697.stm\n\nhttp://sf.indymedia.org/news/2004/02/1678473.php\n\nhttp://www.ncccusa.org/news/04march8guantanamostory.html\n\nhttp://www.afghanmania.com/en/news/0,news,2738,00.php\n\nhttp://www.thenation.com/outrage/index.mhtml?pid=1305\n\nhttp://news.scotsman.com/latest.cfm?id=2639432\n\nhttp://www.reuters.co.uk/newsPackageArticle.jhtml?type=topNews&storyID=47437\n1&section=news\n\nhttp://news.scotsman.com/international.cfm?id=283942004\n\n\n\n"
        },
        {
            "subject": "Suggestion for this Editorial Not",
            "content": "Editorial Note: We are looking for a word to replace \"page\" that applies across technologies. For visual applications, \"screen\" would apply, but would not apply for speech-based technologies such as VoiceXML.\n\nHow about 'media'\n\nPrint media\nPaper media\nScreen media\nVoice/Speech media\n\n\n\n"
        },
        {
            "subject": "Development of platform-independent applications - workshop more info pl",
            "content": "hello i have received this message from w3c.org and i need more info pls\nabout position papers and if possible a small resume about what will\nbe talking then as it seems to be very interesting.\n \nquote:\n===========\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\nunquote\n==========\nbrgds\nmike\nhttp://www.directvreceiver.com \n\n\n\n---------------------------------\nDo you Yahoo!?\nWin a $20,000 Career Makeover at Yahoo! HotJobs \n\n\n\n"
        },
        {
            "subject": "Re: WCAG 2.0 comments: Issue 49",
            "content": "I'll address issues 492 and 496 together, since they are closely \nrelated, and they both seem to fit into Guideline 3.2.\n\nI think the first statement in \"Who benefits from Guideline 3.2\" covers \nthe issue of success feedback in a general sense, though the statement \nmight be adjusted to include reference to situations where no feedback \nis provided.\n\n\"Providing consistent and predictable responses to user actions is \nimportant feedback for users. This lets them know that your site is \nworking properly and encourages them to continue interacting with the \ncontent. When users receive an unexpected response, [ or receive no \nresponse,] they might conclude that something is wrong or broken. Some \npeople might become so confused they will not be able to use your site.\"\n\nAn additional example for guideline 3.2 might be included to describe \nfeedback:\n\n\"Example 4: Provide feedback when a form is submitted, or an action has \nbeen taken, to indicate the outcome. Outcome feedback might include \nsuccess feedback to indicate that the submission or action was \nsuccessful, warning feedback to indicate that potential  errors  may be \npresent or that a decision must be made, and error feedback to indicate \nthat the submission or action has failed and describe why it has failed \nand a course of action if appropriate.\"\n\nThe success criteria at level 2 in guideline 3.2 might reflect feedback \n\"after\" an extreme change, rather than exclusively \"before\" a change.\n\n5. Explicit notice is given in advance of any extreme change of context.\n\nshould read\n\n5. Explicit notice is given of any extreme change of context.\n\nThe primary reason for including success feedback with this guideline is \nto improve usability, more so than accessibility. It comes out of \nexperience using a number of the commercial elearning systems. In most \ncases when users submit a form to add instructional content, or perhaps \npost a forum message, for example, they are required to navigate through \nthe outcome page, or sometimes retrace their path,  to confirm that the \nsubmission was successful. In most systems error messages are used well \nif something goes wrong, but in virtually all cases no success feedback \nis provided, making it difficult for some users to verify the success of \na submission without considerable effort. In each of these cases an \nextreme change occurs after an action has been taken, and warning users \nof such changes before they occur is often impractical (e.g. informing a \nuser before taking an action that \"when this form is submitted you will \nbe redirected back to the forum message list\" -- as opposed to feedback \nafter the change that states \"Your message was posted successfully. You \nmay review it below\" )\n\nIn relation to issue 496 regarding informing users \"before\" an extreme \nchange, success feedback (or other feedback) will appear after an \nextreme change to indicate an outcome. The same strategy could apply to \nthe popup window issue, indicating after the window has opened that an \nextreme change has occurred. We often use such a strategy by including a \nscripted \"close window\" link as the first feature in a popup window. For \ndesign reasons this is our preferred method of indicating new windows, \nreducing clutter on pages where stating  \"opens in a new window\" \ndisrupts the visual appearance or the flow of information on a page.\n\nThe second example for guideline 3.2 might be adjusted to state before \nor after an action indicate that a change will occur, or has occurred:\n\n\"Example 2: a user is informed that a popup window *will* open, with a \nstatement such as \"link opens in a new window\", or that a popup window \n*has* opened, with a statement/function such as \"close window\" as one of \nthe first features in the new window.\n\nThe \"close window\" strategy is now fairly common practice, and most \nusers will understand implicitly that it means a new window has opened, \nor will quickly learn the implicit meaning if they have not previously \nencounter the statement. \n\n\ngreg\n\nWendy A Chisholm wrote:\n\n> Hello Greg,\n>\n> Thank you for your comments on WCAG 2.0 [1].\n>\n> Issue 492 [2]\n>\n> Greg Gay writes:\n>\n> 2.5 Required criteria for this guideline applies to success feedback \n> as well as error feedback. When a screen reader user for instance, \n> submits  a form that performs a particular action, they will often \n> want to verify that the operation was successful. Without success \n> feedback it can be  very time consuming to make this verification.  \n> \"2. after a successful operation , provide the user with confirmation \n> feedback\".\n>\n> Success feedback might have its own guideline (2.6,  though it might \n> fit as 3.4 (3c)) since it is fundamentally different from error \n> feedback, and error recovery.  However, both error and success \n> feedback could be consider  \"graceful recovery\". We distinguish \n> between error, warning, and success feedback in ATutor. Error messages \n> state the problem that occurred and provide courses of action. \n> Warnings state that a possible error has occurred and provide a means \n> to revert to a previous state our take an alternative course of \n> action. Success feedback provides simple confirmation (in most cases)\n>\n> ATutor Instructor Demo (see the feedback system as an instructor by \n> performing various tasks such as creating, updating, or deleting \n> content, modifying preferences, posting announcements....)\n> http://www.atutor.ca/atutor/demo.php\n>\n> See \"Learning from Your Mistakes\" for more about fundamental cognitive \n> differences between error and success feedback\n> http://www.ldrc.ca/projects/projects.php?id=23\n> ===\n>\n> In response to Issue 496, I wrote [3]:\n> This guideline was significantly rewritten in the March 11, 2004 \n> Working Draft [3].  However, the draft does not include anything about \n> success feedback. It is not clear whether the recommendation to \n> include this feedback is something for the guidelines or techniques.  \n> If you feel this should be included as a success criteria, please \n> propose an edit to the latest draft.\n> ===\n>\n> Could you look at our latest draft [4] and write a proposed guideline \n> or success criterion?  I am happy to help you draft a proposal and am \n> available either by telephone or email, whichever you prefer.\n>\n> Thank you,\n> --wendy\n>\n>\nAppended:\nIssue 496 [2]\n\nGreg Gay writes:\n\n3.4 An extreme change can be identified after the change has occurred,\nsuch as a \"close new window\" link as the first feature of a popup\nwindow, or presenting a feedback message after server side redirecting a\nuser from the content editing screen to the content display screen when\nediting is completed (feedback like \"content was successfully updated\"\nsee guideline 2.5 above).\n\nguideline should read \"..., but not necessarily identical\".\n\nThis guideline was significantly rewritten in the March 11, 2004 Working \nDraft [3].  However, the draft does not include anything about success \nfeedback. It is not clear whether the recommendation to include this \nfeedback is something for the guidelines or techniques.\n\n\n\n"
        },
        {
            "subject": "Collection of Comments from Ab",
            "content": "This set of comments were collected during the discussions about\nthe WCAG 2.0 Working Draft by the AbI-Project (Aktionsbuendnis f?r \nbarrierefreie Informationstechnik)\n\nCOMMENTS ON WCAG 2.0 OF 2004-03-11\nAktionsb?ndnis f?r barrierefreie Informationstechnik, Germany\nVersion 3, 2004-05-07, Gottfried Zimmermann, Christian B?hler, Frank Reins\n\nGeneral Comments\n----------------\n(1) We assume that WCAG 2.0 will not be released within the next 12 \nmonths.  In Germany there are currently legislative efforts under way, \nto (a) revise the technical accessibility standard on the federal level, \nand (b) to issue technical accessibility standards on the state and \nmunicipal levels.  Given this situation we strongly encourage the WCAG \ngroup to release a WCAG 1.1 version that has the same structure as WCAG \n1.0 but without some deprecated requirements and (optionally) a few new \ncheckpoints.  Ideally WCAG 1.1 should be released within the next 6 months.\n(2) We welcome the structure of the WCAG 2.0 document with the four \nbasic principles.\n(3) We regret that the old priority levels of WCAG 1.0 have been \nabandoned.  We under stand, however, that there were issues regarding \ntestability of checkpoints.  In general, for the sake of backward \ncompatibility in the German legacy, we would like to see the WCAG 1.0 A- \nand AA-checkpoints covered by WCAG 2.0 level 1&2 criteria, and the WCAG \n1.0 AA-checkpoints covered by WCAG 2.0 level 3 criteria.\n(4) We see the need a mapping document which describes the migration for \nWCAG 1.0 to WCAG 2.0 in detail this document should be available \ntogether with the release of WCAG 2.0:\n* new additional (stronger) requirements\n* deprecated (weaker) requirements based on the level of priorities / \nlevels.\n(5) For some success criteria in WCAG 2.0, it is not specified whether \nthe responsibility is with the Web designer or the user agent developer. \n  This should be made very clear, and necessary harmonization with UAAG \nis required.  Examples:\n* 2.2.2.1: The user is allowed to turn off content that blinks for more \nthan 3 seconds.\n* 2.2.2.2: The user is allowed to pause and/or permanently stop moving \nor timebased content. In the past we have seen user agents, which did \nnot fulfil UAAG requirements. Hence, WCAG 2.0 shall not transfer \nresponsibility to UAAG if the issue can be solved within WCAG \nrequirements. The Problem is that in many countries including Germany \nonly WCAG is adapted by legislation.\n(6) Techniques documents will be consulted by Web developers more than \nWCAG 2.0 itself. Therefore, and because the German regulation is likely \nto adopt them in some form, they should be W3C recommendations rather \nthan informal documents. Furthermore, if the techniques documents are \ninformal only, a Web designer would have the choice between applying a \nspecific technique proposed by the techniques document, or to come up \nwith their own solution based on their interpretation of the WCAG 2.0 \ndocument. This would impose a test problem and interoperability problem \nwith AT.\n(7) Tables are not adequately accommodated in WCAG 2.0.  It is our \nunderstanding that tables are not techniques-specific.\n* 1.3.1.1: Should have the explicit requirement for marking of row and \ncolumn headers in tables, either in guideline 1.3 or guideline 2.4.  Cf. \nWCAG 1.0 checkpoint 5.1.\n* 2.4.3.1: No explicit mentioning of (layout) tables required to be \nlinearized.  Should be added to WCAG 2.0.  Cf. WCAG 1.0 checkpoint 5.3.\n* Summaries for data tables should be explicitly required.  Cf. WCAG 1.0 \ncheckpoint 5.5.\n(8) WCAG 2.0 has no success criteria regarding the contrast in images \n(or \"non-text content\"), only for text (guideline 1.4).  This could be a \nproblem for images containing text - the author could claim that \ncontrast is no issue because it is an image (it is \"non-text content\" \nper definition in the glossary of WCAG 2.0).\n(9) We ask for clarification for WCAG 1.0 checkpoint, which begin with \n\"until user agents support ...\" are those Checkpoints seen as deprecated \nnow or how are they covered in WCAG 2.0. This pertains to 10.2, 10.3, \n10.4, 10.5 and also 1.5\n\nOther Requests for Change - Details\n-----------------------------------\n(10) 4.2.1.1 & 4.2.1.2: Typo: Should say \"(a) through (i)\", not \"(a) \nthrough (j)\".\n(11) 4.2.3.2 should be level 1 or 2.\n(12) 2.2.2.1: Should apply to all blinking content, not only for content \nthat blinks more than 3 seconds.  Could open up a backdoor, if content \nblinks for 3 seconds, then stops blinking for the next 3 seconds, then \nblinking again for 3 seconds...\n(13) 3.2.3.5 should be level 2.  Cf. WCAG 1.0 checkpoint 10.1 Until user \nagents allow users to turn off spawned windows, do not cause pop-ups or \nother windows to appear and do not change the current window without \ninforming the user.\n(14) 2.4.3.4d should be \"applied\", not only \"considered\".  Should be \nlevel 1.\n(15) 2.4.3.4c should be \"applied\", not only \"considered\".  Should be \nlevel 2.\n(16) 3.2.3.1 should be promoted to level 2.  Is there any technical \nreason why this would not be possible?\n(17) The concept of metadata describing resources should be included in \nWCAG 2.0.  Cf. WCAG 1.0 checkpoint 13.2 Provide metadata to add semantic \ninformation to pages and sites.\n(18) 2.4.2.2: \"Navigation bar\" should be added to the list of \"site \nnavigation mechanisms\" in the glossary.  Cf. WCAG 1.0 checkpoint 13.5 \nProvide navigation bars to highlight and give access to the navigation \nmechanism.\n(19) No specific criterion about search function in WCAG 2.0.  Should be \nadded.  Cf. WCAG 1.0 checkpoint 13.7 If search functions are provided, \nenable different types of searches for different skill levels and \npreferences.\n\nQuestions for Clarification\n---------------------------\n(20) 4.2.1.1: Why \"at least one plug-in\"? Shouldn't it apply to all \nplug-ins required?  Are we missing anything here?\n(21) 1.4.2.1 & 1.4.3.1: What is meant by \". or the resource provides a \nmechanism.\". Does it mean that the responsibility shifts from the author \nto the user agent?\n(22) 1.4.3.1: Should be dropped for clarification: \".or the resource \nprovides a mechanism to allow the text to meet this criterion\"?\n(23) 2.4.2.1: Feedback: Is this meant to apply to the \"default \npresentation mode\"?  How can the author make sure it looks or sounds \ndifferent if the user uses their own style sheet?\n(24) 3.1.3.2: Should be harmonized with UAAG.\n(25) 4.2.3.2: \". can still access the resource\": not clear whether it is \nthe same page or could be an alternative page.\n(26) 2.2.2.1: What determines whether the \"user is allowed to turn off \ncontent.\"?\n(27) 2.2.2.2: What determines whether the \"user is allowed to pause.\"?\n(28) 2.2.1.1: What determines whether the \"user is allowed to.\"?  The \nexample in WCAG 2.0 implies that the user must be able to control \nautomatic refresh through a mechanism provided by the author through Web \ncontent.\n(29) From 2.2.3.1 and 2.2.3.2 we conclude: On level 3, essential \ntime-outs (e.g. automatic refreshs, automatic redirects) are only \nallowed if they can be controlled by the user.  Is this\ncorrect?  If yes, what determines whether they can be \npostponed/suppressed by the user?\n(30) 2.1.1.1: Access keys (keyboard shortcuts) could be automatically \nassigned by the user agent, to avoid platform-specific conflicts.  Is \nthis right?\n(31) 2.4.3.4: We are assuming that by \"each page or resource that can be \naccessed inde-pendently\" frames are included.  Is this correct?\n(32) Is 3.2.3.3 meant to apply to a \"default presentation mode\" \n(otherwise conflict with 3.2.3.4)?  If yes, this should be added to the \nwording of the criterion.\n(33) We would like to have 3.2.3.3 a level-2 criterion.  This is \nprobably not possible because of its implications for testability.  Is \nthis correct?\n(34) 2.5.2.2: What exactly is \"and can be provided without jeopardizing \nsecurity\"?\n(35) The following WCAG 1.0 checkpoint should be included in WCAG 2.0:\n5.6 Provide abbreviations for header labels.\n(36) We need a specific criterion for skipping over ASCII art in WCAG \n2.0.  Cf. WCAG 1.0 checkpoint 13.10 Provide a means to skip over \nmulti-line ASCII art.\n\nExpectations for the evolving HTML Techniques Document\n------------------------------------------------------\n(37) We expect that the specific operability issue of server-side image \nmaps will be dealt with in the HTML techniques document.  Cf. WCAG 1.0 \ncheckpoint 1.2.\n(38) Make sure WCAG 1.0 checkpoint 6.1 will have an equivalent in the \nWCAG 2.0 HTML Techniques document.\n6.1 Organize documents so they may be read without style sheets. For \nexample, when an HTML document is rendered without associated style \nsheets, it must still be possible to read the document.\n(39) We expect that the requirement for frames to have unique titles and \ndescriptions will be covered in the HTML techniques document.  Cf. WCAG \n1.0 checkpoints:\n* 12.1 Title each frame to facilitate frame identification and navigation.\n* 12.2 Describe the purpose of frames and how frames relate to each \nother if it is\nnot obvious by frame titles alone.\n\nNote:\n-----\nOur comments are based on our own mapping document between WCAG 1.0 AA \nand WCAG 2.0 Level 2. This document can be made available on request\n\n\n\n"
        },
        {
            "subject": "Feedback on WCAG 2.",
            "content": "List of errors, comments, and suggestions ordered by draft section. \nPlease let me know if I can present this in a form more-easily-digested \nthan plain text. Replying to my main email (listed on my site) will get \nquicker response than this account used for the public WAI-IG list.\n\nThanks,\nJames Craig\n<http://cookiecrook.com/>\n\n---\n\nStatus of this Doc section, second para. Guidelines spelled \"guielines.\"\n\nIntroduction, Section 3. Is this where Wendy wanted to use the examples \nfrom the AIR training materials?\n\nConformance Claims, Editorial Notes, bulleted list. Is the \"claim\" of \nconformance really this big a deal? Is the \"+\" enough of an incentive \nfor some? Have you had requests for this? I think the claim of A+ and \nAA+ are fine, but A+n is getting out of hand. Just my two cents.\n\nGuideline 1.1, Level 3 Success Criteria... I thought of some good \nexamples for this. Full description of a fine art piece could even \ninclude explanation of artist's intention or emotion; something that may \nnot even be obvious to non-disabled users. Also, check out the Goats \ncomic strip: <http://www.goats.com/archive/?info=on>. The markup is not \naccessible, but the would-be data table does a great job of explaining \nthe individual panels. Given accessible markup, it would be a great \nexample of this checkpoint.\n\nGuideline 1.1, Example 1... Agent-specific description here: \"by adding \nthe word link or changing the synthesizer's voice.\" This should be \nchanged to something like, \"a method determined by the user agent.\"\n\nGuideline 1.1, Example 5... This could also include a longer description \nthat explained the score, or perhaps an MML file.\n\nGuideline 1.2, Level 1 Success Criteria, item 4... Erroneous line break \nhere just before \"real-time\" noticed in print version. Might be a fluke \nor strange print media style. Can't seem to reproduce it now.\n\nGuideline 1.2, Example 3... Why wouldn't a synchronized \"descriptive \naudio\" track be required for a silent animation?\n\nGuideline 1.3, Level 1 Success Criteria, item 1a... fourth bullet \nlabeled \"associations between table cells and their headers\" should \nprobably explicitly state \"data table cells.\" I realize that this is \nonly legitimate use for a table cell, but for legacy's sake, I think the \nextra detail will help and can't hurt.\n\nGuideline 1.3, Examples, Editorial note... How are these HTML-specific? \nIs seems that tables and forms are pretty standard in non-HTML forms, too.\n\nGuideline 1.3, Example 2... This one needs some rephrasing using the \n\"simplest language appropriate.\" (grin)\n\nGuideline 1.5, Who Benefits... Would recommend adding \"or other \nbackground sounds\" to the end of this sentence. This applies to more \nthan just \"music.\"\n\nGuideline 2.1, Level 1 Success Criteria... Why is the middle clause in \nthere? Could this sentence just be, \"All of the functionality of the \ncontent is operable through a keyboard or keyboard interface.\"? Also, \nthe following list of three \"notes\" should be an ordered list (lower \nalpha) to remain consistent with rest of document.\n\nGuideline 2.1, Level 2 Success Criteria... Could this give examples of \n\"more abstract\" event handlers or a table comparing some?\n\nGuideline 2.1, Example 2, first bullet... The parenthesized portion is \nredundant and should be removed.\n\nGuideline 2.2, Level 1 Success Criteria, Number 1, second bullet... How \nwas the \"at least ten times\" decided?\n\nGuideline 2.2, Examples, bullet 1.4... Typo: \"after\" spelled \"ater.\"\n\nGuideline 2.4, Level 2 Success Criteria, Number 1... \"look or sound \ndifferent\" regulates design style. This may not be the realm of WCAG. \nGiven the HTML example, do different structural elements like an h4 and \na table caption /need/ to \"look\" different? What about acronym and abbr? \nThis should not be required in all cases. Perhaps this could be \nrephrased to \"sufficiently different for perception as needed.\"\n\nGuideline 2.4, Level 3 Success Criteria, Numbers 1 and 2... Can examples \nbe provided for these two? I'm not sure what is being requested.\n\nGuideline 2.4, Level 3 Success Criteria, Number 3, Editorial Note... \nTestable by a script or human? Is this a matter of opinion what \nconstitutes logical?\n\nGuideline 2.4, Level 3 Success Criteria, Number 4e... Can example be \nprovided?\n\nGuideline 2.4, Example 2... How would this scalable image of a bicycle \nbe spoken through a reader?\n\nGuideline 2.4, Example 5... \"different, more formal voice\" should be \nleft up to the user agent or content author to decide what style is \nappropriate. Perhaps this could be rephrased \"discernibly different style.\"\n\nGuideline 2.4, Level 2 Success Criteria, Number 2... Why does a Level 2 \ncriterion require a Level 1 criterion be met. Shouldn't it also require \nLevel 2?\n\nGuideline 3.1, Level 2 Success Criteria, Numbers 2 and 3... How can \npronunciations and idioms be programmatically determined? Do you have an \nexample or is there another standard to research?\n\nGuideline 3.1, Level 3 Success Criteria, Number 2... Does context not \ncount to determine the meaning of the word?\n\nGuideline 3.1, Editorial Note... All of these bullet points should be \ncomplete sentences, not clauses. For example, bullet 1.1 should be \n\"Organize\" not \"Organizing.\" This problem goes all the way through the \nend of the editor's note and occurs occasionally throughout the \ndocument. Search for \"ing\"...\n\nGuideline 3.1, Editorial Note, In general, bullet 2...\"Using a style \nmanual\" should probably be \"Using a writing style manual,\" as the word \n\"style\" has several implied meanings in this WCAG document. Perhaps \nsuggest titles such as \"The Elements of Style\" by Strunk and White or \n\"The Chicago Manual of Style.\"\n\nGuideline 3.1, Editorial Note, Vocab, bullet 1.3... Typo: erroneous \ncomma after \"languages.\"\n\nGuideline 3.1, Editorial Note, Syntax, bullet 2... \"bulleted or \nnumbered\" list here implies style. This should be \"order or unordered \nlists\" or perhaps just \"lists.\"\n\nGuideline 3.1, Editorial Note, Nouns/pronouns, bullet 1... \"Use single \nnouns or short noun phrases.\" What? Where? Surely this isn't appropriate \nall the time.\n\nGuideline 3.1, Editorial Note, Nouns/pronouns, bullet 2... Period \nmissing at end of sentence. Also, \"example\" should be capitalized.\n\nGuideline 3.1, Editorial Note, Verbs... If this bullet is missing \ncontent, should it be removed?\n\nGuideline 3.1, Editorial Note, Tenses, bullet 1, second sentence... The \nopening parenthesis should be after \"in the first sentence\" not before it.\n\nGuideline 3.1, Editorial Note, Logic and relationships... This whole \nsection seems unnecessary.\n\nGuideline 3.1, bullet 7... \"Sounds, graphics, videos and animations\" \nshould have a comma after \"videos\" to remain consistent with rest of \ndocument and with published writing style guidelines.\n\nGuideline 3.1, Example 1... As far as I know, W3C should be marked as an \nabbreviation, not an acronym. Also, pronunciation should be left to the \nuser agent or author styles. Most real acronyms *should* be pronounced \nas words: such as ZIP, AIR, or NATO. Other abbreviations, such as W3C, \nHTML, Thurs., FedEx, and even etc. should sometimes be spoken as \nletters, sometimes be spoken as real words, and sometimes the \nabbreviations should be fully expanded.\n\nGuideline 3.1, Examples, suggestion for number 8... What about various \ninterpretations of the word \"design\": graphic, software, electrical, \nproject, interior, etc. Lexical ambiguity comes up all the time.\n\nGuideline 3.2, Editorial Note... For replacement of the word \"page,\" how \nabout \"document\" or \"resource?\"\n\nGuideline 3.2, Level 2 Success Criteria, number 1... Does \"in the same \nsequence\" account for sub-level navigation that can change? For example, \ndepending on a site's current section, there may be an expanded sub-nav:\n\n  * Home\n  * Products\n  * About us\n\nIn the \"products\" section, this could change to:\n\n  * Home\n  * Products\n    * Software\n    * Hardware\n  * About us\n\nCurrently the wording does not seem to account for this.\n\nGuideline 3.2, Level 3 Success Criteria, number 4... Can an example be \nprovided?\n\nGuideline 4.1, Level 1 Success Criteria, number 1... This rule allows \nslop tag-soup. Even backwards-compatible sites can use older DTDs. \nViolations of specifications should not be encouraged or condoned.\n\nGuideline 4.1, Level 3 Success Criteria... This ought to be Level 2 \nSuccess Criteria.\n\nGuideline 4.1, Example 2... \"elements designed for applying stylistic \nand presentational characteristics\"? Like font and bold tags? No. This \nshould should be rephrased \"elements devoid of semantic meaning\" like \nspan. Check out arguments against this on Matt May's site and my own site:\n\nhttp://www.bestkungfu.com/archive/?id=471\nhttp://cookiecrook.com/2004/05/#cc108387135135169014\n\nGuideline 4.2... How is the term \"user interfaces\" used here different \nfrom any other web content? A UI is part of the web content and should \ntherefore be held to the same rules as any other web content, right?\n\nGuideline 4.2, Who Benefits, bullet 1.1... This seems like, \"Those who \ndo this will have an easier time doing this.\" Is this redundant?\n\nGuideline 4.2, Example 2... Why encourage duality? Separate but equal? \nNot likely.\n\nGlossary, functionality... I don't agree with the wording of the first \nsentence. Functionality is not the purpose, but how the purpose is achieved.\n\nGlossary, marked in way that the user can access prior to its \nappearance, bullet 3... What is meant by \"provocative\" information? What \nexactly would that information provoke?\n\nGlossary, non-text content... images used as list bullets should count \nas style, not content, right? Also, is there an example of \"any text \nthat cannot be translated into Unicode?\"\n\nGlossary, technology... List not conforming to published writing style \nguides. First items should have commas, last item should have a period, \nand \"or\" should be after second bullet. Also, \"application\" should be \ncapitalized.\n\nA technology is a\n  * markup or programming language,\n  * Application Programming Interface (API), or\n  * communication protocol.\n\nGlossary, time-dependent presentation... Erroneous capitalization on the \nword, \"or\" after first bullet.\n\nAppendix C, first bulleted list... Should contain the word \"and\" after \nthe second-to-last bullet. Sentence leading up to that list is awkward. \nPerhaps the phrase, \"when it eventually becomes a W3C Recommendation\" \nshould be removed.\n\nAppendix C, first numbered list... Commas after all of these phrases, \nperiod on the last one, and the word \"and\" at the end of item 5.\n\nAppendix C (and throughout document)... Look at the lists in Appendix C. \nThere is no reason (apparent to me) why one is a bulleted list and the \nother is a numbered list. This same list inconsistency is demonstrated \nthroughout the document.\n\n\n\n"
        },
        {
            "subject": "Berg video exposed as a frau",
            "content": "Terrorist mastermind Zarqawi has announced his name but hidden his face. The CIA has said it is indeed Zarqawi, but he appears to be reading his own speech from a paper.\n\nThe person holding the knife -- allegedly Zarqawi -- has a Black hood at the video's beginning, but there is an edit (the camera time signatures change) and the knifeholder is then wearing a WHITE hood (and no bulletproof vest).\n\nYou'll also find the following oddities in the heavily edited video, which was heavily edited, presumably in a lab or on a pc:\n\nWM-----|-----Video Clock-----|-----Screen Shot\n0:00 ---|--- nothing ---|-------Arabic letters\n0:05 ---|--- 13:26:24 ---|--- Nick Berg speaking\n0:09 ---|---- 2:18:33 ---|--- Nick Berg sitting\n0:20 ---|---- 2:40:33 ---|--- Speech in Arabic\n4:36 ---|---- 2:44:56 ---|--- Speaker pushes Berg over\n4:38 ---|--- 13:45:48 ---|--- Decapitation begins\n4:43 ---|--- 13:45:52 ---|--- Picture lost\n4:44 ---|--- 13:45:59 ---|--- Picture returns, decapitation continues\n\nSo, if we are to assume the timestamps of the two (?) cameras are accurate, this means Berg was beheaded at 13:47:49 (1:47) but at 2:44, nearly an hour later, he is sitting with his head intact.\n\nZarqawi has also been reported to have an artificial leg; this is definitely not apparent in the video. Nor is his Jordanian accent, according to experts. Also note the gold ring on the \"sinister\" (toilet-using) hand -- a definite no-no for muslims.\n\nThen there's US consulate Beth A. Payne's emails to Berg's family saying their son was in \"US military custody\" for 13 days:\nhttp://www.usatoday.com/news/world/iraq/2004-05-13-emails-text_x.htm\n\nApril 1, 1:26 a.m. (To Michael Berg, Berg's father) \nI have confirmed that your son, Nick, is being detained by the U.S. military in Mosul. He is safe. He was picked up approximately one week ago. We will try to obtain additional information regarding his detention and a contact person you can communicate with directly. \n\nApril 1, 5:23 a.m. (To Suzanne Berg, Berg's mother) \nI have been able to confirm that your son is being detained by the U.S. military. I am attempting to identify a person with the U.S. military or FBI here in Iraq who you can contact directly with your questions. \n\nAnd, according to CNN, Berg himself had contacted a friend -- Chilean reporter Hugo Infante -- saying he was in US custody:\nhttp://www.cnn.com/2004/WORLD/meast/05/13/berg.friends/\n\nThe US Administration denies this, saying he was in Mosul Iraqi police custody, BUT \"...police chief Maj. Gen. Mohammed Khair al-Barhawi in Mosul insisted his department had never arrested Berg and said he had no knowledge of the case.  ''The Iraqi police never arrested the slain American,'' al-Barhawi told reporters. ''Take it from me ... that such reports are baseless.'' \nhttp://www.signonsandiego.com/news/world/iraq/20040513-1057-iraq-berg.html\n\nAnd of course there are the American orange prisoner jumpsuit and white plastic chair and yellow walls which appear in the video -- exactly as they do at Abu Ghraib, the now-notorious site of the American torture of Iraqi POWs:\nhttp://marc.perkel.com/images/berg-chair.jpg\nhttp://marc.perkel.com/images/babe-chair.jpg\nhttp://marc.perkel.com/images/prison01.jpg\nhttp://marc.perkel.com/images/orangegarb.jpg\n\nNext, the hosting website was reported to be in Malaysia, but was discovered to actually located in London:\n\nSays Jackblood.com, which ran a trace:\n\"...www.al-asnar.net and www.al-asnar.biz have apparently been disabled by 'authorities.' ...the publishers for these sites are located in London, England and Nurnberg, Denmark. \n\n\"The addresses began to disappear from the internet listings as we reported this development on The Power Hour Radio Show. Apparently, \"Big Brother\"; had been listening to the show and didn't like the news at all. The location of the publishers for al-ansar.net appears to be at an Arab Press Building, which appears to be shared by different Arab newspublications. The name of the organization is the Arab Press House. Thebuilding is apparently the headquarters for news magazines such as, AlJamilla, Sayidaty, and Al Majallah among others. \n\nThe London address is the following: \nhttp://www.al-ansar.net \nArab Press House \nAbdel Rahman al-Rashed \n184 High Holborn, WCIV78P, London \ntel. 020 78318181 \n\nThe other address is located in Nurnberg, Denmark. It apparently belongs to a man named Omar AbuOmar. His email address is:alansar_alansar@hotmail.com . \n\nThe complete mailing address is the following: \nhttp://www.al-ansar.biz \nOmar AbuOmar \nNew Dream St. 33 \nNurnberg, Denmark, 42114 \nPhone: +965.15441211 \nEmail: alansar_alansar@hotmail.com \n\n....these same websites (www.al-asnar.net and www.al-asnar.biz) were the ones that posted the latest Bin Laden audio recording, weeks ago. Despite knowing the website addresses, and potentially the addresses of their respective publishers, the CIA, the FBI, and the Department of Homeland Security did not make any apparent efforts to monitor the websites for uploaded files or internet traffic. Therefore, no arrests were made.\" \n\nNext, the AK-47 carried by one of the men is a \"Gilal\" -- an Israeli weapon that improves on the AK- 47. Feyadeen and other insurgents almost universally use AK-47s. The man in the left of the video is standing in the American military stance known as \"parade rest\", and several of the apparent terrorists are wearing white tennis shoes ad bulletproof vests.\n\nAt frame 13:46:27, there is an edit and a person with a white ear and a green cap is seen entering from the right. Then the video is re-edited.\n\nMatt Drudge reports that \"The statement in the video was signed off with Zarqawi's name and dated 11 May\" , but Berg's body was reported found on May 10th -- the day before the video was apparently made!\n\nPay attention. This one is definitely a setup. \n\nMore details here:\nhttp://www.libertyforum.org/showflat.php?Cat=&Board=news_international&Number=1471708&view=collapsed&sb=5&o=21%E2%88%82=1\n\n\n\n"
        },
        {
            "subject": "WWAAC Project Recommendation",
            "content": "Dear all,\n\nThe WWAAC project (World Wide Augmentative and Alternative\nCommunication) focuses on guidelines for a World Wide Web that is more\naccessible by people with complex communication needs who use graphic\nsymbol-based augmentative and alternative communication (AAC) - see\nwww.wwaac.org. \n\nThe project has now completed its recommendations and you can find the\nwhole report (with the appendices as a separate document) at:\nhttp://www.wwaac.org/products/Docs/AAC_WebGuidelines.pdf\nand\nhttp://www.wwaac.org/products/Docs/AAC_WebGuidelines_Appendices.pdf\n\nYou will find the most relevant sections for WCAG are: Executive\nSummary, Section 6 (Issues in developing guidelines), Section 7 (WWAAC\nRecommendations for WCAG 2.0), and Conclusions.  \n\nIn summary - A number of issues were discussed with experts within and\noutside the consortium: whether to have one site for all or two\nalternative sites, the conflicting needs of users, simplicity of\ncontent, summaries of content, top loading, tagging images, navigation\nmechanisms, and search engines. Discussions on these issues have helped\nto form a basis for guideline development and have led to the following\nrecommendations, with rationale based on the WWAAC project's user\nrequirements and evaluation work.  These recommendations are proposed as\nsuccess criteria, examples and strategies to be included in the W3C Web\nAccessibility Initiative's (WAI) draft Web Content Accessibility\nGuidelines (WCAG 2.0):\n\nRecommendation 1:  Provide a clear representational image on the site's\nhome page. \n\nRecommendation 2:  Alt tags should provide prime information for the\nuser, and should distinguish between salient (most prominent) and\nnon-salient content.\n\nRecommendation 3:  Provide simple page descriptions as metadata.\n\nRecommendation 4:  Add clear in-page link such as 'Skip-to-content' near\nthe top of the page (as some Web developers already do).\n\nRecommendation 5:  Consider the number, location and focus of links on a\npage.\n\nRecommendation 6:  Provide a progressive complexity for both site and\npage content, so that people with different abilities may be able to\nobtain information from the same Web site.\n\nRecommendation 7:  Use static, rather than dynamic, content for critical\nparts of the Web site.\n\nRecommendation 8:  Consider a change of priorities in the Web Content\nAccessibility Guidelines to reflect the findings of the Disability\nRights Commission report (2004).\n\n\nWe hope these will provide some food for thought in developing further\ndrafts, and we would be interested in your comments.\n\nBest regards,\nColette Nicolle (for the WWAAC project)\n\nResearch Fellow\nErgonomics and Safety Research Institute (ESRI)\nLoughborough University\nHolywell Building\nHolywell Way\nLoughborough, Leicestershire\nLE11 3UZ\n\nSwitchboard: +44 (0)1509 283300\nDirect Dial:    +44 (0)1509 283369\nEmail: c.a.nicolle@lboro.ac.uk\nhttp://www.lboro.ac.uk/esri/\n\n\n\n"
        },
        {
            "subject": "Foreign exchange trading",
            "content": " ?\n ?\nPlease kindly accept my appology for intruding your privacy.I am \nMr.Godfrey Ohiri ,an internal Auditor with Hallmark Bank PLC,Nigeria.I \nam soliciting your assistance to help accept ownership of $1million \ndollars in my bank which I discovered in discharge of my duty.This \nmoney arose as a result of unrecorded foreign exchange trading in our \nbank last year.\n\nI have concluded arrangement for you to simply open an account with our \nbank and this money will be credited to your account,You may latter \ntravel down to Nigeria or appoint an Attorney for us to sign Legal \nAgreement for managment of account or investment of this money \npreferably in your country.Looking forward to receiving your prompt \nreply.\n\nBest regards.\nGodfrey Ohiri.  \n\n\n\n\n\n\ntext/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "IBM comments on 11 March 2004 public draf",
            "content": "Here are the IBM comments on the 11 March 2004 public draft of WCAG 2.0\n\nFront matter - add the following links in the section where the links to\n\"this version\", \"latest version\", and \"previous version\" are.\n   - Errata: The Comm Team policy is now that errata and translations links\n   must appear in at least the head of the document.\n   [1] Example of errata & translations in top matter of W3C spec\n   http://www.w3.org/TR/P3P/\n\n   - Related Documents: There needs to be a link to a related documents\n   \"page\", that can change so as WAI documents are added or rearranged, you\n   have a place to go to find out how they are related.  As techniques,\n   checklist format versions, and other guidelines documents are added,\n   this \"related docs\" page could sort them all out and present them is a\n   logical manner and not depend on the reader to have to read and gather\n   bits and pieces along the way from each WAI recommendation to construct\n   the organization and relationships.\n\n   - Table of Contents: A link on the top of the page that \"skips over\" all\n   the top matter and gets to the table of contents is needed.  Everyone is\n   equally hindered by having to page down and tab forever to get to the\n   main content which begins with the Table of contents of the\n   recommendation.\n\nIntroduction, Purpose, 1st paragraph - Remove the sentences about\naccessibility to a variety of Web-enabled devices. This is a benefit of\naccessibility but it should not be discussed in the first paragraph of the\ndocument. It can be covered later or left to EO to promote.\n\nGuideline 1.1, Benefits - the first bullet implies that providing text\nequivalents helps people who have trouble reading text. This is not\napplicable to this guideline which is about providing access to \"non-text\"\ncontent. People who have trouble reading \"text\" are not the people who have\ntrouble with \"non-text\" content.\n\nGuideline 1.1, Example 1 - How the screen reader identifies links is\nirrelavant to this example which is about providing alt text. Rewording\npropsal: \"An image of a right pointing arrow is used to link to the next\nslide in a slide show. The text equivalent is \"Next slide\". When screen\nreader users hear this as a link, they should understand that this link\nadvances to the next slide in the slide show.\"\n\nGuideline 1.2, Level 1 success criteria - Ordering and rewording\nsuggestions\n\n   1. (previously # 2) Synchronized captions are provided for all\n   significant dialogue and sounds (no need to specify \"in time-dependent\n   material\". This guideline only applies to time-dependent material.)\n\n   2. (previously # 1) In audio-visual media, synchronized audio\n   descriptions of visual events that are not evident from the audio are\n   provided.\n\n   3. Remove. Points 1 and 2 above should specify \"synchronized\" because\n   the guideline itself specifies \"synchronized\". The exception is not\n   needed because if the content is audio only and not time sensitive, it\n   does not meet the definition of time-dependent and this guideline does\n   not apply to it.\n\n   4. What is the need for a specific success criteria addressing realtime\n   video with audio? Success criteria above already require captions\n   whether it is realtime or not. Are we trying to say audio descriptions\n   for visual events are NOT required for real time video with audio? If\n   so, then the audio description success criteria can be reworded as \"In\n   audio-visual media that is not realtime, synchronized audio descriptions\n   of visual events that are not evident from the audio are provided.\"\n\n   5. Either remove this success criteria or change the definition of\n   time-dependent presentation in the glossary. Web content that is\n   non-interactive video only does not meet the current definition of\n   time-dependent presentation.\n\nGuideline 1.2, Level 2 success criteria - The Level 1 success criteria\nalready require synchronized captions for real-time audio with video. What\nis the additional requirement here? The editorial note does not seem to\napply to anything at this level. The note is talking about audio\ndescriptions but the success criteria is about captions.\n\nGuideline 1.2, Benefits - There is a Note in the informative section that\nhas hidden success criteria in it. (\"Where possible (especially for\neducation and training materials), provide content so that it does not\nrequire tracking multiple simultaneous events with the same sense, or, give\nthe user the ability to freeze the video so that captions can be read\nwithout missing the video.\") This should either be removed or made into a\nLevel 3 success criteria.\n\nGuideline 1.2, Examples - Example 3 is a different version of Example 3\nunder guideline 1.1.\n\nGuideline 1.3, Level 1 success criteria - as currently written, simple text\nfiles would not conform to WCAG 2.0 even though they might be quite\naccessible. The level 1 success criteria should be limited to those things\nwhich, if not identified semantically, really do create a barrier to\naccessing the Web site. Two things that definitely require semantic\ninformation are tables and labels for form controls. There may be others\nbut paragraphs, headings, lists, and emphasis should not be required at\nLevel 1. These should be Level 2 requirements.\n\nGuideline 1.3, Benefits, last bullet - need to describe how this guideline\nbenefits people with cognitive, physical, hearing, and visual disabilities.\n\nGuideline 1.4, Level 1 success criteria, note - rewording suggestion:\n\"Images of text that meets guideline 1.1 should satisfy this criterion.\"\n\nGuideline 1.5 - the Level 3 success criteria address background sounds in\nan \"auditory presentation\" but we have no success criteria that address\nbackground audio of a Web site; that is, a Web site that plays music or\nsome other type of audio as background to the visual presentation. Screen\nreader users will have a very hard time listening to the page while the\nbackground audio is playing. Shouldn't there be a requirement that this\ntype of audio can be disabled by the user? I think it might actually belong\nunder guideline 1.3. The background audio is part of the presentation and\nit should be separable from the information, functionality, and structure.\nProposal for Level 1 success criteria: \"Users can disable background audio\nthat automatically plays when a Web site is accessed.\"\n\nGuideline 2.1, example 2, second unnumbered list item - the Web content\nshould be operable via the keys on the cell phone keypad, regardless of\nwhether or not the cell phone supports the attachment of an optional\nkeyboard. A better example here might be a PDA device that is usually\noperated via a stylus but has an optional keyboard that can be attached.\nThe Web content should be operable using the attached keyboard. In this\nexample and all of the others listed under Example 2, it is ambiguous what\nthe content author's responsibility is here. For example, a Palm Pilot\nsupports an attached keyboard but I think the Palm OS only supports data\nentry via the keyboard, not navigation. If the Palm OS and browser don't\nsupport navigation via the optional keyboard, it is impossible for the\ncontent author to provide this function. These examples should either be\nclarified as to the content author's responsibility or removed altogether.\n\nGuideline 2.2 - is \"time limits on their reading\" meant to include server\ntimeouts? In general, server administrators, not content authors, control\nserver timeouts. Propose rewording this guideline as \"Allow users to\ncontrol time limits on reading or interaction that are part of the\nfunctionality of the content unless specific real-time events or rules of\ncompetition make such control impossible.\"\n\nGuideline 2.2, Level 1 success criteria - we should not provide success\ncriteria for scenarios that are excluded by the Guideline itself. The\nfourth and fifth sub-bullets concern time limits that are due to real-time\nevents or competition. The Guideline excludes these types of time limits\nwith the phrase \"...unless specific real-time events or rules of\ncompetition make such control impossible.\"\n\nGuideline 2.2, Benefits - Benefits are written as issues instead of\nbenefits. Proposed rewording of first benefit: \"People with reading\ndisabilities, cognitive disabilities, and learning disabilities who may\nneed more time to read and comprehend written text will be given additional\ntime to read the information.\"  Proposed rewording of 2nd bullet: \"People\nwith physical disabilities can have sufficient time to process and read\ninformation before it is refreshed.\"\n\nGuideline 2.2, Examples of content that must meet the success criteria,\nlast sub-bullet - \"shutdown or deactivation of a resource if activity is\nnot received in a set amount of time\" sounds like server timeouts which are\nnot under the control of the content. Remove or reword.\n\nGuideline 2.3, Level 1 success criteria - not only should the content be\nmarked, there should be a way for the user to avoid seeing it. Proposed\nrewording: \"Content that violates General Flash Threshold or Red Flash\nThreshold is identitified prior to its appearance in a way that allows the\nuser to suppress its appearance.\"\n\nGuideline 2.3, Level 1, 2, and 3 success critera - Threshold definitions\nshould be moved to the glossary terms and the success criteria should link\nto the glossary.\n\nGuideline 2.4, Level 2 success criteria - # 1 and # 2 are very document\ncentric and will be difficult or impossible for Web applications to\nimplement. For example, a table of contents implies that the user can\naccess all content in any order. In Web applications, it is not always\npossible to access all function in any order.\n\nGuideline 2.4, Level 3 success criteria # 4, sub-bullet e - Remove. This is\nalready covered by guideline 1.3, Level 1b\n\nGuideline 2.4, Benefits, first bullet, first sub-bullet & third sub-bullet\n- since the function described is currently only possible with assistive\ntechnology, suggest combining these two bullets and rewording as:\n\"Assistive technology used by people with physical and vision disabilities\ncan provide users with the ability to jump from header to header to get an\noverview or to more quickly \"skim\" to the section they are interested in.\"\n\nGuideline 3.1 - what if a particular technology doesn't support the\nrequirements defined in the success criteria? For example, if PDF doesn't\nhave a way to identify abbreviations and acronyms programmatically, does\nthat mean it is impossible for a PDF document that contains abbreviations\nor acronyms to conform to WCAG Level 1?\n\nGuideline 3.1, Level 1 success criteria, # 2 - The real problem with\nacronyms and abbreviations is how the speech synthesizers speak the\nacronym, not so much how it is expanded.  A subcommittee/WG needs to be\nestablished to identify the various scenarios and apply some logic as to\nwhat the author should do, what the AT/browser should do, what the\nsynthesizer should do, and what the user should do.  For example, the\nauthor can expand the acronym VoiceXML to \"voice extendable markup\nlanguage\", and the user can choose to expand to hear the full expansion,\nbut how does the user get to hear Voice X.M.L. instead of \"voiceexmuhl\"?\nHow the acronym is pronounced should be part of aural cascading style\nsheets, which is not well defined in this scenario.\n\nGuideline 3.1, Level 3 success criteria, # 4 - The Strategies for Reducing\nthe Complexity of Content is a very large section that is disruptive to the\nreading of the document. These should be moved to an appendix with a link\nfrom the success criteria to the appendix.\n\nGuideline 3.1, Level 3 success criteria, Strategies for Reducing the\nComplexity of Content, Alternative representations, second sub-bullet - The\ndefinition of non-text content provided in the glossary includes \"text in\nimages\" and \"ASCII art\". I don't think that is what we are recommending\nhere. We should just specify the types of non-text content we are\nrecommending. Proposal: images, animations, audio, video, multimedia\n\nGuideline 3.1, Benefits, first sub-bullet - \"When editing content,\nauthoring tools can switch between appropriate spelling dictionaries\"\nshould be removed. WCAG 2.0 is about making content accessible to people\nwith disabilities. It's not about ease of authoring.\n\nGuideline 3.1, Benefits, second and third sub-bullets - these do not\nexplain how this requirement helps people with disabilities. It should\neither be reworded or removed. I'm not an expert on this but I suspect that\nthe problem for people with cognitive disabilities is not that they are not\nfamiliar with a particular abbreviation or acronym but that even if they\nknow what it is, they somehow can't understand it when they see it written.\n\nGuideline 3.2, Level 1 success criteria - \"extreme change of context\" is\nnot really defined in the glossary. There are simply 3 examples provided.\nIn the first example, \"opening a new browser window\", I am not familar with\nany way that an author could do this that would not be programmatically\nidentified. In the last two examples, identifiy speaker changes in an\nauditory presentation and in captions, I don't know of any way in which to\ndo this where it could be programmatically identified. So, of the 3\nexamples provided, one is always conforming and the other two can never\nconform.\n\nGuideline 3.2, Level 2 success criteria, # 1 - would navigation bars that\nexpand to display sub-topics conform to this requirement?\n\nGuideline 3.2, Level 2 success criteria, # 5 - The user agent, not the\ncontent author, should be responsible for warning of extreme changes in\ncontext before they happen. When user agents implement the function, the\nuser gets the benefit on all sites, not just on sites where the author has\nimplemented the feature.\n\nGuideline 3.2, Benefits, second bullet, second sub-bullet - using captions\nto note changes in speaker can't be programmatically identified.\n\nGuideline 3.2, Example 3 - this is an example of NOT meeting the\ncheckpoint. Proposed rewording: \"Frames are included in the page history so\nthat the browser's Back button can be used to return to a previous frame.\"\n\nGuideline 4.1, Example 3 - this example seems more appropriate now for\nguideline 4.2.\n\nGuideline 4.2, Level 1 success criteria, # 2 - \"If the custom user\ninterfaces\" should be reworded \"If the programmatic user interfaces\" for\nconsistency with the first sentence.\n\nGuideline 4.2, Level 2 success criteria - this seems too undefined to be a\nsuccess criteria. For example, guideline 2.1 requires the functionality of\nthe content to simply be operable via a keyboard. Would this success\ncriteria require that access keys always be defined on HTML Web sites since\nthey are an accessibility feature of HTML? Another example is that of\nguideline 3.1, level 2 success criteria, # 4 which requires that all\nforeign language passages or phrases be identified. 3.1 L2 #4 clearly does\nnot require individual foreign words to be identified but would 4.2 L2 #1\nrequire this simply because HTML allows individual words to have the \"lang\"\nattribute?\n\nGlossary - The \"Glossary of terms\" should not be part of the\nrecommendation, but kept in a separate doc such as the techniques.  The\n\"common WAI glossary\" just needs to include the definitions that the WG\nproposes.  The process is key here, that the terms be considered as part of\nthe WCAG recommendation up to the \"proposed recommendation\" step, where the\nterms and definitions are \"removed\" from the recommendation and \"ensured\"\nas part of the common glossary for all WAI documents.\n\nGlossary, \"extreme changes in context\" - the first bullet should read\nsimply \"opening a new browser window\". That is the definition of an extreme\nchange in context whether it is expected or not. Our guideline is that this\nchange should be done in a predictable way so that it is not unexpected.\nThe second bullet should simply read \"a change of speaker in an auditory\npresentation\". Again, that is the definition of the extreme change in\ncontext. The advice to provide a caption or visual cue so that the user\nunderstands it is the success criteria. Also, it is unclear how the \"common\nuser actions\" and \"common responses to user actions\" relate to the\ndefinition of \"extreme changes in context\".\n\nAndi\nandisnow@us.ibm.com\nIBM Accessibility Center\nhttp://www.ibm.com/able\n\n\n\n"
        },
        {
            "subject": "Access Board comments on 11 March 2004 draf",
            "content": "Attached are comments from the Access Board on the 11 March 2004 Working \nDraft.  I am forwarding to the archive on their behalf.\n\n-- \nwendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/-- \n\n\n\ntext/html attachment: wai_feedback.htm\n\n\n\n\n"
        },
        {
            "subject": "???C?C?s???W?????A?[???C?C?",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "New Public list - public-compound-documents  maintained by plh&#64;w3.or",
            "content": "Public mailing list for discussion on compound documents and component\nextensions, and how to integrate various specifications produced by the\nDocument Formats and Interaction domains.\n\n\n1.  http://www.w3.org/DF/\n2.  http://www.w3.org/Interaction/\n\n\n-- \nSimon J. Hernandez    |    http://people.w3.org/simon/    |   simon@w3.org\nWorld Wide Web Consortium (W3C)                          http://www.w3.org\nMIT Laboratory for Computer Science    200 Technology Square      NE43-340\nCambridge, MA 02139-3579 USA  Voice: +1.617.253.2920  Fax: +1.617.258.5999\n\n\n\n"
        },
        {
            "subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle",
            "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "CFP: IEEE/WIC/ACM Web Intelligence 200",
            "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepage: http://www.maebashi-it.org/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n           National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, and data/knowledge grids) on the\nnext generation of Web-empowered products, systems, services, and\nactivities. It is one of the most important as well as promising IT\nresearch fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\nWI Topics\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nMore detailed instructions and the On-Line Submission Form can be\nfound from the WI'04 homepage: http://www.maebashi-it.org/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper awards will be conferred on the authors of\nthe best papers at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyoung Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Used Formwork/Peri Dok",
            "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n"
        },
        {
            "subject": "CFP: IEEE/WIC/ACM Web Intelligence 200",
            "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepages: http://www.maebashi-it.org/WI04\n                       http://www.comp.hkbu.edu.hk/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n  Microsoft Research Asia\n                  National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, wisdom Web, and data/knowledge\ngrids) on the next generation of Web-empowered products, systems,\nservices, and activities. It is one of the most important as well as\npromising IT research fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\nFollowing the great successes of WI'01 held in Maebashi City, Japan\nand WI'03 held in Halifax, Canada, WI 2004 provides a leading\ninternational forum for researchers and practitioners (1) to present\nthe state-of-the-art of WI technologies; (2) to examine performance\ncharacteristics of various approaches in Web-based intelligent\ninformation technology; and (3) to cross-fertilize ideas on the\ndevelopment of Web-based intelligent information systems among\ndifferent domains.  By idea-sharing and discussions on the underlying\nfoundations and the enabling technologies of Web intelligence, WI 2004\nwill capture current important developments of new models, new\nmethodologies and new tools for building a variety of embodiments of\nWeb-based intelligent information systems.\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Service-Oriented Computing\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nAll paper submissions will be handled electronically.  More detailed\ninstructions and the On-Line Submission Form can be found from the\nWI'04 homepages: http://www.maebashi-it.org/WI04 and\nhttp://www.comp.hkbu.edu.hk/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper award and the best demo award will be conferred on the\nauthors of the best papers and the best demos at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-Chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyong Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n*******************************************************\nWI/IAT Conference Secretariat\nwi-iat@maebashi-it.org\n\nWI'04:  http://www.maebashi-it.org/WI04/\nIAT'04: http://www.maebashi-it.org/IAT04/\n??????????????????????????\n2003-12-26 17:59:49\n********************************************************\n\n\n\n"
        }
    ]
}