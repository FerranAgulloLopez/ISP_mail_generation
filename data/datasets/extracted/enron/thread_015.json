{
    "mails": [
        {
            "subject": "Re: Low level AP",
            "content": "Hi Leonard\n\n> I don't think that it should be necessary to store \"level\" information to\n> achieve this, and indeed I think that doing so would complicate matters,\n> because if a concept is inserted to create a new level of grouping then\n> the \"levels\" of all the subordinate concepts would change.\n>\nYes, skos takes the approach of expressing broader/narrower/related \nrelationships between concepts. If we are to add what is effectively \nharvesting functionality to the thesaurus, then we would likely return skos \nencoded data as is, from which some client app would be able to build a \nthesaurus browser if required.\n\nIf time permits we may demonstrate how this would work against our own demo \nthesaurus service implementation. For example either by layering Protege on \ntop of our service for browser-based views on the data, or developing \nprototype viewer implementations that we already have.\n\nNikki\n\n\n> Leonard Will\n> --\n> Willpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\n> Information Management Consultants              Tel: +44 (0)20 8372 0092\n> 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\n> L.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n> ---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "Re: Low level AP",
            "content": "Leonard\n \nI think Ron was referring to a \"number of levels\" parameter in the API call\n(ie in SKOS getConceptRelativesByPath) - a relative number of levels (or\nrelationship traversals) from the given concept. It could include the whole\nhierarchy but might not necessarily in some large thesaurus applications\nwhere you wanted a local context display centred around the given concept.\nThus 'Level no'. would not need to be stored in the thesaurus\nrepresentation.\n \nAs Ron mentions, this was something we explored in the JoDI paper, where the\nweb system's browsing interface is constructed dynamically by calls to an\nAPI (in that case a bespoke API).\n \nDoug\n \n\n\n\n"
        },
        {
            "subject": "SKOS AP",
            "content": "Hi all,\n\nJust to explain the state of the SKOS API and the current work going on in\nSWAD-E ... Dave and Nikki are currently working on a reference\nimplementation of the API as is, which will probably be ready by the end of\nthe month.  \n\nThere are a bunch of technical issues, relating to the implementation of\nthis API, such as the question of how to encode the data that the service\nreturns.  \n\nIn parallel there is a continued discussion of the SKOS API at a functional\nlevel.  The SKOS API is intended to be a functional specification for a\nthesaurus service - i.e. it defines the functionality that we require of\nsuch a service.  \n\nSo there are two separate discussions to be made: (1) A discussion of issues\nsurrounding how to implement the current version of the SKOS API (techie\nstuff), and (2) A discussion of how to improve the API itself for the next\nversion (abstract stuff).\n\nObviously there's going to be some overlap, but I reckon it will help if we\nmanage keep this distinction as clear as possible (in our minds at least).  \n\nAl.\n\n\n      \n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of NJ \n> Rogers, Learning\n> and Research Technology\n> Sent: 11 May 2004 16:13\n> To: Leonard Will; public-esw-thes@w3.org\n> Subject: Re: Low level API\n> \n> \n> \n> Hi Leonard\n> \n> > I don't think that it should be necessary to store \"level\" \n> information to\n> > achieve this, and indeed I think that doing so would \n> complicate matters,\n> > because if a concept is inserted to create a new level of \n> grouping then\n> > the \"levels\" of all the subordinate concepts would change.\n> >\n> Yes, skos takes the approach of expressing broader/narrower/related \n> relationships between concepts. If we are to add what is effectively \n> harvesting functionality to the thesaurus, then we would \n> likely return skos \n> encoded data as is, from which some client app would be able \n> to build a \n> thesaurus browser if required.\n> \n> If time permits we may demonstrate how this would work \n> against our own demo \n> thesaurus service implementation. For example either by \n> layering Protege on \n> top of our service for browser-based views on the data, or developing \n> prototype viewer implementations that we already have.\n> \n> Nikki\n> \n> \n> > Leonard Will\n> > --\n> > Willpower Information       (Partners: Dr Leonard D Will, \n> Sheena E Will)\n> > Information Management Consultants              Tel: +44 \n> (0)20 8372 0092\n> > 27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 \n> (0)870 051 7276\n> > L.Will@Willpowerinfo.co.uk               \n> Sheena.Will@Willpowerinfo.co.uk\n> > ---------------- <URL:http://www.willpowerinfo.co.uk/> \n> -----------------\n> >\n> >\n> \n> \n> \n> ----------------------\n> NJ Rogers, Technical Researcher\n> (Semantic Web Applications Developer)\n> Institute for Learning and Research Technology (ILRT)\n> Email:nikki.rogers@bristol.ac.uk\n> Tel: +44(0)117 9287096 (Direct)\n> Tel: +44(0)117 9287193 (Office)\n> \n\n\n\n"
        },
        {
            "subject": "Spanish translation of the SKOSCore Guid",
            "content": "Found this:\n\nhttp://murakami.objectis.net/artigos/skos\n\nHow chuffed am I!\n\n(Anybody speak Spanish and can tell me how good a translation this is?  It\nmight be in Portugese for all I know.)\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Err... portugese translation of SKOSCore Guide ...",
            "content": "Doh.\n\n\n\n"
        },
        {
            "subject": "Re: Low level AP",
            "content": "In message <EF1C49A3F569D41186C900508B6DDC990C5690B1@ems3.glam.ac.uk> on \nTue, 11 May 2004, \"Tudhope D S (Comp)\" <dstudhope@glam.ac.uk> wrote\n>I think Ron was referring to a \"number of levels\" parameter in the API \n>call (ie in SKOS getConceptRelativesByPath) - a relative number of \n>levels (or relationship traversals) from the given concept. It could \n>include the whole hierarchy but might not necessarily in some large \n>thesaurus applications where you wanted a local context display centred \n>around the given concept. Thus 'Level no'. would not need to be stored \n>in the thesaurus representation.\n\nAh, right, that makes sense.\n\nYou might want to specify separately \"number of levels up\" and \"number \nof levels down\", or \"up to the top of the tree and down three levels\" \nfrom the given concept.\n\nI wanted to make sure that people were not trying to impose some scheme \nof absolute levels (though this what the biologists do, labelling levels \nas kingdom - phylum - class - order - family . .  etc., which \nnecessitates awkward interpolations like sub-order and so on).\n\nLeonard\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: Spanish translation of the SKOSCore Guid",
            "content": "Err, indeed it is portuguese. (Which I read reasonably well, but cannot\nwrite)\n\nIt seems like a good translation, except in one of the examples they added\nsomething that wasn't there. (Specifically, in showing how to use\nmultilinugal terms they added a portuguese version of a term, that I don't\nrecall from the original :-)\n\ncheers\n\nChaals\n\nOn Tue, 11 May 2004, Miles, AJ (Alistair)  wrote:\n\n>\n>Found this:\n>\n>http://murakami.objectis.net/artigos/skos\n>\n>How chuffed am I!\n>\n>(Anybody speak Spanish and can tell me how good a translation this is?  It\n>might be in Portugese for all I know.)\n>\n>Al.\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: Low level AP",
            "content": "> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk] \n> Sent: Tuesday, May 11, 2004 11:03 AM\n> Subject: Re: Low level API\n> \n> In message <6.0.0.22.2.20040511155617.01c6c768@pop.skynet.be> \n> on Tue, 11 May 2004, Ron Davies <ron@rondavies.be> wrote\n> >The SKOS API appears to me to be pitched at a very low level. What I \n> >mean is that the client has to do a great deal of work, and send out \n> >many atomic requests to be able to do certain kinds of \n> required tasks, \n> >e.g. build a useful hierarchical display format to allow an \n> end user to \n> >browse a thesaurus. Hierarchical displays are used in a wide \n> number of \n> >thesauri of different styles.\n> \n> I agree with Ron, though I would be interested to know the \n> views of the folk closer to the mechanics of how this would \n> work. Perhaps there is a difference depending on whether you \n> are retrieving a display for a human to look at or specific \n> terms for a machine to use.\n> \n> It would certainly seem more efficient for a server to return \n> a complete hierarchy in response to a single request; most \n> standard thesaurus management software can display such \n> hierarchies, constructing them when needed by following the \n> chain of BT/NT links.\n\nThe SKOS API suffers from the same problem that previous API's\nlike ASDL suffer from.  When dealing with Web services you \nneed to be careful about your interface.  It's not efficient\nfor a server to return a complete hierarcy.  This could amount\nto a lot of data being returned to the client.  Just like its\nnot a good idea to have a \"return the top terms of the thesaurus\"\nrequest, which could wind up sending you the whole thesaurus.  In\neither case, before you could build the XML for the SOAP response\nyour underlying TCP/IP connection would most likely timeout.\n\nFrom what I can see the SKOS API will not scale.  There was a good\nrecently published paper on this subject in Cataloging & Classification\nQuaterly, volumne 37, Issue 3/4.  Matter of fact this whole issue is\na good read, due to the wealth of thesaurus topics:\n\nDistributed Thesaurus Web Services \nEric H. Johnson \nhttp://www.haworthpress.com/store/ArticleAbstract.asp?ID=34895 \nHTML-based information services provide access to online information sources\nbut do not make them useful for much more than viewing in a Web browser.\nThere is also no cohesive cataloging or subject access scheme for the\nInternet. XML and Web services provide the framework for enhancing the\ninformation content of all types of data delivered over the Internet and for\nenhancing the functionality of specialized yet interoperable networked\ninformation retrieval applications. The Thesauro-Web, a proposed network of\nthesaurus access and navigation services, could provide enhanced subject\naccess for the World Wide Web and enhance the functionality of information\nretrieval applications. The idea behind the Thesauro-Web is described here\nin detail, with examples of applicable XMLprotocols and descriptions of\npossible uses. \n\nAnother good article I read recently was in JoDI volume 4, issue 4 -- New\nApplications of KOS http://jodi.ecs.soton.ac.uk/Articles/v04/i04/Binding/\n\nC. Binding, D. Tudhope: KOS at your Service: Programmatic Access to\nKnowledge Organisation Systems\nhttp://jodi.ecs.soton.ac.uk/Articles/v04/i04/Soergel/\n\nAn interesting API approach to thesauri can been seen in Microsoft's\nResearch services available in Office 2003, see: \nhttp://msdn.microsoft.com/office/understanding/research/default.aspx\n\nHere the API is limited to a basic query but the message returned could be\nan XHTML document which opens up the possibility to follow BT/NT/RT\nrelationship in your thesaurus, but this is outside the scope of the\nResearch services API.  Wouldn't it be great to have your favorite thesaurus\navailable to put quality metadata into your research paper?  I realize that\nmany are anti-Microsoft but the Research services API could be lifted and\nput into OpenOffice and/or other products, after all a Web service API is\njust that an API regardless of who created it.  The interesting aspect of\nthis API is that it moves quality metadata creation down to the author.\nWouldn't it also be great to have your favorite SKOS encoded vocabulary\nappear in the Research task pane?  The Research services API provides a\nworking vechicle for how the Semantic Web could actually be useful.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "quote from murakam",
            "content": "I just pulled this quote from the home page of the person who did the\nportuguese translation of the SKOS-Core guide:\n\n\"People become librarians because they know too much. Their knowledge\nextends beyond mere categories. They cannot be confined to disciplines.\nLibrarians are all-knowing and all-seeing. They bring order to chaos. They\nbring wisdow and culture to the masses. They preserve every aspect of human\nknowledge. Librarians rule. And they will kick the crap out of anyone who\nsays otherwise.\"\n\n\n\n"
        },
        {
            "subject": "RE: Low level AP",
            "content": "Hi Andy\n>\n> The SKOS API suffers from the same problem that previous API's\n> like ASDL suffer from.  When dealing with Web services you\n> need to be careful about your interface.  It's not efficient\n> for a server to return a complete hierarcy.  This could amount\n> to a lot of data being returned to the client.  Just like its\n> not a good idea to have a \"return the top terms of the thesaurus\"\n> request, which could wind up sending you the whole thesaurus.  In\n> either case, before you could build the XML for the SOAP response\n> your underlying TCP/IP connection would most likely timeout.\n>\n> From what I can see the SKOS API will not scale.\n\nThanks for the information in this email - I'll have a look at these \nreferences you cite.\n\nI'd like to mention here (as earlier in this thread) that the SKOS API is \nuse case driven. I believe that the SKOS API provides a good initial \nattempt at defining the basis of functionality for some thesaurus service. \nNow that service might be a web service, or it might not - it might instead \nrepresent a programmatic interface for some application. So we are not \nnecessarily constrained by network considerations (& I would also perhaps \nthrow in the word \"Grid\" in at this point :-)).\n\nShould some application require a service's complete thesaurus hierarchy it \ncould potentially harvest the data periodically, and store it locally in \norder to use it for whatever functionality its client app (e.g. \nbrowser-based thesaurus viewer) might require. [and that client app itself \nmight well adhere to the SKOS API specification]. There are harvesting \nprotocols that could apply here e.g. OAI (http://www.openarchives.org/).\n\nIn a different scenario, suppose some client application did not wish to be \npotentially overloaded by large response data sets from a thesaurus web \nservice, well, this situation has been tackled before in the sphere of \nnetwork search and retrieval. For example see \nhttp://zthes.z3950.org/srw/current.html. It is possible to develop a web \nservice that can handle some notion of state such that a client may \nnegotiate with the service how large a result set it is prepared to \nreceive. And so on ....\n\nRegards,\nNikki\n\n> There was a good\n> recently published paper on this subject in Cataloging & Classification\n> Quaterly, volumne 37, Issue 3/4.  Matter of fact this whole issue is\n> a good read, due to the wealth of thesaurus topics:\n>\n> Distributed Thesaurus Web Services\n> Eric H. Johnson\n> http://www.haworthpress.com/store/ArticleAbstract.asp?ID=34895\n> HTML-based information services provide access to online information\n> sources but do not make them useful for much more than viewing in a Web\n> browser. There is also no cohesive cataloging or subject access scheme\n> for the Internet. XML and Web services provide the framework for\n> enhancing the information content of all types of data delivered over the\n> Internet and for enhancing the functionality of specialized yet\n> interoperable networked information retrieval applications. The\n> Thesauro-Web, a proposed network of thesaurus access and navigation\n> services, could provide enhanced subject access for the World Wide Web\n> and enhance the functionality of information retrieval applications. The\n> idea behind the Thesauro-Web is described here in detail, with examples\n> of applicable XMLprotocols and descriptions of possible uses.\n>\n> Another good article I read recently was in JoDI volume 4, issue 4 -- New\n> Applications of KOS http://jodi.ecs.soton.ac.uk/Articles/v04/i04/Binding/\n>\n> C. Binding, D. Tudhope: KOS at your Service: Programmatic Access to\n> Knowledge Organisation Systems\n> http://jodi.ecs.soton.ac.uk/Articles/v04/i04/Soergel/\n>\n> An interesting API approach to thesauri can been seen in Microsoft's\n> Research services available in Office 2003, see:\n> http://msdn.microsoft.com/office/understanding/research/default.aspx\n>\n> Here the API is limited to a basic query but the message returned could be\n> an XHTML document which opens up the possibility to follow BT/NT/RT\n> relationship in your thesaurus, but this is outside the scope of the\n> Research services API.  Wouldn't it be great to have your favorite\n> thesaurus available to put quality metadata into your research paper?  I\n> realize that many are anti-Microsoft but the Research services API could\n> be lifted and put into OpenOffice and/or other products, after all a Web\n> service API is just that an API regardless of who created it.  The\n> interesting aspect of this API is that it moves quality metadata creation\n> down to the author. Wouldn't it also be great to have your favorite SKOS\n> encoded vocabulary appear in the Research task pane?  The Research\n> services API provides a working vechicle for how the Semantic Web could\n> actually be useful.\n>\n>\n> Andy.\n>\n> Andrew Houghton, OCLC Online Computer Library Center, Inc.\n> http://www.oclc.org/about/\n> http://www.oclc.org/research/staff/houghton.htm\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: Supporting arrays of concept",
            "content": "> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk] \n> Sent: Tuesday, May 11, 2004 10:43 AM\n> Subject: Re: Supporting arrays of concepts\n> \n> 2. As regards node labels, I have tried to show that we need \n> to distinguish between\n> \n>         (a) real \"node labels\", which specify a characteristic of\n>         division in the form <xxx by yyy> and\n> \n>         (b) broader concepts which act as parent terms to the \n> terms in a\n>         following array.\n> \n> DDC centred headings and some of the AAT guide terms fall \n> under (b), and should not be called node labels. Structurally \n> these are just terms representing concepts which the \n> thesaurus editor has decided are unsuitable for use in \n> indexing (and may have to be labelled in some way to indicate this).\n\nI think I agree with your idea of separating the two.  Maybe what is\nneeded is another element at the same level as skos:Concept, perhaps\nskos:Summary, that handles (b) and the current proposal for handling\n(a).  Although the current proposal seems odd to me.  It seems to me\nthat you might want to have additional metadata associated with node\nlabel array in addition to the list of concepts associated with it.\nFor example scope notes or other types of notes.\n\n> \n> 3. The more complex issue that I thought would broaden the \n> scope of the project is handling pre-coordinated indexing \n> strings. The problem is described in the following extract \n> from \"FAST : development of simplified headings for metadata \n> / by Rebecca J. Dean\"\n>\n> [quote deleted]\n> \n> DDC and MeSH, similarly, have many provisions for \n> synthesising concepts to express compound concepts that may \n> or may not be enumerated in the schedules. A classification \n> schedule may show these compound concepts in a hierarchical \n> display, as I illustrated in the second example in my message \n> of 6th May, but the hierarchy is not built on the same BT/NT \n> relationships as in a thesaurus.\n\nI guess I didn't quite follow that.  Yes, LCC, DDC, LCSH, MeSH and\nothers allow synthesising concepts, but those concepts are still\nvalid from the vocabularies perspective, its just that they have\nnot been *enumerated* as a standard thesaurus does.  So lets say\nI convert DDC into SKOS.  What you would get is all the predefined\nconcepts defined by the Dewey editors.  If someone builds a class\nnumber, based upon the instructions in the classification, then\nthey can merely create an skos:Concept element and within that\nelement use the skos:inScheme to point to the \"official\" base\nscheme which defines the list of predefined concepts.  Any built\nconcept in LCC, DDC, LCSH, or MeSH participate in same BT/NT \nrelationship established for the vocabulary.  So I seem to be \nmissing something with your analogy.\n\n> It seems to me to be a much more complex job for SKOS to try \n> to create a system that would incorporate rules for creating \n> these compound strings.\n\nYou don't need to incorporate the rules for creating the compound\nstrings.  The \"whole\" compound string *is* the concept and there\nisn't necessarily a BT/NT relationship between the predefined\npart and what was composed.  The whole term should be taken as\nthe concept and its BT/NT relationship is to be taken in the\ncontext of all the other predefined or compound strings in the\nvocabulary.\n\n> The FAST project \n> <http://www.oclc.org/research/projects/fast/> from which I \n> quoted above recognises this problem by treating each of the \n> elements of an LCSH heading separately and grouping them into \n> subject, time, place, form, people and organisations facets. \n> This makes it much more amenable to storing in a structure \n> like SKOS, and seems the best initial approach.\n\nI disagree with this statement on several fronts.  FAST is no\nmore amenable to SKOS than any of the other vocabularies I\nmentioned.  As a matter of fact I forgot to include FAST in\nthe list of vocabularies that we will probably put into SKOS.\nFAST actually doesn't treat LCSH headings much differently than\nLCSH already does.  LCSH is already faceted!  LC may disagree\nwith my statement, but the simple fact, or facet, of the matter\nis when we look at LCSH, which is defined by MARC21, the preferred\nterm of the vocabulary is specified as the 1XX field.  That XX\nshould be a clue.  Looking at the MARC21-A authorities format,\nyou can see the following 1XX definitions:\n\n    * 100 - HEADING--PERSONAL NAME (NR)\n    * 110 - HEADING--CORPORATE NAME (NR)\n    * 111 - HEADING--MEETING NAME (NR)\n    * 130 - HEADING--UNIFORM TITLE (NR)\n    * 148 - HEADING--CHRONOLOGICAL TERM (NR)\n    * 150 - HEADING--TOPICAL TERM (NR)\n    * 151 - HEADING--GEOGRAPHIC NAME (NR)\n    * 155 - HEADING--GENRE/FORM TERM (NR)\n    * 180 - HEADING--GENERAL SUBDIVISION (NR)\n    * 181 - HEADING--GEOGRAPHIC SUBDIVISION (NR)\n    * 182 - HEADING--CHRONOLOGICAL SUBDIVISION (NR)\n    * 185 - HEADING--FORM SUBDIVISION (NR)\n\nTo the naive, those pretty much look like facets.  The 18X are\nused in building composed subject headings.  So the \"real\" facets\nare everything else.\n\nFAST doesn't do anything radically different.  They basically use\nthe similar \"facets\" as LCSH has, but pull out some sub-facets under\nthe existing LCSH pseudo-facets.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Requirements for note",
            "content": "Hi,\n\nThis seems like a good moment to put out a call for suggestions for exactly\nwhat types of note (e.g. editor-note, hierarchy note) should be supported by\nSKOS-Core, and what each note should contain.\n\nCan I ask you to be as precise as possible in outlining what each type of\nnote should be used for.\n\nMany thanks,\n\nAlistair.\n\n\n\n"
        },
        {
            "subject": "Re: Low level AP",
            "content": "Nikki,\n\n1) Oops. I guess the getConceptRelativesByPath didn't register with me when \nI was working my way through the API, since it returns only an array of \nConcepts, which (as you point out) doesn't help much since there is no \nindication of distance or structure. I'm intrigued by your notion of \nsupporting another XML format (which I wonder?) and will stayed tuned for \nfurther updates...\n\n2) As for the use cases, Dan Brickley wrote :\n>I doubt we can specify the human-readable offerings of thesaurus\n>providers in such detail, beyond noting best practice conventions and\n>common useful UI conventions. What we can do, though, is take these\n>as use cases for evaluating the _machine_ interface defined in the SKOS\n>API. We can ask ourselves whether such a UI could be built against\n>any/all SKOS servers that meet the API. This opens up the prospect of\n>write-once, re-use elsewhere thesaurus browsing tools...\n\nDan's first point, about specifying the human-readable offerings of \nthesaurus providers is not a problem, that's been done (and is being \nrevised) in the appropriate national and international standards and in \nbest practices. What I was trying to help do was what Dan was suggesting in \nhis second point, that is, evaluating the appropriateness of the SKOS API \nfor building some of those common UIs. My comments are not intended as a \ncriticism of your work, this is complex stuff,  but I think there have been \na number of problem areas mentioned where the machine interface is not yet \nup to this task.\n\nIMHO this is (or should be) an important issue for SWAD, because it will \naffect adoption of the SKOS API. If thesaurus publishers have to support \none API to interact with the Semantic Web, and another interface to \ninteract with fully functioned thesaurus clients, then they will be \ninclined to implement _neither_. Having a single interface that will \nsupport a reasonably complete set of functionality (and there is a huge \noverlap) means everyone wins. For one thing, the API would be a machine \ninterface that those national and international thesaurus standards (now in \nthe process of being revised) would be able to endorse.\n\nRon\n--------------------------------------\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\nAt 16:46 11/05/2004, NJ Rogers, Learning and Research Technology wrote:\n\n>Hi Ron\n>\n>I am working as a technical developer on the SKOS API and a demo \n>implementation of it and very much welcome your input.\n>\n>A couple of initial points (in lieu of giving your references [1] and [3] \n>a proper read):\n>\n>\"the client has to do a great deal of work, and send out many\n>>atomic requests to be able to do certain kinds of required tasks, e.g.\n>>build a useful hierarchical display format\"\n>\n>1) We do provide (see http://www.w3.org/2001/sw/Europe/reports/thes/api/docs/)\n>methods such as\n>         getConceptRelativesByPath(Concept concept, Relation relation, URI \n> thesaurus, int distance)\n>\n>Which we describe as 'Get a list of concept relatives for a particular \n>thesaurus up to some distance.'\n>\n>And by 'up to some distance' we mean 'number of levels' in the sense that \n>I believe you to be talking about below.  So this avoids the need for \n>repetitive calls to the service to retrieve concepts 'clustered' around \n>some concept in the concept hierarchy. Instead, in response to these sorts \n>of service requests we intend to return sets of concepts. We haven't \n>finalised our strategy for indicating exactly how distant each result-set \n>concept is from a given point in the graph ... (And I note that this issue \n>relates to the syntax we use for encoding the response data the service \n>can send to the client. For our initial SOAP service implementation we are \n>using the soap data encoding syntax and will likely move on to include \n>support for XML as well as RDF/XML).\n>\n>2) You may well have already seen the use cases we're developing at \n>http://www.w3.org/2001/sw/Europe/200311/thes/Use_cases_Thes_Service.html \n>(in need of updating shortly, since I've received more contributions from \n>the community). I hadn't really imagined that client applications would \n>want to build extensive, browsable displays of concept hierarchies via the \n>network and 'on the fly' as it were. But this is an interesting point and \n>I wonder if we need to provide some harvesting capability on the service \n>as well....\n>\n>As I say, an initial response, thank you for your query,\n>regards\n>Nikki\n\n\n\n"
        },
        {
            "subject": "Quasi node label",
            "content": "In message \n<B56ABE145BEB0C40A265238FCAA420DF026F52BE@oa2-server.oa.oclc.org> on \nTue, 11 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n>\n>> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n>> Sent: Tuesday, May 11, 2004 10:43 AM\n>> Subject: Re: Supporting arrays of concepts\n>>\n>> 2. As regards node labels, I have tried to show that we need\n>> to distinguish between\n>>\n>>         (a) real \"node labels\", which specify a characteristic of \n>>division in the form <xxx by yyy> and\n>>\n>>         (b) broader concepts which act as parent terms to the  terms \n>>in a following array.\n>>\n>> DDC centred headings and some of the AAT guide terms fall  under (b), \n>>and should not be called node labels. Structurally  these are just \n>>terms representing concepts which the  thesaurus editor has decided \n>>are unsuitable for use in  indexing (and may have to be labelled in \n>>some way to indicate this).\n>\n>I think I agree with your idea of separating the two.  Maybe what is\n>needed is another element at the same level as skos:Concept, perhaps\n>skos:Summary, that handles (b)\n\nI think that calling it \"summary\" would confuse the issue, because these \nterms _do_ in fact represent concepts, and in the AAT for example they \ncan occur at any level. I'd prefer to see them treated as a sub-class of \nconcept, having the restriction that they are not to be used for \nindexing.\n\n>and the current proposal for handling (a).  Although the current \n>proposal seems odd to me.\n\nSorry, but I'm not clear exactly what you mean by \"the current proposal\" \n- are you referring to the definition of node label as in (a) above, or \nthe SKOS proposals for encoding these?\n\n>It seems to me that you might want to have additional metadata \n>associated with node label array in addition to the list of concepts \n>associated with it. For example scope notes or other types of notes.\n\nAgain, I'm not clear what you mean by \"node label array\". If you mean \nthe node label, as in (a), under which an array of concepts is listed, \nthen I suppose you might have a note clarifying the characteristic of \ndivision*, but that would be unusual. There would be no harm in \nproviding for such a note, but the main point is to avoid confusing node \nlabels with descriptors, i.e. terms that are labels for concepts.\n\n*(As an example, I suppose that the node label <people by occupation> \ncould have a note saying \"Occupation refers to a trade or profession in \nwhich a person is currently engaged for more than the equivalent of one \nday per week\". This is effectively extracting a common factor to avoid \nrepeating it in the scope notes of each of the concepts in the array.)\n\nLeonard Will\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Quasi node label",
            "content": "> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk] \n> Sent: Tuesday, May 11, 2004 6:17 PM\n> Subject: Quasi node labels\n> \n> I think that calling it \"summary\" would confuse the issue, \n> because these terms _do_ in fact represent concepts, and in \n> the AAT for example they can occur at any level. I'd prefer \n> to see them treated as a sub-class of concept, having the \n> restriction that they are not to be used for indexing.\n\nI agree, I thru out \"summary\" because I couldn't come up with\na better name and hoped someone else could.  I guess I should\nhave noted that in my message.  I have been debating whether \nthese should be a subclass of concept or not.  Regardless of\nwhether it is or is not, it still would be defined at the\nsame level as skos:concept.  So if I had:\n\nskos:NodeLabelB\n\nor \n\nskos:Concept\n+-- skos:NodeLabelB\n\nthe RDF serialization would still look like:\n\n<skos:NodeLabelB/>\n<skos:Concept/>\n\nSo it's just a matter of semantics whether you consider it a\nsubclass or not.  From a serialization point of view they are\nexactly at the same level.  One needs to decide whether this \ntruly is a subclass of concept.  I think it might be, but I keep\ngoing back an forth on that point.  I'll leave the semantics,\nto others, but I do think that SKOS does need to make the\ndistinction between (a) and (b) as you pointed out.\n\n> \n> >and the current proposal for handling (a).  Although the current \n> >proposal seems odd to me.\n> \n> Sorry, but I'm not clear exactly what you mean by \"the \n> current proposal\" \n\nI was referring to the original proposal that Miles posted for\ncomments.  I guess I switched topics without being clear on the\nmatter.  Sorry for the confusion.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Compound concepts in a thesaurus structur",
            "content": "In message \n<B56ABE145BEB0C40A265238FCAA420DF026F52BE@oa2-server.oa.oclc.org> on \nTue, 11 May 2004, \"Houghton,Andrew\" <houghtoa@oclc.org> wrote\n\n>If someone builds a class number, based upon the instructions in the \n>classification, then they can merely create an skos:Concept element and \n>within that element use the skos:inScheme to point to the \"official\" \n>base scheme which defines the list of predefined concepts.  Any built \n>concept in LCC, DDC, LCSH, or MeSH participate in same BT/NT \n>relationship established for the vocabulary.  So I seem to be missing \n>something with your analogy.\n>\n>You don't need to incorporate the rules for creating the compound \n>strings. The \"whole\" compound string *is* the concept and there isn't \n>necessarily a BT/NT relationship between the predefined part and what \n>was composed.  The whole term should be taken as the concept and its \n>BT/NT relationship is to be taken in the context of all the other \n>predefined or compound strings in the vocabulary.\n\nWell you could, but I think that you would run into difficulties if you \ntried to combine pre-coordinated strings like this into a thesaurus \nstructure. The following block of LCSH strings is taken from the LC \ncatalogue; certainly you could say that each of these represents a \nsingle compound concept, but I would have difficulty in giving these \nterms a useful set of  BT/NT relationships, and I don't think it \nrealistic for someone to do that for every such string that they create. \nThesaural relationships are normally between the simple concepts of \nwhich such strings are composed..\n\n\nAutomobile dealers.\nAutomobile dealers -- Arizona -- Biography.\nAutomobile dealers -- Brazil.\nAutomobile dealers -- China -- Handbooks, manuals, etc.\nAutomobile dealers -- Colorado Denver Metropolitan Area -- Supply and \ndemand -- Statistics -- Periodicals.\nAutomobile dealers -- Colorado History.\nAutomobile dealers -- Denmark Biography.\nAutomobile dealers -- Drama.\nAutomobile dealers -- Employees -- Fiction.\nAutomobile dealers -- Employees -- Juvenile literature.\nAutomobile dealers -- Employees -- Salaries, etc. -- California -- \nStatistics -- Periodicals.\nAutomobile dealers -- Employees, Training of -- Germany -- Case studies.\n\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Compound concepts in a thesaurus structur",
            "content": "> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk] \n> Sent: Tuesday, May 11, 2004 6:44 PM\n> Subject: Compound concepts in a thesaurus structure\n> \n> Well you could, but I think that you would run into \n> difficulties if you tried to combine pre-coordinated strings \n> like this into a thesaurus structure. The following block of \n> LCSH strings is taken from the LC catalogue; certainly you \n> could say that each of these represents a single compound \n> concept, but I would have difficulty in giving these terms a \n> useful set of  BT/NT relationships, and I don't think it \n> realistic for someone to do that for every such string that \n> they create. \n\nBut that's exactly what happens when librarians create a composed\nLCSH in their local catalog.  They evaluate the new concept against\nthe existing LCSH and add the appropriate BT/NT/RT relationships\nto the record they created.  No one said it was easy... that's why\ncopy cataloging is used so frequently.  Nobody really wants to do\nthe intellectual effort and many would prefer to wait until LC does\nit.  It's expensive to create metadata...\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "RE: Requirements for note",
            "content": "> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: Tuesday, May 11, 2004 1:17 PM\n> Subject: Requirements for notes\n>\n> This seems like a good moment to put out a call for \n> suggestions for exactly what types of note (e.g. editor-note, \n> hierarchy note) should be supported by SKOS-Core, and what \n> each note should contain.\n> \n> Can I ask you to be as precise as possible in outlining what \n> each type of note should be used for.\n\nHere is a survey of the note types in the vocabularies that I'm\ncurrently dealing with: LCC, DDC, LCSH, MeSH, FAST, GSAFD.  They\nbasically fall into three classes, MARC21-A, MARC21-C, and Dewey.\n\n\nMARC21-A Authorities Format\nhttp://www.loc.gov/marc/authority/ecadnote.html\n\n* 667 - NONPUBLIC GENERAL NOTE (R)\nGeneral information about a 1XX heading for which a specialized note field\nhas not been defined.\n\n* 670 - SOURCE DATA FOUND (R)\nA citation for a consulted source in which information is found about the\n1XX heading in an established heading record, an established heading and\nsubdivision record, a subdivision record or a reference record. The\ninformation found in the source may also be present.\n\n* 675 - SOURCE DATA NOT FOUND (NR)\nA citation for a consulted source in which no information is found about the\n1XX heading in an established heading record, an established heading and\nsubdivision record, or a subdivision record.\n\n* 678 - BIOGRAPHICAL OR HISTORICAL DATA (R)\nA summary of the essential biographical, historical, or other information\nabout the 1XX heading in an established heading record, an established\nheading and subdivision record, or a subdivision record.\n\n* 680 - PUBLIC GENERAL NOTE (R)\nGeneral information about a 1XX heading for which a specialized note field\nhas not been defined. The note is written in a form adequate for public\ndisplay.\n\n* 681 - SUBJECT EXAMPLE TRACING NOTE (R)\nDocuments the use of the 1XX subject or authorized subdivision heading as an\nexample or reference in fields 260, 360, and/or 680 in another authority\nrecord.\n\n* 682 - DELETED HEADING INFORMATION (NR)\nAn explanation for the deletion of an established heading or subdivision\nrecord from an authority file (Leader/05, value d). The replacement\nheading(s) may be contained in subfield(s) $a.\n\n* 688 - APPLICATION HISTORY NOTE (R)\nInformation that documents changes in the application of a 1XX heading.\n\n\nMARC21-C Classification Format\nhttp://www.loc.gov/marc/classification/eccdnote.html\n\n* 680 - SCOPE NOTE  (R)\nInformation about the classification number or number span in field 153\n(Classification Number) that describes its scope in the scheme identified in\nfield 084 (Classification Schedule and Edition).\n\n* 681 - CLASSIFICATION EXAMPLE TRACING NOTE (R)\nInformation that documents the use of the 153 classification number or\nnumber span in one record as an example or reference in fields 253, 353\nand/or 6XX note fields in another record.\n\nThis field is primarily intended to serve as a tracing of the use of\nclassification numbers in examples and notes to assist classifiers in\nupdating records. \n\n* 683 - APPLICATION INSTRUCTION NOTE (R)\nInstructions for applying tables, subarrangements, or additions to\nclassification numbers.\n\n* 684 - AUXILIARY INSTRUCTION NOTE (R)\nInformation from, or reference to, a section of a classifier's manual or\nother documentation. An auxiliary instruction note provides advice for\nclassifying in difficult areas, and describes policies and practices that\nmay accompany a classification schedule.\n\n* 685 - HISTORY NOTE (R)\nInformation about the history of the use and meaning of a classification\nnumber that is contained either in a 153 classification number field or in a\n453/553 tracing field with subfield $w/3, Control subfield, code a.\n\n* 686 - RELATIONSHIP TO SOURCE NOTE (R)\nInformation about the relationship of a number to the source edition when\nthe number is different from the standard number for the same topic in the\nprimary source edition. This field is used for numbers based on a source\nother than the primary source, expansions, implemented options, and\nadaptations. The information in this field is intended primarily for\ncomputer processing or to guide classifiers and is often not written in a\nform adequate for public user display.\n\n\nDewey\n\n* ADD NOTE - GENERIC INSTRUCTION\n* ADD NOTE - IDENTIFIED BY SYMBOL\n* ADD NOTE - SCHEDULE NUMBER, PART OF \n* ADD NOTE - SCHEDULE NUMBER, FULL \n* ADD NOTE - TABLE NUMBER, PART OF \n* ADD NOTE - TABLE NUMBER, ADD OF \n* ADD NOTE - REFERRAL TO TABLE\n* ADD NOTE - SEE REFERENCE\n* ADD NOTE - SEE REFERENCE, SCATTERED\n* ADD NOTE - STANDARD SUBDIVISIONS, ARE ADDED\n* ADD NOTE - STANDARD SUBDIVISIONS, DO NOT ADD\n* ADD NOTE - SUBDIVISIONS\n* ADD TABLE NOTE - GENERIC INSTRUCTION\n* ADD TABLE NOTE - IDENTIFIED BY SYMBOL\n* ADD TABLE NOTE - SCHEDULE NUMBER, PART OF\n* ADD TABLE NOTE - TABLE NUMBER, ALL\n* ADD TABLE NOTE - TABLE NUMBER, PART OF\n* ARRANGE ALPHABETICALLY NOTE\n* ARRANGE BY AUTHOR NOTE\n* ARRANGE CHRONOLOGICALLY NOTE\n* ARRANGE NUMERICALLY NOTE\n* ARRANGE BY TITLE NOTE\n* BUILD NOTE\n* BUILT NUMBER NOTE\n* CLASS HERE NOTE\n* CLASS ELSEWHERE NOTE\n* CLASS ELSEWHERE NOTE - SCATTERED\n* DEFINITION NOTE\n* DISCONTINUED NOTE - VACATED NUMBER\n* DISCONTINUED NOTE - PARTIALLY CHANGED NUMBER\n* EDITOR NOTE\n* EDITOR NOTE - FLAG\n* FOOTNOTE - ADD\n* FOOTNOTE - GENERIC\n* FOOTNOTE - OPTION\n* FOOTNOTE - STANDARD SUBDIVISIONS\n* FOOTNOTE - STANDARD SUBDIVISIONS, DO NOT ADD\n* FOOTNOTE - STANDARD SUBDIVISIONS, EXTRA ZEROS\n* FOOTNOTE - STANDARD SUBDIVISIONS, MODIFIED\n* FOOTNOTE - TABLE 2\n* FORMER HEADING NOTE\n* INCLUDING NOTE\n* MANUAL NOTE\n* MANUAL NOTE, LIKE\n* MOST RECENTLY USED NOTE\n* NEW SCHEDULE NOTE\n* NOTATION NOTE - DO NOT USE\n* OPTION NOTE\n* OPTIONAL NUMBER NOTE\n* PREFERENCE NOTE\n* REFERENCE NOTE - SEE ALSO\n* REFERENCE NOTE - SEE\n* REFERENCE NOTE - SEE MANUAL\n* REFERENCE NOTE - SEE SCATTERED\n* RELOCATION NOTE\n* RELOCATION NOTE - ADD\n* RELOCATION NOTE - VACATED NUMBER\n* RELOCATION NOTE - PARTIALLY CHANGED NUMBER\n* REVISION NOTE - COMPLETELY\n* REVISION NOTE - EXTENSIVELY\n* SCOPE NOTE\n* SEGMENTATION NOTE\n* SEMIHIERARCHICAL NOTE\n* STANDARD SUBDIVISIONS NOTE - MODIFIED\n* STANDARD SUBDIVISIONS NOTE - REOCCURRING IRREGULARITIES\n* TABLE NOTE - BUILD\n* TABLE NOTE - GENERIC\n* TABLE NOTE - OPTION\n* TABLE NOTE - PREFERENCE\n* VARIANT NAME NOTE\n\n\nI think I got most of the important Dewey notes...  I decided to skip the\ndefinitions for Dewey since many of them are specific to Dewey itself.  But\nI did rename the notes from what the Dewey editors use so they could be\nclassified into groups so they could be compared with other vocabulary note\ntypes and to discover cross vocabulary similarities.  From the list you can\nsee the diversity of notes in Dewey compared with MARC21-A and MARC21-C.\nThere are patterns to the Dewey note types.\n\nFirst, let me *emphatically* say:\n  I don't feel that SKOS *should support* all these note types.\n\nThat wouldn't be useful since few vocabularies need to or go into such\ndetail.  However, I do see a group of base note types that could be useful\nfor thesauri, subject headings, classification, etc. and a mechanism to\nextend the base note types for specific purposes.\n\nLooking at the original SKOS proposal it had the following note types\ndefined in the RDF schema: skos:scopeNote, skos:generalNote,\nskos:hierarchyNote, skos:editorNote, and skos:historyNote.  Lets just take\nthese and see how MARC21-A, MARC21-C and Dewey fit in.  Note, I didn't find\nan SKOS definition of what each of these note types means, so what follows\nis based upon my *interpretation*.  I think Miles eluded to the fact that\ndefinitions *need* to go along with the SKOS elements, or scope notes for\nnote types.\n\nSKOS                MARC21-A  MARC21-C  Dewey\n------------------  --------  --------  -------------\n\nscopeNote            680       680      SCOPE NOTE\n                               683      CLASS HERE NOTE\n                               684      CLASS ELSEWHERE NOTE\n                                        CLASS ELSEWHERE NOTE - SCATTERED\n                                        DEFINITION NOTE [5]\n                                        INCLUDING NOTE\n                                        OPTION NOTE\n                                        PREFERENCE NOTE\n\ngeneralNote [1]      667 [2]   686 [6]  Probably most everything else goes\nhere,\n                                          with a few exceptions [6]\n\nhierarchyNote [4]                       SEMIHIERARCHICAL NOTE\n\neditorNote           667                EDITOR NOTE\n                                        EDITOR NOTE - FLAG\n\nhistoryNote          678       685      DISCONTINUED NOTE - VACATED NUMBER\n                     682                DISCONTINUED NOTE - PARTIALLY\nCHANGED NUMBER\n                     688                FORMER HEADING NOTE\n                                        MOST RECENTLY USED NOTE\n                                        NEW SCHEDULE NOTE\n                                        RELOCATION NOTE\n                                        RELOCATION NOTE - ADD\n                                        RELOCATION NOTE - VACATED NUMBER\n                                        RELOCATION NOTE - PARTIALLY CHANGED\nNUMBER\n                                        REVISION NOTE - COMPLETELY\n                                        REVISION NOTE - EXTENSIVELY\n\nexample              670 [3]   681      \n                     675 [3]            \n                     681                \n                                        \n\n\n[1] Public or non-public?\n[2] Assumption is non-public.\n[3] A citation could roughly be considered an example,\n    but this doesn't fit well.\n[4] What's the scope for this?\n[5] A definition could roughly be considered a scope note, \n    but this doesn't fit well.\n[6] Assumption is public.\n\n\nThere are some places where the Dewey notes don't fit well.  One area of\nconcern is the VARIANT NAME NOTES.  In Dewey the preferred term is the class\nnumber.  There are many alternate labels, such as the captions associated\nwith the class number from the various translations.  Variant names really\naren't alternate labels for the concept, per say, but the also aren't\nstrictly notes either.  Kind of mixture of the two...  We still aren't sure\nhow to resolve this issue.  I also lumped a lot of stuff in skos:generalNote\nthat probably shouldn't belong their.\n\nFrom these vocabularies I can start to see some patterns.  There are\ndistinctions between public vs. private notes which roughly could fit\nskos:scopeNote vs. skos:editorNote.  However, public notes do not\nnecessarily have to have a scope relationship to the concept.  So the\ndefinition of skos:scopeNote needs a better definition.  For me a scopeNote\ndefines what is or is not in code for the concept.  This would include\nthings like when to use the concept, when not to use the concept, what is\nincluded with the concept, what is not included with the concept, and\noptional or restricted information for using the concept.  A public note is\njust that, a note for public consumption that doesn't relate to the scope of\nthe concept.  Probably not the best definition.\n\nThere are distinctions between editor vs. private notes but in my mind its\ndifficult to say where the line is, e.g. when does a private note become a\neditorial note?  The skos:editorNote could cover both and if the vocabulary\nmaintainer needs to make that distinction it could.  Or better yet you could\nhave skos:editorNote subclass skos:privateNote which subclasses skos:Note.\nIf someone needs to make a different distinction between an skos:editorNote\nand another form of private note they can just subclass skos:privateNote.\nSo maybe a class hierarchy might look like:\n\nskos:Note\n\n  skos:publicNote\n    skos:scopeNote\n    skos:historyNote\n\n  skos:privateNote\n    skos:editorNote\n\nI noted an issue with skos:generalNote, is it public or private?  I think\nthat skos:historyNote is a good generic note type to build different types\nof history notes upon.\n\nBreaking down the MARC21 note formats, we can see the following:\n\n* public notes\n* non-public notes\n* scope notes\n* history notes\n* citation notes\n* application notes\n* general notes\n* examples\n\nBreaking down the Dewey note formats, we can see the following:\n\n* public notes\n* non-public notes\n* scope notes\n* history notes\n* citation notes\n* application notes\n* general notes\n* examples\n* hierarchy notes (not sure whether definition matches SKOS)\n* reference notes\n* arrangement notes\n\nIf I were to suggest a class hierachy for these three vocabularies, it might\nlook something like:\n\nskos:definition\n  - a definition of the concept, useful for encoding dictionaries,\n    jargon, acronym, abbreviations; this is really another form of\n    specialized note, should it be a subclass of skos:Note or\n    skos:publicNote?\n\nskos:example\n  - examples of the usage for the existing concept; this is\n    really another form of specialized note, should it be\n    a subclass of skos:Note or skos:publicNote?\n\nskos:Note\n  - generic class for notes that allows subclassing for \n    specialized note types\n\n  skos:publicNote\n    - generic class for public notes that allows subclassing\n      for specialized note types\n\n    skos:applicationNote\n      - defines instructions for applying tables, subarrangements,\n        or additions to construct new concepts based upon the\n        existing concept\n\n    skos:arrangementNote\n      - defines how to arrange items under the concept\n\n    skos:citationNote\n      - defines a citation of a consulted source for defining\n        the existing concept\n\n    skos:generalNote\n      - defines general information for which a specialized \n        note type has not been defined \n\n    skos:hierarchyNote\n      - [needs a definition]\n\n    skos:historyNote\n      - defines information about the history or past use and \n        meaning of the concept\n\n    skos:referenceNote\n      - defines other places that the person might wish to\n        consider when evaluating the concept for use; these\n        places are outside the scope of the BT/NT/RT semantic\n        relationships\n\n    skos:scopeNote\n      - defines what is or is not in code for the concept and\n        would include things like when to use the concept, \n        when not to use the concept, what is included with \n        the concept, what is not included with the concept, \n        and optional or restricted information for using the \n        concept.  \n\n  skos:privateNote\n    - generic class for non-public, e.g. private, notes that\n      allows subclassing for specialized note types\n\n    skos:editorNote\n      - a note for an editor, translator or maintainer\n        of the vocabulary\n\n\nGiven the above response, I realize that this was a very long message to\nread through, perhaps people who deal with other vocabularies could share\nthe note types they find in them and some broad note type categories that\ncould be generalized for SKOS use.  I have provided a start and the dart\nboard.  Feel free to plunder these ideas and see how other vocabularies fit\nwithin the definitions.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "RE: Compound concepts in a thesaurus structur",
            "content": "Maybe I am missing the point here, but we seem to have jumped from\ntalking about exchanging vocabulary data to the exchange of catalogue\ndata. I thought SKOS was addressing the former, but not the latter. The\nrelationships in a thesaurus are supposed to be paradigmatic, not\nsyntagmatic. But a catalogue or index typically sets up syntagmatic\nrelationships ( i.e. the sort to be found in the context of one\nparticular document), which leads us into the difficulty outlined by\nLeonard. \n\nSorry if this comment is incomplete. I should perhaps say much more, but\nam having great difficulty keeping up with the quantity of interesting\ncorrespondence on this list.\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Houghton,Andrew\nSent: 11 May 2004 23:54\nTo: public-esw-thes@w3.org\nSubject: RE: Compound concepts in a thesaurus structure\n\n\n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Tuesday, May 11, 2004 6:44 PM\n> Subject: Compound concepts in a thesaurus structure\n> \n> Well you could, but I think that you would run into\n> difficulties if you tried to combine pre-coordinated strings \n> like this into a thesaurus structure. The following block of \n> LCSH strings is taken from the LC catalogue; certainly you \n> could say that each of these represents a single compound \n> concept, but I would have difficulty in giving these terms a \n> useful set of  BT/NT relationships, and I don't think it \n> realistic for someone to do that for every such string that \n> they create. \n\nBut that's exactly what happens when librarians create a composed LCSH\nin their local catalog.  They evaluate the new concept against the\nexisting LCSH and add the appropriate BT/NT/RT relationships to the\nrecord they created.  No one said it was easy... that's why copy\ncataloging is used so frequently.  Nobody really wants to do the\nintellectual effort and many would prefer to wait until LC does it.\nIt's expensive to create metadata...\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Re: Compound concepts in a thesaurus structur",
            "content": "In message <000501c437fb$fea39970$0402a8c0@DELL> on Wed, 12 May 2004, \nStella Dextre Clarke <sdclarke@lukehouse.demon.co.uk> wrote\n>\n>Maybe I am missing the point here, but we seem to have jumped from\n>talking about exchanging vocabulary data to the exchange of catalogue\n>data. I thought SKOS was addressing the former, but not the latter. The\n>relationships in a thesaurus are supposed to be paradigmatic, not\n>syntagmatic. But a catalogue or index typically sets up syntagmatic\n>relationships ( i.e. the sort to be found in the context of one\n>particular document), which leads us into the difficulty outlined by\n>Leonard.\n\nI think that Andy is thinking of SKOS as maintaining a subject authority \nfile, including all the simple and compound concepts that are either \nenumerated in schedules or that have been used in creating catalogue \nentries. This is very different from a thesaurus, as you say, and adds a \nwhole new dimension of complexity. If this is to be done I think it \nwould be better to keep the thesaurus and the subject authority file in \nseparate databases.\n\nLeonard\n\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: Requirements for note",
            "content": "To add to Andy's catalogue of notes, here is what we have so far in the\ndraft Parts 1 and 2 of BS8723:\n\nOnly three types of note field are mentioned: Scope note, History note\nand Editorial note, defined as follows.\n\nScope note:  \"note which defines or clarifies the meaning of a concept\nas it is used in the structured vocabulary\"\n\nHistory note:   \"A history note may record the date of introduction, or\nit may give more complex advice on how to search for the concept in\nearlier or later times.\"\n\nThere is no explicit definition of an editorial note, but it is\nrecommended as a housekeeping field rather than a field for display to\nusers, and there is this advice: 'An editorial note is useful for\nentries such as \"Review this term after the company merger complete\" or\n\"This term is mentioned in the scope note of term X\" ' NB notes of the\nlatter type may also be made in reciprocal scope notes, if appropriate,\nand this is set out in the draft.\n\nThe standard does not exclude other types of note, only it does not make\nany requirement for them, nor does it expect them to be used in a\nstandardised way.\n\nBS8723 Parts 1 and 2 will in time supersede BS5723, which deals with\nmonolingual thesauri. Drafts for Public Comment will be published\nshortly. It is hoped the comments and later the fully-fledged standard\nwill lead on to revision of the international standard ISO 2788.\nComments are welcomed at any stage, and we hope the SKOS work will feed\nin to the eventual Part 5.\n\nStella\nConvenor of the Working Group for BS8723\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Houghton,Andrew\nSent: 12 May 2004 00:36\nTo: 'public-esw-thes@w3.org'\nSubject: RE: Requirements for notes\n\n\n\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> Sent: Tuesday, May 11, 2004 1:17 PM\n> Subject: Requirements for notes\n>\n> This seems like a good moment to put out a call for\n> suggestions for exactly what types of note (e.g. editor-note, \n> hierarchy note) should be supported by SKOS-Core, and what \n> each note should contain.\n> \n> Can I ask you to be as precise as possible in outlining what\n> each type of note should be used for.\n\nHere is a survey of the note types in the vocabularies that I'm\ncurrently dealing with: LCC, DDC, LCSH, MeSH, FAST, GSAFD.  They\nbasically fall into three classes, MARC21-A, MARC21-C, and Dewey.\n\n\nMARC21-A Authorities Format\nhttp://www.loc.gov/marc/authority/ecadnote.html\n\n* 667 - NONPUBLIC GENERAL NOTE (R)\nGeneral information about a 1XX heading for which a specialized note\nfield has not been defined.\n\n* 670 - SOURCE DATA FOUND (R)\nA citation for a consulted source in which information is found about\nthe 1XX heading in an established heading record, an established heading\nand subdivision record, a subdivision record or a reference record. The\ninformation found in the source may also be present.\n\n* 675 - SOURCE DATA NOT FOUND (NR)\nA citation for a consulted source in which no information is found about\nthe 1XX heading in an established heading record, an established heading\nand subdivision record, or a subdivision record.\n\n* 678 - BIOGRAPHICAL OR HISTORICAL DATA (R)\nA summary of the essential biographical, historical, or other\ninformation about the 1XX heading in an established heading record, an\nestablished heading and subdivision record, or a subdivision record.\n\n* 680 - PUBLIC GENERAL NOTE (R)\nGeneral information about a 1XX heading for which a specialized note\nfield has not been defined. The note is written in a form adequate for\npublic display.\n\n* 681 - SUBJECT EXAMPLE TRACING NOTE (R)\nDocuments the use of the 1XX subject or authorized subdivision heading\nas an example or reference in fields 260, 360, and/or 680 in another\nauthority record.\n\n* 682 - DELETED HEADING INFORMATION (NR)\nAn explanation for the deletion of an established heading or subdivision\nrecord from an authority file (Leader/05, value d). The replacement\nheading(s) may be contained in subfield(s) $a.\n\n* 688 - APPLICATION HISTORY NOTE (R)\nInformation that documents changes in the application of a 1XX heading.\n\n\nMARC21-C Classification Format\nhttp://www.loc.gov/marc/classification/eccdnote.html\n\n* 680 - SCOPE NOTE  (R)\nInformation about the classification number or number span in field 153\n(Classification Number) that describes its scope in the scheme\nidentified in field 084 (Classification Schedule and Edition).\n\n* 681 - CLASSIFICATION EXAMPLE TRACING NOTE (R)\nInformation that documents the use of the 153 classification number or\nnumber span in one record as an example or reference in fields 253, 353\nand/or 6XX note fields in another record.\n\nThis field is primarily intended to serve as a tracing of the use of\nclassification numbers in examples and notes to assist classifiers in\nupdating records. \n\n* 683 - APPLICATION INSTRUCTION NOTE (R)\nInstructions for applying tables, subarrangements, or additions to\nclassification numbers.\n\n* 684 - AUXILIARY INSTRUCTION NOTE (R)\nInformation from, or reference to, a section of a classifier's manual or\nother documentation. An auxiliary instruction note provides advice for\nclassifying in difficult areas, and describes policies and practices\nthat may accompany a classification schedule.\n\n* 685 - HISTORY NOTE (R)\nInformation about the history of the use and meaning of a classification\nnumber that is contained either in a 153 classification number field or\nin a 453/553 tracing field with subfield $w/3, Control subfield, code a.\n\n* 686 - RELATIONSHIP TO SOURCE NOTE (R)\nInformation about the relationship of a number to the source edition\nwhen the number is different from the standard number for the same topic\nin the primary source edition. This field is used for numbers based on a\nsource other than the primary source, expansions, implemented options,\nand adaptations. The information in this field is intended primarily for\ncomputer processing or to guide classifiers and is often not written in\na form adequate for public user display.\n\n\nDewey\n\n* ADD NOTE - GENERIC INSTRUCTION\n* ADD NOTE - IDENTIFIED BY SYMBOL\n* ADD NOTE - SCHEDULE NUMBER, PART OF \n* ADD NOTE - SCHEDULE NUMBER, FULL \n* ADD NOTE - TABLE NUMBER, PART OF \n* ADD NOTE - TABLE NUMBER, ADD OF \n* ADD NOTE - REFERRAL TO TABLE\n* ADD NOTE - SEE REFERENCE\n* ADD NOTE - SEE REFERENCE, SCATTERED\n* ADD NOTE - STANDARD SUBDIVISIONS, ARE ADDED\n* ADD NOTE - STANDARD SUBDIVISIONS, DO NOT ADD\n* ADD NOTE - SUBDIVISIONS\n* ADD TABLE NOTE - GENERIC INSTRUCTION\n* ADD TABLE NOTE - IDENTIFIED BY SYMBOL\n* ADD TABLE NOTE - SCHEDULE NUMBER, PART OF\n* ADD TABLE NOTE - TABLE NUMBER, ALL\n* ADD TABLE NOTE - TABLE NUMBER, PART OF\n* ARRANGE ALPHABETICALLY NOTE\n* ARRANGE BY AUTHOR NOTE\n* ARRANGE CHRONOLOGICALLY NOTE\n* ARRANGE NUMERICALLY NOTE\n* ARRANGE BY TITLE NOTE\n* BUILD NOTE\n* BUILT NUMBER NOTE\n* CLASS HERE NOTE\n* CLASS ELSEWHERE NOTE\n* CLASS ELSEWHERE NOTE - SCATTERED\n* DEFINITION NOTE\n* DISCONTINUED NOTE - VACATED NUMBER\n* DISCONTINUED NOTE - PARTIALLY CHANGED NUMBER\n* EDITOR NOTE\n* EDITOR NOTE - FLAG\n* FOOTNOTE - ADD\n* FOOTNOTE - GENERIC\n* FOOTNOTE - OPTION\n* FOOTNOTE - STANDARD SUBDIVISIONS\n* FOOTNOTE - STANDARD SUBDIVISIONS, DO NOT ADD\n* FOOTNOTE - STANDARD SUBDIVISIONS, EXTRA ZEROS\n* FOOTNOTE - STANDARD SUBDIVISIONS, MODIFIED\n* FOOTNOTE - TABLE 2\n* FORMER HEADING NOTE\n* INCLUDING NOTE\n* MANUAL NOTE\n* MANUAL NOTE, LIKE\n* MOST RECENTLY USED NOTE\n* NEW SCHEDULE NOTE\n* NOTATION NOTE - DO NOT USE\n* OPTION NOTE\n* OPTIONAL NUMBER NOTE\n* PREFERENCE NOTE\n* REFERENCE NOTE - SEE ALSO\n* REFERENCE NOTE - SEE\n* REFERENCE NOTE - SEE MANUAL\n* REFERENCE NOTE - SEE SCATTERED\n* RELOCATION NOTE\n* RELOCATION NOTE - ADD\n* RELOCATION NOTE - VACATED NUMBER\n* RELOCATION NOTE - PARTIALLY CHANGED NUMBER\n* REVISION NOTE - COMPLETELY\n* REVISION NOTE - EXTENSIVELY\n* SCOPE NOTE\n* SEGMENTATION NOTE\n* SEMIHIERARCHICAL NOTE\n* STANDARD SUBDIVISIONS NOTE - MODIFIED\n* STANDARD SUBDIVISIONS NOTE - REOCCURRING IRREGULARITIES\n* TABLE NOTE - BUILD\n* TABLE NOTE - GENERIC\n* TABLE NOTE - OPTION\n* TABLE NOTE - PREFERENCE\n* VARIANT NAME NOTE\n\n\nI think I got most of the important Dewey notes...  I decided to skip\nthe definitions for Dewey since many of them are specific to Dewey\nitself.  But I did rename the notes from what the Dewey editors use so\nthey could be classified into groups so they could be compared with\nother vocabulary note types and to discover cross vocabulary\nsimilarities.  From the list you can see the diversity of notes in Dewey\ncompared with MARC21-A and MARC21-C. There are patterns to the Dewey\nnote types.\n\nFirst, let me *emphatically* say:\n  I don't feel that SKOS *should support* all these note types.\n\nThat wouldn't be useful since few vocabularies need to or go into such\ndetail.  However, I do see a group of base note types that could be\nuseful for thesauri, subject headings, classification, etc. and a\nmechanism to extend the base note types for specific purposes.\n\nLooking at the original SKOS proposal it had the following note types\ndefined in the RDF schema: skos:scopeNote, skos:generalNote,\nskos:hierarchyNote, skos:editorNote, and skos:historyNote.  Lets just\ntake these and see how MARC21-A, MARC21-C and Dewey fit in.  Note, I\ndidn't find an SKOS definition of what each of these note types means,\nso what follows is based upon my *interpretation*.  I think Miles eluded\nto the fact that definitions *need* to go along with the SKOS elements,\nor scope notes for note types.\n\nSKOS                MARC21-A  MARC21-C  Dewey\n------------------  --------  --------  -------------\n\nscopeNote            680       680      SCOPE NOTE\n                               683      CLASS HERE NOTE\n                               684      CLASS ELSEWHERE NOTE\n                                        CLASS ELSEWHERE NOTE - SCATTERED\n                                        DEFINITION NOTE [5]\n                                        INCLUDING NOTE\n                                        OPTION NOTE\n                                        PREFERENCE NOTE\n\ngeneralNote [1]      667 [2]   686 [6]  Probably most everything else\ngoes\nhere,\n                                          with a few exceptions [6]\n\nhierarchyNote [4]                       SEMIHIERARCHICAL NOTE\n\neditorNote           667                EDITOR NOTE\n                                        EDITOR NOTE - FLAG\n\nhistoryNote          678       685      DISCONTINUED NOTE - VACATED\nNUMBER\n                     682                DISCONTINUED NOTE - PARTIALLY\nCHANGED NUMBER\n                     688                FORMER HEADING NOTE\n                                        MOST RECENTLY USED NOTE\n                                        NEW SCHEDULE NOTE\n                                        RELOCATION NOTE\n                                        RELOCATION NOTE - ADD\n                                        RELOCATION NOTE - VACATED NUMBER\n                                        RELOCATION NOTE - PARTIALLY\nCHANGED NUMBER\n                                        REVISION NOTE - COMPLETELY\n                                        REVISION NOTE - EXTENSIVELY\n\nexample              670 [3]   681      \n                     675 [3]            \n                     681                \n                                        \n\n\n[1] Public or non-public?\n[2] Assumption is non-public.\n[3] A citation could roughly be considered an example,\n    but this doesn't fit well.\n[4] What's the scope for this?\n[5] A definition could roughly be considered a scope note, \n    but this doesn't fit well.\n[6] Assumption is public.\n\n\nThere are some places where the Dewey notes don't fit well.  One area of\nconcern is the VARIANT NAME NOTES.  In Dewey the preferred term is the\nclass number.  There are many alternate labels, such as the captions\nassociated with the class number from the various translations.  Variant\nnames really aren't alternate labels for the concept, per say, but the\nalso aren't strictly notes either.  Kind of mixture of the two...  We\nstill aren't sure how to resolve this issue.  I also lumped a lot of\nstuff in skos:generalNote that probably shouldn't belong their.\n\nFrom these vocabularies I can start to see some patterns.  There are\ndistinctions between public vs. private notes which roughly could fit\nskos:scopeNote vs. skos:editorNote.  However, public notes do not\nnecessarily have to have a scope relationship to the concept.  So the\ndefinition of skos:scopeNote needs a better definition.  For me a\nscopeNote defines what is or is not in code for the concept.  This would\ninclude things like when to use the concept, when not to use the\nconcept, what is included with the concept, what is not included with\nthe concept, and optional or restricted information for using the\nconcept.  A public note is just that, a note for public consumption that\ndoesn't relate to the scope of the concept.  Probably not the best\ndefinition.\n\nThere are distinctions between editor vs. private notes but in my mind\nits difficult to say where the line is, e.g. when does a private note\nbecome a editorial note?  The skos:editorNote could cover both and if\nthe vocabulary maintainer needs to make that distinction it could.  Or\nbetter yet you could have skos:editorNote subclass skos:privateNote\nwhich subclasses skos:Note. If someone needs to make a different\ndistinction between an skos:editorNote and another form of private note\nthey can just subclass skos:privateNote. So maybe a class hierarchy\nmight look like:\n\nskos:Note\n\n  skos:publicNote\n    skos:scopeNote\n    skos:historyNote\n\n  skos:privateNote\n    skos:editorNote\n\nI noted an issue with skos:generalNote, is it public or private?  I\nthink that skos:historyNote is a good generic note type to build\ndifferent types of history notes upon.\n\nBreaking down the MARC21 note formats, we can see the following:\n\n* public notes\n* non-public notes\n* scope notes\n* history notes\n* citation notes\n* application notes\n* general notes\n* examples\n\nBreaking down the Dewey note formats, we can see the following:\n\n* public notes\n* non-public notes\n* scope notes\n* history notes\n* citation notes\n* application notes\n* general notes\n* examples\n* hierarchy notes (not sure whether definition matches SKOS)\n* reference notes\n* arrangement notes\n\nIf I were to suggest a class hierachy for these three vocabularies, it\nmight look something like:\n\nskos:definition\n  - a definition of the concept, useful for encoding dictionaries,\n    jargon, acronym, abbreviations; this is really another form of\n    specialized note, should it be a subclass of skos:Note or\n    skos:publicNote?\n\nskos:example\n  - examples of the usage for the existing concept; this is\n    really another form of specialized note, should it be\n    a subclass of skos:Note or skos:publicNote?\n\nskos:Note\n  - generic class for notes that allows subclassing for \n    specialized note types\n\n  skos:publicNote\n    - generic class for public notes that allows subclassing\n      for specialized note types\n\n    skos:applicationNote\n      - defines instructions for applying tables, subarrangements,\n        or additions to construct new concepts based upon the\n        existing concept\n\n    skos:arrangementNote\n      - defines how to arrange items under the concept\n\n    skos:citationNote\n      - defines a citation of a consulted source for defining\n        the existing concept\n\n    skos:generalNote\n      - defines general information for which a specialized \n        note type has not been defined \n\n    skos:hierarchyNote\n      - [needs a definition]\n\n    skos:historyNote\n      - defines information about the history or past use and \n        meaning of the concept\n\n    skos:referenceNote\n      - defines other places that the person might wish to\n        consider when evaluating the concept for use; these\n        places are outside the scope of the BT/NT/RT semantic\n        relationships\n\n    skos:scopeNote\n      - defines what is or is not in code for the concept and\n        would include things like when to use the concept, \n        when not to use the concept, what is included with \n        the concept, what is not included with the concept, \n        and optional or restricted information for using the \n        concept.  \n\n  skos:privateNote\n    - generic class for non-public, e.g. private, notes that\n      allows subclassing for specialized note types\n\n    skos:editorNote\n      - a note for an editor, translator or maintainer\n        of the vocabulary\n\n\nGiven the above response, I realize that this was a very long message to\nread through, perhaps people who deal with other vocabularies could\nshare the note types they find in them and some broad note type\ncategories that could be generalized for SKOS use.  I have provided a\nstart and the dart board.  Feel free to plunder these ideas and see how\nother vocabularies fit within the definitions.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Re: Requirements for note",
            "content": "Alistair,\n\nAt 19:16 11/05/2004, you wrote:\n>This seems like a good moment to put out a call for suggestions for exactly\n>what types of note (e.g. editor-note, hierarchy note) should be supported by\n>SKOS-Core, and what each note should contain.\n\nI'm not sure that it's really necessary to try to specify a wide range of \ndifferent possible kinds of notes. This seems to me to be a case where your \nidea of subclassing and inheritance is going to be really useful (the other \nis the different types of hierarchical relationship such as partitive, \ngeneric, etc.). I think it's important, as Andy suggests, to distinguish \nbetween public and private notes, since these may be handled in different \nways, but for the rest, I'm not sure it matters a lot. A scope note, a \nhistory note, and some kind of internal note are the ones that I have seen \nmost often, but others have a lot more experience with this.\n\nI'm still a little concerned about delivering all of these notes every time \nwe access a Concept. I would say normally in a _thesaurus_ application at \nleast there's a continuum of how often information gets used, something \nlike this:\n\nMost often used       Concept identification and label information\n         |\n         |                       Relationship information (BTs, NTs, RTs)\n         V\nLeast often used      Notes information\n\nThe Concept object combines the most often used information with the least \noften used information. Sometimes these notes can be very long (Andy is \nperhaps in a good position to confirm or deny my fears here). So the API \nmay be delivering a lot of textual information with Concepts that will only \nbe used a very small percentage of the time. Maybe in practice this \noverhead won't matter, but it's an issue perhaps to evaluate.\n\nRon\n\n\nRon Davies\nInformation and documentation systems consultant\nAv. Baden-Powell 1  Bte 2, 1200 Brussels, Belgium\nEmail:  ron@rondavies.be\nTel:    +32 (0)2 770 33 51\nGSM:    +32 (0)484 502 393\n\n\n\n"
        },
        {
            "subject": "RE: Requirements for note",
            "content": "Hi!\nI would suggest that instruction/application note (683/684/681) need to\nbe clearly encoded and \ndistinct from scopeNotes.  It does not matter whether it is put as a\nsub-type of \nscopeNote or as separate providing it is made machine readable.\n\n-----------------------------------------\nscopeNote            680       680      SCOPE NOTE\n                               683      CLASS HERE NOTE\n                               684      CLASS ELSEWHERE NOTE\n                                        CLASS ELSEWHERE NOTE - SCATTERED\n                                        DEFINITION NOTE [5]\n                                        INCLUDING NOTE\n                                        OPTION NOTE\n                                        PREFERENCE NOTE\n-----------------------------------------------------------------\nscopeNote is usually a simple text. Application note holds the rules  to\nsupport\nindexing tool creation which ought  to be automated (Librarians like to\nthink of\nhyperlinks and 'window-popping' offering terms to be combined :-) ) \n\nInstruction/application notes can be further subdivided and are likely\nto be different for every system\nas is well demonstrated in Andrew's example.\n(For those not familiar with knowledge classification systems these\nnotes exist as every system deploys some kind\nof economy in reusing already listed concepts suggesting the\ncombinations and concept building to avoid\nrepeating and enumeration. E.g.  hierarchy of places, languages,\ncolours, plants, chemical elements etc. will be used \nin many knowledge areas.  Analytico-synthetic classification are\nstructured relationally and general rules \nwork for the whole system so they have less  of 'situational notes'.\nEnumerative systems (Dewey, LCC) have to \nrecord such a possibility for each number or span of numbers - hence the\ncomplexity of Dewey's notes in \nAndrew's example)\n\nBut even assuming all these differences all general and special\nclassifications of knowledge have the following\nkind of Instruction/application notes in common:\n\ni) limiting/linking the use of term for certain area of vocabulary:\ndo(not) use with -->.., (not)valid for -->... \nif ...prefer this --> \n\nii) further divide/denote with/as  -->... (links the auxiliary tables,\nfloating divisions etc.);\n divide as  -->  'parallel division'  (links the part of the schedule\nthat contains hierarchy that needs to be copied)\n\niii) examples of combination (in supporting above rules e.g. parallel\ndivision, combination with auxilairy number\nor number from other table)\n\nThis does not mean that SKOS should go into these fine distinctions.\nThis is more to stress that there\nmay be  the reason for keeping this kind of note separate. \n\n\nAida\n\n\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Houghton,Andrew\nSent: 12 May 2004 00:36\nTo: 'public-esw-thes@w3.org'\nSubject: RE: Requirements for notes\n\n\n\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk]\n> Sent: Tuesday, May 11, 2004 1:17 PM\n> Subject: Requirements for notes\n>\n> This seems like a good moment to put out a call for\n> suggestions for exactly what types of note (e.g. editor-note, \n> hierarchy note) should be supported by SKOS-Core, and what \n> each note should contain.\n> \n> Can I ask you to be as precise as possible in outlining what\n> each type of note should be used for.\n\nHere is a survey of the note types in the vocabularies that I'm\ncurrently dealing with: LCC, DDC, LCSH, MeSH, FAST, GSAFD.  They\nbasically fall into three classes, MARC21-A, MARC21-C, and Dewey.\n\n\nMARC21-A Authorities Format\nhttp://www.loc.gov/marc/authority/ecadnote.html\n\n* 667 - NONPUBLIC GENERAL NOTE (R)\nGeneral information about a 1XX heading for which a specialized note\nfield has not been defined.\n\n* 670 - SOURCE DATA FOUND (R)\nA citation for a consulted source in which information is found about\nthe 1XX heading in an established heading record, an established heading\nand subdivision record, a subdivision record or a reference record. The\ninformation found in the source may also be present.\n\n* 675 - SOURCE DATA NOT FOUND (NR)\nA citation for a consulted source in which no information is found about\nthe 1XX heading in an established heading record, an established heading\nand subdivision record, or a subdivision record.\n\n* 678 - BIOGRAPHICAL OR HISTORICAL DATA (R)\nA summary of the essential biographical, historical, or other\ninformation about the 1XX heading in an established heading record, an\nestablished heading and subdivision record, or a subdivision record.\n\n* 680 - PUBLIC GENERAL NOTE (R)\nGeneral information about a 1XX heading for which a specialized note\nfield has not been defined. The note is written in a form adequate for\npublic display.\n\n* 681 - SUBJECT EXAMPLE TRACING NOTE (R)\nDocuments the use of the 1XX subject or authorized subdivision heading\nas an example or reference in fields 260, 360, and/or 680 in another\nauthority record.\n\n* 682 - DELETED HEADING INFORMATION (NR)\nAn explanation for the deletion of an established heading or subdivision\nrecord from an authority file (Leader/05, value d). The replacement\nheading(s) may be contained in subfield(s) $a.\n\n* 688 - APPLICATION HISTORY NOTE (R)\nInformation that documents changes in the application of a 1XX heading.\n\n\nMARC21-C Classification Format\nhttp://www.loc.gov/marc/classification/eccdnote.html\n\n* 680 - SCOPE NOTE  (R)\nInformation about the classification number or number span in field 153\n(Classification Number) that describes its scope in the scheme\nidentified in field 084 (Classification Schedule and Edition).\n\n* 681 - CLASSIFICATION EXAMPLE TRACING NOTE (R)\nInformation that documents the use of the 153 classification number or\nnumber span in one record as an example or reference in fields 253, 353\nand/or 6XX note fields in another record.\n\nThis field is primarily intended to serve as a tracing of the use of\nclassification numbers in examples and notes to assist classifiers in\nupdating records. \n\n* 683 - APPLICATION INSTRUCTION NOTE (R)\nInstructions for applying tables, subarrangements, or additions to\nclassification numbers.\n\n* 684 - AUXILIARY INSTRUCTION NOTE (R)\nInformation from, or reference to, a section of a classifier's manual or\nother documentation. An auxiliary instruction note provides advice for\nclassifying in difficult areas, and describes policies and practices\nthat may accompany a classification schedule.\n\n* 685 - HISTORY NOTE (R)\nInformation about the history of the use and meaning of a classification\nnumber that is contained either in a 153 classification number field or\nin a 453/553 tracing field with subfield $w/3, Control subfield, code a.\n\n* 686 - RELATIONSHIP TO SOURCE NOTE (R)\nInformation about the relationship of a number to the source edition\nwhen the number is different from the standard number for the same topic\nin the primary source edition. This field is used for numbers based on a\nsource other than the primary source, expansions, implemented options,\nand adaptations. The information in this field is intended primarily for\ncomputer processing or to guide classifiers and is often not written in\na form adequate for public user display.\n\n\nDewey\n\n* ADD NOTE - GENERIC INSTRUCTION\n* ADD NOTE - IDENTIFIED BY SYMBOL\n* ADD NOTE - SCHEDULE NUMBER, PART OF \n* ADD NOTE - SCHEDULE NUMBER, FULL \n* ADD NOTE - TABLE NUMBER, PART OF \n* ADD NOTE - TABLE NUMBER, ADD OF \n* ADD NOTE - REFERRAL TO TABLE\n* ADD NOTE - SEE REFERENCE\n* ADD NOTE - SEE REFERENCE, SCATTERED\n* ADD NOTE - STANDARD SUBDIVISIONS, ARE ADDED\n* ADD NOTE - STANDARD SUBDIVISIONS, DO NOT ADD\n* ADD NOTE - SUBDIVISIONS\n* ADD TABLE NOTE - GENERIC INSTRUCTION\n* ADD TABLE NOTE - IDENTIFIED BY SYMBOL\n* ADD TABLE NOTE - SCHEDULE NUMBER, PART OF\n* ADD TABLE NOTE - TABLE NUMBER, ALL\n* ADD TABLE NOTE - TABLE NUMBER, PART OF\n* ARRANGE ALPHABETICALLY NOTE\n* ARRANGE BY AUTHOR NOTE\n* ARRANGE CHRONOLOGICALLY NOTE\n* ARRANGE NUMERICALLY NOTE\n* ARRANGE BY TITLE NOTE\n* BUILD NOTE\n* BUILT NUMBER NOTE\n* CLASS HERE NOTE\n* CLASS ELSEWHERE NOTE\n* CLASS ELSEWHERE NOTE - SCATTERED\n* DEFINITION NOTE\n* DISCONTINUED NOTE - VACATED NUMBER\n* DISCONTINUED NOTE - PARTIALLY CHANGED NUMBER\n* EDITOR NOTE\n* EDITOR NOTE - FLAG\n* FOOTNOTE - ADD\n* FOOTNOTE - GENERIC\n* FOOTNOTE - OPTION\n* FOOTNOTE - STANDARD SUBDIVISIONS\n* FOOTNOTE - STANDARD SUBDIVISIONS, DO NOT ADD\n* FOOTNOTE - STANDARD SUBDIVISIONS, EXTRA ZEROS\n* FOOTNOTE - STANDARD SUBDIVISIONS, MODIFIED\n* FOOTNOTE - TABLE 2\n* FORMER HEADING NOTE\n* INCLUDING NOTE\n* MANUAL NOTE\n* MANUAL NOTE, LIKE\n* MOST RECENTLY USED NOTE\n* NEW SCHEDULE NOTE\n* NOTATION NOTE - DO NOT USE\n* OPTION NOTE\n* OPTIONAL NUMBER NOTE\n* PREFERENCE NOTE\n* REFERENCE NOTE - SEE ALSO\n* REFERENCE NOTE - SEE\n* REFERENCE NOTE - SEE MANUAL\n* REFERENCE NOTE - SEE SCATTERED\n* RELOCATION NOTE\n* RELOCATION NOTE - ADD\n* RELOCATION NOTE - VACATED NUMBER\n* RELOCATION NOTE - PARTIALLY CHANGED NUMBER\n* REVISION NOTE - COMPLETELY\n* REVISION NOTE - EXTENSIVELY\n* SCOPE NOTE\n* SEGMENTATION NOTE\n* SEMIHIERARCHICAL NOTE\n* STANDARD SUBDIVISIONS NOTE - MODIFIED\n* STANDARD SUBDIVISIONS NOTE - REOCCURRING IRREGULARITIES\n* TABLE NOTE - BUILD\n* TABLE NOTE - GENERIC\n* TABLE NOTE - OPTION\n* TABLE NOTE - PREFERENCE\n* VARIANT NAME NOTE\n\n\nI think I got most of the important Dewey notes...  I decided to skip\nthe definitions for Dewey since many of them are specific to Dewey\nitself.  But I did rename the notes from what the Dewey editors use so\nthey could be classified into groups so they could be compared with\nother vocabulary note types and to discover cross vocabulary\nsimilarities.  From the list you can see the diversity of notes in Dewey\ncompared with MARC21-A and MARC21-C. There are patterns to the Dewey\nnote types.\n\nFirst, let me *emphatically* say:\n  I don't feel that SKOS *should support* all these note types.\n\nThat wouldn't be useful since few vocabularies need to or go into such\ndetail.  However, I do see a group of base note types that could be\nuseful for thesauri, subject headings, classification, etc. and a\nmechanism to extend the base note types for specific purposes.\n\nLooking at the original SKOS proposal it had the following note types\ndefined in the RDF schema: skos:scopeNote, skos:generalNote,\nskos:hierarchyNote, skos:editorNote, and skos:historyNote.  Lets just\ntake these and see how MARC21-A, MARC21-C and Dewey fit in.  Note, I\ndidn't find an SKOS definition of what each of these note types means,\nso what follows is based upon my *interpretation*.  I think Miles eluded\nto the fact that definitions *need* to go along with the SKOS elements,\nor scope notes for note types.\n\nSKOS                MARC21-A  MARC21-C  Dewey\n------------------  --------  --------  -------------\n\nscopeNote            680       680      SCOPE NOTE\n                               683      CLASS HERE NOTE\n                               684      CLASS ELSEWHERE NOTE\n                                        CLASS ELSEWHERE NOTE - SCATTERED\n                                        DEFINITION NOTE [5]\n                                        INCLUDING NOTE\n                                        OPTION NOTE\n                                        PREFERENCE NOTE\n\ngeneralNote [1]      667 [2]   686 [6]  Probably most everything else\ngoes\nhere,\n                                          with a few exceptions [6]\n\nhierarchyNote [4]                       SEMIHIERARCHICAL NOTE\n\neditorNote           667                EDITOR NOTE\n                                        EDITOR NOTE - FLAG\n\nhistoryNote          678       685      DISCONTINUED NOTE - VACATED\nNUMBER\n                     682                DISCONTINUED NOTE - PARTIALLY\nCHANGED NUMBER\n                     688                FORMER HEADING NOTE\n                                        MOST RECENTLY USED NOTE\n                                        NEW SCHEDULE NOTE\n                                        RELOCATION NOTE\n                                        RELOCATION NOTE - ADD\n                                        RELOCATION NOTE - VACATED NUMBER\n                                        RELOCATION NOTE - PARTIALLY\nCHANGED NUMBER\n                                        REVISION NOTE - COMPLETELY\n                                        REVISION NOTE - EXTENSIVELY\n\nexample              670 [3]   681      \n                     675 [3]            \n                     681                \n                                        \n\n\n[1] Public or non-public?\n[2] Assumption is non-public.\n[3] A citation could roughly be considered an example,\n    but this doesn't fit well.\n[4] What's the scope for this?\n[5] A definition could roughly be considered a scope note, \n    but this doesn't fit well.\n[6] Assumption is public.\n\n\nThere are some places where the Dewey notes don't fit well.  One area of\nconcern is the VARIANT NAME NOTES.  In Dewey the preferred term is the\nclass number.  There are many alternate labels, such as the captions\nassociated with the class number from the various translations.  Variant\nnames really aren't alternate labels for the concept, per say, but the\nalso aren't strictly notes either.  Kind of mixture of the two...  We\nstill aren't sure how to resolve this issue.  I also lumped a lot of\nstuff in skos:generalNote that probably shouldn't belong their.\n\n>From these vocabularies I can start to see some patterns.  There are\ndistinctions between public vs. private notes which roughly could fit\nskos:scopeNote vs. skos:editorNote.  However, public notes do not\nnecessarily have to have a scope relationship to the concept.  So the\ndefinition of skos:scopeNote needs a better definition.  For me a\nscopeNote defines what is or is not in code for the concept.  This would\ninclude things like when to use the concept, when not to use the\nconcept, what is included with the concept, what is not included with\nthe concept, and optional or restricted information for using the\nconcept.  A public note is just that, a note for public consumption that\ndoesn't relate to the scope of the concept.  Probably not the best\ndefinition.\n\nThere are distinctions between editor vs. private notes but in my mind\nits difficult to say where the line is, e.g. when does a private note\nbecome a editorial note?  The skos:editorNote could cover both and if\nthe vocabulary maintainer needs to make that distinction it could.  Or\nbetter yet you could have skos:editorNote subclass skos:privateNote\nwhich subclasses skos:Note. If someone needs to make a different\ndistinction between an skos:editorNote and another form of private note\nthey can just subclass skos:privateNote. So maybe a class hierarchy\nmight look like:\n\nskos:Note\n\n  skos:publicNote\n    skos:scopeNote\n    skos:historyNote\n\n  skos:privateNote\n    skos:editorNote\n\nI noted an issue with skos:generalNote, is it public or private?  I\nthink that skos:historyNote is a good generic note type to build\ndifferent types of history notes upon.\n\nBreaking down the MARC21 note formats, we can see the following:\n\n* public notes\n* non-public notes\n* scope notes\n* history notes\n* citation notes\n* application notes\n* general notes\n* examples\n\nBreaking down the Dewey note formats, we can see the following:\n\n* public notes\n* non-public notes\n* scope notes\n* history notes\n* citation notes\n* application notes\n* general notes\n* examples\n* hierarchy notes (not sure whether definition matches SKOS)\n* reference notes\n* arrangement notes\n\nIf I were to suggest a class hierachy for these three vocabularies, it\nmight look something like:\n\nskos:definition\n  - a definition of the concept, useful for encoding dictionaries,\n    jargon, acronym, abbreviations; this is really another form of\n    specialized note, should it be a subclass of skos:Note or\n    skos:publicNote?\n\nskos:example\n  - examples of the usage for the existing concept; this is\n    really another form of specialized note, should it be\n    a subclass of skos:Note or skos:publicNote?\n\nskos:Note\n  - generic class for notes that allows subclassing for \n    specialized note types\n\n  skos:publicNote\n    - generic class for public notes that allows subclassing\n      for specialized note types\n\n    skos:applicationNote\n      - defines instructions for applying tables, subarrangements,\n        or additions to construct new concepts based upon the\n        existing concept\n\n    skos:arrangementNote\n      - defines how to arrange items under the concept\n\n    skos:citationNote\n      - defines a citation of a consulted source for defining\n        the existing concept\n\n    skos:generalNote\n      - defines general information for which a specialized \n        note type has not been defined \n\n    skos:hierarchyNote\n      - [needs a definition]\n\n    skos:historyNote\n      - defines information about the history or past use and \n        meaning of the concept\n\n    skos:referenceNote\n      - defines other places that the person might wish to\n        consider when evaluating the concept for use; these\n        places are outside the scope of the BT/NT/RT semantic\n        relationships\n\n    skos:scopeNote\n      - defines what is or is not in code for the concept and\n        would include things like when to use the concept, \n        when not to use the concept, what is included with \n        the concept, what is not included with the concept, \n        and optional or restricted information for using the \n        concept.  \n\n  skos:privateNote\n    - generic class for non-public, e.g. private, notes that\n      allows subclassing for specialized note types\n\n    skos:editorNote\n      - a note for an editor, translator or maintainer\n        of the vocabulary\n\n\nGiven the above response, I realize that this was a very long message to\nread through, perhaps people who deal with other vocabularies could\nshare the note types they find in them and some broad note type\ncategories that could be generalized for SKOS use.  I have provided a\nstart and the dart board.  Feel free to plunder these ideas and see how\nother vocabularies fit within the definitions.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Re: SKOS and OW",
            "content": "Yes I think this is really good text below.\n\nI like the themes of\n- skos = lower entry barrier\n- skos = allows us to present a thesaurus view onto knowledge data\n\nBut I'd dare to go so far as to say that arguably the notion of owl-ish \n'things' and their subclasses doesn't apply so well to pretty abstract \nconcepts such as 'fear' or, putting it another way, non-object-oriented \nthings such as 'cycling'.\nSo for me the lower entry barrier isn't only thing - it's about offering \nthe flexibility to be *either* casual or precise about how we believe some \n'things' to be subsumed by other 'things'. This in our attempts to organise \nand represent knowledge - particularly knowledge that covers abstract \nterritory.\n\nYou may totally disagree!\n\nBTW I agree with Dan re talking a bit about RDFS and OWL and subclassing \nversus KOS community notions of broader/narrower etc.\n\nNikki\n\n--On Friday, March 05, 2004 11:32:36 +0000 \"Miles, AJ (Alistair) \" \n<A.J.Miles@rl.ac.uk> wrote:\n\n>\n> Anticipating an FAQ item (and probably extended debate) on the\n> relationship between SKOS and OWL, so I had a go at a draft on the\n> subject.  I'd like to know what you think of this.\n>\n> Al.\n>\n> ----------------------------------------------------------\n> Q: What's the difference between SKOS and OWL?\n>\n> A: OWL is the Web Ontology Language, now a recommendation from W3C.  OWL\n> provides a powerful and expressive framework for adding well defined\n> semantics (meaning) to data on the web.  Adding explicit meaning to data\n> allows machines to communicate with each other, turning the web into an\n> environment for effective machine to machine (M2M) interaction, as well as\n> for human to machine (H2M) and human to human (H2H) interaction.  And\n> because it is grounded in well-understood and formally defined systems of\n> logic, we have the opportunity to reason over the data and discover new\n> facts.\n>\n> But what happens when you give somebody (without a formal education in\n> logic and set theory) an ontology editor, and ask them to create an\n> ontology?  In my own experience, the results can be varied.  Most people\n> grasp the basic notions of 'classes' 'individuals' and 'properties'\n> without much trouble. However, one feature that I've seen misunderstood\n> time and again is the 'sub-class' relationship, and the meaning of a\n> class hierarchy.\n>\n> Organising things into hierarchies is a very natural thing to do.  It is\n> akin to putting things into boxes, and the boxes into bigger boxes, so you\n> have a measure of order to a number of things that is too large to hold in\n> the mind at any one time.  Everybody who has a computer has a filesystem,\n> divided into folders and subfolders.  But give a group of people the same\n> set of files, and it's very likely that they'll create completely\n> different directory structures for organising them.  The point I'm making\n> is, hierarchies are natural, convenient and familiar, but different\n> people can mean different things by a hierarchical relationship between\n> two concepts.\n>\n> So often when you let someone loose on an ontology editor, they take one\n> look at the class tree displayed on the left side of the window and treat\n> it like a directory structure.  But the sub-class relationship has a very\n> specific and formally defined meaning, which must be used appropriately if\n> there is to be any guarantee of doing sensible reasoning and inference\n> further down the line.\n>\n> So there is a definite niche for a tool that is simpler to wield than OWL,\n> and won't break when confronted by the variations in peoples preference\n> for different styles of knowledge organisation.\n>\n> That's where SKOS comes in.  SKOS stands for Simple Knowledge Organisation\n> System.  It allows you to define some concepts, and organise them into\n> basic and familiar structures, without having to be too strict about the\n> implied semantics of those structures.  Of course SKOS is extensible, and\n> any amount of semantic precision can be added (or borrowed from other\n> schemas like OWL).  And of course SKOS is designed for maximal\n> interoperability, so there are links between the SKOS property framework\n> and the major vocabularies of RDF RDFS and OWL.  SKOS can be happily used\n> alongside OWL, offering alternative views over the same underlying\n> network of resources.\n>\n> The other major feature of SKOS is that it allows you to capture the link\n> between a concept and the vocabulary (terminology) that is commonly used\n> to refer to it.  So every concept is expected to have a 'preferred\n> label', and may also be given any number of 'alternative labels'.  This\n> feature can be used to turn any SKOS concept scheme or OWL ontology into\n> a thesaurus. Capturing this information adds a lot of value, facilitating\n> H2M and H2H interaction mediated by OWL ontologies or SKOS concept\n> schemes.\n>\n> So SKOS does not try to compete with OWL in any way, but is in fact\n> complementary to it.  It provides a simple and flexible framework for\n> building knowledge organisation schemes.  This means a lower entry barrier\n> for new users of the Semantic Web.  And it provides a path for bringing\n> into the Semantic Web the large amounts of existing knowledge, captured in\n> 'legacy' structures like thesauri, classification schemes, taxonomies and\n> so on, that are not mapped easily into an OWL ontology.\n>\n>\n>\n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n>\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: Compound concepts in a thesaurus structur",
            "content": "> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk] \n> Sent: Wednesday, May 12, 2004 4:49 AM\n> Subject: Re: Compound concepts in a thesaurus structure\n> \n> In message <000501c437fb$fea39970$0402a8c0@DELL> on Wed, 12 \n> May 2004, Stella Dextre Clarke <sdclarke@lukehouse.demon.co.uk> wrote\n> >\n> >Maybe I am missing the point here, but we seem to have jumped from \n> >talking about exchanging vocabulary data to the exchange of \n> catalogue \n> >data. I thought SKOS was addressing the former, but not the \n> latter. The \n> >relationships in a thesaurus are supposed to be paradigmatic, not \n> >syntagmatic. But a catalogue or index typically sets up syntagmatic \n> >relationships ( i.e. the sort to be found in the context of one \n> >particular document), which leads us into the difficulty outlined by \n> >Leonard.\n> \n> I think that Andy is thinking of SKOS as maintaining a \n> subject authority file, including all the simple and compound \n> concepts that are either enumerated in schedules or that have \n> been used in creating catalogue entries. This is very \n> different from a thesaurus, as you say, and adds a whole new \n> dimension of complexity. If this is to be done I think it \n> would be better to keep the thesaurus and the subject \n> authority file in separate databases.\n\nActually, this thread started with Leonard saying:\n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Tuesday, May 11, 2004 5:21 AM\n>\n> OK, I agree that it would be useful to have a mechanism for  encoding \n>pre-coordinate classification schemes and subject  indexing strings, \n>and I do like the idea of treating them in  an integrated way that \n>works smoothly with the encoding of  thesaurus structures.  It will \n>mean a significant expansion  of the project, though. Is it currently\nwithin its scope?\n\nI disagreed with the assessment that it would *significantly* expand the\nSKOS project.  To which Leonard replied:\n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Tuesday, May 11, 2004 10:43 AM\n> Subject: Re: Supporting arrays of concepts\n> \n> It seems to me to be a much more complex job for SKOS to try to create \n> a system that would incorporate rules for creating these compound \n> strings.\n\nI then pointed out that to encode LCSH in SKOS doesn't mean you have to\nincorporate the rules for how LCSH, or any other vocabulary, builds compound\nconcepts.  The \"whole\" compound string *is* the concept and there isn't\nnecessarily a BT/NT/RT relationship between the predefined part and what was\ncomposed.  The whole term should be taken as the concept and its BT/NT/RT\nrelationship is to be taken in the context of all the other predefined, e.g.\nenumerated, or compound strings in the vocabulary.\n\nThe point here is that whether the vocabulary *enumerates* or allows\nsynthesis of new concepts the \"whole\" string *is* the concept and should be\nused as the skos:prefLabel within skos:Concept.  A thesaurus could have\nconstructed concepts just like DDC, LCSH, UDC, etc., if it has the notion of\ntables.  For example, the thesaurus allows you to add a geographic component\nfrom a table to the enumerated list of concepts.  While the thesaurus\n*could* enumerate all the possibilities its probably more efficient to\nspecify a table and have appropriate notes say when the table should be\nused.  This use of tables is no different from how DDC, LCSH, UDC, etc.\nbuild new concepts.  Regardless, the constructed string is a new concept,\ne.g. Cats [enumerated] vs. Cats--United States [constructed] vs.\nCats--France [constructed].\n\nThis means there is *no* impact on SKOS.  Hence, my disagreement with\nLeonard's original assessment that it would *expand* the scope of the SKOS\nproject.  Hope this clears things up...\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "RE: Requirements for note",
            "content": "> From: Ron Davies [mailto:ron@rondavies.be] \n> Sent: Wednesday, May 12, 2004 6:32 AM\n> Subject: Re: Requirements for notes\n>  \n> I'm not sure that it's really necessary to try to specify a wide range of \n> different possible kinds of notes. This seems to me to be a case where\nyour idea \n> of subclassing and inheritance is going to be really useful (the other is\nthe \n> different types of hierarchical relationship such as partitive, generic,\netc.). I \n> think it's important, as Andy suggests, to distinguish between public and\nprivate \n> notes, since these may be handled in different ways, but for the rest, I'm\nnot \n> sure it matters a lot. A scope note, a history note, and some kind of\ninternal \n> note are the ones that I have seen most often, but others have a lot more \n> experience with this.\n> \n> I'm still a little concerned about delivering all of these notes every\ntime we \n> access a Concept. I would say normally in a _thesaurus_ application at\nleast \n> there's a continuum of how often information gets used, something like\nthis: \n\nOne reason for defining a little more than scope, history, internal notes is\nthat it allow you extract the notes that are relevant to your audience.  For\nexample, someone browsing the vocabulary is probably not interested in\napplication, citation, reference, or editorial notes.  They may only need\nscope and public notes.  However, a librarian who is trying to apply the\nvocabulary is probably interested in application, scope, and history notes.\n\nAs I pointed out, Dewey may be far to one side with all its note types.  BTW\nafter I sent my prior message I discovered that the Excel spreadsheet I was\nfiltering that contained the tags and descriptions was filtered incorrectly\nand there were another twenty more note types!  Ouch, however they didn't\nadd anything new to the discussion than what I presented. \n\nIn my prior message I showed that it was possible to boil down all those\nnotes types to a very small set of distinct buckets that one could use to\nbuild more detailed note types.  The buckets I suggested *probably* have\nbroader use across various, thesauri, subject headings, classification\nsystems, etc.  Many vocabularies may only use a few note types as you\nsuggested, but it would be nice to have the additional ones I suggested so\nyou can do finer grained things for presentation or programmatic\nmanipulation.\n\n> The Concept object combines the most often used information with the least\noften\n> used information. Sometimes these notes can be very long (Andy is perhaps\nin a \n> good position to confirm or deny my fears here). So the API may be\ndelivering a \n> lot of textual information with Concepts that will only be used a very\nsmall \n> percentage of the time. Maybe in practice this overhead won't matter, but\nit's an \n> issue perhaps to evaluate.\n\nThe length of notes vary from vocabulary to vocabulary.  I deal with a\nnumber of vocabularies, DDC, LCC, LCSH, MeSH, FAST, GSAFD, Eric, GEM-S,\nGates, Sears, etc.  Most notes are short in these vocabularies.  The\neditorial guidelines for the vocabulary can play into the length of notes.\nIn Dewey, notes are generally concise.  Probably due to the fact that there\nare so many of them.  The note types are for specifically defined purposes.\nHowever, when an editor needs to discuss a topic in more detail, Dewey has a\nsection called the \"Manual\".\n\nThe \"Manual\" is where in-depth discussions about a class number or a class\nnumber in relation to other class numbers goes.  It's a separate section,\ndistinct from the actual classification notes.  The discussions in the\n\"Manual\" are along the lines of why would you use this concept over these\nother concepts and the fine lines that the editors draw between concepts.\nThe \"Manual\" notes wouldn't be converted to SKOS because many times they\ndeal with relationships between concepts.  So if there are multiple concepts\ndiscussed, then which one do you associate the note with?  I guess, if a\n\"Manual\" note discussed three classes you could put the same note in all\nthree classes, but I'm not sure that would be useful.  It borders on the\nsame principal why vocabularies put things into tables, like geographics.\nThey can be used in multiple places and it's far easier to maintain in one\nplace.  The \"Manual\" also seems outside the scope of what we are trying to\ndo with SKOS and vocabularies, however if we needed to incorporate it with\nSKOS we would define our own RDF Resource and use dc:relation in the\nskos:Concept record to relate the concept to the place where it was\ndiscussed.\n\nPart of having finer grained notes allows the API to deliver only what you\nneed and no more.  So if your audience only needs scope and public notes,\nyou should be able to specify what your need is to the API.  If you just had\njust scope, history, and editorial note types, then you could get back a lot\nof stuff that isn't very useful to your audience.  That's because the\nvocabulary maintainer was forced into putting everything into scope notes or\na subclass of scope notes.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "RE: Compound concepts in a thesaurus structur",
            "content": "Andrew, \nIt occurs to me also  that compound/complex concepts may not\nbe relevant for SKOS (assuming here that SKOS will serve as a\ncontainer/carrier while\nevery system will have its own  native database format created with a\npurpose in mind \n(vocabulary management or IR). \nSubject vocabularies are exchanged as both original schedules and\nsubject authority data\n(which Stella calls 'cataloguing data'). Both forms, however,  contain\ncompound/complex terms if\nwe talk about subject heading system and classifications.\nOne can take out from SKOS only what is put in ( i.e. rubbish in/rubbish\nout).\n\nWhat I mean is that synthesized concepts may be stored in the native\ndatabase in two ways\n\n1) complex KOS concepts  as a simple text strings\ne.g. \nclassification\n\n<TAG> 94(73)\n[meaning: History - USA]\n\nsubject heading system\n<TAG>cats -- USA \n\nIf this is the case it is not up to SKOS to break the string down and\nprovide encoding for each element.\nso as Andrew says the whole sting has to be treated as skos:prefLabel\nwithin skos:Concept\n\n2)  complex KOS concepts  as  structured/encoded headings\n(each part of compound concept is separated by meaningful prefix: e.g.\nlet's say that  \nTAG1 is the prefix for the  main heading and   TAG2 is a subheading\nmeaning Place)\n\n<TAG1>94<TAG2>(73)\nor \n<TAG1>cats<TAG2>USA\n\nIf native database holds this kind of data any stripping of TAG prefixes\nwill also mean the stripping\na functionality attached to it.  So  SKOS may as well  accommodate the\nwhole lot: prefix+concept. \nwithin skos:Concept\nin which case the preferred term will not be '94(73)' but\n'<tag1>94<tag2>(73)'\nTextual notes explaining from which table each element comes (as this is\nspecified in classMARC (MARC21)\nare simply an accompanying text and is irrelevant for the problem of\naccessing/searching the complex headings \nthemselves and will not affect the functionality.  When heading is\nencoded this text becomes redundant anyway.\n\nI don't know whether there is any problem with my understanding of 2) \n\naida\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Houghton,Andrew\nSent: 12 May 2004 14:06\nTo: public-esw-thes@w3.org\nSubject: RE: Compound concepts in a thesaurus structure\n\n\n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Wednesday, May 12, 2004 4:49 AM\n> Subject: Re: Compound concepts in a thesaurus structure\n> \n> In message <000501c437fb$fea39970$0402a8c0@DELL> on Wed, 12\n> May 2004, Stella Dextre Clarke <sdclarke@lukehouse.demon.co.uk> wrote\n> >\n> >Maybe I am missing the point here, but we seem to have jumped from\n> >talking about exchanging vocabulary data to the exchange of \n> catalogue\n> >data. I thought SKOS was addressing the former, but not the\n> latter. The\n> >relationships in a thesaurus are supposed to be paradigmatic, not\n> >syntagmatic. But a catalogue or index typically sets up syntagmatic \n> >relationships ( i.e. the sort to be found in the context of one \n> >particular document), which leads us into the difficulty outlined by \n> >Leonard.\n> \n> I think that Andy is thinking of SKOS as maintaining a\n> subject authority file, including all the simple and compound \n> concepts that are either enumerated in schedules or that have \n> been used in creating catalogue entries. This is very \n> different from a thesaurus, as you say, and adds a whole new \n> dimension of complexity. If this is to be done I think it \n> would be better to keep the thesaurus and the subject \n> authority file in separate databases.\n\nActually, this thread started with Leonard saying:\n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Tuesday, May 11, 2004 5:21 AM\n>\n> OK, I agree that it would be useful to have a mechanism for  encoding\n>pre-coordinate classification schemes and subject  indexing strings, \n>and I do like the idea of treating them in  an integrated way that \n>works smoothly with the encoding of  thesaurus structures.  It will \n>mean a significant expansion  of the project, though. Is it currently\nwithin its scope?\n\nI disagreed with the assessment that it would *significantly* expand the\nSKOS project.  To which Leonard replied:\n\n> From: Leonard Will [mailto:L.Will@willpowerinfo.co.uk]\n> Sent: Tuesday, May 11, 2004 10:43 AM\n> Subject: Re: Supporting arrays of concepts\n> \n> It seems to me to be a much more complex job for SKOS to try to create\n\n> a system that would incorporate rules for creating these compound \n> strings.\n\nI then pointed out that to encode LCSH in SKOS doesn't mean you have to\nincorporate the rules for how LCSH, or any other vocabulary, builds\ncompound\nconcepts.  The \"whole\" compound string *is* the concept and there isn't\nnecessarily a BT/NT/RT relationship between the predefined part and what\nwas\ncomposed.  The whole term should be taken as the concept and its\nBT/NT/RT\nrelationship is to be taken in the context of all the other predefined,\ne.g.\nenumerated, or compound strings in the vocabulary.\n\nThe point here is that whether the vocabulary *enumerates* or allows\nsynthesis of new concepts the \"whole\" string *is* the concept and should\nbe\nused as the skos:prefLabel within skos:Concept.  A thesaurus could have\nconstructed concepts just like DDC, LCSH, UDC, etc., if it has the\nnotion of\ntables.  For example, the thesaurus allows you to add a geographic\ncomponent\nfrom a table to the enumerated list of concepts.  While the thesaurus\n*could* enumerate all the possibilities its probably more efficient to\nspecify a table and have appropriate notes say when the table should be\nused.  This use of tables is no different from how DDC, LCSH, UDC, etc.\nbuild new concepts.  Regardless, the constructed string is a new\nconcept,\ne.g. Cats [enumerated] vs. Cats--United States [constructed] vs.\nCats--France [constructed].\n\nThis means there is *no* impact on SKOS.  Hence, my disagreement with\nLeonard's original assessment that it would *expand* the scope of the\nSKOS\nproject.  Hope this clears things up...\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "RE: Compound concepts in a thesaurus structur",
            "content": "> From: Aida Slavic [mailto:aida@acorweb.net] \n> Sent: Wednesday, May 12, 2004 11:39 AM\n> Subject: RE: Compound concepts in a thesaurus structure\n> \n> What I mean is that synthesized concepts may be stored in the \n> native database in two ways\n> \n> 1) complex KOS concepts  as a simple text strings e.g. \n> classification\n> \n> 2)  complex KOS concepts  as  structured/encoded headings \n> (each part of compound concept is separated by meaningful prefix: e.g.\n> let's say that  \n> TAG1 is the prefix for the  main heading and   TAG2 is a subheading\n> meaning Place)\n>\n> If native database holds this kind of data any stripping of \n> TAG prefixes will also mean the stripping a functionality \n> attached to it.  So  SKOS may as well  accommodate the whole \n> lot: prefix+concept. \n> within skos:Concept\n\nI'm not advocating (2) because it would force anyone processing\nSKOS to recognizing the tagging of other XML grammars.  Certainly,\nI could with (1):\n\n  <skos:perfLabel>Cats--France</skos:perfLabel>\n\nor (2)\n\n  <skos:prefLabel rdf:parseType=\"Resource\">\n    <marc:subfield code=\"a\">Cats</marc:subfield>\n    <marc:subfield code=\"z\">France</marc:subfield>\n  </skos:prefLabel>\n\nWhile (2) carries the MARC21-A semantics which might be useful\nfor backend systems, e.g. databases, the systems will need to\nknow about MARC21-A and what a subfield-a and subfield-z mean.\nIn addition, if they are presenting the label they will need\nto know the MARC21 rules for presentation, e.g. how it's\nprinted in those Red Books distributed by LC.\n\nLoosing the sub-tagging, in some circumstances, may result in\nlost functionality.  No argument here.  But if that's the case,\nwhy not skip SKOS and use the MARC-XML records directly?  There\nare many XML database products on the market that can index and\nhandle any XML grammar.  So you can choose which XML grammar \nmakes sense in your context.  Maybe MARC-XML makes sense to \nsomeone and SKOS make sense to another.\n\nI see SKOS as a dumb-down approach, just like Dublin Core is.\nMost of the time you don't need the heavy weight and all the\nrules associated with MARC21 or UniMarc to describe vocabularies.\nYou want a relatively simpler and understandable format that \nyou can use to communicate these vocabularies.  For vocabularies \nthat aren't in electronic form SKOS may be a better choice for\ngetting them into electronic form.  At the same time we want to\nbe able to take all those existing vocabularies and put them in\na good dumb-downed form so people can experience quality\ncontrolled vocabularies for the Semantic Web.  Yes, we may loose\nsome information in the conversion, but so long as it doesn't\naffect the quality, it's acceptable.\n\nI also mentioned in a prior message that creating metadata isn't\neasy nor cheap.  I think the latest statistic I saw was that it\ntakes $70.US to do original cataloging on a book.  Considering\nthat, that book might have cost the library $10.US (paperback\nnovel) that's an expensive acquisition.  There are many\nvocabulary maintainers that will not put their vocabularies on\nthe Web because there is no way to recoup the significant \ninvestment they make on a yearly basis to keep their vocabularies\ncurrent.  However, with SKOS being a dumb-downed approach, it's \npossible to convince them to at least put out skeletal concept \nrecords that will not cannibalize their existing revenue.\n\nMaybe technical standards should be accompanied with a business\nplan, who is going to buy it, why will they buy it, when will\nthe market be ready to buy it, what effect will it have on the\nmarket, etc.  The bottom line for a vocabulary maintainer,\nwhat's in it for me?  It's got to either open new markets or\ngenerate additional revenue on existing products or services.\nJust because it's good for the Semantic Web or Libraries really\ndoesn't pay your creditors...\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "RE: Compound concepts in a thesaurus structur",
            "content": ">I see SKOS as a dumb-down approach, just like Dublin Core is. Most of\nthe time you don't need the heavy weight and all the rules associated\nwith MARC21 or UniMarc to \n>describe vocabularies. You want a relatively simpler and understandable\nformat that \n\nAll depends on the objective behind SKOS.  Generally speaking it is\nbetter to make sure that dumbing down is a decision and choice\nleft to  those who sell/apply/implement systems and not for those\ncreating standards. I would also make sure that it can accommodate\nboth thesauri and classifications and subject heading systems in their\nstandard form or as authority files.\nProvision for complexity does not stop ppl who want to do it  simply and\ncheaply .. dumbing down stops those who have more expensive  and \ncomplex needs.\nFancy you should mention Dublin Core as I wanted to use it to illustrate\nthe opposite. Producing metadata is far too\nexpensive to be created only  to find out that it does not work in IR -\nwhich is what was nasty surprise for many \nattracted to DC promise for cheep/simple/easy  - deciding to ignore\ngolde GIGO rule\n (garbage in garbage out). Which is why we have been flooded with of DC\napplication profiles, vocabularies, rules, guidelines - each \nproject spending money and time to write its own metadata standard\nwithin DC standard to fill the dumbed down gap, \ninventing qualifiers, syntax and refining semantic for generously empty\nDC elements.  Having said that -\n DC had its positive role in teaching people outside bibliographic\ndomain about descriptive metadata role, cost and use.\nSKOS appeared to me as a big step forward from what could be called\nmetadata infancy.\n\nMy suggestion to have possibility of choice and especially case 2)\n[structured heading with specific tags] was precisely because this has\nbeen missing up to now in \nMARC formats  which were created with Dewey and Library of Congress\nClassification in mind - exclusively for  library systems that do not\nuse classification\nfor information retrieval anyway but rather for shelf arrangement which\nmeans mainly American libraries. \nBoth MARC21 (former USMARC Classification Format) and now UNIMARC\nConcise classification \nformat draft form 2001,  fail to provide structured heading for\nclassification which causes problems in searching and managing faceted\nclassifications. \nThe poor exploitation of classification in library systems because of\nthe MARC being dumbed down is complaint that drags through the\nliterature since Wajenberg \narticle in 1983 followed by Cochrane, Drabenstott, Liu, Goedert, Pollitt\netc. as you probably know yourself. \n\nAs for SKOS I am not sure I understand  why 94(73) would be easier to\nparse when downloading data than <tag>94<tag2>(73) both forms being\nparticular\nto a specific systems and both can be interpreted only within this\nidentified system itself anyway. \nFor instance udc number 94(73) is encoded in one of my databases as\nc94f(73) .... why would SKOS be concerned with a form of my prefered\nterm????\nThe only problem is that if there is possibility to have compound terms\nencoded and not encoded it should be possible to say which rule applies\nfor the given \nURI...\n\nAida\n\n\n\n"
        },
        {
            "subject": "RE: Compound concepts in a thesaurus structur",
            "content": "> From: Aida Slavic [mailto:aida@acorweb.net] \n> Sent: Wednesday, May 12, 2004 3:51 PM\n> Subject: RE: Compound concepts in a thesaurus structure\n> \n> All depends on the objective behind SKOS.  Generally speaking \n> it is better to make sure that dumbing down is a decision and \n> choice left to  those who sell/apply/implement systems and \n> not for those creating standards. I would also make sure that \n\nTrue, SKOS is agnostic in this respect.  You can use RDF's\nsubclassing to get finer grain resolution or you can add your\nown metadata elements to the concept record.\n\n> Fancy you should mention Dublin Core as I wanted to use it to \n> illustrate the opposite. Producing metadata is far too \n> expensive to be created only  to find out that it does not \n> work in IR - which is what was nasty surprise for many \n\nNot sure what the problems are with IR, text is text, metadata\nelements help with context, but if you are looking to extract\ndeeper meaning from metadata elements, then you need to fully\nunderstand the XML grammars that your dealing with.  We should\nprobably take this topic offline.\n\n> attracted to DC promise for cheep/simple/easy  - deciding to \n> ignore golde GIGO rule  (garbage in garbage out). Which is \n> why we have been flooded with of DC application profiles, \n> vocabularies, rules, guidelines - each project spending money \n> and time to write its own metadata standard within DC \n> standard to fill the dumbed down gap, inventing qualifiers, \n> syntax and refining semantic for generously empty DC \n> elements.\n\nDC is building an empire...  Everyone wants it their way and\nthey fail to realize that they don't need to reinvent the\nwheel...\n\n> As for SKOS I am not sure I understand  why 94(73) would be \n> easier to parse when downloading data than <tag>94<tag2>(73) \n> both forms being particular to a specific systems and both \n> can be interpreted only within this identified system itself anyway. \n> For instance udc number 94(73) is encoded in one of my databases as\n> c94f(73) .... why would SKOS be concerned with a form of my \n> prefered term????\n\nI don't think I implied that 94(73) was easier to parse than\n<tag>94<tag2>(73).  If I did that was a mistake.  I don't see\nanything in SKOS that says that you are restricted in this\nmanner.  If you need to add additional metadata elements to\nyour concept records, go right ahead.  If you want to add\ndeeper level meaning to your preferred or alternate terms,\nthen go ahead.\n\nFor some internal projects we have planned, we will do \nexactly that.  For other project where we distribute SKOS \nrecords, we will remove internal system specific tagging.\nThat's our choice, SKOS doesn't say we have to do that, \nbut that tagging may not be meaningful outside the internal\nsystem it was used in or there are business decisions were\nthe additional tagging is deemed inappropriate for distribution.\n\nIf you decide to add additional tagging to your preferred\nterms, you shouldn't expect that I will make any sense of it.\nWhether you define your preferred term as:\n\n<skos:prefLabel>94(73)</skos:prefLabel>\n<skos:prefLabel><![CDATA[<tag>94<tag2>(73)]]></skos:prefLabel>\n\nor\n\n<skos:prefLabel rdf:parseType=\"Resource\">\n  <tag>94<tag2>(73)\n</skos:prefLabel>\n\nIn the first case, nobody will care about the CDATA, its just\ntext to someone processing the skos:prefLabel.  The latter case\nmay cause me to do strange things when I process your data.\nLets say I want to display it.  I probably will do the Xpath,\n//skos:prefLabel/text(), so I get 94(73) just as if the tags\nwere not there. [latter case]  Seems reasonable.  But what if\nI decided to put something like MARC-XML in there?\n\n<skos:prefLabel rdf:parseType=\"Resource\">\n  <marc:subfield code=\"a\">Cats</marc:subfield>\n  <marc:subfield code=\"z\">France</marc:subfield>\n</skos:prefLabel>\n\nNow someone uses that Xpath, //skos:prefLabel/text(), and gets\n\"CatsFrance\" which is not the intended form of \"Cats--France\".\nIf the embedded tagging is only used in my system, no harm, no\nfoul because I will have the knowledge to produce the correct\npreferred label when requested.  However, passing it off to you\nand you don't know MARC-XML this could be problematic.  That\nwas my point.  SKOS could care less, it's guidelines might say\ndon't do that, but as far as I can see it doesn't care at the\nmoment.  The problem is interoperability when harvesting SKOS \nschemes and trying to do something with them in online metadata\ncreation systems.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Arrays in SKOS: proposa",
            "content": "Hi all,\n\nHaving reviewed all of the discussion on the issue of arrays and node\nlabels, I would like to go with the following addition to the SKOS schema:\n\n----------------------------\nskos:Arrayardfs:Class;\nrdfs:label'Array';\nrdfs:comment'An array is either an ordered or an unordered\ncollection of concepts.  Arrays can be used for example to organise a set of\nconcepts according to some characteristic of division, primarily for visual\ndisplay.'\n.\n\nskos:arrayardf:Property;\nrdfs:label'array';\nrdfs:domainskos:Concept;\nrdfs:rangeskos:Array;\nrdfs:comment'Use this property to connect a concept to an array\nof narrower concepts.  The narrower and broader statements involving the\nparent concept and the members of the array should still be maintained\nindependently of the array construct.'\n.\n\nskos:membersardf:Property;\nrdfs:label'members';\nrdfs:domainskos:Array;\nrdfs:comment'Use this property to connect the array node to the\nfirst member of an RDF list of concepts and/or arrays.';\n\nskos:orderedardf:Property;\nrdfs:label'order is significant';\nrdfs:domainskos:Array;\nrdfs:rangexsd:Boolean;\nrdfs:comment'Use this property to indicate whether the ordering\nof an array of concepts is significant, and hence should be preserved by\napplications, or is not significant and can be ignored.'\n.\n-----------------------------\n\nBy default, without using arrays, the ordering of narrower concepts is not\npreserved by RDF applications.  Therefore, in any situation where the\nordering of a set of concepts is significant, an array should be used to\nexpress that ordering.  The array may be given a label, but this is not\nnecessary.\n\nThe skos:Array construct is recommended for encoding the grouping of a set\nof concepts according to some 'characteristic of division'.  In the majority\nof cases of the use of characteristics of division, the ordering is\nsignficant.  Applications handling a skos:Array should treat the ordering as\nsignificant by default.  \n\nHowever, in some cases the ordering of concepts under a characteristic of\ndivision is not significant.  It is recommended that a SKOS encoding of a\nthesaurus does not introduce ordering information where such information was\nnot a part of the original thesaurus.  In these cases, the fact that the\nordering is irrelevant should be expressed by adding a\n(skos:ordered,'false') property to the array.\n\nAn array may be a member of another array.  In this way arrays may be\nnested.  \n\nAny objections?\n\nAl. \n\n\n\n\n\n\n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: Arrays in SKOS: proposa",
            "content": "> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: Thursday, May 13, 2004 11:41 AM\n> Subject: Arrays in SKOS: proposal\n> \n> By default, without using arrays, the ordering of narrower \n> concepts is not preserved by RDF applications.  Therefore, in \n> any situation where the ordering of a set of concepts is \n> significant, an array should be used to express that \n> ordering.  The array may be given a label, but this is not necessary.\n> \n> The skos:Array construct is recommended for encoding the \n> grouping of a set of concepts according to some \n> 'characteristic of division'.  In the majority of cases of \n> the use of characteristics of division, the ordering is \n> signficant.  Applications handling a skos:Array should treat \n> the ordering as significant by default.  \n> \n> However, in some cases the ordering of concepts under a \n> characteristic of division is not significant.  It is \n> recommended that a SKOS encoding of a thesaurus does not \n> introduce ordering information where such information was not \n> a part of the original thesaurus.  In these cases, the fact \n> that the ordering is irrelevant should be expressed by adding a\n> (skos:ordered,'false') property to the array.\n> \n\nI'm not clear as to why RDF collections were not used vs. the\nskos:ordered property.  It seems to me that whether there is\nordering or not maps onto rdf:Bag and rdf:Seq which are both\ncollections.  If you didn't want to use rdf:Bag and rdf:Seq\nyou could develop the appropriate SKOS representation and\nmark them in the RDFS as collections.  Can you clarify why\nRDF collections are not being used?\n\n\nThanks, Andy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "skos:TopConcep",
            "content": "skos:TopConcept is not defined as a subclass of skos:Concept\n\nWhy is it so? \n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n \n\n\n\n"
        },
        {
            "subject": "RE: skos:TopConcep",
            "content": "> From: Bernard Vatant [mailto:bernard.vatant@mondeca.com] \n> Sent: Thursday, May 13, 2004 12:47 PM\n> Subject: skos:TopConcept\n> \n> skos:TopConcept is not defined as a subclass of skos:Concept\n> \n> Why is it so? \n\nBecause it's not a concept but a facet or category.  IMHO,\nskos:Facet or skos:Category makes more sense than \nskos:TopConcept, due to the exact reason for your question.\nWhat's being represented are facets for the arrangement of \nthe concepts.  You can see this is MARC21-A.  You have the\nsubject headings, e.g. concepts, but the subject headings \nare arranged by specific categories.  These relate to the\n1XX field ids, so you field id 100 is Personal Name, 150 is\nTopical Heading, etc.  To put this in context:\n\n<skos:Concept rdf:ID=\"Cats--France\">\n <skos:prefLabel>Cats--France</skos:prefLabel>\n</skos:Concept>\n\n<skos:TopConcept>\n  <skos:prefLabel>Topical</skos:prefLabel>\n  <skos:narrower rdf:resource=\"#Cats--France\"/>\n</skos:TopConcept>\n\nFor LCSH, the Topical skos:TopConcept could have several\nhundered thousand skos:narrower elements.  Not very\nscalable.  A better arrangement might be:\n\n<skos:Concept rdf:ID=\"Cats--France\">\n <skos:prefLabel>Cats--France</skos:prefLabel>\n <skos:inFacet rdf:resource=\"#Facet-Topical\"/>\n</skos:Concept>\n\n<skos:Facet rdf:ID=\"Facet-Topical\">\n  <skos:prefLabel>Topical</skos:prefLabel>\n</skos:TopConcept>\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "Re: skos:TopConcep",
            "content": "In message <GOEIKOOAMJONEFCANOKCKEBAEBAA.bernard.vatant@mondeca.com> on \nThu, 13 May 2004, Bernard Vatant <bernard.vatant@mondeca.com> wrote\n>\n>skos:TopConcept is not defined as a subclass of skos:Concept\n>\n>Why is it so?\n\nIs it necessary to have \"skos:TopConcept\"? I assume that a \"top concept\" \nis just a concept that happens, for the moment, to have no relationships \nto any broader concepts.\n\nAs it is therefore possible to identify top concepts by looking at \nrelationships, do they need to go in a distinct subclass? If BT \nrelationships are added or removed during editing of a thesaurus, an \nadditional operation would presumably be needed to move the concept in \nor out of the \"top concept\" subclass.\n\nDescriptors in a thesaurus are sometimes given a \"top concept\" or \"top \nterm (TT)\" relationship, showing the term(s) at the top of the \nhierarchy(ies) in which the descriptor occurs. This is mainly to help \npeople to find the term in a printed hierarchical display, and should \nnot be necessary if such displays can be generated on demand, as \ndiscussed here recently.\n\nWhile writing this, Andy's response has just appeared. I agree with him \nthat if \"top concept\" is really being used as the name of a facet or \ncategory, it would be better to name it accordingly.\n\nLeonard Will\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "RE: skos:TopConcep",
            "content": "Hi Bernard,\n\nEr ... oops!  I always intended skos:TopConcept to be a sub-class of\nskos:Concept.  I'm going to change that asap.\n\nLeonard - yes you are right, a top concept is just a concept without any\nbroader concepts.  I originally removed the TopConcept class from early\nversions of the SKOS-Core schema (we inherited it from the TIF schema that\nwas the early basis for SKOS), for exactly this reason - I thought it was\nredundant.  \n\nHowever it is convenient from a programming point of view to have a\nTopConcept class, so applications can locate the top concepts directly, and\nnot have to discover the top concepts dynamically by examining all of the\nconcepts.  \n\nAl. \n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Bernard Vatant\n> Sent: 13 May 2004 17:47\n> To: public-esw-thes@w3.org\n> Subject: skos:TopConcept\n> \n> \n> \n> \n> skos:TopConcept is not defined as a subclass of skos:Concept\n> \n> Why is it so? \n> \n> Bernard Vatant\n> Senior Consultant\n> Knowledge Engineering\n> Mondeca - www.mondeca.com\n> bernard.vatant@mondeca.com\n>  \n> \n\n\n\n"
        },
        {
            "subject": "RE: Arrays in SKOS: proposa",
            "content": "Hi Andy,\n\nWe are using RDF Collections here - the skos:members property should be used\nexactly as in the #students property in the example at [1].\n\nSo a SKOS e.g. in RDF/XML ...\n\n<skos:Concept rdf:about=\"URI_X\">\n<skos:prefLabel>Aircraft</skos:prefLabel>\n<skos:array>\n<skos:Array>\n<rdfs:label>Aircraft by form</rdfs:label>\n<skos:members rdf:parseType=\"Collection\">\n<skos:Concept rdf:about=\"URI_A\"/>\n<skos:Concept rdf:about=\"URI_B\"/>\n<skos:Concept rdf:about=\"URI_C\"/>\n</skos:members>\n</skos:Array>\n</skos:array>\n<skos:narrower rdf:resource=\"URI_A\"/>\n<skos:narrower rdf:resource=\"URI_B\"/>\n<skos:narrower rdf:resource=\"URI_C\"/>\n</skos:Concept>\n\n<skos:Concept rdf:about=\"URI_A\"/>\n<skos:prefLabel>Flying bomb</skos:prefLabel>\n<skos:broader rdf:resource=\"URI_X\"/>\n</skos:Concept>\n\n<skos:Concept rdf:about=\"URI_B\"/>\n<skos:prefLabel>Seaplane</skos:prefLabel>\n<skos:broader rdf:resource=\"URI_X\"/>\n</skos:Concept>\n\n<skos:Concept rdf:about=\"URI_C\"/>\n<skos:prefLabel>Monoplane</skos:prefLabel>\n<skos:broader rdf:resource=\"URI_X\"/>\n</skos:Concept>\n\nAl.\n\n[1] http://www.w3.org/TR/rdf-primer/#collections    \n\n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Houghton,Andrew\n> Sent: 13 May 2004 17:11\n> To: 'public-esw-thes@w3.org'\n> Subject: RE: Arrays in SKOS: proposal\n> \n> \n> \n> > From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> > Sent: Thursday, May 13, 2004 11:41 AM\n> > Subject: Arrays in SKOS: proposal\n> > \n> > By default, without using arrays, the ordering of narrower \n> > concepts is not preserved by RDF applications.  Therefore, in \n> > any situation where the ordering of a set of concepts is \n> > significant, an array should be used to express that \n> > ordering.  The array may be given a label, but this is not \n> necessary.\n> > \n> > The skos:Array construct is recommended for encoding the \n> > grouping of a set of concepts according to some \n> > 'characteristic of division'.  In the majority of cases of \n> > the use of characteristics of division, the ordering is \n> > signficant.  Applications handling a skos:Array should treat \n> > the ordering as significant by default.  \n> > \n> > However, in some cases the ordering of concepts under a \n> > characteristic of division is not significant.  It is \n> > recommended that a SKOS encoding of a thesaurus does not \n> > introduce ordering information where such information was not \n> > a part of the original thesaurus.  In these cases, the fact \n> > that the ordering is irrelevant should be expressed by adding a\n> > (skos:ordered,'false') property to the array.\n> > \n> \n> I'm not clear as to why RDF collections were not used vs. the\n> skos:ordered property.  It seems to me that whether there is\n> ordering or not maps onto rdf:Bag and rdf:Seq which are both\n> collections.  If you didn't want to use rdf:Bag and rdf:Seq\n> you could develop the appropriate SKOS representation and\n> mark them in the RDFS as collections.  Can you clarify why\n> RDF collections are not being used?\n> \n> \n> Thanks, Andy.\n> \n> Andrew Houghton, OCLC Online Computer Library Center, Inc.\n> http://www.oclc.org/about/\n> http://www.oclc.org/research/staff/houghton.htm\n> \n\n\n\n"
        },
        {
            "subject": "RE: Arrays in SKOS: proposa",
            "content": "> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: Thursday, May 13, 2004 1:59 PM\n> Subject: RE: Arrays in SKOS: proposal\n> \n> Hi Andy,\n> \n> We are using RDF Collections here - the skos:members property \n> should be used exactly as in the #students property in the \n> example at [1].\n> \n> So a SKOS e.g. in RDF/XML ...\n> \n> <skos:Concept rdf:about=\"URI_X\">\n> <skos:prefLabel>Aircraft</skos:prefLabel>\n> <skos:array>\n> <skos:Array>\n> <rdfs:label>Aircraft by form</rdfs:label>\n> <skos:members rdf:parseType=\"Collection\">\n> <skos:Concept rdf:about=\"URI_A\"/>\n> <skos:Concept rdf:about=\"URI_B\"/>\n>                       <skos:Concept rdf:about=\"URI_C\"/>\n>                 </skos:members>\n> </skos:Array>\n> </skos:array>\n> <skos:narrower rdf:resource=\"URI_A\"/>\n> <skos:narrower rdf:resource=\"URI_B\"/>\n> <skos:narrower rdf:resource=\"URI_C\"/>\n> </skos:Concept>\n\nOops, I missed the collection at skos:members, so skos:ordered\ngoes under skos:members?  If that's the case it seems to go\nagainst the grain of how the basic RDF rdf:Alt and rdf:Seq work.\nFor example the collection semantics determine how they the\nelement is interpreted.  So to extend the rdf:Alt and rdf:Seq\nanalogy, I would expect to see skos:membersUnordered and\nskos:membersOrdered.\n\nBTW, I think those rdf:about under skos:members should be\nrdf:resource.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "A question of facet",
            "content": "Just to respond to Andy's mail about facets: I'm going to resist the\nintroduction of anything with the name 'facet' into the SKOS-Core schema,\nbecause the word 'facet' has become too overloaded (see earlier mail [1] and\nsubsequent discussion [2]).  \n\nThe basic problem faced by the community of people involved in thesaurus\ndevelopment and classification as I have experienced it is an overloading of\nfunctional terminology, leading to people talking at cross-purposes.  Hence\nI have always put a lot of thought into the naming and the description of\nthe SKOS-Core schema classes and properties, in an effort to reduce the\npossibility for ambiguity and confusion to an absolute minimum.  \n\nAl.  \n\n[1] http://lists.w3.org/Archives/Public/public-esw-thes/2004Mar/0066.html\n[2] http://lists.w3.org/Archives/Public/public-esw-thes/2004Mar/\n  \n\n\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: Arrays in SKOS: proposa",
            "content": "The skos:ordered property suggestion is intended to be used as in ...\n\n<skos:Concept rdf:about=\"URI_X\">\n<skos:prefLabel>Aircraft</skos:prefLabel>\n<skos:array>\n <skos:Array>\n <rdfs:label>Aircraft by form</rdfs:label>\n <skos:members rdf:parseType=\"Collection\">\n <skos:Concept rdf:about=\"URI_A\"/>\n <skos:Concept rdf:about=\"URI_B\"/>\n             <skos:Concept rdf:about=\"URI_C\"/>\n         </skos:members>\n<skos:ordered>false</skos:ordered>\n </skos:Array>\n </skos:array>\n</skos:Concept>\n\n...\n\nand no, it should be rdf:about, not rdf:resource (check the specs [1]).\n\n(I could have done the example above as ...\n\n<skos:Concept rdf:about=\"URI_X\">\n<skos:prefLabel>Aircraft</skos:prefLabel>\n<skos:array>\n <skos:Array>\n <rdfs:label>Aircraft by form</rdfs:label>\n <skos:members rdf:parseType=\"Collection\">\n <rdf:Description rdf:about=\"URI_A\"/>\n <rdf:Description rdf:about=\"URI_B\"/>\n             <rdf:Description rdf:about=\"URI_C\"/>\n         </skos:members>\n<skos:ordered>false</skos:ordered>\n </skos:Array>\n </skos:array>\n</skos:Concept>\n\n... but it looks prettier if you put the type in the element name).\n\nAl.\n\n[1] http://www.w3.org/TR/rdf-primer/#collections\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n> -----Original Message-----\n> From: public-esw-thes-request@w3.org\n> [mailto:public-esw-thes-request@w3.org]On Behalf Of Houghton,Andrew\n> Sent: 13 May 2004 19:15\n> To: 'public-esw-thes@w3.org'\n> Subject: RE: Arrays in SKOS: proposal\n> \n> \n> \n> > From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> > Sent: Thursday, May 13, 2004 1:59 PM\n> > Subject: RE: Arrays in SKOS: proposal\n> > \n> > Hi Andy,\n> > \n> > We are using RDF Collections here - the skos:members property \n> > should be used exactly as in the #students property in the \n> > example at [1].\n> > \n> > So a SKOS e.g. in RDF/XML ...\n> > \n> > <skos:Concept rdf:about=\"URI_X\">\n> > <skos:prefLabel>Aircraft</skos:prefLabel>\n> > <skos:array>\n> > <skos:Array>\n> > <rdfs:label>Aircraft by form</rdfs:label>\n> > <skos:members rdf:parseType=\"Collection\">\n> > <skos:Concept rdf:about=\"URI_A\"/>\n> > <skos:Concept rdf:about=\"URI_B\"/>\n> >                       <skos:Concept rdf:about=\"URI_C\"/>\n> >                 </skos:members>\n> > </skos:Array>\n> > </skos:array>\n> > <skos:narrower rdf:resource=\"URI_A\"/>\n> > <skos:narrower rdf:resource=\"URI_B\"/>\n> > <skos:narrower rdf:resource=\"URI_C\"/>\n> > </skos:Concept>\n> \n> Oops, I missed the collection at skos:members, so skos:ordered\n> goes under skos:members?  If that's the case it seems to go\n> against the grain of how the basic RDF rdf:Alt and rdf:Seq work.\n> For example the collection semantics determine how they the\n> element is interpreted.  So to extend the rdf:Alt and rdf:Seq\n> analogy, I would expect to see skos:membersUnordered and\n> skos:membersOrdered.\n> \n> BTW, I think those rdf:about under skos:members should be\n> rdf:resource.\n> \n> \n> Andy.\n> \n> Andrew Houghton, OCLC Online Computer Library Center, Inc.\n> http://www.oclc.org/about/\n> http://www.oclc.org/research/staff/houghton.htm\n> \n\n\n\n"
        },
        {
            "subject": "RE: Arrays in SKOS: proposa",
            "content": "Houghton,Andrew writes:\n\n> Oops, I missed the collection at skos:members, so skos:ordered\n> goes under skos:members?  If that's the case it seems to go\n> against the grain of how the basic RDF rdf:Alt and rdf:Seq work.\n> For example the collection semantics determine how they the\n> element is interpreted.  So to extend the rdf:Alt and rdf:Seq\n> analogy, I would expect to see skos:membersUnordered and\n> skos:membersOrdered.\n\nCareful. rdf:Alt, rdf:Seq, and rdf:Bag are part of the \"container\"\nvocabulary. The \"collection\" vocabulary uses rdf:List and has a\ndifferent syntax in RDF/XML.\n\nThe two big advantage of the collection vocabulary are that it is easier\nto reason about (because it involves a finite number of properties) and\nthat collections are \"closed\". (I go into a little more detail at\n<http://lists.w3.org/Archives/Public/www-rdf-interest/2003Nov/0082.html>\n, if anyone is interested.)\n\nAnother difference is that collections have no equivalent to the\nAlt/Bag/Seq classes. Instead, it is up to vocabularies and applications\nto determine what importance to place on the order of elements in a\nlist. (Note that the same is true of Bag and Seq--the formal RDF\nsemantics do not define what they mean.)\n\n\n\nBelow is a concrete example illustrating the difference between the\ncontainer and collection vocabularies.\n\nLets say we have the following terms in our vocabulary.\n\n    thes:001 rdf:type skos:Concept.\n    thes:001 skos:prefLabel \"People\".\n    thes:001 skos:array _:1.\n\n    thes:002 rdf:type skos:Concept.\n    thes:002 skos:prefLabel \"Children (0-12 years)\".\n    \n    thes:003 rdf:type skos:Concept.\n    thes:003 skos:prefLabel \"Teenagers (13-19 years)\".\n\n    thes:004 rdf:type skos:Concept.\n    thes:004 skos:prefLabel \"Adults (over 20 years)\".\n\n(The \"_:1\" and \"_:2\" represent \"blank nodes\", which are essentially a\nresource for which we are not specifying a URI.)\n\nNow, if we were using the container vocabulary, we would write:\n\n    _:1 rdf:type skos:Array.\n    _:1 rdfs:label \"people by age\".\n    _:1 skos:members _:2.\n        \n    _:2 rdf:type rdf:Seq.\n    _:2 rdf:_1 thes:002.\n    _:2 rdf:_2 thes:003.\n    _:2 rdf:_3 thes:004.\n\nIn contrast, using the collection vocabulary, we have:\n\n    _:1 rdf:type skos:Array.\n    _:1 rdfs:label \"people by age\".\n    _:1 skos:members _:2.\n    \n    _:2 rdf:first thes:002.\n    _:2 rdf:rest _:3.\n    \n    _:3 rdf:first thes:003.\n    _:3 rdf:rest _:4.\n    \n    _:4 rdf:first thes:004.\n    _:4 rdf:rest rdf:nil.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "Re: Arrays in SKOS: proposa",
            "content": "Miles, AJ (Alistair)  writes:\n\n> Having reviewed all of the discussion on the issue of arrays and node\n> labels, I would like to go with the following addition to the SKOS\n> schema:\n<snip>\n\nLooks good to me.\n\nFollowing are some off-the-cuff impressions that may or may not be of\ninterest.\n\n--\n\nA stylistic point: When dealing with boolean properties, I find that\nclasses are often more convenient.\n\nThat is, rather than saying,\n\n    _:1 rdf:type skos:Array.\n    _:1 skos:ordered \"false\"^^xsd\"boolean.\n    _:1 skos:members ...\n\nit might be better to say\n\n    _:1 rdf:type skos:UnorderedArray.\n    _:1 skos:members ...\n\nand have skos:UnorderedArray be a subclass of skos:Array. (The sense\nbeing \"this is a kind of array where it doesn't matter if the order of\nmembers is changed.)\n\n--\n\nOn the subject of unordered arrays: From a user standpoint, what do you\nsee as the difference between an ordered array and an unordered array?\nAfter all, even an unordered array must be presented to the user in some\nsort of order.\n\n(One possibility: a UI, given an unordered array in a multilingual\nthesaurus, might sort items lexically according to the user's preferred\nlanguage.)\n\n--\n\nAlso on the subject of unordered arrays: I see the advantage to using\nthe same syntax for ordered and unordered arrays, but there is also one\ndisadvantage. Consider these arrays:\n\n    _:2 a skos:Array\n      ; skos:ordered \"false\"^^xsd:boolean\n      ; skos:members ( A B C D )\n      .\n    \n    _:3 a skos:Array\n      ; skos:ordered \"false\"^^xsd:boolean\n      ; skos:members ( B D A C )\n      .\n\nAt the SKOS level of interpretation, _:2 and _:3 represent the same\narray. However, there is presently no way to indicate that at the RDF\nlevel. That is, there's nothing you can put in the schema that a generic\nRDF tool could use to infer that _:2 and _:3 are identical.\n\nI don't consider this a problem, but it's worth noting.\n\n--\n\nOn the subject of nested arrays: The discussion of this got a bit too\ntechnical for me to follow, but I didn't see anything that convinced me\nthat nested arrays are necessary. On the other hand, I don't see a great\nneed to forbid them.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "RE: Arrays in SKOS: proposa",
            "content": "> From: David Menendez [mailto:zednenem@psualum.com] \n> Sent: Friday, May 14, 2004 12:31 AM\n> Subject: RE: Arrays in SKOS: proposal\n> \n> Careful. rdf:Alt, rdf:Seq, and rdf:Bag are part of the \"container\"\n> vocabulary. The \"collection\" vocabulary uses rdf:List and has \n> a different syntax in RDF/XML.\n\nYou are absolutely correct, I was confusing the two.  Thanks for\npointing this out.\n\n\nAndy.\n\nAndrew Houghton, OCLC Online Computer Library Center, Inc.\nhttp://www.oclc.org/about/\nhttp://www.oclc.org/research/staff/houghton.htm\n\n\n\n"
        },
        {
            "subject": "New list - public-esw  mantained by danbri&#64;w3.or",
            "content": "Purpose:  Public mailing list for the SWAD-Europe IST-7 EU project[1]. The\nmailing list is primarily for discussion amongst the project partners,\nalthough wider participation from other collaborators and members of the\nRDF Interest Group is also expected.\n\n\n1.  http://www.w3.org/2001/sw/EU/\n\n\n\n-- \nSimon J. Hernandez | http://www.w3.org/People/Simon/ | mailto:simon@w3.org\nWorld Wide Web Consortium                                http://www.w3.org\nMIT Laboratory for Computer Science, 200 Technology Square   Room NE43-340\nCambridge, MA 02139 USA       Voice: +1.617.253.2920  Fax: +1.617.258.5999\n\n\n\n"
        },
        {
            "subject": "Re: SWAD-Europe  another worksho",
            "content": "Hi all\n\nThere don't seem to any major objections to the other October workshop\nbeing on calendaring, and Kate is keen to get things moving. Please get\nback to me by the end of the week if you do have any major objections,\notherwise I'll start the preparation.\n\nAndy, I'm sure a query workshop will be very important: I think it needs\nsubstantial preparation though. Perhaps we could start a discussion as\nto when and where we might have one - maybe in 6-8 months time?\n\ncheers\n\nLibby\n\nOn Tue, 30 Jul 2002, Libby Miller wrote:\n\n>\n> As you know we are due to do tho workshops in October, one the postponed\n> 'International workshop' which looks to be colocated with the DC\n> conference, and another ordinary developer workshop which I am\n> organising at first pass.\n>\n> October's calendra currently looks like this:\n> http://www.w3.org/2001/sw/Europe/events/view/calmonth?rdfweburl=http://sw1.ilrt.org/discovery/2002/05/rsscal/confrss.rdf&startorend=start&date=2002-10-02\n>\n> My inital idea was to have it about calendaring, to take advantage of\n> the presence of the Webont working Group at HP in early October. There\n> seemed to be some preference for querying at the face to face. However I\n> don't think that we have sufficient time or resources at this stage to\n> have a workshop on such a controversial, popular and political subject.\n>\n> Therefore I proppose that we go with the calendaring idea, especially\n> given the current interest in RDF calendaring\n>\n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n>\n> http://www.extrememarkup.com/extreme/2002/friday.asp\n> Generalized metadata in your Palm\n> Norman Walsh, Sun Microsystems\n> (Extreme Markup 2002)\n>\n> Apple Ical\n> http://www.apple.com/ical/\n>\n> Mozilla calendar\n> http://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44D001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26safe%3Doff%26group%3Dnetscape.public.mozilla.calendar\n>\n> and the presence of Dan Connolly at the Webont f2f\n>\n> plus, of course, it's one of my particular interests as RDF Calendar\n> Taskforce lead; and I've been doing a lot on it for this project:\n>\n> http://www.w3.org/2001/sw/Europe/events/view/\n> http://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n>\n> what does everyone think? I'd like to start approaching people as soon\n> as possible about this.\n>\n> cheers\n>\n> Libby\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD-Europe  another worksho",
            "content": "Hi all,\n\nI'm going to start organising this, as there have been no objections so\nfar.\n\nI'm going to send a note to www-rdf-calendar, ccing a few people who I\nknow aren't on it. If you know of anyone who might like to come, give me\nshout.\n\nThe webont f2f is on the 7th and 8th October, monday and tuesday, so the\nbest day would probably be wednesday 9th. I've talked to the chairs of\nthe wg about this, and they're ok with it, although there's an event in\nLondon the same way which some people are attending (xml-uk).\n\nAt this stage, I'm thinking that ILRT will try and host it. The\nUniversity has some reasonable rooms if we book ahead, though of course\nthe food won't be as good as HP :)\n\ncheers\n\nLibby\n\n\nOn Tue, 30 Jul 2002, Libby Miller wrote:\n\n>\n> As you know we are due to do tho workshops in October, one the postponed\n> 'International workshop' which looks to be colocated with the DC\n> conference, and another ordinary developer workshop which I am\n> organising at first pass.\n>\n> October's calendra currently looks like this:\n> http://www.w3.org/2001/sw/Europe/events/view/calmonth?rdfweburl=http://sw1.ilrt.org/discovery/2002/05/rsscal/confrss.rdf&startorend=start&date=2002-10-02\n>\n> My inital idea was to have it about calendaring, to take advantage of\n> the presence of the Webont working Group at HP in early October. There\n> seemed to be some preference for querying at the face to face. However I\n> don't think that we have sufficient time or resources at this stage to\n> have a workshop on such a controversial, popular and political subject.\n>\n> Therefore I proppose that we go with the calendaring idea, especially\n> given the current interest in RDF calendaring\n>\n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n>\n> http://www.extrememarkup.com/extreme/2002/friday.asp\n> Generalized metadata in your Palm\n> Norman Walsh, Sun Microsystems\n> (Extreme Markup 2002)\n>\n> Apple Ical\n> http://www.apple.com/ical/\n>\n> Mozilla calendar\n> http://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44D001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26safe%3Doff%26group%3Dnetscape.public.mozilla.calendar\n>\n> and the presence of Dan Connolly at the Webont f2f\n>\n> plus, of course, it's one of my particular interests as RDF Calendar\n> Taskforce lead; and I've been doing a lot on it for this project:\n>\n> http://www.w3.org/2001/sw/Europe/events/view/\n> http://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n>\n> what does everyone think? I'd like to start approaching people as soon\n> as possible about this.\n>\n> cheers\n>\n> Libby\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "invitation to TELEBALT conference in Vilnius (fwd",
            "content": "Unfortunately I can't make this and neither can Charles. However, I\nthink it would be good for the project if someone could do it. Any\ntakers?\n\nLibby\n\n---------- Forwarded message ----------\nDate: Mon, 12 Aug 2002 14:11:01 +0300\nFrom: Saulius <saulius@infobalt.lt>\nTo: libby.miller <libby.miller@bristol.ac.uk>\nSubject: invitation to TELEBALT conference in Vilnius\n\nLibby MILLER\nUniversity of Bristol, Institute for Learning and Research Technology\nSenate House, Tyndall Avenue\nBS8 1TH Bristol, UNITED KINGDOM\n\nDear Libby MILLER,\n\nIt is our great pleasure to extend to you an invitation to make presentation\nor to participate at the TELEBALT  Conference \"Teleworking for Business,\nEducation, Research and e-Commerce\" (Vilnius, Lithuania, 21-22 October\n2002): (http://www.infobalt.lt/telebalt )\n\nOn behalf of the organizers we invite you or your project partner to submit\npresentation topics, abstracts and bios for the TELEBALT Conference. The\nnumber of possible presentation is limited.\n\nOrganised by INFOBALT - Association of Information Technologies,\nTelecommunications and Office Equipment of Lithuania in the frame of the\nproject TELEBALT (Teleworking as a Tool for Information Society Technologies\nProgramme Promotion to Baltic States) funded by Information Society\nProgramme of the European Union. The conference is organized in co-operation\nwith \"Earth Data Networks for Education and Scientific Exchange\" (EDNES),\nFrance, public foundation Open Latvia.\n\nThe Conference \"Teleworking for Business, Education, Research and\ne-Commerce\" aims at strengthening the scientific and technological\nco-operation between the European Union and the Newly Associated States\n(NAS), in particular the Baltic countries in the field of IT application to\nnew methods of work, business, education, research, e-commerce, medicine,\nregional development and social integration using IT.\n\nCurrently Baltic States community faces changes and opening possibilities\nfor cooperation with EU partners in the field of information society\ndevelopment and added value creation through the various information and\ncommunication technology related programmes. In-time acknowledgement about\nthese possibilities would serve as basement for future fruitful\ncollaboration.\n\nSome 50 speakers and 200 participants from all countries of the Baltic\nRegion and the European Union and the European Commission have been invited\nand will be invited. Parallel to the TELEBALT conference INFOBALT organize\n4th International Conference \"Information Society 2002\" and League of\nInvestors. These events will take place in the same venue as TELEBALT. Last\nyear it attracted some 90 speakers and 600 participants. More information\nabout these events at http://www.infobalt.lt/english/ .\nTELEBALT conference participants will have occasion to present their IST\nproject in the INFOBALT 2002 trade fair that will be organized 23-26 October\n2002. It is 9th International ICT sector trade fair and is the major such a\ntype event in Baltic States. Last year it attracted 200 exhibitors and 60000\nvisitors (+ 100 000 visited virtual trade fair). Association INFOBALT and\norganized events will also provide occasion to disseminate material about\nyour project, extend it finding new partners from Candidate Countries or\ninitiate new activities under various EU programmes umbrella.\n\nEdmundas Zvirblis or Saulius Arelis will provide detailed information under\nyour request.\n\nWe also contact you due to the project W3C Semantic Web Advanced Development\nfor EUROPE (SWAD-EUROPE), for which you have been mentioned   as the contact\nperson implementing another Association INFOBALT activity.\n\nAssociation INFOBALT participates in working group P2F (\"Projects to\nFunds\"), which was initiated by the Information Society Development\nCommittee under the Government of Lithuania. The working group P2F was\nespecially formed, to develop a large range of multiple project proposals\nand to seek subsequently for their co-funding at international donor\nprogrammes. Currently, P2F comprises sixteen members from different\nLithuanian ministries, universities and private companies.\nIt is one of our immediate tasks, to gather 50-70 project proposals from\npreviously successful funded ICT projects. Thus, we aim to achieve both, (a)\nto facilitate the project development work of the working group, as well as\n(b) to identify appropriate cooperation partners and programmes for joint\nprojects. The gathered information will be made available to the members of\nthe working group P2F only.\nFor this reason we kindly ask you to provide us with more background\ninformation to the project mentioned above. Of a particular interest for us\nwould be the project application form as it was submitted to the co-funding\ndonor programme (We currently still lack experience with non-national donor\nprogrammes; thus an application example would be of a great value for us).\n\nMany thanks in advance for your assistance. If you have any further\nquestions, please do not hesitate to contact Saulius Arelis at any time. You\nmay also get a deeper insight in the functions and responsibilities of the\ntwo major stakeholder organisations of the working group P2F at the links\nbelow. Yours sincerely,\n\nYours sincerely,\n\nEdmundas Zvirblis\nProject Manager\nTel. + 370 2 622623\nMobile: + 370 86 55422\nFax: + 370 2 622629\nINFOBALT Centras\nVokieciu 28/17-16\nLT-2001 Vilnius\nzvirblis@infobalt.lt\nwww.infobalt.lt\nSaulius Arelis\nProject Manager\nAssociation INFOBALT\nTel. + 370 2 622623\nMobile: + 370 610 35036\nFax: + 370 2 622629\nsaulius@infobalt.lt\n\n\n\n"
        },
        {
            "subject": "SWAD-Europe Semantic Web calendaring workshop 2002-1009, Bristol, U",
            "content": "Hi,\n\nAs part of the SWAD-Europe project[1] we are holding a series of\ndeveloper workshops on various topics. The next workshop is going to be\nabout the Semantic Web and calendaring, and will be held in Bristol, UK\non 9th October 2002.\n\nI'd like to have an idea of some possible numbers for this, so if you\nthink you'd like to attend, please send me an email as soon as you can.\nFeel free to pass this email on, although numbers will be limited.\n\nI think there's some very exciting work going on in calendaring at the\nmoment, and this will be an excellent opportunity to get some developers\nfrom different projects together. The Semantic Web calendar work I've\nseen spans the gap between research and useful tools, so it's an ideal\ntopic for 'Semantic Web 1.0'.\n\nThe agenda isn't finalised yet, and will depend to an extent on the\ninterests of the particpants, but will include demonstrations and\ncalendar-specific RDF-related issues, including handling datatyping,\nquerying and processing of calendar data (for example by calculating\nintervening dates beteen start and finish). Other topics could\nalso include security and privacy issues, practical strategies for\nidentifying the same event from different sources, and user interface\nissues. If you'd like to attend and have preferences about the topics,\nplease mail this list.\n\nHere are a few urls of recent work:\n\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n\nhttp://www.extrememarkup.com/extreme/2002/friday.asp\nGeneralized metadata in your Palm\nNorman Walsh, Sun Microsystems\n(Extreme Markup 2002)\n\nMozilla calendar\nhttp://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44D001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26safe%3Doff%26group%3Dnetscape.public.mozilla.calendar\n\nApple Ical\nhttp://www.apple.com/ical/\n\nCalendaring is one of my particular interests within the SWAD-Europe\nproject, where we are using Semantic Web tools to manage the\nadministrative data within the project:\n\nhttp://www.w3.org/2001/sw/Europe/events/view/\nhttp://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n\nthanks\n\nLibby\n\n[1] http://www.w3.org/2001/sw/Europe/\n\n\n\n"
        },
        {
            "subject": "Re: SWAD-Europe Semantic Web calendaring workshop 2002-1009, Bristol,  U",
            "content": "The Mozilla calendar now outputs the calendar rdf Dan Connolly is working on.\n\nArentJan Banck took my XSLT stylesheets and added support for generating various calendar data from the Mozilla Calendar. The same can be done with Evolution or any application that talks standard iCal.\n\nI don't plan on attending, but would love to see conversation about standard iCalendar and how it works with the various Semantic Web and calendaring projects.\n\nGary\n\nLibby Miller wrote:\n> \n> \n> Hi,\n> \n> As part of the SWAD-Europe project[1] we are holding a series of\n> developer workshops on various topics. The next workshop is going to be\n> about the Semantic Web and calendaring, and will be held in Bristol, UK\n> on 9th October 2002.\n> \n> I'd like to have an idea of some possible numbers for this, so if you\n> think you'd like to attend, please send me an email as soon as you can.\n> Feel free to pass this email on, although numbers will be limited.\n> \n> I think there's some very exciting work going on in calendaring at the\n> moment, and this will be an excellent opportunity to get some developers\n> from different projects together. The Semantic Web calendar work I've\n> seen spans the gap between research and useful tools, so it's an ideal\n> topic for 'Semantic Web 1.0'.\n> \n> The agenda isn't finalised yet, and will depend to an extent on the\n> interests of the particpants, but will include demonstrations and\n> calendar-specific RDF-related issues, including handling datatyping,\n> querying and processing of calendar data (for example by calculating\n> intervening dates beteen start and finish). Other topics could\n> also include security and privacy issues, practical strategies for\n> identifying the same event from different sources, and user interface\n> issues. If you'd like to attend and have preferences about the topics,\n> please mail this list.\n> \n> Here are a few urls of recent work:\n> \n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n> \n> http://www.extrememarkup.com/extreme/2002/friday.asp\n> Generalized metadata in your Palm\n> Norman Walsh, Sun Microsystems\n> (Extreme Markup 2002)\n> \n> Mozilla calendar\n> http://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44D001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26safe%3Doff%26group%3Dnetscape.public.mozilla.calendar\n> \n> Apple Ical\n> http://www.apple.com/ical/\n> \n> Calendaring is one of my particular interests within the SWAD-Europe\n> project, where we are using Semantic Web tools to manage the\n> administrative data within the project:\n> \n> http://www.w3.org/2001/sw/Europe/events/view/\n> http://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n> \n> thanks\n> \n> Libby\n> \n> [1] http://www.w3.org/2001/sw/Europe/\n> \n> \n> \n> \n> \n> \n> \n> \n> \n> \n\n\n\n"
        },
        {
            "subject": "RE: SWAD-Europe  another worksho",
            "content": "I'll cancel the booking at HP.\n\nAndy\n\n-----Original Message-----\nFrom: Charles McCathieNevile [mailto:charles@w3.org] \nSent: 22 June 2002 11:44\nTo: public-esw@w3.org\nSubject: International Workshop\n\nHi all,\n\nFollowing the Kick-off meeting, I am responsible for making sure we organise\nthe International Workshop. We are proposing to hold it on the topic of RDF\nQuerying, in conjunction with the W3C Web Ontology working group meeting in\nBristol 7-8 October.\n\nAt this stage I would propose holding a one day workshop on Wednesday the\n9th of October, and we hope that Hewlett-Packard could host this workshop.\n\nCheers\n\nCharles McCN\n\n-----Original Message-----\nFrom: Libby Miller [mailto:Libby.Miller@bristol.ac.uk] \nSent: 15 August 2002 22:17\nTo: public-esw@w3.org\nSubject: Re: SWAD-Europe - another workshop\n\nHi all,\n\nI'm going to start organising this, as there have been no objections so\nfar.\n\nI'm going to send a note to www-rdf-calendar, ccing a few people who I\nknow aren't on it. If you know of anyone who might like to come, give me\nshout.\n\nThe webont f2f is on the 7th and 8th October, monday and tuesday, so the\nbest day would probably be wednesday 9th. I've talked to the chairs of\nthe wg about this, and they're ok with it, although there's an event in\nLondon the same way which some people are attending (xml-uk).\n\nAt this stage, I'm thinking that ILRT will try and host it. The\nUniversity has some reasonable rooms if we book ahead, though of course\nthe food won't be as good as HP :)\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-Europe  another worksho",
            "content": "thanks Andy\n\nlibby\n\nOn Fri, 16 Aug 2002, Seaborne, Andy wrote:\n\n>\n> I'll cancel the booking at HP.\n>\n> Andy\n>\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org]\n> Sent: 22 June 2002 11:44\n> To: public-esw@w3.org\n> Subject: International Workshop\n>\n> Hi all,\n>\n> Following the Kick-off meeting, I am responsible for making sure we organise\n> the International Workshop. We are proposing to hold it on the topic of RDF\n> Querying, in conjunction with the W3C Web Ontology working group meeting in\n> Bristol 7-8 October.\n>\n> At this stage I would propose holding a one day workshop on Wednesday the\n> 9th of October, and we hope that Hewlett-Packard could host this workshop.\n>\n> Cheers\n>\n> Charles McCN\n>\n> -----Original Message-----\n> From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n> Sent: 15 August 2002 22:17\n> To: public-esw@w3.org\n> Subject: Re: SWAD-Europe - another workshop\n>\n> Hi all,\n>\n> I'm going to start organising this, as there have been no objections so\n> far.\n>\n> I'm going to send a note to www-rdf-calendar, ccing a few people who I\n> know aren't on it. If you know of anyone who might like to come, give me\n> shout.\n>\n> The webont f2f is on the 7th and 8th October, monday and tuesday, so the\n> best day would probably be wednesday 9th. I've talked to the chairs of\n> the wg about this, and they're ok with it, although there's an event in\n> London the same way which some people are attending (xml-uk).\n>\n> At this stage, I'm thinking that ILRT will try and host it. The\n> University has some reasonable rooms if we book ahead, though of course\n> the food won't be as good as HP :)\n>\n> cheers\n>\n> Libby\n>\n>\n\n\n\n"
        },
        {
            "subject": "Face to Face Meetin",
            "content": "Hi everyone, \n\nAt the kick off meeting we provisionally scheduled another face to face \nmeeting for the 23rd September. Please can partners confirm that this \ndate is still convenient for them? Brian/Michael - is it still ok to hold this \nmeeting at RAL?\n\nRegards, \n\nKate..\n\n----------------------\nKate Sharp\nProject Manager\nBiz/ed and SWAD Europe\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-Europe  another worksho",
            "content": "Hang on, I had thought HP were going to host a calendar workshop. Or am I\nconfused - is that ILRT?\n\nCheers\n\nChaals\n\nOn Fri, 16 Aug 2002, Seaborne, Andy wrote:\n\n>\n>I'll cancel the booking at HP.\n>\n>Andy\n>\n>-----Original Message-----\n>From: Charles McCathieNevile [mailto:charles@w3.org]\n>Sent: 22 June 2002 11:44\n>To: public-esw@w3.org\n>Subject: International Workshop\n>\n>Hi all,\n>\n>Following the Kick-off meeting, I am responsible for making sure we organise\n>the International Workshop. We are proposing to hold it on the topic of RDF\n>Querying, in conjunction with the W3C Web Ontology working group meeting in\n>Bristol 7-8 October.\n>\n>At this stage I would propose holding a one day workshop on Wednesday the\n>9th of October, and we hope that Hewlett-Packard could host this workshop.\n>\n>Cheers\n>\n>Charles McCN\n>\n>-----Original Message-----\n>From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n>Sent: 15 August 2002 22:17\n>To: public-esw@w3.org\n>Subject: Re: SWAD-Europe - another workshop\n>\n>Hi all,\n>\n>I'm going to start organising this, as there have been no objections so\n>far.\n>\n>I'm going to send a note to www-rdf-calendar, ccing a few people who I\n>know aren't on it. If you know of anyone who might like to come, give me\n>shout.\n>\n>The webont f2f is on the 7th and 8th October, monday and tuesday, so the\n>best day would probably be wednesday 9th. I've talked to the chairs of\n>the wg about this, and they're ok with it, although there's an event in\n>London the same way which some people are attending (xml-uk).\n>\n>At this stage, I'm thinking that ILRT will try and host it. The\n>University has some reasonable rooms if we book ahead, though of course\n>the food won't be as good as HP :)\n>\n>cheers\n>\n>Libby\n>\n\n-- \nCharles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ---------------- WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia       fax(fr) +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-Europe  another worksho",
            "content": "The topic was changed from Query to Calendar, and Libby is looking to host\nit c/o ILRT (which is easy so long as the room booking done in advance).\n\nDan\n\n\nOn Fri, 16 Aug 2002, Charles McCathieNevile wrote:\n\n>\n> Hang on, I had thought HP were going to host a calendar workshop. Or am I\n> confused - is that ILRT?\n>\n> Cheers\n>\n> Chaals\n>\n> On Fri, 16 Aug 2002, Seaborne, Andy wrote:\n>\n> >\n> >I'll cancel the booking at HP.\n> >\n> >Andy\n> >\n> >-----Original Message-----\n> >From: Charles McCathieNevile [mailto:charles@w3.org]\n> >Sent: 22 June 2002 11:44\n> >To: public-esw@w3.org\n> >Subject: International Workshop\n> >\n> >Hi all,\n> >\n> >Following the Kick-off meeting, I am responsible for making sure we organise\n> >the International Workshop. We are proposing to hold it on the topic of RDF\n> >Querying, in conjunction with the W3C Web Ontology working group meeting in\n> >Bristol 7-8 October.\n> >\n> >At this stage I would propose holding a one day workshop on Wednesday the\n> >9th of October, and we hope that Hewlett-Packard could host this workshop.\n> >\n> >Cheers\n> >\n> >Charles McCN\n> >\n> >-----Original Message-----\n> >From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n> >Sent: 15 August 2002 22:17\n> >To: public-esw@w3.org\n> >Subject: Re: SWAD-Europe - another workshop\n> >\n> >Hi all,\n> >\n> >I'm going to start organising this, as there have been no objections so\n> >far.\n> >\n> >I'm going to send a note to www-rdf-calendar, ccing a few people who I\n> >know aren't on it. If you know of anyone who might like to come, give me\n> >shout.\n> >\n> >The webont f2f is on the 7th and 8th October, monday and tuesday, so the\n> >best day would probably be wednesday 9th. I've talked to the chairs of\n> >the wg about this, and they're ok with it, although there's an event in\n> >London the same way which some people are attending (xml-uk).\n> >\n> >At this stage, I'm thinking that ILRT will try and host it. The\n> >University has some reasonable rooms if we book ahead, though of course\n> >the food won't be as good as HP :)\n> >\n> >cheers\n> >\n> >Libby\n> >\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-Europe  another worksho",
            "content": "The last couple of emails I've suggested ILRT host it, primarily because\nILRT has the lion's share of the cash for organising the workshops. To\nbe honest, it doesn't matter, but noone raised any objections.\n\nLibby\n\nOn Fri, 16 Aug 2002, Charles McCathieNevile wrote:\n\n>\n> Hang on, I had thought HP were going to host a calendar workshop. Or am I\n> confused - is that ILRT?\n>\n> Cheers\n>\n> Chaals\n>\n> On Fri, 16 Aug 2002, Seaborne, Andy wrote:\n>\n> >\n> >I'll cancel the booking at HP.\n> >\n> >Andy\n> >\n> >-----Original Message-----\n> >From: Charles McCathieNevile [mailto:charles@w3.org]\n> >Sent: 22 June 2002 11:44\n> >To: public-esw@w3.org\n> >Subject: International Workshop\n> >\n> >Hi all,\n> >\n> >Following the Kick-off meeting, I am responsible for making sure we organise\n> >the International Workshop. We are proposing to hold it on the topic of RDF\n> >Querying, in conjunction with the W3C Web Ontology working group meeting in\n> >Bristol 7-8 October.\n> >\n> >At this stage I would propose holding a one day workshop on Wednesday the\n> >9th of October, and we hope that Hewlett-Packard could host this workshop.\n> >\n> >Cheers\n> >\n> >Charles McCN\n> >\n> >-----Original Message-----\n> >From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n> >Sent: 15 August 2002 22:17\n> >To: public-esw@w3.org\n> >Subject: Re: SWAD-Europe - another workshop\n> >\n> >Hi all,\n> >\n> >I'm going to start organising this, as there have been no objections so\n> >far.\n> >\n> >I'm going to send a note to www-rdf-calendar, ccing a few people who I\n> >know aren't on it. If you know of anyone who might like to come, give me\n> >shout.\n> >\n> >The webont f2f is on the 7th and 8th October, monday and tuesday, so the\n> >best day would probably be wednesday 9th. I've talked to the chairs of\n> >the wg about this, and they're ok with it, although there's an event in\n> >London the same way which some people are attending (xml-uk).\n> >\n> >At this stage, I'm thinking that ILRT will try and host it. The\n> >University has some reasonable rooms if we book ahead, though of course\n> >the food won't be as good as HP :)\n> >\n> >cheers\n> >\n> >Libby\n> >\n>\n> --\n> Charles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe ---------------- WAI http://www.w3.org/WAI\n>  21 Mitchell street, FOOTSCRAY Vic 3011, Australia       fax(fr) +33 4 92 38 78 22\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Face to Face Meetin",
            "content": "Fine with me.\n\n--stephen\n\n\n-----Original Message-----\nFrom: Kate Sharp [mailto:Kate.Sharp@bristol.ac.uk]\nSent: Friday, August 16, 2002 11:03 AM\nTo: public-esw@w3.org\nSubject: Face to Face Meeting\n\n\n\nHi everyone, \n\nAt the kick off meeting we provisionally scheduled another face to face \nmeeting for the 23rd September. Please can partners confirm that this \ndate is still convenient for them? Brian/Michael - is it still ok to hold\nthis \nmeeting at RAL?\n\nRegards, \n\nKate..\n\n----------------------\nKate Sharp\nProject Manager\nBiz/ed and SWAD Europe\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "RE: Face to Face Meetin",
            "content": "23rd september at RAL: yep, me too...\n\nchaals\n\nOn Fri, 16 Aug 2002, Stephen Buswell wrote:\n\n>\n>Fine with me.\n>\n\n\n\n"
        },
        {
            "subject": "RE: Face to Face Meetin",
            "content": "Should be - will check with Mike when he returns from holiday\non Monday and confirm.\n\nBrian\n\n>  -----Original Message-----\n>  From: Kate Sharp [mailto:Kate.Sharp@bristol.ac.uk]\n>  Sent: 16 August 2002 11:03\n>  To: public-esw@w3.org\n>  Subject: Face to Face Meeting\n>  \n>  \n>  \n>  Hi everyone, \n>  \n>  At the kick off meeting we provisionally scheduled another \n>  face to face \n>  meeting for the 23rd September. Please can partners confirm \n>  that this \n>  date is still convenient for them? Brian/Michael - is it \n>  still ok to hold this \n>  meeting at RAL?\n>  \n>  Regards, \n>  \n>  Kate..\n>  \n>  ----------------------\n>  Kate Sharp\n>  Project Manager\n>  Biz/ed and SWAD Europe\n>  Institute for Learning and Research Technology\n>  University of Bristol, 8-10, Berkeley Square,\n>  Clifton, Bristol, BS8 1HH\n>  Tel: 0117 9287189\n>  Fax: 0117 9287112\n>  \n>  http://www.bized.ac.uk\n>  http://www.w3.org/2001/sw/Europe/\n>  \n>  Kate.Sharp@bristol.ac.uk\n>  \n\n\n\n"
        },
        {
            "subject": "RE: Face to Face Meetin",
            "content": "And me.\n\nOn Fri, 16 Aug 2002, Charles McCathieNevile wrote:\n\n>\n> 23rd september at RAL: yep, me too...\n>\n> chaals\n>\n> On Fri, 16 Aug 2002, Stephen Buswell wrote:\n>\n> >\n> >Fine with me.\n> >\n>\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-Europe  another worksho",
            "content": "There has been a change from the query workshop at HP to a calendaring\nworkshop at ILRT.\n\nAndy\n\n-----Original Message-----\nFrom: Charles McCathieNevile [mailto:charles@w3.org] \nSent: 16 August 2002 14:06\nTo: Seaborne, Andy\nCc: 'public-esw@w3.org'\nSubject: RE: SWAD-Europe - another workshop\n\n\nHang on, I had thought HP were going to host a calendar workshop. Or am I\nconfused - is that ILRT?\n\nCheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Re: Face to Face Meetin",
            "content": "Dan Brickley <danbri@w3.org> writes:\n\n> 23rd september at RAL: yep, me too...\n\nMy Regrets. :-(\nI'll be giving a talk in Budapest.\n\nMax.\n\n\n\n"
        },
        {
            "subject": "RE: Face to Face Meetin",
            "content": "Kate,\n\n2nd SWAD F2F - management meeting.\n\n23rd September, RAL, Conference Room 2 in Building R1 is booked 8am to 5pm.\n\nTo get to RAL see - http://www.clrc.ac.uk/Activity/ACTIVITY=RALMaps;\n\nI'll need to know a list of exact names of those attending by Friday 20th in\norder to inform our security guards.\n\nthanks\n\nMichael Wilson\nBusiness and Information Technology Department   tel: +44 (0)1235 44 6619\nCLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\nChilton, DIDCOT, Oxon, OX11 0QX, UK             \n\nWWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n\nThe contents of this email are sent in confidence for the use of the\nintended recipients only.  If you are not one of the intended recipients\ndo not take action on it or show it to anyone else, but return this\nemail to the sender and delete your copy of it\n\n\n\n\n-----Original Message-----\nFrom: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\nBehalf Of Kate Sharp\nSent: 16 August 2002 11:03\nTo: public-esw@w3.org\nSubject: Face to Face Meeting\n\n\n\nHi everyone, \n\nAt the kick off meeting we provisionally scheduled another face to face \nmeeting for the 23rd September. Please can partners confirm that this \ndate is still convenient for them? Brian/Michael - is it still ok to hold\nthis \nmeeting at RAL?\n\nRegards, \n\nKate..\n\n----------------------\nKate Sharp\nProject Manager\nBiz/ed and SWAD Europe\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "deliverable 10.2 scalable RDBMS mapping repor",
            "content": "Just pottering around the website - I know Dave and Jan have started it\nthinking about this:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-10.html\nhttp://www.w3.org/2001/sw/Europe/reports/scalable_rdbms_mapping_report/\n\nI think the intention of this deliverable is ambigious:\n\n[[\nMonth 5: (10.2: scalable_rdbms_mapping_report) Public report on mapping\ndata from RDBMS. This\n            will describe current best practice on using existing RDBMS\nor other storage systems for general\n            Semantic Web data. (2 months, report, Pub.)\n]]\n\n'mapping from' seems rather different to 'mapping to', i.e. you could\nhave existing data in RDBMS and map it to RDF, or you could be storing\ngeneral RDF in RDBMS. This deliverable seems to cover both. Do we think\nthis is the case? I think it should :)\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: deliverable 10.2 scalable RDBMS mapping repor",
            "content": "On Wed, 21 Aug 2002, Libby Miller wrote:\n\n>\n>\n> Just pottering around the website - I know Dave and Jan have started it\n> thinking about this:\n>\n> http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-10.html\n> http://www.w3.org/2001/sw/Europe/reports/scalable_rdbms_mapping_report/\n>\n> I think the intention of this deliverable is ambigious:\n>\n> [[\n> Month 5: (10.2: scalable_rdbms_mapping_report) Public report on mapping\n> data from RDBMS. This\n>             will describe current best practice on using existing RDBMS\n> or other storage systems for general\n>             Semantic Web data. (2 months, report, Pub.)\n> ]]\n>\n> 'mapping from' seems rather different to 'mapping to', i.e. you could\n> have existing data in RDBMS and map it to RDF, or you could be storing\n> general RDF in RDBMS. This deliverable seems to cover both. Do we think\n> this is the case? I think it should :)\n\nThat was (I think) the intention with this wording.\n\n-- \njan grant, ILRT, University of Bristol. http://www.ilrt.bris.ac.uk/\nTel +44(0)117 9287088 Fax +44 (0)117 9287112 RFC822 jan.grant@bris.ac.uk\nDonate a signature: http://ioctl.org/jan/sig-submit\n\n\n\n"
        },
        {
            "subject": "Re: deliverable 10.2 scalable RDBMS mapping repor",
            "content": ">>>Libby Miller said:\n> I think the intention of this deliverable is ambigious:\n> \n> [[\n> Month 5: (10.2: scalable_rdbms_mapping_report) Public report on mapping\n> data from RDBMS. This\n>             will describe current best practice on using existing RDBMS\n> or other storage systems for general\n>             Semantic Web data. (2 months, report, Pub.)\n> ]]\n> \n> 'mapping from' seems rather different to 'mapping to', i.e. you could\n> have existing data in RDBMS and map it to RDF, or you could be storing\n> general RDF in RDBMS. This deliverable seems to cover both. Do we think\n> this is the case? I think it should :)\n\nI wrote it to be flexible and indeed wanted to and from them in the\nscope.  Jan and I have started sketching notes in the draft area.\n\nIt also can cover \"other storage systems\" that are not RDBMSes.\n\nDave\n\n\n\n"
        },
        {
            "subject": "FP6 Launch Conference, November 2002 (fwd",
            "content": "For info.\nWe are thinking that ILRT can organise some flyers to send. It's not\nclear that we will have any exciting demos to show then at that stage,\nalthough suggestions are welcome.\nIt's also not clear whether they want anyone to come. More info as I get\nit.\n\nLibby\n\n---------- Forwarded message ----------\nDate: Wed, 21 Aug 2002 12:32:41 +0200\nFrom: grainne mulhern <grainne@erin.lu>\nTo: libby.miller <libby.miller@bristol.ac.uk>\nSubject: FP6 Launch Conference, November 2002\n\nDear Ms. Miller,\n\nThe MULTIPLE project (support measure for INFSO D5)  is co-ordinating the\npreparations for the joint DG INFSO D1/D4/D5 stand at the Sixth Framework\nProgramme Launch Conference at Heysel, Belgium in November, and will also be\ninvolved in manning the stand at the conference.\nA key objective will be to publicise and to disseminate information about\nthe various current projects. Therefore, for your own project, SWAD-EUROPE,\nplease can you let me know if you will be able to provide any of the\nfollowing information about the project for display and distribution on the\nstand:\n  a.. literature (such as leaflets, brochures, flyers, directories,\npromotional material, etc),\n  b.. CD-ROMs of project information or demonstrations,\n  c.. demos that we can run on the stand's PC,\n  d.. or any other suitable material.\nTarget quantities for printed material would be up to 400 - 500 copies; for\nCD-ROMs perhaps rather less.\nWe would also be interested in images, in electromic format, which are\nrepresentative of the area of interest of the project (rather than the\nproject's own logo). These should, if at all possible, be suitable for\nprinting - in other words, preferably in a professional format such as .psd,\n.ai. or .eps - and at as high a resolution as possible - 300 dpi is the\nabsolute minimum. These images will be considered for possible inclusion on\nposters to be prepared by the conference organisers, and we will need to\nhave these as soon as possible so that we can send them to the organisers by\nmonth-end.\n\nPlease can you copy my colleague Grainne Mulhern (address in cc: above) on\nyour reply, as she is coordinating this work.\nBest regards\nLaurie Causton\nProject Manager, MULTIPLE\n\n\n\n"
        },
        {
            "subject": "Re: FP6 Launch Conference, November 2002 (fwd",
            "content": "further to this:\nthe website is at\nhttp://europa.eu.int/comm/research/conferences/2002/index_en.html\nand registration is open.\n\nLibby\n\nOn Fri, 23 Aug 2002, Libby Miller wrote:\n\n>\n>\n> For info.\n> We are thinking that ILRT can organise some flyers to send. It's not\n> clear that we will have any exciting demos to show then at that stage,\n> although suggestions are welcome.\n> It's also not clear whether they want anyone to come. More info as I get\n> it.\n>\n> Libby\n>\n> ---------- Forwarded message ----------\n> Date: Wed, 21 Aug 2002 12:32:41 +0200\n> From: grainne mulhern <grainne@erin.lu>\n> To: libby.miller <libby.miller@bristol.ac.uk>\n> Subject: FP6 Launch Conference, November 2002\n>\n> Dear Ms. Miller,\n>\n> The MULTIPLE project (support measure for INFSO D5)  is co-ordinating the\n> preparations for the joint DG INFSO D1/D4/D5 stand at the Sixth Framework\n> Programme Launch Conference at Heysel, Belgium in November, and will also be\n> involved in manning the stand at the conference.\n> A key objective will be to publicise and to disseminate information about\n> the various current projects. Therefore, for your own project, SWAD-EUROPE,\n> please can you let me know if you will be able to provide any of the\n> following information about the project for display and distribution on the\n> stand:\n>   a.. literature (such as leaflets, brochures, flyers, directories,\n> promotional material, etc),\n>   b.. CD-ROMs of project information or demonstrations,\n>   c.. demos that we can run on the stand's PC,\n>   d.. or any other suitable material.\n> Target quantities for printed material would be up to 400 - 500 copies; for\n> CD-ROMs perhaps rather less.\n> We would also be interested in images, in electromic format, which are\n> representative of the area of interest of the project (rather than the\n> project's own logo). These should, if at all possible, be suitable for\n> printing - in other words, preferably in a professional format such as .psd,\n> .ai. or .eps - and at as high a resolution as possible - 300 dpi is the\n> absolute minimum. These images will be considered for possible inclusion on\n> posters to be prepared by the conference organisers, and we will need to\n> have these as soon as possible so that we can send them to the organisers by\n> month-end.\n>\n> Please can you copy my colleague Grainne Mulhern (address in cc: above) on\n> your reply, as she is coordinating this work.\n> Best regards\n> Laurie Causton\n> Project Manager, MULTIPLE\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Invitation to make presentation (fwd",
            "content": "This is the second message we have had. I'm going to have to regretfully\ndecline unless someone wants to do it (Charles and I can't make it).\nThey also want information about the project itself, which I'll sort\nout.\nLet me know asap if you'd liek to do the presentation.\n\nLibby\n\n---------- Forwarded message ----------\nDate: Mon, 26 Aug 2002 16:48:50 +0200\nFrom: Edmundas Zvirblis <zvirblis@infobalt.lt>\nTo: libby.miller <libby.miller@bristol.ac.uk>\nCc: sb <sb@stilo.com>, danbri <danbri@w3.org>, m.d.wilson <m.d.wilson@rl.ac.uk>,\n     martin_merry <martin_merry@hp.com>\nSubject: Invitation to make presentation\n\nDear Libby MILLER,\n\nIt is our great pleasure to extend to you an invitation to make presentation\nor to participate at the TELEBALT  Conference Teleworking for Business,\nEducation, Research and e-Commerce (Vilnius, Lithuania, 21-22 October\n2002): (http://www.infobalt.lt/telebalt )\n\nOn behalf of the organizers we invite you or your project SWAD-EUROPE\npartner to submit presentation topics, abstracts and bios for the TELEBALT\nConference. The number of possible presentation is limited.\n\nOrganised by INFOBALT - Association of Information Technologies,\nTelecommunications and Office Equipment of Lithuania in the frame of the\nproject TELEBALT (Teleworking as a Tool for Information Society Technologies\nProgramme Promotion to Baltic States) funded by Information Society\nProgramme of the European Union. The conference is organized in co-operation\nwith Earth Data Networks for Education and Scientific Exchange (EDNES),\nFrance, public foundation Open Latvia.\n\nThe Conference Teleworking for Business, Education, Research and\n e-Commerce aims at strengthening the scientific and technological\nco-operation between the European Union and the Newly Associated States\n(NAS), in particular the Baltic countries in the field of IT application to\nnew methods of work, business, education, research, e-commerce, medicine,\nregional development and social integration using IT.\n\nCurrently Baltic States community faces changes and opening possibilities\nfor cooperation with EU partners in the field of information society\ndevelopment and added value creation through the various information and\ncommunication technology related programmes. In-time acknowledgement about\nthese possibilities would serve as basement for future fruitful\ncollaboration.\n\nSome 50 speakers and 200 participants from all countries of the Baltic\nRegion and the European Union and the European Commission have been invited\nand will be invited. Parallel to the TELEBALT conference INFOBALT organize\n4th International Conference Information Society 2002 and League of\nInvestors. These events will take place in the same venue as TELEBALT. Last\nyear it attracted some 90 speakers and 600 participants. More information\nabout these events at http://www.infobalt.lt/english/ .\nTELEBALT conference participants will have occasion to present their IST\nproject in the INFOBALT 2002 trade fair that will be organized 23-26 October\n2002. It is 9th International ICT sector trade fair and is the major such a\ntype event in Baltic States. Last year it attracted 200 exhibitors and 60000\nvisitors (+ 100 000 visited virtual trade fair). Association INFOBALT and\norganized events will also provide occasion to disseminate material about\nyour project, extend it finding new partners from Candidate Countries or\ninitiate new activities under various EU programmes umbrella.\n\nEdmundas Zvirblis or Saulius Arelis will provide detailed information under\nyour request.\n\nWe also contact you due to the project SWAD-EUROPE, for which you have been\nmentioned as the contact person implementing another Association INFOBALT\nactivity.\n\nAssociation INFOBALT participates in working group P2F (Projects to\n Funds), which was initiated by the Information Society Development\nCommittee under the Government of Lithuania. The working group P2F was\nespecially formed, to develop a large range of multiple project proposals\nand to seek subsequently for their co-funding at international donor\nprogrammes. Currently, P2F comprises sixteen members from different\nLithuanian ministries, universities and private companies.\nIt is one of our immediate tasks, to gather 50-70 project proposals from\npreviously successful funded ICT projects. Thus, we aim to achieve both, (a)\nto facilitate the project development work of the working group, as well as\n(b) to identify appropriate cooperation partners and programmes for joint\nprojects. The gathered information will be made available to the members of\nthe working group P2F only.\nFor this reason we kindly ask you to provide us with more background\ninformation to the project mentioned above. Of a particular interest for us\nwould be the project application form as it was submitted to the co-funding\ndonor programme (We currently still lack experience with non-national donor\nprogrammes; thus an application example would be of a great value for us).\n\nMany thanks in advance for your assistance. If you have any further\nquestions, please do not hesitate to contact Saulius Arelis at any time. You\nmay also get a deeper insight in the functions and responsibilities of the\ntwo major stakeholder organisations of the working group P2F at the links\nbelow. Yours sincerely,\n\nYours sincerely,\n\nEdmundas Zvirblis\nProject Manager\nTel. + 370 2 622623\nMobile: + 370 86 55422\nFax: + 370 2 622629\nINFOBALT Centras\nVokieciu 28/17-16\nLT-2001 Vilnius\nzvirblis@infobalt.lt\nwww.infobalt.lt\n\nSaulius Arelis\nProject Manager\nAssociation INFOBALT\nTel. + 370 2 622623\nMobile: + 370 610 35036\nFax: + 370 2 622629\nsaulius@infobalt.lt\n\n\n\n"
        },
        {
            "subject": "Re: ANN: SWADEurope Survey of free RDF Triple Store",
            "content": ">   Report on Scalability and Storage: Survey of Free Software / Open\n>     Source RDF Storage systems \n>   Dave Beckett\n>   http://www.w3.org/2001/sw/Europe/reports/rdf_scalable_storage_report/\n\nDave,\n\nNice report!\n\nYou might want to add DAML DB [1].\n\nMike\n\n[1] http://www.daml.org/2001/09/damldb/\n\n\n\n"
        },
        {
            "subject": "SWADeurope dissemination and use pla",
            "content": "I've been working on this, and a rough draft is at\n\nhttp://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n\nThe plan is to send it to the commission in a weeks' time (Tuesday 3rd\nSeptember). There's a lot of tiding to be done, but this is the basic\nstructure we plan to submit.\n\nAt this stage we are looking for comments and for additions,\nparticularly in the sections on partner-specific internal audience\n(Section 1.1), and in the actual DUP (Section 4) where any upcoming\nconferences and other opportunities for dissemination would be useful.\n\nThe document will be updated over time as we know better what\nconferences are coming up and so on.\n\nthanks\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWADeurope dissemination and use pla",
            "content": "Hi Libby et al,\n\n(the list has public in its name, so I hope I'm right in assuming comments\nfrom the public are acceptable here)\n\nGood document, and some worthy aims. It got me thinking about what was\nlacking at present from SW idea dissemination in Europe. So in the interests\nof facilitating \"... collaboration and information exchange between relevant\nSemantic Web communities\", I'd like to suggest the setting up of a mailing\nlist/forum targeted at a particular part of these (potential) communities.\n\nThe discussion on the rdf*@w3.org lists is mostly between those that are\nalready reasonably familiar with Semantic Web/RDF ideas, and I would suspect\nthat this might manifest itself to the newcomer as a kind of exclusivity.\n(To some extent the W3C as whole has this kind of an aura, the WGs populated\nby representatives of multinationals who meet in smoky rooms... for the\noutreach to work, SWAD-E has to at least be perceived as more than a\nsub-cabal of the W3C.)\n\nI'm sure a question like \"How (and why!) do I deploy Dublin Core and RSS on\nmy website?\" would be treated well on rdf-interest, but I still think there\nis need for a place where questions like \"What is Dublin Core?\" would not\nonly be tolerated but encouraged. There is a whole range of technical\ninformation that may be too specific for rdf-interest but not specific\nenough for the lists maintained by developers of particular toolkits etc.\nI think its fair to say that rdf-interest is tending toward the direction of\nxml-dev, where if someone asks why their Xerces parser is crashing on a '&',\nthey are likely to get an answer explaining why namespaces are the work of\nsatan.\n\nThe localisation of SWAD-E also suggests other possibilities, for example a\nforum of the kind I'm suggesting would be a good place to organise meetings\n& conferences that were lower key than the big events.\n\nThe key points I'd suggest for such a list would be -\n\n* topics : Semantic Web, RDF & related technologies\n* emphasis on practice\n* open subscription\n* any European language acceptable\n* minimal formality\n* unmoderated, archived, backed by faq pages (+ irc, wiki..?)\n\nCheers,\nDanny.\n\n\n\n\n\n\n\n---\nDanny Ayers\n<stuff> http://www.isacat.net </stuff>\n\nIdea maps for the Semantic Web\nhttp://ideagraph.net\n\n\n>-----Original Message-----\n>From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n>Behalf Of Libby Miller\n>Sent: 28 August 2002 10:50\n>To: public-esw@w3.org\n>Subject: SWAD-europe dissemination and use plan\n>\n>\n>\n>\n>I've been working on this, and a rough draft is at\n>\n>http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n>\n>The plan is to send it to the commission in a weeks' time (Tuesday 3rd\n>September). There's a lot of tiding to be done, but this is the basic\n>structure we plan to submit.\n>\n>At this stage we are looking for comments and for additions,\n>particularly in the sections on partner-specific internal audience\n>(Section 1.1), and in the actual DUP (Section 4) where any upcoming\n>conferences and other opportunities for dissemination would be useful.\n>\n>The document will be updated over time as we know better what\n>conferences are coming up and so on.\n>\n>thanks\n>\n>Libby\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: ANN: SWADEurope Survey of free RDF Triple Store",
            "content": ">>>Mike Dean said:\n> \n> >   Report on Scalability and Storage: Survey of Free Software / Open\n> >     Source RDF Storage systems \n> >   Dave Beckett\n> >   http://www.w3.org/2001/sw/Europe/reports/rdf_scalable_storage_report/\n> \n> Dave,\n> \n> Nice report!\n\nThanks\n\n> You might want to add DAML DB [1].\n\nI tried to find all the DAML data things I could find - there are so many!\n\n> Mike\n> \n> [1] http://www.daml.org/2001/09/damldb/\n\nErr, that's a 404\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: ANN: SWADEurope Survey of free RDF Triple Store",
            "content": "> > [1] http://www.daml.org/2001/09/damldb/\n> \n> Err, that's a 404\n\nwww.daml.org was temporarily down (with a message only on\nthe root page).  [1] is available now.\n\nThanks!\n\nMike\n\n\n\n"
        },
        {
            "subject": "RE: SWADeurope dissemination and use pla",
            "content": "hey Danny,\n\nThanks for your comments :)\nThis is as you say a public list and we welcome comments from non\nproject partners.\n\nInteresting that you think there's a gap for this beginners' mailing\nlist. Where, out of interest, do you think these sorts of questions go\nat the moment?\n\nWe are going to try to use existing community lists where possible, but\nthis focus would fit with our FAQ based approach. We will discuss it on\nthis list and at our next face to face meeting and see how we go.\n\nThanks again,\n\nLibby\n\nOn Wed, 28 Aug 2002, Danny Ayers wrote:\n\n> Hi Libby et al,\n>\n> (the list has public in its name, so I hope I'm right in assuming comments\n> from the public are acceptable here)\n>\n> Good document, and some worthy aims. It got me thinking about what was\n> lacking at present from SW idea dissemination in Europe. So in the interests\n> of facilitating \"... collaboration and information exchange between relevant\n> Semantic Web communities\", I'd like to suggest the setting up of a mailing\n> list/forum targeted at a particular part of these (potential) communities.\n>\n> The discussion on the rdf*@w3.org lists is mostly between those that are\n> already reasonably familiar with Semantic Web/RDF ideas, and I would suspect\n> that this might manifest itself to the newcomer as a kind of exclusivity.\n> (To some extent the W3C as whole has this kind of an aura, the WGs populated\n> by representatives of multinationals who meet in smoky rooms... for the\n> outreach to work, SWAD-E has to at least be perceived as more than a\n> sub-cabal of the W3C.)\n>\n> I'm sure a question like \"How (and why!) do I deploy Dublin Core and RSS on\n> my website?\" would be treated well on rdf-interest, but I still think there\n> is need for a place where questions like \"What is Dublin Core?\" would not\n> only be tolerated but encouraged. There is a whole range of technical\n> information that may be too specific for rdf-interest but not specific\n> enough for the lists maintained by developers of particular toolkits etc.\n> I think its fair to say that rdf-interest is tending toward the direction of\n> xml-dev, where if someone asks why their Xerces parser is crashing on a '&',\n> they are likely to get an answer explaining why namespaces are the work of\n> satan.\n>\n> The localisation of SWAD-E also suggests other possibilities, for example a\n> forum of the kind I'm suggesting would be a good place to organise meetings\n> & conferences that were lower key than the big events.\n>\n> The key points I'd suggest for such a list would be -\n>\n> * topics : Semantic Web, RDF & related technologies\n> * emphasis on practice\n> * open subscription\n> * any European language acceptable\n> * minimal formality\n> * unmoderated, archived, backed by faq pages (+ irc, wiki..?)\n>\n> Cheers,\n> Danny.\n>\n>\n>\n>\n>\n>\n>\n> ---\n> Danny Ayers\n> <stuff> http://www.isacat.net </stuff>\n>\n> Idea maps for the Semantic Web\n> http://ideagraph.net\n>\n>\n> >-----Original Message-----\n> >From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n> >Behalf Of Libby Miller\n> >Sent: 28 August 2002 10:50\n> >To: public-esw@w3.org\n> >Subject: SWAD-europe dissemination and use plan\n> >\n> >\n> >\n> >\n> >I've been working on this, and a rough draft is at\n> >\n> >http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n> >\n> >The plan is to send it to the commission in a weeks' time (Tuesday 3rd\n> >September). There's a lot of tiding to be done, but this is the basic\n> >structure we plan to submit.\n> >\n> >At this stage we are looking for comments and for additions,\n> >particularly in the sections on partner-specific internal audience\n> >(Section 1.1), and in the actual DUP (Section 4) where any upcoming\n> >conferences and other opportunities for dissemination would be useful.\n> >\n> >The document will be updated over time as we know better what\n> >conferences are coming up and so on.\n> >\n> >thanks\n> >\n> >Libby\n> >\n> >\n> >\n> >\n> >\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: SWADeurope dissemination and use pla",
            "content": "Hi Libby,\n\n>Thanks for your comments :)\n\nThanks for your response ;-)\n\n>This is as you say a public list and we welcome comments from non\n>project partners.\n>\n>Interesting that you think there's a gap for this beginners' mailing\n>list.\n\nHmm - I was thinking not necessarily a beginner's list period, but more of a\ncatch-all for things that fell outside of rdf-interest/logic etc, including\nthings that are more localised (a la RDF South West) and nuts & bolts, e.g.\n\"Does anyone know of an NTriples parser for Jena?\" - ok, I just snatched\nthis from the Jena list, but if that list didn't exist...\nThough now you mention it, perhaps 'rdf-intro' would be a good idea.\n\n> Where, out of interest, do you think these sorts of questions go\n>at the moment?\n\nHaven't the foggiest ;-) Good question though. How do people usually hear of\nthe SW & RDF? I wonder where all those Scientific American readers went.\nIt'd be interesting to see the posters/lurkers ratio for rdf-interest.\n\n>We are going to try to use existing community lists where possible, but\n>this focus would fit with our FAQ based approach.\n\nYes, of course - I'm only guessing there's a need not covered already.\n\n>We will discuss it on\n>this list and at our next face to face meeting and see how we go.\n\nGreat! Thanks again,\nDanny.\n\n\n\n"
        },
        {
            "subject": "Re: Invitation to make presentation (fwd",
            "content": "I'm going to say no. Is that ok? He asked several of us, and I don't\nwant him to get diferent answers from different project members. Tell me\ntoday if you want to do a presentation at this conference.\n\nSure noone wants to do it?\n\n[[\n...many visitors to the region tend to fall madly in love with\nVilnius...\n]]\nhttp://www.balticsww.com/tourist/lithuania/\n\nhttp://www.infobalt.lt/telebalt/\n\nLibby\n\nOn Mon, 26 Aug 2002, Libby Miller wrote:\n\n>\n> This is the second message we have had. I'm going to have to regretfully\n> decline unless someone wants to do it (Charles and I can't make it).\n> They also want information about the project itself, which I'll sort\n> out.\n> Let me know asap if you'd liek to do the presentation.\n>\n> Libby\n>\n> ---------- Forwarded message ----------\n> Date: Mon, 26 Aug 2002 16:48:50 +0200\n> From: Edmundas Zvirblis <zvirblis@infobalt.lt>\n> To: libby.miller <libby.miller@bristol.ac.uk>\n> Cc: sb <sb@stilo.com>, danbri <danbri@w3.org>, m.d.wilson <m.d.wilson@rl.ac.uk>,\n>      martin_merry <martin_merry@hp.com>\n> Subject: Invitation to make presentation\n>\n> Dear Libby MILLER,\n>\n> It is our great pleasure to extend to you an invitation to make presentation\n> or to participate at the TELEBALT  Conference Teleworking for Business,\n> Education, Research and e-Commerce (Vilnius, Lithuania, 21-22 October\n> 2002): (http://www.infobalt.lt/telebalt )\n>\n> On behalf of the organizers we invite you or your project SWAD-EUROPE\n> partner to submit presentation topics, abstracts and bios for the TELEBALT\n> Conference. The number of possible presentation is limited.\n>\n> Organised by INFOBALT - Association of Information Technologies,\n> Telecommunications and Office Equipment of Lithuania in the frame of the\n> project TELEBALT (Teleworking as a Tool for Information Society Technologies\n> Programme Promotion to Baltic States) funded by Information Society\n> Programme of the European Union. The conference is organized in co-operation\n> with Earth Data Networks for Education and Scientific Exchange (EDNES),\n> France, public foundation Open Latvia.\n>\n> The Conference Teleworking for Business, Education, Research and\n>  e-Commerce aims at strengthening the scientific and technological\n> co-operation between the European Union and the Newly Associated States\n> (NAS), in particular the Baltic countries in the field of IT application to\n> new methods of work, business, education, research, e-commerce, medicine,\n> regional development and social integration using IT.\n>\n> Currently Baltic States community faces changes and opening possibilities\n> for cooperation with EU partners in the field of information society\n> development and added value creation through the various information and\n> communication technology related programmes. In-time acknowledgement about\n> these possibilities would serve as basement for future fruitful\n> collaboration.\n>\n> Some 50 speakers and 200 participants from all countries of the Baltic\n> Region and the European Union and the European Commission have been invited\n> and will be invited. Parallel to the TELEBALT conference INFOBALT organize\n> 4th International Conference Information Society 2002 and League of\n> Investors. These events will take place in the same venue as TELEBALT. Last\n> year it attracted some 90 speakers and 600 participants. More information\n> about these events at http://www.infobalt.lt/english/ .\n> TELEBALT conference participants will have occasion to present their IST\n> project in the INFOBALT 2002 trade fair that will be organized 23-26 October\n> 2002. It is 9th International ICT sector trade fair and is the major such a\n> type event in Baltic States. Last year it attracted 200 exhibitors and 60000\n> visitors (+ 100 000 visited virtual trade fair). Association INFOBALT and\n> organized events will also provide occasion to disseminate material about\n> your project, extend it finding new partners from Candidate Countries or\n> initiate new activities under various EU programmes umbrella.\n>\n> Edmundas Zvirblis or Saulius Arelis will provide detailed information under\n> your request.\n>\n> We also contact you due to the project SWAD-EUROPE, for which you have been\n> mentioned as the contact person implementing another Association INFOBALT\n> activity.\n>\n> Association INFOBALT participates in working group P2F (Projects to\n>  Funds), which was initiated by the Information Society Development\n> Committee under the Government of Lithuania. The working group P2F was\n> especially formed, to develop a large range of multiple project proposals\n> and to seek subsequently for their co-funding at international donor\n> programmes. Currently, P2F comprises sixteen members from different\n> Lithuanian ministries, universities and private companies.\n> It is one of our immediate tasks, to gather 50-70 project proposals from\n> previously successful funded ICT projects. Thus, we aim to achieve both, (a)\n> to facilitate the project development work of the working group, as well as\n> (b) to identify appropriate cooperation partners and programmes for joint\n> projects. The gathered information will be made available to the members of\n> the working group P2F only.\n> For this reason we kindly ask you to provide us with more background\n> information to the project mentioned above. Of a particular interest for us\n> would be the project application form as it was submitted to the co-funding\n> donor programme (We currently still lack experience with non-national donor\n> programmes; thus an application example would be of a great value for us).\n>\n> Many thanks in advance for your assistance. If you have any further\n> questions, please do not hesitate to contact Saulius Arelis at any time. You\n> may also get a deeper insight in the functions and responsibilities of the\n> two major stakeholder organisations of the working group P2F at the links\n> below. Yours sincerely,\n>\n> Yours sincerely,\n>\n> Edmundas Zvirblis\n> Project Manager\n> Tel. + 370 2 622623\n> Mobile: + 370 86 55422\n> Fax: + 370 2 622629\n> INFOBALT Centras\n> Vokieciu 28/17-16\n> LT-2001 Vilnius\n> zvirblis@infobalt.lt\n> www.infobalt.lt\n>\n> Saulius Arelis\n> Project Manager\n> Association INFOBALT\n> Tel. + 370 2 622623\n> Mobile: + 370 610 35036\n> Fax: + 370 2 622629\n> saulius@infobalt.lt\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Developer Workshop Report complete",
            "content": "Hi folks,\n\nthe report on the first Developer workshop is completed, available at\nhttp://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_1/\n\n(It has been available for some time in draft form - thanks to those who\ncommented on the drafts).\n\nCheers\n\nCharles McCN\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Intial Workshop Report (Internat'l Workshop) and thought",
            "content": "A very preliminary skeleton for the Initial Workshop Report (the one being\nheld in conjunction with the Dublin Core 2002 Conference) is now available -\nhttp://www.w3.org/2001/sw/Europe/reports/initial_workshop_report/ - and\nlinked from the reports page - http://www.w3.org/2001/sw/Europe/reports/ - as\na work in progress.\n\nAs I was doing this it occurred to me that it might be useful to have an RSS\nfeed available from the reports page, enabling us to track our deliverables\n(and potentially compare them against the calendar of due dates).\n\nIt also seemed like it would be useful to link the deliverables listed in the\nWork package descriptions to the actual reports of deliverables being\ncompleted. Perhaps this is simple enough to automate if we have RDF\ninformation about reports being published.\n\ncheers\n\nCharles\n\n\n\n"
        },
        {
            "subject": "RE: SWAD Europe Marketin",
            "content": "Inspired by the CML work, our RA Alistair is thinking about\nusing RDF to represent molecular structures.  Conversely,\nyou could use those molecular modelling kits, with\nstraws and spiky balls, to construct models of the web!\nDifferent colours for different labels on links and\nresources!\n\nB\n\n\n> -----Original Message-----\n> From: Danny Ayers [mailto:danny666@virgilio.it]\n> Sent: 29 November 2002 17:39\n> To: Graham Klyne; Libby Miller\n> Cc: CV Meek; public-esw@w3.org\n> Subject: RE: SWAD Europe Marketing\n> \n> \n> \n> \n> >At 11:17 AM 11/29/02 +0000, Libby Miller wrote:\n> >>I rather like these:\n> >>http://shop.store.yahoo.com/elogo/tangletoy.html\n> \n> They do look fun.\n> \n> >Before I read this, I was thinking of something that could \n> also illustrate\n> >the utility of RDF.\n> \n> A very good idea. Just prior to Rubik cubes hitting the big \n> time I got one\n> through a small ad somewhere (back of New Scientist?), along with an\n> explanatory booklet. The booklet was more like an academic \n> paper, delving\n> pretty deeply into group theory. I struggled through the \n> booklet, learning\n> stuff I'd have dismissed as just too difficult/dull if it \n> hadn't been for\n> the wonderful cube.\n> \n> >I think this tangle toy probably has a number of topological \n> states that:\n> >(a) could be identified using URIs\n> >(b) their relationships could be described using RDF, e.g. \n> in terms of\n> >loop-twists or some suchlike maneouvre\n> >(c) sequences of operations to change from one state to \n> another might be\n> >derived using a standard RDF tool like cwm or Euler.\n> >\n> >Do we have a mathematician of sufficient skill to work out \n> the details?\n> >\n> >...\n> >\n> >Another thought I had along similar lines was one of those \n> tile puzzles,\n> >where you \"move the hole around\" to obtain some well-ordered\n> >arrangement of\n> >tiles.  (e.g. the RDF-logo?)  Again, linked to RDF \n> descriptions of the\n> >states and solvable using standard off-the-shelf (or off-the-web)\n> >RDF tools.\n> \n> Anyone done RDF for finite state machines??\n> \n> I did see a lovely toy the other day, actually nodes & arcs. \n> The arcs were\n> bar magnets covered in coloured plastic, the nodes ball bearings.\n> Unfortunately they were about ?10 for half a dozen of each.\n> \n> The only thing I can think of to suggest is e-SW angle grinders.\n> (Coincidentally, there some work I need to do on some \n> concrete ledges in our\n> cellar). Cementic Web, anyone?\n> \n> Cheers,\n> Danny.\n> \n> \n\n\n\n"
        },
        {
            "subject": "SWAD-E calendar report  comments pleas",
            "content": "Hi all,\n\nThe second developer report about the calendaring workshop is close to\ncompletion, I think. Comments are very welcome, especially if you\nthink there's something missing.\n\nhttp://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_2/\n\nI'll send it around various lists next week.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Security formats survey  relating to trust wor",
            "content": "As part of the Rutherford Appleton Laboratory work on using semantic web \ntechnology to represent and model trust in open systems, a new document [1] \nis available for review.\n\nThis document surveys a number of security-related Internet protocols and \nsuggests the beginnings of a framework for relating them to trust in open \nsystems.  In internal discussions, we think that a development of this may \nbe the introduction of contracts (and contract descriptions), with quality \nof service requirements, as a way of mapping the unspecified trust inputs \ninto some kind of quantifiable (or describable) values related to risk \nmanagement;  these in turn would be reflected in the policy descriptions \nthat are part of the framework presented here.\n\n#g\n--\n\n[1] http://www.ninebynine.org/SWAD-E/Security-formats-20021202.html\n\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD-E calendar report  comments pleas",
            "content": ">>>Libby Miller said:\n> http://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_2/\n\nThere is one HTML problem the validator found.\n\n173:\n  <h2><a id=\"#outcomes\" name=\"#outcomes\">Outcomes</a></h2>\n\nshould be:\n  <h2><a id=\"outcomes\" name=\"outcomes\">Outcomes</a></h2>\n\nThere are a bunch of broken links and fragments too according to the\nW3C link validator\n  http://validator.w3.org/checklink?uri=http%3A%2F%2Fwww.w3.org%2F2001%2Fsw%2FEurope%2Freports%2Fdev_workshop_report_2%2F&hide_type=all&depth=&check=Check\n\n\nSummary\n\nP2\nsuggest add link\n  W3C 2001 Technical plenary.\n  http://www.w3.org/2001/07/allgroupoverview.html\n\nP4 - add authors names after the various models maybe, to help\ndistinguish them.\n\nMaybe put aims as <ol> so the 1, 2, 3 are clearer.  Or summarize with\none line, giving more detail\n  1. Consider usecases for RDF ..\n    More ...\n  2. Discuss a single RDF calendaring vocab\n    More ...\n  3. Community building; bringing calendar developers together ...\n    More ...\n\nOutcomes\n\nThe http://www.w3.org/2002/10/calendar thing (a 404); was that a\ntodo?  Who suggested it, even if nobody was actioned to do it? DanC\npossibly.\n\nI guess the DanC @@s need passing by his eyes?\n\nLooks like these things need to be owned by people somehow, even if\nit wasn't agreed at the meeting.\n\n\nFAQs\n\nI don't know if it is relevant but I didn't see any mention of the\nABC/harmony model.\n\nOh http://ilrt.org/discovery/2002/04/query/#one is nice; I'd not noticed\nthat before since it was in a doc titled querying.  I'll be citing\nthese as the Miller Principles ;)\n\nUsecases\n\nMaybe after the workshop, but link to the Mitch Kapor / OSA\nFoundation work with PIM tools using RDF?  \"Chandler\" I think\nsomewhere off http://www.osafoundation.org/.  yes:\n\n  [[RDF\n\n  The Resource Description Framework (RDF) is a model for describing\n  metadata, or ?data about data,? facilitating the exchange of\n  structured information between applications. We plan to import and\n  export RDF-formatted information, and support RDF schema semantics in\n  our data model. Users of our application will be able to model their\n  information in terms of classes, objects and the relationships\n  between them.\n  ]] -- http://www.osafoundation.org/technology.htm\n\nMaybe mail a url of this report to their tech list?\n\n\n\"Universal Brokerage Package for Learning\" project needs a ref\nI assume this is UNIVERSAL - http://www.tik.ee.ethz.ch/~univ/\nor http://www.ist-universal.org/\n\nProjects and Tools\n\nI don't see any mention to the Ximian Evolution calendar tools\n\n  Ximian Evolution Calendaring Framework\n  http://developer.ximian.com/articles/whitepapers/calendar/\n\nwhich provides a software API to their calendaring model.  It does\nthe usual stuff such as iCalendar and syncing to palms.  I can't find\nanything more detailed than the above just now.  I think the GNOME\nproject has a calendaring model/API too, somewhere near\nhttp://www.gnome.org/projects/gnome-pilot/.  But since I can't find\nanything specific, feel free to ignore this.\n\n\nReferences\n\nCan you list some of the important references here too, such as\niCalendar, the schemas, all the stuff that is more document-like than\ncode-like, which is already in the last section.\n\nCheers\n\nDave\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "Quoting Chris Hubick <chris@hubick.com>:\n\n> The designers I know don't take accessibility and browser neutrality to\n> heart.  We need more Mac and Linux desktops, more WebTV's, more Mozilla\n> browsers deployed, millions of handhelds with wireless web access, and\n> every web designer needs a deaf or blind person as their boss.  These\n> issues aren't \"real\" enough to most of them.  They think if the page\n> works on their 15\" monitor running Internet Explorer then all is well.\n\n  But only obeying standards do not solve the problems with usability and\n  accessibility. There can be an infinite number of specifications and\n  articles written, still it's obvious that most designers create adequate\n  pages.\n\n  Idea of a \"deaf or blind boss\" is good: there should be an strong authority \n  which keeps reminding a designer that others may not see or feel same effects \n  he's/she's feeling at the moment. But does such an authority exist?\n\n> I think the browsers strict handling of XHTML will probably mean that it\n> will be extremely difficult to catch on.  I think if we would have\n> started out with this behavior 10 years ago, we might all be using\n> gopher or something today.  The reason the web is so successfull is\n> because of the low barrier to entry.  I think there is also a very high\n> elasticity of difficulty.  That is, make it a /little/ harder and you\n> will drop a /lot/ of web authors.\n\n  This is true. \"Learn Web Design in 24 hours\" etc. I've noticed by following\n  several forums that for some reason many designers can't figure the differ-\n  ence between of creating structure, presentation and controls, probably cause \n  of using WYSIWYG editors.\n\n  These designers forms a group, which may design and work actively for the\n  web without a clue about standards and recommendations. Now when someone\n  comes and tells them to start obeying standards, everything stops:\n  \"Have I been doing wrong for years? But how does my browser displays \n   everything properly? Well, it's worth giving a shot..\"\n  When the validator gives first errors about FONT tags and improperly defined\n  dimensions for table, designer usually gives up - rather than starts finding\n  a solution. \n  \n> I think it is the environment.  I think web authors need to be directly\n> exposed to the vast array of user agents out there.  They need to be\n> shown their sites on everything from PC's, Macs, Unix boxes, PDA's,\n> Braille terminals, voice browsers, etc, etc, etc.  And I think they need\n> better examples.  I think Wired's redesign is in the right direction\n> (but still far from ideal).  We need more good examples of real and\n> attractive sites which can display on any device.\n\n  But how can we create those \"good examples and attractive sites\" when nobody's\n  watching or listening? Should there be an inofficial W3C, which would create\n  more practical and easier-to-understand examples for teachers/professors at\n  schools, designers in major companies, etc.? Or is it ok just to wait for\n  re-designs to happen?\n\n  There's still more factors and authors which gives an image that there's no\n  need for obeying standards nor care about users with impairments or limited\n  client programs. I'm not saying these factors should be overruled by the\n  \"absolute truth of designing\", but sometimes it seems futile to claim \n  something which really has no other support than few articles written in the\n  web when there's large corporations/books/teachers on the other side.\n\n  Happy New Year,\n  Zvona\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "Hello Chris,\n\n\nYou wrote:\n>The problem is making people care about doing something the /right/\nway.<\n\nCan you tell me what the differeence is  between learning a foreign\nlanguage using the correct grammar and semantics, and learning an\ninternetlanguage (in this case XHTML)  and  also using the correct\ngrammar and semantics?\n\nIMHO both should be done so correctly as possible.\n\nCheers\nIneke van der Maat\n\n\n\n"
        },
        {
            "subject": "RE: Right Tools RE: Promotion of XHTM",
            "content": "Don't you think it is really up to us, designers and developers who have\nbeen converted, to preach to our colleagues and educate the next\ngeneration of developers?\n\n++++++\n\nYes, it is up to us the \"enlightened\" to promote and educate the next,\nand indeed current, generation of developers (I swear that they're\ngetting sick of me talking about validation and accessibility at work at\nwork).\n\nI suppose it comes down to whether the W3C want to be seen as just a\nstandards organisation who solely write the standards for the WWW and\nwho rely on third parties such as WaSP to work with companies like\nMacromedia. Or do they want to actively work with and get their name on\nsuch high profile products?  For example, HTML Tidy has that great \"if\nyou want to learn more about standards....\" line when you run it (at\nleast in TopStyle it does - it's the only place I've used it).  Now, if\nthat was included in Dreamweaver MX more people would be aware of\nexactly why they are bothering to validate.  They would see that kind of\nmessage every time which would hopefully help bring the concept of XHTML\n/ standards home to people.\n\nIf the W3C just want to write the standards and rely on evangalism to\nspread the message then, IMHO, there's a limited amount that they can\nexpect in return.  It's relying on the passion and dedication of people\nwho know and understand the reasons why it's important to write XHTML.\nBut apart from giving us badges to put on our sites, there's not a huge\namount we can do to really reach the masses.  Sure, we can publsih\narticles online about this very subject, but who apart from the\n\"nerdly-inclined\" will read them?\n\nThe ISO is an organisation that is known globally.  When I was a kid\nthere used to be \"kite marks\" engraved onto car windows showing that the\nglass met a certain standard.  Every time I walked past a car, I'd check\nfor a kite mark and the things were everywhere.  That's what we need for\nthe W3C logo and message(s) - but not just on sites; it needs to be in\nsoftware packages and in the manuals that come with them.  It needs to\nbe ubiquitous with the Web.\n\nFrancis\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "On Wed, 2003-01-01 at 12:14, Ineke van der Maat wrote:\n> You wrote:\n> > The problem is making people care about\n> > doing something the /right/ way.\n> \n> Can you tell me what the differeence is  between learning a foreign\n> language using the correct grammar and semantics, and learning an\n> internetlanguage (in this case XHTML)  and  also using the correct\n> grammar and semantics?\n> \n> IMHO both should be done so correctly as possible.\n\nPeople learn languages, spoken or technical, for the purpose of\ncommunication and information exchange, not for the sake of learning the\nlanguage itself.  Language is a \"means\" not an \"ends\" in both cases. \nPeople generally only learn enough of the language necessary to fulfill\ntheir specific needs.\n\nMany people who speak english don't know what \"anterior\" means because\nthey generally don't /need/ the term to express what they personally use\nenglish for.  Similarily, many people writing web pages don't know what\na \"div\" is, because they generally don't /need/ it to express what they\npersonally use HTML for.\n\nYes, perhaps people would be better off to learn the meaning of both,\nbut neither are required, and are thus used rather infrequently.  If you\nfind a person who is capable of expressing any concept they wish while\nspeaking english, you will have a difficult time getting them to learn\nnew english words.  People generally just learn enough to do what they\nwant to do, learning more only when necessary.\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "Re: Right Tools RE: Promotion of XHTM",
            "content": "Francis wrote:\n> I suppose it comes down to whether the W3C want to be seen as just a\n> standards organisation who solely write the standards for the WWW and\n> who rely on third parties such as WaSP to work with companies like\n> Macromedia. Or do they want to actively work with and get their name on\n> such high profile products?  \n> [...]\n> If the W3C just want to write the standards and rely on evangalism to\n> spread the message then, IMHO, there's a limited amount that they can\n> expect in return.  It's relying on the passion and dedication of people\n> who know and understand the reasons why it's important to write XHTML.\n\nI am not sure this is really a correct or good standpoint to adopt.\nWe shouldn't really be thinking in terms of what the W3C wants\nor not - it should be what we as a web development community wants\nto achieve - and what we should to for ourselves in order to push\nthings the right way. WASP is group of Web designers/developers,\nMACCAWS is a similar group with a specific goal.\n\nWhile I'm rather simplifying it by saying this, the W3C works with \nvarious other companies and organisations to establish recommendations\nwith the aim to ensure a sensible evolution of the Web, but they\nare not by any means a reinforcement authority. I would rather think\nthat we developers who are passionate about growing the Web in a sensible \nmanner have every reason to say this is /what we want/, not what the\nW3C or any other organisation wants.\n\nHowever, it could be good to have an independent certification authority, \nmuch like for ISO certification, which is not actually part of the standards\nbody itself. This authority can certify if a company's websites are compliant \nand are of a particular level of quality, for example, or as what Francis \nsuggested, put labels on software boxes as a sign of a \"quality product\".\n\n> But apart from giving us badges to put on our sites, there's not a huge\n> amount we can do to really reach the masses.  Sure, we can publsih\n> articles online about this very subject, but who apart from the\n> \"nerdly-inclined\" will read them?\n\nThere is plenty we can do to reach the masses. Education begins in\nsmall steps. Education in universities, colleges, education of\nmanagement in companies who are developing or renovating websites, \neducation of designers - establishing where designers are learning their\n\"tricks\" from. The toughest audience I have found, in fact, are\nprogrammers and developers. \n\nThe world doesn't get changed in a day (or at least not by humans)\n- it's a matter of patience and persistance.\n\nregards,\n-steph\n\n-- \n\n\n\n"
        },
        {
            "subject": "RE: Right Tools RE: Promotion of XHTM",
            "content": "At 19:27 +0000 2003-01-01, fstorr wrote:\n>The ISO is an organisation that is known globally.  When I was a kid\n>there used to be \"kite marks\" engraved onto car windows showing that the\n>glass met a certain standard.  Every time I walked past a car, I'd check\n>for a kite mark and the things were everywhere.  That's what we need for\n>the W3C logo and message(s) - but not just on sites; it needs to be in\n>software packages and in the manuals that come with them.  It needs to\n>be ubiquitous with the Web.\n\nIt's called certification and it's another business. :)\n\nsome facts about ISO\nISO - http://www.iso.ch/\nThe ISO has developped around 13000 standards. Their standards are \nnot free. You have to pay to access them. The International \nOrganization for Standardization (ISO) is a worldwide federation of \nnational standards bodies from more than 140 countries, one from each \ncountry. ISO is a non-governmental organization established in 1947. \nThe technical work of ISO is highly decentralized, carried out in a \nhierarchy of some 2 850 technical committees, subcommittees and \nworking groups. They have a full time staff of 665 persons (500 in \nmember bodies + 165 in Geneva)\nISO Budget = 150,000,000.00 Swiss Franc\n  (=108,410,602.00 US Dollar)\n\nW3C\nStaff: 72\nW3C Budget = 7,000,000 US Dollar (I think, not exactly sure)\nThe ISO does not work exactly the same at the organization level than the W3C.\n\n\nbtw in http://www.iso.ch/iso/en/aboutiso/introduction/index.html\n\"Standards are documented agreements containing\n technical specifications or other precise criteria to\n be used consistently as rules, guidelines, or\ndefinitions of characteristics, to ensure that materials,\nproducts, processes and services are fit for their\npurpose.\"\n\nWhat W3C also does for the Web.\n\nW3C is a lot younger than ISO, with less resources.\n\nWhat you were saying about branding comes from the certification \nactivity of ISO. This certification activity is not done by ISO \nitself but by other companies which buy to ISO their ability to \nverify the conformity of something against an ISO standard. These \ncertifiers sells after that their service to put a seal with the ISO \nbrand name on the product, company, etc.\nFor example, the most well known is ISO 9001.\n\nTo discuss certification the list www-qa@w3.org is here for that. :)\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "RE: Right Tools RE: Promotion of XHTM",
            "content": "There is plenty we can do to reach the masses. Education begins in small\nsteps. Education in universities, colleges, education of management in\ncompanies who are developing or renovating websites, \neducation of designers - establishing where designers are learning their\n\"tricks\" from. The toughest audience I have found, in fact, are\nprogrammers and developers. \n\nThe world doesn't get changed in a day (or at least not by humans)\n- it's a matter of patience and persistance.\n\n++++++\n\nIndeed - the toughest audiences are those developers who are already out\nthere and don't really see the need to change because, hey, their page\nworks already.  I remember one of my old managers saying \"hey, who put\nthis damn doctype in the page, no wonder it's stopped working\"......\n\nSo, yes, small steps.  We'll win in the end though :)\n\nFrancis\n\n\n\n"
        },
        {
            "subject": "RE: Right Tools RE: Promotion of XHTM",
            "content": "<snip>\n\n>to be in software packages and in the manuals that come with them.  It \n>needs to be ubiquitous with the Web.\n\nIt's called certification and it's another business. :)\n\n<snip>\n\nAhhh, only 13,000 standards then?\n\nYou've got some catching up to do :)\n\nRegards\n\nFrancis\n\n\n\n"
        },
        {
            "subject": "Re: Teaching XHTML/CSS (was Re: Promotion of XHTML",
            "content": "John Colby wrote:\n\n> And the even lazier way is to make another all enveloping CSS bag whihc \n> can contain multiple XHTML content documents - but the CSS can apply to \n> more than one XHTML content document, so look and feel is easier if you \n> want to change it.\n\nI'm not sure the CSS should be a bag that contains XHTML documents .. \nthat seems wrong.\n\nCSS is the way the boxes are presented - maybe the table they sit on.\n\nTurn the table round through 90 degrees, and you have a different view \nof the same objects (media=\"voice\"). Rotate the table again, and we have \nanother view of the same objects (media=\"print\"). Rotate again, and we \nhave yet another view (media=\"handheld\").\n\nThe XHTML object haven't changed - it's just the way we are viewing them.\n\n-- \ndrew mclellan\n\nauthor: dreamweaver mx web development\nhttp://dreamweaverfever.com/read/\n\nwasp dreamweaver task force\nhttp://www.webstandards.org/\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "\"Ineke van der Maat\" <inekemaa@xs4all.nl>\n> You wrote:\n> >The problem is making people care about doing something the /right/\n> way.<\n>\n> Can you tell me what the differeence is  between learning a foreign\n> language using the correct grammar and semantics, and learning an\n> internetlanguage (in this case XHTML)  and  also using the correct\n> grammar and semantics?\n\nI don't agree, the key thing with foriegn language is being able to get\nthe job done, ie understand, and be understood, proper grammar helps, but\ndoesn't help that much, especially with English where grammar is often\nrather perverse, and trying to use correct grammar can often get in the\nway of actual communication as you concentrate on getting grammar right,\nrather than just getting your idea across.  Correct grammar helps, but it\ndoesn't make such a difference that you won't get your meal, or into your\nhotel.\n\nThis is the same with web authoring, the key thing is communication of the\ncontent, correct grammar helps, but it's not essential, the content is\nessential.  I will never use XHTML, whilst the XML application well\nformedness requirements is taken by XHTML browsers as meaning don't render\nif there's any mistake (this is different to SVG's approach, where\nrendering happens despite well-formedness errors) because whilst my QA\nshould mean no invalid documents are served, I don't want to take the risk\n(especially with proxies altering content on the way.)\n\nSo there's no difference between foriegn languages and mark-up languages,\nthe most important thing is communication, not the grammar.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: Teaching XHTML/CSS (was Re: Promotion of XHTML",
            "content": "On Wed, 1 Jan 2003, Drew McLellan wrote:\n\n> John Colby wrote:\n>\n> > And the even lazier way is to make another all enveloping CSS bag whihc\n> > can contain multiple XHTML content documents - but the CSS can apply to\n> > more than one XHTML content document, so look and feel is easier if you\n> > want to change it.\n>\n> I'm not sure the CSS should be a bag that contains XHTML documents\n> ..  that seems wrong.\n>\n> CSS is the way the boxes are presented - maybe the table they sit\n> on.\n>\n> Turn the table round through 90 degrees, and you have a different\n> view of the same objects (media=\"voice\"). Rotate the table again,\n> and we have another view of the same objects (media=\"print\"). Rotate\n> again, and we have yet another view (media=\"handheld\").\n\nYeah. And then give students several differently colored glasses to\nrepresent client-side styles (and make one set not transparent to\nrepresent blind folks?).\n\n$0.02,\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "calendar workshop report done: thanks for comment",
            "content": "Thanks to Dave, Graham, Dan B and Dan Connolly for very useful comments\n- they were very much appreciated.\n\nhttp://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_2/\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "JOIN for FREE ... Learn and Ear",
            "content": "Hello:\n\n        My name is Charles Cedeno. I am now focusing in one online\nopportunity.I have tried several of these opportunities full of hype\npromising us thousands of dollars every month. I would get all excited and\nrun to my family and friends with another \"Great Money Maker \".  It is a\nsad fact that many people who are in need of additional income, are being\nvictimized by these fly by night scam artists. \nAs a result of trying all these opportunities, I finally found the\ncompany which is true to their words. Not full of hype, but consistently\nsend me the monthly check. They have given me the best compensation plan\nwith their high % commission. I didn't have to perform some juggling act\nto maintain some 60 to 40% balance in my legs. It is not a pyramid, so\nthere are no legs. It is not one of those binary compensation plan\nfailures either. Everyone earns commissions here. They are providing a\nreal service not the one that simply transfers wealth from the new signups\nto the people at the top.\n When you join, you will have a team of up line sponsors who will help\nyou succeed every step of the way. Instead of being left alone, you will\nbe guided step by step by real people, not those auto responders. Only you\ncan make your own success together with the help of your sponsors. If you\nhave 2 to 3 hours a day, you will be able to earn a full income in a few\nmonths. And there is absolutely no limit as to how much you can earn. It\nis designed to gain momentum after some time. But I prefer to avoid such\nstatements as \"You will get rich\". I read it everywhere and will not allow\nmyself to sound like them. I experienced it personally, you can be\ncomfortable. \nTo get your FREE membership ID, send email to charlescedeno@yahoo.com and\nput \"REGISTER ME FOR FREE\" in the subject and your full name in the body\nof your email. Also include the statement below in the body of your email.\n\"By submitting a request for a FREE DHS Club membership I agree to receive\nemails from DHS Club for both their Consumer and Business Opportunities.\"\nI will then register you into the system. You will receive a confirmation\nemail asking you to verify. Open it up and activate your free membership\nimmediately. Then set back and watch as your new business explodes.\n\n\nBest regards,\n\n\nCharles Cedeno\n\n\nNote: You don't need to request for removal. This is a one-time email.\nYour email address will be automatically de-activated in our list if you\ndon't respond to this mail.\n\n\n\n"
        },
        {
            "subject": "note of spam through publicevangelist mailing lis",
            "content": "Hello,\n\nThe following person is using the public-evangelist mailing list as a \nmethod to send spam (unsollicited, commercial e-mail) to me.\n\nHere is a full transcript of that e-mail:\n\n<transcript>\nResent-Date: Mon, 6 Jan 2003 04:47:54 -0500 (EST)\nFrom: \"Charles Cedeno\" <charlescedeno@mail.com>\nTo: <public-evangelist@w3.org>\nDate: Mon, 6 Jan 2003 17:42:59 +0800\nReply-To: \"Charles Cedeno\" <charles.c@konzoo.com>\nSubject: JOIN for FREE ... Learn and Earn\nX-Archived-At: \nhttp://www.w3.org/mid/200301060947.h069lXa23113@intergate.saturnee.com\nResent-From: public-evangelist@w3.org\nX-Mailing-List: <public-evangelist@w3.org> archive/latest/373\nX-Loop: public-evangelist@w3.org\nSender: public-evangelist-request@w3.org\nResent-Sender: public-evangelist-request@w3.org\nList-Id: <public-evangelist.w3.org>\nList-Help: <http://www.w3.org/Mail/>\nList-Unsubscribe: <mailto:public-evangelist-request@w3.org?subject=unsubscribe>\n\n\nHello:\n\n         My name is Charles Cedeno. I am now focusing in one online\nopportunity.I have tried several of these opportunities full of hype\npromising us thousands of dollars every month. I would get all excited and\nrun to my family and friends with another \"Great Money Maker \".  It is a\nsad fact that many people who are in need of additional income, are being\nvictimized by these fly by night scam artists.\nAs a result of trying all these opportunities, I finally found the\ncompany which is true to their words. Not full of hype, but consistently\nsend me the monthly check. They have given me the best compensation plan\nwith their high % commission. I didn't have to perform some juggling act\nto maintain some 60 to 40% balance in my legs. It is not a pyramid, so\nthere are no legs. It is not one of those binary compensation plan\nfailures either. Everyone earns commissions here. They are providing a\nreal service not the one that simply transfers wealth from the new signups\nto the people at the top.\n  When you join, you will have a team of up line sponsors who will help\nyou succeed every step of the way. Instead of being left alone, you will\nbe guided step by step by real people, not those auto responders. Only you\ncan make your own success together with the help of your sponsors. If you\nhave 2 to 3 hours a day, you will be able to earn a full income in a few\nmonths. And there is absolutely no limit as to how much you can earn. It\nis designed to gain momentum after some time. But I prefer to avoid such\nstatements as \"You will get rich\". I read it everywhere and will not allow\nmyself to sound like them. I experienced it personally, you can be\ncomfortable.\nTo get your FREE membership ID, send email to \ncharlescedeno@yahoo.com and\nput \"REGISTER ME FOR FREE\" in the subject and your full name in the body\nof your email. Also include the statement below in the body of your email.\n\"By submitting a request for a FREE DHS Club membership I agree to receive\nemails from DHS Club for both their Consumer and Business Opportunities.\"\nI will then register you into the system. You will receive a confirmation\nemail asking you to verify. Open it up and activate your free membership\nimmediately. Then set back and watch as your new business explodes.\n\n\nBest regards,\n\n\nCharles Cedeno\n\n\nNote: You don't need to request for removal. This is a one-time email.\nYour email address will be automatically de-activated in our list if you\ndon't respond to this mail.\n</transcript>\n\n\nI am not undertaking any actions myself (yet) against this person, \nother than notifying you (reader) of the observed practice. I hope \nthe W3C mailing lists stay free of commercial messages like these.\n\nRegards,\n\n\n\n"
        },
        {
            "subject": "XHTML 2.0 and Semantic",
            "content": "I think that some people will talk about it here.\n\nSo I think you have already read this entry of Mark Pilgrim.\nhttp://diveintomark.org/archives/2003/01/13.html#semantic_obsolescence\n\nabout http://www.w3.org/TR/2002/WD-xhtml2-20021211/\nand http://www.w3.org/TR/2002/WD-xhtml2-20021211/mod-text.html#s_textmodule\n\nI remind people that:\n1. XHTML 2.0 is still a WD\n2. You send comments about this XHTML version to the mailing \nlist. Specs are also made by the public... if this public send \ncomments to the mailing list. The process of W3C has to reply to all \ncomments sent on the mailing list when they address specific issues.\n\n\"Public discussion of XHTML takes place on\nwww-html@w3.org (archive). To subscribe send\nan email to www-html-request@w3.org with the\nword subscribe in the subject line.\n\nPlease report errors in this document to\nwww-html-editor@w3.org (archive).\"\n\nI hope that Mark Pilgrim will send his comments to the www-html \nmailing list too.\n\nThanks.\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "Mr. Dubost, Why would you post this profanity riddled piece of \nself-indulgence to a public mailing list?\n\nIrrespective of the (microscopic)logic of the \"argument\", Mr. Pilgrim's \npost is self-indulgent and immature; it should not be spread any wider \nthan Mr. Pilgrim's already apparently substantial following. If people \nwant to subscribe, perhaps out of amusement, to watch his lack of \nself-control and verbal tantrums that's one thing. To have someone, \nparticularly a person representing the W3C actually post references to \nMr. Pilgrims emotional screed and further spread the noise is \ninappropriate in the extreme.\n\n               ...edN\n\nKarl Dubost wrote:\n> \n> I think that some people will talk about it here.\n> \n> So I think you have already read this entry of Mark Pilgrim.\n> http://diveintomark.org/archives/2003/01/13.html#semantic_obsolescence\n> \n> about http://www.w3.org/TR/2002/WD-xhtml2-20021211/\n> and http://www.w3.org/TR/2002/WD-xhtml2-20021211/mod-text.html#s_textmodule\n> \n> I remind people that:\n>     1. XHTML 2.0 is still a WD\n>     2. You send comments about this XHTML version to the mailing list. \n> Specs are also made by the public... if this public send comments to the \n> mailing list. The process of W3C has to reply to all comments sent on \n> the mailing list when they address specific issues.\n> \n>     \"Public discussion of XHTML takes place on\n>     www-html@w3.org (archive). To subscribe send\n>     an email to www-html-request@w3.org with the\n>     word subscribe in the subject line.\n> \n>     Please report errors in this document to\n>     www-html-editor@w3.org (archive).\"\n> \n> I hope that Mark Pilgrim will send his comments to the www-html mailing \n> list too.\n> \n> Thanks.\n> \n\n\n\n"
        },
        {
            "subject": "Re[2]: XHTML 2.0 and Semantic",
            "content": "Mr. Nixon wrote:\n> To have someone,\n> particularly a person representing the W3C actually post references to \n> Mr. Pilgrims emotional screed and further spread the noise is \n> inappropriate in the extreme.\n\nI've been fairly quiet on this list and don't wish to appear\ndisrespectful in the least, but it would seem to me that the\nsentiments expressed in that online rant (profanity aside) would\nbe /very/ relevant to a list such as this, whose charter includes\n\n> A place to discuss about web standards Education and Outreach\n> with web standards evangelists, authors of books, articles or\n> other resources on web standards.\n\nAfter all, these attitudes may very well represent some of the\nthings we're trying to overcome by evangelising standards, i.e.\n\"what's in it for me\"?\n\nThe post clearly states frustration with the amount of work it\ntakes to embrace the concept of semantic markup and adhering to\nstandards (when moving from a non-semantic and non-standards\nenvironment), while getting little discernible payoff in the\n\"here and now\" - sort of like whistling in the dark to make\nyourself feel better.\n\nWhile I may not agree with the rant 100%, it's not the first time\nI've heard such a thing, and posts like this may make this\nfeeling more widespread. Maybe we could turn this into a\ndiscussion on how to combat it and thereby help with the goal of\nhelping to educate others on the importance of standards?\n\nRegards,\nAngie McKaig\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "I would like to thank Karl for posting [a link to] Mark Pilgrim's\nthoughts on this list. While I am not particularly excited about Mark's\nchoice of words, I think he voices important concerns shared by many\npeople.\n\nIndeed, W3C is having a hard time delivering on its promise of a\n\"future proof\" markup, especially given the amount of new \"things\"\nbeing introduced into the problem domain. Does the gap between W3C and\nreality grow with every new draft? If yes, what can W3C evangelists do\nabout it? These are important questions worth discussing on this list\nand elsewhere.\n\nThank you,\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\nOn Mon, 13 Jan 2003, ed nixon wrote:\n\n>\n> Mr. Dubost, Why would you post this profanity riddled piece of\n> self-indulgence to a public mailing list?\n>\n> Irrespective of the (microscopic)logic of the \"argument\", Mr.\n> Pilgrim's post is self-indulgent and immature; it should not be\n> spread any wider than Mr. Pilgrim's already apparently substantial\n> following. If people want to subscribe, perhaps out of amusement, to\n> watch his lack of self-control and verbal tantrums that's one thing.\n> To have someone, particularly a person representing the W3C actually\n> post references to Mr. Pilgrims emotional screed and further spread\n> the noise is inappropriate in the extreme.\n>\n>                ...edN\n>\n> Karl Dubost wrote:\n> >\n> > I think that some people will talk about it here.\n> >\n> > So I think you have already read this entry of Mark Pilgrim.\n> > http://diveintomark.org/archives/2003/01/13.html#semantic_obsolescence\n> >\n> > about http://www.w3.org/TR/2002/WD-xhtml2-20021211/\n> > and http://www.w3.org/TR/2002/WD-xhtml2-20021211/mod-text.html#s_textmodule\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "At 17:09 -0500 2003-01-13, ed nixon wrote:\n>Mr. Dubost, Why would you post this profanity riddled piece of \n>self-indulgence to a public mailing list?\n\n- About Mark\nNo profanity at all. The role of W3C is to reach the consensus inside \nthe WG. The comments of the public must be addressed and the W3C Team \nor people inside WG are not in an ivory tower. It's why comments of \nthe public are always interesting even if they do not please a part \nof the community.\n\nI have noticed like you that the tone of Mark Pilgrim was a bit \nangry. We are here to have a dialog and a discussion. I will not \nadopt the position of the ostrich (put our head in the sand) and \nignore comments even if they are not favorable. The role of W3C is \nnot to enforce but to find a solution which leads to interoperability.\n\nEvolution means that sometimes you have to drop features and \nsometimes you have to keep some. Not so many people know the process \nof W3C even if the document is widely accessible. And it's why I have \ninvited Mark to send his comments to the list.\n\n*Topic Mark Pilgrim closed*\n\n*Topic XHTML open*\n\nin the QA Specification Guidelines (which is a WORKING DRAFT too), we \nrecommend in the guideline 7. Identify the relation between \ndeprecated features and conformance.\n\nSee http://www.w3.org/QA/WG/2002/12/qaframe-spec-20021220#b2ab3d293\n\nwith the following checkpoints\n\n7.1 Identify each deprecated feature. [Priority 1]\n7.2 For each class of product, specify the degree of\n     support required for each deprecated feature and\n     the conformance consequences of the deprecation. [Priority 1]\n7.3 Include an explanation for the deprecation. [Priority 3]\n7.4 Include examples to illustrate how to avoid\n     using deprecated features. [Priority 3]\n\nI will review with my QA and Conformance hat the XHTML 2.0 WD when it \nwill be close to the Last Call Stage to recommend the HTML WG to \ndeclare every choices like against the QA Spec Guidelines.\n\n\nI remind to the people that it's really important to send your \nreviews and comments to the www-html list if you want to raise your \nvoice.\n\n\nPS: you can call me Karl.\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "On Mon, 2003-01-13 at 15:40, Alex Rousskov wrote:\n> Indeed, W3C is having a hard time delivering on its promise of a\n> \"future proof\" markup\n\nI think they are doing just fine.  All the existing documents that have\nbeen marked up semantically can be easily/automatically translated to\nnewer standards (either by rewriting the document itself, or within the\nuser agent).  With documents using non-semantic markup, font tags, etc,\nit would be vastly more difficult to understand the meaning of these in\nterms of \"new\" semantics.  I think perhaps what we need are more readily\navailable tools for upgrading documents to newer standards, perhaps even\nas part of the working groups deliverables along with the specification.\nAnd as far as the \"future\" is concerned... I think the web as we know it\ntoday is just the tip of the iceberg.  I think the decisions we make\ntoday are going to be increasingly difficult to change in the future, as\nthese standards become vastly even more entrenched than they are\nalready.  I am more concerned with the longer term outlook, even say 25\nto 50 years down the road.  Nobody is forcing you to upgrade to XHTML\n2!  I am, for one, pleased to see a fresh start using all that we have\nlearned.  In the long term I think we will have a cleaner and more rich\nbase of documents to work with, and will look back and be glad we made\nthe transition now.\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "Re: calendar workshop report done: thanks for comment",
            "content": "I've just looked through -- I think that will be a most useful \nresource;  lots of useful pointers, information, etc.\n\nMany thanks,\n\n#g\n--\n\nAt 05:43 PM 12/12/02 +0000, Libby Miller wrote:\n\n\n>Thanks to Dave, Graham, Dan B and Dan Connolly for very useful comments\n>- they were very much appreciated.\n>\n>http://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_2/\n>\n>cheers\n>\n>Libby\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "On 13 Jan 2003, Chris Hubick wrote:\n\n> On Mon, 2003-01-13 at 15:40, Alex Rousskov wrote:\n> > Indeed, W3C is having a hard time delivering on its promise of a\n> > \"future proof\" markup\n>\n> I think they are doing just fine.  All the existing documents that\n> have been marked up semantically can be easily/automatically\n> translated to newer standards (either by rewriting the document\n> itself, or within the user agent) With documents using non-semantic\n> markup, font tags, etc, it would be vastly more difficult to\n> understand the meaning of these in terms of \"new\" semantics.\n\nYou are making an implicit assumption that a \"document\" is something\nstatic that can be easily modified. I bet that most moderately-complex\nsites today are not implemented using static files but are generated\nusing scripts/programs. Thus, in most interesting cases we are talking\nabout modifying _programs_ (server- or client-side), not \"documents\".\nThis kind of modification is not easy to automate at all and \"tools\"\nwill be of little help.\n\nYou are also probably making an implicit assumption that the majority\nof existing documents have been marked up semantically (otherwise, it\nwould make little sense to justify W3C actions by talking about these\ndocuments). I doubt that is true.\n\nBased on my personal experience, it takes a lot of resources to keep\nup-to-date with W3C, and it should not be this way if W3C cares about\nsmall, resource-limited content \"publishers\".\n\nWhat does \"future proof\" stand for? IMO, it means that if I use _any_\nstandard published by W3C, I should not be pummeled for not switching\nto newer standards. I may miss on some cool new features, of course,\nbut I should not receive complaints that my site is not \"standard\" or\nnot \"compliant\". So far, the discussions on this list and other public\ncomments of Web authors make me think that W3C markup is not \"future\nproof\". Moreover, there is no sign of the markup becoming more future\nproof with every new standard published (see Mark Pilgrim comments,\nfor example).\n\n> ... In the long term I think we will have a cleaner and more rich\n> base of documents to work with, and will look back and be glad we\n> made the transition now.\n\nI agree that we should try to look 10-25 years ahead. Unfortunately, I\ndo not see a _transition_ path. Most changes require a _switch_\ninstead of a smooth transition (unless you are willing to support N\nstandards at once, which is even more overhead for small guys). This\nfactor alone can jeopardize our best intentions and create a gap that\n25 years of development will not cure. Think Cobol and Fortran, for\nexample.\n\nWe should not just imagine how things should work and then\nwrite/enforce a standard describing our imaginary ideal! For example,\nmost people would agree that communism is great in its final\n\"everybody is free and happy\" stage, but we all know what happens if\nyou try to jump into that stage without a proper transition. The\nquestion is whether there is a transition path that ends in Markup\nHeaven, and what that path is.\n\n\nThanks,\n\nAlex.\n\n-- \n\n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "Hello Karl,\n\nI don't see pop up my previous mail on this list, so i send this still\nanother time but changed to this list.\n\nYou wrote\n>I will not adopt the position of the ostrich (put our head in the\nsand)<\n\nI have a nice promotion for serving xhtml 1.1 as application/xhtml+xml.\nLook http://www.hoehnermusikfan.net/index.xhtml and you see a real\nostrich that does not put its head in the sand.\nIn German is written when it will not put the head in the sand in 2003\n(is rather politically coloured and was meant as a New year's page) .\n\nI hope Mark Pilgrim will see this page too.\n\nThis is the only real XHTML-page as a test that my fansite really can be\nserved as application/xhtml+xml when IE wants to do it.\n\nI have also concerns about future-proof XHTML. Why replacing XHTML 1.*\nby something that is not backward compatible when many designers have\nnot even made the step to xhtml 1.0 transitional?\nMy concern is that many people will never see a xhtml 2.0 page that is\nnot backward compatible, simply because they refuse to update their\nbrowsers.  So you must have a page version for valid XHTML 2.0, one for\nolder browsers and perhaps  a very simple one for platforms as i-mote\ntoo. Or do you really think that everybody immediately will update\nher/his browser when XHTML 2.0 is a recommendation?\n\nGreetings\nIneke van der Maat\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "Hello Karl,\n\nYou wrote\n>I will not\nadopt the position of the ostrich (put our head in the sand)<\n\nI have a nice promotion for serving xhtml 1.1 as application/xhtml+xml.\nLook http://www.hoehnermusikfan.net/index.xhtml and you see a real\nostrich that does not put its head in the sand.\nIn German is written when it will not put the head in the sand in 2003\n(is rather politically coloured and was meant as a New year's page) .\n\nThis is the only real XHTML-page as a test that my fansite really can be\nserved as application/xhtml+xml when IE wants to do it too.\n\nI hope Mark Pilgrim will see this too.\n\nGreetings\nIneke van der Maat\n\n\n\n"
        },
        {
            "subject": "Re[2]: XHTML 2.0 and Semantic",
            "content": "Hello everyone,\n\n> At 17:09 -0500 2003-01-13, ed nixon wrote:\n>>Mr. Dubost, Why would you post this profanity riddled piece of \n>>self-indulgence to a public mailing list?\n\n> - About Mark\n> No profanity at all. The role of W3C is to reach the consensus inside \n> the WG. The comments of the public must be addressed and the W3C Team \n> or people inside WG are not in an ivory tower. It's why comments of \n> the public are always interesting even if they do not please a part \n> of the community.\nInteresting point. Following your logic, which comments are\nuninteresting? Who is the judge here? I ask because I saw a great\nnumber of letters which were never addressed. Perhaps these were\n\"uninteresting\", huh?\n\n> I have noticed like you that the tone of Mark Pilgrim was a bit \n> angry. We are here to have a dialog and a discussion. I will not \n> adopt the position of the ostrich (put our head in the sand) and \n> ignore comments even if they are not favorable. The role of W3C is \n> not to enforce but to find a solution which leads to interoperability.\nMark was angry because he didn't know what he wanted. He finally stuck\nto HTML 4, and that's great. No one was *forcing* him to move to XHTML\n1.1, because in the end all the W3C produces are recommendations,\nnot laws. He also misinterpreted the WAI guideline 11.1 [1]. Mark\nthought if he uses the W3C technologies he immediately goes into\necstasies. When it didn't happen he bursted out writing essays on\n\"funky markup\" [2].\n\n> Evolution means that sometimes you have to drop features and \n> sometimes you have to keep some.\nFeatures were kept at least three times: from HTML 3.2 to HTML 4.01,\nXHTML 1.0, and XHTML 1.1. It's like from monkey to a very large\nmonkey, to a hairless monkey, and to a orthograde monkey. It's the\ntime to introduce a smart monkey (aka a man). XHTML 2 in our case. :)\n\n> Not so many people know the process\n> of W3C even if the document is widely accessible.\nThe sad thing is that a lot of people have read the document, but\nhonestly, Karl, are you sure all the W3C folks have also read it?\nIf you're not at the W3C it means no matter what letters you\nwrite and no matter how many. Most of them are simply ignored.\nNot \"half-answered\", not \"forgotten\", just ignored. I really\nunderstand why Mark doesn't write to www-html, for example.\n\n> And it's why I have\n> invited Mark to send his comments to the list.\n\n> *Topic Mark Pilgrim closed*\n\n> *Topic XHTML open*\n\n> in the QA Specification Guidelines (which is a WORKING DRAFT too), we \n> recommend in the guideline 7. Identify the relation between \n> deprecated features and conformance.\n\n> See http://www.w3.org/QA/WG/2002/12/qaframe-spec-20021220#b2ab3d293\n\n> with the following checkpoints\n\n> 7.1 Identify each deprecated feature. [Priority 1]\n> 7.2 For each class of product, specify the degree of\n>      support required for each deprecated feature and\n>      the conformance consequences of the deprecation. [Priority 1]\n> 7.3 Include an explanation for the deprecation. [Priority 3]\n> 7.4 Include examples to illustrate how to avoid\n>      using deprecated features. [Priority 3]\n\n> I will review with my QA and Conformance hat the XHTML 2.0 WD when it \n> will be close to the Last Call Stage to recommend the HTML WG to \n> declare every choices like against the QA Spec Guidelines.\n\n> I remind to the people that it's really important to send your \n> reviews and comments to the www-html list if you want to raise your \n> voice.\nI agree it's important. However it's also important to actually\nrespond to those letters.\n\nLinks: [1] http://www.w3.org/TR/1999/WAI-WEBCONTENT-19990505/#gl-use-w3c\n       [2] http://diveintomark.org/archives/2003/01/13.html#semantic_obsolescence\n---\n  Alexander \"Croll\" Savenkov                  http://www.thecroll.com/\n  w3@hotbox.ru                                     http://croll.da.ru/\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "----- Original Message -----\nFrom: \"Alex Rousskov\" <rousskov@measurement-factory.com>\n\n> Does the gap between W3C and\n> reality grow with every new draft?\n\nConsidering that reality is abusing HTML into a plethora of device dependant\nvisual effects, not bothering with validation and semantic value-add - yes\nthere is a gap between W3C and that reality. Has there every been a point\nwhere that gap didn't exist?\n\nIf it is widening then there are two possible scenarios:\n1.) The W3c doesn't understand what the World Wide Web offers to its users\n2.) Website owners don't see the global advantages being offered.\n\n\n> If yes, what can W3C evangelists do about it?\n\nFocus on why its to the visitor's - thus indirectly the website owner's -\nbenefit to adopt recommendations as a starting point. Its a catch-22 really,\nwe need lots of valid and semantically based content to demonstrate the\nglobal-scale usefulness of it, but people want to see the benefits before\nmaking their content semantically useful.\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "\"Karl Dubost\" <karl@w3.org>\n> At 17:09 -0500 2003-01-13, ed nixon wrote:\n> >Mr. Dubost, Why would you post this profanity riddled piece of\n> >self-indulgence to a public mailing list?\n>\n> - About Mark\n> No profanity at all. The role of W3C is to reach the consensus inside\n> the WG. The comments of the public must be addressed and the W3C Team\n> or people inside WG are not in an ivory tower.\n\nUnfortunately though, the role of the W3C is as you say to reach consensus\nwithin the Working Group, dissent from the public can be safely ignored (not\neven addressing the issues) and there's nothing the public can do but rant,\nthe W3 Process does not have any responsibility to the public only to\nmembers.  In theory the public can raise issues which have to be addressed,\nbut in reality these can be ignored without difficulty.  Engaging the public\nis difficult of course, but the W3 has to take public issues seriously, and\nneeds a process to achieve this.  The current laissez-fair attitude to the\nprocess document, means that there's little the public can do often but\nRant. *\n\n> Evolution means that sometimes you have to drop features and\n> sometimes you have to keep some. Not so many people know the process\n> of W3C even if the document is widely accessible. And it's why I have\n> invited Mark to send his comments to the list.\n\nI think the problem Mark is having is assuming that XHTML 2.0 is appropriate\nto his problem, a Mark-Up language is a tool not a religion, if the tool\nisn't right, don't use it.  Personally I've not seen any better tool for web\ndocument publishing since HTML 4.01 strict was released, the improvements\nare not worth the compromises, nor do I see XHTML 1.0 an evolution of HTML,\nor XHTML 2.0 an evolution of XHTML 1.1, yes they are tools aimed at similar\nproblems, and obviously share many features (a posidrive, and flathead\nscrewdriver share many features too, but only 1 is the right tool...)\n\nXHTML 2.0 will also allow much richer mixing of namespaces, so for citing\nother documents, other more complete namespaces can easily be used and may\nbe more sensible.  Instead of having the XHTML WG try and address every type\nof document we might want to publish, we can leave more specific purposes to\nexperrs.  HTML has long suffered a problem where ABBR, and ACRONYM are\nstrangely defined, presumably due to confusion, and lack of experience in\nthe WG when they were developed.  Having XHTML provide a framework where we\ncan hang appropriate vocabularies is much more sensible than trying to have\nXHTML experts design everything.\n\nW3 Evangelism should be about getting people to use the right tool, in the\nright way, not just using the latest trendy tool in a bad way.\n\nJim.\n\n[*] This isn't directed at the XHTML WG specifically, I have no knowledge of\nhow well they respect w3 process and public comments.\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "At 20:03 +0000 2003-01-14, Jim Ley wrote:\n>Unfortunately though, the role of the W3C is as you say to reach consensus\n>within the Working Group, dissent from the public can be safely ignored (not\n>even addressing the issues) and there's nothing the public can do but rant,\n>the W3 Process does not have any responsibility to the public only to\n>members.  In theory the public can raise issues which have to be addressed,\n>but in reality these can be ignored without difficulty.  Engaging the public\n>is difficult of course, but the W3 has to take public issues seriously, and\n>needs a process to achieve this.  The current laissez-fair attitude to the\n>process document, means that there's little the public can do often but\n>Rant. *\n\nThat's definitely wrong :)\n\nhttp://www.w3.org/Consortium/Process-20010719/tr.html#last-call\n***************\n5.2.2 Last Call Working Draft\n\nEntrance criteria. Before advancing a technical report to Last Call \nWorking Draft, the Working Group must:\n\n    1. fulfill the relevant requirements of the Working Group charter \nand those of any accompanying requirements documents, or document \nwhich relevant requirements they have not fulfilled;\n    2. formally address all issues raised by Working Group \nparticipants, other Working Groups, the Membership, and the \n***PUBLIC*** about the Working Draft.\n*******************\n\nformally address is defined in\nhttp://www.w3.org/Consortium/Process-20010719/groups.html#formal-address\n********************\nIn the context of this document, a Working Group has formally \naddressed an issue when the Chair can show (archived) evidence of \nhaving sent a response to the party who raised the issue. This \nresponse should include the Working Group's resolution and should ask \nthe party who raised the issue to reply with an indication of whether \nthe resolution reverses the initial objection.\n*******************\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "\"Karl Dubost\" <karl@w3.org>\n> At 20:03 +0000 2003-01-14, Jim Ley wrote:\n> > In theory the public can raise issues which have to be addressed,\n> >but in reality these can be ignored without difficulty.  Engaging the\npublic\n> >is difficult of course, but the W3 has to take public issues seriously,\nand\n> >needs a process to achieve this.  The current laissez-fair attitude to\nthe\n> >process document, means that there's little the public can do often but\n> >Rant. *\n>\n> That's definitely wrong :)\n\nNo, you're quoting what the Process document says, I agree what it says is\nadequate to ensure Public comments are acknowledged, however since the\npublic have no power of appeal when the process document is not followed, W3\nWGs are free to ignore the Process document (consider the SVG working group,\nit's ignored the process documents requirement on its Charter for at least a\nyear, nothing us public can do but regularly rant about it.)\n\nFormal Addressing of public issues also routinely fail, perhaps because the\nWG fails to monitor the public mailing lists or whatever, but the process\nfails, and the process gives the public no method to appeal (it also has no\nmailing list to raise process issues, which is where this should be, not\npublic-evangelist)\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Blogtalk  A European Weblog Conferenc",
            "content": "http://blogtalk.net/CFP/CFPenglish.html\n\nMaybe a good spot for a e-sw stall?\n\n(I'm thinking of doing a semantic blogging paper, btw)\n\n\n-----------\nDanny Ayers\n\nSemantic Web Log :\nhttp://www.citnames.com/blog\n\n\"The lyf so short, the craft so long to lerne.\" - Chaucer\n\n \n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "On Tue, 14 Jan 2003, Karl Dubost wrote:\n\n> http://www.w3.org/Consortium/Process-20010719/tr.html#last-call\n>     2. formally address all issues raised by Working Group\n> participants, other Working Groups, the Membership, and the\n> ***PUBLIC*** about the Working Draft.\n\nThis not testable and, hence, is not enforceable, of course. There is\nno way to verify whether _all_ raised issues were addressed because\nthere is no practical way to find _all_ raised issues unless WG\nmaintains an apropriate interface, such as a bugzilla database (in\naddition to informal mailing lists).\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "On Wednesday, January 15, 2003, 4:40:23 PM, Alex Rousskov wrote:\n> This not testable and, hence, is not enforceable, of course. There is\n> no way to verify whether _all_ raised issues were addressed because\n> there is no practical way to find _all_ raised issues unless WG\n> maintains an apropriate interface, such as a bugzilla database (in\n> addition to informal mailing lists).\n\nI feel interaction between working groups and the general public could\nbe improved dramatically.\n\nWhat about having working groups being required to issue a monthly\nnewsletter stating what they have done in plain English? Requesting\nfeedback on issues?\n\nOther than answering questions on the public mailing lists and drafts\nfrom time to time, I feel we actually get reasonably little feedback\ndirectly from the WGs.\n\nAnd also, couldn't we have scheduled real-time public meetings? Public\nIRC discussions? That would allow direct conversation and interaction\nbetween members and the public, and would be fantastic imo.\n\n\nCheers\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "ye, use EIRC for a webchat discussion (altho it needs an ircd on the\nwebserver)... easier than pointing people to mirc etc etc...\n\ni have this set up already.. would be happy to set up a w3.org channel/page\nto invite people to...\n\n----- Original Message -----\nFrom: \"Tom Gilder\" <tom@tom.me.uk>\nTo: <public-evangelist@w3.org>\nSent: Thursday, January 16, 2003 12:17 PM\nSubject: Re: XHTML 2.0 and Semantics\n\n\n>\n> On Wednesday, January 15, 2003, 4:40:23 PM, Alex Rousskov wrote:\n> > This not testable and, hence, is not enforceable, of course. There is\n> > no way to verify whether _all_ raised issues were addressed because\n> > there is no practical way to find _all_ raised issues unless WG\n> > maintains an apropriate interface, such as a bugzilla database (in\n> > addition to informal mailing lists).\n>\n> I feel interaction between working groups and the general public could\n> be improved dramatically.\n>\n> What about having working groups being required to issue a monthly\n> newsletter stating what they have done in plain English? Requesting\n> feedback on issues?\n>\n> Other than answering questions on the public mailing lists and drafts\n> from time to time, I feel we actually get reasonably little feedback\n> directly from the WGs.\n>\n> And also, couldn't we have scheduled real-time public meetings? Public\n> IRC discussions? That would allow direct conversation and interaction\n> between members and the public, and would be fantastic imo.\n>\n>\n> Cheers\n> --\n> Tom Gilder\n> http://tom.me.uk/\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "Le jeu 16/01/2003 ? 12:17, Tom Gilder a ?crit :\n> What about having working groups being required to issue a monthly\n> newsletter stating what they have done in plain English? Requesting\n> feedback on issues?\n\nBeing a participant in a WG, I can assure you that the fact that WG have\nto publish a draft every 3 months (as required by W3C Process Document)\nis already a very heavy requirement compared to the resources available\nin WGs. I'm sure that most WG do their best to reply to any issue raised\nin the right forum, to document their issues resolution and to highlight\ntheir open issues in their draft, but requiring them to have more formal\ncommunications on all the front is unlikely to happen due to resources\nconstraint.\n \nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": ">Le jeu 16/01/2003 ? 12:17, Tom Gilder a ?crit :\n>> What about having working groups being required to issue a monthly\n>> newsletter stating what they have done in plain English? Requesting\n>> feedback on issues?\n>\n>Being a participant in a WG, I can assure you that the fact that WG have\n>to publish a draft every 3 months (as required by W3C Process Document)\n>is already a very heavy requirement compared to the resources available\n>in WGs. I'm sure that most WG do their best to reply to any issue raised\n>in the right forum, to document their issues resolution and to highlight\n>their open issues in their draft, but requiring them to have more formal\n>communications on all the front is unlikely to happen due to resources\n>constraint.\n\nI agree formal communication with the public is not a reasonable\nrequirement, however I do feel a public issues list (perhaps with some\nissues censored if necessary) published a number of weeks before a draft\nmoves phases, so the issuer has time to discover if their issue is being\ndiscussed, or has been missed.  There is little extra cost in this other\nthan any censorship required to make the issues list public, rather than\nmember only.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "On Thursday, January 16, 2003, 1:40:42 PM, Dominique Haza?l-Massieux wrote:\n> Being a participant in a WG, I can assure you that the fact that WG have\n> to publish a draft every 3 months (as required by W3C Process Document)\n\nWhere is that requirement?\n\n  \"At least every three months, each Working Group must provide the\n   public with an update of their progress. A progress report may take\n   a variety of forms, including the publication of a technical\n   report\"\n   - http://www.w3.org/Consortium/Process-20010719/groups.html#three-month-rule\n\nAn update could simply be updating a WG homepage as far as I can see.\n\nSomething else I'd like to see are more timelines like the CSS WG have\nwith CSS3 at http://www.w3.org/Style/CSS/current-work#table. Not exact\nrelease dates or anything, it's just nice to have some idea when the\nnext draft might be coming along.\n\n> I'm sure that most WG do their best to reply to any issue raised in\n> the right forum, to document their issues resolution and to\n> highlight their open issues in their draft\n\nIndeed, and they do do an excellent job. The problem is that the\nmailing lists can take a bit of finding, and often aren't very\nfriendly to people new to the W3C (see \"Three design-related (HTML or\nCSS) elements for your consideration\" on www-html for a recent classic\nexample of that).\n\n> but requiring them to have more formal communications on all the\n> front is unlikely to happen due to resources constraint.\n\nReplace an internal WG meeting with a public one every so often? I\ndon't know how practical that would be. Even WGs publishing a simple\nreport of progress they have done ever year would be nice.\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "At 09:08 AM 2003-01-16, Jim Ley wrote:\n\n> >Le jeu 16/01/2003 ? 12:17, Tom Gilder a ?crit :\n> >> What about having working groups being required to issue a monthly\n> >> newsletter stating what they have done in plain English? Requesting\n> >> feedback on issues?\n> >\n> >Being a participant in a WG, I can assure you that the fact that WG have\n> >to publish a draft every 3 months (as required by W3C Process Document)\n> >is already a very heavy requirement compared to the resources available\n> >in WGs. I'm sure that most WG do their best to reply to any issue raised\n> >in the right forum, to document their issues resolution and to highlight\n> >their open issues in their draft, but requiring them to have more formal\n> >communications on all the front is unlikely to happen due to resources\n> >constraint.\n>\n>I agree formal communication with the public is not a reasonable\n>requirement, however I do feel a public issues list (perhaps with some\n>issues censored if necessary) published a number of weeks before a draft\n>moves phases, so the issuer has time to discover if their issue is being\n>discussed, or has been missed.  There is little extra cost in this other\n>than any censorship required to make the issues list public, rather than\n>member only.\n\nWhat we need to formalize is the notion of the \"opt-in panel\" comprising\nthose who took the trouble to contribute comments.  There are multiple\npoints, minor review phases, where the people who should have a voice are\nthose who took the trouble to exercise the invitation to voice comments in a\nclosely related earlier phase.  This could be reflected in access rights,\ntracking notifications, etc.  The notices or digests of activity should come\nautomatically out of the Bugzilla installation [issue-tracking engine] and\nbe controlled by individual preferences as to immediate notification on\nindividual event vs. weekly or whatever periodic updates.  The user can also\nprofile what issues they wish to track.  But they have to take the time to\nget on the reporting-administration site and edit the profile.\n\nAl\n\n>Jim.\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "On Thu, 16 Jan 2003, Al Gilman wrote:\n\n> What we need to formalize is the notion of the \"opt-in panel\"\n> comprising those who took the trouble to contribute comments.\n> There are multiple points, minor review phases, where the people who\n> should have a voice are those who took the trouble to exercise the\n> invitation to voice comments in a closely related earlier phase.\n> This could be reflected in access rights, tracking notifications,\n> etc.  The notices or digests of activity should come automatically\n> out of the Bugzilla installation [issue-tracking engine] and be\n> controlled by individual preferences as to immediate notification on\n> individual event vs. weekly or whatever periodic updates.  The user\n> can also profile what issues they wish to track.  But they have to\n> take the time to get on the reporting-administration site and edit\n> the profile.\n\nI agree, though I would not call it a \"panel\" since W3C, by design,\ndoes not operate on the basis of consensus with public; W3C operates\non the basis of consensus within W3C (AFAIK). Public participants have\nthe right to submit comments and should have the right to see those\ncomments addressed. They should not, however, have formal \"votes\" when\nthe decision is being made. Moreover, W3C does not have to make it\neasy for the public to _group_ their voices;  WG-individual contacts\nshould be sufficient. This is the key difference between IETF (a free\nopt-in public panel) and W3C (a for-fee opt-in semi-private panel).\n\nBugzilla is a good interface for the WG-individual communication, and\nwill make WG accountability relatively simple. However, just\ninstalling Bugzilla would make little difference -- there needs to be\na formal requirement for WGs to address/close pending reports before\neach major milestone. I do not know if W3C is willing to assume such\nan obligation.\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2.0 and Semantic",
            "content": "At 11:38 AM 2003-01-16, Alex Rousskov wrote:\n\n>On Thu, 16 Jan 2003, Al Gilman wrote:\n>\n> > What we need to formalize is the notion of the \"opt-in panel\"\n> > comprising those who took the trouble to contribute comments.\n> > There are multiple points, minor review phases, where the people who\n> > should have a voice are those who took the trouble to exercise the\n> > invitation to voice comments in a closely related earlier phase.\n> > This could be reflected in access rights, tracking notifications,\n> > etc.  The notices or digests of activity should come automatically\n> > out of the Bugzilla installation [issue-tracking engine] and be\n> > controlled by individual preferences as to immediate notification on\n> > individual event vs. weekly or whatever periodic updates.  The user\n> > can also profile what issues they wish to track.  But they have to\n> > take the time to get on the reporting-administration site and edit\n> > the profile.\n>\n>I agree, though I would not call it a \"panel\" since W3C, by design,\n>does not operate on the basis of consensus with public; W3C operates\n>on the basis of consensus within W3C (AFAIK).\n\na) I did not mean to imply any particular voting protocol, or voting status.\n  The 'panel' I referred to is a bag of individuals who have distinguished\nthemselves by contributing comments and to whom it may be beneficial to the\noverall mission satisfaction to afford ancillary services (as individuals),\nsuch as notification of state changes in the processing of comments.\n\nI called them a 'panel' because these people should get asked to verify that\nthe changes actually made to the document address the issues that they\nraised in their comments.  At a point where the general public that hasn't\nspoken up in the public comment period don't get so asked.  This bag of\nindividuals is a quality resource, and we need to recognize this in our\nprocess theories and capitalize on it in our process automation.\n\n>Public participants have\n>the right to submit comments and should have the right to see those\n>comments addressed. They should not, however, have formal \"votes\" when\n>the decision is being made. Moreover, W3C does not have to make it\n>easy for the public to _group_ their voices;  WG-individual contacts\n>should be sufficient. This is the key difference between IETF (a free\n>opt-in public panel) and W3C (a for-fee opt-in semi-private panel).\n>\n>Bugzilla is a good interface for the WG-individual communication, and\n>will make WG accountability relatively simple. However, just\n>installing Bugzilla would make little difference -- there needs to be\n>a formal requirement for WGs to address/close pending reports before\n>each major milestone. I do not know if W3C is willing to assume such\n>an obligation.\n\nBeg pardon?  The formal requirement is already there in many cases, to\nnotify individual commentors of the disposition of their comments and to ask\nthem to indicate their acquiescence or opposition with regard to this\ndisposition.  So far we are missing satisfaction of this requirement too\noften, and when we do satisfy it it is not done in a way that actually\ndelivers the quality assurance value that could be extracted from the process.\n\nWhat we have found in practice is that this communication has to happen in\nat least two waves, when the working group reaches a functional intent as to\nthe resolution, [when the precise language of the docuement change has been\nproposed to or agreed to by the group,] and when the re-drafting resolving all\ncomments has been complete.  Errors often creep in between the first of\nthese steps and the completion of the last.\n\nThis requires better issue tracking tools to make it efficient enough to\ndo it right, and it is most logical to treat commentors inside\nand outside the W3C much the same in this regard.\n\nOur rate of satisfaction of this formal requirements is, say, 70%.\nLess than we would like.  Communication with commentors is an area which\nclearly has room to improve.  The only thing that the public don't know\nis that it's not just them.  The same holds for internal communication.\n\nNot to get too deeply into internal matters, here, we should acknowledge\nthat this is a known problem and that it is the intent of the process\ncrafters to gain the maximum advantage from the knowledge and insights\nof all who take the time to read and comment on the documents.\n\nThis is why, in a companion mail, I am suggesting we need a more visible and\ncustomer-friendly ombudmanic function so members of the public will more\nreadily trust that they are being listened to.\n\nAl\n\n\n>Alex.\n>\n>--\n>                             | HTTP performance - Web Polygraph benchmark\n>www.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n>                             | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: Right Tools RE: Promotion of XHTM",
            "content": "steph wrote:\n\n>On Tue, Dec 31, 2002 at 07:51:09PM -0000, fstorr wrote:\n>  \n>\n>>What would make it easier would be some kind of basic WYSIWYG CSS\n>>editor.  For example you select \"page heading\" (meaning <h1>) then\n>>select from a list of fonts, font weights + styles, background colors\n>>etc.  This would then update the css attached to a page.  The actual\n>>X/HTML editor could run with a series of prebuilt templates (a la\n>>Microsoft's \"Wizards\") that could generate 2, 3 column layouts, etc \n>>\n>I think the point is that no one should have to look at the HTML \n>or really understand what CSS is :) It's the content that matters,\n>not how it's done.  But a tool like this which may aid designers\n>in the creation of Web templates would be nice.\n>\n>Does anyone here know of any software developers (or would can collate\n>a team together) to make such a tool a reality?\n>\nCan we say Amaya?  It prompts for alt text when images are inserted.  It \noffers the ability to have a  template server (you have to make the \ninitial templates).  It is open to new development.\n\n-- \nBrant Langer Gurganus\nhttp://troop545.cjb.net/brant.xhtml\n\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "2 new W3C Notes: CHIPs and CUA",
            "content": "QA Activity has published two W3C Notes: CHIPs and CUAP\n\n    CHIPs is a set of good practices to improve implementations of\n    HTTP and related standards as well as their use. It explains a\n    few basic concepts, points out common mistakes and misbehaviors,\n    and suggests \"best practices\".\n\n    CUAP explains some common mistakes in user agents due\n    to incorrect or incomplete implementation of specifications, and\n    suggests remedies. It also suggests some \"good behavior\" where\n    specifications themselves do not specify any particular behavior\n    (e.g., in the face of error conditions).\n    CUAP is a republication.\n\n\nCHIPShttp://www.w3.org/TR/2003/NOTE-chips-20030128/\nCUAPhttp://www.w3.org/TR/2003/NOTE-cuap-20030128\n\n\nPlease send comments to the publicly archived \n(http://lists.w3.org/Archives/Public/www-qa/) mailing-list of the \nQuality Assurance Interest Group (http://www.w3.org/QA/IG/): \nwww-qa@w3.org.\n\nTranslation of these documents are welcome. See \nhttp://www.w3.org/QA/translations\n\n\n\nPS: Plans for republication after comments on June 2003\nCUAP should take the form of the CHIPs Note for readibility\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Hi,\n\nAnother draft, almost final, should I say, is not available on\n\nhttp://www.nitot.com/temp/Acting_locally_detailed.html\n\n\nOlivier Thereaux wrote:\n\n>\n> Hello Tristan,\n>\n> On Saturday, May 24, 2003, at 12:41 Europe/Budapest, Tristan Nitot wrote:\n>\n>> You'll find a very first draft on \n>> http://www.nitot.com/temp/Acting_locally_detailed.html\n>>\n>> It is more or less supposed to be a sequel to \n>> http://www.w3.org/QA/2002/08/LocalAction\n>\n>\n> This article looks very good indeed. You're saying it is a draft, how \n> far do you think it is from completion? \n\nNow, it is complete, but it still needs final review.\n\n> Do you want a review from this list now, or for a later draft? \n\nA review from the list would be awesome.\n\n> Given its scope and the scope of the existing \"LocalAction\" article in \n> W3C QA space, I believe both could easily be merged. What do you think? \n\nI'm not sure to understand how we could merge these two articles \ntogether. Would it be a complete rewrite of the whole stuff, of would it \nbe just a copy / paste of my article into the \"starting local \ninitiatives\" section ?\n\nanyway, all feedback welcome.\n\n\n--Tristan\n\n-- \nNetscape AOL Technologies, Standards Evangelist, Europe\nhttp://devedge.netscape.com/ : make your site cross-browser compatible\nhttp://openweb.eu.org/       : pour apprendre les standards\nhttp://standblog.com/        : un blog sur les standards\n\n\n\n"
        },
        {
            "subject": "Use Standards or Quality",
            "content": "While we are busy evangelising and promoting Standards, Guidelines, and\nAccessibility ... we need to somehow focus on what is out there and\navailable to download, install, and use.\n\nI am referring to canned or already developed packaged systems or\nsoftware:\nCMS\nBulletin boards, forums\nChat software, systems\nForms\nGalleries\nBlogs, publishing systems\nLibrary Card Cataloging systems or software\nCatalog packages for commerce\nShopping cart systems\netc...\n\nI realize the w3c and possibly other groups do not wish to get involved\nin promoting one package or company over any other, yet, we need to look\nat the reality of what is being used by many others. We need to somehow\ngather a collection of those items that may be supportive of standards,\nand others that may not be too hard to modify to the standards level.\n\nMaybe this can be researched and done on the personal level, or via\nwell-visited sites. The reality, many may not have programming or\ndevelopment skills to produce their own and use what has already been\ncreated. It is crazy to be in a position to be stuck with what is\navailable. We need to have available a list[which may be very short] of\nitems that are usable or can be modified. We also need to somehow get a\nmessage to those creating these items, that standards, guidelines, and\naccessible end products are a goal that is worthy to reach or work and\npossibly a level above the competition. Or in other words, makes their\nwork or projects more desirable in the long run.\n\nI have a few items started on a list, but I am interested in any that\nmay fit or come close for any others. Also, my list of usables or often\nused by others might be short. There may be other items that are used\nfrequently by businesses or web designers that I overlooked.\n\nI believe I spend a lot of time looking at various items to see if they:\n[1] Are close or meet these standards in some way.\n[2] Are not close, and I dig and look to see if they can be modified or\nfixed to meet standards in some way. [templates, css, etc.].\n\nItem 2 can be very time-consuming to fix what is already created and may\nbe in numerous documents, files, includes, or templates.\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Hello Tristan, Hi all.\n\nOn Sunday, Jul 6, 2003, at 00:11 Asia/Tokyo, Tristan Nitot wrote:\n> Another draft, almost final, should I say, is not available on\n>\n> http://www.nitot.com/temp/Acting_locally_detailed.html\n\nGood, starting reading it now.\n\n> Olivier Thereaux wrote:\n>> Given its scope and the scope of the existing \"LocalAction\" article \n>> in W3C QA space, I believe both could easily be merged. What do you \n>> think?\n>\n> I'm not sure to understand how we could merge these two articles \n> together. Would it be a complete rewrite of the whole stuff, of would \n> it be just a copy / paste of my article into the \"starting local \n> initiatives\" section ?\n\nSomething in between. I believe your article is a very worthy addition \nto the existing material, and knowing our audience, I'm certain it's \nbetter to have one good article rather than two to cover this topic. \nHence the need to merge. I suppose a full rewrite won't be needed, and \na copy-paste won't be good enough, but something in between should be \nOK.\n\nThoughts?\n\ncheers\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Helping out the Mozilla Fondatio",
            "content": "Hi everyone, \n\nSorry to barge in like this, but I have come up with an idea to help\nfinance Mozilla which I think is worth mentionning on the public place.\n\nAs you may already be aware now, the Mozilla Foundation has just set up\na Paypal asccount on their website (www.mozilla.org). I am throwing in\nsome sort of a challenge to get as much people as possible to go and\ndonate, even if it's only one dollar. Upon registrering to Paypal, every\nnew member gets 5 dollars for free. I figured if everyone gave their 5\nbucks to Mozilla (plus their little dollar), that could end up being a\nlot for the Foundation. This could very well make the difference for\nthem.\n\nI have explained the whole thing on my website, but since it's in\nfrench, most of you won't be able to understand. However, for those who\ndo, here's the URL : http://makeashorterlink.com/?F16C21455 (shorter\nlink to make it easier, you'll be redirected automatically).\n\nIf every one that cares about Mozilla spoke about it on their site, we\ncould create a mass movement. Together, we cal all make a difference !\n\n______________________________\n\nDenis BOUDREAU [ CYBERcodeur ]\nhttp://www.cybercodeur.net   : Weblog et standards Web\nhttp://w3qc.cybercodeur.net  : Collectif de promotion des normes Web\nhttp://www.openweb.eu.org    : Ressource francophone des normes Web\n\n   \"You can lead a web designer to standards, but you can't make him \n    drink. Designing With Web Standards will make him thirsty\".\n\n\n\n"
        },
        {
            "subject": "Comparing browser",
            "content": "Hi,\n    My interest is in overall web content support, independent of the \ntechnology (HTML, CSS, JavaScript,...). ie, of the all the web pages out \nthere, what percentage of them render and function as intended by the \nauthor in different browsers.\n\nI am interested in Mozilla, Opera, and KHTML/Konqueror.\n\nDo you know where I might find such data?\n\nThanks,\n\n-- \nPhilippe Laporte\nResearch Specialist\nNokia Mobile Phones, Research and Technology Access\nStreet address:It?merenkatu 11-13, 00180 Helsinki, Finland\nPost address:P.O. Box 407, FIN-00045 NOKIA GROUP\nPhone:+358 50 482 1979\nFax:      +358 7180 36229\nE-mail: philippe.laporte@nokia.com\n\n\n\n"
        },
        {
            "subject": "New revision of &quot;Act Locally&quot; article ready for revie",
            "content": "Greetings everyone,\n\nI have edited the \"Think globally, Act locally\" article to include \nTristan Nitot's excellent contribution.\n\nThe result is ready for review at \n<http://www.w3.org/QA/Library/LocalAction>.\nFeedback very welcome.\n\nCheers,\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: WaSP Asks the W3",
            "content": "* Molly E. Holzschlag wrote:\n>In an effort to assist developers and designers in understanding detailed\n>issues when working with web standards, WaSP and the W3C kick off a new\n>project today.\n>\n>The project, \"WaSP Asks the W3C\" involves WaSP Steering Committee members\n>culling questions from supporters and asking members of the W3C's Quality\n>Assurance Group for insight and details. WaSP hopes you'll find the project\n>worthwhile.\n\nWhat's the current status of this project?\n\n\n\n"
        },
        {
            "subject": "RE: Comparing browser",
            "content": " -----Original Message-----\n| From: Philippe Laporte\n| Subject: Comparing browsers\n|\n|\n| Hi,\n|     My interest is in overall web content support, independent of the\n| technology (HTML, CSS, JavaScript,...). ie, of the all the web pages out\n| there, what percentage of them render and function as intended by the\n| author in different browsers.\n|\n| I am interested in Mozilla, Opera, and KHTML/Konqueror.\n|\n| Do you know where I might find such data?\n|\n| Thanks,\n| Philippe Laporte\n ---End Original Message---\n\nPhilippe,\n\nThere is a much bigger question behind your question, and this bigger one\nneeds to be addressed first.  Before one can ask, \"of the all the web pages\nout there, what percentage of them render and function as intended by the\nauthor in different browsers?\", one must ask, \"are authors using internet\ntechnologies properly?\"  In many cases, a page will not render as the author\nintended because the author used poor methods to achieve a particular \"look\"\nor \"function\".\n\nThere's also the question, \"what is the primary browser/UA this site was\ndesigned and tested for?\"  If I design a site and primarily test it in\nMozilla, the code will likely look different than if I were trying to\nachieve a similar presentation for IE, Opera, or a web-enabled cellular\nphone.  One often runs up against a wall at this point, because authors are\nmore likely to design with a certain browser's presentation in mind, rather\nthan coding in a standards-conforming manner.  (I am guilty of this myself.)\n\nThere are <a href=\"http://www.w3.org/Style/CSS/Test/\">test suites</a>\navailable that examine how technologies are supported (according to W3C\nrecommendations) by a number of browsers; but aside from taking an author's\nPhotoshop \"mock-up\" and comparing it to the final page in these browsers, we\ncan't compare Author's Intent to Final Presentation.\n\n(Then there's the whole \"user defined style sheets\" issue, but that's\nprobably out of the scope of your question.  I'll simply address it by\nsaying that even if you design a page that looks \"just right\" in Mozilla\n1.3, a person using that browser can make it look completely different by\nemploying a style sheet that states, \"body: background: #000; color: #fff;\nfont-size: 72px;\".)\n\n\nTravis Seitler, I.S. Technician :: Knox Co. Finance Department\ntravis.seitler@knoxcounty.org\n\n\n\n"
        },
        {
            "subject": "Re: WaSP Asks the W3",
            "content": "Hi Bjoern,\n\n> What's the current status of this project?\n\nThis is so interesting that you ask this today.  I was coordinating this for\nWaSP, but things got busy and you know how that goes.  Just yesterday I\nreferred someone to the article we did back in December, and I realized that\nthis was a very worthy project and I would like to resume working on it.\n\nThat said, I do have a good follow-up article that I was working on with\nOlivier and Karl, so I will commit to finishing that and publishing it on\nthe WaSP site.\n\nI'm really grateful you asked this question because combined with my thought\nonly yesterday it confirms my sense that this is a very good opportunity and\none that I don't want to see lost by the wayside.\n\nThe help I could use here would be a list of great topic ideas, this way we\ncan put together an editorial calendar of sorts and work on a topic a month.\n\nI look forward to everyone's thoughts!\n\nMolly\nMolly E. Holzschlag,  Communications Director\nWorld Organization of Webmasters, http://www.joinwow.org/\npersonal site: http://www.molly.com/\nmolly@molly.com\n\n\n\n"
        },
        {
            "subject": "Re: WaSP Asks the W3",
            "content": "The WASP doesn't do anything. The last thing we have sent has not been \npublished by the WASP.  We are still waiting for something. We don't \neven have answers to emails. I guess it's an organization problem on \nthe WASP side :/\n\nHope they will move.\n\n\nLe Mardi, 29 juil 2003, ? 09:51 Europe/Paris, Bjoern Hoehrmann a ?crit :\n> * Molly E. Holzschlag wrote:\n>> In an effort to assist developers and designers in understanding \n>> detailed\n>> issues when working with web standards, WaSP and the W3C kick off a \n>> new\n>> project today.\n>>\n>> The project, \"WaSP Asks the W3C\" involves WaSP Steering Committee \n>> members\n>> culling questions from supporters and asking members of the W3C's \n>> Quality\n>> Assurance Group for insight and details. WaSP hopes you'll find the \n>> project\n>> worthwhile.\n>\n> What's the current status of this project?\n\n\n\n"
        },
        {
            "subject": "Re: WaSP Asks the W3",
            "content": "Oh !!!\n\n\nLe Mardi, 29 juil 2003, ? 14:56 Europe/Paris, Molly E. Holzschlag a \n?crit :\n\n> only yesterday it confirms my sense that this is a very good \n> opportunity and\n> one that I don't want to see lost by the wayside.\n>\n> The help I could use here would be a list of great topic ideas, this \n> way we\n> can put together an editorial calendar of sorts and work on a topic a \n> month.\n>\n\nGoood !!!!!!\nI hope we will se that on a more regular basis now.\n\nThanks molly.\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Mikael Snaprud wrote:\n\n><snip>\n>\n>Most governments have official policies supporting open web standards.\n>However, it generally seems that the purhcasing policy for authoring tools\n>is not related to this.\n>Perhaps there is a way of comparing the standards compliance of different\n>authoring tools to support more informed (public) procurement.\n>\n\nA comparison of the standards-compliance of some HTML-based online Help \nauthoring tools has been done. It's available at \nhttp://www.knopf.com/resources/hatcomp.\n\nRegards,\n\n\n-- \n\nDavid Knopf ~ Knopf Online ~ San Francisco, CA\nmailto:david@knopf.com ~ http://www.knopf.com\n\nConsulting & Training on FrameMaker & WebWorks Publisher\nWebWorks Publisher Certified\nMember, JavaHelp 2.0 Expert Group\nModerator, HATT, wwp-users & wordhelp\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Mikael Snaprud wrote:\n\n><snip>\n>\n>Most governments have official policies supporting open web standards.\n>However, it generally seems that the purhcasing policy for authoring tools\n>is not related to this.\n>Perhaps there is a way of comparing the standards compliance of different\n>authoring tools to support more informed (public) procurement.\n>\n\nA comparison of the standards-compliance of some HTML-based online Help \nauthoring tools has been done. It's available at \nhttp://www.knopf.com/resources/hatcomp.\n\nRegards,\n\n\n-- \n\nDavid Knopf ~ Knopf Online ~ San Francisco, CA\nmailto:david@knopf.com ~ http://www.knopf.com\n\nConsulting & Training on FrameMaker & WebWorks Publisher\nWebWorks Publisher Certified\nMember, JavaHelp 2.0 Expert Group\nModerator, HATT, wwp-users & wordhelp\n\n\n\n"
        },
        {
            "subject": "valid HTML statistics wrt http://www.w3.org/QA/2002/04/WebQualit",
            "content": "In the document available at http://www.w3.org/QA/2002/04/Web-Quality it is\nstated that\n\n\"Most of the Web sites on the Web are not valid. We may assume that this is\nthe case for 99% of the Web pages, but there are no statistics to support\nthis. It would be interesting to run a survey to prove that this case is\nindeed true.\"\n\nIt is true that a large number of websites are invalid. There was a thesis\nrecently written entitled \"How to cope with incorrect HTML\", which dealt\nwith the nature of errors in HTML documents and strategies for overcoming\nthem. As part of this thesis an investigation into the number of invalid\ndocuments and the type of errors was performed.\n\nThe results are available from the thesis ( urn:isbn:82-8088-088-7 ),\navailable from http://www.ub.uib.no/elpub/2001/h/413001/\n\nI have summarised the results in an entry on my weblog available at\nhttp://www.benmeadowcroft.com/me/archive/2003/january.shtml#link25th\nThe sample size was 2,398,226 documents of which 14,563 were valid HTML\ndocuments. Taking factors such as unknown DTD's etc into account the number\nof documents tested which were valid was 0.71%\n\nI hope this information is of some interest.\n-- \nBen Meadowcroft\nhttp://www.benmeadowcroft.com/\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Hello,\nThank you for the interesting HAT link.\n\nWe are considering to carry out a small assment of Authoring tools by \nanalysing some web content. One problem here is that only about 5% of the \npages we have looked at seem to use the generator tag.\n\nWould you know of some other way to identify what tool has been used to \ngenerate a page? Perhaps some kind of fingerprint scheme ?\n\nGreetings.\nMikael Snaprud\n\n\nOn Saturday 07 June 2003 00:19, David Knopf wrote:\n> Mikael Snaprud wrote:\n> ><snip>\n> >\n> >Most governments have official policies supporting open web standards.\n> >However, it generally seems that the purhcasing policy for authoring tools\n> >is not related to this.\n> >Perhaps there is a way of comparing the standards compliance of different\n> >authoring tools to support more informed (public) procurement.\n>\n> A comparison of the standards-compliance of some HTML-based online Help\n> authoring tools has been done. It's available at\n> http://www.knopf.com/resources/hatcomp.\n>\n> Regards,\n\n\n\n"
        },
        {
            "subject": "Weblogs, etc. on standards and accessibility update",
            "content": "I've just completed an update to my 25 April 2003 post, \"Web standards \nand accessibility weblogs, \netc.\":http://www.lynnparkplace.org/vot/archives/accessibility/000015.html\n\nNew in this version are entries pointing to single items (rather than \nsites) -- reports, articles, findings -- relevant to standards and \naccessibility.\n\nI *think* I've cleared up all the commitments I made to people who had \ncomments or e-mail suggestions. I apologize for the length of time it \nhas taken to get caught up. As always, if there are problems or \ninaccuracies or other references, please send them along.\n\nRegards.                         ...edN\n\n\n\n"
        },
        {
            "subject": "Re: Weblogs, etc. on standards and accessibility update",
            "content": "----- Original Message -----\nFrom: \"ed nixon\"\n\n\n>\n> I've just completed an update to my 25 April 2003 post, \"Web standards\n> and accessibility weblogs,\n>\netc.\":http://www.lynnparkplace.org/vot/archives/accessibility/000015.htm\nl\n>\n> New in this version are entries pointing to single items (rather than\n> sites) -- reports, articles, findings -- relevant to standards and\n> accessibility.\n\nGreat job Ed,\n\nI have my project together now, and it is sorted just a bit differently.\nI tried to get the names of the authors or group of authors for each\nsite. [anyone can correct me or change items if they find a need.\n\nFor Italian Blogs on standards, guidelines, and or accessibility...\nthese 3 are very good additions to add to your section.\n\nUsabile.it: http://www.usabile.it/\nInformation on Usability, Accessibility, and Interactive design. CSS,\nand Navigation topics... http://www.usabile.it/link.htm links in Italian\nor English.\n\nwebaccessibile.org *** [an excellent website]\nAccessibility : Delivery, promotion, and application of WAI(Web\nAccessibility Initiative), UAAG(User Agent Accessibility Guidelines),\nATAG(Authoring Tool Accessibility Guidelines), XAG(XML Accessibility\nGuidelines). Resources, News, Information, and Discussion list. RSS\nFeed.\n\nWebXtutti Fondazione Bordoni: Ministero delle: News and information,\nAccessibility, CSS, resources ...\n\n\n\n"
        },
        {
            "subject": "publicesw&#64;w3.org list membershi",
            "content": "Hi\n\nI've just added everyone from w3c-swad-europe who hadn't subscribed to\npublic-esw@w3.org\n\nThis is the publically visible mailing list for SWAD-Europe. It is\ngenerally for our (ie. project team) use, though we can open it up to\ndiscussion with collaborators as things proceed.\n\nPublic archives are at lists.w3.org/Archives/Public/public-esw/\n\nCurrent membership is listed below:\n\nAndy_Seaborne@hplb.hpl.hp.com\nder@hplb.hpl.hp.com\nmf@w3.org\nB.M.Matthews@rl.ac.uk\nM.D.Wilson@rl.ac.uk\nMartin_Merry@hplb.hpl.hp.com\nStephenB@stilo.com\nc.bardrick@bristol.ac.uk\ncharles@w3.org\ndanbri@w3.org\ndave.beckett@bristol.ac.uk\ndd@w3.org\nem@w3.org\njan.grant@bristol.ac.uk\nkate.sharp@bristol.ac.uk\nlesly.huxley@bristol.ac.uk\nlibby.miller@bristol.ac.uk\n\nAs discussed at the face to face, a more private list for\nadmin and finance will be hosted at University of Bristol.\nKate and/or Libby will be in touch about this. We can then phase out\nthe Member-visible w3c-swad-europe list and do content/tech discussion on\npublic-esw, with project internal admin/finance/reporting discussions on\nthe new not-yet-created admin list.\n\nWe'll police public-esw socially rather than technically, just as\nwe do with other publically-readable W3C lists (eg. WebOnt WG, RDF Core\nWG). In other words, this won't be a free-for all, but it needn't\nbe entirely restricted to allow postings only from project-partner staff.\nWe can work out a balance as the project work gets under way.\n\nLet me know if you have any questions etc.,\n\nDan\n\n(re-emerging after 2 weeks in day long meetings...)\n\n\n-- \nmailto:danbri@w3.org\nhttp://www.w3.org/People/DanBri/\n\n\n\n"
        },
        {
            "subject": "Re: Weblogs, etc. on standards and accessibility update",
            "content": "From: \"Holly Marie\"\n> ----- Original Message -----\n> From: \"ed nixon\"\n>\n>\n> >\n> > I've just completed an update to my 25 April 2003 post, \"Web\nstandards\n> > and accessibility weblogs,\n> >\n>\netc.\":http://www.lynnparkplace.org/vot/archives/accessibility/000015.htm\n> l\n> >\n> > New in this version are entries pointing to single items (rather\nthan\n> > sites) -- reports, articles, findings -- relevant to standards and\n> > accessibility.\n>\n> Great job Ed,\n>\n> I have my project together now, and it is sorted just a bit\ndifferently.\n> I tried to get the names of the authors or group of authors for each\n> site. [anyone can correct me or change items if they find a need.\n>\n> For Italian Blogs on standards, guidelines, and or accessibility...\n> these 3 are very good additions to add to your section.\n>\n> Usabile.it: http://www.usabile.it/\n> Information on Usability, Accessibility, and Interactive design. CSS,\n> and Navigation topics... http://www.usabile.it/link.htm links in\nItalian\n> or English.\n>\n> webaccessibile.org *** [an excellent website]\n> Accessibility : Delivery, promotion, and application of WAI(Web\n> Accessibility Initiative), UAAG(User Agent Accessibility Guidelines),\n> ATAG(Authoring Tool Accessibility Guidelines), XAG(XML Accessibility\n> Guidelines). Resources, News, Information, and Discussion list. RSS\n> Feed.\n>\n> WebXtutti Fondazione Bordoni: Ministero delle: News and information,\n> Accessibility, CSS, resources ...\n\nForgot to add the last link:\nwebxtutti\nhttp://www.webxtutti.it/\n\nGerman Blogs:\n\nBarrierefreies Webdesign: Einfach f?r Alle\nhttp://www.einfach-fuer-alle.de/\nBarrier Free Web Design, Accessibility,articles, events, links,\nresources ...\nEfA-AccessBlog : http://www.einfach-fuer-alle.de/blog/\nAccessibility blog, from the www.einfach-fuer-alle.de/ website\n\n[I am not sure if you have the blog link listed  under Einfach ... ]\n\nWeb Accessibility Links : http://www.webaccessibility.de/\nMartin Stehle: over 360 links to barrier free web. Websites, Forums,\ncommunity, Checklists, Validation and checking, Projects and campaigns,\nArticles, Techniques, Styleguides, Usability ... etc. Links to German\nand English content.\n\n===\n\nEuroaccessibility.org/partners :\nhttp://www.euroaccessibility.org/partners.php\nA listing of Partners(with links) involved in the\nhttp://www.euroaccessibility.org/ project.\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Mikael Snaprud wrote:\n\n>Hello,\n>Thank you for the interesting HAT link.\n>\n>We are considering to carry out a small assment of Authoring tools by \n>analysing some web content. One problem here is that only about 5% of the \n>pages we have looked at seem to use the generator tag.\n>\n>Would you know of some other way to identify what tool has been used to \n>generate a page? Perhaps some kind of fingerprint scheme ?\n>\n\nI think it's very difficult to identify the authoring tool automatically \nin the absence of a meta generator tag. (And even then, the user can \nchange the meta tag.) Some tools do leave obvious fingerprints, which \ncan be identified by examing the code, but others do not. Sorry I \ncouldn't be more helpful.\n\nRegards,\n\n\n-- \n\nDavid Knopf ~ Knopf Online ~ San Francisco, CA\nmailto:david@knopf.com ~ http://www.knopf.com\n\nConsulting & Training on FrameMaker & WebWorks Publisher\nWebWorks Publisher Certified\nMember, JavaHelp 2.0 Expert Group\nModerator, HATT, wwp-users & wordhelp\n\n\n\n"
        },
        {
            "subject": "Re:  Weblogs, etc. on standards and accessibility update",
            "content": "Ed Nixon wrote:\n\n>I've just completed an update to my 25 April 2003 post, \"Web standards and \n>accessibility weblogs, \n>etc.\":http://www.lynnparkplace.org/vot/archives/accessibility/000015.html\n\nGreat!\n\nGood work, Ed.\n\n::\n\nWhy don't we mirror the content of this page on the W3C website QA section?\n\n\n\ngroet,\n\nOskar van Rijswijk\n\n[ www.w3os.nl/oskar ] \n\n\n\n"
        },
        {
            "subject": "Re:  Weblogs, etc. on standards and accessibility update",
            "content": "On Tue, 2003-06-17 at 18:43, Oskar van Rijswijk wrote:\n> Ed Nixon wrote:\n> \n> >I've just completed an update to my 25 April 2003 post, \"Web standards and \n> >accessibility weblogs, \n> >etc.\":http://www.lynnparkplace.org/vot/archives/accessibility/000015.html\n>\n> Why don't we mirror the content of this page on the W3C website QA section?\n\nWe ought to reply to this... Of course, I don't think it makes any sense\nto mirror that on the W3C site (for obvious maintenance reason, +\npossible political issues). But what about announcing it from the QA\nhome page?\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re:  Weblogs, etc. on standards and accessibility update",
            "content": "At 11:13 +0200 2003-06-18, Dominique Haza?l-Massieux wrote:\n>On Tue, 2003-06-17 at 18:43, Oskar van Rijswijk wrote:\n>>  Ed Nixon wrote:\n>>\n>>  >I've just completed an update to my 25 April 2003 post, \"Web standards and\n>>  >accessibility weblogs,\n>>  >etc.\":http://www.lynnparkplace.org/vot/archives/accessibility/000015.html\n>>\n>>  Why don't we mirror the content of this page on the W3C website QA section?\n>\n>We ought to reply to this...\n\nreplied :p in your RSS feed baby!\n\nhttp://www.w3.org/QA/2004/01/News2003#x20030618a\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Weblogs, etc. on standards and accessibility update",
            "content": "Karl Dubost wrote:\n\n>\n> At 11:13 +0200 2003-06-18, Dominique Haza?l-Massieux wrote:\n>\n>> On Tue, 2003-06-17 at 18:43, Oskar van Rijswijk wrote:\n>>\n>>>  Ed Nixon wrote:\n>>>\n>>>  >I've just completed an update to my 25 April 2003 post, \"Web \n>>> standards and\n>>>  >accessibility weblogs,\n>>>  >etc.\":http://www.lynnparkplace.org/vot/archives/accessibility/000015.html\n>>>\n>>>  Why don't we mirror the content of this page on the W3C website QA \n>>> section?\n>>\n>>\n>> We ought to reply to this...\n>\n>\n> replied :p in your RSS feed baby!\n>\n> http://www.w3.org/QA/2004/01/News2003#x20030618a\n\nThanks. This is likely the best solution currently. There have been some \nother ideas floating around about how best to aggregate (and to \nmaintain) this resource. It's probably getting to the size and scope \nwhere those ideas should be explored more thoroughly.\n\nFor example, if it's feasible and I can figure out how to do it in MT, \nperhaps a unique RSS feed would be useful for that entry, instead of or \nin addition to my having to post a new entry to VOT and post a notice to \nthe list.\n\nThis does nothing to deal with the management, integrity and \norganization of the entries themselves, of course. And it is currently  \nlocation specific. I can scratch my head about that too. But suggestions \nand comments would be a help.\n\nThanks.                       ...edN\n\n\n\n"
        },
        {
            "subject": "Re: Weblogs, etc. on standards and accessibility update",
            "content": "----- Original Message -----\nFrom: \"ed nixon\"\n\n> This does nothing to deal with the management, integrity and\n> organization of the entries themselves, of course. And it is currently\n> location specific. I can scratch my head about that too. But\nsuggestions\n> and comments would be a help.\n\nI was thinking about some sort of link portal or link management\nscripting, server side. I was working with an xml, perl project I found\nonline, but there were a few items that were not that smooth.\n\nI did also have the categories by language, but my list is blogs and\nnews. So the list is a bit bigger with a section that has reference to\nsome key standards, guidelines, and accessibility websites.[not all\nblogs].\n\nNext, I sorted each subcategory, alphabetically by blog name/site name\nor title. Included author or authors where found, and short description.\n\nIt would be nice to have as a database project, content management\nset-up, where updates and changes could be made on-the-fly.\n\nAnother option might be some table set-up, with sql, and sort order\noptions on the headers. If done accessibly and via standards/guidelines,\nthis could work well. Maybe a separate table for each language group.\n\nXML still looks like a possibility, and I have been scouting some XSL ,\nstylesheets , transformations, etc ... though I am new to this area, but\nI see sort and group as possibilities through XML.\n\nRight now mine sits in xhtml flat files as a static web page... Not even\nin a blog.\n\nholly\n\n\n\n"
        },
        {
            "subject": "Web Standard Switch in Arabi",
            "content": "Dear Karl,\nPlease find here the Arabic translation of Web Standards Switch.\n\nhttp://www.w3c.org.ma/QA/web-kit.ar.html\n\nIf you have any remarks, please tell me.\n\nRegards,\n\nNajib\n-- \nNajib TOUNSI (mailto:tounsi@w3.org)\nW3C Office in Morocco (http://www.w3c.org.ma)\nEcole Mohammadia d'Ing?nieurs, BP 765 Agdal-RABAT Maroc (Morocco)\nPhone: +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\nMobile: +212 (0) 61 22 00 30\n\n\n\n"
        },
        {
            "subject": "Re: Web Standard Switch in Arabi",
            "content": "I had a look at the website and I must say that a lot of work needs to be\nadded as most of links are in English and:\nhttp://www.w3.org/QA/2003/03/web-kit.html is very hard to fathom!\nSorry\nAhmed Mohamed Bagi\n----- Original Message -----\nFrom: \"Najib Tounsi\" <tounsi@emi.ac.ma>\nTo: <karl@w3.org>\nCc: <w3c-translators@w3.org>; <public-evangelist@w3.org>;\n<w3c-office-pr@w3.org>\nSent: Tuesday, June 24, 2003 12:58 PM\nSubject: Web Standard Switch in Arabic\n\n\n\nDear Karl,\nPlease find here the Arabic translation of Web Standards Switch.\n\nhttp://www.w3c.org.ma/QA/web-kit.ar.html\n\nIf you have any remarks, please tell me.\n\nRegards,\n\nNajib\n--\nNajib TOUNSI (mailto:tounsi@w3.org)\nW3C Office in Morocco (http://www.w3c.org.ma)\nEcole Mohammadia d'Ing?nieurs, BP 765 Agdal-RABAT Maroc (Morocco)\nPhone: +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\nMobile: +212 (0) 61 22 00 30\n\n\n\n"
        },
        {
            "subject": "Re: Web Standard Switch in Arabi",
            "content": "At 13:53 +0100 24/06/03, Ahmed Bagi wrote:\n>I had a look at the website and I must say that a lot of work needs to be\n>added as most of links are in English and:\n>http://www.w3.org/QA/2003/03/web-kit.html is very hard to fathom!\n\nHello Ahmed,\n\nI am glad to make your acquaintance. I don't understand what do you mean.\nThere may some few mistakes to be corrected, but what else goes wrong?\n\nNajib Tounsi\n\n>Sorry\n>Ahmed Mohamed Bagi\n>----- Original Message -----\n>From: \"Najib Tounsi\" <tounsi@emi.ac.ma>\n>To: <karl@w3.org>\n>Cc: <w3c-translators@w3.org>; <public-evangelist@w3.org>;\n><w3c-office-pr@w3.org>\n>Sent: Tuesday, June 24, 2003 12:58 PM\n>Subject: Web Standard Switch in Arabic\n>\n>\n>\n>Dear Karl,\n>Please find here the Arabic translation of Web Standards Switch.\n>\n>http://www.w3c.org.ma/QA/web-kit.ar.html\n>\n>If you have any remarks, please tell me.\n>\n>Regards,\n>\n>Najib\n>--\n>Najib TOUNSI (mailto:tounsi@w3.org)\n>W3C Office in Morocco (http://www.w3c.org.ma)\n>Ecole Mohammadia d'Ing?nieurs, BP 765 Agdal-RABAT Maroc (Morocco)\n>Phone: +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\n>Mobile: +212 (0) 61 22 00 30\n\n\n-- \nNajib TOUNSI (mailto:tounsi@w3.org)\nW3C Office in Morocco (http://www.w3c.org.ma)\nEcole Mohammadia d'Ing?nieurs, BP 765 Agdal-RABAT Maroc (Morocco)\nPhone: +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\nMobile: +212 (0) 61 22 00 30\n\n\n\n"
        },
        {
            "subject": "Re: Web Standard Switch in Arabi",
            "content": "It may be a good idea to use WC3 (in Arabic lettering) ratter than WC3 (in\nEnglish lettering)!\n\nThe following lead to the original (English text): it may have been a good\nidea to leave them in English, see:\nhttp://www.w3.org/QA/2003/03/web-kit.html.de\n\nActivities\n\nQuality Assurance\n\nTechnical Reports and (missed out Publications)\n\nSite Index\n\nFinding Your Way at W3C\n\nAbout the World Wide Web Consortium (W3C)\n\nW3C Membership\n\n\n\nQA Home Page  should link to: Latest News, Resources and Contacts\n\nQA Interest Group (missed out QAIG)\n\nQuality Assurance Calendar - Agenda and Minutes (too abbreviated: Quality\nAssurance Calendar)\n\nYou have also translated standards as criteria and anglicised: web master!\n\nThe link to the original document does not work.\n\nThe whole thing needs a bit of revising and ???flavouring??? so as it is not so\ncumbersome.\n\nI am in the middle of postdoctrate research and I can only be used to\nscrutiniser rather to redo the whole translation! The translation as a whole\nis literal and dose not have a distinct flavour here is an example:\n\nThe method we suggest (suggested) in this paper is suitable for any web\nregardless of the size. This should suit your needs whether you a small\nindividual web or a very large commercial web.\n\nThe emphasis seems to shift from: talking about the designer to talking\ndirectly to a web!\n\n?????????????? ???????? ?????????????? ???? ?????? ???????????? ?????? ???????????? ?????? ???? ???? ??????. ???????????? ??????????????\n???????? ?????? ???????????????? ???????? ?????? ???????? ???????????? ?????????? ???? ???????? ?????? ?????????? ???????? ??????????.\n\n\n\n\n\n\n\n----- Original Message -----\nFrom: \"Najib Tounsi\" <tounsi@emi.ac.ma>\nTo: \"Ahmed Bagi\" <Ahmed@abagi.freeserve.co.uk>; <karl@w3.org>; \"Najib\nTounsi\" <tounsi@emi.ac.ma>\nCc: <w3c-translators@w3.org>; <public-evangelist@w3.org>;\n<w3c-office-pr@w3.org>\nSent: Wednesday, June 25, 2003 5:19 PM\nSubject: Re: Web Standard Switch in Arabic\n\n\n\nAt 13:53 +0100 24/06/03, Ahmed Bagi wrote:\n>I had a look at the website and I must say that a lot of work needs to be\n>added as most of links are in English and:\n>http://www.w3.org/QA/2003/03/web-kit.html is very hard to fathom!\n\nHello Ahmed,\n\nI am glad to make your acquaintance. I don't understand what do you mean.\nThere may some few mistakes to be corrected, but what else goes wrong?\n\nNajib Tounsi\n\n>Sorry\n>Ahmed Mohamed Bagi\n>----- Original Message -----\n>From: \"Najib Tounsi\" <tounsi@emi.ac.ma>\n>To: <karl@w3.org>\n>Cc: <w3c-translators@w3.org>; <public-evangelist@w3.org>;\n><w3c-office-pr@w3.org>\n>Sent: Tuesday, June 24, 2003 12:58 PM\n>Subject: Web Standard Switch in Arabic\n>\n>\n>\n>Dear Karl,\n>Please find here the Arabic translation of Web Standards Switch.\n>\n>http://www.w3c.org.ma/QA/web-kit.ar.html\n>\n>If you have any remarks, please tell me.\n>\n>Regards,\n>\n>Najib\n>--\n>Najib TOUNSI (mailto:tounsi@w3.org)\n>W3C Office in Morocco (http://www.w3c.org.ma)\n>Ecole Mohammadia d'Ing??nieurs, BP 765 Agdal-RABAT Maroc (Morocco)\n>Phone: +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\n>Mobile: +212 (0) 61 22 00 30\n\n\n--\nNajib TOUNSI (mailto:tounsi@w3.org)\nW3C Office in Morocco (http://www.w3c.org.ma)\nEcole Mohammadia d'Ing??nieurs, BP 765 Agdal-RABAT Maroc (Morocco)\nPhone: +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\nMobile: +212 (0) 61 22 00 30\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "Hi folks,\n\nHow do people feel about holding the international workshop in conjunction\nwith the Dublin Core conference in Florence in October, and holding a\nworkshop at HP as discussed as our other required developer workshop in that\nperiod?\n\nThe International workshop should be a little more of a general public\nintroduction to the project than a normal developer workshop, although it\nshould also have a technical focus of some kind, and the Dublin Core\nconference seems more appropriate for that than a single-topic workshop based\non the fact that we potentially have members of the WebOnt working group\navailable.\n\nThere are several possiblities - the workshop could potentially be held as a\nworkshop session on the workshop/tutorial day of the conference, or the day\nafter the conference itself. Obviously we would need to sort out the details\nwith the organisers of that conference. For that reason in particular, I hope\nwe can get fairly rapid feedback on the idea.\n\ncheers\n\nCharles McCN\n\n\nOn Sat, 22 Jun 2002, Charles McCathieNevile wrote:\n\n  Hi all,\n\n  Following the Kick-off meeting, I am responsible for making sure we organise\n  the International Workshop. We are proposing to hold it on the topic of RDF\n  Querying, in conjunction with the W3C Web Ontology working group meeting in\n  Bristol 7-8 October.\n\n  At this stage I would propose holding a one day workshop on Wednesday the 9th\n  of October, and we hope that Hewlett-Packard could host this workshop.\n\n  Cheers\n\n  Charles McCN\n\n\n\n\n-- \nCharles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\nW3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38 78 22\nLocation: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)\n\n\n\n"
        },
        {
            "subject": "cHTML vs XHTML/CS",
            "content": "This is possibly OT - if someone could let me know what other W3C list this \nquestion should go to, that would be great.\n\nI have a question about the status of the cHTML standard. Does anybody have \na feel for what direction the W3C prefers for serving content to mobile \ndevices, either one-document-serves-all XHTML with handheld-specific \nstylesheets, or separate XHTML+CSS files for screen and cHTML-with-no-CSS \nfiles for the little guys? According to webopedia \"cHTML has been fading \ninto obsolescence as XHTML gains acceptance and replaces cHTML\", which I'm \nwilling to believe considering I've only just heard about cHTML. On the \nother hand, even Jakob The Great expresses doubts about whether a single \nXHTML source can really work across such disparate devices and mediums:\n\nhttp://lists.w3.org/Archives/Public/w3c-wai-ig/1999AprJun/0541.html\n\nBasically, I saw a news article about Opera saying they support cHTML for \niMode compatibility, which sparked my wanting to get a better feel for \nwhat's going on with the emerging phone browser world:\nhttp://zdnet.com.com/2100-1104-985655.html\n\nThanks!\n\nAl Abut\n- - -\nhttp://www.alabut.com/\n- - -\n\n\n\n"
        },
        {
            "subject": "cHTML vs XHTML/CS",
            "content": "This is possibly OT - if someone could let me know what other W3C list this \nquestion should go to, that would be great.\n\nI have a question about the status of the cHTML standard. Does anybody have \na feel for what direction the W3C prefers for serving content to mobile \ndevices, either one-document-serves-all XHTML with handheld-specific \nstylesheets, or separate XHTML+CSS files for screen and cHTML-with-no-CSS \nfiles for the little guys? According to webopedia \"cHTML has been fading \ninto obsolescence as XHTML gains acceptance and replaces cHTML\", which I'm \nwilling to believe considering I've only just heard about cHTML. On the \nother hand, even Jakob The Great expresses doubts about whether a single \nXHTML source can really work across such disparate devices and mediums:\n\nhttp://lists.w3.org/Archives/Public/w3c-wai-ig/1999AprJun/0541.html\n\nBasically, I saw a news article about Opera saying they support cHTML for \niMode compatibility, which sparked my wanting to get a better feel for \nwhat's going on with the emerging phone browser world:\nhttp://zdnet.com.com/2100-1104-985655.html\n\nThanks!\n\nAl Abut\n- - -\nhttp://www.alabut.com/\n- - -\n\n\n\n"
        },
        {
            "subject": "Re: cHTML vs XHTML/CS",
            "content": "At 09:31 -0800 2003-03-03, Al Abut wrote:\n>I have a question about the status of the cHTML standard. Does \n>anybody have a feel for what direction the W3C prefers for serving \n>content to mobile devices,\n\nThe discussion is interesting and it would be very good to have an \noverview here. The mailing list for question about HTML, XHTML etc is \nwww-html@w3.org\n\nFor Cell phones the Spec which has been designed is XHTML Basic\nhttp://www.w3.org/TR/xhtml-basic/\n\nHow to serve XHTML documents is explained in this note\nhttp://www.w3.org/TR/xhtml-media-types/\n\n\nSee the summary:\nhttp://www.w3.org/TR/xhtml-media-types/#summary\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Authoring Tools Problem",
            "content": "Hi,\n\nI would like to start and collect the usual problems you have \nidentified in Authoring Tools (Requirements, etc). It has to be \nrelated to Web standards in a way.\n\nThanks.\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Authoring Tools Problem",
            "content": "Karl Dubost wrote:\n\n> I would like to start and collect the usual problems you have identified \n> in Authoring Tools (Requirements, etc). It has to be related to Web \n> standards in a way.\n\nHi Karl,\n\nI work with the Web Standards Project on a team called the Dreamweaver \nTask Force. You can read about us here:\nhttp://www.webstandards.org/act/campaign/dwtf/\n\nIf you'd like to discuss standards issues relating to Macromedia \nDreamweaver, we'd be happy to talk with you.\n\n-- \ndrew mclellan\n\nauthor: dreamweaver mx web development\nhttp://dreamweaverfever.com/read/\n\nwasp dreamweaver task force\nhttp://www.webstandards.org/\n\n\n\n"
        },
        {
            "subject": "Re: Authoring Tools Problem",
            "content": "At 22:35 +0000 2003-03-20, Drew McLellan wrote:\n>I work with the Web Standards Project on a team called the \n>Dreamweaver Task Force. You can read about us here:\n>http://www.webstandards.org/act/campaign/dwtf/\n>\n>If you'd like to discuss standards issues relating to Macromedia \n>Dreamweaver, we'd be happy to talk with you.\n\nThanks Drew.\n\nIt's why I'm inviting people to send their comments about the tools \nand what are the things that could be improved or missing features. \nWhen all the people will have expressed their requirements, we'll be \nable to see how to write a document to address these issues and work \nwith all authoring tools makers to improve the products.\n\nBest.\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Virtual Educatio",
            "content": "I would like to start a thread to discuss the convergence of paper and\ndigital content in the education space.\n\nThanks.\n\njb\n\n\n\n-- \njason barkeloo\nDirector of Research\nACEtek Research\nhttp://www.acetekresearch.com\ntele 513.225.8765\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "Sorry, URI for dublin core conference: http://www.bncf.net/dc2002/\n\nCharles\n\nOn Mon, 1 Jul 2002, Charles McCathieNevile wrote:\n\n  Hi folks,\n\n  How do people feel about holding the international workshop in conjunction\n  with the Dublin Core conference in Florence in October, and holding a\n  workshop at HP as discussed as our other required developer workshop in that\n  period?\n\n  The International workshop should be a little more of a general public\n  introduction to the project than a normal developer workshop, although it\n  should also have a technical focus of some kind, and the Dublin Core\n  conference seems more appropriate for that than a single-topic workshop based\n  on the fact that we potentially have members of the WebOnt working group\n  available.\n\n\n\n"
        },
        {
            "subject": "Virtual Educatio",
            "content": "I would like to start a thread to discuss the convergence of paper and\ndigital content in the education space.\n\nThanks.\n\njb\n\n\n\n-- \njason barkeloo\nDirector of Research\nACEtek Research\nhttp://www.acetekresearch.com\ntele 513.225.8765\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "    I'll throw my blog into the hat. I just \"restarted\" it recently and is a\nwork in progress, but the content will focus on Web Standards,\nAccessibility, and Information Architecture. Check it out and please leave\ncomments on the posted items if you wish.\n \n   Thanks,\n \n            Jon Kahlo          http://stratus.blogspot.com/\n<http://stratus.blogspot.com/> \n \n \n \n\n\n\n"
        },
        {
            "subject": "Re: Virtual Educatio",
            "content": "On Wednesday, April 30, 2003, at 02:10  PM, Jason Barkeloo wrote:\n> I would like to start a thread to discuss the convergence of paper and\n> digital content in the education space.\n>\nOkay.\n\n> Thanks.\n\nYou're welcome.\n\n> --\nKynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\nChief Technologist, Idyll Mountain                http://idyllmtn.com\nAuthor, CSS in 24 Hours                       http://cssin24hours.com\nInland Anti-Empire Blog                      http://blog.kynn.com/iae\nShock & Awe Blog                           http://blog.kynn.com/shock\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "At 12:10 -0400 2003-04-25, ed nixon wrote:\n>I've taken the liberty of culling from the lists of weblogs, \n>magazines and community servers posted today. You can find it here: \n>http://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n>\n\nThe list is really good still looking for\n\nSpanish, Italian, Chinese, Japanese, German, etc... Standards \nrelated blogs. :)\nDo you know some?\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "----- Original Message -----\nFrom: \"Karl Dubost\"\n\n> At 12:10 -0400 2003-04-25, ed nixon wrote:\n> >I've taken the liberty of culling from the lists of weblogs,\n> >magazines and community servers posted today. You can find it here:\n> >http://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n> >\n>\n> The list is really good still looking for\n>\n> Spanish, Italian, Chinese, Japanese, German, etc... Standards\n> related blogs. :)\n> Do you know some?\n\nI have both two lists printed and am going to combine to see where some\nmay be missing? If they are.\nThen I will pop it up on one of my sites and offer the link, later\ntoday.\n\nI am also very interested in others that Karl mentioned...\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "Karl Dubost wrote:\n\n>\n> At 12:10 -0400 2003-04-25, ed nixon wrote:\n>\n>> I've taken the liberty of culling from the lists of weblogs, \n>> magazines and community servers posted today. You can find it here: \n>> http://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n>>\n>\n> The list is really good still looking for\n>\n>     Spanish, Italian, Chinese, Japanese, German, etc... Standards \n> related blogs. :)\n>     Do you know some?\n\nI don't unfortunately. Language-wise, I can stumble with Spanish and \nprobably Italian at about the same level I do with French.\n\nHowever, I'm happy to set up and accept requests from all the linguistic \ngroups assuming I can figure out the encoding issues if there are any.\n\n                   ...edN\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "----- Original Message -----\nFrom: \"ed nixon\"\n\n\n>\n> I've taken the liberty of culling from the lists of weblogs, magazines\n> and community servers posted today. You can find it here:\n> http://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n>\n\nhttp://www.markme.com/accessibility/\n\nMacromedia Accessibility blog to add to the list.\n\n[I am still compiling the two lists together between other work on the\nsidelines]\n\nholly\n\n\n\n"
        },
        {
            "subject": "RE: web standards and accessibility blogs, etc",
            "content": "Karl Dubost [SMTP:karl@w3.org] wrote:\n\n> Spanish, Italian, Chinese, Japanese, German, etc... \n> Standards related blogs. :)\n> Do you know some?\n\nCzech ones (at least the top 5 out of some 10-15):\n\nhttp://www.sovavsiti.cz/weblog/\nhttp://www.pixy.cz/blogg/web/\nhttp://www.oborsky.cz/weblog/\nhttp://machal.creativity.cz/\nhttp://www.jakpsatweb.cz/weblog/\n\nRegards,\n\nMarek\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "It's not a blog but a daily journal fronting a soon to be converted but\nnon-standards based site - and concerns web standards,  accessibility and\nfield trips in Cornwall which we run every year (and this year's our eighth\nannual bash)\n\nIf you think it worth it, include it. It is developing, so look and feel\nchanges on a regular basis. I've set it up after encouragement from my\nstudents who are ripping the code off (with my permission and\nencouragement) to analyse it.\n\nhttp://colbyweb.co.uk\n\nJohn\n\nJohn Colby\nLecturer, School of Computing, Faculty of Computing, Information and\nEnglish\nRoom F328a, Feeney Building, University of Central England,\nFranchise Street, Perry Barr, Birmingham B42 2SU\nTel: +44 (0) 121 331 6937, Fax +44 (0) 121 331 6281, Mobile: 0771 114 1621\n\n\n\n"
        },
        {
            "subject": "updated (finally) standards and accessibility weblog lis",
            "content": "My apologies to all who received my promises that their corrections and \nsuggestions would be done forth-with last week. I failed.\n\nHowever, I've just finished updating \nhttp://www.lynnparkplace.org/vot/archives/accessibility/000015.html to \nreflect what I think is all of the input I've received so far. In \nparticular there are a number of Czech blogs listed, a major addition. \nThanks to Marek Prokop for the pointers.\n\nRegards.                    ...edN\n\n\n\n"
        },
        {
            "subject": "german Standards / Accessibility Blo",
            "content": "Hello,\n\ni read your mail in the wai mailing list, that you are looking for\nblogs. My german blog \"Die Pr?sentationsschicht\" deals with Web\nDevelopment and features Accessibility and Standards as its main\ncontents.\n\nkind regards, Tilo Kley\n\n-- \nTilo Kley\nWeb Development\n\nhttp://www.tilokley.de\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "Seems like a good suggestion (though I would be unlikely to be able to attend\npersonally - budget limitations and slightly difficult timing).\n\nWhat would the focus be?\n\nDave\n\nCharles McCathieNevile wrote:\n> \n> Sorry, URI for dublin core conference: http://www.bncf.net/dc2002/\n> \n> Charles\n> \n> On Mon, 1 Jul 2002, Charles McCathieNevile wrote:\n> \n>   Hi folks,\n> \n>   How do people feel about holding the international workshop in conjunction\n>   with the Dublin Core conference in Florence in October, and holding a\n>   workshop at HP as discussed as our other required developer workshop in that\n>   period?\n> \n>   The International workshop should be a little more of a general public\n>   introduction to the project than a normal developer workshop, although it\n>   should also have a technical focus of some kind, and the Dublin Core\n>   conference seems more appropriate for that than a single-topic workshop based\n>   on the fact that we potentially have members of the WebOnt working group\n>   available.\n\n\n\n"
        },
        {
            "subject": "I forgot to include the url  sorry for this second mail",
            "content": "http://www.praesentationsschicht.de\n\n\n\n"
        },
        {
            "subject": "Proposal of a W3C featur",
            "content": "Hello,\n\nI am a French web developper and documentations writer.\nI write some documentations about web standards, HTML, CSS...\n\nI thought of a service you could propose : a single URL to find the \nspecification of a given HTML markup. I give you 2 examples :\n\nhttp://w3.org/shortcut/html?q=body will redirect to :\nhttp://www.w3.org/TR/html4/struct/global.html#edef-BODY\n\nhttp://w3.org/shortcut/html?q=caption will redirect to :\nhttp://www.w3.org/TR/html4/struct/tables.html#edef-CAPTION\n\nThe benefit of such a service is the capability to automate links \ncreation in documentations, to create bookmarks in our browser.\n\nOf course, there could be other specifications single link, eg:\nhttp://w3.org/shortcut/css?q=%s\nhttp://w3.org/shortcut/xslt?q=%s\n...\n\nThe single link is not a replacement, just an imporvement which could be \ngiven in the W3C matrix.\n\nRegards.\n\n-- \nOlivier Meunier\n       __\n      ( \">\n       )(\n     // )\n  --//\"\"----  om@neokraft.net\n  -/--------  http://www.neokraft.net\n\n\n\n"
        },
        {
            "subject": "Re: Proposal of a W3C featur",
            "content": "Check this out, it's from Gerald Oskoboiny:\n\nhttp://impressive.net/services/dtrt/\n\n--Kynn\n\nOn Friday, May 16, 2003, at 04:29  PM, Olivier Meunier wrote:\n\n>\n> Hello,\n>\n> I am a French web developper and documentations writer.\n> I write some documentations about web standards, HTML, CSS...\n>\n> I thought of a service you could propose : a single URL to find the \n> specification of a given HTML markup. I give you 2 examples :\n>\n> http://w3.org/shortcut/html?q=body will redirect to :\n> http://www.w3.org/TR/html4/struct/global.html#edef-BODY\n>\n> http://w3.org/shortcut/html?q=caption will redirect to :\n> http://www.w3.org/TR/html4/struct/tables.html#edef-CAPTION\n>\n> The benefit of such a service is the capability to automate links \n> creation in documentations, to create bookmarks in our browser.\n>\n> Of course, there could be other specifications single link, eg:\n> http://w3.org/shortcut/css?q=%s\n> http://w3.org/shortcut/xslt?q=%s\n> ...\n>\n> The single link is not a replacement, just an imporvement which could \n> be given in the W3C matrix.\n>\n> Regards.\n>\n> -- \n> Olivier Meunier\n>       __\n>      ( \">\n>       )(\n>     // )\n>  --//\"\"----  om@neokraft.net\n>  -/--------  http://www.neokraft.net\n>\n>\n>\n--\nKynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\nChief Technologist, Idyll Mountain                http://idyllmtn.com\nAuthor, CSS in 24 Hours                       http://cssin24hours.com\nInland Anti-Empire Blog                      http://blog.kynn.com/iae\nShock & Awe Blog                           http://blog.kynn.com/shock\n\n\n\n"
        },
        {
            "subject": "Webkit intr",
            "content": "Bonjour Karl,\n\nI suggest rearranging the sentences for the introduction (more or less):\n\n--\n\"Whether you are a manager, a Web developer, a Marketing or\nCommunications team member, or perhaps an individual Web master, you\nhave read about the interest in Web standards from many sources.\nYou have understood that standards are beneficial for your Web site\nin terms of cost savings, ease of management and profitability,\nand so you have decided to switch - and employ standards within your \nWeb site.\n\nUnfortunately, you haven't found a guide which explains the proceesses\nof where to begin and how to organise this transition of your Web site\nto being standards-compliant. You might think that having a large Web \nsite makes this objective unattainable. If you are unsure about what \nWeb standards are, we encourage you to read about what Web standards really \nmean [WEB-QUALITY], how to purchase and develop a quality Web site \n[REQ-WEBAGENCY], and why an accessible Web site [WAI-PROFIT] is profitable. \n\nThe method that we propose in this document is valid for Web sites of \nany size; it will suit your needs whether you are managing an individual, \nsmall business or a large corporate Web site.\n\nWe will guide you through the individual steps - all of which you\nwill be able to fulfill individually - from the analysis of your\nexisting Web site to the organization of your new Web site. Each of\nthese steps have been designed to be separate, and can be undertaken at\nvarious times, different levels, by different persons regardless of\ntheir skill level, but in accordance to a workflow.\"\n--\n\nI just feel that rearranging these sentences give the first paragraph\nmore \"punch\", and is thus perhaps more effective because it addresses the\naudience more. :)\n\nThoughts?\n\nRegards,\n-steph\n\n\n-- \n\n\n\n"
        },
        {
            "subject": "Re: Webkit intr",
            "content": "At 22:48 +1000 2003-05-21, steph wrote:\n>Bonjour Karl,\n>\n>I suggest rearranging the sentences for the introduction (more or less):\n\ndone.\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "RE: Webkit intr",
            "content": "Hi everyone,\n\nI'm taking the translation of Web-Kit today. I will let you know once\nit's completed.\n\nJe prend la traduction du Web-kit aujourd'hui. Je vous aviserai lorsque\nce sera termin?.\n\nhttp://www.w3.org/QA/2003/03/web-kit\n\nDenis Boudreau\nCYBERcodeur.net\n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Karl Dubost\n> Sent: 22 mai, 2003 12:07\n> To: steph; public-evangelist@w3.org\n> Subject: Re: Web-kit intro\n> \n> \n> \n> At 22:48 +1000 2003-05-21, steph wrote:\n> >Bonjour Karl,\n> >\n> >I suggest rearranging the sentences for the introduction (more or \n> >less):\n> \n> done.\n> \n> -- \n> Karl Dubost / W3C - Conformance Manager\n>            http://www.w3.org/QA/\n> \n>       --- Be Strict To Be Cool! ---\n> \n> \n> \n\n\n\n"
        },
        {
            "subject": "Acting locally : a draft for a new article on W3.or",
            "content": "Hi,\n\nAfter an e-mail discussion with W3 staff people (Olivier and Karl, from \nthe QA group), we came to the conclusion  that sharing my experience \nwith Web standards promotion could help other people replicating and/or \nadapting the French projects I have been participating to in their \nrespective countries and regions.\n\nYou'll find a very first draft on \nhttp://www.nitot.com/temp/Acting_locally_detailed.html\n\nIt is more or less supposed to be a sequel to \nhttp://www.w3.org/QA/2002/08/LocalAction\n\nIt may eventually, after review, being published on W3.org.\n\nSuggestion, critics and reviews are more than welcome.\n\nCheers,\n\n\n--Tristan\n-- \nMozilla and OpenWebGroup contributor\nhttp://openweb.eu.org/\nhttp://standblog.com/\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Hello Tristan,\n\nOn Saturday, May 24, 2003, at 12:41 Europe/Budapest, Tristan Nitot \nwrote:\n> You'll find a very first draft on \n> http://www.nitot.com/temp/Acting_locally_detailed.html\n>\n> It is more or less supposed to be a sequel to \n> http://www.w3.org/QA/2002/08/LocalAction\n\nThis article looks very good indeed. You're saying it is a draft, how \nfar do you think it is from completion? Do you want a review from this \nlist now, or for a later draft?\n\nGiven its scope and the scope of the existing \"LocalAction\" article in \nW3C QA space, I believe both could easily be merged. What do you think?\n\n-- \nOlivier\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Hi Tristan,\n\nYour article is encouraging reading indeed.\nAs you call it a draft do you have any particular topic to extend ?\n\nMost governments have official policies supporting open web standards.\nHowever, it generally seems that the purhcasing policy for authoring tools\nis not related to this.\nPerhaps there is a way of comparing the standards compliance of different\nauthoring tools to support more informed (public) procurement.\n\nMikael\n\n\nOlivier Thereaux wrote:\n\n> Hello Tristan,\n>\n> On Saturday, May 24, 2003, at 12:41 Europe/Budapest, Tristan Nitot\n> wrote:\n> > You'll find a very first draft on\n> > http://www.nitot.com/temp/Acting_locally_detailed.html\n> >\n> > It is more or less supposed to be a sequel to\n> > http://www.w3.org/QA/2002/08/LocalAction\n>\n> This article looks very good indeed. You're saying it is a draft, how\n> far do you think it is from completion? Do you want a review from this\n> list now, or for a later draft?\n>\n> Given its scope and the scope of the existing \"LocalAction\" article in\n> W3C QA space, I believe both could easily be merged. What do you think?\n>\n> --\n> Olivier\n\n\n\n"
        },
        {
            "subject": "Traduction de Web Standards Switch en fran?ai",
            "content": "Bonjour tout le monde :)\n\nJe termine ? l'instant la traduction de Web Standards Switch\n(http://www.w3.org/QA/2003/03/web-kit).\n\nCeux qui ont envie de relire trouveront la traduction ici :\nhttp://cybercodeur.net/weblog/articles/web-kit.html\n\nMerci d'avance!\n\n\nDenis Boudreau [ CYBERcodeur ]\nD?fenseur des standards Web || Architecte d'information\n\nCYBERcodeur.net - VDM - W3Qc - OpenWebGroup\nMail :   denis@cybercodeur.net\nICQ :   115649885\nWEB :  http://www.cybercodeur.net/\n           http://w3qc.cybercodeur.net/\n           http://www.openweb.eu.org/ \n\n\n\n> -----Original Message-----\n> From: Denis Boudreau [ CYBERcodeur.net ] \n> [mailto:denis@cybercodeur.net] \n> Sent: 23 mai, 2003 15:20\n> To: 'public-evangelist@w3.org'; 'w3c-translators-fr@w3.org'\n> Subject: RE: Web-kit intro\n> \n> \n> Hi everyone,\n> \n> I'm taking the translation of Web-Kit today. I will let you \n> know once it's completed.\n> \n> Je prend la traduction du Web-kit aujourd'hui. Je vous \n> aviserai lorsque ce sera termin?.\n> \n> http://www.w3.org/QA/2003/03/web-kit\n> \n> Denis Boudreau\n> CYBERcodeur.net\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "On Tue, 2 Jul 2002, Dave Reynolds wrote:\n\n> Seems like a good suggestion (though I would be unlikely to be able to attend\n> personally - budget limitations and slightly difficult timing).\n>\n> What would the focus be?\n\nOne idea we discussed was to base the workshop around the idea of bringing\npractical DC use cases, requirements and priorities to RDF tool\ndevelopers, with goal of making sure RDF tools are solving real world\nmetadata problems. Flipside of this is to have RDF developers sanity-check\nthe DCMI DC-in-RDF specs by investigating how they work in RDF database,\nAPI, query etc environments.\n\nMy own views on this went into an abstract for DC2002 with Dave and\nLibby, but we didn't get a paper finished on time. I'd be interested to know\nwhether what we drafted chimes with anyone else's view:\n\n\n  > > Title: RDF and the Dublin Core: Practical Prioritizing for RDF Tool Builders\n  > >\n  > > Authors: Dan Brickley, Dave Beckett, Libby Miller\n  > >\n  > > Abstract:\n  > >\n  > > RDF has now been accepted in a variety of contexts, connecting\n  > > digital library, knowledge representation, weblog syndication,\n  > > commercial and open source applications.  Despite this, groups\n  > > seeking to use RDF face a number of hurdles.\n  > >\n  > > This paper outlines some deployment issues surrounding the\n  > > practical use of RDF, and proposes four implementation features as\n  > > priorities for RDF query and storage systems: (i) RDF schema\n  > > sub-property, (ii) phrase, substring and text searching on\n  > > literals, (iii) provenance tracking of RDF statements and (iv)\n  > > smarter aggregation algorithms (or 'smushing').\n  > >\n  > > We discuss each of these features, and relate them to the\n  > > practicalities of widescale Dublin Core deployment in the Semantic\n  > > Web.  We assert that when (i)-(iv) are implemented in widely\n  > > available RDF tools, the Semantic Web will be deployable.\n\n\nAs a paper abstract, this is of course more opinionated (and downbeat,\nre-reading...) than would be appropriate for a whole workshop. But I think\nthe basic idea, of connecting practical metadata apps (DC and related) to\nRDF technology issues faced by implementors is close in spirit to much of\nthe SWAD-E workplan.\n\nDan\n\n> Dave\n>\n> Charles McCathieNevile wrote:\n> >\n> > Sorry, URI for dublin core conference: http://www.bncf.net/dc2002/\n\n> >   How do people feel about holding the international workshop in conjunction\n> >   with the Dublin Core conference in Florence in October, and holding a\n> >   workshop at HP as discussed as our other required developer workshop in that\n> >   period?\n> >\n> >   The International workshop should be a little more of a general public\n> >   introduction to the project than a normal developer workshop, although it\n> >   should also have a technical focus of some kind, and the Dublin Core\n> >   conference seems more appropriate for that than a single-topic workshop based\n> >   on the fact that we potentially have members of the WebOnt working group\n> >   available.\n>\n\n\n\n"
        },
        {
            "subject": "Re: Traduction de Web Standards Switch en fran?ai",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Re: Acting locally : a draft for a new article on W3.or",
            "content": "Cc: Tristan Nitot<tristan@nitot.com>,public-evangelist@w3.org\n\n\nQuoting Olivier Thereaux <ot@w3.org>:\n\n> Hello Tristan,\n> \n> On Saturday, May 24, 2003, at 12:41 Europe/Budapest, Tristan Nitot \n> wrote:\n> > You'll find a very first draft on \n> > http://www.nitot.com/temp/Acting_locally_detailed.html\n> >\n> > It is more or less supposed to be a sequel to \n> > http://www.w3.org/QA/2002/08/LocalAction\n> \n> This article looks very good indeed. \n\nThanks!\n\n> You're saying it is a draft, how \n> far do you think it is from completion? Do you want a review from this\n> \n> list now, or for a later draft?\n\nThe current draft is ready for review, IMHO.\n\n> Given its scope and the scope of the existing \"LocalAction\" article in\n> W3C QA space, I believe both could easily be merged. \n\nI wrote it more as a sequel to \"LocalAction\".\n\n> What do you think?\n\nThat would be fine for me to be a co-author of the resulting work, but I'm not\nsure I'd be able to do the merge myself. If you want to do it, please do.\n\n\n--Tristan\n\n\n\n"
        },
        {
            "subject": "Web Development cours",
            "content": "I work at a community college and am proposing a new course that teaches\nXHTML, DHTML, CSS and JavaScript.  I have to \"justify\" the course to a 9\npanel board.  Here is what they are looking for\n\n\"Usually the review is focused on (1) ensuring that the proposal clearly\nstates a compelling need for the course and (2) reviewing the syllabus.\"\n\nWhat I am looking for is \"the compelling need\" portion.  How can I justify\nsomething we should have been teaching years ago to a group of non-IT\nadministrators/faculty?  The audience for the course is students at the\ncollege who are degree seeking or just looking to update skills.\n\nWe currently teach an intro to web design with HTML and another course on\nE-Commerce that touches on JavaScript.  We are behind the times to say the\nleast ;)\n\nFor those in the field on a more regular basis than myself.  Is it safe to\nsay these skills are necessary for survival?  Is there any info to back it\nup?\n\nIt's a tough job convincing the \"experts\" that they are doing things\nbehind the times and we need to try to get on top of things or we will get\ntrampled on...\n\nThanks for your thoughts/opinions,\n\nDennis\n\n\n\n"
        },
        {
            "subject": "Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "Hi.\n\nIn an effort to complete the collection dedicated to Web sites' quality \nwithin the W3C QA Library [1] and build a more comprehensive set of \nresources adapted to all the kinds of actors involved, we have created \na simplified outline of the various stages and actors of a Web Site's \ncreation[2]. This outline may, eventually, become a good guide for \nreaders to find their way among these resources, but for now it can be \nuseful in assessing which documents are yet to be written and which \ndocuments need to be amended to be more adapted to their intended \naudience.\n\n[1] http://www.w3.org/QA/Library/#websitequality\n[2] http://www.w3.org/QA/2003/05/Web-site-steps\n\nParticipants in the QA Interest group, especially participants in this \nmailing-list, had expressed some interest in contributing material to \nthe QA Library, and for that purpose we wrote up some contributions \nguidelines [3] (for which feedback is still welcome). This outline of \n\"Web site steps\" may be an interesting source of inspiration for \nvolunteer contributors without a clear idea of what they would like to \nprovide help on.\n\n[3] http://www.w3.org/QA/2003/06/Contrib\n\nShould you decide to start work on one of the missing documents, or \nshould you want to have a try at improving one of the existing \ndocuments, please coordinate with other participants on this list.\n\nThank you.\n-- \nolivier\n\n\n\n"
        },
        {
            "subject": "RE: Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "Hi Olivier (and others on this list)\n   As I mentioned to you at the WWW 2003 conference I'm involved in QA\nsupport for a number of digital library programmes in the UK Higher\nEducation community.\n   Details of our work are given in a couple of papers, which are\navailable from:\nhttp://www.ukoln.ac.uk/qa-focus/documents/papers/\n   Our aim is to encourage projects to comply with open standards and\nbest practices - while recognising the constraints that projects face,\nsuch as lack of resources, investment in existing working practices and\ntools, etc.\n   We've producing a range of brief documents, which are available from:\nhttp://www.ukoln.ac.uk/qa-focus/documents/briefings/\n   I'd be happy for the content of any of these documents to be\nrepurposed for the W3C QA Web site.  However some will be out-of-scope\nfor you, while others may be too pragmatic (e.g. suggesting approaches\nfor making PowerPoint files available on the Web or mentioned specific\napplications by name).\n   Anyway I'd welcome comments on these documents, especially if anyone\nfeels they'd make a useful addition to the W3C QA libray of resources.\n\nThanks\n\nBrian\n   \n\n---------------------------------------\nBrian Kelly\nUK Web Focus\nUKOLN\nUniversity of Bath \nBATH\nBA2 7AY\nEmail: B.Kelly@ukoln.ac.uk\nWeb: http://www.ukoln.ac.uk/\nPhone: 01225 383943\nFOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf\nFor info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/\n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of \n> Olivier Thereaux\n> Sent: 02 October 2003 06:55\n> To: public-evangelist@w3.org\n> Subject: Call for contributions: new and improved \"Web site \n> quality\" articles\n> \n> \n> \n> Hi.\n> \n> In an effort to complete the collection dedicated to Web \n> sites' quality \n> within the W3C QA Library [1] and build a more comprehensive set of \n> resources adapted to all the kinds of actors involved, we \n> have created \n> a simplified outline of the various stages and actors of a Web Site's \n> creation[2]. This outline may, eventually, become a good guide for \n> readers to find their way among these resources, but for now \n> it can be \n> useful in assessing which documents are yet to be written and which \n> documents need to be amended to be more adapted to their intended \n> audience.\n> \n> [1] http://www.w3.org/QA/Library/#websitequality\n> [2] http://www.w3.org/QA/2003/05/Web-site-steps\n> \n> Participants in the QA Interest group, especially \n> participants in this \n> mailing-list, had expressed some interest in contributing material to \n> the QA Library, and for that purpose we wrote up some contributions \n> guidelines [3] (for which feedback is still welcome). This outline of \n> \"Web site steps\" may be an interesting source of inspiration for \n> volunteer contributors without a clear idea of what they \n> would like to \n> provide help on.\n> \n> [3] http://www.w3.org/QA/2003/06/Contrib\n> \n> Should you decide to start work on one of the missing documents, or \n> should you want to have a try at improving one of the existing \n> documents, please coordinate with other participants on this list.\n> \n> Thank you.\n> -- \n> olivier\n> \n> \n\n\n\n"
        },
        {
            "subject": "call for short SW articles from Europe  ERCIM new",
            "content": "Apologies for mis-posting or cross-posting if you deem this inappropriate.\n\nThis call is limited to those working in:\n\nAustria, UK, Italy, Czech Republic, Netherlands, Greece, Germany, France,\nNorway,\nSweden, Switzerland, Slovakia, Hungary, Ireland and Finland.\n\n700-800 word articles for general scientific reader consumption on\ninteresting work towards\nthe Semantic Web by Wednesday 21 August 2002.\n\n--------------------------------------------------------------------\nCall for contributions to ERCIM News No. 51 (October 2002)\n--------------------------------------------------------------------\n\nDEADLINE FOR CONTRIBUTIONS: Wednesday 21 August 2002\n\nThe sections of EN51 are :\n\n__________________\n       * Joint ERCIM Actions\n__________________\n       * The European Scene\n__________________\n\n* SPECIAL THEME: Semantic web\n\nCoordinated by J?r?me Euzenat (INRIA)\n\nThe world wide web today enables people to access documents and \nservices on the Internet. It requires human intelligence for \nunderstanding and using pages written in natural and graphic \nlanguages. The size of this web amounts to its success but prohibits \nextensive human management.\nThe idea of a semantic web aims at overcoming this problem. The \nsemantic web augments the current web with formalised knowledge and \ndata that can be processed by computers. Some services will mix human \nreadable and structured data so both humans and computers can use \nthem. Others will support only formalised knowledge and will only be \nused by machines. Research activities for building the semantic web \nare now very active and are central to the \"knowledge technologies\" \narea of the European Union's 6 framework programme.\nThere are currently many proposal of languages, protocols and \napplications for being used in the semantic web. One of the \nchallenges of the current developments is the design of a framework \nin which many understanding of this formalised knowledge can \ninterplay, because the full benefit of the semantic web can only be \nattained when computers relate resources from various sources.\n\nContributions are welcome describing ongoing or accomplished research \nrelated to the semantic web at your institution. This includes \nnotably, but not exclusively:\n- languages for the semantic web;\n- reasoning with and manipulating semantic web knowledge;\n- semantic web infrastructure and protocols;\n- models of trust, proof and rewards for the semantic web;\n- distributed ontology life-cycle support;\n- knowledge capture (from resources or people) for the semantic web;\n- migration and adoption models;\n- legal and social issues of the semantic web;\n- foundational ontologies and general-purpose resources;\n- applications of the semantic web;\n- semantic web services.\n\n________________________________________________\n       * R &D and  Technology Transfer\n________________________________________________\n       * Events\n________________________________________________\n       * In Brief\n\n\n-------------------------------------------------------------------------\nGuidelines for ERCIM News articles\n\nStyle: ERCIM News is read by a large variety of people. Keeping this \nin mind the article should be descriptive (emphasize more the 'what' \nthan the 'how')  without too  much technical detail together with an \nillustration, if possible.\n\nLength : Try to keep the article short, i.e. 700-800 words.\n\nFormat : Submissions preferably in ASCII text or MS Word\n\nStructure of the article :\nThe emphasis in ERCIM News is on 'news'. This should be reflected in \nboth Title and Lead ('teaser'). For example, a title like: 'Semantic \nWeb research at the .. institute' should be avoided, and replaced by \nsomething drawing attention to a new development. Also: no review \narticles!\n\n* a teaser:\na few words about the project/topic. Printed in bold face, this part \nis intended to raise interest. (keep it short)\n\n* details describing :\nwhat the project/product is\nwho is involved\nwhere it takes place\nwhy the research is being done\nwhen it was started/completed the aim of the project\nthe techniques employed\nthe orientation of the project\nfuture activities\nother institutes involved in this project\nco-operation with other ERCIM members in this field\n\n* useful Link(s)\n* a contact address with:\n- full name of the author\n- phone number\n- e-mail address\n\nAdditional items:\n* an illustration (photos, graphics), for example of the product, \napplications mentioned in the article, people working on the project, \netc. (avoid as much as possible flow charts and screen dumps). \nIllustrations must be accompanied by a caption.\n\n---------------------------------------------------------------------\n       About ERCIM News:\n\n      ERCIM News is published in printed form and\n      electronically on the web. The printed edition has a\n      circulation of 8500 copies, distributed in over 80 countries\n\nERCIM News is also available online at\nhttp://www.ercim.org/publication/Ercim_News/\n\nContributions will be distributed to national editors if sent to:\nMartin Prime (M.J.Prime@rl.ac.uk)\nRutherford Appleton Laboratory, Chilton, DIDCOT, Oxon OX11 0QX, UK\nTel: +44 1235 446555, Fax: +44 1235 445281\n\n\n\n"
        },
        {
            "subject": "Re: Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "\"Brian Kelly\" <B.Kelly@ukoln.ac.uk>\n>    As I mentioned to you at the WWW 2003 conference I'm involved in QA\n> support for a number of digital library programmes in the UK Higher\n> Education community.\n>    Details of our work are given in a couple of papers, which are\n> available from:\n> http://www.ukoln.ac.uk/qa-focus/documents/papers/\n\nAs always another site which has singularly failed to swallow it's own\ndogfood, you cannot serve XHTML 1.0 as text/html unless it follows Appendix\nC of XHTML, the above document does not follow Appendix C, and is served as\ntext/html so whilst the material looks incredibly useful and valuable, the\nfact it can be shot down so easily makes it useless, we can't use it to\neducate people.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "RE: Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "> \"Brian Kelly\" <B.Kelly@ukoln.ac.uk>\n> >    As I mentioned to you at the WWW 2003 conference I'm \n> involved in QA \n> > support for a number of digital library programmes in the UK Higher \n> > Education community.\n> >    Details of our work are given in a couple of papers, which are \n> > available from: http://www.ukoln.ac.uk/qa-focus/documents/papers/\n> \n> As always another site which has singularly failed to swallow \n> it's own dogfood, you cannot serve XHTML 1.0 as text/html \n> unless it follows Appendix C of XHTML, the above document \n> does not follow Appendix C, and is served as text/html so \n> whilst the material looks incredibly useful and valuable, the \n> fact it can be shot down so easily makes it useless, we can't \n> use it to educate people.\n> \n> Jim.\nHi Jim\n   Thanks for the comments.\nI assume you're referring to Appendix C in:\nhttp://www.w3.org/TR/xhtml1/\n(which states that \"This appendix is informative.\").\n   It's not clear to me what I should do.  Are you saying the page\nshould be XHTML 1.0 strict, that I need an XML PI, that I need to use a\ndifferent character encoding  or that I should use another MIME type?\n   Hmm.  Have just read section 3.1 in\nhttp://www.w3.org/TR/xhtml-media-types/\nwhich does not seem to *ban* this MIME type although it's clearly not\nrecommended:\n\"In **general**, this media type is NOT suitable for XHTML. ...\"\n\"The use of 'text/html' for XHTML SHOULD be limited for the purpose of\n...\"\n\n  I'd be happy to move to  'application/xhtml+xml' - but there will need\nto be testing for any problems with other resources on the Web site\n(which aren't managed by me).\n\n   The document is XHTML 1.0 compliant (append ,validate to the URL)\n   Note that I've not said anything about MIME types in my documents -\nbut I guess this would be a useful document to be produced.\n  \nBrian\n---------------------------------------\nBrian Kelly\nUK Web Focus\nUKOLN\nUniversity of Bath \nBATH\nBA2 7AY\nEmail: B.Kelly@ukoln.ac.uk\nWeb: http://www.ukoln.ac.uk/\nPhone: 01225 383943\nFOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf\nFor info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/\n\n\n\n"
        },
        {
            "subject": "XHTML in the real worl",
            "content": "How do we deal with sites like this?\n\n<http://news.com.com/>\n<http://validator.w3.org/check?uri=http%3A%2F%2Fnews.com.com%2F>\n\nDoes anyone want to take the lead in contacting them and asking them to \nproduce valid XHTML. I would love to a) hear their response and b) see \nthe site corrected.\n\n/bc\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "\"Brian Kelly\" <B.Kelly@ukoln.ac.uk>\n>    Hmm.  Have just read section 3.1 in\n> http://www.w3.org/TR/xhtml-media-types/\n> which does not seem to *ban* this MIME type although it's clearly not\n> recommended:\n\nXHTML is only \"allowed\" to be served as text/html if it's under Appendix C,\nif someone would like to correct me on that and say Appendix C isn't\nnormative and any old XHTML can be served as text/html then I'll withdraw\nthe criticism.\n\n>    The document is XHTML 1.0 compliant (append ,validate to the URL)\n\nbut it's not Appendix C compliant which AIUI is required to be served as\ntext/html (C.7 for example, I didn't bother looking beyond.)  Also  xhtml\n1.0 SHOULD be served as application/xhtml+xml, and I find it hard to explain\nto people that some SHOULD's are to be ignored, and others are to be obeyed,\nhow is a non-expert supposed to judge which, surely we need to either have\nall or none?\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "Le jeudi, 2 oct 2003, ? 09:40 America/Montreal, Jim Ley a ?crit :\n> As always another site which has singularly failed to swallow it's own\n> dogfood, you cannot serve XHTML 1.0 as text/html unless it follows \n> Appendix\n\nJim they are two methods to change the world. Encourage people or cut \ntheir head.\nI often prefer the first one, it's longer but it's more effective.\n\nWhen something is wrong, encourage people to fix the problems, explain \nsolutions, etc. Do not shoot in their head.\n\n\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "\"Brian Kelly\" <B.Kelly@ukoln.ac.uk>\n>    We've producing a range of brief documents, which are available from:\n> http://www.ukoln.ac.uk/qa-focus/documents/briefings/\n>    I'd be happy for the content of any of these documents to be\n> repurposed for the W3C QA Web site.  However some will be out-of-scope\n> for you, while others may be too pragmatic (e.g. suggesting approaches\n> for making PowerPoint files available on the Web or mentioned specific\n> applications by name).\n\nThe actual content of the briefings are all excellent, and I would very much\nlike them available to a wider audience, either through being repurposed for\nthe QA site, or just linked to/advertised to get the wider audience (the W3\nstamp of approval by being hosted on w3.org would be useful, but not\nessential).\n\nOne comment is the often links to bobby, I'd rather this was to a variety of\ntools, as my experience has shown people often don't like bobby's warnings\nabout things they get right, if you suggest a variety of accessibility\ncheckers they often put things differently and people can judge quicker that\none of them just isn't very good at mechanically checking that feature.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: Call for contributions: new and improved &quot;Web site quality&quot; article",
            "content": "Le jeudi, 2 oct 2003, ? 09:40 America/Montreal, Jim Ley a ?crit :\n>When something is wrong, encourage people to fix the problems, explain\n>solutions, etc. Do not shoot in their head.\n\nOkay, Don't serve up XHTML 1.0 has text/html, application XHTML 1.0 SHOULD\nbe served as application/xhtml+xml.    There's a simple solution, author\nyour documents as HTML 4.01, it's more supported (Appendix C only gives a\nprofile compatible with \"most\" html user agents) and it has established QA\ntools (such as the W3's validator) unlike Appendix C which has none.\n\nThe thing is, I know Brian knows that, the rest of his briefings are\nexcellent, there's nothing to educate him on in the area, it just seemed\nnecessary to point out the problem.  It's unfortunate that it's an example\nof Flavell's law, and I could perhaps have pointed it out more politely, but\nit's a pretty elementary mistake highlighting the lack of QA tools.\n\nIf we're going to public evangelise standards, we need to be whiter than\nwhite, we can't be shot down on the markup of our resources, non-Appendix C\nXHTML 1.0 makes that all too easy.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: XHTML in the real worl",
            "content": "On Thu, 02 Oct 2003 11:08:48 -0400, Bob Clary <bc@bclary.com> wrote:\n\n> How do we deal with sites like this?\n\n> <http://news.com.com/>\n> <http://validator.w3.org/check?uri=http%3A%2F%2Fnews.com.com%2F>\n\n> Does anyone want to take the lead in contacting them and asking them to \n> produce valid XHTML. I would love to a) hear their response and b) see \n> the site corrected.\n\nI'd like to contact them. It seems to me that ~98% of those validation \nerrors are from bare ampersands. Should be easy to correct, especially if I \nalso point them to Tidy.\n\nSue\n\n\n\n"
        },
        {
            "subject": "Re: XHTML in the real worl",
            "content": "Sue Sims wrote:\n\n> On Thu, 02 Oct 2003 11:08:48 -0400, Bob Clary <bc@bclary.com> wrote:\n> \n>> How do we deal with sites like this?\n> \n> \n>> <http://news.com.com/>\n>> <http://validator.w3.org/check?uri=http%3A%2F%2Fnews.com.com%2F>\n> \n> \n>> Does anyone want to take the lead in contacting them and asking them \n>> to produce valid XHTML. I would love to a) hear their response and b) \n>> see the site corrected.\n> \n> \n> I'd like to contact them. It seems to me that ~98% of those validation \n> errors are from bare ampersands. Should be easy to correct, especially \n> if I also point them to Tidy.\n> \n> Sue\n\nSue,\n\nThanks! Although most of the reported errors are due to the use of \nampersands in URLs, there is a mixture of other issues involved here.\n\nThis is a news site with it's own content management system and teams of \nauthors/editors. Getting them to change the way they do business is more \nthan having them run tidy over a single document.\n\nThe errors which are not due to the use of ampersands range from missing \nendtags, to improper case, to missing quotes on attributes, to \nimproperly placed elements. (Not to mention the use of SGML comments \nsurrounding the inline script) In fact, this document is HTML tag soup \nand not even close to XHTML at all. To get them to fix the issue in \ngeneral will take some effort on their part to change the way content is \nauthored and published.\n\nGood Luck and let us know what they say.\n\n/bc\n\n\n\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: XHTML in the real worl",
            "content": "...\n> Good Luck and let us know what they say.\n\nIt's not very likely that I'll get a response. I used their web form for \nfeedback.\n\nSue \"please don't copy me; I subscribe to this list\" Sims\n\n\n\n"
        },
        {
            "subject": "Re: XHTML in the real worl",
            "content": "\"Bob Clary\" <bc@bclary.com>\n> How do we deal with sites like this?\n>\n> <http://news.com.com/>\n> <http://validator.w3.org/check?uri=http%3A%2F%2Fnews.com.com%2F>\n>\n> Does anyone want to take the lead in contacting them and asking them to\n> produce valid XHTML. I would love to a) hear their response and b) see\n> the site corrected.\n\nWe need to demonstrate some business reasons for retrofitting compliant\nXHTML in there, future development is an easier sell, but retrofitting a\nsite which is \"working\" is much harder.  I'm sure they have some QA process\nwhich checks that the site works in UA's, and it probably mostly does.\n\nAs you say later, getting the process changed is going to be difficult, I\nthink the fact they've moved to XHTML shows they've either been fooled by\nbandwagons and just stuck some boilerplate gibberish there, or are actually\ncaring and trying to move to a standardised language.  For me we shouln't\nencourage invalid XHTML - if it's going to be invalid it's much better it's\nHTML.  The only chance UA's have of optimising for valid content is if they\ncan recognise when it's likely to come.\n\nSo, I think we should only advocate XHTML if the person is willing to go the\nwhole hog and actually have a publishing process which ensures validity\n(something like Nick Kew's apache modules on the front) the risks of invalid\nXHTML served as application/xhtml+xml make it a very hard sell - make one\nmistake in your authoring and your content isn't available?  So on these\nlarge sites we need to demonstrate a CMS system that can ensure validity,\nbeyond transcoding modules such as Nick's, are there any CMS's that do this?\n\nInvalid HTML is safer, there's a de-facto standard in tag-soup error\ncorrection, so if the CMS has a bug, the site doesn't disappear until it's\nfixed, so for this it's safer to advocate HTML 4.01, that also helps with\nmissing closing tags etc. (although not he entities problem) as they're\ninserted - even if it won't be what the author intended.\n\nEither way, I can't see how to sell any retrofitting activity can be sold to\nthe site, where's the business value?  I think we should concentrate on the\nones we can win.\n\nAlthough, it may not be completely impossible with news.com.com, as they do\nsupport RSS, and it's valid, so some parts of their CMS is valid XML.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "XHTML 1.0 spec (was Re: Call for contributions: new and improved  &quot;Web site quality&quot; article",
            "content": "Hi Jim\n   Thanks for the comments.\n   I've changed the subject line as there are two seperate threads: my\ndocuments and my use of XHTML and my reading of the XHTML spec and use of\nXHTML.\n   My first comments are about the spec.\n\nOn Thu, 2 Oct 2003, Jim Ley wrote:\n\n>\n> \"Brian Kelly\" <B.Kelly@ukoln.ac.uk>\n> >    Hmm.  Have just read section 3.1 in\n> > http://www.w3.org/TR/xhtml-media-types/\n> > which does not seem to *ban* this MIME type although it's clearly not\n> > recommended:\n>\n> XHTML is only \"allowed\" to be served as text/html if it's under Appendix C,\n> if someone would like to correct me on that and say Appendix C isn't\n> normative and any old XHTML can be served as text/html then I'll withdraw\n> the criticism.\n\nThe document says\n\"C. HTML Compatibility Guidelines\nThis appendix is informative.\"\n\nIf you think that's incorrect I suggest the editor of the spec should be\ninformed (I guess there's a QA of the spec issue).\n\n> >    The document is XHTML 1.0 compliant (append ,validate to the URL)\n> but it's not Appendix C compliant which AIUI is required to be served as\n> text/html (C.7 for example, I didn't bother looking beyond.)\n\nThis comment is also about the spec, or rather interpretation of the\nspec.\n\nC.1. allows you to omit the XML declaration, due to problems with older\nbrowsers.  I've done this.\n\nC.7 says you need lang: and xml:lang attributes.  I have the lang\nattribute in the html element.  I don't need to give the xml:lang\nattribute as C.1 allows me to omit it (as I understand it).\n\nI think I comply with the other requirements (e.g. I use <br /> etc.) -\nalthough I can't formally prove this.\n\nIt does occur to me that there's a need for a tool to validate compliance\nwith this section.\n\n> Also  xhtml\n> 1.0 SHOULD be served as application/xhtml+xml, and I find it hard to explain\n> to people that some SHOULD's are to be ignored, and others are to be obeyed,\n> how is a non-expert supposed to judge which, surely we need to either\nhave\n> all or none?\n\n\nThe previous comments are meant to be factual.  The following comment\nare subjective and open to debate.\n\nAs stated above, I don;'t thinbk my use of the MIME type is wrong - but\nmay not reflect recommended practices.  I'd like to implement best\npractices.  This will include real world implementation issues and not\njust the W3C specs.  I also want to be able to implement solutions which\ncan easily be deployed by others.\n\nMy QA Focus Web site is part of our organisational server.  The Web site\nis based on simple use of PHP.  I manage the XHTMl fragments in HTMLkit.\n\nWe use directory defaults to try to avoid URIs which have gormats encoded\nin them (cf recent discussion on this list).\n\nI don't want to change server configuration options which could affect\nother areas of the Web site.\n\nSo the current approach meant that XHTML resources could be created (and\nvalidated) without having to change server configuration options.  Note\nthat I suspect that some projects that I advise will not be in a position\nto change MIME types (but this is speculation).\n\nSo I think my approach is better than creating HTML 4 resources.\n\nIf I wish to move to a more appropriate MIME type I'll have to work out\nhow best to do that.  It may be that I'll need to do something differently\nwith the file suffix or do something in PHP.  I'd welcome suggestions.\n\nBut going back to the best practices in the real world I think there's\nneed for advice (from this group) on the different approaches to\ndeployment of XHTML.  This should include advice on whether one should\nauthor in XHTML if one has no control over the MIME type (which may be the\ncase with some ISPs) and the pitfalls one may encounter in use of various\nMIME types.\n\nNote that an advantage with text/html is that the page will display if the\nXHTML is invalid.  I think it would be difficult to sell the notion of\napplication/xml if an invalid file is not displayed (I appreciate the need\nfor compliance - this comment is about marketing XHTML.  One could argue\nthat HTML 4.0 is a more fault tolerant format that XHTML (I wouldn't say\nthat but others may).\n\nBrian\n\n\n\n> Jim.\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 1.0 spec (was Re: Call for contributions: new and improved  &quot;Web site quality&quot; article",
            "content": "\"Brian Kelly\" <b.kelly@ukoln.ac.uk>\n> On Thu, 2 Oct 2003, Jim Ley wrote:\n> > XHTML is only \"allowed\" to be served as text/html if it's under Appendix\nC,\n> > if someone would like to correct me on that and say Appendix C isn't\n> > normative and any old XHTML can be served as text/html then I'll\nwithdraw\n> > the criticism.\n>\n> The document says\n> \"C. HTML Compatibility Guidelines\n> This appendix is informative.\"\n>\n> If you think that's incorrect I suggest the editor of the spec should be\n> informed (I guess there's a QA of the spec issue).\n\nI agree Appendix C is non-normative, however the MIME-type definition 5.1 is\nnormative\nhttp://www.w3.org/TR/xhtml1/#media and it says\n\n| XHTML Documents which follow the guidelines set forth in\n| Appendix C, \"HTML Compatibility Guidelines\" may be labeled\n| with the Internet Media Type \"text/html\"\n\nSo whilst Appendix C isn't normative in itself (since you can use\napplication/xml or application/xhtml+xml for your XHTML) if you wish to\nserve it as text/html 5.1 requires it to be.  This is certainly been my\ninterpretation and it's been discussed here and in other places often enough\nthat I'd've thought someone would correct me on it if it was wrong.\n\n> C.7 says you need lang: and xml:lang attributes.  I have the lang\n> attribute in the html element.  I don't need to give the xml:lang\n> attribute as C.1 allows me to omit it (as I understand it).\n\nAh, I understood the xml declaration was the\n<?xml version=\"1.0\"?> and that was all you were being allowed to leave out,\nit had no bearing on C.7, I could be wrong of course, but again, it's been\noften discussed.\n\n\n> So I think my approach is better than creating HTML 4 resources.\n\nAll of your reasons for serving XHTML how are you, I entirely agree with,\nand are completely understandable, indeed they're probably required in the\nreal world.  However you've not given the reason why HTML 4.01 strict is not\nappropriate for you, it's semantically identical to XHTML 1.0.  Or what it\nis about it that makes you not want to author it (a point that I've not yet\nseen made on this list)\n\n> Note that an advantage with text/html is that the page will display if the\n> XHTML is invalid.\n\nI'd personally say, this is a huge disadvantage of XHTML as specified, not\nan advantage of breaking the rules, it doesn't have a method of degrading,\nthe don't display anything in error is a key weakness, and a key strength of\nHTML 4.01 as deployed.  I don't think pretending XHTML is really HTML\ntag-soup and relying on that get us out of trouble if we make a mistake is\nto be applauded.   I don't think we should deploy XHTML in any format,\nunless we have automated publishing tools to actually ensure it's valid, the\nconstraint on invalid - no rendering is too severe a failure, in a document\nthat is mostly correct.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 1.0 spec (was Re: Call for contributions: new and  improved   &quot;Web site quality&quot; article",
            "content": "Brian Kelly wrote:\n\n[snip]\n\n> \n> Note that an advantage with text/html is that the page will display if the\n> XHTML is invalid.  I think it would be difficult to sell the notion of\n> application/xml if an invalid file is not displayed (I appreciate the need\n> for compliance - this comment is about marketing XHTML.  One could argue\n> that HTML 4.0 is a more fault tolerant format that XHTML (I wouldn't say\n> that but others may).\n\nBrian,\n\nI really must chime in and agree with Jim about this.\n\nThe point that he and I have been trying to make over some period of \ntime is that the attitude that serving XHTML as text/html and allowing \nauthors to get in the habit of authoring invalid XHTML all the while \nthinking it is ok will end up destroying the promise that is XHTML.\n\nOne of the great advantages to authoring in XML and XHTML (as \napplication/xhtml+xml) is that the documents must be well formed at the \nvery least. To take the position that the requirement of well formed \ndocuments is a disadvantage and that any hodgepodge of markup should be \ndisplayed is antithetical to the entire idea behind XML.\n\nAs Jim stated, I have not heard a good reason to use XHTML when it is \nserved as text/html, especially when the content is not subject to a \nstrict validation process.\n\nThe reason I brought up the news.com site today was to illustrate the \nBad Things(tm) that are happening to XHTML because of lack of a \ncommitment to what XHTML really is... XML. Why are we recommending XHTML \nover HTML when all we expecting of the author is that they continue to \nauthor HTML as they always have?\n\n/bc\n\n\n\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 1.0 spec (was Re: Call for contributions: new and  improved    &quot;Web site quality&quot; article",
            "content": "Hi Bob\n   Thanks for the email.\n   I understand your (and Jim's) rationale.  I got the impression at the\nWWW 2003 conference that the problem with dodgy XHTML was to be addressed\nwith XHTML 2.0. Anyway I don't have any disagreements with the logic of\nyour position.\n   I guess my current interest is in the deployment of the application/xml\nMIME type in a University server environment (typically a mixture of XHTML\nand HTML; PHP, etc).\n   Thinking about it makes me wonder if the advice on format independent\nURIs ties in with MIME type mapping.\n   BTW the reason I'm using XHTML 1.0 is (1) to gain experience of\nproblems - as I'm now finding; (2) to be able to use XSLT to transform\nthe resources (e.g. to RSS) and (3) is the most recent W3C recommendation\nfor HTML and its use is preferred (this is my current understanding).\n   I get the impression that this (esp. point 3) isn't your's (or Jim's\nview).  I guess your position is that the best approach is\nXHTML+application/xml (or whatever) and if you can't guarantee to provide\nthe MIME type (for whatever reason) you should stick with HTML 4. If this\nis felt to be the best approach, shouldn't there be some advice on the QA\nLibrary covering this?  As I pointed out in a previous message the XHTML 1\nspec does allow text/html.  I think additional caveats about the denages\nof this approach are needed.\n   (My apols if this is going over old ground or slightly out of scope\nfor this list).\n\nBrian\n\n------------------------------------------------------\nBrian Kelly, UK Web Focus\nUKOLN, University of Bath, BATH, England, BA2 7AY\nEmail:  b.kelly@ukoln.ac.uk     URL:    http://www.ukoln.ac.uk/\nHomepage: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/\nPhone:  01225 323943            FAX:   01225 826838\n\nOn Thu, 2 Oct 2003, Bob Clary wrote:\n\n> Brian Kelly wrote:\n>\n> [snip]\n>\n> >\n> > Note that an advantage with text/html is that the page will display if the\n> > XHTML is invalid.  I think it would be difficult to sell the notion of\n> > application/xml if an invalid file is not displayed (I appreciate the need\n> > for compliance - this comment is about marketing XHTML.  One could argue\n> > that HTML 4.0 is a more fault tolerant format that XHTML (I wouldn't say\n> > that but others may).\n>\n> Brian,\n>\n> I really must chime in and agree with Jim about this.\n>\n> The point that he and I have been trying to make over some period of\n> time is that the attitude that serving XHTML as text/html and allowing\n> authors to get in the habit of authoring invalid XHTML all the while\n> thinking it is ok will end up destroying the promise that is XHTML.\n>\n> One of the great advantages to authoring in XML and XHTML (as\n> application/xhtml+xml) is that the documents must be well formed at the\n> very least. To take the position that the requirement of well formed\n> documents is a disadvantage and that any hodgepodge of markup should be\n> displayed is antithetical to the entire idea behind XML.\n>\n> As Jim stated, I have not heard a good reason to use XHTML when it is\n> served as text/html, especially when the content is not subject to a\n> strict validation process.\n>\n> The reason I brought up the news.com site today was to illustrate the\n> Bad Things(tm) that are happening to XHTML because of lack of a\n> commitment to what XHTML really is... XML. Why are we recommending XHTML\n> over HTML when all we expecting of the author is that they continue to\n> author HTML as they always have?\n>\n> /bc\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "URIs for deliverable reports",
            "content": "Hi all, but mostly Dan and Libby.\n\nI am trying t oput together the report for deliverable 3.6:\ndev_workshop_report_1 (the image annotation and EARL workshop held in\nBristol). I know that you are using RDF scraping tools in the SWAD-E web\ncontent, and the README stuff there says this relies on constraints beyond\njust \"valid XHTML/CSS\" (my normal constraints). I see that tehre are also\nstyle sheets designed in that area.\n\nFirst and most important question is whether there are particular URI\nconventions you are using for the scraping to RDF - i.e. should my report go\nin a particular place?\n\nSecond (which is not so urgent) is what styylesheets I should use, etc, and\nhow much I should just figure out for myself.\n\nCheers\n\nChaals\n\n-- \nCharles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\nW3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38 78 22\nLocation: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 1.0 spec (was Re: Call for contributions: new and  improved    &quot;Web site quality&quot; article",
            "content": "\"Brian Kelly\" <b.kelly@ukoln.ac.uk>\n>    I understand your (and Jim's) rationale.  I got the impression at the\n> WWW 2003 conference that the problem with dodgy XHTML was to be addressed\n> with XHTML 2.0.\n\nGetting a new markup language out won't solve the problem of dodgy XHTML,\ndodgy XHTML is a user problem, not a standards problem - developers have\nlittle incentive to author XHTML valid pages, as there's virtually no cost\nin authoring invalid ones.  We can only change this behaviour by providing\nreal benefits in the valid.  As I see there's 2 options to this, ensure that\nnew UA's don't render invalid XHTML - this is completely unrealistic, UA's\nneed to render content that aren't 100% right, planes don't stop flying just\nbecause the lock on the toilet door doesn't work.  Alternatively the UA's\ncan indicate that it's used some form of fixup, perhaps by not using the\nusers stylesheet or something that provides the content, whilst still making\nit clear it's not right.\n\nWhatever we choose we'll only be able to deploy these new User Agents\nagainst application/xhtml+xml, text/html is lost - that means tag-soup, and\nbecause of that we have to ensure that there's not a large userbase of\ninvalid XHTML ready to be dumped on this unsuspecting XHTML ua - if there\nis, that UA will have to render it, or people won't use it.\n\n>    BTW the reason I'm using XHTML 1.0 is\n> (1) to gain experience of problems - as I'm now finding;\n> (2) to be able to use XSLT to transform\n\nThis is a good reason, but we can still present HTML from XHTML sources,\nit's just an extra publishing step, this may be too much trouble, but then I\ndon't find XHTML meets my needs as a storage format in any case - I'd rather\ngo RSS->HTML than XHTML->RSS, keeping the storage in the richer semantic\nformat.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: XHTML in the real worl",
            "content": "hi people, i have a question, if i have\n<node>\n<menu>\n<item>what ever</item>\n<subitem>title 1</subitem>\n<subitem>title 2</subitem>\netc...\n<item>same thing above</item>\n<subitem>...</subitem>\netc...\n</menu>\n</node>\n\nin XSL can i get all values of all items and subitems?\nI use PHP as an example, but, i just can get this values using the PHP\nlanguage (making an array parser), not the XSL language.\n\nThis is possible to do with XSL?\n\n--\nThanks\n\n----- Original Message ----- \nFrom: \"Bob Clary\" <bc@bclary.com>\nTo: <public-evangelist@w3.org>\nSent: Thursday, October 02, 2003 12:08 PM\nSubject: XHTML in the real world\n\n\n> How do we deal with sites like this?\n>\n> <http://news.com.com/>\n> <http://validator.w3.org/check?uri=http%3A%2F%2Fnews.com.com%2F>\n>\n> Does anyone want to take the lead in contacting them and asking them to\n> produce valid XHTML. I would love to a) hear their response and b) see\n> the site corrected.\n>\n> /bc\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: XHTML in the real worl",
            "content": "Le Samedi, 4 octo 2003, ? 00:32 America/Montreal, Turbano a ?crit :\n> hi people, i have a question, if i have\n> <node>\n> <menu>\n> <item>what ever</item>\n> <subitem>title 1</subitem>\n> <subitem>title 2</subitem>\n> etc...\n> <item>same thing above</item>\n> <subitem>...</subitem>\n> etc...\n> </menu>\n> </node>\n>\n> in XSL can i get all values of all items and subitems?\n\nyes it's possible. Use the Appropriate XPath. if you know your output \ntemplate it might be easy to ouput it in XHTML, another XML language, \nRSS 1.0 feed, etc and even text only file.\n\nSee the tutorial there\nhttp://tutorials.beginners.co.uk/read/category/84/id/303\n\n\n\n\n\n-- \nKarl Dubost - http://www.la-grange.net/\nPr?s de vous, madame, oubliant les cieux,?\nL'astronome ?tonn? se trouble; ???????????????\nC'est dans l'?clat caressant de vos yeux,?\nQu'il avait cru trouver l'?toile double.?\n\n\n\n"
        },
        {
            "subject": "Old Web VS New We",
            "content": "before i begin sorry if this message is in this room its just that i couldn't find any \"general / all round - i need to message someone out there for help\" room..so if this is wrong room please forgive me for making the error....( i posted this in www-collaboration@w3.org before this room then someone recommended i post it here - so someone is actually listening-which makes me feel a bit better)\n\n\nTo whom ever may take the time to read this long question/explanation\n\n\nI am almost 22 years old and i have been working (tinkering) with the web since I was younger (14,15,16???) basically since Hotdog(one of the first HTML editor came out)\n\nI have come to know HTML (or the old web as i now call it) basically off the back of my hand and could code it in my sleep.\n\nPeople say that I am good at building website (althou from a developers point of view i am never happy with any of my work as there is so many ways to produce a website  in and never enough time or money to do it in.)\n\nThe point im getting at in this message is, all my time(week days and week ends, i virtually eat, sleep and drink web) - I have put into web(from Flash, ASP, JS, etc) and become (or at least hope so) good at web - the one thing that I adore / love beyond anything even probably more then my mother(god forbid she ever hears that).\n\nI received an email the other day - from someone that will remain anonymous - who said that my website does not meet the W3 standards (validator.w3.org i think the link is)\n\n\nAfter doing some research in this subject  - I have come to find out that basically all i know about the web no longer exists or is so different for what is was. (sure IE and NS displays it fine...but I want that something more...that \"im doing a good job/meeting a standard\" kinda feeling in your gut ) \n\nI have come to find that the new web is using CSS to layout information and images - and that tables are now not being used - im feeling very lost and very upset over this (not because of change - dont get me wrong i love change so long as I have some really good examples as to how to change to the new way)\n\nAre tables really not being used any more? the reason why i ask is because when working with database items you do not know how long something is when returned and if you use CSS with absolute positioning it appears (only from my research, i haven't done it  in practice) it will over lap and that is no good =(\n\nDo not get me wrong with my next sent but I dislike the examples that the W3C give out - they are terrible in my opinion, they are so scientific and lack any real world scenarios. I lik the W3C and I am glad that they exist and that people are making the web technology easier - I just wish they would give proper tutorials instead of just throwing a whole heap of specifications at us and then expecting me to follow without teaching me - like i said please do not take my previous statement the wrong way as insulting its just my insignificant opinion, and yes i have looked around the web for tutorials - they they dont really get into the guts of each topic, sadly. \n\nalso this XML and XSLT - is really confusing is XSLT the same as CSS?(from my research im sure it isn't - I wish i had working examples (that was how i originally learnt the web - with hotdog - and fiddling around with the code then ripping appart other peoples code when i had a web connection))\n\nI asked some of the other web developers I know (2 others) but they were not much help they say why bother most people have IE and if it works in that then it work - me being a stubborn taurus wont settle for that as i know - how do i put this into word -there has to be a personal responsibility to product good web pages, if you do not your work/effort is not worth while - I WANT to produce them to good standards and say \"hey I did a good job\"! plus being in australia you are not exactly surrounded by web developers (which is a good and bad thing).\n\nDoes any one have any working examples?\nDoes anyone else feel as lost as me?\n\nCould someone please help me (an person who feels like an old time geezer)?\n\nI could tell you a whole heap of other stuff if you are still reading this far down but I wont.\n\nThank you heaps\nGavin\nAbyss\n\n\n\n"
        },
        {
            "subject": "Re: Old Web VS New We",
            "content": "Hi,\n\nOn Monday, Oct 6, 2003, at 07:26 Asia/Tokyo, PWP - Information wrote:\n> I am almost 22 years old and i have been working (tinkering) with the \n> web since I was younger (14,15,16???) basically since Hotdog(one of \n> the first HTML editor came out)\n> ?\n> I received an email the other day - from someone that will remain \n> anonymous - who said that my website does not meet the W3 standards \n> (validator.w3.org i think the link is)\n> ??\n> After doing some research in this subject? - I have come to find \n> out?that basically all i know about the web no longer exists or is so \n> different for what is was. (sure IE and NS displays it fine...but I \n> want that something more...that \"im doing a good job/meeting a \n> standard\" kinda feeling in your?gut?)\n> ?\n> I have?come to find that the new web is using CSS to layout \n> information and images - and that tables are now not being used - im \n> feeling very lost and very upset over this (not because of change - \n> dont get me wrong i love change so long as I have some really good \n> examples as to how to change to the new way)\n\nMy main question here is \"why are you upset\"?\n\nApparently, you've been editing the Web for a very long time, and that \nmakes you, believe it or not, a pioneer. At the time you started, the \nWeb was in its infancy and still evolving, and one would be right in \nsaying this is still the case: new Web technologies are still created, \nothers are refined, and existing ones are still being experimented, \nlearned, and as more and more people use them, good practices emerge \nand are embraced by the Web community (and some are not).\n\nAmong these practices are those you mention, that the trend now is to \nuse valid (that is, real) HTML (instead of the thing closely resembling \nHTML called \"tag soup\") and to separate content from style and layout, \nleaving the former to (X)HTML and using CSS for the latter. These new \ntrends make sense for most people and those who see them as a \"good \nthing\"(TM) for the web will tend to advocate for their use. There is, \nhowever, nothing to be upset about, nobody will force you to follow \nthese good practices, though some may try to convince you that they're \nbetter for you too.\n\nSo there is no \"Old vs New\" Web, there's only one Web that's evolving...\n\n\n> Are tables really not being used any more?\n\nOf course tables are still being used, though the (rather abusive) \ntrend of using HTML tables for every and anything, is getting old and \nthe use of CSS for layout, made possible by improved support in user \nagents, is now preferred. Tables can and should still be used for what \nthey're meant, that is, tabular display of data or information.\n\n>  the reason why i ask is because when working with database items you \n> do not know how long something is when returned and if you use CSS \n> with absolute positioning it appears (only from my research, i haven't \n> done it? in practice) it will over lap and that is no good =(\n\nI can only suggest you to actually experiment. There are many, many \nresources out there to help you. Just ask your favorite search engines \nabout e.g \"tableless css\" or \"tables css\" and you will find many good \nresources...\n\n> Do not get me wrong with my next sent but I dislike the examples that \n> the W3C give out\n\nIdeally W3C specifications would be perfect, both absolutely acurate \nfor implementors, clear and detailed for users, and simple for the \ncurious layman. I, however, challenge anyone to do all this with \nlimited time and resources that are the usual constraints in the real \nworld... W3C specifications are done primarily for implementors, and \nwhile there are efforts to create good and acurate documentation around \nte W3C specifications (e.g the work done by people subscribed to this \nlist...), it can not all be done by W3C.\n\n>  and yes i have looked around the web for tutorials - they they dont \n> really get into the guts of each topic, sadly.\n\nI find a lot of the tutorials on CSS quite good actually, it's just \nthat it does take time to learn all this...\n\n> also this XML and XSLT - is really confusing is XSLT the same as CSS?\n\nNo. Check http://www.w3.org/Style/ and \nhttp://www.w3.org/Style/CSS-vs-XSL for a longer answer.\n\n> I asked some of the other web developers I know (2 others) but they \n> were not much help they say why bother most people have IE and if it \n> works in that then it work - me being a stubborn taurus wont settle \n> for that as i know - how do i put this into word -there has to be a \n> personal responsibility to product good web pages, if you do not your \n> work/effort is not worth while - I WANT to produce them to good \n> standards and say \"hey I did a good job\"!\n\nBottom line... You care about interoperability and the quality of your \nproduct, which is great, but you feel your technique is not up to par \nwith the current best practices. I don't think you are alone in that \nsituation, I believe you're actually already quite far on the \"road to \ngood web practices enlightenment\" :)\nThe bad news is, there is plenty to learn.\nThe good news is, there is plenty to learn.\n\nRegards,\n-- \nolivier\n\n\n\n"
        },
        {
            "subject": "RE: XHTML 1.0 spec (was Re: Call for contributions: new and improved  &quot;Web site quality&quot; article",
            "content": "Hi Jim (and Bob)\n    Following your comments about XHTML and MIME types I've written a\ndraft advisory document which takes on-board your suggestions:\nhttp://www.ukoln.ac.uk/qa-focus/documents/briefings/briefing-35/\n\nand a case study which explains why the QA Focus Web site uses XHTML and\nhow we intend to change the MIME types:\nhttp://www.ukoln.ac.uk/qa-focus/documents/case-studies/case-study-22/\n\nComments welcome.\n\nThanks\n\nBrian\n\n---------------------------------------\nBrian Kelly\nUK Web Focus\nUKOLN\nUniversity of Bath \nBATH\nBA2 7AY\nEmail: B.Kelly@ukoln.ac.uk\nWeb: http://www.ukoln.ac.uk/\nPhone: 01225 383943\nFOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf\nFor info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/\n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Jim Ley\n> Sent: 02 October 2003 19:13\n> To: public-evangelist@w3.org\n> Subject: Re: XHTML 1.0 spec (was Re: Call for contributions: \n> new and improved \"Web site quality\" articles\n> \n> \n> \n> \"Brian Kelly\" <b.kelly@ukoln.ac.uk>\n> > On Thu, 2 Oct 2003, Jim Ley wrote:\n> > > XHTML is only \"allowed\" to be served as text/html if it's under \n> > > Appendix\n> C,\n> > > if someone would like to correct me on that and say \n> Appendix C isn't \n> > > normative and any old XHTML can be served as text/html then I'll\n> withdraw\n> > > the criticism.\n> >\n> > The document says\n> > \"C. HTML Compatibility Guidelines\n> > This appendix is informative.\"\n> >\n> > If you think that's incorrect I suggest the editor of the \n> spec should \n> > be informed (I guess there's a QA of the spec issue).\n> \n> I agree Appendix C is non-normative, however the MIME-type \n> definition 5.1 is normative \n> http://www.w3.org/TR/xhtml1/#media and it says\n> \n> | XHTML Documents which follow the guidelines set forth in \n> Appendix C, \n> | \"HTML Compatibility Guidelines\" may be labeled with the \n> Internet Media \n> | Type \"text/html\"\n> \n> So whilst Appendix C isn't normative in itself (since you can \n> use application/xml or application/xhtml+xml for your XHTML) \n> if you wish to serve it as text/html 5.1 requires it to be.  \n> This is certainly been my interpretation and it's been \n> discussed here and in other places often enough that I'd've \n> thought someone would correct me on it if it was wrong.\n> \n> > C.7 says you need lang: and xml:lang attributes.  I have the lang \n> > attribute in the html element.  I don't need to give the xml:lang \n> > attribute as C.1 allows me to omit it (as I understand it).\n> \n> Ah, I understood the xml declaration was the\n> <?xml version=\"1.0\"?> and that was all you were being allowed \n> to leave out, it had no bearing on C.7, I could be wrong of \n> course, but again, it's been often discussed.\n> \n> \n> > So I think my approach is better than creating HTML 4 resources.\n> \n> All of your reasons for serving XHTML how are you, I entirely \n> agree with, and are completely understandable, indeed they're \n> probably required in the real world.  However you've not \n> given the reason why HTML 4.01 strict is not appropriate for \n> you, it's semantically identical to XHTML 1.0.  Or what it is \n> about it that makes you not want to author it (a point that \n> I've not yet seen made on this list)\n> \n> > Note that an advantage with text/html is that the page will \n> display if \n> > the XHTML is invalid.\n> \n> I'd personally say, this is a huge disadvantage of XHTML as \n> specified, not an advantage of breaking the rules, it doesn't \n> have a method of degrading, the don't display anything in \n> error is a key weakness, and a key strength of HTML 4.01 as \n> deployed.  I don't think pretending XHTML is really HTML \n> tag-soup and relying on that get us out of trouble if we make \n> a mistake is\n> to be applauded.   I don't think we should deploy XHTML in any format,\n> unless we have automated publishing tools to actually ensure \n> it's valid, the constraint on invalid - no rendering is too \n> severe a failure, in a document that is mostly correct.\n> \n> Jim.\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: Old Web VS New We",
            "content": "Hi Gavin,\n\nMay I please direct you to some recommended reading:\nI'm 20 and also have benn designing since I was around 14/15.\n\nI hope you find these links helpful.\n\n-- Groups --\n[1] \"Making A Commercial Case for Adopting Web Standards\"\n<http://www.maccaws.org/> *Join this group*\n\n-- Inspirational W3C compliant Sites --\n[2] \"css Zen Garden: The Beauty in CSS Design\" <http://www.csszengarden.com/>\n\n-- Online Articles --\n[3] \"Better Living Through XHTML\"\n<http://www.alistapart.com/stories/betterliving/>\n[4] \"How To Read W3C Specs\" <http://www.alistapart.com/stories/readspec/>\n[5] \"Fixing Your Site With The Right DOCTYPE\"\n<http://www.alistapart.com/stories/doctype/>\n[6] \"Why Don't You Code For Netscape?\"\n<http://www.alistapart.com/stories/netscape/>\n[7] \"From Web Hacks to Web Standards : A Designer's Journey\"\n<http://www.alistapart.com/stories/journey/>\n[8] \"The Business Value of Web Standards\"\n<http://www.adaptivepath.com/publications/essays/archives/000266.php>\n\n-- Books --\n[8] \"Designing With Web Standards\" <http://www.zeldman.com/dwws/>\n\nRegards\nTim Burgan\n\n\n\n"
        },
        {
            "subject": "SWAD-E deliverables  finding out what they are",
            "content": "Hi all,\n\nI've been looking through a few tools Dan and I worked on to try and\ntrack SWAD-e events, especially for Kate.\n\nThis was because we did get deliverables to palm working and this\nmonth's deliverables poppped up on my palm....! This needs a bit more\nwork though (there's the probablility of making a horrible mess with\nduplicates at the moment) - so I'll send a separate note about that\nsometime.\n\nSo I noticed that in addition to Dave's report and Kate's first\nmanagement report we are due to do a dissemination and use plan by the\nend of this month. Dan, Charles and I are on the hook for that - we'll\nbe looking at it this week.\n\n<pm:deliverable>\n<rdf:Description  rdf:about=\"http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-3.html#del_3.5\">\n <pm:name>dissemination_use_plan</pm:name>\n <pm:deliv_lead_email rdf:resource=\"mailto:danbri@w3.org\" />\n <pm:deliv_interest_email rdf:resource=\"mailto:libby.miller@bristol.ac.uk\" />\n <pm:deliv_interest_email rdf:resource=\"mailto:charles@w3.org\" />\n </rdf:Description>\n </pm:deliverable>\n\nI thought I'd better write up some of what we did for future\nreference, and so that people have a better idea of what\nwe can do with SWAD-Europe management tools as they stand.\n\nYou can see the deliverables due using my calendar tool:\n\nhttp://www.w3.org/2001/sw/Europe/events/view/\nhttp://www.w3.org/2001/sw/Europe/events/view/calmonth.jsp?url=&rdfweburl=http://sw1.ilrt.org/discovery/2002/05/rsscal/esw-delivs.rdf\n\n(writeup:\nhttp://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html)\n\nI generated the information from the raw deliverables in RDF output:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/_esw_projdata.rdf\n\nwhich were in turn generated using Dan's Perl program from the\nworkpackages in xhtml\n\nPerl program:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/bin/extract_projdata.pl\n\nsample xhtml file:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-1.html\n\nI used Dan's Ruby code to generate a pseudo RSS+events file from the raw\nRDF:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/bin/esw-delivs-events.rb\n\nand also combined the deliverables information with the information from\nthe face to face about who is responible for which deliverable, so\nthat we get the combined information - what is to be done, and who is\nresponsible.\n\nwho does what file:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/whodoeswhat.rdf\n\nSquish query used:\n\nselect ?deliv, ?email, ?num, ?date, ?dd,\nWHERE\n(pm::deliv_lead_email ?deliv ?email)\n(pm::name ?deliv ?dd)\n(pm::number ?deliv ?num)\n(pm::realDateDue ?deliv ?date)\nUSING\n pm for http://www.w3.org/2002/02/esw/pm#\nfoaf for http://xmlns.com/foaf/0.1/'\n\nWe need more tools to help with this sort of thing - such as - a tool\nwhich tells me what I'm supposed to be delivering when, for example.\nAny other ideas - especially from Kate - would be very welcome.\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: Old Web VS New We",
            "content": "Dear Tim\n\nWow, thanks I will look into those links right away!\n\nthank you heaps - I appreciate it!\n\nRegards\nGavin\n\n\n\n"
        },
        {
            "subject": "Request for ideas, informatio",
            "content": "Greetings.\n\nNext week I'm presenting a talk (\"The Quest for Compliance\") on using\nW3C standards when creating and redesigning Web sites\n(http://www-conf.slac.stanford.edu/interlab03/).\n\nDoes anyone have suggestions where I could find specific, concrete facts\nto back up the benefits of using W3C standards on Web sites? I have one\ngood measurement: size of the same page rendered using tables and using\nXHTML/CSS. Taking the sizes multiplied by number of page views in a\ngiven period, and then cost in bandwidth.\n\nAny suggestions would be most welcome.\n\nThanks.\n\nKim Nylander \n\n_______________________________________________________________\nGet the FREE email that has everyone talking at\nhttp://www.mail2world.com\n\n  \n\n\n\n\n"
        },
        {
            "subject": "Re: Request for ideas, informatio",
            "content": "Hi Kim,\n\nKim Nylander wrote:\n\n> Greetings.\n>\n> Next week I'm presenting a talk (\"The Quest for Compliance\") on using \n> W3C standards when creating and redesigning Web sites \n> (http://www-conf.slac.stanford.edu/interlab03/).\n\nCool.\n\n>\n> Does anyone have suggestions where I could find specific, concrete \n> facts to back up the benefits of using W3C standards on Web sites? I \n> have one good measurement: size of the same page rendered using tables \n> and using XHTML/CSS. Taking the sizes multiplied by number of page \n> views in a given period, and then cost in bandwidth.\n\nNetscape DevEdge still hosts some interesting stuff on this topic :\n\nSee http://devedge.netscape.com/viewsource/2003/media-farm/\n\nIn terms of bandwidth saving, the ESPN interview is great : see \nhttp://devedge.netscape.com/viewsource/2003/espn-interview/01/\n\nfor more case studies, see \nhttp://devedge.netscape.com/central/strategy/2003/case-studies/\n\nFor a more theory-oriented article, see my \nhttp://devedge.netscape.com/viewsource/2003/why-web-standards/\n\n>\n> Any suggestions would be most welcome.\n>\n> Thanks.\n\nPlease let us know of the outcome, and I'd love to see you publish the \nresulting presentation.\n\n\n--Tristan\n\n-- \nContributeur Mozilla et OpenWebGroup\nhttp://mozilla.org/    : Efficiency, safety and liberty for browsing.\nhttp://openweb.eu.org/ : pour apprendre les standards.\nhttp://standblog.com/  : un blog sur les standards.\nhttp://pompage.net/    : de saines lectures ? propos des standards.\n\n\n\n"
        },
        {
            "subject": "WaSP Asks the W3C  HTML or XHTML: Which should we use, and why",
            "content": "Please see the recent WaSP asks the W3C article.  All discussion can take\nplace right here on this list.\n\nhttp://www.webstandards.org/learn/askw3c/oct2003.html\n\nEnjoy!\nMolly\n\nMolly E. Holzschlag\nAuthor / Instructor / Web Designer\nAbout Me: http://www.molly.com/\nAbout Web Standards: http://www.webstandards.org/ \n\n\n\n"
        },
        {
            "subject": "Re: WaSP Asks the W3C  HTML or XHTML: Which should we use, and why",
            "content": "Molly E. Holzschlag wrote:\n> Please see the recent WaSP asks the W3C article.  All discussion can take\n> place right here on this list.\n> \n> http://www.webstandards.org/learn/askw3c/oct2003.html\n\nIt's quite a coincidence that this article be published this week \nbecause we're having quite a passionate discussion related to this in \nthe french web standards community these days. Like anywhere else, \npeople are concerned about who's right and who's wrong in this. Is XHTML \nsuch a bad thing ? Is HTML too old for it's own good ? Ian Hickson who \nbelieves HTML should be used attracts the attention of a minority of \npurists (and I mean that in the most respectful way), and Jeffrey \nZeldman who says XHTML is the one to go for (which seems to attract the \nbroadest pack of followers).\n\nI'm looking forward to a discussion on this because, while we have \nplenty of ideas and opinions, most of them are led by personnal beliefs, \nnot actual proven facts.\n\nThose of you who can understand french will get a glimpse of all this \nmayhem here :\n\nhttp://www.cybercodeur.net/weblog/commentaires/detailsCarnet.php?idmessage=731\n\n-- \nDenis Boudreau [ CYBERcodeur.net ]\nContributeur W3Qu?bec et OpenWeb\n\nWeb1 : http://www.cybercodeur.net/\nWeb2 : http://www.openweb.eu.org/\nMail : denis [at] cybercodeur.net\nT?l. : 514.939.4373 | 514.585.8146\nICQ  : 115649885\n\n<C? : Weblog collaboratif />\nCoder moins, coder mieux !\n\n\n\n"
        },
        {
            "subject": "Current Version of HTML",
            "content": "Hi,\n\nThe WASP asks the W3 article says:\n\nHTML 4.01 is the last version of HTML, yet http://www.w3.org/TR/html (the\nlatest version of HTML according to the HTML 4.01 spec) points too XHTML\n1.0.\n\nI'd certainly be very glad to hear that HTML4.01 is the current version of\nHTML, however I believe this isn't the case, can you confirm the latest\nversion is indeed HTML 4.01 - so I can ask the HTML WG to fix the link?\n\nCheers,\n\nJim.\n\n\n\n"
        },
        {
            "subject": "WASP asks the W3  XHTML 1.0 or HTML 4.0",
            "content": "Hi,\n\nThe first of my two almost certainly predictable responses to...\n\nhttp://www.webstandards.org/learn/askw3c/oct2003.html\n\n(This is for the errors/lack of clarirty in the document, the other is to\nattempt to rebut the arguments)\n\n[in XHTML 1.0]\n\"empty elements are terminated using a space and a trailing slash\"\n\nno they're not in XHTML, they're closed by a trailing slash - the whitespace\nis not relevant.\n\nNext is not strictly an error, but in the context of authoring XHTML 1.0\ntoday, where Appendix C compliance is essential, the example has:\n\n<p xml:lang=\"fr\"> ... </p>\n\nThis is not allowed under Appendix C. which requires that xml:lang and lang\nbe duplicated.\n\nAlso, you state that only syntax not semantics have changed, I do not agree\nwith this statement, in HTML and XHTML\n\n<script type=\"appliction/x-jims-script\">\n<!--\n// -->\n</script>\n\nHas different semantics - in HTML the <!-- is part of a script, in XHTML it\nis a comment.  The semantics may not matter to most people, but the\napplication/x-jims-script actually considers <!-- to mean write the current\ndate. and // --> to write the current time.  Utterly contrived example of\ncourse, but an example of how the semantics of elements have changed IMO\n(what's a comment in XHTML is a script in HTML)\n\n\n\"In HTML, [...] termination of many elements [...] are allowed and\ncommonplace.\"\n\nCould you provide an example of an element in HTML which is allowed to not\nbe terminated. (as opposed to a tag of course which can, AIUI it is not\npossible to have a valid HTML document with elements not closed.)\n\nEnough of the errors, although they need fixing before the rest of the\ndocument can be taken seriously, now the actual content of the document:\n\n\"Switching from HTML 4.01 to XHTML 1.0 brings almost no direct benefits for\nthe visitors of your Web site\"\n\nAlmost no? - could you expand on the benefits it does bring, as this was\nwhat I was hoping to get from the question, and alluding to, but not listing\nthe benefits has left me just wanting more.\n\n\"XHTML is easier to maintain\"\n\nThis glosses over the fact that there are no QA tools to ensure XHTML\nAppendix C compliance, without these, I can't see how the claim can be\njustified - especially as one of the statements isn't even detectable by the\nW3's own XHTML validator, or any other validator/QA tool I know of.\n\n\"The margin for errors in HTML is much broader than in XHTML, where the\nrules are very clear\"\n\nWhat are unclear about the rules of HTML4 ?  The W3's validator, and other\nSGML based validation appear to have no problem in validating to the HTML\nrules - Is the document intending to suggest that the HTML 4 specification\nis flawed?   I have large problems with the XHTML specification for example\nAppendix C.1 suggests avoiding PI's and Appendix C.14 suggests using PI's -\nthis contradiction in the specification is not what I'd call clear.\n\nI really do appreciate the work of the QA team and the WASP, and I'm sorry\nthat my responses to their articles are generally negative, but I do believe\ntheir decision to defend a bad technology decision (XHTML as text/html)\nshould not be supported, and it should have to actually talk the truth and\nnot gloss over the flaws.\n\nCheers,\n\nJim.\n\n\n\n"
        },
        {
            "subject": "RE: WASP asks the W3  XHTML 1.0 or HTML 4.0",
            "content": "Jim and I had a similar discussion a few weeks ago.  This helped me\nclarify my thinking, but I don't necessarily agreed with all of Jim's\nviews.\n\nAnyway, in the context of the WASP document:\n\nWhy use XHTML 1.0?  \n\nOne possible reasons:\n\nIt's the latest recommended version of HTML, according to W3C. If this\nis not the case (it's experimental, browsers aren't ready for it, etc.)\nthe W3C page should be updated to reflect this otherwise W3C are giving\nthe wrong signals.\n\nThe WaSP page says \"XHTML is easier to maintain\".\n\nI would agree with Jim that this is misleading - the current generation\nof tools aren't XHTML-ready; XHTML validators aren't widely deployed,\ngive ambiguous results, etc.\n\nThe WaSP page says 'The margin for errors in HTML is much broader than\nin XHTML, where the rules are very clear.'\n\nI'd draw the opposite conclusion.  The HTML spec allows mixed case for\nelements, quoted or unquoted attributes in many cases, etc.  HTML is\ntherefore more tolerant of not only errors but also different approaches\nto producing compliant HTML; unlike XHTML which does not provide such\nflexibility.\n\nThe WaSP page says \"HTML is easier to teach and to learn\nThe syntax rules defined by XML are far more consistent than those found\nin HTML and therefore easier to explain than the SGML rules on which\nHTML is based.\"\n\nPartly true, but most people won't be learning from scratch and will\nhave to unlearn current HTML.\n\nThe WaSP page says 'XHTML is XSL ready'\n\nI agree this is a valid reason - but there's still the MIME type issue\nto consider.\n\nIncidentally the MIME type issue is a reason why XHTML is not easier to\nmaintain.  Put an unescaped ampersand or an MS Windows character in a\nHTML page and it's still viewable on many platforms; do the same in an\nXHTML document with an XHTML MIME type and you get nothing.  XHTML is\nless fault-tolerant but more rigorous - a simple \"XHTML is easier to\nmaintain\" slogan is quite clearly incorrect.\n\n> \n> \"Switching from HTML 4.01 to XHTML 1.0 brings almost no \n> direct benefits for the visitors of your Web site\"\n> \n> Almost no? - could you expand on the benefits it does bring, \n> as this was what I was hoping to get from the question, and \n> alluding to, but not listing the benefits has left me just \n> wanting more.\n\nWouldn't \"Switching from HTML 4.01 to XHTML 1.0 currently brings almost\nno \ndirect benefits for the visitors of your Web site but the ability to\nmake use of XSLT provides the potential for a range of benefits\" be a\nreasonable comment to make?\n\n> \n> I really do appreciate the work of the QA team and the WASP, \n> and I'm sorry that my responses to their articles are \n> generally negative, but I do believe their decision to defend \n> a bad technology decision (XHTML as text/html) should not be \n> supported, and it should have to actually talk the truth and \n> not gloss over the flaws.\n> \nThe position I'm coming to is that XHTML + correct MIME type should be\ndeployed today in circumstances in which compliant XHTML 1.0 can be\nguaranteed - typically with software which can impose compliance doing\nthe creation.  XHTML 1.0 is not recommended for use with HTML authoring\ntools unless they can force strict compliance or unless there is a\npublication process which addresses these issues (and using vi to write\ndirectly to Web file store can't do that!).\n\nBrian\n\n> Hi,\n> \n> The first of my two almost certainly predictable responses to...\n> \n> http://www.webstandards.org/learn/askw3c/oct2003.html\n> \n> (This is for the errors/lack of clarirty in the document, the \n> other is to attempt to rebut the arguments)\n> \n> [in XHTML 1.0]\n> \"empty elements are terminated using a space and a trailing slash\"\n> \n> no they're not in XHTML, they're closed by a trailing slash - \n> the whitespace is not relevant.\n> \n> Next is not strictly an error, but in the context of \n> authoring XHTML 1.0 today, where Appendix C compliance is \n> essential, the example has:\n> \n> <p xml:lang=\"fr\"> ... </p>\n> \n> This is not allowed under Appendix C. which requires that \n> xml:lang and lang be duplicated.\n> \n> Also, you state that only syntax not semantics have changed, \n> I do not agree with this statement, in HTML and XHTML\n> \n> <script type=\"appliction/x-jims-script\">\n> <!--\n> // -->\n> </script>\n> \n> Has different semantics - in HTML the <!-- is part of a \n> script, in XHTML it is a comment.  The semantics may not \n> matter to most people, but the application/x-jims-script \n> actually considers <!-- to mean write the current date. and \n> // --> to write the current time.  Utterly contrived example \n> of course, but an example of how the semantics of elements \n> have changed IMO (what's a comment in XHTML is a script in HTML)\n> \n> \n> \"In HTML, [...] termination of many elements [...] are \n> allowed and commonplace.\"\n> \n> Could you provide an example of an element in HTML which is \n> allowed to not be terminated. (as opposed to a tag of course \n> which can, AIUI it is not possible to have a valid HTML \n> document with elements not closed.)\n> \n> Enough of the errors, although they need fixing before the \n> rest of the document can be taken seriously, now the actual \n> content of the document:\n> \n> \"Switching from HTML 4.01 to XHTML 1.0 brings almost no \n> direct benefits for the visitors of your Web site\"\n> \n> Almost no? - could you expand on the benefits it does bring, \n> as this was what I was hoping to get from the question, and \n> alluding to, but not listing the benefits has left me just \n> wanting more.\n> \n> \"XHTML is easier to maintain\"\n> \n> This glosses over the fact that there are no QA tools to \n> ensure XHTML Appendix C compliance, without these, I can't \n> see how the claim can be justified - especially as one of the \n> statements isn't even detectable by the W3's own XHTML \n> validator, or any other validator/QA tool I know of.\n> \n> \"The margin for errors in HTML is much broader than in XHTML, \n> where the rules are very clear\"\n> \n> What are unclear about the rules of HTML4 ?  The W3's \n> validator, and other SGML based validation appear to have no \n> problem in validating to the HTML rules - Is the document \n> intending to suggest that the HTML 4 specification\n> is flawed?   I have large problems with the XHTML \n> specification for example\n> Appendix C.1 suggests avoiding PI's and Appendix C.14 \n> suggests using PI's - this contradiction in the specification \n> is not what I'd call clear.\n> \n> I really do appreciate the work of the QA team and the WASP, \n> and I'm sorry that my responses to their articles are \n> generally negative, but I do believe their decision to defend \n> a bad technology decision (XHTML as text/html) should not be \n> supported, and it should have to actually talk the truth and \n> not gloss over the flaws.\n> \n> Cheers,\n> \n> Jim.\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: WASP asks the W3  XHTML 1.0 or HTML 4.0",
            "content": "\"Brian Kelly\" <B.Kelly@ukoln.ac.uk>\n\n> The WaSP page says 'XHTML is XSL ready'\n>\n> I agree this is a valid reason - but there's still the MIME type issue\n> to consider.\n\nThe problem I have with this argument is that you're imposing the needs of a\nparticular programming language onto every author and user agent in\nexistance, when it should really only be people wishing to use XSLT - HTML\n4.01 -> XHTML 1.0 is a mechanical automated process available from a number\nof tools.  I do not feel that users of XSLT should impose their needs on the\nrest of us, or that using XSLT is an argument.\n\nAlso of course people with XSLT hammers would be easily able to convert\ntheir XHTML to HTML 4.01, and serve both to users, there'd be virtually no\ncost in doing so.\n\n> Wouldn't \"Switching from HTML 4.01 to XHTML 1.0 currently\n> brings almost no  direct benefits for the visitors of your Web\n> site but the ability to make use of XSLT provides the potential\n> for a range of benefits\" be a reasonable comment to make?\n\nProbably, although as above I don't feel XSLT alone is a particularly strong\nargument.\n\n> The position I'm coming to is that XHTML + correct MIME type should be\n> deployed today in circumstances in which compliant XHTML 1.0 can be\n> guaranteed\n\nI fully support and agree with this, XHTML in such an environment would lose\nmost of the negatives, without compromising any of the positives.\n\nCheers,\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: Current Version of HTML",
            "content": "Le jeudi, 30 oct 2003, ? 12:00 America/Montreal, Jim Ley a ?crit :\n> HTML 4.01 is the last version of HTML, yet http://www.w3.org/TR/html \n> (the\n> latest version of HTML according to the HTML 4.01 spec) points too \n> XHTML\n> 1.0.\n>\n> I'd certainly be very glad to hear that HTML4.01 is the current \n> version of HTML, however I believe this isn't the case, can you \n> confirm the latest version is indeed HTML 4.01 - so I can ask the HTML \n> WG to fix the link?\n\nIt depends on what are the meanings of the words.\n\nHTML 4.01 is where the last version of the semantics has been defined \nand so the semantics for HTML 4.01 and XHTML 1.0  are defined in the \nHTML 4.01 specifications.\n\nhttp://www.w3.org/TR/html doesn't define a conformant link to a dtd or \nwhatsoever.\n\n\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: Current Version of HTML",
            "content": "\"Karl Dubost\" <karl@w3.org>\n>HTML 4.01 is where the last version of the semantics has been defined\n>and so the semantics for HTML 4.01 and XHTML 1.0  are defined in the\n>HTML 4.01 specifications.\n\nOkay, trying to be simple so there's no ambiguity:\n\nIs XHTML1 HTML?\n\n>http://www.w3.org/TR/html doesn't define a conformant link to a dtd or\n>whatsoever.\n\n\nIt's a link to what the HTML 4.01 Rec defines as \"the current version of\nHTML\"  The DTD is not the only arbiter of what is valid in a HTML document\n(for example prose limits the checked attribute to input type=radio or\ntype=checkbox, something which even the W3 homepage chooses to ignore)\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: WASP asks the W3  XHTML 1.0 or HTML 4.0",
            "content": "Le jeudi, 30 oct 2003, ? 12:55 America/Montreal, Jim Ley a ?crit :\n> http://www.webstandards.org/learn/askw3c/oct2003.html\n\nFirst of all, I want people read clearly something:\n\n\"\"\"C. HTML Compatibility Guidelines\nThis appendix is informative.\"\"\"\n\nThe whole C Appendix is not normative at all.\n\n> [in XHTML 1.0]\n> \"empty elements are terminated using a space and a trailing slash\"\n>\n> no they're not in XHTML, they're closed by a trailing slash - the \n> whitespace is not relevant.\n\nAgreed. I don't often put a space in my own pages. I even tend to \navoid it. Web authoring tool like BBEdit does it very well. You have an \noption to warn you or not about this behaviour. so you have the choice \nof doing it or not.\n\n> Next is not strictly an error, but in the context of authoring XHTML \n> 1.0\n> today, where Appendix C compliance is essential, the example has:\n>\n> <p xml:lang=\"fr\"> ... </p>\n\nAs you said it's not an error and \"The value of the xml:lang attribute \ntakes precedence.\" It's again the choice of the user.\n\nThere's no such thing as \"Appendix C compliance\". It's a strong and \nwrong abuse of words for the meaning of the spec.\n\n> This is not allowed under Appendix C. which requires that xml:lang and \n> lang be duplicated.\n\nAppendix C doesn't require. The section is informative.\n\n> Also, you state that only syntax not semantics have changed, I do not \n> agree with this statement, in HTML and XHTML\n>\n> <script type=\"appliction/x-jims-script\">\n> <!--\n> // -->\n> </script>\n>\n> Has different semantics - in HTML the <!-- is part of a script, in \n> XHTML it is a comment.  The semantics may not matter to most people, \n> but the\n> application/x-jims-script actually considers <!-- to mean write the \n> current date. and // --> to write the current time.  Utterly contrived \n> example of course, but an example of how the semantics of elements \n> have changed IMO (what's a comment in XHTML is a script in HTML)\n\n? I don't understand this comment\n\n> \"In HTML, [...] termination of many elements [...] are allowed and\n> commonplace.\"\n>\n> Could you provide an example of an element in HTML which is allowed to \n> not be terminated. (as opposed to a tag of course which can, AIUI it \n> is not possible to have a valid HTML document with elements not \n> closed.)\n\nargueing on expression, between elements and tags, I guess here?\n\nhttp://www.w3.org/TR/html4/intro/sgmltut.html\n\n\"\"\"\nEach element type declaration generally describes three parts: a start \ntag, content, and an end tag.\n\nThe element's name appears in the start tag (written <element-name>) \nand the end tag (written </element-name>); note the slash before the \nelement name in the end tag. For example, the start and end tags of the \nUL element type delimit the items in a list:\n\n<UL>\n<LI><P>...list item 1...\n<LI><P>...list item 2...\n</UL>\n\nSome HTML element types allow authors to omit end tags (e.g., the P and \nLI element types). A few element types also allow the start tags to be \nomitted; for example, HEAD and BODY. The HTML DTD indicates for each \nelement type whether the start tag and end tag are required.\n\nSome HTML element types have no content. For example, the line break \nelement BR has no content; its only role is to terminate a line of \ntext. Such empty elements never have end tags. The document type \ndefinition and the text of the specification indicate whether an \nelement type is empty (has no content) or, if it can have content, what \nis considered legal content.\n\"\"\"\n\n> Enough of the errors, although they need fixing before the rest of the\n\nnot so many errors finally.\n\n> document can be taken seriously, now the actual content of the \n> document:\n\n> \"Switching from HTML 4.01 to XHTML 1.0 brings almost no direct \n> benefits for the visitors of your Web site\"\n>\n> Almost no? - could you expand on the benefits it does bring, as this \n> was\n> what I was hoping to get from the question, and alluding to, but not \n> listing the benefits has left me just wanting more.`\n\nThe benefits are the ones listed all along the article for people who \nneed it. The points of the article is certainly to not make the switch \na requirement, but just a choice.\n\nWe don't explain and WE WILL NOT explain that you must switch to XHTML \n1.0, it's a choice for most of the users. Nobody is bad because they \nstill use HTML 4.01. Both solutions are perfectly usable.\n\n> \"XHTML is easier to maintain\"\n>\n> This glosses over the fact that there are no QA tools to ensure XHTML\n> Appendix C compliance, without these, I can't see how the claim can be\n\nBis Repetita: There's no such things as \"Appendix C compliance\".\n\n> justified - especially as one of the statements isn't even detectable \n> by the W3's own XHTML validator, or any other validator/QA tool I know \n> of.\n\nSome of the things are detected by BBEdit for example, I don't know \nabout other tools. Would it be nice if you were developping a module in \nPerl to add to the LogValidator which look at the Appendix C items.\n\nA detailed warning analysis of the Markup validator, it would be nice \nto do. As you know, Jim, Markup validator is made by volunteers like \nTerje, Nick, Bjoern, and I'm pretty sur such a detail analysis for a \nfuture warning mode would be very helpful. Giving your knowledge and \nyour strictness on the HTML specifications, it would be a valuable work \nfor the Web community.\n\n> \"The margin for errors in HTML is much broader than in XHTML, where the\n> rules are very clear\"\n>\n> What are unclear about the rules of HTML4 ?\n\nIn the context of education and using HTML 4, the rules are less \nsystematic. Sometimes you can avoid the end tag for an element, \nsometimes not and except if you read the DTD... you can't decide which \nones. I have taught HTML and XHTML, and I can tell certainly that XHTML \nis easier to teach without ambiguities.\nXHTML rules are systematics.\n\n> The W3's validator, and other SGML based validation appear to have no \n> problem in validating to the HTML rules - Is the document intending to \n> suggest that the HTML 4 specification is flawed?   I have large \n> problems with the XHTML specification for example Appendix C.1 \n> suggests avoiding PI's and Appendix C.14 suggests using PI's - this \n> contradiction in the specification is not what I'd call clear.\n\nYes it's a problem of the specification now. Appendix C is not \nnormative.\n\n> I really do appreciate the work of the QA team and the WASP, and I'm \n> sorry that my responses to their articles are generally negative, but \n> I do believe their decision to defend a bad technology decision (XHTML \n> as text/html) should not be supported, and it should have to actually \n> talk the truth and not gloss over the flaws.\n\nIt's fine Jim, often, when people review documents have a tendency to \npick up errors or being extremely critics with them, but that's the \ngoal of the review, there's nothing wrong with that. It doesn't mean \nthe document is bad.\n\nWe don't defend a bad technology. we explained different choices. As a \npersonal point of view, I prefer to use XHTML because it's a lot more \nconvenient for me in my daily business.\n\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: Current Version of HTML",
            "content": "Le vendredi, 31 oct 2003, ? 07:36 America/Montreal, Jim Ley a ?crit :\n> \"Karl Dubost\" <karl@w3.org>\n>> HTML 4.01 is where the last version of the semantics has been defined\n>> and so the semantics for HTML 4.01 and XHTML 1.0  are defined in the\n>> HTML 4.01 specifications.\n>\n> Okay, trying to be simple so there's no ambiguity:\n>\n> Is XHTML1 HTML?\n\nXHTML 1.0 is an hypertext markup language. YES.\n\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "SWADE related conference",
            "content": "I've compiled a list of related conferences for planning purposes. At\nthe moment they're available as an RSS 1.0 +events channel, though maybe\nHTML would have been better - when I have a sec I'll do an xslt\nstylesheet that converts RSS to html.\n\nhttp://sw1.ilrt.org/calendar/events/swevents.rss\n\nViewed with my calendar RSS viewer:\n\nhttp://www.w3.org/2001/sw/Europe/events/view/calmonth.jsp?rdfweburl=http://sw1.ilrt.org/discovery/2002/05/rsscal/confrss.rdf\n\nIf there are some I've missed I'd be grateful for information.\n\ncheers\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: WASP asks the W3  XHTML 1.0 or HTML 4.0",
            "content": "\"Karl Dubost\" <karl@w3.org>\n\n>Le jeudi, 30 oct 2003, ? 12:55 America/Montreal, Jim Ley a ?crit :\n>> http://www.webstandards.org/learn/askw3c/oct2003.html\n\n>First of all, I want people read clearly something:\n\n>\"\"\"C. HTML Compatibility Guidelines\n>This appendix is informative.\"\"\"\n\n>The whole C Appendix is not normative at all.\n\n|Section 5 \"This section is normative.\"\n|\n| 5.1 XHTML Documents which follow the guidelines set\n| forth in Appendix C, \"HTML Compatibility Guidelines\"\n| may be labeled with the Internet Media Type \"text/html\"\n| [RFC2854],\n\nAll my comments are in the context of XHTML as text/html, as the previous\nWASP asks the W3 stated it was relevant.  It is clear from both the\nnormative section 5.1 and RFC 2854 that following the rules of Appendix C is\nrequired if you're serving it as text/html\n\nhttp://www.webstandards.org/learn/askw3c/sep2003.html also makes this clear.\nIf the current document wishes to ignore this advice and is recommending\nXHTML served with the correct mime-type then it needs to make this clear.\n\n>Agreed. I don't often put a space in my own pages. I even tend to\n>avoid it.\n\nI hope you do not serve it as text/html - can you please correct the\ndocument.\n\n>As you said it's not an error and \"The value of the xml:lang attribute\n>takes precedence.\" It's again the choice of the user.\n\nIf serving it as text/html - the author does not have such a choice.\n\n>There's no such thing as \"Appendix C compliance\". It's a strong and\n>wrong abuse of words for the meaning of the spec.\n\nSo what would you suggest I use to describe following the rules of the\nprofile of XHTML defined in Appendix C that can be used if serving the\ncontent as text/html - because that's much too much of a mouthful.  Appendix\nC compliance appears to be well understood even if not strictly accurate.\n\n>> This is not allowed under Appendix C. which requires that xml:lang and\n>> lang be duplicated.\n>\n>Appendix C doesn't require. The section is informative.\n\n\"RFC 2854 and Section 5.1 of the XHTML 1.0 specification require that\nxml:lang and lang be duplicated if serving the document as text/html?\"\n\nIs that acceptable wording?\n\n> I don't understand this comment\n\nIt seems quite clear, in HTML4.01 script is defined as CDATA, therefore\n<!-- --> does not denote a comment, in XHTML 1.0 it's defined as PCDATA\ntherefore <!-- --> defines a comment.  This is a change of semantics of an\notherwise equivalent document\n\n>> Enough of the errors, although they need fixing before the rest of the\n>\n>not so many errors finally.\n\nI don't think any of them have been refuted, just my language needed\nclarification.\n\n>The benefits are the ones listed all along the article for people who\n>need it. The points of the article is certainly to not make the switch\n>a requirement, but just a choice.\n\nI'm sorry I didn't see any - and the document does not make it clear that\nthere is a choice, there's a distinct bias towards XHTML.\n\n> Nobody is bad because they\n>still use HTML 4.01. Both solutions are perfectly usable.\n\nCould you please clarify the document to make this clear, it does not make\nthis clear currently.\n\n>A detailed warning analysis of the Markup validator, it would be nice\n>to do. As you know, Jim, Markup validator is made by volunteers like\n>Terje, Nick, Bjoern, and I'm pretty sur such a detail analysis for a\n>future warning mode would be very helpful. Giving your knowledge and\n>your strictness on the HTML specifications, it would be a valuable work\n>for the Web community.\n\nCertainly unfortunately my programming skills are not appropriate to develop\nPerl or C code that the validator is using, my current knowledge is in\njavascript, and here, I can only offer the validator the skills I have, I\nalso test the beta version of the validator, if you look at the beta version\nof the validator you will javascript I have contributed aswell as the\nbookmarklet at http://validator.w3.org/favelets.html.  If I could help more\nI would gladly do it, unfortunately learning Perl is not an option, but any\nother javascript enhancements or bookmarklets just put in a request I'll\ngladly do them.   In any case it's debateable if the Markup validator is the\nright place for this, Certainly Jukka Korpela and Alan would be anti such\nbehaviour, I'm not sure, I'd rather see a seperate tool, but can appreciate\nthat being within the validator would be useful.\n\nReally though unfortunately all I can offer the validator is cheerleading\nsupport to Terje and Nick in IRC.\n\n>Yes it's a problem of the specification now. Appendix C is not\n>normative.\n\nYet if we want to serve it as text/html (which it seems the W3 does want)\nthen Appendix C is required, it may be not be normative to  XHTML but you\ncertainly have to follow it for text/html.\n\nIf the article is not intended to be read with reference to Appendix C.\nThen I think this needs to made clear, as long as you make it clear the\ndiscussion is limited to xhtml served as \"application/xhtml+xml\" then the\narticle is extremely good.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Hi everyone,\n\nThis month, the WaSP asks the W3C: Which MIME type should XHTML be\nserved with?\n\nThe answer? You'll have to peek at:\nhttp://www.webstandards.org/learn/askw3c/sep2003.html\n\n\nMany thanks to Dominique, Olivier and Karl.\n\nIf you have further questions or points to discuss, don't hesitate to\nwrite to this list on the issue :)\n\nbest regards,\n-steph\n\n-- \n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "\"steph\" <sniffles@unadorned.org>\n> This month, the WaSP asks the W3C: Which MIME type should XHTML be\n> served with?\n>\n> The answer? You'll have to peek at:\n> http://www.webstandards.org/learn/askw3c/sep2003.html\n\nIt says\n\n\"In serving your XHTML document as text/xml you may run into issues with\ncharacter sets because the reuls which apply to text/* MIME types are more\ncomplex than those for application/*.\"\n\nYet fails to note that exactly the same issue applies to text/html other\nthan citing Appendix C.\n\nAppendix C says:\n\n\"If this is not possible, a document that wants to set its character\nencoding explicitly must include both the XML declaration an encoding\ndeclaration and a meta http-equiv statement (e.g., <meta\nhttp-equiv=\"Content-type\" content=\"text/html; charset=EUC-JP\" />)\"\n\nWhich seems to allow for the document to override the charset from the HTTP\nlevel (which if not specified explicity _is_ iso-8859-1 AIUI, if we are not\nallowed to do this with text/xml which is what the answer is presumably\nsaying with the \"much caution on the charset issue\".  Why are we allowed to\ndo it with text/html which has identical defaults?\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "\"steph\" <sniffles@unadorned.org>\n> This month, the WaSP asks the W3C: Which MIME type should XHTML be\n> served with?\n>\n> The answer? You'll have to peek at:\n> http://www.webstandards.org/learn/askw3c/sep2003.html\n\nSays (wrt to app/xml and text/xml)\n\n\"It is also important to note that for either of these MIME types, Internet\nExplorer will display the source code instead of correctly interpreting it\nas XHTML . \"\n\nIt suggests that IE is performing incorrectly in this, could I have a source\nfor this behaviour being incorrect, AIUI there is no requirement for\ndocuments with an XML mime-type be rendered in a particular manner.  You may\nsay that IE's behaviour is not desired in this case, but I cannot see\nanything that says it is incorrect, could you point out the relevant spec.\n\nIE makes no claims to support XHTML, so even if it was required for an XHTML\nconforming browser to render XHTML elements when served as */xml, there can\nbe no such requirements on IE, which only renders XHTML as tag-soup HTML, it\nis an html user-agent.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: SWADE related conference",
            "content": "Libby Miller <Libby.Miller@bristol.ac.uk> writes:\n\n> I've compiled a list of related conferences for planning purposes. At\n> the moment they're available as an RSS 1.0 +events channel, though maybe\n> HTML would have been better - when I have a sec I'll do an xslt\n> stylesheet that converts RSS to html.\n\nBert has written a CSS stylesheet for RSS files. That might do what you need\n\nhttp://www.w3.org/2000/08/w3c-synd/style.css\n\nMax.\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Le jeu 04/09/2003 ? 17:44, Jim Ley a ?crit :\n> \"It is also important to note that for either of these MIME types, Internet\n> Explorer will display the source code instead of correctly interpreting it\n> as XHTML . \"\n>\n> It suggests that IE is performing incorrectly in this\n\nYou're right, this is misleading - we'll remove the word 'correctly'.\n(note that even though IE doesn't do anything bad by displaying the code\nrather than interpreting it, life would be so much simpler if IE did the\n\"\"\"right\"\"\" thing).\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "\"steph\" <sniffles@unadorned.org>\n> The answer? You'll have to peek at:\n> http://www.webstandards.org/learn/askw3c/sep2003.html\n\nIt's an interesting article, and many thanks to the W3 team guys for doing\nthis, but it's a rather strange choice of question, as you've not answered\n\"Why author XHTML?\",   which mime-type is indeed a problem for many, however\nuntil you've established why we want to author in a way which gives us\n\"syntactic tricks which allows an XHTML document to be understood by most\nHTML browsers.\"  I don't see the value of the question,  to me HTML 4.01\nallows us to be accessed by not _most HTML browsers_  but all.\n\nThe article also says \"using content negotiation ... you can actually serve\nyour XHTML 1.0 as ...\"   which gives implicit support for this method, yet\nfails to mention the superior method of actually serving HTML as text/html\nunder content negotiation.  Translation from XHTML 1.0 to HTML 4.01 is a\nmachine process, there is no sensible reason to do content-negotiation and\nserve the same document with different mime-types, the document should\nreflect this and recommend different documents for the different mime-types.\n\nProper content-negotiation also allows you to use XHTML 1.1 rather than a\nstrange subset of 1.0 that has difficult QA (are there any tools which can\nhelp with Appendix C conformance?).\n\nMy question for the W3C is \"Why author XHTML? and why serve XHTML as\ntext/html ?\"\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "> My question for the W3C is \"Why author XHTML? and why serve XHTML as\n> text/html ?\"\n\nIs that a question you would like to see discussed here or a question\nyou would like to see treated in another 'WaSP Asks the W3C' article?\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Dom wrote:\n>> My question for the W3C is \"Why author XHTML? and why serve XHTML as\n>> text/html ?\"\n>\n>Is that a question you would like to see discussed here or a question\n>you would like to see treated in another 'WaSP Asks the W3C' article?\n\nEither would be good, I'd just like to see it addressed really,  as I've yet\nto see anywhere address it, and it seems to be a common problem:\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Dom wrote:\n>> My question for the W3C is \"Why author XHTML? and why serve XHTML as\n>> text/html ?\"\n>\n>Is that a question you would like to see discussed here or a question\n>you would like to see treated in another 'WaSP Asks the W3C' article?\n\nEither would be good, I'd just like to see it addressed really,  as I've yet\nto see anywhere address it, and it seems to be a common problem:\n\n<URL:\nhttp://groups.google.com/groups?selm=sCl5b.1501%248_5.331665%40newsfep2-gui.server.ntli.net >\n\nWhich contains\n\n|But my impression is that no one has\n|posted the killer response to \"what is the advantage to the developer of\n|bog-standard web sites in switching to XHTML?\")\n\nand it would be good to point people at the argument - I of course need\nconvincing too, but I may just be a luddite in this respect.\n\nJim.\n\n(Sorry about partial post, my incompetence)\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Jim Ley wrote:\n\n> Dom wrote:\n> \n>>>My question for the W3C is \"Why author XHTML? and why serve XHTML as\n>>>text/html ?\"\n>>\n>>Is that a question you would like to see discussed here or a question\n>>you would like to see treated in another 'WaSP Asks the W3C' article?\n> \n> \n> Either would be good, I'd just like to see it addressed really,  as I've yet\n> to see anywhere address it, and it seems to be a common problem:\n\nI second Jim's suggestion - there are a lot of myths and misconceptions\nabout XHTML floating around (I know I've been caught out by them often\nenough). Probably as a \"WaSP asks the W3C\" article would be best, since\nit gives me one point of reference to something more concrete than \"just\nan archived mailing list\" post.\n\nThe myths I see often are (in comparison to HTML)\n* XHTML is more accessible\n* XHTML is easier\n* XHTML is better supported in browsers\n* XHTML separates content and presentation\n* XHTML can be parsed with standard parsers\n\n From my personal view, I use XHTML purely for my benefit - I want to\nexperiment and play around with XML tools (not just solely for XHTML),\nbut its a useful source of data if I already have XML-type information\nin existence when I get to the point of writing something interesting.\nApart from that I don't see anything compelling for using XHTML over\nHTML4.01 Strict which benefits my readership.\n\n\nThanks,\nMike\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "> I second Jim's suggestion - there are a lot of myths and misconceptions\n> about XHTML floating around (I know I've been caught out by them often\n> enough). Probably as a \"WaSP asks the W3C\" article would be best, since\n> it gives me one point of reference to something more concrete than \"just\n> an archived mailing list\" post.\n\nRight. It would be much more interesting and more visible if it were \nanother \"WaSP asks W3C\" than just keep it in here as a mere mailing list \npost.\n\n-- \nDenis Boudreau [ CYBERcodeur ]\nCYBERcodeur.net - VDM - W3Qc - OpenWeb Group\nMail : denis@cybercodeur.net\nICQ : 115649885\nWEB : http://www.cybercodeur.net/\n       http://w3qc.cybercodeur.net/\n       http://www.openweb.eu.org/\n\n\"Coder moins, coder mieux !\"\n\n\n\n"
        },
        {
            "subject": "RE: The Return of &quot;WaSP Asks the W3C&quot",
            "content": ">Right. It would be much more interesting and more visible if it were \n>another \"WaSP asks W3C\" than just keep it in here as a mere \n>mailing list \n>post.\n\nTotally!  Listen, we're taking notes, I promise.  It was me who dropped the\nball on this project last year, and now that we have some terrific new WaSPs\non board, there's a real opportunity to take the resources we have and use\nthem.  I'm excited we're getting it going again and grateful for the\nfeedback.\n\nAlong with Steph and Holly and other WaSP members, we're putting together a\nlist of questions that we will then fashion into future articles.  Your\ninput is necessary!  So these are very helpful comments.\n\nIf you have specific questions that you'd like to see addressed, don't\nhesitate to let me know--not sure if this list is the right place to ask\nthem or not--but either way, we're creating that list and will be using it\nas a guideline for all future WaSP Asks editions.\n\nThanks!\nMolly :)\nMolly E. Holzschlag\nauthor / instructor / web designer\nhttp://www.molly.com/\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Molly E. Holzschlag wrote:\n\n>>Right. It would be much more interesting and more visible if it were \n>>another \"WaSP asks W3C\" than just keep it in here as a mere \n>>mailing list post.\n\n> Totally!  Listen, we're taking notes, I promise.  It was me who dropped the\n> ball on this project last year, and now that we have some terrific new WaSPs\n> on board, there's a real opportunity to take the resources we have and use\n> them.  I'm excited we're getting it going again and grateful for the\n> feedback.\n> \n> Along with Steph and Holly and other WaSP members, we're putting together a\n> list of questions that we will then fashion into future articles.  Your\n> input is necessary!  So these are very helpful comments.\n> \n> If you have specific questions that you'd like to see addressed, don't\n> hesitate to let me know--not sure if this list is the right place to ask\n> them or not--but either way, we're creating that list and will be using it\n> as a guideline for all future WaSP Asks editions.\n\nCool, these are all great news as the WaSP asks W3C format is extremely \nimportant in terms of vision and credibility. Is there any way we could \nsee that list you mentionned to see what's on it already ? That way, we \nwould know what to ask for.\n\nRegards,\n\n-- \nDenis Boudreau [ CYBERcodeur ]\nCYBERcodeur.net - VDM - W3Qc - OpenWeb Group\nMail : denis@cybercodeur.net\nICQ : 115649885\nWEB : http://www.cybercodeur.net/\n       http://w3qc.cybercodeur.net/\n       http://www.openweb.eu.org/\n\n\"Coder moins, coder mieux !\"\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "Hi folks,\n\nsorry for the delay in getting back to this.\n\nA rough proposal:\n\nWe hold the international workshop as two sessions at DC-2002:\nAn introduction to SWAD-E. A brief overview of what we hope to achieve is\ngoing to be presented as part of a plenary talk by Eric Miller of the\nSemantic Web Activity at W3C (he is going to be talking about the Semantic\nWeb at W3C in general, as I understand it).\n\nIn addition we have a short session (1 or 2 hours) providing a slightly more\nin-depth overview of the project. My hope for this is that we will present\nthe work we are doing, our goals for the different areas of work, the\npartners in the project, etc. I would like as many of the partners as\npossible to be presenting work, so we will need to discuss how to organise\nthis and still have a reasonable amount of time for discussion of how this\nfits into the wider context of semantic web work in europe and\ninternationally, dublin core, etc.\n\nAnd we have a session of perhaps 6 hours which is a technical work session. A\nproposed topic is schema interoperability - fitting with both the Semweb and\nDublin Core themes. Dan Brickley will give some more detail about this, but\nwe need to respond very quickly to the Dublin Core folks if we would like to\ngo ahead with this.\n\nI am hoping to have enough answers from people by monday afternoon UK time to\nbe able to pass on a sense that we would like to go ahead with this (or\nalternative proposals if people think this is not the way to go). It would be\nuseful to know how many of the partners would (probably) be able to attend\nand present.\n\nAgain, I apologise for the short time-scale. I will post a page on the site\ntomorrow with a bit more detail.\n\nCheers\n\nCharles\n\nOn Mon, 1 Jul 2002, Charles McCathieNevile wrote:\n\n>Sorry, URI for dublin core conference: http://www.bncf.net/dc2002/\n>\n>Charles\n>\n>On Mon, 1 Jul 2002, Charles McCathieNevile wrote:\n>\n>  Hi folks,\n>\n>  How do people feel about holding the international workshop in conjunction\n>  with the Dublin Core conference in Florence in October, and holding a\n>  workshop at HP as discussed as our other required developer workshop in that\n>  period?\n>\n>  The International workshop should be a little more of a general public\n>  introduction to the project than a normal developer workshop, although it\n>  should also have a technical focus of some kind, and the Dublin Core\n>  conference seems more appropriate for that than a single-topic workshop based\n>  on the fact that we potentially have members of the WebOnt working group\n>  available.\n>\n>\n\n-- \nCharles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\nW3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38 78 22\nLocation: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Molly E. Holzschlag wrote:\n\n> If you have specific questions that you'd like to see addressed, don't\n> hesitate to let me know--not sure if this list is the right place to ask\n> them or not--but either way, we're creating that list and will be using it\n> as a guideline for all future WaSP Asks editions.\n\nOh, and while we're on the subject, wouldn't it be time the WaSP had \nit's own mailing list we could subscribe to ? It would be great to \nfollow up on some of the stuff the coalition is up to, get insider \ninformation and stuff like that :)\n\n-- \nDenis Boudreau [ CYBERcodeur ]\nCYBERcodeur.net - VDM - W3Qc - OpenWeb Group\nMail : denis@cybercodeur.net\nICQ : 115649885\nWEB : http://www.cybercodeur.net/\n       http://w3qc.cybercodeur.net/\n       http://www.openweb.eu.org/\n\n\"Coder moins, coder mieux !\"\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Jim Ley wrote:\n\n> this, but it's a rather strange choice of question, as you've not answered\n> \"Why author XHTML?\"\n\nIf XHTML is sent as application/xhtml+xml then there are definitely good \nreasons such as mixing namespaces to author using XHTML.\n\nIf XHTML is sent as text/html then, in my opinion, there is no reason to \nauthor XHTML and indeed there are reasons not to do so. Sending XHTML \nthrough the HTML parser does not provide any benefit (other than \n\"looking cool\") and will lead to yet another generation of authors who \nlearn bad habits and define the \"XHTML standard\" as whatever IE does.\n\nTrust me. Been there. Done that. Mmmm Kay?\n\n/bc\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "* steph wrote:\n>The answer? You'll have to peek at:\n>http://www.webstandards.org/learn/askw3c/sep2003.html\n\nIf the document is supposed to say anything about text/xml, it should\nsay that people should never ever use that type. It is by the way not\ncorrect that the rules for text/xml are more complex than those for\napplication/xml or application/xhtml+xml with respect to character\nencoding, it the other way round, the rules for application/xml are more\ncomplex as with text/xml you will never need to look at the content\nwhile you have to for application/xml and derived types.\n\nThe document seems to identify tag soup as something bad. I would agree\nin theory, but as a matter of fact, XHTML only works in some browsers\nbecause they interprete the document as tag soup. XHTML documents break\nin conforming HTML user agents. So without tag soup parsing, no XHTML.\n\nI disagree that application/xml is an alternate media type for XHTML\ndocuments.\n\n  * XHTML user agents are not required to support this MIME type (of\n    course, they are neither required to support text/html or\n    application/xhtml+xml ...)\n\n  * MIME type sniffing is considered bad practise, you can read long\n    threads about it on www-tag where people complain that IE treats\n    text/plain documents sometimes as text/html documents. If you\n    deliver XHTML documents as application/xml you would either not\n    get the results you want or you rely on MIME type sniffing which\n    is a bad thing.\n\n  * Even if MIME type sniffing is bad practise for some types and good\n    practise for other types, it is undefined how to determine whether\n    an application/xml document should be treated as some sort of\n    application/xhtml+xml. Appendix A.1 of RFC 3023 explicitly warns\n    not to do that or worse rely on specific behaivour in this regard.\n\n  * And if it was defined you would get results you do not desire in\n    some situations, i.e., if you do not want a user agent to apply\n    any kind of special processing for known document types.\n\n  * And even if this weren't issues, fragment identifiers are undefined\n    for application/xml while they are defined for application/xhtml+xml\n    you could thus get all sorts of unexpected results like fragment\n    identifiers do not work or work differently than you expect.\n\nHence, for theoretical and practical matters, the document should say\nthat application/xml should not be used for XHTML documents.\n\nI find it quite troublesome to refer to \"content negotiation\" in this\ndocument as the \"solution\" does not serve different content (which\ncontent negotiation is about) and the proposed solution for the Apache\nweb server, i.e. using \"AddType application/xhtml+xml;qs=0.8\" would\ncause the web server to create an invalid HTTP response as it would send\nout the 'qs' parameter which is not allowed for application/xhtml+xml.\n\nIt is also noteworthy that browser support for XHTML is, well, not\nperfect. Some browser versions claiming support for XHTML do not support\nthe application/xhtml+xml MIME types, some which claim to support the\nMIME type fail to recognize named character references such as &ouml;\nproperly (some versions of Mozilla, Opera, ...) or they fail to ignore\ncomments such as\n\n  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n      \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n  <html xmlns=\"http://www.w3.org/1999/xhtml\">\n  <head>\n    <title></title>\n    <style type='text/css'><!--\n      p { color: red }\n    --></style>\n  </head>\n  <body>\n    <p>This shall not be red</p>\n  </body>\n  </html>\n\nAmaya 8.0 for example, which leads to another point, it should be more\nexplicit that you are likely to get unpleasant surprises if you deliver\nXHTML as application/xhtml+xml as many documents claiming to be XHTML\ndocuments rely on \"features\" that would not if user agents applied XHTML\nrules.\n\n\n\n"
        },
        {
            "subject": "RE: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "...\n> It is also noteworthy that browser support for XHTML is, \n> well, not perfect. ...\n\nFor info, use of XHTML can cause problems with other types of user\nagents.  For example, I know one indexer designed to index Dublin Core\nmetadata embedded in <META> tags which won't work with <meta ... />.  \n\nThe indexer in question is the indexing tool bundled in with the\nMicrosoft SiteServer software.  Note that I don't think this can be\nclassed as a bug in the indexer, as the software wasn't designed for use\nwith XHTML.\n\nHas any work been done on problems with user agents other than browsers\nwith XHTML?\n\nBrian Kelly\n\n---------------------------------------\nBrian Kelly\nUK Web Focus\nUKOLN\nUniversity of Bath \nBATH\nUK\nBA2 7AY\nEmail: B.Kelly@ukoln.ac.uk\nWeb: http://www.ukoln.ac.uk/\nPhone: 01225 383943\nFOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf\nFor info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/> \n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Le ven 05/09/2003 ? 06:06, Bjoern Hoehrmann a ?crit :\n> The document seems to identify tag soup as something bad. I would agree\n> in theory, but as a matter of fact, XHTML only works in some browsers\n> because they interprete the document as tag soup. XHTML documents break\n> in conforming HTML user agents. So without tag soup parsing, no XHTML.\n\n... *in some browsers*! Besides, there is a huge difference between any\nrandom semantic-less tag soup and a well-defined set of contraints that\nare known to work with most HTML user agents.\n\n> I disagree that application/xml is an alternate media type for XHTML\n> documents.\n> \n>   * XHTML user agents are not required to support this MIME type (of\n>     course, they are neither required to support text/html or\n>     application/xhtml+xml ...)\n\nThe fact that they aren't required (which they should be, but that's\nanother matter) to support this MIME-type doesn't prevent them to\nactually do so.\n \n>   * MIME type sniffing is considered bad practise, you can read long\n>     threads about it on www-tag where people complain that IE treats\n>     text/plain documents sometimes as text/html documents. If you\n>     deliver XHTML documents as application/xml you would either not\n>     get the results you want or you rely on MIME type sniffing which\n>     is a bad thing.\n\nMIME Type sniffing consists in overriding the decision that you would\nhave taken by looking solely at the MIME-type by the decision you take\nby looking at the content. Interpreting an XHTML document served as\napplication/xml as XHTML is NOT MIME type sniffing, given that the\ndecision of handling the document as XHTML only completes the decision\nof handling it as XML.\n\n>   * Even if MIME type sniffing is bad practise for some types and good\n>     practise for other types, it is undefined how to determine whether\n>     an application/xml document should be treated as some sort of\n>     application/xhtml+xml.\n\nIndeed, there is no official XML processing model, although there is\nbroadly shared interpretation that a \"generic\" XML processor could rely\non the namespace of the root element to determine what XML language is\nconcerned.\n\n> Appendix A.1 of RFC 3023 explicitly warns\n>     not to do that or worse rely on specific behaivour in this regard.\n\nErr? I just read the appendix and don't find anything that would suggest\nthis?\n\n>   * And if it was defined you would get results you do not desire in\n>     some situations, i.e., if you do not want a user agent to apply\n>     any kind of special processing for known document types.\n\nWell, given that the processing model for a generic XML processor isn't\ndefined, it's up to the user agent to do the right thing, which is\nprobably something along:\n- if you're a browser, processing it smartly is better than displaying\nthe code\n- if you're a user agent whose usage wouldn't benefit from processing\nthe document as XHTML, don't do it\n\nNeither breaks conformance, even though neither behavior is required.\nResults \"you\" do not desire is a bit unclear; you get the results that\nyou desire, provided you use the user agents that meets your desires...\n\n>   * And even if this weren't issues, fragment identifiers are undefined\n>     for application/xml while they are defined for application/xhtml+xml\n>     you could thus get all sorts of unexpected results like fragment\n>     identifiers do not work or work differently than you expect.\n\nI probably won't learn you anything by telling you that XPointer (the\nto-be-RFCized fragment identifier specification for XML) is backwards\ncompatible with the fragment identifiers mechanism currently defined by\nXHTML (and that XHTML MIME Type RFC explicitely makes reference to it).\n\n> Hence, for theoretical and practical matters, the document should say\n> that application/xml should not be used for XHTML documents.\n\nNote that the XHTML Media types note says:\n\"Any XHTML Family document MAY be served as 'application/xml'.\"\nhttp://www.w3.org/TR/2002/NOTE-xhtml-media-types-20020801\n\n> I find it quite troublesome to refer to \"content negotiation\" in this\n> document as the \"solution\" does not serve different content (which\n> content negotiation is about) \n\nWell, it does; the MIME-Type is not dissociable from the content it\nmarks.\n\n> and the proposed solution for the Apache\n> web server, i.e. using \"AddType application/xhtml+xml;qs=0.8\" would\n> cause the web server to create an invalid HTTP response as it would send\n> out the 'qs' parameter which is not allowed for application/xhtml+xml.\n\nI don't why it would be invalid:\n\"Parameters may be required by their\n   defining media type or subtype or they may be optional.  MIME\n   implementations must also ignore any parameters whose names they do\n   not recognize.\"\nhttp://www.ietf.org/rfc/rfc2046\n\nAlthough I dislike the idea that Apache sends this parameter solely used\nfor internal processing, it's not invalid, merely ugly.\n\n> It is also noteworthy that browser support for XHTML is, well, not\n> perfect.\n\nSure, but let's give time to time... I don't think many technologies\nhave ever been implemented perfectly, and even less so during the first\nyears of their deployment. \n\n(FWIW, I'm not really sure this technical/theoretical discussion belongs\nto public-evangelist@w3.org, it would probably be more appropriate in\nwww-html or www-qa for the conformance topics)\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Dominique Haza?l-Massieux wrote:\n> Le ven 05/09/2003 ? 06:06, Bjoern Hoehrmann a ?crit :\n<snip/>\n> (FWIW, I'm not really sure this technical/theoretical discussion belongs\n> to public-evangelist@w3.org, it would probably be more appropriate in\n> www-html or www-qa for the conformance topics)\n\nThere is some validity to this comment, however evangelists and other \ninterested parties should benefit from at least a glazed-eye \nunderstanding of what is at issue regarding the things they are \nevangelizing. A discussion such as this -- although likely more well \ninformed than most -- pre-figures the kind bush-whacking talk that takes \nplace in meetings where evangelists dip their toes (and often withdraw \nquickly, scalded.)\n\nMy take away from this discussion so far is the HTML 4.xx Strict is the \nmost viable place in which to invest evangelical effort. XHTML is simply \ntoo fraught with complexity, controversy and immaturity. I'll be \ngratified to read the \"Why should I server XHTML?\" response; the sooner \nthe better as far as I'm concerned. Let's get to it!\n\n            ...edN\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "\"ed nixon\" <ed.nixon@LynnParkPlace.org>\n>Dominique Haza?l-Massieux wrote:\n>> Le ven 05/09/2003 ? 06:06, Bjoern Hoehrmann a ?crit :\n><snip/>\n>> (FWIW, I'm not really sure this technical/theoretical discussion belongs\n>> to public-evangelist@w3.org, it would probably be more appropriate in\n>> www-html or www-qa for the conformance topics)\n>\n>A discussion such as this -- although likely more well\n>informed than most -- pre-figures the kind bush-whacking talk that takes\n>place in meetings where evangelists dip their toes (and often withdraw\n>quickly, scalded.)\n\nIf an evangelist can't answer the question, \"why are you recommending using\nXHTML? I heard it's fraught with problems, about mime-types, encodings etc.\"\nthen they're likely to be discredited all around, it may not be the right\nplace for the discussion, but it is likely that an evangelist is going to\ncome with people like me, who's seen evangelism discredit XHTML repeatedly\n(for example many sites are sending out XHTML as app/xhtml when the user\nagent specifically announces they do not understand it, and that's down to\nthem evangelising content negotiation but failing to actually understand how\nto do it.)\n\nSo if the suggestion is that evangelising XHTML is a \"good thing\", then\npeople need to be able to address the issues me and Bjoern have, this isn't\nthe place to work out an answer to the question, but if these problems are\nsolved (and we shouldn't be even considering evangelising them until they\nare) then we should be able to be pointed to the previous discussion and\nconclusions, there should be no need to discuss these things.\n\n>My take away from this discussion so far is the HTML 4.xx Strict is the\n>most viable place in which to invest evangelical effort.\n\nHTML 4.01 strict for HTML user agents absolutely, there's no advantage that\nI've seen for sending XHTML as text/html, when real world mixed namespace\nuser agents exist then we can start looking at XHTML+etc.  but even then I\nfeel we're missing a solution for server negotiation of what namespaces a\nuser agent will support (there's no point sending XHTML+MathML, to a UA that\ngroks XHTML+SVG+FOOL etc.)\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "* Dominique Haza?l-Massieux wrote:\n>Indeed, there is no official XML processing model, although there is\n>broadly shared interpretation that a \"generic\" XML processor could rely\n>on the namespace of the root element to determine what XML language is\n>concerned.\n\nEither there is a specification that ensures such behaivour or there is\nno such specification. If there is, application/xml can be considered an\nalternate MIME type for XHTML documents, if there is not it cannot be\nconsidered an alternate.\n\n>> Appendix A.1 of RFC 3023 explicitly warns\n>>     not to do that or worse rely on specific behaivour in this regard.\n>\n>Err? I just read the appendix and don't find anything that would suggest\n>this?\n\n  ...\n  Since MIME dispatchers work off of the MIME type, use of text/xml or\n  application/xml to label discrete media types will hinder correct\n  dispatching and general interoperability.\n  ...\n\nSomething is not interoperable just because it works in some browsers.\nIt seems perfectly reasonable for a search engine robot to skip all\napplication/xml documents when it only supports HTML/XHTML.\n\n>Neither breaks conformance, even though neither behavior is required.\n>Results \"you\" do not desire is a bit unclear; you get the results that\n>you desire, provided you use the user agents that meets your desires...\n\nAs a content provider, I care about user agents other people use and I\ndo not want that my content causes unexpected behaivour which I would\nrisk when relying on undefined behaivours.\n\n>I probably won't learn you anything by telling you that XPointer (the\n>to-be-RFCized fragment identifier specification for XML) is backwards\n>compatible with the fragment identifiers mechanism currently defined by\n>XHTML (and that XHTML MIME Type RFC explicitely makes reference to it).\n\nIn response to my last call comments, yes. However, as long as RFC 3023\ndoes not get updated, interpretation of fragment identifiers for\napplication/xml is undefined and it is thus not reliable to use this\ntype if fragment identifiers are involved.\n\n>Note that the XHTML Media types note says:\n>\"Any XHTML Family document MAY be served as 'application/xml'.\"\n>http://www.w3.org/TR/2002/NOTE-xhtml-media-types-20020801\n\nAs much as any XHTML Family document may be served as 'text/plain' or\n'application/octet-stream'.\n\n>> and the proposed solution for the Apache\n>> web server, i.e. using \"AddType application/xhtml+xml;qs=0.8\" would\n>> cause the web server to create an invalid HTTP response as it would send\n>> out the 'qs' parameter which is not allowed for application/xhtml+xml.\n>\n>I don't why it would be invalid:\n\nBecause RFC 3236 does not allow it.\n\n\n\n"
        },
        {
            "subject": "[FYI] new QAIG homepag",
            "content": "Greetings.\n\nFollowing the creation of the QAIG contributions guidelines, the QAIG \nnow sports a new homepage focusing on participation to the various \nactivities of the Interest Group. Certainly worth a visit if you think \nthe IG is all about discussion on these lists but would like to \nparticipate more, or differently.\n\n<http://www.w3.org/QA/IG/>\n\nCheers, olivier.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "I use XHTML 1.0 exclusively for my web pages these days.  I serve them\nas text/html and follow the compatability suggestions in App C of the\nxhtml spec.  I try to serve pages that will trigger standards-mode in\nrecent browsers**, but I do currently include some fallbacks for older\nbrowsers, so I use xhtml transitional.\n\nThese are a few key practical reasons for my choice of xhtml:\n\n\n[1]  I create all my xml and html documents in the same XML editor\n(Xmetal).  This editor won't allow me to create xhtml that is not\nwell-formed or valid xml, so I don't really have to use the W3C\nvalidator, nor do I get into a cyclical debugging process of editing,\nvalidating, correcting, validating, ....  For example, my editor won't\neven let me save the document if I have duplicate ids, or I'm missing\nrequired attributes such as alt on <img>.\n\nI find that saves time and helps me avoid tag soup and browser specific\nextensions, even when I'm in a hurry.\n\n\n\n[2] I regularly find myself wanting to process files using XSLT or\nPython/Perl etc *some time after* I originally wrote them.  This is no\nproblem with xhtml pages.  \n\nFor example, I just improved my calendar page (team only). I figured out\nhow to extract information in XML from my calendaring system, then used\nxslt to merge that with an xhtml template that contained all the rest of\nmy contact information.  If I had written the original page in html,\nthis would not have been so easy.  I've had these afterthoughts about\nhow to improve pages in conjunction with other xml data several times,\nbut since its all XML code I have no problem processing and integrating\nthe relevant files.\n\n\n\n[3] I figure that if we continue to use HTML then browser developers\nwill have less incentive to implement xhtml properly.  I'd eventually\nlike to be able to use xhtml strict served as application/xhtml+xml, but\nwhy would browser developers feel motivated to enable that if everyone\njust continues to use html?\n\n\n\n[4] Jeffrey Zeldman posits that its easier to author repurposable text\n(eg. to be used on browsers but also mobile phones, pda's and other\nspecialised user agents) if xhtml is used.  I don't know if this is true\n(but I don't see any harm in using xhtml, just in case).\n\n\n\n[5] From a practical, rather than theoretical, viewpoint I don't really\nsee any reason why one *shouldn't* use xhtml at the moment, even served\nas text/html.  Given the positive benefits mentioned above, this seems\nas good a reason as any to use xhtml, given that this is the latest\ntechnology.\n\n\nHope that's of some help,\nRI\n\n\n**  There is one tweak I have to make.  If I want my pages to trigger\nstandards-compliant mode in IE I have to remove the xml declaration\nbefore posting.  I do this with a very simple Python script and it\ncauses no real problem (though it would be nicer not to, if anyone from\nIE is listening!).\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "Seems like a reasonable proposal and I'm happy for it to go ahead.\nThe chances of us being able to send someone are low but not zero.\n\nDave\n\nCharles McCathieNevile wrote:\n> \n> Hi folks,\n> \n> sorry for the delay in getting back to this.\n> \n> A rough proposal:\n> \n> We hold the international workshop as two sessions at DC-2002:\n> An introduction to SWAD-E. A brief overview of what we hope to achieve is\n> going to be presented as part of a plenary talk by Eric Miller of the\n> Semantic Web Activity at W3C (he is going to be talking about the Semantic\n> Web at W3C in general, as I understand it).\n> \n> In addition we have a short session (1 or 2 hours) providing a slightly more\n> in-depth overview of the project. My hope for this is that we will present\n> the work we are doing, our goals for the different areas of work, the\n> partners in the project, etc. I would like as many of the partners as\n> possible to be presenting work, so we will need to discuss how to organise\n> this and still have a reasonable amount of time for discussion of how this\n> fits into the wider context of semantic web work in europe and\n> internationally, dublin core, etc.\n> \n> And we have a session of perhaps 6 hours which is a technical work session. A\n> proposed topic is schema interoperability - fitting with both the Semweb and\n> Dublin Core themes. Dan Brickley will give some more detail about this, but\n> we need to respond very quickly to the Dublin Core folks if we would like to\n> go ahead with this.\n> \n> I am hoping to have enough answers from people by monday afternoon UK time to\n> be able to pass on a sense that we would like to go ahead with this (or\n> alternative proposals if people think this is not the way to go). It would be\n> useful to know how many of the partners would (probably) be able to attend\n> and present.\n> \n> Again, I apologise for the short time-scale. I will post a page on the site\n> tomorrow with a bit more detail.\n> \n> Cheers\n> \n> Charles\n> \n> On Mon, 1 Jul 2002, Charles McCathieNevile wrote:\n> \n> >Sorry, URI for dublin core conference: http://www.bncf.net/dc2002/\n> >\n> >Charles\n> >\n> >On Mon, 1 Jul 2002, Charles McCathieNevile wrote:\n> >\n> >  Hi folks,\n> >\n> >  How do people feel about holding the international workshop in conjunction\n> >  with the Dublin Core conference in Florence in October, and holding a\n> >  workshop at HP as discussed as our other required developer workshop in that\n> >  period?\n> >\n> >  The International workshop should be a little more of a general public\n> >  introduction to the project than a normal developer workshop, although it\n> >  should also have a technical focus of some kind, and the Dublin Core\n> >  conference seems more appropriate for that than a single-topic workshop based\n> >  on the fact that we potentially have members of the WebOnt working group\n> >  available.\n> >\n> >\n> \n> --\n> Charles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\n> W3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38 78 22\n> Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n> (or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "\"Richard Ishida\" <ishida@w3.org>\n> I use XHTML 1.0 exclusively for my web pages these days.  I serve them\n> as text/html and follow the compatability suggestions in App C of the\n> xhtml spec.\n\nWhat QA tool do you use to ensure this, is it purely visual inspection, and\nhuman processing, or do you actually have tools that do it for you?\n\nThe majority of your reasons are about authoring, and there are good reasons\nfor authoring in a semantically rich XML format, however authoring and\npublishing are seperate activities.  For me XHTML doesn't meet my authoring\nneeds, it's semantically pretty empty, and applicable only to certain types\nof documents.  However even if it meets your authoring needs, that doesn't\nfollow that is how you should publish it to html user agents, conversion\nfrom XHTML or other XML formats is a simple mechanical process available\nfrom tools such as tidy, as part of your publishing process you can perform\nthis translation, so you get your authoring ease combined with serving\nappropriate content to all users (rather than content which is only\ncompatible with some html user agents)\n\n> [3] I figure that if we continue to use HTML then browser developers\n> will have less incentive to implement xhtml properly.  I'd eventually\n> like to be able to use xhtml strict served as application/xhtml+xml, but\n> why would browser developers feel motivated to enable that if everyone\n> just continues to use html?\n\nMy problem with this,  XHTML 2.0, it's a very different mark-up language,\nyet as far as I've seen the mime-type will still be application/xhtml+xml,\nthe current preponderance of invalid XHTML being served as text/html with\nthe intention that it will be changed to being served as\napplication/xhtml+xml is a problem for this, as soon as UA's start being\napplication/xhtml+xml user agents exist, people will change the mime-type\nand the UA manufacturers will have to start adding tag-soup parsing of it\ntoo.\n\nFor me, xhtml as text/html is a demonstration of how UA manufacturers can\nensure maximum future compatibility by parsing everything as tag-soup - it\nsupports tag-soup parsing, and far from being a transitional process leading\nto a more compliant world, it's rubber stamping the current tag-soup\nbehaviour.\n\nEncouraging application/xhtml+xml support will be done by serving\napplication/xhtml , not serving tag-soup, serving tag-soup encourages\ntag-soup!\n\n> **  There is one tweak I have to make.  If I want my pages to trigger\n> standards-compliant mode in IE I have to remove the xml declaration\n> before posting.\n\nI don't particularly understand this, as Appendix C clearly says that you\nshouldn't include an xml declaration in any case \"Be aware that processing\ninstructions are rendered on some user agents\" (due to a great many browsers\nactually rendering it, quite apart from those that change rendering modes\nbased on it)\n\nJim.\n\n\n\n"
        },
        {
            "subject": "RE: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Jim Ley\n> Sent: 22 September 2003 14:07\n> To: public-evangelist@w3.org\n> Subject: Re: The Return of \"WaSP Asks the W3C\"\n> \n> \n> \n> \"Richard Ishida\" <ishida@w3.org>\n> > I use XHTML 1.0 exclusively for my web pages these days.  I \n> serve them \n> > as text/html and follow the compatability suggestions in \n> App C of the \n> > xhtml spec.\n> \n> What QA tool do you use to ensure this, is it purely visual \n> inspection, and human processing, or do you actually have \n> tools that do it for you?\n> \n> The majority of your reasons are about authoring,  and there \n> are good reasons for authoring in a semantically rich XML \n> format, however authoring and publishing are seperate \n> activities.  For me XHTML doesn't meet my authoring needs, \n> it's semantically pretty empty, and applicable only to \n> certain types of documents.  However even if it meets your \n> authoring needs, that doesn't follow that is how you should \n> publish it to html user agents, conversion from XHTML or \n> other XML formats is a simple mechanical process available \n> from tools such as tidy, as part of your publishing process \n> you can perform this translation, so you get your authoring \n> ease combined with serving appropriate content to all users \n> (rather than content which is only compatible with some html \n> user agents)\n\nI guess I don't see why you should go to so much trouble.  If it's in\nxhtml for good reasons, as you mention, and if you can successfully\nserve it as xhtml, why change it to html?  (also see below)\n\n> \n> > [3] I figure that if we continue to use HTML then browser \n> developers \n> > will have less incentive to implement xhtml properly.  I'd \n> eventually \n> > like to be able to use xhtml strict served as \n> application/xhtml+xml, \n> > but why would browser developers feel motivated to enable that if \n> > everyone just continues to use html?\n> \n> My problem with this,  XHTML 2.0, it's a very different \n> mark-up language, yet as far as I've seen the mime-type will \n> still be application/xhtml+xml, the current preponderance of \n> invalid XHTML being served as text/html with the intention \n> that it will be changed to being served as \n> application/xhtml+xml is a problem for this, as soon as UA's \n> start being application/xhtml+xml user agents exist, people \n> will change the mime-type and the UA manufacturers will have \n> to start adding tag-soup parsing of it too.\n\nI don't think that the mime-type indicates what DTD to use.  So I'm not\nsure that this is a valid argument.\n\nNote also that I am not serving 'invalid XHTML'.  It is perfectly valid\nxhtml - and therefore well-formed xml too. Actually that's a key reason\nI'm using xhtml.  Its just that the browser handles it as if it were\nhtml.  My desire is to migrate to xhtml 1.0 served as\napplication/xhtml+xml when that is supported.  That should require no\nchange to my document code.  I'll probably only write new documents in\nxhtml 2.0 when that is eventually supported.\n\n\n> \n> For me, xhtml as text/html is a demonstration of how UA \n> manufacturers can ensure maximum future compatibility by \n> parsing everything as tag-soup - it supports tag-soup \n> parsing, and far from being a transitional process leading to \n> a more compliant world, it's rubber stamping the current \n> tag-soup behaviour.\n\nI think my definition of 'tag soup' may be different from yours.  For me\ntag soup is overlapping elements, documents that don't validate against\nthe DTD, use of browser-specific tags, use of presentational markup\ninstead of css, bloated code through use of many font tags, etc. \n\n\n> \n> Encouraging application/xhtml+xml support will be done by \n> serving application/xhtml , not serving tag-soup, serving \n> tag-soup encourages tag-soup!\n\nWell, I agree that serving application/xhtml+xml will encourage browser\ndevelopers more, but it won't make our pages very readable for large\nswathes of the population.  On the other hand, just staying with HTML\ndoesn't provide any incentive at all.  That's why I try to use xhtml to\nthe extent currently possible.\n\n\n> \n> > **  There is one tweak I have to make.  If I want my pages \n> to trigger \n> > standards-compliant mode in IE I have to remove the xml declaration \n> > before posting.\n> \n> I don't particularly understand this, as Appendix C clearly \n> says that you shouldn't include an xml declaration in any \n> case \"Be aware that processing instructions are rendered on \n> some user agents\" (due to a great many browsers actually \n> rendering it, quite apart from those that change rendering \n> modes based on it)\n\nWell, yes, this is another good reason.  \n\nFor my setup I find that I need an xml declaration in XMetal to ensure\nthat the file is read in correctly by the editor.  It can also be\nimportant for indicating the character encoding of xml files.  So I\npersonally tend to keep it at the top of my files until I decide to\nserve them as html.\n\n> \n> Jim.\n> \n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Richard Ishida wrote:\n\n> \n> \n> [4] Jeffrey Zeldman posits that its easier to author repurposable text\n> (eg. to be used on browsers but also mobile phones, pda's and other\n> specialised user agents) if xhtml is used.  I don't know if this is true\n> (but I don't see any harm in using xhtml, just in case).\n> \n\nI spent over two years contacting major web sites and web developers \naround the world trying to educate them about authoring according to the \nW3C Standards. I know from experience how they will respond to comments \nthat their sites work in Internet Explorer due to bugs in Internet \nExplorer and do not work in standards compliant browsers:\n\n\"It works in IE. Why doesn't your browser follow the standards set by IE?\"\n\nBesides non-standard script and invalid markup, examples which are still \nrampant on the web today include invalid SGML comments and inappropriate \nMIME types being reported by servers. I can show numerous examples in \nthe Mozilla Tech Evangelism project to show the inability or \nunwillingness of sites to author correct HTML or to even configure \nservers correctly.\n\nHTML is a lost cause, however XHTML still has a future as a useful, \nwell-defined markup language _unless_ you succeed in redefining support \nfor XHTML to be whatever IE supports.\n\nA perfect example of what is happening:\n\n<http://www.zeldman.com/>\n\nserved as text/html with doc type\n\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n     \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n\ncontains\n\n<style type=\"text/css\">\n<!--\n\n#secondarytop a:visited {\nfont-weight: normal;\nbackground: #c60;\ncolor: #fff;\ntext-decoration: none;\n}\n\nul.inny {\nmargin-top: 0;\nmargin-left: 0;\npadding-left: 0;\n}\n\n.inny li{\ndisplay: inline;\npadding-right: 6px;\npadding-left: 6px;\nborder-right: 1px solid #ccc;\n}\n\nli.first {\npadding-left: 0;\n}\n\nli.last {\nborder-right: none;\n}\n\n-->\n</style>\n\nwhich will be ignored by any browser that supports application/xhtml+xml \n  if the page is served as such.\n\nIf and when IE ever does support application/xhtml+xml then I will bet \ndimes to donuts that it will still apply these rules insteading of \nignoring them at it should.\n\nIf your goal is to allow the dominant, monopolist browser which will not \nreceive major updates to it's standards support for the next 2-4 years \n(if ever) to define XHTML as tag-soup HTML and destroy any browser that \nattempts to support the standards strictly, then your approach should work.\n\n/bc\n\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "From: \"Richard Ishida\" <ishida@w3.org>\n>[mailto:public-evangelist-request@w3.org] On Behalf Of Jim Ley\n>>(rather than content which is only compatible with some html\n>>user agents)\n>\n>I guess I don't see why you should go to so much trouble.  If it's in\n>xhtml for good reasons, as you mention, and if you can successfully\n>serve it as xhtml, why change it to html?  (also see below)\n\nBecause you can't \"successfully serve it as xhtml\" in all cases.  Appendix C\ntext/html content is only \"compatible with most HTML browsers\"  For me, most\nis not successfully serving it, consider WAI, a much more important\nrequirement than HTML validity for me - yet that requires things such as\n\"ensure that pages featuring new technologies transform gracefully\" and\n\"Provide information so that users may receive documents according to their\npreferences (e.g., language, content type, etc.)\"    by sending text/html\nyou are not really telling the truth about the content-type of your\ndocument, (See RFC 3236 for the correct one).\n\nThe W3 HTML WG has also published a note\nhttp://www.w3.org/TR/xhtml-media-types/ , where it says xhtml SHOULD be\nserved as application/xhtml+xml - I don't think \"I'm not willing to go to\nthe trouble\" is really an appropriate reason for ignoring W3 SHOULD's.\n\n>>as soon as UA's\n>>start being application/xhtml+xml user agents exist, people\n>>will change the mime-type and the UA manufacturers will have\n>>to start adding tag-soup parsing of it too.\n>\n>I don't think that the mime-type indicates what DTD to use.  So I'm not\n>sure that this is a valid argument.\n\nIndeed it doesn't, but if you serve XHTML 1.0, XHTML 1.1 and XHTML 2.0 all\nwith the same mime-type then future user agents will have to support all of\nthose, there being no current mechanism for the UA to express a preference\nfor a particular dialect of XHTML - given that XHTML content is almost\nalways invalid now (but people don't notice this as they only view it in\ntag-soup UA's) moving this content over will force those XHTML 2.0 UA's to\nsupport XHTML 1.0 tag-soup - or not render existing pages.  Not rendering\nexisting pages has not proven a good survival strategy in UA authoring.\n\nI see xhtml as text/html being a danger, it allows people to author invalid\nXHTML and see it render, most people don't seem to be equipped to author\nvalid documents, but if it renders, then they'll expect it to render in the\nnext version of a UA, or indeed all.\n\n>I think my definition of 'tag soup' may be different from yours.\n\nI think we can agree that XHTML 1.0 rendering in IE is down to the fact it\nhas a tag-soup parser, and not an SGML validating one.   I call XHTML in\ntext/html as tag-soup because of that, it being reliant on tag-soup parsers\nnot anything else.\n\n>For my setup I find that I need an xml declaration in XMetal to ensure\n>that the file is read in correctly by the editor.  It can also be\n>important for indicating the character encoding of xml files.\n\nHowever when deploying it as text/html you either have to set it in the\ncharset parameter or it's  ISO-8859-1,  you can't set it in the XML PI, it's\ntoo late, HTML's rules take precedence.  Practically this means you have to\nuse UTF-8 or UTF-16.  So I'm afraid that's not an argument I can accept.\n\n> So I\n>personally tend to keep it at the top of my files until I decide to\n>serve them as html.\n\nThat's good - and it just shows how having a publishing process can work\nwell - if you just extend your script to also do an XHTML->html conversion,\nit'll cost you a few moments now, but will save your clients a lot of\nhassle, and will mean you won't have to disregard the shoulds of the HTML\nWG.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "XHTML and UTF8 Re: The Return of &quot;WaSP Asks the W3C&quot",
            "content": "Le lundi, 22 sep 2003, ? 09:07 America/Montreal, Jim Ley a ?crit :\n>> **  There is one tweak I have to make.  If I want my pages to trigger\n>> standards-compliant mode in IE I have to remove the xml declaration\n>> before posting.\n>\n> I don't particularly understand this, as Appendix C clearly says that \n> you\n> shouldn't include an xml declaration in any case \"Be aware that \n> processing\n> instructions are rendered on some user agents\" (due to a great many \n> browsers\n> actually rendering it, quite apart from those that change rendering \n> modes\n> based on it)\n\nIf you encode your file in utf-8, you don't need the XML declaration, \nyour document will be correctly rendered, and it will be XML.\n\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "[SumsaultRT #212]  example of sending correct headers with Apache",
            "content": "Hello,\n\nI was just reading here about character encodings:\n\nhttp://www.w3.org/TR/xhtml1/#guidelines \n\nDown in section C.9, it states: \"the best approach is to ensure that the\nweb server provides the correct headers. \"\n\nI would like to do this, but I'm unsure of how to configure my Apache\nweb server to send the correct headers by default. Could someone post an\nexample of what the correct headers would be and/or an example of a\n\"correct\" Apache configuration for this?\n\nThanks!\n\nMark\n\n-- \n . . . . . . . . . . . . . . . . . . . . . . . . . . . \n   Mark Stosberg            Principal Developer  \n   mark@summersault.com     Summersault, LLC     \n   765-939-9301 ext 202     database driven websites\n . . . . . http://www.summersault.com/ . . . . . . . .\n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212]  example of sending correct headers with Apache",
            "content": "Le mer 24/09/2003 ? 17:51, Mark Stosberg a ?crit :\n> I was just reading here about character encodings:\n>\n> Down in section C.9, it states: \"the best approach is to ensure that the\n> web server provides the correct headers. \"\n> \n> I would like to do this, but I'm unsure of how to configure my Apache\n> web server to send the correct headers by default. Could someone post an\n> example of what the correct headers would be and/or an example of a\n> \"correct\" Apache configuration for this?\n\nProvided that all your xhtml files have a uniform extension (say .html)\nand a uniform encoding (say iso-8859-1), and provided that you serve\nthem as text/html (but this applies trivially to application/xhtml+xml),\nyou can add (or amend an existing entry) the following directive:\nAddType text/html;charset=iso-8859-1html\n\nHope this helps,\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "RE: [SumsaultRT #212]  example of sending correct headers with Apache",
            "content": "See the Internationalization page\nhttp://www.w3.org/International/O-HTTP-charset.html\n\nAlso, if you want to check the information in the header:\nhttp://www.w3.org/International/questions/qa-headers-charset.html\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Mark Stosberg\n> Sent: 24 September 2003 16:52\n> To: public-evangelist@w3.org\n> Subject: [SumsaultRT #212] example of sending correct headers \n> with Apache?\n> \n> \n> \n> Hello,\n> \n> I was just reading here about character encodings:\n> \nhttp://www.w3.org/TR/xhtml1/#guidelines \n\nDown in section C.9, it states: \"the best approach is to ensure that the\nweb server provides the correct headers. \"\n\nI would like to do this, but I'm unsure of how to configure my Apache\nweb server to send the correct headers by default. Could someone post an\nexample of what the correct headers would be and/or an example of a\n\"correct\" Apache configuration for this?\n\nThanks!\n\nMark\n\n-- \n . . . . . . . . . . . . . . . . . . . . . . . . . . . \n   Mark Stosberg            Principal Developer  \n   mark@summersault.com     Summersault, LLC     \n   765-939-9301 ext 202     database driven websites\n . . . . . http://www.summersault.com/ . . . . . . . .\n\n\n\n"
        },
        {
            "subject": "RE: [SumsaultRT #212]  example of sending correct headers with Apache",
            "content": "> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of \n> Dominique Haza?l-Massieux\n> Sent: 24 September 2003 16:54\n> To: Mark Stosberg\n> Cc: public-evangelist@w3.org\n> Subject: Re: [SumsaultRT #212] example of sending correct \n> headers with Apache?\n> \n> \n> Le mer 24/09/2003 ? 17:51, Mark Stosberg a ?crit :\n> > I was just reading here about character encodings:\n> >\n> > Down in section C.9, it states: \"the best approach is to \n> ensure that \n> > the web server provides the correct headers. \"\n> > \n> > I would like to do this, but I'm unsure of how to configure \n> my Apache \n> > web server to send the correct headers by default. Could \n> someone post \n> > an example of what the correct headers would be and/or an \n> example of a \n> > \"correct\" Apache configuration for this?\n> \n> Provided that all your xhtml files have a uniform extension \n> (say .html) and a uniform encoding (say iso-8859-1), and \n\n\nOf course (being in internationalization but also from a practical\nstandpoint), I'd suggest UTF-8 as a preferred uniform encoding -\nespecially useful if you ever need to stray outside Latin1 (eg. for\nturkey, czech republic, etc - not just arabic, chinese, etc.)\n\n\n> provided that you serve them as text/html (but this applies \n> trivially to application/xhtml+xml), you can add (or amend an \n> existing entry) the following directive:\n> AddType text/html;charset=iso-8859-1html\n\n\nOne thing to bear in mind (that many don't realise) is that this\ndirective applies to all files in all subdirectories below the point\nwhere you add it.  You, of course, always have the possibility to\noverride it by adding another directive lower down if needs be.\n\nHope that helps,\nRI\n\n\n\n> \n> Hope this helps,\n> \n> Dom\n> -- \n> Dominique Haza?l-Massieux - http://www.w3.org/People/Dom/ \n> W3C/ERCIM mailto:dom@w3.org\n> \n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212]  example of sending correct headers with Apache",
            "content": "On Wed, Sep 24, 2003 at 05:54:05PM +0200, Dominique Haza?l-Massieux wrote:\n> Le mer 24/09/2003 ? 17:51, Mark Stosberg a ?crit :\n> > I was just reading here about character encodings:\n> >\n> > Down in section C.9, it states: \"the best approach is to ensure that the\n> > web server provides the correct headers. \"\n> > \n> > I would like to do this, but I'm unsure of how to configure my Apache\n> > web server to send the correct headers by default. Could someone post an\n> > example of what the correct headers would be and/or an example of a\n> > \"correct\" Apache configuration for this?\n> \n> Provided that all your xhtml files have a uniform extension (say .html)\n> and a uniform encoding (say iso-8859-1), and provided that you serve\n> them as text/html (but this applies trivially to application/xhtml+xml),\n> you can add (or amend an existing entry) the following directive:\n> AddType text/html;charset=iso-8859-1html\n\nThanks. Just to clarify my specific case:  \n\nWe are an American web hosting company. Nearly all of our pages are in\nAmerican english. Some pages will include declarations to declare their\nown content type, others won't. I think in our case it's reasonable to\nassume that for pages that don't declare a document type, defaulting \nto a standard American english kind of character set is reasonable.\n\nMark\n\n-- \n . . . . . . . . . . . . . . . . . . . . . . . . . . . \n   Mark Stosberg            Principal Developer  \n   mark@summersault.com     Summersault, LLC     \n   765-939-9301 ext 202     database driven websites\n . . . . . http://www.summersault.com/ . . . . . . . .\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "A very bare meeting page. I will be working on this over the next few days:\n\nhttp://www.w3.org/2001/sw/Europe/200210-init/\n\nChaals\n\nOn Thu, 25 Jul 2002, Charles McCathieNevile wrote:\n\n>Hi folks,\n>\n>sorry for the delay in getting back to this.\n>\n>A rough proposal:\n>\n[snipped]\n>\n>Again, I apologise for the short time-scale. I will post a page on the site\n>tomorrow with a bit more detail.\n>\n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "> > provided that you serve them as text/html (but this applies \n> > trivially to application/xhtml+xml), you can add (or amend an \n> > existing entry) the following directive:\n> > AddType text/html;charset=iso-8859-1html\n\nThanks for the responses. So both \"iso-8859-1\" and \"utf-8\" have been\nrecommended for us as the default character encoding type.\nIs there a particular rule of thumb about which to use, or is the\ncentral issue:  \"either one is better than none\"?\n\nMark\n\n-- \n . . . . . . . . . . . . . . . . . . . . . . . . . . . \n   Mark Stosberg            Principal Developer  \n   mark@summersault.com     Summersault, LLC     \n   765-939-9301 ext 202     database driven websites\n . . . . . http://www.summersault.com/ . . . . . . . .\n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "Mark Stosberg wrote:\n\n>>>provided that you serve them as text/html (but this applies \n>>>trivially to application/xhtml+xml), you can add (or amend an \n>>>existing entry) the following directive:\n>>>AddType text/html;charset=iso-8859-1html\n>>>      \n>>>\n>\n>Thanks for the responses. So both \"iso-8859-1\" and \"utf-8\" have been\n>recommended for us as the default character encoding type.\n>Is there a particular rule of thumb about which to use, or is the\n>central issue:  \"either one is better than none\"?\n>  \n>\neach directive has good and bad side.\n\nUTF-8 is quite universal, but you'll have to use html entities (such as \n\"&eacute;\" for \"?\") instead of accented (non-ascii) characters. This \nmakes accented text painful to read and edit.\nusing 8859-1 allows you to insert accented characters in your html, \nprovided they belong to the latin-1 charset . This is the solution that \nI use, because I write in French and in English only. If I wanted to use \ncharacters outside of the iso-8859-1 charset, (e.g. for czech) I'd have \nto use html entities or switch to UTF-8.\n\n\n--Tristan\nPS: I'm not an I18n guru, so feel free to correct me if I'm wrong.\n\n-- \nContributeur Mozilla et OpenWebGroup\nhttp://mozilla.org/    : Efficiency, safety and liberty for browsing.\nhttp://openweb.eu.org/ : pour apprendre les standards.\nhttp://standblog.com/  : un blog sur les standards.\nhttp://pompage.net/    : de saines lectures ? propos des standards.\n\n\n\n"
        },
        {
            "subject": "RE: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Tristan Nitot\n> Sent: 25 September 2003 07:51\n> To: public-evangelist@w3.org\n> Subject: Re: [SumsaultRT #212] iso-8859-1 vs. utf-8\n> \n> \n> \n> \n> \n> Mark Stosberg wrote:\n> \n> >>>provided that you serve them as text/html (but this applies\n> >>>trivially to application/xhtml+xml), you can add (or amend an \n> >>>existing entry) the following directive:\n> >>>AddType text/html;charset=iso-8859-1html\n> >>>      \n> >>>\n> >\n> >Thanks for the responses. So both \"iso-8859-1\" and \"utf-8\" have been \n> >recommended for us as the default character encoding type. \n> Is there a \n> >particular rule of thumb about which to use, or is the \n> central issue:  \n> >\"either one is better than none\"?\n> >  \n> >\n> each directive has good and bad side.\n> \n> UTF-8 is quite universal, but you'll have to use html \n> entities (such as \n> \"&eacute;\" for \"?\") instead of accented (non-ascii) characters. This \n> makes accented text painful to read and edit.\n> using 8859-1 allows you to insert accented characters in your html, \n> provided they belong to the latin-1 charset . This is the \n\n\nHmm.  I think you somehow have this the wrong way round.  UTF-8 means\nyou have no need to use character entities, since it covers the whole\nUnicode repertoire.  As you say, its because ISO 8859-1 only covers\ncharacters used in Western European languages (plus a few other simple\nLatin langs), that if you wanted to represent, say, the Czech c caron,\nthen you'd have to use a Numeric Character Reference or entity.\n\nFor an example, see\nhttp://people.w3.org/rishida/scripts/samples/wrapping-no-dhtml.html (10\nscripts on one page and no NCRs or entities other than &amp;)\n\nYou do, of course, need an editor that supports utf-8, but that's not\ndifficult to find these days.\n\nYou are right, though, when you say that it's better not to use\ncharacter entities, but rather actual codes.\n\n\n\n> solution that \n> I use, because I write in French and in English only. If I \n> wanted to use \n> characters outside of the iso-8859-1 charset, (e.g. for \n> czech) I'd have \n> to use html entities or switch to UTF-8.\n> \n> \n> --Tristan\n> PS: I'm not an I18n guru, so feel free to correct me if I'm wrong.\n> \n> -- \n> Contributeur Mozilla et OpenWebGroup\n> http://mozilla.org/    : Efficiency, safety and liberty for browsing.\n> http://openweb.eu.org/ : pour apprendre les standards. \n> http://standblog.com/  : un blog sur les standards.\n> \nhttp://pompage.net/    : de saines lectures ? propos des standards.\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "Le jeudi, 25 sep 2003, ? 06:43 America/Montreal, Richard Ishida a ?crit \n:\n>>\n>> UTF-8 is quite universal, but you'll have to use html\n>> entities (such as\n>> \"&eacute;\" for \"?\") instead of accented (non-ascii) characters. This\n\n>\n> Hmm.  I think you somehow have this the wrong way round.  UTF-8 means\n> you have no need to use character entities, since it covers the whole\n> Unicode repertoire.  As you say, its because ISO 8859-1 only covers\n\n:) let's clear up a bit. Both of you are right, in some context.\n\n* If you have an editor (authoring tool) which can NOT input utf-8 in \nyour text and you still want to use utf-8 for your document. You can \nuse this low tech method which is\n? -> &eacute; for example, so you will have only us-ascii characters \nin your document and us-ascii is a subset of utf-8.\n\n* If you have an editor which can input utf-8. Just type your accents.\n\n\nBTW, it would be good that someone on the mailing-list makes a list of \nall editors and their support of utf-8.\n\n\n\n"
        },
        {
            "subject": "RE: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "Yep.  I think I alluded to this further down in my message.   However,\nI'd like to encourage the mode of thought that it's a much better plan\nto try and find a utf-8 capable editor than to just fall back on the\nentities.\n\nIn my experience, many English speakers don't think this is a big deal,\nbut as Tristan said, it can seriously affect readability and\nmaintainability of the source in a language like French (not to mention\nChinese or Russian, or even Czech [see below]). As Tristan said using\n&eacute; is to be avoided if at all possible. \n\nRI\n\n\nHere's an example of Czech text where accented characters use NCRs.\nIt's almost impossible to read.\n\nJako efektivn&#x115;j&#x161;&#xED; se n&#xE1;m jev&#xED;\npo&#x159;&#xE1;d&#xE1;n&#xED; tzv. Road Show prost&#x159;ednictv&#xED;m\nna&#x161;ich autorizovan&#x1FD;ch dealer&#x16F; v &#x10C;ech&#xE1;ch a\nna Morav&#x11B;, kter&#xE9; prob&#x11B;hnou v pr&#x16F;b&#x16F;hu\nz&#xE1; &#x159;&#xED; a &#x159;&#xED;jna.\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: Karl Dubost [mailto:karl@la-grange.net] \n> Sent: 25 September 2003 16:58\n> To: ishida@w3.org\n> Cc: public-evangelist@w3.org; 'Tristan Nitot'\n> Subject: Re: [SumsaultRT #212] iso-8859-1 vs. utf-8\n> \n> \n> \n> Le jeudi, 25 sep 2003, ? 06:43 America/Montreal, Richard \n> Ishida a ?crit \n> :\n> >>\n> >> UTF-8 is quite universal, but you'll have to use html \n> entities (such \n> >> as \"&eacute;\" for \"?\") instead of accented (non-ascii) characters. \n> >> This\n> \n> >\n> > Hmm.  I think you somehow have this the wrong way round.  \n> UTF-8 means \n> > you have no need to use character entities, since it covers \n> the whole \n> > Unicode repertoire.  As you say, its because ISO 8859-1 only covers\n> \n> :) let's clear up a bit. Both of you are right, in some context.\n> \n> * If you have an editor (authoring tool) which can NOT input utf-8 in \n> your text and you still want to use utf-8 for your document. You can \n> use this low tech method which is\n> ? -> &eacute; for example, so you will have only \n> us-ascii characters \n> in your document and us-ascii is a subset of utf-8.\n> \n> * If you have an editor which can input utf-8. Just type your accents.\n> \n> \n> BTW, it would be good that someone on the mailing-list makes \n> a list of \n> all editors and their support of utf-8.\n> \n> \n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "Le jeudi, 25 sep 2003, ? 12:29 America/Montreal, Richard Ishida a ?crit \n:\n> Yep.  I think I alluded to this further down in my message.   However,\n> I'd like to encourage the mode of thought that it's a much better plan\n> to try and find a utf-8 capable editor than to just fall back on the\n> entities.\n\nAnother solution:\n\n* iconv\niconv is a small unix program (works on Linux, BSD, Mac OS X)\nhttp://www.gnu.org/software/libiconv/\nhttp://www.gnu.org/software/libiconv/documentation/libiconv/iconv.1.html\n\nFor example to convert from iso-8859-1 to utf-8\n\nkarl% iconv -f ISO-8859-1 -t UTF-8 fileold.html > filenew.html\n\nIf you want to convert a lot of files, create a small scripts like that.\n\n==================\n#!/bin/sh\n#\n# Shell Script\n# to convert a file from Latin 1 to utf-8\n\nWEBDIR=`find  /home/mywebsites/files/ -name '*.html'`\n\necho \"********** Converting File *******\"\nfor i in $WEBDIR;\ndo\n     iconv -f ISO-8859-1 -t UTF-8 $i > $i.new\n     mv $i.new $i\ndone\n==================\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "Karl Dubost wrote:\n\n> \n> \n> Le jeudi, 25 sep 2003, ? 12:29 America/Montreal, Richard Ishida a ?crit :\n> \n>> Yep.  I think I alluded to this further down in my message.   However,\n>> I'd like to encourage the mode of thought that it's a much better plan\n>> to try and find a utf-8 capable editor than to just fall back on the\n>> entities.\n> \n> \n> Another solution:\n> \n> * iconv\n> iconv is a small unix program (works on Linux, BSD, Mac OS X)\n> http://www.gnu.org/software/libiconv/\n> http://www.gnu.org/software/libiconv/documentation/libiconv/iconv.1.html\n> \nI think there are Windows binaries for this utility around. For example, \nit can be got via the libxml binaries download page available here: \nhttp://www.zlatkovic.com/projects/libxml/binaries.html\n\n         ...edN\n\n\n\n"
        },
        {
            "subject": "Re: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "\"Karl Dubost\" <karl@w3.org>\n>Le jeudi, 25 sep 2003, ? 12:29 America/Montreal, Richard Ishida a ?crit\n>:\n>> Yep.  I think I alluded to this further down in my message.   However,\n>> I'd like to encourage the mode of thought that it's a much better plan\n>> to try and find a utf-8 capable editor than to just fall back on the\n>> entities.\n\n\n>* iconv\n>iconv is a small unix program (works on Linux, BSD, Mac OS X)\n\niconv also works great under cygwin on windows machines.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "SWAD-Europe  workpackages, deliverables and effort spreadshee",
            "content": "Hi all,\n\nI've created a comma-separated variable file which works with Excel:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/_deliv_detail.csv\n\nThis is generated from several RDF files:\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/_esw_projdata.rdf\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/partners.rdf\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/whodoeswhat.rdf\n(the last came from the face to face)\n\nusing a Ruby program (with Dan's help):\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/bin/deliv-start-end.rb\n\nKate will use this as the basis for her calculations about who needs to\ndeliver how much effort on each workpackage and deliverable and when, so\nplease have a look at it and check that it makes sense (read the\ninformation below first).\n\nFor each workpackage, it shows calculated deliverable effort per\npartner. From this I've calculated start month for each partner,\nassuming 1FTE from each partner.\n\nThe calculation is as follows:\n\nWhere a person is specified as lead in a deliverable in\n\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/whodoeswhat.rdf\n\nthen the effort specified in the deliverable description is that\npartner's total effort for the deliverable.\nThat effort also determines the duration of the deliverable.\n\nSo, for WP4 we have 2 deliverables, one is this:\n\n[[\nMonth 4: (4.1: xml_graph_serialization_report) Public document\ndescribing the then state of the art concerning XML graph serialization\nsyntaxes for example in RDF, Web Ontologies and SOAP. (4 months, report,\nPub.)\n]]\n\n4 months is assigned to this deliverable in this description.\n\nFrom\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/rdf/whodoeswhat.rdf\n\nI find that the lead is danbri (and so W3C), and that various partners\nare interested in it.\n\nFor example ILRT is interested in 4.1 and 4.2 and has 6 months effort in\nthe WP, so I've just divided that total of 6 by 2 to get the\nper-deliverable effort for ILRT where ILRT is not the lead but is\ninterested. Obviously this is very simplistic, but could be changed - I\nthink the spreadsheet is probably the place for that though.\n\nThe start date for those interested but not leading is simply the end\ndate for the deliverable minus their calculated effort (i.e. it assumes\n1FTE). So for 4.1 and the ILRT, since the end month is 4, and the\neffort is 3 then the start month is 1. I thought this might be useful\nfor calculating how much effort each partner needs to account for every\n3 months.\n\nThe file is ordered so that the sum of deliverables for any partner on\nany WP plus unassigned effort should equal total effort on that WP for\nthat partner - so this is a constraint that could be added to the\nspreadsheet. It should be comparatively easy to create a spreadsheet\ncell that shows which deliverables are happening at any given point.\n\nThere is unassigned effort for some partners - this is effort which was\nneither assigned through lead nor through interest, and needs to be\nassigned (maybe by increasing FTE) or moved to a different WP. Where it\nis negative, then that partner has been overassigned for that WP at\nFTE1.\n\nFinally I included information about the start and the lead for each\ndeliverable, and also a list of email addresses of leads and those\ninterested. I also included a calculated start for each  WP: this is the\nearliest any deliverable in the WP starts. Obviously this could change\ndepending on the FTE amount included in each WP for each partner. There\nis also a start date specified in each html WP file, e.g.\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-6.html,\nbut I think the calculated ones are more accurate.\n\nI hope this is useful to people. Let me know if you think there are\nincorrect details and about any changes you would like to make (e.g. FTE\nlevels), as I'd like to feed any changes back to the html where they\ncame from to keep things consistent.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: [SumsaultRT #212] iso-8859-1 vs. utf",
            "content": "There are similar utilities for Windows users.  Uniconv is one that\ncomes to mind.\n\nThere's also a simple trick that tends to be easily available to most\nWindows users but in my experience not well known: use MS Word to read\nin the file as **encoded text** (not Word format !!), then save it back\nout again. You are offered a very large choice of encodings to save it\nin, one of which is utf-8.\n\nNote that you can do a similar thing with Notepad on XP, but it's not a\ngood idea since it adds a byte order mark to the beginning of a utf-8\nfile which then causes problems in some browsers.\n\n(Of course, it's much easier just to edit in or save out as utf-8 from\nyour editor ;)\n\nhth\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Karl Dubost\n> Sent: 25 September 2003 18:39\n> To: public-evangelist@w3.org\n> Subject: Re: [SumsaultRT #212] iso-8859-1 vs. utf-8\n> \n> \n> \n> \n> Le jeudi, 25 sep 2003, ? 12:29 America/Montreal, Richard \n> Ishida a ?crit \n> :\n> > Yep.  I think I alluded to this further down in my message. \n>   However,\n> > I'd like to encourage the mode of thought that it's a much \n> better plan \n> > to try and find a utf-8 capable editor than to just fall \n> back on the \n> > entities.\n> \n> Another solution:\n> \n> * iconv\n> iconv is a small unix program (works on Linux, BSD, Mac OS X) \n> http://www.gnu.org/software/libiconv/\n> \nhttp://www.gnu.org/software/libiconv/documentation/libiconv/iconv.1.html\n\nFor example to convert from iso-8859-1 to utf-8\n\nkarl% iconv -f ISO-8859-1 -t UTF-8 fileold.html > filenew.html\n\nIf you want to convert a lot of files, create a small scripts like that.\n\n==================\n#!/bin/sh\n#\n# Shell Script\n# to convert a file from Latin 1 to utf-8\n\nWEBDIR=`find  /home/mywebsites/files/ -name '*.html'`\n\necho \"********** Converting File *******\"\nfor i in $WEBDIR;\ndo\n     iconv -f ISO-8859-1 -t UTF-8 $i > $i.new\n     mv $i.new $i\ndone\n==================\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "[ANN] W3C Link Checker - version 3.9.2  first standalone releas",
            "content": "-=====================================================================-\n-     W3C Link Checker - version 3.9.2 - first standalone release     -\n-=====================================================================-\n\nIt is with great pleasure that we are announcing today the first\nstandalone release of the W3C link checker (a.k.a checklink), the\npopular free tool and service for checking the status of links on a web\nsite: finding broken links and solving authentication issues made easy!\n\nPreviously bundled as part of the W3C Markup Validator suite, the free\nonline W3C link checker service has been updated with this latest\nrelease version:\n\nhttp://validator.w3.org/checklink\n\nIn addition to that, we now distribute checklink as a free, standalone\ntool, which should be very easy to install and use as a commandline\ntool, or a service on your Web site.\n\n\n\n**  DOWNLOAD the LINK CHECKER  **\n\nThe Link Checker is available for downloading on the Comprehensive Perl\nArchive Network (CPAN) at:\n\nhttp://search.cpan.org/dist/W3C-LinkChecker/\n\n\n\n**  FEEDBACK  and  DEVELOPMENT  **\n\nThe link checker is a living, evolving tool, and we are committed to\nmake it even better than it is today. You can help us by sending us\ne-mails with your thoughts or bug reports to the *public* W3C mailing\nlist www-validator:\n\nhttp://lists.w3.org/Archives/Public/www-validator/\n\nNote that this list is used for feedback on several different tools, so\nwe suggest that you tag your messages regarding checklink in the subject\nof your e-mail, e.g:\n\nSubject: [checklink] bug report - ....\n\n\nDevelopers are encouraged to get the latest development version of the\ncode for Link Checker at any time from our CVS repository:\n\nhttp://dev.w3.org/cvsweb/perl/modules/W3C/LinkChecker/\n\nPatches, comments and insight on the code are absolutely welcome, also\non the *public* mailing list www-validator.\n\n\n\n**  CHANGES  **\n\nThe major change between the previous stable version and this release\nis obviously the fact that the Link Checker is now distributed as a\nstandalone tool, but there are other notable improvements:\n\n* Better documentation\n   - documentation for the command line use\n   - an embedded man page\n* New features\n   - New option to disable checking documents on non-public IP addresses\n* Bug fixes\n   - Improved redirect loop detection\n   - Recursion scope checking fixes\n   - Markup improvements\n   - Various other small bug fixes\n\n**  CREDITS  **\n\nThe first version of the Link Checker was developed in 1998 by Renaud\nBruyeron, then Hugo Haas rewrote it more or less from scratch in 1999.\nThe Link checker is currently maintained and developed, with the help\nof many volunteers, by the W3C QA Tools Development Team, especially by\nVille Skytt?.\n\n-=====================================================================-\n\n\nFor Ville Skytt?, lead maintainer/developer for the Link Checker\nand the QA tools development Team,\n-- \nolivier Thereaux - W3C / QA / QA Interest Group and Tools Development\nhttp://www.w3.org/People/olivier/ | http://www.w3.org/QA/\n\n\n\n\n"
        },
        {
            "subject": "FYI: Web Standards Award",
            "content": "I didn't know this Web site, but now it's done. Quite cool.\n\n\nhttp://www.webstandardsawards.com/\n\n  The Web Standards Awards aim to highlight the best in \nstandards-compliant  web site design, therefore there are some checks a \nsite must pass before  we will consider it for an award.\n\n  Mandatory criteria:\n Main pages should validate as HTML 4.01 or XHTML 1.0 compliant using \nthe W3C validator. Some exceptions may be given for obvious \ntypographical errors and the inclusion  of rich media, such as Flash.\n  Pages must maintain ? in  spirit ? a separation between data and \npresentation, such as that enabled by the coupled  usage of XHTML and \nCSS.\n  Appropriate tags must be used to mark up data i.e. tables  are for \ntabular data.\n\n  While assessing a site, the judges will consider the following  points:\n Visual appeal\n Degree of separation between data and presentation\n Quality of code\n Usability\n Accessibility\n Uniqueness\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "MarkUp Validator's new clothe",
            "content": "Hi,\n\n  Improving the usability of the W3C MarkUp Validator includes\nimprovements for the layout; it would thus be great to get some\ndiscussion on this matter and ideally see some proposals on how\nit could be improved, so, here we go: compare the following\n\n  [1] http://validator.w3.org:8001/check?uri=http://msdn.microsoft.com\n  [2] http://tinyurl.com/262cj\n\nThe latter is a redirect to output from the XSLT service at\n\n  [3] http://www.w3.org/2001/05/xslt\n\nit transforms [1] using\n\n  [4] http://lists.w3.org/Archives/Public/www-archive/2004Apr/att-0075/vl.xslt_\n\nMy alternate format differs in the following ways:\n\n  * it groups identical error messages, this helps to identify\n    errors made throughout the document like the missing\n    type attribute in\n\n      <script language='Javascript'>\n\n    or the illegal comment syntax in\n\n      <!----------------->\n\n  * it reintroduces the ^ marker which helps to spot certain\n    errors\n\n  * no right-hand navigation bar, I think it just distracts\n    and takes space, Accessibility is certainly important,\n    but I don't think that each and every validator page\n    needs to link seven of them. The same applies to most of\n    the links, a separate page, maybe even the homepage, is\n    a better place for these.\n\n  * the address of the validated page is not locked inside\n    an <input> field but rather an active link to the page\n\n  * it does not include the overly large and distracting\n\n      THIS PAGE IS NOT VALID HTML 4.0 TRANSITIONAL!\n\n    banner. I'd say it's not needed, the rest of the output\n    is already sufficiently clear about whether the document\n    validates or not.\n\n  * it re-introduces <pre> for source fragments. There is\n    a minor issue with pre as it might cause horizontal\n    scrolling, but this is basically caused by including\n    too much text on the right of the error location,\n    we need more text on the left which my XSLT could not\n    easily fix\n\n  * it does not include page source. I am not sure whether\n    it should. It's sometimes useful, sometimes not. It's \n    not what I intended to demonstrate...\n\n  * it does not include the navigation elements on the top,\n    it certainly should, but again, that's been out of scope\n\n  * it does not include all this legal stuff in the footer,\n    whether it must I do not know; I would not put it there\n\n  * it looks much much better, IMHO, and the styles are cross-\n    browser, the validator beta has issues with IE/Windows.\n\nIt is possible to further improve my alternate layout, for example\nit could use scripting to hide the source code fragments and show\nthem on user request or the table could include the error count, etc.\n\nHow would you re-design the Validator?\n\nFeel free to take my XSLT and modify it or just download validator\noutput, change what you like and get back to us!\n\nregards.\n\n\n\n"
        },
        {
            "subject": "General Entity ?!",
            "content": "Hey,\n\n  Who is this General Entity and why is he making my page invalid???\nThis cannot be, I've left the airforce long ago!!11 Damn Validator!\nHere is my page\n\n  http://ieqabar.sourceforge.net/\n\nI need this valid by tomorrow, PLEASE HELP ME OUTTA HERE!!\n\nThanks!\n\n\n\n"
        },
        {
            "subject": "Typo in Web agency requirements pag",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n~From your page: http://www.w3.org/QA/2002/07/WebAgency-Requirements\n\nHence your site must have very strong requirements, and compliance to\nstandards must be part of them to guaranty the general quality.\n\nPlease correct the spelling of \"guaranty\" to \"guarantee\".\n\n- --\nJolyon Forsyth\nhttp://RemoteSupport.com.au\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.2.1-nr1 (Windows XP)\nComment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org\n\niD8DBQFAhy/ECpmTwsvsdLsRAjR4AJ9T3+zB6eQPcyrkUxl3q4S69H5clQCgqGo/\n4uTsxK6v0oirbgDP+IqdsmE=\n=lZNd\n-----END PGP SIGNATURE-----\n\n\n\n"
        },
        {
            "subject": "Another typ",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n~From Page: http://www.w3.org/QA/2002/07/WebAgency-Requirements\n~ What you should include in your requirements list?\n\nShould either read:\nWhat you should include in your requirements list.\nor:\nWhat should you include in your requirements list?\n\n- --\nJolyon Forsyth\nhttp://RemoteSupport.com.au\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.2.1-nr1 (Windows XP)\nComment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org\n\niD8DBQFAhzDuCpmTwsvsdLsRAvwRAJ0R7uqLVNLu1z+5JJSpfW+PogDsxwCdHDqk\ncy6rhyn0ZPmxgqTl6EU/GTw=\n=5v9m\n-----END PGP SIGNATURE-----\n\n\n\n"
        },
        {
            "subject": "Re: Typo in Web agency requirements pag",
            "content": "Hi,\n\nLe jeu 22/04/2004 ? 04:39, Jolyon Forsyth a ?crit :\n> ~From your page: http://www.w3.org/QA/2002/07/WebAgency-Requirements\n> Please correct the spelling of \"guaranty\" to \"guarantee\".\n\nFixed (and the other typo too) ; thanks for the report,\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "SWAD-Europe  another worksho",
            "content": "As you know we are due to do tho workshops in October, one the postponed\n'International workshop' which looks to be colocated with the DC\nconference, and another ordinary developer workshop which I am\norganising at first pass.\n\nOctober's calendra currently looks like this:\nhttp://www.w3.org/2001/sw/Europe/events/view/calmonth?rdfweburl=http://sw1.ilrt.org/discovery/2002/05/rsscal/confrss.rdf&startorend=start&date=2002-10-02\n\nMy inital idea was to have it about calendaring, to take advantage of\nthe presence of the Webont working Group at HP in early October. There\nseemed to be some preference for querying at the face to face. However I\ndon't think that we have sufficient time or resources at this stage to\nhave a workshop on such a controversial, popular and political subject.\n\nTherefore I proppose that we go with the calendaring idea, especially\ngiven the current interest in RDF calendaring\n\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n\nhttp://www.extrememarkup.com/extreme/2002/friday.asp\nGeneralized metadata in your Palm\nNorman Walsh, Sun Microsystems\n(Extreme Markup 2002)\n\nApple Ical\nhttp://www.apple.com/ical/\n\nMozilla calendar\nhttp://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44D001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26safe%3Doff%26group%3Dnetscape.public.mozilla.calendar\n\nand the presence of Dan Connolly at the Webont f2f\n\nplus, of course, it's one of my particular interests as RDF Calendar\nTaskforce lead; and I've been doing a lot on it for this project:\n\nhttp://www.w3.org/2001/sw/Europe/events/view/\nhttp://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n\nwhat does everyone think? I'd like to start approaching people as soon\nas possible about this.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: The error message for uploading a non html documen",
            "content": "On Apr 27, 2004, at 21:53, David Dorward wrote:\n> with a link to a document that explains:\n>\n> * What content types are\n> * Why content types are used\n> * That they are set in different ways depending on what sends them to \n> the validator\n>   - Quick guide to configuring Apache with link to the Apache \n> documentation\n>   - Ditto IIS\n>   - File Upload with browsers (I don't know how they select content \n> types, I guess most of them will use the file extension)\n>   - Otherwise a suggestion to consult the documentation for the \n> software\n\nThat would be a very cool QA/Validator Tip (hence copying \npublic-evangelist@).\nAnyone interested?\n\n-- \nolivier\n\n\n\n\n"
        },
        {
            "subject": "REMINDER: W3C Workshop on Web Applications and Compound Document",
            "content": "[I don't think anything on this topic was ever sent here]\n\nPosition papers for the W3C Workshop on Web Applications and \nCompound Documents are due Friday 30 April.\n\nhttp://www.w3.org/2004/04/webapps-cdf-ws/\n\nIMPORTANT NOTICE: Due to an unfortunate error in the submission\nsystem, submissions entered before Wednesday 28 April may have been\nlost. Please submit again to be safe.\n\nThe workshop will examine the development of platform-independent\napplications on Web clients, as well as technologies surrounding\nthe combination of multiple formats into a single document.\n\nThe workshop is open to both W3C Members and the public (non-members).\n\nPosition papers are required for attendance, and can be from 1 to 4\npages in length.\n\nAny questions, contact the Workshop co-chair, Dean Jackson <dean@w3.org>\n\n\n\n"
        },
        {
            "subject": "older html tags, can be revamped again",
            "content": "hello,\ni,m W. You,\ni have a question :\ni saw in older documents the html tag ISINDEX and i thought maybe \nthis older kind of html tags should be reconsidered after all,maybe they\nare not so useless as it seems they are, or maybe used together with newer html\ntags would help increasing the relevance of an html webpage.\nwhy i'm saying all this?  because people tend to still use  the normal html documents\nthere are smaller quantities of xml  dhtml  document pages on the internet.\nit is interesting to see some examples of older and newer html tags used together\nin a webpage and the relevancy of such a html document compared to a similar one \nin which are used only the accepted html tags.\nbest regards\n \nW. Yuo\n \nhttp://www.netscake.com \n \n\n\n\n---------------------------------\nDo you Yahoo!?\nYahoo! Finance: Get your refund fast by filing online\n\n\n\n"
        },
        {
            "subject": "need help with keeping my department up to date! Web QA Training and Certificatio",
            "content": "I am the Internet Quality Manager at a creative and technology agency\nhere in Portland Oregon. I am looking for training or certification for\nmy employees. Would you have any idea of where to refer me, so my\ndepartment can keep up with emerging technologies and testing standards?\n\nThanks for your help!\n \nLisa\nLisa-Marie Boman\nInternet Quality Manager\nopus:creative\nmain 503.220.0252 | direct 503.972.3941\n2303 NW 23rd Avenue, Suite 206 | Portland, OR 97210 \n <http://www.opuscreative.com/> www.opuscreative.com\n \n\n\n\n"
        },
        {
            "subject": "WaSP asks the W3C  What is CC/P",
            "content": "Hi everyone,\n\nPlease enjoy the latest WaSP asks the W3C column, in which we examine CC/PP.\n\nhttp://www.webstandards.org/learn/askw3c/feb2004.html\n\nBest regards,\nMolly\n\nMolly E. Holzschlag\nAuthor / Instructor / Web Designer\nAbout Me: http://www.molly.com/\nAbout Web Standards: http://www.webstandards.org/ \n\n\n\n"
        },
        {
            "subject": "Re: WaSP asks the W3C  What is CC/P",
            "content": "I should update my poor, neglected CC/PP page that's been sitting around\nliterally for years now!\n\n--Kynn\n\nOn Monday, February 16, 2004, at 08:48 AM, Molly E. Holzschlag wrote:\n\n>\n> Hi everyone,\n>\n> Please enjoy the latest WaSP asks the W3C column, in which we examine \n> CC/PP.\n>\n> http://www.webstandards.org/learn/askw3c/feb2004.html\n>\n> Best regards,\n> Molly\n>\n> Molly E. Holzschlag\n> Author / Instructor / Web Designer\n> About Me: http://www.molly.com/\n> About Web Standards: http://www.webstandards.org/\n>\n>\n>\n--\nKynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\nChief Technologist, Idyll Mountain                http://idyllmtn.com\nAuthor, CSS in 24 Hours                       http://cssin24hours.com\nShock & Awe Blog                                http://shock-awe.info\nInland Anti-Empire Blog                   http://inlandantiempire.org\n\n\n\n"
        },
        {
            "subject": "[Fwd: Fw: WaSP: Disappointing Alternative Description",
            "content": "Hi Olivier, Karl and Dom,\n\nPlease see below ... can we please come up with a suitable longdesc for the graph in the recently published \"WaSP asks W3C\" (WaW)?\n\nhttp://www.webstandards.org/learn/askw3c/feb2004.html\n\nThanks,\n-steph\n\n-------- Original Message --------\nSubject: Fw: WaSP: Disappointing Alternative Description\nDate: Wed, 18 Feb 2004 09:15:09 -0600\nFrom: Dave Shea <dave@mezzoblue.com>\nTo: nigel@miswebdesign.com\nCC: learn@webstandards.org\n\nHey Nigel,\n\nThe alt text is exactly what alt text should be, as far as I'm concerned\n- simple and to the point. But a longdesc or even title would be\nbeneficial in this case, since there's so much extra data that's\nlocked-up in the image.\n\nAny suggestions on how we'd go about summarizing a multi-tiered graph as\ntext? \n\nd.\n\n------------- Forwarded message follows -------------\n\nHi Dave,\n\nIn the following recent WaSP article:\nhttp://www.webstandards.org/learn/askw3c/feb2004.html\n\nThe alternative description for the image 'graph of ccpp' is\ndisappointing, surely there should be a longdesc?\n\nCheers,\nNigel\n\n\n\n"
        },
        {
            "subject": "FW: current internet requirement",
            "content": "What are the current requirements (versions) of Internet Explorer and\nNetscape Browser that people are using?\n\n-----Original Message-----\nFrom: Karl Dubost [mailto:karl@w3.org]\nSent: Thursday, February 19, 2004 11:49 AM\nTo: Green, Kichelle (NIH/NCI)\nSubject: Re: current internet requirements\n\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nHi Kichelle,\n\nWould you like to send your question on public-evangelist@w3.org \n(Public Archived mailing list) and give more context?\n\n\nLe 19 f?vr. 2004, ? 11:42, Green, Kichelle (NIH/NCI) a ?crit :\n> What are the current internet requirements for IE and Netscape?\n>\n> Kichelle\n>\n\n- -- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.2.4 (Darwin)\n\niD8DBQFANOj8+dmsZnpx3tkRAikPAJ4tC2eJBE3OTiUMgDyarum4yQPDfgCeN/1w\n0w4k+VdY18xw7uBDU//s7ks=\n=dAII\n-----END PGP SIGNATURE-----\n\n\n\n"
        },
        {
            "subject": "Re: current internet requirement",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n- -----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n\nLe 19 f?vr. 2004, ? 11:51, Green, Kichelle (NIH/NCI) a ?crit :\n> What are the current requirements (versions) of Internet Explorer and\n> Netscape Browser that people are using?\n\nI am still not sure what you are talking about.\n\n*Could you give more context?*\n\nWhy? What? How? etc.\n\n- - - Is it stats of usage for the browsers?\n\n\n\n\nThings like http://www.upsdell.com/BrowserNews/stat.htm\n\nWhich are never quite exact, for example, Opera Browser to be able to \naccess some Web sites which do browser detection fake its id and is \ncounted as IE.\n\nYou have also plenty of browsers that are not counted but still are an \nimportant part of people using the Web.\n\nVoice Browsers\nBraille Readers\nMobile Phones (a lot in Europe and Asia, North America is years late \non this topic)\nText Browsers\nAuthoring Tools which can be browsers too\nBots\n\netc.\n\n\n\n\n- - -- Karl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n- -----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.2.4 (Darwin)\n\niD8DBQFANO1k+dmsZnpx3tkRAgrZAKCP5iRAjnHX/x+nUH+1rEZd6RiYvQCgwajr\n0JN+AlM3v+A0qq0M5w/8M+M=\n=zwzG\n- -----END PGP SIGNATURE-----\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.2.4 (Darwin)\n\niD8DBQFANO2N+dmsZnpx3tkRAqFsAKCesMAXx+mbxzQep/ho3IQJ5TeKTwCfeoZW\n2Z52PLIl9zxiofkO4s/This=\n=9/mq\n-----END PGP SIGNATURE-----\n\n\n\n"
        },
        {
            "subject": "Re: FW: current internet requirement",
            "content": "Hi Kichelle, \n\nHow do you mean by 'requirements'? \n\nDo you mean if what is the current browser that corporations and educational organisations are using? \n\nOr do you mean what is the latest browser version available, or ... do you mean which browsers are recommended? \n\nOr ... none of the above? :)\n\n\ncheers,\n-steph\n \n\nOn 2/19/04 11:51 AM, Green, Kichelle (NIH/NCI) wrote:\n\n> \n> \n> What are the current requirements (versions) of Internet Explorer and\n> Netscape Browser that people are using?\n> \n> -----Original Message-----\n> From: Karl Dubost [mailto:karl@w3.org]\n> Sent: Thursday, February 19, 2004 11:49 AM\n> To: Green, Kichelle (NIH/NCI)\n> Subject: Re: current internet requirements\n> \n> \n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA1\n> \n> Hi Kichelle,\n> \n> Would you like to send your question on public-evangelist@w3.org \n> (Public Archived mailing list) and give more context?\n> \n> \n> Le 19 f?vr. 2004, ? 11:42, Green, Kichelle (NIH/NCI) a ?crit :\n> \n>>What are the current internet requirements for IE and Netscape?\n>>\n>>Kichelle\n>>\n> \n> \n> - -- \n> Karl Dubost - http://www.w3.org/People/karl/\n> W3C Conformance Manager\n> *** Be Strict To Be Cool ***\n> \n> -----BEGIN PGP SIGNATURE-----\n> Version: GnuPG v1.2.4 (Darwin)\n> \n> iD8DBQFANOj8+dmsZnpx3tkRAikPAJ4tC2eJBE3OTiUMgDyarum4yQPDfgCeN/1w\n> 0w4k+VdY18xw7uBDU//s7ks=\n> =dAII\n> -----END PGP SIGNATURE-----\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: SWAD-Europe  another worksho",
            "content": "Hi, I think it is a bonzer idea.\n\nI should have some RDF to explain that bonzer means good. Or just not use it\nbecause it is un-european <grin/>.\n\nChaals\n\nOn Tue, 30 Jul 2002, Libby Miller wrote:\n\n>\n>\n>As you know we are due to do tho workshops in October, one the postponed\n>'International workshop' which looks to be colocated with the DC\n>conference, and another ordinary developer workshop which I am\n>organising at first pass.\n>\n>October's calendra currently looks like this:\n>http://www.w3.org/2001/sw/Europe/events/view/calmonth?rdfweburl=http://sw1.ilrt.org/discovery/2002/05/rsscal/confrss.rdf&startorend=start&date=2002-10-02\n>\n>My inital idea was to have it about calendaring, to take advantage of\n>the presence of the Webont working Group at HP in early October. There\n>seemed to be some preference for querying at the face to face. However I\n>don't think that we have sufficient time or resources at this stage to\n>have a workshop on such a controversial, popular and political subject.\n>\n>Therefore I proppose that we go with the calendaring idea, especially\n>given the current interest in RDF calendaring\n>\n>http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\n>http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n>\n>http://www.extrememarkup.com/extreme/2002/friday.asp\n>Generalized metadata in your Palm\n>Norman Walsh, Sun Microsystems\n>(Extreme Markup 2002)\n>\n>Apple Ical\n>http://www.apple.com/ical/\n>\n>Mozilla calendar\n>http://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44D001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26safe%3Doff%26group%3Dnetscape.public.mozilla.calendar\n>\n>and the presence of Dan Connolly at the Webont f2f\n>\n>plus, of course, it's one of my particular interests as RDF Calendar\n>Taskforce lead; and I've been doing a lot on it for this project:\n>\n>http://www.w3.org/2001/sw/Europe/events/view/\n>http://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n>\n>what does everyone think? I'd like to start approaching people as soon\n>as possible about this.\n>\n>cheers\n>\n>Libby\n>\n>\n\n-- \nCharles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\nW3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38 78 22\nLocation: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)\n\n\n\n"
        },
        {
            "subject": "Re: FW: current internet requirement",
            "content": "On Thu, 19 Feb 2004, Green, Kichelle (NIH/NCI) wrote:\n\n> What are the current requirements (versions) of Internet Explorer and\n> Netscape Browser that people are using?\n\nPeople (and others) are currently using virtually _all_ released\nversions of Internet Explorer and Netscape browsers as well as many\nother browsers. Are you interested in the currently most popular\nbrowsers and their versions? The answer will depend on your web site\naudience. You can start your research here:\nhttp://www.google.com/search?q=browser+usage\n\nIf you are interested in making your pages \"look good\" in currently\npopular browsers, you can start with\nhttp://www.google.com/search?q=browser+compatibility\n\nHTH,\n\nAlex.\n\n\n\n"
        },
        {
            "subject": "Implementation Report for Open Source browse",
            "content": "Hi,\n\nSomething that could be very useful  for Web developers would be to \nhave Implementation Report of Open source software. I would like to \nknow if people have ideas to organize that and in which fora.\n\nThe test suites are often available, we just need tables for each open \nsource products.\n\nIn the QA Matrix [1], we can find links to already existing Test Suite, \nlike the ones made by the CSS WG (Tantek, Ian, and Co)\n\n+ Should we invite the Web community to test the softwares?\n+ Should we encouraged the Open Source community to do it themselves \ngiving them a few recommendations.\n+ Where should it be hosted?\n+ Should we use EARL [2] or not?\n\nIdeas?\n\nExamples of Implementation Report:\n\nVoiceXML\nhttp://www.w3.org/Voice/2003/ir/voicexml20-ir.html\nUAAG 1.0\nhttp://www.w3.org/WAI/UA/impl-rec/\nDOM HTML Level 2\nhttp://www.w3.org/2002/11/DOM-Level-2-HTML-Results/\nOWL\nhttp://www.w3.org/2001/sw/WebOnt/impls\nSVG\nhttp://www.w3.org/Graphics/SVG/Test/20030813/status/matrix.html\nhttp://www.w3.org/Graphics/SVG/Test/\nXForms Basic 1.0\nhttp://www.w3.org/MarkUp/Forms/Test/XFormBasicImplementationReport.html\nRDF Core\nhttp://www.w3.org/2003/11/results/rdf-core-tests\n\netc.\n\n\n[1] http://www.w3.org/QA/TheMatrix\n[2] http://www.w3.org/TR/EARL10/\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: Implementation Report for Open Source browse",
            "content": "Check out the CSS Test page for more:\n\n http://w3.org/Style/CSS/Test/\n\ne.g. the Selectors Test Suite Implementation Report Template\n\n<http://www.w3.org/Style/CSS/Test/CSS3/Selectors/current/implementreportTEMP\nLATE.html>\n\nand instructions for filling out:\n\nhttp://www.w3.org/Style/CSS/Test/CSS3/Selectors/report-instruct.txt\n\nThe CSS WG has completed a few implementation reports for current\nimplementations yet I didn't see them linked from the test page.  Perhaps\nthey'll show up eventually.\n\n\nNote the focus on features rather than assertions.\n\nAssertions are nice for thoroughness (as are reports on individual test\ncases), but quite meaningless to most folks unless they are aggregated into\nfeatures, and clear communication of whether or not implementations support\neach feature of a specification.\n\n\nTantek\n\n\n\nOn 1/15/04 12:35 PM, \"Karl Dubost\" <karl@w3.org> wrote:\n\n> Hi,\n> \n> Something that could be very useful  for Web developers would be to\n> have Implementation Report of Open source software. I would like to\n> know if people have ideas to organize that and in which fora.\n> \n> The test suites are often available, we just need tables for each open\n> source products.\n> \n> In the QA Matrix [1], we can find links to already existing Test Suite,\n> like the ones made by the CSS WG (Tantek, Ian, and Co)\n> \n> + Should we invite the Web community to test the softwares?\n> + Should we encouraged the Open Source community to do it themselves\n> giving them a few recommendations.\n> + Where should it be hosted?\n> + Should we use EARL [2] or not?\n> \n> Ideas?\n> \n> Examples of Implementation Report:\n> \n> VoiceXML\n> http://www.w3.org/Voice/2003/ir/voicexml20-ir.html\n> UAAG 1.0\n> http://www.w3.org/WAI/UA/impl-rec/\n> DOM HTML Level 2\n> http://www.w3.org/2002/11/DOM-Level-2-HTML-Results/\n> OWL\n> http://www.w3.org/2001/sw/WebOnt/impls\n> SVG\n> http://www.w3.org/Graphics/SVG/Test/20030813/status/matrix.html\n> http://www.w3.org/Graphics/SVG/Test/\n> XForms Basic 1.0\n> http://www.w3.org/MarkUp/Forms/Test/XFormBasicImplementationReport.html\n> RDF Core\n> http://www.w3.org/2003/11/results/rdf-core-tests\n> \n> etc.\n> \n> \n> [1] http://www.w3.org/QA/TheMatrix\n> [2] http://www.w3.org/TR/EARL10/\n\n\n\n"
        },
        {
            "subject": "Re: Implementation Report for Open Source browse",
            "content": "\"Karl Dubost\" <karl@w3.org>\n> Something that could be very useful  for Web developers would be to\n> have Implementation Report of Open source software. I would like to\n> know if people have ideas to organize that and in which fora.\n\nYou may want to get in touch with Peter Schonefeld and the  SVG Foundation\nwho are currently producing a way to make it easier for the implementation\nreport of SVG more accessible to producers and less burdensome on the WG.\nWe've also evangelised the KSVG people into providing a review of KSVG when\nit's released, and that should be there.  I think it's a very good idea to\nencourage the community to do this, especially if we can provide an\nautomated method\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Browser Support Char",
            "content": "Hi, I'm looking for User agents Support Charts.\n\nCSS, (X)HTML, SMIL, SVG, MathML, etc.\n\nMy list so far\n* Interop Charts\nhttp://devedge.netscape.com/library/xref/2003/css-support/css1/ \nmastergrid.html\nhttp://devedge.netscape.com/library/xref/2003/css-support/css2/ \nselectors.html\nhttp://macedition.com/cb/resources/macbrowsercsssupport.html\nhttp://macedition.com/cb/resources/abridgedcsssupport.html\nhttp://macedition.com/cb/resources/tableCSStest.html\nhttp://css.maxdesign.com.au/listamatic/browser-support.htm\nhttp://css.maxdesign.com.au/listamatic2/browser-support.htm\nhttp://www.westciv.com/style_master/academy/browser_support/index.html\nhttp://hotwired.lycos.com/webmonkey/reference/browser_chart/\nhttp://www.xml.com/pub/a/2000/05/03/browserchart/\nhttp://www.itts.ttu.edu/documentation/html/charts/chart2.php\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: Browser Support Char",
            "content": "* Karl Dubost wrote:\n>Hi, I'm looking for User agents Support Charts.\n>\n>CSS, (X)HTML, SMIL, SVG, MathML, etc.\n\nhttp://www.opera.com/docs/specs/#css\nhttp://www.x-smiles.org/features_css.html\nhttp://www.konqueror.org/css/\nhttp://msdn.microsoft.com/workshop/author/css/reference/attributes.asp\nhttp://developer.apple.com/internet/css/safari_css.html\n\n\n\n"
        },
        {
            "subject": "Re: Browser Support Char",
            "content": "From: \"Karl Dubost\"\n\n\n>\n> Hi, I'm looking for User agents Support Charts.\n> CSS, (X)HTML, SMIL, SVG, MathML, etc.\n\nsome of these are older and others, test suites.\n-- or --  may be on your list or not needed.\n\nWebmonkey | Reference: Browser Chart\nhttp://hotwired.lycos.com/webmonkey/reference/browser_chart/index.html\n\n\nMacEdition Guide to CSS2 Support in PDA/Handheld Browsers\nhttp://www.macedition.com/cb/resources/handheldbrowsercsssupport.html\n\nCode Style: Handheld media browser conformance and compatibility\nhttp://www.codestyle.org/css/media/handheld-BrowserSummary.shtml\n\nHandheld media browser conformance, with media attribute.\nhttp://www.codestyle.org/css/media/handheld-BrowserSummary.shtml#conformance\n\nCode Style: Print media browser conformance and compatibility\nhttp://www.codestyle.org/css/media/print-BrowserSummary.shtml\n\n===\n\nWebTV | Microsoft TV HTML support\nhttp://developer.msntv.com/Develop/tags.asp\nand -- Develop and Code\nhttp://developer.msntv.com/Develop/default.asp\n\nCSS Tests [David Baron]\nhttp://dbaron.org/css/test/\n\nRichInStyle.com test suite\nhttp://www.richinstyle.com/test/\n\nDOM test Suite\nhttp://xw2k.sdct.itl.nist.gov/xml/dom-test-suite.html\n\nA collection at\nhttp://www.robinlionheart.com/stds/html4/links.html\n\nMozillified W3C SVG Test Suite\nhttp://www.croczilla.com/svg/fosdem2003/w3c-conformance-suite/mozillified-suite.html\n\nW3C SVG Tiny Test Suite using TinyLine\nhttp://www.tinyline.com/svgt/samples/tiny_test/tiny-index.html\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: Implementation Report for Open Source browse",
            "content": "Thank you Tantek and Jim.\n\nI think I will try to gather the information at least under the form of \nlinks.\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "XML Error Reportin",
            "content": "Dave Hyatt has published a neat way to report XML Errors in Safari\nhttp://weblogs.mozillazine.org/hyatt/archives/2004_01.html#004733\n\nMozilla handling\nhttp://weblogs.mozillazine.org/hyatt/images/mozilla-invalid-xml.jpg\n\nSafari possible handling\nhttp://weblogs.mozillazine.org/hyatt/images/safari-invalid-xml.jpg\n\nWarn the user that there's something wrong, is a neat way, and will \nhelp the developer to fix it faster.\n\n\nI have appreciated the comment in this entry.\nhttp://weblogs.mozillazine.org/hyatt/archives/2004_01.html#004702\n\nAnd particularly the last sentence:\n\"\"\"The #1 reason that HTML pages render incorrectly in alternate \nbrowsers is because of differences in error handling and recovery.\"\"\"\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-Europe  another worksho",
            "content": "One reason why query was the candidate workshop was because of the WebOnt\nF2F and presence (?confirmed) of the DQL people.\n\nI had already mentioned that there was planned to be a query workshop to the\nSesame people.  Don't know if they can come yet but they hoped to.  If it is\ngoing to be calendaring, I'll write to them and tell them of the change.\n\nAndy\n\n-----Original Message-----\nFrom: Libby Miller [mailto:Libby.Miller@bristol.ac.uk] \nSent: 30 July 2002 14:13\nTo: public-esw@w3.org\nSubject: SWAD-Europe - another workshop\n\n\n\n\nAs you know we are due to do tho workshops in October, one the postponed\n'International workshop' which looks to be colocated with the DC\nconference, and another ordinary developer workshop which I am\norganising at first pass.\n\nOctober's calendra currently looks like this:\nhttp://www.w3.org/2001/sw/Europe/events/view/calmonth?rdfweburl=http://sw1.i\nlrt.org/discovery/2002/05/rsscal/confrss.rdf&startorend=start&date=2002-10-0\n2\n\nMy inital idea was to have it about calendaring, to take advantage of\nthe presence of the Webont working Group at HP in early October. There\nseemed to be some preference for querying at the face to face. However I\ndon't think that we have sufficient time or resources at this stage to\nhave a workshop on such a controversial, popular and political subject.\n\nTherefore I proppose that we go with the calendaring idea, especially\ngiven the current interest in RDF calendaring\n\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n\nhttp://www.extrememarkup.com/extreme/2002/friday.asp\nGeneralized metadata in your Palm\nNorman Walsh, Sun Microsystems\n(Extreme Markup 2002)\n\nApple Ical\nhttp://www.apple.com/ical/\n\nMozilla calendar\nhttp://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44\nD001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26saf\ne%3Doff%26group%3Dnetscape.public.mozilla.calendar\n\nand the presence of Dan Connolly at the Webont f2f\n\nplus, of course, it's one of my particular interests as RDF Calendar\nTaskforce lead; and I've been doing a lot on it for this project:\n\nhttp://www.w3.org/2001/sw/Europe/events/view/\nhttp://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n\nwhat does everyone think? I'd like to start approaching people as soon\nas possible about this.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Quality and We",
            "content": "Interesting discussion is happening these days on Weblogs. It has \nstarted with XML Error handling, and shows the importance of QA like \nyou will read in the last post.\n\nhttp://weblogs.mozillazine.org/hyatt/archives/2004_01.html#004702\nhttp://weblogs.mozillazine.org/hyatt/archives/2004_01.html#004716\nhttp://weblogs.mozillazine.org/hyatt/archives/2004_01.html#004721\nhttp://diveintomark.org/archives/2004/01/16/draconianism\nhttp://diveintomark.org/archives/2004/01/14/thought_experiment\nhttp://nick.typepad.com/blog/2004/01/feeddemon_and_w.html\nhttp://nick.typepad.com/blog/2004/01/feeddemon_and_w_1.html\nhttp://www.tbray.org/ongoing/When/200x/2004/01/16/DraconianHistory\nhttp://www.tbray.org/ongoing/When/200x/2004/01/11/PostelPilgrim\nhttp://ln.hixie.ch/?start=1074730185&count=1\n\n\"\"\"Ask someone who does HTML/CSS quality assurance (QA) for a Web \nbrowser, or who has written code for a browser's layout engine. They'll \ngo on at length about the insanities that they have seen, but the short \nversion is that pretty much any random stream of characters has been \nwritten by someone somewhere and been labelled as HTML.\"\"\"\n\nand\n\"\"\"Specifications should ensure that compliant implementations \ninteroperate, whether the content is valid or not.\"\"\"\n\nIan Hickson\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: The error message for uploading a non html documen",
            "content": "A while ago I made a suggestion about providing more information about  \nContent-types  \n<http://lists.w3.org/Archives/Public/www-validator/2004Apr/0175.html>.\n\nSome people thought this was a good idea  \n<http://lists.w3.org/Archives/Public/public-evangelist/2004Apr/ \n0007.html>, but nothing appears to have been done about it yet.\n\nI've found some time to make a start on it. I haven't yet got all the  \ninformation I want in it, and it needs some polish, but you can find a  \ndraft at: <http://dorward.me.uk/www/content-type/>.\n\nCould people please make comments, suggestions, etc.\n\nIf anybody would like to put together some instructions for finding out  \nthe Content-type in MSIE[1] and setting IIS to send the correct  \ncontent-types, it would be much appreciated. (Screenshots are good,  \nscreenshots sent to the mailing list are bad - please send any  \nprivately, or (better) put them online and include a link.)\n\n[1] Could you check that it states the true Content-type though please?  \ni.e. doesn't say text/html if it is text/plain but starts with <html>.  \nI know that MSIE can treat text/plain as text/html, but I don't know if  \nit lies about it in the information window.\n\n(Hopefully this message will not come through twice - as I sent it  \nusing the wrong email address the first time round - and it got held  \nfor me to approve it being archived)\n\n--\nDavid Dorward\n      <http://dorward.me.uk/>\n<http://blog.dorward.me.uk/>\n\n\n\n"
        },
        {
            "subject": "Re: The error message for uploading a non html documen",
            "content": "A while ago I made a suggestion about providing more information about  \nContent-types  \n<http://lists.w3.org/Archives/Public/www-validator/2004Apr/0175.html>.\n\nSome people thought this was a good idea  \n<http://lists.w3.org/Archives/Public/public-evangelist/2004Apr/ \n0007.html>, but nothing appears to have been done about it yet.\n\nI've found some time to make a start on it. I haven't yet got all the  \ninformation I want in it, and it needs some polish, but you can find a  \ndraft at: <http://dorward.me.uk/www/content-type/>.\n\nCould people please make comments, suggestions, etc.\n\nIf anybody would like to put together some instructions for finding out  \nthe Content-type in MSIE[1] and setting IIS to send the correct  \ncontent-types, it would be much appreciated. (Screenshots are good,  \nscreenshots sent to the mailing list are bad - please send any  \nprivately, or (better) put them online and include a link.)\n\n[1] Could you check that it states the true Content-type though please?  \ni.e. doesn't say text/html if it is text/plain but starts with <html>.  \nI know that MSIE can treat text/plain as text/html, but I don't know if  \nit lies about it in the information window.\n\n--\nDavid Dorward\n      <http://dorward.me.uk/>\n<http://blog.dorward.me.uk/>\n\n\n\n"
        },
        {
            "subject": "RE: The error message for uploading a non html documen",
            "content": "David,\n\nWhen you get around to the character encoding stuff you may find the\nfollowing helpful:\nhttp://www.w3.org/International/tutorials/tutorial-char-enc.html\nhttp://www.w3.org/International/articles/serving-xhtml/\n\nAlso, you spelled IANA as INNA in one place.\n\nCheers,\nRI\n\n\n============\nRichard Ishida\nW3C\n\ncontact info:\nhttp://www.w3.org/People/Ishida/ \n\nW3C Internationalization:\nhttp://www.w3.org/International/ \n \n \n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of David Dorward\n> Sent: 03 June 2004 12:00\n> To: public-evangelist@w3.org; 'www-validator@w3.org' list\n> Subject: Re: The error message for uploading a non html document\n> \n> \n> A while ago I made a suggestion about providing more \n> information about Content-types \n> <http://lists.w3.org/Archives/Public/www-validator/2004Apr/0175.html>.\n> \n> Some people thought this was a good idea \n> <http://lists.w3.org/Archives/Public/public-evangelist/2004Apr/\n> 0007.html>, but nothing appears to have been done about it yet.\n> \n> I've found some time to make a start on it. I haven't yet got \n> all the information I want in it, and it needs some polish, \n> but you can find a draft at: <http://dorward.me.uk/www/content-type/>.\n> \n> Could people please make comments, suggestions, etc.\n> \n> If anybody would like to put together some instructions for \n> finding out the Content-type in MSIE[1] and setting IIS to \n> send the correct content-types, it would be much appreciated. \n> (Screenshots are good, screenshots sent to the mailing list \n> are bad - please send any privately, or (better) put them \n> online and include a link.)\n> \n> [1] Could you check that it states the true Content-type \n> though please?  \n> i.e. doesn't say text/html if it is text/plain but starts \n> with <html>.  \n> I know that MSIE can treat text/plain as text/html, but I \n> don't know if it lies about it in the information window.\n> \n> (Hopefully this message will not come through twice - as I \n> sent it using the wrong email address the first time round - \n> and it got held for me to approve it being archived)\n> \n> --\n> David Dorward\n>       <http://dorward.me.uk/>\n> <http://blog.dorward.me.uk/>\n> \n\n\n\n"
        },
        {
            "subject": "Re: The error message for uploading a non html documen",
            "content": "Hi David,\n\nOn Jun 3, 2004, at 20:00, David Dorward wrote:\n> I've found some time to make a start on it. I haven't yet got all the \n> information I want in it, and it needs some polish, but you can find a \n> draft at: <http://dorward.me.uk/www/content-type/>.\n\nQuite an excellent document, thanks for taking the time to write it.\n\n> Could people please make comments, suggestions, etc.\n\nMy comments would depend a lot on your purpose and intended audience. \nIt seems to be fairly well adapted as an introduction for the \"content \nproviding\" crowd to understand the inner mechanisms of content types, \nalthough some of the document seems to be more aimed at an audience \nwith Web server management skills.\n\nIf you plan it to be mostly an introduction, some parts of it could be \ntoned down. A content manager had rather first hear about the \ndifferents types of content before hearing about Content-Type: (without \ntoo much details on the HTTP transaction) whereas a Web administrator \nwill be happy with the storytelling going the way it currently is.\n\nAnother omission (but on purpose, maybe) I notice is that the document \ncurrently does not seem to mention that this system actually comes from \nMIME. I find it an important factor to understand the syntax of the \nheader (granted - I noted above that we may not want to talk too much \nabout this!) Going through the trouble of explaining that a document \nhas a certain type and that it is served with a specific character \nencoding, that a system (mime) has been developed to declare what a \ndocument is and how it is served, and finally explain that Web \ntransactions are based on this system could be a good way to tell the \nstory.\n\nDo you want to explain how the content type plays an important role in \nformat negotiation? Of course you don't want your document to get as \nlong as CHIPs[1]. Trust me, nobody reads anything that long ;)\n[1] http://www.w3.org/TR/chips/\n\nEventually, if you'd like, we could create two summaries (content type \nand encoding) - or one? as tips and link to your document. Any opinion \non that?\n\nThanks\n-- \nolivier\n\n\n\n\n"
        },
        {
            "subject": "[ANN] New LogValidator Release",
            "content": "A new version of W3C's Log Validator, the modular Web server log \nanalysis tool with a strong focus on quality, was released today.\nhttp://www.w3.org/QA/Tools/LogValidator/\n\nIn addition to a few bug fixes and additional features, this version is \nshipped with two new log processing modules, one validating documents \nagainst the W3C CSS validation service, and an experimental survey \nmodule.\n\nDownload the latest version (v0.3) here:\nhttp://www.w3.org/QA/Tools/LogValidator/Manual-Get#Install\n\n\n* Thanks *\n\nThanks a lot to Matthieu Faure for contributing his SurveyEngine \nModule. The module is still under development and we hope to improve it \nfurther and make it a very useful global statistic module for the Log \nValidator.\n\nAlso, thanks to Bjoern Hoehrmann for his \nWebService::Validator::CSS::W3C perl module, which made the iterfacing \nof the Log Validator with the W3C CSS Validator straightforward.\n\n\n* Changes *\n\nExtended list of changes since the latest stable version (0.2 - May \n2003)\n   - adding CSSValidator Module\n   - Adding (experimental) SurveyEngine Module\n   - adding support for \"w3\" log format\n   - changed output for clearer display of results\n   - added an option to set the From: address in Output::Mail\n   - the LogValidator now checks for the actual Content-Type of \ndocuments with no extension (e.g format negociated)\n\n\n* Feedback *\n\nThe Log Validator is an open source project maintained by the W3C \nQuality Assurance activity. For any feedback, question, suggestion or \ncontribution regarding this tool, please send e-mail to the public list \nwww-validator[1] (mention the log validator in the subject) or to me \n(ot@w3.org) directly.\n\n[1] http://lists.w3.org/Archives/Public/www-validator/\n\n\n\nThank you.\n-- \nolivier Thereaux - W3C / QA / Tools\nhttp://www.w3.org/People/olivier/\n\n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "Hi,\n\nI am going ahead with this since HP said yes, and W3C and Bristol (while not\nexpresing much officially on the mailing list :( have said yes, and I am\nassuming that Stilo and RAL don't have a major problem. (If you do have a big\nproblem the time to squeal is straight away...)\n\ncheers\n\nChaals\n\nOn Fri, 26 Jul 2002, Charles McCathieNevile wrote:\n\n>\n>A very bare meeting page. I will be working on this over the next few days:\n>\n>http://www.w3.org/2001/sw/Europe/200210-init/\n>\n>Chaals\n>\n>On Thu, 25 Jul 2002, Charles McCathieNevile wrote:\n>\n>>Hi folks,\n>>\n>>sorry for the delay in getting back to this.\n>>\n>>A rough proposal:\n>>\n>[snipped]\n>>\n>>Again, I apologise for the short time-scale. I will post a page on the site\n>>tomorrow with a bit more detail.\n>>\n>\n\n-- \nCharles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\nW3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38 78 22\nLocation: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)\n\n\n\n"
        },
        {
            "subject": "QA F2F meeting at Mandelie",
            "content": "Hi,\n\nWe have started the QA F2F[1] at Mandelieu during the W3C Tech Plenary \n2004 [1]\n\nIf you want to follow the discussions going on you can see the minutes \npublished after every quarter day of meeting on the QA WG mailing \nlist[3]\n\nThe minutes which has been published so far:\nhttp://lists.w3.org/Archives/Public/www-qa-wg/2004Mar/0003\n\nIf you would like to ask things or clarifications about the meeting and \ntopics, please reply to www-qa@w3.org\n\nYou can also contribute on the QA Wiki\nhttp://esw.w3.org/topic/QA\n\n[1] http://www.w3.org/QA/2004/03/f2f\n[2] http://www.w3.org/2003/08/allgroupoverview\n[3] http://lists.w3.org/Archives/Public/www-qa-wg/\n\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "The use of W3C standards in Denmark (survey",
            "content": "FYI: The use of W3C Standards in danish authorities home pages\nI have made a fresh minor survey for the use of W3C Standards in Denmark\n(February 2004) In Denmark, the Danish Ministry for Science, Technology\nand Innovation strongly encourage all governmental/national/municipal\nauthorities to use W3C standards (HTML/XHTML standards) on their Web\npages. This survey has run a test on 2033 danish authorities home pages.\nThe testing tool was the W3C Validator. Only 3,05 % of the home pages\nwas valid according to the W3C Validator. 71 % of the testing home pages\ndid have problems with the missing DOCTYPE-declaration and character\nencoding labeling (iso-8859-1, UTF-8 etc)\n\nYou can find an english summary and major findings from the survey here\nhttp://www.ae35-unit.dk/standard/english.html\n\nBest regards\nSoren Johannessen\nLibrarian\n\n\n\n"
        },
        {
            "subject": "Re: The use of W3C standards in Denmark (survey",
            "content": "Hi Soren\n\nLe 02 mars 2004, ? 18:37, Soren Johannessen a ?crit :\n> FYI: The use of W3C Standards in danish authorities home pages\n> I have made a fresh minor survey for the use of W3C Standards in \n> Denmark\n\nThis is a very interesting report. I do not read Danish. Do you know an \nautomatic translator for it?\n\nCould you give a bit of more for the tools you have used? And what have \nbeen the comments of the Danish authorities?\n\n\n\n\n\n"
        },
        {
            "subject": "The use of W3C standards in Denmark Part I",
            "content": "2004-03-04: I have got a request for telling more about my survey. In\n2002 the Danish computer magazine \"Computerworld\" made a survey about\nhow many governmental/national/municipal authorities did follow the W3C\nStandards (HTML/XHTML) the survey shows that time only 13 % did follow\nthe W3C Standards. The Danish Ministry for Science, Technology and\nInnovation strongly encourage W3C Standards since 1997. It's not a law\n(more a recomandation), but by following the W3C Standards all the\nDanish citizens could benefits the access to information hosted at the\nauthorities (libraries, schools, etc) by following W3C Standards. That\nwas on of the major reason why use W3C Standards in the public sector. I\ndecided in January 2004 to follow up on this survey from 2002 and make a\nnew one. My survey now shows that 3,05 % of 2033 home pages was valid\naccording W3C Validator.\n\nI am going to tell more about the method to collect the information from\n2033 authorities' home pages. To find all these home pages in Denmark,\nthe Danish Ministry for Science, Technology and Innovation have a online\nlist of them. http://bpn.surveyonline.dk/stat/statalfa.jsp Then I just\nstarted from the first until the last one. Some of the home pages on the\nlist does not exit any more. I made a spreadsheet to insert data from\nall the 2033 home pages.\n\nHow I made a testing - I did use Microsoft Internet Explorer 6.0 as\nbrowser. When I visit a home page I did the following thing. \"View\n>Source\" options so I was sure that I got the main entrance page and not\na Frame (did't use the right click -view source- options by the mouse).\nWhen the raw source text file was open, I was looking after a\nDOCTYPE-Declaration in the top of the document. If no DOCTYPE then the\ntest was finish because W3C Validator can't parse without a DOCTYPE. The\nhome page without a DOCTYPE was consider as non valid. If there were a\nDOCTYPE the W3C Validator was used. I did only test the main entrance\npage. It's good indicator how the rest of the sub-pages are regarding\nW3C standards. I assume, that webmasters has spend most time on the page\nmain entrance page . They have been reading about webdesign guidelines\netc.,  before the main entrance page has been publish live for the\npublic audience. The data from the survey was collected during January\n31th until February 16th 2004..\n\nI provide you all with an option to download the survey data in a\nspreadsheet, I have translated the name of the columns You can download\nit from http://www.ae35-unit.dk/standard/englishw3ctest.xls (420 KB)it's\nin Microsoft Excel format. )\n\nThere are 8 columns in the spreadsheet\n\n1) Name of the home page\n2) The testing URL\n3) Any DOCTYPE? (Yes or No options. If no then I did't use W3C Validator\nbecause never will parse any documents without a DOCTYPE)\n4) Which DOCTYPE? (I have manual from each home page copy and pasted the\nDOCTYPE into the spreadsheet. You will find some creative ways of\nwritting it, like some webmasters think that \"EN\" stands for english and\nthen they have translated it to danish \"DA\" A lot also forget the 2nd\nline of the DOCTYPE like \"\"http://www.w3.org/TR/html4/loose.dtd\" W3C\nValidator can still parse the document even the 2nd line is missing.\n5) Did home pages with a DOCTYPE manage the test at W3C Validator (Yes\nor No)\n6) Encoding problems (for home pages with problems here it's marked in\nthe cell with Encoding problems)\n7) Number of errors (how many errors did W3C Validator found)\n8) Webserver tool (I have use the Web-sniffer http://web-sniffer.net/ to\ndetect the webserver and also to check the encoding labelling\n(iso-8859-1, UTF-8 etc) from the HTTP Response Header (Note Content-Type\nfor text/html is not in the spreadsheet only the webserver tool)\n\n\nNote: it's only a snap-shot of the day I tested the home-page things can\nhave changed. One more thing I can figure out is that when 10 % of the\nhome pages use HTML 3.2 or HTML 2.0 in their DOCTYPE it's a direct way\nto have many errors according W3C Validator. Education in this matter is\nalso needed. The main entrance page is a dynamic page and change quite\noften so using old HTML version is a bad idea, I don't think webmasters\nis thinking about this issues.\n\n\nAfter finding out that 64,8 % is missing the DOCTYPE. I decided to\ncreate a minor guide in Danish for this issue. Since missing character\nencoding labeling (iso-8859-1, UTF-8) is also a major problem. I decided\nto explain very simple about this.  I have also give webmaster a chance\nto begin on Unicode (UTF-8), by given them a links to a Danish \"how to\nuse Unicode on webpages\" however I fell in this matter in Denmark, more\neducation is needed. Often at small authorities home page maybe the\nwebeditor is only working 2-3 hours pr week she/he has other things to\ndo at work. Unicode can be a little bit complex to understand. Since\nmany is using webeditor software like DreamWeaver, Frontpage etc, they\nnever see the HTML code, they just write and then publish.  FrontPage is\npr default inserting \"Windows-1252\"in the META-TAG. My advice for Danish\nMinistry for Science, Technology and Innovation was that in this issue,\nhigh-tech people have to create templates for not so HTML/XHTML familiar\nworkers like the example I gave above. Second advice, high tech people\nhave to set up systems that use PHP/ASP server side scripting language,\nCMS etc. to use a correct W3C Standard template. We can't assume or\ndemand that every one that produce text/content for the web knows things\nlike this.\n\nDuring my survey I have also the purpose explain how the W3C validator\nworks, the W3C validator is a cool tool if you understand the errors\nmessages. For not so good english reading people(webmasters) it's very\ndifficult to figure out the \"Character encoding label\" error etc. Well\nwe need a Danish localized version. Maybe an idea for W3C to create\nlocalized versions for more countries in the world? (HTML-TIDY maybe\nalso?)The local goverments around the world could pay for a localized\nversion then W3C would hosted these versions. It's would benefit a lot\nof not so HTML/XHTML skilled people\n\nWell my main ambition with this survey is to create a debate in Denmark.\nSo politicians begin react. One big problem I also see is that the\nretailer of CMS never ever tells/educate the buyers, how to set up the\nHTML/XHTML template for correct W3C standard. Lot's of people in public\nsector thinks, well we have bought this expensive CMS then we also\nassume that everything is fine, but that's not the case. \n\nFinally, I don't think the problems above are only a problem in Denmark.\nI think it's world wide problem. \n\nHope you can use the data to something and got the major points above.\nPlease feel free to ask me again. After publising my survey 2004-02-28,\nthere has not been to much respons in the danish media yet. I have\ne-mail newspapers etc. But no one yet have publish anything.\nSoren Johannessen\n\n\nMajor findings from survey at\nhttp://www.ae35-unit.dk/standard/english.html\n\n\n\n"
        },
        {
            "subject": "RE: The use of W3C standards in Denmark Part I",
            "content": "I have had a discussion with Soren directly about similar work I have been\ninvolved in.\n\nI have been analysing Further Education college Web sites on a regional\nbasis -the most recent surveys are available at\nhttp://www.ukoln.ac.uk/web-focus/events/workshops/rsc-yorkshire-2004/surveys\n/\n\nLike Soren, the most prevalent errors are (i) No DOCTYPE and (2) No\ncharacter encoding (if there is one, it often defines a Windows character\nset.\n\n[I am also finding, in a number of cases, user agent negotiation so that\ndifferent pages are served to non-IE browser - in one case (not an FE\ncollege) I found that using Opera I was taken to an accessibility Web site -\nand the page did not work :-) ]\n\nAs Soren says, even when we try to encourage authors to validate their\npages, they are often confused by the language of the W3C HTML validator.\nI'd agree that it would be nice to have a HTML Validator for Dummies tool.\n\nI've also been encouraging deployment of testing tools via a URI interface\n(along the lines used on the W3C Web site).  For info on this approach see: \n\nhttp://www.ukoln.ac.uk/qa-focus/documents/briefings/briefing-59/\n\nBTW reading Soren's description of her testing methodology, it occurred to\nme that we could do with something like EARL to describe the methodology in\na machine-understandable way.\n\nBrian\n---------------------------------------\nBrian Kelly\nUK Web Focus\nUKOLN\nUniversity of Bath \nBATH\nBA2 7AY\nEmail: B.Kelly@ukoln.ac.uk\nWeb: http://www.ukoln.ac.uk/\nPhone: 01225 383943\nFOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf\nFor info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/ \n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Soren \n> Johannessen\n> Sent: 04 March 2004 22:44\n> To: public-evangelist@w3.org\n> Subject: The use of W3C standards in Denmark Part II\n> \n> \n> \n> \n> \n> 2004-03-04: I have got a request for telling more about my survey. In\n> 2002 the Danish computer magazine \"Computerworld\" made a \n> survey about how many governmental/national/municipal \n> authorities did follow the W3C Standards (HTML/XHTML) the \n> survey shows that time only 13 % did follow the W3C \n> Standards. The Danish Ministry for Science, Technology and \n> Innovation strongly encourage W3C Standards since 1997. It's \n> not a law (more a recomandation), but by following the W3C \n> Standards all the Danish citizens could benefits the access \n> to information hosted at the authorities (libraries, schools, \n> etc) by following W3C Standards. That was on of the major \n> reason why use W3C Standards in the public sector. I decided \n> in January 2004 to follow up on this survey from 2002 and \n> make a new one. My survey now shows that 3,05 % of 2033 home \n> pages was valid according W3C Validator.\n> \n> I am going to tell more about the method to collect the \n> information from\n> 2033 authorities' home pages. To find all these home pages in \n> Denmark, the Danish Ministry for Science, Technology and \n> Innovation have a online list of them. \n> http://bpn.surveyonline.dk/stat/statalfa.jsp Then I just \n> started from the first until the last one. Some of the home \n> pages on the list does not exit any more. I made a \n> spreadsheet to insert data from all the 2033 home pages.\n> \n> How I made a testing - I did use Microsoft Internet Explorer \n> 6.0 as browser. When I visit a home page I did the following \n> thing. \"View\n> >Source\" options so I was sure that I got the main entrance \n> page and not\n> a Frame (did't use the right click -view source- options by \n> the mouse).\n> When the raw source text file was open, I was looking after a \n> DOCTYPE-Declaration in the top of the document. If no DOCTYPE \n> then the test was finish because W3C Validator can't parse \n> without a DOCTYPE. The home page without a DOCTYPE was \n> consider as non valid. If there were a DOCTYPE the W3C \n> Validator was used. I did only test the main entrance page. \n> It's good indicator how the rest of the sub-pages are \n> regarding W3C standards. I assume, that webmasters has spend \n> most time on the page main entrance page . They have been \n> reading about webdesign guidelines etc.,  before the main \n> entrance page has been publish live for the public audience. \n> The data from the survey was collected during January 31th \n> until February 16th 2004..\n> \n> I provide you all with an option to download the survey data \n> in a spreadsheet, I have translated the name of the columns \n> You can download it from \n> http://www.ae35-unit.dk/standard/englishw3ctest.xls (420 \n> KB)it's in Microsoft Excel format. )\n> \n> There are 8 columns in the spreadsheet\n> \n> 1) Name of the home page\n> 2) The testing URL\n> 3) Any DOCTYPE? (Yes or No options. If no then I did't use \n> W3C Validator because never will parse any documents without \n> a DOCTYPE)\n> 4) Which DOCTYPE? (I have manual from each home page copy and \n> pasted the DOCTYPE into the spreadsheet. You will find some \n> creative ways of writting it, like some webmasters think that \n> \"EN\" stands for english and then they have translated it to \n> danish \"DA\" A lot also forget the 2nd line of the DOCTYPE \n> like \"\"http://www.w3.org/TR/html4/loose.dtd\" W3C Validator \n> can still parse the document even the 2nd line is missing.\n> 5) Did home pages with a DOCTYPE manage the test at W3C \n> Validator (Yes or No)\n> 6) Encoding problems (for home pages with problems here it's \n> marked in the cell with Encoding problems)\n> 7) Number of errors (how many errors did W3C Validator found)\n> 8) Webserver tool (I have use the Web-sniffer \n> http://web-sniffer.net/ to detect the webserver and also to \n> check the encoding labelling (iso-8859-1, UTF-8 etc) from the \n> HTTP Response Header (Note Content-Type for text/html is not \n> in the spreadsheet only the webserver tool)\n> \n> \n> Note: it's only a snap-shot of the day I tested the home-page \n> things can have changed. One more thing I can figure out is \n> that when 10 % of the home pages use HTML 3.2 or HTML 2.0 in \n> their DOCTYPE it's a direct way to have many errors according \n> W3C Validator. Education in this matter is also needed. The \n> main entrance page is a dynamic page and change quite often \n> so using old HTML version is a bad idea, I don't think \n> webmasters is thinking about this issues.\n> \n> \n> After finding out that 64,8 % is missing the DOCTYPE. I \n> decided to create a minor guide in Danish for this issue. \n> Since missing character encoding labeling (iso-8859-1, UTF-8) \n> is also a major problem. I decided to explain very simple \n> about this.  I have also give webmaster a chance to begin on \n> Unicode (UTF-8), by given them a links to a Danish \"how to \n> use Unicode on webpages\" however I fell in this matter in \n> Denmark, more education is needed. Often at small authorities \n> home page maybe the webeditor is only working 2-3 hours pr \n> week she/he has other things to do at work. Unicode can be a \n> little bit complex to understand. Since many is using \n> webeditor software like DreamWeaver, Frontpage etc, they \n> never see the HTML code, they just write and then publish.  \n> FrontPage is pr default inserting \"Windows-1252\"in the \n> META-TAG. My advice for Danish Ministry for Science, \n> Technology and Innovation was that in this issue, high-tech \n> people have to create templates for not so HTML/XHTML \n> familiar workers like the example I gave above. Second \n> advice, high tech people have to set up systems that use \n> PHP/ASP server side scripting language, CMS etc. to use a \n> correct W3C Standard template. We can't assume or demand that \n> every one that produce text/content for the web knows things \n> like this.\n> \n> During my survey I have also the purpose explain how the W3C \n> validator works, the W3C validator is a cool tool if you \n> understand the errors messages. For not so good english \n> reading people(webmasters) it's very difficult to figure out \n> the \"Character encoding label\" error etc. Well we need a \n> Danish localized version. Maybe an idea for W3C to create \n> localized versions for more countries in the world? \n> (HTML-TIDY maybe also?)The local goverments around the world \n> could pay for a localized version then W3C would hosted these \n> versions. It's would benefit a lot of not so HTML/XHTML skilled people\n> \n> Well my main ambition with this survey is to create a debate \n> in Denmark.\n> So politicians begin react. One big problem I also see is \n> that the retailer of CMS never ever tells/educate the buyers, \n> how to set up the HTML/XHTML template for correct W3C \n> standard. Lot's of people in public sector thinks, well we \n> have bought this expensive CMS then we also assume that \n> everything is fine, but that's not the case. \n> \n> Finally, I don't think the problems above are only a problem \n> in Denmark.\n> I think it's world wide problem. \n> \n> Hope you can use the data to something and got the major points above.\n> Please feel free to ask me again. After publising my survey \n> 2004-02-28, there has not been to much respons in the danish \n> media yet. I have e-mail newspapers etc. But no one yet have \n> publish anything.\n> Soren Johannessen\n> \n> \n> Major findings from survey at\n> http://www.ae35-unit.dk/standard/english.html\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: The use of W3C standards in Denmark Part I",
            "content": "Hi,\n\nThis discussion start to be really interesting. I have started to  \nfactorize the information at this place\n\nhttp://esw.w3.org/topic/QA/ValidatorStatistics\n\nYou are welcome to contribute.\n\nLe 05 mars 2004, ? 09:55, Brian Kelly a ?crit :\n> I have had a discussion with Soren directly about similar work I have  \n> been\n> involved in.\n>\n> I have been analysing Further Education college Web sites on a regional\n> basis -the most recent surveys are available at\n> http://www.ukoln.ac.uk/web-focus/events/workshops/rsc-yorkshire-2004/ \n> surveys\n> /\n> http://www.ukoln.ac.uk/qa-focus/documents/briefings/briefing-59/\n\n\nFeel free to add these references to the wiki and describe it a bit.\n\nAnother related questions:\n* How do you use your statistics result to encourage people to switch  \nto Web standards, improve tools, etc.\n* What are the communication strategies associated with these  \nprinciples?\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: The use of W3C standards in Denmark Part I",
            "content": "Soren,\n\nLe 04 mars 2004, ? 23:44, Soren Johannessen a ?crit :\n> list of them. http://bpn.surveyonline.dk/stat/statalfa.jsp Then I just\n> started from the first until the last one. Some of the home pages on \n> the\n> list does not exit any more. I made a spreadsheet to insert data from\n> all the 2033 home pages.\n\nIt's a very impresssive *manual* work you have done.\n* Have you thought about using automatic tools to do it?\n* If no, was it because you had not all skills to create a program for \nthat purpose?\n* Or have you identified things which can not be done automatically?\n\nWhat would we be your dream tools to do that.\n\nYour process seems to be:\n\n1. List of URIs\n2. Detect if Frame or Not\n3. Doctype Yes/No\n  - If no doctype -> invalid\n  - If doctype -> send to the W3C Validator\n4. Which Doctype?\n5. Encoding Problems (what kind of test? validator? visual? -> \nweb-sniffer.net)\n6. Number of Errors Validity (Not a good criteria because of \ncascading). density of errors is a better criteria, but still not \nperfect.\n\nOne possible problems, the Web site does browser sniffing and the Web \npage which has been sent is not really the home page, but a message \npage (error or indirection).\n\n> pr default inserting \"Windows-1252\"in the META-TAG. My advice for \n> Danish\n> Ministry for Science, Technology and Innovation was that in this issue,\n> high-tech people have to create templates for not so HTML/XHTML \n> familiar\n> workers like the example I gave above. Second advice, high tech people\n\ntemplates for Dreamweaver and Frontpage?\n\n> have to set up systems that use PHP/ASP server side scripting language,\n> CMS etc. to use a correct W3C Standard template. We can't assume or\n> demand that every one that produce text/content for the web knows \n> things\n> like this.\n\nDo you have examples of tools producing the right code?\n\n> During my survey I have also the purpose explain how the W3C validator\n> works, the W3C validator is a cool tool if you understand the errors\n> messages. For not so good english reading people(webmasters) it's very\n> difficult to figure out the \"Character encoding label\" error etc. Well\n\nInteresting comments. We are trying to improve the localization of the \nW3C validator.\n\n\n> also?)The local goverments around the world could pay for a localized\n> version then W3C would hosted these versions. It's would benefit a lot\n> of not so HTML/XHTML skilled people\n\nThat would be very interesting. You would be pleased to know that the \nW3C Mark-Up validators is mainly developped by Scandinavian persons. Do \nyou think that the Denmark government could finance such an effort for \nthe Danish version?\n\n> retailer of CMS never ever tells/educate the buyers, how to set up the\n> HTML/XHTML template for correct W3C standard. Lot's of people in public\n> sector thinks, well we have bought this expensive CMS then we also\n> assume that everything is fine, but that's not the case.\n\n:) Yes I see what you mean. I think that Governments have a lot of \npossible outcome on vendors if they associate their requests and \nefforts to create pressure.\n\n> Hope you can use the data to something and got the major points above.\n> Please feel free to ask me again. After publising my survey 2004-02-28,\n> there has not been to much respons in the danish media yet. I have\n> e-mail newspapers etc. But no one yet have publish anything.\n>\n\nDo you know Marko Karppinen effort?\nhttp://www.markokarppinen.com/20030224.html\n\nwhich seems to have been stopped.\n\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "HTML Validity of Wikis (was RE: The use of W3C standards in Denmark Part II",
            "content": "> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Karl Dubost\n> Sent: 05 March 2004 16:16\n> To: public-evangelist@w3.org\n> Cc: 'Soren Johannessen'\n> Subject: Re: The use of W3C standards in Denmark Part II\n> \n> Hi,\n> \n> This discussion start to be really interesting. I have \n> started to factorize the information at this place\n> \n> http://esw.w3.org/topic/QA/ValidatorStatistics\n> \n> You are welcome to contribute.\n\nAdded some thoughts.  I'm pleased to see W3C experminting with Wikis.\n\nI've only just got into Wikis recently.  One slight concern I have is the\nvalidity of Wiki pages (I created some pages in the Wikipedia, with some\nembedded HTML).\n\nI've just validated http://esw.w3.org/topic/QA/ValidatorStatistics and\nnoticed one error (not in the area I added to though!)\n\nBrian\n\n\n---------------------------------------\nBrian Kelly\nUK Web Focus\nUKOLN\nUniversity of Bath \nBATH\nBA2 7AY\nEmail: B.Kelly@ukoln.ac.uk\nWeb: http://www.ukoln.ac.uk/\nPhone: 01225 383943\nFOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf\nFor info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/ \n\n\n> Le 05 mars 2004, ? 09:55, Brian Kelly a ?crit :\n> > I have had a discussion with Soren directly about similar \n> work I have \n> > been involved in.\n> >\n> > I have been analysing Further Education college Web sites on a \n> > regional basis -the most recent surveys are available at \n> > \n> http://www.ukoln.ac.uk/web-focus/events/workshops/rsc-yorkshire-2004/\n> > surveys\n> > /\n> > http://www.ukoln.ac.uk/qa-focus/documents/briefings/briefing-59/\n> \n> \n> Feel free to add these references to the wiki and describe it a bit.\n> \n> Another related questions:\n> * How do you use your statistics result to encourage \n> people to switch to Web standards, improve tools, etc.\n> * What are the communication strategies associated with \n> these principles?\n> \n> \n> --\n> Karl Dubost - http://www.w3.org/People/karl/ W3C Conformance Manager\n> *** Be Strict To Be Cool ***\n> \n\n\n\n"
        },
        {
            "subject": "Re: International Worksho",
            "content": "sorry charles - I'm very much in favour.\n\nLibby\n\nOn Tue, 30 Jul 2002, Charles McCathieNevile wrote:\n\n>\n> Hi,\n>\n> I am going ahead with this since HP said yes, and W3C and Bristol (while not\n> expresing much officially on the mailing list :( have said yes, and I am\n> assuming that Stilo and RAL don't have a major problem. (If you do have a big\n> problem the time to squeal is straight away...)\n>\n> cheers\n>\n> Chaals\n>\n> On Fri, 26 Jul 2002, Charles McCathieNevile wrote:\n>\n> >\n> >A very bare meeting page. I will be working on this over the next few days:\n> >\n> >http://www.w3.org/2001/sw/Europe/200210-init/\n> >\n> >Chaals\n> >\n> >On Thu, 25 Jul 2002, Charles McCathieNevile wrote:\n> >\n> >>Hi folks,\n> >>\n> >>sorry for the delay in getting back to this.\n> >>\n> >>A rough proposal:\n> >>\n> >[snipped]\n> >>\n> >>Again, I apologise for the short time-scale. I will post a page on the site\n> >>tomorrow with a bit more detail.\n> >>\n> >\n>\n> --\n> Charles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409 134 136\n> W3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38 78 22\n> Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n> (or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: HTML Validity of Wikis (was RE: The use of W3C standards in Denmark Part II",
            "content": "Le 05 mars 2004, ? 17:44, Brian Kelly a ?crit :\n> Added some thoughts.  I'm pleased to see W3C experminting with Wikis.\n>\n> I've only just got into Wikis recently.  One slight concern I have is \n> the\n> validity of Wiki pages (I created some pages in the Wikipedia, with \n> some\n> embedded HTML).\n\nYes you are completely right Brian. I'm always afraid to look at the \nsource code of the Web pages produced  MoinMoin wiki engine. :/\nhttp://moin.sourceforge.net/\n\nW3C People have tried to help the main developpers to fix their code \nbut they didn't want to integrate the patches.\n\nThough there is still hope.\nhttp://moinmoin.wikiwikiweb.de/MoinDev\n\nThere's a project to fix the kernel of the engine\nhttp://moinmoin.wikiwikiweb.de/MoinMoinTodo_2fRelease_201_2e3\n\n* WikiDomFormatter as prototype for generating valid output.\nhttp://moinmoin.wikiwikiweb.de/WikiDomFormatter\n\nIn the 1.2 Release, you will have \nhttp://moinmoin.wikiwikiweb.de/MoinMoinTodo_2fRelease_201_2e2\n\nrefactoring HTML (make it HTML 4.01 compliant)\nthe macros RandomQuote and Include use send_page. This creates \nmultiple divs with id=\"content\". id must be unique.\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "RE: The use of W3C standards in Denmark Part I",
            "content": "It's a very impresssive *manual* work you have done.\n* Have you thought about using automatic tools to do it?\nSoren J: YES! I have indeed , a true copy and paste hell doing it\nmanually ;-)\n\n* If no, was it because you had not all skills to create a\nprogram for \nthat purpose?\nSorenJ: I have not such much skills in this issue- I am more a person\nwho takes a free scripts and then modifify so it fits to my purpose on\nWebpages.  \n\n* Or have you identified things which can not be done\nautomatically?\n\nSoren J: I think everything can be done automatically when I first have\nthe collections of URI's ready in a spreadsheet, MySQL database or on a\nweb-page.\n\n\nWhat would we be your dream tools to do that.\n\nYour process seems to be:\n\n1. List of URIs\n2. Detect if Frame or Not\n3. Doctype Yes/No\n  - If no doctype -> invalid\n  - If doctype -> send to the W3C Validator\n4. Which Doctype?\n5. Encoding Problems (what kind of test? validator? visual? -> \nweb-sniffer.net)\nSorenJ: like what does the HTTP header repons says and what does the\nHTML doc's metatag or the XML declaration says. Any conflicts webserver\nversus HTML/XHTML documents.\n\n6. Number of Errors Validity (Not a good criteria because of \ncascading). density of errors is a better criteria, but still not \nperfect.\n\nSorenJ: maybe an PHP script which goes into MySQL database and takes the\nColunms with the URI's and then some IF THEN statesments like you\ndescribe above dectect Frame or not and return the values back from\nDOCTYPE to MySQL database in a new columns and go back to W3C's\nvalidator and return values like VAlID or NOT VALID numbers of errors\netc.\nAnd of course some time out funcitions to the script does not stop,\nbecause it's waiting for W3C Validator or Web-sniffer etc different\ntools.\nThe PHP script should be possible to set up to any META tag I am looking\nfor fx like \"<meta name=\"GENERATOR\"> tag and return it back to MySQL\ndatabase... Is all this a impossible dream?\n\n\n\nOne possible problems, the Web site does browser sniffing and the Web \npage which has been sent is not really the home page, but a message \npage (error or indirection).\n\nSorenJ: As I understood from Brian Kelly this should be the case in 5 %\nof all issues?\n\nMy advice for> Danish\n> Ministry for Science, Technology and Innovation was that in this\nissue,\n> high-tech people have to create templates for not so HTML/XHTML \n> familiar\n> workers like the example I gave above. Second advice, high tech people\n\ntemplates for Dreamweaver and Frontpage?\nSorenJ: Help with templates to all kind of manual webpage editors. \n\n> have to set up systems that use PHP/ASP server side scripting \n> language, CMS etc. to use a correct W3C Standard template. We can't \n> assume or demand that every one that produce text/content for the web \n> knows things like this.\n\nDo you have examples of tools producing the right code?\nSorenJ: Well I as have mention before CMS is not bad if the right people\ncode them correct. But a wild guess here! I think home pages using\nApache webservers is better than others to following the W3C standards.\nI don't have any data from surveys about this yet. A lot of these free\nPHP-webloging with MySQL database as backend tools is also during a good\njob creating correct W3C HTML/XHTML. \n\nThat would be very interesting. You would be pleased to know that the \nW3C Mark-Up validators is mainly developped by Scandinavian persons. Do \nyou think that the Denmark government could finance such an effort for \nthe Danish version?\n\nSorenJ: Nice to know about the scandinavian people and the W3C\nValidator. About a danish version of W3C Validator, how many words are\nthe all help documentations for the endusers \"the explain that options\nyou get when you got an error\"\n, and numbers of words in the W3C Validator home-page. I assume the\nunderlaying programing language is still going to be the same.  If the\nhelp document is only http://validator.w3.org/docs/errors.html and not\nso much more! I maybe can find a team for translation of that for free!\nHow much do you think W3C will charge for hosting  a\n(danishvalidator.w3.org)  danish Validator version pr year.? Then I can\nprovide this amount pr. year and the hole idea for some one in the\nDanish Ministry for Science. Now things are going to be very interesting\nwith ping pong of ideas over the big sea.\n\n\nDo you know Marko Karppinen effort?\nhttp://www.markokarppinen.com/20030224.html\nSorenJ: NO, but it's seem like the same test I did. Strange to be member\nof a standard organization and then not follow the standards ;-)\n\nLatest news from media: a radio journalist is in the near future going\nto produce a radioshows about W3C standards \"He is a Mac user and fell\nthe pains\" he had found my page and was very interesting to contact me\nlater on.\n\nSoren\n\n\n\n"
        },
        {
            "subject": "Re: The use of W3C standards in Denmark Part II &ndash;&ndash; some other dat",
            "content": "Some statistics about correctness of web pages.\n\n... which confirms some of the data presented in this thread.\n\nTwo years ago I made a minor survey of error frequency in Swedish web\npages. The aim was to get some initial data about how well standards are\nadhered to.\n\nI only looked at commercial websites, and only on the home page of these\nsites. The commercial web sites selected were fetched from a list companies\nregistered on the stock exchange, a list that provides information for\nfinancial analysts.\n\nThe investigation was, for simplicity restricted to automatic validity\nchecking, with some manual intervention in the selection and filtering\nprocess.\n\nThe W3C HTML validator was the tool used, and no attempt was made to \nobtain a\nfinegrained classification of the types of errors found -- something that is\ninherently difficult, if one tries an approach based on automated\nanalysis. At that point in time, the only quick-and-dirty way of accessing\nthe results of the validator was to extract ?nformation from the HTML page\nreturned by the validator. Not a nice way, but it was doable. There was some\ndiscussion at that point that a more programmatic interface would be useful,\ne.g. \"W3C Validator as a Web Service\". But I had to make do with what was\navailable, hence the indirect way of dissecting the page generated by the\nValidator.\n\nThere were a number of situations that had to be clearly identified, if the\noutcome was to be trusted.  E.g., to be able to separate those cases \nwhere no\nreal checking was made made by the Validator, I had to identify at least\nthose occurences where the Validator complained that it could not check the\npage for some reason.\n\nSome statistics\n---------------\n\nThe initial list of companies (company web sites) that was used ...\n\n - number of initially selected pages: 330 pages\n\nBut some sites were down or returned something that was not HTML, so...\n\n - number of actually investigated pages: 280 pages\n\nThe sizes of the pages varied significantly:\n\n - minimum page size: 89 characters\n - maximum page size: 129 832 characters\n\nDOCTYPE was a big problem:\n\n - percentage of pages that did not declare DOCTYPE: 76 %\n\n... or at least no DOCTYPE was recognised by the validator!\n\nNo page passed W3C Validator checking! The span in error remarks was\n - minimum number of errors: 1\n - maximum number of errors: 591\n\nAs some pages triggered avalanches of errors, and some pages were extreme in\nsize, they could create bad effects on the statistics. So \"extreme\" pages\nwere filtered out, and statistics was only retained for pages that fulfilled\nthe conditions:\n\n - size of page: 1,000 -- 50,000 characters\n - number of error remarks on page: < 200\n\nAs to the reason for excluding \"small\" pages is obvious -- the size of a\ncorrect (and reasonable) \"hello world\" page is on the order of 200\ncharacters. Small pages are also found when FRAMESETs are used, and such\npages were not further studied.\n\nThis resulted in an effective set of pages ...\n\n - number of pages used in final statistics: 226\n\nThis set was partitioned into two groups -- IT-companies and other\ncompanies. The reason for this partitioning was that one would think that\nIT-companies (e.g. IT-vendors or IT consultants) would be better at\nconstructing correct pages than other companies (e.g. household appliance\nvendors or transport companies) ...\n\n - number of IT companies: 76\n - number of other companies: 150\n\nThe result turned out to be that no clear difference, w.r.t. errors, \ncould be\ndetected between these two types of companies, which was not what one would\nexpect.\n\nDocumentation:\n-------------\nThere is a write-up (in Swedish ;-) ) of these things on:\n  http://www.w3c.se/resources/office/papers/memo1/memo1.html\n\nOn that page there are also some diagrams that describe the correlation \nbetween\n\n * size-of-page vs numbers-of-errors\n * size-of-page vs numbers-of-errors-per-1000-characters-of-page\n\nEach green dot represents one of the 226 pages investigated.\n\nFor those that might want to look at the diagrams, the texts in these can be\ntranslated as:\n\n * \"antalet\" = \"number\"\n * \"sidstorlek\" = \"page size\"\n * \"anm?rkningar\" = \"error remarks\"\n * \"antalet anm?rkningar f?r sida\" = \"number of error remarks per page\"\n * \"antalet anm?rkningar per 1000 tkn i sida\" = \"number of error remarks \nper 1000 chars in page\"\n * \"anm?rkningar/1000 tkn\" = \"error remarks/1000 chars\"\n\n\nThe two last diagrams on that page portray the relationship between size of\npages and the number of pages of that size. Here we aggregate pages into\ngroups of pages (0-2500, 2501-5000, 5000-7500, ... page size in characters)\nand do the correlation of the size represented by each group to the \nnumber of\npages in each group. This is nicely described as a Zipf distribution.\n\n=================================\n\n/olle\n\n-- \n------------------------------------------------------------------\nOlle Olsson   olleo@sics.se   Tel: +46 8 633 15 19  Fax: +46 8 751 72 30\n[Svenska W3C-kontoret: olleo@w3.org]\nSICS [Swedish Institute of Computer Science]\nBox 1263\nSE - 164 29 Kista\nSweden\n------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: The use of W3C standards in Denmark Part II &ndash;&ndash; some other dat",
            "content": "Hi Olle\n\nOne question does the Swedish government also recommend/advocate W3C\nstandards in  Swedish  governmental/national/municipal authorities home\npage? It could be interesting to compare Denmark and Sweden \n(also Norway & Finland if they have same politics for use of W3C\nStandards)\n\n/Soren\n\n\n\n\nSome statistics about correctness of web pages.\n\n... which confirms some of the data presented in this thread.\n\nTwo years ago I made a minor survey of error frequency in Swedish web\npages. The aim was to get some initial data about how well standards are\nadhered to.\n\nI only looked at commercial websites, and only on the home page of these\nsites. The commercial web sites selected were fetched from a list\ncompanies registered on the stock exchange, a list that provides\ninformation for financial analysts.\n\nThe investigation was, for simplicity restricted to automatic validity\nchecking, with some manual intervention in the selection and filtering\nprocess.\n\nThe W3C HTML validator was the tool used, and no attempt was made to \nobtain a\nfinegrained classification of the types of errors found -- something\nthat is inherently difficult, if one tries an approach based on\nautomated analysis. At that point in time, the only quick-and-dirty way\nof accessing the results of the validator was to extract ?nformation\nfrom the HTML page returned by the validator. Not a nice way, but it was\ndoable. There was some discussion at that point that a more programmatic\ninterface would be useful, e.g. \"W3C Validator as a Web Service\". But I\nhad to make do with what was available, hence the indirect way of\ndissecting the page generated by the Validator.\n\nThere were a number of situations that had to be clearly identified, if\nthe outcome was to be trusted.  E.g., to be able to separate those cases\n\nwhere no\nreal checking was made made by the Validator, I had to identify at least\nthose occurences where the Validator complained that it could not check\nthe page for some reason.\n\nSome statistics\n---------------\n\nThe initial list of companies (company web sites) that was used ...\n\n - number of initially selected pages: 330 pages\n\nBut some sites were down or returned something that was not HTML, so...\n\n - number of actually investigated pages: 280 pages\n\nThe sizes of the pages varied significantly:\n\n - minimum page size: 89 characters\n - maximum page size: 129 832 characters\n\nDOCTYPE was a big problem:\n\n - percentage of pages that did not declare DOCTYPE: 76 %\n\n... or at least no DOCTYPE was recognised by the validator!\n\nNo page passed W3C Validator checking! The span in error remarks was\n - minimum number of errors: 1\n - maximum number of errors: 591\n\nAs some pages triggered avalanches of errors, and some pages were\nextreme in size, they could create bad effects on the statistics. So\n\"extreme\" pages were filtered out, and statistics was only retained for\npages that fulfilled the conditions:\n\n - size of page: 1,000 -- 50,000 characters\n - number of error remarks on page: < 200\n\nAs to the reason for excluding \"small\" pages is obvious -- the size of a\ncorrect (and reasonable) \"hello world\" page is on the order of 200\ncharacters. Small pages are also found when FRAMESETs are used, and such\npages were not further studied.\n\nThis resulted in an effective set of pages ...\n\n - number of pages used in final statistics: 226\n\nThis set was partitioned into two groups -- IT-companies and other\ncompanies. The reason for this partitioning was that one would think\nthat IT-companies (e.g. IT-vendors or IT consultants) would be better at\nconstructing correct pages than other companies (e.g. household\nappliance vendors or transport companies) ...\n\n - number of IT companies: 76\n - number of other companies: 150\n\nThe result turned out to be that no clear difference, w.r.t. errors, \ncould be\ndetected between these two types of companies, which was not what one\nwould expect.\n\nDocumentation:\n-------------\nThere is a write-up (in Swedish ;-) ) of these things on:\n  http://www.w3c.se/resources/office/papers/memo1/memo1.html\n\nOn that page there are also some diagrams that describe the correlation \nbetween\n\n * size-of-page vs numbers-of-errors\n * size-of-page vs numbers-of-errors-per-1000-characters-of-page\n\nEach green dot represents one of the 226 pages investigated.\n\nFor those that might want to look at the diagrams, the texts in these\ncan be translated as:\n\n * \"antalet\" = \"number\"\n * \"sidstorlek\" = \"page size\"\n * \"anm?rkningar\" = \"error remarks\"\n * \"antalet anm?rkningar f?r sida\" = \"number of error remarks per page\"\n * \"antalet anm?rkningar per 1000 tkn i sida\" = \"number of error remarks\n\nper 1000 chars in page\"\n * \"anm?rkningar/1000 tkn\" = \"error remarks/1000 chars\"\n\n\nThe two last diagrams on that page portray the relationship between size\nof pages and the number of pages of that size. Here we aggregate pages\ninto groups of pages (0-2500, 2501-5000, 5000-7500, ... page size in\ncharacters) and do the correlation of the size represented by each group\nto the \nnumber of\npages in each group. This is nicely described as a Zipf distribution.\n\n=================================\n\n/olle\n\n-- \n------------------------------------------------------------------\nOlle Olsson   olleo@sics.se   Tel: +46 8 633 15 19  Fax: +46 8 751 72 30\n[Svenska W3C-kontoret: olleo@w3.org]\nSICS [Swedish Institute of Computer Science]\nBox 1263\nSE - 164 29 Kista\nSweden\n------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: The use of W3C standards in Denmark Part II &ndash;&ndash; some other dat",
            "content": "Hello,\n\n >  does the Swedish government also recommend/advocate W3C standards\n\nYes they do.\n\nAt a political level there is no question about adherence to standards \n-- standards: \"YES\"\n\nAt a practical level, there is a great variation in how well different \nagencies succeed in complying to these standards -- standards: \"we \nTHOUGHT we were OK\".\n\nPart of the problem is that the public sector uses commercial tools for \ncontent-management/publishing, and such tools fail to comply to \nstandards. The situation is gradually getting better, of course, but \nslowly (at the pace that Marko Karppinen detected in his investigation).\n\nThere was an initial unfounded expectation that if rules about web \nstandards for the public sector are stated (at the government level), \nthen everything will automatically become compliant. Now there is a \ngrowing insight that such rules only indirectly have an impact on the \npublic websites:\n \n    public policy is stated [standard compliancy]\n     --> requirements for procurement of authoring/publishing tools\n     --> tool vendors see a requirement from a potentially big market\n     --> the vendors adapt their tools to these requirements\n     --> the public sector agencies get good tools\n     --> the public sector must learn how to use theese tools in correct \nways\n     --> .... and then we will see good pages on the web\n\nAt the moment there are a number of initiatives in the public sector to \nsupport the complex of web-presence of the public sector. One aspect is \ncompliance to technical standards, another is living up to accessibility \nrequirements (WAI), yet other things concerns usability in the broader \nspectrum, as well as interoperability across different agencies (not \nonly web services, but also syndication of information).\n\nThere was a broad investigation of accessibility (WAI) issues in the \npublic sector -- it created a heated debate about how such evaluations \nshould be performed. I know of no large scale investigation of \ncompliance to technical standards in the public sector.\n\nBut, of course, such a study could be done.\n\n/olle\n\nSoren Johannessen wrote:\n\n>Hi Olle\n>\n>One question does the Swedish government also recommend/advocate W3C\n>standards in  Swedish  governmental/national/municipal authorities home\n>page? It could be interesting to compare Denmark and Sweden \n>(also Norway & Finland if they have same politics for use of W3C\n>Standards)\n>\n>/Soren\n>\n>\n>\n>\n>Some statistics about correctness of web pages.\n>\n>... which confirms some of the data presented in this thread.\n>\n>Two years ago I made a minor survey of error frequency in Swedish web\n>pages. The aim was to get some initial data about how well standards are\n>adhered to.\n>\n>I only looked at commercial websites, and only on the home page of these\n>sites. The commercial web sites selected were fetched from a list\n>companies registered on the stock exchange, a list that provides\n>information for financial analysts.\n>\n>The investigation was, for simplicity restricted to automatic validity\n>checking, with some manual intervention in the selection and filtering\n>process.\n>\n>The W3C HTML validator was the tool used, and no attempt was made to \n>obtain a\n>finegrained classification of the types of errors found -- something\n>that is inherently difficult, if one tries an approach based on\n>automated analysis. At that point in time, the only quick-and-dirty way\n>of accessing the results of the validator was to extract ?nformation\n>from the HTML page returned by the validator. Not a nice way, but it was\n>doable. There was some discussion at that point that a more programmatic\n>interface would be useful, e.g. \"W3C Validator as a Web Service\". But I\n>had to make do with what was available, hence the indirect way of\n>dissecting the page generated by the Validator.\n>\n>There were a number of situations that had to be clearly identified, if\n>the outcome was to be trusted.  E.g., to be able to separate those cases\n>\n>where no\n>real checking was made made by the Validator, I had to identify at least\n>those occurences where the Validator complained that it could not check\n>the page for some reason.\n>\n>Some statistics\n>---------------\n>\n>The initial list of companies (company web sites) that was used ...\n>\n> - number of initially selected pages: 330 pages\n>\n>But some sites were down or returned something that was not HTML, so...\n>\n> - number of actually investigated pages: 280 pages\n>\n>The sizes of the pages varied significantly:\n>\n> - minimum page size: 89 characters\n> - maximum page size: 129 832 characters\n>\n>DOCTYPE was a big problem:\n>\n> - percentage of pages that did not declare DOCTYPE: 76 %\n>\n>... or at least no DOCTYPE was recognised by the validator!\n>\n>No page passed W3C Validator checking! The span in error remarks was\n> - minimum number of errors: 1\n> - maximum number of errors: 591\n>\n>As some pages triggered avalanches of errors, and some pages were\n>extreme in size, they could create bad effects on the statistics. So\n>\"extreme\" pages were filtered out, and statistics was only retained for\n>pages that fulfilled the conditions:\n>\n> - size of page: 1,000 -- 50,000 characters\n> - number of error remarks on page: < 200\n>\n>As to the reason for excluding \"small\" pages is obvious -- the size of a\n>correct (and reasonable) \"hello world\" page is on the order of 200\n>characters. Small pages are also found when FRAMESETs are used, and such\n>pages were not further studied.\n>\n>This resulted in an effective set of pages ...\n>\n> - number of pages used in final statistics: 226\n>\n>This set was partitioned into two groups -- IT-companies and other\n>companies. The reason for this partitioning was that one would think\n>that IT-companies (e.g. IT-vendors or IT consultants) would be better at\n>constructing correct pages than other companies (e.g. household\n>appliance vendors or transport companies) ...\n>\n> - number of IT companies: 76\n> - number of other companies: 150\n>\n>The result turned out to be that no clear difference, w.r.t. errors, \n>could be\n>detected between these two types of companies, which was not what one\n>would expect.\n>\n>Documentation:\n>-------------\n>There is a write-up (in Swedish ;-) ) of these things on:\n>  http://www.w3c.se/resources/office/papers/memo1/memo1.html\n>\n>On that page there are also some diagrams that describe the correlation \n>between\n>\n> * size-of-page vs numbers-of-errors\n> * size-of-page vs numbers-of-errors-per-1000-characters-of-page\n>\n>Each green dot represents one of the 226 pages investigated.\n>\n>For those that might want to look at the diagrams, the texts in these\n>can be translated as:\n>\n> * \"antalet\" = \"number\"\n> * \"sidstorlek\" = \"page size\"\n> * \"anm?rkningar\" = \"error remarks\"\n> * \"antalet anm?rkningar f?r sida\" = \"number of error remarks per page\"\n> * \"antalet anm?rkningar per 1000 tkn i sida\" = \"number of error remarks\n>\n>per 1000 chars in page\"\n> * \"anm?rkningar/1000 tkn\" = \"error remarks/1000 chars\"\n>\n>\n>The two last diagrams on that page portray the relationship between size\n>of pages and the number of pages of that size. Here we aggregate pages\n>into groups of pages (0-2500, 2501-5000, 5000-7500, ... page size in\n>characters) and do the correlation of the size represented by each group\n>to the \n>number of\n>pages in each group. This is nicely described as a Zipf distribution.\n>\n>=================================\n>\n>/olle\n>\n>  \n>\n\n\n-- \n------------------------------------------------------------------\nOlle Olsson   olleo@sics.se   Tel: +46 8 633 15 19  Fax: +46 8 751 72 30\n[Svenska W3C-kontoret: olleo@w3.org]\nSICS [Swedish Institute of Computer Science]\nBox 1263\nSE - 164 29 Kista\nSweden\n------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: The use of W3C standards in Denmark Part II &ndash;&ndash; some other dat",
            "content": "Hi\n \nIn Denmark the last tree years the National IT- and Telecom Agency have\nmade an annual rating for authorities home pages\nHow they rate a home page can be found at\n\nhttp://www.bedstpaanettet.dk/imageblob/image.asp?objno=6664 (sorry only\nin Danish)\n\nYou will see that a valid HTML/XHTML home page only gives 2 points! This\nshould have been 20 points. \n\nThere is an english summary of \"Top of the Web - Intensified Focus on\nE-government in Denmark\"\nhttp://www.bedstpaanettet.dk/english.asp?page=document&objno=716\n\n\n/Soren\n\n\n\nHello,\n\n >  does the Swedish government also recommend/advocate W3C standards\n\nYes they do.\n\nAt a political level there is no question about adherence to standards \n-- standards: \"YES\"\n\nAt a practical level, there is a great variation in how well different \nagencies succeed in complying to these standards -- standards: \"we \nTHOUGHT we were OK\".\n\nPart of the problem is that the public sector uses commercial tools for \ncontent-management/publishing, and such tools fail to comply to \nstandards. The situation is gradually getting better, of course, but \nslowly (at the pace that Marko Karppinen detected in his investigation).\n\nThere was an initial unfounded expectation that if rules about web \nstandards for the public sector are stated (at the government level), \nthen everything will automatically become compliant. Now there is a \ngrowing insight that such rules only indirectly have an impact on the \npublic websites:\n \n    public policy is stated [standard compliancy]\n     --> requirements for procurement of authoring/publishing tools\n     --> tool vendors see a requirement from a potentially big market\n     --> the vendors adapt their tools to these requirements\n     --> the public sector agencies get good tools\n     --> the public sector must learn how to use theese tools in correct\n\nways\n     --> .... and then we will see good pages on the web\n\nAt the moment there are a number of initiatives in the public sector to \nsupport the complex of web-presence of the public sector. One aspect is \ncompliance to technical standards, another is living up to accessibility\n\nrequirements (WAI), yet other things concerns usability in the broader \nspectrum, as well as interoperability across different agencies (not \nonly web services, but also syndication of information).\n\nThere was a broad investigation of accessibility (WAI) issues in the \npublic sector -- it created a heated debate about how such evaluations \nshould be performed. I know of no large scale investigation of \ncompliance to technical standards in the public sector.\n\nBut, of course, such a study could be done.\n\n/olle\n\nSoren Johannessen wrote:\n\n>Hi Olle\n>\n>One question does the Swedish government also recommend/advocate W3C \n>standards in  Swedish  governmental/national/municipal authorities home\n\n>page? It could be interesting to compare Denmark and Sweden (also \n>Norway & Finland if they have same politics for use of W3C\n>Standards)\n>\n>/Soren\n>\n>\n>\n>\n>Some statistics about correctness of web pages.\n>\n>... which confirms some of the data presented in this thread.\n>\n>Two years ago I made a minor survey of error frequency in Swedish web \n>pages. The aim was to get some initial data about how well standards \n>are adhered to.\n>\n>I only looked at commercial websites, and only on the home page of \n>these sites. The commercial web sites selected were fetched from a list\n\n>companies registered on the stock exchange, a list that provides \n>information for financial analysts.\n>\n>The investigation was, for simplicity restricted to automatic validity \n>checking, with some manual intervention in the selection and filtering \n>process.\n>\n>The W3C HTML validator was the tool used, and no attempt was made to\n>obtain a\n>finegrained classification of the types of errors found -- something\n>that is inherently difficult, if one tries an approach based on\n>automated analysis. At that point in time, the only quick-and-dirty way\n>of accessing the results of the validator was to extract ?nformation\n>from the HTML page returned by the validator. Not a nice way, but it\nwas\n>doable. There was some discussion at that point that a more\nprogrammatic\n>interface would be useful, e.g. \"W3C Validator as a Web Service\". But I\n>had to make do with what was available, hence the indirect way of\n>dissecting the page generated by the Validator.\n>\n>There were a number of situations that had to be clearly identified, if\n\n>the outcome was to be trusted.  E.g., to be able to separate those \n>cases\n>\n>where no\n>real checking was made made by the Validator, I had to identify at \n>least those occurences where the Validator complained that it could not\n\n>check the page for some reason.\n>\n>Some statistics\n>---------------\n>\n>The initial list of companies (company web sites) that was used ...\n>\n> - number of initially selected pages: 330 pages\n>\n>But some sites were down or returned something that was not HTML, so...\n>\n> - number of actually investigated pages: 280 pages\n>\n>The sizes of the pages varied significantly:\n>\n> - minimum page size: 89 characters\n> - maximum page size: 129 832 characters\n>\n>DOCTYPE was a big problem:\n>\n> - percentage of pages that did not declare DOCTYPE: 76 %\n>\n>... or at least no DOCTYPE was recognised by the validator!\n>\n>No page passed W3C Validator checking! The span in error remarks was\n> - minimum number of errors: 1\n> - maximum number of errors: 591\n>\n>As some pages triggered avalanches of errors, and some pages were \n>extreme in size, they could create bad effects on the statistics. So \n>\"extreme\" pages were filtered out, and statistics was only retained for\n\n>pages that fulfilled the conditions:\n>\n> - size of page: 1,000 -- 50,000 characters\n> - number of error remarks on page: < 200\n>\n>As to the reason for excluding \"small\" pages is obvious -- the size of \n>a correct (and reasonable) \"hello world\" page is on the order of 200 \n>characters. Small pages are also found when FRAMESETs are used, and \n>such pages were not further studied.\n>\n>This resulted in an effective set of pages ...\n>\n> - number of pages used in final statistics: 226\n>\n>This set was partitioned into two groups -- IT-companies and other \n>companies. The reason for this partitioning was that one would think \n>that IT-companies (e.g. IT-vendors or IT consultants) would be better \n>at constructing correct pages than other companies (e.g. household \n>appliance vendors or transport companies) ...\n>\n> - number of IT companies: 76\n> - number of other companies: 150\n>\n>The result turned out to be that no clear difference, w.r.t. errors,\n>could be\n>detected between these two types of companies, which was not what one\n>would expect.\n>\n>Documentation:\n>-------------\n>There is a write-up (in Swedish ;-) ) of these things on:\n>  http://www.w3c.se/resources/office/papers/memo1/memo1.html\n>\n>On that page there are also some diagrams that describe the correlation\n>between\n>\n> * size-of-page vs numbers-of-errors\n> * size-of-page vs numbers-of-errors-per-1000-characters-of-page\n>\n>Each green dot represents one of the 226 pages investigated.\n>\n>For those that might want to look at the diagrams, the texts in these \n>can be translated as:\n>\n> * \"antalet\" = \"number\"\n> * \"sidstorlek\" = \"page size\"\n> * \"anm?rkningar\" = \"error remarks\"\n> * \"antalet anm?rkningar f?r sida\" = \"number of error remarks per page\"\n> * \"antalet anm?rkningar per 1000 tkn i sida\" = \"number of error \n> remarks\n>\n>per 1000 chars in page\"\n> * \"anm?rkningar/1000 tkn\" = \"error remarks/1000 chars\"\n>\n>\n>The two last diagrams on that page portray the relationship between \n>size of pages and the number of pages of that size. Here we aggregate \n>pages into groups of pages (0-2500, 2501-5000, 5000-7500, ... page size\n\n>in\n>characters) and do the correlation of the size represented by each\ngroup\n>to the \n>number of\n>pages in each group. This is nicely described as a Zipf distribution.\n>\n>=================================\n>\n>/olle\n>\n>  \n>\n\n\n-- \n------------------------------------------------------------------\nOlle Olsson   olleo@sics.se   Tel: +46 8 633 15 19  Fax: +46 8 751 72 30\n[Svenska W3C-kontoret: olleo@w3.org]\nSICS [Swedish Institute of Computer Science]\nBox 1263\nSE - 164 29 Kista\nSweden\n------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: International Worksho",
            "content": "I don't think that we have any problem with this.\n\nBrian \n\n>  -----Original Message-----\n>  From: Charles McCathieNevile [mailto:charles@w3.org]\n>  Sent: 30 July 2002 14:25\n>  To: public-esw@w3.org\n>  Subject: Re: International Workshop\n>  \n>  \n>  \n>  Hi,\n>  \n>  I am going ahead with this since HP said yes, and W3C and \n>  Bristol (while not\n>  expresing much officially on the mailing list :( have said \n>  yes, and I am\n>  assuming that Stilo and RAL don't have a major problem. (If \n>  you do have a big\n>  problem the time to squeal is straight away...)\n>  \n>  cheers\n>  \n>  Chaals\n>  \n>  On Fri, 26 Jul 2002, Charles McCathieNevile wrote:\n>  \n>  >\n>  >A very bare meeting page. I will be working on this over \n>  the next few days:\n>  >\n>  >http://www.w3.org/2001/sw/Europe/200210-init/\n>  >\n>  >Chaals\n>  >\n>  >On Thu, 25 Jul 2002, Charles McCathieNevile wrote:\n>  >\n>  >>Hi folks,\n>  >>\n>  >>sorry for the delay in getting back to this.\n>  >>\n>  >>A rough proposal:\n>  >>\n>  >[snipped]\n>  >>\n>  >>Again, I apologise for the short time-scale. I will post a \n>  page on the site\n>  >>tomorrow with a bit more detail.\n>  >>\n>  >\n>  \n>  -- \n>  Charles McCathieNevile    http://www.w3.org/People/Charles  \n>  phone: +61 409 134 136\n>  W3C Web Accessibility Initiative     http://www.w3.org/WAI  \n>  fax: +33 4 92 38 78 22\n>  Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia\n>  (or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia \n>  Antipolis Cedex, France)\n>  \n\n\n\n"
        },
        {
            "subject": "Re: The use of W3C standards in Denmark Part I",
            "content": "The surveys are interesting. A couple of comments:\n\na) The W3C Validator does not attempt to report all possible errors in web\npages, just validation or disagreement between the page and the DTD. So it is\npossible for pages to be non-standard or have errors and still validate.\nPerhaps there is a need for a \"checker\" which attempts to identify all possible\nviolations of relevant w3c standards.\n\nPersonally, I think it is a mistake that the validator isn't more complete,\nsince once an author's page is \"validated\" they will stop looking for problems.\n\nb) It would be good, if having identified sites with invalid pages, or perhaps\nless desirable (I presume) transitional pages, they were asked and had the\nopportunity to offer comments on what prevents them from upgrading and\ncomplying.\nThe information could be used to address the obstacles.\n\nI find that the removal of certain features from the standard is a reason for\nnot moving to more recent standards.\nI have in mind the ability to force a page to open in a new window, and others.\n\nRegardless of the arguments for a feature's removal, if authors find it\ndesirable, then it becomes a motivation for not upgrading.\n\nNote my point is not (here anyway) to lobby for a change to the standards, but\nto incorproate into these surveys the opportunities to get insight and\nexplanations for the behaviors found. The info can help the design of future\nstandards or the development of tools to improve migration and upgrading.\n\ntex\n\n\n\n\n\nKarl Dubost wrote:\n> \n> Hi,\n> \n> This discussion start to be really interesting. I have started to\n> factorize the information at this place\n> \n>         http://esw.w3.org/topic/QA/ValidatorStatistics\n> \n> You are welcome to contribute.\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898  mailto:Tex at XenCraft.com\nXen Master         XenCraft           http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Best Practices in HTML Re: The use of W3C standards in Denmark Part I",
            "content": "Le 08 mars 2004, ? 10:54, Tex Texin a ?crit :\n> pages, just validation or disagreement between the page and the DTD. \n> So it is\n> possible for pages to be non-standard or have errors and still \n> validate.\n\nDo you mean with regards to other specifications than HTML like for \nexample accessibility?\nor with regards to the semantics defined in each HTML specifications \n(taking into account, there's no conformance section defining that an \nHTML document MUST respect the Semantics of HTML.)\n\nDo you have something else in mind?\n\n> Perhaps there is a need for a \"checker\" which attempts to identify all \n> possible\n> violations of relevant w3c standards.\n\nWhat kind of checker would you imagine? How will it operate? \nAutomatically, manually?\n\n> Note my point is not (here anyway) to lobby for a change to the \n> standards, but\n> to incorproate into these surveys the opportunities to get insight and\n> explanations for the behaviors found. The info can help the design of \n> future\n> standards or the development of tools to improve migration and \n> upgrading.\n\nYou could contribute to the Mailing list www-html@w3.org or you could \nexplore possibilities of good markup for HTML.\n\nhttp://esw.w3.org/topic/HTMLBestPractices\n\nSomeone has already started that and with the contribution of many \npeople, he has explored HTML Markup. I'm pretty sure, it could be \npushed a bit further.\n\nhttp://www.simplebits.com/bits/simplequiz/\n\nHe will publish a book (PS: I don't know if all people who have \nparticipated in the comments will have money in return or at least a \nfree copy of the book ;)).\n\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark Part I",
            "content": "* Karl Dubost wrote:\n>or with regards to the semantics defined in each HTML specifications \n>(taking into account, there's no conformance section defining that an \n>HTML document MUST respect the Semantics of HTML.)\n\nhttp://www.w3.org/TR/html4/conform#didx-HTML_document\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark Part I",
            "content": "Le 08 mars 2004, ? 13:10, Bjoern Hoehrmann a ?crit :\n\n> * Karl Dubost wrote:\n>> or with regards to the semantics defined in each HTML specifications\n>> (taking into account, there's no conformance section defining that an\n>> HTML document MUST respect the Semantics of HTML.)\n>\n> http://www.w3.org/TR/html4/conform#didx-HTML_document\n\n\n;) Yes Except that for example\n\nhttp://www.w3.org/TR/html4/struct/global.html#edef-ADDRESS\n\n\"\"\"The ADDRESS element may be used by authors to\nsupply contact information for a document or a major\npart of a document such as a form. This element often\nappears at the beginning or end of a document.\"\"\"\n\nAnd has you pointed it in\nhttp://www.w3.org/TR/html4/conform#didx-HTML_document\n\"\"\"An HTML document is an SGML document that\nmeets the constraints of this specification.\"\"\"\n\nAnd in the same page\n\n\"\"\"The key words \"MUST\", \"MUST NOT\", \"REQUIRED\",\n\"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\",\n\"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\ndocument are to be interpreted as described in\n[RFC2119]. However, for readability, these words\ndo not appear in all uppercase letters in this\nspecification.\"\"\"\n\nWhich makes for ADDRESS element a MAY.\nhttp://www.ietf.org/rfc/rfc2119.txt\n\n\"\"\"5. MAY   This word, or the adjective\n\"OPTIONAL\", mean that an item is truly\noptional.\"\"\"\n\nSo you might come as best with a warning. :)\n\n\nI have already an exercise with this game.\nhttp://lists.w3.org/Archives/Public/www-qa/2003Mar/0093\n\nI have not done the MAY.\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark Part I",
            "content": "* Karl Dubost wrote:\n>http://www.w3.org/TR/html4/struct/global.html#edef-ADDRESS\n>\n>\"\"\"The ADDRESS element may be used by authors to\n>supply contact information for a document or a major\n>part of a document such as a form. This element often\n>appears at the beginning or end of a document.\"\"\"\n\n>Which makes for ADDRESS element a MAY.\n>http://www.ietf.org/rfc/rfc2119.txt\n\nYes, I am not required to use <address> for contact information, I can\nuse <p> instead or omit contact information from the document. Is there\nanything in HTML 4.01 that allows to use the <address> element for non-\ncontact information (which seems to be your point?)\n\n>I have already an exercise with this game.\n>http://lists.w3.org/Archives/Public/www-qa/2003Mar/0093\n\nIt would also be an interesting exercice to figure out whether\n\n  * http://lists.w3.org/Archives/Public/www-qa/2003Mar/0093\n  * http://lists.w3.org/Archives/Public/www-qa/2003Mar/thread.html\n\nviolate (implicit or explicit) MUSTs or SHOULDs of the relevant\nspecifications...\n\n\n\n"
        },
        {
            "subject": "Backward Compatibl",
            "content": "I'm struggling with a question for the last month, and I would like to \nhear your opinion on it.\n\n* What do we mean when we say backward compatible in the context of the \nWeb?\n* How would you define it?\n* Do you define it with regards\n- to the specifications?\n- to the tools?\n- to the authoring techniques?\n\nRef:\n\nkarl% dict compatible\n*** Source: WordNet (r) 2.0 ***\ncompatible\n      3: capable of being used with or connected to other devices or\n         components without modification [ant: {incompatible}]\n\nkarl% dict backward\n*** Source: WordNet (r) 2.0 ***\nbackward\n      adv 1: at or to or toward the back or rear; \"he moved back\";\n             \"tripped when he stepped backward\"; \"she looked\n             rearward out the window of the car\" [syn: {back}, \n{backwards},\n              {rearward}, {rearwards}] [ant: {forward}]\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark Part I",
            "content": "Le 08 mars 2004, ? 13:36, Bjoern Hoehrmann a ?crit :\n> Yes, I am not required to use <address> for contact information, I can\n> use <p> instead or omit contact information from the document. Is there\n> anything in HTML 4.01 that allows to use the <address> element for non-\n> contact information (which seems to be your point?)\n\nYes :)\nAnd it's very important to define what we consider mandatory or not. \nConformance model of a specification is not easy to do, specifically \nwhen it comes to the definition of the semantics of the elements and \ntheir content. And we had comments for the QA Framework that we were \nabusing the RFC 2119 keywords.\n\nI have never seen an XHTML/HTML book explaining how to write HTML not \nby explaining the tags but by explaining the semantics of text and by \nusing the appropriate tags when needed. Maybe it will finally come with \nXHTML 2.0.\n\nThough it would be still worthwhile to write one for XHTML 1.0. I \nremember to have discussed the topic in the past with (2 years ago) \nwith Molly?Holzschlag. (ah... If I had more time).\n\nOn the validation topic from a secret informer on my messenger, with \ncontenunu  <humour/> secret name has given me these interesting links\n\nhttp://www.naarvoren.nl/artikel/high_accessibility.html\nhttp://fawny.org/blog/2003/09/?fawnyblog#explain\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark Part   I",
            "content": "Karl,\n\nIt could be the philosophy behind the validator has changed, but in Nov. 2002,\nI reported that the validator did not check for problems such as links to\nfragments that do not exist. (e.g. <a href=\"#tex\"> with no corresponding id=tex\nor name=tex in the document).\nAt the time it was stated that it wasn't a priority for the validator to find\nproblems such as this, unless it was covered by the DTD. i.e. strictly speaking\nit wasn't a validation problem.\n\n(Nov 2002 on the www-validator list.)\n\nSo my understanding is that just because a page validates, it doesn't mean that\nit is likely error-free.\n\ntex\n\n\nKarl Dubost wrote:\n> \n> Le 08 mars 2004, ? 10:54, Tex Texin a ?crit :\n> > pages, just validation or disagreement between the page and the DTD.\n> > So it is\n> > possible for pages to be non-standard or have errors and still\n> > validate.\n> \n> Do you mean with regards to other specifications than HTML like for\n> example accessibility?\n> or with regards to the semantics defined in each HTML specifications\n> (taking into account, there's no conformance section defining that an\n> HTML document MUST respect the Semantics of HTML.)\n> \n> Do you have something else in mind?\n> \n> > Perhaps there is a need for a \"checker\" which attempts to identify all\n> > possible\n> > violations of relevant w3c standards.\n> \n> What kind of checker would you imagine? How will it operate?\n> Automatically, manually?\n> \n> > Note my point is not (here anyway) to lobby for a change to the\n> > standards, but\n> > to incorproate into these surveys the opportunities to get insight and\n> > explanations for the behaviors found. The info can help the design of\n> > future\n> > standards or the development of tools to improve migration and\n> > upgrading.\n> \n> You could contribute to the Mailing list www-html@w3.org or you could\n> explore possibilities of good markup for HTML.\n> \n>         http://esw.w3.org/topic/HTMLBestPractices\n> \n> Someone has already started that and with the contribution of many\n> people, he has explored HTML Markup. I'm pretty sure, it could be\n> pushed a bit further.\n> \n>         http://www.simplebits.com/bits/simplequiz/\n> \n> He will publish a book (PS: I don't know if all people who have\n> participated in the comments will have money in return or at least a\n> free copy of the book ;)).\n> \n> --\n> Karl Dubost - http://www.w3.org/People/karl/\n> W3C Conformance Manager\n> *** Be Strict To Be Cool ***\n> \n>   -------------------------------------------------------------------------------\n>                  Name: PGP.sig\n>    PGP.sig       Type: application/pgp-signature\n>              Encoding: 7bit\n>           Description: =?ISO-8859-1?Q?Ceci_est_une_signature_=E9lectronique_PGP?=\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898  mailto:Tex at XenCraft.com\nXen Master         XenCraft           http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark Part   I",
            "content": "Le 08 mars 2004, ? 14:59, Tex Texin a ?crit :\n> It could be the philosophy behind the validator has changed, but in \n> Nov. 2002,\n> I reported that the validator did not check for problems such as links \n> to\n> fragments that do not exist. (e.g. <a href=\"#tex\"> with no \n> corresponding id=tex\n> or name=tex in the document).\n> At the time it was stated that it wasn't a priority for the validator \n> to find\n> problems such as this, unless it was covered by the DTD. i.e. strictly \n> speaking\n> it wasn't a validation problem.\n\nI think \"link checker\" verifies this type of mistakes: internal links \nof a document\nhttp://validator.w3.org/checklink\n\nWould you be interested to\n1. make the list of all requirements MUST, MAY, SHOULD, etc included \nin the HTML Spec. (MUST are already done, see my previous message.)\n2. give an example on what do you think a validator should work with \nsuch a list. Implementation requirements for the validator to be able \nto detect or warn users.\n\nIt can be a collective  effort of the mailing list. Though I'm not sure \nof the right forum for that? public-qa-dev? www-qa? or here?\n\nOlivier, what do you think about it?\n\n\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "SWADEurope WP 10 Deliverable 10.1 Scalability and Storage: Survey of           Free Software / Open Source RDF storage system",
            "content": "I've completed the first version of this survey report which is\nnow available at\n\n  http://www.w3.org/2001/sw/Europe/reports/rdf_scalable_storage_report/\n\nand will be updated over the SWADE project life.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark   Part   I",
            "content": "Karl,\n\nI guess the gist of what I would be looking for as an author, and as someone\nseeking greater W3C standards compliance, would be a \"checker\" that is not so\ncompartmentalized (eg only does links) and simply reports all possible errors.\n\nI understand this is a difficult request, but I do think it confuses people\nthat they run a validator and yet still undetected and common errors remain.\nRunning separately a validator, and a link checker, and an embedded css\nchecker, suggests that after a lot of checking, other categories of errors\nstill exist and it seems to dilute the value of the effort.\n\nThe solution could be as simple as define a common program interface that\nallows people to integrate checking tools and have one command that verifies a\npage using an extensible list of tools, or perhaps verifies an entire web site.\nOthers could then write additional checkers that share the interface (eg i18n,\nwai, or other checkers).\nIt would also be easier to integrate checking with authoring tools. (A menu\nitem could launch a thorough check.)\n\nAs for your question-\na) list all requirements- my understanding is many of the needed checks are on\ntodo lists...\nI think if a start was made on the list of additional checks people would like\nto have, plenty of input would be offered. ;-)\n\nb) example of what a validator should work with- I am not sure I understand the\nquestion.\nPerhaps the description above captures the sense of what I would like.\nMy goal is really not much more than than to identify common errors in pages\nwith a single tool and not be in the business of collecting multiple tools to\nperform different aspects of what might be considered a single task.\n\nc) a list for discussion would be good.\nI would like to see 2 types of discussion. Perhaps it should be separate lists.\n1) list for more thorough and integrated checking tool, as discussed.\n\n2) a place for people to discuss obstacles to upgrading to more recent\nstandards or to being fully compliant, and potential workarounds or solutions.\nThis might help us understand how to eliminate the (perhaps perceived)\nobstacles.\nFor example, I have heard the arguments for why authors shouldn't specify a new\nwindow vs reusing an existing window.\nNevertheless, I prefer to make the choice in my pages and therefore it is an\nobstacle to moving from transitional to strict dtd. I'd like to discuss\nsolutions so I can be strict without giving up something I see as important.\n\nNote, I am not trying to argue this particular point now, on this list. I am\ngiving an example of issues that a discussion list might be useful to develop\nideas to move people forward more quickly.\n\nhth\ntex\n\n\nKarl Dubost wrote:\n> \n> Le 08 mars 2004, ? 14:59, Tex Texin a ?crit :\n> > It could be the philosophy behind the validator has changed, but in\n> > Nov. 2002,\n> > I reported that the validator did not check for problems such as links\n> > to\n> > fragments that do not exist. (e.g. <a href=\"#tex\"> with no\n> > corresponding id=tex\n> > or name=tex in the document).\n> > At the time it was stated that it wasn't a priority for the validator\n> > to find\n> > problems such as this, unless it was covered by the DTD. i.e. strictly\n> > speaking\n> > it wasn't a validation problem.\n> \n> I think \"link checker\" verifies this type of mistakes: internal links\n> of a document\n>         http://validator.w3.org/checklink\n> \n> Would you be interested to\n>         1. make the list of all requirements MUST, MAY, SHOULD, etc included\n> in the HTML Spec. (MUST are already done, see my previous message.)\n>         2. give an example on what do you think a validator should work with\n> such a list. Implementation requirements for the validator to be able\n> to detect or warn users.\n> \n> It can be a collective  effort of the mailing list. Though I'm not sure\n> of the right forum for that? public-qa-dev? www-qa? or here?\n> \n> Olivier, what do you think about it?\n> \n> --\n> Karl Dubost - http://www.w3.org/People/karl/\n> W3C Conformance Manager\n> *** Be Strict To Be Cool ***\n> \n>   -------------------------------------------------------------------------------\n>                  Name: PGP.sig\n>    PGP.sig       Type: application/pgp-signature\n>              Encoding: 7bit\n>           Description: =?ISO-8859-1?Q?Ceci_est_une_signature_=E9lectronique_PGP?=\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898  mailto:Tex at XenCraft.com\nXen Master         XenCraft           http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark    Part   I",
            "content": "I agree with Tex. Ideally, there needs to be one validator that is as\ncomplete as possible for a given environment. For example, online\nchecks could include link checks and HTTP compliance/robustness checks\nas an option. If that validator can accept plugins to validate new\nthings, the validator development can be more distributed. However,\nfrom a validator user point of view, it does not really matter.\n\nI would also add that it would be great if that validator can be\ninstalled as a local library of some kind, to be integrated with\ncontent development and content generation tools. This requirement\nimplies writing Perl and other wrappers and/or providing a local\nservice with a simple socket interface.\n\nThe output can be a very simple XML output (error ID, location,\ninformal text), I guess. Sophisticated wrappers can be added in some\nenvironments to provide nice rendering and additional features such as\nlinks to specs.\n\nAlex.\n\n\nOn Tue, 9 Mar 2004, Tex Texin wrote:\n\n>\n> Karl,\n>\n> I guess the gist of what I would be looking for as an author, and as someone\n> seeking greater W3C standards compliance, would be a \"checker\" that is not so\n> compartmentalized (eg only does links) and simply reports all possible errors.\n>\n> I understand this is a difficult request, but I do think it confuses people\n> that they run a validator and yet still undetected and common errors remain.\n> Running separately a validator, and a link checker, and an embedded css\n> checker, suggests that after a lot of checking, other categories of errors\n> still exist and it seems to dilute the value of the effort.\n>\n> The solution could be as simple as define a common program interface that\n> allows people to integrate checking tools and have one command that verifies a\n> page using an extensible list of tools, or perhaps verifies an entire web site.\n> Others could then write additional checkers that share the interface (eg i18n,\n> wai, or other checkers).\n> It would also be easier to integrate checking with authoring tools. (A menu\n> item could launch a thorough check.)\n>\n> As for your question-\n> a) list all requirements- my understanding is many of the needed checks are on\n> todo lists...\n> I think if a start was made on the list of additional checks people would like\n> to have, plenty of input would be offered. ;-)\n>\n> b) example of what a validator should work with- I am not sure I understand the\n> question.\n> Perhaps the description above captures the sense of what I would like.\n> My goal is really not much more than than to identify common errors in pages\n> with a single tool and not be in the business of collecting multiple tools to\n> perform different aspects of what might be considered a single task.\n>\n> c) a list for discussion would be good.\n> I would like to see 2 types of discussion. Perhaps it should be separate lists.\n> 1) list for more thorough and integrated checking tool, as discussed.\n>\n> 2) a place for people to discuss obstacles to upgrading to more recent\n> standards or to being fully compliant, and potential workarounds or solutions.\n> This might help us understand how to eliminate the (perhaps perceived)\n> obstacles.\n> For example, I have heard the arguments for why authors shouldn't specify a new\n> window vs reusing an existing window.\n> Nevertheless, I prefer to make the choice in my pages and therefore it is an\n> obstacle to moving from transitional to strict dtd. I'd like to discuss\n> solutions so I can be strict without giving up something I see as important.\n>\n> Note, I am not trying to argue this particular point now, on this list. I am\n> giving an example of issues that a discussion list might be useful to develop\n> ideas to move people forward more quickly.\n>\n> hth\n> tex\n>\n>\n> Karl Dubost wrote:\n> >\n> > Le 08 mars 2004, ? 14:59, Tex Texin a ?crit :\n> > > It could be the philosophy behind the validator has changed, but in\n> > > Nov. 2002,\n> > > I reported that the validator did not check for problems such as links\n> > > to\n> > > fragments that do not exist. (e.g. <a href=\"#tex\"> with no\n> > > corresponding id=tex\n> > > or name=tex in the document).\n> > > At the time it was stated that it wasn't a priority for the validator\n> > > to find\n> > > problems such as this, unless it was covered by the DTD. i.e. strictly\n> > > speaking\n> > > it wasn't a validation problem.\n> >\n> > I think \"link checker\" verifies this type of mistakes: internal links\n> > of a document\n> >         http://validator.w3.org/checklink\n> >\n> > Would you be interested to\n> >         1. make the list of all requirements MUST, MAY, SHOULD, etc included\n> > in the HTML Spec. (MUST are already done, see my previous message.)\n> >         2. give an example on what do you think a validator should work with\n> > such a list. Implementation requirements for the validator to be able\n> > to detect or warn users.\n> >\n> > It can be a collective  effort of the mailing list. Though I'm not sure\n> > of the right forum for that? public-qa-dev? www-qa? or here?\n> >\n> > Olivier, what do you think about it?\n> >\n> > --\n> > Karl Dubost - http://www.w3.org/People/karl/\n> > W3C Conformance Manager\n> > *** Be Strict To Be Cool ***\n> >\n> >   -------------------------------------------------------------------------------\n> >                  Name: PGP.sig\n> >    PGP.sig       Type: application/pgp-signature\n> >              Encoding: 7bit\n> >           Description: =?ISO-8859-1?Q?Ceci_est_une_signature_=E9lectronique_PGP?=\n>\n> --\n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898  mailto:Tex at XenCraft.com\n> Xen Master         XenCraft           http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark   Part   I",
            "content": "Le 09 mars 2004, ? 12:24, Tex Texin a ?crit :\n> The solution could be as simple as define a common program interface \n> that\n> allows people to integrate checking tools and have one command that \n> verifies a\n\nAgreed with an integrated tool but it takes a lot of efforts and a lot \nof resources and engineering to create. Do not forget that the \nvalidator is a volunteer effort. It is developed by valuable people who \nare not counting their time and make it true.\n\nWithout volunteers:\n\nTerje Bless, Bj?rn H?hrmann, Nick Kew,  Ville Skytt?\n\nand Olivier Thereaux (W3C), there would be no progress at all on the \nvalidator.\nSee the full list (http://validator.w3.org/about.html)\n\nA common API would be valuable.\n\nCSS Validator is a java program\nMarkUp Validator is a perl program\nLink checker is a perl program\n\nYou have other validators around too like the RDF, there's a new one \ndevelopped outside of W3C which is an XForms Validator (still \nexperimental).\nhttp://xformsinstitute.com/validator/\n\n> page using an extensible list of tools, or perhaps verifies an entire \n> web site.\n> Others could then write additional checkers that share the interface \n> (eg i18n,\n> wai, or other checkers).\n\nEARL as a reporting language can do that for the report and combine \nresults.\nAs an input usually you have a file or an URI, there's nothing much you \ncan do.\n\n> It would also be easier to integrate checking with authoring tools. (A \n> menu\n> item could launch a thorough check.)\n\nMany tools already do that. They are sending files to the validators or \nthey have syntax checking (like BBEdit), or they have local validation \n(like emacs)\n\n> As for your question-\n> a) list all requirements- my understanding is many of the needed \n> checks are on\n> todo lists...\n> I think if a start was made on the list of additional checks people \n> would like\n> to have, plenty of input would be offered. ;-)\n\nUntil now you said: internal links, which can be easily checked \nautomatically.\n\nWith regards to the desires of a HTML checker:\n\n* How do you check that a \"blockquote\" is used for making a citation?\n* What kind of ouput would you like to see of such a tool?\n* How would you test the different requirement of that section?\n\n\"\"\"\nFor example, to specify that the character\nencoding of the current document is \"EUC-JP\",\na document should include the following META\ndeclaration:\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=EUC-JP\">\nThe META declaration must only be used when\nthe character encoding is organized such that\nASCII-valued bytes stand for ASCII characters\n(at least until the META element is parsed).\nMETA declarations should appear as early as possible in the HEAD \nelement.\n\"\"\"\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark   Part   I",
            "content": "Le 09 mars 2004, ? 12:24, Tex Texin a ?crit :\n> The solution could be as simple as define a common program interface \n> that\n> allows people to integrate checking tools and have one command that \n> verifies a\n\nAgreed with an integrated tool but it takes a lot of efforts and a lot \nof resources and engineering to create. Do not forget that the \nvalidator is a volunteer effort. It is developed by valuable people who \nare not counting their time and make it true.\n\nWithout volunteers:\n\nTerje Bless, Bj?rn H?hrmann, Nick Kew,  Ville Skytt?\n\nand Olivier Thereaux (W3C), there would be no progress at all on the \nvalidator.\nSee the full list (http://validator.w3.org/about.html)\n\nA common API would be valuable.\n\nCSS Validator is a java program\nMarkUp Validator is a perl program\nLink checker is a perl program\n\nYou have other validators around too like the RDF, there's a new one \ndevelopped outside of W3C which is an XForms Validator (still \nexperimental).\nhttp://xformsinstitute.com/validator/\n\n> page using an extensible list of tools, or perhaps verifies an entire \n> web site.\n> Others could then write additional checkers that share the interface \n> (eg i18n,\n> wai, or other checkers).\n\nEARL as a reporting language can do that for the report and combine \nresults.\nAs an input usually you have a file or an URI, there's nothing much you \ncan do.\n\n> It would also be easier to integrate checking with authoring tools. (A \n> menu\n> item could launch a thorough check.)\n\nMany tools already do that. They are sending files to the validators or \nthey have syntax checking (like BBEdit), or they have local validation \n(like emacs)\n\n> As for your question-\n> a) list all requirements- my understanding is many of the needed \n> checks are on\n> todo lists...\n> I think if a start was made on the list of additional checks people \n> would like\n> to have, plenty of input would be offered. ;-)\n\nUntil now you said: internal links, which can be easily checked \nautomatically.\n\nWith regards to the desires of a HTML checker:\n\n* How do you check that a \"blockquote\" is used for making a citation?\n* What kind of ouput would you like to see of such a tool?\n* How would you test the different requirement of that section?\n\n\"\"\"\nFor example, to specify that the character\nencoding of the current document is \"EUC-JP\",\na document should include the following META\ndeclaration:\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=EUC-JP\">\nThe META declaration must only be used when\nthe character encoding is organized such that\nASCII-valued bytes stand for ASCII characters\n(at least until the META element is parsed).\nMETA declarations should appear as early as possible in the HEAD \nelement.\n\"\"\"\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark     Part   I",
            "content": "Karl,\n\nThe efforts of the volunteers and the limits of those resources are\nappreciated.\nThe alternative to the integrated modular approach is to simply put more checks\nin the existing validator, and have a strategy that allows more error detection\nthan validating against a dtd and catching other frequent errors.\nThis is lower cost to implement, but has its own drawbacks.\n\nI am not sure why you asked about blockquote. It is often used for purposes\nother than citation, so I am not sure I would check for that.\n\nHowever, being an i18n bigot, I don't have a problem with reporting errors that\nthe meta statement should be first among meta statements, and the encoding\nshould match the declaration (to the extent it can be verified), etc.\nand the encoding should be declared...\n;-)\n\nIn any event, I understand that you would like suggestions on output formats\nand the like, but I am concerned that report formats, integration, and other\nissues, are tangential to my request and a distraction. Fundamentally, I am\njust looking for detection of other kinds of frequently occurring errors beyond\ndtd validation, and I am happy with whatever can be easily detected. So if\nblockquotes being used for something other than citations is hard to detect,\nthere are still others that can be detected and useful to report... Maybe the\napproach should not be to review the standard for all possible violations, but\nto identify problems that vendors have had to contend with and checking for\nthese real world, typical mistakes.\n\nhth\ntex\n\n\nKarl Dubost wrote:\n> \n> Le 09 mars 2004, ? 12:24, Tex Texin a ?crit :\n> > The solution could be as simple as define a common program interface\n> > that\n> > allows people to integrate checking tools and have one command that\n> > verifies a\n> \n> Agreed with an integrated tool but it takes a lot of efforts and a lot\n> of resources and engineering to create. Do not forget that the\n> validator is a volunteer effort. It is developed by valuable people who\n> are not counting their time and make it true.\n> \n> Without volunteers:\n> \n>         Terje Bless, Bj?rn H?hrmann, Nick Kew,  Ville Skytt?\n> \n> and Olivier Thereaux (W3C), there would be no progress at all on the\n> validator.\n> See the full list (http://validator.w3.org/about.html)\n> \n> A common API would be valuable.\n> \n> CSS Validator is a java program\n> MarkUp Validator is a perl program\n> Link checker is a perl program\n> \n> You have other validators around too like the RDF, there's a new one\n> developped outside of W3C which is an XForms Validator (still\n> experimental).\n>         http://xformsinstitute.com/validator/\n> \n> > page using an extensible list of tools, or perhaps verifies an entire\n> > web site.\n> > Others could then write additional checkers that share the interface\n> > (eg i18n,\n> > wai, or other checkers).\n> \n> EARL as a reporting language can do that for the report and combine\n> results.\n> As an input usually you have a file or an URI, there's nothing much you\n> can do.\n> \n> > It would also be easier to integrate checking with authoring tools. (A\n> > menu\n> > item could launch a thorough check.)\n> \n> Many tools already do that. They are sending files to the validators or\n> they have syntax checking (like BBEdit), or they have local validation\n> (like emacs)\n> \n> > As for your question-\n> > a) list all requirements- my understanding is many of the needed\n> > checks are on\n> > todo lists...\n> > I think if a start was made on the list of additional checks people\n> > would like\n> > to have, plenty of input would be offered. ;-)\n> \n> Until now you said: internal links, which can be easily checked\n> automatically.\n> \n> With regards to the desires of a HTML checker:\n> \n> * How do you check that a \"blockquote\" is used for making a citation?\n> * What kind of ouput would you like to see of such a tool?\n> * How would you test the different requirement of that section?\n> \n>         \"\"\"\n>         For example, to specify that the character\n>         encoding of the current document is \"EUC-JP\",\n>         a document should include the following META\n>         declaration:\n> <META http-equiv=\"Content-Type\" content=\"text/html; charset=EUC-JP\">\n>         The META declaration must only be used when\n>         the character encoding is organized such that\n>         ASCII-valued bytes stand for ASCII characters\n>         (at least until the META element is parsed).\n>         META declarations should appear as early as     possible in the HEAD\n> element.\n>         \"\"\"\n> \n> --\n> Karl Dubost - http://www.w3.org/People/karl/\n> W3C Conformance Manager\n> *** Be Strict To Be Cool ***\n> \n>   -------------------------------------------------------------------------------\n>                  Name: PGP.sig\n>    PGP.sig       Type: application/pgp-signature\n>              Encoding: 7bit\n>           Description: =?ISO-8859-1?Q?Ceci_est_une_signature_=E9lectronique_PGP?=\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898  mailto:Tex at XenCraft.com\nXen Master         XenCraft           http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: Best Practices in HTML Re: The use of W3C standards in Denmark   Part   I",
            "content": "Hi Karl\n   Checkers, validators will be developed by both commercial vendors and by\nthe open source community, such as the W3C tools.\n   It strikes me that something that is needed is a test suite for such\ncheckers.  For example I ran link checkers for several years before finding\nout (using the W3C link checker) that the tool was not checking for broken\nlinks in the <LINK> element.\n   So a link checker should check for link in A, IMG, FRAME, IFRAME, etc.\nHTML elements, links generated in JavaScript, links in personalised/dynamic\npages (e.g. user-agent negotiation, language negotiation, etc.)\n   I think it would be useful if W3C could produce a test suite containing a\nrange of errors, which users & developers of checking software would test\ntheir programs against.\n\nBrian\n\n---------------------------------------\nBrian Kelly\nUK Web Focus\nUKOLN\nUniversity of Bath \nBATH\nBA2 7AY\nEmail: B.Kelly@ukoln.ac.uk\nWeb: http://www.ukoln.ac.uk/\nPhone: 01225 383943\nFOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf\nFor info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/ \n\n> -----Original Message-----\n> From: public-evangelist-request@w3.org \n> [mailto:public-evangelist-request@w3.org] On Behalf Of Karl Dubost\n> Sent: 09 March 2004 18:00\n> To: public-evangelist@w3.org\n> Subject: Re: Best Practices in HTML Re: The use of W3C \n> standards in Denmark Part II\n> \n> \n> Le 09 mars 2004, ? 12:24, Tex Texin a ?crit :\n> > The solution could be as simple as define a common program \n> interface \n> > that allows people to integrate checking tools and have one command \n> > that verifies a\n> \n> Agreed with an integrated tool but it takes a lot of efforts \n> and a lot of resources and engineering to create. Do not \n> forget that the validator is a volunteer effort. It is \n> developed by valuable people who are not counting their time \n> and make it true.\n> \n> Without volunteers:\n> \n> Terje Bless, Bj?rn H?hrmann, Nick Kew,  Ville Skytt?\n> \n> and Olivier Thereaux (W3C), there would be no progress at all \n> on the validator.\n> See the full list (http://validator.w3.org/about.html)\n> \n> A common API would be valuable.\n> \n> CSS Validator is a java program\n> MarkUp Validator is a perl program\n> Link checker is a perl program\n> \n> You have other validators around too like the RDF, there's a \n> new one developped outside of W3C which is an XForms \n> Validator (still experimental).\n> http://xformsinstitute.com/validator/\n> \n> > page using an extensible list of tools, or perhaps verifies \n> an entire \n> > web site.\n> > Others could then write additional checkers that share the \n> interface \n> > (eg i18n, wai, or other checkers).\n> \n> EARL as a reporting language can do that for the report and \n> combine results.\n> As an input usually you have a file or an URI, there's \n> nothing much you can do.\n> \n> > It would also be easier to integrate checking with \n> authoring tools. (A \n> > menu item could launch a thorough check.)\n> \n> Many tools already do that. They are sending files to the \n> validators or they have syntax checking (like BBEdit), or \n> they have local validation (like emacs)\n> \n> > As for your question-\n> > a) list all requirements- my understanding is many of the needed \n> > checks are on todo lists...\n> > I think if a start was made on the list of additional checks people \n> > would like to have, plenty of input would be offered. ;-)\n> \n> Until now you said: internal links, which can be easily \n> checked automatically.\n> \n> With regards to the desires of a HTML checker:\n> \n> * How do you check that a \"blockquote\" is used for making a citation?\n> * What kind of ouput would you like to see of such a tool?\n> * How would you test the different requirement of that section?\n> \n> \"\"\"\n> For example, to specify that the character\n> encoding of the current document is \"EUC-JP\",\n> a document should include the following META\n> declaration:\n> <META http-equiv=\"Content-Type\" content=\"text/html; charset=EUC-JP\">\n> The META declaration must only be used when\n> the character encoding is organized such that\n> ASCII-valued bytes stand for ASCII characters\n> (at least until the META element is parsed).\n> META declarations should appear as early as \n> possible in the HEAD \n> element.\n> \"\"\"\n> \n> \n> \n> --\n> Karl Dubost - http://www.w3.org/People/karl/ W3C Conformance Manager\n> *** Be Strict To Be Cool ***\n> \n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark   Part   I",
            "content": "Le 10 mars 2004, ? 05:35, Brian Kelly a ?crit :\n>    I think it would be useful if W3C could produce a test suite \n> containing a\n> range of errors, which users & developers of checking software would \n> test\n> their programs against.\n\nYes completely agreed on that. And Olivier Th?reaux has started work \nsince the begining of the year 2004 on that. It will take a bit of \ntime, but it's in the process.\n\nIt's mainly a test suite for the Markup validator, but I'm pretty sure \nthat it will be feasible once the framework organized to have one for \nthe Link Checker. If we create a flexible process, people will be able \nto contribute to the test suite.\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTML Re: The use of W3C standards in Denmark    Part   I",
            "content": "On Wed, 10 Mar 2004, Karl Dubost wrote:\n\n> Le 10 mars 2004, ? 05:35, Brian Kelly a ?crit :\n>\n> >    I think it would be useful if W3C could produce a test suite\n> > containing a range of errors, which users & developers of checking\n> > software would test their programs against.\n>\n> Yes completely agreed on that. And Olivier Th?reaux has started work\n> since the begining of the year 2004 on that. It will take a bit of\n> time, but it's in the process.\n\nAnd who is writing a test suite to test Olivier's test suite?\n\nSeriously, while testing never hurts, and more testing usually\nincreases chances of finding bugs, there is always a point of\ndiminishing returns. I am [pleasantly] surprised to learn that W3C has\nalready built all the first-priority testing tools and is now\ndeveloping tools to test test suites, including its own validators.\n\nIMHO, a large representative collection of known-to-be-valid and\nknown-to-be-invalid documents that are related to W3C standards would\nindeed be a vary valuable resource for validator authors and beyond. A\ntest suite to test test suites should be a much lower priority.\n\nAlex.\n\n-- \nProtocol performance, functionality, and reliability testing.\nTools, services, and know-how.\nhttp://www.measurement-factory.com/\n\n\n\n"
        },
        {
            "subject": "HTML Test Suit",
            "content": "Le 10 mars 2004, ? 10:48, Alex Rousskov a ?crit :\n> IMHO, a large representative collection of known-to-be-valid and\n> known-to-be-invalid documents that are related to W3C standards would\n> indeed be a vary valuable resource for validator authors and beyond. A\n> test suite to test test suites should be a much lower priority.\n\nhmmm. This exists for a long time now for HTML 4.01. But I'm not sure \nit's what you want.\n\nhttp://www.w3.org/MarkUp/Test/\n\nplus http://validator.w3.org/dev/tests/#xml\n\nOlivier is trying to set a framework to automatize everything so it \nwill be easy to run the tests and to collect the results before \nreleasing a new validator version.\n\nFor others markup TS you might have some in \nhttp://www.w3.org/QA/TheMatrix.html\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: HTML Test Suit",
            "content": "On Wed, 10 Mar 2004, Karl Dubost wrote:\n\n> Le 10 mars 2004, ? 10:48, Alex Rousskov a ?crit :\n>\n> > IMHO, a large representative collection of known-to-be-valid and\n> > known-to-be-invalid documents that are related to W3C standards\n> > would indeed be a vary valuable resource for validator authors and\n> > beyond. A test suite to test test suites should be a much lower\n> > priority.\n>\n> hmmm. This exists for a long time now for HTML 4.01. But I'm not\n> sure it's what you want. http://www.w3.org/MarkUp/Test/\n\nThis would be a part of the large representative collection, useful\nmostly for user agents, not validators. For collection to be more than\nmarginally useful for validators, it has to include lots of documents,\nincluding realistic mixes of HTML, CSS, SVG/etc.,tiny and huge\ndocuments, documents with very complex/deep internal structure, almost\nbroken documents, almost valid documents, broken links, link\nloops/recursion of various kinds, etc., etc. Essentially, it should be\na representative sample of the Web, where each document is classified\nand categorized.\n\n> plus http://validator.w3.org/dev/tests/#xml\n>\n> Olivier is trying to set a framework to automatize everything so it\n> will be easy to run the tests and to collect the results before\n> releasing a new validator version.\n\nThis sounds like a normal tool development QA, not a full blown test\nsuite to test other test suites.\n\nAlex.\n\n\n\n"
        },
        {
            "subject": "Re: Backward Compatibl",
            "content": "It seems the message didn't have the intended success, which may be a \nproof of the difficulty to define the concept.\n\nLe 08 mars 2004, ? 13:41, Karl Dubost a ?crit :\n> I'm struggling with a question for the last month, and I would like to \n> hear your opinion on it.\n>\n> * What do we mean when we say backward compatible in the context of \n> the Web?\n> * How would you define it?\n> * Do you define it with regards\n> - to the specifications?\n> - to the tools?\n> - to the authoring techniques?\n\nTo try to push forward, because many people seem to use it without \nhaving a clear definition of what it is. It seems often like a rabbit \npulled out of a hat.\n\nJeffrey Zeldman said in an article\n\"\"\"There is no true backward compatibility.\"\"\"\n\nin http://www.digital-web.com/features/feature_2002-09.shtml\n\n\"\"\"\nThat this otherwise brilliant company wastes untold bandwidth to \ndeliver a look and feel no one admires says everything you need to know \nabout the entrenched mindset of developers who hold \"backward \ncompatibility\" in higher esteem than reason, usability, or their own \nprofits.\n\nWhat do developers mean by \"backward compatibility?\" They mean using \nnon-standard, proprietary (or deprecated) markup and code to ensure \nthat every visitor has the same experience, whether they're sporting \nNetscape Navigator 1.0 or IE6. Held up as a Holy Grail of professional \ndevelopment practice, \"backward compatibility\" sounds good in theory. \nBut the cost is too high and the practice has always been based on a \nlie.\n\nThere is no true backward compatibility. There is always a cut-off \npoint. For instance, neither Mosaic (the first visual browser) nor \nNetscape 1.0 support HTML table-based layouts. By definition, then, \nthose who use these ancient browsers cannot possibly have the same \nvisual experience as folks who view the Web through later browsers like \nNetscape 1.1 or MSIE2.\n\nDevelopers and clients who strive for backward compatibility inevitably \nchoose a \"baseline browser\" (say, Netscape 3) beyond which they will \nmake no effort. To support that baseline browser and those that \nsucceeded it, developers layer their markup with a series of \nbrowser-specific, non-standard hacks and workarounds that add weight to \nevery page. At the same time, they write multiple scripts to \naccommodate the browsers they've chosen to support, and use browser \ndetection to feed each browser the code it likes best. In so doing, \nthese developers further increase the girth of their pages, pump up the \nload on their servers, and ensure that the race against perpetual \nobsolescence will continue until they run out of money or go out of \nbusiness.\n\"\"\"\n\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Backward Compatibl",
            "content": "Le 10 mars 2004, ? 16:36, Karl Dubost a ?crit :\n> Le 08 mars 2004, ? 13:41, Karl Dubost a ?crit :\n>> I'm struggling with a question for the last month, and I would like \n>> to hear your opinion on it.\n>>\n>> * What do we mean when we say backward compatible in the context of \n>> the Web?\n>> * How would you define it?\n>> * Do you define it with regards\n>> - to the specifications?\n>> - to the tools?\n>> - to the authoring techniques?\n>\n> To try to push forward, because many people seem to use it without \n> having a clear definition of what it is. It seems often like a rabbit \n> pulled out of a hat.\n\nFrom\nhttp://networking.webopedia.com/TERM/B/backward_compatible.html\n\n\"\"\"\nCompatible with earlier models or versions of the same product. A new \nversion of a program is said to be backward compatible if it can use \nfiles and data created with an older version of the same program. A \ncomputer is said to be backward compatible if it can run the same \nsoftware as the previous model of the computer.\n\n  Backward compatibility is important because it eliminates the need to \nstart over when you upgrade to a newer product. A backward-compatible \nword processor, for instance, allows you to edit documents created with \na previous version of the program. In general, manufacturers try to \nkeep all their products backward compatible. Sometimes, however, it is \nnecessary to sacrifice backward compatibility to take advantage of a \nnew technology.\n\n  The flip side of backward compatibility is upward compatibility. \nUpward compatible is the same as backward compatible, except that it is \nfrom the point of view of the older model.\n\n  Another term for backward compatible is downward compatible\n\"\"\"\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Backward Compatibl",
            "content": "The meaning of \"backward compatible\" in the context of the Web is\npretty much the same as in any other broad context. How about this,\nto start with:\n\nBackward compatibility: compatibility between X and Y,\n                        where X existed prior to Y\n\nJust like compatibility, backward compatibility is only defined for\ngiven concepts or objects (X and Y).\n\nAlex.\n\n\nOn Wed, 10 Mar 2004, Karl Dubost wrote:\n\n> It seems the message didn't have the intended success, which may be a\n> proof of the difficulty to define the concept.\n>\n> Le 08 mars 2004, ? 13:41, Karl Dubost a ?crit :\n> > I'm struggling with a question for the last month, and I would like to\n> > hear your opinion on it.\n> >\n> > * What do we mean when we say backward compatible in the context of\n> > the Web?\n> > * How would you define it?\n> > * Do you define it with regards\n> > - to the specifications?\n> > - to the tools?\n> > - to the authoring techniques?\n>\n> To try to push forward, because many people seem to use it without\n> having a clear definition of what it is. It seems often like a rabbit\n> pulled out of a hat.\n>\n> Jeffrey Zeldman said in an article\n> \"\"\"There is no true backward compatibility.\"\"\"\n>\n> in http://www.digital-web.com/features/feature_2002-09.shtml\n>\n> \"\"\"\n> That this otherwise brilliant company wastes untold bandwidth to\n> deliver a look and feel no one admires says everything you need to know\n> about the entrenched mindset of developers who hold \"backward\n> compatibility\" in higher esteem than reason, usability, or their own\n> profits.\n>\n> What do developers mean by \"backward compatibility?\" They mean using\n> non-standard, proprietary (or deprecated) markup and code to ensure\n> that every visitor has the same experience, whether they're sporting\n> Netscape Navigator 1.0 or IE6. Held up as a Holy Grail of professional\n> development practice, \"backward compatibility\" sounds good in theory.\n> But the cost is too high and the practice has always been based on a\n> lie.\n>\n> There is no true backward compatibility. There is always a cut-off\n> point. For instance, neither Mosaic (the first visual browser) nor\n> Netscape 1.0 support HTML table-based layouts. By definition, then,\n> those who use these ancient browsers cannot possibly have the same\n> visual experience as folks who view the Web through later browsers like\n> Netscape 1.1 or MSIE2.\n>\n> Developers and clients who strive for backward compatibility inevitably\n> choose a \"baseline browser\" (say, Netscape 3) beyond which they will\n> make no effort. To support that baseline browser and those that\n> succeeded it, developers layer their markup with a series of\n> browser-specific, non-standard hacks and workarounds that add weight to\n> every page. At the same time, they write multiple scripts to\n> accommodate the browsers they've chosen to support, and use browser\n> detection to feed each browser the code it likes best. In so doing,\n> these developers further increase the girth of their pages, pump up the\n> load on their servers, and ensure that the race against perpetual\n> obsolescence will continue until they run out of money or go out of\n> business.\n> \"\"\"\n>\n>\n>\n> --\n> Karl Dubost - http://www.w3.org/People/karl/\n> W3C Conformance Manager\n> *** Be Strict To Be Cool ***\n>\n\n\n\n"
        },
        {
            "subject": "Re: Backward Compatibl",
            "content": "Sent: Wednesday, March 10, 2004\nSubject: Re: Backward Compatible\n\n Karl writes:\n> It seems the message didn't have the intended success, which may be a\n> proof of the difficulty to define the concept.\n\n\n> > I'm struggling with a question for the last month, and I would like\n> > to hear your opinion on it.\n\n> > * What do we mean when we say backward compatible in the context of\nthe Web?\n\nA possibility: A web designer/developer would like to be Strict to be\nCool. [smile] and follow the rules for HTML 4.01 strict or XHTML1.0\nstrict, etc. They would like to leave behind the deprecated or\nproprietary markup.\n\nThis designer or developer would like to produce well-formed and valid\ndocuments for the web, or for their client[s].\nThe document may need to have any of a variety of rich media file types\nincluded in the document[sound, swf, rich media file types, inline or\nembedded media, etc.]\n\nIf the designer chooses HTML 4.01 strict or XHTML strict version[s],\n<object> is the way to go, ... however, is there any other way can this\nwork, when, where, or if <object> is not supported?\n\nIn this case, the answer may be, there is no way to embed or include\nmedia inline, other than <object>, because <embed> was never included in\na markup version.\n\n> > * How would you define it?\n\nContent still delivers or is available to end user. It appears it may\nhave to be via a download or link in those cases where there is no\nsupport.\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: HTML Test Suit",
            "content": "On Mar 11, 2004, at 05:58, Alex Rousskov wrote:\n>> Olivier is trying to set a framework to automatize everything so it\n>> will be easy to run the tests and to collect the results before\n>> releasing a new validator version.\n>\n> This sounds like a normal tool development QA, not a full blown test\n> suite to test other test suites.\n\nNot a test suite for test suites indeed, but, as you know, testing a \ntest tool brings an additional level of complexity from any \"regular\" \ntesting of a tool being developed.\n\nThat said, testing test suites is an interesting goal, and I hope the \nexperience gained from testing test tools will help us when/if we want \nto go down this road.\n\n-- \nolivier\n\n\n\n\n"
        },
        {
            "subject": "Re: Best Practices in HTM",
            "content": "Tex, all,\n\nTex Texin wrote:\n\n> a) The W3C Validator does not attempt to report all possible errors in \n> web\n> pages, just validation or disagreement between the page and the DTD. \n> So it is\n> possible for pages to be non-standard or have errors and still \n> validate.\n\nValidation is a very specific thing indeed. I'll note that some efforts \nto have the Markup Validator go beyond pure SGML validation in its \nchecking has received a very harsh and negative response. Some purists \nprefer validation to remain validation, period.\n\nThat does not preclude us from integrating several tools, including \nvalidation, into one checker, as you suggest:\n\n> The solution could be as simple as define a common program interface \n> that\n> allows people to integrate checking tools and have one command that \n> verifies a page using an extensible list of tools, or perhaps verifies \n> an entire web site.\n\n...and this is pretty much where the qa-dev team is going, albeit \nslowly...\n\nAs Karl said the effort is mostly done on a voluntary basis, and each \nstep (such as choosing or adapting an existing parser) takes a lot of \ntime. That said,\n\nI think a high-level discussion on the \"ideal integrated Web page \nchecker\" would be a good thing, even now. www-validator@w3.org would be \nthe right forum for that. Tex, would you start such a discussion?\n\nAlso, anyone interested in participating in the development effort (and \nthat does not necessarily mean big time consuming tasks for coding \ngods, quite the contrary) should feel free to contact me directly.\n\n> I would like to see 2 types of discussion. Perhaps it should be \n> separate lists.\n> 1) list for more thorough and integrated checking tool, as discussed.\n\nWe have www-validator for that, reasonably adapted.\n\n> 2) a place for people to discuss obstacles to upgrading to more recent\n> standards or to being fully compliant, and potential workarounds or \n> solutions.\n\nThis list seems appropriate for such a topic, I think.\n\nThanks,\n-- \nolivier\n\n\n\n\n"
        },
        {
            "subject": "Danish companies and the use of W3C standards (new survey",
            "content": "After I have publish (2004-02-28) my danish survey about\ngovernmental/national/municipal authorities and their use of W3C standards\n(HTML/XHTML standards). Then I have got some e-mails with the question\n\"What about Danish private companies and the W3C standards?\". I have now\nmade a minor survey about this issue. \n\nI have made a test on the 250 largest Danish companies home pages.\nThe picture is\n\n62 % is missing the DOCTYPE-Declaration\n25 % have problems with encoding\n\nOnly one company  did  follow the W3C standard 100 %. This gives 0.4 % of\nall the 250 tested home pages\n\nDanish companies and the use of W3C standards (2004-03-16)\nEnglish summary and major findings can be viewed at \nhttp://www.ae35-unit.dk/standard/danishcompanies.html \n\nSoren Johannessen\n\n\n\n"
        },
        {
            "subject": "Re: Danish companies and the use of W3C standards (new survey",
            "content": "Hi Soren,\n\nLe 16 mars 2004, ? 06:03, Soren Johannessen a ?crit :\n> Danish companies and the use of W3C standards (2004-03-16)\n> English summary and major findings can be viewed at\n> http://www.ae35-unit.dk/standard/danishcompanies.html\n\nAnother interesting document I think if we publish a method and \ntools/templates to create such a survey, It might be possible to \nencourage people to do the same in their own country. I'm pretty sure \nfor example the interop group in France would be happy to run such a \nsurvey.\n\nIt might also help us to identify where the efforts are needed and it \nwill attract the press on such results.\n\n\n* Is there a small group of volunteers on this mailing list to start \nsuch a guide?\n\nThe thread we already had on the list will make it easier to write.\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "Re: Danish companies and the use of W3C standards (new survey",
            "content": "* Karl Dubost wrote:\n>Le 16 mars 2004, ? 06:03, Soren Johannessen a ?crit :\n>> Danish companies and the use of W3C standards (2004-03-16)\n>> English summary and major findings can be viewed at\n>> http://www.ae35-unit.dk/standard/danishcompanies.html\n>\n>Another interesting document I think if we publish a method and \n>tools/templates to create such a survey, It might be possible to \n>encourage people to do the same in their own country.\n\nWell, I've got both..., see \n\nhttp://lists.w3.org/Archives/Public/www-archive/2004Mar/att-0168/ieqacmd-sample-output.txt\n\nfor pretty-printed sample output for the invalid W3C XML\nSchema homepage, <http://www.w3.org/XML/Schema>, and see\n\nhttp://lists.w3.org/Archives/Public/www-archive/2004Mar/0169.html\n\nfor 371 such reports for all W3C Member homepages. I look\nforward to (X)HTML documents generated from the latter :-)\n\nregards.\n\n\n\n"
        },
        {
            "subject": "New Article: Serving XHTML 1.",
            "content": "The GEO task force has published a new article:\n\nServing XHTML 1.0\n\nAt: http://www.w3.org/International/articles/serving-xhtml/\n\n\nThis very briefly describes some, often surprising, aspects of how \nservers send XHTML to the user agent (eg. a browser), and how common \nuser agents handle the markup they receive. This article provides \nbackground information that helps explain why some aspects of CSS \nstyling don't work the way you expect, but also sets the scene for the \napproach you should use for declaring encodings.\n\n\n\n\nYou can find links to internationalization specifications, FAQs, \narticles, tools, tests, and soon tutorials at \nhttp://www.w3.org/International/articles.html\n\n\n\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/\n\nhttp://www.w3.org/International/\nhttp://www.w3.org/International/geo/\n\n\n\n\n"
        },
        {
            "subject": "Multimedial Evangelizatio",
            "content": "Hi,\n\n  Evangelizing Web Standards is getting boring. All we have is dry\nspecifications, some web sites, geeky validators and some badges [1]\nin W3C's 20th century corporate design.\n\nI think it is time to catch up with the Web Accessibility Initiative and\nadvertise Web Standards through Cooler Multimedia [2] which is part of\nW3C's mission [3]. WAI's approach to advertise its deliverables through\nmusic has proven to be very successful [4], hence I propose that the QA\nAcitivity launches a theme song contest as a first step to encourage the\ncommunity to make web standards cooler through music.\n\nThe contest should be public, hence all it takes is setting up a cool\nand convincing contest web site, a submission mailing list, a WBS poll\nto let the community vote on submissions and means to make the public\naware of the contest. For the latter I propose to add a pointer to the\ncontest web site on the various Validator's homepages.\n\n[1] http://www.w3.org/Consortium/Legal/logo-usage-20000308.html\n[2] http://davidmacd.com/web_pages/wcag_theme.htm\n[3] http://www.w3.org/Consortium/Points/\n[4] http://lists.w3.org/Archives/Public/w3c-wai-gl/2003JulSep/0606.html\n\nregards.\n\n\n\n"
        },
        {
            "subject": "Re: Multimedial Evangelization (lyrics ready for a song",
            "content": "Hi\n\nI have wrote down some lyrics for a theme song. I just miss the reggae band,\na lead singer and a chorus. The song is based on Bob Marley's \"One\nlove/People get ready\"\n\nThe chorus sings the text in ()\n\nTitle \"One Web / End Users get ready\"\n\nOne Web! One Standard!\nLet's surf together and feel all right.\nHear the End Users cryin' (One Web!);\nHear the End Users cryin' (One Standard!),\nSayin': give thanks and praise to the W3C and I will feel all right;\nSayin': let's surf together and feel all right. Wo wo-wo wo-wo!\n\nLet them all remove all their dirty markups (One Web!);\nThere is one question I'd really love to ask (One Standard!):\nIs there a place for the hopeless web designer,\nWho has hurt all End Users just to save his own beliefs\n\nOne Web! What about the one Web One Standard!\nWhat about - Let's surf together and feel all right\nAs it was in the beginning (One Web!);\nSo shall it be in the end (One Standard!),\nAll right!\nGive thanks and praise to the W3C and I will feel all right;\nLet's surf together and feel all right.\nOne more thing!\n\nLet's get together to fight this Tag Soup (One Web!),\nSo when the Validator comes there will be no, no errors (One Web!).\nThere ain't no hiding place from the Validator of W3C.\n\nSayin': One Web! What about the One Standard (One Standard!)\nWhat about the - Let's surf together and feel all right.\n\nGive thanks and praise to the W3C and I will feel all right;\nLet's surf together and feel all right.\nGive thanks and praise to the W3C and I will feel all right;\nLet's surf together and feel all right.\n\nRegards\n \n\n\n\n"
        },
        {
            "subject": "Re: Multimedial Evangelization (lyrics ready for a song",
            "content": "I said this many years ago -\n\nWhy can't we all just... get along (html 3.2)?\n\n----- Original Message -----\nFrom: \"Soren Johannessen\" <hal@ae35-unit.dk>\nTo: <public-evangelist@w3.org>\nSent: Tuesday, March 30, 2004 6:47 AM\nSubject: Re: Multimedial Evangelization (lyrics ready for a song)\n\n\n\nHi\n\nI have wrote down some lyrics for a theme song. I just miss the reggae band,\na lead singer and a chorus. The song is based on Bob Marley's \"One\nlove/People get ready\"\n\nThe chorus sings the text in ()\n\nTitle \"One Web / End Users get ready\"\n\nOne Web! One Standard!\nLet's surf together and feel all right.\nHear the End Users cryin' (One Web!);\nHear the End Users cryin' (One Standard!),\nSayin': give thanks and praise to the W3C and I will feel all right;\nSayin': let's surf together and feel all right. Wo wo-wo wo-wo!\n\nLet them all remove all their dirty markups (One Web!);\nThere is one question I'd really love to ask (One Standard!):\nIs there a place for the hopeless web designer,\nWho has hurt all End Users just to save his own beliefs\n\nOne Web! What about the one Web One Standard!\nWhat about - Let's surf together and feel all right\nAs it was in the beginning (One Web!);\nSo shall it be in the end (One Standard!),\nAll right!\nGive thanks and praise to the W3C and I will feel all right;\nLet's surf together and feel all right.\nOne more thing!\n\nLet's get together to fight this Tag Soup (One Web!),\nSo when the Validator comes there will be no, no errors (One Web!).\nThere ain't no hiding place from the Validator of W3C.\n\nSayin': One Web! What about the One Standard (One Standard!)\nWhat about the - Let's surf together and feel all right.\n\nGive thanks and praise to the W3C and I will feel all right;\nLet's surf together and feel all right.\nGive thanks and praise to the W3C and I will feel all right;\nLet's surf together and feel all right.\n\nRegards\n\n\n\n\n\n---\nOutgoing mail does not contain any evil scum virii. (Certified etc.)\nChecked by AVG anti-virus system (http://www.grisoft.com).\nVersion: 6.0.596 / Virus Database: 379 - Release Date: 26/02/2004\n\n\n\n"
        },
        {
            "subject": "Re: Multimedial Evangelizatio",
            "content": "On Mar 26, 2004, at 21:39, Bjoern Hoehrmann wrote:\n> I think it is time to [...] advertise Web Standards through Cooler \n> Multimedia [2]\n\nExcellent idea!\n\nTime for the Web Standards crowd to show its creativity. I have seen \nquite a few efforts showing that you can achieve a cool multimedia Web \nthrough standards, now let's show that Web standards are cool through \nMultimedia.\n\n>  hence I propose that the QA Acitivity launches a theme song contest \n> as a first step to encourage the\n> community to make web standards cooler through music.\n\nSure, let's give everyone one month to give this theme song/music a \ntry, and we'll feature the winner(s) on our site.\nEnough to launch a career, undoubtedly, although skills should not \nmatter as much as originality and creativity, so go and have fun, and \nwe will see.\n\nPeople wanting a playground to hack lyrics, discuss harmonics or plan a \nrecording gig should feel free to hijack the QA Wiki at:\nhttp://esw.w3.org/topic/StandardsAreCool\n\nCheers,\n-- \nolivier\n\n\n\n\n"
        },
        {
            "subject": "AC/WWW 2004 NewYork Availibilit",
            "content": "At the May 3rd QA teleconf, Mark Skall has asked who was going to \nNew-York during the W3C AC Meeting + WWW 2004 Conference.\n\nIf people from the QA WG/IG are willing to share an evening, there \nmight be a possibility to catch up or to organize something all \ntogether. At least a simple dinner or a bar. People from the QA IG \n(www-qa) and public-evangelist are welcome to join.\n\nReply with your presence date, AC, WWW 2004\n\nKarl: May 14 - May 22, AC: No, WWW 2004: Yes\n(busy: May 14 to May 16)\n\nOthers?\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "PHP, Web standards and link",
            "content": "Hi,\n\nI gave a Talk yesterday night in Montreal for PHP Qu?bec about W3C and \nWeb standards and the context of PHP dev, I came with a list of links \nfor the audience. I think it might interest other people too.\n\nPHP Tidy\nhttp://www.coggeshall.org/tidy.php\nSafe HTML Checker\nhttp://simon.incutio.com/archive/2003/02/23/safeHtmlChecker\nhttp://simon.incutio.com/code/php/SafeHtmlChecker.class.php.txt\nStaying Valid\nhttp://simon.incutio.com/archive/2004/05/02/stayingValid\nServe application/xhtml+xml without breaking\nhttp://simon.incutio.com/archive/2003/05/06/knifeEdge\nHTML Syntax Checker in PHP\nhttp://www.hut.fi/u/hsivonen/HTMLSyntaxChecker\nWeblog system PHP+MySQL with validity\nhttp://wordpress.org/\nhttp://www.dotclear.net/\nWiki to XHTML in PHP\nhttp://www.neokraft.net/sottises/wiki2xhtml/\nhttp://ljouanneau.com/softs/wikirenderer/\nPHPTal - Valid templating\nhttp://nyphp.org/content/presentations/3templates/phptal/\nFOAFCorp\nhttp://rdfweb.org/foafcorp/intro.html\nhttp://www.grorg.org/2002/10/foafcorp/\nPHP and Web Standards\nhttp://www.pawscon.com/\nHTML Tody\nhttp://tidy.sourceforge.net/\nPHP and REST\nhttp://www.onlamp.com/pub/a/php/2003/10/30/amazon_rest.html\nDeal with acronyms\nhttp://photomatt.net/scripts/acronymit\nZeldman slides\nhttp://www.happycog.com/lectures/dwws/\nCSS Zen Garden\nhttp://www.csszengarden.com/\nWhy to use iso date on you Web sites\nhttp://www.w3.org/QA/Tips/iso-date\nQA Tips for Webmasters\nhttp://www.w3.org/QA/Tips/\nInternationalization Tutorials and articles\nhttp://www.w3.org/International/tutorials.html\nhttp://www.w3.org/International/articles.html\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n\n"
        },
        {
            "subject": "FYI: new Markup Validator release",
            "content": "... Feel free to spread the word.\nhttp://lists.w3.org/Archives/Public/www-validator/2004May/0014.html\n\nThanks\n-- \nolivier\n\n\n\n\n"
        },
        {
            "subject": "Funny Quote",
            "content": "Funny Quotations\n\nhttp://funny-quotes.blogspot.com\nhttp://woody-allen.blogspot.com\nhttp://george-carlin.blogspot.com\nhttp://johnny_carson.blogspot.com\nhttp://david-letterman.blogspot.com\nhttp://oscar-levant.blogspot.com\nhttp://groucho-marx.blogspot.com\nhttp://mary-richards.blogspot.com\nhttp://joan-rivers.blogspot.com\nhttp://mark-twain.blogspot.com\nhttp://oscar-wilde.blogspot.com\nhttp://henny-youngman.blogspot.com\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "New version of Parser#_",
            "content": "Hi,\n\nSince it looks like this work is going to be part of SWAD Europe, and\nupon Danbri's advice, I'm posting this to this list. I have rewritten\nbig chunks of parser_#5 [1], in order to make it simpler.  It now\ncomes as two XSLT files:\n\n- rdfc14n.xsl, which takes an RDF/XML file and 'canonicalises' it, to\nstriped syntax, adding rdf:Description, turning non rdf attributes on\nresources into sub-elements and so on.\n\n- rdfc2nt.xsl produces, from the output, the n-triples. It is actually a\nsimplified rdf2nt-mf.xsl\n\nThese two passes cannot be done within one XSLT transform (not in pure\nXSLT 1.0, at least), hence the two file.I have tested them on the\nexamples of the RDF/XML spec, but there must be more complex files on\nwhich it chokes.\n\nLet me know if you find bugs, or if you don't but find it useful.\n\n[1] http://www.w3.org/2001/12/rubyrdf/xsltrdf/\n\nMax.\n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Used Formwork/Peri Dok",
            "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n"
        },
        {
            "subject": "New Public mailing list - public-forms-testsuite  maintained by  Thierry Miche",
            "content": "Maintaining Activity:  XForms[1]\n\nPurpose:  XForms testsuite feedback.\n\nReference:  XForms 1.0 Test Suite[2]\n\n\n\n1.  http://www.w3.org/MarkUp/Forms/\n2.  http://www.w3.org/MarkUp/Forms/Test/\n\n\n\n"
        },
        {
            "subject": "Libby mostly 2002-061",
            "content": "[Note:\nI'm writing up what I've been doing for internal communication\npurposes within the ILRT, but I thought it might be helpful also to\nsend it to the SWAD-Europe list as a precedent for regular, informal\ninformation sharing. It will not replace or be used as part of the more\nformal EC reporting proceedures. I'd encourage others to do the same,\nwhether they are directly working under/funded by SWAD-Europe or just\ndoing related work.]\n\nHere are some of the things I've been up to so far this month.\n\n* sorting out the details of the W3C WAI/SWAD-Europe meeting on EARL and\non image annotation. Registration is now closed, but I will report back\nto the public-esw@w3.org list. Nadia is hopefully going to show us some\nRDFPic enhancements; Jim Ley (of SVG image annotation fame) is also\ncoming.\n\nhttp://www.w3.org/2002/05/er-swade-f2f\n\n* looking at query testcases with Danbri and generally cleaning up my\nquery code, including moving to the ARP parser from SiRPAC, and writing\na new Squish Parser using javacc, using an early version of Andy\nSeaborne's parser to learn from. The code is looking better but not\nquite ready for a release. Both Dan and I have query testcases running,\nfor parser and results testing.\n\nhttp://cvs.ilrt.org/cvsweb/inkling/\n\n* chatting with Kate and others about the SWAD-Europe face to face and\nequipment. Ruth and Kate have ordered computers and palms, with helpful\ninput from Dave. We decided to get an experimental iBook as well as a\ndual-boot linux/win DELL laptop. We are struggling with the possible\nsecurity problems of getting a wireless hub.\n\n* writing some experimental Perl code to modularise Martin Hamilton's\nIMesh code.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "setvalu",
            "content": "I am a little confused, I am hoping someone can clarify:\n\nAs per the first assertion made for 10.1.9, \"setvalue actions with no \nmodel+ref or bind attribute MUST be ignored.\" there must be:\n  a: a model and a ref attribute present otherwise the setvalue element is \nignored.\n  or\n  b: a bind attribute present otherwise the setvalue element is ignored.\n\nHowever, in the spec there is no reference made to a model attribute being \nrequired when there is only a ref attribute present, neither is there a \nmodel attribute in the example given with the assertion.\n\nWhich is correct?\n\nSusan\n\n_________________________________________________________________\nThe new MSN 8: advanced junk mail protection and 2 months FREE*  \nhttp://join.msn.com/?page=features/junkmail\n\n\n\n"
        },
        {
            "subject": "tes",
            "content": "please ignore this test\n \nThierry MICHEL\nW3C/ERCIM\n \n\n\n\n"
        },
        {
            "subject": "tes",
            "content": "please ignore this test\n \nThierry MICHEL\nW3C/ERCIM\n \n\n\n\n"
        },
        {
            "subject": "TR : Test case chapter4/016.xm",
            "content": "-----Message d'origine-----\nDe : Michael N. Lipp [mailto:mnl@mnl.de] \nEnvoy? : dimanche 2 mars 2003 15:42\n? : public-forms-testsuite@w3.org\nObjet : Test case chapter4/016.xml\n\n\nHi,\n\nI think test case chapter4/016.xml is wrong. It assumes that instance \ndata is created for a form control because the already existing instance\n\n(arbitrarily) matches the root element created if no instance exists \n(<instanceData/>).\n\nI cannot derive this behaviour from 4.2.5 of the spec. I think \nchapter4/016.xml obviously matches the case \"If the instance referenced \non the form control existed when the first \nxforms-form-control-initialize event is processed: ...\".\n\n  - Michael\n\n\n\n"
        },
        {
            "subject": "Bug in test case c3006a.xm",
            "content": "Hi,\n\nI think there is a bug in test case c3-006a.xml.\n\nConsider the bind elements in the model:\n\n<html xmlns=\"http://www.w3.org/2002/06/xhtml2\"\n       xmlns:xforms=\"http://www.w3.org/2002/xforms/cr\"\n       xmlns:ev=\"http://www.w3.org/2002/xml-events\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"\n       xml:lang=\"en\">\n\n   ...\n\n     <xforms:model id=\"m_001\">\n     <xforms:instance id=\"i_001\" xmlns=\"\">\n     <r>\n     <a>3</a>\n<b>7</b>\n<c>c</c>\n<d>d</d>\n</r>\n     </xforms:instance>\n     <xforms:bind nodeset=\"a\" id=\"i-a\" />\n     <xforms:bind nodeset=\"b\" id=\"i-b\" />\n     <xforms:bind nodeset=\"r/c\" id=\"i-c\" />\n     </xforms:model>\n\nSection 7.3 states in \"rule\" 8 that \"Any namespace declarations in scope \nfor the attribute that defines the expression are applied to the \nexpression\".\n\n\"In scope\" for the \"nodeset\" attributes of the xforms:bind elements is \n(among others) the default namespace \nxmlns=\"http://www.w3.org/2002/06/xhtml2\". Thus the xpath expression in \nthe nodeset attribute results in an empty nodeset, because elements <r> \nand descendants are in the global namespace.\n\nThis is not what is intended here (or have I misunderstood the spec?)\n\n  - Michael Lipp\n\n\n\n"
        },
        {
            "subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico",
            "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n"
        },
        {
            "subject": "Re: Libby mostly 2002-061",
            "content": "Thank you Libby, I for one find this informal information sharing very\nhelpful. Thanks for taking the time to write this up and share this with\nthe rest of the group.\n\n-- \neric miller                              http://www.w3.org/people/em/\nsemantic web activity lead               http://www.w3.org/2001/sw/\nw3c world wide web consortium            http://www.w3.org/\n\n\nOn Tue, 2002-06-18 at 07:50, Libby Miller wrote:\n> \n> \n> [Note:\n> I'm writing up what I've been doing for internal communication\n> purposes within the ILRT, but I thought it might be helpful also to\n> send it to the SWAD-Europe list as a precedent for regular, informal\n> information sharing. It will not replace or be used as part of the more\n> formal EC reporting proceedures. I'd encourage others to do the same,\n> whether they are directly working under/funded by SWAD-Europe or just\n> doing related work.]\n> \n> Here are some of the things I've been up to so far this month.\n> \n> * sorting out the details of the W3C WAI/SWAD-Europe meeting on EARL and\n> on image annotation. Registration is now closed, but I will report back\n> to the public-esw@w3.org list. Nadia is hopefully going to show us some\n> RDFPic enhancements; Jim Ley (of SVG image annotation fame) is also\n> coming.\n> \n> http://www.w3.org/2002/05/er-swade-f2f\n> \n> * looking at query testcases with Danbri and generally cleaning up my\n> query code, including moving to the ARP parser from SiRPAC, and writing\n> a new Squish Parser using javacc, using an early version of Andy\n> Seaborne's parser to learn from. The code is looking better but not\n> quite ready for a release. Both Dan and I have query testcases running,\n> for parser and results testing.\n> \n> http://cvs.ilrt.org/cvsweb/inkling/\n> \n> * chatting with Kate and others about the SWAD-Europe face to face and\n> equipment. Ruth and Kate have ordered computers and palms, with helpful\n> input from Dave. We decided to get an experimental iBook as well as a\n> dual-boot linux/win DELL laptop. We are struggling with the possible\n> security problems of getting a wireless hub.\n> \n> * writing some experimental Perl code to modularise Martin Hamilton's\n> IMesh code.\n> \n> cheers\n> \n> Libby\n> \n\n\n\n"
        },
        {
            "subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico",
            "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n"
        },
        {
            "subject": "offline until september 8, 2003 (automatic reply",
            "content": "I will be offline until September 8. \nThus, your mail regarding\n\n    \"Thank you!\"\n\nmay not be answered until I return.\n\nIf this is of an urgent nature, please\ncontact my assistant, \nJennifer Hodges (formerly Espinoza),\nat jaelyn@ksl.stanford.edu or 650 723-1740.\n\n\n\n"
        },
        {
            "subject": "Re: Beyond the Form",
            "content": "Hi Jerry.\n\nDont forget, that the module for testing the forms need extensive documentation. With that, I \nam willing to take a good part in the further developing of this project.\n\nBye\nTom\n\n\n\n\nText/HTML attachment: LinksX.html\n\n\n\n\n"
        },
        {
            "subject": "Happy Easte",
            "content": "Hi Group.\n\nHappy Easter from down under.\n\nTom (HTML/NoEnc)\n\n\n\n\nText/HTML attachment: LinksX.html\n\n\n\n\n"
        },
        {
            "subject": "Re: Testing agai",
            "content": "Hi Joe.\n\nThe prog that you sent me was working very well. \n\nOnly in the REC.PROC I found some small error, in which you forgot to declare the var \n\"exec\". Keep up the good work.\n\nBye\nTom\n\n--- GoldED/386 2.42.G0614+\n * Origin: Everything goes the bach runter ... \n * http://www.thai-girls.org/cgi-php/DS/index.php\n * http://www.hotels-of.com\n\n\n\n"
        },
        {
            "subject": "International Worksho",
            "content": "Hi all,\n\nFollowing the Kick-off meeting, I am responsible for making sure we organise\nthe International Workshop. We are proposing to hold it on the topic of RDF\nQuerying, in conjunction with the W3C Web Ontology working group meeting in\nBristol 7-8 October.\n\nAt this stage I would propose holding a one day workshop on Wednesday the 9th\nof October, and we hope that Hewlett-Packard could host this workshop.\n\nCheers\n\nCharles McCN\n\n\n\n"
        },
        {
            "subject": "Re: tes",
            "content": "I'm on vacation through Monday, 2 February. In case of emergency,\nI may be available sporadically at +1.206.778.9065. Otherwise, if it\ncan't wait until I return, try contacting Wendy Chisholm (wendy@w3.org)\nor Shawn Henry (shawn@w3.org).\n\n-\nm\n\n\n\n"
        },
        {
            "subject": "hell",
            "content": "Mail transaction failed. Partial message is available.\n\n\n\n\n\n\napplication/octet-stream attachment: doc.zip\n\n\n\n\n"
        },
        {
            "subject": "Re: gdb4.9 and gdb/testsuite failure",
            "content": "> Configuration: configure -v sparc-sun-sunos4.1.1 -norecursion\n> ...\n> I have not seen this posted yet, has any one else tried this?  I had hundreds\n> of failures in the testsuite:\n> \n>                  === gdb Summary ===\n>  \n>  # of expected passes 597\n>  # of expected failures 130\n>  # of unexpected successes 1\n>  # of unexpected failures 836\n>  ../gdb version 4.9 -nx\n\nThis definitely looks like something is wrong somewhere.  For this \nconfiguration there should be no more than about 25 unexpected failures.\n\n> So, can anyone explain to me:\n> \n>  - did I screw up the DejaGnu compile?\n>  - did I screw up the gdb compile?\n\nHard to say, without further information.\n\n>  - is gdb-4.9 that buggy?\n\nNo, at least not for sparc-sun-sunos4.1.1 configurations.  The problem is\nmost likely in dejagnu or the testsuite.\n\n\n\n--- GoldED/386 2.42.G0614+\n * Origin: Everything goes the bach runter ... \n * http://search-engine-log.com\n\n\n\n\n\n\ntext/html attachment: 40602X.html\n\n\n\n\n"
        },
        {
            "subject": "RE: International Worksho",
            "content": "Charles,\n\n> we hope that Hewlett-Packard could host this workshop\n\nNo problem - I have booked a room for 30 people (with tables) all day\nOctober 9th.\n\nThe large conference hall isn't free that day so if you are anticipating\nmore than 30 people then we need to either use two rooms or make other\narrangements.  Let me know how much space you think we need.\n\nAndy\n\n-----Original Message-----\nFrom: Charles McCathieNevile [mailto:charles@w3.org] \nSent: 22 June 2002 11:44\nTo: public-esw@w3.org\nSubject: International Workshop\n\n\n\nHi all,\n\nFollowing the Kick-off meeting, I am responsible for making sure we organise\nthe International Workshop. We are proposing to hold it on the topic of RDF\nQuerying, in conjunction with the W3C Web Ontology working group meeting in\nBristol 7-8 October.\n\nAt this stage I would propose holding a one day workshop on Wednesday the\n9th of October, and we hope that Hewlett-Packard could host this workshop.\n\nCheers\n\nCharles McCN\n\n\n\n"
        },
        {
            "subject": "Re: Used Formwork/Peri Dok",
            "content": "please send prices & fotos\n\n\n\n"
        },
        {
            "subject": "Re: Standard Procedur",
            "content": "Hi John.\n\nAccording to the your Idea to change the report-standard-procedure my suggestion is, that \nthis should be intact and handled in the same way as before.\n\nBye\nTom\n\n\n\n\n\nText/HTML attachment: LinksW3.html\n\n\n\n\n"
        },
        {
            "subject": "RE: fl_do_forms(",
            "content": ">\n> > I have a form that has a xyplot and a hidden button over it, in order\n> > to exit form if you click on it.\n> > The button does not have a callback.\n> > I create multiple instances of the form, but when clicked any of them,\n> > they disappear in reverse order. For example if i open three instances\n> > and i click the first, the therd disappears. I suppose that this is the\n> > right thing to happen, since fl_do_forms() will return there it was\n> > last requested... Can anyone help me, what is the correct way to\n> > treat ths problem???\n>\n> I'm not sure I understand what you're trying to do here, but I think\n> your interpretation of the fl_do_forms() return is incorrect.\n>\n> spl\n>\nSorry, I didn't make clear whats happening...\nI'm making a sort of a calculator (something like xcalc but objects in this form\nhave callbacks, exept from the \"done\" button. When returned, i hide and free the\nform. After that I display a form to enter the xrange etc... Again everything has\nworks differently,\nanyway) and i have the main form, with the display, buttons etc.\nAll objects have callbacks, exept from the menu entry file, which only has an\nexit command. I have a button to create simple plots. When pressed, i display\na form in which you can enter the function to be plotted. All objects in this form\nhave callbacks, exept from the \"done\" button. When returned, i hide and free the\nform. After that I display a form to enter the xrange etc... Again everything has\na callback exept the \"ok\" button and i hide/free this form as soon as it returns.\nAfter that i display the actual form of the plot, which contains a xyplot object\n(no interaction) and a hidden button over it. The button does not have a callback.\nWhat i want to do is when user clicks in the plot, form to disappear. The code in\nthe callback of \"plot\" button of the main form loks like:\n/* display form \"enter function\" */\nfl_do_forms();\n/* some checking */\nfl_do_forms();\n/* some checking */\n/* display form \"plot properties\"*/\nfl_do_forms();\n/* some checking */\n/* calculate arrays to be plotted */\n/* display form \"plot itself\" */\nfl_do_forms();\n/* hide - free \"plot form\" */\nreturn();\n/* end of callback */\n\nBye Thomas\n\n\n--- GoldED/386 2.42.G0614+\n * Origin: Everything goes the bach runter ... \n * http://thai-girls.org/cgi-php/DS/index.php\n * http://electronic-dreamland.com/cgi-bin/DS/index.php\n\n\n\n\n\n\ntext/html attachment: 40519X.html\n\n\n\n\n"
        },
        {
            "subject": "Funny Quote",
            "content": "Funny Quotes\n\nhttp://funny-quotes.blogspot.com\nhttp://woody-allen.blogspot.com\nhttp://george-carlin.blogspot.com\nhttp://johnny_carson.blogspot.com\nhttp://david-letterman.blogspot.com\nhttp://oscar-levant.blogspot.com\nhttp://groucho-marx.blogspot.com\nhttp://mary-richards.blogspot.com\nhttp://joan-rivers.blogspot.com\nhttp://mark-twain.blogspot.com\nhttp://oscar-wilde.blogspot.com\nhttp://henny-youngman.blogspot.com\n\n\n\n"
        },
        {
            "subject": "Some Link",
            "content": "http://www.FindPhonesex.com\nhttp://www.FantasyPhoneCalls.com\nhttp://www.PhonesexBabydolls.com\nhttp://www.PhonesexBootyCalls.com\nhttp://www.GirlsPhoneNumbers.com\nhttp://www.Youngstuff4Phone.com\nhttp://www.StrictlyDommes.com\nhttp://216.247.166.167/hotmaturemomma/main.htm\nhttp://www.JosiesPussycats.com\nhttp://www.PussycatCalls.com\n\n\n\n"
        },
        {
            "subject": "Re: No plans for C0",
            "content": ">>> It's trivial to do that at step 2; you just have to first resolve the \n>>> standard's ambiguity in some consistent fashion.\n>>\n>> But the current issue concerned what the standard now\n>> requires (in the way of diagnostics), not what some\n>> modified version might require.  [...]\n> \n> I wasn't talking about a modified version of the standard. Since the \n> standard leaves it implicitly unspecified, each implementation is free \n> to resolve that ambiguity in either of the two possible ways.\n\n\nYou know, the most useful thing I've got out of reading this newsgroup\nis to understand what a *fundamentally bad idea* it is for nondeterminism\nin technical standards to be implicit.\n\nIn C99, what I'm complaining about is the \"or by the omission of any\nexplicit definition of behavior\" part of clause 4 #2:\n\n# 4. Conformance\n#\n# 2  If a \"shall\" or \"shall not\" requirement that appears outside of a\n#    constraint is violated, the behavior is undefined. Undefined behavior\n#    is otherwise indicated in this International Standard by the words\n#    \"undefined behavior\" or by the omission of any explicit definition\n#    of behavior. There is no difference in emphasis among these three;\n#    they all describe \"behavior that is undefined\".\n\nBye\nThomas\n\n\n--- GoldED/386 2.42.G0614+\n * Origin: Everything goes the bach runter ... \n * http://thai-girls.org/cgi-php/DS/index.php\n * http://electronic-dreamland.com/cgi-bin/DS/index.php\n\n\n\n\n\n\ntext/html attachment: 40528X.html\n\n\n\n\n"
        },
        {
            "subject": "???C?C?s???W?????A?[???C?C?",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Update on glossary project  early April 200",
            "content": "Greetings,\n\nHere is a small update on the glossary project.\n\nI will probably say things you already know, but since this is the \nfirst update on the list, and since everyone on the list was not \nnecessarily present during the presentation and meeting at the \ntechnical plenary, this may be necessary for some of us.\n\nFirst, let me remind you there is a homepage for this project, which is \nbasically a collection of news item. If anyone wants a RSS feed, please \nraison your hand:\nhttp://www.w3.org/QA/2003/01/Glossary\n\nWe're currently working on several things at the same time:\n\n- Pierre, who will be the main developer for the project (at least for \nthe months to come) has been working on information scraping (from W3C \nspecs in HTML, XMLSpec coming in the near future) and is now having a \nlook at back-end systems to manipulate the glossary data.\nPierre has also written an analysis and roadmap of the project:\nhttp://www.w3.org/2003/03/glossary-project/analysis\n\n- In the meantime, (mostly) Dom has started thinking and discussing \nabout data model/schema for our needs. See e.g:\nhttp://lists.w3.org/Archives/Public/www-archive/2003Mar/0063.html\nI encourage you to continue the discussion here (please start another \nthread)\n\n- I would like to take on what has been discussed during the TP meeting:\nhttp://www.w3.org/2003/03/07-glossary.html\nand try to design a mockup of the UI. I will start another thread for \npeople wanting to discuss this.\n\n- I got a note from Charles, whom at a SWAD (semweb development) \nmeeting saw some thesaurus work that covers our needs. Chaals, could \nyou send us a pointer?\n\n\nAll for now. Cheers.\nolivier.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Update on glossary project  early April 200",
            "content": "Greetings,\n\nHere is a small update on the glossary project.\n\nI will probably say things you already know, but since this is the \nfirst update on the list, and since everyone on the list was not \nnecessarily present during the presentation and meeting at the \ntechnical plenary, this may be necessary for some of us.\n\nFirst, let me remind you there is a homepage for this project, which is \nbasically a collection of news item. If anyone wants a RSS feed, please \nraison your hand:\nhttp://www.w3.org/QA/2003/01/Glossary\n\nWe're currently working on several things at the same time:\n\n- Pierre, who will be the main developer for the project (at least for \nthe months to come) has been working on information scraping (from W3C \nspecs in HTML, XMLSpec coming in the near future) and is now having a \nlook at back-end systems to manipulate the glossary data.\nPierre has also written an analysis and roadmap of the project:\nhttp://www.w3.org/2003/03/glossary-project/analysis\n\n- In the meantime, (mostly) Dom has started thinking and discussing \nabout data model/schema for our needs. See e.g:\nhttp://lists.w3.org/Archives/Public/www-archive/2003Mar/0063.html\nI encourage you to continue the discussion here (please start another \nthread)\n\n- I would like to take on what has been discussed during the TP meeting:\nhttp://www.w3.org/2003/03/07-glossary.html\nand try to design a mockup of the UI. I will start another thread for \npeople wanting to discuss this.\n\n- I got a note from Charles, whom at a SWAD (semweb development) \nmeeting saw some thesaurus work that covers our needs. Chaals, could \nyou send us a pointer?\n\n\nAll for now. Cheers.\nolivier.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "SWAD Europe Thesaurus wor",
            "content": "(Bcc: public-esw-thes)\n\nThere is a work package in the SWAD Europe project on the develpoment of an\nRDF Thesaurus, which is closely related to the development of a glossary\nsystem for W3C.\n\nThere is a page about it on the SWAD-E\nWiki at http://esw.w3.org/topic/RdfThesaurus which currently contains a\npointer to the workpackage page itself:\nhttp://www.w3c.rl.ac.uk/SWAD/thesaurus.html\n\nAnd there is a mailing list - public-esw-thes@w3.org archived at\nhttp://lists.w3.org/Archives/Public/public-esw-thes/ which has so far been\nquiet.\n\nThe work is actually a little ahead of what was expected, although I don't\nknow how much has been published to date.\n\ncheers\n\nChaals\n\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Glossary / XMLSpe",
            "content": "Pierre (and all),\n\nHere is as promised a small overview of XMLSpec and what we need to do \nfor the glossary with it.\n\nXMLSpec is a DTD that was first designed to create the XML \nSpecification (hence the name), and has since been used by several \ngroups to create their specs, because it provides a rich vocabulary.\n\nOur scraping system should be able to retrieve definitions and \nglossaries from both specifications written in \"plain\" HTML and XMLSpec \n(even though these may have an HTML version, using the XMLSpec version \nwill have its advantages).\n\nHere are a few pointers to get you started:\n\nOverview and links to the DTD(s)\nhttp://wwws.sun.com/software/xml/developers/specdtd/\n\nGlossaries in XMLSpec (Norm Walsh)\nhttp://www.w3.org/2003/Talks/techplen-xmlspecglossaries/\n\n-- \nOlivier\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "How to submit my works",
            "content": "Hi, there, \nI am a voluntary translator from China. Can I submit my translation of terms? Thank you!\n\nCollin\n\n\n\n"
        },
        {
            "subject": "Link from translation sit",
            "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Used Formwork/Peri Dok",
            "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n"
        },
        {
            "subject": "How to add translations (or terms",
            "content": "[Bcc al grupo traductores Sidar, para informaci?n]\n\nHi,\n\nI thought it used to be possible to add a translation for a term. We're \nin the middle of translating SVG, and we thought it would be good to \nadd our spanish to the glossary (Sidar has a translators group that \ncoordinates a number of translations into spanish).\n\nBut I can't find out how to do it any more :(\n\nCheers\n\nChaals\n\n--\nCharles McCathieNevile                          Fundaci?n Sidar\ncharles@sidar.org                                http://www.sidar.org\n\n\n\n"
        },
        {
            "subject": "Status updat",
            "content": "Hi all.\nAs promised in my previous mail to the list, an alpha version of the glossary \nmanagement system is now available at:\nhttp://www.w3.org/2003/03/glossary-project/UI/home\n\nOnly the search features can be tested for the time being. \nThere are some limitations though:\n- everything that is related to the translations is not implemented yet\n- the error handling for the forms is not optimal (i.e. it gives an unhelpful \nmessage when there is a missing field)\n\nAs we are moving forward in the development phase of the project, it would be \nvery useful for us to get more data for testing. If you have glossaries \navailable that you would like to see integrated in the prototype, please \ncontact anyone of us: \n\npcandela@sophia.inria.fr \ndom@w3.org \not@w3.org \n\nso that we can coordinate on this.\n\nWe would especially be interested in glossaries with translated entries.\n\nFYI, the glossaries used in the tests are not perfect: some entries may have \nbeen missed (and others should have been) when the glossaries were generated.\n\nPierre Candela\n\n\n\n"
        },
        {
            "subject": "Re: Status updat",
            "content": "Hello Pierre,\n\nMany thanks for your work. Some comments:\n\n- I would not display any UI elements that are not functional\n   yet (e.g. 'display translations'). It will only confuse people.\n\n- You should just look through Recommendations on the TR page and\n   find those that contain glossaries and try to extract these.\n   Once you have done that, you can then ask for more material,\n   but I would do that on other lists (chairs, specprod,...).\n   For translated glossaries, you should write to w3c-translators@w3.org.\n\n- In particular, I would make sure that you get some terms from\n   very central W3C specifications (e.g. XML) into your repository.\n   For the average user, it will be much more motivating to\n   e.g. select \"A\" and get \"attribute\" than to select \"A\" and\n   get \"all WG members\".\n\n- The form is served as iso-8859-1. You should use UTF-8 from\n   the start to get internationalization right. It's much easier\n   than changing later. See also\n   http://www.w3.org/International/questions/qa-forms-utf-8.html.\n\n- The A-Z radio buttons will not scale for translations,...\n   (I guess you don't want to have 90,000 buttons for all the\n    characters in Unicode :-).\n\n- The interface looks good for people who know very precisely\n   what they want (look up one specific term), but it would be\n   good if it encouraged more browsing. One idea is to have the\n   list of sources and languages displayed directly instead of\n   hidden in pulldowns.\n\n- french (QC): This should be changed to French (CA). Language\n   names should be capitalized. Also, there should be something\n   for French and for English in general. Some actual entries\n   may not be in a specific sublanguage, and, more important,\n   users may not care about the differences for lookup.\n\n- Please provide a link to a page describing the implementation.\n   This is interesting now but also serves as a documentation later.\n\n- Please have a look at what Ivan did for translations:\n   http://www.w3.org/Consortium/Translation/,\n   http://www.w3.org/2003/03/Translations/OverviewLang,\n   http://www.w3.org/2003/03/Translations/OverviewTech,\n   http://www.w3.org/2003/03/Translations/Overview.\n   (the last one gives explanations of how it is done)\n\nKeep up your good work!\n\nRegards,    Martin.\n\nAt 16:54 03/07/17 +0200, Pierre Candela wrote:\n\n>Hi all.\n>As promised in my previous mail to the list, an alpha version of the glossary\n>management system is now available at:\n>http://www.w3.org/2003/03/glossary-project/UI/home\n>\n>Only the search features can be tested for the time being.\n>There are some limitations though:\n>- everything that is related to the translations is not implemented yet\n>- the error handling for the forms is not optimal (i.e. it gives an unhelpful\n>message when there is a missing field)\n>\n>As we are moving forward in the development phase of the project, it would be\n>very useful for us to get more data for testing. If you have glossaries\n>available that you would like to see integrated in the prototype, please\n>contact anyone of us:\n>\n>pcandela@sophia.inria.fr\n>dom@w3.org\n>ot@w3.org\n>\n>so that we can coordinate on this.\n>\n>We would especially be interested in glossaries with translated entries.\n>\n>FYI, the glossaries used in the tests are not perfect: some entries may have\n>been missed (and others should have been) when the glossaries were generated.\n>\n>Pierre Candela\n\n\n\n"
        },
        {
            "subject": "Re: Status updat",
            "content": "Hi Pierre\n\nSome further comments to what Martin said...\n\nOn Thursday, Jul 17, 2003, at 21:36 Europe/Zurich, Martin Duerst wrote:\n\n>\n> Hello Pierre,\n>\n> Many thanks for your work. Some comments:\n>\n> - You should just look through Recommendations on the TR page and\n>   find those that contain glossaries and try to extract these.\n>   Once you have done that, you can then ask for more material,\n>   but I would do that on other lists (chairs, specprod,...).\n>   For translated glossaries, you should write to \n> w3c-translators@w3.org.\n\nSidar maintains a number of translations in Spanish / Castellano (es - \nwhich has several varieties) and a couple of things in Gallego and \nCatalan (2 more of the 4 official languages in Spain).\n\nWe would be happy to offer the glossaries from any of those. One that \nmight be interesting is the translation of the WAI combined glossary \nthat was done and checked over by the Sidar translator's group - i.e. \nwe vouch for it being an accurate translation, which we have done for \nsome but not all of the translations we maintain.\n\nI realise that W3C doesn't authorise translations, but some other \norganisations do, at least for their own purposes. Being able to find \nout whether a translation had been endorsed by any particular group \nwould be handy.\n\n> - In particular, I would make sure that you get some terms from\n>   very central W3C specifications (e.g. XML) into your repository.\n>   For the average user, it will be much more motivating to\n>   e.g. select \"A\" and get \"attribute\" than to select \"A\" and\n>   get \"all WG members\".\n\nYep...\n\n> -  Also, there should be something\n>   for French and for English in general. Some actual entries\n>   may not be in a specific sublanguage, and, more important,\n>   users may not care about the differences for lookup.\n\nSame for Spanish - es-ES and es-AR are actually reasonably different in \ntheir technical vocabularies (Spaniards use a lot more spanish terms \nthan Argentines, who tend to adopt terms as they find them), but people \nspeaking spanish are interested in both kinds...\n\n> Keep up your good work!\n\nYes...\n\nCheers\n\nCharles\n\n> Regards,    Martin.\n>\n> At 16:54 03/07/17 +0200, Pierre Candela wrote:\n>\n>> Hi all.\n>> As promised in my previous mail to the list, an alpha version of the \n>> glossary\n>> management system is now available at:\n>> http://www.w3.org/2003/03/glossary-project/UI/home\n>>\n\n>> As we are moving forward in the development phase of the project, it \n>> would be\n>> very useful for us to get more data for testing. If you have \n>> glossaries\n>> available that you would like to see integrated in the prototype, \n>> please\n>> contact anyone of us:\n--\nCharles McCathieNevile                          Fundaci?n Sidar\ncharles@sidar.org                                http://www.sidar.org\n\n\n\n"
        },
        {
            "subject": "Status updat",
            "content": "Since May 07: \n(http://lists.w3.org/Archives/Public/public-glossary/2003May/0001.html)\n\n- selected a toolkit for the back-end: RDFLib (http://rdflib.net/)\n- factored my XSLT stylesheets\n- implemented a couple of \"query\" use cases: by keywords (no wildcards \nsupported yet), by glossaries, alphabetical\n- implemented some \"update/edit\" use cases: add concept/definition, delete \nconcept/definition (NB: those CGI scripts are being tested on a local setup, \nat the time being)\n\n\"To do\" in the next few days:\n- update my scripts et stylesheets so that they use Dom's new version of the \nschema: http://www.w3.org/2003/03/glossary-project/schema\n- integrate Olivier's UI for the query results\n- learn how to use CVS (may require more than a few days)\n- add wildcard support for the search by keywords\n- list all the glossaries in an RDF file (will see with Dom for the datamodel)\n\n\"To do\" in the next couple of weeks:\n- implement some more use cases: http://www.w3.org/2003/03/07-glossary.html\n\n\nOnce the UI of the query results is improved, we'll publish an alpha version \nof the glossary management system to demonstrate the work done.\n\nAs always, comments and questions are welcomed.\n\nPierre Candela\n\n\n\n"
        },
        {
            "subject": "Status updat",
            "content": "Since May 07: \n(http://lists.w3.org/Archives/Public/public-glossary/2003May/0001.html)\n\n- selected a toolkit for the back-end: RDFLib (http://rdflib.net/)\n- factored my XSLT stylesheets\n- implemented a couple of \"query\" use cases: by keywords (no wildcards \nsupported yet), by glossaries, alphabetical\n- implemented some \"update/edit\" use cases: add concept/definition, delete \nconcept/definition (NB: those CGI scripts are being tested on a local setup, \nat the time being)\n\n\"To do\" in the next few days:\n- update my scripts et stylesheets so that they use Dom's new version of the \nschema: http://www.w3.org/2003/03/glossary-project/schema\n- integrate Olivier's UI for the query results\n- learn how to use CVS (may require more than a few days)\n- add wildcard support for the search by keywords\n- list all the glossaries in an RDF file (will see with Dom for the datamodel)\n\n\"To do\" in the next couple of weeks:\n- implement some more use cases: http://www.w3.org/2003/03/07-glossary.html\n\n\nOnce the UI of the query results is improved, we'll publish an alpha version \nof the glossary management system to demonstrate the work done.\n\nAs always, comments and questions are welcomed.\n\nPierre Candela\n\n\n\n"
        },
        {
            "subject": "New Public mailing list  public glossar",
            "content": "Maintaining Activity:  Quality Assurance [1]\n\nPurpose:  Public discussion forum for the W3C Glossary project[2].\n\n\n1.  http://www.w3.org/QA/\n2.  http://www.w3.org/QA/2003/01/Glossary\n\n\n\n"
        },
        {
            "subject": "Followup to the Technical Plenary meetin",
            "content": "Greetings,\n\nAs a follow-up to the Technical Plenary meeting we had about the W3C\nGlossary project, Wendy Chisholm took the time to write and publish the\nminutes of this meeting:\nhttp://www.w3.org/2003/03/07-glossary.html\n\nPlease send any corrections you would have on these.\n\nBesides, the technical aspects of the project have started to be\ndeveloped: Pierre Candela, our intern in France, has written a first\nanalysis of the project requirements, with an informative development\nschedule:\nhttp://www.w3.org/2003/03/glossary-project/analysis\n\nYour comments and suggestions on this are also welcome!\n\n(hopefully, the work on the data model will start soon:\nhttp://lists.w3.org/Archives/Public/www-archive/2003Mar/0063.html )\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "FYI: Think piece on natural language usage assistance now   availabl",
            "content": "We finally have an issue paper that connects\n- translation readiness\n- access for persons whose first language is Bliss or some other \nlittle-used and non-textual language\n- glossary technical architecture\n- common architecture for lexicons supporting 'sound' and/or 'sense' \ninformation for textual terms\n\nI posted a little announce message to WAI-XTECH as follows:\n\nX-Archived-At: \nhttp://www.w3.org/mid/5.1.0.14.2.20030328135350.02784960@pop.iamdigex.net\n\nThere is a paper\n\n    Natural Language Usage -- Issues and Strategies for Universal Access to\n                                  Information\n\nPosted at\n\nhttp://www.w3.org/WAI/PF/usage/languageUsageAndAccess.html\n\nLisa Seeman prepared this for WAI/PF as a background piece to fill a need\narising out of some of our work with format groups.\n\nIn order to foster discussion with multiple communities who share no agreed\nprivate space, we are sharing this in public.\n\nIt is intended to be thought-provoking, not prescriptive of a particular\ncourse of action or set of constraints on action.  But it does appear to\nshed light on what is an action opportunity that would benefit all of us,\nand particularly some people with some disabilities will find the web rather\ninaccessible unless some progress is made in this area.\n\nAl\n\n\n\n"
        },
        {
            "subject": "Considering BoF at Budapest (and status update",
            "content": "Hi all,\n\nThose of you who were at the first meeting in Boston may remember that \nwe had thought of another face-to-face meeting during the WWW \nconference in Budapest (in two weeks) in the form of a BoF session.\n\nI would like to know who on this list would be interested by such a \nmeeting.\nCould you send me a private e-mail if you are? That will help assessing \npotential participation. Thanks.\n\nSmall status update on the project while I'm here...\n\n* Pierre has been working on additional XSLT to handle data in XMLSpec.\n* We've tackled a few general issues, and Dominique and Pierre are \nstill working on the Data Model.\n* I'm currently working on (navigable) UI mockups\n\nRegards, olivier.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Considering BoF at Budapest (and status update",
            "content": "Hi all,\n\nThose of you who were at the first meeting in Boston may remember that \nwe had thought of another face-to-face meeting during the WWW \nconference in Budapest (in two weeks) in the form of a BoF session.\n\nI would like to know who on this list would be interested by such a \nmeeting.\nCould you send me a private e-mail if you are? That will help assessing \npotential participation. Thanks.\n\nSmall status update on the project while I'm here...\n\n* Pierre has been working on additional XSLT to handle data in XMLSpec.\n* We've tackled a few general issues, and Dominique and Pierre are \nstill working on the Data Model.\n* I'm currently working on (navigable) UI mockups\n\nRegards, olivier.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico",
            "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n"
        },
        {
            "subject": "Trip report: WWW2002, Hawaii, May 200",
            "content": "hi all,\n\nI attended the WWW2002 conference [1] 6-11 May. I thought I would report\nback to the SWAD Europe team and the ILRT semantic web group in the hope\nof creating a precedent :)\n\nAll the papers are online [2]. You might also like to look at the RDF\nInterest group chatlogs and blog pages for the days covering the\nconference [3] and I also have some photos [4] as does Dave Beckett [5].\nI've also copied it to the new public-esw list, which will be for public\ndiscussion about SWAD-Europe.\n\nWednesday\n\nThe first day I attended was Wednesday 8th. I went to the plenary\nsession [6]. Tim Berners-Lee did a nice speach explaining the importance\nof patent-free infrastructure for the web [7]. Then in the Semantic web\nService track I went to a talk about extending XQuery for implementing\nweb services [8]. It seemed to be an entire programming language.\nI then spent some time working on some slides about SWAD-Europe for a\npresentation that charles was giving. I spent lunch chatting to Andy\nSeaborne and Wolfgang Nejdl about RDF query.\n\nIn the afternoon there was a W3C track on the Semantic web, which\nbasically meant reports back from the working group chairs of RDFCore\nand Webont, plus some information about W3C SWAD activity, and so\nSWAD-Europe, by Ralph Swick [9]. There was also a nice demo by Guha's\nTAP system [10] which illustrates cross searching of google and\nW3C-specific data sources, such as people, working group documents\n(example [11]).\n\nAfter that was a poster session, and after that, a slightly bad-tempered\nbirds of a feather meeting about Semantic Web tools, bravely chaired by\nBrian McBride. Although it was interesting to listen to the Semantic\nweb interests of the 30ish people who were there, the free drinks\nbeforehand made for a rather unproductive discussion.\n\nThursday\n\nThursday I went to the Global community track to see Charles\nMcCathieNevile of W3C present a paper which described among other\nthings the principles behind the design of SWAD-Europe [12]. Charles did\na great job under difficult circumstances, and there was lots of\ninterest in the paper.\n\nThursday afternoon I started in the Semantic Web panel, which wasn't\nvery inspiring, but got tipped off on irc that Dean Jackson was\npresenting a very interesting series of SVG demos. Dean's demos aren't\nup yet, but he helped me hack a version of one of them for the codepiction\ndatabase [13] which gives you a flavour of the quality of them (although\nmy version is much uglier). Another demo was Max Froumentein's XSLT/SVG\nChess demo [14] which is amazing :). Dean's session was part of 'cool\nweb' session, and was very well recieved. I was thinking 'I'm in the\nwrong business'.\n\nFriday\n\nFriday, the main session for me was Query langauges for the semantic\nweb. RQL had a paper [15]; there was also an interesting on on a peer to\npeer system for Education resources, which had several levels of query\nlangauges [16]. Finally there was one about mapping part of XSLT to SQL,\nwhich was interesting because it was by very clever database people and\nbecause ideas in it might bve stealable for RDF (because it uses\nunordered, graph strcuture to represent the query) [17]\n\nLater I went to see Dave Beckett give his talk [18] on WSE - scalable\nRDF searching. It was very well-recieved.\n\nSaturday\n\nSaturday was Developer Day[19]. There was a session on the Semantic web,\nwith lots of demos, including a talk from a guy from Adobe, on their\nimplementation of a subset of RDF, called XMP[20]; a talk by the ISAVIZ\n[21] guy about his vizualisation system for RDF data; Mike Dean [22],\nexcellent as ever, creating tons of data for semantic web using Screen\nscraping techniques. I demoed RDFAuthor [23] on behalf of Damian steer\n(RDFAuthor is being used for a front end to the MEG project,\ncollaborating with UKoln and working with Dave Beckett), I also got a\nplug for the codepiction [24] stuff I've been doing with him and Dan.\nThere were 200+ people in a huge room - very scarey, but I guess the\nSemantic Web's popular now.\n\nThe afternoon I was working on some slides for Luxembourg (trip report\nto follow), so missed demos on Haystack and Annotea, the W3C's\nannotations system. There is plenty on irc about them though [25].\npeople were very impressed with haystack, though its not available yet, and\nwill cost money.\n\nI got back in just in time to see another demo of codepiction stuff, and\nalso the irc 'chump bot' [27](a blogger that writes URLs from irc to a\nwebpage and enbles you to annotate them) on screen.\n\n\nSummary and impressions\n\nThe best thing about the conference was the irc channel [27] being used\nto recommend good presentations, report back about what was going on in\ndifferent sessions, and for rude backchat. because there was a wireless\nnetwork throughout, everyone was communicating all the time.\n\nIts clear that the Semantic web is becoming *a big deal*, and I'm\nworried its becoming an industry initiative, without really being\nfinished off, taking the fun out of it all...\n\nLibby\n\n\n[1] http://www.w3.org/2001/sw/Europe/events/kickoff-f2f\n[2] http://www2002.org/program.html\n[3] http://rdfig.xmlhack.com/,\nhttp://rdfig.xmlhack.com/2002/05/08/2002-05-08.html -\nhttp://rdfig.xmlhack.com/2002/05/12/2002-05-12.html\n[4] http://swordfish.rdfweb.org/photos/2002/05/05/ -\nhttp://swordfish.rdfweb.org/photos/2002/05/12/\n[5] http://photos.dajobe.org/gallery/www2002-hawaii\n[6] http://www2002.org/plenary.html\n[7] http://www.w3.org/2002/Talks/www2002-tbl/\n[8] http://www2002.org/CDROM/refereed/481/\n[9] http://www.w3.org/2002/Talks/0508-swad/\n[10] http://tap.stanford.edu/\n[11] http://tap.stanford.edu/cgi-bin/w3csearch.pl?q=eric+miller&sitesearch=w3.org&domains=w3.org\n[12] http://www2002.org/CDROM/alternate/725/\n[13]\nhttp://swordfish.rdfweb.org/people/libby/rdfweb/paths/6degcodepict.svg\n[14] http://people.w3.org/maxf/ChessGML/\n[15] http://www2002.org/CDROM/refereed/329/\n[16] http://www2002.org/CDROM/refereed/597/\n[17] http://www2002.org/CDROM/refereed/226/\n[18] http://www2002.org/CDROM/alternate/747/\n[19] http://www2002.org/devday.html\n[20] http://www.adobe.com/products/xmp/main.html\n[21] http://www.w3.org/2001/11/IsaViz/\n[22] http://www.daml.org/people/mdean/\n[24] http://rdfweb.org/people/damian/RDFAuthor/\n[25] http://swordfish.rdfweb.org/discovery/2002/02/paths/\n[26] http://rdfig.xmlhack.com/2002/05/12/2002-05-12.html and\nhttp://ilrt.org/discovery/chatlogs/rdfig/2002-05-12.html\n[27] http://rdfig.xmlhack.com\n\n\n\n"
        },
        {
            "subject": "SWAD-Europe Thesaurus Activity  new sit",
            "content": "Dear all,\n\nJust to inform you that the thesaurus activity of the Semantic Web Advanced\nDevelopment for Europe (SWAD-Europe) project is now in full swing.  The\nThesaurus Activity web site has been updated, and contains an up to date\nsummary of all recent developments:\n\n<http://www.w3c.rl.ac.uk/SWAD/thesaurus.html>  \n\nYours,\n\nAlistair Miles.\n\n[1] Semantic Web Advanced Development for Europe project\n<http://www.w3.org/2001/sw/Europe/>\n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RDF Schema for thesaurus dat",
            "content": "Hi,\n\nAs part of the Semantic Web Advanced Development for Europe (SWAD-E)\n(http://www.w3.org/2001/sw/Europe/) project, myself and my colleagues are\ndeveloping an RDF schema for representing thesaurus data.  This schema and\nthe underlying datamodel may be of interest, as it looks like they overlap\nconsiderably with the data and model being developed in the Glossary\nproject.   \n\nThe current state of the schema can be found here\n(http://www.w3c.rl.ac.uk/SWAD/thesaurus/tif/tif.html) with a link to a\ndocument describing the work so far done\n(http://www.w3c.rl.ac.uk/SWAD/thesaurus/tif/deliv81/final.html).   \n\nThis work is ongoing, and comments and feedback are very welcome at this\nstage.  \n\nWe are also beginning development of an open API for thesaurus (terminology)\nweb service.  At this stage we are looking for well-defined use-cases\nrelating to web applications of thesaurus & terminology data.  Any interest\nand/or contribution to this most welcome also.  \n\nYours,\n\nAlistair Miles.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Glossary Project Phase 1 don",
            "content": "Hello,\n\nPierre Candela, our intern working on the Glossary Project, has finished\nhis internship at the beginning of the month; this means that the first\nphase of the glossary project is now done.\n\nA few glossaries have been entered in the glossary database:\nhttp://www.w3.org/2003/glossary/\nFor instance, one of the use case for such a tool of comparing the\ndefinitions of \"user agent\" across W3C specifications can now be easily\nachieved:\nhttp://www.w3.org/2003/glossary/keyword?show_def=yes&show_trans=no&offset=0&size=20&keywords=user+agent&index=All&lang=All\nretrieves 9 different definitions for this term.\n\nThe full set of glossaries has hence 641 concepts:\nhttp://www.w3.org/2003/glossary/subglossary?show_def=yes&show_trans=no&offset=0&size=20&index=All\nWe plan to add new glossaries over time, but with a strong preference\nfor stable glossaries (e.g. glossaries included in Recommendations).\n\nAlthough there is some tweaking needed for the user interface (see the\ntodo list [1]), the interface also allows to enter translations for the\nvarious terms and definitions; entering a translation only requires\nhaving a W3C Public or Member Account, and each translation is\nassociated with the name of its contributor.\nNevertheless, we still need to refine the social process behind\ntranslations before anouncing this to a large forum (feedback on this\naspect is welcome).\n\nThe interface also allows to add/delete glossaries, concepts,\ndefinitions, etc., those operations being reserved to the W3C Team for\nnow.\n\nThis list is informed as the first customer of this tool; there is\ndefinite need for an announce on a broader audience (chairs ? WGs ?), as\nthere is a need for a more detailed technical documentation on the\nvarious technologies used in this system (Pierre's report being a very\ngood basis for this).\n\nThanks to Pierre for the great work he produced during his internship!\nPlease send your comments and suggestions, but note that this system is\nin maintenance mode for the time being (ie, bugs will be fixed as much\nas possible, but important new features will have to wait).\n\nDom\n\n1. http://www.w3.org/2003/03/glossary-project/todo\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "RE: Glossary Project Phase 1 don",
            "content": "Congratulations, it's looking very promising indeed.\n\nOne question though - is the RDF exposed anywhere? There appear to be links,\ne.g.\n\nabstract module\nFrom xhtml-modularization.rdf (2001-04-10)\n\nbut xhtml-modularization.rdf points to:\nhttp://www.w3.org/TR/xhtml-modularization\n\n(hmm, the client's not negotiating, is it?)\n\nMany thanks,\nDanny.\n\n\n> -----Original Message-----\n> From: public-glossary-request@w3.org\n> [mailto:public-glossary-request@w3.org]On Behalf Of Dominique\n> Haza?l-Massieux\n> Sent: 19 September 2003 12:53\n> To: public-glossary@w3.org\n> Subject: Glossary Project Phase 1 done\n>\n>\n> Hello,\n>\n> Pierre Candela, our intern working on the Glossary Project, has finished\n> his internship at the beginning of the month; this means that the first\n> phase of the glossary project is now done.\n>\n> A few glossaries have been entered in the glossary database:\n> http://www.w3.org/2003/glossary/\n> For instance, one of the use case for such a tool of comparing the\n> definitions of \"user agent\" across W3C specifications can now be easily\n> achieved:\n> http://www.w3.org/2003/glossary/keyword?show_def=yes&show_trans=no\n> &offset=0&size=20&keywords=user+agent&index=All&lang=All\n> retrieves 9 different definitions for this term.\n>\n> The full set of glossaries has hence 641 concepts:\n> http://www.w3.org/2003/glossary/subglossary?show_def=yes&show_tran\ns=no&offset=0&size=20&index=All\nWe plan to add new glossaries over time, but with a strong preference\nfor stable glossaries (e.g. glossaries included in Recommendations).\n\nAlthough there is some tweaking needed for the user interface (see the\ntodo list [1]), the interface also allows to enter translations for the\nvarious terms and definitions; entering a translation only requires\nhaving a W3C Public or Member Account, and each translation is\nassociated with the name of its contributor.\nNevertheless, we still need to refine the social process behind\ntranslations before anouncing this to a large forum (feedback on this\naspect is welcome).\n\nThe interface also allows to add/delete glossaries, concepts,\ndefinitions, etc., those operations being reserved to the W3C Team for\nnow.\n\nThis list is informed as the first customer of this tool; there is\ndefinite need for an announce on a broader audience (chairs ? WGs ?), as\nthere is a need for a more detailed technical documentation on the\nvarious technologies used in this system (Pierre's report being a very\ngood basis for this).\n\nThanks to Pierre for the great work he produced during his internship!\nPlease send your comments and suggestions, but note that this system is\nin maintenance mode for the time being (ie, bugs will be fixed as much\nas possible, but important new features will have to wait).\n\nDom\n\n1. http://www.w3.org/2003/03/glossary-project/todo\n--\nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n"
        },
        {
            "subject": "RE: Glossary Project Phase 1 don",
            "content": "Le ven 19/09/2003 ? 18:31, Danny Ayers a ?crit :\n> One question though - is the RDF exposed anywhere? There appear to be links,\n> e.g.\n> \n> abstract module\n> >From xhtml-modularization.rdf (2001-04-10)\n> \n> but xhtml-modularization.rdf points to:\n> http://www.w3.org/TR/xhtml-modularization\n\nThat's a small UI glitch, indeed. I'll try to fix it quickly, but for\nyour information:\n- the name appearing is not supposed to be using the rdf extension (nor\nto link to an RDF file)\n- the underlying RDF files are available at:\nhttp://www.w3.org/2003/03/glossary-project/data/glossaries/\n(but they are not linked from anywhere ... yet).\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: Glossary projec",
            "content": "Dear all,\n\nFew days ago, Ivan Herman informed the offices that there is a published\nversion of the W3C Glossary. The application looks very nice indeed!\n\nSince I want to help with the work, I've briefly played with the\napplication. Few comments in good faith:\n\n1) Perhaps the introduction might want to briefly clarify the selection\ncriteria for the terms (glossary sources)? It seems that some rather\ncentral specifications are not included (perhaps only for now, for\ntechnical reasons?). For instance, searching for the term \"namespace\"\nreturns nothing. However, one might expect to be able to access the\nterminology of, e.g., XML 1.0 & XML NS.\n\n2) The Admin/Edit part seems to talk (also) about \"concepts\" while the\nintro talks about \"terms\". Why the difference? In addition, the very\ndifficult issues related to the taxonomic differences and subclassing of\nterms, and the context of using them (e.g. \"CEO concepts versus technical\nconcepts\")  will probably be dealt with the ontology part? (Search e.g.\nfor a \"profile\".)\n\n3) Assuming translations exist, how can I search for a Finnish translation\nof the definition \"namespace\" (and thus effectively, also a translation of\nthe _term_ itself). Of course, this is different than searching a\ndefinition for the translated term \"nimiavaruus\" (a Finnish translation\nfor \"namespace\"). Perhaps the form\n\n\"Term: [____]\"\n\n...should read:\n\n\"Term: [____] in [Choose language]\"\n\n...and the current language selection should identify the result language.\n\n4) In addition to the above, one might want to search _only_ the\ntranslations? (I.e. currently one gets always the English terms also...)\n\n5) Currently, the language selection (e.g. French) seems to have no\neffect. Or then my French is as fluid (or poor) as my English and I just\ncan't see the difference... This obviously relates to the above... i.e. it\nmight be better that the result set informed the user that \"Currently,\nthere are no French translations for the terms XXX1, XXX2, and XXX3 in the\nDB\".\n\n6) When searching, what is the meaning of the \"Reset\" button? It seems to\nhave no effect. (And even if it had, is the button needed at all?)\n\n7) In addition to searching for terms, one might also like to refer to the\nterms and definitions (e.g. when talking about terms or translations...).\nWhat if the application was added a feature for this (thus effectively\ngiving URI names to the W3C terms +[:-) [*])? Of course, in an ideal case,\none would obviously refer to the original specifications but due to e.g.\nmissing markup, it can't be done. (Well, not without some XPointer-style\nfancy work.)\n\n8) The meaning of the phrase \"definition\" in the \"Search in Term names and\ncheckbox and [] definitions...\" might seem a bit unclear. I assume that it\nmeans a free-text search within definitions but it came to me only in the\nsecond reading...\n\n9) How about a good-old glossary index (a link/control for all languages)?\nTrying the get an overview what the glossary is all about, one might week\nfor a (condensed) index-kind-of page for all the terms. E.g.\n\n-----snip----\n...\nD\n\n..., device, domain, driver, ...\n\nE\n\n..., element, entity, ...\n...\n-----snip----\n\n...where selecting \"entity\" would search the full glossary for the term\n(i.e. the index would not include duplicates). The page might be a bit\nlong but very useful -- I believe it may even become more popular than the\nsearches. And it could clearly point out the terms needing translations...\n(e.g. including \"missing terms\" in English, with different markup [color\netc.])\n\n10) A help would help ;) The application is also a bit slow. I assume the\nspeed has something to do with the real-time part of the application...\nHaving said this, what happens when a spec changes its term or becomes\nresigned? (This is obviously related to [*].)\n\n11) Future wishes: I haven't tried out making translations yet (Ivan told\nthe offices that this is not set up yet). However, a term should obviously\nhave multiple translations in a language (e.g. \"main\" and \"alternatives\").\nIn addition, I might understand the strict sense of a glossary, but the\npossibility of adding examples and comments (e.g. from the Team, WGs, and\nthe TAG) could make this a killer application. (Just imagine the n+1\ncourses, seminars and presentations around the globe teaching these\nthings...)\n\nMy comments are obviously minor (except of course for the 7 and 11)\nremarks to the significant work done by the WG.\n\nKeep up the good work.\n\nCheers,\n\n--Ossi\n\n\n--\nOssi Nyk?nen                              Tel   +358 3 3115 3544\nTampere University of Technology          Fax   +358 3 3115 3549\nDMI / W3C Finnish Office                  Email ossi@w3.org\nP.O. Box 553, FIN-33101 Tampere, Finland  Web   www.w3c.tut.fi\n\n\nOn Fri, 19 Sep 2003, Ivan Herman wrote:\n\n>\n> I hope you still remember this...\n>\n> As a first phase of a glossary project and English (ehm, sorry,\n> American;-) glossary system has now been set up at:\n>\n> http://www.w3.org/2003/glossary/\n>\n> it is still not final, the user interface needs some tuning, etc, but it\n> is an important first step.\n>\n> At this moment, it is populated by the team, and we will have to work\n> out the process to get translated terms into the system. This will come.\n> In the meantime, I think it is already a good resource, and may be\n> interesting for translators, too!\n>\n> Ivan\n>\n> --\n>\n> Ivan Herman\n> W3C Head of Offices\n> C/o W3C Benelux Office at CWI, Kruislaan 413\n> 1098SJ Amsterdam, The Netherlands\n> tel: +31-20-5924163; mobile: +31-641044153;\n> URL: http://www.w3.org/People/all?pictures=yes#ivan\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Glossary projec",
            "content": "Le jeu 25/09/2003 ? 11:40, Ossi Nyk?nen a ?crit :\n> Few days ago, Ivan Herman informed the offices that there is a published\n> version of the W3C Glossary. The application looks very nice indeed!\n\nThanks :)\n\n> Since I want to help with the work, I've briefly played with the\n> application. Few comments in good faith:\n> \n> 1) Perhaps the introduction might want to briefly clarify the selection\n> criteria for the terms (glossary sources)? It seems that some rather\n> central specifications are not included (perhaps only for now, for\n> technical reasons?). For instance, searching for the term \"namespace\"\n> returns nothing. However, one might expect to be able to access the\n> terminology of, e.g., XML 1.0 & XML NS.\n\nThere isn't any real selection criteria, except the existence of an\nextractable glossary... I thought there was none in XML 1.0 and XML NS,\nbut having looked at the XMLSpec version, there was indeed one, and they\nare now integrated in the Glossary system... If you have other\nsuggestions of glossary, please let me know...\n\n> 2) The Admin/Edit part seems to talk (also) about \"concepts\" while the\n> intro talks about \"terms\". Why the difference?\n\nI have added the definition of \"concept\" on the home page of the\nproject; basically, a term conveys the idea that a concept has -\nbasically, the concept is the platonical idea, while the term is is the\nword (or one of the word) that allows to say it in a given language.\n\n> In addition, the very\n> difficult issues related to the taxonomic differences and subclassing of\n> terms, and the context of using them (e.g. \"CEO concepts versus technical\n> concepts\")  will probably be dealt with the ontology part? (Search e.g.\n> for a \"profile\".)\n\nThat's something we want to do in a next phase of the project, but as I\nsaid in \nhttp://lists.w3.org/Archives/Public/public-glossary/2003Sep/0000.html\nwe don't have resources right now to develop further the project; we are\nin a bug fix mode, and I don't plan to integrate big new features for\nnow.\n\n> 3) Assuming translations exist, how can I search for a Finnish translation\n> of the definition \"namespace\" (and thus effectively, also a translation of\n> the _term_ itself). Of course, this is different than searching a\n> definition for the translated term \"nimiavaruus\" (a Finnish translation\n> for \"namespace\"). Perhaps the form\n> \n> \"Term: [____]\"\n> \n> ...should read:\n> \n> \"Term: [____] in [Choose language]\"\n> \n> ...and the current language selection should identify the result language\n\n\n\n"
        },
        {
            "subject": "Re: Glossary projec",
            "content": "Dear Dom et al,\n\n>> 4) In addition to the above, one might want to search _only_ the\n>> translations? (I.e. currently one gets always the English terms\nalso...)\n\n>True, but this seems important since the only official terms are those in\nEnglish. What would be your use case to have the results only in a given\nlanguage different from English?\n>\n\n...I personally would prefer having a functionality like this behind a\nswitch. (And some people do get annoyed when seeing English everywhere.\nNot me, of course, but...)\n\nThe use case I have in mind goes as follows: If I seek e.g. a Finnish\ndefinition of a (Finnish)  term, wouldn't I then expect to have the\nresults only in Finnish as well?  When reading, say a Finnish translation\nof the WCAG 1.0, I might not really care about the fact that the official\nterms are indeed the English ones, I might simply like to find what a term\nin the spec means (i.e. the concept behind the buzzword).\n\nAnother, perhaps a more subtle observation is that, when performing a\n(partial text) search \"element\" (as \"*element*\"), I would like to find\ne.g. terms \"elementti\"  (element) and \"elementin sis?lt?\" (element\ncontent) but not \"element\" (in English). For instance, in Finnish, words\nhave many inflexions, which means that you frequently seek data based on\nonly partial keywords (and by default adding the English words to the\nresult set adds a lot of unwanted data). I believe this linguistic\nproperty may be found in other languages as well.\n\n>> 6) When searching, what is the meaning of the \"Reset\" button? It seems\nto have no effect. (And even if it had, is the button needed at all?)\n\n>Reset is a standard button on a form which allows you to undo any change\nyou may have done on a form; it's there because it's good to allow people\nto revert any action they would have done.\n>\n\nYes. What I meant was rather that the form doesn't remember its state. In\nother words, after a search, it returns to the default state anyway. Thus,\nthe button will be used very little, if at all.\n\n>> 8) The meaning of the phrase \"definition\" in the \"Search in Term names\nand checkbox and [] definitions...\" might seem a bit unclear. I assume\nthat it  means a free-text search within definitions but it came to me\nonly in the second reading...\n\n>How did you understand it at first? What wording would you suggest\ninstead?\n\nSince I anticipated that the system will (eventually) include e.g. CEO\nkind of concepts, and (I wish ;) perhaps examples, I though that the\ncheckbox would _limit_ the search only to the actual definitions from the\nspecs. In other words, when trying the system out without first reading\nthe intro (ahem...), I assumed that by default, the system would search\nfor all sorts of data.\n\nMy suggestion for...\n\n\"Search in Term names and definitions... \"\n\n...would be...\n\n\"Search in Term names and TERM definitions... \"\n\n;)\n\n>> ...\n>> Having said this, what happens when a spec changes its term or becomes\nresigned? (This is obviously related to [*].)\n\n> to [*]?\n\nThis is where markup languages with link syntax start to become useful ;)\n... i.e. I used the \"[*]\" to refer a text segment above (just after the\nsmiling chap with a propeller in his hat... me, perhaps):\n\n-----a copy from above-----\n> 7) In addition to searching for terms, one might also like to refer to\nthe\n> terms and definitions (e.g. when talking about terms or\ntranslations...).\n> What if the application was added a feature for this (thus effectively\n> giving URI names to the W3C terms +[:-) [*])? Of course, in an ideal\ncase,\n> one would obviously refer to the original specifications but due to e.g.\n> missing markup, it can't be done. (Well, not without some XPointer-style\n> fancy work.)\n-----a copy from above-----\n\nI.e. currently these things require manual work and a policy should be\nestablished how to deal with changes. (The URI names should be persistent,\nof course.)\n\n>> ...\n>> In addition, I might understand the strict sense of a glossary, but the\n>> possibility of adding examples and comments (e.g. from the Team, WGs,\nand\n>> the TAG) could make this a killer application. (Just imagine the n+1\n>> courses, seminars and presentations around the globe teaching these\nthings...)\n\n> I think this should be done using another way; annotations comes to my\nmind for instance.\n\nYes, that would indeed provide a cleaner system. However, I feel that the\npractice is a bit behind the specs in this case. In other words, I wonder\nwhen the mainstream browsers will support (and/or people use) a standard\nway of making annotations. (If only more people used Amaya or HayStack...\n;)\n\nNote: I really think the QA is doing a good job. And e.g. the glossary &\ni18n kind of work should gain more visibility and higher profile within\nW3C;  considerably more people read, interpret & use specs than write\nthem. And more often. To me, the glossary is a good example of a\npotentially valuable service that would be very hard to implement outside\nthe W3C. A lesson to be learned, and transferred to member services ($),\nperhaps.\n\nA more general note: The archives seem to have censored Dom's good\ncomments of the other half of my original murmur list (probably for a\nreason ;) I'm saying this just to point out that this might be an\nimplication of a bug. In this case, this doesn't matter since both Dom and\nI have received all the relevant data.\n\nBest regards,\n\n--Ossi\n\n\n--\nOssi Nyk?nen                              Tel   +358 3 3115 3544\nTampere University of Technology          Fax   +358 3 3115 3549\nDMI / W3C Finnish Office                  Email ossi@w3.org\nP.O. Box 553, FIN-33101 Tampere, Finland  Web   www.w3c.tut.fi\n\n\n\n"
        },
        {
            "subject": "Announcement of SWADEurope SKOS API for thesauri web servic",
            "content": "   SWAD-Europe Simple Knowledge Organisation System (SKOS) API\n       Web Service API for a thesaurus service\n\n     http://www.w3.org/2001/sw/Europe/reports/thes/skosapi.html\n\nWe are pleased to announce the initial release of the SKOS API\ndeveloped by the SWAD-Europe[1] project thesaurus activity[2]\nan EU IST-7 funded project.\n\nThe SKOS API defines a web service providing a core set of methods\nfor accessing and querying a thesaurus or terminological resource\nbased on the SKOS-Core schema, as described in the SKOS-Core Guide[3].\n\nThis is an initial release which we expect will evolve in response to\ninput from the wider community.  Our goal is to contribute to the\ndevelopment of a web service API that will be suitable for widespread\nadoption, which in turn will promote ease of interoperability and\nre-use of information systems that exploit thesauri and/or other\nkinds of terminological resource.\n\nWe ask at this stage for initial feedback from web service\ndevelopers, systems designers and KOS experts looking to expose or\naccess this kind of functionality\n\nIn particular, we have the following open issues, in no particular\norder (some of these are from the 'scratch pad' ServiceBits class[4] )\n\n- How much information to return in Concept fields versus API calls.\n- In our implementation, should we use the SOAP encoding model or\n  literal RDF/XML (for example) to represent concepts and\n  relations. Or both.\n- Try to use xsd:anyURI instead of a separate URI class\n- Versioning of the interface, do we add a getVersion() method.\n- Should we provide access to RDF query support where available (like\nJoseki)\n- A REST API would be good to have especially as this is a\n  non-side effecting API, so HTTP GET operations would be safe.\n- Returning values as singletons compared to arrays of size 1\n- What fields of concepts should regexe searches match.\n- Method doubling for thesaurus parameters versus allowing Null values\n  (we are aware WS-I Basic Profile recommends against method\n  overloading, so we avoid that)\n\nA demonstration implementation of using this web service API is\ncurrently under development which will host several thesauri in the\nSKOS schema[5] and provide a public web service.\n\nPlease direct all feedback to the public mailing list:\npublic-esw-thes@w3.org list, more details are available at [6].\n\nAlistair Miles\nNikki Rogers\nDave Beckett\n\n\n[1] http://www.w3.org/2001/sw/Europe/\n[2] http://www.w3.org/2001/sw/Europe/reports/thes/\n[3] http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n[4] http://www.w3.org/2001/sw/Europe/reports/thes/api/docs/\n[5] http://www.w3.org/2004/02/skos/core\n[6] http://lists.w3.org/Archives/Public/public-esw-thes/\n\n\n\n"
        },
        {
            "subject": "Re: How to add translations (or terms",
            "content": "Le lun 29/12/2003 ? 07:11, Charles McCathieNevile a ?crit :\n> I thought it used to be possible to add a translation for a term. We're \n> in the middle of translating SVG, and we thought it would be good to \n> add our spanish to the glossary (Sidar has a translators group that \n> coordinates a number of translations into spanish).\n> \n> But I can't find out how to do it any more :(\n\nIndeed, I disabled it a few weeks ago - I should have mentioned that\nhere, sorry about that. Due to the lack of a well-defined policy on who\nand how these translations should be registered in the global Glossary,\nit seemed easier just not to allow them for now, hoping the translations\ncapabilities of the system can be used once the situation is clarified.\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n\n"
        },
        {
            "subject": "Re: How to add translations (or terms",
            "content": "Fair enough.\n\nUntil that time, should we just install our own version of the \nglossary, where it is possible to add translations?\n\ncheers\n\nChaals\n\nOn Monday, Jan 5, 2004, at 10:10 Europe/Rome, Dominique Haza?l-Massieux \nwrote:\n\n> Le lun 29/12/2003 ? 07:11, Charles McCathieNevile a ?crit :\n>> I thought it used to be possible to add a translation for a term. \n>> We're in the middle of translating SVG, and we thought it would be \n>> good to add our spanish to the glossary (Sidar has a translators \n>> group that coordinates a number of translations into spanish).\n>>\n>> But I can't find out how to do it any more :(\n>\n> Indeed, I disabled it a few weeks ago - I should have mentioned that \n> here, sorry about that. Due to the lack of a well-defined policy on \n> who and how these translations should be registered in the global \n> Glossary, it seemed easier just not to allow them for now, hoping the \n> translations capabilities of the system can be used once the situation \n> is clarified.\n--\nCharles McCathieNevile                          Fundaci?n Sidar\ncharles@sidar.org                                http://www.sidar.org\n\n\n\n"
        },
        {
            "subject": "Re: How to add translations (or terms",
            "content": "At 10:10 04/01/05 +0100, Dominique Hazael-Massieux wrote:\n\n>Indeed, I disabled it a few weeks ago - I should have mentioned that\n>here, sorry about that. Due to the lack of a well-defined policy on who\n>and how these translations should be registered in the global Glossary,\n>it seemed easier just not to allow them for now, hoping the translations\n>capabilities of the system can be used once the situation is clarified.\n\nHello Dominique,\n\nThe glossary should be organized so that anybody can add a translation\n(i.e. propose a translation), but that there can be different translations\nfor one and the same term, and they are annotated by whom proposed them.\nThis is important to be able to really use the glossary system for actual\nwork by the various translators.\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "Re: How to add translations (or terms",
            "content": "Le lun 05/01/2004 ? 15:40, Martin Duerst a ?crit :\n> The glossary should be organized so that anybody can add a translation\n> (i.e. propose a translation), but that there can be different translations\n> for one and the same term, and they are annotated by whom proposed them.\n> This is important to be able to really use the glossary system for actual\n> work by the various translators.\n\nThis is how it works as of today; but there is a more general debate at\nW3C about this free-for all policy, and pending a resolution to this\nquestion, I thought it was better disabling the feature for now.\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n\n"
        },
        {
            "subject": "Abbreviation and or Acrony",
            "content": "Title: Abbreviation and or Acronym\n\nNeed suggestions for Abbreviation and or Acronym for\nIntranet and Extranet terminology .\n\n\n\"w3c\" , World Wide Web Consortium\n\"w3w\" , World Wide Web World\n\"w3i\" , World Wide Web Intranet\n\"w3e\" , World Wide Web Extranet\n\n<ACRONYM TITLE=\"World Wide Web Consortium\">W3C</ACRONYM>,\n<ACRONYM TITLE=\"World Wide Web World\">W3W</ACRONYM>,\n<ACRONYM TITLE=\"World Wide Web Intranet\">W3I</ACRONYM>,\n<ACRONYM TITLE=\"World Wide Web Extranet\">W3E</ACRONYM>,\n\n\n<ABBR TITLE=\"World Wide Web Consortium\">W3C</ABBR>,\n<ABBR TITLE=\"World Wide Web World\">W3W</ABBR>,\n<ABBR TITLE=\"World Wide Web Intranet\">W3I</ABBR>,\n<ABBR TITLE=\"World Wide Web Extranet\">W3E</ABBR>,\n\n\nABBR:\nIndicates an abbreviated form (e.g., WWW, HTTP, URI, Mass., etc.).\n<ABBR title=\"World Wide Web\">WWW</ABBR>\n\nACRONYM:\nIndicates an acronym\n<ACRONYM TITLE=\"Museum of Fine Arts\">MFA</ACRONYM>,\n\n-- \n         Patrizio Mafara\n\n+----------------------+-------------------+---------------------------+\n| Patrizio Mafara      | Supertronic SpA   | pat@supertronic.it        |\n| Divisione Tecnica SW | Tel +390227208200 | http://www.supertronic.it |\n|                      | Fax +390227208270 |                           |\n+----------------------+-------------------+---------------------------+\n\n\n\n"
        },
        {
            "subject": "tes",
            "content": " \n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nwww.Intercore.net\n\nComputer Consultant Los Angeles\n\nwww.Avidware.net\n\nSecurity Consultant Los Angeles\n\nwww.Avidware.com\n\nBusiness Consultant Los Angeles\n\nwww.FastForwardMarcom.com\n\nLos Angeles Computer Consultant\n\nhttp://www.computernetworkingsolutions.net/\n\nWebsite Developer Los Angeles\n\nwww.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nwww.CorpLeasing.com\n\nEmergency Network Recovery Consultant Los Angeles\n\nwww.FreePublicLinks.com/Wicky/index.pl\n\n \n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "tes",
            "content": " \n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nhttp://www.Intercore.net\n\nComputer Consultant Los Angeles\n\nhttp://www.Avidware.net\n\nSecurity Consultant Los Angeles\n\nhttp://www.Avidware.com\n\nBusiness Consultant Los Angeles\n\nhttp://www.FastForwardMarcom.com\n\nWebsite Developer Los Angeles\n\nhttp://www.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nhttp://www.CorpLeasing.com\n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "tes",
            "content": " \n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nhttp://www.Intercore.net\n\nComputer Consultant Los Angeles\n\nhttp://www.Avidware.net\n\nSecurity Consultant Los Angeles\n\nhttp://www.Avidware.com\n\nBusiness Consultant Los Angeles\n\nhttp://www.FastForwardMarcom.com\n\nWebsite Developer Los Angeles\n\nhttp://www.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nhttp://www.CorpLeasing.com\n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "ReVirus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "Virus was found  please ignor",
            "content": " \n \nScott Wiseman\nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\n \n \n\n\n\n"
        },
        {
            "subject": "[publicglossary] &lt;none&gt",
            "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n"
        },
        {
            "subject": "RE: [jenadev] Newbie Design Question...",
            "content": "Hi,\nI hope you don't mind, I'm forwarding your query to the Semantic Web Europe\nlist, as although Bali is a long way away, they're looking at use\ncases/scenarios etc. My own comments below.\n\n\n>-----Original Message-----\n>From: Cokorda Raka Angga Jananuraga [mailto:don_raka@yahoo.com]\n>Sent: 04 November 2002 08:19\n>To: jena-dev@yahoogroups.com\n>Subject: [jena-dev] Newbie Design Question....\n>\n>\n>Hi,\n>\n>Allright, I've been able to use Jena for some simple stuffs in the\n>tutorial :), MemModel, RDBModel (mysql, mm_generic).\n>\n>Now, I'm facing a design question. I have the following case:\n>\n>---\n>I'm a journalist for \"Fortunately\" magazine, responsible for column\n>\"Life Science Advances\". I'm now in the middle of preparing an article\n>about \"Biotechnology\". So, from my home in Bali I browse the web,\n>doing some desk research. I am reading a good article from \"Scientific\n>Earth\" magazine, titled \"Sheep Cloning in Ireland\", when suddenly a\n>memory about the term/idea/concept \"genetic engineering\" come up to\n>surface. It leads me to another memory of an old friend of mine who is\n>now working as lead researcher in \"Bali Biotech Center\"...., Prof.\n>Wayan. He is widely known as an expert in \"genetic engineering\".\n>So..., I decide to have an interview with him, next week.\n>---\n>\n>I want to model that complex statement in RDF. In that model, I need\n>to capture the background why the decision to interview Prof. Wayan is\n>made. (In the above case: the reason to interview Prof. Wayan is\n>because I know he's an expert in genetic engineering, a term which is\n>[according to me] very relevant to the article which I'm reading now.\n>Going further: I'm reading that article as part of my job to complete\n>my next article for my magazine).\n>\n>So I break down that complex statement this way:\n>\n>[1] Statement1 = Prof. Wayan ----expertise-----> Genetic Engineering\n>[2] Statement2 = Article \"Sheep Cloning in Ireland\" ----concept----->\n>Genetic Engineering\n>[3] Statement3 = Statement1 -----evoker-----> Statement2\n>[4] Statement4 = Statement3 -----action-----> Appointment for\n>Interview\n>\n>Well, I feel there's a good chance that the way I break down that\n>complex statement is dead wrong. That's why I'm asking to this\n>forum... for some enlightment ;) Where can I get article / guideline /\n>tutorial / design patterns about modelling that kind of complex\n>statement (or information modelling in RDF)?\n>\n>Thanks in advance,\n>Cokorda Raka\n>PS:\n>[1] There's actually no such thing as \"Bali Biotech Center\". It's\n>purely fictional :)\n>[2] To Brian: I'll try to get BdbModel to work on my laptop tommorow,\n>and write the instruction as I go.\n\nThe way you've approached looks reasonable, though I think the implicit\nstage you've skipped here is probably pretty important, the identification\nof the players in the statements and the identification of the roles. e.g.\nProf. Wayan is presumably a person, so finding an existing vocabulary that\nincludes this so you can qualify this part of the whole statement is\nprobably a useful first step. The same follows with the other entities -\ne.g. genetic engineering might well be an Open Directory category. But the\nprocess I'm applying there depends on my prior knowledge of the\nvocabularies - in practice a repository like the MEG Registry, the DAML\nontology lists or the SWAG Dictionary should be helpful for tracking these\ndown. I think the abstraction technique you used on the properties is valid.\nI guess if a search for terms matching 'evoker', 'action' etc proves\nunrewarding then you will have to generalise this back some more (tricky\nwith 'action'!), or identify the domain ('processes' in this case?) and do a\nsearch on that. If that still doesn't get you anywhere, then it's time to\nrefer to the (mostly vapourware) guides on creating your own terms/vocabs.\n\nI suppose the modelling process is essentially the same as that found in\nother fields like object modelling, E-R or RDBMS schema creation. With a bit\nof luck large chunks of the numerous guidelines for those could be\ntransmogrified into RDF design patterns.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "Announcing SKOS-Core 1.0  an RDF Schema for Thesaur",
            "content": "> Anouncing: SKOS-Core 1.0 - an RDF Schema for thesauri and related\n> knowledge organisation systems.\n> \n> The SKOS-Core 1.0 schema can be found at\n> \n> http://www.w3.org/2004/02/skos/core\n> \n> The SKOS-Core 1.0 Guide accompanying the schema can be found at\n> \n> http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n> \n> Also, the website for the SWAD-Europe Thesaurus Activity has moved to\n> \n> http://www.w3.org/2001/sw/Europe/reports/thes/\n> \n> \n> SKOS stands for Simple Knowledge Organisation System.  The Goal of\n> SKOS-Core is to provide a framework for bringing existing knowledge\n> organisation systems such as thesauri and the semantic web together.  \n> \n> SKOS-Core exploits the features of RDFS and OWL to provide a flexible and\n> extensible framework within which different types of KOS can interoperate.\n> SKOS-Core is ideal for modelling thesauri, and can cope with the\n> variations commonly found in thesaurus design and structure. \n> \n> Yours on behalf of the Semantic Web Advanced Development for Europe\n> project [1],\n> \n> Alistair Miles.\n> Nikki Rogers.\n> Dave Beckett.\n>  \n> [1] SWAD-Europe <http://www.w3.org/2001/sw/Europe/>\n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Low Fixed Cost No. 1 Search Engine Ranking for keywords related to &quot;porn&quot",
            "content": "This is an HTML message.\n\n\n\n"
        },
        {
            "subject": "Fun Quote",
            "content": "Fun Quotes\n\nhttp://funny-quotes.blogspot.com\nhttp://woody-allen.blogspot.com\nhttp://george-carlin.blogspot.com\nhttp://johnny_carson.blogspot.com\nhttp://david-letterman.blogspot.com\nhttp://oscar-levant.blogspot.com\nhttp://groucho-marx.blogspot.com\nhttp://mary-richards.blogspot.com\nhttp://joan-rivers.blogspot.com\nhttp://mark-twain.blogspot.com\nhttp://oscar-wilde.blogspot.com\nhttp://henny-youngman.blogspot.com\n\n\n\n"
        },
        {
            "subject": "Some Link",
            "content": "http://www.FindPhonesex.com\nhttp://www.FantasyPhoneCalls.com\nhttp://www.PhonesexBabydolls.com\nhttp://www.PhonesexBootyCalls.com\nhttp://www.GirlsPhoneNumbers.com\nhttp://www.Youngstuff4Phone.com\nhttp://www.StrictlyDommes.com\nhttp://216.247.166.167/hotmaturemomma/main.htm\nhttp://www.JosiesPussycats.com\nhttp://www.PussycatCalls.com\n\n\n\n"
        },
        {
            "subject": "FTF Minutes  nov 0",
            "content": "I have just posted the minutes at http://www.w3.org/International/geo/2002/11/ftf-minutes-200211.html\n\nApologies for lateness.  I will add a link to Whitney's slides shortly.\n\nIf you have any comments on the minutes, please send to the list.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "WAI requirements do",
            "content": "An early draft of the WAI requirements doc can be found at http://lists.w3.org/Archives/Public/w3c-wai-gl/2002OctDec/0206.html (let me know if you cannot access this).  The archive contains some comments on the document from WAI personnel.\n\nWe were planning to intersect this document and add our own requirements if possible.\n\nPlease take a look and let me know what you think (I will also do so).\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Weekly telecon cancellatio",
            "content": "Sorry for not sending anything out about the meeting yet, but I've been ill for the last couple of days and will need to see the doctor this afternoon (hopefully nothing serious - probably just food poisoning). I suggest we cancel today's meeting and try again next Wednesday.\n\nCheers,\nRichard.\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2002-1211 at 16:00 UTC, 8am Pacific, 11am Eastern, 01:00 Japan (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n-----------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells \"I18N\")\nDuration : 60 minutes\n-----------------------------------------------------------------------------\nDay     : Wednesday\nDate    : December 11\nStart    : 16:00 UTC, 8am Pacific, 11am Eastern, 01:00 Japan (next day!)\n-----------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n-----------------------------------------------------------------------------\n\n\nDraft agenda\n============\n\nReview of agenda\n\n\nActions\n=======\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts doc) \n\nAll: send in pointers to existing guidelines\n\nSuzanne: put together a list of short term vs. long term goals related to education and outreach - send it to us for discussion\n\n\nDependencies\n============\n\nNone.\n\n\n\nToday's key discussion points\n======================\n\nHow to move forward on the identified specs\n-review of work done (if any) and review of next steps\n-assign an editor\n\nWAI requirements doc\n-can we interface with it?\n\nPointers to existing guidelines\n-need to start collecting\n\nRecruitment\n-next steps?  assignments\n\n\nUpcoming Meetings\n===============\n\nNext telecon: 18 december, same time, same bridge\n\nFTF, January 23-24, Microsoft hosts, Seattle\n\nIUC23, week of 24-28 March 2003, Prague\n\n*** Telecons over Xmas period?\n\n\n\nAOB\n====\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Deliverable 12.1.",
            "content": "The first deliverable in WP 12.1 (open demonstrators - selection of \ndemonstrators) is now due and I've just uploaded our report to the web site. \n\nIt is currently at:\n \nhttp://www.w3.org/2001/sw/Europe/reports/open_demonstrators/hp-applications-selection.html\nPlease let me know if this is the right place or whether it should be moved to\nconform to some naming convention.\n\nAs noted earlier we actually made some informal notes on quite a few (~60)\nexisting and proposed semantic web applications in RDF format[*]. The appendix\nof this report contains a formatted version of this raw data. Putting the data\nin the same document made it a bit large so we've separated the appendix out\ninto a separate document. Please let me know if you think this is not\nappropriate and would prefer some different formatting scheme. \n\nFeedback on the report itself is welcome too!\n\nWhat is our procedure for reviewing/accepting deliverables?\nI assume uploading to the web site was OK given our open-source stance but I\ndon't want to subvert whatever \"due process\" we have/intend to have.\n\nDave\n\n[*] We'd be happy to have the RDF files (currently one file per entry) and\nassociated schema public but (a) I wasn't sure on where that sort of stuff\nshould go on the site layout and (b) it might be better to do that along with a\nweb form to allow more contributions to be added but doing that well would quite\na bit of work.\n\n\n\n"
        },
        {
            "subject": "pointers to guideline",
            "content": "http://www.i18nguy.com/guidelines.html\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "HTML spec UR",
            "content": "My understanding is that this is the html spec we're reading for the 18th:\nhttp://www.w3.org/TR/html401/\n\nCorrect?\n\nThanks,\nSteve\n\nSteve Billings\nGlobal 360\nSoftware Globalization Consulting & Training\nwww.global360.com\n+1 978-697-8201\n\n\n\n"
        },
        {
            "subject": "Re: HTML spec UR",
            "content": "Seems right to me.\n\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: HTML spec UR",
            "content": "Correct!\nRI\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n-----Original Message-----\nFrom: public-i18n-geo-request@w3.org\n[mailto:public-i18n-geo-request@w3.org] On Behalf Of Steve Billings\nSent: 11 December 2002 22:28\nTo: public-i18n-geo@w3.org\nSubject: HTML spec URL\n\n\nMy understanding is that this is the html spec we're reading for the\n18th: http://www.w3.org/TR/html401/ \n\nCorrect?\n\nThanks,\nSteve\n\nSteve Billings\nGlobal 360\nSoftware Globalization Consulting & Training\nwww.global360.com\n+1 978-697-8201\n\n\n\n"
        },
        {
            "subject": "Change of telecon times: i18n GE",
            "content": "Hi adminreq,\n\nWe currently have a regular teleconference booked for Wednesdays at 11am Eastern as listed here:  \n\nI18N_GEO\nI18N GEO\nWednesdays\n11:00am-12:30pm/16:00-17:30 UTC\nZakim Bridge, conference 4186 (\"i18n\")\n10 participants\nRichard Ishida <ishida@w3.org>\n\n\nWe have someone from Australia who wants to join, so please could we change the times as follows:\n\nI18N_GEO\nI18N GEO\nWednesdays\n3:00pm-4:30pm/20:00-21:30 UTC\nZakim Bridge, conference 4186 (\"i18n\")\n10 participants\nRichard Ishida <ishida@w3.org>\n\n\nMany thanks,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "GEO FTF meetings  please respond asa",
            "content": "Chaps,\n\nYesterday Martin and I were discussing the Technical Plenary in March. Our discussion lead me to want to check our plans for upcoming face-to-face meetings. \n\nWe are currently scheduled to meet at Microsoft's offices on 23,24 January near Seattle (thanks Russ!).\n\nOther opportunities for face to face meetings include:\n\nA] During the W3C Technical Plenary, 3-7 March in Boston.  (The Tech Plenary is a chance for many WGs to hold co-located meetings so that they can discuss things together / observe each other ).\n\nB] Around the Internationalization & Unicode Conference, 24-26 March in Prague.\n\n**************************\nCould all WG members please send in their thoughts on the following asap (since we ought to finalise plans for the Tech Plenary today.)  \n**************************\n\n\n1] Does it still make sense to have a separate FTF at Microsoft, given the Tech Plenary in Boston in March?\n\n2] Who would like to hold a meeting during the Tech Plenary?\n\n3] Who would like to hold a meeting at the IUC in Prague?\n\n4] If we do hold a meeting at Microsoft before the Tech Plenary, is the timing right, or should we move it into February.\n\n\nMany thanks,\nRI\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18N GEO TF teleconference, 11 nov 200",
            "content": "Attendees\n========\nAC Andrew Cunningham\nSB Steve Billings\nRR Russ Rolfe\nRI Richard Ishida (chair & scribe)\nTT Tex Texin\n\nRegrets\n======\nLH Lloyd Honomichl\n\n\nActions\n=======\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) \nongoing\n\nAll: send in pointers to existing guidelines\nongoing\n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion\nOngoing\n\n\n\nDependencies\n============\n\nNone.\n\n\n\nHow to move forward on the identified specs\n=================================\nAgreed to all read through the HTML 4.01 spec\n[http://www.w3.org/TR/html401/] before next telecon (or as much of it as\npossible), looking for ideas for guidelines.  We should submit our ideas\nto public-i18n-geo@w3.org.  We should submit proposed guidelines - just\nthe pithy do's and don'ts, not with explanatory text etc., but we should\ninclude notes about any additional information that should be included\nto round out the guidelines (eg. Point to IANA names lists, etc.).  \n\nA major objective of this exercise is to help us formulate what\nguidelines we will be developing.  RI urged all to not just look for\nstatements re do's and don'ts in the spec, but to consider how they map\nto tasks or activities that need to be accomplished.\n\nAC agreed to compile, in rough and ready form, the data that people send\nin.\n\n\nWAI requirements doc\n[http://lists.w3.org/Archives/Public/w3c-wai-gl/2002OctDec/0206.html]\n==================\nRichard will study this in detail while working on the framework\ndocument, and will liaise with WAI.\n\nAll GEO WG members should review (it's very short) and send any\nsuggestions to the list.\n\n\n\nPointers to existing guidelines\n======================\n\nThe objective here is to:\n1] gather a set of guidelines we can use as sources for our own\nguidelines development\n2] gather potential guidelines we can point to for areas we are\ncurrently not yet addressing (eg. JSP i18n)\n\nWe will take Tex's list of links to guidelines\n[http://www.i18nguy.com/guidelines.html]\nas a starting point.  We will assess the suitability of linking to Tex's\npage and adding new links to that, or establishing our own list.  In\neither case a link should be added to the GEO home page.\n\nEveryone is encouraged to submit links, preferably with a brief\ncommentary.\n\n\n\nRecruitment\n=========\nWe agreed at the FTF to begin an additional recruitment drive.  Specific\npeople were assigned today to contact people in various companies and\nask whether they knew of people who would be interested in participating\nin the GEO work.\n\nRR john jenkins (Apple), andrea vine (Sun), nuray aykin (Siemens),\ntrados, boeing\nTT mark davis, lisa moore (IBM), hideki hiura (Sun)\nRI craig cummings (Oracle), yves savourel (RWS), christian lieske (SAP),\nfrank tang (Netscape), hakon lee (Opera)\n\n\n\nWeb pages\n=========\nThese have been updated slightly.\n\n\n\nUpcoming Meetings\n===============\nDue to AC wanting to join from Australia, RI will arrange for\nteleconference meetings to be moved to 20:00 UTC on Wednesdays.  \n\nAt the next teleconference we will decide on whether to plan a telecon\nduring the Christmas period.\n\nNext telecon: 18 december, 20:00 UTC, Bridge: +1-617-761-6200 (Zakim)\nwith conference code 4186 (spells \"I18N\")\n\n\nPlease send corrections, additions, or other comments.\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "FW: [Important MIT Systems Notice] Power outage Dec. 28th (fwd",
            "content": "FYI.  Note that, essentially, w3c mail services are unlikely to be\naffected for pretty much the whole of the day of 28th dec. (meaning\n'day' in terms of the East Coast US time zone).\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n-----Original Message-----\nFrom: w3t-request@w3.org [mailto:w3t-request@w3.org] On Behalf Of Simon\nJ. Hernandez\nSent: 13 December 2002 15:46\nTo: w3t@w3.org; system-notices@w3.org\nSubject: [Important MIT Systems Notice] Power outage Dec. 28th (fwd)\n\n\n\n\nWe have received the final date and times for the planned power outage\non 28 Dec 2002.\n\nPending discussion, it is likely the power outage may occur on the\nevening prior to the scheduled power shutdown.\n\nPlease make note, list, and mail services, as well as write access to\nthe site will be suspended during the power outage.\n\n\n\n\nSimon\n\n\n---------- Forwarded message ----------\nDate: Fri, 13 Dec 2002 09:32:48 -0500\nFrom: M. A. Ladd <ladd@lcs.mit.edu>\nTo: all-lcs@lcs.mit.edu\nSubject: Power outage Dec. 28th\nResent-Date: Fri, 13 Dec 2002 09:49:21 -0500\nResent-From: ladd@lcs.mit.edu\nResent-To: all-lcs@lcs.mit.edu\n\nAt a meeting this morning the schedule for the power outage on Dec. 28th\nwas detailed and currently is as follows:\n\n0500 NE43 closed to non-essential personnel\n\n0700 Building power shutdown\n\n1800 Approximate time for power-up\n\nHopefully, we can have the building reopened to everyone two hours after\nthe power is restored.\n\nThis work will put us back onto the tranformers near Main St. and the\nplan is for the building to remain on those transformers until *after*\nwe move to Stata.\n\nMary Ann\n\n\n---------- End Forwarded message ----------\n\n\n\n\n-- \nSimon J. Hernandez    |    http://people.w3.org/simon/    |\nsimon@w3.org\nWorld Wide Web Consortium (W3C)\nhttp://www.w3.org\nMIT Laboratory for Computer Science    200 Technology Square\nNE43-340\nCambridge, MA 02139-3579 USA  Voice: +1.617.253.2920  Fax:\n+1.617.258.5999\n\n\n\n"
        },
        {
            "subject": "My first draft notes from reading the HTML spe",
            "content": "Chaps,\n\nYou can find a first batch of VERY rough notes from me at\nhttp://www.w3.org/People/Ishida/checklists/i18n-guidelines.html\n\nThese are all prompted by a quick reading of section 5, but I have added\none or two other thoughts that sprang to mind as I went.\n\nI tried to roughly organise things in terms of the tasks we were\nenabling the audience to complete, and made a quick and dirty stab at\nwhich things would be relevant to what type of audience.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "RE: Deliverable 12.1.",
            "content": ">http://www.w3.org/2001/sw/Europe/reports/open_demonstrators/hp-appl\n>ications-selection.html\n>Please let me know if this is the right place or whether it should\n>be moved to\n>conform to some naming convention.\n\nCould the response be asap - there's just been the recurring 'but what RDF\napps are there?' thread on xml-dev again, and being able to point to\nsomething like this would be a big step forward.\n\n>Feedback on the report itself is welcome too!\n\nI've only skimmed so far, but it looks really good ;-)\n\nbtw, re. semantic blogging - I've been looking at this area with the\nintention of incorporating such facilities in the 'Ideagraph' app I'm\nworking on. The approach is aimed more towards the informal blogging arena\nrather than the ClaiMaker scholasticism, and I've started putting together a\nschema at http://purl.org/ibis . I'm planning on using this, along with some\nclassification metadata within RSS, and for test domain (dogfood) using my\nblog at http://www.citnames.com/blog/\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "WASP guideline for character encodin",
            "content": "Here is an interesting guideline style, and happens to be about i18n.\n\nhttp://www.webstandards.org/learn/askw3c/dec2002.html\n\ntex\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: GEO FTF meetings  please respond asa",
            "content": "Richard:\n\n1] Does it still make sense to have a separate FTF at Microsoft, given the Tech Plenary in Boston in March?\n==> For me, cash might turn out to be a bigger issue than I thought for the Seattle meeting.\n\n2] Who would like to hold a meeting during the Tech Plenary?\n==> Ideal for me.\n\n3] Who would like to hold a meeting at the IUC in Prague?\n==> I won't be there.\n\n4] If we do hold a meeting at Microsoft before the Tech Plenary, is the timing right, or should we move it into February.\n==> As far as I know at this point, I'm neutral on the timing.\n\nSteve\n\nSteve Billings\nGlobal 360\nSoftware Globalization Consulting & Training\nwww.global360.com <http://www.global360.com/> \n+1 978-697-8201\n \n\n\n-----Original Message-----\nFrom: public-i18n-geo-request@w3.org\n[mailto:public-i18n-geo-request@w3.org]On Behalf Of Richard Ishida\nSent: Friday, December 13, 2002 8:39 AM\nTo: public-i18n-geo@w3.org\nSubject: GEO FTF meetings - please respond asap\n\n\n\nChaps,\n\nYesterday Martin and I were discussing the Technical Plenary in March. Our discussion lead me to want to check our plans for upcoming face-to-face meetings. \n\nWe are currently scheduled to meet at Microsoft's offices on 23,24 January near Seattle (thanks Russ!).\n\nOther opportunities for face to face meetings include:\n\nA] During the W3C Technical Plenary, 3-7 March in Boston.  (The Tech Plenary is a chance for many WGs to hold co-located meetings so that they can discuss things together / observe each other ).\n\nB] Around the Internationalization & Unicode Conference, 24-26 March in Prague.\n\n**************************\nCould all WG members please send in their thoughts on the following asap (since we ought to finalise plans for the Tech Plenary today.)  \n**************************\n\n\n1] Does it still make sense to have a separate FTF at Microsoft, given the Tech Plenary in Boston in March?\n\n2] Who would like to hold a meeting during the Tech Plenary?\n\n3] Who would like to hold a meeting at the IUC in Prague?\n\n4] If we do hold a meeting at Microsoft before the Tech Plenary, is the timing right, or should we move it into February.\n\n\nMany thanks,\nRI\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: GEO FTF meetings  please respond asa",
            "content": "Hi, I have a flu so my fevered brain might not be working clearly (well\nas clear as it gets anyway), so I wonder:\n\n1) Do we have a goal for number of FTF's per year?\n2) Do we have a goal for regional distribution of the FTF's?\n3) Do we have milestones which might drive the need to meet?\n\nIt might be easier to answer the questions below if we knew our\nobjectives.\nFor example, if we thought we should meet 4 vs 6 vs 8 times per year, it\nwould be easier to answer the need to meet in Jan, Feb or Mar.\nAlso if we had an idea that one in \"N\" meetings should be in Europe or\nAsia/Pac to accomodate those members we could gauge the suitability of\nPrague or other locations. We can also then tie in to other events we\nmight attend. Later our meeting dates will be driven by our need to\npublish (and therefore meet) before milestone dates.\n\nFor the near term, I think the more the merrier so we can come together\nas a team (in a social sense, with agreements on working styles and\nprocesses).\n\nThat said, I can't make Wash.\nPrague and Boston are ok.\n\nI wonder if video conferencing is possible? Does w3c cambridge have\nvideo conf. abilities so those of us in boston could attend Wash. that\nway?\n\nok back to fighting the fever.\n\nRichard Ishida wrote:\n> \n> Chaps,\n> \n> Yesterday Martin and I were discussing the Technical Plenary in March. Our discussion lead me to want to check our plans for upcoming face-to-face meetings.\n> \n> We are currently scheduled to meet at Microsoft's offices on 23,24 January near Seattle (thanks Russ!).\n> \n> Other opportunities for face to face meetings include:\n> \n> A] During the W3C Technical Plenary, 3-7 March in Boston.  (The Tech Plenary is a chance for many WGs to hold co-located meetings so that they can discuss things together / observe each other ).\n> \n> B] Around the Internationalization & Unicode Conference, 24-26 March in Prague.\n> \n> **************************\n> Could all WG members please send in their thoughts on the following asap (since we ought to finalise plans for the Tech Plenary today.)\n> **************************\n> \n> 1] Does it still make sense to have a separate FTF at Microsoft, given the Tech Plenary in Boston in March?\n> \n> 2] Who would like to hold a meeting during the Tech Plenary?\n> \n> 3] Who would like to hold a meeting at the IUC in Prague?\n> \n> 4] If we do hold a meeting at Microsoft before the Tech Plenary, is the timing right, or should we move it into February.\n> \n> Many thanks,\n> RI\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/\n> http://www.w3.org/People/Ishida/\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: GEO FTF meetings  please respond asa",
            "content": "Hi Richard,\n\nRichard Ishida wrote:\n\n>\n>1] Does it still make sense to have a separate FTF at Microsoft, given the Tech Plenary in Boston in March?\n>  \n>\nMy first reaction is that it wouldn't make much sense to have two FTF's \nclose together. But on second thoughts it might provide a timeframe for \nus to work towards if we had clearly identified milestones or tasks for \neach FTF.\n\nBut its academic to me in a sense, since I could only attend either in a \nvirtual sense, by teleconference or videoconferencing.\n\n>2] Who would like to hold a meeting during the Tech Plenary?\n>\n>3] Who would like to hold a meeting at the IUC in Prague?\n>\n>4] If we do hold a meeting at Microsoft before the Tech Plenary, is the timing right, or should we move it into February.\n>  \n>\nReally depends on whether we can get through enough material to make the \nMicrosoft FTF worthwhile. I suspect that a FTF at Microsoft and Boston \nmay be too close to get any real benefit from the second FTF, unless \nwe're quite focused. Depends onhow much we can work through between the \ntwo FtF's within the context of our other commitments.\n\nAndrew\n\nAndrew Cunningham\nMultilingual Technical Officer\nOnline Porjects Team, Vicnet\nState Library of Victoria\nAustralia\n\nandrewc@vicnet.net.au\n\n\n\n"
        },
        {
            "subject": "RE: WASP guideline for character encodin",
            "content": "This also has potential for our outreach activities.\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> Sent: 14 December 2002 07:12\n> To: GEO\n> Subject: WASP guideline for character encoding\n> \n> \n> \n> Here is an interesting guideline style, and happens to be about i18n.\n> \n> http://www.webstandards.org/learn/askw3c/dec2002.html\n> \n> tex\n> -- \n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n>                          \n> XenCraft            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n> \n\n\n\n"
        },
        {
            "subject": "RE: Change of telecon times: i18n GE",
            "content": "All,\nPlease note the new teleconference time.  I'll send out an agenda\ntomorrow.\nRI\n \n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n-----Original Message-----\nFrom: Carol Nicolora [mailto:carol@w3.org] \nSent: 13 December 2002 16:39\nTo: ishida@w3.org; adminreq@w3.org\nCc: public-i18n-geo@w3.org\nSubject: Re: Change of telecon times: i18n GEO\n\n\nHi Richard,\n\nPer your request, I have changed this telecon time starting 18 December.\nThis teleconference is scheduled through  22 Jan 03.\n\nI18N_GEO\nI18N GEO\nWednesdays\n3:00pm-4:30pm/20:00-21:30 UTC\nZakim Bridge, conference 4186 (\"i18n\")\n10 participants\nRichard Ishida <ishida@w3.org>\n\n\nBest,\nCarol\n\n\n\n \n\n\n\n"
        },
        {
            "subject": "RE: GEO FTF meetings  please respond asa",
            "content": "Richard,\n\nIt would be easier to give an opinion on when to do face to face if we had a better idea what our agendas would be for the meetings.  With out an agenda and just looking at meeting times, it makes more sense to meet in March at the Tech Plenary, than to have one  January in Seattle, One at the beginning of March for the Tech Plenary and then one at the end of March in Prague.\n\nRegards, Russ\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org] \nSent: Friday, December 13, 2002 5:39 AM\nTo: public-i18n-geo@w3.org\nSubject: GEO FTF meetings - please respond asap\n\n\n\nChaps,\n\nYesterday Martin and I were discussing the Technical Plenary in March. Our discussion lead me to want to check our plans for upcoming face-to-face meetings. \n\nWe are currently scheduled to meet at Microsoft's offices on 23,24 January near Seattle (thanks Russ!).\n\nOther opportunities for face to face meetings include:\n\nA] During the W3C Technical Plenary, 3-7 March in Boston.  (The Tech Plenary is a chance for many WGs to hold co-located meetings so that they can discuss things together / observe each other ).\n\nB] Around the Internationalization & Unicode Conference, 24-26 March in Prague.\n\n**************************\nCould all WG members please send in their thoughts on the following asap (since we ought to finalise plans for the Tech Plenary today.)  \n**************************\n\n\n1] Does it still make sense to have a separate FTF at Microsoft, given the Tech Plenary in Boston in March?\n\n2] Who would like to hold a meeting during the Tech Plenary?\n\n3] Who would like to hold a meeting at the IUC in Prague?\n\n4] If we do hold a meeting at Microsoft before the Tech Plenary, is the timing right, or should we move it into February.\n\n\nMany thanks,\nRI\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Next FT",
            "content": "Chaps,\n\nThanks to all who responded.  Sorry for the rush, but the deadline for\nthe Tech Plenary arrangements was suddenly upon us.  Having just spoken\nwith Russ, I'm leaning toward the idea of skipping the Seattle meeting,\nand going for a meeting at the Technical Plenary in Boston.  Dates would\nbe 3 and 4 March.\n\nLets discuss this as one of our top priorities on Wednesday and take a\ndecision.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "FW: Misha retires as I18n chai",
            "content": "See the note from Tim Berners-Lee below.  I have also added a news item\nto the Internationalization Activity web site [see\nhttp://www.w3.org/International/ and\nhttp://www.w3.org/International/events.html#misha-leaves].\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n-----Original Message-----\nFrom: w3c-i18n-wg-request@w3.org [mailto:w3c-i18n-wg-request@w3.org] On\nBehalf Of Tim Berners-Lee\nSent: 13 December 2002 03:04\nTo: chairs@w3.org\nCc: w3c-i18n-wg@w3.org\nSubject: Misha retires as I18n chair\n\n\n\nAfter years of ardent,  often animated and always enthusiastic service\nto the Internationalization community as I18n working group chair,\nMisha Wolf now finds he has to turn his attention to other \nthings.\nI'd like to thank Misha for everything he has done and fervently hope\nthat this won't be the last we all see of him!\n\nRichard Ishida  has kindly agreed to take over as chair, at least for\nthe near term.\n\nAgain thanks to Misha for all he has done, and to Reuters for \nsupporting his\nexcellent work.\n\nTim Berners-Lee\nDirector W3C\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "Danny Ayers wrote:\n>\n> >Feedback on the report itself is welcome too!\n> \n> I've only skimmed so far, but it looks really good ;-)\n\nThanks. As we noted in the report the app survey is more representative than\ncomprehensive - there are bound to be many important ones we missed and others\nwe haven't fully captured - but it felt like a useful start. \n\n> btw, re. semantic blogging - I've been looking at this area with the\n> intention of incorporating such facilities in the 'Ideagraph' app I'm\n> working on. The approach is aimed more towards the informal blogging arena\n> rather than the ClaiMaker scholasticism, and I've started putting together a\n> schema at http://purl.org/ibis . I'm planning on using this, along with some\n> classification metadata within RSS, and for test domain (dogfood) using my\n> blog at http://www.citnames.com/blog/\n\nSounds interesting. It might be worth exploring whether any of the tools we put\ntogether to support this might be helpful to you and vice versa. If you have any\nthoughts on requirements for such tools then we'd be really interested in\nhearing about them.\n\nCheers,\nDave\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2002-1211 at 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\n-----\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n\"I18N\")\nDuration : 60 minutes\n------------------------------------------------------------------------\n-----\nDay     : Wednesday\nDate    : December 11\nStart    : 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next\nday!)\n------------------------------------------------------------------------\n-----\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n-----\n\n\nDraft agenda\n============\n\nReview of agenda\n\n\nActions\n=======\n\nAll: read through HTML 4.0 spec and send notes to the list about\npossible guidelines.\n\nAndrew: roughly synthesise notes from previous action\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) & also review and respond to WAI requirements doc\n\nAll: send in pointers to existing guidelines\n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion\n\nRuss: contact the following people/orgs in search of additional\nparticipants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n(Siemens), trados, boeing\n\nTex: contact the following people/orgs in search of additional\nparticipants: mark davis, lisa moore (IBM), hideki hiura (Sun)\n\nRichard: craig cummings (Oracle), yves savourel (RWS), christian lieske\n(SAP), frank tang (Netscape), hakon lee (Opera)\n\nRichard: arrange new time for teleconferences to capture Australia\nDone\n\n\n\nDependencies\n============\n\nNone.\n\n\n\nToday's key discussion points\n======================\n\nMeetings\n-do we telecon over Xmas period?\n-next FTF (seattle or boston?)\n\nGuidelines\n-review of work done and next steps\n\n\n\nAOB\n====\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: AGENDA: I18N GEO TF telcon, 2002-1211 at 20:00 UTC, 12noon Pacific,   3pm Eastern, 7am Australia (next day!",
            "content": "Just a status report:\nI did send mails, have had no replies. Probably with the holidays coming\nup it is hard to enlist recruits. Perhaps send ticklers after the new\nyear.\n\nI may be a little late to the meeting, I will be on the road hope to be\nback before 3:20.\n\ntex\n\nRichard Ishida wrote:\nTex: contact the following people/orgs in search of additional\n> participants: mark davis, lisa moore (IBM), hideki hiura (Sun)\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: AGENDA: I18N GEO TF telcon, 2002-1211 at 20:00 UTC, 12noon Pacific,  3pm Eastern, 7am Australia (next day!",
            "content": "Yes, I was actually thinking to wait until the New Year before\ncontacting the people on my list, rather than lose momentum during the\nXmas break.  New Year is also a time of new beginnings and enthusiasm,\nso it may get more attention then for that reason too.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: Tex Texin [mailto:tex@i18nguy.com] \n> Sent: 18 December 2002 01:49\n> To: ishida@w3.org\n> Cc: public-i18n-geo@w3.org\n> Subject: Re: AGENDA: I18N GEO TF telcon, 2002-12-11 at 20:00 \n> UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next day!)\n> \n> \n> Just a status report:\n> I did send mails, have had no replies. Probably with the \n> holidays coming up it is hard to enlist recruits. Perhaps \n> send ticklers after the new year.\n> \n> I may be a little late to the meeting, I will be on the road \n> hope to be back before 3:20.\n> \n> tex\n> \n> Richard Ishida wrote:\n> Tex: contact the following people/orgs in search of additional\n> > participants: mark davis, lisa moore (IBM), hideki hiura (Sun)\n> \n> -- \n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n>                          \n> XenCraft            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n> \n\n\n\n"
        },
        {
            "subject": "RE: AGENDA: I18N GEO TF telcon, 2002-1211 at 20:00 UTC, 12noon Pacific,  3pm Eastern, 7am Australia (next day!",
            "content": "Same here.\n\nRuss\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org] \nSent: Wednesday, December 18, 2002 2:09 AM\nTo: 'Tex Texin'\nCc: public-i18n-geo@w3.org\nSubject: RE: AGENDA: I18N GEO TF telcon, 2002-12-11 at 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next day!)\n\n\n\nYes, I was actually thinking to wait until the New Year before contacting the people on my list, rather than lose momentum during the Xmas break.  New Year is also a time of new beginnings and enthusiasm, so it may get more attention then for that reason too.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: Tex Texin [mailto:tex@i18nguy.com]\n> Sent: 18 December 2002 01:49\n> To: ishida@w3.org\n> Cc: public-i18n-geo@w3.org\n> Subject: Re: AGENDA: I18N GEO TF telcon, 2002-12-11 at 20:00 \n> UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next day!)\n> \n> \n> Just a status report:\n> I did send mails, have had no replies. Probably with the\n> holidays coming up it is hard to enlist recruits. Perhaps \n> send ticklers after the new year.\n> \n> I may be a little late to the meeting, I will be on the road\n> hope to be back before 3:20.\n> \n> tex\n> \n> Richard Ishida wrote:\n> Tex: contact the following people/orgs in search of additional\n> > participants: mark davis, lisa moore (IBM), hideki hiura (Sun)\n> \n> --\n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n>                          \n> XenCraft            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n> \n\n\n\n"
        },
        {
            "subject": "HTML Guidelines: Organizing a multilingual sit",
            "content": "At this point my notes only identify areas to look into further, but here come some of the more significant items from them:\n\nA possible guideline topic: How to organize a multilingual website where each page has multiple versions (alternate pages in different languages and different encodings).\nThe spec addresses it here: http://www.w3.org/TR/html401/struct/links.html#h-12.1.5\n\n- Steve\n\n\n\n"
        },
        {
            "subject": "HTML Guidelines: quick reference for what can be in the document character se",
            "content": "Along with the guidelines, we might want to include a mechanism (like a table or something) for quick access to rules what must be ascii vs. what can be in the document character set. (Localizers might use this.) Things like: \n  a.. content (well, this one is easy) \n  b.. attribute values (both text and numeric); see http://www.w3.org/TR/html401/intro/sgmltut.html#attributes \n  c.. The quotes around text attribute values; see http://www.w3.org/TR/html401/intro/sgmltut.html#attributes \n  d.. URIs \n  e.. anchor names \n  f.. whitespace \n- Steve\n\n\n\n"
        },
        {
            "subject": "HTML Guidelines: URI character set / encodin",
            "content": "I think the HTML guidelines will need to either address URI issues like character set/encoding, or point to something that does in a readable way. Is there something already written about URIs that would be appropriate?\n\n- Steve\n\n\n\n"
        },
        {
            "subject": "General &ndash;&ndash; What to cover when there are no solution",
            "content": "As we develop guidelines, there will be areas that do not have a current solution (e.g.. non-supported Scripts).   With in this area, we should make sure to list \"Things you should not do\" so that people will understand the consequences of possible \"hacks\" as they try to solve their problems.\n \nRuss\n\n\n\n"
        },
        {
            "subject": "Re: HTML Guidelines: URI character set / encodin",
            "content": "There is a draft spec for IRI (Internationalized URI) \n\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri.txt\n\nIt will need some guidelines...\n\n\n> Steve Billings wrote:\n> \n> ???\n> I think the HTML guidelines will need to either address URI issues\n> like character set/encoding, or point to something that does in a\n> readable way. Is there something already written about URIs that would\n> be appropriate?\n> \n> - Steve\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "On Tue, 5 Nov 2002, Dave Reynolds wrote:\n\n>\n> The first deliverable in WP 12.1 (open demonstrators - selection of\n> demonstrators) is now due and I've just uploaded our report to the web site.\n\nNice work!\n\n> It is currently at:\n>\n> http://www.w3.org/2001/sw/Europe/reports/open_demonstrators/hp-applications-selection.html\n> Please let me know if this is the right place or whether it should be moved to\n> conform to some naming convention.\n\nIn http://www.w3.org/2001/sw/Europe/reports/ we've put each of the other\ndeliverables in a directory named after the short name for the\ndeliverable. Makes cross-linking from other indices a bit easier.\n\nIf you could copy yours into a 'chosen_demos_rationale_report'\nsubdirectory, that would be good. I can clean up the other directories if\nyou have any difficulty doing so (remind me, how are you editing the\nsite? jigedit? cvs?).\n\n> As noted earlier we actually made some informal notes on quite a few (~60)\n> existing and proposed semantic web applications in RDF format[*]. The appendix\n> of this report contains a formatted version of this raw data. Putting the data\n> in the same document made it a bit large so we've separated the appendix out\n> into a separate document. Please let me know if you think this is not\n> appropriate and would prefer some different formatting scheme.\n\nSeems OK to me.\n\n> Feedback on the report itself is welcome too!\n\nOne tiny thing that jumped out from a quick skim: s/Wiener/Winer/\n\nI do like the idea of focussing on weblog-style apps. Is nicely nearterm,\npotential for mass uptake, network effects etc...\n\n> What is our procedure for reviewing/accepting deliverables?\n> I assume uploading to the web site was OK given our open-source stance but I\n> don't want to subvert whatever \"due process\" we have/intend to have.\n\nThere's something of a watch-this-space where better process should live.\nChecking works in progress into the site is fine...\n\nDan\n\n> [*] We'd be happy to have the RDF files (currently one file per entry) and\n> associated schema public but (a) I wasn't sure on where that sort of stuff\n> should go on the site layout\n\nA subdirectory of the reports dir would be fine. For other misc things,\njust create a dated directory in the .../sw/Europe/YYYYMM/etc/ tree, eg\nsw/Europe/200211/appsurvey-data/\n\nand (b) it might be better to do that along with a\n> web form to allow more contributions to be added but doing that well would quite\n> a bit of work.\n\nYup\n\n\n\n"
        },
        {
            "subject": "HTML guidelines: character encodin",
            "content": "Richard's notes on HTML 4.01 include the recommendation to use Unicode. \nIt would be useful to link from such a recommendation to guidelines on \nusing unicode in HTML (based on the Unicode report/W3C note \"Unicode in \nXML and other markup languages\" http://www.w3.org/TR/unicode-xml/\n\nAndrew\n\n\n\n"
        },
        {
            "subject": "General: African language",
            "content": "WRT today's teleconference:\n\nWhat follows is very very brief. If people want more details or have \nspecific questions, please let me know.\n\nAfrican languages fall into four categories:\n\n1) languages supported by unicode.\nE.g. Hausa and Pulaar (using Latin script).\n\n2) languages supported by unicode, but require additional support in \nrendering systems.\n\nE.g. Yoruba, Ife, Dinka, Nuer, etc.\n\nThis can include correct placement of combining diacritics based on \nlanguages' typographic conventions, or stacking of combining diacritics. \nIfe offers a challenging example.\n\nSome notes under construction that may illustrate some of the issues:\n\nhttp://www.openroad.net.au/languages/african/ife-2.html\nhttp://www.openroad.net.au/languages/african/dinka-4.html\n\nThis is an issue for font rendering technologies (AAT/ATSUI, Uniscribe \nand Graphite for example). OpenType has features (e.g. MarkToBase, \nMarkToMark) that are designed for correct positioning of combining \ndiacritics. Support for this in Uniscribe is currently under \ndevelopment. (Not sure of the status of AAT/ATSUI in this regard).\n\nIn some cases: (Dinka and Nuer for instance) the existing combining \ndiacritics for some fonts are adequate for lowercase characters (but not \noptimal), although entirely unsuitable for uppercase characters. In \nother cases like Ife, where diacritic stacking is required, it is a \ncrucial concern which will be alleviated when the new versions of the \nfont rendering technologies become widespread.\n\nAdditionally, African languages use alternative glyphs for certain \ncharacters (most common example is uppercase ENG). It is possible to \ncreate alternative glyphs for different languages/typographic traditions \nwithin an opentype font. Unfortunately current software is unable to \ninteract sufficiently with the font rendering systems to allow use of \nlangauge specific features within fonts.\n\nAt least thats my current understanding.\n\n3) languages that have some characters that are not present in Unicode.\nE.g. Dagera (Burkina Faso), Hausa/Pulaar/etc. in Ajami (Arabic script).\n\nThere has been a fair amount of discussion recently on Ajami on the \nUnicode-Afrique, A12N Collaboration and H-Hausa mailing lists.\n\n4) scripts currently not supported by Unicode.\nE.g  N'ko, Vai, Tifinagh, etc.\n\nWith respect to HTML, issues are how to identify languages when there is \nno ISO-639-1 code or IANA language code. How should the \"x-\" convention \nbe used in practical settings?\n\nFor an example:\n\nhttp://home.vicnet.net.au/~andrewc/samples/nuer.htm\n\nI've use a convention \"x-sil-\" to indicate an ethnologue language codes. \nAlthough thats neither here nore there.\n\nOther key issues include charset identification in the absence of \n\"defined\" character encodings.\n\nA useful starting point is the \"A12N gateway\" http://www.bisharat.net/A12N/\n\nAndrew\n\nAndrew Cunningham\nMultilingual Technical Officer\nOPT, Vicnet,\nState Library of Victoria\nAustralia\n\nandrewc@vicnet.net.au\n\n\n\n"
        },
        {
            "subject": "Re: General: African language",
            "content": "Hello Andrew,\n\nAt 20:28 02/12/18 +1100, Andrew Cunningham wrote:\n\n>WRT today's teleconference:\n>\n>What follows is very very brief. If people want more details or have \n>specific questions, please let me know.\n>\n>African languages fall into four categories:\n>\n>1) languages supported by unicode.\n>E.g. Hausa and Pulaar (using Latin script).\n>\n>2) languages supported by unicode, but require additional support in \n>rendering systems.\n>\n>E.g. Yoruba, Ife, Dinka, Nuer, etc.\n>\n>This can include correct placement of combining diacritics based on \n>languages' typographic conventions, or stacking of combining diacritics. \n>Ife offers a challenging example.\n>\n>Some notes under construction that may illustrate some of the issues:\n>\n>http://www.openroad.net.au/languages/african/ife-2.html\n\nVery nice notes.\n\nIt would be very good to note that at least on the Web,\nNFC should always be preferred. I.e. don't just say\n\nU+00E3 U+0300 or U+0061 U+0303 U+0300\nLATIN SMALL LETTER A WITH TILDE WITH COMBINING GRAVE\n\nBut make it clear that U+00E3 U+0300 is the right way to go.\nThis will help a lot for low-level comparisons,...\n\n\n>http://www.openroad.net.au/languages/african/dinka-4.html\n\nI checked this one, and it was in NFC. But I didn't see\na language indication for Dinka. Maybe there is no code?\n\n\n>This is an issue for font rendering technologies (AAT/ATSUI, Uniscribe and \n>Graphite for example). OpenType has features (e.g. MarkToBase, MarkToMark) \n>that are designed for correct positioning of combining diacritics. Support \n>for this in Uniscribe is currently under development. (Not sure of the \n>status of AAT/ATSUI in this regard).\n\nDon't at least some of these technologies offer the possibility to\ndefine glyphs for combinations of characters? Also, please check\nSVG and see whether it contains the necessary mechanisms (it should!).\n\n\n>In some cases: (Dinka and Nuer for instance) the existing combining \n>diacritics for some fonts are adequate for lowercase characters (but not \n>optimal), although entirely unsuitable for uppercase characters. In other \n>cases like Ife, where diacritic stacking is required, it is a crucial \n>concern which will be alleviated when the new versions of the font \n>rendering technologies become widespread.\n\nA more short-time solution would be to create e.g. a True-Type\nfont for Dinka, which covers all the necessary combinations, and\nhas the right glyph shapes for the upper-case diacritics, and\ngive that font priority in style sheets for Dinka material.\n\n\n>Additionally, African languages use alternative glyphs for certain \n>characters (most common example is uppercase ENG). It is possible to \n>create alternative glyphs for different languages/typographic traditions \n>within an opentype font. Unfortunately current software is unable to \n>interact sufficiently with the font rendering systems to allow use of \n>langauge specific features within fonts.\n\nAgain, having a specially-designed font (or some fonts) may be\na short to middle-range solution.\n\n\n>At least thats my current understanding.\n>\n>3) languages that have some characters that are not present in Unicode.\n>E.g. Dagera (Burkina Faso), Hausa/Pulaar/etc. in Ajami (Arabic script).\n>\n>There has been a fair amount of discussion recently on Ajami on the \n>Unicode-Afrique, A12N Collaboration and H-Hausa mailing lists.\n\nVery good. The important thing is to take such discussion (or the\nresults and main points) over to unicode@unicode.org (or even unicore),\nand to work on actual proposals.\n\n\n>4) scripts currently not supported by Unicode.\n>E.g  N'ko, Vai, Tifinagh, etc.\n\nFor some work on the later, please see\nhttp://std.dkuug.dk/jtc1/sc2/wg2/docs/n1757.pdf\n\n\n>With respect to HTML, issues are how to identify languages when there is \n>no ISO-639-1 code or IANA language code. How should the \"x-\" convention be \n>used in practical settings?\n\nNot at all, if possible.\n\n\n>For an example:\n>\n>http://home.vicnet.net.au/~andrewc/samples/nuer.htm\n\n[I find the en-AU in <h1 xml:lang=\"en-AU\">Nuer test page</h1>\na bit too much, but that's a detail.]\n\n\n>I've use a convention \"x-sil-\" to indicate an ethnologue language codes. \n>Although thats neither here nore there.\n\nExactly. If the language in question has some ammout of printed works\n(50 different items to be exact), then you should apply for an iso-639-2\ncode. if the language in question doesn't have that much printed material,\nyou should apply for an IANA code.\n\n\n>Other key issues include charset identification in the absence of \n>\"defined\" character encodings.\n\nThere are no 'undefined' character encodings. If somebody\ndoes an encoding, they should document it, and register it\nwith IANA. It's rather easy to do that. But working towards\ngetting the necessary characters into Unicode may be\nmuch better use of your time.\n\nRegards,    Martin.\n\n\n>A useful starting point is the \"A12N gateway\" http://www.bisharat.net/A12N/\n>\n>Andrew\n>\n>Andrew Cunningham\n>Multilingual Technical Officer\n>OPT, Vicnet,\n>State Library of Victoria\n>Australia\n>\n>andrewc@vicnet.net.au\n\n\n\n"
        },
        {
            "subject": "Re: General: African language",
            "content": "Hi Martin,\n\nMartin Duerst wrote:\n> \n> Very nice notes.\n> \n\njust a work in progress.\n\n> It would be very good to note that at least on the Web,\n> NFC should always be preferred. I.e. don't just say\n> \n> U+00E3 U+0300 or U+0061 U+0303 U+0300\n> LATIN SMALL LETTER A WITH TILDE WITH COMBINING GRAVE\n> \n> But make it clear that U+00E3 U+0300 is the right way to go.\n> This will help a lot for low-level comparisons,...\n> \n> \n\nthanks, i was intending to write up soem notes on using NFC  and also on \naccent ordering.\n\n\n\n>> http://www.openroad.net.au/languages/african/dinka-4.html\n> \n> \n> I checked this one, and it was in NFC. But I didn't see\n> a language indication for Dinka. Maybe there is no code?\n> \n\nDinka doesn't have a ISO-639-1 langauge code, although it does have a \nISO-639-2 code \"din\". The poage was originally a HTML4 page so couldn't \nuse the iso-369-2 language code.\n\n> \n>> This is an issue for font rendering technologies (AAT/ATSUI, Uniscribe \n>> and Graphite for example). OpenType has features (e.g. MarkToBase, \n>> MarkToMark) that are designed for correct positioning of combining \n>> diacritics. Support for this in Uniscribe is currently under \n>> development. (Not sure of the status of AAT/ATSUI in this regard).\n> \n> \n> Don't at least some of these technologies offer the possibility to\n> define glyphs for combinations of characters? Also, please check\n> SVG and see whether it contains the necessary mechanisms (it should!).\n> \n\nI haven't looked at SVG, but will. Thanks.\n\nAAT/ATSUI ... don'ty know enough about it .. been too long since i've \nused macs .. but I suspect it should.\n\nUnsicribe ... there has been ongoiing discussions on some mailing lists, \nwhich included soem type designers and soem of the Microsoft staff. My \nunderstanding at the moment is that the OpenType MarToBase and \nMarkToMark features should be used, but Uniscribe doesnot currentlky \ninclude support for these features for the Latin script (in general), \nalthough support was introduced for Vietnamese at soem sdtage. I'df have \nto check which evrsion of uniscribe that was. So some people will have \ncombining diacritic support for Diactric/base combinations used in \nVietnamese (for soem reason Micrsodt doesn't use NFC or NFD for \nVietnamese Unicode input) but no othger diacritic/base combinations in \nthe Latin script.\n\nAs to which users ahve what .. it depends on\n\n1) which evrsion of windows they ahve installed,\n2) which evrsion of IE they have installed, and wether they have any of \nthe language packs requiring complex script rendering iunstalled, and\n3) which other Microsoft products they have installed.\n\nBoth the uniscribe development team and the Word development team are \nworking on general support for combining diacritics and stacking \ndiacritics. Its currently unknown when this will be released to the \npublic, maybe through the next version of Office if its implemented by then.\n\nuniscribe isn't something that is always automatically upgraded.\n\nGraphite can, but needs soemone to design and build the graphite tables \ninto appropriate fonts. SIL are working on a set of graphite unicoide \nfonts at the moment that should work with graphite and uniscribe. Not \nsure when they will ahve it finished.\n\n\n> \n>> In some cases: (Dinka and Nuer for instance) the existing combining \n>> diacritics for some fonts are adequate for lowercase characters (but \n>> not optimal), although entirely unsuitable for uppercase characters. \n>> In other cases like Ife, where diacritic stacking is required, it is a \n>> crucial concern which will be alleviated when the new versions of the \n>> font rendering technologies become widespread.\n> \n> \n> A more short-time solution would be to create e.g. a True-Type\n> font for Dinka, which covers all the necessary combinations, and\n> has the right glyph shapes for the upper-case diacritics, and\n> give that font priority in style sheets for Dinka material.\n> \n\nproblem is that you still need a rendering engine that can correctly \nposition the diactrics above a capital open-e and open-o. I haven't \ntried suing the gpos and gsub tabl;es in the fonts yet, but in theory \nsupport for that is limited in uniscribe (wrt to the Latin script).\n\nThe fonts can be built, but until teh support exists in the rendering \nengine, the font will not do to much.\n\n> \n>> Additionally, African languages use alternative glyphs for certain \n>> characters (most common example is uppercase ENG). It is possible to \n>> create alternative glyphs for different languages/typographic \n>> traditions within an opentype font. Unfortunately current software is \n>> unable to interact sufficiently with the font rendering systems to \n>> allow use of langauge specific features within fonts.\n> \n> \n> Again, having a specially-designed font (or some fonts) may be\n> a short to middle-range solution.\n> \n\nyep ... i realise that. It would mean i'd have one set of fonts for key \nafrican languages and another for the Yolngu-matha languages for instance.\n\n> \n>> At least thats my current understanding.\n>>\n>> 3) languages that have some characters that are not present in Unicode.\n>> E.g. Dagera (Burkina Faso), Hausa/Pulaar/etc. in Ajami (Arabic script).\n>>\n>> There has been a fair amount of discussion recently on Ajami on the \n>> Unicode-Afrique, A12N Collaboration and H-Hausa mailing lists.\n> \n> \n> Very good. The important thing is to take such discussion (or the\n> results and main points) over to unicode@unicode.org (or even unicore),\n> and to work on actual proposals.\n> \n\nvery true\n\na few people are working on comiling lists at the moment. Once the basic \nwork has been done then it needs to move to the appropraite forums. Kewy \npeople on the a12n-collaboration and Unicode Afrique mailing lists are \npresent on the unicode mailing list.\n\n> \n>> 4) scripts currently not supported by Unicode.\n>> E.g  N'ko, Vai, Tifinagh, etc.\n> \n> \n> For some work on the later, please see\n> http://std.dkuug.dk/jtc1/sc2/wg2/docs/n1757.pdf\n> \n\nyep, I'm aware of this document.\n\n> \n>> With respect to HTML, issues are how to identify languages when there \n>> is no ISO-639-1 code or IANA language code. How should the \"x-\" \n>> convention be used in practical settings?\n> \n> \n> Not at all, if possible.\n> \n\numm .. that leaves the issue of how to identify nost human languages \nthen. For intsnce if I had a XHTML 1.1 page designed for Southern Sudan, \nin Dinka, Nuer and Arabic. I could provide provide an iso-639-2 language \ntag for Dinka, an iso-639-1 langauge tag for Arabic. But Nuer doesn't \nhave an iso-639-1, iso-639-2 or IANA language code.\n\nOK i guess i could go through the hassle of trying to register a code, \nand wait and wait.\n\nWhat happens if I have a database driven web site with content in \nhundreds of African languages, most not having iso-639-1/2 or IANA codes.\n\nNot sure the appropriate bodies would appreciate all those registrations \nbeing dumped on them all at the same time.\n\n> \n>> For an example:\n>>\n>> http://home.vicnet.net.au/~andrewc/samples/nuer.htm\n> \n> \n> [I find the en-AU in <h1 xml:lang=\"en-AU\">Nuer test page</h1>\n> a bit too much, but that's a detail.]\n> \n> \n>> I've use a convention \"x-sil-\" to indicate an ethnologue language \n>> codes. Although thats neither here nore there.\n> \n> \n> Exactly. If the language in question has some ammout of printed works\n> (50 different items to be exact), then you should apply for an iso-639-2\n> code. if the language in question doesn't have that much printed material,\n> you should apply for an IANA code.\n> \n\nLOL :)  I'll keep that in mind for a future project. Not sure IANA will \nappreciate it though :)\n\n> \n>> Other key issues include charset identification in the absence of \n>> \"defined\" character encodings.\n> \n> \n> There are no 'undefined' character encodings. If somebody\n> does an encoding, they should document it, and register it\n> with IANA. It's rather easy to do that. But working towards\n> getting the necessary characters into Unicode may be\n> much better use of your time.\n> \n\nLOL,\n\nI tend to only use unicode these days, although if the language cann't \nbe rendered using unicode, i'll fall back to an 8-bit character \nencoding, but most 8-bit character encodings i've seen and used within \nthe last few years do not have characters encodings registered with \nIANA. I suspect that the people who hacked together the fonts don't even \nknow there is an IANA character encoding registry.\n\nWe know that there is a registry and there are very good reasons for \nusing it, but I come across a lot of people who are not aware of it.\n\nCatch-22\n\nThe amount of education that needs to be done, is extansive. Not just on \nissues relating to designing and implementing web sites and web \nservices, but many of the background issues, relevant standards and why \nusing them is important. The appropraite registries like IANA (for \nalngauge codes and character encodings) or the iso-639 registration \nauthority.\n\nThe most effective ways of using unicode.\n\nBut some of the issues are even more fundamnetal, ie which unicode \ncodepoints refers to which chacacters in the language. A good example of \nthe possible confusions possible is current practice in Yoruba. Yoruba \nsues a diacritic below the \"e\", \"o\" and \"s\". In some textx this will be \n  a dot below the letter, in others a vertical bar below the letter. \nBoth forms are in wide use.\n\nSome Yoruba text will use U+0323 (COMBINING DOT BELOW) or appropriate \nprecomposed forms, while other texts would use U+0329 (COMBINING \nVERTICAL BAR BELOW) which the Unicode charts iundicate is used for Yoruba.\n\nThis lead to two possibilities:\n\n1) the \"dot below\" and the \"vertical bar below\" represent two different \northographic traditions. Which isn't that uncommon in West African \nlanguages. Many langauges in West Africa have different orthographies in \ndifferent regions (ie use different characters to represent the same sound).\n\n2) that they are glyph variations, ie the same character, just different \nshapes in different fonts.\n\napproach 1) means that different codepoints or sequences of codepoints \nwill be used to represent the same \"character\" in the language\". 2) \nmenas that only one unicode character wiull be used, but teh shape of \nthe diacritic will change depending on teh shape of the font. Ie U+0329 \nmight look like a \"vertical bar below\" or it mightlook like U+0323.\n\nEither way, the countries involve may have to standardise the \northography for this language.\n\nEverything is relatively nice and simple when dealing with european \nlanguages and east asian languages. But African languages have been \nneglected so long that its a real mess with respect to standards and web \ninternationalization.\n\n\nAndrew\n\n\n\n"
        },
        {
            "subject": "More notes on HTML guideline",
            "content": "Chaps,\n\nYou can find another batch of VERY rough notes from me at\nhttp://www.w3.org/People/Ishida/checklists/i18n-guidelines.html\n\nI'm thinking of perhaps using the notes in the section 'Implementing\nbidi text' as the basis of an article in Multilingual Computing and a\ntalk for Unicode (and other) conferences.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "Dan Brickley wrote:\n> \n> If you could copy yours into a 'chosen_demos_rationale_report'\n> subdirectory, that would be good. I can clean up the other directories if\n> you have any difficulty doing so (remind me, how are you editing the\n> site? jigedit? cvs?).\n\nDone. \n\nThe report is now at:\n\nhttp://www.w3.org/2001/sw/Europe/reports/chosen_demos_rationale_report/hp-applications-selection.html\n(though it's not a very pretty URL!).\n\nI use jigedit and I've tried to clean up the old directory using the jigedit web\ninterface. Don't know if that is enough.\n\n> One tiny thing that jumped out from a quick skim: s/Wiener/Winer/\n\nFixed. Actually I swear I fixed that within 10m of the first upload - you guys\nmust either be fast at downloading or there is a cache somewhere that needs\nflushing!\n\n> I do like the idea of focussing on weblog-style apps. Is nicely nearterm,\n> potential for mass uptake, network effects etc...\n\nExactly. Glad it seems like a reasonable choice to you. As I said to Danny, any\nsuggestions/requirements input would be welcome.\n \n> > What is our procedure for reviewing/accepting deliverables?\n> > I assume uploading to the web site was OK given our open-source stance but I\n> > don't want to subvert whatever \"due process\" we have/intend to have.\n> \n> There's something of a watch-this-space where better process should live.\n> Checking works in progress into the site is fine...\n\nFine.\n\n> > [*] We'd be happy to have the RDF files (currently one file per entry) and\n> > associated schema public but (a) I wasn't sure on where that sort of stuff\n> > should go on the site layout\n> \n> A subdirectory of the reports dir would be fine. For other misc things,\n> just create a dated directory in the .../sw/Europe/YYYYMM/etc/ tree, eg\n> sw/Europe/200211/appsurvey-data/\n\nOK. I'll try to get something done on that this week. Need to decide whether to\nkeep the separate files or just munge into one big file.\n\nDave\n\n\n\n"
        },
        {
            "subject": "RE: Kick of",
            "content": "Richard:\n\nI think this looks like the right sequence and a great structure for the discussion.\n\nIn the section \"Who are we targeting?\" I'd like to explicitly ask whether or not we are targeting web application (CGI, J2EE, ...) developers (and if so, which technologies?).  I think this will help us understand how to set the scope of topics in B.3.2, and during content brainstorming.\n\nSteve\n\n\n\nSteve Billings\nGlobal 360\nSoftware Globalization Consulting & Training\nwww.global360.com <http://www.global360.com/>\n+1 978-697-8201\n\n\n\n-----Original Message-----\nFrom: public-i18n-geo-request@w3.org\n[mailto:public-i18n-geo-request@w3.org]On Behalf Of Richard Ishida\nSent: Wednesday, October 23, 2002 12:00 PM\nTo: public-i18n-geo@w3.org\nSubject: Kick off\n\n\n\nThe kick off face-to-face meeting will be in Boston on 22-23 November.  Please let me know if you are able to make it. Detailed logistics information will follow shortly.\n\nThe aim of the meeting will be to set the initial direction for the task force.\n\nTo make the discussions as effective as possible, and allow maximum input from those unable to make the meeting, I have prepared some initial ideas at http://www.w3.org/International/geo/plan/ftf1-discussion.html .  I find it is helpful to start from a proposal when developing strategies.  Please don't take this as directive.  It is a means for developing discussion.\n\nI would encourage everyone to make comments on the discussion document by email prior to the meeting.  Please try to build on and refer to the text in the discussion document, so that we can incorporate the ideas easily within the agenda. Alternative wordings, topics or constructive ideas are welcome!  Please try to make suggestions whenever possible.\n\nIf writing a long mail note, please try to state your ideas as concisely and clearly as possible, with a summary at the top or at the beginning of each paragraph.  Break up the text and use headings where appropriate to help the reader.\n\nUnfortunately I have to leave for a vacation this evening, and my wife won't appreciate it if I'm reading email, so I will rejoin the discussion on Tuesday.\n\nI look forward to reading your comments.\n\nAll the best,\nRichard.\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation. \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "RE: Kick of",
            "content": "Here are some thoughts after reading Richard's document. Any section not mention are ones that I mostly agree with.\n\nDiscussion Document: GEO directions\n\nB. Audience, user needs and topic areas for guidelines\n\n  Section 1.2 -- Initial distinctions on categorizing people:\n     We may also want to focus solutions for two different types \n     of HTML content authors: \n       1. Those on a limited budget and only doing a few \n          pages or a small website\n       2. Those with fat budgets with large websites to produce.\n\n  Section 1.3 -- Including authoring tool/user agent developers.\n     We should keep it simple and leave them out at this time.\n     Anyway, if we address what that users should be doing, and\n     they in turn keep asking the developers for tools to do\n     what they need, the developers should fall into place.\n\n  Section 2.1 -- Create a Techniques document\n     Agreed, we need to teach general techniques that they can then\n     use to address new issues they come across and don't have a\n     pre-planned technique for.\n\n  Section 2.2 -- Guideline format\n     We need to be care with terminology.  Every time you call something\n     a \"checklist\", people get the idea that if they cover everything\n     on the list they don't have to worry about anything else.  Better\n     not to ever use Checklist unless it really is one.\n\n  Section 2.3 -- filters\n     If we do the Guideline format right in the first place we should\n     not need filters to get people to what they are looking for.  My\n     fear of filters are that they may filter out to much, instead of\n     to little.\n\n  Section 2.5 -- Pointers to other resources.\n     We should also point to outside resources that have tutorials \n     on using specific technology (i.e. Sun, Microsoft, etc.) to\n     produce solutions.\n\n  Section 2.6 -- Instructions rather than just rules\n     On some thing I agree that instructions would be better, but\n     we should not try to make everything fit this mold.  There\n     may be generic concepts that we want to teach also.\n\n  Section 2.8 -- Write information to allow for integration \n                 into relevant tasks.\n     Agree.  Something we may want to look at is the format Microsoft\n     has used to create it guidelines.  One starts with an overview\n     and then more detailed areas for those who need or want more info.\n     You can see an example of this at:    \n         http://www.microsoft.com/globaldev/wrguide/wrg_unicode.asp\n\n  Section 2.9 -- Browser-specific.\n     If we use something like I suggested for sec 2.8, we could add\n     detailed directions for each of the major browsers as info for\n     those who need to know.\n\n  Section 2.10 -- Parallel approach for authoring tool.\n     The question is there a big enough market for us to spend \n     resources for, or as stated in sec 1.3.  If we develop\n     what the users need, the developers of authoring tools should \n     be able to understand what they need to do to sell more \n     product.\n\n  Section 2.11 -- Translation of guidelines\n     This is important, but are we hoping that people volunteer for\n     this?  If so how do you control the quality, etc.?\n    \n\nI have others, but this is a good start and I will discuss them at our meeting.\n\nRegards, Russ (rrolfe)\nOne of the World-Ready Guides (wrg)\nAre you World-Ready?  http://www.microsoft.com/globaldev\n\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org] \nSent: Wednesday, October 23, 2002 9:00 AM\nTo: public-i18n-geo@w3.org\nSubject: Kick off\n\n\n\nThe kick off face-to-face meeting will be in Boston on 22-23 November.  Please let me know if you are able to make it. Detailed logistics information will follow shortly.\n\nThe aim of the meeting will be to set the initial direction for the task force.\n\nTo make the discussions as effective as possible, and allow maximum input from those unable to make the meeting, I have prepared some initial ideas at http://www.w3.org/International/geo/plan/ftf1-discussion.html .  I find it is helpful to start from a proposal when developing strategies.  Please don't take this as directive.  It is a means for developing discussion.\n\nI would encourage everyone to make comments on the discussion document by email prior to the meeting.  Please try to build on and refer to the text in the discussion document, so that we can incorporate the ideas easily within the agenda. Alternative wordings, topics or constructive ideas are welcome!  Please try to make suggestions whenever possible.\n\nIf writing a long mail note, please try to state your ideas as concisely and clearly as possible, with a summary at the top or at the beginning of each paragraph.  Break up the text and use headings where appropriate to help the reader.\n\nUnfortunately I have to leave for a vacation this evening, and my wife won't appreciate it if I'm reading email, so I will rejoin the discussion on Tuesday.\n\nI look forward to reading your comments.\n\nAll the best,\nRichard.\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "FTF: please confirm attendanc",
            "content": "All,\n\nOur kick-off face-to-face meeting is now quite close, and I have created a preliminary agenda [1].  I will suggest times very soon.  Please let me know if you want to add (or subtract) topics.\n\nAll WG members [2], please confirm asap whether you will be attending or not.  Thanks.\n\nAnyone wanting to participate by phone also please indicate what sessions you are interested in.\n\nPlease also send in your thoughts on the discussion document [3]. This is especially important if you cannot make the meeting, so that your contribution can be included.\n\nBest regards,\nRichard.\n\n\n[1] http://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html\n[2] http://www.w3.org/International/geo/members.html\n[3] http://www.w3.org/International/geo/plan/ftf1-discussion.html\n\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "FW: Resources for language on the we",
            "content": "FYI.  Some user requirements!  From Nick Gassman at British Airways, who\nI met at the W3C/NIST Usability Workshop last week.\nRI\n\n\n-----Original Message-----\nFrom: nick.1.gassman@britishairways.com\n[mailto:nick.1.gassman@britishairways.com] \nSent: 08 November 2002 18:15\nTo: ishida@w3.org\nSubject: Resources for language on the web\n\n\n\nRichard, it was good to meet you again at the workshop. \n\nYou'll recall that I spoke to you about a resource that I felt would be\nuseful, and thought I'd put virtual pen to paper to clarify what I was\ntalking about. It would be great if something like this could appear on\nthe W3C site (failing that, if you know of any other site that has the\ninformation). I'll try to send you a separate email with comments on the\nW3C site as you requested. \n\nThe audience for the languages resoource would range from programmers to\necommerce execs who need to understand the components that need to be\nput together to result in a multi-lingual website. It would cover the\nissues end-to-end, including:- \n\n1) how do I represent different languages and character sets on my PC\n(or Mac etc...), because that's what I'm using to code my site.? \n2) how do languages relate to character sets and fonts. How can I tell\nwhat I've got? \n3) what are all of the html (or xhtml, or xml) tags that relates to\nlanguages, fonts, character sets. When should I use them? How do they\ninteract with each other? What are some use cases and examples? \n4) are these tags consistently implemented in the main browsers? \n5) how do I cope with right-to-left and up-and-down languages? \n6) how can I ensure that when I transfer my newly-authored web page to\nmay server, or when the customer downloads the page, that the encoding\nis not lost? \n7) how can I maximise the likliehood that the customer viewing my page\nwill see the right things? \n8) how can I represent different languages on the same web page? \n\nIt's probably not a comprehensive list. Most sources focus on a subset\nof the elements, whereas the target audiences need to have 'everything\nyou need to know about producing multilingual sites' in one place. A\ngood opportunity potentially for a book also, I would have thought.\n\n------------------------------------------------------------------------\n-------------------------\nSave time by using an eTicket and our Self-Service Check-in Kiosks. For\nmore information go to http://www.britishairways.com/eservice1\n\n\n\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a\ncall for participation. \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "Re: FW: Resources for language on the we",
            "content": "Hello Richard,\n\nIt is a very good idea. I also think of  doing something  similar \nfor  Arabic especially with regard to most of the items enumerrated.\n\nNajib\n\nAt 11:39 +0000 12/11/02, Richard Ishida wrote:\n>FYI.  Some user requirements!  From Nick Gassman at British Airways, who\n>I met at the W3C/NIST Usability Workshop last week.\n>RI\n>\n>\n>-----Original Message-----\n>From: nick.1.gassman@britishairways.com\n>[mailto:nick.1.gassman@britishairways.com]\n>Sent: 08 November 2002 18:15\n>To: ishida@w3.org\n>Subject: Resources for language on the web\n>\n>\n>\n>Richard, it was good to meet you again at the workshop.\n>\n>You'll recall that I spoke to you about a resource that I felt would be\n>useful, and thought I'd put virtual pen to paper to clarify what I was\n>talking about. It would be great if something like this could appear on\n>the W3C site (failing that, if you know of any other site that has the\n>information). I'll try to send you a separate email with comments on the\n>W3C site as you requested.\n>\n>The audience for the languages resoource would range from programmers to\n>ecommerce execs who need to understand the components that need to be\n>put together to result in a multi-lingual website. It would cover the\n>issues end-to-end, including:-\n>\n>1) how do I represent different languages and character sets on my PC\n>(or Mac etc...), because that's what I'm using to code my site.?\n>2) how do languages relate to character sets and fonts. How can I tell\n>what I've got?\n>3) what are all of the html (or xhtml, or xml) tags that relates to\n>languages, fonts, character sets. When should I use them? How do they\n>interact with each other? What are some use cases and examples?\n>4) are these tags consistently implemented in the main browsers?\n>5) how do I cope with right-to-left and up-and-down languages?\n>6) how can I ensure that when I transfer my newly-authored web page to\n>may server, or when the customer downloads the page, that the encoding\n>is not lost?\n>7) how can I maximise the likliehood that the customer viewing my page\n>will see the right things?\n>8) how can I represent different languages on the same web page?\n>\n>It's probably not a comprehensive list. Most sources focus on a subset\n>of the elements, whereas the target audiences need to have 'everything\n>you need to know about producing multilingual sites' in one place. A\n>good opportunity potentially for a book also, I would have thought.\n>\n>------------------------------------------------------------------------\n>-------------------------\n>Save time by using an eTicket and our Self-Service Check-in Kiosks. For\n>more information go to http://www.britishairways.com/eservice1\n>\n>\n>\n>\n>============\n>Richard Ishida\n>W3C\n>\n>The W3C Internationalization Activity has restructured, and has issued a\n>call for participation.\n>See http://www.w3.org/International/about.html\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/International/\n\n\n-- \nNajib TOUNSI (mailto:tounsi@w3.org)\nW3C Office in Morocco (http://www.emi.ac.ma/W3C)\nEcole Mohammadia d'Ing?ieurs, BP 765 Agdal-RABAT Maroc (Morocco) \nPhone : +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\nMobile : +212 (0) 61 22 00 30\n\n\n\n"
        },
        {
            "subject": "Outreach idea",
            "content": "Attached are some initial ideas for outreach activities, including promotional opportunities and education.\n\nLooking forward to talking with the group next week.\n\nSuzanne Topping\nVice President\nBizWonk Inc.\n(Solutions for a Global E-conomy) (TM)\n\nstopping@bizwonk.com\n\n25 N. Washington St.\nRochester, NY 14614-1110\nUSA\n\nPhone: +1 585.454.4210\nFax: +1 585.454.4213 \n\n\n\ntext/html attachment: OutreachPrelimGoalsNov2002.htm\n\n\n\n\n"
        },
        {
            "subject": "ftf meeting",
            "content": "This page http://www.w3.org/International/ws/ says the meeting is 21-22.\nThis page http://www.w3.org/International/ws/2002/11/ftf200211.html says\n22-23\n\nhttp://www.w3.org/International/ws/2002/11/ftf200211-agenda.html says\nfriday sat. 21-22\n(However 21-22 falls on thursday fri)\n\nhttp://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html says\n22-23.\n\nMy understanding is both meetings are the same 2 days in the same\nbuilding.\nThe pages should be fixed so we don't have confusion about when and\nwhere to be.\n\nIs it correct the meetings are on the 22 and 23 of November, 2002,\nFriday and Saturday?\ntex\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Addition to documen",
            "content": "FYI.  I just added a footnote to http://www.w3.org/International/geo/plan/impl-guideline-ideas.html that links to a dynamic document relating to designing accessibility into HTML.\n\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "RE: ftf meeting",
            "content": "Text,\n\nThis is an answer I got from Richard about this very issue.\n\nSee you there, russ\n\n-----Original Message-----\nFrom: Tex Texin [mailto:tex@i18nguy.com] \nSent: Thursday, November 14, 2002 11:24 AM\nTo: GEO; Web Services\nSubject: ftf meetings\n\n\n\nThis page http://www.w3.org/International/ws/ says the meeting is 21-22. This page http://www.w3.org/International/ws/2002/11/ftf200211.html says 22-23\n\nhttp://www.w3.org/International/ws/2002/11/ftf200211-agenda.html says friday sat. 21-22 (However 21-22 falls on thursday fri)\n\nhttp://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html says 22-23.\n\nMy understanding is both meetings are the same 2 days in the same building. The pages should be fixed so we don't have confusion about when and where to be.\n\nIs it correct the meetings are on the 22 and 23 of November, 2002, Friday and Saturday? tex\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\nattached mail follows:\n\nAll,\n\nPlease note that the correct dates for the FTF meeting in Boston are 22-23 November (not 21-22nd as was initially, incorrectly stated on the logisitics page http://www.w3.org/International/ws/2002/11/ftf200211.html ).\n\nThanks to Steve Billings for pointing out the error!\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n\n\n\n"
        },
        {
            "subject": "Re: ftf meeting",
            "content": "Hi Tex,\n\nThe meetings are on the 22nd->23rd (Friday and Saturday). My two pages \nwere corrected at some point, but it looks like they are out of sync again.\n\nAddison\n\nTex Texin wrote:\n> This page http://www.w3.org/International/ws/ says the meeting is 21-22.\n> This page http://www.w3.org/International/ws/2002/11/ftf200211.html says\n> 22-23\n> \n> http://www.w3.org/International/ws/2002/11/ftf200211-agenda.html says\n> friday sat. 21-22\n> (However 21-22 falls on thursday fri)\n> \n> http://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html says\n> 22-23.\n> \n> My understanding is both meetings are the same 2 days in the same\n> building.\n> The pages should be fixed so we don't have confusion about when and\n> where to be.\n> \n> Is it correct the meetings are on the 22 and 23 of November, 2002,\n> Friday and Saturday?\n> tex\n> \n\n\n-- \nAddison P. Phillips\nDirector, Globalization Architecture\nwebMethods, Inc.\n\n+1 408.962.5487  mailto:aphillips@webmethods.com\n-------------------------------------------\nInternationalization is an architecture. It is not a feature.\n\nChair, W3C I18N WG Web Services Task Force\nhttp://www.w3.org/International/ws\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "On Tue, 5 Nov 2002, Dave Reynolds wrote:\n\n> Dan Brickley wrote:\n> > If you could copy yours into a 'chosen_demos_rationale_report'\n> > subdirectory, that would be good. I can clean up the other directories if\n> > you have any difficulty doing so (remind me, how are you editing the\n> > site? jigedit? cvs?).\n>\n> Done.\n\nThanks\n\n> The report is now at:\n>\n> http://www.w3.org/2001/sw/Europe/reports/chosen_demos_rationale_report/hp-applications-selection.html\n> (though it's not a very pretty URL!).\n\nAgreed. You might also want to edit intro.html in the reports directory to\npoint to it, if you've not done that already. That page is linked from the\nproject homepage so there's a navigation path to this as a\nwork-in-progress.\n\n> I use jigedit and I've tried to clean up the old directory using the jigedit web\n> interface. Don't know if that is enough.\n\nI'll take a look\n\n> > One tiny thing that jumped out from a quick skim: s/Wiener/Winer/\n>\n> Fixed. Actually I swear I fixed that within 10m of the first upload - you guys\n> must either be fast at downloading or there is a cache somewhere that needs\n> flushing!\n\nCould be either. We have mirrors of the site (all hidden behind dns\ntrickery for www.w3.org) that have updates  triggered from cvs commits;\nthese have been known to lag a little (usually minutes rather than hours).\n\n> > I do like the idea of focussing on weblog-style apps. Is nicely nearterm,\n> > potential for mass uptake, network effects etc...\n>\n> Exactly. Glad it seems like a reasonable choice to you. As I said to Danny, any\n> suggestions/requirements input would be welcome.\n\nRegarding bibliographies, I did (for obscure reasons) start collecting up\nthe ISBNs of all the books I own. Also scribbled a title/author, but the\nmain thing I wanted was isbns; hope is to hook into a lookup-via-isbn web\nservice to get richer metadata to autogenerate bibliographic records, and\nprovide fodder for collaborative filtering apps. I'm not sure if that kind\nif bibliographic app fits with your plans, have only had time for quickest\nskim of the document today...\n\n> > > What is our procedure for reviewing/accepting deliverables?\n> > > I assume uploading to the web site was OK given our open-source stance but I\n> > > don't want to subvert whatever \"due process\" we have/intend to have.\n> >\n> > There's something of a watch-this-space where better process should live.\n> > Checking works in progress into the site is fine...\n>\n> Fine.\n>\n> > > [*] We'd be happy to have the RDF files (currently one file per entry) and\n> > > associated schema public but (a) I wasn't sure on where that sort of stuff\n> > > should go on the site layout\n> >\n> > A subdirectory of the reports dir would be fine. For other misc things,\n> > just create a dated directory in the .../sw/Europe/YYYYMM/etc/ tree, eg\n> > sw/Europe/200211/appsurvey-data/\n>\n> OK. I'll try to get something done on that this week. Need to decide whether to\n> keep the separate files or just munge into one big file.\n\nOr perhaps both if that won't be too time consuming.\n\ncheers,\n\ndan\n\n> Dave\n>\n\n\n\n"
        },
        {
            "subject": "RE: ftf meeting",
            "content": "Team:\n\nJust to clear up any confusion, I have double checked these pages. The only\ncorrection I needed to make was in the table header in the WS agenda.\nHowever, it seems that browser caching may have contributed to some of you\nseeing the dates of 21-22 November (this is not the first time that has\nhappened).\n\nFor the record: the dates for the GEO and WS Task Force face-to-face meetins\nare this coming Friday and Saturday, 22 and 23 November, in Westborough, MA,\nUSA. Please be sure to refresh your browser when you visit the pages\ndescribing each:\n\nhttp://www.w3.org/International/ws/2002/11/ftf200211.html (Directions,\nInformation)\nhttp://www.w3.org/International/ws/2002/11/ftf200211-agenda.html (WS Task\nForce Agenda)\nhttp://www.w3.org/International/ws (WS Task Force Home Page)\n\nBest Regards,\n\nAddison\n\nAddison P. Phillips\nDirector, Globalization Architecture\nwebMethods, Inc.\n\n+1 408.962.5487 (phone)  +1 408.210.3569 (mobile)\n-------------------------------------------------\nInternationalization is an architecture.\nIt is not a feature.\n\nChair, W3C-I18N-WG Web Services Task Force\nTo participate see http://www.w3.org/International/ws\n\n> -----Original Message-----\n> From: Richard Ishida [mailto:ishida@w3.org]\n> Sent: Thursday, November 14, 2002 11:32 AM\n> To: 'Addison Phillips [wM]'\n> Cc: Richard Ishida\n> Subject: FW: ftf meetings\n>\n>\n> Addison,\n> Could you fix this?  I'm running out of office time this evening.\n> Cheers,\n> RI\n>\n> ============\n> Richard Ishida\n> W3C\n>\n> The W3C Internationalization Activity has restructured, and has issued a\n> call for participation.\n> See http://www.w3.org/International/about.html\n>\n> tel: +44 1753 480 292\n> http://www.w3.org/International/\n>\n>\n>\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org\n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> Sent: 14 November 2002 19:24\n> To: GEO; Web Services\n> Subject: ftf meetings\n>\n>\n>\n> This page http://www.w3.org/International/ws/ says the meeting is 21-22.\n> This page http://www.w3.org/International/ws/2002/11/ftf200211.html says\n> 22-23\n>\n> http://www.w3.org/International/ws/2002/11/ftf200211-agenda.html says\n> friday sat. 21-22 (However 21-22 falls on thursday fri)\n>\n> http://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html says\n> 22-23.\n>\n> My understanding is both meetings are the same 2 days in the same\n> building. The pages should be fixed so we don't have confusion about\n> when and where to be.\n>\n> Is it correct the meetings are on the 22 and 23 of November, 2002,\n> Friday and Saturday? tex\n>\n> --\n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n>\n> XenCraft            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: ftf meeting",
            "content": "Sorry for adding to the confusion then. I thought I had cleared my\ncache, but then I changed browsers and used its old cache.\noh well. At least one was legit.\n\nAre there any plans for friday night, as long as we are all together?\ntex\n\n\"Addison Phillips [wM]\" wrote:\n> \n> Team:\n> \n> Just to clear up any confusion, I have double checked these pages. The only\n> correction I needed to make was in the table header in the WS agenda.\n> However, it seems that browser caching may have contributed to some of you\n> seeing the dates of 21-22 November (this is not the first time that has\n> happened).\n> \n> For the record: the dates for the GEO and WS Task Force face-to-face meetins\n> are this coming Friday and Saturday, 22 and 23 November, in Westborough, MA,\n> USA. Please be sure to refresh your browser when you visit the pages\n> describing each:\n> \n> http://www.w3.org/International/ws/2002/11/ftf200211.html (Directions,\n> Information)\n> http://www.w3.org/International/ws/2002/11/ftf200211-agenda.html (WS Task\n> Force Agenda)\n> http://www.w3.org/International/ws (WS Task Force Home Page)\n> \n> Best Regards,\n> \n> Addison\n> \n> Addison P. Phillips\n> Director, Globalization Architecture\n> webMethods, Inc.\n> \n> +1 408.962.5487 (phone)  +1 408.210.3569 (mobile)\n> -------------------------------------------------\n> Internationalization is an architecture.\n> It is not a feature.\n> \n> Chair, W3C-I18N-WG Web Services Task Force\n> To participate see http://www.w3.org/International/ws\n> \n> > -----Original Message-----\n> > From: Richard Ishida [mailto:ishida@w3.org]\n> > Sent: Thursday, November 14, 2002 11:32 AM\n> > To: 'Addison Phillips [wM]'\n> > Cc: Richard Ishida\n> > Subject: FW: ftf meetings\n> >\n> >\n> > Addison,\n> > Could you fix this?  I'm running out of office time this evening.\n> > Cheers,\n> > RI\n> >\n> > ============\n> > Richard Ishida\n> > W3C\n> >\n> > The W3C Internationalization Activity has restructured, and has issued a\n> > call for participation.\n> > See http://www.w3.org/International/about.html\n> >\n> > tel: +44 1753 480 292\n> > http://www.w3.org/International/\n> >\n> >\n> >\n> > -----Original Message-----\n> > From: public-i18n-geo-request@w3.org\n> > [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> > Sent: 14 November 2002 19:24\n> > To: GEO; Web Services\n> > Subject: ftf meetings\n> >\n> >\n> >\n> > This page http://www.w3.org/International/ws/ says the meeting is 21-22.\n> > This page http://www.w3.org/International/ws/2002/11/ftf200211.html says\n> > 22-23\n> >\n> > http://www.w3.org/International/ws/2002/11/ftf200211-agenda.html says\n> > friday sat. 21-22 (However 21-22 falls on thursday fri)\n> >\n> > http://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html says\n> > 22-23.\n> >\n> > My understanding is both meetings are the same 2 days in the same\n> > building. The pages should be fixed so we don't have confusion about\n> > when and where to be.\n> >\n> > Is it correct the meetings are on the 22 and 23 of November, 2002,\n> > Friday and Saturday? tex\n> >\n> > --\n> > -------------------------------------------------------------\n> > Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> > Xen Master                          http://www.i18nGuy.com\n> >\n> > XenCraft                          http://www.XenCraft.com\n> > Making e-Business Work Around the World\n> > -------------------------------------------------------------\n> >\n> >\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: ftf meeting",
            "content": "At 11:24 02/11/14 -0800, Addison Phillips [wM] wrote:\n\n>Hi Tex,\n>\n>The meetings are on the 22nd->23rd (Friday and Saturday). My two pages \n>were corrected at some point, but it looks like they are out of sync again.\n\nI just fixed the pages that were wrong; they now should all say\n22-23.      Regards,    Martin.\n\n\n>Addison\n>\n>Tex Texin wrote:\n>>This page http://www.w3.org/International/ws/ says the meeting is 21-22.\n>>This page http://www.w3.org/International/ws/2002/11/ftf200211.html says\n>>22-23\n>>http://www.w3.org/International/ws/2002/11/ftf200211-agenda.html says\n>>friday sat. 21-22\n>>(However 21-22 falls on thursday fri)\n>>http://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html says\n>>22-23.\n>>My understanding is both meetings are the same 2 days in the same\n>>building.\n>>The pages should be fixed so we don't have confusion about when and\n>>where to be.\n>>Is it correct the meetings are on the 22 and 23 of November, 2002,\n>>Friday and Saturday?\n>>tex\n>\n>\n>--\n>Addison P. Phillips\n>Director, Globalization Architecture\n>webMethods, Inc.\n>\n>+1 408.962.5487  mailto:aphillips@webmethods.com\n>-------------------------------------------\n>Internationalization is an architecture. It is not a feature.\n>\n>Chair, W3C I18N WG Web Services Task Force\n>http://www.w3.org/International/ws\n\n\n\n"
        },
        {
            "subject": "RE: ftf meeting",
            "content": "Re plans for Friday night: I guess all the out of towners need to eat\nsomewhere.  Logistics may depend on where people are staying.  I suggest\nwe discuss on Friday.\n\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a\ncall for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n> -----Original Message-----\n> From: Tex Texin [mailto:tex@i18nguy.com] \n> Sent: 14 November 2002 21:28\n> To: Addison Phillips [wM]\n> Cc: ishida@w3.org; public-i18n-geo@w3.org; public-i18n-ws@w3.org\n> Subject: Re: ftf meetings\n> \n> \n> Sorry for adding to the confusion then. I thought I had \n> cleared my cache, but then I changed browsers and used its \n> old cache. oh well. At least one was legit.\n> \n> Are there any plans for friday night, as long as we are all \n> together? tex\n> \n> \"Addison Phillips [wM]\" wrote:\n> > \n> > Team:\n> > \n> > Just to clear up any confusion, I have double checked these \n> pages. The \n> > only correction I needed to make was in the table header in the WS \n> > agenda. However, it seems that browser caching may have \n> contributed to \n> > some of you seeing the dates of 21-22 November (this is not \n> the first \n> > time that has happened).\n> > \n> > For the record: the dates for the GEO and WS Task Force \n> face-to-face \n> > meetins are this coming Friday and Saturday, 22 and 23 November, in \n> > Westborough, MA, USA. Please be sure to refresh your \n> browser when you \n> > visit the pages describing each:\n> > \n> > http://www.w3.org/International/ws/2002/11/ftf200211.html \n> (Directions,\n> > Information) \n> > \n> http://www.w3.org/International/ws/2002/11/ftf200211-agenda.html (WS \n> > Task Force Agenda) http://www.w3.org/International/ws (WS \n> Task Force \n> > Home Page)\n> > \n> > Best Regards,\n> > \n> > Addison\n> > \n> > Addison P. Phillips\n> > Director, Globalization Architecture\n> > webMethods, Inc.\n> > \n> > +1 408.962.5487 (phone)  +1 408.210.3569 (mobile)\n> > -------------------------------------------------\n> > Internationalization is an architecture.\n> > It is not a feature.\n> > \n> > Chair, W3C-I18N-WG Web Services Task Force\n> > To participate see http://www.w3.org/International/ws\n> > \n> > > -----Original Message-----\n> > > From: Richard Ishida [mailto:ishida@w3.org]\n> > > Sent: Thursday, November 14, 2002 11:32 AM\n> > > To: 'Addison Phillips [wM]'\n> > > Cc: Richard Ishida\n> > > Subject: FW: ftf meetings\n> > >\n> > >\n> > > Addison,\n> > > Could you fix this?  I'm running out of office time this evening. \n> > > Cheers, RI\n> > >\n> > > ============\n> > > Richard Ishida\n> > > W3C\n> > >\n> > > The W3C Internationalization Activity has restructured, and has \n> > > issued a call for participation. See \n> > > http://www.w3.org/International/about.html\n> > >\n> > > tel: +44 1753 480 292\n> > > http://www.w3.org/International/\n> > >\n> > >\n> > >\n> > > -----Original Message-----\n> > > From: public-i18n-geo-request@w3.org \n> > > [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> > > Sent: 14 November 2002 19:24\n> > > To: GEO; Web Services\n> > > Subject: ftf meetings\n> > >\n> > >\n> > >\n> > > This page http://www.w3.org/International/ws/ says the meeting is \n> > > 21-22. This page \n> > > http://www.w3.org/International/ws/2002/11/ftf200211.html \n> says 22-23\n> > >\n> > > http://www.w3.org/International/ws/2002/11/ftf200211-agenda.html \n> > > says friday sat. 21-22 (However 21-22 falls on thursday fri)\n> > >\n> > > \n> http://www.w3.org/International/geo/2002/11/ftf-agenda-200211.\nhtml \n> > says 22-23.\n> >\n> > My understanding is both meetings are the same 2 days in the same \n> > building. The pages should be fixed so we don't have confusion about\n\n> > when and where to be.\n> >\n> > Is it correct the meetings are on the 22 and 23 of November, 2002, \n> > Friday and Saturday? tex\n> >\n> > --\n> > -------------------------------------------------------------\n> > Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> > Xen Master                          http://www.i18nGuy.com\n> >\n> > XenCraft                          http://www.XenCraft.com\n> > Making e-Business Work Around the World\n> > -------------------------------------------------------------\n> >\n> >\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "FTF Agend",
            "content": "All,\n\nI have made a first attempt to put times on the agenda [1]. \n\nI also added a session.  I was very impressed with a talk given by Whitney Quesenbery, a usability expert, at the W3C/NIST Usability Workshop last week, and I've invited her to give a version of it to the group.  She will dial in, and I'll turn slides, etc.  The title of her talk in Washington was \"Reading to Do: Creating Documents that Lead to Actions\", and I think you'll find it quite thought provoking.\n\nIf you are intending to participate by telephone, please don't forget to let me know when you'll be dialling in, since we won't leave the bridge open unless we know someone is there.\n\nI'm looking forward to this.\nSee you next week.\nRI\n\n[1] http://www.w3.org/International/geo/2002/11/ftf-agenda-200211.html\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "RE: FW: Resources for language on the we",
            "content": "Hi Najib,\n\nI'm looking forward to seeing your stuff, and hopefully integrating it\ninto the GEO deliverables.  \n\nYou know, it occurs to me that maybe people from areas that use the\nArabic script have specific additional questions that we should answer -\nie. as we develop GEO materials, do those folks have any special\nneeds/requests?\n\nThe same would apply to Isaac in China, and anyone else who has\nexperience of users in a non-English environment.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a\ncall for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n> -----Original Message-----\n> From: Najib Tounsi [mailto:tounsi@emi.ac.ma] \n> Sent: 13 November 2002 10:10\n> To: ishida@w3.org; public-i18n-geo@w3.org\n> Cc: nick.1.gassman@britishairways.com\n> Subject: Re: FW: Resources for language on the web\n> \n> \n> Hello Richard,\n> \n> It is a very good idea. I also think of  doing something  similar \n> for  Arabic especially with regard to most of the items enumerrated.\n> \n> Najib\n> \n> At 11:39 +0000 12/11/02, Richard Ishida wrote:\n> >FYI.  Some user requirements!  From Nick Gassman at British Airways, \n> >who I met at the W3C/NIST Usability Workshop last week. RI\n> >\n> >\n> >-----Original Message-----\n> >From: nick.1.gassman@britishairways.com \n> >[mailto:nick.1.gassman@britishairways.com]\n> >Sent: 08 November 2002 18:15\n> >To: ishida@w3.org\n> >Subject: Resources for language on the web\n> >\n> >\n> >\n> >Richard, it was good to meet you again at the workshop.\n> >\n> >You'll recall that I spoke to you about a resource that I \n> felt would be \n> >useful, and thought I'd put virtual pen to paper to clarify \n> what I was \n> >talking about. It would be great if something like this \n> could appear on \n> >the W3C site (failing that, if you know of any other site \n> that has the \n> >information). I'll try to send you a separate email with comments on \n> >the W3C site as you requested.\n> >\n> >The audience for the languages resoource would range from \n> programmers \n> >to ecommerce execs who need to understand the components \n> that need to \n> >be put together to result in a multi-lingual website. It would cover \n> >the issues end-to-end, including:-\n> >\n> >1) how do I represent different languages and character sets \n> on my PC \n> >(or Mac etc...), because that's what I'm using to code my site.?\n> >2) how do languages relate to character sets and fonts. How \n> can I tell \n> >what I've got?\n> >3) what are all of the html (or xhtml, or xml) tags that relates to \n> >languages, fonts, character sets. When should I use them? \n> How do they \n> >interact with each other? What are some use cases and examples?\n> >4) are these tags consistently implemented in the main browsers?\n> >5) how do I cope with right-to-left and up-and-down languages?\n> >6) how can I ensure that when I transfer my newly-authored \n> web page to \n> >may server, or when the customer downloads the page, that \n> the encoding \n> >is not lost?\n> >7) how can I maximise the likliehood that the customer \n> viewing my page \n> >will see the right things?\n> >8) how can I represent different languages on the same web page?\n> >\n> >It's probably not a comprehensive list. Most sources focus \n> on a subset \n> >of the elements, whereas the target audiences need to have \n> 'everything \n> >you need to know about producing multilingual sites' in one place. A \n> >good opportunity potentially for a book also, I would have thought.\n> >\n> >-------------------------------------------------------------\n> ----------\n> >-\n> >-------------------------\n> >Save time by using an eTicket and our Self-Service Check-in \n> Kiosks. For\n> >more information go to http://www.britishairways.com/eservice1\n> >\n> >\n> >\n> >\n> >============\n> >Richard Ishida\n> >W3C\n> >\n> >The W3C Internationalization Activity has restructured, and \n> has issued \n> >a call for participation. See \n> >http://www.w3.org/International/about.html\n> >\n> >tel: +44 1753 480 292\n> >http://www.w3.org/International/\n> \n> \n> -- \n> Najib TOUNSI (mailto:tounsi@w3.org)\n> W3C Office in Morocco (http://www.emi.ac.ma/W3C)\n> Ecole Mohammadia d'Ing?ieurs, BP 765 Agdal-RABAT Maroc (Morocco) \n> Phone : +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\n> Mobile : +212 (0) 61 22 00 30\n> \n\n\n\n"
        },
        {
            "subject": "RE: FW: Resources for language on the we",
            "content": "At 13:19 +0000 15/11/02, Richard Ishida wrote:\n>Hi Najib,\n>\n>I'm looking forward to seeing your stuff, and hopefully integrating it\n>into the GEO deliverables.\n\nHi Richard,\n\nI share your hope. But this will be quite modest in the begining.\n\n>\n>You know, it occurs to me that maybe people from areas that use the\n>Arabic script have specific additional questions that we should answer -\n>ie. as we develop GEO materials, do those folks have any special\n>needs/requests?\n\nSpeaking only for morocco, most web sites are in Frensh,  especialy \ncommercial ones for matketing reasons. And almost all of the very few \nmoroccan internet users navigate in frensh and a little in english. \nSome News papers (http://www.alalam.ma/), portals \n(http://arabe.casanet.net.ma/ ) or government sites \n(http://www.justice.gov.ma/ ) offers two (sometimes many) language \nversions.\n\nMost of arabic sites uses MS tools to design their pages \n(charset=windows 1256).  Even worse, sometimes, in the\nthe same page you find two potions with different encodings (perhaps \noriginated from different tools?) and where some texts are in \nunicode numeric entities while other are in window-1256. There is an \naccessibility problem here. But as more than 95% of PCs use IE, and \nit is all right, this does not seem to be a \"problem\"...\n\nIn fact, we still have to do the work of promoting W3C technologies, \nmeet web designers and get feedbacks from  people realy working with \nArabic. Another big \"chantier\" is accessibility and conformance to \nstandards, not only in Arabic. There is a lot to do. But the chalange \nis exciting.\n\nNajib\n\n>\n>The same would apply to Isaac in China, and anyone else who has\n>experience of users in a non-English environment.\n>\n>Cheers,\n>RI\n>\n>============\n>Richard Ishida\n>W3C\n>\n>The W3C Internationalization Activity has restructured, and has issued a\n>call for participation. \n>See http://www.w3.org/International/about.html\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/International/\n>\n>\n>\n>>  -----Original Message-----\n>>  From: Najib Tounsi [mailto:tounsi@emi.ac.ma]\n>>  Sent: 13 November 2002 10:10\n>>  To: ishida@w3.org; public-i18n-geo@w3.org\n>>  Cc: nick.1.gassman@britishairways.com\n>>  Subject: Re: FW: Resources for language on the web\n>>\n>>\n>>  Hello Richard,\n>>\n>>  It is a very good idea. I also think of  doing something  similar\n>>  for  Arabic especially with regard to most of the items enumerrated.\n>>\n>>  Najib\n>>\n>>  At 11:39 +0000 12/11/02, Richard Ishida wrote:\n>>  >FYI.  Some user requirements!  From Nick Gassman at British Airways,\n>>  >who I met at the W3C/NIST Usability Workshop last week. RI\n>>  >\n>>  >\n>>  >-----Original Message-----\n>>  >From: nick.1.gassman@britishairways.com\n>>  >[mailto:nick.1.gassman@britishairways.com]\n>>  >Sent: 08 November 2002 18:15\n>>  >To: ishida@w3.org\n>>  >Subject: Resources for language on the web\n>>  >\n>>  >\n>>  >\n>>  >Richard, it was good to meet you again at the workshop.\n>>  >\n>>  >You'll recall that I spoke to you about a resource that I\n>>  felt would be\n>>  >useful, and thought I'd put virtual pen to paper to clarify\n>>  what I was\n>>  >talking about. It would be great if something like this\n>>  could appear on\n>>  >the W3C site (failing that, if you know of any other site\n>>  that has the\n>>  >information). I'll try to send you a separate email with comments on\n>>  >the W3C site as you requested.\n>>  >\n>>  >The audience for the languages resoource would range from\n>>  programmers\n>>  >to ecommerce execs who need to understand the components\n>>  that need to\n>>  >be put together to result in a multi-lingual website. It would cover\n>>  >the issues end-to-end, including:-\n>  > >\n>  > >1) how do I represent different languages and character sets\n>  > on my PC\n>  > >(or Mac etc...), because that's what I'm using to code my site.?\n>  > >2) how do languages relate to character sets and fonts. How\n>>  can I tell\n>>  >what I've got?\n>>  >3) what are all of the html (or xhtml, or xml) tags that relates to\n>>  >languages, fonts, character sets. When should I use them?\n>>  How do they\n>>  >interact with each other? What are some use cases and examples?\n>  > >4) are these tags consistently implemented in the main browsers?\n>>  >5) how do I cope with right-to-left and up-and-down languages?\n>>  >6) how can I ensure that when I transfer my newly-authored\n>>  web page to\n>>  >may server, or when the customer downloads the page, that\n>>  the encoding\n>>  >is not lost?\n>>  >7) how can I maximise the likliehood that the customer\n>>  viewing my page\n>>  >will see the right things?\n>>  >8) how can I represent different languages on the same web page?\n>>  >\n>>  >It's probably not a comprehensive list. Most sources focus\n>>  on a subset\n>>  >of the elements, whereas the target audiences need to have\n>>  'everything\n>>  >you need to know about producing multilingual sites' in one place. A\n>>  >good opportunity potentially for a book also, I would have thought.\n>>  >\n>>  >-------------------------------------------------------------\n>>  ----------\n>>  >-\n>>  >-------------------------\n>>  >Save time by using an eTicket and our Self-Service Check-in\n>>  Kiosks. For\n>>  >more information go to http://www.britishairways.com/eservice1\n>>  >\n>>  >\n>>  >\n>>  >\n>>  >============\n>>  >Richard Ishida\n>>  >W3C\n>>  >\n>>  >The W3C Internationalization Activity has restructured, and\n>>  has issued\n>>  >a call for participation. See\n>>  >http://www.w3.org/International/about.html\n>>  >\n>>  >tel: +44 1753 480 292\n>>  >http://www.w3.org/International/\n>>\n>>\n>>  --\n>>  Najib TOUNSI (mailto:tounsi@w3.org)\n>>  W3C Office in Morocco (http://www.emi.ac.ma/W3C)\n>>  Ecole Mohammadia d'Ing?ieurs, BP 765 Agdal-RABAT Maroc (Morocco)\n>>  Phone : +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\n>>  Mobile : +212 (0) 61 22 00 30\n>>\n\n\n-- \nNajib TOUNSI (mailto:tounsi@w3.org) \nW3C Office in Morocco (http://www.emi.ac.ma/W3C)\nEcole Mohammadia d'Ing?ieurs, BP 765 Agdal-RABAT Maroc (Morocco) \nPhone : +212 (0) 37 68 71 74  Fax : +212 (0) 37 77 88 53\nMobile : +212 (0) 61 22 00 30\n\n\n\n"
        },
        {
            "subject": "RE: FW: Resources for language on the we",
            "content": "Hello Najib,\n\nMany thanks for your information.\n\nAt 16:05 02/11/15 +0000, Najib Tounsi wrote:\n\n>Speaking only for morocco, most web sites are in Frensh,  especialy \n>commercial ones for matketing reasons. And almost all of the very few \n>moroccan internet users navigate in frensh and a little in english. Some \n>News papers (http://www.alalam.ma/), portals (http://arabe.casanet.net.ma/ \n>) or government sites (http://www.justice.gov.ma/ ) offers two (sometimes \n>many) language versions.\n>\n>Most of arabic sites uses MS tools to design their pages (charset=windows \n>1256).  Even worse, sometimes, in the\n>the same page you find two potions with different encodings (perhaps \n>originated from different tools?)\n\nThat would be really, really bad.\n\n\n>and where some texts are in unicode numeric entities while other are in \n>window-1256.\n\nThat in and by itself should not be a problem, I guess. It would be better\nif everything was just encoded in a single encoding, but it's not wrong at\nall.\n\nRegards,  Martin.\n\n\n\n"
        },
        {
            "subject": "Notes from today's GEO meetin",
            "content": "Here are my notes from today's meeting. Maybe we should spend a few minutes\ntomorrow making sure these accurately represent what we agreed to:\n\n1. When dealing with an issue where available solutions are limited by the\nlack of support (in, for example, browsers) of certain aspects of W3C\nstandards, we will:\n  A. Provide a solution that can be implemented using currently-available\ntechnology, but also\n  B. Point out how the W3C standards should be implemented (by browsers in\nthis example) to enable the better solution.\n\n\n2. Initial deliverables will cover the following technologies\n\n  A. HTML/XHTML (with the assumption that CSS are used)\n  B. CSS (either level 1 or 2)\n  C. One newer technology (to be determined)\n\n\n3. Discussion points for Saturday:\n\n  A. Create a process for generating the deliverables\n  B. The third technology to cover\n  C. Who is the audience? (maybe we can?t finalize this yet)\n  D. Usability requirements (brainstorming)\n  E. Architecture (what we?ll write in, e.g. xml)\n  F. Education and outreach\n  G. Content brainstorming: declare lang, declare charset, sort, time/date\nformatting, etc.\n\n\nSteve\n\n\nSteve Billings\nGlobal 360\nSoftware Globalization Consulting & Training\nwww.global360.com\n+1 978-697-8201\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "Dan Brickley wrote:\n>\n> Agreed. You might also want to edit intro.html in the reports directory to\n> point to it, if you've not done that already. \n\nDone.\n\n> Regarding bibliographies, I did (for obscure reasons) start collecting up\n> the ISBNs of all the books I own. Also scribbled a title/author, but the\n> main thing I wanted was isbns; hope is to hook into a lookup-via-isbn web\n> service to get richer metadata to autogenerate bibliographic records, and\n> provide fodder for collaborative filtering apps. I'm not sure if that kind\n> if bibliographic app fits with your plans, have only had time for quickest\n> skim of the document today...\n\nDoes sound like a possible fit. It'd certainly be nice to have lots of ways to\nseed a bibliography record and link to several web services to fill in the known\ndetails and ISBNs is a good example of a useful seed. Collaborative filtering of\nbooks sounds like possible test case - at least as a thought experiment to check\nhow it might be built on top of whatever architecture/tool-set emerges.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle",
            "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n"
        },
        {
            "subject": "Teleconference toda",
            "content": "Chaps,\n\nThis is to confirm that we will have a teleconference meeting at the following times TODAY to continue the discussions held at the FTF.  Apologies for short notice.\n\nTimes are:\nSeattle (GMT-8): 8am\nUtah (GMT-7): 9am\nBoston (GMT-5): 11am\nUK (GMT): 4pm\nMorrocco (GMT+1): 5pm\nChina (GMT+7): 11pm\n\nDial-in details are:\nW3C Zakim bridge (+1-617-761-6200) with the conference code 4186.\n\nSpeak to you soon,\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "New WG member",
            "content": "Dear I18N WG,\n\nI'm glad to welcome the following new members of the I18N WG. All have public status as part of the GEO task force (see http://www.w3.org/International/Group/members).\n\n- Steve Billings (Global360), Massachusetts\n- Andrew Cunningham (State Library of Victoria), Australia\n- Isaac Mao (Tangram), China\n- Chulkee Sung (SCO Group), Utah\n\n(I look forward to setting up a teleconference time!)\n\nRegards,   Richard\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "Public-i18ngeo list opened u",
            "content": "All,\n\nPlease note that it is now possible to subscribe to the list public-i18n-geo without committing to the terms for task force participation [1].  This is to allow people who cannot make the commitment to more easily contribute to the I18N GEO (Guidelines, Education & Outreach) work.\n\nThe public-i18n-geo list is dedicated to discussion of work on the GEO deliverables. Note that any general questions or discussions should NOT take place on this list, but on the www-international list [2].\n\nIf you wish to be subscribed to the public-i18n-geo list, please send me an email at ishida@w3.org.\n\nRegards,\nRichard.\n\n[1] http://www.w3.org/International/geo/#join\n[2] http://www.w3.org/International/geo/Overview.html#lists\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "HTML Validator/QA tip",
            "content": "Dear GEO participants,\n\nHere is a pointer to a source of ideas for guidelines:\n\nhttp://www.w3.org/2001/06tips/\n\nThese tips appear (at random) on the (X)HTML validator,\nsee e.g. http://validator.w3.org:8001/check?uri=http://www.w3.org/.\n\n\nI think these tips are interesting for various reasons:\n\n- They show an example of how to ask people for ideas for\n   tips/guidelines,... and how to review them.\n   (http://www.w3.org/2001/06tips/#process)\n\n- They may be one of the places to distribute I18N-related\n   guidelines, or an entry point to I18N guidelines\n\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "Re: HTML Validator/QA tip",
            "content": "Nice to see some discussion starting.\n\nI like the styles guide http://www.w3.org/Provider/Style/ organization\nas a model that is readable sequentially, but allows you to move quickly\nto topics of particular interest as well as being able to read thru\noverviews without getting mired in details. The overviews become the\nquick tips...\n\ntex\n\nMartin Duerst wrote:\n> \n> Dear GEO participants,\n> \n> Here is a pointer to a source of ideas for guidelines:\n> \n> http://www.w3.org/2001/06tips/\n> \n> These tips appear (at random) on the (X)HTML validator,\n> see e.g. http://validator.w3.org:8001/check?uri=http://www.w3.org/.\n> \n> I think these tips are interesting for various reasons:\n> \n> - They show an example of how to ask people for ideas for\n>    tips/guidelines,... and how to review them.\n>    (http://www.w3.org/2001/06tips/#process)\n> \n> - They may be one of the places to distribute I18N-related\n>    guidelines, or an entry point to I18N guidelines\n> \n> Regards,    Martin.\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: Deliverable 12.1.",
            "content": ">Sounds interesting. It might be worth exploring whether any of the\n>tools we put\n>together to support this might be helpful to you and vice versa.\n\nWhat have you got?? ;-)\n\nI'm just in the middle of a rebuild, after deciding what I'd got was getting\ntoo crufty. I think the closest thing around to what I'm aiming for is\nTinderbox, (though I haven't got a Mac on which to play), but more node &\narc based & very web & RDF-aware. In other words a 'Personal Knowledge\nManager', although I'm not sure how far I want to go into the email side of\nthings. I'm approaching the first goal which is mindmapping/(semantic)\nblogging with a graphic UI.\n\n>If you have any\n>thoughts on requirements for such tools then we'd be really interested in\n>hearing about them.\n\nI don't think we can have too many schema registries... but a loose thought\ncloser to your deliverable would be a registry/discovery tool for not only\nRDF-aware apps, but a kind of Citeseer for related (primarily open source)\nsoftware. For example, when I started on the current project I had a pretty\nthorough search for node & arc graphing code & libraries. Nothing was really\nclose enough, so I coded a lot from scratch. Months later, purely by chance\nI came across the library I'm using now (fortunately it was around the time\nI decided on the rewrite, so I can still save some effort).\n\nSomething else which I reckon might be popular would be a 'Jena Lite'\n(mentioned on that list not long ago). An RDF API for folks such as RSS\nfeeders that don't want everything Jena can offer, but want goes beyond\nstraight XML or regexp-based hacking.\n\nCheers,\nDanny.\n\nPS. Winer/Wiener\nsee : http://www.cs.umanitoba.ca/~djc/wiener/w8.html\n\n\n-----------\nDanny Ayers\n\nIdea maps for the Semantic Web\nhttp://ideagraph.net\n\n<stuff> http://www.isacat.net </stuff>\n\nSemantic Web Log :\nhttp://www.citnames.com/blog\n\n\n\n"
        },
        {
            "subject": "Re: HTML Validator/QA tip",
            "content": "Hi\n\nTex Texin wrote:\n> \n> I like the styles guide http://www.w3.org/Provider/Style/ organization\n> as a model that is readable sequentially, but allows you to move quickly\n> to topics of particular interest as well as being able to read thru\n> overviews without getting mired in details. The overviews become the\n> quick tips...\n>\n\nThe style guide incorporating quick tips is an interesting idea, \nalthough the format is better suited to material designed as educational \nmaterial or for casual reading.\n\nFor more intensive uses in the workplace something more concise and \nmaybe akin to the accessibility guidelines/checklists may more useful.\n\nIdeally we need to cover both types/levels of material.\n\nJust my 2 cents worth.\n\nAndrew\n\n-- \nAndrew Cunningham\nMultilingual  Technical Officer\nOPT, Vicnet\nState Library of Victoria\nAustralia\n\nandrewc@vicnet.net.au\n\nPh: +61-3-8664-7001\nFax: +61-3-9639-2175\n\n\n\n"
        },
        {
            "subject": "RE: HTML Validator/QA tip",
            "content": "It does sound like there may be two needs:\n\n1. Quick tips\nA list of the tips provides links into the content\nEach link (tip) summarizes the action to take\n2. A manual\nA more traditional table of contents provides links into the content\nIn addition to the guidelines themselves, the manual could include\nintroductory sections with background material, appendices with backup\nmaterial, etc.\n\nI'm wondering if a single source of content could serve both needs...? That\nis, the quick tips simply become another window into (i.e. a set of links\ninto) the core of the manual (the sections containing the guidelines. There\nmay be a mismatch in style, level of detail needed, or navigational needs,\nbut if it worked it could reduce the time to produce them.\n\nSteve\n\n\nSteve Billings, Global 360\nSoftware Globalization Consulting\nJava Internationalization Training\nURL: http://www.global360.com/\nEmail: mailto:billings@global360.com\nTEL: +1 978-697-8201\n\n-----Original Message-----\nFrom: public-i18n-geo-request@w3.org\n[mailto:public-i18n-geo-request@w3.org]On Behalf Of Andrew Cunningham\nSent: Thursday, October 10, 2002 9:27 PM\nTo: Tex Texin\nCc: Martin Duerst; public-i18n-geo@w3.org\nSubject: Re: HTML Validator/QA tips\n\n\nHi\n\nTex Texin wrote:\n>\n> I like the styles guide http://www.w3.org/Provider/Style/ organization\n> as a model that is readable sequentially, but allows you to move quickly\n> to topics of particular interest as well as being able to read thru\n> overviews without getting mired in details. The overviews become the\n> quick tips...\n>\n\nThe style guide incorporating quick tips is an interesting idea,\nalthough the format is better suited to material designed as educational\nmaterial or for casual reading.\n\nFor more intensive uses in the workplace something more concise and\nmaybe akin to the accessibility guidelines/checklists may more useful.\n\nIdeally we need to cover both types/levels of material.\n\nJust my 2 cents worth.\n\nAndrew\n\n--\nAndrew Cunningham\nMultilingual  Technical Officer\nOPT, Vicnet\nState Library of Victoria\nAustralia\n\nandrewc@vicnet.net.au\n\nPh: +61-3-8664-7001\nFax: +61-3-9639-2175\n\n\n\n"
        },
        {
            "subject": "Name",
            "content": "Hello everyone,\n\nI will soon be sending out a welcome message and starting up some threads in preparation for our kickoff meeting.  \n\nIn the meantime, it occurred to me that we could make some improvements to the member page at http://www.w3.org/International/geo/members.html by including the following:\n\n1] a line after each name entitled: \"Known as: ...\" so people can specify what they'd like to be called.  Very useful for Chinese or Southern Indian people, for example.\n\n2] add another line where appropriate to allow people to add their name in their native script, eg. Arabic, Chinese, etc.  I can add these easily enough if you send me in an HTML attachment (preferably utf-8 encoding).  People will only see these if they have the font, but since most people who would really need to see them would probably have the font, it may be an interesting thing to do.\n\nThoughts?\n\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "Re: Name",
            "content": "Great ideas. We should make our pages as international as possible\nfollowing/demonstrating our own guidelines.\n\nWe should take a tougher stand on the font issue and implement some\nsolutions, even if it means a backup page with gifs or svg drawings.\nMost applications don't have an option to create pages with characters\nthat sometimes can't be seen.\n\ntex\n\n\nRichard Ishida wrote:\n> \n> Hello everyone,\n> \n> I will soon be sending out a welcome message and starting up some threads in preparation for our kickoff meeting.\n> \n> In the meantime, it occurred to me that we could make some improvements to the member page at http://www.w3.org/International/geo/members.html by including the following:\n> \n> 1] a line after each name entitled: \"Known as: ...\" so people can specify what they'd like to be called.  Very useful for Chinese or Southern Indian people, for example.\n> \n> 2] add another line where appropriate to allow people to add their name in their native script, eg. Arabic, Chinese, etc.  I can add these easily enough if you send me in an HTML attachment (preferably utf-8 encoding).  People will only see these if they have the font, but since most people who would really need to see them would probably have the font, it may be an interesting thing to do.\n> \n> Thoughts?\n> \n> RI\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> The W3C Internationalization Activity has restructured, and has issued a call for participation.\n> See http://www.w3.org/International/about.html\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Welcome to the GEO Task Forc",
            "content": "Dear GEO participants,\n\n\nI would like to welcome you all to the Guidelines, Education & Outreach (GEO) Task Force of the W3C Internationalization Working Group (WG). I apologise for the length of this mail, but I want to be able to link to this information in one place.\n\nFor some time now, the W3C and the I18N WG have wanted to develop guidelines and get the internationalisation message out there to strengthen the cause of Universal Access to the web.  I'd like to thank you for signing up to help make this happen.\n\nI think it is time to start the email discussions, even though there are several people still going through the sign up process who I think will have much to add.  \n\nAs Misha Wolf said, at the beginning of the WG way back in 1988, \"As we are a very international WG, I would like to ask you all to write clearly and read carefully, so we minimise misunderstandings due to different language backgrounds.  Please let us find ways of debating and disagreeing without offending each other.\"  (I need as much help as anyone to write clear English, especially given my own en-UK dialect ! ) [Btw, thanks to Misha, whose original mail I have plagiarised quite a lot below.]\n\nI would encourage you to send in some biographical details to this list so that we get to know each other better.  Please also state your key interests in working with the group.\n\n\n\nThere follows information on the following topics:\n\n- W3C Internationalization Groups and Web sites\n- Meetings\n- Mailing lists\n- W3C culture and process\n\n\n\n======================\nOrganizational Information \n======================\n\nMost of the work of the W3C is done within groups called Domains.  Each Domain consists of a number of Activities.  Activities contain Working Groups and Interest Groups.  The GEO Task Force is currently in the Document Formats Domain, the Internationalization Activity, and the Internationalization Working Group (I18N WG).  The WG charter (http://www.w3.org/2002/05/i18n-recharter/WG-charter.html) describes how the work of the I18N WG is structured under three Task Forces.  One or more task forces may become WGs in their own right at some point.  The task forces are described in the charter.  For links to the public and home pages of each task force, see http://www.w3.org/International/about.html#scope .  \n\nPlease bear in mind that all GEO task force information is publicly visible.  The mail archives (http://lists.w3.org/Archives/Public/public-i18n-geo/) and documents can be read by any member of the public.  The Core TF operates almost exclusively within member-only space, whereas the Web Services TF will conduct most of its discussion in public but also has a means to discuss member-confidential information on a separate list if needs be.  If you are a member of one of the other task forces or another working group, please do not cross-post member-confidential information to the public-i18n-geo list.\n\nI am currently both the Chair and the Team Contact for the Task Force.  I would like to find someone else to be the Chair at some point in the not-too-distant future.  At the Internationalization WG level, Misha Wolf is currently the Chair and Martin D??rst the Team Contact.  Martin is also the Internationalization Activity Lead.\n\nThe W3C Internationalization Activity pages are found at http://www.w3.org/International .  The GEO home page is at  http://www.w3.org/International/geo - you should be able to find any information you need about the task force from here. I currently maintain these pages.  I am always open to suggestions for improving them, or reminders of things I have forgotten. \n\nCurrent participants in the task force can be found at http://www.w3.org/International/geo/members.html .  (The full list of working group members is in member-only space at http://www.w3.org/International/Group/members).\n\n\n\n\n========================\nMeetings\n========================\n\nAs announced on the GEO home page (http://www.w3.org/International/geo/Overview.html#meetings)  the WG will hold its \nkick-off meeting on 22-23 November in Boston.  We are still working on the logistics, and I will inform you of the details as soon as possible.\n\nWe typically aim to hold other FTF meetings in conjunction with the International Unicode Conference whenever possible.  This makes travel justifications easier for many of the TF members.  We welcome alternative suggestions.\n\nWe will also establish regular weekly or bi-weekly teleconferences at some point.  These will be useful for complex discussions, and for reaching agreement/consensus.  Since we already have members from Australia, China, North Africa, Europe, and East and (soon) West Coast US and Japan, it will be interesting trying to decide on a time for the telecon, but we will cross that bridge when we come to it!  It is certainly encouraging that this is such an international group.\n\nAt the beginning of March there will also be a Technical Plenary meeting in Boston.  At this forum many working groups meet together for cross-WG discussion.  We should discuss possible participation in this meeting at some point.\n\nIf you are a WG member and are unable to attend a meeting, please ensure that you send in an note before the meeting to say so (this is will be referred to as sending in 'regrets').\n\n\n\n\n\n==========================\nMailing lists\n==========================\n\nPlease note that the public-i18n-geo list is intended for discussions related to the task force's work projects.  Please use the www-international list for any general discussion topics relating to internationalization (you should all be subscribed to that list).  \n\nSince the archives are public, it is quite possible for people who are only subscribed to www-international to follow our discussions and offer some comments or feedback on the www-international list, so we should bear that in mind.  We should also scan the questions raised in www-international for topics to include in our guidelines.  We can also look to the www-international list for help with cultural information, linguistic or script questions, and the like.  There are currently 376 subscribers to that list, from many places around the world.\n\n\n\n\n==========================\nW3C culture and process\n==========================\n\nThe World Wide Web Consortium has a unique culture, and a process.  It may take a while to get an idea of this, but if you have time, it would be a good idea to look at the web site http://www.w3.org/.  For general information, see http://www.w3.org/Consortium.  If you want to, you can read all of the process document http://www.w3.org/Consortium/Process/, but you probably have better ways of spending your time.  If any process problems come up in our work, the W3C team members will be able to help us.\n\nI would also strongly recommend that you take a look at the work of the Web Accessibility Initiative (WAI - pronounced 'way').  I think we should use their experience in guidelines development as much as possible.  Look especially at the WCAG WG (Web Content Accessibility Guidelines) pages. Note that WCAG is currently changing its approach to guidelines development.  I think we should be involved in that process of change, and further we should consider that WAI and GEO might indeed often be addressing the same audience, and should exploit whatever synergies we can.\n\n\n\nThat is a long enough message for one day.  Please feel free to contact me with any questions.  In the meantime, I'm looking forward to working with you all.\n\nBest regards,\nRichard.\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "First thoughts on FTF agend",
            "content": "All,\n\nIt is good to see the task force membership growing, and the discussion beginning already.  We have some other task force members currently going through the application process, and I hope they will be on board very soon.  (When they do, please be patient if they need some time to come up to speed with these discussions, or want to take us in another direction.)\n\nAs it mentions on the GEO home page [1], we are expecting to hold a face to face (FTF) kick-off meeting in Boston on 22-23 November, where we can hold detailed discussions on the way forward for the GEO work.\n\nI have been noting down ideas for agenda topics.  Please send in any others you think of.\n\n-review of WAI (Web Accessibility Initiative) approach to guidelines\n-audience, user needs, and topic areas for guidelines\n-an architecture to support the guidelines (development and deployment)\n-education and outreach (the EO in GEO) \n-content brainstorming: levels, scope, specific ideas for inclusion\n-ways of gathering data / sources of information\n-process\n\nOver the next day or so, I will send out some ideas I have on each of these topics in separate threads, in the hope that this will stimulate discussion that can serve as input to the meeting.\n\nBest regards,\nRichard.\n\n\n\n[1] http://www.w3.org/International/geo/\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "Re: Name",
            "content": "Hello Tex,\n\nMany thanks for your comments.\n\nAt 14:18 02/10/11 -0400, Tex Texin wrote:\n\n>Great ideas. We should make our pages as international as possible\n>following/demonstrating our own guidelines.\n>\n>We should take a tougher stand on the font issue and implement some\n>solutions, even if it means a backup page with gifs or svg drawings.\n>Most applications don't have an option to create pages with characters\n>that sometimes can't be seen.\n\nI think it's important that the guidelines make distinctions on various\naxes. One such axis is the implementations one wants to reach. We can\neasily say something like \"this won't work on generation 3 browsers\".\n\nBut we should also take into account that the Web moves forward,\nand that we (I hope, at least) want it to move forward, rather than\nbackwards. Using gifs can be very helpful in some cases, e.g.\nto help people to check whether their browser does bidirectional\nrendering correctly, but for example using gifs instead of Japanese\ncharacters just because somebody might not have installed a Japanese\nfont is probably not worth spending too much time on.\n\njust my 2 yen.\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "Call for Papers: IUC23 (23rd Internationalization and Unicode Conference",
            "content": ">>>>>>>>>>>>>>>>>>>>>>>>>>  Call for Papers!  <<<<<<<<<<<<<<<<<<<<<<<<<\n\n      Twenty-third Internationalization and Unicode Conference (IUC23)\n       Unicode, Internationalization, the Web: The Global Connection\n                        Week of March 24-28, 2003\n                         Prague, Czech Republic\n\n>>>>>>>>>>>>>>>>>>>>  Send in your submission now!  <<<<<<<<<<<<<<<<<<<\n\n                    Submissions due: November 15, 2002\n                   Notification date: November 29, 2002\n                   Completed papers due: January 6, 2003\n              (in electronic form and camera-ready paper form)\n\n>>>>>>>>>>>>>>>>>>>>>>>>  Just 4 weeks to go!  <<<<<<<<<<<<<<<<<<<<<<<\n\nThe Internationalization & Unicode Conference is the premier technical\nconference worldwide for both software and Web internationalization. The\nconference (renamed from \"Unicode Conference\" to more accurately reflect\nits content) features tutorials, lectures, and panel discussions that\nprovide coverage of standards, best practices, and recent advances in\nthe globalization of software and the Internet. Attendees benefit from\nthe wide range of basic to advanced topics and the opportunities for\ndialog and idea exchange with experts in the field. The conference runs\nmultiple sessions simultaneously to maximize the value provided.\n\nNew technologies, innovative Internet applications, and the evolving\nUnicode Standard bring new challenges along with their new capabilities.\nThis technical conference will explore the opportunities created by the\nlatest advances and how to leverage them for global users, as well as\npotential pitfalls to be aware of, and problem areas that need further\nresearch. There will also be demonstrations of best practices for\ndesigning applications that can accommodate any language.\n\nWe invite you to submit papers that relate to Unicode or any aspect of\nsoftware and Web Internationalization. You can view the programs of\nprevious conferences at:\nhttp://www.unicode.org/unicode/conference/about-conf.html\n\n\nCONFERENCE ATTENDEES\n\nConference attendees are generally involved in either the development\nand deployment of Unicode software, or the globalization of software and\nthe Internet. They include managers, software engineers, systems\nanalysts, font designers, graphic designers, content developers, web\ndesigners, web administrators, technical writers, and product marketing\npersonnel.\n\nTHEME & TOPICS\n\nInternational computing is the overall theme of the Conference.\nPresentations should be geared towards a technical audience.  Topics of\ninterest include, but are not limited to, the following (within the\ncontext of Unicode, internationalization or localizability):\n\n- Internationalization issues with new technologies\n- XML and Web protocols\n- The World Wide Web (WWW)\n- Security concerns e.g. Avoiding the spoofing of UTF-8 data\n- Impact of new encoding standards\n- Implementing Unicode: Practical and political hurdles\n- Implementing new features of recent versions of Unicode\n- Evaluations (case studies, usability studies)\n- Natural language processing\n- Algorithms (e.g. normalization, collation, bidirectional)\n- Programming languages and libraries (Java, Perl, et al)\n- Optimizing performance of systems and applications\n- Search engines\n- Library and archival concerns\n- Portable devices\n- Migrating legacy applications\n- Cross platform issues\n- Printing and imaging\n- Operating systems\n- Databases\n- Large scale networks\n- Government applications\n- Testing applications\n- Business models for software development (e.g. Open source)\n\nWe invite you to submit papers which define tomorrow's computing,\ndemonstrate best practices in  computing today, or articulate problems\nthat must be solved before further advances can occur.\n\n\nSESSIONS\n\nThe Conference Program will provide a wide range of sessions including:\n- Keynote presentations\n- Workshops/Tutorials\n- Technical presentations\n- Panel sessions\n\nAll sessions except the Workshops/Tutorials will be of 40 minute\nduration.  In some cases, two consecutive 40 minute program slots may be\ndevoted to a single session.\n\nThe Workshops/Tutorials will each last approximately three hours.  They\nshould be designed to stimulate discussion and participation, using\nslides and demonstrations.\n\n\nPUBLICATIONS\n\nIf your paper is accepted, your details will be included in the\nConference brochure and Web pages and the paper itself will appear on a\nConference CD, with an optional printed book of Conference Proceedings.\n\n\nCONFERENCE LANGUAGE\n\nThe Conference language is English.  All submissions, papers and\npresentations should be provided in English.\n\n\nSUBMISSIONS\n\nSubmissions MUST contain:\n\n1. An abstract of 150-250 words, consisting of statement of purpose,\npaper description, and your conclusions or final summary.  Also, if this\nis a paper for an intermediate or advanced audience, please specify what\nassumptions you are making about the attendees' prior knowledge.\n\n2. A brief biography.\n\n3. The details listed below:\n\n   SESSION TITLE:             _________________________________________\n\n                              _________________________________________\n\n   TITLE (eg Dr/Mr/Mrs/Ms):   _________________________________________\n\n   NAME:                      _________________________________________\n\n   JOB TITLE:                 _________________________________________\n\n   ORGANIZATION/AFFILIATION:  _________________________________________\n\n   ORGANIZATION'S WWW URL:    _________________________________________\n\n   OWN WWW URL:               _________________________________________\n\n   ADDRESS FOR PAPER MAIL:    _________________________________________\n\n                              _________________________________________\n\n                              _________________________________________\n\n   TELEPHONE:                 _________________________________________\n\n   FAX:                       _________________________________________\n\n   E-MAIL ADDRESS:            _________________________________________\n\n   TYPE OF SESSION:           [ ] Keynote presentation\n\n                              [ ] Workshop/Tutorial\n\n                              [ ] Technical presentation\n\n                              [ ] Panel\n\n   PANELISTS (if Panel):      _________________________________________\n\n                              _________________________________________\n\n                              _________________________________________\n\n                              _________________________________________\n\n                              _________________________________________\n\n                              _________________________________________\n\n                              _________________________________________\n\n                              _________________________________________\n\n   TARGET AUDIENCE (you may select more than one category):\n\n                              [ ] Content Developers\n\n                              [ ] Font Designers\n\n                              [ ] Graphic Designers\n\n                              [ ] Managers\n\n                              [ ] Marketers\n\n                              [ ] Software Engineers\n\n                              [ ] Systems Analysts\n\n                              [ ] Technical Writers\n\n                              [ ] Others (please specify):\n\n                              _________________________________________\n\n                              _________________________________________\n\n   LEVEL OF SESSION (you may select more than one category):\n\n                              [ ] Beginner\n\n                              [ ] Intermediate\n\n                              [ ] Advanced\n\n\n\n\nSubmissions should be sent by e-mail to either of the following\naddresses:\n\n   papers@unicode.org\n\n   info@global-conference.com\n\nThey should use ASCII, non-compressed text and the following subject\nline:\n\n   Proposal for IUC 23\n\nIf desired, a copy of the submission may also be sent by post to:\n\n   23rd Internationalization and Unicode Conference\n   c/o Global Meeting Services, Inc.\n   8949 Lombard Place #416\n   San Diego, CA  92122  USA\n   Tel: +1 858 638 0206\n   Fax: +1 858 638 0504\n\nCONFERENCE PROCEEDINGS\n\nAll Conference papers will be published on CD.  Printed proceedings will\nbe offered as an option.\n\nEXHIBIT OPPORTUNITIES\n\nThe Conference will have an Exhibition area for corporations or\nindividuals who wish to display and promote their products, technology\nand/or services.\n\nEvery effort will be made to provide maximum exposure and advertising.\n\nExhibit space is limited.  For further information or to reserve a\nplace, please contact Global Meeting Services at the above location.\n\nCONFERENCE VENUE\n\nThis 3 day Conference will be held during the week of March 24-28, 2003\nin Prague, Czech Republic.  Exact venue to be announced.\n\nTHE UNICODE CONSORTIUM\n\nThe Unicode Consortium was founded as a non-profit organization in 1991.\nIt is dedicated to the development, maintenance and promotion of The\nUnicode Standard, a worldwide character encoding.  The Unicode Standard\nencodes the characters of the world's principal scripts and languages,\nand is code-for-code identical to the international standard ISO/IEC\n10646.  In addition to cooperating with ISO on the future development of\nISO/IEC 10646, the Consortium is responsible for providing character\nproperties and algorithms for use in implementations.  Today the\nmembership base of the Unicode Consortium includes major computer\ncorporations, software producers, database vendors, research\ninstitutions, international agencies and various user groups.\n\nFor further information on the Unicode Standard, visit the Unicode Web\nsite at http://www.unicode.org or e-mail <info@unicode.org>\n\n                           *  *  *  *  *\n\nUnicode(r) and the Unicode logo are registered trademarks of Unicode,\nInc.  Used with permission.\n\n\n\n"
        },
        {
            "subject": "RI vacatio",
            "content": "Please note that I will be on vacation and unplugged from email from Thurs 24th Oct to Mon 28th Oct, inclusive.  \n\nBest regards,\nRI\n(team members can see my locator page at http://www.w3.org/Team/ishida )\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "There's a bibliography of RFCs, ISO, ITU and a few W3C specs in an XML \nformat at xml.resource.org (site seems down at moment, so can't give \ndefinite URL).\n\nThe XML format used is taken from RFC 2629 [1], and would be easy enough to \nconvert to RDF/foaf++.\n\n#g\n--\n\n[1] http://www.ietf.org/rfc/rfc2629.txt\n\n\nAt 06:00 PM 11/5/02 +0000, Dave Reynolds wrote:\n\n>Dan Brickley wrote:\n> >\n> > Agreed. You might also want to edit intro.html in the reports directory to\n> > point to it, if you've not done that already.\n>\n>Done.\n>\n> > Regarding bibliographies, I did (for obscure reasons) start collecting up\n> > the ISBNs of all the books I own. Also scribbled a title/author, but the\n> > main thing I wanted was isbns; hope is to hook into a lookup-via-isbn web\n> > service to get richer metadata to autogenerate bibliographic records, and\n> > provide fodder for collaborative filtering apps. I'm not sure if that kind\n> > if bibliographic app fits with your plans, have only had time for quickest\n> > skim of the document today...\n>\n>Does sound like a possible fit. It'd certainly be nice to have lots of ways to\n>seed a bibliography record and link to several web services to fill in the \n>known\n>details and ISBNs is a good example of a useful seed. Collaborative \n>filtering of\n>books sounds like possible test case - at least as a thought experiment to \n>check\n>how it might be built on top of whatever architecture/tool-set emerges.\n>\n>Dave\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Kick of",
            "content": "The kick off face-to-face meeting will be in Boston on 22-23 November.  Please let me know if you are able to make it. Detailed logistics information will follow shortly.\n\nThe aim of the meeting will be to set the initial direction for the task force.\n\nTo make the discussions as effective as possible, and allow maximum input from those unable to make the meeting, I have prepared some initial ideas at http://www.w3.org/International/geo/plan/ftf1-discussion.html .  I find it is helpful to start from a proposal when developing strategies.  Please don't take this as directive.  It is a means for developing discussion.\n\nI would encourage everyone to make comments on the discussion document by email prior to the meeting.  Please try to build on and refer to the text in the discussion document, so that we can incorporate the ideas easily within the agenda. Alternative wordings, topics or constructive ideas are welcome!  Please try to make suggestions whenever possible.\n\nIf writing a long mail note, please try to state your ideas as concisely and clearly as possible, with a summary at the top or at the beginning of each paragraph.  Break up the text and use headings where appropriate to help the reader.\n\nUnfortunately I have to leave for a vacation this evening, and my wife won't appreciate it if I'm reading email, so I will rejoin the discussion on Tuesday.\n\nI look forward to reading your comments.\n\nAll the best,\nRichard.\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "Incremental disclosur",
            "content": "To give you a *very* quick and dirty idea of how incremental disclosure and task oriented indexing can work, please see http://www.w3.org/People/Ishida/checklists/wai-html-impl-checklist.html \n\nI threw this together while trying to get my head around WCAG's HTML Techniques doc v1.0.  Headings are mostly theirs. Black text is checkpoints.  Green text are directives I pulled out of the flowing text.  Click on the text to expand or contract the information.\n\nNOTE: I'm not proposing this as a way to implement the GEO guidelines.  But it is an interesting illustration of guiding someone to task-based, checklist oriented information.  Note that the hand icon takes you to the detailed flowing text, if you need to read that.\n\nHope that helps,\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "More new WG member",
            "content": "Dear I18N WG,\n\nI'm glad to welcome the following new members of the I18N WG\n\n- Wendy Chisholm (W3C), Seattle [Wendy is our liaison with WAI]\n- Lloyd Honomichl (Lionbridge), Utah (I think) [Public member]\n- Russ Rolfe (Microsoft), Seattle\n- Suzanne Topping (BizWonk), New York (State) [Public member] [Suzanne is particularly interested in education and outreach]\n\nMany thanks to all in advance for their contributions.\n\nRegards,   Richard\n\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "November FTF logistic",
            "content": "There is now a page at  http://www.w3.org/International/ws/2002/11/ftf200211.html that provides logistical information related to the kick off face-to-face meeting in Boston in November.  Please let me know if you are able to make this meeting.  \n\nAs mentioned before, the aim of this meeting will be to determine the near term direction for the task force.  If you are unable to make the meeting, please send in comments and suggestions to the list beforehand if you can (see the archives at http://lists.w3.org/Archives/Public/public-i18n-geo/).\n\nWe are working on the arrangements for dial-in.  I will send out a draft agenda in a short while.  If you wish to participate by telephone, please indicate at that point which parts of the meeting you wish to dial in to. We will establish dial in facilities just for those times.\n\nBest regards,\nRichard.\n \n\n \n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "FTF meeting date",
            "content": "All,\n\nPlease note that the correct dates for the FTF meeting in Boston are 22-23 November (not 21-22nd as was initially, incorrectly stated on the logisitics page http://www.w3.org/International/ws/2002/11/ftf200211.html ).\n\nThanks to Steve Billings for pointing out the error!\nRI\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "New public list - public-i18n-geo  maintained by Richard Ishid",
            "content": "Maintaining Activity: Internationalization\n\nPurpose: This is the discussion list archive for the GEO (Guidelines,\nEducation and Outreach) Task Force (part of the Internationalization\nWorking Group). Please limit your use of this list to discussions\nsupporting the work of the task force. Comments in this archive are\nvisible to the public.\n\nReference: For more information and resources related to GEO, see the home\npage[1].\n\n\n1.  http://www.w3.org/International/geo/\n\n\n\n"
        },
        {
            "subject": "Face&ndash;to&ndash;face meetings of the W3C I18N task forces &ndash;&ndash; 22/23 Nov 2002, Boston, MA, US",
            "content": "The W3C's three I18N task forces will hold separate face-to-face meetings, in a single location, on:\n\n   Friday 22 November 2002\n   Saturday 23 November 2002\n\nin:\n\n   Boston, MA, USA\n\nWe are looking for a host. If you could host these meetings, please let me know.\n\nThe three I18N task forces are:\n\n-  The Core Task Force is developing the Character Model for the World\n   Wide Web and the Internationalized Resource Identifiers (IRIs)\n   specification.  It also reviews specifications produced by other W3C\n   Working Groups.\n\n-  The Web Services (WS) Task Force is investigating the needs and\n   problems in the area of internationalization of Web Services, in\n   particular the dependency of Web Services on language, culture,\n   region, and locale-related contexts.\n\n-  The GEO (Guidelines, Education & Outreach) Task Force is helping to\n   get the internationalization aspects of W3C technology better\n   understood and more widely and consistently used.\n\nFurther details will be distributed as soon as they are available.\n\nRegards,\n\n============\nRichard Ishida\nW3C\n\nThe W3C Internationalization Activity has restructured, and has issued a call for participation.  \nSee http://www.w3.org/International/about.html\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "Danny Ayers wrote:\n> \n> What have you got?? ;-)\n\nWell hopes, aspirations that sort of thing ...  :-)\n\nActually, we do have some code from our \"ePerson\" community information\nmanagement experiment, though that was an intranet kind of thing with no\nconnection to blogging so we might end up reusing some ideas more than the code.\n\n> I'm just in the middle of a rebuild, after deciding what I'd got was getting\n> too crufty. I think the closest thing around to what I'm aiming for is\n> Tinderbox, (though I haven't got a Mac on which to play), but more node &\n> arc based & very web & RDF-aware. In other words a 'Personal Knowledge\n> Manager', although I'm not sure how far I want to go into the email side of\n> things. I'm approaching the first goal which is mindmapping/(semantic)\n> blogging with a graphic UI.\n\nSounds great. \n\n> >If you have any\n> >thoughts on requirements for such tools then we'd be really interested in\n> >hearing about them.\n> \n> I don't think we can have too many schema registries... but a loose thought\n> closer to your deliverable would be a registry/discovery tool for not only\n> RDF-aware apps, but a kind of Citeseer for related (primarily open source)\n> software. \n\nInteresting thought. Blogged bibliography of software tools ... yes, worth\nexploring.\n\n> For example, when I started on the current project I had a pretty\n> thorough search for node & arc graphing code & libraries. Nothing was really\n> close enough, so I coded a lot from scratch. Months later, purely by chance\n> I came across the library I'm using now (fortunately it was around the time\n> I decided on the rewrite, so I can still save some effort).\n\nWhich library did you end up using?\n\n> Something else which I reckon might be popular would be a 'Jena Lite'\n> (mentioned on that list not long ago). An RDF API for folks such as RSS\n> feeders that don't want everything Jena can offer, but want goes beyond\n> straight XML or regexp-based hacking.\n\nGood suggestion but probably outside the scope of this particular activity. One\nchallenge I'd see with a 'Jena lite' would be the parser. ARP is very much aimed\nat quality and full standards conformance rather than 'liteness' - hence the use\nof Xerces which dwarfs jena.\n\n> PS. Winer/Wiener\n> see : http://www.cs.umanitoba.ca/~djc/wiener/w8.html\n\nThank you for that!\n\nDave\n\n\n\n"
        },
        {
            "subject": "This weeks GEO mt",
            "content": "Chaps,\n\nGiven that several of us are still catching up after the Unicode\nconference in Prague, and that the Daylight Savings times are out of\nkilter this week (US hasn't changed but Europe & Australia have), I was\nthinking that perhaps we should postpone the telecon until next week and\nuse the time to work on content.\n\nIf there's something you'd particularly like to discuss with a call this\nweek, please write to the list asap.  Otherwise, I suggest we meet at\nthe new times next week (I'll send out the minutes today).\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "This weeks GEO mt",
            "content": "Chaps,\n\nGiven that several of us are still catching up after the Unicode\nconference in Prague, and that the Daylight Savings times are out of\nkilter this week (US hasn't changed but Europe & Australia have), I was\nthinking that perhaps we should postpone the telecon until next week and\nuse the time to work on content.\n\nIf there's something you'd particularly like to discuss with a call this\nweek, please write to the list asap.  Otherwise, I suggest we meet at\nthe new times next week (I'll send out the minutes today).\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03031",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n19 March 2003\n\nPresent: Richard (chair, scribe), Lloyd, Andrew, Phil\nRegrets: Steve, Russ, Suzanne, Martin\n\n\nNew Actions\n============\n\nACTION: RI, apply agreed changes to FTF minutes and publish.\n\nACTION: AC to create a list of possibilities for 'non-displayable'\ncharacters\n\nACTION: Lloyd,send a list of deprecated tags in HTML by next meeting \n\n\nPrior Action Items\n==============\n\nACTION: TT, RI need to recontact Bill Hall \nDONE.  Will talk at Unicode Conference.\n\nACTION: RI to send invitation to Gerald Edgar, who observed during the\nTech Plen \nDONE\n\nACTION: RI to follow up tommorrow with Barry Caplan.\nDONE\n\nACTION: Russ, follow-up wrt possible new member from Trados\n\nACTION: RI to propose some new teleconf times to cope with daylight\nsavings at next week's meeting.\nDONE during meeting for two weeks ahead and ongoing.\n\nACTION: RI to ping Suzanne again.\nDONE\n\nACTION: RI, set up an area on the W3C site for people to post proposals,\nand give people access. \nDONE\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n\n\nDependencies\n===========\nNone.\n\n\nNew participants\n==============\nPhil Arko introduced himself.\n\nBarry Caplan of i8n.com has also joined the WG.\n\n\n\nMeetings & Events\n===============\nNew telecon times (due to changes in daylight savings) from 8 april\nonwards:\nGMT \nFriday, April 18, 2003, at 7:00 PM \n\nSeattle\nFri 12:00 PM * \n\nBoston\nFri 3:00 PM * \n\nLondon\nFri 8:00 PM * \n\nEurope 9pm\n\nAustralia\nSat 5:00 AM \n\nNo telecon next week due to Unicode Conference.\n\nRichard will make a pesentation at the regular W3C Offices team meeting\non Friday.  The aim is to inform the office staff around the world of\nwhat we are doing and solicit their help and support.\n\n\nChanges to FTF minutes proposed by Richard were accepted.\nACTION: RI, apply agreed changes to FTF minutes and publish.\n\n\nReview of work progress\n==================\nAll planned conversions to invited expert have been done.  Invited\nexperts can now upload information to the upload location at\nhttp://www.w3.org/International/geo/upload/  Information was sent out\nfrom webreq@w3.org about tools that can be used for this.\n\nAsk Richard or webreq@w3.org if you have any questions/problems.\n\nWe have to decided to use the term 'directives' for the pithy directive\nstatements in a technique, formerly called 'rules'.\n\n\nContent development\n================\nBrainstorming session held:\n\nSection 3.1\nAgreed that we should recommend the use of CSS rather than the\nFont tag\nLloyd has been making a list of deprecated tags in HTML - we may\nwant to add this list as an appendix or to the hints & tips\nACTION: Lloyd,send a list of deprecated tags in HTML by next\nmeeting & we can decide what to do with\n\nSection 3.2\nAC:  the meaning of 'undisplayable characters' is not clear  -\nneed to change the title !\nnon-graphic? Control chars? Font absence? Lacking rendering in\nbrowsers/OS,  eg Khmer, Lao?  Characters missing from Unicode? \nACTION: AC to create a list of possibilities for\n'non-displayable' characters\n\nanother question is how to ensure that authors ensure that pages\nare read\n<<authors should provide links to information to help the user\nwhen there are known issues relating to the display of a particular\nscript or language>> \n[could include where to download fonts from]\n<<provide the information in a way it will work, ie. \n<< use a system that maximises likelihood of correct\ndisplay >>\n<< tell people how to find fonts for ordinary languages\n- especially for minorities >>\nneed a sectoin suggesting that authors ensure that these things\nwork\n\ndo we need a chapter 20? How to perform validation & proofing of\nsites - check that sites display correctly\nor section by section, we could ask how do you validate\nthat you made the right choices - eg. escaping too many chars, do the\nfonts work?\nLH sounds a bit like WAI conformance tests\n\n\nNext meeting:\n==========\nSame time, same bridge, in two weeks.\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "FW: MINUTES: I18n GEO teleconference 03031",
            "content": "-----Original Message-----\nFrom: Tex Texin [mailto:tex@i18nguy.com] \nSent: 02 April 2003 01:57\nTo: ishida@w3.org\nSubject: Re: MINUTES: I18n GEO teleconference 030319\n\n\nI attended although I was late. (I think.)\n\nRichard Ishida wrote:\n> \n> MINUTES\n> \n> W3C I18n GEO Phone Conference\n> 19 March 2003\n> \n> Present: Richard (chair, scribe), Lloyd, Andrew, Phil\n> Regrets: Steve, Russ, Suzanne, Martin\n> \n> New Actions\n> ============\n> \n> ACTION: RI, apply agreed changes to FTF minutes and publish.\n> \n> ACTION: AC to create a list of possibilities for 'non-displayable' \n> characters\n> \n> ACTION: Lloyd,send a list of deprecated tags in HTML by next meeting\n> \n> Prior Action Items\n> ==============\n> \n> ACTION: TT, RI need to recontact Bill Hall\n> DONE.  Will talk at Unicode Conference.\n> \n> ACTION: RI to send invitation to Gerald Edgar, who observed during the\n\n> Tech Plen DONE\n> \n> ACTION: RI to follow up tommorrow with Barry Caplan.\n> DONE\n> \n> ACTION: Russ, follow-up wrt possible new member from Trados\n> \n> ACTION: RI to propose some new teleconf times to cope with daylight \n> savings at next week's meeting. DONE during meeting for two weeks \n> ahead and ongoing.\n> \n> ACTION: RI to ping Suzanne again.\n> DONE\n> \n> ACTION: RI, set up an area on the W3C site for people to post \n> proposals, and give people access. DONE\n> \n> Action: Richard, look at ways of making the document print with a \n> smaller font, while avoiding any WAI issues.\n> \n> All: send in pointers to existing guidelines\n> \n> Suzanne: put together a list of short term vs. long term goals related\n\n> to education and outreach - send it to us for discussion\n> \n> Dependencies\n> ===========\n> None.\n> \n> New participants\n> ==============\n> Phil Arko introduced himself.\n> \n> Barry Caplan of i8n.com has also joined the WG.\n> \n> Meetings & Events\n> ===============\n> New telecon times (due to changes in daylight savings) from 8 april\n> onwards:\n>         GMT\n>         Friday, April 18, 2003, at 7:00 PM\n> \n>         Seattle\n>         Fri 12:00 PM *\n> \n>         Boston\n>         Fri 3:00 PM *\n> \n>         London\n>         Fri 8:00 PM *\n> \n>         Europe 9pm\n> \n>         Australia\n>         Sat 5:00 AM\n> \n> No telecon next week due to Unicode Conference.\n> \n> Richard will make a pesentation at the regular W3C Offices team \n> meeting on Friday.  The aim is to inform the office staff around the \n> world of what we are doing and solicit their help and support.\n> \n> Changes to FTF minutes proposed by Richard were accepted.\n> ACTION: RI, apply agreed changes to FTF minutes and publish.\n> \n> Review of work progress\n> ==================\n> All planned conversions to invited expert have been done.  Invited \n> experts can now upload information to the upload location at \n> http://www.w3.org/International/geo/upload/  Information was sent out \n> from webreq@w3.org about tools that can be used for this.\n> \n> Ask Richard or webreq@w3.org if you have any questions/problems.\n> \n> We have to decided to use the term 'directives' for the pithy \n> directive statements in a technique, formerly called 'rules'.\n> \n> Content development\n> ================\n> Brainstorming session held:\n> \n> Section 3.1\n>         Agreed that we should recommend the use of CSS rather than the\n\n> Font tag\n>         Lloyd has been making a list of deprecated tags in HTML - we \n> may want to add this list as an appendix or to the hints & tips\n>         ACTION: Lloyd,send a list of deprecated tags in HTML by next \n> meeting & we can decide what to do with\n> \n> Section 3.2\n>         AC:  the meaning of 'undisplayable characters' is not clear  -\n\n> need to change the title !\n>         non-graphic? Control chars? Font absence? Lacking rendering in\n\n> browsers/OS,  eg Khmer, Lao?  Characters missing from Unicode?\n>         ACTION: AC to create a list of possibilities for \n> 'non-displayable' characters\n> \n>         another question is how to ensure that authors ensure that \n> pages are read\n>         <<authors should provide links to information to help the user\n\n> when there are known issues relating to the display of a particular \n> script or language>>\n>         [could include where to download fonts from]\n>         <<provide the information in a way it will work, ie.\n>                 << use a system that maximises likelihood of correct \n> display >>\n>                 << tell people how to find fonts for ordinary \n> languages\n> - especially for minorities >>\n>         need a sectoin suggesting that authors ensure that these\nthings\n> work\n> \n>         do we need a chapter 20? How to perform validation & proofing \n> of sites - check that sites display correctly\n>                 or section by section, we could ask how do you \n> validate that you made the right choices - eg. escaping too many \n> chars, do the fonts work?\n>                 LH sounds a bit like WAI conformance tests\n> \n> Next meeting:\n> ==========\n> Same time, same bridge, in two weeks.\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "[IRI] new mailing list: publiciri&#64;w3.or",
            "content": "[Appologies if this announcement reaches you multiple times.]\n\nInternationalized Resource Identifiers (IRIs): new mailing list\n\nTo complete the discussion on Internationalized Resource Identifiers\n(IRIs) [1] and move it to Proposed Standard, we have created a new,\ndedicated mailing list. This is based on discussion at the recent\nBOF on URIs [2] at the IETF in San Francisco.\n\nIf you are interested in IRIs, please subscribe to the list\nby sending a mail to public-iri-request@w3.org with \"subscribe\"\n(without the quotes) as the subject, or just click below on [3].\nThe mailing list is publicly archived at [4]. Please wait for\ndiscussion until next week to give everybody a chance to sign up.\nPlease note that the first time you send a mail, you may be asked\nto confirm your mail via a web page. This serves as spam protection\nand to make sure that you understand that your mail is publicly\narchived.\n\nI have also created an issues list at [5] where I will track\nthe discussion.\n\nRegards,    Martin.\n\n\n[1] http://www.ietf.org/internet-drafts/draft-duerst-iri-03.txt\n[2] http://www.ietf.org/ietf/03mar/uribof.txt\n[3] mailto:public-iri-request@w3.org?subject=subscribe\n[4] http://lists.w3.org/Archives/Public/public-iri/\n[5] http://www.w3.org/International/iri-edit/#Issues\n\n\n\n"
        },
        {
            "subject": "[i18n] education &amp; outreach initiativ",
            "content": "While speaking with Richard last week, he asked me to share some thoughts on\nthe education and outreach part of our work. In our conference call\ntomorrow, we can start to discuss this in more detail.\n\nCurrently, we are quite focused on the guidelines themselves. Does it make\nsense to start thinking about the education & outreach part, or is it still\ntoo early? This will obviously depend upon the content being created. When\nshould we start to define the medium or media within which we share this\ncontent? More importantly, will this influence the way in which we create\nthe guidelines?\n\nMany web designers (at least in the US) typically use a site such as\nWebMonkey.com or Builder.com instead of W3.org. Such sites offer a quick\noverview (although not always completely accurate) of the most important\naspects of a topic. They typically (in my experience) do not look to the\nentire guideline on the W3 site. Can we think about methods of ensuring that\nour deliverables are more easily approachable and more usable, so as to make\nsure that web designers come here first to get the most accurate set of\nguidelines?\n\nRichard shared with me the URL to the draft of the expert format. I think\nthat's definitely a step in the right direction!\n\nThanks,\n\nPhil Arko\nSr. Human Factors Engineer\nSiemens Corporate Research\nUser Interface Design Center\nPrinceton, NJ, USA\n\n\n\n"
        },
        {
            "subject": "RE: [i18n] education &amp; outreach initiativ",
            "content": "> -----Original Message-----\n> From: Arko, Phil [mailto:phil.arko@scr.siemens.com] \n> \n> \n> While speaking with Richard last week, he asked me to share \n> some thoughts on the education and outreach part of our work. \n> In our conference call tomorrow, we can start to discuss this \n> in more detail.\n> \n> Currently, we are quite focused on the guidelines themselves. \n> Does it make sense to start thinking about the education & \n> outreach part, or is it still too early? \n\nApologies to all for my lack of participation over the past few months. Due to a series of curious events I was unavoidably detained.\n\n;^)\n\nAt any rate, I'm planning to attend tomorrow's call, and will be preparing the pieces I've had on my to-do list re. education and outreach prior to the meeting.\n\nAs far as your question above Phil, my opinion is that it's -never- too early to work on this part of the picture.\n\nStay tuned for a document or two, and I'll look forward to talking with you all tomorrow.\n\nSuzanne Topping\nVice President\nBizWonk Inc.\n(Solutions for a Global E-conomy) (TM)\n\nstopping@bizwonk.com\n\n25 N. Washington St.\nRochester, NY 14614-1110\nUSA\n\nPhone: +1 585.454.4210\nFax: +1 585.454.4213 \n\n\n\n"
        },
        {
            "subject": "RE: AGENDA: I18N GEO TF telcon, 2003-0409 at 19:00 UTC, 20:00 UK, 12noon Pacific, 3pm Eastern, 5am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n\"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 9 April 2003\nStart    : 19:00 UTC, 20:00 UK, 12noon Pacific, 3pm Eastern, 5am\nAustralia (next\nday!)\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\n*** indicates a topic that will receive particular attention this week\n\n\n\nDraft agenda\n============\n\nReview of agenda\n\nReview of actions (see below)\n\nReview of dependencies (see below)\n\nReview of pending edits (see below).\n\nMeetings:\n\nNew participants\n\nReview of  recent activity\n****Any questions wrt uploading info to the W3C site\n-New format developments\n-Update on discussions with WAI\n-Review of content activity and items in the pipeline\n\n\nEducation & Outreach\n****Discuss what we should be doing wrt E&O\n\n\nContent discussion\n-Steve's latest submission?\n-Bidi section\n-Brainstorming\n\nAOB\n\n\\================================================\nDetails:\n\n\nCONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\nACTION: RI, apply agreed changes to FTF minutes and publish.\nDONE\n\nACTION: AC to create a list of possibilities for 'non-displayable'\ncharacters\n\nACTION: Lloyd,send a list of deprecated tags in HTML by next meeting \n\nACTION: Russ, follow-up wrt possible new member from Trados\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n\n\n\n\nDEPENDENCIES\n=============\n\nNone.\n\n\n\nEDITS PENDING\n=============\n\nFri 17/01/2003 16:10e, clarify the relationship between 'avoid\nescapes' and 'use hex techniques [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:09e, link to the WAI docs section on language\ndeclarations [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, incorporate guidance related to Character\nModel & Unicode and Markup Languages [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:07e, time & date: improve rules [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:06e, consider when it is appropriate to mention\nsource separation [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:04e, say that fragment identifiers shouldn't be\ntranslated [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, spell out PUA and link to glossary\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, add normalisation info [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, add autoresizing and bidi mirroring info\n[[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\nFri 17/01/2003 16:01edit, mention video\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:59edit, allude to vertical text in the HTML\ntechniques\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:58edit, Add a section on printing issues related\nto paper sizes to the toc. [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:51edit, make the text print smaller [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nThu 16/01/2003 16:32edit, ac 15jan, add stuff on normalisation\n\nThu 16/01/2003 16:30edit, ac 15jan, link to WAI lang stuff\n\nThu 16/01/2003 16:05edit, link to UXML\n\nThu 16/01/2003 14:42edit, standardise spellings\n\nThu 16/01/2003 14:29edit, make 2002 2003\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "RE: Deliverable 12.1.",
            "content": ">> What have you got?? ;-)\n>\n>Well hopes, aspirations that sort of thing ...  :-)\n\n;-)\n\n>Actually, we do have some code from our \"ePerson\" community information\n>management experiment, though that was an intranet kind of thing with no\n>connection to blogging so we might end up reusing some ideas more\n>than the code.\n\nSounds interesting - anything about it online?\n\n>Which library did you end up using?\n\nJGraph. TouchGraph was the other leading contender, but I wanted full-blown\nheavyweight JComponents as graph items, where as TG is more aligned towards\nlightweight drawing. When I was trying to code this stuff myself, the glue\nbetween my graph model and the Swing components started getting really\nugly - eventful spaghetti. JGraph only solves part of the problem, but it's\nthe part that was keeping me awake ;-) Also using a load of other o-s\nlibraries -  Jena, Jython etc. A real boon for functionality, but don't half\nmake for a big package <juvenile snigger/>.\n\n>Good suggestion but probably outside the scope of this particular\n>activity. One\n>challenge I'd see with a 'Jena lite' would be the parser. ARP is\n>very much aimed\n>at quality and full standards conformance rather than 'liteness' -\n>hence the use\n>of Xerces which dwarfs jena.\n\nGood point. It would seem a bit counterproductive to throw the quality away.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "EO Goals document attache",
            "content": "Hello all,\n\nAttached is the long overdue goals document for Education and Outreach. (Richard when you get the chance can you please send me upload instructions for the upload area.)\n\nLooking forward to talking to you later,\n\nSuzanne Topping\nVice President\nBizWonk Inc.\n(Solutions for a Global E-conomy) (TM)\n\nstopping@bizwonk.com\n\n25 N. Washington St.\nRochester, NY 14614-1110\nUSA\n\nPhone: +1 585.454.4210\nFax: +1 585.454.4213 \n\n\n\n\ntext/html attachment: shortLongGoals.htm\n\n\n\n\n"
        },
        {
            "subject": "Re: [i18n] education &amp; outreach initiativ",
            "content": "* Arko, Phil wrote:\n>Many web designers (at least in the US) typically use a site such as\n>WebMonkey.com or Builder.com instead of W3.org. Such sites offer a quick\n>overview (although not always completely accurate) of the most important\n>aspects of a topic. They typically (in my experience) do not look to the\n>entire guideline on the W3 site. Can we think about methods of ensuring that\n>our deliverables are more easily approachable and more usable, so as to make\n>sure that web designers come here first to get the most accurate set of\n>guidelines?\n\nThat's exactly what I thought of when I first heard of I18N GEO, make\nthe authors and developers aware of issues, explain them and provide\nhints how to deal with them. It would be great to have Q&A documents to\npoint at at w3.org. For example, the W3C MarkUp Validator refuses to\nvalidate documents which do not explicitly specify a character encoding.\nMany authors don't understand why this is necessary or how to setup the\nweb server to specify the encoding, it'd be great if I18N GEO would\nprovide sole document dealing with such issues.\n\n\n\n"
        },
        {
            "subject": "Re: [i18n] education &amp; outreach initiativ",
            "content": "I don't know that our documents need to be the sole document, but it would be\na great idea to have tools like the validator provide a link to our documents\nwhen they report an error, such as missing encoding. The error could link\ndirectly to the section on encodings that answer the questions you identify as\nuser needs.\n\nIt's an interesting idea to prioritize having text for errors that are\ndetected by these tools. Would make our web site both valuable and frequently\nreferenced, and that would increase the visibility of other materials we\nproduce.\n\n\ntex\n\n\nBjoern Hoehrmann wrote:\n> \n> * Arko, Phil wrote:\n> >Many web designers (at least in the US) typically use a site such as\n> >WebMonkey.com or Builder.com instead of W3.org. Such sites offer a quick\n> >overview (although not always completely accurate) of the most important\n> >aspects of a topic. They typically (in my experience) do not look to the\n> >entire guideline on the W3 site. Can we think about methods of ensuring that\n> >our deliverables are more easily approachable and more usable, so as to make\n> >sure that web designers come here first to get the most accurate set of\n> >guidelines?\n> \n> That's exactly what I thought of when I first heard of I18N GEO, make\n> the authors and developers aware of issues, explain them and provide\n> hints how to deal with them. It would be great to have Q&A documents to\n> point at at w3.org. For example, the W3C MarkUp Validator refuses to\n> validate documents which do not explicitly specify a character encoding.\n> Many authors don't understand why this is necessary or how to setup the\n> web server to specify the encoding, it'd be great if I18N GEO would\n> provide sole document dealing with such issues.\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: [i18n] education &amp; outreach initiativ",
            "content": "I have also long wanted to look at the validator, add some i18n checks\nif/where needed, and provide useful hints and explanations for warnings\nand errors.  Also HTML Tidy.  This will get a lot of visibility and help\nus make a significant difference.\n\nAdding a Q&A type area to the website also sounds like an interesting\napproach.  For example, I'd like to provide some navigation into the\ncurrent hints & tips that started from some kind of Q&A type format.  (I\nthink Q&A is popular because when using it you are usually hoping to\nfind an answer to a very specific point that you need help with - which\nfits very much into our philosophy so far of identifying and servicing\nthe needs of the community, rather than just producing untargeted\ninformation blindly.)\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Bjoern Hoehrmann\n> Sent: 11 April 2003 04:41\n> To: Arko, Phil\n> Cc: public-i18n-geo@w3.org\n> Subject: Re: [i18n] education & outreach initiative\n> \n> \n> \n> * Arko, Phil wrote:\n> >Many web designers (at least in the US) typically use a site such as \n> >WebMonkey.com or Builder.com instead of W3.org. Such sites offer a \n> >quick overview (although not always completely accurate) of the most \n> >important aspects of a topic. They typically (in my \n> experience) do not \n> >look to the entire guideline on the W3 site. Can we think \n> about methods \n> >of ensuring that our deliverables are more easily \n> approachable and more \n> >usable, so as to make sure that web designers come here first to get \n> >the most accurate set of guidelines?\n> \n> That's exactly what I thought of when I first heard of I18N \n> GEO, make the authors and developers aware of issues, explain \n> them and provide hints how to deal with them. It would be \n> great to have Q&A documents to point at at w3.org. For \n> example, the W3C MarkUp Validator refuses to validate \n> documents which do not explicitly specify a character \n> encoding. Many authors don't understand why this is necessary \n> or how to setup the web server to specify the encoding, it'd \n> be great if I18N GEO would provide sole document dealing with \n> such issues.\n> \n\n\n\n"
        },
        {
            "subject": "Re: [i18n] education &amp; outreach initiativ",
            "content": "At 01:33 03/04/11 -0400, Tex Texin wrote:\n\n>I don't know that our documents need to be the sole document, but it would be\n>a great idea to have tools like the validator provide a link to our documents\n>when they report an error, such as missing encoding. The error could link\n>directly to the section on encodings that answer the questions you identify as\n>user needs.\n\nHello Tex,\n\nI think getting the validator to link should not be too difficult.\nNow we just have to provide the document :-).\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "Re: [i18n] education &amp; outreach initiativ",
            "content": "Martin, agreed and point taken. ;-)\n\ntex\n\nMartin Duerst wrote:\n> \n> At 01:33 03/04/11 -0400, Tex Texin wrote:\n> \n> >I don't know that our documents need to be the sole document, but it would be\n> >a great idea to have tools like the validator provide a link to our documents\n> >when they report an error, such as missing encoding. The error could link\n> >directly to the section on encodings that answer the questions you identify as\n> >user needs.\n> \n> Hello Tex,\n> \n> I think getting the validator to link should not be too difficult.\n> Now we just have to provide the document :-).\n> \n> Regards,    Martin.\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Please Review by Wednesday: Proposed Framework doc for TR publicatio",
            "content": "All,\n\nWe agreed at the Boston FTF mtg recently that we would publish the\nFramework document as a Working Draft to the TR page.  We may have an\nopportunity to publish it on Thursday.  \n\nhttp://www.w3.org/International/geo/framework/\n\nPlease could you read through the document and let me know if you see\nany showstoppers.   The document is not expected to be perfect by\nThursday, since it is a working draft.  I still need to work on the\nstatus section and will run through the pub rules requirements, and will\nbe doing that prior to our Wednesday telecon, where I'd like to discuss\nany significant issues.\n\nCheers,\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03040",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n9 April 2003\n\nPresent: Richard (chair, scribe), Tex, Russ, Andrew, Phil, Martin,\nSuzanne\nRegrets: Steve\n\n\nNew Actions\n============\n\nACTION: RI, set up Phil and Suzanne as Invited Experts\n\nACTION: RI, check on implementation status of OBJECT tag with Steven\n\n\n\nPrior Action Items\n==============\n\nACTION: RI, apply agreed changes to FTF minutes and publish. \nDONE\n\nACTION: AC to create a list of possibilities for 'non-displayable'\ncharacters\nDone but needs posting to list\n\nACTION: Lloyd,send a list of deprecated tags in HTML by next meeting \n\nACTION: Russ, follow-up wrt possible new member from Trados\nDiscussion has taken place - Trados are trying to locate an appropriate\nperson\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion\nDONE \n\n\n\nDependencies\n===========\nNone.\n\n\nReview of recent activity\n===================\n\nWCAG Techniques group asked that we look at the internationalization\nissues surrounding the use of the OBJECT tag in HTML.   Notes from the\ndiscussion:\nBeware of using things like charset or hreflang attributes, if\nappropriate, since they may not be updated if the target entity is\ntext-based and changes.\nNeed to clarify whether we should recommend the use of OBJECT vs. other\ntags like APPLET.\nIf the entity pointed to is text, how does transcoding happen if it is\nneeded?\nWe probably need to address different issues according to the usage of\nthe OBJECT tag.\n\nWCAG is also looking at developing test suites.  There was brief\ndiscussion about whether we should do the same.\n\nTex, Russ and Andrew promised some material for the near future.\n\n\n\n\n\nEducation & Outreach Discussion\n=========================\n\nSuzanne went through the page she sent to the list and we discussed the\nideas and brainstormed additional topics.\n\nNotes follow:\nContributions to university courses:\nPeople might not want to participate because of ownership issues\n& competition\nNeed statement in the proposal that university can benefit from\nthis\nRR would universities see this as too small a niche\nTT need to make the case\nTT a workshop might be useful to solicit information - and\ninvolve people\nflesh out structure with an idea of workshop\nlist contents of such a syllabus\nget people to develop it\n\nRI university courses need a lot of intellectual capital which\nwe don't currently have\nother alternative approaches - eg. Making things available on\nweb like WAI\n\nTT suggests a brokering activity\ncould develop syllabus\nask them what they are trying to accomplish\n\nST look for other opportunities to speak to non i18n people \n\nPA need info on ROI\nneed financials\n\nTT MLC would be willing to post status updates\nMartin wrote an article \n\nTTtouch base with research analysts dealing with i18n\nwe are a resource when they need comments on a topical issue -\nmake the experts available\ncould suggest we do something with the IUC\n\nRI We need a problem statement for the E&O document to indicate\nwhat we want to achieve & help us prioritise\n\n\nPAvisitors to w3c site take too long to find what they wanted\nquick code or checklist would be useful\nalso could be more attractive - w3c is conservative\nthis is a large audience - e-developers\nthis is particularly the case for e-developers\n\nSTinvite other sites to get information from W3C\nPAthese sites accept guest authors\nRIdo want to pull?\n\nPArun a survey past a demographic group\nwhat tools, sites do you use? What do you need?\n\nPA create a community around i18n issues\n\nRRhow do other groups pull these communities together?\nlanguage institute, client side news, i18n gurus\nhow do we make ourselves more successful?\n\nACa lot of people don't want to be subject to an involved process\nthey need to find information quickly\nwe need to make information available\n\nSTso many things to look at these days\n\nMDneed to choose just a couple of things to do\n\nRIWe should also publicise better what we're already doing\ntalks: Unicode, WWW\npapers: Martin's article in Multilingual Computing, Richard's\n(upcoming) in RWS newsletter\nwe could look at providing an RS Feed\nadd things to website news section\n\nperhaps have a new pages/documents section in addition to the\nnew events\npossibly a list of topics under discussion in the mail\nlist/telecons\n\nwe should also announce new documents in MLC\n\nwe should revamp the hints & tips section of the site (and the\nlook & feel of the site itself)\nand raise its visibility\n\nwe could also look for outlets for knowledge in form of short\narticles like the one on charset declarations produced by the\nwebstandards org\nhttp://www.webstandards.org/learn/askw3c/dec2002.html\nother how to pages\n\n\noffer to review articles for people (in return for a mention)\n\n\nNext meeting:\n==========\nSame time, same bridge, next week.\n\n\n\n"
        },
        {
            "subject": "RE: AGENDA: I18N GEO TF telcon, 2003-0416 at 19:00 UTC, 12noon Pacific, 3pm Eastern, 20:00 UK, 5am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n\"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 16 April 2003\nStart    : 19:00 UTC, 20:00 UK, 12noon Pacific, 3pm Eastern, 5am\nAustralia (next\nday!)\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\n*** indicates a topic that will receive particular attention this week\n\n\nDraft agenda\n============\n\nReview of agenda\n\nReview of actions (see below)\n\nReview of dependencies (see below)\n\nMeetings:\n\nNew participants\n\nReview of recent activity\n****Agreement needed for release to TR of Framework Document\nhttp://www.w3.org/International/geo/framework/\nIf agreed by the group, this will be released tomorrow\n\nEducation & Outreach\n****Discuss what we should be doing wrt E&O\n\nContent discussion\n-Steve's latest submission\n-Bidi section\n-Brainstorming\n\nAOB\n\n================================================\nDetails:\n\n\nCONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\nACTION: AC to create a list of possibilities for 'non-displayable'\ncharacters Done but needs posting to list\n\nACTION: Lloyd,send a list of deprecated tags in HTML by next meeting \n\nACTION: Russ, follow-up wrt possible new member from Trados Discussion\nhas taken place\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\n\n\nDEPENDENCIES\n=============\n\nNone.\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03041",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n16 April 2003\n\nPresent: Richard (chair, scribe), Russ, Phil, Martin, Suzanne\nRegrets: Steve, Tex, Andrew, Lloyd, Peter\n\n\nNew Actions\n============\n\nACTION: RI, prepare a first Q&A pair ready for review on 28 april. \n\nACTION: PA, Do some design work with RI's help: link from International\n(& GEO) page, template for list of questions, template for answers that\nwe write ourselves. \n\nACTION: RR, prepare a Q&A pair ready for review on 5 May. \n\nACTION: MD, prepare a first Q&A pair ready for review on 12 May\n\n\n\nPrior Action Items\n==============\n\nACTION: RI, set up Phil and Suzanne as Invited Experts\n\nACTION: AC to create a list of possibilities for 'non-displayable'\nCharacters\n\nACTION: Lloyd, send a list of deprecated tags in HTML by next meeting \n\nACTION: Russ, follow-up wrt possible new member from Trados\nTrados will take a little more time to come back to us\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\n\nDependencies\n===========\nNone.\n\n\nReview of recent activity\n===================\n\nAGREED: The Agreement TR of Framework Document\n[http://www.w3.org/International/geo/framework/] is ready for release to\nthe TR page [http://www.w3.org/TR/].  RI has already prepared a\npublication ready version, and it should hopefully be published tomorrow\nby webreq.\n\n\n\nEducation & Outreach Discussion\n=========================\n\nThe guidelines work, although important and continuing, is progressing\nslowly and it was felt we would like to find a way to start providing\nhelpful, nicely packaged advice to people in the near term and without\ngoing through the full rigour of the guidelines approach.\n\nWe DECIDED to implement a way of providing answers to users' questions\nfrom the http://www.w3.org/International/ site.  These could be any type\nof question relating to web technology (not just HTML&CSS). The answer\ncould be short or long, and could point to existing material or to new\nmaterial developed especially.\n\nWe will start by establishing a clearly visible link on the\nhttp://www.w3.org/International/ page to a question of the week, and to\na (growing) list of previously published questions.  Task force members\nshould take turns to develop questions. \n\nWe decided not to put out a general call for questions on\nwww-international or elsewhere, nor put a form on the site,  because\nRuss's experience with Dr. International would suggest that we'd get\nswamped.  Instead we can identify some questions for ourselves, look at\npast postings on www-international (especially where answers appear),\nuse or point to material we already have in the guidelines or the hints\n& tips section of the web pages, and post here answers to addhoc\nenquiries we receive and have to answer anyway.\n\nWe feel that this will complement our work on guidelines, which will\nproceed as before.  It will provide material for the guidelines, answers\nmay become resources pointed to by the guidelines, and it may help us\ndevelop early drafts of guidelines material for discussion.  The Q&A\nmaterial is focussed on answering a user's specific questions, and the\ntopics will develop in an evolutionary way with minimal attempts to\nguide and structure the contents.  On the other hand, the guidelines\nwill be very structured from the outset, and attempt to help the user\nwho says \"What are all the things I need to know at this point to\nachieve X\".  Initially there will be a single list of questions &\nanswers, but as the number of questions grows some grouping (and\nregrouping) into topics areas will be done.\n\nThe proposed work process is that a member of the group develop a Q&A\npair each week, taking turns.  The material must be published to the\ngroup on a Monday for review.  The contribution will be discussed at the\nWednesday meeting, and published for the following Monday.\n\n\nACTION: RI, prepare a first Q&A pair ready for review on 28 april. \n\nACTION: PA, Do some design work with RI's help: link from International\n(& GEO) page, template for list of questions, template for answers that\nwe write ourselves. \n\nACTION: RR, prepare a Q&A pair ready for review on 5 May. \n\nACTION: MD, prepare a first Q&A pair ready for review on 12 May\n\n. \n\n\nNext meeting:\n==========\nSame time, same bridge, next week.\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "> >Actually, we do have some code from our \"ePerson\" community information\n> >management experiment, though that was an intranet kind of thing with no\n> >connection to blogging so we might end up reusing some ideas more\n> >than the code.\n> \n> Sounds interesting - anything about it online?\n\nThere's a v. brief summary in the application survey that started this thread.\nWe're just finishing off a tech report on it which will be available online (may\nbe short delay while it works through the system though).\n\nDave\n\n\n\n"
        },
        {
            "subject": "Framework Document for i18n Guidelines  publishe",
            "content": "News item: \n\n\nToday the GEO Task Force of the Internationalization Working Group has\nreleased the first Working Draft of its \"Framework Document for i18n\nGuidelines\". \n\nThis describes plans for producing guidelines on internationalization of\nW3C technologies.  The Task Force encourages feedback about the content\nof this document as well as participation in the development of the\nguidelines by people who have experience creating Web content that\nconforms to internationalization needs.\n\nBest regards,\nRichard.\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: Framework Document for i18n Guidelines  publishe",
            "content": "The published document is at http://www.w3.org/TR/i18n-guide-framework/.\n\nCongratulations to the GEO Task Force, keep up your good work.\n\nRegards,   Martin.\n\n\nAt 16:38 03/04/17 +0100, Richard Ishida wrote:\n\n>News item:\n>\n>\n>Today the GEO Task Force of the Internationalization Working Group has\n>released the first Working Draft of its \"Framework Document for i18n\n>Guidelines\".\n>\n>This describes plans for producing guidelines on internationalization of\n>W3C technologies.  The Task Force encourages feedback about the content\n>of this document as well as participation in the development of the\n>guidelines by people who have experience creating Web content that\n>conforms to internationalization needs.\n>\n>Best regards,\n>Richard.\n>\n>\n>============\n>Richard Ishida\n>W3C\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/International/\n>http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Ideas about new Q&amp;A page",
            "content": "Hi Phil,\n\nHere are some of my ideas on how to go about this - open to comment from\nothers!\n\nThe prime technologies used for posting pages on the site include W3C\ntechnologies.  We should probably not try to use server or client based\nscripting or databases for these pages.   We could use XSLT.  I think we\nshould probably just go for hand-crafted pages for now - but build in a\nlot of regularity so we can easily make changes using XSL if needed.\n\nWe should create XHTML in UTF-8 encoding with lang and xml:lang\nattributes in html and meta charset declarations. I think we should try\nto use the XHTML for structural information only (eg. XHTML Strict) -\nall presentation should be applied via an external stylesheet.\n\nI think we need to link to the Question of the Week plus the list of\nquestions so far from both International and geo pages.  Until it grows\na bit we could maybe add a section for current and past questions to\nhttp://www.w3.org/International/resources.html .  (Lets call this the\n'list page' for now, ie. in this email.)\n\nI think the list page should point to small pages we have written and /\nor to pages others have written, and that we should make it clear which\nis which.  One way to do that might be to use different graphics after\nthe end of the question for the different types of target.  I think we\nmay allow multiple links after a single question if there are more than\none good sources of information. It might be good to describe the\ndestination briefly in the title and alt attributes, so you could see it\nif you mouse over.\n\nI am providing some proposed questions here. With links.  We should\ndiscuss this approach at the next meeting.\n\n1. How do I specify the character encoding of a page (the charset)?\nlinks to: http://www.webstandards.org/learn/askw3c/dec2002.html\n(external link)\n\n2. Why does my text collapse spaces between Latin and Arabic/Hebrew\ntext?\nlinks to: attached file\n\n3. How do I specify the language of content in X/HTML and XML?\nlinks to: http://www.w3.org/International/O-HTML-tags\n\n4. Where can I find the ISO language codes?\nlinks to: http://www.loc.gov/standards/iso639-2/langcodes.html\n\n5. Where can I find the list of ISO country codes?\nlinks to:\nhttp://www.iso.org/iso/en/prods-services/iso3166ma/02iso-3166-code-lists\n/list-en1.html\n\n6. Where can I find the IANA charset registry?\nlinks to: http://www.iana.org/assignments/character-sets\n\n7. How do I set up my server to serve pages in the right character\nencoding?\nlinks to: http://www.w3.org/International/O-HTTP-charset\nalso links to: http://www.i18nguy.com/markup/serving.html#tip01\n\n8. How do I set the encoding of a CSS stylesheet?\nlinks to: http://www.i18nguy.com/markup/serving.html#tip02\n\n\nI'm beginning to wonder whether an initial categorization might be along\nthe lines of:\nHow do I ...\nWhere can I find ...\nWhy does ....\n\nWith suitably shortened question text.\n\n\n\nI'm providing some raw grist for a new 'target page' at\nhttp://www.w3.org/International/geo/upload/2003/ri/qa-bidi-space/qa-bidi\n-space.html (the styling is onlyto minimally show the different parts -\ndon't take it as a suggestion!).  It has the potential for a few types\nof information: descriptive text that include examples; test cases;\nadditional links (none in this case) (I really like the way additional\nlinks are handled at\nhttp://www.microsoft.com/globaldev/handson/dev/Mideast.mspx - see the\nright hand side, though we might skip the scripting).\n\nMaybe we need a title for these new pages.  What about something like\n'The I18N WG replies...' ?\n\nFinally (at last!) you should try to ensure that the design conforms to\nWAI accessibility requirements.  You might find this rough and ready\noutline page useful here (my styling stinks!), where I tried to condense\nthe directives from the WCAG 1.0 techniques.\nhttp://www.w3.org/People/Ishida/checklists/wai-html-impl-checklist.html\nJust click on the topic you want to understand... \n\nWell, anyway, those are some initial ideas I had.\n\nRI\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: Arko, Phil [mailto:phil.arko@scr.siemens.com]\n> Sent: 16 April 2003 21:19\n> To: 'ishida@w3.org'\n> Subject: w3.org/international\n> \n> \n> Richard,\n> \n> First question:  What kind of technologies are utilized, or available,\n\n> on the w3.org server?\n> \n> Also, if there is anything else that you think I should know, please \n> refer me accordingly.\n> \n> Many thanks / Vielen Dank,\n> \n> Phil Arko\n> Sr. Human Factors Engineer\n> Siemens Corporate Research\n> User Interface Design Center\n> +1 609-734-3676\n> \n\n\n\n"
        },
        {
            "subject": "RE: Ideas about new Q&amp;A page",
            "content": "I just applied some small corrections to\nhttp://www.w3.org/International/geo/upload/2003/ri/qa-bidi-space/qa-bidi\n-space.html\n\nRI\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-0423 at 19:00 UTC, 12noon Pacific, 3pm Eastern, 20:00 UK, 5am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n\"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 23 April 2003\nStart    : 19:00 UTC, 20:00 UK, 12noon Pacific, 3pm Eastern, 5am\nAustralia (next\nday!)\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\n*** indicates a topic that will receive particular attention this week\n\n\nDraft agenda\n============\n\nReview of agenda\n\nReview of actions (see below)\n\nReview of dependencies (see below)\n\nMeetings:\n\nInfo Share\n****What is this new section about?  Is it useful?\n-Martin & Richard to speak at W3C track of WWW2003 in Budapest in\nMay\n-Article by Martin on I18N Activity in MLC\n-Anyone speaking at LISA in London? \n\nNew participants\n****Trados?\n\nReview of recent activity\n****Framework Document released to TR\nhttp://www.w3.org/TR/i18n-guide-framework/\n\n\nEducation & Outreach\n****Progress on discussions last week\nSee minutes:\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Apr/0017.html\n\n****Discussion about \"Ideas about new Q&A pages\" mail from RI\n\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Apr/0020.html\nWhich questions should we go with?\n\n\n\nContent discussion\n****Brainstorming sections 3 and 4:\nFonts: http://www.w3.org/International/geo/html-tech/#IDAKTCO\nSpecifying the language of content:\nhttp://www.w3.org/International/geo/html-tech/#IDA1TCO\n\nAOB\n\n================================================\nDetails:\n\n\nCONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\nACTION: RI, prepare a first Q&A pair ready for review on 28 april. \n\nACTION: PA, Do some design work with RI's help: link from International\n(& GEO) page, template for list of questions, template for answers that\nwe write ourselves. \n\nACTION: RR, prepare a Q&A pair ready for review on 5 May. \n\nACTION: MD, prepare a first Q&A pair ready for review on 12 May\n\nACTION: RI, set up Phil and Suzanne as Invited Experts\n\nACTION: AC to create a list of possibilities for 'non-displayable'\ncharacters\n\nACTION: Lloyd, send a list of deprecated tags in HTML by next meeting \n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\nDEPENDENCIES\n=============\n\nNone.\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Fwd: Editorial comments on Framework Document   for i18n   Guidelines 1.",
            "content": "FYI.\n\n>Date: Thu, 17 Apr 2003 18:13:23 -0400\n>To: www-i18n-comments@w3.org\n>From: \"A. Vine\" <andrea.vine@Sun.COM> (by way of Martin Duerst \n><duerst@w3.org>)\n>Subject: Editorial comments on Framework Document   for i18n Guidelines 1.0\n>Resent-From: www-i18n-comments@w3.org\n\n\n>All,\n>Just edits.\n>Andrea\n>\n>Whole document\n>---------------\n>\"eg.\" => \"e.g.\"\n>\n>Also, document is part British English and part American English, in \n>spelling and wording.  Is this intentional?\n>\n>------------------------------\n>Titlecase for \"i18n\" is \"I18n\", so \"Framework Document for i18n Guidelines \n>1.0\" should be \"Framework Document for I18n Guidelines 1.0\".  Having said \n>that it is preferable to spell out internationalization.\n>------------------------------\n>\n>1 Introduction\n>------------------------------\n>\" ... has yet to tested against ... \"\n>                 ^be\n>\n>\"It is worth noting that it is not currently expected that the \n>recommendations produced by GEO will be tied in to conformance checking.\" \n>repetition/run-on, maybe remove \"It is worth noting that\"\n>\n>2 Audience & scope\n>------------------------------\n>\"9.  At a later date we may create generalized Guidelines in the WCAG \n>sense, but the initial focus will be to provide technology-specific \n>Techniques.\" - must make a decision about when and why \"guidelines\" and \n>\"techniques\" are capitalized.  In the context of this document, this is \n>the only place where they are capitalized, thus looking out of place.\n>\n>3 Usability\n>------------------------------\n>\"addtional\" => \"additional\"\n>\n>4 General architectural approach\n>------------------------------\n>\"to the rules of the WAI techniques\" - what is WAI?\n>\n>\"w3c\" => \"W3C\"\n>\n>7.1.1 Audience & scope\n>------------------------------\n>\"ie.\" => \"i.e.\"\n>\n>7.1.2 Structure\n>------------------------------\n>\"ie.\" => \"i.e.\"\n\n\n\n"
        },
        {
            "subject": "FW: HTML International Codin",
            "content": "Here is a question and answer we could perhaps add to our Q&A list.\nAnyone disagree?\n\nI'd need to research the XMetal thing if we included it (and be more\nspecific, mentioning that it is version 4).  Anyone know of any other\ntools that allow this, or know more about what XMetal does?\n\n\nRI\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org] \nSent: 29 April 2003 11:37\nTo: 'Askin Charles A. J9C683'\nCc: 'Richard Ishida'\nSubject: RE: HTML International Coding\n\n\nHello,\n\nI just found this languishing in one of my mail folders.  Apologies for\nnot responding sooner!\n\nThe HTML tags are all pre-defined (in English) and must remain that way\nto be recognised by user agents (eg. Browsers).\n\nIn XML it is possible to define your own tag names.  You can do this in\nany language supported by Unicode - though I would caution you to be\ncareful here.  If you yourself had to deal with a tagset in Chinese or\nHindi, this might prove difficult if you don't speak those languages and\nhave the right fonts and rendering software on your system.  English tag\nnames have an advantage in that people from a large number of countries\nare likely to be able to view and understand the meaning of the tags.\n\nI also heard very recently that the XML editor XMetal allows you to\ntemporarily redefine tag names for authors who use other languages - to\nhelp them understand better the semantics - though I've yet to explore\nthis in more detail.\n\nHope that helps,\n\nRichard.\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: Askin Charles A. J9C683 [mailto:Charles.Askin@je.jfcom.mil]\n> Sent: 25 February 2003 16:12\n> To: ishida@w3.org\n> Subject: HTML International Coding\n> \n> \n> Sir,\n> I'm sorry that I will ask this, but my colleagues and I don't\n> know the answer to this and I found your name at \n> http://www.w3.org/International/Activity.html#role .\n> \n> Question:  When someone writes an HTML document for\n> submission on the WWW do they write the tag code (i.e. <html> \n> English) in their native language or do the tags need to be \n> in English.  I realize that the content could be in various \n> languages, but I am curious about within the tags themselves.\n> \n> Any reply would be appreciated.\n> Thank you,\n> Chuck Askin\n> charles.askin@saic.com\n> \n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 12.1.",
            "content": "Also, I just heard about this:\n\n[[\nJust to let you know that we have now a maintained resource with all the\nW3C TR publications:\nhttp://www.w3.org/2002/01/tr-automation/tr.rdf\n]]\n\n#g\n--\n\nAt 11:31 AM 11/6/02 +0000, Graham Klyne wrote:\n\n>There's a bibliography of RFCs, ISO, ITU and a few W3C specs in an XML \n>format at xml.resource.org (site seems down at moment, so can't give \n>definite URL).\n>\n>The XML format used is taken from RFC 2629 [1], and would be easy enough \n>to convert to RDF/foaf++.\n>\n>#g\n>--\n>\n>[1] http://www.ietf.org/rfc/rfc2629.txt\n>\n>\n>At 06:00 PM 11/5/02 +0000, Dave Reynolds wrote:\n>\n>>Dan Brickley wrote:\n>> >\n>> > Agreed. You might also want to edit intro.html in the reports directory to\n>> > point to it, if you've not done that already.\n>>\n>>Done.\n>>\n>> > Regarding bibliographies, I did (for obscure reasons) start collecting up\n>> > the ISBNs of all the books I own. Also scribbled a title/author, but the\n>> > main thing I wanted was isbns; hope is to hook into a lookup-via-isbn web\n>> > service to get richer metadata to autogenerate bibliographic records, and\n>> > provide fodder for collaborative filtering apps. I'm not sure if that kind\n>> > if bibliographic app fits with your plans, have only had time for quickest\n>> > skim of the document today...\n>>\n>>Does sound like a possible fit. It'd certainly be nice to have lots of \n>>ways to\n>>seed a bibliography record and link to several web services to fill in \n>>the known\n>>details and ISBNs is a good example of a useful seed. Collaborative \n>>filtering of\n>>books sounds like possible test case - at least as a thought experiment \n>>to check\n>>how it might be built on top of whatever architecture/tool-set emerges.\n>>\n>>Dave\n>\n>-------------------\n>Graham Klyne\n><GK@NineByNine.org>\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "RE: HTML International Codin",
            "content": "Agreed, Russ \n\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org] \nSent: Tuesday, April 29, 2003 3:47 AM\nTo: public-i18n-geo@w3.org\n\n\nHere is a question and answer we could perhaps add to our Q&A list.\nAnyone disagree?\n\nI'd need to research the XMetal thing if we included it (and be more specific, mentioning that it is version 4).  Anyone know of any other tools that allow this, or know more about what XMetal does?\n\n\nRI\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org]\nSent: 29 April 2003 11:37\nTo: 'Askin Charles A. J9C683'\nCc: 'Richard Ishida'\nSubject: RE: HTML International Coding\n\n\nHello,\n\nI just found this languishing in one of my mail folders.  Apologies for\nnot responding sooner!\n\nThe HTML tags are all pre-defined (in English) and must remain that way\nto be recognised by user agents (eg. Browsers).\n\nIn XML it is possible to define your own tag names.  You can do this in\nany language supported by Unicode - though I would caution you to be\ncareful here.  If you yourself had to deal with a tagset in Chinese or\nHindi, this might prove difficult if you don't speak those languages and\nhave the right fonts and rendering software on your system.  English tag\nnames have an advantage in that people from a large number of countries\nare likely to be able to view and understand the meaning of the tags.\n\nI also heard very recently that the XML editor XMetal allows you to\ntemporarily redefine tag names for authors who use other languages - to\nhelp them understand better the semantics - though I've yet to explore\nthis in more detail.\n\nHope that helps,\n\nRichard.\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: Askin Charles A. J9C683 [mailto:Charles.Askin@je.jfcom.mil]\n> Sent: 25 February 2003 16:12\n> To: ishida@w3.org\n> Subject: HTML International Coding\n> \n> \n> Sir,\n> I'm sorry that I will ask this, but my colleagues and I don't\n> know the answer to this and I found your name at \n> http://www.w3.org/International/Activity.html#role .\n> \n> Question:  When someone writes an HTML document for\n> submission on the WWW do they write the tag code (i.e. <html> \n> English) in their native language or do the tags need to be \n> in English.  I realize that the content could be in various \n> languages, but I am curious about within the tags themselves.\n> \n> Any reply would be appreciated.\n> Thank you,\n> Chuck Askin\n> charles.askin@saic.com\n> \n\n\n\n"
        },
        {
            "subject": "Re: HTML International Codin",
            "content": "For some reason I haven't seen Richard's question yet, just Russ's. We should\ninclude it in q&a.\n\nI think the part about supporting English needs modification to emphasize it\nless.\nThe decision should reflect the audience for the XML and also should take into\naccount it is possible to document the tags.\nThe number of tags is not unlimited so learning the tags is not so\nproblematic. The problem reduces to whether non-speakers are able to type and\ndistinguish and display the tags. (And pronounce perhaps.)\n\nSo we might take the stance, if you were going to use some exotic language for\ntags, here are the things you could do to help non-speakers.\nThen we should turn around and also tell english xml designers, here are the\nsame things you should do for a non-english speaking audience to help them.\n\nWe might also identify some of the non-english characters that are allowed but\na bad idea to use in tags, if tags.\n(I have to check what's allowed, but I have in mind dashes, spaces, etc. that\nmight be especially  confusing)\n\ntex\n\nRuss Rolfe wrote:\n> \n> Agreed, Russ\n> \n> -----Original Message-----\n> From: Richard Ishida [mailto:ishida@w3.org]\n> Sent: Tuesday, April 29, 2003 3:47 AM\n> To: public-i18n-geo@w3.org\n> \n> Here is a question and answer we could perhaps add to our Q&A list.\n> Anyone disagree?\n> \n> I'd need to research the XMetal thing if we included it (and be more specific, mentioning that it is version 4).  Anyone know of any other tools that allow this, or know more about what XMetal does?\n> \n> RI\n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/\n> http://www.w3.org/People/Ishida/\n> \n> -----Original Message-----\n> From: Richard Ishida [mailto:ishida@w3.org]\n> Sent: 29 April 2003 11:37\n> To: 'Askin Charles A. J9C683'\n> Cc: 'Richard Ishida'\n> Subject: RE: HTML International Coding\n> \n> Hello,\n> \n> I just found this languishing in one of my mail folders.  Apologies for\n> not responding sooner!\n> \n> The HTML tags are all pre-defined (in English) and must remain that way\n> to be recognised by user agents (eg. Browsers).\n> \n> In XML it is possible to define your own tag names.  You can do this in\n> any language supported by Unicode - though I would caution you to be\n> careful here.  If you yourself had to deal with a tagset in Chinese or\n> Hindi, this might prove difficult if you don't speak those languages and\n> have the right fonts and rendering software on your system.  English tag\n> names have an advantage in that people from a large number of countries\n> are likely to be able to view and understand the meaning of the tags.\n> \n> I also heard very recently that the XML editor XMetal allows you to\n> temporarily redefine tag names for authors who use other languages - to\n> help them understand better the semantics - though I've yet to explore\n> this in more detail.\n> \n> Hope that helps,\n> \n> Richard.\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/ http://www.w3.org/People/Ishida/\n> \n> > -----Original Message-----\n> > From: Askin Charles A. J9C683 [mailto:Charles.Askin@je.jfcom.mil]\n> > Sent: 25 February 2003 16:12\n> > To: ishida@w3.org\n> > Subject: HTML International Coding\n> >\n> >\n> > Sir,\n> > I'm sorry that I will ask this, but my colleagues and I don't\n> > know the answer to this and I found your name at\n> > http://www.w3.org/International/Activity.html#role .\n> >\n> > Question:  When someone writes an HTML document for\n> > submission on the WWW do they write the tag code (i.e. <html>\n> > English) in their native language or do the tags need to be\n> > in English.  I realize that the content could be in various\n> > languages, but I am curious about within the tags themselves.\n> >\n> > Any reply would be appreciated.\n> > Thank you,\n> > Chuck Askin\n> > charles.askin@saic.com\n> >\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03042",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n23 April 2003\n\nPresent: Richard (chair, scribe), Russ, Lloyd\nRegrets: Phil, Martin, Steve, Tex, Andrew, Suzanne, Peter\n\n\nNew Actions\n============\n\nACTION: Lloyd, prepare a Q&A pair for review on 19 May.\n\n\n\nPrior Action Items\n==============\n\nACTION: RI, prepare a first Q&A pair ready for review on 28 april. \nDONE\n\nACTION: PA, Do some design work with RI's help: link from International\n(& GEO) page, template for list of questions, template for answers that\nwe write ourselves. \nOngoing\n\nACTION: RR, prepare a Q&A pair ready for review on 5 May. \n\nACTION: MD, prepare a first Q&A pair ready for review on 12 May\n\nACTION: RI, set up Phil and Suzanne as Invited Experts\nIn progress - Phil and Suzanne to respond\n\nACTION: AC to create a list of possibilities for 'non-displayable'\ncharacters\n\nACTION: Lloyd, send a list of deprecated tags in HTML by next meeting\nMoved to back burner\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\n\n\nDependencies\n===========\nNone.\n\n\nInfo Share\n========\nRuss and Lloyd thought this would be a useful add to the mtg.  The idea\nis that people can contribute news or informative titbits about events,\ndevelopments, etc that affect our work.  It is information share only -\nif processing is needed we should add an agenda item - although of\ncourse clarification questions are allowed.\n\nThis week's info:\n-Martin & Richard to speak at W3C track of WWW2003 in Budapest in\nMay, outlining progress on activities of the i18n Activity\n-Article by Martin on I18N Activity appeared recently in MLC\n-Richard may be speaking at LISA in London?  Needs to discuss\nwith Mike Anobile.\n\n\nReview of recent activity\n===================\n\nFramework Document [http://www.w3.org/TR/i18n-guide-framework/] was\npublished to the TR page [http://www.w3.org/TR/].  Some helpful\neditorial comments received from Andrea Vine.\n\n\n\nQ&A Review\n=========================\n\nWe reviewed the suggested Q&A items in\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Apr/0020.html\n\nDo we need to ask permission to point to other people's pages?  DECIDED\nwe should probably seek endorsement before use.  We should also be\ncareful to avoid potential bias when pointing to commercial pages.  Note\nthat Dr International usually asks first, and finds it useful because\nthey are often warned of pending changes.\n\nWe agreed that there might be multiple answers for some questions.\n\nWe should probably briefly describe where the reader is going before\nthey click on a link to an answer.  For example, we may say something\nlike: \"for a general view see xxx, for apache servers see more detailed\ninformation yyy\"\n\nWe should distinguish between links to stuff generated by the W3C and\nother stuff, but not on the grounds of 'authoritativeness' - let the\nuser decide what is authoritative.  For example, even if we write stuff\nourselves about apache servers, the only really authority here is the\nApache people.  Icons would probably be a good way to make the\ndistinction.\n\nIt was suggested that we could open a new window for non W3C written\nstuff.\n\nWe reviewed each of the proposed questions in the mailnote and agreed\nthat they were all good candidates.\n\nACTION: Lloyd, prepare a Q&A pair for review on 19 May.\n\n \n\nNext meeting:\n==========\nSame time, same bridge, next week.\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ \nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-0430 at 19:00 UTC, 12noon Pacific, 3pm Eastern, 20:00 UK, 5am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) \nwith conference code 4186 (spells \"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 30 April 2003\nStart    : 19:00 UTC, 20:00 UK, 12noon Pacific, 3pm Eastern, \n5am Australia (next day!)\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\n*** indicates a topic that will receive particular attention this week\n\n\nDraft agenda\n============\n\nReview of agenda\n\nReview of actions (see below)\n\nReview of dependencies (see below)\n\nMeetings:\n\nInfo Share\n**** [Here you can contribute news or informative titbits about\nevents, developments, etc that affect our work.  It is information share\nonly - if processing is needed we should add an agenda item - although\nof course clarification questions are allowed.]\n\nReview of recent activity\n\n\nEducation & Outreach\n****Discussion about \"Ideas about new Q&A pages\" mail from RI\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Apr/0020.html\nWhich questions should we go with?\nAny issues? (see also minutes from last week)\n\n\n\nContent discussion\n****Brainstorming sections 3 and 4:\nFonts: http://www.w3.org/International/geo/html-tech/#IDAKTCO\nSpecifying the language of content:\nhttp://www.w3.org/International/geo/html-tech/#IDA1TCO\n\nAOB\n\n================================================\nDetails:\n\n\nCONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\nACTION: PA, Do some design work with RI's help: link from International\n(& GEO) page, template for list of questions, template for answers that\nwe write ourselves. \n\nACTION: RR, prepare a Q&A pair ready for review on 5 May. \n\nACTION: MD, prepare a first Q&A pair ready for review on 12 May\n\nACTION: Lloyd, prepare a Q&A pair for review on 19 May.\n\nACTION: RI, set up Phil and Suzanne as Invited Experts\n\nACTION: AC to create a list of possibilities for 'non-displayable'\ncharacters\n\nACTION: Lloyd, send a list of deprecated tags in HTML by next meeting\nMoved to back burner\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: send in pointers to existing guidelines \n\n\n\nDEPENDENCIES\n=============\n\nNone.\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: HTML International Codin",
            "content": "Hello Richard,\n\nI think this is an interesting question, but there are many\nmore important questions that we should put out first.\n\nWe should mention the importance of this feature for education.\n\nFor XMetaL, we have to make very clear that it does not change\ntag names, it just presents them differently (I suppose it does\nnot do that for the actual source view).\n\nRegards,    Martin.\n\nAt 11:46 03/04/29 +0100, Richard Ishida wrote:\n\n>Here is a question and answer we could perhaps add to our Q&A list.\n>Anyone disagree?\n>\n>I'd need to research the XMetal thing if we included it (and be more\n>specific, mentioning that it is version 4).  Anyone know of any other\n>tools that allow this, or know more about what XMetal does?\n>\n>\n>RI\n>============\n>Richard Ishida\n>W3C\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/International/\n>http://www.w3.org/People/Ishida/\n>\n>\n>\n>-----Original Message-----\n>From: Richard Ishida [mailto:ishida@w3.org]\n>Sent: 29 April 2003 11:37\n>To: 'Askin Charles A. J9C683'\n>Cc: 'Richard Ishida'\n>Subject: RE: HTML International Coding\n>\n>\n>Hello,\n>\n>I just found this languishing in one of my mail folders.  Apologies for\n>not responding sooner!\n>\n>The HTML tags are all pre-defined (in English) and must remain that way\n>to be recognised by user agents (eg. Browsers).\n>\n>In XML it is possible to define your own tag names.  You can do this in\n>any language supported by Unicode - though I would caution you to be\n>careful here.  If you yourself had to deal with a tagset in Chinese or\n>Hindi, this might prove difficult if you don't speak those languages and\n>have the right fonts and rendering software on your system.  English tag\n>names have an advantage in that people from a large number of countries\n>are likely to be able to view and understand the meaning of the tags.\n>\n>I also heard very recently that the XML editor XMetal allows you to\n>temporarily redefine tag names for authors who use other languages - to\n>help them understand better the semantics - though I've yet to explore\n>this in more detail.\n>\n>Hope that helps,\n>\n>Richard.\n>\n>============\n>Richard Ishida\n>W3C\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/International/ http://www.w3.org/People/Ishida/\n>\n>\n>\n> > -----Original Message-----\n> > From: Askin Charles A. J9C683\n> > Sent: 25 February 2003 16:12\n> > To: ishida@w3.org\n> > Subject: HTML International Coding\n> >\n> >\n> > Sir,\n> > I'm sorry that I will ask this, but my colleagues and I don't\n> > know the answer to this and I found your name at\n> > http://www.w3.org/International/Activity.html#role .\n> >\n> > Question:  When someone writes an HTML document for\n> > submission on the WWW do they write the tag code (i.e. <html>\n> > English) in their native language or do the tags need to be\n> > in English.  I realize that the content could be in various\n> > languages, but I am curious about within the tags themselves.\n> >\n> > Any reply would be appreciated.\n> > Thank you,\n> > Chuck Askin\n\n\n\n"
        },
        {
            "subject": "Regrets for teleconf today (April 30",
            "content": "Dear colleagues,\n\nI'm sorry but I can't attend the teleconference due to a medical\nappointment.\n\nRegards,   Martin.\n\n\n\n"
        },
        {
            "subject": "Re: MINUTES: I18n GEO teleconference 03042",
            "content": "Dear GEO group,\n\nI was in Japan last week, sorry. Some comments below:\n\nAt 07:23 03/04/30 +0100, Richard Ishida wrote:\n\n>MINUTES\n>\n>W3C I18n GEO Phone Conference\n>23 April 2003\n\n>Q&A Review\n>=========================\n\nQ&A is 'question and answer', but it is dangerously close to\nQA, quality assurance. Can we call this FAQ? (frequently\nasked questions)?\n\n\n>We reviewed the suggested Q&A items in\n>http://lists.w3.org/Archives/Public/public-i18n-geo/2003Apr/0020.html\n\n>We agreed that there might be multiple answers for some questions.\n>\n>We should probably briefly describe where the reader is going before\n>they click on a link to an answer.  For example, we may say something\n>like: \"for a general view see xxx, for apache servers see more detailed\n>information yyy\"\n>\n>We should distinguish between links to stuff generated by the W3C and\n>other stuff, but not on the grounds of 'authoritativeness' - let the\n>user decide what is authoritative.  For example, even if we write stuff\n>ourselves about apache servers, the only really authority here is the\n>Apache people.  Icons would probably be a good way to make the\n>distinction.\n\nIcons, the title attribute,... are only secondary things, and they\nhave to be learned/recognized/discovered by users. I think the best\nthing to do is to somehow express the relationship in the text.\nAnother way to do things is to point to our page, and have that\npage point to others with more material.\n\n\n>It was suggested that we could open a new window for non W3C written\n>stuff.\n\nPlease don't do that. It confuses users, and in particular creates\naccessibility problems.\n\n\n>We reviewed each of the proposed questions in the mailnote and agreed\n>that they were all good candidates.\n\nThere are many 'where can I find' questions. Before putting them up,\nit would be good to have some question helping the reader to understand\nwhat these things might be good for. This in particular applies to\nISO language and country codes, which are only used indirectly.\n\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "for comments dealing with currencies, foreign exchange, possible q&amp;",
            "content": "http://www.xencraft.com/resources/multi-currency.html\n\nsome parts are still under development\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "unicode's useful resources pag",
            "content": "this is fyi, \nhttp://www.unicode.org/onlinedat/resources.html\n\nfrom today's wg discussion\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Qs for fa",
            "content": "Or perhaps glossary?\nJust seen definitions requested for these:\n\n?Universally quantified?\n\n(Using the expression \"for all x.\"?)\n\n?existentially quantified?\n\n(Using the expression \"there exists x.\"?)\n\n?Closed world assumption?\n\n(Jos de Roo says:\nhttp://lists.w3.org/Archives/Public/www-rdf-logic/2001Mar/0102.html)\n\nCheers,\nDanny.\n\n\n-----------\nDanny Ayers\n\nSemantic Web Log :\nhttp://www.citnames.com/blog\n\n\n\n"
        },
        {
            "subject": "Bidi background materia",
            "content": "I've been working on some material called 'what you need to know about\nthe Unicode bidirectional algorithm' that we could use eventually as\nbackground material that we point to from the guidelines (which would\nallow us to streamline the guidelines content a lot more).\n\nhttp://people.w3.org/rishida/scripts/bidi/\n\nIt still needs some work, and we probably need to consider styling and\nlocation if we use it.\n\nPlease send any comments to the list.\n\nRI\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "FTF in Atlanta: Please respond asa",
            "content": "To help the planning for the Atlanta FTF, please let me know if you plan\nto attend asap.\n\nThe meeting will be one day only. The main agenda item will be work on\nthe guidelines in order to prepare our first publication to Technical\nReport space.\n\nThanks,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "RE: FTF in Atlanta: Please respond asa",
            "content": "Apologies, I omitted the sentence that said that the FTF will be held on\n6th September - immediately after the Unicode Conference.\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\n> Sent: 05 August 2003 14:22\n> To: 'GEO'\n> Subject: FTF in Atlanta: Please respond asap\n> Importance: High\n> \n> \n> \n> To help the planning for the Atlanta FTF, please let me know \n> if you plan to attend asap.\n> \n> The meeting will be one day only. The main agenda item will \n> be work on the guidelines in order to prepare our first \n> publication to Technical Report space.\n> \n> Thanks,\n> RI\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/People/Ishida/ \n> http://www.w3.org/International/ \n> http://www.w3.org/International/geo/ \n> \n> See the W3C Internationalization FAQ page \n> http://www.w3.org/International/questions.html\n> \n> \n\n\n\n"
        },
        {
            "subject": "Trip report, IST2002 Copenhagen 0406 November 2002 (fwd",
            "content": "Thought this might be interesting for people on the list.\n\nLibby\n\n---------- Forwarded message ----------\nDate: Mon, 11 Nov 2002 21:19:33 +0000 (GMT)\nFrom: Libby Miller <Libby.Miller@bristol.ac.uk>\nTo: ilrt-staff@bristol.ac.uk\nCc: ilrt-mostly@bristol.ac.uk\nSubject: Trip report, IST2002 Copenhagen 04-06 November 2002\n\n\nI had a flying visit to Copenhagen to visit IST2002, which was\nthis years' IST conference[1], where IST is the European Commission's\nInformation Society Technologies Programme [2]. They fund a whole bunch\nof stuff - our SWAD-Europe Semantic Web project [3], but also hard core\nInternet Protocol and switching technology, e-commerce prototypes,\nmobile technologies, electronics, nanotechnology and biotechnology, and\nhealth. Oh, and robots [4].\n\nSWAD-Europe was funded under Framework Programme 5; Framework programme\n6 is launched 15-16th November, and we're looking to participate in one or\nmore projects funded under it. There are big changes this year though.\n\nI attended sessions on FP6, eInclusion, robots, and mobile security\n(which I thought was secure wireless technologies...but I was wrong).\nThere was also an exhibition of European technologies - I've got a\nbooklet describing the stands (for some reason called 'Conference\nexhibition networking guide') which I'll put in the common room in a\nfolder tomorrow.\n\nThose of you who care about accessibility, secure mobility or robots,\nor EC funding over the next 2 years might find the rest of this\ninteresting - otherwise I'd skip it if I were you...although I did find\nout that there is now a wireless network in Brussels airport [5] and I\ntook some photos [6].\n\nAccessibility\n\neInclusion is about accessiblity - there's a horizontal strand in FP6\nabout inclusion of everyone who might be excluded for reasons of class,\ngender, age, disability, race and so on. The previous action line\n'particpation for all' in FP5 have resulted in a policy document about\navoiding information exclusion and also recommended the adoption of the\nW3C's WAI guidelines via a memo and then resolutions. To come are the\npublication of 'design for all' standards, a review of relevant\nlegislation in EC countries, and a network of centres of excellence.\nThe FP6 action plan includes eInclusion in all action lines, and talks\nabout supporting emergence of alternative access platforms. FP6 is all\nabout 'natural and enjoyable access to IST services for all, anywhere,\nanytime' and therefore chimes nicely with accessibility aims.\n\neInclusion will mostly be in the FP6 second call in June 2003.\n\nJudy Brewer of W3C talked about 2 W3C projects, WAI DA (Design for\nall) and WAI TIES (technical implementation and education support) [7].\nWAI DA has already begun, and is about building European\nparticipation, training, WCAG (authoring guidelines) promotion, and a\n'WAI gallery'.\n\nWAI TIES is just beginning. It includes resources for web\nevaluation, training, review teams, and standards harmonization.\n\nThere were some interesting discussions about the business case for\naccessibility by Hartley Millar of Design for all in the DASDA project[8],\nan FP5 accompanying action. The business case seems to be driven mostly\nby legislation (as in the US). Their research suggests that marketing\npeople find it hard to scope the problem of accessibility, and they have\nlack of time to spend on design for all; and if costs rise - even by a\nsmall amount, they probably won't do it.\nThere was also a discussion about smart cards including information\nabout peoples preferences and limitations, that would enable them to\nuse e-services easily and appropriately.\n\nSecure Mobility\nI went to 'secure mobility' thinking it was something about 802.11, but\nit was (in a way) much more interesting - about how to keep things (and\npeople) secure while in transit.\n\nCalum Bunney talked about passenger travel rising very rapidly. The\nairports can't keep up in terms of the physical structures, and so need\nnew processes. Innovations are being driven purely by economics - the\nphysical infrastructure can't deal with projected in increases in\nnumbers of air users. All the things below were in progress before\n9/11.\n\nThe aim is to reduce transaction and inspection times, either by\nidentifying trusted passengers, or by identifying risky passengers.\nThere are some demonstration programmes running already, mostly with\nbusiness travellers, for example the Privium system, at Schipol,\nwhich uses iris recognition and smart card integrated chip passports\n(these are already used in Malaysia, and will be introduced soon in the\nNetherlands).\n\nSmart card passports bring up other possibilities, such as travel\ndocuments, insurance, visa being included, and also passports as ID for\nother ID applications, voting, drivers' licenses.\n\nBiometrics\nOptical memory cards are used in the US, which contain 2D barcodes for\nthe storage of fingerprint info (not always accurate).\nVarious biometrics are being used or considered, for example hand\ngeometry, finger print, iris, face.\nBiometric applications are being used - e.g. UK asylum seekers,\nand passport application issuing in Europe.\n\nProblems\nBiometrics documents are ineffective against basic ID theft - very\nstealable. The cost of kit and training is high; it's not clear what to\nstandardize on; it's difficult to separate false and genuine negatives,\nand it requires lots of uptake to be successful.\nIt's not clear what aspects of biometrics are most trustable.\n\nRobots\n\nThere were lots of robots in the exhibition - many made out of Lego,\nwhich I think is Danish. There was also a series of presentations under\nthe theme 'beyond robotics'. Dario Floreano has been building ant\nrobots, simple individuals which in groups can create complex societies\nand build things. The aim is to create cooperative behaviours with no\noverall coodination.\n\nChris Melhuish (of UWE[9] - I'm going to visit his lab on Wednesday) is\ninterested in intelligent, autonomous systems - 'doing the right thing\nat the right time without human supervision'. He is interested in\nrobots that have their own power - for example solar power, but also\nrobots with artificial stomachs that can 'eat' bacteria.\n\n\nFP6 [10]\nMorten Moller of the EC led a panel on \"Making an IST proposal\" or as he\nwanted to call it \"how to milk a cow\".\nEssentially, FP6 differs form FP5 in that there are new 'instruments' -\nways of getting money off them - which devolve responsibility for\ndistributing money and auditing from the EC to the consortia bidding\nfor money. These are 'Integrated projects' and 'Networks of\nexcellence'. These will be longer, larger, more flexible than before.\n\nIntegrated projects\nIntegrated projects will be three to five or more years, and involve\nmore than 7 participants from 7 countries. Money will be paid as a\ngrant; cost statements will be annual; the distribution of money will\nbe up to the consortium, not the EC. Management will be arduous, and\nwill be funded at 100% for all participants for up to 7% of the total\nfunded. It's anticipated that the coordinating (main) partner will be a\ncompany. It will also be necessary to have a consortium agreement in\nplace at the submission of the proposal. The proposal will cover only\nthe first 18 months in any detail: each year this can be updated with\nthe approval of the commission.\nThere will be no cost categories in FP6 - each company will be able to\nuse its own accounting system.\n\nThey seem to want proposals which involve industry driven research,\ntakeup trials and best practice, with less emphasis on basic or pure\nresearch.\n\nNetworks of Excellence\nNetworks of Excellence are payments for joint, new long-term research\nbetween established research programmes. A network will involve at least\n3 participants and 3 countries, but many will probably be much larger,\nup to several hundred researchers and  5 million euro a year. They will\nbe paid as grants, starting from 20,000 euro per researcher. Like integrated\nprojects there will be a detailed joint programme of activity for 18\nmonths, revised each year, with the consortium distributing the grants.\nThe idea of a network of excellence is to bring together between 8 to 15\nof the best teams in Europe, with 50 to 150 researchers funded per year\nand where the EU funds a small proportion of the total effort; for\ncreating common deliverables, cowriting papers and creating common\nresearch tools (e.g. software).\n\nFP6 calls are over 2 years. The first will be December 17th with a\ndeadline of April; the second will open mid June 2003 and close mid Oct\n2003. About 1/3 of the money will be used to fund 'traditional' funding\ninstruments.\n\nThere are some printouts of slides available - I'll put them in the\ncommon room tomorrow in a file with all the other pamphlets and so on I\ngot and the participant list.\n\nLibby\n\n\n[1] http://2002.istevent.cec.eu.int/\n[2] http://www.cordis.lu/ist/\n[3] http://www.w3.org/2001/sw/Europe/\n[4] http://swordfish.rdfweb.org/photos/2002/11/06/Pages/Image28.html\n[5] http://www.theregister.co.uk/content/59/27964.html\n[6] http://swordfish.rdfweb.org/photos/2002/11/06/\n[7] http://w3.org/WAI, http://w3.org/Resources\n[8] http://www.cordis.lu/ist/ka1/special_needs/home.html,\nhttp://www.designforall.info\n[9] http://www.ias.uwe.ac.uk/\n[10] http://www.cordis.lu/ist/fp6/fp6.htm\n\n\n\n"
        },
        {
            "subject": "Re: FTF in Atlanta: Please respond asa",
            "content": "> > To help the planning for the Atlanta FTF, please let me know if you plan to attend asap.\n\nI don't plan to attend asap. I plan to attend Sept. 6. ;-)\n\ntex\n\n\nRichard Ishida wrote:\n> \n> Apologies, I omitted the sentence that said that the FTF will be held on\n> 6th September - immediately after the Unicode Conference.\n\n> >\n> >\n> > To help the planning for the Atlanta FTF, please let me know\n> > if you plan to attend asap.\n> >\n> > The meeting will be one day only. The main agenda item will\n> > be work on the guidelines in order to prepare our first\n> > publication to Technical Report space.\n> >\n> > Thanks,\n> > RI\n> >\n\n\n\n"
        },
        {
            "subject": "a new darft of the css selectors q",
            "content": "Question\n\nHow do I apply different styles using CSS for different languages in a \nmultilingual document?\n\n\nAnswer:\n\nThere are four ways to apply differnet styles to different languages in \na multlingual documents:\n\n1) a class or id selector\n2) the :lang() psuedo-class selector\n3) a selector that matches the value of an attribute\n4) a selector that matches the beginning of a value of an attribute\n\nAlthough CSS2 provides language specific selectors, these selectors are \nnot widely supported by web browsers. It is necessary to use more \ngeneric CSS selectors for applying different styles for different \nlanguages within a XHTML/HTML document.\n\nPresentation styles are commonly used to control chages in fonts, font \nsizes and line heights when language changes occur in the document.\n\n<h3>Generic selectors</h3>\nNNav, Moz, IE, Opera, others\n\nThe most efficient method is to use a CSS class or id selector. For \nexample, the sentence \"The Nuer language is called Thok Nath\" could be \nmarked up as:\n\n<p>The Nuer language is <span lang=\"ssa\" xml:lang=\"ssa\" \nclass=\"nuer\">Thok Nath</span></p>\n\nAnd a class .nuer could be defined in the stylesheet as\n\n.nuer {font-style: italic; font-weight: bold;} or alternatively, as\n\nspan.nuer {font-style: italic; font-weight: bold;}\n\nLikewise, the html segment:\n\n<div xml:lang=\"en\" lang=\"en\" dir=\"ltr\" class=\"pan\">\n<p>It is polite to welcome people in their own language:</p>\n<ul>\n<li xml:lang=\"zh-CN\" lang=\"zh-CN\" class=\"zhs\">??????</li>\n<li xml:lang=\"zh-TW\" lang=\"zh-CN\" class=\"zht\">??????</li>\n<li xml:lang=\"el\" lang=\"el\">????????????????????????</li>\n<li xml:lang=\"ar\" lang=\"ar\" dir=\"rtl\" class=\"ar\">???????? ??????????</li>\n<li xml:lang=\"ru\" lang=\"ru\">?????????? ????????????????????</li>\n</ul>\n</div>\n\ncould have the following markup,\n\nli {list-style-type: none; line-height: 1.5em;}\n.pan {font-family: \"Times New Roman\"; }\n.ar {font-size: 1.2em; text-align: left;}\n.zht {font-family: PMingLiU,MingLiU;}\n.zhs {font-family: SimSum-18030;SimHei;}\n\n\n<h3>The :lang() psuedo-class selector</h3>\nMoz\n\nFor those interested, CSS2 provides the language psuedo-class selector \n:lang() and language attribute selectors to allow XHTML/HTML document \nauthors to specify rules for langauge specific presentation..\n\nThe :lang() psuedo-class selector allows authors to specify rules that \nmatch languages. I could markup the sentence \"The Nuer refer to \nthemselves as Naath\" as\n\n<p xml:lang=\"en-AU\" lang=\"en-AU\">The Nuer refer to themselves as <span \nxml:lang=\"ssa\" lang=\"ssa\">Naath</span></p>\n\nIn order to display the English text in blue and the Nuer text in green, \nthe following rules could be used:\n\n:lang(en-AU) {font-style: normal;}\n:lang(ssa) {font-style: italic;}\n\nThe selector :lang(en-AU) will only match elements that have a language \nvalue of  ???en-AU??? or have inherited that language value. If the css rule \nspecified :lang(en-US), the rule would not match our sample paragraph.\n\nAlternatively, we could make the language designation more general and \nuse the following rules:\n\n:lang(en) {font-style: normal;}\n:lang(ssa) {font-style: italic;}\n\nThe rule for :lang(en) would math elements with a language value of \n???en???. It would also amtch more specific language specifications such as \nen-US and en-NZ.\n\n<h3>A selector that matches the value of an attribute</h3>\nOpera\n\nThe second method of specifying rules is to use attribute selectors. If \nI markup ???Ye???? loi rot Aboja??? as\n\n<p xml:lang=\"din\" lang=\"din\">Ye???? loi rot Aboja</p>\n\nI could write a rule matching the language attribute.\n\n*[lang=\"din\"] {font-family: \"Doulos SIL\";} This rule will match all \nelements that have a language attribute equal to ???din???.\n\nIf the XHTML/HTML markup was\n\n<div xml:lang=\"en\" lang=\"en\">\n<p>The first line was <span xml:lang=\"din\" lang=\"din\">Ye???? loi rot \nAboja</span></p>\n</div>\n\nand I had two rules\n\np[lang=\"en\"] {font-style: normal;}\n*[lang=\"din\"] {font-family: \"Doulos SIL\"; font-style: italic;}\n\nOnly the second rule would match. The paragraph has no language \nattribute to match.\n\n<h3>A selector that matches the beginning of a value of an attribute</h3>\nOpera\n\nThere is a significant difference between [lang=\"en\"] and [lang|=\"en\"]. \nThe first language selector will only match elements with a language \nattribute equal to ???en???, while the second selector will match any \nelement with a language attribute starting with ???en???. Therefore the \nsecond selector would match ???en-US???, ???en-HK??? or ???en-CA???.\n\nUsing an earlier example:\n\n<div xml:lang=\"en-NZ\" lang=\"en-NZ\" dir=\"ltr\">\n<p>It is polite to welcome people in their own language:</p>\n<ul>\n<li xml:lang=\"zh-CN\" lang=\"zh-CN\">??????</li>\n<li xml:lang=\"zh-TW\" lang=\"zh-CN\">??????</li>\n<li xml:lang=\"el\" lang=\"el\">????????????????????????</li>\n<li xml:lang=\"ar\" lang=\"ar\" dir=\"rtl\">???????? ??????????</li>\n<li xml:lang=\"ru\" lang=\"ru\">?????????? ????????????????????</li>\n</ul>\n</div>\n\nThe style sheet could be written as:\n\nli {list-style-type: none;  line-height: 1.5em;}\n*[lang|=\"en\"] {font-family: \"Times New Roman\";}\n*[lang|=\"el\"] {font-family: \"Times New Roman\";}\n*[lang|=\"ru\"] {font-family: \"Times New Roman\";}\n*[lang|=\"ar\"] {font-family: \"Simplified Arabic\"; font-size: 1.2em;}\nli[lang|=\"ar\"] {text-align: left;}\n*[lang=\"zh-TW\"] {font-family: PMingLiU,MingLiU;}\n*[lang=\"zh-CN\"] {font-family: SimSum-18030;SimHei;}\n\nThe selectors for Chinese use specific values, and will only match to \nthe indicated values, while the other language attribute selectors are \nmore generic. For instance [lang|=\"en\"] will sucessfully match ???en-NZ???.\n\nIt is important to note that not all web browsers can use language \nselectors and it is best to use more generic selectors in your CSS rules.\n\n\nBy the way\n\nI have used the ISO-639-2 language code ???ssa??? for Nuer. Nuer doesn't \nhave a unique ISO-639-2 language code. This is the code for a group of \nlanguages: Nilo-Saharan (Other). Seven Nilo-Saharan languages have \nunique ISO-639-2 codes, while approximately 178 languages share the \ngeneric ???ssa??? language code. The Ethnologue lists the languages at \nhttp://www.ethnologue.com/show_iso639.asp?code=ssa.\n\nI have used the language codes ???zh-TW??? and ???zh-CN???. These language codes \ndo not represent specific languages. ???zh-TW??? would indicate Chinese \nspoken in Taiwan, although there are more than one Chinese language \nspoken in Taiwan. Similarly ???zh-CN??? represents Chinese spoken in China \n(PRC). This could refer to Mandarin or any other Chinese language.\n\nMore often ???zh-CN??? and ???zh-TW??? are used to indicate Chinese languages \nwritten in the simplified script (???zh-CN???) or the traditional script \n(???zh-TW???).\n\nSome of the modern web browsers will use the presence of the language \ntags ???zh-CN??? and ???zh-TW??? to select the default fonts to display the text \nwhen the web page designer does not indicate a font.\n\nIf you need to use language tags to differentiate between Chinese \nlanguages, the IANA language code registry has more precise langauge \ncodes for a range of Chinese languages.\n\nUseful links\nThe language pseudo-class: :lang\nhttp://www.w3.org/TR/REC-CSS2/selector.html#lang\n\nAttribute selectors\nhttp://www.w3.org/TR/REC-CSS2/selector.html#attribute-selectors\n\nClass selectors\nhttp://www.w3.org/TR/REC-CSS2/selector.html#class-html\n\nID selectors\nhttp://www.w3.org/TR/REC-CSS2/selector.html#id-selectors\n\n\n-- \nAndrew Cunningham\nMultilingual Technical Officer\nOnline Projects Team, Vicnet\nState Library of Victoria\n328 Swanston Street\nMelbourne  VIC  3000\nAustralia\n\nandrewc@vicnet.net.au\n\nPh. +61-3-8664-7430\nFax: +61-3-9639-2175\n\nhttp://www.openroad.net.au/\nhttp://www.libraries.vic.gov.au/\nhttp://www.vicnet.net.au/\n\n\n\n"
        },
        {
            "subject": "RTL language",
            "content": "OK, I am ready for another round of abuse. The next draft of the Q&A for\n\"which languages are RTL?\" is here:\n\nhttp://www.i18nguy.com/temp/W3C%20I18N%20Q&A%20Which%20languages%20are%20right-to-left.html\n\nI would be glad for your comments, and in particular your review of the\nlanguages and scripts listed, and suggestions for others.\n\nNote reference to \"bidi\" is removed!\n\ntex\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: RTL language",
            "content": "Hi Tex,\n\nSome notes from a quick first read...\n\n[1] A lot of the expected readers of this Q&A are content authors who\nare struggling to learn about internationalization of web technology.\nApart from the fact that they're unlikely to come across an example of\nit, I think listing languages like Hindi under Arabic script with no\nqualification is likely to create confusion for the (non-script guru)\nreaders of this page - particularly as you don't mention it in the\nsection \"Languages that are not right-to-left\" -   This applies for\nother languages cited too.\n\n[2] Indonesian/Jawi needs some attention.  As I understand it, Jawi is\nanother name for the old 'Malay' script based on the Arabic script which\nwas used to write the Malay language. Indonesian is a (fairly recent)\nderivation of Malay language.  Today, however, Malay and Indonesian\npretty much use Latin script (indeed only ASCII characters).  So I think\nthis is incorrect, but also I think it is misleading/confusing for the\naverage reader of this page without further qualification.\n\n[3] \"Languages that are not right-to-left\" -> \"Languages written in\nscripts that are not right-to-left \".  Also I think a lot of expected\nreaders will find it useful these days if you include indic scripts\nhere.  'Thai' could be commuted to 'South-East Asian'.  You could add\nGeorgian and Armenian, if you like.\n\n[4] \"In actual fact, they are written vertically top-to-bottom in\nlengths of a single character, and therefore appear to be written as\nright-to-left.)\"  -- as I said before this is not necessarily the case.\nI have a Taiwanese newspaper here that does RTL text that is not a\nsingle character deep. (See the attachment - esp the caption of the\nphoto to the left.)  (Note also that this is bidirectional text - see\n8.6% - which has the % on the right, unlike Arabic/Hebrew.)\n\n[5] Please try to describe what's useful to the reader in this context\nbehind links such as Omniglot, Rosetta Project, etc.\n\nHope that helps,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> Sent: 06 August 2003 09:26\n> To: qalam@yahoogroups.com; GEO\n> Subject: RTL languages\n> \n> \n> \n> OK, I am ready for another round of abuse. The next draft of \n> the Q&A for \"which languages are RTL?\" is here:\n> \n> http://www.i18nguy.com/temp/W3C%20I18N%20Q&A%20Which%20languag\nes%20are%20right-to-left.html\n\nI would be glad for your comments, and in particular your review of the\nlanguages and scripts listed, and suggestions for others.\n\nNote reference to \"bidi\" is removed!\n\ntex\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "First test suite pag",
            "content": "Chaps,\n\nI have been working on a test page for css language selectors for a week\nor so, and since Andrew's Q&A is scheduled for this evening thought I'd\nbetter finish and publish it.\n\nSee http://www.w3.org/International/tests/test-css-lang.html\n\nI'd like to discuss this and the possibility of us working on other such\npages this evening.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Re: First test suite pag",
            "content": "* Richard Ishida wrote:\n>I have been working on a test page for css language selectors for a week\n>or so, and since Andrew's Q&A is scheduled for this evening thought I'd\n>better finish and publish it.\n\nHmm, why are the existing tests for :lang and attribute selectors in the\nSelectors test suite (<http://www.w3.org/Style/CSS/Test/>) insufficient?\n\n>See http://www.w3.org/International/tests/test-css-lang.html\n>\n>I'd like to discuss this and the possibility of us working on other such\n>pages this evening.\n\nThere is some documentation and guidelines for CSS tests, see \n\n  http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html\n  http://www.w3.org/Style/CSS/Test/guidelines.html\n\nregards.\n\n\n\n"
        },
        {
            "subject": "Re: css lang() selecto",
            "content": "* Andrew Cunningham wrote:\n>I've been playing around with the CSS :lang() selector on Mozilla \n>(Windows). The current versions support the :lang() selector when the \n>XHTML 1.0/HTML lang attribute is used. On the version of Mozilla I'm \n>using (1.4), the :lang() selector does not work when only the xml:lang \n>attribute is used (i.e. in XHTML 1.1).\n\nAre you sure you are not running into MIME Type issues (i.e., your\ndocument is delivered as text/html and not application/xhtml+xml)?\nFor example,\n\n  http://www.bjoernsworld.de/temp/xml-lang.xhtml\n\nBoth paragraphs are green using Mozilla 1.3a.\n\n\n\n"
        },
        {
            "subject": "RE: First test suite pag",
            "content": "Hi Bjoern,\n\nThe current test is fairly limited.  Thanks for the pointer to the\ndocumentation.  I spoke with Bert Bos earlier about possibility of\ndeveloping our stuff in a way that would make it embeddable in the CSS\ntests.  I'll also talk with the HTML guys - I think they could do with\nsome more detailed bidi tests, for example.  \n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: Bjoern Hoehrmann [mailto:derhoermi@gmx.net] \n> Sent: 06 August 2003 14:45\n> To: ishida@w3.org\n> Cc: 'GEO'\n> Subject: Re: First test suite page\n> \n> \n> * Richard Ishida wrote:\n> >I have been working on a test page for css language selectors for a \n> >week or so, and since Andrew's Q&A is scheduled for this evening \n> >thought I'd better finish and publish it.\n> \n> Hmm, why are the existing tests for :lang and attribute \n> selectors in the Selectors test suite \n(<http://www.w3.org/Style/CSS/Test/>) insufficient?\n\n>See http://www.w3.org/International/tests/test-css-lang.html\n>\n>I'd like to discuss this and the possibility of us working on other \n>such pages this evening.\n\nThere is some documentation and guidelines for CSS tests, see \n\n  http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html\n  http://www.w3.org/Style/CSS/Test/guidelines.html\n\nregards.\n\n\n\n"
        },
        {
            "subject": "Re: RTL language",
            "content": "Richard Ishida wrote:\n> \n> Hi Tex,\n> \n> Some notes from a quick first read...\n> \n> [1] A lot of the expected readers of this Q&A are content authors who\n> are struggling to learn about internationalization of web technology.\n> Apart from the fact that they're unlikely to come across an example of\n> it, I think listing languages like Hindi under Arabic script with no\n> qualification is likely to create confusion for the (non-script guru)\n> readers of this page - particularly as you don't mention it in the\n> section \"Languages that are not right-to-left\" -   This applies for\n> other languages cited too.\n\nI removed Hindi. I don't know which other languages you think are problematic.\nI don't know all of the scripts languages are listed in, nor the probability\nof one or another script being used.\n\n> \n> [2] Indonesian/Jawi needs some attention.  As I understand it, Jawi is\n> another name for the old 'Malay' script based on the Arabic script which\n> was used to write the Malay language. Indonesian is a (fairly recent)\n> derivation of Malay language.  Today, however, Malay and Indonesian\n> pretty much use Latin script (indeed only ASCII characters).  So I think\n> this is incorrect, but also I think it is misleading/confusing for the\n> average reader of this page without further qualification.\n\nremoved.\n> \n> [3] \"Languages that are not right-to-left\" -> \"Languages written in\n> scripts that are not right-to-left \".  Also I think a lot of expected\n> readers will find it useful these days if you include indic scripts\n> here.  'Thai' could be commuted to 'South-East Asian'.  You could add\n> Georgian and Armenian, if you like.\n\ndone.\n> \n> [4] \"In actual fact, they are written vertically top-to-bottom in\n> lengths of a single character, and therefore appear to be written as\n> right-to-left.)\"  -- as I said before this is not necessarily the case.\n> I have a Taiwanese newspaper here that does RTL text that is not a\n> single character deep. (See the attachment - esp the caption of the\n> photo to the left.)  (Note also that this is bidirectional text - see\n> 8.6% - which has the % on the right, unlike Arabic/Hebrew.)\n\nI thought you were the one that had me add the one char deep. oh well.\nremoved.\n\n> [5] Please try to describe what's useful to the reader in this context\n> behind links such as Omniglot, Rosetta Project, etc.\n\nnot this week. I think it's obvious if you go there, but if you don't think\nits clear enough, the we can delete the links.\n> \n> Hope that helps,\n> RI\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/People/Ishida/\n> http://www.w3.org/International/\n> http://www.w3.org/International/geo/\n> \n> See the W3C Internationalization FAQ page\n> http://www.w3.org/International/questions.html\n> \n> > -----Original Message-----\n> > From: public-i18n-geo-request@w3.org\n> > [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> > Sent: 06 August 2003 09:26\n> > To: qalam@yahoogroups.com; GEO\n> > Subject: RTL languages\n> >\n> >\n> >\n> > OK, I am ready for another round of abuse. The next draft of\n> > the Q&A for \"which languages are RTL?\" is here:\n> >\n> > http://www.i18nguy.com/temp/W3C%20I18N%20Q&A%20Which%20languag\n> es%20are%20right-to-left.html\n> \n> I would be glad for your comments, and in particular your review of the\n> languages and scripts listed, and suggestions for others.\n> \n> Note reference to \"bidi\" is removed!\n> \n> tex\n> \n> --\n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n> \n> XenCraft                            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n> \n>   ------------------------------------------------------------------------------\n>                        Name: chinese-bidi.jpg\n>    chinese-bidi.jpg    Type: JPEG Image (image/jpeg)\n>                    Encoding: base64\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: RTL language",
            "content": "thanks for everyone's comments.\nChanges are posted.\nhttp://www.i18nguy.com/temp/W3C%20I18N%20Q&A%20Which%20languages%20are%20right-to-left.html\n\nMarco Cimarosti wrote:\n> \n> Tex Texin wrote:\n> > OK, I am ready for another round of abuse. The next draft of\n> > the Q&A for\n> > \"which languages are RTL?\" is here:\n> >\n> > http://www.i18nguy.com/temp/W3C%20I18N%20Q&A%20Which%20languag\n> > es%20are%20right-to-left.html\n> >\n> > I would be glad for your comments, and in particular your\n> > review of the\n> > languages and scripts listed, and suggestions for others.\n> >\n> > Note reference to \"bidi\" is removed!\n> \n> In addition to what Richard already said:\n> \n> - \"Classical Syriac\", \"Modern Syriac\" and \"Syriac\" are all one and the same\n> script, by the point of view of information technology. I suspect which a\n> pair of these can be seen as the same script also by the point of view of\n> grammatology.\n\nok, merged\n\n> \n> - AFAIK, \"Indonesian\" is not a script. Have you perhaps swapped the Script\n> and Language columns on this row?\n\nremoved. Came from elsewhere.\n> \n> - AFAIK, there is no computer character set for N'ko. Therefore, it is\n> unlikely that a designer is asked to design a page in this language.\n\nok. I'll leave it in for kicks.\n\n> \n> - The South Arabian script is extinct, as probably are the languages which\n> where written with it: Hadhramautic, Himyaritic, Qatabanic, and Sabaic. I am\n> quite confident that Sabaic is extinct.\n\nremoved.\n\n> - Ladino/Judezmo is most often written in the Latin alphabet, especially on\n> a web page. Consider that the biggest Ladino communities are in Turkey and\n> in the two Americas, where the Latin script is normally used. I don't know\n> whether Ladinos in Israel also use the Hebrew script, but I have seen many\n> Israeli pages about folklore where Ladino songs where only in Latin scripts.\n\nok. I added a note at the top of the table. I may remove Ladino, or I may do\nsomething further with identifying languages that use multiple scripts.\n> \n> - The term \"Ideographic languages\" suffers of about the same problems as the\n> term \"bidi languages\". Perhaps even more, as the term \"ideograph(ic)\" per se\n> is debatable. A better term is \"CJK languages (Chinese, Japanese, Korean)\",\n> which is quite likely to be familiar to anyone involved in\n> internationalization.\n\nThe paragraph uses both. I see Ideographic used quite a bit.\n\n> \n> But you should perhaps add information for *all* the script in Unicode and\n> the main languages written with them. It may be less than obvious that, say,\n> Marathi is written in the Devanagari script, and that Devanagari is written\n> LTR.\n\nhmmm, yes. When I get more time. I actually started out that way.\n\n> \n> <SUGGESTION value=$0.02>\n\nIt's a good one, but I can't pursue it now.\nI will continue to accept suggestions as to which languages and scripts should\nbe added.\n\n> \n> If you want to give comprehensive information, it'd perhaps be better to\n> rearrange completely the information in two separate tables, the first one\n> mapping languages to script(s), and the second one mapping scripts to\n> directionality:\n> \n> Languages table:\n> \n>         Language:       Script(s):      Notes:\n>         ...             ...             ...\n>         Croatian        Latin           Cmp. Serbian\n>         ...             ...             ...\n>         Ladino  Latin, Hebrew   Also known as \"Judezmo\" or \"Judeo-Spanish\"\n>         ...             ...             ...\n>         Serbian Cyrillic, Latin Cmp. Croatian\n>         ...             ...             ...\n> \n> Scripts table:\n> \n>         Script: Dir:    Notes:\n>         ...     ...     ...\n>         Cyrillic        LTR\n>         ...     ...     ...\n>         Hebrew  RTL\n>         ...     ...     ...\n>         Latin   LTR     Also known as \"Roman\"\n>         ...     ...     ...\n> \n> A first draft selection of languages for table 1 could all the languages\n> having a two-letter code in ISO 639\n> (http://lcweb.loc.gov/standards/iso639-2/englangn.html). Note that, e.g.,\n> Ladino would not be included.\n> \n> Finding out which script(s) are used for each languages could be an\n> interesting trivia game for the members of this mailing list. :-)\n> \n> </SUGGESTION>\n> \n> _ Marco\n> \n> ------------------------ Yahoo! Groups Sponsor ---------------------~-->\n> Buy Ink Cartridges or Refill Kits for Your HP, Epson, Canon or Lexmark\n> Printer at Myinks.com. Free s/h on orders $50 or more to the US & Canada. http://www.c1tracking.com/l.asp?cid=5511\n> http://us.click.yahoo.com/l.m7sD/LIdGAA/qnsNAA/GP4qlB/TM\n> ---------------------------------------------------------------------~->\n> \n> www.egroups.com/group/qalam - world's writing systems.\n> To unsubscribe: qalam-unsubscribe@egroups.com\n> \n> Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: RTL language",
            "content": "Marco, thanks. I will be glad to accept it, and will credit you on the page.\n\n(If only to protect people at parties from being surprised by you! ;-) )\ntex\n\nMarco Cimarosti wrote:\n> \n> Tex Texin wrote:\n> > > <SUGGESTION value=$0.02>\n> >\n> > It's a good one, but I can't pursue it now.\n> > I will continue to accept suggestions as to which languages\n> > and scripts should be added.\n> \n> So, with your permission, I started out this one myself. When it's finished,\n> you may see if you want to accept it as my contribution to your site, or\n> else I'll keep it for surprising people at parties with fun facts on\n> languages and writings.\n> \n> But I lack (at least) some knowledge to finish it, so here is the trivia for\n> the Qalam people:\n> \n> Which scripts are used to write the following languages?\n> \n>         Abkhaz\n>         Bashkir\n>         Bihari\n>         Chuang (aka Zhuang)\n>         Chuvash\n>         Ganda\n>         Herero\n>         Kanuri\n>         Komi\n>         Kwanyama (aka Kuanyama)\n>         Luba-Katanga\n>         Ndonga\n>         North Ndebele\n>         Ossetic\n>         Pali\n>         Sango\n>         South Ndebele\n>         Sundanese\n>         Tsonga\n>         Venda\n> \n> And which languages are (or were) written with the following scripts?\n> \n>         Buhid\n>         Hanun?o\n>         Tagbanwa\n> \n> _ Marco\n> \n> ------------------------ Yahoo! Groups Sponsor ---------------------~-->\n> Buy Ink Cartridges or Refill Kits for Your HP, Epson, Canon or Lexmark\n> Printer at Myinks.com. Free s/h on orders $50 or more to the US & Canada. http://www.c1tracking.com/l.asp?cid=5511\n> http://us.click.yahoo.com/l.m7sD/LIdGAA/qnsNAA/GP4qlB/TM\n> ---------------------------------------------------------------------~->\n> \n> www.egroups.com/group/qalam - world's writing systems.\n> To unsubscribe: qalam-unsubscribe@egroups.com\n> \n> Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "New version of Q&amp;A: CSS and lan",
            "content": "After discussion with Andrew, I have posted a version of his Q&A at\nhttp://www.w3.org/International/questions/qa-css-lang.html\n\nLet's discuss any remaining points this evening.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "New Q&amp;A: two-letter or threeletter language code",
            "content": "Richard reminded me yesterday that a new Q&A had been due from me on\nMonday. I just managed to finish it, at\nhttp://www.w3.org/International/questions/qa-lang-2or3.html.\n\nOne specific question: Should we say 'language codes', 'language tags',\nor something else, such as 'language identifiers'?\n[HTML 4 (http://www.w3.org/TR/REC-html40/types.html#h-6.8) uses 'language\ncodes', XML (http://www.w3.org/TR/REC-xml#sec-lang-tag) uses 'language\nidentifiers' for the whole thing, but 'codes' for the pieces (language,\ncountry,...), RFC 3066 (as well as 1766) use 'language tags' for overall,\nand 'code' for the pieces, the 'hints and tips' page\n(http://www.w3.org/International/O-HTML-tags.html) uses 'codes' throughout\nexcept for the title :-(]\n\nOther comments welcome.    Regards,    Martin.\n\n\n\n"
        },
        {
            "subject": "RE: FTF in Atlanta: Please respond asa",
            "content": "Richard,\n \nCurrently I plan to be there.\n \nRegards, Russ\n\n________________________________\n\nFrom: public-i18n-geo-request@w3.org on behalf of Richard Ishida\nSent: Tue 8/5/2003 7:31 AM\nTo: 'GEO'\nSubject: RE: FTF in Atlanta: Please respond asap\n\n\n\n\nApologies, I omitted the sentence that said that the FTF will be held on\n6th September - immediately after the Unicode Conference.\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/\nhttp://www.w3.org/International/\nhttp://www.w3.org/International/geo/\n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org\n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\n> Sent: 05 August 2003 14:22\n> To: 'GEO'\n> Subject: FTF in Atlanta: Please respond asap\n> Importance: High\n>\n>\n>\n> To help the planning for the Atlanta FTF, please let me know\n> if you plan to attend asap.\n>\n> The meeting will be one day only. The main agenda item will\n> be work on the guidelines in order to prepare our first\n> publication to Technical Report space.\n>\n> Thanks,\n> RI\n>\n> ============\n> Richard Ishida\n> W3C\n>\n> tel: +44 1753 480 292\n> http://www.w3.org/People/Ishida/\n> http://www.w3.org/International/\n> http://www.w3.org/International/geo/\n>\n> See the W3C Internationalization FAQ page\n> http://www.w3.org/International/questions.html\n>\n>\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-0806 at 19:00 UTC, 12noon Pacific, 3pm Eastern, 20:00 UK, 5am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 6 August 2003\nStart    : 19:00 UTC, 20:00 UK, 12noon Pacific, 3pm Eastern, \n  5am Australia (next day!)\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) \nwith conference code 4186 (spells \"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\n*** indicates a topic that will receive particular attention this week\n\n\n\n\nDraft agenda\n============\n\nREVIEW OF AGENDA\n\nREVIEW OF ACTIONS (see below)\n\nREVIEW OF DEPENDENCIES (see below)\n\n\n\nMEETINGS:\n-FTF in Georgia\n***who plans to attend?\n\n\n\nNEW MEMBERS\n-\n\n\nINFO SHARE\n**** [Here you can contribute news or informative titbits about\nevents, developments, etc that affect our work.  It is information share\nonly - if processing is needed we should add an agenda item - although\nof course clarification questions are allowed.]\n\n****RI: updates to FAQ styling\n****RI: John Yunker working on navigation section for guidelines\n\n\n\nUPDATES ON FRAMEWORK ACTIVITY\n-\n\n\n\nSPECIAL TOPICS\n\nTest suites\n****how should we go about developing tests to support the\nguidelines?\nare some people particularly interested in working on tests?\nwhat browser versions/platforms should we test?\n\n\nReview of WG work items (current and potential)\n*****Guidelines devt\nFAQ development\nArticles: Phil's introduction to web i18n; Richard's bidi\nbackground; ...\nFramework activity (including WAI collaboration)\nUsability work: developing web site; reviewing content &\narchitecture; testing approach\nTest suite development & results gathering\nOutreach coordination\n\n\nFAQ REVIEW\n\nLast chance review \n****ANDREW!\nhttp://www.w3.org/International/questions/qa-css-lang.html\n\n\n\nFirst discussion\n****MARTIN !\nhttp://www.w3.org/International/questions/qa-lang-2or3.html.\n\n\n\nComing Soon...\nRichard: intnl vs mlingl sites\nLloyd: still in the works\nTex: bidi languages\n\n\n\n\nGUIDELINES REVIEW\n\n****Andrew's proposal for addition to guidelines 2.2\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0060.html\n\n\n-Richard's bidi backgrounder\nhttp://people.w3.org/rishida/scripts/bidi/\n\n\n\nDISCUSSION\n\n-is there an issue with Mac browsers and utf-8?\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0002.html\n\n-should we limit ourselves to xhtml served as text/html for the\nguidelines?\n\n-should we be concerned with distinguishing behaviour for \nDOCTYPE related 'standards mode', 'almost standards mode' and\n'quirks mode'\n\n-what should we do wrt distinguishing behaviour for \nXHTML served as text/html or app/xml or app/xhtml+xml?\n\n-should we assume the use of xml declaration for xhtml 1, or\nfactor in that many won't use it?\neg.\nhttp://www.webstandards.org/learn/reference/prolog_problems.html\n\n\n\n\n\nEDUCATION & OUTREACH\n-Progress on article by Phil and co.\n\n\n\n\nAOB\n\n\n\n\n\n================================================\nDetails:\n\n\n\nUPCOMING Q&A ASSIGNMENTS\n------------------------------------------------------\nSend to groupPublish\n(latest)\nMartin: DONE25 June\nRichard:DONE2 July\nTex/Phil:DONE9 July\nRichard:DONE16 July [css vs markup for bidi]\nLloyd:DONE23 July [see his 5 questions]\nTexDONE31 July [what is bidi & which langs]\nAndrewDONE6 August\nMartin4 aug13 aug\nRichard11 aug20 aug [intnl vs mlingl sites]\nTbd18 aug\nTbd25 aug\nTbd1 sept\nRuss8  sept17 sept\n\nNote:\nWe are likely to receive something from Yves Savourel\n\n\n\n\n\nGUIDELINES CONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\nJohn\nNavigation\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\n\nACTION: Lloyd, write up some code samples relating to date formats and\nlink to them from the Q&A page at a later date\n\nACTION: RI, look into a sponsor for ftf in Atlanta\n\nAll: send in pointers to existing guidelines \n\n\nDEPENDENCIES\n=============\n\nHTML (SP): Approve para re application/xml+xhtml for bidi CSS vs markup\nQ&A\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0028.html\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0029.html\n\n\nHTML (SP & MI): help clarify how charset information should be declared\nfor html and xhtml 1.0 pages \nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0033.html\n\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "First thoughts on testin",
            "content": "I think it will be extremely valuable to readers of the guidelines to\nknow how well constructs such as bidi, vertical text, lang selectors,\netc. are supported by browsers.  Not only will it be practical\ninformation for them, but it will help us to include information about\nfuture directions or sparsely implemented features that may still be of\nuse if you are dealing with a known browser-specific population (such as\npeople in large corporations do for internal information). To assemble\nthat information, however, will require us to do testing.\n\nSome points that to my mind are worth discussing include:\n\n-we probably can't test all browser versions on all platforms,\nand in many cases that wouldn't be worthwhile anyway, since people don't\nuse some of the older ones - so which ones should we be concerned about?\n\n-reporting on old quirky browsers may take the readers gaze away\nfrom the standards route - I don't \nthink we should put too much focus on workarounds for non-standards\ncompliant browsers\n\n-new browsers have different modes: quirks, almost standards, and\nstandards - we should probably take that into account, although we\nshould probably also try to convince people to go with standards mode\nwherever possible\n\n-people can serve documents as HTML or XHTML; transitional,\nstrict, etc; text/html, application/xhtml+xml; etc.  How far should that\nconcern us?\n\n\n\n\nMy first thoughts on how to move forward include:\n\nI think there is significant value to reflecting summary information in\ntable form in our outline documents (see\nhttp://www.w3.org/International/geo/html-tech/outline/html-authoring-out\nline.html ), but to make it work we need to choose a manageable yet\nuseful set of baseline browser configurations and versions.  We should\nthen test against these baseline configurations and key subsequent\nreleases.\n\nRemember that we'll also have the ability to throw in descriptive\ninformation in the narrative about problems with specific browser\nversions, and this could go well beyond our baseline set.\n\nI'm planning to use a simple mechanism in the table based summaries to\ndraw attention to bugs and special features that are then described in\nthe narrative.\n\n\n\n\nI would suggest that we use the following as baseline configurations:\nOpera 7 (standards mode)\nIE Mac 5 (standards mode)\nIE Win 6 (standards mode)\nNavigator 6 (standards mode)\nMozilla 1.0 (standards mode)\nSafari v?\n\nI suggest that we additionally test against:\nNavigator 7 (almost standards mode)\nMozilla 1.1, 1.4? (almost standards mode)\n\nWe could also consider testing against Navigator 4.? and IE 5 or 5.5,\nand IE6 with xml declaration, though I see these as a lower priority,\nand the tests as fodder for the descriptive comments rather than the\nsummary tables.\n\n\nThoughts?\nRI\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Re: FTF in Atlanta: Please respond asa",
            "content": "I plan to be there.    Regards,   Martin.\n\nAt 14:21 03/08/05 +0100, Richard Ishida wrote:\n\n>To help the planning for the Atlanta FTF, please let me know if you plan\n>to attend asap.\n>\n>The meeting will be one day only. The main agenda item will be work on\n>the guidelines in order to prepare our first publication to Technical\n>Report space.\n>\n>Thanks,\n>RI\n>\n>============\n>Richard Ishida\n>W3C\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/People/Ishida/\n>http://www.w3.org/International/\n>http://www.w3.org/International/geo/\n>\n>See the W3C Internationalization FAQ page\n>http://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Useful material: IBM's redboo",
            "content": "Go to http://www.redbooks.ibm.com/redbooks/SG246851.html and select\nappendix C to see a couple of interesting points about use of CSS.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Euroweb 2002 Conferenc",
            "content": "Apologies, I should have reminded everyone before, but\nI should pass this on.  The programme is now up - looks\nquite good (but then I am biased :-)\n\nBrian \n\n-------------\n\nEuroweb 2002 Conference\n\nThe Web and the GRID: from e-science to e-business\n\nSt Anne's College Oxford, UK, December 17 and 18th 2002\n\nPlease see:\nhttp://www.w3c.rl.ac.uk/Euroweb/\n\nToday is the last day for the cheaper registration fee\n\nMartin\n\nMartin Prime (M.J.Prime@rl.ac.uk)\nRutherford Appleton Laboratory, Chilton, DIDCOT, Oxon OX11 0QX, UK\nTel: +44 1235 446555, Fax: +44 1235 445281\n\nThe contents of this email are sent in confidence for the use of the\nintended recipients only.  If you are not one of the intended recipients\ndo not take action on it or show it to anyone else, but return this\nemail to the sender and delete your copy of it\n\n\n\n"
        },
        {
            "subject": "Re: [nelocsig] short rtl localization surve",
            "content": "Just fyi, I have updated the page to include the list of\nlanguages/countries/scripts suggested by Russ, and a few other languages.\n\nI have also tried to make the page a little more prescriptive, although\nfundamentally you need to research your target audience.\n\nI would be interested in your comments on the page, is it clear, is it\ncorrect, does it agree with your experience...\n\nI am also interested if any of you is working with an RTL language other than\nHebrew and Arabic.\n\nhttp://www.i18nguy.com/temp/rtl.html\ntex\n\nTex Texin wrote:\n> \n> I am writing a web page on right-to-left languages and want to present a\n> table\n> on which languages are left-to-right vs right-to-left (RTL).\n> \n> No brainer, right? Well....\n> \n> I have a list of Right-to-left scripts and associated languages, but many of\n> the languages are archaic and not likely to be used for localization. Also,\n> as\n> most of you know, some, or perhaps many, languages can be written in more\n> than\n> one script.\n> Azerbaijani can be written in Latin, Cyrillic, or Arabic, for example.\n> \n> I would like the web page to make recommendations for languages that are\n> most\n> likely to be localization targets, rather than overwhelming people with a\n> lengthy list of options, which may not be used in practice for localization.\n> \n> Which brings me to my question- which languages and scripts are used in\n> practice for localization?\n> \n> To answer the question, I would like to conduct a brief survey-\n> If you don't mind, please send me a private mail listing the country,\n> language\n> and script your products are localized to.\n> I am especially interested in hearing from you if you support any of the\n> countries that use languages that can be written in more than one script (to\n> understand if you publish in all scripts or just favor one or two scripts),\n> or\n> if you publish in right to left languages.\n> \n> I don't need to know your co. or anything else. I am not going to contact\n> you\n> or try to sell you services.\n> \n> The mail should look like this:\n> \n> country language  script\n> US      english   latin\n> Japan   japanese  kanji\n> Iran  azerbaijani arabic\n> \n> etc.\n> \n> On the web page, I'll probably publish a similar table, and add ltr, or rtl\n> to\n> each row to indicate writing direction.\n> I'll publish the list here if I get sufficient responses.\n> \n> If you want to see the page I am working on (I'll be glad for further\n> comments), it's here\n> http://www.i18nguy.com/temp/rtl.html\n> \n> thanks in advance for your help.\n> tex\n> --\n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n> \n> XenCraft                        http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n> \n>                    Yahoo! Groups Sponsor\n> \n> \n> \n> This group is sponsored by BizWonk: Solutions for a Global E-conomy\n> (http://www.bizwonk.com).\n> \n> To Unsubscribe, just send a note to: nelocsig-unsubscribe@yahoogroups.com\n> \n> Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: Q&amp;A - Which languages are written right-toleft (RTL)",
            "content": "This will be a very useful resource with the addition of all the popular\nleft-to-right languages and their formats. I wonder if the right-to-left\nspecific title could be changed to more accurately describe this resource?\nOr should this be a separate resource area to which this Q&A can link?\n\nNotably missing are Austria, Belgium, and Switzerland, all of which are\nimportant locales for websites so I would think they would meet the criteria\nfor \"commonly requested languages.\" The latter two countries have multiple\nofficial languages, which I think is always an important point to stress.\n\nPhil\n\n-----Original Message-----\nhttp://www.i18nguy.com/temp/rtl.html\n\n\n\n"
        },
        {
            "subject": "Re: Q&amp;A - Which languages are written right-toleft (RTL)",
            "content": "Phil, I added the countries. \nYes we might need to change the title or break it up. It now answers (at\nleast) two questions-\nI added a point (suggested to me by someone else) about the political and\ncultural overtones of choosing a script, and we might want to separate out\n\"Which script(s) to use\" from the \"Which languages are rtl?\" and perhaps have\na \"What's my direction?\" ;-) question that the table replies to.\n\nUpdates are at: http://www.i18nguy.com/temp/rtl.html\n\n\n\"Arko, Phil\" wrote:\n> \n> This will be a very useful resource with the addition of all the popular\n> left-to-right languages and their formats. I wonder if the right-to-left\n> specific title could be changed to more accurately describe this resource?\n> Or should this be a separate resource area to which this Q&A can link?\n> \n> Notably missing are Austria, Belgium, and Switzerland, all of which are\n> important locales for websites so I would think they would meet the criteria\n> for \"commonly requested languages.\" The latter two countries have multiple\n> official languages, which I think is always an important point to stress.\n> \n> Phil\n> \n> -----Original Message-----\n> http://www.i18nguy.com/temp/rtl.html\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: Q&amp;A - Which languages are written right-toleft (RTL)",
            "content": "Tex,\n\nThis looks good.  I do have one question.   Shouldn't it be Taiwan instead of \"Republic of China\".  I know here at Microsoft we use \"Taiwan\" as the official name of the \"region\"?\n\nRegards, Russ\n \n\n-----Original Message-----\nFrom: public-i18n-geo-request@w3.org [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\nSent: Friday, August 08, 2003 3:07 PM\nTo: Arko, Phil\nCc: 'Tex Texin'; 'public-i18n-geo@w3.org'; nelocsig@yahoogroups.com\nSubject: Re: Q&A - Which languages are written right-to-left (RTL)?\n\n\nPhil, I added the countries. \nYes we might need to change the title or break it up. It now answers (at\nleast) two questions-\nI added a point (suggested to me by someone else) about the political and cultural overtones of choosing a script, and we might want to separate out \"Which script(s) to use\" from the \"Which languages are rtl?\" and perhaps have a \"What's my direction?\" ;-) question that the table replies to.\n\nUpdates are at: http://www.i18nguy.com/temp/rtl.html\n\n\n\"Arko, Phil\" wrote:\n> \n> This will be a very useful resource with the addition of all the \n> popular left-to-right languages and their formats. I wonder if the \n> right-to-left specific title could be changed to more accurately describe this resource?\n> Or should this be a separate resource area to which this Q&A can link?\n> \n> Notably missing are Austria, Belgium, and Switzerland, all of which \n> are important locales for websites so I would think they would meet \n> the criteria for \"commonly requested languages.\" The latter two \n> countries have multiple official languages, which I think is always an important point to stress.\n> \n> Phil\n> \n> -----Original Message-----\n> http://www.i18nguy.com/temp/rtl.html\n\n--\n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: Q&amp;A - Which languages are written right-toleft (RTL)",
            "content": "Russ,\nI thought that the official name is ROC. China is PRC.\n\n\nHowever, looking at ISO 3166\nhttp://www.iso.ch/iso/en/prods-services/iso3166ma/02iso-3166-code-lists/list-en1.html\n\nI see CN is China and TW is \"Taiwan, Province of China\".\n\nSo you and Microsoft are right. I'll fix the page.\n\ntex\n\n\nRuss Rolfe wrote:\n> \n> Tex,\n> \n> This looks good.  I do have one question.   Shouldn't it be Taiwan instead of \"Republic of China\".  I know here at Microsoft we use \"Taiwan\" as the official name of the \"region\"?\n> \n> Regards, Russ\n> \n> \n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> Sent: Friday, August 08, 2003 3:07 PM\n> To: Arko, Phil\n> Cc: 'Tex Texin'; 'public-i18n-geo@w3.org'; nelocsig@yahoogroups.com\n> Subject: Re: Q&A - Which languages are written right-to-left (RTL)?\n> \n> Phil, I added the countries.\n> Yes we might need to change the title or break it up. It now answers (at\n> least) two questions-\n> I added a point (suggested to me by someone else) about the political and cultural overtones of choosing a script, and we might want to separate out \"Which script(s) to use\" from the \"Which languages are rtl?\" and perhaps have a \"What's my direction?\" ;-) question that the table replies to.\n> \n> Updates are at: http://www.i18nguy.com/temp/rtl.html\n> \n> \"Arko, Phil\" wrote:\n> >\n> > This will be a very useful resource with the addition of all the\n> > popular left-to-right languages and their formats. I wonder if the\n> > right-to-left specific title could be changed to more accurately describe this resource?\n> > Or should this be a separate resource area to which this Q&A can link?\n> >\n> > Notably missing are Austria, Belgium, and Switzerland, all of which\n> > are important locales for websites so I would think they would meet\n> > the criteria for \"commonly requested languages.\" The latter two\n> > countries have multiple official languages, which I think is always an important point to stress.\n> >\n> > Phil\n> >\n> > -----Original Message-----\n> > http://www.i18nguy.com/temp/rtl.html\n> \n> --\n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n> \n> XenCraft                            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: Q&amp;A - Which languages are written right-toleft (RTL)",
            "content": "At 18:07 03/08/08 -0400, Tex Texin wrote:\n\n>Phil, I added the countries.\n>Yes we might need to change the title or break it up. It now answers (at\n>least) two questions-\n>I added a point (suggested to me by someone else) about the political and\n>cultural overtones of choosing a script, and we might want to separate out\n>\"Which script(s) to use\" from the \"Which languages are rtl?\"\n\nYes, I think this is an excellent suggestion. Having too much\nmaterial in one question, or actually more than one question in\none question, will be confusing.\n\nRegards,   Martin.\n\n\n\n>and perhaps have\n>a \"What's my direction?\" ;-) question that the table replies to.\n>\n>Updates are at: http://www.i18nguy.com/temp/rtl.html\n>\n>\n>\"Arko, Phil\" wrote:\n> >\n> > This will be a very useful resource with the addition of all the popular\n> > left-to-right languages and their formats. I wonder if the right-to-left\n> > specific title could be changed to more accurately describe this resource?\n> > Or should this be a separate resource area to which this Q&A can link?\n> >\n> > Notably missing are Austria, Belgium, and Switzerland, all of which are\n> > important locales for websites so I would think they would meet the \n> criteria\n> > for \"commonly requested languages.\" The latter two countries have multiple\n> > official languages, which I think is always an important point to stress.\n> >\n> > Phil\n> >\n> > -----Original Message-----\n> > http://www.i18nguy.com/temp/rtl.html\n>\n>--\n>-------------------------------------------------------------\n>Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n>Xen Master                          http://www.i18nGuy.com\n>\n>XenCraft                            http://www.XenCraft.com\n>Making e-Business Work Around the World\n>-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: Useful material: IBM's redboo",
            "content": "At 20:00 03/08/07 +0100, Richard Ishida wrote:\n\n>Go to http://www.redbooks.ibm.com/redbooks/SG246851.html and select\n>appendix C to see a couple of interesting points about use of CSS.\n\nSome interesting stuff, but a strange and inconvenient user interface.\n\nRegards,    Martin.\n\n\n>RI\n>\n>============\n>Richard Ishida\n>W3C\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/People/Ishida/\n>http://www.w3.org/International/\n>http://www.w3.org/International/geo/\n>\n>See the W3C Internationalization FAQ page\n>http://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Re: Euroweb 2002 Conferenc",
            "content": "Dave and I have just registered :)\n\nLibby\n\nOn Fri, 15 Nov 2002, Matthews, BM (Brian)  wrote:\n\n>\n>\n> Apologies, I should have reminded everyone before, but\n> I should pass this on.  The programme is now up - looks\n> quite good (but then I am biased :-)\n>\n> Brian\n>\n> -------------\n>\n> Euroweb 2002 Conference\n>\n> The Web and the GRID: from e-science to e-business\n>\n> St Anne's College Oxford, UK, December 17 and 18th 2002\n>\n> Please see:\n> http://www.w3c.rl.ac.uk/Euroweb/\n>\n> Today is the last day for the cheaper registration fee\n>\n> Martin\n>\n> Martin Prime (M.J.Prime@rl.ac.uk)\n> Rutherford Appleton Laboratory, Chilton, DIDCOT, Oxon OX11 0QX, UK\n> Tel: +44 1235 446555, Fax: +44 1235 445281\n>\n> The contents of this email are sent in confidence for the use of the\n> intended recipients only.  If you are not one of the intended recipients\n> do not take action on it or show it to anyone else, but return this\n> email to the sender and delete your copy of it\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "New FAQ: monolingual vs multilingual page",
            "content": "Sorry this is late.  (I actually thought I'd already done it.)\n\nhttp://www.w3.org/International/questions/qa-mono-multilingual.html\n\nFor discussion in today's meeting.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Tests pag",
            "content": "I have put up a small page to point from one place to all the test pages\nwe develop.  It itself is pointed to from the GEO home page.\n\nhttp://www.w3.org/International/tests/\n\nEnjoy,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03080",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n6 August 2003\n\n\nInfo Share\n==========\nPhil briefly summarised his impression of IWIPS conference in Berlin,\nmixture of advanced and not advanced people - lot of software presns -\nI18n focus - very interesting talk from Adobe: went to Japan, issues\nabout text layout etc.  \n\n\nFAQs\n===========\nReview and comments made on Andrew's contribution. [published next day]\nhttp://www.w3.org/International/questions/qa-css-lang.html\n\nFirst discussion of Martin's contribution.\nhttp://www.w3.org/International/questions/qa-lang-2or3.html.\n\n\n\nTesting\n============\nWe agreed on a set of baseline browser versions/platforms for use when\ndescribing applicability of techniques found in the guidelines.  We will\nonly systematically test applicability to the baseline browsers or\nsignificant later versions.  The baseline versions are as follows:\n\nInternet Explorer / Windows v6\nInternet Explorer / Mac v5\nNetscape Navigator v7\nOpera v7\nMozilla v1.0\nSafari  version tbd\n\nThese were all chosen because they provide standards compliance.  We\nshould test in standards mode where the browser distinguishes between\nstandards and quirks modes. (ie. Using a DOCTYPE, and in the case of\nIE/Win without an xml declaration).\n\nWe may still refer to important quirks with older browsers in the\nua-issues section of the XML.\n\nRichard has put together a couple of test pages [see\nhttp://www.w3.org/International/tests/ ], and has talked briefly with\nBert about integration with the CSS test suite.  We need to study the\nCSS test suite guidelines\n[http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html ] and\nexplore this further.  We should also talk with the HTML group.\n\n\nRI\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-0813 at 19:00 UTC, 12noon Pacific, 3pm Eastern, 20:00 UK, 5am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 13 August 2003\nStart    : 19:00 UTC, 20:00 UK, 12noon Pacific, 3pm Eastern, \n  5am Australia (next day!)\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) \nwith conference code 4186 (spells \"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\n*** indicates a topic that will receive particular attention this week\n\n\n\n\nDraft agenda\n============\n\nREVIEW OF AGENDA\n\nREVIEW OF ACTIONS (see below)\n\nREVIEW OF DEPENDENCIES (see below)\n\n\n\nMEETINGS:\n-FTF in Georgia\n***Russ has agreement to use a MS office close to the hotel, but\nonly he will have network access\n\n\n\nNEW MEMBERS\n-\n\n\nINFO SHARE\n**** [Here you can contribute news or informative titbits about\nevents, developments, etc that affect our work.  It is information share\nonly - if processing is needed we should add an agenda item - although\nof course clarification questions are allowed.]\n\n****RI: tests page http://www.w3.org/International/tests/ \n\n\n\nUPDATES ON FRAMEWORK ACTIVITY\n-\n\n\n\nSPECIAL TOPICS\n\n\nReview of WG work items (current and potential)\n*****Guidelines devt\nFAQ development\nArticles: Phil's introduction to web i18n; Richard's bidi\nbackground; ...\nFramework activity (including WAI collaboration)\nUsability work: developing web site; reviewing content &\narchitecture; testing approach\nTest suite development & results gathering\nOther outreach coordination\n\n\nFAQ REVIEW\n\nLast chance review \n****MARTIN!\nhttp://www.w3.org/International/questions/qa-lang-2or3.html.\n\n\nFirst discussion\n****RICHARD !\nhttp://www.w3.org/International/questions/qa-mono-multilingual.html\n\n\n\nComing Soon...\nTBD: ??\nLloyd: still in the works\nTex: bidi languages\n\n\n\n\nGUIDELINES REVIEW\n\n-Andrew's proposal for addition to guidelines 2.2\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0060.html\n\n\n****Richard's bidi backgrounder\nhttp://people.w3.org/rishida/scripts/bidi/\n\n\n\nDISCUSSION\n\n-is there an issue with Mac browsers and utf-8?\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0002.html\n\n-should we limit ourselves to xhtml served as text/html for the\nguidelines?\n\n-should we be concerned with distinguishing behaviour for \nDOCTYPE related 'standards mode', 'almost standards mode' and\n'quirks mode'\n\n-what should we do wrt distinguishing behaviour for \nXHTML served as text/html or app/xml or app/xhtml+xml?\n\n-should we assume the use of xml declaration for xhtml 1, or\nfactor in that many won't use it?\neg.\nhttp://www.webstandards.org/learn/reference/prolog_problems.html\n\n\n\n\n\nEDUCATION & OUTREACH\n-Article by Phil and co.\n\n\n\n\nAOB\n\n\n\n\n\n================================================\nDetails:\n\n\n\nUPCOMING Q&A ASSIGNMENTS\n------------------------------------------------------\nSend to groupPublish\n(latest)\nMartin: DONE25 June\nRichard:DONE2 July\nTex/Phil:DONE9 July\nRichard:DONE16 July [css vs markup for bidi]\nLloyd:DONE23 July [see his 5 questions]\nTexDONE31 July [what is bidi & which langs]\nAndrewDONE6 August\nMartinDONE13 aug\nRichardDONE20 aug [intnl vs mlingl sites]\nTbd18 aug\nTbd25 aug\nTbd1 sept\nRuss8  sept17 sept\n\nNote:\nWe are likely to receive something from Yves Savourel\n\n\n\n\n\nGUIDELINES CONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\nJohn\nNavigation\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\n\nACTION: Lloyd, write up some code samples relating to date formats and\nlink to them from the Q&A page at a later date\n\nACTION: RI, look into a sponsor for ftf in Atlanta\n\nAll: send in pointers to existing guidelines \n\n\nDEPENDENCIES\n=============\n\nHTML (SP): Approve para re application/xml+xhtml for bidi CSS vs markup\nQ&A\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0028.html\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0029.html\n\n\nHTML (SP & MI): help clarify how charset information should be declared\nfor html and xhtml 1.0 pages \nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jul/0033.html\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Re: New FAQ: monolingual vs multilingual page",
            "content": "Hello Richard,\n\nSome points on this:\n\n- Good question, and important points in the answer.\n- The space before titles turns out completely different\n   in different browsers. In NS, there is almost no space\n   before <h2>, but a lot of space before <h3>. In Amaya,\n   it's the other way round. In IE, both cases have well\n   enough space.\n- I think the second paragraph of the 'Answer' should\n   come first, and the (currently) first one should be\n   worded more crisply. The problem of crispness applies\n   to the rest, too. Maybe use more lists.\n- There should be a better definition/introduction of the\n   terms 'monolingual international Web site' and 'multilingual\n   international Web site'.\n- Please use 'Web site', rather than just 'site'.\n- It is good to use International English as an example, but\n   it should be explained better, and it should be clear that\n   there are international sites that don't use English.\n\nRegards,    Martin.\n\n\nAt 16:29 03/08/13 +0100, Richard Ishida wrote:\n\n>Sorry this is late.  (I actually thought I'd already done it.)\n>\n>http://www.w3.org/International/questions/qa-mono-multilingual.html\n>\n>For discussion in today's meeting.\n>\n>RI\n>\n>============\n>Richard Ishida\n>W3C\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/People/Ishida/\n>http://www.w3.org/International/\n>http://www.w3.org/International/geo/\n>\n>See the W3C Internationalization FAQ page\n>http://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "for toda",
            "content": "I would like to finish this today:\n\nhttp://www.i18nguy.com/temp/rtl.html\n\nDoes anyone have or can point me to, a good definition for \"script\"?\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: for toda",
            "content": "Tex,\n \nHere is what the www.unicode.org glossary says:\n \nScript. A collection of symbols used to represent textual information in one or more writing systems.\n \nThis is what we have on our microsoft www.Microsoft.com/globaldev web site:\n \nScript: A collection of characters for displaying written text, all of which have a common characteristic that justifies their consideration as a distinct set. One script can be used for several different languages (for example, Latin script, which covers all of Western Europe). Some written languages require multiple scripts (for example, Japanese, which requires at least three scripts-the hiragana and katakana syllabifies and the kanji ideographs imported from China). This sense of the word \"script\" has nothing to do with programming scripts such as Perl or Visual Basic Scripting Edition (VBScript).\n \nAnd this is one from Nadine's book:\n \nScript A system of characters used to write one or several languages. Characters denote isolated sounds, syllables, or word elements and are governed by a general set of rules for creating text, such as default writing direction.\n \nHope this helps.\n \nRuss\n\n________________________________\n\nFrom: public-i18n-geo-request@w3.org on behalf of Tex Texin\nSent: Wed 8/13/2003 11:01 AM\nTo: GEO\nSubject: for today\n\n\n\n\nI would like to finish this today:\n\nhttp://www.i18nguy.com/temp/rtl.html\n\nDoes anyone have or can point me to, a good definition for \"script\"?\n\n--\n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                        \nXenCraft                            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "rtl q&amp;a updated",
            "content": "I have updated the page with today's comments.\n\nhttp://www.i18nguy.com/temp/rtl.html\n\n1) I added caveats in front of both tables.\nIndicated these used arabic historically, not currently. kazak, malay,\nmalayalam, somali, javanese\n\n2) Changed China to exclude hk. hk is separate.\n3) noted many languages are spoken in china and india, distinguished offical\nand minority languages.\nAlso indicated israel used hebrew arabic russian english.\n\n4) added urdu/pakistan to both tables.\n\nI have not added (I think its not needed. Will add it if someone requests\nit.):\na) singapore officially uses chinese english tamil malay\n\nb) Waiting on info from Richard for:\ntable adding column heading info\n\nI'll look at the issue of multi-question or multi-page next.\n\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: rtl q&amp;a updated",
            "content": "> b) Waiting on info from Richard for:\n> table adding column heading info\n\nSee the heading 'Tables' at\nhttp://www.w3.org/People/Ishida/checklists/wai-html-impl-checklist.html\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Tex Texin\n> Sent: 14 August 2003 10:24\n> To: GEO\n> Subject: rtl q&a updated.\n> \n> \n> \n> I have updated the page with today's comments.\n> \n> http://www.i18nguy.com/temp/rtl.html\n> \n> 1) I added caveats in front of both tables.\n> Indicated these used arabic historically, not currently. \n> kazak, malay, malayalam, somali, javanese\n> \n> 2) Changed China to exclude hk. hk is separate.\n> 3) noted many languages are spoken in china and india, \n> distinguished offical and minority languages. Also indicated \n> israel used hebrew arabic russian english.\n> \n> 4) added urdu/pakistan to both tables.\n> \n> I have not added (I think its not needed. Will add it if \n> someone requests\n> it.):\n> a) singapore officially uses chinese english tamil malay\n> \n> b) Waiting on info from Richard for:\n> table adding column heading info\n> \n> I'll look at the issue of multi-question or multi-page next.\n> \n> \n> -- \n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n>                          \n> XenCraft            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n> \n\n\n\n"
        },
        {
            "subject": "French semwebrelated sit",
            "content": "\"Exotic Hypertext\" teaching portal\n\nhttp://tecfaseed.unige.ch/staf18iris/index.php?newlang=eng\n\ndual-language.\n\n-----------\nDanny Ayers\n\nSemantic Web Log :\nhttp://www.citnames.com/blog\n\n\"The lyf so short, the craft so long to lerne.\" - Chaucer\n\n \n\n\n\n"
        },
        {
            "subject": "RE: for toda",
            "content": "Hello Russ,\n\nI think the Microsoft definition is a bit long, but much more\nself-contained than the others. The only change I would suggest\nis syllabifies -> syllabaries.\n\nRegards,   Martin.\n\nAt 22:56 03/08/13 -0700, Russ Rolfe wrote:\n\n>Tex,\n>\n>Here is what the www.unicode.org glossary says:\n>\n>Script. A collection of symbols used to represent textual information in \n>one or more writing systems.\n>\n>This is what we have on our microsoft www.Microsoft.com/globaldev web site:\n>\n>Script: A collection of characters for displaying written text, all of \n>which have a common characteristic that justifies their consideration as a \n>distinct set. One script can be used for several different languages (for \n>example, Latin script, which covers all of Western Europe). Some written \n>languages require multiple scripts (for example, Japanese, which requires \n>at least three scripts-the hiragana and katakana syllabifies and the kanji \n>ideographs imported from China). This sense of the word \"script\" has \n>nothing to do with programming scripts such as Perl or Visual Basic \n>Scripting Edition (VBScript).\n>\n>And this is one from Nadine's book:\n>\n>Script A system of characters used to write one or several languages. \n>Characters denote isolated sounds, syllables, or word elements and are \n>governed by a general set of rules for creating text, such as default \n>writing direction.\n>\n>Hope this helps.\n>\n>Russ\n>\n>________________________________\n>\n>From: public-i18n-geo-request@w3.org on behalf of Tex Texin\n>Sent: Wed 8/13/2003 11:01 AM\n>To: GEO\n>Subject: for today\n>\n>\n>\n>\n>I would like to finish this today:\n>\n>http://www.i18nguy.com/temp/rtl.html\n>\n>Does anyone have or can point me to, a good definition for \"script\"?\n>\n>--\n>-------------------------------------------------------------\n>Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n>Xen Master                          http://www.i18nGuy.com\n>\n>XenCraft                            http://www.XenCraft.com\n>Making e-Business Work Around the World\n>-------------------------------------------------------------\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: for toda",
            "content": "Martin,\n\nThanks for the comments.  Actually, what I thought would happen is that Tex could take the good from all of these definitions and then come up with one on his own.\n\nRuss\n\n-----Original Message-----\nFrom: Martin Duerst [mailto:duerst@w3.org] \nSent: Thursday, August 14, 2003 12:37 PM\nTo: Russ Rolfe; Tex Texin; GEO\nSubject: RE: for today\n\nHello Russ,\n\nI think the Microsoft definition is a bit long, but much more self-contained than the others. The only change I would suggest is syllabifies -> syllabaries.\n\nRegards,   Martin.\n\nAt 22:56 03/08/13 -0700, Russ Rolfe wrote:\n\n>Tex,\n>\n>Here is what the www.unicode.org glossary says:\n>\n>Script. A collection of symbols used to represent textual information \n>in one or more writing systems.\n>\n>This is what we have on our microsoft www.Microsoft.com/globaldev web site:\n>\n>Script: A collection of characters for displaying written text, all of \n>which have a common characteristic that justifies their consideration \n>as a distinct set. One script can be used for several different \n>languages (for example, Latin script, which covers all of Western \n>Europe). Some written languages require multiple scripts (for example, \n>Japanese, which requires at least three scripts-the hiragana and \n>katakana syllabifies and the kanji ideographs imported from China). \n>This sense of the word \"script\" has nothing to do with programming \n>scripts such as Perl or Visual Basic Scripting Edition (VBScript).\n>\n>And this is one from Nadine's book:\n>\n>Script A system of characters used to write one or several languages. \n>Characters denote isolated sounds, syllables, or word elements and are \n>governed by a general set of rules for creating text, such as default \n>writing direction.\n>\n>Hope this helps.\n>\n>Russ\n>\n>________________________________\n>\n>From: public-i18n-geo-request@w3.org on behalf of Tex Texin\n>Sent: Wed 8/13/2003 11:01 AM\n>To: GEO\n>Subject: for today\n>\n>\n>\n>\n>I would like to finish this today:\n>\n>http://www.i18nguy.com/temp/rtl.html\n>\n>Does anyone have or can point me to, a good definition for \"script\"?\n>\n>--\n>-------------------------------------------------------------\n>Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n>Xen Master                          http://www.i18nGuy.com\n>\n>XenCraft                            http://www.XenCraft.com\n>Making e-Business Work Around the World\n>-------------------------------------------------------------\n>\n>\n\n\n\n"
        },
        {
            "subject": "multiquestion fa",
            "content": "thanks guys. I also asked on Qalam@yahoogroups.com and there was some\ndiscussion there.\nI will go with the Unicode definition as it is simplest and therefore is\nlikely to require the least defense. ;-)\n\nPlease look at:\nhttp://www.i18nguy.com/temp/rtl1.html\n\nI modified the rtl page to be multi-question to see what it looks like.\nThe background and each subsection became answers to questions. The text\ndidn't change, I just defined the question that each paragraph or section\nanswered. I added the script definition.\n\nOver the long run, I would expect this page to collect more script and\ndirectionality related Q&A (assuming the multi-question page style is\nadopted).\nThe format makes it easy to add a short q&a at any time with little overhead,\nand it is easy for users to see related topics and navigate thru them, and\nsearch engines will identify the topic with more precision and rank the page\nhigher.\n\ntex\n\n\nRuss Rolfe wrote:\n> \n> Martin,\n> \n> Thanks for the comments.  Actually, what I thought would happen is that Tex could take the good from all of these definitions and then come up with one on his own.\n> \n> Russ\n> \n> -----Original Message-----\n> From: Martin Duerst [mailto:duerst@w3.org]\n> Sent: Thursday, August 14, 2003 12:37 PM\n> To: Russ Rolfe; Tex Texin; GEO\n> Subject: RE: for today\n> \n> Hello Russ,\n> \n> I think the Microsoft definition is a bit long, but much more self-contained than the others. The only change I would suggest is syllabifies -> syllabaries.\n> \n> Regards,   Martin.\n> \n> At 22:56 03/08/13 -0700, Russ Rolfe wrote:\n> \n> >Tex,\n> >\n> >Here is what the www.unicode.org glossary says:\n> >\n> >Script. A collection of symbols used to represent textual information\n> >in one or more writing systems.\n> >\n> >This is what we have on our microsoft www.Microsoft.com/globaldev web site:\n> >\n> >Script: A collection of characters for displaying written text, all of\n> >which have a common characteristic that justifies their consideration\n> >as a distinct set. One script can be used for several different\n> >languages (for example, Latin script, which covers all of Western\n> >Europe). Some written languages require multiple scripts (for example,\n> >Japanese, which requires at least three scripts-the hiragana and\n> >katakana syllabifies and the kanji ideographs imported from China).\n> >This sense of the word \"script\" has nothing to do with programming\n> >scripts such as Perl or Visual Basic Scripting Edition (VBScript).\n> >\n> >And this is one from Nadine's book:\n> >\n> >Script A system of characters used to write one or several languages.\n> >Characters denote isolated sounds, syllables, or word elements and are\n> >governed by a general set of rules for creating text, such as default\n> >writing direction.\n> >\n> >Hope this helps.\n> >\n> >Russ\n> >\n> >________________________________\n> >\n> >From: public-i18n-geo-request@w3.org on behalf of Tex Texin\n> >Sent: Wed 8/13/2003 11:01 AM\n> >To: GEO\n> >Subject: for today\n> >\n> >\n> >\n> >\n> >I would like to finish this today:\n> >\n> >http://www.i18nguy.com/temp/rtl.html\n> >\n> >Does anyone have or can point me to, a good definition for \"script\"?\n> >\n> >--\n> >-------------------------------------------------------------\n> >Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> >Xen Master                          http://www.i18nGuy.com\n> >\n> >XenCraft                            http://www.XenCraft.com\n> >Making e-Business Work Around the World\n> >-------------------------------------------------------------\n> >\n> >\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Updated http://www.w3.org/International/O-HTTPcharset.htm",
            "content": "Dear colleagues,\n\nBased on a suggestion from a reader, I have added some information\nabout how to set Content-Type (including charset) from scripts at\nhttp://www.w3.org/International/O-HTTP-charset.html.\nLook for the text\n\"The appropriate header can also be set by in script, as follows:\"\n\nRegards,   Martin.\n\n\n\n"
        },
        {
            "subject": "New WG membe",
            "content": "I'd like to welcome Jungshik Shin as the newest member of the GEO Task\nForce and I18N WG.  Jungshik is based in Korea.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/People/Ishida/ \nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Lloyd's FAQ resurface",
            "content": "I have just had a editorial session with Lloyd and posted what we hope\nis a final version of his FAQ 'Accept-Language used for locale setting'\nat http://www.w3.org/International/questions/qa-accept-lang-locales.html\n\nI propose we announce this to the world a week on Thursday.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "Re: XHTML served as application/xml+xhtm",
            "content": "From: \"Richard Ishida\" <ishida@w3.org>\n> Following our discussion last Friday I proposed to amend the Q&A at\n> http://www.w3.org/International/questions/qa-bidi-css-markup.html by\n> inserting a second para in the section Answer -> XHTML/HTML that reads\n> as follows:\n>\n> ======================\n> (There is an exception to this rule. If the XHTML is served as\n> <code>application/xhtml+xml</code>, rather than <code>text/html</code>\n> it is treated by the user agent as XML rather than HTML, and so needs\n> CSS to map the markup to the appropriate display behaviour, as described\n> in '<a href=\"#xml\">General XML-based markup languages</a>' above.)\n>\n>  ======================\n>\n> Some questions were raised about its validity in our GEO telecon. Would\n> you mind casting an eye over this para and letting us know whether it\n> looks correct / adequate to you?\n\n(Sorry about the delay in replying)\n\nI think there is a confusion here about what determines whether a document\nis HTML or XHTML.\n\nLet me try and explain: if I serve up an HTML document as text/plain, it\nbecomes a text document, not an HTML document, and the rules for text/plain\napply to it, not the rules for text/html. (IE does this wrong by the way).\n\nIf I serve up an XHTML document as text/html, it becomes an HTML document,\nnot XHTML, and so the rules for HTML apply (including the ones in CSS).\n\nIf I serve an XHTML document as application/xhtml+xml (or text/xml), only\nthen is it really XHTML, and the HTML rules no longer apply.\n\nSo there is nothing wrong with the new paragraph, it is the paragraph that\nit applies to that is wrong in bundling HTML and XHTML together. They are\ndifferent beasts, and should have different sections.\n\nSo this paragraph is wrong:\n\n<<<\nXHTML/HTML\n\nUse markup only. The CSS2 recommendation recommends the use of markup for\nbidi text in HTML. In fact it goes as far as to say that conforming HTML\nuser agents may ignore CSS bidi properties. This is because the HTML\nspecification clearly defines the expected behaviour of user agents with\nrespect to the bidi markup.\n>>>\n\nReplace it with something like:\n\n<<<\nHTML\n\nUse markup only. The CSS2 recommendation recommends the use of markup for\nbidi text in HTML. In fact it goes as far as to say that conforming HTML\nuser agents may ignore CSS bidi properties. This is because the HTML\nspecification clearly defines the expected behaviour of user agents with\nrespect to the bidi markup.\n\nXHTML\n\nXHTML (served as text/xml, application/xml or application/xhtml+xml) is XML\nand so needs CSS to map the markup to the appropriate display behaviour, as\ndescribed in '<a href=\"#xml\">General XML-based markup languages</a>' above.\nNote that an XHTML document served as text/html is treated as an HTML\ndocument, not an XHTML one, and so the HTML rules apply, not the XHTML ones.\n>>>\n\nHope this helps.\n\nBest wishes,\n\nSteven Pemberton\n\n\n\n"
        },
        {
            "subject": "Notes from teleconf 2003-082",
            "content": "These are my notes. Feel free to add/correct.\n\nPresent: Richard (chair), Andrew, Russ, Tex, Martin (scribe)\n\n\nInfoshare: Tex may not make the meeting in the next couple weeks because\n            of a project\n\nMeeting: Richard will link the page that Russ has sent him soon.\n          Will anounce it to the list.\n          Russ: ca.15/20min drive north, door will be locked because it\n                is Saturday.\n          Let's start the meeting at 8:30am\n          There is one local telephone line (can be used for phone bridge\n                                  with calling card, or for an ISP dialup)\n          Russ will check things out on Friday\n          People need to tell Richard that they attend\n          Andrew may participtate via phone, depending on the agenda\n          Richard: please send me topics for Agenda\n                   plan to work on encoding section, language section,\n                                   bidi section\n\nRichard on vacation next week. Russ also on vacation next week.\n\nTeleconference next week: Andrew, Martin,... will meet and go through\n(Aug. 27)           Andrew's material and maybe something else\n\nUnicode conference week: the usual teleconference is canceled\n(Sept. 3)\n\nSept. 10th: usual meeting\n\nFAQ: How to cover the weeks ahead\nDiscussing\nhttp://www.w3.org/International/questions/qa-mono-multilingual.html\ndiscussing details, Russ suggests some helpful tweak\n\ninterrupt: we should try to have an IRC channel for this meeting\nAction Richard to send instructions for how to use IRC\n\n\nDiscussing: http://www.i18nguy.com/temp/rtl1.html\ndiscussions mostly about entry, structure, presentation\ndefinition of script should be more standalone\nsome questions will be swapped\nTex will update, comments should be made to the list\n\n\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "SW events as xhtml rss+events profil",
            "content": "http://www.w3.org/2001/sw/Europe/200211/swconferences/events1.html\n\n- a new location. Caroline Meek is hopefuly going to add conferences and\nevents to this list, but if anyone from the project wants to add an\nevent, there's no reason why not, as long as you adhere carefully to\nthe profile of XHTML used so that we can parse it into RSS+events,\nnamely that an event should look something like this,\n\n[[\n\n<div class=\"item\">\n<h2>W3C Technical Plenary</h2>\n<p><a rel=\"details\" href=\"http://www.w3.org/\">W3C Technical Plenary</a>\n will be held in <span class=\"location\">Cambridge, MA, USA</span>,\n starting on <span class=\"startdate\">03 March 2003</span>\n and ending on <span class=\"enddate\">07 March 2003</span>.\n Contact <span class=\"organizer\">mailto:calreq@w3.org</span>.\n\n</p>\n</div>\n]]\n\nIt's a bit out of date at the moment - let me and caroline\n(caroline.meek@bristol.ac.uk) know if you can't edit it and you would\nlike to add something.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "FW: Lloyd's FAQ resurfaces (long",
            "content": "All:\n\nSomewhere under Richard's response below is my initial reaction to Lloyd's\nFAQ about Accept-Language (A-L) and Locale. I have a little heartburn about\nthe specific wording of this FAQ because I feel that it stresses the wrong\nthings about inferring locale from A-L.\n\nI have copied the WSTF list because our group is active in the area of\nlocales.\n\nI agree with nearly all of the detail in the FAQ, but not with the\npresentation.\n\nI would prefer it if the question were rephrased \"How can I obtain a locale\nfrom a browser (user-agent)? Can I get it from the Accept-Language?\" I would\nlike the answer to be \"Yes\", rather than (as it appears now) to be \"No\".\n\nI actually think that nearly all of the current draft is perfectly crafted\nand correct. The whole would be better, though, IMO, if it started with:\n\"Yes, but it is not a good idea to use HTTP Accept-Language\n<emph>alone</emph> to determine the locale preferences of the user.\"\n\nThe page should include reference to the fact that many Web servers, server\nside scripting languages, and operating environments, by default, parse and\ninfer their native locale objects from Accept-Language. For example, .NET\nuses the A-L to determine the default CultureInfo, Java Servlet provides a\ngetLocale() and getLocales() pair of methods that parse A-L, and so forth.\nThese objects are very useful in obtaining resources and other \"language\npreference\" material. They are less useful, as pointed out by the FAQ, in\ndetermining many of the fine grained attributes of users or in designing the\ninternational behavior of a site. A language preference of es-MX doesn't\nnecessarily mean that a postal address form should be formatted or validated\nfor Mexican addresses. I might still live in the USA (or elsewhere).\n\nThe rhetorical question \"Do you want to shove Polish content at a user just\nbecause they are running a user agent in Warsaw?\" might be answered yes in\nsome (many) cases. I think that the particular approach that a website takes\nwhen displaying the homepage depends on the application. If you don't have a\ncookie, logged in user, or other information about a request, it may\nactually be BETTER to follow what limited information you do have (including\nA-L) than ignore it. Do you want to shove French content at a user just\nbecause they haven't clicked on Polish yet? When all you have is an\nAccept-Language, what is your implementation decision?\n\nFinally, I think that the bulleted list at the bottom isn't all that\nappropriate. Of the items listed, only one (date/time formats) can and\nshould be wholly or partially inferred from a locale. The remainder\n(timezone, currency, measurement system, paper size, Tex's shoe/clothing\nsize, physical location) are all orthogonal or, at best, distantly related\nto locale systems. In proper international design, one would not necessarily\ninfer any of these from the user's concrete locale setting, let alone from\nA-L.\n\nThanks for the opportunity to comment.\n\nAddison\n\nAddison P. Phillips\nDirector, Globalization Architecture\nwebMethods, Inc. -- \"Global Business Visibility\"\n\n432 Lakeside Drive, Sunnyvale, CA, USA\n+1 408.962.5487 (office)\n+1 408.210.3569 (mobile)\nmailto:aphillips@webmethods.com\n\nChair, W3C-I18N-WG, Web Services Task Force\nhttp://www.w3.org/International/ws\n\nInternationalization is an architecture.\nIt is not a feature.\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org]\nSent: Wednesday, August 20, 2003 11:46 AM\nTo: aphillips@webmethods.com\nCc: Richard Ishida\nSubject: RE: Lloyd's FAQ resurfaces\n\n\nHi Addison,\n\nDon't worry, I still like you ;)  I think these are generally good\ncomments.  You could, if you want, send these to public-i18n-geo@w3.org\nnow - I signed you up a few days ago.\n\nI guess what you're missing is some information: we do have John Yunker\nworking on more comprehensive guidelines for navigation (and he's quite\nkeen on this topic).  The guidelines are more appropriate for 'how to'\ntype of information such as you are suggesting.  Ideally that would\nexist already, and this FAQ would point to it, but one step at a time...\n\n> If A-L is good for content selection, why not locale selection?\n\nHmm. I'm wavering on this...  Maybe we should soften the text a little.\n\nSome of the points you make lower down (eg. Currency) would be worth\nsending to the geo list.  Would you like to do that, adapting the stuff\nrelating to how-to's in the light of my earlier comment?\n\nRI\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/\n\nhttp://www.w3.org/International/\nhttp://www.w3.org/International/geo/\n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: Addison Phillips [wM] [mailto:aphillips@webmethods.com]\n> Sent: 19 August 2003 20:11\n> To: ishida@w3.org\n> Subject: RE: Lloyd's FAQ resurfaces\n>\n>\n> Gee... you're not going to like me any more...\n>\n> I don't like the flavor of this FAQ. I agree with the exact\n> wording of the first couple of paragraphs. They capture the\n> point perfectly. But this is a non-trivial topic. My big\n> concern here is that it is basically too negative: it leaves\n> the impression of \"don't use A-L to be the locale\" without\n> suggesting the approaches that should be used to infer locale\n> (which, in my opinon, should start with A-L!). In fact, it\n> should say more of the opposite. The point here should really\n> be (and the stress moved around to make clear) that\n> Accept-Language can help indicate default locale and language\n> settings as a starting point to a user session, but that\n> these settings are not sufficient in all cases and in all\n> applications.\n>\n> For starters, you might mention that some users expect the\n> content to be related to the web address (e.g. example.de is\n> in German, while example.com is in English).\n>\n> Mentioning or having an FAQ link to how to do language choice\n> on a web page would also be useful. The design of a\n> particular application's handling of A-L will depend on your\n> applications users and requirements. For example, google.com\n> or hotmail/MSN displays their user interfaces in the topmost\n> language in the user-agent A-L stack. Other sites (altavista\n> or macromedia, for example) use the country-based site as the\n> starting point and allow visible navigation to other language\n> versions (they also allow the user to select specific\n> language preferences that are then stored in cookies to save\n> future navigation). A good example of tailoring is that if\n> you go to www.hotmail.com you will see the login page in your\n> current A-L language (for me at the moment this is Japanese),\n> but once I log in I always see English becuase that's how my\n> profile is set up.\n>\n> If A-L is good for content selection, why not locale selection?\n>\n> Well, why NOT locale selection? You can use A-L to create\n> locale objects or settings in many web platforms. .NET and\n> Java servlet both use and endorse the use of Accept-Language\n> to create the locale (CultureInfo or\n> java.util.Locale) default settings in web pages: this is the\n> default behavior in these systems. These may actually be used\n> to load system resources (resource bundles) in a particular\n> language, relating back to the original intent, which was\n> language selection and content loading/formatting at display time.\n>\n> There are places where the locale you obtain from the A-L is\n> inappropriate. Inferring more than user language choice is\n> potentially dangerous. Just because my langauge is set to\n> de-CH doesn't mean that I want to have you ship products that\n> I order from you to Switzerland. User profile and application\n> preferences should be carefully thought through and\n> country-of-origin information should probably not be inferred\n> from a locale, no matter how the locale is obtained.\n>\n> I'm not wild, as a result, about the bullet items in the\n> background section. These are all orthogonal or a bad idea to\n> infer from a locale to begin with. For example, inferring the\n> currency symbol is an awful idea in all cases. One should get\n> the currency associated with the data itself, not rely on\n> inference from locale. A-L as a locale indicator is no better\n> or worse at this than anything else. Mixing up concepts like\n> this is fatal to many applications. Why blame RFC3066 for this?\n>\n> So the summary of this is that I think the point is\n> insufficiently clear. We appear to be \"taking away\" the\n> existing locale mechanism without explaining what to do instead.\n>\n> Just my two cents.\n>\n> Addison\n>\n> Addison P. Phillips\n> Director, Globalization Architecture\n> webMethods, Inc. -- \"Global Business Visibility\"\n>\n> 432 Lakeside Drive, Sunnyvale, CA, USA\n> +1 408.962.5487 (office)\n> +1 408.210.3569 (mobile)\n> mailto:aphillips@webmethods.com\n>\n> Chair, W3C-I18N-WG, Web Services Task Force\n> http://www.w3.org/International/ws\n>\n> Internationalization is\n> an architecture.\n> It is not a feature.\n>\n> > -----Original Message-----\n> > From: public-i18n-geo-request@w3.org\n> > [mailto:public-i18n-geo-request@w3.org]On Behalf Of Richard Ishida\n> > Sent: Tuesday, August 19, 2003 11:03 AM\n> > To: 'GEO'\n> > Subject: Lloyd's FAQ resurfaces\n> >\n> >\n> >\n> >\n> > I have just had a editorial session with Lloyd and posted\n> what we hope\n> > is a final version of his FAQ 'Accept-Language used for locale\n> > setting' at\n> >\n> http://www.w3.org/International/questions/qa-accept-lang->\nlocales.html\n> >\n> > I propose we announce this to the world a week on Thursday.\n> >\n> > RI\n> >\n> > ============\n> > Richard Ishida\n> > W3C\n> >\n> > contact info: http://www.w3.org/People/Ishida/\n> >\n> > http://www.w3.org/International/\n> http://www.w3.org/International/geo/\n> >\n> > See the W3C\n> Internationalization FAQ page\n> > http://www.w3.org/International/questions.html\n> >\n>\n\n\n\n"
        },
        {
            "subject": "rtl now writing directions of commonly localized language",
            "content": "The updated page is now at:\n\nhttp://www.i18nguy.com/temp/rtl2.html\n\nPer today's discussion:\nchanged the title\nadded the intro to the links at the top of the page.\nadded microsoft's script definition\nlinked the first instance of script to the question what is a script\nswapped the first and second question.\n\nthose were my notes.\n\nthe suggestions were all very good, thanks.\n\nI think its baked now!\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Change to FAQ: CSS vs. markup for bidi suppor",
            "content": "Based on input from Steven Pemberton, I have slightly revised the FAQ at\nhttp://www.w3.org/International/questions/qa-bidi-css-markup.html to\nmore clearly indicate the difference between XHTML served as text/html\nor served as XML.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "FW: Lloyd's FAQ resurfaces (long",
            "content": "The virus problems on the list ate my message...\n\nSo here it is again. Slight revision to it in case the first one eventually\nsurfaces on the list ;-).\n\nAddison\n\n-----Original Message-----\nFrom: Addison Phillips [wM] [mailto:aphillips@webmethods.com]\nSent: Wednesday, August 20, 2003 2:05 PM\nTo: public-i18n-geo@w3.org\nCc: public-i18n-ws@w3.org\nSubject: FW: Lloyd's FAQ resurfaces (long)\n\n\nAll:\n\nSomewhere under Richard's response below is my initial reaction to Lloyd's\nFAQ about Accept-Language (A-L) and Locale. I have copied the WSTF list\nbecause our group is active in the area of locales.\n\nI agree with nearly all of the detail in the FAQ, but not with the overall\npresentation. I would prefer if the question were rephrased \"How can I\nobtain a locale from a browser (user-agent)? Can I get it from the\nAccept-Language?\" I would like the answer to be \"Yes\", rather than (as it\nappears now) to be \"No\". My concern is that the emphasis is in the wrong\nplace. If you re-emphasize the first paragraph like the following, the point\nis clearer:\n\n\"Yes, but it is not a good idea to use HTTP Accept-Language\n<emph>alone</emph> to determine the locale preferences of the user.\"\n\nThe page should include reference to the fact that many Web servers, server\nside scripting languages, and operating environments, by default, parse and\ninfer their native locale objects from Accept-Language. For example, .NET\nuses the A-L to determine the default CultureInfo, Java Servlet provides a\ngetLocale() and getLocales() pair of methods that parse A-L, and so forth.\nThese objects are very useful in obtaining resources and other \"language\npreference\" material. They are less useful, as pointed out by the FAQ, in\ndetermining many of the fine grained attributes of users or in designing the\ninternational behavior of a site. A language preference of es-MX doesn't\nnecessarily mean that a postal address form should be formatted or validated\nfor Mexican addresses. The user might still live in the USA (or elsewhere).\n\nThe rhetorical question \"Do you want to shove Polish content at a user just\nbecause they are running a user agent in Warsaw?\" might be answered yes in\nsome (many) cases. I think that the particular approach that a website takes\nwhen displaying the homepage depends on the application. If you don't have a\ncookie, logged in user, or other information about a request, it may\nactually be BETTER to follow what limited information you do have (including\nA-L) than ignore it. Do you want to shove French content at a user just\nbecause they haven't clicked on Polish yet? When all you have is an\nAccept-Language, what should your implementation decision be?\n\nFinally, I think that the bulleted list at the bottom isn't all that\nappropriate. Of the items listed, only one (date/time formats) can be wholly\nor partially inferred from a locale. The remainder (timezone, currency,\nmeasurement system, paper size, Tex's shoe size, physical location) are all\northogonal or, at best, distantly related to locale systems. In proper\ninternational design, one would not necessarily infer any of these from the\nuser's concrete locale setting, let alone from A-L.\n\nThanks for the opportunity to comment.\n\nAddison\n\nAddison P. Phillips\nDirector, Globalization Architecture\nwebMethods, Inc. -- \"Global Business Visibility\"\n\n432 Lakeside Drive, Sunnyvale, CA, USA\n+1 408.962.5487 (office)\n+1 408.210.3569 (mobile)\nmailto:aphillips@webmethods.com\n\nChair, W3C-I18N-WG, Web Services Task Force\nhttp://www.w3.org/International/ws\n\nInternationalization is an architecture.\nIt is not a feature.\n\n-----Original Message-----\nFrom: Richard Ishida [mailto:ishida@w3.org]\nSent: Wednesday, August 20, 2003 11:46 AM\nTo: aphillips@webmethods.com\nCc: Richard Ishida\nSubject: RE: Lloyd's FAQ resurfaces\n\n\nHi Addison,\n\nDon't worry, I still like you ;)  I think these are generally good\ncomments.  You could, if you want, send these to public-i18n-geo@w3.org\nnow - I signed you up a few days ago.\n\nI guess what you're missing is some information: we do have John Yunker\nworking on more comprehensive guidelines for navigation (and he's quite\nkeen on this topic).  The guidelines are more appropriate for 'how to'\ntype of information such as you are suggesting.  Ideally that would\nexist already, and this FAQ would point to it, but one step at a time...\n\n> If A-L is good for content selection, why not locale selection?\n\nHmm. I'm wavering on this...  Maybe we should soften the text a little.\n\nSome of the points you make lower down (eg. Currency) would be worth\nsending to the geo list.  Would you like to do that, adapting the stuff\nrelating to how-to's in the light of my earlier comment?\n\nRI\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/\n\nhttp://www.w3.org/International/\nhttp://www.w3.org/International/geo/\n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n> -----Original Message-----\n> From: Addison Phillips [wM] [mailto:aphillips@webmethods.com]\n> Sent: 19 August 2003 20:11\n> To: ishida@w3.org\n> Subject: RE: Lloyd's FAQ resurfaces\n>\n>\n> Gee... you're not going to like me any more...\n>\n> I don't like the flavor of this FAQ. I agree with the exact\n> wording of the first couple of paragraphs. They capture the\n> point perfectly. But this is a non-trivial topic. My big\n> concern here is that it is basically too negative: it leaves\n> the impression of \"don't use A-L to be the locale\" without\n> suggesting the approaches that should be used to infer locale\n> (which, in my opinon, should start with A-L!). In fact, it\n> should say more of the opposite. The point here should really\n> be (and the stress moved around to make clear) that\n> Accept-Language can help indicate default locale and language\n> settings as a starting point to a user session, but that\n> these settings are not sufficient in all cases and in all\n> applications.\n>\n> For starters, you might mention that some users expect the\n> content to be related to the web address (e.g. example.de is\n> in German, while example.com is in English).\n>\n> Mentioning or having an FAQ link to how to do language choice\n> on a web page would also be useful. The design of a\n> particular application's handling of A-L will depend on your\n> applications users and requirements. For example, google.com\n> or hotmail/MSN displays their user interfaces in the topmost\n> language in the user-agent A-L stack. Other sites (altavista\n> or macromedia, for example) use the country-based site as the\n> starting point and allow visible navigation to other language\n> versions (they also allow the user to select specific\n> language preferences that are then stored in cookies to save\n> future navigation). A good example of tailoring is that if\n> you go to www.hotmail.com you will see the login page in your\n> current A-L language (for me at the moment this is Japanese),\n> but once I log in I always see English becuase that's how my\n> profile is set up.\n>\n> If A-L is good for content selection, why not locale selection?\n>\n> Well, why NOT locale selection? You can use A-L to create\n> locale objects or settings in many web platforms. .NET and\n> Java servlet both use and endorse the use of Accept-Language\n> to create the locale (CultureInfo or\n> java.util.Locale) default settings in web pages: this is the\n> default behavior in these systems. These may actually be used\n> to load system resources (resource bundles) in a particular\n> language, relating back to the original intent, which was\n> language selection and content loading/formatting at display time.\n>\n> There are places where the locale you obtain from the A-L is\n> inappropriate. Inferring more than user language choice is\n> potentially dangerous. Just because my langauge is set to\n> de-CH doesn't mean that I want to have you ship products that\n> I order from you to Switzerland. User profile and application\n> preferences should be carefully thought through and\n> country-of-origin information should probably not be inferred\n> from a locale, no matter how the locale is obtained.\n>\n> I'm not wild, as a result, about the bullet items in the\n> background section. These are all orthogonal or a bad idea to\n> infer from a locale to begin with. For example, inferring the\n> currency symbol is an awful idea in all cases. One should get\n> the currency associated with the data itself, not rely on\n> inference from locale. A-L as a locale indicator is no better\n> or worse at this than anything else. Mixing up concepts like\n> this is fatal to many applications. Why blame RFC3066 for this?\n>\n> So the summary of this is that I think the point is\n> insufficiently clear. We appear to be \"taking away\" the\n> existing locale mechanism without explaining what to do instead.\n>\n> Just my two cents.\n>\n> Addison\n>\n> Addison P. Phillips\n> Director, Globalization Architecture\n> webMethods, Inc. -- \"Global Business Visibility\"\n>\n> 432 Lakeside Drive, Sunnyvale, CA, USA\n> +1 408.962.5487 (office)\n> +1 408.210.3569 (mobile)\n> mailto:aphillips@webmethods.com\n>\n> Chair, W3C-I18N-WG, Web Services Task Force\n> http://www.w3.org/International/ws\n>\n> Internationalization is\n> an architecture.\n> It is not a feature.\n>\n> > -----Original Message-----\n> > From: public-i18n-geo-request@w3.org\n> > [mailto:public-i18n-geo-request@w3.org]On Behalf Of Richard Ishida\n> > Sent: Tuesday, August 19, 2003 11:03 AM\n> > To: 'GEO'\n> > Subject: Lloyd's FAQ resurfaces\n> >\n> >\n> >\n> >\n> > I have just had a editorial session with Lloyd and posted\n> what we hope\n> > is a final version of his FAQ 'Accept-Language used for locale\n> > setting' at\n> >\n> http://www.w3.org/International/questions/qa-accept-lang->\nlocales.html\n> >\n> > I propose we announce this to the world a week on Thursday.\n> >\n> > RI\n> >\n> > ============\n> > Richard Ishida\n> > W3C\n> >\n> > contact info: http://www.w3.org/People/Ishida/\n> >\n> > http://www.w3.org/International/\n> http://www.w3.org/International/geo/\n> >\n> > See the W3C\n> Internationalization FAQ page\n> > http://www.w3.org/International/questions.html\n> >\n>\n\n\n\n"
        },
        {
            "subject": "Re: XHTML served as application/xml+xhtm",
            "content": "Hello Steven,\n\nSome comments/questions/proposals below.\n\nAt 15:41 03/08/22 +0200, Steven Pemberton wrote:\n\n>From: \"Richard Ishida\" <ishida@w3.org>\n> > Following our discussion last Friday I proposed to amend the Q&A at\n> > http://www.w3.org/International/questions/qa-bidi-css-markup.html by\n> > inserting a second para in the section Answer -> XHTML/HTML that reads\n> > as follows:\n> >\n> > ======================\n> > (There is an exception to this rule. If the XHTML is served as\n> > <code>application/xhtml+xml</code>, rather than <code>text/html</code>\n> > it is treated by the user agent as XML rather than HTML, and so needs\n> > CSS to map the markup to the appropriate display behaviour, as described\n> > in '<a href=\"#xml\">General XML-based markup languages</a>' above.)\n> >\n> >  ======================\n> >\n> > Some questions were raised about its validity in our GEO telecon. Would\n> > you mind casting an eye over this para and letting us know whether it\n> > looks correct / adequate to you?\n>\n>(Sorry about the delay in replying)\n>\n>I think there is a confusion here about what determines whether a document\n>is HTML or XHTML.\n>\n>Let me try and explain: if I serve up an HTML document as text/plain, it\n>becomes a text document, not an HTML document, and the rules for text/plain\n>apply to it, not the rules for text/html. (IE does this wrong by the way).\n>\n>If I serve up an XHTML document as text/html, it becomes an HTML document,\n>not XHTML, and so the rules for HTML apply (including the ones in CSS).\n>\n>If I serve an XHTML document as application/xhtml+xml (or text/xml), only\n>then is it really XHTML, and the HTML rules no longer apply.\n>\n>So there is nothing wrong with the new paragraph, it is the paragraph that\n>it applies to that is wrong in bundling HTML and XHTML together. They are\n>different beasts, and should have different sections.\n>\n>So this paragraph is wrong:\n>\n><<<\n>XHTML/HTML\n>\n>Use markup only. The CSS2 recommendation recommends the use of markup for\n>bidi text in HTML. In fact it goes as far as to say that conforming HTML\n>user agents may ignore CSS bidi properties. This is because the HTML\n>specification clearly defines the expected behaviour of user agents with\n>respect to the bidi markup.\n> >>>\n>\n>Replace it with something like:\n>\n><<<\n>HTML\n>\n>Use markup only. The CSS2 recommendation recommends the use of markup for\n>bidi text in HTML. In fact it goes as far as to say that conforming HTML\n>user agents may ignore CSS bidi properties. This is because the HTML\n>specification clearly defines the expected behaviour of user agents with\n>respect to the bidi markup.\n>\n>XHTML\n>\n>XHTML (served as text/xml, application/xml or application/xhtml+xml) is XML\n>and so needs CSS to map the markup to the appropriate display behaviour, as\n>described in '<a href=\"#xml\">General XML-based markup languages</a>' above.\n>Note that an XHTML document served as text/html is treated as an HTML\n>document, not an XHTML one, and so the HTML rules apply, not the XHTML ones.\n> >>>\n\nI think this is correct, but not complete. The idea with generic XML,\nbidi attributes/elements, and CSS, is that the semantics of the bidi\nattributes/elements is defined by the document type, and that CSS is\nused on a *per document type* base to map from the document-specific\nbidi markup to the styling properties that the rendering engine will\nhandle.\n\nSo for XHTML (as well as for every other document type with bidi markup),\nthis means:\n- When defining the document type, provide a default bidi stylesheet.\n- When using the document type, include this default bidi stylesheet.\n   Never ever change it, except for very very special cases (e.g.\n   transliterating Yiddish to Latin by using a Hebrew font with Latin\n   glyphs; might better do that with XSLT anyway).\n\nSo I think there are two things needed:\n- Make sure that we provide the bidi part of the (X)HTML default stylesheet\n   in a way that is easy to include in a CSS stylesheet. In comments\n   in that stylesheet, clearly say what it is and that it isn't\n   supposed to be changed. My understanding is that currently, the\n   default stylesheet rules are available somewhere in the CSS spec,\n   but not in their own file. I think we should take this back to the\n   HTML and CSS WGs.\n- Tell people to include that stylesheet (be it with @include, with\n   a separate <link>, or by actual copy,...), and NOT to ever touch it.\n   This is something that we should do in the FAQ, and can do now\n   (and add better pointers later).\n\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "RE: rtl now writing directions of commonly localized language",
            "content": "Tex,\n \nI like the new intro paragraph.  It ties things up nicely.\n \nRegards, Russ\n\n\n\n"
        },
        {
            "subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle",
            "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n"
        },
        {
            "subject": "Re: XHTML served as application/xml+xhtm",
            "content": "* Steven Pemberton wrote:\n>Let me try and explain: if I serve up an HTML document as text/plain, it\n>becomes a text document, not an HTML document, and the rules for text/plain\n>apply to it, not the rules for text/html. (IE does this wrong by the way).\n>\n>If I serve up an XHTML document as text/html, it becomes an HTML document,\n>not XHTML, and so the rules for HTML apply (including the ones in CSS).\n\nFrom a specification point of view this scenario is undefined. From a\ncommon browser behaivour point of view some rules apply but certainly\nnot HTML rules. If HTML rules applied to a common construct like <br />\nthe user agent would render the > as character data (as Emacs/W3 does).\n\nThe CSS Validator for example uses an XML processor to parse XHTML\ndocuments regardless of MIME Type. This is causing trouble for common\nISO-8859-1 encoded XHTML documents like\n\n  Content-Type: text/html\n\n  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n   \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n  <html xmlns='http://www.w3.org/1999/xhtml'>\n  <head>\n    <title></title>\n    <meta\n       http-equiv='Content-Type'\n       content='text/html;charset=iso-8859-1' />\n  </head>\n  <body>\n    <p>Bj?rn</p>\n  </body>\n  </html>\n\nThe W3C HTML Validator says the document is fine, the W3C CSS Validator\nsays the document is broken. The document conforms neither to HTML 2.0,\n3.2, 4.0 or 4.01 nor to XHTML 1.0. How are the two user agents supposed\nto handle the document and what should they say about it?\n\n>If I serve an XHTML document as application/xhtml+xml (or text/xml), only\n>then is it really XHTML, and the HTML rules no longer apply.\n\n>XHTML (served as text/xml, application/xml or application/xhtml+xml) is XML\n>and so needs CSS to map the markup to the appropriate display behaviour, as\n>described in '<a href=\"#xml\">General XML-based markup languages</a>' above.\n\nI strongly disagree. If XHTML user agents are not required to process\nbidi markup according to the rules in HTML 4.01 and as I do not see bidi\nmarkup beeing a special case in XHTML, this would mean that you would\nalso need external means to do forms, images, links, scripting or frames\nin XHTML and it would be impossible to author XHTML documents that\nconform to WCAG, i.e., documents that work without style sheets. In\nfact, both, XHTML 1.0 and XHTML M12N say\n\n[...]\n  When the user agent claims to support facilities [elements,\n  attributes, and the semantics associated with those elements and\n  attributes] defined within this specification or required by this\n  specification through normative reference, it must do so in ways\n  consistent with the facilities' definition. \n[...]\n\nand I don't see why bidi markup should be an exception here. There is no\ndifference between bidi markup in HTML and XHTML.\n\n\n\n"
        },
        {
            "subject": "New WG member: Francois Richar",
            "content": "I'd like to welcome Fran?ois Richard from HP, based in Grenoble, as the\nlatest member of the GEO Task Force and I18N WG.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nSee the W3C Internationalization FAQ page\nhttp://www.w3.org/International/questions.html\n\n\n\n"
        },
        {
            "subject": "regret",
            "content": "I won't make the meeting today.\ntex\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Notes from GEO teleconf 2003-082",
            "content": "Present: Phil, Martin\n\nDuration: ca. 20 min\n\nWe talked a bit about the redesign of /International and other pages.\n\nReminder: Next week (Sept. 3rd), the teleconference is canceled due\n           to the Unicode Conference. See you all there!\n\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "RE: JSP containers and default charset (was: Re  DefaultCharset   considered  harmful",
            "content": "On Sun, 30 Nov 2003, Addison Phillips [wM] wrote:\n\nHi Addison,\n\nThanks for the clarification. The more I wrote about it, the clearer it\nbecame how ignorant I am about JSP (which I took up just a week ago).\n\n> > Someone might argue that there need to be two separate 'directives' for\n> > two roles, but I guess it's all right to overload pageEncoding directive.\n\n\n> Not quite: there are two directives: pageEncoding and contentType and they\n> can indicate *different* encodings. If you use pageEncoding on its own, it\n> is assumed that the encoding of the source JSP file should be the encoding\n> used to deliver the file. If you use contentType on its own, then the page\n> is delivered in the encoding specified, but read as Latin-1. If you want to\n> use one encoding (say KS-X-1001) for the JSP file and a different encoding\n> for the delivery (say UTF-8) then you can use both directives together.\n\n  Here's one thing I know more than you do :-). KS X 1001 is not a\ncharacter encoding scheme but just a coded character set without\nLatin letters, numbers and punctuations so that on its own it's\nvirtually useless. It always has to be used along with US-ASCII (ISO\n646:IRV)/ISO-646:KR in CES'(character encodings/MIME charset) like EUC-KR\nand ISO-2022-KR. That is, virtually NONE of Korean text can be written\nwith characters drawn _only_ from KS X 1001. When it comes to JSP, it's\neven more so because all those ASCII charcters are NOT covered by KS X\n1001 unless javac somehow can understand double/full width Latin letters,\nnumbers and punctuations in KS X 1001, which I don't think is the case.\n\n\n> For example, see Norbert Lindeberg's excellent article here:\n> http://developer.java.sun.com/developer/technicalArticles/Intl/MultilingualJSP/\n... snip (good tips/advices) ...\n\nThanks again for the reference and tips.\n\nBTW, wouldn't it be nice if it's possible to specify the DTP with a\nsimple JSP directive instead of having to include it verbatim?  I wrote\na macro for my editor so that I can enter DTDs for xhtml 1.0 and html\n4.x strict/loose rather easily when I edit html/xhtml/jsp files, but a\nsimple JSP directive would make it a lot more pages (generated by JSP)\ncompliant to the standard in that they have the DTD declared.  By the same\ntoken, it'd be nice (although not necessary because the http header is\nemitted to that effect) if  'contentType' directive with __'text/html;\ncharset=XXXX'__ automatically adds '<meta http-equiv.....'  to <head>\nif not present (the same is true of PHP. I don't know what ASP does\nhere.) I realize that both are rather tricky to implement given the\nway JSP files are processed (as you explained in great details) before\nthey're delivered. Maybe, we just have to live with having to  add\nDTD declation manually.\n\n  Jungshik\n\n\n\n"
        },
        {
            "subject": "RE: JSP containers and default charset (was: Re  DefaultCharset  considered  harmful",
            "content": ">\n>   Here's one thing I know more than you do :-). KS X 1001 is not a\n> character encoding scheme but just a coded character set without\n> Latin letters, numbers and punctuations so that on its own it's\n> virtually useless. It always has to be used along with US-ASCII (ISO\n> 646:IRV)/ISO-646:KR in CES'(character encodings/MIME charset) like EUC-KR\n> and ISO-2022-KR....\n>\nYou're right. I was trying to avoid the old \"ksc5601 is obsolete\" issue. I\nsuppose I could have said \"MS949\" or \"EUC-KR\"... :-).\n\nAddison\n\nAddison P. Phillips\nDirector, Globalization Architecture\nwebMethods | Delivering Global Business Visibility\nhttp://www.webMethods.com\nChair, W3C Internationalization (I18N) Working Group\nChair, W3C-I18N-WG, Web Services Task Force\nhttp://www.w3.org/International\n\nInternationalization is an architecture.\nIt is not a feature.\n\n\n\n"
        },
        {
            "subject": "For discussion on Wed: Articles pag",
            "content": "Chaps,\n\nI have posted a page at http://www.w3.org/International/articles.html\nthat I think we should link to from the site.  Please check it out and\nsend comments before Wednesday's meeting.\n\nI have one big reservation about this page... (cf\nhttp://www.w3.org/International/questions.html )  I feel it is a bit\nartificial to split up content according to whether it is an FAQ or an\n'article', or soon a 'tutorial'.  I suspect people might prefer to see\nall useful information we have relating to, say, Character Encoding in\none place - perhaps with small icons to quickly distinguish between FAQ,\narticle or tutorial.  What do you think?\n\nI'd also like to include another link on the page, as follows:\n\n================================\nhttp://people.w3.org/rishida/scripts/bidi/\nWhat you need to know about the bidi algorithm and inline markup\nRevised 19 Aug 2003  \nby Richard Ishida \nDescribes some of the basic principles underlying how the Unicode\nBidirectional Algorithm works, and some scenarios where inline markup or\ncodes are needed to correctly render web content written in a\nright-to-left script.=================================\n\nThis would involve me making a copy of the html page on the w3c site,\n(and perhaps changing the styling??)  Perhaps we should also revisit the\nstyling of the pages already linked to from the articles page?\n\nPlease read this bidi article and send comments to the list before\nWednesday.\n\nDuring Wednesday's meeting I'd like to:\n1. discuss the best way forward for the articles.html page\n2. take a decision to include the bidi article, and decide whether we\nneed to restyle\n\nThanks,\n\nRI\n\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "New International web page suggestion: MTG PREREA",
            "content": "Chaps,\n\nEnclosed is a rough sketch proposal from Phil Arko for a new look for\nthe I18N Activity home page (the current version is\nhttp://www.w3.org/International/ ).  \n\nPlease send in any thoughts you have on this, and let's discuss on\nWednesday.  I have already shown it to Karl Dubost (QA), who agreed with\nthe sentiment, and Janet Daly (Head of Communications) who thought it\nlooked really nice.\n\nThere is also an interest in this from the WAI Education & Outreach\nfolks.  Shawn Henry is leading a task force looking at redesigning the\nWAI web site http://www.w3.org/WAI/EO/2003/wstf (with the possibility of\nspreading the lessons they learn to other parts of the W3C).  I'd like\nto encourage Phil and Leslie to become involved in that activity, if\nthey are willing/interested.  The WAI folks have been doing user\nanalysis so far, but Shawn asked me to send a copy of this since I\nshowed it to her recently.\n\nRI\n\n\nMY THOUGHTS\n\nI quite like this approach.  Phil is suggesting that we make our page\nmore 'graphical', reducing the wordage and scrolling found on many W3C\nhome pages, so that it looks more like the kind of thing that UI\ndesigners out there are actually producing. The underlying message is:\n\"W3C stuff applies to cool site designers too\" - which I think is a very\nvaluable idea for I18N to consider given our outreach mission.\n\nThis is still just an illustration - see the notes below.  \n\n\nNOTES\n\n\n-Important for w3c to have something that looks cool because many\nmodern designers would say to themselves: \"if it's not representative of\nwhat I want to design why should I read it\".  For education and outreach\nthis is a key audience.\n\n-Font: wants better more readable font - may use Verdana as the\nprimary setting - good because geared to younger content audience\n\n-Content: most of the readable content removed from this page but\naccessible with a single click - benefits: cleaner navigation (from the\ntutorial I attended last week, this appears to be standard usability\npractise); actual information gathered in a single location (better\nmaintainability and cleaner reading experience for visitors).\n\n-Flags : Phil took the photo himself, so no copyright issues -\nwants\nto take another with less building in the background\n\n-Colour scheme: builds off W3C home page - infers branding\n\n-Layout: Trying to keep clean - layer motif highlights key\ninformation - want to give idea of building up information - news and\nquestions are highest layer\n\n-Links: suggests we get away from underlining for this page -\nconsistent with current trends - links still blue though\n\n-Expansion: Horizontal growth for question and news - thought\ngiven to the page 'fold' \n\n-Pages below: capture the theme w3c & internationalization -\ncontinue colour scheme - consistent hat - eg .aol time warner - perhaps\nsome breadcrumbs, \"sometimes don't know where you're at on W3C pages\"\n\n-My requirements: utf-8 encoded xhtml strict with all appropriate\nstyling in stylesheet - minimal text in graphics - good degradability\nfor older browsers and accessibility - ability to add scraping related\ninformation\n\n-I'm starting to think we should replace the heading Question of\nthe Week (currently Latest FAQ on the real site) with \"Recently\npublished\" or something similar.  Then include links to new stuff, be it\nFAQs, articles or tutorials - perhaps using standard icons to identify\neach - this ties in with the idea I had recently to unify the pages\npointing to FAQs, articles and tutorials.\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "SWAD Europe Marketin",
            "content": "Dear All, we are currently doing some preliminary research into ways in \nwhich we can market SWAD Europe.\n\nWe are considering having some sort of SWAD-E gadget or toy to give out\nto people and although we have a few ideas in mind we would welcome any\nsuggestions from yourselves.\n\nYou may have attended a conference or workshop where you were given or \nsaw a piece of promotional material that interested you, if so I'd like\nto know.\n\nPlease email this list if you have any ideas or suggestions. \n\nThank you\nCaroline\n\n----------------------\nCaroline V Meek\nPersonnel and Admin Coordinator\nInstitute for Learning and Research Technology\nUniversity of Bristol\n8-10 Berkeley Square\nBristol\nBS8 1HH\nTel: 0117 9287122\nFax: 0117 9287112\nCaroline.Meek@bristol.ac.uk\nwww.ilrt.bris.ac.uk\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-1203 at 19:00 UTC, 11am Pacific,  2pm Eastern, 19:00 UK, 20:00 France, 6am Australia (next day!",
            "content": "GEO Work Items: http://www.w3.org/International/2003/plan.html\n\n\nMeetings\n\n-Xmas arrangements\n\n\nInfo Share\n\n-bring your own contributions !\n\n\nDiscussion\n\n-articles page\nhttp://www.w3.org/International/articles.html\ncontent ok?\nseparate page or merge with FAQs?\n\n-new article review & approval\nwhat you need to know about bidi and inline markup\nhttp://people.w3.org/rishida/scripts/bidi/\n\n-new Activity page look & feel\n\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Dec/0003.html\n\n-GEO activity review & planning \nsee http://www.w3.org/International/2003/plan.html\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "WAI discussion on marking up language chang",
            "content": "I fell upon an interesting thread on the WCAG list which you might be\ninterested in following.  Starts at\nhttp://lists.w3.org/Archives/Public/w3c-wai-gl/2003OctDec/0411.html\n\nRaised the question in my mind \"When tagging language variations in\ntext, where do you draw the line between what is clearly a foreign\nlanguage phrase, what is a neologism drawn from a foreign source, and\nwhat is one of the latter that has become an adopted part of the\nlanguage?\"\n(http://lists.w3.org/Archives/Public/w3c-wai-gl/2003OctDec/0425.html)\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Updated list-styletype tes",
            "content": "Chaps,\n\nSome comments from Jungshik prompted me study list-style-type more\nclosely and to create a better version of the list-style-type test page.\nAt the same time, I finally wrapped the tests in some formatting\n(similar to the FAQs for now).   See\nhttp://www.w3.org/International/tests/test-list-item-type.html\n\nPlease let me know if you spot any blunders.\n\nRI\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Re: Updated list-styletype tes",
            "content": "Richard,\n\nOne suggestion- we should have a place where people can report results\nwith different browsers, platforms, versions, and a list showing what\npeople report.\n\ntex\n\nRichard Ishida wrote:\n> \n> Chaps,\n> \n> Some comments from Jungshik prompted me study list-style-type more\n> closely and to create a better version of the list-style-type test page.\n> At the same time, I finally wrapped the tests in some formatting\n> (similar to the FAQs for now).   See\n> http://www.w3.org/International/tests/test-list-item-type.html\n> \n> Please let me know if you spot any blunders.\n> \n> RI\n> ============\n> Richard Ishida\n> W3C\n> \n> contact info: http://www.w3.org/People/Ishida/\n> \n> http://www.w3.org/International/\n> http://www.w3.org/International/geo/\n> \n> W3C Internationalization FAQs\n> http://www.w3.org/International/questions.html\n> RSS feed: http://www.w3.org/International/questions.rss\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: Updated list-styletype tes",
            "content": "Yep.  That's already in the\nhttp://www.w3.org/International/2003/plan.html doc, under Test\ndevelopment & deployment.\n\nWe already have a way to capture these results in the guidelines - we\ncan list summary information for our baseline and above versions, and we\ncan capture detailed comments too.  What we do need to do, however, is\nrun the tests on our baseline browsers - in particular some of the Mac\nbrowsers - and record the results somewhere.  \n\nThe key thing that's missing at the moment is *someone* to take a stab\nat making it happen.  Anyone interested?\n\nRI\n\n\n\n> -----Original Message-----\n> From: Tex Texin [mailto:tex@i18nguy.com] \n> Sent: 06 December 2003 02:38\n> To: ishida@w3.org\n> Cc: public-i18n-geo@w3.org\n> Subject: Re: Updated list-style-type test\n> \n> \n> Richard,\n> \n> One suggestion- we should have a place where people can \n> report results with different browsers, platforms, versions, \n> and a list showing what people report.\n> \n> tex\n> \n> Richard Ishida wrote:\n> > \n> > Chaps,\n> > \n> > Some comments from Jungshik prompted me study list-style-type more \n> > closely and to create a better version of the list-style-type test \n> > page. At the same time, I finally wrapped the tests in some \n> formatting\n> > (similar to the FAQs for now).   See\n> > http://www.w3.org/International/tests/test-list-item-type.html\n> > \n> > Please let me know if you spot any blunders.\n> > \n> > RI\n> > ============\n> > Richard Ishida\n> > W3C\n> > \n> > contact info: http://www.w3.org/People/Ishida/\n> > \n> > http://www.w3.org/International/ \n> http://www.w3.org/International/geo/\n> > \n> > W3C \n> Internationalization FAQs \n> > http://www.w3.org/International/questions.html\n> > RSS feed: http://www.w3.org/International/questions.rss\n> \n> -- \n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n>                          \n> XenCraft            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n> \n\n\n\n"
        },
        {
            "subject": "Time zone names (was REMINDER: CharMod Call Today",
            "content": "Hmm.  Some thoughts around the topic...\n\n> [1] Let's not use GMT (obsoleted almost 30 years ago). \n\nSince it's still in vigorous use here, obviously nobody dared tell the\nBritish about that  ;-)  More seriously I've come across a lot of people\n(not just in Europe) who don't know what UTC is, but recognise GMT - so\nperhaps we should use both.  \"UTC/GMT\"\n\n> Instead, we have to use UTC. And, 'Eastern' and 'Pacific' are \n> too US-centric, aren't they?\n> :-) US EST and US PST would be better (or UTC -0500 and UTC \n\nWell US EST is pretty US centric too ;-).  I guess the key thing is that\npeople from that area recognise the location.\n\nActually note that EST stands for Eastern Standard Time, which becomes\nEDT Eastern Daylight Time during the summer.  One is UTC-4 and the other\nis UTC-5.  If daylight savings changes at the same time, as it did in\nOctober, using a city name or \"Eastern\" may avoid a little confusion\nhere.\n\nBtw, these 3 letter abbreviations are potentially problematic in more\nways than one.  Some areas don't use them at all.  Some acronyms are\nambiguous, eg. AST where A = Alaska or Atlantic.\n\n\n> -0800). See  (cited in \n> http://bugzilla.mozilla.org/show_bug.cgi?id=224744)\n> \n> Short \n> and sweet: \n>\nhttp://lists.debian.org/debian-boot/1999/debian-boot-199901/msg00450.htm\nl\n\n>More than you ever wanted to know:\nhttp://www.apparent-wind.com/gmt-explained.html\n\n\nThis and other places actually seem to me to make the point that GMT is\nused as the starting point for time zones around the world.  UTC is for\nGPS and other very precise measurements. Note also\nhttp://wwp.greenwichmeantime.com/home.htm that says \"Greenwich Mean Time\nis international time, the basis of the world time clock.  ... Defines\ndate and time and exact time.  The atomic time clock is adjusted by leap\nseconds to maintain synchronicity with GMT.\"  Not the other way around.\n\n\n\n"
        },
        {
            "subject": "Re: Time zone names (was REMINDER: CharMod Call Today",
            "content": "On Mon, 8 Dec 2003, Mark Davis wrote:\n\n> have a meeting \"Tuesdays at 10:00 PT\" (Pacific Time), that carries more (and\n> different) information than saying \"Tuesdays at 10:00 GMT-08:00\". For part of\n> the year -- as a matter of fact, for a *majority* of the year -- it is\n> \"Tuesdays at 10:00 GMT-07:00\". The problem is that you have to go look up\n>  against the\n\n  Well, that's why I speficically say US PST with 'S'. If this had been\nwhen the daylight saving time is in effect, I would have written 'US PDT'.\nNeedless to say, always using UTC is clear and unambigous. If the wall\nclock time is to be used, it can be followed by 'UTC -0800 (US PST)'\nor 'UTC -0700 (US PDT)'. 'US PDT' is enclosed by parentheses because\nI believe that should only be 'parenthetical'. I wouldn't expect any\n'layperson' on the street to do that, but this is on I18N list.\n\n\n> What would truely be useful would be if all those countries of the world that\n> use summer time could standardize on two dates during the year to switch their\n> clocks (e.g. 3th Sundays in March and September, near the ??quinoctia). Then you\n\n  Obviously, that doesn't work even if we put aside arising from\ndifferent climates in different regions in the _same_ hemisphere because\nthere are two hemisphers in a sphere :-)\n\n> could use three appreviations to fully specify the time without needing\n> to know detailed daylight conventions:\n\n  I'm not sure what you meant by 'three appreviations'. Did you mean\nthings like PST, EST, JST, and BST? I don't think using them is a good\nidea in any way except as an aid to 'humans'.\n\n\n> - Tuesdays at 10:00 GMT-08:00 = constant offset -08:00 from GMT\n> - Tuesdays at 10:00 GMT-08:00N = GMT-08:00 from Sept-March, GMT-07:00 from\n> March-Sept\n> - Tuesdays at 10:00 GMT-08:00S = GMT-08:00 from March-Sept, GMT-07:00 from\n> Sept-March\n>\n> (Cross-posting to the ICU list, since there was a recent discussion of timezones\n> there.)\n\n  Is there any reason you stick to GMT (that got obsoleted/abolished a\nlong long time ago) instead of UTC? I also filed a bug on ICU on this\nissue a long time ago, but haven't heard back.\n\n  Jungshik\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-1126 at 19:00 UTC/GMT, 11am San Jose,  2pm Boston, 19:00 London, 20:00 Paris, 6am Melbourne (next day!",
            "content": "GEO Work Items: http://www.w3.org/International/2003/plan.html\n\n\nMeetings\n\n-Xmas arrangements\n\n\nInfo Share\n\n-bring your own contributions !\n\n\nDiscussion\n\n-articles page  **** PLEASE REVIEW IN ADVANCE\nhttp://www.w3.org/International/articles.html\nseeking approval to publish\n\n-new article **** PLEASE READ IN ADVANCE !\nwhat you need to know about bidi and inline markup\nhttp://people.w3.org/rishida/scripts/bidi/\nseeking approval to publish\n\n-new Activity page look & feel\n\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Dec/0003.html\nhow do we move forward?\n\n-GEO activity review & planning \nsee http://www.w3.org/International/2003/plan.html\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Test page renovation",
            "content": "Chaps,\n\n(Heads up.)\n\nI have spent a good deal of time since Friday lunch time studying and\nupdating the tests we had.  You can see the final result for the one set\nI have completed at\nhttp://www.w3.org/International/tests/test-bidi-blocks.html .\n\nI used the CSS templates to rebuild the tests in this fashion, so\nhopefully CSS and others will be able to pick up these tests for their\nown test suites.  I also spent some time reading about how to write\ntests [http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html],\nand have made some changes to enable testers to draw conclusions quickly\n(eg. the image for comparison in the bidi tests, green colors to come in\nthe :lang tests, etc.).\n\nI'll try to transform some more tests tomorrow (which is not so far\naway, so I'd better stop now).\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Re: SWAD Europe Marketin",
            "content": "I rather like these:\nhttp://shop.store.yahoo.com/elogo/tangletoy.html\n\nand I've got one of those light-up hi-bounce balls - some company had\nthem at xml europe 2001 (but mine's from Hawaii sea-world)\nhttp://www.centurynovelty.com/cart/general/balls/BallsPage4.htm\n\nI also got a rather nice neuweb blue curcular enamel badge from IST2002\n\nLibby\n\n\nOn Fri, 29 Nov 2002, CV Meek wrote:\n\n>\n> Dear All, we are currently doing some preliminary research into ways in\n> which we can market SWAD Europe.\n>\n> We are considering having some sort of SWAD-E gadget or toy to give out\n> to people and although we have a few ideas in mind we would welcome any\n> suggestions from yourselves.\n>\n> You may have attended a conference or workshop where you were given or\n> saw a piece of promotional material that interested you, if so I'd like\n> to know.\n>\n> Please email this list if you have any ideas or suggestions.\n>\n> Thank you\n> Caroline\n>\n> ----------------------\n> Caroline V Meek\n> Personnel and Admin Coordinator\n> Institute for Learning and Research Technology\n> University of Bristol\n> 8-10 Berkeley Square\n> Bristol\n> BS8 1HH\n> Tel: 0117 9287122\n> Fax: 0117 9287112\n> Caroline.Meek@bristol.ac.uk\n> www.ilrt.bris.ac.uk\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Test page renovation",
            "content": "Btw, the actual tests pages (eg.\nhttp://www.w3.org/International/tests/bidi-blocks2-sec.html) are in fact\nan HTML wrapper page that pulls in an XHTML test page using the <object>\ntag.  I would have prefered to have had both files in XHTML, but I found\nthat the included file doesn't fill the available space in Firebird if\nyou don't have an HTML wrapper.  (You get a scrollable view about 5/6\nlines deep.)\n\nDoes anyone know why?\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\n> Sent: 08 December 2003 23:05\n> To: public-i18n-geo@w3.org\n> Subject: Test page renovations\n> \n> \n> \n> Chaps,\n> \n> (Heads up.)\n> \n> I have spent a good deal of time since Friday lunch time \n> studying and updating the tests we had.  You can see the \n> final result for the one set I have completed at \n> http://www.w3.org/International/tests/test-bidi-blocks.html .\n> \n> \n> I used the CSS templates to rebuild the tests in this \n> fashion, so hopefully CSS and others will be able to pick up \n> these tests for their own test suites.  I also spent some \n> time reading about how to write tests \n> [http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html]\n,\nand have made some changes to enable testers to draw conclusions quickly\n(eg. the image for comparison in the bidi tests, green colors to come in\nthe :lang tests, etc.).\n\nI'll try to transform some more tests tomorrow (which is not so far\naway, so I'd better stop now).\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Re: Test page renovation",
            "content": "Richard,\n\nA couple comments-\n\nAre we sure that embedding the test page as an object in another page\nisn't affecting the results?\n\nThe objects are typed as text/html. Might be interesting to also type\nthem as xml.\n\nOn the scroll bar test I see two scrollbars in IE 6. One in the frame\nthe other for the page.\n\nIt would be nice if instead of test1, test2, there was a description of\nwhat was being tested or how the tests are different. Otherwise, if\ntestn fails, we don't have a clue as to what is entailed in that test.\n\nThe tests are nice. Is the technique with <object> supported in most\nbrowsers now?\n\ntex\n\n\nRichard Ishida wrote:\n> \n> Chaps,\n> \n> (Heads up.)\n> \n> I have spent a good deal of time since Friday lunch time studying and\n> updating the tests we had.  You can see the final result for the one set\n> I have completed at\n> http://www.w3.org/International/tests/test-bidi-blocks.html .\n> \n> I used the CSS templates to rebuild the tests in this fashion, so\n> hopefully CSS and others will be able to pick up these tests for their\n> own test suites.  I also spent some time reading about how to write\n> tests [http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html],\n> and have made some changes to enable testers to draw conclusions quickly\n> (eg. the image for comparison in the bidi tests, green colors to come in\n> the :lang tests, etc.).\n> \n> I'll try to transform some more tests tomorrow (which is not so far\n> away, so I'd better stop now).\n> \n> RI\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> contact info: http://www.w3.org/People/Ishida/\n> \n> http://www.w3.org/International/\n> http://www.w3.org/International/geo/\n> \n> W3C Internationalization FAQs\n> http://www.w3.org/International/questions.html\n> RSS feed: http://www.w3.org/International/questions.rss\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: Test page renovation",
            "content": "> -----Original Message-----\n> From: Tex Texin [mailto:tex@i18nguy.com] \n> Sent: 09 December 2003 05:48\n> To: ishida@w3.org\n> Cc: public-i18n-geo@w3.org\n> \n> \n> Richard,\n> \n> A couple comments-\n> \n> Are we sure that embedding the test page as an object in \n> another page isn't affecting the results?\n\nHopefully the opposite is true.  The actual test file is isolated from\nany CSS used for the wrapper and can be picked up as is by anyone\nwanting to use it for the CSS or HTML etc test suites.  I'm just\nfollowing the advice for test suite development given by the CSS test\nsuite guidelines.\nhttp://www.w3.org/Style/CSS/Test/testsuitedocumentation.html\n\n\"The navigation page transcludes the test page with an <OBJECT> element,\nwhich references the test file using the data attribute and explicitly\nsets the type of the expected data to \"text/html\". In order to encourage\na user agent to use the entire width of the document, and the remainder\nof the document, both the width and height attributes are set to 100%.\n\n\"The <OBJECT> element was chosen because it is present in all \"current\"\nversions of HTML, from HTML 4.0 Transitional, to XHTML Basic, to XHTML\n1.1. This permits user agents which support any one of these languages\nto easily utilize the navigational pages. In addition, the <OBJECT>\nelement provides an excellent immediate fall back mechanism for user\nagents that either happen to not support <OBJECT>, or that have\ndifficulties transcluding HTML content.\n\n\"Inside the <OBJECT> element is a simple Test hyperlink which directly\nlinks to the test file. Thus user agents that do not recognize the\n<OBJECT> element and therefore ignore its markup, show the simple\nhyperlink instead, thereby providing access to the test file. ....\n\n\"Note that the navigation file has no test content whatsoever. This\nallows the test file to be updated to fix problems in tests without\nhaving to update navigation files.\"\n\nNote that the HTML test suite uses the same approach.  As for <object>\nsupport, I don't know but I guess it must be fairly widespread if both\nCSS and HTML groups use it.\n\n\n> \n> The objects are typed as text/html. Might be interesting to \n> also type them as xml.\n\nIt might indeed, and if we continue to view the guidelines as covering\nXHTML 1.1 then we will need to.\n\n> \n> On the scroll bar test I see two scrollbars in IE 6. One in \n> the frame the other for the page.\n\nThat's correct.  The inside scroll bar is the one you should look at for\nthe test - perhaps I could word that more clearly.\n\n\n> \n> It would be nice if instead of test1, test2, there was a \n> description of what was being tested or how the tests are \n> different. Otherwise, if testn fails, we don't have a clue as \n> to what is entailed in that test.\n\nOK \n\n> \n> The tests are nice. Is the technique with <object> supported \n> in most browsers now?\n\nSee above.\n\n> \n> tex\n> \n> \n> Richard Ishida wrote:\n> > \n> > Chaps,\n> > \n> > (Heads up.)\n> > \n> > I have spent a good deal of time since Friday lunch time \n> studying and \n> > updating the tests we had.  You can see the final result \n> for the one \n> > set I have completed at \n> > http://www.w3.org/International/tests/test-bidi-blocks.html .\n> > \n> > I used the CSS templates to rebuild the tests in this fashion, so \n> > hopefully CSS and others will be able to pick up these \n> tests for their \n> > own test suites.  I also spent some time reading about how to write \n> > tests \n> [http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html]\n,\n> and have made some changes to enable testers to draw conclusions \n> quickly (eg. the image for comparison in the bidi tests, green colors \n> to come in the :lang tests, etc.).\n> \n> I'll try to transform some more tests tomorrow (which is not so far \n> away, so I'd better stop now).\n> \n> RI\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> contact info: http://www.w3.org/People/Ishida/\n> \n> http://www.w3.org/International/ http://www.w3.org/International/geo/\n> \n> W3C Internationalization FAQs \n> http://www.w3.org/International/questions.html\n> RSS feed: http://www.w3.org/International/questions.rss\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Please check out I18N test suit",
            "content": "Hello Bert, Ian,\n\nI have been converting our i18n test pages to use the same model as the\nCSS tests.  I'd be grateful if you could look at two of the tests\nquickly so that I can ensure I'm heading in the right direction.\n\nNote that our navigation pages are slightly different: since the pages\nare still in development there is no set order for all tests yet; our\ntests are used for validating the concepts in our techniques docs and\nare not specific to a single specification.  I also adapted the styling\nof the navigation pages slightly to create a lighter feel. \n\nThe tests I have converted so far are:\n\nhttp://www.w3.org/International/tests/test-css-lang.html\n\nhttp://www.w3.org/International/tests/test-bidi-blocks.html\n\n(To see the other tests waiting in the wings, see\nhttp://www.w3.org/International/tests/ )\n\nMany thanks in advance,\nRI\n\n\n\nPS: Bert, you mentioned that I should contact someone who is currently\nworking on test development.  Could you remind me who that is? Cheers.\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Question inde",
            "content": "I was just updating\nhttp://www.w3.org/International/geo/upload/2003/questions/ when it\noccurred to me that it might be useful to make it more visible as an\nindex to the site information.\n\nWe agreeed in our meeting last week that we should have separate pages\nfor FAQs, articles, etc. but supplement that with a single page pointing\nto all types of information, grouped by theme.  Well in the GEO question\nindex we already have something very much like that.\n\nWhat do people think?  Should we press this into service and give it\nhigh visibility as an index to information on the site?  Should we\nremove the unanswered questions first? etc...\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "RE: Question inde",
            "content": "Richard Ishida wrote:\n\n> We agreeed in our meeting last week that we should have separate pages for FAQs, \n> articles, etc. but supplement that with a single page pointing to all types of \n> information, grouped by theme.  Well in the GEO question index we already have \n> something very much like that.\n\n> What do people think?  Should we press this into service and give it high \n> visibility as an index to information on the site?  Should we remove the \n> unanswered questions first? etc...\n\nI would vote to use it as a start, but remove all of the unanswered question first as long as there was a page that kept all the unanswered questions for our reference.\n\nRegards, Russ\n\n-----Original Message-----\nFrom: public-i18n-geo-request@w3.org [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\nSent: Tuesday, December 09, 2003 7:30 AM\nTo: public-i18n-geo@w3.org\nSubject: Question index\n\n\n\nI was just updating\nhttp://www.w3.org/International/geo/upload/2003/questions/ when it occurred to me that it might be useful to make it more visible as an index to the site information.\n\nWe agreeed in our meeting last week that we should have separate pages for FAQs, articles, etc. but supplement that with a single page pointing to all types of information, grouped by theme.  Well in the GEO question index we already have something very much like that.\n\nWhat do people think?  Should we press this into service and give it high visibility as an index to information on the site?  Should we remove the unanswered questions first? etc...\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/\nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Re: AGENDA: I18N GEO TF telcon, 2003-1126 at 19:00 UTC/GMT,   11am San Jose,  2pm Boston, 19:00 London, 20:00 Paris, 6am Melbourne   (next day!",
            "content": "My regrets. I'm at XML 2003, far away from a phone.\n\nRegards,    Martin.\n\nAt 18:49 03/12/08 +0000, Richard Ishida wrote:\n\n\n>GEO Work Items: http://www.w3.org/International/2003/plan.html\n>\n>\n>Meetings\n>\n>-       Xmas arrangements\n>\n>\n>Info Share\n>\n>-       bring your own contributions !\n>\n>\n>Discussion\n>\n>-       articles page  **** PLEASE REVIEW IN ADVANCE\n>         http://www.w3.org/International/articles.html\n>         seeking approval to publish\n>\n>-       new article **** PLEASE READ IN ADVANCE !\n>         what you need to know about bidi and inline markup\n>         http://people.w3.org/rishida/scripts/bidi/\n>         seeking approval to publish\n>\n>-       new Activity page look & feel\n>\n>http://lists.w3.org/Archives/Public/public-i18n-geo/2003Dec/0003.html\n>         how do we move forward?\n>\n>-       GEO activity review & planning\n>         see http://www.w3.org/International/2003/plan.html\n>\n>\n>\n>============\n>Richard Ishida\n>W3C\n>\n>contact info: http://www.w3.org/People/Ishida/\n>\n>http://www.w3.org/International/\n>http://www.w3.org/International/geo/\n>\n>W3C Internationalization FAQs\n>http://www.w3.org/International/questions.html\n>RSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "RE: AGENDA: I18N GEO TF telcon, 2003-1126 at 19:00 UTC/GMT,   11am San Jose,  2pm Boston, 19:00 London, 20:00 Paris, 6am Melbourne   (next day!",
            "content": "I am sorry that I missed this. I ended up in an activity that keep unavailable until now.\n\nRegards, Russ \n\n-----Original Message-----\nFrom: public-i18n-geo-request@w3.org [mailto:public-i18n-geo-request@w3.org] On Behalf Of Martin Duerst\nSent: Wednesday, December 10, 2003 11:14 AM\nTo: ishida@w3.org; public-i18n-geo@w3.org\nSubject: Re: AGENDA: I18N GEO TF telcon, 2003-11-26 at 19:00 UTC/GMT, 11am San Jose, 2pm Boston, 19:00 London, 20:00 Paris, 6am Melbourne (next day!)\n\n\nMy regrets. I'm at XML 2003, far away from a phone.\n\nRegards,    Martin.\n\nAt 18:49 03/12/08 +0000, Richard Ishida wrote:\n\n\n>GEO Work Items: http://www.w3.org/International/2003/plan.html\n>\n>\n>Meetings\n>\n>-       Xmas arrangements\n>\n>\n>Info Share\n>\n>-       bring your own contributions !\n>\n>\n>Discussion\n>\n>-       articles page  **** PLEASE REVIEW IN ADVANCE\n>         http://www.w3.org/International/articles.html\n>         seeking approval to publish\n>\n>-       new article **** PLEASE READ IN ADVANCE !\n>         what you need to know about bidi and inline markup\n>         http://people.w3.org/rishida/scripts/bidi/\n>         seeking approval to publish\n>\n>-       new Activity page look & feel\n>\n>http://lists.w3.org/Archives/Public/public-i18n-geo/2003Dec/0003.html\n>         how do we move forward?\n>\n>-       GEO activity review & planning\n>         see http://www.w3.org/International/2003/plan.html\n>\n>\n>\n>============\n>Richard Ishida\n>W3C\n>\n>contact info: http://www.w3.org/People/Ishida/\n>\n>http://www.w3.org/International/\n>http://www.w3.org/International/geo/\n>\n>W3C Internationalization FAQs\n>http://www.w3.org/International/questions.html\n>RSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "RE: JSP containers and default charset (was: Re    DefaultCharset  considered  harmful",
            "content": "Hello Addison, others,\n\nOne very specific question about JSP: Is it possible (and if yes,\nhow) to produce an XML file where the correct encoding is automatically\nput into the encoding pseudo-attribute of the XML declaration?\nAlso, is it possible (and how) to use the mechanisms provided\n(rather than doing everything on your own) and produce a HTTP\nresponse without a 'charset' parameter on the Content-Type\nresponse header?\n\nRegards,    Martin.\n\n\nAt 22:09 03/11/30 -0500, Addison Phillips [wM] wrote:\n\n>Hi Jungshik,\n> >\n> > You're absolutely right.  Therefore, the charset declaration in a JSP\n> > file serves dual purposes. It indicates the character encoding of the\n> > JSP file to the Java compiler (i.e. playing the same role as '-encoding'\n> > option when invoking 'javac') and it also indicates in what character\n> > encoding the generated html file should be served to the outside world.\n> > Someone might argue that there need to be two separate 'directives' for\n> > two roles, but I guess it's all right to overload pageEncoding directive.\n> >\n>Not quite: there are two directives: pageEncoding and contentType and they\n>can indicate *different* encodings. If you use pageEncoding on its own, it\n>is assumed that the encoding of the source JSP file should be the encoding\n>used to deliver the file. If you use contentType on its own, then the page\n>is delivered in the encoding specified, but read as Latin-1. If you want to\n>use one encoding (say KS-X-1001) for the JSP file and a different encoding\n>for the delivery (say UTF-8) then you can use both directives together.\n>\n>For example, see Norbert Lindeberg's excellent article here:\n>http://developer.java.sun.com/developer/technicalArticles/Intl/MultilingualJ\n>SP/\n>\n>In addition, the pageEncoding is how the JSP container reads the .jsp file\n>in, but the resulting servlet may not be written in the specified encoding\n>(e.g. the javac invocation might not use an -encoding directive).\n>\n>One more note: if your JSP page reads data from a HttpServletRequest object,\n>you may have to call the setCharacterEncoding() method on that object before\n>retrieving parameters sent to your JSP page via GET or POST.\n>\n>Best Regards,\n>\n>Addison\n\n\n\n"
        },
        {
            "subject": "Re: SWAD Europe Marketin",
            "content": "Yo-yos - they have a node and an arc built in. (I would say plastic\nbows and arrows, but that would be puerile).\n\nA thousand flowers. When was the last time you got a decent flower at a\ntechno-geek thing? (not plastic ones; real ones. You need to explain what it\nis about, but they are memorable)\n\nchaals\n\n>On Fri, 29 Nov 2002, CV Meek wrote:\n>\n>>\n>> Dear All, we are currently doing some preliminary research into ways in\n>> which we can market SWAD Europe.\n>>\n>> We are considering having some sort of SWAD-E gadget or toy to give out\n>> to people and although we have a few ideas in mind we would welcome any\n>> suggestions from yourselves.\n>>\n>> You may have attended a conference or workshop where you were given or\n>> saw a piece of promotional material that interested you, if so I'd like\n>> to know.\n\n\n\n"
        },
        {
            "subject": "New FAQ for review: Apache language negotiation set u",
            "content": "Chaps,\n\nAs a result of a query received here, and with Martin's help, I have put\ntogether an initial draft of an FAQ at\nhttp://www.w3.org/International/questions/qa-apache-lang-neg.html\n\nPlease review before the Wednesday meeting so that we can discuss.  I'd\nlike to publish this in about 10 days time if possible.\n\nThanks,\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "RE: New FAQ for review: Apache language negotiation set u",
            "content": "I have tweaked the wording slightly this morning.  You may need to\nrefresh.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\n> Sent: 15 December 2003 20:10\n> To: public-i18n-geo@w3.org\n> Cc: 'Vivien Lacourba'\n> Subject: New FAQ for review: Apache language negotiation set up\n> \n> \n> \n> Chaps,\n> \n> As a result of a query received here, and with Martin's help, \n> I have put together an initial draft of an FAQ at \n> http://www.w3.org/International/questions/qa-apache-lang-neg.h\ntml\n\nPlease review before the Wednesday meeting so that we can discuss.  I'd\nlike to publish this in about 10 days time if possible.\n\nThanks,\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "Re: New FAQ for review: Apache language negotiation set u",
            "content": "> http://www.w3.org/International/questions/qa-apache-lang-neg.html\n\nHere are some editorial comments:\n\n1) The question is about setting up files, but the answer is also about\nconfiguring apache.\nThe question should be reworded to more accurately reflect the faq\ncontent.\n\nHow do I implement language negotiation on an Apache Web server?\nHow do I configure a multilingual web site on an Apache Web server?\n\n2) This question shows the disdavantage of having the background at the\nend, since the answer seems to start in the middle. A few words of intro\nwould be good to set the stage. Certainly needs something before the\ndiscussion of the examples used occurs. It's a long faq, so it might be\ngood to introduce \"heres what you need to do\" with a brief list of 1)\nchoose file naming convention, 2) associate language with extensions,\netc. and then have the individual sections.\nThe list could be links for fast access as well.\n\n3) Somewhere, maybe not in this faq, we should have a discussion of the\ntradeoffs of having language indicated in the file name vs. in the\ndirectory structure (e.g yadda/yadda/en/index.html)\n\n4) You might indicate if this technique only applies to html or works\nfor other filetypes (e.g. image files, css, xml).\n\n5) The comment in the para on language extension first is the files are\neasier to read or edit when not on a server.\nSuggest saying why. Do you mean because it ends in .html and so the tool\nrecognizes the extension?\nAre you saying that tools will find the files even though the language\ncomponent is not specified? (I dont think so.)\nIt then says always type in browser address or hyperlink without\nextensions.\nI don't understand how the browser knows which language to retrieve if\nthe file is not being accessed via an apache server or with http\nprotocol. (ie on local disk as implied) Please explain.\n\n6) Subsequent para is that it may make the files harder to read if they\nare not on an apache server.\nPls explain why.  I presume the reason is tools can't default the\nlanguage extension.\n\n7) On naming conventions- we should indicate (maybe another faq) when to\nuse language and when to use language-region\n(and someday soon language-script-region...)\nAlso which version is the language default (does fr = fr-FR or fr-CA?\netc.)\n\nThe comment that 3066 should be followed for consistency and recognition\nis a bit specious.\nPerhaps say follow it as an industry convention and is consistent with\nusage as language identifiers in http, html, xml etc. The codes\nthemselves are not always recognizable or consistent. eg ja for language\njp for country is inconsistent.\n\n8) You mention AllowOverride being required for .htaccess but not any\nother permissions or privileges.\nI think for negotiation to work (but don't know for sure), some other\naccess rights or commands may need to be given.\nWe need to make this very clear. I had a great deal of trouble with my\nISP trying to get them to tell me which apache commands I was priv'd to\nuse, and as there were several ways to get it to work, I kept trying\nthings and was never show if I was misapplying the commands, missing\nsome commands or not priv'd.\nI seem to recall multiview being required.\n\nPerhaps we should suggest some tests that show privs and validate\nbehavior or example files that demonstrate correct usage.\n\n9) Now that user has multiple pages and images etc. for different\nlanguages, what is an appropriate test strategy to be sure that the\nlinks are going to the right places+languages?\n\nThis might be a good page to put in another language to show proof of\nconcept. Even if it was just translated to pig latin... Or point to some\nof the other w3c pages that are translated.\n\n10) yes pl-PL is better than po.\n\n11) Will someone from apach review or sanctify the page? \n\n12) How does language negotiation interact with user selection of a\nlanguage via a gateway page?\nFor example, if my browser is Japanese and by default I get the Japanese\npages, and then I select another language from the gateway page, once I\nget to the new language, what happens so that I don't keep getting the\ndefault pages?\n(since the browser will keep specifying Japanese in http) Do we need to\nclarify this? (maybe separate faq?)\n\nhth\n\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-1217 at 19:00 UTC/GMT, 11am San Jose,  2pm Boston, 19:00 London, 20:00 Paris, 6am Melbourne (next day!",
            "content": "------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) \nwith conference code 4186 (spells \"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\nGEO Work Items: http://www.w3.org/International/2003/plan.html\n\n\nMeetings\n\n-Xmas arrangements - next call 7th Jan\n\n\nInfo Share\n\n-bring your own contributions !\n\n\nDiscussion\n\n-new article **** PLEASE READ IN ADVANCE !\nwhat you need to know about bidi and inline markup\nhttp://people.w3.org/rishida/scripts/bidi/\nseeking approval to publish\n\n\n-new faq **** PLEASE READ IN ADVANCE !\nApache language negotiation set up\n\nhttp://www.w3.org/International/questions/qa-apache-lang-neg.html\nseeking topics that need live discussion\n\n\n-GEO activity review & planning \nsee http://www.w3.org/International/2003/plan.html\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "New FAQ choic",
            "content": "Hi,\n\nHere is the FAQ I chose with Richard's help. \nFrom the section \"Writing source text\":\nQUESTION: \"Is it a good idea to put translatable text in style sheets?\" \n\n\n\nDirections for the ANSWER:\n\nIdentify type of content to be handled by style sheet:\n- Repetitive.\n- Linguistically independent.\n- Not context sensitive.\n- Examples: Footnotes, headers, \n- ...\n\nDescribe general benefits: \nMaintenance, reuse, consistency\n...\n\nConditions required: \n- Localize style sheets first\n- Make sure T&L processes and tools handle style sheets\n- ...\n\nOther related topics:\n- That might not be the only data to localize. Font, quotes,...\nmight also require l10n.\n- CSS specifications concerned: 'content' property\n- ...\n\n\n\nAll input and feedback welcomed.\n\n\nFran?ois Richard\nTranslation and Localization\nHP Content Management Services\nhttp://easyweb.grenoble.hp.com/globalization/\nInternal phone: 1386.6144871\nExternal: 33 (0)4 76 14 48 71\n\n\n\n"
        },
        {
            "subject": "Re: New FAQ choic",
            "content": "Hello Francois,\n\nI think this is an excellent choice of topic area!\nHowever, I would suggest to split things up into several smaller\npieces, e.g.:\n\n- XSLT vs. CSS\n- technical aspects vs. design aspects vs. organisatorial aspects\n- Text vs. other localization issues\n- fixed text (e.g. one stylesheet for each language) vs. more\n   advanced techniques\n\nThis will make it easier to create an FAQ quickly, will make\nit easier for readers to understand a single topic, and will\ngive us other opportunities for more FAQs.\n\nRegards,    martin.\n\nAt 14:22 03/12/17 +0100, RICHARD,FRANCOIS (HP-France,ex1) wrote:\n\n>Hi,\n>\n>Here is the FAQ I chose with Richard's help.\n> >From the section \"Writing source text\":\n>QUESTION: \"Is it a good idea to put translatable text in style sheets?\"\n>\n>\n>\n>Directions for the ANSWER:\n>\n>Identify type of content to be handled by style sheet:\n>         - Repetitive.\n>         - Linguistically independent.\n>         - Not context sensitive.\n>         - Examples: Footnotes, headers,\n>         - ...\n>\n>Describe general benefits:\n>         Maintenance, reuse, consistency\n>         ...\n>\n>Conditions required:\n>         - Localize style sheets first\n>         - Make sure T&L processes and tools handle style sheets\n>         - ...\n>\n>Other related topics:\n>         - That might not be the only data to localize. Font, quotes,...\n>might also require l10n.\n>         - CSS specifications concerned: 'content' property\n>         - ...\n>\n>\n>\n>All input and feedback welcomed.\n>\n>\n>Francois Richard\n>Translation and Localization\n>HP Content Management Services\n>http://easyweb.grenoble.hp.com/globalization/\n>Internal phone: 1386.6144871\n>External: 33 (0)4 76 14 48 71\n\n\n\n"
        },
        {
            "subject": "RE: New FAQ for review: Apache language negotiation set u",
            "content": "> From: Tex Texin [mailto:tex@i18nguy.com] \n> Sent: 17 December 2003 08:37\n\n> 8) You mention AllowOverride being required for .htaccess but \n> not any other permissions or privileges. I think for \n> negotiation to work (but don't know for sure), some other \n> access rights or commands may need to be given. We need to \n> make this very clear. I had a great deal of trouble with my \n> ISP trying to get them to tell me which apache commands I was \n> priv'd to use, and as there were several ways to get it to \n> work, I kept trying things and was never show if I was \n> misapplying the commands, missing some commands or not \n> priv'd. I seem to recall multiview being required.\n\nMy problem here is that I don't know what is required.  I'm quite\nunfamiliar with server settings.  \n\nCould someone provide the relevant text for me?\n\nThanks,\nRI\n\n\n\n"
        },
        {
            "subject": "RE: New FAQ for review: Apache language negotiation set u",
            "content": "Thanks for the comments, Tex.  See below...\n\n\n> -----Original Message-----\n> From: Tex Texin [mailto:tex@i18nguy.com] \n> Sent: 17 December 2003 08:37\n> To: ishida@w3.org\n> Cc: public-i18n-geo@w3.org; 'Vivien Lacourba'\n> Subject: Re: New FAQ for review: Apache language negotiation set up\n> \n> \n> > http://www.w3.org/International/questions/qa-apache-lang-neg.html\n> \n> Here are some editorial comments:\n> \n> 1) The question is about setting up files, but the answer is \n> also about configuring apache. The question should be \n> reworded to more accurately reflect the faq content.\n> \n> How do I implement language negotiation on an Apache Web \n> server? How do I configure a multilingual web site on an \n> Apache Web server?\n\nDone.\n\n> \n> 2) This question shows the disdavantage of having the \n> background at the end, since the answer seems to start in the \n> middle. A few words of intro would be good to set the stage. \n> Certainly needs something before the discussion of the \n> examples used occurs. It's a long faq, so it might be good to \n> introduce \"heres what you need to do\" with a brief list of 1) \n> choose file naming convention, 2) associate language with \n> extensions, etc. and then have the individual sections. The \n> list could be links for fast access as well.\n\nI disagree and see it as unnecessary verbosity.  There's a link to the\nbackground information for those who need it.\n\n> \n> 3) Somewhere, maybe not in this faq, we should have a \n> discussion of the tradeoffs of having language indicated in \n> the file name vs. in the directory structure (e.g \n> yadda/yadda/en/index.html)\n\nIt's already in the list of future questions:\nhttp://www.w3.org/International/geo/upload/2003/questions/\n\n> \n> 4) You might indicate if this technique only applies to html \n> or works for other filetypes (e.g. image files, css, xml).\n\nDone.\n\n\n> \n> 5) The comment in the para on language extension first is the \n> files are easier to read or edit when not on a server. \n> Suggest saying why. Do you mean because it ends in .html and \n> so the tool recognizes the extension? Are you saying that \n> tools will find the files even though the language component \n> is not specified? (I dont think so.) It then says always type \n> in browser address or hyperlink without extensions. I don't \n> understand how the browser knows which language to retrieve \n> if the file is not being accessed via an apache server or \n> with http protocol. (ie on local disk as implied) Please explain.\n> \n> 6) Subsequent para is that it may make the files harder to \n> read if they are not on an apache server. Pls explain why.  I \n> presume the reason is tools can't default the language extension.\n\nDone 5 & 6\n\n\n> \n> 7) On naming conventions- we should indicate (maybe another \n> faq) when to use language and when to use language-region \n> (and someday soon language-script-region...) Also which \n> version is the language default (does fr = fr-FR or fr-CA?\n> etc.)\n\nFor indicating language I don't think there is any default, other than\nthat fr is a superset of fr-CA, fr-FR, etc..  Aren't you thinking in\nterms of locale mechanisms?\n\n\n> \n> The comment that 3066 should be followed for consistency and \n> recognition is a bit specious. Perhaps say follow it as an \n> industry convention and is consistent with usage as language \n> identifiers in http, html, xml etc. The codes themselves are \n> not always recognizable or consistent. eg ja for language jp \n> for country is inconsistent.\n\nja and jp is not inconsistent since one refers to language, the other to\ncountry.  There is no reason to expect them to be the same.  I added the\nword 'language' to the text.\n\n\n> \n> 8) You mention AllowOverride being required for .htaccess but \n> not any other permissions or privileges. I think for \n> negotiation to work (but don't know for sure), some other \n> access rights or commands may need to be given. We need to \n> make this very clear. I had a great deal of trouble with my \n> ISP trying to get them to tell me which apache commands I was \n> priv'd to use, and as there were several ways to get it to \n> work, I kept trying things and was never show if I was \n> misapplying the commands, missing some commands or not \n> priv'd. I seem to recall multiview being required.\n> \n> Perhaps we should suggest some tests that show privs and \n> validate behavior or example files that demonstrate correct usage.\n\nSee separate note.\n\n\n> \n> 9) Now that user has multiple pages and images etc. for \n> different languages, what is an appropriate test strategy to \n> be sure that the links are going to the right places+languages?\n\nIt's already in the list of future questions:\nhttp://www.w3.org/International/geo/upload/2003/questions/\n\n\n> \n> This might be a good page to put in another language to show \n> proof of concept. Even if it was just translated to pig \n> latin... Or point to some of the other w3c pages that are translated.\n> \n> 10) yes pl-PL is better than po.\n> \n> 11) Will someone from apach review or sanctify the page? \n\n\nDoes anyone have any contacts? Martin?\n\n> \n> 12) How does language negotiation interact with user \n> selection of a language via a gateway page? For example, if \n> my browser is Japanese and by default I get the Japanese \n> pages, and then I select another language from the gateway \n> page, once I get to the new language, what happens so that I \n> don't keep getting the default pages? (since the browser will \n> keep specifying Japanese in http) Do we need to clarify this? \n> (maybe separate faq?)\n\nI think the answer is not straighforward.  I think many people dealing\nwith gateway pages are dealing with whole sites that have been\nlocalised, and probably more often by country than by language.  So my\nguess is that they wouldn't really do language negotiation in this way,\nrather they would have files in different locations.  I see language\nnegotiation for expressing *linguistic* variants of single or small\ngroups of pages.  This is getting into one of the questions you posed\nearlier.\n\nNote, however, as stated in the FAQ, that you can always point to a\nspecific page by specifying something like example.en.html, although as\nyou say as soon as you follow a link you're likely to revert back to the\nlanguage specified in your HTTP settings.\n\nBTW, if we continue this discussion, let's make it a separate thread.\n\nCheers,\nRI\n\n\n\n"
        },
        {
            "subject": "Re: SWAD Europe Marketin",
            "content": "At 11:17 AM 11/29/02 +0000, Libby Miller wrote:\n>I rather like these:\n>http://shop.store.yahoo.com/elogo/tangletoy.html\n\nBefore I read this, I was thinking of something that could also illustrate \nthe utility of RDF.\n\nI think this tangle toy probably has a number of topological states that:\n(a) could be identified using URIs\n(b) their relationships could be described using RDF, e.g. in terms of \nloop-twists or some suchlike maneouvre\n(c) sequences of operations to change from one state to another might be \nderived using a standard RDF tool like cwm or Euler.\n\nDo we have a mathematician of sufficient skill to work out the details?\n\n...\n\nAnother thought I had along similar lines was one of those tile puzzles, \nwhere you \"move the hole around\" to obtain some well-ordered arrangement of \ntiles.  (e.g. the RDF-logo?)  Again, linked to RDF descriptions of the \nstates and solvable using standard off-the-shelf (or off-the-web) RDF tools.\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "when to use language negotiation author neede",
            "content": "At todays GEO meeting, we reviewed the proposed faq on language\nnegotiation\n\nhttp://www.w3.org/International/questions/qa-apache-lang-neg.html\n\nand decided we need an author for a faq on when it is appropriate, or\nnot, to use language negotiation.\n\n========================\nSome time was spent today discussing when this type of negotiation\nshould be used, and when alternatives should be considered. I was\nactioned with posing the question to the group, to collect information\nand to solicit whether someone might be interested in authoring a FAQ or\narticle on when to use this technique.\n\nWe thought Yves, John or Fran?ois might have a special interest in this\nsubject and so I cc'd them individually.\n\nFor example, there were suggestions that this approach only made sense\nwhere every page had an exact counterpart in another language or region.\nMany sites have different pages or file organization based on\ndifferences in content.\n\nIt might be the case that Language negotiation only makes sense for the\nentry page and after that page is read and a language either defaulted\nor selected by the user, the rest of the content would be linked\ndirectly, without relying on language negotiation. \n\nSome thought organization by language directory (e.g.\nyadda/en/pages.html) might be more practical than by filename (e.g.\nyadda/pages.en.html)\n\nThere were questions about server load and scalability.\n\nThere was also a discussion of roles and authorization, as content\ndevelopers may not have access to some server commands,  and we\nconsidered there is guidance needed for content developers and separate\nguidance needed for administrators.\n\nSo, we would like to ask if there is someone in the to-list who would\nlike to author or contribute to a faq on the subject of when to use\nlanguage negotiation and when not to, or defining situations where are\nalternatives prefered.\n\nAny takers?\n\n\n\n\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "FW: [Moderator Action] Comments on  FAQ: Apache language negotiation set u",
            "content": "Editorial nit: \"...you make it easier to to read...\"  Strike one \"to\".\n\n\nUnder \"File naming\" it says that if you use the example.en.html style, \nyou will need to make links point to \"example\".  This is actually a Good\n\nThing, for reasons other than i18n.  See \"Cool URIs don't change\" at \nhttp://www.w3.org/Provider/Style/URI.html, to which this FAQ should \nprobably point.\n\n\n\"We recommend that you use ISO language and country codes as defined by \nRFC3066\".  Poor wording, the RFC doesn't define ISO codes!  Just say \n\"...use language tags as defined by RFC 3066\".  BTW, the link at the \nbottom of the page says it links to RFC 1766 (obsoleted by 3066) and \nactually points to a Microsoft page on the BOM!\n\n\n\"Note that users can refer to a specific file by typing in the full file\n\nname,\".  It might be good to say that one can also use an incomplete \nname such as \"example.fr\" to specify language but not format, preserving\n\nthe format-independance that \"Cool URIs don't change\" promotes while \nlinking to a specific language version when appropriate.\n\n\nUnless things have changed fairly recently, the Multiviews option needs \nto be enabled in Apache for automatic content negotiation to take place.\n\nIt may or may not be possible to set that option in a .htaccess file, \ndepending on settings higher up.\n\n\nThe Default files section seems to imply that there must be a \nserver-wide default, which is not necessarily the case.  It might be \nworth pointing out that a server-wide default language is a valid \noption, but that then every page must exist in that language; a \nserver-wide default is probably not a good choice for sites where \ncontent varies by language.\n\nSame section, it is a bit ironic that the Core TF of the i18n WG keeps \ntelling other WGs to please use examples other than English/ASCII, and \nhere the GEO TF of the same i18n WG uses English as an example default \nlanguage.  Also, the parenthetic statement \"(likely to often be the best\n\nchoice for a default, given the widespread nature of English)\" should be\n\nat least fixed to not mention the *nature* of English, or better removed\n\naltogether.\n\nRegards,\n\n-- \nFran?ois\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "Tex Texin a ?crit  :\n> and decided we need an author for a faq on when it is appropriate, or \n> not, to use language negotiation.\n\nI'll take that.  Accomplices welcome.\n\n-- \nFran?ois\n> \n> ========================\n> Some time was spent today discussing when this type of negotiation \n> should be used, and when alternatives should be considered. I was \n> actioned with posing the question to the group, to collect information\n\n> and to solicit whether someone might be interested in authoring a FAQ \n> or article on when to use this technique.\n> \n> We thought Yves, John or Fran?ois might have a special interest in \n> this subject and so I cc'd them individually.\n> \n> For example, there were suggestions that this approach only made sense\n\n> where every page had an exact counterpart in another language or \n> region. Many sites have different pages or file organization based on \n> differences in content.\n> \n> It might be the case that Language negotiation only makes sense for \n> the entry page and after that page is read and a language either \n> defaulted or selected by the user, the rest of the content would be \n> linked directly, without relying on language negotiation.\n> \n> Some thought organization by language directory (e.g.\n> yadda/en/pages.html) might be more practical than by filename (e.g.\n> yadda/pages.en.html)\n> \n> There were questions about server load and scalability.\n> \n> There was also a discussion of roles and authorization, as content \n> developers may not have access to some server commands,  and we \n> considered there is guidance needed for content developers and \n> separate guidance needed for administrators.\n> \n> So, we would like to ask if there is someone in the to-list who would \n> like to author or contribute to a faq on the subject of when to use \n> language negotiation and when not to, or defining situations where are\n\n> alternatives prefered.\n> \n> Any takers?\n> \n> \n> \n> \n> \n\n\n\n"
        },
        {
            "subject": "RE: when to use language negotiation author neede",
            "content": "Note that I forwarded this message from Francois Yergeau.\n\nRI\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\n> Sent: 18 December 2003 09:17\n> To: public-i18n-geo@w3.org\n> Subject: Re: when to use language negotiation- author needed\n> \n> \n> \n> Tex Texin a ?crit  :\n> > and decided we need an author for a faq on when it is \n> appropriate, or\n> > not, to use language negotiation.\n> \n> I'll take that.  Accomplices welcome.\n> \n> -- \n> Fran?ois\n> > \n> > ========================\n> > Some time was spent today discussing when this type of negotiation\n> > should be used, and when alternatives should be considered. I was \n> > actioned with posing the question to the group, to collect \n> information\n> \n> > and to solicit whether someone might be interested in \n> authoring a FAQ\n> > or article on when to use this technique.\n> > \n> > We thought Yves, John or Fran?ois might have a special interest in\n> > this subject and so I cc'd them individually.\n> > \n> > For example, there were suggestions that this approach only \n> made sense\n> \n> > where every page had an exact counterpart in another language or\n> > region. Many sites have different pages or file \n> organization based on \n> > differences in content.\n> > \n> > It might be the case that Language negotiation only makes sense for\n> > the entry page and after that page is read and a language either \n> > defaulted or selected by the user, the rest of the content would be \n> > linked directly, without relying on language negotiation.\n> > \n> > Some thought organization by language directory (e.g.\n> > yadda/en/pages.html) might be more practical than by filename (e.g.\n> > yadda/pages.en.html)\n> > \n> > There were questions about server load and scalability.\n> > \n> > There was also a discussion of roles and authorization, as content\n> > developers may not have access to some server commands,  and we \n> > considered there is guidance needed for content developers and \n> > separate guidance needed for administrators.\n> > \n> > So, we would like to ask if there is someone in the to-list \n> who would\n> > like to author or contribute to a faq on the subject of when to use \n> > language negotiation and when not to, or defining \n> situations where are\n> \n> > alternatives prefered.\n> > \n> > Any takers?\n> > \n> > \n> > \n> > \n> > \n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: New FAQ choic",
            "content": "I would like to understand which principles are being applied here.\nWe seem to be asking about text and then working back to advice that\napplies to any element that requires localization.\ne.g. font, color, images, etc.\n\nstyle sheet content whether translatable text or anything else is best\nif it is repetitive, context-insensitive, etc.\n(context-sensitive isnt quite the right wording, since clearly headers,\nfooters, classes, etc. are context...)\n\nThe benefits are the same whether text or other.\n\nconditions-are the same.\n\nGEO should have some discussion about localization of style sheets and\nwhat is really involved. Also I have been grappling lately with whether\nlanguage or culture sensitive information should be in one style sheet\nwith some way of distinguishing which contents is used with which\nlanguage, or just different sheets for different languages.\n\nSo I guess I am asking, is there a presumption of an overall methodology\nfor localizing styles, if so what is it, or should we be describing\napproaches and what is involved in their localization first, and then\nget to the finer point of translatable text, and how translatable text\nis different than other aspects of CSS?\n\n\nFran?ois, I hope this doesn't read like I am criticizing the question.\nThe question is a good one. I am unaware if there is any agreement or\npresumption of what to do with style sheets in the context of\nlocalization, and maybe I just need some orientation first.\n\nWhat references are there on this subject? I am aware of Yves Savourel\nbook, and R. Ishida and others have done some presentations about L10n\nof XML, DTD and the like (I don't recall if they covered CSS.)\n\ntex\n\n\n\"RICHARD,FRANCOIS (HP-France,ex1)\" wrote:\n> \n> Hi,\n> \n> Here is the FAQ I chose with Richard's help.\n> >From the section \"Writing source text\":\n> QUESTION: \"Is it a good idea to put translatable text in style sheets?\"\n> \n> Directions for the ANSWER:\n> \n> Identify type of content to be handled by style sheet:\n>         - Repetitive.\n>         - Linguistically independent.\n>         - Not context sensitive.\n>         - Examples: Footnotes, headers,\n>         - ...\n> \n> Describe general benefits:\n>         Maintenance, reuse, consistency\n>         ...\n> \n> Conditions required:\n>         - Localize style sheets first\n>         - Make sure T&L processes and tools handle style sheets\n>         - ...\n> \n> Other related topics:\n>         - That might not be the only data to localize. Font, quotes,...\n> might also require l10n.\n>         - CSS specifications concerned: 'content' property\n>         - ...\n> \n> All input and feedback welcomed.\n> \n> Fran?ois Richard\n> Translation and Localization\n> HP Content Management Services\n> http://easyweb.grenoble.hp.com/globalization/\n> Internal phone: 1386.6144871\n> External: 33 (0)4 76 14 48 71\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: New FAQ choic",
            "content": ">\n>I would like to understand which principles are being applied \n>here. We seem to be asking about text and then working back to \n>advice that applies to any element that requires localization. \n>e.g. font, color, images, etc.\n\nL10n of font, color, images could be part of \"By the way...\" section.\n>\n>style sheet content whether translatable text or anything else \n>is best if it is repetitive, context-insensitive, etc. \n>(context-sensitive isnt quite the right wording, since clearly \n>headers, footers, classes, etc. are context...)\n>\n>The benefits are the same whether text or other.\n>\n>conditions-are the same.\n\nEmbedding text in style sheets has more implication/risks on the overall\nTranslation and Localisation process than other localizable data.\nThe logic would be to warn reader of the FAQ about potential issue coming\ndown the pipe of the T&L process. As such, the association of text within\nstyle sheet carries a specific risk...\n\nThe corresponding extra condition on text (compared to other localizable\ndata) would be the \"linguistic independence\" (do not know how to call it):\nthe text needs to be transalte-able isolated from the main text...\n\n>\n>GEO should have some discussion about localization of style \n>sheets and what is really involved. Also I have been grappling \n>lately with whether language or culture sensitive information \n>should be in one style sheet with some way of distinguishing \n>which contents is used with which language, or just different \n>sheets for different languages.\n>\n>So I guess I am asking, is there a presumption of an overall \n>methodology for localizing styles, if so what is it, or should \n>we be describing approaches and what is involved in their \n>localization first, and then get to the finer point of \n>translatable text, and how translatable text is different than \n>other aspects of CSS?\n>\n>Fran?ois, I hope this doesn't read like I am criticizing the \n>question. The question is a good one. I am unaware if there is \n>any agreement or presumption of what to do with style sheets \n>in the context of localization, and maybe I just need some \n>orientation first.\n>\n>What references are there on this subject? I am aware of Yves \n>Savourel book, and R. Ishida and others have done some \n>presentations about L10n of XML, DTD and the like (I don't \n>recall if they covered CSS.)\n\nI did not checked yet. But the ones you mentioned are important for sure. Do\nnot know if CSS have been covered.\n/Francois\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "John,\n\nGood comments.\n\n1) On deep linking from search engines and elsewhere, I would think that\nmost of the time the search would result in a page that was in one of\nthe languages of the user. I know it is not always true, but I wouldn't\nthink using lang. negotiation would be an improvement most of the time\nfor a deep link.\n\nBut that's a good use case for language selection being available on\nevery page and for it not to return to the top of the tree, but a\nreasonable counterpart of the page the language switch is being made\nfrom.\n\n2) I don't know the answer to the question on htaccess for changing\nlanguage directories rather than pages.\nI had the same question.\n\n3) Google must use cookies to remember information from past searches,\nespecially your location and things like that. Too many of the searches\nI do show up local companies and reasonable matches, even when I don't\nprovide that many keywords. You would think a search for a chinese\nrestaurant name would give you places randomly around the world rather\nthan American or Massachusetts places being most highly ranked. (Of\ncourse the dominance of american internet helps there.) I guess I'll\nhave to do a few searches, then delete all my cookies to test it.\n\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "Tex,\n\nI believe that Google is using both content negotiation plus some \nmethod of IP address identification. I know of company that has \ncommercialized the service, though I'm not sure how Google goes about \ndoing it.\n\nHere's the company: http://www.verifia.com\n\n\nOn Dec 19, 2003, at 3:40 PM, Tex Texin wrote:\n\n>\n> John,\n>\n> Good comments.\n>\n> 1) On deep linking from search engines and elsewhere, I would think \n> that\n> most of the time the search would result in a page that was in one of\n> the languages of the user. I know it is not always true, but I wouldn't\n> think using lang. negotiation would be an improvement most of the time\n> for a deep link.\n>\n> But that's a good use case for language selection being available on\n> every page and for it not to return to the top of the tree, but a\n> reasonable counterpart of the page the language switch is being made\n> from.\n>\n> 2) I don't know the answer to the question on htaccess for changing\n> language directories rather than pages.\n> I had the same question.\n>\n> 3) Google must use cookies to remember information from past searches,\n> especially your location and things like that. Too many of the searches\n> I do show up local companies and reasonable matches, even when I don't\n> provide that many keywords. You would think a search for a chinese\n> restaurant name would give you places randomly around the world rather\n> than American or Massachusetts places being most highly ranked. (Of\n> course the dominance of american internet helps there.) I guess I'll\n> have to do a few searches, then delete all my cookies to test it.\n>\n>\n> -- \n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n>\n> XenCraft            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n>\n>\n>\n>\nJohn Yunker\nByte Level Research\njyunker@bytelevel.com\n+1 (617) 388-6824\n\n\n\n"
        },
        {
            "subject": "RE: SWAD Europe Marketin",
            "content": ">At 11:17 AM 11/29/02 +0000, Libby Miller wrote:\n>>I rather like these:\n>>http://shop.store.yahoo.com/elogo/tangletoy.html\n\nThey do look fun.\n\n>Before I read this, I was thinking of something that could also illustrate\n>the utility of RDF.\n\nA very good idea. Just prior to Rubik cubes hitting the big time I got one\nthrough a small ad somewhere (back of New Scientist?), along with an\nexplanatory booklet. The booklet was more like an academic paper, delving\npretty deeply into group theory. I struggled through the booklet, learning\nstuff I'd have dismissed as just too difficult/dull if it hadn't been for\nthe wonderful cube.\n\n>I think this tangle toy probably has a number of topological states that:\n>(a) could be identified using URIs\n>(b) their relationships could be described using RDF, e.g. in terms of\n>loop-twists or some suchlike maneouvre\n>(c) sequences of operations to change from one state to another might be\n>derived using a standard RDF tool like cwm or Euler.\n>\n>Do we have a mathematician of sufficient skill to work out the details?\n>\n>...\n>\n>Another thought I had along similar lines was one of those tile puzzles,\n>where you \"move the hole around\" to obtain some well-ordered\n>arrangement of\n>tiles.  (e.g. the RDF-logo?)  Again, linked to RDF descriptions of the\n>states and solvable using standard off-the-shelf (or off-the-web)\n>RDF tools.\n\nAnyone done RDF for finite state machines??\n\nI did see a lovely toy the other day, actually nodes & arcs. The arcs were\nbar magnets covered in coloured plastic, the nodes ball bearings.\nUnfortunately they were about ?10 for half a dozen of each.\n\nThe only thing I can think of to suggest is e-SW angle grinders.\n(Coincidentally, there some work I need to do on some concrete ledges in our\ncellar). Cementic Web, anyone?\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "Yes, I had heard that too and had started to mention it in my comments\nand then removed it because identifying\na users location by ip address isn't that reliable. For example, workers\nfor large companies often connect from anywhere in the world to the\ncorporate network and then all of their outgoing net requests look to\nthe rest of the world as if they came from a single client ip address,\nwhich is a proxy for all the companies users.\n\nThere are other problems as well.\n\nBut maybe google or other search engines use the approach coupled with\nother techniques...\n\nI don't know verifia, I'll give it a look. thanks\ntex\n\n\nJohn Yunker wrote:\n> \n> Tex,\n> \n> I believe that Google is using both content negotiation plus some\n> method of IP address identification. I know of company that has\n> commercialized the service, though I'm not sure how Google goes about\n> doing it.\n> \n> Here's the company: http://www.verifia.com\n> \n> On Dec 19, 2003, at 3:40 PM, Tex Texin wrote:\n> \n> >\n> > John,\n> >\n> > Good comments.\n> >\n> > 1) On deep linking from search engines and elsewhere, I would think\n> > that\n> > most of the time the search would result in a page that was in one of\n> > the languages of the user. I know it is not always true, but I wouldn't\n> > think using lang. negotiation would be an improvement most of the time\n> > for a deep link.\n> >\n> > But that's a good use case for language selection being available on\n> > every page and for it not to return to the top of the tree, but a\n> > reasonable counterpart of the page the language switch is being made\n> > from.\n> >\n> > 2) I don't know the answer to the question on htaccess for changing\n> > language directories rather than pages.\n> > I had the same question.\n> >\n> > 3) Google must use cookies to remember information from past searches,\n> > especially your location and things like that. Too many of the searches\n> > I do show up local companies and reasonable matches, even when I don't\n> > provide that many keywords. You would think a search for a chinese\n> > restaurant name would give you places randomly around the world rather\n> > than American or Massachusetts places being most highly ranked. (Of\n> > course the dominance of american internet helps there.) I guess I'll\n> > have to do a few searches, then delete all my cookies to test it.\n> >\n> >\n> > --\n> > -------------------------------------------------------------\n> > Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> > Xen Master                          http://www.i18nGuy.com\n> >\n> > XenCraft                          http://www.XenCraft.com\n> > Making e-Business Work Around the World\n> > -------------------------------------------------------------\n> >\n> >\n> >\n> >\n> John Yunker\n> Byte Level Research\n> jyunker@bytelevel.com\n> +1 (617) 388-6824\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "At 15:40 03/12/19 -0500, Tex Texin wrote:\n\n>John,\n>\n>Good comments.\n>\n>1) On deep linking from search engines and elsewhere, I would think that\n>most of the time the search would result in a page that was in one of\n>the languages of the user. I know it is not always true, but I wouldn't\n>think using lang. negotiation would be an improvement most of the time\n>for a deep link.\n>\n>But that's a good use case for language selection being available on\n>every page and for it not to return to the top of the tree, but a\n>reasonable counterpart of the page the language switch is being made\n>from.\n\nI agree. If the material is really parallel, e.g. stuff such as manuals,\nit can be helpful to send somebody a link, and they get the page in\ntheir language (if available).\n\n\n>2) I don't know the answer to the question on htaccess for changing\n>language directories rather than pages.\n>I had the same question.\n\nIt must be possible with Apache, because the Apache documentation\nproject uses it. Look e.g. at\nhttp://httpd.apache.org/docs-2.0/en/content-negotiation.html\nhttp://httpd.apache.org/docs-2.0/ko/content-negotiation.html\nhttp://httpd.apache.org/docs-2.0/ja/content-negotiation.html\nand http://httpd.apache.org/docs-2.0/content-negotiation.html.\nBut I haven't figured it out yet, but it seems to involve more\nthan just simple configuration directives.\n\n\nRegards,   Martin.\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "At 17:06 03/12/17 -0500, Tex Texin wrote:\n\n>There were questions about server load and scalability.\n\nUsing negotiation can mean that you get first a list of all\nthe files in a directory, then do a subrequest for each of\nthe file that has the right prefix so that you get the\nrelevant info (language, charset,...). That can cost a lot.\nBut I'm sure there are ways to speed this up. In particular,\ntypemaps should be a lot faster than multiviews because\ntypemaps avoid the above lookups and subrequests. But\nthey have to be kept up to date. See\nhttp://httpd.apache.org/docs-2.0/content-negotiation.html#negotiation.\n\nNegotiation can also affect caching performance, but it\nshould not if the server and the cache use HTTP/1.1\n(instead of HTTP/1.0).\n\nRegards,   Martin.\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "Martin Duerst wrote:\n\n>> 2) I don't know the answer to the question on htaccess for changing\n>> language directories rather than pages.\n>> I had the same question.\n> \n> \n> It must be possible with Apache, because the Apache documentation\n> project uses it. Look e.g. at\n> http://httpd.apache.org/docs-2.0/en/content-negotiation.html\n> http://httpd.apache.org/docs-2.0/ko/content-negotiation.html\n> http://httpd.apache.org/docs-2.0/ja/content-negotiation.html\n> and http://httpd.apache.org/docs-2.0/content-negotiation.html.\n> But I haven't figured it out yet, but it seems to involve more\n> than just simple configuration directives.\n> \n\nI assume they're using type maps, esp since you specify URIs in the type \nmaps rather than filenames.\n\nContent negotiation appears to be implimented at the higher directory \nstructure index levels like http://httpd.apache.org/docs-2.0/ but if you \nfollow a deep link into the documentation you don't have langauge \nnegotiation instead you have to select a language form the langauge \nmenu. Either that or my browser is misbehaving.\n\n\nAndrew\n\n-- \nAndrew Cunningham\ne-Diversity and Content Infrastructure Solutions\nPublic Libraries Unit, Vicnet\nState Library of Victoria\n328 Swanston Street\nMelbourne  VIC  3000\nAustralia\n\nandrewc@vicnet.net.au\n\nPh. +61-3-8664-7430\nFax: +61-3-9639-2175\n\nhttp://www.openroad.net.au/\nhttp://www.libraries.vic.gov.au/\nhttp://www.vicnet.net.au/\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "Tex Texin wrote:\n\n> Yes, I had heard that too and had started to mention it in my comments\n> and then removed it because identifying\n> a users location by ip address isn't that reliable. For example, workers\n> for large companies often connect from anywhere in the world to the\n> corporate network and then all of their outgoing net requests look to\n> the rest of the world as if they came from a single client ip address,\n> which is a proxy for all the companies users.\n> \n\nWithin the sectors I work in, location and/or IP address are \nnon-workable as a solution to content negotiation.\n\nAndrew\n\n-- \nAndrew Cunningham\ne-Diversity and Content Infrastructure Solutions\nPublic Libraries Unit, Vicnet\nState Library of Victoria\n328 Swanston Street\nMelbourne  VIC  3000\nAustralia\n\nandrewc@vicnet.net.au\n\nPh. +61-3-8664-7430\nFax: +61-3-9639-2175\n\nhttp://www.openroad.net.au/\nhttp://www.libraries.vic.gov.au/\nhttp://www.vicnet.net.au/\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "On Mon, 22 Dec 2003, Andrew Cunningham wrote:\n\n> Tex Texin wrote:\n>\n> > Yes, I had heard that too and had started to mention it in my comments\n> > and then removed it because identifying\n> > a users location by ip address isn't that reliable. For example, workers\n\n>\n> Within the sectors I work in, location and/or IP address are\n> non-workable as a solution to content negotiation.\n\n   I third that. IMHO, most of time using IP address is not so good an\nidea. It can be a factor, but should be low in the list of things to\ntake into account.\n\n As for Google (often mentioned in this context),  I'm pretty sure a\nlot of people living in foreign countries have been annoyed by Google's\nignoring 'accept-language' list on the client side. I know for sure that\nit does NOT honor the value of 'accept-language'.  It does use cookies\nto store the prefered UI language, but it's of no use if I use a browser\nthat doesn't support persistent cookies but supports 'accept-language'\n(e.g. Lynx). I already wrote to Google to honor 'accept-language',\nbut haven't seen the change made yet.\n\n  Jungshik\n\n\n\n"
        },
        {
            "subject": "RE: when to use language negotiation author neede",
            "content": "Francois, \n\nMany thanks for volunteering !  Please be aware, however, that John\nYunker is working on some guidelines information for multilingual site\nnavigation, so please confer with him while developing your FAQ.\n\nBtw, you or anyone else on a W3C member mailing list, can now write\ndirectly to the public-i18n-geo list without me needing to forward.  If\nyou would like to be added to that list for receipt, let me know.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\n> Sent: 18 December 2003 09:17\n> To: public-i18n-geo@w3.org\n> Subject: Re: when to use language negotiation- author needed\n> \n> \n> \n> Tex Texin a ?crit  :\n> > and decided we need an author for a faq on when it is \n> appropriate, or\n> > not, to use language negotiation.\n> \n> I'll take that.  Accomplices welcome.\n> \n> -- \n> Fran?ois\n> > \n> > ========================\n> > Some time was spent today discussing when this type of negotiation\n> > should be used, and when alternatives should be considered. I was \n> > actioned with posing the question to the group, to collect \n> information\n> \n> > and to solicit whether someone might be interested in \n> authoring a FAQ\n> > or article on when to use this technique.\n> > \n> > We thought Yves, John or Fran?ois might have a special interest in\n> > this subject and so I cc'd them individually.\n> > \n> > For example, there were suggestions that this approach only \n> made sense\n> \n> > where every page had an exact counterpart in another language or\n> > region. Many sites have different pages or file \n> organization based on \n> > differences in content.\n> > \n> > It might be the case that Language negotiation only makes sense for\n> > the entry page and after that page is read and a language either \n> > defaulted or selected by the user, the rest of the content would be \n> > linked directly, without relying on language negotiation.\n> > \n> > Some thought organization by language directory (e.g.\n> > yadda/en/pages.html) might be more practical than by filename (e.g.\n> > yadda/pages.en.html)\n> > \n> > There were questions about server load and scalability.\n> > \n> > There was also a discussion of roles and authorization, as content\n> > developers may not have access to some server commands,  and we \n> > considered there is guidance needed for content developers and \n> > separate guidance needed for administrators.\n> > \n> > So, we would like to ask if there is someone in the to-list \n> who would\n> > like to author or contribute to a faq on the subject of when to use \n> > language negotiation and when not to, or defining \n> situations where are\n> \n> > alternatives prefered.\n> > \n> > Any takers?\n> > \n> > \n> > \n> > \n> > \n> \n> \n\n\n\n"
        },
        {
            "subject": "WAI worried about inpage language labellin",
            "content": "This is to make you aware of a discussion on the WAI  (Web Accessibility\nInitiative) list.\n\nA short while ago there was an interesting discussion on the WAI list on\nwhether a loan-words or phrases should be marked up for language [\nhttp://lists.w3.org/Archives/Public/w3c-wai-gl/2003OctDec/0411.html\nthread ]. My conclusion was that one should consider the impact of not\nmarking up to decide - if markup wasn't likely to help it may not be\nworthwhile.\n\nToday I noticed another mail on the list questioning whether character\nencoding information would be enough to identify language change, given\nthat \"There is a lot of burden in the requiring of the <Lang> tag. Most\nsites will have vocational English words in the middle of Hebrew\nParagraphs.\"\n\nSee http://lists.w3.org/Archives/Public/w3c-wai-gl/2003OctDec/0610.html\nand following thread. (I wrote back to not confuse language with script,\nbut also wondered whether Hebrew systems can deal with embedded English\ntext anyway.)\n\nI'm not sure what is the best answer - one can see that this could be a\npain for the content author if taken to the nth degree.  But where is\nthe appropriate cutoff?\n\nRI\n\n\n\n============\nRichard Ishida\nW3C\n\ncontact info: http://www.w3.org/People/Ishida/ \n\nhttp://www.w3.org/International/ \nhttp://www.w3.org/International/geo/ \n\nW3C Internationalization FAQs\nhttp://www.w3.org/International/questions.html\nRSS feed: http://www.w3.org/International/questions.rss\n\n\n\n"
        },
        {
            "subject": "RE: New FAQ for review: Apache language negotiation set u",
            "content": "Hello Richard,\n\nI think the setting required by the webmaster (usually in httpd.conf) is:\n\nAllowOverride FileInfo Options\n\nThe setting required at the location where you want to use\nnegotiation would be\n\nOptions MultiViews\n\n(this is not included in Options All).\n\nSee http://httpd.apache.org/docs-2.0/mod/core.html#options,\nhttp://httpd.apache.org/docs-2.0/mod/core.html#allowoverride,\nhttp://httpd.apache.org/docs-2.0/content-negotiation.html#negotiation.\n\nI haven't tested this, though.\n\n\nRegards,    Martin.\n\n\nAt 16:43 03/12/17 +0000, Richard Ishida wrote:\n\n> > From: Tex Texin [mailto:tex@i18nguy.com]\n> > Sent: 17 December 2003 08:37\n>\n> > 8) You mention AllowOverride being required for .htaccess but\n> > not any other permissions or privileges. I think for\n> > negotiation to work (but don't know for sure), some other\n> > access rights or commands may need to be given. We need to\n> > make this very clear. I had a great deal of trouble with my\n> > ISP trying to get them to tell me which apache commands I was\n> > priv'd to use, and as there were several ways to get it to\n> > work, I kept trying things and was never show if I was\n> > misapplying the commands, missing some commands or not\n> > priv'd. I seem to recall multiview being required.\n>\n>My problem here is that I don't know what is required.  I'm quite\n>unfamiliar with server settings.\n>\n>Could someone provide the relevant text for me?\n>\n>Thanks,\n>RI\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "At 12:42 03/12/22 +1100, Andrew Cunningham wrote:\n\n>Martin Duerst wrote:\n\n>>It must be possible with Apache, because the Apache documentation\n>>project uses it. Look e.g. at\n>>http://httpd.apache.org/docs-2.0/en/content-negotiation.html\n>>http://httpd.apache.org/docs-2.0/ko/content-negotiation.html\n>>http://httpd.apache.org/docs-2.0/ja/content-negotiation.html\n>>and http://httpd.apache.org/docs-2.0/content-negotiation.html.\n>>But I haven't figured it out yet, but it seems to involve more\n>>than just simple configuration directives.\n>\n>I assume they're using type maps, esp since you specify URIs in the type \n>maps rather than filenames.\n\nI'll try to find out more. But you might be right. A quick\ncheck gives:\n\nhttp://httpd.apache.org/docs-2.0/en/content-negotiation.var\n-> Forbidden\nhttp://httpd.apache.org/docs-2.0/en/content-negotiation.xyz\n-> Not found\n\nUsing typemaps is certainly possible, but it requires some\namount of management to make sure they are correct. But then,\nApache also needs to do that because it includes links to all\navailable language variants in each page (which is also a\ngood thing to do, of course).\n\n\n>Content negotiation appears to be implimented at the higher directory \n>structure index levels like http://httpd.apache.org/docs-2.0/ but if you \n>follow a deep link into the documentation you don't have langauge \n>negotiation instead you have to select a language form the langauge menu. \n>Either that or my browser is misbehaving.\n\nI have just checked that. For both Netscape 7.1 and Opera 7.2,\ncontent negotiation worked fine, even for documents further down\nin the hierarchy. I can change the order of languages in preferences\nand force a reload at will. So I guess you should check your browser.\n\nRegards,    Martin.\n\n\n\n"
        },
        {
            "subject": "Re: when to use language negotiation author neede",
            "content": "Just spotted this mail from John Yunker.  It failed to reach the list\nbecause John used a yahoo address rather than his bytelevel company\naddress.\nRI\n\nFrom: John Yunker [mailto:yunkerjohn@yahoo.com] \nSent: 19 December 2003 13:36\nTo: Tex Texin; GEO; Yves Savourel; Frangois Yergeau\n\nSorry, I missed this email. Here are my two cents if\nit's not too late...\n\n\n> \n> For example, there were suggestions that this\n> approach only made sense\n> where every page had an exact counterpart in another\n> language or region.\nI think negotiation can and probably should be used\nfor even a few languages. I look at it as just another navigation layer;\nbut I would emphasize that negotiation should not take the place of a\nlanguage or country \"gateway.\" For instance, even if negotiation works\ncorrectly, the user may be using a borrowed computer and want to opt out\nof a language; therefore, a gateway must always be present.\n\n> \n> It might be the case that Language negotiation only\n> makes sense for the\n> entry page and after that page is read and a\n> language either defaulted\n> or selected by the user, the rest of the content\n> would be linked\n> directly, without relying on language negotiation.\nI agree that it should first be used on the home or\nlanding page. When you get deeper into the site, there\nis the issue of people arriving directly to these\npages by means of search engines. In this case it's a\ntougher call. A company may wish to use it here as\nwell along with a redirect back to the initial landing\npage, that is, if the person's preferred language does\nnot match the destination language of the subpage. But\nthis is a hot issue as I know many bilinguals who hate redirection due\nto language negotiation. And there may be overhead issues as well.\n\n> Some thought organization by language directory\n> (e.g.\n> yadda/en/pages.html) might be more practical than by\n> filename (e.g.\n> yadda/pages.en.html)\nI agree. Is it possible to tweak the htaccess file to\npoint to a language directory instead of a specific\npage?\n\n> There were questions about server load and\n> scalability.\nI've heard this concern from a number of techs, yet  I\nfind it odd that Google somehow pulls it without any\nappairent problems. \n\nJY\n\n__________________________________\nDo you Yahoo!?\nNew Yahoo! Photos - easier uploading and sharing.\nhttp://photos.yahoo.com/\n\n\n\n"
        },
        {
            "subject": "Re: Please check out I18N test suit",
            "content": "On Tue, 9 Dec 2003, Richard Ishida wrote:\n>\n> I have been converting our i18n test pages to use the same model as the\n> CSS tests.  I'd be grateful if you could look at two of the tests\n> quickly so that I can ensure I'm heading in the right direction.\n\nSorry it took me so long to reply. I hope my comments are still useful.\n\nOverall these are very good tests. I imagine the CSS working group might\nwant to borrow some of them for the CSS2.1 test suite when we start\ncollecting tests for that. :-)\n\n\n> The tests I have converted so far are:\n>\n> http://www.w3.org/International/tests/test-css-lang.html\n\nNow redirects to\n   http://www.w3.org/International/tests/sec-css-lang-1.html\n\nThe main change I would suggest on this page would be to remove the parts\nof the tests that explain what is going on, e.g. \"The css says: *:lang(es)\n{ color:green; }\" and \"The lang and xml:lang attributes are set to \"es\".\".\n\nAlso, the tests that should \"remain black\" shouldn't -- if the test page\nhas tests that should go green, then they should _all_ go green. The best\nthing to do there is make two pages, one for the \"positive\" tests, and one\nfor the \"negative\" tests. In the negative tests, you style them by default\ngreen, then make the rules make them red if they match.\n\nFinally, note that if a page is sent as text/html, it is HTML, whether or\nnot the DOCTYPE claims otherwise, and UAs will therefore (correctly) not\ninterpret xml:lang attributes. Thus the test that checks that xml:lang is\napplied is wrong as long as the test is sent as text/html.\n\nSame comments apply to -2 and -3.\n\n\n> http://www.w3.org/International/tests/test-bidi-blocks.html\n\nRedirects to:\n   http://www.w3.org/International/tests/sec-dir-1.html\n\nThis test seems pointless -- if the user agent can do whatever it wants\nand still claim compliance, why test it? (Note that no specification\nrequires that the UA use scrollbars, even.)\n\n\n| http://www.w3.org/International/tests/sec-dir-2.html\n\nRemove text like \"The blocks here all inherit RTL directionality from the\n<html> element.\", or at least comment it out. Most QA engineers don't\ncare, or understand, the tests -- they just want to see if the UA passes\nor fails. Once the test is found to fail, then they will always look at\nthe source -- often, at least with tests I normally work with, it turns\nout the test is wrong. Thus the test's claims can never be trusted. :-)\n\nSimilarly, for the tests on this page, remove the sample markup -- if the\ntester wants to know the markup, he'll look at the source.\n\nThe final thing on this test page is that while reference renderings are\nquite useful, on my system they are radically different from the actual\nrendering, due to differences in fonts, anti-aliasing, and so forth. (And\nsince I don't read arabic, I actualy am having trouble working out if the\ncharacters are the same.)\n\nInstead of a reference image, it might be better to have a second way of\nrendering the same content, for example using bidi overrides or\nleft-to-right tables with no borders, with each span in its own cell (a\ncommonly used way of showing the expected results of bidi rendering).\n\nNote, as an aside, that the alt texts of the images are very poor -- when\nread on an aural browser, the tests would sound like this: \"The following\nshould look like this. blablaW3Cblabla. The following should look like\nthis. 1 2 3 blablaW3Cblabla blablaW3Cblabla blablaW3Cblabla\". That's\nprobably not what you intended! :-) The alt text you give is in fact\nbetter suited for the title attribute.\n\nThe same comments apply to -3 and -4.\n\n\n| http://www.w3.org/International/tests/sec-inline-bidi-1.html\n\nDrop the <h2> headers and anything with class=notes, for the same reasons\nas given for the previous tests. The notes about using an alternative to\nreference rendering images and better alt text apply here too.\n\nThe test that says \"Check the text between quotes is in the same order.\"\nshould just be \"Check looks the same (apart from font differences).\" as\nfor the others, since that applies here too. Same with \"Check that all\ncharacters run in the same direction.\", that should just be the same as\nthe other tests. The exclamation mark ones make sense, since it is\nsensible to draw attention to the likely problem in those cases. However,\nI would suggest making two test pages for this, one for the cases where\nthe tests should just look the same, and one for the exclamation mark\ncases. That would make it easier to run through the tests quickly.\n\n\n| http://www.w3.org/International/tests/sec-text-transform-1.html\n\nAs per earlier comments, I would suggest removing most of the introduction\nbit (or putting it in comments) and the class=notes bits and <h2> headers.\n\nIt would probably make sense to split this test into one test per block of\ncodepoints.\n\nIt might also be easier to use this test if the characters were side by\nside, like this:\n\n   a  a\n   b  b\n   c  c\n   d  d\n\n...etc. For example, using a table. This might make the test long though\n(maybe several groups of columns?).\n\n\n| http://www.w3.org/International/tests/sec-list-style-type-1.html\n\nSplit these into one test page per block.\n\nIn general, as you might guess, I'm going to suggest removing most of the\nexplanatory text in these tests. Specifically, removing the \"one, should\nshow\" bits is probably best, so that the tests just look like:\n\n   Each line should show the same text twice.\n\n    a. a\n    b. b\n      a. a\n      b. b\n      c. c\n    d. c\n    e. d\n\n(Oops! That UA has a bug, as is obvious from the mismatched letters at\nthe end.)\n\nThe cases that are undefined are probably not overly useful in a testcase,\nsince they don't test anything.\n\n| http://www.w3.org/International/tests/sec-idn-1.html\n| http://www.w3.org/International/tests/sec-idn-2.html\n\nThese tests are good, except I would encourage you to use a destination\npage more like this:\n\n   http://www.hixie.ch/tests/adhoc/html/flow/object/pass.html\n\nThat makes it easier to determine what is going on for the tester.\n\n\n| http://www.w3.org/International/tests/sec-utf8-signature-1.html\n\nThe second control should say \"These characters should display as\ndescribed: A-tilde, copyright sign ...\" instead of saying what they should\n_not_ look like. :-)\n\nThe \"Additional test\", as written, is not a test, but what I call a \"demo\"\n(it doesn't say what _should_ happen, it merely demonstrates what _does_\nhappen). Since the behaviour is well defined for that test, I think it\nshould define what _should_ happen (namely, three \"random\" characters\nshould appear on the first line).\n\n(And, as for the other tests, I would generally recommend cutting back on\nthe descriptive text.)\n\n\n| http://www.w3.org/International/tests/sec-ruby-markup-1.html\n| http://www.w3.org/International/tests/sec-ruby-markup-2.html\n\nNo new comments beyond those that are mentioned for earlier tests.\n\n\nI hope that helps. Let me know if you have any questions.\n\nCheers,\n-- \nIan Hickson                                      )\\._.,--....,'``.    fL\nU+1047E                                         /,   _.. \\   _\\  ;`._ ,.\nhttp://index.hixie.ch/                         `._.-(,_..'--(,_..'`-.;.'\n\n\n\n"
        },
        {
            "subject": "Re: example page",
            "content": "Ok, I admit it. I was just jealous not to be listed. ;-)\n\nGong Xi Fa Cai! \nHappy New Year!\ntex\n\n\nSteve Billings wrote:\n> \n> Tex:\n> \n> Simplistic, but:\n> 1. He's ahead of us ;-)\n> 2. His references are top notch (Richard and Andrew).\n> \n> Steve\n> \n> Steve Billings\n> Global 360\n> Software Internationalization & Localization\n> http://www.global360.com\n> +1 978-266-1604\n> \n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org\n> [mailto:public-i18n-geo-request@w3.org]On Behalf Of Tex Texin\n> Sent: Friday, January 31, 2003 1:01 AM\n> To: GEO\n> Subject: example pages\n> \n> thought you might like to view these.\n> \n> I like the approach of:\n> http://www.otal.umd.edu/uupractice/non_english/\n> \n> although I might take issue with the content, perhaps its just too\n> simplistic.\n> \n> The link came from here-\n> http://www.otal.umd.edu/uupractice/index.html\n> \n> note the 2 other i18n papers below it.\n> \n> just fyi\n> --\n> -------------------------------------------------------------\n> Tex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\n> Xen Master                          http://www.i18nGuy.com\n> \n> XenCraft                            http://www.XenCraft.com\n> Making e-Business Work Around the World\n> -------------------------------------------------------------\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "tooltips/titl",
            "content": "Many tags have a title element which serves as a tooltip. Fine, nice idea.\nBut it seems to be problematic to have text as a subelement, since there is no\nway to assign other attributes to the title text.\nHow can I specify language or assign a font to the title element? Sometimes\nthis is needed to get it to render correctly.\n\nAny thoughts on this? Do title elements need to be limited to the language and\nfont of the base element?\ntex\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "First draft of section 3.",
            "content": "Here?s a first draft of section 3.1 of Authoring Techniques for XHTML & HTML\nInternationalization:\nhttp://www.global360.com/W3cGeo/HtmlTechniques.htm\n\nPlease review it for the obvious (completeness, accuracy, readability,\nstyle), but also for use of terminology.\n\nThanks in advance for all input.\nSteve\nSteve Billings\nGlobal 360\nSoftware Internationalization & Localization\nhttp://www.global360.com/\n978-266-1604\n\n\n\n"
        },
        {
            "subject": "Re: First draft of section 3.",
            "content": "Steve,\n\nExcellent start! Thanks for kicking us off.\n\n1) I like the breakdown and organization.\n\n2) I am not clear on what we expect the reader to know. Perhaps we should have\na section at the top that says what we think the reader needs to know, and if\nnot where to get it? Maybe that will be more evident in the context of the\noutline, but also, I am not expecting people will read this doc linearly.\n\n3) Do we want to suggest utf-8, or instead Unicode with all its transforms, or\nperhaps be specific about utf-8, utf-16?\n\n4) user agents- I wonder how we are going to establish the details on the UA.\nFor example NS 4 has some support for Unicode, but doesn't work well with it\nin forms. Should we say it can display it but not post it? I think even its\ndisplay is suspect. Doesnt support bidi I believe. For that matter, no UA\nsupports all of Unicode. What do we mean when we say a UA supports Unicode?\n\n5) re Step1: Perhaps instead of choosing an encoding based on text languages,\nwe should break it into smaller steps.\na) identify the scripts used in your text.\nb) identify the encodings supporting those scripts.\n\nSimilarly, implementation complexity is a mouthful:\nc) identify the encodings that are supported by your publishing architecture\n(web server, database, source control system)\nd) identify the encodings supported by your authoring environment and tools \n\ne) I think I might lump considering the user agent requirements with these\nconsiderations.\n\nf) Identify the encodings supported by all these environments and tools and\nsupporting the languages in the text.\n\ng) consider other factors such as performance and error-proneness of the\nencodings (examples code-switching or double-byte), perhaps the need for\nencoding conversions (difficulty, reliability of round-trip, etc.)\n\nNot sure I like all this detail I am proposing however. I throw it out for\ndiscussion.\n\n6) multilingual is about languages and does not map onto encodings so well.\n8859-1 is multilingual. Maybe we should use the term multiscript?\n(I just made that up.)\n\n7) Should this section consider the languages that might be input (into a\nform)? In choosing an encoding, I should consider that my user might not have\nthe same language(s) as my pages.\n\nhth\ntex\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03022",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n29 Jan 2003\n\nPresent: Andrew, Lloyd, Richard (chair, scribe), Russ, Steve, Tex\nRegrets: None\n\n\nNew Actions\n============\n\nACTION: Richard, create a list of section owners.\n\n\nPrior Action Items\n==============\n\nACTION: All, look at the table of contents of\nhttp://www.w3.org/International/geo/html-tech/ and send proposals to the\nlist for topics you would like to work on.\nDONE\n\nACTION: Richard, draw up some ideas on how to develop content, and\ndocument the structure of the documents for editors \nDONE First part only\n\nACTION: Russ, investigate possible tools and approaches for managing\ndistributed content development\nIn progress\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAction: Martin, provide ideas for dealing with character sets &\nencodings in forms. \n[in progress]\n\nAll: register for Tech Plenary (see below)\n[in progress] lloyd pete\nReduced rate for hotel only until Saturday (1 Feb)\n\nAll: Look at Richard's TOC and send in comments.\n[ongoing]\n\nAll: read through HTML 4.0 spec and send notes to the list about\npossible guidelines. \n[closed]\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) & also review and respond to WAI requirements doc  \n[pending]\n\nAll: send in pointers to existing guidelines \n[ongoing]\n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n[pending]\n\nRuss: contact the following people/orgs in search of additional\nparticipants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n(Siemens), trados, boeing \n[andrea contacted - she will be back at Sun in March and will let us\nknow her availability; Nuray - checking with her mgr & ac rep; No\nresponse from others Intel - michael cooperstein plus one other\n(encoding)]\n\nTex: contact the following people/orgs in search of additional\nparticipants: mark davis, lisa moore (IBM), hideki hiura (Sun) \n[mail sent, no replies yet; Spoke with Able - one employee that might be\nappropriate]\n\nRichard: craig cummings (Oracle), yves savourel (RWS), christian lieske\n(SAP), frank tang (Netscape), hakon lee (Opera) \n[Craig is too busy right now.  Mail sent to christian, frank and hakon -\nno reponse yet; Yves contacted, in review]\n\n\n\n\n\nDependencies\n===========\nNone.\n\n\nNew members\n===========\nPete Sigrist introduced himself to the group.\nWelcome Pete.\n\n\nReview of work process proposal\n========================\nDiscuss of\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0044.html\n\nSummary: It's difficult to know whether the structure proposed will work\nor not until we get some content together.  Some people may prefer to\nsubmit ideas in a different format.  We should try to impose as much\nstructure as possible to help us to merge with WAI techniques and\npresent different views, including checklists.  \n\nThe basic process outline seems reasonable.  We should establish a list\nof topic owners, who will develop a particular area.\n\nACTION: Richard, create a list of section owners.\n\n\nContent development\n===============\nWe should add a section on how to layout pages.\n\nWe should also consider issues relating to providing for multilingual\ncommunities.\n\nTitle of authoring techniques doc changed to say 'internationalization'.\n\n\nGlossary\n=======\nWe will put off the discussion about how to put together a glossary\nuntil discussions between W3C groups advances further.  In the meantime\nwe will collect terms that ought to be in a glossary.  Tex will own\nthis.\n\n\n\nNext meeting:\n==========\nSame time, same bridge, next week.\n\n\n\n\nEDITS PENDING\n=============\n\nFri 17/01/2003 16:10e, clarify the relationship between 'avoid\nescapes' and 'use hex techniques [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:09e, link to the WAI docs section on language\ndeclarations [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, incorporate guidance related to Character\nModel & Unicode and Markup Languages [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, ensure use of lower case througout for\nelement names eg. META\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\nDone\n\nFri 17/01/2003 16:07e, time & date: improve rules [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:06e, consider when it is appropriate to mention\nsource separation [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:04e, say that fragment identifiers shouldn't be\ntranslated [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, spell out PUA and link to glossary\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, add normalisation info [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, add autoresizing and bidi mirroring info\n[[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\nFri 17/01/2003 16:01edit, mention video\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:59edit, allude to vertical text in the HTML\ntechniques\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:58edit, Add a section on printing issues related\nto paper sizes to the toc. [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:51edit, make the text print smaller [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:49edit, change title\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\nDone\n\nThu 16/01/2003 16:32edit, ac 15jan, add stuff on normalisation\n\nThu 16/01/2003 16:30edit, ac 15jan, link to WAI lang stuff\n\nThu 16/01/2003 16:05edit, link to UXML\n\nThu 16/01/2003 14:42edit, standardise spellings\n\nThu 16/01/2003 14:29edit, make 2002 2003\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-0205 at 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n\"I18N\")\nDuration : 60 minutes\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 5 February 2003\nStart    : 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next\nday!)\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\nDraft agenda\n============\n\nReview of agenda\n\nReview of actions (see below)\n\nReview of dependencies (see below)\n\nReview of pending edits (see below).\n\nMeetings:\n\n    Next Face-to-Face\n       aligned with Tech Plenary\n       (http://www.w3.org/2002/10/allgroupoverview.html)\n       Royal Sonesta Hotel, Cambridge, MA USA, 3 - 7 March 2003\n       Meeting will be Monday/Tuesday 3-4 March 2003\n\n   HOTEL RATE EXPIRES AT THE END OF THIS WEEK!\n\n    Equipment request: projector, telephone line, net drops?\n\n\nNew participants\n-Yves Savourel\n\nReview of work process\n\nFormat developments\n-Review new developments\n-Update on discussions with WAI\n\nContent development status\n-Review status\n-Glossary\n\nDiscussion of specific content issues\n-Characters, encoding & entities\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Feb/0002.html\n\n-HTML autolayout\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0022.html\n\nAOB\n\n\\================================================\nDetails:\n\n\nCONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\nACTION: Richard, create a list of section owners.\n\nACTION: Richard, document the structure of the documents for editors \n\nACTION: Russ, investigate possible tools and approaches for managing\ndistributed content development In progress\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAction: Martin, provide ideas for dealing with character sets &\nencodings in forms. \n[in progress]\n\nAll: register for Tech Plenary (see below)\n[in progress] lloyd pete\nReduced rate for hotel only until Saturday (1 Feb)\n\nAll: Look at Richard's TOC and send in comments.\n[ongoing]\n\nAll: read through HTML 4.0 spec and send notes to the list about\npossible guidelines. \n[closed]\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) & also review and respond to WAI requirements doc  \n[pending]\n\nAll: send in pointers to existing guidelines \n[ongoing]\n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n[pending]\n\nRuss: contact the following people/orgs in search of additional\nparticipants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n(Siemens), trados, boeing \n[andrea contacted - she will be back at Sun in March and will let us\nknow her availability; Nuray - checking with her mgr & ac rep; No\nresponse from others Intel - michael cooperstein plus one other\n(encoding)]\n\nTex: contact the following people/orgs in search of additional\nparticipants: mark davis, lisa moore (IBM), hideki hiura (Sun) \n[mail sent, no replies yet; Spoke with Able - one employee that might be\nappropriate]\n\nRichard: craig cummings (Oracle), yves savourel (RWS), christian lieske\n(SAP), frank tang (Netscape), hakon lee (Opera) \n[Craig is too busy right now.  Mail sent to christian, frank and hakon -\nno reponse yet; Yves contacted, in review]\n\n\n\n\nDEPENDENCIES\n=============\n\nNone.\n\n\n\nEDITS PENDING\n=============\n\nFri 17/01/2003 16:10e, clarify the relationship between 'avoid\nescapes' and 'use hex techniques [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:09e, link to the WAI docs section on language\ndeclarations [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, incorporate guidance related to Character\nModel & Unicode and Markup Languages [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:07e, time & date: improve rules [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:06e, consider when it is appropriate to mention\nsource separation [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:04e, say that fragment identifiers shouldn't be\ntranslated [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, spell out PUA and link to glossary\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, add normalisation info [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, add autoresizing and bidi mirroring info\n[[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\nFri 17/01/2003 16:01edit, mention video\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:59edit, allude to vertical text in the HTML\ntechniques\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:58edit, Add a section on printing issues related\nto paper sizes to the toc. [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:51edit, make the text print smaller [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nThu 16/01/2003 16:32edit, ac 15jan, add stuff on normalisation\n\nThu 16/01/2003 16:30edit, ac 15jan, link to WAI lang stuff\n\nThu 16/01/2003 16:05edit, link to UXML\n\nThu 16/01/2003 14:42edit, standardise spellings\n\nThu 16/01/2003 14:29edit, make 2002 2003\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n------------------------------------------------------------------------\n--------\n\nNext message: Richard Ishida: \"FW: [techs] summary of today's techniques\ntelecon\" \nPrevious message: Richard Ishida: \"Work process suggestions\" \nMessages sorted by: [ date ] [ thread ] [ subject ] [ author ] \nOther mail archives: [this mailing list] [other W3C mailing lists] \nMail actions: [ respond to this message ] [ mail a new topic ] \n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "glossary pag",
            "content": "fyi, the glossary page is here:\n\nhttp://www.i18nguy.com/markup/i18n-glossary.html\n\nand will have links to your draft chapters.\n\nAs you write, please send me an email with terms, acronyms, abbreviations that\nyou feel should be added.\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "RE: All Group/Tech Plenary AV Questionnaire/Meeting details   Reply Requeste",
            "content": "Hi Amy,\n\nThe GEO task force (mon & tues) would like, if possible:\n\na projector (for laptop projection)\nthree or more wired network connections\na speaker phone\nsomething to scribble on - whiteboard or flipchart\n\nThanks!\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: Amy van der Hiel [mailto:amy@w3.org] \n> Sent: 05 February 2003 16:26\n> To: Bert Bos; Roger Gimson; Stephane Boyera; judy Brewer; \n> Martin Duerst; ishida@w3.org; Patrick D. F. Ion; Max \n> Froumentin; Al Gilman; Lorrie Cranor; Danny Weitzner; Lofton \n> Henderson; Eric Miller; Thierry Michel; Jon Gunderson; Wendy \n> A Chisholm; Champion, Mike; C. M. Sperberg-McQueen; \n> sca@us.ibm.com; ht@w3.org\n> Cc: w3t-tpregister@w3.org\n> Subject: Re: All Group/Tech Plenary AV Questionnaire/Meeting \n> details - Reply Requested\n> \n> \n> Dear all\n> \n> As of today, I have not received responses on the AV questionnaire \n> http://lists.w3.org/Archives/Member/chairs/2003JanMar/0014.htm\nl I sent two \nweeks from the below groups:\n\nCSS\nDI\nEOWG\nGlossary\nI18N Core\nI18N GEO\nMath\nPFWG\nP3PWG\nQAWG\nSWArch\nTimed Text\nUAWG\nWCAG\nWS Arch\nXML Schema\nXSL\n\nPlease note:  If your form is late, we cannot guarantee that you order\nwill \nbe completed. *On-site AV requests will not be accepted.*\n\nIf you have any questions, please contact us at tpregister@w3.org.\n\nThanks very much.\n\nRegards,\nAmy\n\n-- \nAmy van der Hiel\namy@w3.org\nW3C/MIT 200 Technology Square, Cambridge, MA 02139 USA\ntelephone: +1.617.253.5628  fax: +1.617.258.5999\n\n\n\n"
        },
        {
            "subject": "Re: First draft of section 3.",
            "content": "Hello Steve, others,\n\nI just have a few comments to your draft, sorry to be late.\nThey are mainly about terminology. I would suggest the following\nchanges:\n\n'page' -> 'document' (this is standard W3C terminology)\n'character set': If possible, avoid this term altogether\n'page encoding' -> 'character encoding' or 'character encoding of the document'\n\nRegards,    Martin.\n\nAt 12:51 03/02/03 -0500, Steve Billings wrote:\n\n>Here s a first draft of section 3.1 of Authoring Techniques for XHTML & \n>HTML Internationalization:\n>\n><http://www.global360.com/W3cGeo/HtmlTechniques.htm>http://www.global360.co \n>m/W3cGeo/HtmlTechniques.htm\n>\n>\n>\n>Please review it for the obvious (completeness, accuracy, readability, \n>style), but also for use of terminology.\n>\n>\n>\n>Thanks in advance for all input.\n>\n>Steve\n>\n>Steve Billings\n>\n>Global 360\n>\n>Software Internationalization & Localization\n>\n><http://www.global360.com/>http://www.global360.com/\n>\n>978-266-1604\n>\n>\n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03020",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n5 feb 2003\n\nPresent: Andrew, Lloyd, Richard (chair, scribe), Russ, Steve, Tex,\nMartin\nRegrets: None\n\n\nNew Actions\n============\n\nACTION: RI to discuss comments on Steve's proposal for 3.1 off-line\n\nACTION: RI, set up an area on the W3C site for people to post proposals,\nand give people access.\n\nACTION: Tex, include links to submissions on his glossary page in the\nmeantime to gather things together in one place.\n\nACTION: All, send in preferred user names to RI for use in accessing W3C\nsite.\n\nACTION: All, send in any ideas for a better name than 'rule'.\n\n\n\nAction Items review\n==============\n\nACTION: Richard, create a list of section owners.\nDONE\n\nACTION: Richard, document the structure of the documents for editors \n\nACTION: Russ, investigate possible tools and approaches for managing\ndistributed content development \n[closed]\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAction: Martin, provide ideas for dealing with character sets &\nencodings in forms. \n[in progress - Replace with general action item\n\nAll: register for Tech Plenary (see below)\n[only lloyd outstanding - note reduced rate for hotel only until\nSaturday (1 Feb)]\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) & also review and respond to WAI requirements doc  \n[pending]\n\nAll: Look at Richard's TOC and send in comments.\n[ongoing]\n\nAll: send in pointers to existing guidelines \n[ongoing]\n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n[pending]\n\nRuss: contact the following people/orgs in search of additional\nparticipants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n(Siemens), trados, boeing \n[no movement]\n\nTex: contact the following people/orgs in search of additional\nparticipants: mark davis, lisa moore (IBM), hideki hiura (Sun) \n[no replies yet; Spoke with Able - one employee that might be\nappropriate]\n\nRichard: craig cummings (Oracle), yves savourel (RWS), christian lieske\n(SAP), frank tang (Netscape), hakon lee (Opera) \n[Yves now on mailing list]\n\n\n\n\nMeetings\n===========\nWe will request a conference call facility, some wired network\nconnections, and board for scribbling at the Tech Plenary\n\n\nNew participants\n============\nYves Savourel has joined the list.\n\n\nContent development\n===============\nEmail to Tex your suggestions for terms that ought to appear in a\nglossary.  \nTex has added a few items already at\nhttp://www.i18nguy.com/markup/i18n-glossary.html\n\n\nDiscussion of Steve's submission\n=========================\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Feb/0002.html\n\nWe should add a technique saying 'use utf-8 or another Unicode encoding'\nbefore the two that Steve proposes.\nACTION: RI to discuss comments on Steve's proposal for 3.1 off-line\n\nQuestion still needing further discussion:\n-should we represent best practise, current practise, or\nreligious belief?\n\n\nACTION: RI, set up an area on the W3C site for people to post proposals,\nand give people access.\nACTION: Tex, include links to submissions on his glossary page in the\nmeantime to gather things together in one place.\nACTION: All, send in preferred user names to RI for use in accessing W3C\nsite.\n\nDiscussed alternatives for the term 'rule' for the pithy directive\nstatement part of a technique.  WAI will call this 'the technique'\nwithin a technique.\nACTION: All, send in any ideas for a better name than 'rule'.\n\n\n\nNext meeting:\n==========\nSame time, same bridge, next week.\n\n\n\n\nEDITS PENDING\n=============\n\nFri 17/01/2003 16:10e, clarify the relationship between 'avoid\nescapes' and 'use hex techniques [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:09e, link to the WAI docs section on language\ndeclarations [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, incorporate guidance related to Character\nModel & Unicode and Markup Languages [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:07e, time & date: improve rules [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:06e, consider when it is appropriate to mention\nsource separation [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:04e, say that fragment identifiers shouldn't be\ntranslated [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, spell out PUA and link to glossary\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, add normalisation info [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, add autoresizing and bidi mirroring info\n[[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, mention video\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:59edit, allude to vertical text in the HTML\ntechniques\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:58edit, Add a section on printing issues related\nto paper sizes to the toc. [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:51edit, make the text print smaller [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nThu 16/01/2003 16:32edit, ac 15jan, add stuff on normalisation\n\nThu 16/01/2003 16:30edit, ac 15jan, link to WAI lang stuff\n\nThu 16/01/2003 16:05edit, link to UXML\n\nThu 16/01/2003 14:42edit, standardise spellings\n\nThu 16/01/2003 14:29edit, make 2002 2003\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "FW: [techs] proposal to replace use of &quot;rules&quot",
            "content": "FYI.  The enclosed mail outlines WAI's concerns with the term 'rule'\napplied to the directive part of a technique, and proposes an\nalternative that seems to have been accepted.\n\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n-----Original Message-----\nFrom: w3c-wai-gl-request@w3.org [mailto:w3c-wai-gl-request@w3.org] On\nBehalf Of Wendy A Chisholm\nSent: 28 January 2003 18:02\nTo: w3c-wai-gl@w3.org\nSubject: [techs] proposal to replace use of \"rules\"\n\n\n\nHello,\n\nA while ago (january 2002?), when we began making the techniques\ndocuments \nmore testable we used the phrase \"rules\" for the testable statements.\nFor \na reminder of what this looks like, refer to the HTML Techniques [1]. We\n\ndidn't want to use \"checkpoint\" or \"criterion\" since we wanted to \ndistinguish the technology-specifics from the general guidelines and \ncheckpoints.\n\nHowever, there are many acknowledged issues with the term \"rule.\"  e.g.,\nit \ncould be confused with the 508 rules, it may be interpreted as being too\n\nprescriptive. etc.  Thus, to continue the discussion about what term to\nuse \ninstead, here is a proposal.  First, at the top level we currently have:\nGuidelines which are made up of checkpoints Checkpoints which are made\nup of success criteria success criteria\n\nI propose that at the technology-specific level we have:\n(one or many) techniques that show how to meet a top-level success\ncriterion a technique is a combination of:\n- the technique (e.g., \"Use the meta element to...\")\n- examples\n- descriptions\n- etc. (all the other stuff from the schema and techniques requirements)\n\nfor those of you interested in the schema, i think we can continue to\nuse \nthe element \"rule\" but when we generate documents from the xml we do \nsomething along the following:\n\n====\nTITLE: the document title\n\nTechniques:\nUse the TITLE element to describe the document.\n====\n\nBasically, replace \"Rules\" with \"Techniques.\"\n\n--wendy\n\n[1] http://www.w3.org/WAI/GL/WCAG20/wcagtech020320.html\n\n-- \nwendy a chisholm\nworld wide web consortium\nweb accessibility initiative\nhttp://www.w3.org/WAI/\n/-- \n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-0212 at 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n\"I18N\")\nDuration : 60 minutes\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 12 February 2003\nStart    : 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next\nday!)\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\nDraft agenda\n============\n\nReview of agenda\n\nReview of actions (see below)\n\nReview of dependencies (see below)\n\nReview of pending edits (see below).\n\nMeetings:\n\n    Next Face-to-Face\n       aligned with Tech Plenary\n       (http://www.w3.org/2002/10/allgroupoverview.html)\n       Royal Sonesta Hotel, Cambridge, MA USA, 3 - 7 March 2003\n       Meeting will be Monday/Tuesday 3-4 March 2003\n\n    Build agenda for Technical Plenary\nRequest from QA\nJoint mtgs with WAI?\n\n\nNew participants\n\nReview of work process\n-w3c accounts\n\nFormat developments\n-Review new developments\n-Update on discussions with WAI\n\nContent development status\n-Review status\n-Glossary\n\nDiscussion of specific content issues\n-HTML autolayout\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0022.html\n\nAOB\n\n\\================================================\nDetails:\n\n\nCONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\nACTION: RI to discuss comments on Steve's proposal for 3.1 off-line\nDONE\n\nACTION: RI, set up an area on the W3C site for people to post proposals,\nand give people access.\n\nACTION: Tex, include links to submissions on his glossary page in the\nmeantime to gather things together in one place.\nDONE\n\nACTION: All, send in preferred user names to RI for use in accessing W3C\nsite.\n\nACTION: All, send in any ideas for a better name than 'rule'.\n\nACTION: Richard, create a list of section owners.\nDONE\n\nACTION: Richard, document the structure of the documents for editors \nDONE\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: register for Tech Plenary (see below)\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) & also review and respond to WAI requirements doc  \n\nAll: Send in content proposals and proposals relating to structure of\ntemplate..\n\nAll: send in pointers to existing guidelines \n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n\nRuss: contact the following people/orgs in search of additional\nparticipants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n(Siemens), trados, boeing \n\n\nTex: contact the following people/orgs in search of additional\nparticipants: mark davis, lisa moore (IBM), hideki hiura (Sun), Able\n\nRichard: christian lieske (SAP), frank tang (Netscape), hakon lee\n(Opera) \n\n\n\nDEPENDENCIES\n=============\n\nNone.\n\n\n\nEDITS PENDING\n=============\n\nFri 17/01/2003 16:10e, clarify the relationship between 'avoid\nescapes' and 'use hex techniques [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:09e, link to the WAI docs section on language\ndeclarations [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, incorporate guidance related to Character\nModel & Unicode and Markup Languages [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:07e, time & date: improve rules [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:06e, consider when it is appropriate to mention\nsource separation [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:04e, say that fragment identifiers shouldn't be\ntranslated [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, spell out PUA and link to glossary\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, add normalisation info [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, add autoresizing and bidi mirroring info\n[[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\nFri 17/01/2003 16:01edit, mention video\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:59edit, allude to vertical text in the HTML\ntechniques\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:58edit, Add a section on printing issues related\nto paper sizes to the toc. [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:51edit, make the text print smaller [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nThu 16/01/2003 16:32edit, ac 15jan, add stuff on normalisation\n\nThu 16/01/2003 16:30edit, ac 15jan, link to WAI lang stuff\n\nThu 16/01/2003 16:05edit, link to UXML\n\nThu 16/01/2003 14:42edit, standardise spellings\n\nThu 16/01/2003 14:29edit, make 2002 2003\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n------------------------------------------------------------------------\n--------\n\nNext message: Richard Ishida: \"FW: [techs] summary of today's techniques\ntelecon\" \nPrevious message: Richard Ishida: \"Work process suggestions\" \nMessages sorted by: [ date ] [ thread ] [ subject ] [ author ] \nOther mail archives: [this mailing list] [other W3C mailing lists] \nMail actions: [ respond to this message ] [ mail a new topic ] \n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Initial framework document availabl",
            "content": "All,\n\nPlease find an initial draft of a framework document at\nhttp://www.w3.org/International/geo/framework/\n\nThis pulls together decisions made at the FTF last year, and supplements\nit with a small number of ideas from the WCAG requirements document,\ncurrent practise, and pointers to areas needing development.\n\nPlease take a look.  I propose to address some of the outstanding issues\nduring the FTF at Boston.\n\nCheers,\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: Initial framework document availabl",
            "content": "Hello Richard,\n\nWithout looking at the details, it seems that this document\nshould be published as a Working Draft pretty soon, maybe\nbefore the f2f or very soon afterwards.\n\nRegards,    Martin.\n\nAt 19:43 03/02/13 +0000, Richard Ishida wrote:\n\n>All,\n>\n>Please find an initial draft of a framework document at\n>http://www.w3.org/International/geo/framework/\n>\n>This pulls together decisions made at the FTF last year, and supplements\n>it with a small number of ideas from the WCAG requirements document,\n>current practise, and pointers to areas needing development.\n>\n>Please take a look.  I propose to address some of the outstanding issues\n>during the FTF at Boston.\n>\n>Cheers,\n>RI\n>\n>============\n>Richard Ishida\n>W3C\n>\n>tel: +44 1753 480 292\n>http://www.w3.org/International/\n>http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "2nd draft of section 3.1 (choosing an encoding",
            "content": "Here?s a second draft of section 3.1 of Authoring Techniques for XHTML &\nHTML Internationalization:\nhttp://www.global360.com/W3cGeo/HtmlTechniques.htm\n<http://www.global360.com/W3cGeo/HtmlTechniques.htm>\n\nNot all of the review comments have been addressed (see the attached table\nof comments). Most of the open issues are cases where I received suggestions\nthat conflicted with each other. Others are open simply because I don?t yet\nknow what the right solution is.\n\nSteve\n\n\nSteve Billings\nGlobal 360\nSoftware Internationalization & Localization\nhttp://www.global360.com/\n978-266-1604\n\n\n\n"
        },
        {
            "subject": "New versions of techniques file",
            "content": "I have slightly updated the styling of\nhttp://www.w3.org/International/geo/html-tech/ and\nhttp://www.w3.org/International/geo/html-tech/html-tech.html\n\nFor Andrew:\nI have therefore also uploaded new versions of:\nhttp://www.w3.org/International/geo/html-tech/html-authoring.xml\nhttp://www.w3.org/International/geo/html-tech/html-tech.xml\nhttp://www.w3.org/International/geo/html-tech/techniques.css\nhttp://www.w3.org/International/geo/html-tech/xmlspec-tech.xsl\nhttp://www.w3.org/International/geo/html-tech/html-authoring.html\n\nThe xml files have a few more ids assigned to section numbers.\n\nCheers,\nRI\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "New document for review: Checklis",
            "content": "Chaps,\n\nI have put together a mock-up of a checklist-type view [1] on the data\nthat's current in the HTML Authoring document [2].  This is a\nhand-crafted file, but should be derived from the Authoring document\nusing XSLT in the future.  This version is intended to simply provide a\npractical support to help us visualise where we want to go with this\nidea.\n\nNote that the table of contents to the left with expand if you click on\na heading.  Clicking on a subhead will take you to the section, where\nyou will see only the directive parts of the techniques.  To get the\nfull text, click on the icon to the right of the title.  We could also\nadd other icons/information - eg. Direct links to resources.\n\nPlease take a look at it and prepare comments.  We should discuss this\nduring the FTF.\n\nCheers,\nRI\n\n\n[1]\nhttp://www.w3.org/International/geo/upload/2003/02/html-authoring.html\n[2] http://www.w3.org/International/geo/html-tech/\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "RE: New document for review: Checklis",
            "content": "Oops.\n\nLink [1] should read \nhttp://www.w3.org/International/geo/upload/2003/02/html-authoring-ch.htm\nl\n\n\n> -----Original Message-----\n> From: public-i18n-geo-request@w3.org \n> [mailto:public-i18n-geo-request@w3.org] On Behalf Of Richard Ishida\n> Sent: 18 February 2003 16:02\n> To: public-i18n-geo@w3.org\n> Subject: New document for review: Checklist\n> \n> \n> \n> Chaps,\n> \n> I have put together a mock-up of a checklist-type view [1] on \n> the data that's current in the HTML Authoring document [2].  \n> This is a hand-crafted file, but should be derived from the \n> Authoring document using XSLT in the future.  This version is \n> intended to simply provide a practical support to help us \n> visualise where we want to go with this idea.\n> \n> Note that the table of contents to the left with expand if \n> you click on a heading.  Clicking on a subhead will take you \n> to the section, where you will see only the directive parts \n> of the techniques.  To get the full text, click on the icon \n> to the right of the title.  We could also add other \n> icons/information - eg. Direct links to resources.\n> \n> Please take a look at it and prepare comments.  We should \n> discuss this during the FTF.\n> \n> Cheers,\n> RI\n> \n> \n> [1] \n> http://www.w3.org/International/geo/upload/2003/02/html->\nauthoring.html\n> [2] http://www.w3.org/International/geo/html-tech/\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/ http://www.w3.org/People/Ishida/\n> \n\n\n\n"
        },
        {
            "subject": "MINUTES: I18n GEO teleconference 03021",
            "content": "MINUTES \n\nW3C I18n GEO Phone Conference\n12 feb 2003\n\nPresent: Andrew, Richard (chair, scribe), Steve, Tex, Martin\nRegrets: Russ\n\n\n\n\nNew Actions\n============\n\nACTION: Richard, check whether QA needs more than half an hour, and ask\nfor more information about what they want to talk about.\n\n\n\nAction Items review\n==============\n\nACTION: RI to discuss comments on Steve's proposal for 3.1 off-line \nDONE\n\nACTION: RI, set up an area on the W3C site for people to post proposals,\nand give people access.\nIn progress\n\nACTION: Tex, include links to submissions on his glossary page in the\nmeantime to gather things together in one place. \nDONE\n\nACTION: All, send in preferred user names to RI for use in accessing W3C\nsite.\nIn progress\n\nACTION: All, send in any ideas for a better name than 'rule'.\n\nACTION: Richard, document the structure of the documents for editors \nDONE\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nAll: register for Tech Plenary (see below)\nDONE\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) & also review and respond to WAI requirements doc  \n\nAll: Send in content proposals and proposals relating to structure of\ntemplate..\n\nAll: send in pointers to existing guidelines \n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n\nRuss: contact the following people/orgs in search of additional\nparticipants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n(Siemens), trados, boeing \n\nTex: contact the following people/orgs in search of additional\nparticipants: mark davis, lisa moore (IBM), hideki hiura (Sun), Able\n[Tex has spoken with Bill hall, who seems interested.  Richard has asked\nhim to fill out the standard forms.]\n\n\nRichard: christian lieske (SAP), frank tang (Netscape), hakon lie\n(Opera) \n\n\n\n\nMeetings\n===========\nBrief discussion of agenda topics for FTF in Boston\nQA want to talk with us for about half an hour to discuss needs,\nexpectations and position with regards to QA.\nACTION: Richard, check whether QA needs more than half an hour, and ask\nfor more information about what they want to talk about.\nWe could discuss who our audience will be in more detail\ndo we evangelise or document current practise?\nwhat versions of user agent should we care about?\nwhat about mechanisms for printing guidelines if there are\nmultiple pages - what requirements does printing place on us?\nWe could also discuss content\nandrew hopes to submit something about language specification\nthis week\ntex hopes to provide info about div vs. table layout\nsteve wants to produce an update of his previous submission and\nstart on section 3.2\n\n\n\n\nContent development\n===============\nDiscussed some points related to Steve's submission about choosing an\nencoding\nhe has added a first technique saying choose a unicode encoding\ndiscussion about to what detail we should help people choose a\nnon-Unicode character set\nSuggestion that we could develop language or script specific templates\nfor example, a template specifically for people who want to\ncreate arabic pages\ncould this be implemented using filters on the data perhaps?\nWe may need to invent new resource information as part of writing a\nsection - ie. Auxiliary pages pointed to from the techniques\ntechniques descriptions should probably be kept very tightly\nbound to just an explanation of the directive/rule\n\n\n\nNext meeting:\n==========\nSame time, same bridge, next week.\n\n\n\nEDITS DONE\n=============\nNone.\n\n\nEDITS PENDING\n=============\n\nFri 17/01/2003 16:10e, clarify the relationship between 'avoid\nescapes' and 'use hex techniques [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:09e, link to the WAI docs section on language\ndeclarations [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, incorporate guidance related to Character\nModel & Unicode and Markup Languages [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:07e, time & date: improve rules [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:06e, consider when it is appropriate to mention\nsource separation [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:04e, say that fragment identifiers shouldn't be\ntranslated [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, spell out PUA and link to glossary\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, add normalisation info [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, add autoresizing and bidi mirroring info\n[[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, mention video\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:59edit, allude to vertical text in the HTML\ntechniques\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:58edit, Add a section on printing issues related\nto paper sizes to the toc. [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:51edit, make the text print smaller [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nThu 16/01/2003 16:32edit, ac 15jan, add stuff on normalisation\n\nThu 16/01/2003 16:30edit, ac 15jan, link to WAI lang stuff\n\nThu 16/01/2003 16:05edit, link to UXML\n\nThu 16/01/2003 14:42edit, standardise spellings\n\nThu 16/01/2003 14:29edit, make 2002 2003\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "AGENDA: I18N GEO TF telcon, 2003-0219 at 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next day!",
            "content": "AGENDA\nI18N GEO TF teleconference\n\n\nPlease feel free to suggest additional items for the agenda.\n------------------------------------------------------------------------\nBridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n\"I18N\")\nDuration : 60-90 minutes\n------------------------------------------------------------------------\nDay     : Wednesday\nDate    : 19 February 2003\nStart    : 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next\nday!)\n------------------------------------------------------------------------\nZakim information    : http://www.w3.org/2002/01/UsingZakim\nZakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\nZakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n------------------------------------------------------------------------\n\n\n*** indicates a specific topic we need to discuss\n\n\n\nDraft agenda\n============\n\nReview of agenda\n\nReview of actions (see below)\n\nReview of dependencies (see below)\n\nReview of pending edits (see below).\n\nMeetings:\n\n    Next Face-to-Face\n       aligned with Tech Plenary\n       (http://www.w3.org/2002/10/allgroupoverview.html)\n       Royal Sonesta Hotel, Cambridge, MA USA, 3 - 7 March 2003\n      Meeting will be Monday/Tuesday 3-4 March 2003\n\n***Discuss agenda for FTF (RI will send out a proposal)\n\n\nNew participants\n\n\nReview of work process\n-Progress wrt uploading info to the W3C site\n\n\nFormat developments\n-Review new developments\n-Update on discussions with WAI\n***Brief discussion of new checklist\n\n\nContent development status\n-Review status\n-Glossary\n\n\nDiscussion of specific content issues\n***Steve's latest submission?\n\nAOB\n\n\\================================================\nDetails:\n\n\nCONTENT OWNERS\n================\n\nSteve\nAnything in section 3 (character sets, encoding, entities)\n[first priority]\n    Anything in section 10 (Objects)\n\nMartin\ncharacter sets & encodings in forms\n\nLloyd\nForms\n\nRichard \nBidi\n\nRuss\nautomatic layout\n\nAndrew\ni was thinking of jotting down some notes on the following\nareas, and \nthen seeing what i could add to other sections.\n3 Character sets, character encodings and entities\n4 Specifying the language of content\n5 Text direction\n6.4 Ruby\n7 Lists\n8 Tables\n     8.1 Mirroring tables in bidirectional text\n15 Writing source text\n\n\n\n\nACTIONS (ongoing and new)\n=======\n\nACTION: Richard, check whether QA needs more than half an hour, and ask\nfor more information about what they want to talk about.\n\nACTION: RI, set up an area on the W3C site for people to post proposals,\nand give people access. In progress\n\nACTION: All, send in preferred user names to RI for use in accessing W3C\nsite. In progress\n\nACTION: All, send in any ideas for a better name than 'rule'.\n\nAction: Richard, look at ways of making the document print with a\nsmaller font, while avoiding any WAI issues.\n\nRichard: Merge discussion doc and decisions into a framework doc (reqts\ndoc) & also review and respond to WAI requirements doc  \n\nAll: Send in content proposals and proposals relating to structure of\ntemplate..\n\nAll: send in pointers to existing guidelines \n\nSuzanne: put together a list of short term vs. long term goals related\nto education and outreach - send it to us for discussion \n\nRuss: contact the following people/orgs in search of additional\nparticipants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n(Siemens), trados, boeing \n\nTex: contact the following people/orgs in search of additional\nparticipants: mark davis, lisa moore (IBM), hideki hiura (Sun), Able\n[Tex has spoken with Bill hall, who seems interested.  Richard has asked\nhim to fill out the standard forms.]\n\nRichard: christian lieske (SAP), frank tang (Netscape), hakon lie\n(Opera) \n\n\n\nDEPENDENCIES\n=============\n\nNone.\n\n\n\nEDITS PENDING\n=============\n\nFri 17/01/2003 16:10e, clarify the relationship between 'avoid\nescapes' and 'use hex techniques [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:09e, link to the WAI docs section on language\ndeclarations [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:08e, incorporate guidance related to Character\nModel & Unicode and Markup Languages [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:07e, time & date: improve rules [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:06e, consider when it is appropriate to mention\nsource separation [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:04e, say that fragment identifiers shouldn't be\ntranslated [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, spell out PUA and link to glossary\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:03edit, add normalisation info [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 16:01edit, add autoresizing and bidi mirroring info\n[[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\nFri 17/01/2003 16:01edit, mention video\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:59edit, allude to vertical text in the HTML\ntechniques\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:58edit, Add a section on printing issues related\nto paper sizes to the toc. [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nFri 17/01/2003 15:51edit, make the text print smaller [[\nhttp://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\nThu 16/01/2003 16:32edit, ac 15jan, add stuff on normalisation\n\nThu 16/01/2003 16:30edit, ac 15jan, link to WAI lang stuff\n\nThu 16/01/2003 16:05edit, link to UXML\n\nThu 16/01/2003 14:42edit, standardise spellings\n\nThu 16/01/2003 14:29edit, make 2002 2003\n[[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Re: AGENDA: I18N GEO TF telcon, 2003-0219 at 20:00 UTC, 12noon Pacific,   3pm Eastern, 7am Australia (next day!",
            "content": "Is there a problem? It doesn't seem to like my passcode.\n\nRichard Ishida wrote:\n> \n> AGENDA\n> I18N GEO TF teleconference\n> \n> Please feel free to suggest additional items for the agenda.\n> ------------------------------------------------------------------------\n> Bridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n> \"I18N\")\n> Duration : 60-90 minutes\n> ------------------------------------------------------------------------\n> Day     : Wednesday\n> Date    : 19 February 2003\n> Start    : 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next\n> day!)\n> ------------------------------------------------------------------------\n> Zakim information    : http://www.w3.org/2002/01/UsingZakim\n> Zakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\n> Zakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n> ------------------------------------------------------------------------\n> \n> *** indicates a specific topic we need to discuss\n> \n> Draft agenda\n> ============\n> \n> Review of agenda\n> \n> Review of actions (see below)\n> \n> Review of dependencies (see below)\n> \n> Review of pending edits (see below).\n> \n> Meetings:\n> \n>         Next Face-to-Face\n>                 aligned with Tech Plenary\n>                 (http://www.w3.org/2002/10/allgroupoverview.html)\n>                 Royal Sonesta Hotel, Cambridge, MA USA, 3 - 7 March 2003\n>                 Meeting will be Monday/Tuesday 3-4 March 2003\n> \n> ***     Discuss agenda for FTF (RI will send out a proposal)\n> \n> New participants\n> \n> Review of work process\n> -       Progress wrt uploading info to the W3C site\n> \n> Format developments\n> -       Review new developments\n> -       Update on discussions with WAI\n> ***     Brief discussion of new checklist\n> \n> Content development status\n> -       Review status\n> -       Glossary\n> \n> Discussion of specific content issues\n> ***     Steve's latest submission?\n> \n> AOB\n> \n> \\================================================\n> Details:\n> \n> CONTENT OWNERS\n> ================\n> \n> Steve\n>         Anything in section 3 (character sets, encoding, entities)\n> [first priority]\n>         Anything in section 10 (Objects)\n> \n> Martin\n>         character sets & encodings in forms\n> \n> Lloyd\n>         Forms\n> \n> Richard\n>         Bidi\n> \n> Russ\n>         automatic layout\n> \n> Andrew\n>         i was thinking of jotting down some notes on the following\n> areas, and\n>         then seeing what i could add to other sections.\n>         3 Character sets, character encodings and entities\n>         4 Specifying the language of content\n>         5 Text direction\n>         6.4 Ruby\n>         7 Lists\n>         8 Tables\n>              8.1 Mirroring tables in bidirectional text\n>         15 Writing source text\n> \n> ACTIONS (ongoing and new)\n> =======\n> \n> ACTION: Richard, check whether QA needs more than half an hour, and ask\n> for more information about what they want to talk about.\n> \n> ACTION: RI, set up an area on the W3C site for people to post proposals,\n> and give people access. In progress\n> \n> ACTION: All, send in preferred user names to RI for use in accessing W3C\n> site. In progress\n> \n> ACTION: All, send in any ideas for a better name than 'rule'.\n> \n> Action: Richard, look at ways of making the document print with a\n> smaller font, while avoiding any WAI issues.\n> \n> Richard: Merge discussion doc and decisions into a framework doc (reqts\n> doc) & also review and respond to WAI requirements doc\n> \n> All: Send in content proposals and proposals relating to structure of\n> template..\n> \n> All: send in pointers to existing guidelines\n> \n> Suzanne: put together a list of short term vs. long term goals related\n> to education and outreach - send it to us for discussion\n> \n> Russ: contact the following people/orgs in search of additional\n> participants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n> (Siemens), trados, boeing\n> \n> Tex: contact the following people/orgs in search of additional\n> participants: mark davis, lisa moore (IBM), hideki hiura (Sun), Able\n> [Tex has spoken with Bill hall, who seems interested.  Richard has asked\n> him to fill out the standard forms.]\n> \n> Richard: christian lieske (SAP), frank tang (Netscape), hakon lie\n> (Opera)\n> \n> DEPENDENCIES\n> =============\n> \n> None.\n> \n> EDITS PENDING\n> =============\n> \n> Fri 17/01/2003 16:10    e, clarify the relationship between 'avoid\n> escapes' and 'use hex techniques [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:09    e, link to the WAI docs section on language\n> declarations [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:08    e, incorporate guidance related to Character\n> Model & Unicode and Markup Languages [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:07    e, time & date: improve rules [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:06    e, consider when it is appropriate to mention\n> source separation [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:04    e, say that fragment identifiers shouldn't be\n> translated [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:03    edit, spell out PUA and link to glossary\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:03    edit, add normalisation info [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:01    edit, add autoresizing and bidi mirroring info\n> [[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:01    edit, mention video\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 15:59    edit, allude to vertical text in the HTML\n> techniques\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 15:58    edit, Add a section on printing issues related\n> to paper sizes to the toc. [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 15:51    edit, make the text print smaller [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Thu 16/01/2003 16:32    edit, ac 15jan, add stuff on normalisation\n> \n> Thu 16/01/2003 16:30    edit, ac 15jan, link to WAI lang stuff\n> \n> Thu 16/01/2003 16:05    edit, link to UXML\n> \n> Thu 16/01/2003 14:42    edit, standardise spellings\n> \n> Thu 16/01/2003 14:29    edit, make 2002 2003\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/\n> http://www.w3.org/People/Ishida/\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: AGENDA: I18N GEO TF telcon, 2003-0219 at 20:00 UTC, 12noon Pacific,   3pm Eastern, 7am Australia (next day!",
            "content": "never  mind- today is tomorrow.\n\nRichard Ishida wrote:\n> \n> AGENDA\n> I18N GEO TF teleconference\n> \n> Please feel free to suggest additional items for the agenda.\n> ------------------------------------------------------------------------\n> Bridge   : +1-617-761-6200 (Zakim) with conference code 4186 (spells\n> \"I18N\")\n> Duration : 60-90 minutes\n> ------------------------------------------------------------------------\n> Day     : Wednesday\n> Date    : 19 February 2003\n> Start    : 20:00 UTC, 12noon Pacific, 3pm Eastern, 7am Australia (next\n> day!)\n> ------------------------------------------------------------------------\n> Zakim information    : http://www.w3.org/2002/01/UsingZakim\n> Zakim bridge monitor : http://www.w3.org/1998/12/bridge/Zakim.html\n> Zakim IRC bot        : http://www.w3.org/2001/12/zakim-irc-bot.html\n> ------------------------------------------------------------------------\n> \n> *** indicates a specific topic we need to discuss\n> \n> Draft agenda\n> ============\n> \n> Review of agenda\n> \n> Review of actions (see below)\n> \n> Review of dependencies (see below)\n> \n> Review of pending edits (see below).\n> \n> Meetings:\n> \n>         Next Face-to-Face\n>                 aligned with Tech Plenary\n>                 (http://www.w3.org/2002/10/allgroupoverview.html)\n>                 Royal Sonesta Hotel, Cambridge, MA USA, 3 - 7 March 2003\n>                 Meeting will be Monday/Tuesday 3-4 March 2003\n> \n> ***     Discuss agenda for FTF (RI will send out a proposal)\n> \n> New participants\n> \n> Review of work process\n> -       Progress wrt uploading info to the W3C site\n> \n> Format developments\n> -       Review new developments\n> -       Update on discussions with WAI\n> ***     Brief discussion of new checklist\n> \n> Content development status\n> -       Review status\n> -       Glossary\n> \n> Discussion of specific content issues\n> ***     Steve's latest submission?\n> \n> AOB\n> \n> \\================================================\n> Details:\n> \n> CONTENT OWNERS\n> ================\n> \n> Steve\n>         Anything in section 3 (character sets, encoding, entities)\n> [first priority]\n>         Anything in section 10 (Objects)\n> \n> Martin\n>         character sets & encodings in forms\n> \n> Lloyd\n>         Forms\n> \n> Richard\n>         Bidi\n> \n> Russ\n>         automatic layout\n> \n> Andrew\n>         i was thinking of jotting down some notes on the following\n> areas, and\n>         then seeing what i could add to other sections.\n>         3 Character sets, character encodings and entities\n>         4 Specifying the language of content\n>         5 Text direction\n>         6.4 Ruby\n>         7 Lists\n>         8 Tables\n>              8.1 Mirroring tables in bidirectional text\n>         15 Writing source text\n> \n> ACTIONS (ongoing and new)\n> =======\n> \n> ACTION: Richard, check whether QA needs more than half an hour, and ask\n> for more information about what they want to talk about.\n> \n> ACTION: RI, set up an area on the W3C site for people to post proposals,\n> and give people access. In progress\n> \n> ACTION: All, send in preferred user names to RI for use in accessing W3C\n> site. In progress\n> \n> ACTION: All, send in any ideas for a better name than 'rule'.\n> \n> Action: Richard, look at ways of making the document print with a\n> smaller font, while avoiding any WAI issues.\n> \n> Richard: Merge discussion doc and decisions into a framework doc (reqts\n> doc) & also review and respond to WAI requirements doc\n> \n> All: Send in content proposals and proposals relating to structure of\n> template..\n> \n> All: send in pointers to existing guidelines\n> \n> Suzanne: put together a list of short term vs. long term goals related\n> to education and outreach - send it to us for discussion\n> \n> Russ: contact the following people/orgs in search of additional\n> participants: john jenkins (Apple), andrea vine (Sun), nuray aykin\n> (Siemens), trados, boeing\n> \n> Tex: contact the following people/orgs in search of additional\n> participants: mark davis, lisa moore (IBM), hideki hiura (Sun), Able\n> [Tex has spoken with Bill hall, who seems interested.  Richard has asked\n> him to fill out the standard forms.]\n> \n> Richard: christian lieske (SAP), frank tang (Netscape), hakon lie\n> (Opera)\n> \n> DEPENDENCIES\n> =============\n> \n> None.\n> \n> EDITS PENDING\n> =============\n> \n> Fri 17/01/2003 16:10    e, clarify the relationship between 'avoid\n> escapes' and 'use hex techniques [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:09    e, link to the WAI docs section on language\n> declarations [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:08    e, incorporate guidance related to Character\n> Model & Unicode and Markup Languages [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:07    e, time & date: improve rules [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:06    e, consider when it is appropriate to mention\n> source separation [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:04    e, say that fragment identifiers shouldn't be\n> translated [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:03    edit, spell out PUA and link to glossary\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:03    edit, add normalisation info [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:01    edit, add autoresizing and bidi mirroring info\n> [[ http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 16:01    edit, mention video\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 15:59    edit, allude to vertical text in the HTML\n> techniques\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 15:58    edit, Add a section on printing issues related\n> to paper sizes to the toc. [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Fri 17/01/2003 15:51    edit, make the text print smaller [[\n> http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> Thu 16/01/2003 16:32    edit, ac 15jan, add stuff on normalisation\n> \n> Thu 16/01/2003 16:30    edit, ac 15jan, link to WAI lang stuff\n> \n> Thu 16/01/2003 16:05    edit, link to UXML\n> \n> Thu 16/01/2003 14:42    edit, standardise spellings\n> \n> Thu 16/01/2003 14:29    edit, make 2002 2003\n> [[http://lists.w3.org/Archives/Public/public-i18n-geo/2003Jan/0020.html\n> \n> ============\n> Richard Ishida\n> W3C\n> \n> tel: +44 1753 480 292\n> http://www.w3.org/International/\n> http://www.w3.org/People/Ishida/\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "A semantic web trust projec",
            "content": "Hi folks,\n\nRyan Lee did a thesis at W3C / MIT developing a trust system. It is in n3,\nbut might be an interesting basis to develop from.\n\nhttp://www.w3.org/2002/01/pedal/thesis.html (includes source code and\nexamples...)\n\nCheers\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Ideas for TP agend",
            "content": "Define the deliverables better\nReview the framework document:\nhttp://www.w3.org/International/geo/framework/\nWho are the intended users?  What are their needs?\nWhat user agents are we targeting?\nWhat versions of those user agents are we targeting?\nWhat is our approach: document current practise, or evangelise\nbetter practises?\nShould we be working on other templates? Eg. Script-specific?\nWAI-combined?\n\nDefine better the structure of the documents I\nWhat is the toc for the authoring doc, and the x/html and css\ntechniques databases\nShould we have a core database?\nRefine the wording and structure of the authoring toc to best\nmeet the needs of the users\n\nDefine better the structure of the documents II\n-Look at the best way of structuring content for usability of:\n-the authoring template:\nhttp://www.w3.org/International/geo/html-tech/\n-the checklist:\nhttp://www.w3.org/International/geo/upload/2003/02/html-authoring-ch.htm\nl\n-ie. what types of information, how to place that on the page,\nwhat level of detail, etc.?\n-how should these two interact?\n-Additional questions:\n-How do we deal with information about specific user\nagents? Show whether everything works on specific UA versions (like\nDanny Goodman's Dynamic HTML book), or point out unusual or\nnon-conformant features in UAs in an add-hoc manner, or both?\n-How do we handle background information, instructional\ntext, etc. (in detail)\n-How do we handle printing of the documents?\n\nDiscuss content\nbidi\ncharset\n?\n?\n\nMtgs with other groups\nQA\nWCAG?\nWAI E&O?\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "pointer to guidelines (sort of",
            "content": "For the action item about sending in pointers to guidelines:\n\nThere?s some good stuff on this site, including some that is guideline-like:\nhttp://www.alanwood.net/unicode/index.html\n\nSteve\n\nSteve Billings\nGlobal 360\nSoftware Internationalization & Localization\nhttp://www.global360.com/\n978-266-1604\n\n\n\n"
        },
        {
            "subject": "Re: pointer to guidelines (sort of",
            "content": "Yes, it's a good site.\nI added to http://www.i18nguy.com/guidelines.html\n\n\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: pointer to guidelines (sort of",
            "content": "While I think of it, there are the following resources, both \nMicrosoft-centric:\n\nAuthoring HTML for Middle Eastern Content\nhttp://www.microsoft.com/globaldev/handson/dev/Mideast.mspx\n\nThis provides a very good discussion of how the \"dir\" attribute affects \nInternet Explorer's behaviour depending on which element the \"dir\" \nattribute is assigned to (eg HTML element vs BODY element).\n\nDeveloping an International Site\nhttp://www.microsoft.com/technet/treeview/default.asp?url=/technet/prodtechnol/comm/comm2000/deploy/csintdev.asp\n\nAndrew\n\n\nSteve Billings wrote:\n> For the action item about sending in pointers to guidelines:\n> \n>  \n> \n> There?s some good stuff on this site, including some that is guideline-like:\n> \n> http://www.alanwood.net/unicode/index.html\n> \n>  \n> \n> Steve\n> \n>  \n> \n> Steve Billings\n> \n> *Global 360***\n> \n> Software Internationalization & Localization\n> \n> http://www.global360.com/\n> \n> 978-266-1604\n> \n>  \n> \n\n\n\n"
        },
        {
            "subject": "Re: pointer to guidelines (sort of",
            "content": "While I think of it, there are the following resources, both \nMicrosoft-centric:\n\nAuthoring HTML for Middle Eastern Content\nhttp://www.microsoft.com/globaldev/handson/dev/Mideast.mspx\n\nThis provides a very good discussion of how the \"dir\" attribute affects \nInternet Explorer's behaviour depending on which element the \"dir\" \nattribute is assigned to (eg HTML element vs BODY element).\n\nDeveloping an International Site\nhttp://www.microsoft.com/technet/treeview/default.asp?url=/technet/prodtechnol/comm/comm2000/deploy/csintdev.asp\n\na so-so doc.\n\nAndrew\n\nSteve Billings wrote:\n> For the action item about sending in pointers to guidelines:\n> \n>  \n> \n> There?s some good stuff on this site, including some that is guideline-like:\n> \n> http://www.alanwood.net/unicode/index.html\n> \n>  \n> \n> Steve\n> \n>  \n> \n> Steve Billings\n> \n> *Global 360***\n> \n> Software Internationalization & Localization\n> \n> http://www.global360.com/\n> \n> 978-266-1604\n> \n>  \n> \n\n\n\n"
        },
        {
            "subject": "Re: pointer to guidelines (sort of",
            "content": "While I think of it, there are the following resources, both \nMicrosoft-centric:\n\nAuthoring HTML for Middle Eastern Content\nhttp://www.microsoft.com/globaldev/handson/dev/Mideast.mspx\n\nThis provides a very good discussion of how the \"dir\" attribute affects \nInternet Explorer's behaviour depending on which element the \"dir\" \nattribute is assigned to (eg HTML element vs BODY element).\n\nDeveloping an International Site\nhttp://www.microsoft.com/technet/treeview/default.asp?url=/technet/prodtechnol/comm/comm2000/deploy/csintdev.asp\n\na so-so doc.\n\nAndrew\n\nSteve Billings wrote:\n> For the action item about sending in pointers to guidelines:\n> \n>  \n> \n> There?s some good stuff on this site, including some that is guideline-like:\n> \n> http://www.alanwood.net/unicode/index.html\n> \n>  \n> \n> Steve\n> \n>  \n> \n> Steve Billings\n> \n> *Global 360***\n> \n> Software Internationalization & Localization\n> \n> http://www.global360.com/\n> \n> 978-266-1604\n> \n>  \n> \n\n\n\n"
        },
        {
            "subject": "Re: pointer to guidelines (sort of",
            "content": "I added to guidelines page.\nI only skimmed it quickly but the second doc is very specific to Microsoft\nproducts and esp. commerceserver.\nI am not sure that it is helpful to us. Am I missing something?\n\nAndrew Cunningham wrote:\n> \n> While I think of it, there are the following resources, both\n> Microsoft-centric:\n> \n> Authoring HTML for Middle Eastern Content\n> http://www.microsoft.com/globaldev/handson/dev/Mideast.mspx\n> \n> This provides a very good discussion of how the \"dir\" attribute affects\n> Internet Explorer's behaviour depending on which element the \"dir\"\n> attribute is assigned to (eg HTML element vs BODY element).\n> \n> Developing an International Site\n> http://www.microsoft.com/technet/treeview/default.asp?url=/technet/prodtechnol/comm/comm2000/deploy/csintdev.asp\n> \n> a so-so doc.\n> \n> Andrew\n> \n> Steve Billings wrote:\n> > For the action item about sending in pointers to guidelines:\n> >\n> >\n> >\n> > There?s some good stuff on this site, including some that is guideline-like:\n> >\n> > http://www.alanwood.net/unicode/index.html\n> >\n> >\n> >\n> > Steve\n> >\n> >\n> >\n> > Steve Billings\n> >\n> > *Global 360***\n> >\n> > Software Internationalization & Localization\n> >\n> > http://www.global360.com/\n> >\n> > 978-266-1604\n> >\n> >\n> >\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Re: pointer to guidelines (sort of",
            "content": "Sorry, Just realised that the second url i sent was the wrong url, back \nto my bookmarks to find the right one.\n\nassuming my email server stops playing up\n\nAndj.\n\n\n\nTex Texin wrote:\n> I added to guidelines page.\n> I only skimmed it quickly but the second doc is very specific to Microsoft\n> products and esp. commerceserver.\n> I am not sure that it is helpful to us. Am I missing something?\n> \n> Andrew Cunningham wrote:\n> \n>>While I think of it, there are the following resources, both\n>>Microsoft-centric:\n>>\n>>Authoring HTML for Middle Eastern Content\n>>http://www.microsoft.com/globaldev/handson/dev/Mideast.mspx\n>>\n>>This provides a very good discussion of how the \"dir\" attribute affects\n>>Internet Explorer's behaviour depending on which element the \"dir\"\n>>attribute is assigned to (eg HTML element vs BODY element).\n>>\n>>Developing an International Site\n>>http://www.microsoft.com/technet/treeview/default.asp?url=/technet/prodtechnol/comm/comm2000/deploy/csintdev.asp\n>>\n>>a so-so doc.\n>>\n>>Andrew\n>>\n>>Steve Billings wrote:\n>>\n>>>For the action item about sending in pointers to guidelines:\n>>>\n>>>\n>>>\n>>>There?s some good stuff on this site, including some that is guideline-like:\n>>>\n>>>http://www.alanwood.net/unicode/index.html\n>>>\n>>>\n>>>\n>>>Steve\n>>>\n>>>\n>>>\n>>>Steve Billings\n>>>\n>>>*Global 360***\n>>>\n>>>Software Internationalization & Localization\n>>>\n>>>http://www.global360.com/\n>>>\n>>>978-266-1604\n>>>\n>>>\n>>>\n> \n> \n\n\n\n"
        },
        {
            "subject": "MINDSWAP trip repor",
            "content": "Trip Report by Dave Beckett on visit to MINDSWAP group,\n   University of Maryland, College Park, MD, USA\n   2002-09-23 to 2002-09-27\n\n[ This trip was partially funded by SWAD Europe ]\n\nMonday 2002-09-23\n\n  The first working day, I had mostly with Bijan Parsia (hosting me)\n  going over the background and the mindswap groups' projects.  The\n  group:\n    http://www.mindswap.org/\n  is based at the MINDlab at the University of Maryland (UMD),\n  College Park which is just North of Washington DC.  The group is\n  relatively new and last year Professor Jim Hendler started teaching\n  the first semantic web classes to the UMD students, several of who\n  now work for the group.\n\n  Jim is best known for his work on SHOE (Simple HTML Ontology\n  Extensions) - http://www.cs.umd.edu/projects/plus/SHOE/ - but has a\n  background in agents, robots and knowledge representation.  He was\n  seconded to DARPA for several years to run the Darpa Agent Markup\n  Language (DAML) project - http://www.daml.org/ - which later fed\n  into the DAML+OIL ontology language, that became the basis of the\n  W3C's work.  The latter is being developed by the Web Ontology\n  Working Group (WOWG) which Jim co-chairs:\n    http://www.w3.org/2001/sw/WebOnt/\n  and the language is now called OWL (Web Ontology Language).\n\n  The group now works on several projects related to DAML+OIL/OWL,\n  RDF and Parka, more of which later.  They have created several RDF\n  and Ontology markup tools for desktop use that allow attaching of\n  ontological information (properties, classes) to descriptions,\n  creating instance data.  The two main ones are:\n    SMORE - Semantic Markup, Ontology and RDF Editor\n      http://www.mindswap.org/~aditkal/editor.shtml\n    RIC - RDF Instance Creator\n      http://www.mindswap.org/~mhgrove/RIC/RIC.shtml\n  which are both Java+Swing applications.\n\n  The Parka system - http://www.mindswap.org/2002/parka/ -\n  is a knowledge base (in the AI sense) and has been deployed and\n  used commercially for several years; but can be considered a large\n  triple store, thus suitable for RDF/OWL storage.  Parka has\n  recently been released as open source software by Mindswap -\n  http://www.mindswap.org/2002/parka/ - but is a little raw at\n  present.  They have been talking to me about this while I was\n  working on the SWAD Europe storage report:\n    http://www.w3.org/2001/sw/Europe/reports/rdf_scalable_storage_report/\n  and it looked interesting.  Bijan arranged for one of the original technical\n  developers on the project to visit on Wednesday for a runthrough of\n  the system.\n\n  The group is also working on DAML-S - http://www.daml.org/services/\n  - a DAML-based Web Service Ontology.  This allows description of\n  web services that can be tied to WSDL and used with SOAP and so on\n  to create web services in a semantic web style.  There is a new\n  version 0.7 of the DAML-S ontology due out soon.\n\n\nTuesday 2002-09-24\n\n  I was pleased to find out that Jim Hendler had made himself\n  available to me all day; which was an unexpected delight.  I gave\n  him an outline of SWAD Europe work and the possible areas for\n  collaboration we might have.  It had already been noted that their\n  work on the storage systems and mine on the report above and with\n  my Redland system - http://www.redland.opensource.ac.uk/ - would be\n  useful to do collaborate on. Benchmarks and standard datasets for\n  testing stores are further possibilities.\n\n  Mindswap also plan to use Redland software as an interface layer\n  above Parka for using and abstracting from it, so that they can\n  potentially swap out the backend to another datastore for testing,\n  benchmarking; rather than build applications with a parka-only\n  binding.\n\n  The other main relationship with SWAD Europe work was in querying;\n  since Jim et al had worked on DAML query languages and this effort\n  was continuing.  The SWAD Europe work on semweb QLs is extensive\n  and they are keen for collaboration in developing use cases,\n  documenting these things and moving them towards standardising them\n  in due course.\n\n  Jim, Bijan and I also discussed the W3C semantic web standards\n  efforts and sketched out some solutions to tricky syntax problems\n  that were being raised by WebOnt.  It hopefully quickened the\n  resolution since I could discuss pro-s and con-s of different\n  solutions directly.  The particular topic here was OWL's proposed\n  use of elements outside rdf:RDF for doing ontology description.\n\n  After seeing some of the desktop tools, I outlined the work I did\n  on the MEG Registry project - http://137.222.34.57:6543/ - and the\n  desktop schema creation tool created by Damian Steer that talks to\n  it - http://www.ukoln.ac.uk/metadata/education/regproj/\n  This is something that I plan to show at the SWAD Europe workshop\n  at the Dublin Core conference in Florence in mid-October.\n\n  18:00 CMSC 828y class - AI on the Web\n    http://www.cs.umd.edu/users/hendler/CMSC828y/\n\n  Sat in on their class where Jim was going over the OWL guide\n  document to introduce them to the ontology language.  He found a\n  load of errors, but it was a brand new draft document.\n  See also http://www.w3.org/TR/2002/WD-owl-features-20020729/\n\n  The class wiki: http://www.mindswap.org/cgi-bin/webai/moin.cgi\n\n\nWednesday 2002-09-25\n\n  09:00 Meeting about Parka with Merwyn Taylor\n    http://www.cs.umd.edu/users/mtaylor/\n  who worked on Parka but now works at Johns Hopksins University.\n  Also present were Bijan Parisa, Ron Alford and Ronald Reck.\n\n  We went through a presentation (PPT slides) on how the system\n  worked and discussed the built-in limitations, constraints and\n  differences against the RDF triples model.  Parka has no specific\n  literal indexing in it; it hashes the entire string content.  It\n  seems actually that there is no distringuishing strings from URIs,\n  that has to be imposed as a practice on top of the basic core.\n\n  The knowledge base has special in-memory indexing of the subclass,\n  subproperty, instancing relations providing quick indexing.  This\n  is done via static sized arrays which work fine for typical data\n  but would need a recompile to extend them.  Parka was optimised for\n  quick response time - hence the fixed arrays and consideration of\n  fast access to the disk, done by always operating in fixed sector\n  sizes (4k).\n\n  The KB is built on top of an internal relational store which\n  provides simple and quick access.  This was developed by students\n  (including Merywn) as part of a database class and has been stable\n  but there may be a new version if the class took it further.\n  Merwyn said that they had tested Parka on Oracle but the overhead of\n  using it via a query language (SQL) proved too much.\n\n  We had a discussion of the limits in the parka database code, which\n  are somewhat tied to it's frame-based approach on the data model.\n  There is a 2.4M limit in the code on the number of distinct frames\n  (subject URIs in RDF-speak); note frames are not assertions.  This\n  is mostly caused by using an integer for indexing - the 32 bits of\n  the ingeger are split up, limiting the range substantially.  The\n  code does support \"namespaces\", although I'm not sure what that\n  means or how it helps in this regard.  The tables could also be\n  \"chunked\", pointing to next table at the bottom of full ones.\n\n  Other restrictions include how the library is using 4K pages,\n  marked in a fixed array, tracking usage.  This is stored in a 4K\n  header page meaning a limit of (under) 32K pages.  The page size\n  could be increased, although performance is best when it matches\n  the disk page size.  There are also othe rmemory usage per frame to\n  consider, such as the structural assertions (isa, instanceof, ..>)\n  which could be rather a bloat if the data itself was mostly\n  ontological or schema information.  Some of the rdf/s data seen has\n  this characteristic, but most is vastly more data than class and\n  property relationships.\n\n  Throughout the above discussion, I related the various aspects of\n  it to what I had recently read on how TAP -\n  http://tap.stanford.edu/ - solves them which addresses a similar\n  problem area, but for a specific fixed schema.  It uses MySql below\n  as one of the storage mechanisms but also provides several\n  in-memory and partially in-memory (mmap-ed) stores.  TAP, like\n  parka, provides optimised support for the structural assertions, at\n  the RDF-schema level.\n\n  After that discussion, this led onto how a better indexing library\n  could solve some of these problems and reduce the complexity of\n  parka.  I suggested the backends could be MySQL, directly via it's\n  C interface, not via SQL or possibly going direct to\n  Berkeley/Sleepycat DB which is now one of the table tables that BDB\n  allows.\n\n  Merwyn then finished with an explanation of the parka query\n  planning and evaluation.\n\n  I outlined how Redland somewhat overlapped in some of Parka's\n  activity but from an RDF point of view.\n\n\n  12:30 MINDSWAP weekly meeting\n  Aditya Kalyanpur, Ron Alford, Amy Loomis, Ronald Reck, Matt Westhoff,\n  H. Ross Baker, Mike Grove, Jennifer Golbeck, Bijan Parsia and me\n\n  They all discussed what they'd been doing for the last week and\n  then we had a demo of SMORE.  I went over SWAD Europe in outline,\n  the survey stuff I'd done/was doing and Redland.\n\n\n  14:00 Toru Ishida - Social Agents in Digital Cities\n  --  http://www.lab7.kuis.kyoto-u.ac.jp/\n\n  Talk on the use of social agents that understand the conventions of\n  social systems to foster human/human interaction.  Uses interaction\n  scenarios that are described in a language.  Toru was just\n  finishing a visit to the mindlab and had been sharing the office\n  with Bijan.\n\n\nThursday 2002-09-26\n\n  Kendall Clarke arrived, visiting Bijan - he writes for\n  XML.com (as does Bijan), O'Reilly and does technical and other\n  writing and editing -- http://clark.dallas.tx.us/kendall/\n\n  Aditya gave a demonstration of SMORE to Kendall and I, we commented\n  on the user interface since there were several things that seemed\n  unclear to us as we watched him.   It allows you to markup some\n  text (HTML) written as sentences into triple form, then browse and\n  search existing ontologies to find appropriate terms for the\n  relationships, classes.  They can be dragged and dropped to form a\n  description of the content in RDF/DAML+OIL (soon OWL) form.  The\n  resulting description can then be saved.\n\n  Met with Ron Alford and discussed the details of implementing a\n  storage backend to Redland, such as they proposed to do with\n  Parka.  Lots of looking at source code and explaining stuff that\n  really should be in documentation somewhere ;)\n\n\n  12:00  Freedman's Bureau Project\n  -- http://freedmensbureau.com/\n\n  Meeting with Harry Keeling and Jerry ? (Howard University, DC)\n  -- http://www.founders.howard.edu/CEACS/Departments/CompSci/\n  along with Jen, Jim, Bijan, Toru and Kendall.\n\n  This is a (proposed) digital library project based on taking the\n  preserved paper records from the 1865- records made by the\n  \"The Bureau of Refugees, Freedmen and Abandoned Lands,\"\n  which dealt with providing support for the newly freed people.  The\n  result is a large amount of microfiche, which can then give lots of\n  images.  The idea is to set up a system that allows multiple people\n  to annotate and comment on the documents in the images; since there\n  are lots of views or ways of approaching their description.  Some\n  basic ontologies would start it off, but the expectation would be\n  to provide ways to have all interpretations representable.\n\n  I was sure I'd heard of a similar project (scanning, images,\n  annotations, Dublin Core) but couldn't remember or google for the\n  references.\n\n\n  18:00 CMSC 828y class - AI on the Web\n    http://www.cs.umd.edu/users/hendler/CMSC828y/\n\n  Next class and during it I gave an overview of RDF tools and\n  resources on the web that they could use.  The programming\n  experience here seemed to be majority Java, some Python, 1 perl out\n  of the approx 25 students.  I also went through the details of some\n  of the RDF bots work - logger and especially foafbot, which uses\n  redland underneath, but in the detail of how it manages trust\n  relationships.   Also encouraged them to hang out on the #rdfig\n  channel.\n\n  Met for the first time, Jordan Katz, a high school student\n  attending this graduate class, who has been working on displaying\n  RDF via XSLT sheets to give multiple views of the document\n  depending on the audience.\n\n\nFriday 2002-09-27\n\n  10:00 RDF Core Telecon\n\n  Agenda:\n  http://lists.w3.org/Archives/Public/w3c-rdfcore-wg/2002Sep/0329.html\n\n\n  11:20 Meeting with Ronald Reck\n\n  Suggested various surveying things he could do on the datasets he\n  had that would be useful to find out.  Some of the parka\n  restrictions might be worth expanding if common datasets had\n  problems with them (large literals say).\n\n\n  14:00 Redland overview\n\n  I gave a whiteboard outline of Redland and the state of the changes\n  I was making to Ron Alford, Bijan, Kendall and Jim (partially).\n  Some of this is partially done (iterators change) and some is\n  planned (web, query, iostreams) and required to support other\n  features.  I tried to show how Parka, querying and relational\n  backends would fit into the picture which Redland currently has\n  some skeleton support for, but not complete.\n\n\nSaturday 2002-09-28\n\n  Travelling back via Dulles Airport - got a lot of hacking done on\n  Raptor which seems to be reducing in bug count:\n  http://www.redland.opensource.ac.uk/raptor/\n\n\nPlus throughout the week lots of debugging various bits of code and\nhelping them with python and php access to Redland as well as doing a\nlittle report writing (Monday only).\n\n\n\n"
        },
        {
            "subject": "Your attendance at the GEO FTF at the Technical Plenar",
            "content": "Dear FTF observers,\n\nThankyou for your interest in observing the GEO face to face meeting at\nthe Technical Plenary in Boston.  We look forward to seeing you there.\n\nSo as not to slow down the discussion, I would be grateful if you would\nread the following documents before arriving:\n-http://www.w3.org/International/geo/framework/ \n-http://www.w3.org/International/geo/html-tech/ \n-\nhttp://www.w3.org/International/geo/upload/2003/02/html-authoring-ch.htm\nl \n\n\nI would also be grateful if you could note down briefly \n-what interests you in the GEO meeting, \n-what you are hoping to take away from the meeting, and \n-what days/times you are intended to attend.\n\n\nYou can find a first cut at the agenda at\nhttp://www.w3.org/International/geo/2003/02/ftf-agenda-200303.html\n\n\nMany thanks,\nRichard\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "RE: Your attendance at the GEO FTF at the Technical Plenar",
            "content": "> I would also be grateful if you could note down briefly \n> -what interests you in the GEO meeting, \n> -what you are hoping to take away from the meeting, and \n> -what days/times you are intended to attend.\n\nApologies. I meant to add \"and send your note to me at ishida@w3.org\".\n\nThanks.\nRI\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n> -----Original Message-----\n> From: Richard Ishida [mailto:ishida@w3.org] \n> Sent: 20 February 2003 15:08\n> To: 'Steve Bratt'; 'Karl Dubost'; 'Ivan Herman'; 'Olivier \n> Thereaux'; 'Marie-Claire Forgue'; lojek@gmx.net; \n> charles@w3.org; Yin-Leng.Husband@hp.com; Gerald.edgar@boeing.com\n> Cc: Richard Ishida; public-i18n-geo@w3.org\n> Subject: Your attendance at the GEO FTF at the Technical Plenary\n> \n> \n> Dear FTF observers,\n> \n> Thankyou for your interest in observing the GEO face to face \n> meeting at the Technical Plenary in Boston.  We look forward \n> to seeing you there.\n> \n> So as not to slow down the discussion, I would be grateful if \n> you would read the following documents before arriving:\n> -http://www.w3.org/International/geo/framework/ \n> -http://www.w3.org/International/geo/html-tech/ \n> - \n> http://www.w3.org/International/geo/upload/2003/02/html-author\ning-ch.htm\nl \n\n\nI would also be grateful if you could note down briefly \n-what interests you in the GEO meeting, \n-what you are hoping to take away from the meeting, and \n-what days/times you are intended to attend.\n\n\nYou can find a first cut at the agenda at\nhttp://www.w3.org/International/geo/2003/02/ftf-agenda-200303.html\n\n\nMany thanks,\nRichard\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/ http://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "QA discussion during FT",
            "content": "-----Original Message-----\nFrom: Olivier Thereaux [mailto:ot@w3.org] \nSent: 20 February 2003 22:01\nTo: ishida@w3.org\nSubject: Re: Visiting the GEO at tech plenary(?)\n\n\n\n[snip]\n\n>  When I mentioned\n> it to the group, they wanted to get more information about what would\n> be\n> discussed,  Could\n> you give me some details?\n\nFor most groups the focus will be on QA itself: the QAWG wants to know \nwhat each group goals, expectations, understanding of QA is, and of \ncourse where they are in their own QA process.\n\nIn the case of GEO, even though we could discuss this a little, I would \nrather focus the discussion on what we have in common, i.e. outreach. \nDuring last QAWG f2f meeting we had Matt and Wendy as guests, and among \nothers we discussed our plans and experience on outreach, which I \nbelieve was extremely profitable for the QAWG.\n\n> and wondered whether a half hour would be long enough.\n\nHalf an hour was my suggestion, as I don't want to take too much of \nyour time. If you think we can or should take more time, that would be \ngreat. At this point I have nothing but your group schedule for monday, \nso I may probably sit in for half a day with your group and listen.\n\nThanks.\n-- \nOlivier\n\n\n\n"
        },
        {
            "subject": "First draft of section 3.",
            "content": "For your review, I?ve added section 3.2 (specifying the page encoding) to\nthis document:\nhttp://www.global360.com/W3cGeo/HtmlTechniques.htm#s32\n\nSince we haven?t sorted out the terminology issues yet (?page? vs.\n ?document?, etc.), 3.2 is just as broken in that respect as 3.1.\n\nSteve\nSteve Billings\nGlobal 360\nSoftware Internationalization & Localization\nhttp://www.global360.com/\n978-266-1604\n\n\n\n"
        },
        {
            "subject": "TP agend",
            "content": "All,\n\nI am travelling this week on non-W3C business and struggling to get\naccess to the internet, so please bear with me.  Just wanted to let you\nknow that WCAG (WAI's Web Content Accessibility Group) would indeed like\nto meet with us during the Tech Plenary.  We have fixed a meeting for\n5.30-6.30 on the Tuesday.  Wendy Chisholm of WCAG will lead the meeting,\nexplaining to us the relationships between the various aspects of WAI\ndeliverable (guidelines, checkpoints, checklists, techniques, tests...)\nand their plans for architecture and structure of the latest WAI\ntechniques.  We may also have some QA attendance, but that's not yet\nclear.  Towards the end of the meeting we can discuss opportunities for\nconvergence between GEO and WCAG approaches.\n\nAlso, I just heard from Judy Brewer that she is also interested in\nhaving a joint discussion with ourselves and WAI Education & Outreach\npeople - possibly the thrust of this will be for us to keep abreast with\nWAI's latest initiatives re E&O.  I will try to get a clearer idea about\nthis and let you know asap.\n\nCheers,\nRI\n\n\n\n============\nRichard Ishida\nW3C\n\ntel: +44 1753 480 292\nhttp://www.w3.org/International/\nhttp://www.w3.org/People/Ishida/\n\n\n\n"
        },
        {
            "subject": "Annotations Work Package  Deliverable 12.2.",
            "content": "Hi folks,\n\nThis Workpackage is in two parts - the demonstrator and the report.\n\nThere is a demonstrator, in the form of some utilities that work with the\nannotea protocol at http://www.w3.org/2001/sw/Europe/200209/annodemo\n\nThese include a query tool for \"off the shelf\" annotea servers, as well as a\ncustomised query for an annotea server that has been specialised to use EARL.\n\nThe report, due at the end of this month, will include explanation of how to\nset up these tools and others that are available. It will also provide some\nindication of possible future use of the tools.\n\nDuring that development some more simple utilities are likely to be released\n- the next probable development will be upgrading MUTAT -\nhttp://www.w3.org/QA/tools/MUTAT - so that it can also interact with the EARL\nservice, and the existing tools may be further enhanced.\n\n(Sorry for the delay in announcing this)\n\nCheers\n\nCharles\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Transforming XML content into RDF assertions (fwd",
            "content": "A classic FAQ; fwd'd for reference re the XML<->RDF WP.\n\nDan\n\n---------- Forwarded message ----------\nDate: Thu, 03 Oct 2002 10:10:17 -0400\nFrom: Michael Denny <denn@suffolk.lib.ny.us>\nTo: www-rdf-interest@w3.org\nSubject: Transforming XML content into RDF assertions\nResent-Date: Thu, 3 Oct 2002 10:11:12 -0400 (EDT)\nResent-From: www-rdf-interest@w3.org\n\n\nAs a newcomer to this list, who reviewed its archives in only a cursory\nfashion, I have a question about the practical conversion of XML content\ninto an RDF knowledgebase?\n\nIf one has a collection of XML documents sharing one or more XML Schemas and\nan RDF Schema describing the knowledgebase structure, how would they proceed\nto populate the knowledgebase?  Is there a tool that helps one build an\nexecutable mapping between an XML Schema and an RDFS or DAML+OIL schema?\nAre there examples where useable knowledgebases have been realized in this\nmanner?\n\nThanks for any guidance.\n\nMichael Denny\n\n\n\n"
        },
        {
            "subject": "SW application scenarios: Company Account",
            "content": "http://www.w3.org/2002/04/corpinfo/semweb-scenario\nAn experiment in W3C spec overlap: using SVG, MathML, XML, RDF to\nrepresent company accounts in the Web.\n\n\n... just rediscovered some experiments from earlier this year, which I'm\nhoping we might find useful within SWAD-Europe. Includes a proof of\nconcept implementation in N3/cwm.\n\nStephen, Max, any chance you could take a look at this from a MathML\nperspective?\n\ncheers,\n\nDan\n\n\n-- \nmailto:danbri@w3.org\nhttp://www.w3.org/People/DanBri/\n\n\n\n"
        },
        {
            "subject": "[Policysig] First International Conference on Trust Management  (fwd",
            "content": "This might be an interesting venue - I assume Graham Klyne can tell us more,\nsince he is on the program committee.\n\ncheers\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n---------- Forwarded message ----------\nDate: Thu, 10 Oct 2002 09:58:38 +0100\nFrom: Morris Sloman <m.sloman@doc.ic.ac.uk>\nTo: policy-sig@doc.ic.ac.uk\nSubject: [Policy-sig] First International Conference on Trust Management\n\n\nThe First International Conference On Trust Management\n\n28-30 May 2003\n\nHeraklion, Crete, Greece\n( http://www.eBusinessCity.org )\n\n\nThe First International Conference on Trust Management will take place at\nthe beautiful summer resort Kalimera Kriti ( Good Morning Crete )\n(http://www.kalimerakriti.gr/ ) near Heraklion, Crete, Greece, on May 28-30\n2003. The Conference is organized by iTrust, a Working Group on Trust\nManagement in Dynamic Open Systems (http://www.itrust.uoc.gr/) and the\nUniversity of Crete ( http://www.uoc.gr ) and partially funded by the\nFuture and Emerging Technologies (FET) unit of the IST program,\nhttp://www.cordis.lu/ist/fethome.htm The Proceedings will be published by\nthe Lecture Notes in Computer Science (LNCS) series of Springer Verlag,\nhttp://www.springer.de/comp/lncs/index.html .\n\nIts purpose is:\n\n? To facilitate the cross-disciplinary investigation of fundamental issues\nunderpinning computational trust models by bringing together expertise from\ntechnology oriented sciences, law, philosophy and social sciences.\n\n?  To facilitate the emergence of widely acceptable trust management\nprocesses for dynamic open systems and applications\n\n?  To facilitate the development of new paradigms in the area of dynamic\nopen systems which effectively utilise computational trust models.\n\n?  To help the incorporation of trust management elements in existing\nstandards\n\nPapers, short papers, panel, special session and tutorial proposals are\nsolicited in the following list of areas which is indicative and not\nexhaustive:\n\n\nThe ethics, sociology and psychology of trust\nCyberspace freedom vs. safeguarding consumer confidence and trusting\nrelations.\nLegal issues underpinning the management of trust\nTrust in Contract, service level agreement negotiation and management,\norganizational networks\nModels and semantics of trust\nTrust specification, analysis and reasoning\nTrust based on recommendation and reputation\nDesign of trust based architectures and decision-making mechanisms for\ne-community and e-service interactions\nMonitoring trust\nRelationship between trust and risk\nRelationship between trust and security\n\nImportant Dates\n\n\n\nSubmission of papers: January 6\nSubmission of panel or special session proposal: March 30\nSubmission of tutorial proposal: March 30\nSubmission of demo proposal: March 30\nNotification of panel or special session acceptance: April 15\nNotification of tutorial acceptance: April 15\nNotification of demo acceptance: April 15\nNotification of paper acceptance: March 10\nSubmission of final version: March 31\n\n\nKeynote Speaker: Stuart Feldman, IBM VP Internet Technology, USA\n\nProgram Committee\n-----------------\n\nChristos Nikolaou, U. of Crete, Greece, Conference Chair\nPaddy Nixon, U. of Strathclyde, UK, Program Chair\n\nNikos Alivizatos, U. of Athens, Greece\nEliza Bertino, U. of Milano, Italy\nJon Bing, NRCCL, U. of Oslo, Norway\nJoan Borrell, Autonomous University of Barcelona, Spain\nCristiano Castelfranchi, CNR, Italy\nStefano Cerri, U. of Montpellier II, France\nTheo Dimitrakos, CLRC, UK\nValerie Issarny, INRIA, France\nKeith Jeffery, CLRC, UK\nChristian D. Jensen, Trinity College, Ireland & DTU, Denmark\nAndrew Jones, King s College, UK\nAudun Josang, DSTC, Australia\nGraham Klyne, Nine by Nine, UK\nHeiko Krumm, U. of Dortmund, Germany\nManolis Marazakis, Plefsis, Greece\nStefan Poslad, Queen Mary College, UK\nDimitris Raptis, Intracom, Greece\nJakka Sairamesh, IBM Research, USA\nGiovanni Sartor, U. of Bologna, Italy\nSimon Shiu, Hewlett Packard, UK\nMorris Sloman, Imperial College, UK\nKetil Stoelen, SINTEF, Norway\nYao-Hua Tan, Free University of Amsterdam, Holland\nSotirios Terzis, U. of Strathclyde, UK\nDimitris Tsigos, Virtual Trip Ltd, Greece\nStavroula Tsinomera, U. of Crete, Greece\nEmily Weitzenboeck, NRCCL, U. of Oslo, Norway\n\n\nPaper Submission\n-----------------\n\nPapers should be submitted electronically in PDF, HTML or MS-Word format,\neither by e-mail to the Conference Secretariat ( info@itrust.uoc.gr ) or to\nour ftp site (ftp://ftp.eBusinessCity.org ).\n\nIn either case, please follow the guidelines below:\n\nIn your submission, there should be only one file containing the paper\ntext, suitable for review printing (maximum 20 printed pages with font size\nnot less than 10pt).\nEach figure (or other material except text) should be in a separate file\nAll files consisting your paper should be gathered in a single file (zip or\ntar format)\nSubmit your paper either by e-mail or ftp (please note that electronic\nsubmissions are obligatory)\nSend a separate e-mail message to info@itrust.uoc.gr containing the paper\ntitle, abstract, keywords and any relevant contact information.\n\nAll accepted papers for the conference will be published by the LNCS series\nof Springer-Verlag. Please consult the Authors Instructions subpage (\nhttp://www.springer.de/comp/lncs/authors.html ) as well as to the Editors\nInstructions subpage ( http://www.springer.de/comp/lncs/editors.html ) on\nthe LNCS Home Page where answers can be found to most technical questions.\n\n\n  Short Papers\n\nDuring the conference a space will be reserved for short paper sessions.\nResearch projects of any scale are invited to illustrate innovative\nconcepts and prototype systems.\n\nShort paper proposals should include title, names of presenters and outline\n(max. 500 words). Electronic submissions are obligatory; proposals should\nbe submitted by e-mail to the Conference Secretariat, info@itrust.uoc.gr\n\nPanels/Special Sessions chair Christian D. Jensen, Trinity College, Ireland\n& DTU, Denmark\n\nSuggestions for the organisation of panel sessions on one of the proposed\ntopics or on related topics are welcomed. Proposals should include a short\nCV and position paper for each panellist, and should be sent to\nChristian.Jensen@cs.tcd.ie\n\nTutorial chair: Theo Dimitrakos, CLRC, UK\n\nProposals for tutorials are solicited. Tutorials would be either half day\n(3 hours) or full day (6 hours). Each proposal should include a title, a\nsummary (intentions, objectives, etc.), duration and a short CV of the\ninstructor(s) and should be sent to T.Dimitrakos@rl.ac.uk\n\n\nDemo chair: Dimitris Tsigos, Virtual Trip Ltd, Greece\n\nResult demonstrations of on-going projects are strongly encouraged. Those\ninterested should submit a description of the intended Demo to\ntsigos@vtrip-ltd.com\n\nLocal Organizing Committee\n\nChristos Nikolaou, U. of Crete, Chair\nEva Michelidaki, U. of Crete, Dissemination\nCalliope Anagnostopoulou, U. of Crete, Local accommodations\nShore Shadman, U. of Crete, Registration\nKyriakos Papadakis, U. of Crete, Webmaster\nMichalis Klisarchakis, U. of Crete, Webmaster\nVasilis Poursalidis, U. of Crete, Networking & Systems\nElias Theoharopoulos, U. of Crete, Networking & Systems\n\n\n\n______________________________________________________\n\nProfessor Morris Sloman\nImperial College of Science Technology and Medicine\nDepartment of Computing\n180 Queen's Gate\nLondon SW7 2BZ, U.K.\nPhone: +44 20 7594 8279    Fax: +44 20 7594 8282\nEmail: m.sloman@doc.ic.ac.uk\nWWW: http://www.doc.ic.ac.uk/~mss\n\n\n\n_______________________________________________\nPolicy-sig mailing list\nPolicy-sig@doc.ic.ac.uk\nhttp://www2.doc.ic.ac.uk/mailman/listinfo.cgi/policy-sig\n\n\n\n"
        },
        {
            "subject": "RE: [Policysig] First International Conference on Trust Manageme nt  (fwd",
            "content": "That's one of ours!  From the iTrust WG we are in.\nI didn't think that it would be suitable for a workshop\nas its too close to W3C2002.\n\nIt was an action on me to publish when these trust workshops\nare.  After this one, there will be one in the autumn 2003 \n(probably London) and then we are organising a larger event\nin spring 2004, probably in Oxford.\n\nBrian\n\n-----Original Message-----\nFrom: Charles McCathieNevile [mailto:charles@w3.org]\nSent: 10 October 2002 10:33\nTo: public-esw@w3.org\nSubject: [Policy-sig] First International Conference on Trust Management\n(fwd)\n\n\n\nThis might be an interesting venue - I assume Graham Klyne can \ntell us more,\nsince he is on the program committee.\n\ncheers\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: \n+61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI \nhttp://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): \n+33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n---------- Forwarded message ----------\nDate: Thu, 10 Oct 2002 09:58:38 +0100\nFrom: Morris Sloman <m.sloman@doc.ic.ac.uk>\nTo: policy-sig@doc.ic.ac.uk\nSubject: [Policy-sig] First International Conference on Trust Management\n\n\nThe First International Conference On Trust Management\n\n28-30 May 2003\n\nHeraklion, Crete, Greece\n( http://www.eBusinessCity.org )\n\n\nThe First International Conference on Trust Management will \ntake place at\nthe beautiful summer resort Kalimera Kriti ( Good Morning Crete )\n(http://www.kalimerakriti.gr/ ) near Heraklion, Crete, Greece, \non May 28-30\n2003. The Conference is organized by iTrust, a Working Group on Trust\nManagement in Dynamic Open Systems (http://www.itrust.uoc.gr/) and the\nUniversity of Crete ( http://www.uoc.gr ) and partially funded by the\nFuture and Emerging Technologies (FET) unit of the IST program,\nhttp://www.cordis.lu/ist/fethome.htm The Proceedings will be \npublished by\nthe Lecture Notes in Computer Science (LNCS) series of Springer Verlag,\nhttp://www.springer.de/comp/lncs/index.html .\n\nIts purpose is:\n\n? To facilitate the cross-disciplinary investigation of \nfundamental issues\nunderpinning computational trust models by bringing together \nexpertise from\ntechnology oriented sciences, law, philosophy and social sciences.\n\n?  To facilitate the emergence of widely acceptable trust management\nprocesses for dynamic open systems and applications\n\n?  To facilitate the development of new paradigms in the area of dynamic\nopen systems which effectively utilise computational trust models.\n\n?  To help the incorporation of trust management elements in existing\nstandards\n\nPapers, short papers, panel, special session and tutorial proposals are\nsolicited in the following list of areas which is indicative and not\nexhaustive:\n\n\nThe ethics, sociology and psychology of trust\nCyberspace freedom vs. safeguarding consumer confidence and trusting\nrelations.\nLegal issues underpinning the management of trust\nTrust in Contract, service level agreement negotiation and management,\norganizational networks\nModels and semantics of trust\nTrust specification, analysis and reasoning\nTrust based on recommendation and reputation\nDesign of trust based architectures and decision-making mechanisms for\ne-community and e-service interactions\nMonitoring trust\nRelationship between trust and risk\nRelationship between trust and security\n\nImportant Dates\n\n\n\nSubmission of papers: January 6\nSubmission of panel or special session proposal: March 30\nSubmission of tutorial proposal: March 30\nSubmission of demo proposal: March 30\nNotification of panel or special session acceptance: April 15\nNotification of tutorial acceptance: April 15\nNotification of demo acceptance: April 15\nNotification of paper acceptance: March 10\nSubmission of final version: March 31\n\n\nKeynote Speaker: Stuart Feldman, IBM VP Internet Technology, USA\n\nProgram Committee\n-----------------\n\nChristos Nikolaou, U. of Crete, Greece, Conference Chair\nPaddy Nixon, U. of Strathclyde, UK, Program Chair\n\nNikos Alivizatos, U. of Athens, Greece\nEliza Bertino, U. of Milano, Italy\nJon Bing, NRCCL, U. of Oslo, Norway\nJoan Borrell, Autonomous University of Barcelona, Spain\nCristiano Castelfranchi, CNR, Italy\nStefano Cerri, U. of Montpellier II, France\nTheo Dimitrakos, CLRC, UK\nValerie Issarny, INRIA, France\nKeith Jeffery, CLRC, UK\nChristian D. Jensen, Trinity College, Ireland & DTU, Denmark\nAndrew Jones, King s College, UK\nAudun Josang, DSTC, Australia\nGraham Klyne, Nine by Nine, UK\nHeiko Krumm, U. of Dortmund, Germany\nManolis Marazakis, Plefsis, Greece\nStefan Poslad, Queen Mary College, UK\nDimitris Raptis, Intracom, Greece\nJakka Sairamesh, IBM Research, USA\nGiovanni Sartor, U. of Bologna, Italy\nSimon Shiu, Hewlett Packard, UK\nMorris Sloman, Imperial College, UK\nKetil Stoelen, SINTEF, Norway\nYao-Hua Tan, Free University of Amsterdam, Holland\nSotirios Terzis, U. of Strathclyde, UK\nDimitris Tsigos, Virtual Trip Ltd, Greece\nStavroula Tsinomera, U. of Crete, Greece\nEmily Weitzenboeck, NRCCL, U. of Oslo, Norway\n\n\nPaper Submission\n-----------------\n\nPapers should be submitted electronically in PDF, HTML or \nMS-Word format,\neither by e-mail to the Conference Secretariat ( \ninfo@itrust.uoc.gr ) or to\nour ftp site (ftp://ftp.eBusinessCity.org ).\n\nIn either case, please follow the guidelines below:\n\nIn your submission, there should be only one file containing the paper\ntext, suitable for review printing (maximum 20 printed pages \nwith font size\nnot less than 10pt).\nEach figure (or other material except text) should be in a separate file\nAll files consisting your paper should be gathered in a single \nfile (zip or\ntar format)\nSubmit your paper either by e-mail or ftp (please note that electronic\nsubmissions are obligatory)\nSend a separate e-mail message to info@itrust.uoc.gr containing \nthe paper\ntitle, abstract, keywords and any relevant contact information.\n\nAll accepted papers for the conference will be published by the \nLNCS series\nof Springer-Verlag. Please consult the Authors Instructions subpage (\nhttp://www.springer.de/comp/lncs/authors.html ) as well as to \nthe Editors\nInstructions subpage ( \nhttp://www.springer.de/comp/lncs/editors.html ) on\nthe LNCS Home Page where answers can be found to most technical \nquestions.\n\n\n  Short Papers\n\nDuring the conference a space will be reserved for short paper sessions.\nResearch projects of any scale are invited to illustrate innovative\nconcepts and prototype systems.\n\nShort paper proposals should include title, names of presenters \nand outline\n(max. 500 words). Electronic submissions are obligatory; \nproposals should\nbe submitted by e-mail to the Conference Secretariat, info@itrust.uoc.gr\n\nPanels/Special Sessions chair Christian D. Jensen, Trinity \nCollege, Ireland\n& DTU, Denmark\n\nSuggestions for the organisation of panel sessions on one of \nthe proposed\ntopics or on related topics are welcomed. Proposals should \ninclude a short\nCV and position paper for each panellist, and should be sent to\nChristian.Jensen@cs.tcd.ie\n\nTutorial chair: Theo Dimitrakos, CLRC, UK\n\nProposals for tutorials are solicited. Tutorials would be \neither half day\n(3 hours) or full day (6 hours). Each proposal should include a title, a\nsummary (intentions, objectives, etc.), duration and a short CV of the\ninstructor(s) and should be sent to T.Dimitrakos@rl.ac.uk\n\n\nDemo chair: Dimitris Tsigos, Virtual Trip Ltd, Greece\n\nResult demonstrations of on-going projects are strongly \nencouraged. Those\ninterested should submit a description of the intended Demo to\ntsigos@vtrip-ltd.com\n\nLocal Organizing Committee\n\nChristos Nikolaou, U. of Crete, Chair\nEva Michelidaki, U. of Crete, Dissemination\nCalliope Anagnostopoulou, U. of Crete, Local accommodations\nShore Shadman, U. of Crete, Registration\nKyriakos Papadakis, U. of Crete, Webmaster\nMichalis Klisarchakis, U. of Crete, Webmaster\nVasilis Poursalidis, U. of Crete, Networking & Systems\nElias Theoharopoulos, U. of Crete, Networking & Systems\n\n\n\n______________________________________________________\n\nProfessor Morris Sloman\nImperial College of Science Technology and Medicine\nDepartment of Computing\n180 Queen's Gate\nLondon SW7 2BZ, U.K.\nPhone: +44 20 7594 8279    Fax: +44 20 7594 8282\nEmail: m.sloman@doc.ic.ac.uk\nWWW: http://www.doc.ic.ac.uk/~mss\n\n\n\n_______________________________________________\nPolicy-sig mailing list\nPolicy-sig@doc.ic.ac.uk\nhttp://www2.doc.ic.ac.uk/mailman/listinfo.cgi/policy-sig\n\n\n\n"
        },
        {
            "subject": "Re: [Policysig] First International Conference on Trust   Management  (fwd",
            "content": "At 05:33 AM 10/10/02 -0400, Charles McCathieNevile wrote:\n\n>This might be an interesting venue - I assume Graham Klyne can tell us more,\n>since he is on the program committee.\n\nEr, yes, it sometimes surprises me where my name turns up ;-)\n\nI am a participant in the iTrust working group, whose deliverables are the \noutputs from a series of meetings, of which this conference is one.  But \nI'm just a small cog in the machine (or is that grit  ;-).\n\nA salient characteristic of the working group, which I expect to extend to \nthe conference, is its multidisciplinary approach.  At our last meeting I \nhad interesting discussions with ethical philosophers and legal specialists \nas well as computer scientists.  In this respect, it should be an excellent \nopportunity for \"user requirements gathering\" with respect to technological \ndevelopments in the realm of trust.\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "FOAF and trust and certificate",
            "content": "Maybe this has already been considered ... it's obvious enough, but the \nthought has only just struck me.\n\nIt occurs to me that the FOAF experiment of Dan Brickley and friends (and \nFOAFs) might have some relevance to some aspects of trust modelling.  I'm \nscratching some words about public key certificates and CA chaining, and \ngot to this point:\n[[\n           <t>So X.509 employs the idea of certificate chains, where\n             each CA's public key is itself signed by a \"higher\" CA,\n             and so on until a trusted \"root\" CA is encountered.\n             Thus, a chain of certificates can link the holder of\n             some key and a user of the corresponding public key\n             to a common point of trust.  Set against this, the\n             longer the certificate chain the more scope there is\n             for compromise of any one of the CA signing keys, which\n             would effectively nullify the basis for trust in the\n             end user keys thus protected.</t>\n]]\n\nThis describes the X.509 hierarchical CA chaining model.  PGP, on the other \nhand, employs a more grassroots based web of trust, in which any keyholder \ncan express degrees of trust in another.  In his book \"Applied \nCrytography\", Bruce Schneier puts it like this:\n[[\nThere are no key certification authorities;   PGP instead supports a \"web \nof trust\".  Every user generates and distributes his own public key.  Users \nsign each other's public keys, creating an interconnected community of PGP \nusers.\n]]\n\nAll of which has strong resonances with FOAF.  I'm thinking in particular that:\n(a) FOAF might be used to model PGP webs-of-trust.\n(b) FOAF might be able to supply additional information about \nrelationships, which could be used to guide trust decisions in a PGP \nweb-of-trust.\n(c) with a FOAF model and trust strategies modelled as rules on RDF data, \nsome PGP trust decisions might be automated that otherwise are made manually.\n\nHmmm... I must pay more attention to the next IETF key-signing party.\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Re: FOAF and trust and certificate",
            "content": "I've always felt that SPKI/SDSI [1] is a very interesting model of security\nwhich fits rather nicely with the semantic web:\n\n o Rights certificates are bound directly to keys (\"principals\") not to\nidentities. x.509 effectively maps rights to identities but SDSI separates\nthese. This leads to a decentralized design where everyone can be a sort of\ncertification authority, no need for a global hierarchy. This separation also\nmeans you can have some level of privacy and yet still exercise certified\nrights. \n\n o The notion of local namespaces that map from \"principals\" (i.e. keys) to some\nname or identity is very consistent with foaf. First you could use\nfoaf/vCard/person-ont to associate your own names and contact information for\nprincipals that you know. This could be either informal or formally done by SDSI\nidentity certificates. Secondly the SDSI principle of addressing people via\nchains of names in linked local namespaces would fit very nicely with using FOAF\n\"knows\" links. \n\n o The delegation certificate machinery is a good base for allowing\nauthoritative sources to delegate their authority. It could be an interesting\nway of approaching the semantic web trust layer so that when a package of\nassertions is signed it can signed on behalf of some delegation chain giving a\ntraceback mechanism.\n\nDave\n\n[1] http://theory.lcs.mit.edu/~cis/sdsi.html\n\nGraham Klyne wrote:\n> \n> Maybe this has already been considered ... it's obvious enough, but the\n> thought has only just struck me.\n> \n> It occurs to me that the FOAF experiment of Dan Brickley and friends (and\n> FOAFs) might have some relevance to some aspects of trust modelling.  I'm\n> scratching some words about public key certificates and CA chaining, and\n> got to this point:\n> [[\n>            <t>So X.509 employs the idea of certificate chains, where\n>              each CA's public key is itself signed by a \"higher\" CA,\n>              and so on until a trusted \"root\" CA is encountered.\n>              Thus, a chain of certificates can link the holder of\n>              some key and a user of the corresponding public key\n>              to a common point of trust.  Set against this, the\n>              longer the certificate chain the more scope there is\n>              for compromise of any one of the CA signing keys, which\n>              would effectively nullify the basis for trust in the\n>              end user keys thus protected.</t>\n> ]]\n> \n> This describes the X.509 hierarchical CA chaining model.  PGP, on the other\n> hand, employs a more grassroots based web of trust, in which any keyholder\n> can express degrees of trust in another.  In his book \"Applied\n> Crytography\", Bruce Schneier puts it like this:\n> [[\n> There are no key certification authorities;   PGP instead supports a \"web\n> of trust\".  Every user generates and distributes his own public key.  Users\n> sign each other's public keys, creating an interconnected community of PGP\n> users.\n> ]]\n> \n> All of which has strong resonances with FOAF.  I'm thinking in particular that:\n> (a) FOAF might be used to model PGP webs-of-trust.\n> (b) FOAF might be able to supply additional information about\n> relationships, which could be used to guide trust decisions in a PGP\n> web-of-trust.\n> (c) with a FOAF model and trust strategies modelled as rules on RDF data,\n> some PGP trust decisions might be automated that otherwise are made manually.\n> \n> Hmmm... I must pay more attention to the next IETF key-signing party.\n> \n> #g\n> \n> -------------------\n> Graham Klyne\n> <GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Re: FOAF and trust and certificate",
            "content": "I hadn't thought of SPKI in this context.  I agree the directness and \nrelative simplicity appeals, especially when the additional metadata \ncarried in X.509 certs might be supplied as signed RDF.\n\nBut ... I was of the impression that SPKI is not widely used:  do you know \notherwise?  Do you think it's a serious contender in the public key \nsecurity space?\n\n#g\n--\n\nAt 10:31 AM 10/17/02 +0100, Dave Reynolds wrote:\n\n>I've always felt that SPKI/SDSI [1] is a very interesting model of security\n>which fits rather nicely with the semantic web:\n>\n>  o Rights certificates are bound directly to keys (\"principals\") not to\n>identities. x.509 effectively maps rights to identities but SDSI separates\n>these. This leads to a decentralized design where everyone can be a sort of\n>certification authority, no need for a global hierarchy. This separation also\n>means you can have some level of privacy and yet still exercise certified\n>rights.\n>\n>  o The notion of local namespaces that map from \"principals\" (i.e. keys) \n> to some\n>name or identity is very consistent with foaf. First you could use\n>foaf/vCard/person-ont to associate your own names and contact information for\n>principals that you know. This could be either informal or formally done \n>by SDSI\n>identity certificates. Secondly the SDSI principle of addressing people via\n>chains of names in linked local namespaces would fit very nicely with \n>using FOAF\n>\"knows\" links.\n>\n>  o The delegation certificate machinery is a good base for allowing\n>authoritative sources to delegate their authority. It could be an interesting\n>way of approaching the semantic web trust layer so that when a package of\n>assertions is signed it can signed on behalf of some delegation chain giving a\n>traceback mechanism.\n>\n>Dave\n>\n>[1] http://theory.lcs.mit.edu/~cis/sdsi.html\n>\n>Graham Klyne wrote:\n> >\n> > Maybe this has already been considered ... it's obvious enough, but the\n> > thought has only just struck me.\n> >\n> > It occurs to me that the FOAF experiment of Dan Brickley and friends (and\n> > FOAFs) might have some relevance to some aspects of trust modelling.  I'm\n> > scratching some words about public key certificates and CA chaining, and\n> > got to this point:\n> > [[\n> >            <t>So X.509 employs the idea of certificate chains, where\n> >              each CA's public key is itself signed by a \"higher\" CA,\n> >              and so on until a trusted \"root\" CA is encountered.\n> >              Thus, a chain of certificates can link the holder of\n> >              some key and a user of the corresponding public key\n> >              to a common point of trust.  Set against this, the\n> >              longer the certificate chain the more scope there is\n> >              for compromise of any one of the CA signing keys, which\n> >              would effectively nullify the basis for trust in the\n> >              end user keys thus protected.</t>\n> > ]]\n> >\n> > This describes the X.509 hierarchical CA chaining model.  PGP, on the other\n> > hand, employs a more grassroots based web of trust, in which any keyholder\n> > can express degrees of trust in another.  In his book \"Applied\n> > Crytography\", Bruce Schneier puts it like this:\n> > [[\n> > There are no key certification authorities;   PGP instead supports a \"web\n> > of trust\".  Every user generates and distributes his own public key.  Users\n> > sign each other's public keys, creating an interconnected community of PGP\n> > users.\n> > ]]\n> >\n> > All of which has strong resonances with FOAF.  I'm thinking in \n> particular that:\n> > (a) FOAF might be used to model PGP webs-of-trust.\n> > (b) FOAF might be able to supply additional information about\n> > relationships, which could be used to guide trust decisions in a PGP\n> > web-of-trust.\n> > (c) with a FOAF model and trust strategies modelled as rules on RDF data,\n> > some PGP trust decisions might be automated that otherwise are made \n> manually.\n> >\n> > Hmmm... I must pay more attention to the next IETF key-signing party.\n> >\n> > #g\n> >\n> > -------------------\n> > Graham Klyne\n> > <GK@NineByNine.org>\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Re: FOAF and trust and certificate",
            "content": "Graham Klyne wrote:\n> \n> But ... I was of the impression that SPKI is not widely used:  do you know\n> otherwise?  Do you think it's a serious contender in the public key\n> security space?\n\nI agree it is not widely used and that is something of a problem. HP did\nimplement it for the ESpeak product though that is not widely used either ...]\n\nHowever, the attraction of SDSI is it's decentralized nature - you don't need\nglobal PKI to make it work. So it could be bootstrapped up for specific\napplications relatively easily. I guess I was just wondering whether some of the\nSDSI design principles could be reused in developing semantic web trust layer\ndemonstrations. Just a passing thought.\n\nDave\n\n\n\n"
        },
        {
            "subject": "semweb site in Spanis",
            "content": "But not in Spain - Chile instead :\n\nBlog de la Web Sem?ntica\nhttp://e.no-ip.org/prj/ws-blog/\n\n\n\n"
        },
        {
            "subject": "[RSSDEV] Couple of new feeds on XMLfr (and kudos for the events  module) (fwd",
            "content": "More non-en resources...\n\n---------- Forwarded message ----------\nDate: 20 Oct 2002 22:37:32 +0200\nFrom: Eric van der Vlist <vdv@dyomedea.com>\nReply-To: rss-dev@yahoogroups.com\nTo: rss-dev@yahoogroups.com\nSubject: [RSS-DEV] Couple of new feeds on XMLfr (and kudos for the events\n    module)\n\nHi,\n\nJust to mention a couple of new RSS 1.0 feeds on XMLfr.org...\n\n[1] http://xmlfr.org/actualites/breves/breves.rss10\n[2] http://xmlfr.org/actualites/agenda/agenda.rss\n\nThe first one is for short pointers (in French) on XML news in French or\nEnglish. Unlike the usual articles on XMLfr, these are just a pointer\nwith a short description and I am using the content module to give this\nlink and the language of the article in addition to DC for metadata and\nthe taxo module for categorization...\n\nThe second one is for the agenda of XMLfr and is basically the same with\nthe addition of the events module to capture the specific information\nabout the events.\n\nI had never used this module before and find it very simple and usefull.\n\nThe great think about using this module (as opposed to a specific\nvocabulary for calendars) is that I have been able to reuse the\nstylesheets I had already developed to display the events.\n\nAlso, it has kind of changed the way I looked at events and I am know\nconsidering that they are both RSS new items (when I include the mention\nfor an events, this is considered as a news by itself for the current\ndate) and events (included in the calendar).\n\nThe other thing worth mentioning is the way to create new items on\nXMLfr.\n\nIt's too early to formally publish it, but I have developped a very\nsimple bot which is subscribed to the editor's private mailing list on\nXMLfr and these items (including events) are captured from emails by\nrecognition of simple keywords and conventions.\n\nI know that this has been done many time on the IRC, but for whatever\nreason, using the IRC isn't part of the usages amongst XMLfr editors and\nthe adaptation of the concept on a mailing list is working just fine.\n\nAs an example, the item about the P3P workshop is the result of the\nfollowing mail (non significant headers and content skipped):\n\n++++++++++++++++\nFrom: Eric van der Vlist <vdv@dyomedea.com>\nSubject: [redacteurs] Event(tech): Le futur de P3P\nDate: 20 Oct 2002 16:55:08 +0200\n\nLien: http://www.w3.org/2002/p3p-ws/\nDu 12/11/2002 au 13/11/2002\nOrganis? par: W3C\nA: Dulles, Virginie\nDescription: Le W3C organise cet atelier de deux jours pour discuter\ndes applications \"?mergentes et futures\" de la recommandation P3P\n(Platform for Privacy Preferences) et d?terminer quelles ?volutions\nsont ?ventuellement n?cessaires pour permettre ou faciliter\nces applications.\n++++++++++++++++\n\nAll the information inserted in the corresponding item are extracted\nfrom the mail headers or body.\n\nThe bot itself is implemented 50% in Python (from which 50% are done\nthrough regexpes) and 50% in XSLT and is really quite trivial to write.\n\nIt's really facilitating a lot the publishing of new items and I think\nthat it's a good example of how we can easily facilitate the life of our\nusers (including ourselves) while keeping the full power of XML and RDF\nby developping some very simple utilities.\n\nEric\n-- \nFreelance consulting and training.\n                                            http://dyomedea.com/english/\n------------------------------------------------------------------------\nEric van der Vlist       http://xmlfr.org            http://dyomedea.com\n(W3C) XML Schema ISBN:0-596-00252-1 http://oreilly.com/catalog/xmlschema\n------------------------------------------------------------------------\n\n\nTo unsubscribe from this group, send an email to:\nrss-dev-unsubscribe@egroups.com\n\n\n\nYour use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n\n\n\n"
        },
        {
            "subject": "Re: FOAF and trust and certificate",
            "content": ">I've always felt that SPKI/SDSI [1] is a very interesting model of \n>security which fits rather nicely with the semantic web:\n\nBTW: After I spoke to DanC about representing SPKI in N3, he created an \nexample and policy:\n  http://www.w3.org/2000/10/swap/test/spki2may.n3\n\n\n\n"
        },
        {
            "subject": "Re: FOAF and trust and certificate",
            "content": "On a quick review, it certainly *seems* to be more deployable (in terms of \nadditional data to be shipped) than X.509.  I don't know if XKMS would \nchange that.\n\n#g\n--\n\nAt 02:05 PM 10/21/02 -0400, Joseph Reagle wrote:\n\n> >I've always felt that SPKI/SDSI [1] is a very interesting model of\n> >security which fits rather nicely with the semantic web:\n>\n>BTW: After I spoke to DanC about representing SPKI in N3, he created an\n>example and policy:\n>   http://www.w3.org/2000/10/swap/test/spki2may.n3\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Chandler ... Interpersonal Information Manage",
            "content": "[This isn't obviously semantic web related, but it looks as if it ought to \nbe... it touches on a number of areas of interest to SWAD-E -- #g]\n\n[From: http://www.acm.org/technews/articles/2002-4/1023w.html#item12]\n\n\"Dan Gillmor: Software Idea May Be Crazy Enough to Work\"\nSiliconValley.com (10/20/02); Gillmor, Dan\n\nLotus Development founder and cyber-activist Mitch Kapor and his team have \nspent more than a year developing Chandler, an open-source Interpersonal \nInformation Manager software program that encrypts data such as personal \nemail, calendars, and contacts, and facilitates collaboration and \ninformation sharing without the need for costly server computers. Kapor \nsays he is paying for the project with $5 million out-of-pocket, but hopes \nto make the initiative self-sustaining in three years through sponsorships, \noutside contributions, service sales, licensing fees, and other sources. \nBoth the source code and the working program will be freely available, and \nthe first official version of the software is expected to debut in late \n2003 or early 2004. Chandler will run on the Mac OS X, Linux, and Windows \noperating systems. Individuals and small businesses will be initially \ncourted as users, but developers will also be able to build software and \nservices using Chandler as a platform. The software's architecture is based \non the Python development language and environment, and the Jabber \ncommunications infrastructure. Kapor is funding the project through the \nnonprofit Open Source Application Foundation, which could serve as a model \nfor other projects that wish to open up the market to consumers who \ncurrently must settle for software and services from dominant, monopolistic \ncompanies. \"[W]e'll be helping to pave the way for free software to \ndisplace proprietary operating systems at the center of the commercial \nsoftware industry,\" says programmer Andy Hertzfeld, a member of Kapor's \neight-man Chandler development team.\nhttp://www.siliconvalley.com/mld/siliconvalley/4327025.htm\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "timbl in mediaguardia",
            "content": "http://media.guardian.co.uk/mediaguardian/story/0,7558,820468,00.html\n\n[[\n\"The semantic web area, which we've had on the books for a long time, is\nmore like the original web. When people do get it, you can see the twinkle\nin their eye. But it's the same thing - if you show people two computers\nlinked together, they say 'so what'? But then imagine there are millions\nof them... But because there's not that much semantic web data, you have\nto make that initial leap. It takes a bit of imagination to realise that\nif all the databases in the world were linked together, there are all\nsorts of possibilities,\" he says. The project is now moving forward thanks\nto research grants from the EU and the US government.\n]]\n\n\n\n"
        },
        {
            "subject": "(SeWeb) CfP: IV03VSW: Visualisation of the Semantic Web (fwd",
            "content": "Might be of interest, given our workshop plans.\n\nLibby\n\n---------- Forwarded message ----------\nDate: Thu, 31 Oct 2002 12:09:07 +0000\nFrom: Vladimir Geroimenko <vladg@soc.plym.ac.uk>\nTo: \"ontoweb-list@cs.vu.nl\" <ontoweb-list@cs.vu.nl>,\n     \"seweb-list@cs.vu.nl\" <seweb-list@cs.vu.nl>\nSubject: (SeWeb) CfP: IV03-VSW: Visualisation of the Semantic Web\n\n********************************************************************************\n\nInternational Symposium of Visualisation of the Semantic Web, IV03-VSW\n****** http://www.graphicslink.demon.co.uk/IV03/vsw.htm *********\n********************************************************************************\n\n16 - 17 - 18 July 2003\nSOAS, University of London\nLONDON ENGLAND\n--------------------------------------------------------------------------------\n\nCall for Papers and Participation\n\nThe Semantic Web is currently the most evolving area of the Internet\ndevelopment. This Second-Generation Web is based not on HTML but on XML\nand related technologies, such as RDF, Topic Maps, Ontologies,\nNamespaces, and others. The Semantic Web is \"a vision: the idea of data\non the Web defined and linked in a way that it can be used by machines\nfor automation, integration and reuse\". The Semantic Web not only\nrequires adapting existing visualisation techniques and developing new\napproaches, but also opens wide opportunities for their practical\nimplementation. The \"Visualisation of the Semantic Web\" was started in\n2001 as the first International Symposium specially devoted to the\nvisual aspects of the Second Generation Web. The symposium seeks\noriginal research papers that deal with, but are not limited to, the\nfollowing topics:\n\n* Visualisation of Semantic Information and Metadata\n* Visual Design of Ontologies and Schemas\n* Conceptual Modelling of XML Data Using UML\n* Topic Maps Technology\n* Rendering and Viewing XML Documents\n* Semantic Virtual Environments and MetaVR\n* Visual Information Filtering and Knowledge Discovery\n* New Visualisation Techniques for the Semantic Web\n* Semantic-Oriented Use of Existing Visualisation Methods\n* Multimedia Interfaces for XML Documents and Ontologies\n\nSupported by:\nGraphicsLink...\nVGRU, SCISM, South Bank University, UK\nDepartment of Computer Graphics Technology, Purdue University, USA\nDepartment of Visual Art, University of Northern Colorado, USA\nComputer Graphics & Modelling Group - DMU Milton Keynes, UK\nNational Centre for Computer Animation, Bournemouth University, UK\nSchool of Library and Information Science, Indiana University, USA\nMotorola UK Research Lab\nInformation and Computer Science Department, KFUPM, SA\nMixed Reality Ltd, UK\nDepartment of Electronic Imaging and Media Communications, University of\nBradford, UK\nUniversity of Balearic Islands, Spain\nUniversity of Kent at Canterbury, UK\nTechnical University Graz, Austria\n\nCo-operated by:\nInformation Visualisation Society\n\nPreConference Workshop and Tutorials on 15 July 2003:\nWorkshop: CMV 2003 - International Symposium on Co-ordinated & Multiple\nViews in Exploratory Visualization associated with IV'03, London, UK\n\nTutorial: Mapping Scientific Frontiers, Chaomei Chen, Ph.D, Drexel\nUniversity, USA\n\n--------------------------------------------------------------------------------\n\nImportant Dates:\n17 January 2003 - Submission of proposal for symposium\n7 March 2002 -  Submission of papers and  Submission of tutorials &\npre-conference courses\n05 May 2002 - Submission of camera-ready and early registration closes\n\nFurther details and registration form are available at the conference\nweb-site:\nhttp://www.graphicslink.demon.co.uk/IV03/\n\n------------------------------------------------------------------------------\n\nDr Vladimir Geroimenko\nREF: IV03-VSW\nSchool of Computing\nUniversity of Plymouth\nPlymouth, Devon PL4 8AA, UK\nTel: (Int. +44) 1752 232612\nFax: (Int. +44) 1752 232540\nEmail: vladg@soc.plym.ac.uk\n\n\n\n"
        },
        {
            "subject": "SWAD Europe web site link",
            "content": "I find it hard to navitgate our site and find myself editing the URL\nbox in order to move between areas, such as back from\nreports/documents to the home page.  Does anyone else finds this a\nproblem?\n\nCharles suggested on IRC that a navigation bar might help.\nMaybe a floating one like on http://www.w3.org/QA/ ?\n\nI know the links to the events, workplan and reports are on the home\npage but they never stand out to me since they are in a paragraph of\ntext.  I guess presentations and talks could have a page of their own\nand links?  Should the home page point to the flyer/factsheet.  Where\nis the link to that :)\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: SWAD Europe web site link",
            "content": "Sort of related are broken links.\n\nFor any page on the W3C server you can add ,checklink to the end of the URI\nand get a report about broken links (which includes broken fragment\nreferences). It would be nice if we could do this for pages that have changed\nbut I don't know how to make this happen yet.\n\ncheers\n\nChaals\n\nOn Mon, 2 Sep 2002, Dave Beckett wrote:\n\n>\n>\n>I find it hard to navitgate our site and find myself editing the URL\n>box in order to move between areas, such as back from\n>reports/documents to the home page.  Does anyone else finds this a\n>problem?\n>\n>Charles suggested on IRC that a navigation bar might help.\n>Maybe a floating one like on http://www.w3.org/QA/ ?\n>\n>I know the links to the events, workplan and reports are on the home\n>page but they never stand out to me since they are in a paragraph of\n>text.  I guess presentations and talks could have a page of their own\n>and links?  Should the home page point to the flyer/factsheet.  Where\n>is the link to that :)\n>\n>Dave\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: SWAD Europe web site link",
            "content": "Navigation bar please.\n\nMichael Wilson\nBusiness and Information Technology Department   tel: +44 (0)1235 44 6619\nCLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\nChilton, DIDCOT, Oxon, OX11 0QX, UK             \n\nWWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n\nThe contents of this email are sent in confidence for the use of the\nintended recipients only.  If you are not one of the intended recipients\ndo not take action on it or show it to anyone else, but return this\nemail to the sender and delete your copy of it\n\n\n\n\n-----Original Message-----\nFrom: Dave Beckett [mailto:dave.beckett@bristol.ac.uk]\nSent: 02 September 2002 10:47\nTo: public-esw\nSubject: SWAD Europe web site links\n\n\n\n\nI find it hard to navitgate our site and find myself editing the URL\nbox in order to move between areas, such as back from\nreports/documents to the home page.  Does anyone else finds this a\nproblem?\n\nCharles suggested on IRC that a navigation bar might help.\nMaybe a floating one like on http://www.w3.org/QA/ ?\n\nI know the links to the events, workplan and reports are on the home\npage but they never stand out to me since they are in a paragraph of\ntext.  I guess presentations and talks could have a page of their own\nand links?  Should the home page point to the flyer/factsheet.  Where\nis the link to that :)\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: SWADeurope dissemination and use pla",
            "content": "hi\n\nLast chance to comment on the DUP is today or tomorrow. No-one from the\nproject has yet commented. It's an ongoing document, but the first\nversion needs to be given to the Commission this week.\n\nI said:\n[[\n> At this stage we are looking for comments and for additions,\n> particularly in the sections on partner-specific internal audience\n> (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n> conferences and other opportunities for dissemination would be useful.\n>\n]]\n\nThe document is here:\nhttp://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n\nI'll be cleaning up the draft today and tomorrow.\n\nLibby\n\n\nOn Wed, 28 Aug 2002, Libby Miller wrote:\n\n>\n> I've been working on this, and a rough draft is at\n>\n>\n> The plan is to send it to the commission in a weeks' time (Tuesday 3rd\n> September). There's a lot of tiding to be done, but this is the basic\n> structure we plan to submit.\n>\n> At this stage we are looking for comments and for additions,\n> particularly in the sections on partner-specific internal audience\n> (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n> conferences and other opportunities for dissemination would be useful.\n>\n> The document will be updated over time as we know better what\n> conferences are coming up and so on.\n>\n> thanks\n>\n> Libby\n>\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWADeurope dissemination and use pla",
            "content": "My apologies to Dave Reynolds, who sent a reply last week that I missed.\nSorry about that Dave - very useful comments.\n\nanyone else?\n\nLibby\n\nOn Tue, 3 Sep 2002, Libby Miller wrote:\n\n>\n>\n> hi\n>\n> Last chance to comment on the DUP is today or tomorrow. No-one from the\n> project has yet commented. It's an ongoing document, but the first\n> version needs to be given to the Commission this week.\n>\n> I said:\n> [[\n> > At this stage we are looking for comments and for additions,\n> > particularly in the sections on partner-specific internal audience\n> > (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n> > conferences and other opportunities for dissemination would be useful.\n> >\n> ]]\n>\n> The document is here:\n> http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n>\n> I'll be cleaning up the draft today and tomorrow.\n>\n> Libby\n>\n>\n> On Wed, 28 Aug 2002, Libby Miller wrote:\n>\n> >\n> > I've been working on this, and a rough draft is at\n> >\n> >\n> > The plan is to send it to the commission in a weeks' time (Tuesday 3rd\n> > September). There's a lot of tiding to be done, but this is the basic\n> > structure we plan to submit.\n> >\n> > At this stage we are looking for comments and for additions,\n> > particularly in the sections on partner-specific internal audience\n> > (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n> > conferences and other opportunities for dissemination would be useful.\n> >\n> > The document will be updated over time as we know better what\n> > conferences are coming up and so on.\n> >\n> > thanks\n> >\n> > Libby\n> >\n> >\n> >\n> >\n> >\n> >\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWADeurope dissemination and use pla",
            "content": "Comments coming this afternoon...\n\nChaals\n\nOn Tue, 3 Sep 2002, Libby Miller wrote:\n\n>\n>\n>My apologies to Dave Reynolds, who sent a reply last week that I missed.\n>Sorry about that Dave - very useful comments.\n>\n>anyone else?\n>\n>Libby\n>\n>On Tue, 3 Sep 2002, Libby Miller wrote:\n>\n>>\n>>\n>> hi\n>>\n>> Last chance to comment on the DUP is today or tomorrow. No-one from the\n>> project has yet commented. It's an ongoing document, but the first\n>> version needs to be given to the Commission this week.\n>>\n>> I said:\n>> [[\n>> > At this stage we are looking for comments and for additions,\n>> > particularly in the sections on partner-specific internal audience\n>> > (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n>> > conferences and other opportunities for dissemination would be useful.\n>> >\n>> ]]\n>>\n>> The document is here:\n>> http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n>>\n>> I'll be cleaning up the draft today and tomorrow.\n>>\n>> Libby\n>>\n>>\n>> On Wed, 28 Aug 2002, Libby Miller wrote:\n>>\n>> >\n>> > I've been working on this, and a rough draft is at\n>> >\n>> >\n>> > The plan is to send it to the commission in a weeks' time (Tuesday 3rd\n>> > September). There's a lot of tiding to be done, but this is the basic\n>> > structure we plan to submit.\n>> >\n>> > At this stage we are looking for comments and for additions,\n>> > particularly in the sections on partner-specific internal audience\n>> > (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n>> > conferences and other opportunities for dissemination would be useful.\n>> >\n>> > The document will be updated over time as we know better what\n>> > conferences are coming up and so on.\n>> >\n>> > thanks\n>> >\n>> > Libby\n>> >\n>> >\n>> >\n>> >\n>> >\n>> >\n>>\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: SWADeurope dissemination and use pla",
            "content": "Hi folks,\n\nI did some editing on this. I added more stuff about W3C as an audience,\ncorrected some but not all speling errors, and changed the status and\nfeedback address to point to this list.\n\nWhile I was doing that I had the following thoughts:\n\n  It doesn't say much about how to identify existing fora - should it?\n  It should link to the calendar of deliverables but I couldn't find that\n    when I needed it and had to finish.\n  I will make a partners' page in the morning listing the partner\n    organisations. I will try to make it minimalist and ask each partner for\n    additional information and logos that should go on it as needed.\n\nCheers\n\nChaals\n\nOn Tue, 3 Sep 2002, Charles McCathieNevile wrote:\n\n>\n>Comments coming this afternoon...\n>\n>Chaals\n>\n>On Tue, 3 Sep 2002, Libby Miller wrote:\n>\n>>\n>>\n>>My apologies to Dave Reynolds, who sent a reply last week that I missed.\n>>Sorry about that Dave - very useful comments.\n>>\n>>anyone else?\n>>\n>>Libby\n>>\n>>On Tue, 3 Sep 2002, Libby Miller wrote:\n>>\n>>>\n>>>\n>>> hi\n>>>\n>>> Last chance to comment on the DUP is today or tomorrow. No-one from the\n>>> project has yet commented. It's an ongoing document, but the first\n>>> version needs to be given to the Commission this week.\n>>>\n>>> I said:\n>>> [[\n>>> > At this stage we are looking for comments and for additions,\n>>> > particularly in the sections on partner-specific internal audience\n>>> > (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n>>> > conferences and other opportunities for dissemination would be useful.\n>>> >\n>>> ]]\n>>>\n>>> The document is here:\n>>> http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n>>>\n>>> I'll be cleaning up the draft today and tomorrow.\n>>>\n>>> Libby\n>>>\n>>>\n>>> On Wed, 28 Aug 2002, Libby Miller wrote:\n>>>\n>>> >\n>>> > I've been working on this, and a rough draft is at\n>>> >\n>>> >\n>>> > The plan is to send it to the commission in a weeks' time (Tuesday 3rd\n>>> > September). There's a lot of tiding to be done, but this is the basic\n>>> > structure we plan to submit.\n>>> >\n>>> > At this stage we are looking for comments and for additions,\n>>> > particularly in the sections on partner-specific internal audience\n>>> > (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n>>> > conferences and other opportunities for dissemination would be useful.\n>>> >\n>>> > The document will be updated over time as we know better what\n>>> > conferences are coming up and so on.\n>>> >\n>>> > thanks\n>>> >\n>>> > Libby\n>>> >\n>>> >\n>>> >\n>>> >\n>>> >\n>>> >\n>>>\n>>>\n>>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Partners' pag",
            "content": "Hi Folks\n\nThere is now a Partners' page at http://www.w3.org/2001/sw/Europe/partners\n\nIt contains edited versions of the information in the bid - a brief\nintroduction to each partner, Relevant Experience and Skill, and Key\nPersonnel sections.\n\nI wondered if it was worth keeping the key personnel section, or even just\nlisting them and having a \"people page\" or links to more information about\npeople.\n\nI would appreciate each partner checking that there isn't something on the\npage which is incorrect or something really important that is missing. I\nwould also appreciate general feedback on the page...\n\nCheers\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: SWADeurope dissemination and use pla",
            "content": "libby\n\ntext about stilo\n\n\"\"Stilo has typically around 4 or 5 active Research and Development\nprojects, alongside\ndevelopment of our own core technology. These projects usually involve\nexternal partners,\neither in industrial projects such as SophXPack which is a 4-member\nconsortium working on\nKnowledge Engineering technology in Aerospace Design, or joint\nindustry-academic projects \nsuch as SWAD-E and MONET. There is a regular interchange of ideas and\nsometimes staff \nbetween projects, for example we are using some Semantic Web ideas on\nSophXPack. In \naddition we hold internal events (titled 'doughnut meetings'), at which\nprojects\nare presented.\"\"\n\n--s\n\n-----Original Message-----\nFrom: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\nSent: Wednesday, August 28, 2002 9:50 AM\nTo: public-esw@w3.org\nSubject: SWAD-europe dissemination and use plan\n\n\n\n\nI've been working on this, and a rough draft is at\n\nhttp://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n\nThe plan is to send it to the commission in a weeks' time (Tuesday 3rd\nSeptember). There's a lot of tiding to be done, but this is the basic\nstructure we plan to submit.\n\nAt this stage we are looking for comments and for additions,\nparticularly in the sections on partner-specific internal audience\n(Section 1.1), and in the actual DUP (Section 4) where any upcoming\nconferences and other opportunities for dissemination would be useful.\n\nThe document will be updated over time as we know better what\nconferences are coming up and so on.\n\nthanks\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWADeurope dissemination and use pla",
            "content": "cheers Stephen\n\nLibby\n\n\nOn Wed, 4 Sep 2002, Stephen Buswell wrote:\n\n> libby\n>\n> text about stilo\n>\n> \"\"Stilo has typically around 4 or 5 active Research and Development\n> projects, alongside\n> development of our own core technology. These projects usually involve\n> external partners,\n> either in industrial projects such as SophXPack which is a 4-member\n> consortium working on\n> Knowledge Engineering technology in Aerospace Design, or joint\n> industry-academic projects\n> such as SWAD-E and MONET. There is a regular interchange of ideas and\n> sometimes staff\n> between projects, for example we are using some Semantic Web ideas on\n> SophXPack. In\n> addition we hold internal events (titled 'doughnut meetings'), at which\n> projects\n> are presented.\"\"\n>\n> --s\n>\n> -----Original Message-----\n> From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n> Sent: Wednesday, August 28, 2002 9:50 AM\n> To: public-esw@w3.org\n> Subject: SWAD-europe dissemination and use plan\n>\n>\n>\n>\n> I've been working on this, and a rough draft is at\n>\n> http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n>\n> The plan is to send it to the commission in a weeks' time (Tuesday 3rd\n> September). There's a lot of tiding to be done, but this is the basic\n> structure we plan to submit.\n>\n> At this stage we are looking for comments and for additions,\n> particularly in the sections on partner-specific internal audience\n> (Section 1.1), and in the actual DUP (Section 4) where any upcoming\n> conferences and other opportunities for dissemination would be useful.\n>\n> The document will be updated over time as we know better what\n> conferences are coming up and so on.\n>\n> thanks\n>\n> Libby\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Partners' pag",
            "content": "Hi,\n\nI have updated this to edit information provided for HP (thanks) and W3C, and\nLibby has edited ILRT. I have also shortened a few of the longer sections\n\nI also removed the \"relevant experience and skill\" sections at Libby's\nsuggestion (made on the IRC channel) - if people want them back we can do\nthat.\n\nRemember that all partners can get CVS or Jigedit access to edit your\ninformation directly if you would like to (...save me the trouble ;-).\n\nCheers\n\nCharles\n\nOn Wed, 4 Sep 2002, Charles McCathieNevile wrote:\n\n>Hi Folks\n>\n>There is now a Partners' page at http://www.w3.org/2001/sw/Europe/partners\n>\n>It contains edited versions of the information in the bid - a brief\n>introduction to each partner, Relevant Experience and Skill, and Key\n>Personnel sections.\n>\n>I wondered if it was worth keeping the key personnel section, or even just\n>listing them and having a \"people page\" or links to more information about\n>people.\n>\n>I would appreciate each partner checking that there isn't something on the\n>page which is incorrect or something really important that is missing. I\n>would also appreciate general feedback on the page...\n>\n>Cheers\n>\n>Chaals\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "SWADEurope Dissemination and Use pla",
            "content": "last draft before we send it tomorrow:\n\nhttp://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n\nI could do with a paragraph from RAL about internal audience.\n\nAny comments welcome - thanks to all who have commented so far.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Other language",
            "content": "Hi folks,\n\nWe have recently set up an IRC channel as a parallel to #rdfig which is in\nItalian. I am not sure how many people reading this list speak Italian, but\nthe idea is that there are people who do, and who were struggling with RDFIG\nin english. If this experiment (and it is still very much that) works, we may\ntry to repeat it for other languages.\n\nSome links:\nThe thing was \"chumped\" in RDFIG on 5 September:\nhttp://rdfig.xmlhack.com/2002/09/05/2002-09-05.html\n\nThere are two days of logs (quiet, and the logs are hand-edited so badly\nformated): http://www.w3.org/People/Charles/rdfit/20020905a and\nhttp://www.w3.org/People/Charles/rdfit/20020906 (my hope is to have a\nregularl logging bot on this channel and keep the logs in a predictable\nand stable place.)\n\nCheers\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Other language",
            "content": "Cool. Reminds me that http://www.w3.org/RDF/translations.html includes\nan Italian translation of the old Model and Syntax spec.\n\nI wonder if as part of outreach efforts we could look into finding folk to\nupdate (or create) translations of key RDF/SW specs (and other docs?).\nI could bring this up in the Semantic Web Coordination Group, since it'd\nneed to fit with RDFCore and WebOnt WG's schedules. I'm not sure what\npoint in the spec lifecycle is best for encouraging tranlations... need to\nlook into precedents, policy etc first.\n\nAnyway http://www.xml.it:23456/RDF/REC-rdf-syntax-19990222-it.html is the\nItalian version of M+S...\n\nDan\n\nps. re stable url for logs, I hope to have esw.w3.org soon for a public\nWiki, we could use that namespace for IRC logs too. I prefer not to have\npublically writeable stuff at http://www.w3.org/* URIs, to avoid\nconfusion...\n\nOn Sat, 7 Sep 2002, Charles McCathieNevile wrote:\n\n>\n> Hi folks,\n>\n> We have recently set up an IRC channel as a parallel to #rdfig which is in\n> Italian. I am not sure how many people reading this list speak Italian, but\n> the idea is that there are people who do, and who were struggling with RDFIG\n> in english. If this experiment (and it is still very much that) works, we may\n> try to repeat it for other languages.\n>\n> Some links:\n> The thing was \"chumped\" in RDFIG on 5 September:\n> http://rdfig.xmlhack.com/2002/09/05/2002-09-05.html\n>\n> There are two days of logs (quiet, and the logs are hand-edited so badly\n> formated): http://www.w3.org/People/Charles/rdfit/20020905a and\n> http://www.w3.org/People/Charles/rdfit/20020906 (my hope is to have a\n> regularl logging bot on this channel and keep the logs in a predictable\n> and stable place.)\n>\n> Cheers\n>\n> Chaals\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Other language",
            "content": "nice one charles! I think this is exactly the sort of thing we ought to\nbe doing in the project.\n\nLibby\n\nOn Sat, 7 Sep 2002, Charles McCathieNevile wrote:\n\n>\n> Hi folks,\n>\n> We have recently set up an IRC channel as a parallel to #rdfig which is in\n> Italian. I am not sure how many people reading this list speak Italian, but\n> the idea is that there are people who do, and who were struggling with RDFIG\n> in english. If this experiment (and it is still very much that) works, we may\n> try to repeat it for other languages.\n>\n> Some links:\n> The thing was \"chumped\" in RDFIG on 5 September:\n> http://rdfig.xmlhack.com/2002/09/05/2002-09-05.html\n>\n> There are two days of logs (quiet, and the logs are hand-edited so badly\n> formated): http://www.w3.org/People/Charles/rdfit/20020905a and\n> http://www.w3.org/People/Charles/rdfit/20020906 (my hope is to have a\n> regularl logging bot on this channel and keep the logs in a predictable\n> and stable place.)\n>\n> Cheers\n>\n> Chaals\n>\n> --\n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n>  21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Other language",
            "content": "Translations of key specs is something that the W3C Offices\n(apart from UK and Australia at least!) do a lot of.  I could\nask around to see whether offices have tried this - and they\ncould be a source of translators. \n\nBrian \n\n>  -----Original Message-----\n>  From: Dan Brickley [mailto:danbri@w3.org]\n>  Sent: 07 September 2002 19:50\n>  To: Charles McCathieNevile\n>  Cc: public-esw@w3.org\n>  Subject: Re: Other languages\n>  \n>  \n>  \n>  \n>  Cool. Reminds me that \n>  http://www.w3.org/RDF/translations.html includes\n>  an Italian translation of the old Model and Syntax spec.\n>  \n>  I wonder if as part of outreach efforts we could look into \n>  finding folk to\n>  update (or create) translations of key RDF/SW specs (and \n>  other docs?).\n>  I could bring this up in the Semantic Web Coordination \n>  Group, since it'd\n>  need to fit with RDFCore and WebOnt WG's schedules. I'm not sure what\n>  point in the spec lifecycle is best for encouraging \n>  tranlations... need to\n>  look into precedents, policy etc first.\n>  \n>  Anyway \n>  http://www.xml.it:23456/RDF/REC-rdf-syntax-19990222-it.html is the\n>  Italian version of M+S...\n>  \n>  Dan\n>  \n>  ps. re stable url for logs, I hope to have esw.w3.org soon \n>  for a public\n>  Wiki, we could use that namespace for IRC logs too. I prefer \n>  not to have\n>  publically writeable stuff at http://www.w3.org/* URIs, to avoid\n>  confusion...\n>  \n>  On Sat, 7 Sep 2002, Charles McCathieNevile wrote:\n>  \n>  >\n>  > Hi folks,\n>  >\n>  > We have recently set up an IRC channel as a parallel to \n>  #rdfig which is in\n>  > Italian. I am not sure how many people reading this list \n>  speak Italian, but\n>  > the idea is that there are people who do, and who were \n>  struggling with RDFIG\n>  > in english. If this experiment (and it is still very much \n>  that) works, we may\n>  > try to repeat it for other languages.\n>  >\n>  > Some links:\n>  > The thing was \"chumped\" in RDFIG on 5 September:\n>  > http://rdfig.xmlhack.com/2002/09/05/2002-09-05.html\n>  >\n>  > There are two days of logs (quiet, and the logs are \n>  hand-edited so badly\n>  > formated): http://www.w3.org/People/Charles/rdfit/20020905a and\n>  > http://www.w3.org/People/Charles/rdfit/20020906 (my hope \n>  is to have a\n>  > regularl logging bot on this channel and keep the logs in \n>  a predictable\n>  > and stable place.)\n>  >\n>  > Cheers\n>  >\n>  > Chaals\n>  >\n>  >\n>  \n\n\n\n"
        },
        {
            "subject": "RE: Other language",
            "content": "By \"tried this\" I meant of course carried out translations\nfor key RDF/SW recs.  Case of not carrying the context from\nbrain to finger (how swebby :-)\n\nB\n\n\n>  -----Original Message-----\n>  From: Matthews, BM (Brian) [mailto:B.M.Matthews@rl.ac.uk]\n>  Sent: 09 September 2002 11:57\n>  To: 'Dan Brickley'; Charles McCathieNevile\n>  Cc: public-esw@w3.org\n>  Subject: RE: Other languages\n>  \n>  \n>  \n>  \n>  Translations of key specs is something that the W3C Offices\n>  (apart from UK and Australia at least!) do a lot of.  I could\n>  ask around to see whether offices have tried this - and they\n>  could be a source of translators. \n>  \n>  Brian \n>  \n>  >  -----Original Message-----\n>  >  From: Dan Brickley [mailto:danbri@w3.org]\n>  >  Sent: 07 September 2002 19:50\n>  >  To: Charles McCathieNevile\n>  >  Cc: public-esw@w3.org\n>  >  Subject: Re: Other languages\n>  >  \n>  >  \n>  >  \n>  >  \n>  >  Cool. Reminds me that \n>  >  http://www.w3.org/RDF/translations.html includes\n>  >  an Italian translation of the old Model and Syntax spec.\n>  >  \n>  >  I wonder if as part of outreach efforts we could look into \n>  >  finding folk to\n>  >  update (or create) translations of key RDF/SW specs (and \n>  >  other docs?).\n>  >  I could bring this up in the Semantic Web Coordination \n>  >  Group, since it'd\n>  >  need to fit with RDFCore and WebOnt WG's schedules. I'm \n>  not sure what\n>  >  point in the spec lifecycle is best for encouraging \n>  >  tranlations... need to\n>  >  look into precedents, policy etc first.\n>  >  \n>  >  Anyway \n>  >  http://www.xml.it:23456/RDF/REC-rdf-syntax-19990222-it.html is the\n>  >  Italian version of M+S...\n>  >  \n>  >  Dan\n>  >  \n>  >  ps. re stable url for logs, I hope to have esw.w3.org soon \n>  >  for a public\n>  >  Wiki, we could use that namespace for IRC logs too. I prefer \n>  >  not to have\n>  >  publically writeable stuff at http://www.w3.org/* URIs, to avoid\n>  >  confusion...\n>  >  \n>  >  On Sat, 7 Sep 2002, Charles McCathieNevile wrote:\n>  >  \n>  >  >\n>  >  > Hi folks,\n>  >  >\n>  >  > We have recently set up an IRC channel as a parallel to \n>  >  #rdfig which is in\n>  >  > Italian. I am not sure how many people reading this list \n>  >  speak Italian, but\n>  >  > the idea is that there are people who do, and who were \n>  >  struggling with RDFIG\n>  >  > in english. If this experiment (and it is still very much \n>  >  that) works, we may\n>  >  > try to repeat it for other languages.\n>  >  >\n>  >  > Some links:\n>  >  > The thing was \"chumped\" in RDFIG on 5 September:\n>  >  > http://rdfig.xmlhack.com/2002/09/05/2002-09-05.html\n>  >  >\n>  >  > There are two days of logs (quiet, and the logs are \n>  >  hand-edited so badly\n>  >  > formated): http://www.w3.org/People/Charles/rdfit/20020905a and\n>  >  > http://www.w3.org/People/Charles/rdfit/20020906 (my hope \n>  >  is to have a\n>  >  > regularl logging bot on this channel and keep the logs in \n>  >  a predictable\n>  >  > and stable place.)\n>  >  >\n>  >  > Cheers\n>  >  >\n>  >  > Chaals\n>  >  >\n>  >  >\n>  >  \n>  \n\n\n\n"
        },
        {
            "subject": "RE: Other language",
            "content": "Hi Brain,\n\nthat would be great.\n\nThey might also be willing to host logs / chumplogs. I think we want to have\nthem \"in perpetuity\" whatever that really means. I also have some thoughts\nabout logging and chumping:\n\nAuto-translation of an IRC channel currently doesn't work usefully. But there\nare a few things \"chumped\" each day on RDFIG - documents, resources, etc that\npeople on the channel thougt were interesting.\n\nI think it would be useful (picking up on Danny Ayers' idea) to collect those\nfrom channels in different languages and at least post them into a single\nmulti-lingual channel. There are a lot of multilingual people working on the\nsemantic Web, so one could hope for a number of those to have the annotations\ntranslated.\n\nAt which point it is useful to post a ponter back to language-specific\ngroups.\n\n(With more powerful chumping we could do more - pick up on something chumped\nin english, and add italian annotations. Then use something like RSS to\ncollect the chumped resources which have an italian annotation. Or which\ndon't, to see if any should get translated.\n\nI would also like to unify chumping and logging, so a chumpbot can add a\npointer to the context in a logfile.)\n\ncheers\n\nChaals\n\nOn Mon, 9 Sep 2002, Matthews, BM (Brian)  wrote:\n\n>\n>\n>By \"tried this\" I meant of course carried out translations\n>for key RDF/SW recs.  Case of not carrying the context from\n>brain to finger (how swebby :-)\n>\n>B\n>\n>\n>>  -----Original Message-----\n>>  From: Matthews, BM (Brian) [mailto:B.M.Matthews@rl.ac.uk]\n>>  Sent: 09 September 2002 11:57\n>>  To: 'Dan Brickley'; Charles McCathieNevile\n>>  Cc: public-esw@w3.org\n>>  Subject: RE: Other languages\n>>\n>>\n>>\n>>\n>>  Translations of key specs is something that the W3C Offices\n>>  (apart from UK and Australia at least!) do a lot of.  I could\n>>  ask around to see whether offices have tried this - and they\n>>  could be a source of translators.\n>>\n>>  Brian\n>>\n>>  >  -----Original Message-----\n>>  >  From: Dan Brickley [mailto:danbri@w3.org]\n>>  >  Sent: 07 September 2002 19:50\n>>  >  To: Charles McCathieNevile\n>>  >  Cc: public-esw@w3.org\n>>  >  Subject: Re: Other languages\n>>  >\n>>  >\n>>  >\n>>  >\n>>  >  Cool. Reminds me that\n>>  >  http://www.w3.org/RDF/translations.html includes\n>>  >  an Italian translation of the old Model and Syntax spec.\n>>  >\n>>  >  I wonder if as part of outreach efforts we could look into\n>>  >  finding folk to\n>>  >  update (or create) translations of key RDF/SW specs (and\n>>  >  other docs?).\n>>  >  I could bring this up in the Semantic Web Coordination\n>>  >  Group, since it'd\n>>  >  need to fit with RDFCore and WebOnt WG's schedules. I'm\n>>  not sure what\n>>  >  point in the spec lifecycle is best for encouraging\n>>  >  tranlations... need to\n>>  >  look into precedents, policy etc first.\n>>  >\n>>  >  Anyway\n>>  >  http://www.xml.it:23456/RDF/REC-rdf-syntax-19990222-it.html is the\n>>  >  Italian version of M+S...\n>>  >\n>>  >  Dan\n>>  >\n>>  >  ps. re stable url for logs, I hope to have esw.w3.org soon\n>>  >  for a public\n>>  >  Wiki, we could use that namespace for IRC logs too. I prefer\n>>  >  not to have\n>>  >  publically writeable stuff at http://www.w3.org/* URIs, to avoid\n>>  >  confusion...\n>>  >\n>>  >  On Sat, 7 Sep 2002, Charles McCathieNevile wrote:\n>>  >\n>>  >  >\n>>  >  > Hi folks,\n>>  >  >\n>>  >  > We have recently set up an IRC channel as a parallel to\n>>  >  #rdfig which is in\n>>  >  > Italian. I am not sure how many people reading this list\n>>  >  speak Italian, but\n>>  >  > the idea is that there are people who do, and who were\n>>  >  struggling with RDFIG\n>>  >  > in english. If this experiment (and it is still very much\n>>  >  that) works, we may\n>>  >  > try to repeat it for other languages.\n>>  >  >\n>>  >  > Some links:\n>>  >  > The thing was \"chumped\" in RDFIG on 5 September:\n>>  >  > http://rdfig.xmlhack.com/2002/09/05/2002-09-05.html\n>>  >  >\n>>  >  > There are two days of logs (quiet, and the logs are\n>>  >  hand-edited so badly\n>>  >  > formated): http://www.w3.org/People/Charles/rdfit/20020905a and\n>>  >  > http://www.w3.org/People/Charles/rdfit/20020906 (my hope\n>>  >  is to have a\n>>  >  > regularl logging bot on this channel and keep the logs in\n>>  >  a predictable\n>>  >  > and stable place.)\n>>  >  >\n>>  >  > Cheers\n>>  >  >\n>>  >  > Chaals\n>>  >  >\n>>  >  >\n>>  >\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: Face to Face Meetin",
            "content": ">  > 23rd september at RAL:\n\nNot sure whether Mike has asked you yet but will anyone\nbe needing accomodation for this meeting?  Any help with \ntravel?\n\nBrian\n\n\n\n"
        },
        {
            "subject": "FW: Giornata XML, Milano il 20 Settembre 2002",
            "content": "XML day, in collaboration with W3C apparently, but no sign of any E-SW\nmaterial :\n\nhttp://www.ltt.de/xml-days.2002/milan.shtml\n\n\n-------\n\nVi allego l' annuncio della Giornata XML di Milano\nOvviamente, le presentazioni di rilievo sono altre, non la mia :-), ma\ndiffondete pure il messaggio in questa forma.\n\n\nCordiali saluti a tutti e grazie\n\n\n---------------------------------------------------------------------\n\n\nGiornata XML, Milano il 20 Settembre 2002.\n\nLa Giornata XML consiste di una conferenza e di un'area\nespositiva, parte di una serie internazionale di eventi in nove\ncitt? in Europa supportate dal W3C.\n\nL'obiettivo della giornata e? di illustrare l'uso di XML in\nbusiness.\n\nTra i temi che verrano trattati: i \"Web services\", gli strumenti\nsoftware disponibili per creare e scambiare documenti XML, gli\nstandard di interscambio di informazioni tecniche e commerciali\nin vari settori.\n\nTra le presentazioni di rilievo l`intervento di Oreste Signore,\nResponsabile dell'Ufficio Italiano del W3C.\n\nIl programma comprende inoltre due casi di studio e diverse\npresentazioni di societ? internazionali.\n\nPer maggiori informazioni:\nhttp://www.ltt.de/xml-days.2002/milan.shtml\n\n\n----------------------------------------------------------------\n\n\nOreste Signore\nW3C Office Manager in Italy\nUfficio Italiano W3C presso il C.N.R.\nIstituto di Scienza e Tecnologie dell' Informazione \"A. Faedo\"\nArea della Ricerca di Pisa - San Cataldo\nvia G. Moruzzi, 1\n56124 Pisa\n                (Italy)\n\nPhone:  +39 050 315 2995 (office)\n                +39 348 3962627 (mobile)\nFax:            +39 050 313 8091 (G3)\n                +39 050 313 8092 (G4)\ne.mail: oreste@w3.org\n                Oreste.Signore@cnuce.cnr.it\nwww:\n        \"http://www.w3c.it/\"\n        \"http://www.cnuce.pi.cnr.it/\"\n        \"http://info.cnuce.cnr.it/seal_hp.html\"\n\n____________________________________________\n\nEverything should be made as simple as possible, but not simpler\n(Albert Einstein)\n\n\n\n"
        },
        {
            "subject": "RE: Face to Face Meetin",
            "content": "I was thinking I'd go for the day and get the train and then taxi - that\nshould be fine.\n\nthanks Brian\n\nLibby\n\nOn Mon, 9 Sep 2002, Matthews, BM (Brian)  wrote:\n\n>\n>\n>\n> >  > 23rd september at RAL:\n>\n> Not sure whether Mike has asked you yet but will anyone\n> be needing accomodation for this meeting?  Any help with\n> travel?\n>\n> Brian\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RAPIDUS Notification (fwd",
            "content": "Might be interesting for some people.\n\nLibby\n\n---------- Forwarded message ----------\nDate: Thu, 12 Sep 2002 01:04:44 +0100 (WET DST)\nFrom: CORDIS-RAPIDUS <rapidus@cordis.lu>\nSubject: RAPIDUS Notification\n\nRAPIDUS brings you the following updates related to your defined search profile\n\nPlease do not reply to this message and send all your RAPIDUS related questions and comments to the CORDIS HelpDesk (helpdesk@cordis.lu).\n\nCORDIS Database: NEWS\n        Search name: FP6\n        Search description: What's new in FP6\n-------------------------------------------------------------------\nIST in FP6 - UK event\n\nRecord Control Number : 18930\nDate : 2002-09-11\nCategory :  Event\nGeneral Information :\n  UKISHELP and ManIST are holding a conference on IST (information\nsociety technologies)  in the Sixth Framework programme (FP6)  in\nLondon Heathrow on 1 and 2 October.\n\nThe conference is entitled 'Framework 6 IST: Opportunity or\nthreat?' and will focus on the differences between FP5 and FP6.\n\n'In a fast changing technology and market environment it is hardly\nsurprising that priorities and objectives for research and\ntechnological development funding will change from earlier\nFramework programmes. We want to make sure that FP6 is seen as an\nopportunity rather than a threat to UK organisations,' explained\nPatrick McDonald, a Director from the UK government's department of\ntrade and industry (DTI) .\n\nThe event will tackle questions such as:\n- is FP6 collaboration right for our developing business?\n- what will be the benefits?\n- what will be the likely structure for the information society\ntheme?\n- how do we participate?\n\nThe conference will give an introduction to FP6 with in depth\npresentations from DTI and European Commission officials. It will\nalso hold informal and interactive drop in session on FP6\ninstruments, partner searching, 'Go Digital' and participation.\nOne-to-one brokerage meetings will also be held.\n\nText :\n\nRemarks :\n\nData Source Provider : UKISHELP\nDocument Reference : Based on an event announcement\nProgramme Acronym : FRAMEWORK 6C, FP6-INTEGRATING, MS-UK C, FP6-IST\nSubject Index Codes : Information Processing, Information Systems\nContact Person : For further information please consult the following web address:\nhttp://www.framework6.org.uk\nor\nTel: +44 1772 767779\n-------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "SWAD(Europe) logo(s",
            "content": "Eric, SWAD-Europeans,\n\nWe have some resources in SWAD-Europe for publicity materials. This is to\npromote both the project itself, and 'Semantic Web' tools, technology,\nadoption (ie. RDF etc). So we need some distinct identity for the project\n'as a project' but also to avoid sending a confusing msg when promoting\nRDF adoption. We'll likely be making t-shirts, flyers, mugs etc. as part\nof swad-europe publicity/outreach; some of this will have a bias towards\nswad-e as project, some of it towards general promotion of semantic\nwebbery.\n\nSo this creates a challenge w.r.t. logos etc. For eg., if we wanted to\ncreate a mug with 'rdf developer' or 'semantic web' developer on it, plus\na swad-e logo, we're in similiar territory to the work Eric Miller (cc:'d)\nhas already done with the RDF logo (see http://www.w3.org/RDF/icons/). I'd\nlike SWAD-Europe to complement this outreach work rather than pull in a\ndifferent direction; but also for SWAD-Europe to have a distinct identity\nand recognisable logo.\n\nSo one way of proceeding would be for SWAD-E folk to point a designer at\nsome raw materials (eg. the RDF logo Eric produced) plus some constraints\n(eg. that we want to project EUropean-ness, etc) and see what they could\ncome up with. Eric, if you could say a bit more about your plans re\ngeneral Semantic Web education'n'outreach, and particularly logos etc.,\nthat'd be very useful. I'd also want to get input from W3C comms team;\nEric -- have you already talked to them re the design linked above?\n\nThere is some looming urgency in that there's some Commission meeting\n(sorry don't have details to hand; Libby/Kate can you send round info?\ndates?) for which it'd be good to have a logo, flyers etc. T-shirts and\nthe like can come later...\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "I'm putting Coralie in the loop, she's our logo designer expert.\n\n> \n> \n> Eric, SWAD-Europeans,\n> \n> We have some resources in SWAD-Europe for publicity materials. This is to\n> promote both the project itself, and 'Semantic Web' tools, technology,\n> adoption (ie. RDF etc). So we need some distinct identity for the project\n> 'as a project' but also to avoid sending a confusing msg when promoting\n> RDF adoption. We'll likely be making t-shirts, flyers, mugs etc. as part\n> of swad-europe publicity/outreach; some of this will have a bias towards\n> swad-e as project, some of it towards general promotion of semantic\n> webbery.\n> \n> So this creates a challenge w.r.t. logos etc. For eg., if we wanted to\n> create a mug with 'rdf developer' or 'semantic web' developer on it, plus\n> a swad-e logo, we're in similiar territory to the work Eric Miller (cc:'d)\n> has already done with the RDF logo (see http://www.w3.org/RDF/icons/). I'd\n> like SWAD-Europe to complement this outreach work rather than pull in a\n> different direction; but also for SWAD-Europe to have a distinct identity\n> and recognisable logo.\n> \n> So one way of proceeding would be for SWAD-E folk to point a designer at\n> some raw materials (eg. the RDF logo Eric produced) plus some constraints\n> (eg. that we want to project EUropean-ness, etc) and see what they could\n> come up with. Eric, if you could say a bit more about your plans re\n> general Semantic Web education'n'outreach, and particularly logos etc.,\n> that'd be very useful. I'd also want to get input from W3C comms team;\n> Eric -- have you already talked to them re the design linked above?\n> \n> There is some looming urgency in that there's some Commission meeting\n> (sorry don't have details to hand; Libby/Kate can you send round info?\n> dates?) for which it'd be good to have a logo, flyers etc. T-shirts and\n> the like can come later...\n> \n> Dan\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "Cool. I like Coralie's logos.\n\nAre there any ideas we want to convey in the logo? A connection with RDF and\nthe RDF logo? A connection with Europe would be good.\n\nChaals\n\nOn Thu, 12 Sep 2002, Daniel Dardailler wrote:\n\n>\n>\n>I'm putting Coralie in the loop, she's our logo designer expert.\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "On Thu, 12 Sep 2002, Charles McCathieNevile wrote:\n\n>\n> Cool. I like Coralie's logos.\n>\n\nMe too. If Coralie can't do it within the timescales, ILRT can employ\nsomeone who normally does good work (though not as nice as Coralie's\nwork :)\n\nThe deadline is early October for logo and leaflets, for the FP 6 launch\nin November. It would be useful to know as soon as possible who is going\nto undertake the work.\n\n> Are there any ideas we want to convey in the logo? A connection with RDF and\n> the RDF logo? A connection with Europe would be good.\n\nYep: as Dan suggested, it makes sense to have something related to or\neven based on Eric's RDF logo if possible; however, we need also to be\nable to say that this is our logo which conveys Europeanness.\n\nhttp://www.w3.org/RDF/icons/\n\nThe logo has to be suitable for a bunch of stuff too - mugs, posters\nand tshirts as well as leaflets, webpages, different background colours\nand sizes etc.\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "I would be glad to design something(s) and bring the drafts to you!\nI need to know what you want to convey (it helps me a lot)\n\nI'll try to bring idea(s) before early October.\n\ncoralie (much honored :-))\n\nCharles McCathieNevile wrote:\n> Cool. I like Coralie's logos.\n> \n> Are there any ideas we want to convey in the logo? A connection with RDF and\n> the RDF logo? A connection with Europe would be good.\n> \n> Chaals\n> \n> On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n> \n> \n>>\n>>I'm putting Coralie in the loop, she's our logo designer expert.\n>>\n> \n> \n\n\n-- \nCoralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\nWorld Wide Web Consortium                            http://www.w3.org\nW3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\nVoice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "hey Coralie,\n\nThat's great! we would need designs before then though, because we would\nneed some time to create the flyers. I'm not sure how long this would\ntake though - Kate, do you know?\n\nWhat we want to convey is trickier....Europeanness is one\nthing....erm...any ideas everyone?\n\nthanks again Coralie,\n\nLibby\n\nOn Thu, 12 Sep 2002, Coralie Mercier wrote:\n\n>\n> I would be glad to design something(s) and bring the drafts to you!\n> I need to know what you want to convey (it helps me a lot)\n>\n> I'll try to bring idea(s) before early October.\n>\n> coralie (much honored :-))\n>\n> Charles McCathieNevile wrote:\n> > Cool. I like Coralie's logos.\n> >\n> > Are there any ideas we want to convey in the logo? A connection with RDF and\n> > the RDF logo? A connection with Europe would be good.\n> >\n> > Chaals\n> >\n> > On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n> >\n> >\n> >>\n> >>I'm putting Coralie in the loop, she's our logo designer expert.\n> >>\n> >\n> >\n>\n>\n> --\n> Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n> World Wide Web Consortium                            http://www.w3.org\n> W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n> Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "the EU circle of lovely yellow stars ;-)\n\nand the RDF logo, or something recognisably like it.\n\n/me votes against the europe map on the coins after seeing altered pictures\nof it and danbri's porn-filtering exercise\n\nChaals\n\nOn Thu, 12 Sep 2002, Libby Miller wrote:\n\n>\n>\n>hey Coralie,\n>\n>That's great! we would need designs before then though, because we would\n>need some time to create the flyers. I'm not sure how long this would\n>take though - Kate, do you know?\n>\n>What we want to convey is trickier....Europeanness is one\n>thing....erm...any ideas everyone?\n>\n>thanks again Coralie,\n>\n>Libby\n>\n>On Thu, 12 Sep 2002, Coralie Mercier wrote:\n>\n>>\n>> I would be glad to design something(s) and bring the drafts to you!\n>> I need to know what you want to convey (it helps me a lot)\n>>\n>> I'll try to bring idea(s) before early October.\n>>\n>> coralie (much honored :-))\n>>\n>> Charles McCathieNevile wrote:\n>> > Cool. I like Coralie's logos.\n>> >\n>> > Are there any ideas we want to convey in the logo? A connection with RDF and\n>> > the RDF logo? A connection with Europe would be good.\n>> >\n>> > Chaals\n>> >\n>> > On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n>> >\n>> >\n>> >>\n>> >>I'm putting Coralie in the loop, she's our logo designer expert.\n>> >>\n>> >\n>> >\n>>\n>>\n>> --\n>> Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n>> World Wide Web Consortium                            http://www.w3.org\n>> W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n>> Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n>>\n>>\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "I was looking at the RDF logo and wondered if it could be feasible and \nacceptable to use the circle in the center of the blue shape (sorry if \nit represents something real that I don't know/didn't recognize) and \ninsert the EU circle of golden stars?\n\nI was also thinking about having the EU circle of stars around the blue \nshape, or something similar?\n\nIf we are to use the RDF logo (apologies in advance if it's a dumb \nquestion) would that be appropriate to have SWAD-E or SWAD-EU or \nSWAD-Europe instead of RDF?\n\n\n\nCharles McCathieNevile wrote:\n> the EU circle of lovely yellow stars ;-)\n> \n> and the RDF logo, or something recognisably like it.\n> \n> /me votes against the europe map on the coins after seeing altered pictures\n> of it and danbri's porn-filtering exercise\n> \n> Chaals\n> \n> On Thu, 12 Sep 2002, Libby Miller wrote:\n> \n> \n>>\n>>hey Coralie,\n>>\n>>That's great! we would need designs before then though, because we would\n>>need some time to create the flyers. I'm not sure how long this would\n>>take though - Kate, do you know?\n>>\n>>What we want to convey is trickier....Europeanness is one\n>>thing....erm...any ideas everyone?\n>>\n>>thanks again Coralie,\n>>\n>>Libby\n>>\n>>On Thu, 12 Sep 2002, Coralie Mercier wrote:\n>>\n>>\n>>>I would be glad to design something(s) and bring the drafts to you!\n>>>I need to know what you want to convey (it helps me a lot)\n>>>\n>>>I'll try to bring idea(s) before early October.\n>>>\n>>>coralie (much honored :-))\n>>>\n>>>Charles McCathieNevile wrote:\n>>>\n>>>>Cool. I like Coralie's logos.\n>>>>\n>>>>Are there any ideas we want to convey in the logo? A connection with RDF and\n>>>>the RDF logo? A connection with Europe would be good.\n>>>>\n>>>>Chaals\n>>>>\n>>>>On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n>>>>\n>>>>\n>>>>\n>>>>>I'm putting Coralie in the loop, she's our logo designer expert.\n>>>>>\n>>>>\n>>>>\n>>>\n>>>--\n>>>Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n>>>World Wide Web Consortium                            http://www.w3.org\n>>>W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n>>>Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n>>>\n>>>\n>>>\n>>\n> \n\n\n-- \nCoralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\nWorld Wide Web Consortium                            http://www.w3.org\nW3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\nVoice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "Hi, \n\nI think it would be best to work on the logo and other publicity ideas without \nthe panic of current mid October deadline for materials. \n\nSo propose that we design a simple fact sheet without logo for the FP6 Launch \nConference in November while embarking on a more coherent approach for the \noverall marketing of the project. What do you think? \n\nIt would be great to see some logo ideas etc from Coralie in early October to \nstart the ball rolling, \n\nKate..\n\n\nOn Thu, 12 Sep 2002 11:20:59 -0400 (EDT) Charles McCathieNevile \n<charles@w3.org> wrote:\n\n> \n> the EU circle of lovely yellow stars ;-)\n> \n> and the RDF logo, or something recognisably like it.\n> \n> /me votes against the europe map on the coins after seeing altered pictures\n> of it and danbri's porn-filtering exercise\n> \n> Chaals\n> \n> On Thu, 12 Sep 2002, Libby Miller wrote:\n> \n> >\n> >\n> >hey Coralie,\n> >\n> >That's great! we would need designs before then though, because we would\n> >need some time to create the flyers. I'm not sure how long this would\n> >take though - Kate, do you know?\n> >\n> >What we want to convey is trickier....Europeanness is one\n> >thing....erm...any ideas everyone?\n> >\n> >thanks again Coralie,\n> >\n> >Libby\n> >\n> >On Thu, 12 Sep 2002, Coralie Mercier wrote:\n> >\n> >>\n> >> I would be glad to design something(s) and bring the drafts to you!\n> >> I need to know what you want to convey (it helps me a lot)\n> >>\n> >> I'll try to bring idea(s) before early October.\n> >>\n> >> coralie (much honored :-))\n> >>\n> >> Charles McCathieNevile wrote:\n> >> > Cool. I like Coralie's logos.\n> >> >\n> >> > Are there any ideas we want to convey in the logo? A connection with RDF \n> and\n> >> > the RDF logo? A connection with Europe would be good.\n> >> >\n> >> > Chaals\n> >> >\n> >> > On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n> >> >\n> >> >\n> >> >>\n> >> >>I'm putting Coralie in the loop, she's our logo designer expert.\n> >> >>\n> >> >\n> >> >\n> >>\n> >>\n> >> --\n> >> Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n> >> World Wide Web Consortium                            http://www.w3.org\n> >> W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n> >> Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n> >>\n> >>\n> >>\n> >\n> \n> -- \n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 \n> 136\n> SWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n>  21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n> \n\n----------------------\nKate Sharp\nProject Manager\nBiz/ed and SWAD Europe\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "I don't know of anything that it is too much like. Seems like a good start.\n\nI don't see any reason why we need the RDF bit, but fading it into the\nbackground or something might be a good approach.\n\nChaals\n\nOn Thu, 12 Sep 2002, Coralie Mercier wrote:\n\n>\n>I was looking at the RDF logo and wondered if it could be feasible and\n>acceptable to use the circle in the center of the blue shape (sorry if\n>it represents something real that I don't know/didn't recognize) and\n>insert the EU circle of golden stars?\n>\n>I was also thinking about having the EU circle of stars around the blue\n>shape, or something similar?\n>\n>If we are to use the RDF logo (apologies in advance if it's a dumb\n>question) would that be appropriate to have SWAD-E or SWAD-EU or\n>SWAD-Europe instead of RDF?\n>\n>\n>\n>Charles McCathieNevile wrote:\n>> the EU circle of lovely yellow stars ;-)\n>>\n>> and the RDF logo, or something recognisably like it.\n>>\n>> /me votes against the europe map on the coins after seeing altered pictures\n>> of it and danbri's porn-filtering exercise\n>>\n>> Chaals\n>>\n>> On Thu, 12 Sep 2002, Libby Miller wrote:\n>>\n>>\n>>>\n>>>hey Coralie,\n>>>\n>>>That's great! we would need designs before then though, because we would\n>>>need some time to create the flyers. I'm not sure how long this would\n>>>take though - Kate, do you know?\n>>>\n>>>What we want to convey is trickier....Europeanness is one\n>>>thing....erm...any ideas everyone?\n>>>\n>>>thanks again Coralie,\n>>>\n>>>Libby\n>>>\n>>>On Thu, 12 Sep 2002, Coralie Mercier wrote:\n>>>\n>>>\n>>>>I would be glad to design something(s) and bring the drafts to you!\n>>>>I need to know what you want to convey (it helps me a lot)\n>>>>\n>>>>I'll try to bring idea(s) before early October.\n>>>>\n>>>>coralie (much honored :-))\n>>>>\n>>>>Charles McCathieNevile wrote:\n>>>>\n>>>>>Cool. I like Coralie's logos.\n>>>>>\n>>>>>Are there any ideas we want to convey in the logo? A connection with RDF and\n>>>>>the RDF logo? A connection with Europe would be good.\n>>>>>\n>>>>>Chaals\n>>>>>\n>>>>>On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n>>>>>\n>>>>>\n>>>>>\n>>>>>>I'm putting Coralie in the loop, she's our logo designer expert.\n>>>>>>\n>>>>>\n>>>>>\n>>>>\n>>>>--\n>>>>Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n>>>>World Wide Web Consortium                            http://www.w3.org\n>>>>W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n>>>>Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n>>>>\n>>>>\n>>>>\n>>>\n>>\n>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "> I think it would be best to work on the logo and other publicity ideas without \n> the panic of current mid October deadline for materials. \n> \n> So propose that we design a simple fact sheet without logo for the FP6 Launch \n> Conference in November while embarking on a more coherent approach for the \n> overall marketing of the project. What do you think? \n\nI think this is a very sensible suggestion - we did the \nsame for Renardus a couple of years ago: the important \nthing was to register the name and outline of \nwork/objectives in peoples' minds, and as far as I know it \nhad no detrimental effect on subsequent acceptance of our \nlogo/style.\n----------------------\nDr Lesly Huxley : lesly.huxley@bris.ac.uk  \nhttp://www.ilrt.bris.ac.uk/~relh\nResearch Director and Acting Institute Director\nInstitute for Learning and Research Technology\n8-10 Berkeley Sq., University of Bristol,  BS8 1HH, UK   \nTel: +44 117 928 7196 fax: + 44 117 928 7112\n\n\n\n"
        },
        {
            "subject": "Initial agenda items for F2",
            "content": "Hi everyone, \n\nI am circulating some ideas for agenda items for face to face meeting on Mon\n23rd September, 10.00 - 17.00. Please let me know before Weds 18th Sept any \namendments/additions you would like to see.\n\nTechnical work - update from each partner  \nConferences and workshops\nPublicity\nManagement tools - forms, handbook, reports \nCommunication - meetings, Web site \nTechnical plan\nFurther technical discussions on deliverables due \n\nThe meeting will be at RAL (further details to follow).\n\nThis was originally intended to be a management meeting but it was felt that \npeople may like the opportunity to discuss some of the technical work that is \ncoming up too so registration is open to all. \n\nPlease confirm your attendance to me by Weds 18th September so that I can \ninform RAL who are arranging lunch. \n\nLooking forward to seeing you all, \n\nKate..\n----------------------\nKate Sharp\nProject Manager\nBiz/ed and SWAD Europe\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "I had something like an idea:\n\nhttp://tux.w3.org/~charles/swade.png\n\n(if you imagine that the yellow blobs are the EU stars, that the links from\nthem are nicely curved like RDF arcs, and that the whole thing is done by\nsomeone with a bit more talent, like Coralie...)\n\nI had another idea but someone pointed out that it was more like a schematic\nanatomical picture than anything else.\n\nAnyway, I look forward to seeing whatever Coralie decides is a good idea.\n\nChaals\n\nOn Thu, 12 Sep 2002, Charles McCathieNevile wrote:\n\n>Cool. I like Coralie's logos.\n>\n>Are there any ideas we want to convey in the logo? A connection with RDF and\n>the RDF logo? A connection with Europe would be good.\n>\n>Chaals\n>\n>On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n>\n>>\n>>\n>>I'm putting Coralie in the loop, she's our logo designer expert.\n>>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "SWADEurope calendar worksho",
            "content": "I'm looking at finalizing the agenda for this and sending it round a few\nmore lists. Before I do that I'd like to have a registration page if\npossible. Dan, Chaals, do you think this would be possible in the next\nweek? I'm away till the 23rd from tomorrow and so I can send the message\naround when I get back.\n\nI can set up the text in the page, but the text I sent round is at\nhttp://lists.w3.org/Archives/Public/public-esw/2002Aug/0003.html for\ninfo.\n\nthanks,\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope calendar worksho",
            "content": "I'll do registration if you put something in a page.\n\nCheers\n\nChaals\n\nOn Fri, 13 Sep 2002, Libby Miller wrote:\n\n>\n>\n>I'm looking at finalizing the agenda for this and sending it round a few\n>more lists. Before I do that I'd like to have a registration page if\n>possible. Dan, Chaals, do you think this would be possible in the next\n>week? I'm away till the 23rd from tomorrow and so I can send the message\n>around when I get back.\n>\n>I can set up the text in the page, but the text I sent round is at\n>http://lists.w3.org/Archives/Public/public-esw/2002Aug/0003.html for\n>info.\n>\n>thanks,\n>\n>Libby\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Invitation to make presentatio",
            "content": "Dear Edmundas\n\nI am very sorry, but unfortunately none of our project team members is\navailable to speak in this period so that we will have to regretfully\ndecline your invitation.\n\nFor more information about SWAD-Europe please look at the website, which\nis at\n\nhttp://www.w3.org/2001/sw/Europe/\n\nThere is also a fact sheet about the project available at\n\nhttp://www.w3.org/2001/sw/Europe/factsheet/\n\nPlease contact me or public-esw@w3.org, our public email list, if\nyou require any more information about the project.\n\nBest wishes,\n\nLibby Miller\n\n\nOn Mon, 26 Aug 2002, Edmundas Zvirblis wrote:\n\n> Dear Libby MILLER,\n>\n> It is our great pleasure to extend to you an invitation to make presentation\n> or to participate at the TELEBALT  Conference Teleworking for Business,\n> Education, Research and e-Commerce (Vilnius, Lithuania, 21-22 October\n> 2002): (http://www.infobalt.lt/telebalt )\n>\n> On behalf of the organizers we invite you or your project SWAD-EUROPE\n> partner to submit presentation topics, abstracts and bios for the TELEBALT\n> Conference. The number of possible presentation is limited.\n>\n> Organised by INFOBALT - Association of Information Technologies,\n> Telecommunications and Office Equipment of Lithuania in the frame of the\n> project TELEBALT (Teleworking as a Tool for Information Society Technologies\n> Programme Promotion to Baltic States) funded by Information Society\n> Programme of the European Union. The conference is organized in co-operation\n> with Earth Data Networks for Education and Scientific Exchange (EDNES),\n> France, public foundation Open Latvia.\n>\n> The Conference Teleworking for Business, Education, Research and\n>  e-Commerce aims at strengthening the scientific and technological\n> co-operation between the European Union and the Newly Associated States\n> (NAS), in particular the Baltic countries in the field of IT application to\n> new methods of work, business, education, research, e-commerce, medicine,\n> regional development and social integration using IT.\n>\n> Currently Baltic States community faces changes and opening possibilities\n> for cooperation with EU partners in the field of information society\n> development and added value creation through the various information and\n> communication technology related programmes. In-time acknowledgement about\n> these possibilities would serve as basement for future fruitful\n> collaboration.\n>\n> Some 50 speakers and 200 participants from all countries of the Baltic\n> Region and the European Union and the European Commission have been invited\n> and will be invited. Parallel to the TELEBALT conference INFOBALT organize\n> 4th International Conference Information Society 2002 and League of\n> Investors. These events will take place in the same venue as TELEBALT. Last\n> year it attracted some 90 speakers and 600 participants. More information\n> about these events at http://www.infobalt.lt/english/ .\n> TELEBALT conference participants will have occasion to present their IST\n> project in the INFOBALT 2002 trade fair that will be organized 23-26 October\n> 2002. It is 9th International ICT sector trade fair and is the major such a\n> type event in Baltic States. Last year it attracted 200 exhibitors and 60000\n> visitors (+ 100 000 visited virtual trade fair). Association INFOBALT and\n> organized events will also provide occasion to disseminate material about\n> your project, extend it finding new partners from Candidate Countries or\n> initiate new activities under various EU programmes umbrella.\n>\n> Edmundas Zvirblis or Saulius Arelis will provide detailed information under\n> your request.\n>\n> We also contact you due to the project SWAD-EUROPE, for which you have been\n> mentioned as the contact person implementing another Association INFOBALT\n> activity.\n>\n> Association INFOBALT participates in working group P2F (Projects to\n>  Funds), which was initiated by the Information Society Development\n> Committee under the Government of Lithuania. The working group P2F was\n> especially formed, to develop a large range of multiple project proposals\n> and to seek subsequently for their co-funding at international donor\n> programmes. Currently, P2F comprises sixteen members from different\n> Lithuanian ministries, universities and private companies.\n> It is one of our immediate tasks, to gather 50-70 project proposals from\n> previously successful funded ICT projects. Thus, we aim to achieve both, (a)\n> to facilitate the project development work of the working group, as well as\n> (b) to identify appropriate cooperation partners and programmes for joint\n> projects. The gathered information will be made available to the members of\n> the working group P2F only.\n> For this reason we kindly ask you to provide us with more background\n> information to the project mentioned above. Of a particular interest for us\n> would be the project application form as it was submitted to the co-funding\n> donor programme (We currently still lack experience with non-national donor\n> programmes; thus an application example would be of a great value for us).\n>\n> Many thanks in advance for your assistance. If you have any further\n> questions, please do not hesitate to contact Saulius Arelis at any time. You\n> may also get a deeper insight in the functions and responsibilities of the\n> two major stakeholder organisations of the working group P2F at the links\n> below. Yours sincerely,\n>\n> Yours sincerely,\n>\n> Edmundas Zvirblis\n> Project Manager\n> Tel. + 370 2 622623\n> Mobile: + 370 86 55422\n> Fax: + 370 2 622629\n> INFOBALT Centras\n> Vokieciu 28/17-16\n> LT-2001 Vilnius\n> zvirblis@infobalt.lt\n> www.infobalt.lt\n>\n> Saulius Arelis\n> Project Manager\n> Association INFOBALT\n> Tel. + 370 2 622623\n> Mobile: + 370 610 35036\n> Fax: + 370 2 622629\n> saulius@infobalt.lt\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "Hello all\n\nDanny Ayers sent me an idea. I'm not sure it is exactly what he meant. \nAnyway, tell me what you think of the very rough draft. [1]\n\nCoralie\n\n[1] http://www.w3.org/People/CMercier/swad-e-1.gif\n\nCharles McCathieNevile wrote:\n> I had something like an idea:\n> \n> http://tux.w3.org/~charles/swade.png\n> \n> (if you imagine that the yellow blobs are the EU stars, that the links from\n> them are nicely curved like RDF arcs, and that the whole thing is done by\n> someone with a bit more talent, like Coralie...)\n> \n> I had another idea but someone pointed out that it was more like a schematic\n> anatomical picture than anything else.\n> \n> Anyway, I look forward to seeing whatever Coralie decides is a good idea.\n> \n> Chaals\n> \n> On Thu, 12 Sep 2002, Charles McCathieNevile wrote:\n> \n> \n>>Cool. I like Coralie's logos.\n>>\n>>Are there any ideas we want to convey in the logo? A connection with RDF and\n>>the RDF logo? A connection with Europe would be good.\n>>\n>>Chaals\n>>\n>>On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n>>\n>>\n>>>\n>>>I'm putting Coralie in the loop, she's our logo designer expert.\n>>>\n>>\n>>\n> \n\n\n-- \nCoralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\nWorld Wide Web Consortium                            http://www.w3.org\nW3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\nVoice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n\n\n\n"
        },
        {
            "subject": "RE: SWAD(Europe) logo(s",
            "content": "Heh - I like it, but it's nothing like what I was thinking of!\n\nThis is more like what I had in mind (which now looks pretty staid in\ncomparison), though of course with 3d nodes, properly spaced stars and a\ncurlier w... Playing with these shapes came the challenge of doing a minimal\nSVG version, but after half an hour not getting *any* arc right I gave up\nand used Webdraw instead.\n\nhttp://www.ideagraph.net/images/esw.png\n\nhttp://www.ideagraph.net/images/esw.svg\n\nCheers,\nDanny.\n\n---\nDanny Ayers\n<stuff> http://www.isacat.net </stuff>\n\nIdea maps for the Semantic Web\nhttp://ideagraph.net\n\n\n>-----Original Message-----\n>From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n>Behalf Of Coralie Mercier\n>Sent: 13 September 2002 19:46\n>To: Charles McCathieNevile\n>Cc: Daniel Dardailler; Dan Brickley; public-esw@w3.org; em@w3.org\n>Subject: Re: SWAD(-Europe) logo(s)\n>\n>\n>\n>Hello all\n>\n>Danny Ayers sent me an idea. I'm not sure it is exactly what he meant.\n>Anyway, tell me what you think of the very rough draft. [1]\n>\n>Coralie\n>\n>[1] http://www.w3.org/People/CMercier/swad-e-1.gif\n>\n>Charles McCathieNevile wrote:\n>> I had something like an idea:\n>>\n>> http://tux.w3.org/~charles/swade.png\n>>\n>> (if you imagine that the yellow blobs are the EU stars, that the\n>links from\n>> them are nicely curved like RDF arcs, and that the whole thing is done by\n>> someone with a bit more talent, like Coralie...)\n>>\n>> I had another idea but someone pointed out that it was more like\n>a schematic\n>> anatomical picture than anything else.\n>>\n>> Anyway, I look forward to seeing whatever Coralie decides is a good idea.\n>>\n>> Chaals\n>>\n>> On Thu, 12 Sep 2002, Charles McCathieNevile wrote:\n>>\n>>\n>>>Cool. I like Coralie's logos.\n>>>\n>>>Are there any ideas we want to convey in the logo? A connection\n>with RDF and\n>>>the RDF logo? A connection with Europe would be good.\n>>>\n>>>Chaals\n>>>\n>>>On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n>>>\n>>>\n>>>>\n>>>>I'm putting Coralie in the loop, she's our logo designer expert.\n>>>>\n>>>\n>>>\n>>\n>\n>\n>--\n>Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n>World Wide Web Consortium                            http://www.w3.org\n>W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n>Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "I think that's rather lovely!\n\nLibby\n\nOn Fri, 13 Sep 2002, Coralie Mercier wrote:\n\n>\n> Hello all\n>\n> Danny Ayers sent me an idea. I'm not sure it is exactly what he meant.\n> Anyway, tell me what you think of the very rough draft. [1]\n>\n> Coralie\n>\n> [1] http://www.w3.org/People/CMercier/swad-e-1.gif\n>\n> Charles McCathieNevile wrote:\n> > I had something like an idea:\n> >\n> > http://tux.w3.org/~charles/swade.png\n> >\n> > (if you imagine that the yellow blobs are the EU stars, that the links from\n> > them are nicely curved like RDF arcs, and that the whole thing is done by\n> > someone with a bit more talent, like Coralie...)\n> >\n> > I had another idea but someone pointed out that it was more like a schematic\n> > anatomical picture than anything else.\n> >\n> > Anyway, I look forward to seeing whatever Coralie decides is a good idea.\n> >\n> > Chaals\n> >\n> > On Thu, 12 Sep 2002, Charles McCathieNevile wrote:\n> >\n> >\n> >>Cool. I like Coralie's logos.\n> >>\n> >>Are there any ideas we want to convey in the logo? A connection with RDF and\n> >>the RDF logo? A connection with Europe would be good.\n> >>\n> >>Chaals\n> >>\n> >>On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n> >>\n> >>\n> >>>\n> >>>I'm putting Coralie in the loop, she's our logo designer expert.\n> >>>\n> >>\n> >>\n> >\n>\n>\n> --\n> Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n> World Wide Web Consortium                            http://www.w3.org\n> W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n> Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "Yep, me too.\n\nOne thought is that we need to be able to use whatever we come up with as a\nwebsite logo (small...) as well as printing it on t-shirts, mugs, pieces of\npaper (again, sometimes small), and maybe the project Zeppelin if we get one.\n\n(which for that one would mean thicker lines in a small version).\n\ncheers\n\nChaals\n\nOn Sat, 14 Sep 2002, Libby Miller wrote:\n\n>\n>\n>I think that's rather lovely!\n>\n>Libby\n>\n>On Fri, 13 Sep 2002, Coralie Mercier wrote:\n>\n>>\n>> Hello all\n>>\n>> Danny Ayers sent me an idea. I'm not sure it is exactly what he meant.\n>> Anyway, tell me what you think of the very rough draft. [1]\n>>\n>> Coralie\n>>\n>> [1] http://www.w3.org/People/CMercier/swad-e-1.gif\n>>\n>> Charles McCathieNevile wrote:\n>> > I had something like an idea:\n>> >\n>> > http://tux.w3.org/~charles/swade.png\n>> >\n>> > (if you imagine that the yellow blobs are the EU stars, that the links from\n>> > them are nicely curved like RDF arcs, and that the whole thing is done by\n>> > someone with a bit more talent, like Coralie...)\n>> >\n>> > I had another idea but someone pointed out that it was more like a schematic\n>> > anatomical picture than anything else.\n>> >\n>> > Anyway, I look forward to seeing whatever Coralie decides is a good idea.\n>> >\n>> > Chaals\n>> >\n>> > On Thu, 12 Sep 2002, Charles McCathieNevile wrote:\n>> >\n>> >\n>> >>Cool. I like Coralie's logos.\n>> >>\n>> >>Are there any ideas we want to convey in the logo? A connection with RDF and\n>> >>the RDF logo? A connection with Europe would be good.\n>> >>\n>> >>Chaals\n>> >>\n>> >>On Thu, 12 Sep 2002, Daniel Dardailler wrote:\n>> >>\n>> >>\n>> >>>\n>> >>>I'm putting Coralie in the loop, she's our logo designer expert.\n>> >>>\n>> >>\n>> >>\n>> >\n>>\n>>\n>> --\n>> Coralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\n>> World Wide Web Consortium                            http://www.w3.org\n>> W3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\n>> Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n>>\n>>\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "xmlfr.org... and other nonenglish sites covering RDF/XML",
            "content": "...has good coverage of XML, RDF etc. in French.\n\nfor eg., http://xmlfr.org/actualites/tech/000418-000\n\nlots of hits for 'rdf':\nhttp://xmlfr.org/chercher/htsearch.cgi?config=htdigv2&words=rdf\n\nI think some of the content might be translations of XMLHack articles.\n\nDoes anyone know a comprehensive list of similar sites, covering XML (and\nRDF etc) in non-English European languages?\n\nThere's also btw http://xmlhack.ru/ in Russian. Non-EU, but European in\nthe broader sense. See http://xmlhack.ru/topics/rdf/index.html for RDF\nsection, which is (mostly? all?) translated from http://xmlhack.com/list.php?cat=28\n\nI added xmlhack and xmlfr to http://www.w3.org/2001/sw/Europe/developers/\nrecently; would be good to collect up more such links, alongside\ntranslations etc... Pointers/suggestions welcomed...\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: xmlfr.org... and other nonenglish sites covering RDF/XML",
            "content": "Vangelis Vassiliadis has some Greek coverage, including an Introduction to\nS.W.  :\n\nhttp://www.semanticweb.gr\n\n\n---\nDanny Ayers\n<stuff> http://www.isacat.net </stuff>\n\nIdea maps for the Semantic Web\nhttp://ideagraph.net\n\n\n>-----Original Message-----\n>From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n>Behalf Of Dan Brickley\n>Sent: 15 September 2002 15:47\n>To: public-esw@w3.org\n>Subject: xmlfr.org... and other non-english sites covering RDF/XML?\n>\n>\n>\n>\n>\n>...has good coverage of XML, RDF etc. in French.\n>\n>for eg., http://xmlfr.org/actualites/tech/000418-000\n>\n>lots of hits for 'rdf':\n>http://xmlfr.org/chercher/htsearch.cgi?config=htdigv2&words=rdf\n>\n>I think some of the content might be translations of XMLHack articles.\n>\n>Does anyone know a comprehensive list of similar sites, covering XML (and\n>RDF etc) in non-English European languages?\n>\n>There's also btw http://xmlhack.ru/ in Russian. Non-EU, but European in\n>the broader sense. See http://xmlhack.ru/topics/rdf/index.html for RDF\n>section, which is (mostly? all?) translated from\n>http://xmlhack.com/list.php?cat=28\n>\n>I added xmlhack and xmlfr to http://www.w3.org/2001/sw/Europe/developers/\n>recently; would be good to collect up more such links, alongside\n>translations etc... Pointers/suggestions welcomed...\n>\n>Dan\n>\n\n\n\n"
        },
        {
            "subject": "article on web services (objects or xml endpoints)",
            "content": "Web Services: Objects or XML Endpoints?\nhttp://www.oreillynet.com/pub/a/dotnet/2002/09/03/webservices.html\n\nI'm working on the rdf/soap serialization report;\nhttp://www.w3.org/2001/sw/Europe/reports/xml_graph_serialization_report/\n(no interesting changes committed yet). I came across the above article\nand it struck a chord... Lots of SOAP/services intros give the impression\nSOAP is just for remote invocation on objects a la CORBA etc. My working\nhunch is that there's a role for RDF in explaining how to link that\nperspective (and SOAP Encoding) with the more message-oriented and XML\nSchema based style of interaction that seems to be winning out amongst Web\nService enthusiasts...\n\nAnyway, the above article seems worth a read regardless of RDF's role.\n\nDan\n\n\n\n"
        },
        {
            "subject": "SWAD Europe initial workshop",
            "content": "This is now <30 days away and we haven't announced it yet :)\n\nThe agenda on http://www.w3.org/2001/sw/Europe/events/200210-init/\nneeds expanding and the named people and responsibilities allocated.\n\nThere are >8 hours of slots to fill and we need to work out what the\nparticipants are going to get out of it, plus the preparation we\nshould do - handouts, talks, demos.\n\nCheers\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: SWAD Europe initial workshop",
            "content": "Yes, I am behind on this.\n\nI will try to have the workshop page updated today, and announce at least to\nRDF-IG mailing list.\n\nAnyone have other places where it should be announced? I think the technical\nstuff should be announced to the relevant bits of DC, but I hope the peole\nleading that part of the workshop will do it, since they are more likely to\nknow the right places and manners.\n\nChaals\n\nOn Mon, 16 Sep 2002, Dave Beckett wrote:\n\n>\n>\n>This is now <30 days away and we haven't announced it yet :)\n>\n>The agenda on http://www.w3.org/2001/sw/Europe/events/200210-init/\n>needs expanding and the named people and responsibilities allocated.\n>\n>There are >8 hours of slots to fill and we need to work out what the\n>participants are going to get out of it, plus the preparation we\n>should do - handouts, talks, demos.\n>\n>Cheers\n>\n>Dave\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Thinking behind the DC2002 worksho",
            "content": "At the request of danbri I am forwarding this excerpted stuff that covers the\nthinking, so it is archived and visible.\n\nchaals\n---------- Forwarded message ----------\nFrom Dan Brickley:\n[snip]\nCharles suggested we do a SWAD-Europe workshop during DC2002. Libby\nsuggested substring searching etc., so I was wondering whether we\nmight propose a SWAD-E workshop on the themes below\n[snip]\nDave Beckett wrote:\n[snip]\n> RDF has now been accepted in a variety of contexts, connecting\n> digital library, knowledge representation, weblog syndication,\n> commercial and open source applications.  Despite this, groups\n> seeking to use RDF face a number of hurdles.\n>\n> This paper outlines some deployment issues surrounding the\n> practical use of RDF, and proposes four implementation features as\n> priorities for RDF query and storage systems: (i) RDF schema\n> sub-property, (ii) phrase, substring and text searching on\n> literals, (iii) provenance tracking of RDF statements and (iv)\n> smarter aggregation algorithms (or 'smushing').\n>\n> We discuss each of these features, and relate them to the\n> practicalities of widescale Dublin Core deployment in the Semantic\n> Web.  We assert that when (i)-(iv) are implemented in widely\n> available RDF tools, the Semantic Web will be deployable.\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWAD Europe initial workshop",
            "content": "OK, the page has been updated.\n\nWe are trying to work out whether we need a registration system or can just\nget information from the folks running the DC conference - so we may put a\nregistration form up in a couple of days and ask peopleto fill it in.\n\nWe still need (IMHO) to know how the technical workshop will be distributed\nacross the several hours and two days available - just a couple of lines to\nput on the meeting page so people don't get the impression it is just a vague\ntalk-fest spread out over slots that were available.\n\nCheers\n\nChaals\n\nOn Mon, 16 Sep 2002, Charles McCathieNevile wrote:\n\n>\n>Yes, I am behind on this.\n>\n>I will try to have the workshop page updated today, and announce at least to\n>RDF-IG mailing list.\n>\n>Anyone have other places where it should be announced? I think the technical\n>stuff should be announced to the relevant bits of DC, but I hope the peole\n>leading that part of the workshop will do it, since they are more likely to\n>know the right places and manners.\n>\n>Chaals\n>\n>On Mon, 16 Sep 2002, Dave Beckett wrote:\n>\n>>\n>>\n>>This is now <30 days away and we haven't announced it yet :)\n>>\n>>The agenda on http://www.w3.org/2001/sw/Europe/events/200210-init/\n>>needs expanding and the named people and responsibilities allocated.\n>>\n>>There are >8 hours of slots to fill and we need to work out what the\n>>participants are going to get out of it, plus the preparation we\n>>should do - handouts, talks, demos.\n>>\n>>Cheers\n>>\n>>Dave\n>>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI\n 21 Mitchell street, FOOTSCRAY Vic 3011, Australia  fax(fr): +33 4 92 38 78 22\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Visit to MINDSWAP SemWeb group at UM",
            "content": "I arranged at short notice to visit Jim Hendlers' group at University\nof Maryland next week (most of this will be funded by a non-SWADE\nsource).  I forgot to report here that I got this arranged since I've\nbeen on holiday.\n\nThe group home page is http://www.mindswap.org/\n\nThe general idea was to do a bit of SWAD Europe <-> US coordination\nand networking but some more concrete things such as:\n\n  Update each other on what the respective projects and groups are doing.\n\n  Work on semantic web storage and data issues.  \n    This relates to SWADE WP 10 deliverable 10.3, starting 1 Oct and\n    includes updating the scalable storage and rdbms reports,\n    benchmarking stores and maybe collecting and sharing of semantic\n    web datasets.\n\n  Give a presentation to the UMD semweb class students.\n\n  Learn about Parka and DAML-S.\n\n  Help the UMD people working with Redland (my RDF system).\n\n  W3C semweb standards work (Jim co-chairs WebOnt, I'm on RDF Core).\n\n  Working out other common areas of work for the future.\n\n  Teaching the semantic web.\n\n  A bit of blueskying on what tools, data, documents are missing.\n\nplus possibly some other non semweb related stuff :)\n\nDave\n\n\n\n"
        },
        {
            "subject": "RE: SWAD(Europe) logo(s",
            "content": "Some more ideas : http://www.w3c.rl.ac.uk/SWAD/logos/logo_list.html\n\nMichael Wilson\nBusiness and Information Technology Department   tel: +44 (0)1235 44 6619\nCLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\nChilton, DIDCOT, Oxon, OX11 0QX, UK             \n\nWWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n\nThe contents of this email are sent in confidence for the use of the\nintended recipients only.  If you are not one of the intended recipients\ndo not take action on it or show it to anyone else, but return this\nemail to the sender and delete your copy of it\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "So far, for what it's worth, I like Michael's set the most.\n\nIn particular those colors:\n  http://www.w3c.rl.ac.uk/SWAD/logos/Image9.png\n\n(not sure if the RDF net in the middle of the stars was meant not to\nbe centered but I like it like that too)\n\n\n> \n> Some more ideas : http://www.w3c.rl.ac.uk/SWAD/logos/logo_list.html\n> \n> Michael Wilson\n> Business and Information Technology Department   tel: +44 (0)1235 44 6619\n> CLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\n> Chilton, DIDCOT, Oxon, OX11 0QX, UK             \n> \n> WWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n> \n> The contents of this email are sent in confidence for the use of the\n> intended recipients only.  If you are not one of the intended recipients\n> do not take action on it or show it to anyone else, but return this\n> email to the sender and delete your copy of it\n> \n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "Me too, same one as Daniel from Michael's page.\n\nDaniel Dardailler wrote:\n> So far, for what it's worth, I like Michael's set the most.\n> \n> In particular those colors:\n>   http://www.w3c.rl.ac.uk/SWAD/logos/Image9.png\n> \n> (not sure if the RDF net in the middle of the stars was meant not to\n> be centered but I like it like that too)\n> \n> \n> \n>>Some more ideas : http://www.w3c.rl.ac.uk/SWAD/logos/logo_list.html\n>>\n>>Michael Wilson\n>>Business and Information Technology Department   tel: +44 (0)1235 44 6619\n>>CLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\n>>Chilton, DIDCOT, Oxon, OX11 0QX, UK             \n>>\n>>WWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n>>\n>>The contents of this email are sent in confidence for the use of the\n>>intended recipients only.  If you are not one of the intended recipients\n>>do not take action on it or show it to anyone else, but return this\n>>email to the sender and delete your copy of it\n>>\n> \n> \n\n\n-- \nCoralie Mercier, W3C Europe admin manager        mailto:coralie@w3.org\nWorld Wide Web Consortium                            http://www.w3.org\nW3C / INRIA  -  2004 route des lucioles - 06560 Sophia Antipolis -  FR\nVoice: +33(0)492 387 590  Fax: +33(0)492 387 822 http://www.koalie.net\n\n\n\n"
        },
        {
            "subject": "RE: SWAD(Europe) logo(s",
            "content": "Me too - simple, easy to reproduce and interpret,\nand obviously related to project themes.\n\nB\n\n>  -----Original Message-----\n>  From: Coralie Mercier [mailto:coralie@w3.org]\n>  Sent: 18 September 2002 09:05\n>  To: danield@w3.org\n>  Cc: Wilson, MD (Michael); 'Charles McCathieNevile'; Dan Brickley;\n>  public-esw@w3.org\n>  Subject: Re: SWAD(-Europe) logo(s)\n>  \n>  \n>  \n>  Me too, same one as Daniel from Michael's page.\n>  \n>  Daniel Dardailler wrote:\n>  > So far, for what it's worth, I like Michael's set the most.\n>  > \n>  > In particular those colors:\n>  >   http://www.w3c.rl.ac.uk/SWAD/logos/Image9.png\n>  > \n>  > (not sure if the RDF net in the middle of the stars was \n>  meant not to\n>  > be centered but I like it like that too)\n>  > \n>  > \n>  > \n>  >>Some more ideas : http://www.w3c.rl.ac.uk/SWAD/logos/logo_list.html\n>  >>\n>  >>Michael Wilson\n>  >>Business and Information Technology Department   tel: +44 \n>  (0)1235 44 6619\n>  >>CLRC Rutherford Appleton Laboratory             fax: \n>  +44(0)1235 44 5831\n>  >>Chilton, DIDCOT, Oxon, OX11 0QX, UK             \n>  >>\n>  >>WWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n>  >>\n>  >>The contents of this email are sent in confidence for the \n>  use of the\n>  >>intended recipients only.  If you are not one of the \n>  intended recipients\n>  >>do not take action on it or show it to anyone else, but return this\n>  >>email to the sender and delete your copy of it\n>  >>\n>  > \n>  > \n>  \n>  \n>  -- \n>  Coralie Mercier, W3C Europe admin manager        \n>  mailto:coralie@w3.org\n>  World Wide Web Consortium                            \n>  http://www.w3.org\n>  W3C / INRIA  -  2004 route des lucioles - 06560 Sophia \n>  Antipolis -  FR\n>  Voice: +33(0)492 387 590  Fax: +33(0)492 387 822 \nhttp://www.koalie.net\n\n\n\n"
        },
        {
            "subject": "Face to Face meeting  agenda and other inf",
            "content": "Hi all, \n\nfurther information about the meeting on Monday.\n\n-----------------------------------------------------------------------------------------------------\nAgenda SWAD-Europe face-to-face meeting, Mon 23rd Sept, 10.00 - 16.30\n-----------------------------------------------------------------------------------------------------\n\nMeeting to be held in Conference Room 2, RAL, Didcot, Oxfordshire \n\n10.00 - 10.30 Coffee/Update from each partner, technical matters to return to \nin pm\n\n10.30 -11.00 Conferences and workshops \n\n11.00 - 11.30 Publicity  \n\n11.30 - 12.00 Management to include consortium agreement, reports etc.\n\n12.00 - 12.30 Communication - meetings, Web site \n\n12.30 - 13.30 Lunch\n\n13.30 - 14.00 Technical plan \n\n14.00 - 16.30 Further technical discussions on deliverables due (more coffee \nmid afternoon)\n\n------------------\nAttending\n------------------\n\nBrian Matthews, RAL\nMichael Wilson, RAL\nDan Brickley, W3C\nCharles McCathieNevile, W3C\nDave Reynolds, Hewlett Packard\nStephen Buswell, Stilo\nLibby Miller, ILRT\nKate Sharp, ILRT\n\n------------------\nGetting to RAL\n------------------\n\nRAL is located some 17 miles South of Oxford. The nearest railway station is \nDidcot Parkway, conveniently on the mainline from Bristol to London. There is a \npublic bus up to RAL (\"Harwell International Business Centre\"), but more \nconvenient to take a taxi, especially if there are more than one person \ntravelling; costs about ?12, takes about 15mins. \n\nBy car, the M4 is about 8 miles away, take the A34 North at the Newbury \njunction (J13), (or the A34 South from Oxford if coming from that way).   RAL \nis signposted off the A34. \n\nMaps available at: http://www.clrc.ac.uk/Activity/ACTIVITY=RALMaps\n\n----------------------------------------------------------\nInfo on wireless connectivity from Brian \n----------------------------------------------------------\n\nR1 CR02  has wireless available.  The user must use DHCP to get an IP\naddress. The address will be in the RAL DMZ to protect RAL  systems. There is \nno security on this network and for the user  who has a wireless  this should \njust work unless there is a problem with the wireless  network etc.\nIf anyone requires non-wireless connectivity, could they let me know in\nadvance <B.M.Matthews@rl.ac.uk> so I can make appropriate arrangements.\n\nILRT booked on to 8.15 train to Didcot from Bristol Temple Meads - if other \nBristol people want to join us! \n\nLunch will be provided by RAL.\n\nSee you on Monday, \n\nKate..\n\n----------------------\nKate Sharp\nProject Manager\nBiz/ed and SWAD Europe\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "DC2002 early bird registration deadline (fwd",
            "content": "---------- Forwarded message ----------\nDate: Wed, 18 Sep 2002 14:21:40 -0400\nFrom: \"Weibel,Stu\" <weibel@OCLC.ORG>\nTo: DC-GENERAL@JISCMAIL.AC.UK\nSubject: DC-2002 early bird registration deadline\n\nA reminder to those planning on attending DC-2002 in Florence:\n\nSaturday is the final day for early-bird registration (fees go up about 10%\nafter this date).\n\nFurther information about the program, accomodations, and registration can\nbe found at:\n\nhttp://www.bncf.net/dc2002/\n\nregards\n\nstu\n\nStuart Weibel\nExecutive Director\nDublin Core Metadata Initiative\nOCLC Office of Research\n+1 614 764 6081\nweibel@oclc.org\nhttp://dublincore.org\n\n\n\n"
        },
        {
            "subject": "(SeWeb) FP6IST Infoday in Luxembourg on Knowledge Techn. (fwd",
            "content": "for info.\n\n---------- Forwarded message ----------\nDate: Tue, 17 Sep 2002 09:43:52 +0200\nFrom: Hans-Georg.Stork@cec.eu.int\nTo: seweb-list@cs.vu.nl\nSubject: (SeWeb) FP6-IST Infoday in Luxembourg on Knowledge Techn.\n\nThe announcement of the FP6 Infoday(s) of 23-24 October is now online at\n\nhttp://www.cordis.lu/ist/ka3/news.htm\n\nThe event focuses on the Knowledge Technologies part of FP6-IST.\n\nRegards\nGeorge Stork\n\n\n\n"
        },
        {
            "subject": "please register: SWAD-Europe Semantic Web calendaring workshop           2002-1009, Bristol, U",
            "content": "We now have a registration page for this workshop: see\n\nhttp://www.w3.org/2001/sw/Europe/events/200210-cal/\nhttp://cgi.w3.org/Register/selectUser.pl?_w3c_meetingName=swad200210cal\n\nPlease register as soon as you can. I'll send a detailed agenda around\nlater this week.\n\nthanks\n\nLibby\n\n\nOn Fri, 16 Aug 2002, Libby Miller wrote:\n\n>\n>\n> Hi,\n>\n> As part of the SWAD-Europe project[1] we are holding a series of\n> developer workshops on various topics. The next workshop is going to be\n> about the Semantic Web and calendaring, and will be held in Bristol, UK\n> on 9th October 2002.\n>\n> I'd like to have an idea of some possible numbers for this, so if you\n> think you'd like to attend, please send me an email as soon as you can.\n> Feel free to pass this email on, although numbers will be limited.\n>\n> I think there's some very exciting work going on in calendaring at the\n> moment, and this will be an excellent opportunity to get some developers\n> from different projects together. The Semantic Web calendar work I've\n> seen spans the gap between research and useful tools, so it's an ideal\n> topic for 'Semantic Web 1.0'.\n>\n> The agenda isn't finalised yet, and will depend to an extent on the\n> interests of the particpants, but will include demonstrations and\n> calendar-specific RDF-related issues, including handling datatyping,\n> querying and processing of calendar data (for example by calculating\n> intervening dates beteen start and finish). Other topics could\n> also include security and privacy issues, practical strategies for\n> identifying the same event from different sources, and user interface\n> issues. If you'd like to attend and have preferences about the topics,\n> please mail this list.\n>\n> Here are a few urls of recent work:\n>\n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0000.html\n> http://lists.w3.org/Archives/Public/www-rdf-calendar/2002Jul/0001.html\n>\n> http://www.extrememarkup.com/extreme/2002/friday.asp\n> Generalized metadata in your Palm\n> Norman Walsh, Sun Microsystems\n> (Extreme Markup 2002)\n>\n> Mozilla calendar\n> http://groups.google.com/groups?dq=&hl=en&lr=&ie=UTF-8&safe=off&threadm=3D44D001.1050905%40mbox.com.au&prev=/groups%3Fhl%3Den%26lr%3D%26ie%3DUTF-8%26safe%3Doff%26group%3Dnetscape.public.mozilla.calendar\n>\n> Apple Ical\n> http://www.apple.com/ical/\n>\n> Calendaring is one of my particular interests within the SWAD-Europe\n> project, where we are using Semantic Web tools to manage the\n> administrative data within the project:\n>\n> http://www.w3.org/2001/sw/Europe/events/view/\n> http://www.w3.org/2001/sw/Europe/200207/rsscal/xslt-rss-events.html\n>\n> thanks\n>\n> Libby\n>\n> [1] http://www.w3.org/2001/sw/Europe/\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "EC expressions of interest for FP6  searchable databas",
            "content": "The database is here:\n\nhttp://eoi.cordis.lu/search_form.cfm\n(try searching for 'semantic web')\n\nIt's rather slow as it's searching 11,500 proposals.\n\nLibby\n\n---------- Forwarded message ----------\nDate: Wed, 25 Sep 2002 04:30:52 +0100 (WET DST)\nFrom: CORDIS-RAPIDUS <rapidus@cordis.lu>\nSubject: RAPIDUS Notification\n\nRAPIDUS brings you the following updates related to your defined search profile\n\nPlease do not reply to this message and send all your RAPIDUS related questions and comments to the CORDIS HelpDesk (helpdesk@cordis.lu).\n\nCORDIS Database: NEWS\n        Search name: WHAT\n        Search description: What's new on CORDIS\n-------------------------------------------------------------------\nCORDIS publishes project ideas from Europe's research community in\npreparation for FP6\n\nRecord Control Number : 18989\nDate : 2002-09-24\nCategory :  Programme implementation\nGeneral Information :\n  In March 2002, the European Commission launched an invitation to\nsubmit Expressions of interest (EoI)  for research actions under\nthe Sixth Framework programme's (FP6)  new thematic priorities. By\nthe deadline in June 2002, more than 11,500 proposals were received\nwhich will help the Commission in preparing work programmes as well\nas defining the scope of the first FP6 calls for proposals to be\npublished by the end of the year.\n\nCORDIS, the European Commission's Research and Development\nInformation Service, is publishing all the EoI (unless the\nsubmitters have requested otherwise) . A search feature enables a\nquick review of proposed projects. Each record provides contact\ndetails, an abstract on the project, details of which instrument is\napplicable and additional information.\n\nUsers can search and select proposed projects according to the\nthematic priorities, new instruments, countries or keywords. Ideas\nwere submitted by organisations from more than 50 countries and\nthere is a good distribution across the thematic priorities. The\ninformation is therefore a valuable basis for making contacts and\nreviewing readiness to use new instruments in FP6.\n\nCORDIS is supporting preparations for FP6. A fully fledged FP6\nservice will soon be available as well as a redesigned Partners\nservice. Both new sites will offer relevant information enabling\nthe user to keep abreast of the latest decisions, review ideas,\naccess documentation from the first calls and prepare for fruitful\ncollaboration.\n\nText :\n\nRemarks :\n\nData Source Provider : CIMS\nDocument Reference : Based on information from service provider\nProgramme Acronym : FRAMEWORK 6C, ERA\nSubject Index Codes : Information, Media, Policies, Legislation, Regulations\nContact Person : http://eoi.cordis.lu/search_form.cfm\n\n-------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "Visualisation worksho",
            "content": "Hi folks,\n\nAt this stage the next workshop we are planning is for late february, in\namsterdam, about the topic of visualising information.\n\nInteresting work that is related includes\n  Visual editors for RDF\n  converting data into visual form for easy comprehension\n  controlling the rendering for simpler presentation\n  accessibility of visualisation\n\namong other areas. Input to plannning is welcome at the moment - from\nappropriate dates (or impossible dates) do agenda items or desired outcomes.\n\nMore detail will be forthcoming shortly.\n\nCheers\n\nCharles\n\n\n\n"
        },
        {
            "subject": "Re: SWAD(Europe) logo(s",
            "content": "Hi folks,\n\nat the Project management meeting on Monday we chose a logo:\nhttp://www.w3c.rl.ac.uk/SWAD/logos/Image9.png\n\n(with the others that Michael proposed at\nhttp://www.w3c.rl.ac.uk/SWAD/logos/logo_list.html as alternatives...\n\nCheers, and thanks for everyone's input\n\nCharles\n\n\n\n"
        },
        {
            "subject": "wp5 notes on schema mappin",
            "content": "(recovered belatedly from my laptop; from a meeting at Stilo on Wp5)\n\n\nQuestions\n---------\n\nIs there a line between 'multi-namespace chaos' that RDF is good for, vs \nstatic, tightly controlled homogenous namesaces, where schema annotation stops making sense?\n\nIf you have a data model, how to get to yr concrete xml schema encoding, plus \nwhatever annotations are needed to get round trip? (wizard)\n\nsb \"writing schemas is quite difficult. People tend to think about instances and \nthen work backwards. People get started by creating instances and then \nreverse-engineering the schema.\"\ndb \"do they do it well?\" \ns \"not bad...\"\n\npurchase orders\n buyers, sellers, items\n a po has one or more items\n... this tells us nothing about what a po document tells us\n\nlooking at po\n\n...issue of metadata about the doc, header info etc., which \ntends to come at the beginning of the document considered as a\ntree, and mixes in with the 'data proper'.\n\n\nfrom po.xml\n  <purchaseOrder orderDate=\"1999-10-20\">\n  <shipTo country=\"US\">\n  <name>Alice Smith</name> \n  <street>123 Maple Street</street> \n  <city>Mill Valley</city> \n  <state>CA</state> \n  <zip>90952</zip> \n\n  </shipTo>\n\nif po.xml is an xml document, ie a member of class eg:PODoc, \nis shipTo an attribute/property of that thing, or of some other\nentity which the eg:PODoc describes?\n\nie. \n<rdf:Description rdf:about=\"po.xml\">\n <eg:shipTo>\n   <rdf:Description>\n     <eg:country>US</eg:country>\n      ....\n\n\n<rdf:Description rdf:about=\"po.xml\">\n <x:descriptionOf>\n <eg:PurchaseOrder>\n   <eg:shipTo>\n     <rdf:Description>\n       <eg:country>US</eg:country>\n        ....\n   </>\n\n\n\n\n[brian arrives]\n\n\nCan we write po.xsd po.dtd po.rng po.xtr\n...so that they hve the same 'extensions' ie pick out \nthe same xml docs as valid instances?\n\ngiven a dtd, can produce an xsd with the same class extension\n\nfor some xsds, can do reverse?\nq: namespace prefixes, for example.\n\nbrian: \n the class of classes you can describe within dtds is entirely \n contained within xsd.\n\ntaking anything in the dtd class you can do a purely syntactic \nchange to get the dtd equivalent. \nA mapping, \n\nD: dtd -> xsd\nsuch that\nL(d) = L(D(d))\n\n(L being legal extension / Language)\n\nbrian/s agrees\n\n\nS: xsd -> dtd\nsuch that \nL(s)  subsetof<  L(S(d))\n     &  forall d' in \n\n\nmapping such that set of xsd describable is ... of dtd\n\n\ncounter example: character Entities\n\n(see mathml, html for eg)\n\ncan we think of this as a preprocessing stage?\n\nxsd's view: you can have a dtd as well as a schema, for entity stuff\n\n\n\n\n<!ELEMENT eg:thing>\n\nwe can write an xml schema that accepts xmlns:eg \nbut it will also accept xmlns:eg2, so long as namespace URIs are\nsame.\n\nany document thats acceptable via a dtd, we can have a \nschema that generates exactly the same extension. (?except ns)\n\nS: if there are no namespaces in the dtd, we can generate a schema\nthat has exactly same extension.\n\n\n\n<n:a xmlns+:n=\"myurl\">\n  <n:b ...\n  </n:b>\n</n:a>\n\n\n<m:a xmlns+:n=\"myurl\">\n  <n:b ...\n  </n:b>\n</m:a>\n(or ommitting the ns decl)\n  \nAre these equal, equiv etc in any \nsense? \n\n(generate same psvi, for eg? or same infoset?)\n(xml c18n same?)\n\neg. ' vs \"\n\n\nhow far in this direction does xml canonicalisation go?\n(@@todo)\n\n'there is some strange sense in which these are the\nsame document. unfortunately you can write a \ndtd that accepts one and rejects the other'.\n\nDo these have the same PSVI?\nproblem: PSVI is tech specific to XML Schema.\nWe want something common across all xml document typing tech.?\n\nIs there some (XML 1.0+ns based) characterisation of the commonality\nbetween these two/three/etc documents?\n\nWhat is common across the whole space? \n\nPSVI is stated only as 'what happens for xml schemas', perhaps there\n should be a generalised statment of this, ie. that the above 2 egs\ngive the same canonicalised-in-some-sense representation.\n\n\nFrom an RDF perspective, we need to get from infosets to \na set of RDF statements about the world, and then ask\nwhether the two sets have the same truth conditions / make \nthe same claims about the world. Could one be false while the \ntrue... etc\n\n\n==========\n\n\nsticking with po.xml and po.xsd\n\nwe want to be able to _generate_ a sensible po.xsd\nbut starting from our uml/rdf/etc model\n\ntriples:\n\n(i) payload of the instance data as rdf statements\n(ii) rdf schema statements (implied by the instance data\n   (property, class skeletal definitions; that the domain includes ...)\n(iii) more statements, not implied by instance data, \n      that give domain/range for these properties\n(iv) statements about classes of xml document, eg. \n   a PODocType?\n\n\nIf we....\n\n - have an ontology/schema for purchase order world\n - have picked a schema language (XSD)\n - have picked a serialization strategy / xml writing convention \n   (eg. no atrtibutes, edges-encode-properties)\n - (anything else?)\n\n...what do we need before we can (auto)generate an XSD?\n\n- need to choose a root class (or is this arbitrary?)\n- need one root class from each disconnected segment...\n(because serializer could be serializing a disjoint graph)\n\nThe classse and properties may be disconnected at schema level\n...also\nThe individuals and relations may or may not be connected.\n\n\n\"although this is same as in rdf, someone looking at the \ninstance data may be puzzled if it 'starts in wrong place'\".\n\neg. if shipsTo has the PO xml-inside it.\n\nThe property/edge/element names encode assumptions about directedness, \nand about the use of the document.\n\nExample from Professional XML Schema book, re RDBMS mappings:\nch12 creating XML Schema from existing databases.\n\n...generate several different xml schemas from same data, for \ndifferent purposes.\n\nRDF selling pt: its an account of what all the instance data from\n these various instance formats have in common.\n\n<e:Document dc:title=\"...\">\n <e:author>\n  <e:Person foaf:name=\"Tim\">\n\n...this couples our serialisation strategy to choice of \nnamespace / vocab.\n\n<e:Document dc:title=\"...\">\n <e2:wrote x:map=\"inverse\">\n  <e:Person foaf:name=\"Tim\">\n\n...we're free (in princple) to do this. But its ugly \nand not typical colloquial XML.\n\nWe can say in OWL\n\n<rdf:Property rdf:about=\"http://example.com/e#author\">\n  <owl:inverse rdf:about=\"http://example.com/e2#wrote\"/>\n</rdf:Property>\n\n\nHypothesis: people create vocabulary (xml elements and hence implied \nRDF properties, if we take a naive mapping appropach)\n...where they start with classes they're more concerned about, and \nput inside their xml-encoded descriptions mentions of instances of \nless interesting-to-them classes.\nSo, a library might have Document at the top of the xml tree,\nwhich leads them to use an 'author' relation.\n\nA white pages directory, might start with people ,and have \na 'wrote' relation pointing to docs.\n\nThis relates to expected search strategies\n \n - do i look for papers written by ?\n or \n - documents about ?\n\n\n\n\nSerialization strategy depends on expected usage.\n\nWe're generating from RDF world, an annotated XSD which \nincludes hints, mapping rules, xslt etc that lets us get our \nRDF out again.\n\nWe could generate:\n\n<e:Document dc:title=\"...\">\n <e2:wrote x:map=\"inverse\">\n  <e:Person foaf:name=\"Tim\">\n\nor even (though evil)\n\n<e:Document dc:title=\"...\">\n <e2:wrote>\n  <e:Person foaf:name=\"Tim\">\n\n\nor \n <e2:wrote>\n <e:Book foaf:name=\"Timetable\">\n <e:Person foaf:name=\"Tim\">\n </e2:wrote>\n\nor\n\n <e2:wrote>\n <e:Person foaf:name=\"Tim\">\n <e:Book foaf:name=\"Timetable\">\n </e2:wrote>\n\n <s:claim>\n <e2:wrote/>\n <e:Person foaf:name=\"Tim\">\n <e:Book foaf:name=\"Timetable\">\n </s:claim>\n <!-- polish form -->\n\n\n <s:claim>\n <s:rel reluri=\"e2:wrote\"/>\n <e:Person foaf:name=\"Tim\">\n <e:Book foaf:name=\"Timetable\">\n </s:claim>\n\n <rdf:Statement>\n  <rdf:predicate rdf:resource=\"http://example.com/e#wrote\"/>\n   <!-- ... -->\n  </rdf:Statement>\n\n\nOpenMath adopts a similar very generalised style.\n\n <s:claim>\n <s:rel reluri=\"e2:wrote\"/>\n  <s:obj objuri=\"e:Person\" foaf:name=\"Tim\"/>\n </s:claim>\n\n...things become very regular, and data is pushed into \ncontent rather than markup.\n\nSimilar strategy seen in RDF SQL triplestores, where\nthe anticipated schema becomes general, and the content\ndoes all the work.\n\n\"Deep embedding\"\n\n\n\n\n\nLooking at Henry's work:\n\nQ: how tied to XML Schema is this? eg. need for PSVI... maps on types as well as \nelements and attributes.\n\nQ for Henry: in po-mapped.xml why \n- <ns_2:shipTo xmlns:ns_2=\"\" country=\"US\" map:item-to=\"property\" map:item-name=\"\" map:minOccurs=\"\" map:maxOccurs=\"\" map:type-to=\"\" map:type-name=\"{}type.Address.1096\">\n...is country still an attribute, not normlaised \n\n\nRe the generated Java, what's the purpose?  Why aren't property names apparent?\nWhy not use Java classes more explicitly?\n\n\nWhat's the value of creating mapping to java objects, versus using Java interfaces \nto the original data, XML (SAX, DOM), RDF etc?\n\nComparison: SOAP serializers that dump Java OO stuff into XML (-> WP5)\n\nnotes: Schema Adjunct can map to SQL...\n\n\n\nNExt steps:\n\nmake the report page into a table of contents. Separate docs for dan, brian, stephen\n\naim to release draft for review in 2 weeks time.\n\nNext meeting: feb 13th, review and publish meeting. Stilo 10.15am 2003-02-13.\n\n\nPossible Stilo staff: Steve Healey\n\n\nExamples / test data:\n\n - PO and other Edinburgh stuff (quicken?)\n - Doc/Person/wrote example + illustration (also bibliography/RAL)\n - Wine ontology simple egs. (8 line DTD)\n - projects/people/docs\n\nmore real world examples:\n - danbri: wsdl, rss, calendar (ongoing not per feb deadline)\n - ral: cerif (common euro research info format sql/xml and rdf reps)\n \n\n\n  \n\n\n\n"
        },
        {
            "subject": "wp5 notes on schema mappin",
            "content": "(recovered belatedly from my laptop; from a meeting at Stilo on Wp5)\n\n\nQuestions\n---------\n\nIs there a line between 'multi-namespace chaos' that RDF is good for, vs \nstatic, tightly controlled homogenous namesaces, where schema annotation stops making sense?\n\nIf you have a data model, how to get to yr concrete xml schema encoding, plus \nwhatever annotations are needed to get round trip? (wizard)\n\nsb \"writing schemas is quite difficult. People tend to think about instances and \nthen work backwards. People get started by creating instances and then \nreverse-engineering the schema.\"\ndb \"do they do it well?\" \ns \"not bad...\"\n\npurchase orders\n buyers, sellers, items\n a po has one or more items\n... this tells us nothing about what a po document tells us\n\nlooking at po\n\n...issue of metadata about the doc, header info etc., which \ntends to come at the beginning of the document considered as a\ntree, and mixes in with the 'data proper'.\n\n\nfrom po.xml\n  <purchaseOrder orderDate=\"1999-10-20\">\n  <shipTo country=\"US\">\n  <name>Alice Smith</name> \n  <street>123 Maple Street</street> \n  <city>Mill Valley</city> \n  <state>CA</state> \n  <zip>90952</zip> \n\n  </shipTo>\n\nif po.xml is an xml document, ie a member of class eg:PODoc, \nis shipTo an attribute/property of that thing, or of some other\nentity which the eg:PODoc describes?\n\nie. \n<rdf:Description rdf:about=\"po.xml\">\n <eg:shipTo>\n   <rdf:Description>\n     <eg:country>US</eg:country>\n      ....\n\n\n<rdf:Description rdf:about=\"po.xml\">\n <x:descriptionOf>\n <eg:PurchaseOrder>\n   <eg:shipTo>\n     <rdf:Description>\n       <eg:country>US</eg:country>\n        ....\n   </>\n\n\n\n\n[brian arrives]\n\n\nCan we write po.xsd po.dtd po.rng po.xtr\n...so that they hve the same 'extensions' ie pick out \nthe same xml docs as valid instances?\n\ngiven a dtd, can produce an xsd with the same class extension\n\nfor some xsds, can do reverse?\nq: namespace prefixes, for example.\n\nbrian: \n the class of classes you can describe within dtds is entirely \n contained within xsd.\n\ntaking anything in the dtd class you can do a purely syntactic \nchange to get the dtd equivalent. \nA mapping, \n\nD: dtd -> xsd\nsuch that\nL(d) = L(D(d))\n\n(L being legal extension / Language)\n\nbrian/s agrees\n\n\nS: xsd -> dtd\nsuch that \nL(s)  subsetof<  L(S(d))\n     &  forall d' in \n\n\nmapping such that set of xsd describable is ... of dtd\n\n\ncounter example: character Entities\n\n(see mathml, html for eg)\n\ncan we think of this as a preprocessing stage?\n\nxsd's view: you can have a dtd as well as a schema, for entity stuff\n\n\n\n\n<!ELEMENT eg:thing>\n\nwe can write an xml schema that accepts xmlns:eg \nbut it will also accept xmlns:eg2, so long as namespace URIs are\nsame.\n\nany document thats acceptable via a dtd, we can have a \nschema that generates exactly the same extension. (?except ns)\n\nS: if there are no namespaces in the dtd, we can generate a schema\nthat has exactly same extension.\n\n\n\n<n:a xmlns+:n=\"myurl\">\n  <n:b ...\n  </n:b>\n</n:a>\n\n\n<m:a xmlns+:n=\"myurl\">\n  <n:b ...\n  </n:b>\n</m:a>\n(or ommitting the ns decl)\n  \nAre these equal, equiv etc in any \nsense? \n\n(generate same psvi, for eg? or same infoset?)\n(xml c18n same?)\n\neg. ' vs \"\n\n\nhow far in this direction does xml canonicalisation go?\n(@@todo)\n\n'there is some strange sense in which these are the\nsame document. unfortunately you can write a \ndtd that accepts one and rejects the other'.\n\nDo these have the same PSVI?\nproblem: PSVI is tech specific to XML Schema.\nWe want something common across all xml document typing tech.?\n\nIs there some (XML 1.0+ns based) characterisation of the commonality\nbetween these two/three/etc documents?\n\nWhat is common across the whole space? \n\nPSVI is stated only as 'what happens for xml schemas', perhaps there\n should be a generalised statment of this, ie. that the above 2 egs\ngive the same canonicalised-in-some-sense representation.\n\n\nFrom an RDF perspective, we need to get from infosets to \na set of RDF statements about the world, and then ask\nwhether the two sets have the same truth conditions / make \nthe same claims about the world. Could one be false while the \ntrue... etc\n\n\n==========\n\n\nsticking with po.xml and po.xsd\n\nwe want to be able to _generate_ a sensible po.xsd\nbut starting from our uml/rdf/etc model\n\ntriples:\n\n(i) payload of the instance data as rdf statements\n(ii) rdf schema statements (implied by the instance data\n   (property, class skeletal definitions; that the domain includes ...)\n(iii) more statements, not implied by instance data, \n      that give domain/range for these properties\n(iv) statements about classes of xml document, eg. \n   a PODocType?\n\n\nIf we....\n\n - have an ontology/schema for purchase order world\n - have picked a schema language (XSD)\n - have picked a serialization strategy / xml writing convention \n   (eg. no atrtibutes, edges-encode-properties)\n - (anything else?)\n\n...what do we need before we can (auto)generate an XSD?\n\n- need to choose a root class (or is this arbitrary?)\n- need one root class from each disconnected segment...\n(because serializer could be serializing a disjoint graph)\n\nThe classse and properties may be disconnected at schema level\n...also\nThe individuals and relations may or may not be connected.\n\n\n\"although this is same as in rdf, someone looking at the \ninstance data may be puzzled if it 'starts in wrong place'\".\n\neg. if shipsTo has the PO xml-inside it.\n\nThe property/edge/element names encode assumptions about directedness, \nand about the use of the document.\n\nExample from Professional XML Schema book, re RDBMS mappings:\nch12 creating XML Schema from existing databases.\n\n...generate several different xml schemas from same data, for \ndifferent purposes.\n\nRDF selling pt: its an account of what all the instance data from\n these various instance formats have in common.\n\n<e:Document dc:title=\"...\">\n <e:author>\n  <e:Person foaf:name=\"Tim\">\n\n...this couples our serialisation strategy to choice of \nnamespace / vocab.\n\n<e:Document dc:title=\"...\">\n <e2:wrote x:map=\"inverse\">\n  <e:Person foaf:name=\"Tim\">\n\n...we're free (in princple) to do this. But its ugly \nand not typical colloquial XML.\n\nWe can say in OWL\n\n<rdf:Property rdf:about=\"http://example.com/e#author\">\n  <owl:inverse rdf:about=\"http://example.com/e2#wrote\"/>\n</rdf:Property>\n\n\nHypothesis: people create vocabulary (xml elements and hence implied \nRDF properties, if we take a naive mapping appropach)\n...where they start with classes they're more concerned about, and \nput inside their xml-encoded descriptions mentions of instances of \nless interesting-to-them classes.\nSo, a library might have Document at the top of the xml tree,\nwhich leads them to use an 'author' relation.\n\nA white pages directory, might start with people ,and have \na 'wrote' relation pointing to docs.\n\nThis relates to expected search strategies\n \n - do i look for papers written by ?\n or \n - documents about ?\n\n\n\n\nSerialization strategy depends on expected usage.\n\nWe're generating from RDF world, an annotated XSD which \nincludes hints, mapping rules, xslt etc that lets us get our \nRDF out again.\n\nWe could generate:\n\n<e:Document dc:title=\"...\">\n <e2:wrote x:map=\"inverse\">\n  <e:Person foaf:name=\"Tim\">\n\nor even (though evil)\n\n<e:Document dc:title=\"...\">\n <e2:wrote>\n  <e:Person foaf:name=\"Tim\">\n\n\nor \n <e2:wrote>\n <e:Book foaf:name=\"Timetable\">\n <e:Person foaf:name=\"Tim\">\n </e2:wrote>\n\nor\n\n <e2:wrote>\n <e:Person foaf:name=\"Tim\">\n <e:Book foaf:name=\"Timetable\">\n </e2:wrote>\n\n <s:claim>\n <e2:wrote/>\n <e:Person foaf:name=\"Tim\">\n <e:Book foaf:name=\"Timetable\">\n </s:claim>\n <!-- polish form -->\n\n\n <s:claim>\n <s:rel reluri=\"e2:wrote\"/>\n <e:Person foaf:name=\"Tim\">\n <e:Book foaf:name=\"Timetable\">\n </s:claim>\n\n <rdf:Statement>\n  <rdf:predicate rdf:resource=\"http://example.com/e#wrote\"/>\n   <!-- ... -->\n  </rdf:Statement>\n\n\nOpenMath adopts a similar very generalised style.\n\n <s:claim>\n <s:rel reluri=\"e2:wrote\"/>\n  <s:obj objuri=\"e:Person\" foaf:name=\"Tim\"/>\n </s:claim>\n\n...things become very regular, and data is pushed into \ncontent rather than markup.\n\nSimilar strategy seen in RDF SQL triplestores, where\nthe anticipated schema becomes general, and the content\ndoes all the work.\n\n\"Deep embedding\"\n\n\n\n\n\nLooking at Henry's work:\n\nQ: how tied to XML Schema is this? eg. need for PSVI... maps on types as well as \nelements and attributes.\n\nQ for Henry: in po-mapped.xml why \n- <ns_2:shipTo xmlns:ns_2=\"\" country=\"US\" map:item-to=\"property\" map:item-name=\"\" map:minOccurs=\"\" map:maxOccurs=\"\" map:type-to=\"\" map:type-name=\"{}type.Address.1096\">\n...is country still an attribute, not normlaised \n\n\nRe the generated Java, what's the purpose?  Why aren't property names apparent?\nWhy not use Java classes more explicitly?\n\n\nWhat's the value of creating mapping to java objects, versus using Java interfaces \nto the original data, XML (SAX, DOM), RDF etc?\n\nComparison: SOAP serializers that dump Java OO stuff into XML (-> WP5)\n\nnotes: Schema Adjunct can map to SQL...\n\n\n\nNExt steps:\n\nmake the report page into a table of contents. Separate docs for dan, brian, stephen\n\naim to release draft for review in 2 weeks time.\n\nNext meeting: feb 13th, review and publish meeting. Stilo 10.15am 2003-02-13.\n\n\nPossible Stilo staff: Steve Healey\n\n\nExamples / test data:\n\n - PO and other Edinburgh stuff (quicken?)\n - Doc/Person/wrote example + illustration (also bibliography/RAL)\n - Wine ontology simple egs. (8 line DTD)\n - projects/people/docs\n\nmore real world examples:\n - danbri: wsdl, rss, calendar (ongoing not per feb deadline)\n - ral: cerif (common euro research info format sql/xml and rdf reps)\n \n\n\n  \n\n\n\n"
        },
        {
            "subject": "RE: IBIS vocab for sembloggin",
            "content": "ps.\n\nThere's also ThreadsML which appears to have led to a proposed RSS module\nwith one element:\n\n<item> Element:\n<thr:children> ( rdf:Seq )\n\nSome familiar names involved in this around a year ago, but it looks like it\nmay have fizzled out.\n\n(if you hear anymore about this, please let me know)\n\nhttp://web.resource.org/rss/1.0/modules/threading/\n\nhttp://www.quicktopic.com/7/H/rhSrjkWgjnvRq?m1=66&mN=66\n\nCheers,\nDanny.\n\n\n\n> -----Original Message-----\n> From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n> Behalf Of Danny Ayers\n> Sent: 27 March 2003 17:46\n> To: Cayzer, Steve; 'Charles McCathieNevile'\n> Cc: Esw\n> Subject: RE: IBIS vocab for semblogging\n>\n>\n>\n> Hi Steve,\n>\n> > Our take on this was that Claimaker dealt primarily with\n> concepts (not the\n> > papers themselves).\n>\n> I'm not sure, if the subject of a statement is (the URI of) a paper, then\n> presumably that's what's been talked about.\n>\n> Anyhow, the closest thing I'm aware of to what you describe is David\n> Menendez's Thread Description Language [1] :\n>\n> [1] http://www.eyrie.org/~zednenem/2002/web-threads/\n>\n> My main criticism of this would be that it tries too hard to do everything\n> itself, rather than reusing terms from other schema (like Annotea and\n> probably DC). But it does include agreesWith etc.\n>\n> Note that my IBIS vocab isn't set in stone, and suggestions are still\n> welcome ;-)\n>\n> Cheers,\n> Danny.\n>\n> > -----Original Message-----\n> > From: Cayzer, Steve [mailto:Steve_Cayzer@hplb.hpl.hp.com]\n> > Sent: 27 March 2003 16:28\n> > To: 'Charles McCathieNevile'; Danny Ayers\n> > Cc: Esw\n> > Subject: RE: IBIS vocab for semblogging\n> >\n> >\n> > To resurrect an old thread...\n> >\n> > We've started looking at ontologies for 'semantic links'. We\n> had a look at\n> > IBIS, Annotea threads and Claimaker.\n> > Our requirement is to be able to link bibliographic blogs -\n> > primarily using\n> > 'agreesWith', 'disagreesWith'.\n> >\n> > Our take on this was that Claimaker dealt primarily with\n> concepts (not the\n> > papers themselves). IBIS appears to me to take a similar line,\n> > making useful\n> > simplifications to the Claimaker model. These approaches are\n> both good for\n> > 'argumentation networks'.\n> >\n> > For dealing with the items themselves (which is what we want to\n> > do), Annotea\n> > threads offer quite a useful schema. Not a perfect fit to our\n> > domain, since\n> > we are not dealing with threaded discussions, and we might want\n> to extend\n> > the schema to different semantic relationships. But certainly\n> > good enough to\n> > start with. So we are looking to make threads a pluggable version of our\n> > semantic ontology.\n> >\n> > The reason for this rambling mail is to ask whether Danny,\n> > Charles or anyone\n> > else on the list is aware of, or would recommend, any other\n> ontologies for\n> > encoding such semantic links.\n> >\n> > Cheers\n> >\n> > Steve\n> >\n> > -----Original Message-----\n> > From: Charles McCathieNevile [mailto:charles@w3.org]\n> > Sent: 18 January 2003 21:45\n> > To: Danny Ayers\n> > Cc: Esw\n> > Subject: Re: IBIS vocab for semblogging\n> >\n> >\n> >\n> > Hi Danny,\n> >\n> > the vocabulary stuff you are looking at sounds like it is extending\n> > the thread vocabulary produced for Annotea (or for that matter\n> > the original\n> > Annotea vocabulary of annotation types) to allow for discussion threads\n> > to be tracked. This seems to me like a good idea.\n> >\n> > http://www.w3.org/2001/03/thread\n> >\n> > The ability to provide user-friendly interfaces for this (such as the\n> > icon-selection that Amaya has for marking different types of\n> annotation -\n> > see\n> > the help file at\n> >\nhttp://www.w3.org/Amaya/User/attaching_annotations/configuring_icons) is a\n> promising paralell for the use of graphic RDF editors (IdeaGraph, IsaViz,\n> RDFAuthor, etc)\n>\n> cheers\n>\n> Chaals\n>\n> On Fri, 17 Jan 2003, Danny Ayers wrote:\n>\n> >\n> >I didn't realise Semantic Blogging was being followed up as an e-sw case\n> >study, until I found the link on the new blog...\n> >\n> >Anyhow, one of the apps I've been working on for my Ideagraph project is\n> >semantic blogging and to help with this I've started writing up a\n> vocabulary\n> >(RDFS) for 'Issue-Based Information Systems', the idea being to use terms\n> >like 'Argument', 'Question', 'pro', 'con' within blog (and other)\n> discussion\n> >threads.\n> >\n> >http://purl.org/ibis\n> >\n> >Very much a work in progress, suggestions welcome.\n> >\n> >Cheers,\n> >Danny.\n> >\n> >-----------\n> >\n> >http://dannyayers.com\n> >\n> >\"The lyf so short, the craft so long to lerne.\" - Chaucer\n> >\n> >\n> >\n>\n> --\n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134\n> 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33\n> 4 92 38 78\n> 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope publicity: postcard idea",
            "content": "Following from our discussions at the swad-e project meeting, here is\na draft document which has some examples of geographical markup in it:\n\nhttp://www.w3.org/2001/sw/Europe/200303/geo/intro.html\n\ncomments are welcome, preferably to this list.\n\nHere's the link to what we might do with the data for the postcard (and\nsome related work):\n\nhttp://esw.w3.org/topic/EswWp3\n\ncheers\n\nLibby\n\n\nOn Wed, 19 Mar 2003, Libby Miller wrote:\n\n>\n> Hi all\n>\n> We would like to have some SWAD-E publicity materials ready for\n> WWW2003 (late May) and if possible XMLEurope (early May).\n>\n> Given the short time span, I propose something simple such as a\n> postcard. We have used these effectively for publicity at the ILRT, and\n> they would  be relatively quick to produce. In addition they would point\n> straight back to the webste, where we can explain in more detail the\n> content of the project and the Semantic web.\n>\n> Here's an example postcard from 234car, which came from the publicity\n> firm that we use at ILRT:\n>\n> http://www.234car.com/Bristol_postcard_v2.pdf\n>\n> on the reverse there is a short piece of text, perhaps as long in total\n> as the WAI Quick Tips\n>\n> http://www.w3.org/WAI/References/tips.gif\n> http://www.w3.org/WAI/References/QuickTips/\n>\n> If we decided to go this route we would need to think of a picture and\n> some text. The 234car picture is auto generated and shows starting\n> points for car sharing. Something along those lines would be nice I\n> think.\n>\n> What does everyone think? is it a good idea? any ideas for pictures,\n> text?\n>\n> cheers\n>\n> Libby\n>\n>\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "'announce-omatic' / conference announcement tracker, quick writeu",
            "content": "(copying the public SWAD-E list...)\n\nCaroline,\n\nhttp://esw.w3.org/topic/AnnounceOMatic is a quick writeup of the project \nidea we were discussing earlier, ie. finding a better way to manage \nconference announcements to W3C developer mailing lists.\n\nI tried to list some of the questions we ought to be answering; there are\ndoubtless plenty of others. In particular, I'd like to look at prior work\non this, eg. whether any other groups are using iCalendar documents when \nannouncing conferences to mailing lists.\n\nI also linked to some work going on with the UK LTSN network, where they\naggregate (by hand, at each of several subject-specific centres) event \ndescriptions, and then disseminate these further as RSS feeds. \nHere's the economics one, for example:\nhttp://www.economics.ltsn.ac.uk/events/events.xml ...which is also a \ngood use case for GeoInfo / mapping markup, once we get that work a bit \nmore stable.\n\nNext steps? probably to think about a method for trawling through some \nchunk of recent www-rdf-* mailing list archives and summarising the kinds of\nevents we have seen announced, and using that to draft guidelines for people\nusing www-rdf-* for such announcements.\n\nhope this makes sense!\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: 'announce-omatic' / conference announcement tracker,   quick writeu",
            "content": "At 11:53 15/04/2003 -0400, Dan Brickley wrote:\n>Next steps? probably to think about a method for trawling through some\n>chunk of recent www-rdf-* mailing list archives and summarising the kinds of\n>events we have seen announced, and using that to draft guidelines for people\n>using www-rdf-* for such announcements.\n\nHey... it could be a list policy for www-rdf- lists:  no announcements \nunless in RDF ;-)\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\nPGP: 0FAA 69FF C083 000B A2E9  A131 01B9 1C7A DBCA CB5E\n\n\n\n"
        },
        {
            "subject": "Re: wp5 notes on schema mappin",
            "content": "At 03:59 02/04/2003 -0500, Dan Brickley wrote:\n>Examples / test data:\n>\n>  - Wine ontology simple egs. (8 line DTD)\n\nYou're probably already aware of this, but just in case...\n\nFWIW, one of the introductory papers on Description Logics uses wine for a \nseries of examples...\n\n   http://www.bell-labs.com/project/classic/papers/ClassTut/ClassTut.html\n\nis one instantiation.\n\nSome other pointers (incl OWL ontology) here:\n\n   http://lists.w3.org/Archives/Public/www-webont-wg/2003Mar/0034.html\n\n#g\n\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\nPGP: 0FAA 69FF C083 000B A2E9  A131 01B9 1C7A DBCA CB5E\n\n\n\n"
        },
        {
            "subject": "SWADEurope postcard pictur",
            "content": "hi all,\n\nAs outlined at the face to face meet, I've been working on methods of\ngetting coordinate information about the locations of Semantic web\nresearchers and groups. I wrote to the www-rdf-interest list asking for\ndata:\n\nhttp://lists.w3.org/Archives/Public/www-rdf-interest/2003Apr/0252.html\n\nso we'll have to see how that pans out. Please do add yourselves if\nyou've not already there (I just did a few as examples).\n\nThere are some SVG demos, developed from ones by Jim Ley, displaying the\ninformation we have already, which I constructed as examples:\n\nhttp://www.w3.org/2001/sw/Europe/200303/geo/intro.html#demos\n\nSo, now we have to decide on the map which we will use to overlay the\ndots on. We want something that will highlight Europe, especially since\non a world map, Europe is too small to really show up on provide the\nlevel of detail we require. At ILRT, Caroline Meek, Dan and I have had\ndiscussions with a designer, and he has pointed us at some examples, and\nwe've narrowed it down to two that we rather like:\n\nhttp://www.cadmium.co.uk/thumbs/brand%20x/maps%20and%20globes/t_bxp_c31027.jpg.jpg\n\nwhich has the advantage of showing Europe as part of the world (we could\nget rid of the arm of the globe that is showing, and alter the colours);\nand\n\nhttp://www.cadmium.co.uk/thumbs/ds/maps%20and%20globes/t_11407324.jpg.jpg\n\nwhich would be technically simpler to do, but shows Europe in isolation\n(I do like the colour scheme though).\n\nDo people have a preference for one style over the other?\n\nCould you let us know today if possible? We need to specify the map as\nsoon as possible in order to get postcards printed for www2003.\n\nthanks,\n\nLibby\n\np.s. Here's a nice similar idea:\n\nhttp://www.asemantics.net/showcase/zoom.html\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope postcard pictur",
            "content": "From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk] \n> Do people have a preference for one style over the other?\n> Could you let us know today if possible? We need to specify \n> the map as soon as possible in order to get postcards printed for www2003.\nCan't say I'm particularly grabbed by either of them, but if you have to\npick one I'd go for the map, not the globe.  Is there any reason it has to\nbe geographically accurate?  Perhaps a schematic, analogous to the London\nUnderground map of London, would allow you to convey the sense of spatial\ndistribution without getting hung up on the scale problem. Of course, you\nmay not consider that a helpful suggestion given the short timescale :-)\n\nCheers,\nIan\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope postcard pictur",
            "content": "* Dickinson, Ian J <Ian.Dickinson@hp.com> [2003-04-25 12:12+0100]\n> \n> From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk] \n> > Do people have a preference for one style over the other?\n> > Could you let us know today if possible? We need to specify \n> > the map as soon as possible in order to get postcards printed for www2003.\n> Can't say I'm particularly grabbed by either of them, but if you have to\n> pick one I'd go for the map, not the globe.  Is there any reason it has to\n> be geographically accurate?  Perhaps a schematic, analogous to the London\n> Underground map of London, would allow you to convey the sense of spatial\n> distribution without getting hung up on the scale problem. Of course, you\n> may not consider that a helpful suggestion given the short timescale :-)\n\nOne advantage of being geographically accurate is it simplifies our lives when we\ntry to plot SW researchers, groups, events etc on the map...\n\nI prefer the map to the globe, fwiw.\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope postcard pictur",
            "content": "yeah, sorry it's such a rush. It took a long time to write the\ndocument explaining how to write the RDF. At this stage we really need\nexamples to show the designer though - I'll pass your comments along to\nhim, see if he has anything like that.\n\nWhat don't you like about them in particular?\n\nthanks for the feedback\n\nLibby\n\nOn Fri, 25 Apr 2003, Dickinson, Ian J wrote:\n\n> From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n> > Do people have a preference for one style over the other?\n> > Could you let us know today if possible? We need to specify\n> > the map as soon as possible in order to get postcards printed for www2003.\n> Can't say I'm particularly grabbed by either of them, but if you have to\n> pick one I'd go for the map, not the globe.  Is there any reason it has to\n> be geographically accurate?  Perhaps a schematic, analogous to the London\n> Underground map of London, would allow you to convey the sense of spatial\n> distribution without getting hung up on the scale problem. Of course, you\n> may not consider that a helpful suggestion given the short timescale :-)\n>\n> Cheers,\n> Ian\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope postcard pictur",
            "content": "Hi Libby,\n> What don't you like about them in particular?\nThe globe is too visually busy for a background (imho), and if you decrease\nthe opacity I think you'll lose too much of the important bits (like where\nthe UK is :-).   The map would be OK as a backdrop for the FOAF map if it\nwas semi-opaque, but (a) it misses out the rest of the world, as you said\nyourself, and (b) there's a big blue empty space on the left :-).  The\natlantic is just too big** if you keep it to scale, hence my suggestion to\nuse more of a schematic approach.  I guess you need the cartographical\nequivalent of an ellipsis, whatever that might be!\n\nCheers,\nIan\n\n** qv \"[the judge] ruled that the guilty party was 'life itself' for failing\nto be either beautiful or true\" [hhgtg] \n\n\n\n"
        },
        {
            "subject": "FW: Semantic blogging demonstrator now liv",
            "content": "Hi All, \n\njust a quick note to let you know that the semantic blogging demonstrator is\nnow live.\nI have 2 blogs of interest\n\n[1] is an external blog, intended to act pretty much like a normal blog for\nthe project.\n[2] is the demonstrator, onto which semantic blogging capabilities will be\nadded as they come online.\n\nRight at the moment, neither blog is terribly 'semantic' (although you can\nview the metadata behind each entry) but I wanted to get the baseline public\nasap.\n\nI'm currently writing an overall design document which I'll post separately.\n\nComments welcome, to me, to the list or to the blog, whatever seems\nappropriate.\n\nCheers\n\nSteve\n\n[1] http://jena.hpl.hp.com:3030/blojsom-hp/blog/\n[2] http://jena.hpl.hp.com:3030/blojsom-devt/blog/\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope postcard pictur",
            "content": "thanks Ian. I broadly agree with you. For (b) though, that might work in\nour favour, as we can put a logo and/or a slogan there.\n\nLibby\n\nOn Fri, 25 Apr 2003, Dickinson, Ian J wrote:\n\n> Hi Libby,\n> > What don't you like about them in particular?\n> The globe is too visually busy for a background (imho), and if you decrease\n> the opacity I think you'll lose too much of the important bits (like where\n> the UK is :-).   The map would be OK as a backdrop for the FOAF map if it\n> was semi-opaque, but (a) it misses out the rest of the world, as you said\n> yourself, and (b) there's a big blue empty space on the left :-).  The\n> atlantic is just too big** if you keep it to scale, hence my suggestion to\n> use more of a schematic approach.  I guess you need the cartographical\n> equivalent of an ellipsis, whatever that might be!\n>\n> Cheers,\n> Ian\n>\n> ** qv \"[the judge] ruled that the guilty party was 'life itself' for failing\n> to be either beautiful or true\" [hhgtg]\n>\n>\n\n\n\n"
        },
        {
            "subject": "A new image annotation too",
            "content": "This doesn't use Annotea, but instead extends the approach to annotating\nimages used by RDFPic.\n\nAn offering from Norm Walsh that provides tools for adding information to\njpeg images.\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Recommendations for *nontechnical* introductions to Semantic Web (and RDF/XML) ",
            "content": "(copying swad-europe list)\n\nHi\n\nI'm looking for existing non-technical intro materials on Semantic Web \nand RDF/XML, ie. that doesn't assume one knows what XML or RDF is \nor for that matter what the Web/Internet is, except largely in \nterms of user experience. They could assume some experience with HTML and\nURLs and Web browsers and search engines...\n\nSo I was thinking about this last week, and the odd combination of \nthe following popped into my head as a 'reading list' / backgrounder:\n\nTimBL's book([1]), since the SW project is just a natural continuation of\nthe Web project. The Berners-Lee/Hendler/Lassila Scientific American \narticle (although it does geek out a bit towards the end). I also found \nPaul Ford's \"August 2009: How Google beat Amazon and Ebay to the Semantic Web\" \nstrangely charming, v usefully couched more in terms of user experience and \nbusiness case than in terms of technology. Similarly I picked the \n\" Statement on the Intent and Use of PICS: Using PICS Well\"[4] as background on \nthe pluralistic policy context behind SW and the RDF design, even though it \ndoesn't mention the Semantic Web at all.\n\nThis list is of course not intended to be complete. But rather than going on \nI'd rather hear what other folks here are using and recommending. Remember \nI'm looking for non-geeky stuff, so things like the (imho excellent) \nRDF Primer[5] are probably out of scope, although the first couple of \nparagraphs from the Primer intro would be useful to excerpt for a non-technical\nreading list. Similarly, if there are other technical works out there \nwith non-tech sections worth noting, I'd be interested to see them listed.\n\nIf people have any docs or other materials to mention I'll summarise any \nfollowups to this thread in the ESW Wiki somewhere([6]), and hopefully we \ncan begin a compare and contrast on different strategies for introducing \nthe concept of the Semantic Web...\n\nthanks for any suggestions,\n\nDan\n\n\n\n[1] http://www.w3.org/People/Berners-Lee/Weaving/Overview.html\n[2] http://www.sciam.com/article.cfm?articleID=00048144-10D2-1C70-84A9809EC588EF21\n    http://www.sciam.com/print_version.cfm?articleID=00048144-10D2-1C70-84A9809EC588EF21\n[3] http://www.ftrain.com/google_takes_all.html\n    http://www.ftrain.com/google_semweb_commentary.html\n[4] http://www.w3.org/TR/NOTE-PICS-Statement\n[5] http://www.w3.org/TR/rdf-primer/\n[6] http://esw.w3.org/topic/FrontPage\n \n\n\n\n"
        },
        {
            "subject": "RE: Recommendations for *nontechnical* introductions to Semantic Web (and RDF/XML) ",
            "content": "My attempt at RDF in 500 words :\n\nhttp://dannyayers.com/docs/rdf500.htm\n\nI think the only tech assumption is that the reader has an idea what the web\nis.  I should really see if I can get rid of this dependency...\n\nCheers,\nDanny.\n\n> -----Original Message-----\n> From: www-rdf-interest-request@w3.org\n> [mailto:www-rdf-interest-request@w3.org]On Behalf Of Dan Brickley\n> Sent: 28 April 2003 13:08\n> To: www-rdf-interest@w3.org\n> Cc: public-esw@w3.org\n> Subject: Recommendations for *non-technical* introductions to Semantic\n> Web (and RDF/XML) ?\n>\n>\n>\n> (copying swad-europe list)\n>\n> Hi\n>\n> I'm looking for existing non-technical intro materials on Semantic Web\n> and RDF/XML, ie. that doesn't assume one knows what XML or RDF is\n> or for that matter what the Web/Internet is, except largely in\n> terms of user experience. They could assume some experience with HTML and\n> URLs and Web browsers and search engines...\n>\n> So I was thinking about this last week, and the odd combination of\n> the following popped into my head as a 'reading list' / backgrounder:\n>\n> TimBL's book([1]), since the SW project is just a natural continuation of\n> the Web project. The Berners-Lee/Hendler/Lassila Scientific American\n> article (although it does geek out a bit towards the end). I also found\n> Paul Ford's \"August 2009: How Google beat Amazon and Ebay to the\n> Semantic Web\"\n> strangely charming, v usefully couched more in terms of user\n> experience and\n> business case than in terms of technology. Similarly I picked the\n> \" Statement on the Intent and Use of PICS: Using PICS Well\"[4] as\n> background on\n> the pluralistic policy context behind SW and the RDF design, even\n> though it\n> doesn't mention the Semantic Web at all.\n>\n> This list is of course not intended to be complete. But rather\n> than going on\n> I'd rather hear what other folks here are using and recommending.\n> Remember\n> I'm looking for non-geeky stuff, so things like the (imho excellent)\n> RDF Primer[5] are probably out of scope, although the first couple of\n> paragraphs from the Primer intro would be useful to excerpt for a\n> non-technical\n> reading list. Similarly, if there are other technical works out there\n> with non-tech sections worth noting, I'd be interested to see them listed.\n>\n> If people have any docs or other materials to mention I'll summarise any\n> followups to this thread in the ESW Wiki somewhere([6]), and hopefully we\n> can begin a compare and contrast on different strategies for introducing\n> the concept of the Semantic Web...\n>\n> thanks for any suggestions,\n>\n> Dan\n>\n>\n>\n> [1] http://www.w3.org/People/Berners-Lee/Weaving/Overview.html\n> [2]\n> http://www.sciam.com/article.cfm?articleID=00048144-10D2-1C70-84A9\n809EC588EF21\n\nhttp://www.sciam.com/print_version.cfm?articleID=00048144-10D2-1C70-84A9809E\nC588EF21\n[3] http://www.ftrain.com/google_takes_all.html\n    http://www.ftrain.com/google_semweb_commentary.html\n[4] http://www.w3.org/TR/NOTE-PICS-Statement\n[5] http://www.w3.org/TR/rdf-primer/\n[6] http://esw.w3.org/topic/FrontPage\n\n\n\n"
        },
        {
            "subject": "Thesaurus Interchange Format proposed standar",
            "content": "A proposed standard for a Thesaurus Interchange Format (TIF) for the\nsemantic web is now online at:\n\nhttp://www.w3c.rl.ac.uk/SWAD/thesaurus/tif/tif.html\n\nWe hope now for some feedback from users.\n\n\nAlistair Miles.\n\n\n\n"
        },
        {
            "subject": "SWADEurope tshirt discussions continue",
            "content": "Liz has a design for the SWAD-Europe tshirts and will be on irc\n(irc.freenode.net #rdfig) at 11 GMT today to present it and chat about\nit, if you're interested.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope tshirt discussions continue",
            "content": "On Dec 5, 2003, at 11:30 AM, Libby Miller wrote:\n\n>\n>\n> Liz has a design for the SWAD-Europe tshirts and will be on irc\n> (irc.freenode.net #rdfig) at 11 GMT today to present it and chat about\n> it, if you're interested.\n\nsorry I missed that :(\n\nI had a look to the #rdfig weblog - the design looks cool and nice \ncolor too :)\n\nwell done!\n\njust a small comment on the back side of the t-shirt:\n\nhttp://liz.xtdnet.nl/swad/back_men.gif\n\nthe Italian phrasing should more correctly be instead:\n\n\"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n\nor you can use t-shirt instead of \"maglietta\" which is fine too\n\ncheers\n\nAlberto\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt discussions continue",
            "content": "I want two.\n\nno matter what is printed on the back.\n\n\nI wasn't there but we (SemWeb guys) are desperate to \"show flag\"\nabout SemWeb brains here in vienna !\n\n\nhope you can get them to us somehow :-)\n\n\ngreetings\nLeo & Michi\n\nwe paypal\n\n> -----Original Message-----\n> From: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] On Behalf Of Alberto Reggiori\n> Sent: Friday, December 05, 2003 1:09 PM\n> To: Libby Miller\n> Cc: public-esw@w3.org\n> Subject: Re: SWAD-Europe tshirt discussions continued\n> \n> \n> \n> \n> On Dec 5, 2003, at 11:30 AM, Libby Miller wrote:\n> \n> >\n> >\n> > Liz has a design for the SWAD-Europe tshirts and will be on irc\n> > (irc.freenode.net #rdfig) at 11 GMT today to present it and \n> chat about\n> > it, if you're interested.\n> \n> sorry I missed that :(\n> \n> I had a look to the #rdfig weblog - the design looks cool and nice \n> color too :)\n> \n> well done!\n> \n> just a small comment on the back side of the t-shirt:\n> \nhttp://liz.xtdnet.nl/swad/back_men.gif\n\nthe Italian phrasing should more correctly be instead:\n\n\"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n\nor you can use t-shirt instead of \"maglietta\" which is fine too\n\ncheers\n\nAlberto\n\n\n\n"
        },
        {
            "subject": "SWADEurope tshirt agai",
            "content": "hi all,\n\nLiz has some tshirt designs, detailed at:\n\nhttp://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n\nIf you'd like to comment on the design, please do so here, by the end of\nthis week.\n\nThe slogan on the front is not yet finalized - Dan is talking to his W3C\ncolleagues about it this week. He prefers the slogan\n\n\"We helped build the Semantic Web\"\n\n- as a more modest representation of the achievements of the project.\n\nOther suggestions welcome, although it needs to be six words to fit in\nwith the design.\n\nWe will also need to look into how many languages to put on the back\nand and who we can ask to check them for us (thanks Alberto! :)\n\nLiz was thinking of\n\nfrench\nspanish\nitalian\ngerman\ndutch\ngreek\nrussian\narabic\nchinese\njapanese\nhindi\n\nwith english at the bottom. We have the translation for Italian:\n\"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n\nI guess Max or Chaals could do French, Chaals also arabic maybe?\nPerhaps a W3C team member could help us with the Japanese. Liz has\nfriends who can do Dutch, maybe German and Russian. Eva could do Spanish\nfor us.\n\nThat leaves german(?) greek(?) russian(?) chinese and hindi. Plus any\nothers which we think should be in there (Hungarian? Ivan could do\nthat).\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "I'd very much like to get Arabic and Hebrew which can probably be done by\nthe W3C offices  in those countries - they are difficult since they read\nright to left; but they add to the international flavour of the thing.\nArabic without Hebrew could be seen as a political statement that W3C does\nnot wish to make.\n\nThere is also a Korean Office who can do Korean. There is somebody who\nnormally translates things into Russian for W3C - see the list\nw3c-translators@w3.org and the page listing them at\nhttp://www.w3.org/2003/03/Translations/Translators.html\n\nFor the Indian languages (Hindi etc) there are several people liste there.\n\nThere are other language translators listed there is you want to venture\ninto more exotic scripts.\n\nProf Michael Wilson\nManager, W3C Office in the UK and Ireland\nCCLRC Rutherford Appleton Laboratory\nChilton, Didcot, Oxon, OX11 0QX, UK\nhttp://www.bitd.clrc.ac.uk/Person/M.D.Wilson\nFax: +44 1235 445831\n\n\n-----Original Message-----\nFrom: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\nBehalf Of Libby Miller\nSent: 09 December 2003 15:42\nTo: public-esw@w3.org\nCc: liz@ephidrina.org\nSubject: SWAD-Europe tshirt again\n\n\n\n\nhi all,\n\nLiz has some tshirt designs, detailed at:\n\nhttp://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n\nIf you'd like to comment on the design, please do so here, by the end of\nthis week.\n\nThe slogan on the front is not yet finalized - Dan is talking to his W3C\ncolleagues about it this week. He prefers the slogan\n\n\"We helped build the Semantic Web\"\n\n- as a more modest representation of the achievements of the project.\n\nOther suggestions welcome, although it needs to be six words to fit in\nwith the design.\n\nWe will also need to look into how many languages to put on the back\nand and who we can ask to check them for us (thanks Alberto! :)\n\nLiz was thinking of\n\nfrench\nspanish\nitalian\ngerman\ndutch\ngreek\nrussian\narabic\nchinese\njapanese\nhindi\n\nwith english at the bottom. We have the translation for Italian:\n\"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n\nI guess Max or Chaals could do French, Chaals also arabic maybe?\nPerhaps a W3C team member could help us with the Japanese. Liz has\nfriends who can do Dutch, maybe German and Russian. Eva could do Spanish\nfor us.\n\nThat leaves german(?) greek(?) russian(?) chinese and hindi. Plus any\nothers which we think should be in there (Hungarian? Ivan could do\nthat).\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "Thanks Michael :)\n\nLibby\n\nOn Tue, 9 Dec 2003, Wilson, MD (Michael)  wrote:\n\n> I'd very much like to get Arabic and Hebrew which can probably be done by\n> the W3C offices  in those countries - they are difficult since they read\n> right to left; but they add to the international flavour of the thing.\n> Arabic without Hebrew could be seen as a political statement that W3C does\n> not wish to make.\n>\n> There is also a Korean Office who can do Korean. There is somebody who\n> normally translates things into Russian for W3C - see the list\n> w3c-translators@w3.org and the page listing them at\n> http://www.w3.org/2003/03/Translations/Translators.html\n>\n> For the Indian languages (Hindi etc) there are several people liste there.\n>\n> There are other language translators listed there is you want to venture\n> into more exotic scripts.\n>\n> Prof Michael Wilson\n> Manager, W3C Office in the UK and Ireland\n> CCLRC Rutherford Appleton Laboratory\n> Chilton, Didcot, Oxon, OX11 0QX, UK\n> http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n> Fax: +44 1235 445831\n>\n>\n> -----Original Message-----\n> From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n> Behalf Of Libby Miller\n> Sent: 09 December 2003 15:42\n> To: public-esw@w3.org\n> Cc: liz@ephidrina.org\n> Subject: SWAD-Europe tshirt again\n>\n>\n>\n>\n> hi all,\n>\n> Liz has some tshirt designs, detailed at:\n>\n> http://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n>\n> If you'd like to comment on the design, please do so here, by the end of\n> this week.\n>\n> The slogan on the front is not yet finalized - Dan is talking to his W3C\n> colleagues about it this week. He prefers the slogan\n>\n> \"We helped build the Semantic Web\"\n>\n> - as a more modest representation of the achievements of the project.\n>\n> Other suggestions welcome, although it needs to be six words to fit in\n> with the design.\n>\n> We will also need to look into how many languages to put on the back\n> and and who we can ask to check them for us (thanks Alberto! :)\n>\n> Liz was thinking of\n>\n> french\n> spanish\n> italian\n> german\n> dutch\n> greek\n> russian\n> arabic\n> chinese\n> japanese\n> hindi\n>\n> with english at the bottom. We have the translation for Italian:\n> \"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n>\n> I guess Max or Chaals could do French, Chaals also arabic maybe?\n> Perhaps a W3C team member could help us with the Japanese. Liz has\n> friends who can do Dutch, maybe German and Russian. Eva could do Spanish\n> for us.\n>\n> That leaves german(?) greek(?) russian(?) chinese and hindi. Plus any\n> others which we think should be in there (Hungarian? Ivan could do\n> that).\n>\n> cheers\n>\n> Libby\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope tshirt agai",
            "content": "I just chatted to Nikki and she said:\n\n* she likes the brains but the brain stems are a bit yucky in some cases\n* she wondered whether 'we' sort of implied everyone in the world, and\nmaybe it should be 'I'\n\nFor the record, I like the brains and the brainstems :)\n\nLibby\n\nOn Tue, 9 Dec 2003, Libby Miller wrote:\n\n>\n> hi all,\n>\n> Liz has some tshirt designs, detailed at:\n>\n> http://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n>\n> If you'd like to comment on the design, please do so here, by the end of\n> this week.\n>\n> The slogan on the front is not yet finalized - Dan is talking to his W3C\n> colleagues about it this week. He prefers the slogan\n>\n> \"We helped build the Semantic Web\"\n>\n> - as a more modest representation of the achievements of the project.\n>\n> Other suggestions welcome, although it needs to be six words to fit in\n> with the design.\n>\n> We will also need to look into how many languages to put on the back\n> and and who we can ask to check them for us (thanks Alberto! :)\n>\n> Liz was thinking of\n>\n> french\n> spanish\n> italian\n> german\n> dutch\n> greek\n> russian\n> arabic\n> chinese\n> japanese\n> hindi\n>\n> with english at the bottom. We have the translation for Italian:\n> \"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n>\n> I guess Max or Chaals could do French, Chaals also arabic maybe?\n> Perhaps a W3C team member could help us with the Japanese. Liz has\n> friends who can do Dutch, maybe German and Russian. Eva could do Spanish\n> for us.\n>\n> That leaves german(?) greek(?) russian(?) chinese and hindi. Plus any\n> others which we think should be in there (Hungarian? Ivan could do\n> that).\n>\n> cheers\n>\n> Libby\n>\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "I am Austrian, where we have German mother-tongue.\nThis is the better text:\n\n\"Und alles was wir bekamen war dieses dumme T-Shirt\"\n\nthe commas are not needed\n(\"bekamen\" instead of \"erhielten\", sounds better in german)\n\n\n\n\n\nagain:\nI want two ! I want two !\n\nfor me and michi.\n\ngreetings \nLeo\n\n> -----Original Message-----\n> From: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] On Behalf Of Libby Miller\n> Sent: Tuesday, December 09, 2003 4:38 PM\n> To: public-esw@w3.org\n> Cc: liz@ephidrina.org\n> Subject: SWAD-Europe tshirt again\n> \n> \n> \n> \n> hi all,\n> \n> Liz has some tshirt designs, detailed at:\n> \n> http://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n> \n> If you'd like to comment on the design, please do so here, by \n> the end of\n> this week.\n> \n> The slogan on the front is not yet finalized - Dan is talking \n> to his W3C\n> colleagues about it this week. He prefers the slogan\n> \n> \"We helped build the Semantic Web\"\n> \n> - as a more modest representation of the achievements of the project.\n> \n> Other suggestions welcome, although it needs to be six words to fit in\n> with the design.\n> \n> We will also need to look into how many languages to put on the back\n> and and who we can ask to check them for us (thanks Alberto! :)\n> \n> Liz was thinking of\n> \n> french\n> spanish\n> italian\n> german\n> dutch\n> greek\n> russian\n> arabic\n> chinese\n> japanese\n> hindi\n> \n> with english at the bottom. We have the translation for Italian:\n> \"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n> \n> I guess Max or Chaals could do French, Chaals also arabic maybe?\n> Perhaps a W3C team member could help us with the Japanese. Liz has\n> friends who can do Dutch, maybe German and Russian. Eva could \n> do Spanish\n> for us.\n> \n> That leaves german(?) greek(?) russian(?) chinese and hindi. Plus any\n> others which we think should be in there (Hungarian? Ivan could do\n> that).\n> \n> cheers\n> \n> Libby\n> \n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope tshirt agai",
            "content": "Libby Miller <Libby.Miller@bristol.ac.uk> wrote:\n>If you'd like to comment on the design, please do so here, by the end of\n>this week.\nLooks great to me, and I have no strong opinions on brain stems or\nslogan wording...\n\n>We will also need to look into how many languages to put on the back\n... but I of course have to suggest adding Danish to the list of\nlanguages. :)\n\nDanish version:\n\"og det eneste vi fik var denne dumme t-shirt\"\n(replace \"vi\" with \"jeg\" for \"I\" instead of \"we\".)\n\nIn any case, put me down for at least a couple.\n\n\n\nRegards,\nMorten Frederiksen\n--- \nA foolish hobgoblin has a mind of little consistency!\n-- \n<URL: http://xml.mfd-consult.dk/foaf/explorer/?foaf=morten.rdf >\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope tshirt agai",
            "content": "I love it!\n\nWhy chinese, and do we have all the EU languages? (I'd like Hungarian, since\nwe did some stuff in hungarian but I need to find out what it should be).\n\ncheers\n\nchaals\n\n\n\nOn Tue, 9 Dec 2003, Morten Frederiksen wrote:\n\n>\n>Libby Miller <Libby.Miller@bristol.ac.uk> wrote:\n>>If you'd like to comment on the design, please do so here, by the end of\n>>this week.\n>Looks great to me, and I have no strong opinions on brain stems or\n>slogan wording...\n>\n>>We will also need to look into how many languages to put on the back\n>... but I of course have to suggest adding Danish to the list of\n>languages. :)\n>\n>Danish version:\n>\"og det eneste vi fik var denne dumme t-shirt\"\n>(replace \"vi\" with \"jeg\" for \"I\" instead of \"we\".)\n>\n>In any case, put me down for at least a couple.\n>\n>\n>\n>Regards,\n>Morten Frederiksen\n>---\n>A foolish hobgoblin has a mind of little consistency!\n>--\n><URL: http://xml.mfd-consult.dk/foaf/explorer/?foaf=morten.rdf >\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "Hi,\n\nNice design. The text in Spanish sounds more natural as follows:\n\n\"Y TODO LO QUE CONSEGUIMOS ES ESTA CAMISETA ESTUPIDA\"\n\nRegards,\n\nAlvaro\n\n\n> -----Original Message-----\n> From: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] On Behalf Of Libby Miller\n> Sent: Tuesday, December 09, 2003 4:38 PM\n> To: public-esw@w3.org\n> Cc: liz@ephidrina.org\n> Subject: SWAD-Europe tshirt again\n> \n> \n> \n> \n> hi all,\n> \n> Liz has some tshirt designs, detailed at:\n> \n> http://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n> \n> If you'd like to comment on the design, please do so here, by \n> the end of\n> this week.\n> \n> The slogan on the front is not yet finalized - Dan is talking \n> to his W3C\n> colleagues about it this week. He prefers the slogan\n> \n> \"We helped build the Semantic Web\"\n> \n> - as a more modest representation of the achievements of the project.\n> \n> Other suggestions welcome, although it needs to be six words to fit in\n> with the design.\n> \n> We will also need to look into how many languages to put on the back\n> and and who we can ask to check them for us (thanks Alberto! :)\n> \n> Liz was thinking of\n> \n> french\n> spanish\n> italian\n> german\n> dutch\n> greek\n> russian\n> arabic\n> chinese\n> japanese\n> hindi\n> \n> with english at the bottom. We have the translation for Italian:\n> \"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n> \n> I guess Max or Chaals could do French, Chaals also arabic maybe?\n> Perhaps a W3C team member could help us with the Japanese. Liz has\n> friends who can do Dutch, maybe German and Russian. Eva could \n> do Spanish\n> for us.\n> \n> That leaves german(?) greek(?) russian(?) chinese and hindi. Plus any\n> others which we think should be in there (Hungarian? Ivan could do\n> that).\n> \n> cheers\n> \n> Libby\n> \n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "From: Charles McCathieNevile [mailto:charles@w3.org] \n> I love it!\n> \n> Why chinese, and do we have all the EU languages?\nThat could get, um, interesting.  You'd need p- and q-gaelic, Cornish, Manx,\nBasque, Lapp ... Probably ogham script and nordic runes too, not to mention\nthe precursor versions of our modern languages.\n\n\"I helped build the semantic web, and all I got was this stupid full length\ncloak\" :-)\n\nStill, at least no-one has suggested Klingon or Elvish yet.  Oops.\n\nIan\n\n\nPS Joking aside, I think the t-shirt design is good too!\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "The official languages of the EU:\n\n[[\nthe very first regulation (which has been amended after each successive\nenlargement) decided by the Council of Ministers in 1958 listed the\nofficial languages of the Union:\n\nArticle 1\n\n\"The official languages and the working languages of the institutions of\nthe Union shall be Danish, Dutch, English, Finnish, French, German,\nGreek, Italian, Portuguese, Spanish and Swedish.\"\n]]\n\nhttp://europa.eu.int/comm/scic/thescic/multilingualism_en.htm\n\nIt'd probably be a good idea to get these in at least.\nLiz also has additionally\n\nrussian\narabic\nchinese\njapanese\nhindi\n\nand\n\nMichael suggested Hebrew\n\nand\n\nchaals suggested Hungarian.\n\nSo that's 18 languages. Liz needs 12-15. Time to start reducing them?\n\nLibby\n\n\nOn Wed, 10 Dec 2003, Dickinson, Ian J wrote:\n\n>\n> From: Charles McCathieNevile [mailto:charles@w3.org]\n> > I love it!\n> >\n> > Why chinese, and do we have all the EU languages?\n> That could get, um, interesting.  You'd need p- and q-gaelic, Cornish, Manx,\n> Basque, Lapp ... Probably ogham script and nordic runes too, not to mention\n> the precursor versions of our modern languages.\n>\n> \"I helped build the semantic web, and all I got was this stupid full length\n> cloak\" :-)\n>\n> Still, at least no-one has suggested Klingon or Elvish yet.  Oops.\n>\n> Ian\n>\n>\n> PS Joking aside, I think the t-shirt design is good too!\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "tshirt humble opinio",
            "content": "Hi,\n\nI agree that the brains are a bit yucky and I think that a more\ncartoonish style would work better (e.g. [1]), in particular would fit\nthe humour of the overall design better, and would match the \"thought\nbubbles\".\n\nThe swooshy lines and the growing size of the brains as the sentence\nis spelled out makes it seem that it's a single brain making its way\naway from the t-shirt. Is this intended?\n\nI like the women's t-shirt colour better, except that it makes the\nbrains less visible. Would it be too expensive to have more colours\nfor the brains?\n\nThe French is wrong (unsurprising since Libby tells me it's out of\nbabelfish). Better is:\n\nEt tout ce qu'on a eu c'est ce T-shirt stupide\n\nAnd it just stroke it now that that sentence is the continuation of\nthe front sentence. Perhaps a pair of \"...\" on each part would make it\nclearer.\n\nCheers,\n\nMax.\n\n[1] http://www.turboread.com/images/brain.gif\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt market research :",
            "content": "I like it!\n\nI can imagine that some folks might not like the brain (I do, it's ironic\n;-), a possible alternative might be brightly-coloured snookerball style\nnodes, everything else the same (thinking nodes - why not?).\n\nCheers,\nDanny.\n\nwishing it was T-shirt weather\n\n\n\n> Hello everyone,\n>\n> For those of you haven't seen it, the proposed SWAD-Europe tshirt is\n> described and pictured here:\n>\n> http://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n>\n> It'd be great if you'd express your love or hatred of the new designs\n> on public-esw@w3.org, a public list for discussion about SWAD-Europe\n> (you can post to it if you've ever posted to a w3c list - you don't\n> have to subscribe).\n>\n> Many thanks for any comments,\n>\n> Libby\n\n\n\n"
        },
        {
            "subject": "Re: tshirt humble opinio",
            "content": "Hi\n\n> Hi,\n>\n> I agree that the brains are a bit yucky and I think that a more\n> cartoonish style would work better (e.g. [1]), in particular would fit\n> the humour of the overall design better, and would match the \"thought\n> bubbles\".\n>\n+1\n\n> The swooshy lines and the growing size of the brains as the sentence\n> is spelled out makes it seem that it's a single brain making its way\n> away from the t-shirt. Is this intended?\n>\nI reckon it's a metaphor - in the other direction. i.e. the growth of \nintelligence on the web is coming closer to us!\n\n\n> I like the women's t-shirt colour better, except that it makes the\n> brains less visible.\n\nAh, but you see, women's brains ARE less visible ;-)\n\nNikki\n\n\n Would it be too expensive to have more colours\n> for the brains?\n>\n> The French is wrong (unsurprising since Libby tells me it's out of\n> babelfish). Better is:\n>\n> Et tout ce qu'on a eu c'est ce T-shirt stupide\n>\n> And it just stroke it now that that sentence is the continuation of\n> the front sentence. Perhaps a pair of \"...\" on each part would make it\n> clearer.\n>\n> Cheers,\n>\n> Max.\n>\n> [1] http://www.turboread.com/images/brain.gif\n>\n>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "The brains are great the way they are !\n\nThe optical arrangement is fine, also the stem. \n\n\nthe real the better.\n\nhm, an assoziation comes:\nLike Bart and Homer Jay Simpson said to Ned Flanders in \"Little Big Mom\"\nhttp://www.snpp.com/episodes/BABF04\n Bart:[zombie-like] Brains ... brains ...\nHomer:[cheerful] Use your brains to help us.  [zombie-like \nagain] Your delicious brains.\n\n\nLeo\n\n> -----Original Message-----\n> From: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] On Behalf Of Libby Miller\n> Sent: Tuesday, December 09, 2003 7:31 PM\n> To: public-esw@w3.org\n> Cc: liz@ephidrina.org\n> Subject: Re: SWAD-Europe tshirt again\n> \n> \n> \n> \n> I just chatted to Nikki and she said:\n> \n> * she likes the brains but the brain stems are a bit yucky in \n> some cases\n> * she wondered whether 'we' sort of implied everyone in the world, and\n> maybe it should be 'I'\n> \n> For the record, I like the brains and the brainstems :)\n> \n> Libby\n> \n> On Tue, 9 Dec 2003, Libby Miller wrote:\n> \n> >\n> > hi all,\n> >\n> > Liz has some tshirt designs, detailed at:\n> >\n> > \n> http://rdfig.xmlhack.com/2003/12/05/2003-12-05.html#1070620451.543022\n> >\n> > If you'd like to comment on the design, please do so here, \n> by the end of\n> > this week.\n> >\n> > The slogan on the front is not yet finalized - Dan is \n> talking to his W3C\n> > colleagues about it this week. He prefers the slogan\n> >\n> > \"We helped build the Semantic Web\"\n> >\n> > - as a more modest representation of the achievements of \n> the project.\n> >\n> > Other suggestions welcome, although it needs to be six \n> words to fit in\n> > with the design.\n> >\n> > We will also need to look into how many languages to put on the back\n> > and and who we can ask to check them for us (thanks Alberto! :)\n> >\n> > Liz was thinking of\n> >\n> > french\n> > spanish\n> > italian\n> > german\n> > dutch\n> > greek\n> > russian\n> > arabic\n> > chinese\n> > japanese\n> > hindi\n> >\n> > with english at the bottom. We have the translation for Italian:\n> > \"e tutto quello che abbiamo ottenuto e' questa stupida maglietta\"\n> >\n> > I guess Max or Chaals could do French, Chaals also arabic maybe?\n> > Perhaps a W3C team member could help us with the Japanese. Liz has\n> > friends who can do Dutch, maybe German and Russian. Eva \n> could do Spanish\n> > for us.\n> >\n> > That leaves german(?) greek(?) russian(?) chinese and \n> hindi. Plus any\n> > others which we think should be in there (Hungarian? Ivan could do\n> > that).\n> >\n> > cheers\n> >\n> > Libby\n> >\n> \n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "If we have to reduce them, I would start by reducing them to the official\nlanguages. Then adding Euro languages of people who have actually played with\nus and are likely to get a t-shirt. Then other official live languages (there\nare 4 in Spain - castellano/spanish, and euskera/basque, Catal?, Gallego - as\nwell as Welsh, Gaelic, Irish, Sevoo, ... based in part on what Asterix is\npublished in :-)\n\n(although I would really like a full-length cloak)\n\ncheers\n\nChaals\n\nOn Wed, 10 Dec 2003, Libby Miller wrote:\n\n>\n>\n>The official languages of the EU:\n>\n>[[\n>the very first regulation (which has been amended after each successive\n>enlargement) decided by the Council of Ministers in 1958 listed the\n>official languages of the Union:\n>\n>Article 1\n>\n>\"The official languages and the working languages of the institutions of\n>the Union shall be Danish, Dutch, English, Finnish, French, German,\n>Greek, Italian, Portuguese, Spanish and Swedish.\"\n>]]\n>\n>http://europa.eu.int/comm/scic/thescic/multilingualism_en.htm\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "> If we have to reduce them, I would start by reducing them to \n> the official\n> languages. Then adding Euro languages of people who have \n> actually played with\n> us and are likely to get a t-shirt. \n\nI would stop here. \nThe above approach is a good algorithm,\nand you don't have to think about the tough ones like Hebrew and Arabic.\nHindi and chinese are cool, but not ->necessary<-\n\nor ?\n\ngreetings\nLeo\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt agai",
            "content": "On Wed, 2003-12-10 at 23:24, Leo Sauermann wrote:\n> > If we have to reduce them, I would start by reducing them to \n> > the official\n> > languages. Then adding Euro languages of people who have \n> > actually played with\n> > us and are likely to get a t-shirt. \n> The above approach is a good algorithm,\n> and you don't have to think about the tough ones like Hebrew and Arabic.\n> Hindi and chinese are cool, but not ->necessary<-\nI agree, the E in SWAD-E is there for a reason.\n\nHowever, I think the glyphs are pretty, and it would be nice for general\ni18n aspects and the usual political reasons, but if there's not enough\nroom...\n\n\nRegards,\nMorten\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope tshirt agai",
            "content": "we have French Liz, from Max:\n\n\"Et tout ce qu'on a eu c'est ce T-shirt stupide\"\n\n- see http://lists.w3.org/Archives/Public/public-esw/2003Dec/0013.html\n\nI will ping some people about Swedish, since we have worked with\nsevgeral Swedish people.\nI'd like Japanese and Hungarian in there too, because of all the\ncalendar and image work with Masahide, and because WWW2003 was in\nHungary. I can certainly bug people about those too....\n\nLibby\n\nOn Thu, 11 Dec 2003, Liz Turner wrote:\n\n>\n> On Wednesday, December 10, 2003, at 11:24 PM, Leo Sauermann wrote:\n>\n> >> If we have to reduce them, I would start by reducing them to\n> >> the official\n> >> languages. Then adding Euro languages of people who have\n> >> actually played with\n> >> us and are likely to get a t-shirt.\n> >\n> > I would stop here.\n> > The above approach is a good algorithm,\n> > and you don't have to think about the tough ones like Hebrew and\n> > Arabic.\n> > Hindi and chinese are cool, but not ->necessary<-\n> >\n> > or ?\n> >\n> > greetings\n> > Leo\n> >\n>\n> I am a designer, but not a linguist :)\n>\n> I would like to set a print deadline for 14th January.\n>\n> Whichever languages have been accurately translated by then will appear\n> on the shirt.\n> If you think a particular language should be included, please supply a\n> translation if possible.\n> The more colloquial the better.\n>\n> Of the official European languages, I am missing the following:\n>\n> French\n> Finnish\n> Greek\n> Portuguese\n> Swedish\n>\n> Maybe it should be left at that? It might be simpler politically, but\n> nowhere near as fun :)\n>\n> Charles: We can make the cloak as soon as I have closed negotiations\n> with my embroidering minions.\n> They usually accept groats. What is your budget?\n>\n> :)\n> e\n>\n>\n> T-ERRORISM -- \"Contentious Sloganeering in a Wearable Format\"\n> ------------------------------------------------------------------------\n> ------------------\n> http://t-errorism.com/\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "That SWAD Europe tshir",
            "content": "Just to add my tuppennorth, I like the design (with the proviso about\nnon-Babelfished translations on the back)\n-- \nNick Gibbins                                            nmg@ecs.soton.ac.uk\nIAM (Intelligence, Agents, Multimedia)             tel: +44 (0) 23 80598347\nElectronics and Computer Science                   fax: +44 (0) 23 80592865\nUniversity of Southampton\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope tshirt agai",
            "content": "I am working on getting finnish, hungarian, greek and portuguese. I hope   to\ndo it in the next few days (if I wait until January I will probably\nforget...) Naturally it will cost a few t-shirts :-)\n\nOn Thu, 11 Dec 2003, Liz Turner wrote:\n\n>I am a designer, but not a linguist :)\n>\n>I would like to set a print deadline for 14th January.\n>\n>Whichever languages have been accurately translated by then will appear\n>on the shirt.\n>If you think a particular language should be included, please supply a\n>translation if possible.\n>The more colloquial the better.\n>\n>Of the official European languages, I am missing the following:\n>\n>French\n>Finnish\n>Greek\n>Portuguese\n>Swedish\n>\n>Maybe it should be left at that? It might be simpler politically, but\n>nowhere near as fun :)\n>\n>Charles: We can make the cloak as soon as I have closed negotiations\n>with my embroidering minions.\n>They usually accept groats. What is your budget?\n\nis that like a big stoat, weasel and ferret? I have a few of those\nsomewhere... (And I would wear the cloak. A lot.)\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope tshirt agai",
            "content": "On Dec 11, 2003, at 5:34 PM, Charles McCathieNevile wrote:\n\n>\n> I am working on getting finnish, hungarian, greek and portuguese. I \n> hope   to\n> do it in the next few days (if I wait until January I will probably\n> forget...) Naturally it will cost a few t-shirts :-)\n\nif that could help you, I have friends around here from any EU member \ncountry which might be happy to help out for translations.\n\n...of course that would as well cost few+1 t-shirts :-)\n\nbtw: as already pointed out I like the t-shirt design - the female \ncoloring is preferable (darker blue)\n\ncheers\n\nAlberto\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt again (a Korean translation...",
            "content": "Hi,\n\nI tried a Korean translation of the phrase on the back.\n\n\"????????? ?????? ?????? ??? ??? ????????? ????????? ??? ???...\"\n\nPlease use UTF-8 encoding to view the above characters properly.\n\nRegards,\nMinsu\n\n--------------------------------------------------\nMinsu Jang\nSenior Member of Engineering Staff\nBusiness Knowledge Research Team\nElectronics and Telecommunications Research Institute\nPhone: +82-42-860-1250 Fax: +82-42-860-6790 \n\n\n\n"
        },
        {
            "subject": "using publicesw for image description dicsussion",
            "content": "hi all,\n\nI'm going to be collaborating with Greg Elin (fotonotes) and others on\na photos site drawing together depiction metadata for all the WWW\nconferences. We had a discussion today about it:\n\nhttp://rdfig.xmlhack.com/2003/12/18/2003-12-18.html#1071760457.693080\n\nBrian McBride suggested that we use this mailing list for\ndiscussions about this. It's not clear how much traffic this will\ncreate, but it is rather nicely related to the SWAD-E project and in\nparticular, should generate some good FAQs (which we will need for our\nnewsletter, to start in the new year).\n\nThe idea of the project is to create a database of creative-commons\nlicensed photos and metdata and create some interesting interfaces to\nit, to be usable by WWW2004 on May 2004. It's likely that we will use\nmany vocabularies, including Dublin Core, FOAF, GEO, Wordnet and\nRDFiCal, and so hopefully we should be able to come up with some good\ndocumentation about how to combine these vocabularies. In addition, we\nwill run into very real practical problems such as how to identify\npeople and how to create user interfaces to this kind of RDF creation.\n\nI think it's a strong candidate for discussion here, not least\nbecause of the connections with the image workshop we held last year,\nbut I'd like to have your opinions in case there's a better forum. Would\nit bother you guys if we used this list?\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: using publicesw for image description dicsussion",
            "content": "On Dec 18, 2003, at 11:06 AM, Libby Miller wrote:\n\n>\n>\n> hi all,\n>\n> I'm going to be collaborating with Greg Elin (fotonotes) and others on\n> a photos site drawing together depiction metadata for all the WWW\n> conferences. We had a discussion today about it:\n>\n> http://rdfig.xmlhack.com/2003/12/18/2003-12-18.html#1071760457.693080\n>\n> Brian McBride suggested that we use this mailing list for\n> discussions about this. It's not clear how much traffic this will\n> create, but it is rather nicely related to the SWAD-E project and in\n> particular, should generate some good FAQs (which we will need for our\n> newsletter, to start in the new year).\n>\n> The idea of the project is to create a database of creative-commons\n> licensed photos and metdata and create some interesting interfaces to\n> it, to be usable by WWW2004 on May 2004. It's likely that we will use\n> many vocabularies, including Dublin Core, FOAF, GEO, Wordnet and\n> RDFiCal, and so hopefully we should be able to come up with some good\n> documentation about how to combine these vocabularies. In addition, we\n> will run into very real practical problems such as how to identify\n> people and how to create user interfaces to this kind of RDF creation.\n>\n> I think it's a strong candidate for discussion here, not least\n> because of the connections with the image workshop we held last year,\n> but I'd like to have your opinions in case there's a better forum. \n> Would\n> it bother you guys if we used this list?\n\nIt certainly wouldn't bother me :) and I'd be interested in helping in \nany way I can.\n\n--\neric miller                              http://www.w3.org/people/em/\nsemantic web activity lead               http://www.w3.org/2001/sw/\nw3c world wide web consortium            http://www.w3.org/\n\n\n\n"
        },
        {
            "subject": "Re: using publicesw for image description dicsussion",
            "content": "thanks Eric :)\nDoes anyone violently object to us using it? now's the time to say...\n\nThere's also a meeting about the project on IRC, irc.freenode.net #rdfig\nat 15:00 GMT today if anyone is interested.\n\nLibby\n\nOn Thu, 18 Dec 2003, Eric Miller wrote:\n\n>\n> On Dec 18, 2003, at 11:06 AM, Libby Miller wrote:\n>\n> >\n> >\n> > hi all,\n> >\n> > I'm going to be collaborating with Greg Elin (fotonotes) and others on\n> > a photos site drawing together depiction metadata for all the WWW\n> > conferences. We had a discussion today about it:\n> >\n> > http://rdfig.xmlhack.com/2003/12/18/2003-12-18.html#1071760457.693080\n> >\n> > Brian McBride suggested that we use this mailing list for\n> > discussions about this. It's not clear how much traffic this will\n> > create, but it is rather nicely related to the SWAD-E project and in\n> > particular, should generate some good FAQs (which we will need for our\n> > newsletter, to start in the new year).\n> >\n> > The idea of the project is to create a database of creative-commons\n> > licensed photos and metdata and create some interesting interfaces to\n> > it, to be usable by WWW2004 on May 2004. It's likely that we will use\n> > many vocabularies, including Dublin Core, FOAF, GEO, Wordnet and\n> > RDFiCal, and so hopefully we should be able to come up with some good\n> > documentation about how to combine these vocabularies. In addition, we\n> > will run into very real practical problems such as how to identify\n> > people and how to create user interfaces to this kind of RDF creation.\n> >\n> > I think it's a strong candidate for discussion here, not least\n> > because of the connections with the image workshop we held last year,\n> > but I'd like to have your opinions in case there's a better forum.\n> > Would\n> > it bother you guys if we used this list?\n>\n> It certainly wouldn't bother me :) and I'd be interested in helping in\n> any way I can.\n>\n> --\n> eric miller                              http://www.w3.org/people/em/\n> semantic web activity lead               http://www.w3.org/2001/sw/\n> w3c world wide web consortium            http://www.w3.org/\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope tshirt again (a Korean translation...",
            "content": "Thank you Minsu!\n\nLibby\n\nOn Thu, 18 Dec 2003, Minsu Jang wrote:\n\n>\n> Hi,\n>\n> I tried a Korean translation of the phrase on the back.\n>\n> \"????????? ?????? ?????? ??? ??? ????????? ????????? ??? ???...\"\n>\n> Please use UTF-8 encoding to view the above characters properly.\n>\n> Regards,\n> Minsu\n>\n> --------------------------------------------------\n> Minsu Jang\n> Senior Member of Engineering Staff\n> Business Knowledge Research Team\n> Electronics and Telecommunications Research Institute\n> Phone: +82-42-860-1250 Fax: +82-42-860-6790\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "SWADEurope: esws 2004 agai",
            "content": "Just so I remember about this later:\n\n[[\nAll European Semantic Web projects, as well as other research projects\nin the Semantic Web area world-wide, are invited to present a poster at\nthe ESWS2004. Each project presenting a poster is requested to submit a\ntwopage project description. Submission details will be on the web site\nhttp://www.esws2004.org/. Submission deadline is February 28, 2004.\n]]\n\n\n\n"
        },
        {
            "subject": "Demonstrator 12.1: Semantic blogging for bibliographie",
            "content": "The requirements specification [1] for the first of HP's demonstrators,\nsemantic blogging for bibliographies, is now out.\n\nThe document basically defines a small (but useful) tightly scoped core.\nThere are a variety of possible extensions which have been described in\nvarying depth. Of possible interest is an extensive survey of related work\n(both in the blogging and bibliographic world) and a short user study.\n\nOther relevant documents include\n - HP semantic blogging webpage [2]\n - Our previous report on semantic web applications [3]\n\nAs usual, comments welcome.\n\nCheers\n\nSteve\n\n[1]\nhttp://www.w3.org/2001/sw/Europe/reports/open_demonstrators/hp-requirements-\nspecification.html\n[2] http://www.hpl.hp.com/semweb/swade/biblio\n[3]\nhttp://www.w3.org/2001/sw/Europe/reports/open_demonstrators/hp-applications-\nselection.html\n\n________________________________________________________________________\nSteve Cayzer    HP Labs, Bristol, UK    mailto:Steve.Cayzer@hp.com\n\n\n\n"
        },
        {
            "subject": "Page of links to trustrelated resource",
            "content": "In case it may be of interest, this page has been brought to my attention:\n\n   Semantic Web:  Trust and Security Resource Guide\n   http://www.wiwiss.fu-berlin.de/suhl/bizer/SWTSGuide/\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "ANN: CORES Workshop, Budapest, 67 March 2003 (fwd",
            "content": "People may have seen this already - if so, apologies.\n\nchaals\n\nApologies for cross posting\n\n**REGISTRATION NOW OPEN***\n\nCORES Schema Creation and Registration Workshop\nSZTAKI, Budapest, 6-7 March 2003\nhttp://www.ukoln.ac.uk/events/cores/intro.html\n\nThis project has been funded by the European Community.\n\nThe workshop will provide an introduction to the use of RDF to describe\nmetadata vocabularies in the form of machine-understandable schemas. It\nwill focus on the publication of these schemas in the CORES Schema\nRegistry. Practical sessions will allow participants to learn to use the\nCORES Schema Creation Tool to prepare schemas and submit them to the\nRegistry, and to navigate the schemas submitted via the Registry's Web\ninterface.\n\nThe workshop is targetted at those with an interest in creating and\nmanaging metadata vocabularies. Workshop participants should be familiar\nwith a specific metadata element set which they can use as a basis for\ninput into the schema creation tool. Detailed knowledge of RDF Schema\nsemantics and RDF/XML syntax is not required, as the schema encoding\nwill be generated by the tool. For participants wishing to gain a\nworking understanding of RDF and its application to the description of\nmetadata vocabularies, the workshop will provide a good opportunity to\nfocus on some key issues, without the need to focus on syntactic\ndetails.\n\nThe Cost of Registering for the workshop is ?70.00 (Pounds Sterling)\nThe delegate fee includes full attendance at the workshop, refreshments\nand lunch on both days, dinner on 6th March and workshop materials.\n\nFor registration information see\nhttp://www.ukoln.ac.uk/events/cores/intro.html\n\n-------\nPete Johnston\nInteroperability Research Officer\nUKOLN, University of Bath, Bath BA2 7AY, UK\ntel: +44 (0)1225 383619    fax: +44 (0)1225 386838\nmailto:p.johnston@ukoln.ac.uk\nhttp://www.ukoln.ac.uk/ukoln/staff/p.johnston/\n\n\n\n"
        },
        {
            "subject": "Re: Call for a DotGNU/W3C RDF API  (was Re:GPL relicense for Euler (was Re: call for alpha testers EulerSharp for dotgnu/pnet)",
            "content": "for info, b/g context re rdf api discussions...\n\n\nattached mail follows:\n\nDear Stephen,\n\n--- Stephen Compall <s11@member.fsf.org> wrote:\n> On Sunday 09 February 2003 03:15 am, James Michael DuPont wrote:\n> > But the n3 parser for example, that would be good as part of the\n> > dotgnu.rdf native implementation. I dont know if we can include w3c\n> > licensed code as part of the dotgnu project. Can you give me\n> > permission to dual license it? Disjunct under the GPL and under the\n> > w3c?\n> \n> What does it mean to say a license is \"compatible with the GPL\".\n>  \n> It means that the other license and the GNU GPL are compatible; you\n> can \n> combine code released under the other license with code released\n> under \n> the GNU GPL in one larger program. \n\nI completely agree with you, and see you interpretation as correct,\nmy questions were not informed. After I had posted the questions,\nDanbri and I had discussed this issue futher on the RDFIG chat. \n\nIt seems that the license that I had copied from the Euler Webpage(and\nput into the \"COPYING\" file in the Distribution) was out of date, and\nhas now been replaced by the up to date and revised W3C license. Before\nit contained the following statements (Which can still be found in the\narchive, I will remove them on then next release):\n\n[[\n1. Redistributions of source code must retain the above copyright\nnotice,\n   this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\nnotice,\n   this list of conditions and the following disclaimer in the\ndocumentation\n   and/or other materials provided with the distribution.\n]]\n\nOf course these has caused me some concern, because using that code in\na GPLed project would of course be in violation of term 1.\n\nBut that is all resolved now!\n\nI had a particular reason to ask about Dual Licensing :\nAs a (L)GPLed project, we can include W3C code, and it is not different\nthan a large industrial company deciding to use the w3c code in a\nnon-free manner. \n\nBut my question of dual licensing has also another aspect, the one of\nour changes going back to the W3C, and maybe being used by such\ncompanies in a non-free manner. Unlike some who \"Hit and Run\" (or was\nthat \"Embrace and Extend\"?) standard technology for their own self\nserving gains, I suggest that we choose to give back to the W3C some of\nour changes so that others may be compatible with us.\n\nSpecifically, I propose that we (the dotgnu project who I have put back\non the cc) submit officially our Dotgnu.rdf interface (Which is\ninspired from redland) back the w3c as a proposed C# api. This way, we\ncan even provide LGPLed implementation of such code, but also be\ncompatible with non-free implementations. The ECMA Standard IL and the\nDotGNU system in particular will allow for many different\nimplementations of the RDF Libraries, all with varying pluses and\nminuses. \n\nBut behind the concept of interfaces, we can have have many different\nimplementations. That is where the DOTGNU project can fit in.\n\nThe DotGNU project should have IMHO a particular importance to the W3C,\nit will support in the long term Perl and Python via Parrot and Java as\nwell, which Many W3C projects use.\n\nWhen the Parrot(python/perl) and DotGNU projects finally meet in the\nfar future, then it should also in the far future to compile TimBL's\nCWM and have it use a RDF interface written in another language. The\ncode written in Python/Parrot talking to for example a C#\nimplementation of the RDF API. \n\nOn the other side, we should be able to have simple implementations of\nthe n3 parser from Euler for example that just implement the most basic\naxioms of the n3 parsing. This too should be possible to derive from\nthis proposed API. \n\nMy current issue with the huge number of RDF APIS right now is that the\ncustomer and end user is forced to choose, before they even know all\nthe facts. IMHO, We who have taken the time to look into this\ntechnology have the responsibility to provide a better insulation from\nthe underlying implementation. \n\nTherefore I suggest that we also look into the other APIS available,\nJena, Redfoot, Mozilla, RDFLib, putting together a working group of\nDotGNU members and W3C contributors so that we can agree on a core API\nfor RDF in the future. That will be defined as a set of interfaces,\nlike the DOM so that the users have the freedom of choice.\n\nDoes anyone else support this idea? Please respond! :)\n\nMike\n\n=====\nJames Michael DuPont\nhttp://introspector.sourceforge.net/\n\n__________________________________________________\nDo you Yahoo!?\nYahoo! Mail Plus - Powerful. Affordable. Sign up now.\nhttp://mailplus.yahoo.com\n\n\n\n"
        },
        {
            "subject": "Re: ANN: CORES Workshop, Budapest, 67 March 2003 (fwd",
            "content": ">>>Charles McCathieNevile said:\n> \n> People may have seen this already - if so, apologies.\n\nA pity that they didn't mention that the CORES stuff was based on the\nearlier MEG Registry project by UKOLN and ILRT which used DC and RDF\nfor the datamodel.  The technical development was done at ILRT by\nmyself (server in Perl using Redland) and Damian Steer (client in\nJava using Jena)\n\nThe project http://www.ukoln.ac.uk/metadata/education/regproj/\nand the demo registry http://meg.ukoln.ac.uk/\n\nWe had a MEG workshop recently demonstrating these things and had\ngood reports from it.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Announcement: Raptor RDF Parser Toolkit 0.9.",
            "content": "This and the Redland work was done as part of WP10 deliverable 10.3\nwhich is still ongoing.\n\nDave\n\n   Raptor RDF Parser Toolkit 0.9.8\n     http://www.redland.opensource.ac.uk/raptor/\n\nRaptor is a C library that provides parsers for the RDF/XML and\nN-Triples syntaxes returning triples.  It was designed to work\nclosely with the Redland RDF library (RDF Parser Toolkit for Redland\n- - Raptor) but is fully separate.  It is free software / Open Source,\nhas no memory leaks so far and is pretty fast.\n\nThis is a minor bugfix release (synchronising with Redland 0.9.12 release).\nRaptor is a stable library, with some known conformance issues.\n\nSummary of changes:\n\n  * Fixed crashing on empty files\n  * Fixed accepting illegal xmlns:prefix=\"\" (prefix without URI not allowed)\n  * N-Triples bnodeIDs can now have '0's\n  * Utility program rdfdump renamed to rapper; name conflicted with a common\n    Linux utility.\n\nThe release consists of the full sources, RPM binaries and source RPM\npackages for RedHat Linux 7.3.  These are also available from the\nRedland SourceForge mirror site at\n  http://sourceforge.net/projects/librdf/\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS and use Raptor in various demos (as part of\nRedland).\n\nI post updates about Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\n\n\n"
        },
        {
            "subject": "ANNOUNCEMENT: Redland RDF Application Framework 0.9.1",
            "content": "This and the Raptor work was done as part of WP10 deliverable 10.3\nwhich is still ongoing.\n\nDave\n\n\n       Redland RDF Application Framework 0.9.12\nhttp://www.redland.opensource.ac.uk/\n\nRedland is a C library that provides a high-level interface for RDF\nallowing the RDF graph to be parsed from XML, stored, queried and\nmanipulated.  Redland implements each of the RDF concepts in its own\nclass via an object based API, reflected into the other language APIs\n- - Java, Perl, PHP, Python, Ruby and Tcl. Some of the classes\nproviding the parsers, storage mechanisms and other elements are\nbuilt as modules that can be added or removed as required.\n\nRedland 0.9.12 is a major release with many changes and improvements\n(last was 2002-06-08).  The main changes are as follows\n\nNEW FEATURES\n * Added contexts\n   Statements added to Model (when using a Storage that supports\n   contexts) can take an optional Node, returned by the new\n   get_context method on Iterator and Stream classes.\n\n   This is explained in greater detail in the full release notes:\n     http://www.redland.opensource.ac.uk/RELEASE.html#rel0_9_12\n\n\nFORMAT CHANGES\n * The persistent storage format was changed to support RDF typed\n   literals and this will require an upgrade of any existing\n   Berkeley/Sleepycat DB stores created by Redland 0.9.11 or\n   earlier. A utility redland-db-upgrade is provided that creates\n   an updated store from an existing one.\n\nAPI CHANGEs  \n * Iterator and Stream classes. \n   The next/get_next method is split into get_object always\n   returning a shared object and next methods.  get_context method\n   added. (get_object is called current in higher level languaged APIs)\n\n * Model class.\n   Method add_statement no longer takes ownership of the passed in\n   statement. The caller now retains ownership.\n\n   Method add_statements no longer frees the passed in\n   librdf_stream; the caller must free it now.\n\n * Node and Model classes.\n   Added RDF Datatyped Literals. Other literal is_wf_xml\n   constructors and methods deprecated.\n\n * General\n   All literals methods and constructors have no mention of the\n   never-used or supported XML Space argument which hasis not part\n   of an RDF literal.\n\nOTHER CHANGES\n\n * Added a script utils/update-api-0912.pl to help automate the API\n   changes as far as possible or warn about those that cannot be\n   automatically updated.\n\n * Many portability and compiling fixes (OSX, gcc 3.x, FreeBSD,\n   non-gcc compiler)\n\n * Updated to Raptor version 0.9.8 (RDF/XML and N-Triples parser)\n\n * Java API classes. Add finished() method replacing useless\n   finalize().  Use Raptor message callbacks to get parser warnings\n   and errors.\n\n * Build Java API working around the stupid things recent SWIG\n   versions do.\n\n * Make Redland work with BDB/Sleepycat DB v4 (as well as v2 and v3).\n\n * Python API gains pydoc comments and HTML derived version.\n\n * Perl and Python APIs now receive Redland message callbacks.\n\n * Redland URI class now registers with Raptor rather than specially\n   compile Raptor.\n\n * Added RDF/XML Serializer class and made higher level language APIs\n   to it.\n\n * Update to Raptor version 0.9.8 (RDF/XML and N-Triples parser) -\n   see the Raptor NEWS at\n     http://www.redland.opensource.ac.uk/raptor/NEWS.html\n   for more detailed changes since 0.9.5.\n\n * Added skeleton Ruby and PHP APIs.\n\n * Major source reorganisation.\n\nSee also the detailed 0.9.12 release notes at\nhttp://www.redland.opensource.ac.uk/RELEASE.html#rel0_9_12\n\nThe release consists of the full sources, RPM binaries and SRPMS\npackages for RedHat Linux 7.3.  It is also available from the\nRedland SourceForge mirror site at http://sourceforge.net/projects/librdf/\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS and use Redland in various demos.\n\nI post updates about Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\n\n\n"
        },
        {
            "subject": "FW: FIRST EUROPEAN SUMMER SCHOOL ON ONTOLOGICAL ENGINEERING AND THE SEMANTIC WEB          (SSSW2003",
            "content": "(I was going to put a link on the Wiki, but it seems to be timing out)\n\n-----Original Message-----\nFrom: www-rdf-logic-request@w3.org\n[mailto:www-rdf-logic-request@w3.org]On Behalf Of Enrico Motta\nSent: 12 February 2003 16:04\nTo: www-rdf-logic@w3.org\nSubject: FIRST EUROPEAN SUMMER SCHOOL ON ONTOLOGICAL ENGINEERING AND THE\nSEMANTIC WEB (SSSW-2003)\n\n\n\n***APOLOGIES FOR MULTIPLE POSTINGS***\n\n==================================================\nTHE FIRST EUROPEAN SUMMER SCHOOL\nON ONTOLOGICAL ENGINEERING AND THE SEMANTIC WEB (SSSW-2003)\n\nhttp://minsky.dia.fi.upm.es/summerschool/\n\nVENUE\nCercedilla, near Madrid, Spain.\n\nDATE\n21-26, July 2003\n\nORGANIZING COMMITTEE\nEnrico Motta (Director)\nAsun Gomez-Perez (Co-Director)\nArthur Stutt (Project Co-ordinator)\n\nINTRODUCTION\nThe OntoWeb Network Consortium (www.ontoweb.org) is pleased to\nannounce the first European Summer School on Ontological Engineering\nand the Semantic Web. This summer school, presented by leading\nresearchers in the field, is the first opportunity anywhere in the world for\npostgraduate students to equip themselves with the range of\ntheoretical and practical skills necessary for full engagement with\nthe challenges involved in developing Ontologies and Semantic Web\napplications. With this in mind, candidates will need to book early\nto avoid disappointment. The school will be limited to 50 participants.\n\nAPPROACH\nTo avoid a passive learning experience we will augment theoretical\nmaterial with practical workshops. Furthermore, we will ensure that\nthe theoretical sessions are complementary to each other by linking them to\na mini-project. Work on developing and presenting this project in\ncooperation with other participants will serve as a means of\nconsolidating the knowledge and skills gained from lectures and\npractical sessions.\n\nParticipants will be provided with a copy of all course lectures and\naccess to a PC with all necessary tools and environments pre-installed.\n\nCOURSE TOPICS\nKnowledge Representation and Ontologies\nSemantic Web Services\nLanguage Technologies for the Semantic Web\nThe Semantic Web and Knowledge Management\n\nTUTORS\nAsun Gomez-Perez and Mike Uschold:  Knowledge Representation and Ontologies\nJohn Domingue and Terry Payne: Semantic Web Services\nPaul Buitelaar and Fabio Ciravegna: Language Technologies for the Semantic\nWeb\nHans Akkermans and Steffen Staab: Semantic Web Technology for\nKnowledge Management\n\nINVITED SPEAKERS\nCarole Goble: Introduction to the Semantic Web\nNicola Guarino:  Knowledge Representation and Ontologies\nDieter Fensel:  Semantic Web Services\nRichard Benjamins: Semantic Web Technology for Knowledge Management\n\n\nSCIENTIFIC COMMITTEE\nHans Akkermans, Vrije Universiteit Amsterdam (Netherlands)\nRichard Benjamins, iSOCO (Spain)\nPaul Buitelaar, DFKI-Language Technology (Germany)\nFabio Ciravegna, University of Sheffield (UK)\nYing Ding, Leopold Franzens Universit?t (Austria)\nJohn Domingue, The Open University (UK)\nDieter Fensel, University of Innsbruck (Austria)\nCarole Goble, University of Manchester (UK)\nAsun Gomez-Perez, Universidad Polit?cnica de Madrid (Spain)\nNicola Guarino, Consiglio Nazionale delle Ricerche (Italy)\nFrank van Harmelen, Vrije Universiteit Amsterdam (Netherlands)\nJim Hendler, University of Maryland at College Park (USA)\nAtanas Kiryakov, Sygma, (Bulgaria)\nMounia Lalmas, Queen Mary University of London, (UK)\nEnrico Motta, The Open University (UK)\nMark Musen, Stanford University Medical Center (USA)\nNigel Shadbolt, University of Southampton, UK\nTerry Payne, University of Southampton (UK)\nGuus Schreiber, University of Amsterdam (Netherlands)\nSteffen Staab, University of Karlsruhe (Germany)\nArthur Stutt, The Open University (UK)\nMike Uschold, Boeing (USA)\nBob Wielinga, University of Amsterdam (Netherlands)\n\n\nBENEFITS OF ATTENDING\nSSSW-2003 will provide a stimulating and enjoyable environment in\nwhich participants will benefit not only from the formal and practical\nsessions but also from informal and social interactions with\nestablished researchers and peers relatively new to the area.\n\nAfter completing the course, participants will:\n* Understand the motivation behind, and history of, efforts to build a\nSemantic Web\n* Be able to critique research papers on the Semantic Web\n* Be able to use a range of tools to build Semantic Web applications\n* Be able to identify possible new lines of research\n\nACCOMMODATION AND SOCIAL EVENTS\nCercedilla is a small village in the mountains near Madrid. The school\nwill be held in the Universidad Polit?cnica de Madrid's student house.\nThe student house has a range of facilities to make your stay more\npleasant including en suite bathrooms, swimming pool, bars and\nrestaurants in the village.\n\nThere will be an afternoon excursion to a local tourist destination.\nBoth this and a gala dinner will be included in the cost.\n\nPARTICIPANTS\nWe welcome applicants from anywhere in the world. Normally applicants\nwill be first or second year postgraduate students in relevant\ndisciplines with some knowledge of ontological or knowledge\nengineering and/or the development of applications for the World Wide\nWeb.\n\nCOST OF SUMMER SCHOOL INCLUDING\nACCOMMODATION, MEALS AND EXCURSION\n\nEuros 625\n\nTRAVEL AND LOCAL INFORMATION\nThe nearest airport is Madrid-Barajas.\nParticipants will be able to use local rail links from Madrid to Cercedilla.\nWe hope to arrange a coach for participants.\n\nFurther information about how to reach Cercedilla is on the web site.\n\nREGISTRATION\nIf you are interested in SSSW-2003 then please fill in the online\nregistration form at our web site:\n\nhttp://minsky.dia.fi.upm.es/summerschool/\n\nCONTACTS\nEnrico Motta - e.motta@open.ac.uk\nAsun Gomez-Perez - asun@fi.upm.es\nArthur Stutt - a.stutt@open.ac.uk\n\n\n\n"
        },
        {
            "subject": "Updated SWAD Europe report",
            "content": "From my SWAD-Europe weblog posting:\n\nWe promised to keep the two WP10 reports fresh and add feedback. \nI've had some sitting in my inbox for a while and it was time to merge\nthem in.  So this week I've been updating the Mapping data from RDBMS\n(first published in January 2003) and Scalability and Storage: Survey\nof Free Software / Open Source RDF storage systems (July 2002).  The\nformer gained a new section since there are actual mapping tools\nstarting to be available to turn relational databases into RDF.  The\nlatter some updates to new features of Sesame (and other tools) and\nsome corrections.  All the changes are in the corresponding changes\nsections of each document.\n\nhttp://esw.w3.org/mt/esw/archives/000025.html gives you the links\n\nTry posting yourself - it's easy.  Don't forget to change the\npulldown menu to 'Publish' rather than 'Draft'.\n\nCheers\n\nDave\n\n\n\n"
        },
        {
            "subject": "General FAQ",
            "content": "Hi folks\n\nThere are some questions that came from the Initial technical workshop which\nare (I think) really frequently asked ones, and it makes more sense to me\nthat we collect them somewhere other than in one particular workshop report -\nin part because I suspect we will think about updating the answers through\nthe life of the project.\n\nThe possibilities that occur to me are the following:\n\n1. List them and what we know about answers in the report, and use something\nlike RSS to gather them into a document (and know where they are so we know\nwhere to go back and update them as appropriate)\n\n2. Create some general FAQ documents now which we edit on an ongoing basis,\nand point to them from the report write-ups as appropriate.\n\n3. Do something else...\n\nIt seems to me that number 1. is the best option, because it means I can\nstart by creating a few questions and answers, and we can later collect them\nand relate them as we choose. But it seemed worthwhile asking if anyone\nthought otherwise before I went ahead.\n\nIt would in effect be following the existing practise, as per the reports on\nScalable storage systems and Annotation servers. If we want to be doing\noption 2 it is probably as well to start now as later - hence the question.\n\nCheers\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RDF and access contro",
            "content": "Following from my earlier work as part of the RAL contribution to SWAD-E, \nanother couple of documents are now available for review:\n\n\n1.  \"Scenarios for using RDF in support of Trust and Access Control\"\nhttp://www.ninebynine.org/SWAD-E/Trust-scenarios-20021222.html\n[[\nThis memo describes some scenarios in which RDF might be used to model \ntrust and access control in networked systems.\n]]\nThis describes a range of trust- and authorization-related scenarios, some \nof which may form the basis of further exploratory development, such as...\n\n\n2.  \"Using RDF for Home Network Configuration\"\nhttp://www.ninebynine.org/SWAD-E/Scenario-HomeNetwork/HomeNetworkConfig-20021222.html\n[[\nThis memo describes the use of RDF metadata in configuring Internet access \nfrom a home network. Its goal is to demonstrate the practical applicability \nof common semantic web technologies in a simple real-world based \nscenario.  The work has been inspired in part by an architectural proposal \nfor XML network configuration submitted to the IETF.\n]]\nThis describes an exploration of one of the scenarios from the previous \ndocument.  There are links to all the source files used (Notation3).  For \nan overview of the application, with links to source files, see: \nhttp://www.ninebynine.org/SWAD-E/Scenario-HomeNetwork/HomeNetworkAccessConfig.html\n\nI would be interested to hear how folks react to my (tentative) \nconclusions: \nhttp://www.ninebynine.org/SWAD-E/Scenario-HomeNetwork/HomeNetworkConfig-20021222.html#sect-Conclusions\n\n...\n\nSeparately from RAL-sponsored work, I have also prepared a metadata \nworkshop presentation to be given at the SAINT 2003 symposium in Januray \n2003 (http://www.saint2003.org/), with the goal of exposing RDF through the \ndiscussion of a particular scenario.  This is at:\n   http://www.ninebynine.org/SWAD-E/Scenario-HomeNetwork/HomeNetwork/index.html\n\n...\n\nMy SWAD-E page is at:\n   http://www.ninebynine.org/SWAD-E/Intro.html\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Linking between reports Re: General FAQ",
            "content": "On Thu, 2 Jan 2003, Charles McCathieNevile wrote:\n\n>Hi folks\n>\n>There are some questions that came from the Initial technical workshop which\n>are (I think) really frequently asked ones, and it makes more sense to me\n>that we collect them somewhere other than in one particular workshop report -\n>in part because I suspect we will think about updating the answers through\n>the life of the project.\n>\n>The possibilities that occur to me are the following:\n>\n>1. List them and what we know about answers in the report, and use something\n>like RSS to gather them into a document (and know where they are so we know\n>where to go back and update them as appropriate)\n\nThis is what I started to do - to the extent that I listed questions raised,\nand questions raised with answers proposed, in the report for the initial\nworkshop.\n\nA number of the questions raised but not answered in the workshop were\nanswered in the FAQ section of Dave Beckett's report on Open source RDF\nstores and their scalability. So the question is whether the report should\nsimply link to those answers, or we should try to do something smarter.\n\nAgain, my first appraoch is to simply make the question/answer pairs in\nDave's report targets and link to them, but it seems that it will soon be\nmore useful to be able to extract the FAQs. If anyone ahs good ideas about\nhow to do this now, so we can settle on markup conventions before we have too\nmuch to retrofit, I am interested. Otherwise we will just see what happens\nlater...\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "A proposed theme for SW Activity phase 2: 'SW on the Web",
            "content": "Attached is a message I've just sent to the W3C Semantic Web Coordination Group\nlist, where we are discussing priorities to propose for phase two of the \nSemantic Web Activity, beginning later in the spring.  The mail archives for SWCG are \non the W3C Member website at http://lists.w3.org/Archives/Member/w3c-semweb-cg/\nso passwords are needed to track that discussion.\n\nNeedless to say the attached view[1] is just my personal opinion. I'd be interested \nin the views of SWAD-Europe folk on how they see things, personal views or otherwise.\n\nMore context: W3C SW page, http://www.w3.org/2001/sw/ and current \nActivity statement: http://www.w3.org/2001/sw/Activity#\n\nDan\n\n\n[1] http://lists.w3.org/Archives/Member/w3c-semweb-cg/2003Jan/0032.html\n\n\nattached mail follows:\n\n\nShort version: phase two of W3C SW Activity should focus on getting RDF used in the \npublic Web. Everything else (especially new technology creation) is secondary to that \ngoal.\n\n\nHere's a longer account of my view for SW Activity phase two priorities.\n\n(Ontologists, note that I write 'RDF' in its broader sense, as a Framework, for which \nwe now have an Ontology language; when I write 'RDF' pls read 'RDF/OWL' if you prefer).\n\nRDF and SW/Ontology tools are very general. They could be used for almost anything \nto do with modern information management. This broad applicability is what \ndraws many of us to the technology, but also a source of risk: by being \n_usable_ for everything, we risk being _used_ for nothing. A reasurringly wide \nrange of groups are exploring the possibilities of RDF, yet RDF is not tailored to \nany of their specific needs. We must be doing something right. But we shouldn't forget \nthat more tailored solutions in each field could easily discourage RDF adoption.\nWe can't please all the people, all the time.\n\nSomething we might attempt in phase two is to focus our effects a bit on some \nparticular fields for deploying RDF/OWL. I propose (this is so obvious as to \nbarely need saying, perhaps) that we focus on the public Web in phase two of the Activity.\nBy 'the public Web', I mean the work of Web masters, HTML authors, focussing on \npublically available sites who are currently mostly using HTML+CSS+jpeg/gif/png as their \ncontent formats, and perhaps dabbling with RSS, Flash, SVG and other fancy new stuff.\n\nI would like to see more RDF files on publically visible Web servers. RDF files that \nuse a variety of RDF schemas and Ontologies, and that link to other RDF documents \nscattered around the Web. Once we have this, I'm confident the rest (intranets, domain\nspecific tools, RDF in backend databases etc.) will follow. Right now, if you go \nlooking in the public Web for folk using RDF, there really isn't much out there. A few \nlarge datadumps, a few keys into webservice lookups or screen scrapes, a fair amount \nof Dublin Core embedded (invalidly) in HTML or linked as separate files, a promising \nnumber of RSS files, some of which are in RSS 1.0 (but not really exploiting the RDF \naspects of RSS), and a few hundred FOAF files. This is pretty modest situation to be \nin after 5+ years of RDF work. It isn't disasterous, but should be a cause for concern, \nand for focus as we design the next phase of the Activity. \n\nI would like us to go into phase two with some notion of success criteria: what would \ncount as having succeeded? I'm suggesting that an almost quantitative approach \nmay be applicable. If there are lots of RDF documents being used on ordinary Web sites,\nwhether commercial, personal, Weblog, portal or academic, then something is going \nright. If we end phase two without this, then we likely should think about packing \nup and going home. \n\nLet's make phase two all about roll-out. Getting RDF, even simple, perhaps boring RDF, \non the agendas, web sites and CVs of ordinary Web masters and content producers. That \nRDF will be all the more meaningful if it draws on vocabularies enriched with OWL, and \nwe will have our work cut out for us helping folk do this effectively.\n\nIf, in attempting to get RDF deployed in this way, we find the reason for resistence \nis that people need common APIs, more standard query languages, protocols, or rule \nlanguages, then yes, we could start work in those areas. But right now I don't believe \nfor a second that RDF is relatively undeployed because we've not created enough \naccompanying Web standards. When RDF is used, eg. in RSS, or Dublin Core, it is often \n'on faith', ie because people are anticipating some payback from using it where \nthey could have adopted a pre-RDF or vanilla XML solution. Many people are still \nwaiting to see what their RDF dabblings bought them.\n\nBy focussing phase two on public Web deployment, I believe we will have a good \nchance of increasing the number of RDF documents and RDF tools and RDF-basd services \nthat are visible to folk investigating the technology. Since RDF is all about \ndata merging and network effects, it becomes a stronger platform for information \nmanagement with every new shared document that uses it. This, if nothing else, should \ndraw our attention towards priorities that encourage the publication of RDF/XML \ndocuments on the Web. \n\nIf this account of a theme for phase two is at all persuasive, I think we could \nderrive some specific work items and priorities. But let's agree on what we're trying \nto achieve, first. Even if it something as almost-crass as 'lots of RDF documents \non lots of Web sites'. Stating the obvious might be worthwhile, I suspect.\n\ncheers,\n\nDan\n\n\nps. i'll probably forward this to a public archived mailing list, for \nb/g in discussions in SWAD-Europe and the RDFIG. \n\n\n\n"
        },
        {
            "subject": "Re: A proposed theme for SW Activity phase 2: 'SW on the Web",
            "content": "I mostly agree but with a slight note of caution.\n\nI agree that it is best to pick one, or a small number of, focused application\nclasses. I agree that success on the \"public web\" would carry more impact than\nmany alternatives and should be the target if possible.\n\nMy caution is that the semantic web is primarily about machine readable data and\nthe public web is, currently, primarily about human readable data. This tends to\nleave the role of the semantic web technology on the public web as mostly\nconcerned with metadata about otherwise human readable documents. Metadata is\ncertainly useful but (a) is often internal to a site and so benefits less from\nstandardization and (b) is subject to the bottleneck that people avoid providing\nmetadata if they possibly can. \n\nNow I *do* think there are roles for semantic web technologies in the public\nweb, otherwise we wouldn't have proposed semantic blogging and semantic portals\nas our two demonstrator apps! However, I'm not sure we have a clear idea of the\nmost useful roles. So \"yes\" to targeting the public web, but work needs to done\nto make that more specific before you turn it into work priorities.\n\nDave\n[The use of \"I\" lots of times is meant to indicate that this is a personal\nopinion.]\n\nDan Brickley wrote:\n> \n> Attached is a message I've just sent to the W3C Semantic Web Coordination Group\n> list, where we are discussing priorities to propose for phase two of the\n> Semantic Web Activity, beginning later in the spring.  The mail archives for SWCG are\n> on the W3C Member website at http://lists.w3.org/Archives/Member/w3c-semweb-cg/\n> so passwords are needed to track that discussion.\n> \n> Needless to say the attached view[1] is just my personal opinion. I'd be interested\n> in the views of SWAD-Europe folk on how they see things, personal views or otherwise.\n> \n> More context: W3C SW page, http://www.w3.org/2001/sw/ and current\n> Activity statement: http://www.w3.org/2001/sw/Activity#\n> \n> Dan\n> \n> [1] http://lists.w3.org/Archives/Member/w3c-semweb-cg/2003Jan/0032.html\n> \n>   --------------------------------------------------------------------------------\n> \n> Subject: A proposed theme for SW Activity phase 2: 'SW on the Web'\n> Resent-Date: Tue, 14 Jan 2003 08:04:49 -0500 (EST)\n> Resent-From: w3c-semweb-cg@w3.org\n> Date: Tue, 14 Jan 2003 08:04:45 -0500\n> From: Dan Brickley <danbri@w3.org>\n> To: w3c-semweb-cg@w3.org\n> CC: libby.miller@bristol.ac.uk\n> \n> Short version: phase two of W3C SW Activity should focus on getting RDF used in the\n> public Web. Everything else (especially new technology creation) is secondary to that\n> goal.\n> \n> Here's a longer account of my view for SW Activity phase two priorities.\n> \n> (Ontologists, note that I write 'RDF' in its broader sense, as a Framework, for which\n> we now have an Ontology language; when I write 'RDF' pls read 'RDF/OWL' if you prefer).\n> \n> RDF and SW/Ontology tools are very general. They could be used for almost anything\n> to do with modern information management. This broad applicability is what\n> draws many of us to the technology, but also a source of risk: by being\n> _usable_ for everything, we risk being _used_ for nothing. A reasurringly wide\n> range of groups are exploring the possibilities of RDF, yet RDF is not tailored to\n> any of their specific needs. We must be doing something right. But we shouldn't forget\n> that more tailored solutions in each field could easily discourage RDF adoption.\n> We can't please all the people, all the time.\n> \n> Something we might attempt in phase two is to focus our effects a bit on some\n> particular fields for deploying RDF/OWL. I propose (this is so obvious as to\n> barely need saying, perhaps) that we focus on the public Web in phase two of the Activity.\n> By 'the public Web', I mean the work of Web masters, HTML authors, focussing on\n> publically available sites who are currently mostly using HTML+CSS+jpeg/gif/png as their\n> content formats, and perhaps dabbling with RSS, Flash, SVG and other fancy new stuff.\n> \n> I would like to see more RDF files on publically visible Web servers. RDF files that\n> use a variety of RDF schemas and Ontologies, and that link to other RDF documents\n> scattered around the Web. Once we have this, I'm confident the rest (intranets, domain\n> specific tools, RDF in backend databases etc.) will follow. Right now, if you go\n> looking in the public Web for folk using RDF, there really isn't much out there. A few\n> large datadumps, a few keys into webservice lookups or screen scrapes, a fair amount\n> of Dublin Core embedded (invalidly) in HTML or linked as separate files, a promising\n> number of RSS files, some of which are in RSS 1.0 (but not really exploiting the RDF\n> aspects of RSS), and a few hundred FOAF files. This is pretty modest situation to be\n> in after 5+ years of RDF work. It isn't disasterous, but should be a cause for concern,\n> and for focus as we design the next phase of the Activity.\n> \n> I would like us to go into phase two with some notion of success criteria: what would\n> count as having succeeded? I'm suggesting that an almost quantitative approach\n> may be applicable. If there are lots of RDF documents being used on ordinary Web sites,\n> whether commercial, personal, Weblog, portal or academic, then something is going\n> right. If we end phase two without this, then we likely should think about packing\n> up and going home.\n> \n> Let's make phase two all about roll-out. Getting RDF, even simple, perhaps boring RDF,\n> on the agendas, web sites and CVs of ordinary Web masters and content producers. That\n> RDF will be all the more meaningful if it draws on vocabularies enriched with OWL, and\n> we will have our work cut out for us helping folk do this effectively.\n> \n> If, in attempting to get RDF deployed in this way, we find the reason for resistence\n> is that people need common APIs, more standard query languages, protocols, or rule\n> languages, then yes, we could start work in those areas. But right now I don't believe\n> for a second that RDF is relatively undeployed because we've not created enough\n> accompanying Web standards. When RDF is used, eg. in RSS, or Dublin Core, it is often\n> 'on faith', ie because people are anticipating some payback from using it where\n> they could have adopted a pre-RDF or vanilla XML solution. Many people are still\n> waiting to see what their RDF dabblings bought them.\n> \n> By focussing phase two on public Web deployment, I believe we will have a good\n> chance of increasing the number of RDF documents and RDF tools and RDF-basd services\n> that are visible to folk investigating the technology. Since RDF is all about\n> data merging and network effects, it becomes a stronger platform for information\n> management with every new shared document that uses it. This, if nothing else, should\n> draw our attention towards priorities that encourage the publication of RDF/XML\n> documents on the Web.\n> \n> If this account of a theme for phase two is at all persuasive, I think we could\n> derrive some specific work items and priorities. But let's agree on what we're trying\n> to achieve, first. Even if it something as almost-crass as 'lots of RDF documents\n> on lots of Web sites'. Stating the obvious might be worthwhile, I suspect.\n> \n> cheers,\n> \n> Dan\n> \n> ps. i'll probably forward this to a public archived mailing list, for\n> b/g in discussions in SWAD-Europe and the RDFIG.\n\n\n\n"
        },
        {
            "subject": "Agenda for face to fac",
            "content": "Hi everyone, \n\nI am putting together the agenda for the face to face meeting next Tuesday. \nCould you please forward any items that you would like to see covered to me by \nclose of play tomorrow (Weds 15th Jan)?\n\nThanks, \n\nKate..\n\n----------------------\nKate Sharp\nService Manager, Biz/ed and SWAD Europe Project Manager\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "RE: A proposed theme for SW Activity phase 2: 'SW on the Web",
            "content": "Dan,\n\nIt would be good to see more RDF \"out there\".  Getting real use (\"real\"\nbeing relative here!) both increases the visibility of the semantic web and\nfuels the software that makes it all go.  We need to ask what would make for\nmore RDF produced and consumed.\n\nIt is hard today to author RDF or to use RDF.  One really needs to be\ncomfortable with the specs to make serious progress, especially if others\nare going to use the RDF.  For that reason, I think there is much to do in\nthe software tools for RDF to make the barriers to its use much less.\n\nThis is especially true of using RDF read from elsewhere - people will be\nencouraged to add/create RDF to their webs when people think it enhances the\nvalue of their pages.\n\nSo - \"yes\" to use of RDF on the public web, but it is a bit of a \"both\" not\n\"either/or\".\n\nAndy\n\n\n-----Original Message-----\nFrom: Dave Reynolds [mailto:der@hplb.hpl.hp.com] \nSent: 14 January 2003 15:37\nTo: Dan Brickley\nCc: public-esw@w3.org\nSubject: Re: A proposed theme for SW Activity phase 2: 'SW on the Web'\n\n\n\nI mostly agree but with a slight note of caution.\n\nI agree that it is best to pick one, or a small number of, focused\napplication\nclasses. I agree that success on the \"public web\" would carry more impact\nthan\nmany alternatives and should be the target if possible.\n\nMy caution is that the semantic web is primarily about machine readable data\nand\nthe public web is, currently, primarily about human readable data. This\ntends to\nleave the role of the semantic web technology on the public web as mostly\nconcerned with metadata about otherwise human readable documents. Metadata\nis\ncertainly useful but (a) is often internal to a site and so benefits less\nfrom\nstandardization and (b) is subject to the bottleneck that people avoid\nproviding\nmetadata if they possibly can. \n\nNow I *do* think there are roles for semantic web technologies in the public\nweb, otherwise we wouldn't have proposed semantic blogging and semantic\nportals\nas our two demonstrator apps! However, I'm not sure we have a clear idea of\nthe\nmost useful roles. So \"yes\" to targeting the public web, but work needs to\ndone\nto make that more specific before you turn it into work priorities.\n\nDave\n[The use of \"I\" lots of times is meant to indicate that this is a personal\nopinion.]\n\nDan Brickley wrote:\n> \n> Attached is a message I've just sent to the W3C Semantic Web Coordination\nGroup\n> list, where we are discussing priorities to propose for phase two of the\n> Semantic Web Activity, beginning later in the spring.  The mail archives\nfor SWCG are\n> on the W3C Member website at\nhttp://lists.w3.org/Archives/Member/w3c-semweb-cg/\n> so passwords are needed to track that discussion.\n> \n> Needless to say the attached view[1] is just my personal opinion. I'd be\ninterested\n> in the views of SWAD-Europe folk on how they see things, personal views or\notherwise.\n> \n> More context: W3C SW page, http://www.w3.org/2001/sw/ and current\n> Activity statement: http://www.w3.org/2001/sw/Activity#\n> \n> Dan\n> \n> [1] http://lists.w3.org/Archives/Member/w3c-semweb-cg/2003Jan/0032.html\n> \n>\n----------------------------------------------------------------------------\n----\n> \n> Subject: A proposed theme for SW Activity phase 2: 'SW on the Web'\n> Resent-Date: Tue, 14 Jan 2003 08:04:49 -0500 (EST)\n> Resent-From: w3c-semweb-cg@w3.org\n> Date: Tue, 14 Jan 2003 08:04:45 -0500\n> From: Dan Brickley <danbri@w3.org>\n> To: w3c-semweb-cg@w3.org\n> CC: libby.miller@bristol.ac.uk\n> \n> Short version: phase two of W3C SW Activity should focus on getting RDF\nused in the\n> public Web. Everything else (especially new technology creation) is\nsecondary to that\n> goal.\n> \n> Here's a longer account of my view for SW Activity phase two priorities.\n> \n> (Ontologists, note that I write 'RDF' in its broader sense, as a\nFramework, for which\n> we now have an Ontology language; when I write 'RDF' pls read 'RDF/OWL' if\nyou prefer).\n> \n> RDF and SW/Ontology tools are very general. They could be used for almost\nanything\n> to do with modern information management. This broad applicability is what\n> draws many of us to the technology, but also a source of risk: by being\n> _usable_ for everything, we risk being _used_ for nothing. A reasurringly\nwide\n> range of groups are exploring the possibilities of RDF, yet RDF is not\ntailored to\n> any of their specific needs. We must be doing something right. But we\nshouldn't forget\n> that more tailored solutions in each field could easily discourage RDF\nadoption.\n> We can't please all the people, all the time.\n> \n> Something we might attempt in phase two is to focus our effects a bit on\nsome\n> particular fields for deploying RDF/OWL. I propose (this is so obvious as\nto\n> barely need saying, perhaps) that we focus on the public Web in phase two\nof the Activity.\n> By 'the public Web', I mean the work of Web masters, HTML authors,\nfocussing on\n> publically available sites who are currently mostly using\nHTML+CSS+jpeg/gif/png as their\n> content formats, and perhaps dabbling with RSS, Flash, SVG and other fancy\nnew stuff.\n> \n> I would like to see more RDF files on publically visible Web servers. RDF\nfiles that\n> use a variety of RDF schemas and Ontologies, and that link to other RDF\ndocuments\n> scattered around the Web. Once we have this, I'm confident the rest\n(intranets, domain\n> specific tools, RDF in backend databases etc.) will follow. Right now, if\nyou go\n> looking in the public Web for folk using RDF, there really isn't much out\nthere. A few\n> large datadumps, a few keys into webservice lookups or screen scrapes, a\nfair amount\n> of Dublin Core embedded (invalidly) in HTML or linked as separate files, a\npromising\n> number of RSS files, some of which are in RSS 1.0 (but not really\nexploiting the RDF\n> aspects of RSS), and a few hundred FOAF files. This is pretty modest\nsituation to be\n> in after 5+ years of RDF work. It isn't disasterous, but should be a cause\nfor concern,\n> and for focus as we design the next phase of the Activity.\n> \n> I would like us to go into phase two with some notion of success criteria:\nwhat would\n> count as having succeeded? I'm suggesting that an almost quantitative\napproach\n> may be applicable. If there are lots of RDF documents being used on\nordinary Web sites,\n> whether commercial, personal, Weblog, portal or academic, then something\nis going\n> right. If we end phase two without this, then we likely should think about\npacking\n> up and going home.\n> \n> Let's make phase two all about roll-out. Getting RDF, even simple, perhaps\nboring RDF,\n> on the agendas, web sites and CVs of ordinary Web masters and content\nproducers. That\n> RDF will be all the more meaningful if it draws on vocabularies enriched\nwith OWL, and\n> we will have our work cut out for us helping folk do this effectively.\n> \n> If, in attempting to get RDF deployed in this way, we find the reason for\nresistence\n> is that people need common APIs, more standard query languages, protocols,\nor rule\n> languages, then yes, we could start work in those areas. But right now I\ndon't believe\n> for a second that RDF is relatively undeployed because we've not created\nenough\n> accompanying Web standards. When RDF is used, eg. in RSS, or Dublin Core,\nit is often\n> 'on faith', ie because people are anticipating some payback from using it\nwhere\n> they could have adopted a pre-RDF or vanilla XML solution. Many people are\nstill\n> waiting to see what their RDF dabblings bought them.\n> \n> By focussing phase two on public Web deployment, I believe we will have a\ngood\n> chance of increasing the number of RDF documents and RDF tools and\nRDF-basd services\n> that are visible to folk investigating the technology. Since RDF is all\nabout\n> data merging and network effects, it becomes a stronger platform for\ninformation\n> management with every new shared document that uses it. This, if nothing\nelse, should\n> draw our attention towards priorities that encourage the publication of\nRDF/XML\n> documents on the Web.\n> \n> If this account of a theme for phase two is at all persuasive, I think we\ncould\n> derrive some specific work items and priorities. But let's agree on what\nwe're trying\n> to achieve, first. Even if it something as almost-crass as 'lots of RDF\ndocuments\n> on lots of Web sites'. Stating the obvious might be worthwhile, I suspect.\n> \n> cheers,\n> \n> Dan\n> \n> ps. i'll probably forward this to a public archived mailing list, for\n> b/g in discussions in SWAD-Europe and the RDFIG.\n\n\n\n"
        },
        {
            "subject": "Re: Trip report, IST2002 Copenhagen 0406 November 2002 (fwd",
            "content": "Charles, do you know where to forward this most appropriately?\n\nthanks\n\nLibby\n\n---------- Forwarded message ----------\nDate: Wed, 15 Jan 2003 16:15:56 +0000\nFrom: David Kraithman <d.a.kraithman@herts.ac.uk>\nTo: Libby.Miller@bristol.ac.uk\nSubject: Re: Trip report, IST2002 Copenhagen 04-06 November 2002 (fwd)\n\nLibby\n\nI saw your posting.  I am just about to go into a meeting with Steve\nConibear of UKRO to discuss our proposals to  extend the work that we have\nbeen doing on SMIL authoring systems and accessibility beyond\neducation.  If you received any other responses from people who might want\nto collaborate on this area I would be very interested in contacts.\n\nDavid Kraithman\nUniversity of Hertfordshire\n\n\n\n"
        },
        {
            "subject": "RDF query testcases",
            "content": "Hi all\n\nWe have some effort in SWAD-Europe [1] to write a document about RDF\nquery [see [2]]. Part of this will be FAQ-based - a start is here [3],\n(and I'd be grateful for any FAQs or answers).\n\nThe main reason for sending this message it because I've chatted to a\nfew people who feel that a collection of RDF query testcases would be a\nuseful thing to have, and I can put some effort into this - maybe as a\nminimum, finding out what's already available, and maybe look into some\nways of enabling one query language implementation to use another's\ntestcases.\n\nSo, would anyone out there like to share their test and their\nexperiences of writing them? I can infer that Jena and 4suite have\nthem; I think Mozilla has some too. I've got some here for Inkling:\n\nhttp://swordfish.rdfweb.org/rdfquery/tests/\nhttp://swordfish.rdfweb.org/rdfquery/rdf/\nhttp://swordfish.rdfweb.org/rdfquery/queries/\n\nBasically the test scripts read in\nhttp://swordfish.rdfweb.org/rdfquery/rdf/query-results-manifest.rdf\n\nwhich specifies the RDF/XML file to pull in, the query to use and the\nexpected number of rows in the resulting table. So it's only a very\nbasic test of whether the query engine is functioning.\n\nAny more? Any thoughts?\n\ncheers,\n\nLibby\n\n[1] http://www.w3.org/2001/sw/Europe/\n[2] http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-7.html\n[3] http://www.w3.org/2001/sw/Europe/reports/rdf_ql_comparison_report/\n\n\n\n"
        },
        {
            "subject": "Re: RDF query testcases",
            "content": "Libby,\n\nA possible additional [FA]Q?:   Can I enumerate the contents of a container \nusing a query?  A rdf:collection?  (The current version of my query code \nsupports both.  I find it very useful, especially the rdf:collection elements.)\n\n#g\n--\n\nAt 11:40 PM 1/15/03 +0000, Libby Miller wrote:\n\n\n>Hi all\n>\n>We have some effort in SWAD-Europe [1] to write a document about RDF\n>query [see [2]]. Part of this will be FAQ-based - a start is here [3],\n>(and I'd be grateful for any FAQs or answers).\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Agenda for SWAD Europe meetin",
            "content": "(FAO SWAD Europe project staff)\n\nHi everyone, \n\nhere is the agenda for Tuesday. As you will see there is an \nAM management/PM technical split. \n\nAgenda for SWAD Europe Project Meeting, 21/01/03\n\nMeeting to be held in the Hawaii Suite, ILRT, 8 - 10, Berkeley Square, Clifton,\nBS8 1HH details available at: http://www.ilrt.bris.ac.uk/aboutus/finding_ilrt\n\n10.00 - 10.30 Coffee\n10.30 - 12.00 Management issues (cost statements, consortium agreement, \nreporting queries, meetings, and update on deliverables)\n\n12.00 - 13.00 Lunch at ILRT\n\n13.00 - 14.00 Workshops and marketing (WP3)\n14.00 - 16.30 Discussion of ongoing and forthcoming work packages (in \nparticular 2, 4, 5, 7, 8, 9, 10, 12.1, 12.2, 12.4). There will be approx 15 \nminutes per work package for you to update the group on progress and raise any \nother technical issues related to these work packages. \n\nFor the afternoon session on marketing to follow up Caroline Meek's email about\ngood publicity materials please bring along anything that you have been \ngiven/picked up at conferences etc that has had an impact! \n\nThanks, I look forward to seeing you on Tuesday.\n\nKate..\n----------------------\nKate Sharp\nService Manager, Biz/ed and SWAD Europe Project Manager\nInstitute for Learning and Research Technology\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "added Nikki Rogers, Paul Shabajee to swade mailing lis",
            "content": "Just to mention that I've added Nikki Rogers(ILRT), Paul Shabajee(HP/ILRT) \nto public-esw@w3.org. Nikki is working on SemWeb<->Web Services in WP4,\nPaul is involved with HP's demonstrator work[1] in WP12. Welcome Nikki, Paul!\n\nDan\n\n\n[1] http://www.w3.org/2001/sw/Europe/reports/chosen_demos_rationale_report/hp-applications-selection.html\nhttp://www.w3.org/2001/sw/Europe/reports/chosen_demos_rationale_report/hp-applications-survey.html\n \n\n\n\n"
        },
        {
            "subject": "Movable Type (weblog management) installation for SWADEurop",
            "content": "Hi\n\nI have set up an installation of the Movable Type system, for use by \ninterested project partners and collaborators. It is a very popular and pretty slick \nWeblog management package, not opensource but free for non-profit use(*). I've \nused it elsewhere, as has Dave and others. Chatting with Paul Shabajee earlier this \nweek, we noted the overlap with the planned HP demo work on Semantic Blogging/weblogging \nand bibliographic information; we thought that getting some experience with \nthis package would be good background to research/demos elsewhere in the package. \n\nCurrently I have set up accounts for myself, Kate, Nikki, Charles, Libby, Dave. I \ncan create additional accounts for any SWAD-Europe project participants who are \ninterested: please let me know, providing your W3C member account Web username. For \ntechnical and admin reasons this is on a separate box and subdomain from the rest of \nthe W3C website, but I'd like at least to make sure usernames match up. Ideally\nit would be good to have occasional updates, however informal, from each project partner.\n\nCurrently, there is just one Weblog set up under this installation; we could add \nmore, eg with invited participation from the RDF Interest Group on specific topics \n(calendaring, query, thesaurus...). The site currently has some brief news items on it \nfrom me, Libby (re calendaring) and Dave (re his workpackage). There's probably a \nbalance to be found between putting stuff on the weblog (better for broad dissemination, \nclassification etc of articles) versus posting it to this list. I'm sure we'll \nfigure out which works for which purpose as time goes on. For me at least, I find \nweblogs a useful way to keep research notes and be more open about what I'm working on...\n\n\nPublic URL for 'esw' weblog:  http://esw.w3.org/mt/esw/\nAdmin interface: http://esw.w3.org/mtcgi/mt.cgi (username/passwd'd)\nMovable Type homepage:http://www.movabletype.org/\n\nIt also automatically generates an RSS 1.0 (RDF) feed \ndescribing new items, so our postings can get picked up by RSS syndicators.\n\nRSS feed:http://esw.w3.org/mt/esw/index.rdf\n\nLet me know if you have any questions. \n\ncheers,\n\nDan\n\n\n\n\n(*)I intend to register a copy, regardless of whether we're non-profit or not as \na project. \n\n\n\n"
        },
        {
            "subject": "RE: RDF query testcases",
            "content": "The test cases for the RDQL in Jena are shipped with the standard Jena\ndistribution - you can pull them out of the CVS repository on SourceForge as\nwell.\n\nThe control (manifest) file is not RDF - but it could be.  Tests take the\nform \n(query, data, expected result set) and there is code that tests the expected\nresult set is equivalent (same values for variables, subject to bNode-isms,\nnumber or rows etc) to the actual results obtained.  I don't test failure\ncases (i.e. that queries that are wrong fail in the expectedly wrong way).\n\nFor the FAQ: Alberto has gone a great job with:\n\nhttp://rdfstore.sourceforge.net/2002/06/24/rdf-query/query-use-cases.html\n\nAndy\n\n-----Original Message-----\nFrom: Libby Miller [mailto:Libby.Miller@bristol.ac.uk] \nSent: 15 January 2003 23:40\nTo: www-rdf-rules@w3.org\nCc: public-esw@w3.org\nSubject: RDF query testcases?\n\n\n\n\nHi all\n\nWe have some effort in SWAD-Europe [1] to write a document about RDF\nquery [see [2]]. Part of this will be FAQ-based - a start is here [3],\n(and I'd be grateful for any FAQs or answers).\n\nThe main reason for sending this message it because I've chatted to a\nfew people who feel that a collection of RDF query testcases would be a\nuseful thing to have, and I can put some effort into this - maybe as a\nminimum, finding out what's already available, and maybe look into some\nways of enabling one query language implementation to use another's\ntestcases.\n\nSo, would anyone out there like to share their test and their\nexperiences of writing them? I can infer that Jena and 4suite have\nthem; I think Mozilla has some too. I've got some here for Inkling:\n\nhttp://swordfish.rdfweb.org/rdfquery/tests/\nhttp://swordfish.rdfweb.org/rdfquery/rdf/\nhttp://swordfish.rdfweb.org/rdfquery/queries/\n\nBasically the test scripts read in\nhttp://swordfish.rdfweb.org/rdfquery/rdf/query-results-manifest.rdf\n\nwhich specifies the RDF/XML file to pull in, the query to use and the\nexpected number of rows in the resulting table. So it's only a very\nbasic test of whether the query engine is functioning.\n\nAny more? Any thoughts?\n\ncheers,\n\nLibby\n\n[1] http://www.w3.org/2001/sw/Europe/\n[2] http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-7.html\n[3] http://www.w3.org/2001/sw/Europe/reports/rdf_ql_comparison_report/\n\n\n\n"
        },
        {
            "subject": "Re: RDF query testcases",
            "content": "On Thursday, January 16, 2003, at 02:03  PM, Seaborne, Andy wrote:\n\n>\n> The test cases for the RDQL in Jena are shipped with the standard Jena\n> distribution - you can pull them out of the CVS repository on  \n> SourceForge as\n> well.\n\nsame here - we got some simple RDQL regression tests distributed with  \nrdfstore and you can have a look to them on the CVS rep at sourceforge.\n\n>\n> The control (manifest) file is not RDF - but it could be.  Tests take  \n> the\n> form\n> (query, data, expected result set) and there is code that tests the  \n> expected\n> result set is equivalent (same values for variables, subject to  \n> bNode-isms,\n> number or rows etc) to the actual results obtained.  I don't test  \n> failure\n> cases (i.e. that queries that are wrong fail in the expectedly wrong  \n> way).\n\nwe are not going that far at the moment just having some test data,  \nqueries and some expected num of results; everything is in perl code at  \nthe moment but it would be great to have some good ones expressed in  \nsome RDF, like Libby/Dan ones and jena.\n\n>\n> For the FAQ: Alberto has gone a great job with:\n>\n> http://rdfstore.sourceforge.net/2002/06/24/rdf-query/query-use- \n> cases.html\n\nI was proposing to Libby eventually the possibility to add links on  \nthat page to actually add test data to specific use-cases or examples  \ntogether with some test results i.e. link up the tests to the query  \nlanguage example to the use-cases.\n\nis there an RDF Schema for Libby's tests-manifest somewhere? not that I  \nneed one at the moment :-)\n\ncheers\n\nAlberto\n\n\n\n"
        },
        {
            "subject": "Re: RDF query testcases",
            "content": "Hi Libby!\n\ngood question; it seems to us that a query is simply\na set of triples where bnodes play the role of variables\nwe then basically can apply a resolution process\n\n[[[\nThe resolution process starts with a query. A query is a tripleset.\nThe query will be matched against the triplesets of the initial\ngraph G and against the rules. The set unifies with a rule when\none of the triples of the set unifies with the consequent of the\nrule. The set unifies with another set if all triples in the set\nunify with a triple of the other set. This can possibly be done\nin different ways. The result of the unification of two triple\nsets is a list of substitutionlists.\n]]]\nhttp://www.agfa.com/w3c/2002/02/thesis/An_inference_engine_for_RDF.html\nand this is work done by Guido Naudts in his master thesis\n\nwe also have some running code at http://www.agfa.com/w3c/euler/\nand some testcases starting at http://www.agfa.com/w3c/euler/etc5\n\nbut there's still a lot to do...\n\n-- ,\nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n                                                                                                                       \n                    Libby Miller                                                                                       \n                    <Libby.Miller@bris       To:     www-rdf-rules@w3.org                                              \n                    tol.ac.uk>               cc:     public-esw@w3.org                                                 \n                    Sent by:                 Subject:     RDF query testcases?                                         \n                    www-rdf-rules-requ                                                                                 \n                    est@w3.org                                                                                         \n                                                                                                                       \n                                                                                                                       \n                    2003-01-16 12:40                                                                                   \n                    AM                                                                                                 \n                                                                                                                       \n                                                                                                                       \n\n\n\n\n\n\nHi all\n\nWe have some effort in SWAD-Europe [1] to write a document about RDF\nquery [see [2]]. Part of this will be FAQ-based - a start is here [3],\n(and I'd be grateful for any FAQs or answers).\n\nThe main reason for sending this message it because I've chatted to a\nfew people who feel that a collection of RDF query testcases would be a\nuseful thing to have, and I can put some effort into this - maybe as a\nminimum, finding out what's already available, and maybe look into some\nways of enabling one query language implementation to use another's\ntestcases.\n\nSo, would anyone out there like to share their test and their\nexperiences of writing them? I can infer that Jena and 4suite have\nthem; I think Mozilla has some too. I've got some here for Inkling:\n\nhttp://swordfish.rdfweb.org/rdfquery/tests/\nhttp://swordfish.rdfweb.org/rdfquery/rdf/\nhttp://swordfish.rdfweb.org/rdfquery/queries/\n\nBasically the test scripts read in\nhttp://swordfish.rdfweb.org/rdfquery/rdf/query-results-manifest.rdf\n\nwhich specifies the RDF/XML file to pull in, the query to use and the\nexpected number of rows in the resulting table. So it's only a very\nbasic test of whether the query engine is functioning.\n\nAny more? Any thoughts?\n\ncheers,\n\nLibby\n\n[1] http://www.w3.org/2001/sw/Europe/\n[2] http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-7.html\n[3] http://www.w3.org/2001/sw/Europe/reports/rdf_ql_comparison_report/\n\n\n\n"
        },
        {
            "subject": "Re: RDF query testcases",
            "content": "Hi Libby!\n\ngood question; it seems to us that a query is simply\na set of triples where bnodes play the role of variables\nwe then basically can apply a resolution process\n\n[[[\nThe resolution process starts with a query. A query is a tripleset.\nThe query will be matched against the triplesets of the initial\ngraph G and against the rules. The set unifies with a rule when\none of the triples of the set unifies with the consequent of the\nrule. The set unifies with another set if all triples in the set\nunify with a triple of the other set. This can possibly be done\nin different ways. The result of the unification of two triple\nsets is a list of substitutionlists.\n]]]\nhttp://www.agfa.com/w3c/2002/02/thesis/An_inference_engine_for_RDF.html\nand this is work done by Guido Naudts in his master thesis\n\nwe also have some running code at http://www.agfa.com/w3c/euler/\nand some testcases starting at http://www.agfa.com/w3c/euler/etc5\n\nbut there's still a lot to do...\n\n-- ,\nJos De Roo, AGFA http://www.agfa.com/w3c/jdroo/\n\n\n                                                                                                                       \n                    Libby Miller                                                                                       \n                    <Libby.Miller@bris       To:     www-rdf-rules@w3.org                                              \n                    tol.ac.uk>               cc:     public-esw@w3.org                                                 \n                    Sent by:                 Subject:     RDF query testcases?                                         \n                    www-rdf-rules-requ                                                                                 \n                    est@w3.org                                                                                         \n                                                                                                                       \n                                                                                                                       \n                    2003-01-16 12:40                                                                                   \n                    AM                                                                                                 \n                                                                                                                       \n                                                                                                                       \n\n\n\n\n\n\nHi all\n\nWe have some effort in SWAD-Europe [1] to write a document about RDF\nquery [see [2]]. Part of this will be FAQ-based - a start is here [3],\n(and I'd be grateful for any FAQs or answers).\n\nThe main reason for sending this message it because I've chatted to a\nfew people who feel that a collection of RDF query testcases would be a\nuseful thing to have, and I can put some effort into this - maybe as a\nminimum, finding out what's already available, and maybe look into some\nways of enabling one query language implementation to use another's\ntestcases.\n\nSo, would anyone out there like to share their test and their\nexperiences of writing them? I can infer that Jena and 4suite have\nthem; I think Mozilla has some too. I've got some here for Inkling:\n\nhttp://swordfish.rdfweb.org/rdfquery/tests/\nhttp://swordfish.rdfweb.org/rdfquery/rdf/\nhttp://swordfish.rdfweb.org/rdfquery/queries/\n\nBasically the test scripts read in\nhttp://swordfish.rdfweb.org/rdfquery/rdf/query-results-manifest.rdf\n\nwhich specifies the RDF/XML file to pull in, the query to use and the\nexpected number of rows in the resulting table. So it's only a very\nbasic test of whether the query engine is functioning.\n\nAny more? Any thoughts?\n\ncheers,\n\nLibby\n\n[1] http://www.w3.org/2001/sw/Europe/\n[2] http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-7.html\n[3] http://www.w3.org/2001/sw/Europe/reports/rdf_ql_comparison_report/\n\n\n\n"
        },
        {
            "subject": "RE: Movable Type (weblog management) installation for SWADEurop",
            "content": "Excellent. Blogged [1] & blogrolled [2] ;-)\n\nTwo related things I'd like to see around here somewhere (both within SWAD-E\nscope?) :\n\n* a list of semweb related blogs (I've got a handful listed on [2], but most\nof those, e.g. dajobe's, I found by chance)\n\n* tips/scripts for semweb-enabling blogging tools (things on top of RSS 1.0\nfeeds) - dogfood!\n\nCoincidentally I just set up an Movable Type blog [1] for personal stuff\n(the other one's really just for bookmarking semweb-related sites), so I'd\nbe particularly interested in anything MT+RDF you come up with.\n\nCheers,\nDanny.\n\n\n-----------\n\n[1] http://dannyayers.com\n[2] http://www.citnames.com/blog/\n\n\n\n\n>-----Original Message-----\n>From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n>Behalf Of Dan Brickley\n>Sent: 16 January 2003 12:45\n>To: public-esw@w3.org\n>Subject: Movable Type (weblog management) installation for SWAD-Europe\n>\n>\n>\n>Hi\n>\n>I have set up an installation of the Movable Type system, for use by\n>interested project partners and collaborators. It is a very\n>popular and pretty slick\n>Weblog management package, not opensource but free for non-profit\n>use(*). I've\n>used it elsewhere, as has Dave and others. Chatting with Paul\n>Shabajee earlier this\n>week, we noted the overlap with the planned HP demo work on\n>Semantic Blogging/weblogging\n>and bibliographic information; we thought that getting some\n>experience with\n>this package would be good background to research/demos elsewhere\n>in the package.\n>\n>Currently I have set up accounts for myself, Kate, Nikki, Charles,\n>Libby, Dave. I\n>can create additional accounts for any SWAD-Europe project\n>participants who are\n>interested: please let me know, providing your W3C member account\n>Web username. For\n>technical and admin reasons this is on a separate box and\n>subdomain from the rest of\n>the W3C website, but I'd like at least to make sure usernames\n>match up. Ideally\n>it would be good to have occasional updates, however informal,\n>from each project partner.\n>\n>Currently, there is just one Weblog set up under this\n>installation; we could add\n>more, eg with invited participation from the RDF Interest Group on\n>specific topics\n>(calendaring, query, thesaurus...). The site currently has some\n>brief news items on it\n>from me, Libby (re calendaring) and Dave (re his workpackage).\n>There's probably a\n>balance to be found between putting stuff on the weblog (better\n>for broad dissemination,\n>classification etc of articles) versus posting it to this list.\n>I'm sure we'll\n>figure out which works for which purpose as time goes on. For me\n>at least, I find\n>weblogs a useful way to keep research notes and be more open about\n>what I'm working on...\n>\n>\n>Public URL for 'esw' weblog:  http://esw.w3.org/mt/esw/\n>Admin interface: http://esw.w3.org/mtcgi/mt.cgi\n>(username/passwd'd)\n>Movable Type homepage:http://www.movabletype.org/\n>\n>It also automatically generates an RSS 1.0 (RDF) feed\n>describing new items, so our postings can get picked up by RSS syndicators.\n>\n>RSS feed:http://esw.w3.org/mt/esw/index.rdf\n>\n>Let me know if you have any questions.\n>\n>cheers,\n>\n>Dan\n>\n>\n>\n>\n>(*)I intend to register a copy, regardless of whether we're\n>non-profit or not as\n>a project.\n>\n\n\n\n"
        },
        {
            "subject": "IBIS vocab for sembloggin",
            "content": "I didn't realise Semantic Blogging was being followed up as an e-sw case\nstudy, until I found the link on the new blog...\n\nAnyhow, one of the apps I've been working on for my Ideagraph project is\nsemantic blogging and to help with this I've started writing up a vocabulary\n(RDFS) for 'Issue-Based Information Systems', the idea being to use terms\nlike 'Argument', 'Question', 'pro', 'con' within blog (and other) discussion\nthreads.\n\nhttp://purl.org/ibis\n\nVery much a work in progress, suggestions welcome.\n\nCheers,\nDanny.\n\n-----------\n\nhttp://dannyayers.com\n\n\"The lyf so short, the craft so long to lerne.\" - Chaucer\n\n\n\n"
        },
        {
            "subject": "RE: Movable Type (weblog management) installation for SWADEurop",
            "content": "Hi Danny,\n\nco-coincidentally MT just happens to be the blogging tool we are playing\naround with at HP for the SWAD-E demonstrator 12.1\nWe're likely to use it in some form so it's likely that we will produce some\nMT+RDF combo.\n\nCheers\n\nSteve\n\nPS I like your semweb blog, a very useful source of info!\n\n-----Original Message-----\nFrom: Danny Ayers [mailto:danny666@virgilio.it]\nSent: 17 January 2003 09:54\nTo: Dan Brickley; public-esw@w3.org\nSubject: RE: Movable Type (weblog management) installation for\nSWAD-Europe\n\n\n\nExcellent. Blogged [1] & blogrolled [2] ;-)\n\nTwo related things I'd like to see around here somewhere (both within SWAD-E\nscope?) :\n\n* a list of semweb related blogs (I've got a handful listed on [2], but most\nof those, e.g. dajobe's, I found by chance)\n\n* tips/scripts for semweb-enabling blogging tools (things on top of RSS 1.0\nfeeds) - dogfood!\n\nCoincidentally I just set up an Movable Type blog [1] for personal stuff\n(the other one's really just for bookmarking semweb-related sites), so I'd\nbe particularly interested in anything MT+RDF you come up with.\n\nCheers,\nDanny.\n\n\n-----------\n\n[1] http://dannyayers.com\n[2] http://www.citnames.com/blog/\n\n\n\n\n>-----Original Message-----\n>From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n>Behalf Of Dan Brickley\n>Sent: 16 January 2003 12:45\n>To: public-esw@w3.org\n>Subject: Movable Type (weblog management) installation for SWAD-Europe\n>\n>\n>\n>Hi\n>\n>I have set up an installation of the Movable Type system, for use by\n>interested project partners and collaborators. It is a very\n>popular and pretty slick\n>Weblog management package, not opensource but free for non-profit\n>use(*). I've\n>used it elsewhere, as has Dave and others. Chatting with Paul\n>Shabajee earlier this\n>week, we noted the overlap with the planned HP demo work on\n>Semantic Blogging/weblogging\n>and bibliographic information; we thought that getting some\n>experience with\n>this package would be good background to research/demos elsewhere\n>in the package.\n>\n>Currently I have set up accounts for myself, Kate, Nikki, Charles,\n>Libby, Dave. I\n>can create additional accounts for any SWAD-Europe project\n>participants who are\n>interested: please let me know, providing your W3C member account\n>Web username. For\n>technical and admin reasons this is on a separate box and\n>subdomain from the rest of\n>the W3C website, but I'd like at least to make sure usernames\n>match up. Ideally\n>it would be good to have occasional updates, however informal,\n>from each project partner.\n>\n>Currently, there is just one Weblog set up under this\n>installation; we could add\n>more, eg with invited participation from the RDF Interest Group on\n>specific topics\n>(calendaring, query, thesaurus...). The site currently has some\n>brief news items on it\n>from me, Libby (re calendaring) and Dave (re his workpackage).\n>There's probably a\n>balance to be found between putting stuff on the weblog (better\n>for broad dissemination,\n>classification etc of articles) versus posting it to this list.\n>I'm sure we'll\n>figure out which works for which purpose as time goes on. For me\n>at least, I find\n>weblogs a useful way to keep research notes and be more open about\n>what I'm working on...\n>\n>\n>Public URL for 'esw' weblog:  http://esw.w3.org/mt/esw/\n>Admin interface: http://esw.w3.org/mtcgi/mt.cgi\n>(username/passwd'd)\n>Movable Type homepage:http://www.movabletype.org/\n>\n>It also automatically generates an RSS 1.0 (RDF) feed\n>describing new items, so our postings can get picked up by RSS syndicators.\n>\n>RSS feed:http://esw.w3.org/mt/esw/index.rdf\n>\n>Let me know if you have any questions.\n>\n>cheers,\n>\n>Dan\n>\n>\n>\n>\n>(*)I intend to register a copy, regardless of whether we're\n>non-profit or not as\n>a project.\n>\n\n\n\n"
        },
        {
            "subject": "RE: Movable Type (weblog management) installation for SWADEurop",
            "content": ">co-coincidentally MT just happens to be the blogging tool we are playing\n>around with at HP for the SWAD-E demonstrator 12.1\n>We're likely to use it in some form so it's likely that we will\n>produce some\n>MT+RDF combo.\n\nThat's great! I'd really like to see some more interesting stuff done with\nit (trackback etc is pretty cool already), especially since virtually\neveryone seems to be viewing RSS 1.0 merely as just another XML dialect\nrather than using the RDF capabilities. Even something as simple as a\ntemplate for including FOAF links could make a lot of difference.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "Re: Movable Type (weblog management) installation for SWADEurop",
            "content": "* Cayzer, Steve <Steve_Cayzer@hplb.hpl.hp.com> [2003-01-17 10:37-0000]\n> Hi Danny,\n> \n> co-coincidentally MT just happens to be the blogging tool we are playing\n> around with at HP for the SWAD-E demonstrator 12.1\n> We're likely to use it in some form so it's likely that we will produce some\n> MT+RDF combo.\n\nThat would be great, as there are 100s of weblog sites that use MT, and many \nof the weblogging community seem interested in exploring new ideas for \nimproved syndication etc. (especially if they are practical and have some \ntangible benefit).\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: IBIS vocab for sembloggin",
            "content": "Hi Danny,\n\nthe vocabulary stuff you are looking at sounds like it is extending\nthe thread vocabulary produced for Annotea (or for that matter the original\nAnnotea vocabulary of annotation types) to allow for discussion threads\nto be tracked. This seems to me like a good idea.\n\nhttp://www.w3.org/2001/03/thread\n\nThe ability to provide user-friendly interfaces for this (such as the\nicon-selection that Amaya has for marking different types of annotation - see\nthe help file at\nhttp://www.w3.org/Amaya/User/attaching_annotations/configuring_icons) is a\npromising paralell for the use of graphic RDF editors (IdeaGraph, IsaViz,\nRDFAuthor, etc)\n\ncheers\n\nChaals\n\nOn Fri, 17 Jan 2003, Danny Ayers wrote:\n\n>\n>I didn't realise Semantic Blogging was being followed up as an e-sw case\n>study, until I found the link on the new blog...\n>\n>Anyhow, one of the apps I've been working on for my Ideagraph project is\n>semantic blogging and to help with this I've started writing up a vocabulary\n>(RDFS) for 'Issue-Based Information Systems', the idea being to use terms\n>like 'Argument', 'Question', 'pro', 'con' within blog (and other) discussion\n>threads.\n>\n>http://purl.org/ibis\n>\n>Very much a work in progress, suggestions welcome.\n>\n>Cheers,\n>Danny.\n>\n>-----------\n>\n>http://dannyayers.com\n>\n>\"The lyf so short, the craft so long to lerne.\" - Chaucer\n>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: IBIS vocab for sembloggin",
            "content": ">the vocabulary stuff you are looking at sounds like it is extending\n>the thread vocabulary produced for Annotea (or for that matter the original\n>Annotea vocabulary of annotation types) to allow for discussion threads\n>to be tracked. This seems to me like a good idea.\n>\n>http://www.w3.org/2001/03/thread\n\nThanks Chaals, this is excellent - it's been a long time since I looked at\nthe Annotea material and I'd forgotten all about this stuff. You're right -\nIBIS should mesh well with the thread vocab.\n\nfyi, my starting point with the vocab was the other IBIS material by Jack\nPark (of Topic Map fame) and others. There's also the ScholOnto vocabulary,\nwhich is promising but IMHO a bit too focussed on discussing academic papers\nand also Dave Menendez's Thread Description Language\n(http://www.eyrie.org/~zednenem/2002/web-threads/) which is more focussed on\nblogs etc but (again IMHO) crams a little too much in.\n\n>The ability to provide user-friendly interfaces for this (such as the\n>icon-selection that Amaya has for marking different types of\n>annotation - see\n>the help file at\n>http://www.w3.org/Amaya/User/attaching_annotations/configuring_icons) is a\n>promising paralell for the use of graphic RDF editors (IdeaGraph, IsaViz,\n>RDFAuthor, etc)\n\nThanks again - one sub-block of Ideagraph I've nearly got working is holding\nuser preferences in RDF (not unrelated to the XUL kind of thing, but closer\nto the Java Properties class for holding attribute-value pairs). Tying this\ntogether with the thread terms could look very cool.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "RDF query for SQL dat",
            "content": "Jan,\n\nDid you see Eric's post? http://lists.w3.org/Archives/Public/www-rdf-interest/2003Jan/0102.html\n\nHow does this compare to http://www.w3.org/2001/sw/Europe/reports/scalable_rdbms_mapping_report/ ?\n\nDan\n\n\nattached mail follows:\n\nalgae [1] and cwm [2] now both have the ability to query a relational\ndatabase with an application-specific schema. An example OrderTracking\ndatabase is queryable via MySQL at swada.w3.org with the username\nrdftest and no password. The n3 (see example [3])\n\n :o Orders:customer :c .\n :o Orders:product :p .\n :o Orders:orderDate :d .\n\n :p Products:name :productName .\n\n :c Customers:familyName :first .\n :c Customers:givenName :last .\n :c Customers:billingAddress :billAddr .\n\n :billAddr Addresses:street :billStreet .\n :billAddr Addresses:city :billCity .\n :billAddr Addresses:state :billState .\n\nis translated into an SQL query\n SELECT Products_0.id AS p_id,\n          Products_0.name AS productName_name,\n        Addresses_0.id AS billAddr_id,\n          Addresses_0.city AS billCity_city,\n          Addresses_0.state AS billState_state,\n          Addresses_0.street AS billStreet_street,\n        Customers_0.id AS c_id,\n          Customers_0.familyName AS first_familyName,\n          Customers_0.givenName AS last_givenName,\n        Orders_0.id AS o_id,\n          Orders_0.orderDate AS d_orderDate\n FROM Products AS Products_0, Addresses AS Addresses_0, Customers AS Customers_0, Orders AS Orders_0\n WHERE Customers_0.billingAddress=Addresses_0.id\n   AND Orders_0.customer=Customers_0.id\n   AND Orders_0.product=Products_0.id\n\nand executed. The results are mapped back into RDF statements,\navailable for report or furthur inferencing. The algae equivilent (see\nexample [4]) is\n       (OT::Orders.customer?o?c)\n       (OT::Orders.product?o?p)\n       (OT::Orders.orderDate?o?d)\n       (OT::Products.name?p?productName)\n       (OT::Customers.givenName?c?first)\n       (OT::Customers.familyName?c?last)\n       (OT::Customers.billingAddress?c?billAddr)\n       (OT::Addresses.street?billAddr ?billStreet)\n       (OT::Addresses.city?billAddr ?billCity)\n       (OT::Addresses.state?billAddr ?billState)\n\nOne implications of this is that an awful lot of rdb data could be\neasily made available to RDF tools. Another is that mapping such data\nto RDF can be a way to join disparate rdbs. And a third is that RDF\ndata can be made to scale on the same order as rdbs, which is\ngenerally acknowledged as very well.\n\nAnyways, it would be fun to get some feedback if folks want to try out\neither the cwm or algae implementations. If you experiment with cwm,\nyou will need to install mysql drivers for python (debian package\npython2.2-mysqldb) and for algae you will need mysql drivers for perl\n(debian package libdbd-mysql-perl). The perl version has the ability\nto do ORs [5] NOTs, [5] and outer joins [6]. I haven't worked out the\nnotation for that in n3 but it should be feasible to port to cwm as\nwell. As an example, the algae query\n       (OT::Orders.customer?o?c)\n       (OT::Orders.product?o?p)\n       (OT::Orders.orderDate?o?d)\n       (OT::Products.name?p?productName)\n       (OT::Customers.givenName?c?first)\n       (OT::Customers.familyName?c?last)\n       (OT::Customers.billingAddress ?c?billAddr)\n       (OT::Addresses.contact?billAddr ?biller)\n       (OT::Customers.givenName?biller?bFirst)\n       (OT::Customers.familyName?biller?bLast)\n       ~(OT::Orders.shippingAddress?o?shipAddr)\n       ~(OT::Addresses.contact?shipAddr ?signer)\n       (OT::Customers.givenName?signer?sFirst)\n       (OT::Customers.familyName?signer?sLast)\n\nresults in the SQL query\n SELECT Orders_0.id AS o_id,\n Orders_0.orderDate AS d_orderDate,\n        Products_0.id AS p_id,\n Products_0.name AS productName_name,\n        Customers_0.id AS c_id,\n Customers_0.givenName AS first_givenName,\n Customers_0.familyName AS last_familyName,\n        Addresses_0.id AS billAddr_id,\n Addresses_0.street AS billStreet_street,\n Addresses_0.city AS billCity_city,\n Addresses_0.state AS billState_state,\n        Addresses_1.id AS shipAddr_id,\n Addresses_1.street AS shipStreet_street,\n Addresses_1.city AS shipCity_city,\n Addresses_1.state AS shipState_state\n FROM Orders AS Orders_0\n      INNER JOIN Customers AS Customers_0 ON Orders_0.customer=Customers_0.id\n      INNER JOIN Products AS Products_0 ON Orders_0.product=Products_0.id\n      INNER JOIN Addresses AS Addresses_0 ON Customers_0.billingAddress=Addresses_0.id\n      LEFT OUTER JOIN Addresses AS Addresses_1 ON (Orders_0.shippingAddress=Addresses_1.id)\n\nand the data\n+------+----------+------------+------+----------+--------+--------+\n| first|      last| productName|bFirst|     bLast|  sFirst|   sLast|\n|------|----------|------------|------|----------|--------|--------|\n|\"Chip\"|\"Thompson\"| \"nose ring\"|\"Biff\"|\"Thompson\"|    NULL|    NULL|\n|\"Chip\"|\"Thompson\"|\"other ring\"|\"Biff\"|\"Thompson\"|\"Eustis\"|\"Walker\"|\n|\"Biff\"|\"Thompson\"|      \"pool\"|\"Biff\"|\"Thompson\"|    NULL|    NULL|\n|\"Chip\"|\"Thompson\"|\"skateboard\"|\"Biff\"|\"Thompson\"|    NULL|    NULL|\n+------+----------+------------+------+----------+--------+--------+\n\nAnother interesting feature is that both can trap under-constrained\nqueries and throw an exception before executing such potentially\nexpensive (and likely useless) queries. They can also do an\noverconstraint check and warn the certain tables are linked to others\nin more than one way, even if it is via some number of intermediate\ntables.\n\nClearly the largest contribution this technology has to offer,\nhowever, is the cool formatting of the SQL queries.\n\nNext on the plate are some compelling example queries joining data\nfrom the OrderTracking database with some other database. I considered\na product review database, but such services are more likely to be\navailable over HTTP and SQL. (cwm and algae can join against data\nobtained from HTTP, but that was not so much the point of this\nexercise.) I would be interested in suggestion, particularly ones that\nwould be interesting to the web services crowd.\n\nLet me know what you think of this. Thanks.\n\n[1] http://www.w3.org/2000/10/swap/doc/cwm.html\n[2] http://www.w3.org/1999/02/26-modules/\n[3] http://dev.w3.org/cvsweb/2000/10/swap/test/dbork/OrderTracking1.n3\n[4] http://dev.w3.org/cvsweb/perl/modules/W3C/Rdf/test/OrderTracking1-alg.sh \n[5] http://dev.w3.org/cvsweb/perl/modules/W3C/Rdf/test/SqlDBtest7-alg.sh\n[6] http://dev.w3.org/cvsweb/perl/modules/W3C/Rdf/test/OrderTracking5-alg.sh \n-- \n-eric\n\noffice: +1.617.258.5741 NE43-344, MIT, Cambridge, MA 02144 USA\ncell:   +1.857.222.5741\n\n(eric@w3.org)\nFeel free to forward this message to any list for any purpose other than\nemail address distribution.\n\n\n\n"
        },
        {
            "subject": "[WP6] Experience with Edinburgh Schema Mapping Framework (ESME",
            "content": "For WP6, I'm looking at various approaches for mapping XML data into RDF.\n\nRecently I've been experimenting with a framework produced by Henry Thompson and \nAri Krupnikov at the University of Edinburgh. I now have a running installation of \ntheir tools, which combine XSV (an XML Schema system) with XSLT stylesheets to \nuse XML Schema annotations to convert 'colloquial' XML into other representations.\n\nTheir code targets Java src and a very RDF-like First Order logic subset. I've \nadded an extra stylesheet which also outputs RDF as N-Ntriples. To do this I \nhad to make one hack, which is a specifciation of the URI for the namespace each \nproperty belongs in.\n\nDetails are in the 00README.html file alongside all the src and output files I'm working \nwith. There are two worked scenarios currently, which were part of the original \nbundle of files from Henry. I've tried to document things so you can see what \nhappens (most of the smarts is in XSV; it outputs an augmented PSVI infoset), and \nplan to add more worked scenarios to link this approach to others we are exploring \nin the project.\n\nhttp://www.w3.org/2001/sw/Europe/200301/x2r/ht/a1/00README.html\n\nAt the f2f meeting, I'd like to discuss getting test case data for this work \nthat could be held in common for other workpackages (query, RDBMS mapping etc.), as \nwell as for testing other approaches to XML/RDF mapping.\n\nComments, suggestions etc welcome,\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: [WP5][WP6] Experience with Edinburgh Schema Mapping Framework (ESME",
            "content": "Er, I meant [WP5] not [WP6] (although this does relate).\n\nDan \n\nps. I should have a tech overview plan uploaded shortly (yes, I know it's late...)\n\n* Dan Brickley <danbri@w3.org> [2003-01-20 05:33-0500]\n> \n> For WP6, I'm looking at various approaches for mapping XML data into RDF.\n> \n> Recently I've been experimenting with a framework produced by Henry Thompson and \n> Ari Krupnikov at the University of Edinburgh. I now have a running installation of \n> their tools, which combine XSV (an XML Schema system) with XSLT stylesheets to \n> use XML Schema annotations to convert 'colloquial' XML into other representations.\n> \n> Their code targets Java src and a very RDF-like First Order logic subset. I've \n> added an extra stylesheet which also outputs RDF as N-Ntriples. To do this I \n> had to make one hack, which is a specifciation of the URI for the namespace each \n> property belongs in.\n> \n> Details are in the 00README.html file alongside all the src and output files I'm working \n> with. There are two worked scenarios currently, which were part of the original \n> bundle of files from Henry. I've tried to document things so you can see what \n> happens (most of the smarts is in XSV; it outputs an augmented PSVI infoset), and \n> plan to add more worked scenarios to link this approach to others we are exploring \n> in the project.\n> \n> http://www.w3.org/2001/sw/Europe/200301/x2r/ht/a1/00README.html\n> \n> At the f2f meeting, I'd like to discuss getting test case data for this work \n> that could be held in common for other workpackages (query, RDBMS mapping etc.), as \n> well as for testing other approaches to XML/RDF mapping.\n> \n> Comments, suggestions etc welcome,\n> \n> Dan\n\n\n\n"
        },
        {
            "subject": "When to use Weblog, when to use mailing list? (example re schema anno msg",
            "content": "A couple of people have asked me about the Weblog, generally being favourable \nbut not sure when to use it instead of the mailing list, and wary of splitting \ndiscussions across too many fora / technologies.\n\nThere's no right answer, but I guess the thing to bear in mind is that the \nWeblog is abit more outward facing, so readers there may not care so much about \nworkpackage innards, meetings etc. And may need a bit more context on what \nwe're up to.\n\nIn general, I suggest sending major project related progress stuff to the list, \nand if of likely wider interest, also noting it by reference with a quick Weblog \nentry.\n\nFor eg., I just scribbled this note http://esw.w3.org/mt/esw/archives/000015.html\nabout the Schema annotation experiments. It took a couple of minutes, which \nsince the weblog is RSS-syndicated is probably worth the effort, as it can \nkeep a wider audience up to date with our ongoing work. \n\nI also share such links in #rdfig, the RDF Interest Group IRC channel, since that too\nhas a Weblog and RSS view (see http://rdfig.xmlhack.com/) and is widely read by \nRDF folk. Unless you are a regular there, I doubt many will want to enter their \nURLs/descriptions a 3rd time though.\n\nHope this helps,\n\nDan\n\n\n\n"
        },
        {
            "subject": "[WP8] requested mailing list: public-eswthes / Wordnet vocab",
            "content": "As a startup for WP8 (Thesaurus) I have requested a mailing list\nfor RDF/thesaurus discussions: public-esw-thes\n\nWP b/g:\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-8.html\n\nThis work hasn't formally begun yet, but I'm finding there are various \nofflist conversations on this topic happening, and it would be good \nfor the project if we could play host to RDF/thesaurus discussion.\n\nBTW I am also thinking of moving my RDF/Wordnet vocabulary across to \nSWAD-Europe since the namespace needs to change anyway, and it provides \nRDF classes for many thousands of common category terms, as well as \nplacing them in a hierarchy. This is useful for image annotation, \namongst other things. \n\nThat work is currently at http://xmlns.com/2001/08/wordnet/ and uses\nhttp://xmlns.com/wordnet/1.6/ as a namespace URI.\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "[WP3] SWAD-Europe Wiki installation  gone liv",
            "content": "[[\nI have set up a SWAD-Europe Wiki installation, as a place for quick note-taking, \nFAQ drafting and link sharing. Like many Wikis (and mailing lists, though that's \na bit different), it is currently configured as a publically writable space. \nIt may prove useful as a tool to support discussions in the RDF Interest Group \nand associated spin-off task forces (eg. RDF calendaring). Time will tell.\n]] http://esw.w3.org/mt/esw/archives/000017.html\n\n\nMore context: In the RDF Interest Group, we get a fair amount done by email and \nirc, but the same topics tend to recur without answers being drafted. Often an \nemail or irc discussion thread will go some way towards answering the topic, \nbut we've not yet been good at seeing things through to final documentation.\n\nOne goal I have for the Wiki installation is to allow active RDFIG members to\ngather FAQ background materials without centralised bottlenecks (or quality control \n / review). Hosting a Wiki (ie. a publically writable Web-based scratchpad) is \nan experiment towards seeing how well this works, and how the tradeoffs between \ncentralised control vs community scribbling pay off in the RDF developer world.\n\nThe Wiki entry page is at http://esw.w3.org/t//view/ESW/WebHome and could do \nwith better boilerplate, intro text and a few link fixes etc. I wanted to get this \nmade public so that it could be used in the RDF calendar and RDF query test case \ndiscussions that are ongoing (www-rdf-calendar, www-rdf-rules lists). \n\nLibby, would it be worth mentioning this in the Calendar IRC meeting on weds? Do \nyou think that group would find a Wiki scratchpad useful? What about Query?\n\nComments etc welcomed,\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: [WP3] SWAD-Europe Wiki installation  gone liv",
            "content": "I think this could be very useful. I just had a go for summarising some\nof the RDF query testcases discussions, and it worked very well:\n\nhttp://esw.w3.org/t/view/ESW/RDFQueryTestCases\n\nI'm hoping to use this as a notepad for things like this.\n\nLibby\n\nOn Mon, 20 Jan 2003, Dan Brickley wrote:\n\n>\n> [[\n> I have set up a SWAD-Europe Wiki installation, as a place for quick note-taking,\n> FAQ drafting and link sharing. Like many Wikis (and mailing lists, though that's\n> a bit different), it is currently configured as a publically writable space.\n> It may prove useful as a tool to support discussions in the RDF Interest Group\n> and associated spin-off task forces (eg. RDF calendaring). Time will tell.\n> ]] http://esw.w3.org/mt/esw/archives/000017.html\n>\n>\n> More context: In the RDF Interest Group, we get a fair amount done by email and\n> irc, but the same topics tend to recur without answers being drafted. Often an\n> email or irc discussion thread will go some way towards answering the topic,\n> but we've not yet been good at seeing things through to final documentation.\n>\n> One goal I have for the Wiki installation is to allow active RDFIG members to\n> gather FAQ background materials without centralised bottlenecks (or quality control\n>  / review). Hosting a Wiki (ie. a publically writable Web-based scratchpad) is\n> an experiment towards seeing how well this works, and how the tradeoffs between\n> centralised control vs community scribbling pay off in the RDF developer world.\n>\n> The Wiki entry page is at http://esw.w3.org/t//view/ESW/WebHome and could do\n> with better boilerplate, intro text and a few link fixes etc. I wanted to get this\n> made public so that it could be used in the RDF calendar and RDF query test case\n> discussions that are ongoing (www-rdf-calendar, www-rdf-rules lists).\n>\n> Libby, would it be worth mentioning this in the Calendar IRC meeting on weds? Do\n> you think that group would find a Wiki scratchpad useful? What about Query?\n>\n> Comments etc welcomed,\n>\n> Dan\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: When to use Weblog, when to use mailing list? (example re schema  anno msg",
            "content": "On Mon, 20 Jan 2003, Dan Brickley wrote:\n\n>A couple of people have asked me about the Weblog, generally being favourable\n>but not sure when to use it instead of the mailing list, and wary of splitting\n>discussions across too many fora / technologies.\n>\n>For eg., I just scribbled this note http://esw.w3.org/mt/esw/archives/000015.html\n>about the Schema annotation experiments. It took a couple of minutes, which\n>since the weblog is RSS-syndicated is probably worth the effort, as it can\n>keep a wider audience up to date with our ongoing work.\n>\n>I also share such links in #rdfig, the RDF Interest Group IRC channel, since that too\n>has a Weblog and RSS view (see http://rdfig.xmlhack.com/) and is widely read by\n>RDF folk. Unless you are a regular there, I doubt many will want to enter their\n>URLs/descriptions a 3rd time though.\n\nDo we have some mechanism so that we can feed our stuff from public-esw to\n#rdfig? Have we thought long about the implications of doing that (how do you\ndistinguish between spam and legitimate information - is it that an\nindividual produced something as a one-off? ....)\n\ncheers\n\nchaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: [WP8] requested mailing list: public-eswthes / Wordnet vocab",
            "content": "This would seem like a good thing to me. There has been talk of using Wordnet\nin particular, and thesaurus-based technology in geenral, for accessibility -\nthis would fall into things that gt writen up in Work Package 9.\n\ncheers\n\nchaals\n\nOn Mon, 20 Jan 2003, Dan Brickley wrote:\n\n>\n>As a startup for WP8 (Thesaurus) I have requested a mailing list\n>for RDF/thesaurus discussions: public-esw-thes\n>\n>BTW I am also thinking of moving my RDF/Wordnet vocabulary across to\n>SWAD-Europe since the namespace needs to change anyway, and it provides\n>RDF classes for many thousands of common category terms, as well as\n>placing them in a hierarchy. This is useful for image annotation,\n>amongst other things.\n>\n>That work is currently at http://xmlns.com/2001/08/wordnet/ and uses\n>http://xmlns.com/wordnet/1.6/ as a namespace URI.\n>\n>cheers,\n>\n>Dan\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Installing an Annotea serve",
            "content": "Hi folks, as part of the report on anotea systems I am writing up\ninstructions for installing the ZAnnot server. I packaged it for the Mac OS X\nfink system, where it is avialable in the \"unstable\" version, and it is easy\nenough to install in Windows (as I found) and Debian (reported by danbri\nfollowing the instructions page).\n\nI have started on the \"dummies guide\" at\nhttp://www.w3.org/2001/sw/Europe/reports/annotation_demo_server_report/zannot-inst.html\nComments are welcome - I hope to complete it this week - I have other things\nto do, including hopefully write up a dummies guide for the W3C Annotea\nserver - anyone who has installed that already and has pointers is invited to\nshare them...\n\ncheers\n\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "[WP2] Tech Coordination do",
            "content": "http://www.w3.org/2001/sw/Europe/reports/proj_tech_plan/\n\n...idea being to revise and expand the final 'issue list' section \nthrough the life of the project.\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: RDF query test cases",
            "content": "Hi Danny,\n\nThis sounds interesting, and is a limitation that irritates me too.\n\nThe various solutions we have mulled over are:\n1). Simply putting the categories in a taxonomy is a good start (they're not\ncurrently in MT)\n2). Explicitly share a taxonomy (OK for small groups).  \n3). Allow lightweight mappings between related taxonomies, using something\nlike an RDF version of XFML [1]\n\nWe're likely to adopt (1) and (2) for SWAD-E demonstrator 12.1, with (3) as\nan optional extension\nYour wordnet approach is another interesting angle, let us know how it goes!\n\nCheers\n\nSteve\n\n[1] http://xfml.org/  \n\n-----Original Message-----\nFrom: Danny Ayers [mailto:danny666@virgilio.it]\nSent: 21 January 2003 10:08\nTo: Jeen Broekstra; Libby Miller\nCc: www-rdf-rules; Steve Cayzer\nSubject: RE: RDF query testcases?\n\n\nThis thread has provided the answer to a problem that I've been mulling over\nfor a few weeks ;-)\n\nSome blogging tools (such as Movable Type) allow the user to categorise\ntheir posts, but the categories used are totally arbitrary, just strings\ndecided by the user. To be able to index across systems, some sharing of\ntaxonomies would be needed. It occurred to me that a lookup of something\nlike Wordnet would allow the mapping of Cats (in Danny's blog) to\nhttp://whatever/worndet#Cat and thence to Cats (in Libby's blog). So it\nlooks like pretty much any of these query tools would be up to the job. The\nnext stages are I suppose setting the 'dictionary' up as a service, then\nimplementing a user-transparent interface.\n\nCheers,\nDanny.\n\n\n-----------\n\nhttp://dannyayers.com\n\n\"The lyf so short, the craft so long to lerne.\" - Chaucer\n\n\n\n>-----Original Message-----\n>From: www-rdf-rules-request@w3.org\n>[mailto:www-rdf-rules-request@w3.org]On Behalf Of Jeen Broekstra\n>Sent: 21 January 2003 10:27\n>To: Libby Miller\n>Cc: www-rdf-rules\n>Subject: Re: RDF query testcases?\n>\n>\n>\n>Libby Miller wrote:\n>\n>> this is great, thanks Jeen.\n>>\n>> quick question: Sesame supports RDF schema right? so if I did a query\n>> in RDQL over Sesame over an ontology like Wordnet (e.g.\n>> http://xmlns.com/wordnet/1.6/Person) would I get both Person and\n>> Life_form as the classes of an instance of Person?\n>\n>Yes.\n>\n>My RDQL is somewhat shaky, but the query would be something like:\n>\n>SELECT ?c\n>WHERE (?p, <rdf:type>, <wn:Person>),\n>       (?p, <rdf:type>, ?c)\n>\n>Right?\n>\n> > What if I did the same query in RQL?\n>\n>The same. In Sesame, the deductive closure is computed independently of\n>the query module, so both RQL and RDQL could retrieve all these answers.\n>\n>The RQL query in this case would be something like:\n>\n>SELECT typeOf( p )\n>FROM   wn:Person { p }\n>\n>The difference is in the fact that RQL can explicitly express certain\n>types of schema semantics in the query, making it possible to express\n>queries about the schema more easily, and sometimes go beyond what's\n>expressible in an RDF-only QL.\n>\n>A simple example of this is direct subclass relations (A is a direct\n>subclass of B iff there is no C: A < C < B): this is a relation that\n>would be rather awkward to express in RDQL, but RQL has a special\n>language feature for it.\n>\n>> I'm asking this because I was asked to recommend a tool that could be\n>> used for querying a fairly simple, heirarchical ontology (actually\n>> more like a thesaurus - MeSH,\n>> http://www.nlm.nih.gov/mesh/meshhome.html), such that you could, say,\n>> ask for all research groups with 'abdomen' or anything above it in the\n>> heirarchy as their descriptive keyword. (I'm now also wondering whether\n>> things below it in the heirarchy might be more useful...)\n>>\n>> Does that make any sense?\n>\n>This would be fairly straightforward to express, I imagine, so yes :)\n>\n>Best regards,\n>\n>Jeen\n>--\n>jeen.broekstra@aidministrator.nl\n>aidministrator nederland bv - http://www.aidministrator.nl/\n>julianaplein 14b, 3817 cs amersfoort, the netherlands\n>tel. +31-(0)33-4659987, fax. +31-(0)33-4659987\n>\n\n\n\n"
        },
        {
            "subject": "[WP6] xml_sw_prototype_math_logic  application scenarios: Company Account",
            "content": "I think I've circulated this before, but to put it back on the record \nwith a findable Subject: line, here is a page that partially documents \na worked example I hope we'll study in more depth in WP6 \nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-6.html for the \nMonth 21 deliverable, (6.2: xml_sw_prototype_math_logic).\n\nThe writeup and test data is at http://www.w3.org/2002/04/corpinfo/semweb-scenario \n...and includes files (http://www.w3.org/2002/04/corpinfo/) that give basic\n'company reports' markup for several companies, in RDF. There is also an N3 \nrepresentation of some mathematical rules relating the various things that \nappear in these reports. Very much work in progress (except that nobody is \nactively working on it) but interesting I think as a testbed for exploring when\nMathML makes sense, when RDF rules are more appropriate, and how it all \nfits together. \n\nDan\n\n\n\n"
        },
        {
            "subject": "[WP?;] shared whitelist writeu",
            "content": "(copying swad-e list, though this is only superficially an RDF app at this stage)\n(and Gerald, who got me into this idea)\n\nHi Graham,\n\nNice to see you again yesterday. Before I forget, here is a pointer \nto the whitelist-sharing spam filter application I worked on lately, as discussed \nin coffeebreak. FWIW I use it, and take advantage of local access to a (hashed)\nversion of W3C's list of probably-not-spammer mailing list subscribees. It works \nwell, although each day I have several msgs from people who addresses don't match.\n\nDetails: http://www.w3.org/2001/12/rubyrdf/util/foafwhite/intro.html\ngoogle has a few more pointers, http://www.google.com/search?q=%20foaf%20whitelist\nmy own whitelist: http://tux.w3.org/~danbri/rdfweb/foafwhite.xml (feel free to use)\n\nI'm thinking of making a few changes.\n\n - decouple basic idea from foaf (though foaf might prove useful for discovery/trust\n   addons)\n - add both case-normalised and as-is hashes of each mailbox, so that if \n   mailto:danbri@W3.org is on your whitelist, and you check for mailto:danbri@w3.org, \n   you'll get a match.\n - bundle up the code I'm running\n - write it up (I'm wondering whether there's a corner of swad-e where such a \n   piece of writeup makes sense. it isn't a million miles from the Trust WP...)\n\n\nFWIW I had a brief exchange with someone from Mozilla.org about possibility of \nwhitelist exchange to support spam-filtering on mailing lists, some time ago. You \nmentioned possibility of interest from folk running IETF lists too, maybe that \nwould be enough to get critical mass? We'd need to think about privacy issues a bit \nmore carefully before encouraging people to do this. Knowing that a person is on \nsome publically visible technically oriented list isn't such a controversial fact, but \nif the technique were adopted for more controversial (sex/politics/health/etc) fora, \nwe would need to tiptoe rather carefully. Ultimately I would like W3C and other \nlarge mailing list hosts to expose such whitelists for re-use and sharing, but I \nwouldn't want to do that without thinking through the issues.\n\nI do think that whitelist sharing is the way to go re spam filtering, augmented by \ncontent-based filtering. Whitelists paint spammers into a corner, where they have to \nforge From: headers to get mail through to an audience. An obnoxious practice, but \none that makes a starker line between 'goodies' and 'baddies'.\n\nThoughts, suggestions, devastating critiques welcome as always :)\n\nDan\n\n\n\nDan\n\n\n\n"
        },
        {
            "subject": "[WP8] RDF thesaurus schema early start &ndash;&ndash; can you supply schema",
            "content": "Brian,\n\nper http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-8.html and \ndiscussions yesterday, can you mail me your version of the RDF Thesauri Schema\nso I can get it set up as a namespace at http://www.w3.org/ someplace for \ndiscussion, testing etc? \nWe should have a mailing list for this too, soon (public-esw-thes).\n\nIt'd be useful if you could outline the main differences between that and the \nearlier one I worked on with Phil Cross and Traugott Koch, since we have code for \nthe latter knocking around at ILRT somewhere, and it'd be great to consolidate things.\n\nIs http://www.limber.rl.ac.uk/External/SW_conf_thes_paper.htm still an accurate \ndescription of the work you folks have done?\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: IBIS vocab for sembloggin",
            "content": "Hi Danny, Charles,\n\nI hear that DanBri, in reference to HP's open demonstrator (WP 12.1) has\nsuggested sharing ontologies for describing inter-document links. \nI'd certainly be keen on the idea, we certainly need to define such an\nontology and these look highly relevant.\nThe other one that I'm aware of is ClaiMaker[1]. Danny, did you ever get an\nRDF schema [2] from the KMI folks?\n\nCheers\n\nSteve\n\n[1] http://kmi.open.ac.uk/projects/scholonto/docs/ClaiMaker-ISWC2002.pdf\n[2] http://www.bootstrap.org/lists/ba-ohs-talk/0211/msg00004.html\n \n\n-----Original Message-----\nFrom: Charles McCathieNevile [mailto:charles@w3.org]\nSent: 18 January 2003 21:45\nTo: Danny Ayers\nCc: Esw\nSubject: Re: IBIS vocab for semblogging\n\n\n\nHi Danny,\n\nthe vocabulary stuff you are looking at sounds like it is extending\nthe thread vocabulary produced for Annotea (or for that matter the original\nAnnotea vocabulary of annotation types) to allow for discussion threads\nto be tracked. This seems to me like a good idea.\n\nhttp://www.w3.org/2001/03/thread\n\nThe ability to provide user-friendly interfaces for this (such as the\nicon-selection that Amaya has for marking different types of annotation -\nsee\nthe help file at\nhttp://www.w3.org/Amaya/User/attaching_annotations/configuring_icons) is a\npromising paralell for the use of graphic RDF editors (IdeaGraph, IsaViz,\nRDFAuthor, etc)\n\ncheers\n\nChaals\n\nOn Fri, 17 Jan 2003, Danny Ayers wrote:\n\n>\n>I didn't realise Semantic Blogging was being followed up as an e-sw case\n>study, until I found the link on the new blog...\n>\n>Anyhow, one of the apps I've been working on for my Ideagraph project is\n>semantic blogging and to help with this I've started writing up a\nvocabulary\n>(RDFS) for 'Issue-Based Information Systems', the idea being to use terms\n>like 'Argument', 'Question', 'pro', 'con' within blog (and other)\ndiscussion\n>threads.\n>\n>http://purl.org/ibis\n>\n>Very much a work in progress, suggestions welcome.\n>\n>Cheers,\n>Danny.\n>\n>-----------\n>\n>http://dannyayers.com\n>\n>\"The lyf so short, the craft so long to lerne.\" - Chaucer\n>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134\n136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78\n22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: IBIS vocab for sembloggin",
            "content": ">I hear that DanBri, in reference to HP's open demonstrator (WP 12.1) has\n>suggested sharing ontologies for describing inter-document links.\n>I'd certainly be keen on the idea, we certainly need to define such an\n>ontology and these look highly relevant.\n\n+1\n\n>The other one that I'm aware of is ClaiMaker[1]. Danny, did you ever get an\n>RDF schema [2] from the KMI folks?\n\nI did indeed:\n\nhttp://kmi.open.ac.uk/projects/scholonto/resources/\n\nand I found the link by searching my blog ;-)\n\nIt's an interesting file: pretty fine-grained vocab, and stylistically\nrather novel.\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "Re: [WP?;] shared whitelist writeu",
            "content": "Dan,\n\nI haven't had a chance to look at your cooperative whitelist pointers yet, \nbut this is the response I got back from Paul Hoffman, who is not prepared \nto release his whitelist for such a scheme.  And now I think about it, it \nis a glaring vulnerability.   (And that's before even thinking about the \nprivacy concerns you mention.)\n\nThe bottom line is that the security will need to be much more carefully \nthought out if this is going to fly at any significant scale.\n\n>>The suggestion was not that email addresses are exchanged, but SHA-1 \n>>hashes of them, for precisely the reason you raise.\n>\n>Nope, not even that. A list of SHA-1 hashes can be used as a basis for \n>dictionary attacks to determine the list of good LHS against the list of \n>good domain names.\n\n#g\n--\n\n\nAt 04:00 AM 1/22/03 -0500, Dan Brickley wrote:\n>... here is a pointer\n>to the whitelist-sharing spam filter application I worked on lately, as \n>discussed\n>in coffeebreak. FWIW I use it, and take advantage of local access to a \n>(hashed)\n>version of W3C's list of probably-not-spammer mailing list subscribees. It \n>works\n>well, although each day I have several msgs from people who addresses \n>don't match.\n>\n>Details: http://www.w3.org/2001/12/rubyrdf/util/foafwhite/intro.html\n>google has a few more pointers, \n>http://www.google.com/search?q=%20foaf%20whitelist\n>my own whitelist: http://tux.w3.org/~danbri/rdfweb/foafwhite.xml (feel \n>free to use)\n>\n>I'm thinking of making a few changes.\n>\n>  - decouple basic idea from foaf (though foaf might prove useful for \n> discovery/trust\n>    addons)\n>  - add both case-normalised and as-is hashes of each mailbox, so that if\n>    mailto:danbri@W3.org is on your whitelist, and you check for \n> mailto:danbri@w3.org,\n>    you'll get a match.\n>  - bundle up the code I'm running\n>  - write it up (I'm wondering whether there's a corner of swad-e where \n> such a\n>    piece of writeup makes sense. it isn't a million miles from the Trust \n> WP...)\n>\n>\n>FWIW I had a brief exchange with someone from Mozilla.org about \n>possibility of\n>whitelist exchange to support spam-filtering on mailing lists, some time \n>ago. You\n>mentioned possibility of interest from folk running IETF lists too, maybe \n>that\n>would be enough to get critical mass? We'd need to think about privacy \n>issues a bit\n>more carefully before encouraging people to do this. Knowing that a person \n>is on\n>some publically visible technically oriented list isn't such a \n>controversial fact, but\n>if the technique were adopted for more controversial \n>(sex/politics/health/etc) fora,\n>we would need to tiptoe rather carefully. Ultimately I would like W3C and \n>other\n>large mailing list hosts to expose such whitelists for re-use and sharing, \n>but I\n>wouldn't want to do that without thinking through the issues.\n>\n>I do think that whitelist sharing is the way to go re spam filtering, \n>augmented by\n>content-based filtering. Whitelists paint spammers into a corner, where \n>they have to\n>forge From: headers to get mail through to an audience. An obnoxious \n>practice, but\n>one that makes a starker line between 'goodies' and 'baddies'.\n>\n>Thoughts, suggestions, devastating critiques welcome as always :)\n>\n>Dan\n>\n>\n>\n>Dan\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "RE: [WP8] RDF thesaurus schema early start &ndash;&ndash; can you supply sche ma",
            "content": "Dan,\n\nSchema for thesaurus interchange format is at:\n\nhttp://www.limber.rl.ac.uk/External/thesaurus-iso.rdf\n\nDescription of work to reach that schema is at:\n\nhttp://www.limber.rl.ac.uk/External/SW_conf_thes_paper.htm\n\n\nMichael Wilson\nBusiness and Information Technology Department   tel: +44 (0)1235 44 6619\nCLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\nChilton, DIDCOT, Oxon, OX11 0QX, UK             \n\nWWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n\nThe contents of this email are sent in confidence for the use of the\nintended recipients only.  If you are not one of the intended recipients\ndo not take action on it or show it to anyone else, but return this\nemail to the sender and delete your copy of it\n\n\n\n\n-----Original Message-----\nFrom: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\nBehalf Of Dan Brickley\nSent: 22 January 2003 12:48\nTo: Matthews, BM (Brian) \nCc: public-esw@w3.org\nSubject: [WP8] RDF thesaurus schema early start -- can you supply\nschema?\n\n\n\nBrian,\n\nper http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-8.html\nand \ndiscussions yesterday, can you mail me your version of the RDF Thesauri\nSchema\nso I can get it set up as a namespace at http://www.w3.org/ someplace for \ndiscussion, testing etc? \nWe should have a mailing list for this too, soon (public-esw-thes).\n\nIt'd be useful if you could outline the main differences between that and\nthe \nearlier one I worked on with Phil Cross and Traugott Koch, since we have\ncode for \nthe latter knocking around at ILRT somewhere, and it'd be great to\nconsolidate things.\n\nIs http://www.limber.rl.ac.uk/External/SW_conf_thes_paper.htm still an\naccurate \ndescription of the work you folks have done?\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "RE: [WP8] RDF thesaurus schema early start &ndash;&ndash; can you supply sche ma",
            "content": "On Thu, 2003-01-23 at 08:35, Wilson, MD (Michael) wrote:\n> \n> Dan,\n> \n> Schema for thesaurus interchange format is at:\n> \n> http://www.limber.rl.ac.uk/External/thesaurus-iso.rdf\n> \n> Description of work to reach that schema is at:\n> \n> http://www.limber.rl.ac.uk/External/SW_conf_thes_paper.htm\n\nMichael,\n\nI seem to recall hearing that ELSTT (or EELS?) thesaurus was represented\nusing this schema. Can you confirm? and if so, is this online?  Are\nthere any other thesauri that are using this schema?\n\nI've heard rumors of generalizing some of the NISO Z39.19 [1] work to\nsupport multilingual thesaurus and I believe that an RDF schema that\nsupports this requirement would be well received as the basis for such\nwork. Having several thesauri represented this way would make for a more\ncompelling argument.\n\n[1] http://www.niso.org/standards/resources/Z39-19.html\n\n-- \neric miller                              http://www.w3.org/people/em/\nsemantic web activity lead               http://www.w3.org/2001/sw/\nw3c world wide web consortium            http://www.w3.org/\n\n\n\n"
        },
        {
            "subject": "RE: [WP8] RDF thesaurus schema early start &ndash;&ndash; can you supply sche  ma",
            "content": "Eric,\n\nThe ELSST thesaurus is represented using this schema, but it is not entirely\npublically available - only a small fragment at:\n\nhttp://www.limber.rl.ac.uk/External/ELSST_demo_RDF.xml\n\nWe are in the process of encoding other thesauri and word lists into this\nformat, although only for demonstration purposes, and without any permission\nof the owners (these include the UK government category list [GCL], the UK\nDepartment of Trade thesaurus [MATRIX], the medical category list MeSH, and\nthe EU CEC Multilingual Health thesaurus).\nThese are all publically available and will be made available in RDF on our\nThesaurus server for test and demonstration purposes (the server is not\npublic yet).\n\nIf you have access to any thesaurus that you'd like us to put into this\nformat for test and demonstration purposes, please send it to me, or send a\nURL where I can get it.\n\nAs the title of this thread suggests, this activity has just started in the\nSWAD project and we are open to guidance, and suggestions - the schema is\nopen to change if we can't capture what is needed for the example set of\nthesauri - it was developed in a previous project.\n\nI'll look at NISO Z39.19; there are also updates in progress to the ISO\nthesaurus standards, but RDf may be too radical for them.\n\nMichael Wilson\nBusiness and Information Technology Department   tel: +44 (0)1235 44 6619\nCLRC Rutherford Appleton Laboratory             fax: +44(0)1235 44 5831\nChilton, DIDCOT, Oxon, OX11 0QX, UK             \n\nWWW: http://www.bitd.clrc.ac.uk/Person/M.D.Wilson\n\nThe contents of this email are sent in confidence for the use of the\nintended recipients only.  If you are not one of the intended recipients\ndo not take action on it or show it to anyone else, but return this\nemail to the sender and delete your copy of it\n\n\n\n\n-----Original Message-----\nFrom: Eric Miller [mailto:em@w3.org]\nSent: 23 January 2003 16:18\nTo: Wilson, MD (Michael)\nCc: 'Dan Brickley'; Matthews, BM (Brian); Miles, AJ (Alistair);\n'public-esw@w3.org'\nSubject: RE: [WP8] RDF thesaurus schema early start -- can you supply\nsche ma?\n\n\nOn Thu, 2003-01-23 at 08:35, Wilson, MD (Michael) wrote:\n> \n> Dan,\n> \n> Schema for thesaurus interchange format is at:\n> \n> http://www.limber.rl.ac.uk/External/thesaurus-iso.rdf\n> \n> Description of work to reach that schema is at:\n> \n> http://www.limber.rl.ac.uk/External/SW_conf_thes_paper.htm\n\nMichael,\n\nI seem to recall hearing that ELSTT (or EELS?) thesaurus was represented\nusing this schema. Can you confirm? and if so, is this online?  Are\nthere any other thesauri that are using this schema?\n\nI've heard rumors of generalizing some of the NISO Z39.19 [1] work to\nsupport multilingual thesaurus and I believe that an RDF schema that\nsupports this requirement would be well received as the basis for such\nwork. Having several thesauri represented this way would make for a more\ncompelling argument.\n\n[1] http://www.niso.org/standards/resources/Z39-19.html\n\n-- \neric miller                              http://www.w3.org/people/em/\nsemantic web activity lead               http://www.w3.org/2001/sw/\nw3c world wide web consortium            http://www.w3.org/\n\n\n\n"
        },
        {
            "subject": "[WP10] D10.2  Mapping data from RDBM",
            "content": "This deliverable D10.2 is now available:\n\n  Mapping data from RDBMS\n  http://www.w3.org/2001/sw/Europe/reports/scalable_rdbms_mapping_report/\n\n  Authors: Dave Beckett, Jan Grant\n\n  Abstract:\n    A public report on mapping triple stores and RDBMS concentrating\n    on surveying the schemas used and discussing mapping approaches\n    to and from relational schemas. It describes current best\n    practice for using such systems for Semantic Web data including\n    feature comparisons, recommendations for particular applications\n    and advice on tradeoffs.\n\nDave\n\n\n\n"
        },
        {
            "subject": "Vocabulary for result set",
            "content": "At the F2F, I offered to write a vocabulary for result sets.  While I had in\nmind query result sets for queries evaluating to variable bindings, it\noccurred to me that it is the same as providing reasons for pattern-trigger\nrules.  This vocabulary does not cover the case of query languages that\nreturn one or more subgraphs of the target graph.\n\nAttached are:\n\n1/ result-set-vocab.n3  - the vocabulary in N3\n2/ result-set-vocab.xml - the same in XML: machine produced and neatened\n3/ result-set-ex1.n3    - example in N3\n4/ result-set-ex1.xml   - same example in XML (but no type info)\n5/ result-set-ex2.n3    - same bindings in N3 without type decoration,\n                          possibly easier to read\n\nExample: result-set-ex2.n3, which shows it can be layed out so people can\nsee the structure.  Sort of.\n\n------------------------------------------------------------\n@prefix rdfs:   <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix rdf:    <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix dc:     <http://purl.org/dc/elements/1.1/> .\n@prefix q:      <http://somewhere/2003/01/result-set-vocab#> .\n@prefix xsd:    <http://www.w3.org/2000/10/XMLSchema#> .\n\n\n<>  q:size \"2\"^^xsd:integer ;# Some information\nfor convenience\n    q:hasVariable \"x\" ; q:hasVariable \"y\" ;     # Some information for\nconvenience\n    q:hasSolution\n        [ q:hasBinding [ q:variable \"x\" ; q:value \"123\"^^xsd:integer ] ;\n          q:hasBinding [ q:variable \"y\" ; q:value\n<http://example.com/resource1> ]\n        ] ;\n\n    q:hasSolution\n        [ q:hasBinding [ q:variable \"x\" ; q:value \"2003-01-21\" ] ;\n          q:hasBinding [ q:variable \"y\" ; q:value\n<http://example.com/resource2> ]\n        ] ;\n    .\n------------------------------------------------------------\n\n(1) I used multiple occurrences of a property/value, rather than use a bag,\nfor the solutions (rows) in a result set (table) and for the bindings in a\nsolution\n\n(2) I used a struct-like encoding , rather DAML lists / RDF collections, or\na bag, for the bindings.  What is good style for this sort of thing?\n\nComments please,\n\nAndy\n\n\n\n\n\napplication/octet-stream attachment: result-set-ex1.xml\n\napplication/octet-stream attachment: result-set-ex1.n3\n\napplication/octet-stream attachment: result-set-ex2.n3\n\napplication/octet-stream attachment: result-set-vocab.xml\n\napplication/octet-stream attachment: result-set-vocab.n3\n\napplication/octet-stream attachment: result-set-vocab.n3\n\napplication/octet-stream attachment: result-set-vocab.n3\n\napplication/octet-stream attachment: result-set-vocab.xml\n\napplication/octet-stream attachment: result-set-ex1.n3\n\napplication/octet-stream attachment: result-set-ex1.xml\n\napplication/octet-stream attachment: result-set-ex2.n3\n\n\n\n\n"
        },
        {
            "subject": "New Public mailing list - public-esw-thes  maintained by Dan Brickle",
            "content": "The Thesaurus mailing list is up and running. I'll see about getting \nit kicked off properly next week, as well as collecting up links to existing \nthesaurus vocab we and others have done.\n\nDan\n\n\nattached mail follows:\n\n\nMaintaing Activity:  Semantic Web Activity[1]\n\nList Purpose:  This list is for project participants and collaborators in\nthe SWAD-Europe[2] project's work on RDF and Thesaurus systems. This is\nwork is in support of the Semantic Web Activity[1] at W3C and closely\nlinked to the discussions of the RDF Interest Group[3].\n\nReference:  SWAD-Europe\n\n\n\n1.  http://www.w3.org/2001/sw\n2.  http://www.w3.org/2001/sw/Europe/\n3.  http://www.w3.org/RDF/Interest/\n\n\n\n"
        },
        {
            "subject": "RE: [WP10] D10.2  Mapping data from RDBM",
            "content": "Great! This is essential material.\n\nOne reference you may wish to add - chapter 12 of 'Professional XML Meta\nData', Wrox (wot I writ*) describes a generic method of exporting RDBMS data\nas RDF based on the database's metadata (table, column names etc). I'm not\nsure re. best practices, but it worked nicely - using JDBC's meta stuff to\nbuild Jena models.\n\nCheers,\nDanny.\n\n* I don't get any royalties, so this ain't a plug ;-)\n\n-----------\n\nhttp://dannyayers.com\n\n\"The lyf so short, the craft so long to lerne.\" - Chaucer\n\n\n\n>-----Original Message-----\n>From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n>Behalf Of Dave Beckett\n>Sent: 23 January 2003 17:41\n>To: public-esw@w3.org\n>Subject: [WP10] D10.2 - Mapping data from RDBMS\n>\n>\n>\n>\n>This deliverable D10.2 is now available:\n>\n>  Mapping data from RDBMS\n>  http://www.w3.org/2001/sw/Europe/reports/scalable_rdbms_mapping_report/\n>\n>  Authors: Dave Beckett, Jan Grant\n>\n>  Abstract:\n>    A public report on mapping triple stores and RDBMS concentrating\n>    on surveying the schemas used and discussing mapping approaches\n>    to and from relational schemas. It describes current best\n>    practice for using such systems for Semantic Web data including\n>    feature comparisons, recommendations for particular applications\n>    and advice on tradeoffs.\n>\n>Dave\n>\n\n\n\n"
        },
        {
            "subject": "Re: Vocabulary for result set",
            "content": "At 07:25 PM 1/23/03 +0000, Seaborne, Andy wrote:\n>------------------------------------------------------------\n>@prefix rdfs:   <http://www.w3.org/2000/01/rdf-schema#> .\n>@prefix rdf:    <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n>@prefix dc:     <http://purl.org/dc/elements/1.1/> .\n>@prefix q:      <http://somewhere/2003/01/result-set-vocab#> .\n>@prefix xsd:    <http://www.w3.org/2000/10/XMLSchema#> .\n>\n>\n><>  q:size \"2\"^^xsd:integer ;                           # Some information\n>for convenience\n>     q:hasVariable \"x\" ; q:hasVariable \"y\" ;     # Some information for\n>convenience\n>     q:hasSolution\n>         [ q:hasBinding [ q:variable \"x\" ; q:value \"123\"^^xsd:integer ] ;\n>           q:hasBinding [ q:variable \"y\" ; q:value\n><http://example.com/resource1> ]\n>         ] ;\n>\n>     q:hasSolution\n>         [ q:hasBinding [ q:variable \"x\" ; q:value \"2003-01-21\" ] ;\n>           q:hasBinding [ q:variable \"y\" ; q:value\n><http://example.com/resource2> ]\n>         ] ;\n>     .\n>------------------------------------------------------------\n>\n>(1) I used multiple occurrences of a property/value, rather than use a bag,\n>for the solutions (rows) in a result set (table) and for the bindings in a\n>solution\n>\n>(2) I used a struct-like encoding , rather DAML lists / RDF collections, or\n>a bag, for the bindings.  What is good style for this sort of thing?\n\nIf I understand the intent correctly, I think this modelling works fine.\n\nWhen I was playing with modelling access control, the modelling problems I \nran in to with the style use use here were when the truth of the RDF \nassertion was dependent on one or more of the assertions being present.  I \nthink you can remove any of your assertions and the rersult-set assertion \nstatement remains true.\n\nHmmm... I wonder of there should be links to, or identifiers of, the \nknowledge-base and query used, so that valid results from different queries \ncan be differentiated.  In practice, I think this kind of testing is a \nrelatively closed-world activity, so maybe it doesn't matter.\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "RE: Vocabulary for result set",
            "content": "> -----Original Message-----\n> From: Graham Klyne [mailto:GK@NineByNine.org] \n> Sent: 23 January 2003 21:12\n> To: Seaborne, Andy\n> Cc: 'public-esw@w3.org'\n> Subject: Re: Vocabulary for result sets\n> \n\n...\n\n> \n> Hmmm... I wonder of there should be links to, or identifiers of, the \n> knowledge-base and query used, so that valid results from \n> different queries \n> can be differentiated.  In practice, I think this kind of \n> testing is a \n> relatively closed-world activity, so maybe it doesn't matter.\n> \n\nGraham,\n\nGood point.  A number of properties to annotate the result set would be\ngood.  Of course, nothing stops any properties being added ... but putting\nthem in the vocabulary encourages their use. \n\nAre there any suitable properties from other vocabularies to reuse?\n\nAlso - this could be the result from a query, not just recording information\nfor a testcase.  In this case, we still have a query->single graph approach\nbut the presentation of the results isn't a subgraph of the original KB, but\nan encoding of the variable bindings.  Each solution can be substituted into\nthe pattern for the query to generate a sequence of subgraphs, each of which\nsatisfy the query but the result set graph does not feel like knowledege\nextraction anymore.\n\nAndy\n\n\n\n"
        },
        {
            "subject": "RE: Vocabulary for result set",
            "content": "you might also get multiple valid resultsets per query, depending on the\npower of the KB.\n\nOn Fri, 24 Jan 2003, Seaborne, Andy wrote:\n\n>\n> > -----Original Message-----\n> > From: Graham Klyne [mailto:GK@NineByNine.org]\n> > Sent: 23 January 2003 21:12\n> > To: Seaborne, Andy\n> > Cc: 'public-esw@w3.org'\n> > Subject: Re: Vocabulary for result sets\n> >\n>\n> ...\n>\n> >\n> > Hmmm... I wonder of there should be links to, or identifiers of, the\n> > knowledge-base and query used, so that valid results from\n> > different queries\n> > can be differentiated.  In practice, I think this kind of\n> > testing is a\n> > relatively closed-world activity, so maybe it doesn't matter.\n> >\n>\n> Graham,\n>\n> Good point.  A number of properties to annotate the result set would be\n> good.  Of course, nothing stops any properties being added ... but putting\n> them in the vocabulary encourages their use.\n>\n> Are there any suitable properties from other vocabularies to reuse?\n>\n> Also - this could be the result from a query, not just recording information\n> for a testcase.  In this case, we still have a query->single graph approach\n> but the presentation of the results isn't a subgraph of the original KB, but\n> an encoding of the variable bindings.  Each solution can be substituted into\n> the pattern for the query to generate a sequence of subgraphs, each of which\n> satisfy the query but the result set graph does not feel like knowledege\n> extraction anymore.\n>\n> Andy\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Vocabulary for result set",
            "content": "Libby,\n\n> you might also get multiple valid resultsets per query, \n> depending on the\n> power of the KB.\n\nI'm not sure which way round you mean \"multiple valid resultsets per query\":\nthe vocabulary allows multiple solutions per result table.  And also\nmultiple result sets per result graph because it is rooted from a single\nnode.  The example uses <> as that node but there is no reason it has to be\nthat; you could have a bNode there, and have another starting bNode\nsomewhere else.\n\nCould you give an example of when there would be multiple result sets?  I\ncan image a \"query request\" to actually consist of a series of \"queries\" all\nof which should be executed.\n\nAndy\n\n> -----Original Message-----\n> From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk] \n> Sent: 24 January 2003 15:05\n> To: Seaborne, Andy\n> Cc: 'Graham Klyne'; 'public-esw@w3.org'\n> Subject: RE: Vocabulary for result sets\n> \n> \n> \n> you might also get multiple valid resultsets per query, \n> depending on the\n> power of the KB.\n> \n> On Fri, 24 Jan 2003, Seaborne, Andy wrote:\n> \n> >\n> > > -----Original Message-----\n> > > From: Graham Klyne [mailto:GK@NineByNine.org]\n> > > Sent: 23 January 2003 21:12\n> > > To: Seaborne, Andy\n> > > Cc: 'public-esw@w3.org'\n> > > Subject: Re: Vocabulary for result sets\n> > >\n> >\n> > ...\n> >\n> > >\n> > > Hmmm... I wonder of there should be links to, or \n> identifiers of, the\n> > > knowledge-base and query used, so that valid results from\n> > > different queries\n> > > can be differentiated.  In practice, I think this kind of\n> > > testing is a\n> > > relatively closed-world activity, so maybe it doesn't matter.\n> > >\n> >\n> > Graham,\n> >\n> > Good point.  A number of properties to annotate the result \n> set would be\n> > good.  Of course, nothing stops any properties being added \n> ... but putting\n> > them in the vocabulary encourages their use.\n> >\n> > Are there any suitable properties from other vocabularies to reuse?\n> >\n> > Also - this could be the result from a query, not just \n> recording information\n> > for a testcase.  In this case, we still have a \n> query->single graph approach\n> > but the presentation of the results isn't a subgraph of the \n> original KB, but\n> > an encoding of the variable bindings.  Each solution can be \n> substituted into\n> > the pattern for the query to generate a sequence of \n> subgraphs, each of which\n> > satisfy the query but the result set graph does not feel \n> like knowledege\n> > extraction anymore.\n> >\n> > Andy\n> >\n> >\n> >\n> \n\n\n\n"
        },
        {
            "subject": "RE: Vocabulary for result set",
            "content": "I guess I mean that if you were associating a resultset with a query,\nthere might be several different resultsets that would be ok. by this I\nmean several tables which are valid depending on whether the KB does\ntransitive closure on classes or not etc. Maybe it does this: I find it\ndifficult to read N3, and RDF schemas in general. Examples are the thing\nfor me, so I guess I should get on and try and add to yours from the\ndata we have.\n\nMany thanks for doing this Andy :)\n\nLibby\n\nOn Fri, 24 Jan 2003, Seaborne, Andy wrote:\n\n> Libby,\n>\n> > you might also get multiple valid resultsets per query,\n> > depending on the\n> > power of the KB.\n>\n> I'm not sure which way round you mean \"multiple valid resultsets per query\":\n> the vocabulary allows multiple solutions per result table.  And also\n> multiple result sets per result graph because it is rooted from a single\n> node.  The example uses <> as that node but there is no reason it has to be\n> that; you could have a bNode there, and have another starting bNode\n> somewhere else.\n>\n> Could you give an example of when there would be multiple result sets?  I\n> can image a \"query request\" to actually consist of a series of \"queries\" all\n> of which should be executed.\n>\n> Andy\n>\n> > -----Original Message-----\n> > From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n> > Sent: 24 January 2003 15:05\n> > To: Seaborne, Andy\n> > Cc: 'Graham Klyne'; 'public-esw@w3.org'\n> > Subject: RE: Vocabulary for result sets\n> >\n> >\n> >\n> > you might also get multiple valid resultsets per query,\n> > depending on the\n> > power of the KB.\n> >\n> > On Fri, 24 Jan 2003, Seaborne, Andy wrote:\n> >\n> > >\n> > > > -----Original Message-----\n> > > > From: Graham Klyne [mailto:GK@NineByNine.org]\n> > > > Sent: 23 January 2003 21:12\n> > > > To: Seaborne, Andy\n> > > > Cc: 'public-esw@w3.org'\n> > > > Subject: Re: Vocabulary for result sets\n> > > >\n> > >\n> > > ...\n> > >\n> > > >\n> > > > Hmmm... I wonder of there should be links to, or\n> > identifiers of, the\n> > > > knowledge-base and query used, so that valid results from\n> > > > different queries\n> > > > can be differentiated.  In practice, I think this kind of\n> > > > testing is a\n> > > > relatively closed-world activity, so maybe it doesn't matter.\n> > > >\n> > >\n> > > Graham,\n> > >\n> > > Good point.  A number of properties to annotate the result\n> > set would be\n> > > good.  Of course, nothing stops any properties being added\n> > ... but putting\n> > > them in the vocabulary encourages their use.\n> > >\n> > > Are there any suitable properties from other vocabularies to reuse?\n> > >\n> > > Also - this could be the result from a query, not just\n> > recording information\n> > > for a testcase.  In this case, we still have a\n> > query->single graph approach\n> > > but the presentation of the results isn't a subgraph of the\n> > original KB, but\n> > > an encoding of the variable bindings.  Each solution can be\n> > substituted into\n> > > the pattern for the query to generate a sequence of\n> > subgraphs, each of which\n> > > satisfy the query but the result set graph does not feel\n> > like knowledege\n> > > extraction anymore.\n> > >\n> > > Andy\n> > >\n> > >\n> > >\n> >\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: Vocabulary for result set",
            "content": "Libby,\n\nMy take was that Andy's model/vocab catches this quite neatly, because what \nI read it to say way that the result set thus described can be asserted to \nbe a correct result set [for a given knowledge base and query].  A subset \nof that, described in RDF by a subgraph of that given, is also a valid \nresult set -- if it weren't, I'd have been concerned that the RDF semantics \nwere being violated, in particular the subgraph lemma.\n\nWith Andy's vocabulary, I think one could also have a concept of a maximal \nresult-set, of whose graph all valid result-set graphs are subgraphs.  Do \nyou see where I'm going here?\n\nI'm just about to shut down for travelling -- I don't know if I'll be able \nto continue this exchange over the next week.\n\n#g\n--\n\nAt 03:42 PM 1/24/03 +0000, Libby Miller wrote:\n\n>I guess I mean that if you were associating a resultset with a query,\n>there might be several different resultsets that would be ok. by this I\n>mean several tables which are valid depending on whether the KB does\n>transitive closure on classes or not etc. Maybe it does this: I find it\n>difficult to read N3, and RDF schemas in general. Examples are the thing\n>for me, so I guess I should get on and try and add to yours from the\n>data we have.\n>\n>Many thanks for doing this Andy :)\n>\n>Libby\n>\n>On Fri, 24 Jan 2003, Seaborne, Andy wrote:\n>\n> > Libby,\n> >\n> > > you might also get multiple valid resultsets per query,\n> > > depending on the\n> > > power of the KB.\n> >\n> > I'm not sure which way round you mean \"multiple valid resultsets per \n> query\":\n> > the vocabulary allows multiple solutions per result table.  And also\n> > multiple result sets per result graph because it is rooted from a single\n> > node.  The example uses <> as that node but there is no reason it has to be\n> > that; you could have a bNode there, and have another starting bNode\n> > somewhere else.\n> >\n> > Could you give an example of when there would be multiple result sets?  I\n> > can image a \"query request\" to actually consist of a series of \n> \"queries\" all\n> > of which should be executed.\n> >\n> >       Andy\n> >\n> > > -----Original Message-----\n> > > From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n> > > Sent: 24 January 2003 15:05\n> > > To: Seaborne, Andy\n> > > Cc: 'Graham Klyne'; 'public-esw@w3.org'\n> > > Subject: RE: Vocabulary for result sets\n> > >\n> > >\n> > >\n> > > you might also get multiple valid resultsets per query,\n> > > depending on the\n> > > power of the KB.\n> > >\n> > > On Fri, 24 Jan 2003, Seaborne, Andy wrote:\n> > >\n> > > >\n> > > > > -----Original Message-----\n> > > > > From: Graham Klyne [mailto:GK@NineByNine.org]\n> > > > > Sent: 23 January 2003 21:12\n> > > > > To: Seaborne, Andy\n> > > > > Cc: 'public-esw@w3.org'\n> > > > > Subject: Re: Vocabulary for result sets\n> > > > >\n> > > >\n> > > > ...\n> > > >\n> > > > >\n> > > > > Hmmm... I wonder of there should be links to, or\n> > > identifiers of, the\n> > > > > knowledge-base and query used, so that valid results from\n> > > > > different queries\n> > > > > can be differentiated.  In practice, I think this kind of\n> > > > > testing is a\n> > > > > relatively closed-world activity, so maybe it doesn't matter.\n> > > > >\n> > > >\n> > > > Graham,\n> > > >\n> > > > Good point.  A number of properties to annotate the result\n> > > set would be\n> > > > good.  Of course, nothing stops any properties being added\n> > > ... but putting\n> > > > them in the vocabulary encourages their use.\n> > > >\n> > > > Are there any suitable properties from other vocabularies to reuse?\n> > > >\n> > > > Also - this could be the result from a query, not just\n> > > recording information\n> > > > for a testcase.  In this case, we still have a\n> > > query->single graph approach\n> > > > but the presentation of the results isn't a subgraph of the\n> > > original KB, but\n> > > > an encoding of the variable bindings.  Each solution can be\n> > > substituted into\n> > > > the pattern for the query to generate a sequence of\n> > > subgraphs, each of which\n> > > > satisfy the query but the result set graph does not feel\n> > > like knowledege\n> > > > extraction anymore.\n> > > >\n> > > >   Andy\n> > > >\n> > > >\n> > > >\n> > >\n> >\n> >\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Initial Workshop Report &quot;last call&quot",
            "content": "Hi folks,\n\nthe Initial Workshop report is more or less complete (spellchecking still\nneeds to be done) and I am preparing to upgrade it to a completed report.\nAnoyone with comments on the draft should send them now (they are very\nwelcome) -\nhttp://jigteam.w3.org/2001/sw/Europe/reports/initial_workshop_report/Overview\n\ncheers\n\nCharles\n\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "corected URI Re: Initial Workshop Report &quot;last call&quot",
            "content": "Sorry folks, should be\nhttp://www.w3.org/2001/sw/Europe/reports/initial_workshop_report/Overview.html\n\nchaals\n\nOn Tue, 28 Jan 2003, Charles McCathieNevile wrote:\n\n>Hi folks,\n>\n>the Initial Workshop report is more or less complete (spellchecking still\n>needs to be done) and I am preparing to upgrade it to a completed report.\n>Anoyone with comments on the draft should send them now (they are very\n>welcome) -\n>\n>cheers\n>\n>Charles\n>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RDF/XML format for email and other message",
            "content": "For information:\n\nRe:  http://www.ietf.org/internet-drafts/draft-klyne-message-xml-00.txt\n\nI'm reviving an old project of mine to define an XML format to carry \ninformation from email and related message formats.  This work started life \nas a proposal for an instant messaging format, but since attracted interest \nfrom XML application developers who wanted to process email-related \ninformation.  The goal is, in part, to create an XML message format that is \nalso RDF compliant; i.e. accessible to RDF parsers with conversion.  (The \ngoal is NOT to do email-in-XML.)\n\nMy plan for this is to update the document with feedback I'm getting from \nsome interested folks and request publication as an informational RFC.\n\nPaul Hoffman has kindly provided a mailing list and web archive page at the \nIMC site:\n     http://www.imc.org/ietf-message-xml/\n\n#g\n\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope Report: Mapping Semantic Web Data with RDBMSe",
            "content": "Hi,\n\nI have read your paper with great interest, especially section 5 about\nmapping RDBMS schemas onto RDF. There are two Open Source tools for mapping\ndata from a RDBMS to RDF:\n\n1. KAON REVERSE is based on the KAON framework and has a graphical user\ninterface to design mappings. The KOAN team is just working on a new\nextended version, which can map relational database content to ontologies\nenabling both storage of instance data in such databases and querying the\ndatabase through the conceptualisation of the database.\nSee: http://kaon.semanticweb.org/alphaworld/reverse/view\n\n2. D2R MAP (a tool I have developed that) is based on JENA and uses a\ndeclarative XML-based language to describe mappings. It can be used from\ncommand line or in applications working with JENA models.\nSee: http://www.wiwiss.fu-berlin.de/suhl/bizer/d2rmap/D2Rmap.htm\n\nI have been pleased to see that my tool fulfils nearly all the\n\"requirements\" you formulated in your paper:\n5.2. / 5.3 Export of conceptual entities: Supported by the concept of\nClassMaps.\n5.4. Naming of entities: Blank nodes and URIrefs with different construction\nschemas (patterns, translationtables) are supported.\n5.4 Different entities in the same relation: Can be handled with two\nClassMaps and a ObjectPropertyBridge reference between them.\n5.5. Choice of property names: Free name choise is supported.\n5.6. Foreign Keys and multiple relations: Multiple arcs are supported with\nthe groupby attribute. RDF containers are in the language specification but\nare not implemented in the tool yet.\n5.7. Many-many relationships: Supported.\n5.9. rdf:datatypes: Attributes to specify datatypes are part of language\nspecification but not implemented yet (I'm waiting for Jena  to support\ndatatypes).\n\nRegards\nChris\n\n\n\n"
        },
        {
            "subject": "Perl module for FOA",
            "content": "I noticed that Ben Trott has released a perl module for FOAF\nhttp://www.sixapart.com/log/2003/01/fun_with_foaf.shtml\n\nHaven't looked at in in any great detail\n\nCheers\n\nSteve\n\n\n\n"
        },
        {
            "subject": "fw ?????I?I?W???s???v?A???O???????F?? fWjMElNVCtZaTclk",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Thesaurus Pape",
            "content": "Here is the paper which we submitted to the Semantic Web and\nDatabases workshop at VLDB.\n\nB\n\n\n\n\n\n\napplication/octet-stream attachment: swdb-thesaurus.zip\n\n\n\n\n"
        },
        {
            "subject": "Fw: ANNOUNCEMENT: Raptor RDF Parser Toolkit 0.9.1",
            "content": "Started November 2000 and 1.0 is nearly in sight now!\n\nDave\n\n------- Forwarded Message\nTo: www-rdf-interest@w3.org\nSubject: ANNOUNCEMENT: Raptor RDF Parser Toolkit 0.9.11\n\n\n   Raptor RDF Parser Toolkit 0.9.11\n     http://www.redland.opensource.ac.uk/raptor/\n\n               Supported by EU IST project SWAD-Europe\n  http://www.w3.org/2001/sw/Europe/\n\nRaptor is a free software/Open Source C library that parses RDF\nsyntaxes such as RDF/XML and N-Triples into RDF triples.  It handles\nall RDF vocabularies such as FOAF, RSS 1.0, Dublin Core and OWL.\n\nRaptor was designed to work closely with the Redland RDF library but\nis fully separate.  It is a portable library that works across many\nPOSIX systems (Unix, GNU/Linux, BSDs, OSX, cygwin, win32).  Raptor\nhas no memory leaks and is fast.\n\nThis is a major stable release of Raptor and the 1.0 release\ncandidate since it now handles all the RDF Core working group test\ncases.  At version 1.0 the deprecated functions will be removed.\n\nSummary of changes:\n\n * Completely handles the revised RDF/XML syntax\n   (including post W3C Last Call changes)\n   - Added Unicode Normal Form C (NFC) checking for literals\n     (requires GNOME glib 2.0 at present)\n   - Added Exclusive XML Canonicalization for XML Literals\n   - Added many more checks for bad syntax (mostly illegal property attributes)\n   - Updated parseType=\"Collection\" triples after RDF Core WG changes.\n\n * Added an experimental RSS Tag Soup parser to read any pile of XML\n   that has elements such as channel, image, item tags with title,\n   description etc inside them into coherent RSS 1.0 RDF triples.\n   (Requires libxml 2.5.0 or newer)\n\n * API: Added new methods raptor_get_name, raptor_get_label.\n   Added new methods to control generation of IDs.\n   Modified utility function raptor_xml_escape_string arguments.\n\n * Ripped out ISO 3166 country code parts since commercial use might\n   be subject to a license fee.\n\n * Improvements to GNOME GTK example 'grapper'.\n\n * Several internal reorganisations for pulling out a SAX2 API, XML C14N.\n\n * Other minor bug fixes.\n\nThe release consists of the full sources, RPM binaries and source RPM\npackages for RedHat Linux 9.  These are also available from the\nRedland SourceForge mirror site at\n  http://sourceforge.net/projects/librdf/\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS and use Raptor in various demos (as part of Redland).\n\nI post updates about Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\nDave\n\n------- End of Forwarded Message\n\n\n\n"
        },
        {
            "subject": "SWADEurope dissemination and use plan update",
            "content": "http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n\n- it's not quite done, but getting there.\n\nLet me know if you spot any errors or ommissions/have any comments.\n\nthanks\n\nLibby\n\n\n\n"
        },
        {
            "subject": "SWADEurope dissemination and use plan update",
            "content": "http://www.w3.org/2001/sw/Europe/reports/dissemination_use_plan/\n\n- it's not quite done, but getting there.\n\nLet me know if you spot any errors or ommissions/have any comments.\n\nthanks\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: Semantic Storage and Retrieval Day ",
            "content": "On Thu, 5 Jun 2003 15:20:49 +0200 (CEST)\nDirk-Willem van Gulik <staff@asemantics.com> wrote:\n \n> It was good to meet you during the Budapest meeting. Once of the things\n> Dave Beckett and various others touched upon was the desire to have a\n> \"Semantics Storage (and Retrial) Day\" or workshop. Which would centre\n> around 'real' solution and very practical and down to earth things like\n> (simple) query languages and API's. Very bottom of the stack.\n\nMy goal was to organise this and help run it as part of the outreach\nthat the SWAD Europe project which I work for deals with.  Since I\nam involved with the guts of semweb data storage, and (co-)written\nthe reports you mention later, that was the outline of my idea.  Deal\nwith key implementors in europe (but others are very welcome) on\npractical issues and solutions, problems with storing and manipulating\nsemweb data.\n\n> We'd be quite happy to see if we can make such a thing happen in the\n> Netherlands;  lets say within a 30 minute radius around Schiphol Airport\n> (which essentially is Amsterdam) and within easy reach from the other three\n> (budged) airports which people are likely to use.\n\nThanks for the offer\n\n> We can do this either by hosting it ourselves or by working with people at\n> a Leiden, Delft or Amsterdam university. We have the contacts there to\n> borrow a room, and so on - little problem there. If we pick the date right\n> - then reasonable accommodation within walking distance from room and\n> train station should be little problem.\n\nI was hoping that it might be possible to get ensure some of the nearby\npeople at the Amsterdam universities such as Frank van Harmelin,\nGuus Schrieber, co-chair of the web ontology group interested.\n\n> I'd also would like to collect some sort of papers/position statements or\n> something else which we can after the meeting publish as an ID or\n> something like that. Just to have a report which kind of follows up as a\n> straight implementers report on he 2001 reports by Dave and Libby. [1,2]\n\nI wasn't proposing peer-reviewed workshop papers but position papers\nare probably in-order.\n\n> We'll certainly will make sure it is on the 'Night Net', the 24h rail-ring\n> between Amsterdam, Rotterdam, the Hague and Utrecht, so that\n> before/during/after the meetings all the delights of Amsterdam are within\n> striking distance.\n> \n> Question:\n> \n> ->Is this something people want ?\n\nI've had a few private mails with interest from several groups.\n\n> -> Should it have a strong hands/on RDQL, *QL, RDF Query\n> related focus ? Or should it also go in depth with regards\n> to storage strategies, API's and methods ? What scope ?\n\nSee below\n\n> ->One, two or three days ?\n\nI think over two days, maybe 10pm day1 to 4pm day2\n\n> ->Middle of Q3 - or earlier ? Later ? Specific dates which should\n> be totally out ? We need about 5-6 weeks to get a meeting room\n> of the appropriate size and figure out the logistics.\n\nAiming for Oct or later, taking care not to clash with ISWC in Florida\n20-24 Oct.  There also might be clashes in September.\n\n> ->Any specific group in the Netherlands people feel we should\n> approach (first) or really work together with; either at a\n> university or at a company.\n\nPossibly (but more focussed on ontologies, higher level applications??)\n  Frank van Harmelen, On-To-Knowledge\n  http://www.cs.vu.nl/~frankh/\n\n  Guus Schreiber, co-chair of webont, IBROW, Ontoweb\n  http://www.cs.vu.nl/~guus/ \n\nNow both of them are at vu.nl\n\n> ->How many people roughly < 10, 10-25, 20-50 or >50 ?\n\naim for 20\n\n> At @semantics we are happy to just be a facilitator, and all to way up to\n> essentially host it completely. However - given that we are a small\n> company - we obviously have a bit of an agenda. So it may be much better\n> if this is done under the banner of an appropriate faculty department.\n> And we just facilitate to make this happen. So that is also some of the\n> feedback I'd like to hear. As we'd hate to not make use of people or\n> knowledge right next door.\n\n> Ref's:\n> [1] http://www.w3.org/2001/sw/Europe/reports/rdf_scalable_storage_report/\n> [2] http://www.w3.org/2001/sw/Europe/reports/rdf_ql_comparison_report/\n\nOur SWAD Europe project, via myself, would be happy to organise the\nadmin parts of registration, papers, web site, etc. but would need local\nhelp with logistics such as accommodation, rooms, web access, food etc.\n\nI enclose below an updated version of what II proposed originally to the\npublic-esw@w3.org list which is the public list that SWAD Europe works\non.  Feel free to join that last, in fact I'd like to move the workshop\ndiscussion there if possible, or at least CC: it.\n\npublic-esw http://lists.w3.org/Archives/Public/public-esw/\n\nDave\n\n==============================\nProposal\n\nTitle: SWAD Europe Workshop on Semantic Web Storage and APIs\n\nDate: TBD - suggest October - December 2003\n  (avoiding ISWC 20-24 Oct)\n\n   Propose a two day event 10am day 1 to 4pm day 2.\n\nScale: 20 participants\n\nLocation: TBD - Amsterdam or nearby suggested\n\nCurrent Identified Stakeholders (NOT an exclusive list):\n\n  In Europe:\n    AKTORS 3store - University of Southampton, UK\n    Jena - HP Labs, Bristol, UK\n    KAON - FZI / AIFB, Karlsruhe, Germany\n    RDFSuite Group - @semantics, Greece, Netherlands, Italy\n    Sesame - Aidministrator, Netherlands\n    Redland - Dave Beckett (myself), Bristol, UK\n\n    and ... other groups related to the above ?\n      On-To-Knowledge - Frank van Harmelen, Vrije Universiteit Amsterdam\n        project includes University of Karlsruhe - KAON, Aidministrator above\n      IBROW / OntoWeb / WebOnt co-chair - Guus Schreiber\n      Ontoweb projects\n      FOAF implementors\n      W3C/ERCIM ... \n\n  Elsewhere, the Europe in the title not withstanding.\n    4Suite - Buffalo, USA\n    Mindswap - Maryland, USA\n    Mozilla - ?, USA\n    TAP project - Stanford, USA\n    HP USA - DSpace, SIMILE etc - USA\n    n3, cwm, ... - MIT/W3C, USA\n    rdflib - Daniel Krech, USA\n\n\nWorkshop outline\n\nExisting APIs for the RDF family of technologies (RDF, DAML+OIL, OWL ...)\nare maturing after several years of development and improvement.\n\nThere is no single dominant API either across multiple languages (ok,\nRedland has some of that) or in a single implementation language.\nEach of them covers a different goal and has different strengths.\n\nThis workshop would aim to bring together existing and new developers\nof semantic web storage and APIs to share their experiences and\nlessons.  In particular this workshop could cover\n\n  * Implementation techniques\n  * Storage models and database schemas\n  * Scalability, aggregation and provenance\n  * Lessons from using RDBMSes for semantic web storage\n  * Test data and queries for performance comparisons across designs.\n  * Implementing RDF Datatypes\n\nPossibly covering (might be a bit too off-storage):\n  * APIs for query languages\n  * OWL and logic layer functionality - inference engines, validation\n\nExpected Outcomes\n\n  * State of the current APIs\n  * Indication of state of potential API standardisation\n  * Implementation techniques\n  * Updated SWAD-E deliverables 10.1, 10.2\n  * Proposals for a performance comparision test suite\n  * Some Implementation reports on RDF and OWL\n\nRelevant SWAD-E Work\n\nThis relates to at least the following SWAD-E work and completed\ndeliverables (as well as later work).\n\nWP7 Workpackage 7: Databases, Query, API, Interfaces\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-7.html\n\n  D7.1 RDF API requirements and comparison\n  http://www.w3.org/2001/sw/Europe/reports/rdf_api_comparison_report/\n\n  D7.2 Databases, Query, API, Interfaces: report on Query languages\n  http://www.w3.org/2001/sw/Europe/reports/rdf_ql_comparison_report/\n\nWP10: Tools for Semantic Web Scalability and Storage\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-10.html\n\n  D10.1 Scalability and Storage: Survey of Free Software / Open\n    Source RDF storage systems \n  http://www.w3.org/2001/sw/Europe/reports/rdf_scalable_storage_report/\n\n  D10.2 Mapping data from RDBMS\n  http://www.w3.org/2001/sw/Europe/reports/scalable_rdbms_mapping_report/\n\n\nOther Events\n\nAt ISWC 2003 there is a workshop on\n  Practical and Scalable Semantic Systems\n  http://km.aifb.uni-karlsruhe.de/ws/psss03\n \n  (site down right now)\n\nso need to take care with not duplicating work.\n(Also the event is not in Europe, so tricky for EU pariticpants)\n\n\n\n"
        },
        {
            "subject": "Re: Expressing mathematical relationships in an ontology",
            "content": "Fwd'd thread from RDF IG list.\n\nRe MathML/RDF, any MathML folks here want to comment? Stilo people, Max?\n\nDan\n\n----- Forwarded message from Jimmy Cerra <jimbobbs@hotmail.com> -----\n\nFrom: \"Jimmy Cerra\" <jimbobbs@hotmail.com>\nDate: Fri, 13 Jun 2003 20:42:30 -0400\nTo: <www-rdf-interest@w3.org>\nSubject: Re: Expressing mathematical relationships in an ontology?\nMessage-ID: <000101c3320d$d5f6a2a0$0100a8c0@picard>\nReply-To: <jimbobbs@hotmail.com>\nResent-From: www-rdf-interest@w3.org\nResent-Date: Fri, 13 Jun 2003 20:42:40 -0400 (EDT)\n\n\n> It would be nice if this mathematical relationship could\n> be declaratively expressed:\n> 2.54 centimeters = 1.0 inches\n\nMathML is commonly used to mark up mathematical expressions (Mathematica\nuses MathML I think).  Could it be used with RDF?\n--\nJimmy Cerra\n\n] \"I had to learn very early not to limit\n]  myself due to others limited imagination.\"\n]  - Dr. Mae C. Jemison\n\n----- End forwarded message -----\n\n\n\n"
        },
        {
            "subject": "Draft Report  Virtual Geography Worksho",
            "content": "Hi folks,\n\nI have prepared a draft report on the Virtual Workshops held on using RDF for\ngeographic information, at\nhttp://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_3/\n\nany comments are welcome.\n\nCheers\n\nCharles McCN\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Explaining why we use RDF instead of just XM",
            "content": "RDF IG, (copying SWAD-Europe list)\n\nI've just written a few comments in a weblog, \nhttp://www.pmbrowser.info/hublog/archives/000258.html that I thought I'd \narchive here too, see if they make sense to folks. I was trying to explain\na bit about why RDF might make sense for someone considering the use of \nXML for a vocabulary. I think maye I just restated what Danny said there at \ngreater length...\n\n[[\nOne way to think about this: the Resource Description Framework (RDF) \nis a family of XML applications who agree to make a certain tradeoff \nfor the sake of cross-compatibility. In exchange for accepting a number \nof constraints on the way they use XML to write down claims about the world, \nthey gain the ability to have their data freely mixed with that of other \nRDF applications.\n\nSince many descriptive problems are inter-related, this is an attractive offer, \neven if the XML syntax is a little daunting. MusicBrainz can focus on describing \nmusic, RSS 1.0 on describing news channels, FOAF on describing people, \nDublin Core on describing documents, RdfGeo on places and maps, RdfCal on \ndescribing events and meetings, Wordnet on classifying things using nouns, \nChefMoz on restaurants, and so on.\n\nYet because they all bought into the RDF framework, any RDF document can draw \non any of these 'vocabularies'. So an RSS feed could contain markup describing \nthe people and places and music associated with a concert; a calendar entry \ncould contain information about it's location and expected attendees, a \nrestaurant review could use FOAF to describe the reviewer, or a FOAF file \ncould use Dublin Core to describe the documents written by its author, as \nwell as homepages and other information about those authors.\n\nSo, for any particular application, you could do it in standalone XML. RDF \nis designed for areas where there is a likely pay-off from overlaps and \ndata merging, ie. the messy world we live in where things aren't so easily \nparceled up into discrete jobs.\n\nBut it is a tradeoff. Adopting RDF means that you just can't make up your \nXML tagging structure at random, but you have to live by the 'encoding' rules \nexpected of all RDF applications.\nThis is so that software written this year can have some hope of doing useful \nthings with vocabularies invented next year: an unpredictable 'tag soup' \nof arbitrary mixed XML is hard to process. RDF imposes constraints so that \nall RDF-flavoured XML is in broadly the same style (for example, ordering \nof tags is usually insignificant to what those tags tell the world). \nThose constraints take time to learn and understand and explain, and so \nadopting RDF isn't without its costs.\n\nAnd so the more of us who use RDF, the happier the cost/benefit tradeoff gets, \nsince using RDF brings us into a larger and larger family of inter-mixable data.\n\nDoes this make any sense? \n]]\n\n\n\n"
        },
        {
            "subject": "Re: Explaining why we use RDF instead of just XM",
            "content": "On Wed, 25 Jun 2003, Dan Brickley wrote:\n\n[[snipped: a pretty good description of why I use RDF and not just non-RDF\nXML]]\n\n>Does this make any sense?\n\nyes, to me it makes good sense.\n\nchaals\n\n\n\n"
        },
        {
            "subject": "Re: Explaining why we use RDF instead of just XM",
            "content": "It makes sense as far as it goes.  \n\nUnfortunately, this makes RDF sound like a complex and expensive way to define \na simple namespace.  How is an RDF application different from an \nXML-Namespace?\n\n\nOn Wednesday 2003-06-25 02:48, Dan Brickley wrote:\n> RDF IG, (copying SWAD-Europe list)\n\n[Why use RDF applications?]\n> [[\n\n* * * \n\n>\n> So, for any particular application, you could do it in standalone XML. RDF\n> is designed for areas where there is a likely pay-off from overlaps and\n> data merging, ie. the messy world we live in where things aren't so easily\n> parceled up into discrete jobs.\n>\n> Does this make any sense?\n> ]]\n\n\n\n"
        },
        {
            "subject": "Re: Explaining why we use RDF instead of just XM",
            "content": "I don't know that it is. It is different from what I believe people think\nthey are doing when they create XML namespaces - but I suspect that many\npeople are like me and actually don't write a schema first up because they\nwant to play around with it first...   an ideal situation for declaring it as\nan RDF vocabulary instead of using an XML schema.\n\nchaals\n\nOn Wed, 25 Jun 2003, Trent Shipley wrote:\n\n>\n>It makes sense as far as it goes.\n>\n>Unfortunately, this makes RDF sound like a complex and expensive way to define\n>a simple namespace.  How is an RDF application different from an\n>XML-Namespace?\n>\n>\n>On Wednesday 2003-06-25 02:48, Dan Brickley wrote:\n>> RDF IG, (copying SWAD-Europe list)\n>\n>[Why use RDF applications?]\n>> [[\n>\n>* * *\n>\n>>\n>> So, for any particular application, you could do it in standalone XML. RDF\n>> is designed for areas where there is a likely pay-off from overlaps and\n>> data merging, ie. the messy world we live in where things aren't so easily\n>> parceled up into discrete jobs.\n>>\n>> Does this make any sense?\n>> ]]\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: Explaining why we use RDF instead of just XM",
            "content": "my 2'penn'oth\n\nI think that this comes near the nub of the question around\ninteroperability using RDF and its relationship to XML Schema.\n\nMany organisations are spending a lot of time taking \nthe opposite approach to Charles by carefully crafting XML Schemas\nfor their own use (e.g. see the UK e-Gif Schema repository\nhttp://www.govtalk.gov.uk/schemasstandards/schemasstandards.asp),\nreusing components of other schemas and then wanting to use them\nfor interchange.  Combination of elements from different \nschemas is then controlled via namespace - and as they are keen on \nsyntactic validation only in pretty restricted circumstances \n(avoiding \"the unpredictable tag soup\").  From this PoV, the \nfree mixing of vocabulary advocated by Charles and Dan looks \npretty anarchic and uncontrollable.  \n\nThere is a challenge to RDF here to convince them:\n - its more than just the namespace (Trent's question)\n - it can help enable the interoperability required of the XML Schemas\n   when they get into difficulties through conflicting XML representations\n   of the same thing.  But they will still want the structural\n   framework of XML Schema (or similar).\n\nSWAD WP5/6 is looking at this.\n\nBrian \n\n\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org]\n> Sent: 25 June 2003 13:18\n> To: Trent Shipley\n> Cc: public-esw@w3.org; RDF Interest Group\n> Subject: Re: Explaining why we use RDF instead of just XML\n> \n> \n> \n> \n> \n> I don't know that it is. It is different from what I believe \n> people think\n> they are doing when they create XML namespaces - but I \n> suspect that many\n> people are like me and actually don't write a schema first up \n> because they\n> want to play around with it first...   an ideal situation for \n> declaring it as\n> an RDF vocabulary instead of using an XML schema.\n> \n> chaals\n> \n> On Wed, 25 Jun 2003, Trent Shipley wrote:\n> \n> >\n> >It makes sense as far as it goes.\n> >\n> >Unfortunately, this makes RDF sound like a complex and \n> expensive way to define\n> >a simple namespace.  How is an RDF application different from an\n> >XML-Namespace?\n> >\n> >\n> >On Wednesday 2003-06-25 02:48, Dan Brickley wrote:\n> >> RDF IG, (copying SWAD-Europe list)\n> >\n> >[Why use RDF applications?]\n> >> [[\n> >\n> >* * *\n> >\n> >>\n> >> So, for any particular application, you could do it in \n> standalone XML. RDF\n> >> is designed for areas where there is a likely pay-off from \n> overlaps and\n> >> data merging, ie. the messy world we live in where things \n> aren't so easily\n> >> parceled up into discrete jobs.\n> >>\n> >> Does this make any sense?\n> >> ]]\n> >\n> \n> -- \n> Charles McCathieNevile  http://www.w3.org/People/Charles  \n> tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): \n> +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n\n\n\n"
        },
        {
            "subject": "RE: Explaining why we use RDF instead of just XM",
            "content": "danbri - it did make sense, and I particularly liked the last couple of\nparagraphs: future proofing and the contrast between tag soup and a happy\nfamily of compatible data.\n\n> my 2'penn'oth\n>\n> I think that this comes near the nub of the question around\n> interoperability using RDF and its relationship to XML Schema.\n>\n> Many organisations are spending a lot of time taking\n> the opposite approach to Charles by carefully crafting XML Schemas\n> for their own use (e.g. see the UK e-Gif Schema repository\n> http://www.govtalk.gov.uk/schemasstandards/schemasstandards.asp),\n> reusing components of other schemas and then wanting to use them\n> for interchange.  Combination of elements from different\n> schemas is then controlled via namespace - and as they are keen on\n> syntactic validation only in pretty restricted circumstances\n> (avoiding \"the unpredictable tag soup\").  From this PoV, the\n> free mixing of vocabulary advocated by Charles and Dan looks\n> pretty anarchic and uncontrollable.\n>\n> There is a challenge to RDF here to convince them:\n>  - its more than just the namespace (Trent's question)\n>  - it can help enable the interoperability required of the XML Schemas\n>    when they get into difficulties through conflicting XML representations\n>    of the same thing.  But they will still want the structural\n>    framework of XML Schema (or similar).\n>\n> SWAD WP5/6 is looking at this.\n\nThere was an interesting development around the world of blog/RSS not long\nago, where some of the RSS 2.0 brigade started inserting full-content XHTML\ninto their feeds. The people playing with this were generally very smart\nprofessionals with considerable web/XML experience. It's interesting in one\nsense because it means you can XPath on the whole lot together (cargo cult\nRDF?). But interesting too in a non-tech sense, because there seemed to be a\ntacit assumption that namespace qualification also brought magic\ninterpretation. Ok, so this newsreader world isn't far from the browser\nworld, and they were talking about XHTML, and I'm sure some folks would be\naware of what was happening, etc etc, but I don't recall seeing a single\nremark on how the agent was expected to support the stuff that had been\ninserted. It was simply expected to work, i.e. display appropriately in a\nnewsreader, and (ka-zaaam!) most of the time it did. It was only a week or\ntwo later that comments started appearing along the lines of \"I got a\nconflict with the display of my <description> content\" (I believe these\nproblems were quickly ironed out, but I somehow doubt whether there's a\nformal spec to say how). Adoption of XHTML content in feeds by the\ndevelopers was rapid (Sam Ruby's blog was something of a hub once more, some\nrefs at [1]).\n\nOk, this was all occurring in a scruffy side of the industry, but I still\nthink it's quite telling - for blogging apps this is still the mainstream,\nand a lot of the people involved use XML in their day jobs. My (entirely\nsubjective) reading now is that there were probably two assumptions made :\nthat separating the material using namespaces was considered enough to make\nthings work; that the data would never be used outside of the immediate\n(browser-like newsreader) context. Both of which could represent obstacles\nto explaining the joys of RDF. Good luck with WP5/6!\n\nCheers,\nDanny.\n\n[1] http://www.intertwingly.net/blog/1299.html\n\n\n\n"
        },
        {
            "subject": "trip report W3C Technical Plenary 2003-03-03 - 2003-030",
            "content": "I recently attended the W3C technical Plenary in Boston:\n\nhttp://www.w3.org/2002/10/allgroupoverview/\n\nThis was the third such event (they happen yearly). They are a\nweek of working group and interest group meetings with an all-group\nmeeting on the Wednesday. The working groups meetings are sometimes\nopen to observers, sometimes not; the plenary is completely open. The\nmain event for me this time was a \"Semantic Web Architecture Meeting\" -\nan ad-hoc group created to address various semantic web issues, which\nmet all of Thursday 6th and Friday 7th. The meeting page now contains\nlinks to the relevant parts of the logs, as well as attendees:\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/\n\nA major issue in this meeting and in general in the week (at least\namong the people I met) was RDF query.\nChartering an RDF query language working group has seemed like a good\nidea to some people for a while, but it was unclear what the scope would\nbe (e.g. should it be rules and query or just query; should it be\nrestricted to a simple language or encompass complex ones; should it\ninclude protocols). Alberto and Andy's usecases doc seems to have meant\nmore discussion on the matter.\n\nhttp://rdfstore.sourceforge.net/2002/06/24/rdf-query/\n\nThere were several query specific meetings: a birds of a feather lunch\non Wednesday; a 2 hour evening meeting on thursday, and several hours in\nthe Semantic Web architecture meeting on Friday. Various logs are\navailable for all except the lunch meeting:\n\nhttp://www.w3.org/2003/03/06-swarch-irc from 23:31:19\nhttp://www.w3.org/2003/03/07-swarch-irc from start to 01:15:29\n(Thursday night BOF)\nand 13:20:53 to 15:40:32 (and lightning talks afterwards - for Friday\nmorning session)\n\nThe Friday query session was the most formal, led by Tim Berners-Lee,\nand centering around his document:\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/query\n\nsnippet:\n[[\nSo, if work were begun in this area, formally or informally, more or\nless in chronological order, one might hope to see:\nAbstract syntax of query language - probably described in RDF.\n\nDefinition of a few conformance levels (monotonically increasing in\nfeatures supported)\n\nA common concrete syntax in compact (non-XML) form\n\nOntology for description of inference services provided by a service.\n\nA set or sets of standard functions\n\nA profile or profiles which combine the above to enhance\ninteroperability, when experience with common engines is sufficient to\ndefine interop levels.\n]]\n\nMy impression was that there was eventually some agreement that such a\nworking group would need to start with the basics first, probably RDF\nquery only, starting with simple queries. This was after extensive\ndiscussions about the relationship between rules and RDF query, in the\nBOFs and in the Friday session.\n\nPersonally, I think we can get a long way without a working group, for\nexample by creating testcases for interoperability, as is our intention\nin the RDF query meetings run as an input to the SWAD-Europe\ndeliverable 7.2 (the new query testcase page that Dan\nBrickley made is at http://www.w3.org/2003/03/rdfqr-tests/).\n\nHere's what I did in the week.\n\nMon 3rd\n\nDid one of my action items from calendaring, namely wrote up how to\ngenerate the RDF iCalendar schema using CWM:\n\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2003Mar/0003.html\n\nTalked to Eric Prud'hommeaux about his work mapping RDF query langauges\nto relational databases, and creating relational database structures\nfrom a group of RDF triples. Pointed him in the direction of Jan\nGrant. Eric has a document about this:\n\nhttp://www.w3.org/2003/01/21-RDF-RDB-access/#migration\n\nChatted with Pat Hayes, Harold Boley, EricP, Danbri about query and\nrules. Pat talked about his experiences in creating DAML QL.\n\n(Daml QL:\nhttp://www.daml.org/2002/08/dql/dql (model)\nhttp://www.ksl.stanford.edu/projects/dql/syntax.shtml (proposed syntax)\n)\n\nThought that it might be useful for testcases for query if there\nwas a converter between various RDF query syntaxes; wondered how\npossible this was. Hacked on query code in the evening.\n\n\nTuesday 4th\n\nTalked to Hugo Haas about his calendar usecases, and Bert Bos about the\ncalendar stuff he's been doing:\n\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2003Mar/0005.html\n\nAt lunch talked with Benjamin Grosof and Harold Boley about rules and\nquery.\n\nLater spent a long time getting conversion to work between various query\nlanguages. The result was a first pass at a query converter:\n\nhttp://www.ilrt.bris.ac.uk/discovery/2003/03/query/readme.html\n\n\nThusday 6th\n\nSemantic web discussions, see\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/#logs and individual\nentries in http://www.w3.org/2001/sw/meetings/tech-200303/ for each\nsection.\n\nA great deal was discussed. The meeting page has links to logs and\nreferences. Three sections stood out for me:\n\n1. RDF applications (Dan Brickley/Dan Connolly)\n\nA discussion of what vocabularies people use in the room, and what RDF\ndata is out there:\n\nhttp://www.w3.org/2003/03/06-swarch-irc#T15-35-06\n\n2. Embedding RDF in html (led by Ralph Swick)\n\nSome of the html WG came along, and Steven Pemberton presented a\npossible way of getting around the issue that RDF in html cannot be\nvalidated by DTD:\n\nhttp://lists.w3.org/Archives/Public/w3c-rdfcore-wg/2003Feb/0103.html\n\nThere was some discussion of the possibility of anXML syntax for\nN-Triple, and also a discussion of XML schema and RDF:\n\"DanC: It's not possible to write one-last-true-schema for\nRDF/XML.\"\nRelaxNG does much better.\nSeveral people expressed interest in helping HTML WG make a better meta\nsyntax.\nJos de Roo: If you can't do it by value, due it by reference\n\n3. Social meaning discussion (led by Jeremy Carroll)\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/social-meaning.html\nresults:\nhttp://lists.w3.org/Archives/Public/www-rdf-comments/2003JanMar/0486.html\n\n\nEvening meeting about rdf queries and rules - see\n\nhttp://www.w3.org/2003/03/06-swarch-irc from 23:31:19\nhttp://www.w3.org/2003/03/07-swarch-irc from start to 01:15:29\n\n\nFriday\n\n9-4\nSemantic web discussions, see\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/#logs and individual\nentries in http://www.w3.org/2001/sw/meetings/tech-200303/ for each\nsection.\n\nThe query discussion interested me the most - see above for my\nimpressions about that. There were also a number of lightning talks,\nmany about query.\n\nThere were interesting presentations for Liddy Neville and from Guus\nSchreiber about best practice, education and outreach.\n\nGuus:\nhttp://www.w3.org/2001/sw/meetings/tech-200303/best-practices\nhttp://www.w3.org/2003/03/07-swarch-irc#T19:33:18\n\nLiddy:\nhttp://www.w3.org/2003/03/07-swarch-irc#T19:53:00\n\n--\n\nMy photos from the week are at\n\nhttp://swordfish.rdfweb.org/photos/2003/03/03/\nhttp://swordfish.rdfweb.org/photos/2003/03/04/\nhttp://swordfish.rdfweb.org/photos/2003/03/05/\nhttp://swordfish.rdfweb.org/photos/2003/03/06/\nhttp://swordfish.rdfweb.org/photos/2003/03/07/\n\n\nLibby\n\n\n\n"
        },
        {
            "subject": "trip report W3C Technical Plenary 2003-03-03 - 2003-030",
            "content": "I recently attended the W3C technical Plenary in Boston:\n\nhttp://www.w3.org/2002/10/allgroupoverview/\n\nThis was the third such event (they happen yearly). They are a\nweek of working group and interest group meetings with an all-group\nmeeting on the Wednesday. The working groups meetings are sometimes\nopen to observers, sometimes not; the plenary is completely open. The\nmain event for me this time was a \"Semantic Web Architecture Meeting\" -\nan ad-hoc group created to address various semantic web issues, which\nmet all of Thursday 6th and Friday 7th. The meeting page now contains\nlinks to the relevant parts of the logs, as well as attendees:\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/\n\nA major issue in this meeting and in general in the week (at least\namong the people I met) was RDF query.\nChartering an RDF query language working group has seemed like a good\nidea to some people for a while, but it was unclear what the scope would\nbe (e.g. should it be rules and query or just query; should it be\nrestricted to a simple language or encompass complex ones; should it\ninclude protocols). Alberto and Andy's usecases doc seems to have meant\nmore discussion on the matter.\n\nhttp://rdfstore.sourceforge.net/2002/06/24/rdf-query/\n\nThere were several query specific meetings: a birds of a feather lunch\non Wednesday; a 2 hour evening meeting on thursday, and several hours in\nthe Semantic Web architecture meeting on Friday. Various logs are\navailable for all except the lunch meeting:\n\nhttp://www.w3.org/2003/03/06-swarch-irc from 23:31:19\nhttp://www.w3.org/2003/03/07-swarch-irc from start to 01:15:29\n(Thursday night BOF)\nand 13:20:53 to 15:40:32 (and lightning talks afterwards - for Friday\nmorning session)\n\nThe Friday query session was the most formal, led by Tim Berners-Lee,\nand centering around his document:\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/query\n\nsnippet:\n[[\nSo, if work were begun in this area, formally or informally, more or\nless in chronological order, one might hope to see:\nAbstract syntax of query language - probably described in RDF.\n\nDefinition of a few conformance levels (monotonically increasing in\nfeatures supported)\n\nA common concrete syntax in compact (non-XML) form\n\nOntology for description of inference services provided by a service.\n\nA set or sets of standard functions\n\nA profile or profiles which combine the above to enhance\ninteroperability, when experience with common engines is sufficient to\ndefine interop levels.\n]]\n\nMy impression was that there was eventually some agreement that such a\nworking group would need to start with the basics first, probably RDF\nquery only, starting with simple queries. This was after extensive\ndiscussions about the relationship between rules and RDF query, in the\nBOFs and in the Friday session.\n\nPersonally, I think we can get a long way without a working group, for\nexample by creating testcases for interoperability, as is our intention\nin the RDF query meetings run as an input to the SWAD-Europe\ndeliverable 7.2 (the new query testcase page that Dan\nBrickley made is at http://www.w3.org/2003/03/rdfqr-tests/).\n\nHere's what I did in the week.\n\nMon 3rd\n\nDid one of my action items from calendaring, namely wrote up how to\ngenerate the RDF iCalendar schema using CWM:\n\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2003Mar/0003.html\n\nTalked to Eric Prud'hommeaux about his work mapping RDF query langauges\nto relational databases, and creating relational database structures\nfrom a group of RDF triples. Pointed him in the direction of Jan\nGrant. Eric has a document about this:\n\nhttp://www.w3.org/2003/01/21-RDF-RDB-access/#migration\n\nChatted with Pat Hayes, Harold Boley, EricP, Danbri about query and\nrules. Pat talked about his experiences in creating DAML QL.\n\n(Daml QL:\nhttp://www.daml.org/2002/08/dql/dql (model)\nhttp://www.ksl.stanford.edu/projects/dql/syntax.shtml (proposed syntax)\n)\n\nThought that it might be useful for testcases for query if there\nwas a converter between various RDF query syntaxes; wondered how\npossible this was. Hacked on query code in the evening.\n\n\nTuesday 4th\n\nTalked to Hugo Haas about his calendar usecases, and Bert Bos about the\ncalendar stuff he's been doing:\n\nhttp://lists.w3.org/Archives/Public/www-rdf-calendar/2003Mar/0005.html\n\nAt lunch talked with Benjamin Grosof and Harold Boley about rules and\nquery.\n\nLater spent a long time getting conversion to work between various query\nlanguages. The result was a first pass at a query converter:\n\nhttp://www.ilrt.bris.ac.uk/discovery/2003/03/query/readme.html\n\n\nThusday 6th\n\nSemantic web discussions, see\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/#logs and individual\nentries in http://www.w3.org/2001/sw/meetings/tech-200303/ for each\nsection.\n\nA great deal was discussed. The meeting page has links to logs and\nreferences. Three sections stood out for me:\n\n1. RDF applications (Dan Brickley/Dan Connolly)\n\nA discussion of what vocabularies people use in the room, and what RDF\ndata is out there:\n\nhttp://www.w3.org/2003/03/06-swarch-irc#T15-35-06\n\n2. Embedding RDF in html (led by Ralph Swick)\n\nSome of the html WG came along, and Steven Pemberton presented a\npossible way of getting around the issue that RDF in html cannot be\nvalidated by DTD:\n\nhttp://lists.w3.org/Archives/Public/w3c-rdfcore-wg/2003Feb/0103.html\n\nThere was some discussion of the possibility of anXML syntax for\nN-Triple, and also a discussion of XML schema and RDF:\n\"DanC: It's not possible to write one-last-true-schema for\nRDF/XML.\"\nRelaxNG does much better.\nSeveral people expressed interest in helping HTML WG make a better meta\nsyntax.\nJos de Roo: If you can't do it by value, due it by reference\n\n3. Social meaning discussion (led by Jeremy Carroll)\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/social-meaning.html\nresults:\nhttp://lists.w3.org/Archives/Public/www-rdf-comments/2003JanMar/0486.html\n\n\nEvening meeting about rdf queries and rules - see\n\nhttp://www.w3.org/2003/03/06-swarch-irc from 23:31:19\nhttp://www.w3.org/2003/03/07-swarch-irc from start to 01:15:29\n\n\nFriday\n\n9-4\nSemantic web discussions, see\n\nhttp://www.w3.org/2001/sw/meetings/tech-200303/#logs and individual\nentries in http://www.w3.org/2001/sw/meetings/tech-200303/ for each\nsection.\n\nThe query discussion interested me the most - see above for my\nimpressions about that. There were also a number of lightning talks,\nmany about query.\n\nThere were interesting presentations for Liddy Neville and from Guus\nSchreiber about best practice, education and outreach.\n\nGuus:\nhttp://www.w3.org/2001/sw/meetings/tech-200303/best-practices\nhttp://www.w3.org/2003/03/07-swarch-irc#T19:33:18\n\nLiddy:\nhttp://www.w3.org/2003/03/07-swarch-irc#T19:53:00\n\n--\n\nMy photos from the week are at\n\nhttp://swordfish.rdfweb.org/photos/2003/03/03/\nhttp://swordfish.rdfweb.org/photos/2003/03/04/\nhttp://swordfish.rdfweb.org/photos/2003/03/05/\nhttp://swordfish.rdfweb.org/photos/2003/03/06/\nhttp://swordfish.rdfweb.org/photos/2003/03/07/\n\n\nLibby\n\n\n\n"
        },
        {
            "subject": "danbri updat",
            "content": "What I've been up to recently:\n\n * a few weeks back met with Stephen again w.r.t. XML WP5 schema work\n * checked in Stephen's contributions to the website, began work on \n   wrapping it up as a report,  see \n   http://www.w3.org/2001/sw/Europe/reports/xml_schema_tools_techniques_report/\n   Stephen's contrib is currently linked from the 'other docs' section.\n * Discussed WP4 w/ Nikki, published her draft designs at\n   http://www.w3.org/2001/sw/Europe/reports/sw_soap_design_report/\n * then I got really sick and lost most of the week before last\n * got well in time to fly to Boston for W3C Tech Plenary last week,\n   thanks to libby for great writeup to which I don't have much to add \n   except that RDF query seems to be gaining momentum, and that I had \n   some interesting discussions w/ various folk about future of \n   RDF Interest Group.\n * set up shell of RDF Query (and Rules) Test Case Repository,\n   http://www.w3.org/2003/03/rdfqr-tests/\n * Digging myself out from todo lists that piled up in past fortnight\n\n\n\n"
        },
        {
            "subject": "Semantic Web Services: Interest Group creation discussion",
            "content": "RDF IG,\n\nForwarding (see attached) Carine's draft to the W3C Web Services public \ndiscussion list of a 'Semantic Web Interest Group' charter.  I'm copying the \nSWAD-Europe list too since we're looking into doing further work in this \narea. The original thread (useful for tracking followups) is archived\nat http://lists.w3.org/Archives/Public/www-ws/2003Mar/0028.html\nI sent my notes on this proposal last week, see \nhttp://lists.w3.org/Archives/Public/www-ws/2003Mar/0018.html\n(drop/keep CC: list in followups according to taste...)\n\nI'd be interested to hear views from RDF Interest Group members on this \nproposal. It connects also to our own need to start thinking about the \nfuture of the RDF IG over the coming years, and about priorities for future \nwork within W3C. Do people here see \"SW Services\" as the next big thing?\nAs a blue skies research area? As ripe for standardisation? If there were \nan Interest Group, or Working Group, or 'taskforce' or mailing list \ndevoted to this topic, would you be interested in participation? I'm more \ninterested to learn about people's interest levels than go into detail of\nW3C process decisions (WG vs IG vs mailing list) at this stage. In \ngeneral, is this an area that RDF / Semantic Web developers feel would benefit\nfrom some special attention and support? Do you have running code and \nburning questions? Test cases and usage scenarios to share? Services up and \nrunning already? Ideas about business models and their interaction with \ntechnology/standardisation issues?\n\nDo let us know what you think! Carine initially solicited feedback via \nwww-ws@w3.org so you could send mail there too, I'll certainly send a \npointer to that list of any discussions here.\n\ncheers, \n\nDan\n\n(RDF Interest Group chair)\n\n\nattached mail follows:\n\n\nAfter Hugo's report on the BOF during the technical plenary meeting[1]\nI made the draft charter of a \"Semantic Web Services Interest Group\"\npublicly available at:\n\nhttp://www.w3.org/2003/03/swsig-charter.html\n\nPlease review this DRAFT, express your comments & thoughts here\non the www-ws@w3.org list!\n\n(sample questions:\nIs this a good idea to create an IG? Is the scope well-defined? Would you\nprefer a WS-IG rather than a SWS-IG? Would you participate in such an\nIG? What would you expect from it?...)\n\nThanks.\n\n[1] http://lists.w3.org/Archives/Public/www-ws/2003Mar/0017.html\n\n-- \nCarine Bournez -+- W3C Sophia-Antipolis \n\n\n\n"
        },
        {
            "subject": "Re: Semantic Web Services: Interest Group creation discussion",
            "content": "Hi Dan,\n\nDan Brickley <danbri@w3.org> writes:\n\n> [...] Do people here see \"SW Services\" as the next big thing?  As a\n> blue skies research area? As ripe for standardisation? If there were\n> an Interest Group, or Working Group, or 'taskforce' or mailing list\n> devoted to this topic, would you be interested in participation?\n\nI believe that SW Services will be 'the next big thing', simply\nbecause it offers an opportunity to reconcile the two main - but\nlargely disparate - areas of Web development. I'd be interested in\nparticipating, as I suspect would several of my colleagues.\n\nAlthough much of the groundwork for SWS has been laid (in terms of\ndeployed WS and SW technologies and incipient SWS technologies such\nas DAML-S), I think that any attempt to standardise within the short\nto medium term (two years) would be rather premature. Perhaps go\nfor an interim SWAD-style effort as a bridge between blue skies and\nthe standards track?\n\nIn addition to the aforementioned DAML Services, there are other\nprojects in the SW/WS intersection, of which the Semantic Grid[1] is\na good example.\n\nFinally, it may be worth widening this tentative call for\nparticipation to the multi-agent systems community since their work\nhas some strong resonances with SWS development (as we outline in [2]).\n\n[1] http://www.semanticgrid.org/\n[2] http://eprints.aktors.org/archive/00000167/\n-- \nNick Gibbins                                            nmg@ecs.soton.ac.uk\nIAM (Intelligence, Agents, Multimedia)             tel: +44 (0) 23 80598347\nElectronics and Computer Science                   fax: +44 (0) 23 80592865\nUniversity of Southampton\n\n\n\n"
        },
        {
            "subject": "RE: Semantic Web Services: Interest Group creation discussion",
            "content": "We are actively involved in developing and deploying within a major\nconsumer packaged goods company 'semantic web services' in which we are\nusing DAML and WSDL-based services to allow businesses to communicate\ncross-enterprise.  We are very interested in a SW Services interest\ngroup and aligning with others in promoting standardization.\n\n__________________________________________________________________\nEric Hillerbrand, Ph.D., Chief Architect\ni  enLeague Systems \n@ One Coca-Cola Plaza\n       CCP Suite 208\n       Atlanta, Georgia 30313\n \n(  404.515.6953 (Work) \n(  404.676.4400 (enLeague) \n(  404.759.3031 (Cell)  \n(  404.515.0776 (Fax)  \n\n\n\n"
        },
        {
            "subject": "Re: Semantic Web Services: Interest Group creation discussion",
            "content": "In a message dated 3/13/2003 12:22:49 PM US Mountain Standard Time, \ndanbri@w3.org writes:\n\n> I'd be interested to hear views from RDF Interest Group members on this \n> proposal. It connects also to our own need to start thinking about the \n> future of the RDF IG over the coming years, and about priorities for future \n> \n> work within W3C. Do people here see \"SW Services\" as the next big thing?\n\nIMO, semantic web services are critical in areas like Web service \ndiscovery and orchestration.  Additionally, I believe web services in \ngeneral are a catalyst to other semantic web activities as they increase\norganizational awareness of open, layered metadata and the potential for \nsemantic interoperability (as opposed to syntactic interoperability).  It is \nthat \npotential that makes the next step from web services to semantic web \nservices both obvious and desirable.  \n\nSo, in essence, Semantic Web services may well be the watershed event \nto the larger vision of the semantic web.\n\n> As a blue skies research area? As ripe for standardisation? If there were \n> an Interest Group, or Working Group, or 'taskforce' or mailing list \n> devoted to this topic, would you be interested in participation?\n\nI would definitely be interested in participation.\n\nBest wishes,\n\n - Mike\n-------------------------------\nMichael C. Daconta\nChief Scientist, Advanced Programs Group\nMcDonald Bradley, Inc.\nwww.daconta.net\n\n\n\n"
        },
        {
            "subject": "SWADEurope publicity: postcard idea",
            "content": "Hi all\n\nWe would like to have some SWAD-E publicity materials ready for\nWWW2003 (late May) and if possible XMLEurope (early May).\n\nGiven the short time span, I propose something simple such as a\npostcard. We have used these effectively for publicity at the ILRT, and\nthey would  be relatively quick to produce. In addition they would point\nstraight back to the webste, where we can explain in more detail the\ncontent of the project and the Semantic web.\n\nHere's an example postcard from 234car, which came from the publicity\nfirm that we use at ILRT:\n\nhttp://www.234car.com/Bristol_postcard_v2.pdf\n\non the reverse there is a short piece of text, perhaps as long in total\nas the WAI Quick Tips\n\nhttp://www.w3.org/WAI/References/tips.gif\nhttp://www.w3.org/WAI/References/QuickTips/\n\nIf we decided to go this route we would need to think of a picture and\nsome text. The 234car picture is auto generated and shows starting\npoints for car sharing. Something along those lines would be nice I\nthink.\n\nWhat does everyone think? is it a good idea? any ideas for pictures,\ntext?\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: IBIS vocab for sembloggin",
            "content": "To resurrect an old thread...\n\nWe've started looking at ontologies for 'semantic links'. We had a look at\nIBIS, Annotea threads and Claimaker.\nOur requirement is to be able to link bibliographic blogs - primarily using\n'agreesWith', 'disagreesWith'.\n\nOur take on this was that Claimaker dealt primarily with concepts (not the\npapers themselves). IBIS appears to me to take a similar line, making useful\nsimplifications to the Claimaker model. These approaches are both good for\n'argumentation networks'.\n\nFor dealing with the items themselves (which is what we want to do), Annotea\nthreads offer quite a useful schema. Not a perfect fit to our domain, since\nwe are not dealing with threaded discussions, and we might want to extend\nthe schema to different semantic relationships. But certainly good enough to\nstart with. So we are looking to make threads a pluggable version of our\nsemantic ontology. \n\nThe reason for this rambling mail is to ask whether Danny, Charles or anyone\nelse on the list is aware of, or would recommend, any other ontologies for\nencoding such semantic links.\n\nCheers\n\nSteve\n\n-----Original Message-----\nFrom: Charles McCathieNevile [mailto:charles@w3.org]\nSent: 18 January 2003 21:45\nTo: Danny Ayers\nCc: Esw\nSubject: Re: IBIS vocab for semblogging\n\n\n\nHi Danny,\n\nthe vocabulary stuff you are looking at sounds like it is extending\nthe thread vocabulary produced for Annotea (or for that matter the original\nAnnotea vocabulary of annotation types) to allow for discussion threads\nto be tracked. This seems to me like a good idea.\n\nhttp://www.w3.org/2001/03/thread\n\nThe ability to provide user-friendly interfaces for this (such as the\nicon-selection that Amaya has for marking different types of annotation -\nsee\nthe help file at\nhttp://www.w3.org/Amaya/User/attaching_annotations/configuring_icons) is a\npromising paralell for the use of graphic RDF editors (IdeaGraph, IsaViz,\nRDFAuthor, etc)\n\ncheers\n\nChaals\n\nOn Fri, 17 Jan 2003, Danny Ayers wrote:\n\n>\n>I didn't realise Semantic Blogging was being followed up as an e-sw case\n>study, until I found the link on the new blog...\n>\n>Anyhow, one of the apps I've been working on for my Ideagraph project is\n>semantic blogging and to help with this I've started writing up a\nvocabulary\n>(RDFS) for 'Issue-Based Information Systems', the idea being to use terms\n>like 'Argument', 'Question', 'pro', 'con' within blog (and other)\ndiscussion\n>threads.\n>\n>http://purl.org/ibis\n>\n>Very much a work in progress, suggestions welcome.\n>\n>Cheers,\n>Danny.\n>\n>-----------\n>\n>http://dannyayers.com\n>\n>\"The lyf so short, the craft so long to lerne.\" - Chaucer\n>\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134\n136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78\n22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: IBIS vocab for sembloggin",
            "content": "Hi Steve,\n\n> Our take on this was that Claimaker dealt primarily with concepts (not the\n> papers themselves).\n\nI'm not sure, if the subject of a statement is (the URI of) a paper, then\npresumably that's what's been talked about.\n\nAnyhow, the closest thing I'm aware of to what you describe is David\nMenendez's Thread Description Language [1] :\n\n[1] http://www.eyrie.org/~zednenem/2002/web-threads/\n\nMy main criticism of this would be that it tries too hard to do everything\nitself, rather than reusing terms from other schema (like Annotea and\nprobably DC). But it does include agreesWith etc.\n\nNote that my IBIS vocab isn't set in stone, and suggestions are still\nwelcome ;-)\n\nCheers,\nDanny.\n\n> -----Original Message-----\n> From: Cayzer, Steve [mailto:Steve_Cayzer@hplb.hpl.hp.com]\n> Sent: 27 March 2003 16:28\n> To: 'Charles McCathieNevile'; Danny Ayers\n> Cc: Esw\n> Subject: RE: IBIS vocab for semblogging\n>\n>\n> To resurrect an old thread...\n>\n> We've started looking at ontologies for 'semantic links'. We had a look at\n> IBIS, Annotea threads and Claimaker.\n> Our requirement is to be able to link bibliographic blogs -\n> primarily using\n> 'agreesWith', 'disagreesWith'.\n>\n> Our take on this was that Claimaker dealt primarily with concepts (not the\n> papers themselves). IBIS appears to me to take a similar line,\n> making useful\n> simplifications to the Claimaker model. These approaches are both good for\n> 'argumentation networks'.\n>\n> For dealing with the items themselves (which is what we want to\n> do), Annotea\n> threads offer quite a useful schema. Not a perfect fit to our\n> domain, since\n> we are not dealing with threaded discussions, and we might want to extend\n> the schema to different semantic relationships. But certainly\n> good enough to\n> start with. So we are looking to make threads a pluggable version of our\n> semantic ontology.\n>\n> The reason for this rambling mail is to ask whether Danny,\n> Charles or anyone\n> else on the list is aware of, or would recommend, any other ontologies for\n> encoding such semantic links.\n>\n> Cheers\n>\n> Steve\n>\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org]\n> Sent: 18 January 2003 21:45\n> To: Danny Ayers\n> Cc: Esw\n> Subject: Re: IBIS vocab for semblogging\n>\n>\n>\n> Hi Danny,\n>\n> the vocabulary stuff you are looking at sounds like it is extending\n> the thread vocabulary produced for Annotea (or for that matter\n> the original\n> Annotea vocabulary of annotation types) to allow for discussion threads\n> to be tracked. This seems to me like a good idea.\n>\n> http://www.w3.org/2001/03/thread\n>\n> The ability to provide user-friendly interfaces for this (such as the\n> icon-selection that Amaya has for marking different types of annotation -\n> see\n> the help file at\n> http://www.w3.org/Amaya/User/attaching_annotations/configuring_icons) is a\n> promising paralell for the use of graphic RDF editors (IdeaGraph, IsaViz,\n> RDFAuthor, etc)\n>\n> cheers\n>\n> Chaals\n>\n> On Fri, 17 Jan 2003, Danny Ayers wrote:\n>\n> >\n> >I didn't realise Semantic Blogging was being followed up as an e-sw case\n> >study, until I found the link on the new blog...\n> >\n> >Anyhow, one of the apps I've been working on for my Ideagraph project is\n> >semantic blogging and to help with this I've started writing up a\n> vocabulary\n> >(RDFS) for 'Issue-Based Information Systems', the idea being to use terms\n> >like 'Argument', 'Question', 'pro', 'con' within blog (and other)\n> discussion\n> >threads.\n> >\n> >http://purl.org/ibis\n> >\n> >Very much a work in progress, suggestions welcome.\n> >\n> >Cheers,\n> >Danny.\n> >\n> >-----------\n> >\n> >http://dannyayers.com\n> >\n> >\"The lyf so short, the craft so long to lerne.\" - Chaucer\n> >\n> >\n> >\n>\n> --\n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134\n> 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33\n> 4 92 38 78\n> 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: opening hours RDF cal use cas",
            "content": "(copying swad-europe list)\n\n[snip]\n\nJust a brief note to let folks know that I've made an attempt \nat writing up this use case in the ESW Wiki,\nhttp://esw.w3.org/topic/OpeningHoursUseCase\n\nFor now I've stuck with the example from this email thread,\nbut my intention is to extend/augment it with real data \ndescribing real local businesses (from Bristol initially),\nand include photographs, contact details, geographic markup etc.\n\nIf folks have additional examples, do feel free to edit the Wiki\nentry(*).\n\nThe page currently has two examples, the first is the \nun-edited raw ical for the repeating event, the other attempts \nto mix in additional data. I have taken (for now) the approach of\ninventing a new property (foaf:openingHours) that relates a\nresource (some kind of unmodelled business entity) to a \nspecification of its opening hours. Not sure if this works well, \nyet. It would be nice to have some bulk data to play with... does \nanybody here have suggestions on that front? SKICal folks maybe?\n\nThanks for any suggestions, additions...\n\nDan\n\n\n\n(*) \"This is a WikiWikiWeb, a collaborative hypertext \nenvironment, with an emphasis on easy access to \nand modification of information. It is something \nof an experiment in WikiConsensus.\"\n\"You can edit any page by following the link at the bottom \nof the page. Capitalized words joined together form a \nWikiName, which hyperlinks to another page\"\n -- http://esw.w3.org/topic/FrontPage\n\nThere are also (pre last RDF Calendar IRC chat) some notes\non the RDF Calendar effort at:\nhttp://esw.w3.org/topic/RdfCalendar \n\n\n\n"
        },
        {
            "subject": "Re: opening hours RDF cal use cas",
            "content": "As another similar use case, I am avialable by telehpone during certain\nhours, and in person (at a given location) during a different set of hours.\n\nfoaf:openingHours seems to subclass an idea of being \"available\" in a way\nthat is particularly relevant for something carried on at a phyiscal\nlocation. A person doesn't have \"opening hours\" as such, but is responsive in\ndifferent ways (face-to-face, phone, email, etc...) at different times (and\narguably for different people - presumably we will figure that out by having\nthe ability to restrict information according to trust rules).\n\nTo develop the use case further, there are a couple of questions I have. If I\nam arriving in Boston/Bristol and staying for half a day, using travel\ninformation according to Dan Connolly's work, will I be able to get to this\nshop?\n\nThis implies the granularity question you allude to in both time and space -\nwhich seems to be the sort of thing that aboutEachPrefix was meant to help us\ndeal with.\n\nAnd how do the two areas of work (travel times with arrival and departure\nand shop opening hours) interoperate - have we built a system which allows\nfor easy merging of these data?\n\n(And what have we learned along the way in terms of how to design RDF\nvocabularies and how to model the universe...?)\n\ncheers\n\nChaals\n\nOn Fri, 28 Mar 2003, Dan Brickley wrote:\n\n>\n>(copying swad-europe list)\n>\n>[snip]\n>\n>Just a brief note to let folks know that I've made an attempt\n>at writing up this use case in the ESW Wiki,\n>http://esw.w3.org/topic/OpeningHoursUseCase\n>\n>For now I've stuck with the example from this email thread,\n>but my intention is to extend/augment it with real data\n>describing real local businesses (from Bristol initially),\n>and include photographs, contact details, geographic markup etc.\n>\n>If folks have additional examples, do feel free to edit the Wiki\n>entry(*).\n>\n>The page currently has two examples, the first is the\n>un-edited raw ical for the repeating event, the other attempts\n>to mix in additional data. I have taken (for now) the approach of\n>inventing a new property (foaf:openingHours) that relates a\n>resource (some kind of unmodelled business entity) to a\n>specification of its opening hours. Not sure if this works well,\n>yet. It would be nice to have some bulk data to play with... does\n>anybody here have suggestions on that front? SKICal folks maybe?\n>\n>Thanks for any suggestions, additions...\n>\n>Dan\n>\n>\n>\n>(*) \"This is a WikiWikiWeb, a collaborative hypertext\n>environment, with an emphasis on easy access to\n>and modification of information. It is something\n>of an experiment in WikiConsensus.\"\n>\"You can edit any page by following the link at the bottom\n>of the page. Capitalized words joined together form a\n>WikiName, which hyperlinks to another page\"\n> -- http://esw.w3.org/topic/FrontPage\n>\n>There are also (pre last RDF Calendar IRC chat) some notes\n>on the RDF Calendar effort at:\n>http://esw.w3.org/topic/RdfCalendar\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: Semantic Web Services: Interest Group creation discussion",
            "content": "Hi,\n\nI was wondering if there had been any developments on this as the DotGNU\nproject appears to be navigating directly into these waters. From the latest\npost on their list:\n\n[[[\n> I suppose DGEE [DotGNU Execution Environment] makes use of service\ndiscovery?\n\nIt will do.  Right now it's just the execution container - ie the place\nwhere\nwebservices are actually found - with discovery ability coming as and when\nready (ie when there is something to discover :o)\n\n> Does it use RDF?\n\nInternally no.  Externally, almost.\nThe DGEE will export information about its webservices in XML, RDF and other\nformats - I just need an RDF fragment suitable for representing DGEE\nwebservice info and we're off!\n]]]\n\nhttp://dotgnu.org/pipermail/developers/2003-March/010331.html\n\n(btw, I've suggested DAML-S as a possibility - anything else?)\n\nCheers,\nDanny.\n\n\n\n"
        },
        {
            "subject": "SWADE postcard tex",
            "content": "hi all,\n\nNow we need a piece of text to go on the back of the card.\nBasically all it will do is have a two paragraph summary of the project\nand then point them to the site.\n\nso...what do we want to get people to do with respect to the site?\n\n- join in\nirc/w3c mailing lists/workshops/suggestions and questions\npublic-esw/wiki\n\n- find stuff out\nreports, demos, developer page\n\n??more??\n\nWe could also have a slogan of some kind on the front of the\ncard....what do you think? any suggestions?\n\nI rather like this para (from\nhttp://www.w3.org/2001/sw/Europe/factsheet/) as an explanation of what\nwe're doing in the project:\n\n[[\nThe period 2002-2004 will see the first wave of mainstream Semantic Web\napplications. SWAD-Europe's role will be to ensure that the critical\ntechnology components required for widespread Semantic Web adoption are\nreadily accessible to European industry, consumers, and developers. This\ninvolves finding and maintaining a balance between \"in-house\" Open\nSource tool development, community building, outreach and evangelism,\ncombined with more technologically advanced research and analysis to\nsupport and field-test Semantic Web standards.\n]]\n\nany other ideas?\n\nThanks for any input,\n\n\nLibby\n\n\n\n"
        },
        {
            "subject": "SWADE postcard tex",
            "content": "hi all,\n\nNow we need a piece of text to go on the back of the card.\nBasically all it will do is have a two paragraph summary of the project\nand then point them to the site.\n\nso...what do we want to get people to do with respect to the site?\n\n- join in\nirc/w3c mailing lists/workshops/suggestions and questions\npublic-esw/wiki\n\n- find stuff out\nreports, demos, developer page\n\n??more??\n\nWe could also have a slogan of some kind on the front of the\ncard....what do you think? any suggestions?\n\nI rather like this para (from\nhttp://www.w3.org/2001/sw/Europe/factsheet/) as an explanation of what\nwe're doing in the project:\n\n[[\nThe period 2002-2004 will see the first wave of mainstream Semantic Web\napplications. SWAD-Europe's role will be to ensure that the critical\ntechnology components required for widespread Semantic Web adoption are\nreadily accessible to European industry, consumers, and developers. This\ninvolves finding and maintaining a balance between \"in-house\" Open\nSource tool development, community building, outreach and evangelism,\ncombined with more technologically advanced research and analysis to\nsupport and field-test Semantic Web standards.\n]]\n\nany other ideas?\n\nThanks for any input,\n\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: SWADE postcard tex",
            "content": "Hi Libby,\n\n> so...what do we want to get people to do with respect to the site?\n> \n> - join in\n> irc/w3c mailing lists/workshops/suggestions and questions\n> public-esw/wiki\n> \n> - find stuff out\n> reports, demos, developer page\n\nBoth of those. As well as pointing people to the web site (find stuff out) we\nshould encourage then to join us on public-esw to ask questions, let us know of\nrelevant other work going on etc. (I have a preference for emphasising the mail\nlist since I'm irc-challenged!).\n\n> We could also have a slogan of some kind on the front of the\n> card....what do you think? any suggestions?\n\nSorry, I'm terrible with slogans. Sentiments along the lines of \"making the\nsemantic real\" or \"building a practical semantic web 1.0\" might be suitable but\nI haven't got a good form of words.\n\n> I rather like this para (from\n> http://www.w3.org/2001/sw/Europe/factsheet/) as an explanation of what\n> we're doing in the project:\n> \n> [[\n> The period 2002-2004 will see the first wave of mainstream Semantic Web\n> applications. SWAD-Europe's role will be to ensure that the critical\n> technology components required for widespread Semantic Web adoption are\n> readily accessible to European industry, consumers, and developers. This\n> involves finding and maintaining a balance between \"in-house\" Open\n> Source tool development, community building, outreach and evangelism,\n> combined with more technologically advanced research and analysis to\n> support and field-test Semantic Web standards.\n> ]]\n\nAgreed. That's a good paragraph. If there is space it would good to have a few\nmore specifics points mentioned as appetizers to encourge people to follow up\n(by mail or web). For example, mention a few of the specific technology issues\nor investigations or applications.\n\nDoesn't need to be comprehensive just a few bullet highlights.\n\nFor example:\n\n\"Examples of the activities we are involved in include:\n  - bridging the gap between semantic web technology and the XML tool stack\n  - reviewing and developing tools for accessing, storing and search semantic\nweb data\n  - developing case studies and demonstration applications in areas ranging from\nthesaurus management to semantic blogging\n  - a series of developer workshops on topics ranging from image annotation to\ncalendaring.\n\nFor more details on the full range of our activities visit\nhttp://www.w3.org/2001/sw/Europe/ or join us on the public-esw@w3.org mail\nlist.\"\n\nDave\n\n\n\n"
        },
        {
            "subject": "Re: SWADE postcard tex",
            "content": "thanks Dave, that's all excellent :)\n\nI appreciate your help,\n\nLibby\n\nOn Thu, 1 May 2003, Dave Reynolds wrote:\n\n> Hi Libby,\n>\n> > so...what do we want to get people to do with respect to the site?\n> >\n> > - join in\n> > irc/w3c mailing lists/workshops/suggestions and questions\n> > public-esw/wiki\n> >\n> > - find stuff out\n> > reports, demos, developer page\n>\n> Both of those. As well as pointing people to the web site (find stuff out) we\n> should encourage then to join us on public-esw to ask questions, let us know of\n> relevant other work going on etc. (I have a preference for emphasising the mail\n> list since I'm irc-challenged!).\n>\n> > We could also have a slogan of some kind on the front of the\n> > card....what do you think? any suggestions?\n>\n> Sorry, I'm terrible with slogans. Sentiments along the lines of \"making the\n> semantic real\" or \"building a practical semantic web 1.0\" might be suitable but\n> I haven't got a good form of words.\n>\n> > I rather like this para (from\n> > http://www.w3.org/2001/sw/Europe/factsheet/) as an explanation of what\n> > we're doing in the project:\n> >\n> > [[\n> > The period 2002-2004 will see the first wave of mainstream Semantic Web\n> > applications. SWAD-Europe's role will be to ensure that the critical\n> > technology components required for widespread Semantic Web adoption are\n> > readily accessible to European industry, consumers, and developers. This\n> > involves finding and maintaining a balance between \"in-house\" Open\n> > Source tool development, community building, outreach and evangelism,\n> > combined with more technologically advanced research and analysis to\n> > support and field-test Semantic Web standards.\n> > ]]\n>\n> Agreed. That's a good paragraph. If there is space it would good to have a few\n> more specifics points mentioned as appetizers to encourge people to follow up\n> (by mail or web). For example, mention a few of the specific technology issues\n> or investigations or applications.\n>\n> Doesn't need to be comprehensive just a few bullet highlights.\n>\n> For example:\n>\n> \"Examples of the activities we are involved in include:\n>   - bridging the gap between semantic web technology and the XML tool stack\n>   - reviewing and developing tools for accessing, storing and search semantic\n> web data\n>   - developing case studies and demonstration applications in areas ranging from\n> thesaurus management to semantic blogging\n>   - a series of developer workshops on topics ranging from image annotation to\n> calendaring.\n>\n> For more details on the full range of our activities visit\n> http://www.w3.org/2001/sw/Europe/ or join us on the public-esw@w3.org mail\n> list.\"\n>\n> Dave\n>\n>\n\n\n\n"
        },
        {
            "subject": "Tracking semantic web uptak",
            "content": "Is anyone aware of any groups tracking commercial take up of semantic web\ntechnology?\n\nSome of the applications we included in our applications survey report were\ncommercial but I sure there are lots more that weren't covered in that.\n\nIn particular, I was intrigued to notice this quote in an Interweek article on\nthe Semantic Web:\n\n   \"But W3C spokeswoman Janet Daly said RDF technologies are in use today \n    by AOL Time Warner Inc., Hearst Corp. and LexisNexis. \"\n\nAnyone know what any of these people are using RDF for?\n\nDave\n-- \nHewlett-Packard Laboratories    | Phone: +44-117-3128165\nFilton Road, Stoke Gifford      | FAX:   +44-117-3128925\nBristol BS34 8QZ, UK            | dave.reynolds@hpl.hp.com\n\n\n\n"
        },
        {
            "subject": "Re: Tracking semantic web uptak",
            "content": "AOL Time Warner Inc. has, I believe, Some RDF capacity in its browser,\n\"Netscape\". (You've probably heard of it :) I don't know anything more useful\nthan that, but since the three groups do things like dealig with documents\nwhich can be in multiple forms that might be their real use...\n\ncheers\n\nChaals\n\nOn Thu, 1 May 2003, Dave Reynolds wrote:\n\n>\n>Is anyone aware of any groups tracking commercial take up of semantic web\n>technology?\n>\n>Some of the applications we included in our applications survey report were\n>commercial but I sure there are lots more that weren't covered in that.\n>\n>In particular, I was intrigued to notice this quote in an Interweek article on\n>the Semantic Web:\n>\n>   \"But W3C spokeswoman Janet Daly said RDF technologies are in use today\n>    by AOL Time Warner Inc., Hearst Corp. and LexisNexis. \"\n>\n>Anyone know what any of these people are using RDF for?\n>\n>Dave\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-E postcard text  slogan",
            "content": "Libby\n\nI once gave a talk entitled \"In Search of the Semantic Spider\"\nbut this is too obscure ...\n\nthere are various things like \n\nweaving the semantic web (apologies to TBL)\nspinning the semantic web (although this has a secondary meaning we may not\nintend)\nuntangling the semantic web \nbuilding the web of meaning\n\nhm...\n\n--sb\n\n-----Original Message-----\nFrom: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\nSent: Thursday, May 01, 2003 4:42 PM\nTo: Dave Reynolds\nCc: Libby Miller; public-esw\nSubject: Re: SWAD-E postcard text\n\n\n\n\nthanks Dave, that's all excellent :)\n\nI appreciate your help,\n\nLibby\n\nOn Thu, 1 May 2003, Dave Reynolds wrote:\n\n> Hi Libby,\n>\n> > so...what do we want to get people to do with respect to the site?\n> >\n> > - join in\n> > irc/w3c mailing lists/workshops/suggestions and questions\n> > public-esw/wiki\n> >\n> > - find stuff out\n> > reports, demos, developer page\n>\n> Both of those. As well as pointing people to the web site (find stuff out)\nwe\n> should encourage then to join us on public-esw to ask questions, let us\nknow of\n> relevant other work going on etc. (I have a preference for emphasising the\nmail\n> list since I'm irc-challenged!).\n>\n> > We could also have a slogan of some kind on the front of the\n> > card....what do you think? any suggestions?\n>\n> Sorry, I'm terrible with slogans. Sentiments along the lines of \"making\nthe\n> semantic real\" or \"building a practical semantic web 1.0\" might be\nsuitable but\n> I haven't got a good form of words.\n>\n> > I rather like this para (from\n> > http://www.w3.org/2001/sw/Europe/factsheet/) as an explanation of what\n> > we're doing in the project:\n> >\n> > [[\n> > The period 2002-2004 will see the first wave of mainstream Semantic Web\n> > applications. SWAD-Europe's role will be to ensure that the critical\n> > technology components required for widespread Semantic Web adoption are\n> > readily accessible to European industry, consumers, and developers. This\n> > involves finding and maintaining a balance between \"in-house\" Open\n> > Source tool development, community building, outreach and evangelism,\n> > combined with more technologically advanced research and analysis to\n> > support and field-test Semantic Web standards.\n> > ]]\n>\n> Agreed. That's a good paragraph. If there is space it would good to have a\nfew\n> more specifics points mentioned as appetizers to encourge people to follow\nup\n> (by mail or web). For example, mention a few of the specific technology\nissues\n> or investigations or applications.\n>\n> Doesn't need to be comprehensive just a few bullet highlights.\n>\n> For example:\n>\n> \"Examples of the activities we are involved in include:\n>   - bridging the gap between semantic web technology and the XML tool\nstack\n>   - reviewing and developing tools for accessing, storing and search\nsemantic\n> web data\n>   - developing case studies and demonstration applications in areas\nranging from\n> thesaurus management to semantic blogging\n>   - a series of developer workshops on topics ranging from image\nannotation to\n> calendaring.\n>\n> For more details on the full range of our activities visit\n> http://www.w3.org/2001/sw/Europe/ or join us on the public-esw@w3.org mail\n> list.\"\n>\n> Dave\n>\n>\n\n\n\n"
        },
        {
            "subject": "proposed SWAD-E postcard text  comments",
            "content": "hi all\n\nI'm struggling a bit with the text for the SWAD-E postcard\n\nWe need to explain the map on the front of the card a bit...\nHere's what I've come up with so far with everyone's help (thanks\nDan, Dave, Stephen :)\n\n[[\nBuilding a practical Semantic Web 1.0 (maybe on the front?)\n\n* how can I get involved in the Semantic Web?\n* which standards should I use?\n* where are other Semantic Web developers located?\n\nSWAD-Europe is an EC funded project aiming to ensure that the critical\ntechnology components required for widespread Semantic Web adoption are\nreadily accessible to European industry, consumers, and developers.\n\nSWAD-Europe uses Open Source tool development, community building,\noutreach and evangelism, and advanced research and analysis to\nsupport and field-test Semantic Web standards.\n\nOur current activities include\n  - bridging the gap between semantic web technology and the XML tool stack\n  - reviewing and developing tools for accessing, storing and search semantic\nweb data\n  - developing case studies and demonstration applications in areas ranging from\nthesaurus management to semantic blogging\n  - holding developer workshops on topics ranging from image annotation\nto calendaring.\n\nFor more details on the full range of our activities visit\nhttp://www.w3.org/2001/sw/Europe/ or join us on the public-esw@w3.org mail\nlist, the ESW Wiki, or on IRC (irc.freenode.net #rdfig)\n]]\n\n\nany comments? suggestions?\n\nthanks\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-E postcard text  slogan",
            "content": "On Fri, 2 May 2003, Stephen Buswell wrote:\n\n>weaving the semantic web (apologies to TBL)\n\nThink this is too close to timBLs book (we want our own place in the\nremainder shelves :)\n\n>spinning the semantic web (although this has a secondary meaning we may not\n>intend)\n\nor maybe we do.\n\n>untangling the semantic web\n>building the web of meaning\n\nI like this. I think concentrating on the fact that the project is about\ndoing some concrete stuff is important.\n\nBuilding a meaningful web ?\n\nChaals\n\n>hm...\n>\n>--sb\n>\n>-----Original Message-----\n>From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk]\n>Sent: Thursday, May 01, 2003 4:42 PM\n>To: Dave Reynolds\n>Cc: Libby Miller; public-esw\n>Subject: Re: SWAD-E postcard text\n>\n>\n>\n>\n>thanks Dave, that's all excellent :)\n>\n>I appreciate your help,\n>\n>Libby\n>\n>On Thu, 1 May 2003, Dave Reynolds wrote:\n>\n>> Hi Libby,\n>>\n>> > so...what do we want to get people to do with respect to the site?\n>> >\n>> > - join in\n>> > irc/w3c mailing lists/workshops/suggestions and questions\n>> > public-esw/wiki\n>> >\n>> > - find stuff out\n>> > reports, demos, developer page\n>>\n>> Both of those. As well as pointing people to the web site (find stuff out)\n>we\n>> should encourage then to join us on public-esw to ask questions, let us\n>know of\n>> relevant other work going on etc. (I have a preference for emphasising the\n>mail\n>> list since I'm irc-challenged!).\n>>\n>> > We could also have a slogan of some kind on the front of the\n>> > card....what do you think? any suggestions?\n>>\n>> Sorry, I'm terrible with slogans. Sentiments along the lines of \"making\n>the\n>> semantic real\" or \"building a practical semantic web 1.0\" might be\n>suitable but\n>> I haven't got a good form of words.\n>>\n>> > I rather like this para (from\n>> > http://www.w3.org/2001/sw/Europe/factsheet/) as an explanation of what\n>> > we're doing in the project:\n>> >\n>> > [[\n>> > The period 2002-2004 will see the first wave of mainstream Semantic Web\n>> > applications. SWAD-Europe's role will be to ensure that the critical\n>> > technology components required for widespread Semantic Web adoption are\n>> > readily accessible to European industry, consumers, and developers. This\n>> > involves finding and maintaining a balance between \"in-house\" Open\n>> > Source tool development, community building, outreach and evangelism,\n>> > combined with more technologically advanced research and analysis to\n>> > support and field-test Semantic Web standards.\n>> > ]]\n>>\n>> Agreed. That's a good paragraph. If there is space it would good to have a\n>few\n>> more specifics points mentioned as appetizers to encourge people to follow\n>up\n>> (by mail or web). For example, mention a few of the specific technology\n>issues\n>> or investigations or applications.\n>>\n>> Doesn't need to be comprehensive just a few bullet highlights.\n>>\n>> For example:\n>>\n>> \"Examples of the activities we are involved in include:\n>>   - bridging the gap between semantic web technology and the XML tool\n>stack\n>>   - reviewing and developing tools for accessing, storing and search\n>semantic\n>> web data\n>>   - developing case studies and demonstration applications in areas\n>ranging from\n>> thesaurus management to semantic blogging\n>>   - a series of developer workshops on topics ranging from image\n>annotation to\n>> calendaring.\n>>\n>> For more details on the full range of our activities visit\n>> http://www.w3.org/2001/sw/Europe/ or join us on the public-esw@w3.org mail\n>> list.\"\n>>\n>> Dave\n>>\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Tracking semantic web uptak",
            "content": "* Charles McCathieNevile <charles@w3.org> [2003-05-02 06:10-0400]\n> \n> AOL Time Warner Inc. has, I believe, Some RDF capacity in its browser,\n> \"Netscape\". (You've probably heard of it :) I don't know anything more useful\n> than that, but since the three groups do things like dealig with documents\n> which can be in multiple forms that might be their real use...\n\nYep, the only one I know anything about is the Mozilla/Netscape RDF \nimplementation, which was the first RDF implementation out there and \nis probably the one on most desktops, even if folk don't realise it.\n\nI don't know about the others. I'll ask...\n\nDan\n> \n> cheers\n> \n> Chaals\n> \n> On Thu, 1 May 2003, Dave Reynolds wrote:\n> \n> >\n> >Is anyone aware of any groups tracking commercial take up of semantic web\n> >technology?\n> >\n> >Some of the applications we included in our applications survey report were\n> >commercial but I sure there are lots more that weren't covered in that.\n> >\n> >In particular, I was intrigued to notice this quote in an Interweek article on\n> >the Semantic Web:\n> >\n> >   \"But W3C spokeswoman Janet Daly said RDF technologies are in use today\n> >    by AOL Time Warner Inc., Hearst Corp. and LexisNexis. \"\n> >\n> >Anyone know what any of these people are using RDF for?\n> >\n> >Dave\n> >\n> \n> -- \n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-E postcard text  slogan",
            "content": "I too liked Stephen's \"building the web of meaning\" as a starting point. I\nalso played around on qotd.org (always a good displacement activity). Some\nhighlights:\n\nThe least of things with a meaning is worth more in life than the greatest\nof things without it. - Carl Gustav Jung \n\nThe belief that words have a meaning of their own account is a relic of\nprimitive word magic, and it is still a part of the air we breathe in nearly\nevery discussion. - Charles K. Ogden [-ijd probably a bit long, but an\ninteresting point :-)]\n\nOnce you've gotten the meaning, you can forget the words. - Chuang Tzu\n(c.B.C. 369-c.286) [-ijd I suspect that Chang Tzu said it better than that -\nanyone have a better translation?]\n\nIn the world of human thought generally, and in physical science\nparticularly, the most important and fruitful concepts are those to which it\nis impossible to attach a well-defined meaning. - H. A. Kramers [-ijd oh\nbug**r!]\n\nInformation is just signs and numbers, while knowledge involves their\nmeaning. What we want is knowledge, but what we get is information. - Heinz\nR. Pagels\n\nAfter people have repeated a phrase a great number of times, they begin to\nrealize it has meaning and may even be true. - Herbert George Wells \n\nAs an adolescent I aspired to lasting fame, I craved factual certainty, and\nI thirsted for a meaningful vision of human life - so I became a scientist.\nThis is like becoming an archbishop so you can meet girls. - Matt Cartmill\n[-ijd Not relevant to SWAD-e, but I liked it anyway :-)]\n\nThe reserve of modern assertions is sometimes pushed to extremes, in which\nthe fear of being contradicted leads the writer to strip himself of almost\nall sense and meaning. - Winston Churchill \n\nWe are getting into semantics again. If we use words, there is a very grave\ndanger they will be misinterpreted. - H. R. Haldeman \n\n\nNothing interesting showed up for web, and nothing at all for RDF (no\nsurprise - a gap in the market there :-).\n\nCheers,\nIan\n\n> -----Original Message-----\n> From: Stephen Buswell [mailto:StephenB@stilo.com] \n> Sent: 02 May 2003 15:38\n> To: 'Libby Miller'; Dave Reynolds\n> Cc: public-esw\n> Subject: RE: SWAD-E postcard text - slogans\n> \n> \n> \n> Libby\n> \n> I once gave a talk entitled \"In Search of the Semantic \n> Spider\" but this is too obscure ...\n> \n> there are various things like \n> \n> weaving the semantic web (apologies to TBL)\n> spinning the semantic web (although this has a secondary \n> meaning we may not\n> intend)\n> untangling the semantic web \n> building the web of meaning\n> \n> hm...\n> \n> --sb\n\n\n\n"
        },
        {
            "subject": "SWADE postcard mocku",
            "content": "http://sw1.ilrt.org/discovery/2003/04/svggeo/postcard/postcard-txt-2003-05-05.html\n\nIt's a bit grainy - the actual thing won't look like that.\n\ncould I have comments by tomorrow please? We need to get this done and\ndusted asap or we won't have the cards ready for WWW2003.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: SWADE postcard mocku",
            "content": "This looks pretty cool to me.\n\nI would say\n\n\"Which standards should I use\"\nand \"Where can I *find? meet?* other Semantic Web developers\"\n\nbut these are trivial and ignorable quibbles.\n\ngood job!\n\nchaals\n\nOn Mon, 5 May 2003, Libby Miller wrote:\n\n>\n>\n>http://sw1.ilrt.org/discovery/2003/04/svggeo/postcard/postcard-txt-2003-05-05.html\n>\n>It's a bit grainy - the actual thing won't look like that.\n>\n>could I have comments by tomorrow please? We need to get this done and\n>dusted asap or we won't have the cards ready for WWW2003.\n>\n>cheers\n>\n>Libby\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: Tracking semantic web uptak",
            "content": "On Thu, 2003-05-01 at 12:41, Dave Reynolds wrote:\n> \n> Is anyone aware of any groups tracking commercial take up of semantic web\n> technology?\n> \n> Some of the applications we included in our applications survey report were\n> commercial but I sure there are lots more that weren't covered in that.\n> \n> In particular, I was intrigued to notice this quote in an Interweek article on\n> the Semantic Web:\n> \n>    \"But W3C spokeswoman Janet Daly said RDF technologies are in use today \n>     by AOL Time Warner Inc., Hearst Corp. and LexisNexis. \"\n> \n> Anyone know what any of these people are using RDF for?\n\nWith respect to you specific question, these companies are using PRISM\n[1][2] to facilitate the exchange of  publishers content.\n\n[1] http://www.w3.org/TR/rdf-primer/#prism\n[2] http://www.prismstandard.org/\n\nWith respect to your more general question on tracking commercial uptake\nof semantic web technolgies, I am (as best as possible). However some\nRDF based tools for facilitating this 'cataloging' process and allowing\nfor this to be more of a collaborative effort would be extremely helpful\n(wink wink nudge nudge :).\n\n-- \neric miller                              http://www.w3.org/people/em/\nsemantic web activity lead               http://www.w3.org/2001/sw/\nw3c world wide web consortium            http://www.w3.org/\n\n\n\n"
        },
        {
            "subject": "RE: SWADE postcard mocku",
            "content": "Libby -\nLooks pretty good.  Some assorted minor quibblage:\n\n* (probably) most people in the EC will know what \"EC\" stands for, but\nothers quite likely won't\n\n* \"Where are other SW developers located?\" - might want an \"in Europe\" in\nthere somewhere, to acknowledge that there are Other Places in the world (qv\nthe map discussion)  \n\n* is open source really Open Source? :-).  Similarly, you use both Semantic\nWeb and semantic web - would be better to be consistent.  I don't have a\nstrong preference.\n\n* \"bridging the gap between semantic web technology and the XML tool stack \"\nmy suggestion: \"bridging the gaps between semantic web tools and XML tools\"\nor even \"applying standard XML tools to semantic web problems\"\n\n* \"... storing and search semantic web data\" -> s/search/searching/\n\n* \"case studies and demonstration applications\" -> add comma after\napplications\n\n* \"holding developer workshops \" -> delete 'holding' ... a workshop is an\nactivity, I assert :-)\n\n* I'd reorder the second major sentence to emphasise the outcome rather than\nthe process, something like:\n\nOur goal is to refine and field-test Semantic Web standards, through open\nsource tool development, community building, outreach and evangelism, and\nadvanced R&D.\n\nHope this is not too late.\n\nCheers,\nIan\n\n\n> -----Original Message-----\n> From: Libby Miller [mailto:Libby.Miller@bristol.ac.uk] \n> Sent: 05 May 2003 15:52\n> To: public-esw@w3.org; em\n> Subject: SWAD-E postcard mockup\n> \n> \n> \n> \n> http://sw1.ilrt.org/discovery/2003/04/svggeo/postcard/postcard\n> -txt-2003-05-05.html\n> \n> It's a bit grainy - the actual thing won't look like that.\n> \n> could I have comments by tomorrow please? We need to get this \n> done and dusted asap or we won't have the cards ready for WWW2003.\n> \n> cheers\n> \n> Libby\n> \n\n\n\n"
        },
        {
            "subject": "Re: Tracking semantic web uptak",
            "content": "Eric Miller wrote:\n> \n> With respect to you specific question, these companies are using PRISM\n> [1][2] to facilitate the exchange of  publishers content.\n> \n> [1] http://www.w3.org/TR/rdf-primer/#prism\n> [2] http://www.prismstandard.org/\n\nThanks Eric - I should have read the Primer more closely!\n\n> With respect to your more general question on tracking commercial uptake\n> of semantic web technolgies, I am (as best as possible). \n\nExcellent.\n\n> However some\n> RDF based tools for facilitating this 'cataloging' process and allowing\n> for this to be more of a collaborative effort would be extremely helpful\n> (wink wink nudge nudge :).\n\nIts possible the RDF schema and formatting tools we used for our SWAD-E report\n[*] could be useful. It'd take a bit of work to make them user friendly though.\nWhen (if!) my current work crisis abates it'd be fun to think about this.\n\nDave\n\n[*]\nhttp://www.w3.org/2001/sw/Europe/reports/chosen_demos_rationale_report/hp-applications-survey.html\n\n\n\n"
        },
        {
            "subject": "RE: SWADE postcard mocku",
            "content": ">This looks pretty cool to me.\n\nme also\n\n>\"Which standards should I use\"\n>and \"Where can I *find? meet?* other Semantic Web developers\"\n\ni like these\n\n(technically W3C standards are 'recommendations' but i think\n'standards' is clearer for the non-W3C-er)\n\n--sb\n\n\n\n"
        },
        {
            "subject": "SWADE postcard revised tex",
            "content": "new version - I'll send it to Kelvin this evening if you have any more\ncomments.\n\nhttp://sw1.ilrt.org/discovery/2003/04/svggeo/postcard/postcard-txt-2003-05-06.html\n\nLibby\n\n\n\n"
        },
        {
            "subject": "SWADEurope first version of postcard from the designe",
            "content": "Kelvin's been brilliant and has got a first version already:\n\nhttp://sw1.ilrt.org/discovery/2003/04/svggeo/imgs/SWADpostcardv1.pdf\n\nAny comments? I'll tell him to go ahead tomorrow if people are happy.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope first version of postcard from the designe",
            "content": "* Libby Miller <Libby.Miller@bristol.ac.uk> [2003-05-07 18:48+0100]\n> \n> \n> Kelvin's been brilliant and has got a first version already:\n> \n> http://sw1.ilrt.org/discovery/2003/04/svggeo/imgs/SWADpostcardv1.pdf\n> \n> Any comments? I'll tell him to go ahead tomorrow if people are happy.\n\nLooks good! \n\nMain immediate comment: Can you get him to add back in the http:// prefix?\nSemWeb is pretty URI centric, so encouraging a non-URI way of writing Web \naddresses is probably a mistake.\n\"www.w3.org/2001/sw/Europe/\" -> \"http://www.w3.org/2001/sw/Europe/\"\n\nbelated thought occurs:\nHmm I hope all those colourful geo-political boundaries are still timely;\nmy geographic knowledge is so sketchy I couldn't easily check. Which bits are\nformer Yugoslavia? Czech/(o)Slovakia? etc... \n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope first version of postcard from the designe",
            "content": "yes re the first - I was thinking that. As for the second - anyone got\ngood geographical knowledge here? I can't check easily either since I'm\noffline most of the time at the moment...\n\nLibby\n\nOn Wed, 7 May 2003, Dan Brickley wrote:\n\n> * Libby Miller <Libby.Miller@bristol.ac.uk> [2003-05-07 18:48+0100]\n> >\n> >\n> > Kelvin's been brilliant and has got a first version already:\n> >\n> > http://sw1.ilrt.org/discovery/2003/04/svggeo/imgs/SWADpostcardv1.pdf\n> >\n> > Any comments? I'll tell him to go ahead tomorrow if people are happy.\n>\n> Looks good!\n>\n> Main immediate comment: Can you get him to add back in the http:// prefix?\n> SemWeb is pretty URI centric, so encouraging a non-URI way of writing Web\n> addresses is probably a mistake.\n> \"www.w3.org/2001/sw/Europe/\" -> \"http://www.w3.org/2001/sw/Europe/\"\n>\n> belated thought occurs:\n> Hmm I hope all those colourful geo-political boundaries are still timely;\n> my geographic knowledge is so sketchy I couldn't easily check. Which bits are\n> former Yugoslavia? Czech/(o)Slovakia? etc...\n>\n> Dan\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope first version of postcard from the designe",
            "content": "... I've just checked it against two map sites and it seems fine in the\n\"former Yugoslavia? Czech/(o)Slovakia? etc...\" areas.\n\nPaul\n\n----- Original Message -----\nFrom: \"Libby Miller\" <Libby.Miller@bristol.ac.uk>\nTo: \"Dan Brickley\" <danbri@w3.org>\nCc: \"Libby Miller\" <Libby.Miller@bristol.ac.uk>; \"public-esw\"\n<public-esw@w3.org>\nSent: Wednesday, May 07, 2003 7:04 PM\nSubject: Re: SWAD-Europe first version of postcard from the designer\n\n\n>\n>\n> yes re the first - I was thinking that. As for the second - anyone got\n> good geographical knowledge here? I can't check easily either since I'm\n> offline most of the time at the moment...\n>\n> Libby\n>\n> On Wed, 7 May 2003, Dan Brickley wrote:\n>\n> > * Libby Miller <Libby.Miller@bristol.ac.uk> [2003-05-07 18:48+0100]\n> > >\n> > >\n> > > Kelvin's been brilliant and has got a first version already:\n> > >\n> > > http://sw1.ilrt.org/discovery/2003/04/svggeo/imgs/SWADpostcardv1.pdf\n> > >\n> > > Any comments? I'll tell him to go ahead tomorrow if people are happy.\n> >\n> > Looks good!\n> >\n> > Main immediate comment: Can you get him to add back in the http://\nprefix?\n> > SemWeb is pretty URI centric, so encouraging a non-URI way of writing\nWeb\n> > addresses is probably a mistake.\n> > \"www.w3.org/2001/sw/Europe/\" -> \"http://www.w3.org/2001/sw/Europe/\"\n> >\n> > belated thought occurs:\n> > Hmm I hope all those colourful geo-political boundaries are still\ntimely;\n> > my geographic knowledge is so sketchy I couldn't easily check. Which\nbits are\n> > former Yugoslavia? Czech/(o)Slovakia? etc...\n> >\n> > Dan\n> >\n> >\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope first version of postcard from the designe",
            "content": "There is something near Turkey that I don't recognise (I thought it was part\nof Turkey, but it seems green when the rest of Turkey is yellow). Other than\nthat everything seems to be there - Czech Republic is seperated from\nSlovakia, the various countries that used to make up Yugoslavia are more or\nless there (I don't know the current status of the Yugoslav federation which\nlast I heard included Serbia and Montenegro), Monaco is squashed by the\nbutton for Nice, but that's OK, etc...\n\nLooks good. Is there room for a stamp and an address, and a couple of lines\n(\"Hi Mum, semantic Web is great - I'm the button with an X drawn on it, miss\nyou\" sort of thing)?\n\ncheers\n\nChaals\n\nOn Wed, 7 May 2003, Libby Miller wrote:\n\n>\n>\n>yes re the first - I was thinking that. As for the second - anyone got\n>good geographical knowledge here? I can't check easily either since I'm\n>offline most of the time at the moment...\n>\n>Libby\n>\n>On Wed, 7 May 2003, Dan Brickley wrote:\n>\n>> * Libby Miller <Libby.Miller@bristol.ac.uk> [2003-05-07 18:48+0100]\n>> >\n>> >\n>> > Kelvin's been brilliant and has got a first version already:\n>> >\n>> > http://sw1.ilrt.org/discovery/2003/04/svggeo/imgs/SWADpostcardv1.pdf\n>> >\n>> > Any comments? I'll tell him to go ahead tomorrow if people are happy.\n>>\n>> Looks good!\n>>\n>> Main immediate comment: Can you get him to add back in the http:// prefix?\n>> SemWeb is pretty URI centric, so encouraging a non-URI way of writing Web\n>> addresses is probably a mistake.\n>> \"www.w3.org/2001/sw/Europe/\" -> \"http://www.w3.org/2001/sw/Europe/\"\n>>\n>> belated thought occurs:\n>> Hmm I hope all those colourful geo-political boundaries are still timely;\n>> my geographic knowledge is so sketchy I couldn't easily check. Which bits are\n>> former Yugoslavia? Czech/(o)Slovakia? etc...\n>>\n>> Dan\n>>\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope first version of postcard from the designe",
            "content": "Yes this green bit is part of Turkey and should be \nthe same colour. \n\nLooks good though!\n\nB\n\n\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org]\n> Sent: 08 May 2003 12:39\n> To: Libby Miller\n> Cc: Dan Brickley; public-esw\n> Subject: Re: SWAD-Europe first version of postcard from the designer\n> \n> \n> \n> There is something near Turkey that I don't recognise (I \n> thought it was part\n> of Turkey, but it seems green when the rest of Turkey is \n> yellow). Other than\n> that everything seems to be there - Czech Republic is seperated from\n> Slovakia, the various countries that used to make up \n> Yugoslavia are more or\n> less there (I don't know the current status of the Yugoslav \n> federation which\n> last I heard included Serbia and Montenegro), Monaco is \n> squashed by the\n> button for Nice, but that's OK, etc...\n> \n> Looks good. Is there room for a stamp and an address, and a \n> couple of lines\n> (\"Hi Mum, semantic Web is great - I'm the button with an X \n> drawn on it, miss\n> you\" sort of thing)?\n> \n> cheers\n> \n> Chaals\n> \n> On Wed, 7 May 2003, Libby Miller wrote:\n> \n> >\n> >\n> >yes re the first - I was thinking that. As for the second - \n> anyone got\n> >good geographical knowledge here? I can't check easily \n> either since I'm\n> >offline most of the time at the moment...\n> >\n> >Libby\n> >\n> >On Wed, 7 May 2003, Dan Brickley wrote:\n> >\n> >> * Libby Miller <Libby.Miller@bristol.ac.uk> [2003-05-07 18:48+0100]\n> >> >\n> >> >\n> >> > Kelvin's been brilliant and has got a first version already:\n> >> >\n> >> > \n> http://sw1.ilrt.org/discovery/2003/04/svggeo/imgs/SWADpostcardv1.pdf\n> >> >\n> >> > Any comments? I'll tell him to go ahead tomorrow if \n> people are happy.\n> >>\n> >> Looks good!\n> >>\n> >> Main immediate comment: Can you get him to add back in the \nhttp:// prefix?\n>> SemWeb is pretty URI centric, so encouraging a non-URI way of writing Web\n>> addresses is probably a mistake.\n>> \"www.w3.org/2001/sw/Europe/\" -> \"http://www.w3.org/2001/sw/Europe/\"\n>>\n>> belated thought occurs:\n>> Hmm I hope all those colourful geo-political boundaries are still timely;\n>> my geographic knowledge is so sketchy I couldn't easily check. Which bits\nare\n>> former Yugoslavia? Czech/(o)Slovakia? etc...\n>>\n>> Dan\n>>\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134\n136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78\n22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: SWADEurope first version of postcard from the designe",
            "content": "A small nit, ignore if you wish... on-screen, the colours for Portugal, R. \nIreland and Poland are very close to the colour used for the adjacent sea.\n\nOh, and the green bit between Greece, Bulgaria and Turkey is more of \nTurkey, so I guess it should really be green?\n\n#g\n--\n\nAt 18:48 07/05/2003 +0100, Libby Miller wrote:\n\n\n>Kelvin's been brilliant and has got a first version already:\n>\n>http://sw1.ilrt.org/discovery/2003/04/svggeo/imgs/SWADpostcardv1.pdf\n>\n>Any comments? I'll tell him to go ahead tomorrow if people are happy.\n>\n>cheers\n>\n>Libby\n\n-------------------\nGraham Klyne\n<GK@NineByNine.org>\nPGP: 0FAA 69FF C083 000B A2E9  A131 01B9 1C7A DBCA CB5E\n\n\n\n"
        },
        {
            "subject": "SWADE revised postcard (fwd",
            "content": "Here's the message I sent to Kelvin. Subject to those changes, I think\nwe can go ahead.\nThanks all for your helpful comments, espacially the geographical ones\n:)\n\nLIbby\n\n----\n\nhi Kelvin\n\nThanks for the postcard image - the consenus is that it looks great,\nwith just a couple of niggles\n\n* could we have http://www.w3.org/2001/sw/Europe/ rather than\nwww.w3.org/2001/sw/Europe/ as the url on the front?\n\n* apparantly there's a green bit near turkey which should be part of\nTurkey (which is yellow) - is there any chance you could fix this for\nus?\n\n* one person asked\n\n\"Is there room for a stamp and an address, and a couple of\nlines (\"Hi Mum, semantic Web is great - I'm the button with an X drawn\non it, miss you\" sort of thing)?\"\n\n\nI like this idea, but if you think it would squish the text up too much,\nwe can drop it...\n\nYou can see all the emails here:\n\nhttp://lists.w3.org/Archives/Public/public-esw/2003May/0018.html\n\n- and associated thread.\n\nthanks very much for doing this so quickly - we all like the way it\nlooks :)\n\nLet me know if you need anything else.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWADE revised postcard (fwd",
            "content": "Looking very nice indeed.\n\nI wonder if some geo-specific material might be needed on the site before\nthese get distributed - if a person gets a card, sees there's a spot on\nMadrid and wants to find out what's going on SW-wise specifically in Madrid,\nthey'll point their browser at http://www.w3.org/2001/sw/Europe/  and\nthen..?\n\nCheers,\nDanny.\n\nwho appears to have dropped off the map :-(\n\n\n> -----Original Message-----\n> From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n> Behalf Of Libby Miller\n> Sent: 08 May 2003 16:25\n> To: public-esw@w3.org\n> Subject: SWAD-E revised postcard (fwd)\n>\n>\n>\n>\n> Here's the message I sent to Kelvin. Subject to those changes, I think\n> we can go ahead.\n> Thanks all for your helpful comments, espacially the geographical ones\n> :)\n>\n> LIbby\n>\n> ----\n>\n> hi Kelvin\n>\n> Thanks for the postcard image - the consenus is that it looks great,\n> with just a couple of niggles\n>\n> * could we have http://www.w3.org/2001/sw/Europe/ rather than\n> www.w3.org/2001/sw/Europe/ as the url on the front?\n>\n> * apparantly there's a green bit near turkey which should be part of\n> Turkey (which is yellow) - is there any chance you could fix this for\n> us?\n>\n> * one person asked\n>\n> \"Is there room for a stamp and an address, and a couple of\n> lines (\"Hi Mum, semantic Web is great - I'm the button with an X drawn\n> on it, miss you\" sort of thing)?\"\n>\n>\n> I like this idea, but if you think it would squish the text up too much,\n> we can drop it...\n>\n> You can see all the emails here:\n>\n> http://lists.w3.org/Archives/Public/public-esw/2003May/0018.html\n>\n> - and associated thread.\n>\n> thanks very much for doing this so quickly - we all like the way it\n> looks :)\n>\n> Let me know if you need anything else.\n>\n> cheers\n>\n> Libby\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "RE: SWADE revised postcard (fwd",
            "content": "dropped off the map? It may be that an error has crept in and the point\nisn't exactly correct.\n\n[checks]\n\nYou're still there Danny:\nhttp://sw1.ilrt.org/discovery/2003/04/svggeo/aboutairport.jsp?url=http://www.daml.org/cgi-bin/airport?PSA\n\nis that point not correcty positioned? (it's the upper one in Italy).\nMight still be able to change it.\n\nRe the website, yes, we'll have to put a link from the website to the\nwriteup about this stuff.\n\nLibby\n\n\nOn Fri, 9 May 2003, Danny Ayers wrote:\n\n> Looking very nice indeed.\n>\n> I wonder if some geo-specific material might be needed on the site before\n> these get distributed - if a person gets a card, sees there's a spot on\n> Madrid and wants to find out what's going on SW-wise specifically in Madrid,\n> they'll point their browser at http://www.w3.org/2001/sw/Europe/  and\n> then..?\n>\n> Cheers,\n> Danny.\n>\n> who appears to have dropped off the map :-(\n>\n>\n> > -----Original Message-----\n> > From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n> > Behalf Of Libby Miller\n> > Sent: 08 May 2003 16:25\n> > To: public-esw@w3.org\n> > Subject: SWAD-E revised postcard (fwd)\n> >\n> >\n> >\n> >\n> > Here's the message I sent to Kelvin. Subject to those changes, I think\n> > we can go ahead.\n> > Thanks all for your helpful comments, espacially the geographical ones\n> > :)\n> >\n> > LIbby\n> >\n> > ----\n> >\n> > hi Kelvin\n> >\n> > Thanks for the postcard image - the consenus is that it looks great,\n> > with just a couple of niggles\n> >\n> > * could we have http://www.w3.org/2001/sw/Europe/ rather than\n> > www.w3.org/2001/sw/Europe/ as the url on the front?\n> >\n> > * apparantly there's a green bit near turkey which should be part of\n> > Turkey (which is yellow) - is there any chance you could fix this for\n> > us?\n> >\n> > * one person asked\n> >\n> > \"Is there room for a stamp and an address, and a couple of\n> > lines (\"Hi Mum, semantic Web is great - I'm the button with an X drawn\n> > on it, miss you\" sort of thing)?\"\n> >\n> >\n> > I like this idea, but if you think it would squish the text up too much,\n> > we can drop it...\n> >\n> > You can see all the emails here:\n> >\n> > http://lists.w3.org/Archives/Public/public-esw/2003May/0018.html\n> >\n> > - and associated thread.\n> >\n> > thanks very much for doing this so quickly - we all like the way it\n> > looks :)\n> >\n> > Let me know if you need anything else.\n> >\n> > cheers\n> >\n> > Libby\n> >\n> >\n> >\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "SWADE revised postcard v",
            "content": "http://swordfish.rdfweb.org/discovery/2003/04/svggeo/imgs/SWADpostcardv2.pdf\n\nAny last minute comments? - please send them by 1400 BST as this needs\nto go to print today....\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: SWADE revised postcard v",
            "content": "Kaliningrad is part of Russia and should be the same colour green (its a\ngreen blob a bit northeast of poland).\n\nThere are some Spanish islands which are Yellow, like Italy, instead of\nOrange like Spain. (the ones near spain :)\n\nI guess we don't get to use the Postcard as a postcard, huh?\n\ncheers\n\nChaals\n\nOn Mon, 12 May 2003, Libby Miller wrote:\n\n>\n>\n>http://swordfish.rdfweb.org/discovery/2003/04/svggeo/imgs/SWADpostcardv2.pdf\n>\n>Any last minute comments? - please send them by 1400 BST as this needs\n>to go to print today....\n>\n>cheers\n>\n>Libby\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: SWADE revised postcard v",
            "content": "ok, I'll pass it on.\n\nI asked about the card - he said:\n\n[[\nI can't see how we could fit the stamp/address idea, especially seeing\nas the address and stamp would be on the right and the message written\non the left - doesn't leave anywhere for the text.\n]]\n\nso - sadly - no....\n\nLibby\n\nOn Mon, 12 May 2003, Charles McCathieNevile wrote:\n\n> Kaliningrad is part of Russia and should be the same colour green (its a\n> green blob a bit northeast of poland).\n>\n> There are some Spanish islands which are Yellow, like Italy, instead of\n> Orange like Spain. (the ones near spain :)\n>\n> I guess we don't get to use the Postcard as a postcard, huh?\n>\n> cheers\n>\n> Chaals\n>\n> On Mon, 12 May 2003, Libby Miller wrote:\n>\n> >\n> >\n> >http://swordfish.rdfweb.org/discovery/2003/04/svggeo/imgs/SWADpostcardv2.pdf\n> >\n> >Any last minute comments? - please send them by 1400 BST as this needs\n> >to go to print today....\n> >\n> >cheers\n> >\n> >Libby\n> >\n>\n> --\n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: SWADE revised postcard v",
            "content": "Oh. Leave the title at the top, but small enough not to overrun the stamp.\nThen shrink the rest of the text to take about 1/4 of the card so there is\nroom for a cople of lines that go all the way across the top, under the title\nand stamp, plus space on the right for an address under that.\n\nOh well.\n\ncheers\n\nOn Mon, 12 May 2003, Libby Miller wrote:\n\n>\n>ok, I'll pass it on.\n>\n>I asked about the card - he said:\n>\n>[[\n>I can't see how we could fit the stamp/address idea, especially seeing\n>as the address and stamp would be on the right and the message written\n>on the left - doesn't leave anywhere for the text.\n>]]\n>\n>so - sadly - no....\n>\n>Libby\n>\n>On Mon, 12 May 2003, Charles McCathieNevile wrote:\n>\n>> Kaliningrad is part of Russia and should be the same colour green (its a\n>> green blob a bit northeast of poland).\n>>\n>> There are some Spanish islands which are Yellow, like Italy, instead of\n>> Orange like Spain. (the ones near spain :)\n>>\n>> I guess we don't get to use the Postcard as a postcard, huh?\n>>\n>> cheers\n>>\n>> Chaals\n>>\n>> On Mon, 12 May 2003, Libby Miller wrote:\n>>\n>> >\n>> >\n>> >http://swordfish.rdfweb.org/discovery/2003/04/svggeo/imgs/SWADpostcardv2.pdf\n>> >\n>> >Any last minute comments? - please send them by 1400 BST as this needs\n>> >to go to print today....\n>> >\n>> >cheers\n>> >\n>> >Libby\n>> >\n>>\n>> --\n>> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\n>> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n>>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>>\n>>\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "SWAD-E postcard  pointers to technical stuf",
            "content": "for Charles -\n\ndocument\nhttp://www.w3.org/2001/sw/Europe/200303/geo/intro.html\n\nRDF source files\nhttp://www.w3.org/2001/sw/Europe/200303/geo/allSWGroups.rdf\nhttp://swordfish.rdfweb.org/discovery/2003/04/svggeo/rdf/moreSWGroups.rdf\nhttp://esw.w3.org/topic/AnRdfHarvesterStartingPoint\n\ndemos\nhttp://swordfish.rdfweb.org/discovery/2003/04/svggeo/\n\nissues with the projection:\nhttp://rdfig.xmlhack.com/2003/05/04/2003-05-04.html#1052055545.470260\n\nLibby\n\n\n\n"
        },
        {
            "subject": "SWADE revised postcard ",
            "content": "- has just gone to the printers. We should have them back by Friday, in\ntime to take them to WWW2003.\n\nKelvin didn't have time to make all the suggested alterations, but I\nthink it's looking good:\n\nhttp://swordfish.rdfweb.org/discovery/2003/04/svggeo/imgs/SWADpostcardv3.pdf\n\nthanks for all your help getting it right,\n\nLibby\n\n\n\n"
        },
        {
            "subject": "SWADE Updat",
            "content": "Here's my update in what I've been doing since the last technical\ntelcon / meeting.\n\nWP 12.4\n\nOn the demonstrator side of things, I've been doing some background\nwork as well as some development.  I am still looking at appropriate\nsemantic web data sources to use and in particular RSS.  The stuff\non the web is mostly XML and very badly written.  The XML specs\nare very vague, so this is to be expected, so what I needed was\nsomething to scrape out the statements from this RSS tag soup.  I\nwrote a new RSS parser for Raptor that does it, which can get\nRDF triples out of any of the XML RSSes.  In doing this I found\nsome things I need to update internally to Raptor in order that\nit can work over expat as well as libxml2 - that is ongoing.\n\nI have been looking at a new triple store that has emerged, both in\nterms of useful for this work as well as updating the triple store\nsurvey and the RDBMS storage work (WP10.1, 10.2).  This is the 3Store\nwork at http://3store.sourceforge.net/ from the AKTORS project\n(several partners, this work is done at the University Southampton).\nIt is a C library with a triple store interface built using an\nexisting OKBC toolkit directly talking to MySQL and providing an RDQL\nquery.  I've got it working, cooperated with the developers and made\nsome initial queries to it.\n\nRedland and Raptor\n\nI have also been doing some update to the Redland and Raptor APIs to\nbetter deal with contexts and merging, and fix bugs that have been\nreported since the last releases.  I have also done a split of the\nRedland model interface/implementation that will soon allow adding\naggregate data stores so that graphs can be virtually merged across\nmultiple stores as well as actually merged via contexts inside a\nsingle store.\n\n\nPapers\n\nThe main work I've been doing most recently, was writing a paper for\nsubmission to the International Semantic Web Conference 2003 (ISWC)\nto be held in September 2003 in Florida.\n  A retrospective on the development of the RDF/XML Revised Syntax\n  http://ilrt.org/people/cmdjb/2003/05/iswc/\nThis covers the work I did with RDF Core in revising the syntax, the\napproaches taken in the new syntax document.  It then describes the\nexisting problems that remain with syntaxes for RDF and outlines\nvarious ways to address them including sketches of approaches for\nfuture syntax work.  I can see there is another paper here in\nexpanding on the latter half, not from the retrospective point of\nview.\n\nLast week I gave a presentation XML Europe on general status of the\nsemantic web activity including the SWAD work in US and here.  I\nshowed our postcard for what was probably the first time - I think\nit was Thursday's version.\n\n  \"Semantic Web Update - W3C RDF, OWL Standards,Development and Applications\"\n  http://ilrt.org/people/cmdjb/talks/xmleurope2003/\n\nPlus a little RDF Core work - mostly telcons though.\n\nDave\n\n\n\n"
        },
        {
            "subject": "SWAD-E update  Libb",
            "content": "WP7\n\n* work on RDF query interoperability and testcases; rewriting big chunks\nof the Inkling code\n\nI should be able to get a release out this week.\n\nFrom an RDF query testcases irc meeting, I implemented this:\n\nACTION libby convert squish and RDQL jena tests to ntriples and\ncirculate by date of next meet\n\n- and I have a small test framework that can test using Ntriples\nversions of Andy Seaborne and Alberto Reggiori's RDQL tests as well as\nmy Inkling tests. This is limited to conjunctive only queries, and not\nall get the same answer ... yet. But there's definitely some measure of\ninteroperability.\n\nThe tests are here:\n\nhttp://swordfish.rdfweb.org/rdfquery/tests/\n\nWP3\n\n* postcard, supporting documentation, data\n\nsee\nhttp://lists.w3.org/Archives/Public/public-esw/2003May/0032.html\n\nfor pointers to various technical things about it\n\nhttp://swordfish.rdfweb.org/discovery/2003/04/svggeo/imgs/SWADpostcardv3.pdf\n\nis the final version (for now).\n\n\n* chairing 2 irc calendar meetings, two irc query testcase meetings and\ncontributing to Dan's geo meetings\n\ncalendar\n\nhttp://rdfig.xmlhack.com/2003/04/23/2003-04-23.html\nhttp://rdfig.xmlhack.com/2003/04/09/2003-04-09.html\n\nThese meetings focused on calendar/geo overlap (describing a journey,\nopening hours of a thing that has a place),\nusecases for cal/geo data:\nhttp://rdfig.xmlhack.com/2003/04/09/2003-04-09.html#1049901225.181174\nand also EventDiscovery, sources of calendar data\nhttp://esw.w3.org/topic/EventDiscovery\n\nquery\n\nhttp://rdfig.xmlhack.com/2003/04/24/2003-04-24.html\nhttp://rdfig.xmlhack.com/2003/04/10/2003-04-10.html\n\nThese had two main aspects - implementing and testing very simple query\nformats (ntriples-based) using manifest and resultset formats; and\nbetter RDF query languages  - optionals, provenance and transformation\ninto RDF queries.\n\nWe had a topic maps and RDf query languages BOF at XMLEurope\nhttp://esw.w3.org/topic/TMQLBOF\n\nand there is an upcoming BOF at WWW2003:\nhttp://esw.w3.org/topic/RdfQueryTestingBudapestMeeting\n\n\ngeo meetings\n\nhttp://rdfig.xmlhack.com/2003/04/30/2003-04-30.html\nhttp://rdfig.xmlhack.com/2003/04/16/2003-04-16.html\n\nThese has the following agenda items:\n\nopening hours of a thing that has a place\ndescribing a journey\nupdate on DAML spatial work\nDanC update on travel tool writeup\nRelationship to GML (chat w/ Simon Cox)\nheads up from zool re noderunner and nocat developments\nBus and train route visualization\n\nThere's a lot of interest in this area, and a new mailing list:\nhttp://lists.burri.to/mailman/listinfo/geowanking\n\n\nI also went to XMLEurope - report to follow.\n\ncheers,\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-E update  Libb",
            "content": "Hi Libby,\n> There's a lot of interest in this area, \n> and a new mailing list:\n> http://lists.burri.to/mailman/listinfo/geowanking\nHow on earth did it get that particular name?!\n\nIan (mildly surprised that visiting the mail archive was allowed by HP's\nkeep-the-engineers-pure-and-innocent filters)\n\n\n\n"
        },
        {
            "subject": "RE: SWAD-E update  Libb",
            "content": "heh.\nhere's some discussion from the Geo meet about this topic:\n\nhttp://ilrt.org/discovery/chatlogs/rdfig/2003-04-30.html#T15-37-54\n\n[[\n15:38:14 <_joshua> How about Geowankers is a good place to discuss Geo\nstuff and how it relates to real world applications, not ivory-tower GIS\nstuff. Thus including interop with RDF, XML, perl, whatever etc mumble\nfrotz\n]]\n\n[[\n15:40:06 <_joshua> It's just my sense of humor. Don't take it so\nliterally.\n15:40:16 <jben> ..the name should keep the list relatively small\n]]\n\n\nLibby\n\nOn Wed, 14 May 2003, Dickinson, Ian J wrote:\n\n>\n> Hi Libby,\n> > There's a lot of interest in this area,\n> > and a new mailing list:\n> > http://lists.burri.to/mailman/listinfo/geowanking\n> How on earth did it get that particular name?!\n>\n> Ian (mildly surprised that visiting the mail archive was allowed by HP's\n> keep-the-engineers-pure-and-innocent filters)\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "SWAD-E update  Chaal",
            "content": "WP3 - Workshop report 3\n\nI am taking responsibility for finishing this report, but it will be delayed\nat least until the end of next week (Resource crunch :(\n\nIt will discuss the Geo-meetings held as a virtual, ongoing workshop:\n\n>http://rdfig.xmlhack.com/2003/04/30/2003-04-30.html\n>http://rdfig.xmlhack.com/2003/04/16/2003-04-16.html\n>\n>These had the following agenda items:\n>\n>opening hours of a thing that has a place\n>describing a journey\n>update on DAML spatial work\n>DanC update on travel tool writeup\n>Relationship to GML (chat w/ Simon Cox)\n>heads up from zool re noderunner and nocat developments\n>Bus and train route visualization\n>\n>There's a lot of interest in this area, and a new mailing list:\n>http://lists.burri.to/mailman/listinfo/geowanking\n\nOne result of this work is a new project at W3C to develop a graphical\ninterface (SVG) for creating and working with Geographic information in RDF.\nThis also has implications for WP9 Accessibility (beig able to work with the\ninformation), and potentially with Thesaurus work (different descriptions of\nplaces) and other areas such as Web Services integration.\n\nWP3 - Workshop report 4\n\nThere is little likelihood of a successful workshop in Denmark as we had\nhoped for. A possibility being investigated now is a workshop either on\naccessibility applications or on support for a multilingual Web (which\nincludes issues such as treating sign languages used by Deaf people and\nsymbolic languages used by people with intellectual disailities as an\ninternationalisation problem, expanding the scope from plain text somewhat,\nand building on work already done in areas like image annotation and Dublin\nCore classification)\n\nWP9\n\nWork on a note about ways to use the semantic Web to improve accessibility.\nNeed for coordination has delayed this work package more than we hoped, but\nthere is a rough initial draft in the reports area.\n\nNow working concurrently on finishing that, and moving forward with the\nsecond deliverable (getting WAI groups to comment on which bits are useful\nand which bits need development).\n\nTo that end the AnnoteMez package and integration with Wainu are now availble\nin French, and will be translated shortly. Wainu is a standard accessibility\nevaluation-type tool, with an interface to ask the user for human judgement\nquestions (does this text alternative really match this image? etc),\navailable under LGPL.\n\nAnnoteaMez provides Java libraries to do things like provide EARL information\nto, and store it for, tools such as Wainu, using annotea for storage, Jena\nfor dealing with querying (only some annotea servers include a query\nlanguage) generate and interpret Xpointers, etc.\n\nAnnoteaMez (and its integration with Wainu) was developed as a project at\nESSI (an engineering college in Sophia), which I co-supervised, and is\navailable under W3C License (URIs to follow).\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "SWADE Updat",
            "content": "Brief update on activities since last meeting.\n\nWP 5:\nIntroduced Alvaro Arenas to contribute to this WP.  \nAlvaro has started to survey the area and we propose\nto extend the work of the WP to consider different \nmodelling languages (CommonKADS, Object-Z, UML, \nTopic Maps).  Plan under preparation (this week).\n\nWP 8:\nThesaurus demonstrator continuing.  Integrated into \ndatabase querying system.  Thesaurus format survey \nstarting.\n\nWP 11: \nPresentation at Strathclyde University on Trust Management\nand the Semantic Web. \n\nBrian \n\n\n\n"
        },
        {
            "subject": "danbri swade updat",
            "content": "recently,\n\nwp2/3:\n\n -lots of IRC meetings in RDF Interest Group irc (calendar, query, geo)\n\n -discussions w/ various folks about future of the RDF IG as a broader \n  Semantic Web IG. Begun charter drafting at \n  http://www.w3.org/2001/sw/interest/charter.html \n\n - met up w/ libby and caroline m at ilrt re geo/map project and trying \n  to find caroline m some non-geek intro materials on SW. There isn't much.\n\nwp4 (web services):\n - looking at wsdl/rdf mapping issues with eric p (w3c/mit), talking to \n  Bijan Parsia (Mindlab) re his presentation tommorrow to the WS description \n  working group on the use of rdf and owl for ws description. Hope some \n  useful future work items come out of that.\n\nwp5 (re schema anno):\n - contrasting ericp's RelaxNG schema anno work with the previous \n   tools from Henry Thompson that I was working with. Trying to get \n   clarification re opensource licensing of the edinburg work.\n\nwp7: some progress on hooking up the RDF Query testcases to my RDF \n  query system. Stumped at moment as I don't have a parser for \n  parseType=\"Collection\" bundled.\n\n\nAlso somewhat glacially catching up on variosu other things. \n+ prep for ww2003 (rdf query bof; also i need to present a few slides \non swad-europe during w3c track).\n\nDan\n\n\n\n"
        },
        {
            "subject": "SWADE Workshop outlin",
            "content": "As discussed our last telcon, here's more on the potential workshop\nthat I suggested is organised and run.\n\nOK, I ran out of typing energy, comment away.\n\nDave\n\n\nTitle: SWAD-E Workshop on Semantic Web Storage and APIs\n\nDate: TBD - suggest October / November 2003\n\nLocation: TBD - suggest Amsterdam\n\nCurrent Identified Stakeholders (not an exclusive list):\n\n  In Europe:\n    AKTORS 3store - University of Southampton, UK\n    Jena - HP Labs, Bristol, UK\n    KAON - FZI / AIFB, Karlsruhe, Germany\n    RDF Suite Group - ICS FORTH, Greece\n    Sesame - Aidministrator, Netherlands\n\n    plus Redland - that's me, but I'm hardly a group\n\n    and ... other groups related to the above ?\n      FvH at Amsterdam\n      Ontoweb projects\n      FOAF implementors\n      W3C/ERCIM ... \n\n  Elswwhere:\n    4Suite - Buffalo, USA\n    Mindswap - Maryland, USA\n    Mozilla - ?, USA\n    TAP - Stanford, USA\n    n3, cwm, ... - MIT/W3C, USA\n    rdflib - Daniel Krech, USA\n\n\nWorkshop outline\n\nExisting APIs for the RDF family of technologies (RDF, DAML+OIL, OWL ...)\nare maturing after several years of development and improvement.\n\nThere is no single dominant API either across multiple languages (ok,\nRedland has some of that) or in a single implementation language.\nEach of them covers a different goal and has different strengths.\n\nThis workshop would aim to bring together existing and new developers\nof semantic web storage and APIs to share their experiences and\nlessons.  In particular this workshop could cover\n\n  * Implementation techniques\n  * Storage models and database schemas\n  * Scalability, aggregation and provenance\n  * Lessons from using RDBMSes for semantic web storage\n  * OWL and logic layer functionality - inference engines, validation\n  * Implementing RDF Datatypes\n  * APIs for query languages\n  * Network APIs for semantic web services - SOAP, REST, P2P, ...\n  * Web Service APIs - i.e. web service description such as WSDL\n\n\nExpected Outcomes\n\n  * State of the current APIs\n  * Indication of state of potential API standardisation\n  * Implementation techniques\n  * Updated SWAD-E deliverables 10.1, 10.2\n\n\nRelevant SWAD-E Work\n\nThis relates to at least the following SWAD-E work and completed\ndeliverables (as well as later work).\n\nWP7 Workpackage 7: Databases, Query, API, Interfaces\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-7.html\n\n  D7.1 RDF API requirements and comparison\n  http://www.w3.org/2001/sw/Europe/reports/rdf_api_comparison_report/\n\n  D7.2 Databases, Query, API, Interfaces: report on Query languages\n  http://www.w3.org/2001/sw/Europe/reports/rdf_ql_comparison_report/\n\nWP10: Tools for Semantic Web Scalability and Storage\nhttp://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-10.html\n\n  D10.1 Scalability and Storage: Survey of Free Software / Open\n    Source RDF storage systems \n  http://www.w3.org/2001/sw/Europe/reports/rdf_scalable_storage_report/\n\n  D10.2 Mapping data from RDBMS\n  http://www.w3.org/2001/sw/Europe/reports/scalable_rdbms_mapping_report/\n\n\n\n"
        },
        {
            "subject": "RDF for a MultiLingual worl",
            "content": "Hi folks,\n\nI have added a (presently extremely sparse) page to the Wiki - which so far\nattraced the comment that there will be a multilingual extension to the Wiki\nsoon - at http://esw.w3.org/topic/MultiLingual\n\nideas, adding stuff for other languages would be great...\n\ncheers\n\nChaals\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: SWADE Workshop outlin",
            "content": "Dave Beckett wrote:\n> \n> As discussed our last telcon, here's more on the potential workshop\n> that I suggested is organised and run.\n\nI think is a great suggestion.\n\n>   * Implementation techniques\n>   * Storage models and database schemas\n>   * Scalability, aggregation and provenance\n>   * Lessons from using RDBMSes for semantic web storage\n>   * Implementing RDF Datatypes\n\nThese topics are good and focus on the storage issues. I'd like to add:\n  * Test data and queries for performance comparisons across designs.\n\nThe later topics are in danger of making the workshop too broad and I'd suggest\ndropping them. The first few:\n\n>   * APIs for query languages\n>   * OWL and logic layer functionality - inference engines, validation\n\nmight be OK but the last couple:\n\n>   * Network APIs for semantic web services - SOAP, REST, P2P, ...\n>   * Web Service APIs - i.e. web service description such as WSDL\n\nfeel like they diffuse the topic to much.\n\n> Expected Outcomes\n> \n>   * State of the current APIs    \n>   * Indication of state of potential API standardisation\n>   * Implementation techniques\n>   * Updated SWAD-E deliverables 10.1, 10.2\n\nHow about adding:\n   * Proposals for a performance comparision test suite\n?\n\nDave\n\n\n\n"
        },
        {
            "subject": "Pagina Italiana Re: RDF for a MultiLingual worl",
            "content": "Dove ho metto un link alla pagina Italiana che ho creato...\n\nWhere there is a link to the new Italian page.\n\nDanny Ayers, are you out there?\n\nOn Thu, 15 May 2003, Charles McCathieNevile wrote:\n\n>\n>Hi folks,\n>\n>I have added a (presently extremely sparse) page to the Wiki - which so far\n>attraced the comment that there will be a multilingual extension to the Wiki\n>soon - at http://esw.w3.org/topic/MultiLingual\n>\n>ideas, adding stuff for other languages would be great...\n>\n>cheers\n>\n>Chaals\n>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "SWAD-E  updated site wrt postcar",
            "content": "I've added a thumbnail to the front page of the SWAD-E site and linked\nthe developer map documentation and the postcard (so that people who\nget the postcard can find out about it easily). Let me know if you spot\nanything wrong or think it could be done better.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: Pagina Italiana Re: RDF for a MultiLingual worl",
            "content": "Ciao, Charles, come posso aiuti ti? Vedro che cosa posso trovare...\n\nCheers,\nDanny.\n\n> -----Original Message-----\n> From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n> Behalf Of Charles McCathieNevile\n> Sent: 15 May 2003 17:49\n> To: public-esw@w3.org\n> Subject: Pagina Italiana Re: RDF for a MultiLingual world\n> \n> \n> \n> Dove ho metto un link alla pagina Italiana che ho creato...\n> \n> Where there is a link to the new Italian page.\n> \n> Danny Ayers, are you out there?\n> \n> On Thu, 15 May 2003, Charles McCathieNevile wrote:\n> \n> >\n> >Hi folks,\n> >\n> >I have added a (presently extremely sparse) page to the Wiki - \n> which so far\n> >attraced the comment that there will be a multilingual extension \n> to the Wiki\n> >soon - at http://esw.w3.org/topic/MultiLingual\n> >\n> >ideas, adding stuff for other languages would be great...\n> >\n> >cheers\n> >\n> >Chaals\n> >\n> >\n> \n> -- \n> Charles McCathieNevile  http://www.w3.org/People/Charles  tel: \n> +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 \n> 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n\n\n\n"
        },
        {
            "subject": "RE: Pagina Italiana Re: RDF for a MultiLingual worl",
            "content": "Ciao Danny,\n\nPrimo, puoi mettere qualchi dati FOAF, compresi sui linguaggi che parli...\nGuarda anche la pagina MultiLingual per i elenchi.\n\nE se trovi pagine, articoli, ecc interessanti, mettere un elenco.\n\ne tutti sono sempre benvenuti corregere il mio italiano :)\n\na dopo\n\nChaals\n\nOn Sat, 24 May 2003, Danny Ayers wrote:\n\n>\n>Ciao, Charles, come posso aiuti ti? Vedro che cosa posso trovare...\n>\n>Cheers,\n>Danny.\n>\n>> -----Original Message-----\n>> From: public-esw-request@w3.org [mailto:public-esw-request@w3.org]On\n>> Behalf Of Charles McCathieNevile\n>> Sent: 15 May 2003 17:49\n>> To: public-esw@w3.org\n>> Subject: Pagina Italiana Re: RDF for a MultiLingual world\n>>\n>>\n>>\n>> Dove ho metto un link alla pagina Italiana che ho creato...\n>>\n>> Where there is a link to the new Italian page.\n>>\n>> Danny Ayers, are you out there?\n>>\n>> On Thu, 15 May 2003, Charles McCathieNevile wrote:\n>>\n>> >\n>> >Hi folks,\n>> >\n>> >I have added a (presently extremely sparse) page to the Wiki -\n>> which so far\n>> >attraced the comment that there will be a multilingual extension\n>> to the Wiki\n>> >soon - at http://esw.w3.org/topic/MultiLingual\n>> >\n>> >ideas, adding stuff for other languages would be great...\n>> >\n>> >cheers\n>> >\n>> >Chaals\n>> >\n>> >\n>>\n>> --\n>> Charles McCathieNevile  http://www.w3.org/People/Charles  tel:\n>> +61 409 134 136\n>> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33\n>> 4 92 38 78 22\n>>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>>\n>\n\n-- \nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: RDF Thesaurus  Unresolved Design Issue",
            "content": "Hi Alisatir,\n\ngreat move. I've started to look through the followup messages and will send\nsome commments through the week...\n\ncheers\n\nChaals\n\nOn Fri, 31 Oct 2003, Miles, AJ (Alistair)  wrote:\n\n>\n>Hi everyone,\n>\n>I've started a writeup and discussion of unresolved design issues regarding\n>the RDF thesaurus work.  It's on the SWAD wiki\n><http://esw.w3.org/topic/RdfThesaurus>.  Nikki, Dave B., Danbri, Dave R.,\n>Andy, Libby, Chaals, Steve C, Paul, Brian, Ian, Alvaro, everyone in SWAD, it\n>would be great if you could get involved, I could really do with some\n>feedback and a bit of your expertise.\n>\n>I'll post a short summary to the public-esw-thes list when I add any new\n>issues to the wiki, so please keep an eye out.\n>\n>Yours,\n>\n>Alistair.\n>\n>\n>CCLRC - Rutherford Appleton Laboratory\n>Building R1 Room 1.60\n>Fermi Avenue\n>Chilton\n>Didcot\n>Oxfordshire OX11 0QX\n>United Kingdom\n>\n>Email:        a.j.miles@rl.ac.uk\n>Telephone: +44 (0)1235 445440\n>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Fw: SWADEurope Workshop on Semantic Web Storage and Retrieval,           Amsterda",
            "content": "I just announced the workshop details; there are 22 expected people, 3 flying in\nfrom the USA and a good selection of people, which I'm pretty pleased about.\n\nDave\n------- Forwarded Message\n\nDate: Thu, 06 Nov 2003 12:17:25 +0000\nFrom: Dave Beckett <dave.beckett@bristol.ac.uk>\nTo: ... elided ...\nSubject: SWAD-Europe Workshop on Semantic Web Storage and Retrieval, Amsterdam\n\n\nDear workshop attendees\n\nI'm happy to announce that the workshop agenda has been finalised and\nthat the website has been updated with the new details along with\nyour accepted position papers.  You can find out everything you need\nat the following addresses.\n\nWorkshop home page - links to everything else; and includes location\nand transport details to get to VU.\n   http://www.w3.org/2001/sw/Europe/events/20031113-storage/\n\nPosition papers\n  http://www.w3.org/2001/sw/Europe/events/20031113-storage/positions/\n\nExpected attendees\n  http://www.w3.org/2001/sw/Europe/events/20031113-storage/attendees.html\n\nSo you've got a week to have a look at the position papers and think\nabout the issues before I have the pleasure of meeting you all in\nAmsterdam.\n\nIf you have any questions or problems let me know, otherwise\nI'll see you next Thursday.\n\nCheers\n\nDave\n\n\n------- End of Forwarded Message\n\n\n\n"
        },
        {
            "subject": "Re: Fw: SWADEurope Workshop on Semantic Web Storage and Retrieval,           Amsterda",
            "content": "Nice work :)\n\nSorry I won't be there (am in Japan as you know for W3C AC), but am \nlooking forward to hearing how it went. Sounds fun!\n\nDan\n\n* Dave Beckett <dave.beckett@bristol.ac.uk> [2003-11-06 12:23+0000]\n> \n> I just announced the workshop details; there are 22 expected people, 3 flying in\n> from the USA and a good selection of people, which I'm pretty pleased about.\n> \n> Dave\n> ------- Forwarded Message\n> \n> Date: Thu, 06 Nov 2003 12:17:25 +0000\n> From: Dave Beckett <dave.beckett@bristol.ac.uk>\n> To: ... elided ...\n> Subject: SWAD-Europe Workshop on Semantic Web Storage and Retrieval, Amsterdam\n> \n> \n> Dear workshop attendees\n> \n> I'm happy to announce that the workshop agenda has been finalised and\n> that the website has been updated with the new details along with\n> your accepted position papers.  You can find out everything you need\n> at the following addresses.\n> \n> Workshop home page - links to everything else; and includes location\n> and transport details to get to VU.\n>    http://www.w3.org/2001/sw/Europe/events/20031113-storage/\n> \n> Position papers\n>   http://www.w3.org/2001/sw/Europe/events/20031113-storage/positions/\n> \n> Expected attendees\n>   http://www.w3.org/2001/sw/Europe/events/20031113-storage/attendees.html\n> \n> So you've got a week to have a look at the position papers and think\n> about the issues before I have the pleasure of meeting you all in\n> Amsterdam.\n> \n> If you have any questions or problems let me know, otherwise\n> I'll see you next Thursday.\n> \n> Cheers\n> \n> Dave\n> \n> \n> ------- End of Forwarded Message\n\n\n\n"
        },
        {
            "subject": "Re: Design Issue (4)  constraining 'descriptor'/'prefLabel'            cardinality for multilingual thesaur",
            "content": "Cayzer, Steve wrote:\n\n> 1. sound like a workable fallback \n\nAgreed.\n\n> 2. works but adds inference load \n\nWould need a lot of owl:differentFrom assertions in order to actually have \nthe cardinality constraints bite but that would be the case anyway.\n\n> 3. Urgh! This is similar to the classic subclassing error of OO modelling\n> (imo) - except it's subproperty of course.\n> \n> What about saying (apologies for any N3 errors)\n> <concept> \n>    :hasDescriptor [:inLanguage <French>; :value \"chaud\"];   \n>    :hasDescriptor [:inLanguage <English>; :value \"hot\"] .\n\nThat was sort of what I was suggesting earlier, except that I'd use \nxml:lang to convey the language and was suggesting a descriptorSchema \nproperty for descriptors.\n\nThe to me this is better modelling but you can't express the relevant \ncardinality constraints in OWL.\n\n> Or, if you want to keep cardinality constraints, add a level of indirection\n> <concept> \n>    :hasDescriptor [:alternative [:inLanguage <French>; :value \"chaud\"];\n> :alternative [:inLanguage <English>; :value \"hot\"]] .\n\nThat doesn't help with the cardinality. What Alistair wanted was a \ncardinality constraint that means there is only one perferredTerm in each \nlanguage (in each descriptiveSchema). It is the \"in each\" subclauses that \nis hard to express in OWL without introducing an artificial looking class \nhiearchy.\n\nDave\n\n\n>>-----Original Message-----\n>>From: NJ Rogers, Learning and Research Technology \n>>[mailto:Nikki.Rogers@bristol.ac.uk] \n>>Sent: 07 November 2003 12:14\n>>To: Dave Reynolds; Miles, AJ (Alistair)\n>>Cc: 'public-esw-thes@w3.org'\n>>Subject: Re: Design Issue (4) - constraining \n>>'descriptor'/'prefLabel' cardinality for multilingual thesauri\n>>\n>>\n>>\n>>Hi Alistair and Dave,\n>>\n>>>>This does have consequences for constraining the data model.  It \n>>>>means a node typed as a 'soks:Concept' must then be \n>>\n>>allowed to have \n>>\n>>>>multiple 'soks:descriptor' properties, one for each \n>>\n>>language.  Is it \n>>\n>>>>then possible in OWL to express the constraint that a concept may \n>>>>have one and only one 'soks:descriptor' property for each language?\n>>>\n>>>Only if you represent content-in-a-specific-language as a \n>>\n>>class, which \n>>\n>>>would mean having a different class and different cardinality \n>>>constraint for every language. Which probably wouldn't be workable.\n>>>\n>>\n>>I've been trying to consider some options here:\n>>\n>>***********\n>>1. throw out the 'descriptor' cardinality constraint for multilingual \n>>thesauri (as well as for/as distinct from monolingual \n>>thesauri?) and don't \n>>worry about it - live with it, & provide recommendation of use\n>>\n>>instead.\n>>\n>>***********\n>>2. model multilingual thesauri in a specific way: express \n>>each language's\n>>\n>>interpretation of a concept uniquely by giving the same \n>>concept different \n>>uri's in each of the languages in question. Then map the \n>>concepts (using \n>>\"owl:equivalentTo\").  That way we could still specify exactly \n>>1 preferred \n>>label/'descriptor' per concept. Does it upset us to give \n>>different uri's to \n>>what certain communities believe to be the same concept? I guess how \n>>inferencing is then conducted over the thesaurus data (for \n>>queries) is then \n>>critical & I haven't thought about this in any depth. \n>>Therefore I'm not \n>>sure if this approach is currently \"legal\".\n>>\n>>***********\n>>3. Subclass 'soks:Concept' with what we'd understand to be \n>>concepts in the \n>>context of a particular language. I think this is similar to \n>>what Dave is \n>>referring to? And yes, it feels cranky:\n>>\n>>e.g.\n>>\n>>'soks:Concept'\n>>   |\n>>   |\n>>'soks:English_concept'\n>>\n>>Then we'd potentially have multiple properties (e.g. \n>>soks:english_language_concept, soks:japenese_language_concept \n>>etc.) hanging \n>>off any one 'soks:Concept' in a thesaurus schema.\n>>[I guess 'soks:english_language_concept' has domain \n>>'soks:Concept' and \n>>range 'soks:English_concept' ....]\n>>Using this approach, we can keep the cardinality constraint = 1 for \n>>'soks:descriptor' properties (because there would be one for each of \n>>'soks:English_concept', 'soks:Japenese_concept', etc)?\n>>[I suppose 'soks:English_concept' could be further subclassed for \n>>American_english etc.]\n>>However, typically, one then feels that further constraints are now \n>>required to protect data integrity. Such as a constraint that the \n>>'descriptor' property value for any [Language]_concept must \n>>be in the same \n>>language as that [Language]_concept bla bla.\n>>\n>>Hmmm ... :-)\n>>\n>>Nikki\n>>\n>>\n>>>But in any case you need to add the qualifier \"in any given \n>>\n>>conceptual \n>>\n>>>scheme\". That definitely makes expressing the cardinality \n>>\n>>constraint \n>>\n>>>in OWL unworkable.\n>>>\n>>>Dave\n>>>\n>>>\n>>\n>>\n>>\n>>----------------------\n>>NJ Rogers, Technical Researcher\n>>(Semantic Web Applications Developer)\n>>Institute for Learning and Research Technology (ILRT) \n>>Email:nikki.rogers@bristol.ac.uk\n>>Tel: +44(0)117 9287096 (Direct)\n>>Tel: +44(0)117 9287193 (Office)\n>>\n\n\n-- \nHewlett-Packard Laboratories    | Phone: +44-117-3128165\nFilton Road, Stoke Gifford      | FAX:   +44-117-3128925\nBristol BS34 8QZ, UK            | dave.reynolds@hpl.hp.com\n\n\n\n"
        },
        {
            "subject": "RE: RDF Thesaurus  Unresolved Design Issue",
            "content": "Alistair,\n\nI added a couple of comments to the Wiki (issues 7 and 8)\nHowever, if you'd prefer the comments to go on the mailing list - and then\nyou post a summary to the wiki, that's fine too.\n\nCheers\n\nSteve\n\n> -----Original Message-----\n> From: Miles, AJ (Alistair) [mailto:A.J.Miles@rl.ac.uk] \n> Sent: 31 October 2003 16:16\n> To: 'public-esw@w3.org'\n> Cc: 'public-esw-thes@w3.org'; Wilson, MD (Michael) \n> Subject: RDF Thesaurus - Unresolved Design Issues\n> \n> \n> \n> Hi everyone,\n> \n> I've started a writeup and discussion of unresolved design \n> issues regarding the RDF thesaurus work.  It's on the SWAD wiki >\n<http://esw.w3.org/topic/RdfThesaurus>.  Nikki, > Dave B., \n> Danbri, Dave R., Andy, Libby, Chaals, Steve C, \n> Paul, Brian, Ian, Alvaro, everyone in SWAD, it would be great \n> if you could get involved, I could really do with some \n> feedback and a bit of your expertise.\n> \n> I'll post a short summary to the public-esw-thes list when I \n> add any new issues to the wiki, so please keep an eye out.\n> \n> Yours,\n> \n> Alistair.     \n> \n> \n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> \n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "tshirt discussion, today, 111",
            "content": "Liz Turner, who is going to design the SWAD-Europe tshirt is going to be\non irc.freenode.net #rdfig for an hour today starting from 11 GMT, to\ntalk about possible ideas for the design.\n\nAll welcome!\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Re: Drdfat details for SWADE Semantic Storage and Retrieval Workshop             Amsterdam, Nov 13/1",
            "content": "Hi Dave,\n\nLooks like it will be a good meeting and is shaping up well.\n\nCouple of comments:\n\no The 45m session on day two, \"advanced implementing\", could be clarified.\nIt doesn't sound like very long to cover the issues of OWL and inference. I \nassume, given the length, that this slot is to discuss any such issues that \narise from the day1 discussions rather than opening up those topics from \nscratch. Given the scale of the topic it might be worth narrowing it a little, \nfor example to datatypes and RDFS rather than attempt to squeeze useful OWL \ndiscussions into the time - just a suggestion.\n\no How much are you looking to discuss retrieval issues (query, access APIs)?\nThe title and reading list includes retrieval but the agenda doesn't have \nanything specifically on that. Like OWL support, this is a big topic and it \nmight be worth keeping the meeting focused on the narrower storage aspects but \nI'm happy either way.\n\n[The issue for us, and perhaps for other groups, is who should attend. If the \npeople interested in database mapping, in OWL inference and in retrieval \nlanguages are different then it helps us to decide who should go if the meeting \nfocus is clear.]\n\no It won't be in the public page anyway but the Jena entry should be just \"HP \nLabs\" since the people doing the database support in Jena2 are based in Palo \nAlto rather than Bristol.\n\nCheers,\nDave\n\nDave Beckett wrote:\n\n> I've been editing at\n>   http://www.w3.org/2001/sw/Europe/events/20031113-storage/\n> for this workshop taking place on Nov 13/14 in Amsterdam (hosted by VU). \n> \n> This is not an announcement since there are some bits yet to update; but\n> I'd appreciate some feedback before I pass this on.\n> \n> Cheers\n> \n> Dave\n> \n\n\n\n"
        },
        {
            "subject": "Re: Drdfat details for SWADE Semantic Storage and Retrieval Workshop                      Amsterdam, Nov 13/1",
            "content": "On Wed, 01 Oct 2003 12:06:12 +0100\nDave Reynolds <der@hplb.hpl.hp.com> wrote:\n\n> Hi Dave,\n> \n> Looks like it will be a good meeting and is shaping up well.\n> \n> Couple of comments:\n> \n> o The 45m session on day two, \"advanced implementing\", could be clarified.\n> It doesn't sound like very long to cover the issues of OWL and inference. I \n> assume, given the length, that this slot is to discuss any such issues that \n> arise from the day1 discussions rather than opening up those topics from \n> scratch.\n\nYou assume right.\n\n> ... Given the scale of the topic it might be worth narrowing it a little, \n> for example to datatypes and RDFS rather than attempt to squeeze useful OWL \n> discussions into the time - just a suggestion.\n\nYes, there could be something to prune out here, but I'm not sure which\nones. rdfs has been implemented the most, owl next and datatypes probably\nthe least so it is a question of whether to talk about what has been done or\nwhat has not been done (yet).\n\n> o How much are you looking to discuss retrieval issues (query, access APIs)?\n> The title and reading list includes retrieval but the agenda doesn't have \n> anything specifically on that. Like OWL support, this is a big topic and it \n> might be worth keeping the meeting focused on the narrower storage aspects but \n> I'm happy either way.\n\nPersonally I'd support some on the API/interface side of things such as\nquery, WS, programmatic APIs.  When you store the stuff, how you get it\nin/out is important.\n\nIt seems somewhat that removing or reducing the OWL mentions would make\nit fit better into the time.  However it would be a shame to have\nnothing about that since there are people working on it now/recently for\nOWL's CR so getting them together would be useful.  I guess they\nare all off to the ontology conference in Florida anyway so maybe\nthat's not so criticial for this event.\n\n> [The issue for us, and perhaps for other groups, is who should attend. If the \n> people interested in database mapping, in OWL inference and in retrieval \n> languages are different then it helps us to decide who should go if the meeting \n> focus is clear.]\n\nRight.\n\n> o It won't be in the public page anyway but the Jena entry should be just \"HP \n> Labs\" since the people doing the database support in Jena2 are based in Palo \n> Alto rather than Bristol.\n\nOK\n\nDave\n\n\n\n"
        },
        {
            "subject": "SWADE Semantic Storage and Retrieval Workshop  Amsterdam, Nov 13/1",
            "content": "After a lot more editing of the page, link and reference chasing, I\nthink this is ready to announce.  I'll send an announcement something\nlike the message below to www-rdf-interest and directly to the already\nidentified stakeholders (some of whom are probably already on this list),\nto start this off.\n\nDave\n\n     SWAD-Europe Workshop on Semantic Web Storage and Retrieval\n 13-14 November 2003\n     Vrije Universiteit, Amsterdam, Netherlands.\n\n     http://www.w3.org/2001/sw/Europe/events/20031113-storage/\n\nThis is a small workshop (max 25) that aims to bring together\nexisting and new developers of semantic web storage and APIs to share\ntheir experiences and lessons learnt - what worked, what didn't work.\n\nThe workshop is organised by the EU IST project Semantic Web Advanced\nDevelopment (SWAD) Europe project and locally hosted by VU, Amsterdam.\n\nImportant dates\n  * 24 October 2003 Deadline for position papers\n  * 6 November 2003 Registration closed\n\n\n\n"
        },
        {
            "subject": "Liverpool Digital and the Semantic Web (fwd",
            "content": "I offered to forward this message to see if we can help Philip. He\nisn't on the list, so emails to him please.\n\nthanks,\n\nLibby\n\n---------- Forwarded message ----------\nDate: Tue, 14 Oct 2003 22:24:14 +0100\nSubject: Re: Fw: Liverpool Digital and the Semantic Web\n\nHi Libby\n\nMany thanks for getting back to me. If you could post this on the public\nmailing list I'd appreciate it.\n\nI'm identifying business ideas to develop into a commercially sustainable\ndigital industry product using the Liverpool Digital site as a catalyst. The\noverall objective is to turn 7 or 8 ideas into reality, of which the\nSemantic Web might be one. The business development process is to provide a\nmechanism to attract and secure sufficient and suitable commercial activity\nfor the Liverpool Digital initiative at terms acceptable to the North West\nDevelopment Agency.\n\nI'm excited about the opportunities to use Semantic Web developments in new\nmachine readable applications to exploit time based or geographic data on\nthe web. Potential business models for Liverpool Digital are a 'Semantic Web\napplication development house' or a 'training and development organisation\nto encourage companies to develop SW applications'. With either model the\nprocess would be to got out to tender for organisations to run it on a\ncommercial basis.\n\nThe first phase of the business development process is to generate ideas and\nthen phase gate review them (other competing ideas are being generated by\nother groups) - the ones that pass will go onto a feasibility study. I'm up\nagainst a deadline of the 23rd October to get a one page summary for the\nphase gate review by the Liverpool Digital board. Essentially - what is the\nopportunity, benefits, value add, business model, indicative costs etc.\n\nRegards\n\nPhilip\n\nNWDA Regional Business Adviser - Digital Industries\nphilip.hemsted@btopenworld.com\nt   +44 (0) 1925 754 351\nm +44 (0) 7876 398 224\n\n\n\n"
        },
        {
            "subject": "WP8 Thesauri  our items for meeting Thursda",
            "content": "We would like some discussion to centre on what we have so far produced in \nthe way of:\n1. - scope\n2. - scenarios\n3. - use cases\nwhich we see as an important first step in developing the definition of a \nweb service API for access to a thesaurus service\n\n\n1. SCOPE\n\nPlease comment on whether we should widen/narrow our scope:\n\na) A thesaurus service accessible to the end-user as some sort of\n   tool e.g. on a browser sidebar\n\nb) A \"3rd party\" thesaurus service, available for machine to machine\n   (M2M) networking\n\n\n\n2. SCENARIOS\n\nWould anyone like to add to/comment on these scenarios:\n\n***********\nHuman end user:\n***********\n\n- Jim Hendler's use case (from rdf interest): marking up web\n  resources using a thesaurus service\n\n- marking up resources for a specific user community\n  e.g. SOSIG (social sciences) cataloguer\n\n- Alistair Miles's use case: tool support for better searching and\n  also browsing using web search engines s.a. Google\n  [a similar scenario applies for example to a SOSIG end user]\n\n\n**************\nM2M\n**************\n\n- Cross-search\n  (\"invisible\") better query recall across a set of data\n  repositories, e.g. this would extend a tool like SPP's xsearch\n\n- Cross-browse\n  end-users \"seamlessly\" browsing a hierarchy of categories\n  represented across many data repositories in order to refine their\n  search terms, for example when 2 or more KOS's have been \"federated\"\n\n\n\n3. USE CASES\n\nThe set of \"questions\" that might be asked of either type of service seem\nto be the same for both and include the following. Comments please.\n\nAssumption: in the following questions we assume that concepts are\nidentified by their single preferred term (and can have multiple\nnon-preferred terms).  However, we anticipate that concept URIs may\nalso be part of such questions/exchanges:\n   \"give me the URI of the concept in thesaurus Y identified by this\n   preferred term X\"\nor in the case of checking whether the preferred term for some concept\nhas perhaps changed, which would lead to the question:\n  \"give me the preferred term in thesaurus Y for the concept\n  identified by this URI X\"\nWe may build these use cases in.\n\n*** asking for information pertaining to a single thesaurus ****\n\n- \"give me a list of preferred and non-preferred terms in some thesaurus Y \nmatching some submitted keyword\" \n\n  [a cataloguer/searcher who needs to know any terms that are a\n  potential match for some keyword - permitting truncation or\n  stemming. Essentially, the user is trying to find an \"entry\" point\n  into some thesaurus that they are unfamiliar with]\n\n- \"give me the non-preferred term(s) for some concept X in some thesaurus Y\"\n\n- \"give me the scope note for some concept X in some thesaurus Y\"\n\n- \"give me the broader/narrower/related term for some term Z in some\n   thesaurus Y\"\n\n- \"give me all \"top\" (/root) terms for a preferred term X/concept Z in some \n   thesaurus Y\"\n\n[\n- \"give me metadata about thesaurus Y (s.a. it's language, its\n  creator, version ???)\"\n]\n\n[Advanced: \n- perhaps some further questions based around the idea of asking for\n  the *type* of relations between hierarchical terms within a\n  thesaurus for example 'broader-generic', 'broader-partitive'\n  (part-of) as in your document, \n \n   Or are we keeping that sort of data \"behind the scenes\"?\n]\n\n\n\n*** asking for information re mappings between thesauri ***\n\n- \"give me the equivalent term(s) for X in some target thesaurus/thesauri\n  if it exists, or partial equivalent if it exists\"\n\nDave and Nikki\n\n\n\n"
        },
        {
            "subject": "Thesaurus / mapping reference",
            "content": "Crossposted; followups just to public-esw-thes please.\n\n\nForgot about this one from QL'98 position papers on RDF query:\nIn http://www.w3.org/TandS/QL/QL98/pp/queryservice.html\none scenario we implemented was to take two different data services (a couple of\ninternet catalogues at ILRT), each using different schemes, and exploit\nmappings between the taxonomies to merge data into a single environment.\n\nSee section, \"Example: Classification Scheme Mapping\". \n\nNot sure anything there is immediately useful for us now, but it was \ninteresting at the time, combining rule engines with the work we were\ndoing on RDF thesaurus stuff in the DESIRE project (one ancestor of\nTIF).\nhttp://www.desire.org/results/discovery/cat/mapclass_des.htm\nhttp://www.desire.org/results/discovery/rdfthesschema.html\n\nThe inference engine we used, SiLRI, is now no longer maintained.\nNeither is the parser SiRPAC. I think Biz/ed and SOSIG are still going\nthough :) \n\n(though I don't know if they still use different schemes, otherwise this\nmight be a good dataset to revisit...). Kate, does Biz/ed use DDC and\nSOSIG use UDC still?\n\nDan\n\n\n\n"
        },
        {
            "subject": "Trust Conference in Marc",
            "content": "As mentioned at the management meeting today - particularly\nfor the Trust WP 11.\n\nhttp://www.trustmanagement.cclrc.ac.uk/Home/\n\nthanks\n\nBrian\n\n\n\n"
        },
        {
            "subject": "Final remarks on Deliverable 8.2  Review of RDF Thesaurus Wor",
            "content": "Any last words before I tell Kate she can send it to Brussels?\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.2.html\n\nAl. \n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RDF Thesaurus  Unresolved Design Issue",
            "content": "Hi everyone,\n\nI've started a writeup and discussion of unresolved design issues regarding\nthe RDF thesaurus work.  It's on the SWAD wiki\n<http://esw.w3.org/topic/RdfThesaurus>.  Nikki, Dave B., Danbri, Dave R.,\nAndy, Libby, Chaals, Steve C, Paul, Brian, Ian, Alvaro, everyone in SWAD, it\nwould be great if you could get involved, I could really do with some\nfeedback and a bit of your expertise.\n\nI'll post a short summary to the public-esw-thes list when I add any new\nissues to the wiki, so please keep an eye out.\n\nYours,\n\nAlistair.     \n\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "ANNOUNCEMENT: Raptor RDF Parser Toolkit 1.0.",
            "content": "Just shipped 1.0.0\n\nDave\n\n------- Forwarded Message\nTo: www-rdf-interest@w3.org\nSubject: ANNOUNCEMENT: Raptor RDF Parser Toolkit 1.0.0\n\n\n   Raptor RDF Parser Toolkit 1.0.0\n     http://www.redland.opensource.ac.uk/raptor/\n\n               Supported by EU IST project SWAD-Europe\n  http://www.w3.org/2001/sw/Europe/\n\nRaptor is a free software/Open Source C library that parses RDF\nsyntaxes such as RDF/XML and N-Triples into RDF triples.  It handles\nall RDF vocabularies such as FOAF, RSS 1.0, Dublin Core and OWL.\n\nRaptor is designed to work closely with the Redland RDF library but\nis fully separate.  It is a mature, portable and high performance\nlibrary that works across many POSIX systems (Unix, GNU/Linux, BSDs,\nOSX, cygwin) and others. It has been tested on multiple architectures\n(x86, IA64, powerpc, alpha, sparc).  Raptor has no known memory leaks\nand is suitable for embedding in long running applications.\n\nThis is the start of the 1.0 series of Raptor after nearly three\nyears of development.  Fixes to this series will be given 1.0.x\nversions, changes will be in version 1.1.0.\n\nSummary of changes:\n\n * Several long-deprecated functions were removed and consequently \n   the library shared version number was increased to 1.\n * Fixed scanning for rdf:RDF so that RDF/XML in other XML works, such as SVG\n * Normalize RDF/XML xml:lang and N-Triples language to lowercase on input\n * Worked around libxml2 bug causing a crash on some error reporting\n * Added raptor_parse_file_stream for parsing a C FILE*\n * Other minor bug fixes.\n\nRaptor was tested as working out-of-the-box (configure; make; make check)\nwith the following systems:\n    i686-pc-linux-gnu        - Redhat GNU/Linux 9\n    i686-pc-linux-gnu        - Debian GNU/Linux unstable\n    i386-unknown-freebsd4.8  - FreeBSD 4.8\n    powerpc-apple-darwin6.6  - Apple OSX 10.2.6\n    x86_64-unknown-linux-gnu - SuSE GNU/Linux 8ES on AMD64 Opteron\n    sparc-sun-solaris2.8     - Sun Solaris 8\n\nThe release consists of the full sources, RPM binaries and source RPM\npackages for RedHat Linux 9.  These are also available from the\nRedland SourceForge mirror site at\n  http://sourceforge.net/projects/librdf/\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS and use Raptor in various demos (as part of Redland).\n\nI post updates about Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\nDave\n\n\n------- End of Forwarded Message\n\n\n\n"
        },
        {
            "subject": "cfp: JoDI Special Issue on New Applications of Knowledge Organization System",
            "content": "----- Forwarded message from Douglas Tudhope <dstudhope@GLAM.AC.UK> -----\n\nFrom: Douglas Tudhope <dstudhope@GLAM.AC.UK>\nDate: Mon, 8 Sep 2003 17:41:03 +0100\nTo: NKOS@dli2.nsf.gov\nSubject: cfp: JoDI Special Issue on New Applications of Knowledge \n         Organization Systems\nMessage-ID: <01f401c37627$fe9e5fa0$421a4f51@unet.com>\nReply-To: Douglas Tudhope <dstudhope@GLAM.AC.UK>\n\nCall for Papers\n\nJournal of Digital Information announces a Special Issue on\nNew Applications of Knowledge Organization Systems\n\nSpecial issue Editors: Traugott Koch and Doug Tudhope\nLund University and University of Glamorgan\n\nSubmission deadline: 7 October 2003\nPublication: January 2004\n\nSubmissions are sought for a special edition of JoDI on new applications\nand contexts for Knowledge Organisation Systems (KOS). This includes but is\nnot restricted to novel applications and representations of KOS in advanced\ndigital library (DL) and semantic Web environments.\n\nThis call builds on two recent NKOS workshops at JCDL 2003 in Houston, and\nECDL 2003 in Trondheim. A number of submissions have already been committed\nbased on presentations given at the workshops.\n\nMore generally, we welcome submissions that fit the scope of the call from\nall interested parties and communities. Articles from a previous NKOS issue\n(April 2001) rank among the most popular JoDI publications based on access\nstatistics.\n\nKOS services, such as classifications, gazetteers, lexical databases,\nontologies, taxonomies and thesauri model the underlying semantic structure\nof a domain. Embodied as (Web) services, they can facilitate resource\ndiscovery and retrieval. They act as semantic road maps and make possible a\ncommon orientation by indexers and future users (whether human or machine).\nHowever, using them to their full potential in advanced DL and semantic Web\napplications poses various new challenges.\n\nFor more details, indicative topics and the submission procedure, see the\nfull call\nhttp://jodi.ecs.soton.ac.uk/calls/newnkos.html\nAll submissions will be subject to peer review.\n\nThe Journal of Digital Information is an electronic journal published only\nvia the Web. JoDI is currently free to all users thanks to support from the\nBritish Computer Society and Oxford University Press.\nhttp://jodi.ecs.soton.ac.uk/\n\nSome Indicative Topics (not intended to be exhaustive)\n\nDigital library requirements for integration of KOS into DL services\nStandards for constructing, representing and applying KOS in digital\nenvironments\nNamespaces and registries for KOS and KOS relationships\nMaintenance and update of KOS\n\nDistributed access to KOS, Web service applications\nInteroperability, cross-browsing and cross-searching\n\nKnowledge organisation as support for Web-based information retrieval\nKnowledge organisation for filtering, information extraction, summary\nKnowledge organisation for indexing and annotation\n\nKnowledge organisation support for multilingual systems, natural language\nprocessing\nApplication of language engineering/terminology/corpus analysis with KOS\n\nSemantic Web applications of KOS\nOntology description languages, standards and applications\nXML/RDF representations for KOS content\n\nUser interfaces, KOS visualisation\nEvaluation and studies of use, end-user interactions with KOS\n\n----- End forwarded message -----\n\n\n\n"
        },
        {
            "subject": "ANNOUNCEMENT: Redland RDF Application Framework 0.9.1",
            "content": "And also shipped a Redland 0.9.14 to match the Raptor release.\n\nDave\n\n------- Forwarded Message\nTo: www-rdf-interest@w3.org\nSubject: ANNOUNCEMENT: Redland RDF Application Framework 0.9.14\n\n\n       Redland RDF Application Framework 0.9.14\nhttp://www.redland.opensource.ac.uk/\n\n               Supported by EU IST project SWAD-Europe\n  http://www.w3.org/2001/sw/Europe/\n\nRedland is a C library that provides a high-level interface for RDF\nallowing the RDF graph to be parsed from XML, stored, queried and\nmanipulated.  Redland implements each of the RDF concepts in its own\nclass via an object based API, reflected into the other language APIs\n- Java, Perl, PHP, Python, Ruby and Tcl. Some of the classes\nproviding the parsers, storage mechanisms and other elements are\nbuilt as modules that can be added or removed as required.\n\nRedland 0.9.14 is a minor release to synchronise with the\nRaptor 1.0.0 RDF parser library. The main changes are as follows\n\n   * Added a new utility program rdfproc - a general RDF processor\n     for Redland that allows command line use of the library.\n   * Made the Node class intern every node.\n   * Fixed the broken use of Perl UNIVERSAL::isa\n\nSee also the detailed 0.9.14 release notes at\nhttp://www.redland.opensource.ac.uk/RELEASE.html#rel0_9_13\n\nThe release consists of the full sources, RPM binaries and SRPMS\npackages for RedHat Linux 9.  Experimental Debian debs will be\navailable shortly.  It is also available from the Redland SourceForge\nmirror site at http://sourceforge.net/projects/librdf/\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS and use Redland in various demos.\n\nI post updates about Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\nDave\n\n\n------- End of Forwarded Message\n\n\n\n"
        },
        {
            "subject": "RE: JoDI Special Issue on New Applications of Knowledge Organizat ion System",
            "content": "Alistair attended the Trondheim workshop\nmentioned and is writing up a paper for \ninclusion in this special issue. \n\nBrian\n\n> -----Original Message-----\n> From: Dan Brickley [mailto:danbri@w3.org]\n> Sent: 08 September 2003 21:06\n> To: www-rdf-interest@w3.org; public-esw@w3.org\n> Subject: cfp: JoDI Special Issue on New Applications of Knowledge\n> Organization Systems\n> \n> \n> \n> \n> \n> ----- Forwarded message from Douglas Tudhope \n> <dstudhope@GLAM.AC.UK> -----\n> \n> From: Douglas Tudhope <dstudhope@GLAM.AC.UK>\n> Date: Mon, 8 Sep 2003 17:41:03 +0100\n> To: NKOS@dli2.nsf.gov\n> Subject: cfp: JoDI Special Issue on New Applications of Knowledge \n>          Organization Systems\n> Message-ID: <01f401c37627$fe9e5fa0$421a4f51@unet.com>\n> Reply-To: Douglas Tudhope <dstudhope@GLAM.AC.UK>\n> \n> Call for Papers\n> \n> Journal of Digital Information announces a Special Issue on\n> New Applications of Knowledge Organization Systems\n> \n> Special issue Editors: Traugott Koch and Doug Tudhope\n> Lund University and University of Glamorgan\n> \n> Submission deadline: 7 October 2003\n> Publication: January 2004\n> \n> Submissions are sought for a special edition of JoDI on new \n> applications\n> and contexts for Knowledge Organisation Systems (KOS). This \n> includes but is\n> not restricted to novel applications and representations of \n> KOS in advanced\n> digital library (DL) and semantic Web environments.\n> \n> This call builds on two recent NKOS workshops at JCDL 2003 in \n> Houston, and\n> ECDL 2003 in Trondheim. A number of submissions have already \n> been committed\n> based on presentations given at the workshops.\n> \n> More generally, we welcome submissions that fit the scope of \n> the call from\n> all interested parties and communities. Articles from a \n> previous NKOS issue\n> (April 2001) rank among the most popular JoDI publications \n> based on access\n> statistics.\n> \n> KOS services, such as classifications, gazetteers, lexical databases,\n> ontologies, taxonomies and thesauri model the underlying \n> semantic structure\n> of a domain. Embodied as (Web) services, they can facilitate resource\n> discovery and retrieval. They act as semantic road maps and \n> make possible a\n> common orientation by indexers and future users (whether \n> human or machine).\n> However, using them to their full potential in advanced DL \n> and semantic Web\n> applications poses various new challenges.\n> \n> For more details, indicative topics and the submission \n> procedure, see the\n> full call\n> http://jodi.ecs.soton.ac.uk/calls/newnkos.html\n> All submissions will be subject to peer review.\n> \n> The Journal of Digital Information is an electronic journal \n> published only\n> via the Web. JoDI is currently free to all users thanks to \n> support from the\n> British Computer Society and Oxford University Press.\n> http://jodi.ecs.soton.ac.uk/\n> \n> Some Indicative Topics (not intended to be exhaustive)\n> \n> Digital library requirements for integration of KOS into DL services\n> Standards for constructing, representing and applying KOS in digital\n> environments\n> Namespaces and registries for KOS and KOS relationships\n> Maintenance and update of KOS\n> \n> Distributed access to KOS, Web service applications\n> Interoperability, cross-browsing and cross-searching\n> \n> Knowledge organisation as support for Web-based information retrieval\n> Knowledge organisation for filtering, information extraction, summary\n> Knowledge organisation for indexing and annotation\n> \n> Knowledge organisation support for multilingual systems, \n> natural language\n> processing\n> Application of language engineering/terminology/corpus \n> analysis with KOS\n> \n> Semantic Web applications of KOS\n> Ontology description languages, standards and applications\n> XML/RDF representations for KOS content\n> \n> User interfaces, KOS visualisation\n> Evaluation and studies of use, end-user interactions with KOS\n> \n> ----- End forwarded message -----\n> \n\n\n\n"
        },
        {
            "subject": "&quot;From Thesaurus to Ontology&quot; pape",
            "content": "re AAt etc.,\n http://www.swi.psy.uva.nl/usr/Schreiber/papers/Wielinga01a.pdf\n see msg from Guus at \nhttp://lists.w3.org/Archives/Public/www-webont-wg/2001Nov/0117.html\nfor more context.\n\nDan\n \n\n\n\n"
        },
        {
            "subject": "Thesaurus semantics &amp; mapping pape",
            "content": "On problems of thesaurus semantics and inter-thesaurus mapping:\n\nhttp://jodi.ecs.soton.ac.uk/Articles/v01/i08/Doerr/\n\nRDF metadata attached.\n\nAlistair.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n <<ref.rdf.n3>> \n\n\n\n\napplication/octet-stream attachment: ref.rdf.n3\n\n\n\n\n"
        },
        {
            "subject": "Critique of thesaurus standard",
            "content": "A good overview and critique of thesaurus standards:\n\nhttp://www.glam.ac.uk/soc/research/hypermedia/NKOS-workshop%20Folder/Soergel\n2.ppt\n\nRDF metadata attached.\n <<meta.rdf.n3>> \nAlistair. \n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n\n\n\napplication/octet-stream attachment: meta.rdf.n3\n\n\n\n\n"
        },
        {
            "subject": "Re: Thesaurus semantics &amp; mapping pape",
            "content": "Hi Alistair\n\n> On problems of thesaurus semantics and inter-thesaurus mapping:\n>\n> http://jodi.ecs.soton.ac.uk/Articles/v01/i08/Doerr/\n>\nYes, thanks for this - I read it with interest.\nI like the way they describe the issues we discussed at the meeting\n(essentially, the way that a variety of semantic relations are confusingly \nmodelled as subsumption relations) & this has been good for me in terms of \ndeveloping a \"correct\" vocabulary with which to talk about these things.\n\nThey make a good problem statement for the mapping of existing thesauri \nthat carry the legacy of a pre-computer-age approach to the creation of \nthesauri.\nAnd it is interesting to see their suggested approach for the preparation \nof thesauri that are to be mapped to each other (i.e. a particular \nthesaurus' use of subsumption relations, and identifying the qualia under \nwhich subsumption hierarchies are created etc.)- this gets quite complex & \nprobably labour intensive ! But necessary, because they are defining the \naim of the solution space to be to bridge the gap between the methodology \nused by thesauri creators & technical implementors.\n\nSo thanks, & I'll get on to replying to your other email ...\n\nNikki\n\n\n> RDF metadata attached.\n>\n> Alistair.\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>  <<ref.rdf.n3>>\n\n\n\n----------------------\nNJ Rogers, Technical Researcher\n(Semantic Web Applications Developer)\nInstitute for Learning and Research Technology (ILRT)\nEmail:nikki.rogers@bristol.ac.uk\nTel: +44(0)117 9287096 (Direct)\nTel: +44(0)117 9287193 (Office)\n\n\n\n"
        },
        {
            "subject": "fwd: FAQs, best practices, ESW Wik",
            "content": "Nice work from Dan Connolly... (from the WebOnt WG list)\n\n----- Forwarded message from Dan Connolly <connolly@w3.org> -----\n\nFrom: Dan Connolly <connolly@w3.org>\nDate: Wed, 17 Sep 2003 15:29:45 -0500\nTo: www-webont-wg@w3.org\nSubject: FAQs, best practices, ESW Wiki\nMessage-Id: <1063830584.5534.492.camel@dirk.dm93.org>\nResent-From: www-webont-wg@w3.org\nResent-Date: Wed, 17 Sep 2003 16:29:50 -0400 (EDT)\nOrganization: World Wide Web Consortium (http://www.w3.org/)\n\n\nRegarding...\n\n\"ACTION DanC: Propose Wiki be used for FAQ\"\n -- minutes 11Sep\n  http://lists.w3.org/Archives/Public/www-webont-wg/2003Sep/0163.html\n\nThe subject of a FAQ list, best practice guides, and cookbooks\nhave come up in this WG a few times.\nIt also came up in the DAML joint-committee\n\nI'm sure everybody agrees that We Should have one of these;\nit's a question of how, when, who, and the like.\n\nThe FAQ that went out with the OWL CR was written by Jim...\n  http://www.w3.org/2003/08/owlfaq\n  http://www.w3.org/2003/08/owlfaq.html\n  http://www.w3.org/2003/08/owlfaq.html.fr\n\nand edited by Janet and a few others in the W3C team.\n\nBut that sort of W3C communications team resource isn't\navailable on an ongoing basis, and I don't think Jim\nis volunteering to do it regularly.\n\nThe best mechanism I've seen for documenting community\nwisdom in a scalable way is WikiWikiWeb. The European\nCommission funded some semantic web outreach work,\nand we used some of that funding to set up a wiki...\n\n  \"ESW can stand for Evolving, European, Experimental,\n  Extended, Enthusiastic, ... Semantic Web, reflecting its\n  origins in the SWAD-Europe project, and affiliation with\n  the wider RDF / Semantic Web Interest Group.\"\n    -- http://esw.w3.org/topic/FrontPage\n\nI'll let it explain itself a bit more...\n\n[[[\nThis is a WikiWikiWeb, a collaborative hypertext environment, with an\nemphasis on easy access to and modification of information. It is\nsomething of an experiment in WikiConsensus. In some ways the open\nnature of a Wiki is not that different from W3C's open, archived mailing\nlists. In other ways it is rather different (see BeesAndAnts), and\nperhaps more supportive of coming to consensus. \n\nYou can edit any page by following the link at the bottom of the page.\nCapitalized words joined together form a WikiName, which hyperlinks to\nanother page. The highlighted title searches for all pages that link to\nthe current page. Pages which do not yet exist are linked with a\nquestion mark: just follow the link and you can create a suitable page. \n\nThis wiki is particularly focussed on the SemanticWeb, but any W3C work\nareas are on-topic here. There are lots of other wikis (see InterWiki)\nwhich may be more appropriate for some subjects. \n\nIt is good to speak in the community voice, at least when you have some\nidea how the community might think about a subject. It's nice to log in\nusing UserPreferences, so people can see who made which changes. Browse\nthis wiki and others to get an example of style and etiquette.\n]]]\n\nLast week DebM pointed us to a sort of cookbook entry...\n\n  Working with a closed world assumption in OWL/DAML+OIL\nhttp://www.ksl.stanford.edu/people/dlm/webont/HowToDoIt/closingRoles.html\n\nSo I took that and integrated it into the ESW Wiki by\ncreating a ClosedWorldAssumptions topic linked\nfrom SemanticWebArchitecture, and then giving ClosingRoles\nas an example of how to approximate support for\nCloseWorldAssumptions.\n\nI'm not quite sure I understood the closingRoles.html document.\nAnd the topic has already grown a disagreeing annotation.\nBut I trust it will evolve to reflect community wisdom\nin due course.\n\nI hope to try out a couple more topics presently...\n\n  a recipie for ont:UnambiguousProperty, rdfs:isDefinedBy\n  From: Dan Connolly (connolly@w3.org)\n  Date: 05/16/01\n  http://www.daml.org/listarchive/joint-committee/0418.html\nand\n  http://www.daml.org/listarchive/joint-committee/0419.html\n\nI think the potential for synergy between OWL FAQs, RDF\nFAQs, URI FAQs, and XML FAQs is considerable. I had a good\ntime moving a centrally-maintained list into the UriSchemes\ntopic, and the synergy with topics like FollowYourNose\nis already apparent.\n\nJim writes...\n\n[[[\nI have thought about this a while, I worry about a WIKI approach \n- we want to control some of this -- I think a WIKI page for users to \nbe able to write/comment that is linked to a page maintained \nsomewhere in W3C space makes much more sense.  I propose we consider \nstarting this page as a WG, putting an \"expiration date\" on it equal \nto end of our WG (i.e. no commmitment beyond our chartered date) -- \nwe would then have an expectation that the new SWIG (if approved) \nwould take this over, but we would have no commitment if they don't.\n]]]\n\nI don't want any more control than the Wiki gives me.\n\nOther folks in the WG could maintain pages in the\nhttp://www.w3.org/* space, as Mike does with\nthe issues list and Jos and Jeremy do with the\ntest materials. There's a certain level of tedium\ninvolved, but I suppose it might be tolerable.\nI have considered doing that, and the cost of\nhaving all edits funnelled thru one person\n(or a few people) doesn't look worthwhile to me.\n\nLest anyone should doubt that this wiki approach can scale,\nyes, there are considerable risks\n(cf http://c2.com/cgi-bin/wiki?CommunityLifeCycle)\nbut it can also work amazingly well\n(cf http://www.wikipedia.org/). My position is: if\nthe world wants a good OWL FAQ, the Wiki is the\nbest available mechanism to create and maintain it;\nif the world doesn't want a good OWL FAQ, no centralized\nwriting effort is very likely to change that.\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n----- End forwarded message -----\n\n\n\n"
        },
        {
            "subject": "Re: fwd: FAQs, best practices, ESW Wik",
            "content": "On the matter of control...\n\nI thought that one of the features of a wiki system is that it's backed by \nCVS, so that if someone comes along and defaces the site, or makes other \nundesirable modifications, there's an opportunity to back out the \nchanges.  Selectively.  Isn't that enough?\n\n#g\n--\n\nAt 16:34 17/09/03 -0400, Dan Brickley wrote:\n\n>Nice work from Dan Connolly... (from the WebOnt WG list)\n>\n>----- Forwarded message from Dan Connolly <connolly@w3.org> -----\n>\n>From: Dan Connolly <connolly@w3.org>\n>Date: Wed, 17 Sep 2003 15:29:45 -0500\n>To: www-webont-wg@w3.org\n>Subject: FAQs, best practices, ESW Wiki\n>Message-Id: <1063830584.5534.492.camel@dirk.dm93.org>\n>Resent-From: www-webont-wg@w3.org\n>Resent-Date: Wed, 17 Sep 2003 16:29:50 -0400 (EDT)\n>Organization: World Wide Web Consortium (http://www.w3.org/)\n>\n>\n>Regarding...\n>\n>\"ACTION DanC: Propose Wiki be used for FAQ\"\n>  -- minutes 11Sep\n>   http://lists.w3.org/Archives/Public/www-webont-wg/2003Sep/0163.html\n>\n>The subject of a FAQ list, best practice guides, and cookbooks\n>have come up in this WG a few times.\n>It also came up in the DAML joint-committee\n>\n>I'm sure everybody agrees that We Should have one of these;\n>it's a question of how, when, who, and the like.\n>\n>The FAQ that went out with the OWL CR was written by Jim...\n>   http://www.w3.org/2003/08/owlfaq\n>   http://www.w3.org/2003/08/owlfaq.html\n>   http://www.w3.org/2003/08/owlfaq.html.fr\n>\n>and edited by Janet and a few others in the W3C team.\n>\n>But that sort of W3C communications team resource isn't\n>available on an ongoing basis, and I don't think Jim\n>is volunteering to do it regularly.\n>\n>The best mechanism I've seen for documenting community\n>wisdom in a scalable way is WikiWikiWeb. The European\n>Commission funded some semantic web outreach work,\n>and we used some of that funding to set up a wiki...\n>\n>   \"ESW can stand for Evolving, European, Experimental,\n>   Extended, Enthusiastic, ... Semantic Web, reflecting its\n>   origins in the SWAD-Europe project, and affiliation with\n>   the wider RDF / Semantic Web Interest Group.\"\n>     -- http://esw.w3.org/topic/FrontPage\n>\n>I'll let it explain itself a bit more...\n>\n>[[[\n>This is a WikiWikiWeb, a collaborative hypertext environment, with an\n>emphasis on easy access to and modification of information. It is\n>something of an experiment in WikiConsensus. In some ways the open\n>nature of a Wiki is not that different from W3C's open, archived mailing\n>lists. In other ways it is rather different (see BeesAndAnts), and\n>perhaps more supportive of coming to consensus.\n>\n>You can edit any page by following the link at the bottom of the page.\n>Capitalized words joined together form a WikiName, which hyperlinks to\n>another page. The highlighted title searches for all pages that link to\n>the current page. Pages which do not yet exist are linked with a\n>question mark: just follow the link and you can create a suitable page.\n>\n>This wiki is particularly focussed on the SemanticWeb, but any W3C work\n>areas are on-topic here. There are lots of other wikis (see InterWiki)\n>which may be more appropriate for some subjects.\n>\n>It is good to speak in the community voice, at least when you have some\n>idea how the community might think about a subject. It's nice to log in\n>using UserPreferences, so people can see who made which changes. Browse\n>this wiki and others to get an example of style and etiquette.\n>]]]\n>\n>Last week DebM pointed us to a sort of cookbook entry...\n>\n>   Working with a closed world assumption in OWL/DAML+OIL\n>http://www.ksl.stanford.edu/people/dlm/webont/HowToDoIt/closingRoles.html\n>\n>So I took that and integrated it into the ESW Wiki by\n>creating a ClosedWorldAssumptions topic linked\n>from SemanticWebArchitecture, and then giving ClosingRoles\n>as an example of how to approximate support for\n>CloseWorldAssumptions.\n>\n>I'm not quite sure I understood the closingRoles.html document.\n>And the topic has already grown a disagreeing annotation.\n>But I trust it will evolve to reflect community wisdom\n>in due course.\n>\n>I hope to try out a couple more topics presently...\n>\n>   a recipie for ont:UnambiguousProperty, rdfs:isDefinedBy\n>   From: Dan Connolly (connolly@w3.org)\n>   Date: 05/16/01\n>   http://www.daml.org/listarchive/joint-committee/0418.html\n>and\n>   http://www.daml.org/listarchive/joint-committee/0419.html\n>\n>I think the potential for synergy between OWL FAQs, RDF\n>FAQs, URI FAQs, and XML FAQs is considerable. I had a good\n>time moving a centrally-maintained list into the UriSchemes\n>topic, and the synergy with topics like FollowYourNose\n>is already apparent.\n>\n>Jim writes...\n>\n>[[[\n>I have thought about this a while, I worry about a WIKI approach\n>- we want to control some of this -- I think a WIKI page for users to\n>be able to write/comment that is linked to a page maintained\n>somewhere in W3C space makes much more sense.  I propose we consider\n>starting this page as a WG, putting an \"expiration date\" on it equal\n>to end of our WG (i.e. no commmitment beyond our chartered date) --\n>we would then have an expectation that the new SWIG (if approved)\n>would take this over, but we would have no commitment if they don't.\n>]]]\n>\n>I don't want any more control than the Wiki gives me.\n>\n>Other folks in the WG could maintain pages in the\n>http://www.w3.org/* space, as Mike does with\n>the issues list and Jos and Jeremy do with the\n>test materials. There's a certain level of tedium\n>involved, but I suppose it might be tolerable.\n>I have considered doing that, and the cost of\n>having all edits funnelled thru one person\n>(or a few people) doesn't look worthwhile to me.\n>\n>Lest anyone should doubt that this wiki approach can scale,\n>yes, there are considerable risks\n>(cf http://c2.com/cgi-bin/wiki?CommunityLifeCycle)\n>but it can also work amazingly well\n>(cf http://www.wikipedia.org/). My position is: if\n>the world wants a good OWL FAQ, the Wiki is the\n>best available mechanism to create and maintain it;\n>if the world doesn't want a good OWL FAQ, no centralized\n>writing effort is very likely to change that.\n>\n>--\n>Dan Connolly, W3C http://www.w3.org/People/Connolly/\n>\n>\n>----- End forwarded message -----\n\n------------\nGraham Klyne\nGK@NineByNine.org\n\n\n\n"
        },
        {
            "subject": "Re: Last call for comments : 8.",
            "content": "[going to public list, to be linkable]\n\nThese comments I made last week I forgot to forward, still apply to the latest draft\n\n  http://www.w3c.rl.ac.uk/SWAD/thesaurus/tif/deliv81/final.html\n\nSorry for not forwarding till now.\n\nDave\n\n---\n\n    Figure 1\n\nmissing definition of is-indicated-by* - no footnote given for *\n\n\n    Term-Oriented Model\n\n    In a term-oriented model, although it may be tacitly implied that a\n    set of terms stands for some abstract concept, the concept is not\n    reified in the model. Terms which are preferred terms are used as the\n    nodes in the generalisation hierarchy. In this model it is usual to\n    distinbuish between the class of objects that are preferred terms and\n\ndistinguish^\n\n    the class of objects that are non-preferred terms. This model is\n    illustrated in figure [???].\n\nmissing figure number 2\n\n    Summary of the TIF RDF Schema\n\n    Figure 3\n\nThesaurus class isn't related to anything else?\n\n\n    Scope-Note (rdf:ID=\"ScopeNote\")\n\n      Defines a comment on a concept, prescribing the bounds of appropriate\n      usage of the concept. Sub-classes of this class are used to describe\n      specific types of comment. A General-Note refers to [???]. A\n      History-Note refers to [???]. A Hierarchy-Note refers to [???]. A\n      Translation-Note refers to [???]. An Editor-Note refers to [???].\n\nreferences missing\n\n    Properties\n\n    The domain/range values for the properties of the TIF schema are\n    illustrated in figure [???] and also in table 1.\n\nfigure 4\n\n    Figure 4\n\nrather wide figure - 1146x158\n\n\nhas-classification-code (rdf:ID=\"code\")\n    Defines a unique [???] identifier for a Concept.\n\n? is this a reference or just being unsure?\n\nis-defined-by (rdf:ID=\"isDefinedBy\")\n    Relates a Concept to the Thesaurus it is a part of. [Use\n    rdfs:isDefinedBy ???] \n\nIt could be used but rdfs:isDefinedBy remains vague\n\n\n    Language Identifiers\n\n    The Language class and identifiers for all languages defined by\n    ISO639-1 are supplied in a separate file (see Appendix [???]).\n\nAppendix V\n\n    Summary of TIFS RDF Schema\n\n    \"...and UF (use-for)....\"\n\nnever mentioned till now\n\n    Classes\n\n    \"...absence or presence of the use property...\"\n\nuse-for ?\n\nLater I see use/use-for are an inverse pair of properties relating\npreferred to/from non-preferred terms\n\n    Deriving TIFS from TIF\n\nwhat is ^<sup>-1</sup> terminology?  inverse relationship?\n\n\n    RDF Schema or OWL Ontology\n\n\n    in appendices [???]. [should the ontology extend descriptions for\n    the same resources as the schema, or use different ones???].\n\nappendices II (RDFS) III (TIF OWL), IV (TIFS OWL)\n\nBetter say which OWL - OWL DL, OWL Full, OWL Lite\n\n\n    Example: ELSST, a Multilingual Thesaurus\n\nRefers to March 2002 as a future date - this reads as out of date.\n\n\n    Conclusions and Future Work\n\n    The TIF is built as an extensible framework of classes and\n    properties. In this way it may be extended to express other kinds\n    of semantic relationship between concepts or terms. For example,\n    we could introduce ACK /AF relations between terms for\n    abbreviations and acronyms, such as in the DAML+OIL ontology from\n    DRC, ..\n\nreference and citation needed\n\n    ...  or we could express the diagonal relationships\n    related-broader-concept and related-narrower-concept, such as in\n    the ETB thesaurus schema. ...\n\nditto\n\n    ...  We could also model categories, as are\n    found in many thesaurus, as a sub-class of concepts or terms, and\n    the semantically more precise relationships that go with them.\n\n\n    Appendices\n\nLinks to the RDF/S and OWL files would be good.\n\nWhich OWL version (date) are these?\n\nThere are problems with # and rdf:ID in these docs.\n\n<!ENTITY tif \"http://www.w3c.rl.ac.uk/2003/07/31-tif-owl#\" >\nxmlns:tif=\"&tif;\"\nxml:base=\"&tif;\" \n\nand later:\n    rdf:ID=\"Thesaurus\"\n\nwhich will give a URI http://www.w3c.rl.ac.uk/2003/07/31-tif-owl##Thesaurus\n\nCorrect:\n<!ENTITY tif \"http://www.w3c.rl.ac.uk/2003/07/31-tif-owl\" >\nxmlns:tif=\"&tif;#\"\nxml:base=\"&tif;\" \n\n\n\n"
        },
        {
            "subject": "Re: fwd: FAQs, best practices, ESW Wik",
            "content": "On Thu, 2003-09-18 at 05:42, Graham Klyne wrote:\n> On the matter of control...\n> \n> I thought that one of the features of a wiki system is that it's backed by \n> CVS, so that if someone comes along and defaces the site, or makes other \n> undesirable modifications, there's an opportunity to back out the \n> changes.  Selectively.  Isn't that enough?\n\nIt's enough to prevent things from being lost forever,\nbut the work of doing the restoration (and noticing\nthat it needs doing) remains.\n\nThe good news is: it allows *anybody* to do that\nrestoration, not just a select few overworked\neditors or administrators.\n\nThe other good news is: once the community has\na certain critical mass, the opportunity/obligation\nto edit things that one disagrees with can turn\ninto endorsement of pages that are not edited.\n(cf http://esw.w3.org/topic/WikiConsensus)\n\n(Note that the revision control behind the ESW\nwiki is a combination of MoinMoin's built-in\nfile-based history, which the general public\nhas access to, and a separate cron job\nthat periodically copies stuff into W3C's CVS\nrepository for more stable backup.)\n\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n"
        },
        {
            "subject": "Drdfat details for SWADE Semantic Storage and Retrieval Workshop            Amsterdam, Nov 13/1",
            "content": "I've been editing at\n  http://www.w3.org/2001/sw/Europe/events/20031113-storage/\nfor this workshop taking place on Nov 13/14 in Amsterdam (hosted by VU). \n\nThis is not an announcement since there are some bits yet to update; but\nI'd appreciate some feedback before I pass this on.\n\nCheers\n\nDave\n\n\n\n"
        },
        {
            "subject": "SWADE March newsletter availabl",
            "content": "http://lists.w3.org/Archives/Public/public-esw-news/2004AprJun/0000.html\n\nThanks everyone who contributed.\n\nLibby\n\n\n\n"
        },
        {
            "subject": "multilingual vocab  japanese example",
            "content": "http://www.w3.org/2001/sw/Europe/200404/i18n/jptofu-example1.xml\nhttp://rdfig.xmlhack.com/2004/04/13/2004-04-13.html#1081849465.502453\n\nQuick hi from Japan. When I'm back I'd like to revisit Euro-wordnet in\ncontext of this, SKOS, wordnet-in-rdf etc. Basically it is a quick\nexample that tries a few things:\n\nJapanese Kanjii characters for element names (map to RDF classes, \neither subclassing or sameAs classes from English-named vocab, or \ndirectly from a Japanese dictionary as we did with the xmlns.com version \nof wordnet in RDF. Also used kanjii for property names, and in URIs \n(ie. IRIs).\n\nWe tried to come up with some examples of concepts which might be \ntreated in more detail in Japanese than in English. This links to \nconcerns in a European context for multilinugual vocabularies, \nthesauri and (eg. wordnet -> eurowordnet) electronic dictionaries.\n\nI'm looking for more examples, especially for terms that denote classes\nof things, where those classes are associated with words in only some\nlanguages. Suggestions/pointers welcomed.\n\ncheers,\n\nDan\n\n\n\n"
        },
        {
            "subject": "SWADEurope and the ECOinformatics Initiativ",
            "content": "Hi all,\n\nI attended a workshop this week on Environmental Thesauri and Terminologies,\nand presented some work from the SWAD-Europe Thesaurus Activity.\n\nA write-up of the event by me is here:\n\nhttp://esw.w3.org/mt/esw/archives/000052.html\n\nAl.  \n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: SWADEurope and the ECOinformatics Initiativ",
            "content": "Alistair\n\nCool report, to which I subscribe entirely :)\n\nSuppose it would be a good idea to report also to SWBP WG ...\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n> -----Message d'origine-----\n> De : public-esw-request@w3.org [mailto:public-esw-request@w3.org]De la\n> part de Miles, AJ (Alistair)\n> Envoy? : vendredi 16 avril 2004 15:05\n> ? : 'public-esw@w3.org'; 'public-esw-thes@w3.org'\n> Objet : SWAD-Europe and the ECOinformatics Initiative\n>\n>\n>\n> Hi all,\n>\n> I attended a workshop this week on Environmental Thesauri and Terminologies,\n> and presented some work from the SWAD-Europe Thesaurus Activity.\n>\n> A write-up of the event by me is here:\n>\n> http://esw.w3.org/mt/esw/archives/000052.html\n>\n> Al.\n>\n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n>\n>\n\n\n\n"
        },
        {
            "subject": "URIs for Concepts: Best Practice",
            "content": "Hi all,\n\nI wanted to consult you all on this matter.  I have agreement from the EEA\nto publish the GEMET environmental thesaurus in the SKOS/RDF format.  The\nnext step is to work out with them the URIs they wish to assign to their\nthesaurus and concepts.  I'm not sure what to recommend to them on this\nmatter.  \n\nI thought to use an http:// based URI base (e.g.\nhttp://www.eionet.eu.int/GEMET) and then add the id number of each concept\n(e.g. http://www.eionet.eu.int/GEMET#204).   \n\nA first question is, is it OK to use http: URIs for concepts?  Sorry to drag\nthis old chestnut up again, but I need some clear answer on best practices\nfor this.  Are we not at all concerned that the same URI may identify both a\nthesaurus concept and a resolveable network resource (i.e. the file\ncontaining the RDF data)?\n\nWhat do you think of info: based URIs for concepts?\n\nHope to hear from you on this,\n\nAl.\n\n\n\n\n\n  \n\n\n \n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "Hi Al,\n\nI like the approach that is outlined by the OASIS Published Subjects TC\n[1]. Although this document is a draft and omits some pieces that I\nwould like to see, I feel that the general approach is a good one. To\nsummarise, an HTTP identifier, when used to identify a concept *should*\nresolve to a human-readable resource that describes the concept. Despite\ncoming from the topic maps community, I feel that this approach is\napplicable to the creation of any identifier scheme that uses HTTP for\nnamespacing.\n\nThe things that I would like to see the TC consider is recommendations\nfor either embedding, linking to (e.g. using RDDL) or providing as\nparallel resource (via content negotiation), other machine-readable\ndescriptions of the concept and related resource - so an RDF resource\nwould be one example, the same information translated into XTM might be\nanother and so on.\n\nIt would be good to get the Published Subjects work kick started again\n(the committee went quiet a long time ago) - perhaps we could work on\nputting together a technical report to pass either to the OASIS TC or\njust to publish as part of the SWAD work ?\n\nCheers,\n\nKal\n\n[1]\nhttp://www.oasis-open.org/committees/download.php/3050/pubsubj-pt1-1.02-cs.pdf\n\nOn Mon, 2004-04-19 at 18:48, Miles, AJ (Alistair) wrote:\n> Hi all,\n> \n> I wanted to consult you all on this matter.  I have agreement from the EEA\n> to publish the GEMET environmental thesaurus in the SKOS/RDF format.  The\n> next step is to work out with them the URIs they wish to assign to their\n> thesaurus and concepts.  I'm not sure what to recommend to them on this\n> matter.  \n> \n> I thought to use an http:// based URI base (e.g.\n> http://www.eionet.eu.int/GEMET) and then add the id number of each concept\n> (e.g. http://www.eionet.eu.int/GEMET#204).   \n> \n> A first question is, is it OK to use http: URIs for concepts?  Sorry to drag\n> this old chestnut up again, but I need some clear answer on best practices\n> for this.  Are we not at all concerned that the same URI may identify both a\n> thesaurus concept and a resolveable network resource (i.e. the file\n> containing the RDF data)?\n> \n> What do you think of info: based URIs for concepts?\n> \n> Hope to hear from you on this,\n> \n> Al.\n> \n> \n> \n> \n> \n>   \n> \n> \n>  \n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n-- \nKal Ahmed <kal@techquila.com>\ntechquila\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "Miles, AJ (Alistair)  writes:\n\n> I wanted to consult you all on this matter.  I have agreement from\n> the EEA to publish the GEMET environmental thesaurus in the SKOS/RDF\n> format.  The next step is to work out with them the URIs they wish to\n> assign to their thesaurus and concepts.  I'm not sure what to\n> recommend to them on this matter.\n\nDan Brickley's Wordnet vocabulary service[1] at xmlns.com seems like a\nuseful model. Essentially, each concept is given a (non-fragmentary) URI\nwhich, if dereferenced, returns a description of the concept. Mr\nBrickley's system only returns RDF/XML presently, but there's no reason\nit couldn't also return HTML or something else via content negotiation.\n\n[1] http://xmlns.com/2001/08/wordnet/\n\n> I thought to use an http:// based URI base (e.g.\n> http://www.eionet.eu.int/GEMET) and then add the id number of each\n> concept (e.g. http://www.eionet.eu.int/GEMET#204).\n\nThat works, but my preference would be for something like\n<http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID means\nthat an HTTP request to a term's URI will return nothing or else a\ndescription of the entire vocabulary, which I'm guessing is pretty\nlarge.\n\n> A first question is, is it OK to use http: URIs for concepts?  Sorry\n> to drag this old chestnut up again, but I need some clear answer on\n> best practices for this.  Are we not at all concerned that the same\n> URI may identify both a thesaurus concept and a resolveable network\n> resource (i.e. the file containing the RDF data)?\n\nIt would be confusing for a URI to identify a thesaurus concept and an\nRDF file. The key, as I see it, is the idea that the response to an HTTP\nGet is a representation of the resource, not the resource itself. The\nfact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML\ndocument, doesn't mean that it identifies that particular document. If,\nfor some reason, you wanted to talk about that RDF/XML document instead\nof the word \"Dog\", you would need to use a blank node or a different\nURI.\n\nNot everyone agrees with this position.\n\n> What do you think of info: based URIs for concepts?\n\n>From an RDF perspective, it's just as good. From a web perspective, it's\nless useful because it can't be dereferenced.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n> Miles, AJ (Alistair)  writes:\n> \n> > I wanted to consult you all on this matter.  I have agreement from\n> > the EEA to publish the GEMET environmental thesaurus in the SKOS/RDF\n> > format.  The next step is to work out with them the URIs they wish to\n> > assign to their thesaurus and concepts.  I'm not sure what to\n> > recommend to them on this matter.\n> \n> Dan Brickley's Wordnet vocabulary service[1] at xmlns.com seems like a\n> useful model. Essentially, each concept is given a (non-fragmentary) URI\n> which, if dereferenced, returns a description of the concept. Mr\n> Brickley's system only returns RDF/XML presently, but there's no reason\n> it couldn't also return HTML or something else via content negotiation.\n> \n> [1] http://xmlns.com/2001/08/wordnet/\n> \n> > I thought to use an http:// based URI base (e.g.\n> > http://www.eionet.eu.int/GEMET) and then add the id number of each\n> > concept (e.g. http://www.eionet.eu.int/GEMET#204).\n> \n> That works, but my preference would be for something like\n> <http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID means\n> that an HTTP request to a term's URI will return nothing or else a\n> description of the entire vocabulary, which I'm guessing is pretty\n> large.\n> \nI think that this practice would certainly work much better with\nPSI/PSID constructs than the fragmentary approach - one resource per\nconcept is probably a best practice that the Published Subjects TC\nshould recommend.\n\n> > A first question is, is it OK to use http: URIs for concepts?  Sorry\n> > to drag this old chestnut up again, but I need some clear answer on\n> > best practices for this.  Are we not at all concerned that the same\n> > URI may identify both a thesaurus concept and a resolveable network\n> > resource (i.e. the file containing the RDF data)?\n> \n> It would be confusing for a URI to identify a thesaurus concept and an\n> RDF file. The key, as I see it, is the idea that the response to an HTTP\n> Get is a representation of the resource, not the resource itself. The\n> fact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML\n> document, doesn't mean that it identifies that particular document. If,\n> for some reason, you wanted to talk about that RDF/XML document instead\n> of the word \"Dog\", you would need to use a blank node or a different\n> URI.\n> \nIt is certainly true that content negotiation gives you the problem of\ntalking about the descriptive resource as opposed to the described\nthing. That is a strong argument against content negotiation for RDF /\nXTM resources. However, there are still two other options:\n\n1) Embed the RDF / TM markup in its XML form. Then use an rdf:ID\nattribute or XTM id attribute so that the reference to the RDF/XTM would\nbe <http://xmlns.com/wordnet/1.6/Dog#foo>\n\n2) Use a profile of XLink to link to the RDF / TM resource that\ndescribes the concept, and make it completely separate. e.g.\n<http://xmlns.com/wordnet/1.6/Dog/dog.rdf>\n\n> Not everyone agrees with this position.\n> \nI don't think that a position can ever be established which everyone \nwill agree with :-)\n\n> > What do you think of info: based URIs for concepts?\n> \n> >From an RDF perspective, it's just as good. From a web perspective, it's\n> less useful because it can't be dereferenced.\n\nI tend to agree. I tend to consider the use of URIs for subject\nidentification as being divided into three categories:\n1) The URI resolves to the subject being described\n2) The URI resolves to a description of the subject being described\n3) The URI is used as a pure, unresolvable identifier\n\nI think (2) gives the greatest possibility for interchange of semantics\nif the resource addressed by the URI is human-readable - at some point\nthe processing of semantics has to be transferred from SW machinery to\nwet-ware.\n\nCheers,\n\nKal\n-- \nKal Ahmed <kal@techquila.com>\ntechquila\n\n\n\n"
        },
        {
            "subject": "AW: URIs for Concepts: Best Practice",
            "content": "This discussion is coming up from time to time. Its also called\n\"Identity crisis\" or \"Uri crisis\"\n\nSome interesting articles are:\n-rfc2396 (uri)\n- http://www.w3.org/2002/11/dbooth-names/dbooth-names_clean.htm \n- http://www.xml.com/pub/a/2002/09/11/deviant.html\n- http://www.w3.org/DesignIssues/HTTP-URI \n\nMy opinion is to use Http URIs because:\n- they are unique\n- you can optionally put some content at the place the uri identifies\n(be it RDF or HTML)\n\nanother guy behind this approach is Patrick Stickler and his URIQA.\n\nA good concept to think about when using Uris to identify more than one\nthing is to \"Seperate by Ontology\"\n\nYou can use a single resource uri and annotate it with different\ntriples, when you want to describe the \"Web resource\" aspect of the uri,\nuse a web ontology, when you want to describethe \"dog-concept\" aspect,\nuse the dog/concept ontology. They won't mix up, namespaces do the\nseperation. And a single resource can have more than one type. voila.\n\nAd1: Don't use HASH identifiers if you can avoid them!\nhttp://test/doh#hello\nmay come to your web server as:\nhttp://test/doh\n--> whoops.\n\ngreetings\nLeo Sauermann\n\n\n\n> -----Urspr?ngliche Nachricht-----\n> Von: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] Im Auftrag von Kal Ahmed\n> Gesendet: Dienstag, 20. April 2004 09:19\n> An: David Menendez\n> Cc: Miles, AJ (Alistair); 'public-esw-thes@w3.org'; \n> 'public-esw@w3.org'\n> Betreff: Re: URIs for Concepts: Best Practices\n> \n> \n> \n> On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n> > Miles, AJ (Alistair)  writes:\n> > \n> > > I wanted to consult you all on this matter.  I have \n> agreement from \n> > > the EEA to publish the GEMET environmental thesaurus in \n> the SKOS/RDF \n> > > format.  The next step is to work out with them the URIs \n> they wish \n> > > to assign to their thesaurus and concepts.  I'm not sure what to \n> > > recommend to them on this matter.\n> > \n> > Dan Brickley's Wordnet vocabulary service[1] at xmlns.com \n> seems like a \n> > useful model. Essentially, each concept is given a \n> (non-fragmentary) \n> > URI which, if dereferenced, returns a description of the \n> concept. Mr \n> > Brickley's system only returns RDF/XML presently, but there's no \n> > reason it couldn't also return HTML or something else via content \n> > negotiation.\n> > \n> > [1] http://xmlns.com/2001/08/wordnet/\n> > \n> > > I thought to use an http:// based URI base (e.g.\n> > > http://www.eionet.eu.int/GEMET) and then add the id \n> number of each \n> > > concept (e.g. http://www.eionet.eu.int/GEMET#204).\n> > \n> > That works, but my preference would be for something like \n> > <http://eionet.eu.int/GEMET/204>. In practice, using a fragment ID \n> > means that an HTTP request to a term's URI will return \n> nothing or else \n> > a description of the entire vocabulary, which I'm guessing \n> is pretty \n> > large.\n> > \n> I think that this practice would certainly work much better \n> with PSI/PSID constructs than the fragmentary approach - one \n> resource per concept is probably a best practice that the \n> Published Subjects TC should recommend.\n> \n> > > A first question is, is it OK to use http: URIs for \n> concepts?  Sorry \n> > > to drag this old chestnut up again, but I need some clear \n> answer on \n> > > best practices for this.  Are we not at all concerned \n> that the same \n> > > URI may identify both a thesaurus concept and a \n> resolveable network \n> > > resource (i.e. the file containing the RDF data)?\n> > \n> > It would be confusing for a URI to identify a thesaurus \n> concept and an \n> > RDF file. The key, as I see it, is the idea that the response to an \n> > HTTP Get is a representation of the resource, not the \n> resource itself. \n> > The fact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML \n> > document, doesn't mean that it identifies that particular document. \n> > If, for some reason, you wanted to talk about that RDF/XML document \n> > instead of the word \"Dog\", you would need to use a blank node or a \n> > different URI.\n> > \n> It is certainly true that content negotiation gives you the \n> problem of talking about the descriptive resource as opposed \n> to the described thing. That is a strong argument against \n> content negotiation for RDF / XTM resources. However, there \n> are still two other options:\n> \n> 1) Embed the RDF / TM markup in its XML form. Then use an \n> rdf:ID attribute or XTM id attribute so that the reference to the\nRDF/XTM would be > <http://xmlns.com/wordnet/1.6/Dog#foo>\n> \n> 2) Use a profile of \n> XLink to link to the RDF / TM resource that describes the \n> concept, and make it completely separate. e.g. \n<http://xmlns.com/wordnet/1.6/Dog/dog.rdf>\n\n> Not everyone agrees with this position.\n> \nI don't think that a position can ever be established which everyone \nwill agree with :-)\n\n> > What do you think of info: based URIs for concepts?\n> \n> >From an RDF perspective, it's just as good. From a web perspective, \n> >it's\n> less useful because it can't be dereferenced.\n\nI tend to agree. I tend to consider the use of URIs for subject\nidentification as being divided into three categories:\n1) The URI resolves to the subject being described\n2) The URI resolves to a description of the subject being described\n3) The URI is used as a pure, unresolvable identifier\n\nI think (2) gives the greatest possibility for interchange of semantics\nif the resource addressed by the URI is human-readable - at some point\nthe processing of semantics has to be transferred from SW machinery to\nwet-ware.\n\nCheers,\n\nKal\n-- \nKal Ahmed <kal@techquila.com>\ntechquila\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "On Mon, 19 Apr 2004, David Menendez wrote:\n\n> > A first question is, is it OK to use http: URIs for concepts?  Sorry\n> > to drag this old chestnut up again, but I need some clear answer on\n> > best practices for this.  Are we not at all concerned that the same\n> > URI may identify both a thesaurus concept and a resolveable network\n> > resource (i.e. the file containing the RDF data)?\n>\n> It would be confusing for a URI to identify a thesaurus concept and an\n> RDF file. The key, as I see it, is the idea that the response to an HTTP\n> Get is a representation of the resource, not the resource itself. The\n> fact that <http://xmlns.com/wordnet/1.6/Dog> returns an RDF/XML\n> document, doesn't mean that it identifies that particular document.\n\nThat's the REST point of view and it's reiterated in the recent TAG\npublication.\n\n> If,\n> for some reason, you wanted to talk about that RDF/XML document instead\n> of the word \"Dog\", you would need to use a blank node or a different\n> URI.\n\nYes; there's no generally applicable vocab currently (as far as I'm\naware) in RDF to describe the relationship between a URI (as a web\naddress rather than a resource identifier, so probably in the format of\na datatyped literal) and stuff you get when dereferencing that URI,\nincluding specific content-negotiated HTTP conversations. But there's no\nreason why there shouldn't be, and it'd let you explicitly avoid\nconfusions like \"Ora Lassila's size in bytes\".\n\n> Not everyone agrees with this position.\n\nIncluding, I'm led to believe, some members of TAG.\n\n\n\n-- \njan grant, ILRT, University of Bristol. http://www.ilrt.bris.ac.uk/\nTel +44(0)117 9287088 Fax +44 (0)117 9287112 http://ioctl.org/jan/\n\"Sufficiently large\"=\"infinite\" for sufficiently large values of \"sufficiently\"\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "Kal Ahmed writes:\n\n> On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n> > \n> > It would be confusing for a URI to identify a thesaurus concept and\n> > an RDF file. The key, as I see it, is the idea that the response to\n> > an HTTP Get is a representation of the resource, not the resource\n> > itself. The fact that <http://xmlns.com/wordnet/1.6/Dog> returns an\n> > RDF/XML document, doesn't mean that it identifies that particular\n> > document. If, for some reason, you wanted to talk about that\n> > RDF/XML document instead of the word \"Dog\", you would need to use a\n> > blank node or a different URI.\n> > \n> It is certainly true that content negotiation gives you the problem of\n> talking about the descriptive resource as opposed to the described\n> thing. That is a strong argument against content negotiation for RDF /\n> XTM resources.\n\nI've always felt content negotiation was more of an opportunity than a\nproblem. :-)\n\nIf I'm reading you right, in the case of\n<http://xmlns.com/wordnet/1.6/Dog>, the \"described thing\" is the class\n\"Dog\", and the \"descriptive resource\" is the RDF/XML document returned\nif you do an HTTP Get.\n\nThe REST view, as I understand it, is that the URI denotes the class\n\"Dog\". Since you can't actually transmit a class over the internet, any\nattempt to GET that URI will result in (1) a 404 or similar error, or\n(2) a representation of the class \"Dog\", which could be one of many\npossible electronic documents which is selected according to\nnegotiation. All of these representations are themselves distinct\nresources, even if they have no explicit URI (that is, they are blank\nnodes). Some versions of HTTP include a Content-Location header, which\ngives a URI for the particular representation being returned.\n\nIn that case, I would actually recommend content negotiation for RDF\nterms. If I put <http://xmlns.com/wordnet/1.6/Dog> into my web browser,\nI'd rather get a human-readable HTML document than a bunch of RDF. If my\nRDF software GETs the same URI, it should get an RDF document.\n\nIn both of those cases, the goal is to find information about the class\n\"Dog\". We don't care as much (or at all) about the representation which\nconveys that information.\n\n> > Not everyone agrees with this position.\n> > \n> I don't think that a position can ever be established which everyone \n> will agree with :-)\n\nI think we'd all agree to that. :-)\n-- \nDavid Menendez <zednenem@psualum.com> | \"In this house, we obey the laws\n<http://www.eyrie.org/~zednenem>      |        of thermodynamics!\"\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "David Menendez wrote:\n\n>Kal Ahmed writes:\n>\n>  \n>\n>>On Mon, 2004-04-19 at 22:22, David Menendez wrote:\n>>    \n>>\n>>>It would be confusing for a URI to identify a thesaurus concept and\n>>>an RDF file. The key, as I see it, is the idea that the response to\n>>>an HTTP Get is a representation of the resource, not the resource\n>>>itself. The fact that <http://xmlns.com/wordnet/1.6/Dog> returns an\n>>>RDF/XML document, doesn't mean that it identifies that particular\n>>>document. If, for some reason, you wanted to talk about that\n>>>RDF/XML document instead of the word \"Dog\", you would need to use a\n>>>blank node or a different URI.\n>>>\n>>>      \n>>>\n>>It is certainly true that content negotiation gives you the problem of\n>>talking about the descriptive resource as opposed to the described\n>>thing. That is a strong argument against content negotiation for RDF /\n>>XTM resources.\n>>    \n>>\n>\n>I've always felt content negotiation was more of an opportunity than a\n>problem. :-)\n>\n>If I'm reading you right, in the case of\n><http://xmlns.com/wordnet/1.6/Dog>, the \"described thing\" is the class\n>\"Dog\", and the \"descriptive resource\" is the RDF/XML document returned\n>if you do an HTTP Get.\n>  \n>\nI would prefer to say that the described thing is the abstract concept \nof Dog (Dog-ness ?) because the word \"class\" can be misinterpreted as \nmeaning the OWL class Dog, for example. But I think you understood me \ncorrectly.\n\n>The REST view, as I understand it, is that the URI denotes the class\n>\"Dog\". Since you can't actually transmit a class over the internet, any\n>attempt to GET that URI will result in (1) a 404 or similar error, or\n>(2) a representation of the class \"Dog\", which could be one of many\n>possible electronic documents which is selected according to\n>negotiation. All of these representations are themselves distinct\n>resources, even if they have no explicit URI (that is, they are blank\n>nodes). Some versions of HTTP include a Content-Location header, which\n>gives a URI for the particular representation being returned.\n>\n>In that case, I would actually recommend content negotiation for RDF\n>terms. If I put <http://xmlns.com/wordnet/1.6/Dog> into my web browser,\n>I'd rather get a human-readable HTML document than a bunch of RDF. If my\n>RDF software GETs the same URI, it should get an RDF document.\n>\n>In both of those cases, the goal is to find information about the class\n>\"Dog\". We don't care as much (or at all) about the representation which\n>conveys that information.\n>  \n>\nIn principal I agree with you that this would be a good way to go, and \nit fits nicely with a RESTful view of the world and I think it fits well \nwith the distinction between resource and representation. However, I \nstruggle with how to annotate the RDF/XML resource - how do I say that \nthe author of this resource was John Smith ? In this case I am not \ninterested in finding out more about Dog-ness, but I want to know more \nabout this RDF description of Dog-ness - perhaps to establish whether or \nnot I trust the source of information.\n\nWhile writing this, a lightbulb went on and I think I now understand \nsomething I had missed in your previous posting.  In a prior email on \nthis thread, you suggested that a way to refer to a representation could be:\n\n[ a Representation\n  ; source <http://xmlns.com/wordnet/1.6/Dog>\n  ; date \"2004-04-23T01:28:00Z\"\n  ]\n\nSo I suggest that we might extend this model to include the \ncontent-negotiation parameters and then we can attach representation \nmetadata to the blank node.\n\nI need more coffee before I can write out the RDF/XML syntax for this, \nbut hopefully you can see what I'm getting at enough to tell me if we \nare on the same page or if I misunderstood.\n\nCheers,\n\nKal\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "As I don't have all the RDF/OWL etc. syntax rules at my fingertips I \ncan't comment on that part of the discussion, but I'd just like to slip \nin a mention of a long-standing issue, clarification of which might help \nunderstanding.\n\nWhen we are talking about a class or category of entities, such as \n\"dogs\", it is logical and clearer to use the plural form. Any definition \nor link is not to a specific dog, but to the attributes shared by all \nmembers of the class. A class may have sub-classes such as \"spaniels\" or \n\"poodles\", or specific instances such as \"Fido\", \"Rover\" or \"Laika\". It \nis important to be clear whether any URI is pointing to a category or to \na specific instance.\n\nThe convention of using the plural only applies to \"count-nouns\", to \nwhich the question \"how many\" is applicable. \"Non-count-nouns\", to which \n\"how much\" applies, like \"water\" or \"love\", are naturally expressed in \nthe singular form.\n\nLeonard Will\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: URIs for Concepts: Best Practice",
            "content": "At 10:08 23/04/04 +0100, Kal Ahmed wrote:\n>I would prefer to say that the described thing is the abstract concept of \n>Dog (Dog-ness ?) because the word \"class\" can be misinterpreted as meaning \n>the OWL class Dog, for example. But I think you understood me correctly.\n\n[ref. \"dog-ness\"...]\n\nI'm reminded of a piece by Quine [1] - his base example is \"rabbit\", and he \ncomes up with terms like \"rabbithood\" and \"rabbiteth\" to illustrate the \nlinguistic challenges of determining what is indicated.\n\n#g\n--\n\n[1] W. V. Quine, \"Speaking of Objects\", in \"Ontological Relativity and \nOther Essays\"\n\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "Image description workshop, Madrid 78 Jun",
            "content": "Hi folks,\n\nmore information will be forthcoming in the next couple of days, but there\nwill be a SWAD-Europe developers' workshop in Madrid (kindly hosted by\nUniversidad Politecnica de Madrid) on image description on the 7th and 8th of\nJune.\n\nThis workshop will be open to anyone interested in the topic, primarily\ntargeted at developers who are working on RDF-based systems, or users of such\nsystems, and aiming to look at the state of the art, in particular whether\nand how it has advanced since a similar-themed workshop in Bristol in\nmid-2002, and at useful strategies and avenues for further development, or\navenues which it seems should be investigated further.\n\nPlease watch this space for an announcement of a proper meeting page, agenda\ndetails, and so on, but feel free to pass on the news (or put the dates in\nyour own diary).\n\nCheers\n\nCharles McCathieNevile\n\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Announcement of SWADEurope SKOS API for thesauri web servic",
            "content": "   SWAD-Europe Simple Knowledge Organisation System (SKOS) API\n       Web Service API for a thesaurus service\n\n     http://www.w3.org/2001/sw/Europe/reports/thes/skosapi.html\n\nWe are pleased to announce the initial release of the SKOS API\ndeveloped by the SWAD-Europe[1] project thesaurus activity[2]\nan EU IST-7 funded project.\n\nThe SKOS API defines a web service providing a core set of methods\nfor accessing and querying a thesaurus or terminological resource\nbased on the SKOS-Core schema, as described in the SKOS-Core Guide[3].\n\nThis is an initial release which we expect will evolve in response to\ninput from the wider community.  Our goal is to contribute to the\ndevelopment of a web service API that will be suitable for widespread\nadoption, which in turn will promote ease of interoperability and\nre-use of information systems that exploit thesauri and/or other\nkinds of terminological resource.\n\nWe ask at this stage for initial feedback from web service\ndevelopers, systems designers and KOS experts looking to expose or\naccess this kind of functionality\n\nIn particular, we have the following open issues, in no particular\norder (some of these are from the 'scratch pad' ServiceBits class[4] )\n\n- How much information to return in Concept fields versus API calls.\n- In our implementation, should we use the SOAP encoding model or\n  literal RDF/XML (for example) to represent concepts and\n  relations. Or both.\n- Try to use xsd:anyURI instead of a separate URI class\n- Versioning of the interface, do we add a getVersion() method.\n- Should we provide access to RDF query support where available (like\nJoseki)\n- A REST API would be good to have especially as this is a\n  non-side effecting API, so HTTP GET operations would be safe.\n- Returning values as singletons compared to arrays of size 1\n- What fields of concepts should regexe searches match.\n- Method doubling for thesaurus parameters versus allowing Null values\n  (we are aware WS-I Basic Profile recommends against method\n  overloading, so we avoid that)\n\nA demonstration implementation of using this web service API is\ncurrently under development which will host several thesauri in the\nSKOS schema[5] and provide a public web service.\n\nPlease direct all feedback to the public mailing list:\npublic-esw-thes@w3.org list, more details are available at [6].\n\nAlistair Miles\nNikki Rogers\nDave Beckett\n\n\n[1] http://www.w3.org/2001/sw/Europe/\n[2] http://www.w3.org/2001/sw/Europe/reports/thes/\n[3] http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n[4] http://www.w3.org/2001/sw/Europe/reports/thes/api/docs/\n[5] http://www.w3.org/2004/02/skos/core\n[6] http://lists.w3.org/Archives/Public/public-esw-thes/\n\n\n\n"
        },
        {
            "subject": "URI policy for thesaurus concept",
            "content": "On the basis of the previous discussion on URIs for concepts, I'm going to\noffer the recommendation to thesaurus owners that they use http: based uris\nwithout fragment identifiers as URIs for their concepts.\n\nSo for example:\n\nGEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n\nGEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]   \n\nReason for going with http: based URIs is it seems generally agreed that it\nis desirable to have the concept URIs directly resolving to something.\n\nReason for going with / and not # is so that the concept ID is included in\nan http GET request and not lost as it would be if it came after a #.\n\nI.e. decision based on purely practical considerations.\n\nAnybody want to shoot this down before I approach GEMET (& others) with\nthis?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-04-30 16:08+0100]\n> \n> On the basis of the previous discussion on URIs for concepts, I'm going to\n> offer the recommendation to thesaurus owners that they use http: based uris\n> without fragment identifiers as URIs for their concepts.\n> \n> So for example:\n> \n> GEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n> \n> GEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]   \n> \n> Reason for going with http: based URIs is it seems generally agreed that it\n> is desirable to have the concept URIs directly resolving to something.\n> \n> Reason for going with / and not # is so that the concept ID is included in\n> an http GET request and not lost as it would be if it came after a #.\n> \n> I.e. decision based on purely practical considerations.\n> \n> Anybody want to shoot this down before I approach GEMET (& others) with\n> this?\n\nI prefer the / approach, but I should warn that TimBL and others have\nmade the claim that http://blah/ URIs without a # can only name\n'documents' or 'networked information resources', and that concepts,\nclasses, properties etc don't count as those.\n\nSo, if you do advice thesaurus folks one way or the other, try to make\nclear that this aspect of web architecture is still under discussion.\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "On Fri, 30 Apr 2004, Miles, AJ (Alistair)  wrote:\n\n> On the basis of the previous discussion on URIs for concepts, I'm going to\n> offer the recommendation to thesaurus owners that they use http: based uris\n> without fragment identifiers as URIs for their concepts.\n>\n> So for example:\n>\n> GEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n>\n> GEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]\n>\n> Reason for going with http: based URIs is it seems generally agreed that it\n> is desirable to have the concept URIs directly resolving to something.\n>\n> Reason for going with / and not # is so that the concept ID is included in\n> an http GET request and not lost as it would be if it came after a #.\n>\n> I.e. decision based on purely practical considerations.\n>\n> Anybody want to shoot this down before I approach GEMET (& others) with\n> this?\n\nPersonally I like this approach. The recent TAG document endorses a REST\nview; so basically you're saying that\n\nhttp://www.eionet.eu.int/GEMET/[version]\n\n\"names\" the thesaurus, and\n\nhttp://www.eionet.eu.int/GEMET/[version]/[conceptID]\n\n\"names\" the particular concept. That's fine - I ought to be able to ask\n(via content negotiation) for a representation of a concept (or a\nthesaurus) by an HTTP request for each of those URIs. What advice are\nyou offering on the stuff that's found at the end of those URIs?\n\nIt'd be reasonable to generate (for instance) RDF describing an\nindividual concept (that perhaps links it to related concepts) but it's\nnot immediately clear to me what content might live at the \"whole\nthesaurus\" URI. Perhaps the whole thesaurus? Or a document with RDDL\ncontent that points to related web services, etc..?\n\n\n\n\n-- \njan grant, ILRT, University of Bristol. http://www.ilrt.bris.ac.uk/\nTel +44(0)117 9287088 Fax +44 (0)117 9287112 http://ioctl.org/jan/\n( echo \"ouroboros\"; cat ) > /dev/fd/0 # it's like talking to yourself sometimes\n\n\n\n"
        },
        {
            "subject": "RE: URI policy for thesaurus concept",
            "content": "To go along with Dan ...\n\nI also prefer the / approach in principle because it defines more neatly the \"subject\nindicator\", but consider that e.g. OWL uses fragment identifiers to define classes and\nproperties ...\n\nWill not people be confused with OWL elements defined by\nhttp://example.org/myontology#class001\nand SKOS concepts defined by http://example.org/myskos/concept001\n\nWhat about namespace management?\n\nAnd having, e.g. for GEMET, over 8000 different resources/concepts, if you just want to\ndownload the whole stuff, hmm...\nIs not it more simple to have a / namespace for a whole SKOS scheme, and # for each\nconcept in it?\n\nWe've been through this in Published Subjects TC, without clear conclusion ...\n\nBernard Vatant\nSenior Consultant\nKnowledge Engineering\nMondeca - www.mondeca.com\nbernard.vatant@mondeca.com\n\n\n> -----Message d'origine-----\n> De : public-esw-request@w3.org [mailto:public-esw-request@w3.org]De la\n> part de Dan Brickley\n> Envoye : vendredi 30 avril 2004 17:19\n> A : Miles, AJ (Alistair)\n> Cc : 'public-esw-thes@w3.org'; 'public-esw@w3.org'\n> Objet : Re: URI policy for thesaurus concepts\n>\n>\n>\n> * Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-04-30 16:08+0100]\n> >\n> > On the basis of the previous discussion on URIs for concepts, I'm going to\n> > offer the recommendation to thesaurus owners that they use http: based uris\n> > without fragment identifiers as URIs for their concepts.\n> >\n> > So for example:\n> >\n> > GEMET thesaurus URI: http://www.eionet.eu.int/GEMET/[version]\n> >\n> > GEMET concept URIs: http://www.eionet.eu.int/GEMET/[version]/[conceptID]\n> >\n> > Reason for going with http: based URIs is it seems generally agreed that it\n> > is desirable to have the concept URIs directly resolving to something.\n> >\n> > Reason for going with / and not # is so that the concept ID is included in\n> > an http GET request and not lost as it would be if it came after a #.\n> >\n> > I.e. decision based on purely practical considerations.\n> >\n> > Anybody want to shoot this down before I approach GEMET (& others) with\n> > this?\n>\n> I prefer the / approach, but I should warn that TimBL and others have\n> made the claim that http://blah/ URIs without a # can only name\n> 'documents' or 'networked information resources', and that concepts,\n> classes, properties etc don't count as those.\n>\n> So, if you do advice thesaurus folks one way or the other, try to make\n> clear that this aspect of web architecture is still under discussion.\n>\n> Dan\n>\n\n\n\n"
        },
        {
            "subject": "RE: URI policy for thesaurus concept",
            "content": "> Personally I like this approach. The recent TAG document \n> endorses a REST\n> view; so basically you're saying that\n> \n> http://www.eionet.eu.int/GEMET/[version]\n> \n> \"names\" the thesaurus, and\n> \n> http://www.eionet.eu.int/GEMET/[version]/[conceptID]\n> \n> \"names\" the particular concept. That's fine - I ought to be \n> able to ask\n> (via content negotiation) for a representation of a concept (or a\n> thesaurus) by an HTTP request for each of those URIs. What advice are\n> you offering on the stuff that's found at the end of those URIs?\n\nThat's a whole other ball game.  As I understand it, the choice is between\nthe HTTP GET request for the concept URI returning either a machine readable\nor a human readable description of that concept.  I may have boiled that\ndown too much - have I missed anything?      \n\n> \n> It'd be reasonable to generate (for instance) RDF describing an\n> individual concept (that perhaps links it to related \n> concepts) but it's\n> not immediately clear to me what content might live at the \"whole\n> thesaurus\" URI. Perhaps the whole thesaurus? Or a document with RDDL\n> content that points to related web services, etc..?\n> \n\nOne thing a GET request for the thesaurus URI should definitely return is a\ndescription of that thesaurus (i.e. name, version, creators, description of\nscope and content etc.) although again whether that should be machine or\nhuman readable is open.  \n\nThe other question is, should the request for the thesaurus URI also return\nthe entire content of the thesaurus?  Personally I think no, but again I'm\nnot sure about that.\n\nAl.  \n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Miles, AJ (Alistair)  <A.J.Miles@rl.ac.uk> [2004-04-30 16:37+0100]\n> \n> One thing a GET request for the thesaurus URI should definitely return is a\n> description of that thesaurus (i.e. name, version, creators, description of\n> scope and content etc.) although again whether that should be machine or\n> human readable is open.  \n> \n> The other question is, should the request for the thesaurus URI also return\n> the entire content of the thesaurus?  Personally I think no, but again I'm\n> not sure about that.\n\nLots of thesaurus owners might not like that. Lots of sysadmins might\nnot like that. In some cases it might be possible, but 'should' is imho\ntoo strong a claim...\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Why not simply follow Xlink/CPointer in this question?\n\nThe GET request Alistair has been talking about is a conforming solution.\nExample\nhttp://blah?concept=666\n\nThomas Bandholtz\nSemantic Web Consultant\nKarl-Friedrich-Schinkelstr. 2\n53127 Bonn\nGermany\nwww.bandholtz.info\n\n+49 228  9288490\ncell +49 179 4700576\nthomas@bandholtz.info\n\n\n----- Original Message ----- \nFrom: \"Dan Brickley\" <danbri@w3.org>\nTo: \"Miles, AJ (Alistair) \" <A.J.Miles@rl.ac.uk>\nCc: <public-esw-thes@w3.org>; <public-esw@w3.org>\nSent: Friday, April 30, 2004 5:18 PM\nSubject: Re: URI policy for thesaurus concepts\n\n\nAlistair: > > Reason for going with / and not # is so that the concept ID is\nincluded in\n> > an http GET request and not lost as it would be if it came after a #.\n\nDan: > I prefer the / approach, but I should warn that TimBL and others have\n> made the claim that http://blah/ URIs without a # can only name\n> 'documents' or 'networked information resources', and that concepts,\n> classes, properties etc don't count as those.\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-30 17:36+0200]\n> \n> To go along with Dan ...\n> \n> I also prefer the / approach in principle because it defines more neatly the \"subject\n> indicator\", but consider that e.g. OWL uses fragment identifiers to define classes and\n> properties ...\n> \n> Will not people be confused with OWL elements defined by\n> http://example.org/myontology#class001\n> and SKOS concepts defined by http://example.org/myskos/concept001\n\nSome RDF/RDFS/OWL vocabs end in a / and others end in a # and others do\nother things. This is the current state of affairs. The confusion is\nonly a problem because these different approaches have different\ntechnical and standards characteristics (and those aren't well\nexplained, currently).\n\n> What about namespace management?\n\nAn important but relatively independent problem, I think.\n\n> And having, e.g. for GEMET, over 8000 different resources/concepts, if you just want to\n> download the whole stuff, hmm...\n> Is not it more simple to have a / namespace for a whole SKOS scheme, and # for each\n> concept in it?\n> \n> We've been through this in Published Subjects TC, without clear conclusion ...\n\nI've a few years experience using the http://xmlns.com/wordnet/1.6/Cat\netc approach, and have to say it is useful. The ability to return a\nuseful chunk of information from a larger dataset is something I am\nreluctant to give up. Surely in the future we'll have richer (SKOS API,\nRDF DAWG etc) interfaces to these datasets, but the current approach can\nbe implemented with a simple filetree or CGI script, and has proved\nreasonably popular.\n\nDan\n\n\n\n"
        },
        {
            "subject": "AW: URI policy for thesaurus concept",
            "content": "I agree also to using http:// uris and / as delimiter.\nYes, I used some wordnet terms and it seems they work\n\nPerhaps Patrick Stickler will also like it to use http:// and / to\nidentify concepts, his URIQA should work with it.\n\ncheers\nLeo\n\n> * Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-30 17:36+0200]\n> > \n> > To go along with Dan ...\n> > \n> > I also prefer the / approach in principle because it defines more \n> > neatly the \"subject indicator\", but consider that e.g. OWL uses \n> > fragment identifiers to define classes and properties ...\n> > \n> > Will not people be confused with OWL elements defined by \n> > http://example.org/myontology#class001\n> > and SKOS concepts defined by http://example.org/myskos/concept001\n> \n> Some RDF/RDFS/OWL vocabs end in a / and others end in a # and \n> others do other things. This is the current state of affairs. \n> The confusion is only a problem because these different \n> approaches have different technical and standards \n> characteristics (and those aren't well explained, currently).\n> \n> > What about namespace management?\n> \n> An important but relatively independent problem, I think.\n> \n> > And having, e.g. for GEMET, over 8000 different \n> resources/concepts, if \n> > you just want to download the whole stuff, hmm... Is not it more \n> > simple to have a / namespace for a whole SKOS scheme, and # \n> for each \n> > concept in it?\n> > \n> > We've been through this in Published Subjects TC, without clear \n> > conclusion ...\n> \n> I've a few years experience using the \n> http://xmlns.com/wordnet/1.6/Cat etc approach, > and have to \n> say it is useful. The ability to return a useful chunk of \n> information from a larger dataset is something I am reluctant \n> to give up. Surely in the future we'll have richer (SKOS API, \n> RDF DAWG etc) interfaces to these datasets, but the current \n> approach can be implemented with a simple filetree or CGI \n> script, and has proved reasonably popular.\n> \n> Dan\n> \n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Alistair > One thing a GET request for the thesaurus URI should definitely\nreturn is a\n> description of that thesaurus (i.e. name, version, creators, description\nof\n> scope and content etc.) although again whether that should be machine or\n> human readable is open.\n\nObviously *both* must be possible.We had megabytes of discussion on this in\nthe Topic Map community and elsewhere.\nThe answer is very simple - there are humans, and there are machines\n(software agents).\nA service may decide to serve only one of them, but she may decide to serve\nboth.\nShe may even decide to serve several machine protocols or several human\nreadable layouts.\nThe consequence is that a singe URL is not enough.\nWe need pairs of protocol-URL such as\n\nHTML -> http://human.blah.org/thesaurus.html\nWSDL -> http://services.blah.org/thesaurus.wsdl\nDCMI -> http://dcmi.blah.org/thesaurus.xml\netc., etc.,\n\nthese must be explictly *pairs* (protocol -> URL) as the domain name must\nnot contain any significant meaning itself (see RFC URI)\n\nAlistair > The other question is, should the request for the thesaurus URI\nalso return\n> the entire content of the thesaurus?  Personally I think no, but again I'm\n> not sure about that.\n\nIt never should by default!! A well established thesaurus easily counts\n100.000s and more concepts! The requester (be it human or machine) must be\nable to identify the thesaurus source without downloading the whole thing.\n\nI my personal vision, the \"whole thing\" *never* will be downloaded at once:\navoid redunancy, and what the hell are we doing here? ---\nWe are establish means to *link to specific* concepts and make clear where\nthe come from.\n\nDownloading and so duplicating a thesaurus is OK in some situations, but\nthis should be regarded as a very special use case.\n\nThomas\n\n\n\n"
        },
        {
            "subject": "RE: URI policy for thesaurus concept",
            "content": "Miles, AJ (Alistair)  writes:\n\n> > That's fine - I ought to be able to ask (via content negotiation)\n> > for a representation of a concept (or a thesaurus) by an HTTP\n> > request for each of those URIs. What advice are you offering on the\n> > stuff that's found at the end of those URIs?\n> \n> That's a whole other ball game.  As I understand it, the choice is\n> between the HTTP GET request for the concept URI returning either a\n> machine readable or a human readable description of that concept.  I\n> may have boiled that down too much - have I missed anything?      \n\nWith content negotiation, you can do both: requests asking for HTML get\nHTML, and requests asking for RDF/XML get RDF/XML. (The rare case where\nthe request states no preference is probably someone using \"curl\" or\n\"wget\"; I'm guessing they'd want RDF/XML, but there's no real negative\nconsequence to choosing either way.)\n\nIt's even possible to do content negotiation when serving static files,\nthanks to mod_content and equivalents.\n\n> The other question is, should the request for the thesaurus URI also\n> return the entire content of the thesaurus?  Personally I think no,\n> but again I'm not sure about that.\n\nI'd have a description of the thesaurus at its base URI (again, in both\nHTML and RDF via content negotiation), and put the whole content at a\nseparate URI if desired.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "Fw: ANNOUNCEMENT: Redland RDF Application Framework 0.9.1",
            "content": "I released a new version of Redland on Saturday.  This includes the technology\ndeveloped for the demonstrator D12.4.1 that I'm still writing up (nearly done).\n\nAlso in the last few days, there's been some interest in taking up using\nRedland in the GNOME desktop world as part of their desktop metadata\nindexing and search system.  Just at the investigation stage so far.\n\nDave\n\n------- Forwarded Message\n\n       Redland RDF Application Framework 0.9.15\nhttp://www.redland.opensource.ac.uk/\n\n               Supported by EU IST project SWAD-Europe\n  http://www.w3.org/2001/sw/Europe/\n\nRedland is a C library that provides a high-level interface for RDF\nallowing the RDF graph to be parsed from XML, stored, queried and\nmanipulated.  Redland implements each of the RDF concepts in its own\nclass via an object based API, reflected into the other language APIs\n- Java, Perl, PHP, Python, Ruby and Tcl. Some of the classes\nproviding the parsers, storage mechanisms and other elements are\nbuilt as modules that can be added or removed as required.\n\nRedland 0.9.15 is major release and main changes are as follows\n\n  * Update to synchronise with Raptor version 1.2.0 (RDF/XML and\n    N-Triples parser) -- gaining the Turtle Terse RDF Triple Language\n\n  * Added new storage backends:\n    + MySQL written by Morten Frederiksen\n    + AKT Triplestore\n    + File and URI-backed in-memory storage\n\n  * Several classes modified to use unsigned char* for\n    UTF-8 encoded URIs and Literals\n\n  * Added fixes to make Redland compile cleanly under C++ (tested with g++).\n\n  * Added assertion checks and reporting for function arguments.\n\n  * Added a method for finding statements in a context.\n\n  * Added a method for listing the contexts in a graph.\n\n  * Many improvements to the rdfproc RDF processor utility.\n\n  * Many other minor changes and fixes.\n\nSee also the detailed 0.9.15 release notes at\nhttp://www.redland.opensource.ac.uk/RELEASE.html#rel0_9_15\n\nRedland 0.9.15 was tested as working out-of-the-box (configure; make;\nmake check) with the following systems:\n    alphaev67-unknown-linux-gnu - Debian GNU/Linux 3.0 on Alpha\n    i386-unknown-freebsd4.9     - FreeBSD 4.9 on x86\n    i686-pc-linux-gnu           - Debian GNU/Linux unstable on x86\n    i686-pc-linux-gnu           - Redaht GNU/Linux 8 on x86\n    i686-pc-linux-gnu           - Redhat GNU/Linux 9 on x86\n    powerpc-apple-darwin7.2.0   - Apple OSX 10.3.2 on PowerPC\n    sparc-sun-solaris2.8        - Sun Solaris 8 on Sparc\n    x86_64-unknown-linux-gnu    - SuSE GNU/Linux 8ES on AMD64 Opteron\n\nThe release consists of the full sources, RPM binaries and SRPMS\npackages for RedHat Linux 9 and debs for Debian unstable.\nIt is also available from the Redland SourceForge\nmirror site at http://sourceforge.net/projects/librdf/\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS and use Redland in various demos.\n\nI post updates about Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\nDave\n------- End of Forwarded Message\n\n\n\n"
        },
        {
            "subject": "First SWADE newsletter sen",
            "content": "hi all,\n\nI've compiled slightly edited, often shortened versions of January's\nweblog posts to create the SWAD-E newsletter for January:\n\nhttp://lists.w3.org/Archives/Public/public-esw-news/2004JanMar/0000.html\n\nPlease let me know about any formatting or other issues. In future it\nmight be good for people to write a fairly self-contained paragraph at\nthe beginning of weblog posts for this purpose, although I think this\none reads ok.\n\nMany thanks for all the contributions.\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Visit to JISC terminology services worksho",
            "content": "Libby and I were there on Friday, I wrote this up:\n\nhttp://esw.w3.org/mt/esw/archives/000041.html\n\nAl.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Visit to JISC terminology services worksho",
            "content": "Nice writeup Al, and (I thought) great work at the meeting getting the\nthesaurus work across :)\nI think it's the right work at the right time for this community. I\ngrabbed a couple of people and persuaded them to join the thesaurus\nmailing list.\n\nLibby\n\n\nOn Mon, 16 Feb 2004, Miles, AJ (Alistair)  wrote:\n\n>\n> Libby and I were there on Friday, I wrote this up:\n>\n> http://esw.w3.org/mt/esw/archives/000041.html\n>\n> Al.\n>\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n>\n> Email:        a.j.miles@rl.ac.uk\n> Telephone: +44 (0)1235 445440\n>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "SWADE weblog reminder: more news and FAQs pleas",
            "content": "hi everyone,\n\nThe next SWAD-E newsletter will go out at the end of February (probably\n27th as I'm away the first week of March), so this is a reminder to\nput some news and FAQ items up there by then. Thanks Al for putting\nan news item up there already :)\nI'd think it would be good to aim for at least one news item and one FAQ\nanswer per partner if possible.\n\nThe weblog is here:\nhttp://esw.w3.org/mt/esw/\n\nand the editing interface is here:\nhttp://esw.w3.org/mtcgi/mt.cgi\n\nI can let you have a username and password if you don't already have\none.\n\nMany thanks,\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Weblog article on rdf:nodeID  possible erro",
            "content": "Hi,\n\nWas just reading the weblog article on the rdf:nodeID attribute\n<http://esw.w3.org/mt/esw/archives/000034.html>.  I read this bit :\n\n--------------------------------------------------------------\n<rdf:Description rdf:ID=\"me\">\n <foaf:name>Dan Brickley</foaf:Name>\n</rdf:Description>\n\n...if parsed with a base URI of http://example.com/foaf/test1.rdf ...will\ngenerate a single triple:\n\nhttp://example.com/foaf/test1.rdf http://xmlns.com/foaf/0.1/name \"Dan\nBrickley\"\n--------------------------------------------------------------\n\nShouldn't the subject of the triple be :\n\nhttp://example.com/foaf/test1.rdf#me\n\n?\n\nAl.\n\n\n\n"
        },
        {
            "subject": "Re: Weblog article on rdf:nodeID  possible erro",
            "content": "Hi,\n\nThere's a subtle distinction between id= and explicit formation of a URIO \nfrom a namespace and local name.\n\nIn the former case, the URI formation rules are used (ala RFC2396, etc.), \nbut in the latter case its simple concatenation.  That's what the W3C \nvalidator is doing, and that's what seems to be called for by the RDF \nsyntax spec (e.g. section 2.14 ... I need to locate more details, but no \ntime right now).\n\n#g\n--\n\nAt 17:10 19/02/04 +0000, Miles, AJ (Alistair) wrote:\n\n>Hi,\n>\n>Was just reading the weblog article on the rdf:nodeID attribute\n><http://esw.w3.org/mt/esw/archives/000034.html>.  I read this bit :\n>\n>--------------------------------------------------------------\n><rdf:Description rdf:ID=\"me\">\n>  <foaf:name>Dan Brickley</foaf:Name>\n></rdf:Description>\n>\n>...if parsed with a base URI of http://example.com/foaf/test1.rdf ...will\n>generate a single triple:\n>\n>http://example.com/foaf/test1.rdf http://xmlns.com/foaf/0.1/name \"Dan\n>Brickley\"\n>--------------------------------------------------------------\n>\n>Shouldn't the subject of the triple be :\n>\n>http://example.com/foaf/test1.rdf#me\n>\n>?\n>\n>Al.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "Lessons learnt repor",
            "content": "Just a quick heads up (I forgot to do this before Christmas) that we\npublished the semblogging 'lessons learnt' report:\n\nhttp://www.w3.org/2001/sw/Europe/reports/demo_1_report/\n<http://www.w3.org/2001/sw/Europe/reports/demo_1_report/> \n\nCheers\n\nSteve \n\n================================================\nSteve Cayzer\nHewlett-Packard Laboratories\nFilton Road, Stoke Gifford, Bristol BS34 8QZ U.K.\nemail Steve.Cayzer@hp.com\ntel   +44 (0)117 312-7056 \nfax +44 (0)117 312-8924 \n\n\n\n"
        },
        {
            "subject": "Code online to",
            "content": "Semblogging code available at\n\nhttp://jena.hpl.hp.com:3030/blojsom-devt/download.jsp\n<http://jena.hpl.hp.com:3030/blojsom-devt/download.jsp> \n\nIt's pretty experimental in nature and desperately needs refactoring, but it\ndoes the job, and has some nice components in it (imho). Plunder at will :)\n\nI haven't had time to test out the installation on a clean machine, but I'm\nimagining that people won't be shy to mention if there are problems :)\n\nCheers\n\nSteve\n================================================\nSteve Cayzer\nHewlett-Packard Laboratories\nFilton Road, Stoke Gifford, Bristol BS34 8QZ U.K.\nemail Steve.Cayzer@hp.com\ntel   +44 (0)117 312-7056 \nfax +44 (0)117 312-8924 \n\n\n\n"
        },
        {
            "subject": "Report done?",
            "content": "Hi folks,\n\nI think the 12.3.2 deliverable is ready to release - it's at\nhttp://www.w3.org/2001/sw/Europe/reports/viz_tools_impl/ (and I apologise for\nthe fact that it is late)\n\nComments welcome.\n\nCheers\n\nChaals\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "12.3 complete Re: Report done?",
            "content": "Hi folks,\n\nthe other deliverable in this work package should now be complete too:\nhttp://www.w3.org/2001/sw/Europe/reports/viz_rdf_transform_library_impl/Overview.html\n\n(pointers to the relevant bits of software are in the reports).\n\nCheers\n\nChaals\n\nOn Sun, 4 Jan 2004, Charles McCathieNevile wrote:\n\n>\n>Hi folks,\n>\n>I think the 12.3.2 deliverable is ready to release - it's at\n>http://www.w3.org/2001/sw/Europe/reports/viz_tools_impl/ (and I apologise for\n>the fact that it is late)\n>\n>Comments welcome.\n>\n>Cheers\n>\n>Chaals\n>\n>Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\n>SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n> Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n> W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Draft 9.2 deliverabl",
            "content": "A report on adoption of semantic web technology for accessibility is the\ndeliverable 9.2\n\nA draft at http://www.w3.org/2001/sw/Europe/reports/report_wai-techs_updates/\nis available for comments...\n\ncheers\n\nChaals\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "RE: Report done?",
            "content": "Hello Charles,\nThe following citation in your report:\nhttp://www.w3.org/2001/sw/Europe/200306/geo/carte_zone_monde_rdf.svg\ngives an error 404.\n\nI was puzzled by the title of the report (\"SWAD-Europe Deliverable 12.3.2:\nTransformation libraries report\") compared to the content.  I was also\nmildly surprised that your future work and lessons learned (section 7)\naddressed only process issues, not any of the insights you gained about\nusing RDF data for visualisation.  Have you done any user evaluation of the\ntool?  That would be worth knowing more about.\n\nRegards,\nIan\n\n\n> -----Original Message-----\n> From: Charles McCathieNevile [mailto:charles@w3.org] \n> Sent: 04 January 2004 09:10\n> To: public-esw@w3.org\n> Subject: Report done??\n> \n> \n> \n> Hi folks,\n> \n> I think the 12.3.2 deliverable is ready to release - it's at \n> http://www.w3.org/2001/sw/Europe/reports/viz_tools_impl/ (and \n> I apologise for the fact that it is late)\n> \n> Comments welcome.\n> \n> Cheers\n> \n> Chaals\n> \n> Charles McCathieNevile  http://www.w3.org/People/Charles  \n> tel: +61 409 134 136\n> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): \n> +33 4 92 38 78 22\n>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n> \n\n\n\n"
        },
        {
            "subject": "RE: Report done?",
            "content": "Oh, that was an oversight. The process is more about using visualisation to\nwork with RDF data, and the assumption (which turned out to be correct, and\nas you point out should have been explicit) was that visualisation methods\nthat didn't rely on understanding a serialisation designedd for computers\nwould help users.\n\nI'll edit it and fix the link (should be zones not zone). You need Adobe SVG\nviewer running, and you probably now need to leave the thing sitting around\nfor a day or so to get the data :( But you can look at the source code :-)\n\nCheers\n\nChaals\n\nOn Mon, 5 Jan 2004, Dickinson, Ian J wrote:\n\n>Hello Charles,\n>The following citation in your report:\n>http://www.w3.org/2001/sw/Europe/200306/geo/carte_zone_monde_rdf.svg\n>gives an error 404.\n>\n>I was puzzled by the title of the report (\"SWAD-Europe Deliverable 12.3.2:\n>Transformation libraries report\") compared to the content.  I was also\n>mildly surprised that your future work and lessons learned (section 7)\n>addressed only process issues, not any of the insights you gained about\n>using RDF data for visualisation.  Have you done any user evaluation of the\n>tool?  That would be worth knowing more about.\n>\n>Regards,\n>Ian\n>\n>\n>> -----Original Message-----\n>> From: Charles McCathieNevile [mailto:charles@w3.org]\n>> Sent: 04 January 2004 09:10\n>> To: public-esw@w3.org\n>> Subject: Report done??\n>>\n>>\n>>\n>> Hi folks,\n>>\n>> I think the 12.3.2 deliverable is ready to release - it's at\n>> http://www.w3.org/2001/sw/Europe/reports/viz_tools_impl/ (and\n>> I apologise for the fact that it is late)\n>>\n>> Comments welcome.\n>>\n>> Cheers\n>>\n>> Chaals\n>>\n>> Charles McCathieNevile  http://www.w3.org/People/Charles\n>> tel: +61 409 134 136\n>> SWAD-E http://www.w3.org/2001/sw/Europe         fax(france):\n>> +33 4 92 38 78 22\n>>  Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n>>  W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n>>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Coding EARL  multilingual resourc",
            "content": "Hi folks,\n\nThere is a brief tutorial (designed for people who are smart but know nothing\nat all) on EARL available in English, French, Spanish and Italian.\n\nhttp://www.w3.org/2001/sw/Europe/talks/200311-earl/all\n\nComments welcome on any version. They're all in draft, and more or less\nsynchronised.\n\nCheers\n\nChaals\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "SWADE newslette",
            "content": "hi all,\n\nAs part of our revised evaluation plan we have agreed to send out a\nmonthly newsletter about SWAD-E to individuals who want to sign up.\n\nDan's already set up a mailing list[1] for the newsletter. The main\nquestion now is, where do we get the content to put in it?\n\nThere were two suggestions at the last face to face. One was to use\ncontent from the SWAD-E weblog. The other was get each project partner\nto answer an FAQ each month.\n\nSo, this is a heads up and a request that people\n\n- regularly write up some of what you are doing on the SWAD-E weblog\n(Dan's email on how to do this is here[2])\n\n- be prepared to write an FAQ answer (either to a question you choose,\nperhaps from [3], or I'll find one for you).\n\nI will bug people mid-month each month for content and get something\ntogether for mailing at the end of each month, including this month. Any\nsuggestions for topics to write about or any FAQs that have come up\nrecently, send them to this list.\n\nThanks,\n\nLibby\n\n\n[1]http://lists.w3.org/Archives/Public/public-esw-news/\n[2]http://lists.w3.org/Archives/Public/public-esw/2003Jan/0012.html\n[3]http://esw.w3.org/topic/FaqIdeas\n\n\n\n"
        },
        {
            "subject": "SWADE Deliverable 3.11: Developer Workshop Report 4  Workshop on           Semantic Web Storage and Retrieva",
            "content": "Abstract:\n    This report summarises the fourth SWAD-Europe developer Workshop on\nSemantic Web Storage and Retrieval which was held 13-14 November 2003 at\nVrije Universiteit, Amsterdam, Netherlands and attended by 26 semantic\nweb developers from Europe and the USA discussing practical aspects of\ndeveloping and deploying semantic web storage and retrieval systems. \n\nhttp://www.w3.org/2001/sw/Europe/reports/dev_workshop_report_4/\n\nIt got some nice evaluation comments:\n\n* Really enjoyed it, very glad I attended. Inspired to do lots of new work\n* Follow-up workshop in 6-12 months?\n* Great stuff. All very useful, fruitful discussions\n* Nice job\n* Found it useful\n* Good work convening. Interesting to hear divergent feedback. Inserting for me to hear about\n  \"state of the art\"\n\nDave\n\n\n\n"
        },
        {
            "subject": "Turtle  Terse RDF Triple Languag",
            "content": "Forgot to copy here this message I sent to www-rdf-interest.\n\nDave\n\n------- Forwarded Message\n\nI'd like to announce an updated version of the little language I've\nbeen developing for a while:\n\n  Turtle - Terse RDF Triple Language\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/\n\n  (previously called N-Triples Plus)\n\nThe language is based on the N-Triples[1] RDF test case language with\nthe addition of several (now 9) items taken from Notation3[2] that I found the\nmost useful and most used.  The last one I've just added was the (...)\nsyntax for RDF collections which is a handy short form.\n\nIt's defined in an EBNF and I give a few examples, although many N3\nones are also valid if you stick to this subset (mostly subset, see\nthe QNames section).\n\nThe document also links to a pre-print paper that describes the\nideas behind the development.\n\nTurtle is also implemented as a language in it's own right in my\nRDF parser Raptor http://www.redland.opensource.ac.uk/raptor/\nwith the latest addition in the CVS version only; will be in\nthe 1.2.0 version.\n\nLet me know what you think.\n\nCheers\n\nDave\n\n[1] N-Triples http://www.w3.org/TR/rdf-testcases/#ntriples\n  in RDF Test Cases, which I co-edit\n\n[2] Notation3 http://www.w3.org/DesignIssues/Notation3\n by Tim Berners-Lee\n\n\n\n"
        },
        {
            "subject": "Deliverable 8.3 Final Draft  RDF Encoding of Multilingual Thesau r",
            "content": "Hi guys,\n\nFinal draft on the web at\n\nhttp://www.w3c.rl.ac.uk/SWAD/deliverables/8.3.html\n\nany comments before submission?\n\nAlistair.\n\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\n\nEmail:        a.j.miles@rl.ac.uk\nTelephone: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: Deliverable 8.3 Final Draft  RDF Encoding of Multilingual Thesau   r",
            "content": "Looks good and clear.\n\nonly comment is that the code for german is \"de\", not \"ge\", I think.\n\nI'm intrigued by the fact that the examples are all based on describing a\nblank node that is a concept - is this a deliberate choice?\n\nCheers\n\nChaals\n\nOn Mon, 19 Jan 2004, Miles, AJ (Alistair)  wrote:\n\n>\n>Hi guys,\n>\n>Final draft on the web at\n>\n>http://www.w3c.rl.ac.uk/SWAD/deliverables/8.3.html\n>\n>any comments before submission?\n>\n>Alistair.\n>\n>CCLRC - Rutherford Appleton Laboratory\n>Building R1 Room 1.60\n>Fermi Avenue\n>Chilton\n>Didcot\n>Oxfordshire OX11 0QX\n>United Kingdom\n>\n>Email:        a.j.miles@rl.ac.uk\n>Telephone: +44 (0)1235 445440\n>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "SWADE newsletter and weblo",
            "content": "hi all,\n\nIn a previous message[1] I outlined the sort of information we need for\nthe new newsletter, essentially an FAQ answer from each partner and\nsome short pieces of information about what's been happening in the\nproject via the SWAD-E weblog[2] or from elsewhere (e.g. for Steve\nfrom his Semantic Blog[3]).\n\nThanks to those who have already added information to the weblog.\nInformation about how to do so is here[4].\n\nFAQs:\nI've sent individual emails with suggestions, but please answer anything\nthat you think is relevant and interesting. FAQ ideas can be found on\nthe wiki FAQ ideas page[5] (see also the links from there), as well as\nmailing lists.\n\nProject news:\nThe aim of using the (or a) weblog is to disseminate widely within the\nblogging community, as well as to provide information for the\nnewsletter. Please add something if you can.\n\nFor FAQ answers and blog posts or other news, I need the information by\nthe end of Monday (26th Jan) so that I can pull together the newsletter\nby the end of January.\n\nMany thanks,\n\nLibby\n\n[1] http://lists.w3.org/Archives/Public/public-esw/2004Jan/0008.html\n[2] http://esw.w3.org/mt/esw/\n[3] http://jena.hpl.hp.com:3030/blojsom-hp/blog/\n[4] http://lists.w3.org/Archives/Public/public-esw/2003Jan/0012.html\n[5] http://esw.w3.org/topic/FaqIdeas\n\n\n\n"
        },
        {
            "subject": "Re: SWADE newsletter and weblo",
            "content": "Dan just pointed out to me that the FAQs might as well go on the weblog\ntoo, which makes lots of sense. If you could do that and make clear that\nit is an FAQ answer by making the category 'FAQ', that would be\nwonderful. I still need FAQ answers *and* news items though.\n\nthanks,\n\nLibby\n\nOn Tue, 20 Jan 2004, Libby Miller wrote:\n\n>\n>\n> hi all,\n>\n> In a previous message[1] I outlined the sort of information we need for\n> the new newsletter, essentially an FAQ answer from each partner and\n> some short pieces of information about what's been happening in the\n> project via the SWAD-E weblog[2] or from elsewhere (e.g. for Steve\n> from his Semantic Blog[3]).\n>\n> Thanks to those who have already added information to the weblog.\n> Information about how to do so is here[4].\n>\n> FAQs:\n> I've sent individual emails with suggestions, but please answer anything\n> that you think is relevant and interesting. FAQ ideas can be found on\n> the wiki FAQ ideas page[5] (see also the links from there), as well as\n> mailing lists.\n>\n> Project news:\n> The aim of using the (or a) weblog is to disseminate widely within the\n> blogging community, as well as to provide information for the\n> newsletter. Please add something if you can.\n>\n> For FAQ answers and blog posts or other news, I need the information by\n> the end of Monday (26th Jan) so that I can pull together the newsletter\n> by the end of January.\n>\n> Many thanks,\n>\n> Libby\n>\n> [1] http://lists.w3.org/Archives/Public/public-esw/2004Jan/0008.html\n> [2] http://esw.w3.org/mt/esw/\n> [3] http://jena.hpl.hp.com:3030/blojsom-hp/blog/\n> [4] http://lists.w3.org/Archives/Public/public-esw/2003Jan/0012.html\n> [5] http://esw.w3.org/topic/FaqIdeas\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "dissemination questionnaire for SWADE websit",
            "content": "hi again,\n\nWe promised[1] to learn more about the people we arereaching wth our\ndissemination efforts, and one way to find out more is to ask website\nvisitors about themselves. At the last face to face we decided it would\nbe useful to have a short questionnaire for visitors, linked to\ninformation about the newsletter. We need to decide what those questions\nshould be. Here are my suggestions, based on [1].\n\n\n(1) Which group are you from?\n\nOur dissemination plan is based around reaching four different (often\noverlapping) groups:\n\n    * Internet, Web and Open Source developer communities\n    * Academic and Research Community\n    * Content and Tool Producers\n    * Industry and Commerce\n\nand perhaps\n\n    * other\n\nso being able to pick from those (check-box-style) would be one\nimportant question.\n\n\n(2) Where are you geographically based?\n\nTo evaluate whether the project is too uk-centric, it would be useful to\nknow where visitors to the site were based. Perhaps a drop-down menu\nwould be appropriate here.\n\n\n(3) How did you hear of us?\n\nThis might be useful for working out which are our best dissemintation\nefforts.\n\n\nAny thoughts?\n\nLibby\n\n\n[1] http://www.w3.org/2001/sw/Europe/reports/dissemination_plan_2/\n\n\n\n"
        },
        {
            "subject": "updating weblog software-  no blogging please",
            "content": "hi\n\nI'm updating our Movable Type installation to 2.661; shouldn't \n(hopefully) take long. Best if you don't use it right now though! I'll \nmail around when done.\n\nDan\n\n\n\n"
        },
        {
            "subject": "Re: dissemination questionnaire for SWADE websit",
            "content": "On Tue, 20 Jan 2004, Libby Miller wrote:\n\n>\n>\n>hi again,\n>\n>We promised[1] to learn more about the people we arereaching wth our\n>dissemination efforts, and one way to find out more is to ask website\n>visitors about themselves. At the last face to face we decided it would\n>be useful to have a short questionnaire for visitors, linked to\n>information about the newsletter. We need to decide what those questions\n>should be. Here are my suggestions, based on [1].\n>\n>\n>(1) Which group are you from?\n>\n>Our dissemination plan is based around reaching four different (often\n>overlapping) groups:\n>\n>    * Internet, Web and Open Source developer communities\n>    * Academic and Research Community\n>    * Content and Tool Producers\n>    * Industry and Commerce\n>\n>so being able to pick from those (check-box-style) would be one\n>important question.\n\nBeing able to pick multiples is important I think, and having a box for free\ncomment is always a good thing - whether they are otehr or not.\n\n>\n>(2) Where are you geographically based?\n>\n>To evaluate whether the project is too uk-centric, it would be useful to\n>know where visitors to the site were based. Perhaps a drop-down menu\n>would be appropriate here.\n>\n\nEurope, Eastern Europe, North America, South America, Africa, Asia/Pacific?\nplease specify country?\n\nThe difficulty is that because most of the site is in english (I have a\ncouple of things in spanish, french and italian there) it makes sense that\npeople who speak other languages look in other places, even for stuff that\ncomes from the project.\n\n>(3) How did you hear of us?\n>\n>This might be useful for working out which are our best dissemintation\n>efforts.\n\nWe should ensure that we have a privacy policy for all this, and that it\nmatches what we say on the site.\n\ncheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "RE: dissemination questionnaire for SWADE websit",
            "content": "> (1) Which group are you from?\n> (2) Where are you geographically based?\n> (3) How did you hear of us?\n>\n> This might be useful for working out which are our best dissemintation\n> efforts.\n>\n>\n> Any thoughts?\n\nA little one: questions along the lines of\n\n\"Are you currently using semweb tech?\"\n\"Are you planning to in the near future?\"\n\nmight help see whether emphasis should be on initial exposure or a step (or\ntwo) further along.\n\n\n\n"
        },
        {
            "subject": "RE: dissemination questionnaire for SWADE websit",
            "content": "yep, good idea...\n(we'll end up with rdf, right?)\n\nchaals\n\nOn Tue, 20 Jan 2004, Danny Ayers wrote:\n\n>\n>> (1) Which group are you from?\n>> (2) Where are you geographically based?\n>> (3) How did you hear of us?\n>>\n>> This might be useful for working out which are our best dissemintation\n>> efforts.\n>>\n>>\n>> Any thoughts?\n>\n>A little one: questions along the lines of\n>\n>\"Are you currently using semweb tech?\"\n>\"Are you planning to in the near future?\"\n>\n>might help see whether emphasis should be on initial exposure or a step (or\n>two) further along.\n>\n>\n>\n>\n>\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Workshop on metadata and multilingual world, CPH July 15/1",
            "content": "Hi folks,\n\nfor those who find the subject line cryptic, CPH is the airport code for\nCopenhagen.\n\nThat is where the Danish National Library Authority is hosting a SWAD-E and\nCEN/ISSS MMI-DC joint workshop, on the topic of metadata for a multilingual\nworld. It will take place on July 15/16 and registration is free, but please\nregister before 1 July. You are also expected to provide some brief notes\nabout your work and interest in the area - preferably with links so other\npeople can do some homework before the workshop if they would like to.\n\nhttp://www.w3.org/2001/sw/Europe/events/200407-cph/ is the workshop\ninformation page, which lists the approximate goals as:\n\nBring together developers working on the use of metadata and the semantic web\n in multilingual contexts\nExamine a number of questions with regards to using metadata for multilingual\n content, including\n  Translation, versioning and approval processes for multilingual vocabularies\n  Multilingual metadata description and encoding\n  Multilingual and multicultural interoperability of metadata\n  Reuse of RDF vocabularies in the global community\n  Interoperability of metadata in global community\nProvide a brief survey of available tools, development projects, and areas\n where further development would be useful\n\nhope to see some of you there\n\nbest regards\n\nCharles McCN\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Fw: Turtle - Terse RDF Triple Language changes at 2004-061",
            "content": "This is work done under SWADE, an extra :)\n\nDave\n\n----\nBegin forwarded message:\n\nDate: Sat, 12 Jun 2004 17:43:46 +0100\nFrom: Dave Beckett <dave.beckett@bristol.ac.uk>\nTo: www-rdf-interest@w3.org, public-cwm-talk@w3.org\nSubject: Turtle - Terse RDF Triple Language changes at 2004-06-12\n\n\n\nI have just made an update to the Turtle language at\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/\nto cover some points raised since the last change.\nThe full detailed changes are given in the document changelog\nat http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#sec-changelog\n\nDiscussion of Turtle can be done on this list but preferably for\ndetailed items, on public-cwm-talk which is archived at\n  http://lists.w3.org/Archives/Public/public-cwm-talk/\n\n\n1. Turtle names (QNames) are now allowed to use '_' at the start\nof local names but not namespace prefixes since that's used for\nblank node names.\n\nThis change was made because, for example, rdf:_1 was forbidden\nas a QName which is slightly embarrassing :)\n\nChanged the EBNF to support the change above, adding nameStartChar\nand nameChar terms named after the XML equivalent.  This is also\nmeant some Editorial changes to the QNames section at\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#sec-qnames\nto match the change to the grammar terms.\n\n\n2. Allow a predicateObjectList to have a trailing ';' which\nmakes it easier for generating Turtle and for humans.\n\nFor example, this is now allowed (... standing for other property /\nvalue pairs)\n\n----------------------------------------\n_:a a :List ;\n    :item [ :prop1 \"value1\" ... ] ;\n    :item [ :prop1 \"value2\" ... ] ;\n    :item [ :prop1 \"value3\" ... ] ;\n----------------------------------------\n\n\n3. Updated the test cases for Turtle\n\nNew tests.zip at\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/tests.zip\nwith tests for the items above.  This is also available in\nRaptor's CVS, see the end of the Examples section\n  http://www.ilrt.bris.ac.uk/discovery/2004/01/turtle/#sec-examples\nfor pointers.\n\n\nSales Pitch: These changes are implemented in Raptor CVS version\nright now at\n  http://www.redland.opensource.ac.uk/raptor/\nand will be in the 1.3.1 release out soon.\n\nCheers\n\nDave\n\n\n\n"
        },
        {
            "subject": "Fw: ANNOUNCEMENT: Raptor RDF Parser Toolkit 1.3.",
            "content": "Announced yesterday\n\nDave\n---\n\nBegin forwarded message:\n\nDate: Sat, 12 Jun 2004 18:33:23 +0100\nFrom: Dave Beckett <dave.beckett@bristol.ac.uk>\nTo: www-rdf-interest@w3.org\nSubject: ANNOUNCEMENT: Raptor RDF Parser Toolkit 1.3.1\n\n\n\n   Raptor RDF Parser Toolkit 1.3.1\n     http://www.redland.opensource.ac.uk/raptor/\n\n               Supported by EU IST project SWAD-Europe\n  http://www.w3.org/2001/sw/Europe/\n\nRaptor is a free software/Open Source C library that parses RDF\nsyntaxes such as RDF/XML, N-Triples and Turtle into RDF triples.  It\nhandles all RDF vocabularies such as FOAF, RSS 1.0, Dublin Core and OWL.\n\nRaptor is designed to work closely with the Redland RDF library but\nis fully separate.  It is a mature, portable and high performance\nlibrary that works across many POSIX systems (Unix, GNU/Linux, BSDs,\nOSX, cygwin) and others.  It has been tested on multiple architectures\n(x86, IA64, powerpc, alpha, sparc).  Raptor has no known memory leaks\nand is suitable for embedding in long running applications.\n\nThis version is a minor update mostly for portability bulding on win32\nalong with some other fixes.\n\nSummary of main changes:\n\n * Correct raptor_print_statement declaration argument statement to\n   have one less 'const', to match the code.\n * raptor.h now includes stdarg.h\n * Updates to Turtle[1] parser to only allow language with non-datatyped\n   literals; allow a '_' immediately after a ':' in qnames and make\n   bare ':' work. \n * Added a warning for unknown rdf:parseType values, when parsing in\n   lax mode. This is controlled by a new parser feature\n   warn_other_parsetypes \n * The Turtle parser was fixed to re-initialise correctly when\n   performing multiple parsings\n * Fixes to the file: URI support for %-escaping and for Win32 filenames\n\nSee also the detailed 1.3.1 release notes at\nhttp://www.redland.opensource.ac.uk/raptor/RELEASE.html#rel1_3_1\nfor more information\n\nRaptor 1.3.1 was tested as working out-of-the-box (configure; make;\nmake check) with the following systems:\n    i386-pc-solaris2.9          - Sun Solaris on x86\n    i386-unknown-freebsd4.10    - FreeBSD 4.10-PRERELEASE on x86\n    i686-pc-linux-gnu           - Debian GNU/Linux unstable on x86\n    i686-pc-linux-gnu           - Redhat GNU/Linux Fedora Core 2 on x86\n    powerpc-apple-darwin6.8     - Apple OSX 10.2.8 on PowerPC\n    powerpc-apple-darwin7.2.0   - Apple OSX 10.3.2 on PowerPC\n    x86_64-unknown-linux-gnu    - Debian GNU/Linux unstable on AMD64 x86\n\nThe release consists of the full sources, RPM binaries and source RPM\npackages for RedHat Linux Fedora Core 2.\nThese are also available from the Redland SourceForge mirror site at\n  http://sourceforge.net/projects/librdf/\nDebian packages will be made available shortly and are provided\nin the standard Debian unstable archive.\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS and use Raptor in various demos (as part of Redland).\n\nI post updates about Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\nDave\n\n[1] http://www.ilrt.bristol.ac.uk/discovery/2004/01/turtle/\n\n\n\n"
        },
        {
            "subject": "Fw: ANNOUNCEMENT: Rasqal RDF Query Library Toolkit 0.9.",
            "content": "Announced today.  This is an extra deliverable under WP3.  I don't\nthink it has a SWADE deliverable number yet.\n\nDave\n\n--\n\nBegin forwarded message:\n\nDate: Sun, 13 Jun 2004 16:46:53 +0100\nFrom: Dave Beckett <dave.beckett@bristol.ac.uk>\nTo: www-rdf-interest@w3.org\nSubject: ANNOUNCEMENT: Rasqal RDF Query Library 0.9.1\n\n\n\n   Rasqal RDF Query Library 0.9.1\n     http://www.redland.opensource.ac.uk/rasqal/\n\n               Supported by EU IST project SWAD-Europe\n  http://www.w3.org/2001/sw/Europe/\n\nRasqal is a free software/Open Source C library that handles RDF\nquery syntaxes, query construction and query execution returning\nresult bindings.  It currently handles RDF Data Query Language\n(RDQL).  Rasqal was designed to work closely with the Redland[1] RDF\nlibrary and Raptor[2] RDF parsing library but is entirely separate.\n\nThis is the second release of Rasqal and is beta quality: working but\nthe API may be modified or extended.  Rasqal is a portable library\nand has been tested on multiple POSIX systems and a variety\narchitectures (x86, IA64, powerpc, alpha, sparc).  It has no known\nmemory leaks and is suitable for embedding in long running\napplications.\n\nThe only main change in this release is to alter the query results API,\nwhich is now separated from the main query class. Detailed changes\nare given in the 0.9.1 release notes at\nhttp://www.redland.opensource.ac.uk/rasqal/RELEASE.html#rel0_9_1\n\nRaptor 0.9.1 requires Raptor 1.3.1[2] to provide parsing support and\nalso can use either Raptor or Redland[1] to provide a source of\ntriples.  The final requirement is a POSIX regular expression library\nsuch as PCRE or one built into the C library.  It was tested as\nworking out-of-the-box (configure; make; make check) against an\ninstalled Raptor 1.3.1 with the following systems:\n\n    alphaev67-unknown-linux-gnu - Debian GNU/Linux on Alpha\n    i386-pc-solaris2.9          - Sun Solaris 5.9 on x86(*)\n    i386-unknown-freebsd4.10    - FreeBSD 4.10-PRERELEASE on x86\n    i686-pc-linux-gnu           - Debian GNU/Linux unstable on x86\n    i686-pc-linux-gnu           - Redhat GNU/Linux Fedora Core 2 on x86\n    i686-pc-linux-gnu           - Redhat GNU/Linux Redhat 8 on x86\n    powerpc-apple-darwin5.5     - Apple OSX 10.2.X on PowerPC(*)(+)\n    powerpc-apple-darwin7.3.0   - Apple OSX 10.3.3 on PowerPC(+)\n    sparc-sun-solaris2.9        - Sun Solaris 9 on Sparc(*)\n    x86_64-unknown-linux-gnu    - Debian GNU/Linux on AMD x86\n\n    (*) Failed tests requiring PCRE/POSIX regex libraries which were\n        not available \n    (+) Using Fink from http://fink.sourceforge.net/\n\nThe release consists of the full sources, RPM binaries and source RPM\npackages for RedHat GNU/Linux Fedora Core 2.\nThese are also available from the Redland SourceForge mirror site at\n  http://sourceforge.net/projects/librdf/\nDebian packages should be made available shortly.\n\nThe main web site lets you browse and check out the latest version of\nthe sources in CVS.\n\nI post updates about Rasqal, Redland and Raptor to the redland-dev list\nwhich is one of the lists you can join from the list page at\n  http://www.redland.opensource.ac.uk/lists/\n\nDave\n\n[1] http://www.redland.opensource.ac.uk/\n[2] http://www.redland.opensource.ac.uk/raptor/\n\n\n\n"
        },
        {
            "subject": "Thesaurus FAQ Entry: 'How can I make my thesaurus a part of the s emantic web?",
            "content": "Just blogged this FAQ item, <http://esw.w3.org/mt/esw/archives/000045.html>.\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "&quot;Warning: Blogs Can Be Infectious&quot",
            "content": "The following spotted in ACM's Technews service, at:\nhttp://www.acm.org/technews/articles/2004-6/0305f.html#item5\n\nIs there any contact between this and HP's semantic blogging work?\n\nI also wonder if it has any implications for FOAF-related applications.\n\n#g\n--\n\n# \"Warning: Blogs Can Be Infectious\"\nWired News (03/05/04); Asaravala, Amit\n\nResearchers at Hewlett-Packard Labs used Intelliseek's BlogPulse Web \ncrawler to mine numerous Weblogs, after which they mapped out the \nconnections and topics shared among a large number of sites. Analysis \nshowed that topics would often appear on a small number of relatively \nobscure blogs a few days before showing up on more popular sites. \"There is \na lot of speculation that really important people are highly connected, but \nreally, we wonder if the highly connected people just listen to the \nimportant people,\" explains HP Labs researcher Lada Adamic. The team \nlearned that when an idea \"infected\" at least 10 blogs, 70 percent of those \nblogs failed to supply links back to another blog that previously mentioned \nthe idea, so the researchers devised methods to deduce the point of origin \nof information by noting textual, link, and infection rate similarities. \n\"What we're finding is that the important people on the Web are not \nnecessarily the people with the most explicit links [back to their sites], \nbut the people who cause epidemics in blog networks,\" says HP researcher \nEytan Adar. The scientists have encapsulated their techniques into the \niRank search algorithm, which ranks sites according to how well they inject \nideas into the mainstream. Future plans include making iRank resistant to \nGoogle-bomb-type attacks, while some of the team's research is accessible \nonline via the Blog Epidemic Analyzer program. The HP Labs research could \nhelp sociologists chart the course of knowledge epidemics, which marketers \ncould also exploit to sell their products directly to the most influential \nmembers of a group.\nClick Here to View Full Article:\nhttp://www.wired.com/news/culture/0,1284,62537,00.html\n\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "Re: &quot;Warning: Blogs Can Be Infectious&quot",
            "content": "Graham Klyne wrote:\n> \n> The following spotted in ACM's Technews service, at:\n> http://www.acm.org/technews/articles/2004-6/0305f.html#item5\n> \n> Is there any contact between this and HP's semantic blogging work?\n\nNo, it is from Bernado Huberman's group in Palo Alto. Fun stuff though.\n\nDave\n\n\n\n"
        },
        {
            "subject": "SWADEurope February newslette",
            "content": "...is available:\n\nhttp://lists.w3.org/Archives/Public/public-esw-news/2004JanMar/0001.html\n\nAs always, it's based on the weblog:\n\nhttp://esw.w3.org/mt/esw/\n\nThanks to everyone who contributed.\n\nApologies for the delay - the Technical Plenary didn't leave me any time\nto do the newsletter.\n\ncheers\n\nLibby\n\n\n\n"
        },
        {
            "subject": "RE: &quot;Warning: Blogs Can Be Infectious&quot",
            "content": "Heh - thanks for the tipoff Graham, just blogged it.\nhttp://jena.hpl.hp.com:3030/blojsom-hp/blog/technologies/blogging/communitie\ns/?permalink=C3FB344B1EA27A85C24DD1F05BEB4529.textile&smm=y\n\nI was aware of the work but not that it had made Wired.\n\nTry typing in hpl to the search demo mentioned in the article and you get my\nblog!\nhttp://www-idl.hpl.hp.com/cgi-bin/blogs/search_new.cgi?s=hpl\n\nThat's about as near to fame as I can manage :)\n\nSteve\n\n> -----Original Message-----\n> From: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] On Behalf Of Graham Klyne\n> Sent: 08 March 2004 13:15\n> To: public-esw@w3.org\n> Subject: \"Warning: Blogs Can Be Infectious\"\n> \n> \n> \n> The following spotted in ACM's Technews service, at: \n> http://www.acm.org/technews/articles/2004-6/0305f.html#item5\n> \n> Is there any contact between this and HP's semantic blogging work?\n> \n> I also wonder if it has any implications for FOAF-related \n> applications.\n> \n> #g\n> --\n> \n> # \"Warning: Blogs Can Be Infectious\"\n> Wired News (03/05/04); Asaravala, Amit\n> \n> Researchers at Hewlett-Packard Labs used Intelliseek's BlogPulse Web \n> crawler to mine numerous Weblogs, after which they mapped out the \n> connections and topics shared among a large number of sites. Analysis \n> showed that topics would often appear on a small number of relatively \n> obscure blogs a few days before showing up on more popular \n> sites. \"There is \n> a lot of speculation that really important people are highly \n> connected, but \n> really, we wonder if the highly connected people just listen to the \n> important people,\" explains HP Labs researcher Lada Adamic. The team \n> learned that when an idea \"infected\" at least 10 blogs, 70 \n> percent of those \n> blogs failed to supply links back to another blog that \n> previously mentioned \n> the idea, so the researchers devised methods to deduce the \n> point of origin \n> of information by noting textual, link, and infection rate \n> similarities. \n> \"What we're finding is that the important people on the Web are not \n> necessarily the people with the most explicit links [back to \n> their sites], \n> but the people who cause epidemics in blog networks,\" says HP \n> researcher \n> Eytan Adar. The scientists have encapsulated their techniques \n> into the \n> iRank search algorithm, which ranks sites according to how \n> well they inject \n> ideas into the mainstream. Future plans include making iRank \n> resistant to \n> Google-bomb-type attacks, while some of the team's research \n> is accessible \n> online via the Blog Epidemic Analyzer program. The HP Labs \n> research could \n> help sociologists chart the course of knowledge epidemics, \n> which marketers \n> could also exploit to sell their products directly to the \n> most influential \n> members of a group.\n> Click Here to View Full Article: \n> http://www.wired.com/news/culture/0,1284,62537> ,00.html\n> \n> \n> \n> ------------\n> Graham Klyne\n> For email:\n> http://www.ninebynine.org/#Contact\n> \n\n\n\n"
        },
        {
            "subject": "RE: &quot;Warning: Blogs Can Be Infectious&quot",
            "content": "Nice visualizations!  Maybe it should be called \"blobbing\"?\n\n#g\n--\n\nAt 17:01 08/03/04 +0000, Cayzer, Steve wrote:\n\n>Heh - thanks for the tipoff Graham, just blogged it.\n>http://jena.hpl.hp.com:3030/blojsom-hp/blog/technologies/blogging/communitie\n>s/?permalink=C3FB344B1EA27A85C24DD1F05BEB4529.textile&smm=y\n>\n>I was aware of the work but not that it had made Wired.\n>\n>Try typing in hpl to the search demo mentioned in the article and you get my\n>blog!\n>http://www-idl.hpl.hp.com/cgi-bin/blogs/search_new.cgi?s=hpl\n>\n>That's about as near to fame as I can manage :)\n>\n>Steve\n>\n> > -----Original Message-----\n> > From: public-esw-request@w3.org\n> > [mailto:public-esw-request@w3.org] On Behalf Of Graham Klyne\n> > Sent: 08 March 2004 13:15\n> > To: public-esw@w3.org\n> > Subject: \"Warning: Blogs Can Be Infectious\"\n> >\n> >\n> >\n> > The following spotted in ACM's Technews service, at:\n> > http://www.acm.org/technews/articles/2004-6/0305f.html#item5\n> >\n> > Is there any contact between this and HP's semantic blogging work?\n> >\n> > I also wonder if it has any implications for FOAF-related\n> > applications.\n> >\n> > #g\n> > --\n> >\n> > # \"Warning: Blogs Can Be Infectious\"\n> > Wired News (03/05/04); Asaravala, Amit\n> >\n> > Researchers at Hewlett-Packard Labs used Intelliseek's BlogPulse Web\n> > crawler to mine numerous Weblogs, after which they mapped out the\n> > connections and topics shared among a large number of sites. Analysis\n> > showed that topics would often appear on a small number of relatively\n> > obscure blogs a few days before showing up on more popular\n> > sites. \"There is\n> > a lot of speculation that really important people are highly\n> > connected, but\n> > really, we wonder if the highly connected people just listen to the\n> > important people,\" explains HP Labs researcher Lada Adamic. The team\n> > learned that when an idea \"infected\" at least 10 blogs, 70\n> > percent of those\n> > blogs failed to supply links back to another blog that\n> > previously mentioned\n> > the idea, so the researchers devised methods to deduce the\n> > point of origin\n> > of information by noting textual, link, and infection rate\n> > similarities.\n> > \"What we're finding is that the important people on the Web are not\n> > necessarily the people with the most explicit links [back to\n> > their sites],\n> > but the people who cause epidemics in blog networks,\" says HP\n> > researcher\n> > Eytan Adar. The scientists have encapsulated their techniques\n> > into the\n> > iRank search algorithm, which ranks sites according to how\n> > well they inject\n> > ideas into the mainstream. Future plans include making iRank\n> > resistant to\n> > Google-bomb-type attacks, while some of the team's research\n> > is accessible\n> > online via the Blog Epidemic Analyzer program. The HP Labs\n> > research could\n> > help sociologists chart the course of knowledge epidemics,\n> > which marketers\n> > could also exploit to sell their products directly to the\n> > most influential\n> > members of a group.\n> > Click Here to View Full Article:\n> > http://www.wired.com/news/culture/0,1284,62537> ,00.html\n> >\n> >\n> >\n> > ------------\n> > Graham Klyne\n> > For email:\n> > http://www.ninebynine.org/#Contact\n> >\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n"
        },
        {
            "subject": "tes",
            "content": " \n\n \n\nScott Wiseman\n\n \n\nRepresenting the following companies:\n\n \n\nNetwork Consultant Los Angeles\n\nhttp://www.Intercore.net\n\nComputer Consultant Los Angeles\n\nhttp://www.Avidware.net\n\nSecurity Consultant Los Angeles\n\nhttp://www.Avidware.com\n\nBusiness Consultant Los Angeles\n\nhttp://www.FastForwardMarcom.com\n\nWebsite Developer Los Angeles\n\nhttp://www.cyberwebgroup.com\n\nEquipment Leasing Consultant\n\nhttp://www.CorpLeasing.com\n\n \n\n \n\n \n\n \n\n\n\n"
        },
        {
            "subject": "Newspapers and RS",
            "content": "Just out of personal interest, does anyone know if any of the major\nnewspapers are syndicating their news via an RSS feed?\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "RE: Newspapers and RS",
            "content": "Hardly a comprehensive summary, but I know the guardian does\nhttp://www.guardian.co.uk/rss/\n\nAnd I subscribe to the BBC (themed) news feeds\n\n[That's just labelled me, then :) ]\n\nHth\n\nSteve\n\n> -----Original Message-----\n> From: public-esw-request@w3.org \n> [mailto:public-esw-request@w3.org] On Behalf Of Miles, AJ (Alistair) \n> Sent: 09 March 2004 17:11\n> To: 'public-esw@w3.org'\n> Subject: Newspapers and RSS\n> \n> \n> \n> Just out of personal interest, does anyone know if any of the \n> major newspapers are syndicating their news via an RSS feed?\n> \n> Al.\n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "RE: Newspapers and RS",
            "content": "On Thu, 11 Mar 2004, Cayzer, Steve wrote:\n\n>\n> Hardly a comprehensive summary, but I know the guardian does\n> http://www.guardian.co.uk/rss/\n>\n> And I subscribe to the BBC (themed) news feeds\n>\n> [That's just labelled me, then :) ]\n\nIncidentally yesterday I attended a talk by Anthony Hunter from UCL. One\nof the things he's looking at is aggregating and merging newsfeeds\n(well, the case study uses weather reports, but RSS has sufficient\nstructure to make his fusion rules work, I think) to take into account\ninconsistency in the supplied data.\n\nThe technique would really rely on \"semantic\" markup in RSS, though:\nthat is, for instance, using RSS modules for weather, football reports,\netc - or being able to parse the interesting bits out of free text.\n\n\n-- \njan grant, ILRT, University of Bristol. http://www.ilrt.bris.ac.uk/\nTel +44(0)117 9287088 Fax +44 (0)117 9287112 http://ioctl.org/jan/\nUnfortunately, I have a very good idea how fast my keys are moving.\n\n\n\n"
        },
        {
            "subject": "RE: &quot;Warning: Blogs Can Be Infectious&quot",
            "content": "Infected ;-)\n\nhttp://dannyayers.com/archives/002318.html \n\n\n\n"
        },
        {
            "subject": "owl:FunctionalProperty questio",
            "content": "Hi everyone,\n\njust a quick question, hope someone can answer this for me :\n\nIf a property P is a FunctionalProperty, are sub-properties of P also\nnecessarily Functional Properties?\n\nCheers,\n\nAl.\n\n---\nAlistair Miles\nResearch Associate\nCCLRC - Rutherford Appleton Laboratory\nBuilding R1 Room 1.60\nFermi Avenue\nChilton\nDidcot\nOxfordshire OX11 0QX\nUnited Kingdom\nEmail:        a.j.miles@rl.ac.uk\nTel: +44 (0)1235 445440\n\n\n\n"
        },
        {
            "subject": "Re: owl:FunctionalProperty questio",
            "content": "Miles, AJ (Alistair) wrote:\n\n> just a quick question, hope someone can answer this for me :\n> \n> If a property P is a FunctionalProperty, are sub-properties of P also\n> necessarily Functional Properties?\n\nYes.\n\nSuppose Q is a subPropertyOf P and suppose you have:\n\n   X Q V1 .\n   X Q V2 .\n\n  => (by subProperyOf)\n\n   X P V1 .\n   X P V2 .\n\n  => (by P being functional)\n\n   V1 = v2\n\nHence Q is a FunctionalProperty.\n\nCheers,\nDave\n\n\n\n"
        },
        {
            "subject": "[seweblist] ESWS2004 registration is now open (fwd",
            "content": "Hi everyone,\n\nthis is the week before the WWW conference so not great timing. SWADE have \na poster which Libby and Dan (?) are presenting so we are represented but I \nwould be interested in knowing if any other partners are planning on \nattending.\n\nCheers,\n\nKate..\n\n---------- Forwarded Message ----------\nDate: 17 March 2004 18:25 +0100\nFrom: Jos de Bruijn <jos.de-bruijn@deri.ie>\nTo: deri-all@www1-c703.uibk.ac.at, dip-all@informatik.uibk.ac.at, \nsekt@aifb.uni-karlsruhe.de, kweb-all@informatik.uibk.ac.at, \nontoweb-list@www1-c703.uibk.ac.at, seweb-list@www1-c703.uibk.ac.at, \nwww-rdf-logic@w3.org, www-ws@w3.org, www-rdf-interest@w3.org, \npublic-sws-ig@w3.org, www-rdf-rules@w3.org\nSubject: [seweb-list] ESWS2004 registration is now open\n\n** Apologies if you receive multiple copies of this message. **\n\nESWS2004 - 10-12 May 2004, Crete, Greece\n\nhttp://www.esws2004.org/\n\n\n*Early registration until April, 10 2004*\n\n\nDear colleagues,\n\nThe on-line registration First European Semantic Web Symposium is now open\nand early registration is open until April 10, 2004. You can find the\non-line registration on the web site: http://www.esws2004.org/\n\n\nLooking forward to seeing you in Crete!\n\nOn behalf of the Organizing committee,\n\n\n\nJos de Bruijn\n\n\n\n\n-- \nJos de Bruijn, http://homepage.uibk.ac.at/~c703239/\n+43 512 507 6475              jos.de-bruijn@deri.ie\n\nDigital Enterprise Research Institute (DERI)\nUniversity of Innsbruck,        http://www.deri.at/\n\n\n_______________________________________________\nseweb-list mailing list\nseweb-list@informatik.uibk.ac.at\nhttp://informatik.uibk.ac.at:2081/mailman/listinfo/seweb-list\n\n\n\n---------- End Forwarded Message ----------\n\n\n\n----------------------\nKate Sharp\nBiz/ed Service Manager, SWAD Europe and SWARA Project Manager\nUniversity of Bristol, 8-10, Berkeley Square,\nClifton, Bristol, BS8 1HH\nTel: 0117 9287189\nFax: 0117 9287112\n\nhttp://www.bized.ac.uk\nhttp://www.w3.org/2001/sw/Europe/\n\nKate.Sharp@bristol.ac.uk\n\n\n\n"
        },
        {
            "subject": "Announcing SKOS-Core 1.0  an RDF Schema for Thesaur",
            "content": "> Anouncing: SKOS-Core 1.0 - an RDF Schema for thesauri and related\n> knowledge organisation systems.\n> \n> The SKOS-Core 1.0 schema can be found at\n> \n> http://www.w3.org/2004/02/skos/core\n> \n> The SKOS-Core 1.0 Guide accompanying the schema can be found at\n> \n> http://www.w3.org/2001/sw/Europe/reports/thes/1.0/guide/\n> \n> Also, the website for the SWAD-Europe Thesaurus Activity has moved to\n> \n> http://www.w3.org/2001/sw/Europe/reports/thes/\n> \n> \n> SKOS stands for Simple Knowledge Organisation System.  The Goal of\n> SKOS-Core is to provide a framework for bringing existing knowledge\n> organisation systems such as thesauri and the semantic web together.  \n> \n> SKOS-Core exploits the features of RDFS and OWL to provide a flexible and\n> extensible framework within which different types of KOS can interoperate.\n> SKOS-Core is ideal for modelling thesauri, and can cope with the\n> variations commonly found in thesaurus design and structure. \n> \n> Yours on behalf of the Semantic Web Advanced Development for Europe\n> project [1],\n> \n> Alistair Miles.\n> Nikki Rogers.\n> Dave Beckett.\n>  \n> [1] SWAD-Europe <http://www.w3.org/2001/sw/Europe/>\n> \n> ---\n> Alistair Miles\n> Research Associate\n> CCLRC - Rutherford Appleton Laboratory\n> Building R1 Room 1.60\n> Fermi Avenue\n> Chilton\n> Didcot\n> Oxfordshire OX11 0QX\n> United Kingdom\n> Email:        a.j.miles@rl.ac.uk\n> Tel: +44 (0)1235 445440\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "In message <06c001c42eed$e904cfb0$fe78a8c0@Thomast40>, Thomas Bandholtz \n<thomas@bandholtz.info> writes\n\n>It never should by default!! A well established thesaurus easily counts\n>100.000s and more concepts! The requester (be it human or machine) must be\n>able to identify the thesaurus source without downloading the whole thing.\n>\n>I my personal vision, the \"whole thing\" *never* will be downloaded at once:\n>avoid redunancy, and what the hell are we doing here? ---\n>We are establish means to *link to specific* concepts and make clear where\n>the come from.\n\nAbsolutely.  Assuming that the machine-readable description of the \nthesaurus concept contains similarly-formatted references to its \n\"neighbouring\" concepts (or that there is a form of query you can issue \nwhich returns \"all concepts with a link to this one\"), then you can \nbrowse up and down the thesaurus tree structure from the starting \nconcept by issuing multiple requests - if that is what you wish to do.\n\nRichard Light\n-- \nRichard Light\nSGML/XML and Museum Information Consultancy\nrichard@light.demon.co.uk\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "In message <byJeXABEE3kAFAa1@light.demon.co.uk> on Sat, 1 May 2004, \nRichard Light <richard@light.demon.co.uk> wrote\n>Assuming that the machine-readable description of the thesaurus concept \n>contains similarly-formatted references to its \"neighbouring\" concepts \n>(or that there is a form of query you can issue which returns \"all \n>concepts with a link to this one\"), then you can browse up and down the \n>thesaurus tree structure from the starting concept by issuing multiple \n>requests - if that is what you wish to do.\n\nYes, and if the browsing is being done by a human there should also be \nprovision for browsing up and down\n(1) an alphabetical list of terms, starting at any specified point,  and\n(2) a list of terms containing a given character string.\n\nLeonard Will\n-- \nWillpower Information       (Partners: Dr Leonard D Will, Sheena E Will)\nInformation Management Consultants              Tel: +44 (0)20 8372 0092\n27 Calshot Way, Enfield, Middlesex EN2 7BQ, UK. Fax: +44 (0)870 051 7276\nL.Will@Willpowerinfo.co.uk               Sheena.Will@Willpowerinfo.co.uk\n---------------- <URL:http://www.willpowerinfo.co.uk/> -----------------\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "On Sat, 1 May 2004, Leonard Will wrote:\n\n>\n>In message <byJeXABEE3kAFAa1@light.demon.co.uk> on Sat, 1 May 2004,\n>Richard Light <richard@light.demon.co.uk> wrote\n>>concepts with a link to this one\"), then you can browse up and down the\n>>thesaurus tree structure from the starting concept by issuing multiple\n>>requests - if that is what you wish to do.\n>\n>Yes, and if the browsing is being done by a human there should also be\n>provision for browsing up and down\n>(1) an alphabetical list of terms, starting at any specified point,  and\n>(2) a list of terms containing a given character string.\n\nBeing able to browse by terms, as well as by concept relationships, is\nextremely important. The tools we as people have to determine whether we\nreally mean the same concepts are essentially words and pictures.\n\nOne thing that is intersting in implementations is being abel to see why a\ncertain term is not the preferred term for a concept - erhaps because it is a\npreferred term for another concept, or becausee it overlaps too much with its\nuse as an alternative term for another concept...\n\nCheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "* Thomas Bandholtz <thomas@bandholtz.info> [2004-04-30 22:01+0200]\n> \n> \n> Alistair > One thing a GET request for the thesaurus URI should definitely\n> return is a\n> > description of that thesaurus (i.e. name, version, creators, description\n> of\n> > scope and content etc.) although again whether that should be machine or\n> > human readable is open.\n> \n> Obviously *both* must be possible.We had megabytes of discussion on this in\n> the Topic Map community and elsewhere.\n\nSure, both are possible and will remain so. Our focus here, though, is\non the machine readable aspect (and on making machine interfaces that \nare adequate to support an interesting and usable range of human\ninterfaces).\n\n> The answer is very simple - there are humans, and there are machines\n> (software agents).\n> A service may decide to serve only one of them, but she may decide to serve\n> both.\n> She may even decide to serve several machine protocols or several human\n> readable layouts.\n> The consequence is that a singe URL is not enough.\n\nThat doesn't necessarily follow. HTTP supports content negotiation \n(see http://www.w3.org/Protocols/ ftp://ftp.isi.edu/in-notes/rfc2616.txt) \nwhich allows multiple representations of the same thing to be made \naccessible via a common URI.\n\n> We need pairs of protocol-URL such as\n> \n> HTML -> http://human.blah.org/thesaurus.html\n> WSDL -> http://services.blah.org/thesaurus.wsdl\n> DCMI -> http://dcmi.blah.org/thesaurus.xml\n> etc., etc.,\n> \n> these must be explictly *pairs* (protocol -> URL) as the domain name must\n> not contain any significant meaning itself (see RFC URI)\n\nWe can also use XML namespace mixing to make multiple kinds of\ninformation available within a common piece of markup (eg. RDF inside\nXHTML, or RDF styled into XHTML using XSLT). There are a lot of options\nto explore.\n\n> Alistair > The other question is, should the request for the thesaurus URI\n> also return\n> > the entire content of the thesaurus?  Personally I think no, but again I'm\n> > not sure about that.\n> \n> It never should by default!! A well established thesaurus easily counts\n> 100.000s and more concepts! The requester (be it human or machine) must be\n> able to identify the thesaurus source without downloading the whole thing.\n\nYep, I agree, downloading the entire database will be relatively rare.\n\n> I my personal vision, the \"whole thing\" *never* will be downloaded at once:\n> avoid redunancy, and what the hell are we doing here? ---\n> We are establish means to *link to specific* concepts and make clear where\n> the come from.\n\nSearch engine apps may well find value in downloading the entire thing.\n\nAs host to http://xmlns.com/wordnet/1.6/ I have noticed that some people\nhave tried to crawl the entire dataset with repeated HTTP requests,\npresumably so they can populate a local database for query etc. I'd like\nto have conventions for giving them the entire dataset in a more\nefficient manner.\n\nDan\n\n> Downloading and so duplicating a thesaurus is OK in some situations, but\n> this should be regarded as a very special use case.\n> \n> Thomas\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Dan: \n> Sure, both are possible and will remain so. Our focus here, though,is\n> on the machine readable aspect (and on making machine interfaces that\n> are adequate to support an interesting and usable range of human\n> interfaces).\n\nThat's exactly what I am looking for. Especially I am interested in a Web\nService solution.\n\nThomas: \n> > The consequence is that a single URL is not enough.\nDan: \n> That doesn't necessarily follow. HTTP supports content negotiation\n> (see http://www.w3.org/Protocols/ ftp://ftp.isi.edu/in-notes/rfc2616.txt)\n> which allows multiple representations of the same thing to be made\n> accessible via a common URI.\n\nI found http://www.w3.org/Protocols/rfc2616/rfc2616-sec12.html:\n\"Server-driven negotiation has disadvantages:\n      1. It is impossible for the server to accurately determine what\n         might be \"best\" for any given user, since that would require\n         complete knowledge of both the capabilities of the user agent\n         and the intended use for the response (e.g., does the user want\n         to view it on screen or print it on paper?).\"\n\nIMHO we only could think about server-driven negotiation here.\nThis does not sound very encouraging ...\nAgain, I would focus on a Web Service which at least has a WSDL, so the\nclient can see what she will get back.\n\nDan:\n> We can also use XML namespace mixing to make multiple kinds of\n> information available within a common piece of markup (eg. RDF inside\n> XHTML, or RDF styled into XHTML using XSLT). There are a lot of options\n> to explore.\n\nWell, here we have the SKOS Core RDF (2004-03-26) and the SKOS API WSDL/XML\nSchema (2004-04-29) serializations, or  namespaces.\nI thought about using the RDF in the Web Service, but API brings its own\nmodel, which is not fully consistent with the RDF semantically!\n\nIs this really what we need?\n\nWould be nice to have a *complete* information model independent of any\nsyntax (as they have it in ISO19115, where the XML Syntax is a second\nstandard ISO19139).\n\n\nThomas\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Thomas Bandholtz writes:\n\n> Dan: \n> > That doesn't necessarily follow. HTTP supports content negotiation\n> > (see http://www.w3.org/Protocols/\n> > ftp://ftp.isi.edu/in-notes/rfc2616.txt) which allows multiple\n> > representations of the same thing to be made accessible via a\n> > common URI.\n> \n> I found http://www.w3.org/Protocols/rfc2616/rfc2616-sec12.html:\n> \"Server-driven negotiation has disadvantages:\n>       1. It is impossible for the server to accurately determine what\n>          might be \"best\" for any given user, since that would require\n>          complete knowledge of both the capabilities of the user agent\n>          and the intended use for the response (e.g., does the user \n>          want to view it on screen or print it on paper?).\"\n> \n> IMHO we only could think about server-driven negotiation here.\n> This does not sound very encouraging ...\n\nServer-side negotiation can be very effective in combination with the\nAccept headers.\n\nFor example:\n\n    GET /foaf/0.1/ HTTP/1.1\n    Host: xmlns.com\n    Accept: text/html\n\nreturns a description of FOAF in HTML, while\n\n    GET /foaf/0.1/ HTTP/1.1\n    Host: xmlns.com\n    Accept: application/rdf+xml\n\nreturns a schema in RDF/XML.\n-- \nDavid Menendez <zednenem@psualum.com> <http://www.eyrie.org/~zednenem/>\n\n\n\n"
        },
        {
            "subject": "FW: URI policy for thesaurus concept",
            "content": "While I agree with the desirability of enabling all these browse options\n(and also the option of downloading a whole thesaurus *only*\noccasionally) I don't follow the last para below, which seems to suggest\nthat one term may at the same time be a preferred term for one concept\nand a non-preferred term for another. If the thesaurus conforms with ISO\n2788, then each term must be unique, whether preferred or non-preferred.\nIf two concepts in the same thesaurus could be described by the same\nnatural-language word, then thesaurus terms may be concocted by adding\nqualifiers in parentheses, e.g. \"bridges (electrical)\" \"bridges (roads)\"\n\"bridges (teeth)\" etc. Any of these could be made either a preferred\nterm or a non-preferred term, depending on the needs. But other forms of\ncontrolled vocabulary do not always follow the same rule.\nStella\n\n*****************************************************\nStella Dextre Clarke\nInformation Consultant\nLuke House, West Hendred, Wantage, Oxon, OX12 8RR, UK\nTel: 01235-833-298\nFax: 01235-863-298\nSDClarke@LukeHouse.demon.co.uk\n*****************************************************\n\n\n\n-----Original Message-----\nFrom: public-esw-thes-request@w3.org\n[mailto:public-esw-thes-request@w3.org] On Behalf Of Charles\nMcCathieNevile\nSent: 01 May 2004 12:16\nTo: Leonard Will\nCc: public-esw-thes@w3.org; public-esw@w3.org\nSubject: Re: URI policy for thesaurus concepts\n\n\n\nOn Sat, 1 May 2004, Leonard Will wrote:\n\n>\n>In message <byJeXABEE3kAFAa1@light.demon.co.uk> on Sat, 1 May 2004, \n>Richard Light <richard@light.demon.co.uk> wrote\n>>concepts with a link to this one\"), then you can browse up and down \n>>the thesaurus tree structure from the starting concept by issuing \n>>multiple requests - if that is what you wish to do.\n>\n>Yes, and if the browsing is being done by a human there should also be \n>provision for browsing up and down\n>(1) an alphabetical list of terms, starting at any specified point,  \n>and\n>(2) a list of terms containing a given character string.\n\nBeing able to browse by terms, as well as by concept relationships, is\nextremely important. The tools we as people have to determine whether we\nreally mean the same concepts are essentially words and pictures.\n\nOne thing that is intersting in implementations is being abel to see why\na certain term is not the preferred term for a concept - erhaps because\nit is a preferred term for another concept, or becausee it overlaps too\nmuch with its use as an alternative term for another concept...\n\nCheers\n\nChaals\n\n\n\n"
        },
        {
            "subject": "Re: FW: URI policy for thesaurus concept",
            "content": "On Mon, 3 May 2004, Stella Dextre Clarke wrote:\n\n>\n>While I agree with the desirability of enabling all these browse options\n>(and also the option of downloading a whole thesaurus *only*\n>occasionally) I don't follow the last para below, which seems to suggest\n>that one term may at the same time be a preferred term for one concept\n>and a non-preferred term for another. If the thesaurus conforms with ISO\n>2788, then each term must be unique, whether preferred or non-preferred.\n\nOne of the points is the if.  If everybody followed all applicable standards\nall the time many of us would be out of jobs. As you note below, there are\nmany real-world examples where people don't follow 2788, and some of these\narise in use cases such as the first attempt at merging two thesauri, or in\nproducing linguistic thesauri (like Roget's), or from time to time in\ncollaborative and dynamic development of a thesaurus.\n\nMy actual poinnt was that it would be interesting to have a note explaining\nwhy a particular term was not preferred. This can be done with rdfs:commment\n- for example, where developing a glossary for use in W3C specifications it\nwould be helpful to note for other developers that I avoided the term\n\"relative unit\" as the preferred term for a concept because it was used by\nsomeone else to describe a different concept. Nonetheless, the term is often\nused to describe the concept I mean, and for a while it was a preferred term\n(before it had to be used in a larger community, where the clash became\napparent). So it is helpful if people can search via the term and find both\nconcepts.\n\ncheers\n\nChaals\n\n>If two concepts in the same thesaurus could be described by the same\n>natural-language word, then thesaurus terms may be concocted by adding\n>qualifiers in parentheses, e.g. \"bridges (electrical)\" \"bridges (roads)\"\n>\"bridges (teeth)\" etc. Any of these could be made either a preferred\n>term or a non-preferred term, depending on the needs. But other forms of\n>controlled vocabulary do not always follow the same rule.\n>Stella\n>\n>One thing that is intersting in implementations is being abel to see why\n>a certain term is not the preferred term for a concept - erhaps because\n>it is a preferred term for another concept, or becausee it overlaps too\n>much with its use as an alternative term for another concept...\n\n\n\n"
        },
        {
            "subject": "removed upcoming&#64;groups.msn.com from lis",
            "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nI was seeing a lot of mail bounces because the Upcoming address\nwas rejecting posts. I'm not quite sure what the site is, but the\naddress is unsubscribed for now.\n\nhttp://groups.msn.com/Upcoming\n\nDan\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.2.4 (GNU/Linux)\nComment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org\n\niD8DBQFAlid1PhXvL3Mij+QRAij/AJ0eXDG6r6CanjA2OEGuhXTPO2vYDACgn8b3\nbrckcVMphQtlBNPxos1rfS4=\n=Sz1t\n-----END PGP SIGNATURE-----\n\n\n\n"
        },
        {
            "subject": "Details Re: Image description workshop, Madrid 78 Jun",
            "content": "Hello all,\n\nthe registration is now open for this event, and there is a page full of\ndetails at http://www.w3.org/2001/sw/Europe/events/200406-img/ for your\nenjoyment. Please register before 1 June.\n\nMy thanks once again to the Ontology Engineering group at UPM for hosting\nthis event. Look forward to seeing some of you in Spain...\n\ncheers\n\nChaals\n\nOn Mon, 26 Apr 2004, Charles McCathieNevile wrote:\n\n>\n>Hi folks,\n>\n>more information will be forthcoming in the next couple of days, but there\n>will be a SWAD-Europe developers' workshop in Madrid (kindly hosted by\n>Universidad Politecnica de Madrid) on image description on the 7th and 8th of\n>June.\n>\n>This workshop will be open to anyone interested in the topic, primarily\n>targeted at developers who are working on RDF-based systems, or users of such\n>systems, and aiming to look at the state of the art, in particular whether\n>and how it has advanced since a similar-themed workshop in Bristol in\n>mid-2002, and at useful strategies and avenues for further development, or\n>avenues which it seems should be investigated further.\n\nCharles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136\nSWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22\n Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or\n W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Re: URI policy for thesaurus concept",
            "content": "Dan Brickley wrote:\n\n>* Bernard Vatant <bernard.vatant@mondeca.com> [2004-04-30 17:36+0200]\n>  \n>\n>>To go along with Dan ...\n>>\n>>I also prefer the / approach in principle because it defines more neatly the \"subject\n>>indicator\", but consider that e.g. OWL uses fragment identifiers to define classes and\n>>properties ...\n>>\n>>Will not people be confused with OWL elements defined by\n>>http://example.org/myontology#class001\n>>and SKOS concepts defined by http://example.org/myskos/concept001\n>>    \n>>\n>\n>Some RDF/RDFS/OWL vocabs end in a / and others end in a # and others do\n>other things. This is the current state of affairs. The confusion is\n>only a problem because these different approaches have different\n>technical and standards characteristics (and those aren't well\n>explained, currently).\n>  \n>\nThis calls for engineering guidelines, which probably means the issue \nshould be shunted onto the SWBPD WG.\n\n>>And having, e.g. for GEMET, over 8000 different resources/concepts, if you just want to\n>>download the whole stuff, hmm...\n>>Is not it more simple to have a / namespace for a whole SKOS scheme, and # for each\n>>concept in it?\n>>\n>>We've been through this in Published Subjects TC, without clear conclusion ...\n>>    \n>>\n>\n>I've a few years experience using the http://xmlns.com/wordnet/1.6/Cat\n>etc approach, and have to say it is useful. The ability to return a\n>useful chunk of information from a larger dataset is something I am\n>reluctant to give up. Surely in the future we'll have richer (SKOS API,\n>RDF DAWG etc) interfaces to these datasets, but the current approach can\n>be implemented with a simple filetree or CGI script, and has proved\n>reasonably popular.\n>  \n>\nYes, this approach is immediately useful. I suspect it would be sensible \nfor any future interfaces to retain the http://xmlns.com/wordnet/1.6/Cat \nkind of behaviour. This is akin to getting the concise bounded \ndescription of the resource, which as an RDF representation over http in \nRDF/XML seems to make a lot of sense. Similarly, for the root \"service\" \nURI it would probably be consistent, and make pragmatic sense for the \ndefault RDF representation returned to be a concise description of the \nservice rather than the whole caboodle. Having a recommended means of \nretrieving the whole dataset may well be useful, but I'm not sure how \nthis could be done without conflicting with general architectural \nrequirements. All that comes to mind is use of the same URI but content \nnegotiation for an \"application/rdf+kitchensink\" mime type.\n\nCheers,\nDanny.\n\n-- \n----\nRaw\nhttp://dannyayers.com\n\n\n\n"
        },
        {
            "subject": "SWADE April newsletter availabl",
            "content": "http://lists.w3.org/Archives/Public/public-esw-news/2004AprJun/0002.html\n\nthanks everyone,\n\nLibby\n\n\n\n"
        },
        {
            "subject": "Paper on  Modelling Agents and Knowledg",
            "content": "Attached is a paper which Alvaro and myself have just completed and\nsubmitted to\nThe Eleventh International Conference on Artificial Intelligence:\nMethodology, Systems, Applications\n- Semantic Web Challenges - AIMSA 2004, in September.\nhttp://www.aimsa2004.org/main.html <http://www.aimsa2004.org/main.html> \n\nComes under the WP6 - extension activity on modelling.  Currently much as\nsubmitted, but\nI'll reformat/modify it as a SWAD-E note in due course.   In the meantime,\ncomments welcome!\n(particularly if I have completely misunderstood OWL-S!).\n\nthanks\n\nBrian\n\n <<aimsa2004.zip>> \n\n\n\n\n\napplication/octet-stream attachment: aimsa2004.zip\n\n\n\n\n"
        },
        {
            "subject": "french servic",
            "content": "I apologize if you don't understand me perfectly (I'm French).\nWell, I subscribe to your list and I don't understand all you talk about but\nI feel that I don't understand why this list was created. Well, not\nimportant in facts but maybe you'll be able to answer my question.\nI write here a mail because of Xiti. I don't know if you've heard of this\nservice. It's French. The service is : you put a button \"Xiti\" on your site\nand you can have some details about your visitors (with some javascript).\nIt's free (but there is also a Premium service).\nWell, I try at this moment to validate my web site. I use Xiti and that's a\nbig problem for the Validator because Xiti doesn't respect at all the\njavascript standard, and we mustn't change the code (if we do, a robot will\nsay to Xiti there is a problem). And I can't build a code to do the same\nthing as Xiti (for example : build a script to say me if my visitors are in\n800 x 600 or 1024 x 768, if they are on Windows or Linux...). I will try of\ncourse but I don't thing it will be as pretty as Xiti's service.\nLike I wrote above, I don't know really if this list was create for this\nkind of problems.\nIf not, I apologize. But tell me !\nI thank you for reading my letter....\nAlan Picol\n(http://cyberalan.free.fr, in French of course !) :)\n\n\n\n"
        },
        {
            "subject": "CSS: Braille Media Typ",
            "content": "Hi all\n\nDoes anyone know what the current status of the braille media type is?\nCurrently it seems like only the print and aural media types have \nanything definite behind them and the print one is really great to use.\n\nIs there a free (or relatively inexpensive) device that can be used to \ntest an aural css?\n\nSorry, lots of questions :-)\n\nThanks\nJosh Campbell\n\nZYPE - Interface Design\nPhone: 03 963 3735\nMobile: 021 400 472\nWeb: www.zype.co.nz\n\n\n\n"
        },
        {
            "subject": "Internet Standards Organization",
            "content": "I just became the editor for Internet Standards Organizations in the \nOpen Directory.  The URL is \nhttp://dmoz.org/Computers/Internet/Organizations/Standards.  Let me know \nif you see something that doesn't fit or should be added.  Thanks.\n\n-- \nBrant Langer Gurganus\nDefault QA Contact, Mozilla Evangelism\nTechnician, Protonic.com\nWebmaster, troop545.cjb.net\nWebmaster, www.firecrafter.org\nWebmaster, www.msdpt.k12.in.us/etspages/ph\nJunior Assistant Scoutmaster, Troop 545\nEagle Scout, Boy Scouts of America\nMember, Internet Society\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: french servic",
            "content": "Hi,\n\nI'll get in touch off line with Alan in french and see how we can \ndiscuss with Xiti so that their system does not prevent web pages to \nvalidate.\n\nCheers from Paris, France,\n\n\n--Tristan\n\nAlan wrote:\n> I apologize if you don't understand me perfectly (I'm French).\n> Well, I subscribe to your list and I don't understand all you talk about but\n> I feel that I don't understand why this list was created. Well, not\n> important in facts but maybe you'll be able to answer my question.\n> I write here a mail because of Xiti. I don't know if you've heard of this\n> service. It's French. The service is : you put a button \"Xiti\" on your site\n> and you can have some details about your visitors (with some javascript).\n> It's free (but there is also a Premium service).\n> Well, I try at this moment to validate my web site. I use Xiti and that's a\n> big problem for the Validator because Xiti doesn't respect at all the\n> javascript standard, and we mustn't change the code (if we do, a robot will\n> say to Xiti there is a problem). And I can't build a code to do the same\n> thing as Xiti (for example : build a script to say me if my visitors are in\n> 800 x 600 or 1024 x 768, if they are on Windows or Linux...). I will try of\n> course but I don't thing it will be as pretty as Xiti's service.\n> Like I wrote above, I don't know really if this list was create for this\n> kind of problems.\n> If not, I apologize. But tell me !\n> I thank you for reading my letter....\n> Alan Picol\n> (http://cyberalan.free.fr, in French of course !) :)\n> \n\n\n-- \nNetscape Technology and Standards evangelist, Europe.\nhttp://developer.netscape.com/  : cross-browser techniques.\nhttp://www.nitot.com/standards/ : les standards en fran?ais.\nhttp://mozfr.mozdev.org/        : doc. francaise de Mozilla.\n\n\n\n"
        },
        {
            "subject": "New evangelism article open for review: &quot;Buy standards compliant web sites&quot",
            "content": "Greeting, standards lovers\n\nI'm in the process of writing an article trying to show why someone\nordering a web site to a web agency should definitely require standard\ncompliance in its final product.\n\nThis article probably needs more review and suggestions before being\n\"officially\" published. I would so appreciate if you could find some\ntime to review it:\n\"Buy standards compliant web sites\"\nhttp://www.w3.org/QA/2002/07/WebAgency-Requirements (Last modified\n$Date: 2002/08/05 15:43:58 $)\n\nLet me first thank Kim Nylander who did a very careful review of a\nprevious version of this document (I integrated the changes she\nproposed).\n\nPlease send any suggestions, comments and corrections to this list,\nexcept for spelling, grammar and more generally language errors that you\nshould send to me in private to not encumber the mailing list.\n\nThanks for your time,\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n"
        },
        {
            "subject": "Article - WebMonkey  Web Standard for Hard Time",
            "content": "Hi,\n\nInteresting article by Paul Boutin\n\n\"Web standards? You can't afford to ignore them anymore.\n\nJust two years ago, coding your site to the emerging guidelines from \nthe World Wide Web Consortium was next to impossible. After all, any \nsurfers were still saddled with browsers from the days when Netscape \nand Microsoft deliberately built incompatible products.\"\n\nat\n\nhttp://hotwired.lycos.com/webmonkey/templates/print_template.htmlt?meta=/webmonkey/02/33/index1a_meta.html\n\nAnother article will be released also soon on the W3C QA website as \nannounced by Jeffrey Zeldman in \nhttp://www.alistapart.com/stories/doctype/\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Introductio",
            "content": "Greetings!\n\nI just found out about this list from Terje over on www-validator and\ndecided to sign up.  I've read a few of the 'intro' posts from the\narchive and figured I'd introduce myself.\n\nI am a Web developer at Arizona State University, soon (19 August) to\nbecome a full-time doctoral student in modern European history.  I'll\nbe continuing to work on various Web sites here, but won't be full-time\nIT staff any more.  I anticipate actively developing both instructional\nand research Web projects for the whole of my academic career.\n\nI've been doing Web pages since 1995, and I remember how exciting the\nfirst Netscape browser was.  (I still have some nostalgia for the old\nNCSA Mosaic, but my browser of choice is now Galeon.)  I've never used\nWYSIWIG editors for real work -- there weren't any when I started doing\nHTML -- and my \"authoring tool\" is Vim.\n\nI am a passionate partisan of standards compliance (and that includes\nWCAG, not just XHTML/CSS) and Free (libre, not gratis) software, and am\ntherefore quite concerned about patent encumbering in future W3C\nrecommendations.\n\nMy latest interest is working with XML/XSLT.  I'd like to come up with\ntransformations that will allow secretaries to save openoffice.org XML\nfiles and have them automagically converted to servable XHTML (and some\nTeX variant for generating pretty-printable PDFs).\n\nThat's me -- a little background as to where my deranged rants will be\ncoming from ;)\n\n-- \nThanasis Kinias\nWeb Developer, Information Technology\nGraduate Student, Department of History\nArizona State University\nTempe, Arizona, U.S.A.\n\nAsh nazg durbatul?k, ash nazg gimbatul,\nAsh nazg thrakatul?k agh burzum-ishi krimpatul\n\n\n\n"
        },
        {
            "subject": "My city's HTML is valid, how about yours",
            "content": "Long story short:\n\nFood for thought : local communities, city hall, city library, school,\nuniversity, etc. might be a good target for punctual evangelism effort.\n\n\nLong story not so short:\n\nYesterday I visited my city's website: http://www.city.shibuya.tokyo.jp/\nYes, I know, it's all in japanese, but did you see the icons? Yes, the\npage is actually made with valid HTML and CSS.\n\nAt first I went \"wow, my city's cool, I always knew it!\". Then I figured\nout how pathetic it was to be enthusiast just because, for once, I had\nfound a valid webpage that wasn't owned/written by a geek.\n\nWhy do geeks validate their webpages? Because they're cool. Sure, sure.\nBut certainly they did that because they know this guy who has a friend\nwho knows someone that has been at a conference with a speaker who\nread a book by someone who once heard about the validator, or read an\narticle. Or something like that.\n\nThe point is, web geeks do validate because someone convinced them to do\nso. Of course \"web geeks\" are easier to convince than \"web designers\"\n(sorry if this sounds pejorative), but there are other ways to ease the\nevangelism work than \"good will\". Starting with proximity. It's always\neasier (sorry, this is my non-geek side speaking, won't happen again)\nto convince someone when you can chat with this person face-to-face, in\nfront of a coffee. Those of us who have tried to explain \"why this is\nthe right way\" by sending a 'nice, polite, informative e-mail with loads\nof links to comprehensive resources'(TM) know what I'm talking about.\n\nThe web doesn't want to grow up, because it's not funny becoming an\nadult when everyone remains a child. In other words, if we want to beat\nthe \"I don't care about valid HTML, no-one does\" logic, we need to find\na base of sites that are likely to cooperate. \"Public\" sites are a good\ntarget, for two reasons :\n - proximity : you can actually go see the person in charge of the web\n and offer to help (offer a coffee too, it helps ;)\n - quality constraints : it may sound manichean, but where the private\n   sector is driven by marketing (hence the \"go to hell, my customer\n   base uses IE5/NS4/your-browser-here\" typical answer), the public\n   sector has some obligations towards quality. An obvious example is\n   section 508 for accessibility of govt-funded sites in the USA.\n\nThere is space for a nice initiative where volunteers would (try to)\nconvince local authorities to improve the quality of their websites,\nand possibly helping them to do so (there's no better argument to\nconvince public authorities than benevolent work offers :).\n\nAnnex project would be (yes, again) writing a little paper with key\ninformation to explain to those \"people in charge\". I'm confident \n(maybe optimistic) that it wouldn't take a full business cases kit.\n\n\nThoughts, anyone?\n\nCheers. olivier.\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: My city's HTML is valid, how about yours",
            "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>Thoughts, anyone?\n\nYes. Clean this up a bit and publish it under a title along the lines of\n\"Think Globally, Act Locally\" (which is the essence of your essay). This,\nalong with Dom's \"Business Case\" paper, makes a good start at a community\npool of resources for evangelism.\n\n\n-- \nTerje, you are a sick and twisted individual, and I\nthink I speak for all of us when I say, \"Thank you!\"\n\n               -- John Gruber <gruber@barebones.com>\n\n\n\n"
        },
        {
            "subject": "Hohum, here goes news.com agai",
            "content": "http://news.com.com/2100-1023-949492.html\n\n\"Of primary concern to some Web developers is the W3C's warning that XHTML 2.0\nwill not be \"backward compatible\" with HTML 4.0 and XHTML 1.0. That alert has\nraised concern that billions of Web pages risk obsolescence unless they are\ntranslated to the new Web language.\"\n\nSomeone doesn't understand the idea of namespaces and doctypes then...\n\nBut, at least the article is positive towards XHTML in general.\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "Re: My city's HTML is valid, how about yours",
            "content": "On Mon, Aug 12, 2002, Terje Bless wrote:\n> Yes. Clean this up a bit and publish it under a title along the lines of\n> \"Think Globally, Act Locally\" (which is the essence of your essay). This,\n> along with Dom's \"Business Case\" paper, makes a good start at a community\n> pool of resources for evangelism.\n\nWhy not. Here's the article : http://www.w3.org/QA/2002/08/LocalAction\nStill quite draft-y and tainted with the \"mail\" tone but that's a start.\nComments on how to improve it welcome.\n\nThanks for the title, Terje :)\n\nRegards, olivier\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: New evangelism article open for review: &quot;Buy standards compliant web sites&quot",
            "content": "Salut Dom,\n\nOn Tue, Aug 06, 2002, Dominique Haza?l-Massieux wrote:\n> \"Buy standards compliant web sites\"\n> http://www.w3.org/QA/2002/07/WebAgency-Requirements\n\nHere's a quick review, with mixed general comments, proposed\nrewordings, etc. Participants to the list, feel free to say whether you\nagree or not with this review, and of course, feel free to send in your\nreview, too.\n\n\n* Abstract *\n\n[ ordering a web site to a Web Agency? ]\nYes, but it also may apply, in \"bigger\" companies/organisms, \nto the \"web or IT department\". Don't forget internal development\nsometimes use business logic (requirements, contract, deadlines, etc).\n\n[ open standards? ]\nHere I agree with a comment I saw some place else. Yes, we're\ntalking about open standards, but we're talking to decision-making\nexecutives. \"standards\" is certainly already a frightening word for\nthem, so maybe \"open standards\" is too much. I'd suggest you use it once\nor twice, but replace most occurences by \"standards'. \nSaves bandwidth, too :)\n\n[ level of quality for final product ]\nfor {the/a} final product?\n\n[ See also the specific requirements... ]\nThis sentence is... awkward. I don't know exactly why. At least\nI'd link \"specific requirements\" to #reqlist. But I feel there's \nsomething missing, as if \"also\" was \"in addition to...what?\". \n\nProposed rewording, as one paragraph.\n\"Adding open standards compliance to your requirements helps achieve a\nmore powerful, accessible, and maintainable final product, and leverages\nthe energies put into the standards creations. This document details\nthose benefits induced by the use of standards. See also the _specific \nrequirements_ that will help you achieve this goal.\"\n\n\n*Open Standards for the Web*\n\n[ tested by some of the leading experts ]\ndrop \"some of the\"?\n\n[ implemented by several developers ]\nThis is confusing, one could think \"so what, it's implemented \nby several people, not only one person alone...\", whereas the point is\nthere must be several interoperable implementations. I'd suggest\n\"implemented into several compatible products\" if you don't want to talk\nabout interoperability.\n\n[ develop consistent architectural principles across the time and technologies ]\nPlease clarify \"across the time and technologies\".\n\n[ your applications won't depend on a unique provider ]\nI'm not fond of \"provider\". Any idea for a better term?\n\n[ stuck with formats you don't have access to ]\nWell, *now* is the right moment to explain why you're talking \nabout _open_ standards. Using the terms _open_ standards will likely\ndisplease a few execs (\"you mean, like these open-source communists?\")\nBut on the contrary, speaking of \"black-box technologies you can't rely\non nor understand\" instead of \"formats you don't have access to\" might\nring a bell :)\n\n\n[ select from many tools from many different producers ]\nIs this done on purpose because you're talking about XQuery? \nI like \"choose\" better than \"select\". I would also say \"a wide range of\ntools\". Maybe worth adding, too, is the fact that these are very diverse\ntools, suiting various need, requirements, budgets, etc. The power of\nchoice, in some sense.\n\n[ the infamous feature creep ]\nInfamous who? Oh you mean feature creep[1], the result of\ncreeping featurism[2] a.k.a creeping featuritis[3] in its \"medical\"\nversion... OK. May be a good idea to add a link to the definitions for\nidiots like me who didn't know the term :).\n\n\n[1] http://info.astrian.net/jargon/terms/f/feature_creep.html\n[2] http://info.astrian.net/jargon/terms/c/creeping_featurism.html\n[3] http://info.astrian.net/jargon/terms/c/creeping_featuritis.html\n\n\n* What you should include in your requirements list *\n\nAnother possible rationale for CSS use is the power of alternate\npresentation mechanisms it offers.\n\nAnother possible rationale for PNG : patents, anyone? [4] [5]\n\n[4] http://www.forgent.com/company/press_room/in_the_news.shtml\n[5] http://lpf.ai.mit.edu/Patents/Gif/origCompuServe.html\n\n* Generally speaking *\n\nI love the article, it's well written, clear yet full of marketing-ish\nbuzz-talk such as \"technologies that already belong to the future\" (oh\nmy, oh my, where'd you get this one?) that are likely to please execs,\nor at least speak a language they're used to hear.\n\nOne arguments that doesn't seem to be developed, and may be worth\nit, is the fact that well-designed websites save bandwidth. \nfits in the \"Reduced maintenance costs\" section I guess. Tell\ndecision-makers to remember their hosting/network bills, and\nthen give the figures and arguments (was it Zeldman?) gave :\nstylesheet cached once and for all, no more <FONT COLOR=#000000\nFACE=TIMES_NEW_ROMAN_GOTHIC_WINGDINGS SIZE=2> and friends (yum) \nthat account for 20% of your web volume, etc.\n\nKeep up the good work.\nCheers, olivier\n-- \nOlivier Thereaux - W3C http://www.w3.org/People/olivier\n| http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "FYI: Why Web Standards Matte",
            "content": "Why Web Standards Matter - Carrie Bickner -- 7/15/2002\n\nhttp://libraryjournal.reviewsnews.com/index.asp?layout=article&articleid=CA232338&publication=libraryjournal\n\nCarrie Bickner argues that employing standards can make web sites \nmore accessible and save libraries both time and money\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "scripsit Karl Dubost:\n \n> Why Web Standards Matter - Carrie Bickner -- 7/15/2002\n> \n> http://libraryjournal.reviewsnews.com/index.asp?layout=article&articleid=CA232338&publication=libraryjournal\n> \n> Carrie Bickner argues that employing standards can make web sites \n> more accessible and save libraries both time and money\n\nKarl,\n\nThere seems to be a server problem (or maybe a standards problem? it's\nIIS/ASP) -- I'm getting a blank article at that URI.  (Galeon 1.2.5 on\nDebian 3.0.)\n\n(getting a HEAD on that URI shows a 302 to the same URI minus the\narticleid param . . .  that seems to be the problem)\n\nIs there another URI that actually serves the article?\n\n-- \nThanasis Kinias\nDoctoral Student, Department of History\nArizona State University\nTempe, Arizona, U.S.A.\n\nAsh nazg durbatul?k, ash nazg gimbatul,\nAsh nazg thrakatul?k agh burzum-ishi krimpatul\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": " >>Why Web Standards Matter - Carrie Bickner -- 7/15/2002\n >>http://libraryjournal.reviewsnews.com/index.asp?layout=article&articleid=CA232338&publication=libraryjournal\n> Is there another URI that actually serves the article?\n\nhttp://libraryjournal.reviewsnews.com/index.asp?layout=articlePrint&articleID=CA232338&publication=libraryjournal\n\nThe printer-friendly version, no HTTP redirects.\n\n--\nJan!\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "scripsit Jan!:\n> \n> >>Why Web Standards Matter - Carrie Bickner -- 7/15/2002\n> >>http://libraryjournal.reviewsnews.com/index.asp?layout=article&articleid=CA232338&publication=libraryjournal\n> >Is there another URI that actually serves the article?\n> \n> http://libraryjournal.reviewsnews.com/index.asp?layout=articlePrint&articleID=CA232338&publication=libraryjournal\n> \n> The printer-friendly version, no HTTP redirects.\n\nThanks, Jan.\n\n-- \nThanasis Kinias\nDoctoral Student, Department of History\nArizona State University\nTempe, Arizona, U.S.A.\n\nAsh nazg durbatul?k, ash nazg gimbatul,\nAsh nazg thrakatul?k agh burzum-ishi krimpatul\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "scripsit Jan!:\n> \n> >>Why Web Standards Matter - Carrie Bickner -- 7/15/2002\n> >>http://libraryjournal.reviewsnews.com/index.asp?layout=article&articleid=CA232338&publication=libraryjournal\n> >Is there another URI that actually serves the article?\n> \n> http://libraryjournal.reviewsnews.com/index.asp?layout=articlePrint&articleID=CA232338&publication=libraryjournal\n> \n> The printer-friendly version, no HTTP redirects.\n\nFor laughs, check out the output of running the W3C validator on that\ndocument:\n\n<http://validator.w3.org/check?uri=http%3A%2F%2Flibraryjournal.reviewsnews.com%2Findex.asp%3Flayout%3DarticlePrint%26articleID%3DCA%2B232338%26publication%3Dlibraryjournal&charset=%28detect+automatically%29&doctype=Inline>\n\n1. The article, which states \n> The first step in creating accessible sites is to make sure that you\n> are using well-formed XHTML.\nisn't XHTML at all; it's tag-soup MSHTML with some CSS slapped on.\n\n2. There's no DOCTYPE.\n\n3. Manually setting DOCTYPE to HTML 4.01 Transitional yields a slew of\nerrors.\n\nJust how does this sort of advocacy help the cause?\n\n-- \nThanasis Kinias\nDoctoral Student, Department of History\nArizona State University\nTempe, Arizona, U.S.A.\n\nAsh nazg durbatul?k, ash nazg gimbatul,\nAsh nazg thrakatul?k agh burzum-ishi krimpatul\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "At 5:21 -0700 2002-08-19, Thanasis Kinias wrote:\n>scripsit Karl Dubost:\n>\n>  > Why Web Standards Matter - Carrie Bickner -- 7/15/2002\n>>\n>> \n>>http://libraryjournal.reviewsnews.com/index.asp?layout=article&articleid=CA232338&publication=libraryjournal\n>>\n>>  Carrie Bickner argues that employing standards can make web sites\n>  > more accessible and save libraries both time and money\n>There seems to be a server problem (or maybe a standards problem? it's\n>IIS/ASP) -- I'm getting a blank article at that URI.  (Galeon 1.2.5 on\n>Debian 3.0.)\n\nYes I know I had to try two times before to get the article :)\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "At 5:56 -0700 2002-08-19, Thanasis Kinias wrote:\n>For laughs, check out the output of running the W3C validator on that\n>document:\n>\n><http://validator.w3.org/check?uri=http%3A%2F%2Flibraryjournal.reviewsnews.com%2Findex.asp%3Flayout%3DarticlePrint%26articleID%3DCA%2B232338%26publication%3Dlibraryjournal&charset=%28detect+automatically%29&doctype=Inline>\n\nThat's often the problem when the author is not the publisher. The \nonly the author can do is try to convince the people that it must be \ndeliver as standards. Unfortunately, the publisher usually doesn't \ncare or doesn't want to fix all the system for one person requesting \nit.\n\nBut maybe it's another way to ask for more standard, but will work \nonly with big voices. I don't come to your conference if your website \nis not standard.\n\nThe other side of it is we are in an educationnal phase, and the \nconference organizer can say, not a problem we'll ask for someone \nelse.\n\nSo what's the best?\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "On Mon, Aug 19, 2002, Thanasis Kinias wrote:\n> \n> For laughs, check out the output of running the W3C validator on that\n[...]\n> isn't XHTML at all; it's tag-soup MSHTML with some CSS slapped on.\n[...]\n> Just how does this sort of advocacy help the cause?\n\nThat's unpleasant indeed, doesn't look very serious, and I'm certain\nthat people against any form of validation/web standards will have an\neasy job to laugh at the article.\n\nBut think of it this way : the article is not published on the author's\nwebsite[1] (which itself is -hum- almost valid), and it's been written\nto convince librarians, including the people running the library\njournal, that they should follow the standards. I respect the author's\nchoice to publish the article on an invalid website rather than spending\nthe same amount of time trying to convince the \"library journal\" only.\nMakes sense to me.\n\nIn times of need for educational material about web standards, yes I'm\ndisappointed to see a good article on an invalid website, but it's\ncertainly better than no article at all, IMHO.\n\n[1] http://www.roguelibrarian.com/\n\n\nCheers, olivier\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "I forwarded a copy of the recent analysis/validation note to Carrie with \ncommiserations and the suggestion she send it along to the Library \nJournal and the company responsible for the \"Powered by\" logo in the \nleft-hand margin.\n\nThese content management systems can be a real challenge in terms of \nstandards and accessibility. In addition, all parties have so much \nvested in the \"solution\" in terms of money, ego and status, that the \nmessage tends not to be one they want to hear.\n\n            ...edN\n\nKarl Dubost wrote:\n> \n> At 5:56 -0700 2002-08-19, Thanasis Kinias wrote:\n> \n>> For laughs, check out the output of running the W3C validator on that\n>> document:\n>>\n>> <http://validator.w3.org/check?uri=http%3A%2F%2Flibraryjournal.reviewsnews.com%2Findex.asp%3Flayout%3DarticlePrint%26articleID%3DCA%2B232338%26publication%3Dlibraryjournal&charset=%28detect+automatically%29&doctype=Inline> \n>>\n> \n> \n> That's often the problem when the author is not the publisher. The only \n> the author can do is try to convince the people that it must be deliver \n> as standards. Unfortunately, the publisher usually doesn't care or \n> doesn't want to fix all the system for one person requesting it.\n> \n> But maybe it's another way to ask for more standard, but will work only \n> with big voices. I don't come to your conference if your website is not \n> standard.\n> \n> The other side of it is we are in an educationnal phase, and the \n> conference organizer can say, not a problem we'll ask for someone else.\n> \n> So what's the best?\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "On Monday, August 19, 2002, 1:34:48 PM, you wrote:\n> http://libraryjournal.reviewsnews.com/index.asp?layout=articlePrint&articleID=CA232338&publication=libraryjournal\n\nNot exactly the best article about standards ever, but something is\nbetter than nothing. It does make some very common mistakes however...\n\n\n\"Valid XHTML requires that every image on a web site includes\ndescriptive text that tells the user what the image is.\"\n\nNo, no, no. It doesn't. XHTML requires alt text on every image (but\nalt=\"\" is totally valid, and often needed) - and alt text is *not* a\ndescription of an image, it is the meaning. Putting a description in\nevery alt attribute often leads to confusing and over-verbose pages.\n\n\n\"XHTML also requires that headers, lists, and other structural tags be\nused so readers on assistive technology are presented with a coherent\ndocument that flows logically. \"\n\nXHTML doesn't require this either. This is an option you have. You can\nmark everything up with <pre> if you so wish, it would still be valid\nXHTML.\n\n\n\"Furthermore, as a light version of XML, XHTML will help developers\ntransition to full-blown XML, a richer markup language that will soon\nafford even greater interoperability to web sites.\"\n\nEh?? XHTML *is* full-blown XML. Why do people have such a problem with\nunderstanding this? XML isn't going to \"replace\" XHTML by any means.\n\n\n\"In XHTML, even \"empty\" tags like <br> and <img> must close themselves\nby including a space and a forward slash at the very end of the tag\"\n\nNot very good usage of \"must\". It is a good idea to, but you don't\n*have* to.\n\n\nYeh, I'm being picky. But I'm in a picky mood. So there :)\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "scripsit Tom Gilder:\n \n> Not exactly the best article about standards ever, but something is\n> better than nothing. It does make some very common mistakes however...\n\nThere seems to be some conflation of WCAG and XHTML.  I've encounted\nthis in my own work when I introduced valid XHTML, CSS, and WCAG\ncompliance as part of a Web accessibility initiative.  The whole effort\nhad a tendency to be reduced to \"CSS\" or \"ADA\" (the Americans with\nDisabilities Act) in some people's vocabulary.\n\n> \"Valid XHTML requires that every image on a web site includes\n> descriptive text that tells the user what the image is.\"\n> \n> No, no, no. It doesn't. XHTML requires alt text on every image (but\n> alt=\"\" is totally valid, and often needed) - and alt text is *not* a\n> description of an image, it is the meaning. Putting a description in\n> every alt attribute often leads to confusing and over-verbose pages.\n\nTrue, but the difference is subtle to someone first encountering the\nconcept of text alternatives.  I wouldn't be overcritical there, given\nthat it's written for a `layperson'.\n\n> \"XHTML also requires that headers, lists, and other structural tags be\n> used so readers on assistive technology are presented with a coherent\n> document that flows logically. \"\n> \n> XHTML doesn't require this either. This is an option you have. You can\n> mark everything up with <pre> if you so wish, it would still be valid\n> XHTML.\n\nThis is where I think she means WCAG, not XHTML.\n\n> \"Furthermore, as a light version of XML, XHTML will help developers\n> transition to full-blown XML, a richer markup language that will soon\n> afford even greater interoperability to web sites.\"\n> \n> Eh?? XHTML *is* full-blown XML. Why do people have such a problem with\n> understanding this? XML isn't going to \"replace\" XHTML by any means.\n\nProposed interview question for Web `designers': ``Please explain the\nrelationship among SGML, XML, HTML, and XHTML.''\n\nSince so few Web `experts' have any clue what SGML is, or what it has to\ndo with HTML, it's not surprising that the XML::XHTML relationship\nconfuses them.\n\n> \"In XHTML, even \"empty\" tags like <br> and <img> must close themselves\n> by including a space and a forward slash at the very end of the tag\"\n> \n> Not very good usage of \"must\". It is a good idea to, but you don't\n> *have* to.\n\nI don't understand you.  If it's X(HT)ML, empty elements (she conflates\nelements and tags here, too) _must_ be closed, whether as <br /> or\n<br></br>.  We prefer the former so ancient noncompliant browsers don't\nbarf.  But it must be one or the other, or it's not well-formed XML,\nmuch less valid XHTML.\n\n-- \nThanasis Kinias\nDoctoral Student, Department of History\nArizona State University\nTempe, Arizona, U.S.A.\n\nAsh nazg durbatul?k, ash nazg gimbatul,\nAsh nazg thrakatul?k agh burzum-ishi krimpatul\n\n\n\n"
        },
        {
            "subject": "Help welcome  Validator's &quot;tips&quot",
            "content": "Dear WAI EO working group and \"public-evangelist\" participants.\n\nFirst, since I think this is the first cross-post through these two\nlists, let me introduces each other, just in case:\n\nThe WAI Education and Outreach Working Group - http://www.w3.org/WAI/EO/\nhas been around for a long time (since 1998 IIRC) and has produced a lot\nof important resources for WAI education (I'm sure many of you know the\nWAI quicktips card, for example).\n\npublic-evangelist - http://lists.w3.org/Archives/Public/public-evangelist/\nis the (rather young) list of the Quality Assurance Interest Group's\nEO activities, born to host discussion and coordination about \"Web\nstandards Education and Outreach\" at large.\n\n\nNow to the point : about one year ago there was an little, yet\ninteresting initiative to add \"quick tips\" to the HTML Validator's\nresults. Since the validator is the first service at W3C in terms of\nhits, it is believed to be a very efficient EO service. \n\nSee : http://www.w3.org/2001/06tips/\n\nThe new validator, including this quicktips feature, will be sent\nfor beta testing in a few days, so now is, I believe, a good time to\nspeed up the quicktips initiative. Some submissions and ideas were\nsent already, and today a few tips are completed (many are still on a\n\"someday pile\").\n\nThe (rather straightforward) Quicktips submission process is given at : \nhttp://www.w3.org/2001/06tips/#process\n\nOn the same page is the list of completed tips, and a list of candidates\nfor future tips.\n\nI encourage everyone to have a look at this, and if you like, please\nsubmit a new tip (fully documented using the submission process, or just\nan idea) or write up one in the todo list and send it to the QAIG's\npublic list www-qa@w3.org.\n\n\nThank you very much,\nolivier\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: Help welcome  Validator's &quot;tips&quot",
            "content": "There is an excellent resource of tips put together by Mark Pilgrim at:\n\nhttp://diveintoaccessibility.org/\n\nperhaps some of these could be used - or a link to the site could \nbe added from the HMTL validator page.\n\n\n\n\n> \n> Dear WAI EO working group and \"public-evangelist\" participants.\n> \n> First, since I think this is the first cross-post through these two\n> lists, let me introduces each other, just in case:\n> \n> The WAI Education and Outreach Working Group - http://www.w3.org/WAI/EO/\n> has been around for a long time (since 1998 IIRC) and has produced a lot\n> of important resources for WAI education (I'm sure many of you know the\n> WAI quicktips card, for example).\n> \n> public-evangelist - http://lists.w3.org/Archives/Public/public-evangelist/\n> is the (rather young) list of the Quality Assurance Interest Group's\n> EO activities, born to host discussion and coordination about \"Web\n> standards Education and Outreach\" at large.\n> \n> \n> Now to the point : about one year ago there was an little, yet\n> interesting initiative to add \"quick tips\" to the HTML Validator's\n> results. Since the validator is the first service at W3C in terms of\n> hits, it is believed to be a very efficient EO service. \n> \n> See : http://www.w3.org/2001/06tips/\n> \n> The new validator, including this quicktips feature, will be sent\n> for beta testing in a few days, so now is, I believe, a good time to\n> speed up the quicktips initiative. Some submissions and ideas were\n> sent already, and today a few tips are completed (many are still on a\n> \"someday pile\").\n> \n> The (rather straightforward) Quicktips submission process is given at : \n> http://www.w3.org/2001/06tips/#process\n> \n> On the same page is the list of completed tips, and a list of candidates\n> for future tips.\n> \n> I encourage everyone to have a look at this, and if you like, please\n> submit a new tip (fully documented using the submission process, or just\n> an idea) or write up one in the todo list and send it to the QAIG's\n> public list www-qa@w3.org.\n> \n> \n> Thank you very much,\n> olivier\n> -- \n> Olivier Thereaux - W3C\n> http://www.w3.org/People/olivier | http://yoda.zoy.org\n> \n\n---------\ngrace.de-la-flor@bristol.ac.uk\nInstitute for Learning and Research Technology\nUniversity of Bristol\n8-10 Berkeley Square, Bristol BS8 1HH, UK\nTel: +44 (0)117 928 7184, Fax: +44 (0)117 928 7112\nhttp://www.ilrt.bris.ac.uk/ and http://www.ilrt.bris.ac.uk/id/ \n\n\n\n"
        },
        {
            "subject": "Updated version of &quot;Buy standards compliant web sites&quot",
            "content": "Le jeu 15/08/2002 ? 10:24, Olivier Thereaux a ?crit :\n> Here's a quick review, with mixed general comments, proposed\n> rewordings, etc. Participants to the list, feel free to say whether you\n> agree or not with this review, and of course, feel free to send in your\n> review, too.\n\nI've tried to integrate most of your comments, and most of those that I\nhave received in private:\nhttp://www.w3.org/QA/2002/07/WebAgency-Requirements\n\nA brief changelog:\n- diminished the number of \"open standards\"\n- changed the CSS layout techniques of the article itself to have a\nbroader audience\n- removed allusions to non web-site related technologies (essentially\nXML query) and clarified the usage of side cases one (XSLT, XML Schema)\n- added references to DOM and Ecmascript in the requirements list\n- stressed some other saving in maintenance and operational costs\n- some smaller clarifications.\n\nI consider that the article is mostly in its final form now, but I'm\nstill of course very interested in comments, suggestions and\ncorrections.\n\nThanks to those who read it, publicized it and/or sent comments!\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n"
        },
        {
            "subject": "Re: FYI: Why Web Standards Matte",
            "content": "On Tuesday, August 20, 2002, 5:56:25 AM, you wrote:\n> > \"In XHTML, even \"empty\" tags like <br> and <img> must close themselves\n> >  by including a space and a forward slash at the very end of the tag\"\n> > \n> > Not very good usage of \"must\". It is a good idea to, but you don't\n> > *have* to.\n> \n> I don't understand you.  If it's X(HT)ML, empty elements (she conflates\n> elements and tags here, too) _must_ be closed\n\nSorry, I was referring to \"must include a space\". Empty elements don't\n*have* to, if you aren't following the HTML backwards-compatible\nguidelines. It was an extremely picky comment though :)\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "Pushing for accessibility inside a financial company",
            "content": "I'm working for a UK based financial company. People in here are starting to\nwake up about accessibility, mainly because of the amendments to the\nDisability Discrimination Act, which requires FTSE100 companies to make\nreasonable attempts at making their website's compliant.\n\nThere's a lot of usability and design problems with our current website,\nJavascript dependant drop-down menus nested to four-levels deep, linking\nevery page to every other page (with no script independant fallback). Its\nthe design we were stuck with, because it was designed by an external\ncompany, and it was all paid for (The HTML is very presentational heavy). I\nhave been fighting from the very beginning about the usability of this\nwebsite, but marketeers being marketeers, they see only what they want to\nsee. :-(\n\nThe accessibility \"project\" in here is stuck largely with the perception\nthat all that's required is alt text on images and title attributes on\nlinks. Nothing about how our nested table layout design, and 56 layered\njavascript only menu hampers even the most basic accessibility requirements.\nWe're catering for the browser list of: Netscape 4, Internet Explorer 4,5,6\nand Netscape 6 on a PC only (previously decided that Mac browsers weren't\nworth supporting -- even though its the choice of mainstream media). The\naccessibility outside that range of browsers is close to non-existant (Lynx\nshows five lines of content, and two screens of \"navigation\" links).\n\nI don't believe we can add accessibility ontop of what we have, so I am\npushing strongly for a complete from the bottom up rebuild. Building first a\ncompletely accessible HTML structure, and only then adding enhancements like\nCSS and Javascript to those browsers that request it. That way the list of\nsupported browsers will not experience a degradation, and our content and\nservices is still fully accessible to other browsers and devices.\n\nNetscape 4, however, because of the bias that it has to be supported, I'm\nthinking about delivering a tables based layout for that browser alone. With\na templated approach to building a website, it will only involve a\nserverside browser sniff, and selecting a different template. I know the\nproblems about browser-sniffing, so by delivering a standards compliant\ntemplate to all browsers except those that identify themselves as Netscape 4\nshouldn't be too much of a danger.\n\nI've drafted up a discussion paper laying out my position. I've got a lot of\nvery useful material out of the glasshaus book \"Accessible Web Sites\", so a\nlot of the factual and legal arguments come out of this excellent work.\n\nMy current paper is sitting on:\nhttp://www.isolani.co.uk/articles/accessibility.html (I've removed the\ncompany name - in case someone gets funny). My argument is essentially that\na standards based approach is a better alternative to creating a fully\naccessible website than \"adding on accessibility\" to an already broken\nwebsite.\n\nAny comments, suggestions and advice will be greatly appreciated.\n\nThanks\nMike\n\n\n\n"
        },
        {
            "subject": "Re: Pushing for accessibility inside a financial company",
            "content": "scripsit Isofarro:\n> We're catering for the browser list of: Netscape 4, Internet Explorer 4,5,6\n> and Netscape 6 on a PC only (previously decided that Mac browsers weren't\n> worth supporting -- even though its the choice of mainstream media).\n\nThe good news is that if you're standards-compliant, the Mac and\nLinux/Unix browsers other than NS4 will be generally OK.  Opera is\na similar situation.\n\nThe bad news is that all versions of MSIE for Windows have broken\nstandards compliance, IE4 being very bad and IE6 still having serious\nproblems.  You'll need actually to test back to IE4 if you want to make\nsure things work with its bugs.\n\nAs far as serving a special page for NS4, do the `powers that be' demand\nthat the NS4 version be as `pretty' as the accessible version?  An easy\nsolution, if you use true XHTML 1.0 Strict with all presentation in\nexternal CSS files, is simply to hide the CSS from NS4 by exploiting the\n`media=\"all\"' bug.  Then the NS4 users will simply see a plain,\ngrey-background page with all the default settings.  You might even\ninclude a note (hidden to CSS-grokking browsers) suggesting that the\nuser upgrade to a standards-compliant browser.\n\n-- \nThanasis Kinias\nDoctoral Student, Department of History\nArizona State University\nTempe, Arizona, U.S.A.\n\nAsh nazg durbatul?k, ash nazg gimbatul,\nAsh nazg thrakatul?k agh burzum-ishi krimpatul\n\n\n\n"
        },
        {
            "subject": "Re: Pushing for accessibility inside a financial company",
            "content": "Hi,\n\nIsofarro wrote:\n\n>I'm working for a UK based financial company. People in here are starting to\n>wake up about accessibility, \n>\n[snip] on a(nother) web accessibility disaster\n\n>I've drafted up a discussion paper laying out my position. \n>\n>My current paper is sitting on:\n>http://www.isolani.co.uk/articles/accessibility.html (I've removed the\n>company name - in case someone gets funny). My argument is essentially that\n>a standards based approach is a better alternative to creating a fully\n>accessible website than \"adding on accessibility\" to an already broken\n>website.\n>\n>Any comments, suggestions and advice will be greatly appreciated.\n>\nFirst, this is a great article. I learned a lot with the \"legal history\" \nthing. This may be the kind of ammo to hit the marketeers with. :-)\n\nWhen you mention PDF not being accessible, you may want to be more \nspecific, as it looks like Adobe is making progress in this field\n\nsee http://www.adobe.com/products/acrobat/pdfs/pdfaccess.pdf ,\n http://access.adobe.com/ and http://www.pdfzone.com/news/101078.html\n\nWhen you mention that Javascript is needed for navigation, you may link \nto http://www.thecounter.com/stats/2002/April/javas.php , which states \nthat 11% of people do not use javascript while browsing. That would make \nmarketeers think, maybe. Oh wait, they decided not to support macs :-(\n\nCheers,\n\n\n--Tristan\nPS : sometimes I feel I'm not the only Don Quijote around ;-)\n\n-- \nNetscape Technology and Standards evangelist, Europe.\nhttp://developer.netscape.com/  : cross-browser techniques.\nhttp://www.nitot.com/standards/ : les standards en fran?ais.\nhttp://mozfr.mozdev.org/        : doc. francaise de Mozilla.\n\n\n\n"
        },
        {
            "subject": "Re: Updated version of &quot;Buy standards compliant web sites&quot",
            "content": "scripsit Dominique Haza?l-Massieux:\n \n> I consider that the article is mostly in its final form now, but I'm\n> still of course very interested in comments, suggestions and\n> corrections.\n\nDominique,\n\nI have some editorial suggestions (minor grammar/style fixes).  What\nwould be your preferred format for that?  I could send you (off-list)\nthe HTML source with <del> and <ins> elements marking changes, or an\nOpenOffice.org file with change history.\n\nOn a related note, are W3C documents like this meant to conform always to\nU.S. usage?  Is there a preferred style, i.e., Associated Press versus\nChicago Manual of Style versus American Psychological Association?\n\n-- \nThanasis Kinias\nDoctoral Student, Department of History\nArizona State University\nTempe, Arizona, U.S.A.\n\nAsh nazg durbatul?k, ash nazg gimbatul,\nAsh nazg thrakatul?k agh burzum-ishi krimpatul\n\n\n\n"
        },
        {
            "subject": "Re: Pushing for accessibility inside a financial company",
            "content": "----- Original Message -----\nFrom: \"Thanasis Kinias\"\n> As far as serving a special page for NS4, do the `powers that be' demand\n> that the NS4 version be as `pretty' as the accessible version?\n\nUnfortunately yes. I'm hoping that would be the only point I would need to\ncompromise on, and this special delivery of a tables based layout to live\nlong enough until Netscape 4 users have migrated to more standards compliant\nbrowsers, and quietly switch off this non-standard hack.\n\n> You might even\n> include a note (hidden to CSS-grokking browsers) suggesting that the\n> user upgrade to a standards-compliant browser.\n\nI agree in principle with your suggestion. But selling it to a\nmarketeer-driven company is a very tough sell, and I'd rather not let this\nparticular point hold back going down a complete accessibility from the\nground up approach. Sacrifice for the greater good!\n\nThanks,\nMike\n\n\n\n"
        },
        {
            "subject": "Re: Pushing for accessibility inside a financial company",
            "content": "----- Original Message -----\nFrom: \"Tristan Nitot\"\n> When you mention PDF not being accessible, you may want to be more\n> specific, as it looks like Adobe is making progress in this field\n>\n> see http://www.adobe.com/products/acrobat/pdfs/pdfaccess.pdf ,\n>  http://access.adobe.com/ and http://www.pdfzone.com/news/101078.html\n\nExcellent, thanks for the links. I think I'd best address the PDF situation\nin a separate article, and link them in. That way I can keep the focus on\naccessibility, whilst tackling some of the deeper issues on their own pages\nwithout distracting the main argument.\n\n> When you mention that Javascript is needed for navigation, you may link\n> to http://www.thecounter.com/stats/2002/April/javas.php , which states\n> that 11% of people do not use javascript while browsing. That would make\n> marketeers think, maybe. Oh wait, they decided not to support macs :-(\n\nJust the presence of \"the number\" as a percentage will make heads turn,\nespecially because its much higher than they first believed.\n\n\nThanks for the positive comments,\nMike\n\n\n\n"
        },
        {
            "subject": "show, don't sel",
            "content": "Some insightful and funny commentary on selling web standards to clients, \nif people haven't seen it already:\n\nhttp://www.zeldman.com/daily/0802c.html#evangeline\n\n\n\n"
        },
        {
            "subject": "Letter to the News.com editor publishe",
            "content": "After reading the recent story about the forthcoming Opera 7 on news.com, I felt it necessary to respond to some of the statements made by the one Web developer they interviewed. And they actually published the letter!\n\nPerhaps a few people will actually notice, and perhaps a few of those will actually think about the issue in greater depth than \"everyone should just code to IE and forget about the standards\".\n\nhttp://news.com.com/2009-1081-954874.html\n\nI'd urge others on this list to write letters when they see other articles that deserve similar rebuttal. If we just leave these out there unchallenged, most of the readers will just assume that's the way everybody thinks.\n\n\n\n\n\napplication/x-pkcs7-signature attachment: smime.p7s\n\n\n\n\n"
        },
        {
            "subject": "[Article] Web Quality for your website",
            "content": "A new article for you.\n\nAll comments are welcome.\n\n**************************\nHere you will find easy, painless techniques and ideas to improve \nyour Web site quality and make your Web site valid. This document is \nintended for HTML users, developers working on Web applications, and \nWeb masters.\n\nMost of the Web sites on the Web are not valid. We may assume that \nthis is the case for 99% of the Web pages, but there are no \nstatistics to support this. It would be interesting to run a survey \nto prove that this case is indeed true.\n\nWhy?\n\nhttp://www.w3.org/QA/2002/04/Web-Quality\n\n\n-- \nKarl Dubost - http://www.la-grange.net/\nPr?s de vous, madame, oubliant les cieux,\nL'astronome ?tonn? se trouble;\nC'est dans l'?clat caressant de vos yeux,\nQu'il avait cru trouver l'?toile double.\n\n\n\n"
        },
        {
            "subject": "Re: [Article] Web Quality for your website",
            "content": "At 1:27 -0400 2002-08-26, Karl Dubost wrote:\n>A new article for you.\n\nI should not post at 1:30am... I have posted with my personal \naddress. Thank you to the people who already sent comments to me in \nprivate at the right address.\n\nIt's good to post the comments here, because when the ideas are \nshared and debated, we can improve our documents.\n\nThank you.\nPS: I'm also in holidays for 3 days now and for 10 days more :)\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "WebAgency requirement",
            "content": "In order to please a few people :-), i am posting here a few comments\nconcerning the web-agency requirements document\n(http://www.w3.org/QA/2002/07/WebAgency-Requirements).\nI've seen from the list archive that there has always been answers and i\npropably haven't read all of them, so forgive me if  some of my comments\nhave already been made.\n\n1. About \"open\" standards\nIs it necessary to emphasize that much on the *open* side of the standards ?\nIsn't \"standards\" by itself self-explanatory ? I understand that it's all\nabout distinguishing vendor standards and de facto standards from free\nstandards but who would really dare to call HTML a la Microsoft a true\nstandard ? Nobody would in my opinion and developpers are not that stupid.\n\nI think that more than the openness of standards, one should insit on the\nstandards period, and the standards, concerning Xnet technologies, are those\nfrom the W3C : HTML, XHTML, etc. At that point one can point out that they\nare also open standards, which means not being tied-up to a specific\nsoftware vendor, global adoptions by the software community and the vendors\n(which all take part to the standardization process), etc.\n\n2. About the client of the web-agency\nSince it's a document aimed at people managing external people from service\ncompanies, it's extremely important, i think, to emphasize on the fact that\nrelying on standards (by the way, why ommitting ecmascript and the DOM -\nanyway, are we priviledging accessibility or standards...) means easier\ntakeover of the developments by the client and easier modifications in the\nfuture if necessary. \nIt's much more easier to reverseenginneer a development that is both clean\nand developped following clear and well-established rules based on public\nspecifications than bloatware. Consequently, you're not dependent on your\nsupplier in case of future evolutions.\n\n3. About web-agency themselves\nShould notions such as XML or XQL appear in a document aimed at framing a\nweb-agency ? HTML, yes, CSS, yes, the rest no. Or we're talking about a\nbroader article that concerns all new technologies project managers : using\nXML doesn't automatically mean doing Web. I would not have a \"webization of\nIBM mainframe legacy\" project realized by a \"web-agency\" :-)\n\n4. About javascript \nThere is no mention of Ecmascript nor DOM. Once again, i feel like\nundergoing some WAI dictatorship. And this is truly harmful because i think\none of the biggest concerns of industrial web developments actually is\njavascript. And who really cares about full-compliant XHTML when it comes\nwith 500 lines of ununderstandable and inmaintenable javascript ?\n\nIn fact, rather than ignoring it, i think it is really important to point\nout what good javascript should be (while noticing than javascript is not a\ngoal by itself and that a well realized web site should be functionnal even\nif javascript is off).\n\nConclusion : positionning of the document\nBut more than that, i find the positionning of the article a bit awkward : i\ncan't really figure out who it is meant for... it's talking about\nweb-agencies, but it's also talking about XQL or XML-Schema which is, in my\nopinion, off-topic; it sings the praises of standards but they are only seen\nthrough the eye of the WAI. I would have prefered a true article about the\nWAG, their interest and the ways of following their requirements, rather\nthan an article that relies on the industrial interests of standards and\njust uses them to do WAI lobbying. \n\nVoil?\n\nRegards\n\nlaurent\n\n\n\n"
        },
        {
            "subject": "Re: WebAgency requirement",
            "content": "Le mar 27/08/2002 ? 06:25, Prevosto, Laurent a ?crit :\n> In order to please a few people :-), i am posting here a few comments\n> concerning the web-agency requirements document\n> (http://www.w3.org/QA/2002/07/WebAgency-Requirements).\n> I've seen from the list archive that there has always been answers and i\n> propably haven't read all of them, so forgive me if  some of my comments\n> have already been made.\n\nThanks a lot for your very detailed comments. I've tried to integrate\nthem in the last update of the document (since your comments came to me\nearlier in their French version :).\n\nIf you have time to read the new version, I'll be interested in knowing\nhow well it answers your comments.\n\nThanks again,\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n"
        },
        {
            "subject": "Webmaster Clu",
            "content": "I am going to try and start a webmastering club at my school to both \ntake over the website after I graduate at the end of this year and to \nteach quality webmastering.  If anybody comes through the Indianapolis, \nIndiana area, I would be interested in possibly inviting you to speak to \nus about webmastering with accessibility and the standards in mind if I \nget the club started.  If interested, email \nbrantgurganus2001@cherokeescouting.org.  Thank you.\n\n-- \nBrant Langer Gurganus\nEditor, Open Directory Project\nDefault QA Contact, Mozilla Evangelism\nTechnician, Protonic.com\nWebmaster, troop545.cjb.net\nWebmaster, www.firecrafter.org\nWebmaster, www.msdpt.k12.in.us/etspages/ph\nJunior Assistant Scoutmaster, Troop 545\nEagle Scout, Boy Scouts of America\nMember, Internet Society\n\n\n\n"
        },
        {
            "subject": "CSS and Netscap",
            "content": "We are in the process of redesigning a multiple company extranet and have\nlearned that a huge number of our users have Netscape 4.X as their browser.\nConsequently, some of our team is reluctant to design using standards (the main\nconcern is using CSS) since it will mess up the design we have already created.\nThe concerns include CSS becoming overhead and that keeping track of how the\nvarious workarounds for Netscape 4.x work and don't work, along with the\ninheritance issues, will take a huge amount of time. I would love to know what\nsome of our options are, but don't have the technical expertise to make a strong\ncase. Any advice?\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Short and simple:\nIf you want Netscape 4.X support, you do not want standards.\n\nThe Hacks'R'Us department is somewhere else.\n\nI apologize if that sounds crude, but welcome to the real world. Either you\nwant standards (with a small degree of customizations) or you do not want\nstandards and you can keep on using TABLE/FONT/IMG-spacer-based layouts.\n\nGive up Netscape 4 or give up standards.\n\n\nThor Larholm\n<URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n<URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n\n----- Original Message -----\nFrom: <Mike.Steckel@SEMATECH.Org>\nTo: <public-evangelist@w3.org>; <list@webdesign-L.com>\nSent: Thursday, August 29, 2002 7:18 PM\nSubject: CSS and Netscape\n\n\n>\n> We are in the process of redesigning a multiple company extranet and have\n> learned that a huge number of our users have Netscape 4.X as their\nbrowser.\n> Consequently, some of our team is reluctant to design using standards (the\nmain\n> concern is using CSS) since it will mess up the design we have already\ncreated.\n> The concerns include CSS becoming overhead and that keeping track of how\nthe\n> various workarounds for Netscape 4.x work and don't work, along with the\n> inheritance issues, will take a huge amount of time. I would love to know\nwhat\n> some of our options are, but don't have the technical expertise to make a\nstrong\n> case. Any advice?\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Re: CSS and Netscape (verification",
            "content": "Spam Arrest Sender VerificationCould someone unsubscribe Molly? Appareantly she does not want to receive messages from any sender to the list unless each sender verifies his email address - I wonder how many mails she even get from the list ;)\n\n  ----- Original Message ----- \n  From: Molly \n  To: public-evangelist-w3@jscript.dk \n  Sent: Friday, August 30, 2002 11:02 AM\n  Subject: RE: Re: CSS and Netscape (verification)\n\n\n  Molly here, \n    I'm protecting myself from receiving junk mail. \n    Just this once, click the link below so I can receive your emails.\n    You won't have to do this again. \n\n    http://spamarrest.com/a?68689800:53525 \n\n\n\n\n\n\n   \n\n\n  You are receiving this message in response to your email to molly@molly.com, a Spam Arrest customer. \n\n  Spam Arrest requests that senders verify themselves before their email is delivered. \n\n  When you click the above link, you will be taken to a page with a graphic on it. Simply read the word in the graphic, type it into the form, and you're verified. \n\n  You will only need to do this once per Spam Arrest customer. \n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "----- Original Message -----\nFrom: \"Thor Larholm\" public-evangelist-w3@jscript.dk\n\n[Significant user base using Netscape 4]\n> Give up Netscape 4 or give up standards.\n\nWhen it is noticed that a fair chunk of revenue comes from Netscape 4\nvisitors, the above choice is a no-brainer, and standards lose out. Is the\nbest way of advocating standards a typical brusque \"take it or leave it\"?\n\nTaking the importance of the Netscape 4 audience there are two ideas that\nare not of the best quality:\n1.) Tough, go away\n2.) Get a better browser\n\nA more practical and pragmatic approach would be to accept that catering for\nNetscape 4 is a prime requirement, and also to accept that standards based\nauthoring is the best way forward.\n\nTaking a workable technique as described by\nhttp://www.chipcom.net/searchengine1.php which is essentially delivering a\nfully standards compliant website to all user agents, with the exception of\nNetscape 4, give it what it wants.\n\nThe upshot of this technique is that there is no significant overhead in\ncatering for Netscape 4, no overhead in aiming for standards compliancy\nwhere it is important, and no brusque discrimination against browser users.\n\nWhen the time comes that Netscape 4 ceases to be a problem, switching of the\nNN4 browser sniff (sniffing by exception only) leaves a fully standards\ncompliant website, plus the infrastructure to deliver content in means other\nthan HTML and XHTML.\n\nTreat Netscape 4 as the exception it is, not by pretending it isn't\nimportant to visitors.\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "On Friday, August 30, 2002, at 03:59 AM, Thor Larholm wrote:\n> Short and simple:\n> If you want Netscape 4.X support, you do not want standards ....\n> I apologize if that sounds crude, but welcome to the real world .... Give \n> up Netscape 4 or give up standards.\n\nMike, and everyone else, this is absolutely incorrect.\n\nMany designer have been designing standards compliant websites that \ndisplay perfectly and work real swell in Netscape 4 for a couple of years \nnow. Especially using XHTML.\n\nSome believe you must sacrifice your visual design to be standards \ncompliant in NS4. This is untrue. One has nothing to do with the other.\n\nSome believe you must rely on hacks to be standards compliant in NS4. Like \nthe visual design, any hacks used have nothing to do with either NS4 or \nstandards.\n\nThere is no line of comparison that suggests non-standards can, in any way,\n  be better, more cost effective, more visually attractive, or better for \nyour customers than designing with standards.\n\nEven is you use NS4.\n\n--\nAustin\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": ">> We are in the process of redesigning a multiple company extranet and have\n>> learned that a huge number of our users have Netscape 4.X as their\n> browser.\n>> Consequently, some of our team is reluctant to design using standards \n>> (the\n> main\n>> concern is using CSS) since it will mess up the design we have already\n> created.\n\nIt is highly unlikely your design cannot be created in a way that complies \nwith standards. You can create 99% of all designs using standards *and* \nhave them work in NS4 with very, very little to no degradation in \nfunctionality or visual appearance.\n\nIf there is a conflict between your design and standards, you need to make \na *business* decision as to what is more important: your current design \n*as is*, or designing with standards.\n\nI would suggest that when you add everything up, standards are more \nimportant.\n\nIf this means your current design won't work, then 99% of the time, MINOR \nCHANGES TO THE DESIGN will allow you it to work with standards.\n\nI want to stress that almost *any* design is possible with standards, in \nall the major browsers and versions, all the way back to NS4.\n\n>> The concerns include CSS becoming overhead\n\nCSS placed in external files (as is best practice) actually cuts server \noverhead, both in data transfer and data storage. It also cuts manpower \ntime as it is easier to maintain the website as a whole. CSS = less \noverhead.\n\n>>  and that keeping track of how the\n>> various workarounds for Netscape 4.x work and don't work, along with the\n>> inheritance issues, will take a huge amount of time.\n\nNetscape 4 compliant CSS is well-documented. If you're limiting CSS to \nbasic text formatting and background colors (as most of your CSS will be, \ni.e. fonts, colors, size, bold, not bold, link colors, etc.), then you \nwill need NO HACKS and NO WORKAROUNDS to work in NS4.\n\nIf you used more advanced formatting, or even positioning, all of your CSS \nhacks and workarounds would be placed in a second stylesheet (as is best \npractice), so there would be NO problem tracking the workarounds.\n\nIf you or any of your team have any further questions regarding CSS, \nstandards, or getting your design to work with both, please feel free to \ncontact me off-list by email (austin@desiremedia.com), or to email the web \ndesign mailing list (list@webdesign-l.com).\n\n--\nAustin\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "> ----- Original Message -----\n> From: \"Thor Larholm\" public-evangelist-w3@jscript.dk\n>\n> [Significant user base using Netscape 4]\n>> Give up Netscape 4 or give up standards.\n>\n> When it is noticed that a fair chunk of revenue comes from Netscape 4\n> visitors, the above choice is a no-brainer, and standards lose out. Is the\n> best way of advocating standards a typical brusque \"take it or leave it\"?\n\nOk. Maybe I'm crazy. But what kinds of designs are you speaking about, the \nones that are impossible to achieve in NS4 using standards?\n\nMaybe some sample sites you could direct me to, or even screenshots or \nphotoshop mock-ups would be much appreciated.\n\nEither we're not on the same page concerning visual design, or we're not \non the same planet.\n\nThanks,\n--\nAustin\n\n\n\n"
        },
        {
            "subject": "Netscape 4 and ",
            "content": "Now that Netscape 7's been released, has anyone heard anything about the continued support of Netscape 4 by AOL?\n\nI know that NS4 will still be out there, but a supported and non suported product are two entirely different animals.\n\nJohn\n\n\n\n"
        },
        {
            "subject": "RE: CSS and Netscap",
            "content": "Thor Larholm [SMTP:public-evangelist-w3@jscript.dk] wrote:\n> Give up Netscape 4 or give up standards.\n\nFirst, it *is* possible to code for NN4 using valid, strict \n(X)HTML and CSS. Of course, you can't create the same \nsofisticated layouts and visually perfect designs as for modern \nbrowsers, but your documents can still be fully accessible and \nusable.\n\nSecond, is not HTML 4.0 Transitional a valid standard? We may \nconsider XHTML + CSS layout a better standard, however the \ntransitional specs are standards as well and there is nothing \nwrong with a table layout, provided it's done properly.\n\nBest,\n\nMarek Prokop\nhttp://www.sovavsiti.cz/css/\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "From: \"Austin Govella\" <austin@desiremedia.com>\n> You can create 99% of all designs using standards *and*\n> have them work in NS4 with very, very little to no degradation in\n> functionality or visual appearance.\n\nI will have to disagree on the level of degradation, a standards-based\nNS4-compatible design _will_ limit and cripple your choices severely and\nwill leave you with lesser options than what you had in the TABLE/FONT-based\nlayouts of the past.\n\n> Netscape 4 compliant CSS is well-documented.\n\nSo are (a minute subset of) its errors. Know your limits at\nhttp://richinstyle.com/bugs/netscape4.html\n\n> If you're limiting CSS to\n> basic text formatting and background colors (as most of your CSS will be,\n> i.e. fonts, colors, size, bold, not bold, link colors, etc.), then you\n> will need NO HACKS and NO WORKAROUNDS to work in NS4.\n\nThere we go again, limiting ourselfes to use a tiny subset of what is\navailable to cater for one deprecated browser - and even that subset will\nhave to be divided into several stylesheets, as NS4 _does_ have severe\nerrors with it and need workarounds or limitations imposed to even work at\nall, without crashing.\n\n> If you used more advanced formatting, or even positioning, all of your CSS\n> hacks and workarounds would be placed in a second stylesheet (as is best\n> practice), so there would be NO problem tracking the workarounds.\n\nPlease define \"more advanced formatting\".\n\nIn my case, I use no tables for my layouts as tables are indeed intended for\ntabular data. Instead, CSS positioning and floating through reuseable\nclasses take their place, sometimes nesting themselves in an equal depth as\ntables would but nonetheless being managed centrally. Putting this in a\nsecond stylesheet that NS4 would not get would do the exact opposite of what\nyou're aiming for, since it would remove any and all layout from NS4 and\nleave it with plain basic text formatting. That does not exactly sound like\na design that works in NS4.\n\nWhat you think of as \"more advanced formatting\" is in my humble opinion the\ncrude and bare minimum support for basic formatting using standards.\nNetscape 4 will not be able to handle this.\n\nNetscape 4 is the only browser on the planet that you will leave behind if\nyou go for a standards XHTML/CSS-based layout. It has been a dying browser\nfor years now and several of its own generations have surpassed it. Let it\ndie peacefully instead of wasting your hardearned money.\n\n>From a business perspective, there is no reason to use 50% of your\nressources on an everdiminishing 5% of your users. If your client wants you\nto do double the work, I hope you are billing him for double the money.\nGoing back to real life, it's not even 5% globally, but 3%, and looking\nlocally you will find huge variations - as an example, Denmark has less than\n1% Netscape users - in total, with all versions combined.\n\nFor the ontopicness of the list, standards evangelism, we should really urge\nMike to go for the XHTML/CSS design - even if that means NS4 users will get\nno layout but only basic text formatting. After all, it can hardly cope with\nanything more advanced.\n\n\nThor Larholm\n<URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n<URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n\n\n\n"
        },
        {
            "subject": "Re: Netscape 4 and ",
            "content": "Netscape 4 is no longer supported and has not been for quite some time, the\nonly reason that minor upgrades are still released is due to a contractual\nagreement with some large companies that obligate Netscape (who outsourced\nthat part to a different company) to continually address any security issues\nthat are found.\n\nAt least, that's my understanding of the issue :)\n\n\nThor Larholm\n<URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n<URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n\n\n\n"
        },
        {
            "subject": "Re: Netscape 4 and ",
            "content": "From: <john.colby@btinternet.com>\n|\n| Now that Netscape 7's been released, has anyone heard anything about\nthe continued support of Netscape 4 by AOL?\n| I know that NS4 will still be out there, but a supported and non\nsuported product are two entirely different animals.\n\n\nSomeone just told me last week that NN4.8  had been released.\nSo it seems that there still is some support for the 4 versions out\nthere. I do not know what types of changes were made to this release\nversion.\n\nMozilla may be another or better option for the web designer/developer.\nThere are some nice added tools, and less of the packaging/promotion\ntype items that slow down or add weight to the netscape versions.\n\nRendering pages and support of items should be the same across the\nbrowsers.\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "----- Original Message -----\nFrom: \"Marek Prokop\" <mprokop@prokopsw.cz>\n> Thor Larholm [SMTP:public-evangelist-w3@jscript.dk] wrote:\n> > Give up Netscape 4 or give up standards.\n>\n> First, it *is* possible to code for NN4 using valid, strict\n> (X)HTML and CSS. Of course, you can't create the same\n> sofisticated layouts and visually perfect designs as for modern\n> browsers, but your documents can still be fully accessible and\n> usable.\n\nWe are in complete agreement on those points ;)\n\n> Second, is not HTML 4.0 Transitional a valid standard? We may\n> consider XHTML + CSS layout a better standard, however the\n> transitional specs are standards as well and there is nothing\n> wrong with a table layout, provided it's done properly.\n\nI think this is where I got off on the wrong foot on the interpretation with\nAustin. In my opinion (and personal as well as professional situation), we\nhave moved beyond HTML4 and into XHTML + CSS. The only browser we had to\nleave behind was Netscape 4, and considering that Denmark has less than 1%\nNetscape users (combined), that was hardly a difficult choice.\n\nOf course HTML 4 Transitional is still a valid standard, and if Mike wants\nNetscape 4 support he will most likely have to settle for it. I just hope he\nis now aware of the limitations and degredations that he willingly impose on\nhimself through that decision.\n\n\nThor Larholm\n<URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n<URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "> ----- Original Message -----\n> From: \"Austin Govella\" <austin@desiremedia.com>\n> Ok. Maybe I'm crazy. But what kinds of designs are you speaking about, the\n> ones that are impossible to achieve in NS4 using standards?\n\nAny design with a TABLE-less layout. I think our disagreement arose from\nwhat we consider viably usable standards in todays world, see my reply to\nMarek for more on that.\n\n\nThor Larholm\n<URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n<URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "> I will have to disagree on the level of degradation, a standards-based\n> NS4-compatible design _will_ limit and cripple your choices severely and\n> will leave you with lesser options than what you had in the \n> TABLE/FONT-based\n> layouts of the past.\n\nThor, I think you ferreted the disagreement out quite admirably. When you \nsay standards you mean no tables for layout. When I say standards I mean \nsimple tables for layout.\n\nI agree that in an ideal world, we would only use tables for data, but \ntables are a perfectly acceptable part of the XHTML 1.0 specification. You \ncan create NS4 compatible websites using XHTML 1.0 and CSS, without \nsacrificing your visual design.\n\n>> If you're limiting CSS to\n>> basic text formatting and background colors ....\n> There we go again, limiting ourselfes to use a tiny subset of what is\n> available to cater for one deprecated browser\n\nBut these limitations easily cover everything you could do with a font tag.\n  The font name (verdana, arial, times), the font size, the color of the \ntext, and bold or italic or both.\n\n>> If you used more advanced formatting, or even positioning, all of your \n>> CSS\n>> hacks and workarounds would be placed in a second stylesheet (as is best\n>> practice), so there would be NO problem tracking the workarounds.\n> Please define \"more advanced formatting\".\n\nCSS positioning and line-height are two that come to mind. Advanced in the \nsense that they're not reliably supported in NS4. As a side-note, \nline-height isn't *that* important. And the positioning can be handled by \ntables. Other formatting like borders, like line-height, are also not that \nimportant and degrade perfectly (to nothin, which isn't so bad).\n\n>> From a business perspective, there is no reason to use 50% of your\n> ressources on an everdiminishing 5% of your users.\n\nSimple tables with CSS formatting help avoid the above statistics.\n\n--\nAustin\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Hello Thor,\n\n\nYou wrote:\n> Short and simple: ifyou want Netscape 4.X support, you do not want\nstandards. The Hacks'R'Us department is somewhere else.\n I apologize if that sounds crude, but welcome to the real world. Either\nyou  want standards (with a small degree of customizations) or you do\nnot want  standards and you can keep on using\nTABLE/FONT/IMG-spacer-based layouts.\nGive up Netscape 4 or give up standards.\n\nAnd what must I give up now Netscape 4 or the  XHTML 1.1 standard\nwhen you look this page  even coded without tables for layout?\nhttp://www.groenlinkslelystad.nl/verkiezingen/gemeenteverkiezingen/progr\namma/inhoud/\n\nWhen you look the CSS you can see the image also float  in Netscape 4.7\n\nGreetings\nIneke van der Maat\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "While this is all true in the unvarnished sense, I'm finding that \nNetscape 4 is a useful target for what I would call \"base-line\" output.\n\nIn other words, it can be a good target for emulating text-only, \naccessible pages. This view of the content gives designers the \nopportunity to optimize the so called document order of the content to \nbe most accessible and usable by people who must/will use text-only or \nscreen-reader technology. Examples might be, placing banner graphics and \nmenu bars at the bottom of the document so that the text-only reader \nencounters the content immediately and doesn't have to sift through \nunnecessary material; a skip link can be inserted at the top or an \naccess key combination used to jump directly to menu options.\n\nAt the same time, the content is formatted such that no linking or \nnavigating functionality is lost to Netscape 4.x users. In other words, \nthe pages look like pages looked in 1989, at the beginning of it all. \nSometimes this is not necessarily a bad thing.\n\nOn the technical level this is accomplished by \"hiding\" the CSS styling \nmechanism from Netscape 4. Modern browsers, on the other hand, will see \nthe same base-line document but will organize the visual, cosmetically \nenhanced version according to the rules in the style-sheet.\n\nIf this approach is a non-starter for your people, then I'd say you have \na very difficult and, more importantly, very expensive project on your \nhands because virtually everything will have to be done twice, the Bv4 \n(BeforeVersion4) and the Av6 (Version 6 and beyond.)\n\n            ...edN\n\nThor Larholm wrote:\n> Short and simple:\n> If you want Netscape 4.X support, you do not want standards.\n> \n> The Hacks'R'Us department is somewhere else.\n> \n> I apologize if that sounds crude, but welcome to the real world. Either you\n> want standards (with a small degree of customizations) or you do not want\n> standards and you can keep on using TABLE/FONT/IMG-spacer-based layouts.\n> \n> Give up Netscape 4 or give up standards.\n> \n> \n> Thor Larholm\n> <URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n> <URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n> \n> ----- Original Message -----\n> From: <Mike.Steckel@SEMATECH.Org>\n> To: <public-evangelist@w3.org>; <list@webdesign-L.com>\n> Sent: Thursday, August 29, 2002 7:18 PM\n> Subject: CSS and Netscape\n> \n> \n> \n>>We are in the process of redesigning a multiple company extranet and have\n>>learned that a huge number of our users have Netscape 4.X as their\n> \n> browser.\n> \n>>Consequently, some of our team is reluctant to design using standards (the\n> \n> main\n> \n>>concern is using CSS) since it will mess up the design we have already\n> \n> created.\n> \n>>The concerns include CSS becoming overhead and that keeping track of how\n> \n> the\n> \n>>various workarounds for Netscape 4.x work and don't work, along with the\n>>inheritance issues, will take a huge amount of time. I would love to know\n> \n> what\n> \n>>some of our options are, but don't have the technical expertise to make a\n> \n> strong\n> \n>>case. Any advice?\n>>\n>>\n> \n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Web Standards embrace:\n\nHTML 4.01 Transitional Document\nHTML 4.01 Strict Document\nHTML 4.01 Frameset\nXHTML 1.0 Transitional Document\nXHTML 1.0 Strict Document\nXHTML 1.0 Frameset\nXHTML 1.1 Document\n\nAnything that is valid in any of these markup varieties is valid and standard compliant.\n\nAnd from http://www.w3.org/TR/REC-html40/struct/tables.html#h-11.1\n\n?Tables should not be used purely as a means to layout document content as this may present problems when rendering to non-visual media. Additionally, when used with graphics, these tables may force users to scroll horizontally to view a table designed on a system with a larger display. To minimize these problems, authors should use style sheets to control layout rather than tables.?\n\nShould, not must.\n\nSo layouts containing tables are valid if they pass the W3C validity tests. They may not be futureproof and have problems with browsers or other client devices, but what we?re talking here is W3C validity and not WAI accessibility.\n\nBut I?m looking to use table and frameless layouts ? and I?ll cater as best I can for NS4, but put a warning on my pages (in plain text) to this effect. But it is for me and for others a learning curve. Until the only languages in use are XHTML 1.1 and higher, then we have to embrace the standards we?re all so hot on, even if we think some of them are not disappearing as quickly as we like.\n\nRegards\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Re: Netscape 4 and ",
            "content": "At 5:50 AM -0500 8/30/02, Holly wrote:\n>Someone just told me last week that NN4.8  had been released.\n>So it seems that there still is some support for the 4 versions out\n>there. I do not know what types of changes were made to this release\n>version.\n\nIt was released, on or around August 22.  I have yet to install it.\nNetscape's release notes are available, although they (as usual) don't\nactually say anything much.\n\nhttp://wp.netscape.com/eng/mozilla/4.8/relnotes/windows-4.8.html\n\nI can't understand why they would release this ancient browser in the same\nweek as version 7.  Maybe it's a coincidence, or some larger scheme is\nafoot.  Ah Netscape, still an enigma...\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "At 12:51 PM +0200 8/30/02, Thor Larholm wrote:\n>...we have moved beyond HTML4 and into XHTML...\n\nI wanted to ask the group about this.  What version of (X)HTML should a\ncompetent web designer use this days?  Assuming that his/her design would\nwork in all versions.\n\nI've been reading a lot about XHTML and liking it, but is any compatibility\nsacrificed if I leave HTML behind and go straight to XHTML 1.1 for all my\nwork?  Will Netscape 4 survive this, thanks to the transitional\nbackwards-compatibility of XHTML?  Or is it safer, at this junction, to\nstill use HTML 4.0.1?\n\nI've being doing this gig since the early nineties, so I'm used to waiting\n(and waiting...) for good technology to be adopted across all pertinent\nbrowsers.  Is the time right for universal use of XHTML?  Or are there\nstill caveats?\n\nWondering...\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Joseph McLean wrote:\n\n>I wanted to ask the group about this.  What version of (X)HTML should a\n>competent web designer use this days?  Assuming that his/her design would\n>work in all versions.\n>  \n>\nI've never had problems with using XHTML for web-authoring.  I would \nstay away from XHTML 1.1 right now since it cannot technically be served \nas text/html.  XHTML 1.0 Strict is essentially the same thing and if the \nrules are followed, it can be served as text/html.\n\n-- \nBrant Langer Gurganus\nEditor, Open Directory Project\nDefault QA Contact, Mozilla Evangelism\nTechnician, Protonic.com\nWebmaster, troop545.cjb.net\nWebmaster, www.firecrafter.org\nWebmaster, www.msdpt.k12.in.us/etspages/ph\nJunior Assistant Scoutmaster, Troop 545\nEagle Scout, Boy Scouts of America\nMember, Internet Society\n\n\n\n"
        },
        {
            "subject": "W3C Home page switched to full CSS layou",
            "content": "Greetings,\n\nW3C switched today its home page to a full CSS layout instead of the\nprevious table-based one. See:\nhttp://www.w3.org/\n\nThe techniques used in this layout has been documented at:\nhttp://www.w3.org/2002/11/homepage\nIt is basically realized through the float property.\n\nAs you may know, using CSS for horizontal layout has some important\nbenefits:\n- respect of the HTML semantics (tables are really for tabular data)\n- better accessibility\n- better device scalability\n\nThe downside is that some non-CSS2 aware browsers do not render it as\nintended; the page keeps completely readable though.\n\nThe W3C Communication Team is interested in hearing comments on this\nchange on the publicly archived mailing-list site-comments@w3.org\n\n(which doesn't prevent us from discussing some related bits here :)\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "Dom Wrote:\n\n>W3C switched today its home page to a full CSS layout instead of the\n>previous table-based one. See:\n>http://www.w3.org/\n\nI'm very disappointed to see that it begins:\n<?xml version=\"1.0\" encoding=\"us-ascii\"?>\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n\nFirstly of course, it's XHTML, so SHOULD be being served as\napplication/xhtml+xml but is not. How do we evangelise W3C Notes if even\nthe W3 ignore the SHOULDs they contain?\n\nGiven that the bad decision has been made, the next thing to disappoint\nis the inclusion of the XML PI against the warning in Appendix C, showing\nthis text garbage to people using modern HTML viewers for no reason at\nall (ascii being a subset of utf-8, so it adds nothing) makes it seem\nthat to be valid and compliant excludes many modern User Agents.\n\nBeyond that, in what way is W3C an Acronym? Why are classes being used as\npurely presentational not semantic classes (e.g <span\nclass=\"invisible\"> )\n\nAlso, what's the point of:\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "Le jeu 05/12/2002 ? 18:04, Jim Ley a ?crit :\n> Dom Wrote:\n> \n> >W3C switched today its home page to a full CSS layout instead of the\n> >previous table-based one. See:\n> >http://www.w3.org/\n> \n> I'm very disappointed to see that it begins:\n> <?xml version=\"1.0\" encoding=\"us-ascii\"?>\n> <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n>     \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n> \n> Firstly of course, it's XHTML, so SHOULD be being served as\n> application/xhtml+xml but is not. How do we evangelise W3C Notes if even\n> the W3 ignore the SHOULDs they contain?\n\nIt is my intention to make sure this will evolve, thanks to the trick\ndocumented at\nhttp://lists.w3.org/Archives/Public/www-archive/2002Dec/0005.html\n\nBut we need some wider experiment before that (as you know, some quite\nwidespread browsers do not support application/xhtml+xml)\n \n> Given that the bad decision has been made, the next thing to disappoint\n> is the inclusion of the XML PI against the warning in Appendix C, showing\n> this text garbage to people using modern HTML viewers for no reason at\n> all (ascii being a subset of utf-8, so it adds nothing) makes it seem\n> that to be valid and compliant excludes many modern User Agents.\n \nThanks, that needs to be fixed, indeed!\n\n> Beyond that, in what way is W3C an Acronym?\n\nIt is, W3C stands for World Wide Web Consortium. It's not a standard\nacronym, but remembers that's the point of using <acronym> and <abbr> is\nto help people understanding the underlying text, much more than to\ndetermine if something is an acronym, an abbreviation, a geekism, etc.\n\n> Why are classes being used as\n> purely presentational not semantic classes (e.g <span\n> class=\"invisible\"> )\n\nHmm... Aren't you overstating this a bit? Besides \"invisible\" (which is\nindeed presentational, see below), I see: banner, bannerLink, navBlock,\nnavhead, navlink, etc. that do rely on a semantic structure.\n\nMore generally, I could tell you that the fact the class is called\n\"invisible\" doesn't mean anything, but in the mind of the conceptor of\nthe page. What if I told you that by class=\"invisible\" we meant \"links\nto skip navigation blocks\"?\n\nI agree that's the name is probably not very well chosen, but I do think\nthat the discussion on class names is moot, since they are only tokens\nfor computer, not for humans.\n\nThanks for your comments,\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "\"Jim Ley\" <jim@jibbering.com>\n\n[aplogies, trying, and failing to get the hang of the new email proggy)\n\n> Also, what's the point of:\n\n<input type=\"hidden\" id=\"searchW3C\" name=\"sitesearch\" checked=\"checked\"\nvalue=\"w3.org\" /><input type=\"hidden\" name=\"domains\"\nvalue=\"w3.org\" /><input type=\"hidden\" id=\"searchWWW\" name=\"sitesearch\"\nvalue=\"\" />\n\nTwo hidden form values with the same name, but different values and\ndifferent id's?\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": ">Le jeu 05/12/2002 =E0 18:04, Jim Ley a =E9crit :\n>> Firstly of course, it's XHTML, so SHOULD be being served as\n>> application/xhtml+xml but is not. How do we evangelise W3C Notes if\neven\n>> the W3 ignore the SHOULDs they contain?\n>\n>It is my intention to make sure this will evolve, thanks to the trick\n>documented at\n>http://lists.w3.org/Archives/Public/www-archive/2002Dec/0005.html\n\nMy browsers sends accept headers including \"application/xhtml+xml; q=0\"\nThere's nothing more I can do as a client to make it clear that I do not\nsupport, and therefore cannot render XHTML in an appropriate manner, I do\nsupport text/html.  Why will the W3 not send me an HTML representation of\ntheir homepage, why insist on XHTML 1.0?\n\n>But we need some wider experiment before that (as you know, some quite\n>widespread browsers do not support application/xhtml+xml)\n\nIndeed, and many do not support  application/x-chickens  that's why we\nhave the accept-headers!  There's no lack of browser support of HTML 4.01\nso, indeed it's difficult to find a UA that will have any problems with\nit unlike the xhtml, why not serve it?  Rather than work at trying to\nmatch Appendix C, which as we see later, is already causing difficulties.\n\n>> Beyond that, in what way is W3C an Acronym?\n\n>It is, W3C stands for World Wide Web Consortium. It's not a standard\n>acronym, but remembers that's the point of using <acronym> and <abbr> is\n>to help people understanding the underlying text, much more than to\n>determine if something is an acronym, an abbreviation, a geekism, etc.\n\nIt is an abbr surely, so use the appropriate markup - I do not want my\nspeech agent to attempt to say \"W3C\" as a word, it's not going to do a\ngood job of it.  I realise that you're using acronym for browser support,\nbut I see no point in breaking the semantic meaning of a element purely\nto get a particular visual representation in some browsers.\n\n>> Why are classes being used as\n>> purely presentational not semantic classes (e.g <span\n>> class=3D\"invisible\"> )\n\n>More generally, I could tell you that the fact the class is called\n>\"invisible\" doesn't mean anything, but in the mind of the conceptor of\n>the page. What if I told you that by class=3D\"invisible\" we meant \"links\n>to skip navigation blocks\"?\n\nOf course, my issue is that the name is suggestive of a particular visual\nrendering, and that the span in question was there purely for the\npresentational effect.\n\n<span class=\"invisible\"><a class=\"bannerLink\"\ntitle=\"Skip introductory links and the mission statement\"\nhref=\"#technologies\">Skip to Technologies</a> | </span>\n\nIs the pipe character really useful to the situation where's it would be\n\"invisible\", would not normal whitesapce be better, especially as the\nUA's I'm aware of will distinguish the link as a link in any case, so\n\n<a class=\"bannerLink invisible\"\ntitle=\"Skip introductory links and the mission statement\"\nhref=\"#technologies\">Skip to Technologies </a>\n\nWould've been appropriate and would've included purely presentational\nelements, this is what's done elsewhere with the <p class=\"invisible\">\n... </p>  I also think another name would've been appropriate just to\nstop people thinking it was presentational.\n\nMy criticisms were intentionally petty, the page has to be beyond any\ncomplaint.\n\nCheers,\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "Jim, people who live in glass houses should not throw stones.\n\nI congratulate the W3C on the change.\n\nRandy.\n\n\n\n\nRandy Reames  Web Developer  Midwest Energy\nOS X and GNU/Linux  Web Standards and Accessibility.\nblog: www.reames.org   work: www.mwenergy.com  \n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "http://www.w3c.org/\n\nredo and techniques at:\nW3C Home Page Table-less Layout: HOWTO and FAQ\nhttp://www.w3.org/2002/11/homepage\n\n===\n\nThanks Dominique.\nIt does not look that much different, but what looks different even\nlooks even better.\nGlad to see the changes, too.\n\nI will be passing around the news.\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "Jim Ley wrote:\n\n>  Also, what's the point of:\n>\n>  <input type=\"hidden\" id=\"searchW3C\" name=\"sitesearch\" checked=\"checked\"\n>  value=\"w3.org\" /><input type=\"hidden\" name=\"domains\"\n>  value=\"w3.org\" /><input type=\"hidden\" id=\"searchWWW\" name=\"sitesearch\"\n>  value=\"\" />\n>\n>  Two hidden form values with the same name, but different values and\n>  different id's?\n\nThese are Google input items. The last two were radio buttons, formerly\n\"Search w3.org\" and \"Search WWW\". I have removed the last one and find\nthat search functions. Thank you for the report.\n\n-- \nSusan Lesch           http://www.w3.org/People/Lesch/\nmailto:lesch@w3.org               tel:+1.858.483.4819\nWorld Wide Web Consortium (W3C)    http://www.w3.org/\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "\"Randy Reames\" <randy@reames.org>\n> Jim, people who live in glass houses should not throw stones.\n\nI'll gladly accept any feedback anyone wishes to give, and will debate any\nof the design compromises I have chosen, just as I hope others will debate\ntheir design choices, I feel the W3 need to explain the rather strange\ndesign choice to choose the poorly supported XHTML as text/html over HTML\n4.01 - if there are good reasons for it, then we need to know them so we\ncan include the same.\n\n> I congratulate the W3C on the change.\n\nCertainly from an CSS perspective, and semantic layout itself it has much\nto be applauded.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "At 23:37 +0000 2002-12-05, Jim Ley wrote:\n>their design choices, I feel the W3 need to explain the rather strange\n>design choice to choose the poorly supported XHTML as text/html over HTML\n>4.01 - if there are good reasons for it, then we need to know them so we\n>can include the same.\n\nOne of the reason is called XSLT and RSS. If you have an XHTML page \n(XML) you can easily produce an RSS feed of your page.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": " \"Karl Dubost\" <karl@w3.org>\n> At 23:37 +0000 2002-12-05, Jim Ley wrote:\n> >their design choices, I feel the W3 need to explain the rather strange\n> >design choice to choose the poorly supported XHTML as text/html over\nHTML\n> >4.01 - if there are good reasons for it, then we need to know them so\nwe\n> >can include the same.\n>\n> One of the reason is called XSLT and RSS. If you have an XHTML page\n> (XML) you can easily produce an RSS feed of your page.\n\nAnd if you hane an XHTML version of your page you can easily produce a\nHTML 4.01 version of your page with XSLT.  The content-management and\nfinal form versions of the page do not need to be the same.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "At 10:11 06/12/2002 +0000, you wrote:\n\n\n>  \"Karl Dubost\" <karl@w3.org>\n> > At 23:37 +0000 2002-12-05, Jim Ley wrote:\n> > >their design choices, I feel the W3 need to explain the rather strange\n> > >design choice to choose the poorly supported XHTML as text/html over\n>HTML\n> > >4.01 - if there are good reasons for it, then we need to know them so\n>we\n> > >can include the same.\n> >\n> > One of the reason is called XSLT and RSS. If you have an XHTML page\n> > (XML) you can easily produce an RSS feed of your page.\n>\n>And if you hane an XHTML version of your page you can easily produce a\n>HTML 4.01 version of your page with XSLT.  The content-management and\n>final form versions of the page do not need to be the same.\n>\n>Jim.\n\n\nI'm really getting puzzled by al this insistence on HTML4.01. As I \nunderstood it, HTML4.01 is the last of the line of HTML recommendations by \nW3C, we're now onto XHTML 1.0 (an XML application) and XHTML 1.1. XHTML2.0 \nproposals have been published. So why try to tie into a dying legacy \nlanguage that has absolutely no future?\n\nRegards\n\nJohn\n\nAnd apologies to Jim - this should originally have gone to the list \n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "\"John Colby\" <John.colby@btinternet.com>\n> At 10:11 06/12/2002 +0000, you wrote:\n> >And if you hane an XHTML version of your page you can easily produce a\n> >HTML 4.01 version of your page with XSLT.  The content-management and\n> >final form versions of the page do not need to be the same.\n> >\n>\n> I'm really getting puzzled by al this insistence on HTML4.01. As I\n> understood it, HTML4.01 is the last of the line of HTML recommendations\nby\n> W3C, we're now onto XHTML 1.0 (an XML application) and XHTML 1.1.\nXHTML2.0\n> proposals have been published. So why try to tie into a dying legacy\n> language that has absolutely no future?\n\nYou're not tying yourself into anything, your publishing a document\ntoday, XHTML has little support in the real world, HTML 4.01 has\nuniversal support, converting from XHTML 1.0 strict to HTML 4.01 strict,\nis a trivial machine conversion, that turns the XHTML document which will\nrender incorrectly in many browsers, into something that will render\ncorrectly in [basically] all.\n\nIt's a good idea to be creating your content in a form which contains as\nmuch semantics as you want, especially if as Karl suggests one of the\nthings you want to do is produce RSS feeds or other representations of\nthe same data. So absolutely creating XHTML versions of pages may be a\ngood idea (although I'd rather do it in an even more semantically rich\nlanguage like DocBook or XHTML 2.0 than vanilla XHTML 1.0).  There's no\npersuasive argument I've seen (which is why I'm trying to get a\ndiscussion in the evangelist list) that presenting XHTML as the FINAL\nFORM to the client is a good idea, it's simply not supported, and\nactually makes XSLT harder because you need to not do things which are\nperfectly valid in XML.\n\nConsider an XSLT or DOM approach which creates a br element, it's\nperfectly legal to create <br/>  however doing so will create numerous\nproblems, and wouldn't be \"as per Appendix C\".\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "John Colby wrote:\n> \n> I'm really getting puzzled by al this insistence on HTML4.01. As I \n> understood it, HTML4.01 is the last of the line of HTML recommendations \n> by W3C, we're now onto XHTML 1.0 (an XML application) and XHTML 1.1. \n> XHTML2.0 proposals have been published. So why try to tie into a dying \n> legacy language that has absolutely no future?\n> \n> Regards\n> \n> John\n> \n> And apologies to Jim - this should originally have gone to the list\n> \n\nJohn,\n\nPlease let me provide my viewpoint on this issue.\n\nThe page http://www.w3.org/ is served as text/html and as such really is \njust HTML. It will invoke the HTML parser in Mozilla and Netscape 7.0 \nand not the XML parser. You gain no real benefit from using XHTML \ncontent if the page is to be served as text/html.\n\nIn a reply to Jim, Dom wrote:\n\n> But we need some wider experiment before that (as you know, some quite\n> widespread browsers do not support application/xhtml+xml)\n\nTake a look at\n\nhttp://dev.bclary.com/w3/index.html   (served as text/html)\nhttp://dev.bclary.com/w3/index.xhtml  (served as application/xhtml+xml)\nhttp://dev.bclary.com/w3/index.xml    (text/xml)\n\nin Mozilla, Netscape 7.0, Opera 7 beta 1 and Internet Explorer 6.\n\nMozilla, Netscape 7.0, Opera 7 beta 1 will display each version \ncorrectly.  Internet Explorer can not display the page if it is served \nas anything but text/html.\n\n From my point of view, XHTML served as text/html is useless. So, why \nuse XHTML on this page ?\n\nBob\n\n\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "Dominique Haza?l-Massieux wrote:\n\n>Greetings,\n>\n>W3C switched today its home page to a full CSS layout instead of the\n>previous table-based one. See:\n>http://www.w3.org/\n>\n>The techniques used in this layout has been documented at:\n>http://www.w3.org/2002/11/homepage\n>It is basically realized through the float property.\n>  \n>\nBoth initiatives are great steps in the right direction. I understand \nthat in a perfect world these pages should be served using XML content \ntype, as stated in http://www.hixie.ch/advocacy/xhtml . But I also \nunderstand that in such a perfect world, non-perfect browsers would not \nexist.\n\nAnyway, I applaude the effort that makes the consortium's web site to be \nbetter aligned to the principles it preaches. not _perfectly_ aligned, \nbut still.\n\nKudos to the web team, and specifically, Dom.\n\nYou guys rock!\n\n\n--Tristan\n\n-- \nNetscape Technology and Standards evangelist, Europe.\nhttp://devedge.netscape.com/    : cross-browser  techniques.\nhttp://www.nitot.com/standards/ : les standards en fran?ais.\nhttp://mozfr.mozdev.org/        : doc. francaise de Mozilla.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "----- Original Message -----\nFrom: \"Jim Ley\" <jim@jibbering.com>\nTo: <public-evangelist@w3.org>\nSent: Friday, December 06, 2002 7:30 AM\nSubject: Re: W3C Home page switched to full CSS layout\n\n>  XHTML has little support in the real world,\n\nIE 5+, Netscape6+, Mozilla 1, Opera 6+, Lynx 2, all Gecko browsers...\nAll these and more support XHTML. That counts as \"little support\"? With all\ndue respect, please explain what qualifies for acceptable support?\n\nT.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": " \"Daniel\" <tdaniel@adetti.net>\n> >  XHTML has little support in the real world,\n>\n> IE 5+,\n\nIE5 does not support application/xhtml+xml, it also only supports XHTML\nsent as text/html by virtue of its very liberal parser. (simply look at a\nserialisation of IE's DOM by\njavascript:alert(document.documentElement.outerHTML) or similar) you'll\nsee it's an HTML interpretation, not an XHTML one.\n\n> Netscape6+, Mozilla 1, Opera 6+, Lynx 2, all Gecko browsers...\n> All these and more support XHTML.\n\nNetscape 6+, Mozilla and Gecko support it - aren't they the same browser?\n\nSo yes, 3 browsers out of the 20+ still in development is a pretty poor\nsupport by any yardstick I use.\n\n> That counts as \"little support\"? With all\n> due respect, please explain what qualifies for acceptable support?\n\nWell IE support would be required as a minimum, IE and Mozilla cope with\nany old crap, don't mistake \"rendering any old crap\" with \"supporting\nXHTML\"\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "> Netscape 6+, Mozilla and Gecko support it - aren't they the same browser?\nEssentially, yes.\n\n> So yes, 3 browsers out of the 20+ still in development is a pretty poor\n> support by any yardstick I use.\n>\n> > That counts as \"little support\"? With all\n> > due respect, please explain what qualifies for acceptable support?\n>\n> Well IE support would be required as a minimum, IE and Mozilla cope with\n> any old crap, don't mistake \"rendering any old crap\" with \"supporting\n> XHTML\"\n\nGood points, all.\n\nStill, if browsers are rendering the XHTML properly, even if only because\nthere accustomed to \"rendering any old crap\", then is the W3C's usage of\nXHTML causing any *problems*?\n\nT.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "\"Daniel\" <tdaniel@adetti.net>\n\n> >, don't mistake \"rendering any old crap\" with \"supporting XHTML\"\n>\n> Still, if browsers are rendering the XHTML properly, even if only\nbecause\n> there accustomed to \"rendering any old crap\", then is the W3C's usage\nof\n> XHTML causing any *problems*?\n\nYes, because there are other browsers, without such forgiving HTML\nparsers around, since the page has removed the XML declaration, it now\nworks okay in the one I was having specific trouble with before (Pocket\nIE), but there are still others, I only really track javascript capable\nUA's but I know of over 20 of those, and I can't begin to do QA testing\nagainst them all, so the only thing we can do is trust their HTTP Accept\nheaders, and so not send them XHTML if they don't say they can deal with\nit.\n\nThere's also of course the W3's own NOTE's which say that XHTML 1.0\ndocuments _SHOULD_ be being sent as application/xhtml+xml - if we're to\ntake SHOULD's seriously, we have to see the W3 taking them seriously.\nhttp://www.w3.org/TR/xhtml-media-types/ says things like \"In general,\n[the text/html] media type is NOT suitable for XHTML.\" and in the table\nclearly shows that for XHTML 1.0 following the HTML compatibility\nguidelines the mime-type \"application/xhtml+xml\" SHOULD be used.\n\nOkay there may be reasons to ignore a SHOULD, after all that's why it's\nnot a MUST (and it's a NOTE anyway, not a Recommendation), I just don't\nknow what they are, and aren't hearing any come up.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "On Friday, December 6, 2002, at 05:31  AM, Robert Clary wrote:\n\n> You gain no real benefit from using XHTML content if the page is to be \n> served as text/html.\n\nIf nothing else, the syntax rules are more consistent and simply make \nmore sense than HTML4. Don't you think? I know it has been much easier \nto teach strict XHTML than strict HTML4.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "David S wrote:\n\n> On Friday, December 6, 2002, at 05:31  AM, Robert Clary wrote:\n>\n>> You gain no real benefit from using XHTML content if the page is to \n>> be served as text/html.\n>\n> If nothing else, the syntax rules are more consistent and simply make \n> more sense than HTML4. Don't you think? I know it has been much easier \n> to teach strict XHTML than strict HTML4.\n\nActually, in my opinion HTML (event Strict HTML4) is much simpler and \neasier to use than XHTML.\n\n-- \nJames Ross <J.G.Ross@warwick.ac.uk>\nWebmaster, The University of Warwick Computing Society\nhttp://www.warwickcompsoc.co.uk/\n\n\n\n__________________________________________________\nDo You Yahoo!?\nEverything you'll ever need on one web page\nfrom News and Sport to Email and Music Charts\nhttp://uk.my.yahoo.com\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "David S wrote:\n> \n> On Friday, December 6, 2002, at 05:31  AM, Robert Clary wrote:\n> \n>> You gain no real benefit from using XHTML content if the page is to be \n>> served as text/html.\n> \n> \n> If nothing else, the syntax rules are more consistent and simply make \n> more sense than HTML4. Don't you think? I know it has been much easier \n> to teach strict XHTML than strict HTML4.\n> \n> \n\nThe problem is that it is still HTML and will be treated as HTML by \n\"other\" browsers in wide distribution.  This can lead to incorrect \ncoding practices which the \"other\" browser will be forgiving of and \nwhich will result in another generation of web authors learning the \nwrong way to code XHTML/XML. Of course, since whatever broken markup \nthey use works in the \"other\" browser, then any browser which disagrees \nis considered broken. Believe me, I've been there and seen that many \ntimes before.\n\nOf the last two years I have had to deal with numerous sites which \nthought that \"XML was cool\" and would incorrectly use XML syntax in HTML \ndocuments. These people did not really understand what XML was about nor \nhow to use it.\n\nHow do you deal with sites that use empty element syntax for non-empty \nelements such as <form /> or <option /> ? Believe me, it is not just \nminor sites which make these kinds of mistakes. Search the Tech \nEvangelism product in bugzilla.mozilla.org for examples of major sites \nwhich have made this mistake.\n\nIf IE is so broken that it can not handle XHTML served as XHTML then \nsend it a pure HTML page which it can handle. Any web author using it \nwho looks at the W3C home page for inspiration will see a good example \nof using CSS to create a table-less layout in HTML which is a good \nthing.  They will not be confused by the XML syntax and try to use it \ninappropriately in their own pages.\n\nThe W3 home page is served by Apache/1.3.26 (Unix) PHP/3.0.18 which \nshould be able to distinguish downlevel browsers such as Internet \nExplorer and serve them pure HTML while sending XHTML with the \nappropriate content type to browsers which can support it.\n\nI believe that is the most appropriate thing to do.\n\nBob\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "WaSP Asks the W3",
            "content": "In an effort to assist developers and designers in understanding detailed\nissues when working with web standards, WaSP and the W3C kick off a new\nproject today.\n\nThe project, \"WaSP Asks the W3C\" involves WaSP Steering Committee members\nculling questions from supporters and asking members of the W3C's Quality\nAssurance Group for insight and details. WaSP hopes you'll find the project\nworthwhile.\n\nThe first article is on properly specifying character sets.\n\nhttp://www.webstandards.org/learn/askw3c/dec2002.html\n\nDiscussion can take place here.\n\nLooking forward to your thoughts,\nMolly\n\nMolly E. Holzschlag\nEducation Director\nWorld Organization of Webmasters\nAuthor / Instructor / Web Designer\nweb: http://www.molly.com/\nemail: molly@molly.com\n\n\n\n"
        },
        {
            "subject": "Comments on &quot;WaSP Asks the W3C&quot",
            "content": "Hi Molly,\n\nI'm glad to see this collaborative work between WaSP and\nW3C happening. I have a minor suggestion regarding [1].\nPlease have wasp/qa clearly identify the subject and object\nof the questions. The first one, for example, is:\n\n      *  How to properly specify character sets\n\nI would propose instead:\n\n      * How authors specify character sets in Web content\n\nThat's because one could also read the phrase with\nother audiences in mind:\n\n      * How server designers handle character sets\n\n      * How specification writers specify character sets\n\n      * How software designers handle character sets\n\n\nAlso, I think the proper term for the first question\nis \"character encoding\" rather than \"character set.\"\nIt's true that an attribute or parameter named \"charset\"\nis often the means to identify a character encoding,\nbut I believe the title should refer to character encodings.\n\nMy experience with WAI guidelines is that it helps a lot\nwhen you make clear who should be reading which questions.\nOf course, anybody may read them, but the target audience\nshould be given a heads-up.\n\nThank you,\n\n   - Ian\n\n\n[1] http://lists.w3.org/Archives/Public/public-evangelist/2002Dec/0022\n-- \nIan Jacobs (ij@w3.org)   http://www.w3.org/People/Jacobs\nTel:                     +1 718 260-9447\n\n\n\n"
        },
        {
            "subject": "RE: Comments on &quot;WaSP Asks the W3C&quot",
            "content": "Hi Ian,\n\nThanks for your great suggestions.  I really like what you say about\nclarification and audience.  Obviously, this is the first toe in the big\npool, and everyone's comments are more than welcome/necessary to help make\nthis a success.\n\nI'll look at your suggestions and modify the document a bit for clarity.\n\nThanks again,\nMolly\n\nMolly E. Holzschlag\nEducation Director\nWorld Organization of Webmasters\nAuthor / Instructor / Web Designer\nweb: http://www.molly.com/\nemail: molly@molly.com\n\n\n\n"
        },
        {
            "subject": "Re: WaSP Asks the W3",
            "content": "* Molly E. Holzschlag wrote:\n>The first article is on properly specifying character sets.\n>\n>http://www.webstandards.org/learn/askw3c/dec2002.html\n>\n>Discussion can take place here.\n\n[...]\n     There are several ways of specifying the character set for a\n     particular document. Which of the following methods (or combination\n     thereof) does the W3C recommend, and why?\n\n       * Have the server administrator set the proper encoding via the\n         HTTP headers returned by the Web server\n       * Have the author add the encoding with a meta element\n       * XHTML authors can add the character encoding using the XML\n         prolog\n[...]\n\nThe term \"character set\" should be avoided, see\n<http://www.w3.org/MarkUp/html-spec/charset-harmful.html>. The third\nitem should be rephrased to match the prolog. It should be \"XML\ndeclaration\", not \"XML prolog\".\n\n[...]\n     These three ways of providing the character encoding of a document \n     are not equivalent. When trying to figure out the character\n     encoding of a resource, user agents will try, in this order:\n\n       * The HTTP Content-Type header sent by the server\n       * The XML declaration (only for XHTML documents)\n       * The HTML/XHTML meta element\n       * Other ways. There are algorithms to guess the character\n         encoding, for example\n[...]\n\nThe XML declaration should be ignored for XHTML documents delievered as\ntext/html (the HTML WG says, user agents should not use any heuristics\nto determine whether a document is HTML or XHTML and thus parse all\nXHTML documents delivered as text/html as beeing HTML and thus\nprocessing instructions (the XML declaration is a processing instruction\nfrom an HTML point-of-view) are to be ignored) (and this is what most\nuser agents do), this information should be added to the document, it is\notherwise confusing.\n\n[...]\n     However, in at least two cases, this is simply not possible:\n       * The document author does not have any way to configure the \n         server to send the proper HTTP Content-Type header\n       * The document is not served via HTTP. It's a standalone\n         document, or served via MIME\n[...]\n\nMIME also has a Content-Type header, hence this is not a valid\nexception.\n\n[...]\n   In these cases, an HTML document should provide the character\n   encoding via a meta element, and an XML document must provide\n   it via the XML declaration.\n[...]\n\nNo, XML documents do not need to have an XML declaration in these cases\nif they are encoded using one of the default encodings (us-ascii for\ntext/xml, utf-8 or utf-16 for most other cases).\n\n[...]\n     Example of an HTML 4.01 document written in French with a UTF-8\n     encoding:\n\n  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\n    \"http://www.w3.org/TR/html4/strict.dtd\">\n  \n  <html lang=\"fr\">\n  \n  <head>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n  \n  <title>Exemple de document HTML 4.01</title>\n  </head>\n  \n  <body>\n  <h1>Portrait Int?rieur</h1>\n  <h2>Rainer-Maria Rilke</h2>\n  \n  <p>Ce ne sont pas des souvenirs<br />\n  qui, en moi, t'entretiennent ;<br />\n  tu n'es pas non plus mienne<br />\n  par la force d'un beau d?sir.</p>\n  </body>\n  </html>\n[...]\n\nThe \"<br />\"s have to be \"<br>\"s.\n\nregards.\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "James\n\nI would like to refer, for a moment, to the XHTML 1.0 specification. It \nis available on the W3C website at http://www.w3.org/TR/xhtml1 . I am \nnot, however, interested so much in the specification itself. The \nsubtitle is what I would advise you to see.\n\n\nThe subtitle reads, ???A Reformulation of HTML 4 in XML 1.0.??? While I \nunderstand your argument from a theoretical standpoint, in the fact that \nit does take a minute or two to learn how to properly notate <br> and \nothers in XHTML, there is no fundamental change in the vast majority of \nthe specification. Unless you are referring to HTML 3.2, 2.0, or 1.0, \nthere is no real argument for HTML 4 over XHTML 1.\n\nI hope I am not mistaken in any way, but if I am, I would be glad to be \nenlightened.\n\nWes\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "Greetings all\n\nI would firstly like to congratulate the W3C and all related parties on \ntheir decision to move towards a more structurally correct design. The \nmove is, no doubt, a very large decision and one which requires thought \nand planning. The transition to the new design appeared very smooth.\n\nI would like to address a trivial (at least, at this stage) issue that, \nnonetheless, deserves some attention. I would first like to start with a \nconceptual page structure:\n\nh1 (Banner)\n   -links\n   -descriptions\n   h2 (News)\n     h3 (Headline)\n     -story\n     h3 (Headline)\n     -story\n   h2 (Navigation)\n     -links\n   h2 (Search)\n     -search\n   h2 (Contact)\n     -links\n   h2 (Involvement)\n     -links\n   -et cetera with other h2 elements\n\nThis type of layout would make sense to a browser which must make do \nwith only the text flow of the page, as opposed to the positioned and \ncorrect rendering.\n\nRight now, to a browser that does not support CSS (or even a browser \nthat supports CSS, but not properly) the ???W3C A to Z??? section appears \nfirst. Structurally speaking, this is not quite ideal. While the largest \naudience will be able to see the site properly, it would be better for \nthe news to take precedence. This, unfortunately, is not possible with \nthis layout and positioning combination.\n\nTo achieve this goal with absolute positioning, however, would be \nsimple. Setting percentages for each section???s width would ensure \nscaling would be possible. The floats would be guarded against being \npushed ???onto the next line??? when the window is very narrow in IE. Also, \nit would remove the feeling of unevenness, as the floats have caused an \nunsighly larger gap on the right side of the page (tested in Gecko and IE).\n\nI am certainly very excited about the new design. I will continue to \nread comments regarding the site, and I certainly hope to hear any \ncomments regarding my message.\n\nWes\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "(sorry - this is probably a bit off-topic for this list)\n\nWesley Moy wrote:\n\n> James\n>\n> I would like to refer, for a moment, to the XHTML 1.0 specification. \n> It is available on the W3C website at http://www.w3.org/TR/xhtml1 . I \n> am not, however, interested so much in the specification itself. The \n> subtitle is what I would advise you to see.\n>\n>\n> The subtitle reads, ???A Reformulation of HTML 4 in XML 1.0.??? While I \n> understand your argument from a theoretical standpoint, in the fact \n> that it does take a minute or two to learn how to properly notate <br> \n> and others in XHTML, there is no fundamental change in the vast \n> majority of the specification. Unless you are referring to HTML 3.2, \n> 2.0, or 1.0, there is no real argument for HTML 4 over XHTML 1.\n>\n> I hope I am not mistaken in any way, but if I am, I would be glad to \n> be enlightened.\n>\n> Wes\n\nI understand the transition from HTML to XHTML, and I fully support the \nuse of XML itself. The problem with XHTML, for me, is that in their \ninfinite wisdom the W3C made all the tags in XHTML lower-case. This \nalone is enough to prevent me from ever using it (with the porssible \nexception of if I'm being paid to do it).\n\nAs I'm sure others will agree, creating HTML code by hand, or at least \ncreating templates by hand, give the best results (rather than using a \nWYSIWYG, or similar, editor). I've been doing this for years, using \nupper-case HTML tags, without problems. The problem I have with XHTML is \nthat I simple can't edit it, or use my own style, because it's based on \nXML, and is therefor case-sensitive.\n\nFor me, XHTML represents a complete waste of time on the part of the W3C \nbecause of this - I'm never going to use it, instead I'll just switch \nfrom HTML 4 to XML/XSLT when that time comes (getting mighty close, I \nmight add).\n\n-- \nJames Ross <J.G.Ross@warwick.ac.uk>\nWebmaster, The University of Warwick Computing Society\nhttp://www.warwickcompsoc.co.uk/\n\nWhy You Can't Find Your System Administrator:\n  13. The admin is suffering so bad from sleep deprivation that they may as well not be there for all the sense you can make of the words they are saying.\n\n\n\n"
        },
        {
            "subject": "[publicevangelist] &lt;none&gt",
            "content": "subscribe\n-- \nKim Brooks Wei\nwww.kimbwei.com\nP O Box 626\nFair Lawn\nNJ  07410\nV 201.475.1854\nmailto:kimi@kimbwei.com\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "I think that the order of the page is off, because it doesn't flow \nnicely\nin linear order from most important to least. At the very least, the \nnews\n(as the thing that is updated the most) should come before the list of\nlinks.  This is easily accomplished using CSS-P (CSS2) to place the page\ncomponents in proper two-dimensional position while still allowing the\nlinear page order to make sense.\n\nThe Lynx rendition of the homepage follows this message, in plaintext.\n\n--Kynn\n\n\n\n    #Technologies | News | Search | Contents | Footnotes | RSS\n\n                       The World Wide Web Consortium (W3C)\n\nLeading the Web to its Full Potential...\n\n    Skip to Technologies | Activities | Technical Reports | Site Index |\n    New Visitors | About W3C | Join W3C\n\n    The World Wide Web Consortium (W3C) develops interoperable\n    technologies (specifications, guidelines, software, and tools) to \nlead\n    the Web to its full potential. W3C is a forum for information,\n    commerce, communication, and collective understanding. On this page,\n    you'll find W3C news, links to W3C technologies and ways to get\n    involved. New visitors can find help in Finding Your Way at W3C. We\n    encourage you to learn more about W3C.\n\nW3C A to Z\n\n      * Skip to News\n      * Accessibility\n      * Amaya\n      * Annotea\n      * CC/PP\n      * CSS\n      * CSS Validator\n      * Device Independence\n      * DOM\n      * HTML\n      * HTML Tidy\n      * HTML Validator\n      * HTTP\n      * Internationalization\n      * Jigsaw\n      * Libwww\n      * MathML\n      * Multimodal Interaction\n      * Patent Policy\n      * PICS\n      * PNG\n      * Privacy and P3P\n      * Quality Assurance (QA)\n      * RDF\n      * Semantic Web\n      * SMIL\n      * SOAP/XMLP\n      * Style\n      * SVG\n      * TAG\n      * URI/URL\n      * Voice\n      * WAI\n      * WebCGM\n      * Web Services\n      * Web Ontology\n      * XForms\n      * XHTML\n      * XLink\n      * XML\n      * XML Base\n      * XML Encryption\n      * XML Key Management\n      * XML Query\n      * XML Schema\n      * XML Signature\n      * XPath\n      * XPointer\n      * XSL and XSLT\n\n    More topics...\n\nNews\n\n    Skip to Search\n\nXML Encryption, Decryption Become W3C Recommendations\n\n    10 December 2002: The World Wide Web Consortium today released XML\n    Encryption Syntax and Processing and Decryption Transform for XML\n    Signature as W3C Recommendations. The specifications have been\n    reviewed by the W3C Membership, who favor their adoption by industry.\n    Encryption makes sensitive data confidential for storage or\n    transmission. Read the press release and testimonials. (News archive)\n\nFirst Amaya Welcome Page Competition\n\n    10 December 2002: W3C is pleased to announce the first Welcome Page\n    Competition for Amaya, W3C's editor/browser. Design the start page\n    using W3C technologies such as HTML, XHTML, CSS style sheets, MathML\n    expressions, and SVG drawings. Enter as often as you wish. Deadline\n    for submissions is 3 February 2003. (News archive)\n\nModularization of XHTML in XML Schema Last Call Published\n\n    9 December 2002: The HTML Working Group has released a Last Call\n    Working Draft of Modularization of XHTML in XML Schema. Comments are\n    welcome through 31 January. The document provides a complete set of\n    XML Schema modules for XHTML, and allows document authors to modify\n    and extend XHTML in a conformant way. Visit the HTML home page. (News\n    archive)\n\nEARL 1.0 Working Draft Published\n\n    6 December 2002: The Evaluation and Repair Tools Working Group has\n    released the first public Working Draft of the Evaluation and Report\n    Language (EARL) 1.0. The specification explains how to use EARL, a\n    general-purpose language for expressing test results, and defines a\n    basic vocabulary. Feedback is welcome. Read about the Web\n    Accessibility Initiative. (News archive)\n\nW3C Announces Home Page Redesign\n\n    5 December 2002: W3C is pleased to announce a home page redesign and\n    accompanying FAQ. Written for newer, standards-compliant user agents\n    in XHTML 1.0 strict, the design features table-less columns and more\n    navigation for accessibility, and Cascading Style Sheets (CSS) for\n    layout. W3C welcomes your comments. (News archive)\n\nMultimodal Interaction Use Cases Published\n\n    5 December 2002: The Multimodal Interaction Working Group has \nreleased\n    Multimodal Interaction Use Cases as a W3C Note. Airline reservations,\n    driving directions, and name dialing from mobile terminals are\n    analyzed. They highlight device requirements, event handling, network\n    dependencies, and user interaction. Read about the Multimodal\n    Interaction Activity. (News archive)\n\nW3C Co-Hosts XML 2002\n\n    4 December 2002: W3C is pleased to co-host XML 2002 to be held 8-13\n    December in Baltimore, MD, USA. Chris Lilley participates in a Town\n    Hall panel on the W3C Technical Architecture Group on 10 December.\n    Philippe Le H??garet presents W3C Update on 11 December and DOM Level \n3\n    on 12 December. Daniel Weitzner and Liam Quin, W3C XML Activity Lead,\n    will attend. (News archive)\n\nPast News\n\nSearch\n\n    Skip to Contents\n    Google\n    _______________ Go\n\n    Search W3C Mailing Lists\n\nContact Us\n\n      * Skip to Footnotes\n      * Contact W3C\n\nGet Involved\n\n      * Join W3C\n      * Participate\n      * Mailing Lists\n      * Translations\n      * Open Source Software\n      * World Offices\n      * Employment\n      * Subscribe to W3C Weekly News\n\nMission\n\n      * W3C in Seven Points\n      * Frequently Asked Questions\n      * Process Document\n\nMember Area\n\n      * Member Home Page\n      * Current Members\n      * Get Member Password\n\nW3C Team\n\n      * People\n      * Past Talks\n      * Upcoming\n\nPast News\n\n      * News Archive\n      * Press Releases\n      * W3C in the Press\n      _________________________________________________________________\n\n    Read the FAQ and send comments about this page. Syndicate this page\n    with RSS 1.0, an RDF vocabulary used for site summaries.\n\n\n     Webmaster ??? Last modified: $Date: 2002/12/10 15:12:27 $|\n     Valid XHTML 1.0! | Valid CSS1! | Level Double-A conformance icon,\n     W3C-WAI Web Content Accessibility Guidelines 1.0 |\n\n    Copyright ?? 1994-2002 W3C^?? (MIT, INRIA, Keio), All Rights Reserved.\n    W3C liability, trademark, document use and software licensing rules\n    apply. Your interactions with this site are in accordance with our\n    public and Member privacy statements.\n\n\n--\nKynn Bartlett <kynn@idyllmtn.com>                http://kynn.com\nChief Technologist, Idyll Mountain           http://idyllmtn.com\nAuthor, CSS in 24 Hours                  http://cssin24hours.com\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "Kynn Bartlett wrote:\n> \n> I think that the order of the page is off, because it doesn't flow nicely\n> in linear order from most important to least. At the very least, the news\n> (as the thing that is updated the most) should come before the list of\n> links.  This is easily accomplished using CSS-P (CSS2) to place the page\n> components in proper two-dimensional position while still allowing the\n> linear page order to make sense.\n\nHi Kynn,\n\nI think the folks who worked on this concluded that CSS-P was\nnot as widely supported consistently across browsers as floats.\n\n  _ Ian\n\n\n\n-- \nIan Jacobs (ij@w3.org)   http://www.w3.org/People/Jacobs\nTel:                     +1 718 260-9447\n\n\n\n"
        },
        {
            "subject": "RE: W3C Home page switched to full CSS layou",
            "content": "I don't like the idea of having to scroll so much.  The homepage should have been broken up into the homepage and subpages.  The top navigation line and the first paragraph could be the homepage.  The search field could be on all of the pages in the upper right-hand corner.  All of the other sections could be broken up into various subpages in the following manner:\n* W3C A to Z\n* News\n* Past News\n* Contact Us\n* Get Involved\n* Mission\n* Member Area\n* W3C Team\n* Past News\n\nSome of these sections can be popup windows instead of pages and linked at the top and bottom of Webpages.\n\nSandra.\n\n\n\n"
        },
        {
            "subject": "RE: W3C Home page switched to full CSS layou",
            "content": "Sorry - this should have gone to list rather than the one person\n\nJohn\n\n>Some of these sections can be popup windows instead of pages and linked at \n>the top and bottom of Webpages.\n\nWhich will mess up most of the accessibility criteria\n\nFrom\nhttp://www.w3.org/TR/1999/WAI-WEBCONTENT-19990505/\n\n\"  . .  changing the current window or popping up new windows can be very \ndisorienting to users who cannot see that this has happened. \"\n\n\"10.1Until user agents allow users to turn off spawned windows, do not \ncause pop-ups or other windows to appear and do not change the current \nwindow without informing the user. [Priority 2]\"\n\nAnd as far as I know, the criteria for user agents to allow the turning off \nof spawned windows, or otherwise handling them, then the requirements will \nnot be met.\n\nRegards\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "It would be possible to have a more logical order (i.e. have the \"news \nblock\" first, followed by \"A to Z\" and the other navigation bar) if you \nare willing to sacrifice a wee bit of semantic goodness.\n\nhttp://jan.moesen.nu/.temp/20021214_w3c-fix/\n\nI included the news block and the A to Z in a container div which I \nfloated left. The news block and A to Z are both floated right. The \nother navigation block is also floated left, so it touches the news \nblock. After a bit of border fiddling*, it seems to work in Mozilla 1.3, \nIE6, Opera 6 and 7 (all on Windows, don't know about other OSes). Might \nbe an approach worth trying?\n\n* It requires that the news block is the longest of the three blocks to \nhave the borders appear correctly\n\n[Sorry Ian: was meant to go to the entire list in the first place]\n-- \nJan!\nhttp://jan.moesen.nu/\n\n\n\n"
        },
        {
            "subject": "Re: W3C Home page switched to full CSS layou",
            "content": "> I included the news block and the A to Z in a container div which I \n> floated left. The news block and A to Z are both floated right. The \n> other navigation block is also floated left, so it touches the news \n> block. [ . . . ]\n> http://jan.moesen.nu/.temp/20021214_w3c-fix/\n\nOf course I should have pointed to the relevant CSS as well:\nhttp://jan.moesen.nu/.temp/20021214_w3c-fix/StyleSheets/home-import.css\n\nSorry.\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "Nigel Peck - MIS Web Design wrote:\n\n>It's great how XHTML is progressing with version 2 etc. but it strikes me\n>that while the W3C is taking the specs into the future the majority of the\n>Web Development world is lagging miles behind. I don't think I'm the first\n>one to have noticed this but wouldn't we be better putting out efforts into\n>getting other developers to do the XHTML walk rather than producing the\n>XHTML run?\n>\n>For example, a college near to me teaches Web Design. They teach HTML not\n>XHTML. People come out of there happily writing <br> tags and not closing\n>their <p> tags and some will go on to create Web sites. I had an email from\n>a tutor in the states somewhere who is starting to teach his classes XHTML\n>this coming semester. I can't claim to having any more data than that but\n>from looking at code on the sites that I see it seems that most developers\n>still couldn't care less about closing their empty elements and making sure\n>all elements nest properly.\n>\n>I'm just concerned that once XHTML 2 gets released people will hear about\n>it, no backwards compatibility etc. and loads of new elements and be scared\n>by it. It's okay for us making the transition because we're already fully\n>aware of 1.0 but from what I've seen most are not, old habits die hard, and\n>especially with the number of people that know HTML. It's not like a new\n>version of Perl where the majority of users are enthusiastic about the\n>language, most people couldn't care less about the language and just want to\n>get the job done, how do we get them to start being more strict in their\n>coding practices?\n>\n>For my part I've started a series of articles aimed at teaching XHTML to\n>beginners, if anyone is interested it's at:\n>http://www.miswebdesign.com/resources/articles/web-design-xhtml-1-1.html\n>  \n>\nI too have noticed this.  Schools teach the worst Web design since they \nthink they have to use fancy text books (which cost money, take time to \nmake and purchase, etc.) when they could just use the actual \nspecifications which are sometimes even easier and are monetarily free.  \nBy the time the textbook is printed, it is probably out-of-date and if \nadopted, it takes about five years before new text books are adopted.  \nIn the worst cases, Web design education is at least six years behind \nthe Web specifications.  That is why you still see people writing \npresentationally using invalid HTML 3.2 through a Web editor.  Such is \nthe case with my school.  Despite all my efforts, they fail to realize \nthat HTML is a markup language that adds meaning, not fancy colors.  \nThey fail to see that this makes the language easier, not more difficult.\nThey seem to think:\n  I have to be  a nerd to read HTML code.\n  I don't want to be a nerd.\n  I refuse to read HTML code.\n\nNot only is that false logic, being a geek or nerd is not a bad thing.  \nA geek is simply someone with a passion for his or her profession or \nhobby whether it be computers, sports, or something else.\n\nWell, I hope those ramblings didn't stray too far from the original topic.\n\n-- \nBrant Langer Gurganus\nhttp://troop545.cjb.net/brant.xhtml\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "Sounds about right to me. I've no problem with admitting I'm a geek (not a\nnerd :-).\n\nMy concern is that we'll end up with two Web Developer communities that have\nlittle relation to each other, those using the latest standards and those on\nHTML who don't know or care. (even more so than how it is now)\n\nAnd there's no way Browser manufacturers will move browsers to a non\nbackwards compatible language until a very high percentage of users are\naware of it.\n\nNigel\nMIS Web Design\nhttp://www.miswebdesign.com/\n\n-----Original Message-----\nFrom: Brant Langer Gurganus\n[mailto:brantgurganus2001@cherokeescouting.org]\nSent: 30 December 2002 16:18\nTo: Nigel Peck - MIS Web Design\nCc: www-html@w3.org; public-evangelist@w3.org\nSubject: Re: Promotion of XHTML\n\n\nNigel Peck - MIS Web Design wrote:\n\n>It's great how XHTML is progressing with version 2 etc. but it strikes me\n>that while the W3C is taking the specs into the future the majority of the\n>Web Development world is lagging miles behind. I don't think I'm the first\n>one to have noticed this but wouldn't we be better putting out efforts into\n>getting other developers to do the XHTML walk rather than producing the\n>XHTML run?\n>\n>For example, a college near to me teaches Web Design. They teach HTML not\n>XHTML. People come out of there happily writing <br> tags and not closing\n>their <p> tags and some will go on to create Web sites. I had an email from\n>a tutor in the states somewhere who is starting to teach his classes XHTML\n>this coming semester. I can't claim to having any more data than that but\n>from looking at code on the sites that I see it seems that most developers\n>still couldn't care less about closing their empty elements and making sure\n>all elements nest properly.\n>\n>I'm just concerned that once XHTML 2 gets released people will hear about\n>it, no backwards compatibility etc. and loads of new elements and be scared\n>by it. It's okay for us making the transition because we're already fully\n>aware of 1.0 but from what I've seen most are not, old habits die hard, and\n>especially with the number of people that know HTML. It's not like a new\n>version of Perl where the majority of users are enthusiastic about the\n>language, most people couldn't care less about the language and just want\nto\n>get the job done, how do we get them to start being more strict in their\n>coding practices?\n>\n>For my part I've started a series of articles aimed at teaching XHTML to\n>beginners, if anyone is interested it's at:\n>http://www.miswebdesign.com/resources/articles/web-design-xhtml-1-1.html\n>\n>\nI too have noticed this.  Schools teach the worst Web design since they\nthink they have to use fancy text books (which cost money, take time to\nmake and purchase, etc.) when they could just use the actual\nspecifications which are sometimes even easier and are monetarily free.\nBy the time the textbook is printed, it is probably out-of-date and if\nadopted, it takes about five years before new text books are adopted.\nIn the worst cases, Web design education is at least six years behind\nthe Web specifications.  That is why you still see people writing\npresentationally using invalid HTML 3.2 through a Web editor.  Such is\nthe case with my school.  Despite all my efforts, they fail to realize\nthat HTML is a markup language that adds meaning, not fancy colors.\nThey fail to see that this makes the language easier, not more difficult.\nThey seem to think:\n  I have to be  a nerd to read HTML code.\n  I don't want to be a nerd.\n  I refuse to read HTML code.\n\nNot only is that false logic, being a geek or nerd is not a bad thing.\nA geek is simply someone with a passion for his or her profession or\nhobby whether it be computers, sports, or something else.\n\nWell, I hope those ramblings didn't stray too far from the original topic.\n\n--\nBrant Langer Gurganus\nhttp://troop545.cjb.net/brant.xhtml\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "At 11:18 30/12/2002 -0500, Brant wrote:\n\n>Nigel Peck - MIS Web Design wrote:\n>\n>>It's great how XHTML is progressing with version 2 etc. but it strikes me\n>>that while the W3C is taking the specs into the future the majority of the\n>>Web Development world is lagging miles behind.\n\n\n>>For example, a college near to me teaches Web Design. They teach HTML not\n>>XHTML. People come out of there happily writing <br> tags and not closing\n>>their <p> tags and some will go on to create Web sites.\n\n\n>>For my part I've started a series of articles aimed at teaching XHTML to\n>>beginners, if anyone is interested it's at:\n>>http://www.miswebdesign.com/resources/articles/web-design-xhtml-1-1.html\n>>\n>By the time the textbook is printed, it is probably out-of-date and if \n>adopted, it takes about five years before new text books are adopted.\n>In the worst cases, Web design education is at least six years behind the \n>Web specifications.  That is why you still see people writing \n>presentationally using invalid HTML 3.2 through a Web editor.  Such is the \n>case with my school.  Despite all my efforts, they fail to realize that \n>HTML is a markup language that adds meaning, not fancy colors.\n\nI have seen all this, agreeing with the sentiments here and by the greatest \nof good fortune I have been appointed Lecturer in Computing at the \nUniversity of Central England in Birmingham. I start officially on \nWednesday, 1st January. One of my remits it to teach a course on Internet \nTechnologies.\n\nSo it's been a busy Christmas preparing for a complete change in career \ndirection, having spent the last 30 years in industry\n\nNigel's tutorial is interesting, and part of the way I plan to go. However \nmy plan is probably more radical (I am after all teaching people who are \ngetting a degree and will probably have some web page writing experience). \nMy plan is to start off with a basic format of a page with \"Hello World\" as \na header or like of text and then develop it no more - but then attach a \nstyle sheet and then alter the appearance of the page using the style \nsheet. I'll also introduce the difference between bold and strong tags with \nreference to speech browsers as well as visual. All this is in XHTML 1.1. \nSo the initial development is not so much XHTML as the presentation of \ninformation across the web to a variety of internet devices.\n\nOnly after the concept of separating content and presentation is fully \nunderstood will we elaborate on XHTML and develop CSS along with it.\n\nLater on we'll have to consider retrofitting table and frame based HTML \npages, but I haven't got there yet. Neither have I got to the stage of \nserver side PHP, JSP and Client side Javascript. But the core concept is a \nparallel development of XHTML and CSS skills with the goal that web pages \npresented to any browsing device, standard or using adaptive technologies, \nis both standard and accessible.\n\nInitially the coding will be performed using a text editor - the \norganisation's Windows only at the moment but I've already had discussions \nabout Linux and deploying it more widely. - but the one and only tool I've \nbeen able to feel comfortable with is TopStyle Pro \n(http://www.bradsoft.com) and although I've been trying to get to grips \nwith Arachnophilia (http://www.arachnoid.com/arachnophilia/) I haven't yet \nbeen satisfied that I can convert it all into XHTML 1.1 compliant mode \nwithout a load of work (where'd all the time go!?). Although it's free \ndoesn't seem to be approaching the code from the 'right' way IMHO. \nDreamweaver is a great tool, but a no-no because of cost. I'm going to get \nthem to process graphics with the GIMP.\n\nI'd appreciate anyone's views on this and your opinion of this type of \napproach, both for learning style and toolsets, bearing in mind that this \nis classroom teaching by lecture and workshop (it may expand later into \nprint and web media) and is intended to be part of a degree course.\n\nRegards\n\nJohn\n\nJohn Colby\n\njohn.colby@uce.ac.uk (active early January)\nLecturer in Computing, University of Central England, Franchise Street\nPerry Barr, Birmingham B42 2SU phone +44 (0)121 331 5000\n\njohn@colbyweb.co.uk\n4 Ambion Rise, Market Bosworth, Nuneaton, Warwickshire, CV13 0NY\nPhone +44 (0) 1455 290271, mobile 0771 114 1621 website \nhttp://www.colbyweb.co.uk\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "Following on from what everyone else has said, I work with someone who\nstarted learning web design at an evening class at a local college.\nAfter a couple of weeks, she came up and asked me why I wasn't using\nFrontPage.  I despair - this isn't web design, it's \"lets see what\nprettiness I can make with a WYSIWYG editor\" (or to use a great phrase\nstolen from someone WYGIWYD (What You Get Is What You Deserve)).  The\npeople running these courses are really damaging the web!\n\nI think I'm going to have to spend some time explaining exactly what web\ndesign is, rather than what colleges and other such places promote ot as\nto get bums on seats and money in the bank.  It really irritates me.  I\nget called a geek by my intranet manager at work - this coming from the\nman who won't use CSS and uses FrontPage for \"ease\".\n\nI have to say that I'm looking forward to getting my hands on XHTML2.0\nbut I share the fear of others that as it isn't designed to be backwards\ncompatible, it may well put people off.  Also, considering the hacks\nthat we have to use if we want a page to be viewable in numerous\nbrowsers, it's going to be a while until we get decent browser support.\n\nHave a good new year\n\nFrancis\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "On Mon, 30 Dec 2002, fstorr wrote:\n\n> It really irritates me.  I get called a geek by my intranet manager\n> at work - this coming from the man who won't use CSS and uses\n> FrontPage for \"ease\".\n\nTo make any progress, we have to at least identify the primary\nobstacle:\n\nAre you irritated by the fact that FrontPage is easier to use (for\nmost humans) than writing raw markup? Are you irritated by the fact\nthat Microsoft owns FrontPage? Are you irritated by the fact that\nother WYSIWYG tools are not as popular/known as FrontPage? Are you\nirritated by CSS properties that make writing raw CSS/HTML markup\ndifficult and generated markup ugly? Are you irritated by browsers\nthat tolerate invalid markup? Other?\n\nIn other words, what should be the first priority: changing human\nnature, changing Microsoft, changing W3C marketing, changing CSS/HTML,\nor changing browsers?\n\nSimply declaring that \"valid markup is better than invalid one\" and\n\"new XHTML is better than old HTML\" or even \"hand-written markup is\nbetter than generated markup\" is not going to change much, IMHO. This\nis an \"evangelist@w3\" mailing list; does evangelism imply pro-active\naction or just stating personal preferences?\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "John Colby wrote:\n\n>\n> At 11:18 30/12/2002 -0500, Brant wrote:\n>\n>> Nigel Peck - MIS Web Design wrote:\n>>\n>>> It's great how XHTML is progressing with version 2 etc. but it \n>>> strikes me\n>>> that while the W3C is taking the specs into the future the majority \n>>> of the\n>>> Web Development world is lagging miles behind.\n>>\n>\n>\n>>> For example, a college near to me teaches Web Design. They teach \n>>> HTML not\n>>> XHTML. People come out of there happily writing <br> tags and not \n>>> closing\n>>> their <p> tags and some will go on to create Web sites.\n>>\n>\n>\n>>> For my part I've started a series of articles aimed at teaching \n>>> XHTML to\n>>> beginners, if anyone is interested it's at:\n>>> http://www.miswebdesign.com/resources/articles/web-design-xhtml-1-1.html\n>>>\n>> By the time the textbook is printed, it is probably out-of-date and \n>> if adopted, it takes about five years before new text books are adopted.\n>> In the worst cases, Web design education is at least six years behind \n>> the Web specifications.  That is why you still see people writing \n>> presentationally using invalid HTML 3.2 through a Web editor.  Such \n>> is the case with my school.  Despite all my efforts, they fail to \n>> realize that HTML is a markup language that adds meaning, not fancy \n>> colors.\n>\n>\n> I have seen all this, agreeing with the sentiments here and by the \n> greatest of good fortune I have been appointed Lecturer in Computing \n> at the University of Central England in Birmingham. I start officially \n> on Wednesday, 1st January. One of my remits it to teach a course on \n> Internet Technologies.\n>\n> So it's been a busy Christmas preparing for a complete change in \n> career direction, having spent the last 30 years in industry\n>\n> Nigel's tutorial is interesting, and part of the way I plan to go. \n> However my plan is probably more radical (I am after all teaching \n> people who are getting a degree and will probably have some web page \n> writing experience). My plan is to start off with a basic format of a \n> page with \"Hello World\" as a header or like of text and then develop \n> it no more - but then attach a style sheet and then alter the \n> appearance of the page using the style sheet. I'll also introduce the \n> difference between bold and strong tags with reference to speech \n> browsers as well as visual. All this is in XHTML 1.1. So the initial \n> development is not so much XHTML as the presentation of information \n> across the web to a variety of internet devices.\n>\n> Only after the concept of separating content and presentation is fully \n> understood will we elaborate on XHTML and develop CSS along with it.\n>\n> Later on we'll have to consider retrofitting table and frame based \n> HTML pages, but I haven't got there yet. Neither have I got to the \n> stage of server side PHP, JSP and Client side Javascript. But the core \n> concept is a parallel development of XHTML and CSS skills with the \n> goal that web pages presented to any browsing device, standard or \n> using adaptive technologies, is both standard and accessible.\n>\n> Initially the coding will be performed using a text editor - the \n> organisation's Windows only at the moment but I've already had \n> discussions about Linux and deploying it more widely. - but the one \n> and only tool I've been able to feel comfortable with is TopStyle Pro \n> (http://www.bradsoft.com) and although I've been trying to get to \n> grips with Arachnophilia (http://www.arachnoid.com/arachnophilia/) I \n> haven't yet been satisfied that I can convert it all into XHTML 1.1 \n> compliant mode without a load of work (where'd all the time go!?). \n> Although it's free doesn't seem to be approaching the code from the \n> 'right' way IMHO. Dreamweaver is a great tool, but a no-no because of \n> cost. I'm going to get them to process graphics with the GIMP.\n>\n> I'd appreciate anyone's views on this and your opinion of this type of \n> approach, both for learning style and toolsets, bearing in mind that \n> this is classroom teaching by lecture and workshop (it may expand \n> later into print and web media) and is intended to be part of a degree \n> course.\n\nSounds good.  Only problem with Top Style is that it is not monetarily \nfree, but it is definitely good.  I do most of my development personally \nwith either jEdit or Amaya.  jEdit is also in Java so it is cross-platform.\n\n-- \nBrant Langer Gurganus\nhttp://troop545.cjb.net/brant.xhtml\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "On Mon, 2002-12-30 at 13:50, Alex Rousskov wrote:\n> On Mon, 30 Dec 2002, fstorr wrote:\n> \n> > It really irritates me.  I get called a geek by my intranet manager\n> > at work - this coming from the man who won't use CSS and uses\n> > FrontPage for \"ease\".\n> \n> To make any progress, we have to at least identify the primary\n> obstacle:\n\n> In other words, what should be the first priority: changing human\n> nature, changing Microsoft, changing W3C marketing, changing CSS/HTML,\n> or changing browsers?\n\nThe problem is making people care about doing something the /right/ way.\n\nSomeone learning how to make web pages can sit down and relatively\nquickly get the results they want without any regard to proper\nstructural based web design (font tags, etc).  It's hard to explain to\nthem why doing this is wrong, especially since \"everyone else seems to\ndo it this way\".\n\nYou can talk about right and wrong, and accessibility, browser and\nplatform neutrality, but the problem is most people /do/ /not/ /care/. \nStudents glaze over.  They especially don't care when doing it the right\nway is vastly more difficult that doing it the wrong way (table based\nlayout for example). Even if it was easy, they still wouldn't care.  And\nfor the most part they don't want to understand why they should care,\nthey just want their page to be cool and work - which they can get with\nlittle effort.\n\nSo, in answer to your question: Human Nature.\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "At 17:17 30/12/2002 -0500, Brant Langer Gurganus wrote:\n\n>John Colby wrote:\n>\n>>\n>>At 11:18 30/12/2002 -0500, Brant wrote:\n>>\n>>>Nigel Peck - MIS Web Design wrote:\n>>>\n>>>>It's great how XHTML is progressing with version 2 etc. but it strikes me\n>>>>that while the W3C is taking the specs into the future the majority of the\n>>>>Web Development world is lagging miles behind.\n>>\n>>\n>>>>For example, a college near to me teaches Web Design. They teach HTML not\n>>>>XHTML. People come out of there happily writing <br> tags and not closing\n>>>>their <p> tags and some will go on to create Web sites.\n>>\n>>\n>>>>For my part I've started a series of articles aimed at teaching XHTML to\n>>>>beginners, if anyone is interested it's at:\n>>>>http://www.miswebdesign.com/resources/articles/web-design-xhtml-1-1.html\n>>>By the time the textbook is printed, it is probably out-of-date and if \n>>>adopted, it takes about five years before new text books are adopted.\n>>>In the worst cases, Web design education is at least six years behind \n>>>the Web specifications.  That is why you still see people writing \n>>>presentationally using invalid HTML 3.2 through a Web editor.  Such is \n>>>the case with my school.  Despite all my efforts, they fail to realize \n>>>that HTML is a markup language that adds meaning, not fancy colors.\n>>\n>>\n>>I'd appreciate anyone's views on this and your opinion of this type of \n>>approach, both for learning style and toolsets, bearing in mind that this \n>>is classroom teaching by lecture and workshop (it may expand later into \n>>print and web media) and is intended to be part of a degree course.\n>\n>Sounds good.  Only problem with Top Style is that it is not monetarily \n>free, but it is definitely good.  I do most of my development personally \n>with either jEdit or Amaya.  jEdit is also in Java so it is cross-platform.\nI'll try jEdit - and of course you're right about the advantages of Amaya - \nbut TopStyle does give an educational discount. And better, the authors can \nmake in un-nickable\n\nStill - thanks for the views - more homework for me.\n\nRegards\n\nJohn\n\nJohn Colby\n\njohn.colby@uce.ac.uk (active early January)\nLecturer in Computing, University of Central England, Franchise Street\nPerry Barr, Birmingham B42 2SU phone +44 (0)121 331 5000\n\njohn@colbyweb.co.uk\n4 Ambion Rise, Market Bosworth, Nuneaton, Warwickshire, CV13 0NY\nPhone +44 (0) 1455 290271, mobile 0771 114 1621 website \nhttp://www.colbyweb.co.uk\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "Alex Rousskov wrote:\n\n>On Mon, 30 Dec 2002, fstorr wrote:\n>  \n>\n>>It really irritates me.  I get called a geek by my intranet manager\n>>at work - this coming from the man who won't use CSS and uses\n>>FrontPage for \"ease\".\n>>    \n>>\n>To make any progress, we have to at least identify the primary\n>obstacle:\n>\n>Are you irritated by the fact that FrontPage is easier to use (for\n>most humans) than writing raw markup? Are you irritated by the fact\n>that Microsoft owns FrontPage? Are you irritated by the fact that\n>other WYSIWYG tools are not as popular/known as FrontPage? Are you\n>irritated by CSS properties that make writing raw CSS/HTML markup\n>difficult and generated markup ugly? Are you irritated by browsers\n>that tolerate invalid markup? Other?\n>\n>In other words, what should be the first priority: changing human\n>nature, changing Microsoft, changing W3C marketing, changing CSS/HTML,\n>or changing browsers?\n>\nThe problems lie in human nature and a little with Microsoft, but \nMicrosoft certainly is not at fault.  They are simply making a product \nthat their customers want so the problem lies more in human nature.  \nPeople think that \"coding\" is a geek thing.  The mission is to change \nthat, especially for markup languages such as HTML/XHTML where you are \ntelling what you mean or CSS where you tell what you want it to look \nlike.  Coding scripting languages and understanding the DOM is beyond \nmost people, even me sometimes so that cannot be expected.\nUsing standard technologies is like building the Tower of Babel (except \nwe are *not* trying to reach Heaven).  Using proprietary technologies is \nlike building the Tower of Babel before God made man speak different \nlanguages.\n\n>Simply declaring that \"valid markup is better than invalid one\" and\n>\"new XHTML is better than old HTML\" or even \"hand-written markup is\n>better than generated markup\" is not going to change much, IMHO. This\n>is an \"evangelist@w3\" mailing list; does evangelism imply pro-active\n>action or just stating personal preferences?\n>  \n>\n-- \nBrant Langer Gurganus\nhttp://troop545.cjb.net/brant.xhtml\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "On 30 Dec 2002, Chris Hubick wrote:\n\n> > In other words, what should be the first priority: changing human\n> > nature, changing Microsoft, changing W3C marketing, changing CSS/HTML,\n> > or changing browsers?\n>\n> The problem is making people care about doing something the /right/\n> way.\n\nFirst of all, I suspect there is no /right/ way to do it, and even if\nthere is, we do not know it. But let's imagine for a moment that we\nknow the right way to do Web design. Why do people not care? Is it\nbecause, by their nature, people prefer \"easier\"  solutions? Is it\nbecause Microsoft made people not care? Is it because W3C marketing is\nnot effective enough? Is it because modern CSS/HTML makes people to\nstay away from what is right? Or do browsers make people do wrong\nthings?\n\nIt is unlikely that you can make people care if you do not know what\ncauses them not to.\n\n> Someone learning how to make web pages can sit down and relatively\n> quickly get the results they want without any regard to proper\n> structural based web design (font tags, etc).  It's hard to explain\n> to them why doing this is wrong, especially since \"everyone else\n> seems to do it this way\".\n\nTrue. Two conclusions can be derived from your observation:\n- either \"proper structural based web design\" is not \"right\"\n  for humans (so we need to change humans or change our notion\n  of what is right)\n- or the environment where people learn encourages \"wrong\"\n  behavior (so we need to change the environment)\n\nWhat we do next depends on which of the above three primary obstacles\nwe want to change (humans, the notion of \"right\", or the environment).\n\n> You can talk about right and wrong, and accessibility, browser and\n> platform neutrality, but the problem is most people /do/ /not/\n> /care/.  Students glaze over.  They especially don't care when doing\n> it the right way is vastly more difficult that doing it the wrong\n> way (table based layout for example). Even if it was easy, they\n> still wouldn't care.  And for the most part they don't want to\n> understand why they should care, they just want their page to be\n> cool and work - which they can get with little effort.\n>\n> So, in answer to your question: Human Nature.\n\nIf you are right, then we are obviously wasting our time here. I do\nnot think it is reasonable to expect that we can change our own Nature\n(except for, perhaps, destroying it).\n\nIn my opinion it is not Human Nature. It is our notion of \"right\"\nand/or the environment that we have created. It is not clear to me\nwhether perfect structural markup is the \"right\" thing for humans to\nuse. Humans are not computers. You say that \"most people do not care\"\nand, hence, \"create wrong markup\". I say that the environment they\ncreate in forces them to create wrong markup.\n\nA student does not care whether the design/markup is structural-based\nor table-based. Thus, a priory, student does not favor one over the\nother! The environment should force that student to favor the \"right\"\napproach. Changing environment is possible, and the first step would\nbe to identify what makes the current environment bad (again, is it\nthe editors, the markup itself, the browsers, etc.?)\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "On Mon, 30 Dec 2002, Brant Langer Gurganus wrote:\n\n> The problems lie in human nature and a little with Microsoft, but\n> Microsoft certainly is not at fault.  They are simply making a\n> product that their customers want so the problem lies more in human\n> nature.\n\nI disagree. I do not think customers _want_ \"wrong\" (e.g., table-based\nor whatever) design. Most customers do not even know what *ML really\nis. They want an easy-to-use tool to create nice-looking Web pages. It\nwas FrontPage authors decision on how to address that customer need\ntechnically. Thus, we can say that\n\n    - FrontPage authors have chosen the wrong technical solution\n      (i.e., we believe there are ways to produce\n      the \"right\" markup from markup-unaware user inputs)\n\n    - and/or markup itself makes it impossible or impractical\n      to produce the \"right\" markup from markup-unaware user inputs)\n\n> People think that \"coding\" is a geek thing.\n\nAnd it certainly is! An ideal human-oriented interface should not use\ncomputer-oriented codes.\n\n> The mission is to change that, especially for markup languages such\n> as HTML/XHTML where you are telling what you mean or CSS where you\n> tell what you want it to look like.\n\nI disagree that we should focus on making coding more popular. I do\nnot think it is the right direction to go, given human nature. For\nexample, this e-mail thread uses English to exchange ideas; we would\nnot go too far if we had to use computer code for that. If we assume\nthat \"Web designers\" are not a small elite group of people but\nvirtually everybody with Internet access, then making them code is\nwrong and will not work as long as others can provide \"easier\"\nalternatives (like FrontPage does).\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "On Mon, 2002-12-30 at 16:10, Alex Rousskov wrote:\n> On 30 Dec 2002, Chris Hubick wrote:\n> > The problem is making people care about doing something the /right/\n> > way.\n> \n> First of all, I suspect there is no /right/ way to do it, and even if\n> there is, we do not know it.\n\nThe web was invented to separate structure and presentation, doing so is\n\"right\".\n\n>  But let's imagine for a moment that we\n> know the right way to do Web design. Why do people not care? Is it\n> because, by their nature, people prefer \"easier\"  solutions?\n\nMy outlook on humanity is fundamentally cynical in nature.\n\nI would say mainly, yes, to the \"easier solutions\" being the major\nculprit.  As I said...people can easily get a web page which /appears/\nto work for them and (or 95% of) their users without having to learn\nmuch.\n\n>  Is it because W3C marketing is not effective enough?\n\nIn part, possibly.\n\nThe designers I know don't take accessibility and browser neutrality to\nheart.  We need more Mac and Linux desktops, more WebTV's, more Mozilla\nbrowsers deployed, millions of handhelds with wireless web access, and\nevery web designer needs a deaf or blind person as their boss.  These\nissues aren't \"real\" enough to most of them.  They think if the page\nworks on their 15\" monitor running Internet Explorer then all is well.\n\n\n>  Is it because modern CSS/HTML makes people to\n> stay away from what is right? Or do browsers make people do wrong\n> things?\n\nI think the browsers strict handling of XHTML will probably mean that it\nwill be extremely difficult to catch on.  I think if we would have\nstarted out with this behavior 10 years ago, we might all be using\ngopher or something today.  The reason the web is so successfull is\nbecause of the low barrier to entry.  I think there is also a very high\nelasticity of difficulty.  That is, make it a /little/ harder and you\nwill drop a /lot/ of web authors.\n\nI think XHTML 2 will be the first markup language which will even make\nit possible to realize the full ideals of the web while still creating\ncomplex and attractive sites.  We still litter around our structure with\nthe use a lot of presentational oriented div's and span's today, which\nwe arguable shouldn't.  The richer semantics of XHTML 2, such as\nsections, might make that possible.\n\n> > Someone learning how to make web pages can sit down and relatively\n> > quickly get the results they want without any regard to proper\n> > structural based web design (font tags, etc).  It's hard to explain\n> > to them why doing this is wrong, especially since \"everyone else\n> > seems to do it this way\".\n> \n> True. Two conclusions can be derived from your observation:\n> - either \"proper structural based web design\" is not \"right\"\n>   for humans (so we need to change humans or change our notion\n>   of what is right)\n> - or the environment where people learn encourages \"wrong\"\n>   behavior (so we need to change the environment)\n> \n> What we do next depends on which of the above three primary obstacles\n> we want to change (humans, the notion of \"right\", or the environment).\n> \n\nI think it is the environment.  I think web authors need to be directly\nexposed to the vast array of user agents out there.  They need to be\nshown their sites on everything from PC's, Macs, Unix boxes, PDA's,\nBraille terminals, voice browsers, etc, etc, etc.  And I think they need\nbetter examples.  I think Wired's redesign is in the right direction\n(but still far from ideal).  We need more good examples of real and\nattractive sites which can display on any device.\n\n> If you are right, then we are obviously wasting our time here. I do\n> not think it is reasonable to expect that we can change our own Nature\n> (except for, perhaps, destroying it).\n> \n> In my opinion it is not Human Nature. It is our notion of \"right\"\n> and/or the environment that we have created. It is not clear to me\n> whether perfect structural markup is the \"right\" thing for humans to\n> use. Humans are not computers. You say that \"most people do not care\"\n> and, hence, \"create wrong markup\". I say that the environment they\n> create in forces them to create wrong markup.\n> \n> A student does not care whether the design/markup is structural-based\n> or table-based. Thus, a priory, student does not favor one over the\n> other! The environment should force that student to favor the \"right\"\n> approach. Changing environment is possible, and the first step would\n> be to identify what makes the current environment bad (again, is it\n> the editors, the markup itself, the browsers, etc.?)\n\nYou have to draw the line somewhere.\n\nI personally find using and HTML editor (which hides the details) /more/\ndifficult that doing it by hand with the spec handy, when creating a\ncomplex page.\n\nAre a plethora of icons easier to learn than </> ?  People seem to\nfundamentally rebel against learning anything non-trivial.\n\nI don't think the problem is any of these things though. I think the\nproblem is expectations.\n\nPeople expect to be able to have control over things like fonts and\nsizes, positioning, etc.  They miss out on the fundamental fact that\nthey web is TRYING TO TAKE THAT CONTROL AWAY, and they fight against it\nfrom start to finish.  Traditional media thinking, rather than web\nthinking.  Even people doing their first design in any medium have\ntrouble really grokking these concepts - or they give up and forget\nabout them when it get's down to the dirty details.\n \nThe web is a new paradigm medium filled with old paradigm thinking.\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "On 30 Dec 2002, Chris Hubick wrote:\n\n> The web was invented to separate structure and presentation, doing\n> so is \"right\".\n\nIIRC, the Web was invented to ease information sharing in the first\nplace. The structure versus presentation separation came in later and\nis secondary.  Moreover, regardless of the original design goals, the\nquestion is whether humans should be tought to write better markup OR\nwhether computers should be built to generate better markup (based on\ninputs from a human-oriented interface).\n\n> I would say mainly, yes, to the \"easier solutions\" being the major\n> culprit.  As I said...people can easily get a web page which\n> /appears/ to work for them and (or 95% of) their users without\n> having to learn much.\n>\n> The designers I know don't take accessibility and browser neutrality\n> to heart.  We need more Mac and Linux desktops, more WebTV's, more\n> Mozilla browsers deployed, millions of handhelds with wireless web\n> access, and every web designer needs a deaf or blind person as their\n> boss.  These issues aren't \"real\" enough to most of them.  They\n> think if the page works on their 15\" monitor running Internet\n> Explorer then all is well.\n\n...\n\n> I think it is the environment.  I think web authors need to be\n> directly exposed to the vast array of user agents out there.  They\n> need to be shown their sites on everything from PC's, Macs, Unix\n> boxes, PDA's, Braille terminals, voice browsers, etc, etc, etc.\n\nOK. It is technically trivial to show users how their pages look/sound\nin all non-IE browsers. I am sure W3C can make that kind of service.\nOf course, it would make no difference until there are enough\n``non-IE'' users out there! So do we wait until there are more non-IE\nusers around, then?\n\nOr is it possible to build tools that generate markup that works OK\nfor non-IE users based on a naive non-markup [FrontPage] user input?\n\nIn other words, who is responsible for content-versus-structure\nseparation and other good-design principles? Is it a grandma posting a\npicture of a flower on the Web? Or is it the software that helps the\ngrandma to post that picture?\n\n> People expect to be able to have control over things like fonts and\n> sizes, positioning, etc.  They miss out on the fundamental fact that\n> they web is TRYING TO TAKE THAT CONTROL AWAY, and they fight against\n> it from start to finish.  Traditional media thinking, rather than\n> web thinking.  Even people doing their first design in any medium\n> have trouble really grokking these concepts - or they give up and\n> forget about them when it get's down to the dirty details.\n\nIf the medium is so powerful, flexible, and complex, should not it be\nthe computer job to cross-compile user input so that it works well in\nmany environments?\n\nAre we expecting the majority of Web designers to program in and be\nexcited about a Web-equivalent of an assembly language? Should we try\nto learn from past mistakes and migrate to something more\nhuman-oriented like a Web-equivalent of C++ or Java, leaving assembly\nstage to the computer?\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "At 08:35 AM 12/30/2002, Nigel Peck wrote:\n>And there's no way Browser manufacturers will move browsers to a non\n>backwards compatible language until a very high percentage of users are\n>aware of it.\n\nI would venture to say that's the last criterion that will play a factor, \nnot the main one.\n\nDoes the average user today care if the page they're viewing is written in \nHTML 3.2, XHTML 1.0, or typed out by a hamster inside the browser?  As long \nas they get the experience from the page they expect, my guess would be no.\n\nYou won't see browser manufacturers abandon backwards compatibility with \nthe existing iterations of HTML unless a very high percentage of sites have \nabandoned it.  Don't expect to see that happen for many, many years.  The \nsheer volume of legacy content will preclude it, because there is no good \nrationale to forward-convert all that legacy code into a new HTML version.\n\nBill Mason\nAccessible Internet\nw3c@accessibleinter.net\nhttp://www.accessibleinter.net/\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "At 10:05 AM 12/30/2002, John Colby wrote:\n>Initially the coding will be performed using a text editor - the \n>organisation's Windows only at the moment but I've already had discussions \n>about Linux and deploying it more widely. - but the one and only tool I've \n>been able to feel comfortable with is TopStyle Pro \n>(http://www.bradsoft.com) and although I've been trying to get to grips \n>with Arachnophilia (http://www.arachnoid.com/arachnophilia/) I haven't yet \n>been satisfied that I can convert it all into XHTML 1.1 compliant mode \n>without a load of work (where'd all the time go!?). Although it's free \n>doesn't seem to be approaching the code from the 'right' way IMHO. \n>Dreamweaver is a great tool, but a no-no because of cost. I'm going to get \n>them to process graphics with the GIMP.\n>\n>I'd appreciate anyone's views on this and your opinion of this type of \n>approach, both for learning style and toolsets, bearing in mind that this \n>is classroom teaching by lecture and workshop (it may expand later into \n>print and web media) and is intended to be part of a degree course.\n\nUnless you're also teaching serving XHTML 1.1 with the correct MIME type, \nwhy that matters, and what it means to legacy browsers, it's my option that \nteaching to XHTML 1.1 is overkill and possibly even a disservice.\n\nThere's no reason that an HTML 4.01 course cannot be done that also teaches \ngood semantics, separation of content/presentation, standards, \naccessibility, etc.  Just because 4.01 allows for paragraphs with no ending \ntag means one has to teach coding that way....\n\nWith the skills mastered, they transfer to XHTML 1.0, 1.1, and forward into \nthe future.  It's just a matter of understanding the \ngrammatical/syntactical differences, knowing what may have been \ndeprecated/obsoleted, and so forth.\n\nBill Mason\nAccessible Internet\nw3c@accessibleinter.net\nhttp://www.accessibleinter.net/\n\n\n\n"
        },
        {
            "subject": "Re: Promotion of XHTM",
            "content": "\"John Colby\" <John.colby@btinternet.com>\n> At 11:18 30/12/2002 -0500, Brant wrote:\n> I'll also introduce the difference between bold and strong tags with\n> reference to speech browsers as well as visual. All this is in XHTML 1.1.\n> So the initial development is not so much XHTML as the presentation of\n> information across the web to a variety of internet devices.\n\nAll very good in theory, but you're missing the legacy aspect (well actually\nmore current, you're cresting a wave) XHTML 1.1 is not suitable for\ndeployment on the web alone, so unless you're going to also discuss\ntechniques for content negotiation and authoring multiple formats you should\nreally reconsider.\n\nI'd start with HTML 4.01, but as the thread is \"promotion of XHTML\" I\nwouldn't be too hard if you decided on XHTML 1.0 Appendix C.  Although the\nidea of doing QA against an Appendix written in prose and with all sorts of\n\"best avoided's\" in strikes me as rather difficult.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Right Tools RE: Promotion of XHTM",
            "content": "At 23:20 -0700 2002-12-30, Alex Rousskov wrote:\n>Or is it possible to build tools that generate markup that works OK\n>for non-IE users based on a naive non-markup [FrontPage] user input?\n\n\n* Specification case\n\nI think that at least it's possible to improve what we have right \nnow. It's not really the HTML mistake.\n\nResponsibility belongs to the specification when it's hard to \nimplement or ambiguous. When you don't have enough test cases, when \nthe clarity of the spec is not obvious, etc.\n(Clarity of the spec is useful for teachers who teach to \nfuture engineers, etc.)\n\nBut let's talk about tools.\n\n* Visual layout and structure.\n\nUsers (Content editors) want something to use. When you read a \nmagazine, a book, etc. You guess the structure from the visual layout \nof the document. When you write a letter, a class, a report in a \nmeeting or a mail, you do a kind of visual presentation to explain \nthe structure, exactly as I did in this email (and there's no precise \nguide to visually present email :) )\n\nSo people are used to guess the structure of a document from the \nvisual presentation and not from the structure itself. It's even \nsublter than that because they do not really analyze there's a \nstructure, but their brain recognize that this is the title of the \nbook, because it's the big think with large letters in the middle of \nthe book at the first page. But they do not verbally say \"Hey, that's \nthe title\". It's more on the Pavlov side.\n\n* Editing tools for Structure\n\nTo create an editing tool, we have to try to mock-up in part the way \nthe human will act or think and to try to produce the right content \nbehind. Let's take a short look at what already exists in this kind \nof structural editing tools that COULD work but doesn't really now.\n\n- Word (mode Plan)\nThere's a way to structure your document in a very structured \nway in Word. Unfortunately, most of the people do not use it at all, \nor use it correctly. If you use it correctly, you can apply styles to \nyour documents and have automatic generation of Table of Contents, \nlist of tables and images, etc.\nIt's not as powerful as LaTeX, but it's very close.\n- QuarkXPress\nThat's quite the same you have in this tool a lot of \npossibility to apply a structure to a document and apply particular \nstyle rules to the whole document. Most of the newspapers, magazines, \nannual reports, etc. are (were) done with this tool. Unfortunately, \nthere are only a few people who uses it correctly.\n- Outliners\nthese tools are very structured by their nature and you could \nthink that there's a solution here. And there's one, except that the \nuser interface is missing. An interface that will help the edition.\n\nAll these tools miss something, human nature? or bad user interface metaphor?\n\n* Content first!\n\nPeople do not really care about the structure of the mark-up except \nif they really have a benefit for using it. You will only modify the \nhabits of people, only they can improve what they write, make it \nfaster or fun. They have to enjoy the cost of doing the right way.\n\nI think HTML 4.01 is a language which is strongly semantics already, \nbut that we have difficulty to understand the semantics, because \nthere's more than one way to do it. What's missing to the HTML 4.01 \nspecification is a DETAILED semantic guide for using the tags. I hope \nwe will have that for XHTML 2.0 and I encourage people on this list \nto review the specs and propose strong request for that. Imagine \nXHTML 2.0 on the user side but with a Semantics magnifier.\n\nSo don't write Code, but write content.\n\n* Editing Tools\n\nHow to achieve this semantic mark-up without annoying the users? It \nwill be a kind of Christmas wish list.\n\n1. I DO NOT want an editor which says \"add a strong\", \"add a \nblockquote\", etc...\n2. I DO NOT want an editor which says \"make it bold\", \"indent your \ntext on the right\"\n3. I want an editor where I can write plain text.\n4. I want a logical editor\n\nWhen I want to add a title to my document like it doesn't have a \npossibility of styling the document for example with an element \n\"strong\" or with a font face thingy.\nI want \"add a title\" and when I do that, it put a h1 element \nat the top of the page, but I don't even know that's an h1. If I want \nI can precise the style of the h1, and it will create a css with the \nstyle chosen and that will define the style for h1 { ... }\nIn the menu, I can have \"add a section\", \"add a citation\", etc...\n\nFor example, When I add a citation, I will have a pop-up window in my \nbrowser and will have the possibility to give the text and URIs and \ndepending on the context it will add a q or a blockquote, with the \ncite at the right place. The problems with the HTML 4.01 \nSpecification is the precise use of the markup is not enough explain \nto make the implementer's life easy.\n\nFor example, we can say I want to insert a piece of code in my \nwebpage. What the developper must implement?\n\n<pre>\nwhile (1) :\n         print \"Hello World\";\n</pre>\n\nor\n\n<pre><code>\nwhile (1) :\n         print \"Hello World\";\n</code></pre>\n\n\nor .... etc.\n\n* Any hopes?\n\nWe have to improve the specifications for sure, we have to improve \nthe software, we will not be able to change the human nature (except \nif HTML is teached in the right way in schools).\n\nI'm still waiting for the Semantics HTML book too. I have discussed \nalready about that with Molly Hoszchlag. There are no books which \ngives the semantic view of a spec and explain how to use the semantic \nof the language. More of the books, repeat what the specs say will \nmore context, and more examples.\n\nA Semantics book is still to write... ahhh... If I had more time.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Right Tools RE: Promotion of XHTM",
            "content": "Karl Dubost wrote:\n\n> * Editing Tools\n>\n> How to achieve this semantic mark-up without annoying the users? It \n> will be a kind of Christmas wish list.\n>\n> 1. I DO NOT want an editor which says \"add a strong\", \"add a \n> blockquote\", etc...\n> 2. I DO NOT want an editor which says \"make it bold\", \"indent your \n> text on the right\"\n> 3. I want an editor where I can write plain text.\n> 4. I want a logical editor\n>\n> When I want to add a title to my document like it doesn't have a \n> possibility of styling the document for example with an element \n> \"strong\" or with a font face thingy.\n>     I want \"add a title\" and when I do that, it put a h1 element at \n> the top of the page, but I don't even know that's an h1. If I want I \n> can precise the style of the h1, and it will create a css with the \n> style chosen and that will define the style for h1 { ... }\n>     In the menu, I can have \"add a section\", \"add a citation\", etc...\n>\n> For example, When I add a citation, I will have a pop-up window in my \n> browser and will have the possibility to give the text and URIs and \n> depending on the context it will add a q or a blockquote, with the \n> cite at the right place. The problems with the HTML 4.01 Specification \n> is the precise use of the markup is not enough explain to make the \n> implementer's life easy.\n>\n> For example, we can say I want to insert a piece of code in my \n> webpage. What the developper must implement?\n>\n> <pre>\n> while (1) :\n>         print \"Hello World\";\n> </pre>\n>\n> or\n>\n> <pre><code>\n> while (1) :\n>         print \"Hello World\";\n> </code></pre>\n>\n>\n> or .... etc.\n\nIsn't the Amaya project a \"testbed for W3C technologies\".  In my \nopinion, that means it should not only implement HTML, XHTML, MathML, \nSVG, CSS, etc., but it should also be a model browser and a model \neditor.  However, it doesn't seem that a significant amount of people \nuse Amaya and only about three people develop on it.  Once you get \nbeyond the learning curve of it, it is a tool that writes documents that \nare fairly well structured.  However, it fails Karl's first two points.  \nWe should encourage its usage and development to make it that model tool \nfor both developers and users.\n\n-- \nBrant Langer Gurganus\nhttp://troop545.cjb.net/brant.xhtml\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "RE: Right Tools RE: Promotion of XHTM",
            "content": "For example, When I add a citation, I will have a pop-up window in my \nbrowser and will have the possibility to give the text and URIs and \ndepending on the context it will add a q or a blockquote, with the \ncite at the right place. The problems with the HTML 4.01 \nSpecification is the precise use of the markup is not enough explain \nto make the implementer's life easy.\n\n+++++++\n\nDreamweaver MX sort of does this if you have all the Accessibility\noptions turned on - it'll prompt for alt + longdesc attributes for an\n<img> element, caption, summary and headings for <table> elements etc.\n\nWhat would make it easier would be some kind of basic WYSIWYG CSS\neditor.  For example you select \"page heading\" (meaning <h1>) then\nselect from a list of fonts, font weights + styles, background colors\netc.  This would then update the css attached to a page.  The actual\nX/HTML editor could run with a series of prebuilt templates (a la\nMicrosoft's \"Wizards\") that could generate 2, 3 column layouts, etc etc\nalong with user prompts for things such as <q> <blockquote>, <address>,\ncaption etc etc.  If it came with a good set of documentation so that\nnew users could be \"puppy walked\" through exactly why, for example, a 3\ncolumn floated layout might or might be a good idea, and how it works\n(and what exactly \"float\" is!) in plain, easy to userstand language,\nthis might get people more interested in the code side of it.  Add into\nthis something like TopStyle's excellent \"this won't work in Netscape 4,\nOpera and IE5\" thing that it has for CSS and a validator, it would be\nquite a nice tool. And, if the editors generated good code, it might not\nscare the pants off anyone looking at X/HTML for the first time.\n\n+++++++\n\nWe have to improve the specifications for sure, we have to improve \nthe software, we will not be able to change the human nature (except \nif HTML is teached in the right way in schools).\n\n+++++++\n\nIf the specs were easier to understand for the \"non-geek\" and were\npromoted as \"the right way to go\" we might see more people using\nstandards. There are more and more articles and books coming out about\naccessibility and standards, and maybe if the W3C really promoted the\n\"accessible to more users\", \"easier to update mass content with CSS\"\nangles, amongst other things, (yes I know that they do, but how much of\nthat is preaching to the converted - people who actually use and read\nW3C.org all the time) people might start to be more interested in the\nworkings of a page rather than just presentation.\n\nHave a good new year.\n\nFrancis\n\n\n\n"
        },
        {
            "subject": "Re: Right Tools RE: Promotion of XHTM",
            "content": "On Tue, Dec 31, 2002 at 07:51:09PM -0000, fstorr wrote:\n> \n> What would make it easier would be some kind of basic WYSIWYG CSS\n> editor.  For example you select \"page heading\" (meaning <h1>) then\n> select from a list of fonts, font weights + styles, background colors\n> etc.  This would then update the css attached to a page.  The actual\n> X/HTML editor could run with a series of prebuilt templates (a la\n> Microsoft's \"Wizards\") that could generate 2, 3 column layouts, etc etc\n> along with user prompts for things such as <q> <blockquote>, <address>,\n> caption etc etc.  If it came with a good set of documentation so that\n> new users could be \"puppy walked\" through exactly why, for example, a 3\n> column floated layout might or might be a good idea, and how it works\n> (and what exactly \"float\" is!) in plain, easy to userstand language,\n> this might get people more interested in the code side of it.  Add into\n> this something like TopStyle's excellent \"this won't work in Netscape 4,\n> Opera and IE5\" thing that it has for CSS and a validator, it would be\n> quite a nice tool. And, if the editors generated good code, it might not\n> scare the pants off anyone looking at X/HTML for the first time.\n\nI think the point is that no one should have to look at the HTML \nor really understand what CSS is :) It's the content that matters,\nnot how it's done.  But a tool like this which may aid designers\nin the creation of Web templates would be nice.\n\nDoes anyone here know of any software developers (or would can collate\na team together) to make such a tool a reality?\n\n> If the specs were easier to understand for the \"non-geek\" and were\n> promoted as \"the right way to go\" we might see more people using\n> standards. There are more and more articles and books coming out about\n> accessibility and standards, and maybe if the W3C really promoted the\n> \"accessible to more users\", \"easier to update mass content with CSS\"\n> angles, amongst other things, (yes I know that they do, but how much of\n> that is preaching to the converted - people who actually use and read\n> W3C.org all the time) people might start to be more interested in the\n> workings of a page rather than just presentation.\n\nThe W3C specs were never really geared for the general Web development/\ndesign audience - I presume the target audience of the specs is for\nthose who actually implements Web software, be it user-agents or\neditors. \n\nIMHO, it's not enough to just say the W3C should really promote this\nor that - they are comparable to a standards body - lately, when I\ndescribe the kind of standards evanglism I am involved in to non-Web\npeople, I mention a similarity to the ISO. Don't you think it is really \nup to us, designers and developers who have been converted, to preach \nto our colleagues and educate the next generation of developers?\n\nI wish all a fabulous new year. :)\n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "Re: Right Tools RE: Promotion of XHTM",
            "content": "At 07:28 01/01/2003 +1100, Steph wrote:\n\n\n>IMHO, it's not enough to just say the W3C should really promote this\n>or that - they are comparable to a standards body - lately, when I\n>describe the kind of standards evanglism I am involved in to non-Web\n>people, I mention a similarity to the ISO. Don't you think it is really\n>up to us, designers and developers who have been converted, to preach\n>to our colleagues and educate the next generation of developers?\n\nYes, yes, and once again, yes! This is the only way that standards will get \nknown about - by talking about them. Peer example, peer education, peer \npressure if you like - to get more and more people talking about standards \nand the reasons why they a great advantage.\n\nI got into standards because I was (and still am) lazy - I was looking for \nways of writing pages once for all browsers and browsing devices rather \nthan writing exceptions and exclusions. This is why the standards route was \nattractive to me, and then I started learning about problems with \naccessibility as I learned more about people's use of the web.\n\nAnd now standards seem so attractive rather than any non-standard route, \nnot as an end in themselves but because I can continue to be lazy and code \nonce for all users.\n\nAs an aside, I wonder if IE7 will be less buggy with regards to stylesheet \ncompliance? If there ever is going to be an IE7, that is.\n\nRegards\n\nJohn \n\n\n\n"
        },
        {
            "subject": "welcome to PublicEvangeLis",
            "content": "Welcome to this new forum. This is a forum creation test message.\nfor public-EvangeList@w3.org, the web standards education\nand outreach forum hosted at W3C.\n\n-- \nOlivier Thereaux \n\n\n\n"
        },
        {
            "subject": "My Evangelism Effort",
            "content": "I though I would be the first to post to this new list by introducing \nmyself and my evangelism efforts.  I am a high school senior with a \nlarge interest in computer, the Internet, and the World Wide Web.  I \nlearned HTML, CSS, and the other World Wide Web technologies from the \nactual specifications.  I have since become involved in Mozilla \nEvangelism where I have submitted a \"Standards Redirector.\"  I am also \ncreating some articles to publish at moz.zope.org about the Mozilla \nEvangelism effort.  I believe the best way to urge other webmasters to \nfollow the standards of the Internet and the World Wide Web is by \nexample and by creating standards-compliant browsers such as Mozilla \nwhich do not always show pages correctly if they do not follow the \nstandards.\nI would like to hear about the Evangelism efforts of other people so \nplease reply about my activities or about your own.\n\n-- \nBrant Langer Gurganus\nMore depends on will power than on brain power.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Publicevangelist, goals and expectation",
            "content": "Hi, and welcome on public-evangelist!\n\nThanks for all of you that have subscribed so fast to this new mailing\nlist: this is a good omen for the work that we want to see happen\nhere!\n\nLet me just introduce quickly the context and goals of this forum: it\nhas been created as part of the Quality Assurance Activity [1] at W3C (I\nassume you all know what W3C is :). Formally speaking, it is part of the\neducational mission of the QA Interest Group [2].\n\nAs described on the mailing list home page [3], this forum aims to be a\nplace to coordinate the efforts of people trying to make the Web a\nbetter, more interoperable system by inciting compliance to open\nstandards. The kind of cooperations we can imagine:\n- sharing resources, documents, tips and tricks, experiences\n- writing articles, publicizing them across various audiences\n- helping articles and books writers with understanding the standards\nthe right way\n- organizing some network events to publicize the standards (?)\n\nThis is of course not an exhaustive list, and any ideas to complete it\nwould be a good start of discussion! \n\nSome important points:\n- this is a publicly archived mailing list, so everything you sent here\nwill be available to anyone (and this includes your email address and\nany information in your signature)\n- we'll have to set some limits on how far we can help tech writers: we\ndon't give any \"W3C seal of approval\", nor can we do their jobs for\nthem.\n\n\nI know that we have some people from the Mozilla Tech Evangelism Team,\nsome from the WASP project, but probably many others I don't know\nanything about: please feel free to introduce yourself and explain what\nare your expectations from this forum, the projects you have in mind and\nany other relevant informations!\n\nThank you very much, and again, welcome.\n\nDom\n\n1. http://www.w3.org/QA/\n2. http://www.w3.org/QA/IG/\n3. http://lists.w3.org/Archives/Public/public-evangelist/\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n"
        },
        {
            "subject": "I'm here because I'm lazy  a personal intro",
            "content": "I?m here because I?m lazy.\n\nI don?t like having to do work twice ? different conditional markup and scripting for different browsers. I live and work in the U.K. and have both professional and personal interests in websites.\n\nHaving become aware of the Web Standards movement through WaSP a couple of years ago I?m trying to apply this philosophy to both work and home sites. At home I can play as I like, at work I am faced with a committee or two and specifications that are not open, and a narrow subset of browsers used for testing.\n\nIt was the realisation that my existing sites were not suitable for use by people with visual difficulties that made me stop and reassess what I was doing and how I could improve matters. The writing of an educational site for someone else (a charity) made me realise that it was sea change that was needed. For this I?m concentrating on blindness and colour blindness as a start. The RNIB (UK sight organisation) has been helpful in providing guidelines for some of this. \n\nSo my aims are to write everything in XHTML 1.1 using CSS and minimal client side scripting ? I?ll have to use server side scripting using PHP to access MySQL ? and display results in non-conformant browsers (e.g. NS4 series) with a warning message. I?ll test in Opera 6, IE,6, NS 7 and Moz 1 as there are the browser offering of the future, and also internet devices and mobiles as and when I can persuade my friends to see how sites look on theirs. I?ll also try to find speech browsers so that I can check that my sites make sense.\n\nRegards evangelism ? I?m in the middle of writing a personal site promoting Web Standards for the amateur site builder ? and trying to assist friends in making sites compliant. At work I am running education courses for Web Standards ? but I really need big guns to get on my side for this to have a real effect.\n\nAnd from this forum ? hopes that there are sufficient people contributing from the grass roots of web design rather than just the experts ? and one of the things I?m looking for is ideas on how best to promote standards and education material which is as good (or better) a quality as that already available for non-standards HTML.\n\nAbove all we really need a consistent approach that can be followed, maybe by grading educational material already out in the public domain as suitable/not suitable for standards complaint education. \n\nRamble over.\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Re: I'm here because I'm lazy  a personal intro",
            "content": "john.colby@btinternet.com wrote:\n\n>Im here because Im lazy.\n>\nI'm here because this is a big job and every bit helps.\n\n>\n>I dont like having to do work twice  different conditional markup and scripting for different browsers. I live and work in the U.K. and have both professional and personal interests in websites.\n>\nWell, that is why the standards were created.\n\n>\n>Having become aware of the Web Standards movement through WaSP a couple of years ago Im trying to apply this philosophy to both work and home sites. At home I can play as I like, at work I am faced with a committee or two and specifications that are not open, and a narrow subset of browsers used for testing.\n>\n>It was the realisation that my existing sites were not suitable for use by people with visual difficulties that made me stop and reassess what I was doing and how I could improve matters. The writing of an educational site for someone else (a charity) made me realise that it was sea change that was needed. For this Im concentrating on blindness and colour blindness as a start. The RNIB (UK sight organisation) has been helpful in providing guidelines for some of this. \n>\nI have never written a website for hire. All sites I create are \nstandards-compliant and because I don't have to go through a review \nprocess, I can keep things simple, accessible, and admistratable.\n\n>\n>So my aims are to write everything in XHTML 1.1 using CSS and minimal client side scripting  Ill have to use server side scripting using PHP to access MySQL  and display results in non-conformant browsers (e.g. NS4 series) with a warning message. Ill test in Opera 6, IE,6, NS 7 and Moz 1 as there are the browser offering of the future, and also internet devices and mobiles as and when I can persuade my friends to see how sites look on theirs. Ill also try to find speech browsers so that I can check that my sites make sense.\n>\nHey, I haven't figured out if XHTML 1.1 is actually the latest HTML. \nhttp://www.w3.org/TR/html gives XHTML 1.0.\n\n>\n>Regards evangelism  Im in the middle of writing a personal site promoting Web Standards for the amateur site builder  and trying to assist friends in making sites compliant. At work I am running education courses for Web Standards  but I really need big guns to get on my side for this to have a real effect.\n>\nWell, if you saw my other message, I want to complile a list of sites \nlike this.\n\n>\n>And from this forum  hopes that there are sufficient people contributing from the grass roots of web design rather than just the experts  and one of the things Im looking for is ideas on how best to promote standards and education material which is as good (or better) a quality as that already available for non-standards HTML.\n>\nI think a Evangelism day would be cool, similar to Bug days for Mozilla. \nWe would write an article or something about the standards and submit it \nto as many places as possible.\n\n>\n>Above all we really need a consistent approach that can be followed, maybe by grading educational material already out in the public domain as suitable/not suitable for standards complaint education. \n>\nI learn from the actual specifications since most references are \noutdated or encourage presentational markup instead of semantic markup.\n\n>\n>Ramble over.\n>\n>John\n>\n>\n>  \n>\n\n\n-- \nBrant Langer Gurganus\nDon't complain about problems, solve them.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Evangelism Site Lis",
            "content": "I'd like to come up with a good set of references.  I'd like to start by \nlisting sites that have articles about writing standards-compliant HTML \nor how to fix problems with proprietary HTML:\n\n   * http://www.w3.org\n   * http://mozilla.evangelism.bclary.com\n   * http://www.webstandards.org\n   * http://developer.netscape.com/evangelism\n\nPlease add sites you know of to the list.  As I receive responses, I \nwill add them to my home page.\n\n-- \nBrant Langer Gurganus\nDon't complain about problems, solve them.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Re: Evangelism Site Lis",
            "content": "Brant Langer Gurganus said:\n>\n> I'd like to come up with a good set of references.  I'd like to start by\n>  listing sites that have articles about writing standards-compliant HTML\n>  or how to fix problems with proprietary HTML:\n>\n>    * http://www.w3.org\n>    * http://mozilla.evangelism.bclary.com\n>    * http://www.webstandards.org\n>    * http://developer.netscape.com/evangelism\n>\n> Please add sites you know of to the list.  As I receive responses, I\n> will add them to my home page.\n\nevolt.org has articles on these things, among others.\n\nLach\n_____________________________________\nhttp://members.evolt.org/luminosity/\nMSN: luminosity @ members.evolt.org\n_____________________________________\n\n\n\n"
        },
        {
            "subject": "Re: Evangelism Site Lis",
            "content": "Brant Langer Gurganus wrote:\n> I'd like to come up with a good set of references.  I'd like to start by \n> listing sites that have articles about writing standards-compliant HTML \n> or how to fix problems with proprietary HTML:\n> \n>    * http://www.w3.org\n>    * http://mozilla.evangelism.bclary.com\n>    * http://www.webstandards.org\n>    * http://developer.netscape.com/evangelism\n> \n> Please add sites you know of to the list.  As I receive responses, I \n> will add them to my home page.\n\nHow about <http://www.alistapart.com/>? Their articles include \"How To \nRead W3C Specs\" and \"Modifying Dreamweaver To Produce Valid XHTML\".\n\n/Jonas\n\n\n\n"
        },
        {
            "subject": "Re: Publicevangelist, goals and expectation",
            "content": "Hello everyone,\n\nThanks to Karl Dubost from the QA group for getting me involved. We met at\nthe WWW conference in Hawaii not long ago, and I was very happy to hear\nabout plans for this then, and to see it come to fruition now.\n\nMy intro:  I'm Molly, I write books on HTML, XHTML, CSS, and web design and\ndevelopment topics as well as train and speak internationally on W3C\ntechnologies.  I am always working harder to better personally understand\nand in turn be able to express W3C ideas and methods to practitioners, and\nmy participation here is in hopes of gaining support, insight, and guidance\nwhen working to present this information to the public.\n\nI am a steering committee member of WaSP, on the Buzz team and co-editor of\nthe LEARN section (http://www.webstandards.org/).  I am working with the\nWorld Organization of Webmasters (WOW) to boost their interest in standards\n(and convince them to get their site up to par!) since they serve a very\nlarge population (http://www.joinwow.org/).  For more about me, you can\ncheck out my web site at http://www.molly.com/.\n\nI look forward to working with everyone here.\n\nVery best,\nMolly :)\nMolly E. Holzschlag\nauthor + instructor + web designer\nhttp://www.molly.com/\n\n\n\n"
        },
        {
            "subject": "Re: I'm here because I'm lazy  a personal intro",
            "content": "I'm here because I love the web. It's wonderful how it is, but no-one has\nyet even begun to realise the potential of what we can do with this thing.\n\nIf the web is going to keep evolving, it needs to do it based on a set of\nstandards which everyone follows, which luckily seems to be the direction\nthe tools, and quite a few of the authors are currently heading towards.\n\nAs I become more involved with newer technologies, I'm finding a distinct\nlack of any decent documentation, suitable for the average person at all.\nIf we do want to build the future's systems, I think that there needs to\nbe better learning materials, and tools, such that it's easy for anyone to\nparticipate in it. Things like RSS are fine, but they don't become as\npowerful as they should be until everyone starts using them. I want to be\none of those who joins in in being ahead of the pack, implementing new and\ncool stuff, and making sure everyone else is able to follow.\n\nTherefore, I want to see good powerful standards released, and I want to\nsee people such as myself playing with them, figuring out what we can do\nwith them, contributing towards making the next versions even better than\nthe previous ones, and most importantly teaching those who haven't reached\nthat level yet so that they can participate, and add to the tapestry that\nwe're all building.\n\nLach\n_____________________________________\nhttp://members.evolt.org/luminosity/\nMSN: luminosity @ members.evolt.org\n_____________________________________\n\n\n\n"
        },
        {
            "subject": "Re: Evangelism Site Lis",
            "content": "Jonas J?rgensen wrote:\n\n>\n> Brant Langer Gurganus wrote:\n>\n>> I'd like to come up with a good set of references.  I'd like to start \n>> by listing sites that have articles about writing standards-compliant \n>> HTML or how to fix problems with proprietary HTML:\n>>\n>>    * http://www.w3.org\n>>    * http://mozilla.evangelism.bclary.com\n>>    * http://www.webstandards.org\n>>    * http://developer.netscape.com/evangelism\n>>\n>> Please add sites you know of to the list.  As I receive responses, I \n>> will add them to my home page.\n>\n>\n> How about <http://www.alistapart.com/>? Their articles include \"How To \n> Read W3C Specs\" and \"Modifying Dreamweaver To Produce Valid XHTML\".\n>\n> /Jonas\n>\n>\nI added it to my list.\n\n-- \nBrant Langer Gurganus\nDon't complain about problems, solve them.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Re: Evangelism Site Lis",
            "content": "Lachlan Cannon wrote:\n\n>Brant Langer Gurganus said:\n>  \n>\n>>I'd like to come up with a good set of references.  I'd like to start by\n>> listing sites that have articles about writing standards-compliant HTML\n>> or how to fix problems with proprietary HTML:\n>>\n>>   * http://www.w3.org\n>>   * http://mozilla.evangelism.bclary.com\n>>   * http://www.webstandards.org\n>>   * http://developer.netscape.com/evangelism\n>>\n>>Please add sites you know of to the list.  As I receive responses, I\n>>will add them to my home page.\n>>    \n>>\n>\n>evolt.org has articles on these things, among others.\n>\n>Lach\n>_____________________________________\n>http://members.evolt.org/luminosity/\n>MSN: luminosity @ members.evolt.org\n>_____________________________________\n>\n>\n>\n>  \n>\nI added the site to my list.\n\n-- \nBrant Langer Gurganus\nDon't complain about problems, solve them.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Broken browsers",
            "content": "Hi there! First off a quick hello - can't really be bothered to write a full\n\"Why I'm here\" message, but it is really the same as everyone else. I thought I\nmight try and get a discussing going with an interesting issue...\n\n\nClearly it is in the W3C's interest to educate other people about web standards.\nThis has to include practical examples of where they are helpful, and how they\ncan be used best.\n\nBut what happens when popular browsers don't render W3C pages correctly? For\ninstance the W3C Style site - <http://www.w3.org/Style/>. In IE6 for Windows,\nthe links near the top (\"What are style sheets?\" in black, \"Press Clippings\" in\ngreen, etc) are extremely buggy.\n\nIf you roll the cursor over them, the sides of the page vanish into thin air,\nand some of the links are unclickable. This is a result of IE6's very buggy\nstandards-compatible mode, and this behavior was not present in IE5.5.\n\nThere is actually a very easy (although slightly hackish) work-around for this,\nwhich is to very simply to force IE6 into backwards-compatible mode by inserting\nany non-whitespace chars before the doctype (such as an XML prolog, or an empty\ncomment like <!---->).\n\nBut the question is this: should the W3C give in to browser bugs, and employ\nhacks like that?\n\nPersonally, I can come up with reasons for both sides of the argument. Adding\nhacks to work-around browser problems is a bit like waving the white flag and\ngiving in to buggy browsers.\n\nIt is sort-of going back to table layouts and spacer GIFs for much more broken\nbrowsers like NS4 - or is it? Adding a comment before a doctype doesn't\ninvalidate the page. It doesn't have any side-effects that I know of.\n\nBut on the other hand, if someone who is just investigating web standards visits\nthe W3C Style site and finds it doesn't work on his or her brand-new browser,\nthey might well be inclined to think \"well if this is what using web standards\ndoes, I can't be bothered with all this!\" - not good for evangelism in general.\n\nSo, what should the W3C do..?\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "Re: I'm here because I'm lazy  a personal intro",
            "content": "I'm only here for the beer.\n\nI'm Drew, and I work with the WaSP as part of their Dreamweaver Task \nForce. During the recent development of Dreamweaver MX, Rachel Andrew, \nmyself and others from the WaSP worked alongside Macromedia to place \ngentle pressure and make good arguments for standards support. \nMacromedia listened and put loads of hard work in, and as a result \nDreamweaver MX is a fine product with much improved standards support. \nRachel is on this list too - I'm sure she'll introduce herself.\n\nMy first book, Dreamweaver MX Web Development (New Riders) is due out \nnext month. The book teaches standards-based web development with \nDreamweaver as your tool. As you may have gathered, the Dreamweaver \ncommunity is rife with designers and developers who often don't know how \nto operate their tools well, let alone markup a page against a valid \nDTD. There is a vast need for education, as well as the need for a \nstrong counter-attack to the misinformation that is handed out by many \nof the community 'experts'.\n\nSo that's about where I fit in. I'm a guy who believes in web standards, \nwho knows Dreamweaver inside and out but never uses it, and who's keen \nto learn from those around me.\n\nIt's great to be here, and I look forward to some good conversation.\n\n-- \ndrew mclellan\n\nWaSP dreamweaver task force\nhttp://www.webstandards.org/\n\nteam macromedia volunteer\nhttp://www.macromedia.com/go/team\n\n\n\n"
        },
        {
            "subject": "Re: I'm here because I'm lazy  a personal intro",
            "content": ">Rachel Andrew, myself and others from the WaSP worked alongside Macromedia \n>to place gentle pressure and make good arguments for standards support. \n>Macromedia listened and put loads of hard work in, and as a result \n>Dreamweaver MX is a fine product with much improved standards support. \n>Rachel is on this list too - I'm sure she'll introduce herself.\n\nI guess I better had then, now I've been outed as a lurker! ;)\n\nAs Drew has already mentioned, I'm another WaSP DW Task Force member. I'm \ndoing an increasing amount of writing on the subject of web standards - I \nam a co-author of 'Dynamic Dreamweaver MX' for Glasshaus - writing about \nbest practices in development with CSS and XHTML/HTML within Dreamweaver \nMX, and have a few articles dotted around the web.\n\nLooking forward to some interesting discussion here =)\n\n\nRachel Andrew\n\nwork: http://www.edgeofmyseat.com\nplay: http://www.rachelandrew.co.uk\nWaSP Dreamweaver Task Force http://www.webstandards.org\n\n\n\n"
        },
        {
            "subject": "Re: I'm here because I'm lazy  a personal intro",
            "content": "Hi Alll.. I'll attach my introduction and I'll probably be lurking from here\non out.\n\nI'm on the Women Designers list with Rachel and just happened to click on\nthe WaSP link in her sig today. I've\nbeen spending a lot of time at W3.org to help with CSS assignments for\nschool. My first attempt at validating a\npage I coded from scratch was really scary!\n\nI'm a baby as far as all of this standard/xml/css/php and all the other\nacronyms. I've learned what I know.. by doing.\nI've been a volunteer for the herplanet.com network for two years now and\ndove right in and taught myself a lot of the html/coding\nand scripting along with teaching my young ones a few curse words along the\nway (sorry kids).\nI won't be asking newbie questions or flooding the list with \"how do you do\nthis? or how do you do that?\"\nI'm just here to absorb as much as I can.\n\nIn school full time for Digital Media: Web Production emphasis and currently\ntaking a beginning Web Design course which includes xml/css/javascript.. and\nthe next class in the series teaches php. I started with front page.. we\nstill use that program..and learned html just because I had to troubleshoot\nthe fat code that netscape despises. I'm trying to pull away from depending\non WYSIWYG programs.. but it's hard not to fall back on it.\n\nI'm just here to learn as much as I can. Out network is a bit behind the\ntimes and I'm hoping to influence them towards web standards and getting\naway from frames and includes.. a standby in our network.\n\nI am also a single WAHM to six kids ages 5 yo to 17 yo.\n\nDonna M. Snow, CEO\nSnow Write Productions\nhttp://www.snowwrite.com/\ncharming company,princely productions\n--> HR Director http://www.herplanet.com\nEditor http://www.hersmallbusiness.com/\n\n\n\n"
        },
        {
            "subject": "Re: I'm here because I'm lazy  a personal intro",
            "content": "Once upon a time, I could code a \"cutting edge\" page that rendered properly\nin every available browser.  Mosaic, Netscape, Lynx, that flaky little\nMicrosoft IE that no one used -- I could run the gamut.  This was around\nthe time of HTML 3.2, and I could make great sites because I really knew\nthe code I was writing.\n\nMuch of the browser wars were lost to me, busy as I was \"growing the\nbusiness\".  I'm in a small internet speciality shop in British Columbia\nCanada, where we provide all sorts of Internet-related services, training,\nand design, and are generally well-respected in the community.\n\nHowever, one day I woke up and realised that IE was largely dominant,\nNetscape was floundering, the old alternative browsers were all dead\n(replaced by a new guard), and the standards which I based my sites on were\nalmost universally depreciated.  Thankfully, I hadn't used much NS4\nproprietary stuff (who knew?), but I found myself with a lot of obsolete\ncode, and no clear upgrade path.\n\nIt's one thing to make my sites match published standards (that I can do\nwithout difficulty), but another to actually _know_ the full potential of\nthese new languages, styles, and specs.  It seems to me that the vast\nmajority of websites out there have yet to achieve the full potential of\nHTML 4.0, let alone what came next.  I don't want to be like that.  As a\ndeveloper, I face the same challenges that dog standards compliance\nworldwide: finite resources, no time for extended training, a legacy of\nolder code, and impatient clients who will only ever use the browser that\ncomes with their OS.\n\nI'm subscribed to this list because I'm looking for clarity.  I don't need\nto be sold on the idea of standards compliance; I'm already a believer.\nLike most webmasters, I want to build sites that are modern, interesting,\nintuitive, and compliant not just with standards, but with browsers in\ngeneral.\n\nThere are a lot of paths to this goal, and opinions are, um, liberally\nmixed.  I fear that I could learn this the wrong way, and leave with some\nbad habits.  How does one shift a \"classical\" knowledge of HTML to today's\nnifty specs, while maintaining compatibility, wow-factor, and standards?\nCarefully, I'd imagine.  Thus, a discussion between like-minded people\nunder the auspices of the W3C should help me separate the good from the\nbad.  I won't be asking a million random questions -- just taking a lot of\nnotes.  This is my first day here, and I've already learned a surprising\namount (keep those URLs coming!).\n\nIn closing, my hope is that this list can help me with my grey-matter\nupgrade, and make Joseph McLean pass all relevant compliance checks.\n\n-J\n\n+=-\n|Joseph Louis McLean\n|Webmaster <> www.joseph.ca                \"Sanity is not statistical\"\n|Wandering Macintosh Expert                    -George Orwell, 1984\n\n\n\n"
        },
        {
            "subject": "Integratio",
            "content": "Hi :)\n\nPart 1 - Introduction - A practical example:\n\nMany of the web designers I train want to make \"Flash\" sites.  The\nreality is that there are many sites out there who insist on providing\nthis type of content.  I have been strongly encouraging these web\ndesigners to evaluate standard and accessible technologies such as SVG\nand SMIL.  I have been promoting the idea that there is not a lot of\nthings you can do with proprietary technology like Flash or Internet\nExplorer extensions that can't be done just as well through W3C\nrecommendations.  But in my experience demonstrating this, there is one\narea that has traditionally fallen short, and still does.  Sound.\n\nHave you ever tried to include a looped sound clip on a standards\ncompliant web page?  It boils down to this, you can have the page\nvalidate, OR you can have it work.\n\nIn theory I totally agree with the W3C party line that HTML is not a\nmultimedia oriented language, and sound is outside it's scope.  There\nhas also been much debate, which I don't want to get into here (sound is\njust an example of a larger problem), regarding the attitude that\n'proper' web pages should not even play sounds automatically, as it is\nintrusive.  The fact is that there are many cases in the Real World\nwhere sound is very appropriate, whether it be auditory feedback for an\nintranet application, or a page on MTV.com.  I agree that SMIL is the\nappropriate technology for this task.  There are several SMIL players\nout there, one of the more prominently deployed currently being RealONE.\n\nPart 2 - The Actual Problem - Integration\n\nIt's not just sound though.  The problem above is one of many.  The crux\nof most problems I now encounter in doing web design is integration. \nThe W3C has all of these working groups, each with a clearly defined\nscope.  These groups all do a fine job creating technology within their\nscope.  The problem is that none of these technologies exist in a\nvacuum.  There are many practical problems every related working group\nwill tell you are outside their scope (and it's true).\n\nGoing back to my practical example above, have you ever tried to include\nSMIL content in a web page?  If you want it to validate or work, you\nhave to tie that page (CLSID) to a particular implementation (on a\nparticular platform).\n\nIf I write the general cross implementation/platform:\n\n<object type=\"application/smil\" data=\"loopedsound.smil\" />\n\nHow many browsers on computers with current SMIL players will display\nthat properly?  (answer: not many, if any)\n\nNot all of these gaps are even new SVG, SMIL, or CSS3 type issues. \nWorking groups have, within the last year or two, at least started to\nincrease their scope to include things like MIME types as part of the\nspecification, along with Namespaces and such.  But for example, you\nstill have an HTML specification from the W3C which uses a whole chapter\nto define a 'script' element, and you have ECMA with their ECMA-262\nScript (aka Javascript) which has a working group to define a popular\ncontent for said script element, yet they don't define a mime type for\nsaid script.  Yes, that is correct, there is, as far as I know, no\ndocument or standard which defines a mime type for Javascript.  The\ndefacto mime type in use today (text/javascript), which works\neverywhere, is, from a purist perspective, arguably incorrect - it\nshould probably be application/javascript - which, incidentally, doesn't\nreally work anywhere.  There is java script on a LOT of web pages out\nthere, yet no standard formally defines this application.  These gaps\nare what I am talking about.\n\n[Incidentally, some time ago I asked Waldemar Horwat from Netscape, who\nis on the TC39 group which defines ECMA script, about the above issue. \nHe said he would ask at next meeting if they wanted to do something\nabout it, but I never heard back from him]\n\nThere are many problems like this.\n\nThreading!  What if I have a script on some web page manipulating the\nDOM of that page... yet have an event handler in an SVG applet try to do\nthe same?  Multiple threads in a Java applet calling into the web page\nDOM?  \"Threading is outside the scope of this specification\".\n\nPart 3 - Denouement\n\nIt's the gaps between the specifications.  The \"devil is in the details\"\ncomplexities of the interactions between the specifications.  It's the\nproblems nobody thinks belong to them.  These are problems where\nimplementors are just forced to choose something they think is logical,\nand that is how we end up with five varying implementations.\n\nThere /should/ be an integration working group!\n\nI'm sure every web designer out there, and on this list, could name at\nleast a few areas where they have run into undefined behavior such as\nthis.\n\nAt the very least, we need some evangelism effort to get problems like\nthis solved.  Somewhere people can bring questions like this and find\nanswers, or help getting someone to take action.  That is why I am here.\n\nCan this group help get things like\n<object type=\"application/smil\" data=\"loopedsound.smil\" />\nto work?\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "Re: Broken browsers",
            "content": "At 3:11 PM +0100 7/8/02, Tom Gilder wrote:\n>...the W3C Style site - <http://www.w3.org/Style/>. In IE6 for Windows,\n>the links near the top (\"What are style sheets?\" in black, \"Press\n>Clippings\" in\n>green, etc) are extremely buggy.\n>\n>There is actually a very easy (although slightly hackish) work-around for\n>this,\n>which is to very simply to force IE6 into backwards-compatible mode by\n>inserting\n>any non-whitespace chars before the doctype\n\nNon-standard workarounds are always a little spooky to me....\n\n>But the question is this: should the W3C give in to browser bugs, and employ\n>hacks like that?\n\nAbsolutely not, I hope.  Standards are what defines these bugs as \"bugs\" in\nthe first place -- compliance standards are powerful because they don't\ncompromise.  Once a standard begins to patch itself to accommodate the\nbehavioral quirks of the browser industry, we slip right under the table\nagain, into the days of \"hack it until it works\".\n\nAnd if the W3C doesn't hold Microsoft to spec -- who will?\n\n>But on the other hand, if someone who is just investigating web standards\n>visits\n>the W3C Style site and finds it doesn't work on his or her brand-new browser,\n>they might well be inclined to think \"well if this is what using web standards\n>does, I can't be bothered with all this!\" - not good for evangelism in\n>general.\n\nIt's better to declare the emperors's lack of clothes than pretend\notherwise, I feel.  You might lose face in front of a few ill-informed\npeople, but others will realise that the opposite is true -- the _browser_,\nnot the W3C, is wrong.\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Designers/web developer needs (was: I'm here because I'm lazy  a personal intro.",
            "content": "There seems to be a fair number of designers and web developers on this\nforum, and that's a very good thing, since it should allow the\nevangelists ones to get some feedback and ideas on their work.\n\nSpecifically, I think it would be interesting to know what designers and\nweb developers would see as useful resources: \n- to help them with build standard compliant web sites\n- to help them with convincing their managers you should do that\n- to clarify classical errors/misunderstandings they have been through\ndue to bad education outside for instance\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n"
        },
        {
            "subject": "Re: Integratio",
            "content": "Le mar 09/07/2002 ? 01:10, Chris Hubick a ?crit :\n> Part 1 - Introduction - A practical example:\n> \n> Have you ever tried to include a looped sound clip on a standards\n> compliant web page?  It boils down to this, you can have the page\n> validate, OR you can have it work.\n\nHaving such a sound would really be in the scope of CSS and not HTML. I\nthink it has been suggested to the CSS WG several times and they might\nget to the point of producing a specification for this (note that with\nCSS, you gain in much flexibility on when and how to play a sound, and\nyou make it easier for the end user to disable this \"feature\" :)\n \n> Part 2 - The Actual Problem - Integration\n> If I write the general cross implementation/platform:\n> \n> <object type=\"application/smil\" data=\"loopedsound.smil\" />\n> \n> How many browsers on computers with current SMIL players will display\n> that properly?  (answer: not many, if any)\n\nProbably not many, indeed. But I don't think that's on the specification\nside that the problem is, is it? Note that since you're using XHTML in\nyour example, there has been an XHTML+SMIL profile [1] developed to\nallow to include your SMIL markup in the XHTML document itself:\n\n \n> But for example, you\n> still have an HTML specification from the W3C which uses a whole chapter\n> to define a 'script' element, and you have ECMA with their ECMA-262\n> Script (aka Javascript) which has a working group to define a popular\n> content for said script element, yet they don't define a mime type for\n> said script.\n\nWell, it's obviously not the role of W3C to register a MIME Type for an\noutside specification. I think that the lack of MIME Type for javascript\nhas been raised several times, but indeed, I don't know if there has\nbeen much real action for this.\n\nNote that the Technical Architecture Group provides now some guidance so\nthat W3C registers MIME Types along the design of its specifications.\n[2]\n\n> There are many problems like this.\n> \n> Threading!  What if I have a script on some web page manipulating the\n> DOM of that page... yet have an event handler in an SVG applet try to do\n> the same?  Multiple threads in a Java applet calling into the web page\n> DOM?  \"Threading is outside the scope of this specification\".\n\nWhen designing standards [3], you *have* to limit the scope of your work\nif you want to reach a stable state at some point. I think that the\ncurrent standards are already much underused, so creeping them with more\ndetails and side cases features wouldn't really help... That's only my\nopinion, of course :)\n \n> Part 3 - Denouement\n> \n> It's the gaps between the specifications.  The \"devil is in the details\"\n> complexities of the interactions between the specifications.  It's the\n> problems nobody thinks belong to them.  These are problems where\n> implementors are just forced to choose something they think is logical,\n> and that is how we end up with five varying implementations.\n> \n> There /should/ be an integration working group!\n\nNote that W3C has many so called coordination groups whose role is to\nensure that related working groups work together in the same direction,\nwith interoperability in mind, etc. Besides, the way a specification\ngoes through its life per the W3C Process means that its gets a lot of\nreview from a wide range of working groups (especially when it reaches\nits 'last call' stage).\n\nNote that at a different level, the Technical Architecture Group (TAG),\nthe Web Accessibility Initiative, the Internationalization activity and\nthe Quality Assurance Activity [4] ensure transversal reviews of the\nspecifications.\n \n> I'm sure every web designer out there, and on this list, could name at\n> least a few areas where they have run into undefined behavior such as\n> this.\n\nIndeed... But I'm not sure that's what really stopping the standards.\nMost proprietary technologies have much more integrations issues,\nundefined behavior, etc. than the open standard ones.\n \n> At the very least, we need some evangelism effort to get problems like\n> this solved.  Somewhere people can bring questions like this and find\n> answers, or help getting someone to take action.  That is why I am here.\n> \n> Can this group help get things like\n> <object type=\"application/smil\" data=\"loopedsound.smil\" />\n> to work?\n\nHmm... Honestly, I think the goals of this forum is more oriented toward\neducation of content producers than to discuss technical decisions made\nduring the design of the standards. But maybe I misunderstood?\n\nDom\n\n1. http://www.w3.org/TR/XHTMLplusSMIL/\n2. http://www.w3.org/2001/tag/ilist#w3cMediaType-1\n3. http://www.w3.org/People/Bos/DesignGuide/\n4. http://www.w3.org/2001/tag/\n   http://www.w3.org/WAI/\n   http://www.w3.org/International/\n   http://www.w3.org/QA/\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n"
        },
        {
            "subject": "Re: Publicevangelist, goals and expectation",
            "content": "Let me thank you (again) for joining this mailing-list. I am extremely\npleased to see a lot of people sharing the same goal of making a better\nweb through education.\n\nMy intro: I'm Olivier Thereaux, part of the W3C staff, and I am working\non Systems (e.g. the mail search for W3C mailing-lists, which you may\nhave used already) as well as QA. I'll be one of the maintainers of this\nlist, along with Dominique.\n\nI joined the QA activity soon after its birth, with a strong\ndesire to develop its Education and Outreach work (via the Interest\nGroup), so it's an understatement to say that I'm thrilled to see this\nforum exist (at last), and that I have great expectations for it.\n\nIn some sense, the future of the web will depend on authors,\nweb evangelists and teachers such as yourselves, as much as it will\ndepend on new technologies being created or polished at the W3C.\nIt will, of course, also depend on the quality of web authoring\ntools, web automating tools, browsers and emerging technologies\nbeing created around the globe.\n\n\nFirstly, let me point out that we have some ongoing Education work going \non at the W3C:\n- WAI-EO[0] comes to mind, of course\n- Tutorials[1] are another example\n- our validators (HTML[2], CSS[3], RDF[4])\n- Tools (e.g the soon to be released LogValidator[5])\n- and more coming in (QA has a few notes in its pipe).\n\nThis means the situation is not \"W3C versus the Web Standards Education\nworld\", nor is it \"W3C trying to control these people\", but W3C working\nalong with them.\n\nSecondly, the birth of this forum is intended to help web evangelists\nin their work by (and I'm borrowing Molly's words here) \"filling the\ngap between the web education world and W3C\", and by sharing their\nexperience and expertise.\n\n\nLooking forward to discussing with you all.\n\n\nKind Regards,\nOlivier\n\n[0] http://www.w3.org/WAI/EO/\n[1] http://www.w3.org/2002/03/tutorials\n[2] http://validator.w3.org/\n[3] http://jigsaw.w3.org/css-validator/\n[4] http://www.w3.org/RDF/Validator/\n[5] http://www.w3.org/QA/Tools/LogValidator/\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "intro",
            "content": "hi!\n\ni'm daniel, a web developer based out of sydney, australia, with \na permanent hardon for industrial strength web standards.\n\nhopefully the members of this list can help make a difference. \ni'm keen to get involved in whatever way i can. keen to see \naction taking place.\n\nd.\n\n--\n\ndaniel bogan.\n\nwaferbaby: we eat bandwidth for breakfast.\n<http://www.waferbaby.com/>\n\n\n\n"
        },
        {
            "subject": "intr",
            "content": "Hi,\n\nI'm Dave, a web developer for TALL [1] at Oxford Uni, where we are still\nworking towards fully valid and accessible content. I'm currently developing\nan XML Schema for online learning materials.\n\nI'm looking forward to the web's progression from proprietary mish-mash into\nthe accessible, compatible, standards based information tool that it wants\nto be.\n\nCheers,\nDave.\n\n[1] If you're interested, it's the Technology Assisted Lifelong Learning\ndivision of Oxford University's Department of Continuing Education.\nwww.tall.ox.ac.uk\n\n-- \nTALL, OUDCE and the University of Oxford accept no legal responsibility for\nthe contents of this message. Any views or opinions presented are only those\nof the author and not those of TALL, or OUDCE, or the University of Oxford.\nIf this email has come to you in error please delete it and any attachments.\n\n\n\n"
        },
        {
            "subject": "intr",
            "content": "Hello everyone :)\n\nI'm Steph, a web developer/designer currently (though perhaps not permanently) \nbased in Melbourne, Australia. \n\nMy chief interests with regards to advocating Web standards lie in effective, \nconvincing and persuasive education based on sound arguments; telling someone \nwhat may be the 'right way' isn't necessarily going to achieve much, but \nshowing them concrete evidence why they should is an essential step\nforward.\n\nI am also awfully concerned at the number of Web design courses out there \nwhich are not necessarily teaching the right thing to upcoming generation\nof developers and designers.\n\nThere is a lot of talent to be tapped on this forum - so perhaps we can\ndiscuss points of attacks and come up with some good ideas: \n\n* outreach in the current Web designer/development community\n  Books and articles published on known Web sites are valuable resources.\n  Is this enough? Are audiences within this group addressed\n  appropriately?  Where does a new Web designer pick up their\n  skills from, how could they be influenced?\n\n* outreach in colleges, schools, University curriculum\n  Education in Web standards in this particular area is very poor.\n  Some University degrees are catching onto accessibility and\n  usability and mention of Web standards, but on the whole, \n  it is not adequately taught due to various factors. A university\n  lecturer said to me recently, \"I would love to teach them xhtml, but it is \n  beyond the scope of my course to try and even explain XML when some students\n  barely know how to work Windows.\" What can we do about this?\n\n* convincing Management\nConcrete evidence of the benefits of deploying Web standards,\n  (tangible) cost-benefit analysis. We don't seem to have this\n  information, how can we get it? What else?\n\nLet's get the ball rolling!\n   \ncheers,\n-steph\nrandom web dudette\nhttp://unadorned.org/\n\n\n\n"
        },
        {
            "subject": "intr",
            "content": "Hi,\n\nI'm formerly the W3C Conformance Manager and the QA Working Group [1] \nco-chair. Right now, I'm busy with the WG activities and review of \ninternal specs, but I will continue to participate as often as \npossible to this list, and when the QA Framework [2] will be \nfinished, I will join the Education effort.\n\nI want to thanks Jeffrey Zeldman (WASP [3]) and Molly Holzschlag \n(writer of an old WebTechniques column [4]) for their support and \nencouragement for a long time. Many of you on this list are long \nsupporters of Web Standards and often individually, modestly have \nmoved the things : Thanks !!!\n\nSince the begining of the QA Activity (1 year ago), I wished that the \nW3C has more liaisons with the Web Community. Why ? Because I come \nfrom this community and was, in part, hired by W3C for this reason.\n\nThere's certainly a gap between the specifications done for the \nSoftware implementers (perfect or not) and the tutorials / books / \nmaterials available around.\n\nHow to fill the gap ? Because it's not a question of building a \nbridge between two separate worlds, but to help people to better \nunderstand each other in a common world : The Web as large.\n\nWe need tools, we need documentation, we need tutorials, we need to \nhave contact with teachers who teach web development in Computing \nschools as well in Art Schools.\n\nWe need real practices of the real world to build better materials. \nSo how to fix bad habits of web designer, developers and at the same \ntime how to create good materials, how to explain techniques or just \nthings which seem to be obscure wrt W3C technologies.\n\nWe can do it all together.\n\n[1] http://www.w3.org/QA/WG/\n[2] http://www.w3.org/QA/WG/#docs\n[3] http://www.webstandards.org/\n[4] http://www.molly.com/articlemap.php\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: intr",
            "content": "At 10:28 -0400 2002-07-09, Karl Dubost wrote:\n>I'm formerly the W3C Conformance Manager and the QA Working Group [1]\n\nBefore people reacts, I'm still, but the title is not really \nmeaningful it's why I used formerly :)\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: intr",
            "content": "so where's the best place to start?\n\nwill there be a central repository to store all these tools, \ndocuments and tutorials?\n\nd.\n\nOn Wednesday, July 10, 2002, at 12:28  AM, Karl Dubost wrote:\n\n> We need tools, we need documentation, we need tutorials, we \n> need to have contact with teachers who teach web development in \n> Computing schools as well in Art Schools.\n\n--\n\ndaniel bogan.\n\nwaferbaby: we eat bandwidth for breakfast.\n<http://www.waferbaby.com/>\n\n\n\n"
        },
        {
            "subject": "Introductio",
            "content": "Hello to all,\n\nI'm Mark Fletcher of the Virtual Training Company. I produce training cds and online tutorials on\nMacromedia's Dreamweaver / Dreamweaver MX. I am also a member of Team Macromedia for Dreamweaver and\nhave recently written a number of articles that have been featured at macromedia.com. I'm here\nbecause I understand the importance of implementing web standards and want to ensure that I can\npromote these correctly in any future projects I embark upon.\n\nRegards\nMark\n\n\n------------------------------------------------------------------------------------\nMark Fletcher\nWeb Educator | Master VTC Author\nTeam Macromedia Volunteer for Dreamweaver MX\nwww.macromedia.com/support/forums/team_macromedia\n------------------------------------------------------------------------------------\nGet started with Dreamweaver MX and ColdFusion MX today!\nhttp://www.macromedia.com/software/coldfusion/resources/get_started/tutorials/\n------------------------------------------------------------------------------------\nAnnouncing Macromedia MX\nhttp://www.macromedia.com/software/trial/\n------------------------------------------------------------------------------------\n\n\n\n"
        },
        {
            "subject": "intr",
            "content": "Hi all,\n\nMy name is Eddie and am currently residing in Ottawa Canada, having quiet\nrecently from Melbourne Australia. I share the common interest of seeing Web\nstandards become the norm. I am involved in a couple of book projects, and\netch out a living by building sites for clients.\n\nI hope to be able to contribute positively both to this group and to the web\ncommunity at large.\n\nEddie Traversa\nhttp://dhtmlnirvana.com/\n\n\n\n"
        },
        {
            "subject": "yet another intro",
            "content": "Hello all,\n\nMy name is Jeff.  I'm a web developer working and living in the Salt Lake\nCity, Utah,  U.S. area.\n\nI work for an e-learning company doing dhtml stuff for the online courses we\nproduce. Recently I've been working on upgrading our stuff to dxhtml. I\nstill have a bit to go.\n\n\nI am very excited about this forum and what we can accomplish. Thanks w3c\nfor starting this. \n\nJeff Moyes\nMultimedia Programmer\nAllen Communication Learning Services, \na division of Mentergy U.S.A.\nph: 801.799.7231\nfax: 801.537.7805\njeffm@mentergy.com\n\n\n\n"
        },
        {
            "subject": "Re: Designers/web developer need",
            "content": "> - to help them with convincing their managers you should do that\n> - to clarify classical errors/misunderstandings they have been through\n> due to bad education outside for instance\n\nAs you all are surely aware, many people are still trying to practice\n\"traditional medium\" style design on the web.  That is, many designers\nare trying to have precise control over what web users end experience\nwill be like, and haven't really accepted that they can't have this\ncontrol.  They haven't understood that the web was not designed to solve\nthat problem, and that it is not really trying to.  Yet many designers\nstill try to battle this fact every day in their work, or they just give\nup and label the site as \"IE only, min 800x600\".  These are the concepts\nand design goals I try to convey to people when I introduce them to web\ndesign.  I find it helpful to point people at something like\nhttp://www.browserlist.browser.org/ to show just how many different\nbrowsers are out there.  I try to explain how they can't be sure what\nfonts will be available, even on major platforms like the Mac versus\nPC.  I try to explain about the millions of people who will use set top\nboxes and low resolution televisions to view their site, or devices like\nPalm Pilots.\n\nI think one idea for something that might help bring this home would be\nto create an example page designed for IE on the PC desktop.  But then\nhave a list of browsers on different platforms like that linked above,\nwith a screenshot (or audio file!) of the site being displayed on each. \nThen you could label each browser with the number of people who use it,\nor at least, why people would need to use that browser.  Next to a shot\nof the site being mostly illegible, \"This is the most popular set top\nbox in India/China, and in 2005 will be the primary means of internet\naccess for two billion people\" kinda thing.  \"This is a shot from the\nbrowser Ford is placing in the dashboard of 10 million cars over the\nnext five years\".  You could also show the same example page rewritten\nto be more accessible, etc, and how it can still look good on the IE\ndektop, but have shots of the drastically better results on other\nplatforms.\n\nI mean...the problem is the kinda thing we all talk about in theoretical\nterms...but I don't know of anywhere you can really /show/ people the\nresults.\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "Slashdot: &quot;Designers Ignoring Standards&quot",
            "content": "Slashdot is having a lively discussion today on \"Web Designers Ignoring\nStandards & Supporting IE Only\".  I'm sure most of our crowd swings past /.\non a regular basis, but there were a few comments that I wanted to draw\nattention to.\n\nWebMasterJoe (not a relation) had an excellent, detailed rebuttal [1] to\nthe whole IE-centric philosophy of certain lazy designers.  Meanwhile,\nChelloveck advanced the opinion that \"There's no such thing as a WYSIWYG\nweb page builder\" [2] because HTML is meant to be interpreted differently\nby each browser, not painted in exact pixels upon the screen.\n\nSo... what do you think?  Is WYSIWYG HTML an oxymoron, and/or a pipe dream?\nSome of the latest standards seem to be resulting in a largely unified\nrender across browsers, but the effect could be an illusion.\n\nIt seems to me that a great deal of website designers were previously\ninvolved in \"dead tree\" design jobs, where the content stayed firmly in\nplace once it was sent to the printer.  Even those who weren't so employed\noften think the same way.  Will standards ever address their expectations,\nor do they need to change the way they think?\n\n[1] Rebuttal: http://slashdot.org/comments.pl?sid=35578&cid=3842759\n[2] WYSIWYG:  http://slashdot.org/comments.pl?sid=35578&cid=3842310\n\nThe whole article is at http://slashdot.org/article.pl?sid=02/07/08/1313246\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "costbenefit analysis of standards complianc",
            "content": "All,\n\nSteph, in her intro email, mentions:\n\n- convincing Management\n        Concrete evidence of the benefits of deploying Web standards,\n  (tangible) cost-benefit analysis. We don't seem to have this\n  information, how can we get it? What else?\n\n\nThis would be incredible information if it can be found/compiled. At least\nin the corporate world, (tangible) cost-benefit analysis is almost always\nthe underlying determinate factor. If you can show a manager that it will\nsave time and/or money (thereby \"making\" money) they will go for it. If they\ndon't see this than it's questoinable.  I have had to do whatever upgrading\nto standards compliant code I've done as a \"black project\" - i.e. slipping\nit in during normal development, without taking any additional resources to\ndo so.\n\nI haven't seen much in the way of cost-benefit analysis out there. Here are\na couple of things:\n\n\nThis first one is from where else? the wasp (who knows, maybe whomever wrote\nit is on this list).\n\nhttp://www.webstandards.org/about/ - Under the heading \"Quandaries and\nCosts\" the following is included \"The fractured browser market added at\nleast 25% to the cost of developing all sites.\" \n\n\n\nThis one is used to make a dramatic impact - there's no way to say how much\nof the amount really went into \"upgrading\" to later browsers and how much\nwas \"corporate branding\" rework/look and feel/etc. \n\n\nhttp://www.spazowham.com/standards/ - \"The Wall Street Journal paid US$28\nmillion for the last revision to their WSJ Online website. Along with\nimprovements to infrastructure, this revision also covered improvements to\nthe site's HTML. Reportedly, some features of their old website had stopped\nfunctioning in the latest versions of the Netscape and Internet Explorer\nbrowsers. This is because the original designers of WSJ Online attempted,\nwith varying degrees of success, to preserve the look and feel of the\npublication's print version.\"\n\n\n\nThere is, of course, a lot of material relating to the benefits of\nAccessibility compliance. One of the rules in the Web Content Accessibility\nGuidelines is that the web page use w3c standards. Even though Section 508\nin the U.S. doesn't legally  require standards compliance, for accessibility\nto work you really need to be standards compliant. So some of the\ncost-benefit analysis of Accessibility could be applied to standards\ncompliance. If anybody knows of good statistics there, please point them\nout.\n\n While I haven't read through it all the way the w3c does have the\nfollowing:\n\nhttp://www.w3.org/WAI/bcase/benefits.html - Auxiliary Benefits of Accessible\nWeb Design\n\n\nJeff Moyes\nMultimedia Programmer\nAllen Communication Learning Services,\na division of Mentergy U.S.A.\nph: 801.799.7231\nfax: 801.537.7805\njeffm@mentergy.com\n\n\n\n"
        },
        {
            "subject": "repository  was re:intr",
            "content": "All,\n\nIf someone could set up a wiki that would be really cool. (Unfortunately I\ndon't know how to do it).\n\nFor those wondering what a wiki is, it's a collaborative space where anyone\ncan post info. Here's a link http://www.openwiki.com/\n\n  The svg community has been using one for awhile now and it's incredibly\nhelpful. Here's a link to there's http://www.protocol7.com/svg-wiki/\n\n<I should say 'ours' - I've been in the svg community and on the\nsvg-developers@yahoo list for almost 2 1/2 years now! ;) >\n\nJeff Moyes\nMultimedia Programmer\nAllen Communication Learning Services, \na division of Mentergy U.S.A.\nph: 801.799.7231\nfax: 801.537.7805\njeffm@mentergy.com\n\n\n\n"
        },
        {
            "subject": "costbenefit analysi",
            "content": "All,\n\nI'm sorry if this double posts. Our email went out about the time I was\nsending this so I'm not sure if it will go through. So I'm resending\n\n\n\nSteph, in her intro email, mentions:\n\n- convincing Management\n        Concrete evidence of the benefits of deploying Web standards,\n  (tangible) cost-benefit analysis. We don't seem to have this\n  information, how can we get it? What else?\n\n\nThis would be incredible information if it can be found/compiled. At least\nin the corporate world, (tangible) cost-benefit analysis is almost always\nthe underlying determinate factor. If you can show a manager that it will\nsave time and/or money (thereby \"making\" money) they will go for it. If they\ndon't see this than it's questoinable.  I have had to do whatever upgrading\nto standards compliant code I've done as a \"black project\" - i.e. slipping\nit in during normal development, without taking any additional resources to\ndo so.\n\nI haven't seen much in the way of cost-benefit analysis out there. Here are\na couple of things:\n\n\nThis first one is from where else? the wasp (who knows, maybe whomever wrote\nit is on this list).\n\nhttp://www.webstandards.org/about/ - Under the heading \"Quandaries and\nCosts\" the following is included \"The fractured browser market added at\nleast 25% to the cost of developing all sites.\" \n\n\n\nThis one is used to make a dramatic impact - there's no way to say how much\nof the amount really went into \"upgrading\" to later browsers and how much\nwas \"corporate branding\" rework/look and feel/etc. \n\n\nhttp://www.spazowham.com/standards/ - \"The Wall Street Journal paid US$28\nmillion for the last revision to their WSJ Online website. Along with\nimprovements to infrastructure, this revision also covered improvements to\nthe site's HTML. Reportedly, some features of their old website had stopped\nfunctioning in the latest versions of the Netscape and Internet Explorer\nbrowsers. This is because the original designers of WSJ Online attempted,\nwith varying degrees of success, to preserve the look and feel of the\npublication's print version.\"\n\n\n\nThere is, of course, a lot of material relating to the benefits of\nAccessibility compliance. One of the rules in the Web Content Accessibility\nGuidelines is that the web page use w3c standards. Even though Section 508\nin the U.S. doesn't legally  require standards compliance, for accessibility\nto work you really need to be standards compliant. So some of the\ncost-benefit analysis of Accessibility could be applied to standards\ncompliance. If anybody knows of good statistics there, please point them\nout.\n\n While I haven't read through it all the way the w3c does have the\nfollowing:\n\nhttp://www.w3.org/WAI/bcase/benefits.html - Auxiliary Benefits of Accessible\nWeb Design\n\nJeff Moyes\nMultimedia Programmer\nAllen Communication Learning Services, \na division of Mentergy U.S.A.\nph: 801.799.7231\nfax: 801.537.7805\njeffm@mentergy.com\n\n\n\n"
        },
        {
            "subject": "Re: Designers/web developer need",
            "content": "Chris Hubick wrote:\n\n> I mean...the problem is the kinda thing we all talk about in theoretical\n> terms...but I don't know of anywhere you can really /show/ people the\n> results.\n\nAn excellent point, Chris.\n\nIt was always much easier to say \"if you code like this, it will work in \nboth IE4 and NS4\". Developers could try it out and see results. What's \nmore everyone back then knew numerous other folk who had a different \nbrowser preference to themselves, so the benefits were obvious.\n\nWhen trying to evangelize web standards, the benefits are not always so \napparent. How many people personally know someone who browses the web \nwith a Braille reader? How many people even use their darn PDA for \nbrowsing the web? I know I only use my to check sites I've built.\n\nAs far as the forward compatibility benefits go, not that many every-day \ndevelopers have been around on the web as long as some of us, and maybe \nhaven't been put in the position of dealing with legacy pain-in-the-butt \nsystems - they simply can't imagine the immense value in forward \ncompatibility. Who can blame them? The rest of web culture tells them to \nlive for the moment. (you're only ever a quick FTP command away from \ncorrecting your mistakes, so why worry?).\n\nSo how the heck to we make the benefits of standards-based markup/code \nreal to the worker ants on the ground?\n\n-- \ndrew mclellan\n\nWaSP dreamweaver task force\nhttp://www.webstandards.org/\n\nteam macromedia volunteer\nhttp://www.macromedia.com/go/team\n\n\n\n"
        },
        {
            "subject": "Re: Designers/web developer needs (was: I'm here because I'm lazy   a personal intro.",
            "content": "Dominique Haza?l-Massieux wrote:\n\n>There seems to be a fair number of designers and web developers on this\n>forum, and that's a very good thing, since it should allow the\n>evangelists ones to get some feedback and ideas on their work.\n>\n>Specifically, I think it would be interesting to know what designers and\n>web developers would see as useful resources: \n>- to help them with build standard compliant web sites\n>\nA consistent implementation at the same level of the standards across \nthe various browsers.  Specifically, those browsers are Opera, \nMozilla/Netscape/K-Meleon/Galeon/Gecko-based, and Internet Explorer.\n\n>- to help them with convincing their managers you should do that\n>\nA clear list of advantages versus disadvantages of using the standards. \n Obviously, we want to lean toward the advantages side, but the list \nmust be balanced to be effective.  A list of only advantages will show \nthat we don't care about the other side of the balance beam \n(metaphorically).\n\n>- to clarify classical errors/misunderstandings they have been through\n>due to bad education outside for instance\n>\nI think we need to educate properly from the beginning.  We need to make \nfree up-to-date educational materials available to schools.  As a high \nschool student, I know that school will typically buy the cheaper text \nbook.  In the case of the World Wide Web's technologies, this is a bad \nidea.  The text books I have seen teach how to use FrontPage \n(proprietary) and other WYSIWIG environments.  Those that do teach HTML \ninclude the proprietary <marquee> and the deprecated style elements of \nHTML 3.2 and 4.0.  Likewise we need to make it well know that HTML marks \nup semantically as opposed to syntactically.  People think \"How do I \nmake this big, bold, and black?\" instead of \"How do I mark this as a \nheading (HTML) and once it is a heading, how do I tell that it should be \nbig, bold, and black (CSS)?\"\n\n>\n>Dom\n>  \n>\n\n\n-- \nBrant Langer Gurganus\nThere is no failure until you fail to keep trying.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Introductio",
            "content": "Hi everyone,\n\nThought I'd introduce myself for starters. I'm Shirley Kaiser. I'm on the \nWeb Standards Project (WaSP) Steering Committee[1] where I co-lead the \nLearn section with Molly Holzschlag, contribute to WaSP's BUZZ blog, and \npow-wow on ways to help implement and teach others about Web-related standards.\n\nI'm also involved in the online community quite a bit via discussion lists, \nweblogs, independent projects, and more, where I try to help others with \nstandards-related issues especially.\n\nI have my own busy web design business, SKDesigns[2], where I've been \ndesigning and developing standards-compliant sites since 1996. I've also \nwritten tutorials, contributed to web-related books, do tech editing and \nreviewing, and write a daily weblog[3] primarily about website design and \nthe Web.\n\nIn my other life I have a master's degree in piano performance, write \nmusic, give concerts[4], have two kids, and a dog to help keep me out of \nmischief.\n\nI'm especially thrilled about this new discussion list to share ideas, \nexperiences, and more in our efforts toward quality standards \nimplementation and learning. I'm here to learn what I can and contribute as \nI'm able to as well.\n\nWarmly,\nShirley\n\n[1] http://www.webstandards.org/\n[2] http://www.skdesigns.com/\n[3] http://www.brainstormsandraves.com/\n[4] http://www.shirleykaiser.com/\n\n-- \nShirley E. Kaiser, M.A.,  SKDesigns  mailto:skaiser1@skdesigns.com\nWebsite Design, Development      http://www.skdesigns.com/\nWebsiteTips: Design Resources  http://www.websitetips.com/\nBrainstorms and Raves  http://www.brainstormsandraves.com/\nWaSP Steering Committee       http://www.webstandards.org/\n\n\n\n"
        },
        {
            "subject": "Re: costbenefit analysis of standards complianc",
            "content": "On Tue, 2002-07-09 at 15:22, Jeff Moyes wrote:\n> This would be incredible information if it can be found/compiled. At least\n> in the corporate world, (tangible) cost-benefit analysis is almost always\n> the underlying determinate factor. If you can show a manager that it will\n> save time and/or money (thereby \"making\" money) they will go for it. If they\n> don't see this than it's questoinable.  I have had to do whatever upgrading\n> to standards compliant code I've done as a \"black project\" - i.e. slipping\n> it in during normal development, without taking any additional resources to\n> do so.\n\nThe problem is, you have to start by getting the developers on board who\nare actually building the pages.  Yes, web designers could really use a\ncost-benefit analysis in order to convince management, but if they don't\ncare, and aren't even trying to convince them, it won't matter.  I think\nright now, getting the designers on board is the larger task.  I think\nyou and your \"black project\" attitude are definitely the educated\nexception, but I don't think our current situation on the net is as a\nresult of management shooting down standards.\n\nPersonally, when I do consulting... I don't even treat it like it's an\noption.  It takes as long as it will take to create those pages, and\nthey will, at very least, validate - it's not optional.  It never even\ngets up to management.  A non-validating page to me is like programming\nsource code which won't compile - there is no decision to make.\n\nEveryone repeat after me...\n\nIf it doesn't validate, IT'S NOT HTML! :)\n \n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "RE: Designers/web developer need",
            "content": "a thought:\n\nwhat about the possibility of creating some kind of ranked index\nof tutorials, reference and source materials on web standards\ncreated by developers and designers?\n\nsomething in the vein of daypop's top 40 list [1], perhaps. given\nthe volume of material out there, it would be a site that points\nto the best sources, as determined by the developer community.\n\nfrom my own experience, i will often come across a site that best\nexplains a given standard, programming trick, etc. and will then\nbookmark it and refer to it again and again. i would suspect that\nothers do the same, and having these \"people's choice\" sources in\na single location might be worth while...\n\n\ncheers,\n\nanthony\n\n\nanthony baker  | aim: meadowlark07\nt: 415.441.6819  | f: 415.276.9388\nmailto:anthony@designforpeople.org\n\n\n\n\n  >-----Original Message-----\n  >From: public-evangelist-request@w3.org\n\n  >Specifically, I think it would be interesting to know what designers and\n  >web developers would see as useful resources:\n  >- to help them with build standard compliant web sites\n  >- to help them with convincing their managers you should do that\n  >- to clarify classical errors/misunderstandings they have been through\n  >due to bad education outside for instance\n  >\n  >Dom\n  >--\n  >Dominique Haza?l-Massieux - http://www.w3.org/People/Dom/\n  >W3C/INRIA\n  >mailto:dom@w3.org\n  >\n\n\n\n"
        },
        {
            "subject": "Re: costbenefit analysis of standards complianc",
            "content": "At 17:22 -0400 2002-07-09, Jeff Moyes wrote:\n>This would be incredible information if it can be found/compiled. At least\n>in the corporate world, (tangible) cost-benefit analysis is almost always\n\nYes it will be a very good information to have but for that we'll \nhave to define metrics. A set of measurable things that we can give \nto agencies.\n\nSo maybe the first thing is to establish this set of metrics.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Slashdot: &quot;Designers Ignoring Standards&quot",
            "content": "> It seems to me that a great deal of website designers were previously\n> involved in \"dead tree\" design jobs, where the content stayed firmly in\n> place once it was sent to the printer.  Even those who weren't so employed\n> often think the same way.  Will standards ever address their expectations,\n> or do they need to change the way they think?\n\nAside from the common perception that many Web designers come from\nprint backgrounds, in my experience within the corporate environment \nor pseudo-corporate world, there are generally other issues associated \nwith this.\n\nFirstly, the content tends to be owned, or must be approved by\nthe company's marketing department, so it's not very surprising\nthen that the Web is simply an alternative way to ship the same\ncontent (and the afterthought, because the Web is new). \n\nSecondly, the processes which govern the shipping of content\nare likely to be based on 'traditional' paper processes,\nthus you have lots of (poorly structured) Word documents flying \naround before the Web designer might actually hear about it.\n\nBut that's the way it is - our job is not to author the content \n- we present it.\n\nAnd to do a 'faster' job of presentation, one would expect\nyour Web designer to default to their favourite tool - \nFrontpage, Dreamweaver, etc. The information which arrives\nin their inbox or on their desk is unlikely to have been\n'structured' - so your standards-aware Web designer will\nhave to do extra work in order to format these documents\nso the final content is standards compliant.\n\nYour standards-unaware designer has it easier ... it's much\ntoo easy to whack the document in your less-than-compliant\nGUI editor and push-button-ftp publish.\n\nIn other words, in cases like these, unless information \nhandling processes are changed, standards will always\nbe the afterthought.\n\nThere is another phenonemon that I have noticed - in cases\nwhere the thought occurs to management 'we should have a\nwebsite!' but often there is not enough resources to employ\nanother person to do the job. So someone without any prior\nknowledge of publishing for the Web is lumped with the\njob and this individual would have been most likely \naccustomed to Word or Wordperfect - therein lies a seed\nfor the WYSIWYG, pixel-perfect (inaccurate) 'ideal'.\n\n\ncheers,\n-steph\nrandom web dudette\nhttp://unadorned.org/\n-- \n\n\n\n"
        },
        {
            "subject": "Re: costbenefit analysis of standards complianc",
            "content": "> At 17:22 -0400 2002-07-09, Jeff Moyes wrote:\n> >This would be incredible information if it can be found/compiled. At least\n> >in the corporate world, (tangible) cost-benefit analysis is almost always\n> \n> Yes it will be a very good information to have but for that we'll \n> have to define metrics. A set of measurable things that we can give \n> to agencies.\n> \n> So maybe the first thing is to establish this set of metrics.\n\nAhh, Karl beat me to saying this. ;) \n\nI have very few broad ideas of these metrics so far. It would be \ngood if we can grow this and publish it, and run a survey\nacross a sample of design companies, corporate departments,\nand so forth.\n\nI propose a set of metrics based on time - time can be translated \ninto man-hour costs.\n\nSo, very broadly, we may need to know for BOTH complaint/uncompliant\ndesign projects, how much time is taken in:\n\n- concept/design\n- development\n- deployment\n- maintenance\n- ??\n\nWe need to be able to decide which projects are 'similar-sized'\nseeing as it is not an accurate measurement if the basis for\ncomparison is not the same. How do we do this? By a projected\nanticpated amount of time taken based on man-hours? (Any better\nideas?)\n\nOnce these metrics are established, this survey could perhaps \nbe run once every year, or every two years. Then we would also \nhave a trend :)\n\nHow does all this sound?\n\ncheers,\n-steph\nrandom web dudette\nhttp://unadorned.org/\n \n\n\n\n"
        },
        {
            "subject": "Intr",
            "content": "Hi all,\n\nI'm Bryce and I'm a web designer/developer in the central Kentucky \nregion.  Quite frankly, I'm a little in awe of the company I'm keeping \non this list, and will probably endeavor to just stay out of the way and \nlearn what I can to help spread the Standards Gospel intelligently.  \n\nMost of my web development experience comes from working at \nGEAppliances.com, where I evolved (and hopefully still evolve) from \nbeing just another hack HTML writer to being a serious web developer who \nstrived to make the pages I created as  standards-compliant as I was \nallowed.  Starting next week, I will be moving into QA for that  \nwebsite,  and believe I will be in a unique postition to further \nevangelize the decision-makers as to the benefits of \nstandards-compliance.  But as with many corporations, it's the bottom \nline that's important for them, and one thing I hope to derive from my \nassociation with this list is a series of good, sound arguments as to \nwhy coding for standards will benefit GE Appliances (and any future \nclients I may serve later).\n\n------------------------\nBryce Fields\nwww.royalrodent.com\n\n\"Do or do not.  There is no try.\" -- Yoda\n\n\n\n"
        },
        {
            "subject": "Hi al",
            "content": "Citrus PunchHi there\n\nI'm Keran McKenzie, I run a resource site at www.studiowhiz.com and am on\nthe HUNT for good solid XHTML, CSS, and such like tutorials, if you have\nany, want to write any etc ... please feel free to join us.\n\nMe? I've been around the net for too long, I love web standards, and I love\nFlash ... and I think both work well.  I'm trying to make a big PUSH into\nthe NZ Web Industry to get more people using webstandards, but I find a\nlarge number of designers and clients .. just don't care.\n\nI'm in the middle of updating the course I teach from HTML to XHTML and web\nstandards so the next generation of designers are at least aware of these\nstandards.  I also run http://www.kiwi-interactive.com and am promoting the\ncompany as New Zealands' only (okay maybe not only but the FIRST) company to\nbuild web standard compliant sites :)\n\nAnyway I'm rambling ....\n\nK.\n\n\n\n-- \nhttp://www.mediadesign.school.nz/\n\nCAUTION: This communication is confidential and may be legally privileged.\nIf you have received it in error you must not use, disclose, copy or retain\nit. Please immediately notify us by return email and then delete the email.\n\nThis message has been scanned for viruses and dangerous content by\nMailScanner with McAfee UVScan, and is believed to be clean.\n\n\n\n"
        },
        {
            "subject": "Re: repository  was re:intr",
            "content": "> If someone could set up a wiki that would be really cool. (Unfortunately I\n> don't know how to do it).\n\nYeah ... I'd be happy to set one up and Host it .. alas I'm on Linux and not\nWindows\nHowever I'm more than happy to devote an entire Forum area to this at\nwww.studiowhiz.com if people felt that could be a good way of extending this\nknowledge to the general masses. (this site by the way is not fully\ncompliant yet .. we are working towards it though).\n\nI think your all on the right track. Education is important\n\nEducation of the current designers and education of the clients .... As I\nmentioned earlier I'm trying to break into the circles in NZ to talk on\nthese topics. I teach tomorrows designers, and am wanting to expand that.\n\nStudiowhiz currently is a web resource site, and this is exactly the sort of\nthing i've been wanting to expand it too. I don't see HTML, or Flash as\nstandalone solutions...I see them as part of a solution. I want the site to\nhave options and solutions for people.  A while back on\nhttp://pnut.studiowhiz.com (my blog) I said I was collection CSS and XHTML\ntutorials.  The thing I ran into ... and still do as I collect resources ...\nis often it's very personal opinion focused.\n\nPrime example, the whole c|Net vs Wasp browser debate, suddenly got VERY\npersonal and touchy, and I think that if we continue on that track the\naverage Joe Blog web designer is going to get very confused. I'm all for\nbuilding a HEAP of solid resources, BUT on the condition we ditch hearsy and\nopinions and base it on BLACK & WHITE.\n\nThere is a dire need for step by step tutorials, solid articles and more\nsupport of WASP's work. I have users asking me all the time, How do I set up\na basic CSS? How do I do layout without tables that will work in ALL\nbrowsers?  Am I'm attempting to write tutorials that have the answers. Now I\nKNOW a number of you have been there and done that ... I shouldn't need to\nre-invent the wheel. But finding these and making sense of them ... you\nshould see the stakes of printed websites on my desk :)\n\nEnough of my rant ... I think this is an Awesome mailing list .... and I\nlook forward to seeing it grow...\n\nK.\n\nKeran McKenzie\n\nPS: anyone know how to change the email this is sending too .. I subscribed\nunder the wrong email address\n\n\n\n\n\n-- \nhttp://www.mediadesign.school.nz/\n\nCAUTION: This communication is confidential and may be legally privileged.\nIf you have received it in error you must not use, disclose, copy or retain\nit. Please immediately notify us by return email and then delete the email.\n\nThis message has been scanned for viruses and dangerous content by\nMailScanner with McAfee UVScan, and is believed to be clean.\n\n\n\n"
        },
        {
            "subject": "another intr",
            "content": "Hi All\n\nI'm Peter Raftos, a web developer and trainer at the Australian National \nUniversity in Canberra, Australia.\n\nI have been involved here (in my particular area of the university) in pushing \nfor greater awareness of, and compliance with, W3C and associated standards for \nweb publishing, including accessibility.\n\nIf it's not XHTML+CSS, I am not publishing it...\n\nAnd now, back to lurking.\n\nPeter Raftos\nWeb Support Officer, RSPAS\nAustralian National University\nrspas-web@anu.edu.au\n+61 2 6125 5586\n\n\n\n"
        },
        {
            "subject": "Re: costbenefit analysis of standards complianc",
            "content": "steph wrote:\n> \n> So, very broadly, we may need to know for BOTH complaint/uncompliant\n> design projects, how much time is taken in:\n> \n> - concept/design\n> - development\n> - deployment\n> - maintenance\n> - ??\n\n\nDon't forget to take into account the costs of running the site after \nit's been completed. Things like size of page comparisons (bandwidth \ncosts), future updates for new browsers (won't be needed beyond maybe a \nfew lines if you've been coding right from the start), ability to serve \ndifferent media from the one site (maintenance only needs to run on the \none version, instead of having to update multiple versions of the site), \netc.\n\n-- \nLach\n__________________________________________\nhttp://members.evolt.org/luminosity/\nMSN: luminosity @ members.evolt.org\n__________________________________________\n\n\n\n"
        },
        {
            "subject": "Accessibility and Web Standard",
            "content": "Part of the task I've set myself is to understand the requirements of\nvisually impaired users of websites so that I can preach successfully\nfor Web Standards adoption giving a reason for so doing (not the only\nreason). I asked round at work (a software house) and found that the\nterm was not understood as I had hoped, so opted for a small straw\npoll. I mailed an archaeological mailing list of which I'm a member,\nbecause I thought that here was a fairly interested net savvy bunch\nof people, with the following:\n\nQUOTE\n\nI'm writing about accessibility. I need some opinions - you will not\nbe quoted, I just need to clarify my understanding. Would you be kind\nenough to give me (off list to avoid clutter to\nmailto:john.colby@btinternet.com) your FIRST reaction to the\nfollowing:\n\n1) If a website is accessible, what does it mean?\n\n2) If a museum display is accessible, what does that mean?\n\nThanks in advance\n\nUNQUOTE\n\nThe first question was for the answer I was looking, the second was a\ncontrol, as most archaeologists have involvement with museums, and\naccessibility of museum displays is very important if anyone wants\nfunding!\n\nI received 27 responses in an eight hour period. (that's about 7% of the \nlist) This is an analysis:\n\nQuestion 1 (Website accessibility)\n\n7 people gave an answer that in some way or another reasonably well\ndefined accessibility as it is defined by WAI, 2 of these saying that\nBobby compliance was a necessity. Only one person mentioned WAI by\nname.\n\n2 people gave partial answers to the above question.\n\n1 person gave examples of web standards compliant code without\nmentioning visual or other handicap.\n\nQuestion 2 (Museum accessibility)\n\n13 mentions of physical or visual disability\n\n11 mentions (some the same people above) that to be accessible the\ndisplay should be intellectually accessible.\n\nMy first conclusion (and these are only from this limited straw poll)\nis that although accessibility is in some way understood, its not\napplied in the same way to electronic access as it is to physical\naccess among this group.\n\nMy second thoughts concern the use of the term accessible - and the\ntask we have in promoting improved accessibility as a natural\nconsequence of adopting web standards. How should it be explained?\nI'm using examples such as braille readers, speech devices, internet TV\nand mobile devices in my teaching and hoping that people will understand.\n\nMy conclusion is (unless anyone can suggest a way) that when talking\nabout web standards and accessibility that it has to be defined - at\nleast until the term gets into general acceptance. It's not much use\ntalking about accessibility as a consequence of using web standards\nunless the term itself is fully understood, and to make that happen\nwe'll have to explain it every time.\n\nIts certainly made me think about the language and explanations I'm\nusing to describe the reasons for adopting standards compliance.\n\nRegards\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Re: costbenefit analysis of standards complianc",
            "content": "Is someone taking all this together to write an article? - I'm\nfinding it fascinating and need the information, but don't\nwant to re-invent the wheel if someone else is bringing it\nall together\n\nRegards\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Re :intr",
            "content": "Hi! I'm bruce Lawson of glasshaus, a UK publishing house going since March\nthis year.\nWe write books of interest to web professionals on all range of topics that\npresent standards, usability and accessibility as an inherent part of web\ndevelopment (rather than a nice-to-have extra).\n\nI'm brand manager, 35 years old, an ex-kindergarten teacher and prematurely\ngrey-haired.\n\nBruce Lawson\nbrand manager\nwww.glasshaus.com\n\nsee \"Dyanamic Dreamweaver MX\"\n\nhttp://www.glasshaus.com/bookInfo.asp?bookId=63\n\nThe sender cannot accept any liability for any loss or damage sustained as a\nresult of software viruses. It is your responsibility to carry out such\nvirus checking as is necessary before opening any attachment.\n\n\n\n"
        },
        {
            "subject": "Re: Accessibility and Web Standard",
            "content": "On Wed, 2002-07-10 at 02:05, John Colby wrote:\n> My second thoughts concern the use of the term accessible - and the\n> task we have in promoting improved accessibility as a natural\n> consequence of adopting web standards. How should it be explained?\n\nI am by no means an expert in this area, but this question got me\nthinking, and I wanted to write it down.  I haven't read the\naccessibility docs in a long time, so I don't remember if there was a\ndefinition in there, and I don't know if this is even what you were\nlooking for, but I will take a stab at a formal definition of how /I/\ndefine and explain the term accessible:\n\n\nTake any document such as a novel, magazine, or newspaper.  These\ndocuments are more than just a sequence of hieroglyphs - they have\nattributes such as whitespace, fonts, and color - this is\n\"presentation\".  Presentation is the syntax of a document, this syntax\nis used to convey semantics.  At the most basic level, we (normally) use\nthe syntax of whitespace (and punctuation) to define a sequence of\nhieroglyphs semantically as words, sentences, and paragraphs.  At a\nhigher level we often use presentation such as large font sizes or color\nto convey the semantic of headings, and italics to convey emphasis. \nThese semantics are what constitute a documents structure.  The mapping\nof syntax to semantics - presentation to structure - (and back) - is not\nuniversal.  The mapping is effected by everything from the medium being\nused (visual/auditory), to the culture defining the presentation\n(language/text direction), to limitations in peoples ability to perceive\na given presentation (deaf/blind).  Knowing the structure of a document\nfacilitates the ability for creation of a mapping from it's structure to\na presentation suitable for a particular viewer - this is accessibility.\n\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        },
        {
            "subject": "Re: costbenefit analysis of standards complianc",
            "content": "On Wed, Jul 10, 2002 at 09:11:02AM +0100, John Colby wrote:\n> Is someone taking all this together to write an article? - I'm\n> finding it fascinating and need the information, but don't\n> want to re-invent the wheel if someone else is bringing it\n> all together\n\nI'm happy to collate the comments on this topic, yes.  However, \nI'm hoping to actually produce a survey that can be conducted to \ngive us some concrete results.\n\nregards,\n-steph\nrandom web dudette\nhttp://unadorned.org/\n\n\n\n"
        },
        {
            "subject": "Re: Accessibility and Web Standard",
            "content": "Thanks Chris\n\nI'll digest what you've sent and reply.\n\nWhat I was looking for was not so much the\ndefinition as the perception of the term \naccessibility amongst those who are not part \nof the loop promoting it - in this case the \nnet savvy, a lot of them with their own \nwebsites and/or involved in the production \nof websites, mostly public sector so come\nunder any disability discrimination\nlegislation (the term in use in the U.K.)\nIf the majority had understood \nthe term I wouldn't be bothered, but as only \na third of respondents mentioned anything to \ndo with the term as we understand it, it \nneeds explainaing (as you've done) or \nexemplifying in other ways.\n\nStill working on this one.\n\nBTW, the websites to which I referred are \npublic sector\n\nJohn\n\n>  from:    Chris Hubick <chris@hubick.com>\nformal definition of how /I/\n> define and explain the term accessible:\n> \n> \n> Take any document such as a novel, magazine, or newspaper.  These\n\n<snip />\n\n> facilitates the ability for creation of a mapping from it's structure to\n> a presentation suitable for a particular viewer - this is accessibility.\n> \n\n\n\n"
        },
        {
            "subject": "Re: Accessibility and Web Standard",
            "content": "From: \"John Colby\" <john.colby@btinternet.com>\n\n| I asked round at work (a software house) and found that the\n| term was not understood as I had hoped, so opted for a small straw\n| poll. I mailed an archaeological mailing list of which I'm a member,\n| because I thought that here was a fairly interested net savvy bunch\n| of people, with the following:\n\n\nI am not surprised, my first short term independent contract agreement\nwas with a professor working with digital media. He used Jaws and could\nnot see at all, yet has been working on the Internet and with the\nInternet as well as teaching specialized topics in business for years.\nHe was not fully aware of what accessibility is or how to make things\nwork.\n\nAccessibility includes access of information or content to a wider\nvariety of users with various means of accessing the information,\nincluding but not limited to: motor, cognition, hearing, and vision.\nCare needs to be taken when focussing on access issues that we are aware\nof the other cases or situations. Why? Because some focus either leaves\nout other groups, or even makes it harder for other groups, unless we\nare careful when we use these items or when we may decide to take some\nitems out. [multimedia and graphics may be paramount to understanding\ncontent for those with cognitive or even motor challenges.]. I do\nbelieve average populations and more benefit from charts, graphs,\ndiagrams, table structures, and visual examples.\n\nIncreasing awareness is also part of the design/development specialists\njob.\n\n\n| QUOTE\n|\n| I'm writing about accessibility. I need some opinions - you will not\n| be quoted, I just need to clarify my understanding. Would you be kind\n| enough to give me (off list to avoid clutter to\n| mailto:john.colby@btinternet.com) your FIRST reaction to the\n| following:\n|\n| 1) If a website is accessible, what does it mean?\n|\n| 2) If a museum display is accessible, what does that mean?\n\n[*] The Dayton Art Institute and Access Art [one of the first I am aware\nof]\nan accessibly enhanced online art museum [nice examples of how it can be\ndone - multimedia to textual content and alternatives]\nhttp://tours.daytonartinstitute.org/accessart/\nhttp://tours.daytonartinstitute.org/accessart/access.cfm [overview of\nhow it is done]\n\n\n| I received 27 responses in an eight hour period. (that's about 7% of\nthe\n| list) This is an analysis:\n|\n| Question 1 (Website accessibility)\n|\n| 7 people gave an answer that in some way or another reasonably well\n| defined accessibility as it is defined by WAI, 2 of these saying that\n| Bobby compliance was a necessity. Only one person mentioned WAI by\n| name.\n|\n| 2 people gave partial answers to the above question.\n|\n| 1 person gave examples of web standards compliant code without\n| mentioning visual or other handicap.\n|\n| Question 2 (Museum accessibility)\n|\n| 13 mentions of physical or visual disability\n|\n| 11 mentions (some the same people above) that to be accessible the\n| display should be intellectually accessible.\n|\n| My first conclusion (and these are only from this limited straw poll)\n| is that although accessibility is in some way understood, its not\n| applied in the same way to electronic access as it is to physical\n| access among this group.\n|\n| My second thoughts concern the use of the term accessible - and the\n| task we have in promoting improved accessibility as a natural\n| consequence of adopting web standards. How should it be explained?\n| I'm using examples such as braille readers, speech devices, internet\nTV\n| and mobile devices in my teaching and hoping that people will\nunderstand.\n\nIt helps to try these items out while visiting web sites, especially\nsites with many pages containing information about products or services.\nIt is helpful also to visit web sites with detailed forms.\n\nI think the active demonstration imprints a message and highlights the\nchallenges of how our content works for others.\nTry this in various ways:\nWith the monitor off and listening, navigating with a screen\nreader.[visual]\nWithout a mouse, navigate and use a web site[some that are familiar with\nkeyboard shortcuts will have less trouble][motor/some cognitive groups]\nBut also try this using one hand or one finger only[motor]\nSome people access the web with specialized keys because they cannot\npress two keys a the same time[ctrl + shift + key is nearly impossible\notherwise or key combinations across the keyboard is difficult, too]\nSome use a stick or mouth stick to access a web site.\n\nI think active demonstration is a good way. Also remember that the\nInternet opens up access for those that may be homebound or unable to\naccess information in other ways. From their own computers they have the\nopportunity to access a variety of content and are students, users, and\nconsumers, too.\n\nhttp://www.webaim.org  A nice collection of simulations, examples,\narticles, and demonstrations regarding a variety of access topics. There\nare how-to pieces, links to resources, explanations of the WAI\npriorities, law, etc. A good web site to recommend to those interested\nin accessibility and delivery of content.\n\nholly\n\n\n\n"
        },
        {
            "subject": "Hello and a little (in the widest possible sense) intr",
            "content": "Hi, I'm Mike, but I travel around the web under the pseudonym of Isofarro,\nor Iso. (mainly web-related newsgroups and slashdot). I am a full time\nwebdeveloper for a financial company in the UK and have a very strong\ninterest in \"doing the right thing\" and \"doing it right first time\".\n\nI've dabbled on the web development side since 1997 doing everything from\nsimple webpages to framed websites, to table and fonted designs. Only this\nyear have I started doing proper web development - HTML that truely\ndescribes document structure, CSS to encapsulate layout and presentation,\nJavascript to enhance only.\n\nI have a strong interest in knowledge bases (I'm trying to write one --\nphp/mySQL), Content Management, XML and XSL, and recently Accessibility. My\npersonal website http://www.isolani.co.uk/ covers these interests - that was\nthe result of experimenting with XML content and creating the entire website\nusing XSL -- its not completely valid yet.\n\nMy ideal World Wide Web would have arrived when I'm able to travel abroad\nwith my pen-based screen and be able to do the \"bookings and appointments\",\n\"finding directions\" things as well as the things I'm currently stuck at a\ndesk doing - email, looking for info, reading, learning. The Web is a tool\nto make my life easier, not a manual-intensive system.\n\nI've had itches in the past to write articles about specific authoring\nproblems that keep cropping up and frustrating me, such as\nThe Mailto Myth: http://www.isolani.co.uk/newbie/mailto.html -- using the\nmailto as a form action\nFrames Are Evil: http://www.html-faq.com/htmlframes/?FramesAreEvil -- a look\nat the downside of frames.\nAny Size Design: http://www.allmyfaqs.com/faq.pl?AnySizeDesign -- this was\nthe result of a very interesting (sometimes a little bitter) discussion in\nalt.html about advocating \"liquid design\" articles that focused on tables. I\ntry to keep this up-to-date, since its a good reflection of my current\npractical understanding of the right-way-to-do-it. (Hopefully the links\nsection is useful too).\n\nSomehow a few people within the alt.html newsgroup reckoned I would be able\nto maintain a group FAQ, so I'm currently the alt.html FAQ maintainer -\nwhich typically involves finding the gems of knowledge and wisdom in the\ngroup and adding them, as well as recrafting some of the answers. So the\nquality of the site differs by questions really - but its a long term\nproject that I'm enjoying doing.\n\nI've caught the standards compliant bug and the usability bug, so hopefully\nI can write some useful articles about these topics that are of some value\nto me, the webdevelopers that work with me, and the web developers of\nalt.html.\n\nLooking at the list of people who've already posted here, I can see some\nknown authors, influential members of standards-groups, and people from very\nimpressive organisations (Like Glasshaus - I've been impressed with their\nrange of usable web books). In some ways I'm a little worried (maybe\nsceptical is a better word) whether I can do enough to make a useful\ncontribution here. I hope I can, and I'm determined to give it a go.\n\nI'm not a writer, or professional author - I don't believe that's a career I\nwould want to pursue, but I do want to write articles on issues that\ninterest/frustrate me as a web developer. I'm happier on the practical\naspects of web development, not the theory - so I do have difficulty\nunderstanding abstract concepts. I believe in simple solutions to problems,\nand overengineering a solution is an anathema.\n\nTo me, standards based web authoring is a foundation for better things, and\nas such there is no such thing as adding accessibility to a website, because\nit involves a high level of undoing and unlearning all the\nanti-accessibility tricks (like tables based layouts).\n\n\nLook forward to great discussions and positive action.\nMike (Isofarro)\n\n\n\n"
        },
        {
            "subject": "&amp;intro",
            "content": "Hi.\n\nI'm Simon Hill. I'm an addict.\n\nA W3C XHTML/CSS addict that is.\n\nWhy W3C?\nBecause their work is technically superior.\n\nI'm a web-monkey, but I come from a coding background. So I appreciate\nwell-documented and well thought-out design documents.\nI know there are a whole range of other benefits to the work of the W3C,\nbut that's my main focus.\n\nMe? I'm just a uni student. 3rd year CS geek, with the odd spurt of web\nwork.\n\nNB: I have a very... uncompromising attitude towards certain mangled\nmarkup, and certain broken user agents.\n\nThat is all.\n\n\n\n"
        },
        {
            "subject": "intro  yes anothe",
            "content": "heya all\n\ni'm tom zito and i'm a developer\n\ni currently work for the University of North Carolina at Chapel Hill, \nand luckily enjoy a position where we have a mandate to convert our \ncurrent 'official' technical documentation pages to be standards \ncompliant and adhere to U.S. section 508 guidelines for accessibility.\n\nso luckily for us the whole cost-benefit question isn't as much of an \nissue.\n\nback to lurking\n\ncheers\ntom\n\n\n\n"
        },
        {
            "subject": "XML and SuperString Theory??",
            "content": "Catchy title, huh?  Well it got you to open this message.  I?ll get to the \ntitle later, but first\n--- Yet another intro.\n\nFor those on the list who don?t know me (the majority I?m sure), I use the \npen name of Don XML (why? because I have a Slavic last name that most people \ncannot pronounce or spell).  I?m an active participant on the svg-developers \nYahoo Group, and a bunch of lesser known discussion groups that cover \nvarious XML derivative languages.  I worked with Kurt Cagle as the technical \nreviewer on the newest SVG Book - SVG Programming: The Graphical Web (which \nshould be in stores any day now).  I?m an independent consultant based out \nof New Jersey, USA, who specializes in architecting Microsoft .Net \napplications for major corporations (mostly pharms).  I really believe that \nthe best place to start using XML Web Services is in intra-Corporation \napplications.  Divisions within corporations don?t communicate between each \nother very well, typically use different platforms, and have no financial \nreasons to work well with the other divisions.\n\nBecause I work with Microsoft technologies, and pay attention to the W3C \nactivities, I usually try to work as a communications conduit for both \ngroups.  The folks at Microsoft aren?t any different from the folks of any \nother software company.  The best way to influence a software company is \nthru their developers.  They are were the rubber meets the road, and if you \ncan convince them of the benefits of some new technology/specification, \nyou?ve got a good chance of getting it implemented in their software.\n\nAnd now, onto the title subject: XML and SuperString Theory.  I?m sure you \nare saying to your self ?What does XML have to do with Theoretical \nPhysics??.  Well, they don?t currently have much in common, but they happen \nto both be topics I try to stay current with.  One day, as my mind was \nwandering like it does sometimes, both subjects got stuck in my head at the \nsame time.  And it occurred to me that the multidimensional aspects of \nSuperString theory (where they postulated that there are 10 dimensions) \nwould be much easier to depict and model if they used XML.  Exactly how the \nXML should look, well that is where I get stuck.  So if any of you mess \naround with Theoretical Physics, and wish to lend some brain matter, let me \nknow.  Now wouldn?t that be cool if XML was used to help solve the ?Theory \nof Everything?.\n\nDon XML\n\nAlways listen to experts. They'll tell you what can't be done, and why. Then \ndo it.\n\n\n_________________________________________________________________\nMSN Photos is the easiest way to share and print your photos: \nhttp://photos.msn.com/support/worldwide.aspx\n\n\n\n"
        },
        {
            "subject": "Slashdot: &quot;Designers Ignoring Standards&quot",
            "content": "I posted a summary[1] of what I understood to be the main points on alt.html\nlast night, maybe we can use it as a starting point to refine our position:\n\n> Why developers don't develop with standards in mind:\n> http://news.com.com/2100-1023-941926.html?tag=fd_lede\n\nI've been trolling a bit on slashdot over this one, and what I can\ngather there, and the reasons seem to be:\n* The boss doesn't care\n* They are not paid to deliver standards compliant sites\n* The clients know better\n* Who cares? It works in IE\n* Netscape 4\n\nThe overriding impression I get is that web designers are reluctant to\ncorrect misunderstandings their clients have about the web because it\nwill affect them getting the contract, which means no money to put food\non the table. They don't want to do the right thing because they don't\nreally understand what the right thing is, and they don't have the\nconfidence to explain the right thing to their clients.\n\nThe other important impression is that these websites seemed to be\ndesigned on the whim of clients with requirements shaped to \"impress\nthe VP\". Consideration of the end-user never seems to be an important\npart of the requirement.\n\nThe one gem of a comment I saw in the slashdot thread is a logfile\nanalysis of a leading e-commerce website found that Netscape users were\nthree times more likely to buy online than Internet Explorer users --\nsomething I had a gut-feel about. Nice to see confirmation of it though.\n\n> And why to disagree with the article:\n> http://www.webstandards.org/buzz/archive/2002_07.html#a000056\n\nHmm, I am a little disappointed about the substance of this article.\nIts a little too wishy-washy for me. I'm looking deeper into the\narguments put forward, and it is the underlying foundations which are\nshaky.\n\nPlay 20 questions with this and see how far you can go without going\ncyclical:\n\nWhy don't you support the minority that don't use IE5+?\n\n1.) Because its too expensive, we'd have to write a separate website\nper browser.\n\n* Indicative that this designer doesn't understand what a standard\ncompliant-based approach to website design is about.\n\n2.) Vast majority of our users use IE5+\n\n* Number of reasons for this, but essentially a self-fulfilling\nprophecies, just like the \"If you pay peanuts, you are going to get\nmonkeys\" scenario\n\n3.) Because the boss/client said so\n\n* Indicates a lack of confidence/knowledge on the web designer. Surely\nthey are better placed to recommend what works on the web and what\ndoesn't.\n\n4.) Because we can't make the site look good on Netscape 4.\n\n* Its the style versus substance. Big companies believe branding is\nmore important than content.\n\n\nAt least the webstandards.org group have decided to target the web\ndesigner and developers this time around (I'll have to update my FAQ\nentry for them soon *g*), and pursuing the educational angle is a good\napproach. Its obvious that web designers have no confidence in the\nbusiness side of websites, so that will be a key area to tackle.\n\nThere's no point creating a standards compliant website if the designer\nand the clients don't understand why its good to do so.\n\n\n\n----\n[1]\nhttp://groups.google.com/groups?q=author:Isofarro&hl=en&lr=&ie=UTF-8&oe=UTF-\n8&as_qdr=d&selm=i8kfga.b32.ln%40sidious.isolani.co.uk&rnum=2\n\n\n\n"
        },
        {
            "subject": "measuring the costbenefit analysis of standards complianc",
            "content": "I've been trying to think about how we could quickly and efficiently come \nup with some figures to use in such a CBA. I don't think it's practical to \nexpect a good number of designers to measure their time designing and \nmaintaining non-compliant websites and then to compare that with the time \nspent on compliant websites.\n\nBut those are the figures we want.\n\nMeanwhile, I've been reading Tufte's first book on information graphics.\n\nWhile driving to work today, it occured me, we can use his equations for \n\"chart junk\" (the amount of unnecessary clutter in a graphic) to determine \nactual numeric ratings for \"code junk\" in a website.\n\nCompliant websites have less code junk, and it would be simple to connect \nthe amount of code junk on a page, and the time required to edit, maintain,\n  design, or serve that page over a server. And time is money.\n\nMaybe a basic equation like this (and this may be way wrong. I'm just \nbrainstorming here, and I have no background in math or statistics):\n\nactual weight of content / mark-up = code junk rating\n\nWhat do you think? Bad idea? Misapplied? I'm curious for your responses.\n\n--\nAustin Govella\n\n\n\n"
        },
        {
            "subject": "Re: Slashdot: &quot;Designers Ignoring Standards&quot",
            "content": "At 5:22 PM +0100 7/10/02, Isofarro wrote:\n>The overriding impression I get is that web designers are reluctant to\n>correct misunderstandings their clients have about the web because it\n>will affect them getting the contract, which means no money to put food\n>on the table.\n\nYou're right, although there's an important secondary group of people as\nwell (you touched on this but I wanted to underscore it, as the concept\nbothered me).\n\nAnd that is; many website designers act as a baffle or smoke screen between\n\"standards compliance\" and their bosses.  Since a website designer can drop\ninto jargon (a la BOFH) and confuse the issue with great-sounding\ntechnicalities, and since many working relationships with designers place a\ngood amount of trust in their Internet-related opinions, this is a\ndangerous predicament.  Several people on Slashdot recommended that if\nyou're ever to complain about a site design, you should write to the\nappropriate VPs of the company -- not the webmaster, who all too often will\nignore your message completely.\n\nDo these cunning people really exist, in significant numbers?  And if so,\nhow do we educate the hostile?  Some of those positions are likely quite\nsecure.\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "pissed off intr",
            "content": "I'm tired, sometimes even angry and I want web standards to make my job \neasier. I'm hoping to learn from the considerable collective experience on \nthis list and find out how to evangelize to non-technical people.\n\nOh, I understand how web standards work and I'm all for it, I just haven't \nhad much success in convincing others to have our work future-proofed and \navailable on many devices. I'm a young web designer who's only been in the \nfield for a few years and I work in-house as the webmaster for a large \nuniversity (biology.ucsd.edu), so most of the problem has nothing to with \ntechnical details - I'm just at the bottom of a large totem pole. No big \nclient list to cycle through for a sympathetic ear. And on a fundamental \nlevel, web designers are ill-equipped to tell systems administrators why \nthey should kill off Netscape 4, since all we can talk about is the user \nexperience and not many of their issues, like security, stability, etc. IE \n6 may be a great product, but removing the stink of association with \nanything Microsoft is near impossible. Can you blame them, if all they know \nabout Microsoft and the web is the hell created by FrontPage \"authors\"?\n\nAlthough my work is starting to gain recognition outside of our department \nand I'm pretty good at public speaking (I just gave my first presentation \non web standards at a campus conference this morning, it went swimmingly), \nI still haven't had much luck in practicing what I preach and convincing \nothers (especially faculty) that degradation in Netscape 4 is an acceptable \ntrade off, especially when considering the point brought up by another \npost: there is a distinct lack of killer apps that require web standards, \nsince most people don't rely on Pocket PCs or Braille readers on a daily \nbasis. Anyone else that works in a university or large government \norganization may be able to sympathize with my plight! Our server stats \nshow that upwards of 40% of our audience still use some version of NN4, and \nwe get 1-2 million hits a month.\n\nAnd I'm glad to see others care about this issue:\n\nAt 10:53 PM 7/9/2002 +0100, Drew McLellan wrote:\n>So how the heck to we make the benefits of standards-based markup/code \n>real to the worker ants on the ground?\n\nAt 05:22 PM 7/10/2002 +0100, Isofarro wrote:\n>There's no point creating a standards compliant website if the designer\n>and the clients don't understand why its good to do so.\n\nHear, hear. Those are my main concerns also and I am desperately curious to \nhear what works for other people.\n\nAnd sorry to come across as so jaded - it's just that sometimes I want to \nchuck it all and find a web agency that believes in the same values! \nEvangelism in such a large organization is tiring and I have an INCREDIBLE \namount of respect for the tireless efforts of the webstandards.org people \nand Jeffrey Zeldman in particular. How you guys and gals keep it up, I \ndon't know. Caffeine maybe?\n\nrant over...\n\nAl Abut\n\n\n\n"
        },
        {
            "subject": "Promoting standards  to Al Abu",
            "content": "The way I'm using to get the message across in my company in the U.K. is to \nuse references to the Disability Discrimination Act, The RNIB (Royal \nNational institute for the Blind) and other similar organisations to \nemphasise that we're not doing as well as we could. This probably \ntranslates to Section 508 and other organisations in the USA. I'm also \nusing futureproofing (a term I've been using for close on two years and its \nnot sunk in yet) to say that our clients will expect better of us for a \nsmall change in practice. Fortunately we don't have the NS4 usage that you \nhave, less than 3%. It may not be fair using someone else's disability to \nhighlight that we should be doing something different, but do say that \ndisability of whatever form is something that occurs more as people get \nolder, and would you (the audience) like it if you were excluded from \nsomething you can do now? That seems to have some effect. It did the last \ntime I gave a similar presentation, anyway, but the audience was not \ninfluential in the company as I would have liked.\n\nIts taken me two years to get not very far - you're not alone. I'm doing a \npresentation in mid September to try and get the message across again - \nalthough I don't expect to  have the success I think it should have as I'm \nup against a set of people who do not know. It is my job to educate them. \nWell, I think it is, anyway. I am rather a self-appointed evangelist - I \nthink that many people here are, and don't mind being so called.\n\nMy opinion, after posting to this forum for just three days is that there \nis a helluva lot of talent here, and we're all in the same type boat \nsailing on the same type of ocean - a bit lumpy with occasional storms.\n\nThe way I think that this forum will pan out is that there are so many \ncommitted people here writing about Web Standards that resources will soon \ncome along at which you can point people and say \"That's why we should do \nit\". they may not agree first time, but the second, third and so on???\n\nAll I can say is that you have a position I'd envy, and be wary about \ngiving up. There aren't many web agencies who think the way that we do, \nunfortunately. All we can do is give support - you're not on your own - as \nthis list is making very plain.\n\nRegards\n\nJohn\n\nAt 13:16 10/07/02 -0700, Al Abut wrote:\n\n>And sorry to come across as so jaded - it's just that sometimes I want to \n>chuck it all and find a web agency that believes in the same values! \n>Evangelism in such a large organization is tiring and I have an INCREDIBLE \n>amount of respect for the tireless efforts of the webstandards.org people \n>and Jeffrey Zeldman in particular. How you guys and gals keep it up, I \n>don't know. Caffeine maybe?\n\n\n\n"
        },
        {
            "subject": "Re: measuring the costbenefit analysis of standards complianc",
            "content": "On Wed, Jul 10, 2002 at 11:26:24AM -0500, Austin Govella wrote:\n> \n> I've been trying to think about how we could quickly and efficiently come \n> up with some figures to use in such a CBA. I don't think it's practical to \n> expect a good number of designers to measure their time designing and \n> maintaining non-compliant websites and then to compare that with the time \n> spent on compliant websites.\n\nThis occurred to me - and to some extent it depends on the kind\nof questions one asks. For example, \"What proportion of your time per \nweek do you spend on (such a such a task)?\" is possibly a better\nquestion than \"How many hours do you spend ...\".\n\nIt is easier to get a feel for the subdivisions of time rather than \nexact number of hours.\n\nI do not know if it's reasonable to only target designers.\nThe cost of a project is spread over more than just designers,\nso if there's a project manager, that would be the best person\nto be asking these questions (one hopes). \n\nThoughts ?\n\n> While driving to work today, it occured me, we can use his equations for \n> \"chart junk\" (the amount of unnecessary clutter in a graphic) to determine \n> actual numeric ratings for \"code junk\" in a website.\n> \n> Compliant websites have less code junk, and it would be simple to connect \n> the amount of code junk on a page, and the time required to edit, maintain,\n>   design, or serve that page over a server. And time is money.\n>\n> Maybe a basic equation like this (and this may be way wrong. I'm just \n> brainstorming here, and I have no background in math or statistics):\n> \n> actual weight of content / mark-up = code junk rating\n> What do you think? Bad idea? Misapplied? I'm curious for your responses.\n\nVery interesting idea.  How would you measure/establish the actual weight\nof content and the mark-up (hm, what does this mean?)?\n\nIf we can assign a code-junk rating to a site, it might be an \n'encouragement' factor for someone to overhaul their site.\n\nHehe, we still need to know the average time taken to edit/maintain/\ndesign. :) If we have statistics from the metrics I have been proposing,\nthis should be achievable.\n\nI think you can only calculate an average time to work on a page\nfor a particular site, because it may depend on what technology\nthey use, how the site is structured - dynamic content or not? \nexisting CMS? and so forth.  I don't know if this is a reasonable \nassumption or not!\n\nI'm very open to ideas. :)\n\ncheers,\n-steph\nrandom web dudette\nhttp://unadorned.org/\n\n\n\n"
        },
        {
            "subject": "Comparison of Standard and Proprietary Technologie",
            "content": "I am putting together a document to, primarily, show the strengths of \nthe standard technologies and the weaknesses of the proprietary \ntechnologies.  Please review it at \nhttp://moz.zope.org/Members/brantgurganus2001/standards_evangelism/comparison \nand give me your feedback.  I plan to work on more documents and \npublishing them here as well.\n\n-- \nBrant Langer Gurganus\nThe best life is the one worth living.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "Brant Langer Gurganus wrote:\n\n>\n> I am putting together a document to, primarily, show the strengths of \n> the standard technologies and the weaknesses of the proprietary \n> technologies.  Please review it at \n> http://moz.zope.org/Members/brantgurganus2001/standards_evangelism/comparison \n> and give me your feedback.  I plan to work on more documents and \n> publishing them here as well.\n>\nWoops, the file upload is messed up, disregard for right now.\n\n-- \nBrant Langer Gurganus\nThe best life is the one worth living.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Another intro: &quot;ivory tower&quot; or &quot;down in the trenches&quot;",
            "content": "Hi folks, my name is David Bobzien and I'm the webmaster for the University of Nevada, Reno.\n\nLike most public higher education institutions, our web publishing is highly dispersed and downright chaotic.  My direct development responsibilities center on probably only 5% of the documents in the unr.edu domain, but I provide technical assistance and guidance to an incredibly disparate group of developers (admin aids, professors, student employees, etc.) building sites that constitute the university's web presence.\n\nThe importance of standards from my perspective:\n1) As a public institution receiving federal aid for technology, we're on the hook for Section 508 compliance.\n\n2) Web development in a large and open institution like ours is ephemeral- the student that designs a really whiz bang website ends up leaving quite a mess for the staff person left to manage it once they graduate/flunk out/whatever.  We waste untold sums of $$ and time reinventing the wheel with each site's baton passing- standards are one more way to keep everyone efficient and on the same page.\n\nStrategy for standard's evangelism?  In addition to sounding like a broken record talking about 'em, implement standards in my projects according to tiers.\n\n1) Internal sites for fellow university developers: standards all the way.  Demonstrate how much easier life is when you don't worry about making it look pretty in Netscape 4 (ex: my \"home page\": http://unr.edu/homepage/davidb/).  Provide validation links to challenge fellow developers (\"how clean is your code?\") and get them thinking.\n\n2) Internal sites for university employees/students (\"intranet\"): Spoon-fed standards.  Build sites that degrade to Netscape 4, but allow for a noticeable difference in presentation.  Ex: http://www.unr.edu/outstandingresearchers/.  Built on a standard university XHTML transitional template, the light colored horizontal bar isn't displayed in Netscape 4.\n\n3) THE site... www.unr.edu.  Standards as a goal.  The \"top\" of our site is a pathetic mish-mash of non-compliant code and work-arounds.  Little by little, I'm cleaning it up, but until Netscape 4 drops below 5% in our logs (it's still at around 18%), full standards compliance is politically impossible (but not as far as 508 compliance goes.)  The irony is that the majority of our Netscape 4 visits are from on campus (which leads me to the another standards strategy, eradicating Netscape 4 from campus desktops).\n\nThe idea is to move things along this \"standards as a goal / spoon-fed standards / standards all the way\" continuum. My interest in this group revolves around what I guess you would call the \"cultural dynamics\" of standards advocacy in large organizations.\n\nUnrelated quick facts:\n1) It's currently 106 degrees Fahrenheit outside.  This is the desert, but it usually only gets this hot down in Las Vegas.\n\n2) Reno is nowhere near Las Vegas.\n\n\n\n"
        },
        {
            "subject": "numintros+",
            "content": "I normally don't introduce myself on lists but I've been impressed by\nthe number of Australians (or at least residents and ex-residents)\nintroducing themselves that I thought I'd join in. We're going to take\nover the brave new standards-compliant Web world ;)\n\nMy name is Dean and I'm a standards-a-holic. It's been 3 hours\nsince I last validated.\n\nI work for the W3C from Canberra, Australia (this makes me the most\nremote W3C Team member!).\n\nI'm in the Graphics Activity and am the Team Contact for Scalable\nVector Graphics (SVG). I also am the editor of the SVG\nspecification. I see a list like this, the WASP and general\nweb-standards evangelism in general as something that will help\ndemonstrate the benefits of SVG to the world (over other proprietary,\nclosed and less accessible formats).\n\nI see a lot of evangelism for XHTML+CSS, but I'd like more for\nSVG (I notice the WASP mention SVG in their new charter.. woohoo!).\n\nLikes: pretty pictures on the web, XHTML+CSS\n\nDislikes: ugly pictures on the web, HTML (it's time to move on \nto XHTML+CSS)\n\ndean\n\n\n\n"
        },
        {
            "subject": "How do standards solve &quot;everyone's&quot; problem",
            "content": "Hello, My name is John Deighan, and I'm not from Australia.  I've been \nunemployed for the last six months (thank you Osama, thank you Enron, \nthank you WorldCon), but when I *was* working, I was with the web \nservices group of a minor telecom company.\n\nMy observation:  Web standards (and adherence to same) makes \"my\" job \n(as a web page creator/maintainer) easier.  However, the main \n\"consumers\" of these web pages is the marketing department*.  The \nengineers want things to be orderly and logical on \"their\" web site. \n The marketeers want to SELL SELL SELL and to make \"their\" site as \nflashy and sexy as possible: after all, will Joe Average remember you if \nyour site looks like everybody else's site?\n\nWeb standards don't stand a chance unless we show the marketeers how all \nthis makes their job easier as well, and we turn \"our\" web site and \n\"their\" web site into a corporate site we can all be happy with.\n\n\n    Cheers,\n    John Deighan\n\n\n------\n* well, ultimately it's Joe Average out in the great Internet Cloud: and \nif we don't get repeat hits, we gotta scrap the design.  The first \nhurdle a site has to go through in the \"real world\" is the marketing \ndepartment...\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "Brant Langer Gurganus wrote:\n\n>\n> Brant Langer Gurganus wrote:\n>\n>>\n>> I am putting together a document to, primarily, show the strengths of \n>> the standard technologies and the weaknesses of the proprietary \n>> technologies.  Please review it at \n>> http://moz.zope.org/Members/brantgurganus2001/standards_evangelism/comparison \n>> and give me your feedback.  I plan to work on more documents and \n>> publishing them here as well.\n>>\n> Woops, the file upload is messed up, disregard for right now.\n>\nI fixed it.  It is at \nhttp://moz.zope.org/Members/brantgurganus2001/evangelism/comparison\nPlease comment.\n\n-- \nBrant Langer Gurganus\nThe best life is the one worth living.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Re: Slashdot: &quot;Designers Ignoring Standards&quot",
            "content": "From: \"Joseph McLean\" <joseph@secondflux.com>\n> ... many website designers act as a baffle or smoke screen between\n> \"standards compliance\" and their bosses.  Since a website designer can\ndrop\n> into jargon (a la BOFH) and confuse the issue with great-sounding\n> technicalities, and since many working relationships with designers place\na\n> good amount of trust in their Internet-related opinions, this is a\n> dangerous predicament.\n\nThat puts the web-designer in a position of trust, and a position they can\nadd benefit, profit or abuse. So as long as it is in the web-designers\ninterest (financially) not to adopt a standards based approach, the bosses\nwill be none the wiser.\n\nThis suggests a two pronged approach:\n1.) Promoting the concrete benefits of a standards-based accessible web\nauthoring to the designers, on what they can gain from it, what their\nclients can gain from it, and _how_ to actually do it. So lots of practical\nadvice and guidelines, as well as clear arguments against the myths of\naccessible authoring (double the cost of \"normal\" authoring).\n\n2.) Promoting the business benefit of accessible web authoring on the\nclients and bosses, but from a non-technical view point. If bosses and\nclients are insisting on non-accessible design, they should do so with the\nmaterial facts and relevant information. This should include arguments\ntackling the myth that the web is like paper.\n\nIf people don't understand what the web is, where it is going, and why its\ngood for everyone, its a little difficult to convince them why accessibility\nis in their best interests. Websites are focused on today's customers -- the\nones willing to part with their money today. How or why are tommorrows\ncustomers more valuable?\n\n\n\nIso.\n\n\n\n"
        },
        {
            "subject": "Yet another introductio",
            "content": "Since nobody has announced that reading endless introduction is frustrating, \nI'll introduce myself as well.\n\nI'm from Finland (Northern Europe > Scandinavian) an work as a IT Support, \nmostly maintaining server and Intranet, doing (web) applications and user\ninterfaces. I also study in Business Polytechnic, expertising in programming and\nweb designing.\n\nWeb designing has been part of my life since 1997 and programming since 1995. \nI've been interested following standards only couple of years, yet doing active\nresearch, which has provided me wide knowledge of different techniques.\n\nBesides my studies and part-time work I'm working with different (both client-\nand serverside) projects. I'm also a chairman of student's ICT (Information & \nCommunication Technology) team in our school (without wage :().\n\nOne reason why I got interested following standards, still allowing proprietary\ntechniques, is when I started moderating in WA Forum (currently \nCodingForums.com), at HTML&CSS section. It's very concerning to see how many\n\"web designers\" has no idea why to follow standards and why to visit at W3C's\npage frequently. All our moderators are pressuring a lot that every member\nlearns to follow standards.\n\nMy main \"things to do\" is to participate writing a book about advanced and\nmodern web designing..or write a book completely by myself :). I'm also always \nready in writing guest articles to one's website whenever needed about:\n(X)HTML, CSS, client-side scripting / DOM, which are the areas i'm expertized.\n\nHope we'll have a fruity conversation in future. Pleasant and warm summer to\neveryone,\n\nZvona\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "steph wrote:\n\n>Hi Brant,\n>\n>On Wed, Jul 10, 2002 at 11:00:24PM -0500, Brant Langer Gurganus wrote:\n> \n>  \n>\n>>I fixed it.  It is at \n>>http://moz.zope.org/Members/brantgurganus2001/evangelism/comparison\n>>Please comment.\n>>    \n>>\n>\n>Looks good :)  Though I don't understand why you've\n>said that the behavior of non-proprietary user agents is not \n>guaranteed. Please enlighten?\n>\nI am just pointing out that what a non-proprietary browser will do. \n Some browsers might skip the unrecognized element entirely, some might \nrender it as if the unknown tags were not there, some might attempt \nemulation which may or may not work.  Basically, what happens cannot be \npredicted.\n\n>\n>For disadvantages to standards, I think you can also add:\n>- not all user agents which are currently used support standards\n>  adequately.\n>\nI meant to add that.  It is there now (locally).  I will wait until I \nget some more feedback if any before uploading again.\n\n>\n>This is an unfortunate biggie - some designers might have been\n>given the directive that they have to provide the same quality\n>experience for old browsers.\n>\nThere is a hidden advantage that is brought to mind by that.  If a \nbrowser follows the standard, it *should* render the content of an \nunknown element as if the unknown tags were not present.\n\n>\n>Are you able to give examples for each point, and link it off\n>from each dot point to a diff page, for example ?  I really\n>like how straight-to-the-point your table is, and it'd be\n>good to keep it that way.\n>\nI think linking to more in-depth pages for each point is a good idea. \n Thanks.  If you know of any pages that have content fitting a point, \nlet me know.  Some points could probably link to the same page since \neach advantage usually has a disadvantage: Standards are expensive now, \nbut they are cheaper in the future.\n\n>\n>:)\n>\n>regards,\n>-steph\n>\n> \n>\n>  \n>\nThank you for the feedback.  Let me know if you see anything else I \nshould add.\n\n-- \nBrant Langer Gurganus\nThe best life is the one worth living.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "At 09:00 PM 07/10/2002, Brant Langer Gurganus wrote:\n>Please comment.\n\nI would suggest that \"Support for standard technologies will never end.\" \nshould be qualified, as certainly technology gets left behind all the time, \nwhether it be an 8-track tape or a deprecated FONT tag.\n\nProprietary technology can be more innovative, since proprietary technology \ncan be developed faster by its owner than a standard can be invented and \nagreed upon by a standards body.\n\nStandards behavior is not always guaranteed, as the standard can be changed.\n\nBill Mason\nAccessible Internet\nw3c@accessibleinter.net\nhttp://www.accessibleinter.net/\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "Bill Mason wrote:\n\n>\n> At 09:00 PM 07/10/2002, Brant Langer Gurganus wrote:\n>\n>> Please comment.\n>\n>\n> I would suggest that \"Support for standard technologies will never \n> end.\" should be qualified, as certainly technology gets left behind \n> all the time, whether it be an 8-track tape or a deprecated FONT tag.\n\nI removed it.  You do have a point there, but I think proprietary \ntechnologies die faster than standard technologies.  Netscape killed \ntheir own document.layers and <LAYER> proprietary stuff.\n\n>\n>\n> Proprietary technology can be more innovative, since proprietary \n> technology can be developed faster by its owner than a standard can be \n> invented and agreed upon by a standards body.\n>\n> Standards behavior is not always guaranteed, as the standard can be \n> changed. \n\nI will upload a new version shortly.  Continue sending comments.\n\n>\n>\n> Bill Mason\n> Accessible Internet\n> w3c@accessibleinter.net\n> http://www.accessibleinter.net/\n>\n>\n>\n\n\n-- \nBrant Langer Gurganus\nThe best life is the one worth living.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "Two comments:\n\nThe 8-track was made obsolete by developing technology, not changes in standards. The standards for the 8-track still exist and no doubt someone somewhere has one that works.\n\nStandards can be changed, yes, but in a publicly agreed and versioned manner. Proprietary techniques do not have this public constraint - may be better if they did, but a proprietary author is under no obligation to disclose - just say that 'this is the way it works now'.\n\n>  from:    Bill Mason <w3c@accessibleinter.net>\n>  date:    Thu, 11 Jul 2002 16:25:30\n>  to:      public-evangelist@w3.org\n>  subject: Re: Comparison of Standard and Proprietary Technologies\n> \n> \n> At 09:00 PM 07/10/2002, Brant Langer Gurganus wrote:\n> >Please comment.\n> \n> I would suggest that \"Support for standard technologies will never end.\" \n> should be qualified, as certainly technology gets left behind all the time, \n> whether it be an 8-track tape or a deprecated FONT tag.\n> \n> Proprietary technology can be more innovative, since proprietary technology \n> can be developed faster by its owner than a standard can be invented and \n> agreed upon by a standards body.\n> \n> Standards behavior is not always guaranteed, as the standard can be changed.\n> \n> Bill Mason\n> Accessible Internet\n> w3c@accessibleinter.net\n> http://www.accessibleinter.net/\n> \n> \n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "From: \"Brant Langer Gurganus\" <brantgurganus2001@cherokeescouting.org>\n> Bill Mason wrote:\n> > I would suggest that \"Support for standard technologies will never\n> > end.\" should be qualified, as certainly technology gets left behind\n> > all the time, whether it be an 8-track tape or a deprecated FONT tag.\n>\n> I removed it.  You do have a point there, but I think proprietary\n> technologies die faster than standard technologies.  Netscape killed\n> their own document.layers and <LAYER> proprietary stuff.\n\nThat raises the corresponding point that proprietary technologies tend to be\nlimited to a particular implementations - layer only worked on Netscape\nNavigator, similarly marquee only worked on Internet Explorer. So if a\nproprietary product is not hugely successful rather quickly, it doesn't\nbecome adopted by competing or complementary products. document.all is an IE\nonly device, and although used in a browser with +-90% penetration, still\nisn't supported in other browsers, although the non-proprietory\ndocument.getElementById is better supported.\n\n\n\nIso.\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "I would question the assumption that standards are developed less quickly\nthan proprietary technologies.  Although proprietary technologies can be\n_introduced_ by any browser on a whim, this does not place the code at the\ndisposal of website developers.  Even developers who target only IE\nbrowsers would not choose code that breaks all previous versions!.  The\ninstalled base is too large, and WYSIWYG editors aren't exactly\ncutting-edge either.  As a result, proprietary technologies enjoy the a\nsimilar trickle-down effect that standards do.\n\nThe majority of proprietary code washing around out there on the Internet\nis quite old, is it not?\n\nStandards may take longer to introduce, but they generally evolve in a more\npredictable fashion, and (one hopes) devolve cleanly on browsers that came\nbefore them.  So they may be out of the starting gate later, but ready for\nmarket acceptance sooner.  The end result should leave no clear speed\nadvantage for proprietary markup, I feel.\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Re: Promoting standards  to Al Abu",
            "content": "Thanks for the kind words John, and yes, it's very nice to be in the same \nboat with other self-appointed evangelists toiling away in large \norganizations. Designers, programmers and web developers in general have \ntheir circles to talk about issues, but finding people interested in web \nstandards has been another matter.\n\nAs for one of your points:\n\nAt 10:18 PM 7/10/2002 +0100, John Colby wrote:\n>It may not be fair using someone else's disability to highlight that we \n>should be doing something different, but do say that disability of \n>whatever form is something that occurs more as people get older, and would \n>you (the audience) like it if you were excluded from something you can do now?\n\nI do feel sometimes like I'm co-opting the cause of designing with disabled \npeople in mind simply because pages that are accessible for them are \nconsequently easily digestible by other devices as well. There's a few \nPocket PC initiatives starting on campus that are experimenting with \nchanging the way some undergraduate courses are taught, with IPaqs on each \ndesk, and having the course material be already standards-compliant for \nvisually impaired professors helps immensely, since it's trivial to recycle \nthat content. In fact, the only web developers on my campus that have been \nable to implement any kind of usability or accessibility-related designs \nwere in departments where they had disabled faculty. I never pictured \nmyself saying this and I'd wouldn't wish ill upon anyone, but I found \nmyself wishing that our department had more handicapped professors!\n\n\n\n"
        },
        {
            "subject": "Re: Comparison of Standard and Proprietary Technologie",
            "content": "Joseph McLean wrote:\n\n>I would question the assumption that standards are developed less quickly\n>than proprietary technologies.  Although proprietary technologies can be\n>_introduced_ by any browser on a whim, this does not place the code at the\n>disposal of website developers.  Even developers who target only IE\n>browsers would not choose code that breaks all previous versions!.  The\n>installed base is too large, and WYSIWYG editors aren't exactly\n>cutting-edge either.  As a result, proprietary technologies enjoy the a\n>similar trickle-down effect that standards do.\n>\n>The majority of proprietary code washing around out there on the Internet\n>is quite old, is it not?\n>\n>Standards may take longer to introduce, but they generally evolve in a more\n>predictable fashion, and (one hopes) devolve cleanly on browsers that came\n>before them.  So they may be out of the starting gate later, but ready for\n>market acceptance sooner.  The end result should leave no clear speed\n>advantage for proprietary markup, I feel.\n>\n>-Joseph\n>\n>\n>  \n>\nI understand what you mean.  I will updated it.\n\n-- \nBrant Langer Gurganus\nThe best life is the one worth living.\nhttp://troop545.cjb.net/brant.htm\n\n\n\n"
        },
        {
            "subject": "Re: Promoting standards  to Al (access: devices vs. people w/ disabilities",
            "content": ">>From: Al Abut\n>>Sent: Thursday, July 11, 2002 9:30 AM\n\n>>I do feel sometimes like I'm co-opting the cause of designing with disabled \n>>people in mind simply because pages that are accessible for them are \n>>consequently easily digestible by other devices as well.\n\n\nIronic, I find myself doing the reverse: stumping for disabilities accessibility by talking about how great it will be when networked refrigerators can cruise the Web.  Maybe I've got it all backwards!\n\nSeriously, a major hurdle to standards evangelism is the unfortunate residual backlash against disabilities access.  I've seen supposedly enlightened professors in a university setting decry the \"extra work\" necessary to provide accommodation to students with disabilities.  The notion that accessible websites are \"more work\" is unfortunately all too pervasive.\n\nA link to share on accessibility: WebAIM (\"Web Accessibility in Mind\", http://www.webaim.org/).  Their screen reader simulation, http://www.webaim.org/simulations/screenreader/, is an eye-opening look at the (lack of) accessibility of a hypothetical university website.  It's a Shockwave screen reader \"emulator\" that shows how awful an experience an inaccessible site can be.  Easy to share with the people we preach to.\n\nCheers,\n\nDavid Bobzien\n\n\n\n"
        },
        {
            "subject": "k10k ripoff proposa",
            "content": "This was prompted by 37signals, my favorite web agency, launching a \nXHTML/CSS redesign today.\n\nWhy not start a collection of standards-compliant sites? You know, have a \nlinkdrop where we post standards-compliant sites and people can go to one \nresource to see working examples of what the evangelists are talking about, \nthe way k10k-type portals showcase what's going on in the design community. \nIt's one thing to read the tutorials and try stuff out in your own \nbackyard, but it's great to see what other people cook up too. I know my \npersonal interests lie in finding commercial, non-experimental sites like \n37signals that put their money where their mouth is. The only other company \nlike that I've come across was from a Zeldman link a while back, \nhttp://www.spazowham.com/\n\nGood idea?\n\nAl Abut\n\n\n\n"
        },
        {
            "subject": "Re: k10k ripoff proposa",
            "content": "I agree ... and we are starting a links database at www.studiowhiz.com one\nof the catagories slated is the XHTML, CSS built sites. I'll let you know\nwhen this goes live\n\nI've also just rebuilt www.kiwi-interactive.com to complete XHTML Strict and\nCSS. This little project is my company site. I'm going to use it as a living\nexample of Standards Based site design. As I learn more, and push my own\nboundaries it will change. I've yet to add more graphical designs to this.\n\nThe one thing I find...this is me wearing my designer hat for a moment. 99%\nof XHTML & CSS driven sites that I 've seen look very similar and have\nreally lacking imagry.\n\nYou mention k10k ... okay I personally think it's icky .. BUT ... look at\nthe graphically RICH interface there. How on EARTH do you rebuild that AS IT\nIS using standards based HTML?  IE: no tables!\n\nI'd love to be able to do this\n\n.contentCELL {\n    top-right-corner: 1px curve green;\n    top-left-corner: 1px square green;\n    border: 1px solid green;\n    bottom-left-corner: 1px curve green;\n    bottom-right-corner: 1px square green;\n}\n\nOr similar to enable more \"designy\" type interfaces like K10K.  The most\ncommon thing I run into is that XHTML & CSS sites are often boring.\n\nSo I'm all for finding really AWESOMELY designed standards based sites, to\nshow that these too can appeal to designers.\n\n*removing desiner hat*\n\nThanks\nK.\n\n>\n> This was prompted by 37signals, my favorite web agency, launching a\n> XHTML/CSS redesign today.\n>\n> Why not start a collection of standards-compliant sites? You know, have a\n> linkdrop where we post standards-compliant sites and people can go to one\n> resource to see working examples of what the evangelists are talking\nabout,\n> the way k10k-type portals showcase what's going on in the design\ncommunity.\n> It's one thing to read the tutorials and try stuff out in your own\n> backyard, but it's great to see what other people cook up too. I know my\n> personal interests lie in finding commercial, non-experimental sites like\n> 37signals that put their money where their mouth is. The only other\ncompany\n> like that I've come across was from a Zeldman link a while back,\n> http://www.spazowham.com/\n>\n> Good idea?\n>\n> Al Abut\n>\n\n-- \nKeran McKenzie\nFounder | Kiwi Interactive Ltd\n\nhttp://pnut.studiowhiz.com (thoughts)\nhttp://www.studiowhiz.com (Web Resources)\nhttp://www.flashcomponent.com (MX Components)\nhttp://www.kiwi-interactive.com (Web Dev Company)\n\n\n\n"
        },
        {
            "subject": "RE: k10k ripoff proposa",
            "content": "| You mention k10k ... okay I personally think it's icky .. BUT ... look at\n| the graphically RICH interface there. How on EARTH do you rebuild that AS IT\n| IS using standards based HTML?  IE: no tables!\n|\n| Thanks\n| K.\n\n\ni don't think it would be too difficult -- the k10k uses\na lot of graphical titles and other text items, which you\ncan position absolutely on the screen. \n\nfor html-based text, you could use iframe content blocks,\nwhich would allow you to absolutely define both the height\nand width of the content area. no worrying about stretchy\ncontent.\n\nand, to support the absolute positioning of all items on\nthe page, you could launch k10k in a separate browser\nwindow, with the height and width of the window defined.\n\nam pretty sure that they already down browser-sniffing\nand css stylesheet swapping for netscape and ie users\nto begin with...\n\nwho knows... maybe we could get 37 signals to do a\n\"37betterK10K\" site for showcasing this. they just did\na css/xhtml overhaul of their own site.\n\n\n/anthony\n\n\n\nanthony baker  | aim: meadowlark07\nt: 415.441.6819  | f: 415.276.9388 \nmailto:anthony@designforpeople.org \n\n\n\n"
        },
        {
            "subject": "RE: k10k ripoff proposa",
            "content": "> who knows... maybe we could get 37 signals to do a\n> \"37betterK10K\" site for showcasing this. they just did\n> a css/xhtml overhaul of their own site.\n> )\n\nYeah or we could do it ourselves :) he he he\n\n\n\n"
        },
        {
            "subject": "FW: Cost Savings of Using CS",
            "content": "thought y'all might be interested in this, given the conversation\nthat's been going about regarding the positive economics of \nbusinesses adopting css. this is one of the best that i've seen,\nparticularly for large or highly-trafficed websites.\n\nit's taken from the web design list http://webdesign-L.com/\n\nif interested, i can post follow-on replies to this. david \nwertheimer, the design director of the econmist online posted\nsome responses...\n\ncheers,\n\nanthony\n\nanthony baker  | aim: meadowlark07\nt: 415.441.6819  | f: 415.276.9388 \nmailto:anthony@designforpeople.org \n\n\n------------------------------------------------------------------\n\n\nDate: Thu, 11 Jul 2002 10:50:33 -0500\nFrom: jason perkins <jason@somebodydial911.com>\nSubject: [WD]: economist's cost savings [was: google's cost savings]\nMessage-ID: <EF41420E-94E5-11D6-A600-0003936A1B08@somebodydial911.com>\n\nOn Thursday, July 11, 2002, at 01:06 , Chris Lott wrote:\n\n> The best I can find for stats is:\n> http://www.search-engine-optimization-\n> strategies.net/search-engine-statistic\n> s/google-statistics.html -- with 150 million searches per day, saving \n> even a\n> fraction of a K in download time saves a whole lot of bandwidth. But I\n> suspect if that were really the reason for using short variable names, \n> they\n> would optimize in many other ways that they are not on their pages. The\n> short variable names make for a shorter URL, which is probably more \n> useful.\n\ni should've specified that the article that i was referring to had \ntalked about the javascript variable names, ie:\n\n<!--\nfunction sf(){document.f.q.focus();}\nfunction c(p){var f=document.f;if (f.action) {f.action = \n'http://'+p;f.submit();return false;}return true;}\n// -->\n\nwhere i was headed with this was that by using css instead of <font> \ntags on the economist website, they'd wind up saving significant amounts \nof bandwidth. kevin smith and i were chatting about this yesterday and \ncome up with the following: assuming that they had 12 million visitors \nper month (david w. said that if 1% of his users were on NN4x, that'd be \n120,000 page views per month.) and replacing all of the current font \ntags with an external style sheet with a size of appr 2k, then their \nmonthly cost savings in bandwidth is 120 gigs/month. that's without \ntightening up the js, using more css throughout the site, etc. this also \nignores caching of the external style sheet for repeat visitors.\n\nthe css replacement would work for nn 4 that had js enabled. those that \ndidn't could be redirected to a page that did make use of the font tag. \nbased on 10% of the economists visitors using nn 4 and appr 13% of the \ngeneral surfer not having js enabled, that would come out to 156k \nvisitors/month who were redirected to the <font> laden page which would \nbe 3 gigs that would still have to be transferred and lowering the \nsavings to 117 gigs/month.\n\ni don't know how much they're paying for bandwidth, or how much time it \nwould take to maintain two versions of the same page (i'm assuming that \nthe cms that's used there would make this easier to implement and \nmaintain), but figuring those out would give an idea of how much cost \nsavings can be achieved using this (limited) use of css. and it's \ninteresting that something as simple as this can still result in a 6% \ndecrease in the amount of bandwidth that you're using to xfer one page.\n\n\n- --\n:: jason perkins\n:: url -> www.somebodydial911.com\n\n\"A computer lets you make more mistakes faster than any invention in\nhuman history, with the possible exceptions of handguns and tequila.\"\n  -Mitch Ratcliffe, Technology Review, April 1992\n\n\n\n"
        },
        {
            "subject": "Fwd:  vki",
            "content": "Thought some of the people on this list would be interested in the \nfollowing.\n\nLach\n\n-------- Original Message --------\nSubject: [thelist] one more \"vkit\" plug for those who missed it\nDate: Thu, 11 Jul 2002 09:16:16 -0700 (PDT)\nFrom: \"Tom Dell'Aringa\" <pixelmech@yahoo.com>\nReply-To: thelist@lists.evolt.org\nTo: thelist@lists.evolt.org\n\nHey All,\n\nIn case you've missed the absolute flurry of activity, a new thriving\ngroup has been started based on a discussion that happened here\nmerely two days ago. The group is working on building some kind of\n\"kit\" or \"resource\" that will help people just like you go into your\nbosses office and make a strong business case for standards compliant\ncode.\n\nIts been crazy, we have a domain name already, people doing some\ncoding, lots of volunteers and tons of ideas, and its looking like\nits passed the idea stage and now into the real beginning stages of a\nworking idea. There are currently 59 members already in less than 2\ndays, many from this list, but many from others. So if you know of\npeople, or of other lists, let them know!\n\nHere is the statement on the yahoo! groups site - and the link to go\nthere.\n\nTom\n-----------------\nThis group is based on a small thread started on evolt.org which was\nin turn inspired from the article \"Sites bow to Microsoft's browser\nking\" on News.com, on July 8th 2002.\n\nThe idea spawned from the end of Tara Clevelands post:\n\nI think someone should make a kit for designers and developers to\ngive to their bosses. A kit that has all the arguments, studies, as\nmuch info as possible, for valid code, from a financial as well as\n\"it's good for the future of the web\" perspective aimed at company\nowners, managers, clients etc.\n\nHowever, no such kit exists. The purpose of the group is to see if\nsome kind of \"kit\" can be put together - that will validate the use\nof standards compliant code while showing all the benefits that such\nauthoring offers to clients, partners and business owners everywhere.\n\n\nWe are hoping that some of the leaders of the web community will step\nforward to help. If we don't gain some kind of heavyweight support,\nit will be very difficult to realize the goal. Whether that means as\nmuch as taking the lead, or as little as contributing text, code or\nideas, we need them.\n\nThe proposed paper would help the lone individual(s) who are faced\nwith stepping into a (bosses || clients || business owners) office\ntrying to quantify the reasons for writing good code that works in as\nmany browsers (if not all) as possible. And of course, the better\nthat code is written on the web in general, the better it will be for\neveryone involved.\n\nThe goal is to actually author the White Paper and to have it widely\navailable across the web. Any success of it will depend on the\nwillingness of many of you to give your personal time and effort.\nHowever, the benefits of such a paper should be well worth the\neffort.\n\nConsider this group Step 1; a fact-finding mission and discussion.\n----------------\n\nhttp://groups.yahoo.com/group/vkit/\n\n\n\n"
        },
        {
            "subject": "Re: Promoting standards  to Al (access: devices vs. people w/ disabilities",
            "content": "The major factor influencing any decision to \"use\" disability discrimination\nlegislation to promote web standards is that is the only way that the law\nbacks you! (if you see what I mean). Invoking regulation is a far more\npowerful way of getting people to agree with what you're saying because\nit's a sort of gotcha - don't do it and you're in trouble.\n\nThere's no such compulsion for adopting Web Standards per se.\n\n\n\n"
        },
        {
            "subject": "Cost Savings of Using CS",
            "content": "thought y'all might be interested in this, given the conversation\nthat's been going about regarding the positive economics of \nbusinesses adopting css. this is one of the best that i've seen,\nparticularly for large or highly-trafficed websites.\n\nit's taken from the web design list http://webdesign-L.com/\n\ncheers,\n\nanthony\n\nanthony baker  | aim: meadowlark07\nt: 415.441.6819  | f: 415.276.9388 \nmailto:anthony@designforpeople.org \n\n\n------------------------------------------------------------------\n\n\nDate: Thu, 11 Jul 2002 10:50:33 -0500\nFrom: jason perkins <jason@somebodydial911.com>\nSubject: [WD]: economist's cost savings [was: google's cost savings]\nMessage-ID: <EF41420E-94E5-11D6-A600-0003936A1B08@somebodydial911.com>\n\nOn Thursday, July 11, 2002, at 01:06 , Chris Lott wrote:\n\n> The best I can find for stats is:\n> http://www.search-engine-optimization-\n> strategies.net/search-engine-statistic\n> s/google-statistics.html -- with 150 million searches per day, saving \n> even a\n> fraction of a K in download time saves a whole lot of bandwidth. But I\n> suspect if that were really the reason for using short variable names, \n> they\n> would optimize in many other ways that they are not on their pages. The\n> short variable names make for a shorter URL, which is probably more \n> useful.\n\ni should've specified that the article that i was referring to had \ntalked about the javascript variable names, ie:\n\n<!--\nfunction sf(){document.f.q.focus();}\nfunction c(p){var f=document.f;if (f.action) {f.action = \n'http://'+p;f.submit();return false;}return true;}\n// -->\n\nwhere i was headed with this was that by using css instead of <font> \ntags on the economist website, they'd wind up saving significant amounts \nof bandwidth. kevin smith and i were chatting about this yesterday and \ncome up with the following: assuming that they had 12 million visitors \nper month (david w. said that if 1% of his users were on NN4x, that'd be \n120,000 page views per month.) and replacing all of the current font \ntags with an external style sheet with a size of appr 2k, then their \nmonthly cost savings in bandwidth is 120 gigs/month. that's without \ntightening up the js, using more css throughout the site, etc. this also \nignores caching of the external style sheet for repeat visitors.\n\nthe css replacement would work for nn 4 that had js enabled. those that \ndidn't could be redirected to a page that did make use of the font tag. \nbased on 10% of the economists visitors using nn 4 and appr 13% of the \ngeneral surfer not having js enabled, that would come out to 156k \nvisitors/month who were redirected to the <font> laden page which would \nbe 3 gigs that would still have to be transferred and lowering the \nsavings to 117 gigs/month.\n\ni don't know how much they're paying for bandwidth, or how much time it \nwould take to maintain two versions of the same page (i'm assuming that \nthe cms that's used there would make this easier to implement and \nmaintain), but figuring those out would give an idea of how much cost \nsavings can be achieved using this (limited) use of css. and it's \ninteresting that something as simple as this can still result in a 6% \ndecrease in the amount of bandwidth that you're using to xfer one page.\n\n\n- --\n:: jason perkins\n:: url -> www.somebodydial911.com\n\n\"A computer lets you make more mistakes faster than any invention in\nhuman history, with the possible exceptions of handguns and tequila.\"\n  -Mitch Ratcliffe, Technology Review, April 1992\n\n\n\n"
        },
        {
            "subject": "Cost of development",
            "content": "Hey one thing that crossed my mind was this...\n\nLast year I was developing solutions for Rich Media advertising. I was looking\ninto TopLayer and other things. The thing I ran into time and time again is that\nthese solutions don't work on Macintosh, and with limited results in anything\nOTHER than IE on Windows.\n\nWhen I querried companies about this they all came back with the same thing\n\nWhy should we spend money developing a solution that works on all systems that\ncosts XXXXX when we can get one that works on 95% (IE users) of web users for\nhalf the price.\n\nIs this the same attitude designers have to web Standards? Why spend extra time\nmaking sure we've all the tweaks, tricks etc built into our sites when we can\nbuild it and know it works in 95% of our visitors.\n\nPesonally thats 5% I don't want to loose ... but companies I've talked to ..\ndon't seem to care\n\nK.\n\nKeran McKenzie\nhttp://pnut.studiowhiz.com (thoughts)\nhttp://www.studiowhiz.com (Web Resources)\nhttp://www.flashcomponent.com (MX Components)\nhttp://www.kiwi-interactive.com (Web Dev Company)\n\n\n\n"
        },
        {
            "subject": "Re: Cost of development",
            "content": "Yes but - see below.\n\n>  from:    Keran McKenzie <keran@kiwi-interactive.com>\n> \n> Pesonally thats 5% I don't want to loose ... but companies I've talked to ..\n> don't seem to care\n> \n\nI'm using the 'alternative browser' argument - the Web TV, the mobile device,\nthe generic term \"Internet Device\" to alert people that there's more to life\nthan just computers (Really???)\n\nAnd that these devices are going to become more popular and will not be just\nfor the geeks and the gadgeters. Otherwise why would companies be \ninvesting in developing them?\n\nThere's also the language of the Web TV that seems to be standards based\n- article at\nhttp://www.evolt.org/article/DVB_HTML_a_new_standard_Part_1/25/33143/index.html\n\nRegards\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Another Language Developmen",
            "content": "This is for interactive broadcasting - article\nhttp://www.evolt.org/article/DVB_HTML_a_new_standard_Part_1/25/33143/index.html\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Introductio",
            "content": "  Hey all,\n\n   My name is Rick Smorawski, currently working as a Unix System \nAdministrator for an ISP.  I am debating a move to website developement \narea.  I have extensive 'off the record' experience with Perl, PHP, \nhtml, xhtml and some dhtml via javascript & dom.   Being a close mozilla \nfollower for the last 2 years (M8?), as well as an MS hater, I have a \nvested interest in seeing established standards provail over De-Facto \nstandards.  I'm am currently working on an XML/XSLT based  content \nmanagement system (for the practice, mostly).\n\nRegards\nRick\n\n\n\n"
        },
        {
            "subject": "RE: Cost of development? (and Flash on mobile devices",
            "content": "Keran asked whether Flash is going to become a de-facto standard in other \ninternet devices - seems to be heading that way from this press release.\n\nhttp://www.opera.com/pressreleases/en/2002/06/20020617.html\n\nWhat's happening with SVG?\n\nJohn\n\nAt 22:17 12/07/02 +1200, Keran wrote:\n>\n>\n>Personally I see content delivery for these mobile devices moving to Flash.\n>Does Flash have the power to become the default content delivery system for\n>\"alternative browsers?\"\n\n\n\nJohn and Sandy Colby\nhttp://www.colbyweb.co.uk\nGeevor Mine http://www.geevor.com\n\nNo electrons were harmed in the creation, transmission or reading of this \nemail. However, many were excited and some may well have enjoyed the experience.\n\n\n\n"
        },
        {
            "subject": "Re: Cost of development? (and Flash on mobile devices",
            "content": "On Sat, Jul 13, 2002 at 10:02:38PM +0100, John Colby wrote:\n> Keran asked whether Flash is going to become a de-facto standard in other \n> internet devices - seems to be heading that way from this press release.\n> \n> http://www.opera.com/pressreleases/en/2002/06/20020617.html\n> \n> What's happening with SVG?\n\nDean Jackson wrote an excellent article on the future (and current\ndevelopments) of SVG:\nhttp://www.oreillynet.com/pub/a/javascript/2002/06/06/svg_future.html \n\nOn the second page, there is a section titled 'The mobile community\nhas chosen SVG'.\n\ncheers,\n-steph\nrandom web dudette\nhttp://unadorned.org/\n\n\n\n"
        },
        {
            "subject": "RNIB Accessibility tour  for UK evangelist",
            "content": "9 free events around the U.K. sponsored by the Royal National Institute for the Blind.\n\nhttp://www.rnib.org.uk/digital/adobesyst.htm\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Video Broadcasting Standards Article  part ",
            "content": "The second part of the DVB HTML article is at:\nhttp://www.evolt.org/article/DVB_HTML_a_new_standard_Part_2/17/33145/index.html\n\n\n\n"
        },
        {
            "subject": "maccaws  another group devoted to promoting web standard",
            "content": "All,\n\nIt's been mentioned here before (in the post titled \"fdw:vkit\") but for\nthose of you who aren't already involved, there is a group that has been\nformed, that is paralleling a lot of what we are doing here. The group is\ncalled maccaws (\"making a commercial case for adopting web standards\").\nThis group is trying to come up with all the logical arguments for \"why web\nstandards\" and creating resources (white papers, etc) that explain the\narguments. There is a lot of complimentary overlap being done in terms of\ntrying to come up with arguments for using standards. \n\nAlthough the group started temporarily as a yahoo-egroups\n(http://groups.yahoo.com/group/vkit/), it's just a launching pad. The group\nnow has a web site www.maccaws.com and a wiki http://www.maccaws.com/wiki/\nand plans are to eventually host the mailing list off that site.\n\nYou should seriously check it out - I read the fdw:vkit on this list, went\nand investigated, and now I'm in both groups.\n\n\n\nJeff Moyes\nMultimedia Programmer\nAllen Communication Learning Services, \na division of Mentergy U.S.A.\nph: 801.799.7231\nfax: 801.537.7805\njeffm@mentergy.com\n\n\n\n"
        },
        {
            "subject": "Re: maccaws  another group devoted to promoting web standard",
            "content": "As Jeff said, paralleling, not repeating - its so good that there are so many\npeople adopting standards that its no longer a lone battle for us working in\nisolation. And for my money the more web standards groups there are\n(within reason) the more likely there will be some effect.\n\nJohn\n\n>  from:    Jeff Moyes <JeffM@mentergy.com>\n\n> All,\n> \n> . . .  a group that has been\n> formed, that is paralleling a lot of what we are doing here. The group is\n> called maccaws (\"making a commercial case for adopting web standards\").\n> . . . .\n\n> You should seriously check it out - I read the fdw:vkit on this list, went\n> and investigated, and now I'm in both groups.\n>  \n\n\n\n"
        },
        {
            "subject": "Web Standards  example",
            "content": " \n  My name is Greg and I work for a pharmaceutical information company in a\ndepartment called Change Management. It is my job to approve changes to code\nin  production which now includes heavy Web site activity. I have been\nwriting standards for directory structures, 3rd party software and much\nmore.... But am desperately seeking other business examples of such\nstandards. I'm looking to get examples of how other companies deal with the\nDevelopment, Integration, User Acceptance then Production life cycle and how\nthey control, protect and manage code as it moves thru these life cycles\ninto a true production environment. How do they setup NT platforms to\nsupport multiple web efforts, how do they handle 24/7 availability while\nstill allowing software upgrades, patches, etc to these platforms.... And\nmuch more. Any direction or info you can provide would be very appreciated -\nthanks.\n \nGregory Tarta\nChange Management\n \n** Please note my extension has now changed from  610-834-5218 to\n610-260-6634 **\n \n\n\n\n"
        },
        {
            "subject": "Lycos Europe goes XHTML and CSS for layou",
            "content": "This is excellent.\n\nMost of the Lycos Europe sites will shortly be moving to a new design, which\nwill validate to XHTML 1.0 Transitional, and use CSS for layout.\n\nNetscape 4 users will get a plain-text version, with no formatting.\n\nThe new design has already gone live on the German site at http://www.lycos.de/,\nsadly this is not the XHTML/CSS version due to heavy NS4 use there. All other\nsites will be getting a version similar to http://jscript.dk/lycos/2/ - and just\nlook at\n<http://validator.w3.org/check?uri=http%3A%2F%2Fjscript.dk%2Flycos%2F2%2F> :)\n\nI'd like to congratulate the Lycos developers for this, including Thor Larholm\nwho I know has pushed for standards compliance and a tableless layout.\n\nPlease note: I have nothing to do with Lycos. Just reporting good news.\n\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "'silver surfers' in the U",
            "content": "important for UK companies accessibility policies:\n\n http://news.bbc.co.uk/hi/english/sci/tech/newsid_2135000/2135574.stm\n\n40% of UK adults are online.\nwomen almost 50% of those.\n70% consider the net 'essential'.\n\n17% are 'silver surfers'. The report also revealed the increasing importance\nof the silver surfer. The number of elderly online grew by more than 40%\nover the past year.\n\nbruce lawson\nbrand manager\nwww.glasshaus.com\n\nread \"Dynamic Dreamweaver MX\" - dreamweaver for xhtml, standards compliance\nand accessibility\nhttp://www.glasshaus.com/bookInfo.asp?bookId=63\n\n\n\n"
        },
        {
            "subject": "Standards Freshnes",
            "content": "In seeking to modernise my development knowledge, I'll be reading a bunch\nof XHTML and CSS books over the summer.  I noticed that a good deal of\nthese books (like Eric Meyer's impressive \"Cascading Style Sheets: The\nDefinitive Guide\") are a few years old, which seems to be at odds with my\nefforts to get *really* up to date.\n\nIn the past two years, have standards changed in any way as to make some of\nthese volumes incomplete or obsolete?  At what mean point do standards lose\ntheir timeliness?  For example, a good book on HTML 4.0 is still useful,\nbut I can't consider it modern or timely.\n\nLastly, it terms of good general/technical info books for today's XHTML/CSS\nstandards (and real-world browser environment), do my esteemed colleagues\nhave any recommendations?\n\nHopefully,\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "At 09:32 AM 7/18/2002 -0700, Joseph wrote:\n>Lastly, it terms of good general/technical info books for today's XHTML/CSS\n>standards (and real-world browser environment), do my esteemed colleagues\n>have any recommendations?\n\nI agree that there's not a lot of books on the subject right now - well, at \nleast that I know of. A quick search on Amazon for \"web standards\" turned \nup diddly. But funny you should ask today; by coincidence, Zeldman just \nposted a rave review of a new book on CSS. It's by Eric Meyer, the author \nyou mentioned in your post, I guess it's his new one.\n\nhttp://www.zeldman.com/\n\nhttp://www.amazon.com/exec/obidos/ASIN/073571245X/ref=ase_jeffreyzeldmanprA/002-1048969-8576811\n\nZeldman himself is publishing a book on web standards that's not out yet, \nsee his July 15th post. I love how Amazon can let you order books that \naren't out yet, though, and I hope we end up being able to do that with \nthis one as well. I've already done that for a couple of books that I just \nHAD to have, like Personal Web Sites by Joe Shepter. On the \ninspiration-ometer, it's right up there with Curt Cloninger's book.\n\n<rant type=\"mild\">\nNot to get sidetracked, but there's a lot of how-to books out there for the \ntechnical issues of site development and not enough books that actually \nsurvey the scene and see what everybody's up to. I've heard opinions on how \nthat's inherently hard to do, since the web changes daily, but so does art, \nyet there's a ton of art books chronicling how people are innovating and \ntracking the evolution of different trends. That's when I'll know \nstandards-compliant sites are finally mainstream - when there's more than \njust online and printed tutorials, but cool sites with various styles to \ncheck out and draw inspiration from. At this point, all XHTML/CSS sites \nkind of have a common feel to them, as explained more eloquently in this \narticle: http://www.chunkysoup.net/opinion/boringcss/\n</rant>\n\nEnough whining! A great step towards pushing the standards envelope is the \nLife Is But A Dream competition for XHTML design:\n\nhttp://333creativecentral.com/contest/\n\nCheck it out - the deadline hasn't passed yet, Oct.3.\n\nAl\n\n\n\n"
        },
        {
            "subject": "jpeg  a patent concer",
            "content": "see http://www.theregister.co.uk/content/4/26272.html\n\nThe patent referred to is US 4,698672, which does not appear on the\nW3C page at http://www.w3.org/Graphics/JPEG/AnnexL.html\n\nI know nothing of this - this is a heads up for those who do - can\nsomeone please explain?\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "At 12:27 PM -0700 7/18/02, Al Abut wrote:\n>funny you should ask today; by coincidence, Zeldman just posted a rave\n>review of a new book on CSS. It's by Eric Meyer, the author you mentioned\n>in your post, I guess it's his new one.\n\nThanks for the tip...  I was already thinking about that one, but had\nconcerns about the scope of the articles.  If Zeldman learned something, it\nmust be wide!  I think a visit to Amazon is in order.\n\n>Not to get sidetracked, but there's a lot of how-to books out there for\n>the technical issues of site development and not enough books that\n>actually survey the scene and see what everybody's up to.\n\nI agree, and have found a possible match.  Edited by our fellow list-mate\nMolly Holzschlag (hi Molly!), \"Usability: The Site Speaks for Itself\" is a\nreal-world exploration of some big name, big audience sites (eBay,\nmetafilter, BBC News, Economist...).  The usability aspects of each site is\ndescribed in detail by the actual developers, so you're learning from the\nhorse's mouth as it were.\n\nhttp://www.amazon.com/exec/obidos/ASIN/1904151035/josephmclean\n(Note shameless affiliation)\n\nI haven't read it yet (just ordered), but the reviews are universally\nfive-star.\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "Hey Joseph, thanks for the hat tip! :)   ALL: I would like to unabashedly\nrecommend my own book, Special Edition Using HTML and XHTML.  It came out in\nMay, from Que.  For some reason, it's NOT getting a lot of attention.  It is\nnot esoteric, nor is it to beginnerish.  It's geared right at the\nprofessional who is moving toward or working with standards-compliant sites.\nPerhaps the title is confusing to some readers, but obviously won't be for\nthe readers here on this list.\n\nhttp://www.amazon.com/exec/obidos/ASIN/0789727315/qid=1027030874/sr=8-3/ref=\nsr_8_3/002-7193928-4777623\n\nI wrote it, with Steve Champeon as Tech Editor.  I had a lot of assistance\nfrom various WaSP members during the process too, and other\nstandards-oriented people with concern for the future of markup.\n\nIf you'd like to review it for publication let me know and I'll see about\ngetting you a review copy ASAP.\n\nMolly\nMolly E. Holzschlag\nauthor + instructor + web designer\nhttp://www.molly.com/\n\n----- Original Message -----\nFrom: \"Joseph McLean\" <joseph@secondflux.com>\nTo: \"Al Abut\" <aabut@biomail.ucsd.edu>\nCc: <public-evangelist@w3.org>\nSent: Thursday, July 18, 2002 2:23 PM\nSubject: Re: Standards Freshness\n\n\n>\n> At 12:27 PM -0700 7/18/02, Al Abut wrote:\n> >funny you should ask today; by coincidence, Zeldman just posted a rave\n> >review of a new book on CSS. It's by Eric Meyer, the author you mentioned\n> >in your post, I guess it's his new one.\n>\n> Thanks for the tip...  I was already thinking about that one, but had\n> concerns about the scope of the articles.  If Zeldman learned something,\nit\n> must be wide!  I think a visit to Amazon is in order.\n>\n> >Not to get sidetracked, but there's a lot of how-to books out there for\n> >the technical issues of site development and not enough books that\n> >actually survey the scene and see what everybody's up to.\n>\n> I agree, and have found a possible match.  Edited by our fellow list-mate\n> Molly Holzschlag (hi Molly!), \"Usability: The Site Speaks for Itself\" is a\n> real-world exploration of some big name, big audience sites (eBay,\n> metafilter, BBC News, Economist...).  The usability aspects of each site\nis\n> described in detail by the actual developers, so you're learning from the\n> horse's mouth as it were.\n>\n> http://www.amazon.com/exec/obidos/ASIN/1904151035/josephmclean\n> (Note shameless affiliation)\n>\n> I haven't read it yet (just ordered), but the reviews are universally\n> five-star.\n>\n> -Joseph\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "At 02:23 PM 7/18/2002 -0700, Joseph McLean wrote:\n\n>Edited by our fellow list-mate Molly Holzschlag (hi Molly!), \"Usability: \n>The Site Speaks for Itself\" is a real-world exploration of some big name, \n>big audience sites...\n>\n>I haven't read it yet (just ordered), but the reviews are universally \n>five-star.\n\nI'm such a schmuck... I have that book, it rocks and I totally devoured it \nrecently! I guess it slipped my mind because I was thinking of books on web \nstandards and not usability, although the two obviously have some \noverlapping areas. I would love to read a web standards book with that \nformat: lots of working examples, not just theory; interviews with the \ncreators, hearing about their trials and tribulations.\n\nAlso, I totally agree with Molly's approach to hear the site goals from the \nhorse's mouth, not from marketing execs or third-party usability \nguns-for-hire, and that's also the strength of the Joe Shepter and Curt \nCloninger books, albeit with a more artistic bent. After all, what's more \ninteresting - listening to some museum tour guide drone on and on about \npieces they didn't create, or having a conversation with the artist and \nlistening to their inspirations, goals and thoughts? Well, depends on the \nartist, but personally, I'd rather take my chances with them.\n\nI guess the first step would be to get a gallery of interesting \nstandards-compliant websites, along the lines of the Minimalist Web \nProject: http://www.textbased.com/~minimalist/\n\nOk, another little rant here about the term HTMinimaList - it seems to have \nvery different meanings to people and a bit of clarification is in order. I \nread an article discussing the difference between the styles of \nsimple-and-easy-to-use and minimalist-and-not-so-easy-to-use sites (sorry, \nforgot the link! Anyone know?) and how both styles are often lumped under \nHTMinimaList, but there's a third category that I think is woefully \noverlooked: the style of sites that are bandwidth-friendly, have minimal \namounts of HTML and still manage to look good. Too many sites are a bloated \nmess with regards to file-size, yet are lumped under the terms of \"simple\" \nand \"minimalist\" just because of the UI. There's a reason why the \nHTMinimaList chapter in Curt's book discussed not only the clean designs of \n37signals, but the efforts of the 5K design competition ( the5k.org ) to \nget developers to think creatively about bandwidth limitations.\n\nWhew! Am I getting on anyone's nerves yet? I'll keep trying...\n\nAl Abut\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "At 03:26 PM 7/18/2002 -0700, Molly E. Holzschlag wrote:\n\n>ALL: I would like to unabashedly recommend my own book, Special Edition \n>Using HTML and XHTML...\n\nWhoops, I posted just as Molly wrote in and offered up her book to appease \nthe masses!\n\nSo that's how it works, huh? I wish for what I want to see in a book and it \nappears in a matter of minutes. Cool, this web developer thing's easy...\n\nAl\n\n\n\n"
        },
        {
            "subject": "[w3evang] Access Key visualizatio",
            "content": "Hey lot, I was tinkering around a bit with the (X)HTML accesskey \nattribute and CSS2 generated content, in order to visualize what \nelements have which access key. See the URL if that description sucked - \nit's late, I'm tired.\n\nhttp://lumumba.luc.ac.be/~j.moesen/a11y/accesskeys.html\n\nFeedback more than welcome.\n\n   --Jan!\n\n\n\n"
        },
        {
            "subject": "RE: Standards Freshnes",
            "content": "Joseph asked:\n\nLastly, it terms of good general/technical info books for \n> today's XHTML/CSS\n> standards (and real-world browser environment), do my \n> esteemed colleagues\n> have any recommendations?\n\nthe glasshaus CSS book (Steve Champeon, Owen Briggs, Eric Costello, Matt\nPatterson) deals with the real-world x-browser issues of CSS, and is being\nbundled with Usability: The Site Speaks For Itself which Molly Holzschlag\nand I wrote. \n\nhttp://www.amazon.com/exec/obidos/ASIN/1904151043/\n\nDisclaimer: I'm brand manager of glasshaus, so am not disinterested here.\n\n\nBruce Lawson\nbrand manager\nwww.glasshaus.com\n\nsee \"Dreamweaver MX: PHP Web Development\"\nhttp://www.glasshaus.com/bookInfo.asp?bookId=61\n\nsee \"Dynamic Dreamweaver MX\"\n\nhttp://www.glasshaus.com/bookInfo.asp?bookId=63\n\nThe sender cannot accept any liability for any loss or damage sustained as a\nresult of software viruses. It is your responsibility to carry out such\nvirus checking as is necessary before opening any attachment.\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "All this book talk--we should start a list of books that people\nlike/recommend for standards-related topics.\n\nKarl, anyone else--would this be something we can coordinate and place\nonline on the W3C somewhere, something like \"books recommended by interested\nparties\" -- wouldn't have to be a W3C recommendation per se, but a resource\nto external sources that the W3C can provide?\n\n--Molly\nMolly E. Holzschlag\nauthor + instructor + web designer\nhttp://www.molly.com/\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "Hi Molly,\n\nThat sounds like a great idea, just ordered your book by the way, with this and Eric's new CSS book\nit has been an exicting week.\n\nRegards\nMark\n\n------------------------------------------------------------------------------------\nMark Fletcher\nWeb Educator | Master VTC Author\nTeam Macromedia Volunteer for Dreamweaver\nwww.macromedia.com/support/forums/team_macromedia\n------------------------------------------------------------------------------------\nGet started with Dreamweaver MX and ColdFusion MX today!\nhttp://www.macromedia.com/software/coldfusion/resources/get_started/tutorials/\n------------------------------------------------------------------------------------\nAnnouncing Macromedia MX\nhttp://www.macromedia.com/software/trial/\n------------------------------------------------------------------------------------\n\n\n\n----- Original Message -----\nFrom: \"Molly E. Holzschlag\" <molly@Molly.COM>\nTo: \"Bruce Lawson\" <brucel@glasshaus.com>; <public-evangelist@w3.org>\nSent: Friday, July 19, 2002 11:01 AM\nSubject: Re: Standards Freshness\n\n\n>\n> All this book talk--we should start a list of books that people\n> like/recommend for standards-related topics.\n>\n> Karl, anyone else--would this be something we can coordinate and place\n> online on the W3C somewhere, something like \"books recommended by interested\n> parties\" -- wouldn't have to be a W3C recommendation per se, but a resource\n> to external sources that the W3C can provide?\n>\n> --Molly\n> Molly E. Holzschlag\n> author + instructor + web designer\n> http://www.molly.com/\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "Pardon me, but I'm not sure this is a good idea for the following reasons:\n1. It generates yet another list that people may need to monitor and manage.\n2. It is \"context free\" in the sense that it doesn't seem to serve any \npurpose other than bibliographic unless...\n3. What does \"interested parties\" mean? We've recently seen some \nshameless and not so shameless (self) promotion and adulation consuming \nband width on this list; no doubt well deserved, but does it take up any \nless bandwidth on its own list?\n\nMaybe before one runs off \"getting organized\" there might be a little \nopen air to create an opportunity for comment and concensus?\n\nRegards.                 ...edN\n\nMolly E. Holzschlag wrote:\n> All this book talk--we should start a list of books that people\n> like/recommend for standards-related topics.\n> \n> Karl, anyone else--would this be something we can coordinate and place\n> online on the W3C somewhere, something like \"books recommended by interested\n> parties\" -- wouldn't have to be a W3C recommendation per se, but a resource\n> to external sources that the W3C can provide?\n> \n> --Molly\n> Molly E. Holzschlag\n> author + instructor + web designer\n> http://www.molly.com/\n> .\n> \n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "Ed,\n\nI apologize if I was unclear.  I don't mean creating a book-oriented email\nlist. I mean creating a web page where a list of standards-related books\nrecommended by interested developers and designers can be made available for\nothers seeking education in this area.\n\nHope this clarifies,\nMolly\n\nMolly E. Holzschlag\nauthor + instructor + web designer\nhttp://www.molly.com/\n\n\n\n"
        },
        {
            "subject": "RE: Standards Freshnes",
            "content": "> I apologize if I was unclear.  I don't mean creating a\n> book-oriented email\n> list. I mean creating a web page where a list of\n> standards-related books\n> recommended by interested developers and designers can be\n> made available for\n> others seeking education in this area.\n>\n> Hope this clarifies,\n> Molly\n\nMolly,\n\nHope you don't mind too much, but I pinched your idea for MACCAWS and\nwe're starting such a list on our Wiki (http://www.maccaws.org/wiki/ -\nstill public, soon to become private).\n\nYou're welcome to contribute there.\n\nThanks\n\nTony\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "From: \"Joseph McLean\" <joseph@secondflux.com>\n> I agree, and have found a possible match.  Edited by our fellow list-mate\n> Molly Holzschlag (hi Molly!), \"Usability: The Site Speaks for Itself\" is a\n> real-world exploration of some big name, big audience sites\n...\n> I haven't read it yet (just ordered), but the reviews are universally\n> five-star.\n\nI'm currently reading it, along with rereading Jakob Nielsen's \"Website\nUsability\" -- just to get a balanced look at website usability. IMO, it is a\npity the introduction is a collection of straw-man arguments against\nNielsen's contribution to usability (sorry Molly), but there seems to be a\nlot of good content in there -- I've only partially read the BBC bit at the\nmoment, which includes a number of fixed-size arguments based on monitor\nsizes, which really echo the print-biased way of thinking.\n\nNielsen's second book \"Homepage Usability\" is a useful analysis of the home\npages of the top 50 websites (in a variety of categories), with a selection\nof very useful, well thought-out suggestions on improving usability.\n\n\n\n"
        },
        {
            "subject": "[Summary] What next",
            "content": "Hi there.\n\nThis is the first [Summary] message. Fortunately it's not intended\nto re-state the scope of this list, which has been well respected\nso far, congratulations to all. Unless it proves itself useless, or\nannoying, we'll try to issue such [Summary] messages every once in a\nwhile, to summarize discussion (can be useful for new participants) and\nthe main points stated, focus on some topics, and eventually prepare\ndeliverables.\n\nThis is the first [Summary] message, so it will be special. Instead of\nproposing you a summary and/or orientations (which I shall do later), \nI'll simply ask \"what next?\".\n\nThis should be a thrilling question, but it could be our nemesis :\nexcluding \"intro\" messages (very useful and interesting to find out what\nare the context, goals and expectations for each of us), a few book\npromotion, and a call for review of a document under work, we already\nhad a few rounds of discussions. Some of them hold their own value,\nothers will be wasted time (or mere re-doing the world again and again)\nif they're not followed by action, or turned into \"real\" documents.\n\nHere are, therefore, a few proposed deliverables for this group. These\ndeliverables can be done and hosted here (i.e W3C), or elsewhere\n(newborn maccaws group[1] comes to mind, but there are many other site\ngathering such documents), not a problem as long as (John Colby told\nthis very well) we parallelize but don't step on each others' toes.\n\n****************\n\nFirst, lists. I must say I don't fancy lists : they're hard to maintain\nup-to-date, hard to make really objective - not just advertisement -,\netc. Plus, we're at W3C, with vendor neutrality as a core principle,\nthat could make it trickier...\n\nLists ideas which have been floating in the air:\n- standard compliant \"big\" websites\n- web standards books and reviews [2]\n- \"resources\", standards evangelism websites\n\nWe could also, and that's an orientation I deem worthwile, turn our\ndiscussion into \"white-paper\" style documents. reading through the\ndiscussion threads, I see a few candidates already (I shall prepare\nsummaries of those threads later):\n\n- WYSIWYG or multi-platform, why standards can help achieve both\n- metrics and cost/benefits business cases\n- defining metrics (framework)\n- cost/benefits of using valid HTML\n- cost/benefit of using CSS for style\n- others?\n- answering misconceptions about web standards\n(Karl Dubost from W3C QA, in an article to be released, answers, with\na systematic yet not pedantic approach, a few misconceptions; this\ncould/should be extended)\n\nThird idea is to contact and educate people. \n- contact and educate web agencies\n (We - W3C QA - are already working on a \"what you should propose \n to your clients\" note)\n- contact and educate companies\n (We - W3C QA - are already working on a \"what you should ask your\n web design agency/web department)\n- contact and educate teachers and the education world\n- contact and educate governments\n\nBut for all of those, again, we need more than good will and enthusiasm\nto convince, we need material, resources, proofs, figures. This may be\nyet another good thing to work on here.\n\n****************\n\nI suggest we pick a few work orientations among those, and try to focus\non them and try to produce tangible bits out of our discussions.\n\n\n[1] http://www.maccaws.org/\n[2] http://www.maccaws.com/wiki/?page=BooksList\n\nYours, \n\nOlivier\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Standard Fixing Softwar",
            "content": "There are many free and open source softwares to create websites, \nonly a few of them, respect the basic requirements of Web Standards \nlike having a DOCTYPE, having accessibility features, etc.\n\nI think it would be worthwhile to help people to fix this software, \nso to participate to the development or at least to send patch to \ntheir authors to help them to have better products.\n\nSomething like Mark Pilgrim [1] did in his Dive Into Accessibility \n[2] is very useful because for each software, he comes with a \npractical solution to implement in a few weblog products.\n\nWhat Mark did could be extended to other products like having binding \nto his own 30 days. For example, I want to apply the recipes of Mark \nto the Product AcmeLog, what must I do?\n\nAnother thing is to try to push people from the list who have \ntechnical background to make a report on a particular software and \nhelp the developper to fix it. Fixing the softwares (and open source \nones) will help to fix the web.\n\nThe owners of the code have all to benefit from that kind of \nparticipation. The problem is to choose which one to start with. [3]\n\n\n\n[1] http://diveintomark.org/\n[2] http://diveintoaccessibility.org/\n[3] http://www.la-grange.net/cms\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: [Summary] What next",
            "content": "At 5:45 PM +0900 7/23/02, Olivier Thereaux wrote:\n>I must say I don't fancy lists : they're hard to maintain\n>up-to-date, hard to make really objective\n\nI agree that objectivity is hard to establish with any list of resources.\nStill, the snappy appeal of a numbered list -- the literary equivalent of a\nsoundbyte -- should not be underrated.  It gets immediate attention, and if\nthe list is handled properly, it can be an enormously popular/useful\nresource.\n\nPerhaps we can address this \"objectivity\" challenge, somewhere, with a\ndistributed approach to rating the books (and online resources).  Sort of\nlike the Amazon approach, but more closely targeted at the specific\nindustry we're in.  I for one would love to see a list of books with\nratings distilled from the votes of my peers -- that is to say, the people\nwho care about good website design.\n\nI live in a remote community, where I must purchase books sight-unseen.  It\nwould be nice to know the aggregate opinions of everyone here, and on our\nsister lists -- if I follow all the good suggestions so far, Amazon will\neat my paycheque.\n\nI'll follow this with the typical Overworked Webmaster's Pledge: \"If no one\nhas done this, and no one is planning to, I'll do it, in a while\".\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Re: [Summary] What next",
            "content": "On Tue, Jul 23, 2002 at 05:45:28PM +0900, Olivier Thereaux wrote:\n> \n> Third idea is to contact and educate people. \n> - contact and educate web agencies\n>  (We - W3C QA - are already working on a \"what you should propose \n>  to your clients\" note)\n> - contact and educate companies\n>  (We - W3C QA - are already working on a \"what you should ask your\n>  web design agency/web department)\n> - contact and educate teachers and the education world\n> - contact and educate governments\n \n\nIt would be worthwhile to find out what kind of materials will best\nsuit teachers and people who are educating the next generation of Web\ndevelopers/designers.  Different Web courses are written for target\naudiences - courses which cater for websites for small businesses, \npersonal websites, technical web development, and so forth. Therefore,\nmaterials we produce might have to be targeted, or somehow 'rehashable'.\n\nWe would have to give sound explanations on the need to teach standards.\n\nPerhaps a kind of framework for this can be presented at local Web\nconferences which are more academic, so that educators can spread the\nword between themselves?\n\nThoughts?\n\ncheers,\n-steph\nrandom web dudette\n\n\n\n"
        },
        {
            "subject": "RE: costbenefit analysis of standards complianc",
            "content": "I just found this article while poking around on the web.  I think it takes\na step in the right direction regarding how to discuss the cost of\ndeveloping non standards-compliant code with clients.\n \nhttp://www.pirated-sites.com/essays/browser-specs.html\n\n\n\n"
        },
        {
            "subject": "Web Standards Foru",
            "content": "Hi there\n\nSome of you may know I run www.studiowhiz.com a online resource site.\nOne aspect of our site is a forum system, which is growing slowly.\n\nWell I've expanded our forums to include an area for Web Standards, to\nhelp promote and push this important area.\n\nhttp://www.studiowhiz.com/_boards/  you'll see Web Standards number 3 on\nthe list.\n\nPlease feel free to join and post ... I'm looking for some \"moderators\"\nto help with this area too, if anyone is keen.\n\nThanks all\n\nKeran McKenzie\nwww.studiowhiz.com\n\n\n\n"
        },
        {
            "subject": "Re: Standards Freshnes",
            "content": "At 9:32 -0700 7/18/02, Joseph McLean wrote:\n\n>In seeking to modernise my development knowledge, I'll be reading a bunch\n>of XHTML and CSS books over the summer.  I noticed that a good deal of\n>these books (like Eric Meyer's impressive \"Cascading Style Sheets: The\n>Definitive Guide\") are a few years old, which seems to be at odds with my\n>efforts to get *really* up to date.\n\n    Glad you liked the book!  I hope my new tome[1] is as welcome, \neven though it is targeted at a very different audience.  Sorry it's \ntaken me so long to respond to your post, but travel and a massive \ne-mail backlog prevented me from looking at this list's folder until \nthis morning.\n    I wanted to address the point you raise from my personal point of \nview, in the hopes it helps illuminate a small corner of the whole \nstandards situation.  Even though CSS:TDG came out in spring 2000 \n(just over two years ago), I've also fretted a bit about whether the \nbook has passed its \"use-by\" date.  So why hasn't it been updated?\n    The problem is that expanding the book to cover CSS2, as I would \npretty obviously have to do, means I'd have to write a lot of \"this \nis how things should work, but no browser gets this right yet\" or \n\"only one browser will handle this, the rest will gack up a \nhairball.\"  In a book like CSS:TDG[2], which is concerned as much \nwith theory as practice, I vastly prefer to cover theory that can \nactually be put into practice. Who wants to read a 20-page chapter on \ngenerated content when it isn't fully supported by any known \nbrowser[3]?  We already have the CSS2 specification for that, and it \ndoesn't cost USD$34.99 plus tax.\n    That's a big factor in deciding when a second edition might hit \nthe shelves. The release of IE6/Win actually delayed this process, \nbecause it added so little in the way of new and correct CSS support. \nYes, it added \"standards\" mode, which backfilled a number of bugs, \nand that's important.  But almost nothing in the way of support for \nnew CSS2 stuff was added.\n    So there's an unfortunate chicken-and-egg cycle here.  Until \nbrowsers move support forward, I'm less likely to write about using \nCSS2-- but unless authors like me write about CSS2 and push authors \nto try it out, there is a lot less incentive for browsers to expand \ntheir CSS support.  I think this sort of dilemma is an obstacle for \nalmost any standard, really; I'm just speaking from the realm I know \nbest.\n    Perhaps there is room for evangelizing authors to push forward \nwith second, third, and later editions of their books on standards. \nYou don't have to in the case of CSS:TDG, because I talked it over \nrecently with my editor at O'Reilly and we're tentatively planning \nfor a summer 2003 publication.  Which points up another problem: the \nlag time that print publishing inevitably enforces.  Balancing the \ntiming of a book's publication against expected software releases, \nand the features they may have, can be incredibly tricky.  For \nexample, I hope that by the time CSS:TDGv2 hits shelved, IE7/Win will \nbe out.  But I have no idea at all what it may or may not support in \nCSS, let alone any other standard.  I can hope that it will at least \nsupport what IE6/Win does, but can I count on that?  No.  So that's \nanother area to consider.  Is there sense in an effort to have \nbrowser companies disclose their standards-support plans far enough \nin advance for authors to make sensible writing plans?   Should it be \na public disclosure, or an NDA-style program?  And so on.\n    I don't pretend that these are the best ideas, or even that \nthey're particularly good.  They're just what popped into my head as \nI typed.  But the issues that authors face are important, if it's \njudged important that mass-market books be timely, accurate, and \npractical enough to excite readers rather than frustrate them.\n\n\n[1] <http://www.ericmeyeroncss.com/>\n[2] On a personal note, I feel (although others might disagree) that \nCSS:TDG is actually MORE relevant today than when it was published, \nbecause CSS1 is very well and widely supported now.  When I wrote the \nbook, even CSS1 support was kind of dodgy.  Today, it's behind the \ntheory curve but very likely at its practical peak.\n[3] The best generated-content support I've seen is in Opera 6 for \nWindows, but even it has bugs.\n\n--\nEric A. Meyer  (eric@meyerweb.com)  http://www.meyerweb.com/eric/\nAuthor, \"Cascading Style Sheets: The Definitive Guide,\"\n  \"Eric Meyer on CSS,\" \"CSS 2.0 Programmer's Reference,\" and more\n   http://www.meyerweb.com/eric/books/\n\n\n\n"
        },
        {
            "subject": "Bug: &quot;Error: X&quot; when validatin",
            "content": "Ran through the online HTML validator and got several \"error: x\" listings. Here's an example:\n\nLine 466, column 23: \n             <label for=\"idOriginMonth\">Departing:</label>\n                         ^\nError: X\n\n[ In case the spacing gets changed, the ^ is under the \"i\" in \"idOriginMonth.\"]\n\nI suspect the validator is detecting the \"id\" prefix in the For value and half-assuming I intended it to be an Id attribute.\n\n\n\n"
        },
        {
            "subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle",
            "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n"
        },
        {
            "subject": "signal lightin",
            "content": "text/html attachment: stored\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
        },
        {
            "subject": "Is this list still active",
            "content": "The first piece of email I've received from this list in over a month\nappears to be UCE from peter@slopt.com\n\n-Robert\n\n\n\n"
        },
        {
            "subject": "Re: Is this list still active",
            "content": "Robert Belknap wrote:\n\n>The first piece of email I've received from this list in over a month\n>appears to be UCE from peter@slopt.com\n>  \n>\nI don't know.  The list is obviously still online, but not much activity \nhas been seen.  Perhaps we are all busy with our evangelism missions \nright now.\n\n-- \nBrant Langer Gurganus\nhttp://troop545.cjb.net/brant.htm\n\n\n\n\n\napplication/x-pkcs7-signature attachment: S/MIME Cryptographic Signature\n\n\n\n\n"
        },
        {
            "subject": "Re: Is this list still active",
            "content": "At 13:08 -0800 2002-11-27, Robert Belknap wrote:\n>The first piece of email I've received from this list in over a month\n>appears to be UCE from peter@slopt.com\n\nThe list is operationnal, not very active right now, but we should \nhave news soon.\n\nMolly and the W3C are working together to produce something for the \naudience of this list.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Is this list still active",
            "content": "I'm sure tomg's keeping his eyes peeled. ;)\n\n\n----- Original Message -----\nFrom: \"Karl Dubost\" <karl@w3.org>\nTo: <public-evangelist@w3.org>\nSent: Wednesday, November 27, 2002 10:19 PM\nSubject: Re: Is this list still active?\n\n\n>\n> At 13:08 -0800 2002-11-27, Robert Belknap wrote:\n>> The first piece of email I've received from this list in over a month\n>> appears to be UCE from peter@slopt.com\n>\n> The list is operationnal, not very active right now, but we should\n> have news soon.\n>\n> Molly and the W3C are working together to produce something for the\n> audience of this list.\n>\n>\n> -- \n> Karl Dubost / W3C - Conformance Manager\n>            http://www.w3.org/QA/\n>\n>       --- Be Strict To Be Cool! ---\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Netscape 4 and ",
            "content": "Despite the different versions said to be circulating of Netscape 4 \n(4.8?) I do believe Netscape.com and is now blocking the dust-laden \nmonstrosity and encouraging users to upgrade to 6/7\n\nDarn, I was going to include the URI I read this from, but I lost the \narticle...\n\n\n\n"
        },
        {
            "subject": "RE: Netscape 4 and ",
            "content": "Despite the different versions said to be circulating of Netscape 4 \n(4.8?) I do believe Netscape.com and is now blocking the dust-laden \nmonstrosity and encouraging users to upgrade to 6/7\n\nDarn, I was going to include the URI I read this from, but I lost the \narticle...\n\n+++++++++++++\n\nIt was mentioned on Zeldman a few weeks back.  It's on this page:\n\nhttp://www.zeldman.com/daily/0802d.html\n\nAbout 1/3 of the way down\n\nCheers\n\nFrancis\n\n\n\n"
        },
        {
            "subject": "CSS Book",
            "content": "I went shopping yesterday (in Leicester -  fairly major city in the U.K.) \nto buy Eric Meyer's CSS2 Programmers Reference book (its about time I did \nas I need a single reference rather than a sheaf of notes that spills onto \nthe floor with great regularity). Not only did I not find it, but found a \ndearth of books on CSS. This was visiting three major booksellers, \nWatersones being one of them.  The only CSS books were XHTML and CSS (on \nthe MACCAWS booklist) and the Visual Quickstart guide DHTML and CSS.\n\nThis is just a thought that we're trying to promote standards and none of \nthe mainstream publishers seem to be, explicitly - and people will be going \nin to read about language development and NOT get the standards line as \nsuch - which is why we're in existence, I suppose.\n\nIs there any such book that provides for a standards based approach to \n(X)HTML/CSS or is there this vast untapped market? Thinking about it I can \nsee the problem with CSS - unless you're into some sort of standards \ncompliance you'll not have heard of it (OK, sweeping statement, I know) And \nI also know that this is just one sample, but a check on the bookstore's \ncomputer system showed very few of their branches stocking anything to do \nwith CSS explicitly. Is there potential for marketing here? Or should we \neach be offering evening classes in Standards based markup?\n\nThese may only be random late night thoughts but I must admit being \nsurprised by the absence of one of the core techniques of our business.\n\nJohn\n\nP.S. Eric Meyer's book will, today, be on order from our local one-man \nbookseller who can usually get anything in print within a day or so.\n\n\n\nJohn and Sandy Colby\nhttp://www.colbyweb.co.uk\nGeevor Mine http://www.geevor.com\n\nNo electrons were harmed in the creation, transmission or reading of this \nemail. However, many were excited and some may well have enjoyed the experience.\n\n\n\n"
        },
        {
            "subject": "Re: CSS Book",
            "content": "Well, Eric's Programming Reference was on the shelf in Vancouver, Canada --\nalong with the Glasshaus Book, Separating Content from Presentation.  I\npicked up both of them and have been quite happy -- neither is particularly\nlarge, but the content comes fast and thick.\n\nWhat really startled me was the number of books up there with the words\n\"HTML 4\" in the title.  Okay, I know that language isn't really dead -- but\nthere was nothing on XHTML except two fairly useless catch-all books.\nCompared to about twenty on HTML 4.  That, and the sheer mass of \"LEARN\nKILLER FLASH FOR YOUR WEBSITE\" manuals, which managed to span five\nshelves... sigh.\n\nAlthough I did see one Flash book with the best title ever:\n\nhttp://images.chapters.indigo.ca/covers/books/178/073571178X_b.jpg\n\nAt 1:29 AM +0100 10/3/02, John Colby wrote:\n>Thinking about it I can see the problem with CSS - unless you're into some\n>sort of standards compliance you'll not have heard of it (OK, sweeping\n>statement, I know)\n\nCan that really be true?  I've liked CSS as long as I've liked standards\ncompliance, so I have nothing to reference.  But even if your average\nweb-mister doesn't understand semantic markup and the separation of styles,\nsurely they have a need for good typography and content positioning?  What\nelse would they use?  Most hacks that I know of don't even come close.\n\nYes, they may not know how to use CSS \"properly\", but they know how to use\nit in some regard... don't they?\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "Fw: Box Model Fi",
            "content": "I thought this could be of interest to this list as well, an attempt to ease\nthe transition to the W3C CSS Box Model instead of the IE Box Model.\n\nLet's keep the gory details and discussions on css-dicuss ;)\n\n\n----- Original Message -----\nFrom: \"Thor Larholm\" <css-discuss@jscript.dk>\nTo: <css-discuss@westciv.com>\nSent: Thursday, October 03, 2002 3:15 PM\nSubject: Box Model Fix\n\n\n> The faulty box model in Internet Explorer has long been haunting CSS\n> developers. In attempts to circumvent this so that it may appear as the\nW3C\n> Box Model, many flaws and hacks have been discovered and used (Tantek,\nSBMH,\n> etc.). These all require that the CSS developer perform manual\ncalculations\n> on how his paddings and margins affect the width and height under\ndifferent\n> CSS rendering engines, and then implement those in tedious, easily-broken\n> hacks that mainly depend on CSS rendering engine flaws.\n>\n> I propose a different approach. Instead of wasting time on tedious\n> calculations which we often forget to perform and (sometimes)\nnonvalidating\n> hacks that has unexplained and bizarre sideeffects, let us for a minute\n> forget about faulty box models. Let us specify our widths, heights,\npaddings\n> and margins according to the W3C Box Model, according to the CSS\nstandards.\n>\n> Then, let us include a script that will automatically correct any\n> differences there might be between the W3C Box Model and the IE Box Model\n> (or whichever faulty box model) - if, and when, needed.\n>\n> The following page [1] demonstrates this principle. It has a collection of\n> boxes with different widths, heights, margins and paddings - all specified\n> according to the W3C Box Model, in all some simple demonstrations of how\nthe\n> box model works. After this, it has a reference to our correction script.\n>\n> Notice something? It looks the same in IE4+, including IE5, IE5.5, IE6\n(both\n> standards and quirks mode ), NS6+/Mozilla (both standards and quirks\nmode ),\n> Konqueror and Opera.\n>\n> XHTML 1.1 test document [2]\n> HTML quirks test document  [3]\n>\n>\n> So how does it work? There are 2 functions, FixBoxModel and\n> FixBoxModelStyle. FixBoxModel iterates through all CSS rules in all\n> stylesheets, then calls FixBoxModelStyle with each rules style object as\n> argument. FixBoxModelStyle then calculates the proper box size.\n>\n> FixBoxModel is called automatically right after it is inserted, so just\nput\n> the script right after your style declarations and forget about it, and\n> you're done. If you want to, call it onload or whenever - it will only\n> correct the box size once. That is, unless you specify the bForce\nargument,\n> which forces it to recalculate (for advanced users only, if you have\n> dynamically changed padding and margin). This also means that any inline\n> styles will not be corrected, only those specified in STYLE and LINK\n> elements. Maybe I should remember to check imports in the next version,\nbut\n> for now this will suffice as a proof-of-concept demonstration.\n>\n> If you want to correct elements that have inline styles, just call the\n> FixBoxModelStyle function with the elements style object as argument.\n>\n>\n> So what now? I like the concept and it WorksForMe(tm). If you like the\n> concept and/or just feel like helping me out, then test this in the\nbrowsers\n> available to you and tell me about your results so that I can extend the\n> list. I am especially interested in how this works on Mac IE, as I have no\n> Mac available.\n>\n> I would also not use this on a commercial site just yet, as it needs more\n> testing and a 1.0 release first (if ever). I also have no idea if anyone\n> made this before, so a disclaimer on that as well.\n>\n> [1]\n> http://jscript.dk/Util/BoxModelFix/\n> [2]\n> http://jscript.dk/Util/BoxModelFix/boxmodelfix.html\n> [3]\n> http://jscript.dk/Util/BoxModelFix/boxmodelfixquirks.html\n>\n>\n> Regards\n> Thor Larholm\n> <URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n> <URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n>\n\n\n\n"
        },
        {
            "subject": "Dogma W",
            "content": "Hello all\n\nI suppose the following announcement could of interest \nto this group, because it's strongly related to the web \nstandards and their popularization.\n\nSmall group of Czech web designers have just published \nDogma W4 (W4D) at:\n\nhttp://www.pixy.cz/dogmaw4/\n\nW4D is a compact set of rules aiming to more accessible and \nmore usable web page design. W4D doesn't claim to be the only \nuniversal method. It's rather a proclamation of its authors' \nbelief and opinion -- that's why it's called Dogma. If you find \nit useful, you can adopt them for some or all of your web sites, \nhowever you can as well reject it as too restrictive and use \nthe full range of existing standards instead.\n\nI'll highly appreciate your comments, questions, etc. Also, \nplease notice, that authors of the W4D Proclamation are not \nnative English speakers, so the language of the document is \nfar from perfect. Thus your spelling, grammar and stylistic \ncorrections or suggestions are welcome as well.\n\nThank you,\n\nMarek Prokop\nW4D: http://www.pixy.cz/dogmaw4/\nCSS Workshop: http://www.sovavsiti.cz/css/\n\n\n\n"
        },
        {
            "subject": "Fwd: [WD]: Mandarin language websit",
            "content": "A good question on the webdesign-list\n\n\nForward---------debut\nDate: Mon, 7 Oct 2002 17:26:03 +1300\nFrom: Michael Brown <mike@maupuia.com>\nReply-To: Michael Brown <mike@maupuia.com>\nOrganization: maupuia.com\nMessage-ID: <16229385263.20021007172603@maupuia.com>\nTo: list@webdesign-l.com\nSubject: [WD]: Mandarin language website\nSender: owner-list@webdesign-l.com\nList-Help: <http://webdesign-L.com/>\nList-Owner: <mailto:list-owner@webdesign-L.com>\nList-Id: <list.webdesign-l.com>\n\n\nHi\n\nWe've been asked to give some advice on the issues involved with\nhaving an English language website translated into Mandarin. This of\ncourse is not something we've done before! :)\n\nWe're not so much concerned with the translation (as that will be done\nby the client) but with the issues involved in marking-up and\ndisplaying the HTML pages.\n\nI'm after advice/tips/places to go for more information etc.\n\nI'm looking at:\nhttp://www.w3.org/International/\nand trying to find stuff through Google, but anything else (including\nwar stories) would be much appreciated!\n\nI'm happy to summarise what I find for the list.\n\nThanks!\n\n\nRegards\n\nMike Brown\nmaupuia.com :: web development & information architecture\n\nweb: http://www.maupuia.com\nph/fax: (04) 934-9205 | mob: (025) 885-992\n\n\n+----------------------------------------------------------------------+\n   more info about webdesign-l: http://webdesign-L.com/\n                to unsubscribe: http://webdesign-L.com/subscribe.html\n                 list policies: http://webdesign-L.com/policies.html\nForward---------fin\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "RE: [WD]: Mandarin language websit",
            "content": "I understand that XML is perfect for this although I don't know if it's\npossible to convert XML to HTML or if XHTML has an equivalent for it.\n\nSandra.\n\n\n\n"
        },
        {
            "subject": "Re: [WD]: Mandarin language websit",
            "content": "On Mon, Oct 07, 2002 at 06:13:53AM -0400, SanJo wrote:\n> \n> I understand that XML is perfect for this although I don't know if it's\n> possible to convert XML to HTML or if XHTML has an equivalent for it.\n\nXML -> XHTML can be done with XSLT.\n\nI wrote a private reply to Mike on this subject, I think what\nhe's asking is somewhat OT for this list, but I'm forwarding it\nhere for completeness' sake, or if anyone else can give Mike\na hand.\n\nIf anything, something like this raises an issue about\nlanguage encoding standards such as Unicode vs \"old\" 8-bit\nstandards that have been in existence for many years.\n\nHere it is:\n\nFrom: steph <sniffles@unadorned.org>\nTo: mike@maupuia.com\nSubject: Re: Fwd: [WD]: Mandarin language website\nLines: 53\n\nHey Mike :)\n\nI saw the forwarded version of your email to webdesign-L, which\nI'm no longer on ...\n\nI don't know how much help I'd really be ... :) but given that\nI do know Mandarin and did some related stuff for my Honours\nthesis some years ago now, maybe I can help a bit.\n\n> Forward---------debut\n> Date: Mon, 7 Oct 2002 17:26:03 +1300\n> From: Michael Brown <mike@maupuia.com>\n> To: list@webdesign-l.com\n> Subject: [WD]: Mandarin language website\n> \n> We've been asked to give some advice on the issues involved with\n> having an English language website translated into Mandarin. This of\n> course is not something we've done before! :)\n> \n> We're not so much concerned with the translation (as that will be done\n> by the client) but with the issues involved in marking-up and\n> displaying the HTML pages.\n\nI'm pretty sure you're aware of the two main encodings for\nMandarin: Big-5 for Traditional Character set, and GB for\nthe Simplified Character set. Unicode contains both sets\nof characters for Mandarin/Chinese. I am not aware of an\neditor that outputs stuff in Unicode, but it's not hard\nto represent Unicode chars in HTML (pretty sure you know that\ntoo). \n\nThere has been editors around for ages for word processing (I don't \nknow what encoding Chinese Star uses, but it was a very popular \nsoftware), and it's more than likely that these word processing\npackages output HTML, I guess.\n\nI will almost wager that the current Mandarin websites out\nthere use either Big-5 or GB, which require extra plug-ins. I \nbelieve you can get a Unicode plug-in for Windows and it is \nnot too much of a hassle either.\n\nBoth Big-5 and GB are 8-bit, Unicode is 16-bit. :)\n(You probably know that too!)\n\nBut anyway, hope that helps a little bit. \n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "Re: [WD]: Mandarin language website (addendum",
            "content": "On Tue, Oct 08, 2002 at 07:23:45AM +1000, steph wrote:\n> \n> I will almost wager that the current Mandarin websites out\n> there use either Big-5 or GB, which require extra plug-ins. I \n> believe you can get a Unicode plug-in for Windows and it is \n> not too much of a hassle either.\n\nI meant a Unicode /font/, not plug-in. :) \n\nPardon the sloppy jargon, it's been some time.\n\nA good page on Chinese encodings for interested parties:\nhttp://users.erols.com/eepeter/chinesecomputing/encodings/\n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "Wired.com switched to a Web Standards compliant platfor",
            "content": "Wired.com announced 3 days ago that they switched to a fully standard\ncompliant backbone:\nhttp://www.wired.com/news/culture/0,1284,55675,00.html\n\"Wired News has a different appearance, but the new design isn't just\nabout look and feel. The site now complies with standards recommended by\nthe World Wide Web Consortium for greater access to all users.\"\n\n(this very page has actually a small HTML error, but the second page of\nthe article is indeed XHTML 1.0 valid and with a lot of CSS - try the\nvarious available style sheets with Mozilla).\n\nGreat news :)\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "Dominique Haza?l-Massieux wrote:\n\n>Wired.com announced 3 days ago that they switched to a fully standard\n>compliant backbone:\n>http://www.wired.com/news/culture/0,1284,55675,00.html\n>\"Wired News has a different appearance, but the new design isn't just\n>about look and feel. The site now complies with standards recommended by\n>the World Wide Web Consortium for greater access to all users.\"\n>\nfor more details, see Eric Meyer's interview of the project manager :\nhttp://devedge.netscape.com/viewsource/2002/wired-interview/\n\n>(this very page has actually a small HTML error, but the second page of\n>the article is indeed XHTML 1.0 valid and with a lot of CSS - try the\n>various available style sheets with Mozilla).\n>\nthe site now validates :-)\n\n>Great news :)\n>\nindeed.\n\nrelated articles for french-reading people here :\nhttp://www.nitot.com/standards/blog/archives/2002_octobre.php#82882176\nand http://www.nitot.com/standards/blog/archives/2002_octobre.php#82839278\n\n\n--Tristan\n\n-- \nNetscape Technology and Standards evangelist, Europe.\nhttp://devedge.netscape.com/    : cross-browser  techniques.\nhttp://www.nitot.com/standards/ : les standards en fran?ais.\nhttp://mozfr.mozdev.org/        : doc. francaise de Mozilla.\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "Dominique Haza?l-Massieux wrote:\n\n> Wired.com announced 3 days ago that they switched to a fully standard\n> compliant backbone:\n> http://www.wired.com/news/culture/0,1284,55675,00.html\n>\n> [...]\n>\n> (this very page has actually a small HTML error, ...\n\nIt's written in XHTML which is not well-formed - that's worse than HTML tag\nsoup. Furthermore, the page lacks a proper character encoding declaration,\n<meta http-equiv=\"Content-Type\"> isn't sufficient in XHTML. And constructs\nlike\n\n  <a href=\"#\" onclick=\"setActiveStyleSheet('', 1);return false;\">\n\nor\n\n  <!-- BEGIN colMain -->\n  <div id=\"colM\">\n  <div class=\"content\">\n  <div class=\"storyCap\">\n  <div class=\"pgTitle\">\n\naren't examples for good XHTML either.\n\n-- \n<http://schneegans.de/>\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "From: \"Christoph Schneegans\"\n\n|\n| Dominique Haza?l-Massieux wrote:\n|\n| > Wired.com announced 3 days ago that they switched to a fully\nstandard\n| > compliant backbone:\n| > http://www.wired.com/news/culture/0,1284,55675,00.html\n| >\n| > [...]\n| >\n| > (this very page has actually a small HTML error, ...\n|\n| It's written in XHTML which is not well-formed - that's worse than\nHTML tag\n| soup.\n\nStrongly disagree here. I do not think that Tag Soup, including use of\nFonts, absolute sizing, improper nesting, Headers for bolding.\nblockquoting for indents, and sizing is better than XHTML, even if there\nare some minor items needing a change.\n\nOf course we woud need a nice definition of what TAG soup means to apply\nreasoning adequately.\n\nOn a more general approach, TAG Soup, to me, means excessive extra tags\nand no organization, application of tags or elements not in the ways\nwhich were meant.\n\n\n| Furthermore, the page lacks a proper character encoding declaration,\n| <meta http-equiv=\"Content-Type\"> isn't sufficient in XHTML.\n\nI see:\n< meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-1\"\n/ >\nand not the other mentioned, unless we are looking at different pages -\nthis is on the index.html\npage that I see this.\n\n| And constructs  like\n|   <a href=\"#\" onclick=\"setActiveStyleSheet('', 1);return false;\">\n\nNot sure where a problem with this one may be?\n\n|   <!-- BEGIN colMain -->\n|   <div id=\"colM\">\n|   <div class=\"content\">\n|   <div class=\"storyCap\">\n|   <div class=\"pgTitle\">\n|\n| aren't examples for good XHTML either.\n\nWhy not on these items?\nChoice of words?\nMixed case? [attribution words are not limited to lower case]\nUse of class vs ID [re-usable styles for same doc page need class, one\ntime use per page ID]\nor?\n\nDoes this page work on Text only or Lynx view and make sense?\nWill an HTML doc with Tag Soup, degrade similarly for those cases, and\nallow as many user options?\n\nInteresting thoughts you posted, but I would like to hear more about why\nor how this XHTML fails and why tag soup would be better?\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "Interview between Eric Meyer sna the designer of the Wired site (that explains the compromises) here:\n\nhttp://devedge.netscape.com/viewsource/2002/wired-interview/\n\nJust because it ain't perfect doesn't mean that it ain't good progress.\n\nJohn\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "On Monday, October 14, 2002, 2:12:40 PM, Holly wrote:\n> > And constructs  like\n> >   <a href=\"#\" onclick=\"setActiveStyleSheet('', 1);return false;\">\n> \n> Not sure where a problem with this one may be?\n\nBasically, the link will do nothing without scripting. If it had a\nserver fallback, like href=\"setStyleSheet?id=1\", or was only shown\nwhen scripting was enabled (via DOM or document.write), then there\nwouldn't be a problem.\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "From: \"Tom Gilder\"\n\n| On Monday, October 14, 2002, 2:12:40 PM, Holly wrote:\n| > > And constructs  like\n| > >   <a href=\"#\" onclick=\"setActiveStyleSheet('', 1);return false;\">\n| >\n| > Not sure where a problem with this one may be?\n|\n| Basically, the link will do nothing without scripting. If it had a\n| server fallback, like href=\"setStyleSheet?id=1\", or was only shown\n| when scripting was enabled (via DOM or document.write), then there\n| wouldn't be a problem.\n\n\nOk. Well I was under some impression that there was php type server side\noptions or switches, for those without scripting options? But maybe my\nimpression was false? And if this is the case and it is tied to only DOM\nor JavaScript enabled use, perhaps linking to a PHP sheet switch may be\nin order... though cookies enabled may also be a factor in having this\napply to each new page load. [In which case it may be better to leave\nall these options up to a user and his or her learning how to use their\nown tools, devices, or browsers to enhance their web viewing] It would\nbe optimal if browsers put these option buttons clearly on the main\nbrowsing menu bar as default, and also allow advanced users the option\nof customization of same bar if they wish to take it off.\n\nOther than that, the page, if written appropriately, is always resizable\nvia browser options, and there are many ways that a user can define or\nset their own style sheets to replace any sheet on a web site, or use an\nOpera browser to switch them off or another on, resize text more\nquickly.\n\nPersonally, the text sizing feature is just an added extra service and\nnot mandated nor required on any site to display. More or less this item\nor option is a short cut to options already included inside a user's\nbrowser, already, and may in fact be rather limiting in size range as it\nworks now.\n\nPersonally, though nice, I think the range is geared and offered to a\nrather average using group, and not as much towards all accessibility\nusers. Those users are more likely to have a battery of tools or options\nto use, including knowledge on how to increase their text for their own\nviewing after using the web enough.\n\nThough it is nice to offer added extra help in these ways, it is not\nreally our option to train or teach users how to use their computers or\ndevices? is it? If we feel or wish to help or give some hand in that,\nthis is an extra plus on the choice of the designer, though not\nnecessary.\n\nIn no way am I stating or saying that we should not make web sites\naccessible or available to user options.\n\nDo we now need to supply various browser use information and options\nwith all web sites? How to use your browser to optimally view a web\nsite?\n\nholly.\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "> | And constructs  like\n> |   <a href=\"#\" onclick=\"setActiveStyleSheet('', 1);return false;\">\n> \n> Not sure where a problem with this one may be?\n\nhttp://tom.me.uk/scripting/links.asp\n\n\nThor Larholm\n<URL: http://www.jibbering.com/faq/> FAQ for comp.lang.javascript\n<URL: http://jscript.dk/unpatched/> Unpatched IE vulnerabilities\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "\"Holly\" wrote:\n\n>>> http://www.wired.com/news/culture/0,1284,55675,00.html\n>\n> I do not think that Tag Soup, including use of Fonts, absolute sizing,\n> improper nesting, Headers for bolding. blockquoting for indents, and\n> sizing is better than XHTML, (...)\n\nI didn't say that. I noted that this page uses XHTML which is not\nwell-formed. Strictly speaking, this is not XHTML at all. When delivered\nwith a MIME type such as \"application/xhtml+xml\", XHTML user agent won't\nrender it but give you an error message.\n\nThis is worse than tag soup because HTML user agents have learned to deal\nwith invalid HTML.\n\n>> Furthermore, the page lacks a proper character encoding declaration,\n>> <meta http-equiv=\"Content-Type\"> isn't sufficient in XHTML.\n>\n> I see:\n> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-1\" />\n\nOf course that's what I'm referring to. This kind of character encoding\ndeclaration *is* unsufficent in XHTML, see\n<http://www.w3.org/TR/xhtml1/#C_9>.\n\n>>   <a href=\"#\" onclick=\"setActiveStyleSheet('', 1);return false;\">\n>\n> Not sure where a problem with this one may be?\n\nIt doesn't work unless you enable JavaScript. Anyway, changing font sizes\ncan be easily performed within the user agent.\n\n>>   <!-- BEGIN colMain -->\n>>   <div id=\"colM\">\n>>   <div class=\"content\">\n>>   <div class=\"storyCap\">\n>>   <div class=\"pgTitle\">\n>\n> Why not on these items?\n\nThey tried to separate content from style. The only child of the <div\nid=\"colM\"> element is the <div class=\"content\"> element. So this element is\nobviously superfluous and serves no function of the contents.\n\nIn <http://devedge.netscape.com/viewsource/2002/wired-interview/>, Douglas\nBowman states that he wrote \"nested tables 10 levels deep\". Well, he's going\nto make the same mistake again, this time with div's instead of tables.\n\n  <div class=\"buffer\"></div>\n\nand\n\n  <div class=\"clear\">&nbsp;</div>\n\nare other examples for markup without any meaning.\n\n> Does this page work on Text only or Lynx view and make sense?\n\nNo. Did *you* try it? The \"Skip directly to ... Content\" link doesn't work,\nand all these navigation and search bars at the top of the page really don't\nmake sense.\n\n> Will an HTML doc with Tag Soup, degrade similarly for those cases, and\n> allow as many user options?\n\nI don't see any advantages at all.\n\n-- \n<http://schneegans.de/>\n\n\n\n"
        },
        {
            "subject": "Re: Wired.com switched to a Web Standards compliant platfor",
            "content": "Staying positive and learn from the past mistakes is always more constructive.\n\nAt 21:42 +0000 2002-10-14, Christoph Schneegans wrote:\n>In <http://devedge.netscape.com/viewsource/2002/wired-interview/>, Douglas\n>Bowman states that he wrote \"nested tables 10 levels deep\". Well, he's going\n>to make the same mistake again, this time with div's instead of tables.\n\nWired has switched. I will say bravo even if it's not perfect. But \nmore, what we can try to find is why they failed on certain points, \nas how we can understand why they have chosen this more than that.\n\nThis story gives a good opportunity to write a better tutorial and to \nimprove explanation for people that will wish to do the same. People \nmay even want to work with Douglas Bowman to improve Wired XHTML \nmove, version 2.0.\n\nWe all learn of others mistakes, so we have to be indulgent and \nhelped them when it's necessary and try to make it better at each \nversion. Nobody's perfect but the openess will help up to achieve \nquality.\n\nAs Olivier will say \"STEP BY STEP\" and I might keep the role of the \n\"STRICT GUY\" ;)\n\nSo look, identify, learn, and improve your methods, this is the keys.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Hallo Briant\n\nYou wrote\n> I've never had problems with using XHTML for web-authoring.  I would\n> stay away from XHTML 1.1 right now since it cannot technically be\nserved\n> as text/html.  XHTML 1.0 Strict is essentially the same thing and if\nthe\n> rules are followed, it can be served as text/html.\n\nhttp://www.w3.org/TR/2002/NOTE-xhtml-media-types-20020801/#summary tells\nthat also XHTML 1.0 strict should be served as 'application/xhtml+xml'\n\ngreetings\nIneke van der Maat\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Hallo Briant\n\nYou wrote\n> I've never had problems with using XHTML for web-authoring.  I would\n> stay away from XHTML 1.1 right now since it cannot technically be\nserved\n> as text/html.  XHTML 1.0 Strict is essentially the same thing and if\nthe\n> rules are followed, it can be served as text/html.\n\nhttp://www.w3.org/TR/2002/NOTE-xhtml-media-types-20020801/#summary tells\nthat also XHTML 1.0 strict should be served as 'application/xhtml+xml'\n\ngreetings\nIneke van der Maat\n\n\n\n"
        },
        {
            "subject": "XHTML 1.0 Strict MIME types (was: Re: CSS and Netscape",
            "content": "At 12:42 AM 09/01/2002, Ineke van der Maat wrote:\n>http://www.w3.org/TR/2002/NOTE-xhtml-media-types-20020801/#summary tells\n>that also XHTML 1.0 strict should be served as 'application/xhtml+xml'\n\nYou're missing an important point in the note.  The note clearly states \nthat if the HTML Compatibility Guidelines of the XHTML 1.0 spec are met, \nthen XHTML 1.0 may be served as text/html:\n<http://www.w3.org/TR/2002/NOTE-xhtml-media-types-20020801/#text-html>\n\nIt only later says that if you are serving XHTML 1.0 to \"XHTML user \nagents\", then it should be served as applicatoin/xhtml+xml:\n<http://www.w3.org/TR/2002/NOTE-xhtml-media-types-20020801/#application-xhtml-xml>\n\nClearly the vast majority of user agents out there being catered to are not \nXHTML ones.  They're HTML ones.\n\nBill Mason\nAccessible Internet\nw3c@accessibleinter.net\nhttp://www.accessibleinter.net/\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 1.0 Strict MIME types (was: Re: CSS and Netscape",
            "content": "Hello Bill,\n\n> You're missing an important point in the note.  The note clearly\nstates\n> that if the HTML Compatibility Guidelines of the XHTML 1.0 spec are\nmet,\n> then XHTML 1.0 may be served as text/html:\n\nNo I was not something missing, but I made the difference between XHTML\n1.0 strict and XHTML 1.0 transitional/frames\n.\nI wrote only about XHTML 1.0 strict, as in this specs e.g in the img\nelement vspace and hspace are not allowed.\nIn XHTML 1.0 transitional these vspace  and hspace attributes are\nallowed as in HTML.\nI also should  serve for that reason XHTML 1.0 transitional as text/html\nbut not XHTML 1.0 strict.\n\nAs you know is XHTML 1.0 not existing ( XHTML 1.0 has 3 DTDs: strict,\nframes and transitional), while only XHTML 1.1 exists. The text in the\nnote is something confusing I think (it speaks only  about XHTML 1.0 as\nyou do) .\n\nThat makes the difference in my eyes. XHTML 1.0 strict is not\ntotally compatible with HTML as XHTML 1.0 transitional is.\n\nThe differences between XHTML 1.0 strict and XHTML 1.1 are very little.\nOnly the lang attribute has been removed from all elements  (is replaced\nby xml:lang) and the name attribute is replaced in some elements  as in\n<a> by only id.\n\nGreetings\nIneke\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 1.0 Strict MIME types (was: Re: CSS and Netscape",
            "content": ">> You're missing an important point in the note.  The\n>> note clearly states that if the HTML Compatibility\n>> Guidelines of the XHTML 1.0 spec are met, then\n>> XHTML 1.0 may be served as text/html:\n> \n> No I was not something missing, but I made the difference between XHTML\n> 1.0 strict and XHTML 1.0 transitional/frames\n> .\n> I wrote only about XHTML 1.0 strict, as in this specs e.g in the img\n> element vspace and hspace are not allowed.\n> In XHTML 1.0 transitional these vspace  and hspace attributes are\n> allowed as in HTML.\n\nvspace and hspace were not allowed in HTML 4.0 Strict either, only in HTML 4.0 \nTransitional.\n\n> I also should  serve for that reason XHTML 1.0 transitional as text/html\n> but not XHTML 1.0 strict.\n\nThat certain old elements or attributes from HTML 4.0 are not included in XHTML 1.0 \nStrict is irrelevant; a valid XHTML 1.0 Strict document can still be compatible with HTML \n4.0.\n\n> As you know is XHTML 1.0 not existing ( XHTML 1.0 has 3 DTDs: strict,\n> frames and transitional), while only XHTML 1.1 exists. The text in the\n> note is something confusing I think (it speaks only  about XHTML 1.0 as\n> you do) .\n\nIf the note says \"XHTML 1.0\", it obviously refers to all three variants.\n\n> That makes the difference in my eyes. XHTML 1.0 strict is not\n> totally compatible with HTML as XHTML 1.0 transitional is.\n\nXHTML 1.0 Strict is not, but an XHTML 1.0 Strict _document_ can be.\n\n> The differences between XHTML 1.0 strict and XHTML 1.1 are very little.\n> Only the lang attribute has been removed from all elements  (is replaced\n> by xml:lang) and the name attribute is replaced in some elements  as in\n> <a> by only id.\n\nAnd that is what makes XHTML 1.1 incompatible with HTML 4.0. For certain functionality, \nsuch as named anchors, you must add the name attribute to be HTML 4 compatible. You could \ndo that in XHTML 1.0 Strict, but not in XHTML 1.1.\n\n/Jonas\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Quoting Joseph McLean <joseph@secondflux.com>:\n\n> I wanted to ask the group about this.  What version of (X)HTML should a\n> competent web designer use this days?  Assuming that his/her design would\n> work in all versions.\n> \n> I've been reading a lot about XHTML and liking it, but is any compatibility\n> sacrificed if I leave HTML behind and go straight to XHTML 1.1 for all my\n> work?  Will Netscape 4 survive this, thanks to the transitional\n> backwards-compatibility of XHTML?  Or is it safer, at this junction, to\n> still use HTML 4.0.1?\n> \n> I've being doing this gig since the early nineties, so I'm used to waiting\n> (and waiting...) for good technology to be adopted across all pertinent\n> browsers.  Is the time right for universal use of XHTML?  Or are there\n> still caveats?\n> \n> Wondering...\n> \n> -Joseph\n\nHello,\n\nUsing XHTML don't guarantee me being a competent designer, but personally I've\nbeen using XHTML 1.1 DTD[1] for some time. There has been no problems with older\nbrowsers, excluding thead-tfoot-tbody -structure. Last weekend I had to make\none compromise using \"border\" attribute for an anchored image to prevent it\nbeing bordered with NN4.x. As we know, CSS's border property don't render \nproperly in NN4.x\n\n\nWhen one should re-write a HTML 4.01 -document straight to valid XHTML, there\nmay appear some problems. For instance, CSS is treated partly differently[2] \nwith XHTML DTD, and \"converting\" element's attributes to CSS can also bring \nproblems.\n\nIf people keep waiting and asking \"Has the time come for ...\", nothing actually\nevolves. Start using XHTML when you think it'd be appropriate - not when someone\ntells you to do so.\n\nBest Regards,\nSamuli Hakoniemi\n\n[1] http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd\n[2] Eg., overflow property acts differently in BODY and TEXTAREA elements \n    depending on DTD.\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "----- Original Message -----\nFrom: \"Austin Govella\" <austin@desiremedia.com>\nTo: \"Isofarro\" <w3evangelism@faqportal.uklinux.net>\nCc: \"Thor Larholm\" <public-evangelist-w3@jscript.dk>;\n<Mike.Steckel@SEMATECH.Org>; <public-evangelist@w3.org>;\n<list@webdesign-L.com>\nSent: Friday, August 30, 2002 11:08 AM\nSubject: Re: CSS and Netscape\n\n\n> > ----- Original Message -----\n> > From: \"Thor Larholm\" public-evangelist-w3@jscript.dk\n> >\n> > [Significant user base using Netscape 4]\n> >> Give up Netscape 4 or give up standards.\n> >\n> > When it is noticed that a fair chunk of revenue comes from Netscape 4\n> > visitors, the above choice is a no-brainer, and standards lose out. Is\nthe\n> > best way of advocating standards a typical brusque \"take it or leave\nit\"?\n>\n> Ok. Maybe I'm crazy. But what kinds of designs are you speaking about, the\n> ones that are impossible to achieve in NS4 using standards?\n\nIf these designs were possible to do in Netscape 4 using a standards-based\napproach, then I doubt we would be having this particular discussion. :-)\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "----- Original Message -----\nFrom: \"Austin Govella\" <austin@desiremedia.com>\nTo: <Mike.Steckel@SEMATECH.Org>; \"Thor Larholm\"\n<public-evangelist-w3@jscript.dk>\nCc: <public-evangelist@w3.org>; <list@webdesign-L.com>\nSent: Friday, August 30, 2002 11:01 AM\nSubject: Re: CSS and Netscape\n\n\n> If there is a conflict between your design and standards, you need to make\n> a *business* decision as to what is more important: your current design\n> *as is*, or designing with standards.\n>\n> I would suggest that when you add everything up, standards are more\n> important.\n\nFrom a business point of view I don't think this argument stands up. How can\nalienating a portion of your audience and its spending power be alleviated\nby following a standards-based approach?\n\nThe perception with a standards-based approach is that Netscape 4 users will\nsee a dull grey screen, while Internet Explorer 5 will see the perfect\nlayout (as long as the box-model isn't relied on). But at the moment, their\nmainstream website looks very similar in Netscape 4 and Internet Explorer 5,\nand people with Netscape 4 are buying/investing in their site. From this\npoint of view, standards will prevent the business operating with their\nNetscape 4 audience.\n\nHow can standards be more important when you're alienating a portion of your\ntarget audience - isn't that discrimination? How can we offer the chance of\nfull accessibility, but at the same time discriminate against others?\n\nIts not the value of standards I'm arguing against here, it is the way it is\nbeing presented. If there isn't a feasible \"upgrade\" path offered from where\nwebsites are now (tables based Netscape 4 friendly tag soup), and where we\nwant them to be (valid XHTML1.0 & CSS), you have no hope of attracting any\nserious interest in producing mainstream standards-compliant websites.\n\nRevenue or standards?\n\nA business will go for revenue every single time while the standards are not\na mandatory requirement.\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "----- Original Message -----\nFrom: \"ed nixon\" <ed.nixon@lynnparkplace.org>\nTo: \"Thor Larholm\" <public-evangelist-w3@jscript.dk>\nCc: <Mike.Steckel@SEMATECH.Org>; <public-evangelist@w3.org>;\n<list@webdesign-L.com>\nSent: Friday, August 30, 2002 1:43 PM\nSubject: Re: CSS and Netscape\n\n\n[Treating NN4 as a text-browser]\n> If this approach is a non-starter for your people, then I'd say you have\n> a very difficult and, more importantly, very expensive project on your\n> hands because virtually everything will have to be done twice, the Bv4\n> (BeforeVersion4) and the Av6 (Version 6 and beyond.)\n\nThis argument that developing websites that work in Netscape 4 results in\ndouble development time is a straw-man argument. It automatically assumes\nthat there is duplication involved in the entire workstream of the website\ncreation process.\n\nWe all know how important it is to separate content from presentation, and\nNetscape 4 friendliness is no exception. The only duplicate work items are\nthe initial creation of templates, and the testing of those templates. The\ncontent should always be separate from the presentation, so this would be a\nnon-duplicated process.\n\nOn delivery, either deliver a dynamic website that delivers full compliant\nmarkup to all user agents except those identifying themselves as Netscape 4,\nor run it through an html preprocessor and generate two websites.\n\nThe duplication is only imaginary, thus the \"very expensive project\"\nargument equally illusory.\n\n\n\n"
        },
        {
            "subject": "Re: CSS and Netscap",
            "content": "Isofarro wrote:\n> <snip/>\n> [Treating NN4 as a text-browser]\n> This argument that developing websites that work in Netscape 4 results in\n> double development time is a straw-man argument. It automatically assumes\n> that there is duplication involved in the entire workstream of the website\n> creation process.\nThis is all highly over generalized, including my post, and doesn't lend \nitself to anything other than highly overgeneralized discussion.\n\nHowever, the fact that the problem is defined and solved in terms of NS4 \nAND everyone else (which ignores the differences/quirks among the \nvarious versions of Internet Explorer, for example) means that every \nstep of the process will have to contain cycles recognizing, checking \nand resolving for the \"AND\" of the relationship. If you are working as \nan individual, in a putative vacuum, and not in a large, contentious and \ncomplex organizational and project environment, the overhead will be \nminimal; otherwise it will be substantial. There will be costs that will \nnot involve you and your templating activities.\n> \n> We all know how important it is to separate content from presentation, and\n> Netscape 4 friendliness is no exception. The only duplicate work items are\n> the initial creation of templates, and the testing of those templates. The\n> content should always be separate from the presentation, so this would be a\n> non-duplicated process.\n\nThis is good theory and a great goal to pursue. As you know, what one \nconfronts, however, is perception of what is on the screen by the people \nwho are signing the cheque -- \"I know what I like and this ain't it.\" \nOne can try to be as smart as possible about the initial setup; but, \nthere will be tremendous, irresistable pressure in the course of the \nwork that will tend to erode the theory and complexify the product. \nHence, more cycles and more cost, howbeit largely downstream and, for \nthe moment, hidden.\n\n> \n> On delivery, either deliver a dynamic website that delivers full compliant\n> markup to all user agents except those identifying themselves as Netscape 4,\n> or run it through an html preprocessor and generate two websites.\n\nAnd the html preprocessor comes from where? At what cost?\n\nThese are the kinds of cost \"externalities\" that are conveniently \nforgotten, much like the costs of cleaning up after automobiles or \nnuclear power plants. And, if considered properly, these costs radically \nchange the cost-benefit scenarios of most, if not all, Web development \nprojects.\n\nAll of this has to be seen from a management and operational \nperspective, in addition to a designer, coder perspective, in order to \nhave the proper view.\n\nAll I'm suggesting is that web development and operation is a very \nexpensive proposition, too expensive; the mulitplicity of browsers and \ntheir glitches is one of the major factors in inflating the cost. There \nare others. Any cost conscious business contemplating getting into or \nupgrading a website deserves to be given the opportunity of looking at \nthe (total and accurate) incremental costs of supporting each of the \nalternatives. Evloving to higher or more advanced levels of \nstandardization offers the potential for decreasing the number of costly \nalternatives to something greater than one, which I think many people \nthink is a good idea.\n\nThe marginal cost to a user of upgrading a browser, particularly if \nencouraged and assisted in helpful and efficent ways, is trivial in \ncomparison to the aggregate costs to the industry or to a large \norganization. The fact that browser technologies have been historically \n\"free\" is probably the biggest externality we confront. Browsers are \nalso the software application about which people know the least in terms \nof opperation.\n\nWhy don't we talk about how to most positively, expeditiously and \nsynergistically move users away from NS4 rather than gritching and \nsnitching about how to accommodate something we all agree (I hope) is a \npain to work with and just plain bad technology? I'd like to suggest \nthis thread move on to a more \"evangelical\" topics.\n\n          ...edN\n\n\n\n"
        },
        {
            "subject": "99.9% of Websites are obsolet",
            "content": "FYI: An article to read.\n\n_99.9% of Websites Are Obsolete\nAn excerpt from Forward Compatibility: Designing & Building With\nStandards_\nhttp://www.digital-web.com/features/feature_2002-09.shtml\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: 99.9% of Websites are obsolet",
            "content": "From: \"Karl Dubost\"\n\n\n| FYI: An article to read.\n|\n| _99.9% of Websites Are Obsolete\n| An excerpt from Forward Compatibility: Designing & Building With\n| Standards_\n| http://www.digital-web.com/features/feature_2002-09.shtml\n\n\nThanks Karl,\n\nI was reading this article[book excerpt] at Digital Web this morning and\nthought it was great and had good examples. I wonder if others even know\nthat their extensive work arounds are starting to break in newer\nbrowsers?\n\n[looking forward to seeing the published book]\n\nIn reading the article, down towards the bottom is the short quoted\nphrase...\n\n_Write once, publish everywhere,_\n\nholly\n\n\n\n"
        },
        {
            "subject": "Web Design Curriculum ",
            "content": "I was wondering if there are any curriculum models out there for\nUniversities, Colleges, or other educational institutions to follow,  in\norder to restructure, or build a course for teaching web design. A\nstandardized curriculum that would include topics of guidelines,\naccessibility, standards, etc. With hints or help on how to introduce\ntopics along the way.\n\nIt would seem to me that many or most might have to teach these courses\nwith text editors in mind and not web authoring tools, or at least start\nthese students at that text editing point. If they were to use the web\nauthoring tools, they may find themselves in a spot to use up a lot of\ncritical learning time explaining to students how to produce well\nformatted and valid markup.\n\nI think an article or piece, or site directed at teaching institutions\nand instructors is in order.\n\nThere is a wealth of information out there, but it seems like there\nneeds to be a really good central site or set of pages that will help\nfor those wishing to transform. Many sites I can think of are great,\nthough the information is fractured into areas of specific interest.\nAccessibility sites may not embrace the full guidelines and format\nstructure or how to work with CSS and XHTML or strict markup. Likewise\non the markup helpful sites, they may miss out on some critical\ninformation regarding Accessibility issues or key points. This can be a\ntime consuming or an overwhelming task for any Course Developer with the\nabundance of so much good information out there and so many avenues it\nis coming from.\n\nI was wondering if there is such a site up or in the works?\n\nthanks,\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: Web Design Curriculum ",
            "content": "Holly,\n\nThere is curriculum being developed in a variety of ways.  The World\nOrganization of Webmasters (WOW) has actually been very active in\neducational pursuits and has certification programs mapped to university and\ncollege programs.  It is a very rigorous program and there are numerous\nadvisory members collaborating with instructional design experts to come up\nwith really strong models and tests.\n\nAlso, Macromedia has created a Digital Design: Foundations of Web Design\ncourse that also maps to WOW curriculum and will likely be used in a wide\nrange of institutions.  I haven't reviewed it yet but it's here on my desk\nand I'm optimistic that some important standards issues will be discussed\nthere.\n\nThe WOW site is going to be completely redesigned in the next few months to\nbe up to snuff standards-wise, which they aren't now.  They have made a\nformal commitment to supporting standards in all of their educational\ninitiatives and I'm very pleased to see this happen.  Their web site will\ncertainly be a great place for this kind of thing to occur, since they\nreally are the leaders in providing formal education initiatives to unis and\ncolleges at this time.\n\nIf you're interested in hearing more about any of this, check me off-list.\n\n--Molly\n\n\n\n"
        },
        {
            "subject": "Nonconformance by W3C member",
            "content": "It appears that nearly 75% of W3C members are not following the very \nguidelines they help create.\n\nhttp://rss.com.com/2100-1023-956778.html?type=pt&part=rss&tag=feed&subj=news\n\n-- \nBrant Langer Gurganus\nEditor, Open Directory Project\nDefault QA Contact, Mozilla Evangelism\nTechnician, Protonic.com\nWebmaster, troop545.cjb.net\nWebmaster, www.firecrafter.org\nWebmaster, www.msdpt.k12.in.us/etspages/ph\nJunior Assistant Scoutmaster, Troop 545\nEagle Scout, Boy Scouts of America\nMember, Internet Society\n\n\n\n"
        },
        {
            "subject": "Re: Nonconformance by W3C member",
            "content": "At 18:09 -0500 2002-09-05, Brant Langer Gurganus wrote:\n>It appears that nearly 75% of W3C members are not following the very \n>guidelines they help create.\n>\n>http://rss.com.com/2100-1023-956778.html?type=pt&part=rss&tag=feed&subj=news\n\nIt's an interesting indicator that I hope Marko will run as often as \npossible. I know that he will do it every 6 months.\n\nThe home page validation is an indicator but a loosely one, because \nimagine members start to worry about the validity of their home page, \nthey will achieve a better press coverage... but it will not mean \nthat the rest of the Web site is valid or all Web sites that a \ncompagny has in charge.\n\nFor example, it would be good to define a relative scale of validity \nfor a whole website.\n\nproportion of\nvalid pages\n-----------------------------\n<50%  BAD\n50%-70%  you're on the good way\n70%-90%   good\n90%-100%  Great!!! you have a valid website.\n\nAfter the same time we \"evangelize\" for validity, we have also to \nevangelize for the correct semantic use of tags and the accessibility.\n\nfor example\nYou can make a valid document, which is completely incorrect for the \nsemantic, like using a \"blockquote\" element to indent un text and not \nfor a citation.\n\nSo we have work.\n\nPS: When I come back from holidays, I will update the document \nWeb-Quality with ideas that have been sent.\nIf people feel that I have missed bits, examples, or they would like \nto see more things in it. Please send your comments here.\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Nonconformance by W3C member",
            "content": "> At 18:09 -0500 2002-09-05, Brant Langer Gurganus wrote:\n> >It appears that nearly 75% of W3C members are not following the very \n> >guidelines they help create.\n> >\n> >http://rss.com.com/2100-1023-956778.html?type=pt&part=rss&tag=feed&subj=news\n\nHaving an artist in a family doesn't necessarily means everyone craves\nhis or her work. The situation with W3C members may be the same, \nI don't know, I can't and won't speak for all W3C members.\n\nMy only experience is that my W3C Host, Keio university/Shonan Fujisawa\nCampus, has most pages on its site valid, and that's partly because some\npeople from the W3C Team helped and convinced them it was important.\nhttp://www.sfc.keio.ac.jp/\nOn the other hand, the global home for Keio university is invalid...\n\nI wish the survey continues, in order to see whether these figures\nshould make me sad or optimistic. A possible conclusion, today, would be\nthat if \"we\" want to convince people to respect web standards, there may\nnot be any \"easy target\".\n\n\nOn Thu, Sep 05, 2002, Karl Dubost wrote:\n \n> For example, it would be good to define a relative scale of validity \n> for a whole website.\n\nBut then again, how do you define the proportion of valid/invalid\nmaterial? in volume? number of pages? bytes?\n\nI like the \"traffic approach\" that Gerald Oskoboiny had developed in his\n\"top-invalid tool\"[1] - ancestor to the LogValidator[2].\n\n[1] http://lists.w3.org/Archives/Public/www-qa/2001Sep/0031.html\n[2] http://www.w3.org/QA/Tools/LogValidator/\n\nWhat's the traffic approach? Imagine you have 4 documents on a site\n(we'll call them 1,2,3 and 4), accounting for, resp. 40%, 30%, 20% and\n10% of the traffic for this site. \n\nNow imagine that documents 1 and 4 are invalid. that's 50% of the\ndocuments, and 50% of the traffic, and that's bad. If you have time to\nfix both documents, fine, but if you have time to fix only one?\n\nThe usual approach woud be that, well, just fix one and you'll have only\n25% of the documents that are invalid. The traffic approach says, fix\ndocument 1 and go up to 90% of your traffic being valid.\n\nThat may sound ridiculous with 4 documents, but when it's 40000, with a\nlot of legacy, unmaintained documents, you're happy when you can go from\n50% valid to 90% valid by fixing only 25% of the documents.\n\n\nI'm preparing an article/LogV tutorial that explains this and other\nideas to \"fix\" better, so stay tuned.\n\n\n> So we have work.\n\nNow that's a summary :)\n\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: Nonconformance by W3C member",
            "content": "Karl Dubost wrote:\n> for example\n> You can make a valid document, which is completely incorrect for the \n> semantic, like using a \"blockquote\" element to indent un text and not \n> for a citation.\n\nIMO such a document cannot be said to be valid. That validator.w3.org \ndoesn't find any errors does not mean that the document is valid, \nsimilar to how running a document through your word processor's spell \nchecker is no match for having it proof-read by a person.\n\n/Jonas\n\n\n\n"
        },
        {
            "subject": "work from home we will help you",
            "content": "text/html attachment: stored\n\n\n\n\n"
        },
        {
            "subject": "Validation was Re: Nonconformance by W3C member",
            "content": "--- Jonas_J?rgensen <jonasj@jonasj.dk> wrote:\n> \n> Karl Dubost wrote:\n> > for example You can make a valid document, which\n> > is completely incorrect for the semantic, like using\n> > a \"blockquote\" element to indent un text and\n> > not  for a citation.\n> \n> IMO such a document cannot be said to be valid. That\n> validator.w3.org doesn't find any errors does not mean\n> that the document is valid, similar to how running a\n> document through your word processor's spell \n> checker is no match for having it proof-read by a person.\n\nThe W3C page on document validation somewhat discusses this problem\nat <http://www.w3.org/TR/html4/sgml/intro.html>, even though they're\nfocusing on technical mistakes like illegal (but 'valid') attribute\nvalues.\n\nValidation is simply a check against the referenced DTD, nothing\nelse. So any HTML document that conforms to the referenced DTD is\nvalid. Whether the document uses the right markup for the right\ncontent, or whether the text makes any sense at all, is not part of\nthe validation process. That's why even valid HTML, just like\nspell-checked documents, can be complete gibberish. See\n<http://groups.google.com/groups?selm=35080%40sdcc12.ucsd.edu&output=gplain>.\n\nBut of course I do agree that semantic is very important. This aspect\nof the standards sometimes gets lost in the recent coolness of\nvalidation. Perhaps it gets lost because correct semantics require\nthat the author actually know the standards, while validation can be\ndone by a stupid machine.\n\n\nMatthias\n\n\n__________________________________________________\nDo You Yahoo!?\nYahoo! Finance - Get real-time stock quotes\nhttp://finance.yahoo.com\n\n\n\n"
        },
        {
            "subject": "Re: Validation was Re: Nonconformance by W3C member",
            "content": "At 05:20 -0700 2002-09-09, Matthias Gutfeldt wrote:\n>Validation is simply a check against the referenced DTD, nothing\n>else. So any HTML document that conforms to the referenced DTD is\n>valid. Whether the document uses the right markup for the right\n>content, or whether the text makes any sense at all, is not part of\n>the validation process. That's why even valid HTML, just like\n>spell-checked documents, can be complete gibberish. See\n><http://groups.google.com/groups?selm=35080%40sdcc12.ucsd.edu&output=gplain>.\n\nThere's more than that, there are requirements in the W3C \nspecifications which can not be defined with a DTD. So can make a \nthree level rocket ;)\n\n1. Validity with regards to the DTD\nAutomatic process if the validator checks everything and does \nnot contains errors.\n\n2. Conformance with regards to the specifications.\nFor example, the stylesheet language when you are not using a \nstyle element or/and an external style sheet.\nSee http://www.la-grange.net/2002/04/03-styleatt-wo-meta.html\n\n3. Respect of the semantic as you said in your mail.\n\n\nOn top of that we can add the respect of the semantics. :)\n\nI think the respect of the Semantic will be the most difficult to \nachieve even if it's the easiest to achieve and understand.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Tes",
            "content": "Test, please ignore.\n\n\n\n"
        },
        {
            "subject": "Re: WC3 standards and its impact on the broswer war",
            "content": "Mordecai Zemander wrote:\n> I am one of those people, like many here I'm sure, that dislike Internet\n> Explorer immensely.\n\n[*raises hand*]\n\n> While our reasons for disliking the browser may vary\n> from personal choice to anti-ms zealotry, it must be said that writing\n> browsers which adhere to the World Wide Web Consortiums HTML standards,\n> is simply a step backwards in the lopsided browser war.\n> \n> Simply put, IE has set the standard already. Whatever Microsoft defines\n> as the HTML standard should be adopted as the de facto standard.\n> Building a tree-fort and writing up our own standard that is \"better\"\n> than the Microsoft way, can be fun and even noble, but in the end it is\n> totally irrelevant. As it stands now, MS has won. They own at least 80%\n> of the browser share.\n\nActually it's more like 96%, according to my server logs.\n\n> This dictates how web sites are designed and\n> developed, most of which will try hard to satisfy IE first and WC3\n> browsers second. Now yes, most large commercial sites will accommodate\n> multiple browsers, but these are certainly the minority of web sites\n> that exist. The rest of the personal/web log/specific niche interest\n> sites will be the majority, and it should be assumed that since these\n> are made by amateurs, (who probably run IE), they will be designed for\n> IE. This is because designing a site to comply with WC3 standards is too\n> hard for the average user putting up a page about his He-Man figurines.\n> You can't \"throw together\" a WC3 compliant page like you can for\n> Internet Explorer. Instead, you have to contend with CSS style sheets\n> with multiple classes, which most people will not want, have the time,\n> or capacity to deal with.\n> \n> I would argue that people change their browsers because their online\n> friends recommend them to.\n\nI would argue that the vast majority *never* changes their browser. They \nuse the browser that comes with their computer or that their ISP \nprovides for them. Speaking of ISPs, AOL -- the world's largest ISP -- \nhas already switched its Compuserve and AOL/Mac OS X customers from IE \nto Gecko (Mozilla's W3C-complaint, non-IE-emulating rendering engine). \nWhy would they do that if not to test the technology before unleashing \nit on their AOL/Win customers?\n\nAOL has more than 35 *million* subscribers. That's more than most web \nsites can afford to ignore.\n\n> These social groups will have the same\n> interests, and enjoy the same pages as each other, and may often have\n> their own sites reflecting the groups interests. Most likely they will\n> probably never use a WC3 browser over IE, because the sites they\n> collectively visit and write will render best under Internet Explorer,\n> thus limiting the adoption of better browsers like Opera and K-Meleon.\n> How many sites on the Internet render fine under IE versus Mozilla and\n> Opera? I'm guessing IE holds a considerable lead, if not 99% compliance\n> for up-to-date pages, versus a 70% for the others.\n> \n> In conclusion, the other browsers that fight for the remaining 20% of\n> the web surfing pubic, must attempt to emulate Internet Explorer's\n> rendering and HTML standards as much as possible.\n\nMany sites do something like\n\nif (document.all)\n     doStuffSpecificallyTaileredToMsiesCssBugs;\nelse\n     doStuffWhichWillWorkInW3cCompliantBrowsers;\n\nIf other browsers were to implement document.all, they would also have \nto emulate all of the weird bugs of IE5/Win. Given the enormous amount \nof bugs we're talking about here, that would be an impossible goal. It \nwould mean either attempting to reverse-engineer the IE rendering engine \nor writing literally *millions* of test pages.\n\nAlso, which specific MSIE is it that you would like the other browsers \nto emulate? IE5/Win? IE6/Win? IE5/Mac? 'Cause guess what: They all \nrender pages *differently*.\n\n> This is the only\n> viable way to offer the public a better web browsing experience than the\n> one currently offered by Microsoft. By refusing to adhere to this idea,\n> and continuing to adopt WC3 standards, these browsers are effectively\n> signing their own death certificates and at the same time, an open\n> invitation to Microsoft to continue its colonization of the Internet.\n\n*Emulating IE* would be an open invitation to Microsoft continue its \ncolonization of the Internet! It would be mean that Microsoft would \nforever be in control of the web. All non-IE browsers would forever be \nforced play catch-up with the latest IE.\n\nThe only way out of this nightmare is W3C standards.\n\n/Jonas (posting from netscape.public.mozilla.browser, and CC'ing \npublic-evangelist@w3.org.)\n\n-- \n'Open Systems' means no fences. And no fences means no use for Gates.\n- Sun Microsystems\n\n\n\n"
        },
        {
            "subject": "Re: WC3 standards and its impact on the broswer war",
            "content": "Jonas J?rgensen wrote:\n> *Emulating IE* would be an open invitation to Microsoft continue its \n> colonization of the Internet! It would be mean that Microsoft would \n> forever be in control of the web.\n\nSorry, that should have read \"It would mean that Microsoft [...]\". \nIgnore the \"be\".\n\n/Jonas\n\n-- \n'Open Systems' means no fences. And no fences means no use for Gates.\n- Sun Microsystems\n\n\n\n"
        },
        {
            "subject": "Re: WC3 standards and its impact on the browser war",
            "content": "At 7:28 -0400 9/18/02, Jonas J?rgensen wrote:\n\n>Actually it's more like 96%, according to my server logs.\n\n   Other sites may tell a different story: \n<http://www.hacksrus.com/reports/log.agents.html>.\n\n>Many sites do something like\n>\n>if (document.all)\n>     doStuffSpecificallyTaileredToMsiesCssBugs;\n>else\n>     doStuffWhichWillWorkInW3cCompliantBrowsers;\n\n    In the group to which I belong at Netscape, where we're involved \nin standards support, we recommend that site authors who need object \ndetection do the following:\n\n    if (document.getElementById)\n       doStuffThatWillWorkInW3CCompliantBrowsers;\n    else if (document.all)\n       doStuffTailoredForIE4.x;\n    else if (document.layers)\n       doStuffTailoredForNN4.x;\n    else\n       warningMessageAboutLostFunctionality;\n\n...or something like that.  The point it that we tell them to detect \nfor the W3C DOM detection first, because more browsers support it. \nThen the fallbacks come.  This assumes that they feel a need to even \nhave the fallbacks, which most commercial site developers do.  It's a \nsmall performance win in standards-compliant browsers, too, since the \nfirst test is to recognize them.  You can shortcut the rest of the \ntesting branches that way.  In some cases that can actually have a \nperceivable effect on performance.\n\n>If other browsers were to implement document.all, they would also \n>have to emulate all of the weird bugs of IE5/Win. Given the enormous \n>amount of bugs we're talking about here, that would be an impossible \n>goal.\n\n    See for example the rather lengthy discussion contained in \n<http://bugzilla.mozilla.org/show_bug.cgi?id=154589>.\n\n>The only way out of this nightmare is W3C standards.\n\n    Indeed so.\n\n--\nEric A. Meyer  (eric@meyerweb.com)  http://www.meyerweb.com/eric/\nAuthor, \"Cascading Style Sheets: The Definitive Guide,\"\n  \"Eric Meyer on CSS,\" \"CSS 2.0 Programmer's Reference,\" and more\n   http://www.meyerweb.com/eric/books/\n\n\n\n"
        },
        {
            "subject": "DEADLINE for W3C Usability Workshop extended to 30 September 2002   please send your position papers",
            "content": "Hi, Public Evangelist readers.\n\nHere is some information on a Workshop extension that might appeal to \nyou. You can follow up with the NIST organizer with any questions. \nThanks for your consideration.\n\n---\n\nThe Call for Papers for the W3C/NIST Usability Workshop has been\nextended to 30 September 2002.\n\nThere are three aspects that the workshop will consider:\n         1) the usability of W3C specifications\n         2) how they affect usability of software based on them, and\n         3) how to improve the overall usability of the Web.\n\nYou can learn more from the Workshop Homepage at:\n\nhttp://zing.ncsl.nist.gov/uig_w3c/\n\nFor questions, please contact Sharon Laskowski, NIST, at\n\nsharon.laskowski@nist.gov\n\nBest regards,\n\nJanet\n\n--\n\nWorld Wide Web Consortium (W3C)\n\nJanet Daly, Head of Communications\nMIT/LCS NE43-363\n200 Technology Square\nCambridge, MA 02139\nUSA\n\nvoice: +1.617.253.5884\nfax:   +1.617.258.5999\nhttp://www.w3.org/\njanet@w3.org\n\n\n\n"
        },
        {
            "subject": "[Article] WebQuality v1.",
            "content": "Hi,\n\na few corrections, minor updates to the article Web-Quality\nhttp://www.w3.org/QA/2002/04/Web-Quality\n\n\nI would like to add two points, but I need your help.\n\n* \"Major companies have invalid websites. They don't care about \nstandards, why I should care?\"\n\n* \"I'm working in the real world, I'm doing business with real \nclients and they don't care about standards, they want something that \nworks.\"\n\n\nPlease reply to the list.\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "On Fri, 20 Sep 2002, Karl Dubost wrote:\n\n> a few corrections, minor updates to the article Web-Quality\n> http://www.w3.org/QA/2002/04/Web-Quality\n\nI have two specific and two general comments below. The specific\ncomments assume that the reader buys your existing arguments.\n\n> I would like to add two points, but I need your help.\n>\n> * \"Major companies have invalid websites. They don't care about\n> standards, why I should care?\"\n\nAnswer: \"You should care because you cannot afford overheads that\nmajor companies can afford\".\n\n> * \"I'm working in the real world, I'm doing business with real\n> clients and they don't care about standards, they want something\n> that works.\"\n\nAnswer: \"Great! So use standards because of the other arguments to use\nthem. Since your clients do not care and standards work, there is no\nconflict. Also, your clients may start to care tomorrow. If you are\nreading this article today, they may be too. Perhaps you can even\nteach them to care. Customers often do not know what's best for them\nand may seek your advice and expert opinion.\"\n\n\n\nGeneral comment: Your \"Usual comments\" section is nice to read, but it\nwould be very helpful to have a succinct summary of \"Whys\" in a\nseparate section. Right now, it is difficult to answer your own \"Why?\"\nquestion without spending time to extract the answers from the \"Usual\ncomments\". In other words, the article does not answer its own Why?\nquestion in an easy-to-digest way. A bulleted list following the\n\"Usual comments\" section may be appropriate. A TOC would be nice too,\nBTW.\n\nThink of a person who needs to convince management to follow\nstandards. That person will benefit from reading \"Usual comments\", but\nshe cannot send those long paragraphs to the boss. She needs a concise\nsummary and a way to prove her points. You help with the latter, but\nnot with the former.\n\nAnother general comment: To be complete, the article SHOULD mention\nWeb site software that delivers Web content. After all, if the Web\nserver is incompliant, it may corrupt compliant content or otherwise\nfail to deliver it. If you want to argue that standards are the way to\ngo, you should argue that Web servers (and other software involved)\nshould follow corresponding standards like HTTP.\n\nNote that achieving HTTP compliance (from Webmaster point of view) is\nsimply a matter of selecting compliant software and/or making their\npreferences known to software manufactures. In this context, it is\nmuch easier to accomplish compliance because it does not involve\narguments such as Web site design quality or cost. Yet, most, if not\nall HTTP servers are not compliant. This brings an interesting\nquestion: Are you fighting the true cause for incompliance? Perhaps\nall those excuses you are trying to address are not that important if\nsoftware that does not have similar problems is still not compliant?\n\n\nFinally, can you truly say that \"My Web site is standard\" (the title\nof your article) if your HTTP server violates RFC 2616 MUSTs? Should\nyou be saying \"My Web pages are standard, if you can get them\"\ninstead? I believe this is a serious integrity question. From an\noutside observer, it may look like you are advocating standard\ncompliance where it is easy (for you!) to achieve and ignoring it\nwhere it is more difficult.\n\nHTH,\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "At 11:44 AM -0400 9/20/02, Karl Dubost wrote:\n>Hi,\n>\n>a few corrections, minor updates to the article Web-Quality\n>http://www.w3.org/QA/2002/04/Web-Quality\n\nYou should hire an artist to properly illustrate the complex\nconcepts explained in this document.  This will increase the\naccessibility and general usability of the document.\n\n--Kynn\n\n-- \nKynn Bartlett <kynn@idyllmtn.com>                 http://kynn.com\nChief Technologist, Idyll Mountain            http://idyllmtn.com\nNext Book: Teach Yourself CSS in 24       http://cssin24hours.com\nKynn on Web Accessibility ->>          http://kynn.com/+sitepoint\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "--- Karl Dubost <karl@w3.org> wrote:\n> a few corrections, minor updates to the article Web-Quality\n> http://www.w3.org/QA/2002/04/Web-Quality\n> \n> \n> I would like to add two points, but I need your help.\n\nNot the help you asked for, but I find the title \"My Web site is\nstandard! And yours?\" a bit unfortunate. It sounds like the owner is\nproud of having a boring old standard website instead of a sizzlin'\nhot high-tech standards-compliant supergizmo!\n\nIOW: It's not the site that should be standard, it's the code. The\nsite should be extraordinary and special. At least that's what many\nwebdesigners aim for.\n\n \n> * \"Major companies have invalid websites. They don't care about \n> standards, why I should care?\"\n\nCite URLS of other major sites that have valid HTML, correct CSS,\naccessible code, and look great and are fun to use.\n\n\n> * \"I'm working in the real world, I'm doing business with real \n> clients and they don't care about standards, they want something\n> that works.\"\n\n\"If it doesn't work, don't blame it on the standards; blame it on the\nindustry that hasn't caught up with the standards.\"\n\nOTOH, that raises the question how \"standard\" these standards really\nare if the industry doesn't use them. So scratch that.\n\nIn my experience, working with standards doesn't cost more time than\nworking without them. But the overall technical quality of the\nproduct is often better (depending on your and the client's\ndefinition of \"quality\", of course), easier to maintain, and has a\nlonger life expectancy. \n\nYou could also bring examples from other fields where standardization\nhas saved costs, enhanced quality, and worked.\n\n\nMatthias\n\n\n__________________________________________________\nDo you Yahoo!?\nNew DSL Internet Access from SBC & Yahoo!\nhttp://sbc.yahoo.com\n\n\n\n"
        },
        {
            "subject": "RE: [Article] WebQuality v1.",
            "content": "I would like to add two points, but I need your help.\n\n* \"Major companies have invalid websites. They don't care about \nstandards, why I should care?\"\n\nRemember the \"David slaying Goliath\" story?  Just because big companies\nhave badly written, non standards compliant sites doesn't mean you\nshould.  Being large doesn't automatically mean that you are always\ncorrect.\n\nYou should care because you want to provide a solid service for your\nclients and users now and in the future.  If large companies don't want\nto do that for their users, want to spend more money now on hacks and\neven more money in the future on reworking those hacks, then let them\nwaste their bottom line.  Me, I'd rather keep my money!\n\n\n* \"I'm working in the real world, I'm doing business with real \nclients and they don't care about standards, they want something that \nworks.\"\n\nWell, standards work.  At what point are you going to keep on coding for\nold browsers?  Netscape have even launched their own campaign to get\npeople to move away from NS4.x  IE has moved from to 5.5 to 6 and people\ndon't generally code for IE4.  Netscape have from from 6.0 to 6.1 to 6.2\nto 7 - at what point are you going to carry on pandering to the 4.x\nrange?  And in the time that these 2 browsers have had that developemtn\nwe've seen Mozilla reach 1.0, 1.1 and Opera leap up the version numbers.\n\nHow about something like this:  \"You want to be seen as a forward\nlooking company that's leading the way in your field.  You spend X\namount of money on billboards, TV advertising, staff uniforms, etc, etc\nbut the public image you portray to the world via your web site is one\nof not caring.  Coding to standards not only gives you a great site now,\nbut will actually save you money in the future which, I'm sure, your\nshareholders and investors will think is most beneficial\".\n\nDon't know if that's any good...\n\nRegards\n\n\nFrancis\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Torture Test&ndash;&ndash;Is this asking too much of the browser vendors",
            "content": "I'm working on a forthcoming issue (on how well browsers deal with\nstandards) of an e-mail newsletter I write for the computer-aided design\nindustry, and though the article isn't quite done yet, I have created a new\nlayout and related pages as reference material to demonstrate their use and\nhow well browsers support them.\n\nThe newsletter won't hit for about a month, but since I'm doing a few things\nthat are pretty radical, I'd like to make sure I'm not doing things that\njust shouldn't work, I'd like to solicit feedback on what I've created, lest\nI have to issue an embarassing correction to our 30,000 readers because\nI've created something inappropriate.\n\nI decided to try nearly every bit of HTML and CSS I'd always wanted to use,\nbut couldn't because it didn't work right--especially fixed positioning, so\nit provides quite a workout, even for Mozilla and Opera.\n\nhttp://www.cadenceweb.com:8080/newsletter/sheerin/webstandards/\n\nSo try it in your favorite browser, and let me know what you think of the\nchallenge I've set out for the browsers. Have I gone too far? Not far\nenough? Are there significant things I've failed to include?\n\nBecause I'm trying to set an example, and use these pages as a sort-of\nbrowser test, I don't really care how well it degrades in older browsers (in\nfact, it only really works right in Netscape 6.2+, and at least one thing\nwon't work until Mozilla 1.2 progresses a little further), but I'm\ninterested in any and all comments on the design, how it works, or my\nassumptions.\n\n\n\n\n\napplication/x-pkcs7-signature attachment: smime.p7s\n\n\n\n\n"
        },
        {
            "subject": "Re: Torture Test&ndash;&ndash;Is this asking too much of the browser vendors",
            "content": "If you are going to provide instructions, as you do in regard to the \npoints/inches box example, they should be comprehensive enough to work \nproperly, on all platforms if possible or, alternatively, to alert \nreaders to the unavailability of the feature.\n\nFor example, on my W2K system with my combination of graphics card and \nmonitor installed, I find neither the option tabs you mention nor a \n\"virtual ruler\" with which to make adjustments or comparisons.\n\nFinally, you might want to enhance the message by including some \nscripting that provides sniffing/feedback to the reader about the type \nand version of browser they are using, lists more egregious \nlimitations/bugs, and provides links to upgrades.\n\nOtherwise, it's a good message even if I were to have aesthetic quibbles \nwith a very busy page design. Just because something *can* be done \ndoesn't always mean is *should* be done.\n\nCongrats and good luck.              ...edN\n\nPeter Sheerin wrote:\n> I'm working on a forthcoming issue (on how well browsers deal with\n> standards) of an e-mail newsletter I write for the computer-aided design\n> industry, and though the article isn't quite done yet, I have created a new\n> layout and related pages as reference material to demonstrate their use and\n> how well browsers support them.\n\n\n\n"
        },
        {
            "subject": "Converting to standards... (sort of",
            "content": "Hey all,\n\n    This was the one group where I thought this would be of interest. \nI recently noticed on a weblog that KPMG.ca as well as KPMG.com \ncompletely shatters in Gecko-based browsers, and it turned out it was \nbecause the site was handing over NN4.x code to Gecko.  So, in a fit \nof something that induced initiative, I grabbed local copies of \nKPMG.com's main page and Javascript files, and hacked at their \nscripts until they used the W3C DOM enough to work in both Gecko and \nIE.  It's available at <http://www.meyerweb.com/eric/fixed/kpmg/>.\n    Note that it's not a full standards makeover-- the markup is still \ncrawling with FONT tags, probably has poor element nesting, and uses \na ton of scripting to even assemble the page.  And I suspect some of \nthe DOM scripting isn't W3C DOM, but based on shortcuts that happen \nto work in both IE and Gecko.  I'm not really a DOM or a Javascript \nexpert, so I did what I could and, with help, was lucky I got that \nfar.  I freely admit that what I did was a hack job on a hack job, \nand could no doubt be improved upon.  Since it was done as a personal \ngratis project, I was willing to give up only so much of my Saturday \nafternoon to it.\n    Anyway, I'm sharing all this with you for two reasons.  One is \nthat if other people want to fix things up further, please be my \nguest.  I'd love to see it based solely on the W3C DOM and use \nvalidating, non-FONT HTML, and if that got it working in Opera and \nother browsers, so much the better.  (I have no idea if Opera's DOM \nsupport can deal with the site's intended effects or not.)\n    The other reason is to propose that it might be worthwhile for the \ngroup to do this on occasion to high-profile sites that are based on \noutdated development methods, but could work as well-- if not \nbetter-- when based on standards.  Doing this for a major site isn't \neasy, of course, but by sharing the conversion efforts, they'd be \neasier to accomplish.  Sadly, I can't volunteer to be a coordinator \nfor such projects, as I'm already swamped.  I simply wish to put the \nidea in front of the list members to see what you all think.\n\n--\nEric A. Meyer  (eric@meyerweb.com)  http://www.meyerweb.com/eric/\nAuthor, \"Cascading Style Sheets: The Definitive Guide,\"\n  \"Eric Meyer on CSS,\" \"CSS 2.0 Programmer's Reference,\" and more\n   http://www.meyerweb.com/eric/books/\n\n\n\n"
        },
        {
            "subject": "Re: Torture Test&ndash;&ndash;Is this asking too much of the browser vendors",
            "content": "On my Mac IE 5.1 I see nothing but a blank white page, lots of downwards\nscrolling and a little sideways scrolling.\n\nCan't really comment on other aspects when I cant see them. Lol\n\nr\n\n\non 22/9/02 7:32 pm, Peter Sheerin at pete@petesguide.com wrote:\n\n> I'm working on a forthcoming issue (on how well browsers deal with\n> standards) of an e-mail newsletter I write for the computer-aided design\n> industry, and though the article isn't quite done yet, I have created a new\n> layout and related pages as reference material to demonstrate their use and\n> how well browsers support them.\n> \n> The newsletter won't hit for about a month, but since I'm doing a few things\n> that are pretty radical, I'd like to make sure I'm not doing things that\n> just shouldn't work, I'd like to solicit feedback on what I've created, lest\n> I have to issue an embarassing correction to our 30,000 readers because\n> I've created something inappropriate.\n> \n> I decided to try nearly every bit of HTML and CSS I'd always wanted to use,\n> but couldn't because it didn't work right--especially fixed positioning, so\n> it provides quite a workout, even for Mozilla and Opera.\n> \n> http://www.cadenceweb.com:8080/newsletter/sheerin/webstandards/\n> \n> So try it in your favorite browser, and let me know what you think of the\n> challenge I've set out for the browsers. Have I gone too far? Not far\n> enough? Are there significant things I've failed to include?\n> \n> Because I'm trying to set an example, and use these pages as a sort-of\n> browser test, I don't really care how well it degrades in older browsers (in\n> fact, it only really works right in Netscape 6.2+, and at least one thing\n> won't work until Mozilla 1.2 progresses a little further), but I'm\n> interested in any and all comments on the design, how it works, or my\n> assumptions.\n> \n> \n\n\nr.\n\n\n\nRyan McInnes\n\nt. +44 (0) 28 9045 5244   f. +44 (0) 28 9045 5244\nw. http://www.aurion.co.uk   e. ryan@aurion.co.uk\n\naurion  .  the eLearning company\n\n\n\n"
        },
        {
            "subject": "has this been noted on the list",
            "content": "Sorry if this is a repeat.\n\nIt's a link to an paper called, \"Sending XHTML as text/html Considered \nHarmful\"\n\nhttp://www.hixie.ch/advocacy/xhtml\n\nThoughts? Comments?\n\n           ...edN\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "Eric,\n\n\nThank you very much for that.\n\nAt 23:06 -0400 2002-09-22, Eric A. Meyer wrote:\n>in both Gecko and IE.  It's available at \n><http://www.meyerweb.com/eric/fixed/kpmg/>.\n\n\n\n>lucky I got that far.  I freely admit that what I did was a hack job \n>on a hack job, and could no doubt be improved upon.  Since it was \n>done as a personal gratis project, I was willing to give up only so \n>much of my Saturday afternoon to it.\n\nYes I think that many people could do. I hope you will have help for \nthis one. I think I remember to have seen a valid Yahoo! website on a \nlist one day.\n\nI think it could be easily done for Yahoo!, Google, etc.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "Hi Karl, Hi all.\n\nOn Fri, Sep 20, 2002, Karl Dubost wrote:\n> a few corrections, minor updates to the article Web-Quality\n> http://www.w3.org/QA/2002/04/Web-Quality\n\nGood. Since you don'y publish a \"new document\" each time (and thus kep\nthe URI) a small changelog at the end of the document would be a nice\naddition.\n\n> I would like to add two points, but I need your help.\n> \n> * \"Major companies have invalid websites. They don't care about \n> standards, why I should care?\"\n> \n> * \"I'm working in the real world, I'm doing business with real \n> clients and they don't care about standards, they want something that \n> works.\"\n\nThese 2 questions can basically summarized with \"nobody cares, why\nshould I\", and the obvious answer is (crudely said) \"you are a sheep\".\nThen you can add \"the rest of the herd is stupid, stop being a sheep\" or\n\"the other sheeps are starting to move forward, be a leader among\nsheeps\", depending om whom you want to target (happy or unhappy sheeps).\n\nI have, however, a problem with those questions. The other questions are\nspecific problems for specific people, whereas this question (\"nobody\ncares, why should I\") is *the* global question behind non-standard\nconformance, and if you can find a good, convincing answer, then the\nwhole E&O effort here and everywhere else has reached its goal, thank\nyou, you can go home now.\n\nSeriously, even though there have been good ideas on this list to answer\nthis question, you will never be able to answer it completely and\nproperly. The interest of your document is that it's not yet another\n(empty) statement saying \"standards are good, follow standards!\",\ninstead it says why (explaining real-life cases) and how.\n\nyou should keep it this way IMHO.\n\ncheers, olivier.\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "A few more questions that pop up from time to time:\n\nStephane, Web hobbyist developer says: \"I spent dozens of hours reading\nabout and experimenting with standards, and my web site is still using\ntables and does not validate. Can you make the standards simpler?\"\n\nStephane, Web hobbyist developer says: \"I admire your Bene Gesserit skill of\nsaying that standards are simple while keeping a straigth face. But really,\ncould you make them simpler, please ? Pretty please ?\"\n(a lot of web hobbyist developers make their own tools, we can't just tell\nthem to use better tools. Tool making has to be simple too. 2 or 3 valid\ntools is not enough. We need hundred of thousands of them to keep the Web an\nexciting and creative place) (and no, 2 or 3 valid browsers is not enough\neither. Browser making should be doable from scratch (i.e. no Gecko) in a\nreasonable amount of human hours)\n\nStephane, Web hobbyist developers naively asks: \"If we abandoned all\nconcessions to backward compatibility, could we create a simpler standard\nfor web pages? Given the weak adoption rate of current standards and the\neven weaker success rate of adopters, maybe we should consider doing that.\"\n(I just tried validating pages that proudly display the \"Valid W3C\" logo,\nand so far only a very small fraction still validates today)\n\nStephane, Web hobbyist developer says: \"My web site incorporates a lot of\nreal-time input (e.g. snippets of HTML, urls with the & character) from end\nusers and other external sources, should I spent hours making my web site\nvalidate when a single user input can break the validity?\"\n(some very standards-savvy end users do get pissed off when they try to\ninput their fancy <blockquote> and find out I'm stripping nearly all markup,\nbut I don't want them to break everything because of a typo).\n\nThanks,\n\nStephane\nWeb hobbyist developer\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "Stephane,\nA lot to answer here, I'll focus on the core.\n\nOn Fri, Sep 20, 2002, Stephane Gigandet wrote:\n\n> Stephane, Web hobbyist developer says: \n> \"Can you make the standards simpler?\"\n\nthe answer is, no and yes. \n\nI'll assume the \"you\" is \"W3C\" in your request... \nThen no, W3C is not going to make standards easier for web hobbyists.\nWeb hobbyists should not read W3C specifications, they should use tools\n(tools that conform to standards they wouldn't need to read), read books\nor tutorials... but the standards are not for hobbyists to read.\n\nW3C specifications are made for implementors (tools/frameworks/etc\ndevelopers), or the people that write the books and the tutorials\nthat web hobbyists should read. And for those, yes, W3C is trying\nhard to make the specifications simpler. and you can actually do more\nto help than saying the specs are too complicated (indeed some are,\nunfortunately, we're painfully aware of it).\n\nAs you may know, this list is hosted by the Quality Assurance activity\nat W3C, among the goals of which is to improve the quality of W3Cc\nspecifications through the creation of a \"QA framework [1]\", help the\n\"education and outreach\" community in their work (through this list),\nand more...\n\nIf you think you can help, please participate in the QA Interest Group,\nwhich reviews and discusses the framework.\nQAIG home : \nhttp://www.w3.org/QA/IG/\nQAIG public discussion list :\nhttp://lists.w3.org/Archives/Public/www-qa/\n\n\n[1] http://www.w3.org/QA/WG/#docs\n\n\nRegards, olivier.\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "On Tue, 24 Sep 2002, Olivier Thereaux wrote:\n\n> Web hobbyists should not read W3C specifications, ...\n> the standards are not for hobbyists to read.\n\nWhy not? To be precise, why should not base standards be simple enough\nfor a computer hobbyist to follow? I think that should be an ideal,\nalbeit not reachable, goal.\n\nHow does one determine whether the standard is too complex? One test\ncould be to check whether it is simple enough for a computer hobbyist\nto understand.\n\nYou argue that hobbyists should use tools. When there are dozens of\npopular operating systems and programming environments, finding a tool\nthat is both \"good\" and \"works\" in your environment is often not\npossible, especially if you are not using MS Windows or Linux.\n\nIdeally, I want to code simple, valid *ML using a text editor and\nvalidate it using an on-line form on W3C Web site. I cannot do that\ntoday using bleeding-edge W3C standards. I can only do that using old\nstandards that most on this list do not even consider standard enough!\n\n> If you think you can help, please participate in the QA Interest\n> Group, which reviews and discusses the framework.\n\nVery good point! On the other hand, if Stephanie is not supposed to\n_read_ standards, it is highly questionable whether she should be\nencouraged to participate in _writing_ a framework for them. The\nframework itself, BTW, is already more complex than a \"hobbyist\" would\nwant it to be, IMHO. Full circle.\n\n\nI think the answer to Stephane's request is simple -- simple standards\ncannot be created by an organization that has to balance conflicting\ninterests of hundreds of interested parties. If you want a simple\n(hence, not backward compatible) *ML standard, create one and try to\nconvince others to use it. It worked when Tim Berners-Lee invented the\nWeb. Perhaps it was a miracle that was possible only due to a unique\ndemand/supply situation. Perhaps it will work again, but probably not.\nIf you do, and it works, please remember the lessons learned -- try to\nkeep it simple :-).\n\nThanks,\n\nAlex.\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "Howdy everyone,\n\nOn Tue, Sep 24, 2002 at 06:28:43AM +0900, Olivier Thereaux wrote:\n> On Fri, Sep 20, 2002, Karl Dubost wrote:\n> > I would like to add two points, but I need your help.\n> > * \"Major companies have invalid websites. They don't care about \n> > standards, why I should care?\"\n> > \n> > * \"I'm working in the real world, I'm doing business with real \n> > clients and they don't care about standards, they want something that \n> > works.\"\n> \n> These 2 questions can basically summarized with \"nobody cares, why\n> should I\", and the obvious answer is (crudely said) \"you are a sheep\".\n> Then you can add \"the rest of the herd is stupid, stop being a sheep\" or\n> \"the other sheeps are starting to move forward, be a leader among\n> sheeps\", depending om whom you want to target (happy or unhappy sheeps).\n\nThat just gave me visions of companies going 'baaa baaa'. :)\n\nFor the first point at least, I have this to say:\n\nOnce upon a time, there would have been no standards for \ntaps and pipe fittings, but at some point, the industry\nmust have recognised that they need to standardise the \nneed to manufacture pipes, taps and fixtures of the right\nsizes so that things would fit everywhere.\n\nThe Web is young, so standards are still being established\nand are being adopted by pockets of the industry. Technologies\nfor accessing web sites are gradually changing too, and it \nmakes sense to be developing according to standards so that in \nthe future, everything can fit alongside everything else at an \ninfrastructural level. \n\nIf you don't follow standards, you might find a time whereby\nyou can't find a tap to replace the broken one in your bathroom\nbecause your pipe is a really weird size.\n\n(I'm no expert on pipes :D One can use a similar metaphor \nwith old cars or railroad tracks - once upon a time (I was told)\nto travel from Melbourne to Sydney you have to change trains at \nthe border because the tracks were different widths in the two \nstates so the trains which ran in one couldn't run in the other.)\n\n\nFor the second point, perhaps something like this:\n\nWeb designers are professional, are we not? Lawyers are\nprofessional, are they not? If you go to a lawyer, you\nexpect them to give you the best advice under the\ncircumstances about what action to take. \n\nWhen your customer comes to you with a request, you\nare entitled to express that the best action to take \nis to futureproof their website with regards to Web\nstandards. Your customer has every right to know about \nWeb standards because it will effect them in the future, \nand that is more important than just 'something that works'. \nDoing things right this time means they would not have to \noverhaul the current work at a later stage, thus providing\ncost savings.\n\nHope that helps. Feel free to elaborate on my ideas :)\n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "Hi Alex,\n\nOn Mon, Sep 23, 2002, Alex Rousskov wrote:\n\n> Why not? To be precise, why should not base standards be simple enough\n> for a computer hobbyist to follow? I think that should be an ideal,\n> albeit not reachable, goal.\n\nI didn't say they should not be simple enough to be read by hobbyists,\njust that specs were not aimed at them but at implementors and\n\"translators\" (book and tutorial authors are translators from spec-lang\nto real-world language, IMHO). I believe we agree on this point, don't\nwe?\n\n> > If you think you can help, please participate in the QA Interest\n> > Group, which reviews and discusses the framework.\n> Very good point! On the other hand, if Stephanie is not supposed to\n> _read_ standards, it is highly questionable whether she should be\n> encouraged to participate in _writing_ a framework for them. The\n> framework itself, BTW, is already more complex than a \"hobbyist\" would\n> want it to be, IMHO. Full circle.\n\nGood point, but my main argument remains valid : once people are aware\nof a problem, it's useless to complain about them, especially since (at\nW3C) there is plenty of room for people to help/participate in a\nconstrictive manner, through public comments list, through the QAIG,\netc.\n \nCheers, olivier.\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: [Article] WebQuality v1.",
            "content": "At 09:46 24/09/2002 +1000, steph wrote:\n>(I'm no expert on pipes :D One can use a similar metaphor\n>with old cars or railroad tracks - once upon a time (I was told)\n>to travel from Melbourne to Sydney you have to change trains at\n>the border because the tracks were different widths in the two\n>states so the trains which ran in one couldn't run in the other.)\n\nThere was a similar situation in England in the 19th Century. GWR used \nwider tracks than the other three main railway companies. In London, where \nall the networks met, they needed to use track with three rails so that \nboth widths of cars could fit on them. I've been looking for a picture of \nthis on the Internet, but couldn't find one.\n\nA more up to date example would be Betamax verses VHS. By going for \npropriety standards rather than vendor neutral standards the video industry \nwas divided.\n\nNeither of those are quite the same as the situation wrt web standards, but \nthere are parallels.\n\nAndrew\n\n--\nAndrew McFarland\nUNITE Solutions\nhttp://www.unite.net/\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "At 23:06 22/09/2002 -0400, Eric A. Meyer wrote:\n<snip/>\n>    The other reason is to propose that it might be worthwhile for the \n> group to do this on occasion to high-profile sites that are based on \n> outdated development methods, but could work as well-- if not better-- \n> when based on standards.  Doing this for a major site isn't easy, of \n> course, but by sharing the conversion efforts, they'd be easier to \n> accomplish.  Sadly, I can't volunteer to be a coordinator for such \n> projects, as I'm already swamped.  I simply wish to put the idea in front \n> of the list members to see what you all think.\n\nIt would certainly be interesting to do conversions, or partial conversions \non high profile sites, and if enough people were interested I may be able \nto give some time to coordinate things. There are certainly some questions \nin my mind about the best way to do it. If anyone else is interested, give \nme a shout on or off list.\n\nAndrew\n\n--\nAndrew McFarland\nUNITE Solutions\nhttp://www.unite.net/\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "At 9:41 +0100 2002-09-24, Andrew McFarland wrote:\n>It would certainly be interesting to do conversions, or partial \n>conversions on high profile sites, and if enough people were \n>interested I may be able to give some time to coordinate things. \n>There are certainly some questions in my mind about the best way to \n>do it. If anyone else is interested, give me a shout on or off list.\n\n1. Choice of high/well known websites\n2. Traceability of the conversion (techniques used for it)\n3. Authorization of the Web site owner? (often almost impossible, \nbecause people do not reply to individual request for major websites, \nanother problem of Quality)\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "On Tue, 24 Sep 2002, Karl Dubost wrote:\n\n> 3. Authorization of the Web site owner? (often almost impossible,\n\nIANAL, but wouldn't it be a copyright law violation to recreate (copy\nand publish with modifications) a site without permission? To do a\ndecent job (in many aspects), you would need to use same images, same\ntext, same presentation style, which would require copying of\ncopyrighted things. Some say caching violates copyright law; the\nactivity being discussed is probably \"worse\" than caching from a legal\npoint of view.\n\nAs a workaround, you could start with high-profile \"open source\nfriendly\" sites like sourceforge.net or oreilly.com.\n\nAlex.\n\n-- \n                            | HTTP performance - Web Polygraph benchmark\nwww.measurement-factory.com | HTTP compliance+ - Co-Advisor test suite\n                            | all of the above - PolyBox appliance\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "> IANAL, but wouldn't it be a copyright law violation to recreate (copy\n> and publish with modifications) a site without permission? To do a\n> decent job (in many aspects), you would need to use same images, same\n> text, same presentation style, which would require copying of\n> copyrighted things. Some say caching violates copyright law; the\n> activity being discussed is probably \"worse\" than caching from a legal\n> point of view.\n\nI don't think this is a problem in this case--Eric's effort is clearly\nan academic one where the content is necessary to illustrate a\npoint. This falls under the category of fair use.\n\n\n\n"
        },
        {
            "subject": "XHTML 2  WTF",
            "content": "Hi there\n\nI was just reading over an article called \"The Web's Future\"\n( http://www-106.ibm.com/developerworks/library/wa-xhtml/?n-wa-9192 )\n\nThis is kinda interesting BUT I've some questions\n\nThere is the thought of replacing the <br /> tag with \n<line>content</line> which to me makes NO sense at all. For one it \nbloats your files, and if I wanted to wrap things I'd do it with a P \ntag or a SPAN style\n\nAnd what's this rumor about removing the <img /> tag? With an object \ntag... hmm what about ALT tags and such like for accessability?\n\nI do like the new HREF becoming part of the common attrributes .. but \nagain what about accessability on these?\n\nAnyone care to clear up some of these ... I know it's still a rough \nworking draft ... but some of it sounds cool, some of it leaves me \nwondering :)\n\nK.\n-- \nKeran McKenzie\nFounder | Kiwi Interactive Ltd\n\nhttp://pnut.studiowhiz.com (thoughts)\nhttp://www.studiowhiz.com (Web Resources)\nhttp://www.flashcomponent.com (MX Components)\nhttp://www.kiwi-interactive.com (Web Dev Company)\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2  WTF",
            "content": "Keran McKenzie wrote:\n> There is the thought of replacing the <br /> tag with \n> <line>content</line> which to me makes NO sense at all. For one it \n> bloats your files, and if I wanted to wrap things I'd do it with a P \n> tag or a SPAN style\n\nbr is supposed to be presentational whereas line isn't.. i don't really \ncare either way, personally.\n\n> And what's this rumor about removing the <img /> tag? With an object \n> tag... hmm what about ALT tags and such like for accessability?\n\nFirstly, they're alt attributes not tags. Secondly, object is *more* \naccessible. the alt attribute was whacked on at the last minute to add \nacessibility, whereas object is designed for it. If a user agent doesn't \nsupport the content-type of the object, then it falls back by parsing \nit's children instead. Thus you can have multiple nested objects, and \nyour alt text is replaced by what is inside the object tags. Thus you \ncan also tags for its 'alternative' text, as well as all the other \nthings that tag contents can do which attributes can't.\n\n> I do like the new HREF becoming part of the common attrributes .. but \n> again what about accessability on these?\n\nWhat about it?\n-- \nLach\n__________________________________________\nWeb: http://illuminosity.net/\nE-mail: lach @ illuminosity.net\nMSN: luminosity @ members.evolt.org\n__________________________________________\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2  WTF",
            "content": "By the way, this is better addressed on the www-html mailing list rather \nthan this one.\n-- \nLach\n__________________________________________\nWeb: http://illuminosity.net/\nE-mail: lach @ illuminosity.net\nMSN: luminosity @ members.evolt.org\n__________________________________________\n\n\n\n"
        },
        {
            "subject": "Re: XHTML 2  WTF",
            "content": "At 09:38 PM 09/24/2002, Keran McKenzie wrote:\n>And what's this rumor about removing the <img /> tag? With an object\n>tag... hmm what about ALT tags and such like for accessability?\n\nOBJECT already has the ability to render alternative text (among other \nalternatives):\n<http://www.w3.org/TR/html4/struct/objects.html#h-13.3.1>\n\nBill Mason\nAccessible Internet\nw3c@accessibleinter.net\nhttp://www.accessibleinter.net/\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "At 08:01 24/09/2002 -0400, Karl Dubost wrote:\n>1. Choice of high/well known websites\n>2. Traceability of the conversion (techniques used for it)\n>3. Authorization of the Web site owner? (often almost impossible, because \n>people do not reply to individual request for major websites, another \n>problem of Quality)\n\nAnd 4. `Ownership' of the code. I wouldn't mind contributing to, say, \nDmoz.org[1] for free, but I wouldn't want to spend several tens (or \nhundreds) of hours on a commercial website without some benefit to me. This \nis obviously even more complex when you think about a group effort.\n\nAs an initial site, it might be interesting to build a (X)HTML (4.01|1) \nStrict directory using the Dmoz.org RDF dump. Anyone any experience of \nusing Dmoz.org RDF data? Using Dmoz data would cover 3, and possibly 1.\n\n/me toddles off to cpan.org\n\nAndrew\n\n--\nAndrew McFarland\nUNITE Solutions          Phone 028 9077 7338\nhttp://www.unite.net/    Fax   028 9077 7313\n\n[1] The home page at least is Valid 4.01 Transitional\n\n\n\n"
        },
        {
            "subject": "Re: Please visit HiSoftware and Microsoft for a FREE seminar on  &quot;Achieving and Maintaining Accessible Web site solutions.&quot",
            "content": "----- Original Message -----\nFrom: \"Dana Louise Simberkoff\" <danalouise@hisoftware.com>\nTo: <w3c-wai-ig@w3.org>\nSent: Tuesday, September 24, 2002 8:58 PM\nSubject: Please visit HiSoftware and Microsoft for a FREE seminar on\n\"Achieving and Maintaining Accessible Web site solutions.\"\n\n> Please visit HiSoftware and Microsoft for a FREE seminar on Achieving and\n> Maintaining Accessible Web site solutions.\n\nPerhaps it may be useful to explain what you mean by \"Accessible Web site\nsolutions\", taking into account that the \"accessible\" website\nhttp://www.microsoft.com/enable/ (meant to be a live demonstration of how to\ndo it) is neither accessible nor usable due to \"sloppy authoring practices\nmade possible by bugs in Explorer\". Unreadably tiny fonts, inaccessible\nsearch bars in Mozilla.\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "At 8:26 +0100 9/25/02, Andrew McFarland wrote:\n\n>At 08:01 24/09/2002 -0400, Karl Dubost wrote:\n>>1. Choice of high/well known websites\n>>2. Traceability of the conversion (techniques used for it)\n>>3. Authorization of the Web site owner? (often almost impossible, \n>>because people do not reply to individual request for major \n>>websites, another problem of Quality)\n\n    I will say that I didn't ask KPMG if I had permission to fix their \nsite, I just did it on the grounds that they obviously weren't about \nto do it themselves.  Then again, I picked a case where the site was \nso badly broken in Gecko-based browsers that I figured they'd be \nhappy to have a fix offered to them.  If I'm wrong, they'll probably \nsend me a cease-and-desist order, and which point I'll cease and \ndesist.  And post about it.\n\n>And 4. `Ownership' of the code. I wouldn't mind contributing to, \n>say, Dmoz.org[1] for free, but I wouldn't want to spend several tens \n>(or hundreds) of hours on a commercial website without some benefit \n>to me.\n\n    In the first place, an effort of the kind I undertook isn't one of \ntens or hundreds of hours.  I invested less than three hours in \nfixing the DOM scripting and tweaking a bit of HTML, and I'm not even \na DOM expert.  Ironically, I didn't even touch their CSS.  I imagine \nsomeone familiar with the DOM and Javascript could have done what I \ndid in half the time, or less.  So let's assume a full-on makeover of \nthe site would take 20 hours.  Divide that up between four people and \nyou get maybe six hours per person, once accounting for overlapped \neffort, which is inevitable in any team project.  That's not an \nunreasonable investment, in my opinion.\n    As for the benefit to you, it's derived from demonstrating that \nstandards support is more powerful and easier to accomplish than most \npeople seem to realize.  It's also possible that you'd get some \nbenefit from having your name associated with such a project, or \nseries of projects.  I'm more concerned with the benefit such efforts \nwould confer on the community as a whole, not to mention the users of \nthe sites that get fixed.\n\n--\nEric A. Meyer  (eric@meyerweb.com)  http://www.meyerweb.com/eric/\nAuthor, \"Cascading Style Sheets: The Definitive Guide,\"\n  \"Eric Meyer on CSS,\" \"CSS 2.0 Programmer's Reference,\" and more\n   http://www.meyerweb.com/eric/books/\n\n\n\n"
        },
        {
            "subject": "Re: Converting to standards... (sort of",
            "content": "At 10:38 25/09/2002 -0400, Eric A. Meyer wrote:\n>    In the first place, an effort of the kind I undertook isn't one of \n> tens or hundreds of hours.  I invested less than three hours in fixing \n> the DOM scripting and tweaking a bit of HTML, and I'm not even a DOM \n> expert.\n\nI think the amount of time is very much dependant on how the site is \ngenerated, and how much of the site needs fixed. A dynamically generated \nsite can be very easy to fix, or an absolute nightmare, depending on the \nunderlying programming.\n\nI recently fixed up a small site, entirely static HTML, for one of our \nclients. The markup was completely unstructured and it took me the best \npart of a working week to get it to the stage where CSS could be applied \nwith consistency.\n\nWere you thinking of individual page fixes or whole site corrections?\n\n<snip/>\n>    As for the benefit to you,\n\nDon't worry, I wasn't being completely mercenary :-). I live an annoyingly \nbusy life at the moment, and whereas I would be happy to work on projects \nfor the good of the Internet as a whole, I am reluctant to spend a lot of \ntime fixing a commercial website for free. A few hours per week on \ncommercial websites would be OK.\n\nAndrew\n\n--\nAndrew McFarland\nUNITE Solutions          Phone 028 9077 7338\nhttp://www.unite.net/    Fax   028 9077 7313\n\n\n\n"
        },
        {
            "subject": "PCMag ranks the browsers and says IE6 is the bes",
            "content": "The October 15, 2002 issue of PC Magazine has an article on page 116 (The Bionic\nBrowser; referred to as \"Better Browsers\" on the spine) that gives IE6 the\nEditors' Choice pick, and explains this by its \"ability to render every page\nsmoothly, its respectable feature set\".\n\nhttp://www.pcmag.com/article2/0,4149,541235,00.asp\n\nIMHO, the editors deserve some counterpoint that tells the rest of the story, so\nget your pencils and keyboards ready!\n\nFor instance, they extoll that \"Microsoft is now committed to the standards set\nby the World Wide Web Consortium\", while at the same time deriding\nMozilla1/Netscape 7 for not supporting \"nonstandard JavaScript Dynamic HTML\nfeatures that work well in older IE and Netscape versions.\"\n\nThis also sparked an idea--it would be quite helpful if someone could compile a\nlist of sites or test suites that are designed to follow the specs without\nresorting to fallback hacks and non-standard code. Such a list is exactly the\nthing we need in order to counter people that think IE6 or other browsers\n\"render every page smoothly\".\n\nHeck; I'll volunteer to maintain that list, if others can help me flesh it out.\n\nThe first obvious choice is Eric Meyer's css/edge--but what else is out there?\n\n\n\n\napplication/x-pkcs7-signature attachment: smime.p7s\n\n\n\n\n"
        },
        {
            "subject": "PCMag ranks the browsers and says IE6 is the best..",
            "content": "The October 15, 2002 issue of PC Magazine has an article on page 116 (The Bionic\nBrowser; referred to as \"Better Browsers\" on the spine) that gives IE6 the\nEditors' Choice pick, and explains this by its \"ability to render every page\nsmoothly, its respectable feature set\".\n\nhttp://www.pcmag.com/article2/0,4149,541235,00.asp\n\nIMHO, the editors deserve some counterpoint that tells the rest of the story, so\nget your pencils and keyboards ready!\n\nFor instance, they extoll that \"Microsoft is now committed to the standards set\nby the World Wide Web Consortium\", while at the same time deriding\nMozilla1/Netscape 7 for not supporting \"nonstandard JavaScript Dynamic HTML\nfeatures that work well in older IE and Netscape versions.\"\n\nThis also sparked an idea--it would be quite helpful if someone could compile a\nlist of sites or test suites that are designed to follow the specs without\nresorting to fallback hacks and non-standard code. Such a list is exactly the\nthing we need in order to counter people that think IE6 or other browsers\n\"render every page smoothly\".\n\nHeck; I'll volunteer to maintain that list, if others can help me flesh it out.\n\nThe first obvious choice is Eric Meyer's css/edge--but what else is out there?\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "You might be familiar with RichInStyle.com's Test Suite?\nhttp://www.richinstyle.com/test/\nGenerated from a database of 2000 tests with results submission and \nautomatic reporting on bugs, etc.\n\nThey also have a Bug Table generated from the results, which will show you \njust how buggy your browser really is: \nhttp://www.richinstyle.com/php/results.php\n\nShould be everything you're looking for.\nGo Moz !  :)\n\nd.\n\nAt 01:29 PM 9/27/2002 -0700, Peter Sheerin wrote:\n>This also sparked an idea--it would be quite helpful if someone could \n>compile a\n>list of sites or test suites that are designed to follow the specs without\n>resorting to fallback hacks and non-standard code. Such a list is exactly the\n>thing we need in order to counter people that think IE6 or other browsers\n>\"render every page smoothly\".\n>\n>Heck; I'll volunteer to maintain that list, if others can help me flesh it \n>out.\n>\n>The first obvious choice is Eric Meyer's css/edge--but what else is out there?\n\n\ndamien du toit\n\nurl: http://www.coda.co.za\ncell: +27 (0)82 7807118\nicq: 2099552\ngps: cape town, south africa\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "At 19:01 +0200 9/28/02, damien wrote:\n>You might be familiar with RichInStyle.com's Test Suite?\n>http://www.richinstyle.com/test/\n>Generated from a database of 2000 tests with results submission and\n>automatic reporting on bugs, etc.\n>\n>They also have a Bug Table generated from the results, which will\n>show you just how buggy your browser really is:\n>http://www.richinstyle.com/php/results.php\n>\n>Should be everything you're looking for.\n\n    Unfortunately, several of the tests in that suite have been shown \nto be incorrect, which thus throws the accuracy of the results into \ndoubt.  See <http://bugzilla.mozilla.org/show_bug.cgi?id=153699> for \na discussion of these tests.\n\n--\nEric A. Meyer  (eric@meyerweb.com)  http://www.meyerweb.com/eric/\nAuthor, \"Cascading Style Sheets: The Definitive Guide,\"\n  \"Eric Meyer on CSS,\" \"CSS 2.0 Programmer's Reference,\" and more\n   http://www.meyerweb.com/eric/books/\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "My concern with IE and other browser like it is that it \"fixes\" problems\nwith code so that Web developers and users never know if there is a\npotentially serious problem with a page such as a missing tag or botched\ncode on a secured page that would make the page unsecure.  The last browser\nto require Web developers to code page correctly was Netscape Communicator\n4.79.  I still use this browser and, because of it I am able to launch top\nquality Websites.  I also find a lot of poorly coded Websites, many of them\nhigh-profile, corporate Websites!  The frequency of discovery is increasing!\n\nSandra.\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "On Saturday, September 28, 2002, 11:33:27 PM, you wrote:\n> My concern with IE and other browser like it is that it \"fixes\" problems\n> with code so that Web developers and users never know if there is a\n> potentially serious problem with a page such as a missing tag or botched\n> code on a secured page that would make the page unsecure.\n\nIt shouldn't always be the job of the browser to validate. What do\nyou suggest MS do? Make IE chuck an error if it finds an invalid tag?\nMake thousands of websites instantly stop working and annoy users?\n\n> The last browser to require Web developers to code page correctly\n> was Netscape Communicator 4.79.  I still use this browser and,\n> because of it I am able to launch top quality Websites.\n\n!\n\nSorry, why exactly are you on a standards evangelist list? I believe\nyour definition of correct HTML will differ from just about everyone\nelse on this list.\n\n> I also find a lot of poorly coded Websites, many of them\n> high-profile, corporate Websites!  The frequency of discovery is\n> increasing!\n\nEr... lucky you. Or something.\n\nMaybe it isn't in fact they're being marked-up worse, more than\nthey're moving to standards, and don't work in your broken and\noutdated browser?\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "It shouldn't always be the job of the browser to validate. What do\nyou suggest MS do? Make IE chuck an error if it finds an invalid tag?\nMake thousands of websites instantly stop working and annoy users?\n\nNo.  I expect Web developers to do shoddy work and get away with it.  That\nway, if I enter my credit card number on a less-than-secure page on, say\nAmazon.com, the entire world will have it.\n\n> The last browser to require Web developers to code page correctly\n> was Netscape Communicator 4.79.  I still use this browser and,\n> because of it I am able to launch top quality Websites.\n\nWell then, define correct HTML for me.\n\nPending your response, I view my pages in Netscape (and IE) to see how the\nbrowser will render them.  Netscape is honest enough to \"tell\" me when a\ntable or paragraph tag is missing.  It doesn't try to do my thinking for me.\nBrowser standards should require correct coding not gloss over sub-quality\nwork.\n\nEr... lucky you. Or something.\n\nMaybe it isn't in fact they're being marked-up worse, more than\nthey're moving to standards, and don't work in your broken and\noutdated browser?\n\nI have a Pentium-1 computer that works just fine, except for the computer\nindustry's planned obsolesence, which renders a perfectly good computer\nuseless.  Outdated is a relative, and in the computer industry,\npredetermined term.  Likewise, Netscape 4.79 works quite well.  However,\nbecause Microsoft has the computer industry by the prverbial floppy disks,\nthe \"standardars\" are leaning in its direction.  Consequently, everthing\nthat is contrary to the proclaimations of Bill Gates (who legally should be\nin jail) is considered broken and outdated.\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "> Likewise, Netscape 4.79 works quite well.  However,\n> because Microsoft has the computer industry by the prverbial floppy disks,\n> the \"standardars\" are leaning in its direction.  Consequently, everthing\n> that is contrary to the proclaimations of Bill Gates (who legally should be\n> in jail) is considered broken and outdated.\n\nNetscape 4.79 does not work quite well, thank you. Please fire it up and then\ndirect it at this address:\n\nhttp://www.cadenceweb.com:8080/newsletter/sheerin/webstandards/\n\nThis page is composed using nearly web standards that are 4-1/2 years old, and\nwhile you can see most of the content with Netscape 4.79, many things do not\nrender correctly at all. Here's a list of the most obvious things, starting at\nthe top of the page:\n\n* The PNG images do not render correctly--their transparency is ignored and the\ncolors are changed.\n* The linked style sheet is not loaded, removing all of the formatting,\nincluding page layout and text formatting.\n* This is a good thing, though, since if the style sheet were loaded, the page\nwould be formatted in a way\nthat renders it useless.\n* Many important characters from Unicode are not displayed--even though unicode\nis more than a decade old.\n\nOh, I almost forgot--most of that same list applies to IE6 for Windows as\nwell--good proof that most of us on this list are not holding up Microsoft as an\nexample of standards and progress.\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "I did not say that Netscape 4.79 was a standard.  I stated that I like the\nfact that Netscape does not let me get away with sloppy code.\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "On Sunday, September 29, 2002, 8:40:55 PM, SanJo;) wrote:\n> > The last browser to require Web developers to code page correctly\n> > was Netscape Communicator 4.79.  I still use this browser and,\n> > because of it I am able to launch top quality Websites.\n> \n> Well then, define correct HTML for me.\n\nhttp://www.w3.org/TR/html4/ - Tada!\n\nAlthough, NS4 and IE/win's HTML4 support is comparable - the support\nfor other technologies such as CSS is what really matters.\n\n> Pending your response, I view my pages in Netscape (and IE) to see\n> how the browser will render them.  Netscape is honest enough to\n> \"tell\" me when a table or paragraph tag is missing.  It doesn't try\n> to do my thinking for me. Browser standards should require correct\n> coding not gloss over sub-quality work.\n\nNS6+, Mozilla and other Gecko-powered browsers can often be *much*\nstricter in parsing HTML too. In fact, if you use XHTML and serve it\nwith a correct MIME type like application/xhtml+xml, then one unclosed\ntag and the page won't render at all.\n\nBut they will still attempt to parse and render \"tag soup\" pages -\nthey have to, or nobody would even consider using them.\n\n> Outdated is a relative, and in the computer industry, predetermined\n> term.  Likewise, Netscape 4.79 works quite well.\n\nNetscape 4 is an outdated, old, obsolete, stoneage, broken,\nnon-standard, and generally buggered-up browser. Do the Web a favour\nand upgrade to a modern, standards-compliant browser. Or even\ndowngrade! At least NS3 didn't attempt to parse CSS and then fail\ndreadfully.\n\nAnd just a quick question: why on earth are you on this list when you\nuse NS4?\n\n\nThanks\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": ">I did not say that Netscape 4.79 was a standard.  I stated that I like the\n>fact that Netscape does not let me get away with sloppy code.\n\nIn other words, NS4's fragility is what makes it useful as a debugging\ntool.  I agree -- in many cases, for better or worse, the view from\nNetscape 4 represents my lowest common denominator.  The way it hurls\nJavaScript errors at you can also be useful.  I launch Netscape 4.8 several\ntimes a week for this very reason, although I can't say I surf with it.\nCatching sites with their HTML-pants-down is easy enough using any non-MS\nbrowser.\n\nWhenever I experience a modern site that looks really cool (in Mozilla), I\nthrow Netscape 4 at it to see what happens.  If the result is a horrid\ndisaster, I don't think less of them.  But if it still looks presentable, I\nhave a great example of flexible website coding.\n\nI know a lot of people have anger issues with version 4, but it's all so\nlong ago now: the company that made that browser has largely ceased to\nexist, so different is the AOL/Mozilla group.  The old Netscape made a lot\nof mistakes on their road to eventual greatness, and the view from NS4\ncertainly isn't _correct_.  It's just _traditional_, in a \"five years\nhence\" kind of way.\n\nTemporarily viewing the world through this lens is educational, for the\nsake of the NS4 folks still at large.  It's like donning glasses that\ndistort your sight, to see how people with visual disabilities can read\nyour literature.  Running NS4 doesn't make you evil, although running it\nfull-time seems a little weird.  Same metaphor -- take those glasses off!\n\n-Joseph\n\n\n\n"
        },
        {
            "subject": "How we evangelise (Re: PCMag ranks the browsers and says IE6 is the best...",
            "content": "Hello all,\n\nEven with the risk of being stoned, I'm going to speak my mind\non this matter.\n\nOn Sun, Sep 29, 2002 at 01:53:23AM +0100, Tom Gilder wrote:\n> \n> > The last browser to require Web developers to code page correctly\n> > was Netscape Communicator 4.79.  I still use this browser and,\n> > because of it I am able to launch top quality Websites.\n> Sorry, why exactly are you on a standards evangelist list? I believe\n> your definition of correct HTML will differ from just about everyone\n> else on this list.\n> \n> > I also find a lot of poorly coded Websites, many of them\n> > high-profile, corporate Websites!  The frequency of discovery is\n> > increasing!\n> \n> Er... lucky you. Or something.\n> \n> Maybe it isn't in fact they're being marked-up worse, more than\n> they're moving to standards, and don't work in your broken and\n> outdated browser?\n\nI'm sorry, but I don't think the kind of attitude I've just read in\nthe last mails on this thread is at all helpful to our evanglism efforts. \nWhether email-authors really meant to sound harsh or not, I've cringed\nat the responses so far to Sandra's email (except for Joseph's).\n\nPersuasion by evidence in a gentle, educative manner is a far more effective\nmethod than throwing rocks, damaging someone else's pride and then having\nthem trying to throw something back at you.\n\nOkay, so (I hope) most of us think that NS 4.x is an outdated and broken \nbrowser, but we should not condemn those who still use it. I know a couple\nof large corporations still stuck with it because Communicator 4.x had\nfeatures which are tied together with iPlanet server features which\nare (I believe) not available with NS 7 (such as Calendar). \n\nI remember an individuals or two who were worried about upgrading\nbecause they were worried about what might happen to their mail,\nand so forth.  \n\nIt's not good enough to just say 'NS 4 is obsolete, upgrade!' sometimes.\n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "From: \"Tom Gilder\" <tom@tom.me.uk>\n> And just a quick question: why on earth are you on this list when you\n> use NS4?\n\nI find this a rather odd question. Isn't the whole point of adopting\nstandards based approach to web design that of getting away from\nbrowser-dependant authoring? Surely the choice of browser is inconsequential\nsince standards compliant websites are more accessible to more browsers\nanyway. Therein lies the value of adopting standards-based approaches.\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "On Monday, September 30, 2002, 9:16:38 AM, Isofarro wrote:\n> > And just a quick question: why on earth are you on this list when you\n> > use NS4?\n> \n> I find this a rather odd question. Isn't the whole point of adopting\n> standards based approach to web design that of getting away from\n> browser-dependant authoring? Surely the choice of browser is inconsequential\n> since standards compliant websites are more accessible to more browsers\n> anyway. Therein lies the value of adopting standards-based approaches.\n\nBrowser-dependant authoring, yes, but that's only possible if the\nbrowsers support the standards in the first place. NS4 does not. NS4\nscrews many of them - especially CSS - very much up.\n\nIf authors didn't use work-arounds (media=\"all\", @import, comment\nhacks) for NS4, most pages that use CSS extensively will either render\nunreadable at best and totally crash the browser at worst.\n\nNS4 has been - and continues to be - one of the major problems in\ngetting people to use standards. Most NS4 users still unfortunately\nexpect to load pages, and have them look nice.\n\nAnd yes, yes, you can make a validating page that looks OK-ish in NS4.\nEither making a hacked-together CSS file or using transitional HTML\nand tables - but this isn't ideal by any means.\n\nThe faster NS4 users are obliterated the faster standards will be\naccepted and used.\n\n-- \nTom Gilder\nhttp://tom.me.uk/\n\n\n\n"
        },
        {
            "subject": "RE: How we evangelise (Re: PCMag ranks the browsers and says IE6 is the best...",
            "content": "Thank you.\n\nSandra.\n\n-----Original Message-----\nFrom: public-evangelist-request@w3.org\n[mailto:public-evangelist-request@w3.org]On Behalf Of steph\nSent: Sunday, September 29, 2002 11:05 PM\nTo: public-evangelist@w3.org\nSubject: How we evangelise (Re: PCMag ranks the browsers and says IE6 is\nthe best...)\n\n\n\nHello all,\n\nEven with the risk of being stoned, I'm going to speak my mind\non this matter.\n\nOn Sun, Sep 29, 2002 at 01:53:23AM +0100, Tom Gilder wrote:\n>\n> > The last browser to require Web developers to code page correctly\n> > was Netscape Communicator 4.79.  I still use this browser and,\n> > because of it I am able to launch top quality Websites.\n> Sorry, why exactly are you on a standards evangelist list? I believe\n> your definition of correct HTML will differ from just about everyone\n> else on this list.\n>\n> > I also find a lot of poorly coded Websites, many of them\n> > high-profile, corporate Websites!  The frequency of discovery is\n> > increasing!\n>\n> Er... lucky you. Or something.\n>\n> Maybe it isn't in fact they're being marked-up worse, more than\n> they're moving to standards, and don't work in your broken and\n> outdated browser?\n\nI'm sorry, but I don't think the kind of attitude I've just read in\nthe last mails on this thread is at all helpful to our evanglism efforts.\nWhether email-authors really meant to sound harsh or not, I've cringed\nat the responses so far to Sandra's email (except for Joseph's).\n\nPersuasion by evidence in a gentle, educative manner is a far more effective\nmethod than throwing rocks, damaging someone else's pride and then having\nthem trying to throw something back at you.\n\nOkay, so (I hope) most of us think that NS 4.x is an outdated and broken\nbrowser, but we should not condemn those who still use it. I know a couple\nof large corporations still stuck with it because Communicator 4.x had\nfeatures which are tied together with iPlanet server features which\nare (I believe) not available with NS 7 (such as Calendar).\n\nI remember an individuals or two who were worried about upgrading\nbecause they were worried about what might happen to their mail,\nand so forth.\n\nIt's not good enough to just say 'NS 4 is obsolete, upgrade!' sometimes.\n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "I am very much in favor of standards.  When not building or maintaining\nWebsites, I use Mozilla, which I love.  I would like to learn about the\nstandards and possibly even contribute to them.  However, with all of the\negos present on this list, I do not believe that the standards that you\nestablish would be readily accepted by most since the tone presented on this\nlist is so offensive.  Before discussing Web standards, how about\nestablishing a little Netiquette.\n\nSandra.\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "I concur.  However, I believe that the problem browser was Netscape 4.76 not\n4.79.  In any case, hopefully, Mozilla will be aggressive in hawking its\nbrowser as a viable alternative to IE.  For that matter, maybe the Linux and\nUnix communittees will get their acts together and launch a decent offense\nagainst Microsoft and present a higher quality standard for the entire Web\nindustry.  I just felt like saying that.\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "The real question that you need to ask yourself is why are you so obnoxious?\nHave standards replaced Netiquette?\n\nSandra.\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "Citando \"SanJo ;->\" <tumkho@earthlink.net>:\n\n> I am very much in favor of standards.  When not building or maintaining\n> Websites, I use Mozilla, which I love.  I would like to learn about the\n> standards and possibly even contribute to them.  However, with all of \n> the\n> egos present on this list, I do not believe that the standards that you\n> establish would be readily accepted by most since the tone presented on\n> this list is so offensive.  Before discussing Web standards, how about\n> establishing a little Netiquette.\n>\n> Sandra.\n\nHello Sandra and everyone else,\n\nas far as I know, everyone of us are after standards. Everybody has \nmuch to\nlearn, but also much to share. Thus, existence of this list can be \nconsidered\nvery practical.\n\nI know you feel offended due to many comments posted last few days. \nHowever,\nthere are many point of views and one never can assume his/her own \nopinion\nis the \"absolute truth\".\n\nIt's no use to have hostile environment on this list and I'll believe \nthere's\nnothing personal in the air. Personally, I hope you stay with us and \nhelp\nbuilding Web to be better place both for designers and users.\n\nRegards,\nZvona\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "I think we all agree that the Web would be a much better place if NN4.x \nwould go away and everyone would upgrade to the newest, best compliant \nbrowser. But unfortunantly it is not going to happen very soon. I have \ntalked with several NN4.x users that were burnt with Netscape's 6 \nversion browser and are still leery of getting 7. While many of these \npeople are not very Web savvy they have been on line long enough to have \nstarted when Netscape was the browser of choice. The company I work for \nhad 4.x as the company standard for several years. I am getting many in \nthe IIS department to change to Mozilla and sometime we will roll it out \ncompany wide as the standard.\n\nWith working on a Web site for a company that caters to mostly rural \nWestern Kansas USA, I use standards and accessibility as much as I \npossibly can, but sometimes I have to flex. The Web is still evolving \nand we should push as hard as we can for standards, but still understand \nthat each site has its own needs for its users.\n\n-- \nRandy Reames > Web Developer > Midwest Energy\nI use OS X and Linux. I use the Mozilla browser.\nI support Web Standards and Accessibility.\nblog: www.reames.org   work: www.mwenergy.com\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "From: \"Tom Gilder\" <tom@tom.me.uk>\n> On Monday, September 30, 2002, 9:16:38 AM, Isofarro wrote:\n> > Isn't the whole point of adopting\n> > standards based approach to web design that of getting away from\n> > browser-dependant authoring?\n>\n> Browser-dependant authoring, yes, but that's only possible if the\n> browsers support the standards in the first place. NS4 does not. NS4\n> screws many of them - especially CSS - very much up.\n\nIMO, CSS is a nice-to-have and not essential to creating a standards\ncompliant website. As long as Netscape 4 can handle the clean HTML it is\ngiven, then it is a satisfactory way of determining whether HTML4.01 markup\nis correct. I am open to correction on its handling of XHTML however.\n\n> NS4 has been - and continues to be - one of the major problems in\n> getting people to use standards.\n\nIMO, the sheer volume of error correction in mainstream browsers is more of\na problem, since it hides the real problem. The only effective way to\neducate people to discard tag-soup based solutions is to see it fall apart,\nand eliminate all the \"other\" arguments such as this website wasn't designed\nfor pocket computers.\n\n> Most NS4 users still unfortunately\n> expect to load pages, and have them look nice.\n\nThen those expectations need to be _managed_, not delivered with an\nunjustifiable cost of inaccessibility.\n\n> The faster NS4 users are obliterated the faster standards will be\n> accepted and used.\n\nI am not convinced that Netscape 4 users can dominate requirements in this\nway - judging from the plethora of Internet only websites (such as KPMG) as\nexamples.\n\nIMO the faster the dangers of error correction is shown, the easier it will\nbe to advocate a standards based replacement. Exercises like Eric Meyer's\nfix-up of KPMG do far more for standards advocacy than trying to kill of\nNetscape 4.\n\nEven when there are no more Netscape 4 users out there, I doubt there will\nbe a reduction of tag-soup websites - since \"it works in Internet Explorer,\nso why bother?\"\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "Hello all on this list,\n\nIn a German fansite in a page with  important links for fans of the\nband, I also have  links to all the latest versions of the most usual\nbrowsers (also Lynx and Jaws).\n\nIn pages that are not looking well in Netscape 4 at all, I wrote a\nsidebar with the text: When you think the page is not looking nice, why\nshould not you upgrade to the newest Mozilla version?.\n\nIs this perhaps an idea for your pages too?\n\nI only use valid  XHTML 1.1 and CSS. With javascript I send a base\nstylesheet to Netscape 4 and WebTV (is also very bad)\n\nBesites...Amaya is also not so very well in supporting CSS\n\nIn Germany 10% of the users still always have Netscape 4X. I also have\nNetscape 4.71 and this is also very bad. Of course also mozilla 1.1,\nOpera 6.05 and others..\n.\n\nGreetings\nIneke van der Maat\n\n\n\n"
        },
        {
            "subject": "[publicevangelist] &lt;none&gt",
            "content": "ke>\nSubject: Re: PCMag ranks the browsers and says IE6 is the best...\nDate: Mon, 30 Sep 2002 14:40:47 -0000\nMIME-Version: 1.0\nContent-Type: text/plain;\ncharset=\"iso-8859-1\"\nContent-Transfer-Encoding: 7bit\nX-Priority: 3\nX-MSMail-Priority: Normal\nX-Mailer: Microsoft Outlook Express 5.50.4522.1200\nX-MimeOLE: Produced By Microsoft MimeOLE V5.50.4522.1200\n\n\"Ineke van der Maat\" <inekemaa@xs4all.nl>\n> In pages that are not looking well in Netscape 4 at all, I wrote a\n> sidebar with the text: When you think the page is not looking nice, why\n> should not you upgrade to the newest Mozilla version?.\n>\n> Is this perhaps an idea for your pages too?\n\nI believe this should be a very rare thing to do, people are coming for\nyour content - ie we trust you on information about the band, whilst we\nknow we can trust you for browser evangelism, encouraging the general\nsite author to do the same is unconstructive.\n\n> I only use valid  XHTML 1.1 and CSS.\n\nIn which case you SHOULD NOT be sending it as text/html and Netscape 4\nwill not be even trying to render the document so NN4's handling is\npretty irrelevant, or if you are sending it as text/html, then can I\nevangelise the use of W3's recommendations and recommend you use the\ncorrect mime-type. (or a correct version of HTML for text/html.)\n\n> With javascript I send a base\n> stylesheet to Netscape 4 and WebTV (is also very bad)\n\nPlease do not mis-use javascript in this manner.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "Isofarro wrote:\n> From: \"Randy Reames\" <randy@reames.org>\n> \n>>I think we all agree that the Web would be a much better place if NN4.x\n>>would go away and everyone would upgrade to the newest, best compliant\n>>browser.\n> \n> \n> I don't see how upgrading to a browser that allows a web author to get away\n> with tag-soup is any better. Netscape 4 is only an excuse to use tag soup.\n> Removing the excuse just hits us with the next brick wall \"Well it still\n> works in IE\".\n\nAgreed, now if every Web site builder and browser maker would understand \n  this. But that is why this list and other organizations promoting Web \nStandards are here for.\n\n> There needs to be a rational and practical understanding of why tag soup and\n> nested layout tables is a bad thing - IMO its not about modern browsers,\n> since they don't have a problem with tagsoup. Until that is tackled\n> seriously, its going to be a long struggle to entice web authors to\n> compliancy, because what they do now looks like it works.\n> \n> I feel that we need to start stressing the importance of non-browser\n> agents - this is probably a stronger argument for clean HTML and CSS\n> presentation separation. Although I am biased, I have a strong interest in\n> intelligent agent technologies and leveraging information on the World Wide\n> Web\n> \n> I think the problem is that the perception of the World Wide Web is as a\n> TV-like visual only medium, a marketing billboard, rather than an\n> interactive source of information. If we can stress the value of\n> information, and why it needs to be released from the confines of its\n> presentation, then we start making some inroads toward clean markup.\n> \n> Its not about browsers, its about people and their Web user-agents. Until\n> the perception of the World Wide Web as a browser-dependant experience is\n> tackled, then the arguments for standards compliancy remains weak.\n\nI also agree, although testing with links and/or lynx does not give \ncomplete accuracy of how a screen reader or other agents perform it is a \ngood test, and sometimes I do use lynx quite a bit myself.\n\n> \n>>The Web is still evolving\n>>and we should push as hard as we can for standards, but still understand\n>>that each site has its own needs for its users.\n> \n> \n> The strongest and most compelling reason for standards and accessibility is\n> the benefit it gives to visitors. The Web has more readers than writers.\n\nWeb site builders and browser makers are the ones that need the most \nconvincing. Average users for the most part do not really care. It's \nlike the long time Linux users vs Windows users. Linux users say \"It \nshould be done this way.\" Windows users say \"Why? It works fine this \nway.\" Linux \"But it's wrong.\" Windows \"oh well, it works for me.\" and \nround and round.\n\nAlthough there is probably a better solution. I still use the \ndisplay:none and have a small note that says \"This site may be viewed in \nany browser or Internet device, but looks best in one that complies with \n   Web Standards.\" With a link to the Web Standards Project, in hopes \nthat some user or author may click on through and get an understanding \nof what Web Standards are.\n\n-- \nRandy Reames > Web Developer > Midwest Energy\nI use OS X and Linux. I use the Mozilla browser.\nI support Web Standards and Accessibility.\nblog: www.reames.org   work: www.mwenergy.com\n\n\n\n"
        },
        {
            "subject": "Re: PCMag ranks the browsers and says IE6 is the best..",
            "content": "Can I return to the original subject for a second...\n\nAfter having read the PCMag review, I registered on their site with the \nintention of posting my own review - I just couldn't accept or even \nunderstand how they could give Mozilla 3/5 stars for customizability \n(compared to IE 6.0's 5/5 stars) - that, among a list of other things.\n\nThe only mention Mr Mendelson made of IE6's customizability was the following:\n\"IE's easily customized layout sports a main toolbar that can include \nbuttons to launch add-ons and a Links bar to which you can drag any \nshortcut. Windowed and full-screen viewing toggle with the F11 key or a \ntoolbar button, and you can maximize the windowed interface by switching \noff the status bars and all toolbars.\"\n\nUh. Big deal?\nWeren't these standard window features considered novel in Windows 95? That \nhe mentions these as customizability features for IE6 is a joke, when you \nconsider all the enhancements Mozilla & Netscape 7 come with - fully \nskinnable GUI, tabbed browsing, side panel, etc. And if www.mozdev.org \ndoesn't have the largest resource of add-ons for a single browser, then I \ndon't know.\n\nAnyway ... just wanted to find out if anyone had luck posting a review. I \nkeep getting a 404, or the preview page seems to enter an endless loop. :|\n\n\ndamien du toit\n\nurl: http://www.coda.co.za\ncell: +27 (0)82 7807118\nicq: 2099552\ngps: cape town, south africa\n\n\n\n"
        },
        {
            "subject": "Re: [publicevangelist] &lt;none&gt",
            "content": "Hello Jim,\n\nYou wrote:\n>Please do not mis-use javascript in this manner... <\n\nWhat is the alternative way? I only use document.write..and @import does\nnot serve any stylesheet to Netscape 4 and that is not what I want..\n\nThe content in this pages is CD-Covers and they look awfully without CSS\nin Netscape 4.71  Only in pages as these in which the picture is more\nimportant as an usual picture of the band, I have this sidebar. I\nbelieve in 4 or 5 of the more as 70 pages of the fansite.\nIn the other pages the text gives the information and the pictures are\nless important... are only meant as illustration.. There is no sidebar\nat all.\n\n>In which case you SHOULD NOT be sending it as text/html<\n\nYou mean I must serve the xhtml 1.1-site as application/xhtml+xml.. with\nencoding utf-8?\nThat is what I already did.\n\ngreetings\nIneke\n\n\n\n"
        },
        {
            "subject": "Re: [publicevangelist] &lt;none&gt",
            "content": "\"Ineke van der Maat\" <inekemaa@xs4all.nl>\n> You wrote:\n> >Please do not mis-use javascript in this manner... <\n>\n> What is the alternative way? I only use document.write..and @import\ndoes\n> not serve any stylesheet to Netscape 4 and that is not what I want..\n\nYou've not explained how you identify NN4, that is the part which you are\nmisusing, javascript has no way of knowing it is executing in NN4,\ntherefore you cannot perform some action based on that fact, anything\nyou're doing is guesswork.\n\n> >In which case you SHOULD NOT be sending it as text/html<\n>\n> You mean I must serve the xhtml 1.1-site as application/xhtml+xml..\nwith\n> encoding utf-8?\n> That is what I already did.\n\nThen Netscape 4 will not be attempt to render the document then (it\ndoesn't understand that mime-type), so you don't need to hide CSS or\nanything from it.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "Re: [publicevangelist] &lt;none&gt",
            "content": "At 10:45 AM -0400 9/30/02, Jim Ley wrote:\n>  > With javascript I send a base\n>>  stylesheet to Netscape 4 and WebTV (is also very bad)\n>\n>Please do not mis-use javascript in this manner.\n\nHow is it mis-use to send a specific stylesheet to a browser using\nJavascript?\n\n--Kynn\n\n-- \nKynn Bartlett <kynn@idyllmtn.com>                 http://kynn.com\nChief Technologist, Idyll Mountain            http://idyllmtn.com\nNext Book: Teach Yourself CSS in 24       http://cssin24hours.com\nKynn on Web Accessibility ->>          http://kynn.com/+sitepoint\n\n\n\n"
        },
        {
            "subject": "Re: [publicevangelist] &lt;none&gt",
            "content": "\"Kynn Bartlett\" <kynn@idyllmtn.com>\n> At 10:45 AM -0400 9/30/02, Jim Ley wrote:\n> >  > With javascript I send a base\n> >>  stylesheet to Netscape 4 and WebTV (is also very bad)\n> >\n> >Please do not mis-use javascript in this manner.\n> \n> How is it mis-use to send a specific stylesheet to a browser using\n> Javascript?\n\nBecause there's no way to identify a browser with javascript.\n\nJim.\n\n\n\n"
        },
        {
            "subject": "RE: PCMag ranks the browsers and says IE6 is the best..",
            "content": "> IMO, CSS is a nice-to-have and not essential to creating a standards\ncompliant website. As long as Netscape 4 can handle > the clean HTML it\nis given, then it is a satisfactory way of determining whether HTML4.01\nmarkup is correct. I am open  > to correction on its handling of XHTML\nhowever.\n\n___________________________\n\n\nSurely this depends on the level of standards that you are working to?\nOnce you move away from transitional 4.01 and 4.01 strict and xhtml, css\nisn't a nice to have, it's essential.  I'm guessing that most people on\nthis list are trying to push for:\n\nA: standards in general (in the main)\nB: a move away from html and into xhtml\n\nYes, you can have a perfectly valid page with loads of depreciated\nelements and the like using an HTML transitional DTD, but once you start\ngetting into XHTML the validity is gone.\n\nCheers\n\nFrancis\n\n\n\n"
        },
        {
            "subject": "[reminder] scope/rules of the lis",
            "content": "public-evangelist participants.\n\nI feel now is a good time to remind everyone what the scope of this \nlist is:\n\n[[\n[ excerpt from http://www.w3.org/QA/IG/#list-evangelist ]\nThis mailing-list is :\n* A place to discuss about web standards Education and Outreach with \nweb standards evangelists, authors of books, articles or other \nresources on web standards.\n* A neutral ground for communication, coordination, and \ncross-pollinisation between groups involved in web-standards Education \nand Outreach.\n* A forum to improve the quality of web-standards related books, \npublications, lectures and training courses. \n]]\n\nI would like to stress out the fact that \"*discussion* and \n*coordination* about web standards education and outreach\" is quite \ndifferent from \"*arguing* about web standards, about compliance of \nvendor X, etc\".\n\nI believe that slightly off-topics messages can lead to interesting and \nproductive results if people participate with basic netiquette and list \nscope in mind. Reviewing or asking for opinions on a resource may be a \nlittle off-topic (unless it is your resource, then it fits), but if it \nis made in a constructive way (sharing good resources, useful \ncriticism, discussing and building counter-arguments or corrections...) \nit is very welcome on the public-evangelist mailing-list. However, \n\"rants\", \"raw\" criticism, aggressive messages towards other posters, \netc. should be avoided here, as well as in any other W3C mailing-list.\n\nThis place is a wonderful forum for an important task, let's keep it \nthis way, shall we?\n\n\nYours sincerely, olivier.\n-- \nOlivier Thereaux - W3C\nmaintainer - public-evangelist@w3.org\nhttp://www.w3.org/People/olivier \n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "search featur",
            "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n"
        },
        {
            "subject": "[W3C] LogValidator Beta ",
            "content": "Hi,\n\nA new beta release of a tool helping people to improve the validity \nof their website (or any kind of criterias).\n\n\nLog Validator is a web server log analysis tool which finds the N \nmost popular documents matching a particular criteria. Thanks to its \nmodular design the criteria can be whatever one chooses, however the \nLog Validator has been first written with Validation (HTML, CSS, \netc.) It can thus help web content managers find and fix the most \nimportant invalid documents on a Web site.\n\nLog Validator - http://www.w3.org/QA/Tools/LogValidator/\nValidate your site step by step - http://www.w3.org/QA/2002/09/Step-by-step\n\n\nThe Log Validator is Free and Open Source, anyone is more than \nwelcome to use it, modify it, or develop modules for it.\n\nDownload / get the source code - \nhttp://www.w3.org/QA/Tools/LogValidator/Manual-Get\nCreating new modules - http://www.w3.org/QA/Tools/LogValidator/Manual-Modules\n\n\nThe Log Validator is under development, feedback (bug reports, \nfeature wishes, etc) is welcome on the public mailing-list of W3C's \nvalidation service (www-validator@w3.org).\n\nList archives - http://lists.w3.org/Archives/Public/www-validator/\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Web Standards Evangelist Related Blogs",
            "content": "Anyone know of any good bloggers that rant about W3C Standards, hopefully \nsomething positive?\n\nI read Kurt Cagle's stuff (not really a blog) - http://www.kurtcagle.net and \na lot fo the MS .Net bloggers, but I was looking for some other view points. \n  I have my own - www.dotnetweblogs.com/donxml , but I'm looking to cross \nlink my .Net stuff with some W3C stuff.\n\nIt would be great to get people like Chris Lilley, Dean Jackson, Liam Quin, \nMichael Kay and Dan Connolly starting blogging, and help spread the word.\n\n\nDon XML\n\nAlways listen to experts. They'll tell you what can't be done, and why. Then \ndo it.\n\n\n\n\n_________________________________________________________________\nTired of spam? Get advanced junk mail protection with MSN 8. \nhttp://join.msn.com/?page=features/junkmail\n\n\n\n"
        },
        {
            "subject": "RE: Web Standards Evangelist Related Blogs",
            "content": "Here are a few:\nwww.webstandards.org\nwww.zeldman.com\nwww.scottandrew.com\nwww.alistapart.com\nwww.glish.com\n\nbest,\n\nIva A. Koberg\nwww.livestoryboard.com \n\n\n\n>> \n>> -----Original Message-----\n>> From: public-evangelist-request@w3.org \n>> [mailto:public-evangelist-request@w3.org] On Behalf Of Don XML\n>> Sent: Thursday, April 24, 2003 5:01 PM\n>> To: public-evangelist@w3.org\n>> \n>> \n>> Anyone know of any good bloggers that rant about W3C \n>> Standards, hopefully something positive?\n>> \n>> I read Kurt Cagle's stuff (not really a blog) - \n>> http://www.kurtcagle.net and a lot fo the MS .Net bloggers, \n>> but I was looking for some other view points. \n>>   I have my own - www.dotnetweblogs.com/donxml , but I'm \n>> looking to cross link my .Net stuff with some W3C stuff.\n>> \n>> It would be great to get people like Chris Lilley, Dean \n>> Jackson, Liam Quin, Michael Kay and Dan Connolly starting \n>> blogging, and help spread the word.\n>> \n>> \n>> Don XML\n>> \n>> Always listen to experts. They'll tell you what can't be \n>> done, and why. Then \n>> do it.\n>> \n>> \n>> \n>> \n>> _________________________________________________________________\n>> Tired of spam? Get advanced junk mail protection with MSN 8. \n>> http://join.msn.com/?page=features/junkmail\n>> \n>> \n>> \n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "From: \"Don XML\"\n\n> Anyone know of any good bloggers that rant about W3C Standards,\nhopefully\n> something positive?\n\nhttp://www.accessify.com/\nhttp://www.nitot.com/\nhttp://www.nitot.com/standards/blog/\nhttp://standblog.com/\nhttp://openweb.eu.org/openwebgroup/demarche_standard/\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "From: \"Don XML\" <don_xml@hotmail.com>\nSubject: Web Standards Evangelist Related Blogs?\n\n\n> Anyone know of any good bloggers that rant about W3C Standards, hopefully\n> something positive?\n\nI have a blog covering both web accessibility and web standards at:\nhttp://www.isolani.co.uk/blog/access.html\n\nMy Semantic Web / Intelligent Agent blog is at:\nhttp://www.isolani.co.uk/blog/agents.html\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "> Anyone know of any good bloggers that rant about W3C Standards, hopefully\n> something positive?\n\nI rant and rave about standards as much as I can, the link is in my\nsignature. Here are some others that haven't been mentioned yet:\n\nhttp://tantek.com/log/\nhttp://www.digital-web.com/new/ (Nick Finck)\nhttp://diveintomark.org/\nhttp://www.pixelcharmer.com/fieldnotes/\nhttp://www.intertwingly.net/blog/\nhttp://bitworking.org/\nhttp://dougal.gunters.org/\nhttp://simon.incutio.com/\nhttp://www.dashes.com/anil/\nhttp://noeljackson.com/\nhttp://www.stopdesign.com/\nhttp://www.treetrybe.com/imm/\nhttp://jessey.net/blog/\n\nSome of these talk about standards-relevant issues more than others, but all\nevangelize the W3C through their  their actions.\n\n--Matt\nhttp://photomatt.net\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "Holly Marie a ?crit:\n\n> From: \"Don XML\" \n\n>> Anyone know of any good bloggers that rant about W3C Standards,  \n>\n> hopefully\n>\n>> something positive?\n>\n>\n> http://www.accessify.com/\n> http://www.nitot.com/\n> http://www.nitot.com/standards/blog/\n> http://standblog.com/\n> http://openweb.eu.org/openwebgroup/demarche_standard/\n\nAll those but accessify are in french. I have compiled a list of other \nfrench blogs, and plan to do the same for US bloggers that I read daily, \nto inspire my writings on the StandBlog. I'll send it to the list when \nit's done.\n\nIn the meantime, here is a FR list :\n\n   * Samuel Latchman <http://www.latchman.org/sam/>\n   * Denis Boudreau <http://www.cybercodeur.net/index.php>\n   * Emmanuel Cl?ment <http://emmanuel.clement.free.fr/blog/>\n   * Laurent Denis <http://www.blogblues.com/blog.asp>\n   * Laurent Jouanneau <http://ljouanneau.free.fr/blog/>\n   * Olivier Meunier <http://weblog.neokraft.net/>\n   * Pascale Lambert-Charreteur <http://mammouthland.free.fr/>\n   * Mathieu Pillard <http://totalementcretin.apinc.org/>\n   * Karl Dubost <http://www.la-grange.net/>\n   * Daniel Glazman <http://daniel.glazman.free.fr/weblog/>\n   * Stephanie Booth <http://www.climbtothestars.org/>\n   * Point-conforme <http://conforme.phidji.com/>\n   * Mozillazine-fr <http://mozillazine-fr.org/>\n   * Fran?ois Hodierne <http://cortexfh.free.fr/beta/news.php?t=webtek>\n   * Pascal Chevrel <http://pascal.chevrel.free.fr/carnet/>\n   * Marco Trottinet' <http://perso.wanadoo.fr/la_page_de_marco/web/>\n   * Carnets Bleus <http://www.experiense.com/carnets-bleus/>\n   * Eric Daspet <http://blog.dreams4net.com/>\n\nMany of those participate to the OpenWeb effort I have the privilege to \n\"herd\" ;-)\nhttp://openweb.eu.org/\n\n\n--Tristan\n-- \n\nhttp://devedge.netscape.com/index_fr.html\nhttp://standblog.com/\nhttp://openweb.eu.org/\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "From: \"Tristan Nitot\"\n\n\n>\n>\n> Holly Marie a ?crit:\n>\n> > From: \"Don XML\"\n>\n> >> Anyone know of any good bloggers that rant about W3C Standards,\n> >\n> > hopefully\n> >\n> >> something positive?\n> >\n> >\n> > http://www.accessify.com/\n> > http://www.nitot.com/\n> > http://www.nitot.com/standards/blog/\n> > http://standblog.com/\n> > http://openweb.eu.org/openwebgroup/demarche_standard/\n>\n> All those but accessify are in french. I have compiled a list of other\n> french blogs, and plan to do the same for US bloggers that I read\ndaily,\n> to inspire my writings on the StandBlog. I'll send it to the list when\n> it's done.\n\n\nSeems to me, I read your blog in English, too Tristan.  Several times.\n:)\nAny of these are readable via a babelfish translation, though the\nautomated translation process leaves a bit to be desired. Sometimes the\ntranslations are a bit humorous, though.\n\nI am interested in several standards blogs, so keep the list rolling. It\nMatters not if these are in other languages. [just indicate which]\nThanks for the French list...\n\nholly\nmember of several things, have a few blogs, myself ...\nbut especially love being a member of WaSP [another blog, the buzz\nblog... ]\nhttp://webstandards.org   ;)\n\n> In the meantime, here is a FR list :\n>\n>    * Samuel Latchman <http://www.latchman.org/sam/>\n>    * Denis Boudreau <http://www.cybercodeur.net/index.php>\n>    * Emmanuel Cl?ment <http://emmanuel.clement.free.fr/blog/>\n>    * Laurent Denis <http://www.blogblues.com/blog.asp>\n>    * Laurent Jouanneau <http://ljouanneau.free.fr/blog/>\n>    * Olivier Meunier <http://weblog.neokraft.net/>\n>    * Pascale Lambert-Charreteur <http://mammouthland.free.fr/>\n>    * Mathieu Pillard <http://totalementcretin.apinc.org/>\n>    * Karl Dubost <http://www.la-grange.net/>\n>    * Daniel Glazman <http://daniel.glazman.free.fr/weblog/>\n>    * Stephanie Booth <http://www.climbtothestars.org/>\n>    * Point-conforme <http://conforme.phidji.com/>\n>    * Mozillazine-fr <http://mozillazine-fr.org/>\n>    * Fran?ois Hodierne\n<http://cortexfh.free.fr/beta/news.php?t=webtek>\n>    * Pascal Chevrel <http://pascal.chevrel.free.fr/carnet/>\n>    * Marco Trottinet' <http://perso.wanadoo.fr/la_page_de_marco/web/>\n>    * Carnets Bleus <http://www.experiense.com/carnets-bleus/>\n>    * Eric Daspet <http://blog.dreams4net.com/>\n>\n> Many of those participate to the OpenWeb effort I have the privilege\nto\n> \"herd\" ;-)\n> http://openweb.eu.org/\n>\n>\n> --Tristan\n\n> http://devedge.netscape.com/index_fr.html\n> http://standblog.com/\n> http://openweb.eu.org/\n>\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "Thanks to everyone for their input.  I knew there were folks out there, but \ncouldn't find them, and knew this was the place to ask.  A writer in Silcon \nValley calls blogging  a secret society, and sometimes it does feel that \nway.  But once you get plugged in, it is anything but secret.\n\nAnd yes I know that my blog site does not validate.  It is written in \nASP.Net, and that is one of the biggest compliants, you can't produce valid \nXHTML easily.  There is a core group of .Net developers trying to work on MS \nto make it easier to produce valid XHTML, but I'm looking for more fuel to \nadd to the fire, and these blogs should help.  The problem with ASP.Net is \nthat they wanted it to render in almost any downlevel browser (like Netscape \n3), so they sacrificed sticking to known standards.\n\nPlus, the site I'm using is hosted (for free) by someone else.  I'm working \nwith others on an open source blogging system written in .Net, and that one \nI'm doing my best to make sure it validates.\n\nDon XML\n\nAlways listen to experts. They'll tell you what can't be done, and why. Then \ndo it.\n\n\n_________________________________________________________________\nMSN 8 helps eliminate e-mail viruses. Get 2 months FREE*.  \nhttp://join.msn.com/?page=features/virus\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "Don XML a ?crit:\n\n> The problem with ASP.Net is that they wanted it to render in almost \n> any downlevel browser (like Netscape 3), so they sacrificed sticking \n> to known standards.\n\ninteresting...\n\n> Plus, the site I'm using is hosted (for free) by someone else.  I'm \n> working with others on an open source blogging system written in .Net, \n> and that one I'm doing my best to make sure it validates. \n\nErr, I'm not sure you are interested, but for the bloggers among the \nlist, I just started to use B2 (GPL, available for free from \nhttp://cafelog.com ), which produces valid XHTML 1.0 transitional \ncontent out of the \"box\".\n\nI've installed it in 10 minutes on a very cheap hosting service ($15 per \nyear), http://apinc.org\n\nIt's quite interesting. Having something similar in the .Net world is \nindeed a good thing.\n\n\n--Tristan\n-- \nhttp://openweb.eu.org/\nhttp://standblog.com/\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "On Friday, April 25, 2003, 12:36:17 PM, Don XML wrote:\n> And yes I know that my blog site does not validate. It is written in\n> ASP.Net, and that is one of the biggest compliants, you can't\n> produce valid XHTML easily.\n\nYou can, from what I've seen (although I'm not an ASP.NET developer,\nI've only played with it for a bit). You just have to keep clear of\nthe Web controls, which nobody forces you to use.\n\nASP.NET can be used just like ASP3, without the server-side controls\nstuff. Some people say that's a fundamental part of it, but you can\nstill make working pages without it.\n\nOr you can always re-write the controls to produce valid HTML, or\nwrite your own ones from scratch.\n\n> There is a core group of .Net developers trying to work on MS to\n> make it easier to produce valid XHTML, but I'm looking for more fuel\n> to add to the fire, and these blogs should help. \n\nHeh, MS have repeatedly stated that everything ASP.NET generates is\nXHTML-compatible, clearly they think adding a forward-slash to the end\nof every empty element is enough.\n\n> The problem with ASP.Net is that they wanted it to render in almost\n> any downlevel browser (like Netscape 3), so they sacrificed sticking\n> to known standards. \n\nThe problem is, they didn't even manage to stay compatible with IE6 -\nif you disable scripting, that is. JavaScript pseudo-protocol links\npop up everywhere with ASP.NET (for instance, see the download links\non <http://asp.net/ibuyspy/download.aspx>).\n\nI think ASP.NET should be viewed as a major target for evangelists,\nthere are more and more broken and invalid ASP.NET sites popping up\nevery day. It's easy development, at the cost of compliance and\naccessibility.\n\n-- \nTom Gilder, http://tom.me.uk/\nhttp://www.shelldesign.co.uk/\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "Hi again,\n\nHolly Marie a ?crit:\n\n>>All those but accessify are in french. I have compiled a list of other\n>>french blogs, and plan to do the same for US bloggers that I read\n>>    \n>>\n>daily,\n>  \n>\n>>to inspire my writings on the StandBlog. I'll send it to the list when\n>>it's done.\n>>    \n>>\n>\n>Seems to me, I read your blog in English, too Tristan.  Several times.\n>:)\n>Any of these are readable via a babelfish translation, though the\n>automated translation process leaves a bit to be desired. Sometimes the\n>translations are a bit humorous, though.\n>\n:-)\n\n>I am interested in several standards blogs, so keep the list rolling. \n>\nHere you are!\n\nI tried not to list too many blogs, as some blogs are not updated often, \nand others may only occasionnally mention web standards. So I focused on \nblogs updated several times a week, talking mainly about standards, web \ndevelopment and modern browsers.\n\nhttp://meyerweb.com/ (closed for the moment for sad and obvious reasons)\nhttp://www.webstandards.org/\nhttp://www.zeldman.com/\nhttp://www.stopdesign.com/\nhttp://tantek.com/log (Tantek's)\nhttp://diveintomark.org/\nhttp://www.whatdoiknow.org/\nhttp://www.brainstormsandraves.com/\nhttp://daniel.glazman.free.fr/weblog/\nhttp://www.bradsoft.com/topstyle/blog/index.asp\nhttp://www.holovaty.com/\nhttp://www.digital-web.com/new/\nhttp://ln.hixie.ch/\nhttp://dbaron.org/log/\nhttp://www.mozillazine.org/weblogs/hyatt/\nhttp://simon.incutio.com/\nhttp://www.ordinary-life.net/\nhttp://www.thenoodleincident.com/inflight_correction/log.html\nhttp://www.saila.com/columns/lcky/\nhttp://www.simplebits.com/\n\nMozilla contributors' weblogs are listed on \nhttp://www.mozillazine.org/weblogs/ . Most are related either to the \nbrowser or to web standards.\n\nAccessibility-related :\nhttp://www.madeforall.com (focus on accessibility, news on bottom of page)\nhttp://www.anitrapavka.com/ (accessibility-related)\nhttp://www.accessify.com/default.asp\n\nAdditional sites :\nhttp://www.evolt.org/\nhttp://www.boxesandarrows.com/\nhttp://alistapart.org/\n\n\n\n--Tristan\n\n>>http://devedge.netscape.com/index_fr.html\n>>http://standblog.com/\n>>http://openweb.eu.org\n>>\n\n\n\n"
        },
        {
            "subject": "RE: Web Standards Evangelist Related Blogs",
            "content": ">  -----Original Message-----\n>  From: public-evangelist-request@w3.org\n>  [mailto:public-evangelist-request@w3.org]On Behalf Of Tristan Nitot\n>  Sent: April 25, 2003 9:30 AM\n>  To: public-evangelist@w3.org\n>  Subject: Re: Web Standards Evangelist Related Blogs?\n\n\n>  >Seems to me, I read your blog in English, too Tristan.  Several times.\n>  >Any of these are readable via a babelfish translation, though the\n>  >automated translation process leaves a bit to be desired. Sometimes the\n>  >translations are a bit humorous, though.\n\nFunny this should be mentionned because no later than last night I was\nhaving a chat with some friends and I was expressing the idea of generating\ntransllation of the content I produce on the fly using some service\navailable on the Web. To my understanding, these srervices were actually\nvery poor and did a bad job at best... Am I wrong ? have these been\ntremendously improved over time ?\n\nAs I plan on making my writings more easily available to english speaking\nfolks (ie, translated), I am wondering if babelfish would happen to be the\nbest service out there at the moment. Any ideas on the subject ?\n\nAs I update my site a few times daily on the subject of web standards and\nall related stuff (information architecture, browsers and web design), i\nneed something that can be relied upon so i can remain cinfident that what i\nsay preserves it's meaning once translated (at least partially).\n\nThanks for the feedback :)\n\n\nDenis Boudreau\nD?fenseur des standards Web || Architecte d'information\n\nCYBERcodeur.net - VDM - W3Qc - OpenWebGroup\nMail : denis@cybercodeur.net\nICQ : 115649885\nWEB : http://www.cybercodeur.net/\n          http://www.openweb.eu.org/\n\n\"Faites beaucoup de alt, surtout lors des longs trajets. (Sam Latchman)\"\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "On Fri, Apr 25, 2003 at 09:56:40AM -0400, Denis Boudreau [ CYBERcodeur.net ] wrote:\n> >  >Seems to me, I read your blog in English, too Tristan.  Several times.\n> >  >Any of these are readable via a babelfish translation, though the\n> >  >automated translation process leaves a bit to be desired. Sometimes the\n> >  >translations are a bit humorous, though.\n> \n> Funny this should be mentionned because no later than last night I was\n> having a chat with some friends and I was expressing the idea of generating\n> transllation of the content I produce on the fly using some service\n> available on the Web. To my understanding, these srervices were actually\n> very poor and did a bad job at best... Am I wrong ? have these been\n> tremendously improved over time ?\n\nThe quality of the translation depends on the content and on the\nquality of the the original article. If the article is well-written,\nuncomplicated and gramatically correct (with no spelling mistakes), you \ncan get a very reasonable translation. :) If the content is more poetic, \nutilises slang and cultural/language specific quips, then the translator \nwill only be able to translate these literally, hence the original \nmeaning might not come through very clearly.\n\ncheers,\n-steph,  (who has used translators a lot ...)\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "From: \"Denis Boudreau [ CYBERcodeur.net ]\n\n> As I update my site a few times daily on the subject of web standards\nand\n> all related stuff (information architecture, browsers and web design),\ni\n> need something that can be relied upon so i can remain cinfident that\nwhat i\n> say preserves it's meaning once translated (at least partially).\n\nHuamn translation is probably best. When I was young, I learned\nBastillian based spanish: read, write, speak ... Though like any other\ncountry and language there are variations for different regions or\ngroups. Some of those nuances get lost in the translation and can make\nfor some odd differences.\n\nI suspect, for the most part, many of us that speak a few languages\nrealize this and allow for some differences. Sometimes, the automated\ntranslations can be funny, or challenging to understand. Though most\ntimes it is not too difficult.\n\nholly\n\np.s. you have a great site... I enjoy reading it.\n\n\n\n"
        },
        {
            "subject": "web standards and accessibility blogs, etc",
            "content": "I've taken the liberty of culling from the lists of weblogs, magazines \nand community servers posted today. You can find it here: \nhttp://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n\nIt's a rough job of cut and paste further chewed via Textile. I've tried \nto clean up spelling problems, etc. and I've tried to add some value by \ngoing to each of the sites and getting an impression of what it's about. \nHowever, I admit I may have resorted to \"easy humour\" on occasion as I \ngot punchier and punchier with the work. For that I apologize.\n\nHowever, the comments about legibility come from a boomer, \npost-fifty-type guy with tri-focals whose eyes have seen many glories, \nbut are getting dimmer with age. You might take that to heart in \nparticular with respect to the more pastel of the text-color choices. \nNeutral and desaturated text is also a major chore.\n\nIf you find errors, dead links, etc. OR if you have additional (high \nquality with sustained content please) links, please forward them or put \nthem up on the list. In addition, the HTML (or Textile formatted) source \ncan be got for the price of an email request to yours truly.\n\n               ...edN\n\n\n\n"
        },
        {
            "subject": "RE: web standards and accessibility blogs, etc",
            "content": ">  -----Original Message-----\n>  From: public-evangelist-request@w3.org\n>  [mailto:public-evangelist-request@w3.org]On Behalf Of ed nixon\n>  Sent: April 25, 2003 12:10 PM\n>  To: public-evangelist@w3.org\n>  Subject: web standards and accessibility blogs, etc.\n>\n>\n>\n>  I've taken the liberty of culling from the lists of weblogs, magazines\n>  and community servers posted today. You can find it here:\n>  http://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n>\n>  It's a rough job of cut and paste further chewed via Textile. I've tried\n>  to clean up spelling problems, etc. and I've tried to add some value by\n>  going to each of the sites and getting an impression of what it's about.\n>  However, I admit I may have resorted to \"easy humour\" on occasion as I\n>  got punchier and punchier with the work. For that I apologize.\n>\n>  However, the comments about legibility come from a boomer,\n>  post-fifty-type guy with tri-focals whose eyes have seen many glories,\n>  but are getting dimmer with age. You might take that to heart in\n>  particular with respect to the more pastel of the text-color choices.\n>  Neutral and desaturated text is also a major chore.\n>\n>  If you find errors, dead links, etc. OR if you have additional (high\n>  quality with sustained content please) links, please forward them or put\n>  them up on the list. In addition, the HTML (or Textile formatted) source\n>  can be got for the price of an email request to yours truly.\n\nWow, great initiative! This is a wonderful idea :)\n\nWe should definitely try to make it as complete as possible, for everybody's\nreferences :)\n\nHowever right off the bat two things should be clarified :\n\nTristan Nitot - the webblog\nURL should be pointing to new address : http://www.standblog.com/ , not old\n\nEric Daspet - looks like a project journal about the [re]design of the blog\nsite.\nThis is more like a Weblog on technologies and opinions. While it is\nfocussing on it's redesign at the moment, it is much more than that :)\n\nDenis Boudreau\nwww.cybercodeur.net\n\n\n\n"
        },
        {
            "subject": "RE: Web Standards Evangelist Related Blogs",
            "content": ">  -----Original Message-----\n>  From: Holly Marie [mailto:hollymarie@ameritech.net]\n>  Sent: April 25, 2003 11:11 AM\n>  To: denis@cybercodeur.net; public-evangelist@w3.org\n>  Subject: Re: Web Standards Evangelist Related Blogs?\n>\n>\n>  From: \"Holly Marie\" kindly wrote :\n\n>  p.s. you have a great site... I enjoy reading it.\n\nWell thank you very much... it comes to show you never know who you actually\nconnect to when blogging...\n\nI am quite amazed to realize that I am not limited to the french community.\nSometimes, I wish i did write in english to touch more people, but the\nreason why it's in french only is because there was a complete lack of such\nresources when i started back in feb 2002. Even Tristan Nitot\n(www.standblog.com) who does a wonderful job, only started last summer.\nsince then, many have followed and we now have great resources in french.\n\nThe realisation of openweb is just one of many examples that quality\noriginal content can also be made available in french. :)\n\nI feel i can make a difference for those of us who don't understand english\nbut publishing in french. However, realizing that i manage to come through\nin english all the same makes me very happy. It feels more complete that\nway... :)\n\nDenis Boudreau\nwww.cybercodeur.net\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "This is a great start, but what I was eventually going to suggest is an \naggregator site (preferably on the W3C site since that is who benefits from \nit).  For the .Net world we have sites like \nhttp://activehead.com/dotnetweblogs/ which is a great place to start if you \nwant to hook into the .Net bloggers.  I was envisioning something similar \nfor W3C standards stuff.  The problem with this approach is that not \neveryone has RSS feeds, and then people tend to mix topics in their blogs.  \nWhat some of the .Net guys are working on getting people to use the category \nsupport in RSS 2.0.  This way aggregator sites can pull in only the blog \nentries that are relevant to them.  Mix all those blog entries with the W3C \nRSS feed, and you?ve got a great standards evangelist site.\n\nDon XML\n\nAlways listen to experts. They'll tell you what can't be done, and why. Then \ndo it.\n\n----Original Message Follows----\nFrom: ed nixon <ed.nixon@LynnParkPlace.org>\nTo: public-evangelist@w3.org\nSubject: web standards and accessibility blogs, etc.\nDate: Fri, 25 Apr 2003 12:10:03 -0400\n\n\nI've taken the liberty of culling from the lists of weblogs, magazines and \ncommunity servers posted today. You can find it here: \nhttp://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n\nIt's a rough job of cut and paste further chewed via Textile. I've tried to \nclean up spelling problems, etc. and I've tried to add some value by going \nto each of the sites and getting an impression of what it's about. However, \nI admit I may have resorted to \"easy humour\" on occasion as I got punchier \nand punchier with the work. For that I apologize.\n\nHowever, the comments about legibility come from a boomer, post-fifty-type \nguy with tri-focals whose eyes have seen many glories, but are getting \ndimmer with age. You might take that to heart in particular with respect to \nthe more pastel of the text-color choices. Neutral and desaturated text is \nalso a major chore.\n\nIf you find errors, dead links, etc. OR if you have additional (high quality \nwith sustained content please) links, please forward them or put them up on \nthe list. In addition, the HTML (or Textile formatted) source can be got for \nthe price of an email request to yours truly.\n\n               ...edN\n\n\n\n\n_________________________________________________________________\nHelp STOP SPAM with the new MSN 8 and get 2 months FREE*  \nhttp://join.msn.com/?page=features/junkmail\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "Ok. Thanks for the mail, the comments and the trackbacks. I've \nincorporated comments and suggestions and updated the post. I think I've \ndone justice to everyone's input; if not, let me know.\n\nAnd...\n\nDon XML wrote:\n\n> <snip/>\n> I was envisioning something similar for W3C standards stuff. The \n> problem with this approach is that not everyone has RSS feeds, and \n> then people tend to mix topics in their blogs. What some of the .Net \n> guys are working on getting people to use the category support in RSS \n> 2.0. This way aggregator sites can pull in only the blog entries that \n> are relevant to them. Mix all those blog entries with the W3C RSS \n> feed, and you?ve got a great standards evangelist site. \n\nYes, it occurred to me that I was working \"fast\", but not particularly \n\"smart\". I didn't mean to get in your way, Don. Apologies.\n\nI wonder if this great aggregator idea doesn't need a bit more lead-time \nand planning? For example, what I've posted is really not as \"pure\" on \nthe subject of standards as it could be; there is a mix of the personal, \nthe mundane, sometimes the bizarre and also the standards related. If \nthere were an aggregator, you'd like to have only the standards and/or \naccessibility topics getting pinged through. That kind of leaves it up \nto the individual blogger to organize the site in a compatible fashion. \nNot impossible, but in need of some discussion. Have no idea how close \nto this we might be right now.\n\nW3C *is* the logical place to put the aggregator and if someone can push \nsome buttons to get that working, that makes a lot of sense. \nAlternatively, there might be other venues. For example, the Internet \nTopic Exchange (http://topicexchange.com/) is already up and running and \nseems to be a self-administered utility. This might be worth a look. It \nmight happen more quickly and it might get more spread given it's a link \nexchange venue that attracts diffuse interests.\n\nWhat do you think Don?\n\nCheers. ...edN\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "Ed,\n\nYour not getting in my way, whatever is best for us.  I'm just throwing \naround some ideas.\n\nAnd yes, letting individuals make the decsion on what category an entry \nrelates to will not always work, but it is the best way for now.  What the \nDotNetWeblogs do is to self administer.  Anyone that starts to cross link \njust to get readers are warned, and ifit continues, eventually dropped form \nthe site.  It is easier to say, than to do, but you got to eliminate the \n\"static\", otherwise you'll get too much static, and people stop reading.\n\nDon XML\n\nAlways listen to experts. They'll tell you what can't be done, and why. Then \ndo it.\n\n\n\n_________________________________________________________________\nHelp STOP SPAM with the new MSN 8 and get 2 months FREE*  \nhttp://join.msn.com/?page=features/junkmail\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "My Maccessibility.com blog probably counts, and on the left hand side\nthere are links to related blogs.\n\nhttp://www.maccessibility.com/\n\nAn RSS feed is available for Maccessibility.com.\n\n--Kynn\n\n--\nKynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\nChief Technologist, Idyll Mountain                http://idyllmtn.com\nAuthor, CSS in 24 Hours                       http://cssin24hours.com\nInland Anti-Empire Blog                      http://blog.kynn.com/iae\nShock & Awe Blog                           http://blog.kynn.com/shock\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "On Friday, April 25, 2003, at 10:00  AM, Don XML wrote:\n\n>\n> This is a great start, but what I was eventually going to suggest is \n> an aggregator site (preferably on the W3C site since that is who \n> benefits from it).\n\nLike this:\n\nhttp://dev11.otherworks.com/theotherblog/newsability\n\n--Kynn\n\n> --\nKynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\nChief Technologist, Idyll Mountain                http://idyllmtn.com\nAuthor, CSS in 24 Hours                       http://cssin24hours.com\nShock & Awe Blog                           http://blog.kynn.com/shock\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "Kynn,\n\nThanks. I've looked and it looks great (it took a long time to load for \nme for some reason?). I'll do another edit to include your site sometime \nlate in the weekend, after I've picked up more one's and two's.\n\nThe news aggregator is interesting too. Do you maintain it yourself? by \nhand? What's involved in making it a user subscribable, self-managing \nthingy?\n\nWe're kind of becalmed here with respect to the aggregator idea; I guess \nsomeone is going to have to \"do\" something. My problem is I don't have a \ngood idea what, if anything, folks want to do. For example, should we \nwait for input from the list moderator about the feasibility of doing it \non W3C facilities? Or just go ahead and do something else? If so, what?\n\nMy preference would be to get some feedback from the QA/IG side or at \nleast wait until the silence becomes deafening..\n\nThoughts?                                     ...edN\n\n\n\nKynn Bartlett wrote:\n\n>\n> My Maccessibility.com blog probably counts, and on the left hand side\n> there are links to related blogs.\n>\n> http://www.maccessibility.com/\n>\n> An RSS feed is available for Maccessibility.com.\n>\n> --Kynn\n>\n> -- \n> Kynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\n> Chief Technologist, Idyll Mountain                http://idyllmtn.com\n> Author, CSS in 24 Hours                       http://cssin24hours.com\n> Inland Anti-Empire Blog                      http://blog.kynn.com/iae\n> Shock & Awe Blog                           http://blog.kynn.com/shock\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs? [starting to get off  topic?",
            "content": "I'm just reading this post on Seb's Open Research. It's called \"The \ndynamics of ridiculously easy group-forming\" and it talks around what \nwe're thinking about with the standards aggregator idea. He's a big fan \nof  Internet Topic Exchange (http://topicexchange.com/), probably \nbecause it's the first implementation of the idea. Take a look and see \nif anything clicks.\n\nHere's the link: http://radio.weblogs.com/0110772/2003/04/25.html#a928\n\nCheers.                        ...edN\n\ned nixon wrote:\n\n>\n> Kynn,\n>\n> Thanks. I've looked and it looks great (it took a long time to load \n> for me for some reason?). I'll do another edit to include your site \n> sometime late in the weekend, after I've picked up more one's and two's.\n>\n> The news aggregator is interesting too. Do you maintain it yourself? \n> by hand? What's involved in making it a user subscribable, \n> self-managing thingy?\n>\n> We're kind of becalmed here with respect to the aggregator idea; I \n> guess someone is going to have to \"do\" something. My problem is I \n> don't have a good idea what, if anything, folks want to do. For \n> example, should we wait for input from the list moderator about the \n> feasibility of doing it on W3C facilities? Or just go ahead and do \n> something else? If so, what?\n>\n> My preference would be to get some feedback from the QA/IG side or at \n> least wait until the silence becomes deafening..\n>\n> Thoughts?                                     ...edN\n>\n>\n>\n> Kynn Bartlett wrote:\n>\n>>\n>> My Maccessibility.com blog probably counts, and on the left hand side\n>> there are links to related blogs.\n>>\n>> http://www.maccessibility.com/\n>>\n>> An RSS feed is available for Maccessibility.com.\n>>\n>> --Kynn\n>>\n>> -- \n>> Kynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\n>> Chief Technologist, Idyll Mountain                http://idyllmtn.com\n>> Author, CSS in 24 Hours                       http://cssin24hours.com\n>> Inland Anti-Empire Blog                      http://blog.kynn.com/iae\n>> Shock & Awe Blog                           http://blog.kynn.com/shock\n>>\n>>\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "Re: Web Standards Evangelist Related Blogs",
            "content": "On Friday, April 25, 2003, at 04:48  PM, ed nixon wrote:\n\n>\n> Kynn,\n>\n> Thanks. I've looked and it looks great (it took a long time to load \n> for me for some reason?).\n\nYeah, all of my blogs have been loading slowly. I need to look into \nthis.\n\n> I'll do another edit to include your site sometime late in the \n> weekend, after I've picked up more one's and two's.\n>\n> The news aggregator is interesting too. Do you maintain it yourself? \n> by hand? What's involved in making it a user subscribable, \n> self-managing thingy?\n\nThe aggregator isn't mine, it belongs to someone else.\n\n--Kynn\n\n--\nKynn Bartlett <kynn@idyllmtn.com>                     http://kynn.com\nChief Technologist, Idyll Mountain                http://idyllmtn.com\nAuthor, CSS in 24 Hours                       http://cssin24hours.com\nShock & Awe Blog                           http://blog.kynn.com/shock\n\n\n\n"
        },
        {
            "subject": "Re: web standards and accessibility blogs, etc",
            "content": "From: \"ed nixon\" .\n\n\n> I've taken the liberty of culling from the lists of weblogs, magazines\n> and community servers posted today. You can find it here:\n> http://www.lynnparkplace.org/vot/archives/accessibility/000015.html.\n\nHi Ed,\nThis is great. Let me compare your list to one I have in html and see if\nthere are a few you did not list. Looks like most of the standards,\nguidelines, and accessibility blogs are present, though I think I missed\nseeing a few. Will get back to you tomorrow on this, and if I forget,\nemail me a nice note.\n\nI need to make a collection of these for another purpose or two. So we\nare going to be able to attack two situations with one task.  [smile]\n\nThanks,\nholly\n\n\n\n"
        },
        {
            "subject": "QA Matrix in RDF. Why? A practical applicatio",
            "content": "Hi,\n\n\n    [1]The QA Matrix gives information about the [2]W3C specifications\n    useful for implementors and formatted in a synthesized table. This\n    document:\n\n[3]Why the QA Matrix in RDF?\n\n    is a tale of why it has been beneficial to use the RDF model\n    to manage this information.\n\n      [1] http://www.w3.org/QA/TheMatrix\n      [2] http://www.w3.org/TR/\n      [3] http://www.w3.org/2003/08/rdf-reloaded\n\n\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Re: QA Matrix in RDF. Why? A practical applicatio",
            "content": "Le mercredi, 20 ao? 2003, ? 13:48 America/Montreal, Karl Dubost a ?crit \n:\n> [3]Why the QA Matrix in RDF?\n\nOopps mistake for the URI.\n\n      [3] http://www.w3.org/QA/2003/08/rdf-reloaded\n\n\n\n"
        },
        {
            "subject": "Re: QA Matrix in RDF. Why? A practical applicatio",
            "content": "Le mercredi, 20 ao? 2003, ? 13:48 America/Montreal, Karl Dubost a ?crit \n:\n> [3]Why the QA Matrix in RDF?\n\nOopps mistake for the URI.\n\n      [3] http://www.w3.org/QA/2003/08/rdf-reloaded\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Guidelines for the contribution of new material to the QAI",
            "content": "Greetings,\n[ Please follow-up to www-qa@w3.org. thank you. ]\n\nAs you probably know, the QA IG does not have any specific deliverable.\nHowever, the discussion among participants can (and often do) trigger \nthe creation of new resources for the QA Library.\n   <http://www.w3.org/QA/Library>\n\nGiven the success of recent contributions and the increasing demand for \nsuch a resource, QA chairs and Team have developed the following guide \nfor contributing new material to the QA Interest Group.\n   <http://www.w3.org/QA/2003/06/Contrib>\n\n\nPlease note that direct contribution of material to the IG is there to \nease the creation of useful resources on the W3C QA Web space but \nshould not replace the usual discussion/idea/production way.\n\nFeedback on these guidelines are, of course, welcome, and we expect the \nguidelines to evolve after some time of use \"in the real world\".\n\nRegards,\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "Re: Weblogs, etc. on standards and accessibility update",
            "content": "Le mardi, 17 juin 2003, ? 10:22 America/Montreal, ed nixon a ?crit :\n\n> I've just completed an update to my 25 April 2003 post, \"Web standards  \n> and accessibility weblogs,  \n> etc.\":http://www.lynnparkplace.org/vot/archives/accessibility/ \n> 000015.html\n\nTristan[1] has discovered two new ones:\nhttp://jba.blogspot.com/ French\nhttp://www.annevankesteren.nl/weblog/English\n\n[1] http://standblog.com/index.php?p=93112998&c=1\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Common Web Authoring Problem",
            "content": "Hi,\n\nIn March 2003, we have tried to start to collect information[1] for a \nNote that would be the companion of CHIPS[2] and CUAP[3].\n\nUnfortunately, we don't think there's enough material to create such a \ndocument. A few issues arise when we start to collect a few guidelines \nfor such a document.\n\nWhat's an authoring tool: Wysiwyg? plain text? Script generating \npages? libraries? Converter?\nOnce you have addressed the fact to produce valid content. What are \nthe other issues?\nShould we recommend scenarios when they are not defined in the \nspecifications?\nWhich technologies?\n\nAll these issues are complex and sometimes do not have a single answer. \nI would encourage people to review W3C specifications and question the \neditorial part.\n- old specs: What's missing?\n- new specs: Should we ask for more details on the editing techniques \npart?\n\nSo except if there's an important number of contribution, We decided to \nnot create such a document.\n\nPS: For accessibility problems with regards to Authoring Tools.\nSee http://www.w3.org/TR/ATAG10/\nAuthoring Tool Accessibility Guidelines 1.0\n\n\n[1] http://lists.w3.org/Archives/Public/public-evangelist/2003Mar/0003\n[2] http://www.w3.org/TR/chips\n[3] http://www.w3.org/TR/cuap\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n"
        },
        {
            "subject": "Benefits of XHTML Modularizatio",
            "content": "Hi folks,\n\nJust letting you know that the new \"WaSP asks W3C\" is up at:\nhttp://www.webstandards.org/learn/askw3c/dec2003.html\n\n:)\n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "Re: Benefits of XHTML Modularizatio",
            "content": "steph wrote:\n\n>\n> Hi folks,\n>\n> Just letting you know that the new \"WaSP asks W3C\" is up at:\n> http://www.webstandards.org/learn/askw3c/dec2003.html\n>\nGood job! It looks like it's leaking into the blogosphere ;-)\n\nhttp://standblog.com/blog/2003/12/18/93113230-ModularisationDeXhtml (for \nthose of you who read French)\n\n\n--Tristan\n\n-- \nContributeur Mozilla et OpenWebGroup\nhttp://mozilla.org/    : Efficiency, safety and liberty for browsing.\nhttp://openweb.eu.org/ : pour apprendre les standards.\nhttp://standblog.com/  : un blog sur les standards.\nhttp://pompage.net/    : de saines lectures ? propos des standards.\n\n\n\n"
        },
        {
            "subject": "Re: Benefits of XHTML Modularizatio",
            "content": "we have placed a \"link to\" for the SVG community\nat http://www.svgx.org\n\nthanks\nmichael bolger\n\n> steph wrote:\n> \n> >\n> > Hi folks,\n> >\n> > Just letting you know that the new \"WaSP asks W3C\" is up at:\n> > http://www.webstandards.org/learn/askw3c/dec2003.html\n> >\n> Good job! It looks like it's leaking into the blogosphere ;-)\n> \n> http://standblog.com/blog/2003/12/18/93113230-ModularisationDeXhtml (for \n> those of you who read French)\n> \n> \n> --Tristan\n\n\n\n"
        },
        {
            "subject": "Announce: New documentation and guidelines for CSS testuite",
            "content": "The CSS working group published updated documentation for the CSS test\nsuites, including instructions for people who want to contribute and\nauthoring guidelines based on experience with existing tests.\n\n    http://www.w3.org/Style/CSS/Test/testsuitedocumentation.html\n    http://www.w3.org/Style/CSS/Test/guidelines.html\n\n(The previous version is also still available.)\n\nOne of the main goals of the documentation is to make it easy for\npeople to write test cases. The format is meant to be suitable for\nwriting tests \"by hand\" and for generating them automatically. We hope\npeople will adopt the format and send us their tests.\n\nAnother goal is to make it easy to reuse tests and to separate the\ntests from the harness that is provided for navigating them. E.g., the\ntests for a specification can be used also for a \"profile\" of that\nspecification, because they are only included by reference. In most\nenvironments, in particular in modern desktop browsers, this inclusion\nby reference is transparent to the user.\n\nFor now, reactions and tests are best sent to www-style@w3.org. We may\nopen a dedicated mailing list later for people involved in CSS\ntesting.\n\n\n\nBert\n-- \n  Bert Bos                                ( W 3 C ) http://www.w3.org/\n  http://www.w3.org/people/bos/                              W3C/INRIA\n  bert@w3.org                             2004 Rt des Lucioles / BP 93\n  +33 (0)4 92 38 76 92            06902 Sophia Antipolis Cedex, France\n\n\n\n"
        },
        {
            "subject": "Announce: New Netscape DevEdg",
            "content": "Hello,\n\n    I meant to give this list a heads-up that Netscape DevEdge \n(http://devedge.netscape.com/) has been redesigned with valid HTML \nand CSS for layout, and no tables used for layout, but I forgot to do \nit until just now.  From the newsletter we sent to everyone \nsubscribed to our outreach list:\n\n    Now DevEdge is not only a great source of tools and information for\n    developers, it demonstrates extensive use of web standards for\n    accessibility, maintainability, and user interaction. When navigating\n    DevEdge, you will find features such as customizable themes, default\n    print style sheets and an accessibility-oriented interface. The site\n    framework is now HTML-tableless, uses advanced CSS and it's optimized\n    for standards-compliant web browsers.\n\nYou can read more about it, and find links to articles that explore \nour CSS and JavaScript efforts for the new design, at\n<http://devedge.netscape.com/viewsource/2003/devedge-redesign/>.\n    Note that you may find a few places online where people have said \nthe site doesn't validate.  At the moment they wrote those comments, \nthey were correct: I made some really dumb mistakes that didn't get \ncaught before launch, and for its first 22 hours the new markup was \ninvalid.  Those errors have been corrected, and the majority of the \nsite now validates.  There may be places where legacy content \nprevents validation, but the common code that all pages share is \nclean.\n    Any feedback should be sent to the DevEdge team (which includes \nme) via the contact form at \n<http://devedge.netscape.com/community/feedback/>.  If we get a lot \nof the same comments or questions we'll create an FAQ about the \ndesign and publish it on DevEdge.\n    Apologies to those of you on the list who will be seeing this for \nthe third or fourth time.\n\n--\nEric A. Meyer  (eric@meyerweb.com)  http://www.meyerweb.com/eric/\nAuthor, \"Cascading Style Sheets: The Definitive Guide,\"\n  \"Eric Meyer on CSS,\" \"CSS 2.0 Programmer's Reference,\" and more\n   http://www.meyerweb.com/eric/books/\n\n\n\n"
        },
        {
            "subject": "Re: Announce: New Netscape DevEdg",
            "content": "* Eric A. Meyer wrote:\n>    I meant to give this list a heads-up that Netscape DevEdge \n>(http://devedge.netscape.com/) has been redesigned with valid HTML \n>and CSS for layout, and no tables used for layout, but I forgot to do \n>it until just now.  From the newsletter we sent to everyone \n>subscribed to our outreach list:\n\nMost of devedge.netscape.com still returns `404 Not Found` because of my\n\n  Accept-Language: de,en;q=0.7,*;q=0.3\n\nHTTP header (the server dislikes the `*` and thus violates HTTP/1.1)...\n\n\n\n"
        },
        {
            "subject": "Browser Complianc",
            "content": "Does the W3C take an official stance on Browser standards?\nNetscape 4x browsers specifically?\nIs there any documentation about this specific Browser?\nIf so is it posted on W3C.org?\n\nI see that W3C has shown many things that need to be in place to show that\nit's w3c compliant...but I can't find an actual stance on Browsers\nthemselves. I am specifically trying to find something that states that\nNetscape id NOT supported by W3C.\n\nI got your email off this page:\nhttp://www.w3.org/QA/2002/07/WebAgency-Requirements#reqlist\n\n\nThanks so much!\n-David Lockhart\n\n\nThanks,\nDavid Lockhart\n\n_________________________________\nDavid Lockhart - CitiCapital Technology\ndavid.lockhart@citigroup.com\n250 E. Carpenter Frwy, HO5-1\nIrving, TX  75062\n972-652-5433 - Phone\n972-652-4571 - FAX\n\nhttp://www.citicapital.com\n\n\n\n"
        },
        {
            "subject": "Re: Browser Complianc",
            "content": "I think you have it backwards.  W3C doesn't \"support\" browsers, but\nbrowsers support (or are supposed to support) W3C recommendations.\n\nThus if you're looking for something that says \"W3C doesn't support\nNetscape 4\", you won't find it.\n\n--Kynn\n\nOn Thursday, February 20, 2003, at 12:11 PM, Lockhart, David wrote:\n> Does the W3C take an official stance on Browser standards?\n> Netscape 4x browsers specifically?\n> Is there any documentation about this specific Browser?\n> If so is it posted on W3C.org?\n>\n> I see that W3C has shown many things that need to be in place to show \n> that\n> it's w3c compliant...but I can't find an actual stance on Browsers\n> themselves. I am specifically trying to find something that states that\n> Netscape id NOT supported by W3C.\n>\n> I got your email off this page:\n> http://www.w3.org/QA/2002/07/WebAgency-Requirements#reqlist\n>\n>\n> Thanks so much!\n> -David Lockhart\n>\n>\n> Thanks,\n> David Lockhart\n>\n> _________________________________\n> David Lockhart - CitiCapital Technology\n> david.lockhart@citigroup.com\n> 250 E. Carpenter Frwy, HO5-1\n> Irving, TX  75062\n> 972-652-5433 - Phone\n> 972-652-4571 - FAX\n>\n> http://www.citicapital.com\n>\n>\n>\n\n\n\n"
        },
        {
            "subject": "PHP Class to validate your marku",
            "content": "Hi,\n\nI'll be interested to know the list of tools which are OPEN SOURCE \nand helps people to validate (not only HTML) and maintain the quality \nof their Web sites.\n\n\nExample:\nhttp://simon.incutio.com/archive/2003/02/23/safeHtmlChecker\n\n***************************\nI've finally enabled a subset of HTML in my comments. In doing so, I \nhad several requirements that needed to be fulfilled:\n\n    1. Entered markup must be valid to XHTML strict, to stop comments \nform breaking validation and keep things nice and tidy.\n    2. No presentational markup! I want to maintain control over how \nthings look via my stylesheets - comments posted should only be able \nto use structural HTML elements.\n    3. Attributes should be restricted to those that add semantic \nmeaning. Javascript event attributes and CSS related attributes \nshould not be allowed.\n    4. I should retain full control over the tags and attributes \nallowed in the comments.\n    5. Submitted HTML must be kept free from anything that could pose \na security risk, such as javascript: URLs.\n\nThe system I have implemented works by running submitted posts \nthrough an XML parser, which checks that each element is in my list \nof allowed elements, is nested correctly (you can't put a blockquote \ninside a p for example) and doesn't have any illegal attributes. My \ninitial test have shown it to work pretty well, but if anyone wants \nto have a go at breaking it please, be my guest.\n\nThe code for the main class is available here: SafeHtmlChecker.class.php\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n"
        },
        {
            "subject": "Re: PHP Class to validate your marku",
            "content": "Karl Dubost wrote:\n> I'll be interested to know the list of tools which are OPEN SOURCE and \n> helps people to validate (not only HTML) and maintain the quality of \n> their Web sites.\n\nhere's an list :\n<http://checky.mozdev.org/services.html>\n(it is the list available by Checky, which is a mozilla extension).\nI guess all these validators are of free use, and many of them is \nopen-source.\n\n-- \nXandreX\n\n\n\n"
        },
        {
            "subject": "&quot;step-bystep&quot; guide to website validity and the LogValidato",
            "content": "Hello,\n\nYou may remember hearing about the LogValidator [1] project being \ndeveloped by the QA activity at W3C. This website log analysis (and \nvalidation) tool is entering today a beta test phase, with a tentative \nstable release date around the end of March 2003.\n\n[1] http://www.w3.org/QA/Tools/Logvalidator/\n\n\nAs a companion to this tool, I have written, with the help of the QA \nteam and contributor Kim Nylander an article covering the simple ideas \nbehind this tools, also acting as a tutorial. [2]\n\n[2] http://www.w3.org/QA/2002/09/Step-by-step\n\nThe ideas presented in this document are quite simple and could be \nsummarized as follows:\n- if you have many things to do and little time to do it, you start \nwith what's most important\n- for a webserver, what's more important is what gets more traffic\n- analysing your webserver logs can tell you what resources need love \nand caring\n- we have developed a flexible tool for that purpose\n\n\n\nI believe the Log Validator (with the help of this article) is \npotentially a very helpful Web Quality tool. The public-qa-dev \ncommunity can help make it possible by:\n- Reviewing the tutorial\n- Participating in the Public Beta Test for the Log Validator\n\n- Talking about it within the Web Community, inviting people to use and \nreview both the tool and its tutorial.\n\nThank you. olivier.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n"
        },
        {
            "subject": "URL correction on Home Page - [was] Re: &quot;step-bystep&quot; guide to website validity and the LogValidato",
            "content": "From: \"Olivier Thereaux\"\n> You may remember hearing about the LogValidator [1] project being\n> developed by the QA activity at W3C. This website log analysis (and\n> validation) tool is entering today a beta test phase, with a tentative\n> stable release date around the end of March 2003.\n>\n> [1] http://www.w3.org/QA/Tools/Logvalidator/\n\n\n\n> As a companion to this tool, I have written, with the help of the QA\n> team and contributor Kim Nylander an article covering the simple ideas\n> behind this tools, also acting as a tutorial. [2]\n>\n> [2] http://www.w3.org/QA/2002/09/Step-by-step\n\nThe idea looks good, also...  at the home page of LogValidator[1]\n\nThe link anchor to the beta download section has two hash marks and\nneeds to be fixed.\n\nFound at page text -\nNEWS!\n*Public beta Test* of the Log Validator, February 28th, 2003 - March\n28th, 2003.\n\n* the correct link for the beta download info* :\nhttp://www.w3.org/QA/Tools/LogValidator/#download-test\n\n\nholly\n\n\n\n"
        },
        {
            "subject": "Re: URL correction on Home Page - [was] Re: &quot;step-bystep&quot; guide to website validity and the LogValidato",
            "content": "Holly,\n\nThanks for spotting this, I just fixed the typo.\n(and thanks for forwarding the news to the webdesign-l list)\n\n-- \nOlivier\n\n\n\n"
        },
        {
            "subject": "Teaching XHTML/CSS (was Re: Promotion of XHTML",
            "content": "On Mon, Dec 30, 2002 at 03:25:11PM -0700, Chris Hubick wrote:\n> \n> You can talk about right and wrong, and accessibility, browser and\n> platform neutrality, but the problem is most people /do/ /not/ /care/. \n> Students glaze over.  They especially don't care when doing it the right\n> way is vastly more difficult that doing it the wrong way (table based\n> layout for example). Even if it was easy, they still wouldn't care.  And\n> for the most part they don't want to understand why they should care,\n> they just want their page to be cool and work - which they can get with\n> little effort.\n\nI had a conversation with a university lecturer who was teaching\na web-related course in Information Management about why she was\nstill teaching HTML and not XHTML.  Her answer was that most\nstudents can barely cope with effectively using computers, \nlet alone trying to grasp XML/XHTML.\n\nI don't believe that this is a sufficient 'excuse'. To some\nextent, learning technical things (mathematics, programming, languages) \ntend to begin with some degree of acceptance about \"this is the way things \nare\" on the part of the student; this is part of the learning curve.\nFrom my own experiences, after some time, the student might truly \nunderstand the why, but in the beginning, they can start with understanding \nthe how - explaining whys in the beginning don't always make sense until\nthey have seen a few examples and have worked through a few themselves.\n\nThis is why I think it would be better to teach XHTML right in the beginning\n- we say, \"this is the way things are now\". I have found that teaching valid \nHTML 4, explaining laying out web pages in tables, /and then/ explaining\nXHTML/CSS to be much more confusing for students - they expressed a\npreference towards the first concept they learned, and they don't understand\nthe transition or the reasoning behind the difference. \n\nThe method I ended up using in teaching basic XHTML/CSS, was bringing\na series of different sized cardboard boxes into class: a big box to \nsignify the <html> container, a box to signify the <header> container, \na box to signify the <body> containter, headings, paragraphs ..\nand so forth. \n\nThis way, students were able to conceptualise the structure of a Web\ndocument without even beginning to understand what XHTML is. I used\nyellow stickies to label the XHTML:  these are the names we are calling\nthese boxes. Eg, a div and a span are special kinds of boxes, we can call\nthem what we want.\n\nThe advantage to this method of conceptualising meant that it became\nquite easy to explain CSS. Students were able to see what cascading\nmeant - it made a kind of sense that a property belonging to a \nsmaller box should override a property inherited by a containing box. \nAnd I think was not difficult to see why structure is separated\nfrom the presentation: the content goes in the boxes, the presentation\nis described \"on top\" of the boxes.\n\nI didn't have the chance to experiment with this method more than \na couple of times. If someone else is willing to give it a try, I'd \nlike to know if this method is truly workable and effective. :)\n\ncheers,\n-steph\n\n\n\n"
        },
        {
            "subject": "Re: Teaching XHTML/CSS (was Re: Promotion of XHTML",
            "content": "At 20:58 01/01/2003 +1100, Steph wrote:\n\n>I had a conversation with a university lecturer who was teaching\n>a web-related course in Information Management about why she was\n>still teaching HTML and not XHTML.  Her answer was that most\n>students can barely cope with effectively using computers,\n>let alone trying to grasp XML/XHTML.\n>\n>I don't believe that this is a sufficient 'excuse'. To some\n>extent, learning technical things (mathematics, programming, languages)\n>tend to begin with some degree of acceptance about \"this is the way things\n>are\" on the part of the student; this is part of the learning curve.\n> >From my own experiences, after some time, the student might truly\n>understand the why, but in the beginning, they can start with understanding\n>the how - explaining whys in the beginning don't always make sense until\n>they have seen a few examples and have worked through a few themselves.\n\nI don't think this is valid, either, which is why I'm tying Standards to \nAccessibility, because that can have the force of the law behind it.\n\n\n>This is why I think it would be better to teach XHTML right in the beginning\n>- we say, \"this is the way things are now\". I have found that teaching valid\n>HTML 4, explaining laying out web pages in tables, /and then/ explaining\n>XHTML/CSS to be much more confusing for students - they expressed a\n>preference towards the first concept they learned, and they don't understand\n>the transition or the reasoning behind the difference.\nTeach it right from the outset and then you don't have to get them to \nunlearn, but also teach the retrofit of sites that are non-compliant. Not \nthat it's impossible to make sites accessible with non-standard code - its \njust a whole load more difficult. If they want to switch off and not do it \nthe correct way, then they will have to remember who's marking the exams.\n\n>The method I ended up using in teaching basic XHTML/CSS, was bringing\n>a series of different sized cardboard boxes into class: a big box to\n>signify the <html> container, a box to signify the <header> container,\n>a box to signify the <body> containter, headings, paragraphs ..\n>and so forth.\n>\n>This way, students were able to conceptualise the structure of a Web\n>document without even beginning to understand what XHTML is. I used\n>yellow stickies to label the XHTML:  these are the names we are calling\n>these boxes. Eg, a div and a span are special kinds of boxes, we can call\n>them what we want.\n>\n>The advantage to this method of conceptualising meant that it became\n>quite easy to explain CSS. Students were able to see what cascading\n>meant - it made a kind of sense that a property belonging to a\n>smaller box should override a property inherited by a containing box.\n>And I think was not difficult to see why structure is separated\n>from the presentation: the content goes in the boxes, the presentation\n>is described \"on top\" of the boxes.\n\nAnd the even lazier way is to make another all enveloping CSS bag whihc can \ncontain multiple XHTML content documents - but the CSS can apply to more \nthan one XHTML content document, so look and feel is easier if you want to \nchange it.\n\n\n>I didn't have the chance to experiment with this method more than\n>a couple of times. If someone else is willing to give it a try, I'd\n>like to know if this method is truly workable and effective. :)\n\n\nSteph\n\nI will try this. The Russian Doll concept of XHTML - hmmmmm!\n\nThanks\n\nJohn\n\n\n\n"
        },
        {
            "subject": "RE: Promotion of XHTM",
            "content": "On Mon, 2002-12-30 at 13:50, Alex Rousskov wrote:\n> On Mon, 30 Dec 2002, fstorr wrote:\n> \n> > It really irritates me.  I get called a geek by my intranet manager\n> > at work - this coming from the man who won't use CSS and uses\n> > FrontPage for \"ease\".\n> \n> To make any progress, we have to at least identify the primary\n> obstacle:\n\n> In other words, what should be the first priority: changing human\n> nature, changing Microsoft, changing W3C marketing, changing CSS/HTML,\n> or changing browsers?\n\nThe problem is making people care about doing something the /right/ way.\n\nSomeone learning how to make web pages can sit down and relatively\nquickly get the results they want without any regard to proper\nstructural based web design (font tags, etc).  It's hard to explain to\nthem why doing this is wrong, especially since \"everyone else seems to\ndo it this way\".\n\nYou can talk about right and wrong, and accessibility, browser and\nplatform neutrality, but the problem is most people /do/ /not/ /care/. \nStudents glaze over.  They especially don't care when doing it the right\nway is vastly more difficult that doing it the wrong way (table based\nlayout for example). Even if it was easy, they still wouldn't care.  And\nfor the most part they don't want to understand why they should care,\nthey just want their page to be cool and work - which they can get with\nlittle effort.\n\nSo, in answer to your question: Human Nature.\n\n-- \nChris Hubick\nmailto:chris@hubick.com\nhttp://www.hubick.com/\n\n\n\n"
        }
    ]
}