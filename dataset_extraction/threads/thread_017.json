[{"subject": "Re: issue idnuri02: New approach, new tex", "content": "Hello Bjoern,\n\nI have copied the URI list, because this is a topic of mutual concern.\n\nAt 05:23 03/04/29 +0200, Bjoern Hoehrmann wrote:\n>* Martin Duerst wrote:\n> >Issue http://www.w3.org/International/iri-edit#idnuri-02 is about\n> >whether to use %-escaping or punycode to map the domain name part\n> >of an IRI to an URI. This was discussed at the IETF in San Francisco,\n> >and the general tendency there seemed to be towards using punycode.\n>\n>The hostname production rule in RFC 2396 (as updated by RFC 2732)\n>does not allow %-escaping, using %-escaping for URI conversion is\n>thus not an option, so why was this at all subject to discussion?\n\nBecause of a lot of reasons:\n\n- Some user agents actually allow it (try using IE with http://www.w%33.org)\n\n- The 'U' in URI stands (among else) for 'uniform', and so it is very\n   natural to use the same convention everywhere.\n\n- IRIs are defined in many specs (XML, XLink, XML Schema,...) without\n   the exception for domain names, so there is code out there that\n   produces (or will produce, once it receives IDNs) %-escapes.\n\n- URIs are (or were, Roy said he would change that) not limited to\n   DNS host names after the //: this field is (was) more general.\n   Obviously, forcing other mechanisms outside DNS to use punycode\n   would be impossible. The above change is crucial, but I'm still\n   not sure that betting URIs on using only DNS forever is a good idea.\n\n- There are other fields in an URI/IRI which cannot be identified by\n   generic URI/IRI software as being host names; these have to use\n   %-escapes anyway.\n\n- I wrote http://www.ietf.org/internet-drafts/draft-ietf-idn-uri-03.txt\n   for the IDN WG. This formally proposes an update to the URI spec.\n\n- The implementation experience I have with Amaya/libwww suggests that\n   it is much easier and more natural to use %hh, at least internally.\n   Amaya doesn't know about punycode, it uses %hh throughout to talk\n   to lower layers. Libwww unescapes back, at a point it knows it\n   has a domain name, and then applies punycode. See\n   http://dev.w3.org/cvsweb/libwww/Library/src/HTDNS.c?rev=2.32.2.6&content- \nhttp://dev.w3.org/cvsweb/libwww/Library/src/HTDNS.c?rev=2.32.2.6&content-typ \ne=text/x-cvsweb-markup\n   for the actual code. In other words, the URI/IRI code doesn't need\n   to know about punycode, only the DNS-specific code needs to know.\n\n\nThe reasons I know against using %-escapes are:\n- http proxies won't understand URIs with %-escapes in the host name part.\n   (Note that this in not a problem for the Host: field, which could\n    be defined just to match, and only needs to be treated by the\n    server that does IDNs, so it's not a general update problem. Obviously\n    it's also not a problem for direct access, because one way or the\n    other, user agents have to understand IDNs if they want to support them.)\n- As you mention, syntax restrictions, although it is a long principle in\n   URI software design that you shouldn't check more than necessary, to\n   allow for extensibility.\n\n\nGiven the long list of pros, now that I have written this up, I'm\nactually surprised that I made the change. In the long run, I'm\nsure we would be much better of with using %-escapes in domain names.\n\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-0016974"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": "Hello Bjoern,\n\nI have copied the URI list, because this is a topic of mutual concern.\n\nAt 05:23 03/04/29 +0200, Bjoern Hoehrmann wrote:\n>* Martin Duerst wrote:\n> >Issue http://www.w3.org/International/iri-edit#idnuri-02 is about\n> >whether to use %-escaping or punycode to map the domain name part\n> >of an IRI to an URI. This was discussed at the IETF in San Francisco,\n> >and the general tendency there seemed to be towards using punycode.\n>\n>The hostname production rule in RFC 2396 (as updated by RFC 2732)\n>does not allow %-escaping, using %-escaping for URI conversion is\n>thus not an option, so why was this at all subject to discussion?\n\nBecause of a lot of reasons:\n\n- Some user agents actually allow it (try using IE with http://www.w%33.org)\n\n- The 'U' in URI stands (among else) for 'uniform', and so it is very\n   natural to use the same convention everywhere.\n\n- IRIs are defined in many specs (XML, XLink, XML Schema,...) without\n   the exception for domain names, so there is code out there that\n   produces (or will produce, once it receives IDNs) %-escapes.\n\n- URIs are (or were, Roy said he would change that) not limited to\n   DNS host names after the //: this field is (was) more general.\n   Obviously, forcing other mechanisms outside DNS to use punycode\n   would be impossible. The above change is crucial, but I'm still\n   not sure that betting URIs on using only DNS forever is a good idea.\n\n- There are other fields in an URI/IRI which cannot be identified by\n   generic URI/IRI software as being host names; these have to use\n   %-escapes anyway.\n\n- I wrote http://www.ietf.org/internet-drafts/draft-ietf-idn-uri-03.txt\n   for the IDN WG. This formally proposes an update to the URI spec.\n\n- The implementation experience I have with Amaya/libwww suggests that\n   it is much easier and more natural to use %hh, at least internally.\n   Amaya doesn't know about punycode, it uses %hh throughout to talk\n   to lower layers. Libwww unescapes back, at a point it knows it\n   has a domain name, and then applies punycode. See\n   http://dev.w3.org/cvsweb/libwww/Library/src/HTDNS.c?rev=2.32.2.6&content- \nhttp://dev.w3.org/cvsweb/libwww/Library/src/HTDNS.c?rev=2.32.2.6&content-typ \ne=text/x-cvsweb-markup\n   for the actual code. In other words, the URI/IRI code doesn't need\n   to know about punycode, only the DNS-specific code needs to know.\n\n\nThe reasons I know against using %-escapes are:\n- http proxies won't understand URIs with %-escapes in the host name part.\n   (Note that this in not a problem for the Host: field, which could\n    be defined just to match, and only needs to be treated by the\n    server that does IDNs, so it's not a general update problem. Obviously\n    it's also not a problem for direct access, because one way or the\n    other, user agents have to understand IDNs if they want to support them.)\n- As you mention, syntax restrictions, although it is a long principle in\n   URI software design that you shouldn't check more than necessary, to\n   allow for extensibility.\n\n\nGiven the long list of pros, now that I have written this up, I'm\nactually surprised that I made the change. In the long run, I'm\nsure we would be much better of with using %-escapes in domain names.\n\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-0027752"}, {"subject": "Re: Interpretation if %-escapes in IRIs [escapeInterpret14", "content": "Hello Bjoern,\n\nI decided to create an issue for this, even though it may\nnot require any changes.\nhttp://www.w3.org/International/iri-edit/#escapeInterpret-14\n\nAt 20:31 03/04/30 +0200, Bjoern Hoehrmann wrote:\n>* Martin Duerst wrote:\n> >>   Is there a section in the current IRI draft that specifies how\n> >>%-escapes in IRIs are to be interpreted?\n>\n> >%-escapes in IRIs are handled mostly the same way as in URIs.\n> >There is no special text about this. Do you think there should\n> >be? If yes, where should it go? What should it say?\n>\n>The %-escaping mechanism in RFC 2396 is an irreversible encoding, RFC\n>2396 says, you can escape \"&\" as %26 but it does not say, that %26 can\n>be unescaped to \"&\". RFC 2396 also does not specify how characters\n>outside the US-ASCII range have to be %-escaped, neither does the IRI\n>draft (except when IRIs are converted to URIs).\n\nmostly agreed.\n\n\n>IMO, the IRI draft should say, that if %-escaping is used in an IRI, the\n>escape sequence must be generated from UTF-8 octets and %-escapes must\n>be interpreted as octets in an UTF-8 sequence.\n\nwhy should it say so? In that case, you should not really use\n%-escaping in an IRI, you should use real characters.\n\n\n>This approach would be problematical if the IRI originates from an URI\n>that used %-escapes that could not be interpreted as UTF-8 sequence or\n>if people like to encode abitrary binary data in the IRI. The latter is\n>IMO not a valid use case for IRIs, if a specific scheme wants binary\n>data, it should first convert the bytes to characters (using e.g.\n>Base64) and then apply %-escpaping to these characters if necessary. The\n>former could be resolved by either making such URIs unconvertable or by\n>adding an additional escaping scheme for either non-UTF-8 octets or\n>UTF-8 octets (like http://www.example.org/%U0000F6 for\n>http://www.example.org/$B?\n(B, I prefer to make them unconvertable.\n\nExactly. There are definitely URIs that have escape sequences that\ndon't match UTF-8. There are examples in the latest version of the\ndraft. It can be pretty frequent that e.g. some part is UTF-8 based,\nbut another is not (e.g. the path is not, but the query part is, or\nthe other way round) In order to be able to use IRIs as a replacement\nfor URIs, we cannot have URIs that cannot be expressed as IRIs.\n\nAs for raw data, any actual examples I know support your oppinion\n(e.g. the data: URI), but still people are bringing this case up\ntoo often to just ignore it.\n\n\n>IRIs are a sequence of characters, I think this definition should not\n>change to a sequence of characters, intermixed with abitrary octets\n>after unescaping %-escapes.\n\nIRIs are a sequence of characters, correct. The same way that URIs\nare a sequence of characters. A %-escape sequence is three characters,\nboth for IRIs and for URIs. This was discussed (for the URI side)\nat length on www-tag. I don't know of any part of the draft where\nIRIs are defined as \"sequence of characters, intermixed with abitrary\noctets after unescaping %-escapes\". There is only one place where\nsuch a construct is used, in the mapping from URIs to IRIs, in\nan intermediate stage.\n\nDo you think there is a need for any clarifications to the draft?\nIf yes, where?\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0039247"}, {"subject": "Re: Interpretation if %-escapes in IRIs [escapeInterpret14", "content": "* Martin Duerst wrote:\n>>IMO, the IRI draft should say, that if %-escaping is used in an IRI, the\n>>escape sequence must be generated from UTF-8 octets and %-escapes must\n>>be interpreted as octets in an UTF-8 sequence.\n>\n>why should it say so? In that case, you should not really use\n>%-escaping in an IRI, you should use real characters.\n\nWhat if it is impossible to use \"real\" characters due limitations of the\ntransport media, the transport encoding, if I need to escape a reserved\ncharacter to avoid it's special meaning, if the character is disallowed\nor if I want to encode binary data that does not represent any\ncharacter?\n\nWhat if my IRI-aware application receives an IRI containing %-escape\nsequences but needs characters in order to work, like some kind of\nserver for file transfer expecting a file name or a database frontend\nexpecting a search string?\n\nLet's say there is an 'uri' URI scheme and an 'iri' IRI scheme (the + in\nthe query part has no special meaning and may thus stay unescaped):\n\n  uri://www.example.org/search?Bj+APY-rn\n  iri://www.example.org/search?Bj+APY-rn\n\nDecoding the query part of the URI I would get the octets\n\n  <42><6A><2B><41><50><59><2D><72><6E>\n\nThe database frontend would then search for \"Bj?rn\", since it decodes\nthe octets represented by characters in the URL as UTF-7 octets. What\nabout the IRI? Is the frontend supposed to search for \"Bj+APY-rn\" or\nfor \"Bj?rn\"? Is a data character in an IRI a character or is it a\nrepresentation of an octet or even something else?\n\nIf an IRI data character is a \"real\" character, refer %-escape sequence\nalso to real characters? Are these IRIs equivalent:\n\n  iri://www.example.org/search?Bj%F6rn\n  iri://www.example.org/search?Bj?rn\n\njust like these URIs are:\n\n  uri://www.example.org/search?a\n  uri://www.example.org/search?%61\n\nAre these equivalent:\n\n  iri://www.example.org/search?Bj%C3%B6rn\n  iri://www.example.org/search?Bj?rn\n\nand are these IRIs:\n\n  iri://www.example.org/search?a\n  iri://www.example.org/search?%61\n\nequivalent? If the latter two IRIs are equivalent, how would one then\nencode binary data in an IRI? What octets are represented in the query\npart of e.g.\n\n  iri://www.example.org/search?<U+20AC>\n  iri://www.example.org/search?<U+1D7F6>\n\nConsider I want to send an IRI in a text/plain e-mail using us-ascii,\nbut the IRI has non-ASCII characters, like\n\n  iri://www.example.org/bj?rn\n\ncan I use %-escaping to encode the \"?\" and if yes, how would the IRI\nthen look like? Would it be\n\n  iri://www.example.org/bj%F6rn\n  iri://www.example.org/bj%ECrn\n  iri://www.example.org/bj%C3%B6rn\n  iri://www.example.org/bj%00%F6rn\n  ...\n\nCurrently neither RFC 2396 nor the IRI draft give an advise here. Is\nthis a scenario not supported by IRIs? If yes, why do you think it is\nnot necessary or not possible to support it, and why does the IRI draft\nnot mention that %-escaping cannot be used for non-ASCII characters, but\nrather says it SHOULD NOT be used? If it is possible to use %-escaping\nfor non-ASCII characters, the IRI draft must say how the non-ASCII\ncharacter have to be encoded (actually, how any character is to be\nencoded) and should say, how one gets the characters back.\n\nregards.\n\n\n\n", "id": "lists-017-0050304"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": "* Martin Duerst wrote:\n>> >Issue http://www.w3.org/International/iri-edit#idnuri-02 is about\n>> >whether to use %-escaping or punycode to map the domain name part\n>> >of an IRI to an URI. This was discussed at the IETF in San Francisco,\n>> >and the general tendency there seemed to be towards using punycode.\n>>\n>>The hostname production rule in RFC 2396 (as updated by RFC 2732)\n>>does not allow %-escaping, using %-escaping for URI conversion is\n>>thus not an option, so why was this at all subject to discussion?\n>\n>Because of a lot of reasons:\n>\n>[...]\n\nThese are reasons to change RFC 2396 in a way that allows %-escapes\nin the hostname component (and probably other components). Has this\nbeen considered and refused?\n\nThe only reason to create %-escapes in the hostname part when converting\nIRIs to URIs is simplicity and simplicity is bad when it breaks in\nconforming implementations. Even though I wrote software that does not\nhandle %-escapes in the hostname component (but rather fails to parse\nthe URI or keeps the escape sequence) and I know a lot of code that\nneither supports it (many PHP scripts, for example), I would support to\nchange the production rule in RFC 2396bis, e.g.\n\n>- IRIs are defined in many specs (XML, XLink, XML Schema,...) without\n>   the exception for domain names, so there is code out there that\n>   produces (or will produce, once it receives IDNs) %-escapes.\n\nthis is a very good reason to do so. Various W3C Recommendations require\nconforming applications or recommend to generate invalid URIs (as error\nrecovery from invalid URIs, oh well...) Not that all implementations\nimplement these recommendations or requirements (not even the W3C MarkUp\nValidator does), but there is indeed a lot of code out there that does,\nso we have an interoperability problem here.\n\nIf RFC 2396bis does not change the hostname production rule (and\nprobably others), should there be errata for HTML4, XML, etc. to deal\nwith internationalized domain names? Errata or not, should existing\napplications be updated to avoid %-escapes in the hostname part? I\nimplemented what HTML4 recommends for invalid URIs in HTML Tidy, it\ncurrently \"correctly\" changes\n\n  <a href='http://bj%f6rn.h%f6hrmann.de/'>...</a>\n\nto\n\n  <a href='http://bj%C3%B6rn.h%C3%B6hrmann.de/'>...</a>\n\nShould Tidy try to keep the hostname part unchanged, should it use\npunycode or should Tidy continue to create invalid URI references? Tidy\ngives a warning if an %URI; attribute value contains invalid characters,\nshould Tidy give an additional warning if the hostname component\ncontains invalid/non-ascii characters? Should Tidy give a specific\nwarning if the hostname component contains %-escapes?\n\nAs we are here, should Tidy NFC-normalize the %URI; attribute value\nbefore escaping it (IRI draft) or should it keep it as-is (HTML 4.01)?\n\n>The reasons I know against using %-escapes are:\n\n  * A lot of existing software does not handle %-escapes in hostnames,\n    it breaks existing conforming software\n\n  * Spam filters might consider messages containing them as spam, since\n    up to now invalid %-escapes in the hostname were used only by spam\n    messages to hide the real link destination\n\n  * punycode can safely be transcoded to Unicode; what domain name\n    refers http://bj%F6rn/ to? IRI conversion could generate such\n    a URI if the %F6 is an artifact from URI=>IRI conversion and if you\n    expect implementers to handle %-escapes, you need to define how,\n    punycode already solved this issue.\n\n  * if you have no idea what %C3%B6 could mean, what looks worse,\n    %-escapes or punycode? Ok, %-escapes might win here...\n\nWell, I am pro a change to RFC 2396bis and I agree that the benefits\noutweight reasons against such a change, and iff RFC 2396bis changes\nthe production rule(s), the IRI specification could use %-escapes rather\nthan punycode. I am uncertain whether it should, punycode is more\nreliable while %-escapes is consistent with existing defined error\nrecovery behaivour.\n\nSo, again, why not change RFC 2396bis?\n\n\n\n", "id": "lists-017-0060905"}, {"subject": "Re: Some issues with the IRI document [legacyNFC06", "content": "Hello Paul,\n\nI'm closing this issue. Thanks for your help.\n\nRegards,    Martin.\n\nAt 16:06 03/04/17 -0700, Paul Hoffman / IMC wrote:\n\n>At 5:22 PM -0400 4/17/03, Martin Duerst wrote:\n>>I have changed variant B) in step 1) of section 3.1 from\n>>\n>>    If the IRI is in some digital representation\n>>    (e.g. an octet stream) in some non-Unicode encoding:\n>>    Convert the IRI to a sequence of characters from the UCS\n>>    normalized according to NFC.\n>>\n>>to\n>>\n>>    If the IRI is in some digital representation\n>>    (e.g. an octet stream) in some *known* non-Unicode encoding:\n>>    Convert the IRI to a sequence of characters from the UCS\n>>    normalized according to NFC.\n>>\n>>(emphasis only here).\n>>\n>>Do you think that this helps, or do you think that other changes\n>>are needed?\n>\n>It certainly helps. That, plus the other changes you have made about \n>spelling out UTF-8, makes it clear.\n>\n>--Paul Hoffman, Director\n>--Internet Mail Consortium\n\n\n\n", "id": "lists-017-0073099"}, {"subject": "Re: Some issues with the IRI document [applicabilityUTF810", "content": "Hello Paul,\n\nSorry for the delay, I was traveling.\n\nAt 16:04 03/04/17 -0700, Paul Hoffman / IMC wrote:\n\n>At 5:35 PM -0400 4/17/03, Martin Duerst wrote:\n>>Can you please check whether you are okay with the new section at\n>>http://www.w3.org/International/iri-edit/draft-duerst-iri.html#UTF8use,\n>>or whether you think that it needs some stronger normative wording?\n>\n>Yep, that's much better.\n>\n>One suggestion, though: the last sentence of the third paragraph of that \n>section ends \"...the escaped octets cannot be converted to actual \n>characters in an IRI, because the escaping is based on iso-8859-1 rather \n>than UTF-8.\" That is true, but it brings in an encoding issue that isn't \n>necessary. I propose \"...the escaped octets cannot be converted to actual \n>characters in an IRI, because the escaping is not encoded as UTF-8.\"\n\nI have removed the reference to iso-8859-1, although I have\nleft the text as \"escaping is not based on UTF-8\" rather than\n\"escaping is not encoded as UTF-8\".\n\nI hope this is okay with you, and I'm closing the issue.\nPlease tell me if you don't like it, and want the issue kept open.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0080990"}, {"subject": "Closing issue [arabicnum03", "content": "This serves to close\nhttp://www.w3.org/International/iri-edit/#arabicnum-03.\n\nI had put this issue on the issues list because in examples\n7-9 of the BidiExamples page\n(http://www.w3.org/International/iri-edit/BidiExamples),\nI saw Arabic-Indic digits in the Arabic examples rather\nthan the European digits that I was expecting.\n\nFurther examination has shown that this is a browser issue.\nNetscape 7 (/Mozilla) is the only browser that I have found\nthat converts digit shapes when displaying them. Tango,\nIE6, Safari, and Opera don't change digit shapes.\n\nSection 13.3 (http://www.unicode.org/book/ch13.pdf, p. 320)\nof Unicode 3.0 is clear that nominal behavior (not changing\nthe glyphs used to display the digits) is correct, and\nusing national digit shaping would only be acceptable if\nusing the deprecated and strongly discouraged numeric\nshape selectors (which I have of course not used).\nSo Netscape/Mozilla is wrong here, and should be fixed.\nI have told somebody in the i18n team at Netscape.\n\nI have added a note at the top of the BidiExamples page\nsaying that a browser doing digit shaping correctly should\nbe used. I have closed this issue.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0089715"}, {"subject": "Re: Some issues with the IRI document [applicabilityUTF810", "content": "At 3:41 PM -0400 5/2/03, Martin Duerst wrote:\n>I have removed the reference to iso-8859-1, although I have\n>left the text as \"escaping is not based on UTF-8\" rather than\n>\"escaping is not encoded as UTF-8\".\n\nWorks for me.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-017-0097835"}, {"subject": "Closing issue [arabicnum03", "content": "Hello Martin,\nRegarding numeric  shapes in the browser, they should follow the system\nsettings, so if it is contextual or national they should appear in Arabic\ndigits. Otherwise they should appear in European digits.\nSo Netscape is working properly, please don't ask to disable this feature.\nalso IE behaves the same way.\nNumeric shapes are part of the country culture and should not be\ndeprecated.\n\nHave a nice day\nRasha Morgan\n------------------------------------------------------------------------\nThe Hardest victory is victory over self. Aristotle\n------------------------------------------------------------------------\nAdvisory Globalization Specialist, team leader\nIBM Egypt Branch,\nPyramids Heights,\nBuilding No. 10\n22 Km. Cairo - Alex. Desert Road,\nGuiza, Egypt.\nTel:  SB: +202 5392539    ext 1409        DID: +202 536 1409\nFax. +20 2 539 2505\n\nE-mail : rasham@eg.ibm.com\nVM     : RASHAM  at  IBMEG\nhttp://ctdc.cairo.ibm.com/CairoTDCWebsite/home.jsp\n\n\n\n----- Forwarded by Rasha Morgan/Egypt/IBM on 06/05/2003 01:18 ? -----\n\n----- Forwarded by Ahmed Talaat/Egypt/IBM on 04/05/2003 12:47 ? -----\n\n\n---------------------- Forwarded by Matitiahu Allouche/Israel/IBM on\n04/05/2003 09:50 ---------------------------\n\n\nMartin Duerst <duerst@w3.org>@w3.org on 02/05/2003 23:57:44\n\nSent by:    public-iri-request@w3.org\n\n\nTo:    public-iri@w3.org\ncc:\n\nSubject:    Closing issue [arabicnum-03]\n\n\nThis serves to close\nhttp://www.w3.org/International/iri-edit/#arabicnum-03.\n\nI had put this issue on the issues list because in examples\n7-9 of the BidiExamples page\n(http://www.w3.org/International/iri-edit/BidiExamples),\nI saw Arabic-Indic digits in the Arabic examples rather\nthan the European digits that I was expecting.\n\nFurther examination has shown that this is a browser issue.\nNetscape 7 (/Mozilla) is the only browser that I have found\nthat converts digit shapes when displaying them. Tango,\nIE6, Safari, and Opera don't change digit shapes.\n\nSection 13.3 (http://www.unicode.org/book/ch13.pdf, p. 320)\nof Unicode 3.0 is clear that nominal behavior (not changing\nthe glyphs used to display the digits) is correct, and\nusing national digit shaping would only be acceptable if\nusing the deprecated and strongly discouraged numeric\nshape selectors (which I have of course not used).\nSo Netscape/Mozilla is wrong here, and should be fixed.\nI have told somebody in the i18n team at Netscape.\n\nI have added a note at the top of the BidiExamples page\nsaying that a browser doing digit shaping correctly should\nbe used. I have closed this issue.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0105175"}, {"subject": "Re: Closing issue [arabicnum03", "content": "Hello Rasha,\n\nMany thanks for your comments.\n\nAt 14:09 03/05/06 +0300, Rasha Morgan wrote:\n>Hello Martin,\n>Regarding numeric  shapes in the browser, they should follow the system\n>settings,\n\nI have a Japanese system, and don't remember having made such\na system setting. And you seem to imply that if such a system\nsetting is present, all the digits would appear as Arabic\ndigits. Fortunately for me, that's not the case. Even on the page\nin question (http://www.w3.org/International/iri-edit/BidiExamples),\nonly digits in vicinity of Arabic characters change shape.\nI'm not sure what the rule/algorithm is that Netscape uses for this.\nI don't like undefined (and therefore unpredictable and varying)\nbehavior.\n\n\n>so if it is contextual or national they should appear in Arabic\n>digits. Otherwise they should appear in European digits.\n\nWho made up this rule? Unicode clearly states otherwise, as I already\nhave explained (see below). And HTML and XML are based on Unicode.\n\n\n>So Netscape is working properly, please don't ask to disable this feature.\n>also IE behaves the same way.\n\nIn my case, IE doesn't, as I have explained before (see below).\n\n\n>Numeric shapes are part of the country culture and should not be\n>deprecated.\n\nI haven't said anything that would deprecate Arabic(-Indic) digits.\nUnicode has them, and anybody who wants to use them can use them.\nHowever, I wanted the digits in my page, which are European digits,\nto be displayed as European digits, and I think any browser (or other\napplication, for that matter) that tries to change this behind my\nback is doing something wrong.\n\nRegards,    Martin.\n\n\n\n>Have a nice day\n>Rasha Morgan\n>------------------------------------------------------------------------\n>The Hardest victory is victory over self. Aristotle\n>------------------------------------------------------------------------\n>Advisory Globalization Specialist, team leader\n>IBM Egypt Branch,\n>Pyramids Heights,\n>Building No. 10\n>22 Km. Cairo - Alex. Desert Road,\n>Guiza, Egypt.\n>Tel:  SB: +202 5392539    ext 1409        DID: +202 536 1409\n>Fax. +20 2 539 2505\n>\n>E-mail : rasham@eg.ibm.com\n>VM     : RASHAM  at  IBMEG\n>http://ctdc.cairo.ibm.com/CairoTDCWebsite/home.jsp\n>\n>\n>\n>----- Forwarded by Rasha Morgan/Egypt/IBM on 06/05/2003 01:18 $Bc (B-----\n>\n>----- Forwarded by Ahmed Talaat/Egypt/IBM on 04/05/2003 12:47 $Bc (B-----\n>\n>\n>---------------------- Forwarded by Matitiahu Allouche/Israel/IBM on\n>04/05/2003 09:50 ---------------------------\n>\n>\n>Martin Duerst <duerst@w3.org>@w3.org on 02/05/2003 23:57:44\n>\n>Sent by:    public-iri-request@w3.org\n>\n>\n>To:    public-iri@w3.org\n>cc:\n>\n>Subject:    Closing issue [arabicnum-03]\n>\n>\n>This serves to close\n>http://www.w3.org/International/iri-edit/#arabicnum-03.\n>\n>I had put this issue on the issues list because in examples\n>7-9 of the BidiExamples page\n>(http://www.w3.org/International/iri-edit/BidiExamples),\n>I saw Arabic-Indic digits in the Arabic examples rather\n>than the European digits that I was expecting.\n>\n>Further examination has shown that this is a browser issue.\n>Netscape 7 (/Mozilla) is the only browser that I have found\n>that converts digit shapes when displaying them. Tango,\n>IE6, Safari, and Opera don't change digit shapes.\n>\n>Section 13.3 (http://www.unicode.org/book/ch13.pdf, p. 320)\n>of Unicode 3.0 is clear that nominal behavior (not changing\n>the glyphs used to display the digits) is correct, and\n>using national digit shaping would only be acceptable if\n>using the deprecated and strongly discouraged numeric\n>shape selectors (which I have of course not used).\n>So Netscape/Mozilla is wrong here, and should be fixed.\n>I have told somebody in the i18n team at Netscape.\n>\n>I have added a note at the top of the BidiExamples page\n>saying that a browser doing digit shaping correctly should\n>be used. I have closed this issue.\n>\n>Regards,    Martin.\n\n\n\n", "id": "lists-017-0118287"}, {"subject": "Re: Closing issue [arabicnum03", "content": "Please refer to the following bug for this issue:\n\nhttp://bugzilla.mozilla.org/show_bug.cgi?id=181711\n\nRasha, I think you should argue your position in the above bug if you\nfeel strongly but Simon indicates in his latest comments that Gecko\nshould follow Section 13.3 of Unicode 3.0 as referred to by Martin.\n\n- Kat\n\nMartin Duerst wrote:\n\n> Hello Rasha,\n>\n> Many thanks for your comments.\n>\n> At 14:09 03/05/06 +0300, Rasha Morgan wrote:\n>\n>> Hello Martin,\n>> Regarding numeric shapes in the browser, they should follow the system\n>> settings,\n>\n>\n> I have a Japanese system, and don't remember having made such\n> a system setting. And you seem to imply that if such a system\n> setting is present, all the digits would appear as Arabic\n> digits. Fortunately for me, that's not the case. Even on the page\n> in question (http://www.w3.org/International/iri-edit/BidiExamples),\n> only digits in vicinity of Arabic characters change shape.\n> I'm not sure what the rule/algorithm is that Netscape uses for this.\n> I don't like undefined (and therefore unpredictable and varying)\n> behavior.\n>\n>\n>> so if it is contextual or national they should appear in Arabic\n>> digits. Otherwise they should appear in European digits.\n>\n>\n> Who made up this rule? Unicode clearly states otherwise, as I already\n> have explained (see below). And HTML and XML are based on Unicode.\n>\n>\n>> So Netscape is working properly, please don't ask to disable this\n>> feature.\n>> also IE behaves the same way.\n>\n>\n> In my case, IE doesn't, as I have explained before (see below).\n>\n>\n>> Numeric shapes are part of the country culture and should not be\n>> deprecated.\n>\n>\n> I haven't said anything that would deprecate Arabic(-Indic) digits.\n> Unicode has them, and anybody who wants to use them can use them.\n> However, I wanted the digits in my page, which are European digits,\n> to be displayed as European digits, and I think any browser (or other\n> application, for that matter) that tries to change this behind my\n> back is doing something wrong.\n>\n> Regards, Martin.\n>\n>\n>\n>> Have a nice day\n>> Rasha Morgan\n>> ------------------------------------------------------------------------\n>> The Hardest victory is victory over self. Aristotle\n>> ------------------------------------------------------------------------\n>> Advisory Globalization Specialist, team leader\n>> IBM Egypt Branch,\n>> Pyramids Heights,\n>> Building No. 10\n>> 22 Km. Cairo - Alex. Desert Road,\n>> Guiza, Egypt.\n>> Tel: SB: +202 5392539 ext 1409 DID: +202 536 1409\n>> Fax. +20 2 539 2505\n>>\n>> E-mail : rasham@eg.ibm.com\n>> VM : RASHAM at IBMEG\n>> http://ctdc.cairo.ibm.com/CairoTDCWebsite/home.jsp\n>>\n>>\n>>\n>> ----- Forwarded by Rasha Morgan/Egypt/IBM on 06/05/2003 01:18 $Bc\n>> (B-----\n>>\n>> ----- Forwarded by Ahmed Talaat/Egypt/IBM on 04/05/2003 12:47 $Bc\n>> (B-----\n>>\n>>\n>> ---------------------- Forwarded by Matitiahu Allouche/Israel/IBM on\n>> 04/05/2003 09:50 ---------------------------\n>>\n>>\n>> Martin Duerst <duerst@w3.org>@w3.org on 02/05/2003 23:57:44\n>>\n>> Sent by: public-iri-request@w3.org\n>>\n>>\n>> To: public-iri@w3.org\n>> cc:\n>>\n>> Subject: Closing issue [arabicnum-03]\n>>\n>>\n>> This serves to close\n>> http://www.w3.org/International/iri-edit/#arabicnum-03.\n>>\n>> I had put this issue on the issues list because in examples\n>> 7-9 of the BidiExamples page\n>> (http://www.w3.org/International/iri-edit/BidiExamples),\n>> I saw Arabic-Indic digits in the Arabic examples rather\n>> than the European digits that I was expecting.\n>>\n>> Further examination has shown that this is a browser issue.\n>> Netscape 7 (/Mozilla) is the only browser that I have found\n>> that converts digit shapes when displaying them. Tango,\n>> IE6, Safari, and Opera don't change digit shapes.\n>>\n>> Section 13.3 (http://www.unicode.org/book/ch13.pdf, p. 320)\n>> of Unicode 3.0 is clear that nominal behavior (not changing\n>> the glyphs used to display the digits) is correct, and\n>> using national digit shaping would only be acceptable if\n>> using the deprecated and strongly discouraged numeric\n>> shape selectors (which I have of course not used).\n>> So Netscape/Mozilla is wrong here, and should be fixed.\n>> I have told somebody in the i18n team at Netscape.\n>>\n>> I have added a note at the top of the BidiExamples page\n>> saying that a browser doing digit shaping correctly should\n>> be used. I have closed this issue.\n>>\n>> Regards, Martin.\n>\n>\n-- \nKatsuhiko Momoi <momoi@netscape.com>\nSenior International Manager, Web Standards/Embedding\nNetscape Technology Evangelism/Developer Support\n\n\n\n", "id": "lists-017-0133006"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": "> These are reasons to change RFC 2396 in a way that allows %-escapes\n> in the hostname component (and probably other components). Has this\n> been considered and refused?\n\nYes, it has been considered and refused.  The IETF developed IDNA in\norder to avoid the need for operating system infrastructure to be\nupdated en masse prior to deployment of i18n domains.  URI processors\nare part of that infrastructure and the rationale for not changing them\nis the same as that provided for not globally changing the \nimplementations\nof BIND.\n\nIRIs have to be processed by applications that accept the burden of\nfull Unicode processing already.  URIs do not.  Adding punycode\ninterpretation to the processing of URIs or gethostbyname simply\nwill not happen because that technology is already deployed.  Thus,\nin order to make deployment possible, punycode processing moves up\na layer and URIs are specified such that it becomes easier for the\nIRI processor to determine where it is needed.\n\nSchemes that use DNS within components other than authority will have\nto provide their own percent-encoding-to-punycode processing, but that's\nno big deal because there are no such schemes deployed that actually\nuse the domain name for DNS access (they simply use it for \nidentification,\nwhich does not require punycode).\n\n....Roy\n\n\n\n", "id": "lists-017-0148431"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": "On Tue, 2003-05-06 at 16:49, Roy T. Fielding wrote:\n> > These are reasons to change RFC 2396 in a way that allows %-escapes\n> > in the hostname component (and probably other components). Has this\n> > been considered and refused?\n> \n> Yes, it has been considered and refused.\n\nIf I'm following correctly, that's documented at...\nhttp://www.apache.org/~fielding/uri/rev-2002/issues.html#036-host-escaping\n\n\n>   The IETF developed IDNA in\n> order to avoid the need for operating system infrastructure to be\n> updated en masse prior to deployment of i18n domains.  URI processors\n> are part of that infrastructure and the rationale for not changing them\n> is the same as that provided for not globally changing the \n> implementations\n> of BIND.\n> \n> IRIs have to be processed by applications that accept the burden of\n> full Unicode processing already.  URIs do not.  Adding punycode\n> interpretation to the processing of URIs or gethostbyname simply\n> will not happen because that technology is already deployed.  Thus,\n> in order to make deployment possible, punycode processing moves up\n> a layer and URIs are specified such that it becomes easier for the\n> IRI processor to determine where it is needed.\n\nHas anybody got an example to show how this works?\n\nI'm trying to collecte examples/tests, if only to keep\nall this stuff straight in my own mind.\n\n> \n> Schemes that use DNS within components other than authority will have\n> to provide their own percent-encoding-to-punycode processing, but that's\n> no big deal because there are no such schemes deployed that actually\n> use the domain name for DNS access (they simply use it for \n> identification,\n> which does not require punycode).\n> \n> ....Roy\n\n-- \nDan Connolly, W3C http://www.w3.org/People/Connolly/\n\n\n\n", "id": "lists-017-0157888"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": "At 16:59 03/05/06 -0500, Dan Connolly wrote:\n>On Tue, 2003-05-06 at 16:49, Roy T. Fielding wrote:\n> > > These are reasons to change RFC 2396 in a way that allows %-escapes\n> > > in the hostname component (and probably other components). Has this\n> > > been considered and refused?\n> >\n> > Yes, it has been considered and refused.\n>\n>If I'm following correctly, that's documented at...\n>http://www.apache.org/~fielding/uri/rev-2002/issues.html#036-host-escaping\n\nYes.\n\n\n> >   The IETF developed IDNA in\n> > order to avoid the need for operating system infrastructure to be\n> > updated en masse prior to deployment of i18n domains.  URI processors\n> > are part of that infrastructure and the rationale for not changing them\n> > is the same as that provided for not globally changing the\n> > implementations\n> > of BIND.\n\nURI processors are clearly part of infrastructure. But the decision\nfor IDNA wasn't that everything else should use punycode blindly.\nThe various issues have to be reconsidered at each level.\nIn general, URI processors are quite a bit closer to actual\nuser-oriented applications than DNS calls.\n\n\n> > IRIs have to be processed by applications that accept the burden of\n> > full Unicode processing already.  URIs do not.  Adding punycode\n> > interpretation to the processing of URIs or gethostbyname simply\n> > will not happen because that technology is already deployed.  Thus,\n> > in order to make deployment possible, punycode processing moves up\n> > a layer and URIs are specified such that it becomes easier for the\n> > IRI processor to determine where it is needed.\n\nI think we should be very careful about initial deployment\n(for which I agree) and longer-term deployment, for which\nI have to disagree.\n\n\n>Has anybody got an example to show how this works?\n\nFor example servers that actually work, see\nhttp://www.w3.org/2003/Talks/0425-duerst-idniri/slide12-0.html.\nFor each bullet, the first link uses the actual IDN\n(internationalized domain name), the second link is the\nmangled punycode equivalent. Unless you have a *very* new\nbrowser or a special IDN plugin, only the second ones will work.\n\nIf you want to test out how some actual IDN converts to punycode,\nI suggest looking at http://josefsson.org/idn.php. Just enter\nyour IDN (or copy/paste), and you get the punycode back.\n\n\n>I'm trying to collecte examples/tests, if only to keep\n>all this stuff straight in my own mind.\n\nFor actual code, see my recent commits to libwww (on the IDN branch),\ne.g. http://dev.w3.org/cvsweb/libwww/Library/src/HTDNS.c\nThis actually compiles and works on my machine (Win2000), but\nhasn't been tested further than that. This is based on\nidnkit by JPNIC (where I gave a talk 1.5 weeks ago, see\nslides above).\n\nPlease note that while I agree with Roy that there is an initial\ndeployment problem, when anybody actually gets to implement IDNs,\nit makes sense to implement them (i.e. do the IDN->punycode conversion)\nas low as possible. In libwww, I did that just before the call\nto 'gethostbyname'. The main other thing I had to add was the Host:\nheader. But defining the Host: header to be %-escaped, or even to\nbe in UTF-8, would not cause any deployment problems that I know of\n(this stuff is new, we just have to tell people what to do).\nThe main issue that Roy's approach makes easier are proxies.\nWe have to assume that clients who want to use IDNs have to\nupdate in some way, and we also can assume that servers serving\nIDNs can be asked to do some upgrade. Proxies are in the middle,\nand expecting them to upgrade soon is difficult.\n\nAnother datapoint showing that actual implementations will tend\nto go as low as possible in the stack is idnkit itself. It\nactually allows to patch binaries, if the software is e.g.\nwritten according to the posix locale model.\n\nSo I expect that in languages such as python and perl, which\nare getting better and better at their character encoding model,\nthe equivalent of 'gethostbyname' will accept IDNs. Initially,\nthat will be implemented by using an outside idn library, but\nlater, it will be using the idn code provided by the OS.\n\n\nAnother case that it worth considering is domain names in other\npositions that 'authority'. Roy said:\n >>>>>>>>\nSchemes that use DNS within components other than authority will have\nto provide their own percent-encoding-to-punycode processing, but that's\nno big deal because there are no such schemes deployed that actually\nuse the domain name for DNS access (they simply use it for identification,\nwhich does not require punycode).\n >>>>>>>>\n\nI'm not sure I understand that. A simple HTTP URI, such as the one\nsent to the W3C validator, can contain a domain name. People trying\nto validate URIs with IDNs won't want to do a punycode conversion in\ntheir head. So the validator will have to be upgraded to accept things\nsuch as\nhttp://validator.w3.org/check?uri=http%3A%2F%2F%E7%B4%8D%E8%B1%86.w3.mag.kei \no.ac.jp.\n\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-0168104"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": "At 7:15 PM -0400 5/6/03, Martin Duerst wrote:\n>If you want to test out how some actual IDN converts to punycode,\n>I suggest looking at http://josefsson.org/idn.php. Just enter\n>your IDN (or copy/paste), and you get the punycode back.\n\nThere is another one at <http://www.imc.org/idna/>, which uses \ncompletely different code.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-017-0182001"}, {"subject": "Re: Closing issue [arabicnum03", "content": "If I remember well, the preference for number shaping appears (in Windows \nRegional Options) only when the selected locale is an Arabic one.  This \npreference determines whether digits (hexa 30 to 39) should be presented \nalways as European numbers, always as Hindi numbers or depending on \ncontext.  Depending on context means that hexa 30 to 39 are presented as \nEuropean numbers when the last previous letter was not an Arabic one, and \nas Hindi numbers if it was an Arabic letter.\n\nThis is not undefined, nor unpredictable and varying, to use Martin's \nwords.\n\nSection 13.3 in TUS 3.0 only deprecates using Numeric Shape selectors \n(U+206E and U+206F) to control the glyphs used for presenting numbers. The \nlast sentence says \"This state (nominal) is the default state in the \nabsence of any numeric shape selector or a higher-level protocol\", which \nleaves the door open to selection of digit glyphs based on a higher-level \nprotocol.   Preferences at the Operating System level or at the browser \nlevel are definitely a higher-level protocol, and they should be \nconsidered good Unicode citizens, IMHO.\n\nSo it seems to me that Netscape is performing correctly (I don't remember \nhow it sets its default handling of numeric shaping, probably not based on \nWindows preferences, since it tries to be platform independent), and IE \nbehaves differently because it relies on the Windows preferences, which on \na Japanese-locale will always select the European glyphs for numbers.\n\n\nShalom (Regards),  Mati\n           Bidi Architect\n           Globalization Center Of Competency - Bidirectional Scripts\n           IBM Israel\n           Phone: +972 2 5888802    Fax: +972 2 5870333    Mobile: +972 52 \n554160\n\n\nTo:        Martin Duerst <duerst@w3.org>\ncc:        Rasha Morgan/Egypt/IBM@IBMEG, public-iri@w3.org, Matitiahu \nAllouche/Israel/IBM@IBMIL, Ahmed Talaat/Egypt/IBM@IBMEG, Gilan \nFelfela/Egypt/IBM@IBMEG, Tarek Abou Aly/Egypt/IBM@IBMEG, Mark \nDavis/Cupertino/IBM@IBMUS, Mark Davis <mark@macchiato.com>, Simon Montagu \n<smontagu@netscape.com>, Yung-Fong Tang <ytang0648@aol.com> \nSubject:        Re: Closing issue [arabicnum-03]\n\n\n\nPlease refer to the following bug for this issue:\n\nhttp://bugzilla.mozilla.org/show_bug.cgi?id=181711\n\nRasha, I think you should argue your position in the above bug if you\nfeel strongly but Simon indicates in his latest comments that Gecko\nshould follow Section 13.3 of Unicode 3.0 as referred to by Martin.\n\n- Kat\n\nMartin Duerst wrote:\n\n> Hello Rasha,\n>\n> Many thanks for your comments.\n>\n> At 14:09 03/05/06 +0300, Rasha Morgan wrote:\n>\n>> Hello Martin,\n>> Regarding numeric shapes in the browser, they should follow the system\n>> settings,\n>\n>\n> I have a Japanese system, and don't remember having made such\n> a system setting. And you seem to imply that if such a system\n> setting is present, all the digits would appear as Arabic\n> digits. Fortunately for me, that's not the case. Even on the page\n> in question (http://www.w3.org/International/iri-edit/BidiExamples),\n> only digits in vicinity of Arabic characters change shape.\n> I'm not sure what the rule/algorithm is that Netscape uses for this.\n> I don't like undefined (and therefore unpredictable and varying)\n> behavior.\n>\n>\n>> so if it is contextual or national they should appear in Arabic\n>> digits. Otherwise they should appear in European digits.\n>\n>\n> Who made up this rule? Unicode clearly states otherwise, as I already\n> have explained (see below). And HTML and XML are based on Unicode.\n>\n>\n>> So Netscape is working properly, please don't ask to disable this\n>> feature.\n>> also IE behaves the same way.\n>\n>\n> In my case, IE doesn't, as I have explained before (see below).\n>\n>\n>> Numeric shapes are part of the country culture and should not be\n>> deprecated.\n>\n>\n> I haven't said anything that would deprecate Arabic(-Indic) digits.\n> Unicode has them, and anybody who wants to use them can use them.\n> However, I wanted the digits in my page, which are European digits,\n> to be displayed as European digits, and I think any browser (or other\n> application, for that matter) that tries to change this behind my\n> back is doing something wrong.\n>\n> Regards, Martin.\n>\n>\n>\n>> Have a nice day\n>> Rasha Morgan\n>> Advisory Globalization Specialist, team leader\n>> IBM Egypt Branch,\n>> ----- Forwarded by Rasha Morgan/Egypt/IBM on 06/05/2003 01:18 -----\n>>\n>> ----- Forwarded by Ahmed Talaat/Egypt/IBM on 04/05/2003 12:47 -----\n>>\n>>\n>> ---------------------- Forwarded by Matitiahu Allouche/Israel/IBM on\n>> 04/05/2003 09:50 ---------------------------\n>>\n>>\n>> Martin Duerst <duerst@w3.org>@w3.org on 02/05/2003 23:57:44\n>>\n>> Sent by: public-iri-request@w3.org\n>>\n>>\n>> To: public-iri@w3.org\n>> cc:\n>>\n>> Subject: Closing issue [arabicnum-03]\n>>\n>>\n>> This serves to close\n>> http://www.w3.org/International/iri-edit/#arabicnum-03.\n>>\n>> I had put this issue on the issues list because in examples\n>> 7-9 of the BidiExamples page\n>> (http://www.w3.org/International/iri-edit/BidiExamples),\n>> I saw Arabic-Indic digits in the Arabic examples rather\n>> than the European digits that I was expecting.\n>>\n>> Further examination has shown that this is a browser issue.\n>> Netscape 7 (/Mozilla) is the only browser that I have found\n>> that converts digit shapes when displaying them. Tango,\n>> IE6, Safari, and Opera don't change digit shapes.\n>>\n>> Section 13.3 (http://www.unicode.org/book/ch13.pdf, p. 320)\n>> of Unicode 3.0 is clear that nominal behavior (not changing\n>> the glyphs used to display the digits) is correct, and\n>> using national digit shaping would only be acceptable if\n>> using the deprecated and strongly discouraged numeric\n>> shape selectors (which I have of course not used).\n>> So Netscape/Mozilla is wrong here, and should be fixed.\n>> I have told somebody in the i18n team at Netscape.\n>>\n>> I have added a note at the top of the BidiExamples page\n>> saying that a browser doing digit shaping correctly should\n>> be used. I have closed this issue.\n>>\n>> Regards, Martin.\n>\n>\n--\nKatsuhiko Momoi <momoi@netscape.com>\nSenior International Manager, Web Standards/Embedding\nNetscape Technology Evangelism/Developer Support\n\n\n\n", "id": "lists-017-0190510"}, {"subject": "Re: Closing issue [arabicnum03", "content": "Mati,\n\nThanks for your comments. My comments below.\n\nMatitiahu Allouche wrote:\n\n>If I remember well, the preference for number shaping appears (in Windows \n>Regional Options) only when the selected locale is an Arabic one.  This \n>preference determines whether digits (hexa 30 to 39) should be presented \n>always as European numbers, always as Hindi numbers or depending on \n>context.  Depending on context means that hexa 30 to 39 are presented as \n>European numbers when the last previous letter was not an Arabic one, and \n>as Hindi numbers if it was an Arabic letter.\n>\n>This is not undefined, nor unpredictable and varying, to use Martin's \n>words.\n>\n>Section 13.3 in TUS 3.0 only deprecates using Numeric Shape selectors \n>(U+206E and U+206F) to control the glyphs used for presenting numbers. The \n>last sentence says \"This state (nominal) is the default state in the \n>absence of any numeric shape selector or a higher-level protocol\", which \n>leaves the door open to selection of digit glyphs based on a higher-level \n>protocol.   Preferences at the Operating System level or at the browser \n>level are definitely a higher-level protocol, and they should be \n>considered good Unicode citizens, IMHO.\n>\n>So it seems to me that Netscape is performing correctly (I don't remember \n>how it sets its default handling of numeric shaping, probably not based on \n>Windows preferences, since it tries to be platform independent), and IE \n>behaves differently because it relies on the Windows preferences, which on \n>a Japanese-locale will always select the European glyphs for numbers.\n>\nMy experiments on Windows XP-en shows that when the locale is set to \nArabic/Egypt, IE6 and NN7.02 behave exactly the same as far as \ncontextual numeral changes are concerned, i.e. they both perform numeral \nchanges.\n\nBut when the locale is something other than a bidi one, NN7.02 still \nperforms contextual numeral changes while IE6 does not. This seems to be \nwhat Martin noticed on his Japanese locale Windows.\n\nIf the parity with IE6 is what we want, we might change this behavior so \nthat the pref item, bidi.numeral, will have a value of  \"1\" (i.e. \nnumeral change occurs) only if the user locale is a bidi one.\n\n- Kat\n\n>\n>\n>Shalom (Regards),  Mati\n>           Bidi Architect\n>           Globalization Center Of Competency - Bidirectional Scripts\n>           IBM Israel\n>           Phone: +972 2 5888802    Fax: +972 2 5870333    Mobile: +972 52 \n>554160\n>\n>\n>To:        Martin Duerst <duerst@w3.org>\n>cc:        Rasha Morgan/Egypt/IBM@IBMEG, public-iri@w3.org, Matitiahu \n>Allouche/Israel/IBM@IBMIL, Ahmed Talaat/Egypt/IBM@IBMEG, Gilan \n>Felfela/Egypt/IBM@IBMEG, Tarek Abou Aly/Egypt/IBM@IBMEG, Mark \n>Davis/Cupertino/IBM@IBMUS, Mark Davis <mark@macchiato.com>, Simon Montagu \n><smontagu@netscape.com>, Yung-Fong Tang <ytang0648@aol.com> \n>Subject:        Re: Closing issue [arabicnum-03]\n>\n>\n>\n>Please refer to the following bug for this issue:\n>\n>http://bugzilla.mozilla.org/show_bug.cgi?id=181711\n>\n>Rasha, I think you should argue your position in the above bug if you\n>feel strongly but Simon indicates in his latest comments that Gecko\n>should follow Section 13.3 of Unicode 3.0 as referred to by Martin.\n>\n>- Kat\n>\n>Martin Duerst wrote:\n>\n>  \n>\n>>Hello Rasha,\n>>\n>>Many thanks for your comments.\n>>\n>>At 14:09 03/05/06 +0300, Rasha Morgan wrote:\n>>\n>>    \n>>\n>>>Hello Martin,\n>>>Regarding numeric shapes in the browser, they should follow the system\n>>>settings,\n>>>      \n>>>\n>>I have a Japanese system, and don't remember having made such\n>>a system setting. And you seem to imply that if such a system\n>>setting is present, all the digits would appear as Arabic\n>>digits. Fortunately for me, that's not the case. Even on the page\n>>in question (http://www.w3.org/International/iri-edit/BidiExamples),\n>>only digits in vicinity of Arabic characters change shape.\n>>I'm not sure what the rule/algorithm is that Netscape uses for this.\n>>I don't like undefined (and therefore unpredictable and varying)\n>>behavior.\n>>\n>>\n>>    \n>>\n>>>so if it is contextual or national they should appear in Arabic\n>>>digits. Otherwise they should appear in European digits.\n>>>      \n>>>\n>>Who made up this rule? Unicode clearly states otherwise, as I already\n>>have explained (see below). And HTML and XML are based on Unicode.\n>>\n>>\n>>    \n>>\n>>>So Netscape is working properly, please don't ask to disable this\n>>>feature.\n>>>also IE behaves the same way.\n>>>      \n>>>\n>>In my case, IE doesn't, as I have explained before (see below).\n>>\n>>\n>>    \n>>\n>>>Numeric shapes are part of the country culture and should not be\n>>>deprecated.\n>>>      \n>>>\n>>I haven't said anything that would deprecate Arabic(-Indic) digits.\n>>Unicode has them, and anybody who wants to use them can use them.\n>>However, I wanted the digits in my page, which are European digits,\n>>to be displayed as European digits, and I think any browser (or other\n>>application, for that matter) that tries to change this behind my\n>>back is doing something wrong.\n>>\n>>Regards, Martin.\n>>\n>>\n>>\n>>    \n>>\n>>>Have a nice day\n>>>Rasha Morgan\n>>>Advisory Globalization Specialist, team leader\n>>>IBM Egypt Branch,\n>>>----- Forwarded by Rasha Morgan/Egypt/IBM on 06/05/2003 01:18 -----\n>>>\n>>>----- Forwarded by Ahmed Talaat/Egypt/IBM on 04/05/2003 12:47 -----\n>>>\n>>>\n>>>---------------------- Forwarded by Matitiahu Allouche/Israel/IBM on\n>>>04/05/2003 09:50 ---------------------------\n>>>\n>>>\n>>>Martin Duerst <duerst@w3.org>@w3.org on 02/05/2003 23:57:44\n>>>\n>>>Sent by: public-iri-request@w3.org\n>>>\n>>>\n>>>To: public-iri@w3.org\n>>>cc:\n>>>\n>>>Subject: Closing issue [arabicnum-03]\n>>>\n>>>\n>>>This serves to close\n>>>http://www.w3.org/International/iri-edit/#arabicnum-03.\n>>>\n>>>I had put this issue on the issues list because in examples\n>>>7-9 of the BidiExamples page\n>>>(http://www.w3.org/International/iri-edit/BidiExamples),\n>>>I saw Arabic-Indic digits in the Arabic examples rather\n>>>than the European digits that I was expecting.\n>>>\n>>>Further examination has shown that this is a browser issue.\n>>>Netscape 7 (/Mozilla) is the only browser that I have found\n>>>that converts digit shapes when displaying them. Tango,\n>>>IE6, Safari, and Opera don't change digit shapes.\n>>>\n>>>Section 13.3 (http://www.unicode.org/book/ch13.pdf, p. 320)\n>>>of Unicode 3.0 is clear that nominal behavior (not changing\n>>>the glyphs used to display the digits) is correct, and\n>>>using national digit shaping would only be acceptable if\n>>>using the deprecated and strongly discouraged numeric\n>>>shape selectors (which I have of course not used).\n>>>So Netscape/Mozilla is wrong here, and should be fixed.\n>>>I have told somebody in the i18n team at Netscape.\n>>>\n>>>I have added a note at the top of the BidiExamples page\n>>>saying that a browser doing digit shaping correctly should\n>>>be used. I have closed this issue.\n>>>\n>>>Regards, Martin.\n>>>      \n>>>\n>>    \n>>\n>--\n>Katsuhiko Momoi <momoi@netscape.com>\n>Senior International Manager, Web Standards/Embedding\n>Netscape Technology Evangelism/Developer Support\n>\n>  \n>\n-- \nKatsuhiko Momoi <momoi@netscape.com>\nSenior International Manager, Web Standards/Embedding\nNetscape Technology Evangelism/Developer Support\n\n\n\n", "id": "lists-017-0210981"}, {"subject": "Re: Some issues with the IRI document [NFCsecurity09", "content": "Hello Simon,\n\nSorry for the delay in moving this issue forward.\n\nAt 00:09 03/04/17 +0200, Simon Josefsson wrote:\n\n>Martin Duerst <duerst@w3.org> writes:\n>\n> > NFC is only required in the current draft when encoding something\n> > from e.g. the side of a bus, or when transcoding it from a non-\n> > Unicode encoding. This is only to provide a base level of\n> > predictability.\n>\n>Section 2.4 says \"IRIs SHOULD be created using Normalization Form C\n>(NFC).\"  I don't interprete that to only apply to the scenarios you\n>mention, rather it seem to imply that whenever a IRI is created, by\n>whatever process, NFC should be used.  Perhaps it can be clarified?\n\nI see what you mean. It definitely should be qualified. The intent\nis NOT to use NFC in all cases. That's why the SHOULD is there.\nIf there is some underlying data that is not in NFC, then\nnormalizing to NFC when creating the IRI is a bad idea.\nI haven't yet worded this out, but I think that's what the\ndocument should say. Would that remove your concerns?\n\n\n> > Still indeed this could lead to security problems with the\n> > mechanisms you describe above, if there are two users that have user\n> > names that only differ in normalization. But it would seem to me\n> > that in this case, the security issue comes from these mechanisms\n> > (or the actual use with these specific user names) rather than from\n> > IRIs.\n>\n>If this is so, I believe the IRI security considerations should\n>mention this so that people can be aware of it, and abstain from\n>deploying IRIs in systems that behave in this way,\n\nI think it's not a problem of systems, but a problem of\nthe individual IRIs. I.e. if there are two user names that\nonly differ by normalization, then there is no reason not\nto use IRIs for all the other users.\n\n\n>since doing so\n>would introduce problems.  Perhaps some properly worded text could\n>be derived from the following strawman?\n>\n>    Whenever fields of an IRI are normalized, the octet representation\n>    is modified.  While this is unavoidable if ambiguities are to be\n>    resolved, it can raise security issues in some situations.  In\n>    particular, if a iuserinfo field is normalized, a security protocol\n>    expecting a certain byte sequence as a username may receive a\n>    different one.  This can lead to interoperability failures, but\n>    also more serious failures in systems, e.g. when the system\n>    performs authorization based on the username.\n\nI'm currently not convinced we need this text (assuming the\nclarifications I outlined at the start of this mail).\nIRIs are not normalized at will. If they are normalized\nwhen transcoding from legacy encodings, then the problem\nis in the legacy encoding, because the legacy encoding isn't\nable to distinguish e.g. the two user names.\nIn addition, as I have said, creating two user names that\ndiffer only by normalization is a security issue for whoever\ncreated these user names, not an issue for IRIs.\nAlso, a system that performs authorization based on\nuser name (alone) is a serious security issue, again not\nthe fault of IRIs.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0231040"}, {"subject": "Re: Some issues with the IRI document [NFCsecurity09", "content": "Martin Duerst <duerst@w3.org> writes:\n\n> Hello Simon,\n>\n> Sorry for the delay in moving this issue forward.\n\nHello.\n\n>> > NFC is only required in the current draft when encoding something\n>> > from e.g. the side of a bus, or when transcoding it from a non-\n>> > Unicode encoding. This is only to provide a base level of\n>> > predictability.\n>>\n>>Section 2.4 says \"IRIs SHOULD be created using Normalization Form C\n>>(NFC).\"  I don't interprete that to only apply to the scenarios you\n>>mention, rather it seem to imply that whenever a IRI is created, by\n>>whatever process, NFC should be used.  Perhaps it can be clarified?\n>\n> I see what you mean. It definitely should be qualified. The intent\n> is NOT to use NFC in all cases. That's why the SHOULD is there.\n> If there is some underlying data that is not in NFC, then\n> normalizing to NFC when creating the IRI is a bad idea.\n> I haven't yet worded this out, but I think that's what the\n> document should say. Would that remove your concerns?\n\nI think so, yes.\n\n>> > Still indeed this could lead to security problems with the\n>> > mechanisms you describe above, if there are two users that have user\n>> > names that only differ in normalization. But it would seem to me\n>> > that in this case, the security issue comes from these mechanisms\n>> > (or the actual use with these specific user names) rather than from\n>> > IRIs.\n>>\n>>If this is so, I believe the IRI security considerations should\n>>mention this so that people can be aware of it, and abstain from\n>>deploying IRIs in systems that behave in this way,\n>\n> I think it's not a problem of systems, but a problem of\n> the individual IRIs. I.e. if there are two user names that\n> only differ by normalization, then there is no reason not\n> to use IRIs for all the other users.\n\nIf I were to design the system, and knew IRIs couldn't distinguish\nbetween two international words that may be used in customers deployed\nsystems, I'd be cautious about using IRIs at all.  I'm mostly only\nfamiliar with NFKC and it would generate these hassles, and perhaps\nNFC avoids them.\n\n>>    Whenever fields of an IRI are normalized, the octet representation\n>>    is modified.  While this is unavoidable if ambiguities are to be\n>>    resolved, it can raise security issues in some situations.  In\n>>    particular, if a iuserinfo field is normalized, a security protocol\n>>    expecting a certain byte sequence as a username may receive a\n>>    different one.  This can lead to interoperability failures, but\n>>    also more serious failures in systems, e.g. when the system\n>>    performs authorization based on the username.\n>\n> I'm currently not convinced we need this text (assuming the\n> clarifications I outlined at the start of this mail).\n\nGiven clarifications, it would have to be modified, and if the\nspecification defined the exact situations where normalization is used\nmore clearly, it could probably be dropped alltogether.\n\n> IRIs are not normalized at will. If they are normalized\n> when transcoding from legacy encodings, then the problem\n> is in the legacy encoding, because the legacy encoding isn't\n> able to distinguish e.g. the two user names.\n> In addition, as I have said, creating two user names that\n> differ only by normalization is a security issue for whoever\n> created these user names, not an issue for IRIs.\n\nI'm not convinced by this.  Existing deployed solutions, like SASL,\nsupports all valid UTF-8 strings as user names.  There has been no\nwarnings presented that administrators should not pick user names that\nonly differ by normalization.  So if IRIs may arbitrary NFC strings,\nit is IRIs that introduce a security problem that wasn't there before.\nPeople would have a problem to start using IRIs without redesigning\ntheir existing systems.\n\n> Also, a system that performs authorization based on\n> user name (alone) is a serious security issue, again not\n> the fault of IRIs.\n\nI assumed users are authenticated before the authorization process\nstarts, which is the case in the systems I'm familiar with.\n\n\n\n", "id": "lists-017-0241924"}, {"subject": "Re: Closing issue [arabicnum03", "content": "Hello Momoi-san,\nIE reads the system settings and accordingly decides about the numeric\nshapes.\nHowever Netscape/Mozilla try to be system independent, so to solve this\nthey defaulted to contextual shaping, this might not be the best option in\nsome Arab countries, so what can be done is to default to contextual when\nthe default browser locale is for one of the Arab countries which use\nNational digits.\nOr optimally to add in the preference an item for the Arabic numeric shapes\nfor the user to choose.\n\nHave a nice day\nRasha Morgan\n------------------------------------------------------------------------\nThe Hardest victory is victory over self. Aristotle\n---------------------------------------------------------------------------\nAdvisory Globalization Specialist, team leader\nIBM Egypt Branch,\nPyramids Heights,\nBuilding No. 10\n22 Km. Cairo - Alex. Desert Road,\nGuiza, Egypt.\nTel:  SB: +202 5392539    ext 1409        DID: +202 536 1409\nFax. +20 2 539 2505\n\nE-mail : rasham@eg.ibm.com\nVM     : RASHAM  at  IBMEG\nhttp://ctdc.cairo.ibm.com/CairoTDCWebsite/home.jsp\n\n\n\n\n\n                                                                                                                                       \n                      momoi@netscape.co                                                                                                \n                      m (Katsuhiko             To:       Matitiahu Allouche/Israel/IBM@IBMIL                                           \n                      Momoi)                   cc:       Martin Duerst <duerst@w3.org>, Rasha Morgan/Egypt/IBM@IBMEG,                  \n                                                public-iri@w3.org, Ahmed Talaat/Egypt/IBM@IBMEG, Gilan Felfela/Egypt/IBM@IBMEG, Tarek  \n                      08/05/2003 07:03          Abou Aly/Egypt/IBM@IBMEG, Mark Davis/Cupertino/IBM@IBMUS, Mark Davis                   \n                      ?                         <mark@macchiato.com>, Simon Montagu <smontagu@netscape.com>, Yung-Fong Tang            \n                                                <ytang0648@aol.com>                                                                    \n                                               Subject:  Re: Closing issue [arabicnum-03]                                              \n                                                                                                                                       \n                                                                                                                                       \n                                                                                                                                       \n\n\n\nMati,\n\nThanks for your comments. My comments below.\n\nMatitiahu Allouche wrote:\n      If I remember well, the preference for number shaping appears (in\n      Windows\n      Regional Options) only when the selected locale is an Arabic one.\n      This\n      preference determines whether digits (hexa 30 to 39) should be\n      presented\n      always as European numbers, always as Hindi numbers or depending on\n      context.  Depending on context means that hexa 30 to 39 are presented\n      as\n      European numbers when the last previous letter was not an Arabic one,\n      and\n      as Hindi numbers if it was an Arabic letter.\n\n      This is not undefined, nor unpredictable and varying, to use Martin's\n\n      words.\n\n      Section 13.3 in TUS 3.0 only deprecates using Numeric Shape selectors\n\n      (U+206E and U+206F) to control the glyphs used for presenting\n      numbers. The\n      last sentence says \"This state (nominal) is the default state in the\n      absence of any numeric shape selector or a higher-level protocol\",\n      which\n      leaves the door open to selection of digit glyphs based on a\n      higher-level\n      protocol.   Preferences at the Operating System level or at the\n      browser\n      level are definitely a higher-level protocol, and they should be\n      considered good Unicode citizens, IMHO.\n\n      So it seems to me that Netscape is performing correctly (I don't\n      remember\n      how it sets its default handling of numeric shaping, probably not\n      based on\n      Windows preferences, since it tries to be platform independent), and\n      IE\n      behaves differently because it relies on the Windows preferences,\n      which on\n      a Japanese-locale will always select the European glyphs for numbers.\nMy experiments on Windows XP-en shows that when the locale is set to\nArabic/Egypt, IE6 and NN7.02 behave exactly the same as far as contextual\nnumeral changes are concerned, i.e. they both perform numeral changes.\n\nBut when the locale is something other than a bidi one, NN7.02 still\nperforms contextual numeral changes while IE6 does not. This seems to be\nwhat Martin noticed on his Japanese locale Windows.\n\nIf the parity with IE6 is what we want, we might change this behavior so\nthat the pref item, bidi.numeral, will have a value of  \"1\" (i.e. numeral\nchange occurs) only if the user locale is a bidi one.\n\n- Kat\n\n\n\n\n      Shalom (Regards),  Mati\n                 Bidi Architect\n                 Globalization Center Of Competency - Bidirectional Scripts\n                 IBM Israel\n                 Phone: +972 2 5888802    Fax: +972 2 5870333    Mobile:\n      +972 52\n      554160\n\n\n      To:        Martin Duerst <duerst@w3.org>\n      cc:        Rasha Morgan/Egypt/IBM@IBMEG, public-iri@w3.org, Matitiahu\n\n      Allouche/Israel/IBM@IBMIL, Ahmed Talaat/Egypt/IBM@IBMEG, Gilan\n      Felfela/Egypt/IBM@IBMEG, Tarek Abou Aly/Egypt/IBM@IBMEG, Mark\n      Davis/Cupertino/IBM@IBMUS, Mark Davis <mark@macchiato.com>, Simon\n      Montagu\n      <smontagu@netscape.com>, Yung-Fong Tang <ytang0648@aol.com>\n      Subject:        Re: Closing issue [arabicnum-03]\n\n\n\n      Please refer to the following bug for this issue:\n\n      http://bugzilla.mozilla.org/show_bug.cgi?id=181711\n\n      Rasha, I think you should argue your position in the above bug if you\n      feel strongly but Simon indicates in his latest comments that Gecko\n      should follow Section 13.3 of Unicode 3.0 as referred to by Martin.\n\n      - Kat\n\n      Martin Duerst wrote:\n\n\n            Hello Rasha,\n\n            Many thanks for your comments.\n\n            At 14:09 03/05/06 +0300, Rasha Morgan wrote:\n\n\n                  Hello Martin,\n                  Regarding numeric shapes in the browser, they should\n                  follow the system\n                  settings,\n\n\n            I have a Japanese system, and don't remember having made such\n            a system setting. And you seem to imply that if such a system\n            setting is present, all the digits would appear as Arabic\n            digits. Fortunately for me, that's not the case. Even on the\n            page\n            in question (\n            http://www.w3.org/International/iri-edit/BidiExamples),\n            only digits in vicinity of Arabic characters change shape.\n            I'm not sure what the rule/algorithm is that Netscape uses for\n            this.\n            I don't like undefined (and therefore unpredictable and\n            varying)\n            behavior.\n\n\n\n                  so if it is contextual or national they should appear in\n                  Arabic\n                  digits. Otherwise they should appear in European digits.\n\n\n            Who made up this rule? Unicode clearly states otherwise, as I\n            already\n            have explained (see below). And HTML and XML are based on\n            Unicode.\n\n\n\n                  So Netscape is working properly, please don't ask to\n                  disable this\n                  feature.\n                  also IE behaves the same way.\n\n\n            In my case, IE doesn't, as I have explained before (see below).\n\n\n\n                  Numeric shapes are part of the country culture and should\n                  not be\n                  deprecated.\n\n\n            I haven't said anything that would deprecate Arabic(-Indic)\n            digits.\n            Unicode has them, and anybody who wants to use them can use\n            them.\n            However, I wanted the digits in my page, which are European\n            digits,\n            to be displayed as European digits, and I think any browser (or\n            other\n            application, for that matter) that tries to change this behind\n            my\n            back is doing something wrong.\n\n            Regards, Martin.\n\n\n\n\n                  Have a nice day\n                  Rasha Morgan\n                  Advisory Globalization Specialist, team leader\n                  IBM Egypt Branch,\n                  ----- Forwarded by Rasha Morgan/Egypt/IBM on 06/05/2003\n                  01:18 -----\n\n                  ----- Forwarded by Ahmed Talaat/Egypt/IBM on 04/05/2003\n                  12:47 -----\n\n\n                  ---------------------- Forwarded by Matitiahu\n                  Allouche/Israel/IBM on\n                  04/05/2003 09:50 ---------------------------\n\n\n                  Martin Duerst <duerst@w3.org>@w3.org on 02/05/2003\n                  23:57:44\n\n                  Sent by: public-iri-request@w3.org\n\n\n                  To: public-iri@w3.org\n                  cc:\n\n                  Subject: Closing issue [arabicnum-03]\n\n\n                  This serves to close\n                  http://www.w3.org/International/iri-edit/#arabicnum-03.\n\n                  I had put this issue on the issues list because in\n                  examples\n                  7-9 of the BidiExamples page\n                  (http://www.w3.org/International/iri-edit/BidiExamples),\n                  I saw Arabic-Indic digits in the Arabic examples rather\n                  than the European digits that I was expecting.\n\n                  Further examination has shown that this is a browser\n                  issue.\n                  Netscape 7 (/Mozilla) is the only browser that I have\n                  found\n                  that converts digit shapes when displaying them. Tango,\n                  IE6, Safari, and Opera don't change digit shapes.\n\n                  Section 13.3 (http://www.unicode.org/book/ch13.pdf, p.\n                  320)\n                  of Unicode 3.0 is clear that nominal behavior (not\n                  changing\n                  the glyphs used to display the digits) is correct, and\n                  using national digit shaping would only be acceptable if\n                  using the deprecated and strongly discouraged numeric\n                  shape selectors (which I have of course not used).\n                  So Netscape/Mozilla is wrong here, and should be fixed.\n                  I have told somebody in the i18n team at Netscape.\n\n                  I have added a note at the top of the BidiExamples page\n                  saying that a browser doing digit shaping correctly\n                  should\n                  be used. I have closed this issue.\n\n                  Regards, Martin.\n\n\n\n      --\n      Katsuhiko Momoi <momoi@netscape.com>\n      Senior International Manager, Web Standards/Embedding\n      Netscape Technology Evangelism/Developer Support\n\n\n--\nKatsuhiko Momoi <momoi@netscape.com>\nSenior International Manager, Web Standards/Embedding\nNetscape Technology Evangelism/Developer Support\n\n\n\n", "id": "lists-017-0253538"}, {"subject": "Turismo Rural  promo??es fant?sticas / promociones fant?stico", "content": "==== Arribes del Duero === Nature Park of Douro International === Parque Natural do Douro Internacional =====\n\n\n  Centro de Turismo Rural (4 estrellas) - di?ria apenas 35 Euros por persona, pension completa !!!      \n\n\n  Rural Tourism (4 stars Inn) - diary only 35 Euros per person, full pension!!!      \n\n\nTurismo Rural (4 estrelas) - di?ria apenas 35 Euros por pessoa em pens?o completa !!!      \n\n\n                               \n\n\nContacto / Contact\n                                                                                              \nEstalagem SOLAR DOS MARCOS\nRua de santa cruz\n5200-055 BEMPOSTA\nParque Natural Internacional das Arribas do Douro\nTel:+351  279570010\nFax: +351279570019\nE.mail: marcos.marcos@oninet.pt\nWEB:  www.marcos-e-marcos.pt\n\n\n========================= castelhano ================================\nEstimados Se?ores: \nPor la presente le informamos que en el ?Solar dos Marcos? (centro de turismo rural de 4 estrellas)  hace un rebaja / promocion fant?sticos para que usted puede venir a desfrutar de unos dias de descanso in este rincon de los Arribes del Duero, muy cerca de Fermoselle (Castilla-Le?n).\n\nPrecio de di?ria, pension completa 35 Euros por persona\n\nEsta promocion es valida em los meses de Maio e Junio\n\ny entre los dias de la semana - Martes asta Jueves (incluido)\n\n\nHaga usted hoy su reserva !\n\n============================ Sobre el Solar dos Marcos ======================\n\nEl edificio es clasificado, adaptado de una vieja residencia episcopal (Sec. XVIII) y situado en la aldea de Bemposta, en el parque natural lleno del Douro internacional, es un lugar obligatorio para reclinarse y para apreciar los placeres de la regi?n. \n\nEl solar comtempla 4 cuartos dobles, 4 cuartos de pares y a?n 1 habitaci?n. \nTodos los cuartos m?s la habitaci?n poseen el casa-de-ba?o privative con la ba?era, el sat?lite de la TV, la calefacci?n central y el exterior privative del varanda para el jard?n. Uno de los cuartos respeta las condiciones de los acessibilidades para los ciudadanos en la silla de ruedas. Servicio disponible el almuerzo peque?o y comidas en los cuartos. \n\nEl solar  tiene disponible a restaurante/bar, sitio congresos, lig?ndose de los el Internet y a?n un servicio religioso semanal en nuestra capilla privative. Nuestras hu?spedes todav?a tienen discountings en los programas de la animaci?n tur?stica. \n\nEl Douro internacional es una regi?n desigual que preserv? su abundancia natural, para conocerles ancestral, de la gente simple y hospitalaria, que puede ser apreciada hoy por el visitante de esta parte magn?fica del mundo. \n\nEl solar tiene disponible un programa de la animaci?n, de que incluye circuitos internacionales con la gu?a, da un paseo el barco en el r?o Douro, o uno \"viaje\" de del autom?vil, de con los peatones de las incursiones, de para la llave de los puntos y de de un inter?s m?s grande el parque natural los del Douro y parque de \"Los Arribes del Duero\" en Espa?a. \n\n\n \n========================= english ===================================\n\nDear Sir,\n\nTake a chance to visit Solar dos Marcos - 4 star Inn - in the Nature Park of Douro International, Portugal, near the border \nwith Spain. \n\n- Daily price per person, in full pension - 35 Euros\n\nThis promotion is valid during May and June, between \nTuesday until Thursday, inclusive. \n\nCome to visit us. Make your reservations still today !\n\n======================== About Solar dos Marcos =========================\nClassified building, adapted of an old episcopal residence (Sec. XVIII) and situated in the village of Bemposta, in full Natural Park of the International Douro, is a place of obligator stopping to rest and to appreciate the delights of the region. \n\nThe Solar contemplates 4 double rooms, 4 rooms of couple and still 1 Suite. All the rooms more the Suite possess privative house-of-bath with bathtub, TV satellite, central heating and varanda privative exterior for the garden. One of the rooms respects the conditions of acessibilidades for citizens in chair of wheels. Available service of small lunch and meals in the rooms. \n\nThe Solar has still available to restaurante/bar, room of congresses, linking to the InterNet and still a weekly religious service in our privative chapel. Our guests still have discountings in the programs of tourist animation. The International Douro is an uneven region that preserved its natural wealth, to know them ancestral, of simple and hospitable people, that today can be appreciated by the visitor of this magnificent part of the world. \n\nThe Solar has available a animation program, that includes circuits with guide, stroll of boat in the river Douro, or one \"tour\" of automobile, with incursions pedestrians, for the points key and of bigger interest of both Natural Park of the International Douro and Park of \"Los Arribes del Duero\" in Spain. \n\n========================= portugu?s =================================\nEx.mos Srs,\n\nAproveite esta campanha de promo??o de turismo alternativo no Solar dos Marcos (estalagem de quatro estrelas), no Parque Natural de Douro Internacional. \n\nDi?ria com Pens?o Completa - 35, Euros / pessoa \n\nEsta promo??o ? v?lida durante os meses de Maio e Junho\ne de Ter?a a Quinta-feira, inclusiv?.\n\nFa?a hoje j? a sua reserva !\n\n========================= Sobre o Solar dos Marcos =====\nEdif?cio classificado, adaptado duma velha resid?ncia episcopal (Sec. XVIII) e situado na aldeia de Bemposta, em pleno Parque Natural do Douro Internacional, ? um local de paragem obrigat?ria para  repousar e apreciar as del?cias da regi?o.\n\nO Solar dos Marcos contempla 4 quartos duplos, 4 quartos de casal e ainda 1 Suite.\n\nTodos os quartos mais a Suite possuem casa-de-banho privativa com banheira, TV sat?lite, aquecimento central e varanda privativa exterior para o jardim.\nUm dos quartos respeita as condi??es de acessibilidades para cidad?os em cadeira de rodas. \n\nDispon?vel servi?o de pequeno almo?o e refei??es nos quartos. \n\nO Solar dos Marcos tem ainda dispon?vel um restaurante/bar, sala de congressos, liga??o ? Internet e ainda um servi?o religioso semanal na nossa capela privativa. \n\nOs nossos h?spedes tem ainda descontos nos programas de anima??o tur?stica. \n\n\n\n", "id": "lists-017-0280995"}, {"subject": "draft-duerst-iri05.tx", "content": "I have made the following updates to the IRI draft\nand submitted as draft-duerst-iri-05.txt. See\nhttp://www.w3.org/International/iri-edit for\nthe newest version, or\nhttp://www.ietf.org/internet-drafts/draft-duerst-iri-05.txt\nfor the actual publication. This is what I have done:\n\nChanges based on input from Michel Suignard:\n- Added a definition for 'running text'\n- Removed definition (and a couple usages) of code point/codepoint\n- Added explanation for <hh> octet notation used in 3.2.1\n   to 1.4 Notation.\n- Removed \"Note:\" from \"Note: To reduce variability,\n   the hexadecimal notation SHOULD use upper case letters.\"\n- Fixed alignement problem for IRI syntax rule.\n- Reorganized some of the text in 3.1 to avoid making\n   normative statements in notes, and to have the normative\n   statements first. Also, removed reference to previous\n   drafts (without changing substance).\n- Fixed example \"&#x10300;&#x10301;&#x10301;\" to\n   \"&#x10300;&#x10301;&#x10302;\"\n- Changed production name 'isegment' to 'ipath-segment'\n   to make clearer that it is a path segment.\n- tweaked language on using NFKC, by replacing\n   \"Using NFKC will avoid even more problems.\" with\n   \"Using NFKC may avoid even more problems,\n    for example by choosing half-width Latin letters instead of full-width,\n    and full-width Katakana instead of half-width.\"\n- Reworded the paragarph starting \"Because we do not know...\" that\n   explains the overall normalization strategy. Made it less personal,\n   and made it a note.\n- Uppercased 'SHOULD NOT' in \"It SHOULD NOT be applied between\n   components that are known to be able to handle IRIs.\"\n- Rewrote \"On the other hand, the HTTP URL scheme does not specify\n   how to encode original characters, and therefore IRIs only can be\n   used for some HTTP URLs.\" to\n- Clarified paragaraph that was saying:\n   \"As an example of variant settings, input method editors for East\n    Asian Languages usually allow the input of Latin letters and related\n    characters in full-width or half-width versions. For IRI input, the\n    input method editor should be set to half-width input, in order\n    to produce US-ASCII characters where possible.\"\n   to make clear to use half-width for Latin, and full-width for Katakana:\n   \"As an example of variant settings, input method editors for East\n    Asian Languages usually allow the input of Latin letters and related\n    characters in full-width or half-width versions. For IRI input, the\n    input method editor should be set so that it produces half-width\n    Latin letters, and full-width Katakana.\"\n- In the next paragraph, changed 'should' to 'may'.\n- Removed \"Display software should be upgraded only after upgraded\n   entry software has been widely deployed to the population that\n   will see the displayed result.\" because it's unclear, and it seems\n   the opposite is actually happening.\n- Moved a paragraph in the security section.\n\n\nOther things done:\n- Added a reference to http://www.w3.org/DesignIssues/ModelConsequences\n   to explain why conversion from Unicode to punycode is only applied\n   in the position just after //.\n- Added a new example 10 in the bidi section based on input from\n   Roy Badami (and put him in the acks).\n- Updated some references.\n- Added something about query parts at the end of 6.4\n\n\nRegards,   Martin. \n\n\n\n", "id": "lists-017-0326190"}, {"subject": "RE: ambiguity in BNF: no nonnumeric TLDs", "content": "[moved over to the IRI list from the URI list]\n\nAt 18:29 03/11/13 -0800, Michel Suignard wrote:\n\n>I guess we need to make sure we have similar text in IRI.\n\nI have just added it to the internal draft\n(see http://www.w3.org/International/iri-edit)\n\nRegards,    Martin.\n\n\n>BTW Roy, when can we expect your revised RFC2396 text to move ahead? IRI\n>has a dependency on it.\n>\n>Michel\n>\n>-----Original Message-----\n>From: Roy T. Fielding [mailto:fielding@apache.org]\n>\n> > Can we assume that TLDs will be non-numeric?\n>\n>Yes, but we can't assume that the last domain is a TLD.\n>\n> > It looks to me that the BNF is ambiguous between hostname and IPv4\n> > addresses because the BNF for hostname doesn't rule out\n> >   nnn.nnn.nnn.nnn\n>\n>Yes, it says that in the text describing the rule:\n>\n>     The production for host is ambiguous because it does not completely\n>     distinguish between an IPv4address and a hostname.  Again, the\n>     \"first-match-wins\" algorithm applies: If host matches the production\n>     for IPv4address, then it should be considered an IPv4 address\n>literal\n>     and not a hostname.\n>\n>All of our attempts to disambiguate within the grammar itself did not\n>work because, without a trailing \".\", there is no way to know which is\n>the TLD.\n>\n>....Roy\n\n\n\n", "id": "lists-017-0335712"}, {"subject": "Bidi: now I'm confuse", "content": "Ok, I have a problem with what I understand to be the display model\nfor IDNA and IRI (and presumably by extension IMA).\n\nI'm assuming that the display model is 'render using bidi in an LTR\ncontext'.\n\nSpecifically, the IRI draft says:\n\n  When rendered, bidirectional IRIs MUST be rendered using the Unicode\n  Bidirectional Algorithm [UNIV4], [UNI9]. Bidirectional IRIs MUST be\n  rendered with an overall left-to-right (ltr) direction.\n\nThe latter requirement isn't specified in bidi-speak, but is\npresumably to be interpreted as saying they must be rendered at an\neven embedding level.  Actually, this isn't quite enough in the\ngeneral case, since what comes before the string may affect weak type\nresolution, but since IRIs generally start with a latin letter\n(generally 'h' :) this isn't really much of a problem.\n\nSo lets for the moment assume that the display model is that IDNs,\nIRIs, IMAs are rendered at an even embedding level, such that the\nIDN/IRI/IMA constitutes the sole text in the level run.  (This can\neasily be achieved by bracketing the string with LRE and PDF prior to\nrendering.)\n\nConsider the domain:\n\n123.ARAB.com (logical order)\n123.BARA.com (display order)\n\nnow consider the domain:\n\nARAB.123.com (logical order)\n123.BARA.com (display order)\n\nErgo, we need another display model; this one doesn't work, at least\nnot if we don't want two completely different domains to display\nidentically.\n\nI recall that there was a proposal on the IDN list that domains should\nalways be rendered with the labels appearing in order, least\nsignificant to the left and top-level domain on the right.  (This can\nbe trivially achieved by bracketing each label with LRE/PDF,\nseparating the labels with dots, and then bracketing the whole domain\nwith LRE/PDF.)\n\nThis would solve the above problem, but potentially might be less\nfriendly to users of RTL languages in other ways.\n\nIt also clearly is not what the authors of stringprep had in mind,\nsince the bidi restrictions in stringprep are much stronger than would\nbe necessary if this was the model.\n\n-roy\n\n\n\n", "id": "lists-017-0365673"}, {"subject": "Bidi: now I'm confuse", "content": "I wrote:\n > Ergo, we need another display model; this one doesn't work \n\nThere are also other real nasties with this display model:\n\nARABIC.3com.com (logical order)\n3.CIBARAcom.com (display order)\n\nARABIC.3-com.com (logical order)\n3.CIBARA-com.com (display order)\n\nHEBREW.3-com.com (logical order)\n3-.WERBEHcom.com (display order)\n\n\n-roy\n\n\n\n", "id": "lists-017-0374518"}, {"subject": "Bidi: is stringprep broken", "content": "I wrote:\n\n >  > Ergo, we need another display model; this one doesn't work \n > There are also other real nasties with this display model:\n\nWorse than that, I think the bidi restrictions in stringprep don't\nactually achieve their goal of ensuring that you can't have two\ndifferent labels that render the same.\n\nConsider the labels:\n\nA-123,456B\n\nand\n\nA456,-123B\n\nHere, A is HEBREW LETTER ALEF, B is HEBREW LETTER BET (or any\ncharacters of bidi class R that you like, but *not* arabic letters,\nwhich are class AL) and the comma is actually ARABIC COMMA U+060C (or\nany character of class CS or ES).\n\nAs far as I can tell these both pass nameprep with UseSTD13ASCIIRules\nset, and they both render identically under bidi as:\n\nB-123,456A\n\nIf you don't care about UseSTD13ASCIIRules, you can replace\nARABIC COMMA with COMMA, SOLIDUS or COLON.\n\nI fully expect someone to reply explaining why I'm mistaken, but I've\nchecked the above as best I can...\n\n-roy\n\n\n\n", "id": "lists-017-0382026"}, {"subject": "Re: Bidi: is stringprep broken", "content": "According to my understanding, and to testing against the Unicode C \nreference implementation, you are correct in stating that the 2 strings (\"A-123,456B\" and \"A456,-123B\") will give the same display according to the Unicode algorithm for \nBidirectional text.\n\nIt proves that you have a more creative mind than the people who proposed \nthe limitations for Bidi names in IRIs, at least more than mine.\n\nYou will admit that your example is more than a little contrived.  The \nlimitations set on IRIs intend to avoid ambiguity when converting from the \ndisplay order to the logical order (which in this case is not achieved, \nalthough the vast majority of users would assume form A-123,456B, because the other form with the comma adjacent to a minus sign makes \nlittle sense in a domain name).  But those limitations were also designed \nnot to restrict too much the potential of creating interesting domain \nnames, so a compromise had to be achieved.  I  can find other examples of \nnames allowed by the rules which can mislead users trying to induce the \nlogical order based on the display order.  All of these examples are quite \nbizarre.\n\nBy the way, can you give a reference to \"UseSTD13ASCIIRules\", for an ignoramus like myself?\n\nShalom (Regards),  Mati\n           Bidi Architect\n           Globalization Center Of Competency - Bidirectional Scripts\n           IBM Israel\n           Phone: +972 2 5888802    Fax: +972 2 5870333    Mobile: +972 52 \n554160\n\n\nSent by:        public-iri-request@w3.org\nTo:        ietf-imaa@imc.org, public-iri@w3.org\ncc:         \nSubject:        Bidi: is stringprep broken?\n\n\n\nI wrote:\n\n >  > Ergo, we need another display model; this one doesn't work \n > There are also other real nasties with this display model:\n\nWorse than that, I think the bidi restrictions in stringprep don't\nactually achieve their goal of ensuring that you can't have two\ndifferent labels that render the same.\n\nConsider the labels:\n\n                 A-123,456B\n\nand\n\n                 A456,-123B\n\nHere, A is HEBREW LETTER ALEF, B is HEBREW LETTER BET (or any\ncharacters of bidi class R that you like, but *not* arabic letters,\nwhich are class AL) and the comma is actually ARABIC COMMA U+060C (or\nany character of class CS or ES).\n\nAs far as I can tell these both pass nameprep with UseSTD13ASCIIRules\nset, and they both render identically under bidi as:\n\n                 B-123,456A\n\nIf you don't care about UseSTD13ASCIIRules, you can replace\nARABIC COMMA with COMMA, SOLIDUS or COLON.\n\nI fully expect someone to reply explaining why I'm mistaken, but I've\nchecked the above as best I can...\n\n                 -roy\n\n\n\n", "id": "lists-017-0390256"}, {"subject": "Re: Bidi: is stringprep broken", "content": "Matitiahu Allouche writes:\n > According to my understanding, and to testing against the Unicode C \n > reference implementation, you are correct in stating that the 2 strings (\"A-123,456B\" and \"A456,-123B\") will give the same display according to the Unicode algorithm for \n > Bidirectional text.\n\nThanks for verifying it.  Though it's still possible that I'm mistaken\nabout it passing nameprep.\n\n > You will admit that your example is more than a little contrived. \n\nYes, and it's probably unlikely ever to be registerable, since it\ninvolves punctuation (and not only that, but punctuation associated\nwith the wrong script).\n\nMy other example (that ARAB.123.com and 123.ARAB.com render the same)\nworries me more.\n\n > I can find other examples of names allowed by the rules which can\n > mislead users trying to induce the logical order based on the\n > display order.  All of these examples are quite bizarre.\n\nI'd be interested in the examples you have.\n\n > By the way, can you give a reference to \"UseSTD13ASCIIRules\", for\n > an ignoramus like myself?\n\nRFC3490.  When the UseSTD13ASCIIRules flag is set, ASCII characters\nother than alphanumerics and HYPHEN-MINUS are prohibited, in\naccordance with traditional hostname rules.  Hence my use of ARABIC\nCOMMA; I needed a character that was a number separator, was\nnon-ASCII, and didn't have a compatibility decomposition (since IDNA\nuses NFKC).\n\n-roy\n\n\n\n", "id": "lists-017-0401764"}, {"subject": "Re: Bidi: now I'm confused (issue [bidiDigits18]", "content": "Hello Roy,\n\nI think that in general, you are right about your analysis.\nHaving labels (or other components) with numbers only may\nlead to ambiguous displays. I seem to remember that we were\nactually aware of that fact, but there was not much to do\nabout it:\n\n- There currently are labels with only digits in the DNS,\n   outlawing them is not an option. (it would have been nice\n   if we could have said that the same restrictions apply\n   for digits and LTR letters as they do for digits and RTL\n   letters)\n- Very explicitly for IDN, but also in many ways for IRIs,\n   it is highly undesirable to have inforced restrictions\n   on two or more labels/components. (note that this may be\n   somewhat different for the LHS side)\n\nI have created an issue for this for the IRI draft, at\nhttp://www.w3.org/International/iri-edit#bidiDigits-18.\n\nI propose to address this by adding text that points out\nsuch cases and warns against them (without going as far as\nactually prohibiting them). I hope that this is acceptable\nfor you.\n\nBy the way, the alternative of having components displayed\nstrictly LTR was what we had for a long time. The two problems\nwith this approach are:\n- It does not seem to correspond with what Arabic and Hebrew\n   writers do naturally, in particular for freestanding domain\n   names.\n- It would require much more control over the contexts of\n   IRI display than we think will be available (if we get\n   an overall context of LTR reasonably widely implemented,\n   I think we already have achieved something).\n\nRegards,    Martin.\n\n\n\nAt 15:08 03/09/07 +0100, Roy Badami wrote:\n\n\n>Ok, I have a problem with what I understand to be the display model\n>for IDNA and IRI (and presumably by extension IMA).\n>\n>I'm assuming that the display model is 'render using bidi in an LTR\n>context'.\n>\n>Specifically, the IRI draft says:\n>\n>   When rendered, bidirectional IRIs MUST be rendered using the Unicode\n>   Bidirectional Algorithm [UNIV4], [UNI9]. Bidirectional IRIs MUST be\n>   rendered with an overall left-to-right (ltr) direction.\n>\n>The latter requirement isn't specified in bidi-speak, but is\n>presumably to be interpreted as saying they must be rendered at an\n>even embedding level.  Actually, this isn't quite enough in the\n>general case, since what comes before the string may affect weak type\n>resolution, but since IRIs generally start with a latin letter\n>(generally 'h' :) this isn't really much of a problem.\n>\n>So lets for the moment assume that the display model is that IDNs,\n>IRIs, IMAs are rendered at an even embedding level, such that the\n>IDN/IRI/IMA constitutes the sole text in the level run.  (This can\n>easily be achieved by bracketing the string with LRE and PDF prior to\n>rendering.)\n>\n>Consider the domain:\n>\n>123.ARAB.com (logical order)\n>123.BARA.com (display order)\n>\n>now consider the domain:\n>\n>ARAB.123.com (logical order)\n>123.BARA.com (display order)\n>\n>Ergo, we need another display model; this one doesn't work, at least\n>not if we don't want two completely different domains to display\n>identically.\n>\n>I recall that there was a proposal on the IDN list that domains should\n>always be rendered with the labels appearing in order, least\n>significant to the left and top-level domain on the right.  (This can\n>be trivially achieved by bracketing each label with LRE/PDF,\n>separating the labels with dots, and then bracketing the whole domain\n>with LRE/PDF.)\n>\n>This would solve the above problem, but potentially might be less\n>friendly to users of RTL languages in other ways.\n>\n>It also clearly is not what the authors of stringprep had in mind,\n>since the bidi restrictions in stringprep are much stronger than would\n>be necessary if this was the model.\n>\n>         -roy\n>\n\n\n\n", "id": "lists-017-0411052"}, {"subject": "Re: Bidi: now I'm confused (issue [bidiDigits18]", "content": " > I think that in general, you are right about your analysis.\n > Having labels (or other components) with numbers only may\n > lead to ambiguous displays. I seem to remember that we were\n > actually aware of that fact, but there was not much to do\n > about it:\n\nMore specifically, assuming labels (or syntactic components) obey the\nstringprep bidi rules (as IDNA requires, and IRI has as a 'SHOULD')\nthen I think the problematic case is when a label contains one or more\ndigits, and no strong characters.  These are just quick examples off\nthe top of my head; I haven't checked them carefully against the bidi\nalgorithm.\n\n1-2.HEBREW.com (logical order)\n1-2.WERBEH.com (display order)\n\nHEBREW.1-2.com (logical order)\n1-2.WERBEH.com (display order)\n\nAnd another.  N is a neutral character (presumably non-ASCII, since\nthere are no ASCII neutrals allowed by hostname rules).\n\n1N2.ABC.com (logical order)\n1N2.CBA.com (display order)\n\nABC.2N1.com (logical order)\n1N2.CBA.com (display order)\n\n\nOf course, this may need to be restated somewhat for IMA because the\nLHS doesn't formally have structure.\n\n > I propose to address this by adding text that points out\n > such cases and warns against them (without going as far as\n > actually prohibiting them). I hope that this is acceptable\n > for you.\n\nIf we can't change the display model (and I see why that may not be\ndesirable and/or practiable) then I guess that's all that can\nrealistically be done.  I'm tempted to say it ought to be a 'SHOULD\nNOT', and not just a recommendation (in line with the other 'SHOULD\nNOTs' about bidi IRIs).\n\nI think that IMA will need to contain a similar 'SHOULD NOT'.\n\nIn the case of IMA we need to warn people (at least) against addresses\nsuch as:\n\n123@ABC.com (logical order)\nABC@123.com (logical order)\n\nboth of which display as \n\n123@CBA.com (display order)\n\nbut I think there are other cases as well.\n\n-roy\n\n\n\n", "id": "lists-017-0422843"}, {"subject": "IRIs and XPointe", "content": "I have recently been reading the latest IRI draft, and was interested to note \na divergence between it and the xpointer recommendation.\n\nThis is a comment on the following two documents:\n\nXPtr:\nhttp://www.w3.org/TR/2003/REC-xptr-framework-20030325/\n\nIRI\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri-04.txt\n(June 2003 expires December 2003)\n\nIRI:\n[[\n   Note: Earlier drafts of this specification allowed the space\n   character and various delimiters in IRIs and IRI references.  The\n   full list of these characters was: \"<\", \">\", '\"', Space, \"{\", \"}\",\n   \"|\", \"\\\", \"^\", and \"`\", i.e.  all printable characters in US-ASCII\n   that are not allowed in URIs.  For backwards compatibility,\n   implementations MAY also include these characters in step 3) above.\n   If such characters are found but are not converted, then the\n   conversion SHOULD fail.  Please note that the number sign (\"#\"), the\n   percent sign (\"%\"), and the square bracket characters (\"[\", \"]\") are\n   not part of the above list, and MUST not be converted.  Protocols and\n   formats that have used earlier definitions of IRIs including these\n   characters MAY require unescaping of these characters as a\n   preprocessing step to extract the actual IRI from a given field.\n   Such preprocessing MAY also be used by applications allowing the user\n   to enter an IRI.\n]]\n\nXptr:\n[[\nB. Pointer in IRI reference\n#xpointer(string-range(//P,\"my favorite smiley :-^)\"))\n]] \n\nThe example B includes space and the delimiter ^ ...\n\nthis appears to be a mismatch.\n\nBTW I support the changes in the IRI draft mentioned in this note, which I \nunderstand to have been made in response to comments on the earlier drafts.\n\nJeremy Carroll\n\n\n\n", "id": "lists-017-0433258"}, {"subject": "closing issue [URIsyntax11", "content": "I have closed issue URIsyntax-11 at\nhttp://www.w3.org/International/iri-edit#URIsyntax-11.\nI have adapted the syntax to\nhttp://www.ietf.org/internet-drafts/draft-fielding-uri-rfc2396bis-05.txt\nand because Roy has said that this is done, I have closed this\nissue. Of course, I will reopen it if there are any new changes.\n[I have also checked the ABNF with Harald Alvestand's ABNF checker,\nand fixed a bug or two.]\n\nRegards,    Martin. \n\n\n\n", "id": "lists-017-0465559"}, {"subject": "Re: presentation elements (issue presentationElement25) (was:   Are   IDNs allowed in http IRIs?", "content": "Hello Michel,\n\nBecause I haven't heard from you on this issue, I assume\nthat you are fine with the changes I made, and so I'm\nclosing this issue.\n\nRegards,     Martin.\n\nAt 07:33 04/03/30 -0500, Martin Duerst wrote:\n\n>At 00:23 04/03/19 -0800, Michel Suignard wrote:\n>\n>>Adam, I think you have a valid point, I would however make a simpler \n>>suggestion, which is two fold:\n>>\n>>- introduce the concept of IRI used as presentation element of URI \n>>protocol element. In that sense http://jose'.example.net/ is a \n>>presentation element for the following protocol element \n>>http://xn--jos-dma.example.net/ and as you noted \n>>http://jos%C3%A9.example.net/ is not a correct URI (per RFC 2616 \n>>referring to host itself defined in RFC 2396). I have suggested text in \n>>that sense to the IRI main editor (Martin). Having the concept of \n>>presentation element validates http IRIs which exist de facto, whatever \n>>we like it or not.\n>\n>Hello Michel,\n>\n>I have noted this as issue presentationElement-25 and have\n>added the text you sent me, with some changes.\n>\n>Please check it and send more comments if necessary. Otherwise,\n>I'd like to close this issue.\n>\n>\n>Regards,    Martin.\n\n\n\n", "id": "lists-017-0472170"}, {"subject": "Re: Are IDNs allowed in http IRIs? (Issue IDNhttp19", "content": "Hello Adam,\n\nAt 04:38 04/03/30 -0500, Martin Duerst wrote:\n\n>Hello Adam,\n>\n>I have assigned this issue IDNhttp-19, which I have tentatively closed\n>after the edits I made today (described below).\n\nI have now closed this issue, because I haven't heard from you anymore,\nand assume that you are okay with the fixes to the text.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0481222"}, {"subject": "RE: presentation elements (issue presentationElement25) (was:  Are   IDNs allowed in http IRIs?", "content": "Martin, yes, the changes are ok with me.\n\nMichel \n\n-----Original Message-----\nFrom: Martin Duerst [mailto:duerst@w3.org] \nSent: Monday, April 26, 2004 1:33 AM\nTo: Michel Suignard; public-iri@w3.org; uri@w3.org\nSubject: Re: presentation elements (issue presentationElement-25) (was:\nAre IDNs allowed in http IRIs?)\n\nHello Michel,\n\nBecause I haven't heard from you on this issue, I assume that you are\nfine with the changes I made, and so I'm closing this issue.\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-0488290"}, {"subject": "Issue IURIsearch24 (rejected/closed", "content": "Larry and I have received private mail a few weeks ago suggesting\nthat IRIs should be renamed back to IURIs to make it easier to find\nthem with search engines.\n\nI'm usually not making formal issues out of private mail, but\nI have made an exception this time:\nhttp://www.w3.org/International/iri-edit/#IURIsearch-24\n\nIt is indeed the case that IRIs are currently difficult to\nsearch for; Google for example brings up the first IRI-related\nreference on position 54.\n\nHowever, it should be expected that this will improve once the\nspec becomes an RFC, and gets referenced from other places.\nSearch is also possible by using the full name\n(Internationalized Resource Identifiers) or e.g. by combining\nIRI and URI.\n\nSearchability is not the only criterion for choosing a\nname/acronym. The previous \"IURI\" made it difficult to guess how\nto pronounce it. It also made the specification difficult to\nwrite because the distinction between URIs and IURIs was less\nclear than the distinction between URIs and IRIs.\n\nSwitching back to another name would mean that everybody in the\nWeb community knowing about IRIs has to re-learn.\n\nSo overall, I'm rejecting this issue and closing it.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0498417"}, {"subject": "RE: convert to punycode: SHOULD or MAY (was: RE: Are IDNs   allowed   in  http IRIs?", "content": "Hello Larry,\n\nAt 03:07 04/03/30 -0800, Larry Masinter wrote:\n\n>I think this is an interoperability issue, and that neither SHOULD nor MAY\n>are appropriate. Rather, there is a MUST with a couple of alternatives.\n>Implementations\n>resolving an IRI with non-ascii host names MUST use one of the established\n>methods of resolving the host name correctly.\n\nI think this is a very valid point. However, I think that this is\noverall covered by the current spec. The spec has an overall MUST\nfor the general conversion procedure:\n\n\"Applications MUST map IRIs to URIs using the following two steps.\"\n\nIt then allows (MAY) an additional step in certain well-defined cases:\n\n\"Infrastructure accepting IRIs MAY convert the ireg-name\ncomponent of an IRI as follows (before step 2 above) for schemes\nthat are known to use domain names in ireg-name, but where the\nscheme definition does not allow %-escaping for ireg-name:\"\n\nFinally, it recommends that the above additional step be taken\nunder certain conditions:\n\n\"This conversion SHOULD be used when the goal is to\nmaximize interoperability with legacy URI resolvers.\"\n\nSo it seems to me that this is covered. Of course, there is\nalways the question of whether other things, not discussed in\nthe spec, are allowed or not, but I think it is a general\nprinciple when writing IETF specs to not include generalities\nsuch as \"Any other method than those discussed in this\ndocument MUST NOT be used.\"\n\n\nI hope this reply sufficiently addresses this issue\n(punycodeSHOULD-23). I have noted this as tentatively closed.\n\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-0506686"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "Hello Adam,\n\nThis is all related to issue idnuri-02\n(http://www.w3.org/International/iri-edit/#idnuri-02).\nI have tentatively closed this issue.\n\n\nAt 20:01 04/02/19 +0000, Adam M. Costello BOGUS address, see signature wrote:\n\n>Martin Duerst <duerst@w3.org> wrote:\n\n> > And it's not really IRIs that should need percent-encoding, although\n> > you need it in some cases, if characters are not encoded as UTF-8 in\n> > the corresponding URI.\n>\n>Percent-encoding could also be useful for displaying an IRI when\n>the local charset is not Unicode, or when the available fonts are\n>insufficient.  If an IRI contains many non-ASCII characters that are\n>displayable, plus one character that's not displayable, it might be\n>nice to use percent-encoding only for the oddball and display the\n>rest intelligibly, rather than convert the entire IRI to a URI.  If\n>that displayed IRI is cut & pasted or manually retyped into another\n>application, it should be handled properly.\n\nThis is currently allowed by the IRI spec. In practice, however,\nthere may be other ways to display non-displayable characters,\nand cut-and-paste is usually able to copy even non-displayable\ncharacters.\n\n\n>If an individual scheme restricts a component to contain only ASCII\n>characters, then scheme-specific IRI consumers would be required\n>to check the component before using it, and fail gracefully if any\n>non-ASCII characters are found.\n>\n>That's much simpler, requiring only one bit of knowledge about the\n>syntax of the component (whether it allows non-ASCII).\n\nWell, yes, but what exactly is a \"scheme-specific IRI consumer\"?\nIn the implementation I know, there is no such thing. IRIs get\nconverted to %HH, then the scheme-specific logic takes this apart,\nthen for some schemes, DNS resolution is called, which knows\nabout %HH and IDNs and does the right thing. What is such an\nimplementation supposed to do? Why should the spec give requirements\nabout things that don't exist in implementations?\n\n\n> > What do you mean by 'fail gracefully'?\n>\n>If the component is supposed to be a Foo, and a Foo is supposed to be\n>ASCII, and the component contains non-ASCII, then you must not use\n>the component as a Foo (whatever that means).  If you were about to\n>do something that entailed using the component as a Foo (for example,\n>passing it to something that takes a Foo as an argument), then you\n>must abort the attempt, and the error is something like \"invalid Foo\n>(non-ASCII)\".\n\nThis just sounds to me like two very general principles:\n- defensive programming\n- good error messages\n\nI don't see a particular point in mentioning these in the IRI spec,\nbecause they are also not mentioned in other IETF specs. Nor do\nI see any good reason for mentioning them for one particular point\nin the IRI spec, because they should apply to all of the spec.\n\n\n> > And why would that have to be checked before use?  Why could it not\n> > simply be the result of actual use?\n>\n>Because the original Foo spec might be old (even if the IRI scheme\n>containing a Foo component is more recent), and might have its own\n>installed base of stuff that does not behave interoperably when\n>presented with a non-ASCII Foo, and therefore it might have needed to\n>introduce a client-side downgrading operation in order to safely extend\n>the syntax.  If the IRI consumer blindly tries to use the Foo component\n>as a Foo without performing the downgrading operation, the result will\n>be unpredictable.\n\nYes. We have a sloppy spec/implementation on the one hand, and\nsomebody sending stuff they are not supposed to send on the\nother hand. Not surprising that it doesn't work.\n\n\n>Maybe there will be a misleading error message like\n>\"Foo xyz not found\" even though xyz actually exists,\n\nThat's always a possibility for URIs and IRIs. Not all schemes may\nbe known, and the network isn't perfect,...\n\n\n>or maybe the\n>mangled request will map onto some other Foo by coincidence or malice.\n\nIf you think this needs to be documented as a security issue,\nplease say so (please propose some wording).\n\n\n>Ideally, the Foo spec should have specified what to do whenever you\n>encounter a syntactically invalid Foo, so that Foo implementations bear\n>full responsibility for interoperability as the Foo syntax is extended,\n>and nothing about the Foo syntax need be known at the IRI-processing\n>layer.  But there is one kind of syntax extension where neglect has\n>been the rule rather than the exception: the extension from ASCII to\n>non-ASCII.  Because it has been so common for protocols to assume ASCII\n>without saying enough about how to react to non-ASCII, and because\n>the ASCII-to-non-ASCII transition is the same one being made by the\n>introduction of IRIs, and because IRIs are uniquely positioned as a\n>narrow interface between a wide range of protocols and a wide range of\n>applications (sort of like IP is a narrow interface between a wide range\n>of networks and a wide range of applications), IRIs are a good place to\n>interpose a simple type-safety check.\n\nWell, IRIs are defined as generic. Because the checks needed are\nspecific to different protocols,..., I don't think that such\nchecks belong into a generic spec. If a spec needs fixing, it\nshould be fixed. Using another, vaguely related spec to try\nand fix the first spec is probably a bad idea.\n\n\n> > > (That would prevent IRIs from suffering some of the problems we are\n> > > now seeing with URIs.  In URIs, percent-encoding was prohibited\n> > > in the host component, and non-ASCII was prohibited in the host\n> > > component, and there was no requirement telling URI consumers\n> > > what to do if they should find either of those things in the host\n> > > component, so now we have different implementations behaving\n> > > differently when they encounter such things.)\n> >\n> > Well, yes.  But that's just a result of how things are implemented,\n> > not a problem in the specification, I guess.\n>\n>I think it's a problem in the specification.  I think we've learned the\n>hard way that specs need to say what to do when you encounter unexpected\n>syntax, otherwise it's difficult to ever extend the syntax.\n\nI agree. But I don't think the IRI spec is the right place to fix\nall the other specs.\n\n\n>RFC-2396 said the host component does not contain percent-escapes, but\n>didn't say what to do if it did contain them, so some implementations\n>decode the escapes, and some don't, and neither group is wrong.\n\nAnd RFC 2396bis fixes that.\n\n\n> > We already made an exception for domain names.  I don't want to make\n> > any other exceptions.  The goal is not a hodgepodge of scheme-specific\n> > conventions, but to take advantage of the fact that many URI schemes\n> > already are based on UTF-8, many others allow UTF-8 to be used (in\n> > many parts at least) and UTF-8 is also the recommendation for new\n> > schemes.\n>\n>I agree with those goals, but there is a distinct possibility that an\n>ACE will be defined for email local parts, in which case IRI-to-URI\n>converters with knowledge of mailto: will want to use the ACE for\n>compatibility with existing mailto: resolvers.\n\nYes, in the case such a possibility becomes reality, some converters\nmight do that, if they think that helps. They will do that whether or\nnot a spec tells them to. On the other hand, the mailto: URI scheme should\nbe updated to allow %HH (based on UTF-8) in the LHS, and to otherwise\nbe better internationalized.\n\n\n>Maybe there are\n>other ASCII-only components lurking in existing URI schemes facing\n>backward-compatibility challenges similar to those of domain names, and\n>maybe they will likewise find it necessary to use the ACE approach to\n>internationalization.\n\nDo you know of any?\n\n\n>The IRI spec would not need to mention any of the individual\n>scheme-specific exceptions.  It mentions the IDN exception because ihost\n>is a potential component of IRIs in general, and domain names are used\n>in a great many schemes, but those reasons wouldn't apply to any other\n>exceptional components (like email local parts).\n\nOkay.\n\n\n> > > 2) If the verification failed, or if you didn't recognize the\n> > > scheme, then perform the generic conversion to percent-encoded UTF-8\n> > > as described in the IRI draft, and prepend the prefix i- to the\n> > > scheme.\n> >\n> > Why should i- be prepended?\n>\n>Because URI processing does not include the ASCII-component-check\n>(whereas IRI processing, being a new spec, could include the check).\n>Blindly dumping non-ASCII characters (even percent-encoded ones) into\n>a URI would bypass the check.  If the URI contains a component that\n>used to be limited to ASCII, legacy implementations might behave in\n>unpredictable ways when that component contains (percent-encoded)\n>non-ASCII.\n\nI think there is a tradeoff. Introducing your i- pattern would\nmean that the chance that any subsequent URI resolver actually\nresolves that URI currently would be zero, and might stay very\nclose to zero for a very long time. As we know, introducing\na new URI scheme is very hard.\n\nThe alternative is to not use the i-, meaning that already\nin quite a few implementations, the URI in question can be\nresolved, and this number will be increasing faster than in\nthe i- case, at the expense of an occasional unpredictability\n(which in most cases is just a 'not found').\n\nFor me, having things actually work, maybe with occasional\nhickups, is clearly preferable to a theoretically safe\nsolution that doesn't work in practice.\n\n\n>Basically, i-foo: means \"this identifier was blindly converted from a\n>foo: IRI without foo-specific knowledge, so it does not necessarily\n>conform to foo: URI syntax, but it does conform to generic URI syntax,\n>and you can certainly recover the foo: IRI\".\n\nThere are many other ways (e.g. by hand) to create foo: URIs that\ndon't conform to foo: URI syntax. The IRI draft clearly says that\nyou are not supposed to use non-ASCII characters where the scheme\ncan't handle it. Please see\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri.html#UTF8use\nfor actual text.\n\n\n>Another answer to your question (\"Why should i- be prepended?\") is:  So\n>that the IRI spec does not invite applications to violate the IDNA spec.\n>The ireg-name component is an IDN-aware slot in schemes that use domain\n>names there (because the IRI draft invites the usage of non-ASCII domain\n>names there and cites IDNA).  The corresponding reg-name slot in the\n>URI is IDN-unaware.  To convert a foo: IRI to a foo: URI, IDNA requires\n>ToASCII to be applied.  But when the application doesn't know the\n>scheme, the IRI draft invites the application to use percent-encoding\n>instead, disregarding the IDNA requirement.\n\nWell, I think that IDNA tried very hard to predict all cases of\nuse of IDNs, and put down general rules that would apply for all\ncases. But in general, such things are just impossible. reg-name\nis a typical example: a slot that can contain both domain names\nand other stuff. And URIs are a typical example: In RFC 2396,\nthis slot only allowed US-ASCIII. In RFC 2396bis, %HH is also\nallowed. Implementations have evolved likewise.\n\nThe IRI spec does the best it reasonably can to navigate in this\narea. Requiring everything to be prefixed with -i, in practice\nmaking things less working, just to nominally conform to IDNA,\ndoesn't seem to make sense.\n\nNot every application will know all relevant schemes, but the\nnumber of current schemes using DNS in reg-name is not that large,\nand any future schemes can be defined to allow %HH from the start.\nSo in practice, it is not too difficult for IRI implementations to\nfollow IDNA, and there is definitely nothing in the IRI spec\nthat says that implementations should disregards IDNA.\n\n\n> > New schemes can be designed so that they fit together well with IRIs\n> > (if the relevant BCP guidelines are used, that will be the case\n> > automatically).\n>\n>The resolvers of those new schemes can simply strip off the i- prefix if\n>they know that the generic IRI-to-URI conversion is sufficient for those\n>schemes.  That could be mentioned in the IRI spec and in the guidelines\n>for creating new schemes.\n\nDesigning things so that the future gets more complicated, rather\nthan more straightforward, just to deal with some sloppy specs/\nimplementations, does not seem to be a good idea.\n\n\n>By the way, I should insert a rule 0 in my proposed IRI-to-URI\n>conversion:\n>\n>0) If the IRI contains no non-ASCII characters (not even percent-encoded\n>ones) then stop; it's already a URI.\n>\n>(Without this rule, if the scheme was unknown, the only effect of the\n>other rules would be to prepend the i- prefix, which would be protecting\n>nothing.)\n\nWell, yes. And don't add a i- prefix if there already is one,\nand make sure we reserve all scheme names starting with i-, and\na few other 'details'. Way too much hassle for what it's worth,\nsorry.\n\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-0515884"}, {"subject": "Re: Interpretation if %-escapes in IRIs [escapeInterpret14", "content": "Hello Bjoern,\n\nI haven't heard anything on this, and I'm therefore closing this issue.\n\nRegards,    Martin.\n\nAt 06:29 03/06/27 -0400, Martin Duerst wrote:\n\n>Hello Bjoern,\n>\n>Many thanks for all your questions.\n>\n>Most of these questions, if not all of them, are answered\n>in the actual draft. Please check it and tell me where you\n>think something is missing or not clear enough.\n>\n>At 05:37 03/05/02 +0200, Bjoern Hoehrmann wrote:\n>>* Martin Duerst wrote:\n>> >>IMO, the IRI draft should say, that if %-escaping is used in an IRI, the\n>> >>escape sequence must be generated from UTF-8 octets and %-escapes must\n>> >>be interpreted as octets in an UTF-8 sequence.\n>> >\n>> >why should it say so? In that case, you should not really use\n>> >%-escaping in an IRI, you should use real characters.\n>>\n>>What if it is impossible to use \"real\" characters due limitations of the\n>>transport media, the transport encoding,\n>\n>Then preferably use a transport-specific escaping or encoding\n>(e.g. the various MIME mechanisms for email, numeric character\n>references for HTML and XML,...).\n>\n>\n>>if I need to escape a reserved character to avoid it's special meaning,\n>\n>Then use escaping. That's very clear in the draft.\n>\n>\n>>if the character is disallowed\n>\n>Then use escaping. Again, the draft says so.\n>\n>\n>>or if I want to encode binary data that does not represent any\n>>character?\n>\n>Then use escaping. Same thing again.\n>\n>\n>>What if my IRI-aware application receives an IRI containing %-escape\n>>sequences but needs characters in order to work, like some kind of\n>>server for file transfer expecting a file name or a database frontend\n>>expecting a search string?\n>\n>Then the server will do the conversion from %-escapes to octets\n>the same way it currently does, and some servers (e.g. Apache and IIS\n>on WinNT/2000/XP), or server configurations, will convert further,\n>where possible, to whatever character encoding is used internally\n>in the server.\n>\n>\n>>Let's say there is an 'uri' URI scheme and an 'iri' IRI scheme\n>\n>There is really no such difference. All URI schemes can be used\n>with IRIs. For some, the benefit of using IRIs is greater than\n>for others. I think what you wanted to say is that there are\n>two protocol slots, let's say\n>iri=\"http://www.example.org/search?Bj+APY-rn\" and\n>uri=\"http://www.example.org/search?Bj+APY-rn\". I'll assume\n>this for the following examples, but I'll not change your syntax.\n>\n>\n>>(the + in\n>>the query part has no special meaning and may thus stay unescaped):\n>>\n>>   uri://www.example.org/search?Bj+APY-rn\n>>   iri://www.example.org/search?Bj+APY-rn\n>>\n>>Decoding the query part of the URI I would get the octets\n>>\n>>   <42><6A><2B><41><50><59><2D><72><6E>\n>\n>Yes.\n>\n>\n>>The database frontend would then search for \"Bjo\"rn\",\n>\n>Sorry to have to use \"Bjo\"rn\" for your example due to my\n>Japanese mailer.\n>\n>\n>>since it decodes\n>>the octets represented by characters in the URL as UTF-7 octets.\n>\n>If the database frontend is programmed that way, then that's correct.\n>\n>\n>>What\n>>about the IRI? Is the frontend supposed to search for \"Bj+APY-rn\" or\n>>for \"Bjo\"rn\"?\n>\n>If the same frontend is used, the same thing will happen.\n>The frontend has no way to distinguish whether it receives an URI\n>or an IRI.\n>\n>\n>>Is a data character in an IRI a character or is it a\n>>representation of an octet or even something else?\n>\n>It is a character. That does not prohibit that these characters\n>are (mis)used to represent other characters, as in the case of\n>UTF-7.\n>\n>\n>>If an IRI data character is a \"real\" character, refer %-escape sequence\n>>also to real characters? Are these IRIs equivalent:\n>>\n>>   iri://www.example.org/search?Bj%F6rn\n>>   iri://www.example.org/search?Bjo\"rn\n>\n>These are definitely not equivalent, because the %F6 is based\n>on Latin-1, not UTF-8.\n>\n>\n>>just like these URIs are:\n>>\n>>   uri://www.example.org/search?a\n>>   uri://www.example.org/search?%61\n>\n>If you read section 6 of\n>http://www.ietf.org/internet-drafts/draft-fielding-uri-rfc2396bis-03.txt\n>carefully, you'll see that these are equivalent\n>under certain definitions of equivalence, and for\n>those protocols/applications that use this definition\n>of equivalence.\n>\n>\n>>Are these equivalent:\n>>\n>>   iri://www.example.org/search?Bj%C3%B6rn\n>>   iri://www.example.org/search?Bjo\"rn\n>\n>These are equivalent under certain definitions of equivalence.\n>\n>\n>>and are these IRIs:\n>>\n>>   iri://www.example.org/search?a\n>>   iri://www.example.org/search?%61\n>\n>They are as equivalent as the same URIs (see above).\n>\n>\n>>equivalent? If the latter two IRIs are equivalent, how would one then\n>>encode binary data in an IRI? What octets are represented in the query\n>>part of e.g.\n>>\n>>   iri://www.example.org/search?<U+20AC>\n>>   iri://www.example.org/search?<U+1D7F6>\n>\n>The octets, when octets are needed, are based on UTF-8, i.e.\n>E2 82 AC in the first case, and F0 9D 9F B6 in the second case.\n>\n>\n>>Consider I want to send an IRI in a text/plain e-mail using us-ascii,\n>>but the IRI has non-ASCII characters, like\n>>\n>>   iri://www.example.org/bjo\"rn\n>\n>In the first place, you should not use us-ascii for sending this IRI.\n>There are many encodings, starting with iso-8859-1 and utf-8 that\n>can easily transfer the IRI.\n>\n>\n>>can I use %-escaping to encode the 'o\"' and if yes, how would the IRI\n>>then look like? Would it be\n>>\n>>   iri://www.example.org/bj%F6rn\n>>   iri://www.example.org/bj%ECrn\n>>   iri://www.example.org/bj%C3%B6rn\n>\n>If anything, it would be this one, with \"bj%C3%B6rn\", using UTF-8.\n>While this would not work for namespaces (i.e. XML parsers and\n>XSLT processors would treat the namespaces\n>iri://www.example.org/bjo\"rn and iri://www.example.org/bj%C3%B6rn\n>differently), it would at least resolve to the same thing, e.g.\n>over http (exactly the same applies to http://www.example.org/search?a\n>and http://www.example.org/search?%61).\n>\n>\n>>   iri://www.example.org/bj%00%F6rn\n>>   ...\n>>\n>>Currently neither RFC 2396 nor the IRI draft give an advise here. Is\n>>this a scenario not supported by IRIs?\n>\n>Which scenario? The scenario of sending IRIs over US-ASCII?\n>Or another one?\n>\n>\n>>If yes, why do you think it is\n>>not necessary or not possible to support it,\n>\n>If you mean sending IRIs over US-ASCII, then it's not possible in\n>the same way it's not really possible to send German or Japanese\n>email over US-ASCII.\n>\n>\n>>and why does the IRI draft\n>>not mention that %-escaping cannot be used for non-ASCII characters, but\n>>rather says it SHOULD NOT be used?\n>\n>Because it depends on exactly what you are doing.\n>\n>\n>>If it is possible to use %-escaping\n>>for non-ASCII characters, the IRI draft must say how the non-ASCII\n>>character have to be encoded (actually, how any character is to be\n>>encoded) and should say, how one gets the characters back.\n>\n>There are two very detailed sections in the draft discussing this.\n>For escaping, see section 3.1, \"Mapping of IRIs to URIs\".\n>For unescaping, see section 3.2, \"Converting URIs to IRIs\".\n>If you find anything that is unclear, please tell us, so that I can\n>fix it.\n>\n>\n>Regards,   Martin.\n\n\n\n", "id": "lists-017-0536206"}, {"subject": "Re: Issue IURIsearch24 (rejected/closed", "content": "--On Tuesday, April 27, 2004 1:16 PM +0900 Martin Duerst <duerst@w3.org> wrote:\n> \n> It is indeed the case that IRIs are currently difficult to\n> search for; Google for example brings up the first IRI-related\n> reference on position 54.\n> \n> However, it should be expected that this will improve once the\n> spec becomes an RFC, and gets referenced from other places.\n> Search is also possible by using the full name\n> (Internationalized Resource Identifiers) or e.g. by combining\n> IRI and URI.\n\nYahoo is doing somewhat better, with a hit at #34.\n\nThanks for considering this. I expect that you are wrong about\nsearchability improving. That would require the acronym to become\nunambiguous or more popular than the other expansions. Other \npeople will not rename their institutes or companies because of \nsomeone else's standard, so the conflicts will remain. And internet\nstandards have not been the most important documents on the web\nfor several years.\n\nExpecting searchers to type \"internationalized\" is unreasonable,\nespecially considering that a lot of experts have given up on that\nand use \"i18n\" for \"internationalization\".\n\nI recommend buying ads if you want this term to be found.\n\nwunder\n--\nWalter Underwood\nPrincipal Architect, Verity\n\n\n\n", "id": "lists-017-0551652"}, {"subject": "Re: Some issues with the IRI document [nfcnfkc04] (closed", "content": "The new section 5 has been completed for quite a while,\nbut I didn't get around to close this issue.\n\nYou can find the new section 5 at\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri.html#equivalence.\nIt is closely modeled on section 6 of the new (RFC2396bis) URI draft, which\nhas been authored by the W3C TAG. It is in the same document (as Paul\nwanted it), it is not in an Appendix, which addresses Ted's concerns.\n\n\nThe section about normalization is at:\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri.html#normalization\nThe text that Paul explicitly asked to be included at\nhttp://lists.w3.org/Archives/Public/public-iri/2003Apr/0026.html\nis a note in that section.\n\nRegards,    Martin.\n\nAt 06:15 03/04/18 -0400, Martin Duerst wrote:\n\n>I have started a new section 5, entitled \"IRI Equivalence and Comparison\".\n>The intro text currently reads:\n>\n>@@@@ This section will be worked out to discuss IRI Equivalence and Comparison\n>similar to the section \"URI Normalization and Comparison\" in RFC2396bis, with\n>frequent references to that section, and pointing out differences between URIs\n>and IRIs and IRI-specific issues (text normalization, language-dependence of\n>casing operations, and so on.\n>\n>I have moved sections 2.3 and 2.4 to that section to serve as\n>starting material. I'll have to work on it some more.\n>\n>Regards,    Martin.\n>\n>\n>At 11:14 03/04/17 -0700, Ted Hardie wrote:\n>\n>>Whether it is in this document or another, I believe it should be\n>>in a normative part of the specification.  I'm concerned that\n>>moving the question of equivalence to an appendix may not\n>>have the force needed to flag that this is one of the critical\n>>requirements for interoperability.\n>>                                         regards,\n>>                                                         Ted\n>>\n>>On Thursday, April 17, 2003, at 10:06 AM, Paul Hoffman / IMC wrote:\n>>\n>>>\n>>>At 9:33 AM -0700 4/17/03, Larry Masinter wrote:\n>>>>I think it sounds like the IRI document might need an\n>>>>expanded section or even separate document covering\n>>>>IRI equivalence, including the additional considerations\n>>>>of escape sequences, different normalization, different\n>>>>case transitions based on language, etc.\n>>>\n>>>Agree, but not about a separate document. It should be in this document, \n>>>but can be an appendix.\n>>>\n>>>--Paul Hoffman, Director\n>>>--Internet Mail Consortium\n\n\n\n", "id": "lists-017-0560060"}, {"subject": "IRIs and bidi: Addition regarding higherlevel protocol", "content": "As a result of discussions in the Unicode technical committee about\ntweaks to the Unicode Bidirectional Algorithm (see issue 13 at\nhttp://www.unicode.org/review/ and the actual draft at\nhttp://www.unicode.org/reports/tr9/tr9-12.html), Michel Suignard\nhas suggested making clear in the IRI spec that the provision\nfor higher-level protocols to be able to change the bidi algorithm\nshould not be misused to change the display behavior of IRIs.\n\nI have added the following text to the first paragraph in the\nsection \"Logical Storage and Visual Presentation\":\n\n >>>>>>>>\nThe Unicode Bidirectional Algorithm (<xref target=\"UNI9\"/>,\nSection 4.3) permits higher-level protocols to influence bidirectional\nrendering. Such changes by higher-level protocols MUST NOT be used\nif they change the rendering of IRIs.\n >>>>>>>>\n\nPlease check this in the draft version linked from\nhttp://www.w3.org/International/iri-edit/.\n\nMichel, others, any comments?\n\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-0596107"}, {"subject": "RE: IRIs and bidi: Addition regarding higherlevel protocol", "content": "> From Martin Duerst\n>\n> But this seems to bring up an other chance for trouble that \n> we haven't really looked at yet. What about the following case:\n> \n> logical:  latin text http://www.example.EGYPT ARABIC latin text\n> visual?:  latin text http://www.example.CIBARA TPYGE latin text\n> \n> This means that we have to be very clear about the fact that \n> IRIs should always be embedded LTR by themselves if there is \n> some RTL text before or after them. This would then \n> automatically address the 3.3.3 W2 case above, too. What do you think?\n\nMartin, concerning your new clause:\n<<\nWhen rendered, bidirectional IRIs MUST be rendered using the Unicode\nBidirectional Algorithm [UNIV4], [UNI9]. Bidirectional IRIs MUST be\nrendered with an overall left-to-right (ltr) direction. The Unicode\nBidirectional Algorithm ([UNI9], Section 4.3) permits higher-level\nprotocols to influence bidirectional rendering. Such changes by\nhigher-level protocols MUST NOT be used if they change the rendering of\nIRIs. \n>>\nIt doesn't seem to cover the issue mentioned above, furthermore LTR\nembedding would also not be sufficient to avoid an AL character before\nthe IRI influencing 3.3.3 W2 result on the IRI itself.\nWe need to address both cases.\n\nI would propose the following text to replace the above quoted\nsub-clause:\n\n<<\nWhen rendered, bidirectional IRIs MUST be rendered using the Unicode\nBidirectional Algorithm [UNIV4], [UNI9] with the additional conditions:\n1. Bidirectional IRIs MUST be rendered with an overall left-to-right\n(ltr) direction.\n2. Bidirectional IRIs MUST be embedded LTR by themselves if there is RTL\ntext immediately before or after them.\n3. For the purpose of clause W2 of the Unicode Bidirectional Algorithm\n[UNIV4], it is assumed that the IRI is immediately preceded by a type L\n(Left-to-Right) character. No additional bidirectional rendering change\nby higher-level protocols is allowed. \n>>\n\nThe small diagramm (to be seen in monospaced chars) shows the desired\nresult\n\n-String before-|  IRI  |-String after--\n              L    ON   L\n(For the string before and after, the IRI behaves as bidi 'ON')\n(For the IRI itself, string before and after behave as bidi 'L')\n\nMy proposed text would probably require some wordsmithing (especially\nfor the 2nd condition) but I wanted to float the proposal before doing\nmore work on it.\n\nMichel\n\n\n\n", "id": "lists-017-0604765"}, {"subject": "RE: [bidi] Re: IRIs and bidi: Addition regarding higherlevel protocol", "content": "Once we have internationalized TLDs, it it is conceivable, desirable and\nunavoidable to have RTL bidi IRIs.\n\n\n????//:????/????.????.??\n\nJony\n\n\n\n\n> -----Original Message-----\n> From: bidi-bounce@unicode.org\n> [mailto:bidi-bounce@unicode.org] On Behalf Of Michel Suignard\n> Sent: Friday, February 06, 2004 8:07 AM\n> To: Martin Duerst\n> Cc: public-iri@w3.org; bidi@unicode.org\n> Subject: [bidi] Re: IRIs and bidi: Addition regarding\n> higher-level protocols\n>\n>\n> > From Martin Duerst\n> >\n> > But this seems to bring up an other chance for trouble that\n> > we haven't really looked at yet. What about the following case:\n> >\n> > logical:  latin text http://www.example.EGYPT ARABIC latin text\n> > visual?:  latin text http://www.example.CIBARA TPYGE latin text\n> >\n> > This means that we have to be very clear about the fact that\n> > IRIs should always be embedded LTR by themselves if there is\n> > some RTL text before or after them. This would then\n> > automatically address the 3.3.3 W2 case above, too. What do\n> you think?\n>\n> Martin, concerning your new clause:\n> <<\n> When rendered, bidirectional IRIs MUST be rendered using the\n> Unicode Bidirectional Algorithm [UNIV4], [UNI9].\n> Bidirectional IRIs MUST be rendered with an overall\n> left-to-right (ltr) direction. The Unicode Bidirectional\n> Algorithm ([UNI9], Section 4.3) permits higher-level\n> protocols to influence bidirectional rendering. Such changes\n> by higher-level protocols MUST NOT be used if they change the\n> rendering of IRIs.\n> >>\n> It doesn't seem to cover the issue mentioned above,\n> furthermore LTR embedding would also not be sufficient to\n> avoid an AL character before the IRI influencing 3.3.3 W2\n> result on the IRI itself. We need to address both cases.\n>\n> I would propose the following text to replace the above quoted\n> sub-clause:\n>\n> <<\n> When rendered, bidirectional IRIs MUST be rendered using the\n> Unicode Bidirectional Algorithm [UNIV4], [UNI9] with the\n> additional conditions: 1. Bidirectional IRIs MUST be rendered\n> with an overall left-to-right\n> (ltr) direction.\n> 2. Bidirectional IRIs MUST be embedded LTR by themselves if\n> there is RTL text immediately before or after them. 3. For\n> the purpose of clause W2 of the Unicode Bidirectional\n> Algorithm [UNIV4], it is assumed that the IRI is immediately\n> preceded by a type L\n> (Left-to-Right) character. No additional bidirectional\n> rendering change by higher-level protocols is allowed.\n> >>\n>\n> The small diagramm (to be seen in monospaced chars) shows the\n> desired result\n>\n> -String before-|  IRI  |-String after--\n>               L    ON   L\n> (For the string before and after, the IRI behaves as bidi\n> 'ON') (For the IRI itself, string before and after behave as bidi 'L')\n>\n> My proposed text would probably require some wordsmithing\n> (especially for the 2nd condition) but I wanted to float the\n> proposal before doing more work on it.\n>\n> Michel\n>\n>\n>\n\n\n\n", "id": "lists-017-0616192"}, {"subject": "RE: [bidi] Re: IRIs and bidi: Addition regarding higherlevel   protocol", "content": "Hello Jony,\n\nAt 09:49 04/02/06 +0200, Jony Rosenne wrote:\n > Once we have internationalized TLDs, it it is conceivable, desirable and\n > unavoidable to have RTL bidi IRIs.\n\nThe rest of your mail didn't show up on my (Japanese) mailer.\nI went to the archive at\nhttp://lists.w3.org/Archives/Public/public-iri/2004Feb/0002.html\nto look at it.\n\nUsing the usual 'upper-case for RTL' notation, what I saw was\n(in a very crude transliteration):\n\nLI.LSMM.DZVA/MISM://PTTH\n\nI can only identify the first and the last component, which\nI think got placed right. The rest got messed up in my opinion.\nFollowing the IRI spec, it should look like:\n\n     MISM/LI.LSMM.DZVA//:PTTH\n\nThis is based on the assumption that '/', '.', and ':' are all\nweak, and that even the overall LTR direction required for IRIs\ndoesn't affect the total reordering if everything is RTL.\n\nCould you please clarify how you input this example, and how\nit shows up at your end, or how you think it should show up?\n\nThe above example of course is currently not allowed, and\nwould have to be rewritten to show up as:\n\n    http://MISM/LI.LSMM.DZVA\n\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-0628229"}, {"subject": "Re: IRIs and bid", "content": "Martin,\n\nThe point is that I disagree with \"the overall LTR direction required for\nIRIs\". In an RTL environment, be it Hebrew or Arabic or any other RTL\nscript, RTL IRIs should be allowed.\n\nYou are right, I meant:\n\nMISM/LI.LSMM.RZVA://PTTH\n\nSince it is entirely RTL, in an RTL environment I would just type it in\nplain logical order.\n\nA person or a child who only knows his own language should be able to use\nthe internet, even if his native script is Hebrew or Arabic. We have many\npeople here who cannot read English, and I'm certain the same is true for\nthe Arab countries, Iran and Pakistan.\n\nJony\n\n> -----Original Message-----\n> From: Martin Duerst [mailto:duerst@w3.org] \n> Sent: Friday, February 06, 2004 6:40 PM\n> To: Jony Rosenne; public-iri@w3.org\n> Subject: RE: [bidi] Re: IRIs and bidi: Addition regarding \n> higher-level protocols\n> \n> \n> Hello Jony,\n> \n> At 09:49 04/02/06 +0200, Jony Rosenne wrote:\n>  > Once we have internationalized TLDs, it it is conceivable, \n> desirable and  > unavoidable to have RTL bidi IRIs.\n> \n> The rest of your mail didn't show up on my (Japanese) mailer.\n> I went to the archive at \n> http://lists.w3.org/Archives/Public/public-iri/2004Feb/0002.ht\nml\nto look at it.\n\nUsing the usual 'upper-case for RTL' notation, what I saw was (in a very\ncrude transliteration):\n\nLI.LSMM.DZVA/MISM://PTTH\n\nI can only identify the first and the last component, which\nI think got placed right. The rest got messed up in my opinion. Following\nthe IRI spec, it should look like:\n\n     MISM/LI.LSMM.DZVA//:PTTH\n\nThis is based on the assumption that '/', '.', and ':' are all weak, and\nthat even the overall LTR direction required for IRIs doesn't affect the\ntotal reordering if everything is RTL.\n\nCould you please clarify how you input this example, and how\nit shows up at your end, or how you think it should show up?\n\nThe above example of course is currently not allowed, and\nwould have to be rewritten to show up as:\n\n    http://MISM/LI.LSMM.DZVA\n\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-0637288"}, {"subject": "RE: IRIs and bid", "content": "Jony, there seems to be some miscommunication or maybe I wasn't clear in\nmy messages. RTL IRIs are allowed, they just have to be rendered in a\nLTR embedding level, and furthermore their rendering should have no\ndependency on the surrounding text, and shouldn't interfere with\nsurrounding text either.\n\nIt is perfectly valid to enter a Bidi IRI in a RTL environment in\nlogical order. There are only 2 caveats:\n- some restrictions have been put on IRI fragment concerning the mix of\nRTL and LTR characters, similarly to the ones put on IDN\n- once an IRI is recognized as such by the text processing engine, it\nmust render according to the rules expressed in the IRI spec.\n\nIf an IRI (or IRI fragment) is not recognized as an IRI by the syntax\nanalyzer (like having an invalid syntax), the rendering would default\nback to whatever the bidi rendering of the original text is (plain text\nor higher protocol).\n\nMichel\n\n> -----Original Message-----\n> From: unicore-bounce@unicode.org \n> [mailto:unicore-bounce@unicode.org] On Behalf Of Jony Rosenne\n> Sent: Friday, February 06, 2004 9:35 AM\n> To: Unicore; public-iri@w3.org\n> Subject: Re: IRIs and bidi\n> \n> Martin,\n> \n> The point is that I disagree with \"the overall LTR direction \n> required for IRIs\". In an RTL environment, be it Hebrew or \n> Arabic or any other RTL script, RTL IRIs should be allowed.\n> \n> You are right, I meant:\n> \n> MISM/LI.LSMM.RZVA://PTTH\n> \n> Since it is entirely RTL, in an RTL environment I would just \n> type it in plain logical order.\n> \n> A person or a child who only knows his own language should be \n> able to use the internet, even if his native script is Hebrew \n> or Arabic. We have many people here who cannot read English, \n> and I'm certain the same is true for the Arab countries, Iran \n> and Pakistan.\n> \n> Jony\n> \n> > -----Original Message-----\n> > From: Martin Duerst [mailto:duerst@w3.org]\n> > Sent: Friday, February 06, 2004 6:40 PM\n> > To: Jony Rosenne; public-iri@w3.org\n> > Subject: RE: [bidi] Re: IRIs and bidi: Addition regarding \n> higher-level \n> > protocols\n> > \n> > \n> > Hello Jony,\n> > \n> > At 09:49 04/02/06 +0200, Jony Rosenne wrote:\n> >  > Once we have internationalized TLDs, it it is conceivable, \n> > desirable and  > unavoidable to have RTL bidi IRIs.\n> > \n> > The rest of your mail didn't show up on my (Japanese) mailer.\n> > I went to the archive at\n> > http://lists.w3.org/Archives/Public/public-iri/2004Feb/0002.ht\n> ml\n> to look at it.\n> \n> Using the usual 'upper-case for RTL' notation, what I saw was \n> (in a very crude transliteration):\n> \n> LI.LSMM.DZVA/MISM://PTTH\n> \n> I can only identify the first and the last component, which I \n> think got placed right. The rest got messed up in my opinion. \n> Following the IRI spec, it should look like:\n> \n>      MISM/LI.LSMM.DZVA//:PTTH\n> \n> This is based on the assumption that '/', '.', and ':' are \n> all weak, and that even the overall LTR direction required \n> for IRIs doesn't affect the total reordering if everything is RTL.\n> \n> Could you please clarify how you input this example, and how \n> it shows up at your end, or how you think it should show up?\n> \n> The above example of course is currently not allowed, and \n> would have to be rewritten to show up as:\n> \n>     http://MISM/LI.LSMM.DZVA\n> \n> \n> Regards,   Martin.\n> \n> \n> \n> \n> \n> \n\n\n\n", "id": "lists-017-0646912"}, {"subject": "Re: [bidi] Re: IRIs and bidi: Addition regarding higherlevel   protocol", "content": "At 10:06 PM 2/5/2004, Michel Suignard wrote:\n>No additional bidirectional rendering change\n>by higher-level protocols is allowed.\n\nIs this intended to mean:\n\n\"None of the additional permissible options allowed to higher\nlevel protocols under the specification of the bi-directional\nalgorithm may be applied to an IRI.\"\n\nThe term \"HLP\" is Unicode specific. It might be even better to\\\nwrite:\n\n\"None of the additional options allowed in section 4.3 of\nthe bi-directional algorithm may be applied to an IRI.\"\n\nA./ \n\n\n\n", "id": "lists-017-0659681"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "Hello  Roy, others,\n\nAt 15:41 04/02/10 -0800, Roy T. Fielding wrote:\n\n>On Friday, February 6, 2004, at 12:11  PM, Stephen Pollei wrote:\n>>Also at issue is that the uri\n>>spec SHOULD be neutral as to what particular host name lookup\n>>technologies and restrictions a particular uri resolution implementation\n>>may choose to use. I might use DNS, Host Tables, yp/nis/nis+, etc.\n>\n>Done.  This was implemented as part of removing hostname productions\n>in favor of general registered names.\n\nThe restriction of hostnames to DNS was discussed and agreed on\nat the San Francisco IETF based on interactions with IRIs.\n\nThe argument was that conversion from IRIs to URIs (defined in the\nIRI spec) should take care of conversion from non-ASCII characters\nto punycode in the DNS part. But this is only possible in a scheme-\nindependent way if it's possible to know what is a domain name\nand what not.\n\nThe alternative, which Roy has chosen now, and which I think is\narchitecturally cleaner, is to have IRI to URI conversion use\n%-escaping. The main impact of this is that proxies may receive\n%-escaped domain names, and may have to convert them to punycode\nif they want to support IRIs. [for Roy's benefit: I volunteer\nto work on a module that does this for Apache]\n\nI can go ahead and change the IRI spec to do things this way,\nbut before I do this, I'd prefer to get a confirmation that\nthis is the last change on this topic; flip-flopping on an\nimportant part of a spec is no fun.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0668149"}, {"subject": "RE: IRIs and bidi: Addition regarding higherlevel protocol", "content": "Martin, here is my new proposed text (in quotes) for replacement ofn the\n2nd paragraph of clause 4.1:\n\n<<\nWhen rendered, bidirectional IRIs MUST be rendered using the Unicode\nBidirectional Algorithm [UNIV4] [UNI9] with an overall left-to-right\n(ltr) direction. To achieve this, the IRI is embedded left-to-right in\nall the following cases:\n1. If the current embedding level before the IRI is odd (right-to-left)\n2. If the last character with a strong directionality before the IRI is\nright-to-left\n3. If the first character with a strong directionality after the IRI is\nright-to-left.\nNo additional bidirectional rendering change by higher-level protocols\nis allowed. \n\nNote: Embedding the IRI left-to-right can be achieved by embedding the\ntext with LRE...PDF. If the maximum allowed embedding level is exceded\n(above 62), the IRI overall left-to-right direction may not be enforced.\n>>\n\nThe small diagramm (to be seen in monospaced chars) shows the desired\nresult\n\n-String before-|  IRI  |-String after--\n              L    ON   L\n(For the string before and after, the IRI behaves as bidi 'ON') (For the\nIRI itself, string before and after behave as bidi 'L')\n\nBTW I am interpreting clause W2 of the Unicode Bidi algorithm concerning\nthe strong type enumeration as including as well the embedding\ncharacters (at least the LRE) as it is necessary in the logic expressed\nabove. I have tried one of the sample bidi algorithm (Asmus Freytag\nversion) and it behaves that way.\n\nMichel\n\n\n\n", "id": "lists-017-0678369"}, {"subject": "RE: IRIs and bidi: Addition regarding higherlevel protocol", "content": "I see why it would be desirable to demand an overall left-to-right direction\nfor mixed (LTR and RTL) IRIs, but not for pure RTL IRIs in an RTL\nenvironment.\n\nThis requirement should be changed.\n\nJony\n\n> -----Original Message-----\n> From: public-iri-request@w3.org \n> [mailto:public-iri-request@w3.org] On Behalf Of Michel Suignard\n> Sent: Thursday, February 12, 2004 3:05 AM\n> To: Martin Duerst\n> Cc: public-iri@w3.org; Mark Davis\n> Subject: RE: IRIs and bidi: Addition regarding higher-level protocols\n> \n> \n> \n> Martin, here is my new proposed text (in quotes) for \n> replacement ofn the 2nd paragraph of clause 4.1:\n> \n> <<\n> When rendered, bidirectional IRIs MUST be rendered using the \n> Unicode Bidirectional Algorithm [UNIV4] [UNI9] with an \n> overall left-to-right\n> (ltr) direction. To achieve this, the IRI is embedded \n> left-to-right in all the following cases: 1. If the current \n> embedding level before the IRI is odd (right-to-left) 2. If \n> the last character with a strong directionality before the \n> IRI is right-to-left 3. If the first character with a strong \n> directionality after the IRI is right-to-left. No additional \n> bidirectional rendering change by higher-level protocols is allowed. \n> \n> Note: Embedding the IRI left-to-right can be achieved by \n> embedding the text with LRE...PDF. If the maximum allowed \n> embedding level is exceded (above 62), the IRI overall \n> left-to-right direction may not be enforced.\n> >>\n> \n> The small diagramm (to be seen in monospaced chars) shows the \n> desired result\n> \n> -String before-|  IRI  |-String after--\n>               L    ON   L\n> (For the string before and after, the IRI behaves as bidi \n> 'ON') (For the IRI itself, string before and after behave as bidi 'L')\n> \n> BTW I am interpreting clause W2 of the Unicode Bidi algorithm \n> concerning the strong type enumeration as including as well \n> the embedding characters (at least the LRE) as it is \n> necessary in the logic expressed above. I have tried one of \n> the sample bidi algorithm (Asmus Freytag\n> version) and it behaves that way.\n> \n> Michel\n> \n> \n> \n\n\n\n", "id": "lists-017-0688764"}, {"subject": "RE: IRIs and bidi: Addition regarding higherlevel protocol", "content": "Hello Jony,\n\nIt turns out that for pure RTL IRIs, both an overall left-to-right\ndirection and an overall right-to-left direction results in the\nsame display order, right-to-left. You can (almost) see this in\nthe examples at http://www.w3.org/International/iri-edit/BidiExamples,\nthe one that comes closest is example 3.\n\nThis actually was one reason for going with *overall* left-to-right\ndirection, as opposed to component-wise left-to-right direction.\n\nRegards,    Martin.\n\nAt 06:50 04/02/12 +0200, Jony Rosenne wrote:\n\n>I see why it would be desirable to demand an overall left-to-right direction\n>for mixed (LTR and RTL) IRIs, but not for pure RTL IRIs in an RTL\n>environment.\n>\n>This requirement should be changed.\n>\n>Jony\n>\n> > -----Original Message-----\n> > From: public-iri-request@w3.org\n> > [mailto:public-iri-request@w3.org] On Behalf Of Michel Suignard\n> > Sent: Thursday, February 12, 2004 3:05 AM\n> > To: Martin Duerst\n> > Cc: public-iri@w3.org; Mark Davis\n> > Subject: RE: IRIs and bidi: Addition regarding higher-level protocols\n> >\n> >\n> >\n> > Martin, here is my new proposed text (in quotes) for\n> > replacement ofn the 2nd paragraph of clause 4.1:\n> >\n> > <<\n> > When rendered, bidirectional IRIs MUST be rendered using the\n> > Unicode Bidirectional Algorithm [UNIV4] [UNI9] with an\n> > overall left-to-right\n> > (ltr) direction. To achieve this, the IRI is embedded\n> > left-to-right in all the following cases: 1. If the current\n> > embedding level before the IRI is odd (right-to-left) 2. If\n> > the last character with a strong directionality before the\n> > IRI is right-to-left 3. If the first character with a strong\n> > directionality after the IRI is right-to-left. No additional\n> > bidirectional rendering change by higher-level protocols is allowed.\n> >\n> > Note: Embedding the IRI left-to-right can be achieved by\n> > embedding the text with LRE...PDF. If the maximum allowed\n> > embedding level is exceded (above 62), the IRI overall\n> > left-to-right direction may not be enforced.\n> > >>\n> >\n> > The small diagramm (to be seen in monospaced chars) shows the\n> > desired result\n> >\n> > -String before-|  IRI  |-String after--\n> >               L    ON   L\n> > (For the string before and after, the IRI behaves as bidi\n> > 'ON') (For the IRI itself, string before and after behave as bidi 'L')\n> >\n> > BTW I am interpreting clause W2 of the Unicode Bidi algorithm\n> > concerning the strong type enumeration as including as well\n> > the embedding characters (at least the LRE) as it is\n> > necessary in the logic expressed above. I have tried one of\n> > the sample bidi algorithm (Asmus Freytag\n> > version) and it behaves that way.\n> >\n> > Michel\n> >\n> >\n> >\n\n\n\n", "id": "lists-017-0699617"}, {"subject": "Fwd: Re: Canonical Form of URIs &quot;/&quot; and IRI", "content": "Mainly for the record:\n\n\n>Date: Mon, 9 Feb 2004 18:08:14 -0800\n>Cc: <uri@w3.org>\n>To: \"Jeremy Carroll\" <jjc@hplb.hpl.hp.com>\n>From: \"Roy T. Fielding\" <fielding@gbiv.com>\n>Subject: Re: Canonical Form of URIs \"/\" and IRIs\n\n>On Thursday, December 4, 2003, at 09:40  AM, Jeremy Carroll wrote:\n>>I have two comments on section 6.3 of\n>>\n>>http://gbiv.com/protocols/uri/rev-2002/draft-fielding-uri-rfc2396bis- 03.html\n>>#canonical-form\n>>\n>>1) suggest add the following additional rule:\n>>\n>>+ For URIs following the generic syntax produce an abs_path of \"/\" in\n>>preference to omitting the abs_path\n>>  (this might need an additional example earlier in the doc\n>>http://example.com\n>>vs http://example.com/ )\n>\n>Done.\n\nI have added a corresponding bullet point in \"5.4 Preferred Forms\"\nof the IRI draft, reading:\n\n\"For schemes that define an empty path to be equivalent to a path of \"/\", \nuse \"/\".\"\n\n(directly copied from 6.3  Canonical Form of the URI draft at\nhttp://gbiv.com/protocols/uri/rev-2002/rfc2396bis.html#comparison).\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0711701"}, {"subject": "RE: IRIs and bidi: Addition regarding higherlevel protocol", "content": "Martin,\n\nIt doesn't make sense to change to LTR in this case. \n\nPlease consider an RTL user in an RTL environment, who knows nothing about\nLTR languages and scripts.\n\nJony\n\n> -----Original Message-----\n> From: public-iri-request@w3.org \n> [mailto:public-iri-request@w3.org] On Behalf Of Martin Duerst\n> Sent: Thursday, February 12, 2004 6:02 PM\n> To: Jony Rosenne; public-iri@w3.org\n> Cc: bidi@unicode.org\n> Subject: RE: IRIs and bidi: Addition regarding higher-level protocols\n> \n> \n> \n> Hello Jony,\n> \n> It turns out that for pure RTL IRIs, both an overall \n> left-to-right direction and an overall right-to-left \n> direction results in the same display order, right-to-left. \n> You can (almost) see this in the examples at \n> http://www.w3.org/International/iri-edit/BidiExamples,\n> the one that comes closest is example 3.\n> \n> This actually was one reason for going with *overall* \n> left-to-right direction, as opposed to component-wise \n> left-to-right direction.\n> \n> Regards,    Martin.\n> \n> At 06:50 04/02/12 +0200, Jony Rosenne wrote:\n> \n> >I see why it would be desirable to demand an overall left-to-right \n> >direction for mixed (LTR and RTL) IRIs, but not for pure RTL \n> IRIs in an \n> >RTL environment.\n> >\n> >This requirement should be changed.\n> >\n> >Jony\n> >\n\n\n\n", "id": "lists-017-0720580"}, {"subject": "RE: IRIs and bidi: Addition regarding higherlevel protocol", "content": "Hello Michel,\n\nMany thanks for yor text. I have taken a different way. The new text\nnow reads:\n\n<<<<<<<<\n    When rendered, bidirectional IRIs MUST be rendered using the Unicode\n    Bidirectional Algorithm [UNIV4], [UNI9].  Bidirectional IRIs MUST be\n    rendered in the same way as they would be rendered if they were in an\n    left-to-right embedding, i.e.  as if they were preceded by U+202A,\n    LEFT-TO-RIGHT EMBEDDING (LRE), and followed by U+202C, POP\n    DIRECTIONAL FORMATTING (PDF).  Setting the embedding direction can\n    also be done in a higher-order protocol (e.g.  the dir='ltr'\n    attribute in HTML).\n\n    There is no requirement to actually use the above embedding if the\n    display is still the same without the embedding.  For example, a\n    bidirectional IRI in a text with left-to-right base directionality\n    (such as used for English or Cyrillic) that is preceded and followed\n    by whitespace and  strong left-to-right characters does not need an\n    embedding.  Also, a bidirectional relative IRI that only contains\n    strong right-to-left characters and weak characters and that starts\n    and ends with a strong rigth-to-left character and appears in a text\n    with right-to-left base directionality (such as used for Arabic or\n    Hebrew) and is preceded and followed by whitespace and strong\n    characters does not need an embedding.\n\n    In some other cases, using U+200E, LEFT-TO-RIGHT MARK (LRM) may be\n    sufficient to force the correct display behavior.  However, the\n    details of the Unicode Bidirectional algorithm are not always easy to\n    understand.  Implementers are strongly advised to err on the side of\n    caution and to use embedding in all cases where they are not\n    completely sure that the display behavior is unaffected without the\n    embedding.\n\n    The Unicode Bidirectional Algorithm ([UNI9], Section 4.3) permits\n    higher-level protocols to influence bidirectional rendering.  Such\n    changes by higher-level protocols MUST NOT be used if they change the\n    rendering of IRIs.\n\n    The bidirectional formatting characters that may be used before or\n    after the IRI to assure correct display are themselves not part of\n    the IRI.  IRIs MUST NOT contain bidirectional formatting characters\n    (LRM, RLM, LRE, RLE, LRO, RLO, and PDF).  They affect the visual\n    rendering of the IRI, but do not themselves appear visually.  It\n    would therefore not be possible to correctly input an IRI with such\n    characters.\n<<<<<<<<\n\n\nThe old text read:\n\n >>>>>>>>\n    When rendered, bidirectional IRIs MUST be rendered using the Unicode\n    Bidirectional Algorithm [UNIV4], [UNI9].  Bidirectional IRIs MUST be\n    rendered with an overall left-to-right (ltr) direction.  The Unicode\n    Bidirectional Algorithm ([UNI9], Section 4.3) permits higher-level\n    protocols to influence bidirectional rendering.  Such changes by\n    higher-level protocols MUST NOT be used if they change the rendering\n    of IRIs.\n\n    In text with a left-to-right base directionality or embedding (such\n    as used for English or Cyrillic), the Unicode Bidirectional Algorithm\n    will automatically use an overall ltr direction for the IRI.  In text\n    with a rtl base directionality or embedding (such as used for Arabic\n    or Hebrew), setting a different embedding direction for the IRI is\n    needed.  Setting the embedding direction can be done in a higher-\n    order protocol (e.g.  the dir='ltr' attribute in HTML).  If this is\n    not available (e.g.  in plain text), setting the embedding is done\n    with Unicode bidi formatting codes, i.e.  U+202A, LEFT-TO-RIGHT\n    EMBEDDING (LRE) before the IRI, and U+202C, POP DIRECTIONAL\n    FORMATTING (PDF) after the IRI, both not being part of the IRI\n    itself.\n\n    IRIs MUST NOT contain bidirectional formatting characters (LRM, RLM,\n    LRE, RLE, LRO, RLO, and PDF).  They affect the visual rendering of\n    the IRI, but do not themselves appear visually.  It would therefore\n    not be possible to correctly input an IRI with such characters.\n >>>>>>>>\n\n\nThere are several changes, in particular:\n\n- Making clear that the required display behavior is that of an ltr\n   embedding (not just ltr base directionality).\n- Tightening the case(s) that don't actually need the embedding\n   to avoid the cases that were wrongly included, as found by Michael.\n- Describing a case where no embedding is necessary in a purely\n   rtl context (what Jony was looking for).\n\nThe rest is mostly just moving things around a bit. Please check and\ntell me if I have missed something.\n\n\nAt 17:04 04/02/11 -0800, Michel Suignard wrote:\n>Martin, here is my new proposed text (in quotes) for replacement ofn the\n>2nd paragraph of clause 4.1:\n>\n><<\n>When rendered, bidirectional IRIs MUST be rendered using the Unicode\n>Bidirectional Algorithm [UNIV4] [UNI9] with an overall left-to-right\n>(ltr) direction.\n>To achieve this, the IRI is embedded left-to-right in\n>all the following cases:\n>1. If the current embedding level before the IRI is odd (right-to-left)\n>2. If the last character with a strong directionality before the IRI is\n>right-to-left\n>3. If the first character with a strong directionality after the IRI is\n>right-to-left.\n\nI think these three conditions would cover all the necessary cases,\nbut they would also force embedding in Jony's case, which is not\nnecessary and which I wanted to avoid.\n\n\n>No additional bidirectional rendering change by higher-level protocols\n>is allowed.\n>\n>Note: Embedding the IRI left-to-right can be achieved by embedding the\n>text with LRE...PDF. If the maximum allowed embedding level is exceded\n>(above 62), the IRI overall left-to-right direction may not be enforced.\n> >>\n\nI prefer not to mention the 62 levels case. It is part of the bidi\nalgorithm, and the limit is set so high that it shouldn't affect\nanything but pathological cases anyway.\n\n\n\n\n>The small diagramm (to be seen in monospaced chars) shows the desired\n>result\n>\n>-String before-|  IRI  |-String after--\n>               L    ON   L\n>(For the string before and after, the IRI behaves as bidi 'ON')\n\nI'm not actually sure that that's possible with an embedding.\nFor example in rule W1 in the bidi algorithm, we have\n\nsor NSM -> sor L\n(assuming sor is L)\n\nA sor of L could result from a closing of an ltr embedding.\nSo if I understand the way to calculate sor/eor correctly,\nthe IRI would appear as L to the surroundings.\n\n\n>(For the\n>IRI itself, string before and after behave as bidi 'L')\n\nThat I think is correct.\n\n\n>BTW I am interpreting clause W2 of the Unicode Bidi algorithm concerning\n>the strong type enumeration as including as well the embedding\n>characters (at least the LRE) as it is necessary in the logic expressed\n>above.\n\nYes. That's expressed by the sor, which would be L in the case of\nstarting an ltr embedding.\n\n\nRegards,   Martin.\n\n\n>I have tried one of the sample bidi algorithm (Asmus Freytag\n>version) and it behaves that way.\n>\n>Michel\n\n\n\n", "id": "lists-017-0730595"}, {"subject": "Re: [bidi] Re: IRIs and bidi: Addition regarding higherlevel protocol", "content": "<Jony Rosenne wrote>\nI see why it would be desirable to demand an overall left-to-right\ndirection\nfor mixed (LTR and RTL) IRIs, but not for pure RTL IRIs in an RTL\nenvironment.\n<end of Jony Rosenne quote>\n\nBut if an IRI is pure RTL, can you show real cases where putting LRE/PDF\naround it is going to make a difference in its display?\n\nMati\n\n\n\n", "id": "lists-017-0745818"}, {"subject": "RE: [bidi] Re: IRIs and bidi: Addition regarding higherlevel protocol", "content": "How can we, in this case, explain to the user that he needs an invisible\nLRE/PDF? \n\nAnyway, the wording suggested by Martin, \"as if they were preceded  by\nU+202A, LEFT-TO-RIGHT EMBEDDING (LRE), and followed by U+202C, POP\nDIRECTIONAL FORMATTING (PDF)\" solves the problem.\n\nJony\n\n> -----Original Message-----\n> From: Matitiahu Allouche [mailto:matial@il.ibm.com] \n> Sent: Friday, February 13, 2004 4:15 AM\n> To: Jony Rosenne\n> Cc: public-iri@w3.org; bidi@unicode.org\n> Subject: Re: [bidi] Re: IRIs and bidi: Addition regarding \n> higher-level protocols\n> \n> \n> \n> <Jony Rosenne wrote>\n> I see why it would be desirable to demand an overall \n> left-to-right direction for mixed (LTR and RTL) IRIs, but not \n> for pure RTL IRIs in an RTL environment. <end of Jony Rosenne quote>\n> \n> But if an IRI is pure RTL, can you show real cases where \n> putting LRE/PDF around it is going to make a difference in \n> its display?\n> \n> Mati\n> \n> \n> \n> \n\n\n\n", "id": "lists-017-0754613"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "Hello Adam,\n\nMany thanks for your comments.\n\nAt 09:51 04/02/15 -0500, Adam M. Costello BOGUS address, see signature wrote:\n\n>\"Roy T. Fielding\" <fielding@gbiv.com> wrote:\n>\n> > This was implemented as part of removing hostname productions in favor\n> > of general registered names.\n>\n>Martin Duerst <duerst@w3.org> replied:\n>\n> > The restriction of hostnames to DNS was discussed and agreed on at the\n> > San Francisco IETF based on interactions with IRIs.\n> >\n> > The argument was that conversion from IRIs to URIs (defined in the\n> > IRI spec) should take care of conversion from non-ASCII characters to\n> > punycode in the DNS part.\n>\n>I was very happy to see the IRI draft take that approach.  The issue is\n>explained very well in the issues list (040-reg-name):\n>\n>     report: Martin Duerst, 20 Mar 2003, URI BOF:\n>\n>     In order for internationalized characters in the authority\n>     component to be handled directly by an IRI processor, it must\n>     either\n>\n>       a) be able to encode the authority characters as %hh and rely on\n>          gethostbyname to do the conversion, or\n>\n>       b) know that the scheme uses hostport and not registry-based names\n>          and thus be able to convert the hostname to IDNA form.\n>\n>     action: Roy T. Fielding, 20 Mar 2003, URI BOF:\n>\n>     Note that IDNA was created specifically to avoid (a), so that\n>     doesn't seem to be a viable alternative for the IETF.\n>\n>Exactly.  Why go to the trouble of defining a backward-compatible\n>encoding (ACE) and then make it impossible to use?\n\nI don't think the current RFC2396bis draft says that you can't use\nACE. If you use ACE, it will just work.\n\nAnd I think a) is a bit too short, it should read\n       a) be able to encode the authority characters as %hh and rely on\n          gethostbyname or a layer (just) above it to do the conversion, or\n\n\n>What's the point of\n>downgrading an IRI to a URI if the URI still fails on legacy software?\n\nIn practice, things are a little bit more complicated, but that actually\nmakes this choice a little bit easier.\n\nWhen implementing IRIs on something like a browser, what I have\nseen (or done myself) so far is that it is much easier to implement\nthe UTF-8 and %-escape steps in one place, and the IDN -> punycode\nstep much lower in the stack.\n\nThe IRI draft (if and when I get around to do the edits this afternoon)\nwill change to convert everything to %-escapes, but it will contain\na note that points out that for backwards compatibility, in particular\nfor proxy and similar scenarios where IRI -> URI mapping and DNS\nresolution are strictly separated (and under the condition that\nthe scheme is known to be DNS-based), implementations MAY convert\ndirectly to punycode.\n\nSo in theory, this is a black-and-white distinction, but in practice,\nit's not.\n\n\n>RFC-2396 defined the host field as a host name or IPv4 address; there\n>was no mention of registered names.\n\nSorry, wrong. From http://www.ietf.org/rfc/rfc2396.txt:\n\n >>>>\n3.2. Authority Component\n\n    Many URI schemes include a top hierarchical element for a naming\n    authority, such that the namespace defined by the remainder of the\n    URI is governed by that authority.  This authority component is\n    typically defined by an Internet-based server or a scheme-specific\n    registry of naming authorities.\n\n       authority     = server | reg_name\n >>>>\n\nAnd while in San Francisco, the general understanding was that\nregistry-based naming authorities that use DNS hostnames have\nbeen the only such URIs in deployment, in the meantime, this\nunderstanding has been crumbled in the meantime. In addition,\nit was considered highly unadvisable to bet the future of\nURIs and IRIs on the DNS.\n\n\n\n>Currently, a URI like http://www.w%33.org/ will fail on many browsers,\n>which is no problem because the URI is invalid according to RFC-2396.\n\nIt works on IE, Opera, and Amaya. And it's not really an issue, because\nnobody would actually use that except for testing. For %-escapes\nderived from IDNs, it's very easy to make IRIs, IDNs, and this\n%-escaping all work without problems. Please remember: a browser\nthat doesn't support IDNs just doesn't.\n\n\n>By the way, the draft contains a factual error:\n>\n> > The reg-name syntax allows for percent-encoded octets, which is\n> > necessary to enable internationalized domain names to be provided in\n> > URIs;\n>\n>Every IDN has an ACE form; therefore percent-escapes are not necessary\n>for using IDNs in URIs.  Percent-escapes would be necessary for\n>using internationalized reg-names (because reg-names are not domain\n>names and IDNA does not apply to them), but not necessary for using\n>internationalized domain names.\n\nI suggest to change this to:\n\nThe reg-name syntax allows for percent-encoded octets, in order to\nenable internationalized domain names to be provided in URIs in\nan uniform way;\n\n\n>Stephen Pollei <stephen_pollei@comcast.net> wrote:\n>\n> > So it's my understanding that lots of names are legal, just not\n> > recommended.\n\n>RFC-952 gave the syntax:\n\n>So there is no doubt that host names can contain only ASCII letters,\n>digits, hyphens, and dots.  It's an open-and-shut case.\n\nSo Stephen's host, with an underscore, just doesn't exist, or what?\nEven if every browser actually gets there? Is the tail wagging the\ndog here, or what do you think is going on?\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0764145"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "[I apologize for breaking the no-cross-posting rule, but I guess if I'm\nreplying to a message that was cross-posted by a W3C member, I should\ndefer to his judgement.  I'm a newbie to W3C mailing lists.]\n\nMartin Duerst <duerst@w3.org> wrote:\n\n> > Why go to the trouble of defining a backward-compatible encoding\n> > (ACE) and then make it impossible to use?\n>\n> I don't think the current RFC2396bis draft says that you can't use\n> ACE.  If you use ACE, it will just work.\n\nI meant that you can't use the ACE unless you know that the name in\nquestion is a domain name rather than a reg-name.\n\n> > RFC-2396 defined the host field as a host name or IPv4 address; there\n> > was no mention of registered names.\n> \n> Sorry, wrong.\n\nOops!  I grepped for \"reg-name\" and \"registered\", and missed both\n\"reg_name\" and \"registry\".  Sorry!  I was suggesting to avoid\nintroducing an ambiguity between hostnames and reg-names, but the\nambiguity already existed in RFC-2396.\n\n> The IRI draft (if and when I get around to do the edits this\n> afternoon) will change to convert everything to %-escapes, but it will\n> contain a note that points out that for backwards compatibility, in\n> particular for proxy and similar scenarios where IRI -> URI mapping\n> and DNS resolution are strictly separated (and under the condition\n> that the scheme is known to be DNS-based), implementations MAY convert\n> directly to punycode.\n\nThe problem with this approach is that the IRI spec would be asking\napplications to use IDNs in a way that violates the IDNA spec.  Consider\nthe IRI:\n\nfoobar://jos?.net/\n\nSuppose the foobar: scheme spec makes no reference to IDNA (maybe it\npredates IDNA).  Also suppose the application performing the IRI-to-URI\nconversion doesn't recognize the foobar: scheme.  Then it cannot be sure\nwhether jos?.net is an IDN or a reg-name.  If it's a reg-name and the\napplication applies ToASCII, that is clearly wrong, because IDNA does\nnot apply to reg-names.  Percent-escapes are allowed in reg-names, so\nthe proper URI would be\n\nfoobar://jos%C3%A9.net/\n\nOn the other hand, if the name is a host name and the application uses\nthe percent-encoded UTF-8 approach, then the application has violated\nthe IDNA spec by putting a non-ASCII domain name into an IDN-unaware\nslot (remember that foobar: URIs are IDN-unaware).  (I'm viewing\njos%C3%A9 as non-ASCII.  If it is viewed as ASCII, then it's wrong for a\ndifferent reason: \"jos%C3%A9\" (literally) is not the intended label, and\nis not going to be found in the DNS, and it violates host name syntax.)\n\nI see two ways out of this.  One way is to make hostnames and reg-names\nsyntactically distinguishable, but that would mean retracting some of\nthe syntactic freedom that RFC-2396 granted to reg-names, by adding a\nrequirement that reg-names must contain some marker that cannot appear\nin hostnames.  This would solve the problem for hostname fields in IRIs\nthat begin scheme://server/ (which is the lion's share of cases), but\nthe same or similar problem would still exist for traditionally-ASCII\nprotocol elements in other kinds of schemes (for example, both the local\npart and domain part in the mailto: scheme).\n\nAnother (more general) way out is to introduce an explicit\nhalf-way-house between IRIs and URIs.  The rule for converting IRIs to\nURIs would be:\n\n1) If the IRI contains only uric characters, then leave it as-is.\n\n2) Otherwise, if you know the foobar: URI scheme, then you know whether\nthe name is a hostname or a reg-name, and therefore you can convert\ndirectly to a foobar: URI.  (And more generally, you know which\ncomponents of a foobar: URI can use percent-encoded UTF-8 and which\ncomponents need some other kind of conversion.)\n\n3) If you don't know the foobar: scheme, then you can only convert to an\ni: URI.  For example,\n\nfoobar://jos?.net/  -->  i:foobar://jos%C3%A9.net/\n\nThe i: URI scheme acts as a meta-scheme, so we can think of i:foobar:\nas a URI scheme.  The i:foobar: URI scheme is just like the foobar: IRI\nscheme (not the foobar: URI scheme), except that it uses percent-encoded\nUTF-8 rather than native non-ASCII characters.  Therefore, any IDN-aware\nfields in the foobar: IRI scheme remain IDN-aware in the i:foobar: URI\nscheme.\n\nAnything that is foobar-aware can finish the conversion.  Note that\nanything that needs to resolve i:foobar://jos%C3%A9.net/ will need to be\nfoobar-aware anyway.\n\ni:foobar://jos%C3%A9.net/\n  -->  foobar://xn--jos-dma.net/    (if foobar: uses hostnames)\n  -->  foobar://jos%C3%A9.net/      (if foobar: uses reg-names)\n\nIf the name was a reg-name, then the introduction of i: has created\na new opportunity for failure (the agent wanting to resolve the URI\nmight recognize foobar: but not i:).  But if the name was a hostname\n(the more common scenario), then the introduction of i: has prevented\nan opportunity for non-graceful failure.  It has prevented the case of\nfoobar://jos%C3%A9.net/ falling into the hands of an application that\nrecognizes foobar: but is IDN-unaware.  Any agent that understands how\nto handle percent-escapes in hostnames can be expected to recognize i:,\nbecause they are both new syntax that could be introduced at the same\ntime in the same new spec (RFC-2396bis).\n\nA nice feature of this i: trick is that it works not only for\ngeneric-syntax IRIs (scheme:/...) but all IRIs, and works not only for\nIDN-aware fields, but Ianything-aware fields.  For example, suppose that\nsome solution for internationalized email local parts is adopted, and a\nmailto: IRI is defined.  An IRI-to-URI converter that doesn't know the\nmailto: IRI syntax will perform:\n\nmailto:jos?@jos?.net  -->  i:mailto:jos%C3%A9@jos%C3%A9.net\n\nThat i:mailto: URI can be tunneled through ASCII infrastrcture until\neventually something that understands internationalized mail addresses\nand the mailto: scheme can perform the appropriate conversions:\n\ni:mailto:jos%C3%A9@jos%C3%A9.net  -->  mailto:????@xn--jos-dma.net\n\n???? stands for whatever ASCII local part needs to be substituted\nfor the internationalized local part jos?.  Or if there is no such\nASCII fallback, then conversion to a mailto: URI is impossible, and\nthe i:mailto: URI can just be resolved directly, but only by an agent\nthat understands internationalized local parts (ILP).  The i: prevents\nILP-unaware agents from being deceived into thinking they understand\nsomething that they really don't.\n\nAnother nice feature of the i: trick is that it makes it easier for\nsoftware authors to appreciate the implications of doing scheme-unaware\nIRI-to-URI conversions.  For example, http://jos%C3%A9.net/ is just as\nincompatible with legacy software as i:http://jos%C3%A9.net/ is (neither\ncan be resolved without ToASCII), but the latter is more obviously\nincompatible and therefore more likely to remind software authors to\nuse their knowledge of the http: scheme to invoke ToASCII and use\nhttp://xn--jos-dma.net/ instead.\n\nAlso, since http://jos%C3%A9.net/ violates RFC-2396, it's hard to\npredict how applications will react.  Some might reject it, some\nmight pass jos%C3%A9.net literally to their host name resolver, some\nmight percent-decode it before calling the resolver, some might even\nperform charset transcoding before calling the resolver.  And then\nwho knows what the resolver will do with whatever it gets.  There are\nundoubtedly spoofing opportunities in there.  I think it's cleaner to\nstick the i: in front of it so that old applications fail gracefully\nwith \"unrecognized scheme\".\n\n> > Currently, a URI like http://www.w%33.org/ will fail on many\n> > browsers, which is no problem because the URI is invalid according\n> > to RFC-2396.\n>\n> It works on IE, Opera, and Amaya.\n\nIt fails on both of the browsers I use: Mozilla Firefox (formerly\nFirebird) and w3m (both on Linux).\n\n> For %-escapes derived from IDNs, it's very easy to make IRIs, IDNs,\n> and this %-escaping all work without problems.  Please remember: a\n> browser that doesn't support IDNs just doesn't.\n\nI'm alarmed by that last sentence.  The goal of IDNA was that, at\nworst, a browser that doesn't support IDNs will fail to display IDNs\nintelligibly, and will fail to let you type IDNs into the location\nfield, but it will still allow you to follow all links in HTML pages,\nbecause the domain name slots in the URI slots in HTML are IDN-unaware\nand therefore can contain ACEs but not percent-encoded UTF-8.\n\nA new URI spec that allows percent-encoded UTF-8 host names would not be\nbackward-compatible with the previous URI spec, and should therefore not\nbe automatically incorporated by reference into other specs.  HTML, for\nexample, has done an admirable job of evolving in a backward-compatible\nway, so far.  If percent-encoded non-ASCII host names suddenly became\nlegal in HTML, that would not be backward-compatible, and the new HTML\nshould really have a different media-type.  The media type text/html\nshould refer to an HTML that uses a kind of URI that uses only ASCII\nhost names.  If we don't want to have two different kinds of URI,\nthen the new URI spec cannot invite percent-escapes into host names;\nit needs to keep the distinction between hostnames (which prohibit\npercent-escapes) and reg-names (which allow them) as in RFC-2396.\n\n> > So there is no doubt that host names can contain only ASCII letters,\n> > digits, hyphens, and dots.  It's an open-and-shut case.\n>\n> So Stephen's host, with an underscore, just doesn't exist, or what?\n\nThe purpose of standards is to let everyone know what is expected of\nthem, so that they can interoperate.  If the standard says that host\nnames cannot contain underscores, then someone out there could have\nlegitimately created a protocol and/or software that uses underscores to\ndelimit or annotate host names, and Stephen's host would be inaccessible\nvia that protocol/software.\n\nAMC\n\n\n\n", "id": "lists-017-0779029"}, {"subject": "New draft-duerst-iri06.tx", "content": "I just submitted draft-duerst-iri-06.txt to the Internet-Drafts editor.\nYou can find it at\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri-06.txt.\nI upgraded the syntax to take into account the recent changes to\nthe URI syntax (RFC2396bis). This has resulted in a reversal of\nhttp://www.w3.org/International/iri-edit/#idnuri-02 (still needs\nto be documented), with quite some related edits. Please check.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0796799"}, {"subject": "Http and RFC239", "content": ">-----Original Message-----\n>From: public-iri-request@w3.org [mailto:public-iri-request@w3.org]\n> On Behalf Of Adam M. Costello BOGUS >address, see signature\n>\n>\n>Also, since http://jos%C3%A9.net/ violates RFC-2396, it's hard to\npredict\n> how applications will react.  Some might reject it, some might pass\njos%C3%A9.net\n> literally to their host name resolver,...\n\nIn which way does it violate RFC-2396? Could you point to the relevant\ntext? I would agree that it was not the intent to allow it as you would\nexpect the http scheme to use the 'server' notation, not the 'reg_name'.\nBut 'authority' contains both 'server' and 'reg_name'. I was trying to\nfind some prose in RFC-2396 that would restrict the http scheme, but\ncouldn't find it.\n\nOn the same thread, is there somewhere a formal up-to-date definition in\nABNF for current URI schemes, such as http, mailto, ftp, etc...?\n\nOtherwise Adam's mail was very useful for my understanding of the\nissues.\n\nMichel Suignard\n\n\n\n", "id": "lists-017-0803595"}, {"subject": "Re: Http and RFC239", "content": "Michel Suignard <michelsu@windows.microsoft.com> wrote:\n\n> > Also, since http://jos%C3%A9.net/ violates RFC-2396,\n>\n> In which way does it violate RFC-2396? Could you point to the relevant\n> text?\n\nSorry, I said that wrong.  It violates RFC-2616 (HTTP), specifically the\nparts of RFC-2616 that are incorporated by reference from RFC-2396.\n\nRFC-2616:\n\n  3.2.1 General Syntax\n\n    For definitive information on URL syntax and semantics, see \"Uniform\n    Resource Identifiers (URI):  Generic Syntax and Semantics,\"\n    RFC 2396...  This specification adopts the definitions of ...\n    \"host\", ... from that specification.\n\n  3.2.2 http URL\n\n    http_URL = \"http:\" \"//\" host [ \":\" port ] [ abs_path [ \"?\" query ]]\n\nRFC-2396:\n\n  A. Collected BNF for URI\n\n    host          = hostname | IPv4address\n    hostname      = *( domainlabel \".\" ) toplabel [ \".\" ]\n    domainlabel   = alphanum | alphanum *( alphanum | \"-\" ) alphanum\n    toplabel      = alpha | alpha *( alphanum | \"-\" ) alphanum\n    IPv4address   = 1*digit \".\" 1*digit \".\" 1*digit \".\" 1*digit\n\n> On the same thread, is there somewhere a formal up-to-date definition\n> in ABNF for current URI schemes, such as http, mailto, ftp, etc...?\n\nhttp://www.iana.org/assignments/uri-schemes\n\nEach scheme is defined in its own document, except for the ones that\nhaven't been updated since RFC-1738.\n\nAMC\nhttp://www.nicemice.net/amc/\n\n\n\n", "id": "lists-017-0812855"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "I wrote:\n\n> Another (more general) way out is to introduce an explicit\n> half-way-house between IRIs and URIs.\n\nAfter some further thought, I would make a few tweaks to that idea.\n\nFirst, percent-encoding would always be allowed in all components of all\nIRIs; individual schemes would be unable to prohibit percent-encoding\nanywhere.  Second, if an individual scheme restricts a component to\ncontain only a certain subset of Unicode characters (for example, the\nASCII subset), scheme-specific IRI consumers would be required to check\nthe component before using it, and fail gracefully if any characters are\nfound outside the subset.\n\n(That would prevent IRIs from suffering some of the problems we are now\nseeing with URIs.  In URIs, percent-encoding was prohibited in the host\ncomponent, and non-ASCII was prohibited in the host component, and there\nwas no requirement telling URI consumers what to do if they should find\neither of those things in the host component, so now we have different\nimplementations behaving differently when they encounter such things.)\n\nThe rule for converting an IRI to a URI would be:\n\n1) If you recognize the scheme, then verify that no component contains\ncharacters that it's not supposed to contain.  If the verification\nsucceeds, then apply whatever conversions are appropriate for each\ncomponent.\n\n2) If the verification failed, or if you didn't recognize the scheme,\nthen perform the generic conversion to percent-encoded UTF-8 as described\nin the IRI draft, and prepend the prefix i- to the scheme.\n\n(The prefix i- is a better choice than my previous suggestion of i:\nbecause it is less prone to interact strangely with relative references.\nThe prefix could be registered as an \"alternate tree\" as described in\nRFC-2717.)\n\nTo resolve an i-* URI, you conceptually convert it back to an IRI, then\nredo the IRI-to-URI conversion using the scheme-specific knowledge\nthat was lacking in the earlier IRI-to-URI conversion.  Of course an\nimplementation might use a more direct route.\n\nAMC\nhttp://www.nicemice.net/amc/\n\n\n\n", "id": "lists-017-0821560"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "Hello Adam,\n\nI still plan to look at your previous emails,\nbut here an answer on this one.\n\nAt 11:35 04/02/18 +0000, Adam M. Costello BOGUS address, see signature wrote:\n\n>I wrote:\n>\n> > Another (more general) way out is to introduce an explicit\n> > half-way-house between IRIs and URIs.\n>\n>After some further thought, I would make a few tweaks to that idea.\n>\n>First, percent-encoding would always be allowed in all components of all\n>IRIs;\n\nIt's currently not, in particular in the 'scheme' component.\n\nAnd it's not really IRIs that should need percent-encoding,\nalthough you need it in some cases, if characters are not\nencoded as UTF-8 in the corresponding URI.\n\n\n>individual schemes would be unable to prohibit percent-encoding\n>anywhere.  Second, if an individual scheme restricts a component to\n>contain only a certain subset of Unicode characters (for example, the\n>ASCII subset), scheme-specific IRI consumers would be required to check\n>the component before using it, and fail gracefully if any characters are\n>found outside the subset.\n\nWhat do you mean by 'fail gracefully'? The IRI would just not be\nresolved? Or anything else? And why would that have to be checked\nbefore use? Why could it not simply be the result of actual use?\n\n\n>(That would prevent IRIs from suffering some of the problems we are now\n>seeing with URIs.  In URIs, percent-encoding was prohibited in the host\n>component, and non-ASCII was prohibited in the host component, and there\n>was no requirement telling URI consumers what to do if they should find\n>either of those things in the host component, so now we have different\n>implementations behaving differently when they encounter such things.)\n\nWell, yes. But that's just a result of how things are implemented,\nnot a problem in the specification, I guess.\n\n\n>The rule for converting an IRI to a URI would be:\n>\n>1) If you recognize the scheme, then verify that no component contains\n>characters that it's not supposed to contain.\n\nAgain, why check before use? Of course if the IRI or URI is actually\nused, there will naturally be some things that don't work out.\nBut why should we e.g. check that a domain name doesn't contain\na $, when it's just as easy to let this try and resolve and\nnot be found? For IDNA, a very strict check was important because\nthere is a justified fear that some registrants will step over\nthe boundary of what's allowed in terms of characters. But in\ngeneral, that's not that much of an issue.\n\n\n>If the verification\n>succeeds, then apply whatever conversions are appropriate for each\n>component.\n\nWe already made an exception for domain names. I don't want to\nmake any other exceptions. The goal is not a hodgepodge of\nscheme-specific conventions, but to take advantage of the\nfact that many URI schemes already are based on UTF-8,\nmany others allow UTF-8 to be used (in many parts at least)\nand UTF-8 is also the recommendation for new schemes.\n\nSchemes and parts that are not based on UTF-8 just have to\nlive with the fact that they cannot use the benefits of IRIs,\nor upgrade themselves.\n\n\n>2) If the verification failed, or if you didn't recognize the scheme,\n>then perform the generic conversion to percent-encoded UTF-8 as described\n>in the IRI draft, and prepend the prefix i- to the scheme.\n\nWhy should i- be prepended? New schemes can be designed\nso that they fit together well with IRIs (if the relevant\nBCP guidelines are used, that will be the case automatically).\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0831270"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "Martin Duerst <duerst@w3.org> wrote:\n\n> > First, percent-encoding would always be allowed in all components of\n> > all IRIs;\n>\n> It's currently not, in particular in the 'scheme' component.\n\nThat's fine.  The rule can be: percent-encoding is allowed everywhere\nexcept the scheme, and individual schemes cannot make exceptions to this\nrule.\n\n> And it's not really IRIs that should need percent-encoding, although\n> you need it in some cases, if characters are not encoded as UTF-8 in\n> the corresponding URI.\n\nPercent-encoding could also be useful for displaying an IRI when\nthe local charset is not Unicode, or when the available fonts are\ninsufficient.  If an IRI contains many non-ASCII characters that are\ndisplayable, plus one character that's not displayable, it might be\nnice to use percent-encoding only for the oddball and display the\nrest intelligibly, rather than convert the entire IRI to a URI.  If\nthat displayed IRI is cut & pasted or manually retyped into another\napplication, it should be handled properly.\n\n> > Second, if an individual scheme restricts a component to contain\n> > only a certain subset of Unicode characters (for example, the ASCII\n> > subset), scheme-specific IRI consumers would be required to check\n> > the component before using it, and fail gracefully if any characters\n> > are found outside the subset.\n\nThat paragraph of mine started off more focused, then I generalized it,\nand now I think I'd like to return to the more focused version:\n\nIf an individual scheme restricts a component to contain only ASCII\ncharacters, then scheme-specific IRI consumers would be required\nto check the component before using it, and fail gracefully if any\nnon-ASCII characters are found.\n\nThat's much simpler, requiring only one bit of knowledge about the\nsyntax of the component (whether it allows non-ASCII).\n\n> What do you mean by 'fail gracefully'?\n\nIf the component is supposed to be a Foo, and a Foo is supposed to be\nASCII, and the component contains non-ASCII, then you must not use\nthe component as a Foo (whatever that means).  If you were about to\ndo something that entailed using the component as a Foo (for example,\npassing it to something that takes a Foo as an argument), then you\nmust abort the attempt, and the error is something like \"invalid Foo\n(non-ASCII)\".\n\n> And why would that have to be checked before use?  Why could it not\n> simply be the result of actual use?\n\nBecause the original Foo spec might be old (even if the IRI scheme\ncontaining a Foo component is more recent), and might have its own\ninstalled base of stuff that does not behave interoperably when\npresented with a non-ASCII Foo, and therefore it might have needed to\nintroduce a client-side downgrading operation in order to safely extend\nthe syntax.  If the IRI consumer blindly tries to use the Foo component\nas a Foo without performing the downgrading operation, the result will\nbe unpredictable.  Maybe there will be a misleading error message like\n\"Foo xyz not found\" even though xyz actually exists, or maybe the\nmangled request will map onto some other Foo by coincidence or malice.\n\nIdeally, the Foo spec should have specified what to do whenever you\nencounter a syntactically invalid Foo, so that Foo implementations bear\nfull responsibility for interoperability as the Foo syntax is extended,\nand nothing about the Foo syntax need be known at the IRI-processing\nlayer.  But there is one kind of syntax extension where neglect has\nbeen the rule rather than the exception: the extension from ASCII to\nnon-ASCII.  Because it has been so common for protocols to assume ASCII\nwithout saying enough about how to react to non-ASCII, and because\nthe ASCII-to-non-ASCII transition is the same one being made by the\nintroduction of IRIs, and because IRIs are uniquely positioned as a\nnarrow interface between a wide range of protocols and a wide range of\napplications (sort of like IP is a narrow interface between a wide range\nof networks and a wide range of applications), IRIs are a good place to\ninterpose a simple type-safety check.\n\nThe check would serve the same purpose as the scheme component itself.\nIf you try to use a URI/IRI with an unknown scheme, the results are\nvery predictable: you get a graceful failure, \"unknown scheme\".  The\nscheme acts as a type tag to prevent operations from being misapplied\nto the wrong type of data (with unpredictable results).  Including\nthe suggested ASCII-component-check in IRI processing would allow the\npresence of non-ASCII characters to serve as a type tag, to prevent\nlegacy ASCII-assuming operations from being misapplied to non-ASCII data\n(with unpredictable results).\n\n> > (That would prevent IRIs from suffering some of the problems we are\n> > now seeing with URIs.  In URIs, percent-encoding was prohibited\n> > in the host component, and non-ASCII was prohibited in the host\n> > component, and there was no requirement telling URI consumers\n> > what to do if they should find either of those things in the host\n> > component, so now we have different implementations behaving\n> > differently when they encounter such things.)\n>\n> Well, yes.  But that's just a result of how things are implemented,\n> not a problem in the specification, I guess.\n\nI think it's a problem in the specification.  I think we've learned the\nhard way that specs need to say what to do when you encounter unexpected\nsyntax, otherwise it's difficult to ever extend the syntax.\n\nRFC-2396 said the host component does not contain percent-escapes, but\ndidn't say what to do if it did contain them, so some implementations\ndecode the escapes, and some don't, and neither group is wrong.\nRFC-1123 said that host names were ASCII, and didn't say what to do if\nyou encountered a non-ASCII host name, so some implementations might\nreject it, some might pass it to DNS without doing transcoding, some\nmight pass it to DNS after transcoding, or who knows what else.  So the\nsituation now is that using percent-encoding in the host field of a URI\ncan lead to any number of unpredictable outcomes.\n\nSimilarly, the IP spec and the TCP spec both said that certain flag\nbits in their headers were reserved and must be zero, but they did not\nclearly say what you should do if they're not zero.  Years later, a good\nidea for an extension comes along, Explicit Congestion Notification\n(ECN), which uses some of those flag bits, and its deployment is being\ngreatly hampered by machines that drop packets or TCP connections that\nhave those bits set.  (For example, when I enable ECN on my machine,\nI cannot access one of my bank web sites.)  ECN would be completely\nbackward-compatible if all hosts ignored incoming reserved flag bits,\nwhich perhaps they would do if the specs had clearly stated that\nrequirement.\n\nAs another example, RFC-822 said that mail headers are ASCII, but didn't\nsay what to do if you encountered bytes outside 0..127 in a header.  Now\nwe have implementations that remove 128..160 (sendmail), interpret the\nbytes using the local charset, and who knows what else.  This makes it\nvery difficult to extend the standard to define a meaning for bytes\n128..255 in mail headers.\n\n> > 1) If you recognize the scheme, then verify that no component\n> > contains characters that it's not supposed to contain.\n>\n> Again, why check before use? Of course if the IRI or URI is actually\n> used, there will naturally be some things that don't work out.  But\n> why should we e.g. check that a domain name doesn't contain a $, when\n> it's just as easy to let this try and resolve and not be found?\n\nYes, I guess checking for $ is probably getting too nosey into the\ninternal syntax of the component.  But I think a simple check for ASCII\nvs. non-ASCII would be valuable and not too nosey.\n\n> We already made an exception for domain names.  I don't want to make\n> any other exceptions.  The goal is not a hodgepodge of scheme-specific\n> conventions, but to take advantage of the fact that many URI schemes\n> already are based on UTF-8, many others allow UTF-8 to be used (in\n> many parts at least) and UTF-8 is also the recommendation for new\n> schemes.\n\nI agree with those goals, but there is a distinct possibility that an\nACE will be defined for email local parts, in which case IRI-to-URI\nconverters with knowledge of mailto: will want to use the ACE for\ncompatibility with existing mailto: resolvers.  Maybe there are\nother ASCII-only components lurking in existing URI schemes facing\nbackward-compatibility challenges similar to those of domain names, and\nmaybe they will likewise find it necessary to use the ACE approach to\ninternationalization.\n\nThe IRI spec would not need to mention any of the individual\nscheme-specific exceptions.  It mentions the IDN exception because ihost\nis a potential component of IRIs in general, and domain names are used\nin a great many schemes, but those reasons wouldn't apply to any other\nexceptional components (like email local parts).\n\n> > 2) If the verification failed, or if you didn't recognize the\n> > scheme, then perform the generic conversion to percent-encoded UTF-8\n> > as described in the IRI draft, and prepend the prefix i- to the\n> > scheme.\n>\n> Why should i- be prepended?\n\nBecause URI processing does not include the ASCII-component-check\n(whereas IRI processing, being a new spec, could include the check).\nBlindly dumping non-ASCII characters (even percent-encoded ones) into\na URI would bypass the check.  If the URI contains a component that\nused to be limited to ASCII, legacy implementations might behave in\nunpredictable ways when that component contains (percent-encoded)\nnon-ASCII.\n\nWhereas IRIs can use the presence of non-ASCII as a type tag (if IRI\nprocessing includes the check), URIs cannot (because URI processing\ndoes not include the check).  The i- prefix would serve as a type tag\nfor URIs, indicating that the URI contains unchecked components.  It\nwould prevent legacy implementations from misapplying ASCII-assuming\noperations to non-ASCII data, because legacy implementations would not\nrecognize the scheme.\n\nBasically, i-foo: means \"this identifier was blindly converted from a\nfoo: IRI without foo-specific knowledge, so it does not necessarily\nconform to foo: URI syntax, but it does conform to generic URI syntax,\nand you can certainly recover the foo: IRI\".\n\nAnother answer to your question (\"Why should i- be prepended?\") is:  So\nthat the IRI spec does not invite applications to violate the IDNA spec.\nThe ireg-name component is an IDN-aware slot in schemes that use domain\nnames there (because the IRI draft invites the usage of non-ASCII domain\nnames there and cites IDNA).  The corresponding reg-name slot in the\nURI is IDN-unaware.  To convert a foo: IRI to a foo: URI, IDNA requires\nToASCII to be applied.  But when the application doesn't know the\nscheme, the IRI draft invites the application to use percent-encoding\ninstead, disregarding the IDNA requirement.\n\nI see no way for an application lacking scheme-specific knowledge to\nconvert a foo: IRI to a foo: URI without violating the IDNA spec.  But\nthe application can convert any IRI to *some* URI, using the i- prefix.\nThat works because an i-*: URI is really an IRI semantically, and a URI\nsyntactically.  Therefore the domain name slots in an i-*: URI are still\nIDN-aware, so the percent-encoded form is okay there.\n\n> New schemes can be designed so that they fit together well with IRIs\n> (if the relevant BCP guidelines are used, that will be the case\n> automatically).\n\nThe resolvers of those new schemes can simply strip off the i- prefix if\nthey know that the generic IRI-to-URI conversion is sufficient for those\nschemes.  That could be mentioned in the IRI spec and in the guidelines\nfor creating new schemes.\n\nBy the way, I should insert a rule 0 in my proposed IRI-to-URI\nconversion:\n\n0) If the IRI contains no non-ASCII characters (not even percent-encoded\nones) then stop; it's already a URI.\n\n(Without this rule, if the scheme was unknown, the only effect of the\nother rules would be to prepend the i- prefix, which would be protecting\nnothing.)\n\nAMC\nhttp://www.nicemice.net/amc/\n\n\n\n", "id": "lists-017-0842882"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "Graham Klyne <GK@ninebynine.org> wrote:\n\n> > The rule can be: percent-encoding is allowed everywhere except the\n> > scheme, and individual schemes cannot make exceptions to this rule.\n>\n> I think that's pretty close to what we have (if permitted\n> normalization is taken into account - section 6.2.2.2).\n\nI was talking about IRIs there, not URIs.\n\n[This thread was cross-posted to both mailing lists early on, when it\nwas talking about both URIs and IRIs, but it has progressively shifted\nattention more toward IRIs.  I forgot to manually fix the Reply-To:\nfield in my last message to point to both lists, so your message went\nonly to the URI list.  I've restored the former To: and Reply-To: fields\nfor this message, but someone please tell me if it's time to stop the\ncross-posting.]\n\nURIs already have a legacy of schemes that prohibit percent-encoding in\nsome components (all schemes that cite RFC-2396 and contain a hostname\ncomponent prohibit percent-encoding in the hostname).  The main point I\nwas trying to make in the quotation above is that the IRI spec should\navoid that pitfall by explicitly requiring all IRI consumers to expect\npercent-encoding in all components (except the scheme component) of all\nschemes.  Individual schemes should not be able to ban percent-encoding\nanywhere in IRIs.\n\n> > If an individual scheme restricts a component to contain only ASCII\n> > characters, then scheme-specific IRI consumers would be required\n> > to check the component before using it, and fail gracefully if any\n> > non-ASCII characters are found.\n> >\n> > That's much simpler, requiring only one bit of knowledge about the\n> > syntax of the component (whether it allows non-ASCII).\n>\n> this is about *generic* URI syntax, and I'm currently implementing a\n> *generic* URI parser.  How am I supposed to know whether a particular\n> scheme restricts a particular component in any particular way?\n\nPlease note the phrase \"scheme-specific IRI consumers\" in the quoted\npassage.  The proposed rule is not about URI parsers at all, nor is it\nabout generic IRI parsers; it is about scheme-specific IRI parsers.\n(It's too late to add a similar requirement for scheme-specific URI\nconsumers, because there's already a huge installed base.)\n\nThe proposed rule, in other words, is that if you're going to use\nscheme-specific knowledge to use a component in a scheme-specific way,\nthen you must first use your scheme-specific knowledge to check for\nthe occurrence of non-ASCII characters where they don't belong.  On\nthe other hand, if you have no scheme-specific knowledge then you're\nincapable of performing that check, but that's okay because you're also\nincapable of doing what the check prevents: feeding the component to\na scheme-specific ASCII-assuming operation.  The only operations you\nknow are generic IRI-component operations, all of which are designed to\nhandle non-ASCII.\n\nAMC\nhttp://www.nicemice.net/amc/\n\n\n\n", "id": "lists-017-0862976"}, {"subject": "IRIs discussed in new IAB documen", "content": "Greetings again. I just noticed that the IAB character repertoire \ndocument that uses IRI as an example has been updated. It can be \nfound at \n<http://www.ietf.org/internet-drafts/draft-iab-char-rep-01.txt>.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-017-0873382"}, {"subject": "Help  Numbers and Telephone Numbers in a localized application (Unicode", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-017-0922327"}, {"subject": "Re: Help  Numbers and Telephone Numbers in a localized   application (Unicode", "content": "Hello Leesa,\n\nThis mailing list is for the discussion of IRIs.\nYour question is not related to IRIs and therefore not\nappropriate for this list, sorry.\n\nRegards,   Martin.\n\nAt 17:03 04/01/28 -0500, Leesa Haslam wrote:\n>When converting a Latin1 software application to support Unicode, we \n>encountered some issues.  We have several fields which we use as \"numbers\" \n>and perform math on them, for example: we search in a range of plus or \n>minus two years from an input number of years.  We also use telephone \n>number as part of a unique identifier.\n>\n>The application will be used in China, Japan, Russia, and several other \n>countries.\n>\n>My question: Can/should we require that numbers be U+0030 thru U+0039?\n>\n>Please advise.\n>\n>\n>\n>----------\n><http://g.msn.com/8HMBENUS/2746??PS=>Check out the coupons and bargains on \n>MSN Offers!\n\n\n\n", "id": "lists-017-0929370"}, {"subject": "draft-duerst-iri08.txt submitted to IES", "content": "I have just submitted draft-duerst-iri-08.txt to the IESG for\nreview and approval as a Proposed Standard.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-0959128"}, {"subject": "reagle&#64;w3.or", "content": "Here is a casino giving away $25 Free when you sign up an account.\nNo credit card required\nhttp://secretbonus.cls2.org/iwin.html\n\n\nJames\n\n\n\n", "id": "lists-017-0965221"}, {"subject": "123fant?stico", "content": "<p><a href=\"http://www.test.com\">test</a></p>\n\n\n\n", "id": "lists-017-0992610"}, {"subject": "Re: IRIs are forbidden in HTML [htmlIRI12", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-0998538"}, {"subject": "Re: [check] :8001 updated, 0.6.1 in progress..", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>RPMs rolled as well, and uploading to <http://cachalot.ods.org/> right\n>now.\n\nCool! Thanks for doing this Ville! Very much appreciated!\n\n\n>Terje, some last-minute CSS changes made fonts in 0.6.1 look ugly on\n>RH8, Galeon/Mozilla, Konqueror and Opera.  I don't have time to\n>investigate at the moment, so attached is a couple of screenshots.  Note\n>in particular the monospace font in buttons.\n\nThe \"ugly\" fonts are intentional; though perhaps not too well considered.\nIn an attempt to deal with the squished fonts in Konq I tried to set an\nexplicit font that I know is available on Linux but not normally found on\nWindows or Mac OS (\"Luxi Sans\"). I'm not particularly happy with the\nresult, but if it will cure the Konq issue I can live with it.\n\nOTOH, it's beginning to look like we should just dispense with the fonts\nalltogether and set generic families (\"sans-serif\") instead. I'm useless at\ntypography -- as I may have mentioned :-) -- so this half-assed attempt is\nprobably worse then useless.\n\n\nThe monospaced font in the buttons is intentional. I want that to stand out\nsince the button is the \"action\" on the page and it otherwise tends to\ndisappear in the body of the page.\n\n-- \nInterviewer: \"In what language do you write your algorithms?\"\n    Abigail: English.\nInterviewer: \"What would you do if, say, Telnet didn't work?\"\n    Abigail: Look at the error message.\n\n\n\n", "id": "lists-017-10000004"}, {"subject": "Re: Redirecting old checklink doc pag", "content": "On Sun, Dec 01, 2002, Ville Skytt? wrote:\n> Could someone make the old doc page,\n> <http://www.w3.org/2000/07/checklink> redirect to\n> <http://validator.w3.org/docs/checklink.html>?\n\nDone with a 302. Just ping me if you'd prefer a 301.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-10009133"}, {"subject": "Re: [check] :8001 updated, 0.6.1 in progress..", "content": "Terje Bless <link@pobox.com> wrote:\n\n>Among other things, that means HEAD is off-limits until I finish the\n>merge!\n\nOk, HEAD is merged and my template code just landed. Yay! :-)\n\nThis means HEAD is now horribly broken and will be for quite a clip until\nthe template code stabilizes. But it is now open for commits if anyone has\nanything they want in there.\n\n-- \nI have to admit that I'm hoping the current situation with regard to XML\nNamespaces and W3C XML Schemas is a giant practical joke,   but I see no\nsigns of pranksters coming forward with a gleeful smile to announce that\nthey were just kidding.                              -- Simon St.Laurent\n\n\n\n", "id": "lists-017-10016722"}, {"subject": "Re: [ANN] New generation of the &quot;Markup Validator&quot; release", "content": "Hey gerald,\n\nOn Monday, Dec 2, 2002, at 18:10 Asia/Tokyo, Gerald Oskoboiny wrote:\n> BTW, if I notice small things like typos, should I go ahead and\n> commit changes myself, or send bug reports here? Either is fine\n> with me. (doing the commits directly seems more efficient)\n\nIt's certainly OK if you commit changes yourself. However, since the \ncode has been branched and all, it's probably better if you discuss it \na bit, either on IRC or on the public-qa-dev list (it's closed to \nsubscription, but feel free to add yourself), beforehand.\n\n-- Olivier\n\n\n\n", "id": "lists-017-10025303"}, {"subject": "Re: [ANN] New generation of the &quot;Markup Validator&quot; release", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>On Monday, Dec 2, 2002, at 18:10 Asia/Tokyo, Gerald Oskoboiny wrote:\n>>BTW, if I notice small things like typos, should I go ahead and commit\n>>changes myself, or send bug reports here? Either is fine with me.\n>>(doing the commits directly seems more efficient)\n>\n>It's certainly OK if you commit changes yourself. However, since the\n>code has been branched and all, it's probably better if you discuss it a\n>bit, either on IRC or on the public-qa-dev list (it's closed to\n>subscription, but feel free to add yourself), beforehand.\n\nHmm. And given that /source/ now points at the wrong branch we should\nprobably try to document the CVS branch practice.\n\nFYI Ger, CVS HEAD is now \"unstable\" and stabilization towards a release\ngoes onto a branch. Currently we're at \"validator-0_6_0-branch\", with 0.6.1\n(CVS Tag \"validator-0_6_1-release) just out the door and, it looks like, a\n0.6.2 release soon to follow.\n\n\n-- \nWhen I decide that the situation is unacceptable for me, I'll simply fork\nthe tree.   I do _not_ appreciate being enlisted into anyone's holy wars,\nso unless you _really_ want to go _way_ up in my  personal shitlist don't\nplay politics in my vicinity.                   -- Alexander Viro on lkml\n\n\n\n", "id": "lists-017-10033563"}, {"subject": "[check] Bug 6", "content": "Terje just pointed this one at me.  I just looked at it.\n\nBj?rn reports an alleged bug.  I'm not convinced, and commented:\n\n\n  The bug report seems to me to be in error.  Or, more specifically, it\n  hinges  on whether unescaped ? is allowed in a QUERY_STRING.  It may be\n  unsafe(?), but is AFAICS nevertheless legal, so ISTM SP is working\n  correctly, and the bug is in the serverside script.\n\n  Lynx agrees:\n\n  [nick@jarl nick]$ lynx -dump -source \n  http://www.bjoernsworld.de/cgi-bin/dtd.pl?bj%f6rn\n  <!ELEMENT foo (bar)>\n  <!---->\n  [nick@jarl nick]$ lynx -dump -source \n  http://www.bjoernsworld.de/cgi-bin/dtd.pl?bj%c3%b6rn\n  <!ELEMENT foo (bar)>\n  <!ELEMENT bar EMPTY>\n\n  If someone can convince me otherwise, I could patch it fairly easily to\n  escape 8-bit URIs, but I fear that could introduce serious bugs when\n  working with a 16-bit charset.  So at the very least I'd have to ask on\n  openjade-devel.\n\nBj?rn is basically saying that OpenSP should have escaped the first URL\nto the second.  AFAICS it would not be wrong to do so, but neither is\nit required.  Who is right?\n\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=66\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10043206"}, {"subject": "Re: [check] Bug 6", "content": "* Nick Kew <nick@webthing.com> wrote:\n>  The bug report seems to me to be in error.  Or, more specifically, it\n>  hinges  on whether unescaped ? is allowed in a QUERY_STRING.  It may be\n>  unsafe(?), but is AFAICS nevertheless legal, so ISTM SP is working\n>  correctly, and the bug is in the serverside script.\n\n>  If someone can convince me otherwise, I could patch it fairly easily to\n>  escape 8-bit URIs, but I fear that could introduce serious bugs when\n>  working with a 16-bit charset.  So at the very least I'd have to ask on\n>  openjade-devel.\n>\n>Bj?rn is basically saying that OpenSP should have escaped the first URL\n>to the second.  AFAICS it would not be wrong to do so, but neither is\n>it required.  Who is right?\n\nI am :-) See section 4.2.2 of XML 1.0,\nhttp://www.w3.org/TR/REC-xml#dt-sysid\n\n[...]\n  * Each disallowed character is converted to UTF-8 [IETF RFC 2279] as\n    one or more bytes.\n\n  * Any octets corresponding to a disallowed character are escaped with\n    the URI escaping mechanism (that is, converted to %HH, where HH is\n    the hexadecimal notation of the byte value).\n\n  * The original character is replaced by the resulting character\n    sequence.\n[...]\n\nThis is a MUST.\n\n\n\n", "id": "lists-017-10051323"}, {"subject": "Re: Uppercase character reference", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1005587"}, {"subject": "Re: [check] Bug 6", "content": "On Wed, 4 Dec 2002, Bjoern Hoehrmann wrote:\n\n> \n> I am :-) See section 4.2.2 of XML 1.0,\n> http://www.w3.org/TR/REC-xml#dt-sysid\n> \n> [...]\n>   * Each disallowed character is converted to UTF-8 [IETF RFC 2279] as\n>     one or more bytes.\n\nI don't see any disallowed character under #2.1 of rfc2396 in your\ntestcase.\n\nApplying the rather different rules you referenced is going to lead to\ndeeper bugs than this alleged one.\n\nYour testcase was declared as iso-8859-1, so escaping as UTF-8 is\nat best perverse, and breaks commonsense.  This is relevant here as\nOpenSP groks SGML (and on the web in general where agents grok\nsome form of HTML).\n\nIf your testcase had declared a 16-bit charset, then AFAICS that rule\nwould lead to more brokenness.\n\nI'm thinking as I write: what happens if we apply perverse-XML rules\nwhen OpenSP's -wxml is in force?  This avoids breaking SGML, but\nI'm not convinced about implementing it.\n\nTerje, how are we applying iconv to incoming documents these days?\nISTM that any document that is converted to utf-8 before being\nprocessed by OpenSP sidesteps this problem altogether (because\niconv does the job).\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10059867"}, {"subject": "Re: [check] Bug 6", "content": "Nick Kew <nick@webthing.com> wrote:\n\n>Terje, how are we applying iconv to incoming documents these days? ISTM\n>that any document that is converted to utf-8 before being processed by\n>OpenSP sidesteps this problem altogether (because iconv does the job).\n\nAll incoming documents are converted to UTF-8 before being fed to OpenSP.\n\n\n\n", "id": "lists-017-10068491"}, {"subject": "Re: [check] Bug 6", "content": "* Nick Kew wrote:\n>> I am :-) See section 4.2.2 of XML 1.0,\n>> http://www.w3.org/TR/REC-xml#dt-sysid\n>> \n>> [...]\n>>   * Each disallowed character is converted to UTF-8 [IETF RFC 2279] as\n>>     one or more bytes.\n>\n>I don't see any disallowed character under #2.1 of rfc2396 in your\n>testcase.\n\nThere is a U+00F6 (LATIN SMALL LETTER O WITH DIAERESIS), URIS most not\ncontain non-ASCII characters, see e.g. section 2.4 of RFC 2396.\n\n>Your testcase was declared as iso-8859-1, so escaping as UTF-8 is\n>at best perverse, and breaks commonsense.\n\nWell, it's a normative requirement of XML 1.0, and actually using UTF-8\nfor disallowed characters in URIs *is* commonsense, you'll find a\nsimilar section in HTML 4.01 (appendix B.2.1), take a look at \n\n  http://www.w3.org/International/O-URL-and-ident.html\n\nThe requirement in XML 1.0 is however only for the system identifier and\nthere are XML processors that implement it the way the recommendation\nwants it, e.g.\n\n  http://www.stg.brown.edu/service/xmlvalid/\n\n\n\n", "id": "lists-017-10076520"}, {"subject": "[check] Status on HEAD... (Templates done, Config code up next", "content": "Terje Bless <link@pobox.com> wrote:\n\n>Ok, HEAD is merged and my template code just landed. Yay! :-)\n\nAnd the Template code now passes all the text cases on /dev/tests/ so it's\nmore or less feature-complete compared to the stable branch, but still\nneeds massive stabilization work and the i18n framework is still AWOL.\n\nHowever, to get complete i18n it's not enough to use the current template\ncode. We have at least 3 distinct areas that need to be i18n-ized. The\ncurrent template code takes care of the basics for the first, normal\noutput, and the two remaining are fatal error messages (which contain\nhard-coded messages and markup) and onsgmls output.\n\nThe latter is still wide-open; there are several ways we could achieve it\nwith no clear deciding factor as yet, and is a massive amount of work. So\nI'm going to leave this off for a while.\n\nThe fatal error handling will probably need real exception handling and a\ngettext-ish i18n framework. This will also be usable for the i18n of the\nnormal output, which is why I've left that unfinished for now.\n\nFor this I have some more or less specific plans, but I need to look closer\nat the alternatives (which i18n library) before they gel completely so I'll\nget back to the specifics later.\n\n\nAll in all this needs to bake a while before I'm ready to continue. So...\n\n\n...Next up is an overhaul of the configuration files and related code. This\nwill break HEAD in a similar manner as the Template code, but will give us\na more consolidated and uniform configuration, strip out a goodly bit of\nhard-coded messages, enable some new features, and make it easier to add\nnew document types++ to the Validator.\n\nUsing Ville's Config::General code, I'm working on one unified config file\nthat specifies, for each known document type (e.g. HTML 4.01 Transitional),\nthe allowed Content-Types, the URI for the \"Valid Foo\" image, the FPI,\nwhether it should be parsed as XML or SGML, etc.\n\nThis will obsolete several of the config files that are basically lookup\ntables and consolidate them into one single file (which is basically a\ncomplex datastructure). It will also require some supporting code in\n\"check\" to provide reverse mappings (e.g. from FPI to \"pretty name\" etc.),\nbut it should result in a net cleanup of the affected code and can cleanly\nbe moved into a module and hidden behind OO magic when we get around to\nm12n the code.\n\n\nDetails left out for brevity; if anyone wants to play, ping me and I'll\nwrite up something more specific on what I'm planning.\n\n\n-- \nOf course we are the good guys! We define what is good and evil. All other\ndefinitions are wrong, and possibly the product of a deranged imagination.\n                                                         -- Stephen Harris\n\n\n\n", "id": "lists-017-10084482"}, {"subject": "[check] Progress on 0.6.2..", "content": "[ CCed to Frederic Schutz, see below ]\n\nSince W3C-folk/Olivier has acted on the \"burning\" issue from 0.6.1, we may\nno longer be that much in need of a 0.6.1 release from a v.w3.org\nperspective. But there are still some open issues that could do with an\nupdate and there are packaging issues that would make a 0.6.2 release\nappropriate IMO.\n\nFirst off, IMO we should invite Frederic Schutz <schutz@mathgen.ch> who is\ndoing the Debian packages to join the QA-Dev list. I don't know how much\ninterest he has in the details of the Validator development and other\nQA-Dev topics, but it's cumbersome to do the packaging discussions in\noff-list email.\n\n\nSecond, based on feedback from Frederic and Ville the plan for the\npostulated 0.6.2 release is as follows:\n\n1. Change /source/ to start off with a blurb about the latest version\n   always being available from http://v.w.org/source/.\n\n2. Make the rest of the page refer _specifically_ to the current release\n   (c.f. the new CVS practice which makes HEAD unsuitable).\n\n3. Create a non-versioned /download/ directory on v.w3.org where RPMs\n   and possibly .debs can live. This directory should not have a static\n   index to avoid linkrot, and apart from symlinks to latest should have\n   versioned file names.\n\n4. Figure out how to get packages from the packagers and into this\n   directory (an upload CGI, HTTP PUT, W3Cer to do the legwork, etc.)\n\n5. More...? What else does Frederic/Ville need to facilitate packaging\n   and distribution of official packages? cf. apt-get etc.\n\nWhen it comes to packaging I have, apart from general good quality, only\none specific concern; namely that I want packages that are not in a\nvendor's standard distribution to be hosted somewhere at w3.org (probably\nv.w3.org). This mainly to make clear that the packages are \"official\"[0]\nand to make them easy to find for users. This does not, of course, prevent\nthe packagers from viewing the v.w3.org copies as a secondary location\nand/or mirror of their own preferred placements. :-)\n\nOnly if this doesn't inconvenience the packagers unduly, of course.\n\nWant to chime in on this Ville, Frederic[1]?\n\n\n[0] - The \"officialness\" is actually also for the benefit of the users\n      so they won't have to worry about whether these are actually\n      supported packages or some hack put together in 5 minutes by an\n      unrelated party.\n\n[1] - Your message will end up in a moderation queue since you're not\n      subscribed yet, Frederic. But the moderator can manually let any\n      replies through, it just takes a little while.\n\n\n\n-- \n\"A plague o' both your houses! I am sped.\" - Mercutio, kinsman to the Prince.\n                   See Project Gutenberg <URL:http://promo.net/pg/> for more.\n\n\n\n", "id": "lists-017-10094661"}, {"subject": "Re: [check] Progress on 0.6.2... yes please", "content": "On Sat, 2002-12-07 at 07:34, Terje Bless wrote:\n\n> Since W3C-folk/Olivier has acted on the \"burning\" issue from 0.6.1, we may\n> no longer be that much in need of a 0.6.1 release from a v.w3.org\n> perspective. But there are still some open issues that could do with an\n> update and there are packaging issues that would make a 0.6.2 release\n> appropriate IMO.\n\nAs you may have noticed, I fixed an old bug in checklink today, which\ncaused it to recurse *everywhere* if the submitted URI didn't have a\nslash after the hostname, eg. <http://validator.w3.org>.  I also tested\nit by running against v.w.o and fixed some broken links while at it.\n\nSince checklink is distributed with validator, I'd like to see 0.6.2\nsoon, as well as live on v.w.o.\n\nAll changes to checklink are at the moment in the 0_6_0 branch of\nvalidator, HEAD is outdated.  There's no \"experimental\" version of\nchecklink ATM, so I prefer to keep the newest version in a branch that\nis closest to the running production release.  Checklink needs some\nrefactoring, though, the code is actually pretty hairy; that will most\nlikely happen in HEAD (or wherever the dev branch is) sometime.\n\n> 5. More...? What else does Frederic/Ville need to facilitate packaging\n>    and distribution of official packages? cf. apt-get etc.\n\nAs discussed before, this is not a \"must have\", we can generate apt\nindexes offsite, they're transferable.\n\n> When it comes to packaging I have, apart from general good quality, only\n> one specific concern; namely that I want packages that are not in a\n> vendor's standard distribution to be hosted somewhere at w3.org (probably\n> v.w3.org). This mainly to make clear that the packages are \"official\"[0]\n> and to make them easy to find for users. This does not, of course, prevent\n> the packagers from viewing the v.w3.org copies as a secondary location\n> and/or mirror of their own preferred placements. :-)\n> \n> Only if this doesn't inconvenience the packagers unduly, of course.\n\nI'm fine with this.\n\nOh, and a cleanup suggestion: could the following files be 'cvs rm'd\nfrom dev.w3.org; they're outdated and add unnecessary confusion in the\nvalidator tarballs.  Remember, \"cvs rm\" doesn't *delete* the files,\nthey're still accessible in CVS' Attic dirs, and can be easily restored\nif need be.\n\n   httpd/cgi-bin/: traceroute, p3p, referers, LinkChecker.pl\n   htdocs/:        p3p.html, favlets.html\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10105151"}, {"subject": "Please update checklink on v.w.", "content": "On Sun, 2002-12-08 at 20:32, Ville Skytt? wrote:\n\n> As you may have noticed, I fixed an old bug in checklink today, which\n> caused it to recurse *everywhere* if the submitted URI didn't have a\n> slash after the hostname, eg. <http://validator.w3.org>.  I also tested\n> it by running against v.w.o and fixed some broken links while at it.\n> \n> Since checklink is distributed with validator, I'd like to see 0.6.2\n> soon, as well as live on v.w.o.\n\nHmm, maybe I didn't put it prominently enough here: the current (3.06)\nchecklink on v.w.o has some embarrassing bugs which have been fixed in\nthe newest CVS version (3.6.2.3, in validator-0_6_0-branch).  Could\nsomeone update it?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10115365"}, {"subject": "Re: Please update checklink on v.w.", "content": "Le ven 13/12/2002 ? 18:23, Ville Skytt? a ?crit :\n> Hmm, maybe I didn't put it prominently enough here: the current (3.06)\n> checklink on v.w.o has some embarrassing bugs which have been fixed in\n> the newest CVS version (3.6.2.3, in validator-0_6_0-branch).  Could\n> someone update it?\n\nDone.\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-10123337"}, {"subject": "Re: Tes", "content": "http://lists.w3.org/Archives/Public/public-w3c-talk-china/\n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1012564"}, {"subject": "Re: [check] Progress on 0.6.2; and a new addition. :", "content": "With any kind of luck, Frederic should be receiving two copies of this. :-)\n\n\nSince Olivier is unavailable for while list moderator issues are mostly on\nhold until he returns -- hence your eternally queued message Frederic --\nbut Dom has added Frederic to the list so future messages should avoid\nmoderation delay.\n\nFor those that don't know, Frederic Shutz <schutz@mathgen.ch> has\nvolunteered to be our Debian packager. Welcome on board Frederic!\n\n\nVille Skytt? <ville.skytta@iki.fi> wrote:\n\n>Oh, and a cleanup suggestion: could the following files be 'cvs rm'd\n>from dev.w3.org; they're outdated and add unnecessary confusion in the\n>validator tarballs.  Remember, \"cvs rm\" doesn't *delete* the files,\n>they're still accessible in CVS' Attic dirs, and can be easily restored\n>if need be.\n>\n>httpd/cgi-bin/: traceroute, p3p, referers, LinkChecker.pl\n>htdocs/:        p3p.html, favlets.html\n\nGo ahead and \"cvs rm\" these. I checked with Dom on IRC and as far as we\ncould tell, only /traceroute was ever publically exposed -- and, as we all\nknow, \"Cool URIs Don't Change\" :-) -- and we need to make some changes to\naccount for that on v.w3.org, but these can be specific to there and don't\nneed to be in CVS. The rest are not (or no longer) used.\n\nDom: cf. our discussion on IRC:\n\n  Could you dump the \"Alice doesn't live here anymore\" HTML from\n  /traceroute, save it to /usr/local/validator/htdocs/traceroute.html,\n  and remove the ScriptAlias for /traceroute from httpd.conf?\n\n\n\nOh, and about progress towards 0.6.2; the big issue for 0.6.2 -- the GET\nvs. POST thing -- has been dealt with so I'm in no particular hurry to get\na new version out the door. But we still have quite a few issues that were\naddressed after 0.6.1 was released and we have yet to nail down a good way\nto distribute the \"binary\" packages.\n\nI've created a 0.6.2 Release meta-bug in Bugzilla[0] (Bug #121). Please\nthink carefully about issues remaining that you want addressed for 0.6.2,\ncreate bugs in Bugzilla for them, and add them as blockers for the\nmeta-bug.\n\nAs a timing guide, I want to be ready to make a 0.6.2 release before the\nend of the year (even if we choose to wait until later to actually do the\nrelease) that is sufficiently solid that we won't need a 0.6.3 release, and\nwhich deals with debs/rpms in a sufficiently sane manner that I won't walk\naround feeling permanently guilty about not doing enough to support\nFrederic and Ville in their packaging efforts. :-|\n\n\n[0] - <http://www.w3.org/Bugs/Public/show_bug.cgi?id=121>\n\n\nOh, and speaking of availability; I'll probably be mostly-offline from\nFriday 20th until Friday 27th. I'll be off visiting the in-laws -- also\nknown as \"Being A Good Boyfriend\" :-) -- with metered ISDN dialup as the\nonly Internet access. IOW, do not expect replies to email in this period.\n\n\n-- \nOf course we are the good guys! We define what is good and evil. All other\ndefinitions are wrong, and possibly the product of a deranged imagination.\n                                                         -- Stephen Harris\n\n\n\n", "id": "lists-017-10131221"}, {"subject": "Type of error", "content": "In the process of being more educative and not making people afraid, \nI said it in the past, but I don't remember if Terje thought it would \nbe difficult to implement :)\n\nWhen we validate a Webpage, we have the number of errors which is \ngiven, but not the number of errors type that have been made.\n\nFor example if the tag ALT has been forgotten in the page 43 times, \nit means that the same error come again and again :)\n\nSo it could be modified in that way:\n\nErrors: 80 (3 types of errors)\nor\nErrors: 80 (43 for ALT, 34 for TYPE, 3 no attributes \"HEIGHT\")\n\n\nIn the EARL report, it's quite easy with an XSLT, but in the HTML output?\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-10142777"}, {"subject": "Re: Type of error", "content": "On Sun, 29 Dec 2002, Karl Dubost wrote:\n\n> In the process of being more educative and not making people afraid, \n> I said it in the past, but I don't remember if Terje thought it would \n> be difficult to implement :)\n\nThat wouldn't be too hard.  It's a pretty standard Perl technique.\n\n> For example if the tag ALT has been forgotten in the page 43 times, \n> it means that the same error come again and again :)\n> \n> So it could be modified in that way:\n> \n> Errors: 80 (3 types of errors)\n> or\n> Errors: 80 (43 for ALT, 34 for TYPE, 3 no attributes \"HEIGHT\")\n\nThe first of those is straightforward, though I'd prefer something\nlike \"80 instances of 3 errors\".  The second would require us to devise\nsome appropriate abbreviation for every each error message, and is\nlikely to lead to (at best) confusing reports, so I wouldn't recommend\ntrying it.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10149966"}, {"subject": "[check] Beta 3 Relnotes..", "content": "I'm about to tag Beta 3 in CVS. Below are proposed release notes.\n\n\nThe big issue that needs discussion is the XML Output. Stay or go?\n\nI have an updated version\n<URL:http://mail.tj.unn.no/check?uri=www.vir.si;output=xml> that includes a\nDocument Type Declaration and an XSLT Stylesheet (thanks to Nick). I'm more\ncomfortable comitting to supporting this version -- allthough it's most\ndefinitely labelled \"Beta\"! -- considering it won't likely be very\ninteresting to most people if I get the SOAP interface in in 0.7.0.\n\nBut my \"liability\" on this thing is zero so y'all W3Cers are invited to\n\"veto\" it's release if you feel it necessary. I'm still somewhat ambivalent\nabout it. The XML output has sorta just grown happenstance instead of being\n\"designed\" as such, so while I'm reasonably comfortable with it's current\nstate, experience suggests there are pitfalls lurking in there too.\n\nUnless some discussion happens, it will be released by default!\n\n\nPre-Release Notes -- still in need of some grammar and spelling love:\n\n-- cut here\nThe following changes and new features:\n\n* The error message when the configuration file is not found is now\n  much clearer.\n* The XML Output is now much improved, and nominally at Beta status.\n* Many spelling, captialization, and grammar fixes.\n* The DOCTYPE override will now replace the orginal DOCTYPE instead\n  of always inserting it at the beginning fo the file.\n* Sample code in output and documentation has been updated.\n* More error messages now take into account whether file upload or\n  normal processing was done.\n* Output layout has changed to adress usability concerns.\n* Many POST requests are now redirected to a GETable URL when possible.\n* Perl version 5.6.0 is now the minimum required version.\n* The jump links in output are now context sensitive.\n* We're now excrisiatingly up fromt about SP's limitations with XML.\n* More links to external resources (thanks to Liam Quinn and the WDG).\n* We now allow the pedantically correct /referrer as well as /referer. :-)\n* Many output-escaping fixes and entity reference related fixes.\n\n\n\n\nID Result    Summary\n== =========\n=================================================================\n 1 FIXED     XHTML 1.1/Basic 1.0 missing from detailed.html\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0066.html\n\n 2 FIXED     ISO-8859-3 mislabelled on detailed.html.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0071.html\n\n 3 FIXED     Results from Advanced form are not GETable.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0069.html\n\n 5 FIXED     No Revalidate button on files without doctype [...].\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0072.html\n\n 7 FIXED     Fatal Error: No DOCTYPE specified!\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0073.html\n \n13 FIXED     Caveat about limited XML support missing.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0075.html\n\n15 FIXED     Wrong MIME type for SVG.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0083.html\n\n16 FIXED     Config filename in error message is wrong.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0089.html\n\n17 FIXED     Bad style on invalid results page.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0094.html\n\n19 FIXED     \"page NOT valid\" should be \"page not valid\".\n20 FIXED     \"this icon\" is unclear after position of icon changed.\n21 FIXED     Find alternate way to handle buggy CSS implementations.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0077.html\n\n23 FIXED     Missing URI/File gives bad error message.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0159.html\n\n25 INVALID   preparse() called twice per request\n\n40 INVALID   Charset defaulting behaviour.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0190.html\n\n41 FIXED     Trailing slash on /check/ breaks relative links.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0197.html\n\n46 FIXED     \"would validate\" too hard to spot.\n47 FIXED     Output refers to \"Strict\" for a \"Transitional\" file.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0070.html\n\n57 FIXED     Validator requires perl >= 5.6.0\n\n58 FIXED     Doctype override always inserts to first line\n\n59 FIXED     Jump to bar has always same links\n\n64 FIXED     Validator does not escape & properly.\n   http://lists.w3.org/Archives/Public/www-validator/2002Oct/0224.html\n-- cut here\n\n\n\n-- \n> I suggest you attend some sort of anger management class....\nThat's where you learn to upset the PHBs? -- Peter da Silva\n\n\n\n", "id": "lists-017-10192258"}, {"subject": "Re: New Public mailing list - publicir", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1019460"}, {"subject": "[logvalidator] Online logvalidator ", "content": "Damn, I just had an idea :)\n\nThe logvalidator is (unfortunately, libwww is a pain sometimes...) not \nso easy to install, and since I believe it's a cool service, I'd be \ntempted to create an online version : people would upload a log file \n(could be big, though...), fill in a few necessary fields, and voila!\n\n(or maybe I should package libwww and all necessary libs with the \nlogvalidator library...)\n\nBesides, that'd be a replacement for a recursive validator, which we're \nnot likely to provide soon.\n\nThoughts? Worth working on?\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-10205056"}, {"subject": "Re: Maintaining sgmlli", "content": "Nick,\n\nI think this is a good question, and I believe this is an important \nproblem that I (or Dom), as \"staff contact\" for the qa dev projects, \nshould handle.\n\nI Need, however, to know more about the situation before going forward.\n\nOn Wednesday, Oct 30, 2002, at 11:19 Asia/Tokyo, Nick Kew wrote:\n> If we were to run a CVS server for [sg|x]ml-lib on qa-dev\n\nI believe we run a CVS server for sgml-lib, at least, on dev.w3.org\nhttp://dev.w3.org/cvsweb/validator/htdocs/sgml-lib/\n\nAre we talking about the same thing, and are you suggesting we move \nthis to qa-dev?\nIf \"yes\", then I think it should remain on dev, see below.\n\n\n> , I wonder\n> if it would be possible for someone to crack a whip amongst the WGs\n> to ask them to contribute their work\n\nIf we want the WGs to contribute (which I think is a good idea, BTW), \nthen we should use dev, where all the staff contacts for WGs have write \naccess.\n\nStaff contacts and chairs should probably be our primary target if we \nare to ask WG to cooperate (more) closely with us about DTD and schemas \nreleases.\n\n\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-10212318"}, {"subject": "Re: [logvalidator] Online logvalidator ", "content": "On Tue, 2002-11-05 at 09:24, Olivier Thereaux wrote:\n\n> The logvalidator is (unfortunately, libwww is a pain sometimes...) not \n> so easy to install,\n\nHmm, what do you mean?  \"perl -MCPAN -e shell\", \"install LWP\" or use ppm\nwith ActivePerl or use the pre-packaged version from an OS vendor?\n\n> and since I believe it's a cool service, I'd be \n> tempted to create an online version : people would upload a log file \n> (could be big, though...), fill in a few necessary fields, and voila!\n\nSounds kind of neat, but I wouldn't feel comfortable uploading my\nserver's logs to a public service.  If I'd host such a service myself, I\nthink it could be useful.\n\n> (or maybe I should package libwww and all necessary libs with the \n> logvalidator library...)\n\nBrr...\n\n> Besides, that'd be a replacement for a recursive validator, which we're \n> not likely to provide soon.\n> \n> Thoughts? Worth working on?\n\nWhy not, especially because of the \"recursive validator\" idea.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10220213"}, {"subject": "Re: [logvalidator] Online logvalidator ", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>On Tue, 2002-11-05 at 09:24, Olivier Thereaux wrote:\n\nArgh! I /knew/ there was something I'd forgotten to reply to. :-(\n\n>>The logvalidator is (unfortunately, libwww is a pain sometimes...) not\n>>so easy to install,\n>\n>Hmm, what do you mean?  \"perl -MCPAN -e shell\", \"install LWP\" or use ppm\n>with ActivePerl or use the pre-packaged version from an OS vendor?\n\nI think Olivier means that LogValidator isn't too easy to install; it has\nsome dependancies and it's partially implemented as a module and not a\n\"script\". LWP is merely \"moderately hard\" to install. :-)\n\n\n>>and since I believe it's a cool service, I'd be tempted to create an\n>>online version : people would upload a log file (could be big,\n>>though...), fill in a few necessary fields, and voila!\n>\n>Sounds kind of neat, but I wouldn't feel comfortable uploading my\n>server's logs to a public service.  If I'd host such a service myself, I\n>think it could be useful.\n\nI agree. This is more a tool for use behind a firewall and on the internet\nthen on the Internet or provided by the W3C. Even though I'm sure there\nwould be interest for it, it encourages unsafe practices and careless\ntreatement of sensitive data.\n\n\n>>Besides, that'd be a replacement for a recursive validator, which we're\n>>not likely to provide soon.\n>>\n>>Thoughts? Worth working on?\n>\n>Why not, especially because of the \"recursive validator\" idea.\n\nAlways worth working on if you can spare the time; especially if a localy\ninstallable version could be produced. But for a recursive Validator, I\nthink the time would be better spent on actually producing a recursive\nValidator. :-)\n\nAnd it isn't necessarily that far off. Depending on when we decide to\nfeature freeze 0.7.0 it could go in as early as that or in the next version\nafter 0.7.0 (1.0?). Of course, it may also not make it in this side of the\nheat death of the universe... :-)\n\n-- \n\"You gonna take advice from somebody who slapped DEE BARNES?!\" -- eminem\n\n\n\n", "id": "lists-017-10228519"}, {"subject": "Re: [logvalidator] Online logvalidator ", "content": "On Sun, 2002-11-10 at 20:10, Terje Bless wrote:\n\n> >>The logvalidator is (unfortunately, libwww is a pain sometimes...) not\n> >>so easy to install,\n> >\n> >Hmm, what do you mean?  \"perl -MCPAN -e shell\", \"install LWP\" or use ppm\n> >with ActivePerl or use the pre-packaged version from an OS vendor?\n> \n> I think Olivier means that LogValidator isn't too easy to install; it has\n> some dependancies and it's partially implemented as a module and not a\n> \"script\". LWP is merely \"moderately hard\" to install. :-)\n\nYep, but libwww was explicitly mentioned to be \"a pain sometimes\"...\n\nAnyway, IMO it's the configuration of the LogValidator that is a bit\npainful; installation is just the usual \"perl Makefile.PL && make\ninstall\".\n\nPerhaps the LogValidator (and Validator, checklink etc) could be\ndistributed via CPAN so eg. CPAN.pm and friends could take care of the\ndependencies?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10238294"}, {"subject": "Re: [logvalidator] Online logvalidator ", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>Perhaps the LogValidator (and Validator, checklink etc) could be\n>distributed via CPAN so eg. CPAN.pm and friends could take care of the\n>dependencies?\n\nFor Validator, I plan to look into that when I modularize it.\n\n\n\nBTW, Ville, I plan to make an update of :8001 ASAP. Is that ok with the\ncurrent state of checklink?\n\n\n-- \n\"Frailty, thy name is woman!\"                    - Hamlet, Prince of Denmark.\n                   See Project Gutenberg <URL:http://promo.net/pg/> for more.\n\n\n\n", "id": "lists-017-10246475"}, {"subject": "Re: [check] Beta 3 Relnotes..", "content": "All,\n\nOn Monday, Nov 4, 2002, at 04:18 Asia/Tokyo, Terje Bless wrote:\n> I'm about to tag Beta 3 in CVS. Below are proposed release notes.\n>\n> The big issue that needs discussion is the XML Output. Stay or go?\n\nWe have discussed this on IRC, but for the record, I'd want at least \nthe EARL and n3 (and of course HTTP) to stay. And I think it's OK to \nkeep the XML output, even if this means we have to keep it as a beta \nfeature in a stable product.\n\nI'm quite disappointed by the relative lack of feedback on these \nvarious outputs, but I think we should proceed.\n\n\n> Unless some discussion happens, it will be released by default!\nFine.\n\n\n> Pre-Release Notes -- still in need of some grammar and spelling love:\n> * Many spelling, captialization, and grammar fixes.\ns/capti/capit/\n\n> * We're now excrisiatingly up fromt about SP's limitations with XML.\nex-what? My dear friend dict -v doesn't know this either, it seems :)\nand s/fromt/front/ I assume.\n\nVery good work done with this beta so far, I'm proud of being part of \nthis.\n\nCheers,\n-- \nOlivier\n\n\n\n", "id": "lists-017-10254685"}, {"subject": "Re: [logvalidator] Online logvalidator ", "content": "On Mon, 2002-11-11 at 03:17, Terje Bless wrote:\n\n> BTW, Ville, I plan to make an update of :8001 ASAP. Is that ok with the\n> current state of checklink?\n\nYes.  I have some local changes that I won't apply just yet (trying to\nget Referer sent properly, and respecting robots.txt).  But I'm starting\nto feel that checklink needs refactoring and modularization as well, the\ncode is unnecessarily hairy at the moment.  When the validator\nmodularization work begins, let's do it for checklink at the same time\n(as well as some integration, at least in the UI).\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10262570"}, {"subject": "Re: Some issues with the IRI document [NFCsecurity09", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1026529"}, {"subject": "Re: [logvalidator] Online logvalidator ", "content": "On Saturday, Nov 9, 2002, at 20:33 Asia/Tokyo, Ville Skytt? wrote:\n> On Tue, 2002-11-05 at 09:24, Olivier Thereaux wrote:\n>\n>> The logvalidator is (unfortunately, libwww is a pain sometimes...) not\n>> so easy to install,\n>\n> Hmm, what do you mean?  \"perl -MCPAN -e shell\", \"install LWP\" or use \n> ppm\n> with ActivePerl or use the pre-packaged version from an OS vendor?\n\nInteresting. Being a \"download, make, make install\" person, I confess \nmy ignorance about CPAN semi-automated mechanisms. Really interesting, \nI should look at this and update the doc.\n\nI also plan to make it CPAN package (I believe it's CPAN compliant, or \nalmost, already), especially if it helps installation.\n\n> Sounds kind of neat, but I wouldn't feel comfortable uploading my\n> server's logs to a public service.\n\nYes, I understand this. I've been thinking about it, and even though \nthere would be a few \"tricks\" to make it look safe (upload via https, \nclear statement of our policy, etc), it doesn't look *quite* right.\n\n\n>> (or maybe I should package libwww and all necessary libs with the\n>> logvalidator library...)\n>\n> Brr...\n\nI meant \"make available in the same repository\", not in the same \npackage :)\nBut that may be pointless anyway.\n\n\n>> Thoughts? Worth working on?\n> Why not, especially because of the \"recursive validator\" idea.\n\nGiven the answers (thanks!), I probably should rather work on the \ninstall documentation and help on a recursive validator.\n\nThanks.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-10270104"}, {"subject": "Re: [logvalidator] Online logvalidator ", "content": "On Mon, 2002-11-11 at 10:20, Olivier Thereaux wrote:\n\n> > Hmm, what do you mean?  \"perl -MCPAN -e shell\", \"install LWP\" or use \n> > ppm\n> > with ActivePerl or use the pre-packaged version from an OS vendor?\n> \n> Interesting. Being a \"download, make, make install\" person, I confess \n> my ignorance about CPAN semi-automated mechanisms. Really interesting, \n> I should look at this and update the doc.\n> \n> I also plan to make it CPAN package (I believe it's CPAN compliant, or \n> almost, already), especially if it helps installation.\n\nI believe it is, IIRC I've sent some patches to address this in the past\nmyself :)  But the tough part is the configuration file, I don't know\nhow that should be treated in a CPAN package.\n\nAnyway, the really nice thing about all the above automated mechanisms\nis the ability to track dependencies and install them on demand.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10279370"}, {"subject": "Forst prototype XML Validation Webservic", "content": "I've put up the XML Validator at\n<URL:http://qa-dev.w3.org:8888/>\n\nThis is based on the existing experimental service at valet, but\nhas been updated to use Xerces 2.1 and I've made some other\nlong-overdue improvements.  It's definitely alpha-quality,\nand liable to fall about in a heap just now.\n\nQuestions:\n  * Are people happy with the general format of this service?\n  * If so, shall I put the code into qa-dev cvs at this point?\n  * If not, what should be changed?\n  * Has anyone put any XML catalogue stuff onto qa-dev?\n    It'll run a lot faster and more efficiently if it can\n    resolve entities locally!\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10286969"}, {"subject": "we're going to have an official bugzill", "content": "OK, so we're going to have an official (i.e supported) public bugzilla \nat W3C.\n\nWe (systems) were on a meeting today, and the vicious circle (no public \nbugzilla because no-one to use it, and no-one to use it because there \nis no public bugzilla) was broken when I said that yes, we really \nreally needed one, besides we're already using one.\n\nTerje will send me the files from his instance, and I will install it \non our CGI box. It will be proxied from http://www.w3.org/Bugs/ \n(currently 403, we're working on it).\n\nThanks a lot to Terje for hosting the temp service, by the way...\n-- \nOlivier\n\n\n\n", "id": "lists-017-10294530"}, {"subject": "Re: we're going to have an official bugzill", "content": "Done! (hopefully working fine).\n\nhttp://www.w3.org/Bugs/Public/\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-10302199"}, {"subject": "Re: we're going to have an official bugzill", "content": "* Olivier Thereaux wrote:\n> We (systems) were on a meeting today, and the vicious circle (no public\n> bugzilla because no-one to use it, and no-one to use it because there\n> is no public bugzilla) was broken when I said that yes, we really\n> really needed one, besides we're already using one.\n\nMay anyone create an account there? Is the installation limited to the\nthree products already maintained or may other tools also use it? I'd\nlike to use it for the W3C CSS Validator.\n\n\n\n", "id": "lists-017-10309873"}, {"subject": "Re: we're going to have an official bugzill", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>Done! (hopefully working fine). http://www.w3.org/Bugs/Public/\n\nOutstanding, thanks Olivier!\n\nBTW, could we quickly get some sort of consensus on what policy to have for\nthis; in re who gets to have accounts and what \"products\" are hosted there\n(cf. Bj?rn's message)?\n\nI'd say \"Public\" means _Public_ and we should let everyone at it to file\nbugs; if we run into trouble with people spamming it or closing open issues\netc. that's soon enough to start looking at locking it down a bit.\n\nAnd hosting the CSS Validator bug database there seems the natural fit to\nme (regardless of whether this is \"QA Run\" or \"W3C Run\", the CSS Validator\nfalls into both categories). This would also mean we could have MarkUp\nValidator bugs depend on CSS Validator fixes (*chough*DOCTYPEs*chough*) and\nvice versa.\n\nThe sooner that gets set up the better IMO, and the sooner Bugzilla's\nexistance is announced to www-validator likewise!\n\n-- \nBy definition there is _no_way_ any problem can be my fault. Any problems\nyou think you can find in my code are in your imagination. If you continue\nwith such derranged imaginings then I may be forced to perform corrective\nbrain surgery... with an axe!                            -- Stephen Harris\n\n\n\n", "id": "lists-017-10317438"}, {"subject": "Re: we're going to have an official bugzill", "content": "On Monday, Nov 18, 2002, at 05:04 Asia/Tokyo, Terje Bless wrote:\n> BTW, could we quickly get some sort of consensus on what policy to \n> have for\n> this; in re who gets to have accounts and what \"products\" are hosted \n> there\n> (cf. Bj?rn's message)?\n\nNow that W3C has a public bugzilla running there is no reason why it \nshouldn't be used by other groups than QA (this is the reason why I \nwanted a W3C bugzilla rather than a QA bugzilla...).\n\n\n> I'd say \"Public\" means _Public_ and we should let everyone at it to \n> file\n> bugs; if we run into trouble with people spamming it or closing open \n> issues\n> etc. that's soon enough to start looking at locking it down a bit.\n\nThat's the current config as far as I can tell, and (even though I'm a \nlittle worried) I guess that's fine, indeed.\n\n> And hosting the CSS Validator bug database there seems the natural fit \n> to\n> me\n\nDitto.\n\n>  sooner that gets set up the better IMO, and the sooner Bugzilla's\n> existance is announced to www-validator likewise!\n\nYes, I had \"something to figure out\" before the bugzilla goes official, \nbut I can't remember what it was... ;)\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-10327256"}, {"subject": "Re: [check] Beta 3 Relnotes..", "content": "* Olivier Thereaux wrote:\n> We have discussed this on IRC, but for the record, I'd want at least\n> the EARL and n3 (and of course HTTP) to stay. And I think it's OK to\n> keep the XML output, even if this means we have to keep it as a beta\n> feature in a stable product.\n>\n> I'm quite disappointed by the relative lack of feedback on these\n> various outputs, but I think we should proceed.\n\nThat's due to lack of documentation and the non-official nature of these\nfeatures.\n\n\n\n", "id": "lists-017-10335824"}, {"subject": "Re: First prototype XML Validation Webservic", "content": "On Wed, 13 Nov 2002, Nick Kew wrote:\n\n> I've put up the XML Validator at\n> <URL:http://qa-dev.w3.org:8888/>\n\nThis has now been updated:\n  - fixed bug in mod_xml's Xalan-1.4 bindings that was causing\n    larger reports in HTML and EARL formats to break down.\n  - Added web browser based validator.\n\nIf noone on qa-dev is interested in this, I'd now be comfortable\nannouncing it to a wider audience on www-validator.  Is there\nan official policy concerning where I can/can't announce\nsomething like this?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10343179"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1034334"}, {"subject": "[check] Progress Towards Release..", "content": "Looks like Beta 3 is more or less solid, judging from the feedback coming\nin after its release. Given this is the case (as opposed to just apathy\n;D), this is probably the most solid release of Validator to date. I have\nonly one open issue from www-validator (which is less then I've had, ever)\nand mainly packaging and release related issues in Bugzilla.\n\nThis is mostly thanks to the contributions from Ville, Nick, and Liam; the\nexcellent support from Olivier; and the fine testing provided by Bjoern.\nMany many thanks all of you!\n\nIn light of that I think it's time to push out a final release.\n\nI have some final cleanup to do (change the \"What's New\", rip stuff out of\ntodo.html, etc.), but other then that I think I'll tag the final release in\nCVS ASAP so we can begin packaging and release, with the final update of\n:80 tomorrow or Tuesday.\n\nPlease let me know either way whether you agree with this asessment!\n\n\n\nI plan to make 0.6.0 into a branch in CVS once we tag the final version.\nThat way we can keep bug fixing etc. on that branch and keep the trunk for\nfuture development. This will break the automatic generation of the\ntarball, but since we're now making real releases we can do that manually.\n\nIf anyone feels the need for a quick rundown of how to work with branches\nin CVS I can put together a mini-howto for it. Let me know!\n\n\nBTW, one of the first thing to go into HEAD once the release is made is\nprobably new configuration parser code from Ville. Concurrently with that\nwe may take the opportunity to rearrange the directory layout in CVS and\nprune some old gunk that isn't needed any more.\n\nSince you've done a little thinking on this Ville, perhaps you want to do a\nlittle braindump we can use as a basis for the reorg?\n\n-- \nOf course we are the good guys! We define what is good and evil. All other\ndefinitions are wrong, and possibly the product of a deranged imagination.\n                                                         -- Stephen Harris\n\n\n\n", "id": "lists-017-10351067"}, {"subject": "Re: First prototype XML Validation Webservic", "content": "At 0:32 +0000 2002-11-23, Nick Kew wrote:\n>On Wed, 13 Nov 2002, Nick Kew wrote:\n>\n>  > I've put up the XML Validator at\n>  > <URL:http://qa-dev.w3.org:8888/>\n\nvery interesting and nice interface\n\nBe careful to the auto validation things. Just to avoid trolls.\n\nhttp://validator.w3.org:8001/check?uri=http://qa-dev.w3.org:8888/val.so\n\nI don't see any problems, it's nice to have this output. It would be \ngood to have a detailed explanation of what we get in return, type of \nmessages, type of errors, DTDs if any etc.\n\nA manual :p\n\nThe output seems to come back on one line (maybe it's my terminal which sucks)\nif it's the case, maybe a formatted output would be better.\n\nFor example\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<rdf:RDF\nxmlns:r=\"modxml:validator#0.1\"\nxmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\nxmlns:val=\"http://valet.webthing.com/xmlns/validator.rdf#\"\nxmlns:earl=\"http://www.w3.org/2001/03/earl/1.0-test#\">\n\n<rdf:Description rdf:ID=\"testcase\">\n<earl:testCase rdf:resource=\"http://www.w3.org/XML/#\"/>\n<val:testmode>valid,namespace,schema</val:testmode>\n</rdf:Description>\n\n<earl:Assertor rdf:ID=\"xml-val-svc\">\n<earl:name>W3C XML Validation Service</earl:name>\n<earl:testMode rdf:resource ....\n\n.... etc\n\nif you put Earl as the defaut namespace it will make the syntax a bit \nmore readable :)\n\nxmlns=\"http://www.w3.org/2001/03/earl/1.0-test#\"\n\n\n\nGreat.\nIf I have forgotten things I will come back.\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-10361002"}, {"subject": "Re: [check] Progress Towards Release..", "content": "Terje Bless <link@pobox.com> wrote:\n\n>BTW, one of the first thing to go into HEAD once the release is made is\n>probably new configuration parser code from Ville. Concurrently with\n>that we may take the opportunity to rearrange the directory layout in\n>CVS and prune some old gunk that isn't needed any more.\n\nIn particular, I'm thinking of pruning sgml-lib by removing (cvs rm) the\nfollowing directories:\n\n  cougar/\n  mod/\n  old/\n  pro/\n  sp-1.3/\n  spyglass/\n  CR-MathML2-20001113/\n  CR-SVG11-20020430/\n  PR-html40-19990824/\n  PR-MathML2-20010108/\n  PR-smil20-20010605/\n  PR-SVG-20010719/\n  PR-xhtml1-19990824/\n  PR-xhtml1-19991210/\n  WD-html-in-xml-19981205/\n  WD-html-in-xml-19990224/\n  WD-html-in-xml-19990304/\n  WD-html40-970708/\n  WD-html40-970917/\n  WD-xhtml1-19991124/\n\n...and these files...\n\n  catalog\n  html-0.dtd\n  html-0s.dtd\n  html-1.dtd\n  html-1s.dtd\n  html-2.1e.dtd\n  html-3-as.dtd\n  html-3.2.1996-08-15.dtd\n  html-3.2.1996-09-09.dtd\n  html-3.2.dtd\n  html-3.dtd\n  html-3s.dtd\n  html-970421.decl\n  html-970421.dtd\n  html-cougar.dtd\n  html-hj.dtd\n  html-hjs.dtd\n  html-i18n.decl\n  html-icons.sgml\n  html-latin.sgml\n  html-math.sgml\n  html-mcom.dtd\n  html-mcoms.dtd\n  html-old.decl\n  html-old2.decl\n  html-orig.decl\n  html-s.dtd\n  html-sq.dtd\n  html.dtd\n  htmli.decl\n  ie30-s.dtd\n  ie30.dtd\n  ie30tables.dtd\n  iehtml-s.dtd\n  iehtml.dtd\n  ietables.dtd\n  ISOlat1.ent\n  ISOlat1.sgml\n  mathml.dcl\n  mathml.soc\n  oreilly-additional.entities\n  oreilly-draft-table.elements\n  oreilly-html-relaxed.dtd\n  oreilly-html.dtd\n  oreilly-rfc1866.dtd\n  smil.dcl\n  smil.soc\n  spec.dtd\n  svg.dcl\n  svg.soc\n  xhtml.dcl\n  xhtml.soc\n\n-- \n\"You gonna take advice from somebody who slapped DEE BARNES?!\" -- eminem\n\n\n\n", "id": "lists-017-10370529"}, {"subject": "Re: [check] Progress Towards Release..", "content": "Terje Bless <link@pobox.com> wrote:\n\n>Terje Bless <link@pobox.com> wrote:\n>\n>>BTW, one of the first thing to go into HEAD once the release is made is\n>>probably new configuration parser code from Ville. Concurrently with\n>>that we may take the opportunity to rearrange the directory layout in\n>>CVS and prune some old gunk that isn't needed any more.\n>\n>In particular, I'm thinking of pruning sgml-lib by removing (cvs rm) the\n>following directories:\n\nWhich, BTW, would leave the sgml-lib directory looking like this:\n\n  ISO-HTML/\n  REC-html40-19980424/\n  REC-html40-971218/\n  REC-html401-19991224/\n  REC-MathML2-20010221/\n  REC-smil-19980615/\n  REC-SVG-20010904/\n  REC-xhtml-basic-20001219/\n  REC-xhtml1-20000126/\n  REC-xhtml1-20020801/\n  REC-xhtml11-20010531/\n  UPD-MathML2-20021015/\n\n  xhtml-math-svg-20020430.dtd\n  xhtml-math-svg-20020809.dtd\n  xhtml-math-svg-flat-20020430.dtd\n  xhtml-math-svg-flat-20020809.dtd\n  AppleHelp1.0.dtd\n  spec.dtd\n  sgml.dcl\n  sgml.soc\n  xml.dcl\n  xml.soc\n\nMuch nicer. :-)\n\n-- \n\"I don't mind being thought of as a badguy,\n but it /really/ annoys me to be thought of\n as an *incompetent* badguy!\" -- John Moreno\n\n\n\n", "id": "lists-017-10379884"}, {"subject": "Re: [check] Progress Towards Release..", "content": "On Mon, 2002-11-25 at 07:20, Terje Bless wrote:\n\n> >In particular, I'm thinking of pruning sgml-lib by removing (cvs rm) the\n> >following directories:\n> \n> Which, BTW, would leave the sgml-lib directory looking like this:\n[...]\n> Much nicer. :-)\n\nYep.  How's about that sgml-lib separation from validator in CVS, any\nnews?  How about making the split already now on the \"tarball level\",\nsomething like:  validator-0.6.0.tar.gz and w3c-sgml-lib-0.6.0.tar.gz?\n\nI'll take a better look at the release as well as my jobs before it this\nevening.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10388994"}, {"subject": "Re: [check] Progress Towards Release..", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>How's about that sgml-lib separation from validator in CVS, any\n>news?\n\nIF QA doesn't want to take over the responsibility for a separate DTD\ncollection, lets, for 0.7.0 onward, move the sgml-lib/ out of htdocs/ and\nup to the top-level $CVSROOT/validator/share/dtds/ or somesuch.\n\n\n>How about making the split already now on the \"tarball level\",\n>something like:  validator-0.6.0.tar.gz and w3c-sgml-lib-0.6.0.tar.gz?\n\nGood idea; lets do that...   ...he said, knowing full well the \"Build\nTarball\" Bug is assigned to him in Bugzilla. :-)\n\n\n>I'll take a better look at the release as well as my jobs before it this\n>evening.\n\nCool. As soon as you close or reschedule the two bugs (#70 and #72, IIRC)\nI'll tag the release in CVS and build tarballs so you can get started on\nthe RPMs. BTW, weren't you supposed to check in the spec file? Or do we\nwait for 0.7.0 and the CVS reorg to do that?\n\n-- \nTerje, you are a sick and twisted individual, and I\nthink I speak for all of us when I say, \"Thank you!\"\n\n               -- John Gruber <gruber@barebones.com>\n\n\n\n", "id": "lists-017-10396820"}, {"subject": "Re: [check] Progress Towards Release..", "content": "On Mon, 2002-11-25 at 19:58, Terje Bless wrote:\n\n> >How's about that sgml-lib separation from validator in CVS, any\n> >news?\n> \n> IF QA doesn't want to take over the responsibility for a separate DTD\n> collection, lets, for 0.7.0 onward, move the sgml-lib/ out of htdocs/ and\n> up to the top-level $CVSROOT/validator/share/dtds/ or somesuch.\n\nOk.\n\n\n> >I'll take a better look at the release as well as my jobs before it this\n> >evening.\n> \n> Cool. As soon as you close or reschedule the two bugs (#70 and #72, IIRC)\n\nWill take a look right now.\n\n> I'll tag the release in CVS and build tarballs so you can get started on\n> the RPMs. BTW, weren't you supposed to check in the spec file? Or do we\n> wait for 0.7.0 and the CVS reorg to do that?\n\nThe spec file will have to wait.  First, I need to see the tarballs\nbefore creating the RPMs (chicken-egg-chicken...), and second, we\nrequire (?) OpenSP 1.5 which will need some spanking to get RPM'd (it's\nbundled with OpenJade currently on RH8 so both of them need to be\nrepackaged and watched closely in order to not break anything).\n\nThis doesn't mean that there wouldn't be RPMs of 0.6.0, I do intend to\nroll 'em a bit later.\n\nTerje, I'll ping you when I'm finished with my open bugz.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10406257"}, {"subject": "Re: [check] Progress Towards Release..", "content": "Bjoern Hoehrmann <derhoermi@gmx.net> wrote:\n\n>* Terje Bless wrote:\n>>Looks like Beta 3 is more or less solid, judging from the feedback\n>>coming in after its release.\n>\n>Dunno about others, but I hadn't had time to look at it yet.\n\nI do realise the pace has accellerated somewhat and that there simply may\nnot have been time for the relevant feedback to appear yet. But I also\nthink we're overall in sufficiently good shape to release and am planning\nfor an interrim release (0.6.1) to deal with anything that got left out.\n\nIf anyone thinks I'm pushing it by going to release now, you'd better start\nscreaming very loudly right about now! :-)\n\n-- \n\"Hath no man's dagger here a point for me?\"   - Leonato, Governor of Messina.\n                   See Project Gutenberg <URL:http://promo.net/pg/> for more.\n\n\n\n", "id": "lists-017-10415122"}, {"subject": "Re: Closing issue [arabicnum03", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1042004"}, {"subject": "Re: [check] Progress Towards Release..", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>The spec file will have to wait.  First, I need to see the tarballs\n>before creating the RPMs (chicken-egg-chicken...), and second, we\n>require (?) OpenSP 1.5 which will need some spanking to get RPM'd (it's\n>bundled with OpenJade currently on RH8 so both of them need to be\n>repackaged and watched closely in order to not break anything).\n>\n>This doesn't mean that there wouldn't be RPMs of 0.6.0, I do intend to\n>roll 'em a bit later.\n\nOk. As you've seen from your CCs; since the OpenJade project doesn't have a\npackager for RPM I've sort of nominated you for the task. Given you were\ndoing RPMs anyways and the differences are pretty much zero AFAICT, I hoped\nyou wouldn't mind?\n\nTim Waugh used to do Red Hat RPMs of OpenJade/OpenSP, but I suspect it'll\nbe a while before they move to OpenSP 1.5 and OpenJade 1.3.2 so...\n\n-- \n> I suggest you attend some sort of anger management class....\nThat's where you learn to upset the PHBs? -- Peter da Silva\n\n\n\n", "id": "lists-017-10423745"}, {"subject": "Re: [check] Progress Towards Release..", "content": "Bjoern Hoehrmann <derhoermi@gmx.net> wrote:\n\n>* Terje Bless wrote:\n>>If anyone thinks I'm pushing it by going to release now, you'd better\n>>start screaming very loudly right about now! :-)\n>\n>I'd like to see an explicit Request for Comments on XML/N3/EARL output\n>(with some introduction, an example, pointer at documentation). I think\n>many people just overlooked it. Maybe a general Last Call for Comments\n>(including the above) would be fair, with a deadline 2002/12/01 for\n>example, just like LC WDs do.\n\nWell, this isn't a new spec being published, it's a new version of a\nsoftware program. Thus I find the notion of a \"Last Call\" somewhat odd in\nthe context. This code has been in development for ages now so you may want\nto consider the Beta period as a \"Last Call\" period.\n\nI think I do see what you mean, but waiting any further now would impose\ntoo much of a delay. I'm pushing this out now because I have (finally!)\nmanaged to take a couple of weeks off from my day job to work on this. If\nwe were to have a Last Call period now we'd push the release back\npotentially until early next year!\n\nThat may be unavoidable of course, but my current impression is that it\nisn't.\n\n\nIn particular, the XML/EARL/N3 will still be labelled as \"Beta\", with no\nvisible user interface, and with a big honkin' bright yellow warning label\nin the documentation. I think that's good enough to avoid problems.\n\nAnd I've asked people with reservations about these options to make some\nnoise before. If anyone truly thinks it would be harmfull to include them\nin this release, you have to come through very loudly and very clearly so I\ncan _remove_ them from the code before release.\n\nAnd, gentlemen, the clock _is_ ticking!\n\n\n-- \n\"You gonna take advice from somebody who slapped DEE BARNES?!\" -- eminem\n\n\n\n", "id": "lists-017-10432537"}, {"subject": "Re: [check] Progress Towards Release..", "content": "Bjoern Hoehrmann <derhoermi@gmx.net> wrote:\n\n>* Terje Bless wrote:\n>>In particular, the XML/EARL/N3 will still be labelled as \"Beta\", with\n>>no visible user interface, and with a big honkin' bright yellow warning\n>>label in the documentation. I think that's good enough to avoid\n>>problems.\n>\n>Well, a release with beta features...\n\nThe feature as such isn't really \"released\"; it's just included in the code\nthat comprised the release, if I can make that distinction. See\n<URL:http://validator.w3.org:8001/docs/users.html#Output>\n\n\n>but ok, if this is the case, I won't object making a release now.\n\nOk, good.\n\n\n-- \nI have lobbied for the update and improvement of SGML. I've done it for years.\nI consider it the jewel for which XML is a setting.  It does deserve a bit or\npolishing now and then.                                        -- Len Bullard\n\n\n\n", "id": "lists-017-10442147"}, {"subject": "Re: [check] Progress Towards Release..", "content": "* Terje Bless wrote:\n> Looks like Beta 3 is more or less solid, judging\n> from the feedback coming in after its release.\n\nDunno about others, but I hadn't had time to look at it yet.\n\n\n\n", "id": "lists-017-10450890"}, {"subject": "Re: [check] Progress Towards Release..", "content": "* Terje Bless wrote:\n> If anyone thinks I'm pushing it by going to release now, you'd better \n> start\n> screaming very loudly right about now! :-)\n\nI'd like to see an explicit Request for Comments on XML/N3/EARL output\n(with some introduction, an example, pointer at documentation). I think\nmany people just overlooked it. Maybe a general Last Call for Comments\n(including the above) would be fair, with a deadline 2002/12/01 for\nexample, just like LC WDs do.\n\n\n\n", "id": "lists-017-10458331"}, {"subject": "Re: [check] Progress Towards Release..", "content": "* Terje Bless wrote:\n> In particular, the XML/EARL/N3 will still be labelled as \"Beta\", with \n> no\n> visible user interface, and with a big honkin' bright yellow warning \n> label\n> in the documentation. I think that's good enough to avoid problems.\n\nWell, a release with beta features ... but ok, if this is the case,\nI won't object making a release now.\n\n\n\n", "id": "lists-017-10466082"}, {"subject": "[check] Almost there, tarballs, CVS, done..", "content": "Ok, I've tagged validator-0_6_0-release in CVS and built tarballs from it.\nTarballs are at <URL:http://validator.w3.org/validator-0_6_0.tar.gz> and\n<URL:http://validator.w3.org/sgml-lib-0_6_0.tar.gz>.\n\n\"validator-0_6_0-release\" will track the release and must be moved up if\nany last minute changes are made.\n\nThere is also a \"validator-0_6_0-branch\" where maintenance on the 0.6.0\nrelease is done (moving towards 0.6.1, say).\n\n\nNominally this also means that the trunk is open for new development in the\ndirection of 0.7.0 (IOW, your new config parser can go in whenever you feel\nlike it Ville). :-)\n\nExpect the trunk to become periodically broken from now on.\n\n-- \nLadies and gentlemen, you must resist those all-too-human feelings and decide\nthis case on the evidence.    And the evidence plainly shows that Mr. Landa's\ninjuries,   disfiguring as they are,  are nowhere near as important to a free\nsociety as the fundamental right to make smart-ass remarks.   -- Katie @ AtAT\n\n\n\n", "id": "lists-017-10473496"}, {"subject": "Re: First prototype XML Validation Webservic", "content": "On Sun, 24 Nov 2002, Karl Dubost wrote:\n\n> very interesting and nice interface\n\nThankyou :-)\n\n\n> Be careful to the auto validation things. Just to avoid trolls.\n> \n> http://validator.w3.org:8001/check?uri=http://qa-dev.w3.org:8888/val.so\n\nAh, the xmlns: attributes.  I've updated the stylesheet to\nsuppress that.\n\n> I don't see any problems, it's nice to have this output. It would be \n> good to have a detailed explanation of what we get in return, type of \n> messages, type of errors, DTDs if any etc.\n> \n> A manual :p\n\nAh yes, the drudgery bit of it.  Keep badgering me, and things may\nhappen - eventually.  Recruit more bodies to it and things might\nhappen faster:-)\n\n> The output seems to come back on one line (maybe it's my terminal which sucks)\n> if it's the case, maybe a formatted output would be better.\n\nHmmm, I never thought the EARL version was supposed to be human-\nreadable.  Too tired tonight to figure out whether there's a\nRight Way to do that; I'd rather not use a hack.\n\n> if you put Earl as the defaut namespace it will make the syntax a bit \n> more readable :)\n\nDone.\n\n> If I have forgotten things I will come back.\n\nI'll look forward to it:-)\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10481732"}, {"subject": "Re: issue idnuri02: New approach, new tex", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1049024"}, {"subject": "Re: [check] Almost there, tarballs, CVS, done..", "content": "On Tue, 2002-11-26 at 01:05, Terje Bless wrote:\n\n> Ok, I've tagged validator-0_6_0-release in CVS and built tarballs from it.\n> Tarballs are at <URL:http://validator.w3.org/validator-0_6_0.tar.gz> and\n> <URL:http://validator.w3.org/sgml-lib-0_6_0.tar.gz>.\n> \n> \"validator-0_6_0-release\" will track the release and must be moved up if\n> any last minute changes are made.\n> \n> There is also a \"validator-0_6_0-branch\" where maintenance on the 0.6.0\n> release is done (moving towards 0.6.1, say).\n> \n> \n> Nominally this also means that the trunk is open for new development in the\n> direction of 0.7.0 (IOW, your new config parser can go in whenever you feel\n> like it Ville). :-)\n\nThat'll be tomorrow evening (GMT+2).  I'll see about the RPMs then as\nwell.\n\nThanks for your efforts, Terje!  When do we see The New One replacing\nthe old public validator?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10490756"}, {"subject": "Re: [check] Almost there, tarballs, CVS, done..", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>Thanks for your efforts, Terje!  When do we see The New One replacing\n>the old public validator?\n\nPossibly during today, .jp time. Depending on how scheduling stuff works\nout best for Olivier (and myself I suppose).\n\n\n-- \nBy definition there is _no_way_ any problem can be my fault. Any problems\nyou think you can find in my code are in your imagination. If you continue\nwith such derranged imaginings then I may be forced to perform corrective\nbrain surgery... with an axe!                            -- Stephen Harris\n\n\n\n", "id": "lists-017-10499192"}, {"subject": "Re: First prototype XML Validation Webservic", "content": "At 23:29 +0000 2002-11-25, Nick Kew wrote:\n>Hmmm, I never thought the EARL version was supposed to be human-\n>readable.  Too tired tonight to figure out whether there's a\n>Right Way to do that; I'd rather not use a hack.\n\nIs the EARL produced by an XSLT?\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-10507403"}, {"subject": "[draft][ANN] New generation of the &quot;Markup Validator&quot; release", "content": "Here is a first draft (basically, the announcement is a re-write of the\nbeta announcement, and the relnotes come from the \"what's new\" page on\n:8001 ) Comments much welcome, but rapidly, we're going to move forward\nreal soon (I'm talking hours here...).\n\n---- CUT HERE ----\n\n-===================================================================- \n-         New generation of the \"Markup Validator\" released         -\n-===================================================================-\n\n  After a little more than a year of development, and a month of \n  beta test, we're proud to announce today the release of the new \n  version of the Markup Validator, along with an update of the\n  eponymous online service at :\n<URL:http://validator.w3.org>\n\n  This new version include, among many changes, improved and \n  more accessible interfaces, support for more document types, \n  better internationalization support, and much more...\n  (see the release notes for a more detailed list).\n\n\n** C R E D I T S   A N D   C O N T A C T **\n\n  This new version was made possible thanks to the work and\n  external contributions of many, including:\n\n                        * Terje Bless\n    * Aaron Swartz      * Jim Ley         * Nick Kew\n    * Christian Smith   * Karl Dubost     * Olivier Thereaux\n    * Dan Connolly      * Liam Quinn      * Sean Palmer\n    * Hugo Haas         * Martin D?rst    * Ville Skytt?\n\n\n  In addition, the developers would like to acknowledge the following\n  people who have contrubuted suggestions, bug reports, and feeback:\n\n    * Bj?rn H?rhmann\n    * Peter K. Sheerin\n\n  As well as the many many good people on www-validator who have\n  contributed of their time and experience to help improve the\n  Validator. Many thanks to you all!\n\n  The W3C MarkUp Validator was created by Gerald Oskoboiny and is\n  now maintained by members of the W3C QA Activity Team and external\n  collaborators. The W3C Team Contacts for the W3C MarkUp Validator\n  are Olivier Thereaux <ot@w3.org> and Dominique Haza?l-Massieux\n  <dom@w3.org>. \n\n  The main point of contact for this service is the public mailing\n  list www-validator@w3.org. The public archives for this list, as \n  well as administrativia information (subscribe/unsubscribe)\n  are available at :\n        <URL:http://lists.w3.org/Archives/Public/www-validator/>.\n\n  Feedback on the Markup Validator is more than welcome. Be sure to\n  read the documentation on \"How to provide feedback\": \n<URL:http://validator.w3.org:8001/feedback.html>\n\n\n** R E L E A S E   N O T E S **\n\nChanges for this version include: \n\n\n- Improved design of layout, including for Validation results. \nOutput has also been reworked to be easier to understand.\n\n- New feature : Tip-of-the-Day.\n\n- Many accessibility fixes, both to the web site and the Result page.\n\n- Major internal restructuring. The code has undergone significant\n  refactoring with many benefits. It is more readable and easier to\n  understand, much more robust, much improved security, more modular,\n  and performance should be significantly better. There is tentative\n  support for running under mod_perl (leading to even greater\n  performance enhancements) and memory consumption should be much\n  improved.\n\n- Many new document types are supported and support for some existing\n  document types has been improved. \n  Notable changes and additions include:\n\n    * Support for MathML is back in good shape.\n    * Support for application/xhtml+xml.\n    * Support for XHTML+MathML and XHTML+MathML+SVG.\n    * Support for SVG and image/svg+xml.\n    * Support for XHTML 1.0 Second Edition and XHTML 1.1.\n\n---- CUT HERE ----\n\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-10515063"}, {"subject": "Re: [draft][ANN] New generation of the &quot;Markup Validator&quot; release", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>This new version was made possible thanks to the work and external\n>contributions of many, including:\n>\n>                        * Terje Bless\n\nDon't even /think/ about it Olivier! :-)\n\n>    * Aaron Swartz      * Jim Ley         * Nick Kew\n>    * Christian Smith   * Karl Dubost     * Olivier Thereaux\n>    * Dan Connolly      * Liam Quinn      * Sean Palmer\n>    * Hugo Haas         * Martin D?rst    * Ville Skytt?\n\n\n\n><URL:http://validator.w3.org:8001/feedback.html>\n                             ^^^^^\nOops.\n\n\n-- \nIf you believe that will stop spammers, you're sadly misled. Rusty hooks,\nrectally administered fuel oil enemas, and the gutting of their machines,\n*that* stops spammers!                                         -- Saundo\n\n\n\n", "id": "lists-017-10526917"}, {"subject": "New checklink doc page broke", "content": "Eek, the new checklink doc page is broken at\n<http://validator.w3.org/docs/checklink.html>, it's not using SSI at all\n:(\n\nCould someone make it executable (I guess XBitHack is in use at v.w.o?)\n\nAnd someone with shell access to the server could perhaps change its\npermissions in the repo as well to prevent this from happening again...\n\nThanks,\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10536428"}, {"subject": "Re: New checklink doc page broke", "content": "Le mar 26/11/2002 ? 18:46, Ville Skytt? a ?crit :\n> Eek, the new checklink doc page is broken at\n> <http://validator.w3.org/docs/checklink.html>, it's not using SSI at all\n> :(\n> \n> Could someone make it executable (I guess XBitHack is in use at v.w.o?)\n\nDone.\n \n> And someone with shell access to the server could perhaps change its\n> permissions in the repo as well to prevent this from happening again...\n\nAnd done :)\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-10543814"}, {"subject": "Re: New checklink doc page broke", "content": "On Tue, 2002-11-26 at 19:47, Dominique Haza?l-Massieux wrote:\n\n> > And someone with shell access to the server could perhaps change its\n> > permissions in the repo as well to prevent this from happening again...\n> \n> And done :)\n\nWow, that was quick, thanks!\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10552022"}, {"subject": "Re: First prototype XML Validation Webservic", "content": "On Mon, 25 Nov 2002, Karl Dubost wrote:\n\n> Is the EARL produced by an XSLT?\n\nYes, both the HTML and EARL are produced by XSLT.\n\nThe XSLT files I'm using are in /home/nick/httpd/modxml.  I guess\nthey'd better go under CVS once I get a round tuit.\n\nBTW, mod_xml precompiles and caches the stylesheets, so Apache has\nto be restarted when you update them.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10559379"}, {"subject": "tes", "content": " \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1056363"}, {"subject": "Re: [draft][ANN] New generation of the &quot;Markup Validator&quot; release", "content": "On Tue, 26 Nov 2002, Terje Bless wrote:\n\n> \n> Olivier Thereaux <ot@w3.org> wrote:\n> \n> >This new version was made possible thanks to the work and external\n> >contributions of many, including:\n> >\n> >                        * Terje Bless\n> \n> Don't even /think/ about it Olivier! :-)\n\nPerhaps that should be <strong class=\"distinguished\">Terje Bless</strong>\n\n> \n> >    * Aaron Swartz      * Jim Ley         * Nick Kew\n> >    * Christian Smith   * Karl Dubost     * Olivier Thereaux\n> >    * Dan Connolly      * Liam Quinn      * Sean Palmer\n> >    * Hugo Haas         * Martin Drst    * Ville Skytt\n\nI wonder if we shouldn't just add Bjoern and Peter to that list?\nBjoern at least has ISTM contributed quite a lot?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10566973"}, {"subject": "Re: [draft][ANN] New generation of the &quot;Markup Validator&quot; release", "content": "Nick Kew <nick@webthing.com> wrote:\n\n>> \n>> >    * Aaron Swartz      * Jim Ley         * Nick Kew\n>> >    * Christian Smith   * Karl Dubost     * Olivier Thereaux\n>> >    * Dan Connolly      * Liam Quinn      * Sean Palmer\n>> >    * Hugo Haas         * Martin Drst    * Ville Skytt\n>\n>I wonder if we shouldn't just add Bjoern and Peter to that list?\n>Bjoern at least has ISTM contributed quite a lot?\n\nUhm, yeah, the idea was rather to single those two out among the \"non-core\"\ncontributors as having made extraordinary contributions. But you're right;\nit's confusing. Let's just lump everyone together in the one list.\n\n\n-- \nI'm [less] than thrilled by the [VM situation]; all sides of it. I [think]\nwe need a [fork] in that area so that you guys would stop stepping on each\nothers' toes.  I'm taking no part in your merry 5-way clusterfuck  -- sort\nthat mess out between yourselves.                -- Alexander Viro on lkml\n\n\n\n", "id": "lists-017-10576765"}, {"subject": "Re: [ANN] New generation of the &quot;Markup Validator&quot; release", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>-===================================================================- \n>-         New generation of the \"Markup Validator\" released         -\n>-===================================================================-\n\nWell, just past the 36 hour mark and nobody is screaming bloody murder yet.\nMust mean we're in reasonably good shape. :-)\n\n\nIn what may be hopeless optimism, I've switched :8001 over to\nvalidator-0_6_0-branch which allready has fixes for most of the issues\nreported so far. In particular, it has Ville's fix for the URI escaping as\nwell as the new code that lets you request \"Verbose\" validation results.\n\nDepending on whether the feedback on w-v stays civil -- :-) -- we may even\nbe able to release the 0.6.1 maintenance update this weekend (give or take\na few days; it's a holliday in certain parts of the world, non?).\n\n\nOf course, there still may be screaming over the new strict behaviour in re\ndoctypes and charsets when people start to notice. :-)\n\n\n\n", "id": "lists-017-10586286"}, {"subject": "FYI : power outage at keio, december 1s", "content": "Hi.\n\nJust for your information, there will be a power outage at Keio sunday \nmorning (Dec 1st). This means that qa-dev (the server, not the list) \nwill be down for a few hours.\n\n-- \nOlivier \n\n\n\n", "id": "lists-017-10594628"}, {"subject": "Validator changes: 0_6_0 or HEAD", "content": "Terje,\n\nI'm confused about where to commit validator changes at the moment, to\n0_6_0-branch or HEAD?  Are you planning a 0_6_0 -> HEAD merge after\n0.6.1 is out?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10601233"}, {"subject": "Re: Validator changes: 0_6_0 or HEAD", "content": "Wooops! That was supposed to go to QA Dev. Serves me right for answering\nemail after 24 hours without sleep. :-)\n\n\n\nTerje Bless <link@pobox.com> wrote:\n\n>Ville Skytt? <ville.skytta@iki.fi> wrote:\n>\n>>I'm confused about where to commit validator changes at the moment, to\n>>0_6_0-branch or HEAD?  Are you planning a 0_6_0 -> HEAD merge after\n>>0.6.1 is out?\n>\n>Short version: check in to 0_6_0-branch or HEAD depending on whether\n>it's small fix that should be in the 0.6.1 release or a larger change\n>that is targetted for \"some future version\". Yes, I plan to merge 0.6.x\n>onto the trunk after 0.6.1 is out the door.\n>\n>\n>Long Version:\n>\n>I'm planning a 0.6.1 release (hopefully even some time around this\n>weekend) with mostly just bug fixes. This is what's happening on the\n>validator-0_6_0-branch.\n>\n>HEAD is a freeforall (more or less) to add big or distruptive new stuff.\n>Eventually we'll branch for validator-0_7_0-(branch|release) and any\n>maintenance releases for that.\n>\n>Once 0.6.1 is out the door I'll merge validator-0_6_0-branch onto HEAD.\n>Similarly if we need a 0.6.2 release; including a merge after that too.\n>\n>\n>The idea is that HEAD is at any given moment almost by definition broken\n>and in flux. When we want to work towards a release we split off a\n>branch where we can be as anal as necessary about changes to achieve\n>stability without hindering new feature work on HEAD.\n>\n>Merging after a release, instead of doing it concurrently, is just so\n>small fixes to a release branch don't have to be slowed down by\n>determining how and if they shoudl be applied to HEAD. Especially since\n>many bug fixes -- both in terms of what they fix and in how they are\n>implemented -- are specific to the release branch and/or no longer apply\n>to the HEAD.\n>\n>\n>For /really/ disruptive stuff I envision making experimental branches\n>even off from HEAD so that you can still work on HEAD while someone is\n>off redefining the world (typically; the template system or modularizing\n>the validator).\n>\n>It's a bit more expensive because you have to spend time merging\n>periodically, but I think it'll end up being much cleaner in the long\n>run.\n-- \n\"I don't mind being thought of as a badguy,\n but it /really/ annoys me to be thought of\n as an *incompetent* badguy!\" -- John Moreno\n\n\n\n", "id": "lists-017-10608629"}, {"subject": "[FYI] Buzgilla config chang", "content": "Hi,\n\nFollowing Terje's request, I've investigated a bit why our public\nBugzilla wasn't sending emails, and still following Terje's lucid\nadvices, I changed the configuration of the email queue handling.\n\nIndeed, http://bugzilla.mozilla.org/show_bug.cgi?id=84876 seems to imply\nthat Bugzilla doesn't go well with Postfix when email queuing is set.\n\nI simply unset it and it seems to work. One of the drawback is that it\ncan slow down bugzilla, according to the configuration documentation.\nWould our bugzilla set up be too slow, we should try to remember this :)\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/INRIA\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-10618910"}, {"subject": "Press Coverag", "content": "W3C updates validation service\nhttp://www.infoworld.com/articles/hn/xml/02/11/27/021127hnvalidate.xml\n\nhttp://zdnet.com.com/2110-1104-960640.html\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-10626038"}, {"subject": "Re: Press Coverag", "content": "Karl Dubost <karl@w3.org> wrote:\n\n>W3C updates validation service\n>http://www.infoworld.com/articles/hn/xml/02/11/27/021127hnvalidate.xml\n>\n>http://zdnet.com.com/2110-1104-960640.html\n\nGack! I'm forwarding these to my _mother_! :-)\n\n\n\n", "id": "lists-017-10633036"}, {"subject": "RE: tes", "content": " \n \n-----Original Message-----\nFrom: public-iri-request@w3.org [mailto:public-iri-request@w3.org] On\nBehalf Of Scott Wiseman\nSent: Tuesday, March 09, 2004 11:46 AM\nTo: public-iri@w3.org\nSubject: test\n \n \n \n \nNetwork Consultant Los Angeles\nhttp://www.InterCore.net\nExchange Consultant Los Angeles\nhttp://www.Avidware.com\nSecurity Consultant Los Angeles\nhttp://www.FastForwardMarcom.com\nOutsourcing Consulting Programming\nhttp://www.OutsourcingAnswers.org\nAmericas best Singles Dating Service in Los Angeles\nhttp://www.AllAboutSingles.com\n \n \n \n \n\n\n\n", "id": "lists-017-1063461"}, {"subject": "Re: Press Coverag", "content": "Karl Dubost <karl@w3.org> wrote:\n\n>W3C updates validation service\n>http://www.infoworld.com/articles/hn/xml/02/11/27/021127hnvalidate.xml\n>\n>W3C updates conformance tester\n>http://zdnet.com.com/2110-1104-960640.html\n\nW3C updates conformance tester (same as ZDnet story)\nhttp://news.com.com/2102-1023-960640.html\n\nW3C updates validation service (same as Infoworld story)\nhttp://www.idg.com.hk/cw/printstory.asp?aid=20021128003\n\n\n\n-- \nYes, Micro$oft products work extremely well after you lobotomize yourself,\naffect a zombie-like stare, and forever chant the \"Micro$oft-knows-best\"\nmantra until your soul dissolves and you start believing all their crap.\n\n\n\n", "id": "lists-017-10640755"}, {"subject": "[check] :8001 updated, 0.6.1 in progress..", "content": "http://validator.w3.org:8001/ is updated with the latest devel code.\n\nAFAICT this is fairly solid and adresses all the issues that can be\nadressed for a maintenance update. IOW, I think we can release this as the\n0.6.1 update very soon now.\n\nMainly I'd like to see RPMs of the Validator and of OpenSP before release,\nbut depending on how soon that can happen we could just release Validator\nand add links to the RPMs as they become available.\n\n\n-- \n\"You gonna take advice from somebody who slapped DEE BARNES?!\" -- eminem\n\n\n\n", "id": "lists-017-10648546"}, {"subject": "welcome to public-qadev&#64;w3.or", "content": "Hi,\n\nThis is a first message to test the creation of the list.\nThe archive is public and should be at \nhttp://lists.w3.org/Archives/Public/public-qa-dev/\n\nSubscription and posting are closed.\n\nWelcome.\n\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-10706550"}, {"subject": "Re: welcome to public-qadev&#64;w3.or", "content": "On Fri, 4 Oct 2002, Olivier Thereaux wrote:\n\n> This is a first message to test the creation of the list.\n> The archive is public and should be at \n> http://lists.w3.org/Archives/Public/public-qa-dev/\n\n[ ok, let's give it a go :-]\n\nThanks.  I look forward to getting to work on the new server.\n\nISTR A few days ago on IRC we were discussing validator-EARL:\nTerje - remind me to raise this again next time we get a decent session.\n\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-10713565"}, {"subject": "Re: Hell", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-017-1071570"}, {"subject": "Fwd: validator/httpd/cgibin chec", "content": "Hello Ville,\n\nJust to make sure that I understand what's going on:\n\nmy original version was:\n    return $encodingA && $encodingB && $encodingA ne $encodingB;\nyour first version was:\n    return $encodingA && $encodingB and $encodingA ne $encodingB;\nyour current version is:\n    return (($encodingA && $encodingB) and ($encodingA ne $encodingB));\n\nI think that my original version was correct, yes?\nI don't understand why you want to make a difference between\nthe first logical 'and' and the second logical 'and', both\nare equivalent.\n\nI would therefore prefer to either return to the original version,\nor to write it as:\n    return ($encodingA and $encodingB and $encodingA ne $encodingB);\nor maybe\n    return ($encodingA and $encodingB and ($encodingA ne $encodingB));\nor\n    return $encodingA && $encodingB && ($encodingA ne $encodingB);\nto make the structure clearer.\n\nPlease change it to your preferred version.\n\nPlease note that I may change this again; I'm thinking about\ndistinguishing 'undef' and empty string, to catch cases such\nas <?xml version='1.0' encoding=''?>\n\nRegards,    Martin.\n\n\n>Date: Sat, 5 Oct 2002 07:21:09 -0400\n>From: \"DEV user - Ville Skytta - contact ot - ville.skytta@iki.fi - ville\" \n><ville@abyss.w3.org>\n>To: www-validator-cvs@w3.org\n>Subject: validator/httpd/cgi-bin check\n\n>Modified Files:\n>         check\n>Log Message:\n>Fixed an operator precedence bug in charset conflict detection.\n>It's again possible to validate pages that properly define UTF-8 in the HTTP\n>headers, like the validator itself.\n>VS: ----------------------------------------------------------------------\n\n\n\n", "id": "lists-017-10721111"}, {"subject": "Fwd: validator/httpd/cgibin chec", "content": "Hello Ville,\n\nI have looked at these changes. They mostly appear in\ncalls to add_warning and add_table,... I wonder if it wouldn't\nhave been easier to do the processing inside these functions,\nin one place?\n\nRegards,    Martin.\n\n>Date: Sat, 5 Oct 2002 11:50:02 -0400\n>From: \"DEV user - Ville Skytta - contact ot - ville.skytta@iki.fi - ville\" \n><ville@abyss.w3.org>\n>To: www-validator-cvs@w3.org\n>Subject: validator/httpd/cgi-bin check\n\n>Modified Files:\n>         check\n>Log Message:\n>A big bunch of cross site scripting/output escaping fixes.\n\n\n\n", "id": "lists-017-10730474"}, {"subject": "Re: Fwd: validator/httpd/cgibin chec", "content": "On Wed, 2002-10-09 at 07:08, Martin Duerst wrote:\n\n> I have looked at these changes. They mostly appear in\n> calls to add_warning and add_table,... I wonder if it wouldn't\n> have been easier to do the processing inside these functions,\n> in one place?\n\nIf you look closer, you'll see that there are several places where\nmarkup is fed to these functions.  So escaping inside one of them would\nbreak stuff.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10738532"}, {"subject": "Re: Fwd: validator/httpd/cgibin chec", "content": "On Wed, 2002-10-09 at 07:05, Martin Duerst wrote:\n\n> Just to make sure that I understand what's going on:\n> \n> my original version was:\n>     return $encodingA && $encodingB && $encodingA ne $encodingB;\n\nYep, that works.\n\n> your first version was:\n>     return $encodingA && $encodingB and $encodingA ne $encodingB;\n\nNo.  That was Terje's change in\n<http://dev.w3.org/cvsweb/validator/httpd/cgi-bin/check.diff?r1=1.234&r2=1.235&f=h>, which actually broke things.\n\n> your current version is:\n>     return (($encodingA && $encodingB) and ($encodingA ne $encodingB));\n\nYes.  That works again, and uses the \"and\" Terje seems to love :)\n\n> I think that my original version was correct, yes?\n> I don't understand why you want to make a difference between\n> the first logical 'and' and the second logical 'and', both\n> are equivalent.\n\nNo, \"and\" and \"&&\" are *not* the same in Perl.  See man perlop for\ndetails.  But I agree that I put in too many parens there.  Just for\nfun, try the script at the end of this message for a demonstration about\nthe logical and operator precedence.\n\nThat's why I personally never use the \"and\" form.  Mixing \"and\" and \"&&\"\nis always IMHO either 1) wrong 2) hard to read correctly.\n\n>     return $encodingA && $encodingB && ($encodingA ne $encodingB);\n> \n> Please change it to your preferred version.\n\nOk, this one it is.\n\n----------------------------------------------------------------------------\n#!/usr/bin/perl\n\nsub conflict1 {\n  my $encodingA = shift;\n  my $encodingB = shift;\n  return $encodingA && $encodingB && $encodingA ne $encodingB;\n}\n\nsub conflict2 {\n  my $encodingA = shift;\n  my $encodingB = shift;\n  return $encodingA && $encodingB and $encodingA ne $encodingB;\n}\n\nprint conflict1('utf-8', 'utf-8') ? \"yes c1\" : \"no c1\", \"\\n\";\nprint conflict2('utf-8', 'utf-8') ? \"yes c2\" : \"no c2\", \"\\n\";\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10745850"}, {"subject": "tagging messages / subject (Was : validator/httpd/cgibin check", "content": "Hi,\n\nReading the thread(s) about the latest cvs commits, I was thinking it \nwould be much better if people answering cvs commit messages on this \nlist could amend the subject to say what actually the message is about \n(or we could have made the validator-cvs list archived and not created \nthis list...)\n\nOn a general basis I'd also suggest that we tag messages specific to \none of the tools in the subject, e.g\n[HTMLvalidator] Why did you split this subroutine?\n\nI don't really care whether the tags are consistent (to me, [HTML] and \n[check] and [HTMLvalidator] would mean the same thing), I just would \nlike to make archives readable and easy to search...\n\nThanks.\n-- \nOlivier\n\n\n\n", "id": "lists-017-10755688"}, {"subject": "[check] current checkout always says 'not valid", "content": "Dear colleagues,\n\nI just set up again my trial version at http://validator.w3.org:8188.\n\nHowever, on documents that are supposed to be valid, I get\na message saying\n    This Page Is NOT Valid XHTML 1.0 Transitional!\nwithout any single warning or error message.\nI thought this was due to the following code just calling\n&erport_errors if $DEBUG is set:\n\n   if ($File->{'Is Valid'} and not $DEBUG) {\n     &report_valid($File);\n   } else {\n     $File->{Opt}->{'Show Source'} = TRUE;\n     print &jump_links($File);\n     print qq(<div class=\"splash\">\\n);\n     &print_table($File);\n     &print_warnings($File);\n     print qq(</div>\\n);\n     &report_errors($File);\n     &outline($File)     if $File->{Opt}->{'Outline'};\n     &show_source($File) if $File->{Opt}->{'Show Source'};\n     &parse_tree($File)  if $File->{Opt}->{'Show Parsetree'};\n     &show_esis($File)   if $File->{Opt}->{'Show ESIS'};\n     &show_errors($File) if $File->{Opt}->{'Show Errors'};\n   }\n\n\nBut even when setting the code to something like\n\n   if ($File->{'Is Valid'} ) { #and not $DEBUG) {\n     &report_valid($File);\n   } else {\n     $File->{Opt}->{'Show Source'} = TRUE;\n     print &jump_links($File);\n     print qq(<div class=\"splash\">\\n);\n     &print_table($File);\n     &print_warnings($File);\n     print qq(</div>\\n);\n     if ($File->{'Is Valid'}) {\n       &report_valid($File);\n     } else {\n       &report_errors($File);\n     }\n     &outline($File)     if $File->{Opt}->{'Outline'};\n     &show_source($File) if $File->{Opt}->{'Show Source'};\n     &parse_tree($File)  if $File->{Opt}->{'Show Parsetree'};\n     &show_esis($File)   if $File->{Opt}->{'Show ESIS'};\n     &show_errors($File) if $File->{Opt}->{'Show Errors'};\n   }\n\nAND setting DEBUG to 0, I still get the same behavior.\n\nAny help?\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-10764119"}, {"subject": "Re: Fwd: validator/httpd/cgibin chec", "content": "At 10:07 02/10/09 +0300, Ville Skytt wrote:\n>On Wed, 2002-10-09 at 07:05, Martin Duerst wrote:\n>\n> > Just to make sure that I understand what's going on:\n> >\n> > my original version was:\n> >     return $encodingA && $encodingB && $encodingA ne $encodingB;\n>\n>Yep, that works.\n>\n> > your first version was:\n> >     return $encodingA && $encodingB and $encodingA ne $encodingB;\n>\n>No.  That was Terje's change in\n><http://dev.w3.org/cvsweb/validator/httpd/cgi-bin/check.diff?r1=1.234&r2=1. \n>235&f=h>, which actually broke things.\n\nVery sorry about that miss-attribution.\n\n\n> > your current version is:\n> >     return (($encodingA && $encodingB) and ($encodingA ne $encodingB));\n>\n>Yes.  That works again, and uses the \"and\" Terje seems to love :)\n>\n> > I think that my original version was correct, yes?\n> > I don't understand why you want to make a difference between\n> > the first logical 'and' and the second logical 'and', both\n> > are equivalent.\n\nI wanted to say that the computation we are trying to do\nis just an operation of logical ands of three things,\nwithout any further inherent structure. So there is no\nreason to use && in one instance and 'and' in another\ninstance, and using different operators only clouds\nwhat's going on.\n\n>No, \"and\" and \"&&\" are *not* the same in Perl. See man perlop for\n>details.  But I agree that I put in too many parens there.  Just for\n>fun, try the script at the end of this message for a demonstration about\n>the logical and operator precedence.\n>\n>That's why I personally never use the \"and\" form.  Mixing \"and\" and \"&&\"\n>is always IMHO either 1) wrong 2) hard to read correctly.\n>\n> >     return $encodingA && $encodingB && ($encodingA ne $encodingB);\n> >\n> > Please change it to your preferred version.\n>\n>Ok, this one it is.\n>\n>----------------------------------------------------------------------------\n>#!/usr/bin/perl\n>\n>sub conflict1 {\n>   my $encodingA = shift;\n>   my $encodingB = shift;\n>   return $encodingA && $encodingB && $encodingA ne $encodingB;\n>}\n>\n>sub conflict2 {\n>   my $encodingA = shift;\n>   my $encodingB = shift;\n>   return $encodingA && $encodingB and $encodingA ne $encodingB;\n>}\n>\n>print conflict1('utf-8', 'utf-8') ? \"yes c1\" : \"no c1\", \"\\n\";\n>print conflict2('utf-8', 'utf-8') ? \"yes c2\" : \"no c2\", \"\\n\";\n\nIt should say:\nno c1\nyes c2\nbecause the second one is interpreted as\n   (return $encodingA && $encodingB) and $encodingA ne $encodingB;\n\nAnd that's of course not what we want.\nThanks for finding that bug; I'm not sure I would have found\nit easily.\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-10773554"}, {"subject": "Are IDNs allowed in http IRIs", "content": "Are IDNs allowed in http IRIs?  It seems like a silly question, but\ncurrently the IRI draft tries to inherit the answer from the URI & HTTP\nspecs, and the URI draft tries to inherit the answer from the HTTP spec,\nand of course the HTTP spec knows nothing of IDNs.  The result is that\nthe question has no clear answer.  Does it need a clear answer, and if\nso, which document is the place to provide that answer?\n\nConsider the purported IRI http://jos%e9.example.net/.  Is that a valid\nhttp IRI?  If so, what does it mean?\n\nThere are four places we might hope to find clues to answer those\nquestions:  The IRI spec, the URI spec, the HTTP spec, and the IDNA\nspec.\n\nHere's what the IRI spec has to say on the matter:\n\n    IRIs are only valid if they map to syntactically valid URIs.\n\n    the resource that the IRI locates is the same as the one located by\n    the URI obtained after converting the IRI\n\nAccording to the conversion procedure, http://jos%e9.example.net/\nmay be converted to either http://jos%C3%A9.example.net/ or\nhttp://xn--jos-dma.example.net/.  Maybe we'll be lucky and the answers\nto our two questions will be the same for both URIs, or maybe we'll be\nunlucky and the answers will be different for the two URIs, in which\ncase the answers for the IRI are indeterminate.\n\nAccording to the HTTP and IDNA specs, http://xn--jos-dma.example.net/ is\nvalid and has a clear meaning, while http://jos%C3%A9.example.net/ is\ninvalid for two reasons.  First, it does not match the http URI grammar,\nwhich explicitly uses the host component from RFC-2396, which does not\nallow percent-escapes.  Second, the IDNA spec requires the ASCII form\n(xn--jos-dma.example.net) in IDN-unaware domain name slots, and the host\ncomponent of an http URI is an IDN-unaware domain name slot (because\nRFC-2616 predates RFC-3490).\n\nThe only way for the URI http://jos%C3%A9.example.net/ to become valid\nand meaningful is for the HTTP URI spec to be updated, either by a\nsuccessor to RFC-2616, or by a sweeping action of the successor to\nRFC-2396.  For example, 2396bis could say that it updates all schemes\nthat use domain names to use IDNs.  Such a sweeping update would of\ncourse explicitly bypass the interoperability protections designed into\nthe IDNA architecture, and would let things break during the transition\n(it amounts to \"just send UTF-8\"), but I suppose it's an option.\n\nThe current 2396bis draft does not make such an update.  It says:\n\n    When a non-ASCII host name represents an internationalized domain\n    name intended for resolution via DNS, the name must be transformed\n    to the IDNA encoding [RFC3490] prior to name lookup.\n\nIt does not tell us when a non-ASCII host name represents an IDN, so\npresumably that determination is left up to the scheme.  Existing\nschemes like http don't use non-ASCII names to represent IDNs (the IDNA\nspec makes that clear).\n\nGetting back to the original questions regarding the purported IRI\nhttp://jos%e9.example.net/, we have not been able to determine whether it\nis valid or what it means, because the answers change depending on which\nconversion to to URI we happen to use, and the IRI spec blesses both\nconversions.\n\nOf course the same indeterminacy exists for ftp://jos%e9.example.net/ and\nmailto:postmaster@jos?.example.net etc.\n\nIs this indeterminacy intended?\n\nIf not, I can think of two ways to rectify the situation (and maybe\nother folks can think of other ways).  One way is for the URI spec to\nupdate all URI schemes along these lines:\n\n    All schemes that use data types that use an ASCII-Compatible\n    Encoding (ACE) for internationalization are hereby updated to\n    allow the use of equivalent non-ASCII forms, represented as\n    percent-encoded UTF-8.  An example of such a data type is domain\n    names, see [IDNA].\n\n(Here I've generalized from IDNs to ACEs because there is a possibility\nthat email address local parts will also use an ACE.)\n\nAlternatively, the URI spec could be left as-is, and the IRI spec could\nredefine the validity of IRIs along these lines:\n\n    An IRI is valid if it conforms to the syntax of the corresponding\n    URI except for the following two additional freedoms:\n\n       1) Wherever the URI might contain percent-encoded octets\n       representing UTF-8, the IRI may instead use non-ASCII characters\n       whose UTF-8 encoding is those same octets.\n\n       2) Wherever the URI might contain a data type that uses an\n       ASCII-Compatible Encoding (ACE) for internationalization, the IRI\n       may instead use an equivalent non-ASCII form.  An example of such\n       a data type is domain names, see [IDNA].\n\n    When an IRI is converted to a URI, the conversion MAY use\n    scheme-specific knowledge to convert appropriate components to ACE\n    forms rather than percent-encoded UTF-8.  Lack of scheme-specific\n    knowledge (or failure to use it) can cause valid IRIs to be\n    converted to invalid URIs that contain percent-encoded non-ASCII\n    text where only the ACE form would be permitted.  Such invalid URIs\n    cannot in general be resolved directly, but can always be converted\n    back into valid IRIs, which could then be reconverted to valid URIs\n    by a scheme-specific converter.\n\nMaybe it would be bothersome to bless a conversion procedure that can\nproduce invalid output.  If not, disregard the rest of this message.\nOtherwise, the possibility of invalid output could be avoided by\ncreating a new \"scheme name registration tree\" (BCP-35).  For example,\nthe \"i\" tree could be defined as follows:  For any scheme foo, the\nscheme i-foo is just like foo except for the following additional\nfreedom:\n\n    Wherever the foo: URI might contain a data type that uses an\n    ASCII-Compatible Encoding (ACE) for internationalization, the\n    i-foo: URI may instead use an equivalent non-ASCII form, represented\n    as percent-encoded UTF-8.  An example of such a data type is domain\n    names, see [IDNA].\n\nA scheme-agnostic IRI-to-URI converter can avoid the possibility of\ninvalid output by prefixing i- to the front of the output.  When the URI\neventually makes its way to an agent with scheme-specific knowledge,\nthat agent can know whether the prefix can simply be discarded, or if\nACE conversions need to be performed first.\n\nA URI-to-IRI converter can always discard the i- prefix, even without\nrecognizing the scheme.\n\nAMC\nhttp://www.nicemice.net/amc/\n\n\n\n", "id": "lists-017-1077538"}, {"subject": "Re: [check] current checkout always says 'not valid", "content": "On Wed, 2002-10-09 at 11:47, Martin Duerst wrote:\n\n> However, on documents that are supposed to be valid, I get\n> a message saying\n>     This Page Is NOT Valid XHTML 1.0 Transitional!\n> without any single warning or error message.\n\nMake sure that you're running Liam Quinn's lq-nsgmls (from\n<http://www.htmlhelp.com/tools/validator/src/lq-sp-1.3.4.9.tar.gz>),\nit's required nowadays for some additional security fixes, I guess.\n\nAlternatively, you can use the normal nsgmls, just remove '-R' from its\noptions (look for @xmlflags) in the validator source.\n\nHmm, perhaps the possible \"-R\" should be part of the \"SGML Parser\"\nconfig var in validator.conf instead of being hardcoded in the script...\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10783901"}, {"subject": "Re: [check] current checkout always says 'not valid", "content": "Turned out the reason was that I forgot the -dP on cvs up,\nso a lot of dtd stuff was missing. Also, the pointer to\nthe sp binary (from the config file) was wrong.\n\nSorry for bothering you. Back to my real work.\n\nRegards,    Martin.\n\nAt 22:39 02/10/09 +0300, Ville Skytt wrote:\n>On Wed, 2002-10-09 at 11:47, Martin Duerst wrote:\n>\n> > However, on documents that are supposed to be valid, I get\n> > a message saying\n> >     This Page Is NOT Valid XHTML 1.0 Transitional!\n> > without any single warning or error message.\n>\n>Make sure that you're running Liam Quinn's lq-nsgmls (from\n><http://www.htmlhelp.com/tools/validator/src/lq-sp-1.3.4.9.tar.gz>),\n>it's required nowadays for some additional security fixes, I guess.\n>\n>Alternatively, you can use the normal nsgmls, just remove '-R' from its\n>options (look for @xmlflags) in the validator source.\n>\n>Hmm, perhaps the possible \"-R\" should be part of the \"SGML Parser\"\n>config var in validator.conf instead of being hardcoded in the script...\n>\n>--\n>\\/ille Skyttaville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10792576"}, {"subject": "[check] Outdated error message", "content": "I just found that http://validator.w3.org:8188/docs/errors.html#bad-char\nis totally outdated. Anybody wants to fix it?\n\nRegards,    Martin.\n\n x non SGML character number ### x \n\n     You've used an illegal character in your text. HTML uses the standard \nISO8859-1 character encoding, and ISO8859-1 leaves undefined 65 character \ncodes (0 to 31 inclusive and 127 to 159 inclusive); the validator has found \none of these undefined characters in your document. The character may \nappear on your browser as a curly quote, or a trademark symbol, or some \nother fancy glyph; on a different computer, however, it will likely appear \nas a completely different character, or nothing at all.\n\n     Your best bet is to replace the character with the nearest equivalent \nASCII character, or to use an appropriate character entity. For more \ninformation on ISO8859-1, see Alan Flavell's excellent ISO8859-1/HTML \nreference.\n\n     This error can also be triggered by formatting characters embedded in \ndocuments by some word processors. If you use a word processor to edit your \nHTML documents, be sure to use the \"Save as ASCII\" or similar command to \nsave the document without formatting information.\n x `####' is not a valid character number x \n\n     You'll get several occurrences of this error if you use the Cougar \nDTD. Cougar uses the 16-bit UCS-4 (a.k.a. \"Unicode\") character set instead \nof the 8-bit ISO8859-1 character set used by HTML 2.0 and HTML 3.2. It also \ndefines mnemonic entities for various Unicode characters; for instance, the \nentity &trade; is defined as the character entity &#8482;, which is the \nUnicode trademark character. Unfortunately, the nsgmls executable used by \nthe validator does not appear to have 16-bit character support compiled in, \nand so it chokes on these 16-bit character entities.\n\n     These errors are not produced by anything in your document and should \nnot otherwise affect the validation of your document, so you can pretty \nmuch ignore them.\n\n\n\n", "id": "lists-017-10801253"}, {"subject": "[check] Tag names always lower cas", "content": "Terje told me to be careful with fixing spelling errors.\nSome tags still appear as upper case in error messages,\ne.g. the H1 and H6 in:\n\n       Below is an outline for this document, automatically generated from the\n       heading tags (<code>&lt;H1&gt;</code> through <code>&lt;H6&gt;</code>.)\n\nBecause of XHTML, I think all tag names should be lower case.\nAnybody differing?\n\nregards,    Martin.\n\n\n\n", "id": "lists-017-10810108"}, {"subject": "EARL patc", "content": "Validator EARL shows traces of an RDF learning curve: XML striping\nis suppressed for no obvious reason, and overuse of\nrdf:parsetype=\"Resource\" generates huge numbers of bnodes.\nLooking at the report generated by a page with a small number of errors\n(http://valet.webthing.com/invalid.html) I can't make too much sense of\nthe picture generated by the RDF validator from the HTML validator report.\n\nI attach a patch to generate a compact but meaningful EARL report.\nI'm not quite sure how it'll go down with the EARL folks, but IMO\nit's worth putting to them.\n\nRationale:\n  (1) Validator asserts that {page} passes or fails {valid HTML}\n      That is one assertion - no problem.\n  (2) For the individual error messages, I've minimised the Subjects\n      and Objects, on the grounds that they are known to be {points\n      within the page} and {violations of the HTML standard} respectively.\n      Not quite sure whether everyone will be happy with the minimisation,\n      but it looks nice to me!\n\n-- \nNick Kew\n\n\n\n\nTEXT/PLAIN attachment: earlpatch\n\n\n\n\n", "id": "lists-017-10817402"}, {"subject": "Re: Fwd: validator/httpd/cgibin chec", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>No.  That was Terje's change in\n><http://dev.w3.org/cvsweb/validator/httpd/cgi-bin/check.diff?r1=1.234&r2\n>=1.235&f=h>, which actually broke things.\n\nWoops! My bad.\n\n\n>Yes.  That works again, and uses the \"and\" Terje seems to love :)\n>[...]\n>That's why I personally never use the \"and\" form.  Mixing \"and\" and \"&&\"\n>is always IMHO either 1) wrong 2) hard to read correctly.\n\nThere is a reason why Perl has two logical AND operators with different\nprecendence; one of them being exactly to cut down on paranthesis. And my\npersonal Perl Style Guide demands \"and\" over \"&&\" where possible to enable\nthe code to read more like a English sentence (without going to extremes;\nI'm not a candyfloss-language fan!), to cut down on the amount of\npunctuation, and to use the loosest binding (lowest precendence) operator\nthat will do the job.\n\n\n\n", "id": "lists-017-10825111"}, {"subject": "Re: welcome to public-qadev&#64;w3.or", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>This is a first message to test the creation of the list. The archive is\n>public and should be at\n>http://lists.w3.org/Archives/Public/public-qa-dev/\n>\n>Subscription and posting are closed.\n\nAh, that explains why the list is called \"*public*-qa-dev\" then. Perfectly\nlogical of course.\n\nOh, and remember that little chat we had about List-ID and hierarchical\nnamespaces? I swear you do this just to piss me off! :-)\n\n\n-link, amassing \"special case\" rules in his filters like a\n       neveryoumind and seriously considering sending some\n       Ronin to have a little \"chat\" with Olivier-san!\n\n\n\n", "id": "lists-017-10833537"}, {"subject": "Re: [check] Outdated error message", "content": "Martin Duerst <duerst@w3.org> wrote:\n\n>I just found that http://validator.w3.org:8188/docs/errors.html#bad-char\n>is totally outdated. Anybody wants to fix it?\n\nI've solicited patches for this on w-v but so far have had no takers.\nEventually I'll get fed up and do it myself, but...\n\n\n\n", "id": "lists-017-10841873"}, {"subject": "Re: [check] Tag names always lower cas", "content": "Martin Duerst <duerst@w3.org> wrote:\n\n>Terje told me to be careful with fixing spelling errors. Some tags still\n>appear as upper case in error messages, e.g. the H1 and H6 in:\n>\n>Below is an outline for this document, automatically generated from the\n>heading tags (<code>&lt;H1&gt;</code> through <code>&lt;H6&gt;</code>.)\n>\n>Because of XHTML, I think all tag names should be lower case. Anybody\n>differing?\n\nNope, not at all. :-)\n\nMy comments about spelling changes was related to capitalization of terms.\ne.g. I tend to capitalize \"Validate\" and \"Validator\" to stress the fact\nthat these are terms with special meaning outside of their normal English\nmeaning. I'm ready to be convinced this is a Bloody Stupid[tm] thing to do,\nbut I'd prefer if y'all didn't define them as simple typos and \"fix\" them\nwilly-nilly. Convince me it's stupid (so I stop putting them in) and lets\nfix _all_ of them in one go if we're to change them at all. Consistency and\nall that... :-)\n\n\n\n", "id": "lists-017-10849268"}, {"subject": "Re: EARL patc", "content": "Nick Kew <nick@webthing.com> wrote:\n\n>Validator EARL shows traces of an RDF learning curve: [...]\n\nNamely that I don't know Earl from Tom, Dick, or Harry. :-)\n\nI've asked Nick to redo the diff as a unidiff -- so I manage to read it; I\ncan't stand context diffs -- and intend to apply it on the theory that Nick\nknows what he's doing.\n\nAll those opposed say \"cvs diff -u\". :-)\n\n\n\n", "id": "lists-017-10857654"}, {"subject": "Re: [check] current checkout always says 'not valid", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>On Wed, 2002-10-09 at 11:47, Martin Duerst wrote:\n>\n>>However, on documents that are supposed to be valid, I get a message\n>>saying This Page Is NOT Valid XHTML 1.0 Transitional! without any\n>>single warning or error message.\n>\n>Make sure that you're running Liam Quinn's lq-nsgmls (from\n><http://www.htmlhelp.com/tools/validator/src/lq-sp-1.3.4.9.tar.gz>),\n>it's required nowadays for some additional security fixes, I guess.\n\nActually, I'm pretty much \"requiring\" OpenSP these days. The security fixes\nare just some of what lq-nsgmls lacks and supporting both will be far too\nmuch of a pain unless and until the mythical pluggable backends become a\nreality.\n\n\n>Alternatively, you can use the normal nsgmls, just remove '-R' from its\n>options (look for @xmlflags) in the validator source.\n\nNo! Please don't do this on any server exposed to the world.\n\n\n>Hmm, perhaps the possible \"-R\" should be part of the \"SGML Parser\"\n>config var in validator.conf instead of being hardcoded in the script...\n\nI don't want to make it too easy to turn it off. You'd better know\n_exactly_ what you're doing before you mess with that particular switch.\n\n\n\n", "id": "lists-017-10865271"}, {"subject": "Re: [check] current checkout always says 'not valid", "content": "On Fri, 2002-10-11 at 22:16, Terje Bless wrote:\n\n> Actually, I'm pretty much \"requiring\" OpenSP these days.\n\nHmm, do you know if there's an OpenSP tarball out that has the -R option\nor must one still build from their CVS to get it?\n\n> >Alternatively, you can use the normal nsgmls, just remove '-R' from its\n> >options (look for @xmlflags) in the validator source.\n> \n> No! Please don't do this on any server exposed to the world.\n\nOops, my bad, sorry.\n\n> >Hmm, perhaps the possible \"-R\" should be part of the \"SGML Parser\"\n> >config var in validator.conf instead of being hardcoded in the script...\n> \n> I don't want to make it too easy to turn it off. You'd better know\n> _exactly_ what you're doing before you mess with that particular switch.\n\nRight.  Thanks for clearing my head and nice to hear from you again :)\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10874411"}, {"subject": "Re: [check] current checkout always says 'not valid", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>On Fri, 2002-10-11 at 22:16, Terje Bless wrote:\n>\n>>Actually, I'm pretty much \"requiring\" OpenSP these days.\n>\n>Hmm, do you know if there's an OpenSP tarball out that has the -R option\n>or must one still build from their CVS to get it?\n\nYou still have to build from CVS, but Ian had intended to release 1.5 final\nwhen we get it tested on Red Hat 8.0 (which I'd promised to do, but...).\n\n\n>[...] nice to hear from you again :)\n\nI just today tipped over the 250 hours of overtime per year that is the\nmaximum allowed in .no; so no more overtime for me until the boss gets\naround to getting dispensation from the rules for me. :-)\n\n\n\n", "id": "lists-017-10883049"}, {"subject": "Re: welcome to public-qadev&#64;w3.or", "content": "On Saturday, Oct 12, 2002, at 04:28 Asia/Tokyo, Terje Bless wrote:\n> Olivier Thereaux <ot@w3.org> wrote:\n>> Subscription and posting are closed.\n>\n> Ah, that explains why the list is called \"*public*-qa-dev\" then. \n> Perfectly\n> logical of course.\n\nList names only reflect \"read\" policy (archives), not anything else.\nNot my choice, but the actual policy at W3C.\nBTW I think this is a good config for this list, but tell me if you \ndisagree.\n\n> Oh, and remember that little chat we had about List-ID and hierarchical\n> namespaces?\n\nI remember the chat, and I remember I was not convinced (enough to go \nfiddle with smartlist's config and change from the default \nbehaviour...) :)\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-10891064"}, {"subject": "Re: welcome to public-qadev&#64;w3.or", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>Terje Bless <link@pobox.com> wrote:\n>>Olivier Thereaux <ot@w3.org> wrote:\n>>\n>>>Subscription and posting are closed.\n>>Ah, that explains why the list is called \"*public*-qa-dev\" then.\n>>Perfectly logical of course.\n>\n>List names only reflect \"read\" policy (archives), not anything else. Not\n>my choice, but the actual policy at W3C. BTW I think this is a good\n>config for this list, but tell me if you disagree.\n\nI don't really see what the \"public-\" bit is for; have you, or do you\nintend to, set up a _private_-qa-dev? I've always been vaguely annoyed by\nthe \"www-foo\" names, but at least \"www\" is easy to type...\n\nOooh. Let me guess. The \"public-\" bit is so that Members[tm] recall that\nwhat they say is actually going to be read by The Community[tm] (aka. \"The\nUnwashed Masses\")? :-)\n\n\n>>Oh, and remember that little chat we had about List-ID and hierarchical\n>>namespaces?\n>\n>I remember the chat, and I remember I was not convinced (enough to go\n>fiddle with smartlist's config and change from the default behaviour...)\n>:)\n\nYou do realise, don't you, that this means war?\n\n\n\n\n-link, trying to decide whether giant robots or tentacled monsters\n       would be more effective in \"convincing\" yod to reconsider...\n\n\n\n", "id": "lists-017-10899523"}, {"subject": "Re: EARL patc", "content": "On Fri, 11 Oct 2002, Terje Bless wrote:\n\n> I've asked Nick to redo the diff as a unidiff -- so I manage to read it; I\n> can't stand context diffs -- and intend to apply it on the theory that Nick\n> knows what he's doing.\n\nI attach the updated patch.\n\nI'm not 100% convinced about my use of the rdf:About attribute (will have\nto get feedback on that one), and of course the EARL spec remains\nhopelessly incomplete in some areas, but this is now (I believe)\nsignificantly better EARL than my own Page Valet tool is producing.\n\n-- \nNick Kew\n\n\n\n\n\nTEXT/PLAIN attachment: check.diff\n\n\n\n\n", "id": "lists-017-10908556"}, {"subject": "Re: EARL patc", "content": "Nick Kew <nick@webthing.com> wrote:\n\n>I attach the updated patch.\n\nIs this the one you sent me and which I applied in CVS?\n\n\n\n", "id": "lists-017-10916125"}, {"subject": "RE: Are IDNs allowed in http IRIs", "content": "Adam, I think you have a valid point, I would however make a simpler suggestion, which is two fold:\n\n- introduce the concept of IRI used as presentation element of URI protocol element. In that sense http://jos%e9.example.net/ is a presentation element for the following protocol element http://xn--jos-dma.example.net/ and as you noted http://jos%C3%A9.example.net/ is not a correct URI (per RFC 2616 referring to host itself defined in RFC 2396). I have suggested text in that sense to the IRI main editor (Martin). Having the concept of presentation element validates http IRIs which exist de facto, whatever we like it or not.\n\n- add text in the IRI spec saying the following:\n<<\nWhen an IRI is converted to a URI, the conversion SHOULD use scheme-specific knowledge to convert appropriate components where the scheme syntax prevents the usage of percent-encoded text into such components. Lack of scheme-specific knowledge (or failure to use it) can cause valid IRIs to be converted to invalid URIs that contain percent-encoded non-ASCII text where they are not permitted.\n>>\nIt is my opinion that anybody in its right mind would implement IRI to URI mapping considering all the schemes where 'host' is used and map accordingly (ie use Punycode). My text avoids direct reference to ACE which is in my opinion unnecessary in the IRI spec and also makes the suggestion to use scheme aware mapping much stronger (SHOULD instead of MAY). It is a SHOULD instead of a MUST simply because a scheme may be updated in the future, making the scheme awareness eventually not necessary.\n\nMichel\n\n\n\n", "id": "lists-017-1091697"}, {"subject": "[check] Status and Progres", "content": "A few quick words on current status and what happens in the near future...\n\n\nAs y'all may or may not be aware, I've been pretty much swamped lately and\nas a result been AWOL from Validator stuff. Hopefully the worst of that is\nover now and I'll have my normal copious amounts of free time to work on\nValidator. :-)\n\n\nAFAICT, Validator is in reasonably good shape. There may be some charset\nissues remaining, but I got the feeling from Martin that the brunt of it\nwas sorted. That means I have only one issue outstanding before calling a\npublic beta, and that is updated MathML 2 DTDs (which ought to go in today\nor tomorrow depending on how much grief they give me).\n\nHow about the rest of you? Anyone else have anything that needs to be\naddressed before a public beta period?\n\n\nGoing forward I'm thinking we'll call a public beta ASAP. I'll advertize\nthe hell out of it anywhere I can think of (mailinglists, newsgroups, etc.)\nand hopefully we'll get all the \"Dude, you *suck*!\" messages _before_ we\nupdate :80 with the new version this time. :-)\n\nDepending on how much and what kind of feedback we get I'm now aiming to do\nthe final release around the middle of November. The reason being simply\nthat it looks like I'll be able to take two weeks off work at the end of\nNovember (Week 47 and 48, Nov. 17-30, probably) to work on fixing any bugs\nor perhaps start work on the next version.\n\n\n\nAnd speaking of the next version...\n\nI was initially going to keep that a relatively minor thing to keep the\nrelease cycle short, but since these things seem to take over a year no\nmatter how carefully scheduled, I'm now thinking of just ripping it\ncompletely to pieces and going wild.\n\nIn particular, I'm thinking of splitting \"check\" into (at least) two\npieces; the CGI bit containing the logic, and a Perl module containing\npretty much all the subroutines with a little OO interface sprinkled on\nthem. And, for extra kicks, I want to strip out all embedded/hardcoded HTML\nsnippets from the code and replacing them with a templating system\n(probably i18n-ing the validator in the process).\n\nThat's probably more then enough to completely destabilize the code for a\ngood clip so if anyone thinks we ought be a bit more carefull now is the\ntime to holler before I go wild. :-)\n\n\nTo prove I'm not completely reckless, I intend to split off the current\nrelease version of Validator onto a branch (\"validator-0_6_0-release\" or\nsummat) where bugfixing for :80 can take place. If anyone has trouble with\nCVS branches I can put together a mini-howto for dealing with them in re\nValidator.\n\n\nAnyways, enough braindumping. Any comments?\n\n\n\n", "id": "lists-017-10923308"}, {"subject": "Re: [check] Status and Progres", "content": "Hi,\n\nOn Thursday, Oct 17, 2002, at 04:38 Asia/Tokyo, Terje Bless wrote:\n> A few quick words on current status and what happens in the near \n> future...\n>\n>\n> As y'all may or may not be aware, I've been pretty much swamped lately \n> and\n> as a result been AWOL from Validator stuff.\n\nSo was I, actually. I have a little more time to deal with validator \nwork in the weeks to come, so if I'm needed I should be more responsive.\n\nHowever, since I'm not (yet) involved in the coding, I shouldn't be a \nshowstopper for, at least, proceeding to beta test status.\n\n> AFAICT, Validator is in reasonably good shape. There may be some \n> charset\n> issues remaining, but I got the feeling from Martin that the brunt of \n> it\n> was sorted. That means I have only one issue outstanding before \n> calling a\n> public beta, and that is updated MathML 2 DTDs (which ought to go in \n> today\n> or tomorrow depending on how much grief they give me).\n\nI don't have a very clear vision of all the issues (the ones I can \nthink of are character entities, missing DTDs, logos?... and those may \nhave been fixed already, I have some mail backlog to finish). As a \nsidenote, during the QA Team face-to-face I received the AI to work on \ncompleting and (semi)-automating the \"test\" suite for the validator. \n(will talk about this in another mail, later)\n\n\n\n> Going forward I'm thinking we'll call a public beta ASAP.\n\nAgreed.\n\n> I'll advertize\n> the hell out of it anywhere I can think of (mailinglists, newsgroups, \n> etc.)\n> and hopefully we'll get all the \"Dude, you *suck*!\" messages _before_ \n> we\n> update :80 with the new version this time. :-)\n\nI wonder if it will benefit from an \"official\" voice (e.g calls for \nreviews sent with a W3 address) and if it needs any \"coverage\", i.e if \nwe should ask the comm to talk about it. I'm tempted to think the \nanswer to the former might be \"yes\", whereas comm coverage can wait for \nthe \"real update\". I'm wishing to hear other opinions, though.\n\n> Depending on how much and what kind of feedback we get I'm now aiming \n> to do\n> the final release around the middle of November.\n\nI like the date. We'll have a W3C members meeting around mid-nov, and \nthere is at least one big web conf around these dates, a a new release \nwould be a perfect time to try and push for more use of the validator.\n\n> And speaking of the next version...\n>\n> In particular, I'm thinking of splitting \"check\" into (at least) two\n> pieces; the CGI bit containing the logic, and a Perl module containing\n> pretty much all the subroutines with a little OO interface sprinkled on\n> them. And, for extra kicks, I want to strip out all embedded/hardcoded \n> HTML\n> snippets from the code and replacing them with a templating system\n> (probably i18n-ing the validator in the process).\n\nI like the ideas. templating the messages is a good move, It may \nattract people wishing to improve the \"user experience\" with translated \nmessages (in en_newbie or other languages). \"modularizing\" a bit seems \nlike a reasonable move too.\n\nI'm totally in favour to these ideas, provided that (as you mentioned) \nwe branch the code in order to allow bug fixes of the prod version a \nlittle more often than real \"releases\".\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-10932939"}, {"subject": "Re: [check] Status and Progres", "content": "> > In particular, I'm thinking of splitting \"check\" into (at least) two\n> > pieces; the CGI bit containing the logic, and a Perl module containing\n> > pretty much all the subroutines with a little OO interface sprinkled on\n> > them. And, for extra kicks, I want to strip out all embedded/hardcoded \n> > HTML\n> > snippets from the code and replacing them with a templating system\n> > (probably i18n-ing the validator in the process).\n> \n> I like the ideas. templating the messages is a good move, It may \n> attract people wishing to improve the \"user experience\" with translated \n> messages (in en_newbie or other languages). \"modularizing\" a bit seems \n> like a reasonable move too.\n> \n> I'm totally in favour to these ideas, provided that (as you mentioned) \n> we branch the code in order to allow bug fixes of the prod version a \n> little more often than real \"releases\".\n\nSeconded.  But how about using XSLT for the \"templating\" instead of some\nPerl stuff?  Dunno if the XML generation for XSLT should be templatized\nor hardcoded in Perl, though...\n\nI've had an idea of using Validator as a backend for a validating proxy\nfor some time now.  Using such a proxy would be useful when checking\nsome dynamic pages which are behind custom authentication schemes and\ndepend on the User-Agent etc.  There are unresolved issues still, like\nwhere to put/how to handle the validation results etc, and I haven't\nreally looked at the Validator code in the sense of really using it in a\nHTTP proxy.  But the modularization of the code sounds good to me in\nthis respect too.\n\nOh, perhaps a bit offtopic in this thread, but I noticed a couple of\nweeks ago that Validator doesn't run with mod_perl 2, at least the one\nthat comes with RedHat 8.0 (1.99_05).  IIRC there's nothing we can do\nabout it, but it happened when passing the STDIN to open3(), barfing\nsomething like \"Can't locate method FILENO in request_rec\".  But it\nworks fine with Perl 5.8.0 and Apache 2 (without mod_perl).  I'll\nprovide more details on request.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10943498"}, {"subject": "[checklink] New location for doc pag", "content": "We've discussed with Hugo about a new location for the checklink page\ncurrently at <http://www.w3.org/2000/07/checklink>.\n\nThe problem with the current location is that AFAICT it's not in a place\nwhere I'd be able to update it.  And to people who don't already know;\nthe main checklink development responsibility has been transferred over\nto me after discussions with Hugo and Olivier.\n\nSo unless somebody objects, I'll put the checklink doc page in CVS into\nvalidator/htdocs/checklink.html.  When that is publicly available\nsomewhere, eg. deployed on validator.w3.org, we'll redirect the old doc\nURI to that one.\n\nI also have some pending work to do, like making it run under mod_perl\nwithout trashing the server error log, as well as the entries already in\nthe todo list at <http://www.w3.org/2000/07/checklink#what>.  I hope\nI'll get to look at those next week.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10952678"}, {"subject": "Re: [checklink] New location for doc pag", "content": "Ville,\n\nOn Monday, Oct 21, 2002, at 01:47 Asia/Tokyo, Ville Skytt? wrote:\n> So unless somebody objects, I'll put the checklink doc page in CVS into\n> validator/htdocs/checklink.html.  When that is publicly available\n> somewhere, eg. deployed on validator.w3.org, we'll redirect the old doc\n> URI to that one.\n\nWe can redirect, or proxy. Either will be acceptable.\n\nWhen/if you need to change things on the www.w3.org, you can ask me, or \n(better, to avoir having a single point of failure) this list (where a \nfew team members are).\n\n-- \nOlivier Thereaux - W3C - QA : http://ww.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-10960507"}, {"subject": "Re: [checklink] New location for doc pag", "content": "On Sun, 2002-10-20 at 23:55, Olivier Thereaux wrote:\n\n> On Monday, Oct 21, 2002, at 01:47 Asia/Tokyo, Ville Skytt? wrote:\n> > So unless somebody objects, I'll put the checklink doc page in CVS into\n> > validator/htdocs/checklink.html.  When that is publicly available\n> > somewhere, eg. deployed on validator.w3.org, we'll redirect the old doc\n> > URI to that one.\n> \n> We can redirect, or proxy. Either will be acceptable.\n> \n> When/if you need to change things on the www.w3.org, you can ask me, or \n> (better, to avoir having a single point of failure) this list (where a \n> few team members are).\n\nOk, I'll put the page to CVS as outlined above, then.  Proxying might\nnot work if (when?) I update the page to take advantage of Validator's\nSSI things but that's not at the top of my todo list.\n\n> Olivier Thereaux - W3C - QA : http://ww.w3.org/QA/\n\nHmm, ww.w3.org ? :)\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10968777"}, {"subject": "Re: [checklink] New location for doc pag", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>Ok, I'll put the page to CVS as outlined above, then.  Proxying might\n>not work if (when?) I update the page to take advantage of Validator's\n>SSI things but that's not at the top of my todo list.\n\nWhat makes you think Proxying won't work? Last-Modified? That's supposed to\nwork even if this is SSI (that's what XBitHack is for (among other things).\n\n\nOn a slightly different note, I think it would probably be usefull to\nintegrate checklink and check more on v.w3.org. As it is they seem to be\ntwo completely different tools despite being linked at the hip in CVS.\n\nLonger term I still think the brunt of both should be made into modules and\nlet CGI switches decide what gets output froma single CGI application. But\nuntil we get there, perhaps we could look at integrating the web sites (the\n*.html files, basically)? Combined docs, and perhaps two Submit buttons for\nthe same FORM field (\"Check Markup\" and \"Check Links\")?\n\n\n-- \n\"See... *That* is the problem... Scotch is for sipping, relaxing, and deep\n thoughts... Jack is what you drink when you need to work through the pain.\"\n                                                                                                                   -- John C. Welch\n\n\n\n", "id": "lists-017-10977265"}, {"subject": "Re: [check] Status and Progres", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>But how about using XSLT for the \"templating\" instead of\n>some Perl stuff?  Dunno if the XML generation for XSLT should be\n>templatized or hardcoded in Perl, though...\n\nI have several reservations about using XSLT. Apart from a general dislike\nfor that way of doing things, my experience is that the current crop of\ntools aren't up to the task.\n\nIOW, a lot of people will have to talk very fast to convince me to use\nanything but HTML::Template (or the equivalent). :-)\n\n\nAt least for the first cut I think HTML::Template is necessary if for no\nother reason then because I'm familiar with it and I'm definitely not\nfamiliar with XSLT. IOW, using XSLT would carry significant overhead while\nI familiarized myself with it and slow development down.\n\n\n\n", "id": "lists-017-10986219"}, {"subject": "Re: [checklink] New location for doc pag", "content": "On Mon, 2002-10-21 at 21:18, Terje Bless wrote:\n\n> >Ok, I'll put the page to CVS as outlined above, then.  Proxying might\n> >not work if (when?) I update the page to take advantage of Validator's\n> >SSI things but that's not at the top of my todo list.\n> \n> What makes you think Proxying won't work? Last-Modified? That's supposed to\n> work even if this is SSI (that's what XBitHack is for (among other things).\n\nD'oh, there were some key words missing from my post.  The SSI mechanism\nshould work just fine when proxied, but I have a hunch that the relative\nlinks contained in them, eg. in header.html won't, unless practically\neverything in v.w3.org is proxied.  Haven't really thought about this\ntoo much, but redirection seems more hassle-free to me.\n\n> On a slightly different note, I think it would probably be usefull to\n> integrate checklink and check more on v.w3.org. As it is they seem to be\n> two completely different tools despite being linked at the hip in CVS.\n> \n> Longer term I still think the brunt of both should be made into modules and\n> let CGI switches decide what gets output froma single CGI application. But\n> until we get there, perhaps we could look at integrating the web sites (the\n> *.html files, basically)? Combined docs, and perhaps two Submit buttons for\n> the same FORM field (\"Check Markup\" and \"Check Links\")?\n\nSounds good to me.  Maybe a good start would be to add the checklink doc\npage into docs/checklink.html (maybe it's better under docs/), and\nadding an entry into docs/index.html.\n\nI don't currently have a publicly accessible site available for\nprotoing; the new dev box would be very much welcome...\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-10994530"}, {"subject": "Re: [check] Status and Progres", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>>Going forward I'm thinking we'll call a public beta ASAP.\n>\n>Agreed.\n\nOk. Since nobody is yelling \"WAIT\", I'll move ahead with that at some point\nduring the next 24-48 hours.\n\n\n>>I'll advertize the hell out of it anywhere I can think of\n>>(mailinglists, newsgroups, etc.) and hopefully we'll get all the\n>>\"Dude, you *suck*!\" messages _before_ we update :80 with the new\n>>version this time. :-)\n>\n>I wonder if it will benefit from an \"official\" voice (e.g calls for\n>reviews sent with a W3 address) and if it needs any \"coverage\", i.e if\n>we should ask the comm to talk about it. I'm tempted to think the\n>answer to the former might be \"yes\", whereas comm coverage can wait\n>for the \"real update\". I'm wishing to hear other opinions, though.\n\nI don't want to involve Comms in this for the beta, but anything coming\nfrom @w3.org is going to catch more eyes then @pobox.com so if you want to\ntake on that bit it would be great. My initial thought of where to send an\nannouncement includes:\n\nwww-validator\nwww-html\ncomp.infosystems.www.<somewhere>\n\nwith specially adapted notes to:\n\n#validator\n#rdfig\nThe MathML list\nThe WAI ER IG list\nZeldman (since people keep quoting him at me)\n\nIn addition, I was thinking of dropping a personal note to the following\npeople and groups:\n\nTodd Fahrner |\nEric Meyer   |- (All of whom I've talked Validator with off-list)\nTantek ?elik |\n.no web design newsgroups\nBBSW Web Authoring list\n\nIf anyone has more ideas then please do holler! The more of these places\n(apart from the latter group) get a note from @w3.org the better, but if\nyou're not a USENET kind of guy, I'm sure we could persuade Nick to post to\nciwah (right Nick?).\n\n\nBelow is a first cut of a release announcement:\n\n-- cut here\n -=====================================================================-\n |                        Public Beta Test of The                      |\n |                     W3C MarkUp Validation Service                   |\n -=====================================================================-\n\nAfter about a year of saying \"Real Soon Now[tm]\", a new version of the\nW3C MarkUp Validation Service is now available for testing.\n\n                    <URL:http://validator.w3.org:8001/>\n\nThis is a public beta test of the new version before it is released in\nproduction. This implies that the code is _not_ ready for use in a\nproduction environment. If you have somehow managed to find a \"Mission\nCritical\" use for the MarkUp Validator you are insane and should probably\nbe restrained to prevent doing harm to yourself. :-)\n\nThere is no fixed schedule for the final release of this new version, but\nwe sincerely hope to get it out the door before the end of the year; much\nsooner if we can manage it. Depending on the amount and nature of the\nfeedback we recieve the release may be dubbed \"Final Release\" in a matter\nof weeks!\n\nWe are looking for feedback on all aspects of the MarkUp Validator, but we\nare in particular interested to hear from people who experience problem\nwith the new version that do not exist in the current stable release. Other\nspecific areas we are particularly interested in feedback on include:\n\n    * Problems with the current stable release that are fixed in\n      the new version.\n\n    * The new design for the web interface and the website.\n\n    * Any and all problems related to the Accessibility of the web\n      interface and website[0].\n\n    * The documentation (Yes, Virginia, there really _is_ documentation\n      for the MarkUp Validator!).\n\n    * Missing features[1] etc.\n\nBut don't let that hold you back! We are looking for any and all feedback\n-- good or bad! -- for all aspects of the service. Don't hesitate to drop\nus a note no matter how little the issue. In particular, don't assume\nsomething is so obvious that we're surely aware of it! Send it in anyways.\nReally!\n\n\nC O N T A C T:\n\n    The main contact point for feedback on the W3C MarkUp Validation\n    Service is the publically archived mailinglist <www-validator@w3.org>.\n    You can subscribe to this list by sending a message to\n\n        <www-validator-request@w3.org>\n\n    with the word \"subscribe\" in the Subject field. To view the archives of\n    this list you can visit\n\n        <URL:http://lists.w3.org/Archives/Public/www-validator/>.\n\n    Several of the developers also frequent the IRC channel #validator\n    on OPN (irc.openprojects.net).\n\n\nW H A T ' S  N E W\n\n    The majority of changes in this new version are either bug fixes or\n    internal restructuring to facilitate future development. Significant\n    changes include:\n\n    * Valid Result Pages now show more human readable results and less\n      technical detail. This behaviour may be changed if significant\n      negative feedback surfaces (so don't forget to send us feedback!).\n\n    * Character Encoding issues are more fully handled and the majority of\n      the Character Encoding related code has been rewritten. This should\n      mean better and more robust handling of Character Encodings --\n      particularly for non-US/European Encodings -- but is also stricter\n      with sloppy encoding declarations and malformed encoded documents\n      (Windows-1252 users take note!).\n\n    * Source Code is now always displayed if a page contains errors.\n\n    * More error message now have explanations, and the explanations have\n      been improved. We are still looking for contributions of more\n      explanations and improvements of the existing explanations.\n\n    * Many more Document Types are supported, and many DTDs have been\n      updated to more recent versions.\n\n    * An ecclectinc assortment of minor tweaks and changes that have\n      accumulated over the past year; too numerous and finicky to be\n      mentioned. :-)\n\n\nC R E D I T S\n\n    The W3C MarkUp Validator was created by Gerald Oskoboiny and is\n    now maintained by members of the W3C QA Activity Team and external\n    collaborators. The W3C Team Contacts for the W3C MarkUp Validator\n    are Olivier Thereaux <ot@w3.org> and Dominique Haza?l-Massieux\n    <dom@w3.org>. Much of the i18n code was written from scratch by\n    Martin D?rst <duerst@w3.org>.\n\n    Significant external contributions were made by many, including:\n\n      * Aaron Swartz      * Jim Ley         * Nick Kew\n      * Christian Smith   * Karl Dubost     * Olivier Thereaux\n      * Dan Connolly      * Liam Quinn      * Sean Palmer\n      * Hugo Haas         * Martin D?rst    * Ville Skytt?\n\n    In addition, the developers would like to acknowledge the following\n    people who have contrubuted suggestions, bug reports, and feeback:\n\n    * Bj?rn H?rhmann\n    * Peter K. Sheerin\n\n    As well as the many many good people on www-validator who have\n    contributed of their time and experience to help improve the\n    Validator. Many thanks to you all!\n\n\n\n[0] - Please note that while we've made some advances towards making the\n      MarkUp Validator Accessible, there are still likely to be many issues\n      remaining and they probably will not be dealt with this time around.\n      If you can volunteer any time towards helping us with this, please\n      drop us a note to that effect. When we start the work -- in a future\n      version -- we'll need help with the Accessibility aspects from the\n      early development work and close cooperation with testers and\n      collaborators with Accessibility experience.\n\n[1] - Please note that the featureset for this release of the MarkUp\n      Validator is largely frozen -- with a few key exceptions -- and\n      any feedback on new features will go into the development effort\n      for the next version (which will happen in paralell with\n      maintenance releases).\n-- cut here\n-- \nEditor's note: in the last update,   we noted that Larry Wall would \"vomment\"\non existing RFCs. Some took that to be a cross between \"vomit\" and \"comment.\"\nWe are unsure of whether it was a subconscious slip or a typographical error.\nWe are also unsure of whether or not to regret the error.      -- use.perl.org\n\n\n\n", "id": "lists-017-11003427"}, {"subject": "RE: Are IDNs allowed in http IRIs", "content": "It seems like a pretty big change to the IRI concept to have\nIRI -> URI transformations use scheme-specific knowledge.\nFormerly, IRI -> URI transformation was specified as scheme\nindependent.\n\nI understand that this seems necessary because of IDN, but\nit's a big concern.\n\nAnd to use \"SHOULD\" would leave us subject to\nthe indeterminate knowledge of which method is going to\nbe used.\n\nIf you believe that IRI->URI needs to be scheme specific,\nthen is it really tractable to define IRI as a generic concept?\nDo we need a separate spec for \"http:\", \"mailto:\", \"ftp:\" IRIs,\nwhere each specifies the punycode vs. hex-encoding of the\nvarious parts? For example, a 'data' IRI might need a separate\nspecification for the default MIME type (since text/plain\ndefaults US-ASCII). And an IRI URN might also have a\ndifferent mapping, etc.\n\nLarry\n\n\n> \n> \n> Adam, I think you have a valid point, I would however make a \n> simpler suggestion, which is two fold:\n> \n> - introduce the concept of IRI used as presentation element \n> of URI protocol element. In that sense \n> http://jos%e9.example.net/ is a presentation element for the \n> following protocol element http://xn--jos-dma.example.net/ \n> and as you noted http://jos%C3%A9.example.net/ is not a \n> correct URI (per RFC 2616 referring to host itself defined in \n> RFC 2396). I have suggested text in that sense to the IRI \n> main editor (Martin). Having the concept of presentation \n> element validates http IRIs which exist de facto, whatever we \n> like it or not.\n> \n> - add text in the IRI spec saying the following:\n> <<\n> When an IRI is converted to a URI, the conversion SHOULD use \n> scheme-specific knowledge to convert appropriate components \n> where the scheme syntax prevents the usage of percent-encoded \n> text into such components. Lack of scheme-specific knowledge \n> (or failure to use it) can cause valid IRIs to be converted \n> to invalid URIs that contain percent-encoded non-ASCII text \n> where they are not permitted.\n> >>\n> It is my opinion that anybody in its right mind would \n> implement IRI to URI mapping considering all the schemes \n> where 'host' is used and map accordingly (ie use Punycode). \n> My text avoids direct reference to ACE which is in my opinion \n> unnecessary in the IRI spec and also makes the suggestion to \n> use scheme aware mapping much stronger (SHOULD instead of \n> MAY). It is a SHOULD instead of a MUST simply because a \n> scheme may be updated in the future, making the scheme \n> awareness eventually not necessary.\n> \n> Michel\n\n\n\n", "id": "lists-017-1101483"}, {"subject": "Re: [checklink] New location for doc pag", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>Haven't really thought about this too much, but redirection seems more\n>hassle-free to me.\n\nAgreed.\n\n\n>I don't currently have a publicly accessible site available for\n>protoing; the new dev box would be very much welcome...\n\nAs mentioned off-list, I have a box available that I can give you access to\nto (throwaway Red Hat 8.0 install just used temporarily for smoketesting).\n\n-- \n\"Hath no man's dagger here a point for me?\"   - Leonato, Governor of Messina.\n                   See Project Gutenberg <URL:http://promo.net/pg/> for more.\n\n\n\n", "id": "lists-017-11021136"}, {"subject": "Re: [check] Status and Progres", "content": "On Mon, 21 Oct 2002, Terje Bless wrote:\n\n> Ville Skytt <ville.skytta@iki.fi> wrote:\n> \n> >But how about using XSLT for the \"templating\" instead of\n> >some Perl stuff?  Dunno if the XML generation for XSLT should be\n> >templatized or hardcoded in Perl, though...\n> \n> I have several reservations about using XSLT. Apart from a general dislike\n> for that way of doing things, my experience is that the current crop of\n> tools aren't up to the task.\n\nPhooey!  Current tools process XSLT nicely, and mod_xml even lets you\npre-parse and cache the XSLT for performance.  All you have to do is\nlook a bit further than Perl's rather embryonic XML support.\n\n> At least for the first cut I think HTML::Template is necessary if for no\n> other reason then because I'm familiar with it and I'm definitely not\n> familiar with XSLT. IOW, using XSLT would carry significant overhead while\n> I familiarized myself with it and slow development down.\n\nIndeed.  Something to use for new developments, rather than the existing\nvalidator and forthcoming release.  Where's that new server?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11028896"}, {"subject": "Re: [check] Status and Progres", "content": "On Tuesday, Oct 22, 2002, at 05:03 Asia/Tokyo, Terje Bless wrote:\n\n> Ok. Since nobody is yelling \"WAIT\", I'll move ahead with that at some \n> point\n> during the next 24-48 hours.\n\nAs said on IRC, after discussion with Martin on the  i18n code, \"go \nahead\".\nLet's give ourselves 24 hours for details (e.g announcement, choosing \ntargets etc) and do it.\n\n> I don't want to involve Comms in this for the beta\n\nOk, good.\n\n> , but anything coming\n> from @w3.org is going to catch more eyes then @pobox.com so if you \n> want to\n> take on that bit it would be great. My initial thought of where to \n> send an\n> announcement includes:\n\n\n> www-validator\n> www-html\n> Zeldman (since people keep quoting him at me)\n\nI can do those easily, others if you want (e.g math and ER WGs).\n\n\n> If anyone has more ideas then please do holler!\n\nI think I'd also post a note (maybe not the full announcement, but a \nlink to it) to the EO list (public-evangelist), plus (obviously) the \nW3C team.\n\n\n> Below is a first cut of a release announcement:\n\nMinor comments inline.\n\n>  If you have somehow managed to find a \"Mission\n> Critical\" use for the MarkUp Validator you are insane and should \n> probably\n> be restrained to prevent doing harm to yourself. :-)\n\nHmm hmm. At least I'd be very clear that the danger is in the beta one. \nI don't want to carry the message that the validator is not reliable.\n\n\n>     * The new design for the web interface and the website.\n\nI'd rather avoid the word \"design\". Discussing the UI will be \ninteresting, but I don't really want people to argue to death about \ncolour, shapes, style etc.\n\n\n>     * The documentation (Yes, Virginia, there really _is_ documentation\n>       for the MarkUp Validator!).\n\n:)\n\n[snip, the rest is fine]\n-- \nOlivier\n\n\n\n", "id": "lists-017-11037611"}, {"subject": "[check][logval] automating validator's testing using logvalidato", "content": "A few days ago, I wrote :\n\n> As a sidenote, during the QA Team face-to-face I received the AI to \n> work on completing and (semi)-automating the \"test\" suite for the \n> validator. (will talk about this in another mail, later)\n\nSo, here's the plan...\n\nAs far as I know, there are \"test files\" here and there, that are used \nto test the validator's behaviour, either when changing the prod \ninstance, or just to test the dev one.\n\nI know at least :\nhttp://validator.w3.org/dev/tests/\nhttp://www.w3.org/2002/09/xhtml-i18n-tests/\nand I guess Masayasu Ishikawa (HML activity lead) has tons of others.\n\nSome tests are here to check error messages, strange cases, etc, but \nmost of those are either \"should be valid\" or \"should be invalid\". It \nshould be straightforward to automate this using the logvalidator, and \nit should save a lot of time.\n\nThe logvalidator is usually fed logs (hence the name...) but it's easy \nto make it run on a specific list of URIs.\n\nSimple (very basic) use of the logval to test the validator would be to \nrun both (\"should be valid\" and \"should be invalid\") lists through it \nand check \"by hand\" that the results are correct. Refinements could \ninclude analysis of the results, diff-ing the results for tests run on \nthe prod validator and on the tested instance, etc.\n\nThis, of course, relies on the HTTP headers feature of the validator, \nand if this one is broken or simply not working (e.g on the current \n:80), it won't work.\n\nThoughts?\n\nP.S: logvalidator at http://www.w3.org/QA/Tools/LogValidator\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11046346"}, {"subject": "[check] announcement, amende", "content": "First, thanks Terje for coming up with the initial text.\n\nHere are the changes I'm planning to make\n\n> This is a public beta test of the new version before it is released in\n> production. This implies that the code is _not_ ready for use in a\n> production environment. If you have somehow managed to find a \"Mission\n> Critical\" use for the MarkUp Validator you are insane and should \n> probably\n> be restrained to prevent doing harm to yourself. :-)\n\nI'm not a fan of legalese verbiage, but I think the following would be \nmore appropriate for an official announcement:\n\nThis is a public beta test of the new version before it is released in \nproduction. This implies that the code is _not_ ready for use in a \nproduction environment. If you are making a \"Mission Critical\" use of \nthe validator you should not rely on this beta version. On a more \ngeneral note, please remember that the Markup validator software and \nservice are provided as is and with no warranty.\n\n\n>     * The new design for the web interface and the website.\n\nbecomes :\n  * The new web site and user interface.\n\nI will use this version (unless someone strongly objects) for the \nannouncements to w-v and www-html, then will drop a note to other w3c \nlists, and will contact a few people (including the WASP).\n\nTerje, can I ask you to take care of the people/lists you know \npersonnally? I can post to newsgroups, but will have to set up a news \nclient first (as I said, been a while...).\n\nNow may or may not be an appropriate moment for that, but I sincerely \nthank everyone for their work, making this long-awaited move possible...\n\nThanks.\n-- \nOlivier\n\n\n\n", "id": "lists-017-11055207"}, {"subject": "Re: [check] announcement, amende", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>I'm not a fan of legalese verbiage, but I think the following would be\n>more appropriate for an official announcement:\n\nSpoilsport! :-)\n\n\n>Terje, can I ask you to take care of the people/lists you know\n>personnally?\n\nYup; as I mentioned, the ones in the last group I intend to notify\npersonally. I just mentioned them \"FYI\" so y'all know where the\nannouncement goes.\n\n\n>I can post to newsgroups, but will have to set up a news\n>client first (as I said, been a while...).\n\nI'm going to assume Nick will pick up on the announcement when you send it\nto w-v and send it (adapted if/as necessary) to ciwah and whatever other\nnewsgroups seems appropriate. Perhaps the uk.* web groups?\n\nHmmm. How about the HWG? Since Gerald volunteers(-ed?) as a listadmin+ over\nthere, he could perhaps suggest and/or post to whatever lists are\nappropriate there?\n\n\n>Now may or may not be an appropriate moment for that, but I sincerely\n>thank everyone for their work, making this long-awaited move\n>possible...\n\nNot the least of which is the excellent support you have provided. Many\nthanks Olivier!\n\n\n\n-- \n\"Temper Temper! Mr. Dre? Mr. NWA? Mr. AK, comin?\n straight outta Compton and y'all better make way?\"            -- eminem\n\n\n\n", "id": "lists-017-11063959"}, {"subject": "Re: [check] Status and Progres", "content": "At 22:03 +0200 2002-10-21, Terje Bless wrote:\n>Todd Fahrner |\n>Eric Meyer   |- (All of whom I've talked Validator with off-list)\n>Tantek ?elik |\n>.no web design newsgroups\n>BBSW Web Authoring list\n\n\nI'm on Webdesign-l, I can do that one.\nxmlfr.org\nxmlhack.com\nSlashdot\nhttp://www.wpdfd.com/\n\nThe text is fine. Modifications of Olivier are great too.\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-11072702"}, {"subject": "Re: [check] Status and Progres", "content": "At 21:38 +0200 2002-10-16, Terje Bless wrote:\n>And speaking of the next version...\n>them. And, for extra kicks, I want to strip out all embedded/hardcoded HTML\n>snippets from the code and replacing them with a templating system\n>(probably i18n-ing the validator in the process).\n\nI think it's a very good idea that will help to make it more \ninternational and more flexible. Exactly like the CSS validator, it \nwill open the door to help mesages in french, german, etc.\n\n>That's probably more then enough to completely destabilize the code for a\n>good clip so if anyone thinks we ought be a bit more carefull now is the\n>time to holler before I go wild. :-)\n\nIs there a way to pull out piece by piece? or is it better to restart \nfrom scratch. If it's the second solution is it better to create a \nnew CVS tree to maintain it?\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-11080204"}, {"subject": "Re: [check][logval] automating validator's testing using  logvalidato", "content": "At 12:08 +0900 2002-10-22, Olivier Thereaux wrote:\n>Simple (very basic) use of the logval to test the validator would be \n>to run both (\"should be valid\" and \"should be invalid\") lists \n>through it and check \"by hand\" that the results are correct. \n>Refinements could include analysis of the results, diff-ing the \n>results for tests run on the prod validator and on the tested \n>instance, etc.\n>\n>Thoughts?\n>\n>P.S: logvalidator at http://www.w3.org/QA/Tools/LogValidator\n\nI think we'll have to verify and check the test.\n\nA test can be an invalid HTML file or a valid HTML file. So we'll \nhave correct and incorrect file so this is the association of URIs + \nResult which will be meaningful.\n\n1=ValidY= Success\n0=InvalidN= Failed\nvalidityValidatorPassed\n---------------------------------------------------\n  uri10  0Y\n  uri2   1  1Y\n  uri301N\n  uri410N\n\nThis Test suite is crucial for the reliability of the HTML validator \nfor different reasons:\nPeople who own website\nTR/ space at W3C, the HTML validator is one of his main tool.\n\nI think a mention, when the validator is released, must be made about \nthe fact that it has been verified against the Test Suite xxx.\n\nA mini process for TS should be done too. Something light but that \nwill help to maintain the test files.\n\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-11088473"}, {"subject": "[check] announcement sent (pointer", "content": "Announcement sent to www-validator and www-html (with mail-followup-to \nthe former).\nPointer to the text, if you want to send just a link:\nhttp://lists.w3.org/Archives/Public/www-validator/2002Oct/0058.html\n\nW3C Team, Math and WAI-ER groups on the way.\n\nPlease report here when you've sent yours.\n\nThank you.\n-- \nOlivier\n\n\n\n", "id": "lists-017-11097206"}, {"subject": "Re: [check] Status and Progres", "content": "At 16:58 -0400 2002-10-22, Karl Dubost wrote:\n>I'm on Webdesign-l, I can do that one.\n>xmlfr.org\n>xmlhack.com\n>Slashdot\n>http://www.wpdfd.com/\n\nAll done. Allready quoted in xmlhack newswire.\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-11103902"}, {"subject": "[check] add 'beta' to beta service pages / wrong commit", "content": "Hi.\n\nAs suggested by Karl, I tried to add a [beta] flag to the title/banner \nof the beta service.\n\nUnfortunately I'm yet to be familiar with CVS tagging, and I think I \ncommited only to the HEAD, but not to the 0.6.0-beta.\nI, therefore, didn't update the files on :8001.\n\nIf someone can fix my mistake, thanks in advance :)\n-- \nOlivier\n\n\n\n", "id": "lists-017-11111074"}, {"subject": "Re: [check] Status and Progres", "content": "Terje Bless <link@pobox.com> wrote:\n\n>#rdfig, Todd Fahrner, Eric Meyer, Tantek ?elik, .no web design\n>newsgroups, BBSW Web Authoring list\n\n... Have now all recieved a note about the new version.\n\n\nThe first comments from DanC on #rdfig arrived after ~25 seconds! :-)\n\n-- \n\"Violence accomplishes nothing.\"   What a contemptible lie!    Raw, naked\n violence  has  settled  more  issues  throughout  history than any other\n method ever employed.  Perhaps the city fathers of Carthage could debate\n the issue, with Hitler and Alexander as judges?\n\n\n\n", "id": "lists-017-11118406"}, {"subject": "closed issue [bidiDigits18] (was: Re: Bidi: now I'm confused", "content": "Hello Roy, others,\n\nAs proposed, I have added an additional example (example 10) in\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri-06.txt\n(and also in http://www.w3.org/International/iri-edit/BidiExamples).\n\nI'm herewith closing this issue\n(http://www.w3.org/International/iri-edit/#bidiDigits-18).\nPlease tell me if you think that's not enough\n(and in that case, if possible, what else is needed).\n\nRegards,   Martin.\n\n\n\nAt 15:50 03/09/08 -0400, Martin Duerst wrote:\n\n>Hello Roy,\n>\n>I think that in general, you are right about your analysis.\n>Having labels (or other components) with numbers only may\n>lead to ambiguous displays. I seem to remember that we were\n>actually aware of that fact, but there was not much to do\n>about it:\n>\n>- There currently are labels with only digits in the DNS,\n>   outlawing them is not an option. (it would have been nice\n>   if we could have said that the same restrictions apply\n>   for digits and LTR letters as they do for digits and RTL\n>   letters)\n>- Very explicitly for IDN, but also in many ways for IRIs,\n>   it is highly undesirable to have inforced restrictions\n>   on two or more labels/components. (note that this may be\n>   somewhat different for the LHS side)\n>\n>I have created an issue for this for the IRI draft, at\n>http://www.w3.org/International/iri-edit#bidiDigits-18.\n>\n>I propose to address this by adding text that points out\n>such cases and warns against them (without going as far as\n>actually prohibiting them). I hope that this is acceptable\n>for you.\n>\n>By the way, the alternative of having components displayed\n>strictly LTR was what we had for a long time. The two problems\n>with this approach are:\n>- It does not seem to correspond with what Arabic and Hebrew\n>   writers do naturally, in particular for freestanding domain\n>   names.\n>- It would require much more control over the contexts of\n>   IRI display than we think will be available (if we get\n>   an overall context of LTR reasonably widely implemented,\n>   I think we already have achieved something).\n>\n>Regards,    Martin.\n>\n>\n>\n>At 15:08 03/09/07 +0100, Roy Badami wrote:\n>\n>\n>>Ok, I have a problem with what I understand to be the display model\n>>for IDNA and IRI (and presumably by extension IMA).\n>>\n>>I'm assuming that the display model is 'render using bidi in an LTR\n>>context'.\n>>\n>>Specifically, the IRI draft says:\n>>\n>>   When rendered, bidirectional IRIs MUST be rendered using the Unicode\n>>   Bidirectional Algorithm [UNIV4], [UNI9]. Bidirectional IRIs MUST be\n>>   rendered with an overall left-to-right (ltr) direction.\n>>\n>>The latter requirement isn't specified in bidi-speak, but is\n>>presumably to be interpreted as saying they must be rendered at an\n>>even embedding level.  Actually, this isn't quite enough in the\n>>general case, since what comes before the string may affect weak type\n>>resolution, but since IRIs generally start with a latin letter\n>>(generally 'h' :) this isn't really much of a problem.\n>>\n>>So lets for the moment assume that the display model is that IDNs,\n>>IRIs, IMAs are rendered at an even embedding level, such that the\n>>IDN/IRI/IMA constitutes the sole text in the level run.  (This can\n>>easily be achieved by bracketing the string with LRE and PDF prior to\n>>rendering.)\n>>\n>>Consider the domain:\n>>\n>>123.ARAB.com (logical order)\n>>123.BARA.com (display order)\n>>\n>>now consider the domain:\n>>\n>>ARAB.123.com (logical order)\n>>123.BARA.com (display order)\n>>\n>>Ergo, we need another display model; this one doesn't work, at least\n>>not if we don't want two completely different domains to display\n>>identically.\n>>\n>>I recall that there was a proposal on the IDN list that domains should\n>>always be rendered with the labels appearing in order, least\n>>significant to the left and top-level domain on the right.  (This can\n>>be trivially achieved by bracketing each label with LRE/PDF,\n>>separating the labels with dots, and then bracketing the whole domain\n>>with LRE/PDF.)\n>>\n>>This would solve the above problem, but potentially might be less\n>>friendly to users of RTL languages in other ways.\n>>\n>>It also clearly is not what the authors of stringprep had in mind,\n>>since the bidi restrictions in stringprep are much stronger than would\n>>be necessary if this was the model.\n>>\n>>         -roy\n\n\n\n", "id": "lists-017-1112155"}, {"subject": "Re: [check] add 'beta' to beta service pages / wrong commit", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>As suggested by Karl, I tried to add a [beta] flag to the title/banner\n>of the beta service.\n>\n>Unfortunately I'm yet to be familiar with CVS tagging, and I think I\n>commited only to the HEAD, but not to the 0.6.0-beta. I, therefore,\n>didn't update the files on :8001.\n\nvalidator-0_6_0-beta isn't a branch tag, it's a release tag. IOW, that tag\nidentifies a fixed set of individual revisions of the files in the HEAD\nbranch. But the files on v.w3.org:8001 were checked out with\n\"validator-0_6_0-beta\" as a \"Sticky Tag\"; IOW, any \"cvs status\" or \"cvs\nupdate\" will only refer to that tag in CVS, not the latest versions.\n\nSo to make a never version eligble to update :8001, you need to move the\ntag from the version on :8001 to the version you want. You do that by doing\n(in this case):\n\n    cvs tag -F validator-0_6_0-beta header.html\n\n\nThink of it this way: \"HEAD\" is a branch of development. On this branch we\nhave the floating checkpoint \"validator-0_6_0-beta\" which is the latest\ncode in the beta series. In addition we have a few fixed tags\n\"validator-0_6_0b2\" (and before that, -b1c1 (beta 1, candidate 1)) that\nidentify a specific release of the beta series.\n\nWhen we open development on the next version, we'll branch off\n\"validator-0_6_0-branch\" as a branch tag and do new development in HEAD.\nOnce that code becomes stable we'll branch it off into\n\"validator-0_7_0-branch\". Each branch will have \"validator-0_X_X-release\"\ntags to identify a particular release so we can go back and fix minor bugs.\n\nThe released code on :80 will be \"subscribed\" to the particular release\nbranch so that a \"cvs update\" will bring in the latest version of the code\n__on_that_branch__ instead of the current development code. That lets\nupdates be done more often with little chance of snafus, and it won't hold\nback development while waiting for the inevitable bug fixes after a new\nversion is released.\n\n\nThere is of course the caveat that a new repository may be set up where the\nversion numbers and repository layout changes, but that plan is easily\nadoptable still.\n\n\nWell, or that's what I'm thinking anyways. Y'all feel free to chime in. :-)\n\n\n-- \n\"A plague o' both your houses! I am sped.\" - Mercutio, kinsman to the Prince.\n                   See Project Gutenberg <URL:http://promo.net/pg/> for more.\n\n\n\n", "id": "lists-017-11126355"}, {"subject": "Bug Fixes Managemen", "content": "Hi,\n\nIs it possible to fill a page with each time a bug has been filed by \nsomeone on the list.\n\nNumber: ex: 2002-10-21-01\nName of the Bug Submitter\nLink the mail in the archives\nTitle: abstract of the prob.\nResolution: to fill later, link to the mail which explains the resolutions.\n\nMaybe it's already in place but it could help to avoid to have to \nexplain a multiple time the same things.\n\nWhat do you think? too complex?\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-11136220"}, {"subject": "Re: Bug Fixes Managemen", "content": "Karl Dubost <karl@w3.org> wrote:\n\n>Is it possible to fill a page with each time a bug has been filed by\n>someone on the list.\n\nPossible? Yes. But...\n\nIf we're to have this -- and I do think it would be a very very good idea\n-- the two options I see are:\n\n    1) a W3C general but public Bugzilla, or...\n    b) a Validator-specific Bugzilla.\n\nYou could of course use some other bug tracking tool, but Bugzilla seems\nsuitable. The main point is that we need some real bug/issue tracking\nsystem. Not some manually updated web page or our own cobbled together CGI\nscripts.\n\nIf push comes to shove, I can probably find a box and set it up here. But I\ndon't know that I can committ to hosting \"The W3C Validator Bug Tracker\" on\na permanent basis.\n\n\n-- \nInterviewer: \"In what language do you write your algorithms?\"\n    Abigail: English.\nInterviewer: \"What would you do if, say, Telnet didn't work?\"\n    Abigail: Look at the error message.\n\n\n\n", "id": "lists-017-11143340"}, {"subject": "Re: Bug Fixes Managemen", "content": "On Wed, 2002-10-23 at 15:47, Terje Bless wrote:\n> \n> Karl Dubost <karl@w3.org> wrote:\n> \n> >Is it possible to fill a page with each time a bug has been filed by\n> >someone on the list.\n> \n> Possible? Yes. But...\n> \n> If we're to have this -- and I do think it would be a very very good idea\n> -- the two options I see are:\n> \n>     1) a W3C general but public Bugzilla, or...\n>     b) a Validator-specific Bugzilla.\n\nPerhaps the new dev box [when it's up] could run Bugzilla?\n\nMore on bug fixes *during* the beta test, should bugs be fixed \"on the\nfly\" or should the code be left alone during this period?  And where to\ncommit, HEAD or to a branch/tag?\n\nAnyway, here's a couple of bugs I spotted:\n\nheader.html has:\n  <link rev=\"made\" href=\"mailto:gerald@w3.org\" />\n...perhaps that should be changed to be consistent with the footer.\n\nThere are various checks in the code like:\n  if ($File->{Type} eq 'xml')\n...which should be using the &is_xml and friends functions.  Eg. the\nnamespace for an X(HT)ML document won't be displayed because of this in\nthe results.\n\nThe namespace table rows need a colspan=\"2\" tweak.  That'll be a bug\nonly when the above one is fixed, though :)\n\n/feedback.html, the \"Usenet newsgroup\" bit needs tuning; only the group\nname should be linked, and in monospace.\n\nI have patches on hold for these, but I'll wait for the info whether any\nvalidator fixes should be committed during the test, and if, where.\n\nI'm also about to start working with checklink, clearing the patch/bug\nqueue I've received from Hugo.  He already committed one today to HEAD,\nso I guess I'll continue there as validator and checklink aren't really\nbound to each other yet.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11151779"}, {"subject": "Re: [check] announcemen", "content": "OK, I just posted to ciwah and ciwat.  Should catch the mainstream\non usenet.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11160897"}, {"subject": "Re: Bug Fixes Managemen", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>Perhaps the new dev box [when it's up] could run Bugzilla?\n\nWell, it's unlikely to be ready in time to be any use in this beta test,\nbut otherwise it's a good idea.\n\n\n>More on bug fixes *during* the beta test, should bugs be fixed \"on the\n>fly\" or should the code be left alone during this period?  And where to\n>commit, HEAD or to a branch/tag?\n\nChanges are fine so long as they are \"conservative\". :8001 is subscribed to\nvalidator-0_6_0-beta so changes on HEAD won't affect it until we move that\ntag up with \"cvs tag -F validator-0_6_0-beta\".\n\n\n>header.html has:\n><link rev=\"made\" href=\"mailto:gerald@w3.org\" />\n>....perhaps that should be changed to be consistent with the footer.\n\ns/gerald/www-validator/\n\n\n>There are various checks in the code like:\n>if ($File->{Type} eq 'xml')\n>....which should be using the &is_xml and friends functions.  Eg. the\n>namespace for an X(HT)ML document won't be displayed because of this in\n>the results.\n\nThis one takes some thinking I, uhm, \"think\" because it messes with the\nsomwhat hairy code that generates the table in the output, but if you think\nit'll be low or zero-impact go ahead and commit a fix,\n\n\n>The namespace table rows need a colspan=\"2\" tweak.  That'll be a bug\n>only when the above one is fixed, though :)\n\nAnd lands smack dab in the middle of the frightening mess that is\n\"serialize_table\" and friends. :-(\n\n\n>/feedback.html, the \"Usenet newsgroup\" bit needs tuning; only the group\n>name should be linked, and in monospace.\n\nKnock yourself out.\n\n-- \nI have lobbied for the update and improvement of SGML. I've done it for years.\nI consider it the jewel for which XML is a setting.  It does deserve a bit or\npolishing now and then.                                        -- Len Bullard\n\n\n\n", "id": "lists-017-11167823"}, {"subject": "EARL patc", "content": "Re my previous EARL patch, my use of rdf:about doesn't work:\nit causes the RDF triples to lose information.\n\nI attach a tiny patch to fix that.\n\nHope we can get some feedback from the wider RDF community:-)\n\n-- \nNick Kew\n\n\n\n\nTEXT/PLAIN attachment: cvs.diff\n\n\n\n\n", "id": "lists-017-11177162"}, {"subject": "Re: EARL patc", "content": "Nick Kew <nick@webthing.com> wrote:\n\n>Re my previous EARL patch, my use of rdf:about doesn't work: it causes\n>the RDF triples to lose information. I attach a tiny patch to fix that.\n\nApplied.\n\n\n-- \n\"Python 2.0 beta 1 is now available from BeOpen PythonLabs.   There is a long\n list of new features since Python 1.6, released earlier today. We don't plan\n on any new releases in the next 24 hours.\"  - From Python 2.0b1 Announcement\n\n\n\n", "id": "lists-017-11183942"}, {"subject": "Re: [check] Tag names always lower cas", "content": "Martin Duerst <duerst@w3.org> wrote:\n\n>Some tags still appear as upper case in error messages, e.g. the H1 and\n>H6 in:\n>\n>    Below is an outline for this document, automatically generated from\n>    the heading tags (<code>&lt;H1&gt;</code> through\n>    <code>&lt;H6&gt;</code>.)\n>\n>Because of XHTML, I think all tag names should be lower case. Anybody\n>differing?\n\nFixed. And lets do all other such instances as we find them.\n\n-- \nLadies and gentlemen, you must resist those all-too-human feelings and decide\nthis case on the evidence.    And the evidence plainly shows that Mr. Landa's\ninjuries,   disfiguring as they are,  are nowhere near as important to a free\nsociety as the fundamental right to make smart-ass remarks.   -- Katie @ AtAT\n\n\n\n", "id": "lists-017-11191127"}, {"subject": "Re: [check] Status and Progres", "content": "Karl Dubost <karl@w3.org> wrote:\n\n>>That's probably more then enough to completely destabilize the code for\n>>a good clip so if anyone thinks we ought be a bit more carefull now is\n>>the time to holler before I go wild. :-)\n>\n>Is there a way to pull out piece by piece? or is it better to restart\n>from scratch. If it's the second solution is it better to create a new\n>CVS tree to maintain it?\n\nI think perhaps restructuring CVS may be a good idea in any case. The\ncurrent CVS reflects a \"dump\" of a server layout that hasn't been relevant\nfor some time now (in particular, the httpd.conf is way out of sync with\nreality), and I know Ville has some good ideas in this area.\n\nIt's not really necessary of course; there is no reason why we couldn't\njust keep going in current CVS on a branch.\n\n-- \nThese are the same customers you are referring to whom Microsoft thought\nwould need MS Bob and the Talking Paperclip?   One thing is to give them\nenough rope to hang themselves,  but a boobytrapped thermonuclear weapon\nrunning on a rand(time) countdown... Is that really wise? - Me to MS rep.\n\n\n\n", "id": "lists-017-11198996"}, {"subject": "Re: Bug Fixes Management (bugzilla / dev box", "content": "On Wednesday, Oct 23, 2002, at 21:47 Asia/Tokyo, Terje Bless wrote:\n>\n>> Is it possible to fill a page with each time a bug has been filed by\n>> someone on the list.\n> If we're to have this -- and I do think it would be a very very good \n> idea\n> -- the two options I see are:\n>\n>     1) a W3C general but public Bugzilla, or...\n>     b) a Validator-specific Bugzilla.\n\nb) seems to be the way to go (for good or bad). We can put it on the \ndev box (as Ville said), but unfortunately I've been too busy to work \non the box. I think I'll change my plan and provide accounts without \nhaving installed all I wanted to install, so that you can start working \non the dev box soon.\n\nETA next week.\n\n> If push comes to shove, I can probably find a box and set it up here. \n> But I\n> don't know that I can committ to hosting \"The W3C Validator Bug \n> Tracker\" on\n> a permanent basis.\n\nIf it is urgent and want to host it for a week or two (because of the \nbeta), go ahead, we can export the data to the dev box when it's ready. \nNo need to host the service longer.\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11207156"}, {"subject": "Re: Bug Fixes Management (bugzilla / dev box", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>If it is urgent and want to host it for a week or two (because of the\n>beta), go ahead, we can export the data to the dev box when it's ready.\n>No need to host the service longer.\n\nOk. There's a Bugzilla up and running on http://bugs.tj.unn.no/. Go ahead\nand make accounts and register bugs. Go easy on test bugs as it's a real\nPITA to delete them (for obvious reasons). Also the box hasn't been locked\ndown __at_all__ so please don't advertize it outside of this place. Quite\napart from the issue of whether to allow J. Random User to open bugs on the\npermenent Bugzilla, I don't want to have to deal with the issues that\nraises on this quickly thrown together installation.\n\nAny new accounts created will probably not have access to do all you need\nto do. Try using it and drop me a note when you get a \"permission denied\"\nor some field isn't editable (well, or any other problem I suppose) and\nI'll try to fix it ASAP.\n\nI'm going to try to start assigning beta bugs from what's reported on the\nlists. Currently I'm thinking I'll reply to the reporter with the Bugzilla\nBug number, and reference that number in release notes for betas, so\nreporters can check that they're bugs are fixed. If we decide to let\neveryone access a permanent Bugzilla we can start referencing the URL.\n\n-- \nWe've gotten to a point where a human-readable,  human-editable text format\nforstructured data has become a complex nightmare where somebody can safely\nsay \"As many threads on xml-dev have shown, text-based processing of XML is\nhazardous at best\" and be perfectly valid in saying it.     -- Tom Bradford\n\n\n\n", "id": "lists-017-11215479"}, {"subject": "Re: Bug Fixes Management (bugzilla / dev box", "content": "At 17:52 +0200 2002-10-24, Terje Bless wrote:\n>Olivier Thereaux <ot@w3.org> wrote:\n>\n>>If it is urgent and want to host it for a week or two (because of the\n>>beta), go ahead, we can export the data to the dev box when it's ready.\n>>No need to host the service longer.\n>\n>Ok. There's a Bugzilla up and running on http://bugs.tj.unn.no/. Go ahead\n>and make accounts and register bugs. Go easy on test bugs as it's a real\n\nI tried to create an account, still waiting for the mail :)\nThe account has been created but I don't receive the mail with the password :)\n\n\n-- \nKarl Dubost / W3C - Conformance Manager\n           http://www.w3.org/QA/\n\n      --- Be Strict To Be Cool! ---\n\n\n\n", "id": "lists-017-11225296"}, {"subject": "Re: Bug Fixes Management (bugzilla / dev box", "content": "Karl Dubost <karl@w3.org> wrote:\n\n>I tried to create an account, still waiting for the mail :) The account\n>has been created but I don't receive the mail with the password :)\n\nSorry about that. I'd set Bugzilla to send email immediately instead of\nqueuing it and then forgot to start sendmail on the box. IOW the mail tried\nto relay through localhost, which didn't have a MTA running, and so\nbounced. I've submitted a \"forgot password\" request for both you and Ville\n(who'd also set up an account, dunno if he was bit by this) so you should\nrecieve the email now.\n\n-- \nI have lobbied for the update and improvement of SGML. I've done it for years.\nI consider it the jewel for which XML is a setting.  It does deserve a bit or\npolishing now and then.                                        -- Len Bullard\n\n\n\n", "id": "lists-017-11234115"}, {"subject": "Accounts on qadev / status of contributor", "content": "Hi all,\n\nAs I wrote earlier, I didn't have time to finish installing things on \nthe dev box, but feel now is a good time to start using it.\n\nSo here we go. Please read everything carefully, there are important \ndetails).\n\nTechnical details\n--------------------------------------\nThe box is a bi pIII-550, 256M ram, and a hardware raid1 box with two \n40G HDD.\nCurrently installed is debian unstable, not much more.\nThe box is pretty much standalone in the w3 network, and is hosted in \nJapan.\n\nI'll create everyone(on this list)'s account on monday (2002-10-28).\nNick, I need your ssh (v1) public key to create your account.\n\n\nStatus of contributors\n--------------------------------------\nWe should clarify everyone's status.\nThe situation is clear for W3C Team members, but for \"contributors\" it \nwas not clear until now.\n\nTools development contributors are a special instance of collaborators, \nas defined in [1]. Collaborators are usually in the member realm and \ndealing with W3C core business, specifications, whereas here, it is \npublic and about software, hence the collaborator agreement is not \nimmediatly applicable.\nHowever, what is applicable :\n- point 1,2,3,4,5 of collaborator agreement [1]\n- software contribution agreement [2]\n\nI need a mail (sent to this list for the record) from all contributors \nnot alredy involved by contract in W3C activities, that you have read \nand agreed to the points above.\n\n[1] http://www.w3.org/Consortium/Legal/collaborators-agreement\n[2] http://www.w3.org/PATCHES.html\n\nThat should be enough to have a clearer status for dev contributors.\n\nThank you.\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-11242842"}, {"subject": "Re: Some issues with the IRI document [NFCsecurity09", "content": "Hello Simon,\n\nI have definitively closed this issue. I assume this is okay with you.\n\nRegards,    Martin.\n\n>Date: Thu, 26 Jun 2003 16:44:37 -0400\n>To: Simon Josefsson <jas@extundo.com>\n>From: Martin Duerst <duerst@w3.org>\n>Subject: Re: Some issues with the IRI document [NFCsecurity-09]\n>Cc: public-iri@w3.org\n>\n>Hello Simon,\n>\n>I have looked at your issue again, and found a way to fit it into\n>the current draft. In the security section, there currently is\n>a paragraph saying:\n>\n> >>>>\n>    Spoofing can occur for various reasons.  A first reason is that\n>    normalization expectations of a user or actual normalization when\n>    entering an IRI do not match the normalization used on the server\n>    side.  Conceptually, this is no different from the problems\n>    surrounding the use of case-insensitive web servers.  For example, a\n>    popular web page with a mixed case name (http://big.site/\n>    PopularPage.html) might be \"spoofed\" by someone who is able to create\n>    http://big.site/popularpage.html.  However, the introduction of\n>    character normalization, and of additional mappings for user\n>    convenience, may increase the chance for spoofing.\n> >>>>\n>\n>I have appended this to:\n>\n> >>>>\n>    Spoofing can occur for various reasons.  A first reason is that\n>    normalization expectations of a user or actual normalization when\n>    entering an IRI, or when transcoding an IRI from a legacy encoding,\n>    do not match the normalization used on the server side.\n>    Conceptually, this is no different from the problems surrounding the\n>    use of case-insensitive web servers.  For example, a popular web page\n>    with a mixed case name (http://big.site/PopularPage.html) might be\n>    \"spoofed\" by someone who is able to create http://big.site/\n>    popularpage.html.  However, the introduction of character\n>    normalization, and of additional mappings for user convenience, may\n>    increase the chance for spoofing.  Protocols and servers that allow\n>    the creation of resources with unnormalized names, and resources with\n>    names that are not normalized, are particularly vulnerable to such\n>    attacks.  This is an inherent security problem of the relevant\n>    protocol, server, or resource, and not specific to IRIs, but\n>    mentioned here for completeness.\n> >>>>\n>\n>As I have explained earlier, I still consider this a security issue\n>much more for the particular protocol or setup than for IRIs per se,\n>and have said so.\n>\n>I hope this addresses your concerns. I am tentatively closing this\n>issue, but any comments or suggestions for improvement are welcome.\n>\n>\n>Regards,    Martin.\n>\n>\n>At 00:09 03/04/17 +0200, Simon Josefsson wrote:\n>\n>>Martin Duerst <duerst@w3.org> writes:\n>>\n>> > NFC is only required in the current draft when encoding something\n>> > from e.g. the side of a bus, or when transcoding it from a non-\n>> > Unicode encoding. This is only to provide a base level of\n>> > predictability.\n>>\n>>Section 2.4 says \"IRIs SHOULD be created using Normalization Form C\n>>(NFC).\"  I don't interprete that to only apply to the scenarios you\n>>mention, rather it seem to imply that whenever a IRI is created, by\n>>whatever process, NFC should be used.  Perhaps it can be clarified?\n>>\n>> > Still indeed this could lead to security problems with the\n>> > mechanisms you describe above, if there are two users that have user\n>> > names that only differ in normalization. But it would seem to me\n>> > that in this case, the security issue comes from these mechanisms\n>> > (or the actual use with these specific user names) rather than from\n>> > IRIs.\n>>\n>>If this is so, I believe the IRI security considerations should\n>>mention this so that people can be aware of it, and abstain from\n>>deploying IRIs in systems that behave in this way, since doing so\n>>would introduce problems.  Perhaps some properly worded text could\n>>be derived from the following strawman?\n>>\n>>    Whenever fields of an IRI are normalized, the octet representation\n>>    is modified.  While this is unavoidable if ambiguities are to be\n>>    resolved, it can raise security issues in some situations.  In\n>>    particular, if a iuserinfo field is normalized, a security protocol\n>>    expecting a certain byte sequence as a username may receive a\n>>    different one.  This can lead to interoperability failures, but\n>>    also more serious failures in systems, e.g. when the system\n>>    performs authorization based on the username.\n>>\n>>Thanks.\n\n\n\n", "id": "lists-017-1124750"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>Status of contributors\n>--------------------------------------\n>We should clarify everyone's status.\n>The situation is clear for W3C Team members, but for \"contributors\" it \n>was not clear until now.\n>\n>Tools development contributors are a special instance of collaborators, \n>as defined in [1]. Collaborators are usually in the member realm and \n>dealing with W3C core business, specifications, whereas here, it is \n>public and about software, hence the collaborator agreement is not \n>immediatly applicable.\n>However, what is applicable :\n> - point 1,2,3,4,5 of collaborator agreement [1]\n> - software contribution agreement [2]\n>\n>I need a mail (sent to this list for the record) from all contributors \n>not alredy involved by contract in W3C activities, that you have read \n>and agreed to the points above.\n>\n>[1] http://www.w3.org/Consortium/Legal/collaborators-agreement\n>[2] http://www.w3.org/PATCHES.html\n\nOk. For concience's sake I'll note a certain reservation on principle as\nregards the Confidentiality clause[0], but, yes:\n\n  \"I, THE UNDERSIGNED, HERETOFORE KNOWN AS  ``TERJE BLESS??,  HEREAFTER\n   KNOWN AS ``GAGMEWITHASPOON??  DOES DECLARE  THAT HE,  BEING OF SOUND\n   MIND AND POSESSING WHAT LITTLE FACULTY HE MAY,  HE,  GAGMEWITHASPOON,\n   HAS, TO WIT, READ THE ABOVE REFERENCED LEGAL MUMBO JUMBO AND THAT HE,\n   GAGMEWITHASPOON,   HAS,   INSOFAR  AS  POSSIBLE  FOR  A  LAY  PERSON,\n   UNDERSTOOD   THE   PREVIOUSLY   SPECIFIED   AND   REFERENCED   VOODO.\"\n\nNow aren't you glad you asked? :-)\n\n\n(\n  Ok, yes, I've read sections 1 through 5 of the Collaborators Agreement\n  as well as the Software Contribution \"Patch\" Agreement, understand the\n  requirements they impose, and agree to abide by them.\n)\n\n\nBoth of which documents, BTW, I offered to sign and send by snailmail to\nGerald when I first started throwing patches at him so I suppose in the\nlegal sense I've been bound by those terms all along.\n\n\n-- \nMy mom is a professional botanist, or, as her spousal equivalent described\nit, they'll be out hiking in the woods, she'll see a plant off by the side\nof the trail, run up to it, bend down, and start talking Latin at it.\n                                                      -- Steve VanDevender\n\n\n\n", "id": "lists-017-11252167"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>I'll create everyone(on this list)'s account on monday (2002-10-28).\n>Nick, I need your ssh (v1) public key to create your account.\n\nI'll note again that SSH Protocol Version 1 has known weaknesses --\npractical attacks as well as theoretical, IIRC -- and should be avoided\nwhere possible. Since SSH Protocol Version 2.0 clients are available for\nall relevant platforms, it should IMO be the default unless some particular\nreason (such as developers with legacy hardware/OS) exists for also\nsupporting the older version.\n\n\n\n(\n  And if Cisco supports SSH v2 in IOS 12.3 I claim credit for it as\n  I've been nagging on them about this for ages too! :-)\n)\n\n-- \nInterviewer: \"In what language do you write your algorithms?\"\n    Abigail: English.\nInterviewer: \"What would you do if, say, Telnet didn't work?\"\n    Abigail: Look at the error message.\n\n\n\n", "id": "lists-017-11262552"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "On Fri, 2002-10-25 at 05:29, Olivier Thereaux wrote:\n\n> However, what is applicable :\n> - point 1,2,3,4,5 of collaborator agreement [1]\n> - software contribution agreement [2]\n> \n> I need a mail (sent to this list for the record) from all contributors \n> not alredy involved by contract in W3C activities, that you have read \n> and agreed to the points above.\n> \n> [1] http://www.w3.org/Consortium/Legal/collaborators-agreement\n> [2] http://www.w3.org/PATCHES.html\n> \n> That should be enough to have a clearer status for dev contributors.\n\nYep, I've read these, and agree to their terms.\n\nWhat about the Access Request Form at\n<http://cgi.w3.org/MemberAccess/AccessRequest>?  IIRC I haven't\nsubmitted that, should I?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n\n", "id": "lists-017-11271616"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>What about the Access Request Form at\n><http://cgi.w3.org/MemberAccess/AccessRequest>?  IIRC I haven't\n>submitted that, should I?\n\nDo we need access to Member-space? I wouldn't think so -- not that I'm not\ncurious as to the contents of the xml-sig mailinglist archives :-) -- given\nthe whole point here is stuff like write acccess to CVS and login accounts\non a more or less completely standalone box (and protecting W3C from legal\nliability as regards the code we contribute, of course ;D).\n\nAccess to Member space also makes practical (as opposed to theoretical) the\nissue of watching what you can and can't say in public -- because then you\nare suddenly privvy to Member Confidential information -- and, frankly, I'd\njust as soon avoid being in that situation.\n\n-- \n> ...publicity rights, moral rights, and rights against unfair competition...\nWell, you've got me there.   I have no idea what any of those have to do with\nSGML. Next you'll be claiming that running NSGMLS constitutes an unauthorized\npublic performance of SGML.                                  -- Richard Tobin\n\n\n\n", "id": "lists-017-11279861"}, {"subject": "[check] Public Bugzilla", "content": "Predictably, the issue of making the bug database public has surfaced on\nw-v. Now as mentioned, the immediate reason I don't make my setup public is\nthat I don't trust the installation, robust-wise as well as security-wise.\n\nHowever, when we get a Bugzilla running hosted at W3C the question remains;\nshould the Bugzilla be public?\n\nOne caveat with a public bug database would be that we'd need the access\ncontrols to work as we want them to; so Joe R. Webduhsigner can't\naccidentally or maliciously close a bug, change milestone goals,\nassignments, or wreak other havoc. Having the ability for anyone to create\nbugs, confirm bugs, or add comments would be very good.\n\nHowever, there is also a question of what the intention behind this\nBugzilla is. Will it only host Validator and Validator-related bug\ndatabases? Or will it function as a bug database for all QA related\nDevelopment? I can easily envision circumstances where the QA Activity (or\nWG, or whatever) would need to do some closed development and keep a closed\nbug database -- some of whch circumstances I even consider valid reasons\nfor closing things up :-) -- that would ill fit with a public Bugzilla.\n\n\nThe devil's advocate bit done, however, my opinion is that the Bugzilla\nshould be set up to be public and then we (well, you, actually ;D) can deal\nwith any such \"closed development\" issues when they arrive, iff they ever\narrive. A public Bugzilla is far too usefull to let it get shot down by the\nmere theoretical possibility that some other mode of operation /may/ be\nneeded at some point in the future.\n\n\n\n-- \n\"You gonna take advice from somebody who slapped DEE BARNES?!\" -- eminem\n\n\n\n", "id": "lists-017-11289193"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "On Fri, 2002-10-25 at 21:31, Terje Bless wrote:\n> \n> Ville Skytt? <ville.skytta@iki.fi> wrote:\n> \n> >What about the Access Request Form at\n> ><http://cgi.w3.org/MemberAccess/AccessRequest>?  IIRC I haven't\n> >submitted that, should I?\n> \n> Do we need access to Member-space? I wouldn't think so -- not that I'm not\n> curious as to the contents of the xml-sig mailinglist archives :-)\n\nSeconded, both points.  Just wondering if The Process requires this,\nperhaps not.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11297751"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "On Fri, 25 Oct 2002, Olivier Thereaux wrote:\n\n> I need a mail (sent to this list for the record) from all contributors \n> not alredy involved by contract in W3C activities, that you have read \n> and agreed to the points above.\n\nI have read and agreed to the points above.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11305630"}, {"subject": "[check(link)] Use of javascript", "content": "Hi,\n\nwhat's the policy on use of JavaScript in validator or checklink?\nIs it a no-no or can it be used to enhance the UI?\n\nThere are some useful little things like focusing a default form element\nwhen a page is loaded and preventing form submission if the URL field is\nempty etc, for which IMHO JavaScript could be used.\n\nJust a notice in advance, I think \"application/x-javascript\" should be\nused for the content type for javascript, instead of \"text/javascript\"\n(*not* registered), even though using the former makes MSIE 6 to ignore\nthe scripts most of the time...\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11313145"}, {"subject": "Re: [check(link)] Use of javascript", "content": "On 27 Oct 2002, Ville Skytt? wrote:\n\n> There are some useful little things like focusing a default form element\n> when a page is loaded and preventing form submission if the URL field is\n> empty etc, for which IMHO JavaScript could be used.\n\n+1\n\nThat kind of enhancement is a permanent lurker on my todo list.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11320618"}, {"subject": "Re: [check(link)] Use of javascript", "content": "On Monday, Oct 28, 2002, at 01:02 Asia/Tokyo, Ville Skytt? wrote:\n> what's the policy on use of JavaScript in validator or checklink?\n\nI'm not sure there's any such thing as a policy for this.\n\nMy policy, if any, would be that if it's valid/standard and usable with \nany agent, there's no reason not to use it.\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11328311"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "On Saturday, Oct 26, 2002, at 02:07 Asia/Tokyo, Terje Bless wrote:\n\n>\n> Olivier Thereaux <ot@w3.org> wrote:\n>\n>> I'll create everyone(on this list)'s account on monday (2002-10-28).\n>> Nick, I need your ssh (v1) public key to create your account.\n>\n> I'll note again that SSH Protocol Version 1 has known weaknesses\n\nActually for the dev box we can do as we want, so ssh2 keys are OK.\nHowever, for cvs commit ability we'll need a ssh1 key anyway (at some \npoint).\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11336053"}, {"subject": "[server] accounts create", "content": "I have created accounts, with the \"usual\" login name, for : Dom, Karl, \nMartin, Nick, Terje, Ville (and me).\n\nAccounts should work (except Nick's, we still need to work the ssh key \nout), if they don't, drop me a line.\n\nNo need to be lenghty about the usual \"be careful, no abuse, etc\", I \nassume. If you want to install something, just go ahead if it's a small \ntool, lib, etc. Just try to document what you've done here, so that we \ndon't step on each others' toes. For bigger things, we have this lists.\n\nDrop me a line if you need (to know) something.\n\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-11344064"}, {"subject": "Re: [check(link)] Use of javascript", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>On Monday, Oct 28, 2002, at 01:02 Asia/Tokyo, Ville Skytt? wrote:\n>>what's the policy on use of JavaScript in validator or checklink?\n>\n>I'm not sure there's any such thing as a policy for this.\n>\n>My policy, if any, would be that if it's valid/standard and usable with\n>any agent, there's no reason not to use it.\n\nLike Nick, adding suitable little bits if JavaScript has been on my TODO\nfor ages (and I've been bugging Jim Ley about adding some ;D). It obviously\nneeds to be super-carefull not to make any stupid mistakes that might\nlegitimize stuff like browser-sniffers to Joe R. Wubduhsigner, but even\nmore, it would be nice to be able to act as a showcase for JavaScript\n__done_right__!\n\nIOW, Accessible and inclusionary JavaScript would be a big plus as far as\nI'm concerned...\n\n\n-- \nEverytime I write a rhyme these people thinks its a crime\nI tell `em what's on my mind. I guess I'm a CRIMINAL!\nI don't gotta say a word I just flip `em the bird and keep goin,\nI don't take shit from no one. I'm a CRIMINAL!\n\n\n\n", "id": "lists-017-11351521"}, {"subject": "Re: Accounts on qadev / status of contributor", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>On Saturday, Oct 26, 2002, at 02:07 Asia/Tokyo, Terje Bless wrote:\n>>I'll note again that SSH Protocol Version 1 has known weaknesses\n>\n>Actually for the dev box we can do as we want, so ssh2 keys are OK.\n>However, for cvs commit ability we'll need a ssh1 key anyway (at some\n>point).\n\nSpeaking of the CVS server, now that we have the current maintainer of\nFreeBSD-cvsweb on board, any chance of looking at updating the cvsweb\ninstallation on dev? My biggest gripe is the fubar line spacing in Annotate\nand the biggest wishlist is enscripted/color-coded output of code...\n\nI /think/ the old URLs should still work (unlike with ViewCVS) and worst\ncase the two could coexist in paralell.\n\n\n-- \n\"Allright... Calm down! Relax! Start breathin?...\"         -- Dr. D.R.E.\n\n\n\n", "id": "lists-017-11359676"}, {"subject": "Re: [server] accounts create", "content": "On Mon, 2002-10-28 at 01:29, Olivier Thereaux wrote:\n\n> Accounts should work (except Nick's, we still need to work the ssh key \n> out), if they don't, drop me a line.\n\nVerified, works (after an educated guess about the name of the box,\nwhich seems to be qa-dev.w3.org in case someone else's wondering).  And\nSSH2 works as well, I already upped my v2 key there.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11368013"}, {"subject": "[check] Platform Support", "content": "Ville raised an issue recently...\n\nWe're aiming to provide both tarballs and RPMs of the Validator and OpenSP\n(the latter to ensure a compatible version is avilable regardless of what\nthe OpenSP developers decide to do). Initially, my thought was that we\nwould only support Red Hat (8.0) with the RPMs (the tarball is of course\nmore or less platform independant). But that might be construed as the W3C\nendorsing a particular vendor...\n\nMy feeling is that we're supporting Red Hat with a binary installation only\nbecause that is what we are able to support -- implying among other things\nthat if a Debian or *BSD packager should volunteer they'd be gratefully\naccepted, of course -- and that this will not be a problem in practice.\n\nBut perhaps the resident W3Cers have guidelines and such they have to\nfollow? Opinions on the matter?\n\nSince Ville is the one who will actually do (is allready doing, for that\nmatter) the RPM packaging, he'll have to speak to how Red Hat and version\nspecific the RPMs will be (cf. other RPM based ditros).\n\n\n-- \n> ...publicity rights, moral rights, and rights against unfair competition...\nWell, you've got me there.   I have no idea what any of those have to do with\nSGML. Next you'll be claiming that running NSGMLS constitutes an unauthorized\npublic performance of SGML.                                  -- Richard Tobin\n\n\n\n", "id": "lists-017-11374886"}, {"subject": "RE: Are IDNs allowed in http IRIs", "content": "Larry, it is either that (scheme-specific knowledge for the schemes that use 'host' when mapping) or the IRI spec needs to have an appendix which updates all the RFCs that currently use 'host' in their authority when specifying scheme syntax (such as RFC 2616 for http). I really don't mind either way, although the 2nd alternative could be quite a lot of work. BTW I am not sure I understand your following message:\n<<\nFor example, a 'data' IRI might need a separate specification for the default MIME type (since text/plain defaults US-ASCII). And an IRI URN might also have a different mapping, etc.\n>>\nCould you elaborate?\n\nMichel\n> -----Original Message-----\n> From: Larry Masinter [mailto:LMM@acm.org] \n> \n> It seems like a pretty big change to the IRI concept to have \n> IRI -> URI transformations use scheme-specific knowledge.\n> Formerly, IRI -> URI transformation was specified as scheme \n> independent.\n> \n> I understand that this seems necessary because of IDN, but \n> it's a big concern.\n> \n> And to use \"SHOULD\" would leave us subject to the \n> indeterminate knowledge of which method is going to be used.\n> \n> If you believe that IRI->URI needs to be scheme specific, \n> then is it really tractable to define IRI as a generic concept?\n> Do we need a separate spec for \"http:\", \"mailto:\", \"ftp:\" \n> IRIs, where each specifies the punycode vs. hex-encoding of \n> the various parts? For example, a 'data' IRI might need a \n> separate specification for the default MIME type (since \n> text/plain defaults US-ASCII). And an IRI URN might also have \n> a different mapping, etc.\n> \n> Larry\n> \n> \n> > \n> > \n> > Adam, I think you have a valid point, I would however make \n> a simpler \n> > suggestion, which is two fold:\n> > \n> > - introduce the concept of IRI used as presentation element of URI \n> > protocol element. In that sense http://jos%e9.example.net/ is a \n> > presentation element for the following protocol element \n> > http://xn--jos-dma.example.net/ and as you noted \n> > http://jos%C3%A9.example.net/ is not a correct URI (per RFC 2616 \n> > referring to host itself defined in RFC 2396). I have \n> suggested text \n> > in that sense to the IRI main editor (Martin). Having the \n> concept of \n> > presentation element validates http IRIs which exist de facto, \n> > whatever we like it or not.\n> > \n> > - add text in the IRI spec saying the following:\n> > <<\n> > When an IRI is converted to a URI, the conversion SHOULD use \n> > scheme-specific knowledge to convert appropriate components \n> where the \n> > scheme syntax prevents the usage of percent-encoded text into such \n> > components. Lack of scheme-specific knowledge (or failure \n> to use it) \n> > can cause valid IRIs to be converted to invalid URIs that contain \n> > percent-encoded non-ASCII text where they are not permitted.\n> > >>\n> > It is my opinion that anybody in its right mind would \n> implement IRI to \n> > URI mapping considering all the schemes where 'host' is \n> used and map \n> > accordingly (ie use Punycode).\n> > My text avoids direct reference to ACE which is in my opinion \n> > unnecessary in the IRI spec and also makes the suggestion to use \n> > scheme aware mapping much stronger (SHOULD instead of MAY). It is a \n> > SHOULD instead of a MUST simply because a scheme may be \n> updated in the \n> > future, making the scheme awareness eventually not necessary.\n> > \n> > Michel\n> \n> \n\n\n\n", "id": "lists-017-1138127"}, {"subject": "Re: [check] Platform Support", "content": "On Mon, 2002-10-28 at 09:42, Terje Bless wrote:\n> \n> Ville raised an issue recently...\n> \n> We're aiming to provide both tarballs and RPMs of the Validator and OpenSP\n> (the latter to ensure a compatible version is avilable regardless of what\n> the OpenSP developers decide to do). Initially, my thought was that we\n> would only support Red Hat (8.0) with the RPMs (the tarball is of course\n> more or less platform independant). But that might be construed as the W3C\n> endorsing a particular vendor...\n> \n> My feeling is that we're supporting Red Hat with a binary installation only\n> because that is what we are able to support -- implying among other things\n> that if a Debian or *BSD packager should volunteer they'd be gratefully\n> accepted, of course -- and that this will not be a problem in practice.\n\n> \n> But perhaps the resident W3Cers have guidelines and such they have to\n> follow? Opinions on the matter?\n\nYes, they'd be very much welcome at this point, before too much sweat\nhas been put into packaging.\n\n> Since Ville is the one who will actually do (is allready doing, for that\n> matter) the RPM packaging, he'll have to speak to how Red Hat and version\n> specific the RPMs will be (cf. other RPM based ditros).\n\nI haven't really tested my RPMs on anything but RH 7.3 and more\nrecently, RH 8.0; but even if the validator is platform independent,\nthere are substantial differences eg. in the Apache (config/webroot)\nlayout between distributions.  A validator RPM that runs out of the box\non whatever-you-install-it-to isn't very likely to happen, and I have\nsome doubts about providing such a spec file or source RPM too (though\nthere wouldn't be that many things one would have to change).\n\nDistributing OpenSP can be even harder, it's platform-dependent and most\nOS vendors already have an older version of it, usually bundled in a\n\"openjade\" package or something.  But then again, we can always install\nit to a \"private\" location, so it wouldn't interfere with the vendor's\npackages.\n\nI'm fine with providing an unofficial RPM of validator and it's\nrequirements for RH8 elsewhere, but would prefer if it could be\ndistributed on the validator website (with an \"unofficial\" label if need\nbe).\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11383205"}, {"subject": "Re: [check] Platform Support", "content": "A quick answer, I can investigate further if needed.\n\nFirst, I think providing packaged versions of our software is a good \nthing. It does not mean we have to spend a lot of work packaging the \nvalidator for each architecture and each packaging system.\n\nWhat we can do and this seems to be the current practice at W3C:\n\n- we provide the tarballs as the \"official\" released package,\n- depending on availability in-house, we can also provide a few \npackages. We used to have a redhat fan at W3C (Daniel Veillard, \nrpmfind's father), so for a long time we had rpm packages (etc.).\n- we welcome packages created by external contributors, and we either \nlink to them or host them, with proper credit and warning.\n\nOn Monday, Oct 28, 2002, at 16:42 Asia/Tokyo, Terje Bless wrote:\n> Initially, my thought was that we\n> would only support Red Hat (8.0) with the RPMs (the tarball is of \n> course\n> more or less platform independant). But that might be construed as the \n> W3C\n> endorsing a particular vendor...\n\nI understand some people may think so, but I wouldn't pay it much \nattention : most people would be happy to have rpm, and enemies of rpms \ncannot complain very long if we tell them we would be glad if they \ncreate their own package.\n\n\n> My feeling is that we're supporting Red Hat with a binary installation \n> only\n> because that is what we are able to support -- implying among other \n> things\n> that if a Debian or *BSD packager should volunteer they'd be gratefully\n> accepted, of course -- and that this will not be a problem in practice.\n\nExactly.\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11392288"}, {"subject": "Maintaining sgmlli", "content": "This subject came up today on ciwah.  Since I agree with the\noriginal questioner and have myself been through his frustration\nin the past, I'll raise it here.\n\nValidator, in common with various external projects, attempts to\nmaintain an up-to-date library of DTDs, modules and schemas @w3.\nOf course, given the multitude of WGs producing them and the\nfact that some of them take no notice of validator, this can\nbe challenging.  It is doubly so from outside W3C, as you\neffectively have to spider the modules[1].\n\nIf we were to run a CVS server for [sg|x]ml-lib on qa-dev, I wonder\nif it would be possible for someone to crack a whip amongst the WGs\nto ask them to contribute their work - at least when anything goes\npublic - so we can maintain a decent repository without having to\njump through hoops ourselves.\n\n\n[1] Hmmm - I wonder if I should hack up a DTD spider for exactly\n    that purpose?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11400365"}, {"subject": "Re: Maintaining sgmlli", "content": "On Wed, 2002-10-30 at 04:19, Nick Kew wrote:\n\n> If we were to run a CVS server for [sg|x]ml-lib on qa-dev, I wonder\n> if it would be possible for someone to crack a whip amongst the WGs\n> to ask them to contribute their work - at least when anything goes\n> public - so we can maintain a decent repository without having to\n> jump through hoops ourselves.\n\nI like the idea a lot (and we happened to discuss this with Terje a few\ndays ago).  Tarballs and clearly labeled \"releases\" would make this even\nbetter.  And everything, of course, properly catalogued (SGML catalogs,\nOASIS XML catalogs).\n\nYes, please,\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11408176"}, {"subject": "[check] added site/comma tool", "content": "Hi,\n\nI've added site tools to the httpd config. I have not tagged it so that  \nwe can discuss it (if needed) and enable it in next beta.\n\nThe comma tools I have added are :\n,text ,validate ,checklink ,checklinks ,rchecklink ,rchecklinks ,tablin  \n,detab ,headers\n(these are \"vanilla\" and work as at W3C's main site)\n\n,cvs ,cvslog\nFor these (they do the same thing) it either:\n- shows the /httpd/cgi-bin tree if called from check or checklink\n- shows the file CVS history otherwise\n\nI think I'll create a small page a la http://www.w3.org,tools to  \nexplain those (and then I'll add \",tools\") next week. (I plan to take  \nsome time to work on the doc next week, and this fits in...)\n\nIf you have any comment, other tools you think are worth adding,  \nplease... if not, FYI.\nhttp://dev.w3.org/cvsweb/validator/httpd/conf/ \nhttpd.conf.diff?r1=1.14&r2=1.15&f=h\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11415749"}, {"subject": "Re: [check] Public Bugzilla", "content": "Hi Terje, All.\n\nOn Saturday, Oct 26, 2002, at 04:52 Asia/Tokyo, Terje Bless wrote:\n>\n> One caveat with a public bug database would be that we'd need the \n> access\n> controls to work as we want them to; so Joe R. Webduhsigner can't\n> accidentally or maliciously close a bug, change milestone goals,\n> assignments, or wreak other havoc. Having the ability for anyone to \n> create\n> bugs, confirm bugs, or add comments would be very good.\n\nHmm, yes, a read-only bugzilla may certainly be less useful, but at \nleast it would be better than nothing at all. However, I believe \nbugzilla is flexible enough, and we could give \"visitors\" the proper \nrights while avoiding abuses. ...Or maybe not, at least the group \neditor does not seem flexible enough.\nhttp://bugs.tj.unn.no/editgroups.cgi\n\n\n\n> However, there is also a question of what the intention behind this\n> Bugzilla is.\n\nMy plan would be to use it for public bug tracking of public QA \nsoftware dev.\nIf other things don't fit, then they look for another bugzilla. Simple \n:)\n\n\n>  A public Bugzilla is far too usefull to let it get shot down by the\n> mere theoretical possibility that some other mode of operation /may/ be\n> needed at some point in the future.\n\n+1. Definitely.\n\n-- \nOlivier Thereaux - W3C - QA : http://www.w3.org/QA/\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-11423402"}, {"subject": "Re: [check] added site/comma tool", "content": "Olivier Thereaux <ot@w3.org> wrote:\n\n>I've added site tools to the httpd config. I have not tagged it so that\n>we can discuss it (if needed) and enable it in next beta.\n\nGreat! Thanks Olivier.\n\n\n>,cvs ,cvslog\n\nHow about ,blame for the \"cvs annotate\" output? And perhaps an equivalent\nto recent-commits -- ,cvsci ? -- but limited to the /validator tree?\n\n\n>shows the /httpd/cgi-bin tree if called from check or checklink\n\nWhy not show the history for these?\n\n\n>I think I'll create a small page a la http://www.w3.org,tools to explain\n>those (and then I'll add \",tools\") next week. (I plan to take some time\n>to work on the doc next week, and this fits in...)\n\nAh, better and better. He does docs too! :-)\n\n-- \nOf course we are the good guys! We define what is good and evil. All other\ndefinitions are wrong, and possibly the product of a deranged imagination.\n                                                         -- Stephen Harris\n\n\n\n", "id": "lists-017-11431455"}, {"subject": "Dealing with broken HTT", "content": "I've just had email from a user who told me Page Valet declined to\nfetch his page, whereas v.w.o was happy with it.\n\nOn investigation, I found Page Valet was bailing out with a message\nabout a malformed HTTP response.  This was due to the server using\nbare LF in place of CRLF for its line endings, in violation of RFC2616.\nI've now updated Page Valet to tolerate this particular form of HTTP\nbrokenness, but issue a stern warning to the user.\n\nIt seems to me that a validator may allow a certain amount of\nerror correction, but shouldn't let anything so broken pass\nwithout comment.\n\nTerje - I can't see anything in LWP that would address this problem:\ncan you see any way of fixing this in Perl?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11492672"}, {"subject": "Dealing with broken HTT", "content": "I've just had email from a user who told me Page Valet declined to\nfetch his page, whereas v.w.o was happy with it.\n\nOn investigation, I found Page Valet was bailing out with a message\nabout a malformed HTTP response.  This was due to the server using\nbare LF in place of CRLF for its line endings, in violation of RFC2616.\nI've now updated Page Valet to tolerate this particular form of HTTP\nbrokenness, but issue a stern warning to the user.\n\nIt seems to me that a validator may allow a certain amount of\nerror correction, but shouldn't let anything so broken pass\nwithout comment.\n\nTerje - I can't see anything in LWP that would address this problem:\ncan you see any way of fixing this in Perl?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11499203"}, {"subject": "Re: Are IDNs allowed in http IRIs", "content": "Michel Suignard scripsit:\n\n> For example, a 'data' IRI might need a separate specification for the\n> default MIME type (since text/plain defaults US-ASCII). And an IRI\n> URN might also have a different mapping, etc.\n\nThis isn't really apt, because the charset parameter in MIME types tells\nhow to translate an entity body (which is made of bytes) into a character\nstream.  URIs/IRIs are already a character stream, so the question doesn't\narise.\n\n-- \n\"You know, you haven't stopped talking          John Cowan\nsince I came here. You must have been           http://www.reutershealth.com\nvaccinated with a phonograph needle.\"           jcowan@reutershealth.com\n        --Rufus T. Firefly                      http://www.ccil.org/~cowan\n\n\n\n", "id": "lists-017-1150373"}, {"subject": "[check] the case of the missing Doctype/Charse", "content": "Hi.\n\nAs far as I can tell the issue was (last) raised in this thread\nhttp://lists.w3.org/Archives/Public/www-validator/2003Mar/thread.html#42\nand can be summarized as follows:\n\nCurrently the validator considers the absence of doxtype or charset as \na fatal error not allowing it to proceed with parsing (and validation), \nthus avoiding bogus errors, but potentially repelling users who don't \nwant to fix their charset, come back, the fix the doctype, come back, \nand finally be able to see their hundreds of errors. (tsk, some people \ndon't know where the real fun is...).\n\nTerje has been implementing some fallback mechanism, which basically \ntrigger the doctype/charset override (which is, BTW, always available) \nif none is present. The question is how/when/whether to give the users \nthe choice to use this.\n\nA few possible solutions. I'll try to be objective, and will give my \nopinion on each of them in a separate message).\n\nI\n   - fatal error by default, improve warning\n   - fallback as an option (triggered by radio button)\n\nIbis\n   - fatal error by default, improve warning\n   - fallback as an option (in drop-down menu, \"detect automatically\" \nuses fallback, add blank option to not use fallback - used by default -)\n\nII\n   - fallback by default (+warning pointing to explanation(s), \n+tentative validation)\n   - (in drop-down menu, \"detect automatically\" uses fallback, add blank \noption to not use fallback)\n\nIIbis\n   - fallback by default (+ warning with explanations, + tentative \nvalidation)\n   - (in drop-down menu, \"detect automatically\" uses fallback, add blank \noption to not use fallback)\n\nIII\n   - by default, fallback, but only \"summarized\" validation, a la\n\"I have not found a _charset_|_doctype_ in your document, and will need \none to properly validate the document. (_more info_)\nIf I try to validate the document with the [foo] charset | [bar] \ndoctype, the document appears to be valid|invalid with 1242 errors\"\n   - Options to give full output of tentative validation\n\nAny preference? Other options?\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11506224"}, {"subject": "[check] Re: [Bug 77] Support for SSL/TLS (https://). also on nonstandard port", "content": "Recent mail sent by bugzilla reminding me of #77:\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=77\n>\n>            What    |Removed                     |Added\n> ----------------------------------------------------------------------- \n> -----\n>             Summary|Support for SSL/TLS         |Support for SSL/TLS\n>                    |(https://).                 |(https://). also on  \n> non-\n>                    |                            |standard ports\n\njust FYI, I expect a decision to be taken today about the SSL  \ncertificates issue for www.w3.org and other w3.org servers, which I  \nbelieve are one of the showstoppers for resolution of #77.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-11536404"}, {"subject": "Re: [check] Re: [Bug 77] Support for SSL/TLS (https://). also on nonstandard port", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nOlivier Thereaux <ot@w3.org> wrote:\n\n>just FYI, I expect a decision to be taken today about the SSL\n>certificates issue for www.w3.org and other w3.org servers, which I\n>believe are one of the showstoppers for resolution of #77.\n\nSo what was the conclusion?\n\n- -- \n> I suggest you attend some sort of anger management class....\nThat's where you learn to upset the PHBs? -- Peter da Silva\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBP0sXHaPyPrIkdfXsEQK/aACdG+UtReGY/2OIvXy/763RfNpVdw0AoKrt\ny3K4d8JWkvC7KQ4S7btn97ZP\n=wGEM\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-11544324"}, {"subject": "[check] Headsup, new beta imminent? (was: validator/misc w3c-markupvalidator.spec", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>Will there be another live beta release?  Could estimate the cost there.\n\nAs you may or may not have noticed, there is now a validator-0_6_5-beta1 tag\nin CVS and v.w3.org:8001 is updated. The general announcement of the beta will\ngo out as soon as I get around to writing it up and sending it (probably a\nlittle later today). I'm going over some final issue ATM so there may yet be a\nholdup, but it is mostly done. If you need me to delay then yell, now.\n\nNot that it is a major crisis if you need something in as I think we can allow\nourselves to keep the code on :8001 somewhat floating this round (i.e. update\nto interrim code without going through the rigmarole of a ??Release??).\n\nBTW, the new output is looking pretty spiffy if I do say so myself. Y'all\nshould make a point of checking it out if you haven't allready seen it. :-)\n\n- -- \nOf course we are the good guys! We define what is good and evil. All other\ndefinitions are wrong, and possibly the product of a deranged imagination.\n                                                         -- Stephen Harris\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBP0sYzaPyPrIkdfXsEQJrsgCgvlxoAdq6of6KDIGSNzIfh2ei2LwAoKOK\ndk5Lv6x20EyIGYfr+2y8dFov\n=WzsO\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-11553490"}, {"subject": "Re: [check] Re: [Bug 77] Support for SSL/TLS (https://). also on nonstandard port", "content": "On Tuesday, Aug 26, 2003, at 04:15 America/Montreal, Terje Bless wrote:\n>> just FYI, I expect a decision to be taken today about the SSL\n>> certificates issue for www.w3.org and other w3.org servers, which I\n>> believe are one of the showstoppers for resolution of #77.\n>\n> So what was the conclusion?\n\nWe're trying to get certificates donated by one of our members...\nIt may take time, and if it doesn't come we're likely to create our own \n(at the expense of bothering browser warnings).\n\n-- \nolivier\n\n\n\n", "id": "lists-017-11562361"}, {"subject": "CatalogueManager: maintaining and distributing up-todate SGML and  XML Catalogue", "content": "We've discussed this a couple of times with reference to the\never-changing MathML DTDs.  I've now implemented a working\nproof-of-concept for a distributed master catalogue that anyone\ncan reference to synchronise their local installation.\n\nIt's at http://valet.webthing.com/catalogue/\n(the HTML page is a placeholder I hacked together in 5 minutes)\n\nThe program uses OpenSP to read a master definition file (SGML),\nwhich defines a simple doctype and includes entities containing\ndefinitions for different document types (currently HTML, XHTML,\nDocbook, MathML, SVG, SMIL, WAP).  The user can run the program\nto sync with the \"master\" catalogue\n( http://valet.webthing.com/catalogue/master.sgml ) installing/updating\neverything it defines, or can hack local versions to customise it.\n\nThis clearly fits in with the Validator as well as with Valet,\nand I'd be happy to see it become a W3C project.  Any interest?\n\n\n-- \nNick Kew\n\nIn urgent need of paying work - see http://www.webthing.com/~nick/cv.html\n\n\n\n", "id": "lists-017-11570626"}, {"subject": "Re: Are IDNs allowed in http IRIs", "content": "At 21:46 04/03/21 -0500, John Cowan wrote:\n\n>This isn't really apt, because the charset parameter in MIME types tells\n>how to translate an entity body (which is made of bytes) into a character\n>stream.  URIs/IRIs are already a character stream, so the question doesn't\n>arise.\n\nSorry, but that's wrong. URIs are indeed sequences of characters, but\nthey stand for sequences of octets. While in many cases, this distinction\nisn't easy to see, the data: scheme provides a good example. If you\nfor example write: data:image/gif,....\nand assume you don't use base64, then you may have the character\n'3' in tha data, but that's not a '3' in the image, that's just\nthe octet 0x33 in the data for the image.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1158932"}, {"subject": "checklink credit", "content": "Hi Ville, all,\n\nDo you have a list of significant contributors for checklink? \n\nI noticed that your name is not credited in the documentation page (nor\nin the footer) and unless you prefer it that way, I'd like to add proper\ncredits for you and the other \"others\" mentioned in the checklink\nfooter.\n\nAlso, since the development of checklink and check are not necessarily\ngoing at the same pace, if you think we should (at least) put the latest\nversion on :80 just ping the list (or me).\n \n-- \nolivier\n\n\n\n", "id": "lists-017-11602069"}, {"subject": "Re: checklink credit", "content": "On Tue, 2003-12-09 at 03:51, Olivier Thereaux wrote:\n> Hi Ville, all,\n> \n> Do you have a list of significant contributors for checklink?\n\nAt least Fr?d?ric Schutz meets my personal definition of recent,\nsignificant contributor :)\n\n> I noticed that your name is not credited in the documentation page (nor\n> in the footer) and unless you prefer it that way, I'd like to add proper\n> credits for you and the other \"others\" mentioned in the checklink\n> footer.\n\nFine with me, but I'd appreciate not including my email address anywhere\nonline, as feedback and bug reports are better sent to the validator\nlist, and I receive enough spam already...\n\nBTW, the CVS version of checklink contains an embedded manual page which\nhas a AUTHOR section, currently mentioning Hugo, Renaud, me, Fr?d?ric\nand \"many other volunteers\".\n\n> Also, since the development of checklink and check are not necessarily\n> going at the same pace, if you think we should (at least) put the latest\n> version on :80 just ping the list (or me).\n\nI would appreciate that, as well as (of course) striving to get $TNV of\nvalidator out as soon as possible.\n\nReading the diffs between the current \"production\" version and the\nlatest checklink in validator-0_6_0-branch tells me that the upgrade\nwould require taking care of checklink.conf, by default in\n/etc/w3c/checklink.conf.  It's not strictly mandatory as checklink will\nrun without the config file using default settings (== disallow checking\nprivate IP addresses, send authentication info only to the host which\nrequested it).\n\nBut the current production version uses .w3.org as the \"trusted\" domain.\n\nIf you wish to preserve that, I'd suggest configuring 2 instances of\nchecklink, one without a config file for public use, and another for W3C\ninternal use, using a config file containing \"Trusted = \\.w3\\.org$\". \nSee the default config in htdocs/config/checklink.conf.\n\nTesting in :8001 first could be a good idea :)\n\n\n\n", "id": "lists-017-11609099"}, {"subject": "[check] install guide (draft", "content": "[Copy to qa-team]\n\nIf you've read the CVS logs and/or the w-v list in the past few days you\nwill have noticed that I have been enthusiastic about buidling a (good)\nguide to install the validator.\n\nOur failure to do so in the past may have been a big strategic\nmistake... Having Joe Homepage and Bill Webdesigner happily using the\nvalidator(s) and checking their small-medium content is a good thing,\nbut not necessarily very relevant compared to the millions of corporate\nWeb pages either on the Web or on intranets.\n\nI'm not rejecting the grassroot Web community, obviously, only pointing\nout that if we manage to make (more) big companies and Web agencies\nhappy users of the package [check, checklink and the logval] - which\nshare a large common infrastructure - we may have a much bigger impact\nthan we do now.\n\nThe draft is up on the beta validator site:\nhttp://validator.w3.org:8001/docs/devel\n\nI would appreciate any comment you would have to make this better. Best\nwould be if someone could follow it step by step and see how it works.\nKarl, I know you're good at this, can I count on you?\n\nNo need to announce it (+QA News?), I can take care of that when I come\nback from vacation next week.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-11617772"}, {"subject": "Re: [check] install guide (draft", "content": "Le mer 17/12/2003 ? 08:40, Olivier Thereaux a ?crit :\n> The draft is up on the beta validator site:\n> http://validator.w3.org:8001/docs/devel\n> \n> I would appreciate any comment you would have to make this better.\n\nLooks really good! I would make two pages out of it, though, since it\nseems to target two mostly different audiences:\n- possible contributors to the validator for development\n- people wanting to install the validator on a server\n\nMy fear is that the 2nd audience might get discouraged by the length of\nthe document and the gory details of the internals of the validator.\n\nMinor details follow:\n- for the versions of the Perl modules, unless the dependencies are\nstronger than I think, I suggest that the versions should be indicated\nas minimal versions (e.g. CGI (>= 2.81) )\n- a few <acronym> or <abbr> on the abbreviation could help contributors\ngetting into the project (FPI, SGML, ...)\n- move out the \"Thanks\" from the body of the text to an acknowledgment\nsection\n- the development download from CVS could be removed from the generic\ninstall guide, and moved in the separate contrib document\n- a link to a tutorial on using the CPAN installer could be useful\n- \"Copy [validatorpath]/httpd/conf/httpd.conf to\n[validatorpath]/httpd/conf/validator-httpd.conf\" is strange; why do we\nincite using a different filename than the one used in our\nrepository/tarball?\n- the configure section (but part 6) is really Apache-centric\n(configuration files, includes, restarting on change of config, etc.); I\nwould suggest making it clearer and removing the 'with apache' prefixes\n- s/webserver/Web server/\n- s/online/on-line/\n- s/mailinglist/mailing list/ (and a link to the archives would be a\ngood idea too)\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n\n", "id": "lists-017-11625880"}, {"subject": "Re: [check] install guide (draft", "content": "Le 17 d?c. 2003, ? 08:52, Dominique Haza?l-Massieux a ?crit :\n\n> Le mer 17/12/2003 ? 08:40, Olivier Thereaux a ?crit :\n>> The draft is up on the beta validator site:\n>> http://validator.w3.org:8001/docs/devel\n>>\n>> I would appreciate any comment you would have to make this better.\n>\n> Looks really good! I would make two pages out of it, though, since it\n> seems to target two mostly different audiences:\n> - possible contributors to the validator for development\n> - people wanting to install the validator on a server\n\n+1 in fact three pages.\nAn intro doc with:\nYou are a developper\nYou want to install the validator.\n\n\n- We should try to find three people who have the competences to create \nclickorama installer. I have recently installed Bloxsom (Perl) on my \nmacintosh. You download a package, you double click and it's working... \nit's very very elegant. If we can do that for the validator, it will \nhelp a lot.\n\n- Have you thought already about localization of install docs and to \nmaintain the different versions?\n\n\nGood work.\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n", "id": "lists-017-11635516"}, {"subject": "Re: [check] install guide (draft", "content": "On Wed, 2003-12-17 at 09:40, Olivier Thereaux wrote:\n\n> The draft is up on the beta validator site:\n> http://validator.w3.org:8001/docs/devel\n> \n> I would appreciate any comment you would have to make this better.\n\nI think it's better to include the CPAN module distribution and its\nversion instead of referring to individual modules for dependencies. \nOtherwise some people will install only the mentioned module and be\nsurprised that nothing actually works.  Also, mentioning LWP::UserAgent\n>= 1.90 doesn't really tell much to a non-Perl-hacker, libwww-perl >=\n5.60 is more obvious.  And the module distributions may have\ndependencies of their own, of which it doesn't IMO make sense to try to\nkeep a complete up-to-date list.\n\nThe Net-IP dependency is missing from the new doc.\n\nAn up to date list of dependencies and the older installation\ninstructions is at http://validator.w3.org:8001/source/\nCombining that and the new guide would be a good idea in order to remove\nredundancy and improve the chances that the information will be kept up\nto date.\n\n\n\n", "id": "lists-017-11644252"}, {"subject": "Re: [check] install guide (draft", "content": "Thanks all (sorry for the bulk reply) for your suggestions to the new\ninstall guide. I basically implemented most if not all of them, with \none minor point of disagreement and a few open questions.\n\nYou are of course welcome to follow-up...\n\n\nDom wrote: \n> Looks really good! I would make two pages out of it\n\nYes, I gave it a try and that's indeed better.\n \n> Minor details follow:\n> - for the versions of the Perl modules, unless the dependencies are\n> stronger than I think, I suggest that the versions should be indicated\n> as minimal versions (e.g. CGI (>= 2.81) )\n\nDone automagically by following Ville's suggestion and linking to\n/source instead of the prerequisites part of /docs/devel.\n\n> - a few <acronym> or <abbr> on the abbreviation could help contributors\n> getting into the project (FPI, SGML, ...)\n\nWill take care of that when polishing the text, i.e. when I'm happy with\nthe bulk.\n\n> - move out the \"Thanks\" from the body of the text to an acknowledgment\n> section\n\nyes\n\n> - the development download from CVS could be removed from the generic\n> install guide, and moved in the separate contrib document\n\nIn the version I have now, there are only two small notes about CVS,\nwhich should not be too misleading for people installing for the\ntarballs. I don't really want to \"copy\" the whole guide for developers\nusing CVS and this seems like a decent compromise (reserving my right to\nchange my mind without justification later... ;)\n\n> - a link to a tutorial on using the CPAN installer could be useful\n\nyes\n\n> - \"Copy [validatorpath]/httpd/conf/httpd.conf to\n> [validatorpath]/httpd/conf/validator-httpd.conf\" is strange; why do we\n> incite using a different filename than the one used in our\n> repository/tarball?\n\nThere are two config files that will always be modified when installing.\nOne is the validator'S config, which we copy to /etc/w3c/, and the other\nis the Web server's, which I suggest to copy to another location too.\nThis makes upgrading and error recovery safer.\n\nShould I explain this in the guide?\n\n> - the configure section (but part 6) is really Apache-centric\n> (configuration files, includes, restarting on change of config, etc.); I\n> would suggest making it clearer and removing the 'with apache' prefixes\n\nyes\n\n> - s/webserver/Web server/\n> - s/online/on-line/\n> - s/mailinglist/mailing list/ (and a link to the archives would be a\n> good idea too)\n\nUm did someone fix these spelling errors or did I do it in my sleep?\nThanks anyway!\n\nKarl wrote:\n>1 in fact three pages.\n>        An intro doc with:\n>                You are a developper\n>                You want to install the validator.\n\nWell, the intro doc is more or less what the /docs/ index page is\nsupposed to do, but I guess it may be improved, too...\n\n> - We should try to find three people who have the competences to create\n> clickorama installer. I have recently installed Bloxsom (Perl) on my\n> macintosh. You download a package, you double click and it's working...\n> it's very very elegant. If we can do that for the validator, it will\n> help a lot.\n\nYes, clickorama installers are a good help. That may not be very easy in \nour case because of the fact that :\n- this is server software, so we should not expect people to have a\n  GUI... even less a consistent cross-platform one (though I suppose a\ngnome installer would be cool, but a luxury given our resources)\n- dependencies and prerequisites are what make the installation\n  difficult.\n- we do have something close to \"clickorama\" with the deb and rpms done\n  by Ville and Frederic.\n\nIdeas:\n- a small shell/perl script copying files where needed (and asking\n  questions along the way) and pre-editing the conf files.\n- a dummy CPAN module taking care of the dependencies. We can't bundle\n  the validator in a CPAN module (or can we? Ville, you're our local\nexpert, do you have any idea?) but we can pretend...\n\n\n> - Have you thought already about localization of install docs and to\n> maintain the different versions?\n\nLocalization should not be too much of a problem. For the versions, I\nbelieve we just need to have the documentation fit the latest tarball\nversion. Or am I missing the point?\n\nVille Wrote:\n\n> An up to date list of dependencies and the older installation\n> instructions is at http://validator.w3.org:8001/source/\n> Combining that and the new guide would be a good idea in order to remove\n> redundancy and improve the chances that the information will be kept up\n> to date.\n\nIndeed. I moved the reference to prerequisites to this place. I'm\nconsidering simply removing the prereq part of the devel documentation\nwhen I work on it (i.e probably tomorrow)\n\n\n\nThanks again, looking at the result I think your suggestions are\nstarting to make the guide shine!\n\n-- \nolivier\n\n\n\n", "id": "lists-017-11651863"}, {"subject": "Re: [check] install guide (draft", "content": "On Thu, 2003-12-25 at 11:40, Olivier Thereaux wrote:\n\n> - a dummy CPAN module taking care of the dependencies. We can't bundle\n>   the validator in a CPAN module (or can we? Ville, you're our local\n> expert, do you have any idea?) but we can pretend...\n\nI think the CPAN dependencies-only approach works better for the\nvalidator and checklink due to configuration issues and the need for\nexternal binaries which obviously cannot be handled by CPAN.  More info\nabout Bundle modules is at\nhttp://www.cpan.org/misc/cpan-faq.html#How_make_bundle\n\nI rolled experimental, untested Bundles for both the validator and the\nlink checker, they're available at http://koti.welho.com/vskytta/\n\nIf you wish, I can upload these to CPAN for testing.  If you think it'd\nbe better to use Olivier's CPAN account for all validator related perl\nmodules there (ie. currently the same location as the LogValidator\nmodules), that's very much fine with me too.  Let me know what you\nthink.\n\n\n\n", "id": "lists-017-11663852"}, {"subject": "RE: Are IDNs allowed in http IRIs", "content": "At 09:20 04/03/19 -0800, Larry Masinter wrote:\n\n>It seems like a pretty big change to the IRI concept to have\n>IRI -> URI transformations use scheme-specific knowledge.\n>Formerly, IRI -> URI transformation was specified as scheme\n>independent.\n\nYes. I definitely want to keep it that way as much as possible.\nAt most, there should be a single bit per scheme that says\nwhether punycode should be applied to the 'host' part. But\nhopefully, even that should be transitory. In no way do I\nwant this to be a slippery slope.\n\n\n>I understand that this seems necessary because of IDN, but\n>it's a big concern.\n>\n>And to use \"SHOULD\" would leave us subject to\n>the indeterminate knowledge of which method is going to\n>be used.\n\nYes. But to a large extent, this is actually an implementation\nissue. For all those cases where IRIs are resolved directly,\nit just boils down to whether you implement the IDN->Punycode\nconversion before passing 'host' to your dns resolver code,\nor whether you beef up the code that calls the dns resolver\nwith IDN. That should be left to the application.\n\nOverall, there are three ways to use IRIs:\n\n1) direct resolution (e.g. in a browser)\n2) use just as an identifier (e.g. as a namespace)\n3) conversion to URI (e.g. for proxies,...)\n\nThe question really only turns up in case 3). In the IRI draft,\neverything is described in terms of 3), because this helps a\nlot in writing the spec, it avoids copying all the details about\nwhat an URI is, how the generic syntax works, and so on. In\npractice, straghtforward, full conversion is somewhat less\nimportant (which does not mean that it should not be defined).\n\n\n>If you believe that IRI->URI needs to be scheme specific,\n>then is it really tractable to define IRI as a generic concept?\n>Do we need a separate spec for \"http:\", \"mailto:\", \"ftp:\" IRIs,\n>where each specifies the punycode vs. hex-encoding of the\n>various parts?\n\nI very much hope not. As I have documented in the IRI draft,\nif you want to try and make everything just 'work', the\nscheme is not the limit. Host names can appear as query\nparameters in IRIs, and only (if necessary) an update of\nthe query interface (and script behind it) can actually\nlet users use IRI functionality in that case. Look for\nthe 'validator' example in the draft.\n\n\n>For example, a 'data' IRI might need a separate\n>specification for the default MIME type (since text/plain\n>defaults US-ASCII).\n\nMaybe yes. For the moment, one would have to write:\ndata:text/plain;charset=utf-8,SOME%20DATA\n(where SOME and DATA would be non-ASCII characters).\nBut how much is data: actually used just for text?\n\n\n>And an IRI URN might also have a\n>different mapping, etc.\n\nAs mentioned in the IRI draft, URNs are already defined to\nuse UTF-8 if there are some non-ASCII characters. So they\nwork together perfectly with IRIs.\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-1167380"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "On Sat, 2003-01-25 at 17:25, Ville Skytt? wrote:\n\n> I'll try to land some new code into CVS today or tomorrow for this and\n> will post a notification here.  I'll also see if I can set up a test\n> version on qa-dev.w3.org.\n\nOkay, it took a week longer than I anticipated, but the new checklink is\nin CVS.  See the changelog entry for the new features.\n\n<http://dev.w3.org/cvsweb/validator/httpd/cgi-bin/checklink.pl>\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11695821"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "On Sun, 2003-01-26 at 09:21, Olivier Thereaux wrote:\n\n> Agreed, however I think this applies more to what is called by the \n> comma tool rather than what's at validator.w3.org/checklink. In other \n> word, the comma tool could call checklink?uri=foobar&auth=w3.org \n> instead of just checklink?uri=foobar.\n> \n> Hope this makes sense.\n\nIf this is really necessary, it can be implemented (please add a RFE to\nBugzilla if so).  But the current behaviour is that unless configured\notherwise, the authentication will be sent to the hostname that\nrequested it.  I imagine this will satisfy common use cases.\n\nRegarding whether the authentication should be sent to a hostname or\ndomain if nothing was configured or given in the command line, I went\nfor the hostname.  As Olivier said, it's the safe side, not to mention\nit was easier for me to implement it :)\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11702985"}, {"subject": "Re: inaccuracies in validato", "content": "On Saturday, Feb 15, 2003, at 02:38 Asia/Tokyo, Ville Skytt? wrote:\n>> Next, I think, this code should conform to appropriate DTD. But in \n>> case ISO/IEC\n>> 15445:2000 atribute border can't be used in IMG tag.\n\n\nDamn, I did not know ISO HTML was so popular. Sheesh! :)\n\nAnyway, I think we have to release 0.6.2 soon now. I would like to do \nit this week. What do you think?\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11710554"}, {"subject": "New project on this list : Glossar", "content": "Hi all,\n\nPlease welcome Pierre Candela on the list.\nPierre will be specifically working on the W3C Glossary project, the \nlatest addition to the \"QA development\" projects.\n\nPierre, a few pointers sent by Charles yesterday to a WAI list, which \nmay be of some interest as they are \"similar work\":\n\n[[\nWordnet is a project to produce a dictionary in RDF [2], which allows \nwords\nto be classified in terms of relations to other words - for example an \neagle\nis a type of raptor, a type of bird, etc, and cat has two senses - in \none it\nis a type of mammal and in the other it is a type of whip.\n\nThe SWAD-Europe project also has some work one thesaurus development [3]\nwhich builds on (and points to) work already done in the area.\n\n[2] http://xmlns.com/2001/08/wordnet/\n[3] http://www.w3.org/2001/sw/Europe/plan/workpackages/live/esw-wp-8\n]]\n\nThanks.\n-- \nOlivier\n\n\n\n", "id": "lists-017-11718123"}, {"subject": "[check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Monday, Feb 17, 2003, at 06:46 Asia/Tokyo, Olivier Thereaux wrote:\n> Anyway, I think we have to release 0.6.2 soon now. I would like to do \n> it this week. What do you think?\n\nI had a chance to chat with Terje today, who would like a little more \ntime to clean up some code for 0.6.2.\n\nI don't have a strong opinion against waiting a few more weeks if it \nmakes sense. If we decide to wait, I'll try to work a little on the \ndocumentation (won't have time to do very much, though).\n\n-- \nOlivier \n\n\n\n", "id": "lists-017-11725458"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Mon, 2003-02-17 at 06:37, Olivier Thereaux wrote:\n\n> I had a chance to chat with Terje today, who would like a little more \n> time to clean up some code for 0.6.2.\n\nOk...\n\n> I don't have a strong opinion against waiting a few more weeks if it \n> makes sense. If we decide to wait, I'll try to work a little on the \n> documentation (won't have time to do very much, though).\n\nHere's a couple of things that should be updated (I've had the intention\nto do it but have failed so far):\n\nsource/index.html should mention the CVS branches, ie. the difference\nbetween HEAD and validator-0_6_0-branch.\n\nThe version number of the validator should be somewhere in the UI. \nMaybe a <meta name=\"generator\" content=\"W3C Markup Validator 0.6.2\" />\nwould be enough.\n\nBy the way, is it \"MarkUp\" or \"Markup\"?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11733387"}, {"subject": "Resultats intermediaire", "content": "Le fichier Tmp1.txt contient les infos extraites de QA Framework: Test \nGuidelines\nLe fichier Tmp2.txt contient les infos extraites de QA Framework: Introduction\nLe fichier Tmp3.txt contient les infos extraites de QA Framework: \nSpecification Guidelines\n\nLe fichier Fusion.txt est la fusion des infos contenues dans les fichiers \nprecedents.\n\n\n\ntext/plain attachment: Fusion.txt\n\ntext/plain attachment: Tmp1.txt\n\ntext/plain attachment: Tmp2.txt\n\ntext/plain attachment: Tmp3.txt\n\n\n\n\n", "id": "lists-017-11741731"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>source/index.html should mention the CVS branches, ie. the difference\n>between HEAD and validator-0_6_0-branch.\n\nCurrent CVS does. It also contains a link to http://validator.w3.org/dist/;\na directory that is not version controlled and where packages (tarballs,\nRPMs, and Debs) can be placed. The \"Source Code\" link in the navigation\nmenu now also always points to http://validator.w3.org/source/ instead of\nto the local installation.\n\nThat leaves just links to your main repositories for RPMs and Debs and some\nexplanations for users of same. Could you (Ville, Frederic) send me\n\"patches\" for whatever you need to make the binary dists work to your\nsatisfaction?\n\n\n>The version number of the validator should be somewhere in the UI. Maybe\n>a <meta name=\"generator\" content=\"W3C Markup Validator 0.6.2\" /> would\n>be enough.\n\n<meta name=\"revision\" content=\"1.305.2.12\" />\n\nThe output contains the CVS revision number of the \"check\" CGI script (as\nwell as the version number of the HTML Template). Do you think we need the\n\"human readable\" version number also?\n\n\n>By the way, is it \"MarkUp\" or \"Markup\"?\n\nIt's \"MarkUp\" just because I happened to like StuddlyCaps there that day\nsince that's how w3.org tends to spell it. If it irks you, feel free to do\na global search and replace on it. :-)\n\n\n\nThat leaves some documentation work from Olivier, and some collaboration on\nthe Release Notes (since I've lost track of what's happened since 0.6.1).\nY'all seem to have fixed all the bugs that cropped up (at least, there's\nnothing in Bugzilla indicating any outstanding issues).\n\n\nAnyone have anything left to deal with?\n\nI'm going to do a scan through the ~275 unread messages in my www-validator\nmailbox as time allows, but modulo that I'm not aware of any outstanding\nissues.\n\n\nPS. Frederic, I haven't heard from you in a while; ping the list with\ncurrent status of Debian packages if you have the time?\n\n-- \nNow Playing \"Hells Bells\" by \"AC/DC\"\", from the album \"Back In Black\".\n\n\n\n", "id": "lists-017-11748883"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Fri, 2003-02-21 at 16:36, Terje Bless wrote:\n\n> >source/index.html should mention the CVS branches, ie. the difference\n> >between HEAD and validator-0_6_0-branch.\n> \n> Current CVS does. It also contains a link to http://validator.w3.org/dist/;\n> a directory that is not version controlled and where packages (tarballs,\n> RPMs, and Debs) can be placed. The \"Source Code\" link in the navigation\n> menu now also always points to http://validator.w3.org/source/ instead of\n> to the local installation.\n\nAh, I wasn't aware of that.  Sounds good.\n\n> That leaves just links to your main repositories for RPMs and Debs and some\n> explanations for users of same. Could you (Ville, Frederic) send me\n> \"patches\" for whatever you need to make the binary dists work to your\n> satisfaction?\n\nMy RPM doesn't have a clean patch at the moment, but a hunk of perl code\nthat does some in-place edits to check.cfg and the httpd.conf snippet. \nIt's a perl hunk instead of a patch because it uses stuff provided by\nRPM, basically some directory locations which is better from a RPM point\nof view than a patch with \"hardcoded\" paths.  And it avoids the need for\na separate patch file.  You can see the hunk in the spec file in CVS,\nlook for \"# Localize config files\".  Yell if you need clarification on\nthat.\n\n> >The version number of the validator should be somewhere in the UI. Maybe\n> >a <meta name=\"generator\" content=\"W3C Markup Validator 0.6.2\" /> would\n> >be enough.\n> \n> <meta name=\"revision\" content=\"1.305.2.12\" />\n> \n> The output contains the CVS revision number of the \"check\" CGI script (as\n> well as the version number of the HTML Template). Do you think we need the\n> \"human readable\" version number also?\n\nYes, I do, as long as we have the \"human readable\" ones in Bugzilla and\nrefer to them in public elsewhere.  Of course, that causes some extra\nthings for the \"release manager\", but there are other places where this\nis needed anyway.  So it's just one addition to the list.\n\n> >By the way, is it \"MarkUp\" or \"Markup\"?\n> \n> It's \"MarkUp\" just because I happened to like StuddlyCaps there that day\n> since that's how w3.org tends to spell it. If it irks you, feel free to do\n> a global search and replace on it. :-)\n\nThe reason why I asked is because I have a feeling that w3.org does\n*not* tend to spell it in camelcase :).  See eg.\n<http://www.google.com/custom?q=markup&sitesearch=w3.org&domains=w3.org>...\n\nI can do the search and replace, but would like a confirmation which way\nis \"correct\" from a W3C rep.\n\n> That leaves some documentation work from Olivier, and some collaboration on\n> the Release Notes (since I've lost track of what's happened since 0.6.1).\n> Y'all seem to have fixed all the bugs that cropped up (at least, there's\n> nothing in Bugzilla indicating any outstanding issues).\n\n    cvs log -NS -rvalidator-0_6_0-release::validator-0_6_1-release\n\n...is your friend (change the release numbers as appropriate).  I think\n\n    cvs log -NS -rvalidator-0_6_1-release::\n\n...should work too, but I get a \"Terminated with fatal signal 11\" when\ntrying it.\n\n> Anyone have anything left to deal with?\n\nApart from a couple of trivial documentation updates (checklink needs\nConfig::General), nothing here that should absolutely go into 0.6.2. \nThere are some checklink bug reports that I'll be working on soon(tm),\nbut nothing critical that would prevent this release.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11760107"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>\n>My RPM doesn't have a clean patch at the moment, but a hunk of perl code\n>that does some in-place edits to check.cfg and the httpd.conf snippet.\n>It's a perl hunk instead of a patch because it uses stuff provided by\n>RPM, basically some directory locations which is better from a RPM point\n>of view than a patch with \"hardcoded\" paths.  And it avoids the need for\n>a separate patch file.  You can see the hunk in the spec file in CVS,\n>look for \"# Localize config files\".  Yell if you need clarification on\n>that.\n\nHmmm. I'm not really sure we can avoid that since RPM wants tokens -- e.g.\n%{_sysconfdir} -- in there and we want real paths. I'm not sure there is\nany problem with v.w3.org not using the config file from CVS, but it should\nbe usable for CVS/tarball users without pre-processing with RPM.\n\nThe DEBUG option has been disabled in CVS, but other then that I can't\nreally see any way to eliminate that perl chunk in the spec file.\n\n\n>>>The version number of the validator should be somewhere in the UI.\n>>\n>>[...] Do you think we need the \"human readable\" version number also?\n>\n>Yes, I do, as long as we have the \"human readable\" ones in Bugzilla and\n>refer to them in public elsewhere.\n\nOk, header.html now includes it in the initial <h1> on every page\n(including Validator output).\n\n\n>Of course, that causes some extra things for the \"release manager\",\n>but there are other places where this is needed anyway.  So it's\n>just one addition to the list.\n\nSure, it may even be helpfull in tightening up the release process.\n\n\n>>Anyone have anything left to deal with?\n>\n>Apart from a couple of trivial documentation updates (checklink needs\n>Config::General), nothing here that should absolutely go into 0.6.2.\n>There are some checklink bug reports that I'll be working on soon(tm),\n>but nothing critical that would prevent this release.\n\nWell, Checklink can be more easily updated independantly of the Validator\nso I suppose that's ok. In general I'm really hoping this will be the last\nrelease of 0.6.x before focusing on 0.7.0. At which point, BTW, I would\nlike to see Checklink and the Validator get better integrated from the POV\nof the user visiting http://validator.w3.org/.\n\n-- \nNow Playing \"What Am I Gonna Do With You\" by \"Barry White\"\", from the album\n\"The Ultimate Collection\".\n\n\n\n", "id": "lists-017-11772226"}, {"subject": "Character-by-Character Distinct IRI-&gt; Char-bychar equivalent UR", "content": "[Shifting discussion to public-iri from tag@w3.org]\n\n> >So to be clear... the IRI draft section 5.1 seems to suggest that it is \n> >possible for the IRI->URI mapping to generate superious \n> >character-by-character equivalences (between the resulting URI) from \n> >distinct IRI.\n> >\n> >If that can't in fact happen, then maybe the wording in 5.1 that \n> >suggest that it could should be changed.\n> \n> It can happen. The IRI http://www.example.org/ros&eacute; is \n> not character-by-character equivalent to the URI/IRI \n> http://www.example.org/ros%C3%A9, but when you convert the \n> IRI http://www.example.org/ros&eacute; to an URI, you get the \n> URI http://www.example.org/ros%C3%A9.\n\nSo... what other IRI, distinct from http://www.example.org/ros&eacute;\nyields URI http://www.example.org/ros%C3%A9.\n\nOh... yes I see, the IRI http://www.example.org/ros%C3%A9 (because in your\nview URI are IRI) maps to the URI http://www.example.org/ros%C3%A9.\naaaaggghhhh.\n\nThis gets us back to the question of whether IRI are intended 1) as a\nreplacement for URI as 'the' identifier for the Web, or 2) as a distinct set\nof a internationalised identifiers (distinct value space, overlapping\nlexical space wrt URI) which are mapped to URI for use in protocol elements\nthat require URI - URI then remain 'the' identifier on the Web and IRI serve\nas an internationalisation friendly form for inclusion in documents and UI\nartifacts (from which URI are generated when necessary).\n\nView 2 treats URI and IRI as different types even though there lexical forms\noverlap. In this view I'm not sure quite how the IRI\nhttp://www.example.org/ros%C3%A9 would arise.\n\nI accept that simply looking at the lexical form leaves an ambiguity about\nwhether one is looking at a URI or an IRI.\n\n> So what the IRI draft says is that if you need character-by- \n> character equivalence, for example for XML namespaces (e.g. \n> XSLT) or for RDF to match nodes in a graph, don't convert to an URI.\n\nie. you do character-by-character comparison of two IRI.\n\n> >[Also, I'm not entirely comfortable with all \"URIs are IRIs\" - but I'll \n> >dwell on that - this discomfort is at the level of whether the set of \n> >real numbers and the set of integers are disjoint or not - ie. they are \n> >different types (value-space) although the may share lexical space \n> >presentation.]\n> \n> I'm not totally familiar with this kind of philosophical discussion.\n> I tend to think about this from an operational view. Most if \n> not all operations that you can do on 'integer 2' you can do \n> on 'real 2', with the same results. Same the other way round.\n> As far as I know, all the relevant operations you can do with \n> the URI http://www.example.org/ros%C3%A9 you can do with the \n> IRI http://www.example.org/ros%C3%A9, and vice versa, with \n> the same result. So trying to distinguish them will only \n> complicate the spec, without adding anything other than \n> confusing most readers.\n\nBut you are demonstrating a situation where for two IRI x and y:\n\n(not(x == y)) && (iriToUri(x) == iriToUri(y))\n\noperationally this is also confusing.\n\nStuart\n--\n\n> -----Original Message-----\n> From: Martin Duerst [mailto:duerst@w3.org] \n> Sent: 25 March 2004 15:18\n> To: Williams, Stuart; Williams, Stuart; Ian B. Jacobs\n> Cc: tag@w3.org\n> Subject: RE: [Minutes] 22 March 2004 TAG teleconf \n> (charmodReview-17, LC-klyne26, LC-kopecky5, LC-kopecky6, \n> LC-booth3, LC-schema17)\n> \n> Hello Stuart,\n> \n> At 12:46 04/03/25 +0000, Williams, Stuart wrote:\n> > > From: Martin Duerst [mailto:duerst@w3.org]\n> \n> > > What you are looking for, namely that with respect to \n> > > character-by-character equivalence, the IRI->URI mapping would have \n> > > the property that distinct IRI map to distinct URI, is basically \n> > > impossible.\n> > >\n> > > For example, you have (in HTML notation)\n> > >     http://www.example.org/ros&eacute;\n> > > as an IRI, but because all URIs are also IRIs, you also have\n> > >     http://www.example.org/ros%C3%A9 (and three other case variants) \n> > > as an IRI. You can't have them be the same and different at the same \n> > > time.\n> >\n> >If by \"other case variants\" you're refering to variants that \n> end \"%c3%A9\"\n> \n> Yes.\n\n> >etc, that's not my concern since the IRI spec is clear that the mapping \n> >uses uppercase a-f. In anycase that would address suprious differences \n> >and the concern was triggered by the phrase \"spurious equivalence\".\n> >\n> >So to be clear... the IRI draft section 5.1 seems to suggest that it is \n> >possible for the IRI->URI mapping to generate superious \n> >character-by-character equivalences (between the resulting URI) from \n> >distinct IRI.\n> >\n> >If that can't in fact happen, then maybe the wording in 5.1 that \n> >suggest that it could should be changed.\n> \n> It can happen. The IRI http://www.example.org/ros&eacute; is \n> not character-by-character equivalent to the URI/IRI \n> http://www.example.org/ros%C3%A9, but when you convert the \n> IRI http://www.example.org/ros&eacute; to an URI, you get the \n> URI http://www.example.org/ros%C3%A9.\n> \n> So what the IRI draft says is that if you need character-by- \n> character equivalence, for example for XML namespaces (e.g. \n> XSLT) or for RDF to match nodes in a graph, don't convert to an URI.\n> \n> \n> \n> >BTW \"~\" seems to be amongst the unreserved characters in RFC2396bis and \n> >so should not be %-encoded anyway - so maybe the example in the draft \n> >IRI spec is bogus.\n> \n> It was originally not allowed in URIs. The newest URI draft \n> says that it should not be escaped, but it doesn't disallow \n> %7E or %7e.\n> \n> \n> >[Also, I'm not entirely comfortable with all \"URIs are IRIs\" - but I'll \n> >dwell on that - this discomfort is at the level of whether the set of \n> >real numbers and the set of integers are disjoint or not - ie. they are \n> >different types (value-space) although the may share lexical space \n> >presentation.]\n> \n> I'm not totally familiar with this kind of philosophical discussion.\n> I tend to think about this from an operational view. Most if \n> not all operations that you can do on 'integer 2' you can do \n> on 'real 2', with the same results. Same the other way round.\n> As far as I know, all the relevant operations you can do with \n> the URI http://www.example.org/ros%C3%A9 you can do with the \n> IRI http://www.example.org/ros%C3%A9, and vice versa, with \n> the same result. So trying to distinguish them will only \n> complicate the spec, without adding anything other than \n> confusing most readers.\n> \n> Regards,  Martin.\n> \n> \n> >Stuart\n> >--\n> >\n> > > BTW, character-by-character equivalence on IRIs is what xml \n> > > namespaces as well as RDF specify. The former is well implemented \n> > > (with IRIs, not URIs, despite the fact that the 1.0 namespace rec \n> > > says URIs) in XSLT processors. The later has tests associated, in \n> > > http://www.w3.org/TR/2004/REC-rdf-testcases-20040210/\n> > > at \"Issue: rdf-charmod-uris has 4 tests\". Late last year, \n> as shown at:\n> > > http://www.w3.org/2003/11/results/rdf-core-tests.html,\n> > > one test had 5 pass, one undecided, one fail, one test \n> had 7 pass, \n> > > and two tests had two pass and two undecided, all of \n> these very much \n> > > in similar patterns to other, unrelated tests.\n> > > Yesterday, I tested with Tim with cwm, which also \n> conformed to the \n> > > RDF REC (although at an earlier point, it didn't).\n> >\n> >I think this is also a different matter concerned with IRI<->IRI \n> >comparison testing rather than comparison of URI resulting \n> from IRI->URI mapping.\n> >\n> > >\n> > > Regards,    Martin.\n> >\n> >Stuart\n> >--\n> >\n> > >\n> > > At 14:15 04/03/24 +0000, Williams, Stuart wrote:\n> > > >Ian,\n> > > >\n> > > >Under 2.2.1...\n> > > >\n> > > >[Stuart]\n> > > >http://example.org/~user, http://example.org/%7euser, and \n> > > >http://example.org/%7Euser are not equivalent under this\n> > > definition. In\n> > > >such a case, the comparison function MUST NOT map IRIs to\n> > > URIs, because\n> > > >such a mapping would create additional spurious equivalences.\"\n> > > >\n> > > >...is part of a /me comment that went wrong. I'd be \n> happy for the \n> > > >ommitted /me line(s) that preceded these to be included in\n> > > the record\n> > > >(it would then make more sense) or for these lines to be \n> struck....\n> > > >\n> > > >[Stuart] I was disturbed to see the following in section 5.1\n> > > of the IRI\n> > > >Draft:\n> > > >\"As an example, http://example.org/~user,\n> > > http://example.org/%7euser,\n> > > >and http://example.org/%7Euser are not equivalent under this \n> > > >definition. In such a case, the comparison function MUST NOT\n> > > map IRIs\n> > > >to URIs, because such a mapping would create additional\n> > > spurious equivalences.\"\n> > > >\n> > > >Not stated on IRC, but for info... what I found distrubing\n> > > is that with\n> > > >respect to character-by-character equivalence the IRI -> URI \n> > > >mapping does not have the property that distinct IRI map to \n> > > >distinct URI, as evidenced by the quoted example from the draft.\n> > > >\n> > > >Regards\n> > > >\n> > > >Stuart\n> > > >--\n> \n\n\n\n", "id": "lists-017-1178140"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "Le Fri, 21 Feb 2003 15:36:14 +0100, tu as ecrit :\n\n>PS. Frederic, I haven't heard from you in a while; ping the list with\n>current status of Debian packages if you have the time?\n\nYes. The package is doing fine, it's been included in debian \"unstable\" in\nJanuary. No big problem discovered so far, the only real problem that I\nhave is the opensp bug that hit me a few months ago, and that has been\nreproduced by a few people using Debian (but not by Terje on several\nmachines -- of http://bugs.debian.org/170795 for more information).\nOtherwise, it's still available from my home page, for Debian woody/stable\nor testing. The woody version requires a few packages to be backported (3\nat the moment, 4 very soon) -- what was the decision about storing the\nRPM/DEBs and their dependencies on v.w.o ? \n\n>That leaves just links to your main repositories for RPMs and Debs and some\n>explanations for users of same. Could you (Ville, Frederic) send me\n>\"patches\" for whatever you need to make the binary dists work to your\n>satisfaction?\n\nI'll have to do a diff again to make sure that I don't forget anything (I\nhaven't really looked at the validator since mid-January), but I remember 2\nthings. First, I added a note on the \"source\" page saying that if you are\non a Debian system, you can see the source by doing bla bla and bla.\n\nThe second thing is about the SGML lib. At the moment, you can configure\nthe script to tell it where the SGML library is -- and the name of the\ncatalog(s) files is then hardcoded (and they are supposed to be in the same\ndirectory). This doesn't work very well if the system provides a\ncentralised catalog ! At the moment, I have just adapted sgml.soc and\nxml.soc so that they reference the Debian DTDs and I added a new\nconfiguration option (SGML Catalog if I remember well) so that I can store\nthese in a different dictionary. In the near future, I would like to use\nDebian's centralised SGML and (future) XML catalogs, and get rid of\nsgml.soc and xml.soc entirely -- this would require more changes to the\nconfiguration file.\n\nTo make a long story short, I made only ad-hoc changes to the script, and\nthere is nothing really that (sh|c)ould be directly integrated into the\noriginal source -- but it would be nice to have a more customizable way to\nspecify which catalog/sgml lib to use. Any idea ?\n\nOh, and of course, there is the Debian sub-directory, which contains all\npackaging information, but it is usually not recommended to add it to the\noriginal source -- the main reason being that the Debian developer, in\ngeneral, will not have CVS write access to the original source and he\ndoesn't want an outdated debian/ directory to overwrite his newer local\nversion when he updates to a new release.\n\nAnd last thing, a small suggestion that I remember writing in my TODO file\n(on another machine), I don't think it's been added in the CVS version yet:\nturning on the \"debug\" option should automatically turn on the \"verbose\"\noption as well, or you won't see any debugging information.\n\nFr?d?ric\n\n\n\n", "id": "lists-017-11783627"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Mon, 2003-02-24 at 05:02, Terje Bless wrote:\n\n> Hmmm. I'm not really sure we can avoid that since RPM wants tokens -- e.g.\n> %{_sysconfdir} -- in there and we want real paths.\n\nI'm actually pretty sure that we shouldn't even try to avoid that\nstuff.  I'm perfectly fine with it, but hey, you asked to see the\npatches :)\n\n>  I'm not sure there is\n> any problem with v.w3.org not using the config file from CVS, but it should\n> be usable for CVS/tarball users without pre-processing with RPM.\n\nAgreed, but there's simply no way to make it so that it pleases everyone\nout-of-the-box...\n\n> The DEBUG option has been disabled in CVS\n\nThanks for the heads up, that makes the perl hunk one line smaller :)\n\n> Ok, header.html now includes it in the initial <h1> on every page\n> (including Validator output).\n\nSounds good.\n\n> >Apart from a couple of trivial documentation updates (checklink needs\n> >Config::General), nothing here that should absolutely go into 0.6.2.\n\nOops, I was wrong about that, I already documented it some time ago. \nThe only thing left on my list is to update misc/w3c-validator.spec with\nsome educated guesses about the tarball locations and stuff.  I'm also\ngoing to rename the package to w3c-markup-validator for consistency with\nthe product name and Frederic's .debs.\n\n> At which point, BTW, I would\n> like to see Checklink and the Validator get better integrated from the POV\n> of the user visiting http://validator.w3.org/.\n\nThat'd be nice.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11795019"}, {"subject": "Glossary Work Progres", "content": "Within this mail, you'll find the following files attached:\n\nExtract.xsl: the stylesheet used to extract relevant information from the \nfollowing documents:\nhttp://www.w3.org/TR/qaframe-spec/\nhttp://www.w3.org/TR/qaframe-intro/\nhttp://www.w3.org/TR/qaframe-test/\n\nTmp1.txt, Tmp2.txt, Tmp3.txt: the output files generated by the SAXON XSLT \nprocessor when you apply the Extract.xsl stylesheet to the above documents.\n\nThe information extracted are:\n- document title\n- document version\n- number of editors\n- list of editors: fullname (contact mailbox)\n- list of terms and their definitions\n\nGlossary.txt: the fusion of the above text files. Generated by a Java routine.\n\nGlossary.rdf: the first draft (incomplete and inaccurrate) of the glossary \nusing RDF Syntax\n\nPierre Candela\n\n\n\ntext/rdf attachment: Extract.rdf\n\ntext/rdf attachment: Glossary.rdf\n\ntext/plain attachment: Glossary.txt\n\ntext/plain attachment: Tmp3.txt\n\ntext/plain attachment: Tmp2.txt\n\ntext/plain attachment: Tmp1.txt\n\n\n\n\n", "id": "lists-017-11804762"}, {"subject": "Re: Glossary Work Progres", "content": "Le mar 25/02/2003 ? 12:04, Pierre Candela a ?crit :\n> Extract.xsl: the stylesheet used to extract relevant information from the \n> following documents:\n> http://www.w3.org/TR/qaframe-spec/\n> http://www.w3.org/TR/qaframe-intro/\n> http://www.w3.org/TR/qaframe-test/\n\nA few remarks about extract.xsl:\n- it uses some saxon extension (all the elements prefixed with saxon: );\nwhile it makes life easier, I'd much prefer if you could avoid doing so,\nsince that makes your XSLT not usable in a standard xslt processor. You\ncan replace most of your use of saxon:function by equivalent named\nxsl:template (which are heavier to use, but are standard).\n \n> The information extracted are:\n> - document title\n> - document version\n> - number of editors\n> - list of editors: fullname (contact mailbox)\n\nNote that the part to extract the informations about the specification\n(title, editors, ...) is not really necessary, since there is already a\nstyle sheet that allows to extract those from a TR document:\nhttp://www.w3.org/2001/10/trdoc2rdf.xsl\nwhich itself uses a more generic style sheet to extract raw data from\nsuch document:\nhttp://www.w3.org/2001/10/trdoc-data.xslt\n\nWith xsl:import, you can directly import the features you need from one\nor the other of these style sheets.\n\n> - list of terms and their definitions\n> \n> Glossary.txt: the fusion of the above text files. Generated by a Java routine.\n> \n> Glossary.rdf: the first draft (incomplete and inaccurrate) of the glossary \n> using RDF Syntax\n\nI've already sent you my notes about the RDF syntax. Here is how should\nlook an entry in an RDF glossary. Let's assume for the time being that\nwe map one glossary into one RDF schema; for instance, we create an RDF\nschema for the glossary created in SpecGL\nhttp://example.org/specGL/20030210\nSuch a schema would contain an entry for each term looking like:\n<rdf:Description\nrdf:about=\"http://example.org/specGL/20030210#discretionaryChoices\">\n<rdfs:label xml:lang=\"en\">discretionary choices</rdfs:label>\n<rdfs:comment>a value or behavior may be chosen from a well-defined\nenumerated set of two or more possibilities</rdfs:comment>\n<rdfs:isDefinedBy\nrdf:resource=\"http://www.w3.org/TR/2003/WD-qaframe-spec-20030210/\"/>\n</rdf:Description>\n\nOne of the advantage of using RDF is that you don't need to build\nspecific tools to merge the results, since one of the by-design feature\nof RDF is its mergeability and that there are already tool to do that.\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-11813223"}, {"subject": "Glossary Work Progres", "content": "Within this mail, you'll find the following files attached:\n\nExtract.xsl: I made a few modifications regarding the use of some saxon \nextension, according to Dominique Haza?l-Massieux's feedback. (and changed \nthe file extension :)\n\nGlossary.rdf: the new draft (still incomplete but RDF Valid) of the glossary\n\nPierre Candela\n\n\n\ntext/xml attachment: Extract.xsl\n\ntext/rdf attachment: Glossary.rdf\n\n\n\n\n", "id": "lists-017-11823783"}, {"subject": "Re: Glossary Work Progres", "content": "On Tuesday 25 February 2003 14:29, Dominique Haza?l-Massieux wrote:\n>  Here is how should\n> look an entry in an RDF glossary. Let's assume for the time being that\n> we map one glossary into one RDF schema; for instance, we create an RDF\n> schema for the glossary created in SpecGL\n> http://example.org/specGL/20030210\n> Such a schema would contain an entry for each term looking like:\n> <rdf:Description\n> rdf:about=\"http://example.org/specGL/20030210#discretionaryChoices\">\n> <rdfs:label xml:lang=\"en\">discretionary choices</rdfs:label>\n> <rdfs:comment>a value or behavior may be chosen from a well-defined\n> enumerated set of two or more possibilities</rdfs:comment>\n> <rdfs:isDefinedBy\n> rdf:resource=\"http://www.w3.org/TR/2003/WD-qaframe-spec-20030210/\"/>\n> </rdf:Description>\n\nDom,\nI'm not sure I understand what you mean by \"creating an RF Schema for the \nglossary created in ...\".\nI used your pointers \"how should an entry in an RDF glossary\" and inserted it \nin my previous draft of the glossary.\nAttached to this mail is the result. (Fusion.rdf). Tell me if it's accurate.\n\nPierre Candela\n\n\n\ntext/rdf attachment: Fusion.rdf\n\n\n\n\n", "id": "lists-017-11830602"}, {"subject": "host for the test version of the CSS Validato", "content": "I may have found a computer for the test version of the CSS Validator.\nSeems that qa-dev.w3.org is dedicated for this kind of use. We can then\ndeploy a test version of the CSS Validator on it and get people to test\nit. Olivier agreed to create the appropriate accounts on this computer\nfor Yves, Sijtsche and myself (Sijtsche would have to sign or approve\nsomething I believe).\nWe may need to deploy the sources from CVS as anonymous if we want to\nuse the same copy of the repository. Olivier, can you please create a\nunix group as well for us (\"css\" or something like that)?\n\nThanks!\n\nPhilippe\n\n\n\n", "id": "lists-017-11839073"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "Frederic Schutz <schutz@mathgen.ch> wrote:\n\n>what was the decision about storing the RPM/DEBs and their\n>dependencies on v.w.o ?\n\nI've made the /source/ page point at a /dist/ directory on v.w3.org with\nthe intention that this directory will not exist in CVS. This is where I\nintended that anything downloadable should reside.\n\nWhether or not to host the binary packages and the dependencies there\ndepend entirely on what you and Ville think is best. If it is practical for\nyou and for users to host it there I think that makes sense (IIRC Olivier\nalso thinks this would be ok, right?).\n\nIt probably makes sense to keep development/interrim versions on your own\nweb sites, but I see now reason why they couldn't also be on v.w3.org if\nyou would prefer. The big hurdle is probably that it's a PITA to get things\nuploaded there ATM as Olivier and the other W3Cers are the only ones with\nsufficient privileges to put stuff in place ATM (though that can probably\nbe fixed if we need to).\n\n\n>I'll have to do a diff again to make sure that I don't forget anything\n>(I haven't really looked at the validator since mid-January), but I\n>remember 2 things. First, I added a note on the \"source\" page saying\n>that if you are on a Debian system, you can see the source by doing bla\n>bla and bla.\n\nCan this reasonably be integrated into the v.w3.org version so you won't\nhave to maintain this diff?\n\n\n>The second thing is about the SGML lib. At the moment, you can configure\n>the script to tell it where the SGML library is -- and the name of the\n>catalog(s) files is then hardcoded (and they are supposed to be in the\n>same directory). This doesn't work very well if the system provides a\n>centralised catalog ! At the moment, I have just adapted sgml.soc and\n>xml.soc so that they reference the Debian DTDs and I added a new\n>configuration option (SGML Catalog if I remember well) so that I can\n>store these in a different dictionary. In the near future, I would like\n>to use Debian's centralised SGML and (future) XML catalogs, and get rid\n>of sgml.soc and xml.soc entirely -- this would require more changes to\n>the configuration file.\n\nI'll see what I can do to make this work better for Debian. It would help\nif you could describe the directory structure and relevant filenames for\nme.\n\nVille: Can we use the vendor sgml-lib on Red Hat? Integrate with it?\n\nIn the 0.7.0 timeframe we should be able to provide a suffieciently clean\nsgml-lib package -- possibly the proposed separate DTD registry/collection\nproject -- that we could propose Red Hat use that instead/in addition to\nwhat they ship now.\n\n\n>Oh, and of course, there is the Debian sub-directory, which contains all\n>packaging information, but it is usually not recommended to add it to\n>the original source -- the main reason being that the Debian developer,\n>in general, will not have CVS write access to the original source and he\n>doesn't want an outdated debian/ directory to overwrite his newer local\n>version when he updates to a new release.\n\nIf it should become practical/necessary I'm sure we can arrange CVS write\naccess for you somehow. I dunno how fine-grained the \"ACL\" is for\ndev.w3.org, but there are other ways to arrange it if that should prove\nimpractical.\n\nVille maintains the spec file (more or less?) in CVS, but I dunno whether\nthat would make sense for you and the Debian package.\n\n\n>And last thing, a small suggestion that I remember writing in my TODO\n>file (on another machine), I don't think it's been added in the CVS\n>version yet: turning on the \"debug\" option should automatically turn on\n>the \"verbose\" option as well, or you won't see any debugging\n>information.\n\nI think I have this in my TODO somewhere too. Ping me about it if it hasn't\nbeen fixed when I tag 0.6.2 in CVS will you?\n\n\n\n-- \nNow Playing \"Let Me Put My Love Into You\" by \"AC/DC\"\",\n from the album \"Back In Black\".\n\n\n\n", "id": "lists-017-11847066"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>On Mon, 2003-02-24 at 05:02, Terje Bless wrote:\n>\n>>Hmmm. I'm not really sure we can avoid that since RPM wants tokens --\n>>e.g. %{_sysconfdir} -- in there and we want real paths.\n>\n>I'm actually pretty sure that we shouldn't even try to avoid that stuff.\n>I'm perfectly fine with it, but hey, you asked to see the patches :)\n\nOh, I meant diffs that you would like to see integrated so you wouldn't\nhave to keep patching for every release. :-)\n\n\n\n-- \nNow Playing \"Back In Black\" by \"AC/DC\"\",\n from the album \"Back In Black\".\n\n\n\n", "id": "lists-017-11859170"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Friday, Feb 28, 2003, at 13:37 US/Eastern, Terje Bless wrote:\n> Frederic Schutz <schutz@mathgen.ch> wrote:\n\n> If it is practical for\n> you and for users to host it there I think that makes sense (IIRC \n> Olivier\n> also thinks this would be ok, right?).\n\nYes.\n\n\n> The big hurdle is probably that it's a PITA to get things\n> uploaded there ATM as Olivier and the other W3Cers are the only ones \n> with\n> sufficient privileges to put stuff in place ATM (though that can \n> probably\n> be fixed if we need to).\n\nWe could proxy this particular location on v.w3.org to someplace else \nwhere it's less of a burden to give upload privileges (e.g qa-dev), or \nI can set up a cron'd sync from another location (Frederic and Ville's \nsites, etc.) Plenty of potential solutions.\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11867648"}, {"subject": "[check] New Copyright Statement (was: validator/htdocs footer.html", "content": "Olivier Thereaux <ot@abyss.w3.org> wrote:\n\n>Update of /sources/public/validator/htdocs\n>\n>Modified Files: footer.html \n>Log Message:    adding new copyright statement to footer\n\nWhy?\n\n\n\n", "id": "lists-017-11909360"}, {"subject": "Re: Type of error", "content": "Karl Dubost <karl@w3.org> wrote:\n\n>In the process of being more educative and not making people afraid, I\n>said it in the past, but I don't remember if Terje thought it would be\n>difficult to implement :)\n>\n>When we validate a Webpage, we have the number of errors which is given,\n>but not the number of errors type that have been made.\n>\n>For example if the tag ALT has been forgotten in the page 43 times, it\n>means that the same error come again and again :)\n>\n>So it could be modified in that way:\n>\n>Errors: 80 (3 types of errors) or\n>Errors: 80 (43 for ALT, 34 for TYPE, 3 no attributes \"HEIGHT\")\n>\n>In the EARL report, it's quite easy with an XSLT, but in the HTML output?\n\nIf this is \"quite easy\" with EARL and XSLT I would very much like to see an\nimplementation!\n\n\nThe first problem lies in the classification of the some odd hundred\npossible messages that can be emitted into meaningfull categories -- some\nof which would change categories depending on the exact context in which\nthey are emitted! -- only then do you get to the implementation problem of\nidentifying each message (being a variable text string) and placing it into\nthese categories.\n\nYou could of course forego the classification and just count each possible\nmessage as its own category, but this still leaves the problem of\nidentifying each message in the output. This can be achieved by \"stupid\"\npattern matching and a table of regex->category patterns, by implementing a\nmessage catalog parser that reads OpenSP's .po files, or by trapping\nOpenSP's message numbers and mapping from these and into categories.\n\nMy plan for friendlier error messages is currently to do the latter and\nhave a separate -- validator-specific -- catalog of messages indexed by\nthese error numbers (which can, BTW, be shared among all the OpenSP-based\nValidators if desired).\n\nSince OpenSP's error messages are variable, at least the initial\nimplementation would emit the original error message first, with the custom\nerror message appearing as an inline \"explanation\" (as opposed to replacing\nthe error message). This implementation also facilitates a more robust and\nmaintainable implementation of the linked error explanations and lays some\nof the groundwork for context-sensitive Tips of the Day.\n\n\nIOW it's not \"difficult to implement, it's difficult to implement _right_.\n:-)\n\n\n-- \nInterviewer: \"In what language do you write your algorithms?\"\n    Abigail: English.\nInterviewer: \"What would you do if, say, Telnet didn't work?\"\n    Abigail: Look at the error message.\n\n\n\n", "id": "lists-017-11916997"}, {"subject": "XML validator and W3 CV", "content": "I've let this drift for some time (as is my bad habit:-), but I'd like\nto introduce the XML validator into W3C CVS.  Olivier organised my CVS\naccess, and that appears to work fine.\n\nSince the XML validator is entirely separate from \"the\" validator,\nI think xml-val should be created as a new top-level project.\nAny problems with that?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11926627"}, {"subject": "Re: [check] New Copyright Statement (was: validator/htdocs footer.html", "content": "On Tuesday, Jan 7, 2003, at 00:29 US/Pacific, Terje Bless wrote:\n>> Modified Files: footer.html\n>> Log Message:    adding new copyright statement to footer\n>\n> Why?\n\nOh, yes, I wanted to drop a line here about that but have had limited \nconnectivity here (QAIG/WG face-to-face) so I let it slip.\n\nBasically, that's W3C \"policy\" to mention its policies as much as \npossible on its \"top\" page. Since W3C has changed one of its hosts on \nJan 1st, we've been trying to update the copyright/policy statements, \nand add one where missing.\n\nThe validator is one of those top pages (arguably the #1 service...) \nand lacked such a notice (there is a link to the policy in the download \nsource though, IIRC). I fixed that.\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11933837"}, {"subject": "plans for early 2003", "content": "Hi all,\n\nAfter about a month with Dom and myself more-or-less away from \n(regular) business, we're finally back.\n\nThis may be a good time to review our plans for (the beginning of) this \nyear.\n\nA few questions that may be worth discussing:\n- Any (technical/logistical) help needed? Anything not going quite as \ngood as it should?\n- Development plans (I am yet to test the newest stuff, esp. the XML \nvalidator)?\n- Hos is the Dev Team going? Too small? Should we invite other people \nin?\n- Release plans (validator's 0.6.2, publicizing the LogValidator - \nthrough a beta2 release- , others?)\n\n\nI am yet to catch up on everything that has happened during the past \nweeks, so if I say something irrelevant, please don't hesitate to tell \nme.\n\nThanks, I wish you all best for this year.\n-- \nOlivier\n\n\n\n", "id": "lists-017-11941869"}, {"subject": "Re: XML validator and W3 CV", "content": "Nick,\n\n\nOn Wednesday, Jan 8, 2003, at 06:20 Asia/Tokyo, Nick Kew wrote:\n\n>\n>\n> I've let this drift for some time (as is my bad habit:-), but I'd like\n> to introduce the XML validator into W3C CVS.  Olivier organised my CVS\n> access, and that appears to work fine.\n\nGood.\n\n> Since the XML validator is entirely separate from \"the\" validator,\n> I think xml-val should be created as a new top-level project.\n> Any problems with that?\n\nThis sounds good. However, I've been told the current practice is to \nuse \"dated space\", so the xml-validator should be under \ndev.w3.org:/sources/public/2003/xml-val(idator).\n\nThanks.\n-- \nOlivier\n\n\n\n", "id": "lists-017-11949339"}, {"subject": "Re: plans for early 2003", "content": "On Tue, 2003-01-14 at 03:34, Olivier Thereaux wrote:\n\n> - Release plans (validator's 0.6.2, publicizing the LogValidator - \n> through a beta2 release- , others?)\n\nTo the \"others\" category; I'm planning to try out Xerces-J's HTML\nvalidation capabilities sometime, just for fun, and possibly combined\nwith JavaScript parsing with Mozilla's Rhino.  And maybe CSS with the\nCSS-validator/SAC/flute code...\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11957248"}, {"subject": "Re: XML validator and W3 CV", "content": "On Mon, 20 Jan 2003, Olivier Thereaux wrote:\n\n> This sounds good. However, I've been told the current practice is to \n> use \"dated space\", so the xml-validator should be under \n> dev.w3.org:/sources/public/2003/xml-val(idator).\n\nOK, I've imported it into dev.w3.org:/sources/public/2003/xml-val\nI'm perpetually struggling with CVS, so I hope it's imported OK.\n\nThis is currently a pretty minimal import, but it's what's running\nat qa-dev.w3.org:8888 and now also at valet.webthing.com/xml-val/\n\nAt valet, I have an XML catalogue I constructed myself.  For W3,\nI want to investigate the XML components of our SGMLIB package,\nand feed it to the validator.  This remains subject to round tuits,\nand if anyone's actually installed something on qa-dev, it'll save\na lot of work if you let me know so I can just configure xml-val\nto use it.\n\nRegards,\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11964612"}, {"subject": "Re: plans for early 2003", "content": "Ville,\n\nOn Tuesday, Jan 21, 2003, at 05:32 Asia/Tokyo, Ville Skytt? wrote:\n> To the \"others\" category; I'm planning to try out Xerces-J's HTML\n> validation capabilities sometime, just for fun, and possibly combined\n> with JavaScript parsing with Mozilla's Rhino.  And maybe CSS with the\n> CSS-validator/SAC/flute code...\n\nLooks interesting. FYI, there's a new release of the CSS validator \ncoming soon, I've been told.\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11972940"}, {"subject": "Re: XML validator and W3 CV", "content": "Nick.\n\nOn Wednesday, Jan 22, 2003, at 08:29 Asia/Tokyo, Nick Kew wrote:\n\n>\n> On Mon, 20 Jan 2003, Olivier Thereaux wrote:\n>\n>> This sounds good. However, I've been told the current practice is to\n>> use \"dated space\", so the xml-validator should be under\n>> dev.w3.org:/sources/public/2003/xml-val(idator).\n>\n> OK, I've imported it into dev.w3.org:/sources/public/2003/xml-val\n> I'm perpetually struggling with CVS, so I hope it's imported OK.\n\nLooks OK from here.\n\n> This is currently a pretty minimal import, but it's what's running\n> at qa-dev.w3.org:8888 and now also at valet.webthing.com/xml-val/\n\nDo you have, or need, people playing with it at this stage, other than \njust the small qa-dev group? There's no guarantee of course, but we \ncould ask people from the XML community at W3C to test it...\n\n> At valet, I have an XML catalogue I constructed myself.  For W3,\n> I want to investigate the XML components of our SGMLIB package,\n> and feed it to the validator.  This remains subject to round tuits,\n> and if anyone's actually installed something on qa-dev, it'll save\n> a lot of work if you let me know so I can just configure xml-val\n> to use it.\n\nI'm not sure. I don't remember how far we went in our discussions about \nsgml-lib...\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-11980153"}, {"subject": "Re: XML validator and W3 CV", "content": "On Wed, 22 Jan 2003, Olivier Thereaux wrote:\n\n> \n> Nick.\n> \n> On Wednesday, Jan 22, 2003, at 08:29 Asia/Tokyo, Nick Kew wrote:\n> \n> >\n> > On Mon, 20 Jan 2003, Olivier Thereaux wrote:\n> >\n> >> This sounds good. However, I've been told the current practice is to\n> >> use \"dated space\", so the xml-validator should be under\n> >> dev.w3.org:/sources/public/2003/xml-val(idator).\n> >\n> > OK, I've imported it into dev.w3.org:/sources/public/2003/xml-val\n> > I'm perpetually struggling with CVS, so I hope it's imported OK.\n> \n> Looks OK from here.\n\n:-)\n\n> > This is currently a pretty minimal import, but it's what's running\n> > at qa-dev.w3.org:8888 and now also at valet.webthing.com/xml-val/\n> \n> Do you have, or need, people playing with it at this stage, other than \n> just the small qa-dev group? There's no guarantee of course, but we \n> could ask people from the XML community at W3C to test it...\n\nWatch this space.  And hassle me if I go quiet on it.\n\nI certainly have issues with it.  One is to improve the output:\nfor that I need to hack in to Xerces itself to extract the info\nI'm looking for (unless someone has a better idea).  Another\nis setting up the XML catalogue and lib - and that's something\nI'd really like help with (I could just copy stuff from Valet,\nbut I *know* that's a homebrew and has gaps in it).\n\nApart from that, I'd really like to see it tested properly -\nEg for those of you in .jp, does it cope with CJK?  And do we\nhave a test corpus anywhere?   Bjoern has been my best critic,\nbut neither he nor I can expect to see everything.\n\n> I'm not sure. I don't remember how far we went in our discussions about \n> sgml-lib...\n\nAnyone?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-11988732"}, {"subject": "Re: Character-by-Character Distinct IRI-&gt; Char-by-char   equivalent URI (issue #IRIURIcharequiv20", "content": "Hello Stuart,\n\nMany thanks for forwarding this discussion to public-iri. I have listed\nthis as an issue at\nhttp://www.w3.org/International/iri-edit/Overview.html#IRIURIcharequiv-20.\n\nAt 16:38 04/03/25 +0000, Williams, Stuart wrote:\n\n>[Shifting discussion to public-iri from tag@w3.org]\n>\n> > >So to be clear... the IRI draft section 5.1 seems to suggest that it is\n> > >possible for the IRI->URI mapping to generate superious\n> > >character-by-character equivalences (between the resulting URI) from\n> > >distinct IRI.\n> > >\n> > >If that can't in fact happen, then maybe the wording in 5.1 that\n> > >suggest that it could should be changed.\n> >\n> > It can happen. The IRI http://www.example.org/ros&eacute; is\n> > not character-by-character equivalent to the URI/IRI\n> > http://www.example.org/ros%C3%A9, but when you convert the\n> > IRI http://www.example.org/ros&eacute; to an URI, you get the\n> > URI http://www.example.org/ros%C3%A9.\n>\n>So... what other IRI, distinct from http://www.example.org/ros&eacute;\n>yields URI http://www.example.org/ros%C3%A9.\n>\n>Oh... yes I see, the IRI http://www.example.org/ros%C3%A9 (because in your\n>view URI are IRI) maps to the URI http://www.example.org/ros%C3%A9.\n>aaaaggghhhh.\n>\n>This gets us back to the question of whether IRI are intended 1) as a\n>replacement for URI as 'the' identifier for the Web, or 2) as a distinct set\n>of a internationalised identifiers (distinct value space, overlapping\n>lexical space wrt URI) which are mapped to URI for use in protocol elements\n>that require URI\n\nMy answer here is:\n- both, depending on the situation\n- this might look bothering, but it really isn't much of an issue\n\n\n>- URI then remain 'the' identifier on the Web and IRI serve\n>as an internationalisation friendly form for inclusion in documents and UI\n>artifacts (from which URI are generated when necessary).\n\nOnce most of what the users will see are IRIs, I'm not sure\nit's appropriate to call them 'UI artifacts'. Users will\njust see them, and probably talk about them as URLs, not even\nURIs, because they haven't yet learned that the 'politically\ncorrect' name is now URI.\n\n\n>View 2 treats URI and IRI as different types even though there lexical forms\n>overlap. In this view I'm not sure quite how the IRI\n>http://www.example.org/ros%C3%A9 would arise.\n\nHopefully not too often. But somebody can just write it down,\nas it is written down in this email. You are right that it should\nbe very rare, but from a spec point of view, the question is how\nto disallow it. We can't disallow percent-escaping because that\nwould disallow http://www.example.org/ros%E9, which has to be\nlegal for backwards compatibility purposes (and is different\nfrom the above).\n\n\n>I accept that simply looking at the lexical form leaves an ambiguity about\n>whether one is looking at a URI or an IRI.\n\nYes, of course. And often (e.g. on a napkin or a business card),\nthat's the only thing you have.\n\n\n> > So what the IRI draft says is that if you need character-by-\n> > character equivalence, for example for XML namespaces (e.g.\n> > XSLT) or for RDF to match nodes in a graph, don't convert to an URI.\n>\n>ie. you do character-by-character comparison of two IRI.\n\nYes.\n\n\n> > >[Also, I'm not entirely comfortable with all \"URIs are IRIs\" - but I'll\n> > >dwell on that - this discomfort is at the level of whether the set of\n> > >real numbers and the set of integers are disjoint or not - ie. they are\n> > >different types (value-space) although the may share lexical space\n> > >presentation.]\n> >\n> > I'm not totally familiar with this kind of philosophical discussion.\n> > I tend to think about this from an operational view. Most if\n> > not all operations that you can do on 'integer 2' you can do\n> > on 'real 2', with the same results. Same the other way round.\n> > As far as I know, all the relevant operations you can do with\n> > the URI http://www.example.org/ros%C3%A9 you can do with the\n> > IRI http://www.example.org/ros%C3%A9, and vice versa, with\n> > the same result. So trying to distinguish them will only\n> > complicate the spec, without adding anything other than\n> > confusing most readers.\n>\n>But you are demonstrating a situation where for two IRI x and y:\n>\n>         (not(x == y)) && (iriToUri(x) == iriToUri(y))\n>\n>operationally this is also confusing.\n\nLooks like it may create problems. But up to now, I haven't heard\nabout any. This situation is very similar to a situation purely\non URIs. It is very easy to construct two URIs that are guaranteed\nto always resolve to the same thing but that don't compare\ncharacter-by-character equivalent.\n\nFor example http://www.example.org/ (1) and http://www.example.org (2).\nThe URI spec says that these are equivalent, but they identify\ntwo different namespaces, and they identify two different nodes\nin an RDF graph. So we could indeed create two different types,\nlet's call them aURI (the ones that are only equivalent if they\nare character-by-character equivalent) and bURI (they are\nequivalent in some more cases, as far as the URI spec allows).\n(1) and (2) are the same bURI, but a different aURI. And you\ncan't even know whether they are aURIs or bURIs by just looking\nat them. So which ones are 'the' identifier for the Web?\naURIs or bURIs?\n\n\nSo in summary:\n- This issue is not a problem because very similar issues also\n   exist with URIs themselves.\n- Given that IRIs allow (many) more characters than URIs, but we\n   want IRIs that are also URIs (or if you prefer: that also look\n   like URIs) to map to themselves, it is impossible to preserve\n   the same equivalence classes for character-by-character on IRIs\n   and on URIs. So there does not seem to be a solution\n   (if you know about one, please tell us).\n- There is already a clear warning in the draft about this, which\n   seems to have been clear enough to catch your attention.\n\nI therefore am tentatively closing this issue with 'no action needed'.\nIf you think that some change to the document is needed, please say\nso (ideally with some actual proposed text).\n\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-1199315"}, {"subject": "[checklink] HTTP basic authenticatio", "content": "Hmm,\n\nI just realized that checklink defaults to '\\.w3\\.org' as the \"trusted\ndomain\" regexp, ie. it's not possible currently to use HTTP basic\nauthentication with resources whose uri doesn't match this.  Eek.\n\nAdditionally, I think that regexp is not the best possible default.\n\nSanity checking myself, how does this sound to you:\n\n1) The default is the hostname (or domain) of the first encountered\n   resource requiring basic authentication.  Hostname or domain?\n2) We can't ask this multiple times in the online version.  Actually, we\n   can only ask it before any output has been sent, which means that it\n   is supported only for resources in the same domain|hostname as the\n   initial URI.\n3) The command line version could ask it multiple times whenever\n   needed, unless a \"trusted domain\" was given in the command line.\n   If it was, only forward the credentials to the matching resources,\n   and don't prompt for others while checking.\n4) Of course, there could be an input field for the regexp in the online\n   version, but IMHO that's overkill.\n\nThoughts?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-11997532"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "Ville,\n\nOn Friday, Jan 24, 2003, at 05:30 Asia/Tokyo, Ville Skytt? wrote:\n> Sanity checking myself, how does this sound to you:\n>\n> 1) The default is the hostname (or domain) of the first encountered\n>    resource requiring basic authentication.  Hostname or domain?\n\nHostname is the safe side. As a user, I'd be happy if it were the \ndomain, but... On the other hand, a few agents I know try what they \nhave in their keychain for the domain when prompted for auth. This is a \npoint worth discussing on w-v, maybe.\n\n\n> 2) We can't ask this multiple times in the online version.  Actually, \n> we\n>    can only ask it before any output has been sent, which means that it\n>    is supported only for resources in the same domain|hostname as the\n>    initial URI.\n\nSounds good.\n\n> 3) The command line version could ask it multiple times whenever\n>    needed, unless a \"trusted domain\" was given in the command line.\n>    If it was, only forward the credentials to the matching resources,\n>    and don't prompt for others while checking.\n\n[disclaimer - never used the cmdline version] is there an option for \n\"cron'd\" mode? I assume some people want the script to run totally \nnot-interactively, so there should be an option for this, other than \ngiving a trusted domain.\n\n> 4) Of course, there could be an input field for the regexp in the \n> online\n>    version, but IMHO that's overkill.\n\nAgreed.\n\n-- \nOlivier\n\n\n\n", "id": "lists-017-12005624"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "Le jeu 23/01/2003 ? 21:30, Ville Skytt? a ?crit :\n> I just realized that checklink defaults to '\\.w3\\.org' as the \"trusted\n> domain\" regexp, ie. it's not possible currently to use HTTP basic\n> authentication with resources whose uri doesn't match this.  Eek.\n> \n> Additionally, I think that regexp is not the best possible default.\n\nI agree this is far from ideal, but at the same time, I'm sure we will\nhear big complaints if people at W3C aren't able to check their links as\neasily as they could previously. One possible solution would be to go\nthe way you say, but add a GET parameter to specify W3C as a trusted\ndomain (or specify a regexp as a trusted domain, but that looks more\ndangerous to me). We would use this parameter in the comma tools\nversion.\n\nWhat do you think?\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-12014283"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "On Fri, 2003-01-24 at 03:20, Olivier Thereaux wrote:\n\n> > 1) The default is the hostname (or domain) of the first encountered\n> >    resource requiring basic authentication.  Hostname or domain?\n> \n> Hostname is the safe side. As a user, I'd be happy if it were the \n> domain, but... On the other hand, a few agents I know try what they \n> have in their keychain for the domain when prompted for auth. This is a \n> point worth discussing on w-v, maybe.\n\nOk.  Maybe the spec has something to say about the domain/hostname\nscope?\n\n> > 3) The command line version could ask it multiple times whenever\n> >    needed, unless a \"trusted domain\" was given in the command line.\n> >    If it was, only forward the credentials to the matching resources,\n> >    and don't prompt for others while checking.\n> \n> [disclaimer - never used the cmdline version] is there an option for \n> \"cron'd\" mode? I assume some people want the script to run totally \n> not-interactively, so there should be an option for this, other than \n> giving a trusted domain.\n\nAgreed, there should be a separate option that would force\nnon-interactive mode in the cmdline version.  I'll implement that.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12022914"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "On Fri, 2003-01-24 at 09:31, Dominique Haza?l-Massieux wrote:\n\n> One possible solution would be to go\n> the way you say, but add a GET parameter to specify W3C as a trusted\n> domain (or specify a regexp as a trusted domain, but that looks more\n> dangerous to me). We would use this parameter in the comma tools\n> version.\n\nSounds somewhat hackish to me.  Would it be possible to set up another\ninstance of checklink for W3C internal use that would use the current\ndefault of \".w3.org\"?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12031201"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "Le sam 25/01/2003 ? 15:15, Ville Skytt? a ?crit :\n> On Fri, 2003-01-24 at 09:31, Dominique Haza?l-Massieux wrote:\n> > One possible solution would be to go\n> > the way you say, but add a GET parameter to specify W3C as a trusted\n> > domain (or specify a regexp as a trusted domain, but that looks more\n> > dangerous to me). We would use this parameter in the comma tools\n> > version.\n> \n> Sounds somewhat hackish to me.  Would it be possible to set up another\n> instance of checklink for W3C internal use that would use the current\n> default of \".w3.org\"?\n\nWhat about making the trusted domain a configuration option? That way,\npeople could set it to what would fit their need on their local setup,\nand we at W3C would set it for W3C?\nI'd really dislike having a tool running on a W3C site not adapted to\nW3C needs...\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-12039318"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "On Sat, 2003-01-25 at 16:20, Dominique Haza?l-Massieux wrote:\n\n> What about making the trusted domain a configuration option? That way,\n> people could set it to what would fit their need on their local setup,\n> and we at W3C would set it for W3C?\n\nThis is exactly what I meant by suggesting the W3C specific instance,\nbut I don't think validator.w3.org/checklink should be that one.  IMO,\nthe current one should stay \"generic\", and a new one set up to satisfy\nW3C needs.\n\nThe only configuration methods checklink currently supports are the\ncommand line options/form parameters and some variables in the script\nitself.  See the script, in particular $_trusted.  That's the default\nvalue for the trusted domain (and it will always be used in the current\nonline version).\n\nAdditionally, checklink should really have an external configuration\nfile using Config::General, I'll add a RFE to bugzilla.\n\n> I'd really dislike having a tool running on a W3C site not adapted to\n> W3C needs...\n\nOf course.  OTOH, it doesn't make sense to me to provide a public\nservice on the W3C site which is /fixed/ (partially, in this case) to\nW3C needs :)\n\nI'll try to land some new code into CVS today or tomorrow for this and\nwill post a notification here.  I'll also see if I can set up a test\nversion on qa-dev.w3.org.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12048162"}, {"subject": "Re: [checklink] HTTP basic authenticatio", "content": "On Saturday, Jan 25, 2003, at 23:20 Asia/Tokyo, Dominique \nHaza?l-Massieux wrote:\n> I'd really dislike having a tool running on a W3C site not adapted to\n> W3C needs...\n\nAgreed, however I think this applies more to what is called by the \ncomma tool rather than what's at validator.w3.org/checklink. In other \nword, the comma tool could call checklink?uri=foobar&auth=w3.org \ninstead of just checklink?uri=foobar.\n\nHope this makes sense.\n-- \nOlivier\n\n\n\n", "id": "lists-017-12056841"}, {"subject": "[check] Misc. Headsup..", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nA few misc. \"headsup\" warnings...\n\n1. The current release-to-be will likely get its version number bumped.\n   In addition to the stuff detailed below, the presence of the doctype\n   fallbacks and the rest of those changes warrant doing a major revision\n   (or, rather, are inappropriate for a minor revision). Since 0.7 is taken\n   -- and I can't easily change that for various bonehead technical reasons --\n   that leaves the next version as \"0.6.5\" (despite my hating \".5\" releases\n   as \"sneak\" major releases).\n\n2. I am winding up towards checking in several moderately\n   disruptive/significant changes. They are unlikely to break anything in\n   any major way, but they have plenty potential for smaller breakage. IOW,\n   if you want a stable base to work from, now is the time to get a CVS\n   snapshot (I may create a CVS tag prior to checkins to make this easier).\n\nDetails on the upcoming stuff...\n\na. New \"fussy/strict\" parse mode adapted from Nick Kew's Page Valet code.\n   This will require documents to be \"fully-tagged\" and otherwise warn about\n   stuff like dubious SHORTTAGS features in HTML.\nb. New error explanations code (just the code, not (necessarily) the\n   explanations themselves) that should allow inline explanations and much\n   more robust detection of specific error messages.\nc. The base framework for a minimal WS API. This will be just the framework\n   and be disabled by default. It goes in mainly to facilitate further\n   experimentation (keep the diff sizes down in the branched code) and will\n   eventually come with a configuration switch to toggle it on or off.\nd. CSS and HTML tweaks; nothing revolutionary but it may break in some\n   browsers so a headsup is warranted.\n\nAll depending on how well it appears to work (or, how badly it breaks ;D) etc.\netc. of course; and no specific time-table implied.\n\nIn particular, as regards the time-table, I'm playing this pretty loose. If I\nget an attack of inspiration I may make a new beta release tomorrow or, just\nas likely, get side-tracked and let it slip for a couple months more. If\nanyone wants any particular timing for anything you need to let me know about\nit!\n\nEspecially Ville and Frederic; if you want to make sure you have something\nsuitable for release coinciding with a Debian/RedHat milestone (or whatever),\ny'all need to let me know about it or I'll just keep winding my way as whim\ntakes me on this front. (I bring this up since the last beta took you guys by\nsurprise)\n\n\n\n- -- \nAs a cat owner, I know this for a fact... Nothing says \"I love you\" like a\ndecapitated gopher on your front porch.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPxHtE6PyPrIkdfXsEQJMkQCdFKR/uLFtdKVyF0bpLiWj9xqG8sUAniPp\nHuO97JIXnyklWTev4t8BLJtw\n=bQvg\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12094826"}, {"subject": "Re: [check] Misc. Headsup..", "content": "On Mon, 2003-07-14 at 02:36, Terje Bless wrote:\n\n> 2. I am winding up towards checking in several moderately\n>    disruptive/significant changes. They are unlikely to break anything in\n>    any major way, but they have plenty potential for smaller breakage. IOW,\n>    if you want a stable base to work from, now is the time to get a CVS\n>    snapshot (I may create a CVS tag prior to checkins to make this easier).\n\nWhat branch do you plan to work in?  Methinks it's about time to get\nHEAD rolling again after The Next Release is out, and use the\n0_6_0-branch only for critical bugfixes...\n\n> Especially Ville and Frederic; if you want to make sure you have something\n> suitable for release coinciding with a Debian/RedHat milestone (or whatever),\n> y'all need to let me know about it or I'll just keep winding my way as whim\n> takes me on this front. (I bring this up since the last beta took you guys by\n> surprise)\n\nThanks.  By the way, is Frederic subscribed to public-qa-dev?\n\nSome status on the RPMs: I've updated the specfile in 0_6_0-branch so\nthat apart from the version numbers, it should be ready to roll. \n\nSpecifically, the Version:, Release: (reset to 1w3c if the next version\nis > 0.6.2), Source0: and Source1: tags should be updated to match the\nversion number.  And a %changelog entry would be nice :)  Feel free to\nupdate it when you feel it's time for a new release if I'm unresponsive.\n\nOpenSP 1.5 continues to be a slight PITA on Red Hat.  I won't go into\ndetails; just a note that their Rawhide (WIP area) contains\nopenjade-1.3.2 which includes OpenSP 1.5.  OpenSP 1.5 is not available\nfor RH 9 (current release) and earlier versions from RH.\n\nIn general, I think that RH release dates should not affect validator's\nrelease dates at all.\n\nI would like to get the local/private IP \"disclosure\" [1] dealt with\nfixed in both validator and checklink in the next release.  This will\nneed 1 config variable for each, and will most likely introduce a\ndependency on Net::IP [2].\n\n[1] http://lists.w3.org/Archives/Public/www-validator/2003Jul/0102.html\n[2] http://search.cpan.org/dist/Net-IP/\n\n-- \n\\/\n\n\n\n", "id": "lists-017-12104416"}, {"subject": "Re: [check] Misc. Headsup..", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>On Mon, 2003-07-14 at 02:36, Terje Bless wrote:\n>\n>>2. I am winding up towards checking in several moderately\n>>disruptive/significant changes. They are unlikely to break anything in\n>>any major way, but they have plenty potential for smaller breakage.\n>>IOW, if you want a stable base to work from, now is the time to get a\n>>CVS snapshot (I may create a CVS tag prior to checkins to make this\n>>easier).\n>\n>What branch do you plan to work in?  Methinks it's about time to get\n>HEAD rolling again after The Next Release is out, and use the\n>0_6_0-branch only for critical bugfixes...\n\nWell, as mentioned, for various bonehead reasons I can't do this cleanly. HEAD\nis borken and will take ages to get into releaseable state. IOW, anything\nreleased soon(ish) will have to come off the validator-0_6_0-branch. But since\nwe've allready added stuff that is inappropriate for a minor revision (doctype\nfallbacks etc.), we do need to bump the version number a bit more.\n\nHow about this...\n\nWe leave 0.6.1 as the last 0.6.x release for now, and then branch off to\nvalidator-0_7-branch from the validator-0_6_0-branch (instead of branching\nfrom HEAD) and make a 0.7.0 release from there.\n\nvalidator-0_7-branch then becomes the stable/critical-bugfix-only branch (with\ncheckin dicipline in effect[0]) and immediately transition to adding new stuff\non HEAD. If HEAD is too borken to easily add a given random minor\nfeature/change, then that is just a great incentive to _un_break HEAD.\n\nIf nobody hollers I'll proceede after that plan (probably beginning tonight).\n\n\nOh, and \"checkin dicipline\"; how about summat like:\n\n  1. Any checkin needs to reference a Bugzilla Bug #.\n  2. Any checkin needs to be applied also to HEAD.\n\n(excepting trivial/typo-style stuff onbviously)\n\nMainly just to remind folks[0] to put stuff where it belongs (i.e. I don't\nreally want to end up with a real Mozilla.org-style burocracy with Drivers,\nReview, and Super-Review etc.).\n\n\n>>Especially Ville and Frederic; if you want to make sure you have\n>>something suitable for release coinciding with a Debian/RedHat\n>>milestone (or whatever), y'all need to let me know about it or I'll\n>>just keep winding my way as whim takes me on this front. (I bring this\n>>up since the last beta took you guys by surprise)\n>\n>Thanks.  By the way, is Frederic subscribed to public-qa-dev?\n\nHe was, but he may have unsubscribed, been bounced, or not currently have time\nto follow the list. This message CCed in the hopes of getting current status.\nFrederic...?\n\n\n>Some status on the RPMs: I've updated the specfile in 0_6_0-branch so\n>that apart from the version numbers, it should be ready to roll.\n>\n>Specifically, the Version:, Release: (reset to 1w3c if the next version\n>is > 0.6.2), Source0: and Source1: tags should be updated to match the\n>version number.  And a %changelog entry would be nice :)\n\nI assume this is changelog for the _RPM_ and not in general?\n\n\n>OpenSP 1.5 continues to be a slight PITA on Red Hat.  I won't go into\n>details; just a note that their Rawhide (WIP area) contains\n>openjade-1.3.2 which includes OpenSP 1.5.  OpenSP 1.5 is not available\n>for RH 9 (current release) and earlier versions from RH.\n\nI've asked them to split the packages but twaugh seems disinclined to do so\nfor whatever reason (it took the -R security issue to get them to upgrade it\nat all). I think we need to get upstream to forcibly split the packages before\nRed Hat will follow suit. Note that a new OpenSP release (1.5.1) appears to be\nin the offing, so that may happen eventually).\n\n\n>In general, I think that RH release dates should not affect validator's\n>release dates at all.\n\nWell, we're not jumping through hoops for them, but if we can teak scheduling\nslightly in order to take advantage of new release attention I think that\nwould be advantageous. e.g. to announce Red Hat 9.1 packages immediately after\nthey start sending press releases ought to get us a little bit of free\nattention.\n\n\n\n\n[0] - To keep _me_ from getting lazy/careless; everyone else has been\n      exemplary in this regard. :-)\n\n- -- \nI'm [less] than thrilled by the [VM situation]; all sides of it. I [think]\nwe need a [fork] in that area so that you guys would stop stepping on each\nothers' toes.  I'm taking no part in your merry 5-way clusterfuck  -- sort\nthat mess out between yourselves.                -- Alexander Viro on lkml\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPxq2KKPyPrIkdfXsEQK1+ACg2sTL+iUBF8twNTrpIqqvWaN5nBoAoJzy\nUYpgyJk9MfjUUjPe2T3yJf/J\n=3mHr\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12113525"}, {"subject": "Re: [check] Misc. Headsup..", "content": "On Sun, 2003-07-20 at 18:32, Terje Bless wrote:\n\n> How about this...\n> \n> We leave 0.6.1 as the last 0.6.x release for now, and then branch off to\n> validator-0_7-branch from the validator-0_6_0-branch (instead of branching\n> from HEAD) and make a 0.7.0 release from there.\n> \n> validator-0_7-branch then becomes the stable/critical-bugfix-only branch (with\n> checkin dicipline in effect[0]) and immediately transition to adding new stuff\n> on HEAD. If HEAD is too borken to easily add a given random minor\n> feature/change, then that is just a great incentive to _un_break HEAD.\n> \n> If nobody hollers I'll proceede after that plan (probably beginning tonight).\n> \n> \n> Oh, and \"checkin dicipline\"; how about summat like:\n> \n>   1. Any checkin needs to reference a Bugzilla Bug #.\n>   2. Any checkin needs to be applied also to HEAD.\n> \n> (excepting trivial/typo-style stuff onbviously)\n\nNo objections here.\n\n> >Some status on the RPMs: I've updated the specfile in 0_6_0-branch so\n> >that apart from the version numbers, it should be ready to roll.\n> >\n> >Specifically, the Version:, Release: (reset to 1w3c if the next version\n> >is > 0.6.2), Source0: and Source1: tags should be updated to match the\n> >version number.  And a %changelog entry would be nice :)\n> \n> I assume this is changelog for the _RPM_ and not in general?\n\nYes.\n\n> >OpenSP 1.5 continues to be a slight PITA on Red Hat.  I won't go into\n> >details; just a note that their Rawhide (WIP area) contains\n> >openjade-1.3.2 which includes OpenSP 1.5.  OpenSP 1.5 is not available\n> >for RH 9 (current release) and earlier versions from RH.\n> \n> I've asked them to split the packages but twaugh seems disinclined to do so\n> for whatever reason (it took the -R security issue to get them to upgrade it\n> at all).\n\nThose are probably the very same issues that I've found, it'll be\nnecessary to rebuild a biggish bunch of other, dependent packages too if\none wants to cleanly repackage SP and Jade separately :/  And even if\nthat can be done, it may get hairy to support smooth upgrades from\nprevious versions.\n\n> Well, we're not jumping through hoops for them, but if we can teak scheduling\n> slightly in order to take advantage of new release attention I think that\n> would be advantageous. e.g. to announce Red Hat 9.1 packages immediately after\n> they start sending press releases ought to get us a little bit of free\n> attention.\n\nYep.  Because of the SP/Jade issues above, I think it would make sense\nto make the RPM 9.1 (or whatever it'll be called) only when it's out,\ninstead of providing a package that isn't really out of the box workable\nanywhere.\n\n-- \n\\/\n\n\n\n", "id": "lists-017-12126664"}, {"subject": "Re: [check] Misc. Headsup..", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nTerje Bless <link@pobox.com> wrote:\n\n>We leave 0.6.1 as the last 0.6.x release for now, and then branch off to\n>validator-0_7-branch from the validator-0_6_0-branch (instead of\n>branching from HEAD) and make a 0.7.0 release from there.\n>\n>validator-0_7-branch then becomes the stable/critical-bugfix-only branch\n\nBTW, this also means I will have to renumber/retarget Bugzilla bugs currently\ntargetted at 0.6.2 and 0.7.0; which will generate a lot of noise to all\nreporters and bug owners.\n\nThe only obvious alternative I see is to do the 0.6.2->0.6.5 bump, which will\nbe possible to do much more quietly but does not leave us with a clean CVS\nbranch structure.\n\n\nWhile waiting for feedback from y'all on this I'll check in what I have in my\nworkspace on validator-0_6_0-branch (style tweaks and inline error messages).\nIf I haven't heard anything to the contrary by the time I need to commit the\nnew parse mode and WSAPI stuff I'll spam Bugzilla and do the renumbering.\n\n\nIOW, I want feedback (either way) on this (and ASAP if possible)!\n\n\n\nOh, and BTW, pinging me on IRC (#validator on irc.freenode.net) is usually the\nfastest way to get my attention if I'm about to make a no-no or you have\nanother urgent issue. Depending on how backlogged I am, email may well sit\nuntouched for weeks at a time.\n\nAlso a lot of administrative/policy (-ish; very much \"-ish\" ;D) stuff gets\ntalked about on IRC (e.g. release scheduling and play-by-play on stuff like\nthe new stylesheet/error messages) -- simply because it has lower impedance\nthen email, making it easier to make the decision \"does anyone really care\nabout this or should I not bother sending it?\" -- so stopping by / hanging out\nthere is highly recommended even if you're not an \"IRC\" kind of person.\n\n- -- \n\"Allright... Calm down! Relax! Start breathin??...\"         -- Dr. D.R.E.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPxq+6aPyPrIkdfXsEQKe7ACg0DU6LHnr+gQNITOrt8EOAeS3pvoAoMN1\nqGtq5vts1GEfyMng7OMD3Wov\n=Mby4\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12136618"}, {"subject": "Re: [check] Misc. Headsup..", "content": "On Monday, Jul 21, 2003, at 00:32 Asia/Tokyo, Terje Bless wrote:\n> We leave 0.6.1 as the last 0.6.x release for now, and then branch off \n> to\n> validator-0_7-branch from the validator-0_6_0-branch (instead of \n> branching from HEAD) and make a 0.7.0 release from there.\n\nWhy not release what we've been beta testing as 0.6.2 and then proceed? \nWhat's benn tagged as 0.6.2 is not perfect, agreed, but some people are \nwaiting for it, and I believe we'd do the community a favor by \nreleasing it instead if waiting for the big bulk of stuff we have in \nthe pipe to be ready...\n\n>> Thanks.  By the way, is Frederic subscribed to public-qa-dev?\n\nYes. (Just checked).\n\n-- \nolivier\n\n\n\n", "id": "lists-017-12146624"}, {"subject": "Re: [check] Misc. Headsup..", "content": "Quoting Terje Bless <link@pobox.com>:\n\n> He was, but he may have unsubscribed, been bounced, or not currently have\n> time to follow the list. This message CCed in the hopes of getting current\n> status. Frederic...?\n\nI am indeed subscribed -- sorry for not answering earlier. I read all the\nmessages, but wanted to take some time to prepare an comprehensive\nanswer before answering. Oh well, let's go for the partial answer...\n\nFrom the Debian point of view, there is no release planned in the next\ncouple of months (there has been no freeze on the 'testing' distribution,\nso a release is very unlikely before next year), so there is no need to \nhave something released in the very near future in order to have it included\ninto Debian Sarge (the next release). In addition, the current Debian package\nis in pretty good shape (and the Debian packaging of OpenSP doesn't cause any\nproblem AFAIK), I've only received minor bug reports that I forwarded to\nVille. The only thing I would absolutely need for the release is a better\nway of configuring the validator so that it can use the catalog and DTDs\nthat are provided by the distribution. I've promised Terje a summary of the\nsituation a long time ago, and I should do that ASAP. But this doesn't have\nto be linked to a new release of the validator -- if (and when) we agree on\na fix, I can backport it to the current version in Debian.\n\nI won't say much about the next release in general -- I was personaly\nhoping for a 0.6.2 'bug-fix' release in the near future because I understood\nit was needed (even though I haven't been personaly bitten by any bug in the \ncurrent release), but I haven't followed the details of the changes. Whatever\nthe new version, it would be nice to have something out in the not-so-far\nfuture. Once a decision has be made, I'll create a new (unofficial) Debian\npackage with the pre-(0.6.2|0.6.5) version of the validator so that it can be\neasily tested by people using Debian.\n\nFrederic\n\n\n\n", "id": "lists-017-12154071"}, {"subject": "Re: Character-by-Character Distinct IRI-&gt; Char-by-char   equivalent URI (issue #IRIURIcharequiv20", "content": "> For example http://www.example.org/ (1) and http://www.example.org (2).\n> The URI spec says that these are equivalent, but they identify\n> two different namespaces, and they identify two different nodes\n> in an RDF graph.\n\nNo they don't.  The result of processing them with namespaces may\nbe disjunct name sets, and the result of processing them with\nRDF may be bifurcated graphs, but what they identify is the same\nregardless of the processing rules of any technology other than\nthe URI scheme's name assignment algorithm.  Any other technology\nis implicitly licensed to join those sets or those graphs if they\nwish to spend the effort to do so -- RDF and xmlns specifications\nmerely define the processing rules for minimal conformance, not\nequivalence of resources.\n\n....Roy\n\n\n\n", "id": "lists-017-1216084"}, {"subject": "div#main padding in validator/htdocs/base.cs", "content": "Terje,\n\nI found what was the detail I disliked in the newest CSS : lack of \nbalance between left and right padding.\n\nI suggest something as I did for\n  <http://www.w3.org/QA/2003/07/cssvalidator>\n\nwhich basically corresponds to this diff\n[[\n--- /Users/ot/Documents/cvs/validator/validator-branch/htdocs/base.css  \nTue Jul 22 12:39:22 2003\n+++ base.css    Thu Jul 24 14:54:31 2003\n\n@@ -25,8 +25,12 @@\n  }\n\n  div#main {\n-  padding-left: 2em;\n+  /*padding-left: 2em;*/\n    padding-top: 1em;\n+}\n+\n+div#main p {\n+padding-left: 1em;\n  }\n\n  fieldset {\n]]\n\nI find it more pleasant to the eye.\nMind if I commit this?\n\nolivier\n\n\n\n", "id": "lists-017-12163365"}, {"subject": "Re: div#main padding in validator/htdocs/base.cs", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nOlivier Thereaux <ot@w3.org> wrote:\n\n>Mind if I commit this?\n\nGo right ahead. If anything breaks or I don't like it, I'll cheerfully and\nshamelessly revert it or change it. Unless a commit involves non-trivial\nchanges to Perl code or the config files, I see no reason to be so\nconservative in commits. Easy change management is the reason to use CVS. :-)\n\nThat said, I'll probably tweak that bit some more. I'm not really happy with\nthe way it turned out (the Submit button in particular) so some more tweaking\nis due before release.\n\n- -- \nThese are the same customers you are referring to whom Microsoft thought\nwould need MS Bob and the Talking Paperclip?   One thing is to give them\nenough rope to hang themselves,  but a boobytrapped thermonuclear weapon\nrunning on a rand(time) countdown... Is that really wise? - Me to MS rep.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPx/186PyPrIkdfXsEQKa0QCg74FsEElVNlQ+S+E4EBA9lwjMr0QAoJDG\nFmUpWGDrHmCrOt0hrE0J/5q1\n=fA5T\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12171329"}, {"subject": "Re: div#main padding in validator/htdocs/base.cs", "content": "On Friday, Jul 25, 2003, at 00:06 Asia/Tokyo, Terje Bless wrote:\n> Olivier Thereaux <ot@w3.org> wrote:\n> Go right ahead. If anything breaks or I don't like it, I'll cheerfully \n> and\n> shamelessly revert it or change it. Unless a commit involves \n> non-trivial\n> changes to Perl code or the config files, I see no reason to be so\n> conservative in commits.\n\nFine with me, I just wanted to be on the safe side since I knew this is \nsomething you've been working on lately. I will follow the \"go ahead \nfor anything minor\" idea from now on.\n\n> That said, I'll probably tweak that bit some more. I'm not really \n> happy with\n> the way it turned out (the Submit button in particular) so some more \n> tweaking\n> is due before release.\n\nMy experience with forms and CSS tells me that unless you go with \ntables (yeah, I know...), you'll never get the submit buttons to align \nwell. The behaviour varies too much from one agent to another. But good \nluck anyway :).\n\nolivier\n\n\n\n", "id": "lists-017-12180553"}, {"subject": "[check] small notes on style/layou", "content": "Hi.\n\njust a few notes before I go to bed...\n\n- after some discussion on the w-v-css list, it seems nobody awfully \ndisliked the \"new\" validator style, and so it seems like the css \nvalidator's homepage will be using the same style and layout as the \nvalidator, which I believe is a very nice step towards a good usability \nof our services. (Hi! Philippe, Sijtsche!)\n\n- One comment we're very likeky to have is that (even in non-verbose \nmode maybe, but even more then) the \"this page is not valid FOO\" block \nis too low. At my resolution I have to scroll down one to two pages. I \nbelieve it was higher before, was there a specific reason to move it \nbelow the warning boxes?\n\nCheers,\n-- \nolivier\n\n\n\n", "id": "lists-017-12188568"}, {"subject": "Re: [check] small notes on style/layou", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nOlivier Thereaux <ot@w3.org> wrote:\n\n>- after some discussion on the w-v-css list, it seems nobody awfully\n>disliked the \"new\" validator style, and so it seems like the css\n>validator's homepage will be using the same style and layout as the\n>validator, which I believe is a very nice step towards a good usability\n>of our services. (Hi! Philippe, Sijtsche!)\n\nYay! :-)\n\n/me notices he's been unsubscribed from the -css list, again... Y'all need to\nget less finicky mailinglist software! :-(\n\n\n>- One comment we're very likeky to have is that (even in non-verbose\n>mode maybe, but even more then) the \"this page is not valid FOO\" block\n>is too low. At my resolution I have to scroll down one to two pages. I\n>believe it was higher before, was there a specific reason to move it\n>below the warning boxes?\n\nYes. HTH, HAND. :-)\n\n\n\n\n( I can't recall what it was. Go ahead and move it where you think it makes\nsense, and we'll do any cleanup as necessary. )\n\n- -- \n\"When you have no nails your hammer grows restless, and you begin to throw\n sideways glances at screws and pieces of string.\"    -- Jarkko Hietaniemi\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPyUmGqPyPrIkdfXsEQJ+SACfYYmmH4a1ulxkMNJRcS6rxFfJsy0AoKtl\n7EslIleZKozXApLJ3LZVLad4\n=iATz\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12196080"}, {"subject": "FTP_PASSIVE needed on v.w.", "content": "v.w.o seems to need passive FTP.\n\nCould someone add this to the relevant Apache configuration files and\nrestart (-HUP) the port 80 and 8001 instances?\n\n  SetEnv FTP_PASSIVE 1\n\nRecent CVS checklink and validator default to passive mode, but until\nthey're updated, the setups are bitten by:\n\n  ville@validator:~$ HEAD ftp://ftp.isi.edu/in-notes/rfc2506.txt\n  404 File 'rfc2506.txt' not found\n  Client-Date: Tue, 29 Jul 2003 10:44:51 GMT\n\n  ville@validator:~$ FTP_PASSIVE=1 HEAD ftp://ftp.isi.edu/in-notes/rfc2506.txt\n  200 OK\n  Server: ftp.isi.edu NcFTPd Server (free educational license)\n  Content-Length: 24892\n  Content-Type: text/plain\n  Last-Modified: Wed, 10 Mar 1999 00:05:29 GMT\n  Client-Date: Tue, 29 Jul 2003 10:45:01 GMT\n  Client-Request-Num: 1\n\nDitto for GET.\n\n-- \n\\/\n\n\n\n", "id": "lists-017-12204912"}, {"subject": "Re: FTP_PASSIVE needed on v.w.", "content": "Le mar 29/07/2003 ? 12:46, Ville Skytt? a ?crit :\n> v.w.o seems to need passive FTP.\n> \n> Could someone add this to the relevant Apache configuration files and\n> restart (-HUP) the port 80 and 8001 instances?\n> \n>   SetEnv FTP_PASSIVE 1\n\nI have done it on the port 80 instance, but I didn't mess up with the\n8001 one (which seems to be run from Terje's account).\n\n(and that does fix the problem, see e.g.\nhttp://validator.w3.org/checklink?uri=http%3A//lists.w3.org/Archives/Public/public-qa-dev/2003Jul/0012.html vs http://validator.w3.org:8001/checklink?uri=http%3A//lists.w3.org/Archives/Public/public-qa-dev/2003Jul/0012.html)\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-12212429"}, {"subject": "Re: FTP_PASSIVE needed on v.w.", "content": "On Tue, 2003-07-29 at 14:56, Dominique Haza?l-Massieux wrote:\n> Le mar 29/07/2003 ? 12:46, Ville Skytt? a ?crit :\n>\n> I have done it on the port 80 instance, but I didn't mess up with the\n> 8001 one (which seems to be run from Terje's account).\n> \n> (and that does fix the problem, see e.g.\n> http://validator.w3.org/checklink?uri=http%3A//lists.w3.org/Archives/Public/public-qa-dev/2003Jul/0012.html vs http://validator.w3.org:8001/checklink?uri=http%3A//lists.w3.org/Archives/Public/public-qa-dev/2003Jul/0012.html)\n\nThanks!\n\n-- \n\\/\n\n\n\n", "id": "lists-017-12220937"}, {"subject": "Re: validator/misc w3c-markupvalidator.spe", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytta <ville@abyss.w3.org> wrote:\n\n>Don't install htdocs/config/verbosemsg.rc even if it's in the tarball.\n\nHmmm. Perhaps we should be keeping in mind the possibility of having a\nseparate \"*-devel\" package for stuff like this? Probably not needed yet,\nbut...\n\n- -- \nI'm [less] than thrilled by the [VM situation]; all sides of it. I [think]\nwe need a [fork] in that area so that you guys would stop stepping on each\nothers' toes.  I'm taking no part in your merry 5-way clusterfuck  -- sort\nthat mess out between yourselves.                -- Alexander Viro on lkml\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPyeT0KPyPrIkdfXsEQIzJgCg7bJBOOBkb45GkJJKA6FIKyGG1ukAoPsP\nZGGuVCcyJB0a8furoAuMmItK\n=kTfE\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12228311"}, {"subject": "Re: validator/misc w3c-markupvalidator.spe", "content": "On Wed, 2003-07-30 at 12:45, Terje Bless wrote:\n\n> >Don't install htdocs/config/verbosemsg.rc even if it's in the tarball.\n> \n> Hmmm. Perhaps we should be keeping in mind the possibility of having a\n> separate \"*-devel\" package for stuff like this? Probably not needed yet,\n> but...\n\nYep.  spmpp.pl would belong there too.  Later...\n\nWhat about the Config::General/265kB verbosemsg.cfg issue?  I can have a\ngo at using Storable to persist/use the parsed file if it 1) doesn't\nexist or 2) is older than verbosemsg.cfg if you think it's a good idea.\n\n-- \n\\/\n\n\n\n", "id": "lists-017-12236879"}, {"subject": "Re: validator/misc w3c-markupvalidator.spe", "content": "On Wed, 2003-07-30 at 12:53, Ville Skytt? wrote:\n> On Wed, 2003-07-30 at 12:45, Terje Bless wrote:\n> \n> > >Don't install htdocs/config/verbosemsg.rc even if it's in the tarball.\n> > \n> > Hmmm. Perhaps we should be keeping in mind the possibility of having a\n> > separate \"*-devel\" package for stuff like this? Probably not needed yet,\n> > but...\n> \n> Yep.  spmpp.pl would belong there too.  Later...\n\n...as well as stuff in htdocs/dev.\n\n> What about the Config::General/265kB verbosemsg.cfg issue?  I can have a\n> go at using Storable to persist/use the parsed file if it 1) doesn't\n> exist or 2) is older than verbosemsg.cfg if you think it's a good idea.\n\nOn a second thought, it would be better if Config::General could do this\ntransparently.\n\n-- \n\\/\n\n\n\n", "id": "lists-017-12244934"}, {"subject": "Re: validator/misc w3c-markupvalidator.spe", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>>What about the Config::General/265kB verbosemsg.cfg issue?  I can have\n>>a go at using Storable to persist/use the parsed file if it 1) doesn't\n>>exist or 2) is older than verbosemsg.cfg if you think it's a good idea.\n>\n>On a second thought, it would be better if Config::General could do this\n>transparently.\n\nWell, I must admit I'm somewhat ambivalent on this issue. As you demonstrated\nthere is quite a bit of overhead associated with the current implementation,\nbut the question is whether it is significant in the context (e.g. \"check\" is\npretty resource intensive as it is).\n\nAdding Storable would add complexity and an additional point of failure that\nneeds to be traded off against the performance gain. I'm not certain which way\nthe needle should/would tip in this case (meaning that anyone with strong\nopinions in either direction are invited to make that decision!).\n\n\nBut implementing this as a new feature for Config:General instead of as a\nlocal modification does make sense if upstream will take such a patch.\n\n- -- \nI have to admit that I'm hoping the current situation with regard to XML\nNamespaces and W3C XML Schemas is a giant practical joke,   but I see no\nsigns of pranksters coming forward with a gleeful smile to announce that\nthey were just kidding.                              -- Simon St.Laurent\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPyebcaPyPrIkdfXsEQINQgCg8WQl/FPklBTJQjlTn4D6GhxIx3MAoI6+\nyTP5VnKwN45lSvouWH1yL2ww\n=cbVE\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12253267"}, {"subject": "RE: Character-by-Character Distinct IRI-&gt; Char-by-char   equivale nt URI (issue #IRIURIcharequiv20", "content": "Hello Martin,\n\n> I therefore am tentatively closing this issue with 'no action needed'.\n> If you think that some change to the document is needed, \n> please say so (ideally with some actual proposed text).\n\nThe short answer is yes... I agree.\n\nI chewed on this of quite a time. Even came with and idea to address your\nchallenge (which I'll mention below) but I think it amounts the same thing\nas the MUST NOT in section 5.1:\n\n   As an example,\n   http://example.org/~user, http://example.org/%7euser, and\n   http://example.org/%7Euser are not equivalent under this definition.\n   In such a case, the comparison function MUST NOT map IRIs to URIs,\n   because such a mapping would create additional spurious equivalences.\n\nIt was the \"spurious equivalences\" phrase that triggered my concern.\n\nMy idea to address your challenge, which I'm not overly committed to... and\nI think amounts the the same as the MUST NOT above is this:\n\nRegard the lexical spaces of URI and IRI as disjoint ie. if the identifier\nstring is valid under the URI grammar... it's a URI and *not* an IRI. IRI\nare then the remaining strings that match the IRI grammar. Effectively this\nforces IRI to be only those identifier strings that actually contain\ncharacters that are not 'legal' in URI. Character by character IRI/IRI and\nURI/URI comparision work as normal. Character-by-character IRI/URI\ncomparison always yield not-equal (because URI and IRI are disjoint). \n\nThanks,\n\nStuart\n--\n\n> -----Original Message-----\n> From: public-iri-request@w3.org \n> [mailto:public-iri-request@w3.org] On Behalf Of Martin Duerst\n> Sent: 25 March 2004 20:21\n> To: Williams, Stuart; Williams, Stuart; Williams, Stuart; Ian \n> B. Jacobs\n> Cc: public-iri@w3.org\n> Subject: Re: Character-by-Character Distinct IRI-> \n> Char-by-char equivalent URI (issue #IRIURIcharequiv-20)\n> \n> \n> Hello Stuart,\n> \n> Many thanks for forwarding this discussion to public-iri. I \n> have listed this as an issue at \n> http://www.w3.org/International/iri-edit/Overview.html#IRIURIc\nharequiv-20.\n> \n> At 16:38 04/03/25 +0000, Williams, Stuart wrote:\n> \n> >[Shifting discussion to public-iri from tag@w3.org]\n> >\n> > > >So to be clear... the IRI draft section 5.1 seems to \n> suggest that \n> > > >it is possible for the IRI->URI mapping to generate superious \n> > > >character-by-character equivalences (between the resulting URI) \n> > > >from distinct IRI.\n> > > >\n> > > >If that can't in fact happen, then maybe the wording in 5.1 that \n> > > >suggest that it could should be changed.\n> > >\n> > > It can happen. The IRI http://www.example.org/ros&eacute; is not \n> > > character-by-character equivalent to the URI/IRI \n> > > http://www.example.org/ros%C3%A9, but when you convert the IRI \n> > > http://www.example.org/ros&eacute; to an URI, you get the URI \n> > > http://www.example.org/ros%C3%A9.\n> >\n> >So... what other IRI, distinct from \n> http://www.example.org/ros&eacute;\n> >yields URI http://www.example.org/ros%C3%A9.\n> >\n> >Oh... yes I see, the IRI http://www.example.org/ros%C3%A9 \n> (because in \n> >your view URI are IRI) maps to the URI \n> http://www.example.org/ros%C3%A9.\n> >aaaaggghhhh.\n> >\n> >This gets us back to the question of whether IRI are \n> intended 1) as a \n> >replacement for URI as 'the' identifier for the Web, or 2) as a \n> >distinct set of a internationalised identifiers (distinct \n> value space, \n> >overlapping lexical space wrt URI) which are mapped to URI \n> for use in \n> >protocol elements that require URI\n> \n> My answer here is:\n> - both, depending on the situation\n> - this might look bothering, but it really isn't much of an issue\n> \n> \n> >- URI then remain 'the' identifier on the Web and IRI serve as an \n> >internationalisation friendly form for inclusion in documents and UI \n> >artifacts (from which URI are generated when necessary).\n> \n> Once most of what the users will see are IRIs, I'm not sure \n> it's appropriate to call them 'UI artifacts'. Users will just \n> see them, and probably talk about them as URLs, not even \n> URIs, because they haven't yet learned that the 'politically \n> correct' name is now URI.\n> \n> \n> >View 2 treats URI and IRI as different types even though \n> there lexical \n> >forms overlap. In this view I'm not sure quite how the IRI\n> >http://www.example.org/ros%C3%A9 would arise.\n> \n> Hopefully not too often. But somebody can just write it down, \n> as it is written down in this email. You are right that it \n> should be very rare, but from a spec point of view, the \n> question is how to disallow it. We can't disallow \n> percent-escaping because that would disallow \n> http://www.example.org/ros%E9, which has to be legal for \n> backwards compatibility purposes (and is different from the above).\n> \n> \n> >I accept that simply looking at the lexical form leaves an ambiguity \n> >about whether one is looking at a URI or an IRI.\n> \n> Yes, of course. And often (e.g. on a napkin or a business \n> card), that's the only thing you have.\n> \n> \n> > > So what the IRI draft says is that if you need character-by- \n> > > character equivalence, for example for XML namespaces (e.g.\n> > > XSLT) or for RDF to match nodes in a graph, don't convert \n> to an URI.\n> >\n> >ie. you do character-by-character comparison of two IRI.\n> \n> Yes.\n> \n> \n> > > >[Also, I'm not entirely comfortable with all \"URIs are \n> IRIs\" - but \n> > > >I'll dwell on that - this discomfort is at the level of \n> whether the \n> > > >set of real numbers and the set of integers are disjoint \n> or not - \n> > > >ie. they are different types (value-space) although the \n> may share \n> > > >lexical space presentation.]\n> > >\n> > > I'm not totally familiar with this kind of philosophical \n> discussion.\n> > > I tend to think about this from an operational view. Most \n> if not all \n> > > operations that you can do on 'integer 2' you can do on 'real 2', \n> > > with the same results. Same the other way round.\n> > > As far as I know, all the relevant operations you can do with the \n> > > URI http://www.example.org/ros%C3%A9 you can do with the IRI \n> > > http://www.example.org/ros%C3%A9, and vice versa, with the same \n> > > result. So trying to distinguish them will only \n> complicate the spec, \n> > > without adding anything other than confusing most readers.\n> >\n> >But you are demonstrating a situation where for two IRI x and y:\n> >\n> >         (not(x == y)) && (iriToUri(x) == iriToUri(y))\n> >\n> >operationally this is also confusing.\n> \n> Looks like it may create problems. But up to now, I haven't \n> heard about any. This situation is very similar to a \n> situation purely on URIs. It is very easy to construct two \n> URIs that are guaranteed to always resolve to the same thing \n> but that don't compare character-by-character equivalent.\n> \n> For example http://www.example.org/ (1) and \n> http://www.example.org (2).\n> The URI spec says that these are equivalent, but they \n> identify two different namespaces, and they identify two \n> different nodes in an RDF graph. So we could indeed create \n> two different types, let's call them aURI (the ones that are \n> only equivalent if they are character-by-character \n> equivalent) and bURI (they are equivalent in some more cases, \n> as far as the URI spec allows).\n> (1) and (2) are the same bURI, but a different aURI. And you \n> can't even know whether they are aURIs or bURIs by just \n> looking at them. So which ones are 'the' identifier for the Web?\n> aURIs or bURIs?\n> \n> \n> So in summary:\n> - This issue is not a problem because very similar issues also\n>    exist with URIs themselves.\n> - Given that IRIs allow (many) more characters than URIs, but we\n>    want IRIs that are also URIs (or if you prefer: that also look\n>    like URIs) to map to themselves, it is impossible to preserve\n>    the same equivalence classes for character-by-character on IRIs\n>    and on URIs. So there does not seem to be a solution\n>    (if you know about one, please tell us).\n> - There is already a clear warning in the draft about this, which\n>    seems to have been clear enough to catch your attention.\n> \n> I therefore am tentatively closing this issue with 'no action needed'.\n> If you think that some change to the document is needed, \n> please say so (ideally with some actual proposed text).\n> \n> \n> Regards,     Martin.\n> \n> \n\n\n\n", "id": "lists-017-1225680"}, {"subject": "Re: validator/misc w3c-markupvalidator.spe", "content": "On Wed, 2003-07-30 at 13:18, Terje Bless wrote:\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA1\n> \n> Ville Skytt? <ville.skytta@iki.fi> wrote:\n> \n> >>What about the Config::General/265kB verbosemsg.cfg issue?  I can have\n> >>a go at using Storable to persist/use the parsed file if it 1) doesn't\n> >>exist or 2) is older than verbosemsg.cfg if you think it's a good idea.\n> >\n> >On a second thought, it would be better if Config::General could do this\n> >transparently.\n> \n> Well, I must admit I'm somewhat ambivalent on this issue. As you demonstrated\n> there is quite a bit of overhead associated with the current implementation,\n> but the question is whether it is significant in the context (e.g. \"check\" is\n> pretty resource intensive as it is).\n\nYep, but adding roughly 0.3-0.4 seconds CPU time to each request can't\nbe good... dunno what the overall effect would be in per-request\nwallclock time in production at v.w.o.\n\n> But implementing this as a new feature for Config:General instead of as a\n> local modification does make sense if upstream will take such a patch.\n\nWill probably see later.  Config::General::ParseConfig already takes a\n-Tie argument; but I'm not familiar enough with tie() stuff to even tell\nwhether that could be applicable or useful here.\n\nWill there be another live beta release?  Could estimate the cost there.\n\n-- \n\\/\n\n\n\n", "id": "lists-017-12262586"}, {"subject": "Re: validator/misc w3c-markupvalidator.spe", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>Yep, but adding roughly 0.3-0.4 seconds CPU time to each request can't\n>be good... dunno what the overall effect would be in per-request\n>wallclock time in production at v.w.o.\n\nlink@validator:cgi-bin<1>$ time HEAD \\\n  http://validator.w3.org/check?uri=http://www.w3.org/ >/dev/null\n\n    real    0m1.159s\n    user    0m0.340s\n    sys     0m0.010s\n\nlink@validator:cgi-bin<2>$ time HEAD \\\n    http://validator.w3.org/check?uri=http://www.yahoo.com/ >/dev/null\n\n    real    0m1.739s\n    user    0m0.280s\n    sys     0m0.060s\n\nSo we're talking about between 1.0 and 1.75 wallclock seconds for the\nprocessing alone; making your numbers something like 30-50% increase.\n\n\n>Will there be another live beta release?  Could estimate the cost there.\n\nI'm aiming to do a new beta as soon as I make a final call on some WS code I'm\nworking on (haven't quite decided on Go/No Go yet) && Olivier is happy with\ndocs and style tweaks && I hear back from Jim about some JavaScript stuff[0].\n\nLets make a point to profile this stuff in a more reliable manner then. Well,\nor you could just go ahead immediately in a separate server on v.w3.org.\n\n\n\n[0] - I've \"voluntered\" Jim Ley to do some JavaScript for the Results page to\n      show Error Explanations on demand; but he's pretty busy so I don't know\n      how long until he has time for this. If it's soon I want to hold off on\n      beta until we can add the JS to maximized the amount of testing it gets.\n\n\n\n- -- \nInterviewer: \"In what language do you write your algorithms?\"\n    Abigail: English.\nInterviewer: \"What would you do if, say, Telnet didn't work?\"\n    Abigail: Look at the error message.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPye+f6PyPrIkdfXsEQLorgCglVLO7B2IGC0qtj1SZk4BuW07IXAAoJpo\nW6rFLBTXDgesvg4+v5EujdeC\n=Zb7k\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12271498"}, {"subject": "Re: Dogfood... (was: MathML 2.0, second edition", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n[ Message CCed to qa-dev ]\n\nLofton Henderson <lofton@rockynet.com> wrote:\n\n>Let's see, I was at the end of a chain of several people, and used\n>jigedit to post this with Web Commander.  If it were somehow possible to\n>get a validation notification at time of posting (by Web Comm'dr, or\n>other tools), then that would relieve me of having to remember every\n>time, \"oh yeah, has anyone validated it yet?\".  It is that extra,\n>voluntary step in the workflow that is problematic.\n\nHmmm. There seems to be two obvious solutions to this; enforce Validation in\neither Web Commander[0] or the remote server at PUT time.\n\nI'm not sufficiently familiar with the setup at either end here to evaluate\nthe feasability of the two. Initially I'd say that since this is an\nenforcement of a publishing policy it belongs in the server and not the client\n(i.e. the \"authoring\" end), but that may run into practical problems with e.g.\nthe round-robin setup or similar?\n\nOtherwise the obvious way to go about it would be a server plugin\n(module/filter for Apache) that enforces Valid content in PUT.\n\nIf that is deemed infeasible, perhaps we could prevail on Henrik to add a POST\nto validator.w3.org to Web Commander.\n\n\n\n[0] - I assume it's <http://www.w3.org/WinCom/> we're talking about here?\n\n- -- \nMy mom is a professional botanist, or, as her spousal equivalent described\nit, they'll be out hiking in the woods, she'll see a plant off by the side\nof the trail, run up to it, bend down, and start talking Latin at it.\n                                                      -- Steve VanDevender\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPtmql6PyPrIkdfXsEQJ6BgCfXjEOvcf7oWdCkR6NxobQyputqeQAoNPd\nCSJZKeJ+Nir1AHYeHm9n1qrG\n=ggIF\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12312134"}, {"subject": "Re: Dogfood... (was: MathML 2.0, second edition", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n[ Message CCed to qa-dev ]\n\nLofton Henderson <lofton@rockynet.com> wrote:\n\n>Let's see, I was at the end of a chain of several people, and used\n>jigedit to post this with Web Commander.  If it were somehow possible to\n>get a validation notification at time of posting (by Web Comm'dr, or\n>other tools), then that would relieve me of having to remember every\n>time, \"oh yeah, has anyone validated it yet?\".  It is that extra,\n>voluntary step in the workflow that is problematic.\n\nHmmm. There seems to be two obvious solutions to this; enforce Validation in\neither Web Commander[0] or the remote server at PUT time.\n\nI'm not sufficiently familiar with the setup at either end here to evaluate\nthe feasability of the two. Initially I'd say that since this is an\nenforcement of a publishing policy it belongs in the server and not the client\n(i.e. the \"authoring\" end), but that may run into practical problems with e.g.\nthe round-robin setup or similar?\n\nOtherwise the obvious way to go about it would be a server plugin\n(module/filter for Apache) that enforces Valid content in PUT.\n\nIf that is deemed infeasible, perhaps we could prevail on Henrik to add a POST\nto validator.w3.org to Web Commander.\n\n\n\n[0] - I assume it's <http://www.w3.org/WinCom/> we're talking about here?\n\n- -- \nMy mom is a professional botanist, or, as her spousal equivalent described\nit, they'll be out hiking in the woods, she'll see a plant off by the side\nof the trail, run up to it, bend down, and start talking Latin at it.\n                                                      -- Steve VanDevender\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPtmql6PyPrIkdfXsEQJ6BgCfXjEOvcf7oWdCkR6NxobQyputqeQAoNPd\nCSJZKeJ+Nir1AHYeHm9n1qrG\n=ggIF\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12321531"}, {"subject": "Re: [check] Status and Progres", "content": "The new version looks like?a big improvement on the previous version.\n?\nI used the old version for way too long ;|\n?\n--------------\nPegaweb Web Design & Photoshop Tutorials\nhttp://www.pegaweb.com\n?\n\n\n\n", "id": "lists-017-12331385"}, {"subject": "Fwd: New code for better display of undecodable line", "content": "[this is the right list to send that kind of messages :) ]\n\nBegin forwarded message:\n\n> Resent-From: www-validator-cvs@w3.org\n> From: Martin Duerst <duerst@w3.org>\n> Date: Fri Jun 6, 2003  00:32:52 Asia/Tokyo\n> To: Terje Bless <link@pobox.com>\n> Cc: www-validator-cvs@w3.org\n> Subject: New code for better display of undecodable lines\n> X-Spam-Level:\n>\n>\n> Hello Terje, others,\n>\n> I just created a small branch labeled \"iconv-halfline\", and\n> committed some code that prints out whatever part of a line\n> that can be converted if the whole line can't be converted.\n> It's currently at 1.324.2.2.\n>\n> Can you please have a look at the code, and merge it back\n> in if you think it looks okay?\n>\n> It would be a good idea to style the #### piece e.g.\n> red and bold, so that people would see it more easily.\n> Then probably the number of # can be reduced.\n>\n> Regards,    Martin.\n>\n>\n\n\n\n", "id": "lists-017-12338074"}, {"subject": "Fwd: Leftover source fragmen", "content": "Begin forwarded message:\n\n> Resent-From: www-validator-cvs@w3.org\n> From: Martin Duerst <duerst@w3.org>\n> Date: Thu Jun 5, 2003  22:19:46 Asia/Tokyo\n> To: Terje Bless <link@pobox.com>\n> Cc: www-validator-cvs@w3.org\n> Subject: Leftover source fragment\n> X-Spam-Level:\n>\n>\n> Hello Terje, others,\n>\n> I just had a quick look at my version of 'check'.\n>\n> I found the following code changes that I had made but\n> never checked in:\n>\n> duerst@validator:~/validator/httpd/cgi-bin$ cvs diff check\n> Index: check\n> ===================================================================\n> RCS file: /sources/public/validator/httpd/cgi-bin/check,v\n> retrieving revision 1.324\n> diff -r1.324 check\n> 339c339\n> < } elsif ($File->{Charset}->{Auto} =~ /^utf-16[bl]e$/ && $File->{BOM} \n> == 2) {\n> ---\n> > } elsif ($File->{Charset}->{Auto} =~ /^utf-16[bl]e$/) {\n> 450a451,459\n> >     </p>\n> > .EOF.\n> > }\n> >\n> > if ($File->{Charset}->{Use} eq 'utf-16' and $File->{BOM} != 2) {\n> >   $File->{'Error Flagged'} = TRUE;\n> >   $File->{'Error Message'} = <<'.EOF.';\n> >     <p>\n> >       UTF-16 without a BOM is not legal XML.\n>\n>\n> Maybe these changes are irrelevant because the same thing is now done\n> by other changes. But the issue is definitely one that we have to\n> check for.\n>\n>\n> Regards,    Martin.\n>\n\n\n\n", "id": "lists-017-12347463"}, {"subject": "Error message", "content": "The debate has come to life on www-validator again!\n\nI'm posting the ParserMessages.msg I use for Page Valet here, and I'll\npost a pointer in the current thread on validator.  Should we consider\nusing these (or some further-modified version) for v.w.o?\n\n-- \nNick Kew\n\n\n\n\nTEXT/PLAIN attachment: ParserMessages.msg\n\n\n\n\n", "id": "lists-017-12356129"}, {"subject": "Re: Error message", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nNick Kew <nick@webthing.com> wrote:\n\n>The debate has come to life on www-validator again!\n>\n>I'm posting the ParserMessages.msg I use for Page Valet here, and I'll\n>post a pointer in the current thread on validator.  Should we consider\n>using these (or some further-modified version) for v.w.o?\n\nWell, we certainly need better messages; but I really don't want to use a\npatched version of OpenSP for the Validator if at all possible. My current\nplan (for 0.7) is to get the message numbers out of onsgmls and keep a\ncompletely separate catalog; either to replace its messages or to supplement\nthem. Possibly also context sensitive so that references to specific elements\nwill trigger appropriate explanations.\n\n\n- -- \n\"Temper Temper! Mr. Dre? Mr. NWA? Mr. AK, comin??\n straight outta Compton and y'all better make way?\"            -- eminem\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA+AwUBPuz3o6PyPrIkdfXsEQL55ACgw/noYdhHkNX5quKjylcDvQsWLbUAmLbt\noZGGKYCS2YctQ4ABn3po3N4=\n=b6Yn\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12363171"}, {"subject": "Re: Fwd: New code for better display of undecodable line", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nOlivier Thereaux <ot@w3.org> wrote:\n\n>>Can you please have a look at the code, and merge it back in if you\n>>think it looks okay?\n>>\n>>It would be a good idea to style the #### piece e.g. red and bold, so\n>>that people would see it more easily. Then probably the number of # can\n>>be reduced.\n\nYup, this is now in CVS. Unfortunately, there is no easy way to style it in\nthe current code. I'll look at options for doing that (in general) for 0.7.\n\n- -- \nWe've gotten to a point where a human-readable,  human-editable text format\nfor structured data has become a complex nightmare where someone can safely\nsay \"As many threads on xml-dev have shown, text-based processing of XML is\nhazardous at best\" and be perfectly valid in saying it.     -- Tom Bradford\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBPuz4WqPyPrIkdfXsEQLKXQCdHQOJ99TRumejUmH3Pmgvn/eQ+DoAn2Ni\nwe9oQxrjia2u8x/vh5Pr+eYW\n=Qigi\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12371520"}, {"subject": "Re: Error message", "content": "On Mon, 2003-06-16 at 01:48, Terje Bless wrote:\n> Nick Kew <nick@webthing.com> wrote:\n>\n> >I'm posting the ParserMessages.msg I use for Page Valet here, and I'll\n> >post a pointer in the current thread on validator.  Should we consider\n> >using these (or some further-modified version) for v.w.o?\n> \n> Well, we certainly need better messages; but I really don't want to use a\n> patched version of OpenSP for the Validator if at all possible.\n\nHooray from the packaging point of view! :)\n\nNick, aren't your changes (or a subset of them) acceptable upstream in\nOpenSP?\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12380189"}, {"subject": "Re: Error message", "content": "On 16 Jun 2003, Ville Skytt? wrote:\n\n> > Well, we certainly need better messages; but I really don't want to use a\n> > patched version of OpenSP for the Validator if at all possible.\n>\n> Hooray from the packaging point of view! :)\n\nIt's not really a serious issue for packaging; the different sets of\nmessages are completely interchangable as far as building and running\na working installation are concerned.\n\n\n> Nick, aren't your changes (or a subset of them) acceptable upstream in\n> OpenSP?\n\nI haven't asked there.  The basic issue is that some of the changes\nare pretty specific to the validation task, and would probably not\nbe appropriate to other OpenSP applications.\n\nFor example, it replaces a warning about NET-enabling start tag with\n(from memory) \"Stray slash found in start tag: are you confusing SGML\nand XML (or HTML and XHTML) syntax?\"\n\nDo you think I should post a diff to openjade-devel with a pointer to\nthis thread, and ask for opinions?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-12387856"}, {"subject": "Re: Error message", "content": "On Mon, 2003-06-16 at 02:35, Nick Kew wrote:\n> On 16 Jun 2003, Ville Skytt? wrote:\n> \n> > > Well, we certainly need better messages; but I really don't want to use a\n> > > patched version of OpenSP for the Validator if at all possible.\n> >\n> > Hooray from the packaging point of view! :)\n> \n> It's not really a serious issue for packaging; the different sets of\n> messages are completely interchangable as far as building and running\n> a working installation are concerned.\n\nOk, but there's stuff like\n<http://validator.w3.org:8001/docs/errors.html>...\n\n> > Nick, aren't your changes (or a subset of them) acceptable upstream in\n> > OpenSP?\n> \n> I haven't asked there.  The basic issue is that some of the changes\n> are pretty specific to the validation task, and would probably not\n> be appropriate to other OpenSP applications.\n> \n> For example, it replaces a warning about NET-enabling start tag with\n> (from memory) \"Stray slash found in start tag: are you confusing SGML\n> and XML (or HTML and XHTML) syntax?\"\n> \n> Do you think I should post a diff to openjade-devel with a pointer to\n> this thread, and ask for opinions?\n\nThat's what I'd do.  It's a win-win situation for everyone in the end if\neven some of the changes are considered improvements to OpenSP and get\napplied there.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12395981"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Fri, 2003-02-28 at 20:37, Terje Bless wrote:\n\n> Ville: Can we use the vendor sgml-lib on Red Hat?\n\nI believe the vendor libs are currently only a small subset of what we\nwant to be able to validate against.  They seem to be adding more\nthough, rawhide has xhtml1-dtds for example.\n\n>  Integrate with it?\n\nYes, the catalogs can be integrated with the system, using\ninstall-catalog(8) and/or xmlcatalog(1).  I'll have a look at doing this\nin the spec file, probably already for 0.6.2.\n\n> In the 0.7.0 timeframe we should be able to provide a suffieciently clean\n> sgml-lib package -- possibly the proposed separate DTD registry/collection\n> project -- that we could propose Red Hat use that instead/in addition to\n> what they ship now.\n\nYes, my +[as many as I have] for it.  And by no means it should be\nlimited to Red Hat; there are multiple OS's and the like that would\nbenefit greatly from this.  I'm interested in contributing some work to\nmake this happen.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12429790"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Fri, 2003-02-28 at 20:37, Terje Bless wrote:\n\n> Ville: Can we use the vendor sgml-lib on Red Hat?\n\nI believe the vendor libs are currently only a small subset of what we\nwant to be able to validate against.  They seem to be adding more\nthough, rawhide has xhtml1-dtds for example.\n\n>  Integrate with it?\n\nYes, the catalogs can be integrated with the system, using\ninstall-catalog(8) and/or xmlcatalog(1).  I'll have a look at doing this\nin the spec file, probably already for 0.6.2.\n\n> In the 0.7.0 timeframe we should be able to provide a suffieciently clean\n> sgml-lib package -- possibly the proposed separate DTD registry/collection\n> project -- that we could propose Red Hat use that instead/in addition to\n> what they ship now.\n\nYes, my +[as many as I have] for it.  And by no means it should be\nlimited to Red Hat; there are multiple OS's and the like that would\nbenefit greatly from this.  I'm interested in contributing some work to\nmake this happen.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12438079"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "On Fri, 2003-02-28 at 21:05, Olivier Thereaux wrote:\n\n> > The big hurdle is probably that it's a PITA to get things\n> > uploaded there ATM as Olivier and the other W3Cers are the only ones \n> > with\n> > sufficient privileges to put stuff in place ATM (though that can \n> > probably\n> > be fixed if we need to).\n> \n> We could proxy this particular location on v.w3.org to someplace else \n> where it's less of a burden to give upload privileges (e.g qa-dev), or \n> I can set up a cron'd sync from another location (Frederic and Ville's \n> sites, etc.) Plenty of potential solutions.\n\nI would not prefer cron'd syncs because I don't have direct control over\nthe host where I have my stuff at the moment.  ~ville/dist/ or something\nat qa-dev sounds good to me.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-12446420"}, {"subject": "RE: Character-by-Character Distinct IRI-&gt; Char-by-char     equivale nt URI (issue #IRIURIcharequiv20", "content": "At 23:29 04/03/25 +0000, Williams, Stuart wrote:\n\n>Hello Martin,\n>\n> > I therefore am tentatively closing this issue with 'no action needed'.\n> > If you think that some change to the document is needed,\n> > please say so (ideally with some actual proposed text).\n>\n>The short answer is yes... I agree.\n\nOkay, great, thanks! I'll move the issue to closed, then.\n\n\n>I chewed on this of quite a time. Even came with and idea to address your\n>challenge (which I'll mention below) but I think it amounts the same thing\n>as the MUST NOT in section 5.1:\n>\n>    As an example,\n>    http://example.org/~user, http://example.org/%7euser, and\n>    http://example.org/%7Euser are not equivalent under this definition.\n>    In such a case, the comparison function MUST NOT map IRIs to URIs,\n>    because such a mapping would create additional spurious equivalences.\n>\n>It was the \"spurious equivalences\" phrase that triggered my concern.\n\nIf you have any idea on how to phrase this in a better way,\nplease tell me. I agree that \"spurious equivalences\" can be\na bit misleading.\n\n\n>My idea to address your challenge, which I'm not overly committed to... and\n>I think amounts the the same as the MUST NOT above is this:\n>\n>Regard the lexical spaces of URI and IRI as disjoint ie. if the identifier\n>string is valid under the URI grammar... it's a URI and *not* an IRI. IRI\n>are then the remaining strings that match the IRI grammar. Effectively this\n>forces IRI to be only those identifier strings that actually contain\n>characters that are not 'legal' in URI. Character by character IRI/IRI and\n>URI/URI comparision work as normal. Character-by-character IRI/URI\n>comparison always yield not-equal (because URI and IRI are disjoint).\n\nThis alone wouldn't do it. Just take a more complicated example:\n\nhttp://www.example.org/ros&eacute;/ros%C3%A9 and\nhttp://www.example.org/ros&eacute;/ros&eacute;\n\nBoth of them are IRIs in your definition (because the contain at\nleast one &eacute; non-ascii character), and both of them map to\nthe URI\n\nhttp://www.example.org/ros%C3%A9/ros%C3%A9\n\nThere are probably ways to wiggle out of that problem, but that\nwould mean changing the IRI->URI function, making it much more\ncomplicated, for a doubtful gain in practice.\n\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-1244905"}, {"subject": "Re: [check] 0.6.2 release (Was Re: inaccuracies in validator", "content": "Le Fri, 28 Feb 2003 19:37:54 +0100, tu as ecrit :\n\n>> what was the decision about storing the RPM/DEBs and their\n>> dependencies on v.w.o ?\n\n> I've made the /source/ page point at a /dist/ directory on v.w3.org with\n> the intention that this directory will not exist in CVS. This is where I\n> intended that anything downloadable should reside.\n\n> Whether or not to host the binary packages and the dependencies there\n> depend entirely on what you and Ville think is best. If it is practical for\n> you and for users to host it there I think that makes sense (IIRC Olivier\n> also thinks this would be ok, right?).\n\nI'll have the package (and its dependencies) on my site in any case, but it\nmay be a good idea to mirror it on v.w.o, if only to ensure that the\npackages will always be available at a \"stable\" URL, even if someone take\nover the package maintenance. A cron'd sync (as suggested by Olivier) would\nbe fine, this way I won't need any special access to a w3c server.\n\n>> I added a note on the \"source\" page saying that if you are on a\n>> Debian system, you can see the source by doing bla bla and bla.\n> Can this reasonably be integrated into the v.w3.org version so you won't\n> have to maintain this diff?\n\nYes -- see attached diff. Comments welcome (about content or grammar).\n\n> I'll see what I can do to make this work better for Debian. It would help\n> if you could describe the directory structure and relevant filenames for\n> me.\n\nThe situation is as follows:\n\n  - /etc/sgml contains all the catalogs, including the main catalog\n    (/etc/sgml/catalog) which references the other catalogs\n    (/etc/sgml/w3c-dtd-xhtml.cat, etc).\n  - all the DTDs are stored in subdirectories of /usr/share/sgml\n \nAs far as I know, the validator does not really need to know about the\ncatalog (onsgmls knows about the main catalog), but it has to add\n/etc/sgml and /usr/share/sgml to SGML_SEARCH_PATH because of the -R\noption.\n\nJust an idea about a possible way to do it:\n\n  - have an option in the config file which specifies additional\n    directories that should be added to SGML_SEARCH_PATH;\n  - leave the \"SGML Library\" config option empty in the Debian package, and\n    modify check so that it does not specify a catalog for onsgmls in this\n    case.\n\nIn any case, it would certainly be worth moving some hardcoded options\n(like the catalog names, xml.soc etc) into the configuration file in a way\nor another.\n\n> In the 0.7.0 timeframe we should be able to provide a suffieciently clean\n> sgml-lib package -- possibly the proposed separate DTD registry/collection\n> project -- that we could propose Red Hat use that instead/in addition to\n> what they ship now.\n\nFollowing Ville's comment (\"I believe the vendor libs are currently\nonly a small subset of what we want to be able to validate against\"), I\nwas wondering: which DTDs should the validator be able to validate against\n? Debian doesn't contain all the DTDs that are provided in sgml-lib, but do\nwe really need all of them ? If needed, I can package the missing ones, but\nsome of them do not seem essential.\n\n> Ville maintains the spec file (more or less?) in CVS, but I dunno\n> whether that would make sense for you and the Debian package.\n\nNo, an independant /debian dir is the best solution at the moment. \n\n> I think I have this in my TODO somewhere too. Ping me about it if it\n> hasn't been fixed when I tag 0.6.2 in CVS will you?\n\nWill do !\n\nFr?d?ric\n\n\n\n\ntext/plain attachment: email.txt\n\n\n\n\n", "id": "lists-017-12454565"}, {"subject": "mod_validato", "content": "As some of you know, I've been working on validation as an Apache\nmodule.  This gives us major performance benefits when running online,\nand I've taken the opportunity to make further improvements.\n\nThis will go public as Page Valet 4.0 as soon as I feel sufficiently\nconfident in it.  But it appears to be working well, and I've now\nput up a preview at <URL:http://valet.webthing.com/page/index4.html>.\nComments and criticisms invited!\n\nMight W3C be interested in using this?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-12465502"}, {"subject": "CVS not up to date", "content": "I thought I'd fix the bad error explanation as pointed out by Jukka in\nhttp://lists.w3.org/Archives/Public/www-validator/2003Nov/0012.html but\ndid not find that in CVS.\n\nv.w.o:8001 seems to have a verbosemsg.cfg which is not in CVS nor is the\ncorresponding verbosemsg.rc that would produce it.  I didn't find the\n*.rc on v.w.o either.  Terje, is it possible that you've forgot to\ncommit something? :)\n\n\n\n", "id": "lists-017-12495166"}, {"subject": "[checklink] very long checking times  any idea", "content": "Hi,\n\nI just got reports of \"sluggishness\" for checklink. I checked, and it \nseems indeed like checklink takes > 5 seconds to HEAD each resource.\n\nsample below\n[[\nHEAD http://www2003.org/  fetched in 5.3s\nChecking link http://www.w3.org/Icons/WWW/w3c_home\nHEAD http://www.w3.org/Icons/WWW/w3c_home  fetched in 5.0s\nChecking link http://www.w3.org/QA/Activity\nHEAD http://www.w3.org/QA/Activity  fetched in 5.0s\n]]\n\nThe server is, however, not awfully overloaded, and although it has \nsuffered a DOS attack recently, I doubt this is related.\n\nVille, do you have any idea what could cause this, or any experience of \nsimilar trouble?\n\n-- \nolivier\n\n\n\n", "id": "lists-017-12521777"}, {"subject": "Re: [checklink] very long checking times  any idea", "content": "On Thu, 2003-10-09 at 19:46, Olivier Thereaux wrote:\n\n> I just got reports of \"sluggishness\" for checklink. I checked, and it \n> seems indeed like checklink takes > 5 seconds to HEAD each resource.\n[...]\n>\n> Ville, do you have any idea what could cause this, or any experience of \n> similar trouble?\n\nAt least there are some DNS problems on v.w.o.  The primary nameserver\n(ie the first one in /etc/resolv.conf) doesn't answer at all, others\nseem to be fine.  The effect can be witnessed eg. by running the\nfollowing several times and comparing the results:\n\n   time HEAD -d http://www.w3.org/\n   time HEAD -d http://18.29.1.34/\n\nA 5 second DNS timeout somewhere?  I was about to suggest running nscd\non v.w.o but it seems to be running named anyway...\n\nThere are some problems with checklink that prevent HTTP Keep-Alive\nworking too well, the LWP::UserAgent instances aren't always reused. \nThat may cause the delay even between requests to the same hostname\nduring a single checklink run.\n\n\n\n", "id": "lists-017-12529709"}, {"subject": "Re: [checklink] very long checking times  any idea", "content": "On Friday, Oct 10, 2003, at 03:24 Asia/Tokyo, Ville Skytt? wrote:\n> On Thu, 2003-10-09 at 19:46, Olivier Thereaux wrote:\n>> Ville, do you have any idea what could cause this, or any experience \n>> of\n>> similar trouble?\n>\n> At least there are some DNS problems on v.w.o.\n\nGood catch Ville, thanks for investigating. I'll try to have that fixed \nASAP.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-12538432"}, {"subject": "Source Page and Other Validator", "content": "Saqib Ali - who posted to www-validator a couple of months ago -\nhas made his PHP-based validator available at Sourceforge and\nannounced it on ciwah.  This looks like a serious alternative to\nthe Usual Suspects, and set me thinking ...\n\nv.w.o already links to other online services (wdg and valet).\nBut should the Source page also link to other open-source\nvalidator programs?  Something along the lines of:\n\n===================================================\nOther HTML Validators:\n\nThere are several alternative webserver-based validators available\nfor free download:\n\n  * The [WDG Validator] is another Perl validator broadly\n    comparable to this one.\n  * [mod_validator] is a C++ validator that links directly in to\n    the [Apache webserver].\n  * The [LDP Validator] is a PHP-based validator.\n\nAnother option is a desktop validator:\n  * [Validator-Lite] is a C++ desktop validator with GTK frontend.\n\nAnother tool that may be of interest is [CatalogueManager], that\nserves to keep your DTDs and Entity collection up to date.\n\n===================================================\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-12545969"}, {"subject": "Re: Are IDNs allowed in http IRIs", "content": "Larry Masinter <LMM@acm.org> wrote:\n\n> It seems like a pretty big change to the IRI concept to have IRI ->\n> URI transformations use scheme-specific knowledge.  Formerly, IRI ->\n> URI transformation was specified as scheme independent.\n\nI think it may help conceptually to distinguish between generic URIs and\nURIs of a particular scheme.  For example, foo:bar is a valid generic\nURI, but it might not be a valid foo: URI.\n\nGiven a foo: IRI, there are two kinds of IRI -> URI conversion we might\nbe interested in.  We might merely want to convert to a valid generic\nURI in order to tunnel it through some ASCII infrastructure before being\nultimately resolved by an IRI resolver, in which case we don't actually\nneed a valid foo: URI.  Or we might want to convert to a valid foo: URI\nso that a foo: URI resolver can resolve it.\n\nThe former of those two tasks can obviously be done without\nscheme-specific knowledge.  But if you want the URI to be\nresolvable, you can't get the job done without scheme-specific\nknowledge.  Many (most?) browsers today will not resolve\nhttp://%E7%8C%AB%E3%81%AB%E5%B0%8F%E5%88%A4.nicemice.net/ because\nthey don't handle percent-encoding in the host component, because\nit's not valid according to the current http: URI spec.  (Even\nFirefox, which fetches the page when I type the Japanese domain\nlabel directly in Japanese, cannot resolve the percent-encoded\nUTF-8 form.)  Many (most?) browsers today will not resolve\nmailto:webmaster@%E7%8C%AB%E3%81%AB%E5%B0%8F%E5%88%A4.nicemice.net even\nthough they percent-decode the domain, because they (or the MUA they\ninvoke) are not expecting UTF-8 in the mail address, because it's not\nvalid according to the current mail address spec.  If you want URIs that\nare meaningful according to current specs and can be resolved by current\nURI resolvers, you need http://xn--r9j282hvzgc6x.nicemice.net/ and\nmailto:webmaster@xn--r9j282hvzgc6x.nicemice.net.\n\n> Do we need a separate spec for \"http:\", \"mailto:\", \"ftp:\" IRIs, where\n> each specifies the punycode vs. hex-encoding of the various parts?\n\nI don't think so; I think it is sufficient to have separate specs for\nhttp, mailto, and ftp URIs, which we already have.  The conversion of\nIRIs to URIs can then be defined by general rules in the IRI spec.  For\nexample, see the latter part of\n\nhttp://lists.w3.org/Archives/Public/uri/2004Mar/0049.html\n\nafter \"redefine the validity of IRIs\".\n\nMartin Duerst <duerst@w3.org> wrote:\n\n> At most, there should be a single bit per scheme that says whether\n> punycode should be applied to the 'host' part.\n\nThis middle-ground approach is both too much (every IRI-to-URI convertor\nneeds to recognize all schemes) and too little (mailto: is not handled).\nWhat do you think of recognizing two kinds of IRI-to-URI conversion, a\nscheme-agnostic kind for tunneling through URI infrastructure to IRI\nresolvers, and a fully scheme-aware kind for interoperating with URI\nresolvers (and for defining the meaning of the IRI)?\n\nIn other words, there are three data types:  IRIs are non-ASCII and\ncan be resolved by IRI resolvers.  URIs are ASCII and can be resolved\nby legacy URI resolvers.  HRIs (hybrid resource identifiers) are both\nIRIs and generic URIs; they can be resolved by IRI resolvers but not\nby legacy URI resolvers; they can traverse infrastructure that accepts\ngeneric URIs without needing to resolve them; and they survive relative\nURI processing.  Conversion between IRIs and HRIs (in either direction)\nneeds no scheme-specific knowledge, but conversion to URIs does.\n\nThis model recognizes the inescapable fact that in order for something\nlike mailto:postmaster@jos?.example.net to be useful, two pieces of\nknowledge need to come together:  IDNA (which is internationalization\nknowledge), and the fact that the thing after the at-sign is a domain\nname (which is mailto knowledge).  The three-type model makes it clear\nthat you can either smarten up the IRI layer with scheme knowledge or\nsmarten up the URI resolution layer with IRI knowledge, but one or\nthe other is required, and therefore the meaning of something like\nmailto:postmaster@jos?.example.net can be well-defined.  I think the\ntwo-type model lets this requirement slip through the cracks; both\nlayers try to limit their knowledge at the same time, but that just\ndoesn't work.\n\n> But to a large extent, this is actually an implementation issue.\n\nBefore I can begin to plan or assess an implementation, I need to know\nwhat it intends to implement.  What is http://jos%e9.example.net/ supposed\nto mean?  The IRI spec says it is supposed to mean the same thing as\nToURI(http://jos%e9.example.net/), but that is not deterministic; it is\nboth http://jos%C3%A9.example.net/ and http://xn--jos-dma.example.net/,\nand while the latter has a meaning, the former doesn't (at least, not\nwith rfc2396bis as it stands, see my previous message).\n\nIn order for the IRI http://jos%e9.example.net/ to have a well-defined\nmeaning, so that we know what our implementation is aiming for, we need\nto tweak either the HTTP spec, the URI spec, the IDNA spec, or the IRI\nspec.  Since the URI and IRI specs are the ones in flux at the moment,\nthey seem like the prime candidates.\n\nAMC\nhttp://www.nicemice.net/amc/\n\n\n\n", "id": "lists-017-1255189"}, {"subject": "Re: Source Page and Other Validator", "content": "On Thu, 23 Oct 2003, Saqib Ali wrote:\n\n> Nick,\n>\n> Thanks for the email. Just a little bit more information about the\n> validator at http://validate.sf.net\n>\n> The validator is being primarily implemented for the \"Linux Documentation\n> Project\" (LDP) where authors submit documents using DocBook XML\n> v4.1.2/4.2. But I plan to support all the HTML/XHTML DTDs as well.\n\nYes, I got that from your announcement.\n\n> One thing that is required for LDP is that, the documents can reference\n> external entities, using ENTITY or XINCLUDE. So I have to support that\n> i.e. be able to validate the master document as well as the external\n> entities. So I am working on that. Meanwhile we will support all\n> HTML/XHTML DTDs.\n\nPage Valet/mod_validator already validates external entities, but\nsuppresses messages coming from them (to avoid unduly confusing the\nissue for the majority Web-ish users).  All you need is the option\nto uncheck this suppression in the Advanced Form.\n\nI think the same is in principle true of the onsgmls-based validators,\nwith the provisos that you have the extra job of parsing output, and\nthat its XML support is less complete.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-12554488"}, {"subject": "[check] validators hosed today  hopefully OK no", "content": "Hi all.\n\nFor a couple hours the validators (:80 and 8001... not :8000 but it's \nnot using onsgmls, and nobody cares about it anyway) were hosed. I \nimmediatly knew there was something fishy with openSP, but couldn't \nreally find what (broken debian upgrade?) until I killed this little \nbugger process on v.w.o:\n\nnobody   15504 56.6  0.7  6168 3868 ?        R    00:10 114:20 \n/usr/bin/onsgmls -n -c /home/link/validator/htdocs/sgml-lib/xml.soc -R \n-wvalid -wnon-sgml-char-ref -wno-duplicate -wxml -E0\n\nwhich had been running for a very long time.\n\nWhy *this* process apparently caused all onsgmls processes to fail \nbaffles me, but at least it seems we're back in business.\n\n*phew*\n-- \nolivier\n\n\n\n", "id": "lists-017-12585368"}, {"subject": "[check] RPM nitpicks..", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nFYI, on my clean Red Hat Linux 9 + errata box, installing from the RPMs\n(??rpm -Uvh *.rpm??) generated the following output:\n\n[[[\nwarning: docbook-dtds-1.0-22.1.noarch.rpm: \\\n  V3 DSA signature: NOKEY, key ID e418e3aa\nwarning: docbook-style-dsssl-1.78-2.noarch.rpm: \\\n  V3 DSA signature: NOKEY, key ID 897da07a\nwarning: perl-Config-General-2.21-0.fdr.1.noarch.rpm: \\\n  V3 DSA signature: NOKEY, key ID bcd241cb\nPreparing...                ########################################### [100%]\n   1:w3c-markup-validator-li########################################### [ 11%]\n   2:perl-Text-Iconv        ########################################### [ 22%]\n   3:perl-Set-IntSpan       ########################################### [ 33%]\n   4:perl-Net-IP            ########################################### [ 44%]\n   5:perl-Config-General    ########################################### [ 56%]\n   6:docbook-dtds           ########################################### [ 67%]\n   7:openjade               ########################################### [ 78%]\n   8:docbook-style-dsssl    ########################################### [ 89%]\n   9:w3c-markup-validator   ########################################### [100%]\nFailed to remove entry from /etc/sgml/sgml-docbook-3.0-1.0-17.cat\nFailed to remove entry from /etc/sgml/sgml-docbook-3.1-1.0-17.cat\nFailed to remove entry from /etc/sgml/sgml-docbook-4.0-1.0-17.cat\nFailed to remove entry from /etc/sgml/sgml-docbook-4.1-1.0-17.cat\nFailed to remove entry from /etc/sgml/xml-docbook-4.1.2-1.0-17.cat\nFailed to remove entry from /etc/sgml/sgml-docbook-4.2-1.0-17.cat\nFailed to remove entry from /etc/sgml/xml-docbook-4.2-1.0-17.cat\n]]]\n\n\nSimilar ??NOKEY?? warnings were generated when doing the same with only the\n??w3c-markup-validator?? and ?????-libs?? RPMs (i.e. without satisfying all the\ndependancies).\n\n- -- \n\"A plague o' both your houses! I am sped.\" - Mercutio, kinsman to the Prince.\n                   See Project Gutenberg <URL:http://promo.net/pg/> for more.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBP134CKPyPrIkdfXsEQIQSwCggE3z2Jav1crQUmQy1DRoMJRQ9NYAn0aa\nGhDPTOcDIGreK1pg/cx5TbMW\n=hwpi\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12592210"}, {"subject": "RFC: A Distributed Universal SGML/XML Catalogue Management Syste", "content": "Rationale\n=========\n\nMany applications today benefit from an SGML and/or XML Entity Catalogue\nto dereference entities referenced by a Public Identifier.  For a\nvalidating SGML parser this is an absolute requirement.  For any\nSGML or XML parser it serves to enable entities such as DTDs and\nmodules to be resolved locally.\n\nHitherto, different packages and applications have distributed entity\ncatalogues.  Examples are Docbook, HTML Validators, the OpenSP parser,\nand operating system distros.  However, there is little coordination\nbetween the distributors of these, and no common package distributors\ncan rely on.  Even in tightly-controlled environments such as the\nDebian packages, the W3C Validator includes its own Entity\nCatalogue rather than relying on it being available as a dependency.\n\nThis situation should be rationalised to allow for an SGML and XML\ncatalogue to be a single package on which other packages can depend.\nIn this note, we propose a framework for managing such a package.\n\nGoals\n=====\n* To maintain a Universal Catalogue\n* To provide an automated process for generating local installations of\n  all or part of the Universal Catalogue.\n* To minimise the effort and coordination required to ensure that the\n  universal catalogues and local installations remain up-to-date.\n  In particular, end-users should be offered a self-maintaining default\n  installation that eliminates effort on their part altogether.\n* To enable control of different parts of the catalogue to be delegated\n  to the people/organisations responsible for them.\n\nA loose analogy could be drawn to DNS.  But since immediate lookup of\n[SG|X]ML entities is dealt with by SYSTEM ids, we only have to deal with\nefficient cacheing of local copies of PUBLIC ids.  Entities are in\ngeneral long-lived, but by no means immutable (for example, the MathML 2\nDTD modules have undergone several minor revisions).\n\nManaging a Universal Catalogue\n==============================\n\nIn principal, all organisations creating public identifiers should be\nregistered with ISO.\nBut this is not widely practiced, and the present chaotic situation\nindicates that it is not effectively meeting todays needs.  We propose\nthat a distributed architecture for automating catalogue management\nis both feasible and preferable.\n\n#### ISO registry: availability???\n\nOur proposal envisages a central registry, cooperating with a set of\nrecognised repositories each managing its own entity catalogue locally.\nFor example, the W3C, WapForum and Oasis each manage their own catalogues\nindependently.  Likewise, different groups acting independently within\nW3C are responsible for different areas such as HTML, MathML, SVG and\nSMIL.\nWe propose that a universal catalogue will work best if responsibility\nfor each sub-catalogue is explicitly devolved to the working group\nresponsible for defining it.  The central registry will serve merely\nto reference the reponsible groups, in a manner somewhat analagous to DNS.\n\nThis is broadly in line with the registry already run by the ISO but\nnot widely used.  What our proposal adds is the availability of the\nregistry online in machine-readable format, and its integration with\ncatalogues maintained by each participating organisation.  It is\npossible that tying the registry in to distribution of Markup libraries\nand catalogues may in itself be an incentive for organisations to\nregister.\n\n#### Implications for naming conventions?\n\nImplementation\n==============\n\nSince the Universal Catalogue serves SGML and XML applications, it is\nappropriate that it should itself be capable of implementation as an\nSGML or XML application.  This is straightforward: all we need is a\nDTD for declaring catalogues and catalogue entries, and a list of\nentities defining catalogues maintained by the groups entrusted with\ndoing so.  This is then implemented by a program to fetch the data\nrequired and write the catalogues.  Local installations may be\ncustomised by selecting which entities to include, while package\nmaintainers can ship a standard configuration.\n\nAn implementation demonstrating the above is available at\n<URL:http://valet.webthing.com/catalogue/>.  It fetches the master\ncatalogue, DTD and Entities by HTTP.  It updates all entries defined,\nbut uses HTTP If-Modified-Since header to avoid the overhead of re-\nfetching anything that is already up-to-date in the local installation.\nIt can therefore be run regularly (e.g. monthly) with minimal overhead.\n\nCatalogueManager may be used as-is, but is intended as a proof-of-concept.\nNon-technical issues such as how to delegate responsibility for different\nsub-catalogues need to be addressed, and the file format used for\nthe demonstrator is likely to be subject to improvement.\n\nSecurity\n========\n\nA package such as CatalogueManager that updates system files based on\nthird-party definitions has potential to introduce malicious files.\nIt is strongly recommended that standard system security be used to\navoid serious consequences in the event of any of the sub-catalogues\nbeing compromised.  CatalogueManager should run as a user with no\nprivilege to write to the local filesystem except within a designated\nSGML/XML library area, such as /usr/local/share/sgmlib.\nDistributors creating a package such as an RPM of CatalogueManager\nshould ensure your users' security.\n\nA more inherently secure architecture would generate all local filenames\ninternally, and is probably preferable.  The current implementation serves\nfor back-compatibility until the proposal can be considered stable.\n\n\n\n", "id": "lists-017-12601445"}, {"subject": "Re: [check] RPM nitpicks..", "content": "On Tue, 2003-09-09 at 18:55, Terje Bless wrote:\n\n> warning: docbook-dtds-1.0-22.1.noarch.rpm: \\\n>   V3 DSA signature: NOKEY, key ID e418e3aa\n> warning: docbook-style-dsssl-1.78-2.noarch.rpm: \\\n>   V3 DSA signature: NOKEY, key ID 897da07a\n> warning: perl-Config-General-2.21-0.fdr.1.noarch.rpm: \\\n>   V3 DSA signature: NOKEY, key ID bcd241cb\n\nRecent versions of rpm complain if you haven't imported the keys that\nthe to-be-installed packages are signed with.  The keys:\n\nbcd241cb: My key.\n897da07a: The old Red Hat Rawhide key.\ne418e3aa: The new (2003) Red Hat Rawhide key.\n\nSee http://cachalot.mine.nu/9/#key for more info.\n\n> Failed to remove entry from /etc/sgml/sgml-docbook-3.0-1.0-17.cat\n> Failed to remove entry from /etc/sgml/sgml-docbook-3.1-1.0-17.cat\n> Failed to remove entry from /etc/sgml/sgml-docbook-4.0-1.0-17.cat\n> Failed to remove entry from /etc/sgml/sgml-docbook-4.1-1.0-17.cat\n> Failed to remove entry from /etc/sgml/xml-docbook-4.1.2-1.0-17.cat\n> Failed to remove entry from /etc/sgml/sgml-docbook-4.2-1.0-17.cat\n> Failed to remove entry from /etc/sgml/xml-docbook-4.2-1.0-17.cat\n\nThese, on the other hand look like packaging bugs in the Rawhide (or\nRHL9) docbook-dtds package.  I haven't rebuilt them at all, just\ndownloaded from Rawhide to my repository (as witnessed by the RH\nsignature).  This is part of the pain of getting a sane OpenSP 1.5 (or\nopenjade 1.3.2 in RH's case) installed on RHL 9.\n\n\n\n", "id": "lists-017-12613661"}, {"subject": "[server] one disk dead, data may have been los", "content": "Just for the information of those who may have been working on the \nqa-dev server lately.\n\nIn spite of using raid and a journaled fs, a hard drive crash on the \nmachine apparently caused some havoc yesterday, and according to the \nDaigo who worked on salvaging the machine, there *might* have been some \ndata lost. Bad luck.\n\nJust thought you might want to know that, just in case.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-12621659"}, {"subject": "FYI: New tips on prod validato", "content": "Hi all,\n\nA few proposed tips have gone through the 2 weeks period review on\nwww-qa, and so have I pushed them on the production service:\nhttp://www.w3.org/2003/07/30-color\n  If You Pick One Color, Pick Them All\nhttp://www.w3.org/2003/07/30-font-size\n  Care With Font Size\nhttp://www.w3.org/2001/06tips/use-links\n Use <link>s in your document\n\nSee:\nhttp://dev.w3.org/cvsweb/validator/htdocs/config/tips.cfg\n(I have put them in both the prod branch, and the current HEAD).\n\nOlivier, I have not put there \"Create legible Web pages\" as I was not\nsure if you still wanted it as a tip or if you thought it was to be\nsuperseded by Susan's tips.\nI think it doesn't hurt to have redundancy on those topics, but let me\nknow what you think.\n\nDOm\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-12628453"}, {"subject": "Re: FYI: New tips on prod validato", "content": "On Friday, Sep 19, 2003, at 01:26 Asia/Tokyo, Dominique Haza?l-Massieux \nwrote:\n\n> Hi all,\n>\n> A few proposed tips have gone through the 2 weeks period\n\nYeah, reminds me there is a new one to review...\n\n> http://www.w3.org/2003/07/30-color\n>   If You Pick One Color, Pick Them All\n\nThis one's borken, probably because of the comma.\nI tried the obvious (quote marks in the config file) without success.\nGuess DanC didn't foresee we'd use commas... I wish we'd use \nConfig::General already.\n>\n> Olivier, I have not put there \"Create legible Web pages\" as I was not\n> sure if you still wanted it as a tip or if you thought it was to be\n> superseded by Susan's tips.\n\nSusan's work expands and supersedes what I had done.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-12637330"}, {"subject": "validator.w3.org:80 down", "content": "validator.w3.org (the port 80 version) isn't responding at the moment. \nThe port 8001 version seems fine.\n\n\n\n", "id": "lists-017-12645584"}, {"subject": "Re: validator.w3.org:80 down", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>validator.w3.org (the port 80 version) isn't responding at the moment.\n>The port 8001 version seems fine.\n\nLooks ok from here now...\n\n- -- \n\"I don't mind being thought of as a badguy,\n but it /really/ annoys me to be thought of\n as an *incompetent* badguy!\" -- John Moreno\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.2\n\niQA/AwUBP3iAV6PyPrIkdfXsEQJyvACg9k0ZCGAIhOLai071mkB7aT9JikgAn1pP\nOJ+Js9peMHqFujkj1X4R3sgS\n=3cfu\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12652205"}, {"subject": "Re: validator.w3.org:80 down", "content": "On Mon, 2003-09-29 at 21:56, Terje Bless wrote:\n> Ville Skytt? <ville.skytta@iki.fi> wrote:\n> \n> >validator.w3.org (the port 80 version) isn't responding at the moment.\n> >The port 8001 version seems fine.\n> \n> Looks ok from here now...\n\nDitto, but when I posted that, it wouldn't respond even to \"telnet\nlocalhost 80\", just timed out.\n\nBy the way, now the 8001 version is refusing connections:\n\n  ville@lovejoy:~$ telnet localhost 8001\n  Trying 127.0.0.1...\n  telnet: Unable to connect to remote host: Connection refused\n\n\n\n", "id": "lists-017-12660519"}, {"subject": "Re: validator.w3.org:80 down", "content": "On Tuesday, Sep 30, 2003, at 04:28 Asia/Tokyo, Ville Skytt? wrote:\n> By the way, now the 8001 version is refusing connections:\n\nrestarted.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-12668590"}, {"subject": "Markup Validator's test suite  using EARL", "content": "Hi.\n\nI am currently working on a test suite for the Markup Validator, which \nwill eventually be semi-automated through the use of the Log Validator.\n\nCurrently the \"suite\" [1] is just a page with links pointing to either \nvalidation pages (using the test instance of the validator) or other \n\"test suites\", with notes about whether the page should validate or \nnot, sometimes a description of what is being tested (XML, charset, \netc). I would like to clean this up, bind it all using n3 and interface \nit with the Log Validator.\n\n[1] http://validator.w3.org/dev/tests/\n\n\nAfter a better look at how MUTAT [2] works, I started wondering whether \nwe could actually use EARL for the test descriptions.\n\n[2] http://www.barbwired.com/nadiaweb/tester/ (we have a version at \nw3.org but it doesn't work as well as this one, need to contact Nadiah \nabout it)\n\n\nIndeed we have:\n- web resources (our test cases)\n- which we know is invalid \"specX\" or not\n- which is used to test this or that part of the validator (XML, SGML, \ncharset, ...)\n\n- we know that for each of these test cases the current validator \"gets \nit right\" or not, which could certainly be expressed using EARL \nassertions.\n\n\nWithout really wanting to start (again) a discussion about a generic \nTest Case Description Language, I was wondering if anyone more familiar \nwith EARL and/or Test Cases would have comments and ideas about this.\n\ncheers,\n-- \nolivier\n\n\n\n", "id": "lists-017-12675841"}, {"subject": "Re: Markup Validator's test suite  using EARL", "content": "Le Lundi, 29 sept 2003, ? 22:13 America/Montreal, Olivier Thereaux a \n?crit :\n> After a better look at how MUTAT [2] works, I started wondering \n> whether we could actually use EARL for the test descriptions.\n\ndo you mean EARL for the report of passing the Test Suite?\nor to describe the test?\n\nWe will have to consider something where the success of passing the \ntest suite is not the fact of being valid.\n\nTest A -> Has to be always invalid -> Success if invalid\n   -> Failed  if valid\nTest B -> Has to be always valid   -> Success if invalid\n   -> Failed  if invalid\n\nSo I guess something like\n\n===================\n#   Mockup for a test file\n      @prefix : <http://www.w3.org/QA/2003/09/validator/vocab#> .\n      @prefix dc: <http://purl.org/dc/elements/1.1/> .\n\n<> dc:title \"W3C Markup Validator Test Suite\";\n    dc:description \"\"\"\nList of test cases for a Validator Test suite.\nDescribe here the organisation.\n\"\"\" .\n\n<http://validator.w3.org/dev/tests/2003/09/test001.html>\na :testCase;\n:ExpectedResult <http://validator.w3.org/valid>;\ndc:title \"Simple XHTML 1.0 Strict Document\";\ndc:description \"\"\"\nXHTML 1.0 Strict document has given in the\nW3C XHTML 1.0 Specification.\n\"\"\";\n:reference <http://www.w3.org/TR/2000/REC-xhtml1-20000126/#strict> .\n\n<http://validator.w3.org/dev/tests/2003/12/test069.html>\na :testCase;\n:ExpectedResult <http://validator.w3.org/invalid>;\ndc:title \"Invalid HTML Document\";\ndc:description \"\"\"\nHTML Document which must be invalid all the time\nno doctype\n\"\"\";\n:reference \n<http://lists.w3.org/Archives/Public/public-qa-dev/Dec2003/001.html> .\n\n<http://validator.w3.org/dev/tests/2003/12/test070.html>\na :testCase;\n:ExpectedResult <http://validator.w3.org/nocharset>;\ndc:title \"Wrong Charset document\";\ndc:description \"\"\"\nThe document has no charset. The validator must report it.\n\"\"\";\n:reference \n<http://lists.w3.org/Archives/Public/public-qa-dev/Dec2003/004.html> .\n=============================\n\n\nI put together some examples. It doesn't mean it has to be like that.\n\n:validatorResult points to an URI\nvalid\ninvalid\nnocharset\n\nWhich is the expected result of the validator. So if the test says that \nthe result should be \"nocharset\" and the validator validates the file \nwithout complaining about the charset. The test didn't pass.\n\nAre the information about the test itself should be inside the test \nitself? At first we could say yes thinking in terms of HTML, but it \nwill mean we will have to define of describing metadata for each kind \nof markup. It might be easier to put this information in the n3 file.\n\nreference could be one or more reference to understand the context of \nthe test itself. People who have submitted, references in the specs, \ndiscussions about the tests.\n\n\nThere is quite a huge number of tests in the HTML 4.01 Test Suite as \nwell.\n\nhttp://www.w3.org/MarkUp/Test/HTML401/\n\n--\nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n", "id": "lists-017-12684265"}, {"subject": "Re: Are IDNs allowed in http IRIs? (Issue IDNhttp19", "content": "Hello Adam,\n\nI have assigned this issue IDNhttp-19, which I have tentatively closed\nafter the edits I made today (described below).\n\n\nAt 03:42 04/03/19 +0000, Adam M. Costello BOGUS address, see signature wrote:\n\n>Are IDNs allowed in http IRIs?  It seems like a silly question, but\n>currently the IRI draft tries to inherit the answer from the URI & HTTP\n>specs, and the URI draft tries to inherit the answer from the HTTP spec,\n>and of course the HTTP spec knows nothing of IDNs.  The result is that\n>the question has no clear answer.  Does it need a clear answer, and if\n>so, which document is the place to provide that answer?\n>\n>Consider the purported IRI http://jose'.example.net/.  Is that a valid\n>http IRI?  If so, what does it mean?\n>\n>There are four places we might hope to find clues to answer those\n>questions:  The IRI spec, the URI spec, the HTTP spec, and the IDNA\n>spec.\n>\n>Here's what the IRI spec has to say on the matter:\n>\n>     IRIs are only valid if they map to syntactically valid URIs.\n\n[I have looked at that paragraph, and have simplified it to eliminate\nthe word 'valid', because although it is used in RFC2396bis, it is\nnot used with respect to scheme-specific rules.\n\na) Syntactical: Many URI schemes and components define additional\n    syntactical restrictions not captured in Section 2.2.\n    Scheme-specific restrictions are applied to IRIs by converting\n    IRIs to URIs and checking the URIs against the scheme-specific\n    restrictions.]\n\n>     the resource that the IRI locates is the same as the one located by\n>     the URI obtained after converting the IRI\n\nI added the following paragraph to fix the formal problems:\n\nAn IRI with a scheme that is known to use domain names in ireg-name,\nbut where the scheme definition does not allow %-escaping for ireg-name,\nmeets scheme-specific restrictions if either the straightforward\nconversion or the conversion using the ToASCII operation on ireg-name\nresult in an URI that meets the scheme-specific restrictions.\nAn IRI with a scheme that is known to use domain names in ireg-name,\nbut where the scheme definition does not allow %-escaping for ireg-name,\nresolves to the URI obtained after converting the IRI including using\nthe ToASCII operation on ireg-name. Implementations do not need to\ndo this conversion as long as they produce the same result.\n\nPlease note the extended text in the second line:\n\"but where the scheme definition does not allow %-escaping for ireg-name\"\nto be open to future/upgraded schemes that allow %-escaping in\nreg-name/ireg-name.\n\n\n>The only way for the URI http://jos%C3%A9.example.net/ to become valid\n>and meaningful is for the HTTP URI spec to be updated, either by a\n>successor to RFC-2616, or by a sweeping action of the successor to\n>RFC-2396.\n\nWell, RFC2396bis essentially does allow %-escaping, but it's not\nworded in the 'sweeping action' way that you propose.\n\n\n>For example, 2396bis could say that it updates all schemes\n>that use domain names to use IDNs.  Such a sweeping update would of\n>course explicitly bypass the interoperability protections designed into\n>the IDNA architecture, and would let things break during the transition\n>(it amounts to \"just send UTF-8\"), but I suppose it's an option.\n\nI think IDNA was right to be very careful about interoperability\nprotections. But it did go a bit too far in that it tried to\nstrictly enforce exactly the same interoperability protection/\nupgrade path model on all users of domain names. As you admit,\nin different contexts, different ways to go about upgrading\nmay be more appropriate.\n\n\n>The current 2396bis draft does not make such an update.  It says:\n>\n>     When a non-ASCII host name represents an internationalized domain\n>     name intended for resolution via DNS, the name must be transformed\n>     to the IDNA encoding [RFC3490] prior to name lookup.\n>\n>It does not tell us when a non-ASCII host name represents an IDN, so\n>presumably that determination is left up to the scheme.\n\nThe assumption is that if something appears in a place where\nthe scheme uses DNS (that's what the 'intended for resolution via\nDNS\" is for), but it contains non-ASCII characters, then\nit's an IDN. But it might help to make this more explicit.\n\n\n>Existing\n>schemes like http don't use non-ASCII names to represent IDNs (the IDNA\n>spec makes that clear).\n>\n>Getting back to the original questions regarding the purported IRI\n>http://jose'.example.net/, we have not been able to determine whether it\n>is valid or what it means, because the answers change depending on which\n>conversion to to URI we happen to use, and the IRI spec blesses both\n>conversions.\n\nI hope this is clarified now.\n\n\n>Of course the same indeterminacy exists for ftp://jose'.example.net/\n\nThis is also fixed.\n\n\n>and mailto:postmaster@jose'.example.net etc.\n\nwhich, as I said, is an exception.\n\n>Is this indeterminacy intended?\n>\n>If not, I can think of two ways to rectify the situation (and maybe\n>other folks can think of other ways).  One way is for the URI spec to\n>update all URI schemes along these lines:\n\nI think updating the URI spec, or specific scheme specs, is possible,\nbut I prefer to not have to depend on any of this. So the new wording\nin the IRI draft is intended to clarify the situation directly. If\nschemes get updated, then all the better.\n\n\n>     All schemes that use data types that use an ASCII-Compatible\n>     Encoding (ACE) for internationalization are hereby updated to\n>     allow the use of equivalent non-ASCII forms, represented as\n>     percent-encoded UTF-8.  An example of such a data type is domain\n>     names, see [IDNA].\n>\n>(Here I've generalized from IDNs to ACEs because there is a possibility\n>that email address local parts will also use an ACE.)\n>\n>Alternatively, the URI spec could be left as-is, and the IRI spec could\n>redefine the validity of IRIs along these lines:\n>\n>     An IRI is valid if it conforms to the syntax of the corresponding\n>     URI except for the following two additional freedoms:\n>\n>        1) Wherever the URI might contain percent-encoded octets\n>        representing UTF-8, the IRI may instead use non-ASCII characters\n>        whose UTF-8 encoding is those same octets.\n>\n>        2) Wherever the URI might contain a data type that uses an\n>        ASCII-Compatible Encoding (ACE) for internationalization, the IRI\n>        may instead use an equivalent non-ASCII form.  An example of such\n>        a data type is domain names, see [IDNA].\n\nThis is essentially what I have done, but on a smaller scale.\nOpening this up to arbitrary ACEs in arbitrary positions would\nbe rather unworkable. It could go as far as specific query\nparameters of specific URIs/IRIs (see the validator example\nin the IRI draft).\n\n\n>Maybe it would be bothersome to bless a conversion procedure that can\n>produce invalid output.  If not, disregard the rest of this message.\n>Otherwise, the possibility of invalid output could be avoided by\n>creating a new \"scheme name registration tree\" (BCP-35).  For example,\n>the \"i\" tree could be defined as follows:  For any scheme foo, the\n>scheme i-foo is just like foo except for the following additional\n>freedom:\n>\n>     Wherever the foo: URI might contain a data type that uses an\n>     ASCII-Compatible Encoding (ACE) for internationalization, the\n>     i-foo: URI may instead use an equivalent non-ASCII form, represented\n>     as percent-encoded UTF-8.  An example of such a data type is domain\n>     names, see [IDNA].\n\nI don't think creating additional schemes is a viable solution\nfor URI internationalization.\n\nRegards,    Martin.\n\n\n>A scheme-agnostic IRI-to-URI converter can avoid the possibility of\n>invalid output by prefixing i- to the front of the output.  When the URI\n>eventually makes its way to an agent with scheme-specific knowledge,\n>that agent can know whether the prefix can simply be discarded, or if\n>ACE conversions need to be performed first.\n>\n>A URI-to-IRI converter can always discard the i- prefix, even without\n>recognizing the scheme.\n>\n>AMC\n>http://www.nicemice.net/amc/\n\n\n\n", "id": "lists-017-1268914"}, {"subject": "Re: Markup Validator's test suite  using EARL", "content": "On Wednesday, Oct 1, 2003, at 03:28 Asia/Tokyo, karl wrote:\n> do you mean EARL for the report of passing the Test Suite?\n> or to describe the test?\n\nI meant to describe the test.\nUsing as a basis for a Test Description Language, though obviously not \nits primary purpose, has some appeal, because most if not all of the \nneeded concepts are there already.\n\n\n> We will have to consider something where the success of passing the \n> test suite is not the fact of being valid.\n>\n> Test A -> Has to be always invalid -> Success if invalid\n>    -> Failed  if valid\n> Test B -> Has to be always valid   -> Success if invalid\n>    -> Failed  if invalid\n\nThere is actually one more dimension, which is the \"regular\" result \ngiven by the current validator. I suppose we could keep those apart as \na list of assertions with the assertor being \n<http://validator.w3.org/check> a earl:Tool.\n\n\n> So I guess something like\n>\n> ===================\n[snip] the example looks quite good.\n> =============================\n\n\n> :validatorResult points to an URI\n> valid\n> invalid\n> nocharset\n\nnocharset is included in invalid ;)\nI'd rather have the result be either valid or invalid, and add a result \nproperty stating why it wasinvalid (charset, doctype, etc.)\n\n> Are the information about the test itself should be inside the test \n> itself? At first we could say yes thinking in terms of HTML, but it \n> will mean we will have to define of describing metadata for each kind \n> of markup. It might be easier to put this information in the n3 file.\n\nI think so too. Besides for some tests we may want to have no test or \ncomment whatsoever inside, to test a specific case.\n\n> reference could be one or more reference to understand the context of \n> the test itself. People who have submitted, references in the specs, \n> discussions about the tests.\n\nThen I would distinguish reference as in \"Reference specification(s)\" \n(may be multiple in case of mixed namespaces) and reference as in \"see \nalso\".\n\n> There is quite a huge number of tests in the HTML 4.01 Test Suite as \n> well.\n> http://www.w3.org/MarkUp/Test/HTML401/\n\nRight. We're definitely not lacking test documents, but we're seriously \nlacking some organization for them :)\n\nThanks a lot, your examples and suggestions help me a lot.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-12695916"}, {"subject": "[DRAFT] ann message for checklink release 3.9.", "content": "Ville, (and everyone),\n\nCan you give this a look and help me improve this release text by tomorrow? \nIt is loosely based on the text that was sent at the time of the beta\ntest, back at the end of february.\n\n[P.S : accents not working well on this machine, I'll add them for the\nproper announcement]\n\nThank you.\n-- \nolivier\n\n\n\n\ntext/plain attachment: checklink-392-ann.draft\n\n\n\n\n", "id": "lists-017-12733706"}, {"subject": "Re: [DRAFT] ann message for checklink release 3.9.", "content": "On Thu, 2004-04-01 at 10:59, Olivier Thereaux wrote:\n> Ville, (and everyone),\n> \n> Can you give this a look and help me improve this release text by tomorrow? \n> It is loosely based on the text that was sent at the time of the beta\n> test, back at the end of february.\n\nLooks good to me as is, thanks!  I trust you or someone with appropriate\nrights will update the production version to 3.9.2 tomorrow before\nsending the announcement?\n\n3.9.2 has entered CPAN a few minutes ago, for now it's visible at\nhttps://pause.perl.org/pub/PAUSE/authors/id/S/SC/SCOP/.  I believe\nhttp://search.cpan.org/dist/W3C-LinkChecker/ will start working as\nexpected soonish.\n\n\n\n", "id": "lists-017-12741010"}, {"subject": "Re: [DRAFT] ann message for checklink release 3.9.", "content": "On Apr 2, 2004, at 05:44, Ville Skytt? wrote:\n> Looks good to me as is, thanks!  I trust you or someone with \n> appropriate\n> rights will update the production version to 3.9.2 tomorrow before\n> sending the announcement?\n\nYes, in a few hours (or as soon as the CPAN URI works) I will test \ninstalling through CPAN on my machine, then update :80, then send the \nann.\n\n> 3.9.2 has entered CPAN a few minutes ago, for now it's visible at\n> https://pause.perl.org/pub/PAUSE/authors/id/S/SC/SCOP/.  I believe\n> http://search.cpan.org/dist/W3C-LinkChecker/ will start working as\n> expected soonish.\n\nGreat.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12749421"}, {"subject": "[checklink] release  wrapping u", "content": "Hi all.\n\nFirst, warm congratulations to Ville for leading the work through this  \nrelease.\nWe are yet to receive feedback, but this packaging of checklink will be  \na great benefit for many.\n\nI have announced the release to the www-validator as well as the  \neducation list of W3C/QA, and posted announcements on the QA homepage  \nand the Open Source software page. Another announcement has also been  \nposted on the W3C homepage, which is excellent news.\n\nInstallation on v.w.o went well. I downloaded and installed the package  \nas anyone would be, and replaced the old checklink with a link to the  \nnew one.\n\nThe only minor issue was with checklink.html (etc.). There is already a  \nredirect from the old checklink page at  \nhttp://www.w3.org/2000/07/checklink to  \nhttp://validator.w3.org/docs/checklink, and even though I could have  \nredirected them both to  \ndev.w3.org/cvsweb/~checkout~/perl/modules/W3C/LinkChecker/docs/ \nchecklink.html?content-type=text/html;%20charset=utf-8 apparently  \napache does not like these characters in a redirect and I preferred,  \nfor the moment, to update directly the files in /docs/. The issue there  \nwas that there are checklink.html and checklink.css... Bad idea,  \ntriggers content negotiation on non equivalent resources. I renamed the  \nCSS and all went well.\n\nOne thing I wondered when installing was whether checklink's config  \nneeded to be tweaked through a .conf or not. Tell me if that needs to  \nbe done.\n\nNow I think we can wait for feedback, and start thinking/working on  \nripping it apart (ha!).\nI'm personnally very interested by a modular approach, since an API  \nwould make it easy to make a checklink plugin for the Log Validator.\n\nCheers!\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12757629"}, {"subject": "Re: [DRAFT] ann message for checklink release 3.9.", "content": "On Thu, 1 Apr 2004, Olivier Thereaux wrote:\n\n> Ville, (and everyone),\n>\n> Can you give this a look and help me improve this release text by tomorrow?\n> It is loosely based on the text that was sent at the time of the beta\n> test, back at the end of february.\n\n[ aaargh - I can't figure out how to get pine to include the attachment,\n  so I'll just cut&paste.\n]\n\nThe language of the whole thing is a bit flowery - though not as bad\nas many product announcements.\n\n> It is with great pleasure that we are announcing today the first\n\ns/are announcing/announce/\nA more usual wording is \"We are pleased to announce ...\"\n\n> finding broken links and solving authentication issues made easy!\n\n\"solving authentication issues\"?\n\n> Previously bundled as part of the W3C Markup Validator suite, the free\n> online W3C link checker service has been updated with this latest\n> release version:\n>\n>        http://validator.w3.org/checklink\n\n> In addition to that, we now distribute checklink as a free, standalone\n> tool, which should be very easy to install and use as a commandline\n> tool, or a service on your Web site.\n\n\n/me not comfortable with that; tries to reword.\n\nThis is the software driving the W3C link checker service\nhttp://validator.w3.org/checklink\nPreviously bundled with the W3C Markup Validator suite, checklink is\nnow available for download as a free, standalone tool which can be\ninstalled locally either as a commandline utility or a web-based service.\n\n\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-12766255"}, {"subject": "Re: [DRAFT] ann message for checklink release 3.9.", "content": "On Fri, Apr 02, 2004, Nick Kew wrote:\n> The language of the whole thing is a bit flowery - though not as bad\n> as many product announcements.\n\nYeah, sorry, I should have prepared it earlier. \nYour message came after I sent the actual announcement, and that is too\nbad, I liked your corrections. Thanks for sending them.\n\nWill do better next time...\n \n-- \nolivier\n\n\n\n", "id": "lists-017-12775683"}, {"subject": "Re: [checklink] release  wrapping u", "content": "On Fri, 2004-04-02 at 09:14, olivier Thereaux wrote:\n\n> I have announced the release to the www-validator as well as the  \n> education list of W3C/QA, and posted announcements on the QA homepage  \n> and the Open Source software page. Another announcement has also been  \n> posted on the W3C homepage, which is excellent news.\n\nYep, nice!\n\n> The only minor issue was with checklink.html (etc.). There is already a  \n> redirect from the old checklink page at  \n> http://www.w3.org/2000/07/checklink to  \n> http://validator.w3.org/docs/checklink, and even though I could have  \n> redirected them both to  \n> dev.w3.org/cvsweb/~checkout~/perl/modules/W3C/LinkChecker/docs/ \n> checklink.html?content-type=text/html;%20charset=utf-8 apparently  \n> apache does not like these characters in a redirect and I preferred,  \n> for the moment, to update directly the files in /docs/. The issue there  \n> was that there are checklink.html and checklink.css... Bad idea,  \n> triggers content negotiation on non equivalent resources. I renamed the  \n> CSS and all went well.\n\nI was thinking about this a bit as well.  There might be a better\nlocation than the cvsweb one to redirect to, for example\nhttp://search.cpan.org/dist/W3C-LinkChecker/docs/checklink.html\n\nAnyway, I will change the documentation link to point to\nhttp://www.w3.org/2000/07/checklink again now that it points to an up to\ndate version of the doc.\n\nRegarding renaming the CSS, do you think it should be done in the\ndistribution too, and what should it be renamed to?  Something that does\nnot conflict with the validator's files, obviously.\n\n> One thing I wondered when installing was whether checklink's config  \n> needed to be tweaked through a .conf or not. Tell me if that needs to  \n> be done.\n\nFor the general purpose public version, no .conf is needed.  On the\nother hand, if there are some W3C users who wish to have the basic\nauthentication forwarded to all of w3.org instead of the host of the\nfirst document to be checked only, that would need a version which sets\nthe \"Trusted\" regexp in checklink.conf, and probably a W3C-only instance\nof the checker.  I will clarify the docs on this, BTW.\n\n> Now I think we can wait for feedback, and start thinking/working on  \n> ripping it apart (ha!).\n> I'm personnally very interested by a modular approach, since an API  \n> would make it easy to make a checklink plugin for the Log Validator.\n\nMy current plan is to make one more release without any drastic\nstructural changes, incorporating various smaller bits I have on my TODO\nlist.  And then, start modularizing and adding \"new cool stuff\".\n\nI have not thought about the public API yet at all, but done some work\non internal handlers and plug-ins.  Do you have ideas what kind of link\nchecker API you would like for the log validator?  SAX-like event-based,\nsomething else?\n\n\n\n", "id": "lists-017-12783124"}, {"subject": "[meeting] schedule and tentative agenda - 2004-040", "content": "Hello,\n\nReminder: We're having our regular IRC meeting tomorrow.\n\nVenue: #validator on freenode\nTime: 17:00 CET (18:00 EET)\nhttp://timeanddate.com/worldclock/fixedtime.html? \nyear=2004&month=4&day=6&hour=15&min=0&sec=0\n\nAgenda:\nI haven't seen news from Dodji yet, so I assume he did not have time to  \nimplement what we discussed last meeting. I'm therefore tempted by the  \nfollowing agenda:\n\n* Checklink:\n  - lessons learned from release\n  - making checklink (tool) and checklink (service on w3.org) behave  \nnicely\n  - what next\n\n* Markup Validator:\n  - Scheduling beta + release - now?\n  - the cataloguing issue\n  - what's next\n\nOK for 1h30, everyone? or do you think we'll need 2h? Also, please  \nsuggest agenda items if you think I missed anything.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12792871"}, {"subject": "Re: [meeting] schedule and tentative agenda - 2004-040", "content": "Hey,\n\nSorry for my silence.\n\nI went forward in the plan we defined.\nNow, libcroco provides parsing location (line/col/byte offset) for all\nthe CSS language constructions available at the SAC level.\nI haven't started to work on the structured error reporting \narchitecture yet.\n\nYou still can start testing the library.\n\nI use GNU ARCH as source control management in development mode.\nThe GNOME CVS is just a stable repository where a merge code from the \nGNU arch\nrepository from time to time.\n\nTo know how to access the public GNU ARCH source archive of libcroco \nyou can\nread \nhttp://mail.gnome.org/archives/libcroco-list/2004-March/msg00011.html .\n\nCheers,\n\nDodji.\n\n\nSelon olivier Thereaux <ot@w3.org>:\n\n> Hello,\n>\n> Reminder: We're having our regular IRC meeting tomorrow.\n>\n> Venue: #validator on freenode\n> Time: 17:00 CET (18:00 EET)\n> http://timeanddate.com/worldclock/fixedtime.html?\n> year=2004&month=4&day=6&hour=15&min=0&sec=0\n>\n> Agenda:\n> I haven't seen news from Dodji yet, so I assume he did not have time to\n> implement what we discussed last meeting. I'm therefore tempted by the\n> following agenda:\n>\n> * Checklink:\n>   - lessons learned from release\n>   - making checklink (tool) and checklink (service on w3.org) behave\n> nicely\n>   - what next\n>\n> * Markup Validator:\n>   - Scheduling beta + release - now?\n>   - the cataloguing issue\n>   - what's next\n>\n> OK for 1h30, everyone? or do you think we'll need 2h? Also, please\n> suggest agenda items if you think I missed anything.\n>\n> -- \n> olivier\n>\n\n\n\n\n\n\n", "id": "lists-017-12801096"}, {"subject": "installed cvssyncmai", "content": "Upon recommendation from Bjoern, I installed cvs-syncmail instead of \nthe crude mechanism that was sending info to www-validator-cvs. I also \nconfigured it for the CSS Validator, Link Checker (new repository) and \nLog Validator.\n\nI am not a regular user of syncmail, so if you have any preference for \nits options, tell me.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12810982"}, {"subject": "new host server for w.v.", "content": "Folks,\n\nThe W3C systems Team has prepared a new box for validator.w3.org. A \nnice hefty dual processor. The system is installed and some files were \ncopied from the existing host (not all, yet, e.g not /home).\n\nI installed checklink, but check seems to dislike this new host. \nonsgmls is the well-known \"1.5pre8\" yet check behaves as if it were an \noutdated version (\"invalid, no error\"). could be related to perl on \nthis new box (v5.8.3, versus 5.6.1 on the old one). That said it's the \nsame perl as qa-dev and I haven't seen any issue there. so...\n\nI may give it another try later, in the meantime, ideas welcome.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12817494"}, {"subject": "Re: [meeting] schedule clarification - 2004-040", "content": "On Apr 5, 2004, at 18:06, olivier Thereaux wrote:\n> Venue: #validator on freenode\n> Time: 17:00 CET (18:00 EET)\n> http://timeanddate.com/worldclock/fixedtime.html? \n> year=2004&month=4&day=6&hour=15&min=0&sec=0\n\nas Ville wrote to me, this is not clear, if not completely wrong. I am  \nadmittedly lost in timezones and summer time shift...\n\nSo to be clear, this will be\n16:00 UK,\n17:00 France / Norway,\n18:00 Finland,\n24:00 Japan.\n\nI should indeed give a reference time in UTC next time.\n\nHope to talk to all of you then.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12824835"}, {"subject": "Re: [meeting] agenda+ libcroco - 2004-040", "content": "Salut Dodji,\n\nOn Apr 5, 2004, at 18:19, dodji@seketeli.org wrote:\n> Sorry for my silence.\n\nNo problem, I hope my remark did not seem harsh, it would be perfectly \nfine if you didn't have time to work on it, and it's even better if you \ndid! :)\n\n> I went forward in the plan we defined.\n> Now, libcroco provides parsing location (line/col/byte offset) for all\n> the CSS language constructions available at the SAC level.\n> I haven't started to work on the structured error reporting \n> architecture yet.\n>\n> You still can start testing the library.\n\nThanks. I guess we'll spend a little time during the meeting discussing \nhow we should go forward w.r.t this. I don't think we should spend too \nlong on the topic, though.\n\nYou're obviously most welcome to join the meeting.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12832500"}, {"subject": "Re: [meeting] agenda+ libcroco - 2004-040", "content": "> You're obviously most welcome to join the meeting.\n\nThanks ! I will then ;)\n\nSee you.\n\nDodji.\n\n\n\n", "id": "lists-017-12840856"}, {"subject": "Re: new host server for w.v.", "content": "On Apr 6, 2004, at 11:39, olivier Thereaux wrote:\n> I installed checklink, but check seems to dislike this new host. \n> onsgmls is the well-known \"1.5pre8\" yet check behaves as if it were an \n> outdated version (\"invalid, no error\"). could be related to perl on \n> this new box (v5.8.3, versus 5.6.1 on the old one).\n\n  Bjoern yesterday helped me find the reason for that...\n\nIt seems that perl -T does not like our usage of IPC::Open3 in the :80 \ninstance.\n\nApparently -T has become even more paranoid with version 5.8 and we're \nnot the only ones to have had such an issue.\n\n=> We'll probably have to wait until the upcoming release (which seems \nto work fine even with -T) before we \"migrate\" w.v.o to this new box.\n\nThoughts, or further analysis, welcome, off-list if necessary.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12848323"}, {"subject": "Re: Are IDNs allowed in http IRIs", "content": "At 03:03 04/03/29 +0000, Adam M. Costello BOGUS address, see signature wrote:\n\n>I think it may help conceptually to distinguish between generic URIs and\n>URIs of a particular scheme.  For example, foo:bar is a valid generic\n>URI, but it might not be a valid foo: URI.\n>\n>Given a foo: IRI, there are two kinds of IRI -> URI conversion we might\n>be interested in.  We might merely want to convert to a valid generic\n>URI in order to tunnel it through some ASCII infrastructure before being\n>ultimately resolved by an IRI resolver, in which case we don't actually\n>need a valid foo: URI.  Or we might want to convert to a valid foo: URI\n>so that a foo: URI resolver can resolve it.\n>\n>The former of those two tasks can obviously be done without\n>scheme-specific knowledge.  But if you want the URI to be\n>resolvable, you can't get the job done without scheme-specific\n>knowledge.  Many (most?) browsers today will not resolve\n>http://%E7%8C%AB%E3%81%AB%E5%B0%8F%E5%88%A4.nicemice.net/ because\n>they don't handle percent-encoding in the host component, because\n>it's not valid according to the current http: URI spec.\n\nOpera 7.2 resolves this. My personal version of Amaya\n(compiling with the 'IDN' branch of libwww) resolves this.\n\nMy expectation is that browsers that do both IRIs (in general)\nand IDNs will resolve the above also, just as a side effect of\nhow the various steps of resolution work, or can easily be\nmade to resolve this by really small changes.\n\n\n>(Even\n>Firefox, which fetches the page when I type the Japanese domain\n>label directly in Japanese, cannot resolve the percent-encoded\n>UTF-8 form.)  Many (most?) browsers today will not resolve\n>mailto:webmaster@%E7%8C%AB%E3%81%AB%E5%B0%8F%E5%88%A4.nicemice.net even\n>though they percent-decode the domain, because they (or the MUA they\n>invoke) are not expecting UTF-8 in the mail address, because it's not\n>valid according to the current mail address spec.\n\nmailto: is a different problem, because it does not use what's\ncalled the 'generic' syntax in RFC 2396.\n\n\n>If you want URIs that\n>are meaningful according to current specs and can be resolved by current\n>URI resolvers, you need http://xn--r9j282hvzgc6x.nicemice.net/ and\n>mailto:webmaster@xn--r9j282hvzgc6x.nicemice.net.\n>\n> > Do we need a separate spec for \"http:\", \"mailto:\", \"ftp:\" IRIs, where\n> > each specifies the punycode vs. hex-encoding of the various parts?\n>\n>I don't think so; I think it is sufficient to have separate specs for\n>http, mailto, and ftp URIs, which we already have.  The conversion of\n>IRIs to URIs can then be defined by general rules in the IRI spec.  For\n>example, see the latter part of\n>\n>http://lists.w3.org/Archives/Public/uri/2004Mar/0049.html\n>\n>after \"redefine the validity of IRIs\".\n>\n>Martin Duerst <duerst@w3.org> wrote:\n>\n> > At most, there should be a single bit per scheme that says whether\n> > punycode should be applied to the 'host' part.\n>\n>This middle-ground approach is both too much (every IRI-to-URI convertor\n>needs to recognize all schemes)\n\nWell, all schemes deployed currently that use DNS names in the\n'host' slot of the generic syntax. New schemes can easily\nbe defined to allow the %-escaping syntax.\n\n\n>and too little (mailto: is not handled).\n\nAs I said above, it's a separate issue. In my opinion, once we have\nsome good idea of where i18n of mail addresses is going, we will have\nto update the mailto: RFC.\n\n\n>What do you think of recognizing two kinds of IRI-to-URI conversion, a\n>scheme-agnostic kind for tunneling through URI infrastructure to IRI\n>resolvers, and a fully scheme-aware kind for interoperating with URI\n>resolvers (and for defining the meaning of the IRI)?\n\nI think we are actually very close to this. But I don't want to\nmake this more explicit than necessary.\n\n\n>In other words, there are three data types:  IRIs are non-ASCII and\n>can be resolved by IRI resolvers.  URIs are ASCII and can be resolved\n>by legacy URI resolvers.  HRIs (hybrid resource identifiers) are both\n>IRIs and generic URIs; they can be resolved by IRI resolvers but not\n>by legacy URI resolvers; they can traverse infrastructure that accepts\n>generic URIs without needing to resolve them; and they survive relative\n>URI processing.  Conversion between IRIs and HRIs (in either direction)\n>needs no scheme-specific knowledge, but conversion to URIs does.\n\nI don't think we need to be that explicit. To the extent that there is\na need for 'tunneling' (I haven't seen any explicit examples for this\nyet), that will just work out anyway.\n\n\n\n>This model recognizes the inescapable fact that in order for something\n>like mailto:postmaster@jose'.example.net to be useful, two pieces of\n>knowledge need to come together:  IDNA (which is internationalization\n>knowledge), and the fact that the thing after the at-sign is a domain\n>name (which is mailto knowledge).  The three-type model makes it clear\n>that you can either smarten up the IRI layer with scheme knowledge or\n>smarten up the URI resolution layer with IRI knowledge, but one or\n>the other is required, and therefore the meaning of something like\n>mailto:postmaster@jose'.example.net can be well-defined.  I think the\n>two-type model lets this requirement slip through the cracks; both\n>layers try to limit their knowledge at the same time, but that just\n>doesn't work.\n\nIn actual implementations, what you may have to do is just to\nexchange (or beef up) your dns resolving code with something\nthat understands the %-escaped stuff as UTF-8 and knows how to\nconvert this to punycode.\n\n\n> > But to a large extent, this is actually an implementation issue.\n>\n>Before I can begin to plan or assess an implementation, I need to know\n>what it intends to implement.  What is http://jose'.example.net/ supposed\n>to mean?  The IRI spec says it is supposed to mean the same thing as\n>ToURI(http://jose'.example.net/), but that is not deterministic; it is\n>both http://jos%C3%A9.example.net/ and http://xn--jos-dma.example.net/,\n>and while the latter has a meaning, the former doesn't (at least, not\n>with rfc2396bis as it stands, see my previous message).\n>\n>In order for the IRI http://jose'.example.net/ to have a well-defined\n>meaning, so that we know what our implementation is aiming for, we need\n>to tweak either the HTTP spec, the URI spec, the IDNA spec, or the IRI\n>spec.  Since the URI and IRI specs are the ones in flux at the moment,\n>they seem like the prime candidates.\n\nThe IRI spec has been tweaked. I hope this is okay.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1285485"}, {"subject": "Re: new host server for w.v.", "content": "Selon olivier Thereaux <ot@w3.org>:\n\n>   Bjoern yesterday helped me find the reason for that...\n> \n> It seems that perl -T does not like our usage of IPC::Open3 in the :80 \n> instance.\n> \n> Apparently -T has become even more paranoid with version 5.8 and we're \n> not the only ones to have had such an issue.\n\nI have also been bitten by this on Debian a few months ago -- when Perl was \nupdated to 5.8, the packaged version of the validator stopped working. I\nlooked into the problem and came to the same conclusion -- and noticed \nafterwards that Terje already knew about this and, if I am not mistaken, had \nalready commited a (short) fix to the CVS, which I backported to the Debian \npackage. The backport is easy, in case you are thinking of applying it on\nthe current released version so that it runs on the new machine.\n\nWhile I'm here, I just wanted to say that I plan to make a separate Debian\npackage for the linkchecker, based on the standalone version, but I have had\nsome problems with my computers lately (read: they got stolen) and haven't\nbeen able to do anything. Hopefully, this will be done quite soon so that\nthe new separate package will be included in the upcoming Sarge release.\n\nFrederic\n\n\n\n", "id": "lists-017-12856335"}, {"subject": "Re: new host server for w.v.", "content": "* olivier Thereaux wrote:\n>On Apr 6, 2004, at 11:39, olivier Thereaux wrote:\n>> I installed checklink, but check seems to dislike this new host. \n>> onsgmls is the well-known \"1.5pre8\" yet check behaves as if it were an \n>> outdated version (\"invalid, no error\"). could be related to perl on \n>> this new box (v5.8.3, versus 5.6.1 on the old one).\n>\n>  Bjoern yesterday helped me find the reason for that...\n>\n>It seems that perl -T does not like our usage of IPC::Open3 in the :80 \n>instance.\n>\n>Apparently -T has become even more paranoid with version 5.8 and we're \n>not the only ones to have had such an issue.\n\nIt seems that $CFG->{'SGML Parser'} and $catalog are considered tainted;\nI untainted them with the result that Perl is unable to find cmd.exe\nwhich is the result of\n\n  # Get rid of (possibly insecure) $PATH.\n  delete $ENV{PATH};\n\n(I believe that Perl is broken in this regard, it seems to attempt to\nopen \"cmd.exe\" directly rather than relying on %ComSpec% which is an\nabsolute reference...) commenting the delete out yields in\nfatalsToBrowser with\n\n  open3: IO::Pipe: Can't spawn-NOWAIT: Bad file descriptor at check ...\n\n(I) Just run it without -T...\n\n\n\n", "id": "lists-017-12864811"}, {"subject": "Re: new host server for w.v.", "content": "* Frederic Schutz wrote:\n>I have also been bitten by this on Debian a few months ago -- when Perl was \n>updated to 5.8, the packaged version of the validator stopped working. I\n>looked into the problem and came to the same conclusion -- and noticed \n>afterwards that Terje already knew about this and, if I am not mistaken, had \n>already commited a (short) fix to the CVS, which I backported to the Debian \n>package.\n\nThis does not seem to be the case at least for check v1.305.2.84 on\nWin32 / ActiveState Perl v5.8.2. Hmm, check v1.305.2.12 (that should\nbe :80...) appears to have no problem with -T except that I would get\n\n  open3: IO::Pipe: Can't spawn-NOWAIT: Bad file descriptor at check ...\n\nthere too. Hmm, in v1.305.2.84 we have\n\n  # Launder data for Perl 5.8+ taint mode, trusting the config...\n  $v =~ /^(.*)$/;\n  $cfg{$k} = $1;\n\nHmm, of course, now I am unable to reproduce prior Insecure dependency\nfatal errors with v1.305.2.84... though I still get \n\n  open3: IO::Pipe: Can't spawn-NOWAIT: Bad file descriptor at check ...\n\nInteresting. So it appears that copy & paste read_cfg() from v1.305.2.85\n(latest) to v1.305.2.12 (:80) would fix the problem on non-Win32...\n\n\n\n", "id": "lists-017-12873399"}, {"subject": "Re: new host server for w.v.", "content": "On Wed, 2004-04-07 at 05:15, Bjoern Hoehrmann wrote:\n\n>   # Get rid of (possibly insecure) $PATH.\n>   delete $ENV{PATH};\n> \n> (I believe that Perl is broken in this regard, it seems to attempt to\n> open \"cmd.exe\" directly rather than relying on %ComSpec% which is an\n> absolute reference...)\n\nHm, possibly a stupid question, but do you know why is any \"cmd.exe\"\nneeded in the first place?  I thought that when doing a system(),\nexec(), open3() and friends with the arguments properly split and passed\nin as a list would avoid the need for a shell/command interpreter.  Or\nis this different in Windows?\n\nIf the \":80 version\" already has the IPC::Run stuff in place, could you\ntry with that instead of IPC::Open3, and see if it works better?  It'll\nneed commenting out a mod_perl check near the first occurrence of\n$HAVE_IPC_RUN, and of course installing it :)\n\n\n\n", "id": "lists-017-12881733"}, {"subject": "Link checker robot code  probably tonigh", "content": "I did not manage to commit the robots.txt stuff for checklink yesterday\nbecause I ran into a couple of bugs in WWW::RobotRules and got\ndistracted fixing them.  I have an idea for a workaround, and will\nhopefully get that and the rest of what I've done into a CVS near you\nlater tonight.\n\n\n\n", "id": "lists-017-12889704"}, {"subject": "Re: Link checker robot code  probably tonigh", "content": "On Wed, 2004-04-07 at 17:29, Ville Skytt? wrote:\n> I did not manage to commit the robots.txt stuff for checklink yesterday\n> because I ran into a couple of bugs in WWW::RobotRules and got\n> distracted fixing them.  I have an idea for a workaround, and will\n> hopefully get that and the rest of what I've done into a CVS near you\n> later tonight.\n\nHo-hum, and now that I run \"cvs up\" on my LWP tree, I noticed that Liam\nhas been busy fixing apparently the exact same issues.  The fixes are\nincluded in 5.77 (and 5.78 is already out).  Duh!\n\n\n\n", "id": "lists-017-12896767"}, {"subject": "Re: new host server for w.v.", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>Hm, possibly a stupid question, but do you know why is any \"cmd.exe\"\n>needed in the first place?  I thought that when doing a system(),\n>exec(), open3() and friends with the arguments properly split and passed\n>in as a list would avoid the need for a shell/command interpreter.  Or\n>is this different in Windows?\n\nI expect this is due to Perl emulating fork() on `doze.\n\n\n- -- \nIf you believe that will stop spammers, you're sadly misled. Rusty hooks,\nrectally administered fuel oil enemas, and the gutting of their machines,\n*that* stops spammers!                                         -- Saundo\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQHQYBKPyPrIkdfXsEQJOxwCeIhUQWnXLKoRHxsWfZOaPIB5vOXAAn3in\nCgOLovXNAgxT+YT+O+BzvrP7\n=7aUc\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12904036"}, {"subject": "Re: new host server for w.v.", "content": "* Ville Skytt? wrote:\n>Hm, possibly a stupid question, but do you know why is any \"cmd.exe\"\n>needed in the first place?  I thought that when doing a system(),\n>exec(), open3() and friends with the arguments properly split and passed\n>in as a list would avoid the need for a shell/command interpreter.  Or\n>is this different in Windows?\n\nOne reason for that is that Perl uses CreateProcess(...) to spawn new\nprocesses which has a behavior different from the CRT _spawn*(...)\nroutines (and the cmd.exe shell), for example, CreateProcess(...)\nassumes a .exe file name extension if the application name lacks an\nextension, while _spawn*(...) would first search for .com, ... AFAIR\nCreateProcess(...) also expects only executable files, hence you could\nnot use it to execute a .cmd file without explicitly using cmd.exe with\nproper arguments. perl/win32/win32.c:win32_spawnvp(...) probably\ncontains comments to this effect, long since I last looked at it.\n\n>If the \":80 version\" already has the IPC::Run stuff in place, could you\n>try with that instead of IPC::Open3, and see if it works better?  It'll\n>need commenting out a mod_perl check near the first occurrence of\n>$HAVE_IPC_RUN, and of course installing it :)\n\nNo, v1.305.2.12 lacks such code, but for v1.305.2.84 IPC::Run seems to\ndo better than IPC::Open3 on the command line, but when invoked via CGI\nit hangs (ongmls.exe remains in the process list). It is impossible to\nkill the onsgmls.exe instances through the task manager, I had to `kill\n-f` them...\n\n\n\n", "id": "lists-017-12912217"}, {"subject": "Re: new host server for w.v.", "content": "On Wed, 2004-04-07 at 20:44, Bjoern Hoehrmann wrote:\n\n> No, v1.305.2.12 lacks such code, but for v1.305.2.84 IPC::Run seems to\n> do better than IPC::Open3 on the command line, but when invoked via CGI\n> it hangs (ongmls.exe remains in the process list). It is impossible to\n> kill the onsgmls.exe instances through the task manager, I had to `kill\n> -f` them...\n\nHm.  What if you remove the timeout(60) from the run() call, does that\nchange anything?\n\n\n\n", "id": "lists-017-12921110"}, {"subject": "Re: Validator(s)' Test suite  requirements (thoughts", "content": "* olivier Thereaux wrote:\n>Here are my thoughts on the topic of a test suite for our various \n>validators (including checklink by stretching the definition a bit).\n\nM12N of the code solves a number of problems in this regard, I would\nexpect that the resulting modules will have their own test suite in\nthe standard Perl make test framework...\n\n\n\n", "id": "lists-017-12928519"}, {"subject": "Re: new host server for w.v.", "content": "* Ville Skytt? wrote:\n>> No, v1.305.2.12 lacks such code, but for v1.305.2.84 IPC::Run seems to\n>> do better than IPC::Open3 on the command line, but when invoked via CGI\n>> it hangs (ongmls.exe remains in the process list). It is impossible to\n>> kill the onsgmls.exe instances through the task manager, I had to `kill\n>> -f` them...\n>\n>Hm.  What if you remove the timeout(60) from the run() call, does that\n>change anything?\n\nNo.\n\n\n\n", "id": "lists-017-12935671"}, {"subject": "[meeting] Notes and log - 2004-040", "content": "Here is a summary of our IRC meeting on April 6th, 2004.\n\nThe meeting started with a discussion about libcroco, with Bjoern and \nNick asking for a snapshot release of Dodji's modifications, so that \nthey can test it easily.\n\nAgenda 1 : Link checker\n\nThe release went well, and the main feedback is the (old) issue of the \nlink checker not following the robots exclusion protocol. While Bjoern \nand Olivier don't think it should be absolutely necessary, there is a \nneed for the instance on validator.w3.org to behave nicely, and Ville \nwill work on implementing the protocol by using LWP::RobotUA.\n\nThe main problem with RobotUA is that its constructor needs an e-mail \naddress for contact. But the link checker can be used without any \nconfiguration at all, and this means that it would need to guess a good \ncontact e-mail or put a default one.\n\nAmong all the possible solutions (default would be serveradmin, or an \naddress at w3c, or a bogus address, or override the constructor to not \nneed an address), none seemed to get everyone's vote, and the issue \nwill have to be solved on the list. In the meantime Ville will override \nthe constructor (if no e-mail given in config?)\n\n\nAgenda 2 : Markup Validator\n\nWe discussed the timeline for the 0.6.5 release and beyond... We are \ngoing to work on a low-profile beta for 0.6.5b2, and a rapid release.\n\nThe fact that HEAD has gone far into development while features were \nadded and bugs were fixed in 0.6 branch may not have been the best \nstrategy, not to mention the issue with people downloading HEAD by \ndefault.\n=> after the release, HEAD and 0.6 branch will be merged (bringing \ntemplates in) and advanced development will not be done in HEAD but in \na new branch...\n\nWe will need to be careful (disciplined) to make our development easier \nto manage, smaller releases, more frequent and less feature-rich.\n\n[[ ACTION - Terje to Document current and planned CVS Branch layout ]]\n\n\nNick suggested trying/looking at mod_validator for the multi-parser \narchitecture, and will install a test instance on the qa-dev server for \nall to play with.\n\nThe issues about cataloguing were quickly discussed, and we agreed that \nthey could not be fixed just now.\n\nMore in the IRC log, trimmed and (lightly) edited.\n\n-- \nolivier\n\n\n\n\n\n\n\n\ntext/plain attachment: qa-dev-log-20040406.txt\n\n\n\n\n", "id": "lists-017-12943068"}, {"subject": "checklink: need dummy config file on v.w.", "content": "Due to a thinko in link checker version 3.9.2, the default configuration\noptions are not set if there's no configuration file.  This has been\nfixed in CVS, and the workaround for the current version should be a\nmatter of this on v.w.o (as root, and the file must have size > 0):\n\n  # echo '#' > /etc/w3c/checklink.conf\n\nCould someone take care of this?  TIA!\n\n\n\n", "id": "lists-017-12952695"}, {"subject": "Re: checklink: need dummy config file on v.w.", "content": "On Apr 9, 2004, at 02:25, Ville Skytt? wrote:\n>   # echo '#' > /etc/w3c/checklink.conf\n>\n> Could someone take care of this?  TIA!\n\nSure, done.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12959866"}, {"subject": "Link Checker: CVS HEAD &#64; qade", "content": "http://qa-dev.w3.org/wlc/checklink\n>From CVS HEAD, updated daily from my crontab.\n\n\n\n", "id": "lists-017-12967096"}, {"subject": "Re: [meeting] Notes and log - 2004-040", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@w3.org> wrote:\n\n>[[ ACTION - Terje to Document current and planned CVS Branch layout ]]\n\nOk, here goes... :-)\n\nThere are currently two main branches in CVS; HEAD and validator-0_6_0-branch.\n\n??validator-0_6_0-branch?? is misnamed; it's really ?????-0_6-branch??. On this\nbranch is 0.6.0, 0.6.1, 0.6.2, and 0.6.5 (including betas); and each of them\nhas a tag corresponding with the version or release number.\n\nHEAD has no (relevant) tags.\n\nThe status of ??validator-0_6_0-branch?? is as we've discussed; it needs some\nwork to be releaseable, but is otherwise in fairly good shape.\n\nHEAD is in a semi-working state, including major new feature work (Templates\nchief among them), but rather far diverged from ???-0_6_0-branch and merging\nthem is going to be a bit of a pain.\n\n\nThe immediate plan once 0.6.5 is out, is to merge 0.6.5 back onto HEAD and\nthen feature-freeze the ???-0_6_0-branch. That is, _only_ absolutely critical\nbugfixes ??? of the type that are then imediately `cvs up`ed on v.w3.org ???\nshould go in after the merge.\n\nOnce 0.6.5 and HEAD have been merged, I'm thinking we immediately branch\n??validator-0_7-branch??. This branch starts out beeing feature-frozen (unlike\n0.6.0 did), with only stabilization work getting done. New features that are\nwell contained and stable get added on HEAD, and the 0.7.0 branch gets merged\nback onto the trunk regularly.\n\nThe intent is that once 0.7.0 gets released we can, if we have enough new\nfeatures yet, immediately branch HEAD into a (feature-frozen) 0.8 branch and\nrepeat the process.\n\nThat way, HEAD is always in a more or less runnable state (roughly alpha\nquality) and it never gets too far diverged from the current release train\nbranch.\n\n\nAny major and destabilizing work gets done on its own branch; the existing\nTemplate work and the future modularization work beeing prime candidates.\n\nFor these branches, whoever makes the branch is responsible for keeping it in\nsync with HEAD. Merges happen from HEAD to branch ??? instead of the other way\naround ??? until the new feature work is ready to be merged back onto HEAD and\nintegrated into the next version released.\n\n\nA quick illustration is at <http://qa-dev.w3.org/wmvs/wmv-cvs-branches.png>;\nno specific relation to current devel plans, just meant to illustrate the\nsetup I'm talking about. :-)\n\n\nComments?\n\n\n- -- \n> ...publicity rights, moral rights, and rights against unfair competition...\nWell, you've got me there.   I have no idea what any of those have to do with\nSGML. Next you'll be claiming that running NSGMLS constitutes an unauthorized\npublic performance of SGML.                                  -- Richard Tobin\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQHhmUqPyPrIkdfXsEQKCbgCfYiwEHvYNxgDcHNbfpAhsf7fDcIAAoMCg\nGHPeqGVbfIjW22ezx1GgbJyE\n=tGkk\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-12973446"}, {"subject": "[check] preparing 0.6.5b", "content": "Hi,\n\nI have gone through CVS logs since 0.6.5 beta 1 and usedd that to \ncreate an entry for whatsnew.html in preparation for a beta2 this \nfriday... If all goes well and if you agree that we can go ahead.\n\nI have tagged everything as 0_6_5-beta2.\n\nMy question(s) (especially for Ville and Terje, who made most of the \nmodifications since beta1)... Do you think we can go forward? Did I \nforget anything in the \"small\" changelog (in whatsnew)? Any last minute \nmodification you want to do before we move on with this beta?\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-12983881"}, {"subject": "Re: [check] preparing 0.6.5b", "content": "On Wed, 2004-04-14 at 04:54, olivier Thereaux wrote:\n\n> My question(s) (especially for Ville and Terje, who made most of the \n> modifications since beta1)... Do you think we can go forward?\n\nAs far as I know, yep.\n\n>  Did I forget anything in the \"small\" changelog (in whatsnew)?\n\nNot that I remember.\n\n>  Any last minute \n> modification you want to do before we move on with this beta?\n\nNot really a validator thing, but perhaps reconsider that libwww-perl\nupgrade at the same time?  AFAICT anything >= 5.78 should be good (5.79\nis already out).  Not at all mandatory for the validator, but the next\nlink checker would benefit quite a bit from it.\n\n\n\n", "id": "lists-017-12991069"}, {"subject": "[checklink] Preparing for 3.9.", "content": "I believe it's soon time to release Link Checker 3.9.3.  The only\nshowstopper (unless I've missed something) is the presentation of the\n\"forbidden by robots.txt\" cases, which are now treated as 403's, with\nscreaming red background.\n\nSo apart from that, for all your urgent link checking needs, this one\ncould use some testing: http://qa-dev.w3.org/wlc/checklink :)\n\n\n\n", "id": "lists-017-12998114"}, {"subject": "Re: [checklink] Preparing for 3.9.", "content": "Ville,\n\nOn Apr 15, 2004, at 02:11, Ville Skytt? wrote:\n> I believe it's soon time to release Link Checker 3.9.3.\n\nGreat!\n\nAre you planning a short beta test soon? I haven't had time to test it \nyet, but I went through the diff and things look good. I will try to \nplay with it within a few days, tell me how you'd like to schedule the \nnext steps.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13005131"}, {"subject": "convert to punycode: SHOULD or MAY (was: RE: Are IDNs allowed   in http IRIs?", "content": "Hello Michel,\n\nRegarding the SHOULD vs. MAY for the use of punycode in the conversion\nfrom IRIs to URIs, I have created an issue (punycodeSHOULD-23), and\nbased on the discussion, in particular also Larry's comment, I have\nchosen to make a compromize. The text now says 'MAY' in the general\ncase, but then says \"This conversion SHOULD be used when the goal is to\nmaximize interoperability with legacy URI resolvers.\"\n(where the second part of this sentence is from Roy's draft).\n\nPlease tell me if that's acceptable for you.\n\nRegards,    Martin.\n\nAt 00:23 04/03/19 -0800, Michel Suignard wrote:\n\n>Adam, I think you have a valid point, I would however make a simpler \n>suggestion, which is two fold:\n>\n>- introduce the concept of IRI used as presentation element of URI \n>protocol element. In that sense http://jos x example.net/ is a presentation \n>element for the following protocol element http://xn--jos-dma.example.net/ \n>and as you noted http://jos%C3%A9.example.net/ is not a correct URI (per \n>RFC 2616 referring to host itself defined in RFC 2396). I have suggested \n>text in that sense to the IRI main editor (Martin). Having the concept of \n>presentation element validates http IRIs which exist de facto, whatever we \n>like it or not.\n>\n>- add text in the IRI spec saying the following:\n><<\n>When an IRI is converted to a URI, the conversion SHOULD use \n>scheme-specific knowledge to convert appropriate components where the \n>scheme syntax prevents the usage of percent-encoded text into such \n>components. Lack of scheme-specific knowledge (or failure to use it) can \n>cause valid IRIs to be converted to invalid URIs that contain \n>percent-encoded non-ASCII text where they are not permitted.\n> >>\n>It is my opinion that anybody in its right mind would implement IRI to URI \n>mapping considering all the schemes where 'host' is used and map \n>accordingly (ie use Punycode). My text avoids direct reference to ACE \n>which is in my opinion unnecessary in the IRI spec and also makes the \n>suggestion to use scheme aware mapping much stronger (SHOULD instead of \n>MAY). It is a SHOULD instead of a MUST simply because a scheme may be \n>updated in the future, making the scheme awareness eventually not necessary.\n>\n>Michel\n\n\n\n", "id": "lists-017-1300878"}, {"subject": "BleedValidator in WinI", "content": "Hi,\n\n  The layout of e.g.\n\n? http://qa-dev.w3.org/wmvs/0.6/check?uri=http%3A%2F%2Fmsdn.microsoft.com&verbose=0\n\nstill suffers from <http://www.google.com/search?q=guillotine+bug> in\nInternet Explorer/Windows. Elements jump around when hovering links and\nit causes the scrollbar to flicker. Terje said some time ago the latest\nfixes weren't in CVS, is this still the case? Or were there any new\n\"fixes\"?\n\nregards.\n\n\n\n", "id": "lists-017-13012845"}, {"subject": "How to make verbosemsg.cfg more usefu", "content": "Hi,\n\n  I wondered whether I can include verbosemsg.cfg into my toolbar and\ntried to review it. That's basically not possible without prior\npre-processing. I am not sure why all these messages are included there,\nit is most unlikely that that our users will ever see a message like\n\n[...]\n  character number %1 cannot be assigned to LCNMCHAR,\n  UCNMCHAR, LCNMSTRT or UCNMSTRT because it is RS\n[...]\n\nI neither really understand why there is the same \"Help Wanted!\" text\nover and over and over again, or why this is stored in such a odd\nformat. Maybe this saves a few lines of code... Can we change this to\nan XML format and only include the messages that actually have code?\nWe could use\n\n  <message num = '0815'>\n     <original>...</original>\n  </message>\n\nto easy processing, but all this \"Help Wanted!\" should be inferred from\ncheck, not hardcoded, and I guess we can still parse the format using\nregular expressions if we follow some rules for the content. Maybe this\n\"Help Wanted!\" stuff is really the wrong approach, maybe we should\nmaintain this stuff in the Wiki and point to the wiki for people who\nwant to help. This would of course need some moderation...\n\nregards.\n\n\n\n", "id": "lists-017-13020103"}, {"subject": "Re: [checklink] Preparing for 3.9.", "content": "On Thu, 2004-04-15 at 10:44, olivier Thereaux wrote:\n> Ville,\n> \n> On Apr 15, 2004, at 02:11, Ville Skytt? wrote:\n> > I believe it's soon time to release Link Checker 3.9.3.\n> \n> Great!\n> \n> Are you planning a short beta test soon? I haven't had time to test it \n> yet, but I went through the diff and things look good. I will try to \n> play with it within a few days, tell me how you'd like to schedule the \n> next steps.\n\nI'll try to get the robots-text-is-screaming-red-403 issue fixed in the\nweekend, after that we could do a quick beta test.  But nothing prevents\nfrom testing already now, because about all the real functional changes\nfor 3.9.3 are already in as far as I'm concerned.\n\nThe status of libwww-perl needs attention though, I believe the link\nchecker $TNV *could* in theory work with the 5.64 on v.w.o, 5.66+ is\nneeded for command line use.  But perhaps the upgrade to 5.79 would not\nbe a bad idea.\n\nI've notified the Debian libwww-perl maintainer about the 5.76 file:\nredirect issue, perhaps there will be an updated .deb available soon. \nFedora Core 2 will most likely include 5.79 (it's in Rawhide now).\n\n\n\n", "id": "lists-017-13028315"}, {"subject": "Re: BleedValidator in WinI", "content": "On Apr 15, 2004, at 16:59, Bjoern Hoehrmann wrote:\n>   The layout [...] still suffers from \n> <http://www.google.com/search?q=guillotine+bug> in Internet \n> Explorer/Windows.\n\nHmm, I heard of it but since my windows machine won't work any more, I \ncan't really test and fix.\n\nGiven that 0-6-5b2 is mostly about presentation, layout and \ndocumentation, I am going forward with it today, the beta test period \nwill be used for fixing CSS bugs with a larger pool of \nbrowsers/platform that we had when coding the CSS changes.\n\nAnd AFAIK, http://qa-dev.w3.org/wmvs/0.6/ (and CVS) has all the latest \nCSS code. Terje commited his a short while ago.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13037001"}, {"subject": "Re: [checklink] Preparing for 3.9.", "content": "On Apr 16, 2004, at 04:12, Ville Skytt? wrote:\n> The status of libwww-perl needs attention though, I believe the link\n> checker $TNV *could* in theory work with the 5.64 on v.w.o, 5.66+ is\n> needed for command line use.  But perhaps the upgrade to 5.79 would not\n> be a bad idea.\n>\n> I've notified the Debian libwww-perl maintainer about the 5.76 file:\n> redirect issue, perhaps there will be an updated .deb available soon.\n> Fedora Core 2 will most likely include 5.79 (it's in Rawhide now).\n\nHaven't got time to look yet but I suppose from what you're saying that \n5.79 fixes the file: redirect bug, which is good. That said, are we \nsure it's a good candidate (i.e stable enough) to put into production?\n\nI realize that updating lwp is starting to be important and urgent, I \njust would not want to regret any hasty move.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13045058"}, {"subject": "Re: How to make verbosemsg.cfg more usefu", "content": "I asked myself similar questions when working on the beta2 recently. I \nthink the current (annoying, perhaps) display of \"can you find a better \nexplanation\" could be made less visible when we move to release. In the \nmeantime, if seeing it motivates people to contribute more explanation \nmessages, good for us and them.\n\nAs for the format, I (as main editor of the messages, at least \nrecently) would also be happier with a simpler design for the file.\n\nI wish I had more ideas for the \"help wanted\". The list isn't such a \nbad thing for that purpose, especially given how few we receive.\n\nIdeas welcome, I may tweak the code, though certainly not today...\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13053321"}, {"subject": "Re: How to make verbosemsg.cfg more usefu", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@zoy.org> wrote:\n\n>I asked myself similar questions when working on the beta2 recently. I\n>think the current (annoying, perhaps) display of \"can you find a better\n>explanation\" could be made less visible when we move to release. In the\n>meantime, if seeing it motivates people to contribute more explanation\n>messages, good for us and them.\n\nThe current \"Help Wanted\" blurb was always intended to only be there for the\nBeta. For production the intent was to either remove it completely or tone it\ndown to one short sentence/link.\n\n\n>As for the format, I (as main editor of the messages, at least recently)\n>would also be happier with a simpler design for the file.\n\nThe format of the file is what Config::General uses, and is supposed to be\nreminiscent of Apache config file syntax. Using a homebrew config parser is\nnot an option as far as I'm concerned (BTDT), and since we need\nConfig::General for the other config files it makes little sense to have a\ncustom parser for just the verbose messages resource file.\n\nHowever, the Config::General syntax is very flexible so it may well be that we\ncan do what you want even within those confines.\n\n- -- \n\"I don't want to learn to manage my anger;\n I want to FRANCHISE it!\" -- Kevin Martin\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQH/KS6PyPrIkdfXsEQL2XQCg4HAFZeh3SZtdhma9Rq9BSuPczskAni3U\nlTNMzek9rFFJ8WCtxGZPKz9w\n=CtUY\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13061564"}, {"subject": "Re: How to make verbosemsg.cfg more usefu", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nBjoern Hoehrmann <derhoermi@gmx.net> wrote:\n\n>I am not sure why all these messages are included there,\n>it is most unlikely that that our users will ever see a message like\n\nThey are there because when we started out we had _zero_ explanations and\nneeded a good list of possibles to start from. That file is automatically\ngenerated from OpenSP source, so it is canonical in a sense.\n\n\n>I neither really understand why there is the same \"Help Wanted!\" text\n>over and over and over again\n\nIt was a tradeoff. By embedding the Help Wanted text into the Perl code you\nmake future developments in the file format/features and l10n more difficult;\nand locks us in to the specific HTML format used in the message.\n\nI'm not sure the tradeoff fell down on the \"right\" side (but neither am I\nconvinced it's \"wrong\" today!).\n\nAll work on the file format should take into account Flexibility, i18n, and\nwhat effect it has on forward and backward compatibility between versions. Not\nthat that would prevent the things you've suggested here, but...\n\n- -- \nEditor's note: in the last update,   we noted that Larry Wall would \"vomment\"\non existing RFCs. Some took that to be a cross between \"vomit\" and \"comment.\"\nWe are unsure of whether it was a subconscious slip or a typographical error.\nWe are also unsure of whether or not to regret the error.      -- use.perl.org\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQH/MDqPyPrIkdfXsEQJU1QCgxHx5vcyFdB3pYuX7YphDZFwCQ8EAoOa5\n09SCK9cIRXVpYvkZjstjW5ih\n=rx+q\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13070817"}, {"subject": "Meeting next week (?) + schedule chang", "content": "Hi all,\n\nYan, whom I am copying in this mail, dropped by IRC today and we had an \ninteresting discussion about a few things he had been working on, \ntaking as a base our HEAD Markup Validator. Yan would certainly be \nbetter at explaining his work, but I'll try to summarize...\n\nHe used the templates to create a FR_CA version of the Validator, also \nmodularized it to some extent, made it work with mod_perl on apache2, \nand also played with php to create a dual \"W3C-like\"/\"grouped error\" \nvalidation output.\n\nI was thinking maybe we could have a meeting next tuesday to discuss \nthat all together, and Bjoern suggested we switch our IRC meeting \nrhythm to \"every 2 weeks\" instead of our current monthly rate.\n\nHowever, Bjoern will have, in the foreseeable future, time constraints \nthat would not allow him to join IRC at our regular time.\n\nHence a few questions:\n- Would you be available for a discussion on IRC next week?\n[ ] NO  [ ] YES\n- Would you like our meetings to be every 2 weeks?\n[ ] NO  [ ] YES\n- Would you like our meetings to start 30 minutes later than now?\n[ ] NO  [ ] YES  [ ] Can live with\n- Would you prefer same time, another day?\n[ ] NO [ ] YES : [   day(s)  ]\n- Somebody (in my IRC logs) suggested sunday PM / monday AM.\nHow about 16:30 MTL, 22:30 Paris, 23:30 Helsinki, 05:30 Tokyo?\n[ ] NO [ ] YES [ ] Can live with\n\nI know, I should be creating a WBS questionnaire for that, but you'd \nall need (public) web accounts for w3.org. Which would actually be a \ngood idea, but we'll address that later.\n\nAs usual, reply to the list or to me, as you like.\n\nThanks\n-- \nolivier\n\n\n\n\n\n", "id": "lists-017-13080012"}, {"subject": "0.6.5b2 tarball", "content": "http://validator.w3.org:8001/validator.tar.gz and\nhttp://validator.w3.org:8001/sgml-lib.tar.gz still point to the 0.6.5b1\nones.\n\nCould someone who has done it before, roll & update those tarballs for\n0.6.5b2 (and preferably, add the script to do that in CVS somewhere)?  I\nwould like to use a \"real release tarball\" for the validator RPM instead\nof a self-made-from-CVS-checkout one.\n\n\n\n", "id": "lists-017-13088764"}, {"subject": "Re: [checklink] Preparing for 3.9.", "content": "On Fri, 2004-04-16 at 01:38, olivier Thereaux wrote:\n\n> Haven't got time to look yet but I suppose from what you're saying that \n> 5.79 fixes the file: redirect bug, which is good. That said, are we \n> sure it's a good candidate (i.e stable enough) to put into production?\n> \n> I realize that updating lwp is starting to be important and urgent, I \n> just would not want to regret any hasty move.\n\nUnderstood and agreed.  But all the development work I'm doing is with\n5.79 (and I've reviewed quite a bit of the current LWP codebase lately,\nit should be in good shape), qa-dev currently has 5.76 and v.w.o has\n5.64.  As long as the production version will be using something that we\ntest 3.9.3 with, it's fine with me.  Well, as long as it's newer than\n5.60, excluding 5.76 ;)\n\nUpdating the system LWP on v.w.o would of course need the validator to\nbe tested with the new one as well.  But if need be, one or even both of\n{validator,checklink} can be using their \"own\" LWP installation,\nbasically it's just a matter of unpacking the LWP dist tarball, doing a\nSetEnv to the libwww-perl-*/lib dir in Apache's config for the relevant\nscript, and removing the -T flag from the CGI's perl shebang.  Note, I'm\nnot advocating this, just pointing it out as a possibility just in\ncase...\n\n\n\n", "id": "lists-017-13095705"}, {"subject": "Re: [checklink] Preparing for 3.9.", "content": "On Thu, 2004-04-15 at 22:12, Ville Skytt? wrote:\n> On Thu, 2004-04-15 at 10:44, olivier Thereaux wrote:\n\n> > Are you planning a short beta test soon? I haven't had time to test it \n> > yet, but I went through the diff and things look good. I will try to \n> > play with it within a few days, tell me how you'd like to schedule the \n> > next steps.\n> \n> I'll try to get the robots-text-is-screaming-red-403 issue fixed in the\n> weekend, after that we could do a quick beta test.\n\nOk, this is now done (although the implementation is somewhat ugly), and\nhttp://qa-dev.w3.org/wlc/checklink is up to date.  I think 3.9.3 is now\nready for a beta test now.\n\n\n\n", "id": "lists-017-13104000"}, {"subject": "Re: [checklink] Preparing for 3.9.", "content": "Hi Ville, All,\n\nOn Apr 20, 2004, at 05:17, Ville Skytt? wrote:\n>> I'll try to get the robots-text-is-screaming-red-403 issue fixed in \n>> the\n>> weekend, after that we could do a quick beta test.\n>\n> Ok, this is now done (although the implementation is somewhat ugly), \n> and http://qa-dev.w3.org/wlc/checklink is up to date.\n> I think 3.9.3 is now ready for a beta test now.\n\nI have just installed LWP 5.79 on qa-dev. Maybe we can check for a day \nor two whether that causes no problem with either the validator or \nchecklink, and proceed with a beta (with 5.79 installed on w.v.o) \nwithin a couple days?\n\nI just tested the new feature (and style for the robots exclusion) and \nit seems to work fine, great job.\n\nI still find it frustrating that the link checker HAS to follow \nrobots.txt and telling users to check links manually, even in non \nrecursive mode, but I reckon I am against the majority here, and I \nshould probably just accept I am wrong and shut up ;)\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13111805"}, {"subject": "Re: Are IDNs allowed in http IRIs", "content": "On Mar 29, 2004, at 11:43 AM, Martin Duerst wrote:\n\n>>  Many (most?) browsers today will not resolve\n>> http://%E7%8C%AB%E3%81%AB%E5%B0%8F%E5%88%A4.nicemice.net/ because\n>> they don't handle percent-encoding in the host component, because\n>> it's not valid according to the current http: URI spec.\n>\n> Opera 7.2 resolves this. My personal version of Amaya\n> (compiling with the 'IDN' branch of libwww) resolves this.\n\nSafari does too. This is the first time I've seen kanji in the \naddress-bar, cool! -Tim\n\n\n\n\napplication/pkcs7-signature attachment: smime.p7s\n\n\n\n\n", "id": "lists-017-1311900"}, {"subject": "[meeting] 2004-0420 confirme", "content": "On Apr 16, 2004, at 21:43, olivier Thereaux wrote:\n> I was thinking maybe we could have a meeting next tuesday to discuss \n> that all together, and Bjoern suggested we switch our IRC meeting \n> rhythm to \"every 2 weeks\" instead of our current monthly rate.\n\nGiven the answers I received, we should try and have a meeting \ntoday/tomorrow (April 20th), half an hour after last time's schedule, \nwhich should be, if I am not mistaken:\n\n16:30 UK,\n17:30 France / Germany / Norway,\n18:30 Finland,\n24:30 Japan.\n\nVenue as usual : #validator on irc.freenode.net\n\nApologies for the late confirmation... I am not sure everyone will see \nthis message in time and/or will be able to join, so we will have an \nad-hoc agenda.\n\nHope you can make it.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13119936"}, {"subject": "Re: [checklink] Preparing for 3.9.", "content": "On Tue, 2004-04-20 at 01:06, olivier Thereaux wrote:\n\n> I have just installed LWP 5.79 on qa-dev. Maybe we can check for a day \n> or two whether that causes no problem with either the validator or \n> checklink, and proceed with a beta (with 5.79 installed on w.v.o) \n> within a couple days?\n\nSounds good.\n\n> I still find it frustrating that the link checker HAS to follow \n> robots.txt and telling users to check links manually, even in non \n> recursive mode, but I reckon I am against the majority here, and I \n> should probably just accept I am wrong and shut up ;)\n\nFWIW, I am not a huge fan of it either.\n\nA doc snippet (and a pointer to it from the \"forbidden by robots.txt\"\nexplanation) how to allow the link checker in /robots.txt would probably\nbe a good idea, I'll look into it.\n\n\n\n", "id": "lists-017-13127594"}, {"subject": "[meeting] Notes and log - 2004-042", "content": "Hi all,\n\nHere are my notes from yesterday's (2004-04-20) meeting.\n\nStarting with the summary of (a lot of) action items and main \nresolutions.\n\nACTION: Bjoern to modify priorities in CSSValidator's bugzilla\nACTION: Yves and Bjoern send olivier list of \"test\" cases URI for the \nCSS validator\nACTION: Olivier to (re)start work on test suites for Validators\nACTION: Olivier contact PLH/Sijtsche and ask them what is implemented / \nto what extent (esp. CSS3)\nACTION: Nick to install mod_validator @ qa-dev\nACTION: Bjoern to send reservations re CVS plans to the list\nACTION : Olivier to compare :8001 traffic to :80 traffic\nACTION : ALL - get public Web accounts (if no member/team account \nalready)\n\nRESOLUTION: new beta for checklink, get feedback on implementation of \nrobots.txt\nRESOLUTION: short beta3 for Markup Validator, and release <= May 1st\nRESOLUTION: bi-weekly meeting\n\nThere were 3 items in the agenda, making that 4 for clarity of the \nrecord.\n\n* 1 - checklink *\n\nVille was given the \"fastest hacker\" award for his implementation of \nthe robots exclusion protocol, Kudos.\n\nThere is, however, dissent on whether/when the link checker is actually \na robot, and a feeling (for some of us) that following robots.txt makes \nit less useful. A first workaround (implemented during the meeting!) is \nto add a note explaining how to modify one's robots.txt to allow the \nlink checker to do more than other agents.\n\nGood points were raised on other ideas and methods, but no agreement, \nso we will proceed with a new beta test, specifically asking for \nfeedback on the issue of robots.txt, and then act accordingly for a \nrelease of checklink 3.9.3.\n\n\n* 2 - CSS validator *\n\nYves actively fixing bugs, and wishing to have a prioritized list of \nthings to do. Bjoern will give his priorities on the Bugzilla list.\n\nIt is apparently not clear how much of CSS3 is implemented, nor how \nmuch is implemented (period). Olivier will contact PLH, Sijtsche, +CSS \nWG to clarify that.\n\n\n* 3 - Test suites *\n\nrelated to the topic of prioritized bug, the lack of progress on Test \nsuite work is a burden. Yves and Bjoern will send olivier test cases, \nand olivier will shift focus back to test suite work.\n\n* 4 - Markup Validator *\n\nNot much feedback for the low-profile Markup Validator 0.6.5b2, but the \nfeedback is generally limited anyway. We should try to ask feedback on \nspecific points to specific people as much as possible in the future.\n\nOlivier got (annoyed) feedback on XML limitations, plus rumours of a \nXML-friendlier OpenSP, will followup.\n\nAt this point, momentum being preferred over perfection, the agreed \nplan is to fix the CSS \"guillotine\" problem, launch a quick beta3, and \nrelease 0.6.5 before May 1st, \"unless something big comes up\".\n\n[adjourned - 1h50]\n\nIRC log attached, with light trimming as usual.\n\n\n\n-- \nolivier\n\n\n\n\ntext/plain attachment: qadevlog-20040420.txt\n\n\n\n\n", "id": "lists-017-13134904"}, {"subject": "Re: [meeting] extra Action Item - 2004-042", "content": "Dom,\n\nOn Apr 21, 2004, at 10:55, olivier Thereaux wrote:\n>\n> * 1 - checklink *\n> There is, however, dissent on whether/when the link checker is \n> actually a robot, and a feeling (for some of us) that following \n> robots.txt makes it less useful. A first workaround (implemented \n> during the meeting!) is to add a note explaining how to modify one's \n> robots.txt to allow the link checker to do more than other agents.\n\nThe note is at:\nhttp://qa-dev.w3.org/wlc/#bot\n\nCould I assign you the (extra) action item of taking care of this for \nthe robots.txt at www.w3.org? This would be setting a good example.\n\nThanks\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13144955"}, {"subject": "Compared (recent) :8001 and :80 traffi", "content": "On Apr 21, 2004, at 10:55, olivier Thereaux wrote:\n> ACTION : Olivier to compare :8001 traffic to :80 traffic\n\nI isolated the :8001 logs for 2004-04-19.\n:8001 made 5176 hits that day (859 GET for /check?foobar and 15 HEAD)\n\nTo be compared to the daily average of 585012 hits per day (128000 for \n/check) on :80 in April.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13153242"}, {"subject": "bugzilla  minor modification", "content": "Just FYI, I have turned \"QA contact\" support ON for our Public bugzilla.\n\nI also made myself default owner for Documentation and Test suite \nissues.\n\nDon't hesitate to ask me for other tweaks to the bugzilla configuration.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13160256"}, {"subject": "Re: [meeting] extra Action Item - 2004-042", "content": "Hi Olivier,\n\nLe mer 21/04/2004 ? 04:01, olivier Thereaux a ?crit :\n> On Apr 21, 2004, at 10:55, olivier Thereaux wrote:\n> > * 1 - checklink *\n> > There is, however, dissent on whether/when the link checker is \n> > actually a robot, and a feeling (for some of us) that following \n> > robots.txt makes it less useful. A first workaround (implemented \n> > during the meeting!) is to add a note explaining how to modify one's \n> > robots.txt to allow the link checker to do more than other agents.\n> \n> The note is at:\n> http://qa-dev.w3.org/wlc/#bot\n> \n> Could I assign you the (extra) action item of taking care of this for \n> the robots.txt at www.w3.org? This would be setting a good example.\n\nSure, done. FWIW, I couldn't test it as well as I wanted, because my\nauth credentials are rejected when trying to checklink e.g. /Projects\n(Team-only) ; I'm not sure why they were, nor if that's a known problem\nin this instance of the linkchecker (I tried several other password\nprotected areas without luck).\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n\n", "id": "lists-017-13166780"}, {"subject": "Re: [meeting] extra Action Item - 2004-042", "content": "Dom,\n\nOn Wed, Apr 21, 2004, Dominique Haza?l-Massieux wrote:\n> > Could I assign you the (extra) action item of taking care of this for \n> > the robots.txt at www.w3.org? This would be setting a good example.\n> \n> Sure, done. \n\nGreat, thanks.\n\n>FWIW, I couldn't test it as well as I wanted, because my\n> auth credentials are rejected when trying to checklink e.g. /Projects\n\nBefore that change to robots.txt, checklink did not even try.\nAuthentication means that it works. Cross-checked by testing with\nhttp://www.w3.org/People/olivier/\nwhich has a link to my Team page.\n\n\n> I'm not sure why they were, nor if that's a known problem\n> in this instance of the linkchecker (I tried several other password\n> protected areas without luck).\n\nAFAIK the auth forwarding hack is not present on qa-dev.w3.org, that\nwould be the explanation.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13175808"}, {"subject": "Re: [meeting] extra Action Item - 2004-042", "content": "On Wed, 2004-04-21 at 10:57, Olivier Thereaux wrote:\n\n> > I'm not sure why they were, nor if that's a known problem\n> > in this instance of the linkchecker (I tried several other password\n> > protected areas without luck).\n> \n> AFAIK the auth forwarding hack is not present on qa-dev.w3.org, that\n> would be the explanation.\n\nI tried adding it (see /etc/apache2/conf.d/wlc.conf), but for some\nreason it still does not seem to work, while in my local Apache2\n(2.0.48, Fedora Core 1) that same hack works just fine.\n\n\n\n", "id": "lists-017-13184314"}, {"subject": "Re: [meeting] extra Action Item - 2004-042", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>I tried adding it (see /etc/apache2/conf.d/wlc.conf), but for some\n>reason it still does not seem to work, while in my local Apache2\n>(2.0.48, Fedora Core 1) that same hack works just fine.\n\nAFAIK, getting Apache to pass authentication info on to CGI space requires a\ncompile-time option still; unless using the native Apache API (in which case\nyou should be able to access it directly).\n\nBut then I'm not all that familiar with the relevant bits of code...\n\n\n- -- \n??I also need a longer attention sp- Ooh! Feet!?? ??? Loz Pycock\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQIbaOqPyPrIkdfXsEQKp+QCguxYhsF338lwuAOec6rrYC9b0+4AAmgKQ\nqo4A4wQbPHVXM4vk3et7AHZl\n=MfsY\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13192001"}, {"subject": "Re: [meeting] extra Action Item - 2004-042", "content": "On Wed, 2004-04-21 at 23:31, Terje Bless wrote:\n> Ville Skytt? <ville.skytta@iki.fi> wrote:\n> \n> >I tried adding it (see /etc/apache2/conf.d/wlc.conf), but for some\n> >reason it still does not seem to work, while in my local Apache2\n> >(2.0.48, Fedora Core 1) that same hack works just fine.\n> \n> AFAIK, getting Apache to pass authentication info on to CGI space requires a\n> compile-time option still;\n\nIf you are referring to the SECURITY_HOLE_PASS_AUTHORIZATION #define,\nI'm pretty sure that distributors like Red Hat do not build their Apache\nwith it set...\n\nI thought that the mod_rewrite hack deployed on v.w.o (and now at\nqa-dev) should work everywhere.  It does here, anyway; and without the\nhack, $ENV{HTTP_AUTHORIZATION} is never populated.\n\n>  unless using the native Apache API (in which case\n> you should be able to access it directly).\n\nYep, eg. under mod_perl one can do $r->header_in('Authorization').  This\nis already done in checklink but it won't obviously work when it is run\nas a ordinary CGI script.\n\n\n\n", "id": "lists-017-13200920"}, {"subject": "RE: convert to punycode: SHOULD or MAY (was: RE: Are IDNs allowed   in  http IRIs?", "content": "I think this is an interoperability issue, and that neither SHOULD nor MAY\nare appropriate. Rather, there is a MUST with a couple of alternatives.\nImplementations\nresolving an IRI with non-ascii host names MUST use one of the established\nmethods of resolving the host name correctly.\n\nLarry\n\n\n\n", "id": "lists-017-1320348"}, {"subject": "css validator on qadev.w3.or", "content": "Hi Yves, Philippe.\n\nA while ago I remember discussing the installation of an instance of \nthe CSS validator on the qa-dev.w3.org test server. I wonder what the \nprogress is on that.\n\nCurrently, the server has auto-cvs-updated instances of both the Markup \nValidator and Link Checker, which I find very handy to see and show \nmodifications made in CVS.\n\nAs you may have heard, the Spanish W3C office is willing to take care \nof the translation of the interfaces of our validators, and asked \nwhether there was such a test instance for them to check their work. I \nbelieve an instance on qa-dev.w3.org would do that job.\n\nIf you still agree it's a good idea, please tell me how I can help you \nwith this.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13209565"}, {"subject": "Re: How to make verbosemsg.cfg more usefu", "content": "On Apr 16, 2004, at 20:58, Terje Bless wrote:\n\n> The current \"Help Wanted\" blurb was always intended to only be there  \n> for the\n> Beta. For production the intent was to either remove it completely or  \n> tone it\n> down to one short sentence/link.\n\nHow about the following?\n\n<p class=\"helpwanted\">\n  <a  \nhref=\"mailto:www-validator@w3.org? \nSubject=[VE][XXX]%20New%20Error%20Message%20Suggestion\">\n   Can you think of a better explanation?\n  </a>\n</p>\n\n\n\n\n", "id": "lists-017-13217123"}, {"subject": "Re: How to make verbosemsg.cfg more usefu", "content": "Make that:\n\n<p class=\"helpwanted\">\n  <a  \nhref=\"mailto:www-validator@w3.org? \nSubject=[VE][XXX]%20New%20Error%20Message%20Suggestion\"\n   title=\"submit a better explanation for this message to the public  \nvalidator mailing-list\">\n   Can you think of a better explanation?\n  </a>\n</p>\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13225452"}, {"subject": "0_6_0 results layout problem", "content": "The latest on 0_6_0 has some layout problems here, using Firefox 0.8 and\nKonqueror 3.1 on Fedora Core 1:\nhttp://qa-dev.w3.org/~ville/validator-firefox.png\nhttp://qa-dev.w3.org/~ville/validator-konq.png\n\n\n\n", "id": "lists-017-13233347"}, {"subject": "Re: 0.6.5b2 tarball", "content": "On Sat, 2004-04-17 at 00:45, Ville Skytt? wrote:\n> http://validator.w3.org:8001/validator.tar.gz and\n> http://validator.w3.org:8001/sgml-lib.tar.gz still point to the 0.6.5b1\n> ones.\n> \n> Could someone who has done it before, roll & update those tarballs for\n> 0.6.5b2 (and preferably, add the script to do that in CVS somewhere)?  I\n> would like to use a \"real release tarball\" for the validator RPM instead\n> of a self-made-from-CVS-checkout one.\n\nI went ahead and created the tarballs, and added misc/mkrelease.sh to\nCVS (0_6_0-branch).\n\n\n\n", "id": "lists-017-13239765"}, {"subject": "Re: BleedValidator in WinI", "content": "* olivier Thereaux wrote:\n>Hmm, I heard of it but since my windows machine won't work any more, I \n>can't really test and fix.\n\nI've added\n\n  a { position: relative }\n\nto (my local copy of) base.css and removed\n\n  fieldset { margin-bottom: 3em }\n\nfrom it. This seems to fix these layout issues. Instead we could have a\n<br /> after the fieldsets in question, for example. Otherwise, removing\nall :hover { background-color } rules should fix it, too.\n\n\n\n", "id": "lists-017-13246819"}, {"subject": "Re: [markup validator] source quoting i18n bug", "content": "[moving to qa-dev for semi gory details]\n\nOn Apr 25, 2004, at 2:16, Bjoern Hoehrmann wrote:\n>> I am far from being an expert on that part of the code, but it seems\n>> like a typical i18n problem.\n>\n> Yes, this is documented in the source (for truncate_line):\n>\n> [...]\n>   # This *really* wants Perl 5.8.0 and it's improved UNICODE support.\n>   # Byte semantics are in effect on all length(), substr(), etc. calls,\n>   # so offsets will be wrong if there are multi-byte sequences prior to\n>   # the column where the error is detected.\n> [...]\n\nMy guess was right, I really should have looked a bit further... Thanks \nBjoern for the confirmation.\n\nThe good news is that the new box waiting to be serving \nvalidator.w3.org has perl5.8, and so has our test server, so that \nshould be a breeze to fix.\n\nOne thing I wonder, though...\n\ncheck currently requires perl > 5.6, and perl 5.6 has \"use utf8\" (even \nthough this is deprecated by 5.8's better support (TM) of UTF8).\nAny reason we are not using that, and any reason we should not use that \nfor users of perl < 5.8?\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13254098"}, {"subject": "[meeting] rescheduling 2004-0504", "content": "Folks,\n\nOur next meeting should be, if we stick to the biweekly schedule, next \ntuesday. However, that day being a holiday in Japan, I do not know yet \nwhether I will be available for a meeting. I also remember Terje saying \nhe'd be busy at that time too.\n\nMaybe we could postpone to may 11th? I'll be in a f2f meeting in \nMontreal but shoud be able to take a couple of hours of reasonable \nattention to an IRC meeting. Or we could stick with our schedule and \nsee how things evolve.\n\nThoughts welcome.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13261991"}, {"subject": "[check] ready for beta 3", "content": "Hi.\n\nWe're scheduled for a beta3 of the Markup Validator this friday.\n\nI believe, but would like to have your confirmation, that since \nBjoern's patch seems to have fixed the display bug and since Terje \nsolved the righthand navbar issue, we are happy to move forward.\n\nI have already tagged all the files for the beta release. should you \nmake any modification before friday, and you want them to appear in the \nbeta, don't forget to 'cvs tag -F validator-0_6_5-beta3'\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13268768"}, {"subject": "Re: [check] ready for beta 3", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@w3.org> wrote:\n\n>I believe, but would like to have your confirmation, that since Bjoern's\n>patch seems to have fixed the display bug and since Terje solved the\n>righthand navbar issue, we are happy to move forward.\n\nIIRC there are still some lingering CSS issues (excessive right margins, some\nmissing left margins, etc.) that needs to be fixed before Beta3.\n\n- -- \nThese are the same customers you are referring to whom Microsoft thought\nwould need MS Bob and the Talking Paperclip?   One thing is to give them\nenough rope to hang themselves,  but a boobytrapped thermonuclear weapon\nrunning on a rand(time) countdown... Is that really wise? - Me to MS rep.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQI9RMaPyPrIkdfXsEQKZvwCcDuO6BKvAQJNSEfMJUOqASd60KT0AoO8O\nXnDLDvqmk93gOhn8ywQX1CvP\n=WQ6G\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13276056"}, {"subject": "Re: validator/htdocs footer.html,1.5.2.11,1.5.2.1", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nOlivier Thereaux <ot@lionel-hutz.w3.org> wrote:\n\n>Modified Files:\n>   Tag: validator-0_6_0-branch\n>       footer.html\n>Log Message:\n> Good question: how does one know which version of the validator they\n> are using? Important info, e.g for bug reports in bugzilla.\n>\n>In the dev version, the top banner gives that info, otherwise it's\n>harder.\n>\n>Thus, adding a version number to the footer.\n\nIn the beta version, the version number is already given in the header. You've\nadded it to the footer of the beta version. IOW, the version in the footer is\nredundant.\n\nI'd also say that adding it to current production is pointless provided we\nmake our release target of next Thursday; since current beta -- which has the\nversion number -- then becomes current prod.\n\n- -- \n\"See... *That* is the problem... Scotch is for sipping, relaxing, and deep\n thoughts... Jack is what you drink when you need to work through the pain.\"\n                                                           -- John C. Welch\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQI9TV6PyPrIkdfXsEQJ1MwCggTo0fGf/EEIfOtX6+7lZfAomEHEAoNMr\n5fHnuymrg7CsJRUsqGaiU6wk\n=+i6y\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13284954"}, {"subject": "presentation elements (issue presentationElement25) (was: Are   IDNs allowed in http IRIs?", "content": "At 00:23 04/03/19 -0800, Michel Suignard wrote:\n\n>Adam, I think you have a valid point, I would however make a simpler \n>suggestion, which is two fold:\n>\n>- introduce the concept of IRI used as presentation element of URI \n>protocol element. In that sense http://jose'.example.net/ is a \n>presentation element for the following protocol element \n>http://xn--jos-dma.example.net/ and as you noted \n>http://jos%C3%A9.example.net/ is not a correct URI (per RFC 2616 referring \n>to host itself defined in RFC 2396). I have suggested text in that sense \n>to the IRI main editor (Martin). Having the concept of presentation \n>element validates http IRIs which exist de facto, whatever we like it or not.\n\nHello Michel,\n\nI have noted this as issue presentationElement-25 and have\nadded the text you sent me, with some changes.\n\nPlease check it and send more comments if necessary. Otherwise,\nI'd like to close this issue.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1329261"}, {"subject": "Re: [check] ready for beta 3", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nTerje Bless <link@pobox.com> wrote:\n\n>IIRC there are still some lingering CSS issues (excessive right margins,\n>some missing left margins, etc.) that needs to be fixed before Beta3.\n\nOh, and we need to update the footer background with the updated PNG from\nBj??rn that uses a gradient into the background color instead of trying for\nalpha transparency (which ain't working in MSIE:win).\n\n- -- \n\"See... *That* is the problem... Scotch is for sipping, relaxing, and deep\n thoughts... Jack is what you drink when you need to work through the pain.\"\n                                                           -- John C. Welch\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQI9UWqPyPrIkdfXsEQI+YQCbBYVgH+cXyuw5hqi2qsz9MxLgSU4AoNWE\ncxo90j+vlw1DWKMPSdV0xfqm\n=Cu7w\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13293581"}, {"subject": "header/footer version inf", "content": "On Wed, Apr 28, 2004, Terje Bless wrote:\n> In the beta version, the version number is already given in the header. You've\n> added it to the footer of the beta version. IOW, the version in the footer is\n> redundant.\n\nI was assuming we'd get rid of the info in the header, since the version\ninformation is mostly important when testing a specific version (as\nopposed to *the* prod version).\n\nEither way is fine with me, though.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13302310"}, {"subject": "Re: [check] ready for beta 3", "content": "On Wed, Apr 28, 2004, Terje Bless wrote:\n> IIRC there are still some lingering CSS issues \n\nThought most were fixed... I gave it another try.\n\n> excessive right margins, some missing left margins, etc.\n\nI assumed you were talking about fieldsets? there are probably others I\nhave missed, please identify.\n\nThanks\n-- \nolivier\n\n\n\n", "id": "lists-017-13310052"}, {"subject": "Re: header/footer version inf", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nOlivier Thereaux <ot@w3.org> wrote:\n\n>I was assuming we'd get rid of the info in the header, since the version\n>information is mostly important when testing a specific version (as\n>opposed to *the* prod version).\n\nI prefer nuking it from the footer and keeping it in the header. The footer\nlooks like crap with it and having it in the header stands a chance of getting\nnoticed. We could deemphasise is somehow if you find it distracting there.\n\n\n- -- \n \"Oh, my. What? Did I hurt your little, iddy,\n  biddy feelings widdle MCSE kind of person?\"    -- Tina Holmboe\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQI/QMqPyPrIkdfXsEQKnsgCg62dHBQxiXtPazj6eRvcbXAEjiu8AnRLi\n4lWR7XxD6hKBp5hOJcpa/4xJ\n=09Vl\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13317655"}, {"subject": "Re: [check] ready for beta 3", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nOlivier Thereaux <ot@w3.org> wrote:\n\n>I assumed you were talking about fieldsets? there are probably others I\n>have missed, please identify.\n\nThe header has some wonkyness with the height of the background image vs. the\nheight of the W3C and QA logos. The top border of the horizontal navbar needs\nto overlap the black bottom (non-CSS) border of the W3C logo. The header\nshould probably have a top border overlapping the W3C logo's top (non-CSS)\nborder.\n\nThe Error Listing and the Source Display sections -- that I've checked -- on\nthe results page needs a small left/right margin. The footer needs to have a\ntop-margin to avoid it smushing whatever is at the bottom of the page (e.g. on\nthe results page). The left text in the footer needs a small margin to be\nlegible.\n\nAnd if we can find a way to do it without reintroducing the Guillotine\ntrouble, we should push some whitespave in between the two fieldsets on the\nfront page.\n\n- -- \nWhen I decide that the situation is unacceptable for me, I'll simply fork\nthe tree.   I do _not_ appreciate being enlisted into anyone's holy wars,\nso unless you _really_ want to go _way_ up in my  personal shitlist don't\nplay politics in my vicinity.                   -- Alexander Viro on lkml\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQI/SPaPyPrIkdfXsEQKiEgCgwPYJ3ejrISPoxzgteda2TOtRnHkAoJZv\n6LVZE37AvArMPPxxToenrIqj\n=WAuF\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13326266"}, {"subject": "Re: [check] ready for beta 3", "content": "* Terje Bless wrote:\n>And if we can find a way to do it without reintroducing the Guillotine\n>trouble, we should push some whitespave in between the two fieldsets on the\n>front page.\n\n<br>...\n\n\n\n", "id": "lists-017-13335703"}, {"subject": "Re: [check] ready for beta 3", "content": "* olivier Thereaux wrote:\n>I believe, but would like to have your confirmation, that since \n>Bjoern's patch seems to have fixed the display bug and since Terje \n>solved the righthand navbar issue, we are happy to move forward.\n\nI assume we will turn verbose mode off by default. There is another\nissue with the script for verbose mode, for some reason IE does not\ngenerate hundreds of these help wanted boxes, only a few...\n\n\n\n", "id": "lists-017-13343035"}, {"subject": "Re: header/footer version inf", "content": "* Terje Bless wrote:\n>>I was assuming we'd get rid of the info in the header, since the version\n>>information is mostly important when testing a specific version (as\n>>opposed to *the* prod version).\n>\n>I prefer nuking it from the footer and keeping it in the header. The footer\n>looks like crap with it and having it in the header stands a chance of getting\n>noticed. We could deemphasise is somehow if you find it distracting there.\n\nI think it should not be there, it's not useful for our users.\n\n\n\n", "id": "lists-017-13350327"}, {"subject": "Re: [check] ready for beta 3", "content": "On Apr 29, 2004, at 00:48, Terje Bless wrote:\n> The header has some wonkyness with the height of the background image \n> vs. the\n> height of the W3C and QA logos. The top border of the horizontal \n> navbar needs\n> to overlap the black bottom (non-CSS) border of the W3C logo. The \n> header\n> should probably have a top border overlapping the W3C logo's top \n> (non-CSS)\n> border.\n\nI wish the W3C logo had no border at all. I fixed some of the issues by \nputting the bottom border for the banner div rather than the h1.\n\n> The Error Listing and the Source Display sections -- that I've checked \n> -- on\n> the results page needs a small left/right margin.\n\nSource display: indeed. I gave it a bit of air by removing the \"auto\" \nmargins (hope they were not set to avoid a bug with some kind of \nsource, though my short tests did not show anything special). For the \nerror listing, looks OK\n\n> The footer needs to have a top-margin to avoid it smushing whatever is \n> at the bottom of the page (e.g. on the results page). The left text in \n> the footer needs a small margin to be legible.\n\nDone and done.\nThe margin and padding for the footer had been redefined and set to 0, \nI cleaned that part of the CSS a bit.\n\n\n> [ about version info ]\n> I prefer nuking it from the footer and keeping it in the header. The \n> footer looks like crap with it and having it in the header stands a \n> chance of getting noticed. We could deemphasise is somehow if you find \n> it distracting there.\n\nI was finding it a bit big, and Bjoern seems to dislike it too.\nI tried to see if we could tone it down a bit (and while doing so got \nsemantically pedantic and removed the version info out of the h1 - \nthough I'm having doubts now). I have removed the version info from the \nfooter, for now at least.\n\n\n\n\n\n", "id": "lists-017-13357728"}, {"subject": "Re: [check] ready for beta 3", "content": "* Terje Bless wrote:\n>Oh, and we need to update the footer background with the updated PNG from\n>Bj?rn that uses a gradient into the background color instead of trying for\n>alpha transparency (which ain't working in MSIE:win).\n\nThat would be <http://www.bjoernsworld.de/temp/footer.png>.\n\n\n\n", "id": "lists-017-13366698"}, {"subject": "Xml Report broke", "content": "Hi,\n\n  http://validator.w3.org:80/check?uri=http://www.w3.org&output=xml\n  http://validator.w3.org:8001/check?uri=http://www.w3.org&output=xml\n\nThe printf for <warning> should refer to ent($_->{Message}) rather\nthan &ent($_).\n\nregards.\n\n\n\n", "id": "lists-017-13374183"}, {"subject": "Re: [meeting] schedule and tentative agenda - 2004-020", "content": "Given the few answers I got, The following seems like a good schedule \nto try at least once.\n\nirc://freenode#validator\ntuesday, Feb. 3rd 17:00 CET (18:00 EET, 11:00 Boston/Montreal)\nfor two hours (or till I fall asleep)\n\nAgenda ideas:\n  - recent progress /work\n  - Bjoern's CSS schema\n  - validators' test suites\n\nagenda additions welcome if you think that won't be enough.\n-- \nolivier\n\n\n\n", "id": "lists-017-13444636"}, {"subject": "Re: [meeting] schedule and tentative agenda - 2004-020", "content": "* olivier Thereaux wrote:\n>  - Bjoern's CSS schema\n\nWhich is at http://www.websitedev.de/css/schema/draft/ btw.\n\n\n\n", "id": "lists-017-13452041"}, {"subject": "Re: [meeting] Notes from 2004-020", "content": "Notes from 2003-02-03 IRC meeting.\n\nAttendees : Bjoern, Nick, Yves, Ville, Karl, olivier + lurkers\n(Regrets: Terje)\n\nAgenda:\n- CSS schema and parser\n- Checklink\n- Test suite/harness for validator(s)\n\nAction items after this meeting:\nAI (cont): Bjoern -  write a specification for css schema\nAI (cont): Bjoern - contact libcroco maintainers\nAI (cont): Nick - investigate Apache2+modperl, play with :8001;\nAI (cont): olivier - review and integrate submitted error messages\nAI (new): Nick - demo test harness\nAI (new): Ville - send edited changelog for checklink\nAI (new): olivier - organize release cycle for checklink\n\n\n****************************************\n\n- CSS schema and parser\n\nBjoern showed and explained his draft[1] (ideas and issues) of CSS \nschema.\nthe basic idea is to have a language that helps writing tools for css \nand a new css validator.\n\n[1] http://www.websitedev.de/css/schema/draft/\n\nThe group then discussed available CSS parsers to work from (or lack \nthereof). Ideal would be a C (CPP) engine, other languages Ok as well.\n\nExisting products: SAC implementations are mostly vapourware, W3C CSS \nvalidator needs to be (partly) rewritten, libcroco the best-available \napproximation. Bjoern has a (continued) AI to contact libcroco \ndevelopers and will proceed with that, and will work on his draft, show \nit to www-style at the end of february.\n\n\n- Checklink\n\nCurrently Link Checker (checklink) tied to the Markup Validator (check) \nbut the two have very different development process and speed. No \nspecific reason for them to be tied (though nothing prevents against \nadding some integration glue somewhere if that is desired).\n\nDecision: We will work on a beta test and standalone release, as well \nas packaging of checklink ASAP.\nVille will send a list/summary of changes from code in stable \nvalidator, olivier will prepare beta announcement from it.\n\nFuture work: tearing apart / modularizing. Easier now that it should \nnot go in the way of markup validator's release pace.\n\n\n- Test suite/harness\n\nCurrently we have a basic list[2] of links as \"test suite\" for markup \nvalidator. Not sufficient, nor very flexible.\n\n[2]http://validator.w3.org/dev/tests/\n\nWhat would be much better: (semi?) automated test system, a solid \nrepository of test cases with description/expected result, and an easy \n(i.e not bugzilla-heavy) process to submit test cases (e.g with bug \nreports). Not only for markup validator, checklink.\n\nOlivier has been playing with the current tests and Log validator[3], \nbut that does not address all necessary features, e.g test the \nvalidators ui, escaping html, uris, showing proper dialogs, etc.\n\n[3] http://www.w3.org/QA/2003/10/valtest/\n\nNick has ideas, will hack up a demo.\nOlivier will gather clear and full feature set and requirements.\n\n****************************************\n\nNext meeting : March 2nd, 2004, 17:00 CET (18:00 EET, 11:00 \nBoston/Montreal)\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13459414"}, {"subject": "Re: [meeting] Notes from 2004-020", "content": "On Wed, 2004-02-04 at 10:54, olivier Thereaux wrote:\n\n> AI (new): Ville - send edited changelog for checklink\n\nOk, here goes a \"NEWS\"-like change log since the production version\n(full changelog available at\nhttp://dev.w3.org/cvsweb/validator/httpd/cgi-bin/checklink.pl?only_with_tag=validator-0_6_0-branch, see changes since revision 3.6.2.3):\n\n- Improved redirect loop detection\n- Recursion scope checking fixes\n- Config option to disable checking documents on non-public IP addresses\n  -> new dependency on the Net::IP CPAN module\n- Markup improvements\n- Documentation improvements (command line options, embedded man page)\n- Various other small bug fixes\n\n> Future work: tearing apart / modularizing.\n\nI have started some initial work on this, implementing some per-document\ntype (ie. MIME type) based handlers, akin to HTML::LinkExtor, using a\nfactory pattern.  Currently first cut implementations exist for generic\nXML documents (XML Base, XLink, XInclude) and CSS (using CSS::SAC which\nis currently broken for url(...) property values -> only @import's\nwork).\n\nOnly the handlers are implemented currently, checklink does not even use\nthem yet.  Will continue that development and post betas for discussion\nafter the next \"production\" checklink is out and modularization\nofficially starts.\n\n\n\n", "id": "lists-017-13469692"}, {"subject": "Test cases for improper marku", "content": "Hi,\n\n  Lot's of free improper markup, free download, free validator links\nincluded! Featuring <marquee> and <blink> tags! Feel free to get them\nfor free from:\n\n  http://www.websitedev.de/markup/validator/tests/\n\nregards.\n\n\n\n", "id": "lists-017-13477643"}, {"subject": "Validator(s)' Test suite  requirements (thoughts", "content": "Here are my thoughts on the topic of a test suite for our various \nvalidators (including checklink by stretching the definition a bit).\n\nI'm mixing the ideas of a test suite and test framework because I \nbelieve the former must be designed precisely enough to allow us to \nbuild the latter. If we don't fix this requirement for the test suite, \nI guess a simple list of document (or something a bit more complex, as \nBj?rn just did).\n\nWe want a system that allows, in priority (use cases):\n- a large (enough) collection of test\n- (very easy) contribution of a test case with, ideally, each bug report\n- testing of several instances of the validator + comparison of \ndifferent instances + comparison with expected result (so a fixed list \nof validator-uri is a no-no)\n- Classification of test. possibility to run only a subset of the suite\n\nThe main issue... Is to build a test suite for a test tool (duh). This \nbrings one (or even several) levels of complexity that I don't think \nare too common in software testing (but I don't claim to be an espert \non the matter).\n\nLet us just pretend for a moment that a test case is a document (I have \nideas to refine that, which I will explain later). Considering a test \ncase linked to the validation engine (as opposed to UI, formatting, \netc, which the system should also address). What's the expected result? \nThe result that the production validator gives, and which, for \nconsistency, the tested version is supposed to give, or is it the known \n(or guessed) validity of the test case wrt a given DTD? This is not \nsuch a complicated question, I guess, and once we make a clear \ndistinction between the expected (validity) and usual results, it is \npossible to envision having the expected result \"hardcoded\" with the \ntest case, and keep former results (including the reference results \nfrom the current prod tool) in EARL or whatever other format suits the \npurpose (EARL looks quite good).\n\nWhat would the system do (taken and completed from Bj?rn's list of \n200402 meeting):\n  - read list of cases\n  - filter (keep only subset we want to test)\n  - run the tool\n* get outcome (EARL format?)\n* scrape results (in whatever output we want to test, usually XHTML I \nsuppose)\n  - Check UI [if included in the test description?] => escaping / URIs / \ndialogs / proper output according to options (source tree etc.)\n  - Compare test result with expected outcome\n  - compare test result with known results from other instances\n\nI gave an incomplete listing of UI tests, and the process assumes that \nwe also test the validation engine. I remember being told that testing \nthe core (openSP / libs) was not ours to do, and I guess to some extent \nthat is true, but I suppose a few tests could be used to check that at \nleast all these components are present (e.g that the lib is up to date \nand that all the right DTDs are known)\n\n From all the thoughts above I can start outlining how a test would be \ndescribed:\n- URI of the tested document\n- tools' options (to be appended/sent in a GET/POST)\n- DTD used\n- validity wrt DTD used\n+ well formed (if XML)*\n- long description (not fond of having the document describe itself)\n\n(*)e.g v.w.o/dev/tests/xhtml-mathml2.html is well formed but not valid \n(AFAIK)\n\n\n\nAll for now. Please give your opinion or provide additions so that I \ncan write a complete req. document, for the record.\n\nthanks.\n-- \nolivier\n\n\n\n", "id": "lists-017-13484733"}, {"subject": "Re: Test cases for improper marku", "content": "Bj?rn,\n\n\nI can't believe my spam filter did not explode with your description :)\nBut thanks, these will be very useful.\n\nOn Feb 10, 2004, at 05:45, Bjoern Hoehrmann wrote:\n>   http://www.websitedev.de/markup/validator/tests/\n\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13495260"}, {"subject": "Re: Validator(s)' Test suite  requirements (thoughts", "content": "Le 09 f?vr. 2004, ? 20:44, olivier Thereaux a ?crit :\n> Let us just pretend for a moment that a test case is a document (I \n> have ideas to refine that, which I will explain later). Considering a \n> test case linked to\n\nDo you mean a test case for HTML 4.01 is only an HTML 4.01 document, \nlike a Web page.\n\nSo here come the mess, when you have to test things like conflicting \nencoding or conflicting mime-type.\nAn utf-8 document served as iso-8859-1\nAn XHTML 1.1 document served as text/html\n\nThese two cases can't be treated only as one document. It can be a \ncombination of two documents.\n- .htaccess\n- test-case-encoding-xhgn001.html\n\nA way to have a trace somewhere that there's an additional information \nfor this test case is important.\n\n\n-- \nKarl Dubost - http://www.w3.org/People/karl/\nW3C Conformance Manager\n*** Be Strict To Be Cool ***\n\n\n\n", "id": "lists-017-13502538"}, {"subject": "Update checklink on 8001", "content": "Any objections if I go ahead and update checklink from CVS on\nv.w.o:8001?  (assuming I have enough perms to do it, which I seem to\nhave.  I don't mind if someone else does it though :)\n\n\n\n", "id": "lists-017-13510526"}, {"subject": "Re: Update checklink on 8001", "content": "On Feb 16, 2004, at 05:34, Ville Skytt? wrote:\n> Any objections if I go ahead and update checklink from CVS on\n> v.w.o:8001?  (assuming I have enough perms to do it, which I seem to\n> have.  I don't mind if someone else does it though :)\n\nFine with me, go ahead. I did not have time to prepare the call for \nbeta test (you changelog is good and we'd just need to wrap that a bit) \nbecause I was busy, but it's time to move forward.\n\nJust drop us a line when you're done, and say whether you prefer to \nsend the call for beta test or if you want me to do it. Both are just \nfine with me.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13517299"}, {"subject": "Re: Update checklink on 8001", "content": "On Mon, 2004-02-16 at 02:08, olivier Thereaux wrote:\n\n> Just drop us a line when you're done, and say whether you prefer to \n> send the call for beta test or if you want me to do it. Both are just \n> fine with me.\n\nI'll try to get it done tomorrow.  And it'd be great if you could\nprepare the beta announcement/call for testers.\n\n\n\n", "id": "lists-017-13525178"}, {"subject": "Re: Validator(s)' Test suite  requirements (thoughts", "content": "On Feb 10, 2004, at 10:44, olivier Thereaux wrote:\n\n> Here are my thoughts on the topic of a test suite for our various \n> validators\n\nTransfered to the QA wiki so that anyone can include their ideas - \nwe'll edit a formal requirement doc from that.\n\nhttp://esw.w3.org/topic/ValidatorTestSuite\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13532748"}, {"subject": "Re: Update checklink on 8001", "content": "On Mon, 2004-02-16 at 20:08, Ville Skytt? wrote:\n> On Mon, 2004-02-16 at 02:08, olivier Thereaux wrote:\n> \n> > Just drop us a line when you're done, and say whether you prefer to \n> > send the call for beta test or if you want me to do it. Both are just \n> > fine with me.\n> \n> I'll try to get it done tomorrow.\n\nOk, done.  :8001 is now running the latest and greatest checklink from\nthe validator-0_6_0-branch.\n\n>   And it'd be great if you could\n> prepare the beta announcement/call for testers.\n\n(Olivier sent a draft of this to me for review, it looks good and will\nprobably be finished/announced soon.)\n\n\n\n", "id": "lists-017-13539894"}, {"subject": "Re: Update checklink on 8001", "content": "On Feb 18, 2004, at 06:20, Ville Skytt? wrote:\n> Ok, done.  :8001 is now running the latest and greatest checklink from\n> the validator-0_6_0-branch.\n\nSplendid!\n\nI wonder if we could/should add a [Beta] tag to the title of the page, \nfor clarity's sake.\n\n>>   And it'd be great if you could\n>> prepare the beta announcement/call for testers.\n>\n> (Olivier sent a draft of this to me for review, it looks good and will\n> probably be finished/announced soon.)\n\nYes, done.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13548027"}, {"subject": "Re: Update checklink on 8001", "content": "On Feb 18, 2004, at 06:20, Ville Skytt? wrote:\n> Ok, done.  :8001 is now running the latest and greatest checklink from\n> the validator-0_6_0-branch.\n\nJust a thought... Since one of the major changes, de facto, will be the \nfact that we'll distribute checklink on its own, if there is no \ncritical bug report, we should prepare packages (after a few days of \nbeta?) for people to test local installation.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13555628"}, {"subject": "distribute checklink after this beta", "content": "On Feb 18, 2004, at 07:05, olivier Thereaux wrote:\n> Just a thought... Since one of the major changes, de facto, will be \n> the fact that we'll distribute checklink on its own, if there is no \n> critical bug report, we should prepare packages (after a few days of \n> beta?) for people to test local installation.\n\nApparently, from a message I received (too late) from Ville, it's not \nclear whether we decided to start distributing checklink on its own \nnow, or later when it's properly modularized/ CPAN'd.\n\nThoughs welcome on the matter.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13563410"}, {"subject": "Re: distribute checklink after this beta", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@w3.org> wrote:\n\n>Thoughs welcome on the matter.\n\n??Whatever Ville think best?? is the sum of my thoughts on this matter. :-)\n\nThe two should be better integrated on v.w3.org, and should make an effort to\nshare more code through modularization; but should definitely be decoupled in\nas far as the current interdependancy is artifical and arbitrary.\n\n- -- \n> ...publicity rights, moral rights, and rights against unfair competition...\nWell, you've got me there.   I have no idea what any of those have to do with\nSGML. Next you'll be claiming that running NSGMLS constitutes an unauthorized\npublic performance of SGML.                                  -- Richard Tobin\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQDOyNaPyPrIkdfXsEQLxqwCfQK5QQpOKZtBmbB5bnWyZ4HJSELAAoPEz\n6IhYQLQxD5p445UKID+hkvc8\n=ezlt\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13571104"}, {"subject": "Re: distribute checklink after this beta", "content": "On Wed, 2004-02-18 at 20:43, Terje Bless wrote:\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA1\n> \n> olivier Thereaux <ot@w3.org> wrote:\n> \n> >Thoughs welcome on the matter.\n> \n> ?Whatever Ville think best? is the sum of my thoughts on this matter. :-)\n\nWell, I had the impression that the packaging separation would happen\nafter this release, but now I am comfortably leaning towards making it\nhappen already for this version :)\n\nSo, a TODO list follows:\n\nCPAN distribution name:  Currently the perl packages inside the script\nare W3C::UserAgent and W3C::CheckLink::*, but I think W3C-LinkChecker\nwould be good so it is similar to W3C::Validator (which doesn't exist\nyet :) and W3C::LogValidator.  checklink is IMO fine as the script name,\nbut perhaps change to W3C::LinkChecker::* hierarchy when modularizing\n(for the link checker specific parts).\n\nCPAN distribution dir:  I am fine with using my CPAN dir (account SCOP)\nor something else.\n\nWhen agreed on the CPAN distribution name and location, CPAN namespace\nregistration.  If you agree on W3C-LinkChecker and my account, just let\nme know and I can take care of the \"paper\"work.\n\nCVS organization:  a CPAN-like distribution layout would be good. \nShould there be a new top-level directory on dev.w3.org, or a subdir\nunder eg perl/modules/W3C/LinkChecker/ for consistency with\nLogValidator? \n\nOther stuff which I'll take care of: $VERSION when/if moving the script\nto a new location under CVS, documentation updates.\n\n\n\n", "id": "lists-017-13579684"}, {"subject": "Re: distribute checklink after this beta", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>CPAN distribution name:  Currently the perl packages inside the script\n>are W3C::UserAgent and W3C::CheckLink::*, but I think W3C-LinkChecker\n>would be good so it is similar to W3C::Validator (which doesn't exist\n>yet :) and W3C::LogValidator. [???]\n\nAgreed. W3C::LinkChecker is good.\n\n\n>CPAN distribution dir:  I am fine with using my CPAN dir (account SCOP)\n>or something else.\n\nCPAN dir can change as needed (e.g. Perl itself follows the current Pumpking);\nusing your dir makes sense since you're the one maintaining it.\n\n\n>CVS organization:  a CPAN-like distribution layout would be good. Should\n>there be a new top-level directory on dev.w3.org, or a subdir under eg\n>perl/modules/W3C/LinkChecker/ for consistency with LogValidator?\n\nI'm loath to implement too deep directory structures, but in this case I think\nit makes sense to keep it under $CVSROOT/perl/modules/W3C/LinkChecker/. Not\nthe least reason for which is that I foresee the modularized Markup Validator\nkeeping its modules there while the Markup Validator itself (i.e. check, the\nconfig files, etc.) live on in the ??validator?? module; at least until the\nmodularized code is stable, but possibly indefinitely.\n\nWe'd best define a CVS module for ??LinkChecker?? though, so we don't force\npeople to pull from seven subdirectories deep.\n\n\n\n- -- \n\"I don't mind being thought of as a badguy,\n but it /really/ annoys me to be thought of\n as an *incompetent* badguy!\" -- John Moreno\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQDPWrqPyPrIkdfXsEQLqnACgyIVN4GJ9uUJQbnFyLXSoDxGcSdMAnRv+\nGkNt11tIV6q3E3ex0nR6kZ2K\n=Uur6\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13588784"}, {"subject": "W3C validator image transparency test", "content": "Hi,\n\n  W3C validator image transparency tests\n\n  http://www.w3.org/2000/09/vsimg/transparency-test.html\n  http://lists.w3.org/Archives/Public/www-validator/2000JulSep/0185\n\nregards.\n\n\n\n", "id": "lists-017-13597995"}, {"subject": "SVG Badge", "content": "Hi,\n\n  Known history of SVG badges:\n\n  http://lists.w3.org/Archives/Public/www-svg/2000Sep/0070.html\n  http://lists.w3.org/Archives/Public/www-validator/2001Jul/0208.html\n  http://www.w3.org/mid/bg2ers$r6s$1@main.gmane.org\n\nStill no official badges... Most important are of course Valid SVG\nbadges to allow recursive conformance claims as in\n\n  Valid SVG 1.0!\n    Valid SVG 1.0!\n      Valid SVG 1.0!\n        Valid SVG 1.0!\n          Valid SVG 1.0!\n            Valid SVG 1.0!\n              Valid SVG 1.0!\n               ...\n\n\n\n", "id": "lists-017-13604622"}, {"subject": "Re: distribute checklink after this beta", "content": "On Wed, 2004-02-18 at 22:16, Ville Skytt? wrote:\n\n> So, a TODO list follows:\n\n...and the first test version of checklink as a CPAN distribution is\navailable for testing at http://koti.welho.com/vskytta/W3C-LinkChecker/\n\nKnown issues:\n- Some broken links :)\n- Documentation needs to be improved\n\nRegarding the release, I will be away from computers (vacation) for two\nweeks starting next Saturday (28 Feb).  I would like to proceed with the\nfollowing plan: fix the reported issues when I'm back, finish the\npackaging and CVS reorganization, and arrange a quick new testing\nsession for a couple of days using the packaged version running at\n:8001.\n\n\n\n", "id": "lists-017-13611481"}, {"subject": "Re: distribute checklink after this beta", "content": "On Wed, Feb 25, 2004, Ville Skytt? wrote:\n> Regarding the release, I will be away from computers (vacation) for two\n> weeks starting next Saturday (28 Feb).  I would like to proceed with the\n> following plan: fix the reported issues when I'm back, finish the\n> packaging and CVS reorganization, and arrange a quick new testing\n> session for a couple of days using the packaged version running at\n> :8001.\n\nThe plan sounds good. Enjoy your vacation.\n \n-- \nolivier\n\n\n\n", "id": "lists-017-13619346"}, {"subject": "Re: Bundles(Was: [check] install guide (draft)", "content": "Ville, all.\n\nOn Sat, Dec 27, 2003, Ville Skytt? wrote:\n> On Thu, 2003-12-25 at 11:40, Olivier Thereaux wrote:\n> \n> I think the CPAN dependencies-only approach works better for the\n> validator and checklink due to configuration issues and the need for\n> external binaries which obviously cannot be handled by CPAN.  More info\n> about Bundle modules is at\n> http://www.cpan.org/misc/cpan-faq.html#How_make_bundle\n\nI remembered having a look at bundles a while ago but did not remember\nin details, thanks a lot for the pointer to the documentation. \n\n> I rolled experimental, untested Bundles for both the validator and the\n> link checker, they're available at http://koti.welho.com/vskytta/\n\nExcellent!\n\n> If you wish, I can upload these to CPAN for testing.  If you think it'd\n> be better to use Olivier's CPAN account for all validator related perl\n> modules there (ie. currently the same location as the LogValidator\n> modules), that's very much fine with me too.\n\nNo clear preference. I created that CPAN account for qa-dev stuff\n(maybe, on second thought, I should have created it under a generic\nname, not mine) so this would be a good candidate, but I definitely\ndon't mind if you think it's more convenient for you to upload them with\nyour account.\n\n \n-- \nolivier\n\n\n\n", "id": "lists-017-13659456"}, {"subject": "Re: checklink credit", "content": "On Sat, Dec 13, 2003, Ville Skytt? wrote:\n> On Tue, 2003-12-09 at 03:51, Olivier Thereaux wrote:\n \n> Fine with me, but I'd appreciate not including my email address anywhere\n> online, as feedback and bug reports are better sent to the validator\n> list, and I receive enough spam already...\n\nSure, I agree with all of the above.\n\n \n> BTW, the CVS version of checklink contains an embedded manual page which\n> has a AUTHOR section, currently mentioning Hugo, Renaud, me, Fr?d?ric\n> and \"many other volunteers\".\n\nIndeed. Which does not preclude us from updating the credits in the HTML\ndocumentation.\n\n> \n> > Also, since the development of checklink and check are not necessarily\n> > going at the same pace, if you think we should (at least) put the latest\n> > version on :80 just ping the list (or me).\n> \n> I would appreciate that, as well as (of course) striving to get $TNV of\n> validator out as soon as possible.\n\nWhile we're at it... You wrote in another thread :\n\n> I think the CPAN dependencies-only approach works better for the\n> validator and checklink due to configuration issues and the need for\n> external binaries which obviously cannot be handled by CPAN. \n\nI think I misunderstood it at first, but my understanding of it, now, is\nthat unlike the validator (with its dependencies) checklink could be\ndistributed as a CPAN module and not just a bundle to take care of\ndependencies, right? (though I reckon that the config file might be an\nissue).\n\n\n> Reading the diffs between the current \"production\" version and the\n> latest checklink in validator-0_6_0-branch tells me that the upgrade\n> would require taking care of checklink.conf, by default in\n> /etc/w3c/checklink.conf.\n\nWon't be a problem.\n\n> But the current production version uses .w3.org as the \"trusted\" domain. \n> If you wish to preserve that, I'd suggest configuring 2 instances of\n> checklink, one without a config file for public use, and another for W3C\n> internal use, using a config file containing \"Trusted = \\.w3\\.org$\". \n> See the default config in htdocs/config/checklink.conf.\n\nI must confess partial ignorance of this trusted domain. I know from the\ncode that this trusted domain will be passed authentication information,\nbut I am still fuzzy on the details. The current prod version does seem\nto forward authentication to my private domain even though it is not at\nw3.org, so maybe I am missing the point.\n\nI remember a thread back in early 2003 about this parameter, and as far\nas I know there was no clear outcome.\n[searching archives]\n\nThere was no answer to my (probably clueless) suggestion at\nhttp://lists.w3.org/Archives/Public/public-qa-dev/2003Jan/0018.html\nso I gather it is not possible to set a trusted domain in the query\nstring (makes sense)... In such a case, I need to understand the details\nof how having a trusted domain is a problem for other domains, and how\nnot having one would be an issue for W3C internal use before having a\nclear opinion... I think it would be possible, though perhaps sensitive,\nto have a specific instance for internal (comma tool) use, though.\n\n> Testing in :8001 first could be a good idea :)\n\nAnytime... Though, if there are a lot of new things, I'd like\nto publicize the test and subsequent release a bit.\n\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13666969"}, {"subject": "Re: checklink credit", "content": "On Mon, 2004-01-05 at 04:22, Olivier Thereaux wrote:\n> On Sat, Dec 13, 2003, Ville Skytt? wrote:\n> \n> > BTW, the CVS version of checklink contains an embedded manual page which\n> > has a AUTHOR section, currently mentioning Hugo, Renaud, me, Fr?d?ric\n> > and \"many other volunteers\".\n> \n> Indeed. Which does not preclude us from updating the credits in the HTML\n> documentation.\n\nBut of course not, just pointing it out hoping that they'll be\nconsistently listed $whereverTheyAre.\n\n> > I think the CPAN dependencies-only approach works better for the\n> > validator and checklink due to configuration issues and the need for\n> > external binaries which obviously cannot be handled by CPAN. \n> \n> I think I misunderstood it at first, but my understanding of it, now, is\n> that unlike the validator (with its dependencies) checklink could be\n> distributed as a CPAN module and not just a bundle to take care of\n> dependencies, right?\n\nRight.  There has been some discussion about integrating the checklink\ndocs more closely with the validator's, but as of now it's self\ncontained IIRC.  I think that the CPAN \"full\" checklink distribution is\na good idea.\n\n>  (though I reckon that the config file might be an\n> issue).\n\nNot currently, as the config file is completely optional; without it\nsane defaults will be used.  See commentary in the BEGIN block of\nW3C::CheckLink.\n\n> I must confess partial ignorance of this trusted domain. I know from the\n> code that this trusted domain will be passed authentication information,\n> but I am still fuzzy on the details. The current prod version does seem\n> to forward authentication to my private domain even though it is not at\n> w3.org, so maybe I am missing the point.\n\nUnless configured otherwise, the basic authentication should only be\nsent to URLs on the same host which initially asked it (ie. in CGI mode,\nthe host of the initial URL given; in command line mode it does not have\nto be the initial URL because we can prompt for the info later).\n\nIf Trusted is set, basic auth info will be forwarded *only* to URIs\nmatching that regexp.  Note that this means that if the first requested\nlink to be checked does not match, it will not receive the auth info\neither -> no link checking.  This is a somewhat draconian approach\nthough, admitted.\n\nNote also that since 1.3.$something, Apache needs to be built with\n-DSECURITY_HOLE_PASS_AUTHORIZATION or checklink will need to be running\nunder mod_perl, otherwise the basic auth forwarding trickery will not\nwork at all.  More info:\nhttp://httpd.apache.org/dev/apidoc/apidoc_SECURITY_HOLE_PASS_AUTHORIZATION.html\nI don't know why v.w.o does not seem to be affected, in theory I believe\nbasic auth forwarding for validator and checklink should not work at all\nthere at the moment.\n\n(The validator is bitten by this too, BTW, and the mod_perl workaround\nhas not been implemented in it at the moment.  And yes, this should be\ndocumented somewhere ;)\n\n> There was no answer to my (probably clueless) suggestion at\n> http://lists.w3.org/Archives/Public/public-qa-dev/2003Jan/0018.html\n> so I gather it is not possible to set a trusted domain in the query\n> string (makes sense)...\n\nYep, not currently possible.  I do think that the value needs to be a\nregular expression to be powerful enough, but on the other hand letting\nend users specify (== override the sysadmin's setting) it at least needs\nsome thought.\n\n>  In such a case, I need to understand the details\n> of how having a trusted domain is a problem for other domains, and how\n> not having one would be an issue for W3C internal use before having a\n> clear opinion... I think it would be possible, though perhaps sensitive,\n> to have a specific instance for internal (comma tool) use, though.\n\nIn addition to the above, I believe W3C users typically want the\nauthorization information sent to the whole .w3.org domain, that's at\nleast what the old hardcoded default was.  Now, if checklink is\nconfigured to send it only to .w3.org, such a service would not be too\nuseful for non-W3C folks wrt basic authentication forwarding.\n\n\n\n", "id": "lists-017-13677037"}, {"subject": "Re: checklink credit", "content": "Le mar 06/01/2004 ? 01:16, Ville Skytt? a ?crit :\n> Note also that since 1.3.$something, Apache needs to be built with\n> -DSECURITY_HOLE_PASS_AUTHORIZATION or checklink will need to be running\n> under mod_perl, otherwise the basic auth forwarding trickery will not\n> work at all.  More info:\n> http://httpd.apache.org/dev/apidoc/apidoc_SECURITY_HOLE_PASS_AUTHORIZATION.html\n> I don't know why v.w.o does not seem to be affected, in theory I believe\n> basic auth forwarding for validator and checklink should not work at all\n> there at the moment.\n\nWe're using a trick to work around this security setting; it's the same\ntrick as the one detailed e.g. in\nhttp://mail.zope.org/pipermail/zope/2001-April/088252.html\n\nDom\n\n\n\n\n", "id": "lists-017-13688294"}, {"subject": "Re: checklink credit", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nDominique Haza??l-Massieux <dom@w3.org> wrote:\n\n>Le mar 06/01/2004 ?? 01:16, Ville Skytt?? a ??crit :\n>>Note also that since 1.3.$something, Apache needs to be built with\n>>-DSECURITY_HOLE_PASS_AUTHORIZATION or checklink will need to be running\n>>under mod_perl, otherwise the basic auth forwarding trickery will not\n>>work at all.  More info:\n>>http://httpd.apache.org/dev/apidoc/\n>>apidoc_SECURITY_HOLE_PASS_AUTHORIZATION.html I don't know why v.w.o\n>>does not seem to be affected, in theory I believe basic auth forwarding\n>>for validator and checklink should not work at all there at the moment.\n>\n>We're using a trick to work around this security setting; it's the same\n>trick as the one detailed e.g. in\n>http://mail.zope.org/pipermail/zope/2001-April/088252.html\n\nWhich is why I'm inclined to ditch this behaviour alltogether, in favour of\nrequiring Apache+mod_perl for the CGI version. Then again, I don't make use of\nthe auth-proxy feature so I'm kinda ignoring the issue for now.\n\nA requirement for a recompiled (with insecure settings no less) Apache is not\nacceptable; except this is for an add-on feature and not basic functionality.\n\n\nI know Gerald wanted it to behave this way ?????I asked once earlier about\nditching this ??? but I think the main issue is satisfying the underlying needs\n(i.e. easy auth for w3.org protected pages) so an alternate approach would\nprobably do.\n\nSince this is a common need for both the Validator and the Link Checker, and a\nwell contained piece of code, this might be a perfect opportunity to begin the\nmodularization and sharing code between the two. W3C::MarkUp::Util::AuthProxy?\n\n\nOpinions?\n\n\n\n- -- \nThese are the same customers you are referring to whom Microsoft thought\nwould need MS Bob and the Talking Paperclip?   One thing is to give them\nenough rope to hang themselves,  but a boobytrapped thermonuclear weapon\nrunning on a rand(time) countdown... Is that really wise? - Me to MS rep.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBP/qr6qPyPrIkdfXsEQKUHQCdFCTcLDUlaa+qed0siAiHJieQO9cAn1d+\nlRCihfvMrmrVA2AA6HJb3ppu\n=jmhA\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13696250"}, {"subject": "Re: checklink credit", "content": "On Tue, 2004-01-06 at 14:36, Terje Bless wrote:\n\n> Which is why I'm inclined to ditch this behaviour alltogether, in\n> favour of requiring Apache+mod_perl for the CGI version.\n\nI would not mind an Apache+mod_perl prerequisite for the validator or\nchecklink, even though this particular \"feature\" is perhaps not that\nsevere so it would absolutely require such a change.  Checklink still\nneeds quite a bit of work to allow it to be clearly run under mod_perl\nthough.  It \"works\" now, but trashes the error logs with lots of\nwarnings.  And I have never implemented anything that would be run\neither under mod_perl or from the command line... I don't see why it\nwouldn't be doable though.\n\n> A requirement for a recompiled (with insecure settings no less) Apache is not\n> acceptable; except this is for an add-on feature and not basic functionality.\n\nAgreed.  But documenting the workaround(s) for enabling this feature,\nie. either using the mod_rewrite tricks or enabling mod_perl would be ok\nIMO.  I'll see what I can do...\n\n> Since this is a common need for both the Validator and the Link Checker, and a\n> well contained piece of code, this might be a perfect opportunity to begin the\n> modularization and sharing code between the two. W3C::MarkUp::Util::AuthProxy?\n\nGenerally I'm all for modularization/reuse, but at the moment I think we\nshould really focus on getting the current beta validator and the\nchecklink from that branch in production before starting to tear either\nof them apart in any way.\n\n\n\n", "id": "lists-017-13706567"}, {"subject": "Re: checklink credit", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>Generally I'm all for modularization/reuse, but at the moment I think we\n>should really focus on getting the current beta validator and the\n>checklink from that branch in production before starting to tear either\n>of them apart in any way.\n\nRight. And I'm not writing any code these days so I'm not proposing this for\nimmediate implementation unless someone else wants to take it on. But this\nlooked like a good place to start when we eventually get to that point, and it\nwouldn't hurt to keep that in mind while doing other stuff in the code.\n\nIt's just been a while since I looked at that code ??? as I mentioned, it was\nwhile Gerald was still actively involved ??? so I'm not sure my asessment of the\nfeasability is correct.\n\n- -- \n\"Temper Temper! Mr. Dre? Mr. NWA? Mr. AK, comin??\n straight outta Compton and y'all better make way?\"            -- eminem\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBP/31mqPyPrIkdfXsEQI0KwCfQqOXPHlf+lT0AuTy+v8YowVKts8AnRRS\nbcGQfD0QmyCPC7MHeGlJWvDy\n=CI+j\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13714834"}, {"subject": "regular meeting  tentative schedul", "content": "Hi folks,\n\nsorry for being so long in coming back to you with a proposed schedule.\n\nApparently, everyone seems to be happy with a regular IRC meeting with \na specific agenda (as opposed to the usual chat on freenode:#val), and \n\"during the day\" (CET) seemed to be the preferred option (my apologies \nif I forgot someone said \"during the day is a no-no\").\n\nSo what about \"first tuesday of the month\" 2PM Central European Time\n(with the current winter time that'd be 10PM Tokyo / 8AM Montreal)?\n\nActually, there will be no \"first tuesday\" before almost a month, but \nif we agree rapidly we can have a first meeting next tuesday - I have \nagenda items ready if we do.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13722851"}, {"subject": "Re: regular meeting  tentative schedul", "content": "On Fri, 9 Jan 2004, olivier Thereaux wrote:\n\n> Apparently, everyone seems to be happy with a regular IRC meeting with\n> a specific agenda (as opposed to the usual chat on freenode:#val), and\n> \"during the day\" (CET) seemed to be the preferred option (my apologies\n> if I forgot someone said \"during the day is a no-no\").\n>\n> So what about \"first tuesday of the month\" 2PM Central European Time\n> (with the current winter time that'd be 10PM Tokyo / 8AM Montreal)?\n\nThat's fine with me.\n\n> Actually, there will be no \"first tuesday\" before almost a month, but\n> if we agree rapidly we can have a first meeting next tuesday - I have\n> agenda items ready if we do.\n\nWe've been talking CSS parsing over the last couple of days; that\nshould be agenda-ised.\n\nMore blue-skies: (optional) extra validation checks, such as\nwhether attribute values are valid.  I have some thoughts;\nnot sure how they'll work.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-13730627"}, {"subject": "Re: regular meeting  tentative schedul", "content": "Le ven 09/01/2004 ? 03:44, olivier Thereaux a ?crit :\n> So what about \"first tuesday of the month\" 2PM Central European Time\n> (with the current winter time that'd be 10PM Tokyo / 8AM Montreal)?\n\nWorks for me.\n\n> Actually, there will be no \"first tuesday\" before almost a month, but \n> if we agree rapidly we can have a first meeting next tuesday - I have \n> agenda items ready if we do.\n\nI'm available then. Thanks for setting this up!\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n", "id": "lists-017-13739218"}, {"subject": "Re: regular meeting  tentative schedule (+agenda", "content": "On Jan 9, 2004, at 13:03, Nick Kew wrote:\n> On Fri, 9 Jan 2004, olivier Thereaux wrote:\n>> So what about \"first tuesday of the month\" 2PM Central European Time\n>> (with the current winter time that'd be 10PM Tokyo / 8AM Montreal)?\n>\n> That's fine with me.\n\nGood.\nReading my IRC backlog I noticed that it wasn't best for nighttime \nfolks... True. I suggested, however, early afternoon (and not morning) \neurope time for that purpose, though not too late so that it wouldn't \nbe too much of a pain for me (JST). If it's really a problem, we can \ntalk, though :)\n\n> We've been talking CSS parsing over the last couple of days; that\n> should be agenda-ised.\n\nYes, was on my list, along with \"current progress\" and modularization, \nalthough I think at least the latter can be discussed on the list for a \nwhile since there is no urgency - and other more urgent things.\n>\n> More blue-skies: (optional) extra validation checks, such as\n> whether attribute values are valid.  I have some thoughts;\n> not sure how they'll work.\n\nKarl has on his someday pile to look at all the cases in the HTML spec \nthat are not covered by DTD validation, so that's indeed a topic worth \ndiscussing - extending \"fussy\" parsing.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13747281"}, {"subject": "[meeting] 2004-0113 &#64; 14:00 CE", "content": "On Jan 9, 2004, at 11:44, olivier Thereaux wrote:\n> Actually, there will be no \"first tuesday\" before almost a month, but \n> if we agree rapidly we can have a first meeting next tuesday - I have \n> agenda items ready if we do.\n\nNot many answers to this proposal so far, but no negative answer at \nall, so we will try to meet on IRC (usual channel, freenode#validator) \n2004-01-13 14:00CET.\n\nThe meeting will last one hour (only for this time, since the QA Team \nhas another meeting after that... next times we may double this if we \nfeel it's needed). Be there on time.\n\nProposed Agenda:\n- check / checklink release calendar [35 min]\n(and \"should we organize separate test/release/etc)\n- CSS parsing [25 min]\npreliminary discussion on what all of us have been/are/will be working \non in this area.\n\nNote: I though Yves and Philippe were subscribed, they were not... I \ninvited them directly, and hope they can join us at least for the \nsecond part.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13756568"}, {"subject": "Re: [meeting] 2004-0113 &#64; 14:00 CE", "content": "On Tue, 2004-01-13 at 05:38, olivier Thereaux wrote:\n\n> Not many answers to this proposal so far, but no negative answer at \n> all, so we will try to meet on IRC (usual channel, freenode#validator) \n> 2004-01-13 14:00CET.\n\nD'oh, I guess I missed this.  Any memos/ public IRC logs available?\n\n\n\n", "id": "lists-017-13764897"}, {"subject": "[meeting] notes and log for 2004-011", "content": "Here are my notes from the meeting (summary). Hopefully accurate.\nI am including a list of what I think are all the action items at the \nbottom, and attaching the IRC log.\n\nAttendees: Yves, Bjoern, Philippe, Nick, Terje, olivier\nNext meeting: Tuesday, Feb 3rd, 2004 (2PM CET)\n(should schedule for 1h30 / 2h next time)\n\n\n\n* CSS parsing / validation and validators itegration *\n\nNick is working on a CSS analysis tool doing both validation and \nwarning for accessibility issues.\nPlans to integrate it with Valet, possibility to also integrate with \nMarkup Validator (fetch and validate stylesheets) That would, however, \nimply that the Markup Validator would need to be able to check \nattributes\n\nBest candidate parser is libcroco, though it has limitations.\n\nThe idea of integration shifted the discussion to more general topics \non how to achieve it:\n  - comparing how different validators (CSS, Markup, mod_validator) work \nand which parser they use.\n  - Quickly exploring the idea of CSS validation through schema based \nvalidation (i.e using similar mechanisms as markup validation), which \nis something Bjoern is working on.\n  - discussing online integration through WS paradigms (soap/1.2 \ninterface)\n\n\n* Markup Validator - release plan *\n\nThe plan was to address all issues raised and integrating the submitted \nerror messages before moving forward with a new beta of the Markup \nValidator. Terje being really busy, this plan goes against the wish to \nroll in a new beta fairly soon (and to move usability/documentation \nimprovements to :80 ASAP). If we want to do that, we may have to leave \ncontroversial code (e.g fussy parsing) aside and focus on major issues \nfor a minor release.\n\nDecisions made in order to move forward:\n- Need to integrate error messages (olivier)\n- We may have to officially postpone addressing some (of Bjoern's) \nraised issues and plan a later release\n- Bjoern will have a look at current state - feel free to commit code\n- Need to test current :8001 and branch (olivier - Bjoern can help)\n- Need to move qa-dev to Debian testing and 2.6 kernel (olivier with \nhelp from Yves/Daigo)\n\n\n* Summary of action items *\n\nAI: Bjoern -  write a specification for css schema by end of january\nAI: ?? - contact libcroco maintainers to see what we/they can do to \nimplement the features we need\nAI: Nick - investigate Apache2+modperl, play with :8001;\nAI: Nick - work/experiment on CSS parse\nAI: olivier - review and integrate submitted error messages\nAI: olivier (+Bjoern) - test current :8001 and branch\nAI: olivier (+Yves, +Daigo?) - move qa-dev to Debian testing and 2.6 \nkernel\n\nAttached is the public IRC log.\n\nThank you.\n-- \nolivier\n\n\n\n\n\n\n\n\n\n\napplication/text attachment: qadev-20040113.log\n\n\n\n\n", "id": "lists-017-13772284"}, {"subject": "RE: convert to punycode: SHOULD or MAY (was: RE: Are IDNs   allowed in http IRIs?", "content": "It's now a week since I tentatively closed issue\nhttp://www.w3.org/International/iri-edit/#punycodeSHOULD-23.\nI haven't heard about any problem, so I'm closing this issue.\n\nRegards,  Martin.\n\nAt 13:17 04/04/27 +0900, Martin Duerst wrote:\n\n>Hello Larry,\n>\n>At 03:07 04/03/30 -0800, Larry Masinter wrote:\n>\n>>I think this is an interoperability issue, and that neither SHOULD nor MAY\n>>are appropriate. Rather, there is a MUST with a couple of alternatives.\n>>Implementations\n>>resolving an IRI with non-ascii host names MUST use one of the established\n>>methods of resolving the host name correctly.\n>\n>I think this is a very valid point. However, I think that this is\n>overall covered by the current spec. The spec has an overall MUST\n>for the general conversion procedure:\n>\n>\"Applications MUST map IRIs to URIs using the following two steps.\"\n>\n>It then allows (MAY) an additional step in certain well-defined cases:\n>\n>\"Infrastructure accepting IRIs MAY convert the ireg-name\n>component of an IRI as follows (before step 2 above) for schemes\n>that are known to use domain names in ireg-name, but where the\n>scheme definition does not allow %-escaping for ireg-name:\"\n>\n>Finally, it recommends that the above additional step be taken\n>under certain conditions:\n>\n>\"This conversion SHOULD be used when the goal is to\n>maximize interoperability with legacy URI resolvers.\"\n>\n>So it seems to me that this is covered. Of course, there is\n>always the question of whether other things, not discussed in\n>the spec, are allowed or not, but I think it is a general\n>principle when writing IETF specs to not include generalities\n>such as \"Any other method than those discussed in this\n>document MUST NOT be used.\"\n>\n>\n>I hope this reply sufficiently addresses this issue\n>(punycodeSHOULD-23). I have noted this as tentatively closed.\n>\n>\n>Regards,     Martin.\n\n\n\n", "id": "lists-017-1377673"}, {"subject": "Re: [meeting] 2004-0113 &#64; 14:00 CE", "content": "Ville,\n\nOn Jan 14, 2004, at 4:29, Ville Skytt? wrote:\n> D'oh, I guess I missed this.\n\nYes, I guess that was a bit of a short notice, sorry about that.\nWill you be available monthly (starting Feb 3rd) or is the schedule not \ngood for you?\n\n>   Any memos/ public IRC logs available?\n\nJust sent notes and log to the list.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13782287"}, {"subject": "Re: Problem with SSI in Beta versio", "content": "On Sun, 2004-01-18 at 14:29, Nicolas Roeser wrote:\n\n> the Extended File Upload Interface of the beta version of the Validator \n> does not include the file 'doctype-select.html' correctly.\n> \n> In <URL:http://validator.w3.org:8001/file-upload.html>, line 126 reads:\n> <!--#include virtual=\"doctype-select.html\" -->\n\nFYI: /home/link/validator/htdocs/detailed-form.html was not executable,\nthat's why.  To avoid this in the future, maybe:\n\nSomeone with shell access to the CVS repository, do a \"chmod +x\ndetailed-form.html,v\".\n\nor IMHO maybe slightly better:\n\nGet rid of the somewhat fragile XBitHack configuration altogether, do an\n\"AddHandler server-parsed .html\" instead for the validator configs, see\nhttpd/conf/httpd.conf in CVS for an example.\n\n\n\n", "id": "lists-017-13789911"}, {"subject": "Re: Problem with SSI in Beta versio", "content": "On Jan 19, 2004, at 03:15, Ville Skytt? wrote:\n> or IMHO maybe slightly better:\n>\n> Get rid of the somewhat fragile XBitHack configuration altogether, do \n> an\n> \"AddHandler server-parsed .html\" instead for the validator configs, see\n> httpd/conf/httpd.conf in CVS for an example.\n\nAny idea which is best for caching? I thought XBitHack Full was the \nbest config for that, but I may be wrong.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13797529"}, {"subject": "Re: Problem with SSI in Beta versio", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@w3.org> wrote:\n\n>Any idea which is best for caching? I thought XBitHack Full was the best\n>config for that, but I may be wrong.\n\nXBitHack is intended to preserve cacheability, yes. But we can probably\ncombine it with AddHandler unless Apache is designed to let one kill the\nother. Anyone know?\n\n- -- \nWhen I decide that the situation is unacceptable for me, I'll simply fork\nthe tree.   I do _not_ appreciate being enlisted into anyone's holy wars,\nso unless you _really_ want to go _way_ up in my  personal shitlist don't\nplay politics in my vicinity.                   -- Alexander Viro on lkml\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQAr+/qPyPrIkdfXsEQL8BwCeLcuk7ONmyt+YHg+DAoCsN216v8UAnRMX\nj3b7QecpAlBlGNcGIf+3x7xO\n=mecu\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13805388"}, {"subject": "Re: Problem with SSI in Beta versio", "content": "On Sun, 2004-01-18 at 23:47, Terje Bless wrote:\n\n> >Any idea which is best for caching? I thought XBitHack Full was the best\n> >config for that, but I may be wrong.\n> \n> XBitHack is intended to preserve cacheability, yes.\n\nUhh, XBitHack is even more a hack than I imagined.  Never bothered to\nRTFM on it before now.\n\n>  But we can probably\n> combine it with AddHandler unless Apache is designed to let one kill the\n> other. Anyone know?\n\nDunno.  Maybe it's best just to stick with the current config and do the\nchmod in the CVS repo after all.\n\n\n\n", "id": "lists-017-13813847"}, {"subject": "Re: Problem with SSI in Beta versio", "content": "On Jan 19, 2004, at 7:08, Ville Skytt? wrote:\n> On Sun, 2004-01-18 at 23:47, Terje Bless wrote:\n>\n> Dunno.  Maybe it's best just to stick with the current config and do \n> the\n> chmod in the CVS repo after all.\n\n(done, which should not stop us from discussing this any further).\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13821471"}, {"subject": "qadev server now sports 2.6 kerne", "content": "On Jan 14, 2004, at 10:37, olivier Thereaux wrote:\n> AI: olivier (+Yves, +Daigo?) - move qa-dev to Debian testing and 2.6 \n> kernel\n\nThe 2.6 kernel was successfully installed on qa-dev by our local Server \nguru, Daigo Matsubara (Thanks a lot!).\n\nAlso, regarding the debian distribution on this machine, I remember \nthinking during the meeting that the distribution was actually, or had \nbeen, \"testing\". I was wrong, it is (and probably has been for quite a \nwhile) \"unstable\", which should work fine for experiment purposes.\n\nPlease contact me if you need anything else.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13828734"}, {"subject": "Verbose error message", "content": "Hi,\n\nJust before I start breaking everything (also known as populating our \ndatabase of error messages with what was contributed so far), is there \nanything I should know about it?\n\nThe syntax of the verbosemsg.cfg is straightforward, but I'm a bit \npuzzled by verbosemsg.rc.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13835955"}, {"subject": "Re: Verbose error message", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@w3.org> wrote:\n\n>The syntax of the verbosemsg.cfg is straightforward, but I'm a bit\n>puzzled by verbosemsg.rc.\n\n??verbosemsg.rc?? is a local copy of OpenSP's ??ParserMessages.rc??; the one used\nto generate the skeleton ??verbosemsg.cfg?? in use. You can safely ignore it for\nnow.\n\n- -- \n> ...publicity rights, moral rights, and rights against unfair competition...\nWell, you've got me there.   I have no idea what any of those have to do with\nSGML. Next you'll be claiming that running NSGMLS constitutes an unauthorized\npublic performance of SGML.                                  -- Richard Tobin\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQA455qPyPrIkdfXsEQLcBACg21PJt4Dx1WCOUs8MyS+MgwiM1m8An2AL\n/f+zN5IP0wiGe2lKotu8IiOy\n=UikJ\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-13843156"}, {"subject": "Re: Bugrepor", "content": "On Jan 27, 2004, at 1:05, David Dorward wrote:\n> Nothing wrong with the validator here, it just knows HTML better then \n> you do.\n\nHa!\nI definitely could quote that as a tag line for the validator's FAQ.\n\ncheers,\n-- \nolivier\n\n\n\n", "id": "lists-017-13851243"}, {"subject": "[meeting] scheduling 2004-020", "content": "Hello everyone,\n\nWe'll be having a qa-dev IRC meeting next tuesday.\n\nNotes from last time are at:\nhttp://lists.w3.org/Archives/Public/public-qa-dev/2004Jan/0013.html\n\nVille told me that (even though in general mail worked best for him) \nthe only possible times would be 18-24 EET, that is 17-23CET if I'm not \nmistaken. I guess that may also be best for the night folks among us.\n\nWould it thus be possible to hold a quick poll for tuesday's meeting?\nPlease send me a mail stating your preference:\n- 14:00 CET (15:00 EET, 08:00 Boston/Montreal)\n- 17:00 CET (18:00 EET, 11:00 Boston/Montreal)\n\nthanks\n-- \nolivier\n\n\n\n", "id": "lists-017-13857882"}, {"subject": "Re: uri handling of hosts is too restrictiv", "content": "It's now a week since I tentatively closed issue\nhttp://www.w3.org/International/iri-edit/#idnuri-02.\nI haven't heard about any problem, so I'm closing this issue.\n\nRegards,     Martin.\n\nAt 15:21 04/04/27 +0900, Martin Duerst wrote:\n\n>Hello Adam,\n>\n>This is all related to issue idnuri-02\n>(http://www.w3.org/International/iri-edit/#idnuri-02).\n>I have tentatively closed this issue.\n>\n>\n>At 20:01 04/02/19 +0000, Adam M. Costello BOGUS address, see signature wrote:\n>\n>>Martin Duerst <duerst@w3.org> wrote:\n>\n>> > And it's not really IRIs that should need percent-encoding, although\n>> > you need it in some cases, if characters are not encoded as UTF-8 in\n>> > the corresponding URI.\n>>\n>>Percent-encoding could also be useful for displaying an IRI when\n>>the local charset is not Unicode, or when the available fonts are\n>>insufficient.  If an IRI contains many non-ASCII characters that are\n>>displayable, plus one character that's not displayable, it might be\n>>nice to use percent-encoding only for the oddball and display the\n>>rest intelligibly, rather than convert the entire IRI to a URI.  If\n>>that displayed IRI is cut & pasted or manually retyped into another\n>>application, it should be handled properly.\n>\n>This is currently allowed by the IRI spec. In practice, however,\n>there may be other ways to display non-displayable characters,\n>and cut-and-paste is usually able to copy even non-displayable\n>characters.\n>\n>\n>>If an individual scheme restricts a component to contain only ASCII\n>>characters, then scheme-specific IRI consumers would be required\n>>to check the component before using it, and fail gracefully if any\n>>non-ASCII characters are found.\n>>\n>>That's much simpler, requiring only one bit of knowledge about the\n>>syntax of the component (whether it allows non-ASCII).\n>\n>Well, yes, but what exactly is a \"scheme-specific IRI consumer\"?\n>In the implementation I know, there is no such thing. IRIs get\n>converted to %HH, then the scheme-specific logic takes this apart,\n>then for some schemes, DNS resolution is called, which knows\n>about %HH and IDNs and does the right thing. What is such an\n>implementation supposed to do? Why should the spec give requirements\n>about things that don't exist in implementations?\n>\n>\n>> > What do you mean by 'fail gracefully'?\n>>\n>>If the component is supposed to be a Foo, and a Foo is supposed to be\n>>ASCII, and the component contains non-ASCII, then you must not use\n>>the component as a Foo (whatever that means).  If you were about to\n>>do something that entailed using the component as a Foo (for example,\n>>passing it to something that takes a Foo as an argument), then you\n>>must abort the attempt, and the error is something like \"invalid Foo\n>>(non-ASCII)\".\n>\n>This just sounds to me like two very general principles:\n>- defensive programming\n>- good error messages\n>\n>I don't see a particular point in mentioning these in the IRI spec,\n>because they are also not mentioned in other IETF specs. Nor do\n>I see any good reason for mentioning them for one particular point\n>in the IRI spec, because they should apply to all of the spec.\n>\n>\n>> > And why would that have to be checked before use?  Why could it not\n>> > simply be the result of actual use?\n>>\n>>Because the original Foo spec might be old (even if the IRI scheme\n>>containing a Foo component is more recent), and might have its own\n>>installed base of stuff that does not behave interoperably when\n>>presented with a non-ASCII Foo, and therefore it might have needed to\n>>introduce a client-side downgrading operation in order to safely extend\n>>the syntax.  If the IRI consumer blindly tries to use the Foo component\n>>as a Foo without performing the downgrading operation, the result will\n>>be unpredictable.\n>\n>Yes. We have a sloppy spec/implementation on the one hand, and\n>somebody sending stuff they are not supposed to send on the\n>other hand. Not surprising that it doesn't work.\n>\n>\n>>Maybe there will be a misleading error message like\n>>\"Foo xyz not found\" even though xyz actually exists,\n>\n>That's always a possibility for URIs and IRIs. Not all schemes may\n>be known, and the network isn't perfect,...\n>\n>\n>>or maybe the\n>>mangled request will map onto some other Foo by coincidence or malice.\n>\n>If you think this needs to be documented as a security issue,\n>please say so (please propose some wording).\n>\n>\n>>Ideally, the Foo spec should have specified what to do whenever you\n>>encounter a syntactically invalid Foo, so that Foo implementations bear\n>>full responsibility for interoperability as the Foo syntax is extended,\n>>and nothing about the Foo syntax need be known at the IRI-processing\n>>layer.  But there is one kind of syntax extension where neglect has\n>>been the rule rather than the exception: the extension from ASCII to\n>>non-ASCII.  Because it has been so common for protocols to assume ASCII\n>>without saying enough about how to react to non-ASCII, and because\n>>the ASCII-to-non-ASCII transition is the same one being made by the\n>>introduction of IRIs, and because IRIs are uniquely positioned as a\n>>narrow interface between a wide range of protocols and a wide range of\n>>applications (sort of like IP is a narrow interface between a wide range\n>>of networks and a wide range of applications), IRIs are a good place to\n>>interpose a simple type-safety check.\n>\n>Well, IRIs are defined as generic. Because the checks needed are\n>specific to different protocols,..., I don't think that such\n>checks belong into a generic spec. If a spec needs fixing, it\n>should be fixed. Using another, vaguely related spec to try\n>and fix the first spec is probably a bad idea.\n>\n>\n>> > > (That would prevent IRIs from suffering some of the problems we are\n>> > > now seeing with URIs.  In URIs, percent-encoding was prohibited\n>> > > in the host component, and non-ASCII was prohibited in the host\n>> > > component, and there was no requirement telling URI consumers\n>> > > what to do if they should find either of those things in the host\n>> > > component, so now we have different implementations behaving\n>> > > differently when they encounter such things.)\n>> >\n>> > Well, yes.  But that's just a result of how things are implemented,\n>> > not a problem in the specification, I guess.\n>>\n>>I think it's a problem in the specification.  I think we've learned the\n>>hard way that specs need to say what to do when you encounter unexpected\n>>syntax, otherwise it's difficult to ever extend the syntax.\n>\n>I agree. But I don't think the IRI spec is the right place to fix\n>all the other specs.\n>\n>\n>>RFC-2396 said the host component does not contain percent-escapes, but\n>>didn't say what to do if it did contain them, so some implementations\n>>decode the escapes, and some don't, and neither group is wrong.\n>\n>And RFC 2396bis fixes that.\n>\n>\n>> > We already made an exception for domain names.  I don't want to make\n>> > any other exceptions.  The goal is not a hodgepodge of scheme-specific\n>> > conventions, but to take advantage of the fact that many URI schemes\n>> > already are based on UTF-8, many others allow UTF-8 to be used (in\n>> > many parts at least) and UTF-8 is also the recommendation for new\n>> > schemes.\n>>\n>>I agree with those goals, but there is a distinct possibility that an\n>>ACE will be defined for email local parts, in which case IRI-to-URI\n>>converters with knowledge of mailto: will want to use the ACE for\n>>compatibility with existing mailto: resolvers.\n>\n>Yes, in the case such a possibility becomes reality, some converters\n>might do that, if they think that helps. They will do that whether or\n>not a spec tells them to. On the other hand, the mailto: URI scheme should\n>be updated to allow %HH (based on UTF-8) in the LHS, and to otherwise\n>be better internationalized.\n>\n>\n>>Maybe there are\n>>other ASCII-only components lurking in existing URI schemes facing\n>>backward-compatibility challenges similar to those of domain names, and\n>>maybe they will likewise find it necessary to use the ACE approach to\n>>internationalization.\n>\n>Do you know of any?\n>\n>\n>>The IRI spec would not need to mention any of the individual\n>>scheme-specific exceptions.  It mentions the IDN exception because ihost\n>>is a potential component of IRIs in general, and domain names are used\n>>in a great many schemes, but those reasons wouldn't apply to any other\n>>exceptional components (like email local parts).\n>\n>Okay.\n>\n>\n>> > > 2) If the verification failed, or if you didn't recognize the\n>> > > scheme, then perform the generic conversion to percent-encoded UTF-8\n>> > > as described in the IRI draft, and prepend the prefix i- to the\n>> > > scheme.\n>> >\n>> > Why should i- be prepended?\n>>\n>>Because URI processing does not include the ASCII-component-check\n>>(whereas IRI processing, being a new spec, could include the check).\n>>Blindly dumping non-ASCII characters (even percent-encoded ones) into\n>>a URI would bypass the check.  If the URI contains a component that\n>>used to be limited to ASCII, legacy implementations might behave in\n>>unpredictable ways when that component contains (percent-encoded)\n>>non-ASCII.\n>\n>I think there is a tradeoff. Introducing your i- pattern would\n>mean that the chance that any subsequent URI resolver actually\n>resolves that URI currently would be zero, and might stay very\n>close to zero for a very long time. As we know, introducing\n>a new URI scheme is very hard.\n>\n>The alternative is to not use the i-, meaning that already\n>in quite a few implementations, the URI in question can be\n>resolved, and this number will be increasing faster than in\n>the i- case, at the expense of an occasional unpredictability\n>(which in most cases is just a 'not found').\n>\n>For me, having things actually work, maybe with occasional\n>hickups, is clearly preferable to a theoretically safe\n>solution that doesn't work in practice.\n>\n>\n>>Basically, i-foo: means \"this identifier was blindly converted from a\n>>foo: IRI without foo-specific knowledge, so it does not necessarily\n>>conform to foo: URI syntax, but it does conform to generic URI syntax,\n>>and you can certainly recover the foo: IRI\".\n>\n>There are many other ways (e.g. by hand) to create foo: URIs that\n>don't conform to foo: URI syntax. The IRI draft clearly says that\n>you are not supposed to use non-ASCII characters where the scheme\n>can't handle it. Please see\n>http://www.w3.org/International/iri-edit/draft-duerst-iri.html#UTF8use\n>for actual text.\n>\n>\n>>Another answer to your question (\"Why should i- be prepended?\") is:  So\n>>that the IRI spec does not invite applications to violate the IDNA spec.\n>>The ireg-name component is an IDN-aware slot in schemes that use domain\n>>names there (because the IRI draft invites the usage of non-ASCII domain\n>>names there and cites IDNA).  The corresponding reg-name slot in the\n>>URI is IDN-unaware.  To convert a foo: IRI to a foo: URI, IDNA requires\n>>ToASCII to be applied.  But when the application doesn't know the\n>>scheme, the IRI draft invites the application to use percent-encoding\n>>instead, disregarding the IDNA requirement.\n>\n>Well, I think that IDNA tried very hard to predict all cases of\n>use of IDNs, and put down general rules that would apply for all\n>cases. But in general, such things are just impossible. reg-name\n>is a typical example: a slot that can contain both domain names\n>and other stuff. And URIs are a typical example: In RFC 2396,\n>this slot only allowed US-ASCIII. In RFC 2396bis, %HH is also\n>allowed. Implementations have evolved likewise.\n>\n>The IRI spec does the best it reasonably can to navigate in this\n>area. Requiring everything to be prefixed with -i, in practice\n>making things less working, just to nominally conform to IDNA,\n>doesn't seem to make sense.\n>\n>Not every application will know all relevant schemes, but the\n>number of current schemes using DNS in reg-name is not that large,\n>and any future schemes can be defined to allow %HH from the start.\n>So in practice, it is not too difficult for IRI implementations to\n>follow IDNA, and there is definitely nothing in the IRI spec\n>that says that implementations should disregards IDNA.\n>\n>\n>> > New schemes can be designed so that they fit together well with IRIs\n>> > (if the relevant BCP guidelines are used, that will be the case\n>> > automatically).\n>>\n>>The resolvers of those new schemes can simply strip off the i- prefix if\n>>they know that the generic IRI-to-URI conversion is sufficient for those\n>>schemes.  That could be mentioned in the IRI spec and in the guidelines\n>>for creating new schemes.\n>\n>Designing things so that the future gets more complicated, rather\n>than more straightforward, just to deal with some sloppy specs/\n>implementations, does not seem to be a good idea.\n>\n>\n>>By the way, I should insert a rule 0 in my proposed IRI-to-URI\n>>conversion:\n>>\n>>0) If the IRI contains no non-ASCII characters (not even percent-encoded\n>>ones) then stop; it's already a URI.\n>>\n>>(Without this rule, if the scheme was unknown, the only effect of the\n>>other rules would be to prepend the i- prefix, which would be protecting\n>>nothing.)\n>\n>Well, yes. And don't add a i- prefix if there already is one,\n>and make sure we reserve all scheme names starting with i-, and\n>a few other 'details'. Way too much hassle for what it's worth,\n>sorry.\n>\n>\n>Regards,     Martin.\n\n\n\n", "id": "lists-017-1387008"}, {"subject": "Re: mod_validato", "content": "* Nick Kew wrote:\n>OK, mod_validator is now running mostly-smoothly on qa-dev: any\n>serious differences to Page Valet are probably a reportable bug\n>(although they could also be due to more up-to-date libraries).\n\nSome feedback, I sometimes get\n\n  System Messages\n  Error 70007 in connect \n  Error accessing http://bjoern.hoehrmann.de - aborting. \n\nand if that works it complains\n\n  E: Line 2, char 50, cannot find \"html/valet.dtd\"; tried . \n\nThis seems to be a problem with -R (or it's C-equivalent). Hmm,\n\n? http://qa-dev.w3.org:8888/validator/validate.v?url=http%3A%2F%2Fbjoern.hoehrmann.de&parser=Xerces&parseMode=web&resultsMode=noerrors\n\ncalls me \"Bjrn Hhrmann\" several times... I am also not too fond of\nrefusing to process text/html documents with Xerces if that is what\nI request... hmm, e.g.\n\n? http://qa-dev.w3.org:8888/validator/validate.v?url=http%3A%2F%2Fwww.w3.org%2FStyle%2FCSS%2FTest%2FCSS3%2FSelectors%2F20040510%2Fxhtml%2Ftests%2Fcss3-modsel-134.xml&parser=Xerces&parseMode=web&resultsMode=noerrors\n\nit removes the namespace declarations, is this intentional? I am also\nnot sure whether stating\n\n  Content type suggests XML, but the document doesn't look like XML\n\nthere is such a good idea...\n\n? http://qa-dev.w3.org:8888/validator/validate.v?url=http%3A%2F%2Fwww.w3.org%2FStyle%2FCSS%2FTest%2FCSS3%2FSelectors%2F20040510%2Fxhtml%2Ftests%2Fcss3-modsel-134.xml&parser=Xerces&parseMode=web&resultsMode=traditional\n\nIt says\n\n  Parse Options Force=NO, Schema=NO, Namespace=NO \n\nand then\n\n  Result Not well-formed \n  ...\n? 1. fatal: Line 21, char 65, The prefix 'a' has not been mapped to any URI. \n? 2. fatal: Line 22, char 62, The prefix 'a' has not been mapped to any URI. \n? 3. fatal: Line 23, char 62, The prefix 'b' has not been mapped to any URI. \n? 4. fatal: Line 24, char 59, The prefix 'b' has not been mapped to any URI. \n\nwhich are namespace errors, the document *is* well-formed without\nnamespace processing!?\n\n\n\n", "id": "lists-017-13898484"}, {"subject": "specific list / feedback mails / timeframe issu", "content": "Based on some (strong) suggestion from Bjoern (IIRC), I \"sampled\" a few \npeople, all active w-v participants, whether creating a list to discuss \nand provide help on validation problems would be a good idea. The \ncurrent w-v charter does not include such messages, but the come in \nanyway, especially since the \"send feedback\" links were added to the \nprod version.\n\nThe reasons were varied, but everyone I consulted was in favor to the \ncreation of such a list.\nWhile not convinced at first, I now agree to give it a go... And unless \nsomeone objects, I plan to create it on monday.\n\nAnother (related) issue is the \"send feedback\" links and the swarm of \ncalls for help that they allowed to come through to w-v. I think having \nthese links on :8001 was a great success, not quite sure about :80. I \ncan agree there *is* some interesting feedback - and not only suggested \nmessages but more of a study of the psychology of the validator's users \n- in these messages, but the s/n ratio is qutie terrible. Terje has \nasked for some patience, which *I* can do, but apparently patiences are \ngetting a bit thin.\n\nPotential short term solutions:\n  - add a well-placed display:none in the CSS\n  - comment out the code\n  - change address. I'm sure it could be less of a waste of time if I \nwere receiving and dispatching these, even if not in \"real time\".\n\nWe could discuss long term solutions at our meeting on tuesday - we \nshould have had enough input on w-v by then.\n\nNote also that if we decide to do anything \"heavy\" in the days to come \nI will not be able to do it, as I will be away from keyboards for 10 \ndays starting next thursday. The rest of the QA Team should be around, \nthough.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-13907394"}, {"subject": "proposed charter for &quot;help&quot; lis", "content": "On Fri, Jun 04, 2004, olivier Thereaux wrote:\n> While not convinced at first, I now agree to give it a go... And unless \n> someone objects, I plan to create it on monday.\n\nI haven't received any comment on the creation of the list itself so I\nsuppose everyone's fine with it. I'm leaning towards\n\"public-validation-help\" for the name (thought of ...-problems first but\nindeed, it's long).\n\nproposed charter follows. Please comment on it as soon as possible.\n \n[[\nproposed charter for public-validation-help\n\nThis mailing-list [public-validation-help @ w3.org] is a forum for\npeople of the Web community to exchange help on validating Web documents\nwith the W3C Markup[1] and CSS[2] validation services. With time, this\nlist should mainly become a repository of answers to commonly\nencountered validation problems.\n\n[1] http://validator.w3.org/\n[2] http://jigsaw.w3.org/css-validator/\n\nThis is *not* a general mailing-list for help on web design and\ndevelopment\nThis is *not* a discussion mailing-list on the development of the\nvalidators. Specific lists (Markup[3], CSS[4]) serve this purpose.\nThis is *not* a discussion mailing-list on HTML, CSS, or other Web\ntechnologies.\n\n[3] http://lists.w3.org/Archives/Public/www-validator/\n[4] http://lists.w3.org/Archives/Public/www-validator-css/\n\n\n\nPosting criteria:\n - Before posting a request for assistance, be sure to search the list's\narchives and check that the answers to your questions have not been\ngiven already.\n - Before posting a request for assistance, be sure to check documents on\nthe Web discussing common validation problems. We suggest you check out\nat least our Help and FAQ document[5], as well as the  Web authoring\nFAQ[6]\n[5] http://validator.w3.org/docs/help.html\n[6] http://www.htmlhelp.com/faq/\n - Messages asking for help on the validation of a document must be as\nclear as possible:\n   + Include minimal context and other bits of information you deem\nrelevant, such as which validator, which mode or options you used\n   + If possible, always give the URL for the document you are trying to\nvalidate.\n   + Pasting the output of the validator used can be a good idea, but\nthat output should be trimmed to the relevant minimum.\n - Note that all messages sent to the list will be publicly archived.\n - The usual netiquette and good mailing-list manners apply.\n\nThis list relies solely on the good will of volunteer participants. One\nshould not expect to receive any answer if the above criteria are not\nmet. \n]]\n\nGiven the specificity of this list, I am tempted to use archive-approval\nsystem AND moderation, and switch w-v to that too. At least for some\ntime, while redirecting people to the appropriate list for the relevant\ntopic. This means, however, that now may not be the best time to create\nthe list, given that I'll be afk for 9 days... unless I find one or\nseveral co-moderators.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13916048"}, {"subject": "checklink: 3.9.3 beta, feedback request", "content": "I have committed the stuff I had on my mind for link checker 3.9.3. \nhttp://qa-dev.w3.org/wlc/checklink is up to date.\n\nRegarding the beta announcement, I would like to request feedback in\nparticular of the following (feel free to rephrase, comment, and add\nitems):\n\n- Robots exclusion standard support in the link checker.  Good or bad?\n\n- Should the \"Check linked documents recursively\" checkbox be removed?\n  Recursion is implicit if there's anything in the \"depth\" field, so\n  the checkbox is sort of redundant.\n\nChangelog since 3.9.2 is attached.  The corresponding in-a-nutshell, or\nNEWS-like list (excluding command line only changes) would be something\nlike:\n\n- Support for the robots exclusion standard has been added.\n- Sleep 1 second between requests to servers.\n- Cookie handling logic is now more robust and predictable.\n- Harmonized layout with the Markup Validator.\n- Do not send an Accept-Language header at all if the client did not\n  send us one.  Previously, \"Accept-Language: *\" was sent by default.\n- Miscellaneous markup, layout, and documentation improvements, minor\n  bug fixes and warning cleanups.\n\n2004-06-08  ville\n\n* bin/checklink.pod: Document Doc_URI and Style_URI.\n\n2004-06-08  ville\n\n* docs/linkchecker.css: Remove some unused properties, and do a\ngratuitous whitespace cleanup.\n\n2004-06-08  ville\n\n* bin/checklink, docs/linkchecker.css: Restore some lost CSS\nproperties, and selectively sync some of the new layout stuff from\nthe current markup validator.\n\n2004-06-08  ville\n\n* bin/checklink: Avoid warning when no realm is given in\nWWW-Authenticate.\n\n2004-06-08  ville\n\n* docs/linkchecker.css: Use JPEG versions of header and footer\nimages.\n\n2004-06-08  ville\n\n* bin/checklink, docs/checklink.html, docs/linkchecker.css: Remove\nthe \"Skip navigation\" link as it is not too useful at the moment.\n\n2004-06-02  ville\n\n* bin/checklink, docs/checklink.html: Add/revise accesskeys.\n(l=linkchecker,i=download/install,d=docs,m=markup validator,s=skip\nnavigation)\n\n2004-06-02  ville\n\n* bin/checklink: Switch to HTML 4.01 strict, and make related\nadjustments and layout consistency improvements mainly to error\nmessage views.\n\n2004-06-02  ville\n\n* bin/checklink: Work around a bug in URI::sip(s) in URI 1.22-1.30.\n\nhttp://lists.w3.org/Archives/Public/www-validator/2004Jun/0003.html\n\n2004-06-01  ville\n\n* bin/checklink: More markup improvements.\n\n2004-06-01  ville\n\n* bin/checklink: Avoid error log warning when no Content-Type is\nreceived, improve markup.\n\n2004-06-01  ville\n\n* bin/checklink, bin/checklink.pod, etc/checklink.conf: Typo and\nconsistency fixes.\n\n2004-06-01  ville\n\n* bin/checklink: Apply parameters from cookie only when loading the\n\"front\" page.  Also, only load the cookie we set (not all possibly\nsent to us), when deciding how to output the cookie options on the\nfront page.  This should make the effect of the cookie more\npredictable.\n\n2004-06-01  ville\n\n* bin/checklink: Avoid warning from invalid (non-numeric) recursion\ndepth.\n\n2004-05-31  ot\n\n* bin/checklink: fixing some silliness in my recent patches -\nthanks Ville for the catch\n\n2004-05-31  ot\n\n* docs/linkchecker.css: adding style specific to linkchecker\nresults\n\n2004-05-31  ot\n\n* bin/checklink, docs/checklink.html, etc/checklink.conf: Changing\nthe layout of checklink (script) to math the one for the\ndocumentation. - adding Style_URI configuration parameter   - The\nlayout now uses default links pointing to the instance on v.w.o\n\n2004-05-16  ville\n\n* bin/checklink: HTML-escape given URI in the \"you cannot check\nsuch a URI\" message.\n\n2004-05-14  ot\n\n* docs/checklink.html, docs/linkchecker.css: quick attempt at\nstyling link checker as the Markup Validator.  Fr the actial\nservice, an idea would be to keep some of its inline style + a link\nto the stylesheet in the repository.\n\n2004-05-10  ville\n\n* bin/checklink: Treat non-empty URI's \"ok\" again with JavaScript\nimplementations without String.search().\n\n2004-05-10  ville\n\n* bin/checklink: Tweak fieldset padding.\n\n2004-05-10  ville\n\n* bin/checklink: Don't send Content-Script-Type as a real HTTP\nheader, use <meta http-equiv> instead.Also make uriOk() focus the\nURI field if it was not 'ok'.\n\n2004-05-07  ville\n\n* bin/checklink: Use relative self-referencing URL without the\nquery string for the form action.\n\n2004-05-07  ville\n\n* bin/checklink: Associate all labels explicitly with their\ncontrols as recommended by WCAG 1.0.  Thanks to Hugo Silveira da\nCunha for the heads up.\n\n2004-05-03  ville\n\n* bin/checklink.pod: Always point to\nhttp://www.w3.org/2000/07/checklink for docs, small POD entity\ntweaks.\n\n2004-04-28  ville\n\n* bin/checklink: Set \"self URI\" to\nhttp://validator.w3.org/checklink in command line HTML mode.\nThanks to James Gallagher for the report.\n\n2004-04-20  ville\n\n* bin/checklink, docs/checklink.html, docs/linkchecker.css: Add\ninstructions how to allow us in /robots.txt, and include a link to\nit in the results.\n\n2004-04-19  ville\n\n* bin/checklink: Implement \"better\" (yet somewhat hacky) handling\nof non-HTTP error codes, currently used for \"forbidden by\nrobots.txt\" and \"bad hostname\" messages from LWP.  While at it,\ndisplay \"forbidden by robots.txt\" with a light gray background (CVS\nclass \"dubious\") instead of screaming-red-403.\n\n2004-04-17  ville\n\n* t/00compile.t: Add a _very_ basic \"test suite\".\n\n2004-04-12  ville\n\n* bin/checklink: Fix broken fragment UI (was broken in revision\n3.30).\n\n2004-04-12  ville\n\n* bin/checklink: Small wording improvements.\n\n2004-04-11  ville\n\n* bin/checklink: Use \"(no message)\" if for some reason we do not\nreceive a reason phrase in the response status line.\n\n2004-04-11  ville\n\n* docs/checklink.html: Redirect loops are no longer a problem with\nthe link checker and libwww-perl 5.76 (but redirects to file: URLs\nstill are).\n\n2004-04-11  ville\n\n* bin/checklink, bin/checklink.pod, docs/checklink.html: Make sleep\ntime between requests to each server configurable in command line\nuse (-S/--sleep, defaults to 1 second), remove old \"sleep 3 seconds\nbetween documents\" feature, and show used settings in the results.\n\n2004-04-11  ville\n\n* bin/checklink: Fix typo in results CSS.\n\n2004-04-11  ville\n\n* bin/checklink: Reimplement/replace internal redirect tracking\nlogic using the response chaining feature of libwww-perl\n(HTTP::Response->previous()).  Should be more robust and\nRobotUA-friendly now.\n\n2004-04-10  ville\n\n* bin/checklink: Code cleanups.\n\n2004-04-10  ville\n\n* bin/checklink: Eliminate a couple of recently introduced printf()\nwarnings.\n\n2004-04-10  ville\n\n* docs/checklink.html: RobotUA/RobotRules works for local files\nfrom command line in LWP 5.66+, bump the required version.\n\n2004-04-10  ville\n\n* bin/checklink: Don't mask LWP's default redirect_ok()\nfunctionality, remove some dead code.\n\n2004-04-09  ville\n\n* bin/checklink, etc/checklink.conf: New configuration parameter\n(Doc_URI) to aid local doc installations.\n\n2004-04-09  ville\n\n* docs/checklink.html, docs/linkchecher.css, docs/linkchecker.css:\nRename the doc CSS once more (to linkchecker.css).\n\n2004-04-08  ot\n\n* docs/checklink.css, docs/linkchecher.css: changing name to avoid\nconneg issues\n\n2004-04-08  ville\n\n* bin/checklink: Make sure default configuration options are set\nalso when there is no configuration file.  D'oh!  Thanks to Rafael\nGieschke for the report.\n\n2004-04-07  ville\n\n* bin/checklink, docs/checklink.html: Initial (partial)\nimplementation for support for robots exclusion standard.  The UI\nstill needs some work: the results view should be fixed and some\nnew configuration options (admin address, minimum delay) should be\nadded.As a side effect, we now require libwww-perl >= 5.60.\n\n2004-04-04  ville\n\n* bin/checklink, bin/checklink.pod: Do not send any Accept-Language\nheader by default in command line mode, and don't default to \"*\" in\nCGI mode either (but still use the client-supplied value if\npresent).  In command line mode, -L auto now autodetects a value\nfrom the environment, and the -n/--noacclanguage option is\ndeprecated and does nothing.\n\n2004-04-03  ville\n\n* bin/checklink: Usage message improvements.\n\n2004-04-03  ville\n\n* bin/checklink: Link to http://www.w3.org/2000/07/checklink for\ndocs again.\n\n2004-04-03  ville\n\n* bin/checklink, bin/checklink.pod: Improve the \"Trusted\" domain\ndocumentation.\n\n2004-04-03  ville\n\n* bin/checklink: Compile trusted and exclude-docs regexps only\nonce.\n\n2004-04-03  ville\n\n* bin/checklink, bin/checklink.pod: New command line option\n(--exclude-docs) for excluding checking links in documents whose\nURIs match a regexp; thanks to Michael Ernst.  Also, some\nimprovements to argument and configuration option checking and\nerror reporting.\n\n2004-04-02  ville\n\n* README.cvs: Fix link to the online version.\n\n2004-04-01  ot\n\n* README.cvs: adding download instructions\n\n\n\n", "id": "lists-017-13925982"}, {"subject": "Re: checklink: 3.9.3 beta, feedback request", "content": "* Ville Skytt? wrote:\n>Regarding the beta announcement, I would like to request feedback in\n>particular of the following (feel free to rephrase, comment, and add\n>items):\n>\n>- Robots exclusion standard support in the link checker.  Good or bad?\n\nIt would be good to announce in what way it supports it; as discussed,\nthere are apparently several approaches, like do you read the submitted\ndocument if the robots.txt of that server does not allow it or will it\nrefuse to check any link in that case (as it does not download anything\nbut robots.txt). Without such information one would have to figure this\nout by testing or looking at the code which is unlikely to yield in\nmuch feedback.\n\n\n\n", "id": "lists-017-13942514"}, {"subject": "Re: checklink: 3.9.3 beta, feedback request", "content": "On Wed, 2004-06-09 at 01:06, Bjoern Hoehrmann wrote:\n> * Ville Skytt? wrote:\n> >Regarding the beta announcement, I would like to request feedback in\n> >particular of the following (feel free to rephrase, comment, and add\n> >items):\n> >\n> >- Robots exclusion standard support in the link checker.  Good or bad?\n> \n> It would be good to announce in what way it supports it; as discussed,\n> there are apparently several approaches, like do you read the submitted\n> document if the robots.txt of that server does not allow it or will it\n> refuse to check any link in that case (as it does not download anything\n> but robots.txt). Without such information one would have to figure this\n> out by testing or looking at the code which is unlikely to yield in\n> much feedback.\n\nThe current behaviour is the \"blunt\" one, ie. nothing except /robots.txt\nis fetched if /robots.txt disallows it.  Oh, and the version of the\nsupported exclusion standard is the \"original 1994 one\" (for now, as\nthat's what the current LWP::RobotUA supports), and <meta name=\"robots\">\nis not supported at all in this version.\n\nThis info should be included in the docs, BTW, not (only) the beta\nannouncement.  Will take a look at improving the documentation tomorrow\nunless someone beats me to it... ;)\n\n\n\n", "id": "lists-017-13950794"}, {"subject": "[meeting] notes and log 2004-060", "content": "Here is a summary of the discussion during yesterday's IRC meeting.\nAlso attaching a (trimmed) log.\n\n* Action Item Review\n  (need to sort out issues about privacy policy versus cookies)\n* Press corner\n  our tools mentioned recently in computer & mainstream press\n* CSS Validator\n  - BUGS.html and TODO.html will be modified to link to bugzilla\n  - broken (line ending) entries in repository - need to fix\n* Log Validator\n  - released soon with CSS validator module\n* Link Checker\n  - removing #skip\n  - preparing beta for 2004-06-09\n* Markup Validator\n  - shocking validation result : trying to get a grasp on our lost irony\n  - document without encoding info: Martin reportedly saying it's best \nwe can do\n  - feedback/help: discussion should proceed on list\n\n[will update wiki with new/updated action items]\n\n\n\n\n-- \nolivier\n\n\n\n\ntext/plain attachment: qadev-20040608.txt\n\n\n\n\n", "id": "lists-017-13959394"}, {"subject": "Re: checklink: 3.9.3 beta, feedback request", "content": "On Wed, 2004-06-09 at 01:25, Ville Skytt? wrote:\n\n> This info should be included in the docs, BTW, not (only) the beta\n> announcement.  Will take a look at improving the documentation tomorrow\n> unless someone beats me to it... ;)\n\nOk, done.  http://qa-dev.w3.org/wlc/#bot\n\n\n\n", "id": "lists-017-13966667"}, {"subject": "Re: checklink: 3.9.3 bet", "content": "Ville,\n\nOn Jun 9, 2004, at 07:01, Ville Skytt? wrote:\n> I have committed the stuff I had on my mind for link checker 3.9.3.\n> http://qa-dev.w3.org/wlc/checklink is up to date.\n\nThanks for doing all that. I'm in the process of setting it up on \nvwo:8001\n\nI've used the opportunity for a minimal cleanup of the file structure. \nMany checklink files still had to be within the validator tree, even \nthough they're not in CVS ther eany more.\n\nWhat I have done:\n\n* http://validator.w3.org:8001/checklink is now aliased as follows:\n   ScriptAlias /checklink \n/usr/local/perl/modules/W3C/LinkChecker/bin/checklink\n\n* Whereas http://validator.w3.org/checklink points to:\n   ScriptAlias /checklink        /usr/local/bin/checklink\n\n* removed symlinks and stale copies in httpd/cgi-bin/\n\n* on both :80 and :8001 htdocs/docs/checklink.html and linkchecker.css \nare symlinked to the docs in \n/usr/local/perl/modules/W3C/LinkChecker/docs/\n\n\nThis should allow us to \"make install\" when we want to update :80 and \ncvs-up when dealing with :8001. This seems reasonable, although there \nmight be @INC issues when we modularize. We may want to think of this \nin advance.\n\nI just noticed a small issue with the relative URIs for the images. \nchecklink.html tries to access images in \".\". Maybe we could replicate \nthe directory structure of the validator and put images in images/, \ndocs in docs/ and have the docs refer to \"../images/foo\" ?\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13973926"}, {"subject": "Re: checklink: 3.9.3 beta, feedback request", "content": "On Jun 9, 2004, at 07:01, Ville Skytt? wrote:\n> Regarding the beta announcement, I would like to request feedback in\n> particular of the following (feel free to rephrase, comment, and add\n> items):\n\nThe feeback request (with the clarifications in your other mail), along \nwith the changelog, should be perfect to create the announcement. given \nit's a beta and we mainly want feedback, there does not seem to be no \nneed for specific formality in the announcement.\n\ndepending on my time this afternoon I may send you a draft \nannouncement, but if I don't have the time, I'll take the material we \nhave already, with minor rewording maybe, tomorrow morning (my time).\n\n-- \nolivier\n\n\n\n", "id": "lists-017-13982867"}, {"subject": "Re: checklink: 3.9.3 bet", "content": "On Wed, 2004-06-09 at 10:12, olivier Thereaux wrote:\n\n> This should allow us to \"make install\" when we want to update :80 and \n> cvs-up when dealing with :8001. This seems reasonable, although there \n> might be @INC issues when we modularize. We may want to think of this \n> in advance.\n\nA well-chosen \"SetEnv PERL5LIB\" in httpd.conf should work.  OTOH it\nneeds to be checked whether that works with taint mode.\n\n> I just noticed a small issue with the relative URIs for the images. \n> checklink.html tries to access images in \".\". Maybe we could replicate \n> the directory structure of the validator and put images in images/, \n> docs in docs/ and have the docs refer to \"../images/foo\" ?\n\nMaybe, but that would mean a bit of extra work for folks installing the\nlink checker (docs) locally, and the doc couldn't any more be installed\nto /checklink.html (theoretically /../images might not \"work\").  Not big\nissues, but before changing, we should be really sure that the new setup\nis \"correct\" and that we don't have to change soon again.\n\n\n\n", "id": "lists-017-13990523"}, {"subject": "validator.w3.org:8001 down", "content": ">From /home/link/validator/httpd/logs/error_log:\n\n  [Fri Jun 11 11:38:42 2004] [notice] caught SIGTERM, shutting down\n\nIt seems some(one|thing) shut validator.w3.org:8001 down gracefully\ntoday.  Anybody know why?  I did not restart it yet in case this was for\na reason.\n\n\n\n", "id": "lists-017-13998338"}, {"subject": "Re: validator.w3.org:8001 down", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>\n>>From /home/link/validator/httpd/logs/error_log:\n>\n> [Fri Jun 11 11:38:42 2004] [notice] caught SIGTERM, shutting down\n>\n>It seems some(one|thing) shut validator.w3.org:8001 down gracefully\n>today.  Anybody know why?  I did not restart it yet in case this was for\n>a reason.\n\nThe box was reboot'ed today (probably by Ted given the source IP). I don't\nknow why and if there was any advance notice of this it was Team internal.\n\nI've started :8001 again. Confirm that it's working?\n\n- -- \n\"I don't mind being thought of as a badguy,\n but it /really/ annoys me to be thought of\n as an *incompetent* badguy!\" -- John Moreno\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQMn2hqPyPrIkdfXsEQJ1dwCdFSBsI+DG80DXLq7aC28AK9IFRC0AnRoQ\nzkt9KzALxdRIRWJ3SgNuO18s\n=ht2F\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14005416"}, {"subject": "Re: validator.w3.org:8001 down", "content": "On Fri, 2004-06-11 at 21:14, Terje Bless wrote:\n\n> I've started :8001 again. Confirm that it's working?\n\nYup, seems to work.  Thanks.\n\n\n\n", "id": "lists-017-14014415"}, {"subject": "[meeting] schedule and tentative agenda - 2004-030", "content": "Hi everyone,\n\nTomorrow's the first tuesday of the month and we'll be having our \nregular IRC meeting. Scheduled as last month, i.e:\n\nvenue : irc://freenode#validator\ndate/time: tuesday, March 2nd 17:00 CET (18:00 EET)\nlength: for one hour and a half\n\nAgenda ideas:\nThe good news is that we should have Dodji, the libcroco maintainer \nwith us, so we will continue our discussion on CSS parsing.\nSee last meeting's minutes:\nhttp://lists.w3.org/Archives/Public/public-qa-dev/2004Feb/0002.html\n\nI believe Yves has started some work on test cases, and so has Bjoern, \nso it is becoming urgent to discuss how we are going to manage all \nthese test cases (and Yves has ideas on systems to use them, too).\n\nWe may have extra time, so if you have other topics ready, bring them \nwith you.\n\n\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14049046"}, {"subject": "Meeting/Agend", "content": "Well, it seems we've got Dodji (libcroco author) joining us, so I guess\nwe should make CSS a major agenda item.  I'm not sure if that might\npre-empt my next subject due to time constraints ...\n\nAnother subject that has come up separately is collecting validation\nstatistics.  I'm thinking we could run a database at qa-dev, with\nBjoern's MSIE toolbar feeding it data (at the option ot users of\nthe toolbar).\n\nThis idea arose out of a Usenet thread, and if we put it on the\nagenda, we might want to invite Michael Rozdoba to join us for it.\n\nOn a separate note, why are there two separate lists of third-party\ncontributors at /QA/Tools/qa-dev/ ?  Wouldn't it be more equitable\njust to merge them?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14056498"}, {"subject": "Re: Meeting/Agend", "content": "On Mar 1, 2004, at 14:47, Nick Kew wrote:\n> Another subject that has come up separately is collecting validation\n> statistics.\n\nInteresting, though tricky, topic. We're just discussing about it on \nthe IRC channel now, and unless you work on a given panel of pages, \nit's difficult to achieve.\n\n> On a separate note, why are there two separate lists of third-party\n> contributors at /QA/Tools/qa-dev/ ?\n\nTrue, when I first made the page I first listed the people who had \naccounts on the qa-dev test server, then added other significant \ncontributors. Merged now as people's contribution normally tends to \nfluctuate anyway, any attempt at a classification is silly.\n\n> Wouldn't it be more equitable just to merge them?\n\nNot sure there is an equitable way anyway, but you had a point.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14063963"}, {"subject": "libcroco wishes #", "content": "I'd be looking to use the SAC API, so that's the primary focus of\nmy thoughts here.\n\n* Robust parsing - should be capable of recovering - or trying to recover -\n  after fatal error.\n  The simplest regime for this would be on a fatal error to emit an\n  error message, find the next \"}\", emit a message \"skipping to line/char\"\n  and try to resume parsing after it.  But maybe we can do better.\n\n* Messages should identify where they come from (file/line/col).\n  This applies both to normal events and errors.\n\n* Robust recovery from lesser errors\n  e.g. if a value field is malformed, remaining rules in the ruleset\n  should still be parsed.\n\n* fragment parsing - e.g. for inlined styles\n\nand one that could be implemented at a higher level:\n\n* Parsing of property values to an O-O representation\n  e.g. a box has position, size and colour attributes.\n  colour has RGB, hex and (sometimes) tokenised representations.\n\n\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14071287"}, {"subject": "Re: Meeting/Agend", "content": "On Mar 1, 2004, at 14:47, Nick Kew wrote:\n> Another subject that has come up separately is collecting validation\n> statistics.\n\nOn this topic, I just received:\nhttp://www.ae35-unit.dk/standard/english.html\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14078383"}, {"subject": "CatalogueManage", "content": "I don't recollect whether we ever discussed this properly.\n\nSome time ago I wrote a demo/prototype manager for automated\nmanagement and update of SGML/XML catalogues.  Would W3/anyone\nbenefit from this becoming a qa-dev project?\n\nhttp://valet.webthing.com/catalogue/\nhttp://lists.w3.org/Archives/Public/public-qa-dev/2003Sep/0002.html\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14085229"}, {"subject": "Re: New issue: clarifying generation/creation   generateclarify15] (closed", "content": "I have added the following definitions in section 1.3:\n\ncreate (an URI or IRI):\n      With respect to URIs and IRIs, the word 'create' is used for the\n      initial creation. This may be the initial creation of a resource\n      with a certain name, or the initial exposition of a resource under\n      a particular name.\n\ngenerate (an URI or IRI):\n      With respect to URIs and IRIs, the word 'generate' is used when\n      the IRI is generated by derivation from other information.\n\nI have also checked the text and tweaked some occurrences to fit\nthese definitions. In some cases, the distinction is difficult to\nmake, but in some others, these definitions should inhance the\nclarity of the text.\n\nI'm closing this issue.\n\nRegards,    Martin.\n\n\nAt 05:37 03/06/27 -0400, Martin Duerst wrote:\n\n>[Cross-posted to the uri list because this is a somewhat general\n>subject, and I hope to get some useful advice.]\n>\n>The current IRI draft (internal latest version at\n>http://www.w3.org/International/iri-edit/draft-duerst-iri.txt)\n>has quite a bit of language referring to generation or creation of IRIs.\n>\n>I think there are (at least) two separate concepts:\n>\n>- Creating a resource and giving it a name (e.g. domain names,\n>   file names, name of database fields, and so on).\n>\n>- Generating an URI/IRI out of various components such as domain\n>   names, file names,...\n>\n>In some cases, these two operations actually happen simultaneously,\n>i.e. when I create a new URI/IRI by saving to a specific location\n>using PUT. In other cases, a file with its name is created long\n>before it is exposed over the Web.\n>\n>Any advice on what terminology to use?\n>\n>I have created an issue for this, see\n>http://www.w3.org/International/iri-edit/#generateclarify-15.\n>\n>Regards,    Martin.\n>\n>\n\n\n\n", "id": "lists-017-1408814"}, {"subject": "[meeting] notes from 2004-030", "content": "Here are notes from our meeting last week. Sorry for the delay in \nsending these. I am also attaching the log of the IRC discussion, for \nreference.\n\n* Participants : Bjoern, Nick, Terje, Dodji (guest / libcroco), Yves, \nolivier\n\n* Action Items review\n From http://lists.w3.org/Archives/Public/public-qa-dev/2004Feb/0002.html\nRemaining AIs:\nAI (cont): Nick - investigate Apache2+modperl, play with :8001;\nAI (new): Nick - demo test harness\n\n* Agenda: CSS parser / LibCroco\n\nDodji, maintainer of libcroco (CSS parser) joined the meeting for a \nchat on what kind of features a CSS parser would need to suit our needs \nfor a next-generation CSS validator. Bjoern and Nick listed their \ndesiderata, including, mostly, robust parsing, error recovery, precise \nerrors (file, line, col, type). Dodji will start implementing this, and \njoins the qa-dev mailing-list for further discussion.\n\n* Agenda: Test\n\nShort report from olivier on the state of requirements list. We need to \ndiscuss this a bit further. Wiki not very popular among participants, \nwe will continue the discussion on the mailing-list, instead. Nick \nthinks catalogmanager could be useful, may send his ideas to the list.\n\n[adjourning after 1 hour 30 ]\n\nattaching log...\n\n\n\n-- \nolivier\n\n\n\n\ntext/plain attachment: qa-dev-20040203.txt\n\n\n\n\n", "id": "lists-017-14091851"}, {"subject": "Re: distribute checklink after this beta", "content": "On Wed, 2004-02-25 at 00:43, Ville Skytt? wrote:\n\n> I would like to proceed with the\n> following plan: fix the reported issues when I'm back, finish the\n> packaging and CVS reorganization, and arrange a quick new testing\n> session for a couple of days using the packaged version running at\n> :8001.\n\nStatus update:\n\nI've committed a CPANified link checker to perl/modules/W3C/LinkChecker,\nor http://dev.w3.org/cvsweb/perl/modules/W3C/LinkChecker/ and requested\nthe namespace W3C::LinkChecker from CPAN (no confirmation yet).\n\nThe packaging is almost complete, although the documentation still needs\nto be updated in many places.  This version is practically the same as\nthe current one in validator-0_6_0-branch, the only notable change being\nsplitting the POD documentation into a separate file.  No functional\nchanges yet as there weren't any real bug reports during my vacation, it\nseems.\n\nI'll ping the list once I think this is ready for a new smoketest at\nv.w.o:8001.  Testing and comments of course welcome already now :)\n\nWould it be possible to get CVS commit notifications from the new CVS\nlocation to www-validator-cvs@?\n\n\n\n", "id": "lists-017-14099894"}, {"subject": "Patch for source/index.htm", "content": "/me just got tired parroting about the URI/Text-Iconv bug in the stable\nversion on mailing lists :)  Could someone who has enough permissions\napply the attached patch to\n/usr/local/validator/htdocs/source/index.html on v.w.o?  TIA!\n\n\n\n\n\ntext/x-patch attachment: srcindex.patch__charset_iso-8859-1\n\n\n\n\n", "id": "lists-017-14107898"}, {"subject": "Re: Patch for source/index.htm", "content": "On Mar 23, 2004, at 03:46, Ville Skytt? wrote:\n> /me just got tired parroting about the URI/Text-Iconv bug in the stable\n> version on mailing lists :)  Could someone who has enough permissions\n> apply the attached patch to\n> /usr/local/validator/htdocs/source/index.html on v.w.o?  TIA!\n\nDone.\n\nWe'll have to remember this when cvs up'ing next release (although CVS \nwill remind us, too).\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14115012"}, {"subject": "[check] open bug roundu", "content": "I have browsed our bugzilla today, trying to have a better picture at \nwhich bugs we have associated with which target, and what we'd need to \ndo to move forward with check for at least a 0.6.5beta2.\n\nAs far as I can tell, except for bugs 297[1] and 300[2], there is no \nopen/new bug for this target, and most remaining bugs (quite a few, I \nagree) have been pushed to 0.7.0.\n[1] http://www.w3.org/Bugs/Public/show_bug.cgi?id=297\n[2] http://www.w3.org/Bugs/Public/show_bug.cgi?id=300\n\nOf these two, only 297 (config option to integrate better with system \ncatalog) may be hard to implement.\n\nThen there is the issue of \"fussy parsing\", for which which I am not \ncertain we have reached a decision. But if we decide either to trash \nthe idea altogether or to make it non-default, I do not think it should \nbe very long to make the changes.\n\nGiven all of the above, I would like to go around the table for your \nopinion on pushing the 0.6.5beta2 (as it is in its current state) \nforward, even to a release state:\nPRO: long awaited changes. Provided we take care of bug#297 and roll \nout the current CVS version, 0.6.5 will reasonably be, if not \nthe_perfect_release, the usable, installable release, which is \nsomething our current production version is lacking...\nCON: that would be postponing to some future version many of the \nchanges requested during the beta1.\n\nTimeline: I have to help Ville roll out checklink first, but once this \nis done, I can probably focus on check. That means we could target a \ndate around our next monthly meeting.\n\nCould everyone give their view on the topic?\nThanks.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14122218"}, {"subject": "Re: [check] open bug roundu", "content": "Le mar 23/03/2004 ? 06:19, olivier Thereaux a ?crit :\n> Then there is the issue of \"fussy parsing\", for which which I am not \n> certain we have reached a decision. But if we decide either to trash \n> the idea altogether or to make it non-default, I do not think it should \n> be very long to make the changes.\n\nI think making it non-default, with a call for feedback on the results\npage when it is used by the requester would be a good first compromise.\n\n> Given all of the above, I would like to go around the table for your \n> opinion on pushing the 0.6.5beta2 (as it is in its current state) \n> forward, even to a release state:\n\nI'm all for releasing a new beta, with a short deadline before going to\nproduction.\n\nDom\n-- \nDominique Haza?l-Massieux - http://www.w3.org/People/Dom/\nW3C/ERCIM\nmailto:dom@w3.org\n\n\n\n\n\n", "id": "lists-017-14130939"}, {"subject": "Re: [check] open bug roundu", "content": "On Tue, 2004-03-23 at 10:32, Dominique Haza?l-Massieux wrote:\n> Le mar 23/03/2004 ? 06:19, olivier Thereaux a ?crit :\n> > Then there is the issue of \"fussy parsing\", for which which I am not \n> > certain we have reached a decision. But if we decide either to trash \n> > the idea altogether or to make it non-default, I do not think it should \n> > be very long to make the changes.\n> \n> I think making it non-default, with a call for feedback on the results\n> page when it is used by the requester would be a good first compromise.\n\n+1.  Then there's the issue how to mark docs that produce\nerrors/warnings in fussy mode.  If I've understood correctly, some\ndocuments may be currently marked \"not valid\" even though technically\nthey are valid, and the reported issues are due to fussiness only.  If\nthis is correct, perhaps add an explanation and never say \"not valid\" in\nfussy mode?  Apologies if this is already taken care of, I haven't\nchecked for a while.\n\n> > Given all of the above, I would like to go around the table for your \n> > opinion on pushing the 0.6.5beta2 (as it is in its current state) \n> > forward, even to a release state:\n> \n> I'm all for releasing a new beta, with a short deadline before going to\n> production.\n\nSeconded.\n\n\n\n", "id": "lists-017-14139267"}, {"subject": "Re: [check] open bug roundu", "content": "On Tue, 2004-03-23 at 07:19, olivier Thereaux wrote:\n\n> [1] http://www.w3.org/Bugs/Public/show_bug.cgi?id=297\n> Of these two, only 297 (config option to integrate better with system \n> catalog) may be hard to implement.\n\nI added a quick comment about this to Bugzilla.\n\n> Timeline: I have to help Ville roll out checklink first, but once this \n> is done, I can probably focus on check.\n\nchecklink is almost there.  I'll commit some cosmetic'ish changes\ntonight and ping when done.\n\n\n\n", "id": "lists-017-14147601"}, {"subject": "New checklink for testin", "content": "Ok, here's a new version of checklink for testing.\nTarball: http://koti.welho.com/vskytta/W3C-LinkChecker-3.9.1.tar.gz\nOnline:  http://validator.w3.org:8001/checklink\n\nNote that the v.w.o:8001 version is just bin/checklink from the tarball\ncopied into ~link/validator/httpd/cgi-bin/checklink.pl, so it's not\nreally CVS controlled at the moment.\n\nThe CPAN namespace W3C-LinkChecker is confirmed and ok.  Unless we find\nblockers, I'm fine with releasing 3.9.1 to CPAN.\n\n\n\n", "id": "lists-017-14154782"}, {"subject": "Re: [check] open bug roundu", "content": "On Tue, Mar 23, 2004, Ville Skytt? wrote:\n> +1.  Then there's the issue how to mark docs that produce\n> errors/warnings in fussy mode. \n\nPrecisely, that's where the complication comes from.\n\nIf you have a look at opensp's output when feeding it a document with\nshorttags (otherwise valid)\n[[\n24/03 15:19 ot@wasabi ~% cat SHORTTAG-test.html| onsgmls  -wmin-tag -wfully-tagged -wrefc -wmissing-att-name\nonsgmls:<OSFD>0:2:6:E: NET-enabling start-tag requires SHORTTAG YES\nonsgmls:<OSFD>0:2:6:E: document type does not allow element \"TITLE\" here\nonsgmls:<OSFD>0:4:0:E: unclosed start-tag requires SHORTTAG YES\nonsgmls:<OSFD>0:4:0:E: document type does not allow element \"UL\" here\nonsgmls:<OSFD>0:4:34:W: empty end-tag\nonsgmls:<OSFD>0:5:20:E: no document element\n]]\n\nIf I understand onsgmls speak, that means even though the -w options\nare supposed to add *warnings*, it actually spits out both errors and\nwarnings. Which means that, even if we are (were?) marking errors and\nwarnings differently, there would be no way for us to mark fussy-induced\nwarnings as such.\n\nIn other words, the options we have at this point are, I believe:\n- make fussy mode optional and be happy with the fact tat it marks\n  documents as invalid. (+ s/lax/normal/ in the fussy mode note)\n- remove fussy mode altogether (comment it out)\n\nThe latter is unfortunate, but so will be the rants of people pointing\nout that the validator still marks valid documents as invalid (in this\nparticular mode).\n-- \nolivier\n\n\n\n", "id": "lists-017-14162244"}, {"subject": "Re: [check] open bug roundu", "content": "* olivier Thereaux wrote:\n>Then there is the issue of \"fussy parsing\", for which which I am not \n>certain we have reached a decision. But if we decide either to trash \n>the idea altogether or to make it non-default, I do not think it should \n>be very long to make the changes.\n\nhttp://www.htmlhelp.com/tools/validator/ resolved everything in this\nregard, as far as I am concerned. Long before this \"fussy\" thingy has\nbeen added to the W3C MarkUp Validator, actually. -wfully-tagged is not\nof any use for the community as long as it complains about all <table>\nelements without a <tbody> inside. -wmin-tag should certainly be the\ndefault and rewrite its errors to warnings, see the WDG Validator.\n\n>Given all of the above, I would like to go around the table for your \n>opinion on pushing the 0.6.5beta2 (as it is in its current state) \n>forward, even to a release state:\n\nI do not care much what happens on a port != 80, but I would like to\npoint out that I consider the beta highlighting behavior unusable, see\n<http://validator.w3.org:8001/check?uri=http://msdn.microsoft.com> vs.\n<http://validator.w3.org:80/check?uri=http://msdn.microsoft.com>.\n\n\n\n", "id": "lists-017-14170693"}, {"subject": "Re: Migration of HTTP to the use of IRIs [queryclarify16", "content": "Hello Chris,\n\nI have added a new paragraph to section 7.8 of the IRI spec, reading\nas follows:\n\n >>>>>>>>\nIt is often possible to reduce the effort and dependencies for upgrading\nto IRIs by using UTF-8 rather than another encoding where there is a free\nchoice of encodings. For example, when setting up a new file-based Web\nserver, using UTF-8 as the encoding of the file names will make the\ntransition to IRIs easier. Likewise, when setting up a new Web form\nusing UTF-8 as the encoding of the form page, the returned query\nURIs will use UTF-8 as an encoding and will therefore be compatible\nwith IRIs.\n >>>>>>>>\n\nThis is to cover the issue queryclarify-16, and it also gives\nsome more information with regards to UTF-8. When this section\nwas originally written (which was one of the very early drafts,\nif I remember correctly), browsers and other clients that\nunderstood UTF-8 were not very widely available, so this advice\nwas not appropriate, but this has clearly changed in the meantime.\n\nI have marked this issue as tentatively closed.\n\nRegards,    Martin.\n\n\nAt 01:19 03/06/28 -0400, Martin Duerst wrote:\n\n>Hello Chris,\n>\n>Many thanks for your comments on the IRI spec.\n>\n>I have noted your issue as:\n>http://www.w3.org/International/iri-edit#queryclarify-16\n>\n>More explanations below.\n>\n>At 23:21 03/06/26 +0100, Chris Haynes wrote:\n>\n>>Dear Martin / Michel,\n>>\n>>I'm looking at draft-duerst-iri-04 from the viewpoint of a provider of\n>>web server technology. I'm trying to understand the likely migration\n>>path to the use of IRIs, and I'm concerned that there's a gap I don't\n>>see being filled.\n>>\n>>It may well be that filling the gap is outside the scope of your\n>>Internet Draft, but unless the gap is filled, I fear there may be a\n>>_long_ delay before IRIs are adopted where they are most needed.\n>>\n>>Your section 7.8, Upgrading Strategy, contains some useful thoughts /\n>>advice, which I have summarised to myself as \"Don't put in an\n>>IRI-aware server until all the resources on the site(s) you serve are\n>>published in IRI\".\n>>\n>>However that's not the problem that concerns me.\n>>\n>>I'm concerned about the encoding of HTTP GET query strings, typically\n>>carrying text inserted by a user into a browser's form.\n>\n>You are right that section 7.8 does not address query strings,\n>and that it doesn't say so clearly, and that there is otherwise\n>not too much about how query strings are supposed to work.\n>I have noted this specific aspect of your mail as an issue,\n>and will try to update the draft accordingly.\n>\n>\n>>Assume below that \"I\" am the developer of a web server. (I'm not, but\n>>I advise someone who is).\n>>\n>>I want to support IRIs as soon as possible. I know that 'out there'\n>>are many different makes and releases of browsers; I have no control\n>>over them.\n>>\n>>As is well known, there is no mechanism in RFCs 2396 / 2616 for\n>>indicating the encoding associated with any %hh octet-triplets in\n>>URIs.\n>\n>Agreed.\n>\n>\n>>Unless I've missed something, your draft implies that user agents\n>>(browsers) may perform IRI to URI conversion, so that 'my' server sees\n>>an RFC 2396-conformant URI.\n>\n>Well, they actually have to do this conversion, because HTTP\n>does not allow anything else than an URI in the request.\n>\n>\n>>How do I know it is was originally an IRI and that I should apply the\n>>reverse conversions of your section 3.2 before extracting the query\n>>name-value pairs?\n>\n>You don't. Equally well, you don't know whether the name/value\n>pairs were in iso-8859-1 (Latin-1), or shift-jis, or whatever.\n>HTTP does not help you there at all.\n>\n>\n>>The problem is not 'academic', the vast majority of browser requests\n>>received today which have %hh triplets used encodings other than\n>>UTF-8, and these will continue to arrive for the next 20-or-more\n>>years.\n>\n>Well, for query parts, you actually have quite some control over\n>what encoding you get the query part back. Already since a few years,\n>browsers send back the query part in the encoding that they received\n>the page in. This works quite well. So if you want to have any\n>idea of what you get back from a browser, you have to know how\n>you send out your pages. And if you use UTF-8 for your pages,\n>then you get three main benefits when compared to other encodings:\n>- UTF-8 can handle the widest range of characters\n>- UTF-8 will bring your GET request in line with IRIs\n>- UTF-8 can be checked with very high reliability\n>\n>For more information, please also see the Q&A page that we put up\n>recently:\n>http://www.w3.org/International/questions/qa-forms-utf-8.html\n>\n>\n>>You may well answer that the way IRIs are to be applied is to be\n>>scheme-dependent; the problem/opportunity  is for the HTTP RFC2616++\n>>community to address.\n>\n>Well, part of it could be addressed scheme-by-scheme. For example,\n>a new scheme could require that only UTF-8 be used in the query\n>part. It can also be addressed by other technologies, for example,\n>XForms, which requires the use of UTF-8 in the query part of GET\n>requests (see http://www.w3.org/TR/xforms/slice11.html#serialize-urlencode).\n>\n>\n>>I would feel *far* more comfortable if I knew that they were aware of\n>>this and if there were draft proposals visible on this list and being\n>>checked for feasibility and for 'compatibility' with your drafts.\n>>I've seen no evidence for this, and you don't appear to\n>>cross-reference any related HTTP activity in your draft.\n>>\n>>\n>>It is not beyond the bounds of possibility, for example, that the HTTP\n>>community might conclude that they cannot provide IRI support unless\n>>your RFC-to-be  includes some kind of marker or syntactic construction\n>>within \"URIs which were converted from IRIs\" which explicitly\n>>identifies them as such.\n>>\n>>In other words it might be found that all IRIs MUST be mapped into\n>>some character sequence which IS NOT a 'legal'  URI (by the current\n>>RFC2396), so that the receiver knows that the reverse process of your\n>>section 3.2 MUST be applied.\n>\n>This would mean choosing a different escape convention.\n>We considered this years ago, but decided against it.\n>Using something that is illegal in an URI would not have\n>worked, and would still not work, with the current infra-\n>structure.\n>\n>\n>>There are other approaches the HTTP community could take, which\n>>_would_ be compatible with your current draft, (and I have my own\n>>candidate solution), but surely there should at least be some kind of\n>>'existence proof' or 'feasibility study' by which they agree that they\n>>_can_ work with your proposals before they are finalized?\n>\n>I hope what I have explained above is enough of an 'existence proof'.\n>\n>Please tell me if you don't think so.\n>\n>Regards,    Martin.\n>\n>\n>>Without some kind of 'roadmap' for HTTP use of IRIs I don't see how\n>>anyone can pass final judgement on your draft.\n>>\n>>Please reassure me by telling me I'm an idiot for not knowing about\n>>XXX or not reading YYY.\n>>\n>>Regards,\n>>\n>>Chris Haynes\n\n\n\n", "id": "lists-017-1417861"}, {"subject": "Re: [check] open bug roundu", "content": "On Wed, 24 Mar 2004, Olivier Thereaux wrote:\n\n>\n> On Tue, Mar 23, 2004, Ville Skytt? wrote:\n> > +1.  Then there's the issue how to mark docs that produce\n> > errors/warnings in fussy mode.\n>\n> Precisely, that's where the complication comes from.\n\n\"Parsing [url] in [****] mode\"\n\"Result: [pass|fail] (approx. n messages)\"\nIF mode has extra warnings:\n\"Note: parsing in [mode] mode generates additional warnings\nover and above technical validation errors.\"\n\n> In other words, the options we have at this point are, I believe:\n> - make fussy mode optional and be happy with the fact tat it marks\n>   documents as invalid. (+ s/lax/normal/ in the fussy mode note)\n> - remove fussy mode altogether (comment it out)\n\nIf we term it pass/fail, we avoid that problem by not applying the\nword valid or invalid to a document.  Problem solved.\n\nBut I still think we need a sensible warnings mode.\nonsgmls -wmin-tag (as used in Valet Web mode and htmlhelp \"warnings\")\nis IMNSHO the most useful for most of our users (except Jukka).\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14178920"}, {"subject": "libwwwperl issues/upgrade", "content": "There are a couple of issues with the libwww-perl 5.64 installed on v.w.o:\n\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=226\n...and a new one, which is according to my tests fixed in 5.68 and later\n(see below and\nhttp://lists.w3.org/Archives/Public/www-validator/2004Mar/0059.html). \nPerhaps we could consider upgrading to 5.70 or later, on :8001 first for\na test period?\n\n\n$ perl -MLWP -e 'print \"$LWP::VERSION\\n\"'\n5.64\n$ HEAD https://ntc.cap.af.mil/ops/tests/check_cookie.cfm\nCan't call method \"request\" on an undefined value at /usr/share/perl5/LWP/UserAgent.pm line 362.\nville@lovejoy:~$ export PERL5LIB=/home/ville/libwww-perl-5.68/lib\nville@lovejoy:~$ perl -MLWP -e 'print \"$LWP::VERSION\\n\"'\n5.68\n$ HEAD https://ntc.cap.af.mil/ops/tests/check_cookie.cfm\n200 EOF\nClient-Date: Wed, 24 Mar 2004 19:49:47 GMT\nClient-Peer: 164.235.4.147:443\nClient-Response-Num: 1\nClient-SSL-Cert-Issuer: /C=US/O=U.S. Government/OU=DoD/OU=PKI/CN=DOD CLASS 3 CA-3\nClient-SSL-Cert-Subject: /O=U.S/OU=DOD/OU=PKI/OU=DLA/CN=ntc.cap.af.mil/Email=rharris@cols.disa.mil\nClient-SSL-Cipher: DES-CBC3-SHA\nClient-SSL-Warning: Peer certificate not verified\n\n\n\n", "id": "lists-017-14187195"}, {"subject": "[check] issue #207 (sgmlxml catalogs", "content": "Regarding http://www.w3.org/Bugs/Public/show_bug.cgi?id=297\n\n\nThe main problem, it seems is that sgml-lib and packages such as \nsgml-data have different directory structures (the latter separates \nsgml and xml), and a different catalog (as Ville was noting earlier).\n\nAm I being naive in thinking that Nick's catalogue manager would solve \nat least part of this issue?\n\nhttp://valet.webthing.com/catalogue/\n\nI remember that some people in the W3C team did not like the idea, \nbecause ideally (if I remember correctly) this kind of catalogue should \nnot exist, and we should be using URIs. That seems to be the exact \nopposite idea than the one behind the -R switch in onsgmls.\n\nI'll try to bring people here to discuss this topic, which I admit I do \nnot master.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14195405"}, {"subject": "Re: libwwwperl issues/upgrade", "content": "On Wed, Mar 24, 2004, Ville Skytt? wrote:\n> \n> There are a couple of issues with the libwww-perl 5.64 installed on v.w.o:\n> \n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=226\n> ...and a new one, which is according to my tests fixed in 5.68 and later\n> (see below and\n> http://lists.w3.org/Archives/Public/www-validator/2004Mar/0059.html). \n> Perhaps we could consider upgrading to 5.70 or later, on :8001 first for\n> a test period?\n\nAh, must be that time of the release cycle when the Debian stable loses\nits \"b\". I note that wasabi, where my test instance resides, has been\nrunning 5.76-2 for a while without trouble.\n\nhttp://packages.debian.org/cgi-bin/search_packages.pl?keywords=libwww-perl&searchon=names&subword=1&version=all&release=all\n\nDo you think it is dangerous to just install the deb testing package and\nthat we should carefully test on :8001 first?\n\n \n-- \nolivier\n\n\n\n", "id": "lists-017-14202572"}, {"subject": "Re: New checklink for testin", "content": "On Mar 24, 2004, at 07:17, Ville Skytt? wrote:\n> Ok, here's a new version of checklink for testing.\n> Tarball: http://koti.welho.com/vskytta/W3C-LinkChecker-3.9.1.tar.gz\n\nThis is excellent. I tried to \"foolproof\" it by impersonating a \nfirst-time user (and impatient). giving each document only a few \nseconds to convince. The \"I want to install and use the commandline \nversion\" and \"I want that in my CGIs\" scenarios worked well (Thanks to \nthe fact that most of the info is both in the README and html \ndocumentation). So the packaging is solid.\n\nI tried the commandline version for the first time (I should really \nhave done that better) and was a bit confused at first (still \nimpersonating - easy this time - the impatient newbie...). (no \nreadline?)\n\n'/usr/bin/checklink' and '/usr/bin/checklink -h' gave me respectively \nnothing and a chunk of HTML (not a full page). I know, this is not \nsomething anyone will do after reading the doc, but improving this \ncould be a wishlist item for a future version.\n\nNo blocker, though, and I think we're good for a first release. OK with \nearly next week?\n\n> The CPAN namespace W3C-LinkChecker is confirmed and ok.  Unless we find\n> blockers, I'm fine with releasing 3.9.1 to CPAN.\n\nDefinitely fine with me too.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14211082"}, {"subject": "Re: libwwwperl issues/upgrade", "content": "On Thu, 2004-03-25 at 02:14, Olivier Thereaux wrote:\n\n> Do you think it is dangerous to just install the deb testing package and\n> that we should carefully test on :8001 first?\n\nI guess the upgrade should be pretty safe, and can be rolled back\nquickly if problems are found.  I haven't tested the validator at all\nwith 5.76, but checklink seems to be fine.\n\n\n\n", "id": "lists-017-14219751"}, {"subject": "Bugzilla is broke", "content": "http://www.w3.org/Bugs/Public/\n\nSoftware error:\nBugzilla is currently broken. Please try again later. If the problem\npersists, please contact webreq@w3.org. The error you should quote is:\nUnknown MySQL Server Host 'db2.w3.org' (1) at globals.pl line 140.\n\n\n\n", "id": "lists-017-14226790"}, {"subject": "Re: New checklink for testin", "content": "On Fri, 2004-03-26 at 09:53, olivier Thereaux wrote:\n\n> '/usr/bin/checklink' and '/usr/bin/checklink -h' gave me respectively \n> nothing and a chunk of HTML (not a full page). I know, this is not \n> something anyone will do after reading the doc, but improving this \n> could be a wishlist item for a future version.\n\nThanks for the feedback.  This was such a small change that I\nimplemented it right away, running checklink without arguments now\noutputs the usage message.  It does also introduce an incompatible\nchange, namely -h no more means --html, but --help instead.  -H is now\nan alias for --html.\n\n> No blocker, though, and I think we're good for a first release. OK with \n> early next week?\n\nOk.  I re-rolled 3.9.1, with the change above and some other cosmetic\nones.  CVS is up to date and tagged, and the tarball is again at\nhttp://koti.welho.com/vskytta/W3C-LinkChecker-3.9.1.tar.gz.\n\nAfter this is uploaded to CPAN, I will create also RPMs of it.  At that\npoint, I'll revise the validator installation instructions and the RPM\npackage, removing checklink from it to avoid conflicts.  What do you\nthink, should we remove the old checklink from the validator CVS tree?\n\n\n\n", "id": "lists-017-14233938"}, {"subject": "Re: Bugzilla is broke", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>http://www.w3.org/Bugs/Public/\n>\n>Software error: Bugzilla is currently broken. Please try again later. If\n>the problem persists, please contact webreq@w3.org. The error you should\n>quote is: Unknown MySQL Server Host 'db2.w3.org' (1) at globals.pl line\n>140.\n\nHmmm. Red Hat's Bugzilla was also exhibiting similar problems this morning;\nbut they're back up now. Perhaps someone was playing silly buggers, trying to\nexploit one of the several security issues in Bugzilla, and Red Hat had\npatched their Bugzilla in a slightly more timely fashion?\n\n\n- -- \n\"When you have no nails your hammer grows restless, and you begin to throw\n sideways glances at screws and pieces of string.\"    -- Jarkko Hietaniemi\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQGba2qPyPrIkdfXsEQL7zACdEHXV3smS6LwicxR7b1yakL41+gIAn0Sd\nV2rvj0DneIxoMXJnzVX+C9GA\n=C+6X\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14242480"}, {"subject": "Re: New checklink for testin", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>After this is uploaded to CPAN, I will create also RPMs of it.  At that\n>point, I'll revise the validator installation instructions and the RPM\n>package, removing checklink from it to avoid conflicts.  What do you\n>think, should we remove the old checklink from the validator CVS tree?\n\nYes. Having a tale copy in CVS is guaranteed to generate more confusion than\nany other possible resolution. We can put huge pointers in the relevant places\nto make sure people can find it.\n\n- -- \nWe've gotten to the point where a human-readable, human-editable text format\nfor structured data has become a complex nightmare where somebody can safely\nsay  \"As many threads on xml-dev have shown, text-based processing of XML is\nhazardous at best\"  and be perfectly valid in saying it.     -- Tom Bradford\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQGbbvqPyPrIkdfXsEQLHwwCfQsB+ZdAtnWliceKY1U+Q6jSVfXkAoPhL\nipcLr4kXUzQPTIOLQQiAYEmq\n=acDT\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14251253"}, {"subject": "Do not upgrade to libwwwperl 5.7", "content": "I found a bug in libwww-perl 5.76 which affects the link checker (lots\nof spurious \"redirect loop\" warnings) and possibly the validator. \nAFAICS, earlier versions of libwww-perl are not affected.  More info:\nhttps://rt.cpan.org/NoAuth/Bug.html?id=5828\n\n\n\n", "id": "lists-017-14260204"}, {"subject": "Re: Bugzilla is broke", "content": "On Mar 28, 2004, at 18:22, Ville Skytt? wrote:\n> http://www.w3.org/Bugs/Public/\n>\n> Software error:\n> Bugzilla is currently broken. Please try again later. If the problem\n> persists, please contact webreq@w3.org. The error you should quote is:\n> Unknown MySQL Server Host 'db2.w3.org' (1) at globals.pl line 140.\n\nWeird, db2 does not exist any more.\nI fixed the config, it seems to work now.\n\nThanks for the warning, Ville.\n-- \nolivier\n\n\n\n", "id": "lists-017-14267162"}, {"subject": "Re: Do not upgrade to libwwwperl 5.7", "content": "On Mar 28, 2004, at 23:15, Ville Skytt? wrote:\n> I found a bug in libwww-perl 5.76 which affects the link checker\n\nGood catch. I'm thus considering installing 5.70 (by hand)... Wonder if \nI could find a deb of that, or if we'll have to move away from the \npackages.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-14274635"}, {"subject": "Re: New checklink for testin", "content": "On Mar 28, 2004, at 18:23, Ville Skytt? wrote:\n> Ok.  I re-rolled 3.9.1, with the change above and some other cosmetic\n> ones.  CVS is up to date and tagged, and the tarball is again at\n> http://koti.welho.com/vskytta/W3C-LinkChecker-3.9.1.tar.gz.\n\nLooks good. I was planning to release and announce on thursday, but \nsomehow the idea of announcing a release on an April 1st makes me \nuncomfortable ;).\n\nOK with friday?\n\nI'm thinking of announcing it to QA lists, QA site, W3C Open Source \nsite. Will ping people again for a homepage item on w3.org. Also \nthinking of a couple webdesign lists/groups such as wasp/evolt. \nAnything else? CIWAH?\n\nI'll draft an announcement based on the Beta text today.\n\n>  What do you think, should we remove the old checklink from the \n> validator CVS tree?\n\nThis sounds like the most reasonable idea indeed.\n\n-- \nolivier\n\n\n\n", "id": "lists-017-14281829"}, {"subject": "[check] midterm development plan + branch mes", "content": "Although we'll have to discuss that at our meeting next week (reminder: \nwe have a meeting next week), I'm seriously planning to move on quickly \nwith check version 0.6.5, by moving the target for the remaining bugs \nif necessary. The rationale for that being that the usability \nimprovements justify the new beta, not to mention obviously that the \nactual release is overdue.\n\nIt is probably a good time to think of our release cycles (won't \nanybody think of the release cycles!), and I think one key to success \nin this area will be how and whether we manage to clean up the \nHEAD/branch mess.\n\nDon't misunderstand my position though, I still think some branching \nwas not such a bad idea, but the fact that 0.6 was *not* done after \n0.6.1 and that there was very little work on 0.7 for a long time made \nthe HEAD rot while all work was made in the 0.6branch. Bad luck \nhappens, but we must do better next time.\n\nMy requirements for any solution would be:\n- The ability to commit unstable code without fear\n- The ability to do some researchy code (modularization)\n- The ability for people to download, install, test, have fun with the \nMarkup validator\n- The ability for people to install a stable, working version of the \nMarkup validator\n- The ability to do a very quick fix to the :80 (e.g broken links) \nwithout it being too big a burden\n\nThinking ahead, I don't think we'll have resource swarming toward us in \nthe near future. IOW, developing a new modular codebase and fixing all \nthe bugs in the monolithic one does not seem too reasonable. Thus we \nmay have to decide between ditching all hopes of a new, clean \ngeneration in order to fix all the bugs in our current service, OR \nleave the service as is (reasonably - ahem - stable and bug-free) and \ndevelop a new generation.\n\nDepending on which path we choose, I can see a few possibilities for \nour management of CVS:\n1 - stay as things currently are\n2 - invert... HEAD would be the current work (synced with 0.6branch - \ncan we do that, technically? - or removing the 0.6 branch) and advanced \ndevelopment would be done in a specific branch\n3 - no more branches.\n4 - two branches, stable and unstable\n\nMy opinion is still fluctuating, and I'd like to discuss this seriously \nwith all of you. So far I think we have reached the limits of our \nmonolithic+openSP design, and tweaking it to death to fix XML related \nbugs may just take more effort than re-starting with a multi-parser \ndesign. I would then favour option 2, or option 1 (2 being more \nfriendly to semi-clueless people wanting to get something slightly more \n*cutting edge* than the tarball).\n\n[YOUR THOUGHTS HERE]\n-- \nolivier \n\n\n\n\n", "id": "lists-017-14290119"}, {"subject": "Re: New checklink for testin", "content": "On Wed, 2004-03-31 at 01:49, olivier Thereaux wrote:\n> On Mar 28, 2004, at 18:23, Ville Skytt? wrote:\n> > Ok.  I re-rolled 3.9.1, with the change above and some other cosmetic\n> > ones.  CVS is up to date and tagged, and the tarball is again at\n> > http://koti.welho.com/vskytta/W3C-LinkChecker-3.9.1.tar.gz.\n> \n> Looks good. I was planning to release and announce on thursday, but \n> somehow the idea of announcing a release on an April 1st makes me \n> uncomfortable ;).\n> \n> OK with friday?\n\nOk.  After discovering the libwww-perl 5.76 issue, I could not resist\ndocumenting it and doing some other cleanups; no real code changes:\nhttp://koti.welho.com/vskytta/W3C-LinkChecker-3.9.2.tar.gz\n\n> I'm thinking of announcing it to QA lists, QA site, W3C Open Source \n> site. Will ping people again for a homepage item on w3.org. Also \n> thinking of a couple webdesign lists/groups such as wasp/evolt. \n> Anything else? CIWAH?\n> \n> I'll draft an announcement based on the Beta text today.\n\nSounds good, thanks!  I will upload it to CPAN tomorrow evening, so\nit'll be there waiting when the announcement goes public.\n\n> >  What do you think, should we remove the old checklink from the \n> > validator CVS tree?\n> \n> This sounds like the most reasonable idea indeed.\n\nOk, will do once we get this version out.\n\n\n\n", "id": "lists-017-14299150"}, {"subject": "Re: Migration of HTTP to the use of IRIs [queryclarify16", "content": "Martin,\n\nThanks for this response.\n\nActually, my original core concern has now been covered in your section 1.2.a -\nApplicability, where you make it clear that \"the intent is not to introduce IRIs\ninto contexts that are not defined to accept them\".\n\nThis now makes it clear that new schemas will be required to replace http: ,\nhttps: etc. These will need to be self-identifying in some way, so that\nreceiving equipment will know that an IRI is being presented.\n\nSo, as I commented last June, I await with interest the recognition among those\nresponsible for the HTTP schema that new schemas with new names are required\nbefore IRIs can be used.\n\n\nReturning to the logged issue...\n\nYour new paragraph in 7.8 is helpful, but not, I fear, strictly accurate.\n\nThe phrase \"returned query URIs will use UTF-8 as an encoding\" is accurate only\nif the browser's user has not manually changed the page encoding via the menu\ncommands available to her (e.g. with MSIE the  \"View - Encoding\" menu sequence).\nIt can easily be demonstrated that this user selection of the encoding overrides\nthe encoding declared in the HTML text or associated HTTP header when requests\nare formulated.\n\n'will use' is therefore too strong.\n\nChanging the phrase to \"returned query URIs will, by default, use UTF-8 as an\nencoding\" is an accurate statement - it just leaves open the question of what\n'by default' means.\n\nChris\n.\n\n\n----- Original Message -----\nFrom: \"Martin Duerst\" <duerst@w3.org>\nTo: \"Chris Haynes\" <chris@harvington.org.uk>; <public-iri@w3.org>\nSent: Thursday, May 06, 2004 8:55 AM\nSubject: Re: Migration of HTTP to the use of IRIs [queryclarify-16]\n\n\n> Hello Chris,\n>\n> I have added a new paragraph to section 7.8 of the IRI spec, reading\n> as follows:\n>\n>  >>>>>>>>\n> It is often possible to reduce the effort and dependencies for upgrading\n> to IRIs by using UTF-8 rather than another encoding where there is a free\n> choice of encodings. For example, when setting up a new file-based Web\n> server, using UTF-8 as the encoding of the file names will make the\n> transition to IRIs easier. Likewise, when setting up a new Web form\n> using UTF-8 as the encoding of the form page, the returned query\n> URIs will use UTF-8 as an encoding and will therefore be compatible\n> with IRIs.\n>  >>>>>>>>\n>\n> This is to cover the issue queryclarify-16, and it also gives\n> some more information with regards to UTF-8. When this section\n> was originally written (which was one of the very early drafts,\n> if I remember correctly), browsers and other clients that\n> understood UTF-8 were not very widely available, so this advice\n> was not appropriate, but this has clearly changed in the meantime.\n>\n> I have marked this issue as tentatively closed.\n>\n> Regards,    Martin.\n>\n>\n> At 01:19 03/06/28 -0400, Martin Duerst wrote:\n>\n> >Hello Chris,\n> >\n> >Many thanks for your comments on the IRI spec.\n> >\n> >I have noted your issue as:\n> >http://www.w3.org/International/iri-edit#queryclarify-16\n> >\n> >More explanations below.\n> >\n> >At 23:21 03/06/26 +0100, Chris Haynes wrote:\n> >\n> >>Dear Martin / Michel,\n> >>\n> >>I'm looking at draft-duerst-iri-04 from the viewpoint of a provider of\n> >>web server technology. I'm trying to understand the likely migration\n> >>path to the use of IRIs, and I'm concerned that there's a gap I don't\n> >>see being filled.\n> >>\n> >>It may well be that filling the gap is outside the scope of your\n> >>Internet Draft, but unless the gap is filled, I fear there may be a\n> >>_long_ delay before IRIs are adopted where they are most needed.\n> >>\n> >>Your section 7.8, Upgrading Strategy, contains some useful thoughts /\n> >>advice, which I have summarised to myself as \"Don't put in an\n> >>IRI-aware server until all the resources on the site(s) you serve are\n> >>published in IRI\".\n> >>\n> >>However that's not the problem that concerns me.\n> >>\n> >>I'm concerned about the encoding of HTTP GET query strings, typically\n> >>carrying text inserted by a user into a browser's form.\n> >\n> >You are right that section 7.8 does not address query strings,\n> >and that it doesn't say so clearly, and that there is otherwise\n> >not too much about how query strings are supposed to work.\n> >I have noted this specific aspect of your mail as an issue,\n> >and will try to update the draft accordingly.\n> >\n> >\n> >>Assume below that \"I\" am the developer of a web server. (I'm not, but\n> >>I advise someone who is).\n> >>\n> >>I want to support IRIs as soon as possible. I know that 'out there'\n> >>are many different makes and releases of browsers; I have no control\n> >>over them.\n> >>\n> >>As is well known, there is no mechanism in RFCs 2396 / 2616 for\n> >>indicating the encoding associated with any %hh octet-triplets in\n> >>URIs.\n> >\n> >Agreed.\n> >\n> >\n> >>Unless I've missed something, your draft implies that user agents\n> >>(browsers) may perform IRI to URI conversion, so that 'my' server sees\n> >>an RFC 2396-conformant URI.\n> >\n> >Well, they actually have to do this conversion, because HTTP\n> >does not allow anything else than an URI in the request.\n> >\n> >\n> >>How do I know it is was originally an IRI and that I should apply the\n> >>reverse conversions of your section 3.2 before extracting the query\n> >>name-value pairs?\n> >\n> >You don't. Equally well, you don't know whether the name/value\n> >pairs were in iso-8859-1 (Latin-1), or shift-jis, or whatever.\n> >HTTP does not help you there at all.\n> >\n> >\n> >>The problem is not 'academic', the vast majority of browser requests\n> >>received today which have %hh triplets used encodings other than\n> >>UTF-8, and these will continue to arrive for the next 20-or-more\n> >>years.\n> >\n> >Well, for query parts, you actually have quite some control over\n> >what encoding you get the query part back. Already since a few years,\n> >browsers send back the query part in the encoding that they received\n> >the page in. This works quite well. So if you want to have any\n> >idea of what you get back from a browser, you have to know how\n> >you send out your pages. And if you use UTF-8 for your pages,\n> >then you get three main benefits when compared to other encodings:\n> >- UTF-8 can handle the widest range of characters\n> >- UTF-8 will bring your GET request in line with IRIs\n> >- UTF-8 can be checked with very high reliability\n> >\n> >For more information, please also see the Q&A page that we put up\n> >recently:\n> >http://www.w3.org/International/questions/qa-forms-utf-8.html\n> >\n> >\n> >>You may well answer that the way IRIs are to be applied is to be\n> >>scheme-dependent; the problem/opportunity  is for the HTTP RFC2616++\n> >>community to address.\n> >\n> >Well, part of it could be addressed scheme-by-scheme. For example,\n> >a new scheme could require that only UTF-8 be used in the query\n> >part. It can also be addressed by other technologies, for example,\n> >XForms, which requires the use of UTF-8 in the query part of GET\n> >requests (see http://www.w3.org/TR/xforms/slice11.html#serialize-urlencode).\n> >\n> >\n> >>I would feel *far* more comfortable if I knew that they were aware of\n> >>this and if there were draft proposals visible on this list and being\n> >>checked for feasibility and for 'compatibility' with your drafts.\n> >>I've seen no evidence for this, and you don't appear to\n> >>cross-reference any related HTTP activity in your draft.\n> >>\n> >>\n> >>It is not beyond the bounds of possibility, for example, that the HTTP\n> >>community might conclude that they cannot provide IRI support unless\n> >>your RFC-to-be  includes some kind of marker or syntactic construction\n> >>within \"URIs which were converted from IRIs\" which explicitly\n> >>identifies them as such.\n> >>\n> >>In other words it might be found that all IRIs MUST be mapped into\n> >>some character sequence which IS NOT a 'legal'  URI (by the current\n> >>RFC2396), so that the receiver knows that the reverse process of your\n> >>section 3.2 MUST be applied.\n> >\n> >This would mean choosing a different escape convention.\n> >We considered this years ago, but decided against it.\n> >Using something that is illegal in an URI would not have\n> >worked, and would still not work, with the current infra-\n> >structure.\n> >\n> >\n> >>There are other approaches the HTTP community could take, which\n> >>_would_ be compatible with your current draft, (and I have my own\n> >>candidate solution), but surely there should at least be some kind of\n> >>'existence proof' or 'feasibility study' by which they agree that they\n> >>_can_ work with your proposals before they are finalized?\n> >\n> >I hope what I have explained above is enough of an 'existence proof'.\n> >\n> >Please tell me if you don't think so.\n> >\n> >Regards,    Martin.\n> >\n> >\n> >>Without some kind of 'roadmap' for HTTP use of IRIs I don't see how\n> >>anyone can pass final judgement on your draft.\n> >>\n> >>Please reassure me by telling me I'm an idiot for not knowing about\n> >>XXX or not reading YYY.\n> >>\n> >>Regards,\n> >>\n> >>Chris Haynes\n>\n>\n>\n\n\n\n", "id": "lists-017-1433313"}, {"subject": "Re: Xml Report broke", "content": "On Sat, 2004-05-01 at 00:28, Bjoern Hoehrmann wrote:\n> Hi,\n> \n>   http://validator.w3.org:80/check?uri=http://www.w3.org&output=xml\n>   http://validator.w3.org:8001/check?uri=http://www.w3.org&output=xml\n> \n> The printf for <warning> should refer to ent($_->{Message}) rather\n> than &ent($_).\n\nFixed in CVS, thanks!\n\n\n\n", "id": "lists-017-14344878"}, {"subject": "Checklink on :800", "content": "Hi,\n\n  http://validator.w3.org:8001/checklink gives 500 Internal Server\nError. Now that the right hand navbar is gone, the homepage no longer\nlinks to checklink. I would suggest we replace the \"Download\" link with\na link to checklink.\n\nregards.\n\n\n\n", "id": "lists-017-14351175"}, {"subject": "Re: Checklink on :800", "content": "On Sun, 2004-05-02 at 05:02, Bjoern Hoehrmann wrote:\n\n>   http://validator.w3.org:8001/checklink gives 500 Internal Server\n> Error.\n\nFixed.  That instance was actually an older one (3.9.1) than the current\nproduction one, I updated it to CVS HEAD.  The setup is not too clean at\nthe moment, and it is possible that it'll break again when validator is\nupdated from CVS in case \"cvs up\" removes checklink.pl.  After the next\n:8001 restart, checklink will be using\n/home/ville/LinkChecker/etc/checklink.conf.\n\n>  Now that the right hand navbar is gone, the homepage no longer\n> links to checklink. I would suggest we replace the \"Download\" link with\n> a link to checklink.\n\nWhy not.  Download info is available through Docs, depends how prominent\nwe want that to be if we want to replace or add the checklink link.\n\nBy the way, we need to do something about the download/install/devel\ndocumentation.  Currently there are:\nhttp://validator.w3.org:8001/docs/install.html\nhttp://validator.w3.org:8001/docs/devel.html\nhttp://validator.w3.org:8001/source/\n\nAll those contain more or less the same information, but at least\ndevel.html has outdated prerequisites.  I'll look into it.\n\n\n\n", "id": "lists-017-14358005"}, {"subject": "Validator source/install/devel doc", "content": "On Sun, 2004-05-02 at 16:00, Ville Skytt? wrote:\n\n> By the way, we need to do something about the download/install/devel\n> documentation.  Currently there are:\n> http://validator.w3.org:8001/docs/install.html\n> http://validator.w3.org:8001/docs/devel.html\n> http://validator.w3.org:8001/source/\n\nSuggestion: combine all of this stuff into install.html, and remove\ndevel.html and source/ (and add redirects from them to install.html).\n\n\n\n", "id": "lists-017-14366209"}, {"subject": "Bundle::W3C::Validato", "content": "http://koti.welho.com/vskytta/Bundle-W3C-Validator-0.6.5.tar.gz\n\nI have a CPAN bundle ready and namespace registered for\nBundle::W3C::Validator.  It's very close to the one I submitted some\nmonths ago for demoing purposes, changes since that are cleanups only.\n\nUnless there are objections, I'm ready to upload it to CPAN and commit\nthe stuff somewhere on dev.w3.org.  I'm currently planning to put it to\nvalidator/misc/bundle (on 0_6_0-branch).  Let me know what you think.\n\n\n\n", "id": "lists-017-14373302"}, {"subject": "Re: [meeting] rescheduling 2004-0504", "content": "On Apr 27, 2004, at 09:49, olivier Thereaux wrote:\n> Maybe we could postpone to may 11th?\n\nLet's do this - sorry for the late notice.\n\n-- \nolivier - not really back online\n\n\n\n\n", "id": "lists-017-14380602"}, {"subject": "[Fwd: CPAN Upload: S/SC/SCOP/Bundle-W3C-Validator0.6.5.tar.gz", "content": "On Tue, 2004-05-04 at 00:01, Ville Skytt? wrote:\n\n> Unless there are objections, I'm ready to upload it to CPAN and commit\n> the stuff somewhere on dev.w3.org.  I'm currently planning to put it to\n> validator/misc/bundle (on 0_6_0-branch).  Let me know what you think.\n\nDone in CVS and CPAN.\n\n-----Forwarded Message----- \nFrom: PAUSE <upload@pause.fiz-chemie.de>\nTo: Ville Skytta <ville.skytta@iki.fi>\nSubject: CPAN Upload: S/SC/SCOP/Bundle-W3C-Validator-0.6.5.tar.gz\nDate: Wed, 05 May 2004 20:42:03 +0200\n\nThe URL\n\n    http://koti.welho.com/vskytta/Bundle-W3C-Validator-0.6.5.tar.gz\n\nhas entered CPAN as\n\n  file: $CPAN/authors/id/S/SC/SCOP/Bundle-W3C-Validator-0.6.5.tar.gz\n  size: 2791 bytes\n   md5: e093c9ff42a950dbd756c0639d819390\n\nNo action is required on your part\nRequest entered by: SCOP (Ville Skytt?)\nRequest entered on: Wed, 05 May 2004 18:41:00 GMT\nRequest completed:  Wed, 05 May 2004 18:42:03 GMT\n\n\n\n", "id": "lists-017-14387429"}, {"subject": "Re: Bundle::W3C::Validato", "content": "On May 4, 2004, at 06:01, Ville Skytt? wrote:\n> Unless there are objections, I'm ready to upload it to CPAN and commit\n> the stuff somewhere on dev.w3.org.  I'm currently planning to put it to\n> validator/misc/bundle (on 0_6_0-branch).  Let me know what you think.\n\nThis is nice. I guess an update of the installation documentation is in \norder now.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14396023"}, {"subject": "[check] releasing 0.6.5 tomorrow (?", "content": "As you may have noticed from the CVS notification system, I've been \nrather active polishing the documentation for the Markup Validator \ntoday.\n\nIn spite of a very tight schedule (between a flurry of national \nholidays and an overseas trip) I am inclined to release v0.6.5 of the \nMarkup Validator tomorrow.\n\nRationale:\n  - Most of the issues regarding navigation are, I believe, sorted out;\n  - Most validation / broken links issues have been sorted out, too;\n  - I am now fairly happy with the source/install/devel documentation;\n  - Coordination with W3C Commm is going well and they are ready to \nannounce the release;\n  - I am aware that some problems (may) remain, but we're likely to have \nto do a corrective release in a few weeks however long we take before \nthis release. If we're serious about trying to release often, this is \nthe time to prove it;\n  ... and we haven't made a release in a very, very long time.\n\nThat said, if you think there is any important reason *not to* release, \nplease say so rapidly.\n\nVille, I gather you may want to update validator.spec. The syntax is \nnot so complicated, but I failed to understand some of its subtleties.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14403217"}, {"subject": "Re: [check] releasing 0.6.5 tomorrow / proposed changelo", "content": "On May 6, 2004, at 15:56, olivier Thereaux wrote:\n> In spite of a very tight schedule (between a flurry of national \n> holidays and an overseas trip) I am inclined to release v0.6.5 of the \n> Markup Validator tomorrow.\n\nTomorrow sounds even better now, since the CSS validator has (somehow \nby mistake, I had forgotten to tell Yves I was working on the hTML \nfiles) been updated and now sports the new style/interface. Will be \nnice to update both services around the same time.\n\nI am still struggling with last-minute issues and decisions... Bjoern \npointed out that changes I had made today was breaking a well-known \nbehaviour (clicking on a label should usually select the button, not go \nto another page), so I reverted that.\n\nI also changed the default to non-verbose on the homepage interface, \nthough I think it's OK to leave it preselected for the advanced \ninterface and revalidate box. Your opinions welcome by tomorrow, and in \nany case, none of all this is cast in stone.\n\nBelow is my - proposed - compiled changelog for the announcement. \nOpinions on this much welcome.\n\nGeneral\n- new style, new (simpler) navigation mechanism [ shared with CSS \nvalidator ]\n- Bug tracking system now officially supported \n<http://www.w3.org/Bugs/Public/>\n- updating and expanding catalog of supported character encoding and \ndocument types\n\nFeatures / Bug fixes\n- additional explanations for error messages in \"verbose\" mode - \ncontributed by the www-validator community -.\n- new fallback mechanism when doctype or charset is missing\n- fixed broken markup output bugs\n- internationalization improvements, other small fixes\n\nDocumentation\n  - FAQ (NEW, added to the help page) lists a lot of the usual \nvalidation problems\n  - installation documentation (NEW) makes it much easier to install the \nmarkup validator locally\n  - user and developer's documentation (UPDATED)\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14411423"}, {"subject": "Re: [check] releasing 0.6.5 tomorrow / proposed changelo", "content": "* olivier Thereaux wrote:\n>I am still struggling with last-minute issues and decisions... Bjoern \n>pointed out that changes I had made today was breaking a well-known \n>behaviour (clicking on a label should usually select the button, not go \n>to another page), so I reverted that.\n\n(It also breaks keyboard navigation to some extend as you would\nselect the checkbox, then the label, then the link, etc.)\n\n>I also changed the default to non-verbose on the homepage interface, \n>though I think it's OK to leave it preselected for the advanced \n>interface and revalidate box. Your opinions welcome by tomorrow, and in \n>any case, none of all this is cast in stone.\n\nIt would somehow suggest that the results you got in the first place\nalready *are* verbose and there is no point in re-validating it. I\nhad similar issues with, AFAIR, the show source checkbox, as it was\nunchecked and yet it showed the source.\n\n>Below is my - proposed - compiled changelog for the announcement. \n>Opinions on this much welcome.\n>\n>General\n>- new style, new (simpler) navigation mechanism [ shared with CSS \n>validator ]\n\nI think we should not announced that this is \"shared\" with the CSS\nValidator. I for example get the german version of the CSS Validator\nby default which is not updated and it's currently a bit unfinished...\n\nWe should probably also point out that this is more a maintenance\nrelease than The Next Generation.\n\n\n\n", "id": "lists-017-14420783"}, {"subject": "Re: [check] releasing 0.6.5 tomorrow / proposed changelo", "content": "On May 7, 2004, at 00:36, Bjoern Hoehrmann wrote:\n>  I had similar issues with, AFAIR, the show source checkbox, as it was\n> unchecked and yet it showed the source.\n\nIndeed, forcing source display is yet another \"love it or hate it\" \ndiscussion. I wrote (in w-v@, I think, that I did not think the reason \nwhy it was done in the first place made sense any more since snippets \nof code are given with the errors. So I removed the override. I'll \nnote, as David said on w-v today, that all this would indeed be easier \nif we could record users' preferences.\n\n> I think we should not announced that this is \"shared\" with the CSS\n> Validator. I for example get the german version of the CSS Validator\n> by default which is not updated and it's currently a bit unfinished...\n\nGood point.\n\n> We should probably also point out that this is more a maintenance\n> release than The Next Generation.\n\nYes.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14430110"}, {"subject": "Re: [check] releasing 0.6.5 tomorrow (?", "content": "On Thu, 2004-05-06 at 09:56, olivier Thereaux wrote:\n> As you may have noticed from the CVS notification system, I've been \n> rather active polishing the documentation for the Markup Validator \n> today.\n\nThe changes in content look mostly good to me.  I've fixed some bugs\nhere and there, but one biggish one remains: we cannot use 'id=\"foo\"\nname=\"foo\"' for <p>, <div>, <hX> etc since the Validator claims to be\nXHTML 1.0 Strict (== no \"name\" attribute for those elements).  There are\nquite a few places in the docs and the script output where this breakage\noccurs ATM.\n\n> That said, if you think there is any important reason *not to* release, \n> please say so rapidly.\n\nThe above must definitely be fixed before releasing IMO.\n\n> Ville, I gather you may want to update validator.spec. The syntax is \n> not so complicated, but I failed to understand some of its subtleties.\n\nYeah, it's fairly simple, usually just changing the version numbers and\nURLs that point to the tarballs is enough.\n\nThe only new thing that needs attention now is that a relative URL is\nused to point to /source/, instead of the old \"hardcoding\" of\nv.w.o/source/.  That's not a good thing for local installations, for\nexample the tarball links will definitely be broken in those.\n\nI'll work around this in the spec now, and will make an educated guess\nwhere the validator tarballs will be available for download when they\nare... (hint, hint :)\n\n\n\n", "id": "lists-017-14438578"}, {"subject": "Re: [check] releasing 0.6.5 tomorrow (?", "content": "On May 7, 2004, at 03:48, Ville Skytt? wrote:\n> I've fixed some bugs here and there\n\nThanks. I realize I really shouldn't code like I did, especially when \nso tired :)\n\n>  but one biggish one remains: we cannot use 'id=\"foo\"\n> name=\"foo\"' for <p>, <div>, <hX> etc since the Validator claims to be \n> XHTML 1.0 Strict (== no \"name\" attribute for those elements).\n\nOops. That's right. Bulk fixed, and I went through most of the \ndocuments and output and validated it. Looks good, but still \ncross-checking.\n\n> The only new thing that needs attention now is that a relative URL is \n> used to point to /source/, instead of the old \"hardcoding\" of\n> v.w.o/source/.  That's not a good thing for local installations, for \n> example the tarball links will definitely be broken in those.\n\nShould not be a problem if the actual links to the tarballs are \nabsolute and pointing to v.w.o, right? I changed the ones I had \nforgotten.\n\n> I'll work around this in the spec now, and will make an educated guess \n> where the validator tarballs will be available for download when they \n> are... (hint, hint :)\n\n... or the other way around. I'll name them after what you named them \n(and the naming scheme is pretty straightforward) :)\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14447189"}, {"subject": "new release (check), new serve", "content": "I finished the release for check v0.6.5 this morning. Apparently \neverything went well, and we're being put on the W3C Homepage as I \nwrite this. So kudos and thanks for the great work, I am incredibly \npleased with our progress.\n\nJust after that I discussed with Systeam and we finally decided to \nproceed with the hardware switch for validator.w3.org.\n\nThere again, all seems well, but should anything horrible (or just \nannoying) happen while I'm away (I'll be traveling in the next few \ndays), please contact either Dom or sysreq@ so that they can fix, or \nrevert to the old server.\n\nThanks\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14455990"}, {"subject": "Please use misc/mkrelease.sh for release tarball", "content": "On Fri, 2004-05-07 at 04:48, olivier Thereaux wrote:\n> I finished the release for check v0.6.5 this morning.\n\n*applause*\n\nBut could we please use misc/mkrelease.sh for creating the release\ntarballs?\n\nIt cleans up extra files, fixes permissions and modes inside the\ntarballs, and creates the (versioned) directory structure that most of\nthe world uses, and which the RPM spec file expects (--> the RPM build\nis broken at the moment).\n\nUsage:\n\n  $ mkdir foo\n  $ cd foo\n  $ cvs -z3 -d:pserver:anonymous@dev.w3.org:/sources/public export -r validator-0_6_5 validator\n  $ cd validator\n  $ misc/mkrelease.sh 0.6.5\n  $ ls *.tar.gz\n  sgml-lib-0_6_5.tar.gz  validator-0_6_5.tar.gz\n\nI would appreciate it if the release tarballs currently at v.w.o would\nbe replaced with ones created by this script.\n\n\n\n", "id": "lists-017-14463408"}, {"subject": "Re: [check] releasing 0.6.5 tomorrow (?", "content": "On Fri, 2004-05-07 at 01:16, olivier Thereaux wrote:\n\n> > The only new thing that needs attention now is that a relative URL is \n> > used to point to /source/, instead of the old \"hardcoding\" of\n> > v.w.o/source/.  That's not a good thing for local installations, for \n> > example the tarball links will definitely be broken in those.\n> \n> Should not be a problem if the actual links to the tarballs are \n> absolute and pointing to v.w.o, right?\n\nSort of.  But the (local) source, installation etc. docs and the actual\nonline tarballs may easily get out of sync, trivially so if the links\npoint to the unversioned validator.tar.gz and sgml-lib.tar.gz.  And if\nthey point to the versioned ones there is one more easily forgotten\nplace to keep up to date in the docs at release times.\n\nI (still) do not include anything from under /source/ in the RPMs, but\npoint to v.w.o/source/ instead.  A bit ugly, but should always work.\n\n\n\n", "id": "lists-017-14471635"}, {"subject": "Re: Please use misc/mkrelease.sh for release tarball", "content": "On May 7, 2004, at 12:53, Ville Skytt? wrote:\n> But could we please use misc/mkrelease.sh for creating the release\n> tarballs?\n\nOh, didn't know we had a specific script. scripts++. Done.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14479200"}, {"subject": "[meetings] next 2004-0511, wiki opene", "content": "All,\n\na reminder that our next meeting is tomorrow. Following a suggestion \nfrom Bjoern, we now have a drafty wiki page for QA-dev, where we'll be \nable to all read/edit agenda, action items, etc.\n\nhttp://esw.w3.org/topic/QaDev\n\nFor the reference, tomorrow's meeting will be held\n- 16:30 UK,\n- 17:30 France / Germany / Norway,\n- 18:30 Finland,\n- 11:30 Montreal (I'm in Montreal/Boston this week)\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14486537"}, {"subject": "Re: [meetings] next 2004-0511, wiki opene", "content": "On Mon, 10 May 2004, olivier Thereaux wrote:\n\n> All,\n>\n> a reminder that our next meeting is tomorrow. Following a suggestion\n> from Bjoern, we now have a drafty wiki page for QA-dev, where we'll be\n> able to all read/edit agenda, action items, etc.\n>\n> http://esw.w3.org/topic/QaDev\n\nPoint of order: I just corrected a typo on there (under 1.4.2 you had\n\"Mew interface\"), and it made no attempt to verify who I am.  That\nseems to me perhaps excessively open.\n\nBTW, on action items, I've installed mod_validator @qa-dev, but have\na few problems with it.  Watch this space.\n\n-- \nNick Kew\n\nNick's manifesto: http://www.htmlhelp.com/~nick/\n\n\n\n", "id": "lists-017-14493990"}, {"subject": "Re: [meetings] next 2004-0511, wiki opene", "content": "On May 10, 2004, at 18:28, Nick Kew wrote:\n>> http://esw.w3.org/topic/QaDev\n>  and it made no attempt to verify who I am.\n\nIt did log who you were (your host at least) and kept a diff.\n\n>  That seems to me perhaps excessively open.\n\nThat's the idea of a wiki, yes.\nExcessively open, which is generally ok for some types of content.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14502401"}, {"subject": "[meeting] notes and log 2004-051", "content": "Summary of new Action Items:\n\nAction Item (Ville): send 0.6.6 bug roundup/status/plan -> qa-dev\nAction Item (olivier): harmonization of checklink's layout based on \ncurrent markup validator\n\n\nSummary of discussions:\n\n  * Markup Validator\n\nNew design caused a lot of reactions - good and bad -. Style can be \nimproved still, and we will welcome suggestions, although small \nmodifications will be much more likely to be accepted than larger, \nradical re-designs, and as usual, it's best to submit a patch.\n\n,text and ,tablin in Jump bar not very popular, they'll be replaced as \nwe move toward better multiple output. Some discussion on using XSLT \nfor that, Bjoern/Nick interested in doing it, though no immediate plan \nto do this before we complete modularization.\n\n  - 0.6.6 release within 1/2 weeks (without beta), including minor fixes.\n    Ville will lead the bug roundup.\n  - 0.6.5 merged with HEAD (with template code), result in the process \nof being fixed.\n  - goal for 0.7: get rid of all inline HTML not needed\n  - modularization is next big goal\n\n* Link Checker\n\nA few bugs left to fix, and the interface to be modified to be \nreasonably consistent with Markup Validator, then we'll proceed with a \nrelease\n\n* Others\n\nBugzilla will be upgraded soon, then CVSWeb (Ville and olivier to \ncoordinate)\n\nLog attached, as usual.\n\n\n\n-- \nolivier\n\n\n\n\ntext/plain attachment: qadev-20040511.txt\n\n\n\n\n", "id": "lists-017-14510076"}, {"subject": "0.6.6 bug roundu", "content": "Here's the validator 0.6.6 roundup, sorry for the delay.\n\nAlready fixed in CVS:\n\n* Don't output line number links if we're not showing the source.\n\n* Avoid trashing server error log (pop instead of undef the last\n  line of ESIS for valid cases).\n\n* Install documentation fixed wrt requred perl modules and RPM\n  download location.\n\nOpen issues that I think should be fixed in 0.6.6:\n\n* Warnings printed twice:\n  http://www.w3.org/Bugs/Public/show_bug.cgi?id=710\n\n* onsgmls error/warning locators beyond EOL (I have a patch):\n  http://www.w3.org/Bugs/Public/show_bug.cgi?id=715\n\n* Internal server error\n  http://www.w3.org/Bugs/Public/show_bug.cgi?id=716\n\n* Output of parse tree trashes error log when elements without an entry \n  in eref.cfg are met in onsgmls output, such as <embed>; I have a local\n  fix for this.\n\n* \"Show source\" discards source indentation, there are many \n  www-validator@ reports about this.\n\n* Doctype/charset override/fallback issues (I have not looked into\n  this in great detail, but have observer similar issues):\n  http://lists.w3.org/Archives/Public/www-validator/2004May/0089.html\n\n* Verbose on or off by default?  Many seem to prefer \"on\" but as Bjoern\n  noted, we shouldn't change the defaults too often.  IMO we now still\n  can change if found reasonable since the new validator will have been\n  out for only 2'ish weeks when 0.6.6 is out.  Whatever will be the \n  default in 0.6.6 is what we should stick with.\n\n* Ugly fonts issues, use only generic families?\n\n* Not strictly 0.6.6 related, but while I'm at it: installation issue,\n  v.w.o runs Apache 1.3.27 which has a pretty nasty CGI zombie problem,\n  easily noticeable with \"top\" on v.w.o.  Perhaps upgrade?  There are\n  also numerous security issues fixed in later 1.3.x's if the 1.3 series\n  is what we wish to stick with.\n  http://www.apache.org/dist/httpd/CHANGES_1.3\n  http://archive.apache.org/gnats/6961\n  http://archive.apache.org/gnats/8664\n\nHopefully I did not miss too many issues.  Bugzilla now has a 0.6.6\ntarget milestone, to which I've set the above couple of filed issues. \nComments, takers?  I will file the rest of the yet unfiled issues to\nBugzilla in the weekend.\n\n\n\n", "id": "lists-017-14518174"}, {"subject": "RE: Migration of HTTP to the use of IRIs [queryclarify16", "content": "> From:  Chris Haynes\n> Sent: Thursday, May 06, 2004 4:50 AM\n>\n> Actually, my original core concern has now been covered in your\nsection\n> 1.2.a - Applicability, where you make it clear that \"the intent is not\nto\n> introduce IRIs into contexts that are not defined to accept them\".\n>\n> This now makes it clear that new schemas will be required to replace\n> http: , https: etc. These will need to be self-identifying in some\nway, so\n> that receiving equipment will know that an IRI is being presented.\n>\n> So, as I commented last June, I await with interest the recognition\namong\n> those responsible for the HTTP schema that new schemas with new names\nare\n> required before IRIs can be used.\n\nI'd like to comment on that. The IRI spec is fairly explicit on that IRI\ncan be used as presentation elements for URI protocol elements (ref\nclause 3 intro). This is to recognize that applications out there have\nnot waited for us for creating presentation layers that use non ascii\nnative characters for schemes that supposedly should not use them (such\nas http). The presentation layer principle is there to support that. So\nI expect IRI to be used for both purposes:\n- presentation layer for existing URI schemes\n- core layer for new schemes exclusively defined using IRI for protocol\nelements syntax.\n\nFor a while I'd expect the vast majority of IRI usage to be in the first\ncategory.\n\nMichel\n\n\n\n", "id": "lists-017-1452356"}, {"subject": "Comma Tool Setu", "content": "Hi,\n\n  Regarding comma tools, I use a setup like\n\n  <IfModule mod_rewrite.c>\n    RewriteEngine on\n    RewriteCond  %{QUERY_STRING} , [OR]\n    RewriteCond  %{REQUEST_URI} ,\n    RewriteRule (.*) /cgi-bin/r.pl [L]\n  </IfModule>\n\nthis would call the r.pl script for all request URIs containing a comma,\nregardless of whether in the path or the query string. This allows\ncombining scripts and comma tools and gives further flexibility for the\nactual tool setup. It is possible to chain comma tools, for examle I can\ndo ,tidy,validate,validate to validate the Validators output for HTML\nTidy's output for some document; or I can pass parameters to comma tools\nlike ,xslt=http://example.org/tosvg,svg2png which would transform the\ndocument using http://example.org/tosvg and convert the resulting SVG to\nPNG using the ,svg2png tool...\n\nI had to use a script here as I could not convince mod_rewrite to\nproperly escape the URI without using a RewriteMap (and RewriteMap is\nnot available from a .htaccess file...) It should be possible to do the\nsame without a script but it would probably be a bit more complicated...\nThe script is then something like\n\n  #!perl -w\n  use strict;\n  use warnings;\n  use URI::Escape 'uri_escape';\n  \n  sub tool\n  {\n    my $req = shift;\n    return unless defined $req;\n  \n    my ($new, $tool, $param) = $req =~ /^(.*),(\\w+)(?:=(.+?))?$/;\n    return unless defined $tool;\n  \n    my %tools = map { split/\\s+/ } <DATA> ;\n    my $dst = $tools{$tool};\n    return unless defined $dst;\n  \n    my $host = $ENV{HTTP_HOST} || $ENV{SERVER_NAME};\n    return unless defined $host;\n    $host =~ s/:\\d+$//;\n  \n    $new = uri_escape(\"http://$host$new\", \"^A-Za-z0-9\\-_.!~*'()\");\n    $param = uri_escape($param, \"^A-Za-z0-9\\-_.!~*'()\");\n  \n    $dst =~ s:\\$uri:$new:;\n    $dst =~ s:\\$param:$param: if defined $param;\n  \n    return $dst;\n  }\n  \n  my $tool = tool $ENV{REQUEST_URI} ;\n  if (not defined $tool)\n  {\n    print \"Status: 404\\n\\n\";\n  }\n  else\n  {\n    print \"Status: 302\\n\";\n    print \"Location: $tool\\n\\n\";\n  }\n  \n  __DATA__\n  links   http://www.google.com/search?q=link:$uri\n  text    http://cgi.w3.org/cgi-bin/html2txt?url=$uri\n  xslt    http://w3.org/2000/06/webdata/xslt?xslfile=$param&xmlfile=$uri\n  ...\n\nI could not convince Apache+SSL 1.3.12 to use this for URIs containing\nquery strings (i.e., the server just hangs) but it works flawlessly on\nApache 1.3.31 and Apache 2.0.48...\n\nregards.\n\n\n\n", "id": "lists-017-14527554"}, {"subject": "Re: 0.6.6 bug roundu", "content": "* Ville Skytt? wrote:\n>* \"Show source\" discards source indentation, there are many \n>  www-validator@ reports about this.\n\nWhy do we do what we currently do? And how to fix it?\n\n>* Doctype/charset override/fallback issues (I have not looked into\n>  this in great detail, but have observer similar issues):\n>  http://lists.w3.org/Archives/Public/www-validator/2004May/0089.html\n\nYeah, this needs to be fixed... why do we default to UTF-8 and not\nISO-8859-1 or Windows-1252? It seems rather unlikely that defaulting\nto UTF-8 yields in desireable results... maybe we should use\nEncoding::Guess with UTF-8, ISO-2022-JP, Shift_JIS, Big5, ISO-8859-1\nand Windows-1252 or something? Or just try UTF-8 first and then ISO-\n8859-1 with Iconv?\n\n>* Verbose on or off by default?  Many seem to prefer \"on\" but as Bjoern\n>  noted, we shouldn't change the defaults too often.\n\nI am not sure whether those in favor actually had a close look at it...\nMany fell in love with this fuzzy fussy feature and we dropped it.. I'm\nall for verbose mode (and on by default), but I'd say it's currently not\nready for prime time. If we keep it off, we should remove the hidden\nverbose config option, it generates overly long URIs; and turn it off\nin check if it defaults to on.\n\n\n\n", "id": "lists-017-14536402"}, {"subject": "Re: 0.6.6 bug roundu", "content": "On Fri, 2004-05-14 at 18:24, Bjoern Hoehrmann wrote: \n> * Ville Skytt? wrote:\n> >* \"Show source\" discards source indentation, there are many \n> >  www-validator@ reports about this.\n> \n> Why do we do what we currently do?\n\nI don't know, maybe it's an oversight.  It was introduced in 0.6.5b1:\nhttp://dev.w3.org/cvsweb/validator/htdocs/results.css?only_with_tag=validator-0_6_0-branch#rev1.13.2.19\n\n>  And how to fix it?\n\nCandidate fix at:\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=717\nTesting/comments welcome.\n\n> >* Doctype/charset override/fallback issues (I have not looked into\n> >  this in great detail, but have observer similar issues):\n> >  http://lists.w3.org/Archives/Public/www-validator/2004May/0089.html\n> \n> Yeah, this needs to be fixed... why do we default to UTF-8 and not\n> ISO-8859-1 or Windows-1252? It seems rather unlikely that defaulting\n> to UTF-8 yields in desireable results... maybe we should use\n> Encoding::Guess with UTF-8, ISO-2022-JP, Shift_JIS, Big5, ISO-8859-1\n> and Windows-1252 or something? Or just try UTF-8 first and then ISO-\n> 8859-1 with Iconv?\n\nAhh... Encode::Guess!  I have been looking for something like this,\nthanks for the pointer!  Dunno if it's the right thing to do here\nthough, we still have the \"strong default\" of HTTP, ISO-8859-1, for\ncases where no encoding is explicitly set.\n\nI think this is just a bug introduced somewhere near the final 0.6.5\nrelease as I don't remember seeing it earlier.\n\nAnyway, there should be an option to override the encoding, cases like\nthis are annoying:\nhttp://validator.w3.org/check?uri=http%3A%2F%2Fwww.hut.fi\n\n> >* Verbose on or off by default?  Many seem to prefer \"on\" but as Bjoern\n> >  noted, we shouldn't change the defaults too often.\n> \n> I am not sure whether those in favor actually had a close look at it...\n> Many fell in love with this fuzzy fussy feature and we dropped it.. I'm\n> all for verbose mode (and on by default), but I'd say it's currently not\n> ready for prime time.\n\nOk.\n\n>  If we keep it off, we should remove the hidden\n> verbose config option, it generates overly long URIs; and turn it off\n> in check if it defaults to on.\n\n+1\n\n\n\n", "id": "lists-017-14544925"}, {"subject": "Re: 0.6.6 bug roundu", "content": "On Fri, 2004-05-14 at 10:00, Ville Skytt? wrote:\n> Here's the validator 0.6.6 roundup, sorry for the delay.\n\n...and now in Bugzilla:\nhttp://www.w3.org/Bugs/Public/buglist.cgi?product=Validator&target_milestone=0.6.6\n\nAs discussed in this week's meeting, could someone with enough\npermissions set the QA contact for validator and link checker to\npublic-qa-dev@ ?\n\n\n\n", "id": "lists-017-14554483"}, {"subject": "User control of validator results pages", "content": "As hinted a few times on IRC, I'd like to see the presentation of\nresults pages compacted a little, with the full gory detail a\nuser option.\n\nUgly prototype hacked up (from a real results page) at\nhttp://qa-dev.w3.org/~nick/check.html\n\nAnyone agree or disagree with this as a principle?\n\n-- \nNick Kew\n\nNick's manifesto: http://www.htmlhelp.com/~nick/\n\n\n\n", "id": "lists-017-14561956"}, {"subject": "Re: 0.6.6 bug roundu", "content": "On May 15, 2004, at 19:51, Ville Skytt? wrote:\n> As discussed in this week's meeting, could someone with enough\n> permissions set the QA contact for validator and link checker to\n> public-qa-dev@ ?\n\nActually you have the permissions to edit the products and components, \nbut the user had to be created first. Done.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14569299"}, {"subject": "Re: 0.6.6 bug roundu", "content": "On Sun, 2004-05-16 at 22:03, olivier Thereaux wrote:\n> On May 15, 2004, at 19:51, Ville Skytt? wrote:\n> > As discussed in this week's meeting, could someone with enough\n> > permissions set the QA contact for validator and link checker to\n> > public-qa-dev@ ?\n> \n> Actually you have the permissions to edit the products and components, \n> but the user had to be created first. Done.\n\nAh, thanks.  It was a user error, I could not find the place where to\nset the QA contact so I assumed it's due to insufficient permissions.\n\n\n\n", "id": "lists-017-14576797"}, {"subject": "Re: 0.6.6 bug roundu", "content": "On May 15, 2004, at 19:51, Ville Skytt? wrote:\n> As discussed in this week's meeting, could someone with enough\n> permissions set the QA contact for validator and link checker to\n> public-qa-dev@ ?\n\nAfter some discussion, I moved the bugzilla announcements to \nwww-validator-cvs@ which may be better for tracking than the discussion \nlist. Can be changed later.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14584291"}, {"subject": "v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>Here's the validator 0.6.6 roundup, sorry for the delay.\n>\n>Already fixed in CVS: [???]\n>Open issues that I think should be fixed in 0.6.6: [???]\n\nAccording to my in-memory list and Bugzilla, these should now all be dealt\nwith[0]. Ready for 0.6.6?\n\n\n\n[0] - Except for [[[\n    * Internal server error\n      http://www.w3.org/Bugs/Public/show_bug.cgi?id=716\n    ]]] which isn't really release-critical.\n\n\n- -- \nBy definition there is _no_way_ any problem can be my fault. Any problems\nyou think you can find in my code are in your imagination. If you continue\nwith such derranged imaginings then I may be forced to perform corrective\nbrain surgery... with an axe!                            -- Stephen Harris\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKmGbaPyPrIkdfXsEQLm8ACg+y+SxOdPUPeOVnlQSqmofngpHa4An1Dv\nCr+tW20hgbxQ5v9MyplByZQp\n=Ic5z\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14591674"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On May 18, 2004, at 12:43, Terje Bless wrote:\n> According to my in-memory list and Bugzilla, these should now all be \n> dealt\n> with[0].\n\nGreat!\n\n> Ready for 0.6.6?\n\nThere were quite a few modifications done in the past couple days.\nIt seems to make sense to test for just a few days and release. What do \nyou think?\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14600356"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On Tue, 2004-05-18 at 12:15, olivier Thereaux wrote:\n> On May 18, 2004, at 12:43, Terje Bless wrote:\n>\n> > Ready for 0.6.6?\n> \n> There were quite a few modifications done in the past couple days.\n> It seems to make sense to test for just a few days and release. What do \n> you think?\n\nI'd like to hear opinions from others wrt\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=705\n\nMy .02?: remove the catalog fallback in 0.6.6, try to find a\nnon-disruptive way to re-enable the functionality for 0.7.0.\n\n\n\n", "id": "lists-017-14607930"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "* Ville Skytt?? wrote:\n>I'd like to hear opinions from others wrt\n>http://www.w3.org/Bugs/Public/show_bug.cgi?id=705\n>\n>My .02???: remove the catalog fallback in 0.6.6, try to find a\n>non-disruptive way to re-enable the functionality for 0.7.0.\n\nYou mean, the Validator should say \"FATAL ERROR\" again?\n\n\n\n", "id": "lists-017-14616107"}, {"subject": "Re: what should the charset be in the response to the serve", "content": "Hello Chris,\n\nMany thanks for your reply. I have copied the IRI list\nbecause I think this discussion is relevant for the current\ndraft.\n\nAt 13:38 04/05/06 +0100, Chris Haynes wrote:\n>Thanks for the response, Martin,\n>\n>I only noticed this response _after_ I had replied to your other response \n>on the\n>IRI list, so I apologize that my earlier response did not take into \n>account this\n>message of yours.\n>\n>Trying to bring this topic to closure, I think my core worry arises each time\n>there are what-appear-to-me-to-be normative statements that 'the page encoding\n>determines the encoding used in requests derived from that page' - \n>ignoring the\n>possibility of users having changed the encoding setting.\n>\n>We obviously both agree that users 'should not' use these controls (just as I\n>diapprove of the use of 'tone controls' and spectral filters in Hi Fi systems\n>for other than 'loudness' compensation), but I get worried every time the\n>possibility of their use is ignored.\n>\n>The situation is not purely  'theoretical ' I've seen reports that it is \n>common\n>practice in some countries for people to switch to their 'national' character\n>set every time they appear to have a problem in viewing a page - which \n>could be\n>occasioned by their browser not having UTF-8 support.\n\nOk, so let's have a look at this case: Either switching to their 'national'\ncharacter encoding solves the problem, in which case the page was badly\nlabeled, and the page author is to blame. Or switching does not solve\nthe problem, in which case the user may even not be able to read the\npage, and therefore won't fill in the form. Or the page only contains\nUS-ASCII characters to begin with, and the user doesn't have any reason\nto switch encodings.\n\nThat probably leaves us with just one intermediate case: The page is\nmostly in US-ASCII, but with a few other characters (e.g. 'smart quotes',...).\nThe user sees some problem, tries to fix it by switching the encoding.\nThat doesn't help, so the user gives up, and just fills in the form\n(which is readable enough to complete the task).\n\nIf you know about any other scenarios where switching encoding and then\nfilling in the form with a wrong encoding can happen realistically,\nplease tell me.\n\n\n>I help provide support to the users of an open-source web server, and we\n>frequently get requests for help from people managing web services who, having\n>read the appropriate RFCs and W3 specs in detail, had not appreciated that \n>user\n>agents can change the encoding in ways which the request-receiving server \n>cannot\n>detect.\n\nI was giving a tutorial about Web internationalization for years, and\nthe issue of encoding in forms always came up, but from the time when\nthe first browsers supporting UTF-8 came out, that was always given as\nan answer, and I haven't heard anybody question this before you. But\nof course your mileage may vary.\n\nBut there is an additional point: A server isn't helpless against users\nchanging the encoding. UTF-8 has the very helpful property of having\nvery specific byte sequences. It is easy to check these with a\nregular expression, for an example, please see\nhttp://www.w3.org/International/questions/qa-forms-utf-8.html.\n\n\n>I suppose I'm just keen to make sure that wherever this topic appears, the\n>potential behavior of the vast majority of browsers in the world is adequately\n>and completely described.\n>\n>If there were an RFC somewhere which said that the user agent 'MUST NOT' \n>change\n>the encoding, and that real-world browsers were ignoring this stricture, I \n>would\n>agree that other RFCs were right to describe what should be, rather than what\n>is.\n>\n>But as far as I know, the ability for users to override the encoding does not\n>contravene any existing RFC, and therefore other RFCs ought at least to\n>recognize that possibility, and not infer, by omission, a level of certainty\n>which can never be assured.\n>\n>I think I would have a very poor view of any web site which told me it was my\n>fault a request got garbled because I made use of a freely-available \n>control on\n>my browser.\n>\n>Let me try to conclude this by just asking that, so long as user control over\n>the encoding is permitted by RFCs, that possibility is explicitly \n>recognized by\n>other RFCs., and that we dont try to pretend that it does not exist or, even\n>worse, that failures and errors in decoding are the user's fault for \n>breaking an\n>unwritten, untestable  non-rule.\n\nI'm still not sure to what extent this is really happening. But I have\nclarified this issue by expanding the sentence in question as follows:\n\n\"Likewise, when setting up a new Web form using UTF-8 as the encoding\nof the form page, the returned query URIs will use UTF-8 as an encoding\n(unless the user for whatever reason changes the character encoding)\nand will therefore be compatible with IRIs.\"\n\nThis leaves it to the reader to judge for him/herself how high\nthe probability is that the user is switching code pages.\n\nRegards,    Martin.\n\n\n>Chris\n>\n>\n>----- Original Message -----\n>From: \"Martin Duerst\" <duerst@w3.org>\n>To: \"Chris Haynes\" <chris@harvington.org.uk>; <www-international@w3.org>\n>Cc: \"Michel Suignard\" <michelsu@microsoft.com>\n>Sent: Thursday, May 06, 2004 8:04 AM\n>Subject: Re: what should the charset be in the response to the server\n>\n>\n> > Hello Chris,\n> >\n> > In trying to clear up the remaining IRI issues, I found out that\n> > I planned to reply to this message of yours, but didn't get around\n> > to do it.\n> >\n> > At 17:20 03/08/07 +0100, Chris Haynes wrote:\n> >\n> > >  \"Martin Duerst\" Replied:\n> > >\n> > >\n> > > > At 12:15 03/07/26 +0100, Chris Haynes wrote:\n> > > >\n> > > > >  \"Jungshik Shin\" replied at: Saturday, July 26, 2003 11:31 AM\n> > > >\n> > > > > >   It also depends on whether or not you set 'send URLs always in\n> > > > >UTF-8' in\n> > > > > > Tools|Options(?) in MS IE.\n> > > > > >\n> > > > >\n> > > > >True, but I'm trying to find a 'reliable' mechanism which is not\n> > > > >dependent on user-accessible controls.\n> > > > >IMHO, this is also a 'dangerous' option, in that it goes agains the\n> > >de\n> > > > >facto conventions and anticipates (parhaps incorrectly) the\n> > > > >recommendations of the proposed IRI RFC. It can only safely be used\n> > > > >with a 'consenting' server site.\n> > > >\n> > > > Sorry, no. The main dangerous thing is that authors use non-ASCII\n> > > > characters in URIs (without any %HH escaping) when this is clearly\n> > > > forbidden.\n> > > >\n> > > > Regards,  Martin.\n> > >\n> > >\n> > >Martin,\n> > >\n> > >Are you saying that you approve of relying on users to select the\n> > >(Microsoft-specific)  'send URLs always in\n> > >UTF-8'  menu option  to ensure that UTF8 gets returned to the server?\n> > >\n> > >That is what was being suggested.\n> >\n> > Well, my above statement was meant in the following sense:\n> > There is NO spec that would allow inclusion of non-ASCII\n> > characters in URIs. The IRI spec is the first one that\n> > defines something similar to an URI that actually allows this.\n> > Any authors that for example put raw iso-8859-1 characters\n> > into an URI in a page in iso-8859-1 are therefore wrong;\n> > any 'it works' effect is coincidental, not according to specs.\n> > Suggesting that a browser that anticipates a future spec\n> > (the IRI spec) is dangerous, while (implicitly) blessing\n> > browsers and pages that don't conform to any spec is in\n> > my eyes a dangerous idea.\n> >\n> >\n> > >My argument was that any current HTTP-like system in which the\n> > >character encoding could be modified by menu controls in the user\n> > >agent, (and in which the actual encoding used is *not* conveyed in the\n> > >request) was inherently unreliable.\n> >\n> > I think we have to look at different parts of a HTTP request separately.\n> > There are mainly two parts: the 'path' part and the 'query' part.\n> >\n> > With respect to the path part, this is indeed influenced by the\n> > 'send URLs always in UTF-8' option in MS IE. But there are ways\n> > to get around this. For an example, see my Apache 'mod_fileiri'\n> > module, which allows to map requests both in a legacy encoding and\n> > in UTF-8 back to the file in question.\n> > [see http://www.w3.org/2003/06/mod_fileiri/Overview.html for an overview,\n> > including pointers to the actual code and to a talk of mine].\n> >\n> > With respect to the query part, this is not affected by the\n> > 'send URLs always in UTF-8' option in MS IE. The query part\n> > is always sent in the encoding of the actual page, except\n> > for some browsers that implement the 'accept-charset' attribute\n> > on <form>. But for queries, it is rather easy to e.g. convert\n> > all the forms related to that query URI to UTF-8.\n> >\n> > You are right that the (perceived) character encoding of the\n> > page can affect both parts. Of course, users might always\n> > change the character encoding, and as a result send something\n> > that the server gets as garbage. However, users don't use\n> > menus just for fun, and if anybody would ever come and complain,\n> > the server side would be very justified to say \"don't mess\n> > around with the settings if you expect your queries to work\".\n> > So this is very much a theoretical concern.\n> >\n> >\n> > Regards,    Martin.\n> >\n> >\n\n\n\n", "id": "lists-017-1462380"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On Wed, 2004-05-19 at 00:07, Bjoern Hoehrmann wrote:\n> * Ville Skytt? wrote:\n> >I'd like to hear opinions from others wrt\n> >http://www.w3.org/Bugs/Public/show_bug.cgi?id=705\n> >\n> >My .02?: remove the catalog fallback in 0.6.6, try to find a\n> >non-disruptive way to re-enable the functionality for 0.7.0.\n> \n> You mean, the Validator should say \"FATAL ERROR\" again?\n\nI mean that the validator should not say \"This Page Is Valid HTML 4.01\nTransitional!\" for clearly bogus cases, such as:\nhttp://qa-dev.w3.org/wmvs/0.6/check?uri=http%3A%2F%2Fkoti.welho.com%2Fvskytta%2Fbug705.html\n\nI don't care about the actual implementation that much.  If that's the\nbest that we can do for 0.6.6, IMO \"FATAL ERROR\" + a doctype override\ndrop-down box sitting next to it is a lot better than the current\nbehaviour.\n\n\n\n", "id": "lists-017-14624098"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "* Ville Skytt?? wrote:\n>> >http://www.w3.org/Bugs/Public/show_bug.cgi?id=705\n>> >\n>> >My .02???: remove the catalog fallback in 0.6.6, try to find a\n>> >non-disruptive way to re-enable the functionality for 0.7.0.\n>> \n>> You mean, the Validator should say \"FATAL ERROR\" again?\n>\n>I mean that the validator should not say \"This Page Is Valid HTML 4.01\n>Transitional!\" for clearly bogus cases, such as:\n>http://qa-dev.w3.org/wmvs/0.6/check?uri=http%3A%2F%2Fkoti.welho.com%2Fvskytta%2Fbug705.html\n\nSure, but\n\n>I don't care about the actual implementation that much.  If that's the\n>best that we can do for 0.6.6, IMO \"FATAL ERROR\" + a doctype override\n>drop-down box sitting next to it is a lot better than the current\n>behaviour.\n\nwe cannot advertise more friendly behavior as great new feature in\n0.6.5 and turn it off in 0.6.6. If that is the only option I'd\nrather say we won't fix it for 0.6.6.\n\n\n\n", "id": "lists-017-14632750"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On Wed, 2004-05-19 at 00:31, Bjoern Hoehrmann wrote:\n> * Ville Skytt? wrote:\n> >> >http://www.w3.org/Bugs/Public/show_bug.cgi?id=705\n> >> >\n> >> >My .02?: remove the catalog fallback in 0.6.6, try to find a\n> >> >non-disruptive way to re-enable the functionality for 0.7.0.\n> >> \n> >> You mean, the Validator should say \"FATAL ERROR\" again?\n> >\n> >I mean that the validator should not say \"This Page Is Valid HTML 4.01\n> >Transitional!\" for clearly bogus cases, such as:\n> >http://qa-dev.w3.org/wmvs/0.6/check?uri=http%3A%2F%2Fkoti.welho.com%2Fvskytta%2Fbug705.html\n> \n> Sure, but\n> \n> >I don't care about the actual implementation that much.  If that's the\n> >best that we can do for 0.6.6, IMO \"FATAL ERROR\" + a doctype override\n> >drop-down box sitting next to it is a lot better than the current\n> >behaviour.\n> \n> we cannot advertise more friendly behavior as great new feature in\n> 0.6.5 and turn it off in 0.6.6. If that is the only option I'd\n> rather say we won't fix it for 0.6.6.\n\nI disagree, but I seem to be in the minority so I'll shut up after\nthis.  If \"friendliness\" and the core task (or reason for existence, if\nyou prefer) of the Validator conflict, to me the solution is clear: be\nhonest, sacrifice friendliness, not validation, to the extent\nnecessary.  And advertising should not get into the way of fixing known\nmajor bugs or backing out (if that's the best we can do) new known buggy\nfeatures.\n\n\n\n", "id": "lists-017-14641520"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>If \"friendliness\" and the core task (or reason for existence, if you\n>prefer) of the Validator conflict, to me the solution is clear: be\n>honest, sacrifice friendliness, not validation, to the extent necessary.\n\nI agree, completely, but \"the extent necessary\" is what's at issue here.\n\n\n>And advertising should not get into the way of fixing known major bugs\n>or backing out (if that's the best we can do) new known buggy features.\n\nI disagree that it's a \"major bug\" (and with the \"advertising\" term in this\ncontext, BTW). The result it produces is certainly catastrophically wrong, but\nonly in a limited set of circumstances; this is only triggered by pages that\nbegin with ??<!DOCTYPE html?? but have some kind of garbage for the FPI/SI.\n\nIn particular, it will _not_ manifest for the most common of these ??? the\nlower-case ??<!doctype?? produced by Netscape's 4.x editor ??? nor for any other\ncase with a missing DOCTYPE Declaration.\n\nThe number of documents that specify a Document Type Name of ??html?? without\ngiving a proper Public or System Identifier is relatively minor; especially\nwhen compared to the number of pages that lack any form of DOCTYPE Declaration\n(which is our biggest problem, and the one this behaviour was designed to deal\nwith).\n\n\nNote also that ??<!DOCTYPE html>?? is perfectly acceptable from an SGML point of\nview; it's an explicit part of the SGML design that the ???receiving??? SGML\nApplication's Parser be able to resolve the External Subset from the Document\nType Name alone[0]. The current issue is one created solely by the odd special\ncase of the Web where certain FPIs ??? and even some SIs ??? are mandated by the\nprose of the relevant specifications.\n\n\nNot to imply that this behaviour isn't wrong and misleading ??? we will have to\nfigure out some way to resolve it eventually ??? but looking at the\ncircumstances that trigger it and the consequences of the failure, when\ncompared to anything we might conceivably do to counteract it in the near\nterm, the former weighs inconsequentially little compared to the latter.\n\n\n\n\n[0] - If ???The Web??? had been conceived with acknowledgement of its SGML\n      roots, you could even conceivably have implied both SGML Declaration\n      and Document Type Definition from the MIME Content-Type ??? while still\n      beeing in perfect alignment with SGML in general ??? and avoided this\n      whole problem alltogether.\n\n\n\n- -- \nIf you believe that will stop spammers, you're sadly misled. Rusty hooks,\nrectally administered fuel oil enemas, and the gutting of their machines,\n*that* stops spammers!                                         -- Saundo\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKrcl6PyPrIkdfXsEQIiFgCgjVjYcvmkkEyXP3IIZDZMe6DcMNYAoJJo\n2/T3LmLIKMCGV4OzU4OnVAIW\n=UdWk\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14650875"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On Tue, 18 May 2004, Ville Skytt? wrote:\n\n> My .02?: remove the catalog fallback in 0.6.6, try to find a\n> non-disruptive way to re-enable the functionality for 0.7.0.\n\nSo long as the headline message tells the user their document\n\"is/isn't valid foo\", I'd strongly agree that we can't allow\nfoo to take a default value.\n\nIf the headline changes to \"pass|fail validation as foo\", we're\nno longer telling a lie when the document isn't actually foo.\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14661325"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nNick Kew <nick@webthing.com> wrote:\n\n>On Tue, 18 May 2004, Ville Skytt?? wrote:\n>\n>>My .02?: remove the catalog fallback in 0.6.6, try to find a\n>>non-disruptive way to re-enable the functionality for 0.7.0.\n>\n>So long as the headline message tells the user their document \"is/isn't\n>valid foo\", I'd strongly agree that we can't allow foo to take a default\n>value.\n>\n>If the headline changes to \"pass|fail validation as foo\", we're no\n>longer telling a lie when the document isn't actually foo.\n\nHmmm. That might make sense in general too. But note that the difference is\nslight, and probably won't make much difference in practice; my guess is that\nit'll be far too subtle a distinction for the users (who lack the context).\n\nOpinions? Ville?\n\n\n\n- -- \nIf you believe that will stop spammers, you're sadly misled. Rusty hooks,\nrectally administered fuel oil enemas, and the gutting of their machines,\n*that* stops spammers!                                         -- Saundo\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKsKM6PyPrIkdfXsEQITmwCgtm3oaGuftSihXFNeF69G8lT/oBUAn31x\nUuGN+mg9bj8vpmo2JXr/Pdip\n=Xvu+\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14669489"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On Tue, 18 May 2004, Ville Skytt? wrote:\n\n> I'd like to hear opinions from others wrt\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=705\n\nAfter entering a comment on that and a quick chat with Terje, I think\nI have it.\n\nBasically, we hack the DTD used as a default fallback:\n\n<!ENTITY % HTML.Version \"-//W3C//DTD HTML 4.01 PROVISIONAL//EN\">\n<!ENTITY % version \"version CDATA #FIXED '%HTML.Version;'\">\n<!ATTLIST HTML %i18n; %version;>\n\nNow onsgmls will give us a version string of PROVISIONAL\nthat we can test for.\n\nThat's a good excuse for some further hacks to the default DTD too :-)\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14678454"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On Wed, 2004-05-19 at 10:18, Terje Bless wrote:\n> Nick Kew <nick@webthing.com> wrote:\n> \n> >So long as the headline message tells the user their document \"is/isn't\n> >valid foo\", I'd strongly agree that we can't allow foo to take a default\n> >value.\n> >\n> >If the headline changes to \"pass|fail validation as foo\", we're no\n> >longer telling a lie when the document isn't actually foo.\n> \n> Hmmm. That might make sense in general too.\n\n+1.  While at it, how about revising the headline a bit more; now it\nsays \"This page\", which sounds like it's referring to the validation\nresults page, not the one checked?  Dunno about the use of the word\n\"page\" either.  But I'm having a hard time coming up with a good and\nshort enough replacement for the headline that would satisfy all of the\nabove \"requirements\".  Perhaps just:\n\n  Validation results ($doctype): pass|fail|tentative\n\n>  But note that the difference is\n> slight, and probably won't make much difference in practice; my guess is that\n> it'll be far too subtle a distinction for the users (who lack the context).\n\nAgreed, but I think this is an improvement worth applying anyway (+ not\nonly the headline, but also the paragraph below it (c|sh)ould be\nrephrased).\n\n\n\n", "id": "lists-017-14686652"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "On Wed, 2004-05-19 at 10:45, Nick Kew wrote:\n\n> Now onsgmls will give us a version string of PROVISIONAL\n> that we can test for.\n\nSounds workable, but will of course also need some new code and\nexplanation(s).\n\n\n\n", "id": "lists-017-14695277"}, {"subject": "[checklink] navbar link", "content": "I've been discussing a bit with Ville on our decision to put the same \nstyle and navigation for checkink as we have for the Markup Validator.\n\nThe latest idea would be along these lines:\n> I suppose we could have links as follows:\n>\n> homepage: [homepage] + download + documentation + WMVS\n> documentation: homepage + download + [documentation] + WMVS\n> results: homepage + download + documentation + WMVS\n\n(with [foo] not being a link, only showing where you are)\n\nthe documentation page being a configuration option, it will be easy to \nfigure out the link to [documentation]. However, I'm a bit puzzled \nabout the link to \"homepage\", as the documentation is generally pulled \noff cvsweb, not the local instance.\n\nThoughts and ideas on that? It seems to be the last blocker(?) for a \nrelease of 3.9.3.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14702502"}, {"subject": "Re: User control of validator results pages", "content": "On May 15, 2004, at 22:18, Nick Kew wrote:\n> As hinted a few times on IRC, I'd like to see the presentation of\n> results pages compacted a little, with the full gory detail a\n> user option.\n\nI like the principle and I certainly can see usage scenarios where this \nwould be useful. An alternate take un the principle would be a tabbed \ninterface (also as hinted on IRC).\n\nI guess the interest of a \"vertical\" expand-collapse (as opposed to \ntabbed interface) is that we could implement a user-based preference (I \nsuppose cookies+scripting would do the trick) and keep some sections \ncollapsed and some expanded when validating another page.\n\n\nWould like to hear others' ideas on this.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14709546"}, {"subject": "Re: User control of validator results pages", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@w3.org> wrote:\n\n>Would like to hear others' ideas on this.\n\nLets Not Go There??! :-)\n\nSupporting an actual user preference system ??? especially one based on cookies\ninstead of HTTP Auth + user database ??? is far too much pain compared to the\nbenefits.\n\nAt most I'd consider having UI gizmos for toggling various things that try to\nset a cookie and automagically recalls it on later visits[0]. e.g. so that if\nyou visit a postulated tabbed interface and press the ???Switch to linear\nversion??? gizmo, a cookie gets set so you get the linear version by default on\nnext visit.\n\nIf you want to get any more fancy than that, we should set up an actual user\nregistration system ??? with HTTP auth instead of stupid user/pass web forms and\ncookie session-ids ??? and go all out with periodic revalidation of pages and a\nreminder function (\"warn if this page fails to validate three months from\nnow\"), site crawler system, LogValidator run on uploaded logs, etc.\n\n\n\n\n[0] - And if that's all you mean by \"Preference\" system then I dispute\n      the accuracy of your choice of terminology! :-)\n\n\n\n- -- \n\"Temper Temper! Mr. Dre? Mr. NWA? Mr. AK, comin??\n straight outta Compton and y'all better make way?\"            -- eminem\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKxG1qPyPrIkdfXsEQKKDACfTPSjdAzlvqxsypiMxzH6J3UMiKgAoIG2\n+O8XNLAt0Yxl4bBR5O1K6eh3\n=V9Q0\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14717453"}, {"subject": "Re: v0.6.6 Release", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>On Wed, 2004-05-19 at 10:45, Nick Kew wrote:\n>\n>>Now onsgmls will give us a version string of PROVISIONAL that we can\n>>test for.\n>\n>Sounds workable, but will of course also need some new code and\n>explanation(s).\n\nYes, and it will quite significantly fuck with core logic in a way that I'm\nextremely hesitant to do to the 0.6.6 code. I suggest we get 0.6.6 out the\ndoor first and then issue these changes (including any wording changes on\nresult pages or the front page blurb) in a 0.6.7 update shortly afterwards.\n\nHey, lets see if we can get in 3 new Validator versions during WWW2004? :-)\n\n- -- \n\"I don't mind being thought of as a badguy,\n but it /really/ annoys me to be thought of\n as an *incompetent* badguy!\" -- John Moreno\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKxEUKPyPrIkdfXsEQJo7wCeP3NSIrMibQ76KCZFF2fzrvMcG60Anihf\ni0T1AFx/KpdIrfcvp1EqP6h4\n=EdC7\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14726640"}, {"subject": "Re: v0.6.6 Release", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>+1.  While at it, how about revising the headline a bit more; now it\n>says \"This page\", which sounds like it's referring to the validation\n>results page, not the one checked?  Dunno about the use of the word\n>\"page\" either.  But I'm having a hard time coming up with a good and\n>short enough replacement for the headline that would satisfy all of the\n>above \"requirements\".  Perhaps just:\n>\n>Validation results ($doctype): pass|fail|tentative\n\nI've actually been thinking lately about dropping the banner-ish display of\nthe status alltogether. Granted it solves the problem of making Validation\nstatus abundantly clear, but several people have complained about it on\nvarious grounds and it's a real bitch to work into the visual design of the\npage (not to mention the number of conditionals in the code to emit it).\n\nRight now I'm leaning towards making it simply the first or second row of the\nheader/metadata table at the top, and simply styling it in some garish (or\notherwise \"LOOK AT ME!!!\" manner).\n\n\nThe theory, which I haven't quite mulled through yet, is that the reason the\nred/blue banner design was necessary as a workaround for the amount of clutter\nat the top of results pages. If we clean that up ??? and it has been cleaned up\na little allready ??? the large banner thing shouldn't be as necessary.\n\n\nIn any case, that would make the natural way to phrase it be;\n\n  Status: [Validates as [FPI|PrettyName]|] Failed; \\d+ errors found.]\n\n???or possibly???\n\n    Status: [OK|Failed]\n    Errors: \\d+\n  Warnings: \\d+\n\n???with the [FPI|PrettyName] given as the selected entry in the Doctype row\nbelow.\n\n\nOpinions?\n\n\n\n>>But note that the difference is slight, and probably won't make much\n>>difference in practice; my guess is that it'll be far too subtle a\n>>distinction for the users (who lack the context).\n>\n>Agreed, but I think this is an improvement worth applying anyway (+ not\n>only the headline, but also the paragraph below it (c|sh)ould be\n>rephrased).\n\nEXPN? Well, or \"cvs ci/diff\"... :-)\n\n\n\nOh, and BTW, see also my other message in this thread regarding timing of any\nof these changes.\n\n\n- -- \n\"You gonna take advice from somebody who slapped DEE BARNES?!\" -- eminem\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKxDSKPyPrIkdfXsEQKgDwCgr+Yz7NVmTk+Rxkk1HvZIemrhLGsAn04l\ngZklgus8JGY4Fcalpt4gF+Zp\n=HL8h\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14735017"}, {"subject": "Re: User control of validator results pages", "content": "On May 20, 2004, at 14:49, Terje Bless wrote:\n> At most I'd consider having UI gizmos for toggling various things that \n> try to\n> set a cookie and automagically recalls it on later visits[0].\n\nThat was my idea when writing this mail, indeed. I know that we could \nhave something more complicated, user registration and all, which could \nbe useful for other aspects (monitor this for me an e-mail, etc, etc) \nbut that was not what I was referring to.\n\n> [0] - And if that's all you mean by \"Preference\" system then I dispute\n>       the accuracy of your choice of terminology! :-)\n\nBe my guest! I have plenty of things, including fever, to blame it on ;)\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14744761"}, {"subject": "Re: v0.6.6 Release", "content": "On May 20, 2004, at 14:38, Terje Bless wrote:\n> I suggest we get 0.6.6 out the\n> door first and then issue these changes (including any wording changes \n> on\n> result pages or the front page blurb) in a 0.6.7 update shortly \n> afterwards.\n\nsounds good.\n\nSince we're going for at least two other maintenance releases, I'd like \nconfirmation of my understanding of our CVS state...\n\n- HEAD is 0.6.5 plus templates code\n- 0_6-branch is 0.6.5 plus fixes\n\nIf so, I suppose we are going to merge again after 0.6.6 and work on \n0.6.7 in the branch, etc. Would that mean by any chance that we're \nalready in a scheme similar to the one explained in\nhttp://lists.w3.org/Archives/Public/public-qa-dev/2004Apr/0030.html\n?\n(Bjoern, have you sent your comments on this?)\n\n> Hey, lets see if we can get in 3 new Validator versions during \n> WWW2004? :-)\n\n*cough*. How about \"no\"...? :)\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14752090"}, {"subject": "Re: v0.6.6 Release", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nolivier Thereaux <ot@w3.org> wrote:\n\n>Since we're going for at least two other maintenance releases, I'd like\n>confirmation of my understanding of our CVS state...\n>\n>   - HEAD is 0.6.5 plus templates code\n>   - 0_6-branch is 0.6.5 plus fixes\n>\n>If so, I suppose we are going to merge again after 0.6.6 and work on\n>0.6.7 in the branch, etc.\n\nCorrect; that's what I'm thinking.\n\n\n>Would that mean by any chance that we're already in a scheme similar to\n>the one explained in\n><http://lists.w3.org/Archives/Public/public-qa-dev/2004Apr/0030.html>?\n\nYes. With a couple of caveats...\n\nThe merge to HEAD is not complete. While all the code has been brought over\nfrom the validator-0_6_0-branch, not all the resulting breakage has been fixed\nyet. And I don't expect anyone has been testing this code much yet (at least,\nnobody has sent me notes about the things I know of that are broken).\n\nAlso, I'm not entirely certain whether we should immediately\nbranch+feature-freeze HEAD->0.7 yet; or whether squeezing in a few more\nfeatures on HEAD first would be a good idea. I'm still too focussed on 0.6.x\nfor this to have really gelled in my mind yet. Opinions?\n\n\n>>Hey, lets see if we can get in 3 new Validator versions during WWW2004?\n>>:-)\n>\n>*cough*. How about \"no\"...? :)\n\nBah! Spoilsport! How about two then? 0.6.6 ASAP, and 0.6.7 on the 22nd? :-)\n\n\n- -- \nWe've gotten to the point where a human-readable, human-editable text format\nfor structured data has become a complex nightmare where somebody can safely\nsay  \"As many threads on xml-dev have shown, text-based processing of XML is\nhazardous at best\"  and be perfectly valid in saying it.     -- Tom Bradford\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKxyyqPyPrIkdfXsEQLigQCg+dKDmp+dBzd4HOK4c3P9u31pM0AAoL++\nBxeb0b1Pi2VE8sntvXG/yU3U\n=9rl9\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14759938"}, {"subject": "Re: v0.6.6 Release", "content": "On Thu, May 20, 2004, Terje Bless wrote:\n> Also, I'm not entirely certain whether we should immediately\n> branch+feature-freeze HEAD->0.7 yet; or whether squeezing in a few more\n> features on HEAD first would be a good idea. I'm still too focussed on 0.6.x\n> for this to have really gelled in my mind yet. Opinions?\n\nI suppose it depends on which features you'd be planning on adding. We\nhave decided to try and release often, and not creep in too many\nfeatures for each release. That said, we seem to be embarking in a\nrythm where we do several small, low profile maintenance releases (0.6.5\nbeing a notable exception, given its timeframe, for the low-profile\naspect) for one feature-rich release... All of this with our own\nviewpoint - what we view as \"icing\" may be perceived by users as a big\nfeature. \n\nTherefore it would probably be OK to take our time for a feature release.\n(reasonably so...)\n\n\n> Bah! Spoilsport! How about two then? 0.6.6 ASAP, and 0.6.7 on the 22nd? :-)\n\nIf everyone's happy with the current state of the code we could push 0.6.6 \nout as soon as tomorrow. As for 0.6.7 on the 22nd, sure! I just can't\nguarantee which month.\n\nCheers!\n-- \nolivier\n\n\n\n", "id": "lists-017-14769255"}, {"subject": "Re: v0.6.6 Release? (was: 0.6.6 bug roundup", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nNick Kew <nick@webthing.com> wrote:\n\n>That's a good excuse for some further hacks to the default DTD too :-)\n\nEXPN?\n\n\n- -- \n\"I don't want to learn to manage my anger;\n I want to FRANCHISE it!\" -- Kevin Martin\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQKzr8aPyPrIkdfXsEQI3fgCfWE3Kg6dSJvsZXmgSNbuazRe1XC8AoMSD\naEdkFz9JHQOqRSPnSfK9WMJs\n=r9Hx\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14777383"}, {"subject": "Re: [Bug 705] The Markup Validation Service detects HTML 4.01 Strict as HTML 4.01 Transitional", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nbugzilla@wiggum.w3.org wrote:\n\n>Sort of fixed, but the \"friendliness\" ie. fallback from no doctype to\n>HTML 4.01 Transitional seems to be gone, or at least is partially\n>broken:\n>http://qa-dev.w3.org/wmvs/0.6/check?uri=http%3A%2F%2Fkoti.welho.com%\n>2Fvskytta%2Fbug705 -2.html\n\nYup, the whole thing was b0rked due to a braino on my part; I'd used \"#\" as a\ncomment marker inside an SGML Open Catalog (never ever do \"cvs ci\" mere hours\nbefore release when you're terminally sleep-deprived).\n\nIf you look at <http://qa-dev.w3.org/wmvs/0.6.5/check?uri=http://koti.welho.\ncom/vskytta/bug705-2.html> and <http://qa-dev.w3.org/wmvs/0.6.6/check?\nuri=http://koti.welho.com/vskytta/bug705-2.html> this ought to be fixed now.\n\nAlso, <http://qa-dev.w3.org/wmvs/0.6.5/check?uri=http://www.cs.tut.fi/\n~jkorpela/test/frames.html> vs. <http://qa-dev.w3.org/wmvs/0.6.6/check?\nuri=http://www.cs.tut.fi/~jkorpela/test/frames.html> ought to indicate that\nJukka's problem is also fixed.\n\nAnd finally, our favourite test case,\n<http://qa-dev.w3.org/wmvs/0.6.5/check?uri=http://www.yahoo.com/> vs.\n<http://qa-dev.w3.org/wmvs/0.6.6/check?uri=http://www.yahoo.com/> should give\nsomething meaningfull.\n\n\nPlease double-check this to make sure I haven't missed anything again!\n\n\nI've moved up the \"validator-0_6_6-release\" tag to include this fix; now we\njust need to get someone to do \"cd sgml-lib/ && cvs up sgml.soc\" on v.w3.org\nand we should be good.\n\n\nWell, except there seems to be a problem with the stylesheets on v.w3.org.\nOlivier: Did you do \"cvs up -dP\" or just \"cvs up\" when you updated? (and who\ngave you permission to not be available on IRC 24/7 BTW? ;D)\n\n- -- \nI have to admit that I'm hoping the current situation with regard to XML\nNamespaces and W3C XML Schemas is a giant practical joke,   but I see no\nsigns of pranksters coming forward with a gleeful smile to announce that\nthey were just kidding.                              -- Simon St.Laurent\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQK3FpaPyPrIkdfXsEQJYAACdGg48aB8dOKMy5+mxhgb6DXOUkWEAoMA/\ndkUd621rNWh1RZun5EmQBQq0\n=HkEU\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14785097"}, {"subject": "Re: [Bug 705] The Markup Validation Service detects HTML 4.01 Strict as HTML 4.01 Transitional", "content": "On Fri, May 21, 2004, Terje Bless wrote:\n> I've moved up the \"validator-0_6_6-release\" tag to include this fix; now we\n> just need to get someone to do \"cd sgml-lib/ && cvs up sgml.soc\" on v.w3.org\n> and we should be good.\n\nDone, also scp'd sgml-lib-0_6_6.tar.gz to proper location.\n \n> Well, except there seems to be a problem with the stylesheets on v.w3.org.\n> Olivier: Did you do \"cvs up -dP\" or just \"cvs up\" when you updated? \n\nmy history tells me -dP (which I usually do). What's the issue with the\nstylesheets?\n\n-- \nolivier\n\n\n\n", "id": "lists-017-14797078"}, {"subject": "validator0_6_6.tar.gz update", "content": "I've recreated validator-0_6_6.tar.gz on v.w.o [1]; the previous one was\napparently created from an unclean development dir somewhere and\ncontained some backup files as well as other junk that should not have\nbeen there.  The sgml-lib tarball is ok, did not touch it.  (See\ncommentary in misc/mkrelease.sh for info how to create clean release\ntarballs.)\n\n[1] Yeah, brown paper bag updates should be avoided...\n\n\n\n", "id": "lists-017-14805758"}, {"subject": "Re: [Fwd: Software error:", "content": "(I changed s/www-validator/public-qa-dev/)\n\nOn Sat, 2004-05-22 at 21:40, Bjoern Hoehrmann wrote:\n> * Vivien Lacourba wrote:\n> >Another one ...\n> \n> Thanks Vivien, the error message is generated by the CGI.pm Perl module.\n> It's either a bug in our code, in CGI.pm or in the browser of these\n> users. Could you ask these users to report details on what browsers they\n> have used, etc. to www-validator or forward their mails to me so I can\n> ask them?\n\nSome more thoughts: the error message was \"Malformed multipart POST\" but\nthe feedback said \"when trying to validate online HTML documents\"; that\ncombination makes no sense to me.  Did the user use upload or URI\nsubmission?\n\nIf upload, at least some (old) versions of Opera did have issues with\nfile uploads, but AFAIK CGI.pm had a workaround for this already in\nversion 2.89, and v.w.o has 3.01.\n\nIf it was validation using a URI, I have no explanation.\n\n>  We should probably configure validator.w3.org so that it lists\n> www-validator or public-qa-dev as contact address rather than\n> web-human...\n\npublic-qa-dev++\n\n\n\n", "id": "lists-017-14812365"}, {"subject": "Re: [Fwd: Software error:", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>public-qa-dev++\n\nExcept \"public\"-qa-dev is subscriber-only...\n\nPersonally I could live with having Apache on v.w3.org give web-human as the\ncontact adress ??? it makes sense to me that all web service related issues get\nadressed to the same place within the w3.org domain, and the web-human will\npresumably direct questions to the right place for v.w3.org as for all other\nsections of the greater w3.org site ??? but then it's not me that has to handle\nthe web-human mail queue so... :-)\n\n\n\n\n- -- \nThese are the same customers you are referring to whom Microsoft thought\nwould need MS Bob and the Talking Paperclip?   One thing is to give them\nenough rope to hang themselves,  but a boobytrapped thermonuclear weapon\nrunning on a rand(time) countdown... Is that really wise? - Me to MS rep.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQK+5aqPyPrIkdfXsEQJnywCdFOgat0bJ73SYqr7qV6cS/esgDLcAoPOn\nibvewJ1BhaOOmbV2YKCnx+4t\n=CCQF\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14820750"}, {"subject": "Re: what should the charset be in the response to the serve", "content": "Martin,\n\nMany thanks for the response.\n\nYour expanded sentence fully addresses this issue, as far as I am concerned.\n\nChris\n\n\n----- Original Message -----\nFrom: \"Martin Duerst\" <duerst@w3.org>\nTo: \"Chris Haynes\" <chris@harvington.org.uk>; <www-international@w3.org>\nCc: \"Michel Suignard\" <michelsu@microsoft.com>; <public-iri@w3.org>\nSent: Friday, May 07, 2004 7:02 AM\nSubject: Re: what should the charset be in the response to the server\n\n\n>\n> Hello Chris,\n>\n> Many thanks for your reply. I have copied the IRI list\n> because I think this discussion is relevant for the current\n> draft.\n>\n> At 13:38 04/05/06 +0100, Chris Haynes wrote:\n> >Thanks for the response, Martin,\n> >\n> >I only noticed this response _after_ I had replied to your other response\n> >on the\n> >IRI list, so I apologize that my earlier response did not take into\n> >account this\n> >message of yours.\n> >\n> >Trying to bring this topic to closure, I think my core worry arises each time\n> >there are what-appear-to-me-to-be normative statements that 'the page\nencoding\n> >determines the encoding used in requests derived from that page' -\n> >ignoring the\n> >possibility of users having changed the encoding setting.\n> >\n> >We obviously both agree that users 'should not' use these controls (just as I\n> >diapprove of the use of 'tone controls' and spectral filters in Hi Fi systems\n> >for other than 'loudness' compensation), but I get worried every time the\n> >possibility of their use is ignored.\n> >\n> >The situation is not purely  'theoretical ' I've seen reports that it is\n> >common\n> >practice in some countries for people to switch to their 'national' character\n> >set every time they appear to have a problem in viewing a page - which\n> >could be\n> >occasioned by their browser not having UTF-8 support.\n>\n> Ok, so let's have a look at this case: Either switching to their 'national'\n> character encoding solves the problem, in which case the page was badly\n> labeled, and the page author is to blame. Or switching does not solve\n> the problem, in which case the user may even not be able to read the\n> page, and therefore won't fill in the form. Or the page only contains\n> US-ASCII characters to begin with, and the user doesn't have any reason\n> to switch encodings.\n>\n> That probably leaves us with just one intermediate case: The page is\n> mostly in US-ASCII, but with a few other characters (e.g. 'smart quotes',...).\n> The user sees some problem, tries to fix it by switching the encoding.\n> That doesn't help, so the user gives up, and just fills in the form\n> (which is readable enough to complete the task).\n>\n> If you know about any other scenarios where switching encoding and then\n> filling in the form with a wrong encoding can happen realistically,\n> please tell me.\n>\n>\n> >I help provide support to the users of an open-source web server, and we\n> >frequently get requests for help from people managing web services who,\nhaving\n> >read the appropriate RFCs and W3 specs in detail, had not appreciated that\n> >user\n> >agents can change the encoding in ways which the request-receiving server\n> >cannot\n> >detect.\n>\n> I was giving a tutorial about Web internationalization for years, and\n> the issue of encoding in forms always came up, but from the time when\n> the first browsers supporting UTF-8 came out, that was always given as\n> an answer, and I haven't heard anybody question this before you. But\n> of course your mileage may vary.\n>\n> But there is an additional point: A server isn't helpless against users\n> changing the encoding. UTF-8 has the very helpful property of having\n> very specific byte sequences. It is easy to check these with a\n> regular expression, for an example, please see\n> http://www.w3.org/International/questions/qa-forms-utf-8.html.\n>\n>\n> >I suppose I'm just keen to make sure that wherever this topic appears, the\n> >potential behavior of the vast majority of browsers in the world is\nadequately\n> >and completely described.\n> >\n> >If there were an RFC somewhere which said that the user agent 'MUST NOT'\n> >change\n> >the encoding, and that real-world browsers were ignoring this stricture, I\n> >would\n> >agree that other RFCs were right to describe what should be, rather than what\n> >is.\n> >\n> >But as far as I know, the ability for users to override the encoding does not\n> >contravene any existing RFC, and therefore other RFCs ought at least to\n> >recognize that possibility, and not infer, by omission, a level of certainty\n> >which can never be assured.\n> >\n> >I think I would have a very poor view of any web site which told me it was my\n> >fault a request got garbled because I made use of a freely-available\n> >control on\n> >my browser.\n> >\n> >Let me try to conclude this by just asking that, so long as user control over\n> >the encoding is permitted by RFCs, that possibility is explicitly\n> >recognized by\n> >other RFCs., and that we dont try to pretend that it does not exist or, even\n> >worse, that failures and errors in decoding are the user's fault for\n> >breaking an\n> >unwritten, untestable  non-rule.\n>\n> I'm still not sure to what extent this is really happening. But I have\n> clarified this issue by expanding the sentence in question as follows:\n>\n> \"Likewise, when setting up a new Web form using UTF-8 as the encoding\n> of the form page, the returned query URIs will use UTF-8 as an encoding\n> (unless the user for whatever reason changes the character encoding)\n> and will therefore be compatible with IRIs.\"\n>\n> This leaves it to the reader to judge for him/herself how high\n> the probability is that the user is switching code pages.\n>\n> Regards,    Martin.\n>\n>\n> >Chris\n> >\n> >\n> >----- Original Message -----\n> >From: \"Martin Duerst\" <duerst@w3.org>\n> >To: \"Chris Haynes\" <chris@harvington.org.uk>; <www-international@w3.org>\n> >Cc: \"Michel Suignard\" <michelsu@microsoft.com>\n> >Sent: Thursday, May 06, 2004 8:04 AM\n> >Subject: Re: what should the charset be in the response to the server\n> >\n> >\n> > > Hello Chris,\n> > >\n> > > In trying to clear up the remaining IRI issues, I found out that\n> > > I planned to reply to this message of yours, but didn't get around\n> > > to do it.\n> > >\n> > > At 17:20 03/08/07 +0100, Chris Haynes wrote:\n> > >\n> > > >  \"Martin Duerst\" Replied:\n> > > >\n> > > >\n> > > > > At 12:15 03/07/26 +0100, Chris Haynes wrote:\n> > > > >\n> > > > > >  \"Jungshik Shin\" replied at: Saturday, July 26, 2003 11:31 AM\n> > > > >\n> > > > > > >   It also depends on whether or not you set 'send URLs always in\n> > > > > >UTF-8' in\n> > > > > > > Tools|Options(?) in MS IE.\n> > > > > > >\n> > > > > >\n> > > > > >True, but I'm trying to find a 'reliable' mechanism which is not\n> > > > > >dependent on user-accessible controls.\n> > > > > >IMHO, this is also a 'dangerous' option, in that it goes agains the\n> > > >de\n> > > > > >facto conventions and anticipates (parhaps incorrectly) the\n> > > > > >recommendations of the proposed IRI RFC. It can only safely be used\n> > > > > >with a 'consenting' server site.\n> > > > >\n> > > > > Sorry, no. The main dangerous thing is that authors use non-ASCII\n> > > > > characters in URIs (without any %HH escaping) when this is clearly\n> > > > > forbidden.\n> > > > >\n> > > > > Regards,  Martin.\n> > > >\n> > > >\n> > > >Martin,\n> > > >\n> > > >Are you saying that you approve of relying on users to select the\n> > > >(Microsoft-specific)  'send URLs always in\n> > > >UTF-8'  menu option  to ensure that UTF8 gets returned to the server?\n> > > >\n> > > >That is what was being suggested.\n> > >\n> > > Well, my above statement was meant in the following sense:\n> > > There is NO spec that would allow inclusion of non-ASCII\n> > > characters in URIs. The IRI spec is the first one that\n> > > defines something similar to an URI that actually allows this.\n> > > Any authors that for example put raw iso-8859-1 characters\n> > > into an URI in a page in iso-8859-1 are therefore wrong;\n> > > any 'it works' effect is coincidental, not according to specs.\n> > > Suggesting that a browser that anticipates a future spec\n> > > (the IRI spec) is dangerous, while (implicitly) blessing\n> > > browsers and pages that don't conform to any spec is in\n> > > my eyes a dangerous idea.\n> > >\n> > >\n> > > >My argument was that any current HTTP-like system in which the\n> > > >character encoding could be modified by menu controls in the user\n> > > >agent, (and in which the actual encoding used is *not* conveyed in the\n> > > >request) was inherently unreliable.\n> > >\n> > > I think we have to look at different parts of a HTTP request separately.\n> > > There are mainly two parts: the 'path' part and the 'query' part.\n> > >\n> > > With respect to the path part, this is indeed influenced by the\n> > > 'send URLs always in UTF-8' option in MS IE. But there are ways\n> > > to get around this. For an example, see my Apache 'mod_fileiri'\n> > > module, which allows to map requests both in a legacy encoding and\n> > > in UTF-8 back to the file in question.\n> > > [see http://www.w3.org/2003/06/mod_fileiri/Overview.html for an overview,\n> > > including pointers to the actual code and to a talk of mine].\n> > >\n> > > With respect to the query part, this is not affected by the\n> > > 'send URLs always in UTF-8' option in MS IE. The query part\n> > > is always sent in the encoding of the actual page, except\n> > > for some browsers that implement the 'accept-charset' attribute\n> > > on <form>. But for queries, it is rather easy to e.g. convert\n> > > all the forms related to that query URI to UTF-8.\n> > >\n> > > You are right that the (perceived) character encoding of the\n> > > page can affect both parts. Of course, users might always\n> > > change the character encoding, and as a result send something\n> > > that the server gets as garbage. However, users don't use\n> > > menus just for fun, and if anybody would ever come and complain,\n> > > the server side would be very justified to say \"don't mess\n> > > around with the settings if you expect your queries to work\".\n> > > So this is very much a theoretical concern.\n> > >\n> > >\n> > > Regards,    Martin.\n> > >\n> > >\n>\n>\n\n\n\n", "id": "lists-017-1482173"}, {"subject": "Re: [Fwd: Software error:", "content": "* Ville Skytt? wrote:\n>If upload, at least some (old) versions of Opera did have issues with\n>file uploads, but AFAIK CGI.pm had a workaround for this already in\n>version 2.89, and v.w.o has 3.01.\n\nDid we change the CGI.pm during the upgrade / server change?\nCould someone have a look at the error logs for some insight?\n\n\n\n", "id": "lists-017-14829339"}, {"subject": "Error log diving (was: Re: [Fwd: Software error:]", "content": "On Sun, 2004-05-23 at 00:06, Bjoern Hoehrmann wrote:\n> * Ville Skytt? wrote:\n> >If upload, at least some (old) versions of Opera did have issues with\n> >file uploads, but AFAIK CGI.pm had a workaround for this already in\n> >version 2.89, and v.w.o has 3.01.\n> \n> Did we change the CGI.pm during the upgrade / server change?\n\nI have no idea.  Olivier?\n\n> Could someone have a look at the error logs for some insight?\n\nIt's a bit hard to find the interesting entries since validator is quite\nan errorlog-trasher (still, even though I managed to get some of the\nnoisiest bugs fixed for 0.6.6).\n\nAnyway, there are 46 \"Malformed multipart POST\" and \"Malformed multipart\nPOST: data truncated\" entries in today's error log, but unfortunately\nthere doesn't seem to be anything terribly interesting nearby.  Samples\n(as well as POST examples with the same timestamp from access log, or\ncomplete_log as it's called on v.w.o) with IP addresses masked:\n\n  [Sat May 22 14:41:28 2004] check: Malformed multipart POST: data truncated\n  [Sat May 22 14:50:08 2004] check: Malformed multipart POST\n\n  2004-05-22T14:41:28Z 200 7054 na /usr/local/validator/httpd/cgi-bin/check xxx.xxx.xxx.xxx - \"POST /check HTTP/1.1\" \"http://validator.w3.org/\" \"text/html\" \"-\" \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; .NET CLR 1.1.4322)\" \"validator.w3.org\"\n  2004-05-22T14:41:28Z 200 265 na /usr/local/validator/httpd/cgi-bin/check yyy.yyy.yyy.yyy - \"POST /check HTTP/1.1\" \"-\" \"text/html\" \"-\" \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0) Opera 7.23  [en]\" \"validator.w3.org\"\n  2004-05-22T14:50:08Z 200 249 na /usr/local/validator/httpd/cgi-bin/check xxx.xxx.xxx.xxx - \"POST /check HTTP/1.1\" \"http://validator.w3.org/\" \"text/html\" \"-\" \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; .NET CLR 1.1.4322)\" \"validator.w3.org\"\n\nNote that the response status has been 200 for all those POSTs.  There\nare also quite a few some weird error log entries, not necessarily near\nthe above, like:\n\n  [Sat May 22 16:22:12 2004] [error] [client zzz.zzz.zzz.zzz] request failed: erroneous characters after protocol string: t reproduce in part or whole without permission.<br>\n\nWhile peeking into the logs, here's a bunch of URIs, checking all of\nwhich have resulted in \"500 internal server error\" today, some examples:\n\nhttp://www.w3.org/TR/query-semantics/ (~1.6MB)\n  My local installation and qa-dev seem to be fine with this, but the\n  memory footprint of the \"check\" process peaks at 170MB (!) in my local\n  instance just before the validation finishes.\nhttp://www.w3.org/TR/2003/WD-xsl11-20031217/ (~1.8MB)\n  Ditto, peak memory usage 107MB.\nhttp://www.go-mono.com/class-status-System.Windows.Forms.html (~0.9MB)\n  Ditto, plus takes ages to validate, I already thought this would   \n  kill my box until it eventually finished, peak mem usage 141MB.\n\nRunning \"top\" on v.w.o suggests that it seems to kill the \"check\"\nprocess once its footprint reaches 100MB when validating any of the\nabove URLs.  I did not see any related configuration or limits in\nhttpd.conf, and the box does not run out of memory or anything.  Nothing\nmeaningful in the error log when it terminates either, only:\n\n  [Sat May 22 18:21:20 2004] [error] [client nnn.nnn.nnn.nnn] Premature end of script headers: /usr/local/validator/httpd/cgi-bin/check\n\nBTW, Normal, smallish validation cases seem to take 10MB or so per\n\"check\" process on my box, so 100+ MB is pretty much... ideas?\n\nThere is also one 500 from what is apparently caused by someone\nrepeatedly (7ish times) clicking the referer badge in the lower right\nhand corner of the results page after having validated a pretty large\ndocument with show source and show parse tree options on, causing\novbiously pretty heavy recursion and an URL with length of about 2k...\nany ideas how we could prevent this?\n\n\n\n", "id": "lists-017-14837171"}, {"subject": "Re: Error log diving (was: Re: [Fwd: Software error:]", "content": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nVille Skytt?? <ville.skytta@iki.fi> wrote:\n\n>It's a bit hard to find the interesting entries since validator is quite\n>an errorlog-trasher (still, even though I managed to get some of the\n>noisiest bugs fixed for 0.6.6).\n\nAnd we should probably make an effort to reduce this problem even further\nfairly quickly.\n\n\n><http://www.w3.org/TR/query-semantics/>         (~1.6MB) [170MB]\n><http://www.w3.org/TR/2003/WD-xsl11-20031217/>  (~1.8MB) [107MB]\n><http://www.go-mono.com/[???].Windows.Forms.html> (~0.9MB) [141MB]\n>\n>Normal, smallish validation cases seem to take 10MB or so per\n>\"check\" process on my box, so 100+ MB is pretty much... ideas?\n\nProcess size will balloon with input document size (and hence complexity)\nsince each element has a gazillion attributes who will show up in the ESIS\nwhether they're in the physical markup or not. A normal document has a very\nlarge markup:content ratio; the cited documents have inordinatly much markup\ncompared to the amount of data in them.\n\nWell, or at least that's my theory. :-)\n\nBTW, Bj??rn has (on IRC) just suggested some optimizations that can be used to\navoid some of this overhead in a number of cases. I'll have a look at whether\nthat can reasonably be done for 0.6.7. The bug on this has been targetted for\n0.7 IIRC.\n\n\n>Running \"top\" on v.w.o suggests that it seems to kill the \"check\"\n>process once its footprint reaches 100MB when validating any of the\n>above URLs.  I did not see any related configuration or limits in\n>httpd.conf, and the box does not run out of memory or anything.\n\nWhich means these are probably either Apache compile-time limits or Debian\nkernel ulimits.\n\n\n>There is also one 500 from what is apparently caused by someone\n>repeatedly (7ish times) clicking the referer badge in the lower right\n>hand corner of the results page after having validated a pretty large\n>document with show source and show parse tree options on, causing\n>ovbiously pretty heavy recursion and an URL with length of about 2k...\n>any ideas how we could prevent this?\n\nLook for the User-Agent or similar distinguishing characteristic of the\nincoming request, and if it's ourselves we append an extra token (\"recursive\")\nto out User-Agent string. If a request comes in with \"recursive\" we throw a\nfatal error. Add in a configurable prmitted recursion level perhaps...\n\n- -- \n\"Temper Temper! Mr. Dre? Mr. NWA? Mr. AK, comin??\n straight outta Compton and y'all better make way?\"            -- eminem\n\n-----BEGIN PGP SIGNATURE-----\nVersion: PGP SDK 3.0.3\n\niQA/AwUBQK/gHqPyPrIkdfXsEQLL5QCg1HJZgRVZhZtOEDaQ1B1Qwkrf4F0An3U4\nSWGhS3bzWDuWdgTEBRlHLNo7\n=6FgA\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-017-14848827"}, {"subject": "Re: Error log diving (was: Re: [Fwd: Software error:]", "content": "On Sun, 2004-05-23 at 02:20, Terje Bless wrote:\n> Ville Skytt? <ville.skytta@iki.fi> wrote:\n> \n> >It's a bit hard to find the interesting entries since validator is quite\n> >an errorlog-trasher (still, even though I managed to get some of the\n> >noisiest bugs fixed for 0.6.6).\n> \n> And we should probably make an effort to reduce this problem even further\n> fairly quickly.\n\nYep.  Attached is a couple of lowly scripts I've used every once in a\nwhile (when bored or something :), first grab some URLs from the access\nlog on v.w.o:\n\n  ./graburls.sh 3000 > urls.txt\n\n...then transfer urls.txt to my box and replay on a local validator\ninstance, 'tail -f'ing its error log in another shell:\n\n  ./replay-validator.sh < urls.txt\n\n\n\n\napplication/x-shellscript attachment: graburls.sh\n\napplication/x-shellscript attachment: replay-validator.sh\n\n\n\n\n", "id": "lists-017-14859692"}, {"subject": "Re: [Fwd: Software error:", "content": "On Sat, May 22, 2004, Bjoern Hoehrmann wrote:\n> Did we change the CGI.pm during the upgrade / server change?\n\nI think we did, by changing the base perl from 5.6.1 (with CGI v2.752) to\n5.8.3 (with CGI v3.01).\n\n-- \nolivier\n\n\n\n", "id": "lists-017-14868137"}, {"subject": "Re: [Fwd: Software error:", "content": "* Olivier Thereaux wrote:\n>On Sat, May 22, 2004, Bjoern Hoehrmann wrote:\n>> Did we change the CGI.pm during the upgrade / server change?\n>\n>I think we did, by changing the base perl from 5.6.1 (with CGI v2.752) to\n>5.8.3 (with CGI v3.01).\n\nIOW, someone should try to figure out what's different between those\nversions and how to restore the old behavior?\n\n\n\n", "id": "lists-017-14875313"}, {"subject": "&quot;send feedback&quot; links not quite used for suggestion", "content": "[ I'm putting this on the agenda for our IRC meeting tomorrow, BTW]\n\nIt was fine as long as we were using the \"send feedback\" links on \n:8001, but now that they are on :80, even toned down, the number of \nlost users clicking on these links as though they were reaching for a \nfloater in a shipwreck is a bit annoying...\n\nI'd rather these messages with \"default\" subjects were kept for \ntracking of actual suggestions, not calls for help. On the other hand \nof course it's a nice change from the previous favorite subject \"bug in \nthe validator\". Another issue is that this link bypasses the feedback \npage, thus not directing people to the FAQ.\n\nI'd suggest these links go to a (dynamic) page similar to the feedback \npage:\n- linking to the FAQ and feedback page for general feedback\n- asking to *only* use this service to suggest error message \nexplanations\n- linking (eventually) to the appropriate mailto:\n\nOther ideas?\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14882528"}, {"subject": "[meeting] notes and log 2004-052", "content": "Here are my notes from yesterday's (2004-05-25) meeting.\n\nLog is attached, as usual, and action items were edited at:\nhttp://esw.w3.org/topic/QaDev\n\n\nCSS Validator:\n\nDiscussing the most urgent bugs, as well as how/when to package and \ndistribute the tool. olivier will take ownership of bugs (in bugzilla) \nand \"dispatch\" them as appropriate.\n\nOne targeted improvement will be the addition of error message \nexplanations (from the FAQ - http://www.websitedev.de/css/validator-faq \n- and developed frm there). Yves will take care of the back end, Bjoern \nand olivier will take care of the content.\n\n\nChecklink:\n\nDiscussion on (temporary?) solutions for the addition of the navigation \nbar. Links will go to the instance at v.w.o\n\n\n\nMarkup Validator:\n\n     Icons: plenty of issues of transparency, color, missing icons. Need \nto regenerate many (all?). olivier will talk to Dom about that.\n\n     Header-Footer: too big in PNG, and some browsers don't cache them. \n80k per page is way too much. Switching to jpeg.\n\n     Malformed Multipart Post, error handling and 500 ErrorDoc: \nMultipart post problem does not seem easy to reproduce. We should \nprobably contact L.Stein about it, and maybe try CGI.pm 3.05 (now \n3.01).\n\nThe general question of how we handle fatal errors is another issue. \nVille has a few patches to improve that. In some cases we want to be \nable to log much more than we are at the moment. Also, 500 Error Doc \ngives link the web-human, and webmaster not too happy about it (not to \nmention additional steps before we can contact whoever reports issues). \nWe'll need to investigate how to improve that while not messing too \nmuch with CGI::Carp.\n\n\n\n\n-- \nolivier\n\n\n\n\ntext/plain attachment: qadev-20040525.txt\n\n\n\n\n", "id": "lists-017-14890017"}, {"subject": "Fwd: Two validator", "content": "On the topic of multiple SGML/XML parsers.\n\nHenry S. Thompson wrote:\n> It's really not a great idea to\n> keep trying to make openSP be a fully-compliant XML validator when\n> there is a _tiny_ user/developer community for it in that role,\n> compared to the huge amount of effort which is put into the top 3 or 4\n> XML validators.  I would recommend rxp, since it's open source, fast,\n> produces good error messages and is a Univ. of Edinburgh product owned\n> and operated by Richard Tobin, member of the XML Core WG, but any of\n> the validators which did well in Rusty Harold's conformance\n> comparison, reported at XML Europe 2004, would do.\n\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14898260"}, {"subject": "[check] documentation additions / refactorin", "content": "There seems to have been a few discussions on the validator's \ndocumentation recently, I'll try and summarize what I am aware of so \nthat we can improve the documentation globally, not just locally.\n\n1- I had a discussion with Bjoern on the help&FAQ document. Bjoern \nwould certainly be better at explaining his point, but his ideas were \nbasically that\n  * having a FAQ and a docs link in the navbar was confusing\n  * help should be a help page, not a FAQ\n  * mixing general, legal and technical aspects in the FAQ was not a \ngood idea\n  * there should be a \"top validation problems\" document.\nhttp://esw.w3.org/topic/ValidationProblems\n\n2- Terje and Daniel Biddle (deltab) had a discussion on IRC about the \nneed for a document stating what the markup validator does *not* do...\nCSS, script check, link check, spell check, and other web page quality \nchecks\n\n3- the docs/ index should be made more compact for an easier global \nview of the documentation\n\n\nIdeas about this. Should really be considered more as ramblings than \nactually a plan.\n\nSolving the FAQ/document index problem. I admit the FAQ (with three \nsections on about / using / common problems) casts a big shadow on the \ndocumentation index, and since many have to scroll to find the links \nfor the \"frequently asked questions\", it might not be too useful.\n\nIf we manage to improve the documentation index there should not be a \nneed for two entry points to the documentation.\n\nWhat are the use cases where we really want people to find the \ndocumentation easily? perhaps not advanced users. Some people have been \nasking for a document to link the icons from (instead of revalidation, \nwhich is the official use for the icons) and a section has been added \nto the help doc to help that, but not sure it's really useful.\nMaybe we need to think more of all the usage scenarios for the \ndocumentation before revamping it.\n\nShould \"what the validator is not\" be a part of \"what the validator is \n(about)\"?\n\nShould we have a specific document on license, usage rights and other \nlegalese fun?\n\nMore sections for the documentation? General help (help, about), Usage \n(users, favelets, accesskeys) Troubleshooting (common validation \nproblems, error message explanations) Installation and development (the \nrest). Should the documentation index link to all or focus on \nintroducing the most important and link to second-level docs from \nfirst-level docs (e.g link favelets from users, etc)?\n\n\nAll for now. Comments and your answers to all these questions much \nwelcome, otherwise i'll just keep them here for reference and keep \nplaying with the documentation until I have something I am happy with - \nno real urgency anyway.\n-- \nolivier\n\n\n\n\n", "id": "lists-017-14905540"}, {"subject": "Re: Fwd: Two validator", "content": "On Wed, 26 May 2004, olivier Thereaux wrote:\n\n> On the topic of multiple SGML/XML parsers.\n>\n> Henry S. Thompson wrote:\n\n(this response Cc: Henry)\n\n> > It's really not a great idea to\n> > keep trying to make openSP be a fully-compliant XML validator when\n> > there is a _tiny_ user/developer community for it in that role,\n> > compared to the huge amount of effort which is put into the top 3 or 4\n> > XML validators.\n\nIndeed, I don't think we're arguing with him about that.  Although the\nW3C validator is still limited to OpenSP, various related projects such\nas my own Site Valet and Bj?rn's MSIE validation bar use multiple parsers.\n\nIt's the relatively narrow but crucial subject of HTML validation\nwhere we have no alternative in sight.\n\n>  I would recommend rxp, since it's open source, fast,\n> > produces good error messages and is a Univ. of Edinburgh product owned\n> > and operated by Richard Tobin, member of the XML Core WG, but any of\n> > the validators which did well in Rusty Harold's conformance\n> > comparison, reported at XML Europe 2004, would do.\n\nI used Xerces in mod_validator, because at the time of writing it was\nthe only available parser offering full validation (for values of\n\"available\" that precluded anything-Java).\n\nNowadays I would choose libxml2 for new software.  Indeed, I regard\nlibxml2 as the way ahead for several reasons over and above the\nvalidation we have:\n\n(1) It's very fast (see the xmlbench results @sourceforge),\n    widely-deployed, and easy to work with.\n(2) I've used it successfully in the past for related projects\n    (AccessValet, and more recently mod_annot).\n(3) It has all the basics we need for extending it beyond validation\n    to full conformance testing.\n(4) It's the basis for libcroco, so should integrate well with CSS\n    analysis.\n(5) It has an active and responsive development community.\n\nHenry (or anyone) want to present arguments for AN Other option?\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14914626"}, {"subject": "syncmail back - restarted :8001  updated verbosems", "content": "It seems we're slowly getting back to working conditions...\n\nA few things I finally managed to do:\n- restarted vwo:8001,\n- reinstalled syncmail (twice) (so that we get notifications in \nwww-validator-cvs),\n- tested and installed the latest verbosemsg.cfg\n\nThere are a few issues remaining, but we're getting... somewhere.\n\n-- \nolivier\n\n\n\n\n\n", "id": "lists-017-14923554"}, {"subject": "mod_validato", "content": "OK, mod_validator is now running mostly-smoothly on qa-dev: any\nserious differences to Page Valet are probably a reportable bug\n(although they could also be due to more up-to-date libraries).\n\nIt's still looking slower than I'd expect, and I'll have to figure\nout whether it's doing anything stupid like fetching entities\nover the 'net.\n\nGetting the file upload working remains TBD - sometime when I'm\nless knackered.  Last I tried it was giving 400, which is what\nthe software does if presented with invalid input, so hopefully\nall I need to do is fix the file upload form.\n\n\nPlayground: http://qa-dev.w3.org:8888/validator/\n\nIf I put it under CVS, will anyone use it?\n\n\n-- \nNick Kew\n\n\n\n", "id": "lists-017-14930226"}, {"subject": "New Public list - public-qt-comments  maitained by mf&#64;w3.or", "content": "public-qt-comments (qt stands for Query and Transform) is for public\nfeedback on the following W3C specifications published by the XML Query[1]\nand XSL Working Groups[2]:\n\nXQuery 1.0[3]\nXSLT 2.0[4]\nXPath 2.0[5]\nXQuery 1.0 and XPath 2.0 Data Model[6]\nXQuery 1.0 and XPath 2.0 Functions and Operators Version 1.0[7]\n\n\n\n\n1.  http://www.w3.org/XML/Query\n2.  http://www.w3.org/Style/XSL/\n3.  http://www.w3.org/TR/xquery/\n4.  http://www.w3.org/TR/xslt20/\n5.  http://www.w3.org/TR/xpath20/\n6.  http://www.w3.org/TR/query-datamodel/\n7.  http://www.w3.org/TR/xquery-operators/\n\n-- \nSimon J. Hernandez | http://www.w3.org/People/Simon/ | mailto:simon@w3.org\nWorld Wide Web Consortium                                http://www.w3.org\nMIT Laboratory for Computer Science, 200 Technology Square   Room NE43-340\nCambridge, MA 02139 USA       Voice: +1.617.253.2920  Fax: +1.617.258.5999\n\n\n\n", "id": "lists-017-15009129"}, {"subject": "Re: tes", "content": "scott_boag@us.ibm.com writes:\n\n> An official test for this mailing list.\n\nAnd an official reply.\n\nMax.\n\n\n\n", "id": "lists-017-15016781"}, {"subject": "tes", "content": "An official test for this mailing list.\n\n-scott\n\n\n\n", "id": "lists-017-15023538"}, {"subject": "Re: Migration of HTTP to the use of IRIs [queryclarify16", "content": "Michel,\n\nThanks for this comment, but I think my point is still valid - even just for\npresentational uses.\n\nGiven that many URI encodings exist 'in the wild' which use %HH escaping of\nnon-UTF-8 sequences, I fail to see how one can know that it is valid to convert\nany such URI into an IRI (as per sect. 3.2) - even if just for presentational\npurposes.\n\nMy concern is the same:  unless there is some kind of syntactic indicator within\nthe URI as a whole, how can one reliably know that UTF-8 has been used and that\nit is intended to have a corresponding IRI?\n\nIt seems to me that IRI will only be deployed accurately and effectively if one\nof the following situations occurs:\n\n1) New protocol schemes (e.g. httpi, httpis ) are introduced which make it\nexplicit that this spec. applies to the URI,\n\n2) They are used within a closed environment in which it is a convention that\nonly IRIs and IRI-derived URIs are in use (no legacy-encoding escapes, or they\nare allowed to be mis-interpreted)\n\n3) A new market-dominating user agent is launched which behaves as if (2) above\nwere the case - i.e. there is an attempt to establish IRIs as the de facto\ndefault through market force, ignoring or discarding resulting errors of\npresentation or of resource identification.\n\nMy big fear is that without rapid progress on (1), IRIs on the open Internet\nwill only ever take off if someone does (3) - which will be without benefit of\nadequate standards backing.\n\nI'd love to either:\n\na) be shown that my logic is faulty\n\nor\n\nb) be pleasantly surprised by being told that there _is_  RFC work taking place\non new schemes covering at least the space of http(s)\n\notherwise, I fail to understand how IRIs will 'take off' in the 'real world' -\nwhere they are so badly needed.\n\nChris\n\n\n\n\n----- Original Message -----\nFrom: \"Michel Suignard\" <michelsu@windows.microsoft.com>\nTo: \"Chris Haynes\" <chris@harvington.org.uk>\nCc: <public-iri@w3.org>; \"Martin Duerst\" <duerst@w3.org>\nSent: Friday, May 07, 2004 1:43 AM\nSubject: RE: Migration of HTTP to the use of IRIs [queryclarify-16]\n\n\n\n> From:  Chris Haynes\n> Sent: Thursday, May 06, 2004 4:50 AM\n>\n> Actually, my original core concern has now been covered in your\nsection\n> 1.2.a - Applicability, where you make it clear that \"the intent is not\nto\n> introduce IRIs into contexts that are not defined to accept them\".\n>\n> This now makes it clear that new schemas will be required to replace\n> http: , https: etc. These will need to be self-identifying in some\nway, so\n> that receiving equipment will know that an IRI is being presented.\n>\n> So, as I commented last June, I await with interest the recognition\namong\n> those responsible for the HTTP schema that new schemas with new names\nare\n> required before IRIs can be used.\n\nI'd like to comment on that. The IRI spec is fairly explicit on that IRI\ncan be used as presentation elements for URI protocol elements (ref\nclause 3 intro). This is to recognize that applications out there have\nnot waited for us for creating presentation layers that use non ascii\nnative characters for schemes that supposedly should not use them (such\nas http). The presentation layer principle is there to support that. So\nI expect IRI to be used for both purposes:\n- presentation layer for existing URI schemes\n- core layer for new schemes exclusively defined using IRI for protocol\nelements syntax.\n\nFor a while I'd expect the vast majority of IRI usage to be in the first\ncategory.\n\nMichel\n\n\n\n", "id": "lists-017-1505037"}, {"subject": "Groupin", "content": "I have a question about grouping in the working draft.  We have some\ncustomer use cases where we need to group by multiple criteria, say the\nvalues of multiple attributes instead of just one.  Here's an example:\n\nSource XML document:\n  <os>\n     <o id= 'Bif' a='1' b='1' />\n     <o id= 'Bay' a='1' b='1' />\n     <o id= 'Bob' a='1' b='2' />\n     <o id= 'May' a='2' b='1' />\n     <o id= 'Moe' a='2' b='1' />\n     <o id= 'Mel' a='2' b='2' />\n     <o id= 'Joe' a='3' b='2' />\n     <o id= 'Sue' a='4' b='1' />\n  <os>\nDesired output:\n\n    <table>\n      <tr>\n        <td>Bif, Bay</td>\n      </tr>\n      <tr>\n        <td>Bob</td>\n      </tr>\n      <tr>\n        <td>May, Moe</td>\n      </tr>\n      <tr>\n        <td>Mel</td>\n      </tr>\n      <tr>\n        <td>Joe</td>\n      </tr>\n      <tr>\n        <td>Sue</td>\n      </tr>\n    </table>\n\nThe best solution we could come up with:\n<table xsl:version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n   <xsl:for-each-group select=\"os/o\" group-by=\"concat(@a, ',', @b\">\n      <tr>\n         <td>\n            <xsl:value-of select=\"current-group()/@id\" separator=\", \"/>\n         </td>\n      </tr>   </xsl:for-each-group>\n</table>\nI'm not too happy with having to use concat to generate a group, as it's\ndifficult to optimize and somewhat unintuitive.  I'd like to see something\nmore like this:\n\n<xsl:sort-key name=\"o-sort\">  <xsl:sort select=\"@a\"/>  <xsl:sort\nselect=\"@b\"/></xsl:sort-key>\n<table xsl:version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n   <xsl:for-each-group select=\"os/o\" group-by-sort-key=\"o-sort\">\n      <tr>\n         <td>\n            <xsl:value-of select=\"current-group()/@id\" separator=\", \"/>\n         </td>\n      </tr>   </xsl:for-each-group>\n</table>\nThe semantics would be that the processor would use the named sort key to\ngroup the nodes into a set of equivalence classes.   Each set of nodes for\nwhich all the sort keys compare equal will define a group.  The advantage of\nthis approach is that the second sort key does not have to be used for nodes\nthat are already unique under the first sort key.  In this small of an\nexample it wouldn't matter, but you could imagine larger documents in which\nit would make a difference, especially if the select on the second sort key\nwas a more complicated expression.\n\nPerhaps this is what the committee was thinking of with Issue 54 in the 2.0\nworking draft?  It wasn't clear to me what exactly was being addressed\nthere.\n\n\nThanks,\n\nJeff Yemin\nThinkshare Corporation\n\n\n\n", "id": "lists-017-15051735"}, {"subject": "Re: Groupin", "content": "Hi Jeff,\n\n> The best solution we could come up with:\n> <table xsl:version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n>    <xsl:for-each-group select=\"os/o\" group-by=\"concat(@a, ',', @b\">\n>       <tr>\n>          <td>\n>             <xsl:value-of select=\"current-group()/@id\" separator=\", \"/>\n>          </td>\n>       </tr>   </xsl:for-each-group>\n> </table>\n> I'm not too happy with having to use concat to generate a group, as\n> it's difficult to optimize and somewhat unintuitive. I'd like to see\n> something more like this:\n\nI agree. It also doesn't deal well with mixing data types -- if the a\nattribute was a string and the b attribute was a number, for example.\n\n> <xsl:sort-key name=\"o-sort\">  <xsl:sort select=\"@a\"/>  <xsl:sort\n> select=\"@b\"/></xsl:sort-key>\n> <table xsl:version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n>    <xsl:for-each-group select=\"os/o\" group-by-sort-key=\"o-sort\">\n>       <tr>\n>          <td>\n>             <xsl:value-of select=\"current-group()/@id\" separator=\", \"/>\n>          </td>\n>       </tr>   </xsl:for-each-group>\n> </table>\n\nI think that could get a little confusing, given that xsl:sort is used\nfor sorting things elsewhere, and in particular since xsl:sort is also\nused within the xsl:for-each-group instruction. I've previously\nsuggested using an xsl:group element inside xsl:for-each to do the\ngrouping:\n\n  <table xsl:version=\"2.0\"\n         xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n    <xsl:for-each select=\"os/o\">\n      <xsl:group select=\"@a\" />\n      <xsl:group select=\"@b\" />\n      <tr>\n        <td>\n          <xsl:value-of select=\"current-group()/@id\" separator=\", \" />\n        </td>\n      </tr>\n    </xsl:for-each>\n  </table>\n\nSee\nhttp://lists.w3.org/Archives/Public/xsl-editors/2001OctDec/0052.html\nfor the proposal I made. Mike replied at\nhttp://lists.w3.org/Archives/Public/xsl-editors/2002JanMar/0036.html\nthat the grouping key could be a sequence and that this would enable\nyou to have compound grouping keys, but this doesn't seem to have\nfiltered through into the WD yet...\n  \n> Perhaps this is what the committee was thinking of with Issue 54 in\n> the 2.0 working draft? It wasn't clear to me what exactly was being\n> addressed there.\n\nAs I understand Issue 54, it's about specifying a collation to\ndetermine whether two strings are the same in order to determine\nwhether two things should be grouped together or not. For example, if\nyou had:\n\n  <os>\n     <o id= 'Bif' a='a' b='1' />\n     <o id= 'Bay' a='A' b='1' />\n     <o id= 'Bob' a='a' b='2' />\n     <o id= 'May' a='b' b='1' />\n     <o id= 'Moe' a='b' b='1' />\n     <o id= 'Mel' a='B' b='2' />\n     <o id= 'Joe' a='C' b='2' />\n     <o id= 'Sue' a='d' b='1' />\n  <os>\n\nand a collation called \"my:case-insensitive\" then you should be able\nto do:\n\n  <table xsl:version=\"2.0\"\n         xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n    <xsl:for-each-group select=\"os/o\"\n                        group-by=\"concat(@a, ',', @b)\"\n                        collation=\"my:case-insensitive\">\n      <tr>\n        <td>\n          <xsl:value-of select=\"current-group()/@id\" separator=\", \" />\n        </td>\n      </tr>\n    </xsl:for-each>\n  </table>\n\nto get the output that you were after before -- Bif and Bay would be\ngrouped together because 'a' is equal to 'A' under a case-insensitive\ncollation.\n  \nCheers,\n\nJeni\n\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15061697"}, {"subject": "RE: Groupin", "content": "One way of meeting this requirement is to use two nested xsl:for-each-group\ninstructions:\n \n<xsl:for-each-group select=\"os/o\" group-by=\"@a\">\n  <xsl:for-each-group select=\"current-group()\" group-by=\"@b\">\n      <tr>\n         <td>\n            <xsl:value-of select=\"current-group()/@id\" separator=\", \"/>\n         </td>\n      </tr>\n   </xsl:for-each-group>\n </xsl:for-each-group>\n \nWhether you think this is preferable to the solution using concat() is\nlargely a matter of personal taste; but it seems difficult to justify\nadditional syntax to meet this requirement when a solution is already\navailable.\n \nIssue 54 is unrelated, it is concerned with how one decides whether two\ngrouping keys are equal, for example do \"Smith\" and \"SMITH\" go in the same\ngroup? XSLT 2.0 and XPath 2.0 will allow the use of user-selected collations\nin all contexts where strings need to be compared.\n \nMichael Kay\n\n\n-----Original Message-----\nFrom: Jeff Yemin [mailto:jeffx@thinkshare.com] \nSent: 01 August 2002 17:43\nTo: public-qt-comments@w3.org\nCc: me\nSubject: Grouping\n\n\nI have a question about grouping in the working draft.  We have some\ncustomer use cases where we need to group by multiple criteria, say the\nvalues of multiple attributes instead of just one.  Here's an example:\n \nSource XML document:\n\n<os>\n   <o id= 'Bif' a='1' b='1' />\n   <o id= 'Bay' a='1' b='1' />\n   <o id= 'Bob' a='1' b='2' />\n   <o id= 'May' a='2' b='1' />\n   <o id= 'Moe' a='2' b='1' />\n   <o id= 'Mel' a='2' b='2' />\n   <o id= 'Joe' a='3' b='2' />\n   <o id= 'Sue' a='4' b='1' />\n<os>\n\nDesired output:\n \n    <table>\n      <tr>\n        <td>Bif, Bay</td>\n      </tr>\n      <tr>\n        <td>Bob</td>\n      </tr>\n      <tr>\n        <td>May, Moe</td>\n      </tr>\n      <tr>\n        <td>Mel</td>\n      </tr>\n      <tr>\n        <td>Joe</td>\n      </tr>\n      <tr>\n        <td>Sue</td>\n      </tr>\n    </table>\n\nThe best solution we could come up with:\n\n\n<table xsl:version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n\n   <xsl:for-each-group select=\"os/o\" group-by=\"concat(@a, ',', @b\">\n\n      <tr>\n\n         <td>\n\n            <xsl:value-of select=\"current-group()/@id\" separator=\", \"/>\n\n         </td>\n\n      </tr>\n   </xsl:for-each-group>\n\n</table>\n\nI'm not too happy with having to use concat to generate a group, as it's\ndifficult to optimize and somewhat unintuitive.  I'd like to see something\nmore like this:\n \n\n<xsl:sort-key name=\"o-sort\">\n  <xsl:sort select=\"@a\"/>\n  <xsl:sort select=\"@b\"/>\n\n\n</xsl:sort-key>\n<table xsl:version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n\n   <xsl:for-each-group select=\"os/o\" group-by-sort-key=\"o-sort\">\n\n      <tr>\n\n         <td>\n\n            <xsl:value-of select=\"current-group()/@id\" separator=\", \"/>\n\n         </td>\n\n      </tr>\n   </xsl:for-each-group>\n\n</table>\nThe semantics would be that the processor would use the named sort key to\ngroup the nodes into a set of equivalence classes.   Each set of nodes for\nwhich all the sort keys compare equal will define a group.  The advantage of\nthis approach is that the second sort key does not have to be used for nodes\nthat are already unique under the first sort key.  In this small of an\nexample it wouldn't matter, but you could imagine larger documents in which\nit would make a difference, especially if the select on the second sort key\nwas a more complicated expression.\n \nPerhaps this is what the committee was thinking of with Issue 54 in the 2.0\nworking draft?  It wasn't clear to me what exactly was being addressed\nthere.\n \n \nThanks,\n \nJeff Yemin\nThinkshare Corporation\n\n\n\n", "id": "lists-017-15073087"}, {"subject": "RE: Groupin", "content": "> See \n> http://lists.w3.org/Archives/Public/xsl-editors/2001OctDec/0052.html\n> for the proposal I made. Mike replied at \n> http://lists.w3.org/Archives/Public/xsl-editors/2002JanMar/0036.html\n> that the grouping key could be a sequence and that this would \n> enable you to have compound grouping keys, but this doesn't \n> seem to have filtered through into the WD yet...\n\nThere has since been another suggestion that a sequence-valued grouping key\nshould be taken to mean that the same node should be included in more than\none group (analogously to the way xsl:key works). It obviously can't have\nboth meanings...\n\nI think there is some feeling in the WG that we have hit about the right\nlevel of functionality with xsl:for-each-group and that we don't want to\ncomplicate it any further. If there really are problems that can't be solved\n(as distinct from problems that are a little awkward to solve) then we will\ncertainly look at them.\n\nMichael Kay\n\n\n\n", "id": "lists-017-15084940"}, {"subject": "XSLT 2.0  Proposal for additional Varaible  requirement", "content": "To date I have been fairly successful in achieving my XML transformation\ngoals with XSLT 1.0.  Early on I ran into the same problem which\neveryone has/will: variable values can not be changed once established.\n\nHowever, I am finding it an increasingly aggrevating limitation that\nthere is no easy way of accumulating a final result in a piece-meal or\niterative fashion in a manner than allows the final accumulation to be\nutilized within the transformation process.\n\nXSL(T) transforms input XML into something else.  This transformation is\nstate driven.  This state is established by the input XML and by XSL\nstylesheets.  For simple transformations, it is sufficient that this\nstate is established directly.  Complex transformations will frequently\nrequire derived state information.  Derived state information can not\nalways be established immediately/directly/recursively.\n\nXPATH 2.0 is introducing several new requirements which indirectly (and\npartially) address this very issue:\n  a) 1.3 Must Support Explicit \"For Any\" or \"For All\" Comparison and\nEquality Semantics\n  b) 1.4 Must Extend Set of Aggregation Functions (e.g. max(), min()).\n\nThese requirements are providing solutions to problems which, while\nconceptually\nsimple, tend to be very difficult to articulate in XSLT 1.0 in a usable\nmanner.  These, in my mind, are a direct response to instances of the\nmore general issue of not being able to accumulate a result.\n\nThe requirements above are probably very important.  However, in my\nmind:\na) they will only lend themselves effectively to homogeneous\nelements/node-sets,\nb) they are point-source solutions to a more systemic issue.\n\n>From seeing the issues raised in some of the news groups, I know this a\nfairly common/general issue with XSLT.  From a statement made under XSL\n2.0 Requirements Goals (\"Turning XSLT into a general-purpose programming\nlanguage.\"); I suspect that this issue is being tabled under the\ncategory of \"not a general-purpose programming language\".\n\nObservation 1: Requirements should never be stated in terms of\nnegatives.  It is usually a bad idea to try to describe something in\nterms of what it is not.\n\nObservation 2: XSLT _is_ a programming language.  In several references\nI have read it is explicitly described as a \"declartive programming\nlanguage\".\n\nObservation 3: This issue is pervasive.  As such it would seem that XSL\n2.0 should attempt to address it.\n\nRegards,\nEd Knoll\n\n--\nEdward L. Knoll   Phone (work)     : (719)484-2717\n                  e-mail (work)    : f49660c@cosd.fedex.com\n                  e-mail (business): eknoll@sf-inc.com\n                  e-mail (personal): edward@elknoll.com\n\n\n\n", "id": "lists-017-15092865"}, {"subject": "XSL 2.0  Proposal for a indirect dereferencing  requirement", "content": "I am fairly new to XML/XSL, but I have been keeping a list of the most\nlimiting issues I have encountered with XSL 1.0.  Thankfully it appears\nthat most of the ones on my list are being addressed by XSL 2.0.\n\nHowever, one issue that I am encountering more frequently the more I use\nXSL is that there is no way to indirectly dereference a variable.  There\nis no way to construct or establish the name of variable into a variable\nand then dereference the constructed/established name.  In short, there\nis no way to dereference a variable (var1) which contains the name of\nanother variable (var2) to get the value of var2.\n\nI have seen many issues is some the XML/XSL news groups archives related\nto users trying to construct a variable name or use some other field to\ndetermine the name of the variable, so I don't believe this problem is\nunique to my experience.\n\nSeems like a good candidate for an XSL 2.0 requirement.\n\nRegards,\nEd Knoll\n\n-- \nEdward L. Knoll   Phone (work)     : (719)484-2717\n                  e-mail (work)    : ed.knoll@cosd.fedex.com\n                  e-mail (business): eknoll@sf-inc.com\n                  e-mail (personal): edward@elknoll.com\n\n\n\n", "id": "lists-017-15103385"}, {"subject": "RE: XSL 2.0  Proposal for a indirect dereferencing  requirement", "content": "> I am fairly new to XML/XSL, but I have been keeping a list of \n> the most limiting issues I have encountered with XSL 1.0.  \n> Thankfully it appears that most of the ones on my list are \n> being addressed by XSL 2.0.\n> \n> However, one issue that I am encountering more frequently the \n> more I use XSL is that there is no way to indirectly \n> dereference a variable.  There is no way to construct or \n> establish the name of variable into a variable and then \n> dereference the constructed/established name.  In short, \n> there is no way to dereference a variable (var1) which \n> contains the name of another variable (var2) to get the value of var2.\n> \n> I have seen many issues is some the XML/XSL news groups \n> archives related to users trying to construct a variable name \n> or use some other field to determine the name of the \n> variable, so I don't believe this problem is unique to my experience.\n\nThanks for the suggestion. We did give very careful thought to introducing a\ndynamic evaluation capability in XSLT 2.0 (that is, the ability to construct\nXPath expressions, including variable references, on the fly from strings),\nand we decided against it. The basic reasons are difficulties in defining\nthe semantics in an interoperable way, and worries about the effect on\nperformance, optimization, and type safety.\n\nThe decision was a difficult one with good arguments on both sides, but I\nthink we are unlikely to re-open the question.\n\nYou may be aware that several products have an xx:evaluate() extension\nfunction which meets this requirement.\n\nMichael Kay \n\n\n\n", "id": "lists-017-15112536"}, {"subject": "RE: XSLT 2.0  Proposal for additional Varaible  requirement", "content": "Changing XSLT from being a functional language without side-effects into a\nprocedural scripting language would certainly ease the learning curve for\npeople coming to it from things such as JavaScript. However, there are good\nreasons for the fact that the language is designed on functional lines, and\nI don't think anyone on the working group wants to change this principle,\nwhich is pretty fundamental to the way the language is conceived.\n\nI myself found it difficult to get over the learning curve initially, but\nlike most people who have made the effort, I found that in the longer term,\nthe benefits in terms of improved maintainability of code are quite\nconsiderable. Please persevere!\n\nMichael Kay\n\n\n\n> \n> To date I have been fairly successful in achieving my XML \n> transformation goals with XSLT 1.0.  Early on I ran into the \n> same problem which everyone has/will: variable values can not \n> be changed once established.\n> \n> However, I am finding it an increasingly aggrevating \n> limitation that there is no easy way of accumulating a final \n> result in a piece-meal or iterative fashion in a manner than \n> allows the final accumulation to be utilized within the \n> transformation process.\n> \n> XSL(T) transforms input XML into something else.  This \n> transformation is state driven.  This state is established by \n> the input XML and by XSL stylesheets.  For simple \n> transformations, it is sufficient that this state is \n> established directly.  Complex transformations will \n> frequently require derived state information.  Derived state \n> information can not always be established \n> immediately/directly/recursively.\n> \n> XPATH 2.0 is introducing several new requirements which \n> indirectly (and\n> partially) address this very issue:\n>   a) 1.3 Must Support Explicit \"For Any\" or \"For All\" \n> Comparison and Equality Semantics\n>   b) 1.4 Must Extend Set of Aggregation Functions (e.g. max(), min()).\n> \n> These requirements are providing solutions to problems which, \n> while conceptually simple, tend to be very difficult to \n> articulate in XSLT 1.0 in a usable manner.  These, in my \n> mind, are a direct response to instances of the more general \n> issue of not being able to accumulate a result.\n> \n> The requirements above are probably very important.  However, in my\n> mind:\n> a) they will only lend themselves effectively to homogeneous \n> elements/node-sets,\n> b) they are point-source solutions to a more systemic issue.\n> \n> >From seeing the issues raised in some of the news groups, I \n> know this a\n> fairly common/general issue with XSLT.  From a statement made \n> under XSL 2.0 Requirements Goals (\"Turning XSLT into a \n> general-purpose programming language.\"); I suspect that this \n> issue is being tabled under the category of \"not a \n> general-purpose programming language\".\n> \n> Observation 1: Requirements should never be stated in terms \n> of negatives.  It is usually a bad idea to try to describe \n> something in terms of what it is not.\n> \n> Observation 2: XSLT _is_ a programming language.  In several \n> references I have read it is explicitly described as a \n> \"declartive programming language\".\n> \n> Observation 3: This issue is pervasive.  As such it would \n> seem that XSL 2.0 should attempt to address it.\n> \n> Regards,\n> Ed Knoll\n> \n> --\n> Edward L. Knoll   Phone (work)     : (719)484-2717\n>                   e-mail (work)    : f49660c@cosd.fedex.com\n>                   e-mail (business): eknoll@sf-inc.com\n>                   e-mail (personal): edward@elknoll.com\n> \n\n\n\n", "id": "lists-017-15121771"}, {"subject": "XQuery type system not integrated into the  languag", "content": "Hello,\n\nAlthough XQuery has many excellent features, its type system does not seem \nto be well integrated into the language.  Complex types can only be defined \nexternally in  a different language called XML Schema.  We would hope that \nyou consider designing a language that has a fully integrated type system.\n\nTo better understand the issues involved, we implemented an experimental \nversion of XQuery that uses the type system described in the Formal \nSemantics document as its native type system.\n\nThe demo is located at http://www.cogneticsystems.com/xquery/xquery.html. \n Our reasons for doing this are described at \nhttp://www.cogneticsystems.com/xquery/alignment.html#fs.\n\nThe demo displays both the static and dynamic types for query results. This \nis useful for observing what happens with the \"assert as\", \"treat as\", and \n\"cast as\" operators.  We have also implemented a \"validate as\" operator \nwhich validates XML content assigning types to its text nodes.  There are a \n number of interesting queries listed under, \"simple queries\" and \"type \nexamples\" on the web site.\n\nBill Patton\nCognetic Systems, Inc.\n\n\n\n", "id": "lists-017-15134046"}, {"subject": "Why don't we have &quot;xsl:continue&quot; or &quot;xsl:break&quot;  element", "content": "We do have \"xsl:for-each\" and \"xsl:if\" elements. Why\ncannot we have \"xsl:continue\" or \"xsl:break\" element?\nIt's so inconvenient without such element cooperating\nwith \"xsl:for-each\" and \"xsl:if\" elements. \nI have encountered this problem while doing a project\nusing XSLT.\nThank you for your consideration!\nTong\n\n__________________________________________________\nDo You Yahoo!?\nYahoo! Health - Feel better, live better\nhttp://health.yahoo.com\n\n\n\n", "id": "lists-017-15142446"}, {"subject": "Re: inconsistent definition of order comparison", "content": "Apologies, wrong section of spec attached (to early in the morning). \nCorrect now\n\nHi,\n\nI believe the xpath2 spec to be incorrect in its definition.\n\n\n\nhttp://www.w3.org/TR/xpath20/#id-order-comparisons\n\n2.6.4 Order Comparisons\n\n3. A comparison with the << operator returns true if the first operand \nnode is earlier than the second operand node in document order, or false \nif the first operand node is later than the second operand node in \ndocument order.\n4. A comparison with the >> operator returns true if the first operand \nnode is later than the second operand node in document order, or false if \nthe first operand node is earlier than the second operand node in document \norder.\n\n\n\nhttp://www.w3.org/TR/xquery-operators/#func-node-before\n\n\n11.1.7 op:node-before\nop:node-before(node $parameter1, node $parameter2) => boolean\n\nIf the node identified by the value of $parameter1 occurs in document \norder before the node identified by the value of $parameter2, this \nfunction returns true; otherwise, it returns false. The rules determining \nthe order of nodes within a single document and in different documents can \nbe found in [XQuery 1.0 and XPath 2.0 Data Model]. This function backs up \nthe \"<<\" operator.\n\n11.1.8 op:node-after\nop:node-after(node $parameter1, node $parameter2) => boolean\n\nIf the node identified by the value of $parameter1 occurs in document \nafter the node identified by the value of $parameter2, this function \nreturns true; otherwise, it returns false. The rules determining the order \nof nodes within a single document and in different documents can be found \nin [XQuery 1.0 and XPath 2.0 Data Model]. This function backs up the \">>\" \noperator.\n\n\n\nGareth\n\n\n\n", "id": "lists-017-15150512"}, {"subject": "inconsistent definition of order comparison", "content": "Hi,\n\nI believe the xpath2 spec to be incorrect in its definition.\n\n\n\nhttp://www.w3.org/TR/xpath20/#id-order-comparisons\n\n2.6.4 Order Comparisons\n\n3. A comparison with the << operator returns true if the first operand \nnode is earlier than the second operand node in document order, or false \nif the first operand node is later than the second operand node in \ndocument order.\n4. A comparison with the >> operator returns true if the first operand \nnode is later than the second operand node in document order, or false if \nthe first operand node is earlier than the second operand node in document \norder.\n\n\n\nhttp://www.w3.org/TR/xquery-operators/#op-node-precedes\n\n11.1.9 op:node-precedes\nop:node-precedes(node $srcval1, node $srcval2) => boolean\n\nReturns true if the node identified by $srcval1 occurs before the node \nidentified by $srcval2 in document order, but is not an ancestor of the \nnode identified by $srcval2. Otherwise returns false. This function backs \nup the \"precedes\" operator on nodes.\n11.1.10 op:node-follows\nop:node-follows(node $srvcal1, node $srcval2) => boolean\n\nReturns true if the node identified by $srcval1 occurs after the node \nidentified by $srcval2 in document order, but is not a descendant of the \nnode identified by $srcval2. Otherwise returns false. This function backs \nup the \"follows\" operator on nodes.\n\n\n\n-- \nGareth Reakes, Head of Product Development  \nDecisionSoft Ltd.            http://www.decisionsoft.com\nOffice: +44 (0) 1865 203192\n\n\n\n", "id": "lists-017-15159733"}, {"subject": "RE: Why don't we have &quot;xsl:continue&quot; or &quot;xsl:break&quot;  element", "content": "> We do have \"xsl:for-each\" and \"xsl:if\" elements. Why\n> cannot we have \"xsl:continue\" or \"xsl:break\" element?\n> It's so inconvenient without such element cooperating\n> with \"xsl:for-each\" and \"xsl:if\" elements. \n\nThe instructions you propose would only make sense if <xsl:for-each> were\nexecuted sequentially, that is, if the n'th node is always processed before\nthe (n+1)th. But the semantics of XSLT are non-sequential; the nodes\nselected by xsl:for-each can be processed in any order, or in parallel.\nTherefore xsl:break would not make sense.\n\nYou can always achieve the same effect by replacing the xsl:for-each with a\nrecursive template call.\n\nMichael Kay\nSoftware AG\n\n\n\n", "id": "lists-017-15168822"}, {"subject": "RE: inconsistent definition of order comparison", "content": "In the April draft we included two pairs of operators:\n\n   << , >>\n   precedes , follows\n\nwith subtly different semantics, and we included an issue (#229) suggesting\nthat we didn't really need both pairs of operators.\n\nWe have since made a decision on this issue, and the next draft will include\nonly the first pair of operators.\n\nThanks for your comments.\n\nMichael Kay\nSoftware AG\n\n\n\n> \n> I believe the xpath2 spec to be incorrect in its definition.\n> \n> \n> \nhttp://www.w3.org/TR/xpath20/#id-order-comparisons\n\n2.6.4 Order Comparisons\n\n3. A comparison with the << operator returns true if the first operand \nnode is earlier than the second operand node in document order, or false \nif the first operand node is later than the second operand node in \ndocument order.\n4. A comparison with the >> operator returns true if the first operand \nnode is later than the second operand node in document order, or false if \nthe first operand node is earlier than the second operand node in document \norder.\n\n\n\nhttp://www.w3.org/TR/xquery-operators/#op-node-precedes\n\n11.1.9 op:node-precedes\nop:node-precedes(node $srcval1, node $srcval2) => boolean\n\nReturns true if the node identified by $srcval1 occurs before the node \nidentified by $srcval2 in document order, but is not an ancestor of the \nnode identified by $srcval2. Otherwise returns false. This function backs \nup the \"precedes\" operator on nodes.\n11.1.10 op:node-follows\nop:node-follows(node $srvcal1, node $srcval2) => boolean\n\nReturns true if the node identified by $srcval1 occurs after the node \nidentified by $srcval2 in document order, but is not a descendant of the \nnode identified by $srcval2. Otherwise returns false. This function backs \nup the \"follows\" operator on nodes.\n\n\n\n-- \nGareth Reakes, Head of Product Development  \nDecisionSoft Ltd.            http://www.decisionsoft.com\nOffice: +44 (0) 1865 203192\n\n\n\n", "id": "lists-017-15177389"}, {"subject": "Re: Migration of HTTP to the use of IRIs [altdesign17", "content": "Hello Chris,\n\nI have changed the issue for this mail to altdesign-17, because it\nseems more appropriate.\n\nAt 11:07 04/05/07 +0100, Chris Haynes wrote:\n\n>Michel,\n>\n>Thanks for this comment, but I think my point is still valid - even just for\n>presentational uses.\n>\n>Given that many URI encodings exist 'in the wild' which use %HH escaping of\n>non-UTF-8 sequences, I fail to see how one can know that it is valid to \n>convert\n>any such URI into an IRI (as per sect. 3.2) - even if just for presentational\n>purposes.\n\nSection 3.2 very clearly says that there is a risk that you convert\nto something that didn't exist previously.\nBut in practice, this is not that much of an issue, because it is\nvery rare to find reasonable text encoded in legacy encodings that\nmatches UTF-8 byte patters. Please try to find some examples yourself,\nand you will see this.\n\n\n>My concern is the same:  unless there is some kind of syntactic indicator \n>within\n>the URI as a whole, how can one reliably know that UTF-8 has been used and \n>that\n>it is intended to have a corresponding IRI?\n\nYou are correct that one cannot do this with 100% certainty.\nBut then, if you study the URI spec very carefully, you will\nfind that it also doesn't guarantee that an 'a' in an URI\nactually corresponds to an 'a' in the original data (e.g.\nfile name). For details, please see the \"Laguna Beach\"\nexample in Section 2.5 of draft-fielding-uri-rfc2396bis-05.txt,\nfor example at\nhttp://gbiv.com/protocols/uri/rev-2002/draft-fielding-uri-rfc2396bis-05.txt.\n\nSo in those rare cases where an URI with an octet sequence\nthat by chance corresponds to an UTF-8 pattern, but that was\nnever intended as UTF-8, is converted to an IRI, one will just\nget a weird name, but reusing that name again e.g. in a browser\nthat accepts IRIs will lead back to the original resource.\n\n\n\n>It seems to me that IRI will only be deployed accurately and effectively \n>if one\n>of the following situations occurs:\n>\n>1) New protocol schemes (e.g. httpi, httpis ) are introduced which make it\n>explicit that this spec. applies to the URI,\n\nIntroducing a new URI scheme is *extremely* expensive. I have heard\nTim Berners-Lee say this over and over again, and I know he knows it.\nAnd in the case at hand, it's highly unnecessary. The cost of an\noccasional accidental 'wrong' conversion back to an IRI (as discussed\nabove) is much, much smaller than the cost of introducing new schemes.\n\nAnd what would the real benefit of new schemes be? Would they be\nuseful to distinguish URIs from true IRIs (I'm writing 'true' IRIs\nhere to exclude URIs which are by definition also IRIs). Not really,\nit's much cheaper to identify IRIs by checking for non-ASCII characters.\n\nSo they would only be used to distinguish URIs without known origin\nfrom URIs originating from conversion from IRIs. But assume I had\nan IRI like like http://www.example.org/ros&#xE9; (rose'). In order\nto pass it to others whom I know can only process URIs, not IRIs,\nwould I want to convert it to http://www.example.org/ros%C3%A9,\nor to httpi://www.example.org/ros%C3%A9 ? The former strictly\nspeaking looses the information that this was an IRI, so converting\nit back to rose' is a guess (but because of the UTF-8 patters,\nactually a rather safe one). But it actually will go to the\nright page, on hunderds of millions of Web browsers, without\nexception. The later can safely be converted back to the IRI\n(by all the software that knows how to do this, which currently\nnumbers exactly 0). But it will work only on the browsers\nthat know the httpi: scheme (again, currently numbering\nexactly 0). For me the alternative is very clear,\nhttp://www.example.org/ros%C3%A9 works in much more cases,\nand is therefore much better.\n\n\n>2) They are used within a closed environment in which it is a convention that\n>only IRIs and IRI-derived URIs are in use (no legacy-encoding escapes, or they\n>are allowed to be mis-interpreted)\n\nThe current draft clearly allows legacy-encoded escapes, for backwards\ncompatibility. I'm not sure what you mean by 'mis-interpreted', but\nif you mean that they are converted to IRIs, then yes, the current\ndraft allows this in those cases where it is possible (i.e. the\nbyte pattern matches UTF-8,...). But this misinterpretation does\nnot lead to an actual misinterpretation of the resource that the\nIRI identifies.\n\n\n>3) A new market-dominating user agent is launched which behaves as if (2) \n>above\n>were the case - i.e. there is an attempt to establish IRIs as the de facto\n>default through market force, ignoring or discarding resulting errors of\n>presentation or of resource identification.\n>\n>My big fear is that without rapid progress on (1), IRIs on the open Internet\n>will only ever take off if someone does (3) - which will be without benefit of\n>adequate standards backing.\n\nI'm not sure I understand you. Several browsers, for example\nOpera and Safari, already implement IRIs. MS IE also does it\nif the relevant flag is set correctly. And the standard is\nclose to done; this is the last real issue I'm trying to close.\nSo I don't see the problem.\n\n\n>I'd love to either:\n>\n>a) be shown that my logic is faulty\n\nI guess yes. Not in theory, where absolute correctness is the\nonly goal, but in practice, where big numbers and deployment\nare important.\n\n>or\n>\n>b) be pleasantly surprised by being told that there _is_  RFC work taking \n>place\n>on new schemes covering at least the space of http(s)\n\nSome schemes may benefit from an update, in particular those that\nhaven't thought about internationalization. The first example that\nwould come to my mind is the mailto: scheme.\n\n\nRegards,    Martin.\n\n\n\n>otherwise, I fail to understand how IRIs will 'take off' in the 'real world' -\n>where they are so badly needed.\n>\n>Chris\n>\n>\n>\n>\n>----- Original Message -----\n>From: \"Michel Suignard\" <michelsu@windows.microsoft.com>\n>To: \"Chris Haynes\" <chris@harvington.org.uk>\n>Cc: <public-iri@w3.org>; \"Martin Duerst\" <duerst@w3.org>\n>Sent: Friday, May 07, 2004 1:43 AM\n>Subject: RE: Migration of HTTP to the use of IRIs [queryclarify-16]\n>\n>\n>\n> > From:  Chris Haynes\n> > Sent: Thursday, May 06, 2004 4:50 AM\n> >\n> > Actually, my original core concern has now been covered in your\n>section\n> > 1.2.a - Applicability, where you make it clear that \"the intent is not\n>to\n> > introduce IRIs into contexts that are not defined to accept them\".\n> >\n> > This now makes it clear that new schemas will be required to replace\n> > http: , https: etc. These will need to be self-identifying in some\n>way, so\n> > that receiving equipment will know that an IRI is being presented.\n> >\n> > So, as I commented last June, I await with interest the recognition\n>among\n> > those responsible for the HTTP schema that new schemas with new names\n>are\n> > required before IRIs can be used.\n>\n>I'd like to comment on that. The IRI spec is fairly explicit on that IRI\n>can be used as presentation elements for URI protocol elements (ref\n>clause 3 intro). This is to recognize that applications out there have\n>not waited for us for creating presentation layers that use non ascii\n>native characters for schemes that supposedly should not use them (such\n>as http). The presentation layer principle is there to support that. So\n>I expect IRI to be used for both purposes:\n>- presentation layer for existing URI schemes\n>- core layer for new schemes exclusively defined using IRI for protocol\n>elements syntax.\n>\n>For a while I'd expect the vast majority of IRI usage to be in the first\n>category.\n>\n>Michel\n>\n>\n\n\n\n", "id": "lists-017-1517787"}, {"subject": "Color Highlighting in document at  http://www.w3.org/TR/xslt20", "content": "Hello,\n\nFirst of all I would like to thank w3c for the work done to publish the draft.\n\nThe idea of highlighting the changes and additions using color is really great,\nas it would help users distinguish between old and new content. But, the colors\nare very bright and trying to read through the portions of highlighted text is\npainful.\n\nIn the interest of all the readers and users of the document, I request you to\nuse pleasant colors. It would be of great convenience to users with eyes\nalready tired from non-stop staring at the monitor.\n\nThank you.\n\nwith regards,\nAdam\n\n\n__________________________________________________\nDo You Yahoo!?\nHotJobs - Search Thousands of New Jobs\nhttp://www.hotjobs.com\n\n\n\n", "id": "lists-017-15186922"}, {"subject": "RE: Color Highlighting in document at  http://www.w3.org/TR/xslt2 0", "content": "> \n> The idea of highlighting the changes and additions using \n> color is really great, as it would help users distinguish \n> between old and new content. But, the colors are very bright \n> and trying to read through the portions of highlighted text \n> is painful.\n> \n\nI've switched from using 00ff00 and ffff00 to the much more subdued 66ff66\nand ffff66. I hope everyone finds these easier on the eye.\n\nMichael Kay\n\n\n\n", "id": "lists-017-15194401"}, {"subject": "XSLT 2.0 WD &ndash;&ndash; question about handling Nan", "content": "In section 12.2 of the WD, the last paragraph says that NaNs are less than\nany other value (including -INF).  This conflicts with the XML Schema Data\nModel description (sections 3.2.4 and 3.2.5), with which XSLT is supposed\nto conform, that says that NaNs are greater than all other values\n(including +INF).\n\nSo, we have two incompatible specs (3 if you count the IEEE 754 spec, \nwhich says a third thing about NaNs).  Who gets to make them right?\n\n\n-- \n\nJeff Kenton\nDataPower Technology, Inc.\n *** Wire Speed XSLT ***\n\nhttp://www.datapower.com/products.shtml\n\n\n\n", "id": "lists-017-15202105"}, {"subject": "Question about XPath 2.0 precedence rule", "content": "In the XPath 2.0 WD, in the Appendix, Section A.2 Precedence Order, the \nprecedence of various comparisons are all listed with equal values (4).  \nThis seems different from XPath 1.0 (Section 3.4), which has Relational \nExpressions at higher priority than Equality Expressions.\n\nIs this intentional? If so, it has been left out of Appendix F, which \nlists known incompatibilities between 1.0 and 2.0.\n\n-- \n\nJeff Kenton\nDataPower Technology, Inc.\n *** Wire Speed XSLT ***\n\nhttp://www.datapower.com/products.shtml\n\n\n\n", "id": "lists-017-15210507"}, {"subject": "XPath data model: identifying element/attribute typ", "content": "Hi,\n\nIn Section 3.6 of the latest Data Model WD, it says:\n\n  The type of an element information item is represented by an\n  expanded-QName whose namespace and local name corresponds to the\n  first applicable item in the following list:\n\n  - xs:anyType if the [validity] property is \"invalid\" or \"notKnown\", or\n\n  - the {target namespace} and {name} properties of the [member type\n    definition] schema component if that exists, or\n\n  - the {target namespace} and {name} properties of the [type\n    definition] schema component if that exists, or\n\n  - the [member type definition namespace] and the [member type\n    definition name] if [member type definition anonymous] exists and\n    is false, or\n\n  - the [type definition namespace] and the [type definition name]\n    if [type definition anonymous] exists and is false, or\n\n  - it corresponds to xs:anyType.\n\nNote that currently the last bullet point cannot be reached from a\nlegal PSVI because every element in a PSVI must have one of the\ncombinations of properties listed. Elements whose type definition is\n*anonymous* still have a [type definition] property, it's just that\nthe type definition's [name] is ?absent? (the property exists, I\nthink, but it has no value). Under the scheme above, such elements\nwould have type whose namespace was the target namespace of the schema\nand whose name was nothing.\n\nBTW, I'm not sure what distinction you're making between [name] and\n{name}. As I understand it in the XML Schema spec, {name} is a\nproperty on a schema component while [name] is a property on an\ninformation item in the PSVI. Since you're talking about properties in\nthe PSVI, I believe you should be using the notation [name] rather\nthan {name}.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15219317"}, {"subject": "data model of xslt/xpath 2.0 should be  extensibl", "content": "hello.\n\na quick look through the xpath 2.0 draft reveals that the underlying \ndata model seems to be hardwired to the xml infoset. however, it should \nbe extensible, so that infoset extensions could be handled. an example:\n\nhttp://dret.net/netdret/docs/tikrep148.pdf describes a proposal for an \nxlink data model in terms of infoset contributions. xpath and xslt \nshould be designed in a way that this infoset extension could be \nassociated with an identifier (for example, a namespace), and then i \ncould write an xpath using the new axis selecting link information items \nin a very simple way:\n\nsomeelement/xlinknamespaceprefix:link::title\n\ntheis would select the title property of the link item associated with \nthe someelement element. don't take this example literally, but i guess \nyou get the picture...\n\nare there any plans to support this kind of data model extensibility? \nplease see the following resources for related discussions:\n\nhttp://lists.w3.org/Archives/Member/w3c-xml-linking-ig/2002Aug/0000.html\nhttp://lists.xml.org/archives/xml-dev/200208/msg00831.html\n\neven though i am currently trying to push the issue of defining data \nmodels in terms of infoset extensions (in particular, an xlink data \nmodel), it is pretty hard to keep track of discussions fragmented over \nmultiple high-volume high-noise mailing lists. anybody has a better \nalternative for this?\n\ncheers,\n\nerik wilde  -  tel:+41-1-6325132  -  fax:+41-1-6321035\n           mailto:net.dret@dret.net -  http://dret.net/\n           computer engineering and networks laboratory\n           swiss federal institute of technology  (eth)\n           * try not. do, or do not. there is no try. *\n\n\n\n", "id": "lists-017-15227689"}, {"subject": "xf:escape-uri and utf", "content": "How is uri-escape(str, bool) to deal with unicode strings in str?\n\nIt seems to me that it should output the string in utf-8 encoded as hex\nstream with %s.\n\nThis has several payoffs:\n\nTransparent behaviour for uris:\nthe examples in the current draft continue to work\nAll of normal ascii gets encoded as expected\nWill behave the way most people expect\n\nA well-defined map for all of unicode\n\nPOST/GETs to CGIs can support internationalisation as long as they realize\ntheir data is in utf-8\n\nrfc822 mail headers for non-iso-8859 languages work simply:\n<xsl:text>Subject: =?utf-8?Q?</xsl:text>\n<xsl:value-of select=\"translate(uri-encode(subject, true), '%', '=')\"/>\n<xsl:text>?=<xsl:text>\n\nI am sure many other hacks are possible when one knows that the output is\nhas charset utf-8. So, please clarify the output charset used for encoding\nthe unicode string prior to hexifying it. This way all implementation will\nuse a common charset and greatly increase the utility of this function.\n\n-- \nWesley W. Terpstra <wesley@terpstra.ca>\n\n\n\n", "id": "lists-017-15235930"}, {"subject": "XQuery lexical stuff agai", "content": "XQuery 1.0: An XML Query Language \nW3C Working Draft 16 August 2002\n\n---------------------------------------------------------------------------\n3.1.5 Comments\n\n\"Comments may be used before and after major tokens within expressions and\nwithin element content.\"\n    What is a \"major token\"?\n\n---------------------------------------------------------------------------\nA.1 Lexical structure\n\n\"Legal characters are tab, carriage return, line feed, and the legal\ncharacters of Unicode and ISO/IEC 10646, as long as these characters are\nlegal XML characters as defined in the [XML] recommendation.\"\n    Why not just say:\n        Legal characters are those allowed in the [XML] recommendation.\n\n\"A lexeme is the smallest meaningful unit in the grammar that has syntactic\ninterpretation.\"\n    This doesn't appear to be true. For instance, the subsequent table\n    indicates that 'p:foo' is a lexeme, but it seems clear (to me, anyway)\n    that 'p' and 'foo' are smaller meaningful units that have syntactic\n    interpretation. (Note that I don't object to calling 'p:foo' a lexeme,\n    I just object to this definition.)\n\n    I think it's pointless to try to give that kind of definition for\n    'lexeme'. You'd be much better off saying something like:\n        A lexeme is any sequence of characters derived from one of the\n        following symbols: ...\n\n    Better yet, how about this:\n        For the grammar presented in A.2, the terminal symbols are:\n        (1) all of the quoted strings appearing in the grammar, and\n        (2)\n            NCName\n            QName\n\n            IntegerLiteral\n            DecimalLiteral\n            DoubleLiteral\n            StringLiteral\n\n            S\n            EscapeQuot\n            URLLiteral\n            PITarget\n            VarName\n            FuncName\n            NCNameForPrefix\n            PredefinedEntityRef\n            CharRef\n            EscapeApos\n            Char\n\n        [You might say that these terminal symbols are \"lexeme symbols\" or\n        \"lexical symbols\".]\n        A lexeme is any sequence of characters derived from (matching) one\n        of these symbols. (It is an 'instance' of that symbol.)\n\n\"A token is a symbol that matches lexemes,\"\n    A token is not a symbol. Normally, a token is an *instance* of a\n    symbol. But here, it doesn't even appear to be that. See later.\n\n\"and is the output of the lexical analyzer.\"\n    Why couldn't a lexical analyzer output lexemes?\n\n\"A token symbol is the symbolic name given to that token.\"\n    I wouldn't say that we \"give names to tokens\".  Really, a token symbol\n    is any symbol whose instances you choose to call tokens. So the best\n    way to define token symbols would be by listing them.\n\n\"A single token may be composed of one or more lexemes. If there is more\nthan one lexeme, they may be separated by whitespace or punctuation.\"\n    Surely not punctuation: if two lexemes are separated by punctuation,\n    the punctuation would itself be a lexeme.\n\n\"For instance, the token AxisDescendantOrSelf has two lexemes,\n\"descendant-or-self\" and \"::\".\"\n    Except that there is no such token (token symbol) any more. None of the\n    multi-part token symbols exist any more. So if you want to say that the\n    combination of \"descendant-or-self\" and \"::\" constitutes a token, then\n    it's a token that is not an instance of any symbol.\n\n    Given this, I think things might be clearer (and closer to standard\n    terminology) if you made the following changes in nomenclature:\n        \"token\"  -> \"token phrase\" or \"token pattern\"\n        \"lexeme\" -> \"token\"\n    (Note that \"token symbols\" can stay pretty much as is, because\n    everything currently called a token symbol is also what would currently\n    be called a lexeme symbol, and thus what would, after these changes, be\n    called a token symbol.)\n\n\"For instance, an implementation may decide that a token named 'For' ...\"\n    Huh? The token symbol 'For' doesn't exist any more.\n\n\"... is composed of only \"for\", or may decide that it is composed of\n(\"for\" \"(\").\"\n    Why would you have \"for\" followed by an open paren? Did you mean \"$\"\n    instead of \"(\"?\n\n    The idea that an implementation can decide what constitues a token\n    seems at odds with the rest of A.1.\n\n\"In the first case the implementation may decide to use lexical lookahead\nto distinguish the \"for\" lexeme from a QName that has the lexeme \"for\".\"\n    It might be clearer to say:\n        ... to distinguish the keyword \"for\" from the QName \"for\".\n\n    Mind you, A.3 says that \"for\" is a reserved word. If that means that\n    it's never allowed as a QName, then you wouldn't need lexical lookahead\n    to distinguish the two cases: the second is always illegal. In which\n    case, this is a poor example.  Or maybe A.3 means something else.\n\n\"Lexemes that must be described by lexical lookahead ...\"\n    You've just considered a case that could be handled/described by\n    lexical lookahead *or* by \"long tokens\". The \"must\" in the phrase in\n    question implies that some cases can *only* be handled/described by\n    lexical lookahead.  I don't think this is what you meant.\n\n\"... are delimited with the tokens that it must look ahead to, in order to\nbe recoginized, by \"<\" and \">\".\"\n    This is fairly clunky phrasing. I think this would convery your meaning\n    better:\n        In the BNF, the notation \"< ... >\" is used to indicate/delimit\n        a sequence of lexemes that must be recognized using lexical\n        lookahead or some equivalent means.\n\n    (Delete the first \"i\" in \"recoginized\".)\n\n\"This grammar implies lexical states\"\n    No, lexical states are an aspect of a particular implementation\n    strategy. The grammar does not imply them.\n\n\"the normative rules for calculating these states are given in the A.1.2\nLexical Rules section.\"\n    No such rules appear.\n\n\"Whitespace may be freely added between lexemes, except a few cases where\nwhitespace is needed to disambiguate the token.\"\n    So actually, whitespace may be freely added there as well; what you\n    can't do in those cases is freely *subtract* whitespace.\n\n\"Whitespace is not freely allowed in the Constructor productions\"\n    Except it's presumably allowed in the computed constructor productions.\n\n\"but is specified specifically in the grammar\"\n    \"specified specifically\" is a bit clunky. Maybe change \"specifically\"\n    to \"explicitly\".\n\n\"Lexically, these states are as follows\"\n    There isn't an antecedent for \"these states\".\n\n---------------------------------------------------------------------------\nA.1.1 Syntactic Constructs\n\n[149] Nmstart\n[150] Nmchar\n[232] NCNameForPrefix\n    The definition for Nmchar is the same as the definition of NCNameChar\n    in XML Namespaces.  Why not use it?\n\n    In fact, the only use of Nmstart and Nmchar is in NCNameForPrefix,\n    which is equivalent to NCName. Why not just use NCName, and drop\n    Nmstart and Nmchar completely?\n\n[193] Digits\n[236] HexDigits\n    I don't think you want these to be token symbols, because they only\n    occur within things that you *do* want to be token symbols: numeric\n    literals and character references.\n\n[229] FuncName\n    The definition is the same as that of QName. Why not use it?\n\n[255] WhitespaceChar\n    It doesn't make much sense to call this a token symbol, because it\n    only occurs in the definition of S, which is (supposedly) a token\n    symbol itself.\n\n---------------------------------------------------------------------------\nA.1.2 Lexical Rules\n\n\"there are various strategies that can be used by an implementation to\ndisambiguate token symbol choices\"\n    Disambiguation is something done by the language specification, not\n    implementations.\n\n\"This specification does not dictate what strategy to use.\"\n    Hurray!\n\n\"However, this section does describe normative rules with which these\ndecisions must conform to. ... An implementation need not follow this\napproach in implementing lexer rules, but does need to conform to the\nresults.\"\n    Argh! How can I convince you what a bad idea this is? Perhaps an\n    analogy would help. Imagine that the spec said this:\n\n        There are various strategies that can be used to parse queries.\n        Among the choices are recursive descent, LL(k), LR(k), GLR(k),\n        et cetera. This specification does not dictate what strategy\n        to use.  However, this section presents a normative LL(1)\n        parsing automaton which parsers must conform to.\n\n    Such a statement would be met (I suspect) with howls of indignation, as\n    (a) it favours a particular implementation strategy, making conformance\n        more difficult for anyone choosing to use a different strategy; and\n    (b) it's completely unnecessary, since the *grammar* is already all the\n        specification that implementers need. (Moreover, it's more concise,\n        more declarative, and more likely to be bug-free.)\n\n    Both of these arguments carry over to lexing. It isn't the spec's job\n    to define the lexer any more than it's the spec's job to define the\n    parser. Instead, it's the spec's job to define the *language*.\n\n    Note that I don't much mind if the spec contains this lexical\n    automaton, as long as it isn't normative in any way.\n\n    (By the way, \"with which these decisions must conform to\" has an extra\n    preposition. Delete \"with\", say.)\n\n\"For instance, instead of using ...\"\n    This sentence seems to belong more to the previous paragraph. Why not\n    combine it with the \"Among the choices\" sentence?\n\n\"a state automata\"\n    Change \"automata\" to \"automaton\".\n\n\"an implementation might use lexecal look-behind\"\n    Change \"lexecal\" to \"lexical\".\n\n\"a more ambiguous token strategy\"\n    Ambiguity is a property of grammars, so it's probably misleading to\n    use it to describe an implementation strategy.\n\n---------------------------------------------------------------------------\nA.2 BNF\n\nI think it would make more sense to put this section before A.1 Lexical\nStructure. In the same way that the grammar in this section has been laid\nout in a roughly top-down order (symbols are generally used, then defined),\nthe whole of Appendix A could be laid out this way. (The phrase-structure\ngrammar is ultimately defined in terms of terminal/lexical/token symbols,\nwhich are then defined in terms of sub-lexical symbols, which are then\ndefined in terms of character classes.) This is closer to how Appendix A\nused to be laid out; I'm not sure why it was changed.\n\n\"The following grammar uses the same Basic EBNF notation as [XML], except\nthat grammar symbols always have initial capital letters.\"\n    I still wonder what the reason for this exception is.\n\n    There's another exception: the use of < and > as delimiters.\n\n\"The EBNF contains the lexemes embedded in the productions.\"\n    Lexemes don't occur in the grammar, they occur in the texts derived\n    from (or matching) the grammar. Presumably you're referring to the\n    presence of quoted strings in the grammar. While this is different from\n    previous XQuery drafts, it isn't different from the EBNF notation of\n    XML or XPath 1.0 or most other places, so it's not really worth\n    pointing out.\n\n---------------------------------------------------------------------------\nA.3 Reserved Words\n\n\"The following is a list of reserved words for XQuery\"\n    But you don't define what this means. Presumably it means that their\n    use is illegal in certain contexts where it would otherwise appear to\n    be legal, but you need to specify what those contexts are.\n\n---------------------------------------------------------------------------\n\n-Michael Dyck\n\n\n\n", "id": "lists-017-15243344"}, {"subject": "Issue-0079: String-value vs. string-value of the typedvalu", "content": "Hi,\n\nI feel strongly that it would be a mistake to state that the\nstring-value() of an element (or attribute) is the string value of its\ntyped-value().\n\nFirst, consider what happens when an element has mixed content, for\nexample the string-value() of the element 'foo' in:\n\n  <foo xsi:type=\"fooType\">\n    blah <bar>blah</bar> blah\n  </foo>\n\nwhere the type definition of fooType is:\n\n<xs:complexType name=\"fooType\" mixed=\"true\">\n  <xs:choice minOccurs=\"0\" maxOccurs=\"unbounded\">\n    <xs:element name=\"bar\" />\n  </xs:choice>\n</xs:complexType>\n\nThis type definition has complex content, therefore attempting to\naccess the typed-value() of this element will cause an error. If\naccessing the string-value() also caused an error, this would make it\nvery tedious to do the otherwise very simple and common-place\noperation of pulling out the text within the foo element.\n\nI think it would be confusing if mixed-content elements or complex\ncontent elements were made an exception to a general rule.\n\nAlso, for elements with a simple type, I think it will be confusing\nfor XSLT users to find that getting the string value of the element\nusing xsl:value-of will give a different result from apply templates\nto the text node held by the element. XSLT authors are used to:\n\n<xsl:template match=\"bar\">\n  <xsl:value-of select=\".\" />\n</xsl:template>\n\nand:\n\n<xsl:template match=\"bar\">\n  <xsl:apply-templates />\n</xsl:template>\n\nbeing the same when bar only holds text.\n\nIn addition, I'll note that even when there is a small gap between the\nactual text in the source document and the text you can get hold of in\na transformation, people get confused. They wonder why they can't copy\nover entity references from the source to the result, for example.\nWhen people get the value of:\n\n  <value xsi:type=\"xs:double\">32</value>\n\nthey expect to get the string \"32\", not the string \"3.2E1\", because\nit's \"32\" in the source.\n\nYet another objection is the problem of what to do when you can't get\na string version of a value. What would the string value of this\nelement be, were the string value defined as the string value of the\ntyped value:\n\n  <foo xmlns:bar=\"http://www.example.com/\" xsi:type=\"xs:QName\">\n    bar:baz\n  </foo>\n\nFinally, just on a philosophical/political level, I think it's\nimportant to balance the view of those who think of XML as serialised\ndata (where what's important is the typed value of a node) and those\nwho think of XML as marked up text (where what's important is the\ncontent of node in the physical document). I think that equating the\nstring value to the string value of the typed value places an emphasis\non the data-oriented view of XML; retaining the distinction between\nthe two is much more balanced.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15261841"}, {"subject": "typed value of xs:anyType element", "content": "Hi,\n\nI have the feeling that I've commented on this before, but I still\ndon't like the fact that the typed value of an element with the type\nxs:anyType is computed by taking its string value and converting that\nto an atomic value of type xs:anySimpleType, whereas trying to get the\ntyped value of an element of any other type with complex content\ncauses an error.\n\nI think it should be consistently one way or the other. Either getting\nthe typed value of an element with the type xs:anyType should raise an\nerror or elements with types with complex content should have typed\nvalues based on converting their string value to an atomic value of\ntype xs:anySimpleType.\n\nEither way could work I think; the first option is only really\npractical if invalid/unvalidated elements don't have the type\nxs:anyType.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15271508"}, {"subject": "Data Model WD: [Issue0062: Namespace fixups required", "content": "Hi,\n\nFirst, I absolutely agree that namespace fixup (as described in\nSection 4.5 of the XSLT 2.0 WD) should be specified as part of the\nData Model, within the definition of element construction.\n\nSecond, when this gets done, remember that as well as the attributes\nof the element having their own namespace, the values of those\nattributes and possibly the element itself might be QNames and\ntherefore require namespace nodes to be added to the element. For\nexample:\n\n  <foo>\n    <xsl:attribute name=\"ns1:bar\"\n      namespace=\"http://www.example.com/ns1\"\n      type-annotation=\"xs:QName\"\n      xmlns:ns2=\"http://www.example.com/ns2\">ns2:baz</xsl:attribute>\n  </foo>\n\nshould generate a foo element with (among others) the namespace nodes\n{ns1, 'http://www.example.com/ns1'} and {ns2,\n'http://www.example.com/ns2'} so that the resulting XML is:\n\n  <foo xmlns:ns1=\"http://www.example.com/ns1\"\n       xmlns:ns2=\"http://www.example.com/ns2\"\n       ns1:bar=\"ns2:baz\" />\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15278853"}, {"subject": "op:concatenate vs. xf:conca", "content": "Hi,\n\nIt isn't an issue in XPath because the op:concatenate operator is an\n',' operator rather than a function, but having two\noperators/functions that have very similar names but do completely\ndifferent things is very confusing in the Data Model WD.\n\nThe definition of infoitem-to-text-nodes() in Section 4.7.4 of the\nData Model WD, for example, uses both op:concatenate() and xf:concat()\nin the same expression. I found it hard to understand what was going\non until it came to me that op:concatenate() must be combining\nsequences while xf:concat() combines strings.\n\nPerhaps op:concatenate's name could be changed to something more\nexplicit, such as op:construct-sequence?\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15287342"}, {"subject": "Data Model WD: infoitem-to-textnodes() functio", "content": "Hi,\n\nI might be missing something, but I think that the definition of\ninfoitem-to-text-nodes() function is wonky. The definition in the Data\nModel WD is:\n\ndefine function infoitem-to-text-nodes(Node* $nodes)\n       returns Node* \n{\n  if (xf:empty($nodes)) then return empty-sequence()\n  else\n    let $head:= op:item-at($nodes, 1), \n        $tail:= xf:subsequence($nodes, 2)\n    return\n      if (dm:node-kind($head) = \"text\") then\n        /* Collapse two consecutive text nodes and apply \n           infoitem-to-text-nodes recursively */\n        if (xf:empty($tail)) then $head\n        else if (dm:node-kind(op:item-at($tail,1))=\"text\") then \n          infoitem-to-text-nodes(\n            op:concatenate(\n              dm:text-node(xf:concat(dm:string-value($head),\n                   dm:string-value(op:item-at($tail,1)))), \n              xf:subsequence($tail, 2)\n            )\n          )\n        else op:concatenate($head,\n               op:concatenate(op:item-at($tail,1),\n                              infoitem-to-text-nodes($tail)))\n      else op:concatenate($head, infoitem-to-text-nodes($tail))\n  }\n\nConsider the operation over the content of the foo element in:\n\n  <foo> blah <bar /></foo>\n\nHere, the sequences of nodes is a text node, followed by a bar\nelement. I'll call these $node[1] and $node[2]. Running through the\nfunction we get:\n\n1st recursion:\n  $head = ( $node[1] )\n  $tail = ( $node[2] )\n\n  // $head is text; $tail[1] isn't empty and isn't text\n  \n  return\n    op:concatenate($node[1],\n      op:concatenate($node[2],\n                     infoitem-to-text-nodes( ($node[2]) )))\n\n2nd recursion:\n  $head = ( $node[2] )\n  $tail = ()\n\n  // $head isn't text\n  \n  return\n    op:concatenate( $node[2], () )\n\nSo we end up with:\n\n  ( $node[1], $node[2], $node[2] )\n\nwhereas I think we want:\n\n  ( $node[1], $node[2] )\n\nThe problem is here:\n\n        else op:concatenate($head,\n               op:concatenate(op:item-at($tail,1),\n                              infoitem-to-text-nodes($tail)))\n\nwhich I think should be:\n\n        else op:concatenate($head,\n               op:concatenate(op:item-at($tail, 1),\n                 infoitem-to-text-nodes(xf:subsequence($tail, 2))))\n\nor possibly, for simplicity:\n\n        else op:concatenate($head,\n                            infoitem-to-text-nodes($tail))\n  \nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15294469"}, {"subject": "Data Model WD: Error checkin", "content": "Hi,\n\nI think that there needs to be some clarification and consistency in\nthe Data Model WD regarding whether the\nconstructors/accessors/functions defined in the Data Model WD can\nraise errors and what happens when they do.\n\nI had been going to post a comment about error-checking in the node\nconstructor functions. For example, I expected something about what\nhappens if a comment is constructed with a value that contains \"--\" or\nwhat happens if an element is constructed with a sequence of\nattributes that includes two attributes with the same name.\n\nThen I thought that you'd probably left out these things deliberately\nbecause you wanted the host language for XPath (e.g. XSLT or XQuery)\nto determine what happens in these cases, and didn't want to specify\nerror checking/handling within the data model.\n\nBut now I've come to Section 5, where it says (in the 5th paragraph):\n\n  An atomic value can be constructed from its lexical representation.\n  dm:atomic-value takes a string and a corresponding atomic type and\n  constructs an atomic value in such a way to be consistent with\n  validation. In particular the construction takes into consideration\n  the facets of the type. **If the string does not represent a valid\n  value of the type an error is raised**...\n\nIs this mention of errors an oversight, or is there some rationale\nbehind some errors being detected and others not?\n\nFor what it's worth, I think that the data model *should* define all\nthe error checking that goes on when constructing nodes and values,\nbecause that ensures that the various host languages of XPath detect\nthe same set of errors. The host languages themselves should be able\nto decide what to do when an error gets raised, of course...\n  \nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15303344"}, {"subject": "Data Model WD: dm:atomic-valuesequence() functio", "content": "Hi,\n\nIn the Data Model WD, the definition of the dm:atomic-value-sequence()\nfunctions says:\n\n  If an atomic type is used as the argument to\n  dm:atomic-value-sequence... When a list type is used with\n  dm:atomic-value-sequence... Using xs:anySimpleType as the\n  argument.... Using xs:anyType as the argument... If a complex type\n  with complex content is used to invoke the constructor...\n\nThere are two kinds of types that are missing from this definition and\nthat should be added:\n\n  1. complex types with simple content\n  2. union types\n\nPresumably complex types with simple content are treated like the\nsimple type of the simple content, and if the simple content has an\nanonymous type then they're treated like xs:anySimpleType (although\nhopefully that'll change once you've decided how to treat anonymous\ntypes more generally).\n\nFor 2, presumably the constructor goes through the member types of the\nunion type one by one, in order, until it finds one that doesn't raise\nan error when it's used to construct the atomic value sequence, and\nthis it the type that gets used.\n\nThe other thing is that the definition for a list type argument is\ncurrently:\n\n  When a list type is used with dm:atomic-value-sequence the resulting\n  sequence will contain atomic values whose type is the item type of\n  the list type.\n\nThere's no guarantee that the item type of a list type is going to be\nan atomic type. It could easily be a union type. The phrasing of this\nsentence needs to be altered a bit to cater for this possibility.\n  \nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15311538"}, {"subject": "Data Model and F&amp;O WD: string values of atomic value", "content": "Hi,\n\nIn Section 5 of the Data Model WD, it says:\n\n  The accessor dm:string-value can be used to recover a lexical\n  representation of the atomic value. The details of converting an\n  atomic value to its string representation are described in the\n  \"Casting Functions\" section of [XQuery 1.0 and XPath 2.0 Functions\n  and Operators]. In particular if the atomic value's type is\n  primitive, dm:string-value returns the atomic value's canonical\n  lexical representation for that primitive type as specified in\n  [XMLSchema Part 2]. If the atomic value's type is derived, the\n  lexical representation depends on whether a value is supplied for\n  the type's pattern facet: If no such value is supplied\n  dm:string-value returns the atomic value's canonical lexical\n  representation for the base type (which is a primitive type).\n  Otherwise dm:string-value returns a lexical representation that\n  matches the value specified for the pattern facet. (This case\n  includes xs:integers.)\n\nThere are several things that confuse me here, specifically in the\nsecond half of this paragraph.\n\nI can't find the place in the F&O WD where it talks about casting from\na derived type to a string (e.g. from an integer to a string). The F&O\nWD talks about casting from a derived type to *its* primitive type in\nSection 16.2 and about casting from a primitive type to a string in\nSection 16.6, but there's nothing that I can see about casting\ndirectly from a derived type to a string.\n\nThere is a hint that you might be able to pipeline the two casts\ntogether in one step, so:\n\n  cast as xs:string(xs:integer('2'))\n\nwould be the same as:\n\n  cast as xs:string(\n    cast as xs:decimal(xs:integer('2')))\n\nbut if you did that then you'd lose information about the fact that\nintegers can't have any significant decimal places, and you'd get the\nstring \"2.0\" rather than \"2\".\n\nThe only mention of the pattern facet that I can find in the \"Casting\nFunctions\" section of the F&O WD is where it talks about casting\nbetween two types that are both derived from the same primitive type,\nwhich doesn't apply in this case.\n\nPerhaps when this part of the Data Model WD says:\n\n  The details of converting an atomic value to its string\n  representation are described in the \"Casting Functions\" section of\n  [XQuery 1.0 and XPath 2.0 Functions and Operators]. In particular...\n\nIt means:\n\n  The normal method of converting an atomic value to its string\n  representation is described in the \"Casting Functions\" section of\n  [XQuery 1.0 and XPath 2.0 Functions and Operators]. In this case,\n  though...\n\nOr perhaps the F&O WD hasn't yet been updated with the decisions\ndescribed in this section of the Data Model WD.\n  \nBTW, I should note that in the XML Schema for XML Schema, xs:integer\nis defined as:\n\n  <xs:simpleType name=\"integer\" id=\"integer\">\n    <xs:annotation>\n      <xs:documentation\n        source=\"http://www.w3.org/TR/xmlschema-2/#integer\"/>\n    </xs:annotation>\n    <xs:restriction base=\"xs:decimal\">\n      <xs:fractionDigits value=\"0\" fixed=\"true\" id=\"integer.fractionDigits\"/>\n    </xs:restriction>\n  </xs:simpleType>\n\nThe pattern facet isn't set in this definition, nor mentioned in the\nprose description, although I agree that it should be, since the valid\nlexical representations for integers do not include the canonical\nlexical representations for decimals. Perhaps you can suggest this as\nan erratum.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15319674"}, {"subject": "Data Model WD: Appendix ", "content": "Hi,\n\n(I seem to comment on this appendix in every draft, sorry!)\n\nThere are a couple of problems with the schema in Appendix D of the\nData Model WD.\n\n<xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\n           targetNamespace=\"http://www.example.com/PartSchema\"\n           xmlns=\"http://www.example.com/PartSchema\"\n           elementFormDefault=\"qualified\">\n  <xs:element name=\"part\" type=\"part-type\"/>\n  <xs:complexType name=\"part-type\">\n    <xs:sequence>\n      <xs:element name=\"mfg\" type=\"xs:string\"/>\n      <xs:element name=\"price\" type=\"xs:decimal\"/>\n    </xs:sequence>\n    <xs:attribute name=\"name\" type=\"part-name\"/>\n  </xs:complexType>\n  <xs:simpleType name=\"part-name\">\n    <xs:restriction base=\"xsd:string\">\n      <xs:pattern value=\"[A-Z]{2}-\\d{3}-[A-Z]*\"/>\n    </xs:restriction>\n  </xs:simpleType>\n</xs:schema>\n\nFirst, in the part-name simple type definition, the xs:restriction\nelement has a base attribute with the value 'xsd:string'. That should\nbe 'xs:string', or you should add a namespace declaration associating\nthe prefix 'xsd' with the XML Schema namespace.\n\nSecond, I think that the pattern for the part-name type should be:\n\n  [A-Z]{2}-\\d{3}-[a-z]*\n\nAt least, in the instance that you claim to be valid against this\nschema, the part-name is \"NB-401-nutbolt\" which doesn't match the\npattern as currently specified.\n\nIf you make those changes it validates according to Xerces-J, and by\neye.\n\nThere are also a couple of problems in the description of the data\nmodel generated from the instance and the schema.\n\nFirst, dm:type(A1) (the type of the name attribute) should be\n\n  xf:QName-from-uri(\"http://www.example.com/PartSchema\",\n                    \"part-name\")\n\nshouldn't it? Or was the invalidity on purpose? If it was, then\nsurely dm:typed-value(A1) should be:\n\n  dm:atomic-value(\"NB-401-nutbolt\",\n      xf:QName-from-uri(\"http://www.w3.org/2001/XMLSchema\",\n                        \"anySimpleType\"))\n\nand dm:type(A1) should be:\n\n  xf:QName-from-uri(\"http://www.w3.org/2001/XMLSchema\",\n                    \"anySimpleType\")\n\nSecond, dm:string-value(A2) (the string value of the\nxsi:schemaLocation attribute) seems to have a '\\' in it? I'm not sure\nwhat that's doing there, or is it meant to indicate that there's an\ninsignificant line break?\n\nFinally, in the picture, the schemaLocation attribute should probably\nbe called xsi:schemaLocation, since the other qualified nodes use the\nprefix to indicate their namespace.\n\nAs it stands, this example is fairly straight-forward. It would be\ngreat if this example could be turned into something that really\ndemonstrated some of the stickier features of the data model, such as:\n\n  - partial validity\n  - union types\n  - list types\n  - lists of unions\n  - unions of lists\n  - whitespace normalisation of values\n  - the effect of xml:base\n  - anonymous types\n  - a schema with more than one level in the type hierarchy\n\nI think that such an example would greatly illuminate the spec.\n  \nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15330001"}, {"subject": "[public-qtcomments] &lt;none&gt", "content": "in the document: \"XML Query Use Cases  W3C Working Draft 16 Aug 2002\"\n\n1.1.9.7 Q7\n\nList the titles and years of all books published by Addison-Wesley after \n1991, in alphabetic order.\nSolution in XQuery:\n<bib>\n   {\n     for $b in document(\"www.bn.com/bib.xml\")//book\n     where $b/publisher = \"Addison-Wesley\" and $b/@year > 1991\n     return\n         <book>\n             { $b/@year }\n             { $b/title }\n         </book>\n     sort by (title)\n   }\n</bib>\nExpected Result:\n<bib>\n     <book year=\"1992\">\n         <title>Advanced Programming in the Unix environment</title>\n     </book>\n     <book year=\"1994\">\n         <title>TCP/IP Illustrated</title>\n     </book>\n</bib>\n\n$b/@year is interpreted as an attribute of the <book>\n\n1.5.4.6 Q6\nList the short titles of all sections (the values of the \"shorttitle\" \nattributes of all \"section\" elements, expressing each short title as the \nvalue of a new element.)\nSolution in XQuery:\n<result>\n   {\n     for $s in input()//section/@shorttitle\n     return <stitle>{ $s }</stitle>\n   }\n</result>\nExpected Result:\nAttribute values in start-tags on lines 23, 50, 59\n\nIf I interprete \"...each short title as the value of a new element\"\nThe result should be:\n\n<result>\n<stitle>What is markup?</stitle>\n<stitle>What is SGML?</stitle>\n<stitle>How does SGML work?</stitle>\n</result>\n\nIs this interpretation correct?\nIf yes, what makes the different interpretation of attributes in 1.1.9.7 Q7 \nand1.5.4.6 Q6 ?\n\nWhat is the expected result of the query:\n\n     for $y in document(\"www.bn.com/bib.xml\")//book/@year\n     return $y\n\n\n\n", "id": "lists-017-15340461"}, {"subject": "XML Query and XSL WGs on break until Sep", "content": "After publishing our specifications on Aug 16 the XML Query and XSL\nWorking Groups are taking a well-disserved rest and will not be meeting\nagain until the first week in September.  \n\nThis may delay responses from WG members to your comments on the new\nWorking Drafts.  Please be patient.\n\n/paulc\nChair, XML Query WG\n\nPaul Cotton, Microsoft Canada \n17 Eleanor Drive, Nepean, Ontario K2E 6A3 \nTel: (613) 225-5445 Fax: (425) 936-7329 \n<mailto:pcotton@microsoft.com> \n\n\n\n", "id": "lists-017-15349143"}, {"subject": "Re: what should the charset be in the response to the serve", "content": "Hello Chris,\n\nMany thanks for your clear response. I have closed this issue.\n\nRegards,    Martin.\n\nAt 10:30 04/05/07 +0100, Chris Haynes wrote:\n\n>Martin,\n>\n>Many thanks for the response.\n>\n>Your expanded sentence fully addresses this issue, as far as I am concerned.\n>\n>Chris\n>\n>\n>----- Original Message -----\n>From: \"Martin Duerst\" <duerst@w3.org>\n>To: \"Chris Haynes\" <chris@harvington.org.uk>; <www-international@w3.org>\n>Cc: \"Michel Suignard\" <michelsu@microsoft.com>; <public-iri@w3.org>\n>Sent: Friday, May 07, 2004 7:02 AM\n>Subject: Re: what should the charset be in the response to the server\n>\n>\n> >\n> > Hello Chris,\n> >\n> > Many thanks for your reply. I have copied the IRI list\n> > because I think this discussion is relevant for the current\n> > draft.\n> >\n> > At 13:38 04/05/06 +0100, Chris Haynes wrote:\n> > >Thanks for the response, Martin,\n> > >\n> > >I only noticed this response _after_ I had replied to your other response\n> > >on the\n> > >IRI list, so I apologize that my earlier response did not take into\n> > >account this\n> > >message of yours.\n> > >\n> > >Trying to bring this topic to closure, I think my core worry arises \n> each time\n> > >there are what-appear-to-me-to-be normative statements that 'the page\n>encoding\n> > >determines the encoding used in requests derived from that page' -\n> > >ignoring the\n> > >possibility of users having changed the encoding setting.\n> > >\n> > >We obviously both agree that users 'should not' use these controls \n> (just as I\n> > >diapprove of the use of 'tone controls' and spectral filters in Hi Fi \n> systems\n> > >for other than 'loudness' compensation), but I get worried every time the\n> > >possibility of their use is ignored.\n> > >\n> > >The situation is not purely  'theoretical ' I've seen reports that it is\n> > >common\n> > >practice in some countries for people to switch to their 'national' \n> character\n> > >set every time they appear to have a problem in viewing a page - which\n> > >could be\n> > >occasioned by their browser not having UTF-8 support.\n> >\n> > Ok, so let's have a look at this case: Either switching to their 'national'\n> > character encoding solves the problem, in which case the page was badly\n> > labeled, and the page author is to blame. Or switching does not solve\n> > the problem, in which case the user may even not be able to read the\n> > page, and therefore won't fill in the form. Or the page only contains\n> > US-ASCII characters to begin with, and the user doesn't have any reason\n> > to switch encodings.\n> >\n> > That probably leaves us with just one intermediate case: The page is\n> > mostly in US-ASCII, but with a few other characters (e.g. 'smart \n> quotes',...).\n> > The user sees some problem, tries to fix it by switching the encoding.\n> > That doesn't help, so the user gives up, and just fills in the form\n> > (which is readable enough to complete the task).\n> >\n> > If you know about any other scenarios where switching encoding and then\n> > filling in the form with a wrong encoding can happen realistically,\n> > please tell me.\n> >\n> >\n> > >I help provide support to the users of an open-source web server, and we\n> > >frequently get requests for help from people managing web services who,\n>having\n> > >read the appropriate RFCs and W3 specs in detail, had not appreciated that\n> > >user\n> > >agents can change the encoding in ways which the request-receiving server\n> > >cannot\n> > >detect.\n> >\n> > I was giving a tutorial about Web internationalization for years, and\n> > the issue of encoding in forms always came up, but from the time when\n> > the first browsers supporting UTF-8 came out, that was always given as\n> > an answer, and I haven't heard anybody question this before you. But\n> > of course your mileage may vary.\n> >\n> > But there is an additional point: A server isn't helpless against users\n> > changing the encoding. UTF-8 has the very helpful property of having\n> > very specific byte sequences. It is easy to check these with a\n> > regular expression, for an example, please see\n> > http://www.w3.org/International/questions/qa-forms-utf-8.html.\n> >\n> >\n> > >I suppose I'm just keen to make sure that wherever this topic appears, the\n> > >potential behavior of the vast majority of browsers in the world is\n>adequately\n> > >and completely described.\n> > >\n> > >If there were an RFC somewhere which said that the user agent 'MUST NOT'\n> > >change\n> > >the encoding, and that real-world browsers were ignoring this stricture, I\n> > >would\n> > >agree that other RFCs were right to describe what should be, rather \n> than what\n> > >is.\n> > >\n> > >But as far as I know, the ability for users to override the encoding \n> does not\n> > >contravene any existing RFC, and therefore other RFCs ought at least to\n> > >recognize that possibility, and not infer, by omission, a level of \n> certainty\n> > >which can never be assured.\n> > >\n> > >I think I would have a very poor view of any web site which told me it \n> was my\n> > >fault a request got garbled because I made use of a freely-available\n> > >control on\n> > >my browser.\n> > >\n> > >Let me try to conclude this by just asking that, so long as user \n> control over\n> > >the encoding is permitted by RFCs, that possibility is explicitly\n> > >recognized by\n> > >other RFCs., and that we dont try to pretend that it does not exist \n> or, even\n> > >worse, that failures and errors in decoding are the user's fault for\n> > >breaking an\n> > >unwritten, untestable  non-rule.\n> >\n> > I'm still not sure to what extent this is really happening. But I have\n> > clarified this issue by expanding the sentence in question as follows:\n> >\n> > \"Likewise, when setting up a new Web form using UTF-8 as the encoding\n> > of the form page, the returned query URIs will use UTF-8 as an encoding\n> > (unless the user for whatever reason changes the character encoding)\n> > and will therefore be compatible with IRIs.\"\n> >\n> > This leaves it to the reader to judge for him/herself how high\n> > the probability is that the user is switching code pages.\n> >\n> > Regards,    Martin.\n> >\n> >\n> > >Chris\n> > >\n> > >\n> > >----- Original Message -----\n> > >From: \"Martin Duerst\" <duerst@w3.org>\n> > >To: \"Chris Haynes\" <chris@harvington.org.uk>; <www-international@w3.org>\n> > >Cc: \"Michel Suignard\" <michelsu@microsoft.com>\n> > >Sent: Thursday, May 06, 2004 8:04 AM\n> > >Subject: Re: what should the charset be in the response to the server\n> > >\n> > >\n> > > > Hello Chris,\n> > > >\n> > > > In trying to clear up the remaining IRI issues, I found out that\n> > > > I planned to reply to this message of yours, but didn't get around\n> > > > to do it.\n> > > >\n> > > > At 17:20 03/08/07 +0100, Chris Haynes wrote:\n> > > >\n> > > > >  \"Martin Duerst\" Replied:\n> > > > >\n> > > > >\n> > > > > > At 12:15 03/07/26 +0100, Chris Haynes wrote:\n> > > > > >\n> > > > > > >  \"Jungshik Shin\" replied at: Saturday, July 26, 2003 11:31 AM\n> > > > > >\n> > > > > > > >   It also depends on whether or not you set 'send URLs \n> always in\n> > > > > > >UTF-8' in\n> > > > > > > > Tools|Options(?) in MS IE.\n> > > > > > > >\n> > > > > > >\n> > > > > > >True, but I'm trying to find a 'reliable' mechanism which is not\n> > > > > > >dependent on user-accessible controls.\n> > > > > > >IMHO, this is also a 'dangerous' option, in that it goes \n> agains the\n> > > > >de\n> > > > > > >facto conventions and anticipates (parhaps incorrectly) the\n> > > > > > >recommendations of the proposed IRI RFC. It can only safely be \n> used\n> > > > > > >with a 'consenting' server site.\n> > > > > >\n> > > > > > Sorry, no. The main dangerous thing is that authors use non-ASCII\n> > > > > > characters in URIs (without any %HH escaping) when this is clearly\n> > > > > > forbidden.\n> > > > > >\n> > > > > > Regards,  Martin.\n> > > > >\n> > > > >\n> > > > >Martin,\n> > > > >\n> > > > >Are you saying that you approve of relying on users to select the\n> > > > >(Microsoft-specific)  'send URLs always in\n> > > > >UTF-8'  menu option  to ensure that UTF8 gets returned to the server?\n> > > > >\n> > > > >That is what was being suggested.\n> > > >\n> > > > Well, my above statement was meant in the following sense:\n> > > > There is NO spec that would allow inclusion of non-ASCII\n> > > > characters in URIs. The IRI spec is the first one that\n> > > > defines something similar to an URI that actually allows this.\n> > > > Any authors that for example put raw iso-8859-1 characters\n> > > > into an URI in a page in iso-8859-1 are therefore wrong;\n> > > > any 'it works' effect is coincidental, not according to specs.\n> > > > Suggesting that a browser that anticipates a future spec\n> > > > (the IRI spec) is dangerous, while (implicitly) blessing\n> > > > browsers and pages that don't conform to any spec is in\n> > > > my eyes a dangerous idea.\n> > > >\n> > > >\n> > > > >My argument was that any current HTTP-like system in which the\n> > > > >character encoding could be modified by menu controls in the user\n> > > > >agent, (and in which the actual encoding used is *not* conveyed in the\n> > > > >request) was inherently unreliable.\n> > > >\n> > > > I think we have to look at different parts of a HTTP request \n> separately.\n> > > > There are mainly two parts: the 'path' part and the 'query' part.\n> > > >\n> > > > With respect to the path part, this is indeed influenced by the\n> > > > 'send URLs always in UTF-8' option in MS IE. But there are ways\n> > > > to get around this. For an example, see my Apache 'mod_fileiri'\n> > > > module, which allows to map requests both in a legacy encoding and\n> > > > in UTF-8 back to the file in question.\n> > > > [see http://www.w3.org/2003/06/mod_fileiri/Overview.html for an \n> overview,\n> > > > including pointers to the actual code and to a talk of mine].\n> > > >\n> > > > With respect to the query part, this is not affected by the\n> > > > 'send URLs always in UTF-8' option in MS IE. The query part\n> > > > is always sent in the encoding of the actual page, except\n> > > > for some browsers that implement the 'accept-charset' attribute\n> > > > on <form>. But for queries, it is rather easy to e.g. convert\n> > > > all the forms related to that query URI to UTF-8.\n> > > >\n> > > > You are right that the (perceived) character encoding of the\n> > > > page can affect both parts. Of course, users might always\n> > > > change the character encoding, and as a result send something\n> > > > that the server gets as garbage. However, users don't use\n> > > > menus just for fun, and if anybody would ever come and complain,\n> > > > the server side would be very justified to say \"don't mess\n> > > > around with the settings if you expect your queries to work\".\n> > > > So this is very much a theoretical concern.\n> > > >\n> > > >\n> > > > Regards,    Martin.\n> > > >\n> > > >\n> >\n> >\n\n\n\n", "id": "lists-017-1535180"}, {"subject": "Typos in the F&amp;O August working draf", "content": "In my reading of the F&O draft I noticed a number of typos and minor\nerrors, listed below.  Hope it's helpful.\n\nThanks,\nPriscilla\n\n\n8.4.6 - xf:get-seconds-from-dayTimeDuration says it returns an integer\n(in the signature) - shouldn't that be a decimal?\n\n8.4.9.1 - example shows the wrong function name (year instead of day)\n\n8.4.11.1 - missing colon in xs:dateTime\n\n8.4.21.1 - xf:time should be xs:time\n\n8.5.8 - op:divide-dayTimeDuration - says result is rounded to the\nnearest month. I imagine that no rounding takes place, but if it does it\nwould be to the nearest second.\n\n8.6.1 through 8.6.5  All the examples are missing the seconds portion of\nthe time values (both in the arguments and the results.)  \n\n8.7.3 and 8.7.4 both the subtract-dates and subtract-times function say\n\"If the value of $srcval1 follows in time the value of $srcval2, then\nthe returned value is a negative duration.\" but this conflicts with what\nis shown in the examples.  I think this is meant to be reversed?\n\n8.7.3.1 - second xs:date is missing a quote\n\n8.7.4.1 - second xs:time value is missing a leading zero (needs to be 09\ninstead of 9)\n\n8.7.8.1 - shouldn't the result of the example be 2000-10-27T09:57:00\n(one day earlier?)\n\n8.7.11.1 - first constructor should be xs:date not xs:dateTime.  Also\nneed a space between \"thedate\" and there's an extra quote at the end of\nthe sentence\n\n13.1 - in the summary table, description of the local-name function says\nit returns a QName rather than an NCName.\n\n14.2.6 - example shows the wrong function name (empty instead of exists)\n\n16.1 - the table does not appear to reflect the ability to cast between\nthe various date and time types, as described in section 16.8.\n\n16.8 item 6, 1st bullet point - looks like it's constructing a gMonthDay\nvalue instead of a gYearMonth value\n\n16.8 item 7, 2nd bullet point says \"If ST is gYearMonth, then TV is SV.\"\nI think this is meant to say gYear instead of gYearMonth, since you are\ncasting to gYear\n\n\n\n", "id": "lists-017-15358421"}, {"subject": "Re: [public-qtcomments] &lt;none&gt", "content": "At 12:34 PM 8/19/2002 -0400, Fei Sha wrote:\n\n>in the document: \"XML Query Use Cases  W3C Working Draft 16 Aug 2002\"\n>\n>1.1.9.7 Q7\n>$b/@year is interpreted as an attribute of the <book>\n\nYes.\n\n>1.5.4.6 Q6\n>List the short titles of all sections (the values of the \"shorttitle\" \n>attributes of all \"section\" elements, expressing each short title as the \n>value of a new element.)\n>\n>If I interprete \"...each short title as the value of a new element\"\n>The result should be:\n>\n><result>\n><stitle>What is markup?</stitle>\n><stitle>What is SGML?</stitle>\n><stitle>How does SGML work?</stitle>\n></result>\n>\n>Is this interpretation correct?\n\nThe text is misleading. The query would actually return:\n\n<result>\n<stitle shorttitle=\"What is markup?\"/>\n<stitle shorttitle=\"What is SGML?\"/>\n<stitle shorttitle=\"How does SGML work?\"/>\n</result>\n\nThe query could have been written differently to produce the result you \ngive, eg:\n\n<result>\n  {\n   for $s in input()//section/@shorttitle\n   return <stitle>{ string-value($s) }</stitle>\n  }\n</result>\n\nI will change either the query or the text for the next Working Draft.\n\n>What is the expected result of the query:\n>\n>     for $y in document(\"www.bn.com/bib.xml\")//book/@year\n>     return $y\n\nOur answers to use  cases are generally presented as serialized XML text, \nbut not every instance of the data model can be serialized as well-formed \nXML. In this case, you have a sequence of attributes, which is a perfectly \nvalid query result, but can not be serialized as an XML document. That's \nwhy we put the attributes into elements in the query in 1.5.4.6 Q6.\n\nJonathan\n\n\n\n", "id": "lists-017-15366888"}, {"subject": "RE: Data Model WD: Appendix ", "content": "> I think that such an example would greatly illuminate the spec.\n\nWould you like to supply such an example?  I am sure the WGs would be\nglad to consider such a submission.\n\n/paulc\n\nPaul Cotton, Microsoft Canada \n17 Eleanor Drive, Nepean, Ontario K2E 6A3 \nTel: (613) 225-5445 Fax: (425) 936-7329 \n<mailto:pcotton@microsoft.com> \n\n\n> -----Original Message-----\n> From: Jeni Tennison [mailto:jeni@jenitennison.com]\n> Sent: Monday, August 19, 2002 6:42 PM\n> To: public-qt-comments@w3.org\n> Subject: Data Model WD: Appendix D\n> \n> \n> Hi,\n> \n> (I seem to comment on this appendix in every draft, sorry!)\n> \n> There are a couple of problems with the schema in Appendix D of the\n> Data Model WD.\n> \n> <xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\n>            targetNamespace=\"http://www.example.com/PartSchema\"\n>            xmlns=\"http://www.example.com/PartSchema\"\n>            elementFormDefault=\"qualified\">\n>   <xs:element name=\"part\" type=\"part-type\"/>\n>   <xs:complexType name=\"part-type\">\n>     <xs:sequence>\n>       <xs:element name=\"mfg\" type=\"xs:string\"/>\n>       <xs:element name=\"price\" type=\"xs:decimal\"/>\n>     </xs:sequence>\n>     <xs:attribute name=\"name\" type=\"part-name\"/>\n>   </xs:complexType>\n>   <xs:simpleType name=\"part-name\">\n>     <xs:restriction base=\"xsd:string\">\n>       <xs:pattern value=\"[A-Z]{2}-\\d{3}-[A-Z]*\"/>\n>     </xs:restriction>\n>   </xs:simpleType>\n> </xs:schema>\n> \n> First, in the part-name simple type definition, the xs:restriction\n> element has a base attribute with the value 'xsd:string'. That should\n> be 'xs:string', or you should add a namespace declaration associating\n> the prefix 'xsd' with the XML Schema namespace.\n> \n> Second, I think that the pattern for the part-name type should be:\n> \n>   [A-Z]{2}-\\d{3}-[a-z]*\n> \n> At least, in the instance that you claim to be valid against this\n> schema, the part-name is \"NB-401-nutbolt\" which doesn't match the\n> pattern as currently specified.\n> \n> If you make those changes it validates according to Xerces-J, and by\n> eye.\n> \n> There are also a couple of problems in the description of the data\n> model generated from the instance and the schema.\n> \n> First, dm:type(A1) (the type of the name attribute) should be\n> \n>   xf:QName-from-uri(\"http://www.example.com/PartSchema\",\n>                     \"part-name\")\n> \n> shouldn't it? Or was the invalidity on purpose? If it was, then\n> surely dm:typed-value(A1) should be:\n> \n>   dm:atomic-value(\"NB-401-nutbolt\",\n>       xf:QName-from-uri(\"http://www.w3.org/2001/XMLSchema\",\n>                         \"anySimpleType\"))\n> \n> and dm:type(A1) should be:\n> \n>   xf:QName-from-uri(\"http://www.w3.org/2001/XMLSchema\",\n>                     \"anySimpleType\")\n> \n> Second, dm:string-value(A2) (the string value of the\n> xsi:schemaLocation attribute) seems to have a '\\' in it? I'm not sure\n> what that's doing there, or is it meant to indicate that there's an\n> insignificant line break?\n> \n> Finally, in the picture, the schemaLocation attribute should probably\n> be called xsi:schemaLocation, since the other qualified nodes use the\n> prefix to indicate their namespace.\n> \n> As it stands, this example is fairly straight-forward. It would be\n> great if this example could be turned into something that really\n> demonstrated some of the stickier features of the data model, such as:\n> \n>   - partial validity\n>   - union types\n>   - list types\n>   - lists of unions\n>   - unions of lists\n>   - whitespace normalisation of values\n>   - the effect of xml:base\n>   - anonymous types\n>   - a schema with more than one level in the type hierarchy\n> \n> I think that such an example would greatly illuminate the spec.\n> \n> Cheers,\n> \n> Jeni\n> ---\n> Jeni Tennison\n> http://www.jenitennison.com/\n\n\n\n", "id": "lists-017-15376146"}, {"subject": "XSLT 2.0: Typos in RFC3236 reference and  citatio", "content": "The reference to RFC3236 The 'application/xhtml+xml' Media Type (M. Baker, P. Stark. January 2002) is incorrectly cited as RFC2336 (note transposition of 3 2 at the beginning).  The reference in section 20.2 and the citation in section A.2 both need to be corrected.\n\n20.2 XHTML Output Method\nIn the fifth bullet following the example:\nThe content type should be set to the value given for the media-type attribute; the default value for XHTML is text/html. The value application/xhtml+xml, registered in [RFC2336], may also be used.\nShould be:\nThe content type should be set to the value given for the media-type attribute; the default value for XHTML is text/html. The value application/xhtml+xml, registered in [RFC3236], may also be used.\nSimilarly, the href and the anchor to which it refers should be corrected.\n\nA.2 Other References\nRFC2336 \nM. Baker, P. Stark. The 'application/xhtml+xml' Media Type. IETF RFC 2278. See http://www.ietf.org/rfc/rfc2336.txt.\nShould be:\nRFC3236 \nM. Baker, P. Stark. The 'application/xhtml+xml' Media Type. IETF RFC 3236. See http://www.ietf.org/rfc/rfc3236.txt.\nAnd this reference should be move between RFC2396 and UNICODE TR10.\n\nRob Biedenharn\nRob_Biedenharn@alum.mit.edu\n\n\n\n", "id": "lists-017-15389246"}, {"subject": "xf:compare collationLiteral is an anyURI", "content": "                                                                                                               \n                                                                                                               \n                                                                                                               \n\n\nThe spec says xf:compare collationLiteral is an anyURI. But your examples\ninclude\n      xf:compare('Strasse', 'Stra?e', anyURI('deutsch'))\n\nIf that's really a URI, it's a relative URI reference and needs to be\ninterpreted relative to a base URI. But this example strongly suggests that\nyou intended it to be taken only as a literal string.\n\nI submit that if it's a literal it shouldn't be called a URI, to avoid this\nconfusion. Remember the massive debate over whether relative URIs were\nmeaningful as namespaces? You _really_ don't want to go there.\n\nConversely, if it really us a URI, you shouldn't be using the relative form\nin this example since (a) it's misleading to the reader and (b) it's not\ntypical use -- you generally wouldn't want a document's collation to change\nif the document is moved to a new base URI.\n\n______________________________________\nJoe Kesselman  / IBM Research\n\n\n\n", "id": "lists-017-15398041"}, {"subject": "Is &quot;Expanded QName&quot; underspecified", "content": "I'm trying to prototype the xf:node-name function. Problem is, I really \ncan't tell what the behavior of the returned value should be. It's \npossible I'm not looking at the most recent documents, but:\n\n\nOperators says this returns an expanded QName and points to the Data Model \nspec.\n\nData Model says \"An expanded QName is in the value space of xs:QName, and \nconsists of a namespace URI and a local name\". But that doesn't tell me \nhow this value behaves when I actually try to operate on it -- to take one \ntrivial example, it doesn't tell me what the lexical representation of an \n_expanded_ QName should be.\n\nYou've got an open issue (Issue-0063: Is prefix preserved?) which suggests \nthat the non-expanded lexical value -- the Namespaces-style qualified name \n-- _might_ be available. But it isn't clear that this is the intended \nlexical value under all cases, or which cases it applies to... and the \nissue itself indicates that you hadn't decided where the prefix would be \ntaken from.\n\nChecked the XSLT2 spec; didn't find any help there.\n\n\nIs there really a hole in the spec where someone made an assumption, or \ndid I miss something? \n\n______________________________________\nJoe Kesselman  / IBM Research\n\n\n\n", "id": "lists-017-15406090"}, {"subject": "XPath Gramma", "content": "Here are some minor comments on the XPath grammar, mostly readability issues,\n\nA.1.1 Syntactic Constructs\n\n1. I find is easier to read if productions are shown in some form of \ndependency order, i.e. new ones build on old ones. For example, Digit should \nbe defined before IntegerLiteral. This is also consistent with the XML spec \nordering.\n\n2. A URLLiteral is a StringLiteral so should be defined that way.\n\n3. URLLiteral does not appear to be used anywhere in this spec.\n\n4. FuncName is defined equivalently to a QName.\n\n5. There is a quite a mixture of reuse of productions from XML Names and \nredefinition via another name. It appears that at least some of this has been \ncaused by not having suitable productions defined elsewhere. The result is \n'S' being defined in-terms of 'WhitespaceChar' rather than been taken from \nthe XML spec. I find the mixture quite confusing where new names are been \nused to define well known ideas, see 'Nmchar' redundant as a redefinition of \n'NCNameChar'. As you can't create the needed productions in the other specs \nwould it not be better to simply not use 'XML Names' as a reference and \ninclude all needed productions with there standard definition. An note could \nmake it clear that they are deliberately identical.\n\nC.1 Normative References\n\n1. The reference to 'XML' shows a link to \n'http://www.w3.org/TR/2000/REC-xml-20001006' but\nactually links to 'http://www.w3.org/TR/1998/REC-xml-19980210'.\n\n\n\n", "id": "lists-017-15414544"}, {"subject": "nodename accessor on a PI", "content": "The Working Draft of Functions & Operators dated 16 August 2002 says\nin section 2.2 that the node-name accessor returns a QName \"for node\nkinds that can have names\" but does not list those kinds. Please state\nexplicitly whether processing instructions are deemed to have names.\n\nI note that we have the QName functions in chapter 9, plus name(),\nlocal-name(), namespace-uri() in chapter 13, and chapter 4 gives rise\nto Name(), NCName(), and QName(). If there are any conflicts or\npossible surprises in the relationships among these 11 functions,\nthe spec should point them out.\n.................David Marston\n\n\n\n", "id": "lists-017-15422211"}, {"subject": "XPath 2.0 Functions xf:substring-before and  xf:substringafte", "content": "Hi\n\nThere is an issue with both of these functions that you may find worth considering.\nFunction substring-before (http://www.w3.org/TR/xquery-operators/#func-substring-before)\nhas the signatures:\n\nxf:substring-before(string? $operand1, string? $operand2) => string? \n      xf:substring-before( string?  $operand1, \n      string?  $operand2, \n      anyURI  $collationLiteral) => string? \n\n\nParagraph 3 of the description of the function states: \n...\nIf the value of $operand1 does not contain a string that is equal to the value of $operand2, then the \nfunction returns the zero-length string.\n...\n\nThe issue is that, if the value of $operand1 is equal to the value of $operand2 (in which case \nthe value of $operand1 certainly contains a string that is equal to the value of $operand2), \nthen the function also returns a zero-length string. This is precisely what one would expect from \nthe first paragraph of the description. So the function returns the same value when the two strings \ndefined by the arguments are identical, and when they are entirely different.\n\nOne way to resolve this would be to distinguish between an empty or null string, and what \nmight be called an \"undefined string\". The undefined string could then be returned by the function \nwhen the condition of paragraph 3 is satisfied ($operand1 does not contain a string that is\nequal to the value of $operand2). This implies that the string domain would need to be extended \nto include this additional member, which then raises the unfortunate logical problem that the \nextended domain includes a member that does not belong to it ...\n\nBest regards,\nKen Aldous.\n\n--\nKen Aldous\nAdvanced Manufacturing\nIndustrial Research Limited\n5 Sheffield Crescent\nPO Box 20 028, Bishopdale\nChristchurch\nNew Zealand\nhttp://www.irl.cri.nz/\n\nPh:  +64 3 358 6818\nFax: +64 3 358 9506\nk.aldous@irl.cri.nz\n\n\n\n", "id": "lists-017-15429267"}, {"subject": "RE: XSLT 2.0: Typos in RFC3236 reference and  citatio", "content": "Many thanks for this correction.\n\nMichael Kay\nSoftware AG\n\n> -----Original Message-----\n> From: Rob Biedenharn [mailto:Rob_Biedenharn@gap.com] \n> Sent: 20 August 2002 16:53\n> To: public-qt-comments@w3.org\n> Subject: XSLT 2.0: Typos in RFC3236 reference and citation\n> \n> \n> \n> \n> \n> \n> The reference to RFC3236 The 'application/xhtml+xml' Media \n> Type (M. Baker, P. Stark. January 2002) is incorrectly cited \n> as RFC2336 (note transposition of 3 2 at the beginning).  The \n> reference in section 20.2 and the citation in section A.2 \n> both need to be corrected.\n> \n> 20.2 XHTML Output Method\n> In the fifth bullet following the example:\n> The content type should be set to the value \n> given for the media-type attribute; the default value for \n> XHTML is text/html. The value application/xhtml+xml, \n> registered in [RFC2336], may also be used. Should be:\n> The content type should be set to the value \n> given for the media-type attribute; the default value for \n> XHTML is text/html. The value application/xhtml+xml, \n> registered in [RFC3236], may also be used. Similarly, the \n> href and the anchor to which it refers should be corrected.\n> \n> A.2 Other References\n> RFC2336 \n> M. Baker, P. Stark. The \n> 'application/xhtml+xml' Media Type. IETF RFC 2278. See \nhttp://www.ietf.org/rfc/rfc2336.txt.\nShould be:\nRFC3236 \nM. Baker, P. Stark. The 'application/xhtml+xml'\nMedia Type. IETF RFC 3236. See http://www.ietf.org/rfc/rfc3236.txt.\nAnd this reference should be move between RFC2396 and UNICODE TR10.\n\nRob Biedenharn\nRob_Biedenharn@alum.mit.edu\n\n\n\n", "id": "lists-017-15438060"}, {"subject": "RE: XSLT 2.0 WD &ndash;&ndash; question about handling Nan", "content": "> In section 12.2 of the WD, the last paragraph says that NaNs \n> are less than any other value (including -INF).  This \n> conflicts with the XML Schema Data Model description \n> (sections 3.2.4 and 3.2.5), with which XSLT is supposed to \n> conform, that says that NaNs are greater than all other \n> values (including +INF).\n> \n> So, we have two incompatible specs (3 if you count the IEEE 754 spec, \n> which says a third thing about NaNs).  Who gets to make them right?\n> \n\nYes, the discrepancy is unfortunate. The XSLT rule that NaN precedes other\nvalues (note that this only applies to xsl:sort) was introduced as an\nerratum to XSLT 1.0 (see E20 in\nhttp://www.w3.org/1999/11/REC-xslt-19991116-errata/ ) and pre-dates the\npublication of XML Schema, which adopted the opposite convention. It's not\nobvious whether the problem is serious enough to be worth fixing, and if so,\nhow it should be fixed: as far as I can see it is untidy that the two specs\nshould adopt different conventions but it does not make anything actually\nbreak.\n\nMichael Kay\nSoftware AG\n\n\n\n", "id": "lists-017-15448328"}, {"subject": "RE: Question about XPath 2.0 precedence rule", "content": "> In the XPath 2.0 WD, in the Appendix, Section A.2 Precedence \n> Order, the \n> precedence of various comparisons are all listed with equal \n> values (4).  \n> This seems different from XPath 1.0 (Section 3.4), which has \n> Relational \n> Expressions at higher priority than Equality Expressions.\n> \n> Is this intentional? If so, it has been left out of Appendix F, which \n> lists known incompatibilities between 1.0 and 2.0.\n\nThanks for pointing this out. This is still true in the August drafts. I\ndon't know of any particular reason why this has changed from 1.0, and at\nthe very least, it should be documented as an incompatibility. \n\nBy copying this message to the XPath TF, I am requesting that we register\nthis as an issue.\n\nMichael Kay\n\n\n\n", "id": "lists-017-15456840"}, {"subject": "RE: Data Model WD: [Issue0062: Namespace fixups required", "content": "> First, I absolutely agree that namespace fixup (as described \n> in Section 4.5 of the XSLT 2.0 WD) should be specified as \n> part of the Data Model, within the definition of element construction.\n> \n> Second, when this gets done, remember that as well as the \n> attributes of the element having their own namespace, the \n> values of those attributes and possibly the element itself \n> might be QNames and therefore require namespace nodes to be \n> added to the element....\n\nThe problem of writing QName-valued attributes to the result tree is\nprobably the major thing that's been holding this up. There are significant\nproblems here that we still have to solve. In general, the model for result\ntree construction in XQuery is [now]that values are serialized by converting\nthem to strings, and the resulting serialized XML is then passed through a\nschema processor to attach type annotations. The model in XSLT is very\nsimilar. This model doesn't yet work properly for QName-valued attributes\n(let alone other attributes containing namespace prefixes, such as XPath\nexpressions). There is \"work in progress\" in this area.\n\nMichael Kay\nSoftware AG\n\n\n\n", "id": "lists-017-15465571"}, {"subject": "RE: escape-uri and utf", "content": "The specification [1] states:\n\nThe effect of the function is to replace any special character in the string\nby an escape sequence of the form %xx%yy..., where xxyy... is the\nhexadecimal representation of the octets used to represent the character in\nUTF-8.\n\nIs this not clear enough?\n\n[1] http://www.w3.org/TR/xquery-operators/#func-escape-uri\n\nMichael Kay\nSoftware AG\n\n> -----Original Message-----\n> From: Wesley W. Terpstra [mailto:wesley@terpstra.ca] \n> Sent: 17 August 2002 23:14\n> To: public-qt-comments@w3.org\n> Subject: xf:escape-uri and utf-8\n> \n> \n> \n> \n> \n> \n> How is uri-escape(str, bool) to deal with unicode strings in str?\n> \n> It seems to me that it should output the string in utf-8 \n> encoded as hex stream with %s.\n> \n> This has several payoffs:\n> \n> Transparent behaviour for uris:\n> the examples in the current draft continue to work\n> All of normal ascii gets encoded as expected\n> Will behave the way most people expect\n> \n> A well-defined map for all of unicode\n> \n> POST/GETs to CGIs can support internationalisation as long as \n> they realize their data is in utf-8\n> \n> rfc822 mail headers for non-iso-8859 languages work simply:\n> <xsl:text>Subject: =?utf-8?Q?</xsl:text>\n> <xsl:value-of select=\"translate(uri-encode(subject, \n> true), '%', '=')\"/>\n> <xsl:text>?=<xsl:text>\n> \n> I am sure many other hacks are possible when one knows that \n> the output is has charset utf-8. So, please clarify the \n> output charset used for encoding the unicode string prior to \n> hexifying it. This way all implementation will use a common \n> charset and greatly increase the utility of this function.\n> \n> -- \n> Wesley W. Terpstra <wesley@terpstra.ca>\n> \n\n\n\n", "id": "lists-017-15474157"}, {"subject": "RE: Is &quot;Expanded QName&quot; underspecified", "content": "> I'm trying to prototype the xf:node-name function. Problem \n> is, I really \n> can't tell what the behavior of the returned value should be. It's \n> possible I'm not looking at the most recent documents, but:\n> \n> \n> Operators says this returns an expanded QName and points to \n> the Data Model \n> spec.\n> \n> Data Model says \"An expanded QName is in the value space of \n> xs:QName, and \n> consists of a namespace URI and a local name\". But that \n> doesn't tell me \n> how this value behaves when I actually try to operate on it \n> -- to take one \n> trivial example, it doesn't tell me what the lexical \n> representation of an \n> _expanded_ QName should be.\n\nAn expanded QName is a (URI, localname) pair. \n\nThe current situation is that there is no way of converting an expanded\nQName to a string (see\nhttp://www.w3.org/TR/xquery-operators/#casting-from-primitive-to-primitive)\nand therefore there is no way of writing a QName to the result tree.\n\nThe operations you can perform on an expanded QName are to extract the\nnamespace URI and the local name. You can also compare two expanded QNames\nfor equality.\n\nThis isn't very satisfactory, but it's the best we could do for the time\nbeing.\n\nMichael Kay\nSoftware AG\n\n\n\n\n> \n> You've got an open issue (Issue-0063: Is prefix preserved?) \n> which suggests \n> that the non-expanded lexical value -- the Namespaces-style \n> qualified name \n> -- _might_ be available. But it isn't clear that this is the intended \n> lexical value under all cases, or which cases it applies \n> to... and the \n> issue itself indicates that you hadn't decided where the \n> prefix would be \n> taken from.\n> \n> Checked the XSLT2 spec; didn't find any help there.\n> \n> \n> Is there really a hole in the spec where someone made an \n> assumption, or \n> did I miss something? \n> \n> ______________________________________\n> Joe Kesselman  / IBM Research\n> \n> \n\n\n\n", "id": "lists-017-15483679"}, {"subject": "RE: XPath 2.0 Functions xf:substring-before and  xf:substringaft e", "content": "The specification of these functions is constrained by the requirement to\nkeep them backwards compatible with XPath 1.0. The problem you point out is\nknown, but it is easy to get around it by first calling xf:contains().\n \nMichael Kay\nSoftware AG\n\n-----Original Message-----\nFrom: Ken Aldous [mailto:k.aldous@irl.cri.nz] \nSent: 26 August 2002 03:00\nTo: public-qt-comments@w3.org\nSubject: XPath 2.0 Functions xf:substring-before and xf:substring-after\n\n\nHi\n \nThere is an issue with both of these functions that you may find worth\nconsidering.\nFunction substring-before\n(http://www.w3.org/TR/xquery-operators/#func-substring-before\n<http://www.w3.org/TR/xquery-operators/#func-substring-before> )\nhas the signatures:\n \nxf:substring-before(string? $operand1, string? $operand2) => string? \nxf:substring-before( string?  $operand1,\nstring?  $operand2,\nanyURI  $collationLiteral) => string?\n \nParagraph 3 of the description of the function states: \n...\nIf the value of $operand1 does not contain a string that is equal to the\nvalue of $operand2, then the \nfunction returns the zero-length string.\n...\n \nThe issue is that, if the value of $operand1 is equal to the value of\n$operand2 (in which case \nthe value of $operand1 certainly contains a string that is equal to the\nvalue of $operand2), \nthen the function also returns a zero-length string. This is precisely what\none would expect from \nthe first paragraph of the description. So the function returns the same\nvalue when the two strings \ndefined by the arguments are identical, and when they are entirely\ndifferent.\n \nOne way to resolve this would be to distinguish between an empty or null\nstring, and what \nmight be called an \"undefined string\". The undefined string could then be\nreturned by the function \nwhen the condition of paragraph 3 is satisfied ($operand1 does not contain a\nstring that is\nequal to the value of $operand2). This implies that the string domain would\nneed to be extended \nto include this additional member, which then raises the unfortunate logical\nproblem that the \nextended domain includes a member that does not belong to it ...\n \nBest regards,\nKen Aldous.\n \n--\nKen Aldous\nAdvanced Manufacturing\nIndustrial Research Limited\n5 Sheffield Crescent\nPO Box 20 028, Bishopdale\nChristchurch\nNew Zealand\nhttp://www.irl.cri.nz/ <http://www.irl.cri.nz/> \n \nPh:  +64 3 358 6818\nFax: +64 3 358 9506\nk.aldous@irl.cri.nz <mailto:k.aldous@irl.cri.nz> \n\n\n\n", "id": "lists-017-15493678"}, {"subject": "RE: Is &quot;Expanded QName&quot; underspecified", "content": ">The current situation is that there is no way of converting \n> an expanded QName to a string (see...) and therefore there\n> is no way of writing a QName to the result tree.\n\nSo I take it we should simply consider the behavior of this datatype \n\"unstable\" for now, and conversion to string should either throw an error \nor otherwise Do Something Reasonable until such time as the open issues \nare resolved... Good enough for dance music.\n\n______________________________________\nJoe Kesselman  / IBM Research\n\n\n\n", "id": "lists-017-15505030"}, {"subject": "XQuery 1.0 and XPath 2.0 Functions and Operators (16th August", "content": "Some comments on the latest F & O draft.\n\nDavid\n\n\n\n\n\n2.6 xf:unique-ID\n  \"which may have been assigned by the user.\"\n  It isn't clear here what or who \"the user\" is. (well it's clear if you\n  know from elsewhere what this function does). In particular it isn't\n  the user of _this function_. It would be better just to delete this\n  phrase and just use the infoset property, as for other accessors.\n\n \n4 Constructor Functions\n\n\n  The semantics of the constructor function xs:TYP(item) are identical\n  to the semantics of cast as xs:TYP (item).\n\n  having introduced this functional syntax for casting (which is a good\n  thing and potentially reduces the dependence on W3C-schema as one could\n  imagine other namespaces providing types) one could consider dropping\n  the \"cast as\" syntax, I see this is flagged as a possibility\n  elsewhere, but wanted to comment that this would appear to be a useful\n  simplification.\n\n\n5.2.5 op:numeric-integer-divide\n\n  If the quotient is not evenly divided by the divisor, then the\n  quotient is the integer value obtained, ignoring any remainder that\n  results from the division (that is, no rounding is performed). \n\n  I'm not sure that this is clear enough in the cases where one of the\n  arguments is negative. You might want to specify the values of\n   3 idiv  2\n  -3 idiv  2\n   3 idiv -2\n  -3 idiv -2\n   3 idiv  0\n\n5.2.8 op:numeric-unary-minus\n  You might want to clarify the behaviour on NaN  0 +0 and -0.\n\n6.2 Equality and Comparison of Strings\n\n \"it is not possible to guarantee that all strings in all XML documents\n  are, in fact, normalized, or that they are normalized in the same\n  manner.\"\n \n You might want to add a node tracking XML 1.1 which might (or might\n not) change the truth if this statement.\n\n6.3.15 xf:matches\n\n Much improved functionality from previous versions, thanks.\n (Will need some time and experimentation to see if it really captures\n what is needed, but seems reasonable at first reading.)\n\n\n8 Functions and Operators on Durations, Dates, and Times\n  I wish I could add some constructive suggestions here.\n  It is fairly horrible as it stands but its not clear which bits could\n  easily be simplified. It's a shame though that given all this mass of\n  functions invoving dates the one thing that is most often requested\n  and currently requires shelling out to an extension language in all\n  but the simplest cases will still require an extension language:\n  Parsing locale-specific strings in instance documents into dates.\n  \"January 15th, 2002\" etc.\n\n\n11.1 Comparisons of base64Binary and hexBinary Values\n  It would be more useful to compare after removing white space.\n  that would mean that the encoded binary values were equal.\n\n\n13.1.7 xf:deep-equal\n  This function should not be in the core.\n  Processing expectations require many variants of equality (ignoring,\n  or not, comments, pis, white space, etc etc). It would be better to\n  give this as an example of a user-defined function in the Xquer and XSLT\n  documents where function definition is defined.\n\n\n13.1.10 xf:copy\n  This function should not be in the core (since it's not in XSLT).\n  It ought be in an Xquery-specific function library.\n  Also the name is bad as it corresponds to xsl:copy-of rather than\n  xsl:copy.\n\n  [Issue 60: What are the precise semantics of the copy() function?]\n  in addition to the points raised in the node, the current spec only\n  says that xf:copy produces a node with identity different from\n  its argument. probably it should specify that it is a new node with\n  unique identity that is\n  xf:copy(x) is xf:copy(x)\n  is false. Similarly it probably needs specifying that the node is not\n  in a document so xf:root(xf:copy(x)) is the same as xf:copy(x).\n\n\n13.2 xf:if-absent() and xf:if-empty()\n   Neither of these functions should be in the core, for reasons stated\n   in comments on earlier drafts.\n\n14.1.1 op:to\n  \"Converts both its operands to integers \"\n   You might need to more fully specify what is returned if this\n   conversion fails. -INF to INF for example.\n\n \n\n14.2.5 xf:empty\n  This function is unnecessary (duplicates casting to boolean) and confusingly uses \n  a different meany of \"empty\" to if-empty().\n\n\n14.2.6 xf:exists\n  This function is unnecessary (duplicates casting to boolean) but if it\n  is kept the example should use xf:exists not  xf:empty\n\n14.2.7 xf:distinct-nodes\nor rather: [Issue 154: Should we define a second order distinct function?]\n  Provision of higher order functions was clearly one of the main\n  requirements coming from previous use of XPath. It remains a great\n  disappointment that this requirement has not been met. rather than\n  further complicate matters with special purpose syntax it may not be too\n  late to really consider adding higher order functions to solve this\n  issue (and simplify many other parts of the spec).\n\n\n14.2.10 xf:remove\n  This appears to be the same as $target[position() != $position]\n  If it is the same it ought to be defined that way, if it isn't perhaps\n  a note could be given explaining the difference.\n\n14.3.1 xf:sequence-deep-equal\n  I think the justification of this function (as of xf:deep-equal) is\n  slight. It is also yet another part of the spec that could be\n  simplified by higher order functions (in this case mapping an equality\n  operator over a list)\n\n\n14.4.2 xf:avg\n  In this draft the meaning has been clarified as\n  (computed as sum($srcval) div count($srcval)).\n  but is that really intended?\n  if the nodes contain data which are lists of integers\n  <x>1 2</x>\n  <x>3 4</x>\n  count(x) is 2 but is sum(x) an error or 10 ?\n  I'd have expected avg(x) to be 2.5 (10/4) in this case.\n\n\n  similar comments apply to all the aggregate functions.\n  They all use the phrase\n   \"Values that equal the empty sequence are discarded\"\n  whereas I would have expected them tou have used the standard list\n  flattening procedure, which would naturally imply that empty sequence\n  was discarded, but would also specify what to do in the case that the\n  typed value was of list type.\n\n16 Casting Functions\n  This is clearer than in previous drafts but still fairly horrible.\n  It still would seem preferable if the data model (and core\n  XPath/Xquery) had a much reduced set of basic types, more like Xpath1+\n  something for date/time. This would simplify the casting rules and the\n  whole of the language. A W3C-schema-specific function library could then\n  map the W3C-schema types to these core types.\n\n\n\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-15513215"}, {"subject": "unparsed-entity-publicid in August XSLT2 draf", "content": "16.5.3 unparsed-entity-public-id()\n\nStates that \"\" is returned if there is no entity of the specified name.\nIt probably should also state that \"\" is returned if the entity has no\npublic identifier (this situation doesn't arise for\nunparsed-entity-uri()\nas the SYSTEM ID must always be given).\n\nDavid\n\n\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-15526678"}, {"subject": "XSLT2 draft  (16th August) XHTML outpu", "content": "> 20.2 XHTML Output Method\n\nThe XHTML output description specifies that the /> form should not be\nused if the declared content model (by implication, in XHTML 1.0 DTD)\nis non empty. However the first bullet simply says that a space should\nbe placed before the /> for \"empty elements\" which would seem to include\nall empty elements rather than just those declared EMPTY in XHTML.\n\nThe first bullet point requiring a space before /> should probably be\nexplictly restricted to elements in the XHTML namespace with which are\ndeclared EMPTY in (one of) the XHTML 1.0 DTD.\n\nWould it be possible for the XHTML output method to force that the\nxhtml namespace is default and so output XHTML elements unprefixed. If\nthe aim is to work in legacy HTML browsers outputting as <kjfkcwwa:br />\nwhich would be allowed by the current rules will not realy work.\n\nsimilar comment on the fith bullet\n  \"If there is a head element\"\ndoes this mean any element with local name \"head\" or an element with\nlocal name name  \"head\" and namespace uri \"xhtml-namespace\".\n\nDavid\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-15534289"}, {"subject": "RE: XSLT2 draft  (16th August) XHTML outpu", "content": "> > 20.2 XHTML Output Method\n> \n> The XHTML output description specifies that the /> form\n> should not be used if the declared content model (by \n> implication, in XHTML 1.0 DTD) is non empty. However the \n> first bullet simply says that a space should be placed before \n> the /> for \"empty elements\" which would seem to include all \n> empty elements rather than just those declared EMPTY in XHTML.\n> \n> The first bullet point requiring a space before /> should\n> probably be explictly restricted to elements in the XHTML \n> namespace with which are declared EMPTY in (one of) the XHTML 1.0 DTD.\n\nYes, I think this is essentially a question of editorial clarification:\nperhaps the second bullet point should come before the first.\n> \n> Would it be possible for the XHTML output method to force\n> that the xhtml namespace is default and so output XHTML \n> elements unprefixed. If the aim is to work in legacy HTML \n> browsers outputting as <kjfkcwwa:br /> which would be allowed \n> by the current rules will not realy work.\n\nThis seems a reasonable suggestion. I'll register it as an issue so it gets\nonto the WG agenda. It's not trivial to specify this, because namespace\nprefixes are allocated as part of the namespace fixup process during result\ntree construction, not during serialization. It may be simplest to express\nit in the form of a suggestion to implementors.\n> \n> similar comment on the fith bullet\n>   \"If there is a head element\"\n> does this mean any element with local name \"head\" or an\n> element with local name name  \"head\" and namespace uri \n> \"xhtml-namespace\".\n> \nI think it means an element with local name \"head\" in the XHTML namespace,\nand will add a clarification to that effect unless anyone in the WG objects.\n\nThanks for the comments, as always.\n\nMichael Kay\n\n\n\n", "id": "lists-017-15542595"}, {"subject": "RE: unparsed-entity-publicid in August XSLT2 draf", "content": "Thanks. I'll add an issue here. It might be better to return () rather than\n\"\" in either or both of these situations.\n\nMichael Kay\n\n> -----Original Message-----\n> From: David Carlisle [mailto:davidc@nag.co.uk] \n> Sent: 27 August 2002 14:11\n> To: public-qt-comments@w3.org\n> Subject: unparsed-entity-public-id in August XSLT2 draft\n> \n> \n> \n> \n> 16.5.3 unparsed-entity-public-id()\n> \n> States that \"\" is returned if there is no entity of the \n> specified name. It probably should also state that \"\" is \n> returned if the entity has no public identifier (this \n> situation doesn't arise for\n> unparsed-entity-uri()\n> as the SYSTEM ID must always be given).\n> \n> David\n> \n> \n> \n> _____________________________________________________________________\n> This message has been checked for all known viruses by Star \n> Internet delivered through the MessageLabs Virus Scanning \n> Service. For further information visit \n> http://www.star.net.uk/stats.asp or > alternatively call Star \n> Internet for details on the Virus Scanning Service.\n> \n\n\n\n", "id": "lists-017-15551798"}, {"subject": "XPath grammar problems and recommendation", "content": "Hi\n\nThe Aug 16 Xpath 2.0 WD is much improved on the 30-Apr WD.\n\nThere are however problems. \n\ninstance of attribute\n---------------------\n\nA problem arises when an instnace of is followed by any of\n\nthe or/and/for/quantified/if precedence operators\n\nsince there is then an ambiguity between\n\n{... instance of attribute operator} ...\n\nand\n\n{... instance of attribute} operator ...\n\nPerhaps some <> annotations should specify a resolution for the\nabove, presumably as the normal left maximisation, since parentheses\ncan be used to force termination between attribute and operator.\n\nHowever the ambiguity is unplesasant, and could be better\nresolved with parentheses in the grammar: instance of (SequenceType).\n\nAtomicType\n----------\n\nThe grammar for ItemType is trivially impossible since AtomicType is a QName and\nso covers node and comment etc which are distinct ItemType's.\n\nThis easily implemented by suppressing the bogus matches, but requires a semantic\nstatement as to whether node etc are valid AtomicTypes. if so, then the QName production\nshould be corrected to exclude the invalid names. If not then alternate syntax is needed.\n\nLexical states\n--------------\n\nI tried implementing the 30-Apr states and filled in the nissing holes, and\nthen just deleted all the states and fixed the shift reduce conflicts. Just fixing\nthe conflicts worked more easily for the 16-Aug version. I have no idea whether\nmy grammar corresponds to the state machines. I suspect it doesn't quite:\n\"validate\" gave me no trouble and I discovered the above problems. CUP gave\na very large number of states, so I doubt that the critical parts really\ncorresponded to those specified.\n\nIt must be wrong that a stanadrd high tech implementation approach is uncheckable\nagainst a specification that struggles to support lower tech approaches. Clearly\nthe attempt to describe how an LL parser might solve the\nproblems has introduced a large amount of complicated and potentially erroneous\ninformation. The EBNF with the <> annotations is sufficient to define the grammar,\nanything more is dangerous.\n\nI appreciate the desire to avoid prescribing an LALR parser, but they're old\ntechnology and available for Java. By the time you start pushing states\nit really gets quite hard to avoid one. Trimming the EBNF to just the necessary,\nperhaps with an observation that this is LALR parsable, is sufficient. When someone\nhas a proven LL approach it could be added, but I suspect that the LL approach is\nmost easily derived by reverse engineering the LALR states.\n\nIt seems ironic that Java which has a solid LALR grammar has undermined the\n20 years of yacc/bison with inferior tools such as JavaCC.\n\nThe simple CUP and JLex grammars are attached, cluttered by some extra support for\na more readable XSL interface, howeever the xpath_xxx productions are clean.\n\nRegards\n\nEd Willink\n\n------------------------------------------------------------------------\nE.D.Willink,                 Email: mailto:Ed.Willink@uk.thalesgroup.com\nThales Research Ltd,                  Tel:   +44 118 923 8278 (direct)\nWorton Drive,                          or    +44 118 986 8601 (ext 8278)\nWorton Grange Industrial Estate,      Fax:   +44 118 923 8399\nReading,   RG2 0SB\nENGLAND          http://www.computing.surrey.ac.uk/personal/pg/E.Willink\n------------------------------------------------------------------------\n(formerly Racal Research and Thomson-CSF)\n\nAs the originator, I grant the addressee permission to divulge\nthis email and any files transmitted with it to relevant third parties.\n\n\n\n*******************************************************************************\nThis email and any files transmitted with it are intended solely for the use of\nthe individual or entity to whom they are addressed and may not be divulged to\nany third party without the express permission of the originator.  Any views\nexpressed in this message are those of the individual sender, except where the\nsender specifically states them to be the views of Thales Research Ltd.\n*******************************************************************************\n\n\n\n\n\napplication/octet-stream attachment: NiceXSL.lex\n\napplication/octet-stream attachment: NiceXSL.cup\n\n\n\n\n", "id": "lists-017-15560924"}, {"subject": "Added appendix on design alternatives [altdesign17", "content": "I have added an appendix on design alternatives, entitled\n\"Appendix A: Design Alternatives\". The bulk of discussion\non these has taken place years ago, and I have limited myself\nto a rather cursory discussion. If anybody sees something that\nreally needs to be mentioned, please tell me.\n\nI'm herewith tentatively closing issue altdesign-17.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1559132"}, {"subject": "Re: Bug in operator to function mapping in XQuer", "content": "Hi Patrick,\nThanks for pointing this out. Of course, you are right. I will fix this in \nthe next edition of the XPath and XQuery documents. I do not believe any \nnew functions are needed. Instead, I propose to map \"A ge B\" to \n\"fn:not(op:numeric-less-than(A, B))\". Similar changes will be needed to \nthe ge and le operators for all the date/time/duration types.\nBest regards,\n--Don Chamberlin\n\n---------------------- (referenced note) -----------------------------\n\nDate: Wed, 20 Nov 2002 06:05:50 -0500 (EST)\nFrom: \"Patrick Lehti\" <lehti@ipsi.fhg.de>\nTo: <public-qt-comments@w3.org>\nMessage-ID: <004201c29084$bd074bd0$291c0c8d@pcspindle>\nSubject: Bug in operator to function mapping in XQuery\n\nHi,\nthere is a bug in the operator to function mapping (appendix B.2 in\nXQuery 1.0 document and appendix B in Formal Semantics document). \n\nA ge B is definitly not the same as op:numeric-less-than(B, A) for the\ncase that A equals B. The same mistake is found for the \"le\" operator. I\nassume that you have to add two additional functions to the F&O document\nfor these operators.\n\nBy the way, this bug was already there in the WD of August. Sorry that I\ndid not point you to this earlier.\n\nBest regards,\nPatrick\n\n\n\n", "id": "lists-017-15626709"}, {"subject": "Casting from string inconsistenc", "content": "Section 16.6 of XQuery 1.0 and XPath 2.0 Functions and Operators states:\n\nCasting is permitted from string and anySimpleType to any primitive \natomic type or an atomic type derived by restriction except QName.\n\nHowever, the table in section 16 shows that neither a string nor \nanySimpleType can be cast to a notation. Either the table or the \nstatement in section 16.6 is wrong. I don't know which.\n-- \n\n+-----------------------+------------------------+-------------------+\n| Elliotte Rusty Harold | elharo@metalab.unc.edu | Writer/Programmer |\n+-----------------------+------------------------+-------------------+\n|          XML in a  Nutshell, 2nd Edition (O'Reilly, 2002)          |\n|              http://www.cafeconleche.org/books/xian2/              |\n|  http://www.amazon.com/exec/obidos/ISBN%3D0596002920/cafeaulaitA/  |\n+----------------------------------+---------------------------------+\n|  Read Cafe au Lait for Java news:  http://www.cafeaulait.org/      |\n|  Read Cafe con Leche for XML news: http://www.cafeconleche.org/    |\n+----------------------------------+---------------------------------+\n\n\n\n", "id": "lists-017-15635479"}, {"subject": "RE: Casting from string inconsistenc", "content": "The text in 16.6 is incorrect.  Section 16.13 says that it is not\npossible to cast from any other type to NOTATION.  \n\nAll the best, Ashok\n\n-----Original Message-----\nFrom: Elliotte Rusty Harold [mailto:elharo@metalab.unc.edu] \nSent: Friday, December 06, 2002 6:52 PM\nTo: public-qt-comments@w3.org\nSubject: Casting from string inconsistency\n\n\n\n\n\nSection 16.6 of XQuery 1.0 and XPath 2.0 Functions and Operators states:\n\nCasting is permitted from string and anySimpleType to any primitive \natomic type or an atomic type derived by restriction except QName.\n\nHowever, the table in section 16 shows that neither a string nor \nanySimpleType can be cast to a notation. Either the table or the \nstatement in section 16.6 is wrong. I don't know which.\n-- \n\n+-----------------------+------------------------+-------------------+\n| Elliotte Rusty Harold | elharo@metalab.unc.edu | Writer/Programmer |\n+-----------------------+------------------------+-------------------+\n|          XML in a  Nutshell, 2nd Edition (O'Reilly, 2002)          |\n|              http://www.cafeconleche.org/books/xian2/              |\n|  http://www.amazon.com/exec/obidos/ISBN%3D0596002920/cafeaulaitA/  |\n+----------------------------------+---------------------------------+\n|  Read Cafe au Lait for Java news:  http://www.cafeaulait.org/      |\n|  Read Cafe con Leche for XML news: http://www.cafeconleche.org/    |\n+----------------------------------+---------------------------------+\n\n\n\n", "id": "lists-017-15643908"}, {"subject": "Feedback for yo", "content": "Hello, Working Group!\n\nAs many of you know, I am writing the other XQuery book for\nAddison-Wesley, and while reviewing the drafts I've gathered a lot of\nfeedback for you.  To avoid confusion within our product groups at\nMicrosoft, and also to make it clear that this is my personal feedback\nand unrelated to the opinions of my employer, I'm sending this from my\npersonal account to the public feedback alias, instead of going through\nour excellent reps.\n\nDo you prefer I gather up the feedback and submit it all at once (I've\ngot 8+ pages of it), one email per item, or items grouped together in\nrelated clusters?\n\n\nThanks,\n\nMichael Brundage\nxquery@attbi.com\n\nTechnical Lead\nXML Query Processing\nMicrosoft\nAuthor, \"XQuery: The XML Query Language,\" Addison-Wesley, 2003\nCo-author, \"Professional XML Databases,\" Wrox Press, 2000\n\n\n\n", "id": "lists-017-15653941"}, {"subject": "F&amp;O comments on 6.", "content": "I went through the mail archives since October and removed any feedback\nI had that was previously raised and answered (one item below was raised\nbut not answered in the archives, so I left it in).\n\n\n***\n*** Questions/comments on 6.4.17:\n***\n\n- What is the result of replace(\"xxy\", \"x.\", \"z\") ?  The spec says\n\"non-overlapping substrings\", so I assume this does not result in \"zz\",\nbut does it result in \"xz\" or \"zy\" ?  This should be made clear.\n\n- What is the result of replace(\"xxx\", \"x(xx)|(x)xx\", \"y$1\") ?  Is it\n\"yxx\" or \"yx\" ?  Perhaps a simpler example is replace(\"xx\", \"(x)|x\",\n\"$1\").  Does it result in \"\", \"x\", or \"xx\"?\n\n- So, an error is raised for replace(\"xxx\", \".*?\", \"\") because the\nreluctant quantifier causes .* to match the \"shortest possible\nsubstring\" which in this case is the empty string?  If so, I think it's\nworth mentioning that the reluctant quantifiers can cause patterns that\nwould normally succeed to error.  If this was not intended, then the\ndefinitions need reworking.\n\n- Is an error raised only if the entire pattern matches the zero-length\nstring?  What about captured substrings, like replace(\"xxx\", \"()x*\",\n\"$1\") or replace(\"xxx\", (^).*($)\", \"$1$2\")?  Are these allowed\n(resulting in the empty string?) or are they errors?\n\n- If the replacement pattern is invalid, is it an error?  (This is not\nstated.)  For example, replace(\"x\", \"(x)\", \"$\").  What if the\nreplacement pattern refers to a non-existent match, such as replace(\"x\",\n\"(x)\", \"$5\") ?\n\n- If $ must be escaped as \\$, then clearly \\ must also be escaped\n(probably \\\\).  Otherwise, it would be impossible to insert a backslash\nfollowed by a captured substring.  For example, replace($anything,\n\"(.*)\", \"\\$1\") needs to be replace($anything, \"(.*)\", \"\\\\$1\")\n\n***\n*** Questions/comments on 6.4.16.1:\n***\n\n- What's considered a \"newline character\" for the purpose of ^$.\nmatching?  \\r? \\n? \\r\\n? (which isn't a character, but a sequence)\n\n-  The additional meta-characters change what is considered a \"normal\ncharacter\" in the regular expression.  So in addition to modifying the\nXML Schema quantifier production (4), you also want to modify the Char\nproduction (10).\n\nI note in passing that the XML Schema spec appendix F contains two\nerrors:  The definition of metacharacter omits the vertical bar | (which\nis properly accounted for in the Char production), while the Char\nproduction omits the curly brace metacharacters { and } (which are\nproperly accounted for in the metacharacter definition).  Oops.\n\nFurthermore, the XML Schema regexp grammar allows for expressions like\n\"|\" and \"()|()\".  This is possibly an error.  (Both branches to the\nchoice are allowed to be empty, because branch ::= piece*.  Similarly,\nparentheses can wrap the empty string.)\n\n- Because the XML Schema grammar for regexps is flawed, and you're using\nonly a small part of it unmodified anyway, it's probably best to\ncompletely define your (corrected, modified) regexp grammar here.\n\n-  \"The effect of [reluctant quantifiers] is that the regular expression\nmatches the shortest possible substring (consistent with the match as a\nwhole succeeding).\"  I think this parenthetical statement should not be\nparenthetical, because it significantly affects the behavior of the\nreluctant quantifier.\n\n\n***\n*** Questions/comments on 6.4.19\n***\n\n- I suppose you know that the escaping rules differ for each URI part?\nSection 2.4.2 of RFC 2396 might be illuminating.  I'm not sure\nescape-uri() is useful as-is.  Should probably be something more along\nthe lines of construct-uri(part1 string?, part2 string?, ...).\n\n- Consider adding functions for XML entitization/de-entitization\n(suggested: entitize(string?) string? and unentitize(string?) string?).\nI suppose I can cobble together the same functionality by going through\na dummy element constructor, but I think this functionality is more\ncentral to XQuery than URI escaping.\n\n\n\n", "id": "lists-017-15661631"}, {"subject": "Re: Added appendix on design alternatives [altdesign17", "content": "Martin, the appendix looks good to me.\nSeems like a nice concise summary of considerations and rational decisions.\ntex\n\nMartin Duerst wrote:\n> \n> I have added an appendix on design alternatives, entitled\n> \"Appendix A: Design Alternatives\". The bulk of discussion\n> on these has taken place years ago, and I have limited myself\n> to a rather cursory discussion. If anybody sees something that\n> really needs to be mentioned, please tell me.\n> \n> I'm herewith tentatively closing issue altdesign-17.\n> \n> Regards,    Martin.\n\n-- \n-------------------------------------------------------------\nTex Texin   cell: +1 781 789 1898   mailto:Tex@XenCraft.com\nXen Master                          http://www.i18nGuy.com\n                         \nXenCraft            http://www.XenCraft.com\nMaking e-Business Work Around the World\n-------------------------------------------------------------\n\n\n\n", "id": "lists-017-1566512"}, {"subject": "RE: comment on Xpath 2.0  no strong typing!", "content": "Michael Kay wrote [Thu, 3 Oct 2002 13:08:07 +0200]\n> The term \"strong typing\" means different things to different people.\n> There are some type rules in XPath 1.0, for example you cannot\n> supply a number as an argument to the count() function or as an\n> operand of the \"/\" operator.\n>\n\nAt the risk of being pedantic, I'd just like to point out that \"strongly\ntyped\" has a well-defined meaning, and any other use of the term is just\na corruption of the language.  See, for example,\nhttp://whatis.techtarget.com/definition/0,289893,sid9_gci213058,00.html\nWe can quibble over minor details (as always), but the core meaning\nholds.\n\nThe confusion over XSLT/XPath stems largely from the fact that these\nlanguages are, as you well know, only \"half-way\" strongly-typed.  With a\nhandful of exceptions (external parameters, external script functions),\nevery expression in XPath and XSLT 1.0 has a type that is known at\ncompile-time.  Granted, these types are fairly weak (number, node,\netc.), although some compile-time analysis can improve that somewhat\n(integer, double, element, attribute, ...), but nevertheless, almost all\nexpressions in an XSLT/XPath are strongly typed.\n\nI've heard the XQuery WG comment publicly several times now that XSLT is\nweakly-typed and not optimizable, and I think you are doing yourselves a\ndisservice by resorting to flawed argumentation.  Numerous XSLT\nimplementations can and have successfully applied both strong-typing\nrules and non-trivial optimizations (even though the standard did little\nto lay a solid foundation for either).\n\nFurthermore, eliminating implicit type conversions does not make a\nlanguage more strongly-typed -- it just makes it more rigid (which can\nbe a positive aspect).  For example, raising an error whenever a\nsequence has more than one member instead of just handling the case with\nsome reasonable semantic (even if that's something silly like first\nsemantics in XPath 1.0), is not a requirement to claim the language is\nstrongly-typed.  In some cases raising an error may help to discover a\nuser error at compile-time; in other cases, it only makes the language\nmore verbose and less usable.\n\n\nBest wishes,\n\nMichael Brundage\nxquery@attbi.com\n\n\n\n", "id": "lists-017-15672596"}, {"subject": "RE: Feedback for yo", "content": "Hi Michael:\nCould you copy me on the F&O feedback?  I think one e-mail per item\nworks best.\n\nAll the best, Ashok\n\n-----Original Message-----\nFrom: Roaming Anomaly [mailto:RoamingAnomaly@hotmail.com] \nSent: Sunday, December 08, 2002 9:41 PM\nTo: public-qt-comments@w3.org\nSubject: Feedback for you\n\n\n\n\n\nHello, Working Group!\n\nAs many of you know, I am writing the other XQuery book for\nAddison-Wesley, and while reviewing the drafts I've gathered a lot of\nfeedback for you.  To avoid confusion within our product groups at\nMicrosoft, and also to make it clear that this is my personal feedback\nand unrelated to the opinions of my employer, I'm sending this from my\npersonal account to the public feedback alias, instead of going through\nour excellent reps.\n\nDo you prefer I gather up the feedback and submit it all at once (I've\ngot 8+ pages of it), one email per item, or items grouped together in\nrelated clusters?\n\n\nThanks,\n\nMichael Brundage\nxquery@attbi.com\n\nTechnical Lead\nXML Query Processing\nMicrosoft\nAuthor, \"XQuery: The XML Query Language,\" Addison-Wesley, 2003\nCo-author, \"Professional XML Databases,\" Wrox Press, 2000\n\n\n\n", "id": "lists-017-15682091"}, {"subject": "RE: F&amp;O comments on 6.", "content": "> \n> ***\n> *** Questions/comments on 6.4.17:\n> ***\n> \n> - What is the result of replace(\"xxy\", \"x.\", \"z\") ?  The spec \n> says \"non-overlapping substrings\", so I assume this does not \n> result in \"zz\", but does it result in \"xz\" or \"zy\" ?  This \n> should be made clear.\n\nThanks, yes, the spec should make it clear that if the pattern does match\ntwo overlapping substrings, the one that starts first is chosen.\n> \n> - What is the result of replace(\"xxx\", \"x(xx)|(x)xx\", \"y$1\") \n> ?  Is it \"yxx\" or \"yx\" ?  Perhaps a simpler example is \n> replace(\"xx\", \"(x)|x\", \"$1\").  Does it result in \"\", \"x\", or \"xx\"?\n\nThere's a meta-question here: how are we going to provide a definitive\nspecification of the semantics of our regular expressions? Are we going to\ntry and include all the rules ourselves, or refer to some external\nauthority? The difficulties here is that it is very hard to find a\ndefinitive specification for regular expressions that we can simply refer\nto. I see that Java refers to  Mastering Regular Expressions, Jeffrey E. F.\nFriedl, O'Reilly and Associates, 1997. The Perl specification seems\nhopelessly informal, and full of statements like \"this feature is\nexperimental\".\n\nI imagine the answer here is that when several alternatives match, the one\nthat counts is the first.\n> \n> - So, an error is raised for replace(\"xxx\", \".*?\", \"\") \n> because the reluctant quantifier causes .* to match the \n> \"shortest possible substring\" which in this case is the empty \n> string?  If so, I think it's worth mentioning that the \n> reluctant quantifiers can cause patterns that would normally \n> succeed to error.  If this was not intended, then the \n> definitions need reworking.\n\nYes, it may be worth including an example like this.\n> \n> - Is an error raised only if the entire pattern matches the \n> zero-length string?  What about captured substrings, like \n> replace(\"xxx\", \"()x*\",\n> \"$1\") or replace(\"xxx\", (^).*($)\", \"$1$2\")?  Are these \n> allowed (resulting in the empty string?) or are they errors?\n\nI can't see any strong reason why a zero-length captured substring shouldn't\nbe allowed, but perhaps I'm missing something.\n> \n> - If the replacement pattern is invalid, is it an error?  (This is not\n> stated.)  For example, replace(\"x\", \"(x)\", \"$\").  What if the \n> replacement pattern refers to a non-existent match, such as \n> replace(\"x\", \"(x)\", \"$5\") ?\n\nI think we should state that these are both dynamic errors.\n> \n> - If $ must be escaped as \\$, then clearly \\ must also be \n> escaped (probably \\\\).  Otherwise, it would be impossible to \n> insert a backslash followed by a captured substring.  For \n> example, replace($anything, \"(.*)\", \"\\$1\") needs to be \n> replace($anything, \"(.*)\", \"\\\\$1\")\n\nYes, it would seem so.\n> \n> ***\n> *** Questions/comments on 6.4.16.1:\n> ***\n> \n> - What's considered a \"newline character\" for the purpose of \n> ^$. matching?  \\r? \\n? \\r\\n? (which isn't a character, but a sequence)\n\nI think x0A only. Users have to try quite hard to get any other sequence\nthrough the XML parser.\n> \n> -  The additional meta-characters change what is considered a \n> \"normal character\" in the regular expression.  So in addition \n> to modifying the XML Schema quantifier production (4), you \n> also want to modify the Char production (10).\n\nnoted\n> \n> I note in passing that the XML Schema spec appendix F contains two\n> errors:  The definition of metacharacter omits the vertical \n> bar | (which is properly accounted for in the Char \n> production), while the Char production omits the curly brace \n> metacharacters { and } (which are properly accounted for in \n> the metacharacter definition).  Oops.\n> \n> Furthermore, the XML Schema regexp grammar allows for \n> expressions like \"|\" and \"()|()\".  This is possibly an error. \n>  (Both branches to the choice are allowed to be empty, \n> because branch ::= piece*.  Similarly, parentheses can wrap \n> the empty string.)\n> \n> - Because the XML Schema grammar for regexps is flawed, and \n> you're using only a small part of it unmodified anyway, it's \n> probably best to completely define your (corrected, modified) \n> regexp grammar here.\n\nI'm reluctant to do this. Looking at the specs for regular expressions in\nPerl, Java, and Schema shows how difficult it is to do it well; I think we\nwould be rather arrogant to assume we can do it better if we do it all\nourselves, and I would rather avoid the risk of creating accidental\ndifferences from the XML Schema specification.\n> \n> -  \"The effect of [reluctant quantifiers] is that the regular \n> expression matches the shortest possible substring \n> (consistent with the match as a whole succeeding).\"  I think \n> this parenthetical statement should not be parenthetical, \n> because it significantly affects the behavior of the \n> reluctant quantifier.\n\nReasonable comment, though I think it's editorial.\n> \n> \n> ***\n> *** Questions/comments on 6.4.19\n> ***\n> \n> - I suppose you know that the escaping rules differ for each \n> URI part? Section 2.4.2 of RFC 2396 might be illuminating.  \n> I'm not sure\n> escape-uri() is useful as-is.  Should probably be something \n> more along the lines of construct-uri(part1 string?, part2 \n> string?, ...).\n\nYes, URI escaping is a highly fraught subject. But I think that the function\nwe have defined here will meet the common use cases.\n> \n> - Consider adding functions for XML entitization/de-entitization\n> (suggested: entitize(string?) string? and unentitize(string?) \n> string?). I suppose I can cobble together the same \n> functionality by going through a dummy element constructor, \n> but I think this functionality is more central to XQuery than \n> URI escaping.\n\nSorry, what is \"XML entitization\" supposed to do?\n\nMichael Kay\n> \n\n\n\n", "id": "lists-017-15691324"}, {"subject": "RE: comment on Xpath 2.0  no strong typing!", "content": "> Michael Kay wrote [Thu, 3 Oct 2002 13:08:07 +0200]\n> > The term \"strong typing\" means different things to \n> different people. \n> > There are some type rules in XPath 1.0, for example you \n> cannot supply \n> > a number as an argument to the count() function or as an operand of \n> > the \"/\" operator.\n> >\n>\nMichael Brundage: \n> At the risk of being pedantic, I'd just like to point out \n> that \"strongly typed\" has a well-defined meaning, and any \n> other use of the term is just a corruption of the language.  \n> See, for example, \n> http://whatis.techtarget.com/definition/0,289893,sid9_gci21305\n8,00.html\nWe can quibble over minor details (as always), but the core meaning holds.\n\nI'm not sure what you're quarrelling with in my statement. The first\nsentence was just a disclaimer saying I'd prefer to avoid using the phrase\n\"strong typing\" without defining it first: in fact I'm quite sure that many\npeople would disagree with the assertion in the definition that you cite\nthat \"[strong typing] prevents the programmer from inventing a data type not\nanticipated by the developers of the programming language\"  \n\nThe second sentence of mine is obviously true.\n\n\nMB>The confusion over XSLT/XPath stems largely from the fact that these\nlanguages are, as you well know, only \"half-way\" strongly-typed.  With a\nhandful of exceptions (external parameters, external script functions),\nevery expression in XPath and XSLT 1.0 has a type that is known at\ncompile-time.  Granted, these types are fairly weak (number, node, etc.),\nalthough some compile-time analysis can improve that somewhat (integer,\ndouble, element, attribute, ...), but nevertheless, almost all expressions\nin an XSLT/XPath are strongly typed.\n\nMK>Well, the definition of \"strongly-typed\" that you used says \"all\nconstants or variables defined for a given program must be described with\none of the data types\", and under that definition XPath 1.0 is obviously NOT\nstrongly typed.\n\nMB>I've heard the XQuery WG comment publicly several times now that XSLT is\nweakly-typed and not optimizable, and I think you are doing yourselves a\ndisservice by resorting to flawed argumentation.  Numerous XSLT\nimplementations can and have successfully applied both strong-typing rules\nand non-trivial optimizations (even though the standard did little to lay a\nsolid foundation for either).\n\nMK>This is true. It is also true that implementations could do more\noptimization if more type information were available statically. The fact\nthe the type of parameters is not known in advance certainly limits what an\noptimizer can do.\n\nMB>Furthermore, eliminating implicit type conversions does not make a\nlanguage more strongly-typed -- it just makes it more rigid (which can be a\npositive aspect).\n\nMK>Well, see http://www.wkonline.com/d/weak_typing.html, which says \"C and\nC++ are weakly typed, as they automatically coerce many types e.g. ints and\nfloats.\" \n\nMichael Kay\n\n\n\n", "id": "lists-017-15705322"}, {"subject": "Use Cases 1.2.4.1 (TREEQ1): wrong solutio", "content": "The use case is supposed to take an input file like this\n\n<book>\n   <title>Data on the Web</title>\n   <author>Serge Abiteboul</author>\n   <author>Peter Buneman</author>\n   <author>Dan Suciu</author>\n   <section id=\"intro\" difficulty=\"easy\" >\n     <title>Introduction</title>\n     <p>Text ... </p>\n     <section>\n       <title>Audience</title>\n       <p>Text ... </p>\n     </section>\n     <section>\n       <title>Web Data and the Two Cultures</title>\n       <p>Text ... </p>\n       <figure height=\"400\" width=\"400\">\n         <title>Traditional client/server architecture</title>\n         <image source=\"csarch.gif\"/>\n       </figure>\n       <p>Text ... </p>\n     </section>\n   </section>\n...\nand generate a nested table of contents.\nHowever, the solution\n\n\ndefine function toc($e as element )\n   as element*\n{\n   let $n := local-name( $e )\n   return\n     if ($n = \"section\")\n     then <section>\n              { $e/@* }\n              { toc($e/*) }\n            </section>\n     else if ($n = \"title\")\n     then $e\n     else ()\n}\n\n<toc>\n   {\n     toc( document(\"book.xml\")/book )\n   }\n</toc>\n\nwill generate nothing.\n\n- toc will be called the first time with the node \"book\" as the $e parameter\n- the local-name of $e is \"toc\"\n- so toc will return the empty sequence and processing will stop\n\nThe correct definition for the \"toc\" function would be\n\ndefine function toc( $elmt as element)\n   as element*\n{\n   for $e in $elmt/*\n   let $n := local-name( $e )\n   return\n     if ($n = \"section\")\n     then\n         <section>\n            { $e/@* }\n            { toc($e) }\n         </section>\n     else if ($n = \"title\")\n     then $e\n     else ()\n}\n\nAlberto\n\n-------------------------------\nAlberto Massari\neXcelon Corp.\nhttp://www.StylusStudio.com\n\n\n\n", "id": "lists-017-15715873"}, {"subject": "[admin] New mailing list syste", "content": "Dear subscribers,\n\nIn order to facilitate the work of the moderators of mailing lists,\nand to make the W3C's mail archive policy explicit we have a new system\nfor our lists. Now when you send a message to a list you will receive\nan automatic reply asking you to confirm that you want to post to that list.\nIf you specify so in your response, the system will remember your address\nand will never prompt you again.\n\nMax.\n\n\n\n", "id": "lists-017-15724519"}, {"subject": "Re: Issue-0079: String-value vs. string-value of the typedvalu", "content": "I would like to propose an alternative view to Jeni's suggestion that \"it\nwould be a mistake to state that the string-value() of an element (or\nattribute) is the string value of its typed-value()\".  I hope also that my\nproposal might encourage further discussion in the following related areas:\n\n1) Issue 0079 (Data Model): String-value vs. string-value of the typed-value\n2) Issue 0080 (Data Model): Typed value of Document, PI and Comment nodes.\n3) The idea that a text node typed value is just xs:anySimpleType.\n4) The idea that <xsl:value-of> creates a string.\n\nApologies in advance to Jeni Tennison if this seems highly contrary to your\nview.  I hope I can convince you this approach has merit, especially since I\nthink it meshes well with your other proposal on \"sequence-constructors\"\nwhich I whole-heartedly agree with!\n\n0079: String-value vs. string-value of the typed value\n=====================================\n\nBefore addressing the issues above, and Jeni's message, I would like to\nidentify three value spaces then walk through some simple examples to see\nhow they are related.  The value spaces (meanings in parenthesis) are:\n\ni) Lexical-value (serialized form)\nii) String-value (xs:string that results from some XPath/XQuery function).\niii) Typed-value (atomic-value*)\n\nThe first case I will consider is an XML source without type information\n(i.e. parsed without a schema).  In this case, attribute values will have\nthe type annotation xs:anySimpleType and are essentially opaque.  The string\nvalue is the same as the lexical value.  The typed value of the attribute is\nof xs:anySimpleType and the string-value() of the typed-value is the same as\nthe lexical value.  So far this discussion does not inform the real nature\nof the string-value. To some, talking about the string-value is synonymous\nwith talking about the lexical value (\"those who think of XML as marked up\ntext\"), while to others this is just a coincidence born out of the un-typed\ncase I have just described.\n\nNow consider the case of an XML source with type information and what\nhappens to an xs:decimal(\"01\") and an xs;QName(\"foo:bar\") (forgive the\nconstructor hand-waving and assume that both types are fully parsed and\nexpanded respectively).  The lexical values are clearly not open to dispute\nbeing \"01\" and \"foo:bar\".  The typed values are 1 and the uri/local-name\npair (uri corresponding to foo, baz).  The string value (as defined by XPath\n1.0) is \"1\" for the xs:decimal and undefined for the xs:QName.  The point I\nwould like to make here is that string-value is only tenuously connected to\nthe lexical value and we have some choice to define string-value so that we\nstrike the right balance between backwards compatibility and usefulness.  I\nbelieve that the best way to define the string-value is the canonical string\nvalue of the typed-value and not as the lexical value (OK, so now I have to\ndefine \"canonical\" - I'm getting to that!).  While this may at first appear\noffensive to those who in Jeni's words, \"think of XML as marked up text\", I\nbelieve that upon deeper analysis the objections melt away and everyone\nwins. I'm going to conclude this second use case by making the following\nsuggestion:  The canonical value has it's conventional meaning i.e.\nxs:double(\"32\") has a canonical string value of \"3.2E1\" (or something like\nthat ;)), and the canonical string value of an xs:QName is\n\"{namespace-uri}local-name\".  I'll attempt to explain why this makes sense.\nFirst, using the example of an xs:double (and to address one of Jeni's\npoints) what is the string value of the following content?:\n\n<value xsi:type=\"xs:double\">32</value>\n\nUnfortunately for Jeni, XPath 2.0 defines it to be \"3.2E1\". Yes, that's\ndifferent from XPath 1.0, but at least it is consistent with the parsing\nrules. However, Jeni, you did tell me the type so how can you complain?\nBesides, if you are really concerned about format then you should not rely\non the lexical form you were given and should use formatting functions.\nHarsh but fair don't you think? ;)\n\nThe string value of the xs:QName follows from the need for the string value\nto be context-free.  Since string-value of a complex type does not contain\nmarkup (and therefore no prefix mappings), information is best preserved if\nthe result is made as context-free as possible.  \n\nWithout defining all the rules for string-value (leave that to the spec\neditors), this analysis leads me to two general principles for string-value:\n\n1) Canonical.\n2) Context-free.\n\nThis appears to create a contradiction in one of Jeni's examples which I\nalso reproduce here:\n\n<foo xmlns:bar=\"http://www.example.com/\" xsi:type=\"xs:QName\">\nbar:baz\n</foo>\n\nThe string value by rule #2 is \"{http://www.example.com/\"}baz\"\n\nNow, if the content was untyped then the string value is \"bar:baz\" because\nit's just an xs:anySimpleType.  Is this a contradiction? Did we \"loose\"\ninformation? Well not really.  If you don't know the type then you can't\nconclude that \"bar\" in bar:baz is a prefix. So you might as well not have\nthe prefix mapping xmlns:bar=\"...\" and so what information have you really\nlost?\n\nAddressing another of Jeni's examples - the case of mixed content:\n\n<foo xsi:type=\"fooType\">\n   blah <bar>blah</bar> blah\n</foo>\n\nThe string value of the foo element *can* be obtained from it's typed value\n- it's not an error. Here I'll assert that the typed value of <foo> is the\nsequence obtained by concatonating the typed value of all the child nodes\n(atomization of the child node sequence).  Important to note here that this\ndefinition inverts the algorithm defined in the Data Model spec which\npre-supposes that a string value is available and constructs a typed value\nbased on that.  Since the type of the <bar> element is not specified in\nJeni's example then it is impossible to say whether the string value yieds\n\"CRLFblah blah blahCRLF\" or something similar with the middle \"blah\"\nexpanded.  In general this kind of ambiguity does not create a problem\nbecause users doing string-value over mixed content are unlikely to\nencounter types (like xs:QName) that expand into something surprising (they\ndeal in Annula Reports and Shakespeare plays).  Conversely, users who \"think\nof XML as serialized data\" are unlikely to be doing string-value over mixed\ncontent. Anyone else working on documents that contain XPath expressions and\nQNames (like XSDL, WSDL, XSD) should be aware of the pitfalls.\n\n\n0080: Typed value of document, PI, comment nodes\n======================================\n\nWith the \"atomization\" for elements approach outlined above it is also\npossible to define what the typed value and string value of a document node\nshould be because they use the same algorithm.  The typed value of PI's and\ncomments can also be brought into the fold as xs:string.\n\nText nodes should not be restricted to returning xs:anySimpleType for the\ntyped value.\n==============================================================\n\nI would also suggest that text nodes be allowed to return a type other than\nxs:anySimpleType.  The normalization rules for text nodes make it possible\nto think of text nodes as typed values which are bound to elements or\ndocuments.  However, text nodes don't have type annotations.  I strongly\nbelieve that allowing text nodes to return typed-values other than simple\ntypes will be key to making the Data Model spec feasible to implement.\nWithout it, a data model would have to perform endless calculations and\ncaching as the user alternates between the typed view and the text-node\nview.  I would also almost go so far as to say that the dm:string-value\naccessor on the Data Model is redundant because it can be calculated from\nthe typed value, but for performance reasons with untyped data it probably\nshould be retained.\n\n<xsl:value-of> and <xsl:text> don't create strings!\n====================================\n\nHaving these instructions generate strings as opposed to typed values makes\nit impossible to correctly emit an xs:QName.  The correct approach here is\nfor these instructions to first create a sequence through their appropriate\nsequence constructors (select attribute or \"content-constructor\") which is\nthen atomized to create a typed value.  That typed value then creates a text\nnode or a series of atomic values depending upon the output context (for\nXSLT this context is usually a Data Model node, but the creation of\nsequences is possible).  These instructions are also converging and probably\nshould share the same syntax (excepting the actual tag name. Both should\nhave optional select expressions or sequence(content) constructors like\nxsl:variable.  Implementations must deal with separators carefully but the\napproach is conceptually simple - rendering should be delayed as long as\npossible because serialization of an atomic value is, in general, context\ndependent.  In general I believe that conceptual simplifications occur in\nthe XSLT specification if the Data Model concept of sequences and\ntyped-values are embraced as being the first-class citizens and intermediate\nstring values and fragments are shunned as being a bottleneck for\ntype-enabling XSLT.  I also believe that this can be done in a way that\nminimises backwards compatibility issues (even though these are a *should*\nin the RFC) and above all in a way that makes sense of the string-value\nconcept.\n\nCheers\n\nDavid Holmes\ndholmes@tibco.com\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "lists-017-15732109"}, {"subject": "Re: Migration of HTTP to the use of IRIs [altdesign17", "content": "Michael,\nThanks for your patience.\n\nSo I think you are saying that the flaw in my logic is when I asserted that\nthere is no syntactic indication of the use of an IRI. Your assertion, in\neffect, is that the syntactic indication is only present when needed, and is\nimplicit in the use of UTF-8 encoding.\n\nYour assertion below is that the vast majority of cases which were not encoded\nin UTF-8 will generate one or more octet sub-sequences which are not legal\nrepresentations of characters in UTF-8. I should use the presence of such\nsequences to conclude that the URI was not encoded in UTF-8 and therefore that\nconversion to an IRI  is not applicable.\n\nMy first thought was to try applying the processing you define in (draft 7) sect\n3.2, to see if that would provide a 'failure indication' that I could use.\n\nBut I came to your Step 3:\n\n\"Re-escape any octet produced in step 2 that is not part of a strictly legal\nUTF-8 sequence\".\n\n\nThis step re-absorbs octet sequences which are illegal in UTF-8 into the IRI\nworld, so, applying section 3.2 in its entirety _cannot_ be used as the basis of\na decision on whether or not UTF-8 encoding was used in the original escaping.\n\nSection 3.2 can only be applied if it is desired to _force_ everything that is\nreceived into an IRI.\n\nYour draft 7  does not provide the basis for deciding whether or not the URI\nshould be treated in this way. i.e. it does not give any opportunity for\nconcluding that the presented URI was encoded using some other (legacy)\nencoding.\n\nYou may recall that my concern is for the design of a web server including\nsomething like a Servlet handler, which has to decode the URI before it can\nidentify and invoke the referenced servlet (which might know what encoding was\nused in URIs identifying that Servlet).\n\nIn this 'real world' that I keep worrying about there will be a long transition\nphase when there will be many inbound URLs which contain escapes generated using\nother encodings. Forcing them into IRIs is not appropriate behaviour; by some\nother means the appropriate decoding must be selected and applied.\n\nIt seems to me that, in this situation, where URLs containing encodings other\nthan UTF-8 are to be handled differently, rather than be forced into IRIs by\nyour section 3.2, a different sequence is required. Something like:\n\nA)  Convert the received URI into an octet sequence as follows: Each %HH triplet\ngenerates an octet whose value is defined by the hex digits HH. All other\n(ASCII) characters generate an octet whose value is that of the code point of\nthat character in the ASCII/UTF-8 code table.\n\nB) Attempt to process the octet sequence generated by B as a UTF_8-encoded octet\nsequence. If the octet sequence is 'legal', i.e. it is the correct encoding of a\nsequence of integer values (but not necessarily representing valid Unicode code\npoints), then the URI does represent an IRI and the processing of (draft 7\nsect.32.) should be applied to extract the IRI.\n\nC) If, in step B, there should have been found one or more octet sequences which\ndid not form part of any 'legal' UTF_8 sequence, then no IRIs are involved and\nthe interpretation of the presented URI is to be decided by other means.\n\nNote that the application of the procedure A-C above will mean that your step 3\nwill never be applied.\n\n\nSo I think we have two possible scenarios:\n\nScenario 1)  The world is to be viewed as containing only IRIs.  _All_ received\nURIs are converted into IRIs consisting of a sequence of  'appropriate' (your\nstep 4) UTF characters.  Any non-UTF-8 escapes are still present as\nstill-escaped sequences in the IRI; there has been no attempt to interpret these\nas characters in some other encoding.\n\nScenario 2)  In a word in which URIs intended to represent IRIs co-exist with\nURIs encoded using other character encodings, and where the difference has to be\ndetected so that the appropriate decoding can be applied, then my steps A-C must\nfirst be undertaken. If my steps A-C indicate that another encoding was used,\nthen the URI is to be handled in some other way, and no IRI is involved. If no\nevidence of a different encoding is found, then it is to be assumed that\nconversion to an IRI is valid and your steps 1-5 should be applied (but step 3\nwill never be invoked).\n\nMy tentative conclusion is this:\n\nThe IRI draft 7 does not provide any support or advice for those needing to\nrecognize and process (intelligently and efficiently) URIs containing encodings\nother than UTF-8.\n\nWhere this needs to be done, something akin to my steps A-C is necessary, before\nit can be decided that URI to IRI conversion should be applied.\n\n\nMy concerns would be assuaged if there were a Section or Appendix in the IRI\nInternet-Draft :\n\n- Recognizing these transitional / co-existence needs,\n- Detailing the necessary and sufficient URI inspection required to decide\nwhether or not to invoke IRI processing,\n- Containing the cautions about the remote possibility of incorrect decisions\nbeing made.\n\nI'd be prepared to help draft it.\n\nFootnote 1:\nIn a 'real' implementation the two processing sequences 1-5 and A-C could be\nundertaken in a single pass through the URI using a merged algorithm,\nparameterised to define how it should proceed if a non-UTF_8 octet sequence\nshould be detected (i.e. parameterised to adopt Scenarios 1 or 2). The\nperformance penalty of my proposed addition would be insignificant.\n\nFootnote 2:\nYour approach of assuming that an IRI interpretation is valid in all situations\nin which UTF_8 has been used ought also to be validated. People are already\nusing UTF-8 encoding with no knowledge of IRIs.  I've not explored what impact\nthe application of the stage 4+5 processing of your draft (i.e. beyond that of\nde-escaping and decoding the UTF-8 characters) could have, and whether or not it\ncould cause any problems for pre-IRI users of UTF-8. I don't intent to pursue\nthis line of enquiry ;-)\n\n\nChris\n\n\n----- Original Message -----\nFrom: \"Martin Duerst\" <duerst@w3.org>\nTo: \"Chris Haynes\" <chris@harvington.org.uk>; \"Michel Suignard\"\n<michelsu@windows.microsoft.com>\nCc: <public-iri@w3.org>\nSent: Sunday, May 09, 2004 1:37 AM\nSubject: Re: Migration of HTTP to the use of IRIs [altdesign-17]\n\n\n> Hello Chris,\n>\n> I have changed the issue for this mail to altdesign-17, because it\n> seems more appropriate.\n>\n> At 11:07 04/05/07 +0100, Chris Haynes wrote:\n>\n> >Michel,\n> >\n> >Thanks for this comment, but I think my point is still valid - even just for\n> >presentational uses.\n> >\n> >Given that many URI encodings exist 'in the wild' which use %HH escaping of\n> >non-UTF-8 sequences, I fail to see how one can know that it is valid to\n> >convert\n> >any such URI into an IRI (as per sect. 3.2) - even if just for presentational\n> >purposes.\n>\n> Section 3.2 very clearly says that there is a risk that you convert\n> to something that didn't exist previously.\n> But in practice, this is not that much of an issue, because it is\n> very rare to find reasonable text encoded in legacy encodings that\n> matches UTF-8 byte patters. Please try to find some examples yourself,\n> and you will see this.\n>\n>\n> >My concern is the same:  unless there is some kind of syntactic indicator\n> >within\n> >the URI as a whole, how can one reliably know that UTF-8 has been used and\n> >that\n> >it is intended to have a corresponding IRI?\n>\n> You are correct that one cannot do this with 100% certainty.\n> But then, if you study the URI spec very carefully, you will\n> find that it also doesn't guarantee that an 'a' in an URI\n> actually corresponds to an 'a' in the original data (e.g.\n> file name). For details, please see the \"Laguna Beach\"\n> example in Section 2.5 of draft-fielding-uri-rfc2396bis-05.txt,\n> for example at\n> http://gbiv.com/protocols/uri/rev-2002/draft-fielding-uri-rfc2396bis-05.txt.\n>\n> So in those rare cases where an URI with an octet sequence\n> that by chance corresponds to an UTF-8 pattern, but that was\n> never intended as UTF-8, is converted to an IRI, one will just\n> get a weird name, but reusing that name again e.g. in a browser\n> that accepts IRIs will lead back to the original resource.\n>\n>\n>\n> >It seems to me that IRI will only be deployed accurately and effectively\n> >if one\n> >of the following situations occurs:\n> >\n> >1) New protocol schemes (e.g. httpi, httpis ) are introduced which make it\n> >explicit that this spec. applies to the URI,\n>\n> Introducing a new URI scheme is *extremely* expensive. I have heard\n> Tim Berners-Lee say this over and over again, and I know he knows it.\n> And in the case at hand, it's highly unnecessary. The cost of an\n> occasional accidental 'wrong' conversion back to an IRI (as discussed\n> above) is much, much smaller than the cost of introducing new schemes.\n>\n> And what would the real benefit of new schemes be? Would they be\n> useful to distinguish URIs from true IRIs (I'm writing 'true' IRIs\n> here to exclude URIs which are by definition also IRIs). Not really,\n> it's much cheaper to identify IRIs by checking for non-ASCII characters.\n>\n> So they would only be used to distinguish URIs without known origin\n> from URIs originating from conversion from IRIs. But assume I had\n> an IRI like like http://www.example.org/ros&#xE9; (rose'). In order\n> to pass it to others whom I know can only process URIs, not IRIs,\n> would I want to convert it to http://www.example.org/ros%C3%A9,\n> or to httpi://www.example.org/ros%C3%A9 ? The former strictly\n> speaking looses the information that this was an IRI, so converting\n> it back to rose' is a guess (but because of the UTF-8 patters,\n> actually a rather safe one). But it actually will go to the\n> right page, on hunderds of millions of Web browsers, without\n> exception. The later can safely be converted back to the IRI\n> (by all the software that knows how to do this, which currently\n> numbers exactly 0). But it will work only on the browsers\n> that know the httpi: scheme (again, currently numbering\n> exactly 0). For me the alternative is very clear,\n> http://www.example.org/ros%C3%A9 works in much more cases,\n> and is therefore much better.\n>\n>\n> >2) They are used within a closed environment in which it is a convention that\n> >only IRIs and IRI-derived URIs are in use (no legacy-encoding escapes, or\nthey\n> >are allowed to be mis-interpreted)\n>\n> The current draft clearly allows legacy-encoded escapes, for backwards\n> compatibility. I'm not sure what you mean by 'mis-interpreted', but\n> if you mean that they are converted to IRIs, then yes, the current\n> draft allows this in those cases where it is possible (i.e. the\n> byte pattern matches UTF-8,...). But this misinterpretation does\n> not lead to an actual misinterpretation of the resource that the\n> IRI identifies.\n>\n>\n> >3) A new market-dominating user agent is launched which behaves as if (2)\n> >above\n> >were the case - i.e. there is an attempt to establish IRIs as the de facto\n> >default through market force, ignoring or discarding resulting errors of\n> >presentation or of resource identification.\n> >\n> >My big fear is that without rapid progress on (1), IRIs on the open Internet\n> >will only ever take off if someone does (3) - which will be without benefit\nof\n> >adequate standards backing.\n>\n> I'm not sure I understand you. Several browsers, for example\n> Opera and Safari, already implement IRIs. MS IE also does it\n> if the relevant flag is set correctly. And the standard is\n> close to done; this is the last real issue I'm trying to close.\n> So I don't see the problem.\n>\n>\n> >I'd love to either:\n> >\n> >a) be shown that my logic is faulty\n>\n> I guess yes. Not in theory, where absolute correctness is the\n> only goal, but in practice, where big numbers and deployment\n> are important.\n>\n> >or\n> >\n> >b) be pleasantly surprised by being told that there _is_  RFC work taking\n> >place\n> >on new schemes covering at least the space of http(s)\n>\n> Some schemes may benefit from an update, in particular those that\n> haven't thought about internationalization. The first example that\n> would come to my mind is the mailto: scheme.\n>\n>\n> Regards,    Martin.\n>\n>\n>\n> >otherwise, I fail to understand how IRIs will 'take off' in the 'real\nworld' -\n> >where they are so badly needed.\n> >\n> >Chris\n> >\n> >\n> >\n> >\n> >----- Original Message -----\n> >From: \"Michel Suignard\" <michelsu@windows.microsoft.com>\n> >To: \"Chris Haynes\" <chris@harvington.org.uk>\n> >Cc: <public-iri@w3.org>; \"Martin Duerst\" <duerst@w3.org>\n> >Sent: Friday, May 07, 2004 1:43 AM\n> >Subject: RE: Migration of HTTP to the use of IRIs [queryclarify-16]\n> >\n> >\n> >\n> > > From:  Chris Haynes\n> > > Sent: Thursday, May 06, 2004 4:50 AM\n> > >\n> > > Actually, my original core concern has now been covered in your\n> >section\n> > > 1.2.a - Applicability, where you make it clear that \"the intent is not\n> >to\n> > > introduce IRIs into contexts that are not defined to accept them\".\n> > >\n> > > This now makes it clear that new schemas will be required to replace\n> > > http: , https: etc. These will need to be self-identifying in some\n> >way, so\n> > > that receiving equipment will know that an IRI is being presented.\n> > >\n> > > So, as I commented last June, I await with interest the recognition\n> >among\n> > > those responsible for the HTTP schema that new schemas with new names\n> >are\n> > > required before IRIs can be used.\n> >\n> >I'd like to comment on that. The IRI spec is fairly explicit on that IRI\n> >can be used as presentation elements for URI protocol elements (ref\n> >clause 3 intro). This is to recognize that applications out there have\n> >not waited for us for creating presentation layers that use non ascii\n> >native characters for schemes that supposedly should not use them (such\n> >as http). The presentation layer principle is there to support that. So\n> >I expect IRI to be used for both purposes:\n> >- presentation layer for existing URI schemes\n> >- core layer for new schemes exclusively defined using IRI for protocol\n> >elements syntax.\n> >\n> >For a while I'd expect the vast majority of IRI usage to be in the first\n> >category.\n> >\n> >Michel\n> >\n> >\n>\n>\n>\n\n\n\n", "id": "lists-017-1574750"}, {"subject": "RE: Issue-0079: String-value vs. string-value of the typedvalu", "content": "> -----Original Message-----\n> From: David Holmes [mailto:dholmes@tibco.com] \n> Sent: 10 December 2002 20:21\n> To: 'public-qt-comments@w3.org'\n> Subject: Re: Issue-0079: String-value vs. string-value of the \n> typed-value\n> \n<snip/>\n> \n> 0079: String-value vs. string-value of the typed value \n> =====================================\n> \n> Before addressing the issues above, and Jeni's message, I \n> would like to identify three value spaces then walk through \n> some simple examples to see how they are related.  The value \n> spaces (meanings in parenthesis) are:\n> \n> i) Lexical-value (serialized form)\n> ii) String-value (xs:string that results from some \n> XPath/XQuery function).\n> iii) Typed-value (atomic-value*)\n> \n> The first case I will consider is an XML source without type \n> information (i.e. parsed without a schema).  In this case, \n> attribute values will have the type annotation \n> xs:anySimpleType and are essentially opaque.  The string \n> value is the same as the lexical value.\n\nOK. <snip/>\n> \n> Now consider the case of an XML source with type information \n> and what happens to an xs:decimal(\"01\") and an \n> xs;QName(\"foo:bar\") (forgive the constructor hand-waving and \n> assume that both types are fully parsed and expanded \n> respectively).  The lexical values are clearly not open to \n> dispute being \"01\" and \"foo:bar\".  The typed values are 1 and \n> the uri/local-name pair (uri corresponding to foo, baz).  The \n> string value (as defined by XPath\n> 1.0) is \"1\" for the xs:decimal and undefined for the \n> xs:QName.  \n\nDid you mean \"as defined by XPath 2.0\"? In 1.0, clearly, the string values\nare \"01\" and \"foo:bar\". In 2.0, as currently defined, they are the same, but\nthis is the subject of issue 079.\n\nThis is obviously a rather controversial issue, there has been a lot of\ndiscontent expressed on the xsl-list with the suggestion that information\n(such as trailing zeros) might be lost as a result of data typing. Some\npeople see data typing and schemas as purely a validation mechanism, and\nresent any idea that a schema should cause the value as written to be\ncanonicalized in some way. I'm not saying these people are right or wrong,\njust that there's definitely an open issue here and whatever we decide is\ngoing to leave some people dissatisfied.\n\n> The point I would like to make here is that \n> string-value is only tenuously connected to the lexical value\n\nThat's one point of view: it tends to be the \"data\" point of view, whereas\nthe \"document\" point of view leans the other way.\n\n<snip/>\n \n> First, using the example of an \n> xs:double (and to address one of Jeni's\n> points) what is the string value of the following content?:\n> \n> <value xsi:type=\"xs:double\">32</value>\n> \n> Unfortunately for Jeni, XPath 2.0 defines it to be \"3.2E1\".\n\nNo, the current definition in the XPath data model is that the string value\nof an element node is the concatenation of the contents of the text nodes.\n \n<snip/>\n> \n> Addressing another of Jeni's examples - the case of mixed content:\n> \n> <foo xsi:type=\"fooType\">\n>    blah <bar>blah</bar> blah\n> </foo>\n> \n> The string value of the foo element *can* be obtained from \n> it's typed value\n> - it's not an error. Here I'll assert that the typed value of \n> <foo> is the sequence obtained by concatonating the typed \n> value of all the child nodes (atomization of the child node \n> sequence).\n\nAgain, that's one possible definition of the typed value, but it's not the\none in the current data model. You hit a problem here if the tree is more\nthan two levels deep, because sequences can't contain sequences. Do you want\nthe tree to be flattened, losing the hierarchic structure? This seems\ndubious.\n\n<snip/>\n> \n> I would also suggest that text nodes be allowed to return a \n> type other than xs:anySimpleType.  The normalization rules \n> for text nodes make it possible to think of text nodes as \n> typed values which are bound to elements or documents.\n\nText nodes appear either in simple content or in mixed content. In simple\ncontent you never need concern yourself with text nodes, because you can use\nthe typed value of the containing element: unless you are actually\ninterested in embedded comments and processing instructions. In mixed\ncontent, text nodes clearly can't have any sensible type other than string.\nSo I'm not sure what you're trying to achieve. \n \n> However, text nodes don't have type annotations.  I strongly \n> believe that allowing text nodes to return typed-values other \n> than simple types will be key to making the Data Model spec \n> feasible to implement. Without it, a data model would have to \n> perform endless calculations and caching as the user \n> alternates between the typed view and the text-node view.  I \n> would also almost go so far as to say that the \n> dm:string-value accessor on the Data Model is redundant \n> because it can be calculated from the typed value, but for \n> performance reasons with untyped data it probably should be retained.\n\nIn XSLT, we get enough complaints from people that we throw away entity\nreferences and CDATA sections when they try to do an identity\ntransformation. If we convert 1234.00 to 1234.0 just because the schema says\nthe type is xs:decimal, we are certainly going to have some unhappy users,\nand quite possibly some failing applications. In XQuery too, the feedback\nfrom our (Tamino) users is that they want to retain a high degree of\nfidelity in the documents they store: if they wanted to store conventional\nstructured data, they wouldn't be using an XML database. So my own\npreference is that we should keep the lexical value and treat the typed\nvalue as being derived from it.\n> \n> <xsl:value-of> and <xsl:text> don't create strings! \n> ====================================\n> \n> Having these instructions generate strings as opposed to \n> typed values makes it impossible to correctly emit an \n> xs:QName.\n\nThis is currently true, though I think we can probably find a solution to\nthis requirement.\n\n> The correct approach here is for these \n> instructions to first create a sequence through their \n> appropriate sequence constructors (select attribute or \n> \"content-constructor\") which is then atomized to create a \n> typed value.\n\nThis debate was one the working group (or rather, the two working groups\ntogether) had in great detail. It's difficult to summarize the debate and\nthe reasons for choosing what was dubbed \"Alternative 1\" in a few lines.\nAlternative 1 was that tree construction should always construct lexical\nvalues, and type annotations should only be restored by applying schema\nvalidation (this is the current situation in XQuery, though XSLT has relaxed\nthis to allow simple type annotations to be specified at node construction\ntime). Alternative 3 allowed an arbitrary sequence to be written to a node,\nincluding heterogeneous sequences such as a sequence of arbitrary strings,\nwhich in general cannot be serialized and reparsed losslessly. Alternative 2\nhad various flavours which attempted to identify cases where the type of the\nsequence could be retained without creating instances of the data model that\ncould never arise from parsing real XML. None of the flavours of Alternative\n2 worked, so we ended up (with considerable reluctance) adopting alternative\n1.\n\n\n> That typed value then creates a text node or a \n> series of atomic values depending upon the output context \n> (for XSLT this context is usually a Data Model node, but the \n> creation of sequences is possible).  These instructions are \n> also converging and probably should share the same syntax \n> (excepting the actual tag name. Both should have optional \n> select expressions or sequence(content) constructors like \n> xsl:variable.  \n\nI don't see that much would be gained by merging xsl:value-of and xsl:text\nat this stage of the game, though a single instruction that served the\npurposes of both might have been a good idea originally.\n\n\n> Implementations must deal with separators \n> carefully but the approach is conceptually simple - rendering \n> should be delayed as long as possible because serialization \n> of an atomic value is, in general, context dependent.\n\nWhat makes it non-simple is that many sequence values that we allow in our\ndata model could never be obtained by parsing an actual XML document and\nvalidating it with a schema. We made the decision, which I think is the\nright one, that it should not be possible to construct such trees\nprogrammatically. This ensures that the data model is round-trippable to\nserialized XML.\n\n> In \n> general I believe that conceptual simplifications occur in \n> the XSLT specification if the Data Model concept of sequences \n> and typed-values are embraced as being the first-class \n> citizens and intermediate string values and fragments are \n> shunned as being a bottleneck for type-enabling XSLT.  I also \n> believe that this can be done in a way that minimises \n> backwards compatibility issues (even though these are a \n> *should* in the RFC) and above all in a way that makes sense \n> of the string-value concept.\n> \n\nI think it's entirely possible that the language could be described\nconsistently in the way you advocate. It certainly isn't obvious that this\nwould make it simpler, and it would certainly take it further away from the\nexpectations of many document-oriented XML and XSLT users, who are currently\ngenerating a lot of noise trying to push us in the opposite direction (that\nis, returning to the roots of XML as a language for annotating text using\nmarkup).\n\nThanks for your comments. There are no easy answers!\n\nMichael Kay\nSoftware AG\n\n\n\n", "id": "lists-017-15749496"}, {"subject": "F&amp;O comments: collations, code points, and  comparison", "content": "Mostly editorial comments on the F&O Nov 15 draft (these also still\napply to the internal Dec 10 draft; section numbers refer to the Dec 10\ndraft for your convenience).\n\n\n- The link on the internal group page to the latest internal F&O draft\nis wrong (points to the July 15 draft instead of the Dec 10 draft).\n\n- Don't use \"codepoint\", use \"code point\".  Both the W3C Character Model\nand the Unicode Consortium use \"code point\" in all their docs (as far as\nI can tell).  [Also, codepoint gets a red squiggle, and I refuse to add\nit to my spellchecker's dictionary :-)]\n\n- 6.3: The \"Unicode codepoint collation\" is named but not defined\nanywhere.  Confusingly, it's introduced around the same time as the\nUnicode Collation Algorithm (which is unused by XQuery).\n\n- 6.3.1: The definition of compare() explains what happens when one\nstring differs in length from the other; but this should be up to the\ncollation.\n\n- 6.4.6, 6.4.7, 6.4.14: Surrogate pairs are irrelevant.  You've already\ndefined things in terms of code points -- so the underlying bytes (and\ntherefore, surrogate pairs) never come into play.\n\n- 9.2.1, 10.2.1, 12.1.1: should all compare according to the context\ncollation\n\n- 6.3, etc.: As Jeni Tennison already brought up [1], URIs as collation\nnames are unusual (and not even followed by the draft itself).  Although\nthe idea has merit for WS-I, almost every collation implementation I can\nfind uses RFC 1766 (locale names like en-US and fr-FR).  Perhaps some\nimplementations will invent a URI syntax for their collations, but I\nexpect most Java and .NET implementations will rely on\njava.text.RuleBasedCollation and System.Globalization.CultureInfo, both\nof which are based on RFC 1766.  If you're going to insist on URIs, then\nat least make the draft examples consistent with that.\n\n- Speaking of Jeni's prior feedback, I'd like to echo the request for\ntitle-case().  Aside from newspapers and poems, I think customers really\nwant it -- I see a ton of Java and .NET questions about title case [2,\n3].  I think I said this yesterday, but it seems arbitrary omit\ntitle-case when you're already implementing most of the rest of the\nUnicode Case Mapping.  (And it shouldn't be a big implementation burden\n-- both Java and .NET provide it in their class library/frameworks.)\n\n\nCheers,\n\nMichael Brundage\nxquery@attbi.com\n\n\n[1]\nhttp://lists.w3.org/Archives/Public/public-qt-comments/2002May/0052.html\n[2] http://www.google.com/search?q=%22title+case%22+Java+%22how+do%22\n[3] http://www.google.com/search?q=%22title+case%22+NET+%22how+do%22\n\n\n\n", "id": "lists-017-15768579"}, {"subject": "RE: F&amp;O comments: collations, code points, and  comparison", "content": "Personal replies to some of your points...\n\n> \n> Mostly editorial comments on the F&O Nov 15 draft (these also \n> still apply to the internal Dec 10 draft; section numbers \n> refer to the Dec 10 draft for your convenience).\n> \n> \n> - 6.3.1: The definition of compare() explains what happens \n> when one string differs in length from the other; but this \n> should be up to the collation.\n\nI've made this point in the past, and I agree with it. I think we have now\nestablished that functions like contains() and starts-with() do need a\ncollation that has this property (described in the last NOTE in section\n6.3), but functions that purely compare for equality and ordering do not.\n\n> \n> - 6.4.6, 6.4.7, 6.4.14: Surrogate pairs are irrelevant.  \n> You've already defined things in terms of code points -- so \n> the underlying bytes (and therefore, surrogate pairs) never \n> come into play.\n\nTechnically, you are correct that this note is redundant. However, since so\nmany other programming languages that claim to have Unicode support actually\ntreat a char as a 16-bit code unit rather than a Unicode character, I think\nit's important that we make this point. Some XSLT 1.0 implementations are\nnon-compliant in this area and it's very useful to have a definitive\nstatement in the spec that proves they are wrong.\n> \n> - 9.2.1, 10.2.1, 12.1.1: should all compare according to the \n> context collation\n\n9.2.1: QNames should NOT be compared using a collation, they should be\ncompared using Unicode code points, as described in the XML 1.0 (or perhaps\nXML 1.1) specification.\n\n10.2.1 There is still some debate about exactly how anyURIs should be\ncompared, for example how escapes are handled. We're monitoring the\ndiscussion on this in the W3C TAG. However, URIs are not natural language\ntext and it certainly doesn't make sense to use the same algorithm as when\ncomparing strings.\n\n12.1.1 NOTATION is an XML concept (and a pretty obscure one at that) and we\nshould follow the XML rules for comparison, which are based on code point\ncomparison. \n> \n> - 6.3, etc.: As Jeni Tennison already brought up [1], URIs as \n> collation names are unusual (and not even followed by the \n> draft itself).  Although the idea has merit for WS-I, almost \n> every collation implementation I can find uses RFC 1766 \n> (locale names like en-US and fr-FR).  Perhaps some \n> implementations will invent a URI syntax for their \n> collations, but I expect most Java and .NET implementations \n> will rely on java.text.RuleBasedCollation and \n> System.Globalization.CultureInfo, both of which are based on \n> RFC 1766.  If you're going to insist on URIs, then at least \n> make the draft examples consistent with that.\n\nWe've been through a few rounds on this and no-one has come up with a\nsatisfactory alternative. Locale names do not identify collations, they only\nidentify communities that may have preferences for a particular collation.\nWithin a locale such as en-GB, you will find that lexicographers,\ngeographers, and compilers of telephone directories use completely different\ncollations. So a locale name can only be a hint.\n\nI think that all the examples do use valid anyURI values (or at least,\nstrings that can be cast to anyURI). The big question in this area is issue\n44, which asks about the meaning of relative URIs and suggests that we\nshould require the anyURI to be absolute.\n\nFor use in XSLT, it would be much more consistent with existing practice to\nuse a QName, but it would be difficult to define a meaning for this outside\nthe context of a stylesheet.\n\nI think the biggest problem we face in this area is how to achieve a level\nof interoperability. I hope that vendors will provide mechanisms that allow\nthe URI used in a query to be defined by the user and mapped to some\ncollation offered by the implementation - see the way saxon:collation works\nin Saxon 7.x for an example of how this might be done.\n\n> \n> - Speaking of Jeni's prior feedback, I'd like to echo the \n> request for title-case().  \n\nMy Personal View Is That Title Case Is Used Only In North America, and we\nare trying to restrict ourselves to functions that have global appeal. But\nin the end, deciding whether to include or exclude particular functions is a\nmatter of judgement.\n\nMichael Kay\n\n\n\n", "id": "lists-017-15779569"}, {"subject": "RE: F&amp;O comments on 6.", "content": "Hi,\n\n> > - Is an error raised only if the entire pattern matches the \n> > zero-length string?  What about captured substrings, like \n> > replace(\"xxx\", \"()x*\",\n> > \"$1\") or replace(\"xxx\", (^).*($)\", \"$1$2\")?  Are these \n> > allowed (resulting in the empty string?) or are they errors?\n> \n> I can't see any strong reason why a zero-length captured substring shouldn't\n> be allowed, but perhaps I'm missing something.\n> \n\nWhile zero-length captured substrings might be permissible, I beleive\nthese examples would result in errors being thrown because both \"()x*\" and\n\"(^).*($)\" match the zero-length string.\n\nAccordingly, valid examples for this would be replace(\"xxx\", \"()x+\", \"$1\")\nand replace(\"xxx\", \"(^).*($)\", \"$1$2\"), both of which do not have patterns\nmatching the zero length string. Like the original examples, these should \nresult in the empty string.\n\nCheers, \nJennifer\n\n-- \nJennifer \"Georgina\" Schachter, Software Engineer   +44-1865-203192\nDecisionSoft Limited                               http://www.decisionsoft.com\nXML Development and Services\n\n\n\n", "id": "lists-017-15791902"}, {"subject": "RE: Issue-0079: String-value vs. string-value of the typedvalu", "content": "Michael Kay,\nI noticed throughout your reply a general emphasis on retaining the\noriginal lexical form of the XML source.  I did a comparison of the two\nlatest drafts of the XQuery 1.0 and XPath 2.0 Data Model (Drafts 15 Nov 2002\nand 16 Aug 2002) and found the following subtle change in the definition of\nthe dm:string-value accessor:\n\n15 Nov 2002:\n\"The dm:string-value accessor can be used to recover the lexical\nrepresentation of an atomic value.\"\n\n16 Aug 2002:\n\"The accessor dm:string-value can be used to recover a lexical\nrepresentation of the atomic value.\"\n\nDo you notice the semantic difference (\"a\" becomes \"the\")?  I must confess\nthat I didn't. Should the latest definition be interpreted as \"recover the\n(original) lexical representation\" or \"recover the (canonical) lexical\nrepresentation\" or something else? In the second case I wish to make it\nquite clear that I am trying to say that the recovered lexical\nrepresentation is in no way constrained to be identical to the original\nsource lexical representation. Thus a \"01\" which is typed as xs:integer\nwould have a canonical lexical representation of \"1\".  If your\ninterpretation of the spec is the \"original\" version and the Data Model WG\nconfirm this interpretation then I stand corrected for mis-quoting the Data\nModel spec and I thank you for pointing out the inaccuracy.\n\nHowever, this does not change my previous proposal. Furthermore, if it is\ntrue that this subtle difference reflects a change in the stance of the Data\nModel WG then this actually strengthens my resolve to see that the Data\nModel does not become tied to *the* original lexical form. I'm sure that I\ndon't need to elaborate on the implementation ramifications of retaining the\noriginal lexical form and I would like to spare us all the mutual tedium of\ndoing so. However, if you do suggest retaining the original lexical form I\nwould like to hear your thoughts at least on the duplication of lexical and\ntyped values and the implications for integrity and memory usage.\n\nI won't come back on all of your replies just now because I think that many\nof them are conditional upon the questions I have made in these opening\nparagraphs and the answers to them from yourself and the Data Model WG.\n\nI look forward to your reply and thanks for your comments.\n\nDavid Holmes\n\n\n\n", "id": "lists-017-15800775"}, {"subject": "Issues from the DOM Working Group on the XML Query 1.0 XPath 2.0  Data Mode", "content": "Attached are issues from the DOM Working Group with respect to the XML \nQuery 1.0 XPath 2.0 Data Model for your consideration.\n\nThanks,\n\nRay Whitmer\nDOM WG Chair\nrayw@netscape.com\n\n\n\n\n\ntext/html attachment: XSLQDataModel3.html\n\n\n\n\n", "id": "lists-017-15810791"}, {"subject": "XQuery: A.3 Reserved Function Name", "content": "XQuery 1.0: An XML Query Language\nW3C Working Draft 13 November 2002\n\nA.3 Reserved Function Names\n\n(Are these names in any particular order? If not, how about alphabetical?)\n\nI can see why you'd need to forbid these as function names:\n    comment\n    if\n    node\n    processing-instruction\n    text\n    typeswitch\nbut why these?:\n    item\n    element\n    attribute\n    id\n    key\n\nIn fact, since 'id' and 'key' don't occur anywhere in the grammar, there\ndoesn't seem to be any reason to reserve them in any context.\n\nTo eliminate the ambiguity of ItemType, it looks like you'll have to forbid\nthese lexemes as the QName of the AtomicType of an ItemType:\n    element\n    attribute\n    node\n    processing-instruction\n    comment\n    text\n    document\n    item\n    untyped\nSimilarly, you'll have to forbid \"empty\" as the QName of the AtomicType of\nthe ItemType of a SequenceType.\n\n-Michael Dyck\n\n\n\n", "id": "lists-017-15818072"}, {"subject": "XQuery: A.4 Precedence Orde", "content": "XQuery 1.0: An XML Query Language\nW3C Working Draft 15 November 2002\n\nA.4 Precedence Order\n\n\"In the cases where a number of statements are a choice at the same\nproduction level, the expressions are always evaluated from left to right.\"\n\n    Presumably, \"statements\" should be \"expressions\".\n\n    The phrase \"a choice at the same production level\" is somewhat vague.\n\n    And the order in which the *expressions* are evaluated is immaterial.\n    For example, in the AdditiveExpr A - B - C, the order in which you\n    evaluate A, B, and C doesn't matter; what matters is the order in which\n    you evaluate the subtractions.\n\n    Here's something that adresses these points, and comes closer to using\n    standard terminology:\n        When a production directly derives a sequence of expressions\n        separated by binary operators, the operators are evaluated from\n        left to right.\n\n    In any event, an example might help.\n\n-Michael Dyck\n\n\n\n", "id": "lists-017-15825767"}, {"subject": "Re: XQuery: A.3 Reserved Function Name", "content": "Michael, thanks for the comments.\n\n> A.3 Reserved Function Names\n\nYes, there are known bugs in this list.  To be fixed in the next\npublication.\n\n> To eliminate the ambiguity of ItemType, it looks like you'll have to\nforbid\n> these lexemes as the QName of the AtomicType of an ItemType:\n\nYes, there are known bugs with ItemType/SequenceType.  To be fixed in the\nnext publication.\n\n-scott\n\n\n\n", "id": "lists-017-15832909"}, {"subject": "Function", "content": "The current spec only allows functions to be either built in or defined in\nthe query in which they are used. I think it would be very useful to allow\nfunctions to be imported just like schemas are imported. This would allow\nauthors to create a library of functions and include them in their query\nwithout the need to duplicate them or make the global (or built-in)\n\nHow about?\nImportFunctions    ::=   <\"import\" \"functions\" \"at\"> StringLiteral\n\nRegards,\nEddie \n\n\n\n", "id": "lists-017-15840561"}, {"subject": "RE: Function", "content": "The WG is working on such a facility.  Please see Issues 74 and 75 (and\nrelated issues).\n\n/paulc\nXML Query WG Chair\n\nPaul Cotton, Microsoft Canada \n17 Eleanor Drive, Nepean, Ontario K2E 6A3 \nTel: (613) 225-5445 Fax: (425) 936-7329 \n<mailto:pcotton@microsoft.com> \n\n\n> -----Original Message-----\n> From: Eddie McGreal [mailto:emcgreal@BlackPearl.com]\n> Sent: Wednesday, December 18, 2002 12:50 PM\n> To: 'public-qt-comments@w3.org'\n> Subject: Functions\n> \n> \n> The current spec only allows functions to be either built in or\ndefined in\n> the query in which they are used. I think it would be very useful to\nallow\n> functions to be imported just like schemas are imported. This would\nallow\n> authors to create a library of functions and include them in their\nquery\n> without the need to duplicate them or make the global (or built-in)\n> \n> How about?\n> ImportFunctions    ::=   <\"import\" \"functions\" \"at\"> StringLiteral\n> \n> Regards,\n> Eddie\n\n\n\n", "id": "lists-017-15848174"}, {"subject": "RE: Function", "content": "Thanks: we're working on specifications for \"modules\" at the moment, one of\nthe main aims is to support such function libraries.\n\nMichael Kay\n\n> -----Original Message-----\n> From: Eddie McGreal [mailto:emcgreal@BlackPearl.com] \n> Sent: 18 December 2002 17:50\n> To: 'public-qt-comments@w3.org'\n> Subject: Functions\n> \n> \n> \n> The current spec only allows functions to be either built in \n> or defined in the query in which they are used. I think it \n> would be very useful to allow functions to be imported just \n> like schemas are imported. This would allow authors to create \n> a library of functions and include them in their query \n> without the need to duplicate them or make the global (or built-in)\n> \n> How about?\n> ImportFunctions    ::=   <\"import\" \"functions\" \"at\"> StringLiteral\n> \n> Regards,\n> Eddie \n> \n\n\n\n", "id": "lists-017-15857415"}, {"subject": "Six comments on the XQuery grammar (2002 Nov 15 draft", "content": "1. ExprComment disallows } for no good reason.\n(By analogy, CdataSection and XmlComment do not prohibit >.)\nRecommended change:\n\n[6] ExprComment ::= \"{--\" Char* \"--}\"\n\nNote that ExprComment, CdataSection, XmlComment, and\nXmlProcessingInstruction could be more properly defined using:\n\n[6] ExprComment   ::= \"{--\" ([^-]* | \"-\" [^-]* | \"--\" [^}]*) \"--}\"\n[99] CdataSection ::= \"<![CDATA[\"\n                      ([^&#x005D;]* | \"]\" [^&#x005D;]* | \"]]\" [^>]*)\n                      \"]]>\"\n[100] XmlPI       ::= \"<?\" PITarget ([^?]* | \"?\" [^>]*)  \"?>\" \n[101] XmlComment  ::= \"<!--\" ([^-]* | \"-\" [^-]* | \"--\" [^}]*) \"-->\" \n\nThis change would remove the need to specify the exception cases in\nprose outside the grammar (\"Char*, except for the terminator\"), and also\nwould make the lookahead explicit.\n\n\n2. VarName should include \"$\".\nEvery occurrence of \"$\" precedes VarName; conversely every occurrence of\nVarName follows \"$\".  Therefore, \"$\" should be rolled into VarName.\nRecommended change:\n\n[13] VarName ::= \"$\" QName\n\n(and update all referring productions)\n\n\n3. ElementContent is ambiguous.\nIn ElementContent, whitespace is significant.  How then should the\nfollowing expression parse?\n\n<x>{--x--}</x>\n\nI see three possible ways to parse this XQuery:\n(i)   An element containing the seven characters {, -, -, x, -, -, and }\n(ii)  An empty element (parsing the content as an XQuery comment which\nis ignored)\n(iii) An element whose content is the value of the enclosed expression\n--x-- (which is semantically equivalent to -(-(x--)), that is, unary\nminus applied twice to the path x--)\n\nWhich is the correct one?\n\n\n4.  Another ambiguity in ElementContent.\nThe Char must disallow {, }, <, and &. In other words, the production\nshould be changed to:\n\n[102] ElementContent ::= [^{}<&]\n                       | \"{{\" | \"}}\"\n                       | ElementConstructor\n                       | EnclosedExpr\n                       | CharRef\n                       | PredefinedEntityRef\n                       | XmlComment\n                       | XmlProcessingInstruction\n(see also next feedback item)\n\n5. AttributeValueContent is ambiguous.\nClearly the Char must disallow the terminator, so at a minimum these\nproductions must be changed to:\n\n[104] AttributeValue ::= ('\"' (EscapeQuot | [^\"] |\nAttributeValueContent)* '\"')\n                       | (\"'\" (EscapeApos | [^'] |\nAttributeValueContent)* \"'\") \n[105] AttributeValueContent ::=  CharRef \n                              |  \"{{\"\n                              |  \"}}\"\n                              |  EnclosedExpr \n                              |  PredefinedEntityRef \n\nHowever, there are still ambiguities with & and { (see next item).\n\n6. Escapes, strings, and content could be simplified.\n\nAccording to the explanation of the *_ATTRIBUTE_CONTENT lexical states,\nthe EnclosedExpr nests lexical states and therefore may contain the\nterminator.  For example, the XQuery expression <x a=\"{\"\"}\"/> is\nsyntactically valid and semantically equivalent to <x a=\"\"/>.\n\nOn the one hand, you could potentially simplify the lexer by eliminating\nthis nesting condition (i.e., any occurrence of the terminator, even in\nan EnclosedExpr, ends the attribute value).\n\nOn the other hand, as long as this nesting condition remains, you have\nno less than four different ways to escape the terminator:\n   (a) use a predefinedEntityRef: <x a=\"&quot;\"/>\n   (b) use a numerical ref (hex or decimal): <x a=\"&#x22;\"/>\n   (c) use an enclosed expr: <x a=\"{'\"'}\"/>\n   (d) double it up: <x a=\"\"\"\"/>\n\nThere is no good reason to introduce a fourth mechanism (doubling-up)\nwhen three others already exist.  I recommend removing it, and then\nsimplifying the grammar as follows:\n\nDelete: 11, 18, 105 (EscapeQuot, EscapeApos, AttributeValueContent) \nAdd:\n[X1] ComputedString    ::= ('\"' (QuotStringContent | EnclosedExpr)* '\"')\n                         | (\"'\" (AposStringContent | EnclosedExpr)* \"'\")\n[X2] QuotStringContent ::= [^\"&{}] | EscapeSequence\n[X3] AposStringContent ::= [^'&{}] | EscapeSequence\n[X4] EscapeSequence    ::= CharRef\n                         | PredfinedEntityRef\n                         | \"{{\" | \"}}\"\nChange:\n[4] StringLiteral    ::= '\"' QuotStringContent* '\"'\n                       | \"'\" AposStringContent* \"'\"\n[5] URLLiteral       ::= StringLiteral\n[104] AttributeValue ::= ComputedString\n[102] ElementContent ::= Char\n                       | EscapeSequence\n                       | ElementConstructor\n                       | CdataSection\n                       | XmlComment\n                       | XmlProcessingInstruction\n\n(or if you adopt item #4 above, this would instead be:\n[102] ElementContent ::= [^{}<&]\n                       | EscapeSequence\n                       | ElementConstructor\n                       | CdataSection\n                       | XmlComment\n                       | XmlProcessingInstruction\n)\n\nPersonally, I would then enhance the language by allowing ComputedString\nin PrimaryExpr (and possibly also ProcessingInstructionTest) :\n\n[62] PrimaryExpr ::= Literal\n                   | ComputedString\n                   | FunctionCall\n                   | (\"$\" VarName)\n                   | ParenthesizedExpr\n\nThese changes have the added advantage that now the grammar allows\ncharref and predefinedentityref in StringContent, and eliminates the\nChar ambiguity that occurred in AttributeValue.\n\nNote also that the \"}}\" escape is technically unnecessary, and both it\nand the \"{{\" escape are redundant with the existing CharRef escapes.\nConsider removing these redundant escapes.\n\n\nCheers,\n\nMichael Brundage\nxquery@attbi.com\nAuthor, \"XQuery: The XML Query Language\", Addison-Wesley\n\n\n\n", "id": "lists-017-15866069"}, {"subject": "[xslt2] typo in example, Saxo", "content": "Hi :)\n\n1. typo\n\nhttp://www.w3.org/TR/xslt20/#regular-expressions\n###\n<xsl:analyze-string select=\"abstract\" regex=\"\\n\">\n   <xsl:non-matching-substring>\n     <xsl:value-of select=\".\"/>\n   </xsl:non-matching-substring>\n   <xsl:matching-substring>\n     <br/>\n   </xsl:matching-substring>\n</xsl:for-each>\n###\n\nThe last line should be\n\n   </xsl:analyze-string>\n\nAFAICS.\n\n2. Saxon\n\nShould the examples in\n   http://www.w3.org/TR/xslt20/#regular-expressions\nrun in the latest Saxon?\n\nTobi\n\n-- \nhttp://www.pinkjuice.com/\n\n\n\n", "id": "lists-017-15879033"}, {"subject": "Re: [xslt2] typo in example, Saxo", "content": "P.S.\n\n\nanalyze-string etc work quite well so far :)\n\nThanks!\n\nTobi\n\n\n> 2. Saxon\n> \n> Should the examples in\n>   http://www.w3.org/TR/xslt20/#regular-expressions\n> run in the latest Saxon?\n\n\n-- \nhttp://www.pinkjuice.com/\n\n\n\n", "id": "lists-017-15886933"}, {"subject": "RE: [xslt2] typo in example, Saxo", "content": "> \n> 1. typo\n> \n> http://www.w3.org/TR/xslt20/#regular-expressions\n> ###\n> <xsl:analyze-string select=\"abstract\" regex=\"\\n\">\n>    <xsl:non-matching-substring>\n>      <xsl:value-of select=\".\"/>\n>    </xsl:non-matching-substring>\n>    <xsl:matching-substring>\n>      <br/>\n>    </xsl:matching-substring>\n> </xsl:for-each>\n> ###\n> \n> The last line should be\n> \n>    </xsl:analyze-string>\n> \n> AFAICS.\n\nThanks, now fixed.\n> \n> 2. Saxon\n> \n> Should the examples in\n>    http://www.w3.org/TR/xslt20/#regular-expressions\n> run in the latest Saxon?\n> \n\nYes (though I haven't tested them specifically).\n\nMichael Kay\n\n\n\n", "id": "lists-017-15894328"}, {"subject": "Regarding your comment on xsleditor", "content": "Thank you for your comment to xsl-editors@w3.org archived at\nhttp://lists.w3.org/Archives/Public/xsl-editors/2002JanMar/0108\n\nThe XSL WG is going through the comments at this time, developing\nerrata and lists of items to consider for a future version of XSL.\n\nThe following is our disposition of your above comment:\n\n---\nDisposition: Future XSL version\n\nYou are correct, index support is not part of XSL 1.0. \n\nThis request for new functionality will be considered for a future version of XSL.\n---\n\nPlease Reply (cc-ing xsl-editors@w3.org) if you wish to make\nan objection to our resolution.\n\nThank you for your interest in XSL.\n\nPaul Grosso for the XSL FO Subgroup of the XSL WG \n\n\n\n", "id": "lists-017-15939468"}, {"subject": "Regarding your comment on xsleditor", "content": "Thank you for your comment to xsl-editors@w3.org archived at\nhttp://lists.w3.org/Archives/Public/xsl-editors/2002JanMar/0130\n\nThe XSL WG is going through the comments at this time, developing\nerrata and lists of items to consider for a future version of XSL.\n\nThe following is our disposition of your above comment:\n\n---\n\nDisposition: Explanation of why no change will be made\n\nThe issue of the design of the inheritance model has been extensively discussed by the WG. This is the reply to a quite similar comment at the CR\nstage: \n\nThe design approach taken for XSL was to have a simple inheritance model. Making this change would obviously introduce an exception to this\nmodel. There are many other properties that one MIGHT not want to inherit from e.g. a table-and-caption to the content of the cells so why single\nout indent? If one, for example, wants to center a table-and-caption one specifies text-align=\"center\" for the table-and-caption, which inherits to the\ncells.\n\nThere are also cases where it is necessary to be able to use the value of an indent value in effect outside a reference area inside it. One example is for\n\"CSS side floats\" where the floated object is to have the same indent as where the float was defined. In XSL this means that the indent of the content\nof the reference area generated by the fo:float should be the same as the indent of the fo in which the float occurred. In other cases, eg when using an\n\"offset\" style where paragraphs are indented, but \"headings\" are not, it is also more convenient to inherit the indents. \n\nThe consensus of the working group was to not introduce this breaking of the inheritance as it is sometimes very useful and in the cases where it is\nnot what the stylesheet author wishes it is very easy to make an explicit specification of the desired indent. An example, using attribute-sets, has been\nadded to the specification to show this. \n\n---\n\nPlease Reply (cc-ing xsl-editors@w3.org) if you wish to make\nan objection to our resolution.\n\nThank you for your interest in XSL.\n\nPaul Grosso for the XSL FO Subgroup of the XSL WG \n\n\n\n", "id": "lists-017-15947156"}, {"subject": "Regarding your comment on xsleditor", "content": "Thank you for your comment to xsl-editors@w3.org archived at\nhttp://lists.w3.org/Archives/Public/xsl-editors/2002JanMar/0121\n\nThe XSL WG is going through the comments at this time, developing\nerrata and lists of items to consider for a future version of XSL.\n\nThe following is our disposition of your above comment:\n\n---\n>Could you please clarify for me the role of properties defined on\n>elements of the layout-master-set subtree in inheritance within\n>page-sequences.  For example, numerous properties apply to\n>fo:simple-page-master and the various regions which are not exclusive to\n>the layout-master-set.  These properties seem, in general, not to be\n>inherited, but to support the  `inherit' keyword.  When such properties\n>occur in an fo:flow with the `inherit' specifier, in the absence of any\n>specification in the line of descent from fo:root to the element in the\n>fo tree, but with a specified value on the relevant region-body, is the\n>computed value derived from the initial value or from the value\n>specified on fo:region-body?\n\n\nDisposition: Explanation of XSL spec\n\nIt is derived from the value specified on fo:region-body. \n\n\n>When properties not directly applicable to the layout-master-set and its\n>children are specified on one of those children which later becomes\n>involved in the page generation for a flow, are those properties\n>inherited, of available for `inherit' specification, by children of the\n>flow?\n\n\nDisposition: Explanation of XSL spec\n\nNo. \n\n>When the from-nearest-specified-value function is invoked within a flow,\n>are the properties specified on the page master elements for the current\n>page also available to the function? \"The value returned is that for the\n>closest ancestor of the formatting object for which the expression is\n>evaluated on which there is an assignment of the property in the XML\n>result tree in the fo namespace.\"\n\n\nDisposition: Explanation of XSL spec\n\nNo. \n---\n\nPlease Reply (cc-ing xsl-editors@w3.org) if you wish to make\nan objection to our resolution.\n\nThank you for your interest in XSL.\n\nPaul Grosso for the XSL FO Subgroup of the XSL WG \n\n\n\n", "id": "lists-017-15956573"}, {"subject": "Does XPath 2.0 allow me to return a node and a  subset of its child  nodes", "content": "Hello All,\n\nXPath 1.0 only seems to be able to return an element and ALL of its \nchildren. Does XPath 2.0 allow to write an expression that returns an \nelement and SOME of its children?\n\nExample:\n\n         <publisher name=\"Addison Wesley\">\n                 <book title=\"... XML ..\"/>\n                 <book title=\"... Eiffel ...\"/>\n                 <book title=\"... XML ...\"/>\n         </publisher>\n         <publisher name=\"O'Reilly\">\n                 <book title=\"... XML ...\"/>\n                 <book title=\"... Java ...\"/>\n         </publisher>\n\nI want to get all books where XML appears in the title, but I want to \nknow the publisher as well. This is the result I want to see:\n\n         <publisher name=\"Addison Wesley\">\n                 <book title=\"... XML ..\"/>\n                 <book title=\"... XML ...\"/>\n         </publisher>\n         <publisher name=\"O'Reilly\">\n                 <book title=\"... XML ...\"/>\n         </publisher>\n\n\nI've been unable to express this query with XPath 1.0. \npublisher[book/@title='XML'] returns publishers and ALL books, and\npublisher/book[@title='XML'] gives ONLY the books and does NOT have the \nparent <publisher> (read for '=' contains()...).\n\n\nWhat I can understand from the specs, a for loop can do what I want. But \ncan anyone suggest what it would look like? This is probably incorrect:\n\nfor $p in (//publisher)\nreturn (<publisher name=\"$p\">,\n         for $b in //book[../@name=$p/@name]\n         return $b,\n         </publisher>)\n\n\nBut more importantly, is there an expression that doesn't use \nprogramming? My XPath expressions are meant for non-programmers, and a \nfor loop is probably not easy to understand for them.\n\nIn the use cases (1.2.4.1 Q1) I found something like this:\n\n<result>\n   {\n     let $b := document(\"publishers.xml\")\n     return\n         filter($b//publisher | $b//publisher/book[@title='XML'])\n   }\n</result>\n\n\nI really didn't understand this expression at all. I assume it's equal \nto [//publisher | //publisher/book[@title='XML'] but with XPath 1.0 this \nreturns all publishers, including all their child elements, i.e. all \nbooks and not only the books with 'XML' in the title. Is XPath 2.0 \ndifferent in this respect? So does $b//publisher just return publishers \nand not the child nodes??\n\nTo give you some background: for a certain XML database I'm \ninvestigating what language is most appropiate to use to specify \nqueries. XPath 1.0 seemed to be limited in its power, but a full \nprogramming language is too much. So I'm searching for a relative simple \ndeclarative query language, that isn't too hard to implement and can run \nfast on a relational database (the XML is stored in a relational \ndatabase). So I like to know if XPath 2.0 is more suited to the task.\n\n\nAny help appreciated.\n\nRegards,\n\nBerend. (-:\n\n\n\n", "id": "lists-017-15966154"}, {"subject": "Regarding your comment on xsleditor", "content": "Thank you for your comment to xsl-editors@w3.org archived at\nhttp://lists.w3.org/Archives/Public/xsl-editors/2002JanMar/0145\n\nThe XSL WG is going through the comments at this time, developing\nerrata and lists of items to consider for a future version of XSL.\n\nThe following is our disposition of your above comment:\n\n---\nDisposition: Accepted (bug in spec)\n\nYes the example is wrong.\n\nErratum, Section 6.6.1.1.2:\n\nReplace:\n\nin XSL stylesheet: <fo:external-graphic src=\"{@image}\"/>\n\nwith\n\n<fo:external-graphic src=\"'url({@image})'\"/> \n\nReplace:\n\nfo: element and attribute tree: <fo:external-graphic src=\"TH0317A.jpg\"/>\n\nwith\n\n<fo:external-graphic src=\"'url(TH0317A.jpg)'\"/>\n\n\n>Should I be telling my students it is mandatory?\n\n\nDisposition: Explanation of XSL spec\n\nYes!\n---\n\nPlease Reply (cc-ing xsl-editors@w3.org) if you wish to make\nan objection to our resolution.\n\nThank you for your interest in XSL.\n\nPaul Grosso for the XSL FO Subgroup of the XSL WG \n\n\n\n", "id": "lists-017-15976465"}, {"subject": "RE: Does XPath 2.0 allow me to return a node and a  subset of its child  nodes", "content": "I would like to suggest that you send this kind of question to the\nwww-ql@w3.org list. \n \nPublic-qt-comments@w3.org is meant for comments/issues on the\nXQuery/XPath/XSLT specifications.  \n\nIt is more likely that you will get a timely answer to your question\nusing www-ql@w3.org.\n\n/paulc\nChair, XML Query WG\n\nPaul Cotton, Microsoft Canada \n17 Eleanor Drive, Nepean, Ontario K2E 6A3 \nTel: (613) 225-5445 Fax: (425) 936-7329 \n<mailto:pcotton@microsoft.com> \n\n\n> -----Original Message-----\n> From: Berend de Boer [mailto:berend@xsol.co.nz]\n> Sent: Sunday, June 30, 2002 6:10 PM\n> To: public-qt-comments@w3.org\n> Subject: Does XPath 2.0 allow me to return a node and a subset of its\n> child nodes?\n> \n> \n> \n> \n> \n> Hello All,\n> \n> XPath 1.0 only seems to be able to return an element and ALL of its\n> children. Does XPath 2.0 allow to write an expression that returns an\n> element and SOME of its children?\n> \n> Example:\n> \n>          <publisher name=\"Addison Wesley\">\n>                  <book title=\"... XML ..\"/>\n>                  <book title=\"... Eiffel ...\"/>\n>                  <book title=\"... XML ...\"/>\n>          </publisher>\n>          <publisher name=\"O'Reilly\">\n>                  <book title=\"... XML ...\"/>\n>                  <book title=\"... Java ...\"/>\n>          </publisher>\n> \n> I want to get all books where XML appears in the title, but I want to\n> know the publisher as well. This is the result I want to see:\n> \n>          <publisher name=\"Addison Wesley\">\n>                  <book title=\"... XML ..\"/>\n>                  <book title=\"... XML ...\"/>\n>          </publisher>\n>          <publisher name=\"O'Reilly\">\n>                  <book title=\"... XML ...\"/>\n>          </publisher>\n> \n> \n> I've been unable to express this query with XPath 1.0.\n> publisher[book/@title='XML'] returns publishers and ALL books, and\n> publisher/book[@title='XML'] gives ONLY the books and does NOT have\nthe\n> parent <publisher> (read for '=' contains()...).\n> \n> \n> What I can understand from the specs, a for loop can do what I want.\nBut\n> can anyone suggest what it would look like? This is probably\nincorrect:\n> \n> for $p in (//publisher)\n> return (<publisher name=\"$p\">,\n>          for $b in //book[../@name=$p/@name]\n>          return $b,\n>          </publisher>)\n> \n> \n> But more importantly, is there an expression that doesn't use\n> programming? My XPath expressions are meant for non-programmers, and a\n> for loop is probably not easy to understand for them.\n> \n> In the use cases (1.2.4.1 Q1) I found something like this:\n> \n> <result>\n>    {\n>      let $b := document(\"publishers.xml\")\n>      return\n>          filter($b//publisher | $b//publisher/book[@title='XML'])\n>    }\n> </result>\n> \n> \n> I really didn't understand this expression at all. I assume it's equal\n> to [//publisher | //publisher/book[@title='XML'] but with XPath 1.0\nthis\n> returns all publishers, including all their child elements, i.e. all\n> books and not only the books with 'XML' in the title. Is XPath 2.0\n> different in this respect? So does $b//publisher just return\npublishers\n> and not the child nodes??\n> \n> To give you some background: for a certain XML database I'm\n> investigating what language is most appropiate to use to specify\n> queries. XPath 1.0 seemed to be limited in its power, but a full\n> programming language is too much. So I'm searching for a relative\nsimple\n> declarative query language, that isn't too hard to implement and can\nrun\n> fast on a relational database (the XML is stored in a relational\n> database). So I like to know if XPath 2.0 is more suited to the task.\n> \n> \n> Any help appreciated.\n> \n> Regards,\n> \n> Berend. (-:\n> \n\n\n\n", "id": "lists-017-15984991"}, {"subject": "RE: Does XPath 2.0 allow me to return a node and a  subset of its  child  nodes", "content": "> XPath 1.0 only seems to be able to return an element and ALL of its \n> children. Does XPath 2.0 allow to write an expression that returns an \n> element and SOME of its children?\n\nThis list isn't really intended for such questions: it's designed for\ncomments on the spec, not for getting help and advice.\n\nYou are wrong about XPath 1.0: the expression\n\n    publisher[book[contains(@title, 'XML')]]\n    | publisher/book[contains(@title, 'XML')]\n\nreturns a node-set containing the required books together with their\npublishers. \n\nIn XPath 2.0 you can express this more concisely as:\n\n    publisher/book[contains(@title, 'XML')]/(.|..)\n\nHowever, your example shows that this isn't really what you want.\n> \n> Example:\n> \n>          <publisher name=\"Addison Wesley\">\n>                  <book title=\"... XML ..\"/>\n>                  <book title=\"... Eiffel ...\"/>\n>                  <book title=\"... XML ...\"/>\n>          </publisher>\n>          <publisher name=\"O'Reilly\">\n>                  <book title=\"... XML ...\"/>\n>                  <book title=\"... Java ...\"/>\n>          </publisher>\n> \n> I want to get all books where XML appears in the title, but I want to \n> know the publisher as well. This is the result I want to see:\n> \n>          <publisher name=\"Addison Wesley\">\n>                  <book title=\"... XML ..\"/>\n>                  <book title=\"... XML ...\"/>\n>          </publisher>\n>          <publisher name=\"O'Reilly\">\n>                  <book title=\"... XML ...\"/>\n>          </publisher>\n> \nNeither XPath 1.0 nor XPath 2.0 can construct this result. XPath only\nselects nodes in an existing tree. To construct a new tree, by selectively\ncopying nodes from an existing tree, you need XSLT or XQuery. \n\nMichael Kay\n\n\n\n", "id": "lists-017-15999393"}, {"subject": "Re: Migration of HTTP to the use of IRIs [altdesign17", "content": "Hello Chris,\n\nI have changed this to be about issue altdesign-17.\n\nAt 12:49 04/05/06 +0100, Chris Haynes wrote:\n\n>Martin,\n>\n>Thanks for this response.\n>\n>Actually, my original core concern has now been covered in your section \n>1.2.a -\n>Applicability, where you make it clear that \"the intent is not to \n>introduce IRIs\n>into contexts that are not defined to accept them\".\n>\n>This now makes it clear that new schemas will be required to replace http: ,\n>https: etc. These will need to be self-identifying in some way, so that\n>receiving equipment will know that an IRI is being presented.\n\nI'm very surprised that you interpret this in this way. The point\ndiscussing applicability of IRIs with respect to various URI schemes\nis section 1.2.c. This is the only applicability item where URI\nschemes are discussed. [I hope you don't confuse XML Schema and\nURI schemes.]\n\nWhat the spec means by 'contexts' is slots in a protocol or format\nwhere URIs or IRIs may go. As an example, the first line in a\nHTTP protocol exchange usually looks like:\n\nGET /foo/bar/baz.html HTTP/1.1\n\nThe \"GET\" is the request method. The \"HTTP/1.1\" is the protocol\nversion. The \"/foo/bar/baz.html\" is an URI, absolute (for proxies)\nor relative to the server in question. The HTTP spec designates\nthis as an URI, and section 1.2.a says that you are not supposed\nto suddenly use an IRI in such a context, which means that if you\nhave an IRI that you want to resolve, you have to convert it to\nan URI as described in the IRI spec.\n\n\n>So, as I commented last June, I await with interest the recognition among \n>those\n>responsible for the HTTP schema that new schemas with new names are required\n>before IRIs can be used.\n\nThere is no such recognition, and there is no need to create new schemas.\nWhile creating new schemas might in one way or another lead to a cleaner\nsolution, it would be overkill because it would be very difficult to\ndeploy.\n\n\nRegards,    Martin.\n\n\n\n>Returning to the logged issue...\n>\n>Your new paragraph in 7.8 is helpful, but not, I fear, strictly accurate.\n>\n>The phrase \"returned query URIs will use UTF-8 as an encoding\" is accurate \n>only\n>if the browser's user has not manually changed the page encoding via the menu\n>commands available to her (e.g. with MSIE the  \"View - Encoding\" menu \n>sequence).\n>It can easily be demonstrated that this user selection of the encoding \n>overrides\n>the encoding declared in the HTML text or associated HTTP header when requests\n>are formulated.\n>\n>'will use' is therefore too strong.\n>\n>Changing the phrase to \"returned query URIs will, by default, use UTF-8 as an\n>encoding\" is an accurate statement - it just leaves open the question of what\n>'by default' means.\n>\n>Chris\n>.\n\n\n\n", "id": "lists-017-1600203"}, {"subject": "Comments on April XQuery drafts (long, sorry", "content": "This is a set of comments on the suite of XQuery-related Working Drafts.\nIt is based on perusal of the drafts dated April 30, 2002 (Formal\nSemantics is March 26, Requirements of Feb 15 2001).  I paid particular\nattention to the XML Query and Use-Cases specifications. I've given my\ncomments numbers in case somebody wants to call any of them out.\n\nI apologize in advance for using the contraction \"XQuery\" throughout.\nAlso I use \"XSD\" to denote W3C XML Schemas.\n\nTB 1. Maximalism\n\nThe family of XML Query specification makes no visible effort to hit an\n80/20 point.  It is trying very hard to stake out COMPLETE solution in\nthe XML query space, which is rather courageous given the profound lack\nof industry experience.\n\nThe immense amount of work that has gone into this specification would\nhave a much higher chance of a positive impact on the world if the\nfeatures and functions provided in XQuery were reduced by a huge factor,\ncutting back at least to XPath 1.0's level of semantic richness.\n\nFurthermore, this specification's size and complexity make it inevitable\nthat its arrival will be delayed by amounts of time that seem\nunreasonable to those on the outside looking in.  This will cause\nproblems because vendors who need this functionality will release\nsoftware based on unstable drafts, creating a combination of conversion\nand interoperability problems down the road.\n\nThe size and complexity also ensure that when XQuery 1.0 finally\narrives, it will be well-populated with bugs, some of which will be\nhighly injurious to interoperability.\n\nFurthermore, the immense size of the XQuery language as specified here\nwill make implementations difficult and time-consuming.  This will lead\nto consideration of conformance levels.  Industry experience with\nleveled conformance, specifically in the case of SQL, has been very bad;\nleveled conformance leads inevitably to interoperability problems.\n\nA core mandate of the W3C is to deliver specifications that promote\ninteroperability.  The extreme size and complexity of the current XQuery\ndrafts clearly are harmful to interoperability, for the reasons detailed\nabove.  Radical surgery should be applied to the XQuery feature\nset. This will lead to a higher-quality, more  widely-deployed result\nwith a substantially smaller investment of work.\n\nTB 2. Spec Suite organization\n\nThere needs to be an overview somewhere, a starting point, mostly\ntutorial in nature, that explains the relationships between XQuery, the\ndata model, the use cases, the functions and operators, and XPath 2.\nHaving read all of them at least in part, I remain fairly puzzled as to\nhow they're supposed to fit together.\n\nTB 3. Function of the \"Data Model\" and \"Formal Semantics\"\n\nIt is not clear that both the Data Model and Formal Semantics\nspecs need to exist, or that they need to have independent lives outside\nof the XQuery spec.  In particular, I'm pretty sure that a conformant\nXQuery implementation could be built with little or no reference to\nanything but the XQuery and F&O specs, raising questions as to whether\nall the work on DM and FS are cost-effective.\n\nThe Data Model and Formal Semantics docs are sufficiently complex and\nhard to understand that they don't seem to serve any tutorial purpose.\nAt the very least, the spec suite needs to be very clear as to whether\nimplementors need to read them (in whole or in part), and if so why.\n\nTB 4. Overlapping material\n\nThere is a large amount of overlapping material in XQuery, the Data\nModel, the Formal Semantics, and XPath 2.  This has the negative effect\nthat it's really hard to read both XQuery and XPath and pay attention,\nbecause the attention wanders as you realize you've already read this\n15-page sequence.  It would be highly desirable if the material that is\n*not* common could be called out somehow.\n\nI as an implementor would be very interested in which bits of machinery\nare XQuery-only, XPath-only, or shared.\n\nSince the portions that are shared are sensibly generated from a common\nsource, I assume that such a call-out is achievablle.\n\nI note considerable overlap also in the FS and DM specs with each other\nand with XQuery.  The same comment applies.\n\nTB 5. Use Cases for Type-based operations\n\nXQuery defines built-in primitives which operate in terms of data types:\n\"cast\", \"treat\", \"assert\", and \"validate\".  The volume of design that\nhas gone into building this framework is highly out of proportion to the\nscenarios presented in the Use Cases document.\n\nIn particular, there are no use cases for the \"cast\", \"assert\", or\n\"validate\" built-ins.  Almost every other aspect of XQuery has a far\nricher backing in the use-case document. It is difficult to understand\nhow the design of such a framework can proceed intelligently without\nuse-cases in mind.\n\nThe best solution to this problem would be simply to drop most of these\ntype-based operations in the interests of getting a reasonably\ninteroperable XQuery 1.0 done in a reasonable amount of time.\n\nTB 6. XML Schema Data Types and Duration\n\nThe reliance on XML Schema basic types seems well-thought-through,\nalthough the comprehensibility and ease of implementation of XQuery\nwould be greatly increased by dropping support for some number of XSD\nbasic types, without, it seems, much serious loss of functionality.\n\nThe use of two types derived from XSD's \"Duration\" type is obviously\nnecessary, but highlights a co-ordination problem.  Anybody who wants\nto do computation with duration-typed data is pretty clearly going to\nwant the XQuery version, not the XSD version.  Since it seems that many\ndifferent activities want to use XSD basic data types, it is highly\nunsatisfactory that they are going to have to call out to two\nspecifications, XSD and XQuery.  As a co-ordination issue, XML Schema\nshould be required to fix this design defect.\n\nTB 7. PIs and Comments\n\nIf I read XQuery 2.1.3.2 and 2.3.1.2 correctly, XQuery includes the\ncapability of searching on the presence of comments and on PIs and their\ntargets.\n\nPI search capability is guaranteed to provoke controversy since there is\na body of opinion that PIs are architecturally second-class citizens and\nanything that promotes their use should be deprecated.   This should be\nseriously considered for removal.\n\nXQuery access to comments seems simply incorrect given that there is\nno assurance that they will be present in the data model even if they\nare in the source document, and also because it is highly\narchitecturally unsound to encourage the use of comments for holding\ninformation of lasting interest.  This should be removed without further\nado.\n\nThe inclusion of Comment and PI in XQuery is further evidence of lack of\nattention to 80/20 thinking and cost/benefit trade-offs.\n\nFor similar reasons, all of section 2.8.4 (constructors for CDATA\nsections, PIs, and comments) should be considered for removal.\n\nTB 8. Relation to Schema Languages\n\nAt the moment, by conscious design choice traceable back to the\nrequirements documents, XQuery is quite strongly linked to W3C XML\nSchemas in several ways.\n\nIn retrospect, this choice was unfortunate.  Fortunately, the situation\ncan be rectified at moderate cost and with considerable benefit.\n\nReasons why the linkage to XML Schema is problematic:\n\n- XML Schema is large, complex, and buggy.  The linkage greatly\nincreases the difficulty of understanding and implementing XQuery.\n\n- XML Schema is poorly suited to the needs of certain application\nclasses (in particular publishing applications), and there are other\nschema alternatives available which are much better suited.  These\napplication classes are also likely to be heavy potential users of XQuery.\n\n- XML Schema is a radical step forward in declarative constraint\ntechnology, full of design choices that are based on speculation rather\nthan experience.  It is highly unlikely that XSD will be the last word\nin schema technology for XML, even in those application areas in which\nit specializes.  In particular, ISO has a serious effort underway to\ncreate standards which describe multiple XML schema languages; it would\nbe disadvantageous if the use of these were incompatible with XQuery.\nDecoupling XQuery from XSD will increase survivability in the face of\ninevitable (and desirable) evolution in schema languages.\n\n- Every cross-specification dependency introduces potential versioning\nproblems that will increase the complexity and difficulty of maintaining\nthe specification suite as time goes on.  To the extent that such\ndependencies can be reduced, the W3C and the community win.\n\nNote that in the rather old XQuery requirements doc, section 3.5.5, it\nsays that \"Schema\" can mean either XML Schema or DTD.  This is an\nadmirably open viewpoint, and note that since that time, the schema\nuniverse has grown.\n\nThere is one dependency from XQuery on XSD which should not be severed,\nthe dependency on atomic data types.  XQuery clearly needs such a\nrepertory of types, and those provided by XSchema are adequate.\n\nThe remainder of this note discusses the ways in which XQuery is\ncurrently linked to XSD and how they might be dealt with.\n\nLinkage: The XQuery data model is described (in part) using terms\ndefined in XML Schema, and a specific procedure is given for\nconstructing it using the XSD PSVI as input.\n\nResolution: This is not a problem; the Data Model is described in enough\ndetail that it could be generated (as the draft notes) by a relational\ndatabase or a variety of other software modules, and understanding of\nXSD (aside from the base data types) is not required to understand the\ndata model.  The construction procedure is not really normative in terms\nof the operation of XQuery.  No change seems required.\n\nLinkage: XQuery (sect. 3.1) provides for Schema Imports, to establish\nthe in-scope schema environment.  It is assumed that these are W3C\nXML Schemas.\n\nResolution: Add a clause to production [80] to identify the schema\nfacility in use, by namespace name or or mime-type, for example:\n\n    schema \"http://www.w3.org/1999/xhtml\"\n      of namespace \"http://www.w3.org/2001/XMLSchema\"\n      at \"http:/www.w3.org/1999/xhtml/xhtml.xsd\"\n\nLinkage: XQuery provides type-based querying, where the types are those\nidentified by QNames in the data model.  Examples from XQuery 2.1.3.2:\n\n    element person of type Employee\n    attribute color of type xs:integer\n\nResolution 1: The semantics of matching the type identified by the qname\ndepend on the in-scope schema class as identified above.  XSD matches\nthe type if it's identical to or is a derivation of the named type;\nother schema languages might have a more flexible notion of type matching.\n\nResolution 2: Adjust XQuery to say that the \"of type\" clause is\nsatisfied if and only if the type given in the query is identical to\nthat found in the data model, requiring only direct qname comparison\nand bypassing schema semantics.\n\nResolution 3: Drop type-based querying in the interests of the speedier\ndelivery of a higher-quality recommendation.\n\nLinkage: XQuery provides run-time type processing through the \"treat\",\n\"assert\", and \"cast\" built-ins.\n\nResolution 1: The semantics of these functions depend on the class of\nthe in-scope schema as identified above.\n\nResolution 2: Drop these primitives from XQuery 1.0 - they have weak\nsupport in the use cases anyhow.\n\nLinkage: XQuery provides run-time validation and type-checking through\nthe \"validate\" built-in.\n\nResolution 1: The semantics of this function depend on the class of the\nin-scope schema as identified above.\n\nResolution 2: Drop this primitive from XQuery 1.0 - it has weak support\nin the use cases anyhow.\n\nBest regards, Tim Bray\n\n\n\n", "id": "lists-017-16008948"}, {"subject": "XQuery whitespac", "content": "XQuery 1.0: An XML Query Language\nW3C Working Draft 30 April 2002\n\nAre these queries valid?\n     10div 3\n     10 div3\n     10div3\nAccording to the current spec, I think they're all valid (and mean the same \nas '10 div 3').\n\nRe the space between '10' and 'div':\nI can't find anything that would require it.\n\nRe the space between 'div' and '3':\nI imagine you would claim that A.4's \"longest match\" rule implies that when \nthe lexer sees 'div3', it should prefer the 4-character NCName over the \n3-character Div. But the rule says \"the longest possible token ... that \nwould be valid in the current syntactic context\", and an NCName is not valid \nin the syntactic context established by the IntegerLiteral '10'. (Perhaps,\nrather than \"syntactic context\", you mean \"lexical state\".)\n\n-Michael Dyck\n\n\n\n", "id": "lists-017-16027756"}, {"subject": "RE: XQuery whitespac", "content": "> XQuery 1.0: An XML Query Language\n> W3C Working Draft 30 April 2002\n> \n> Are these queries valid?\n>      10div 3\n>      10 div3\n>      10div3\n\nYes, no, no\n\n> \n> Re the space between '10' and 'div':\n> I can't find anything that would require it.\n\nCorrect\n> \n> Re the space between 'div' and '3':\n> I imagine you would claim that A.4's \"longest match\" rule \n> implies that when \n> the lexer sees 'div3', it should prefer the 4-character \n> NCName over the \n> 3-character Div. But the rule says \"the longest possible \n> token ... that \n> would be valid in the current syntactic context\", and an \n> NCName is not valid \n> in the syntactic context established by the IntegerLiteral \n> '10'. (Perhaps, rather than \"syntactic context\", you mean \n> \"lexical state\".)\n\nI think this rule is wrong, and have commented to that effect. I'm expecting\nit to change in the next draft. The boundaries between tokens should be\ncontext-independent, it's only the classification of tokens that should\ndepend on the lexical state.\n\n(A personal view)\n\nMichael Kay\n\n\n\n", "id": "lists-017-16035007"}, {"subject": "RE: Comments on April XQuery drafts (long, sorry", "content": "Thanks for this contribution, Tim. It echoes what a number of people are\nsaying inside the WG. I hope we'll give it the attention it deserves.\n\nIt's not going to be easy to cut back: when 20% of a group really want a\nfeature and the other 80% of the group consider it superfluous but harmless,\nthe tendency is to put it in (the gHorribleKludge syndrome). And the large\nnumber of documents, I think, is a consequence of the large number of\ncreative and talented individuals who want to contribute to this effort:\nit's hard to do anything about the root cause of this particular problem!\n\nThe only part of your comments where I tend to disagree with you is TB 7.\nWherever there is something in XML that can't be retained through an XSLT\ntransformation (DOCTYPE, CDATA sections, entity references), we get user\ncomplaints. If we left out more (comments, PIs) we would get more\ncomplaints. I don't think it would be right for XQuery to choose a smaller\nsubset of XML to include in its data model than the subset supported by\nXSLT, XPath, and the InfoSet. In fact, I thought the whole aim of the\nInfoSet concept was that we should all support the same definition as to\nwhich constructs in an XML document are information-bearing and which are\nnot.\n\nMichael Kay \n(personal response)\n\n> -----Original Message-----\n> From: Tim Bray [mailto:tbray@textuality.com] \n> Sent: 10 July 2002 23:09\n> To: public-qt-comments@w3.org\n> Subject: Comments on April XQuery drafts (long, sorry)\n> \n> \n> \n> \n> \n> \n> This is a set of comments on the suite of XQuery-related \n> Working Drafts. It is based on perusal of the drafts dated \n> April 30, 2002 (Formal Semantics is March 26, Requirements of \n> Feb 15 2001).  I paid particular attention to the XML Query \n> and Use-Cases specifications. I've given my comments numbers \n> in case somebody wants to call any of them out.\n> \n> I apologize in advance for using the contraction \"XQuery\" \n> throughout. Also I use \"XSD\" to denote W3C XML Schemas.\n> \n> TB 1. Maximalism\n> \n> The family of XML Query specification makes no visible effort \n> to hit an 80/20 point.  It is trying very hard to stake out \n> COMPLETE solution in the XML query space, which is rather \n> courageous given the profound lack of industry experience.\n> \n> The immense amount of work that has gone into this \n> specification would have a much higher chance of a positive \n> impact on the world if the features and functions provided in \n> XQuery were reduced by a huge factor, cutting back at least \n> to XPath 1.0's level of semantic richness.\n> \n> Furthermore, this specification's size and complexity make it \n> inevitable that its arrival will be delayed by amounts of \n> time that seem unreasonable to those on the outside looking \n> in.  This will cause problems because vendors who need this \n> functionality will release software based on unstable drafts, \n> creating a combination of conversion and interoperability \n> problems down the road.\n> \n> The size and complexity also ensure that when XQuery 1.0 \n> finally arrives, it will be well-populated with bugs, some of \n> which will be highly injurious to interoperability.\n> \n> Furthermore, the immense size of the XQuery language as \n> specified here will make implementations difficult and \n> time-consuming.  This will lead to consideration of \n> conformance levels.  Industry experience with leveled \n> conformance, specifically in the case of SQL, has been very \n> bad; leveled conformance leads inevitably to interoperability \n> problems.\n> \n> A core mandate of the W3C is to deliver specifications that \n> promote interoperability.  The extreme size and complexity of \n> the current XQuery drafts clearly are harmful to \n> interoperability, for the reasons detailed above.  Radical \n> surgery should be applied to the XQuery feature set. This \n> will lead to a higher-quality, more  widely-deployed result \n> with a substantially smaller investment of work.\n> \n> TB 2. Spec Suite organization\n> \n> There needs to be an overview somewhere, a starting point, \n> mostly tutorial in nature, that explains the relationships \n> between XQuery, the data model, the use cases, the functions \n> and operators, and XPath 2. Having read all of them at least \n> in part, I remain fairly puzzled as to how they're supposed \n> to fit together.\n> \n> TB 3. Function of the \"Data Model\" and \"Formal Semantics\"\n> \n> It is not clear that both the Data Model and Formal Semantics \n> specs need to exist, or that they need to have independent \n> lives outside of the XQuery spec.  In particular, I'm pretty \n> sure that a conformant XQuery implementation could be built \n> with little or no reference to anything but the XQuery and \n> F&O specs, raising questions as to whether all the work on DM \n> and FS are cost-effective.\n> \n> The Data Model and Formal Semantics docs are sufficiently \n> complex and hard to understand that they don't seem to serve \n> any tutorial purpose. At the very least, the spec suite needs \n> to be very clear as to whether implementors need to read them \n> (in whole or in part), and if so why.\n> \n> TB 4. Overlapping material\n> \n> There is a large amount of overlapping material in XQuery, \n> the Data Model, the Formal Semantics, and XPath 2.  This has \n> the negative effect that it's really hard to read both XQuery \n> and XPath and pay attention, because the attention wanders as \n> you realize you've already read this 15-page sequence.  It \n> would be highly desirable if the material that is\n> *not* common could be called out somehow.\n> \n> I as an implementor would be very interested in which bits of \n> machinery are XQuery-only, XPath-only, or shared.\n> \n> Since the portions that are shared are sensibly generated \n> from a common source, I assume that such a call-out is achievablle.\n> \n> I note considerable overlap also in the FS and DM specs with \n> each other and with XQuery.  The same comment applies.\n> \n> TB 5. Use Cases for Type-based operations\n> \n> XQuery defines built-in primitives which operate in terms of \n> data types: \"cast\", \"treat\", \"assert\", and \"validate\".  The \n> volume of design that has gone into building this framework \n> is highly out of proportion to the scenarios presented in the \n> Use Cases document.\n> \n> In particular, there are no use cases for the \"cast\", \n> \"assert\", or \"validate\" built-ins.  Almost every other aspect \n> of XQuery has a far richer backing in the use-case document. \n> It is difficult to understand how the design of such a \n> framework can proceed intelligently without use-cases in mind.\n> \n> The best solution to this problem would be simply to drop \n> most of these type-based operations in the interests of \n> getting a reasonably interoperable XQuery 1.0 done in a \n> reasonable amount of time.\n> \n> TB 6. XML Schema Data Types and Duration\n> \n> The reliance on XML Schema basic types seems \n> well-thought-through, although the comprehensibility and ease \n> of implementation of XQuery would be greatly increased by \n> dropping support for some number of XSD basic types, without, \n> it seems, much serious loss of functionality.\n> \n> The use of two types derived from XSD's \"Duration\" type is \n> obviously necessary, but highlights a co-ordination problem.  \n> Anybody who wants to do computation with duration-typed data \n> is pretty clearly going to want the XQuery version, not the \n> XSD version.  Since it seems that many different activities \n> want to use XSD basic data types, it is highly unsatisfactory \n> that they are going to have to call out to two \n> specifications, XSD and XQuery.  As a co-ordination issue, \n> XML Schema should be required to fix this design defect.\n> \n> TB 7. PIs and Comments\n> \n> If I read XQuery 2.1.3.2 and 2.3.1.2 correctly, XQuery \n> includes the capability of searching on the presence of \n> comments and on PIs and their targets.\n> \n> PI search capability is guaranteed to provoke controversy \n> since there is a body of opinion that PIs are architecturally \n> second-class citizens and\n> anything that promotes their use should be deprecated.   This \n> should be\n> seriously considered for removal.\n> \n> XQuery access to comments seems simply incorrect given that \n> there is no assurance that they will be present in the data \n> model even if they are in the source document, and also \n> because it is highly architecturally unsound to encourage the \n> use of comments for holding information of lasting interest.  \n> This should be removed without further ado.\n> \n> The inclusion of Comment and PI in XQuery is further evidence \n> of lack of attention to 80/20 thinking and cost/benefit trade-offs.\n> \n> For similar reasons, all of section 2.8.4 (constructors for \n> CDATA sections, PIs, and comments) should be considered for removal.\n> \n> TB 8. Relation to Schema Languages\n> \n> At the moment, by conscious design choice traceable back to \n> the requirements documents, XQuery is quite strongly linked \n> to W3C XML Schemas in several ways.\n> \n> In retrospect, this choice was unfortunate.  Fortunately, the \n> situation can be rectified at moderate cost and with \n> considerable benefit.\n> \n> Reasons why the linkage to XML Schema is problematic:\n> \n> - XML Schema is large, complex, and buggy.  The linkage \n> greatly increases the difficulty of understanding and \n> implementing XQuery.\n> \n> - XML Schema is poorly suited to the needs of certain \n> application classes (in particular publishing applications), \n> and there are other schema alternatives available which are \n> much better suited.  These application classes are also \n> likely to be heavy potential users of XQuery.\n> \n> - XML Schema is a radical step forward in declarative \n> constraint technology, full of design choices that are based \n> on speculation rather than experience.  It is highly unlikely \n> that XSD will be the last word in schema technology for XML, \n> even in those application areas in which it specializes.  In \n> particular, ISO has a serious effort underway to create \n> standards which describe multiple XML schema languages; it \n> would be disadvantageous if the use of these were \n> incompatible with XQuery. Decoupling XQuery from XSD will \n> increase survivability in the face of inevitable (and \n> desirable) evolution in schema languages.\n> \n> - Every cross-specification dependency introduces potential \n> versioning problems that will increase the complexity and \n> difficulty of maintaining the specification suite as time \n> goes on.  To the extent that such dependencies can be \n> reduced, the W3C and the community win.\n> \n> Note that in the rather old XQuery requirements doc, section \n> 3.5.5, it says that \"Schema\" can mean either XML Schema or \n> DTD.  This is an admirably open viewpoint, and note that \n> since that time, the schema universe has grown.\n> \n> There is one dependency from XQuery on XSD which should not \n> be severed, the dependency on atomic data types.  XQuery \n> clearly needs such a repertory of types, and those provided \n> by XSchema are adequate.\n> \n> The remainder of this note discusses the ways in which XQuery \n> is currently linked to XSD and how they might be dealt with.\n> \n> Linkage: The XQuery data model is described (in part) using \n> terms defined in XML Schema, and a specific procedure is \n> given for constructing it using the XSD PSVI as input.\n> \n> Resolution: This is not a problem; the Data Model is \n> described in enough detail that it could be generated (as the \n> draft notes) by a relational database or a variety of other \n> software modules, and understanding of XSD (aside from the \n> base data types) is not required to understand the data \n> model.  The construction procedure is not really normative in \n> terms of the operation of XQuery.  No change seems required.\n> \n> Linkage: XQuery (sect. 3.1) provides for Schema Imports, to \n> establish the in-scope schema environment.  It is assumed \n> that these are W3C XML Schemas.\n> \n> Resolution: Add a clause to production [80] to identify the \n> schema facility in use, by namespace name or or mime-type, \n> for example:\n> \n>     schema \"http://www.w3.org/1999/xhtml\"\n>       of namespace \"http://www.w3.org/2001/XMLSchema\"\n>       at \"http:/www.w3.org/1999/xhtml/xhtml.xsd\"\n> \n> Linkage: XQuery provides type-based querying, where the types \n> are those identified by QNames in the data model.  Examples \n> from XQuery 2.1.3.2:\n> \n>     element person of type Employee\n>     attribute color of type xs:integer\n> \n> Resolution 1: The semantics of matching the type identified \n> by the qname depend on the in-scope schema class as \n> identified above.  XSD matches the type if it's identical to \n> or is a derivation of the named type; other schema languages \n> might have a more flexible notion of type matching.\n> \n> Resolution 2: Adjust XQuery to say that the \"of type\" clause \n> is satisfied if and only if the type given in the query is \n> identical to that found in the data model, requiring only \n> direct qname comparison and bypassing schema semantics.\n> \n> Resolution 3: Drop type-based querying in the interests of \n> the speedier delivery of a higher-quality recommendation.\n> \n> Linkage: XQuery provides run-time type processing through the \n> \"treat\", \"assert\", and \"cast\" built-ins.\n> \n> Resolution 1: The semantics of these functions depend on the \n> class of the in-scope schema as identified above.\n> \n> Resolution 2: Drop these primitives from XQuery 1.0 - they \n> have weak support in the use cases anyhow.\n> \n> Linkage: XQuery provides run-time validation and \n> type-checking through the \"validate\" built-in.\n> \n> Resolution 1: The semantics of this function depend on the \n> class of the in-scope schema as identified above.\n> \n> Resolution 2: Drop this primitive from XQuery 1.0 - it has \n> weak support in the use cases anyhow.\n> \n> Best regards, Tim Bray\n> \n> \n\n\n\n", "id": "lists-017-16043044"}, {"subject": "RE: Comments on April XQuery drafts (long,  sorry", "content": "From: \"Kay, Michael\" <Michael.Kay@softwareag.com>\n\n> Thanks for this contribution, Tim. It echoes what a number of people are\n> saying inside the WG. I hope we'll give it the attention it deserves.\n\n> It's not going to be easy to cut back: when 20% of a group really want a\n> feature and the other 80% of the group consider it superfluous but harmless,\n> the tendency is to put it in (the gHorribleKludge syndrome). \n\nJust speaking generally, without any comment on the particular situation in the WG,\nI think we should be careful not to think that featuritus comes just from committee-\ncompromises or personalities, which cannot be helped.  (Nor from Stockholm Syndrome :-)   \n\nIt is very important that a WG should not be too bound by the decisions it makes\nearlier in its life.  For example, a WG had rules that it required a simple\nmajority to vote something in but an absolute majority to vote something out,\nas I believe Robert's rules suggest for committees where the members have\nan economic stake in the outcome. This rule seems good, because it prevents\nsudden and repeated changes in tack, thus wasting developer time.\n\nBut its effect can be harmful for standards-making.  The drafts are prototypes,\nand sometimes prototypes, even very advanced ones, reach a stage where \nit become clear that the pig needs a sharper stick to finish it off.\n\nSo committee rules themselves can promote that a Working Group finds it\neasier to enhance, refine and restate, rather than remove, features. This of course\nmay apply as much to use-cases and requirements as it does to features. \n\nI hope the chairs of WGs will keep their eyes on this issue. It is quite possible\nfor supposedly equitable committee rules (such as the one above, being applied in an\ninappropriate circumstance) to prevent \"echoes\" from being heard.\n\nCheers\nRick Jelliffe\n\n\n\n", "id": "lists-017-16066603"}, {"subject": "Re: Comments on April XQuery drafts (long,  sorry", "content": "Kay, Michael wrote:\n\n> It's not going to be easy to cut back: when 20% of a group really want a\n> feature and the other 80% of the group consider it superfluous but harmless,\n> the tendency is to put it in (the gHorribleKludge syndrome). And the large\n> number of documents, I think, is a consequence of the large number of\n> creative and talented individuals who want to contribute to this effort:\n> it's hard to do anything about the root cause of this particular problem!\n\nAs I should have said (but didn't) I was really impressed by the quality \nof the thinking that XQuery evidences and I think it'll end up highly \nuseful.  It's just crystal-clear that it would be better if there were \nless of it.  Yes, it's difficult and strenuous to cut back on features \nbut the rewards are very high in terms of interoperability.\n\nAnd if I may make one point that highly influenced the end-game when we \nwere finishing up XML 1.0 in 1998: if you leave something out, you can \nalways put it in later.  The reverse is not true.\n\n> The only part of your comments where I tend to disagree with you is TB 7.\n> Wherever there is something in XML that can't be retained through an XSLT\n> transformation (DOCTYPE, CDATA sections, entity references), we get user\n> complaints. \n\nI can see this point, and it sounds (mostly) like something on which \nreasonable people may disagree.  With the exception of XQuery on \ncomments, which is nondeterministic, unsafe, and positively encourages \nbad practice.  It has no place whatsoever in XQuery and is highly likely \nto run into trouble in the AC or the XML community.  Also it's totally \nunsound architecturally. -Tim\n\n\n\n", "id": "lists-017-16076031"}, {"subject": "Escaping of URI Reference", "content": "Hi,\n\nThe current XQuery 1.0 and XPath 2.0 Functions and Operators Working\nDraft states, that applying the string() function to an instance of a\nanyURI data type results in a string without any URI encoding applied\nto the anyURI for compatibility reasons. It further notes URI escaping\nshould be under user control. However, there is no function defined for\nURI escaping. While I do not care too much about escaping space\ncharacters, it is a major shortcoming if one is not able to convert a\nanyURI to a URI. Consider you have an XML Schema based XML document like\n\n  ...\n  <link href='http://www.hoehrmann.de/~bj%f6rn/' />\n  ...\n\nThe href attribute in this example is an anyURI. anyURIs allow IRI\nReferences, hence the anyURI is valid. If I now want to transform this\ndocument to XHTML, which uses URIs instead of anyURIs, I can do\nsomething like\n\n  <xsl:template match='link'>\n    <xhtml:a href='{@href}'><xsl:value-of select='@href'/></xhtml:a>\n  </xsl:template>\n\nbut I will get\n\n  <a href='http://www.hoehrmann.de/~bj%f6rn/'\n    >http://www.hoehrmann.de/~bj%f6rn/</a>\n\nThis is invalid XHTML since the '?' is disallowed in URI References. The\ndesired output would be\n\n  <a href='http://www.hoehrmann.de/~bj%C3%B6rn/'\n    >http://www.hoehrmann.de/~bj%f6rn/</a>\n\nBut is is not possible to generate this fragment using the function set\nprovided by the draft. A possible solution is to add a new function\n'xf:anyURI-escape' or 'xf:anyURI-toURI' that converts an anyURI to an\nURI as defined in section 3.2.17 of XML Schema Part 2. However, I do not\nlike this solution, always using this function makes style sheets, XPath\nquerys, XQuerys, etc. rather hard to read, consider\n\n  <xsl:template match='link'>\n    <xhtml:a href='{xf:anyURI-to-URI(@href)}'\n     ><xsl:value-of select='xf:anyURI-to-URI(@href)'/></xhtml:a>\n  </xsl:template>\n\nreal ugly compared to the above. XSLT 2.0 could add some convenience\nmethod to perform this conversion implicitly. This could be as easy as\nadding a new attribute to the xsl:output element if it is considered\nthat documents will allow either URIs or anyURIs. However, such function\nis necessary.\n\nregards.\n\n\n\n", "id": "lists-017-16085343"}, {"subject": "Re: Comments on April XQuery drafts (long,  sorry", "content": ">  With the exception of XQuery on \n> comments, which is nondeterministic, unsafe, and positively encourages \n> bad practice.\n\nXpath 1 supports comments (if the parser reports them, all parsers used\nwith xslt 1 do report these as far as can see). It is therefore\nnecessary that Xpath2 does the same. Xquery could of course not do so,\nbut wouldn't this be an unneeded difference between the two languages?\n\nSupporting comments in Xpath1/XSLT1 turns out to be very useful.\nA very common use case is to make \"identity transformations\" with minor\nadjustments, perhaps updating from one version of a dtd to the next.\n\nDocuments often contain comments for good reason and there is no reason\nwhy these transforms should drop the comments.\n\nDavid\n(Not a member of the WG but signed up to this list)\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-16094919"}, {"subject": "%-escape -&gt; percentencod", "content": "In order to align with RFC 2396bis, I have converted all occurrences\nof %-escape to percent-encode. I have also changed a lot of occurrences\nof 'encoding' to 'character encoding' for clarity.\n\nI have not listed this as an issue.\n\nRegards,     Martin. \n\n\n\n", "id": "lists-017-1610245"}, {"subject": "RE: Escaping of URI Reference", "content": "XSLT 1.0 does URI escaping (\"of non-ASCII characters\") as part of the HTML\nserialization method, when attributes known to be URIs are output. This has\nsome recognized limitations, for example browsers can be unhappy if the\nfragment part of the URI reference is escaped. In XSLT 2.0 we are planning\nto provide an option to switch off this automatic escaping and to give the\nuser control on a more selective basis using a function.\n\nWe have drafted and discussed such an escape-URI() function and unless there\nare any last-minute hitches I hope it will appear in the next draft.\n\nMichael Kay\n\n> -----Original Message-----\n> From: Bjoern Hoehrmann [mailto:derhoermi@gmx.net] \n> Sent: 11 July 2002 20:02\n> To: public-qt-comments@w3.org\n> Subject: Escaping of URI References\n> \n> \n> \n> \n> \n> \n> Hi,\n> \n> The current XQuery 1.0 and XPath 2.0 Functions and Operators \n> Working Draft states, that applying the string() function to \n> an instance of a anyURI data type results in a string without \n> any URI encoding applied to the anyURI for compatibility \n> reasons. It further notes URI escaping should be under user \n> control. However, there is no function defined for URI \n> escaping. While I do not care too much about escaping space \n> characters, it is a major shortcoming if one is not able to \n> convert a anyURI to a URI. Consider you have an XML Schema \n> based XML document like\n> \n>   ...\n>   <link href='http://www.hoehrmann.de/~bj%f6rn/' />\n>   ...\n> \n> The href attribute in this example is an anyURI. anyURIs \n> allow IRI References, hence the anyURI is valid. If I now \n> want to transform this document to XHTML, which uses URIs \n> instead of anyURIs, I can do something like\n> \n>   <xsl:template match='link'>\n>     <xhtml:a href='{@href}'><xsl:value-of select='@href'/></xhtml:a>\n>   </xsl:template>\n> \n> but I will get\n> \n>   <a href='http://www.hoehrmann.de/~bj%f6rn/'\n>     >http://www.hoehrmann.de/~bj%f6rn/</a>\n> \n> This is invalid XHTML since the '?' is disallowed in URI \n> References. The desired output would be\n> \n>   <a href='http://www.hoehrmann.de/~bj%C3%B6rn/'\n>     >http://www.hoehrmann.de/~bj%f6rn/</a>\n> \n> But is is not possible to generate this fragment using the \n> function set provided by the draft. A possible solution is to \n> add a new function 'xf:anyURI-escape' or 'xf:anyURI-toURI' \n> that converts an anyURI to an URI as defined in section \n> 3.2.17 of XML Schema Part 2. However, I do not like this \n> solution, always using this function makes style sheets, \n> XPath querys, XQuerys, etc. rather hard to read, consider\n> \n>   <xsl:template match='link'>\n>     <xhtml:a href='{xf:anyURI-to-URI(@href)}'\n>      ><xsl:value-of select='xf:anyURI-to-URI(@href)'/></xhtml:a>\n>   </xsl:template>\n> \n> real ugly compared to the above. XSLT 2.0 could add some \n> convenience method to perform this conversion implicitly. \n> This could be as easy as adding a new attribute to the \n> xsl:output element if it is considered that documents will \n> allow either URIs or anyURIs. However, such function is necessary.\n> \n> regards.\n> \n> \n\n\n\n", "id": "lists-017-16103069"}, {"subject": "Type as a sequence of QName", "content": "Hi,\n\nYou've probably already thought of this, but thinking about the\npossibility of using RELAX NG to provide type information during the\nconstruction of a node tree, I was wondering if the data model could\nbe made more schema-language neutral by having the 'type' of a node be\na sequence of QNames instead.\n\nFor node trees derived from the PSVI from XML Schema validation, the\nsequence could contain the type of the node, its base type and so on\nup to and including xs:anyType/xs:anySimpleType.\n\nFor node trees generated during RELAX NG validation, the sequence\ncould contain the names of the define elements used while validating\nthe content of the node.\n\nEven languages like Schematron could be used -- each rule could have\nan 'type' annotation and the node be assigned a type based on these\nannotations.\n\nThen type matching in sequence type matching could test whether the\nnamed type was listed within the type of the node without having to\nworry about (or depend on) type hierarchies being present.\n\nIn parallel, I suppose that the name of an element could be a sequence\nalso containing the name of the head elements of any substitution\ngroups that it belongs to; the name() function could still just return\nthe first (actual) name of the element, but the sequence could be used\nwhen doing sequence type matching.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16114438"}, {"subject": "RE: Type as a sequence of QName", "content": "> You've probably already thought of this, but thinking about \n> the possibility of using RELAX NG to provide type information \n> during the construction of a node tree, I was wondering if \n> the data model could be made more schema-language neutral by \n> having the 'type' of a node be a sequence of QNames instead.\n\nThis kind of thing has been suggested and rejected in the past, and the idea\nis currently being explored once again to see whether it solves any of the\nproblems with anonymous types. I've no idea what the outcome will be: but\nthanks for the contribution.\n\nMichael Kay\n\n\n\n", "id": "lists-017-16122775"}, {"subject": "RE: Type as a sequence of QName", "content": "As far as I know, RELAX-NG is a Schema language that does validation but\ndoes not provide type information.  There is, for example, nothing like\nthe PSVI.  Of course, it could be made to provide type info but that's a\nlot of work and what is the motivation for doing this work?  \n\nAll the best, Ashok \n-----Original Message-----\nFrom: Kay, Michael [mailto:Michael.Kay@softwareag.com] \nSent: Monday, July 15, 2002 5:00 AM\nTo: Jeni Tennison; public-qt-comments@w3.org\nSubject: RE: Type as a sequence of QNames\n\n\n> You've probably already thought of this, but thinking about \n> the possibility of using RELAX NG to provide type information \n> during the construction of a node tree, I was wondering if \n> the data model could be made more schema-language neutral by \n> having the 'type' of a node be a sequence of QNames instead.\n\nThis kind of thing has been suggested and rejected in the past, and the\nidea\nis currently being explored once again to see whether it solves any of\nthe\nproblems with anonymous types. I've no idea what the outcome will be:\nbut\nthanks for the contribution.\n\nMichael Kay\n\n\n\n", "id": "lists-017-16130706"}, {"subject": "Re: Type as a sequence of QName", "content": "Hi Ashok,\n\n> As far as I know, RELAX-NG is a Schema language that does validation\n> but does not provide type information. There is, for example,\n> nothing like the PSVI. Of course, it could be made to provide type\n> info but that's a lot of work and what is the motivation for doing\n> this work?\n\nThe reason any schema language provides type information is that it\ncan be used in downstream processing of the XML document. Currently,\nthere's no standard way of using that information at all; XPath 2.0\nprovides one. So the motivation for creating RELAX NG validators that\nmake available type information would be the ability for people using\nXPath 2.0 to use it.\n\nIt's certainly true that it is a lot of hard work to enable RELAX NG\nvalidators to create the data model currently required for XPath 2.0.\nThat's why I wondered whether a slightly different XPath 2.0 data\nmodel would make that easier/possible and therefore XPath 2.0 less\nschema-language specific.\n\nCheers,\n\nJeni\n\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16140657"}, {"subject": "XSLT 2.0 grouping into several group", "content": "Hi,\n\nA question on XSL-List today asked about grouping single elements into\nmultiple groups. The example was roughly:\n\n<?xml version=\"1.0\"?>\n<data>\n<story>\n  <story_id>589608</story_id>\n  <story_title>It's Only Human Nature</story_title>\n  <program_name>Science Show</program_name>\n  <transmission_date>20020629</transmission_date>\n  <description>What is human nature? Who really knows?</description>\n  <subjects>\n    <subject>Psychology</subject>\n    <subject>Health</subject>\n  </subjects>\n</story>\n<story>\n  <story_id>591325</story_id>\n  <story_title>Fins responsible for Hyshot crash</story_title>\n  <program_name>Science News</program_name>\n  <transmission_date>20020627</transmission_date>\n  <description>The failure of a set of fins on the launch rocket was likely\nto be the cause of the Hyshot scramjet crash in October 2001, according to\nthe final report of the investigation released last week. The finding\nclears the way for a second launch.</description>\n  <subjects>\n    <subject>Australian</subject>\n    <subject>Space</subject>\n    <subject>Engineering</subject>\n  </subjects>\n</story>\n<story>\n  <story_id>591756</story_id>\n  <story_title>Immunisation gets bad rap on internet</story_title>\n  <program_name>Science News</program_name>\n  <transmission_date>20020627</transmission_date>\n  <description>The internet has an abundance of websites that are negative\ntowards vaccination and tend to rely on unscientific evidence according to\ntwo separate studies published this week.</description>\n  <subjects>\n    <subject>Australian</subject>\n    <subject>Health</subject>\n    <subject>Information Technology</subject>\n  </subjects>\n</story>\n</data>\n\nwith the output grouping the stories into groups based on the subject.\nI don't think that there's an example of this sort in the grouping\nrequirements in http://www.w3.org/TR/xslt20req and there probably\nshould be (it doesn't come up a huge amount, but it does on occasion\nand it's something that tends to catch people out).\n\nThe questioner was having problems because the way people think about\nthis kind of grouping (grouping stories by subject) isn't the way you\nhave to do the grouping. In XSLT 2.0, people's first guess (by\nextension from grouping by single values) would be:\n\n  <xsl:for-each-group select=\"story\" group-by=\"subjects/subject\">\n    ...\n    <xsl:for-each select=\"current-group()\">\n      ...\n    </xsl:for-each>\n    ...\n  </xsl:for-each-group>\n\nBut as you know, the way xsl:for-each-group works, each story has to\nbelong to a single group, so you actually have to do:\n\n  <xsl:for-each-group select=\"story/subjects/subject\" group-by=\".\">\n    ...\n    <xsl:for-each select=\"current-group()/ancestor::story\">\n      ...\n    </xsl:for-each>\n    ...\n  </xsl:for-each-group>\n\nI wonder if the definition of xsl:for-each-group could be changed so\nthat the natural/intuitive method would actually work. Perhaps, if the\ngrouping key is a sequence, the item could be added to each group\ncorresponding to a value in that sequence. I think that then, to get\nhold of the particular grouping key value that was being used for a\nparticular group, there would have to be another function such as\ncurrent-group-value(). In other words, you would do:\n\n  <xsl:for-each-group select=\"story\" group-by=\"subjects/subject\">\n    Subject: <xsl:value-of select=\"current-group-value()\" />\n    <xsl:for-each select=\"current-group()\">\n      Title: <xsl:value-of select=\"story_title\" />\n    </xsl:for-each>\n  </xsl:for-each-group>\n\nThe same kind of change doesn't make sense for group-adjacent or\ngroup-starting/ending-with, of course.\n\nIf a change like this isn't made, it might be an idea to include an\nexample along these lines in the spec, so that people can see how to\ndeal with it.\n  \nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16149080"}, {"subject": "xpath ", "content": "The only example of distinct-values appears to be targetted at \nthe query users.\nIsn't it about time that the two uses were seperated?\nCommon functions,\nthen two WD's, one for XSLT+XPATH, one for the query users?\n\n\n\n\nfor $a in distinct-values(//author)\nreturn ($a,\n        for $b in //book[$b/author = $a]\n        return $b/title)\n\n\nAs a minimum, please provide examples for *both* user groups,\nunless the query group have totally taken over the WD?\n\nregards \nDaveP\nAC RNIB.\n\n\n\n************snip here************** \n\n- \n\nNOTICE: The information contained in this email and any attachments is \nconfidential and may be legally privileged. If you are not the \nintended recipient you are hereby notified that you must not use, \ndisclose, distribute, copy, print or rely on this email's content. If \nyou are not the intended recipient, please notify the sender \nimmediately and then delete the email and any attachments from your \nsystem.\n\nRNIB has made strenuous efforts to ensure that emails and any \nattachments generated by its staff are free from viruses. However, it \ncannot accept any responsibility for any viruses which are \ntransmitted. We therefore recommend you scan all attachments.\n\nPlease note that the statements and views expressed in this email \nand any attachments are those of the author and do not necessarily \nrepresent those of RNIB.\n\nRNIB Registered Charity Number: 226227\n\nWebsite: http://www.rnib.org.uk \n\n\n\n", "id": "lists-017-16159857"}, {"subject": "2 week mailing list last cal", "content": "With no open issues and only two tentatively closed ones remaining,\nI just submitted draft-duerst-iri-07.txt to the Internet-Drafts\nEditor. It is also available at\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri-07.txt.\n\nIf you find any new issues think that an old one needs to be reopened,\nplease say so on this mailing list (public-iri@w3.org) within the next\ntwo weeks (up to and including Sunday, May 23).\nIf no significant changes are required, I will send this spec\nto the IESG afterwards.\n\nIn other words, this is a two-week mailing list last call.\n\nRegards,    Martin. \n\n\n\n", "id": "lists-017-1616712"}, {"subject": "RE: [saxon] Strange things: xsl:sort with lang attribut", "content": "[\n  Question on the Saxon list regarding the context of the AVT in\n  <xsl:for-each select=\"foo\">\n    <xsl:sort lang=\"{...}\" />\n]\n\n> > BTW, which node is the context node in this expression? Is it \n> > foo or foo's parent or maybe something completely different?\n> \n> This isn't clearly stated in the XSLT 1.0 spec. But the only logical\n> node to use as the context node (and the one that Saxon uses) is the\n> same one that is used for evaluating the select expression in the\n> <xsl:for-each>.\n\nThen please add something in the XSLT 2.0 spec. I couldn't find\nsomething at first go.\n\nTo my mind it is a little bit odd that in\n<xsl:sort select=\"expr1\" lang=\"{expr2}\" />\nexpr1 and expr2 refer to different context nodes.\n\nCheers,\nOliver\n\n\n/-------------------------------------------------------------------\\\n|  ob|do        Dipl.Inf. Oliver Becker                             |\n|  --+--        E-Mail: obecker@informatik.hu-berlin.de             |\n|  op|qo        WWW:    http://www.informatik.hu-berlin.de/~obecker |\n\\-------------------------------------------------------------------/\n\n\n\n", "id": "lists-017-16168105"}, {"subject": "RE: [saxon] Strange things: xsl:sort with lang attribut", "content": "> \n> > > BTW, which node is the context node in this expression? Is it foo \n> > > or foo's parent or maybe something completely different?\n> > \n> > This isn't clearly stated in the XSLT 1.0 spec. But the\n> only logical\n> > node to use as the context node (and the one that Saxon\n> uses) is the\n> > same one that is used for evaluating the select expression in the\n> > <xsl:for-each>.\n> \n> Then please add something in the XSLT 2.0 spec. I couldn't\n> find something at first go.\n\nIt's spelled out in 12.2 (April draft): <quote>Those attributes of the\nxsl:sort elements whose values are attribute value templates are evaluated\nusing the outer focus. If the element that contains the xsl:sort elements is\nan xsl:sort-key declaration, then the outer focus is a singleton focus based\non the document node of the principal source document. Otherwise, the outer\nfocus is the focus used to evaluate the select attribute of the containing\ninstruction (for example, xsl:for-each or xsl:apply-templates).</quote>\n\n> \n> To my mind it is a little bit odd that in\n> <xsl:sort select=\"expr1\" lang=\"{expr2}\" />\n> expr1 and expr2 refer to different context nodes.\n\nIt is indeed a bit odd, but logical given that these attributes are\nparameters to the sort operation as a whole, not things that can vary for\neach sort key.\n\nI will add this to my list as a candidate 1.0 erratum, though I'm not sure\nif and when we'll get round to publishing further errata.\n\nMichael Kay\n\n\n\n", "id": "lists-017-16177643"}, {"subject": "XSLT 2.0 Namespac", "content": "How come the XSLT namespace[0] is not being changed in version 2.0 from that used in version 1.0? Isn't this in conflict with the W3C's policy on namespace names[1]?\n \nMy question is exactly how one is supposed to differentiate between the W3C XML Schema for XSLT 1.0 and XSLT 2.0 if they use the same namespace and W3C XML Schema doesn't provide a way to specify alternative content models based on an attribute's value? \n \n[0] http://www.w3.org/TR/2002/WD-xslt20-20020430/#xslt-namespace\n[1] http://www.w3.org/1999/10/nsuri <http://www.w3.org/1999/10/nsuri> \n\n\n\n", "id": "lists-017-16187371"}, {"subject": "Re: XSLT 2.0 Namespac", "content": "Hi Dare,\n\n> My question is exactly how one is supposed to differentiate between\n> the W3C XML Schema for XSLT 1.0 and XSLT 2.0 if they use the same\n> namespace and W3C XML Schema doesn't provide a way to specify\n> alternative content models based on an attribute's value?\n \nAs you've probably read, XSLT 2.0 has some pretty complex rules\ngoverning forwards [1] and backwards [2] compatibility. (XSLT 1.0 only\nneeded to worry about forwards compatibility since there was nothing\nto be backwards compatible with.[3])\n\nXML Schema will have a hard time articulating these rules, it's true.\nBut then, XML Schema simply doesn't deal well with the kind of markup\nlanguage that XSLT is -- one in which elements from different\nnamespaces mix semi-freely, many of the attributes contain values that\nare impossible to validate using regular expressions, and in which the\npresence of an attribute can change the legal content of an element.\n\nSo, frankly, I doubt that an XML Schema for XSLT would serve much\npurpose given XSLTs design in areas quite aside from version control,\nand I think that redesigning XSLT in such a way that XML Schema is a\nuseful schema language for it is doomed to failure. I don't think that\nyou'll win the argument about using namespaces to indicate versions\nusing the fact that XML Schema finds it easier to represent these\nkinds of languages.\n\nInstead, let's consider what's important for versioning in XSLT. XSLT\nis a language that is likely to exist in several versions at once,\nfirstly because it has a wide user base which won't \"upgrade\" all at\nonce (or at all in some cases), and secondly because it's a language\nthat's used in distributed applications -- you might write a\nstylesheet there that I run here, on my particular setup with my\nparticular processor; I don't have control over what version you use\nand you don't have control over what version my processor supports. So\nwe're going to get:\n\n  - both version 1.0 and version 2.0 stylesheets floating around\n  - processors that support both 1.0 and 2.0 at the same time\n  - stylesheets that intermix 1.0 and 2.0 constructs (particularly to\n    gain backwards compatibility so that they can be used with older\n    processors/browsers)\n\nNow consider the implementers who have to add on XSLT 2.0 support to\ntheir XSLT 1.0 processors. The vast majority of the instructions in\nXSLT 2.0 are exactly the same as they were in XSLT 1.0. Under your\nproposal, they would be regarded as completely different elements\n(XSLT processors are *very* namespace aware -- they have to be) so\nimplementers would have to copy the code for dealing with the XSLT 1.0\nversion for the XSLT 2.0 version.\n\nAlso consider people who write stylesheets that interpret XSLT --\nsomething that happens fairly frequently. If I wanted to list all the\nnames of the global parameters used in a stylesheet, I'd have to use:\n\n  /*/(xsl1:param | xsl2:param)/@name\n\nand I'd have to expand this XPath even further if the namespace\nchanged again for XSLT 3.0. These kinds of paths are often used by\npeople manipulating the DOM of the stylesheet prior to transformation\nin client-side scripts using MSXML; for example to change the way in\nwhich something is sorted, you might have to use an XPath expression\nlike:\n\n  /*/(xsl1:template | xsl2:template)[@name = 'doSort']\n    /(xsl1:for-each | xsl2:for-each)\n    /(xsl1:sort | xsl2:sort)/@select\n\nAnd then consider people who are writing stylesheets that mix XSLT 1.0\nand XSLT 2.0. They would have to declare both namespaces, of course,\nand then have to choose whether to use the XSLT 1.0 or XSLT 2.0\nconstruct at each point. For example, when defining a template,\npresumably I should use the XSLT 1.0 namespace because I need XSLT 1.0\nprocessors to be able to understand it, but what if I want to use the\nXSLT 2.0 feature of specifying the types of the parameters? xsl2:param\nelements won't be recognised as parameter definitions by an XSLT 1.0\nprocessor, but a type attribute on a xsl1:param element wouldn't be\nused by an XSLT 2.0 processor. I'd be in an impossible situation.\n\nI think that the key thing here is that there are going to be multiple\nversions of XSLT around, including multiple versions used within the\nsame stylesheet. While versioning-by-namespace might be a reasonable\ncourse for markup languages where that isn't the case, I think that\nit makes versioning-by-namespace untenable for XSLT.\n    \nCheers,\n\nJeni\n\n[1] http://www.w3.org/TR/2002/WD-xslt20-20020430/#forwards\n[2] http://www.w3.org/TR/2002/WD-xslt20-20020430/#backwards\n[3] http://www.w3.org/TR/xslt#forwards\n\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16195517"}, {"subject": "Names beginning with xml..", "content": "This is related to a user example recently posted to xsl-list.\nThe example was demonstrating some other problem but I note it had an\nXPath variable $xml.\n\nIt wasn't clear to me (In XPath 1 or XPath 2 drafts) whether this text\n(from XML 1.0 2e) is supposed to apply to QNames (which are by\ndefinition also Names) used as variable names (and other syntactic\nconstructs such as mode names in XSLT). As stated in XML spec it is not a\nrestriction on element and attribute names but on the use of the Name\nproduction itself (arguably).\n\n  [Definition: A Name is a token beginning with a letter or one of a few\n  punctuation characters, and continuing with letters, digits, hyphens,\n  underscores, colons, or full stops, together known as name characters.]\n  Names beginning with the string \"xml\", or any string which would match\n  (('X'|'x') ('M'|'m') ('L'|'l')), are reserved for standardization in\n  this or future versions of this specification.\n\n\nI don't really mind either way but perhaps this could be made clearer in\n2.0 ?\n\nDavid\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-16207502"}, {"subject": "RE: Names beginning with xml..", "content": "I think I would take the view that the restriction *doesn't* apply to names\ndeclared in XPath and XSLT, but I agree it should be clarified.\n\nThe view seems to be that \"reserved\" means that users should avoid these\nnames but software should accept them, so the practical implications are\npossibly rather academic.\n\nMichael Kay\n\n> -----Original Message-----\n> From: David Carlisle [mailto:davidc@nag.co.uk] \n> Sent: 24 July 2002 12:31\n> To: public-qt-comments@w3.org\n> Subject: Names beginning with xml...\n> \n> \n> \n> \n> \n> \n> \n> This is related to a user example recently posted to \n> xsl-list. The example was demonstrating some other problem \n> but I note it had an XPath variable $xml.\n> \n> It wasn't clear to me (In XPath 1 or XPath 2 drafts) whether \n> this text (from XML 1.0 2e) is supposed to apply to QNames \n> (which are by definition also Names) used as variable names \n> (and other syntactic constructs such as mode names in XSLT). \n> As stated in XML spec it is not a restriction on element and \n> attribute names but on the use of the Name production itself \n> (arguably).\n> \n>   [Definition: A Name is a token beginning with a letter or \n> one of a few\n>   punctuation characters, and continuing with letters, \n> digits, hyphens,\n>   underscores, colons, or full stops, together known as name \n> characters.]\n>   Names beginning with the string \"xml\", or any string which \n> would match\n>   (('X'|'x') ('M'|'m') ('L'|'l')), are reserved for standardization in\n>   this or future versions of this specification.\n> \n> \n> I don't really mind either way but perhaps this could be made \n> clearer in 2.0 ?\n> \n> David\n> \n> _____________________________________________________________________\n> This message has been checked for all known viruses by Star \n> Internet delivered through the MessageLabs Virus Scanning \n> Service. For further information visit \n> http://www.star.net.uk/stats.asp or > alternatively call Star \n> Internet for details on the Virus Scanning Service.\n> \n> \n\n\n\n", "id": "lists-017-16215510"}, {"subject": "RE: xpath ", "content": "> The only example of distinct-values appears to be targetted at\n> the query users.\n\nI'm having difficulty understanding why you think this, Dave. Is it\nbecause the result of the expression (in the XPath book, section 2.8)\nhas been shown with a particular serialization that might be more\nfamiliar to XQuery users?\n\nThe problem of course is that XPath itself has no way of serializing a\nsequence of elements, so the result of this expression can only be\ndescribed by inventing some notation. There might be a case for showing\nexamples of XPath as used in an XSLT context, but we've never done that\nin the past (XPath 1.0 has no references to XSLT).\n\nThe example itself is actually rather artificial: in practice both\nXQuery and XSLT users would construct a tree rather than a sequence\nwith the results, but tree construction is outside the scope of XPath\nwhich is why the example has been done in this way. To be honest, I'm\nnot sure it belongs in this section of the document at all.\n\nMichael Kay\n>\n>\n> for $a in distinct-values(//author)\n> return ($a,\n>         for $b in //book[$b/author = $a]\n>         return $b/title)\n>\n>\n> As a minimum, please provide examples for *both* user groups,\n> unless the query group have totally taken over the WD?\n>\n> regards\n> DaveP\n> AC RNIB.\n>\n>\n>\n> ************snip here**************\n>\n> -\n>\n> NOTICE: The information contained in this email and any\n> attachments is\n> confidential and may be legally privileged. If you are not the\n> intended recipient you are hereby notified that you must not use,\n> disclose, distribute, copy, print or rely on this email's content. If\n> you are not the intended recipient, please notify the sender\n> immediately and then delete the email and any attachments from your\n> system.\n>\n> RNIB has made strenuous efforts to ensure that emails and any\n> attachments generated by its staff are free from viruses. However, it\n> cannot accept any responsibility for any viruses which are\n> transmitted. We therefore recommend you scan all attachments.\n>\n> Please note that the statements and views expressed in this email\n> and any attachments are those of the author and do not necessarily\n> represent those of RNIB.\n>\n> RNIB Registered Charity Number: 226227\n>\n> Website: http://www.rnib.org.uk\n>\n\n\n\n", "id": "lists-017-16225269"}, {"subject": "Re: Migration of HTTP to the use of IRIs [altdesign17", "content": "Hello Chris,\n\nAt 11:05 04/05/09 +0100, Chris Haynes wrote:\n\n>Michael,\n\n[Well, Martin that would have been.]\n\n\n>Thanks for your patience.\n>\n>So I think you are saying that the flaw in my logic is when I asserted that\n>there is no syntactic indication of the use of an IRI. Your assertion, in\n>effect, is that the syntactic indication is only present when needed, and is\n>implicit in the use of UTF-8 encoding.\n\nNot exactly. There is no syntactic indication needed for HTTP\nand URIs/IRIs to work the way they are designed.\n\nHTTP may in the future decide to introduce a convention to let the\nclient tell the server about character encodings e.g. in query parameters,\nbut this is idenpendent of the IRI spec. Such a convention may use another\nscheme (which I doubt very much), a special named query parameter\n(much more likely, some browsers can already do this, and some\nsites (e.g. google) use this), or something else.\n\nSuch a solution could take UTF-8 as a special case, or it could\ntreat UTF-8 just as one choice among many. IRIs will definitely\nprovide a push towards UTF-8, but they cannot force anybody to\nuse UTF-8.\n\n\n>Your assertion below is that the vast majority of cases which were not encoded\n>in UTF-8 will generate one or more octet sub-sequences which are not legal\n>representations of characters in UTF-8.\n\nYes. Or they will trivially be ASCII-only, in which case\nthe question of encoding is mostly irrelevant.\n\n\n>I should use the presence of such\n>sequences to conclude that the URI was not encoded in UTF-8 and therefore that\n>conversion to an IRI  is not applicable.\n>\n>My first thought was to try applying the processing you define in (draft \n>7) sect\n>3.2, to see if that would provide a 'failure indication' that I could use.\n>\n>But I came to your Step 3:\n>\n>\"Re-escape any octet produced in step 2 that is not part of a strictly legal\n>UTF-8 sequence\".\n>\n>\n>This step re-absorbs octet sequences which are illegal in UTF-8 into the IRI\n>world, so, applying section 3.2 in its entirety _cannot_ be used as the \n>basis of\n>a decision on whether or not UTF-8 encoding was used in the original escaping.\n\nYes. Section 3.2 isn't something that returns a boolean, it returns\nan IRI. And it tries to convert as many escapes as possible into\nactual characters. If that's not what you need, don't use Section 3.2.\n\n\n>Section 3.2 can only be applied if it is desired to _force_ everything that is\n>received into an IRI.\n>\n>Your draft 7  does not provide the basis for deciding whether or not the URI\n>should be treated in this way. i.e. it does not give any opportunity for\n>concluding that the presented URI was encoded using some other (legacy)\n>encoding.\n\nYes. There may be many reasons why somebody may want to use Section 3.2,\nand many other reasons why one wouldn't want to use it, or would not\nwant to use it exactly as described.\n\n\n>You may recall that my concern is for the design of a web server including\n>something like a Servlet handler, which has to decode the URI before it can\n>identify and invoke the referenced servlet (which might know what encoding was\n>used in URIs identifying that Servlet).\n\nIf there is really a cyclic interdependency (i.e. servlet knows encoding,\nbut servlet handler has to know encoding to be able to call servlet),\nthen the only thing you can really do seems to be trial-and-error.\n\nIf there is not really a cyclic interdependency (i.e. servlet knows\nencoding, and could handle it, but you want to do decoding in the\nservlet handler code), then this might just be bad design and\nsoftware engineering.\n\nThis does not mean that the servlet handler couldn't do certain\nthings on behalf of the servlet, but you most probably need a\nmore flexible interaction.\n\n\n>In this 'real world' that I keep worrying about there will be a long \n>transition\n>phase when there will be many inbound URLs which contain escapes generated \n>using\n>other encodings.\n\nYes in general. But this will be very different for different servers.\nI know of cases where UTF-8 is already used throughout since years,\nand I'm sure there are cases where legacy encodings will still be\nused in some years. Thus different servers will have different\nneeds when it comes to analyzing incomming HTTP URIs, in particular\nquery parts.\n\n\n>Forcing them into IRIs is not appropriate behaviour; by some\n>other means the appropriate decoding must be selected and applied.\n\nAgreed. But I don't think the draft ever says you have to do that.\n\nIn more general terms, I'm not sure why you want to convert an\nURI arrived on the server to an IRI. What you want to do is to\ntake the URI appart and work on resolving it.\n\n\n>It seems to me that, in this situation, where URLs containing encodings other\n>than UTF-8 are to be handled differently, rather than be forced into IRIs by\n>your section 3.2,\n\nSection 3.2 in no way forces you to convert URIs to IRIs on the server!\n\n\n>a different sequence is required. Something like:\n>\n>A)  Convert the received URI into an octet sequence as follows: Each %HH \n>triplet\n>generates an octet whose value is defined by the hex digits HH. All other\n>(ASCII) characters generate an octet whose value is that of the code point of\n>that character in the ASCII/UTF-8 code table.\n>\n>B) Attempt to process the octet sequence generated by B as a UTF_8-encoded \n>octet\n>sequence. If the octet sequence is 'legal', i.e. it is the correct \n>encoding of a\n>sequence of integer values (but not necessarily representing valid Unicode \n>code\n>points), then the URI does represent an IRI and the processing of (draft 7\n>sect.32.) should be applied to extract the IRI.\n>\n>C) If, in step B, there should have been found one or more octet sequences \n>which\n>did not form part of any 'legal' UTF_8 sequence, then no IRIs are involved and\n>the interpretation of the presented URI is to be decided by other means.\n\nIn some cases, a procedure like the above may be appropriate for\nimplementing some servlet logic. But please note that what you are\nactually trying to do really has nothing to do with reconstructing\nan IRI from an URI; what you are trying to do is to reconstruct the\noriginal characters that should be handled to the servlet.\n\nLooking at the details, I see the following issues:\n- The decision should probably not be taken for the whole URI, but\n   e.g. on the query part only. There can easily be cases where the\n   query part is in UTF-8, but the path part is not, or the other\n   way round.\n- The procedure isn't really complete if you end with 'is to be\n   decided by other means'. Here several situations may arise,\n   and they may need different solutions. In general, you need\n   to have a way to know the actual encoding. The most general\n   way to do this is to include a hidden form element in the\n   form, with a text that will be encoded differently in the\n   encodings you want to distinguish (e.g. UTF-8, iso-2022-jp,\n   euc-jp, and shift_jis for Japanese).\n\nSo if you are working with content, forms, and an audience where\nyou expect query parts in a variety of encodings, your above\nprocedure won't really cut it.\n\n\n>Note that the application of the procedure A-C above will mean that your \n>step 3\n>will never be applied.\n>\n>\n>So I think we have two possible scenarios:\n>\n>Scenario 1)  The world is to be viewed as containing only IRIs.  _All_ \n>received\n>URIs are converted into IRIs consisting of a sequence of  'appropriate' (your\n>step 4) UTF characters.  Any non-UTF-8 escapes are still present as\n>still-escaped sequences in the IRI; there has been no attempt to interpret \n>these\n>as characters in some other encoding.\n\nIt's much better to think about this per server or Web application.\nThere may be Web applications where only IRIs are expected. If\nnon-UTF-8 escapes are found, then rather than keep these as still-\nescaped sequences, they should produce an appropriate error message\nto the user, e.g. \"You have submitted data to this application\nthat could not be processed correctly, because it was not encoded\ncorrectly by your browser. If you have a very old browser, please\nupgrade. ...\"\n\n\n>Scenario 2)  In a word in which URIs intended to represent IRIs co-exist with\n>URIs encoded using other character encodings, and where the difference has \n>to be\n>detected so that the appropriate decoding can be applied, then my steps \n>A-C must\n>first be undertaken. If my steps A-C indicate that another encoding was used,\n>then the URI is to be handled in some other way, and no IRI is involved. If no\n>evidence of a different encoding is found, then it is to be assumed that\n>conversion to an IRI is valid and your steps 1-5 should be applied (but step 3\n>will never be invoked).\n\nFor servers where this is the case, if there is only one other encoding,\nthen the above might be okay. But if there are potentially multiple\nlegacy encodings, that won't do the job.\n\n\n>My tentative conclusion is this:\n>\n>The IRI draft 7 does not provide any support or advice for those needing to\n>recognize and process (intelligently and efficiently) URIs containing \n>encodings\n>other than UTF-8.\n\nThat is right. The draft is about IRIs, and about URIs resulting from\nconversion from IRIs. It's not implementation advice for implementers\nof servers and Web applications on how to distinguish different legacy\nencodings.\n\n\n>Where this needs to be done, something akin to my steps A-C is necessary, \n>before\n>it can be decided that URI to IRI conversion should be applied.\n>\n>\n>My concerns would be assuaged if there were a Section or Appendix in the IRI\n>Internet-Draft :\n>\n>- Recognizing these transitional / co-existence needs,\n\nI don't think distinguishing legacy encodings is part of what the\nIRI spec should do.\n\n\n>- Detailing the necessary and sufficient URI inspection required to decide\n>whether or not to invoke IRI processing,\n\nWhat may be going on on the server is not a conversion from URIs to IRIs,\nit's an attempt to extract original data from an URI. Because Section\n3.2 looks somewhat similar to what you had in mind to do that job,\nyou got confused.\n\n\n>- Containing the cautions about the remote possibility of incorrect decisions\n>being made.\n\nThere is already such caution. The draft says that detecting UTF-8\nis correct with high probablity; it doesn't say it's always correct.\n\n\n>I'd be prepared to help draft it.\n>\n>Footnote 1:\n>In a 'real' implementation the two processing sequences 1-5 and A-C could be\n>undertaken in a single pass through the URI using a merged algorithm,\n>parameterised to define how it should proceed if a non-UTF_8 octet sequence\n>should be detected (i.e. parameterised to adopt Scenarios 1 or 2). The\n>performance penalty of my proposed addition would be insignificant.\n\nAnybody who finds a more efficient way to do things is always\nwelcome to use that way. Specs usually try to give clear and\nprecise instructions, rather than to be most efficient.\n\n\n>Footnote 2:\n>Your approach of assuming that an IRI interpretation is valid in all \n>situations\n>in which UTF_8 has been used ought also to be validated. People are already\n>using UTF-8 encoding with no knowledge of IRIs.  I've not explored what impact\n>the application of the stage 4+5 processing of your draft (i.e. beyond that of\n>de-escaping and decoding the UTF-8 characters) could have, and whether or \n>not it\n>could cause any problems for pre-IRI users of UTF-8. I don't intent to pursue\n>this line of enquiry ;-)\n\nWell, if somebody has used UTF-8 up to now, others can use IRIs.\nAs an example, I have used http://www.w3.org/People/D%C3%BCrst\nfor years. If somebody inputs it in a browser, on some browsers\n(e.g. Opera) they will actually see a real IRI.\nThe only danger with this kind of IRIs is that they then give\nthat IRI to somebody else, and that person doesn't have a browser\nthat can resolve IRIs yet. But that's not anything that could\nnot happen with something that was created to be used as an\nIRI from the start.\n\n\nRegards,    Martin.\n\n\n\n>Chris\n>\n>\n>----- Original Message -----\n>From: \"Martin Duerst\" <duerst@w3.org>\n>To: \"Chris Haynes\" <chris@harvington.org.uk>; \"Michel Suignard\"\n><michelsu@windows.microsoft.com>\n>Cc: <public-iri@w3.org>\n>Sent: Sunday, May 09, 2004 1:37 AM\n>Subject: Re: Migration of HTTP to the use of IRIs [altdesign-17]\n>\n>\n> > Hello Chris,\n> >\n> > I have changed the issue for this mail to altdesign-17, because it\n> > seems more appropriate.\n> >\n> > At 11:07 04/05/07 +0100, Chris Haynes wrote:\n> >\n> > >Michel,\n> > >\n> > >Thanks for this comment, but I think my point is still valid - even \n> just for\n> > >presentational uses.\n> > >\n> > >Given that many URI encodings exist 'in the wild' which use %HH \n> escaping of\n> > >non-UTF-8 sequences, I fail to see how one can know that it is valid to\n> > >convert\n> > >any such URI into an IRI (as per sect. 3.2) - even if just for \n> presentational\n> > >purposes.\n> >\n> > Section 3.2 very clearly says that there is a risk that you convert\n> > to something that didn't exist previously.\n> > But in practice, this is not that much of an issue, because it is\n> > very rare to find reasonable text encoded in legacy encodings that\n> > matches UTF-8 byte patters. Please try to find some examples yourself,\n> > and you will see this.\n> >\n> >\n> > >My concern is the same:  unless there is some kind of syntactic indicator\n> > >within\n> > >the URI as a whole, how can one reliably know that UTF-8 has been used and\n> > >that\n> > >it is intended to have a corresponding IRI?\n> >\n> > You are correct that one cannot do this with 100% certainty.\n> > But then, if you study the URI spec very carefully, you will\n> > find that it also doesn't guarantee that an 'a' in an URI\n> > actually corresponds to an 'a' in the original data (e.g.\n> > file name). For details, please see the \"Laguna Beach\"\n> > example in Section 2.5 of draft-fielding-uri-rfc2396bis-05.txt,\n> > for example at\n> > \n> http://gbiv.com/protocols/uri/rev-2002/draft-fielding-uri-rfc2396bis-05.txt.\n> >\n> > So in those rare cases where an URI with an octet sequence\n> > that by chance corresponds to an UTF-8 pattern, but that was\n> > never intended as UTF-8, is converted to an IRI, one will just\n> > get a weird name, but reusing that name again e.g. in a browser\n> > that accepts IRIs will lead back to the original resource.\n> >\n> >\n> >\n> > >It seems to me that IRI will only be deployed accurately and effectively\n> > >if one\n> > >of the following situations occurs:\n> > >\n> > >1) New protocol schemes (e.g. httpi, httpis ) are introduced which make it\n> > >explicit that this spec. applies to the URI,\n> >\n> > Introducing a new URI scheme is *extremely* expensive. I have heard\n> > Tim Berners-Lee say this over and over again, and I know he knows it.\n> > And in the case at hand, it's highly unnecessary. The cost of an\n> > occasional accidental 'wrong' conversion back to an IRI (as discussed\n> > above) is much, much smaller than the cost of introducing new schemes.\n> >\n> > And what would the real benefit of new schemes be? Would they be\n> > useful to distinguish URIs from true IRIs (I'm writing 'true' IRIs\n> > here to exclude URIs which are by definition also IRIs). Not really,\n> > it's much cheaper to identify IRIs by checking for non-ASCII characters.\n> >\n> > So they would only be used to distinguish URIs without known origin\n> > from URIs originating from conversion from IRIs. But assume I had\n> > an IRI like like http://www.example.org/ros&#xE9; (rose'). In order\n> > to pass it to others whom I know can only process URIs, not IRIs,\n> > would I want to convert it to http://www.example.org/ros%C3%A9,\n> > or to httpi://www.example.org/ros%C3%A9 ? The former strictly\n> > speaking looses the information that this was an IRI, so converting\n> > it back to rose' is a guess (but because of the UTF-8 patters,\n> > actually a rather safe one). But it actually will go to the\n> > right page, on hunderds of millions of Web browsers, without\n> > exception. The later can safely be converted back to the IRI\n> > (by all the software that knows how to do this, which currently\n> > numbers exactly 0). But it will work only on the browsers\n> > that know the httpi: scheme (again, currently numbering\n> > exactly 0). For me the alternative is very clear,\n> > http://www.example.org/ros%C3%A9 works in much more cases,\n> > and is therefore much better.\n> >\n> >\n> > >2) They are used within a closed environment in which it is a \n> convention that\n> > >only IRIs and IRI-derived URIs are in use (no legacy-encoding escapes, or\n>they\n> > >are allowed to be mis-interpreted)\n> >\n> > The current draft clearly allows legacy-encoded escapes, for backwards\n> > compatibility. I'm not sure what you mean by 'mis-interpreted', but\n> > if you mean that they are converted to IRIs, then yes, the current\n> > draft allows this in those cases where it is possible (i.e. the\n> > byte pattern matches UTF-8,...). But this misinterpretation does\n> > not lead to an actual misinterpretation of the resource that the\n> > IRI identifies.\n> >\n> >\n> > >3) A new market-dominating user agent is launched which behaves as if (2)\n> > >above\n> > >were the case - i.e. there is an attempt to establish IRIs as the de facto\n> > >default through market force, ignoring or discarding resulting errors of\n> > >presentation or of resource identification.\n> > >\n> > >My big fear is that without rapid progress on (1), IRIs on the open \n> Internet\n> > >will only ever take off if someone does (3) - which will be without \n> benefit\n>of\n> > >adequate standards backing.\n> >\n> > I'm not sure I understand you. Several browsers, for example\n> > Opera and Safari, already implement IRIs. MS IE also does it\n> > if the relevant flag is set correctly. And the standard is\n> > close to done; this is the last real issue I'm trying to close.\n> > So I don't see the problem.\n> >\n> >\n> > >I'd love to either:\n> > >\n> > >a) be shown that my logic is faulty\n> >\n> > I guess yes. Not in theory, where absolute correctness is the\n> > only goal, but in practice, where big numbers and deployment\n> > are important.\n> >\n> > >or\n> > >\n> > >b) be pleasantly surprised by being told that there _is_  RFC work taking\n> > >place\n> > >on new schemes covering at least the space of http(s)\n> >\n> > Some schemes may benefit from an update, in particular those that\n> > haven't thought about internationalization. The first example that\n> > would come to my mind is the mailto: scheme.\n> >\n> >\n> > Regards,    Martin.\n> >\n> >\n> >\n> > >otherwise, I fail to understand how IRIs will 'take off' in the 'real\n>world' -\n> > >where they are so badly needed.\n> > >\n> > >Chris\n> > >\n> > >\n> > >\n> > >\n> > >----- Original Message -----\n> > >From: \"Michel Suignard\" <michelsu@windows.microsoft.com>\n> > >To: \"Chris Haynes\" <chris@harvington.org.uk>\n> > >Cc: <public-iri@w3.org>; \"Martin Duerst\" <duerst@w3.org>\n> > >Sent: Friday, May 07, 2004 1:43 AM\n> > >Subject: RE: Migration of HTTP to the use of IRIs [queryclarify-16]\n> > >\n> > >\n> > >\n> > > > From:  Chris Haynes\n> > > > Sent: Thursday, May 06, 2004 4:50 AM\n> > > >\n> > > > Actually, my original core concern has now been covered in your\n> > >section\n> > > > 1.2.a - Applicability, where you make it clear that \"the intent is not\n> > >to\n> > > > introduce IRIs into contexts that are not defined to accept them\".\n> > > >\n> > > > This now makes it clear that new schemas will be required to replace\n> > > > http: , https: etc. These will need to be self-identifying in some\n> > >way, so\n> > > > that receiving equipment will know that an IRI is being presented.\n> > > >\n> > > > So, as I commented last June, I await with interest the recognition\n> > >among\n> > > > those responsible for the HTTP schema that new schemas with new names\n> > >are\n> > > > required before IRIs can be used.\n> > >\n> > >I'd like to comment on that. The IRI spec is fairly explicit on that IRI\n> > >can be used as presentation elements for URI protocol elements (ref\n> > >clause 3 intro). This is to recognize that applications out there have\n> > >not waited for us for creating presentation layers that use non ascii\n> > >native characters for schemes that supposedly should not use them (such\n> > >as http). The presentation layer principle is there to support that. So\n> > >I expect IRI to be used for both purposes:\n> > >- presentation layer for existing URI schemes\n> > >- core layer for new schemes exclusively defined using IRI for protocol\n> > >elements syntax.\n> > >\n> > >For a while I'd expect the vast majority of IRI usage to be in the first\n> > >category.\n> > >\n> > >Michel\n> > >\n> > >\n> >\n> >\n> >\n\n\n\n", "id": "lists-017-1623838"}, {"subject": "RE: xslt 2.0 vs xslt 1.0 ", "content": "If you are new to XSLT, Othman, then I suggest you concentrate on learning\nXSLT 1.0 and XPath 1.0 for the time being, since the 2.0 versions are still\nunder development and not available yet in most products.\n \nThe only real way to learn about XSLT 2.0 and XPath 1.0 at present is to\nstudy the W3C specifications, though you will probably find it useful to\nread Evan Lenz's introductory articles first:\n \nhttp://www.xml.com/pub/a/2002/03/20/xpath2.html\n<http://www.xml.com/pub/a/2002/03/20/xpath2.html> \nhttp://www.xml.com/pub/a/2002/04/10/xslt2.html\n<http://www.xml.com/pub/a/2002/04/10/xslt2.html> \n \nMichael Kay\n\n-----Original Message-----\nFrom: Othman Haddad [mailto:ohaddad@neomalogic.com] \nSent: 31 May 2002 16:28\nTo: xsl-editors@w3.org\nCc: public-qt-comments@w3.org\nSubject: xslt 2.0 vs xslt 1.0 !\n\n\n \n  \n\ni'm sorry,\nbut i was wondering if studying any xslt tutorial is ok for me, even if i\nwant to work on the new XSLT2.0?\nare they too many differences ?, i know there are some between XPATH 1.0 and\nXPATH2.0 (sequences instead of nodes etc..), but does it change anything for\nthe XSLT?\nthank you..\n  \n\n\n\n", "id": "lists-017-16271066"}, {"subject": "static or dynamic binding of focus", "content": "[This is a reposting of a message sent to www-xml-query-comments\non April 22.  However, there was never a response, and this is\na rather critical issue.]\n\nIt seems to me that the definition of the context item, size,\nposition, and document in the Formal Semantics is inconsistent\nwith that in the other documents.  This may be a known issue,\nbut I haven't seen it mentioned.\n\nThe Formal Semantics defines path expressions so that the\nvariables $fs:dot, $fs:position, and $fs:last get set.  However,\nthese variables are *lexical* variables that are defined using 'let'\nclauses.\n\nHowever, the Functions and Operators document defines (for example)\nposition() as \"an unsignedInt indicating the position of the context\nitem within the sequence of items currently being processed\".  This\nimplifies that the position is part of the dynamic state, not just\nthe static state.\n\nTo use a concrete example, the question I have is whether the following\nis (intended to be) well-defined:\n\ndefine function is-mid() {\n    return position() == last() / 2\n}\n\ndocument(\"foo.xml\")/book/chapter[is-mid()]\n\nAccording to the Formal Semantics document, this gets re-written so\nthat lexical variable $fs:position would be defined, such that the\npredicate is-mid() is the scope of the variable.  Thus the invocation\nof position() in the body of is-mid is within the *dynamic* scope\nof the $fs:position variable.  However, it is not within the *lexical*\nscope of $fs:position.\n\nSo I see three possibilities:\n(1) The value of position is bound dynamically, the Formal Semantics is\nwrong, and my example is well-defined.\n(2) The value of position is bound statically, the Formal Semantics is\ncorrect, and the Functions and Operators is wrong in talking about\n\"context functions\".  Instead a \"function\" like position() is actually\na macro (syntactic sugar), and my example is not definied.\n(3) The value of position is bound dynamically, both documents are\ncorrect, and my example is well-defined.  A 'let' clauses creates a\ndynamic or \"fluid\" binding, rather than a lexical binding.  This is\nconsistent, and many scripting langauges use it - but it seems\nincompatible with static typing.\n-- \n--Per Bothner\nper@bothner.com   http://www.bothner.com/per/\n\n\n\n", "id": "lists-017-16280172"}, {"subject": "Re: Comments on the XPath data model, from a DOM  perspective", "content": "Hello Ray Withmer,\n\nThis is in response to your comments on the\nXPath datamodel from the DOM perspective\n(http://lists.w3.org/Archives/Public/www-xml-query-comments/2002Apr/0000\n.html)\n\nAt Fraunhofer IPSI we are implementing XQuery, including XPath 2.0\non the basis of the Xerces DOM 2 implementation\n(see http://ipsi.fhg.de/oasys/projects/ipsi-xq/index_e.html\nand http://ipsi.fhg.de/oasys/projects/ipsi-xq/overview_e.html\nfor a short description of the underlying architecture).\n\nIn the most recent version, we have even wrapped the DOM-interface\nwith a thin layer of XQuery/XPath-Datamodel classes, to allow\nfor plugging in alternative XML-storage models. \n\nGenerally, the Xerces DOM turns out to be a suitable basis for\nthe XQuery datamodel. Here are the main problems that we encountered\nand their workaround.\n\n(1) Xerces DOM 2 has no (XML-Schema) type annotations. We used\n    Xerces' extensibility mechanism of user defined annotations to\n    represent them. We will have a look at the DOM 3 Schema module.\n(2) Xerces DOM 2 does not directly support node-ids with document\n    order.\n    Again we represent them by means of user defined annotations.\n(3) Some expressions of XQuery return heterogeneous sequences of nodes\n    and simple values (aka items). We have implemented such sequences in\n    a proprietary way with one level of indirection (pointers to nodes\n    and simple values). Because such sequences only occur for interim\nXQuery results,\n    and never within a constructed element, this is appropriate\n    in the IPSI-XQ architecture, which works on the XQuery/XPath\n    Datamodel abstraction. However, for applications wanting to\n    operate directly on interim XQuery results (e.g. via a cursor on\n    DOM-\"items\" rather than DOM-\"nodes\"), this indeed can mean an\nadditional\n    complication.\n\nAltogether, the DOM and the XQuery/XPath datamodel are not as far from\neach other as may seem at first sight. However, wrapping the DOM-API\nwith\na (thin) XQuery/XPath abstraction has allowed us to even more closely\nalign\nour implementation with the XQuery working drafts.\n\nHope this clarifies,\n\nPeter Fankhauser\nInfonyte GmbH\n(on leave from Fraunhofer IPSI)\n\n\n\n", "id": "lists-017-16288684"}, {"subject": "RE: feature request", "content": "There is a neat trick you can use for this: just declare your namespace as\nan extension namespace.\n\n<xsl:stylesheet\n   xmlns:x=\"my.accessibility.namespace\"\n   extension-element-prefixes=\"x\">\n\n\n   <x:comment>....</x:comment>\n\nThe XSLT processor is required to ignore extension instructions in a\nnamespace that it does not recognize.\n\nMichael Kay\n\n\n> -----Original Message-----\n> From: DPawson@rnib.org.uk [mailto:DPawson@rnib.org.uk] \n> Sent: 18 June 2002 08:02\n> To: xsl-editors@w3.org\n> Subject: feature request.\n> \n> \n> \n> That it be possible to utilise a given namespace for\n> (effectively) comments, i.e. the named namespace is not\n> treated as a literal and output.\n> \n> Rationale:\n> \n>  E.g. constructing an\n> outline of the stylesheet operation,\n> explanatory documentation,  \n> providing multi-modal representations, etc.\n> \n> Perhaps something like\n> <xsl:ns-ignore prefix='doc'/>\n> \n> The stylesheet application then simply bypasses anything\n> in that namespace, treating it as a comment.\n> \n> \n> This would support conformance to the XML accessibility guidelines.\n> \nhttp://www.w3.org/TR/xag\n\nregards DaveP\n\n************snip here************** \n\n- \n\nNOTICE: The information contained in this email and any attachments is \nconfidential and may be legally privileged. If you are not the \nintended recipient you are hereby notified that you must not use, \ndisclose, distribute, copy, print or rely on this email's content. If \nyou are not the intended recipient, please notify the sender \nimmediately and then delete the email and any attachments from your \nsystem.\n\nRNIB has made strenuous efforts to ensure that emails and any \nattachments generated by its staff are free from viruses. However, it \ncannot accept any responsibility for any viruses which are \ntransmitted. We therefore recommend you scan all attachments.\n\nPlease note that the statements and views expressed in this email \nand any attachments are those of the author and do not necessarily \nrepresent those of RNIB.\n\nRNIB Registered Charity Number: 226227\n\nWebsite: http://www.rnib.org.uk \n\n14th June 2002 is RNIB Look Loud Day - visit http://www.lookloud.org.uk to\nfind out all about it.\n\n\n\n", "id": "lists-017-16298653"}, {"subject": "Re: feature request", "content": "> There is a neat trick you can use for this: just declare your namespace as\n> an extension namespace.\n\nOh. I use this trick a lot but I always throw in an empty xsl:fallback\nelement as well I thought this was needed and was surprised by your\ncomment\n\n> The XSLT processor is required to ignore extension instructions in a\n> namespace that it does not recognize.\n\nthe XSLT 1.0 spec seems a bit obscure here.\n\n14.1 says\n\n An XSLT processor must not signal an error merely because a template\n contains an extension element for which no implementation is\n available.\n\nHowever the preceding sentence is\n\n\n  When such an extension element is instantiated, then the XSLT\n  processor must perform fallback for the element as specified in [15\n  Fallback]. \n\nand fallback says:\n\n  if the instruction element has one or more xsl:fallback children, then\n  the content of each of the xsl:fallback children must be instantiated\n  in sequence; otherwise, an error must be signaled.  \n\nI have always read this as saying if there are no xsl;fallback elements\nthen the \"otherwise\" clause implies that an error will be signaled.\n\n\nDavid\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-16309333"}, {"subject": "RE: feature request", "content": "> There is a neat trick you can use for this: just declare your \n> namespace as\n> an extension namespace.\n> \n> <xsl:stylesheet\n>    xmlns:x=\"my.accessibility.namespace\"\n>    extension-element-prefixes=\"x\">\n> \n> \n>    <x:comment>....</x:comment>\n> \n> The XSLT processor is required to ignore extension instructions in a\n> namespace that it does not recognize.\n\nThanks Michael. \nRequest please, trick or not, perhaps if some note to this \neffect could be added to the rec, for information?\n\nregards DaveP.\n\n- \n\nNOTICE: The information contained in this email and any attachments is \nconfidential and may be legally privileged. If you are not the \nintended recipient you are hereby notified that you must not use, \ndisclose, distribute, copy, print or rely on this email's content. If \nyou are not the intended recipient, please notify the sender \nimmediately and then delete the email and any attachments from your \nsystem.\n\nRNIB has made strenuous efforts to ensure that emails and any \nattachments generated by its staff are free from viruses. However, it \ncannot accept any responsibility for any viruses which are \ntransmitted. We therefore recommend you scan all attachments.\n\nPlease note that the statements and views expressed in this email \nand any attachments are those of the author and do not necessarily \nrepresent those of RNIB.\n\nRNIB Registered Charity Number: 226227\n\nWebsite: http://www.rnib.org.uk \n\n14th June 2002 is RNIB Look Loud Day - visit http://www.lookloud.org.uk to\nfind out all about it.\n\n\n\n", "id": "lists-017-16317916"}, {"subject": "Re: feature request", "content": "DaveP> Thanks Michael. \nDaveP> Request please, trick or not, perhaps if some note to this \nDaveP> effect could be added to the rec, for information?\n\n\nthe technique is by the way documented at the XSLT FAQ site maintained\nby, er, now who was it maintained by...\nhttp://www.dpawson.co.uk/xsl/sect2/documentation.html#d115e91\n\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-16326937"}, {"subject": "RE: feature request", "content": "You're right (sorry). There must be an <xsl:fallback/>. I was thinking of\ntop-level elements.\n\nMichael Kay\n\n> -----Original Message-----\n> From: David Carlisle [mailto:davidc@nag.co.uk] \n> Sent: 18 June 2002 11:16\n> To: Michael.Kay@softwareag.com\n> Cc: DPawson@rnib.org.uk; public-qt-comments@w3.org\n> Subject: Re: feature request.\n> \n> \n> \n> > There is a neat trick you can use for this: just declare your \n> > namespace as an extension namespace.\n> \n> Oh. I use this trick a lot but I always throw in an empty \n> xsl:fallback element as well I thought this was needed and \n> was surprised by your comment\n> \n> > The XSLT processor is required to ignore extension \n> instructions in a \n> > namespace that it does not recognize.\n> \n> the XSLT 1.0 spec seems a bit obscure here.\n> \n> 14.1 says\n> \n>  An XSLT processor must not signal an error merely because a \n> template  contains an extension element for which no \n> implementation is  available.\n> \n> However the preceding sentence is\n> \n> \n>   When such an extension element is instantiated, then the XSLT\n>   processor must perform fallback for the element as specified in [15\n>   Fallback]. \n> \n> and fallback says:\n> \n>   if the instruction element has one or more xsl:fallback \n> children, then\n>   the content of each of the xsl:fallback children must be \n> instantiated\n>   in sequence; otherwise, an error must be signaled.  \n> \n> I have always read this as saying if there are no \n> xsl;fallback elements then the \"otherwise\" clause implies \n> that an error will be signaled.\n> \n> \n> David\n> \n> _____________________________________________________________________\n> This message has been checked for all known viruses by Star \n> Internet delivered through the MessageLabs Virus Scanning \n> Service. For further information visit \n> http://www.star.net.uk/stats.asp or > alternatively call Star \n> Internet for details on the Virus Scanning Service.\n> \n\n\n\n", "id": "lists-017-16334540"}, {"subject": "Use Cases 2002043", "content": "In line 1 of the \"Status of this document\" section reference is made to \"W3C \nXML Requirements\".\n\nI assume that that should read \"W3C XML Query Requirements\"?\n\nAndrew Watt\n\n\n\n", "id": "lists-017-16369330"}, {"subject": "Re: Use Cases 2002043", "content": "Yes.\n\nJonathan\n\nAt 04:36 AM 5/1/2002 -0400, Svgdeveloper@aol.com wrote:\n>In line 1 of the \"Status of this document\" section reference is made to \"W3C\n>XML Requirements\".\n>\n>I assume that that should read \"W3C XML Query Requirements\"?\n>\n>Andrew Watt\n\n\n\n", "id": "lists-017-16375725"}, {"subject": "public-qtcomments&#64;w3.or", "content": "Yesterday's Functions and Operators draft still says to send comments to\n    www-xml-query-comments@w3.org\nPresumably, that should be changed to \n    public-qt-comments@w3.org\n\nNot surprisingly, the drafts that were not re-released yesterday\n(Requirements, Formal Semantics, and XQueryX) also still point to\nwww-xml-query-comments@w3.org.  Will they stay that way until the next\nrelease? Should commenters send to public-qt-comments anyway?\n\nThe Use-cases draft gives the address as\n   public-qt-comments@w3.org@w3.org\n\nThe XSLT 2.0 draft doesn't appear to tell readers where to send their\ncomments.\n\nAt http://lists.w3.org/Archives/Public/public-qt-comments/,\nthe link for \"XSL\" has an empty href.\n\nhttp://www.w3.org/XML/Query indicates that www-xml-query-comments@w3.org is\nnow \"for submitting comments just to the XML Query wg. Please use this list\nonly if you think the XML Query working group, and not the XSL working\ngroup, should be the recipient of the message.\" Any pointers on how to make\nthat decision? I mean, of all the various Query drafts, if I were to pick a\ncouple that I thought the XSL wg didn't need to see the comments on, I would\nguess the Uses-cases doc and the \"XML Query Language\" doc. But both of those\ndocs tell me to send comments to public-qt-comments. So what's left? What\nwould be of concern *only* to the Query wg? \n\n-Michael Dyck\n\n\n\n", "id": "lists-017-16383390"}, {"subject": "Re: [Moderator Action] public-qtcomments&#64;w3.or", "content": "Hi Michael,\n\nThanks for pointing out those inconsistencies. The Working Groups will\ndiscuss them and improve the situation. In the meantime send your\ncomments to the list indicated in the relevant working draft. If you\nhave more general comments that do not necessarily refer to a single\ndocument, send them to public-qt-comments@w3.org. The will always be people\nfrom both working groups reading it anyway and able to forward the comment\nto the appropriate group or subgroup.\n\nMichael Dyck <michaeldyck@shaw.ca> writes:\n\n> At http://lists.w3.org/Archives/Public/public-qt-comments/,\n> the link for \"XSL\" has an empty href.\n\nThat was an error and it is now fixed. Thanks.\n\nMax.\nModerator of public-qt-comments@w3.org\n\n\n\n", "id": "lists-017-16392697"}, {"subject": "RE: public-qtcomments&#64;w3.or", "content": "> -----Original Message-----\n> From: Michael Dyck [mailto:michaeldyck@shaw.ca]\n> \n> Yesterday's Functions and Operators draft still says to send \n> comments to\n>     www-xml-query-comments@w3.org\n> Presumably, that should be changed to \n>     public-qt-comments@w3.org\n> \nYes, that's an unfortunate oversight.\n> \n> The Use-cases draft gives the address as\n>    public-qt-comments@w3.org@w3.org\n\nAnd that one's a typo. Sorry!\n> \n> The XSLT 2.0 draft doesn't appear to tell readers where to send their\n> comments.\n\nYes it does. Perhaps you were blinded by the bright green background.\nTwo-thirds of the way down the Status section, it says: \"Comments on this\nspecification may be sent to public-qt-comments@w3.org; archives of the\ncomments are available\".\n\nMichael Kay\n\n\n\n", "id": "lists-017-16401104"}, {"subject": "RE: public-qtcomments&#64;w3.or", "content": "Michael: \nThe F&O draft went to press before the change in the comments list was\nannounced.  We'll fix in the next release.\nRegards, Ashok  \n\n\n-----Original Message-----\nFrom: Michael Dyck [mailto:michaeldyck@shaw.ca] \nSent: Wednesday, May 01, 2002 9:42 AM\nTo: www-xml-query-comments@w3.org; public-qt-comments@w3.org\nSubject: public-qt-comments@w3.org\n\nYesterday's Functions and Operators draft still says to send comments to\n    www-xml-query-comments@w3.org\nPresumably, that should be changed to \n    public-qt-comments@w3.org\n\nNot surprisingly, the drafts that were not re-released yesterday\n(Requirements, Formal Semantics, and XQueryX) also still point to\nwww-xml-query-comments@w3.org.  Will they stay that way until the next\nrelease? Should commenters send to public-qt-comments anyway?\n\nThe Use-cases draft gives the address as\n   public-qt-comments@w3.org@w3.org\n\nThe XSLT 2.0 draft doesn't appear to tell readers where to send their\ncomments.\n\nAt http://lists.w3.org/Archives/Public/public-qt-comments/,\nthe link for \"XSL\" has an empty href.\n\nhttp://www.w3.org/XML/Query indicates that www-xml-query-comments@w3.org\nis\nnow \"for submitting comments just to the XML Query wg. Please use this\nlist\nonly if you think the XML Query working group, and not the XSL working\ngroup, should be the recipient of the message.\" Any pointers on how to\nmake\nthat decision? I mean, of all the various Query drafts, if I were to\npick a\ncouple that I thought the XSL wg didn't need to see the comments on, I\nwould\nguess the Uses-cases doc and the \"XML Query Language\" doc. But both of\nthose\ndocs tell me to send comments to public-qt-comments. So what's left?\nWhat\nwould be of concern *only* to the Query wg? \n\n-Michael Dyck\n\n\n\n", "id": "lists-017-16410681"}, {"subject": "WD-query-datamodel-20020430: &quot;qualified&quot; names  and, eg., issue0061", "content": "The WD-query-datamodel-20020430 draft continues to use the term\n\"qualified\" name in a manner which confounds reason. The usage is\nsomewhat improved, as the text attempts to clarify the intent with forms\nsuch as \"expanded qualified name\" or \"the value space of xs:QName\". It\nis not material, that the sources for the xs:Qname term themselves\nconfound reason. While these attempts are well-meaning, it would be more\neffective to simply use distinct names for the distinct meanings.\n \nA more adequate hierarchy is\n\n(defclass name ()\n((local-part :type string)))\n\n(defclass qualified-name (name)\n((prefix :type string :initform \"\")))\n\n(defclass universal-name (name)\n((namespace :type string)))\n\n(defclass expanded-name (universal-name qualified-name)\n())\n\n\nThe \"expanded-name\" form is equivalent to the \"QName object that is a\ntriple, local-name, namespace-uri, and prefix,\" which issue-0061\ndescribes and suggests as a means to support the XPath name function.\n\nIt remains, however, to be demonstrated that any function other than the\nname function demands this abstract name form. Furthermore, it remains\nto be demonstrated that the name function itself - even when more\naccurately identified as \"qualified-name\" rather than \"name\" - needs\nthis tripartite name form. The provisos which govern use of the \"name\"\nfunction demonstrate that its result is valid only in a given namespace\nbinding environment. This environment has customarily been understood to\nbe that of the respective element - that is, its set of in-scope\nnamespace nodes. Issue 61 calls that assumption into question. A similar\nconcern arises with respect to attribute and element content which is\nintended to denote universal names (see ref to the xslt requiremnt\nbelow). the ensuing problems suggest that a more adequate definition for\nthe \"name\" function would make the namespace scope argument explicit.\nwhich definition renders the expanded-name form superfluous, as the\nuniversal-name form is then adequate for a complete xpath/xquery model.\n\nAs demonstrated by requirements 1.5 and 1.7 of WD-xslt20req-20010214, it\nwould be beneficial to rephrase the abstract syntax in terms of\nuniversal names.\n\nAs demonstrated by the qname handling in WD-xslt20-20011220.html, in\nparticular the presence of ERR018 and ERR019, the languages can be\ndefined - and xslt is defined, such that the interpretation of their\nabstract syntax does not require that qualified name prefixes be retained.\n\n...\n\n\n\n", "id": "lists-017-16422472"}, {"subject": "RE: Sequence Type Checkin", "content": "> That being the case, isn't the current set of productions for\n> SequenceType ambiguous? \n\nI agree with you, there is a reserved word problem with type names.\nGenerally we have been happy to have reserved words in XQuery but not in\nXPath, and I don't think we've achieved that here.\n> \n> If neither of those is the case, one method of clarifying this would\n> be to make those ItemTypes that are actually node types look like\n> (node) KindTests (production [31]), so you'd have node(),\n> processing-instruction() and so on. This could be extended to include\n> element() and attribute(), perhaps adopting the same syntax as\n> processing instruction tests to provide the name of the node:\n> \n>   element('foo')\n> \n> would mean the same as:\n> \n>   element foo\n>\n\nWe've been discussing within the XSL WG how to incorporate type matching\ninto the XSLT pattern syntax, and we have ideas that run along these lines,\nbut no detailed proposal yet.\n> \n> Another thing here is how you match elements and attributes if you use\n> an ElemOrAttrType..... \n\nI'll leave this part to people who understand schemas better than I do.\n> \n> Personally, I'd like to see the syntax used here unified with the\n> syntax used in XSLT in match patterns. It strikes me that you're doing\n> a similar kind of thing as match patterns here: putting together a\n> test that identifies the kind of things that are allowed in a\n> sequence. Perhaps an alternative, therefore, would be to use type(),\n> say, to indicate a type and have things like:\n> \n>   type('xs:date')        refers to the built-in Schema type date\n>   @*?                    refers to an optional attribute\n>   *                      refers to any element\n>   office:letter          refers to an element with a specific name\n>   *[type('po:address')]+ refers to one or more elements of the given\n>                          type\n>   node()*                refers to a sequence of zero or more nodes of\n>                          any type\n>   item()*                refers to a sequence of zero or more nodes or\n>                          atomic values\n> \nWe've been toying with such ideas in XSL WG. Thanks for the contribution.\n\nMichael Kay \n\n\n\n", "id": "lists-017-16431555"}, {"subject": "Sequence Type Checkin", "content": "Hi,\n\nCan you clarify what \"AtomicType\" means in the context of sequence\ntype checking in Section 2.1.3.2. (SequenceType) of the XPath 2.0 WD?\nI think that you mean this to include all atomic simple types, since\nhigher up, in the introduction part of Section 2.1.3 (Types), you say:\n\n  \"The set of named types includes all the built-in types *and all\n  user-defined simple or complex types* for which the type declaration\n  contains a name.\" (my emphasis)\n\nThat being the case, isn't the current set of productions for\nSequenceType ambiguous? What if I defined the following type in a\nschema with no target namespace:\n\n<xs:simpleType name=\"item\">\n  <xs:restriction base=\"xs:token\">\n    <xs:pattern value=\"item[0-9]{3}\" />\n  </xs:restriction>\n</xs:simpleType>\n\nThis is a user-defined atomic type whose name is 'item' (with no\ntarget namespace and thus no prefix). Since atomic types are simply\nnamed, saying:\n\n  item+\n\ncould mean \"one or more of the item type from the schema\" or it could\nmean \"one or more items of any type\". Similarly, I could have types\ncalled \"element\", \"attribute\", \"node\" and so on for the other ItemType\nkeywords.\n\nOr perhaps you are restricting XML Schema to that subset of XML\nSchemas in which all the components have a target namespace? If so, I\ndon't *think* you've mentioned that anywhere, and it's a pretty big\nrestriction. Or perhaps you mean for types that are named the same as\nthe keywords to have to be prefixed with a \":\" as elsewhere? In which\ncase you should incorporate that into the BNF.\n\nIf neither of those is the case, one method of clarifying this would\nbe to make those ItemTypes that are actually node types look like\n(node) KindTests (production [31]), so you'd have node(),\nprocessing-instruction() and so on. This could be extended to include\nelement() and attribute(), perhaps adopting the same syntax as\nprocessing instruction tests to provide the name of the node:\n\n  element('foo')\n\nwould mean the same as:\n\n  element foo\n\n\nAnother thing here is how you match elements and attributes if you use\nan ElemOrAttrType. The text says:\n\n  2. Another form of ElemOrAttrType is simply a QName, which is\n     interpreted as the required name of the element or attribute. The\n     QName must be an element or attribute name that is found in the\n     in-scope schema definitions.\n\nBut earlier on, in-scope schema definitions is defined as:\n\n  In-scope schema definitions. This is a set of (QName, type\n  definition) pairs. It defines the set of types that are available\n  for reference within the expression. It includes the built-in schema\n  types and all globally-declared types in imported schemas.\n\nPerhaps you're using \"type definition\" in a different way from XML\nSchema, but in XML Schema, \"type definitions\" aren't element\ndeclarations. I think that you might need to add something to the\nstatic context -- \"in-scope element declarations\" and \"in-scope\nattribute declarations\" -- in which to search, although I notice that\nthese are explicitly left out of the data model...\n\nI think that you mean that doing \"element foo\" will only match foo\nelements that are declared at the top level of the schema (i.e.\n{element declarations} on schema component Schema). Is that correct? I\nthink it might also be helpful to be able to distinguish between\n\"elements of this name, wherever they're declared\" and \"elements of\nthis name declared at the top-level of the schema\". Similarly, indeed\nparticularly, for attributes. You'll commonly have the following\nwithin a schema (particularly those generated from DTDs):\n\n<xs:element name=\"foo\">\n  <xs:complexType>\n    <xs:attribute name=\"id\" type=\"xs:ID\" />\n  </xs:complexType>\n</xs:element>\n\n<xs:element name=\"bar\">\n  <xs:complexType>\n    <xs:attribute name=\"id\" type=\"xs:ID\" />\n  </xs:complexType>\n</xs:element>\n\nAnd currently there's no way that I can see of referring to \"id\nattributes wherever they're declared\" or even \"id attributes as in the\nelement declaration for foo or the element declaration for bar\".\n\nFurthermore, if you do mean to have \"element foo\" only match top-level\nelement declarations, then I don't understand why you're allowed to\nspecify a type when matching those kinds of elements, but aren't\nallowed to do so when matching local element declarations. A top-level\nelement declaration can only have one type, just like a local element\ndeclaration. Perhaps you mean it to be that when the type is specified\nyou match all elements, wherever their declaration?\n\nA final thing here is that the SchemaGlobalContext should include\nattribute groups and model groups, so that you can distinguish between\nfoo elements with the following declarations:\n\n<xs:element name=\"foo\" type=\"type1\" />\n\n<xs:complexType name=\"bar\">\n  <xs:sequence>\n    <xs:element name=\"foo\" type=\"type2\" />\n  </xs:sequence>\n</xs:complexType>\n\n<xs:group name=\"bar\">\n  <xs:sequence>\n    <xs:element name=\"foo\" type=\"type3\" />\n  </xs:sequence>\n</xs:group>\n\nIf you did allow for this kind of schema, you'd also have to add\n\"in-scope group definitions\" and \"in-scope attribute definitions\" to\nthe static context.\n\n---\n\nPersonally, I'd like to see the syntax used here unified with the\nsyntax used in XSLT in match patterns. It strikes me that you're doing\na similar kind of thing as match patterns here: putting together a\ntest that identifies the kind of things that are allowed in a\nsequence. Perhaps an alternative, therefore, would be to use type(),\nsay, to indicate a type and have things like:\n\n  type('xs:date')        refers to the built-in Schema type date\n  @*?                    refers to an optional attribute\n  *                      refers to any element\n  office:letter          refers to an element with a specific name\n  *[type('po:address')]+ refers to one or more elements of the given\n                         type\n  node()*                refers to a sequence of zero or more nodes of\n                         any type\n  item()*                refers to a sequence of zero or more nodes or\n                         atomic values\n\nI am not advocating a full pattern syntax here -- I understand that\nyou want to be able to *identify* the node/type from these\nSequenceType indicators, not only match them, so that you can do\nstatic analysis. Ths kind of thing I'm thinking about is something\nlike (forgive the BNF):\n\nSequenceType   ::=  (ItemTypes OccurrenceIndicator) | EmptyType\nEmptyType      ::=  \"(\" \")\"\nItemTypes      ::=  ItemType\n                    | \"(\" ItemType (\"|\" ItemType)+ \")\"\nItemType       ::=  NodeType\n                    | AtomicType\n                    | \"item\" \"(\" \")\"\nNodeType       ::=  NamedNodeType\n                    | \"node\" \"(\" \")\"\n                    | \"document\" \"(\" \")\"  // or perhaps \"/\"\n                    | \"text\" \"(\" \")\"\n                    | \"processing-instruction\" \"(\" \")\"\n                    | \"comment\" \"(\" \")\"\nNamedNodeType  ::=  ElemOrAttr SchemaType?\n                    | SchemaContext ElemOrAttr\nElemOrAttr     ::=  \"@\"? (\"*\" | QName)\nSchemaType     ::=  \"[\" \"type\" \"(\" QNameLiteral \")\" \"]\"\nQNameLiteral   ::=  (\"'\" QName \"'\") | ('\"' QName '\"')\nSchemaContext  ::=  SchemaGlobalContext (\"/\" SchemaContextStep)* \"/\"\nSchemaGlobalContext ::= \"schema\" \"(\" \")\" \"/\" (TypeOrGroup | QName)\nTypeOrGroup         ::= (\"type\" | \"group\") \"(\" QNameLiteral \")\"\nSchemaContextStep   ::= QName\nAtomicType          ::= \"type\" \"(\" (UnknownType | QNameLiteral)? \")\"\nUnknownType         ::= (\"'\" \"'\") | ('\"' '\"')\nOccurrenceIndicator ::= (\"*\" | \"+\" | \"?\")\n\nSo for example rather than writing:\n\n  element foo in type bar/baz +\n\nYou'd write:\n\n  schema()/type('bar')/baz/foo +\n\nRather than writing \"empty\", you'd write \"()\". Rather than writing\n\"unknown\", you'd write \"type('')\". Rather than writing \"atomic value\",\nyou'd write \"type()\"\n\nYou could say something like \"any number of id attributes declared\nwithin foo or bar element declarations\" with:\n\n  (schema()/foo/@id | schema()/bar/@id)*\n\nWith a few adjustments, this kind of syntax would enable users to make\nthe distinction between \"elements declared anywhere\" and \"elements\ndeclared at the top level\". The former could be matched with:\n\n  foo\n\nwhereas the latter with:\n\n  schema()/foo\n\nObviously the above would still need some work (in the above, \"type()\"\nmeans different things in different situations), but I'd hope that a\nunified syntax with XSLT match patterns will make the sequence typing\nmore flexible in the long run, easier to learn for people with\nexperience with XSLT, and eventually enable XSLT templates to match\nthings other than nodes.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16441204"}, {"subject": "PSVI and XPath 2.0 data mode", "content": "At 6:58 PM +0100 5/7/02, Michael Kay wrote:\n\n>The XPath 2.0 data model is based on the PSVI, not on the schema definition\n>language. It's explicitly an aim that you can generate the PSVI by\n>validation against a DTD, it should also be possible to generate it by\n>validation against other schema languages.\n>\n\nOn an unrelated matter, does XPath 2.0 bother to define how the PSVI \nis actually constructed from a specific XML document or does it allow \nprocessors to create whatever PSVI they want to whether or not that \nPSVI has any relation to the original XML document at all? For \ninstance, is it acceptable for an XSLT2 processor to replace all \nchild elements with attributes or convert rectangle elements into \ncircle elements? or simply replace the entire input document with the \nGospel According to Bob?\n\nOf course, such insane behavior would render a processor useless. \nHowever, some people have claimed that XSLT 1.0 permits this. I \npersonally don't believe those assertions. I think they're based on \nmisreadings of the XSLT 1.0 spec. However, I would like to have XSLT2 \nrule out these possibilities very clearly, so we can stop having that \nargument. Alternately, if the XSLT2 working group makes the wrong \ndecision and endorses such silliness, then everyone on the XSLT \nconformance group can stop wasting their time, since clearly any \nbehavior could be made conformant.\n\nLet me make a specific proposal here: the XSLT working draft should \nrequire that:\n\n1. When two conformant XML processors are presented with the same XML \ndocument, whether as a stream, DOM Document, a sequence of SAX \nevents, or some other form that can reasonably express a XML \ndocument; and\n\n2. An XSLT stylesheet does not use any features explicitly marked as optional;\n\nThen, both processors must be able to generate an XML document as a \nsequence of bytes or characters, such that, when the two documents \nare compared according to Canonical XML with comments, the two output \ndocuments are identical.\n\nThe wording clearly needs work, but you get the drift. I want it \npossible to be able to do conformance testing on XXSLT processors \nwithout any weaseling about source tree construction. I want a clear \npath from genuine XML document to PSVI to source tree.\n-- \n\n+-----------------------+------------------------+-------------------+\n| Elliotte Rusty Harold | elharo@metalab.unc.edu | Writer/Programmer |\n+-----------------------+------------------------+-------------------+\n|          The XML Bible, 2nd Edition (Hungry Minds, 2001)           |\n|             http://www.cafeconleche.org/books/bible2/              |\n|   http://www.amazon.com/exec/obidos/ISBN=0764547607/cafeaulaitA/   |\n+----------------------------------+---------------------------------+\n|  Read Cafe au Lait for Java news:  http://www.cafeaulait.org/      |\n|  Read Cafe con Leche for XML news: http://www.cafeconleche.org/    |\n+----------------------------------+---------------------------------+\n\n\n\n", "id": "lists-017-16457967"}, {"subject": "RE: Hurry up please", "content": "> In this particular application I need to do many detailed and\ndifficult\n> queries and my present means using XPath just isn't cutting it.  \n\nAre there specific queries that the current XQuery WD [1] cannot handle?\nIf not why can you not base your system on the current WD even though it\nmight not be as stable as you wish?  \n\nIf the current WD cannot handle your application's queries requirements\nthen please give us some examples of these queries so we know more about\nyour requirements.\n\n/paulc\nChair, XML Query WG\n\nPS: In the future please send your comments to the new public comments\nlist at public-qt-comments@w3.org archived at [2].\n\n[1] http://www.w3.org/TR/xquery/ \n[2] http://lists.w3.org/Archives/Public/public-qt-comments/ \n\nPaul Cotton, Microsoft Canada \n17 Eleanor Drive, Nepean, Ontario K2E 6A3 \nTel: (613) 225-5445 Fax: (425) 936-7329 \n<mailto:pcotton@microsoft.com> \n\n\n> -----Original Message-----\n> From: My Aleous [mailto:damianspaulding@hotmail.com]\n> Sent: Tuesday, May 07, 2002 2:08 PM\n> To: www-xml-query-comments@w3.org\n> Subject: Hurry up please.\n> \n> I have been working months on a major application for an executive\nsearch\n> firm that has hired me to design their system.  I took the risk of\nmaking\n> XML my database backbone in hopes that XQuery would be out before I\nneeded\n> it in design time.  Unfortunately that was not the case.\n> In this particular application I need to do many detailed and\ndifficult\n> queries and my present means using XPath just isn't cutting it.  I am\n> extremely frustrated that you have not yet released a version of\nXQuery\n> that\n> can properly manage the queries I need to perform.  This limitation is\n> costing me a great deal of time and money.\n> I understand that good things come to those who wait and you need time\nto\n> finish your work producing your \"PL\", but the cost for me is beginning\nto\n> become too great to justify.  Please catch up to internet time and\nproduce\n> at least a \"beta\" version for us programmers to utilize while you\nfinish\n> creating the \"polished\" version of XQuery.\n> Thank you for hearing my request, and I hold you all in the highest\n> regards.\n> - Damian Spaulding\n> \n> \n> _________________________________________________________________\n> MSN Photos is the easiest way to share and print your photos:\n> http://photos.msn.com/support/worldwide.aspx\n\n\n\n", "id": "lists-017-16468718"}, {"subject": "RE: PSVI and XPath 2.0 data mode", "content": "> On an unrelated matter, does XPath 2.0 bother to define how the PSVI\n> is actually constructed from a specific XML document or does it allow\n> processors to create whatever PSVI they want to whether or not that\n> PSVI has any relation to the original XML document at all? For\n> instance, is it acceptable for an XSLT2 processor to replace all\n> child elements with attributes or convert rectangle elements into\n> circle elements? or simply replace the entire input document with the\n> Gospel According to Bob?\n\nIt is not acceptable for an XSLT2 processor (or an XSLT1 processor) to\nmodify the tree that is provided as its input. It is acceptable for\narbitrary processing to take place during the construction of that tree.\nThis processing is not part of what an XSLT processor does, but it can be\ndone by other software that you choose to run before running the XSLT\nprocessor.\n\n>\n> Let me make a specific proposal here: the XSLT working draft should\n> require that:\n>\n> 1. When two conformant XML processors are presented with the same XML\n> document, whether as a stream, DOM Document, a sequence of SAX\n> events, or some other form that can reasonably express a XML\n> document; and\n>\n> 2. An XSLT stylesheet does not use any features explicitly\n> marked as optional;\n\nI think the closest we could get to that might be to require that an\nimplementor documents a method of constructing the input tree from an XML\ndocument using the \"standard mapping\" of XML documents to trees.\n\nWe would also need to consider whether to put in a similar provision about\nserialization.\n\n\nMichael Kay\nSoftware AG\nhome: Michael.H.Kay@ntlworld.com\nwork: Michael.Kay@softwareag.com\n\n\n\n", "id": "lists-017-16479961"}, {"subject": "RE: Where are the bitwise operators ", "content": "Please send your XQuery/XPath comments to the new comments list at\npublic-qt-comments@w3.org.\n\nPaul Cotton, Microsoft Canada \n17 Eleanor Drive, Nepean, Ontario K2E 6A3 \nTel: (613) 225-5445 Fax: (425) 936-7329 \n<mailto:pcotton@microsoft.com> \n\n\n> -----Original Message-----\n> From: Vinicius [mailto:Vinicius@upsight.com.br]\n> Sent: Tuesday, May 07, 2002 8:34 PM\n> To: 'www-xml-query-comments@w3.org'\n> Subject: Where are the bitwise operators ?\n> \n> Dear sirs,\n> \n> We have been observing the XPath drafts, and in fact it is very\n> powerful. But our group, and many other friends are missing the common\n> \"bitwise\" operators: and, or, xor, not. Is there any particular reason\n> why it is not been delivered for the next version of XPath (2.0)?\n> \n> Yours sincerely,\n> \n> Vinicius Bloise.\n> \n> \n> \n\n\n\n", "id": "lists-017-16489348"}, {"subject": "RE: Where are the bitwise operators ", "content": "> > Dear sirs,\n> > \n> > We have been observing the XPath drafts, and in fact it is very\n> > powerful. But our group, and many other friends are missing \n> the common\n> > \"bitwise\" operators: and, or, xor, not. Is there any \n> particular reason\n> > why it is not been delivered for the next version of XPath (2.0)?\n> > \n\nNo, there is no particular reason, other than (a) pressure of time, and (b)\npublic comments from people who are alarmed that the function library for\nXPath 2.0 is already five times the size of XPath 1.0.\n\nThere are many candidates for useful additional functions - trigonometric\nfunctions are another category. I think quite a good way forward with these\nis to propose specifications for inclusion in the EXSLT library (see\nwww.exslt.org), which many vendors are choosing to integrate into their\nproducts. Those specifications that prove popular with implementors and\nusers can then migrate into the core library at some later stage.\n\nMichael Kay\n\n\n\n", "id": "lists-017-16499288"}, {"subject": "RE: XSLT 2.0: Sorting and indeterminate comparison", "content": "Jeni:\nWe are trying to get away from indeterminate comparisons.\nOur attempt is to deprecate 'duration' and have users use\ntwo totally ordered subtypes of duration called 'yearMonthDuration'\nand 'dayTimeDuration'.\n\nFor the date/time types we say that for purposes of comparison and\narithmetic all date/time values have an implementation specific timezone\nThis makes them totally ordered.\n\nTake a look at the latest Functions and Operators document:\nhttp://www.w3.org/TR/xquery-operators/\nThis does not contain the changes for the date/time datatypes  \nmentioned above.  These will appear in the next version.\n\nAll the best, Ashok \n===========================================================\nAshok Malhotra              <mailto: ashokma@microsoft.com> \nMicrosoft Corporation\n212 Hessian Hills Road\nCroton-On-Hudson, NY 10520 USA \nRedmond: 425-703-9462                New York: 914-271-6477 \n\n\n\n-----Original Message-----\nFrom: Jeni Tennison [mailto:jeni@jenitennison.com] \nSent: Thursday, May 09, 2002 6:02 AM\nTo: public-qt-comments@w3.org\nCc: xsl-editors\nSubject: XSLT 2.0: Sorting and indeterminate comparisons\n\nHi,\n\n[I didn't realise that the email address for XSLT 2.0 comments had\nchanged as well...]\n\nThis is a follow-on from my last message about indeterminate\ncomparisons between durations and date/times in the F&O WD and\nsorting. Currently the XSLT 2.0 WD says:\n\n  The items in the initial sequence are ordered into a sorted sequence\n  by comparing their sort keys. The relative position of two items A\n  and B in the sorted sequence is determined as follows. The first\n  sort key of A is compared with the first sort key of B, according to\n  the rules of the first sort key definition. If, under these rules, A\n  is less than B, then A will precede B in the sorted sequence, unless\n  the order attribute of this sort key definition specifies\n  descending, in which case B will precede A in the sorted sequence.\n  If, however, the relevant sort keys compare equal, then the second\n  sort key of A is compared with the second sort key of B, according\n  to the rules of the second sort key definition. This continues until\n  two sort keys are found that compare unequal. If all the sort keys\n  compare equal, then A will precede B in the sorted sequence if A\n  preceded B in the initial sequence, and vice versa.\n\n  In general, comparison of two values is performed according to the\n  rules of the XPath lt operator. However, special rules apply to\n  certain data types, as described below. [ERR069] It is a dynamic\n  error if, for any sort key definition, the set of sort keys\n  evaluated for all the items in the initial sequence, after any type\n  conversion requested, contains a pair of values for which the result\n  of the XPath lt operator is an error or an empty sequence. The\n  processor must either signal the error, or must recover by assigning\n  an arbitrary ordering to any such pair of values.\n\nGiven that indeterminate comparisons were allowed, I think that it\nwould be much more helpful if the comparisons between pairs of values\nwere described in terms of only lt rather than lt and eq. The second\npart of the first paragraph would be:\n\n  If, however, B is not less than A, then the second sort key of A is\n  compared with the second sort key of B, according to the rules of\n  the second sort key definition. This continues until two sort keys\n  are found for which A is less than B or B is less than A. If all the\n  sort keys compare equal, then A will precede B in the sorted\n  sequence if A preceded B in the initial sequence, and vice versa.\n\nFor totally ordered data types, this makes no difference. For\npartially ordered data types, this will create an intuitive ordering,\nand not require an error to be raised. For example, with the source:\n\n  <relationship length=\"P1M\">...</relationship>\n  <relationship length=\"P21D\">...</relationship>\n  <relationship length=\"P5Y1D\">...</relationship>\n  <relationship length=\"P28D\">...</relationship>\n  <relationship length=\"P3M\">...</relationship>\n\nit would be possible to sort them with:\n\n  <xsl:for-each select=\"relationship\">\n    <xsl:sort select=\"@length\" data-type=\"xs:duration\" />\n    <xsl:copy-of select=\".\" />\n  </xsl:for-each>\n\nin order to get:\n\n  <relationship length=\"P21D\">...</relationship>\n  <relationship length=\"P1M\">...</relationship>\n  <relationship length=\"P28D\">...</relationship>\n  <relationship length=\"P3M\">...</relationship>\n  <relationship length=\"P5Y1D\">...</relationship>\n\nwithout getting an error of any kind.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16507842"}, {"subject": "RE: XSLT 2.0: Sorting and indeterminate comparison", "content": "Echoing Ashok's response, the current situation is that the \"lt\" operator,\nif it is defined at all for a given data type, always returns a determinate\nboolean answer. Defining sorting in terms of \"lt\" and \"eq\" therefore works.\n\nI agree that if we allowed an indeterminate result of \"lt\" we could treat it\nfor sorting purposes as if the items were equal. Currently, the value of\nP29D lt P1M is not indeterminate, it is an error. \n\nI expect that in a future draft we may list the data types that can be used\nin xsl:sort. These are likely to include dayTimeDuration and\nyearMonthDuration but not xsd:duration.\n\nMichael Kay \n\n> -----Original Message-----\n> From: Jeni Tennison [mailto:jeni@jenitennison.com]\n> Sent: 09 May 2002 14:02\n> To: public-qt-comments@w3.org\n> Cc: xsl-editors\n> Subject: XSLT 2.0: Sorting and indeterminate comparisons\n> \n> \n> Hi,\n> \n> [I didn't realise that the email address for XSLT 2.0 comments had\n> changed as well...]\n> \n> This is a follow-on from my last message about indeterminate\n> comparisons between durations and date/times in the F&O WD and\n> sorting. Currently the XSLT 2.0 WD says:\n> \n>   The items in the initial sequence are ordered into a sorted sequence\n>   by comparing their sort keys. The relative position of two items A\n>   and B in the sorted sequence is determined as follows. The first\n>   sort key of A is compared with the first sort key of B, according to\n>   the rules of the first sort key definition. If, under these rules, A\n>   is less than B, then A will precede B in the sorted sequence, unless\n>   the order attribute of this sort key definition specifies\n>   descending, in which case B will precede A in the sorted sequence.\n>   If, however, the relevant sort keys compare equal, then the second\n>   sort key of A is compared with the second sort key of B, according\n>   to the rules of the second sort key definition. This continues until\n>   two sort keys are found that compare unequal. If all the sort keys\n>   compare equal, then A will precede B in the sorted sequence if A\n>   preceded B in the initial sequence, and vice versa.\n> \n>   In general, comparison of two values is performed according to the\n>   rules of the XPath lt operator. However, special rules apply to\n>   certain data types, as described below. [ERR069] It is a dynamic\n>   error if, for any sort key definition, the set of sort keys\n>   evaluated for all the items in the initial sequence, after any type\n>   conversion requested, contains a pair of values for which the result\n>   of the XPath lt operator is an error or an empty sequence. The\n>   processor must either signal the error, or must recover by assigning\n>   an arbitrary ordering to any such pair of values.\n> \n> Given that indeterminate comparisons were allowed, I think that it\n> would be much more helpful if the comparisons between pairs of values\n> were described in terms of only lt rather than lt and eq. The second\n> part of the first paragraph would be:\n> \n>   If, however, B is not less than A, then the second sort key of A is\n>   compared with the second sort key of B, according to the rules of\n>   the second sort key definition. This continues until two sort keys\n>   are found for which A is less than B or B is less than A. If all the\n>   sort keys compare equal, then A will precede B in the sorted\n>   sequence if A preceded B in the initial sequence, and vice versa.\n> \n> For totally ordered data types, this makes no difference. For\n> partially ordered data types, this will create an intuitive ordering,\n> and not require an error to be raised. For example, with the source:\n> \n>   <relationship length=\"P1M\">...</relationship>\n>   <relationship length=\"P21D\">...</relationship>\n>   <relationship length=\"P5Y1D\">...</relationship>\n>   <relationship length=\"P28D\">...</relationship>\n>   <relationship length=\"P3M\">...</relationship>\n> \n> it would be possible to sort them with:\n> \n>   <xsl:for-each select=\"relationship\">\n>     <xsl:sort select=\"@length\" data-type=\"xs:duration\" />\n>     <xsl:copy-of select=\".\" />\n>   </xsl:for-each>\n> \n> in order to get:\n> \n>   <relationship length=\"P21D\">...</relationship>\n>   <relationship length=\"P1M\">...</relationship>\n>   <relationship length=\"P28D\">...</relationship>\n>   <relationship length=\"P3M\">...</relationship>\n>   <relationship length=\"P5Y1D\">...</relationship>\n> \n> without getting an error of any kind.\n> \n> Cheers,\n> \n> Jeni\n> ---\n> Jeni Tennison\n> http://www.jenitennison.com/\n> \n\n\n\n", "id": "lists-017-16522361"}, {"subject": "Data Model W", "content": "Hi,\n\nCongratuations on the new version of the Data Model WD. On the whole,\nit's very clear and well put-together.\n\nI see that you're considering what to do about anonymous types. I\ndon't think that using the empty sequence as their name will help,\nsince that's the only method of access to type information, and would\nimply that:\n\n<xs:element name=\"foo\">\n  <xs:complexType>...</xs:complexType>\n</xs:element>\n\nand:\n\n<xs:element name=\"bar\">\n  <xs:simpleType>...</xs:simpleType>\n</xs:element>\n\nhad the same type. But I think that it's important, particularly for\nsimple types, that they're not just ignored or substituted for\nxs:anySimpleType, especially if you consider anonymous simple type\ndefinitions nested within list and union types. For example:\n\n<xs:simpleType name=\"listOfDatesIn2002\">\n  <xs:list>\n    <xs:simpleType>\n      <xs:restriction base=\"xs:date\">\n        <xs:minInclusive value=\"2002-01-01\" />\n        <xs:maxExclusive value=\"2003-01-01\" />\n      </xs:restriction>\n    </xs:simpleType>\n  </xs:list>\n</xs:simpleType>\n\nSay I had:\n\n  <holidays xsi:type=\"listOfDatesIn2002\">\n    2002-05-06 2002-06-03\n  </holidays>\n\nI can't find the part of the Data Model WD that explains how the\n[schema normalized value], which is the string \"2002-05-06 2002-06-03\"\ngets turned into a sequence of AtomicValues, but I assume that's done\nby splitting the string at spaces and querying the element's type\ndefinition to get hold of the item type definition somehow (a\nparticularly complicated process when the item type is a union type).\n\nIt would be very unhelpful to have these values interpreted as strings\nwhen they're obviously dates. I think that, at least with anonymous\nsimple types, it would be more helpful to use the base type of the\nanonymous simple type than xs:anySimpleType. Perhaps anonymous complex\ntypes could be treated similarly, although that case is more\ncomplicated because of the different types of derivation that could\noccur.\n\n\nOne thing that caused me some confusion on my first read was the way\nthat the typed value of elements is created (Section 4.2). It appears\nthat if an element to have a complex type in the schema, then\ndm:typed-value returns an error, unless it's declared with the complex\ntype xs:anyType, in which case dm:typed-value returns its string\nvalue. The more I think about it, the more it makes sense, since\nxs:anySimpleType is a subtype of xs:anyType, and for consistency with\nthe treatment of well-formed documents, but it might be worth a note\nor a bit of rephrasing.\n\nBy the way, I think that the changes that have been made here have\naddressed the issue I raised about whitespace normalization of element\nvalues (Issue-0073: Whitespace normalization of the string-value of\nelements with simple content).\n\n\nThere's a small typo in Section 5 Atomic Values. It says:\n\n \"XML Schema simple types can be derived by list. Values\n  corresponding to such types are represented by a sequence of atomic\n  values whose type is the base type.\"\n\nPresumably you mean \"whose type is the item type\". The base type of a\nlist type (or a union type) is xs:anySimpleType.\n\n\nThe schema from Appendix D isn't valid at the moment, because the\ncomplex type part-type has an xs:attribute within an xs:sequence. It\nshould be:\n\n  <xs:complexType name=\"part-type\">\n    <xs:sequence>\n      <xs:element name=\"mfg\" type=\"xs:string\"/>\n      <xs:element name=\"price\" type=\"xs:decimal\"/>\n    </xs:sequence>\n    <xs:attribute name=\"name\" type=\"part-name\"/>\n  </xs:complexType>\n\nEven if it were valid, though, the instance document wouldn't be valid\nagainst it. The instance document is:\n\n<?xml version=\"1.0\"?>\n<p:part xmlns:p=\"http://www.example.com/PartSchema\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation = \"http://www.example.com/PartSchema\n                              http://www.example.com/PartSchema\"\n        name=\"NB-401-nutbolt\">\n  <p:mfg>Acme</p:mfg>\n  <p:price>10.50</p:price>\n</p:part>\n\nin which the mfg and price elements are in the\nhttp://www.example.com/PartSchema namespace. However, these elements\nare declared locally within the schema (in the complex type definition\nabove), which means, by default, that they should be in no namespace.\n\nYou should either change the instance document so that the mfg and\nprice elements are in no namespace:\n\n<?xml version=\"1.0\"?>\n<p:part xmlns:p=\"http://www.example.com/PartSchema\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation = \"http://www.example.com/PartSchema\n                              http://www.example.com/PartSchema\"\n        name=\"NB-401-nutbolt\">\n  <mfg>Acme</mfg>\n  <price>10.50</price>\n</p:part>\n\nor add an elementFormDefault attribute with the value 'qualified' to\nthe xs:schema element in the schema:\n\n<xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\n           targetNamespace=\"http://www.example.com/PartSchema\"\n           xmlns=\"http://www.example.com/PartSchema\"\n           elementFormDefault=\"qualified\">\n  ...\n</xs:schema>\n\n\nI hope these comments are helpful.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16535729"}, {"subject": "F&amp;O WD: Issue 16: Is a constructor more than a  different syntax for CAST", "content": "Hi,\n\nYou say that you want comments on Issue 16: Is a constructor more than\na different syntax for CAST?\n\nI think that constructors are different beasts from casts since a\nconstructor implies that a literal string can be tested and converted\nat compile time, whereas a cast implies that it should be tested and\nconverted at run time.\n\nHowever, I don't think that the majority of users will understand this\ndistinction if a functional syntax is used for constructors; I think\nthat they will wonder why they can do xf:date('2002-09-05') but not do\nxf:date(@date). There's a similar situation with the\nprocessing-instruction() node test in XPath 1.0. Until quite recently,\nI believed that you could do processing-instruction($piName) whereas\nactually the processing-instruction() node test has to contain a\nliteral string. I suspect that the only reason this isn't a FAQ is\nthat people don't use processing instructions much.\n\nSo I think there are two options. You could change the syntax for\nconstructors, so that the string that's interpreted to construct the\nvalue doesn't look like a string, perhaps by using a different\ndelimiter, for example:\n\n  xs:date \\2002-09-05\\\n\nOr you could merge casting and construction in a functional syntax,\nand state that if the argument is a literal string, it's a static\nerror if the string is not in the correct format.\n\nI think that merging casting and construction is more friendly to\nusers, as it also prevents people from making the \"mistake\" of using a\ncast when they could use a constructor.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16548735"}, {"subject": "F&amp;O WD: Issue 150: Should we support comparisons  of date/time types that return indeterminate results", "content": "Hi,\n\nYou ask for comments on Issue 150: Should we support comparisons of\ndate/time types that return indeterminate results?\n\nI strongly believe that you should support comparisons between\ndate/time types that return indeterminate results, and between\nduration types that return indeterminate results. I think that this is\na question of finding a balance between logical robustness and\nusability, and that usability should be more important. People\nshould be able to test whether a year is longer than a second, or\nwhether 35 days is longer than a month.\n\nGiven that there's support for dealing properly with error values in\nlogical expressions, why not have indeterminate results return an\nerror? Users can then choose to treat that error as true or false, or\ndeal with it specially, as their application requires.\n\nI think that this is particularly important not for individual\ncomparisons but for the effect that it has on sorting. From what I can\ntell, it's currently not possible to sort elements on attributes that\nare declared with the type xs:duration, without taking extra steps to\nconvert them into one of the two xs:duration subtypes. I don't think\nthat users should be made to jump through this hoop -- it should \"just\nwork\".\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16557261"}, {"subject": "XSLT 2.0: Sorting and indeterminate comparison", "content": "Hi,\n\n[I didn't realise that the email address for XSLT 2.0 comments had\nchanged as well...]\n\nThis is a follow-on from my last message about indeterminate\ncomparisons between durations and date/times in the F&O WD and\nsorting. Currently the XSLT 2.0 WD says:\n\n  The items in the initial sequence are ordered into a sorted sequence\n  by comparing their sort keys. The relative position of two items A\n  and B in the sorted sequence is determined as follows. The first\n  sort key of A is compared with the first sort key of B, according to\n  the rules of the first sort key definition. If, under these rules, A\n  is less than B, then A will precede B in the sorted sequence, unless\n  the order attribute of this sort key definition specifies\n  descending, in which case B will precede A in the sorted sequence.\n  If, however, the relevant sort keys compare equal, then the second\n  sort key of A is compared with the second sort key of B, according\n  to the rules of the second sort key definition. This continues until\n  two sort keys are found that compare unequal. If all the sort keys\n  compare equal, then A will precede B in the sorted sequence if A\n  preceded B in the initial sequence, and vice versa.\n\n  In general, comparison of two values is performed according to the\n  rules of the XPath lt operator. However, special rules apply to\n  certain data types, as described below. [ERR069] It is a dynamic\n  error if, for any sort key definition, the set of sort keys\n  evaluated for all the items in the initial sequence, after any type\n  conversion requested, contains a pair of values for which the result\n  of the XPath lt operator is an error or an empty sequence. The\n  processor must either signal the error, or must recover by assigning\n  an arbitrary ordering to any such pair of values.\n\nGiven that indeterminate comparisons were allowed, I think that it\nwould be much more helpful if the comparisons between pairs of values\nwere described in terms of only lt rather than lt and eq. The second\npart of the first paragraph would be:\n\n  If, however, B is not less than A, then the second sort key of A is\n  compared with the second sort key of B, according to the rules of\n  the second sort key definition. This continues until two sort keys\n  are found for which A is less than B or B is less than A. If all the\n  sort keys compare equal, then A will precede B in the sorted\n  sequence if A preceded B in the initial sequence, and vice versa.\n\nFor totally ordered data types, this makes no difference. For\npartially ordered data types, this will create an intuitive ordering,\nand not require an error to be raised. For example, with the source:\n\n  <relationship length=\"P1M\">...</relationship>\n  <relationship length=\"P21D\">...</relationship>\n  <relationship length=\"P5Y1D\">...</relationship>\n  <relationship length=\"P28D\">...</relationship>\n  <relationship length=\"P3M\">...</relationship>\n\nit would be possible to sort them with:\n\n  <xsl:for-each select=\"relationship\">\n    <xsl:sort select=\"@length\" data-type=\"xs:duration\" />\n    <xsl:copy-of select=\".\" />\n  </xsl:for-each>\n\nin order to get:\n\n  <relationship length=\"P21D\">...</relationship>\n  <relationship length=\"P1M\">...</relationship>\n  <relationship length=\"P28D\">...</relationship>\n  <relationship length=\"P3M\">...</relationship>\n  <relationship length=\"P5Y1D\">...</relationship>\n\nwithout getting an error of any kind.\n\nCheers,\n\nJeni\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16565747"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Martin,\n\nThese comments are based on a quick skim rather than a detailed reading.\n\nLooking at this from an implementer's perspective, I feel it would be \nhelpful if the relationship between the IRI and URI *grammars* were more \nclearly delineated;  e.g. a presentation of IRI syntax that is based on the \nRFC2396bis grammar, replacing a minimum number of productions.  On this \nbasis, it would be easier to see what needs to be changed in a URI parser \nto yield an IRI parser.  Also, I note that the RFC2396bis grammar has been \nthrough several revisions as subtle issues are exposed by review and \nimplementation experience;  by replicating the entire grammar (rather than \nsaying that an IRI is like a URI with designated changes), can you be \nconfident that such issues have not been re-introduced?\n\n...\n\nSection 3.1:\n\nThere is a subtlety here that is not obvious to one not well-versed in \nUnicode specifics:\n[[\n       Variant B) If the IRI is in some digital representation (e.g. an\n          octet stream) in some known non-Unicode character encoding:\n          Convert the IRI to a sequence of characters from the UCS\n          normalized according to NFC.\n\n       Variant C) If the IRI is in an Unicode-based character encoding\n          (for example UTF-8 or UTF-16): Do not normalize. Move directly\n          to Step 2.\n]]\n\nThis raises two questions in my mind:\n\n(a) what is the implication of this NFC stuff;  I think a brief example \nwould help.\n\n(b) by saying \"Move directly to Step 2\" it sounds as if this is saying that \nstep 2 should be operated directly on the \"Unicode-based character \nencoding\" rather than on the UCS characters, which I don't think is what \nyou intend.  I think something like this is intended:\n[[\n       Variant C) If the IRI is in an Unicode-based character encoding\n          (for example UTF-8 or UTF-16): Do not normalize.  Apply step 2\n          directly to the encoded Unicode character sequence.\n]]\n\n...\n\nSection 3.2:\n\nIs this really true (about always mapping back to the same URI)?:\n[[\n3.2  Converting URIs to IRIs\n\n    In some situations, it may be desirable to try to convert a URI into\n    an equivalent IRI. This section gives a procedure to do such a\n    conversion. The conversion described in this section will always\n    result in an IRI which maps back to the URI that was used as an input\n    for the conversion (except for potential case differences in\n    percent-encoding). However, the IRI resulting from this conversion\n    may not be exactly the same as the original IRI (if there ever was\n    one).\n]]\n\nIn light of:\n[[\n    2) Convert all percent-encodings (% followed by two hexadecimal\n       digits) except those corresponding to '%', characters in\n       'reserved', and characters in US-ASCII not allowed in URIs, to the\n       corresponding octets.\n]]\n\nIt seems to me that removing percent encodings for non-reserved and other \ncharacters is a non-reversible transformation.  I think that mapping back \nto the original URI is only true under escape normalization, per rfc2396bis.\n\nAlso, not knowing anything about bidi encodings, it's difficult for me to \ntell if there's any possible interaction between this and the section 4 \nmaterial on bidi sequences.\n\n...\n\nSection 5.1:\n\n[[\n5.1  Simple String Comparison\n\n    In some scenarios a definite answer to the question of IRI\n    equivalence is needed that is independent of the scheme used and\n    always can be calculated quickly and without accessing a network. An\n    example of such a case is XML Namespaces ([XMLNamespace]). In such\n    cases, two IRIs SHOULD be defined as equivalent if and only if they\n    are character-by-character equivalent. This is the same as being\n    byte-by-byte equivalent if the character encoding for both IRIs is\n    the same. As an example,\n    http://example.org/~user, http://example.org/%7euser, and\n    http://example.org/%7Euser are not equivalent under this definition.\n    In such a case, the comparison function MUST NOT map IRIs to URIs,\n    because such a mapping would create additional spurious equivalences.\n]]\n\nIt's not clear to me what the MUST NOT here is saying.  Making normative \nstatements that are conditional on some postulated application scenario \nseems to be a bit confusing to me.   I think the final sentence maybe \nshould be:\n[[\nThe IRI to URI mapping function described above [ref] does not preserve \nthis form of equivalence.\n]]\n\n(Further, the MUST NOT here seems even more perverse in light of the \nintroductory material in section 3.1)\n\nI suspect there should be some discouragement of applications depending on \nthis level of equivalence, in view of the spurious distinctions that are \nlost when IRIs are converted to URIs.   To my mind the string equivalence \nof the URI-converted form seems like the lowest reasonable level of \ndistinction to be encouraged.\n\n...\n\nSection 5.2:\n\nThe MUST in the second paragraph seems to be straying inappropriately into \napplication design territory.\n\n...\n\nReferences\n\nI think RFC2119 should appear under Normative references, not Informative.\n\nI don't know about this, but should [UNIV4] and [UNI9] be normative?\n\n...\n\nFinally, I find myself being vaguely concerned about the complexity and \nsubtlety of this specification.  I expect that a lot of software will be \nwritten by programmers who are not aware of the various subtle implications \nof I18N issues.  As such, will it be a realistic expectation for such \nprogrammers to write robust interoperable software based on this \nspecification.  Or, another way of addressing this concern:  to what extent \ncan the various subtleties described here be wrapped up in a library that \ncan be used successfully by a programmer who is not expert in I18N issues?\n\n(I think part of the difficulty here is the extent to which IRIs straddle \nwire-protocol and user presentation concerns.  I don't normally advocate \nthe idea of standardized APIs, but wonder if this is a case for which \ndefining a common API might help to flush out some of these concerns.)\n\n#g\n--\n\nAt 11:07 10/05/04 +0900, Martin Duerst wrote:\n\n>Dear URI Experts,\n>\n>Yesterday, I have announced a 2 week mailing list last call on the\n>public-iri@w3.org mailing list for the newest version of the IRI\n>spec, which you can find at\n>http://www.w3.org/International/iri-edit/draft-duerst-iri-07.txt.\n>Additional information is at http://www.w3.org/International/iri-edit/.\n>The last call ends on Sunday, May 23, 2004.\n>\n>I'm copying this announcement (see below) here because the IRI\n>draft relies strongly on RFC 2396bis.\n>\n>So if you have any comments (I of course hope they will be mainly\n>of editorial nature), please send them to public-iri@w3.org\n>(and not to this list) by May 23.\n>\n>Regards,   Martin.\n>\n>>Date: Sun, 09 May 2004 21:46:44 +0900\n>>To: public-iri@w3.org\n>>From: Martin Duerst <duerst@w3.org>\n>>Subject: 2 week mailing list last call\n>>X-Archived-At: \n>>http://www.w3.org/mid/4.2.0.58.J.20040509212717.059f56b8@localhost\n>>\n>>With no open issues and only two tentatively closed ones remaining,\n>>I just submitted draft-duerst-iri-07.txt to the Internet-Drafts\n>>Editor. It is also available at\n>>http://www.w3.org/International/iri-edit/draft-duerst-iri-07.txt.\n>>\n>>If you find any new issues think that an old one needs to be reopened,\n>>please say so on this mailing list (public-iri@w3.org) within the next\n>>two weeks (up to and including Sunday, May 23).\n>>If no significant changes are required, I will send this spec\n>>to the IESG afterwards.\n>>\n>>In other words, this is a two-week mailing list last call.\n>>\n>>Regards,    Martin.\n>\n>------------\n>Graham Klyne\n>For email:\n>http://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1657162"}, {"subject": "Re: XSLT 2.0: Sorting and indeterminate  comparison", "content": "Ashok,\n\n> We are trying to get away from indeterminate comparisons. Our\n> attempt is to deprecate 'duration' and have users use two totally\n> ordered subtypes of duration called 'yearMonthDuration' and\n> 'dayTimeDuration'.\n\nYes, I understand that and I've read that part of the F&O WD. I think\nthat decision is completely wrong-headed -- absolutely horrendous,\nactually -- which is why I'm commenting on it. I thought that was the\npoint of making working drafts public and inviting people to review\nthem.\n\nI don't think that it's XQuery/XPath's job to dictate what data types\npeople use in their schemas, and I think that attempts to do so are\nlikely end in failure and frustration, mostly for those people who are\nunfortunate enough to have to work with it.\n\nI think more effort should be made thinking about what people *do*\nwant to do or *might* want to do, and less trying to dictate what they\n*should* want to do.\n\nCheers,\n\nJeni\n\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16577232"}, {"subject": "XSLT 2.0 light", "content": "Dear XSLT WG,\n\nFirst of all I really appreciate all the hard work put into the XSLT 2.0 \nand related specs. The new grouping facilities look wonderful, and the \nresult tree fragment is a particularly good riddance. I apologize in \nadvance for the whining to come...\n\nI have one, rather big, problem with the spec in its current form: I \ndon't understand it. Suddenly, to understand XSLT, I have to understand \nthe XML Schema spec (and I'm, regretfully, having a hard time already at \nhttp://www.w3.org/TR/xmlschema-1/) and in particular the PSVI, the \nmodified PSVI as defined by the XQuery/XPath data model, the XQuery \nformal semantics, the multitude of language about types in the XPath \nspecs themselves, and what have you. And I don't, quite frankly.\n\nThat leaves me with little hope of understanding what an arbitrary XSLT \n2.0 style sheet actually does - and this bothers me. It may be that I'm \nunusually slow, or that there will appear some article any day now that \nwill make all the intricacies of the type system clear to slow people \nlike me, but I'm still worried.\n\nTo me, it seems that the step from XSLT 1 to XSLT 2 is way bigger than, \nsay, from K&R C to the latest C++ standard. And that's a rather big step.\n\nSo: Most of all, I would like to see XSLT 2 minus the type system.\n\nSeeing that this may be unrealistic, I would very much like to see a \nnamed conformance level for XSLT/XPath 2 that doesn't involve the type \nsystem (in other words: something like XSLT 2 + XPath 1, essentially). I \nwould also like a way to tell the XSLT processor to use ONLY that level, \nsay by means of xsl:version=\"2.0-light\" or somesuch.\n\nBarring that, an XSLT 1.1 consisting of XSLT 1.0 + grouping + multiple \noutput documents - result tree fragments would be more than great for my \nconcerns.\n\nAgain, thank you for your good work, and for your time,\n\n/dan\n--\nDan Holmsand\ndan@eyebee.com\n\n\n\n", "id": "lists-017-16586131"}, {"subject": "Re: [xml-dev] XPath 2.0  how much of XQuery should it include", "content": "> Is it a mistake for XPath to try to incorporate so much of XQuery, or is \n> this what users really want?\n\nJeni's answered many of the technical issues, but just to pick up on\nthis question which goes I think to the heart of the problem.\nThe way the question is phrased highlights the warped view of history\nthat has caused Xpath2 to be so alien. Xpath is an existing language,\nand Xquery is just a draft spec, so the question shouldn't be about\nXpath incorporating Xquery, but rather \n\nWhy has Xquery failed to pick up on so many of the lessons learned from\nover two years of Xpath use?\n\n\nLook at the only comparable thing to supporting schema types in Xpath1\nDTD ID support and the id() function. Have users been crying out for\nmore of this? No! The usual advice is to use xsl defined keys instead.\n\nJeni said:\n\n  - dereferences -- id(), which does basically the same thing, is\n    very rarely used because people tend to want to make their\n    stylesheets robust in case DTDs aren't available for some reason,\n    so use key() instead. I don't see that dereferencing will be any\n    different, although if it used XML Schema identity constraints it\n    would be a lot more compelling\n\n\nUsing XSL keys allows you to tune your index to the needs of the\nstylesheet rather than whatever features the author of the dtd/schema\nfor that document type thought might be useful things to index on. They\nalso protect the stylesheet from optional behaviour by XML parsers which\nmight or might not report the ID information.\n\nSo what does Xpath 2 do?\n\nFirstly it provides the bizarre => operator which is a restricted\nversion of id(), then for all the new types it stresses the id()\napproach of inferring type information which might possibly be supplied\nby a suitable parser, rather than the approach that has proved far more\nrobust, allowing the stylesheet to specify what types it wants to use\nfor the content of certain elements.\n\nDavid\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-16594906"}, {"subject": "Re: [xml-dev] XPath 2.0  how much of XQuery should it include", "content": "> (b) you have to write it in XML Schema rather than XQuery/XSLT.\n\nwhich rather drives a hole through the argumment that XPath2 is not\ndependent on Schema but takes a PSVI from any source.\n\nIf I wanted all elements matching copyright/date to be years I'd much\nrather do something like xsl:key specifying an Xpath match, together\nwith a type. Given that I have Xpath available why should I go to a\ncompletely different language to specify some subcollection of my\nelements that should be dates?\n\n> There are still issues here:\nyes.\n\nDavid\n\n_____________________________________________________________________\nThis message has been checked for all known viruses by Star Internet\ndelivered through the MessageLabs Virus Scanning Service. For further\ninformation visit http://www.star.net.uk/stats.asp or alternatively call\nStar Internet for details on the Virus Scanning Service.\n\n\n\n", "id": "lists-017-16605891"}, {"subject": "Re: [xml-dev] XPath 2.0  how much of XQuery should it include", "content": "At 12:35 PM 5/10/2002 +0100, Jeni Tennison wrote:\n>I do think that it's a lot easier to add features to a language than\n>it is to take them away; XPath 2.0 should be *core* functionality, not\n>XQuery minus node-constructors. And the other users of XPath --\n>XPointers, XForms, XML Schema, should be considered as well.\n\nI think most people seem to be agreeing with you.\n\nDoes anyone disagree?\n\nJonathan\n\n\n\n", "id": "lists-017-16614731"}, {"subject": "RE: F&amp;O WD: Issue 150: Should we support comparisons  of date/tim e types that return indeterminate results", "content": "Thanks for the comment.\n\nDealing with partial ordering causes many problems, and therefore surprises.\nFor example it means that the user (and the optimizer) can no longer rely on\ninvariants such as A<B => not(A>=B). It causes particular problems for\nimplementors (such as Microsoft) who want to map XQuery to an underlying SQL\ndatabase. We've been hoping to find a way of avoiding this level of\ncomplexity. In the case of durations, one solution I proposed was to achieve\na total ordering by equating a month to 365.242199 div 12 days; this would\nmean 12 months > 365 days and 12 months < 366 days, which would at least be\ncomprehensible even if not always what the user wanted. Unfortunately it\ngets complicated when you look at the interactions with addition of\ndurations to dates, where you want some invariants like DATE1 + DURATION1 <\nDATE1 + DURATION2 iff DURATION1 < DURATION2. So we decided to park the\nproblem on the back burner by disallowing the awkward cases for the time\nbeing. Better to disallow them now than to allow them with semantics that we\nwill regret later.\n\nMichael Kay\n\n> -----Original Message-----\n> From: Jeni Tennison [mailto:jeni@jenitennison.com] \n> Sent: 09 May 2002 13:37\n> To: public-qt-comments@w3.org\n> Subject: F&O WD: Issue 150: Should we support comparisons of \n> date/time types that return indeterminate results?\n> \n> \n> Hi,\n> \n> You ask for comments on Issue 150: Should we support \n> comparisons of date/time types that return indeterminate results?\n> \n> I strongly believe that you should support comparisons \n> between date/time types that return indeterminate results, \n> and between duration types that return indeterminate results. \n> I think that this is a question of finding a balance between \n> logical robustness and usability, and that usability should \n> be more important. People should be able to test whether a \n> year is longer than a second, or whether 35 days is longer \n> than a month.\n> \n> Given that there's support for dealing properly with error \n> values in logical expressions, why not have indeterminate \n> results return an error? Users can then choose to treat that \n> error as true or false, or deal with it specially, as their \n> application requires.\n> \n> I think that this is particularly important not for \n> individual comparisons but for the effect that it has on \n> sorting. From what I can tell, it's currently not possible to \n> sort elements on attributes that are declared with the type \n> xs:duration, without taking extra steps to convert them into \n> one of the two xs:duration subtypes. I don't think that users \n> should be made to jump through this hoop -- it should \"just work\".\n> \n> Cheers,\n> \n> Jeni\n> ---\n> Jeni Tennison\n> http://www.jenitennison.com/\n> \n> \n\n\n\n", "id": "lists-017-16624166"}, {"subject": "RE: F&amp;O WD: Issue 16: Is a constructor more than a  different syn tax for CAST", "content": "Thanks. We are going to be looking at a proposal to merge constructors and\ncasts at our next meeting (with luck).\n\nMichael Kay\n\n> -----Original Message-----\n> From: Jeni Tennison [mailto:jeni@jenitennison.com] \n> Sent: 09 May 2002 12:07\n> To: public-qt-comments@w3.org\n> Subject: F&O WD: Issue 16: Is a constructor more than a \n> different syntax for CAST?\n> \n> \n> Hi,\n> \n> You say that you want comments on Issue 16: Is a constructor \n> more than a different syntax for CAST?\n> \n> I think that constructors are different beasts from casts \n> since a constructor implies that a literal string can be \n> tested and converted at compile time, whereas a cast implies \n> that it should be tested and converted at run time.\n> \n> However, I don't think that the majority of users will \n> understand this distinction if a functional syntax is used \n> for constructors; I think that they will wonder why they can \n> do xf:date('2002-09-05') but not do xf:date(@date). There's a \n> similar situation with the\n> processing-instruction() node test in XPath 1.0. Until quite \n> recently, I believed that you could do \n> processing-instruction($piName) whereas actually the \n> processing-instruction() node test has to contain a literal \n> string. I suspect that the only reason this isn't a FAQ is \n> that people don't use processing instructions much.\n> \n> So I think there are two options. You could change the syntax \n> for constructors, so that the string that's interpreted to \n> construct the value doesn't look like a string, perhaps by \n> using a different delimiter, for example:\n> \n>   xs:date \\2002-09-05\\\n> \n> Or you could merge casting and construction in a functional \n> syntax, and state that if the argument is a literal string, \n> it's a static error if the string is not in the correct format.\n> \n> I think that merging casting and construction is more \n> friendly to users, as it also prevents people from making the \n> \"mistake\" of using a cast when they could use a constructor.\n> \n> Cheers,\n> \n> Jeni\n> ---\n> Jeni Tennison\n> http://www.jenitennison.com/\n> \n\n\n\n", "id": "lists-017-16636524"}, {"subject": "RE: XSLT 2.0 light", "content": "Thanks for the comments. You're not alone in finding XML Schema Part 1\ndifficult to digest. Clearly in writing specs it's not our job to produce a\ntutorial, but we can certainly bear your comments in mind. In particular, I\nthink we probably need to be clearer about how processing happens in the\nabsence of a schema: at the moment we rather rely on people knowing that\nthis is just a special case of the PSVI, and the specs concentrate on\ndescribing the general case which is of course much more complex.\n\nI think some features of the XPath 2.0 type system are things you are just\ngoing to have to live with. The introduction of sequences, I think, brings\nmany benefits. The expansion from the three scalar types (boolean, double,\nand string) of XPath 1.0 to the 19 primitive types of XML Schema is a larger\nexpansion than many of us would have liked, but many of the primitive types\nwill hardly ever be used so you will be able to ignore them most of the\ntime. Complex types arise only when using schemas, and again I hope we can\nensure that when you don't use a schema, you don't really need to be aware\nof them.\n\nThere will probably be a conformance level in XSLT 2.0 that doesn't require\nschema support; defining conformance levels is something we have not yet\ntackled.\n\nMichael Kay\n\n\n> \n> Dear XSLT WG,\n> \n> First of all I really appreciate all the hard work put into \n> the XSLT 2.0 \n> and related specs. The new grouping facilities look \n> wonderful, and the \n> result tree fragment is a particularly good riddance. I apologize in \n> advance for the whining to come...\n> \n> I have one, rather big, problem with the spec in its current form: I \n> don't understand it. Suddenly, to understand XSLT, I have to \n> understand \n> the XML Schema spec (and I'm, regretfully, having a hard time \n> already at \n> http://www.w3.org/TR/xmlschema-1/) and in particular the PSVI, the \n> modified PSVI as defined by the XQuery/XPath data model, the XQuery \n> formal semantics, the multitude of language about types in the XPath \n> specs themselves, and what have you. And I don't, quite frankly.\n> \n> That leaves me with little hope of understanding what an \n> arbitrary XSLT \n> 2.0 style sheet actually does - and this bothers me. It may \n> be that I'm \n> unusually slow, or that there will appear some article any \n> day now that \n> will make all the intricacies of the type system clear to slow people \n> like me, but I'm still worried.\n> \n> To me, it seems that the step from XSLT 1 to XSLT 2 is way \n> bigger than, \n> say, from K&R C to the latest C++ standard. And that's a \n> rather big step.\n> \n> So: Most of all, I would like to see XSLT 2 minus the type system.\n> \n> Seeing that this may be unrealistic, I would very much like to see a \n> named conformance level for XSLT/XPath 2 that doesn't involve \n> the type \n> system (in other words: something like XSLT 2 + XPath 1, \n> essentially). I \n> would also like a way to tell the XSLT processor to use ONLY \n> that level, \n> say by means of xsl:version=\"2.0-light\" or somesuch.\n> \n> Barring that, an XSLT 1.1 consisting of XSLT 1.0 + grouping + \n> multiple \n> output documents - result tree fragments would be more than \n> great for my \n> concerns.\n> \n> Again, thank you for your good work, and for your time,\n> \n> /dan\n> --\n> Dan Holmsand\n> dan@eyebee.com\n> \n> \n\n\n\n", "id": "lists-017-16647081"}, {"subject": "RE: email change without notification", "content": "> Why has the email address changed please,\n> without informing recipients?\n> \nAfter the December round of publications, there were several public comments\nthat said people didn't know which address to send their comments to,\nbecause they affected more than one specification. In response, we decided\nto set up a single address for comments on all the documents. The new\naddress is given as the comments address in each of the documents (except,\nby accident, Functions and Operators). Perhaps we should also have notified\nsubscribers to the existing lists - sorry.\n\nMichael Kay\n\n\n\n", "id": "lists-017-16658287"}, {"subject": "Re: [xml-dev] XPath 2.0  how much of XQuery should it include", "content": "Hi Jonathan,\n\n[Moved to public-qt-comments@w3.org]\n\n> Mike Kay forwarded your email to our internal lists. I will try to\n> summarize the results of this thread for the XPath task force, and\n> ask for this to be put on our agenda.\n\nI don't think it's anything I haven't said before, including on the\ncomments lists.\n\n>>XPath 2.0 incorporates a number of *statements* that are already\n>>provided by XSLT 2.0. The for \"expression\" and the if \"expression\"\n>>would be classed as statements in any other language.\n>\n> The reason they are not called statements in XPath 2.0 is that XPath\n> 2.0, like XQuery, is a functional language, and it doesn't really\n> have statements. They do resemble traditional statements\n> syntactically, but these are expressions to be evaluated, not\n> statements to be executed. Is the syntactic form the problem - that\n> it looks too much like the XSLT statements?\n\nI think that might be part of the problem. As others pointed out, I'm\nwrong to think in terms of expressions and statements, but I think\nanyone that doesn't have a large dose of Lisp/Scheme etc. in their\nblood (i.e. the majority of people working with XSLT, most of whom are\neither programmers in the VB/Java line, or not programmers at all)\nwill think in these terms.\n\nThere seems like there should be a qualitative distinction between the\njobs that XPath and XSLT carry out. I've demonstrated through my posts\nhere that I'm surpremely unable to articulate what the distinction\nshould be, but I know it ain't the one that's being made at the\nmoment.\n\n>>   - for expressions, because XSLT has xsl:for-each, although I do\n>>     think that a simple mapping operator would be essential if there\n>>     weren't for expressions\n>>\n>>   - conditional expressions, as they currently are, because XSLT has\n>>     xsl:if and xsl:choose, although I do think that a simple\n>>     conditional expression (i.e. test ? true : false) would be vital\n>>     if there weren't if expressions\n>\n> For these two, you are essentially asking for a simpler syntax to be\n> used in XPath to express a subset of the functionality of existing\n> expressions in XQuery. I am a little allergic to this, because that\n> means that XQuery would probably have to support both, moving the\n> duplication out of XPath and into XQuery. Is changing the syntax of\n> if and for important enough to justify this?\n\nYes. I can see why you'd be slightly allergic to it, but I think it\nactually simplifies the things that you'd want to do as well. Instead\nof:\n\n<results>\n{\n    for $b in document(\"http://www.bn.com\")/bib/book\n    return\n        <result>\n            { $b/title }\n            { $b/author  }\n        </result>\n}\n</results>\n\nYou could use:\n\n<results>\n  {\n  document(\"http://www.bn.com\")/bib/book\n    -> <result> {title} {author} </result>\n  }\n</results>\n\nRather than:\n\n<bib>\n  {\n    for $b in document(\"www.bn.com/bib.xml\")//book\n    where count($b/author) > 0\n    return\n        <book>\n            { $b/title }\n            {\n                for $a in $b/author[position()<=2]  \n                return $a\n            }\n            {\n                if (count($b/author) > 2)\n                then <et-al/>\n                else ()\n            }\n        </book>\n  }\n</bib>\n\nYou could use:\n\n<bib>\n  {\n    for $b in document(\"www.bn.com/bib.xml\")//book\n    where count($b/author) > 0\n    return\n        <book>\n            { $b/title }\n            { $b/author[position() <= 2] -> . }\n            { (count($b/author) > 2) ? <et-al/> : () }\n        </book>\n  }\n</bib>\n\nBasically, with the for expression, it saves you from having to make\nup variable names for the simplest kind of for expression, which is\njust a mapping of an expression over the items in that sequence.\n\nIt's also handy when you need to have the sequence that you iterate\nover with the for expression be generated with another for expression\n-- a lot like the / operator, but for general sequences.\n  \nI've been told that XQuery people don't like the \"line noise\" of\nXPath, and prefer to use keywords instead. In some ways that's because\nyou have the whole document to play within; in XSLT, we have to put\neverything in attribute values -- XPath is the concise side of the\nXSLT+XPath language -- so short is best.\n\nSo if you don't want to have a short syntax, an alternative compromise\nwould be to have a really small core of XPath, smaller than XPath 1.0,\nsomething that incorporated only the operators/functions/axes that are\nused across XPath 1.0, XQuery, XPointer, XML Schema and XForms, then\nhave XSLT extend this with a few axes, operators and functions, to\ncreate a XSLT-version of XPath that addresses the requirements of XSLT\nusers.\n\n\nSince you like use cases, to demonstrate why this is important for\nXSLT+XPath, let me use an amended version of one of the XQuery use\ncases, 1.4.4.6. The query is \"For each item whose highest bid is more\nthan twice its reserve price, list the item number, description,\nreserve price, and highest bid.\" Let's say that instead it was \"Return\na sequence of the highest bids of those items whose highest bid is\nmore than twice its reserve price.\"\n\nSince we want to return a sequence of values, and XSLT 2.0 doesn't\nsupport the generation of sequences of existing nodes, we need to do\nthis with XPath. The original query is:\n\n for $item in document(\"items.xml\")//item_tuple\n    let $b := document(\"bids.xml\")//bid_tuple[itemno = $item/itemno]\n    let $z := max(for $x in $b/bid return decimal($x))\n    where $item/reserve_price * 2 < $z\n    return $z\n\nAn XPath/XSLT version would be:\n\n  <xsl:variable name=\"bids\"\n                select=\"document('bids.xml')//bid_tuple\" />\n  <xsl:variable name=\"highest-bids\"\n    select=\"for $item in document('items.xml')//item_tuple\n                           [reserve_price * 2 <\n                            max(for $x in $bids[itemno = $item/itemno]\n                                return decimal($x))]\n            return max(for $x in $bids[itemno = $item/itemn]\n                       return decimal($x))\" />\n  \nOf course most people will simplify this by defining a function that\nwill calculate the maximum bid for a particular item, though the fact\nthat you can't assign values to variables in XPath means that unless\nyou've got fairly sophisticated memoisation, you're going to be\ncalculating the maximum bid twice for each item.\n\nThe version that I'm proposing is:\n\n  <xsl:variable name=\"bids\"\n                select=\"document('bids.xml')//bid_tuple\" />\n  <xsl:variable name=\"highest-bids\">\n    <xsl:for-each select=\"document('items.xml')//item_tuple\">\n      <xsl:variable name=\"b\"\n                    select=\"$bids[itemno = current()/itemno]\" />\n      <xsl:variable name=\"z\" select=\"max($b/bid -> decimal(.))\" />\n      <xsl:if test=\"reserve_price * 2 < $z\">\n        <xsl:item select=\"$z\" />\n      </xsl:if>\n    </xsl:for-each>\n  </xsl:variable>\n\nSay that I then decided that I wanted the $highest-bids variable to\nhold a sequence of <bid> elements instead, so that I could include\ninformation on the reserve price on them. With the current syntax,\nbecause this process now involves generating nodes rather than values,\nI have to use XSLT to do the sequence generation. I guess there are a\ncouple of ways I could do it. I could reuse my existing code:\n\n  <xsl:variable name=\"bids\"\n                select=\"document('bids.xml')//bid_tuple\" />\n  <xsl:variable name=\"highest-bids-temp\"\n    select=\"for $item in document('items.xml')//item_tuple\n                           [reserve_price * 2 <\n                            max(for $x in $bids[itemno = $item/itemno]\n                                return decimal($x))]\n            return max(for $x in $bids[itemno = $item/itemn]\n                       return decimal($x))\" />\n  <xsl:variable name=\"highest-bids\">\n    <xsl:for-each select=\"document('items.xml')//item_tuple\">\n      <xsl:variable name=\"p\" select=\"position()\" />\n      <bid reserve=\"{reserve_price}\">\n        <xsl:value-of select=\"$highest-bids-temp[$p]\" />\n      </bid>\n    </xsl:for-each>\n  </xsl:variable>\n\nor I could completely rewrite it:\n\n  <xsl:variable name=\"bids\"\n                select=\"document('bids.xml')//bid_tuple\" />\n  <xsl:variable name=\"highest-bids\">\n    <xsl:for-each select=\"document('items.xml')//item_tuple\">\n      <xsl:variable name=\"b\"\n                    select=\"$bids[itemno = current()/itemno]\" />\n      <xsl:variable name=\"z\"\n                    select=\"max(for $x in $b return decimal($x))\" />\n      <xsl:if test=\"reserve_price * 2 < $z\">\n        <bid reserve=\"{reserve_price}\">\n          <xsl:value-of select=\"$z\" />\n        </bid>\n      </xsl:if>\n    </xsl:for-each>\n  </xsl:variable>\n\nwhich is obviously very similar to the version that you'd use with the\ndesign that I'm suggesting; it's very easy to change that version to\nthe one above.\n\nPerhaps people won't have to change code between creating new nodes\nand returning sequences of existing nodes or atomic values that often,\nI'm not sure, but they will have to change their thinking between the\ntwo tasks frequently. In XQuery, the two mechanisms are exactly the\nsame, which makes it very easy to know how to approach a given task. I\njust want that to be true in XSLT as well.\n\n>>Other things I feel less strongly about; I wouldn't abandon XPath 2.0\n>>if they remained, but I don't particularly see the point of them (or\n>>the requirement, if you want to go by use cases):\n>>\n>>   - comments in XPaths -- if an XPath gets long enough that you need\n>>     to embed comments in it, you should break it up and use XML\n>>     comments instead\n>\n> Or perhaps we need to think about how to use XQuery and XSLT\n> together, so that people can use XQuery when they need complex\n> expressions like these.\n\nI think that what people need is more support in XSLT, not another\nlanguage tacked on to XSLT.\n\nTo be honest, I think that the kind of merger that people have in mind\nwhen they talk about using XQuery and XSLT together is to replace XSLT\nwith XQuery. Much as I can see the advantages of XQuery, I do think\nthat there are advantages to having an XML syntax, such as the fact\nthat it can be parsed by existing tools, edited in existing editors,\neasily manipulated by other programs and so on, so I don't want to see\nthat go.\n\nIf there was to be a merger, I'd like to see XSLT becoming the XML\nsyntax for XQuery. If people viewed it like that, they might start to\nunderstand why there doesn't need to be replicated functionality in\nXPath and XSLT.\n\n>>   - the \"union\" operator -- when is it ever a good idea to have more\n>>     than one symbol for the same operator?\n>\n> Would you want the 'intersect' operator in XPath? If so, I would\n> rather use 'union' and 'intersect' than '|' and 'intersect'.\n\nYes, I do want the 'intersect' and more importantly 'except' operators\nin XPath. If you were designing the language from scratch, your\nargument would be valid. But you're not, you're building on top of\nXPath, and XPath already has '|'. I know it's not consistent with the\nrest of the naming scheme. I'm sorry.\n\n>>   - eq/ne/lt/gt/ge/le -- these do exactly the same as =/!=/</>/>=/<=.\n>>     The only difference for XPath (as far as I can see) is that if the\n>>     arguments are sequences then they (due to fallback processing)\n>>     compare the first of the items in those sequences rather than\n>>     every combination of values of those sequences. I can't think of\n>>     any occasion in which that's useful.\n>\n> I bet you rewrote that last sentence three times before you came up\n> with a formulation this polite ;->\n\nI wrote the entire email three times! ;)\n\n>>You didn't want me to go into the functions, did you?...\n>\n> Oh yes!!! The status quo is that XPath is going to inherit the\n> entire function library. If you don't want this, let's hear the\n> feedback.\n\nOK, I'll work through it in detail. My main impression of the December\ndrafts is that it basically provides more or less the same set of\nfunctions (if you ignore all the constructors and operators), but with\n(it appears to me) less detailed descriptions (though more examples,\nwhich are great), without consideration of the functions that have\nbeen requested for XPath 2.0 by XPath 1.0 users (and implemented in\nlibraries such as EXSLT and FXSL), and without consideration about how\neasy it's going to be for people to use the functions to achieve real\ntasks. But I'd like to be able to make more constructive comments\nabout individual functions... there's just so darned much to go\nthrough.\n\n> I wonder if anybody has time to raise this subject on\n> xsl-list@lists.mulberrytech.com. I don't have time to participate in\n> another active discussion, but it would be interesting to see\n> whether those people agree.\n\nTo be honest, I doubt whether many people have had the energy to go\nthrough the WDs, so any opinion they do have will have been formed by\nthe generally positive demonstrations of XSLT 2.0 that there have been\non the list or by the generally negative impression that XPath 2.0 is\nbased on the PSVI and therefore hideously complex because XML Schema\nis hideously complex.\n\nIt's hard to get an objective assessment, given that most people who\ncould raise the question would have their own bias. Perhaps Max could\nask for people's opinions on individual features.\n\n> The main reason that has been given for including all these features\n> in XPath is the claim that XSL users really want them. If that's not\n> the case, I really think we should keep XPath simpler.\n\nWe want the functionality, we just don't want all of it in XPath.\n\nCheers,\n\nJeni\n\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16666635"}, {"subject": "xpath 2.0 comment", "content": "hi,\nI guess people are getting their comments in now, I pretty much feel the\nsame as the rest of the community I think, that while xsl-t 2.0 is\nreasonable, xpath 2.0 is awful, so far at least.\n \nStuff I don't like:\n    \n    1.  if, for expressions, leave that to scripting technologies, xsl-t\nthat use xpath. People seem to be expressing some trepidation on writing\nxpaths in the proposed version, hey, I'm afraid of trying to debug\ntransforms, and it seems to me the ability to have conditional\nexpressions will increase the capacity to screw up a transform without a\nvery great enhancement of its abilities. \nJeni Tennison remarked in an email some months back to me on the subject\nthat we could always hope that processors will give good error messages,\nI personally have never been a great believer in the existence of good\nerror messages. \n    2. comments, I think this will just increase the illegibility of an\nxpath, it's a pretty compact syntax and comments in the middle will do\nthe opposite of what people hope comments will, i.e improve legibility.\nEnvision comments in complicated regular expressions.\n    3.  I've been a pain elsewhere talking against the tight integration\nwith xml schema, this seems to me especially wrong headed. But hell I\nguess it's coming.\n \n \n \n \nStuff I like\n  I'm writing this part because my mother always taught me to end on an\nupbeat note, that said I'd be willing to do without the stuff I like if\nI could get rid of the stuff I dislike.\n    1. Sequences, ranges of sequences.\n    2. some of the functions, although some of them I can't get at all,\nlike for example xf:Unique-ID() \"assigned by the User\" huh? That said,\nexcess functions could be problematic, will not gripe about any if I can\nget rid of if, for expressions.\n \n \n\n\n\n", "id": "lists-017-16689442"}, {"subject": "XPath 2.0 Requirements  Suggestion", "content": "I would like to suggest that the title of the document is updated to read \n\"XPath Version 2.0 Requirements\" rather than its current form.\n\nI would also like to suggest that the Working Group replace the phrase \"XPath \n2.0 has the following goals\" in 1. Goals with something less fatuous. Such \nanthropomorphic references to a technology serve only to conceal the \nrationale for a particular approach. And the rationale for the approach taken \nto XPath 2.0 is something that deserves more open discussion.\n\nPerhaps change the phrase to, \"The XPath 2.0 Working Group has the following \ngoals for XPath 2.0 ...\".\n\nFor each goal I would suggest a brief statement be added describing the \nbenefits anticipated for/from the goal, and a description of who benefits and \nwho is disadvantaged by the change.\n\nI would also like to suggest that an explicit Goal \"That XPath 2.0 does not \nadd unnecessary and irrelevant complexity for users of XSLT\" be added to an \nupdated Requirements document.\n\nAndrew Watt\n\n\n\n", "id": "lists-017-16697899"}, {"subject": "XPath 2.0  Implications of typing for XPointe", "content": "If XPath 2.0 is to support XPointer is there not a case for a much smaller \nXPath 2.0 specification which (as with XPath 1.0) corresponds to common \nfunctionality of XSLT and XPointer? To that can be added (as a distinct \nmodule) whatever additional functionality is relevant to XQuery 1.0.\n\nIt would also be useful to have some indication of how typing is to be \nhandled for XPointer points and ranges.\n\nAndrew Watt\n\n\n\n", "id": "lists-017-16705646"}, {"subject": "XPath 2.0  the relevance of XPointer", "content": "In Chapter 1.2 of the XPath 2.0 Requirements WD it is stated: \"The scope of \nXPath 2.0 must be the set of common functionality between the expression \nlanguage of XSLT 2.0 and the expression language of XML Query 1.0.\".\n\nSince XPath 1.0 contains functionality common to XSLT 1.0 and XPointer 1.0, \nthe absence of mention of XPointer should be explained and justified.\n\nIs the absence of mention of XPointer in the Requirements document an \nimplicit indication that XPointer is to be dumped by the W3C? Or is it a \nconscious or unconscious oversight on the part of the WG?\n\nAndrew Watt\n\n\n\n", "id": "lists-017-16712968"}, {"subject": "RE: email change without notification", "content": "And just in case these haven't got the editors,\nplease note the comments at\nhttp://lists.xml.org/archives/xml-dev/200205/msg00548.html\n\nA fair critique?\nI am most concerned over the complexity issue for use\nin XSLT. \n\nRegards DaveP.\n\n\n\n> Why has the email address changed please,\n> without informing recipients?\n> \n> Perhaps due to the expected response\n> to the swamping of xpath2?\n> \n> Regards DaveP\n> AC RNIB.\n> \n> ************snip here************** \n> \n> - \n> \n> NOTICE: The information contained in this email and any \n> attachments is \n> confidential and may be legally privileged. If you are not the \n> intended recipient you are hereby notified that you must not use, \n> disclose, distribute, copy, print or rely on this email's content. If \n> you are not the intended recipient, please notify the sender \n> immediately and then delete the email and any attachments from your \n> system.\n> \n> RNIB has made strenuous efforts to ensure that emails and any \n> attachments generated by its staff are free from viruses. However, it \n> cannot accept any responsibility for any viruses which are \n> transmitted. We therefore recommend you scan all attachments.\n> \n> Please note that the statements and views expressed in this email \n> and any attachments are those of the author and do not necessarily \n> represent those of RNIB.\n> \n> RNIB Registered Charity Number: 226227\n> \n> Website: http://www.rnib.org.uk \n> \n> 14th June 2002 is RNIB Look Loud Day - visit \nhttp://www.lookloud.org.uk to\nfind out all about it.\n\n- \n\nNOTICE: The information contained in this email and any attachments is \nconfidential and may be legally privileged. If you are not the \nintended recipient you are hereby notified that you must not use, \ndisclose, distribute, copy, print or rely on this email's content. If \nyou are not the intended recipient, please notify the sender \nimmediately and then delete the email and any attachments from your \nsystem.\n\nRNIB has made strenuous efforts to ensure that emails and any \nattachments generated by its staff are free from viruses. However, it \ncannot accept any responsibility for any viruses which are \ntransmitted. We therefore recommend you scan all attachments.\n\nPlease note that the statements and views expressed in this email \nand any attachments are those of the author and do not necessarily \nrepresent those of RNIB.\n\nRNIB Registered Charity Number: 226227\n\nWebsite: http://www.rnib.org.uk \n\n14th June 2002 is RNIB Look Loud Day - visit http://www.lookloud.org.uk to\nfind out all about it.\n\n\n\n", "id": "lists-017-16720365"}, {"subject": "RE: XPath 2.0  the relevance of XPointer", "content": "The absence of a reference to XPointer was not an unconscious oversight.\nXPath is an infrastructure specification whose application is based upon the\nhost language that uses it.  The fact that XPointer uses XPath 1.0 in no way\nobligates it to use 2.0.  XLink is still trying to finish up XPointer 1.0.\nThe relevance for the joint XSLT and XQuery statement reflects that both\ngroups are actively working to create XPath 2.0 as we both have need for\ndatatype support.  I don't see how this can be read as any statement\nregarding the future of XPointer.  There are already OASIS specs such as\nDSML that depend upon it.\n\nRegards,\n\nMark\n\n----------------------------------------------------------------\nMark V. Scardina              Group Product Mgr & XML Evangelist\nCORE & XML DEVELOPMENT GROUP  E-mail: Mark.Scardina@oracle.com\nWeb Site: http://otn.oracle.com/tech/xml/\n\n\n> -----Original Message-----\n> From: public-qt-comments-request@w3.org\n> [mailto:public-qt-comments-request@w3.org]On Behalf Of\n> AndrewWatt2001@aol.com\n> Sent: Friday, May 10, 2002 6:40 AM\n> To: public-qt-comments@w3.org\n> Subject: XPath 2.0 - the relevance of XPointer?\n>\n>\n> In Chapter 1.2 of the XPath 2.0 Requirements WD it is stated:\n> \"The scope of\n> XPath 2.0 must be the set of common functionality between the expression\n> language of XSLT 2.0 and the expression language of XML Query 1.0.\".\n>\n> Since XPath 1.0 contains functionality common to XSLT 1.0 and\n> XPointer 1.0,\n> the absence of mention of XPointer should be explained and justified.\n>\n> Is the absence of mention of XPointer in the Requirements document an\n> implicit indication that XPointer is to be dumped by the W3C? Or is it a\n> conscious or unconscious oversight on the part of the WG?\n>\n> Andrew Watt\n>\n>\n\n\n\n", "id": "lists-017-16730437"}, {"subject": "Request for XQuery Mission Document to be made  publi", "content": "The XQuery Mission Document located at http://www.w3.org/XML/Group/Query is \nwithheld from the public.\n\nIf those outside W3C are to comment meaningfully on XQuery and related \nspecifications it makes sense that they are fully informed.\n\nAsking those outside to comment on XQuery etc while withholding information \nabout the strategy is asking for comment about the details of an answer to a \nquestion which is not disclosed.\n\nAndrew Watt\n\n\n\n", "id": "lists-017-16740995"}, {"subject": "Re: [xmldev] Request for XQuery Mission Document to be made publi", "content": "AndrewWatt2000@aol.com wrote:\n> The XQuery Mission Document located at http://www.w3.org/XML/Group/Query is \n> withheld from the public.\n\nThis is not a \"Mission Document\" - it's the internal working group\nweb page, with stuff like telephone numbers for conference calls,\nlinks to travel arrangements for face to face meetings, internal\nworking documents in the process of being edited into drafts,\nmember contact information, and so forth.\n\nThe page you are looking for is at http://www.w3.org/XML/Query where\nyou'll find links to the requirements document and use cases.\n\nLiam\n\n-- \nLiam Quin, W3C XML Activity Lead, liam@w3.org\nAlternate staff contact, XML Query\n\n\n\n", "id": "lists-017-16748787"}, {"subject": "Editorial suggestions for draft-duerst-iri0", "content": "Hello public-iri,\n\nThese editorial comments relate to\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri-07.txt\n\nFrom the new appendix A\n\n>  New schemes are not needed to distinguish URIs from true IRIs (i.e.\n   IRIs that contain non-ASCII characters). The benefit of being able to\n   detect the origin of percent-encodings is marginal, also because\n   UTF-8 can be detected with very high reliably. Deploying new schemes\n   is extremely hard. Not needing new schemes for IRIs makes deployment\n   of IRIs vastly easier. Making conversion scheme-dependent is highly\n   unadvisable. Using an uniform convention for conversion from IRIs to\n   URIs makes IRI implementation orthogonal from the introduction of\n   acual new schemes.\n\nI suggest some slight wording and spelling changes (editorial)\n\n  New schemes are not needed to distinguish URIs from true IRIs (i.e.\n  IRIs that contain non-ASCII characters). The benefit of being able\n  to detect the origin of percent-encodings is marginal, because UTF-8\n  can be detected with very high reliability. Deploying new schemes is\n  extremely hard, so not requiring new schemes for IRIs makes\n  deployment of IRIs vastly easier. Making conversion scheme-dependent\n  is highly inadvisable, and would be encouraged by such an approach.\n  Using an uniform convention for conversion from IRIs to URIs makes\n  IRI implementation orthogonal to the introduction of actual new\n  schemes.\n\nIt might also be added that the TAG recommends not adding new schemes\nthat are almost exactly like HTTP; i:http: or httpi: would have\nexactly that problem.\n\n>  UTF-8 avoids a double layering and overloading of the use of the \"+\"\n   character. UTF-8 is fully compatible with US-ASCII, and has\n   therefore been recommended by the IETF, and is being used widely,\n   while UTF-7 has never been used much and is now clearly being\n   discouraged.\n\nI suggest a small change\n\n   Using UTF-8 avoids a double layering and overloading of the use of\n   the \"+\" character. UTF-8 is fully compatible with US-ASCII, and has\n   therefore been recommended by the IETF, and is being used widely,\n   while UTF-7 has never been used much and is now clearly being\n   discouraged.\n\nYou might also mention here that using UTF-8 here is existing practice\nand that requiring implementations to convert to the rarely used UTF-7\nis an additional implementation burden.\n\nThe arguments against using %u and against inline encoding\ndeclarations are well made.\n\nIn 3.1  Mapping of IRIs to URIs, the renumbering of the sub steps in\nstep two is clearer than in the previous draft.\n\nShould non-realworld, non-resolving sample URIs such as\nhttp://big.site/PopularPage.html not be, for example,\nhttp://big.example/PopularPage.html ?\n\n-- \n Chris Lilley                    mailto:chris@w3.org\n Chair, W3C SVG Working Group\n Member, W3C Technical Architecture Group\n\n\n\n", "id": "lists-017-1675697"}, {"subject": "Re: F&amp;O WD: Issue 150: Should we support comparisons  of date/tim  e types that return indeterminate results", "content": "Mike wrote:\n> Dealing with partial ordering causes many problems, and therefore\n> surprises. For example it means that the user (and the optimizer)\n> can no longer rely on invariants such as A<B => not(A>=B). It causes\n> particular problems for implementors (such as Microsoft) who want to\n> map XQuery to an underlying SQL database. We've been hoping to find\n> a way of avoiding this level of complexity. In the case of\n> durations, one solution I proposed was to achieve a total ordering\n> by equating a month to 365.242199 div 12 days; this would mean 12\n> months > 365 days and 12 months < 366 days, which would at least be\n> comprehensible even if not always what the user wanted.\n> Unfortunately it gets complicated when you look at the interactions\n> with addition of durations to dates, where you want some invariants\n> like DATE1 + DURATION1 < DATE1 + DURATION2 iff DURATION1 <\n> DURATION2. So we decided to park the problem on the back burner by\n> disallowing the awkward cases for the time being. Better to disallow\n> them now than to allow them with semantics that we will regret\n> later.\n\nWhen you say \"for the time being\" are you talking about \"for the next\ncouple of iterations on the WDs\" or are you talking about \"for this\nversion of XQuery/XPath 2.0\"? If it's the latter, I think that's a big\nmistake. If it's the former, put this message on ice until you come to\nreviewing your decision.\n\nPerhaps the problem is similar to that of strings. When you ask\nwhether one string is less than another string, the answer is \"it\ndepends\". What about defining collations for dates, which might use\nspecific dates against which to test durations? Or, better, using\nthree-valued logic, which you already have some support for by way of\nerror values?\n\nThe direct results of this decision on usability are:\n\n  - the inability for people to manipulate durations that don't fit\n    neatly into those categories, such as:\n    - values that internally mix months and days (e.g. prison\n      sentences: \"man sentenced to a year and a day\")\n    - values of types that might be in months or days (e.g. durations\n      between checkups: \"come to see me every six months\"; \"I think I\n      need to see you once a week\")\n    \n  - the inability for people to use existing schemas that involve\n    xs:duration without casting to the more specific types within\n    their query or stylesheet\n\n  - even more hugely long function names\n\nAt the very least, couldn't you allow people to add all kinds of\ndurations to dateTimes\n(http://www.w3.org/TR/xmlschema-2/#adding-durations-to-dateTimes)?\nThen users could get around the lack of xs:duration support by\nchoosing a date, adding the durations to it, and comparing them.\n\nOr have you made the order of addition flexible so that you can\noptimise by doing the calculations in whatever order you like? If so,\nyou still have problems:\n\n  (2000-02-29 + P1Y) + P1M => 2001-03-28\n  (2000-02-29 + P1M) + P1Y => 2001-03-29\n\nCheers,\n\nJeni\n\n---\nJeni Tennison\nhttp://www.jenitennison.com/\n\n\n\n", "id": "lists-017-16757690"}, {"subject": "XML Query Use Case R, query 1", "content": "XML Query Use Cases\nW3C Working Draft 30 April 2002\n\nhttp://www.w3.org/TR/xmlquery-use-cases#rdb-queries-results-q14\nUse Case \"R\", Q 14 (1.4.4.14)\nSolution in XQuery\n\nOn the line\n    sortby(decimal(avgbid)) descending)\nthere's an extra ')'. Delete the one before 'descending'.\n\n-Michael Dyck\n\n\n\n", "id": "lists-017-16768579"}, {"subject": "public-qtcomments moderatio", "content": "Hi,\n\nThe moderators of public-qt-comments will no longer allow cross-posts\nto make it through to the list. Both public-qt-comments and xml-dev\nserve different purposes: xml-dev is a discussion list while\npublic-qt-comments is actually not a list but an address to send\ncomments to the working groups about the specifications.\n\nMax\n\n\n\n", "id": "lists-017-16775215"}, {"subject": "Re: Migration of HTTP to the use of IRIs [altdesign17", "content": "Ok Martin,\n\nHaving carefully re-read the draft, and having checked the terms of reference\nfor this activity, I now understand that I was placing unwarrented expectations\non the scope and applicability of this work.\n\nI therefore have no further concerns re. altdesign-17\n\nChris\n\n\n\"Martin Duerst\" replied:\n\n>\n> Hello Chris,\n>\n> At 11:05 04/05/09 +0100, Chris Haynes wrote:\n>\n> >Michael,\n>\n> [Well, Martin that would have been.]\n>\n>\n> >Thanks for your patience.\n> >\n> >So I think you are saying that the flaw in my logic is when I asserted that\n> >there is no syntactic indication of the use of an IRI. Your assertion, in\n> >effect, is that the syntactic indication is only present when needed, and is\n> >implicit in the use of UTF-8 encoding.\n>\n> Not exactly. There is no syntactic indication needed for HTTP\n> and URIs/IRIs to work the way they are designed.\n>\n> HTTP may in the future decide to introduce a convention to let the\n> client tell the server about character encodings e.g. in query parameters,\n> but this is idenpendent of the IRI spec. Such a convention may use another\n> scheme (which I doubt very much), a special named query parameter\n> (much more likely, some browsers can already do this, and some\n> sites (e.g. google) use this), or something else.\n>\n> Such a solution could take UTF-8 as a special case, or it could\n> treat UTF-8 just as one choice among many. IRIs will definitely\n> provide a push towards UTF-8, but they cannot force anybody to\n> use UTF-8.\n>\n>\n> >Your assertion below is that the vast majority of cases which were not\nencoded\n> >in UTF-8 will generate one or more octet sub-sequences which are not legal\n> >representations of characters in UTF-8.\n>\n> Yes. Or they will trivially be ASCII-only, in which case\n> the question of encoding is mostly irrelevant.\n>\n>\n> >I should use the presence of such\n> >sequences to conclude that the URI was not encoded in UTF-8 and therefore\nthat\n> >conversion to an IRI  is not applicable.\n> >\n> >My first thought was to try applying the processing you define in (draft\n> >7) sect\n> >3.2, to see if that would provide a 'failure indication' that I could use.\n> >\n> >But I came to your Step 3:\n> >\n> >\"Re-escape any octet produced in step 2 that is not part of a strictly legal\n> >UTF-8 sequence\".\n> >\n> >\n> >This step re-absorbs octet sequences which are illegal in UTF-8 into the IRI\n> >world, so, applying section 3.2 in its entirety _cannot_ be used as the\n> >basis of\n> >a decision on whether or not UTF-8 encoding was used in the original\nescaping.\n>\n> Yes. Section 3.2 isn't something that returns a boolean, it returns\n> an IRI. And it tries to convert as many escapes as possible into\n> actual characters. If that's not what you need, don't use Section 3.2.\n>\n>\n> >Section 3.2 can only be applied if it is desired to _force_ everything that\nis\n> >received into an IRI.\n> >\n> >Your draft 7  does not provide the basis for deciding whether or not the URI\n> >should be treated in this way. i.e. it does not give any opportunity for\n> >concluding that the presented URI was encoded using some other (legacy)\n> >encoding.\n>\n> Yes. There may be many reasons why somebody may want to use Section 3.2,\n> and many other reasons why one wouldn't want to use it, or would not\n> want to use it exactly as described.\n>\n>\n> >You may recall that my concern is for the design of a web server including\n> >something like a Servlet handler, which has to decode the URI before it can\n> >identify and invoke the referenced servlet (which might know what encoding\nwas\n> >used in URIs identifying that Servlet).\n>\n> If there is really a cyclic interdependency (i.e. servlet knows encoding,\n> but servlet handler has to know encoding to be able to call servlet),\n> then the only thing you can really do seems to be trial-and-error.\n>\n> If there is not really a cyclic interdependency (i.e. servlet knows\n> encoding, and could handle it, but you want to do decoding in the\n> servlet handler code), then this might just be bad design and\n> software engineering.\n>\n> This does not mean that the servlet handler couldn't do certain\n> things on behalf of the servlet, but you most probably need a\n> more flexible interaction.\n>\n>\n> >In this 'real world' that I keep worrying about there will be a long\n> >transition\n> >phase when there will be many inbound URLs which contain escapes generated\n> >using\n> >other encodings.\n>\n> Yes in general. But this will be very different for different servers.\n> I know of cases where UTF-8 is already used throughout since years,\n> and I'm sure there are cases where legacy encodings will still be\n> used in some years. Thus different servers will have different\n> needs when it comes to analyzing incomming HTTP URIs, in particular\n> query parts.\n>\n>\n> >Forcing them into IRIs is not appropriate behaviour; by some\n> >other means the appropriate decoding must be selected and applied.\n>\n> Agreed. But I don't think the draft ever says you have to do that.\n>\n> In more general terms, I'm not sure why you want to convert an\n> URI arrived on the server to an IRI. What you want to do is to\n> take the URI appart and work on resolving it.\n>\n>\n> >It seems to me that, in this situation, where URLs containing encodings other\n> >than UTF-8 are to be handled differently, rather than be forced into IRIs by\n> >your section 3.2,\n>\n> Section 3.2 in no way forces you to convert URIs to IRIs on the server!\n>\n>\n> >a different sequence is required. Something like:\n> >\n> >A)  Convert the received URI into an octet sequence as follows: Each %HH\n> >triplet\n> >generates an octet whose value is defined by the hex digits HH. All other\n> >(ASCII) characters generate an octet whose value is that of the code point of\n> >that character in the ASCII/UTF-8 code table.\n> >\n> >B) Attempt to process the octet sequence generated by B as a UTF_8-encoded\n> >octet\n> >sequence. If the octet sequence is 'legal', i.e. it is the correct\n> >encoding of a\n> >sequence of integer values (but not necessarily representing valid Unicode\n> >code\n> >points), then the URI does represent an IRI and the processing of (draft 7\n> >sect.32.) should be applied to extract the IRI.\n> >\n> >C) If, in step B, there should have been found one or more octet sequences\n> >which\n> >did not form part of any 'legal' UTF_8 sequence, then no IRIs are involved\nand\n> >the interpretation of the presented URI is to be decided by other means.\n>\n> In some cases, a procedure like the above may be appropriate for\n> implementing some servlet logic. But please note that what you are\n> actually trying to do really has nothing to do with reconstructing\n> an IRI from an URI; what you are trying to do is to reconstruct the\n> original characters that should be handled to the servlet.\n>\n> Looking at the details, I see the following issues:\n> - The decision should probably not be taken for the whole URI, but\n>    e.g. on the query part only. There can easily be cases where the\n>    query part is in UTF-8, but the path part is not, or the other\n>    way round.\n> - The procedure isn't really complete if you end with 'is to be\n>    decided by other means'. Here several situations may arise,\n>    and they may need different solutions. In general, you need\n>    to have a way to know the actual encoding. The most general\n>    way to do this is to include a hidden form element in the\n>    form, with a text that will be encoded differently in the\n>    encodings you want to distinguish (e.g. UTF-8, iso-2022-jp,\n>    euc-jp, and shift_jis for Japanese).\n>\n> So if you are working with content, forms, and an audience where\n> you expect query parts in a variety of encodings, your above\n> procedure won't really cut it.\n>\n>\n> >Note that the application of the procedure A-C above will mean that your\n> >step 3\n> >will never be applied.\n> >\n> >\n> >So I think we have two possible scenarios:\n> >\n> >Scenario 1)  The world is to be viewed as containing only IRIs.  _All_\n> >received\n> >URIs are converted into IRIs consisting of a sequence of  'appropriate' (your\n> >step 4) UTF characters.  Any non-UTF-8 escapes are still present as\n> >still-escaped sequences in the IRI; there has been no attempt to interpret\n> >these\n> >as characters in some other encoding.\n>\n> It's much better to think about this per server or Web application.\n> There may be Web applications where only IRIs are expected. If\n> non-UTF-8 escapes are found, then rather than keep these as still-\n> escaped sequences, they should produce an appropriate error message\n> to the user, e.g. \"You have submitted data to this application\n> that could not be processed correctly, because it was not encoded\n> correctly by your browser. If you have a very old browser, please\n> upgrade. ...\"\n>\n>\n> >Scenario 2)  In a word in which URIs intended to represent IRIs co-exist with\n> >URIs encoded using other character encodings, and where the difference has\n> >to be\n> >detected so that the appropriate decoding can be applied, then my steps\n> >A-C must\n> >first be undertaken. If my steps A-C indicate that another encoding was used,\n> >then the URI is to be handled in some other way, and no IRI is involved. If\nno\n> >evidence of a different encoding is found, then it is to be assumed that\n> >conversion to an IRI is valid and your steps 1-5 should be applied (but step\n3\n> >will never be invoked).\n>\n> For servers where this is the case, if there is only one other encoding,\n> then the above might be okay. But if there are potentially multiple\n> legacy encodings, that won't do the job.\n>\n>\n> >My tentative conclusion is this:\n> >\n> >The IRI draft 7 does not provide any support or advice for those needing to\n> >recognize and process (intelligently and efficiently) URIs containing\n> >encodings\n> >other than UTF-8.\n>\n> That is right. The draft is about IRIs, and about URIs resulting from\n> conversion from IRIs. It's not implementation advice for implementers\n> of servers and Web applications on how to distinguish different legacy\n> encodings.\n>\n>\n> >Where this needs to be done, something akin to my steps A-C is necessary,\n> >before\n> >it can be decided that URI to IRI conversion should be applied.\n> >\n> >\n> >My concerns would be assuaged if there were a Section or Appendix in the IRI\n> >Internet-Draft :\n> >\n> >- Recognizing these transitional / co-existence needs,\n>\n> I don't think distinguishing legacy encodings is part of what the\n> IRI spec should do.\n>\n>\n> >- Detailing the necessary and sufficient URI inspection required to decide\n> >whether or not to invoke IRI processing,\n>\n> What may be going on on the server is not a conversion from URIs to IRIs,\n> it's an attempt to extract original data from an URI. Because Section\n> 3.2 looks somewhat similar to what you had in mind to do that job,\n> you got confused.\n>\n>\n> >- Containing the cautions about the remote possibility of incorrect decisions\n> >being made.\n>\n> There is already such caution. The draft says that detecting UTF-8\n> is correct with high probablity; it doesn't say it's always correct.\n>\n>\n> >I'd be prepared to help draft it.\n> >\n> >Footnote 1:\n> >In a 'real' implementation the two processing sequences 1-5 and A-C could be\n> >undertaken in a single pass through the URI using a merged algorithm,\n> >parameterised to define how it should proceed if a non-UTF_8 octet sequence\n> >should be detected (i.e. parameterised to adopt Scenarios 1 or 2). The\n> >performance penalty of my proposed addition would be insignificant.\n>\n> Anybody who finds a more efficient way to do things is always\n> welcome to use that way. Specs usually try to give clear and\n> precise instructions, rather than to be most efficient.\n>\n>\n> >Footnote 2:\n> >Your approach of assuming that an IRI interpretation is valid in all\n> >situations\n> >in which UTF_8 has been used ought also to be validated. People are already\n> >using UTF-8 encoding with no knowledge of IRIs.  I've not explored what\nimpact\n> >the application of the stage 4+5 processing of your draft (i.e. beyond that\nof\n> >de-escaping and decoding the UTF-8 characters) could have, and whether or\n> >not it\n> >could cause any problems for pre-IRI users of UTF-8. I don't intent to pursue\n> >this line of enquiry ;-)\n>\n> Well, if somebody has used UTF-8 up to now, others can use IRIs.\n> As an example, I have used http://www.w3.org/People/D%C3%BCrst\n> for years. If somebody inputs it in a browser, on some browsers\n> (e.g. Opera) they will actually see a real IRI.\n> The only danger with this kind of IRIs is that they then give\n> that IRI to somebody else, and that person doesn't have a browser\n> that can resolve IRIs yet. But that's not anything that could\n> not happen with something that was created to be used as an\n> IRI from the start.\n>\n>\n> Regards,    Martin.\n>\n>\n>\n> >Chris\n> >\n> >\n> >----- Original Message -----\n> >From: \"Martin Duerst\" <duerst@w3.org>\n> >To: \"Chris Haynes\" <chris@harvington.org.uk>; \"Michel Suignard\"\n> ><michelsu@windows.microsoft.com>\n> >Cc: <public-iri@w3.org>\n> >Sent: Sunday, May 09, 2004 1:37 AM\n> >Subject: Re: Migration of HTTP to the use of IRIs [altdesign-17]\n> >\n> >\n> > > Hello Chris,\n> > >\n> > > I have changed the issue for this mail to altdesign-17, because it\n> > > seems more appropriate.\n> > >\n> > > At 11:07 04/05/07 +0100, Chris Haynes wrote:\n> > >\n> > > >Michel,\n> > > >\n> > > >Thanks for this comment, but I think my point is still valid - even\n> > just for\n> > > >presentational uses.\n> > > >\n> > > >Given that many URI encodings exist 'in the wild' which use %HH\n> > escaping of\n> > > >non-UTF-8 sequences, I fail to see how one can know that it is valid to\n> > > >convert\n> > > >any such URI into an IRI (as per sect. 3.2) - even if just for\n> > presentational\n> > > >purposes.\n> > >\n> > > Section 3.2 very clearly says that there is a risk that you convert\n> > > to something that didn't exist previously.\n> > > But in practice, this is not that much of an issue, because it is\n> > > very rare to find reasonable text encoded in legacy encodings that\n> > > matches UTF-8 byte patters. Please try to find some examples yourself,\n> > > and you will see this.\n> > >\n> > >\n> > > >My concern is the same:  unless there is some kind of syntactic indicator\n> > > >within\n> > > >the URI as a whole, how can one reliably know that UTF-8 has been used\nand\n> > > >that\n> > > >it is intended to have a corresponding IRI?\n> > >\n> > > You are correct that one cannot do this with 100% certainty.\n> > > But then, if you study the URI spec very carefully, you will\n> > > find that it also doesn't guarantee that an 'a' in an URI\n> > > actually corresponds to an 'a' in the original data (e.g.\n> > > file name). For details, please see the \"Laguna Beach\"\n> > > example in Section 2.5 of draft-fielding-uri-rfc2396bis-05.txt,\n> > > for example at\n> > >\n> > http://gbiv.com/protocols/uri/rev-2002/draft-fielding-uri-rfc2396bis-05.txt.\n> > >\n> > > So in those rare cases where an URI with an octet sequence\n> > > that by chance corresponds to an UTF-8 pattern, but that was\n> > > never intended as UTF-8, is converted to an IRI, one will just\n> > > get a weird name, but reusing that name again e.g. in a browser\n> > > that accepts IRIs will lead back to the original resource.\n> > >\n> > >\n> > >\n> > > >It seems to me that IRI will only be deployed accurately and effectively\n> > > >if one\n> > > >of the following situations occurs:\n> > > >\n> > > >1) New protocol schemes (e.g. httpi, httpis ) are introduced which make\nit\n> > > >explicit that this spec. applies to the URI,\n> > >\n> > > Introducing a new URI scheme is *extremely* expensive. I have heard\n> > > Tim Berners-Lee say this over and over again, and I know he knows it.\n> > > And in the case at hand, it's highly unnecessary. The cost of an\n> > > occasional accidental 'wrong' conversion back to an IRI (as discussed\n> > > above) is much, much smaller than the cost of introducing new schemes.\n> > >\n> > > And what would the real benefit of new schemes be? Would they be\n> > > useful to distinguish URIs from true IRIs (I'm writing 'true' IRIs\n> > > here to exclude URIs which are by definition also IRIs). Not really,\n> > > it's much cheaper to identify IRIs by checking for non-ASCII characters.\n> > >\n> > > So they would only be used to distinguish URIs without known origin\n> > > from URIs originating from conversion from IRIs. But assume I had\n> > > an IRI like like http://www.example.org/ros&#xE9; (rose'). In order\n> > > to pass it to others whom I know can only process URIs, not IRIs,\n> > > would I want to convert it to http://www.example.org/ros%C3%A9,\n> > > or to httpi://www.example.org/ros%C3%A9 ? The former strictly\n> > > speaking looses the information that this was an IRI, so converting\n> > > it back to rose' is a guess (but because of the UTF-8 patters,\n> > > actually a rather safe one). But it actually will go to the\n> > > right page, on hunderds of millions of Web browsers, without\n> > > exception. The later can safely be converted back to the IRI\n> > > (by all the software that knows how to do this, which currently\n> > > numbers exactly 0). But it will work only on the browsers\n> > > that know the httpi: scheme (again, currently numbering\n> > > exactly 0). For me the alternative is very clear,\n> > > http://www.example.org/ros%C3%A9 works in much more cases,\n> > > and is therefore much better.\n> > >\n> > >\n> > > >2) They are used within a closed environment in which it is a\n> > convention that\n> > > >only IRIs and IRI-derived URIs are in use (no legacy-encoding escapes, or\n> >they\n> > > >are allowed to be mis-interpreted)\n> > >\n> > > The current draft clearly allows legacy-encoded escapes, for backwards\n> > > compatibility. I'm not sure what you mean by 'mis-interpreted', but\n> > > if you mean that they are converted to IRIs, then yes, the current\n> > > draft allows this in those cases where it is possible (i.e. the\n> > > byte pattern matches UTF-8,...). But this misinterpretation does\n> > > not lead to an actual misinterpretation of the resource that the\n> > > IRI identifies.\n> > >\n> > >\n> > > >3) A new market-dominating user agent is launched which behaves as if (2)\n> > > >above\n> > > >were the case - i.e. there is an attempt to establish IRIs as the de\nfacto\n> > > >default through market force, ignoring or discarding resulting errors of\n> > > >presentation or of resource identification.\n> > > >\n> > > >My big fear is that without rapid progress on (1), IRIs on the open\n> > Internet\n> > > >will only ever take off if someone does (3) - which will be without\n> > benefit\n> >of\n> > > >adequate standards backing.\n> > >\n> > > I'm not sure I understand you. Several browsers, for example\n> > > Opera and Safari, already implement IRIs. MS IE also does it\n> > > if the relevant flag is set correctly. And the standard is\n> > > close to done; this is the last real issue I'm trying to close.\n> > > So I don't see the problem.\n> > >\n> > >\n> > > >I'd love to either:\n> > > >\n> > > >a) be shown that my logic is faulty\n> > >\n> > > I guess yes. Not in theory, where absolute correctness is the\n> > > only goal, but in practice, where big numbers and deployment\n> > > are important.\n> > >\n> > > >or\n> > > >\n> > > >b) be pleasantly surprised by being told that there _is_  RFC work taking\n> > > >place\n> > > >on new schemes covering at least the space of http(s)\n> > >\n> > > Some schemes may benefit from an update, in particular those that\n> > > haven't thought about internationalization. The first example that\n> > > would come to my mind is the mailto: scheme.\n> > >\n> > >\n> > > Regards,    Martin.\n> > >\n> > >\n> > >\n> > > >otherwise, I fail to understand how IRIs will 'take off' in the 'real\n> >world' -\n> > > >where they are so badly needed.\n> > > >\n> > > >Chris\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >----- Original Message -----\n> > > >From: \"Michel Suignard\" <michelsu@windows.microsoft.com>\n> > > >To: \"Chris Haynes\" <chris@harvington.org.uk>\n> > > >Cc: <public-iri@w3.org>; \"Martin Duerst\" <duerst@w3.org>\n> > > >Sent: Friday, May 07, 2004 1:43 AM\n> > > >Subject: RE: Migration of HTTP to the use of IRIs [queryclarify-16]\n> > > >\n> > > >\n> > > >\n> > > > > From:  Chris Haynes\n> > > > > Sent: Thursday, May 06, 2004 4:50 AM\n> > > > >\n> > > > > Actually, my original core concern has now been covered in your\n> > > >section\n> > > > > 1.2.a - Applicability, where you make it clear that \"the intent is not\n> > > >to\n> > > > > introduce IRIs into contexts that are not defined to accept them\".\n> > > > >\n> > > > > This now makes it clear that new schemas will be required to replace\n> > > > > http: , https: etc. These will need to be self-identifying in some\n> > > >way, so\n> > > > > that receiving equipment will know that an IRI is being presented.\n> > > > >\n> > > > > So, as I commented last June, I await with interest the recognition\n> > > >among\n> > > > > those responsible for the HTTP schema that new schemas with new names\n> > > >are\n> > > > > required before IRIs can be used.\n> > > >\n> > > >I'd like to comment on that. The IRI spec is fairly explicit on that IRI\n> > > >can be used as presentation elements for URI protocol elements (ref\n> > > >clause 3 intro). This is to recognize that applications out there have\n> > > >not waited for us for creating presentation layers that use non ascii\n> > > >native characters for schemes that supposedly should not use them (such\n> > > >as http). The presentation layer principle is there to support that. So\n> > > >I expect IRI to be used for both purposes:\n> > > >- presentation layer for existing URI schemes\n> > > >- core layer for new schemes exclusively defined using IRI for protocol\n> > > >elements syntax.\n> > > >\n> > > >For a while I'd expect the vast majority of IRI usage to be in the first\n> > > >category.\n> > > >\n> > > >Michel\n> > > >\n> > > >\n> > >\n> > >\n> > >\n>\n>\n>\n\n\n\n", "id": "lists-017-1685865"}, {"subject": "Re: Migration of HTTP to the use of IRIs [altdesign17", "content": "Great, thanks!\n\nI have closed this issue, as well as IDnits-26.\n\nRegards,   Martin.\n\nAt 08:27 04/05/11 +0100, Chris Haynes wrote:\n\n>Ok Martin,\n>\n>Having carefully re-read the draft, and having checked the terms of reference\n>for this activity, I now understand that I was placing unwarrented \n>expectations\n>on the scope and applicability of this work.\n>\n>I therefore have no further concerns re. altdesign-17\n>\n>Chris\n\n\n\n", "id": "lists-017-1721668"}, {"subject": "Issues: Section 3.1 references to nonASCII character", "content": "Here are three related issues re. draft 7, Sect 3.1, Step 2.\n\n\n\nI have a concern with the sentence \"The disallowed characters consist of all\nnon-ASCII characters allowed in IRIs.\"\n\n(Issue 1) Since this step is referring to (presumably legal) IRIs, then the\nphrase \"allowed in IRIs\" is superfluous - there could be no others.\n\n--------------\n\n(Issue 2) Is the phrase \"non-ASCII characters\" sufficiently precice / normative?\n\nI think here is a much cleaner definition available, providing you don't mind\ndropping the allusion to the reasoning:\n\n\"The disallowed characters consist of all those matching 'ucschar' or 'iprivate'\nof Section 2.2\"\n\nAltenatively, you could say something like \"The disallowed characters consist of\nall those whose UTF-8 encodings employ two or more octets\" (which is more to the\npoint and all-embracing).\n\n--------------\n\n\nTYhe definition of disallowed characters  now leads us to an apparent conflict\nwith step 2.1, which currently says to \"convert the character to one or more\noctets using UTF-8\".\n\nUnless I've misunderstood some subtlety in the definition of 'disallowed\ncharacters', all such characters will require at least two octets for their\nencoding so we reach issue 3:\n\n\n(Issue 3)  In Step 2.1 none of the characters to be so processed can have just\none octet in their UCS-8 encoding, so the instruction, strictly-speaking, cannot\nbe obeyed.\n\n--------------\n\n\nI also find the mixture of negatives and plurals in the introduction to step 2\nsomewhat confusing, so I've taken the liberty of suggesting some re-drafts which\naddresses all three issues.\n\n\nOne possible re-draft of the start of Step 2, which consolidates all the above\npoints, is:\n\nVersion 1:\n vvvvvvvvvvvvvvvv\n   Step 2)\n      IRI characters matching 'ucschar' or 'iprivate' (section 2.2) are\ndisallowed in URI\n      references. For each such character apply steps 2.1 through 2.3 below..\n\n         2.1) Encode the disallowed character using UTF-8, which will generate a\nsequence\n         of two or more octets.\n\n         2.2) Convert each octet to %HH ........\n^^^^^^^^^^^^^^^^\n\nAn alternative re-draft is:\n\nVersion 2:\nvvvvvvvvvvvvvvvv\n   Step 2)\n      IRI characters whose UCS-8 encodings emply two or more octets are\ndisallowed in\n      URI references. For each such character apply steps 2.1 through 2.3\nbelow..\n\n         2.1) Encode the disallowed character using UTF-8, which will generate a\nsequence\n          of two or more octets.\n\n         2.2) Convert each octet to %HH ........\n^^^^^^^^^^^^^^^^\n\n\nyet a third, which restores the reasoning, is:\n\nVersion 3:\nvvvvvvvvvvvvvvvv\n   Step 2)\n      IRI characters whose UCS-8 encodings emply two or more octets are\ndisallowed in\n      URI references because they are not US-ASCII characters. For each such\ncharacter\n      apply steps 2.1 through 2.3 below..\n\n         2.1) Encode the disallowed character using UTF-8, which will generate a\nsequence\n         of two or more octets.\n\n        2.2) Convert each octet to %HH ........\n^^^^^^^^^^^^^^^^\n\nTake your pick!\n\n\n---------------------------\n\nOne final general point:  throughout the document I can see both 'ASCII' and\n'US-ASCII' in use. Should not a single designation be selected, and a normative\nreference supplied (such as that in RFC 2396 [ASCII] )?\n\n\nHTH\n\nChris Haynes\n\n\n\n", "id": "lists-017-1730009"}, {"subject": "Re: Editorial suggestions for draft-duerst-iri-07 [issue   editorial-Lilley27", "content": "At 03:08 04/05/11 +0200, Chris Lilley wrote:\n\n>Hello public-iri,\n\nHello Chris,\n\nMany thanks for your comments. Because they are all editorial,\nI have kept them as a single issue.\n[http://www.w3.org/International/iri-edit/#editorial-Lilley-27]\nUp to now, I haven't usually 'issuefied' editorial stuff, but I'm\nstarting to do that to document what has happened in last call.\n\n\n>These editorial comments relate to\n>http://www.w3.org/International/iri-edit/draft-duerst-iri-07.txt\n>\n> From the new appendix A\n>\n> >  New schemes are not needed to distinguish URIs from true IRIs (i.e.\n>    IRIs that contain non-ASCII characters). The benefit of being able to\n>    detect the origin of percent-encodings is marginal, also because\n>    UTF-8 can be detected with very high reliably. Deploying new schemes\n>    is extremely hard. Not needing new schemes for IRIs makes deployment\n>    of IRIs vastly easier. Making conversion scheme-dependent is highly\n>    unadvisable. Using an uniform convention for conversion from IRIs to\n>    URIs makes IRI implementation orthogonal from the introduction of\n>    acual new schemes.\n>\n>I suggest some slight wording and spelling changes (editorial)\n>\n>   New schemes are not needed to distinguish URIs from true IRIs (i.e.\n>   IRIs that contain non-ASCII characters). The benefit of being able\n>   to detect the origin of percent-encodings is marginal, because UTF-8\n>   can be detected with very high reliability. Deploying new schemes is\n>   extremely hard, so not requiring new schemes for IRIs makes\n>   deployment of IRIs vastly easier. Making conversion scheme-dependent\n>   is highly inadvisable, and would be encouraged by such an approach.\n>   Using an uniform convention for conversion from IRIs to URIs makes\n>   IRI implementation orthogonal to the introduction of actual new\n>   schemes.\n\nChanged. I replaced \"by such an approach\" with \"by separate schemes\nfor IRIs\" to make things even clearer.\n\n\n>It might also be added that the TAG recommends not adding new schemes\n>that are almost exactly like HTTP; i:http: or httpi: would have\n>exactly that problem.\n\nDo you have a reference? I'd like to give the underlying argument\nrather than just saying 'the TAG said'.\n\n\n> >  UTF-8 avoids a double layering and overloading of the use of the \"+\"\n>    character. UTF-8 is fully compatible with US-ASCII, and has\n>    therefore been recommended by the IETF, and is being used widely,\n>    while UTF-7 has never been used much and is now clearly being\n>    discouraged.\n>\n>I suggest a small change\n>\n>    Using UTF-8 avoids a double layering and overloading of the use of\n>    the \"+\" character. UTF-8 is fully compatible with US-ASCII, and has\n>    therefore been recommended by the IETF, and is being used widely,\n>    while UTF-7 has never been used much and is now clearly being\n>    discouraged.\n>\n>You might also mention here that using UTF-8 here is existing practice\n\nDo you mean in the context of URIs, or much more general?\nThe subsection starts out with \"At an early stage, UTF-7 was considered\",\nand in that context, it wouldn't be true. The fact that many URI\nschemes now use UTF-8 in one way or another is largely due to the decision\nto use UTF-8 for IRIs, and to the general rise of UTF-8.\n\n\n>and that requiring implementations to convert to the rarely used UTF-7\n>is an additional implementation burden.\n\nThat's a good point. I added:\n\"Requiring implementations to convert from UTF-8\nto UTF-7 and back would be an additional implementation burden.\"\n\n\n>The arguments against using %u and against inline encoding\n>declarations are well made.\n\nThanks!\n\n\n>In 3.1  Mapping of IRIs to URIs, the renumbering of the sub steps in\n>step two is clearer than in the previous draft.\n\nThanks. That was a private suggestion from Chris Haynes.\n\n\n>Should non-realworld, non-resolving sample URIs such as\n>http://big.site/PopularPage.html not be, for example,\n>http://big.example/PopularPage.html ?\n\nIn that case probably http://big.example.com/PopularPage.html.\nDone. [I made that example.com, even though all other examples\nare example.org, but I guess in that case, that's justified.]\n\n\nRegards,   Martin.\n\n>--\n>  Chris Lilley                    mailto:chris@w3.org\n>  Chair, W3C SVG Working Group\n>  Member, W3C Technical Architecture Group\n\n\n\n", "id": "lists-017-1740786"}, {"subject": "Re: draft-duerst-iri-07.txt: 2 week mailing list last call   (IRIsyntax28", "content": "Hello Graham,\n\nMany thanks for your comments. I'm responding in pieces,\nas I split things up into issues. This is issue\nhttp://www.w3.org/International/iri-edit/#IRIsyntax-28\n\nAt 12:02 04/05/10 +0100, Graham Klyne wrote:\n\n>Martin,\n>\n>These comments are based on a quick skim rather than a detailed reading.\n>\n>Looking at this from an implementer's perspective, I feel it would be \n>helpful if the relationship between the IRI and URI *grammars* were more \n>clearly delineated;  e.g. a presentation of IRI syntax that is based on \n>the RFC2396bis grammar,\n\nIt definitely is. I have very carefully followed all the changes\nin the RFC2396bis grammar. I very much hope I got it right, but\nany additional crosschecks would be greatly appreciated.\n\n\n>replacing a minimum number of productions.\n\nI think that's also the case.\n\nI think what you mean is to only change some terminal productions,\nbut leave the rest unchanged. There are several reasons why this\nhasn't been done:\n\n- In the most general sense, it would have been okay to just\n   add ucschar to unreserved. But there is the issue of allowing\n   private characters in query parts, but not elsewhere.\n- Looking top down, what you seem to want may actually imply\n   to use 'URI' rather than 'IRI' at the start of the grammar.\n   I think that would have been more confusing than helpful.\n   And once you start making these distinctions, it would\n   then again be confusing to e.g. use 'path' rather than\n   'ipath'.\n- The current solution allows to very easily create a combined\n   grammar of URIs and IRIs, which some people might want to do.\n   If the two grammars would use the same symbols for things that\n   are on  purpose the same, but in actual syntax are different,\n   that wouldn't work.\n- The grammar allows somebody who wants to only implement IRIs\n   to do that directly. It may lead to less implementation\n   divergence than a verbal description of differences against\n   another spec.\n\n\n>On this basis, it would be easier to see what needs to be changed in a URI \n>parser to yield an IRI parser.\n\nI hope it's already easy enough to see. I have used very\nstraightforward naming conventions to correlate the corresponding\nnonterminals in both grammars. If there is 'URI' in the original\nnonterminal, I have changed that to 'IRI'. Otherwise, I have\nprefixed an 'i'. If you think this is helpful, I can add a\nsentence to that effect.\n\n\n>Also, I note that the RFC2396bis grammar has been through several \n>revisions as subtle issues are exposed by review and implementation \n>experience;  by replicating the entire grammar (rather than saying that an \n>IRI is like a URI with designated changes), can you be confident that such \n>issues have not been re-introduced?\n\nOf course, there is never any absolute confidence, but as far as\nI remember, these issues were all related to details around\nspecial cases such as e.g. empty paths. They are therefore\northogonal to the issue of extending the repertoire of\n'reserved' characters. One might be able to immagine some\ninteractions if e.g. authorities and paths were extended\nin a different way, but the difference is for query parts,\nwhich are very clearly delineated, and haven't been at\nissue in the bugs you mention above.\n\nI hope you are satisfied with this answer. If not, I would\nappreciate a more detailled proposal.\n\n\nRegards,   Martin.\n\n\n\n", "id": "lists-017-1753896"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nI have labeled this issue as convertASCII-30.\n\n\nAt 12:02 04/05/10 +0100, Graham Klyne wrote:\n\n>Section 3.2:\n>\n>Is this really true (about always mapping back to the same URI)?:\n>[[\n>3.2  Converting URIs to IRIs\n>\n>    In some situations, it may be desirable to try to convert a URI into\n>    an equivalent IRI. This section gives a procedure to do such a\n>    conversion. The conversion described in this section will always\n>    result in an IRI which maps back to the URI that was used as an input\n>    for the conversion (except for potential case differences in\n>    percent-encoding). However, the IRI resulting from this conversion\n>    may not be exactly the same as the original IRI (if there ever was\n>    one).\n>]]\n>\n>In light of:\n>[[\n>    2) Convert all percent-encodings (% followed by two hexadecimal\n>       digits) except those corresponding to '%', characters in\n>       'reserved', and characters in US-ASCII not allowed in URIs, to the\n>       corresponding octets.\n>]]\n>\n>It seems to me that removing percent encodings for non-reserved and other \n>characters is a non-reversible transformation.  I think that mapping back \n>to the original URI is only true under escape normalization, per rfc2396bis.\n\nYes, good catch. I looked at the actual text that needs to be fixed.\nI can either add non-reserved ASCII characters to the 'except'\nclause in parentheses in the original text, or can change the\nprocedure. Overall, in terms of edits, both need about the same\nwork. Which one would you prefer?\n\nIt is clear that with or without removing percent-encodings for\nnon-reserved ASCII characters, this can be done, and different\nusages may choose different variants, according to their needs.\n\n\n>Also, not knowing anything about bidi encodings, it's difficult for me to \n>tell if there's any possible interaction between this and the section 4 \n>material on bidi sequences.\n\nThere is some interaction as some characters and character\ncombinations are excluded by the bidi section. I think the\nvarious cross-references within the text take care of this.\nThere is also some interaction that with the conversion\nfrom URI to IRI, the display sequence of the components\nmay change. But this will just happen automatically, this\nis not something the algorithm has to worry about.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1765740"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nI have made this issue charcompareMUST-31.\n\n\nAt 12:02 04/05/10 +0100, Graham Klyne wrote:\n\n\n>Section 5.1:\n>\n>[[\n>5.1  Simple String Comparison\n>\n>    In some scenarios a definite answer to the question of IRI\n>    equivalence is needed that is independent of the scheme used and\n>    always can be calculated quickly and without accessing a network. An\n>    example of such a case is XML Namespaces ([XMLNamespace]). In such\n>    cases, two IRIs SHOULD be defined as equivalent if and only if they\n>    are character-by-character equivalent. This is the same as being\n>    byte-by-byte equivalent if the character encoding for both IRIs is\n>    the same. As an example,\n>    http://example.org/~user, http://example.org/%7euser, and\n>    http://example.org/%7Euser are not equivalent under this definition.\n>    In such a case, the comparison function MUST NOT map IRIs to URIs,\n>    because such a mapping would create additional spurious equivalences.\n>]]\n>\n>It's not clear to me what the MUST NOT here is saying.  Making normative \n>statements that are conditional on some postulated application scenario \n>seems to be a bit confusing to me.\n\nIf you interpreted the statement as conditional on some application\nscenario, then it is indeed confusing. It was intended conditional\nto the comparison function. I.e. if you use character-by-character\ncomparison, you MUST NOT map IRIs to URIs,\nbecause such a mapping would create additional spurious equivalences.\n\nI have replaced \"In such a case\" with \"When comparing character-by-character\".\n\n\n>I think the final sentence maybe should be:\n>[[\n>The IRI to URI mapping function described above [ref] does not preserve \n>this form of equivalence.\n>]]\n>\n>(Further, the MUST NOT here seems even more perverse in light of the \n>introductory material in section 3.1)\n\nI have checked that material again, and did not find any problems.\nYou may observe that that material is carefully worded in terms of\nretrieval when it comes to IRI->URI mapping, not in terms of\nabstract resource identification.\n\n\n>I suspect there should be some discouragement of applications depending on \n>this level of equivalence, in view of the spurious distinctions that are \n>lost when IRIs are converted to URIs.   To my mind the string equivalence \n>of the URI-converted form seems like the lowest reasonable level of \n>distinction to be encouraged.\n\nWell, there are some serious arguments against this:\n- Some very important applications, in particular XML Namespaces\n   and RDF, use this equivalence. So recommendation against this\n   would cause confusion.\n- Needing to convert to URIs for every comparison is inefficient\n   (that was the main argument for namespaces)\n- Needing to convert to URIs may lead to more URIs (rather than IRIs)\n   floating around, because in some cases, the conversion would\n   leak.\nSo that's why we should not go there.\n\nI hope the above addresses your concerns.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1776266"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nI have removed the uri list for this issue, because it's\nreally iri-specific.\nThis is issue\n\nAt 12:02 04/05/10 +0100, Graham Klyne wrote:\n\n>Section 3.1:\n>\n>There is a subtlety here that is not obvious to one not well-versed in \n>Unicode specifics:\n>[[\n>       Variant B) If the IRI is in some digital representation (e.g. an\n>          octet stream) in some known non-Unicode character encoding:\n>          Convert the IRI to a sequence of characters from the UCS\n>          normalized according to NFC.\n>\n>       Variant C) If the IRI is in an Unicode-based character encoding\n>          (for example UTF-8 or UTF-16): Do not normalize. Move directly\n>          to Step 2.\n>]]\n>\n>This raises two questions in my mind:\n>\n>(a) what is the implication of this NFC stuff;  I think a brief example \n>would help.\n\nNon-Unicode encodings are less or more prone to variability when\ntranscoding. For example, when transcoding from the windows-1258\nhharset (Vietnamese), you can either transcode codepoint-by-codepoint,\nor you can normalize. For example, Vietnam is written\n     Vi&#x1EC7;t Nam\ni.e. a single \"LATIN SMALL LETTER E WITH CIRCUMFLEX AND DOT BELOW\" in\nUnicode (in particular NFC/NFKC), whereas in windows-1258, you have\nto use the following characters:\n     Vi&#xEA;&#x323;t Nam\ni.e. \"LATIN SMALL LETTER E WITH CIRCUMFLEX\" followed by\n\"COMBINING DOT BELOW\", because the character &#x1EC7; just\ncannot be encoding in windows-1252. Similar issues exist\nwith all other 8-bit encodings for Vietnamese. Encodings\nfor other languages are also affected, but to a lesser extent.\n\nI have added a note using this example.\n\n\n>(b) by saying \"Move directly to Step 2\" it sounds as if this is saying \n>that step 2 should be operated directly on the \"Unicode-based character \n>encoding\" rather than on the UCS characters, which I don't think is what \n>you intend.  I think something like this is intended:\n>[[\n>       Variant C) If the IRI is in an Unicode-based character encoding\n>          (for example UTF-8 or UTF-16): Do not normalize.  Apply step 2\n>          directly to the encoded Unicode character sequence.\n>]]\n\nThis is a helpful clarification, and a good catch, which I have\nintegrated (capitalizing 'Step' in 'Step 2').\n\n\nI have tentatively closed this issue; please tell me if the\nabove changes address your issue.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1787231"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nI have marked this as issue 5.2resolve-32.\n\nAt 12:02 04/05/10 +0100, Graham Klyne wrote:\n\n>Section 5.2:\n>\n>The MUST in the second paragraph seems to be straying inappropriately into \n>application design territory.\n\nSorry, but I don't think so. If different applications resolve\nin different ways, that would be a very bad idea.\n\nThis is also equivalent to some of the text at the start of\nSection 3.1.\n\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-1797498"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nThis is my last reply. Many thanks again for your comments.\nThis is issue needAPI-34.\n\nAt 12:02 04/05/10 +0100, Graham Klyne wrote:\n\n>Finally, I find myself being vaguely concerned about the complexity and \n>subtlety of this specification.  I expect that a lot of software will be \n>written by programmers who are not aware of the various subtle \n>implications of I18N issues.  As such, will it be a realistic expectation \n>for such programmers to write robust interoperable software based on this \n>specification.  Or, another way of addressing this concern:  to what \n>extent can the various subtleties described here be wrapped up in a \n>library that can be used successfully by a programmer who is not expert in \n>I18N issues?\n>\n>(I think part of the difficulty here is the extent to which IRIs straddle \n>wire-protocol and user presentation concerns.  I don't normally advocate \n>the idea of standardized APIs, but wonder if this is a case for which \n>defining a common API might help to flush out some of these concerns.)\n\nWe have already seen implementations of IRIs in various browsers\n(Opera, Safari, IE (with the exception of IDN), Amaya, Netscape).\nNobody from these implementers has every mentioned the need for\nan API, at least not to me.\n\nIn many cases I guess APIs for URIs are reused by making use\nof the fact that IRIs essentially work the same way as URIs,\nand in many programming languages these days representing\nUnicode is no longer that much of a problem.\n\nThere may be other applications than browser that have other\nneeds. But I'm not sure we could guess their needs now.\n\nIf there turns out to be a need for an API in some area in\nthe future, I'm confident this can be addressed as a separate\nproject.\n\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-1805712"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nI have listed this as issue normRef-33.\n\n\nAt 12:02 04/05/10 +0100, Graham Klyne wrote:\n\n>References\n>\n>I think RFC2119 should appear under Normative references, not Informative.\n\nDone.\n\n\n>I don't know about this, but should [UNIV4] and [UNI9] be normative?\n\nThey are referenced in a normative sentence in the bidi section, so\nyes, fixed. I guess we could move [UNIV4] out of that, if we really\nwant (our reference practice seems to lean towards ISO 10646,\nrather than Unicode).\n\nMichel, what do you think? Can you have a look at it?\nI guess the reference to 10646 may also need updating,\ncan you give me the newest version?\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1815281"}, {"subject": "Re: draft-duerst-iri-07.txt: 2 week mailing list last call   (IRIsyntax28", "content": "Martin,\n\nThanks for your response.  Where you say:\n[[\nI think what you mean is to only change some terminal productions,\nbut leave the rest unchanged. There are several reasons why this\nhasn't been done:\n]]\nThis was roughly what I had in mind, but I can see why you prefer not to do \nthis.  This is primarily a matter of preference and perspective, and I am \ncontent to accept your decision.  Your point about URI vs IRI is well-made.\n\nSimply adding a brief descriptive paragraph capturing the thrust of this:\n[[\n- In the most general sense, it would have been okay to just\n   add ucschar to unreserved. But there is the issue of allowing\n   private characters in query parts, but not elsewhere.\n]]\nin the introduction to the section about the grammar would have helped me \nto see quickly where the changes were; e.g.\n[[\nThe following grammar closely follows the URI grammar in [RFC2396bis], \nexcept that the range of unreserved characters is expanded to include UCS \ncharacters, with the restriction that private UCS characters can occur only \nin query parts and not elsewhere.\n]]\n\n#g\n--\n\nAt 10:02 12/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>Many thanks for your comments. I'm responding in pieces,\n>as I split things up into issues. This is issue\n>http://www.w3.org/International/iri-edit/#IRIsyntax-28\n>\n>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>\n>>Martin,\n>>\n>>These comments are based on a quick skim rather than a detailed reading.\n>>\n>>Looking at this from an implementer's perspective, I feel it would be \n>>helpful if the relationship between the IRI and URI *grammars* were more \n>>clearly delineated;  e.g. a presentation of IRI syntax that is based on \n>>the RFC2396bis grammar,\n>\n>It definitely is. I have very carefully followed all the changes\n>in the RFC2396bis grammar. I very much hope I got it right, but\n>any additional crosschecks would be greatly appreciated.\n>\n>\n>>replacing a minimum number of productions.\n>\n>I think that's also the case.\n>\n>I think what you mean is to only change some terminal productions,\n>but leave the rest unchanged. There are several reasons why this\n>hasn't been done:\n>\n>- In the most general sense, it would have been okay to just\n>   add ucschar to unreserved. But there is the issue of allowing\n>   private characters in query parts, but not elsewhere.\n>- Looking top down, what you seem to want may actually imply\n>   to use 'URI' rather than 'IRI' at the start of the grammar.\n>   I think that would have been more confusing than helpful.\n>   And once you start making these distinctions, it would\n>   then again be confusing to e.g. use 'path' rather than\n>   'ipath'.\n>- The current solution allows to very easily create a combined\n>   grammar of URIs and IRIs, which some people might want to do.\n>   If the two grammars would use the same symbols for things that\n>   are on  purpose the same, but in actual syntax are different,\n>   that wouldn't work.\n>- The grammar allows somebody who wants to only implement IRIs\n>   to do that directly. It may lead to less implementation\n>   divergence than a verbal description of differences against\n>   another spec.\n>\n>\n>>On this basis, it would be easier to see what needs to be changed in a \n>>URI parser to yield an IRI parser.\n>\n>I hope it's already easy enough to see. I have used very\n>straightforward naming conventions to correlate the corresponding\n>nonterminals in both grammars. If there is 'URI' in the original\n>nonterminal, I have changed that to 'IRI'. Otherwise, I have\n>prefixed an 'i'. If you think this is helpful, I can add a\n>sentence to that effect.\n>\n>\n>>Also, I note that the RFC2396bis grammar has been through several \n>>revisions as subtle issues are exposed by review and implementation \n>>experience;  by replicating the entire grammar (rather than saying that \n>>an IRI is like a URI with designated changes), can you be confident that \n>>such issues have not been re-introduced?\n>\n>Of course, there is never any absolute confidence, but as far as\n>I remember, these issues were all related to details around\n>special cases such as e.g. empty paths. They are therefore\n>orthogonal to the issue of extending the repertoire of\n>'reserved' characters. One might be able to immagine some\n>interactions if e.g. authorities and paths were extended\n>in a different way, but the difference is for query parts,\n>which are very clearly delineated, and haven't been at\n>issue in the bugs you mention above.\n>\n>I hope you are satisfied with this answer. If not, I would\n>appreciate a more detailled proposal.\n>\n>\n>Regards,   Martin.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1824113"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "At 17:59 12/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>I have labeled this issue as convertASCII-30.\n>\n>\n>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>\n>>Section 3.2:\n>>\n>>Is this really true (about always mapping back to the same URI)?:\n>>[[\n>>3.2  Converting URIs to IRIs\n>>\n>>    In some situations, it may be desirable to try to convert a URI into\n>>    an equivalent IRI. This section gives a procedure to do such a\n>>    conversion. The conversion described in this section will always\n>>    result in an IRI which maps back to the URI that was used as an input\n>>    for the conversion (except for potential case differences in\n>>    percent-encoding). However, the IRI resulting from this conversion\n>>    may not be exactly the same as the original IRI (if there ever was\n>>    one).\n>>]]\n>>\n>>In light of:\n>>[[\n>>    2) Convert all percent-encodings (% followed by two hexadecimal\n>>       digits) except those corresponding to '%', characters in\n>>       'reserved', and characters in US-ASCII not allowed in URIs, to the\n>>       corresponding octets.\n>>]]\n>>\n>>It seems to me that removing percent encodings for non-reserved and other \n>>characters is a non-reversible transformation.  I think that mapping back \n>>to the original URI is only true under escape normalization, per rfc2396bis.\n>\n>Yes, good catch. I looked at the actual text that needs to be fixed.\n>I can either add non-reserved ASCII characters to the 'except'\n>clause in parentheses in the original text, or can change the\n>procedure. Overall, in terms of edits, both need about the same\n>work. Which one would you prefer?\n\nI'm not sure.  I think it's most important to remove the inconsistency.  I \nthink that, in practice, this is an area which developers and users would \nbe well-advised to avoid.\n\n#g\n--\n\n>It is clear that with or without removing percent-encodings for\n>non-reserved ASCII characters, this can be done, and different\n>usages may choose different variants, according to their needs.\n>\n>\n>>Also, not knowing anything about bidi encodings, it's difficult for me to \n>>tell if there's any possible interaction between this and the section 4 \n>>material on bidi sequences.\n>\n>There is some interaction as some characters and character\n>combinations are excluded by the bidi section. I think the\n>various cross-references within the text take care of this.\n>There is also some interaction that with the conversion\n>from URI to IRI, the display sequence of the components\n>may change. But this will just happen automatically, this\n>is not something the algorithm has to worry about.\n>\n>\n>Regards,    Martin.\n>\n>\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1837553"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "At 18:05 12/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>I have marked this as issue 5.2resolve-32.\n>\n>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>\n>>Section 5.2:\n>>\n>>The MUST in the second paragraph seems to be straying inappropriately \n>>into application design territory.\n>\n>Sorry, but I don't think so. If different applications resolve\n>in different ways, that would be a very bad idea.\n\nI agree that would not be good.  I think the \"MUST\" in the first paragraph \naddresses this.  I was referring to the \"MUST\" in the second paragraph:\n[[\nFor comparison, such conversions MUST only\nbe done on the fly, while retaining the original IRI.\n]]\n\n#g\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1848684"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "I'm entirely satisfied with this response.\n\n#g\n--\n\nAt 17:17 12/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>I have removed the uri list for this issue, because it's\n>really iri-specific.\n>This is issue\n>\n>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>\n>>Section 3.1:\n>>\n>>There is a subtlety here that is not obvious to one not well-versed in \n>>Unicode specifics:\n>>[[\n>>       Variant B) If the IRI is in some digital representation (e.g. an\n>>          octet stream) in some known non-Unicode character encoding:\n>>          Convert the IRI to a sequence of characters from the UCS\n>>          normalized according to NFC.\n>>\n>>       Variant C) If the IRI is in an Unicode-based character encoding\n>>          (for example UTF-8 or UTF-16): Do not normalize. Move directly\n>>          to Step 2.\n>>]]\n>>\n>>This raises two questions in my mind:\n>>\n>>(a) what is the implication of this NFC stuff;  I think a brief example \n>>would help.\n>\n>Non-Unicode encodings are less or more prone to variability when\n>transcoding. For example, when transcoding from the windows-1258\n>hharset (Vietnamese), you can either transcode codepoint-by-codepoint,\n>or you can normalize. For example, Vietnam is written\n>     Vi&#x1EC7;t Nam\n>i.e. a single \"LATIN SMALL LETTER E WITH CIRCUMFLEX AND DOT BELOW\" in\n>Unicode (in particular NFC/NFKC), whereas in windows-1258, you have\n>to use the following characters:\n>     Vi&#xEA;&#x323;t Nam\n>i.e. \"LATIN SMALL LETTER E WITH CIRCUMFLEX\" followed by\n>\"COMBINING DOT BELOW\", because the character &#x1EC7; just\n>cannot be encoding in windows-1252. Similar issues exist\n>with all other 8-bit encodings for Vietnamese. Encodings\n>for other languages are also affected, but to a lesser extent.\n>\n>I have added a note using this example.\n>\n>\n>>(b) by saying \"Move directly to Step 2\" it sounds as if this is saying \n>>that step 2 should be operated directly on the \"Unicode-based character \n>>encoding\" rather than on the UCS characters, which I don't think is what \n>>you intend.  I think something like this is intended:\n>>[[\n>>       Variant C) If the IRI is in an Unicode-based character encoding\n>>          (for example UTF-8 or UTF-16): Do not normalize.  Apply step 2\n>>          directly to the encoded Unicode character sequence.\n>>]]\n>\n>This is a helpful clarification, and a good catch, which I have\n>integrated (capitalizing 'Step' in 'Step 2').\n>\n>\n>I have tentatively closed this issue; please tell me if the\n>above changes address your issue.\n>\n>Regards,    Martin.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1857304"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "I'm sure your right.  This wasn't a particularly helpful comment on my part \nand should probably be closed without further action.\n\n#g\n--\n\nAt 18:25 12/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>This is my last reply. Many thanks again for your comments.\n>This is issue needAPI-34.\n>\n>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>\n>>Finally, I find myself being vaguely concerned about the complexity and \n>>subtlety of this specification.  I expect that a lot of software will be \n>>written by programmers who are not aware of the various subtle \n>>implications of I18N issues.  As such, will it be a realistic expectation \n>>for such programmers to write robust interoperable software based on this \n>>specification.  Or, another way of addressing this concern:  to what \n>>extent can the various subtleties described here be wrapped up in a \n>>library that can be used successfully by a programmer who is not expert \n>>in I18N issues?\n>>\n>>(I think part of the difficulty here is the extent to which IRIs straddle \n>>wire-protocol and user presentation concerns.  I don't normally advocate \n>>the idea of standardized APIs, but wonder if this is a case for which \n>>defining a common API might help to flush out some of these concerns.)\n>\n>We have already seen implementations of IRIs in various browsers\n>(Opera, Safari, IE (with the exception of IDN), Amaya, Netscape).\n>Nobody from these implementers has every mentioned the need for\n>an API, at least not to me.\n>\n>In many cases I guess APIs for URIs are reused by making use\n>of the fact that IRIs essentially work the same way as URIs,\n>and in many programming languages these days representing\n>Unicode is no longer that much of a problem.\n>\n>There may be other applications than browser that have other\n>needs. But I'm not sure we could guess their needs now.\n>\n>If there turns out to be a need for an API in some area in\n>the future, I'm confident this can be addressed as a separate\n>project.\n>\n>\n>Regards,     Martin.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1867806"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "At 18:00 12/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>I have made this issue charcompareMUST-31.\n>\n>\n>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>\n>\n>>Section 5.1:\n>>\n>>[[\n>>5.1  Simple String Comparison\n>>\n>>    In some scenarios a definite answer to the question of IRI\n>>    equivalence is needed that is independent of the scheme used and\n>>    always can be calculated quickly and without accessing a network. An\n>>    example of such a case is XML Namespaces ([XMLNamespace]). In such\n>>    cases, two IRIs SHOULD be defined as equivalent if and only if they\n>>    are character-by-character equivalent. This is the same as being\n>>    byte-by-byte equivalent if the character encoding for both IRIs is\n>>    the same. As an example,\n>>    http://example.org/~user, http://example.org/%7euser, and\n>>    http://example.org/%7Euser are not equivalent under this definition.\n>>    In such a case, the comparison function MUST NOT map IRIs to URIs,\n>>    because such a mapping would create additional spurious equivalences.\n>>]]\n>>\n>>It's not clear to me what the MUST NOT here is saying.  Making normative \n>>statements that are conditional on some postulated application scenario \n>>seems to be a bit confusing to me.\n>\n>If you interpreted the statement as conditional on some application\n>scenario, then it is indeed confusing. It was intended conditional\n>to the comparison function. I.e. if you use character-by-character\n>comparison, you MUST NOT map IRIs to URIs,\n>because such a mapping would create additional spurious equivalences.\n\nI was taking the choice of comparison function to be part of the \napplication scenario.\n\n>I have replaced \"In such a case\" with \"When comparing character-by-character\".\n\nI think that's better, though it doesn't quite capture my original \ncomment.  (Consider:  as this is given as a normative statement, how do you \npropose to find interoperable implementations to demonstrate conformance \nwhen moving to Draft Standard?  I still prefer my suggestion (below), \nbut  now I've raised the issue I'm happy for you to decide.\n\n>>I think the final sentence maybe should be:\n>>[[\n>>The IRI to URI mapping function described above [ref] does not preserve \n>>this form of equivalence.\n>>]]\n\n\n>>(Further, the MUST NOT here seems even more perverse in light of the \n>>introductory material in section 3.1)\n>\n>I have checked that material again, and did not find any problems.\n>You may observe that that material is carefully worded in terms of\n>retrieval when it comes to IRI->URI mapping, not in terms of\n>abstract resource identification.\n\nOK, ignore that last comment.  (I wasn't specifically thinking about \nabstract identification.)\n\nBut I note that it's not obvious to me that start of section 3.1 is subject \nto the mention of \"resource retrieval\" that appears in section \n3[.0].  Indeed the fact that the material in 3.1 is also said to apply to \nreferences and fragment identifiers suggests otherwise.\n\nChecking for scheme-specific syntax restrictions does not seem to be \nspecifically related to resource retrieval.  (cf. URN syntax checking.)\n\nLooking more closely at point (b) in 3.1, which clearly *is* about resource \nretrieval, I find myself having further qualms:\n[[\nHowever, when an IRI is used for resource\nretrieval, the resource that the IRI locates is the same as the\none located by the URI obtained after converting the IRI according\nto the procedure defined here. This means that there is no need to\ndefine resolution separately on the IRI level.\n]]\n\nThis seems to preclude the possibility of defining a resolution protocol \nthat uses IRIs natively.  Effectively, this is an imposition on any future \nprotocol specification that can be used to resolve IRIs, which seems like a \nrather broad sweep.  Maybe this is OK, and really is what was intended, but \nI feel compelled to at least mention the point.   If this is what you \nintend, I think the point would usefully be more prominent in the text, and \nshould be made a normative assertion;  e.g. a top-level paragraph ala:\n[[\nWhen an IRI is used for resource retrieval, >>it must be by means of a \nprotocol that\ncan also be used with URIs, and<< the resource that the IRI locates MUST be \nthe same as\nthe one located by the URI obtained after converting the IRI according to the\nprocedure defined here.\n]]\n\nIt might be argued that the text between >> and << is redundant, to the \nextent that any URI is also a valid IRI.  (But, thinking aloud, ... suppose \nI wanted to invent a new IRI scheme and protocol to serve as a kind of \nChinese WordNet, with definitions retrievable in much the same way as they \nare for WordNet.  (Notwithstanding that this may not be a good idea for \nother reasons.)  In such a scheme, maybe there is a component which, \naccording to the IRI scheme specification, must contain Chinese character \nsymbol(s), so there are no URIs that are valid IRIs according to this \nscheme.  I don't know where this leads.  My main point is to try and raise \na vaguely plausible scenario in which existence of a URI form for resource \nretrieval may be undesirable.)\n\n\n>>I suspect there should be some discouragement of applications depending \n>>on this level of equivalence, in view of the spurious distinctions that \n>>are lost when IRIs are converted to URIs.   To my mind the string \n>>equivalence of the URI-converted form seems like the lowest reasonable \n>>level of distinction to be encouraged.\n>\n>Well, there are some serious arguments against this:\n>- Some very important applications, in particular XML Namespaces\n>   and RDF, use this equivalence. So recommendation against this\n>   would cause confusion.\n>- Needing to convert to URIs for every comparison is inefficient\n>   (that was the main argument for namespaces)\n>- Needing to convert to URIs may lead to more URIs (rather than IRIs)\n>   floating around, because in some cases, the conversion would\n>   leak.\n>So that's why we should not go there.\n\nBut these \"important applications\" are defined in terms of URIs, not \nIRIs.  I'm not suggesting that one should be required to convert to URIs \nfor every comparison, but that it might be discouraged to rely on \ndifferences between IRIs that are not present on conversion to URIs.\n\nI note that your document specifically makes reference to conversion to \nURIs being (notionally) used for a number of purpose, so in this respect \nIRIs are not something whose existence is independent of URIs, and to that \nextent I think to gloss over problems that might arise when conversion to \nURIs is performed may leave room for problems.\n\nPlease note that the general thrust of my comments is not to request any \nchange to the actual (normative) specification, but to clearly signal in \nsome way that problems might occur if these issues are not observed.\n\n>I hope the above addresses your concerns.\n\nI regard this as ultimately your call, and I won't raise any formal \nobjection if you don't agree with me, but I may continue to debate the \nmatter with you to the extent that it's helpful to you.\n\n#g\n\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1877607"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "For the record, I'm entirely satisfied with this response.\n\n#g\n--\n\nAt 18:13 12/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>I have listed this as issue normRef-33.\n>\n>\n>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>\n>>References\n>>\n>>I think RFC2119 should appear under Normative references, not Informative.\n>\n>Done.\n>\n>\n>>I don't know about this, but should [UNIV4] and [UNI9] be normative?\n>\n>They are referenced in a normative sentence in the bidi section, so\n>yes, fixed. I guess we could move [UNIV4] out of that, if we really\n>want (our reference practice seems to lean towards ISO 10646,\n>rather than Unicode).\n>\n>Michel, what do you think? Can you have a look at it?\n>I guess the reference to 10646 may also need updating,\n>can you give me the newest version?\n>\n>\n>Regards,    Martin.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1893028"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nMany thanks for your quick responses. I have closed issues\nnormRef-33, 3.1BC-norm-29, and needAPI-34.\n\nRegards,     Martin.\n\nAt 13:03 04/05/12 +0100, Graham Klyne wrote:\n\n>For the record, I'm entirely satisfied with this response.\n>\n>#g\n>--\n>\n>At 18:13 12/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>I have listed this as issue normRef-33.\n>>\n>>\n>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>\n>>>References\n>>>\n>>>I think RFC2119 should appear under Normative references, not Informative.\n>>\n>>Done.\n>>\n>>\n>>>I don't know about this, but should [UNIV4] and [UNI9] be normative?\n>>\n>>They are referenced in a normative sentence in the bidi section, so\n>>yes, fixed. I guess we could move [UNIV4] out of that, if we really\n>>want (our reference practice seems to lean towards ISO 10646,\n>>rather than Unicode).\n>>\n>>Michel, what do you think? Can you have a look at it?\n>>I guess the reference to 10646 may also need updating,\n>>can you give me the newest version?\n>>\n>>\n>>Regards,    Martin.\n>\n>------------\n>Graham Klyne\n>For email:\n>http://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1902179"}, {"subject": "Re: draft-duerst-iri-07.txt: 2 week mailing list last call     (IRIsyntax28", "content": "Hello Graham,\n\nI have added the text that you propose below, and appended the\nfollowing:\nThe grammar is split into two parts, rules that differ from\n[RFC2396bis] because of the above-mentioned expansion, and rules\nthat are the same as in [RFC2396bis]. For rules that are different\nthan in [RFC2396bis], the names of the non-terminals have been\nchanged as follows: If the non-terminal contains 'URI', this has\nbeen changed to 'IRI'. Otherwise, an 'i' has been prefixed.\n\nI have tentatively closed this comment.\n\nRegards,    Martin.\n\nAt 10:37 04/05/12 +0100, Graham Klyne wrote:\n\n>Martin,\n>\n>Thanks for your response.  Where you say:\n>[[\n>I think what you mean is to only change some terminal productions,\n>but leave the rest unchanged. There are several reasons why this\n>hasn't been done:\n>]]\n>This was roughly what I had in mind, but I can see why you prefer not to \n>do this.  This is primarily a matter of preference and perspective, and I \n>am content to accept your decision.  Your point about URI vs IRI is well-made.\n>\n>Simply adding a brief descriptive paragraph capturing the thrust of this:\n>[[\n>- In the most general sense, it would have been okay to just\n>   add ucschar to unreserved. But there is the issue of allowing\n>   private characters in query parts, but not elsewhere.\n>]]\n>in the introduction to the section about the grammar would have helped me \n>to see quickly where the changes were; e.g.\n>[[\n>The following grammar closely follows the URI grammar in [RFC2396bis], \n>except that the range of unreserved characters is expanded to include UCS \n>characters, with the restriction that private UCS characters can occur \n>only in query parts and not elsewhere.\n>]]\n>\n>#g\n>--\n>\n>At 10:02 12/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>Many thanks for your comments. I'm responding in pieces,\n>>as I split things up into issues. This is issue\n>>http://www.w3.org/International/iri-edit/#IRIsyntax-28\n>>\n>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>\n>>>Martin,\n>>>\n>>>These comments are based on a quick skim rather than a detailed reading.\n>>>\n>>>Looking at this from an implementer's perspective, I feel it would be \n>>>helpful if the relationship between the IRI and URI *grammars* were more \n>>>clearly delineated;  e.g. a presentation of IRI syntax that is based on \n>>>the RFC2396bis grammar,\n>>\n>>It definitely is. I have very carefully followed all the changes\n>>in the RFC2396bis grammar. I very much hope I got it right, but\n>>any additional crosschecks would be greatly appreciated.\n>>\n>>\n>>>replacing a minimum number of productions.\n>>\n>>I think that's also the case.\n>>\n>>I think what you mean is to only change some terminal productions,\n>>but leave the rest unchanged. There are several reasons why this\n>>hasn't been done:\n>>\n>>- In the most general sense, it would have been okay to just\n>>   add ucschar to unreserved. But there is the issue of allowing\n>>   private characters in query parts, but not elsewhere.\n>>- Looking top down, what you seem to want may actually imply\n>>   to use 'URI' rather than 'IRI' at the start of the grammar.\n>>   I think that would have been more confusing than helpful.\n>>   And once you start making these distinctions, it would\n>>   then again be confusing to e.g. use 'path' rather than\n>>   'ipath'.\n>>- The current solution allows to very easily create a combined\n>>   grammar of URIs and IRIs, which some people might want to do.\n>>   If the two grammars would use the same symbols for things that\n>>   are on  purpose the same, but in actual syntax are different,\n>>   that wouldn't work.\n>>- The grammar allows somebody who wants to only implement IRIs\n>>   to do that directly. It may lead to less implementation\n>>   divergence than a verbal description of differences against\n>>   another spec.\n>>\n>>\n>>>On this basis, it would be easier to see what needs to be changed in a \n>>>URI parser to yield an IRI parser.\n>>\n>>I hope it's already easy enough to see. I have used very\n>>straightforward naming conventions to correlate the corresponding\n>>nonterminals in both grammars. If there is 'URI' in the original\n>>nonterminal, I have changed that to 'IRI'. Otherwise, I have\n>>prefixed an 'i'. If you think this is helpful, I can add a\n>>sentence to that effect.\n>>\n>>\n>>>Also, I note that the RFC2396bis grammar has been through several \n>>>revisions as subtle issues are exposed by review and implementation \n>>>experience;  by replicating the entire grammar (rather than saying that \n>>>an IRI is like a URI with designated changes), can you be confident that \n>>>such issues have not been re-introduced?\n>>\n>>Of course, there is never any absolute confidence, but as far as\n>>I remember, these issues were all related to details around\n>>special cases such as e.g. empty paths. They are therefore\n>>orthogonal to the issue of extending the repertoire of\n>>'reserved' characters. One might be able to immagine some\n>>interactions if e.g. authorities and paths were extended\n>>in a different way, but the difference is for query parts,\n>>which are very clearly delineated, and haven't been at\n>>issue in the bugs you mention above.\n>>\n>>I hope you are satisfied with this answer. If not, I would\n>>appreciate a more detailled proposal.\n>>\n>>\n>>Regards,   Martin.\n>\n>------------\n>Graham Klyne\n>For email:\n>http://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1910766"}, {"subject": "Re: draft-duerst-iri-07.txt: 2 week mailing list last call     (IRIsyntax28", "content": "At 14:20 13/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>I have added the text that you propose below, and appended the\n>following:\n>The grammar is split into two parts, rules that differ from\n>[RFC2396bis] because of the above-mentioned expansion, and rules\n>that are the same as in [RFC2396bis]. For rules that are different\n>than in [RFC2396bis], the names of the non-terminals have been\n>changed as follows: If the non-terminal contains 'URI', this has\n>been changed to 'IRI'. Otherwise, an 'i' has been prefixed.\n>\n>I have tentatively closed this comment.\n\nI think that's fine.  Thanks.\n\n#g\n\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-1925325"}, {"subject": "Re: Editorial suggestions for draft-duerst-iri-07 [issue  editorial-Lilley27", "content": "On Tuesday, May 11, 2004, 2:59:51 PM, Martin wrote:\n\nMD> At 03:08 04/05/11 +0200, Chris Lilley wrote:\n\n>>Hello public-iri,\n\nMD> Hello Chris,\n\nMD> Many thanks for your comments. Because they are all editorial,\nMD> I have kept them as a single issue.\nMD> [http://www.w3.org/International/iri-edit/#editorial-Lilley-27]\nMD> Up to now, I haven't usually 'issuefied' editorial stuff, but I'm\nMD> starting to do that to document what has happened in last call.\n\n\n>>These editorial comments relate to\n>>http://www.w3.org/International/iri-edit/draft-duerst-iri-07.txt\n>>\n>> From the new appendix A\n>>\n>> >  New schemes are not needed to distinguish URIs from true IRIs (i.e.\n>>    IRIs that contain non-ASCII characters). The benefit of being able to\n>>    detect the origin of percent-encodings is marginal, also because\n>>    UTF-8 can be detected with very high reliably. Deploying new schemes\n>>    is extremely hard. Not needing new schemes for IRIs makes deployment\n>>    of IRIs vastly easier. Making conversion scheme-dependent is highly\n>>    unadvisable. Using an uniform convention for conversion from IRIs to\n>>    URIs makes IRI implementation orthogonal from the introduction of\n>>    acual new schemes.\n>>\n>>I suggest some slight wording and spelling changes (editorial)\n>>\n>>   New schemes are not needed to distinguish URIs from true IRIs (i.e.\n>>   IRIs that contain non-ASCII characters). The benefit of being able\n>>   to detect the origin of percent-encodings is marginal, because UTF-8\n>>   can be detected with very high reliability. Deploying new schemes is\n>>   extremely hard, so not requiring new schemes for IRIs makes\n>>   deployment of IRIs vastly easier. Making conversion scheme-dependent\n>>   is highly inadvisable, and would be encouraged by such an approach.\n>>   Using an uniform convention for conversion from IRIs to URIs makes\n>>   IRI implementation orthogonal to the introduction of actual new\n>>   schemes.\n\nMD> Changed. I replaced \"by such an approach\" with \"by separate schemes\nMD> for IRIs\" to make things even clearer.\n\nThats good.\n\n\n>>It might also be added that the TAG recommends not adding new schemes\n>>that are almost exactly like HTTP; i:http: or httpi: would have\n>>exactly that problem.\n\nMD> Do you have a reference? I'd like to give the underlying argument\nMD> rather than just saying 'the TAG said'.\n\nArchitecture of the World Wide Web, First Edition\nEditor's Draft 10 May 2004\n\n2.4. URI Schemes\nhttp://www.w3.org/2001/tag/2004/webarch-20040510/#URI-scheme\n\nGood practice: New URI schemes\n\nA specification SHOULD NOT introduce a new URI scheme when an existing\nscheme provides the desired properties of identifiers and their\nrelation to resources\n\n\n>> >  UTF-8 avoids a double layering and overloading of the use of the \"+\"\n>>    character. UTF-8 is fully compatible with US-ASCII, and has\n>>    therefore been recommended by the IETF, and is being used widely,\n>>    while UTF-7 has never been used much and is now clearly being\n>>    discouraged.\n>>\n>>I suggest a small change\n>>\n>>    Using UTF-8 avoids a double layering and overloading of the use of\n>>    the \"+\" character. UTF-8 is fully compatible with US-ASCII, and has\n>>    therefore been recommended by the IETF, and is being used widely,\n>>    while UTF-7 has never been used much and is now clearly being\n>>    discouraged.\n>>\n>>You might also mention here that using UTF-8 here is existing practice\n\nMD> Do you mean in the context of URIs, or much more general?\n\nBoth.\n\nMD> The subsection starts out with \"At an early stage, UTF-7 was considered\",\nMD> and in that context, it wouldn't be true. The fact that many URI\nMD> schemes now use UTF-8 in one way or another is largely due to the decision\nMD> to use UTF-8 for IRIs, and to the general rise of UTF-8.\n\nSo its circular. Okay.\n\n\n>>and that requiring implementations to convert to the rarely used UTF-7\n>>is an additional implementation burden.\n\nMD> That's a good point. I added:\nMD> \"Requiring implementations to convert from UTF-8\nMD> to UTF-7 and back would be an additional implementation burden.\"\n\nGreat.\n\n>>The arguments against using %u and against inline encoding\n>>declarations are well made.\n\nMD> Thanks!\n\n\n>>In 3.1  Mapping of IRIs to URIs, the renumbering of the sub steps in\n>>step two is clearer than in the previous draft.\n\nMD> Thanks. That was a private suggestion from Chris Haynes.\n\n\n>>Should non-realworld, non-resolving sample URIs such as\n>>http://big.site/PopularPage.html not be, for example,\n>>http://big.example/PopularPage.html ?\n\nMD> In that case probably http://big.example.com/PopularPage.html.\nMD> Done. [I made that example.com, even though all other examples\nMD> are example.org, but I guess in that case, that's justified.]\n\n\nYes, thats fine.\n\nThank you, I am satisfied by the response to all my comments.\n\n-- \n Chris Lilley                    mailto:chris@w3.org\n Chair, W3C SVG Working Group\n Member, W3C Technical Architecture Group\n\n\n\n", "id": "lists-017-1934596"}, {"subject": "RE: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "> From: Martin Duerst [mailto:duerst@w3.org] \n>\n> Michel, what do you think? Can you have a look at it?\n> I guess the reference to 10646 may also need updating,\n> can you give me the newest version?\n\nMartin in the normative reference section please update as follows:\n\n [ISO10646]   ISO/IEC 10646:2003\n              International Organization for Standardization,\n              \"Information Technology - Universal Multiple-Octet Coded\n              Character Set (UCS), December 2003.\n\n   [UNI9]     Davis, M., \"The Bidirectional Algorithm\", Unicode Standard\n              Annex #9, March 2004,\n<http://www.unicode.org/reports/tr9/tr9-13.html>.\n\n   [UNIV4]    The Unicode Consortium, \"The Unicode Standard, Version\n              4.01\", March 2004, defined by: The Unicode Standard,\nVersion 4.0\n              (Reading, MA, Addison-Wesley, 2003. ISBN 0-321-18578-1),\n              as amended by Unicode 4.0.1\n(http://www.unicode.org/versions/Unicode4.0.1/).\n\n   [UTR15]    Davis, M. and M. Duerst, \"Unicode Normalization Forms\",\n              Unicode Standard Annex #15, April 2003,\n<http://www.unicode.org/reports/tr15/tr15-23.html>.\n \n\nI updated the link to 10646 to the latest edition which was just\npublished by ISO. Technically it is the same as before, but that edition\nmerge the two parts.\nYou should make sure that the normative reference to the Unicode webd\nsites are dated, one of your previous links [UNI9] went to the 'latest'\none which is not proper for normative references. The HTML version of\nthe IRI draft should also show explicitly the link values, which it\ndoesn't as of now. Unicode 4.01 still use the same repertoire as\n10646:2003, so we are good on that part.\n\nMichel\n\n\n\n", "id": "lists-017-1948600"}, {"subject": "RE: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Michel,\n\nI have listed this as issue ISO-Uni-ref-34.\n\nAt 09:45 04/05/14 -0700, Michel Suignard wrote:\n\n> > From: Martin Duerst [mailto:duerst@w3.org]\n> >\n> > Michel, what do you think? Can you have a look at it?\n> > I guess the reference to 10646 may also need updating,\n> > can you give me the newest version?\n>\n>Martin in the normative reference section please update as follows:\n>\n>  [ISO10646]   ISO/IEC 10646:2003\n>               International Organization for Standardization,\n>               \"Information Technology - Universal Multiple-Octet Coded\n>               Character Set (UCS), December 2003.\n>\n>    [UNI9]     Davis, M., \"The Bidirectional Algorithm\", Unicode Standard\n>               Annex #9, March 2004,\n><http://www.unicode.org/reports/tr9/tr9-13.html>.\n>\n>    [UNIV4]    The Unicode Consortium, \"The Unicode Standard, Version\n>               4.01\",\n\nI think this should be 4.0.1, yes?\n\n\n>March 2004, defined by: The Unicode Standard,\n>Version 4.0\n>               (Reading, MA, Addison-Wesley, 2003. ISBN 0-321-18578-1),\n>               as amended by Unicode 4.0.1\n>(http://www.unicode.org/versions/Unicode4.0.1/).\n>\n>    [UTR15]    Davis, M. and M. Duerst, \"Unicode Normalization Forms\",\n>               Unicode Standard Annex #15, April 2003,\n><http://www.unicode.org/reports/tr15/tr15-23.html>.\n>\n>\n>I updated the link to 10646 to the latest edition which was just\n>published by ISO. Technically it is the same as before, but that edition\n>merge the two parts.\n\nThanks. This simplifies a lot.\n\n\n>You should make sure that the normative reference to the Unicode webd\n>sites are dated, one of your previous links [UNI9] went to the 'latest'\n>one which is not proper for normative references.\n\nWell yes. But for the record, my personal expectation would be\nthat the IRI spec follows updates of these other specs in the\nfuture. In most cases, the changes only deal with edge cases\nanyway. Of course, we have to make sure that we take this\ndecision explicitly in each case, so that we can assess\nthe impact.\n\n\n>The HTML version of\n>the IRI draft should also show explicitly the link values, which it\n>doesn't as of now.\n\nIf you know what option to set in xml2rfc, I'll do it.\nOtherwise, I don't want to spend the time, because the HTML\nversion is just a sideline. What counts for the IETF is the\ntext/plain version.\n\n\n>Unicode 4.01 still use the same repertoire as\n>10646:2003, so we are good on that part.\n\nI have marked this issue as tentatively closed.\nCan you please do another cross-check?\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1959436"}, {"subject": "Re: draft-duerst-iri-07.txt: 2 week mailing list last call       (IRIsyntax28", "content": "At 17:19 04/05/13 +0100, Graham Klyne wrote:\n\n>At 14:20 13/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>I have added the text that you propose below, and appended the\n>>following:\n>>The grammar is split into two parts, rules that differ from\n>>[RFC2396bis] because of the above-mentioned expansion, and rules\n>>that are the same as in [RFC2396bis]. For rules that are different\n>>than in [RFC2396bis], the names of the non-terminals have been\n>>changed as follows: If the non-terminal contains 'URI', this has\n>>been changed to 'IRI'. Otherwise, an 'i' has been prefixed.\n>>\n>>I have tentatively closed this comment.\n>\n>I think that's fine.  Thanks.\n\nThanks. I have closed this issue.     Martin.\n\n\n\n", "id": "lists-017-1970334"}, {"subject": "Re: Editorial suggestions for draft-duerst-iri-07 [issue    editorial-Lilley27", "content": "Hello Chris,\n\nMany thanks for your response.\n\nAt 05:26 04/05/14 +0200, Chris Lilley wrote:\n\n>On Tuesday, May 11, 2004, 2:59:51 PM, Martin wrote:\n>\n>MD> At 03:08 04/05/11 +0200, Chris Lilley wrote:\n>\n>MD> Many thanks for your comments. Because they are all editorial,\n>MD> I have kept them as a single issue.\n>MD> [http://www.w3.org/International/iri-edit/#editorial-Lilley-27]\n\n> >>It might also be added that the TAG recommends not adding new schemes\n> >>that are almost exactly like HTTP; i:http: or httpi: would have\n> >>exactly that problem.\n>\n>MD> Do you have a reference? I'd like to give the underlying argument\n>MD> rather than just saying 'the TAG said'.\n>\n>Architecture of the World Wide Web, First Edition\n>Editor's Draft 10 May 2004\n>\n>2.4. URI Schemes\n>http://www.w3.org/2001/tag/2004/webarch-20040510/#URI-scheme\n>\n>Good practice: New URI schemes\n>\n>A specification SHOULD NOT introduce a new URI scheme when an existing\n>scheme provides the desired properties of identifiers and their\n>relation to resources\n\nThanks. I have decided to not reference it, although in theory,\na reference to 'work in progress' could be okay even for a\nStandards Track document. But I think it's good to have this\nhere in the mailing list for potential future reference.\nAs for the underlying arguments, I think the current text already\nprovides them, although of course in a very compact fashion.\n\n\n>Thank you, I am satisfied by the response to all my comments.\n\nI have closed this issue.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1979330"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "At 14:02 04/05/12 +0100, Graham Klyne wrote:\n\n>At 18:05 12/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>I have marked this as issue 5.2resolve-32.\n>>\n>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>\n>>>Section 5.2:\n>>>\n>>>The MUST in the second paragraph seems to be straying inappropriately \n>>>into application design territory.\n>>\n>>Sorry, but I don't think so. If different applications resolve\n>>in different ways, that would be a very bad idea.\n>\n>I agree that would not be good.  I think the \"MUST\" in the first paragraph \n>addresses this.  I was referring to the \"MUST\" in the second paragraph:\n>[[\n>For comparison, such conversions MUST only\n>be done on the fly, while retaining the original IRI.\n>]]\n\nOkay, sorry for the confusion. So we are looking at the following text:\n\n    If this kind of equivalence is to be tested, the percent-encoding of\n    both IRIs to be compared has to be aligned, for example by converting\n    both IRIs to URIs (see Section 3.1) and making sure that the case of\n    the hexadecimal characters in the percent-encode is always the same\n    (preferably upper case). For comparison, such conversions MUST only\n    be done on the fly, while retaining the original IRI.\n\nI have noticed that this again assumes that there are no escaping issues\nwith URIs, which is not true. I have therefore changed it to:\n\n    If this kind of equivalence is to be tested, the percent-encoding of\n    both IRIs to be compared has to be aligned, for example by converting\n    both IRIs to URIs (see Section 3.1), *eliminating escape\n    differences in the resulting URIs,* and making sure that the case of\n    the hexadecimal characters in the percent-encode is always the same\n    (preferably upper case). For comparison, such conversions MUST only\n    be done on the fly, while retaining the original IRI.\n\n\nComing back to your original point, I have reworded\n\n    For comparison, such conversions MUST only be done on the fly,\n    while retaining the original IRI.\n\nto\n\n    In order to conserve the original IRIs, such conversions SHOULD\n    only be done on the fly, while retaining the IRIs.\n\nThe main goal here is to make clear to implementers that they shouldn't\njust convert everything to URIs and stay there, because then the whole\npoint of IRIs would be lost. So to some extent, you may call this \"straying \ninto application design territory\", but to some extent, it's just a\nconsequence of actually using IRIs. I have changed the MUST to a SHOULD,\nbecause I think that's more appropriate.\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-1988615"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nAt 12:44 04/05/12 +0100, Graham Klyne wrote:\n\n>At 18:00 12/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>I have made this issue charcompareMUST-31.\n>>\n>>\n>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>\n>>\n>>>Section 5.1:\n>>>\n>>>[[\n>>>5.1  Simple String Comparison\n>>>\n>>>    In some scenarios a definite answer to the question of IRI\n>>>    equivalence is needed that is independent of the scheme used and\n>>>    always can be calculated quickly and without accessing a network. An\n>>>    example of such a case is XML Namespaces ([XMLNamespace]). In such\n>>>    cases, two IRIs SHOULD be defined as equivalent if and only if they\n>>>    are character-by-character equivalent. This is the same as being\n>>>    byte-by-byte equivalent if the character encoding for both IRIs is\n>>>    the same. As an example,\n>>>    http://example.org/~user, http://example.org/%7euser, and\n>>>    http://example.org/%7Euser are not equivalent under this definition.\n>>>    In such a case, the comparison function MUST NOT map IRIs to URIs,\n>>>    because such a mapping would create additional spurious equivalences.\n>>>]]\n>>>\n>>>It's not clear to me what the MUST NOT here is saying.  Making normative \n>>>statements that are conditional on some postulated application scenario \n>>>seems to be a bit confusing to me.\n>>\n>>If you interpreted the statement as conditional on some application\n>>scenario, then it is indeed confusing. It was intended conditional\n>>to the comparison function. I.e. if you use character-by-character\n>>comparison, you MUST NOT map IRIs to URIs,\n>>because such a mapping would create additional spurious equivalences.\n>\n>I was taking the choice of comparison function to be part of the \n>application scenario.\n\nWell, I think it depends on what you mean by 'application'. If\n'XML Namespaces' or 'RDF' are applications, then you are right.\nIf each XML or RDF parser are applications, then it is wrong.\n\n\n>>I have replaced \"In such a case\" with \"When comparing \n>>character-by-character\".\n>\n>I think that's better, though it doesn't quite capture my original \n>comment.  (Consider:  as this is given as a normative statement, how do \n>you propose to find interoperable implementations to demonstrate \n>conformance when moving to Draft Standard?  I still prefer my suggestion \n>(below), but  now I've raised the issue I'm happy for you to decide.\n\nWell, testing a few XSLT implementations would clearly show that they\ntreat IRIs as such, and don't convert them to URIs, for namespace URIs.\nI have already done such tests quite a while ago.\nSo I don't think demonstrating conformance would be a big deal for this.\n\n\n>>>I think the final sentence maybe should be:\n>>>[[\n>>>The IRI to URI mapping function described above [ref] does not preserve \n>>>this form of equivalence.\n>>>]]\n>\n>\n>>>(Further, the MUST NOT here seems even more perverse in light of the \n>>>introductory material in section 3.1)\n>>\n>>I have checked that material again, and did not find any problems.\n>>You may observe that that material is carefully worded in terms of\n>>retrieval when it comes to IRI->URI mapping, not in terms of\n>>abstract resource identification.\n>\n>OK, ignore that last comment.  (I wasn't specifically thinking about \n>abstract identification.)\n>\n>But I note that it's not obvious to me that start of section 3.1 is \n>subject to the mention of \"resource retrieval\" that appears in section 3[.0].\n\nThis is again taken up and explained in more detail in \"b) Interpretational:\".\n\n\n>Indeed the fact that the material in 3.1 is also said to apply to \n>references and fragment identifiers suggests otherwise.\n\nYou mean the sentence:\n\"Everything in this section applies also to IRI references and URI references,\nas well as components thereof (for example fragment identifiers).\"\n\nI agree that the 'everything' may be a bit general. But what is 'everything'\nof 3.1? First, it is the mapping procedure itself. This means that you can\nmap an IRI reference to an URI reference in the same way you can map an\nIRI to an URI. And you can map a fragid in an IRI to a fragid in an URI\nin the same way as you map an IRI to an URI.\n\nSecond, it is the context/purpose. Two purposes are given:\n- retrieval\n- syntax check\nWith respect to syntax check, the sentence above means that you can\nsyntax check an IRI reference or a fragid of an IRI by converting to\nan URI reference or fragid of an URI. With respect to retrieval,\nwith an appropriate base, IRI references and URI references can\ndefinitely be retrieved. You are right that retrieval of\nfragment identifiers does not make that much sense.\n\n\n>Checking for scheme-specific syntax restrictions does not seem to be \n>specifically related to resource retrieval.  (cf. URN syntax checking.)\n\nYes, right, I forgot to mention it before.\n\n\n>Looking more closely at point (b) in 3.1, which clearly *is* about \n>resource retrieval, I find myself having further qualms:\n>[[\n>However, when an IRI is used for resource\n>retrieval, the resource that the IRI locates is the same as the\n>one located by the URI obtained after converting the IRI according\n>to the procedure defined here. This means that there is no need to\n>define resolution separately on the IRI level.\n>]]\n>\n>This seems to preclude the possibility of defining a resolution protocol \n>that uses IRIs natively.\n\nNo. This just precludes the possibility of defining a resolution protocol\nthat makes a distinction e.g. between '%7e', '%7E', and '~'. Most resolution\nprotocols are not able to make this distinction, because they do not use\npercent-encoding, and therefore the client resolves these differences.\nThe only protocol I know that doesn't is HTTP, and HTTP also defines\nthat these are equivalent, and servers implement things that way\n(except where the percent-encoding is used to distinguish reserved\ncharacters that the server has to deal with, such as '?').\n\n\n>Effectively, this is an imposition on any future protocol specification \n>that can be used to resolve IRIs, which seems like a rather broad \n>sweep.  Maybe this is OK, and really is what was intended, but I feel \n>compelled to at least mention the point.   If this is what you intend, I \n>think the point would usefully be more prominent in the text, and should \n>be made a normative assertion;  e.g. a top-level paragraph ala:\n>[[\n>When an IRI is used for resource retrieval, >>it must be by means of a \n>protocol that\n>can also be used with URIs, and<<\n\nThis would be a tautology, because all URIs are by definition IRIs.\n\n\n>the resource that the IRI locates MUST be the same as\n>the one located by the URI obtained after converting the IRI according to the\n>procedure defined here.\n>]]\n\nThis is given normatively in Section 5.2:\n\n\"For actual resolution, differences in percent-encoding (except for the\npercent-encoding of reserved characters) MUST always result in the same \nresource.\"\n\nDo you want to say that this should be in two places, or that it is\nin the wrong place?\n\n\n>It might be argued that the text between >> and << is redundant, to the \n>extent that any URI is also a valid IRI.\n\nYes indeed, I just did that, sorry.\n\n\n>(But, thinking aloud, ... suppose I wanted to invent a new IRI scheme and \n>protocol to serve as a kind of Chinese WordNet, with definitions \n>retrievable in much the same way as they are for \n>WordNet.  (Notwithstanding that this may not be a good idea for other \n>reasons.)  In such a scheme, maybe there is a component which, according \n>to the IRI scheme specification, must contain Chinese character symbol(s), \n>so there are no URIs that are valid IRIs according to this scheme.\n\nNo, all the URIs that result from percent-encoding the UTF-8-encoded\nChinese characters would be legal. Not necessarily in the protocol\n(the protocol may specify that these are just transmitted as raw octets),\nbut on the URI/IRI level.\n\n\n>I don't know where this leads.  My main point is to try and raise a \n>vaguely plausible scenario in which existence of a URI form for resource \n>retrieval may be undesirable.)\n\nWell, of course it would not be very desirable to use the percent-encoded\nform of a Chinese WordNet IRI, at least not for Chinese speakers. But\nit could be convenient for you, assuming you don't read Chinese.\n\n\n>>>I suspect there should be some discouragement of applications depending \n>>>on this level of equivalence, in view of the spurious distinctions that \n>>>are lost when IRIs are converted to URIs.   To my mind the string \n>>>equivalence of the URI-converted form seems like the lowest reasonable \n>>>level of distinction to be encouraged.\n>>\n>>Well, there are some serious arguments against this:\n>>- Some very important applications, in particular XML Namespaces\n>>   and RDF, use this equivalence. So recommendation against this\n>>   would cause confusion.\n>>- Needing to convert to URIs for every comparison is inefficient\n>>   (that was the main argument for namespaces)\n>>- Needing to convert to URIs may lead to more URIs (rather than IRIs)\n>>   floating around, because in some cases, the conversion would\n>>   leak.\n>>So that's why we should not go there.\n>\n>But these \"important applications\" are defined in terms of URIs, not IRIs.\n\nNo, not exactly. Namespaces 1.0 is defined in terms of URIs, but if you test\nactual implementations (which I have done), it's implemented in terms of IRIs.\nNamespaces 1.1 fixes that gap by using IRIs.\nRDF uses something called RDF URI references, which, if you look closely,\nare actually IRIs. Please check out\nhttp://www.w3.org/TR/2004/REC-rdf-concepts-20040210/#dfn-URI-reference.\n\n\n>I'm not suggesting that one should be required to convert to URIs for \n>every comparison,\n\nGood.\n\n\n>but that it might be discouraged to rely on differences between IRIs that \n>are not present on conversion to URIs.\n\nGood point. This has been brought up in various discussions e.g. related\nto namespaces. In terms of namespaces, it reads: Namespaces compare\ncharacter-by-character, so don't chage escaping. But don't try to use\ntwo namespaces that only differ by escaping, because that would just\nbe stupid and would lead to confusion.\n\nI added some text at the end of 5.1:\n\n >>>>\n    On the other hand, even if the only forseen use of an IRI is as\n    an identifier in scenarios that use character-by-character equivalence,\n    creators of IRIs should not create IRIs that only differ by \npercent-escaping.\n    As an example, using both http://example.org/~user and\n    http://example.org/%7Euser to identify XML Namespaces is a bad idea.\n >>>>\n\nI hope this addresses your concern.\n\n\n>I note that your document specifically makes reference to conversion to \n>URIs being (notionally) used for a number of purpose, so in this respect \n>IRIs are not something whose existence is independent of URIs, and to that \n>extent I think to gloss over problems that might arise when conversion to \n>URIs is performed may leave room for problems.\n>\n>Please note that the general thrust of my comments is not to request any \n>change to the actual (normative) specification, but to clearly signal in \n>some way that problems might occur if these issues are not observed.\n>\n>>I hope the above addresses your concerns.\n>\n>I regard this as ultimately your call, and I won't raise any formal \n>objection if you don't agree with me, but I may continue to debate the \n>matter with you to the extent that it's helpful to you.\n\nI hope we are getting closer. The more people reading the spec, the\nbetter we can make sure we all know what it is supposed to say.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-1999113"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nAt 14:06 04/05/12 +0100, Graham Klyne wrote:\n\n>At 17:59 12/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>I have labeled this issue as convertASCII-30.\n>>\n>>\n>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>\n>>>Section 3.2:\n>>>\n>>>Is this really true (about always mapping back to the same URI)?:\n>>>[[\n>>>3.2  Converting URIs to IRIs\n>>>\n>>>    In some situations, it may be desirable to try to convert a URI into\n>>>    an equivalent IRI. This section gives a procedure to do such a\n>>>    conversion. The conversion described in this section will always\n>>>    result in an IRI which maps back to the URI that was used as an input\n>>>    for the conversion (except for potential case differences in\n>>>    percent-encoding). However, the IRI resulting from this conversion\n>>>    may not be exactly the same as the original IRI (if there ever was\n>>>    one).\n>>>]]\n>>>\n>>>In light of:\n>>>[[\n>>>    2) Convert all percent-encodings (% followed by two hexadecimal\n>>>       digits) except those corresponding to '%', characters in\n>>>       'reserved', and characters in US-ASCII not allowed in URIs, to the\n>>>       corresponding octets.\n>>>]]\n>>>\n>>>It seems to me that removing percent encodings for non-reserved and \n>>>other characters is a non-reversible transformation.  I think that \n>>>mapping back to the original URI is only true under escape \n>>>normalization, per rfc2396bis.\n>>\n>>Yes, good catch. I looked at the actual text that needs to be fixed.\n>>I can either add non-reserved ASCII characters to the 'except'\n>>clause in parentheses in the original text, or can change the\n>>procedure. Overall, in terms of edits, both need about the same\n>>work. Which one would you prefer?\n>\n>I'm not sure.  I think it's most important to remove the inconsistency.\n\nI have decided that it is better to also remove spurious percent-encodings\nof non-reserved US-ASCII characters, because probably the main use of\nthe conversion from URIs to IRIs is for presentation purposes.\n\nI have changed\n\n    (except for potential case differences in percent-encoding)\n\nto\n\n    (except for potential case differences in percent-encoding\n     and for potential percent-encoded unreserved characters)\n\nI have also changed\n\n    This procedure will convert as many percent-encoded non-ASCII\n    characters as possible to characters in an IRI.\nto\n    This procedure will convert as many percent-encoded characters\n    as possible to characters in an IRI.\n\nI hope this addresses your concern.\n\n\nRegards,   Martin.\n\n>I think that, in practice, this is an area which developers and users \n>would be well-advised to avoid.\n>\n>#g\n>--\n>\n>>It is clear that with or without removing percent-encodings for\n>>non-reserved ASCII characters, this can be done, and different\n>>usages may choose different variants, according to their needs.\n>>\n>>\n>>>Also, not knowing anything about bidi encodings, it's difficult for me \n>>>to tell if there's any possible interaction between this and the section \n>>>4 material on bidi sequences.\n>>\n>>There is some interaction as some characters and character\n>>combinations are excluded by the bidi section. I think the\n>>various cross-references within the text take care of this.\n>>There is also some interaction that with the conversion\n>>from URI to IRI, the display sequence of the components\n>>may change. But this will just happen automatically, this\n>>is not something the algorithm has to worry about.\n>>\n>>\n>>Regards,    Martin.\n>>\n>\n>------------\n>Graham Klyne\n>For email:\n>http://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-2019720"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "At 12:07 19/05/04 +0900, Martin Duerst wrote:\n>Coming back to your original point, I have reworded\n>\n>    For comparison, such conversions MUST only be done on the fly,\n>    while retaining the original IRI.\n>\n>to\n>\n>    In order to conserve the original IRIs, such conversions SHOULD\n>    only be done on the fly, while retaining the IRIs.\n\nMartin,\n\nI think that's better, but I still think it is making normative statements \nabout implementation technique, which was the point of my original \ncomment.  (And I think the normative point you do want to make really \nshould be a MUST!)\n\nFor example, I think this this might say what you want without dictating \nimplementation:\n[[\nIf the IRI is to be passed to another application, or used further in some \nother way, its original form MUST be preserved;  the conversion described \nhere should be performed only for the purpose of local comparison.\n]]\n\n#g\n--\n\nAt 12:07 19/05/04 +0900, Martin Duerst wrote:\n>At 14:02 04/05/12 +0100, Graham Klyne wrote:\n>\n>>At 18:05 12/05/04 +0900, Martin Duerst wrote:\n>>>Hello Graham,\n>>>\n>>>I have marked this as issue 5.2resolve-32.\n>>>\n>>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>>\n>>>>Section 5.2:\n>>>>\n>>>>The MUST in the second paragraph seems to be straying inappropriately \n>>>>into application design territory.\n>>>\n>>>Sorry, but I don't think so. If different applications resolve\n>>>in different ways, that would be a very bad idea.\n>>\n>>I agree that would not be good.  I think the \"MUST\" in the first \n>>paragraph addresses this.  I was referring to the \"MUST\" in the second \n>>paragraph:\n>>[[\n>>For comparison, such conversions MUST only\n>>be done on the fly, while retaining the original IRI.\n>>]]\n>\n>Okay, sorry for the confusion. So we are looking at the following text:\n>\n>    If this kind of equivalence is to be tested, the percent-encoding of\n>    both IRIs to be compared has to be aligned, for example by converting\n>    both IRIs to URIs (see Section 3.1) and making sure that the case of\n>    the hexadecimal characters in the percent-encode is always the same\n>    (preferably upper case). For comparison, such conversions MUST only\n>    be done on the fly, while retaining the original IRI.\n>\n>I have noticed that this again assumes that there are no escaping issues\n>with URIs, which is not true. I have therefore changed it to:\n>\n>    If this kind of equivalence is to be tested, the percent-encoding of\n>    both IRIs to be compared has to be aligned, for example by converting\n>    both IRIs to URIs (see Section 3.1), *eliminating escape\n>    differences in the resulting URIs,* and making sure that the case of\n>    the hexadecimal characters in the percent-encode is always the same\n>    (preferably upper case). For comparison, such conversions MUST only\n>    be done on the fly, while retaining the original IRI.\n>\n>\n>Coming back to your original point, I have reworded\n>\n>    For comparison, such conversions MUST only be done on the fly,\n>    while retaining the original IRI.\n>\n>to\n>\n>    In order to conserve the original IRIs, such conversions SHOULD\n>    only be done on the fly, while retaining the IRIs.\n>\n>The main goal here is to make clear to implementers that they shouldn't\n>just convert everything to URIs and stay there, because then the whole\n>point of IRIs would be lost. So to some extent, you may call this \n>\"straying into application design territory\", but to some extent, it's just a\n>consequence of actually using IRIs. I have changed the MUST to a SHOULD,\n>because I think that's more appropriate.\n>\n>Regards,     Martin.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-2031903"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Martin,\n\nI think our discussion becomes one of specification style.  I appreciate \nthe need to prepare a specification that reflects what applications \nactually do, but I'd prefer that it not do so by saying that future \napplications must follow the same procedures as existing applications.\n\n(By \"application\", I mean here any end-user function that employs the \ntechnologies.  So for this debate, I'd view 'XML Namespaces' or 'RDF' as \npart of the infrastructure whose functionality might or might not be part \nof an application.)\n\nUnfortunately, I've lost the context of the original comment, so now that \nit's been aired I'll leave it to your discretion.\n\nRegarding your suggested addition:\n> >>>>\n>    On the other hand, even if the only forseen use of an IRI is as\n>    an identifier in scenarios that use character-by-character equivalence,\n>    creators of IRIs should not create IRIs that only differ by \n> percent-escaping.\n>    As an example, using both http://example.org/~user and\n>    http://example.org/%7Euser to identify XML Namespaces is a bad idea.\n> >>>>\n\nI think this helps, but I'd probably strengthen it a bit, thus:\n[[\n    When an IRI is used as an identifier in scenarios that depend\n    upon character-by-character equivalence, creators of IRIs should\n    take additional care to avoid IRIs that only differ in their use\n    of percent-escaping.\n    As an example, using both http://example.org/~user and\n    http://example.org/%7Euser to identify XML Namespaces is a bad idea.\n]]\n\n(Changes:  (a) avoid reference to \"foreseen\" use;  (b) try to avoid the \nimplication that it's OK in other scenarios -- I think we'd agree that it's \nnever ideal to coin IRIs that differ only in their use of escaping.)\n\n#g\n--\n\n\nAt 14:18 19/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>At 12:44 04/05/12 +0100, Graham Klyne wrote:\n>\n>>At 18:00 12/05/04 +0900, Martin Duerst wrote:\n>>>Hello Graham,\n>>>\n>>>I have made this issue charcompareMUST-31.\n>>>\n>>>\n>>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>>\n>>>\n>>>>Section 5.1:\n>>>>\n>>>>[[\n>>>>5.1  Simple String Comparison\n>>>>\n>>>>    In some scenarios a definite answer to the question of IRI\n>>>>    equivalence is needed that is independent of the scheme used and\n>>>>    always can be calculated quickly and without accessing a network. An\n>>>>    example of such a case is XML Namespaces ([XMLNamespace]). In such\n>>>>    cases, two IRIs SHOULD be defined as equivalent if and only if they\n>>>>    are character-by-character equivalent. This is the same as being\n>>>>    byte-by-byte equivalent if the character encoding for both IRIs is\n>>>>    the same. As an example,\n>>>>    http://example.org/~user, http://example.org/%7euser, and\n>>>>    http://example.org/%7Euser are not equivalent under this definition.\n>>>>    In such a case, the comparison function MUST NOT map IRIs to URIs,\n>>>>    because such a mapping would create additional spurious equivalences.\n>>>>]]\n>>>>\n>>>>It's not clear to me what the MUST NOT here is saying.  Making \n>>>>normative statements that are conditional on some postulated \n>>>>application scenario seems to be a bit confusing to me.\n>>>\n>>>If you interpreted the statement as conditional on some application\n>>>scenario, then it is indeed confusing. It was intended conditional\n>>>to the comparison function. I.e. if you use character-by-character\n>>>comparison, you MUST NOT map IRIs to URIs,\n>>>because such a mapping would create additional spurious equivalences.\n>>\n>>I was taking the choice of comparison function to be part of the \n>>application scenario.\n>\n>Well, I think it depends on what you mean by 'application'. If\n>'XML Namespaces' or 'RDF' are applications, then you are right.\n>If each XML or RDF parser are applications, then it is wrong.\n>\n>\n>>>I have replaced \"In such a case\" with \"When comparing \n>>>character-by-character\".\n>>\n>>I think that's better, though it doesn't quite capture my original \n>>comment.  (Consider:  as this is given as a normative statement, how do \n>>you propose to find interoperable implementations to demonstrate \n>>conformance when moving to Draft Standard?  I still prefer my suggestion \n>>(below), but  now I've raised the issue I'm happy for you to decide.\n>\n>Well, testing a few XSLT implementations would clearly show that they\n>treat IRIs as such, and don't convert them to URIs, for namespace URIs.\n>I have already done such tests quite a while ago.\n>So I don't think demonstrating conformance would be a big deal for this.\n>\n>\n>>>>I think the final sentence maybe should be:\n>>>>[[\n>>>>The IRI to URI mapping function described above [ref] does not preserve \n>>>>this form of equivalence.\n>>>>]]\n>>\n>>\n>>>>(Further, the MUST NOT here seems even more perverse in light of the \n>>>>introductory material in section 3.1)\n>>>\n>>>I have checked that material again, and did not find any problems.\n>>>You may observe that that material is carefully worded in terms of\n>>>retrieval when it comes to IRI->URI mapping, not in terms of\n>>>abstract resource identification.\n>>\n>>OK, ignore that last comment.  (I wasn't specifically thinking about \n>>abstract identification.)\n>>\n>>But I note that it's not obvious to me that start of section 3.1 is \n>>subject to the mention of \"resource retrieval\" that appears in section 3[.0].\n>\n>This is again taken up and explained in more detail in \"b) Interpretational:\".\n>\n>\n>>Indeed the fact that the material in 3.1 is also said to apply to \n>>references and fragment identifiers suggests otherwise.\n>\n>You mean the sentence:\n>\"Everything in this section applies also to IRI references and URI references,\n>as well as components thereof (for example fragment identifiers).\"\n>\n>I agree that the 'everything' may be a bit general. But what is 'everything'\n>of 3.1? First, it is the mapping procedure itself. This means that you can\n>map an IRI reference to an URI reference in the same way you can map an\n>IRI to an URI. And you can map a fragid in an IRI to a fragid in an URI\n>in the same way as you map an IRI to an URI.\n>\n>Second, it is the context/purpose. Two purposes are given:\n>- retrieval\n>- syntax check\n>With respect to syntax check, the sentence above means that you can\n>syntax check an IRI reference or a fragid of an IRI by converting to\n>an URI reference or fragid of an URI. With respect to retrieval,\n>with an appropriate base, IRI references and URI references can\n>definitely be retrieved. You are right that retrieval of\n>fragment identifiers does not make that much sense.\n>\n>\n>>Checking for scheme-specific syntax restrictions does not seem to be \n>>specifically related to resource retrieval.  (cf. URN syntax checking.)\n>\n>Yes, right, I forgot to mention it before.\n>\n>\n>>Looking more closely at point (b) in 3.1, which clearly *is* about \n>>resource retrieval, I find myself having further qualms:\n>>[[\n>>However, when an IRI is used for resource\n>>retrieval, the resource that the IRI locates is the same as the\n>>one located by the URI obtained after converting the IRI according\n>>to the procedure defined here. This means that there is no need to\n>>define resolution separately on the IRI level.\n>>]]\n>>\n>>This seems to preclude the possibility of defining a resolution protocol \n>>that uses IRIs natively.\n>\n>No. This just precludes the possibility of defining a resolution protocol\n>that makes a distinction e.g. between '%7e', '%7E', and '~'. Most resolution\n>protocols are not able to make this distinction, because they do not use\n>percent-encoding, and therefore the client resolves these differences.\n>The only protocol I know that doesn't is HTTP, and HTTP also defines\n>that these are equivalent, and servers implement things that way\n>(except where the percent-encoding is used to distinguish reserved\n>characters that the server has to deal with, such as '?').\n>\n>\n>>Effectively, this is an imposition on any future protocol specification \n>>that can be used to resolve IRIs, which seems like a rather broad \n>>sweep.  Maybe this is OK, and really is what was intended, but I feel \n>>compelled to at least mention the point.   If this is what you intend, I \n>>think the point would usefully be more prominent in the text, and should \n>>be made a normative assertion;  e.g. a top-level paragraph ala:\n>>[[\n>>When an IRI is used for resource retrieval, >>it must be by means of a \n>>protocol that\n>>can also be used with URIs, and<<\n>\n>This would be a tautology, because all URIs are by definition IRIs.\n>\n>\n>>the resource that the IRI locates MUST be the same as\n>>the one located by the URI obtained after converting the IRI according to the\n>>procedure defined here.\n>>]]\n>\n>This is given normatively in Section 5.2:\n>\n>\"For actual resolution, differences in percent-encoding (except for the\n>percent-encoding of reserved characters) MUST always result in the same \n>resource.\"\n>\n>Do you want to say that this should be in two places, or that it is\n>in the wrong place?\n>\n>\n>>It might be argued that the text between >> and << is redundant, to the \n>>extent that any URI is also a valid IRI.\n>\n>Yes indeed, I just did that, sorry.\n>\n>\n>>(But, thinking aloud, ... suppose I wanted to invent a new IRI scheme and \n>>protocol to serve as a kind of Chinese WordNet, with definitions \n>>retrievable in much the same way as they are for \n>>WordNet.  (Notwithstanding that this may not be a good idea for other \n>>reasons.)  In such a scheme, maybe there is a component which, according \n>>to the IRI scheme specification, must contain Chinese character \n>>symbol(s), so there are no URIs that are valid IRIs according to this scheme.\n>\n>No, all the URIs that result from percent-encoding the UTF-8-encoded\n>Chinese characters would be legal. Not necessarily in the protocol\n>(the protocol may specify that these are just transmitted as raw octets),\n>but on the URI/IRI level.\n>\n>\n>>I don't know where this leads.  My main point is to try and raise a \n>>vaguely plausible scenario in which existence of a URI form for resource \n>>retrieval may be undesirable.)\n>\n>Well, of course it would not be very desirable to use the percent-encoded\n>form of a Chinese WordNet IRI, at least not for Chinese speakers. But\n>it could be convenient for you, assuming you don't read Chinese.\n>\n>\n>>>>I suspect there should be some discouragement of applications depending \n>>>>on this level of equivalence, in view of the spurious distinctions that \n>>>>are lost when IRIs are converted to URIs.   To my mind the string \n>>>>equivalence of the URI-converted form seems like the lowest reasonable \n>>>>level of distinction to be encouraged.\n>>>\n>>>Well, there are some serious arguments against this:\n>>>- Some very important applications, in particular XML Namespaces\n>>>   and RDF, use this equivalence. So recommendation against this\n>>>   would cause confusion.\n>>>- Needing to convert to URIs for every comparison is inefficient\n>>>   (that was the main argument for namespaces)\n>>>- Needing to convert to URIs may lead to more URIs (rather than IRIs)\n>>>   floating around, because in some cases, the conversion would\n>>>   leak.\n>>>So that's why we should not go there.\n>>\n>>But these \"important applications\" are defined in terms of URIs, not IRIs.\n>\n>No, not exactly. Namespaces 1.0 is defined in terms of URIs, but if you test\n>actual implementations (which I have done), it's implemented in terms of IRIs.\n>Namespaces 1.1 fixes that gap by using IRIs.\n>RDF uses something called RDF URI references, which, if you look closely,\n>are actually IRIs. Please check out\n>http://www.w3.org/TR/2004/REC-rdf-concepts-20040210/#dfn-URI-reference.\n>\n>\n>>I'm not suggesting that one should be required to convert to URIs for \n>>every comparison,\n>\n>Good.\n>\n>\n>>but that it might be discouraged to rely on differences between IRIs that \n>>are not present on conversion to URIs.\n>\n>Good point. This has been brought up in various discussions e.g. related\n>to namespaces. In terms of namespaces, it reads: Namespaces compare\n>character-by-character, so don't chage escaping. But don't try to use\n>two namespaces that only differ by escaping, because that would just\n>be stupid and would lead to confusion.\n>\n>I added some text at the end of 5.1:\n>\n> >>>>\n>    On the other hand, even if the only forseen use of an IRI is as\n>    an identifier in scenarios that use character-by-character equivalence,\n>    creators of IRIs should not create IRIs that only differ by \n> percent-escaping.\n>    As an example, using both http://example.org/~user and\n>    http://example.org/%7Euser to identify XML Namespaces is a bad idea.\n> >>>>\n>\n>I hope this addresses your concern.\n>\n>\n>>I note that your document specifically makes reference to conversion to \n>>URIs being (notionally) used for a number of purpose, so in this respect \n>>IRIs are not something whose existence is independent of URIs, and to \n>>that extent I think to gloss over problems that might arise when \n>>conversion to URIs is performed may leave room for problems.\n>>\n>>Please note that the general thrust of my comments is not to request any \n>>change to the actual (normative) specification, but to clearly signal in \n>>some way that problems might occur if these issues are not observed.\n>>\n>>>I hope the above addresses your concerns.\n>>\n>>I regard this as ultimately your call, and I won't raise any formal \n>>objection if you don't agree with me, but I may continue to debate the \n>>matter with you to the extent that it's helpful to you.\n>\n>I hope we are getting closer. The more people reading the spec, the\n>better we can make sure we all know what it is supposed to say.\n>\n>\n>Regards,    Martin.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-2043735"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Martin,\n\nFor the process, this looks fine to me.\n\n#g\n--\n\nAt 16:52 19/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>At 14:06 04/05/12 +0100, Graham Klyne wrote:\n>\n>>At 17:59 12/05/04 +0900, Martin Duerst wrote:\n>>>Hello Graham,\n>>>\n>>>I have labeled this issue as convertASCII-30.\n>>>\n>>>\n>>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>>\n>>>>Section 3.2:\n>>>>\n>>>>Is this really true (about always mapping back to the same URI)?:\n>>>>[[\n>>>>3.2  Converting URIs to IRIs\n>>>>\n>>>>    In some situations, it may be desirable to try to convert a URI into\n>>>>    an equivalent IRI. This section gives a procedure to do such a\n>>>>    conversion. The conversion described in this section will always\n>>>>    result in an IRI which maps back to the URI that was used as an input\n>>>>    for the conversion (except for potential case differences in\n>>>>    percent-encoding). However, the IRI resulting from this conversion\n>>>>    may not be exactly the same as the original IRI (if there ever was\n>>>>    one).\n>>>>]]\n>>>>\n>>>>In light of:\n>>>>[[\n>>>>    2) Convert all percent-encodings (% followed by two hexadecimal\n>>>>       digits) except those corresponding to '%', characters in\n>>>>       'reserved', and characters in US-ASCII not allowed in URIs, to the\n>>>>       corresponding octets.\n>>>>]]\n>>>>\n>>>>It seems to me that removing percent encodings for non-reserved and \n>>>>other characters is a non-reversible transformation.  I think that \n>>>>mapping back to the original URI is only true under escape \n>>>>normalization, per rfc2396bis.\n>>>\n>>>Yes, good catch. I looked at the actual text that needs to be fixed.\n>>>I can either add non-reserved ASCII characters to the 'except'\n>>>clause in parentheses in the original text, or can change the\n>>>procedure. Overall, in terms of edits, both need about the same\n>>>work. Which one would you prefer?\n>>\n>>I'm not sure.  I think it's most important to remove the inconsistency.\n>\n>I have decided that it is better to also remove spurious percent-encodings\n>of non-reserved US-ASCII characters, because probably the main use of\n>the conversion from URIs to IRIs is for presentation purposes.\n>\n>I have changed\n>\n>    (except for potential case differences in percent-encoding)\n>\n>to\n>\n>    (except for potential case differences in percent-encoding\n>     and for potential percent-encoded unreserved characters)\n>\n>I have also changed\n>\n>    This procedure will convert as many percent-encoded non-ASCII\n>    characters as possible to characters in an IRI.\n>to\n>    This procedure will convert as many percent-encoded characters\n>    as possible to characters in an IRI.\n>\n>I hope this addresses your concern.\n>\n>\n>Regards,   Martin.\n>\n>>I think that, in practice, this is an area which developers and users \n>>would be well-advised to avoid.\n>>\n>>#g\n>>--\n>>\n>>>It is clear that with or without removing percent-encodings for\n>>>non-reserved ASCII characters, this can be done, and different\n>>>usages may choose different variants, according to their needs.\n>>>\n>>>\n>>>>Also, not knowing anything about bidi encodings, it's difficult for me \n>>>>to tell if there's any possible interaction between this and the \n>>>>section 4 material on bidi sequences.\n>>>\n>>>There is some interaction as some characters and character\n>>>combinations are excluded by the bidi section. I think the\n>>>various cross-references within the text take care of this.\n>>>There is also some interaction that with the conversion\n>>>from URI to IRI, the display sequence of the components\n>>>may change. But this will just happen automatically, this\n>>>is not something the algorithm has to worry about.\n>>>\n>>>\n>>>Regards,    Martin.\n>>\n>>------------\n>>Graham Klyne\n>>For email:\n>>http://www.ninebynine.org/#Contact\n>\n>------------\n>Graham Klyne\n>For email:\n>http://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-2067418"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Martin Duerst scripsit:\n\n> Good point. This has been brought up in various discussions e.g. related\n> to namespaces. In terms of namespaces, it reads: Namespaces compare\n> character-by-character, so don't chage escaping. But don't try to use\n> two namespaces that only differ by escaping, because that would just\n> be stupid and would lead to confusion.\n\nI have proposed that the XML Core WG add the following motherhood note\nto both NS 1.0 and NS 1.1:\n\nNote:  Although namespace names are only identical if they\nconsist of the same characters in the same order, other uses of\nURIs provide different rules for identity.  Therefore, namespace\nnames SHOULD NOT:\n\na) use upper case characters in the scheme name;\nb) percent-encode any character that does not require it;\nc) use upper case letters in the host name;\nd) contain the sequences \"/../\" or \"/./\";\ne) specify an explicit port number that is equal to the default;\nf) end in \"/\" or \"#\" (namespace names used by RDF are an exception);\ng) make use of the \"file:\" scheme, since its meaning is not absolute.\n\nOf course, I'm not allowed to tell you what they think of the idea.  ;-)\n\nImprovements are solicited.\n\n-- \nJohn Cowan  jcowan@reutershealth.com  www.ccil.org/~cowan  www.reutershealth.com\n\"If I have seen farther than others, it is because I was standing on\nthe shoulders of giants.\"\n        --Isaac Newton\n\n\n\n", "id": "lists-017-2080260"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello John,\n\nAt 07:08 04/05/19 -0400, John Cowan wrote:\n\n>Martin Duerst scripsit:\n>\n> > Good point. This has been brought up in various discussions e.g. related\n> > to namespaces. In terms of namespaces, it reads: Namespaces compare\n> > character-by-character, so don't chage escaping. But don't try to use\n> > two namespaces that only differ by escaping, because that would just\n> > be stupid and would lead to confusion.\n>\n>I have proposed that the XML Core WG add the following motherhood note\n>to both NS 1.0 and NS 1.1:\n\nI think it is a very good idea to add such a note. Another, related\nthing is that namespace documents should actually contain the\nnamespace URI/IRI literally, rather than just rely on where they\nare, because they might be found with a slightly different URI/IRI.\nBut I guess that's too much of implementation advice that probably\ndoesn't belong in the spec.\n\n\n>         Note:  Although namespace names are only identical if they\n>         consist of the same characters in the same order, other uses of\n>         URIs provide different rules for identity.\n\nI would probably try to avoid the word 'identity'.\n\n\n>Therefore, namespace\n>         names SHOULD NOT:\n\nI think it is better to refer to the relevant section of RFC 2396bis,\nand to wait for that to become an RFC. Several of your points are\nnot alligned with RFC 2396bis, and you risk to be out of sync if\nthere are any changes.\n\n\n>         a) use upper case characters in the scheme name;\n>         b) percent-encode any character that does not require it;\n>         c) use upper case letters in the host name;\n>         d) contain the sequences \"/../\" or \"/./\";\n>         e) specify an explicit port number that is equal to the default;\n>         f) end in \"/\" or \"#\" (namespace names used by RDF are an exception);\n\nI think the '/' end is the default for some things in RFC 2396bis.\n\n\n>         g) make use of the \"file:\" scheme, since its meaning is not absolute.\n\nThis is the only point that is not discussed in section 6 of RFC 2396bis.\nBut it should be more general, there may be other schemes that are similar\nto \"file:\".\n\n\n>Of course, I'm not allowed to tell you what they think of the idea.  ;-)\n>\n>Improvements are solicited.\n\nYou should send this also to the URI list (uri@w3.org) for feedback.\n\nOne might also be able to argue that with the new URI spec and IRI spec,\nthe namespace spec(s) wouldn't need to say things like this anymore.\nBut it's probably still better to mention it.\n\n\nRegards,    Martin.\n\n\n>--\n>John \n>Cowan  jcowan@reutershealth.com  www.ccil.org/~cowan  www.reutershealth.com\n>\"If I have seen farther than others, it is because I was standing on\n>the shoulders of giants.\"\n>         --Isaac Newton\n\n\n\n", "id": "lists-017-2089865"}, {"subject": "Re: Issues: Section 3.1 references to nonASCII character", "content": "Hello Chris,\n\nI have noted this as issue non-ASCII-3.1-33.\n\nAt 10:37 04/05/11 +0100, Chris Haynes wrote:\n\n>Here are three related issues re. draft 7, Sect 3.1, Step 2.\n>\n>\n>\n>I have a concern with the sentence \"The disallowed characters consist of all\n>non-ASCII characters allowed in IRIs.\"\n>\n>(Issue 1) Since this step is referring to (presumably legal) IRIs, then the\n>phrase \"allowed in IRIs\" is superfluous - there could be no others.\n\nsee below.\n\n\n>--------------\n>\n>(Issue 2) Is the phrase \"non-ASCII characters\" sufficiently precice / \n>normative?\n>\n>I think here is a much cleaner definition available, providing you don't mind\n>dropping the allusion to the reasoning:\n>\n>\"The disallowed characters consist of all those matching 'ucschar' or \n>'iprivate'\n>of Section 2.2\"\n>\n>Altenatively, you could say something like \"The disallowed characters \n>consist of\n>all those whose UTF-8 encodings employ two or more octets\" (which is more \n>to the\n>point and all-embracing).\n\nsee below.\n\n>--------------\n>\n>\n>The definition of disallowed characters  now leads us to an apparent conflict\n>with step 2.1, which currently says to \"convert the character to one or more\n>octets using UTF-8\".\n>\n>Unless I've misunderstood some subtlety in the definition of 'disallowed\n>characters', all such characters will require at least two octets for their\n>encoding so we reach issue 3:\n>\n>\n>(Issue 3)  In Step 2.1 none of the characters to be so processed can have just\n>one octet in their UCS-8 encoding, so the instruction, strictly-speaking, \n>cannot\n>be obeyed.\n\nWell, you are right, except that strictly speaking, there is also\nthe following possibility, mentioned later in the spec:\n\n >>>>\nInfrastructure accepting IRIs MAY also deal with the printable characters\nin US-ASCII that are not allowed in URIs, namely \"&lt;\", \"&gt;\", '\"',\nSpace, \"{\", \"}\", \"|\", \"\\\", \"^\", and \"`\", in Step 2.2 above.\n >>>>\n\nExcept that it should say \"Step 2\", which I have fixed.\n\n\n\n>--------------\n>\n>\n>I also find the mixture of negatives and plurals in the introduction to step 2\n>somewhat confusing, so I've taken the liberty of suggesting some re-drafts \n>which\n>addresses all three issues.\n>\n>\n>One possible re-draft of the start of Step 2, which consolidates all the above\n>points, is:\n>\n>Version 1:\n>  vvvvvvvvvvvvvvvv\n>    Step 2)\n>       IRI characters matching 'ucschar' or 'iprivate' (section 2.2) are\n>disallowed in URI\n>       references. For each such character apply steps 2.1 through 2.3 below..\n>\n>          2.1) Encode the disallowed character using UTF-8, which will \n> generate a\n>sequence\n>          of two or more octets.\n>\n>          2.2) Convert each octet to %HH ........\n>^^^^^^^^^^^^^^^^\n>\n>An alternative re-draft is:\n>\n>Version 2:\n>vvvvvvvvvvvvvvvv\n>    Step 2)\n>       IRI characters whose UCS-8 encodings emply two or more octets are\n>disallowed in\n>       URI references. For each such character apply steps 2.1 through 2.3\n>below..\n>\n>          2.1) Encode the disallowed character using UTF-8, which will \n> generate a\n>sequence\n>           of two or more octets.\n>\n>          2.2) Convert each octet to %HH ........\n>^^^^^^^^^^^^^^^^\n>\n>\n>yet a third, which restores the reasoning, is:\n>\n>Version 3:\n>vvvvvvvvvvvvvvvv\n>    Step 2)\n>       IRI characters whose UCS-8 encodings emply two or more octets are\n>disallowed in\n>       URI references because they are not US-ASCII characters. For each such\n>character\n>       apply steps 2.1 through 2.3 below..\n>\n>          2.1) Encode the disallowed character using UTF-8, which will \n> generate a\n>sequence\n>          of two or more octets.\n>\n>         2.2) Convert each octet to %HH ........\n>^^^^^^^^^^^^^^^^\n\nI think we can do this even shorter and more clearly.\n\nI changed the introduction of step 2) to:\n\n >>>>\n    For each character in 'ucschar' or 'iprivate', apply\n    Steps 2.1 through 2.3 below.\n >>>>\n\nI think that addresses your issues 1 and 2.\n\n\n>Take your pick!\n>\n>\n>---------------------------\n>\n>One final general point:  throughout the document I can see both 'ASCII' and\n>'US-ASCII' in use. Should not a single designation be selected, and a \n>normative\n>reference supplied (such as that in RFC 2396 [ASCII] )?\n\nGood catch. I have added the reference, and went through the document\nto change everything to US-ASCII, except for 'non-ASCII' (also used in\nRFC 2396bis) and things like ToASCII,... I also changed a couple\noccurrences of \"US-ASCII range\" to \"US-ASCII repertoire\" to allign\nwith terminology. I also cought one occurrence where US-ASCII is\nalluded to as a script, which I fixed.\n\n\nI hope this addresses your issues. Please confirm.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-2101133"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nAt 10:10 04/05/19 +0100, Graham Klyne wrote:\n\n>Martin,\n>\n>For the process, this looks fine to me.\n\nOkay, thanks. I have closed this issue.\n\nRegards,    Martin.\n\n\n>#g\n>--\n>\n>At 16:52 19/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n\n>>I have decided that it is better to also remove spurious percent-encodings\n>>of non-reserved US-ASCII characters, because probably the main use of\n>>the conversion from URIs to IRIs is for presentation purposes.\n>>\n>>I have changed\n>>\n>>    (except for potential case differences in percent-encoding)\n>>\n>>to\n>>\n>>    (except for potential case differences in percent-encoding\n>>     and for potential percent-encoded unreserved characters)\n>>\n>>I have also changed\n>>\n>>    This procedure will convert as many percent-encoded non-ASCII\n>>    characters as possible to characters in an IRI.\n>>to\n>>    This procedure will convert as many percent-encoded characters\n>>    as possible to characters in an IRI.\n>>\n>>I hope this addresses your concern.\n>>\n>>\n>>Regards,   Martin.\n\n\n\n", "id": "lists-017-2113556"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nAt 09:42 04/05/19 +0100, Graham Klyne wrote:\n\n>At 12:07 19/05/04 +0900, Martin Duerst wrote:\n>>Coming back to your original point, I have reworded\n>>\n>>    For comparison, such conversions MUST only be done on the fly,\n>>    while retaining the original IRI.\n>>\n>>to\n>>\n>>    In order to conserve the original IRIs, such conversions SHOULD\n>>    only be done on the fly, while retaining the IRIs.\n>\n>Martin,\n>\n>I think that's better, but I still think it is making normative statements \n>about implementation technique, which was the point of my original \n>comment.  (And I think the normative point you do want to make really \n>should be a MUST!)\n>\n>For example, I think this this might say what you want without dictating \n>implementation:\n>[[\n>If the IRI is to be passed to another application, or used further in some \n>other way, its original form MUST be preserved;  the conversion described \n>here should be performed only for the purpose of local comparison.\n>]]\n\nOkay, now I understand: You wanted the 'on the fly' removed, because\nthis would have forbidden caching,... I have used your text, and\ntentatively closed this issue.\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-2122596"}, {"subject": "Usage Scenarios draft announcemen", "content": "This is a draft for an announcement of our Usage Scenarios draft.\nThis should probably go to the following lists:\n\n- chairs\n- www-international\n- unicode/unicore\n- SC22/WG20\n\nany others?\n\n\n\nDear ....\n\nThe Web Service Task Force of the W3C Internationalization Working Group\nis glad to announce the publication of a new, thoroughly revised Working\nDraft entitled \"Web Services Internationalization Usage Scenarios\", at\nhttp://www.w3.org/TR/2004/WD-ws-i18n-scenarios-20040512/.\n\nThis Working Draft is close to finalization and publication as a Note,\nand this is therefore the best time to review the document and send us\ncomments and suggestions as quickly as possible.\n\nTogether with \"Requirements for the Internationalization of Web Services\"\n(at http://www.w3.org/TR/ws-i18n-req/), this will serve as input to the\nrechartering of the Internationalization Working Group this summer.\n\n\nWith kind regards,    ....\n\n\n\n", "id": "lists-017-2131583"}, {"subject": "Re: Usage Scenarios draft announcemen", "content": "At 17:00 04/05/20 +0900, Martin Duerst wrote:\n\n>This is a draft for an announcement of our Usage Scenarios draft.\n>This should probably go to the following lists:\n\nSorry, this should have gone to another mailing list!   Martin.\n\n\n\n", "id": "lists-017-2139408"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Martin,\n\nLooks good to me:  I support closure.  Thanks.\n\n#g\n--\n\n\nAt 15:11 20/05/04 +0900, Martin Duerst wrote:\n>Hello Graham,\n>\n>At 09:42 04/05/19 +0100, Graham Klyne wrote:\n>\n>>At 12:07 19/05/04 +0900, Martin Duerst wrote:\n>>>Coming back to your original point, I have reworded\n>>>\n>>>    For comparison, such conversions MUST only be done on the fly,\n>>>    while retaining the original IRI.\n>>>\n>>>to\n>>>\n>>>    In order to conserve the original IRIs, such conversions SHOULD\n>>>    only be done on the fly, while retaining the IRIs.\n>>\n>>Martin,\n>>\n>>I think that's better, but I still think it is making normative \n>>statements about implementation technique, which was the point of my \n>>original comment.  (And I think the normative point you do want to make \n>>really should be a MUST!)\n>>\n>>For example, I think this this might say what you want without dictating \n>>implementation:\n>>[[\n>>If the IRI is to be passed to another application, or used further in \n>>some other way, its original form MUST be preserved;  the conversion \n>>described here should be performed only for the purpose of local comparison.\n>>]]\n>\n>Okay, now I understand: You wanted the 'on the fly' removed, because\n>this would have forbidden caching,... I have used your text, and\n>tentatively closed this issue.\n>\n>\n>Regards,    Martin.\n\n------------\nGraham Klyne\nFor email:\nhttp://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-2146251"}, {"subject": "RE: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "> From: Martin Duerst [mailto:duerst@w3.org] \n>\n> I have listed this as issue ISO-Uni-ref-34.\n>\n> I think this should be 4.0.1, yes?\n\nAbsolutely, my bad.\n\n> Well yes. But for the record, my personal expectation\n> would be that the IRI spec follows updates of these other\n> specs in the future. In most cases, the changes only deal\n> with edge cases anyway. Of course, we have to make sure\n> that we take this decision explicitly in each case, so\n> that we can assess the impact.\n\nWe are in agreement here.\n\n>> The HTML version of the IRI draft should also show\n>> explicitly the link values, which it doesn't as of now.\n>\n> If you know what option to set in xml2rfc, I'll do it.\n> Otherwise, I don't want to spend the time, because the\n> HTML version is just a sideline. What counts for the\n> IETF is the text/plain version.\n>\n>\n>> Unicode 4.01 still use the same repertoire as 10646:2003,\n>> so we are good on that part.\n>\n> I have marked this issue as tentatively closed.\n> Can you please do another cross-check?\n\nThis is fine by me, assuming of course you update the references.\n\nMichel\n\n\n\n", "id": "lists-017-2155638"}, {"subject": "Low Fixed Cost No.1 Search Engine Ranking for &quot;PORN&quot; related keyword", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-017-2165421"}, {"subject": "Low Fixed Cost No. 1 Search Engine Ranking for keywords related to &quot;porn&quot", "content": "This is an HTML message.\n\n\n\n", "id": "lists-017-2171892"}, {"subject": "additional editorial change", "content": "Dear IRI specialists,\n\nAs part of the two-week mailing list last call, I have done one more\nreading through the spec. I'm listing this as the single issue\neditCleanup-35 and tentatively closing it. In my view, all of the\nitems below are editorial. In case you think that any of these items\nneed further discussion, please say so very soon.\n\nAs a result, I have made the following edits, which I think should\nall be uncontroversial:\n\n- Moved the stuff in the Editorial Note just after the Abstract to\n   the end of 1.1 (in part) and to the Acknowledgement section (in part)\n\n- Added some text at the end of 1.1 to provide a somewhat better\n   overview of the document\n\n- Followed I-D/RFC Editor guidelines for abbreviations (expansion\n   first, abbreviation in (), on first occurrence)\n\n- For point a) in applicability, changed:\n     The protocol or format element used should be explicitly designated\n     to carry IRIs. That is, the intent is not to introduce IRIs into\n     contexts that are not defined to accept them. For example, XML schema\n     [XMLSchema] has an explicit type \"anyURI\" that designates the use of IRIs.\n   to:\n     The protocol or format element where IRIs are used should be explicitly\n     designated to be able to carry IRIs. That is, the intent is not to\n     introduce IRIs into contexts that are not defined to accept them.\n     For example, XML schema [XMLSchema] has an explicit type \"anyURI\"\n     that includes IRIs and IRI references. Therefore, IRIs and IRI references\n     can be in attributes and elements of type \"anyURI\".\n     On the other hand, in the HTTP protocol [RFC2616], the Request URI is\n     defined as an URI, which means that direct use of IRIs is not allowed\n     in HTTP requests.\n   I realized that this more explicit wording could have avoided some\n   confusion in the discussion with Chris Haynes, and I hope it will\n   reduce confusion for future readers.\n\n- Created a IANA consideration section saying\n   \"This document has no actions for IANA.\"\n   (as per http://www.ietf.org/ID-Checklist.html)\n\n- Upper-cased one instance of 'internationalized resource identifier'\n   for consistency.\n\n- Changed Step 1) of Section 3.1 from:\n     This step generates a UCS-based character encoding from\n     the original IRI format.\n   to:\n     This step generates a UCS character sequence from\n     the original IRI format.\n   This is to allign with Graham's comment on variant C) of that step\n   at http://www.w3.org/International/iri-edit#3.1BC-norm-29\n\n- In section 3.1, Step 2.2), changed\n     Note: This is identical...\n   to\n     Note that this is identical...\n   to avoid the impression that there might be some formatting problem.\n\n- In \"Infrastructure accepting IRIs MAY convert the ireg-name\n   component of an IRI as follows (before Step 2.2 above) for schemes\n   that are known to use domain names in ireg-name, but where the\n   scheme definition does not allow percent-encoding for ireg-name:\",\n   changed 'Step 2.2' to 'Step 2', because Step 2.2 is about single\n   characters, which obviously is wrong (I think this mistake was\n   introduced when I changed the step labeling to the clearer\n   2.2) from a simple 2).\n\n- Same for \"The uniform treatment of the whole IRI in Step 2.2 above\n   is important to not make processing dependent on URI scheme.\"\n\n- Fixed some (non-)escaping problems with two instances of Viet Nam.\n\n- In section 3.2, changed from\n     c) The conversion may result in a character that is not appropriate in an\n        IRI. See Section 6.1 for further details.\n   to:\n     c) The conversion may result in a character that is not appropriate in an\n        IRI. See Section 2.2, Section 4.1, and Section 6.1 for further details.\n   Rationale: syntax restrictions and bidi restrictions of course apply.\n\n   Also, changed:\n     4) Re-percent-encode all octets produced in Step 3 that in UTF-8\n        represent characters that are not appropriate according to\n        Section 4.1 and Section 6.1.\n   to:\n     4) Re-percent-encode all octets produced in Step 3 that in UTF-8\n        represent characters that are not appropriate according to\n        Section 2.2, Section 4.1, and Section 6.1.\n\n- Removed \"The notation <hh> is used to denote octets outside those\n   that can be represented in this document.\" because this is covered\n   in Section 1.4 (Notation).\n\n- In Section 4.1, changed from \"higher-order protocol\" to \"higher-\n   level protocol\", because that's the term used in the Unicode Bidi\n   algorithm as well as in some other instance in the draft.\n\n- In section 5.2, changed \"making sure that the case of the hexadecimal\n   characters in the percent-encode is always the same\" to\n   \"making sure that the case of the hexadecimal\n   characters in the percent-encodeING is always the same\"\n   [uppercase only here]\n\n- In Section 6.1, changed \"This section discusses limitations on characters\n   and character sequences usable for IRIs.\" to \"This section discusses\n   limitations on characters and character sequences usable for IRIs\n   beyond those given in Section 2.2 and Section 4.1.\"\n   to make sure the reader does not forget the more basic syntax and bidi\n   limitations.\n\n- At the end of the first paragraph of Section 6.4 (Use of UTF-8),\n   added the sentence:\n     For background information on encoding characters into URIs, see\n     also Section 2.5 of [RFCYYYY].\n   This section is a very helpful addition to RFC 2396bis.\n\n- In section 7.2, changed from:\n     For IRI input, the input method editor should be set so that it produces\n     half-width Latin letters, and full-width Katakana.\n   to:\n     For IRI input, the input method editor should be set so that it produces\n     half-width Latin letters AND PUNCTUATION, and full-width Katakana.\n   [uppercase only here]\n   This is rather important because all the reserved characters are\n   punctuation characters.\n\n- In Section 7.8, changed from:\n     Display software should be upgraded only after upgraded entry software\n     has been widely deployed to the population that will see the displayed\n     result.\n   to:\n     Software converting from URIs to IRIs for display should be upgraded\n     only after upgraded entry software has been widely deployed to the\n     population that will see the displayed result.\n   Rationale: The previous wording also applied to display of IRIs as such,\n   where it would in many cases have needed a software downgrade rather\n   than a software upgrade. This wording was put in here quite early\n   on, where the implicit assumption seems to made sense.\n\n- In the security section, simplified the sentence:\n     Protocols and servers that allow the creation of resources with\n     unnormalized names, and resources with names that are not normalized,\n     are particularly vulnerable to such attacks.\n   to:\n     Protocols and servers that allow the creation of resources with\n     names that are not normalized are particularly vulnerable to such\n     attacks.\n   to avoid a duplication.\n\n- Removed the URIs from references to RFCs.\n   [wouldn't it be great if the IETF and the RFC editor would commit\n    to more stable URIs so that we could make use of them, for the\n    benefits of everybody?]\n\n- Changed the Note to RFC Editor for [RFCYYYY] so that it appears\n   in the .txt version.\n\n- Updated several references. By upgrading the reference to XML from\n   the second to the third edition, was able to get rid of the\n   Erratum pointer. Fixed the URI for XML Namespaces.\n\n- Fixed a double mention of the same person in the Acknowledgements\n\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-2178594"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Hello Graham,\n\nAt 10:06 04/05/19 +0100, Graham Klyne wrote:\n\n>Martin,\n>\n>I think our discussion becomes one of specification style.  I appreciate \n>the need to prepare a specification that reflects what applications \n>actually do, but I'd prefer that it not do so by saying that future \n>applications must follow the same procedures as existing applications.\n\nI agree. But the current text doesn't use a MUST, only a SHOULD, and\nclearly gives conditions. If there are scenarios where speed is not\nof importance to the extent that they need to use character-by-character\ncomparison, then the text doesn't apply anymore.\n\n\n>(By \"application\", I mean here any end-user function that employs the \n>technologies.  So for this debate, I'd view 'XML Namespaces' or 'RDF' as \n>part of the infrastructure whose functionality might or might not be part \n>of an application.)\n\nWell, in that case, the applications really must follow the infrastructure\nwhere they use it, otherwise we get chaos. But that's for these\ninfrastructure specs to make sure, not for the IRI spec.\n[and by the way, that part of the spec avoids any use of the word\n'application' :-).]\n\n\n>Unfortunately, I've lost the context of the original comment, so now that \n>it's been aired I'll leave it to your discretion.\n\nOkay, then I declare this issue closed.\n\n[By the way, if it turns out that some of the MUST/SHOULD don't\nmake sense when we try to go to Draft Standard, then we will just\nhave to take them out. That's what I understand the Draft Standard\nstage is there for.]\n\n\n>Regarding your suggested addition:\n>> >>>>\n>>    On the other hand, even if the only forseen use of an IRI is as\n>>    an identifier in scenarios that use character-by-character equivalence,\n>>    creators of IRIs should not create IRIs that only differ by \n>> percent-escaping.\n>>    As an example, using both http://example.org/~user and\n>>    http://example.org/%7Euser to identify XML Namespaces is a bad idea.\n>> >>>>\n>\n>I think this helps, but I'd probably strengthen it a bit, thus:\n>[[\n>    When an IRI is used as an identifier in scenarios that depend\n>    upon character-by-character equivalence, creators of IRIs should\n>    take additional care to avoid IRIs that only differ in their use\n>    of percent-escaping.\n>    As an example, using both http://example.org/~user and\n>    http://example.org/%7Euser to identify XML Namespaces is a bad idea.\n>]]\n>\n>(Changes:  (a) avoid reference to \"foreseen\" use;  (b) try to avoid the \n>implication that it's OK in other scenarios -- I think we'd agree that \n>it's never ideal to coin IRIs that differ only in their use of escaping.)\n\nI have adopted your text, thanks!\n\nRegards,    Martin.\n\n>#g\n>--\n>\n>\n>At 14:18 19/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>At 12:44 04/05/12 +0100, Graham Klyne wrote:\n>>\n>>>At 18:00 12/05/04 +0900, Martin Duerst wrote:\n>>>>Hello Graham,\n>>>>\n>>>>I have made this issue charcompareMUST-31.\n>>>>\n>>>>\n>>>>At 12:02 04/05/10 +0100, Graham Klyne wrote:\n>>>>\n>>>>\n>>>>>Section 5.1:\n>>>>>\n>>>>>[[\n>>>>>5.1  Simple String Comparison\n>>>>>\n>>>>>    In some scenarios a definite answer to the question of IRI\n>>>>>    equivalence is needed that is independent of the scheme used and\n>>>>>    always can be calculated quickly and without accessing a network. An\n>>>>>    example of such a case is XML Namespaces ([XMLNamespace]). In such\n>>>>>    cases, two IRIs SHOULD be defined as equivalent if and only if they\n>>>>>    are character-by-character equivalent. This is the same as being\n>>>>>    byte-by-byte equivalent if the character encoding for both IRIs is\n>>>>>    the same. As an example,\n>>>>>    http://example.org/~user, http://example.org/%7euser, and\n>>>>>    http://example.org/%7Euser are not equivalent under this definition.\n>>>>>    In such a case, the comparison function MUST NOT map IRIs to URIs,\n>>>>>    because such a mapping would create additional spurious equivalences.\n>>>>>]]\n>>>>>\n>>>>>It's not clear to me what the MUST NOT here is saying.  Making \n>>>>>normative statements that are conditional on some postulated \n>>>>>application scenario seems to be a bit confusing to me.\n>>>>\n>>>>If you interpreted the statement as conditional on some application\n>>>>scenario, then it is indeed confusing. It was intended conditional\n>>>>to the comparison function. I.e. if you use character-by-character\n>>>>comparison, you MUST NOT map IRIs to URIs,\n>>>>because such a mapping would create additional spurious equivalences.\n>>>\n>>>I was taking the choice of comparison function to be part of the \n>>>application scenario.\n>>\n>>Well, I think it depends on what you mean by 'application'. If\n>>'XML Namespaces' or 'RDF' are applications, then you are right.\n>>If each XML or RDF parser are applications, then it is wrong.\n>>\n>>\n>>>>I have replaced \"In such a case\" with \"When comparing \n>>>>character-by-character\".\n>>>\n>>>I think that's better, though it doesn't quite capture my original \n>>>comment.  (Consider:  as this is given as a normative statement, how do \n>>>you propose to find interoperable implementations to demonstrate \n>>>conformance when moving to Draft Standard?  I still prefer my suggestion \n>>>(below), but  now I've raised the issue I'm happy for you to decide.\n>>\n>>Well, testing a few XSLT implementations would clearly show that they\n>>treat IRIs as such, and don't convert them to URIs, for namespace URIs.\n>>I have already done such tests quite a while ago.\n>>So I don't think demonstrating conformance would be a big deal for this.\n>>\n>>\n>>>>>I think the final sentence maybe should be:\n>>>>>[[\n>>>>>The IRI to URI mapping function described above [ref] does not \n>>>>>preserve this form of equivalence.\n>>>>>]]\n>>>\n>>>\n>>>>>(Further, the MUST NOT here seems even more perverse in light of the \n>>>>>introductory material in section 3.1)\n>>>>\n>>>>I have checked that material again, and did not find any problems.\n>>>>You may observe that that material is carefully worded in terms of\n>>>>retrieval when it comes to IRI->URI mapping, not in terms of\n>>>>abstract resource identification.\n>>>\n>>>OK, ignore that last comment.  (I wasn't specifically thinking about \n>>>abstract identification.)\n>>>\n>>>But I note that it's not obvious to me that start of section 3.1 is \n>>>subject to the mention of \"resource retrieval\" that appears in section 3[.0].\n>>\n>>This is again taken up and explained in more detail in \"b) \n>>Interpretational:\".\n>>\n>>\n>>>Indeed the fact that the material in 3.1 is also said to apply to \n>>>references and fragment identifiers suggests otherwise.\n>>\n>>You mean the sentence:\n>>\"Everything in this section applies also to IRI references and URI \n>>references,\n>>as well as components thereof (for example fragment identifiers).\"\n>>\n>>I agree that the 'everything' may be a bit general. But what is 'everything'\n>>of 3.1? First, it is the mapping procedure itself. This means that you can\n>>map an IRI reference to an URI reference in the same way you can map an\n>>IRI to an URI. And you can map a fragid in an IRI to a fragid in an URI\n>>in the same way as you map an IRI to an URI.\n>>\n>>Second, it is the context/purpose. Two purposes are given:\n>>- retrieval\n>>- syntax check\n>>With respect to syntax check, the sentence above means that you can\n>>syntax check an IRI reference or a fragid of an IRI by converting to\n>>an URI reference or fragid of an URI. With respect to retrieval,\n>>with an appropriate base, IRI references and URI references can\n>>definitely be retrieved. You are right that retrieval of\n>>fragment identifiers does not make that much sense.\n>>\n>>\n>>>Checking for scheme-specific syntax restrictions does not seem to be \n>>>specifically related to resource retrieval.  (cf. URN syntax checking.)\n>>\n>>Yes, right, I forgot to mention it before.\n>>\n>>\n>>>Looking more closely at point (b) in 3.1, which clearly *is* about \n>>>resource retrieval, I find myself having further qualms:\n>>>[[\n>>>However, when an IRI is used for resource\n>>>retrieval, the resource that the IRI locates is the same as the\n>>>one located by the URI obtained after converting the IRI according\n>>>to the procedure defined here. This means that there is no need to\n>>>define resolution separately on the IRI level.\n>>>]]\n>>>\n>>>This seems to preclude the possibility of defining a resolution protocol \n>>>that uses IRIs natively.\n>>\n>>No. This just precludes the possibility of defining a resolution protocol\n>>that makes a distinction e.g. between '%7e', '%7E', and '~'. Most resolution\n>>protocols are not able to make this distinction, because they do not use\n>>percent-encoding, and therefore the client resolves these differences.\n>>The only protocol I know that doesn't is HTTP, and HTTP also defines\n>>that these are equivalent, and servers implement things that way\n>>(except where the percent-encoding is used to distinguish reserved\n>>characters that the server has to deal with, such as '?').\n>>\n>>\n>>>Effectively, this is an imposition on any future protocol specification \n>>>that can be used to resolve IRIs, which seems like a rather broad \n>>>sweep.  Maybe this is OK, and really is what was intended, but I feel \n>>>compelled to at least mention the point.   If this is what you intend, I \n>>>think the point would usefully be more prominent in the text, and should \n>>>be made a normative assertion;  e.g. a top-level paragraph ala:\n>>>[[\n>>>When an IRI is used for resource retrieval, >>it must be by means of a \n>>>protocol that\n>>>can also be used with URIs, and<<\n>>\n>>This would be a tautology, because all URIs are by definition IRIs.\n>>\n>>\n>>>the resource that the IRI locates MUST be the same as\n>>>the one located by the URI obtained after converting the IRI according \n>>>to the\n>>>procedure defined here.\n>>>]]\n>>\n>>This is given normatively in Section 5.2:\n>>\n>>\"For actual resolution, differences in percent-encoding (except for the\n>>percent-encoding of reserved characters) MUST always result in the same \n>>resource.\"\n>>\n>>Do you want to say that this should be in two places, or that it is\n>>in the wrong place?\n>>\n>>\n>>>It might be argued that the text between >> and << is redundant, to the \n>>>extent that any URI is also a valid IRI.\n>>\n>>Yes indeed, I just did that, sorry.\n>>\n>>\n>>>(But, thinking aloud, ... suppose I wanted to invent a new IRI scheme \n>>>and protocol to serve as a kind of Chinese WordNet, with definitions \n>>>retrievable in much the same way as they are for \n>>>WordNet.  (Notwithstanding that this may not be a good idea for other \n>>>reasons.)  In such a scheme, maybe there is a component which, according \n>>>to the IRI scheme specification, must contain Chinese character \n>>>symbol(s), so there are no URIs that are valid IRIs according to this scheme.\n>>\n>>No, all the URIs that result from percent-encoding the UTF-8-encoded\n>>Chinese characters would be legal. Not necessarily in the protocol\n>>(the protocol may specify that these are just transmitted as raw octets),\n>>but on the URI/IRI level.\n>>\n>>\n>>>I don't know where this leads.  My main point is to try and raise a \n>>>vaguely plausible scenario in which existence of a URI form for resource \n>>>retrieval may be undesirable.)\n>>\n>>Well, of course it would not be very desirable to use the percent-encoded\n>>form of a Chinese WordNet IRI, at least not for Chinese speakers. But\n>>it could be convenient for you, assuming you don't read Chinese.\n>>\n>>\n>>>>>I suspect there should be some discouragement of applications \n>>>>>depending on this level of equivalence, in view of the spurious \n>>>>>distinctions that are lost when IRIs are converted to URIs.   To my \n>>>>>mind the string equivalence of the URI-converted form seems like the \n>>>>>lowest reasonable level of distinction to be encouraged.\n>>>>\n>>>>Well, there are some serious arguments against this:\n>>>>- Some very important applications, in particular XML Namespaces\n>>>>   and RDF, use this equivalence. So recommendation against this\n>>>>   would cause confusion.\n>>>>- Needing to convert to URIs for every comparison is inefficient\n>>>>   (that was the main argument for namespaces)\n>>>>- Needing to convert to URIs may lead to more URIs (rather than IRIs)\n>>>>   floating around, because in some cases, the conversion would\n>>>>   leak.\n>>>>So that's why we should not go there.\n>>>\n>>>But these \"important applications\" are defined in terms of URIs, not IRIs.\n>>\n>>No, not exactly. Namespaces 1.0 is defined in terms of URIs, but if you test\n>>actual implementations (which I have done), it's implemented in terms of \n>>IRIs.\n>>Namespaces 1.1 fixes that gap by using IRIs.\n>>RDF uses something called RDF URI references, which, if you look closely,\n>>are actually IRIs. Please check out\n>>http://www.w3.org/TR/2004/REC-rdf-concepts-20040210/#dfn-URI-reference.\n>>\n>>\n>>>I'm not suggesting that one should be required to convert to URIs for \n>>>every comparison,\n>>\n>>Good.\n>>\n>>\n>>>but that it might be discouraged to rely on differences between IRIs \n>>>that are not present on conversion to URIs.\n>>\n>>Good point. This has been brought up in various discussions e.g. related\n>>to namespaces. In terms of namespaces, it reads: Namespaces compare\n>>character-by-character, so don't chage escaping. But don't try to use\n>>two namespaces that only differ by escaping, because that would just\n>>be stupid and would lead to confusion.\n>>\n>>I added some text at the end of 5.1:\n>>\n>> >>>>\n>>    On the other hand, even if the only forseen use of an IRI is as\n>>    an identifier in scenarios that use character-by-character equivalence,\n>>    creators of IRIs should not create IRIs that only differ by \n>> percent-escaping.\n>>    As an example, using both http://example.org/~user and\n>>    http://example.org/%7Euser to identify XML Namespaces is a bad idea.\n>> >>>>\n>>\n>>I hope this addresses your concern.\n>>\n>>\n>>>I note that your document specifically makes reference to conversion to \n>>>URIs being (notionally) used for a number of purpose, so in this respect \n>>>IRIs are not something whose existence is independent of URIs, and to \n>>>that extent I think to gloss over problems that might arise when \n>>>conversion to URIs is performed may leave room for problems.\n>>>\n>>>Please note that the general thrust of my comments is not to request any \n>>>change to the actual (normative) specification, but to clearly signal in \n>>>some way that problems might occur if these issues are not observed.\n>>>\n>>>>I hope the above addresses your concerns.\n>>>\n>>>I regard this as ultimately your call, and I won't raise any formal \n>>>objection if you don't agree with me, but I may continue to debate the \n>>>matter with you to the extent that it's helpful to you.\n>>\n>>I hope we are getting closer. The more people reading the spec, the\n>>better we can make sure we all know what it is supposed to say.\n>>\n>>\n>>Regards,    Martin.\n>\n>------------\n>Graham Klyne\n>For email:\n>http://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-2193179"}, {"subject": "Re: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "Okay, thanks, closed.      Martin.\n\nAt 10:16 04/05/20 +0100, Graham Klyne wrote:\n\n>Martin,\n>\n>Looks good to me:  I support closure.  Thanks.\n>\n>#g\n>--\n>\n>\n>At 15:11 20/05/04 +0900, Martin Duerst wrote:\n>>Hello Graham,\n>>\n>>At 09:42 04/05/19 +0100, Graham Klyne wrote:\n>>\n>>>At 12:07 19/05/04 +0900, Martin Duerst wrote:\n>>>>Coming back to your original point, I have reworded\n>>>>\n>>>>    For comparison, such conversions MUST only be done on the fly,\n>>>>    while retaining the original IRI.\n>>>>\n>>>>to\n>>>>\n>>>>    In order to conserve the original IRIs, such conversions SHOULD\n>>>>    only be done on the fly, while retaining the IRIs.\n>>>\n>>>Martin,\n>>>\n>>>I think that's better, but I still think it is making normative \n>>>statements about implementation technique, which was the point of my \n>>>original comment.  (And I think the normative point you do want to make \n>>>really should be a MUST!)\n>>>\n>>>For example, I think this this might say what you want without dictating \n>>>implementation:\n>>>[[\n>>>If the IRI is to be passed to another application, or used further in \n>>>some other way, its original form MUST be preserved;  the conversion \n>>>described here should be performed only for the purpose of local comparison.\n>>>]]\n>>\n>>Okay, now I understand: You wanted the 'on the fly' removed, because\n>>this would have forbidden caching,... I have used your text, and\n>>tentatively closed this issue.\n>>\n>>\n>>Regards,    Martin.\n>\n>------------\n>Graham Klyne\n>For email:\n>http://www.ninebynine.org/#Contact\n\n\n\n", "id": "lists-017-2218797"}, {"subject": "RE: draft-duerst-iri07.txt: 2 week mailing list last cal", "content": "At 10:32 04/05/20 -0700, Michel Suignard wrote:\n\n> > From: Martin Duerst [mailto:duerst@w3.org]\n> >\n> > I have listed this as issue ISO-Uni-ref-34.\n\n> >> Unicode 4.01 still use the same repertoire as 10646:2003,\n> >> so we are good on that part.\n> >\n> > I have marked this issue as tentatively closed.\n> > Can you please do another cross-check?\n>\n>This is fine by me, assuming of course you update the references.\n\nOkay, I have closed this issue.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-2228245"}, {"subject": "Re: additional editorial change", "content": "At 18:02 04/05/26 +0900, Martin Duerst wrote:\n\n>Dear IRI specialists,\n>\n>As part of the two-week mailing list last call, I have done one more\n>reading through the spec. I'm listing this as the single issue\n>editCleanup-35 and tentatively closing it. In my view, all of the\n>items below are editorial. In case you think that any of these items\n>need further discussion, please say so very soon.\n\nI haven't heard from anybody, so I'm closing this issue.\n\nRegards,    Martin.\n\n\n\n", "id": "lists-017-2236336"}, {"subject": "Fwd: Re: Issues: Section 3.1 references to nonASCII character", "content": "[forwarded to the list, for documentation purposes]\n\n>Date: Fri, 28 May 2004 15:02:52 +0900\n>To: \"Chris Haynes\" <chris@harvington.org.uk>\n>From: Martin Duerst <duerst@w3.org>\n>Subject: Re: Issues: Section 3.1 references to non-ASCII characters\n>\n>At 08:07 04/05/20 +0100, Chris Haynes wrote:\n>>Thanks Martin.\n>>\n>>Your amendments satisfy all my concerns.\n>\n>Okay, thanks, I have closed this issue.\n>\n>Regards,    Martin.\n>\n>\n>>Chris Haynes\n>>\n>>\n>>\n>>  \"Martin Duerst\" responded:\n>>\n>> >\n>> > Hello Chris,\n>> >\n>> > I have noted this as issue non-ASCII-3.1-33.\n>> >\n>> > At 10:37 04/05/11 +0100, Chris Haynes wrote:\n>> >\n>> > >Here are three related issues re. draft 7, Sect 3.1, Step 2.\n>> > >\n>> > >\n>> > >\n>> > >I have a concern with the sentence \"The disallowed characters consist \n>> of all\n>> > >non-ASCII characters allowed in IRIs.\"\n>> > >\n>> > >(Issue 1) Since this step is referring to (presumably legal) IRIs, \n>> then the\n>> > >phrase \"allowed in IRIs\" is superfluous - there could be no others.\n>> >\n>> > see below.\n>> >\n>> >\n>> > >--------------\n>> > >\n>> > >(Issue 2) Is the phrase \"non-ASCII characters\" sufficiently precice /\n>> > >normative?\n>> > >\n>> > >I think here is a much cleaner definition available, providing you \n>> don't mind\n>> > >dropping the allusion to the reasoning:\n>> > >\n>> > >\"The disallowed characters consist of all those matching 'ucschar' or\n>> > >'iprivate'\n>> > >of Section 2.2\"\n>> > >\n>> > >Altenatively, you could say something like \"The disallowed characters\n>> > >consist of\n>> > >all those whose UTF-8 encodings employ two or more octets\" (which is more\n>> > >to the\n>> > >point and all-embracing).\n>> >\n>> > see below.\n>> >\n>> > >--------------\n>> > >\n>> > >\n>> > >The definition of disallowed characters  now leads us to an apparent \n>> conflict\n>> > >with step 2.1, which currently says to \"convert the character to one \n>> or more\n>> > >octets using UTF-8\".\n>> > >\n>> > >Unless I've misunderstood some subtlety in the definition of 'disallowed\n>> > >characters', all such characters will require at least two octets for \n>> their\n>> > >encoding so we reach issue 3:\n>> > >\n>> > >\n>> > >(Issue 3)  In Step 2.1 none of the characters to be so processed can have\n>>just\n>> > >one octet in their UCS-8 encoding, so the instruction, strictly-speaking,\n>> > >cannot\n>> > >be obeyed.\n>> >\n>> > Well, you are right, except that strictly speaking, there is also\n>> > the following possibility, mentioned later in the spec:\n>> >\n>> >  >>>>\n>> > Infrastructure accepting IRIs MAY also deal with the printable characters\n>> > in US-ASCII that are not allowed in URIs, namely \"&lt;\", \"&gt;\", '\"',\n>> > Space, \"{\", \"}\", \"|\", \"\\\", \"^\", and \"`\", in Step 2.2 above.\n>> >  >>>>\n>> >\n>> > Except that it should say \"Step 2\", which I have fixed.\n>> >\n>> >\n>> >\n>> > >--------------\n>> > >\n>> > >\n>> > >I also find the mixture of negatives and plurals in the introduction \n>> to step\n>>2\n>> > >somewhat confusing, so I've taken the liberty of suggesting some \n>> re-drafts\n>> > >which\n>> > >addresses all three issues.\n>> > >\n>> > >\n>> > >One possible re-draft of the start of Step 2, which consolidates all the\n>>above\n>> > >points, is:\n>> > >\n>> > >Version 1:\n>> > >  vvvvvvvvvvvvvvvv\n>> > >    Step 2)\n>> > >       IRI characters matching 'ucschar' or 'iprivate' (section 2.2) are\n>> > >disallowed in URI\n>> > >       references. For each such character apply steps 2.1 through 2.3\n>>below..\n>> > >\n>> > >          2.1) Encode the disallowed character using UTF-8, which will\n>> > > generate a\n>> > >sequence\n>> > >          of two or more octets.\n>> > >\n>> > >          2.2) Convert each octet to %HH ........\n>> > >^^^^^^^^^^^^^^^^\n>> > >\n>> > >An alternative re-draft is:\n>> > >\n>> > >Version 2:\n>> > >vvvvvvvvvvvvvvvv\n>> > >    Step 2)\n>> > >       IRI characters whose UCS-8 encodings emply two or more octets are\n>> > >disallowed in\n>> > >       URI references. For each such character apply steps 2.1 \n>> through 2.3\n>> > >below..\n>> > >\n>> > >          2.1) Encode the disallowed character using UTF-8, which will\n>> > > generate a\n>> > >sequence\n>> > >           of two or more octets.\n>> > >\n>> > >          2.2) Convert each octet to %HH ........\n>> > >^^^^^^^^^^^^^^^^\n>> > >\n>> > >\n>> > >yet a third, which restores the reasoning, is:\n>> > >\n>> > >Version 3:\n>> > >vvvvvvvvvvvvvvvv\n>> > >    Step 2)\n>> > >       IRI characters whose UCS-8 encodings emply two or more octets are\n>> > >disallowed in\n>> > >       URI references because they are not US-ASCII characters. For \n>> each such\n>> > >character\n>> > >       apply steps 2.1 through 2.3 below..\n>> > >\n>> > >          2.1) Encode the disallowed character using UTF-8, which will\n>> > > generate a\n>> > >sequence\n>> > >          of two or more octets.\n>> > >\n>> > >         2.2) Convert each octet to %HH ........\n>> > >^^^^^^^^^^^^^^^^\n>> >\n>> > I think we can do this even shorter and more clearly.\n>> >\n>> > I changed the introduction of step 2) to:\n>> >\n>> >  >>>>\n>> >     For each character in 'ucschar' or 'iprivate', apply\n>> >     Steps 2.1 through 2.3 below.\n>> >  >>>>\n>> >\n>> > I think that addresses your issues 1 and 2.\n>> >\n>> >\n>> > >Take your pick!\n>> > >\n>> > >\n>> > >---------------------------\n>> > >\n>> > >One final general point:  throughout the document I can see both \n>> 'ASCII' and\n>> > >'US-ASCII' in use. Should not a single designation be selected, and a\n>> > >normative\n>> > >reference supplied (such as that in RFC 2396 [ASCII] )?\n>> >\n>> > Good catch. I have added the reference, and went through the document\n>> > to change everything to US-ASCII, except for 'non-ASCII' (also used in\n>> > RFC 2396bis) and things like ToASCII,... I also changed a couple\n>> > occurrences of \"US-ASCII range\" to \"US-ASCII repertoire\" to allign\n>> > with terminology. I also cought one occurrence where US-ASCII is\n>> > alluded to as a script, which I fixed.\n>> >\n>> >\n>> > I hope this addresses your issues. Please confirm.\n>> >\n>> > Regards,    Martin.\n>> >\n>> >\n>> >\n>> >\n>> >\n\n\n\n", "id": "lists-017-2243427"}, {"subject": "Issue number cleanu", "content": "I have discovered that some issue numbers have been handed out twice.\nSo I have changed\nnon-ASCII-3.1-33   to    non-ASCII-3.1-36, and\nISO-Uni-ref-34     to    ISO-Uni-ref-37\n\nSorry for the confusion.     Martin.\n\n\n\n", "id": "lists-017-2258785"}, {"subject": "draft-duerst-iri08.txt submitte", "content": "I have just submitted draft-duerst-iri-08.txt to the Internet-Drafts\nEditor for publication. It should appear in the usual places in a few\ndays. You can find a copy at\nhttp://www.w3.org/International/iri-edit/draft-duerst-iri-08.txt.\n\nThe two-week mailing list last call has helped to fix a lot of details,\nbut hasn't brought up any controversial issues. I therefore intend to\nsubmit the above draft to the IESG when it's published. Anybody having\nany objections should say so here quickly and clearly.\n\nRegards,     Martin.\n\n\n\n", "id": "lists-017-2265142"}, {"subject": "Fwd: I-D ACTION:draft-duerst-iri08.tx", "content": "FYI.\n\n>To: i-d-announce@ietf.org\n>From: Internet-Drafts@ietf.org\n>Date: Fri, 28 May 2004 15:42:19 -0400\n>Subject: I-D ACTION:draft-duerst-iri-08.txt\n\n>A New Internet-Draft is available from the on-line Internet-Drafts \n>directories.\n>\n>\n>         Title           : Internationalized Resource Identifiers (IRIs)\n>         Author(s)       : M. Duerst, M. Suignard\n>         Filename        : draft-duerst-iri-08.txt\n>         Pages           : 40\n>         Date            : 2004-5-28\n>\n>This document defines a new protocol element, the Internationalized\n>    Resource Identifier (IRI), as a complement to the Uniform Resource\n>    Identifier (URI). An IRI is a sequence of characters from the\n>    Universal Character Set (Unicode/ISO 10646). A mapping from IRIs to\n>    URIs is defined, which means that IRIs can be used instead of URIs\n>    where appropriate to identify resources.\n>    The approach of defining a new protocol element was chosen, instead\n>    of extending or changing the definition of URIs, to allow a clear\n>    distinction and to avoid incompatibilities with existing software.\n>    Guidelines for the use and deployment of IRIs in various protocols,\n>    formats, and software components that now deal with URIs are\n>    provided.\n>\n>A URL for this Internet-Draft is:\n>http://www.ietf.org/internet-drafts/draft-duerst-iri-08.txt\n>\n>To remove yourself from the I-D Announcement list, send a message to\n>i-d-announce-request@ietf.org with the word unsubscribe in the body of the \n>message.\n>You can also visit https://www1.ietf.org/mailman/listinfo/I-D-announce\n>to change your subscription settings.\n>\n>\n>Internet-Drafts are also available by anonymous FTP. Login with the username\n>\"anonymous\" and a password of your e-mail address. After logging in,\n>type \"cd internet-drafts\" and then\n>         \"get draft-duerst-iri-08.txt\".\n>\n>A list of Internet-Drafts directories can be found in\n>http://www.ietf.org/shadow.html\n>or ftp://ftp.ietf.org/ietf/1shadow-sites.txt\n>\n>\n>Internet-Drafts can also be obtained by e-mail.\n>\n>Send a message to:\n>         mailserv@ietf.org.\n>In the body type:\n>         \"FILE /internet-drafts/draft-duerst-iri-08.txt\".\n>\n>NOTE:   The mail server at ietf.org can return the document in\n>         MIME-encoded form by using the \"mpack\" utility.  To use this\n>         feature, insert the command \"ENCODING mime\" before the \"FILE\"\n>         command.  To decode the response(s), you will need \"munpack\" or\n>         a MIME-compliant mail reader.  Different MIME-compliant mail readers\n>         exhibit different behavior, especially when dealing with\n>         \"multipart\" MIME messages (i.e. documents which have been split\n>         up into multiple messages), so check your local documentation on\n>         how to manipulate these messages.\n>\n>\n>Below is the data which will enable a MIME compliant mail reader\n>implementation to automatically retrieve the ASCII version of the\n>Internet-Draft.\n>Content-Type: text/plain\n>Content-ID: <2004-5-28160739.I-D@ietf.org>\n>\n>ENCODING mime\n>FILE /internet-drafts/draft-duerst-iri-08.txt\n>\n><ftp://ftp.ietf.org/internet-drafts/draft-duerst-iri-08.txt>\n>_______________________________________________\n>I-D-Announce mailing list\n>I-D-Announce@ietf.org\n>https://www.ietf.org/mailman/listinfo/i-d-announce\n\n\n\n", "id": "lists-017-2271911"}, {"subject": "[BH] P3P and Extensible Provisioning Protoco", "content": "Scott (and the PRP WG), \n\nI'm chairing a \"Beyond HTTP\" taskforce of the W3C P3P Activity looking to \nother applications and protocols for an understanding of their requirements \nfor *reusing* P3P. We've noted [2] your use of P3P and I hope you wouldn't \nmind giving us some feedback so we can help others in your context re-use \nas much as possible of P3P -- mitigating and confusing divergences.\n\n1. Did you find anything particularly troublesome with adapting P3P to your \ncontext from a protocol/binding position? (I assume not, you just include \nP3P in your XML.) Do you have any scenarios where your XML application \nwould also be transported over HTTP, which itself could conceivable have a \nP3P policy? (Or is this an unlikely scenario?)\n2. What led you to make the changes to the vocabulary that you did? (Some \nterms are removed, some are altered -- we're these casual changes or did \nyou have significant market/policy tensions in your app context?) \n3. Your XML app does use schema, did you give any thought to actually using \nelements from the P3P namespace and if so, what discouraged that?\n4. Do you have any other feedback that I've missed? <smile/>\n\n[1] http://www.w3.org/P3P/2003/04-beyond-http.html\n[2] http://lists.w3.org/Archives/Public/public-p3p-spec/2003Mar/0008.html\n\n-- \nJoseph Reagle Jr.                 http://www.w3.org/People/Reagle/\nW3C Policy Analyst                mailto:reagle@w3.org\nIETF/W3C XML-Signature Co-Chair   http://www.w3.org/Signature/\nW3C XML Encryption Chair          http://www.w3.org/Encryption/2001/\n\n\n\n", "id": "lists-017-2355287"}, {"subject": "[BH] P3P and Extensible Provisioning Protoco", "content": "Scott (and the PRP WG), \n\nI'm chairing a \"Beyond HTTP\" taskforce of the W3C P3P Activity looking to \nother applications and protocols for an understanding of their requirements \nfor *reusing* P3P. We've noted [2] your use of P3P and I hope you wouldn't \nmind giving us some feedback so we can help others in your context re-use \nas much as possible of P3P -- mitigating and confusing divergences.\n\n1. Did you find anything particularly troublesome with adapting P3P to your \ncontext from a protocol/binding position? (I assume not, you just include \nP3P in your XML.) Do you have any scenarios where your XML application \nwould also be transported over HTTP, which itself could conceivable have a \nP3P policy? (Or is this an unlikely scenario?)\n2. What led you to make the changes to the vocabulary that you did? (Some \nterms are removed, some are altered -- we're these casual changes or did \nyou have significant market/policy tensions in your app context?) \n3. Your XML app does use schema, did you give any thought to actually using \nelements from the P3P namespace and if so, what discouraged that?\n4. Do you have any other feedback that I've missed? <smile/>\n\n[1] http://www.w3.org/P3P/2003/04-beyond-http.html\n[2] http://lists.w3.org/Archives/Public/public-p3p-spec/2003Mar/0008.html\n\n-- \nJoseph Reagle Jr.                 http://www.w3.org/People/Reagle/\nW3C Policy Analyst                mailto:reagle@w3.org\nIETF/W3C XML-Signature Co-Chair   http://www.w3.org/Signature/\nW3C XML Encryption Chair          http://www.w3.org/Encryption/2001/\n\n\n\n", "id": "lists-017-2363982"}, {"subject": "UA: demographic translation", "content": "I just noticed that IE translates the <demographic> element as:\nDemographic and socioeconomic data, such as gender, age, and income, not\ntied to an identifiable person.\n\nThat last part (\"not tied to an identifiable person\") troubles me. Nothing\nin P3P 1.0 indicates that is the meaning of the demographic element, unless\nI'm missing something.\n\nI notice that the Privacy Bird and Netscape translations don't include any\nphrasing like this, too.\n\nAlso, while I'm on the topic, data like State and Zip Code also fall in the\ndemographic category, but none of the translations mention them. I would\nguess that collecting region information is more often as or more common\nthan collection gender, age, and income, so I would suggest that the\ntranslations include that in their translations, e.g. \"such as geographic\nregion, gender, age, or income\".\n\n++Jack++\n\n\n\n", "id": "lists-017-2372901"}, {"subject": "Re: UA: demographic translation", "content": "On Wednesday, April 2, 2003, at 06:49  PM, Humphrey, Jack wrote:\n\n>\n> I just noticed that IE translates the <demographic> element as:\n> Demographic and socioeconomic data, such as gender, age, and income, \n> not\n> tied to an identifiable person.\n>\n> That last part (\"not tied to an identifiable person\") troubles me. \n> Nothing\n> in P3P 1.0 indicates that is the meaning of the demographic element, \n> unless\n> I'm missing something.\n>\n> I notice that the Privacy Bird and Netscape translations don't include \n> any\n> phrasing like this, too.\n\nI find that curious as well.\n\n> Also, while I'm on the topic, data like State and Zip Code also fall \n> in the\n> demographic category, but none of the translations mention them. I \n> would\n> guess that collecting region information is more often as or more \n> common\n> than collection gender, age, and income, so I would suggest that the\n> translations include that in their translations, e.g. \"such as \n> geographic\n> region, gender, age, or income\".\n\nAs I recall, it was a rather late decision we made to change the \nclassification of state, postalcode, etc. to demographic (rather than \nphysical contact). That is indicated in section 5.5.6.1 but never \nupdated in the category definitions. Besides taking that into \nconsideration in our UA guidelines, perhaps we should mention that in \nthe definition of the demographic category in section 3.4? I'll add \nthat to bugzilla.\n\nLorrie\n\n\n\n", "id": "lists-017-2380808"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "In a nutshell...\n\n(I'm one of the co-chairs of the WG, Jaap Akkerhuis is the other, but\nI am not an implementor of the protocol.)\n\nPlease note that I took \"public-p3p-spec@w3.org\" off the cc list - to\navoid cross-posting and I'm not on that list.  If anyone wants to\nforward this message to that list, you have my permission.\n\nAt 18:20 -0500 4/2/03, Joseph Reagle wrote:\n>1. Did you find anything particularly troublesome with adapting P3P to\n> your context from a protocol/binding position? (I assume not, you just\n> include P3P in your XML.) Do you have any scenarios where your XML\n> application would also be transported over HTTP, which itself could\n> conceivable have a P3P policy? (Or is this an unlikely scenario?)\n\nNot that I am aware of - trouble with adapting P3P, that is.\n\nOn HTTP - one of the items in our charter has been to investigate\n\"other transports\" with \"other\" meaning \"not TCP\" in the context.\nBut to date, there's been no sustained interest in pursuing any\ntransport other than TCP (with TLS) but multiple members of the WG.\nIt's not so much that HTTP was rejected, no one suggested doing it.\n\n>2. What led you to make the changes to the vocabulary that you did? (Some\n>terms are removed, some are altered -- we're these casual changes or did\n>you have significant market/policy tensions in your app context?)\n\nTo some extent because our protocol is \"business to business\" and\nconstrained in it's reach, as opposed to being \"person to business\"\nand in general use.\n\n>3. Your XML app does use schema, did you give any thought to actually\n> using elements from the P3P namespace and if so, what discouraged that?\n\nI'd have to research that.\n\n>4. Do you have any other feedback that I've missed? <smile/>\n\nNone, other than to say that I thought the P3P specification is well\nwritten and organized, especially from the perspective of someone who\nhas written specifications in the past.  I like having the\nrequirement clearly stated and then use prose to convey the spirit.\n--\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nEdward Lewis                                            +1-703-227-9854\nARIN Research Engineer\n\nI've had it with world domination.  The maintenance fees are too high.\n\n\n\n", "id": "lists-017-2389483"}, {"subject": "RE: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "I'll add my two cents below to what Ed has already provided.\n\n-Scott-\n\n> -----Original Message-----\n> From: Joseph Reagle [mailto:reagle@w3.org]\n> Sent: Wednesday, April 02, 2003 6:20 PM\n> To: shollenbeck@verisign.com\n> Cc: ietf-provreg@cafax.se\n> Subject: [ietf-provreg] [BH] P3P and Extensible Provisioning Protocol\n>\n>\n> Scott (and the PRP WG),\n>\n> I'm chairing a \"Beyond HTTP\" taskforce of the W3C P3P\n> Activity looking to\n> other applications and protocols for an understanding of\n> their requirements\n> for *reusing* P3P. We've noted [2] your use of P3P and I hope\n> you wouldn't\n> mind giving us some feedback so we can help others in your\n> context re-use\n> as much as possible of P3P -- mitigating and confusing divergences.\n>\n> 1. Did you find anything particularly troublesome with\n> adapting P3P to your\n> context from a protocol/binding position? (I assume not, you\n> just include\n> P3P in your XML.) Do you have any scenarios where your XML\n> application\n> would also be transported over HTTP, which itself could\n> conceivable have a\n> P3P policy? (Or is this an unlikely scenario?)\n\nThe most significant issue that we had to deal with involved an analysis of\nthe elements from the perspextive of our operational model.  We're not\ndealing with web browser users and web servers, so many of the web-specific\nfeatures of P3P weren't of interest to us.\n\nOur XML protocol *could* be transported over HTTP, but that's not something\nwe're currently doing in the provreg WG.  The IETF has had a bit of\nheartburn lately about layering protocols on top of HTTP.\n\n> 2. What led you to make the changes to the vocabulary that\n> you did? (Some\n> terms are removed, some are altered -- we're these casual\n> changes or did\n> you have significant market/policy tensions in your app context?)\n\nIt was all an attempt to tailor the P3P elements to the EPP operating\nenvironment.  We wanted to eliminate elements that weren't needed and\n ensure that those that remained made sense in our operational context.\n\n> 3. Your XML app does use schema, did you give any thought to\n> actually using\n> elements from the P3P namespace and if so, what discouraged that?\n\nYes, we did.  See my responses to 1. and 2. above for the rationale.\n\n> 4. Do you have any other feedback that I've missed? <smile/>\n\nNot really.  I found P3P to be a very complete work, it was just contained\nmore than what we needed.\n\n-Scott-\n\n\n\n", "id": "lists-017-2399503"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "Scott and Edward, thanks for your response!\n\nOn Thursday 03 April 2003 18:06, Edward Lewis wrote:\n> Please note that I took \"public-p3p-spec@w3.org\" off the cc list - to\n> avoid cross-posting and I'm not on that list.  If anyone wants to\n> forward this message to that list, you have my permission.\n\nWhile cross-listing is generally bad, I'm including w3c list in the cc \nbecause this is definitely a substantive in-scope issue for us, and since \nyou guys didn't remove provreg I assume you thought it relevant there too \n<smile/.>\n\n\n> At 18:20 -0500 4/2/03, Joseph Reagle wrote:\n> On HTTP - one of the items in our charter has been to investigate\n> \"other transports\" with \"other\" meaning \"not TCP\" in the context.\n> But to date, there's been no sustained interest in pursuing any\n> transport other than TCP (with TLS) but multiple members of the WG.\n> It's not so much that HTTP was rejected, no one suggested doing it.\n\nUnderstood.\n\n> >2. What led you to make the changes to the vocabulary that you did?\n> > (Some terms are removed, some are altered -- we're these casual changes\n> > or did you have significant market/policy tensions in your app\n> > context?)\n>\n> To some extent because our protocol is \"business to business\" and\n> constrained in it's reach, as opposed to being \"person to business\"\n> and in general use.\n\nAnd as Scott said, it was a question of operational experience. However, \nsince we, in the P3P context, are trying to figure out how to promote \nreuse, mind if I follow up on that? For instance, if we come to \nunderstanding of which parts folks keep, and which parts get dropped or \nmodified depending on the context, perhaps we can provide guidance and \nbetter structures. I've included a table comparing P3P XML, Compact, and \nEPP with the following characterization of changes:\n\nACCESS\nEPP uses a epp:null whereas p3p has a related p3p:nonident. epp:null means \nthat only transient data was collected, but p3p:nonident is still a valid \ndescription of that, particular when used with p3p:no-retention is used. In \nthis case, I'd recommend EPP converge with p3p:noident and support \np3p:no-retention since the separation of those two axes is cleaner.\n\nDISPUTES\nEPP doesn't support how a dispute can be addressed. Is this because in P3P \nthis is a representation to the consumer, and EPP isn't B2C? Is the \nregulatoriness <smile/> of it too scary? I'll also note the P3P Compact \nSyntax collapses this all into a DSP token with no p3p:{service, \nindependent, court, law}.\n\nREMEDIES\nEPP doesn't support this, see question in DISPUTES.\n\nNON-IDENTIFIABLE\nEPP doesn't support this, not sure why.\n\nPURPOSE\nEPP supports p3p:{admin, contact, other} and epp:prov. I can see the PURPOSE \nvarying widely across application contexts and I think it makes sense to \ndrop and extend from this axes as appropriate.\n\nREQUIRED\nNo ability designate whether data is required, opt-in, and opt-out. Again, \nprobably because EPP is not B2C?\n\nRETENTION\nSee ACCESS. I recommend you support \"no-retention\" and then both P3P and EPP \nwill still sync up on these two axes.\n\n\n\ntext/html attachment: p3p.html\n\n\n\n\n", "id": "lists-017-2409649"}, {"subject": "[Agent/Domain] brainstormin", "content": "There haven't been any responses to my previous attempt to get this\ndiscussion going, so I'm going to attempt to summarize my view of the\nproblem and the ideas I've had so far. I look forward to some discussion.\n\nI'd like to schedule a conference call of the task force for this week, so\nif you think you'd like to be involved, please email me directly.\n\nTerminology:\n- Business agent: an entity that acts on behalf of another entity\n- Business domains: list of DNS domains or hosts that are owned (directly or\nindirectly) by a single entity\n- First-party business: entity providing the primary site or service with\nwhich user is interacting\n- Third-party business: separately-owned entity that may have access to data\ncollected during user's interaction with first-party business\n- Third-party context: non-primary domains that are owned by either: the\nfirst-party business (other business domains), business agents for the\nfirst-party business, or third-party businesses\n\nThe basic premise I'm working under is that user agents should only restrict\ntrue third-party businesses, not sites/services provided by the first-party\nbusiness or its agents. We should consider changes to the specification for\nrequired/recommended user agent behavior as well as the more fundamental\nchanges (discussed below) to make it possible to describe these\nrelationships.\n\nQuestions/Problems:\n- Agent: how to denote that it is an agent of the first-party business\n- Agent: how to denote which data is collected on behalf of the first party\n- Agent: how to denote that purposes are stated in the first party policy\n- Agent: how to denote that a domain belongs to an agent acting on behalf of\nthe business and should not be treated as a third-party domain\n- Domain: how to denote that other domains are part of the same business and\nshould not be treated as third-party domains\n- How to map these changes to compact policies\n- How does policy reference file need to change\n\nIdeas:\n- Ability to denote agent status (in ENTITY element as addition to business\ndataset?)\n- Ability to list business domains (in ENTITY element?)\n- If not otherwise specified, a domain in the third-party context should be\nconsidered a third-party business and restricted as such.\n- New recipient element (e.g. \"<FIRST-PARTY>\") for an agent's policy, to\ndenote that data is being collected on behalf of the first-party business\nentity\n- Ability for policy to reference the first-party policy that should apply\n(e.g. URI attribute on new recipient element)\n- New purpose element (e.g. \"<FIRST-PARTY-USES>\") for an agent's policy, to\ndenote that data will be used for purposes declared in referenced policy\n- New P3P HTTP header to reference first-party domain or business domains\nlist, or compact policy token(s) to force use of full policy\n\nJack Humphrey\nCoremetrics\n\n\n\n", "id": "lists-017-2421706"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "Joseph,\n\n> > It's not so much that HTTP was rejected, no one suggested doing it.\n> \n> Understood.\n\nThere is an implementation.\n\n> ACCESS\n\nThe vocabulary element(s) in the EPP schema which correspond to the ACCESS\nelement are not identical to those in the P3P schema.\n\np3p:nonident - does not collect identified data\nepp:null - data is not persistent\n\nThe problem-domains are not identical. P3P is concerned with \"initial data\ncollection\", EPP is concerned with \"onward transport\" of data previously \ncollected.\n\nComment: Data that moves from one onward-transport node to another may not\nbe persistent on any particular node. In particular, a registry could sink\npart of a data flow (technical data) and discard part of a data flow (social\ndata).\n\n> DISPUTES\n> EPP doesn't support how a dispute can be addressed.\n\nThere is no vocabulary element(s) in the EPP schema which correspond to\nthe DISPUTES-GROUP element, and its child DISPUTES elements.\n\nNo requirement in the problem-domain exists.\n\nComment: There is a regulatory regime that is controlling for a class of\noperators, hence of implementors. There is the complement to that class,\nwhich lacks an equivalent single regulatory regime, and may be particular\nto each element in that class (ccTLD operators). There is yet another class\nfor which little activity is present (non-tld operators, non-dns operators,\nand non-IANA root dns operatos, if any).\n\n> REMEDIES\n> EPP doesn't support this, see question in DISPUTES.\n\nSee above.\n\n> NON-IDENTIFIABLE\n> EPP doesn't support this, not sure why.\n\nThe problem-domains are not identical.\n\n> PURPOSE\n> EPP supports p3p:{admin, contact, other} and epp:prov. I can see the PURPOSE \n> varying widely across application contexts and I think it makes sense to \n> drop and extend from this axes as appropriate.\n\nThe comment is not clear.\n\n> REQUIRED\n\n(N.B. An optional child element of PURPOSE. EBW)\n\n1. No requirement in the problem-domain exists for users.\n2. No requirement statement for data in the problem-domain is optional.\n\n> RETENTION\n> See ACCESS.\n\nSee above.\n\nI hope this has helped.\n\nNow for something ... individual.\n\nI advocated the <dcp> construct for this problem domain, because I thought\nit the best mechanism to policy the data, and to allow scoped policies.\nI've tried to kill whois:43 by several means, stealth, poision, very blunt\ninstruments (my wit), etc.\n\nOthers reject the notion that a protocol with a fixed grammer targeting a\nparticular application domain, in particular data collection, is of the\nslightest use in this problem domain, and insist upon mechanism(s) that\nsupport registrant (\"user\" in p3p usage) defined access et al models.\n\nAs \"others\" are the IESG, looking at what bits of a data collection vocab\nare substantially similar, or dissimilar, across problem domains, may not\nbe the best use of anyone's time.\n\nI hope this has helped too.\n\nEric\n\nP.S. It might help to keep things in focus to recall every now and again\njust how much, or little, anyone actually pays for \"privacy\". Indirect\ncost recovery models for the internet may be ... historic.\n\n\n\n", "id": "lists-017-2431891"}, {"subject": "P3P spec wg call April 1", "content": "P3P 1.1 Specification working group members,\n\nPlease plan to participate in our first conference call on April 16 at \n11 am Eastern. Dial-in information is available from \nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html (you may \nneed a password to access... please try this URL and request a password \nnow if you need one rather than waiting for the day of the call when \nyou don't have the number!)\n\nTask force chairs: I will ask each of you to give an update on the \nprogress of your TF on this call. Please be ready to tell us how you \nplan to proceed and commit to some milestones for your deliverables.\n\nEveryone should also sign up for a W3C buzilla account if you have not \nalready done so http://www.w3.org/Bugs/Public/\n\n\n\n", "id": "lists-017-2444075"}, {"subject": "RE: [Agent/Domain] brainstormin", "content": "Jack,\nI guess I am still confused what problem we are attempting to address.  My\nconcern is that there should not be a method of obfuscating the traditional\ndeclaratations via the use of some type of an AGENT token.  If data is being\n\"used\" in given ways the fact that it was collected by an agent is really\nimmaterial in that it is still expressible under given syntax.\n\nSo I have always taken it that if I, e.g. BrooksCo was acting as an agent in\nsay a Site Analytics or Ad Serving capacity for GatesCo and providing a\npairing of unique identifiers back to GatesCo (say  a cookie id and an\nidentifier meaningless to me but identifiable to Gatesco) that the correct\ndeclarations would be perfectly expressible under current syntax:\nENTITY: has to be Dobbsco the agent unless acting in a 1:1 capacity soley\nfor Gatesco in other words the cookie is not a shared resource across\nmultiple other entities for whom Dobbsco is acting as an agent.  If a 1:1\nexists then simply have the entity described as Gatesco.\nRECIPIENT: OURS (unless Gatesco provides the data externally and then modify\nfrom their perspective)\nALL the rest in accordance to how GATESCO is using the data...  if dobbsco\nhas no rights to the data and is only acting as a processor the only duty I\nsee for him is to get from Gatesco what the correct statements would be.\n\nNot sure but are we attempting to come up with a token that in effect says -\n\"I am not sure what Gatesco is doing with data, I am just the collector and\nnot using it myself?\"\n\n-Brooks\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Monday, April 07, 2003 4:28 PM\nTo: public-p3p-spec@w3.org\nSubject: [Agent/Domain] brainstorming\n\n\n\nThere haven't been any responses to my previous attempt to get this\ndiscussion going, so I'm going to attempt to summarize my view of the\nproblem and the ideas I've had so far. I look forward to some discussion.\n\nI'd like to schedule a conference call of the task force for this week, so\nif you think you'd like to be involved, please email me directly.\n\nTerminology:\n- Business agent: an entity that acts on behalf of another entity\n- Business domains: list of DNS domains or hosts that are owned (directly or\nindirectly) by a single entity\n- First-party business: entity providing the primary site or service with\nwhich user is interacting\n- Third-party business: separately-owned entity that may have access to data\ncollected during user's interaction with first-party business\n- Third-party context: non-primary domains that are owned by either: the\nfirst-party business (other business domains), business agents for the\nfirst-party business, or third-party businesses\n\nThe basic premise I'm working under is that user agents should only restrict\ntrue third-party businesses, not sites/services provided by the first-party\nbusiness or its agents. We should consider changes to the specification for\nrequired/recommended user agent behavior as well as the more fundamental\nchanges (discussed below) to make it possible to describe these\nrelationships.\n\nQuestions/Problems:\n- Agent: how to denote that it is an agent of the first-party business\n- Agent: how to denote which data is collected on behalf of the first party\n- Agent: how to denote that purposes are stated in the first party policy\n- Agent: how to denote that a domain belongs to an agent acting on behalf of\nthe business and should not be treated as a third-party domain\n- Domain: how to denote that other domains are part of the same business and\nshould not be treated as third-party domains\n- How to map these changes to compact policies\n- How does policy reference file need to change\n\nIdeas:\n- Ability to denote agent status (in ENTITY element as addition to business\ndataset?)\n- Ability to list business domains (in ENTITY element?)\n- If not otherwise specified, a domain in the third-party context should be\nconsidered a third-party business and restricted as such.\n- New recipient element (e.g. \"<FIRST-PARTY>\") for an agent's policy, to\ndenote that data is being collected on behalf of the first-party business\nentity\n- Ability for policy to reference the first-party policy that should apply\n(e.g. URI attribute on new recipient element)\n- New purpose element (e.g. \"<FIRST-PARTY-USES>\") for an agent's policy, to\ndenote that data will be used for purposes declared in referenced policy\n- New P3P HTTP header to reference first-party domain or business domains\nlist, or compact policy token(s) to force use of full policy\n\nJack Humphrey\nCoremetrics\n\n\n\n", "id": "lists-017-2451860"}, {"subject": "RE: [Agent/Domain] brainstormin", "content": "Brooks,\n\nThe basic problem I'm trying to address affects business agents as well as\ndomains owned by the same entity, and it is that there is no way to declare\nthose relationships so that a user agent can make better decisions about\napplying restrictions.\n\nA secondary problem is that an agent might indeed just be collecting data on\nbehalf of the PRIMARY entity (e.g. the service/site with which the user is\nactually interacting), and therefore want to augment the first party's\npolicy instead of defining it for them. \n\nNot sure I see your point about the Dobbsco agent cookie being a shared\nresource across multiple entities. If the agent uses an identifier in a\ndobbsco.com cookie, but does not use that cookie to link data across its\nclients, then we're back to the linked versus linkable argument.\n\nIn any case, even if the 1:1 exists, it might not necessarily be proper for\nDobbsco (the agent) to declare itself to be Gatesco (the first party). For\nexample, the Dobbsco agent might want to declare certain ways in which it\nuses the data in a non-identifiable way (e.g. administrative purposes), but\ndefer declaration of the ultimate purposes of the collection to Gatesco.\n\nBut let's suppose that Dobbsco declaring itself to be Gatesco was okay --\nit's not possible now to do that in a way that indicates to the user agent\nthat Dobbsco is not a true third-party, is it? (assuming that we're talking\nabout a dobbsco.com cookie set in the context of the gatesco.com web site)\n\nIt seems to me that there's more accountability if the policy on the agent\nsite can refer to a policy posted on the first party site, instead of\ndeclaring the first party's policies on their behalf.\n\n++Jack++\n\n-----Original Message-----\nFrom: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\nSent: Tuesday, April 08, 2003 4:07 PM\nTo: 'Humphrey, Jack'; public-p3p-spec@w3.org\nSubject: RE: [Agent/Domain] brainstorming\n\n\nJack,\nI guess I am still confused what problem we are attempting to address.  My\nconcern is that there should not be a method of obfuscating the traditional\ndeclaratations via the use of some type of an AGENT token.  If data is being\n\"used\" in given ways the fact that it was collected by an agent is really\nimmaterial in that it is still expressible under given syntax.\n\nSo I have always taken it that if I, e.g. BrooksCo was acting as an agent in\nsay a Site Analytics or Ad Serving capacity for GatesCo and providing a\npairing of unique identifiers back to GatesCo (say  a cookie id and an\nidentifier meaningless to me but identifiable to Gatesco) that the correct\ndeclarations would be perfectly expressible under current syntax:\nENTITY: has to be Dobbsco the agent unless acting in a 1:1 capacity soley\nfor Gatesco in other words the cookie is not a shared resource across\nmultiple other entities for whom Dobbsco is acting as an agent.  If a 1:1\nexists then simply have the entity described as Gatesco.\nRECIPIENT: OURS (unless Gatesco provides the data externally and then modify\nfrom their perspective)\nALL the rest in accordance to how GATESCO is using the data...  if dobbsco\nhas no rights to the data and is only acting as a processor the only duty I\nsee for him is to get from Gatesco what the correct statements would be.\n\nNot sure but are we attempting to come up with a token that in effect says -\n\"I am not sure what Gatesco is doing with data, I am just the collector and\nnot using it myself?\"\n\n-Brooks\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Monday, April 07, 2003 4:28 PM\nTo: public-p3p-spec@w3.org\nSubject: [Agent/Domain] brainstorming\n\n\n\nThere haven't been any responses to my previous attempt to get this\ndiscussion going, so I'm going to attempt to summarize my view of the\nproblem and the ideas I've had so far. I look forward to some discussion.\n\nI'd like to schedule a conference call of the task force for this week, so\nif you think you'd like to be involved, please email me directly.\n\nTerminology:\n- Business agent: an entity that acts on behalf of another entity\n- Business domains: list of DNS domains or hosts that are owned (directly or\nindirectly) by a single entity\n- First-party business: entity providing the primary site or service with\nwhich user is interacting\n- Third-party business: separately-owned entity that may have access to data\ncollected during user's interaction with first-party business\n- Third-party context: non-primary domains that are owned by either: the\nfirst-party business (other business domains), business agents for the\nfirst-party business, or third-party businesses\n\nThe basic premise I'm working under is that user agents should only restrict\ntrue third-party businesses, not sites/services provided by the first-party\nbusiness or its agents. We should consider changes to the specification for\nrequired/recommended user agent behavior as well as the more fundamental\nchanges (discussed below) to make it possible to describe these\nrelationships.\n\nQuestions/Problems:\n- Agent: how to denote that it is an agent of the first-party business\n- Agent: how to denote which data is collected on behalf of the first party\n- Agent: how to denote that purposes are stated in the first party policy\n- Agent: how to denote that a domain belongs to an agent acting on behalf of\nthe business and should not be treated as a third-party domain\n- Domain: how to denote that other domains are part of the same business and\nshould not be treated as third-party domains\n- How to map these changes to compact policies\n- How does policy reference file need to change\n\nIdeas:\n- Ability to denote agent status (in ENTITY element as addition to business\ndataset?)\n- Ability to list business domains (in ENTITY element?)\n- If not otherwise specified, a domain in the third-party context should be\nconsidered a third-party business and restricted as such.\n- New recipient element (e.g. \"<FIRST-PARTY>\") for an agent's policy, to\ndenote that data is being collected on behalf of the first-party business\nentity\n- Ability for policy to reference the first-party policy that should apply\n(e.g. URI attribute on new recipient element)\n- New purpose element (e.g. \"<FIRST-PARTY-USES>\") for an agent's policy, to\ndenote that data will be used for purposes declared in referenced policy\n- New P3P HTTP header to reference first-party domain or business domains\nlist, or compact policy token(s) to force use of full policy\n\nJack Humphrey\nCoremetrics\n\n\n\n", "id": "lists-017-2464810"}, {"subject": "Re: UA: user agent translation documents to revie", "content": "I have now posted the PB, Netscape, and IE translations at \nhttp://www.w3.org/P3P/1.1/documents.html#ua. UA task force members, \nplease review these documents and send email directly to me to let me \nknow your availability to participate in a conference call to begin our \ndiscussions on April 14 or April 21.\n\nLorrie\n\n\n\n", "id": "lists-017-2480092"}, {"subject": "[BH] Comments on draft-ietf-geopriv-reqs0", "content": "I've reviewed [1] as part of my background research for the \"Beyond-HTTP\" \nP3P taskforce [2]. I'm not presently able to draw any conclusions with \nrespect to [2] but I think it's an interesting document and have two \ncomments.\n\n[1] http://www.ietf.org/internet-drafts/draft-ietf-geopriv-reqs-03.txt\n[2] http://www.w3.org/P3P/2003/04-beyond-http.html\n\n[[[\n   5.2. The Location Object and Using Protocol\n   ...\n      Location Object (LO): This data contains the Location Information\n         of the Target, and other fields including an identity or\n         pseudonym of the Target, time information, core Privacy Rules,\n         authenticators, etc.  ...\n\n   Nothing is said about the semantics of a missing field.  For\n   instance, a partially filled object MAY be understood implicitly as\n   the request to complete it....\n]]]\n\nSince a LO contains the core Privacy Rules, one should *not* permit the \nabsence of the privacy rule syntax to result in ambigous semantic \ninterpretation [3].\n\n[3] http://www.w3.org/TR/md-policy-design#_Semantic_Clarity\n\n\n\n[[[\n  5.5. Privacy Rules\n   ...A full set of Privacy Rules will likely include both rules that have\n   only one possible technical meaning, and rules that will be affected\n   by a locality's prevailing laws and customs. \n]]]\n\nThis, and the example, makes it sound as if these were disjoint sets. \"You \nmay not store my location for more than 2 days\" is very clear even if it is \noverridden by other (legal) rules. This paragraph seems to be confusing the \narticulation of a non-ambiguous rule with the an a posteriori \ninterpretation of all operative rules that might exceed the knowledge of \nthe Rule Maker or Location Recipient beforehand.\n\n\n\n", "id": "lists-017-2487101"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "On Monday 07 April 2003 20:27, Eric Brunner-Williams in Portland Maine \nwrote:\n> p3p:nonident - does not collect identified data\n> epp:null - data is not persistent\n>\n> The problem-domains are not identical. P3P is concerned with \"initial\n> data collection\", EPP is concerned with \"onward transport\" of data\n> previously collected.\n\nIf the initial data collection had a particular policy (P3P) wouldn't it be \nbest to pass on the initial P3P agreed to, with the data, when it is \ndistributed to those with the \"same\" policies?\n\nLet me back way up and ask what data is involved here? Was there a usage \nscenario? (Didn't see one, but I expect its clear to those involved with \nprovreg, of which I'm mostly ignorant.) I was presuming, as you said, that \nthe data was initially collected by a registrar and then shared with a \nregistry. So for instance:\n  https://www.gandi.net/whois?l=EN&domain=w3.org\ncontains personally identifiable data. My (continued) presumption was that \nthe registrar, Gandi, might have a policy associated with the collection of \nthis information. Now, Gandi might also share this with a .org TLD registry \ndata base. So in it's initial <create> it would see the registry <greeting> \nand note its <dcp> (policy). If this didn't match the data it collected it \nunder, then it might not upload the information if it said p3p:same, or it \nmight if it said p3p:other-recipient. (In the first case, it's more likely \nto say p3p:public since whois is public, or at least to set its privacy \npolicy based on the policies it knows it must interact with on the back \nend.)\n\nHowever, my scenario, which is probably incorrect, fails to predict the \nvariances in EPP.\n\n> As \"others\" are the IESG, looking at what bits of a data collection vocab\n> are substantially similar, or dissimilar, across problem domains, may not\n> be the best use of anyone's time.\n\nI didn't follow this bit.\n\n\n\n", "id": "lists-017-2497463"}, {"subject": "Re: [BH] Comments on draft-ietf-geopriv-reqs0", "content": "Joe,\n\nLet me offer my 2 cents in reaction to your comments.   Then, for the \nbenefit of the \"beyond http\" P3P task force in the W3C (a new effort \nthat I am just joining within the W3C), I will add at the end of this \nmessage my quick personal overview of where geopriv is now and where \nit is likely to go.  I encourage anyone on the  geopriv list to \ncorrect or supplement my overview.\n\nJohn Morris\n\nAt 3:13 PM -0400 4/9/03, Joseph Reagle wrote:\n>I've reviewed [1] as part of my background research for the \"Beyond-HTTP\"\n>P3P taskforce [2]. I'm not presently able to draw any conclusions with\n>respect to [2] but I think it's an interesting document and have two\n>comments.\n>\n>[1] http://www.ietf.org/internet-drafts/draft-ietf-geopriv-reqs-03.txt\n>[2] http://www.w3.org/P3P/2003/04-beyond-http.html\n>\n>[[[\n>    5.2. The Location Object and Using Protocol\n>    ...\n>       Location Object (LO): This data contains the Location Information\n>          of the Target, and other fields including an identity or\n>          pseudonym of the Target, time information, core Privacy Rules,\n>          authenticators, etc.  ...\n>\n>    Nothing is said about the semantics of a missing field.  For\n>    instance, a partially filled object MAY be understood implicitly as\n>    the request to complete it....\n>]]]\n>\n>Since a LO contains the core Privacy Rules, one should *not* permit the\n>absence of the privacy rule syntax to result in ambigous semantic\n>interpretation [3].\n>\n>[3] http://www.w3.org/TR/md-policy-design#_Semantic_Clarity\n\nI agree -- and I think that the working assumption of the geopriv WG \naddresses this point.  I believe there is agreement in the WG that \nthe default rule is that location should receive a high level of \nprivacy protection in the absence of rules to the contrary.  In other \nwords, the protocol will default to \"do not disclose\" unless a \nPrivacy Rule (in the LO or external) would permit disclosure.\n\nBut having said that, I cannot locate anywhere where this default \nassumption is clearly articulated in a WG document.  If it is not, we \nneed to add it.\n\n>[[[\n>   5.5. Privacy Rules\n>    ...A full set of Privacy Rules will likely include both rules that have\n>    only one possible technical meaning, and rules that will be affected\n>    by a locality's prevailing laws and customs.\n>]]]\n>\n>This, and the example, makes it sound as if these were disjoint sets. \"You\n>may not store my location for more than 2 days\" is very clear even if it is\n>overridden by other (legal) rules. This paragraph seems to be confusing the\n>articulation of a non-ambiguous rule with the an a posteriori\n>interpretation of all operative rules that might exceed the knowledge of\n>the Rule Maker or Location Recipient beforehand.\n\nI agree that this discussion warrants clarification.  The goal was \nnot to suggest two exclusive sets:\n\n1.  technically unambiguous rules, and\n2.  rules that will be affected by local law, etc.\n\nInstead, the goal was to acknowledge that (a) some rules can be \nexpressed in technically unambiguous terms, while (b) other rules \nwill not be clear without resort to an applicable legal norm.  But \nboth types of rules (a+b) can certainly be affected or overridden by \na local law.   What we were concerned about was to make clear that \nthe set of (b) rules were still valuable to include even if they did \nnot have a single unambiguous technical meaning.   But in any event, \nthe clarification you suggest is worthwhile.  I'll work on some \nspecific language to address the two points raised here.\n\nLet me change gears and give the BH/P3P task force a quick overview of geopriv:\n\nGreatly summarizing the geopriv charter [4], the mission of the WG is \nto create a privacy protecting protocol to be used when location \ninformation is transmitted.  In the language of the WG, the WG is \ncreating a \"Location Object\" [LO] which will be able to contain both \nlocation information and privacy rules (or a pointer to external \nprivacy rules).  The protocol must be usable in situations with \nconstrained devices with low bandwidth and/or computing power.  The \nWG is approaching a final requirements draft [5].\n\nThat draft says that the Location Object must be able to carry a \nlimited set of privacy rules, and must be able to refer to an \nexternal set of rules as well.  There is not final agreement on \nprecisely what privacy rules will be built into a LO, but the most \nrecent proposal of some WG participants (including me) is found at \n[6].  Even a couple of elements in that version, however, are in a \nstate of flux (something that I will try to bring back to the geopriv \nlist shortly).\n\nLooking more broadly, the WG has NOT decided on the format for the \nexpression of the LO, but XML has certainly been discussed as a \nstrong candidate.   Even more generally, I think that many in the \ngeopriv WG would be open to using, or at least being compatible with, \nP3P, so long as that goal did not slow down geopriv's already slow \n(but significantly accelerating) progress to date.\n\nLet me know if there are more specific points about geopriv that the \npublic-p3p-spec@w3.org wants to know at this point.....  John\n\n[4]  http://www.ietf.org/html.charters/geopriv-charter.html\n[5]  http://www.ietf.org/internet-drafts/draft-ietf-geopriv-reqs-03.txt\n[6]  http://www.ietf.org/internet-drafts/draft-morris-geopriv-core-01.txt\n\n\n\n", "id": "lists-017-2508588"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "> Sheesh, okay EBW, \"no one suggested doing it - on our mailing list.\" ;) ;)\n\nGranted, I had prior general knowledge, but it did leak into PROVREG, via its\nprinciple implementor.\n\n------- Forwarded Messages\n\nReturn-Path: owner-ietf-provreg@cafax.se\nDelivery-Date: Sat Feb  1 13:37:27 2003\nReturn-Path: <owner-ietf-provreg@cafax.se>\nReceived: from nic.cafax.se (nic.cafax.se [192.71.228.17])\nby nic-naa.net (8.12.6/8.12.6) with ESMTP id h11IbQRS025784\nfor <brunner@nic-naa.net>; Sat, 1 Feb 2003 13:37:27 -0500 (EST)\n(envelope-from owner-ietf-provreg@cafax.se)\nReceived: from nic.cafax.se (localhost [127.0.0.1])\nby nic.cafax.se (8.12.5/8.12.5) with ESMTP id h11IQF9p008342\nfor <ietf-provreg-outgoing@nic.cafax.se>; Sat, 1 Feb 2003 19:26:15 +0100 (MET)\nReceived: by nic.cafax.se (8.12.5/8.12.5/Submit) id h11IQFAo008341\nfor ietf-provreg-outgoing; Sat, 1 Feb 2003 19:26:15 +0100 (MET)\nX-Authentication-Warning: nic.cafax.se: majordom set sender to owner-ietf-provreg@cafax.se using -f\nReceived: from bartok.sidn.nl (bartok.sidn.nl [193.176.144.164])\nby nic.cafax.se (8.12.5/8.12.5) with ESMTP id h11IQE9p008336\nfor <ietf-provreg@cafax.se>; Sat, 1 Feb 2003 19:26:14 +0100 (MET)\nReceived: from bartok.sidn.nl (localhost.sidn.nl [IPv6:::1])\nby bartok.sidn.nl (8.12.6/8.12.6) with ESMTP id h11IQEMH047050\nfor <ietf-provreg@cafax.se>; Sat, 1 Feb 2003 19:26:14 +0100 (CET)\n(envelope-from jaap@bartok.sidn.nl)\nReceived: (from jaap@localhost)\nby bartok.sidn.nl (8.12.6/8.12.6/Submit) id h11IQDcX047049\nfor ietf-provreg@cafax.se; Sat, 1 Feb 2003 19:26:13 +0100 (CET)\nReceived: from eddie.Austria.EU.net (eddie.austria.eu.net [193.154.142.22])\nby nic.cafax.se (8.12.5/8.12.5) with ESMTP id h11IJE9p008209\nfor <ietf-provreg@cafax.se>; Sat, 1 Feb 2003 19:19:14 +0100 (MET)\nReceived: from eddie.Austria.EU.net (localhost [127.0.0.1])\nby eddie.Austria.EU.net (8.12.3/8.12.3/Debian -4) with ESMTP id h11IJDs5012961\nfor <ietf-provreg@cafax.se>; Sat, 1 Feb 2003 19:19:13 +0100\nReceived: (from lendl@localhost)\nby eddie.Austria.EU.net (8.12.3/8.12.3/Debian -4) id h11IJDf9012960\nfor ietf-provreg@cafax.se; Sat, 1 Feb 2003 19:19:13 +0100\nDate: Sat, 1 Feb 2003 19:19:13 +0100\nFrom: Otmar Lendl <lendl@nic.at>\nTo: ietf-provreg@cafax.se\nSubject: [ietf-provreg] FYI: nic.at presentations from RIPE44\nMessage-ID: <20030201191913.A12932@eunet-ag.at>\nReferences: <200302011751.h11HpnMH046835@bartok.sidn.nl>\nMime-Version: 1.0\nContent-Type: text/plain; charset=us-ascii\nContent-Disposition: inline\nIn-Reply-To: <200302011751.h11HpnMH046835@bartok.sidn.nl>\nUser-Agent: Mutt/1.3.23i\nSender: owner-ietf-provreg@cafax.se\nPrecedence: bulk\n\nOn 2003/02/01 18:02, Jaap Akkerhuis <jaap@sidn.nl> wrote:\n> At the DNR-forum at RIPE-44 last week, the polish registry presented\n> their implementation of EPP.\n\nOn a related note: Our presentation from monday's Centr workshop\nare online as well. You can get the .ppt files (and the latest source\ncode tarballs) from \nhttp://sourceforge.net/project/showfiles.php?group_id=66464 .\n\n/ol\n\n\n------- Message 2\n\nReturn-Path: owner-ietf-provreg@cafax.se\nDelivery-Date: Sat Feb  1 14:03:03 2003\nReturn-Path: <owner-ietf-provreg@cafax.se>\nReceived: from nic.cafax.se (nic.cafax.se [192.71.228.17])\nby nic-naa.net (8.12.6/8.12.6) with ESMTP id h11J32RS025829\nfor <brunner@nic-naa.net>; Sat, 1 Feb 2003 14:03:03 -0500 (EST)\n(envelope-from owner-ietf-provreg@cafax.se)\nReceived: from nic.cafax.se (localhost [127.0.0.1])\nby nic.cafax.se (8.12.5/8.12.5) with ESMTP id h11Ipr9p008607\nfor <ietf-provreg-outgoing@nic.cafax.se>; Sat, 1 Feb 2003 19:51:53 +0100 (MET)\nReceived: by nic.cafax.se (8.12.5/8.12.5/Submit) id h11IpruU008606\nfor ietf-provreg-outgoing; Sat, 1 Feb 2003 19:51:53 +0100 (MET)\nX-Authentication-Warning: nic.cafax.se: majordom set sender to owner-ietf-provreg@cafax.se using -f\nReceived: from bartok.sidn.nl (bartok.sidn.nl [193.176.144.164])\nby nic.cafax.se (8.12.5/8.12.5) with ESMTP id h11Ipq9p008601\nfor <ietf-provreg@cafax.se>; Sat, 1 Feb 2003 19:51:53 +0100 (MET)\nReceived: from bartok.sidn.nl (localhost.sidn.nl [127.0.0.1])\nby bartok.sidn.nl (8.12.6/8.12.6) with ESMTP id h11IpqMH047140\nfor <ietf-provreg@cafax.se>; Sat, 1 Feb 2003 19:51:52 +0100 (CET)\n(envelope-from jaap@bartok.sidn.nl)\nMessage-Id: <200302011851.h11IpqMH047140@bartok.sidn.nl>\nTo: ietf-provreg@cafax.se\nSubject: Re: [ietf-provreg] FYI: nic.at presentations from RIPE44 \nIn-reply-to: Your message of Sat, 01 Feb 2003 19:19:13 +0100.\n             <20030201191913.A12932@eunet-ag.at> \nDate: Sat, 01 Feb 2003 19:51:52 +0100\nFrom: Jaap Akkerhuis <jaap@sidn.nl>\nSender: owner-ietf-provreg@cafax.se\nPrecedence: bulk\n\n\n    On 2003/02/01 18:02, Jaap Akkerhuis <jaap@sidn.nl> wrote:\n    > At the DNR-forum at RIPE-44 last week, the polish registry presented\n    > their implementation of EPP.\n\n    On a related note: Our presentation from monday's Centr workshop\n    are online as well. You can get the .ppt files (and the latest\n    source code tarballs) from\n    http://sourceforge.net/project/showfiles.php?group_id=66464 .\n\nLet me clarify a bit about this. At the first day of RIPE meetings\nthere is usually a CENTR technical meeting. This time, the afternoon\nwas devoted to EPP.  SInce the meeting is limited to CENTR members\nand invitees (Scott Hollenbeck was there, among others) I don't\nfeel comfortable about quoting from that, although often the meeting\nminutes are published on the CENTR website.\n\nAnyway, Otmar Lendl on behalf of the Austrian registry, presented\nat the centr-tech meeting an implementation of an EPP server as a\nmod_epp Apache module.  It is nice to see that this is actually\npublic information. For details, see the URL he mentions.\n\njaap\n\n------- End of Forwarded Messages\n\n\n\n", "id": "lists-017-2523180"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "> If the initial data collection had a particular policy (P3P)\n\nThis may be a theory-of-foo bump, or it may be a slow moving armidillo, but\ndata originates at a registrar.\n\nWe (epp-hat==1) aren't designing the registrar's UI.\n\n> ... wouldn't it be \n> best to pass on the initial P3P agreed to, with the data, when ...\n\nThis is an aside, but (you asked for it). A party interposes on the data\nflow between source and sink, and edits the data. Is policy unaffected by\nthe transform? I gave this a lot of thought before, and after, the joint\nWAPF/W3C meeting in Munich (Dec 1999), and concluded that proof of closure\nwas not trivial.\n\nFor the IETFers, take a look at any of the three cache BoF/WGs that came\nout two years ago -- there was a reason why Mark Nottingham (co-chair, WEBI)\nattended our f2f at IETF-51 (London), and it wasn't just because we were\nthen both contributors to the W3C's P3P Spec WG.\n\nOf these, only Leslie's considered the possibility that cached content\nwas policied (in an IRTF-IDRM-esque fashion) before it was transformed\nfor edge device delivery.\n\nFor the P3Pers, consider a nice bit of html with a nice p3p statement in\nthe usual WKL. It is accessed via a WAP device, and transformed by some\nWAP content management cache for \"last mile\" lower bandwidth link reasons,\nand additional operator policy goals (\"walled garden\"). How does an user's\np3p evaluation engine evaluate the delivered p3p statement(s)?\n\nAnyway, we don't know that there was a p3p statement when the data was\ninitially collected by the agent/reseller/registrar. What we do know is\nthat a registrar is surrendering, and possibly retaining, data, and a\nregistry is collecting, and possibly discarding, data.\n\n> when it is distributed to those with the \"same\" policies?\n\nBut it isn't. There are several adminstrative or jurisdictional policies\nthat the registrar-collected data might be provisioned (onward-transported)\nto, and the registries may be unable, under the distinct operational and/or\npolicy regimes they operate under, to accept some registrar-collected data,\nregardless of the policy under which that data was collected.\n\n...\n\n> I didn't follow this bit.\n\nAssume no one has any use for 95/46/ec, or the OECD Guidelines, or the FTC\nrule-of-the-day (generally, policy on collectors), and only wants raw read\nand write access on the registries, and a trap on read-requests by other,\nto interpose a write (or its static equivalent, some sort of mask), for a\nregistrant (user), and/or his/her cluefull agency.\n\nNow (epp-hat==1) and (p3p-hat==1) are very, very far apart. Sailing on\ndifferent currents altogether, and diverging too.\n\nFortunately, this [1] shows that the problem is minor. Also, the ICANN\nRegistrars may be limiting whois (both bulk and :43) more effectively\nthan we (PROVREG +/- IESG) are.\n\nCheers,\nEric\n\n[1] http://www.cdt.org/speech/spam/030319spamreport.pdf\n\n\n\n", "id": "lists-017-2547346"}, {"subject": "UA: comments on translation document", "content": "I have reviewed the IE, Netscape, and PB translations and would like\nto share my observations.\n\nGeneral Observations\n\n- Overall I found most of the translations to be accurate\n   representations of the P3P vocabulary. However, there were a small\n   number of elements that have a translations in one or more UA that I\n   would argue are misleading (I will list them below).\n\n- I found the translations of some of the elements (especially the IE\n   translations) to be rather verbose and in some cases written in\n   language that I don't think will be all that clear to end\n   users. For the most part I don't find these translations\n   misleading and therefore I wouldn't really object to their\n   continued use. However, I think they can be improved.\n\n- I found the grammar used in some of the Netscape translations to be\n   problematic. Many elements listed under the same heading lack\n   parallel structure. Again, this is not misleading, but any\n   guidelines we issue should have proper grammar and consistent\n   structure.\n\n\nSpecific Observations\n\n- IE: uniqueid - I would strike \"by a Web site or service\" as this is\n   a restriction not included in the P3P definition. Furthermore this\n   definition does not make it clear that government-issued\n   identifiers are excluded from this category\n\n- IE: demographic - I would strike \"not tied to an identified person\"\n   as this is not a restriction included in the P3P definition.\n\n- IE: pseudo-analysis - I found the example in this definition\n   especially confusing.\n\n- IE: ours - I found the this definition especially confusing.\n\n- IE: retention - I liked most of these definitions\n\n- IE: court - This is the only disputes that does not include a short\n   description string... why?\n\n- IE: disputes - does not display long description string or remedies\n\n- IE: required attribute - not displayed... I would argue that this\n   is fairly important\n\n- IE: consequence - not displayed\n\n- IE: data - only categories are displayed, not individual data\n   elements... I would argue that it is important to display\n   individual data elements or at the very least the categories they\n   belong to rather than omitting them completely (unless all DATA is\n   omitted)\n\n- PB: retention - does not display retention\n\n- PB: disputes - does not have translations -- displays short and\n   long description... does not display remedies\n\n- NS: access - nonident and none don't fit parallel structure\n\n- NS: other-ident - I don't understand this definition at all\n\n- NS: disputes:law - I don't understand this definition at all\n\n- NS: correct - doesn't fit parallel structure\n\n- NS: purpose heading - \"that you have supplied\" is too limiting --\n   P3P policies also cover data the user may not have explicitly\n   supplied\n\n- NS: pseudo-decision - short version doesn't mention pseudonymity\n   and is indistinguishable from individual-decision\n\n- NS: other purpose / other category - I like the fact that NS flags\n   other purposes that are missing the mandatory human-readable\n   explanation -- this is a good alternative to refusing to process the\n   whole P3P policy because of this\n\n- NS: ours - I think this definition is confusing\n\n- NS: uniqueid - not parallel structure\n\n- NS: demographic - I don't think this really captures the full P3P\n   definition\n\n\nSome Questions for the TF to Consider\n\n- Should we try to converge on a single set of translations? Should\n   we come up with a long and short translation for each element,\n   perhaps using the click through approach like NS uses? Should our\n   guidelines list all acceptable translations they people submit\n   rather than trying to converge or one or two?\n\n- Should we recommend that P3P user agents be capable of displaying\n   complete translations (all elements, including all human-readable\n   elements)? If not, is there a minimum set of elements they should\n   display? Or perhaps some guidelines on completeness that will\n   prevent misleading users?\n\n- Should we make any recommendations about displaying human-readable\n   fields?\n\n- Should we make any recommendations about displaying data elements\n   and categories?\n\n- What other types of guidelines should we consider?\n   - recommendation that UAs have ability to save policies\n   - recommendation that UAs have ability to print policies (if run on\n     devices connected to printers)\n   - recommendation that UAs refuse to process CPs for sites not\n     \"properly\" P3P-enabled\n   - recommendation for checking cookie policies (strengthen 2.3.2.7\n     requirements)\n\n\n\n", "id": "lists-017-2559811"}, {"subject": "Re: P3P spec wg call April 1", "content": "The next P3P specification group conference call will be on\nWednesday, April 16, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports -- chairs please be prepared to explain the plan\n    you have for your TF and propose milestones\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relaitonships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben [also note charter change]\n\n2. Review current bugzilla list (141, 144, 167, 168, 169, 170, 171,\n    172, 173, 174, 178)\n    - Please register for bugzilla -- You can use the interface at\n    http://www.w3.org/Bugs/Public/query.cgi to get a list of all P3P\n    open issues\n\n3. Set date of next conference call (April 23 or 30?)\n\n\n\n", "id": "lists-017-2570918"}, {"subject": "UA: task force teleconference April 21, 1 p", "content": "The UA TF will have a conference call on Monday, april 21 at 1 pm \nEastern (for 1 hour). We will use the same bridge and code as is being \nused for the full working group call. If you are not a TF member but \nwould like to participate in this call (or join the TF), please send me \nemail.\n\nWe will begin our discussions of high-level observations about the \nthree translation documents and the questions I posed in \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Apr/0018.html\n\n\n\n", "id": "lists-017-2578788"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "On Friday 11 April 2003 06:20, Eric Brunner-Williams in Portland Maine \nwrote:\n> > If the initial data collection had a particular policy (P3P)\n>\n> This may be a theory-of-foo bump, or it may be a slow moving armidillo,\n> but data originates at a registrar.\n> We (epp-hat==1) aren't designing the registrar's UI.\n\nSo is the information covered is not my data (my contact info I've placed \nwith the registrar) but the registrars information? I continue to fail to \nunderstand exactly what information the practice applies to and governs. I \nsuspect a step-by-step scenario would be immensely useful.\n\n\n\n", "id": "lists-017-2586458"}, {"subject": "[Agent/Domain] proposed milestone", "content": "Agent/Domain Relationship Task Force\nProposed Milestones\n\n1) Agree on terminology. Proposed terminology (different from my last\nemail):\n a) Service: a web site (identified by domain or host name) or other\napplicable endpoint\n b) Agent service: a service that acts solely on behalf of another service\n c) Primary service: service with which user is DIRECTLY interacting\n d) Secondary service: service with which user is INDIRECTLY interacting due\nto configuration of primary service (e.g. image on primary web site served\nby secondary web site)\n\n2) Agree on goals. Proposed set:\n a) Ability to denote that a policy applies to multiple services (for full\nand compact policies), e.g. because the same entity owns all services\n b) Ability to denote that a secondary service setting and receiving cookies\nis an agent collecting data solely on behalf of the primary service (for\nfull and compact policies)\n c) Recommendation (requirement?) that user agents do not apply different\nstandards to  cookies set by secondary services when:\n  i) same policy applies to both primary and secondary services, or\n  ii) secondary service declares itself to be an agent of primary service\n d) Ability for agent services to refer to declaration of purposes in a\npolicy provided by primary service (for full and compact policies)\n e) Recommendation (requirement?) that user agents follow reference in (d)\nand consider policy to be the union of the two policies\n\n3) Draft proposal specification modifications to achieve agreed-upon goals\n\nIf possible, I would like to have a preliminary discussion of the\nterminology and goals with the TF tomorrow, in advance of the Wednesday WG\ncall.\n\nJack Humphrey\nCoremetrics\n\n\n\n", "id": "lists-017-2596453"}, {"subject": "Re: [ietfprovreg] [BH] P3P and Extensible Provisioning Protoco", "content": "> > > If the initial data collection had a particular policy (P3P)\n> >\n> > This may be a theory-of-foo bump, or it may be a slow moving armidillo,\n> > but data originates at a registrar.\n> > We (epp-hat==1) aren't designing the registrar's UI.\n> \n> So is the information covered is not my data (my contact info I've placed \n> with the registrar) but the registrars information? I continue to fail to \n> understand exactly what information the practice applies to and governs. I \n> suspect a step-by-step scenario would be immensely useful.\n\nWe have some rules, things like delete-object-before-create-object returns\nan error.\n\nWhat we don't have rule about are where registrars go to get \"data\", they\ncould just be making it up.\n\nThere is no in-band mechanism to distinguish \"registrar-generated-data\"\nfrom \"entity-other-than-registrar-generated-data\".\n\nThere is a data collection policy announcement from a data collector, which\nis indifferent as to the originator of the data which it collects, and it is\npossible that a registrar might use non-fictive data.\n\nDid the registrar use P3P when collecting the data? I've no idea. I don't\neven know if the registrar was the initial data collector, or if the initial\ndata collector was a reseller and the registrar engaged in onward-transport.\nI don't know how the data got to the registrar.\n\nWhat the <dcp> covers is _everything_ in a session. Since sessions exhaust,\nfor the time being, the semantics of state exchange between registrars and\nregistries, everything collected by a registry is policied. Note that any\nregistry may have a number other than one of applicable <dcp> statements,\nwith non-overlapping session-scope.\n\nEric\n\n\n\n", "id": "lists-017-2605228"}, {"subject": "[CONV] Some XML based profile", "content": "Seems that there might be two requirements in tension:\n1. To create a high fidelity transliteration of the existing structures into \na format specifiable by XML schema.\n2. To converge with existing formats\n\nSome links on that latter point:\n\nhttp://xml.coverpages.org/vcard.html\nhttp://www.oasis-open.org/committees/ciq/ciq.shtml \nhttp://www.globecom.net/ietf/draft/draft-dawson-vcard-xml-dtd-02.html\n\n\n\n", "id": "lists-017-2616152"}, {"subject": "RE: [CONV] Some XML based profile", "content": "Yes you are right. I think that the 1. is for P3P1.1. and 2. is for P3P2.0\nThanks for the links.\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n[mailto:public-p3p-spec-request@w3.org]On Behalf Of Joseph Reagle\nSent: Wednesday, April 16, 2003 5:55 PM\nTo: 'public-p3p-spec@w3.org'\nSubject: [CONV] Some XML based profiles\n\n\n\nSeems that there might be two requirements in tension:\n1. To create a high fidelity transliteration of the existing structures into\na format specifiable by XML schema.\n2. To converge with existing formats\n\nSome links on that latter point:\n\nhttp://xml.coverpages.org/vcard.html\nhttp://www.oasis-open.org/committees/ciq/ciq.shtml\nhttp://www.globecom.net/ietf/draft/draft-dawson-vcard-xml-dtd-02.html\n\n\n\n", "id": "lists-017-2623748"}, {"subject": "[Minutes] of the 16 April 2003 WG Cal", "content": "Minutes\n\n1. Task force reports -- chairs please be prepared to explain the plan\n   you have for your TF and propose milestones\n   - P3P beyond HTTP[1] - Joseph Reagle\n   Enumarated participants[2] \n Gave a report on work going on and enuermated a lot of questions\n like: where does it belong? Web Services, Soap or rather P3P\n distinguishing P3P statements\n a lot of people taking a statement and give it with the third party\n transfer. \n From those questions we get a lot of input for requirements for\n future versions. See the page of the taskforce[3]\n Lorrie asked for the XML P3P tag\n\n   + Relationsship with Liberty Alliance. Danny already received email\n   but hasn't responded yet. \n   Joseph: This is a potential use-case. \n ACTION: Lorrie follow up with Liberty Alliance\n\n   - User agent behavior - Lorrie Cranor\n   Lorrie reported: Planning on having a call on next Monday (see\n meetings page[4] ) There are the terms presented and now the\n translation of the elements from XML to english has to be reviewed. \n Discussion about holiday..\n ACTION: everybody, please be sure to copy rigo@w3.org on every\n meeting arrangement to update the meeting-page[4]\n \n   - Compact policies - Brian Zwit\n   Mail from Brian, but nothing new\n \n   - Article 10 vocabulary issues - Giles Hogben\n     Diana is not available for the moment. Planned to meet with Giles,\n Diana Rigo, probably teleconf, so people from outside EU could join\n in. It will be sometime in May. \n \n   - Agent and domain relaitonships - Jack Humphrey\n   Haven't had teleconf, put up one for next week. Try to find some\n useful terminology to know what we are talking about. Try to find\n which problems we want to solve. \n\n Jack wanted feedback from anybody outside that want to contribute \n to the TF. He will send email to public-p3p-spec and public-p3p\n \n   - Consent choices - Matthias Schunter\n   no feedback yet\n\n \n   - Converting P3P data schema to XML schema - Giles Hogben\n     written of specification on how it would look in xsd and also wrote\n XSLT to transform old dataschema into xsd. \n Had problems transforming categories. Jo asked whether it could be\n an attribute. But this did not satisfy Giles. He wanted to have an\n XML-tree to represents. \n\n Questions: is it allright to use the semantic user as category and\n put a subcategory name.\n Are one or more categories allowed or are more categories allowed?\n \n \n   - Signed P3P policies  - Giles Hogben [also note charter change]\n   We need more justification why we would need that work.\n \n ACTION: rigo update charter and determine what this group is\n supposed to do together with Danny and Giles. \n\n Joseph: you need a place to stick the signature and you need to be\n clear about the meaning of that signature. I've written that note\n http://www.w3.org/TR/xmldsig-p3p-profile/\n\n The third party can better determine whether it is secured .\n Question: should to PRF or the policy should be signed? We probably\n need both. \n\n Action: giles rigo, provide some justification and usecase. \n \n\n2. Review current bugzilla [5] list (141, 144, 167, 168, 169, 170, 171,\n   172, 173, 174, 178)\n   - Please register for bugzilla [5] -- You can use the interface at\n   http://www.w3.org/Bugs/Public/query.cgi to get a list of all P3P\n   open issues\n\n   Lorrie gave a short overview. Many people already registered\n\n3. Set date of next conference call (April 23 or 30?)\n\n  Next call will be 30 April 2003, more information on the meetings page\n\n  1. http://www.w3.org/P3P/2003/04-beyond-http.html\n  2. http://www.w3.org/P3P/2003/03-tf.html#beyond\n  3. http://www.w3.org/P3P/2003/03-binding.html\n  4. http://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n  5. http://www.w3.org/Bugs/Public/reports.cgi?product=P3P&output=most_doomed&links=1&banner=1\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-2632405"}, {"subject": "Re: BH: Introducing the Beyond HTTP (BH) Task Forc", "content": "INTRODUCTION\n\nMy name is Patrick and I am very interested in joining the \"Beyond HTTP (BH)\nTask Force.\"\n\nCurrently, I am working on a health informatics project at CSIRO by using\nWeb services technologies.\nMy main task is to tackle the security and privacy issues for this project.\nYou can download one of my \npapers about this project from:\nhttp://www.acm.org/sigs/sigecom/exchanges/volume_3_(02)/3.3-Hung.pdf\n\nIn addition, I am the session chair of \"Web Services Security\" of the First\nInternational Conference on Web \nServices (ICWS'03), which is to be held at Las Vegas in coming June:\nhttp://tab.computer.org/tfec/icws03/\n\nTherefore, I am keen to work in this task force.\n\nThanks and regards,\n\n--------------------------------------\nPatrick C. K. Hung\nResearch Scientist, Security and Privacy Group\nCommonwealth Scientific & Industrial Research Organisation (CSIRO)\nCSIRO Mathematical and Information Sciences (CMIS)\nGPO Box 664, Canberra, ACT 2601, Australia\nPh: +612 6216 7031, Fax: +612 6216 7111\nEmail: Patrick.Hung@csiro.au\nURL: www.cmis.csiro.au/Patrick.Hung\n\n\n\n", "id": "lists-017-2643674"}, {"subject": "Ref: the Beyond HTTP (BH) Task Forc", "content": "Hi Joseph,\n\nReferring to the document at http://www.w3.org/P3P/2003/04-beyond-http.html\nand your message posted on Mar 29, here are some comments.\n\n> The most interesting/difficult requirement is with respect to delegation\nand \n> propagation. The Web Services Architecture Usage Scenarios has a Third \n> Party Intermediary scenario [4] that is perhaps closes to what we would \n> want to do?\n>\n> [4] http://www.w3.org/TR/2002/WD-ws-arch-scenarios-20020730/#S030\n>\n> While I've looked at the WS-Policy specifications [5] I think it's perhaps\n\n> best to play with this scenario in the context of a SOAP message header\n[6] \n> or a WSDL definition [7] for the time being.\n> [5] \n>\nhttp://msdn.microsoft.com/webservices/understanding/default.aspx?pull=/libra\nry/en-us/dnglobspec/html/wspolicyspecindex.asp\n> [6] http://www.w3.org/TR/soap12-part1/#muprocessing\n> [7] http://www.w3.org/TR/2001/NOTE-wsdl-20010315#A3\n\nI have done a bit about WS-Policy and also the delegation issues of Web\nservices\nfor a health informatics project by using Web services technologies. If you\nare \ninterested in it, you can check some relevant information at:\nhttp://www.eti.hku.hk/eti/web/download/WSS2003.pdf\nhttp://www.cmis.csiro.au/Patrick.Hung/documents/Hung-Qiu-2003-IEEE-CEC03.pdf\n\nIn fact, I have been thinking whether it is feasible and appropriate to\nimplement/apply P3P \ninto WS-Policy for the project. Anyway, the first job for me is to\n\"modify/change/re-create\" \nthe PURPOSE elements (Section 3.3.4 from The P3P1.0 Specification) for this\nproject. Thus, \nI have to define the <purposes/> of collecting/processing the health data as\nsome specific \npurposes in the context of health data and epidemiological statistics, such\nas \"<vital-statistics/>,\" \n\"<morbidity-statistics/>,\" and etc. Anyway, I am still studying on it.\n\n> I haven't made an attempt at it yet -- has anyone else? -- but I hope to \n> soon. However, even without doing so, I ask myself if:\n> 1. Does the privacy statement belong at the SOAP level, or HTTP? In the \n> majority of cases SOAP will be transported over HTTP, what happens if both\n\n> of a HTTP statement?\n\nAs HTTP is a carrier for SOAP messages, I don't really get what you mean\nhere. Do you mean\nthat what happens if both \"Web service requestor\" and \"Web service provider\"\nusing HTTP and \nno SOAP message?\n\n> An application specification MUST specify where relevant P3P statements\ncan be found. We recommend \n> that a higher/abstract layer MAY include the privacy policy of layers it\nis dependent upon, but that lower \n> layers SHOULD NOT represent the policies of higher layers. For example, an\napplication that transfers data \n> with SOAP over HTTP that uses cookies, MUST specify:\n>\n> 1. the P3P policy associated with SOAP is normative and includes the HTTP\npolicy, or \n> 2. there are distinct P3P policies associated with the SOAP and HTTP\nlayers.\n\nBy \"my understanding,\" it should not be possible for a Web service requestor\n(i.e., Web service) to set \ncookies at the side of Web service requestor (e.g., an application program\nor even another Web service), \nexcept the Web services requestor's interface resides in a browser. The Web\nservice provider always resides \nin a Web server.\n\n> 2. Does the privacy statement belong at the WSDL level? Not every service \n> must have a service description. And if they did for the purposes of \n> privacy then *have* to fetch the WSDL before proceeding with the \n> interaction? My sense here is that SOAP would trump the OPTIONAL WSDL \n> definition.\n\nReferring to the first question, do we need separate P3P (privacy) policies\nfor each operation \n(web method) in a Web service? Then, for the second question, it may be\nclosely related to\nthe matchmaking process between Web service requestors and providers. In the\nworkflow\nenvironment, the service locators (i.e., matchmakers) may have to deal with\nthe P3P policies from\nboth tasks and Web services by using APPEL.\n\nPlease correct me if I misunderstood anything.\n\nThanks,\n\n--------------------------------------\nPatrick C. K. Hung\nResearch Scientist, Security and Privacy Group\nCommonwealth Scientific & Industrial Research Organisation (CSIRO)\nCSIRO Mathematical and Information Sciences (CMIS)\nGPO Box 664, Canberra, ACT 2601, Australia\nPh: +612 6216 7031, Fax: +612 6216 7111\nEmail: Patrick.Hung@csiro.au\nURL: www.cmis.csiro.au/Patrick.Hung\n\n\n\n", "id": "lists-017-2652320"}, {"subject": "BH: About Marc Langhernrich's paper on ubiquitous computing envir onments + P3", "content": "Hi Marc,\n\nI am interested in your paper at\nhttp://www.inf.ethz.ch/vs/publ/papers/privacy-awareness.pdf\n\nCould I get more details about the implementation of your paw3? Such as the\ndetails of the SOAP \nservices for handling P3P policies and APPEL at both user and data\ncollector?\n\nFurther, is it possible for me to have a copy of your paper:\n\nMarc Langheinrich. Privacy by design - principles of privacy-aware\nubiquitous systems. In\nProceedings of Ubicomp, pages 273-291. Springer LNCS, September 2001.\n\nThanks a lot,\n\nPatrick.\n--------------------------------------\nPatrick C. K. Hung\nResearch Scientist\nCommonwealth Scientific & Industrial Research Organisation (CSIRO)\nCSIRO Mathematical and Information Sciences (CMIS)\nGPO Box 664, Canberra, ACT 2601, Australia\nPh: +612 6216 7031, Fax: +612 6216 7111\nEmail: Patrick.Hung@csiro.au\nURL: www.cmis.csiro.au/Patrick.Hung\n\n\n\n", "id": "lists-017-2664910"}, {"subject": "Re: BH: About Marc Langhernrich's paper on ubiquitous computing envir onments + P3", "content": "On Sun, 20 Apr 2003, Patrick.Hung@csiro.au wrote:\n> Could I get more details about the implementation of your paw3? Such as\n> the details of the SOAP services for handling P3P policies and APPEL at\n> both user and data collector?\npatrick, thanks for your interest! i'm travelling until end of april so i\nwould send out some details by then if that's ok...\n\n> Further, is it possible for me to have a copy of your paper:\n> \n> Marc Langheinrich. Privacy by design - principles of privacy-aware\n> ubiquitous systems. In\n> Proceedings of Ubicomp, pages 273-291. Springer LNCS, September 2001.\nhmm, this should be available as pdf somewhere off my homepage, or -\nalternatively - off our group's publication list at\nwww.inf.ethz.ch/vs/publ/  (let me know if it isn't or if the link's screwed\nup and i'll fix things right away...)\n\ncheers,\n\n-m\n-- \nMarc Langheinrich <langhein@inf.ethz.ch> Institute for Pervasive Computing\nDept. of Computer Science, ETH Zurich, IFW D48.2, 8092 Zurich, Switzerland\nfon: +41-1-632-0688, fax: +41-1-632-1659,  web: www.inf.ethz.ch/~langhein/\n\n\n\n", "id": "lists-017-2673980"}, {"subject": "RE: BH: About Marc Langhernrich's paper on ubiquitous computing e nvironments + P3", "content": "Thanks a lot, Marc.\n\nI have downloaded your paper from your group publication list.\n\nPatrick.\n\n-----Original Message-----\nFrom: Marc Langheinrich [mailto:langhein@inf.ethz.ch]\nSent: Monday, 21 April 2003 1:27 AM\nTo: Patrick.Hung@csiro.au\nCc: public-p3p-spec@w3.org\nSubject: Re: BH: About Marc Langhernrich's paper on ubiquitous computing\nenvir onments + P3P\n\n\nOn Sun, 20 Apr 2003, Patrick.Hung@csiro.au wrote:\n> Could I get more details about the implementation of your paw3? Such as\n> the details of the SOAP services for handling P3P policies and APPEL at\n> both user and data collector?\npatrick, thanks for your interest! i'm travelling until end of april so i\nwould send out some details by then if that's ok...\n\n> Further, is it possible for me to have a copy of your paper:\n> \n> Marc Langheinrich. Privacy by design - principles of privacy-aware\n> ubiquitous systems. In\n> Proceedings of Ubicomp, pages 273-291. Springer LNCS, September 2001.\nhmm, this should be available as pdf somewhere off my homepage, or -\nalternatively - off our group's publication list at\nwww.inf.ethz.ch/vs/publ/  (let me know if it isn't or if the link's screwed\nup and i'll fix things right away...)\n\ncheers,\n\n-m\n-- \nMarc Langheinrich <langhein@inf.ethz.ch> Institute for Pervasive Computing\nDept. of Computer Science, ETH Zurich, IFW D48.2, 8092 Zurich, Switzerland\nfon: +41-1-632-0688, fax: +41-1-632-1659,  web: www.inf.ethz.ch/~langhein/\n\n\n\n", "id": "lists-017-2684012"}, {"subject": "UA: notes from April 21 task force teleconferenc", "content": "As previously announced [1] we had our UA TF call this afternoon. \nBrooks and I were the only ones on the call despite several others \ntelling me they would be there.\n\nWe focussed our discussion on the document I sent out with observations \non the the three translations [2]. Brooks and I were mostly in \nagreement on the high level observations. We didn't go over the \ndetailed observations. It would be useful for everyone in this TF to \nsend in their own observations and raise any points of disagreement \nwith my observations.\n\nWe discussed the list of questions I posed for the TF to consider (at \nthe end of [2]). To this list Brooks suggested we also consider \nguidelines about the display of policy summaries for the site vs. its \ncookies, as well as guidelines for displaying information about cookies \non a basis other than URL (for example, if a site has multiple cookies \nassociated with a given URI that have different policies associated \nwith them -- currently IE6 does not provide a way to distinguish these \npolicies).\n\nWe spent some time discussing the first question on my list. Both of us \nwould prefer to converge on a single set of translations, but we're not \nsure whether this will be possible.\n\nI would like to get people focussed on this TF ASAP so we can try to \nmove forward, so let me assign some action items to all UA TF members. \nPlease try to complete these items and send email to the  mailing list \nby the end of this week.\n\nACTION ITEM 1: Please review the translation documents and my \nobservations about them [2]. Please send to the mailing list any \ndisagreements you have with my observations and any additional \nobservations you have that I didn't cover.\n\nACTION ITEM 2: Please begin discussing the first question in my list of \nquestions for the TF to consider:\n\n    Should we try to converge on a single set of translations? Should\n    we come up with a long and short translation for each element,\n    perhaps using the click through approach like NS uses? Should our\n    guidelines list all acceptable translations they people submit\n    rather than trying to converge or one or two?\n\n\n\n[1] \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Apr/0020.html\n[2] \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Apr/0018.html\n[3] http://www.w3.org/P3P/1.1/documents.html#ua\n\n\n\n", "id": "lists-017-2694900"}, {"subject": "UA: single set of translations or multiple translations", "content": "In \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Apr/0018.html I \nposed the question:\n\n    Should we try to converge on a single set of translations? Should\n    we come up with a long and short translation for each element,\n    perhaps using the click through approach like NS uses? Should our\n    guidelines list all acceptable translations they people submit\n    rather than trying to converge or one or two?\n\nFor most of the elements in the three translations, there are three \nversions of the translation that I find acceptable, but there is one \nthat I find preferable. In most (but not all) cases I find the other \ntwo to be accurate, but less clear or more verbose. I would prefer to \nconverge on a single translation because it would promote more \nconsistency and make it easier for web sites to understand how users \nare going to see their policies. However, if we find it difficult to \nagree on a single translation I would rather have a set of acceptable \ntranslations than no guidelines at all. So my inclination would be to \nattempt to agree on a single set of translations but re-evaluate this \napproach if it ends up being problematic in practice.\n\nLorrie\n\n\n\n", "id": "lists-017-2704533"}, {"subject": "Re: Ref: the Beyond HTTP (BH) Task Forc", "content": "Thank you for the comments Patrick.\n\nOn Saturday 19 April 2003 06:08, Patrick.Hung@csiro.au wrote:\n> In fact, I have been thinking whether it is feasible and appropriate to\n> implement/apply P3P\n> into WS-Policy for the project. Anyway, the first job for me is to\n> \"modify/change/re-create\"\n> the PURPOSE elements (Section 3.3.4 from The P3P1.0 Specification) for\n> this project. Thus,\n> I have to define the <purposes/> of collecting/processing the health data\n> as some specific\n> purposes in the context of health data and epidemiological statistics,\n> such as \"<vital-statistics/>,\"\n> \"<morbidity-statistics/>,\" and etc. Anyway, I am still studying on it.\n\nI'll note this as more evidence that p3p:PURPOSE is likely to be a part of \nthe vocabularly most likely to change. However, I'm thinking it will be \nuseful to distinguish the meta \"purpose\" of \"current\" and \"other\" from the \nother terms. I expect you'd want to user both of those terms independent of \nthe others...?\n\n> > I haven't made an attempt at it yet -- has anyone else? -- but I hope\n> > to soon. However, even without doing so, I ask myself if:\n> > 1. Does the privacy statement belong at the SOAP level, or HTTP? In the\n> > majority of cases SOAP will be transported over HTTP, what happens if\n> > both\n> >\n> > of a HTTP statement?\n>\n> As HTTP is a carrier for SOAP messages, I don't really get what you mean\n> here. Do you mean\n> that what happens if both \"Web service requestor\" and \"Web service\n> provider\" using HTTP and\n> no SOAP message?\n\nNo, what happens if the HTTP header has a P3P statement, and the SOAP \nmessage has one too, and they don't agree, or they do in parts but not in \nothers?\n\n> By \"my understanding,\" it should not be possible for a Web service\n> requestor (i.e., Web service) to set\n\nThis is an interesting point, if the web service client isn't a web browser, \nit might not support cookies anyway. However, I don't think we can presume \nthis just yet. Might be worth a few setences on the point.\n\n> > 2. Does the privacy statement belong at the WSDL level? Not every\n> > service must have a service description. And if they did for the\n> > purposes of privacy then *have* to fetch the WSDL before proceeding\n> > with the interaction? My sense here is that SOAP would trump the\n> > OPTIONAL WSDL definition.\n>\n> Referring to the first question, do we need separate P3P (privacy)\n> policies for each operation\n> (web method) in a Web service? Then, for the second question, it may be\n> closely related to\n> the matchmaking process between Web service requestors and providers. \n\nOh, good point. I'll add this as an issue to the outline I'm working on.\n\n\n\n", "id": "lists-017-2712450"}, {"subject": "Re: BH: About Marc Langhernrich's paper on ubiquitous computing envir onments + P3", "content": "Marc, \n\nNaming the URI here would have helped right away and would have been\nbetter for the archive\n\nBest, \n\nRigo\n\nOn Sun, Apr 20, 2003 at 05:27:29PM +0200, Marc Langheinrich wrote:\n> > Marc Langheinrich. Privacy by design - principles of privacy-aware\n> > ubiquitous systems. In\n> > Proceedings of Ubicomp, pages 273-291. Springer LNCS, September 2001.\n> hmm, this should be available as pdf somewhere off my homepage, or -\n> alternatively - off our group's publication list at\n> www.inf.ethz.ch/vs/publ/  (let me know if it isn't or if the link's screwed\n> up and i'll fix things right away...)\n\n\n\n", "id": "lists-017-2723048"}, {"subject": "RE: BH: About Marc Langhernrich's paper on ubiquitous computing e nvir onments + P3", "content": "I downloaded his paper from\nhttp://www.inf.ethz.ch/vs/publ/papers/privacy-principles.pdf\n\nPatrick.\n\n-----Original Message-----\nFrom: Rigo Wenning [mailto:rigo@w3.org]\nSent: Wednesday, 23 April 2003 4:51 PM\nTo: public-p3p-spec@w3.org\nSubject: Re: BH: About Marc Langhernrich's paper on ubiquitous computing\nenvir onments + P3P\n\n\n\nMarc, \n\nNaming the URI here would have helped right away and would have been\nbetter for the archive\n\nBest, \n\nRigo\n\nOn Sun, Apr 20, 2003 at 05:27:29PM +0200, Marc Langheinrich wrote:\n> > Marc Langheinrich. Privacy by design - principles of privacy-aware\n> > ubiquitous systems. In\n> > Proceedings of Ubicomp, pages 273-291. Springer LNCS, September 2001.\n> hmm, this should be available as pdf somewhere off my homepage, or -\n> alternatively - off our group's publication list at\n> www.inf.ethz.ch/vs/publ/  (let me know if it isn't or if the link's\nscrewed\n> up and i'll fix things right away...)\n\n\n\n", "id": "lists-017-2730827"}, {"subject": "P3P Data Schema as XML Schem", "content": "Hi,\nHere are notes and files I promised on XML Schema for BSD. Rigo, perhaps you\ncould post the files on a server somewhere as promised. The XSLT works with\nmsxml but can easily be adapted for others (see notes below).\n\nNote that this is an investigation of how to express the existing schema as\nXSD, not an investigation of alternatives.\nI do think that we should eventually make a switch to a more interoperable\nand efficient format but I don't think this would be a good idea at present.\n\nbsd.xsd is the (formatted) result of a transformation on the P3P1.0 BSD\nbsdtransform.xml is the xml of the p3p1.0 BSD\nbsdtransform.xsl is the xslt\nbsdtransform.html is the client side code for executing the transform and\noutputting as HTML.\n\nThe notes below are also attached as a word document.\n\n----------------------------------\nP3P Base Data Schema as XML Schema\n----------------------------------\n\n\nGiles Hogben JRC\n\n----\nAims\n----\n\nThe aims of this first pass solution were\n1. To allow a simple 1 to 1 transformation between policies expressed in the\nold format and policies which conform to the XML schema.\n2. To allow a simple 1 to 1 transformation between any custom built data\nschemas and the new format. For this purpose I have provided an xslt.\n\nAlthough I have provided an XML version of the transformed schema, it is\nnecessarily complex and this document explains how it is structured.\n\nThese aims led to the following\n\n------------------------------------------------\nRequirements for the base data schema XML schema:\n------------------------------------------------\n\n1. The schema must express classes of data and their allowed relationships\nin terms of sub and superclasses.\n\nIn the old format this led to expressions like\n<data ref=\"user.home-info\">\nWhich I take to mean - the information the statement is about is an instance\nin the class home-info, in the class user.\nOR\n<data ref=\"user.home-info.online.uri\">\nWhich I take to mean - the information the statement is about is an instance\nin the class uri, in the class online etc?.\n\n2. These classes (called structures in the old format) are reused at\ndifferent levels of the hierarchy and therefore must be declared by\nreference within the schema hierarchy.\n\nFor example the class denoted by the structure \"contact\" may be used by both\nbusiness-info and home-info.\n\n3. The XML language can assume a semantic such that nested elements imply\nsubclassing.\n\nAlthough there is no formally defined semantics for P3P, by inspecting the\nuse of elements such as purpose, one can gather that use of a sub-element in\nP3P may be equated to the semantic \"is a subclass of?\"\n\nFor example:\n<purpose>\n<current/>\n</purpose>\n\nMeans something like:\n\n\"The data this statement is about has purpose of type (subclass of purpose)\ncurrent \"\n\n4. An overall set of \"categories\" is assumed within any DS from which are\nderived subsets of categories for any class. These categories do not have\nthe same semantic as classes. They superclass any classes used but only a\ncertain subset of all the categories may superclass a given class. This\nsuperclassing is inherited within the DS but it follows a reverse\ninheritance rule because superclasses of the standard classes inherit the\ncategories of their subclasses. For this reason it has to be declared at\neach level and cannot use standard inheritance syntax using the XML tree.\nFor example in the BSD,\n\n<data ref=\"user.home-info\">\n\nMay be given the additional semantic of \"this data type is in the online\ncategory\"\n\n<data ref=\"user.home-info\"><CATEGORIES><online/></CATEGORIES></data>\n\n\nThese requirements are satisfied by the following\n\n----------------------\nInformal specification\n----------------------\n\nThis informal specification is formally specified in the attached XML\nSchema.\n\nData types are expressed as subclasses of a root \"Datatype\" element. The\nsubclass semantic is expressed by making an element a child of another\nelement.\n\nFor example\n\n<Datatype>\n<user>\n<home-info>\n<online/>\n</home-info>\n</user>\n</Datatype>\n\n\nCategories are defined by a <category name=\"xxxx\"> element, which  may\nappear ONLY AS LEAVES. This mimics the previous syntax where the classes\nwere specified up to a certain granularity which was then given a category.\nFor example:\n\nP3P1.0:\n-------\n\n<data\nref=\"user.home-info\"><CATEGORIES><online/><demographic>/</CATEGORIES></data>\n\nP3P 1.1. XML Schema Compliant\n-----------------------------\n\n<Datatype>\n<user>\n<home-info>\n<category name=\"online\"/>\n<category name=\"demographic\"/>\n</home-info>\n</user>\n</Datatype>\n\n\n\nP3P 1.0\n-------\n\n<data\nref=\"user.home-info.online.email\"><CATEGORIES><online/></CATEGORIES></data>\n\nP3P 1.1. XML Schema Compliant\n\n<Datatype>\n<user>\n<home-info>\n<online>\n<email>\n<category name=\"online\"/>\n<email/>\n</online>\n</home-info>\n</user>\n</Datatype>\n\n\nNotice that the names of the \"structures\" are not specified in the XSD as a\nformal naming of a group of subelements is no longer necessary. An informal\ndescription of the structure of the BSD should however be given within the\nspecification document, allowing users to know how to use the classes\nwithout reading the XSD (Maybe it's even possible to write an XSLT for the\nspecification document J ).\n\n--------------------------\nNotes for Transform files:\n--------------------------\n\n1. The XSLT is general and will transform any data schema, which is\nsyntactically correct according to P3P 1.0.\n\n2. The files provided are everything you need to transform a data schema\nusing client side transformation in MS IE.\n\nbsdtransform.xml is the xml of the p3p1.0 BSD\nbsdtransform.xsl is the xslt\nbsdtransform.html is the client side code for executing the transform and\noutputting as HTML.\nbsd.xsd is the (formatted) result of a transformation on the P3P1.0 BSD\n\n4. You can use the stylesheet with other xsl processors but you need to\nchange the node-set extension. To transform a different DS, just change the\nxml input document in bsdtransform.html\n\n5. The mechanism of the transform of the old BSD to XSD is extremely complex\nbut is explained in the comments of the XSLT. The transform uses a multipass\ntransform which uses the node-set xslt extension so it is specific to msxml.\nIt can be used with SAXON with a very minor change which is written in the\nxslt.\n\n\n----------------------------------\nExplanation of Schema Syntax Used:\n----------------------------------\n\nThe schema is contained in bsd.xsd.\n\nThe schema starts with a definition of all the categories from which the\nallowed categories are derived.\n\nStarting with a definition of the root <datatype> element, it then uses the\n<choice> element to specify the subelements of this recursively. For each\nsubelement, there is then a further <choice> which specifies the use of\ncategories. It says that <category> elements used must be a leaf by saying\nmaking their usage mutually exclusive wrt any subelements (using\n<xs:choice>).\n\n\n\n\n\n\ntext/xml attachment: bsd.xml\n\napplication/octet-stream attachment: bsd.xsd\n\ntext/html attachment: bsdtransform.html\n\ntext/xml attachment: bsdtransform.xsl\n\napplication/msword attachment: p3p_base_data_schema_as_XML_schema.doc\n\napplication/msword attachment: p3p_base_data_schema_as_XML_schema.doc\n\n\n\n\n", "id": "lists-017-2740144"}, {"subject": "Ref: the Beyond HTTP (BH) Task Forc", "content": "Thanks for your message, Joseph. Here are my comments.\n\n\"I'll note this as more evidence that p3p:PURPOSE is likely to be a part of \nthe vocabularly most likely to change. However, I'm thinking it will be \nuseful to distinguish the meta \"purpose\" of \"current\" and \"other\" from the \nother terms. I expect you'd want to user both of those terms independent of \nthe others...?\"\n\nYes, I do. In such a loosely coupled Web services execution environment, I \nam thinking whether we should have a general dictationary for p3p:PURPOSE \n(e.g., \"current\" and \"other\") and also some application-specific\ndictationaries \n(e.g., financial applications) for p3p:PURPOSE in different scenarios?\n\n\"I haven't made an attempt at it yet -- has anyone else? -- but I hope\nto soon. However, even without doing so, I ask myself if:\n1. Does the privacy statement belong at the SOAP level, or HTTP? In the\nmajority of cases SOAP will be transported over HTTP, what happens if\nboth of a HTTP statement?\"\n\nI would expect that we may have to have P3P statements at both the HTTP (if\napplicable) and SOAP level. At the HTTP level, the P3P statements should\nwork and behave the same as described in the original P3P Specification for \nthe Web sites. At the SOAP level, the P3P statements should be on both\ngeneral and application-oriented semantics (it may be hard). What do you\nthink?\n\n\"This is an interesting point, if the web service client isn't a web\nbrowser, \nit might not support cookies anyway. However, I don't think we can presume \nthis just yet. Might be worth a few setences on the point.\"\n\nFor your information, you can even send a SOAP message by a plain text\ne-mail message as long as the Web service can interpret e-mail message\nlike those mailing list server (e.g., subscribe).\n\n\"> > 2. Does the privacy statement belong at the WSDL level? Not every\n> > service must have a service description. And if they did for the\n> > purposes of privacy then *have* to fetch the WSDL before proceeding\n> > with the interaction? My sense here is that SOAP would trump the\n> > OPTIONAL WSDL definition.\n>\n> Referring to the first question, do we need separate P3P (privacy)\n> policies for each operation\n> (web method) in a Web service? Then, for the second question, it may be\n> closely related to\n> the matchmaking process between Web service requestors and providers. \n\nOh, good point. I'll add this as an issue to the outline I'm working on.\"\n\nAs WS-Policy is mainly for specifying the security requirements, I guess\nthat there may have a flag to identify the privacy requirement in WS-Policy\nsuch as \"require\" or \"not require.\" Then if the \"require\" flag is set to\ntrue, \nWeb services must retrieve their WS-Privacy document (like P3P Policy) for \nvalidation by using APPEL? OR something like that.\n\nDo we have a meeting call on April 30?\n\n\n\n", "id": "lists-017-2756918"}, {"subject": "Re: Ref: the Beyond HTTP (BH) Task Forc", "content": "On Wednesday 23 April 2003 12:17, Patrick.Hung@csiro.au wrote:\n> Thanks for your message, Joseph. Here are my comments.\n\nBTW: without the \">\" I have a hard time distinguishing your comments from \nyour context..\n\n> I would expect that we may have to have P3P statements at both the HTTP\n> (if applicable) and SOAP level. At the HTTP level, the P3P statements\n> should work and behave the same as described in the original P3P\n> Specification for the Web sites. At the SOAP level, the P3P statements\n> should be on both general and application-oriented semantics (it may be\n> hard). What do you think?\n\nMy inclination is that an application will specify which bindings its SOAP \nis supported with. *If* this is the case, then I would RECOMMEND that it \ndefine the SOAP statement as being inclusive of the SOAP interaction and \nthe binding.\n\n> For your information, you can even send a SOAP message by a plain text\n> e-mail message as long as the Web service can interpret e-mail message\n> like those mailing list server (e.g., subscribe).\n\nYep, though I expect HTTP will be very common. (In fact, it was recently \nreported that of Amazon's SOAP and REST (HTTP) interfaces, 85% of their \nusage is of the REST interface.)\n\n> Do we have a meeting call on April 30?\n\nThat's what the page says:\n  http://www.w3.org/P3P/Group/Specification/\n  Wednesday 30 April 2003 11am-12pm US Eastern/16:00-17:00 UTC \n  Dial-in number: Zakim Bridge +1.617.761.6200 Code: 73794 (\"P3PWG\")\n\n\n\n", "id": "lists-017-2767646"}, {"subject": "RE: Ref: the Beyond HTTP (BH) Task Forc", "content": "Thanks for your message, Joseph.\n\n>My inclination is that an application will specify which bindings its SOAP \n>is supported with. *If* this is the case, then I would RECOMMEND that it \n>define the SOAP statement as being inclusive of the SOAP interaction and \n>the binding.\n\nLet's talk about an application and a Web service. An application is trying\nto call an operation (e.g., Webmethod in .Net Web Sevices) in a Web service.\nThus, the Web service have toy the SOAP bindings for its oerations.\n\n>Yep, though I expect HTTP will be very common. (In fact, it was recently \n>reported that of Amazon's SOAP and REST (HTTP) interfaces, 85% of their \n>usage is of the REST interface.)\n\n\n> That's what the page says:\n>  http://www.w3.org/P3P/Group/Specification/\n>  Wednesday 30 April 2003 11am-12pm US Eastern/16:00-17:00 UTC \n>  Dial-in number: Zakim Bridge +1.617.761.6200 Code: 73794 (\"P3PWG\")\n\nI will be there.\n\n\n\n", "id": "lists-017-2776650"}, {"subject": "RE: Ref: the Beyond HTTP (BH) Task Forc", "content": "** Sorry for the previous \"fault\" e-mail.\n\nThanks for your message, Joseph.\n\n>My inclination is that an application will specify which bindings its SOAP \n>is supported with. *If* this is the case, then I would RECOMMEND that it \n>define the SOAP statement as being inclusive of the SOAP interaction and \n>the binding.\n\nLet's talk about an application and a Web service. An application is trying\nto call an operation (e.g., Webmethod in .Net Web Sevices) in a Web service.\nThus, the Web service have to specify the SOAP bindings for its operations.\nThe application has to follow those SOAP bindings in order to call a\nparticular\noperation in the Web service. Now, our question is *if* both application and\nWeb service have their own privacy policies. Let's call them as WS-Policies.\nI\nstill try to guess what is WS-Policy :-). What should be the scenario in\nthis\nsituation? When do they exchange/match their WS-Policies before an\ninteraction\nis taken?\n\n>Yep, though I expect HTTP will be very common. (In fact, it was recently \n>reported that of Amazon's SOAP and REST (HTTP) interfaces, 85% of their \n>usage is of the REST interface.)\n\nYes, I agree with you.\n\n> That's what the page says:\n>  http://www.w3.org/P3P/Group/Specification/\n>  Wednesday 30 April 2003 11am-12pm US Eastern/16:00-17:00 UTC \n>  Dial-in number: Zakim Bridge +1.617.761.6200 Code: 73794 (\"P3PWG\")\n\nI will be there.\n\n\n\n", "id": "lists-017-2785263"}, {"subject": "More Correction: the Beyond HTTP (BH) Task Forc", "content": ">My inclination is that an application will specify which bindings its SOAP \n>is supported with. *If* this is the case, then I would RECOMMEND that it \n>define the SOAP statement as being inclusive of the SOAP interaction and \n>the binding.\n\nLet's talk about an application and a Web service. An application is trying\nto call an operation (e.g., Webmethod in .Net Web Sevices) in a Web service.\nThus, the Web service have to specify the SOAP bindings for its operations.\nThe application has to follow those SOAP bindings in order to call a\nparticular operation in the Web service. Now, our question is *if* both \napplication and Web service have their own privacy policies. Let's call them\n\nas *** WS-Privacy ***. I still try to guess what is *** WS-Privacy *** :-). \nWhat should be the scenario in this situation? When do they exchange/match \ntheir *** WS-Privacy *** before an interaction is taken?\n\nWhat should be described in these *** WS-Privacy ***?\n\n\n\n", "id": "lists-017-2794095"}, {"subject": "P3P Agent/Domain TF Conference Call: 4/25 9AM ED", "content": "The first conference call of the Agent/Domain Relationship task force will\nbe tomorrow, Friday 4/25, from 9:00 AM - 10:00 AM EDT. \n\nThe primary agenda item will be to discuss the goals of this task force and\nestablish an initial task list.\n\nIf you're not part of the task force but would like to join the call, please\ncontact me. Minutes from the meeting will be posted here.\n\nJack Humphrey\nDevelopment Manager, Data Acquisition\nCoremetrics\n\n\n\n", "id": "lists-017-2802131"}, {"subject": "Re: P3P Data Schema as XML Schem", "content": "On Wednesday 23 April 2003 09:00, Giles Hogben wrote:\n> Here are notes and files I promised on XML Schema for BSD. Rigo, perhaps\n> you could post the files on a server somewhere as promised. The XSLT\n> works with msxml but can easily be adapted for others (see notes below).\n\nHi Giles, good stuff! Some comments below:\n\n> bsd.xsd is the (formatted) result of a transformation on the P3P1.0 BSD\n\nI presume I should be able to run this against a P3P instance? But one of \nthe annoyances of Schema is not being able to clearly distinguish the root \nelement, and in this case I don't think there is any? So which subset of a \nP3P XML instance is this schema file supposed to validate against? (Not \nagainst the root POLICIES ... ENTITY? DATA-GROUP?)\n\nWhy is there a seven after the schema element?\n  <schema targetNamespace=\"http://www.w3.org/2002/01/P3Pv1\">7\n\n> bsdtransform.xsl is the xslt\n\n\n> This informal specification is formally specified\n\n<smile/>\n\n> 4. You can use the stylesheet with other xsl processors but you need to\n> change the node-set extension. \n\nThat's on line 44 now, the documentation says 42.\n\nMight include the following URI so folks can read about it:\n  http://saxon.sourceforge.net/saxon6.5.2/extensions.html#nodeset\n\n\"xx\" is an unbound prefix. Why not include:\n  xmlns:xx=\"http://exslt.org/common\"\nin your xslt. Even if it's not used, it won't hurt anything would it?\n(Found that namespace in:\n  http://www.exslt.org/exsl/index.html\n)\n\nI haven't been able to confirm the transform yet. I'm not a big fan of java \n-- never got saxon to run -- I don't think sablotron \nsupports that function and xsltproc gives me odd results:\n\n> xsltproc bsdtransforms.xsl bsd.xml\n<?xml version=\"1.0\"?>\n<schema xmlns:xx=\"http://exslt.org/common\" \ntargetNamespace=\"http://www.w3.org/2002/01/P3Pv1\">7<simpleType \nname=\"allCategories\"><restriction base=\"xs:string\">\n                                                @br/~<enumeration \nvalue=\"uniqueid\">\n                                                @br/~</enumeration>\n                                                @br/~<enumeration \nvalue=\"demographic\">\n                                                @br/~</enumeration>\n                                                @br/~<enumeration \nvalue=\"physical\">\n                                                @br/~</enumeration>\n                                                @br/~<enumeration \nvalue=\"online\">\n                                                @br/~</enumeration>\n                                                @br/~<enumeration \nvalue=\"computer\">\n                                                @br/~</enumeration>\n                                                @br/~<enumeration \nvalue=\"navigation\">\n                                                @br/~</enumeration>\n                                                @br/~<enumeration \nvalue=\"interactive\">\n                                                \n@br/~</enumeration></restriction></simpleType></schema>\n\n\n\n", "id": "lists-017-2809713"}, {"subject": "P3P Agent/Domain TF Conference Cal", "content": "Dear all, \n\nplease find the information on this call on the member-readable group\npage: http://www.w3.org/P3P/Group/Specification/\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n----- Begin forwarde message -----\nWe will have our first conference call tomorrow, Friday 4/25, from 9:00 AM -\n10:00 AM EDT. This was the time that worked for most of us. Let me know if\nyou won't be able to join.\n\nThe primary agenda item will be to discuss the goals of this task force and\nestablish an initial task list.\n\nLooking forward to getting the ball rolling.\n\nJack Humphrey\nDevelopment Manager, Data Acquisition\nCoremetrics\n\n----- End forwarded message -----\n\n\n\n", "id": "lists-017-2820466"}, {"subject": "[BH] First (Very Rought) Outline of Beyond HTT", "content": "As stated, I've tried to put together an outline [1] that hopefully gives a \nsense of the goals, the scenario, and the \"chunks\" that we'll want to \naddress.\n\n[1] http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n\nI welcome comments on *anything* including any of the above, or volunteers \nto take a stab at:\n1) Feel like writing up an instance of linking a P3P policy with an XFORM \n(xlink?), SOAP message or WSDL definition?\n2) Writing text for one of the chunks?\n\nFor any examples or schemas that we use, I'd like to accept those as \ndiscrete self-validating files [1]. I've previously written a python script \nthat when given a XML PI (processing instruction) can then take an excerpt \nfrom a remote XML file and include it in the spec. That way we don't have \nto maintain examples in the spec and as seperate files, with errors \ncreaping into each, but particularly those in the spec.\n\n[2] http://lists.w3.org/Archives/Public/spec-prod/2003JanMar/0007.html\n\n\n\n", "id": "lists-017-2827732"}, {"subject": "P3P spec working group call April 3", "content": "The next P3P specification group conference call will be on\nWednesday, April 30, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Update on P3P 1.1 chartering (Rigo)\n\n2. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relaitonships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n3. Review current bugzilla list (141, 144, 167, 168, 169, 170, 171,\n    172, 173, 174, 178)\n    - Please register for bugzilla -- You can use the interface at\n    http://www.w3.org/Bugs/Public/query.cgi to get a list of all P3P\n    open issues\n\n4. Set date of next conference call (May 7 or 21 - several of us will\n    be at FTC meeting May 14)\n\n\n\n", "id": "lists-017-2835153"}, {"subject": "RE: P3P Data Schema as XML Schem", "content": "Here are some more files on this issue\nI have corrected some small errors in the schema transform (e.g. it was\noutputting category element and attribute element definitions with global\nscope where it shouldn't have been).\nI have also included a 2 stage transform which avoids using extensions (you\ndo transform 1 and then transform2 on the results of transform1 to eliminate\nduplicates) and, for the benefit of other members of list the files for the\npolicy transform I sent earlier.\n\nApologies for confusing the acronyms BDS and BSD... BDS means the base data\nschema and BSD is an OS...\n\nFor those who don't want to get bogged down in nasty amounts of complexity,\njust look at the file bdsfinal.xsd which is the final result schema, or try\nthe policy transformer on a policy (e.g. the one included). Hope the\ndirectory and file names are relatively self explanatory\n\nRegards\n\nGiles\n\n\n\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: 28 April 2003 20:08\nTo: Giles Hogben\nSubject: Re: P3P Data Schema as XML Schema\n\n\nOn Saturday 26 April 2003 09:06, you wrote:\n> Yeah - sorry - it was the quickest and easiest way to get it to work\n> at the time - will try to send a self executing .jar file at some\n> point - maybe that'll help.\n\nI'm still not following, keep in mind I know nothing about MS IE and very\nlittle about Java (I'm more of a XML and Python person) <smile/>. I was\nexpecting to do something like:\n  xsltproc bsdtransform.xsl p3p1_0.xml > converted_p3p_1_0.xsd\nthen I can check a P3P instance against that schema:\n  xsv p3p.xml converted_p3p_1_0.xsd\n\nWhat is \"BSD\" btw?\n\n\n\n\napplication/x-zip-compressed attachment: P3PBDSXMLSchema.zip\n\napplication/x-zip-compressed attachment: P3PBDSTransform.zip\n\n\n\n\n", "id": "lists-017-2843287"}, {"subject": "RE: P3P Data Schema as XML Schem", "content": "P3Pers, apologies for having missed the call today, XQuery is swamping me these days.\nAnyway, some quick words on the \"P3P data schema in XML Schema\".\nThis issue had already been tackled quite some time ago in the P3P spec group (you might have wondered if somebody hadn't thought\nabout it before... right? ;)\nIn fact, this has at a time been discussed as an alternate proposal, and finally rejected.\nI'll state the reasons and some comments here, because these still apply (which means, reopening this issue in P3P1.1 should then\nagain mean challenge again the \"con\" of the solution).\n\nFirst big motivation: who needs it? What are the real advantages? Implementers, at the time, let us know they didn't like the\n\"xml-schema way\" (let's call it this way), because\na) it makes parsing heavier\nb) it makes simple data declaration too verbose (as you have to duplicate each subpart of a data element in begin and end tags)\n\nThis was the main objection at the time. Now, we are no more in the designing phase (1.0), so tackling this issue again in 1.1 has\nto face the new, crucial, additional problem:\nc) what are the costs of adding an alternate format to the spec?\n\nThere was also other considerations that led not to consider that design, that I'll recap here too:\nd) splitting data elements (etc) in separate tags, apparently leads to the loss of the \"reference with a URI\" property: you'd still\nneed to recombine the info in a single-line canonicalization to get this property back (so, essentially going back to the status\nquo).\ne) makes DTD support more difficult\n\nOk, enough with historical motivations for today ;)\nSo all in all, the above considerations just apply if this proposal is going to end in 1.1 (i.e., it's reopening the issue).\nIf it's instead a translation-only thing (like the RDFization note of P3P), likely to end as a Note or so, then of course all the\nabove is moot ;)\n-M\n\n\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org\n> [mailto:public-p3p-spec-request@w3.org]On Behalf Of Giles Hogben\n> Sent: Tuesday, April 29, 2003 6:28 PM\n> To: Joseph Reagle\n> Cc: public-p3p-spec@w3.org; Rigo Wenning; Jeremy Epling\n> Subject: RE: P3P Data Schema as XML Schema\n>\n>\n> Here are some more files on this issue\n> I have corrected some small errors in the schema transform (e.g. it was\n> outputting category element and attribute element definitions with global\n> scope where it shouldn't have been).\n> I have also included a 2 stage transform which avoids using extensions (you\n> do transform 1 and then transform2 on the results of transform1 to eliminate\n> duplicates) and, for the benefit of other members of list the files for the\n> policy transform I sent earlier.\n>\n> Apologies for confusing the acronyms BDS and BSD... BDS means the base data\n> schema and BSD is an OS...\n>\n> For those who don't want to get bogged down in nasty amounts of complexity,\n> just look at the file bdsfinal.xsd which is the final result schema, or try\n> the policy transformer on a policy (e.g. the one included). Hope the\n> directory and file names are relatively self explanatory\n>\n> Regards\n>\n> Giles\n>\n>\n>\n>\n> -----Original Message-----\n> From: Joseph Reagle [mailto:reagle@w3.org]\n> Sent: 28 April 2003 20:08\n> To: Giles Hogben\n> Subject: Re: P3P Data Schema as XML Schema\n>\n>\n> On Saturday 26 April 2003 09:06, you wrote:\n> > Yeah - sorry - it was the quickest and easiest way to get it to work\n> > at the time - will try to send a self executing .jar file at some\n> > point - maybe that'll help.\n>\n> I'm still not following, keep in mind I know nothing about MS IE and very\n> little about Java (I'm more of a XML and Python person) <smile/>. I was\n> expecting to do something like:\n>   xsltproc bsdtransform.xsl p3p1_0.xml > converted_p3p_1_0.xsd\n> then I can check a P3P instance against that schema:\n>   xsv p3p.xml converted_p3p_1_0.xsd\n>\n> What is \"BSD\" btw?\n>\n\n\n\n", "id": "lists-017-2853791"}, {"subject": "Regrets (RE: P3P spec working group call April 30", "content": "Contrarily to my hurried last post, I didn't (yet) miss the P3P call... ;)\nAnyway, regrets, tomorrow, same time, I have to be at the XQuery editors call. Sorry!\n-M\n\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org\n> [mailto:public-p3p-spec-request@w3.org]On Behalf Of Lorrie Cranor\n> Sent: Monday, April 28, 2003 8:44 PM\n> To: public-p3p-spec@w3.org\n> Subject: P3P spec working group call April 30\n> \n> \n> \n> The next P3P specification group conference call will be on\n> Wednesday, April 30, 2003, 11 am - 12 pm US Eastern. Dial-in\n> information is available at\n> http://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n> \n> AGENDA\n> \n> 1. Update on P3P 1.1 chartering (Rigo)\n> \n> 2. Task force reports\n>     - P3P beyond HTTP - Joseph Reagle\n>     - User agent behavior - Lorrie Cranor\n>     - Compact policies - Brian Zwit\n>     - Article 10 vocabulary issues - Giles Hogben\n>     - Agent and domain relaitonships - Jack Humphrey\n>     - Consent choices - Matthias Schunter\n>     - Converting P3P data schema to XML schema - Giles Hogben\n>     - Signed P3P policies  - Giles Hogben\n> \n> 3. Review current bugzilla list (141, 144, 167, 168, 169, 170, 171,\n>     172, 173, 174, 178)\n>     - Please register for bugzilla -- You can use the interface at\n>     http://www.w3.org/Bugs/Public/query.cgi to get a list of all P3P\n>     open issues\n> \n> 4. Set date of next conference call (May 7 or 21 - several of us will\n>     be at FTC meeting May 14)\n> \n\n\n\n", "id": "lists-017-2867260"}, {"subject": "Re: P3P Data Schema as XML Schem", "content": "On Tuesday 29 April 2003 12:27, Giles Hogben wrote:\n> Apologies for confusing the acronyms BDS and BSD... BDS means the base\n> data schema and BSD is an OS...\n\n(Do the BSD files only work on that OS then???)\n\n> For those who don't want to get bogged down in nasty amounts of\n> complexity, just look at the file bdsfinal.xsd which is the final result\n> schema, or try the policy transformer on a policy (e.g. the one\n> included). Hope the directory and file names are relatively self\n> explanatory\n\nFYI I've attached the result of running:\n  > xsltproc p3ptransform.xsl  p3ptransform.xml > out.xml\n\nNote I first had to remove the commented section (lines 57-78) from \np3ptransform.xsl in order to get it to work (otherwise my XML tools \ncomplain it isn't well formed: comments don't nest).\n\n\n\n\ntext/xml attachment: out.xml\n\n\n\n\n", "id": "lists-017-2876953"}, {"subject": "RE: P3P Data Schema as XML Schem", "content": "My thoughts on this as an implementer. It would be good to have other\npeople's feedback:\n\n1. As far as making custom schemas is concerned, the current version (let's\ncall it BDS and the new one XSD) is a complete non-starter. The syntax is so\nunintuitive that no-one can make head or tail of it and the only custom data\nschema I've seen had completely misunderstood it. The whole thing of having\nDEF's, ref's and structrefs and matching using the first half of the ref\nelement is really a mess! Just take a look at the code I had to write in the\nxsl files to get an XSD that makes sense.\n2. From the same point of view, validating any new schemas is a nightmare.\nHaving built a (the only) system for parsing and validating generalised DS's\nin our implementation, I can tell you that it was a horrible, horrible job.\n3. I don't agree that this version makes it heavier. It means that any APPEL\nlike engine can just carry on doing sub-tree matching instead of going into\nanother regular expression based mode which we found added weight. You're\nright that it will be slightly more verbose. Could you explain why you'd\nwant it \"reference with a URI\". Surely this could be solved - maybe by\nreferring to a particular element in the XSD - they are unique.\n4. The format is so non-intuitive that it is very difficult to make sense of\nit.\n5. XSD does not have a formal semantics, but its informal semantics is a lot\neasier to make sense of than BDS. I think the RDFS attempt at codifying the\nBDS shows both how impossible it is for people to understand  the BDS format\nand how confused the semantics are (vide our discussion about a year ago on\nthis subject) - the RDFS schema has a uri for EVERY possible combination of\nallowed structures - I think it ends up being about 5000 lines because of\nthis!\n6. What I am suggesting here has a 1-1 mapping to the old version with an\nxslt so it's quite legacy-friendly isn't it. I don't think it should just\nend up with a note that nobody is going to read.\n\nThoughts?\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n[mailto:public-p3p-spec-request@w3.org]On Behalf Of Massimo Marchiori\nSent: 29 April 2003 18:54\nTo: Giles Hogben; Joseph Reagle\nCc: public-p3p-spec@w3.org; Rigo Wenning; Jeremy Epling\nSubject: RE: P3P Data Schema as XML Schema\n\n\n\nP3Pers, apologies for having missed the call today, XQuery is swamping me\nthese days.\nAnyway, some quick words on the \"P3P data schema in XML Schema\".\nThis issue had already been tackled quite some time ago in the P3P spec\ngroup (you might have wondered if somebody hadn't thought\nabout it before... right? ;)\nIn fact, this has at a time been discussed as an alternate proposal, and\nfinally rejected.\nI'll state the reasons and some comments here, because these still apply\n(which means, reopening this issue in P3P1.1 should then\nagain mean challenge again the \"con\" of the solution).\n\nFirst big motivation: who needs it? What are the real advantages?\nImplementers, at the time, let us know they didn't like the\n\"xml-schema way\" (let's call it this way), because\na) it makes parsing heavier\nb) it makes simple data declaration too verbose (as you have to duplicate\neach subpart of a data element in begin and end tags)\n\nThis was the main objection at the time. Now, we are no more in the\ndesigning phase (1.0), so tackling this issue again in 1.1 has\nto face the new, crucial, additional problem:\nc) what are the costs of adding an alternate format to the spec?\n\nThere was also other considerations that led not to consider that design,\nthat I'll recap here too:\nd) splitting data elements (etc) in separate tags, apparently leads to the\nloss of the \"reference with a URI\" property: you'd still\nneed to recombine the info in a single-line canonicalization to get this\nproperty back (so, essentially going back to the status\nquo).\ne) makes DTD support more difficult\n\nOk, enough with historical motivations for today ;)\nSo all in all, the above considerations just apply if this proposal is going\nto end in 1.1 (i.e., it's reopening the issue).\nIf it's instead a translation-only thing (like the RDFization note of P3P),\nlikely to end as a Note or so, then of course all the\nabove is moot ;)\n-M\n\n\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org\n> [mailto:public-p3p-spec-request@w3.org]On Behalf Of Giles Hogben\n> Sent: Tuesday, April 29, 2003 6:28 PM\n> To: Joseph Reagle\n> Cc: public-p3p-spec@w3.org; Rigo Wenning; Jeremy Epling\n> Subject: RE: P3P Data Schema as XML Schema\n>\n>\n> Here are some more files on this issue\n> I have corrected some small errors in the schema transform (e.g. it was\n> outputting category element and attribute element definitions with global\n> scope where it shouldn't have been).\n> I have also included a 2 stage transform which avoids using extensions\n(you\n> do transform 1 and then transform2 on the results of transform1 to\neliminate\n> duplicates) and, for the benefit of other members of list the files for\nthe\n> policy transform I sent earlier.\n>\n> Apologies for confusing the acronyms BDS and BSD... BDS means the base\ndata\n> schema and BSD is an OS...\n>\n> For those who don't want to get bogged down in nasty amounts of\ncomplexity,\n> just look at the file bdsfinal.xsd which is the final result schema, or\ntry\n> the policy transformer on a policy (e.g. the one included). Hope the\n> directory and file names are relatively self explanatory\n>\n> Regards\n>\n> Giles\n>\n>\n>\n>\n> -----Original Message-----\n> From: Joseph Reagle [mailto:reagle@w3.org]\n> Sent: 28 April 2003 20:08\n> To: Giles Hogben\n> Subject: Re: P3P Data Schema as XML Schema\n>\n>\n> On Saturday 26 April 2003 09:06, you wrote:\n> > Yeah - sorry - it was the quickest and easiest way to get it to work\n> > at the time - will try to send a self executing .jar file at some\n> > point - maybe that'll help.\n>\n> I'm still not following, keep in mind I know nothing about MS IE and very\n> little about Java (I'm more of a XML and Python person) <smile/>. I was\n> expecting to do something like:\n>   xsltproc bsdtransform.xsl p3p1_0.xml > converted_p3p_1_0.xsd\n> then I can check a P3P instance against that schema:\n>   xsv p3p.xml converted_p3p_1_0.xsd\n>\n> What is \"BSD\" btw?\n>\n\n\n\n", "id": "lists-017-2885290"}, {"subject": "UA translation", "content": "Sorry for late entry into this discussion - lack of time, not because I'm\nnot interested!\n\nHere are some comments on the docs: I went through the 3 docs trying to be\nas picky as possible...:)\nDisclaimer - haven't had time to look through other people's comments + I\ncan be a bit picky about exact meanings of things - Philosophy+Physics at\nUni + lots of proof reading...)\n\nGeneral comments. The thing that struck me as most important is to come up\nwith consistent and good ways of expressing a couple of things like\n\"identifies you\". My impression from reading them that they haven't been\nlooked at by a lawyer. I think as we suggested, they need to be run by a\nusability lab and a lawyer (for consistency and to look at implications)\n\nLorrie - let me know if you would like me to structure this better.\n\n-------------\nPrivacy Bird:\n-------------\n\n\n\"identified with you\" is a. inconsistent with \"about you\" and b. could be\nmisleading.\nThe word identity or related words should probably be avoided unless\nspecifically talking about identity.\nAlso - is the information really about \"you\" - I mean couldn't it be more\nfactual and say \"your activities\"\n\n\n3 different terms for the same thing - \"about you\", \"your information\" and\n\"information identified with you\"\n\nPurpose- current - \"data was provided\" - is ambiguous - first of all it\nhasn't necessarily been provided yet - it's a policy after all and secondly\nprovided sounds like something a provider does - would suggest submitted.\n\nadmin - To do web site and system administration - the information doesn't\ndo the administration does it. Suggest \"Used in ....\". Perhaps you mean\n\"PURPOSE is to do ....\"  but that's still not what we really mean.\n\n\"To do research and development without creating a record identified with\nyou\" - identified with you in common parlance is not a very exact phrase -\n\"which identifies you\"?\n\n\"To contact you through means other than telephone (email, postal mail,\netc.) to interest you in other services or products\" - \"to interest you\" is\nnot really what the purpose - usually it is \"to sell you\" although interest\nmight be a bi-product. Ditto below for telemarketing.\n\nOther unknown uses - are they unknown or just incapable of being expressed\nwithin P3P?\n\n--  \"only if you request this\" is ambiguous - should be more exact.\n\n\"Delivery companies who may also use your information for other purposes\" -\nis that correct or is it \"only for delivery\"? Surely that makes more sense?\n\n\"PREFERENCEInformation about your tastes or preferences\" - tastes is a bit\nvague. Doesn't really add anything to the meaning.\n\n\n---------\nNetscape:\n---------\n General comment - unclear about voice - should be either \"this site (owner\nof policy is talking)\" or \"the site (browser manufacturer is talking)\" but\nnot both. Another example \"our stated business practice\".\n\n\"Contact and other specific information \" - \"other specific information\" is\nmeaningless\n\n\"Information identified on this web site such as your account statement.\"\nUnclear what \"identified on this web site\" - specific examples restrict the\ndomain too much.\n\n\"?Reference to applicable law\" - applicable doesn't mean much to me.\n\n\"<money>\n?Payment to you of an amount specified in the privacy policy or the amount\nof damages.\"\nWhat is \"the amount\". How do we determine what amount is specified in the\nprivacy policy. Which privacy policy??\n\n\"?Complete the activity for which it was specifically provided.\" - Complete\nor carry out?\n\n\"?Provide technical support of the web site and its computer system.\" wrong\npreposition.\n\n\"?Customize or tailor the design or content on the site during a single\nvisit to the site?it will not be maintained for future visits to the site.\n\" - did we mean to make it session specific?\n\npseudoanalysis - \"without linking them to you personally\" - you personally\nis ambiguous - PII would be better.\n\nindividual-analysis does not explicitly say whether information is linkable.\n\n\"?Preserve social history in accordance with an existing law or policy.\"\nVery different from PB definition - did anyone mention law or policy?\n\nOpt-in/opt out description - \"you can\" and \"you will be given an\nopportunity\" for the same thing - should use the same phrase.\n\n<ours> \"an agent \" is a bit ambigous - no longer an agent under mandate of\nthis site etc...\n\nDelivery different from PB definition.\n\n\"held accountable to this web site \" is very ambiguous. How can you be\naccountable to a web site?\n\n\n\"<unrelated>\n?Other entities that do not tell us what they will do with your\ninformation.\" I don't think the point is that they don't tell us. It is that\nwe do not know (and are not accountable).\n\n\n\"<public>\n?Public bulletin boards, chat rooms, or other public forums or services.\"\nThe boards are not the recipients - as PB rightly makes clear.\n\n\"Your information will be destroyed and it will not be logged or archived\nafter your session ends.\" is ambiguous - what the \"after your session ends\"\napplies to.\n\n\"?As long as it is required by law or liability under applicable law.\nClick here for more information. ADD: The information is retained to meet a\nspecific purpose but may be retained longer that it takes to meet that\npurpose. For example, if a consumer has 30 days to dispute a transaction,\nthe web site may maintain the transaction information for 30 days until the\ntime for lodging the dispute has passed.\"\n\nAdditional info does not mention anything about law - or only as an\nexample - very ambiguous.\n\n\"?Identifies you as a unique user but does not use your e-mail address,\nsocial security number, or name to identify you.\" - is this correct???\n\n\"?Your passive behavior on the web site such as which pages you have\nvisited.\" - passive will be misinterpreted. Needs to be made more explicit.\n\n\"<content>\n?Specific content that you have provided to the site such as the text of an\ne-mail.\" - not a very good example - an email is not an email when it's on a\nsite - so it's a bit confusing.\n\n\"?Your current physical location such as GPS data.\" your GPS co-ordinates.\n\n---------------------\nInternet Explorer\n---------------------\n\n\"Information that allows an individual to be contacted or located in the\nphysical world\" - how does it differ from location - not clear\n\nOnline - \"located on the internet\" - what does this mean?\n\n\"identifying an individual over time.  \" Identifying is always over time -\nthis doesn't mean much. Identity comes from Latin \"idem\" meaning same - as\nwe are not talking about \"the same type of thing in 2 different places\"\nidentity means the same thing at 2 different times.\n\n\"Information about an individual's finances, **including** account status,\naccount balance, payment or overdraft history, and information about an\nindividual's purchase or use of financial instruments, including credit\ncards or debit cards.\" - implies that all those things will be collected.\nShould say \"can include\" or \"such as\" - such terms should be used\nconsistently throughout.\n\n\"Demographic and socioeconomic data, , such as gender, age, and income, not\ntied to an identifiable person. \"  double comma in IE too? Tied to an\nidentifiable person is a bit vague - there are so many ways of saying this -\nwe need to come up with a good way of saying this and use it consistently.\n\n\"The words and expressions contained in the body of a communication. For\nexample, the text of an e-mail message, bulletin board postings, or chat\nroom communications. \"  It's unclear how a P3P agent would collect such\nthings in its prsent form as it can't be applied to chat rooms or email\ncommunication.\n\n\"Mechanisms, such as HTTP cookies, for maintaining an active connection with\nan individual or for automatically identifying an individual who has visited\na particular site or previously accessed particular content. \" This is\ncompletely confusing - does it mean identifying an individual in the sense\nof knowing their identity or does it mean knowing that they are the same guy\nas five minutes ago. Very different. \"An active connection with an\nindividual\" is also not clear - it sounds like some kind of social\ninteraction.\n\n\"Information about membership in or affiliation with groups such as\nreligious organizations, trade unions, professional associations, political\nparties, etc. \"  It's not clear what links the items hence \"etc...\" is a bit\nunclear here.\n\n\"Information, such as global positioning data, that can be used to identify\nan individual's current physical location and track him as his location\nchanges. \" - \"current\" is not what is meant - the information might be\nstored. Avoid identify unless it's connected with identity. Don't use gender\nspecific pronouns. The fact that his location might change seems irrelevant.\n\n\"Identifiers issued by a government for purposes of identifying an\nindividual over time, such as a driver_ s license number, social security\nnumber, or passport number.\"  - double use of word identity. Identifying the\nindividual may not be the PURPOSE of a drivers' license number as is\nimplied.\n\n\"What types of information about myself do I have access to? \" where - how?\n\n\"Personally identifiable online and physical contact information, as well as\nto other information linked to an identifiable person.\" - wrong grammar -\nuse of \"to other information\" we are trying to describe what sort of\ninformation I have access to, not the access itself. Contains yet another\nphrase for \"linkable\".\n\n \"Information that is based upon a unique identifier but that cannot be\nlinked to an individual may be used for research, analysis, and reporting.\nFor example, the number of users within a ZIP code. \"  - it's not clear that\na ZIP code cannot be linked to an individual. Maybe that's true in America\nbut if I use the word post-code, in the UK, this is a dubious example to\nuse.\n\n\"Information that can be linked to an individual may be used to make a\ndecision that directly affects that individual. For example, a Web site\nmight show an individual houses that are within her ability to purchase,\nregardless of the price range she has researched before. \" - I don't see the\ndifference between this example and the one with the ZIP code/location given\nabove. They are both using information which is not unique to the individual\nto give tailored information.\n\n\n\"Legal entities performing delivery services that may use data for purposes\nother than completion of the stated purpose. \"\nThe P3P description here is strange. In terms of what people will be\ninterested in, aren't delivery services who will not use data for purposes\nother than delivering more of interest. Otherwise it probably just falls\ninto the category of <other> for practical purposes. I.e. if you give your\ninfo to them, you can say goodbye to your privacy.\n\nno-retention - \"the single online interaction.  \" What does this mean\n_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\nVia Enrico Fermi 1\n21020 Ispra,   Italy\nTel.:   +39 0332 789187\nFax.:   +39 0332 789576\ne-mail: giles.hogben@jrc.it\n\n\n\n", "id": "lists-017-2901684"}, {"subject": "XML  Schema transform on the documents pag", "content": "On Wed, Apr 30, 2003 at 02:53:01PM +0200, Giles Hogben wrote:\n> Hi Rigo,\n> Could you put the XML Schema docs up on the server? \n\nGiles, \n\nI've added all the documents to the server and added them to\nhttp://www.w3.org/P3P/1.1/documents.html\nand\nhttp://www.w3.org/P3P/2003/03-xml-data-schema.html\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-2920714"}, {"subject": "Re: UA translation", "content": "Giles,\n\nThanks for the detailed notes. One quick comment. You raised questions \nabout the delivery definitions used by all three user agents. While the \nwording may be more or less clear, I think PB and IE both have correct \ndefinitions and Netscape has a definition that is correct, but \nincomplete. If a web site only uses delivery companies that use data \naccording to the agent definition in <ours/> then they don't need to \nmake an explicit delivery disclosure. The <deliver/> element was added \nfor the common (in the US at least) case that a company uses a delivery \nservice whose privacy practices they don't know (or they know to be \nless restrictive than their own).\n\nLorrie\n\n\n\n", "id": "lists-017-2928157"}, {"subject": "BH: Introducing the Beyond HTTP (BH) Task Forc", "content": "INTRODUCTION\n\nMy name is Christine O'Keefe and I lead a research group\nin \"Security and Privacy\" for the Commonwealth Scientific\nand Industrial Research Organisation (CSIRO), based in\nCanberra, Australia. My colleague Patrick Hung has\nalready introduced himself to you. \n\nOur current focus is to address the fundamental security \nand privacy issues involved in integrating existing isolated \nhealth and social databases for research, without compromising \nstandards of privacy, security or intellectual property. \n\nOur intention is to implement the integration using Web \nServices Technologies, and as such the \"Beyond HTTP (BH) \nTask Force\", particularly the migration of P3P to Web Services, \nis of great interest to us.  \n\nLooking forward to talking with you soon,\nChristine\n\n-------------------------------------------------\nA/Prof Christine M O'Keefe                       Ph +61 2 6216 7021\nGroup Leader, Security and Privacy\nCSIRO Mathematical and Information Sciences      \n\nwww.cmis.csiro.au/Christine.OKeefe\nwww.cmis.csiro.au/esecurity\n\n\n\n", "id": "lists-017-2935819"}, {"subject": "AGENDA: P3P Spec call Aug ", "content": "The next P3P specification group conference call will be on\nWednesday, August 6, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Patrick Hung\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n2. Bugzilla 283 Change definition of recipient in 3.3.5 for\n    consistancy\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=283\n\nCurrently the definition of recipient in 3.3.5 says \"the legal entity,\nor domain, beyond the service provider and its agents where data may\nbe distributed.\" However the defintions of the individual recipient\nelements include the service provider and its agents. For consistancy\nwe should drop the words \"beyond the service provider and its agents\"\nfrom this definition. This can probably be viewed as an errata.\n\n3. Discuss Jeremy's grouping draft and related proposals - Bugzilla 169\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=169\n\n4. Discussion of Ari's revised identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\n\n5. Discuss performance issues (raised by Jeremy)\n\n6. Set date for next call (Aug 13?)\n\n\n\n", "id": "lists-017-2999488"}, {"subject": "P3P Beyond HTTP Task Force Repor", "content": "Dear Elisa,\n\nJoseph and I have created a P3P Beyond HTTP Task Force Report that\nmay cover some of the privacy issues in Web services the Liberty\nAlliance is interested in:\n\nhttp://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n\nIn fact, I am studying the Liberty Alliance specifications and try to\nfigure out the common areas.\n\nMany thanks and I am looking forward to hearing from you soon.\n\nPatrick.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Friday, 9 May 2003 5:57 AM\nTo: Elisa Korentayer\nCc: public-p3p-spec@w3.org\nSubject: Re: Liberty-P3P Interaction\n\n\n\nOn Wednesday 30 April 2003 12:07, Elisa Korentayer wrote:\n> The Liberty subteam that has been charged with drafting the Privacy\n> Preferences Expression Languages White Paper is very interested in\n> continuing the discussion and cooperation started with P3P at the Boston\n> meeting in March.\n\nElisa, thank you for the pointers. I've reviewed the documents and besides \nthe editorial comment below don't have many substantive comments. It's \nquite a lot material to get my mind around. I don't trust I understand it \nall quite yet, but after my efforts I was left with the following two \nimpressions:\n1. When it comes to making a declaration in the context of federated \nidentity services, a possible challenge is specifying the scope of the \nsoliciting service and the subsequent recipients? For example, should an \nidentity service represent the policy from itself, rather narrowly, with a \nwider recipient, or define \"itself\" as the set of all affiliates it might \nshare the information with, with no other recipients?\n2. Where is the p3p hook? I note that the SOAP binding has a consent header \nblock, how does that relate to a privacy declaration? I unfortunately \nremember little of the \"five level policy approach\", have you published \nanything with respect to that yet?\n\nThe editorial nit was in the Architecture Overview, it uses the term \n\"introduce\" and \"federate\" (i.e., \"You may Federate your Airline Inc. \nidentity with any others...\") without first defining it. Unfortunately, the \ndocuments aren't hypertext (so I can't easily follow a link to their \nnormative definitions) but it seems the glossary gives a definition for \nfederate (i.e. bind), but not introduce. I'm sure the Overview states their \nmeanings, but perhaps doing so more explicitly would help it sink in. \n<smile/>\n\n> In terms of scheduling, we would like to get a sense from you as to\n> whether P3P, or the P3P members engaged in this project, would be\n> interested in having a phone conversation at the end of May to speak more\n> on these issues.  \n\nI'll defer this question to the P3P group for discussion.\n\n> And, on a larger scale, we would like to get a sense of\n> P3P's interest level, and timeline, for working on a White Paper for the\n> use of P3P in the Liberty context.\n\nOn that note, I'm working in a task force to hopefully address some \nquestions of how to bind SOAP or WSDL with a P3P statement. Once it is in \ndecent form it might be relevant to the questions you have and I would also \nbe willing to review/comment upon the White Paper.\n\n\n\n", "id": "lists-017-3007374"}, {"subject": "[BP] P3P Beyond HTTP Task Force Repor", "content": "The latest version of the P3P Beyond HTTP Task Force Report is ready on:\n\nhttp://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n\nAny comment/suggestion is more than welcome.\n\nAs the current draft does not contain any W3C member confidential material,\nI am going to invite non-W3C people to comment it via DBWORLD mailing list. \n\nBest Regards,\n\nPatrick.\n\n\n\n", "id": "lists-017-3018509"}, {"subject": "Re: Grouping Statements Proposa", "content": "We discussed  this on today's call, minutes should be forthcoming. My \nquick summary is:\n\n- combining these two group concepts probably makes sense\n- we probably want an extension that looks something like the following \nthat can be inserted into all statement's that belong to a group:\n\n<STATEMENT>\n<EXTENSION>\n   <STATEMENT-GROUP id = \"fflyer\" />\n</EXTENSION>\n. . .\n</STATEMENT>\n\nThen somewhere else in the policy\n<EXTENSION\n   <STATEMENT-GROUP-DEF id=\"fflyer\"\n   short-description=\"Frequent Flyer Club\"\n   consent = \"opt-in\" />\n</EXTENSION>\n\nSome groups of statements might not be consent groups, in which case \nthey might use an attribute like consent = \"no-group\" (which might be \nthe default).\n\nThere are also some concerns about consent group that need to be worked \nout. In Mathias' proposal it says that all PURPOSE and RECIPIENT \nelements in a group have to have the same required attribute. But ours \nand current are special cases that don't have this attribute. This \nneeds to be accounted for (the example in Mathias' draft is actually \nincorrect because of this). Also we need to be clear on how to handle \nerrors. What if someone uses consent group but then uses different \nrequired attributes (which is incorrect)? Does that invalidate the \npolicy? Perhaps if that happens the user agent should treat it as if it \nis consent = \"no-group\" ?\n\nIn any case, Jeremy is going to put together a more specific proposal \non this grouping. Mathias, it would be great if you could work with him \non the consent aspect.\n\nLorrie\n\n\nOn Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n\n>\n> Hi Jeremy,\n>\n> thanks for your design. I feel that grouping statements is a good idea.\n>\n> The actual syntax for grouping is elaborated in our earlier draft on \n> consent choices:\n>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>\n> I feel that grouping statements is a good idea for multiple purposes.\n> Therefore, I feel that we should have a general group mechanism where \n> each group should have multiple properties:\n> - opt-in opt-out or always (from consent choices)\n>   syntactically this can be implicit: either all statements are \n> always/opt-in, or opt-out.\n> - target (something specifying whether it's the ebay or amazon part)\n>   The target is something that might be useful to add to your proposal.\n>   I don't know how to express this in a nice syntax.\n>\n> Why don't we merge both proposals into a \"grouping statements\" \n> proposal?\n>\n> Regards,\n>\n> matthias\n>\n>\n>\n> At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>\n>> Below are the basics of my proposal for statement grouping.\n>>\n>>\n>>\n>> Problems\n>>    * Policies are not relevant to how a user interacts with the site\n>>        * Users don t know what part of a P3P policy applies to them \n>> and there activities on a site\n>>        * Users understand scenarios of how they interact with a site \n>> better than a series of statements related to a feature of the site\n>>    * Policy authors have to make highest common denominate policies \n>> that could look more privacy impacting than they are for most users\n>>\n>>\n>> Goals\n>>    * Provide a method for showing the sections of the P3P policy that \n>> apply to how a user interacts with the site/service\n>>    * Allow an easy way for policy authors to describe what sections \n>> of their P3P policy apply to different user interaction with their \n>> site/service\n>>\n>>\n>> Scenarios\n>>    * User browses to ebay and views the P3P policy. They are able to \n>> skip to the buyer section of the P3P policy since that is what \n>> applies to them.\n>>    * User browses to amazon and views the P3P policy. The can see \n>> that since they are not logged in less information is collected about \n>> them.\n>>\n>>\n>> Design\n>>\n>>\n>>\n>> The P3P author decides the name of the statement group which is used \n>> in the display of the agent when it translates the nodes to natural \n>> language.\n>>\n>>\n>>\n>> <Statement>\n>>\n>>             <extention>\n>>\n>>                         <grouping-id>Member</grouping-id>\n>>\n>>             </extention>\n>>\n>> <statement>\n>>\n>>\n>>\n>> Issues\n>>    * Do agents now show conflicts per grouping?\n>>\n>>\n>> Jeremy Epling\n>> Windows - Privacy and Trust UX\n>>\n>> <BLOCKED::>wpihelp - where to go for all your privacy questions\n>>\n>>\n>\n> -- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n> Fax +41-1-724 8953; More info at www.semper.org/sirene\n> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n\n\n\n", "id": "lists-017-3025545"}, {"subject": "[Bug 167] explanation of identified, identifiable, and linke", "content": "Updated Draft based on comments from the WG:\n\n----\n\n\nIdentity Definitions in the P3P Specification\n\nIn privacy regulations, guidelines and papers about privacy a variety \nof terms are used to describe data that identifies an individual to \nvarying degrees.  The European Union Directive defines \"an \nidentifiable person\" as \"one who can be identified, directly or \nindirectly, in particular by reference to an identification number or \nto one or more factors specific to his physical, physiological, \nmental, economic, cultural or social identity.\"  The Directive also \nstates that in determining whether a person is identifiable \"account \nshould be taken of all the means likely reasonably to be used either \nby the controller or by any other person to identify the said person; \nwhereas the principles of protection shall not apply to data rendered \nanonymous in such a way that the data subject is no longer \nidentifiable.\"  In other policy documents terms such as \"personally \nidentifiable  information (PII)\" are often not defined or the cause \nfor heated debate.\n\nIn different documents, \"identity\" can be tied to:\n\n1) how the information can be or is being used,\n2) how the information is stored, or\n3) the type of information.\n\nThe P3P Specification Working Group tried to capture all three of \nthese ideas so that different implementers and users can make \ndecisions based on the importance they place on these various \ndefinitions of identity. (1)\n\nIdentity Through Usage (\"identified\" data)\n\nThe most common term in the specification is \"identified data\" and \nfocuses on how the information can be or is being used.\n\n\"Identified data\" is information that reasonably can be used by the \ndata collector to identify an individual.  Admittedly, this is a \nsomewhat subjective standard.  For example, a data collector storing \nInternet Protocol (IP) addresses  (which can be created dynamically \nor could be static and therefore tied to a particular computer used\nby a single individual) should consider the IP address \"identified \ndata\" only when an attempt is made to tie the exact addresses to past \nrecords or work with others to identify the specific individual or \ncomputer over a long period of time.  In the more common case, where \ndata collectors use IP addressing information in the aggregate or \nmake no attempt to tie the IP address to a specified individual or \ncomputer over a long period of time, IP addresses are not considered \nidentified even though it is possible for someone (eg, law \nenforcement agents with proper subpoena powers) to identify the \nindividual based on the stored data.\n\nIn the P3P Specification, the term \"identifiable\" is used in a \nsimilar way as it as used in the EU Directive. Thus, in the P3P \ncontext, any data that can be used reasonably by a data controller or \nany other person to identify an individual is considered to be \nidentifiable data. The P3P specification uses the term \"identified\" \nto describe a subset of this data that can be reasonably used by a \ndata collector *without assistance from other parties* to identify an \nindividual.\n\nIdentity Through Storage (\"non-identifiable\" and \"linked\" data)\n\nThe working group also felt that data collectors should be able \nacknowledge when they make specific attempts to anonymize what would \notherwise be identifiable in its storage.\n\nThe term \"non-identifiable\" data refers to how the information is \nstored.  For example, a data collector collecting and storing IP \naddresses but not using them should NOT call this data \n\"non-identifiable\" even in the common case where they have no plans \nto identify an actual individual or computer. However, if a Web site \ncollects IP addresses, but actively deletes all but the last four \ndigits of this information in order to determine short term use, but \ninsure that a particular individual or computer cannot be \nconsistently identified, then the data collector can and should call \nthis information \"non-identifiable.\"  Also, non-identifiable can be \nused in cases where no information is being collected at all.  Since \nmost Web servers are designed to keep Web logs for maintenance, this \nwould most likely mean that the data collector has taken specific\nefforts to ensure the anonymity of users.\n\nUnder the above definitions, a lot of information could be \n\"identifiable\" (not specifically made anonymous), but not \n\"identified\" (reasonably able to be tied to an individual or \ncomputer).\n\nSimilarly, the term \"linked\" refers to how information is being \nstored in connection with a cookie. All data in a cookie or linked to \na particular user must be disclosed in the cookie's policy. Using the \nterminology above, if the data collector collects \"identifiable\" \ninformation about the user it is generally \"linked\" data. For \nexample, if the data collector stores a login name in a file \nassociated with a persistent cookie and the login name is linked to \npersonal data, the cookie is clearly \"linked.\"\n\nIn less clear cut example, if the data collector ties the cookie to a \nspecific order id in a flat file and that order id is tied to \npersonal information in a related file, the cookie would be linked to \nall of the relational data unless specific precautions have been \ntaken to ensure that a data operator with access to the relational \ndata cannot access the flat cookie data and vice versa.\n\nIdentity Through Information Type\n\nThe Working Group decided against an identified or identifiable label \nfor particular types of data. However, user agent implementers have \nthe option of assigning these or other labels themselves and building \nuser interfaces that allow users to make decisions about web sites on \nthe basis of how they collect and use certain types of data.\n\nThe Working Group felt that different user agent implementations \ncould be created to focus on different concerns around data type. \nTherefore, the working group enabled the creation of a robust data \nschema including broad categories of information that may be \nconsidered sensitive by certain user groups.  The Working Group hopes \nthat a diverse set of user agents will be created to allow users the \nability to make identity decisions based on specific collections and \ntypes of collects if they desire to do so.  For example, a user agent \ncould allow users to opt to be prompted when medical or financial \nidentifier is being collected, independent of how that information is \nbeing used.\n\n(1)   More information on the debate and the definitions can be found \nin Lorrie Faith Cranor's book Web Privacy with P3P, O'Reilly, 2002.\n\n\n\n-- \n------------------------------------\nAri Schwartz\nAssociate Director\nCenter for Democracy and Technology\n1634 I Street NW, Suite 1100\nWashington, DC 20006\n202 637 9800\nfax 202 637 0968\nari@cdt.org\nhttp://www.cdt.org\n------------------------------------\n\n\n\n", "id": "lists-017-3038619"}, {"subject": "MINUTES: 6 August 2003 P3P spec cal", "content": "Minutes of the 6 August 2003 P3P spec wg call\n\nPresent\nLorrie Cranor, AT&T, Chair\nAri Schwartz, CDT\nPatrick Hung, CSIRO\nGiles Hogben, JRC\nJeremy Epling, Microsoft\n\n\nSUMMARY\n\n1. Task force reports\n    - P3P beyond HTTP - Patrick Hung\n      -> The working draft has been revised a bit and tried to get comments\nfrom the Liberty people.\n    \n    - User agent behavior - Lorrie Cranor\n      -> Hope to get comments about user agent translations by next\nWednesday\n      -> To get Rigo involved in this process\n      -> Expect to have a proposal by next week \n    \n    - Article 10 vocabulary issues - Giles Hogben\n      -> Nothing new\n    \n     - Converting P3P data schema to XML schema - Giles Hogben\n      -> Expect to get the first draft of specification in the coming weeks\n      -> 2 human readable elements: long and short descritpion\n      -> Giles mentioned that the attribute of long description (CDATA) is\nnot using at all and wonder \n         whether we should cut it\n      -> The major difference between the attributes of long and short\n(STRING) description is the limitation \n         in length\n      -> Intend to keep the functionalities as many as possible and just\neasy to ignore\n      -> Retain the attribute of short description to be STRING, and open to\nthe attribute of long description \n         that can include markup\n    - Signed P3P policies  - Giles Hogben\n      -> Not to enforce security in the recent version of P3P because of no\nstandard\n      -> The European people are still keeping their focus on this issue\n\n2. Bugzilla 283 Change definition of recipient in 3.3.5 for\n    consistancy\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=283\n\n-> Minor change of the definition of receipient\n-> The revised definition of recipient is \"the legal entity, or domain, \n   where data may be be distributed\"\n\n3. Discuss Jeremy's grouping draft and related proposals - Bugzilla 169\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=169\n\nQuote from Lorrie's e-mail:\n\n\"We discussed  this on today's call, minutes should be forthcoming. My \nquick summary is:\n\n- combining these two group concepts probably makes sense\n- we probably want an extension that looks something like the following \nthat can be inserted into all statement's that belong to a group:\n\n<STATEMENT>\n<EXTENSION>\n   <STATEMENT-GROUP id = \"fflyer\" />\n</EXTENSION>\n. . .\n</STATEMENT>\n\nThen somewhere else in the policy\n<EXTENSION\n   <STATEMENT-GROUP-DEF id=\"fflyer\"\n   short-description=\"Frequent Flyer Club\"\n   consent = \"opt-in\" />\n</EXTENSION>\n\nSome groups of statements might not be consent groups, in which case \nthey might use an attribute like consent = \"no-group\" (which might be \nthe default).\n\nThere are also some concerns about consent group that need to be worked \nout. In Mathias' proposal it says that all PURPOSE and RECIPIENT \nelements in a group have to have the same required attribute. But ours \nand current are special cases that don't have this attribute. This \nneeds to be accounted for (the example in Mathias' draft is actually \nincorrect because of this). Also we need to be clear on how to handle \nerrors. What if someone uses consent group but then uses different \nrequired attributes (which is incorrect)? Does that invalidate the \npolicy? Perhaps if that happens the user agent should treat it as if it \nis consent = \"no-group\" ?\n\nIn any case, Jeremy is going to put together a more specific proposal \non this grouping. Mathias, it would be great if you could work with him \non the consent aspect.\"\n\nOther issues:\n\n-> Tie the consent to a group of attributes in version 2.0? \n-> Need a human readable field in consent?\n-> Giles likes only using ID as a simple reference and Lorrie suggests to\nuse ID + small description\n-> Pay attention to the semantic as it may cause some impossiblities of\napplying opt-in and opt-out\n-> Concern about using CDATA for ID because it may contain HTML codes. It is\npermitted but no \n   guaranatee how the uer agent will behave.\n-> If you have any particular markup tag that suits some applicatons, you\ncan always submit a proposal\n   and will be considered for implementing in the user agent.\n-> Jeremy will put all these ideas/issues into Section 3.3.\n\n4. Discussion of Ari's revised identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\n\n-> Ari will work with Rigo on it when Rigo is back.\n\n5. Discuss performance issues (raised by Jeremy)\n\n-> Expect to do it soon. \n\n6. Set date for next call (Aug 13?)\n\n-> Plan to get all working drafts by the third week of Sept. \n-> While Lorrie will be not available for a couple weeks in Sep, Rigo will\nrun the meeting call. \n-> Get all working drafts to become W3C recommendations in 2004 one by one.\n-> Next meeting: Aug 13. \n\n\n\n", "id": "lists-017-3052997"}, {"subject": "[FYI] CfP: WHOLES  A Multiple View of Individual Privacy in a Networked Worl", "content": "Dear all, \n\nattached a call for participation of the WHOLES-Workshop, which asks\nmore generic questions about privacy.\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\nattached mail follows:\nDear all,\n\nThank you for agreeing to participate in the program committee of the WHOLES\nworkshop. You will find the first CfP attached in text, HTML and PDF. Please\nfeel free to redistribute it wherever you feel it would be appropriate.\n\nDue to the late date of this first CfP, I felt that the submission deadline\nand date for notification of acceptance had to be somewhat delayed, I hope\nthat this change will not cause problems for anyone.\n\nMore information about the workshop venue will be made available by the end\nof August.\n\nbest regards,\n\nMarkus Bylund, Ph.Lic.\nResearcher\nSwedish Institute of Computer Science\nBox 1263\nSE-164 29 Kista\nSWEDEN\nwww: http://www.sics.se/~bylund\ne-mail: markus.bylund@sics.se\nphone: +46 (08) 633 15 00\nmobile: +46 (0)70 661 54 60\nfax: +46 (0)8 751 72 30\n\n\n\n\n\napplication/pdf attachment: cfp1.pdf\n\ntext/html attachment: cfp1.html\n\ntext/plain attachment: cfp1.txt\n\n\n\n\n", "id": "lists-017-3064881"}, {"subject": "Re: Grouping Statements Proposa", "content": "Hi!\n\nThe proposal looks good. Once Jerry contacts me, I'll work with him to \nresolve the remaining issues. Some initial ideas/remarks:\n- the opt-in or opt-in elements inside all elements of an opt-in/out-out \ngroup where included\n   to preserve backward compatibility of the semantics.\n- The issue of the OURS/CURRENT may be resolved by defining that they \ncannot be included in an\n   opt-in/opt-out group.\n- Does it makes sense to use \"required\" instead of \"no-group\" or do you \nenvision that with\n   consent=\"no-group\", one can nevertheless have opt-in's and out's inside?\n\nRegards,\n  matthias\n\n\n\n\nAt 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n\n>We discussed  this on today's call, minutes should be forthcoming. My \n>quick summary is:\n>\n>- combining these two group concepts probably makes sense\n>- we probably want an extension that looks something like the following \n>that can be inserted into all statement's that belong to a group:\n>\n><STATEMENT>\n><EXTENSION>\n>   <STATEMENT-GROUP id = \"fflyer\" />\n></EXTENSION>\n>. . .\n></STATEMENT>\n>\n>Then somewhere else in the policy\n><EXTENSION\n>   <STATEMENT-GROUP-DEF id=\"fflyer\"\n>   short-description=\"Frequent Flyer Club\"\n>   consent = \"opt-in\" />\n></EXTENSION>\n>\n>Some groups of statements might not be consent groups, in which case they \n>might use an attribute like consent = \"no-group\" (which might be the default).\n>\n>There are also some concerns about consent group that need to be worked \n>out. In Mathias' proposal it says that all PURPOSE and RECIPIENT elements \n>in a group have to have the same required attribute. But ours and current \n>are special cases that don't have this attribute. This needs to be \n>accounted for (the example in Mathias' draft is actually incorrect because \n>of this). Also we need to be clear on how to handle errors. What if \n>someone uses consent group but then uses different required attributes \n>(which is incorrect)? Does that invalidate the policy? Perhaps if that \n>happens the user agent should treat it as if it is consent = \"no-group\" ?\n>\n>In any case, Jeremy is going to put together a more specific proposal on \n>this grouping. Mathias, it would be great if you could work with him on \n>the consent aspect.\n>\n>Lorrie\n>\n>\n>On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n>\n>>\n>>Hi Jeremy,\n>>\n>>thanks for your design. I feel that grouping statements is a good idea.\n>>\n>>The actual syntax for grouping is elaborated in our earlier draft on \n>>consent choices:\n>>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>>\n>>I feel that grouping statements is a good idea for multiple purposes.\n>>Therefore, I feel that we should have a general group mechanism where \n>>each group should have multiple properties:\n>>- opt-in opt-out or always (from consent choices)\n>>   syntactically this can be implicit: either all statements are \n>> always/opt-in, or opt-out.\n>>- target (something specifying whether it's the ebay or amazon part)\n>>   The target is something that might be useful to add to your proposal.\n>>   I don't know how to express this in a nice syntax.\n>>\n>>Why don't we merge both proposals into a \"grouping statements\" proposal?\n>>\n>>Regards,\n>>\n>>matthias\n>>\n>>\n>>\n>>At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>>\n>>>Below are the basics of my proposal for statement grouping.\n>>>\n>>>\n>>>\n>>>Problems\n>>>    * Policies are not relevant to how a user interacts with the site\n>>>        * Users don t know what part of a P3P policy applies to them and \n>>> there activities on a site\n>>>        * Users understand scenarios of how they interact with a site \n>>> better than a series of statements related to a feature of the site\n>>>    * Policy authors have to make highest common denominate policies \n>>> that could look more privacy impacting than they are for most users\n>>>\n>>>\n>>>Goals\n>>>    * Provide a method for showing the sections of the P3P policy that \n>>> apply to how a user interacts with the site/service\n>>>    * Allow an easy way for policy authors to describe what sections of \n>>> their P3P policy apply to different user interaction with their site/service\n>>>\n>>>\n>>>Scenarios\n>>>    * User browses to ebay and views the P3P policy. They are able to \n>>> skip to the buyer section of the P3P policy since that is what applies to them.\n>>>    * User browses to amazon and views the P3P policy. The can see that \n>>> since they are not logged in less information is collected about them.\n>>>\n>>>\n>>>Design\n>>>\n>>>\n>>>\n>>>The P3P author decides the name of the statement group which is used in \n>>>the display of the agent when it translates the nodes to natural language.\n>>>\n>>>\n>>>\n>>><Statement>\n>>>\n>>>             <extention>\n>>>\n>>>                         <grouping-id>Member</grouping-id>\n>>>\n>>>             </extention>\n>>>\n>>><statement>\n>>>\n>>>\n>>>\n>>>Issues\n>>>    * Do agents now show conflicts per grouping?\n>>>\n>>>\n>>>Jeremy Epling\n>>>Windows - Privacy and Trust UX\n>>>\n>>><BLOCKED::>wpihelp - where to go for all your privacy questions\n>>>\n>>\n>>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-3073691"}, {"subject": "Re: Grouping Statements Proposa", "content": "On Monday, August 11, 2003, at 09:13  AM, Matthias Schunter wrote:\n\n> Hi!\n>\n> The proposal looks good. Once Jerry contacts me, I'll work with him to \n> resolve the remaining issues. Some initial ideas/remarks:\n> - the opt-in or opt-in elements inside all elements of an \n> opt-in/out-out group where included\n>   to preserve backward compatibility of the semantics.\n\nYes, that's what I remember too. But the problem still occurs as to \nwhat to do if people violate this rule. I think we need to define how \nto handle this error case.\n\n> - The issue of the OURS/CURRENT may be resolved by defining that they \n> cannot be included in an\n>   opt-in/opt-out group.\n\nI think we may need to include them, but perhaps we can define that the \nopt-in/opt-out doesn't apply to them.\n\n> - Does it makes sense to use \"required\" instead of \"no-group\" or do \n> you envision that with\n>   consent=\"no-group\", one can nevertheless have opt-in's and out's \n> inside?\n\nI was envisioning the \"no-group\" would indicate a mix of opt-in's \nopt-out's and required, or all required.\n\nLorrie\n\n\n>\n> Regards,\n>  matthias\n>\n>\n>\n>\n> At 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n>\n>> We discussed  this on today's call, minutes should be forthcoming. My \n>> quick summary is:\n>>\n>> - combining these two group concepts probably makes sense\n>> - we probably want an extension that looks something like the \n>> following that can be inserted into all statement's that belong to a \n>> group:\n>>\n>> <STATEMENT>\n>> <EXTENSION>\n>>   <STATEMENT-GROUP id = \"fflyer\" />\n>> </EXTENSION>\n>> . . .\n>> </STATEMENT>\n>>\n>> Then somewhere else in the policy\n>> <EXTENSION\n>>   <STATEMENT-GROUP-DEF id=\"fflyer\"\n>>   short-description=\"Frequent Flyer Club\"\n>>   consent = \"opt-in\" />\n>> </EXTENSION>\n>>\n>> Some groups of statements might not be consent groups, in which case \n>> they might use an attribute like consent = \"no-group\" (which might be \n>> the default).\n>>\n>> There are also some concerns about consent group that need to be \n>> worked out. In Mathias' proposal it says that all PURPOSE and \n>> RECIPIENT elements in a group have to have the same required \n>> attribute. But ours and current are special cases that don't have \n>> this attribute. This needs to be accounted for (the example in \n>> Mathias' draft is actually incorrect because of this). Also we need \n>> to be clear on how to handle errors. What if someone uses consent \n>> group but then uses different required attributes (which is \n>> incorrect)? Does that invalidate the policy? Perhaps if that happens \n>> the user agent should treat it as if it is consent = \"no-group\" ?\n>>\n>> In any case, Jeremy is going to put together a more specific proposal \n>> on this grouping. Mathias, it would be great if you could work with \n>> him on the consent aspect.\n>>\n>> Lorrie\n>>\n>>\n>> On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n>>\n>>>\n>>> Hi Jeremy,\n>>>\n>>> thanks for your design. I feel that grouping statements is a good \n>>> idea.\n>>>\n>>> The actual syntax for grouping is elaborated in our earlier draft on \n>>> consent choices:\n>>>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>>>\n>>> I feel that grouping statements is a good idea for multiple purposes.\n>>> Therefore, I feel that we should have a general group mechanism \n>>> where each group should have multiple properties:\n>>> - opt-in opt-out or always (from consent choices)\n>>>   syntactically this can be implicit: either all statements are \n>>> always/opt-in, or opt-out.\n>>> - target (something specifying whether it's the ebay or amazon part)\n>>>   The target is something that might be useful to add to your \n>>> proposal.\n>>>   I don't know how to express this in a nice syntax.\n>>>\n>>> Why don't we merge both proposals into a \"grouping statements\" \n>>> proposal?\n>>>\n>>> Regards,\n>>>\n>>> matthias\n>>>\n>>>\n>>>\n>>> At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>>>\n>>>> Below are the basics of my proposal for statement grouping.\n>>>>\n>>>>\n>>>>\n>>>> Problems\n>>>>    * Policies are not relevant to how a user interacts with the site\n>>>>        * Users don t know what part of a P3P policy applies to them \n>>>> and there activities on a site\n>>>>        * Users understand scenarios of how they interact with a \n>>>> site better than a series of statements related to a feature of the \n>>>> site\n>>>>    * Policy authors have to make highest common denominate policies \n>>>> that could look more privacy impacting than they are for most users\n>>>>\n>>>>\n>>>> Goals\n>>>>    * Provide a method for showing the sections of the P3P policy \n>>>> that apply to how a user interacts with the site/service\n>>>>    * Allow an easy way for policy authors to describe what sections \n>>>> of their P3P policy apply to different user interaction with their \n>>>> site/service\n>>>>\n>>>>\n>>>> Scenarios\n>>>>    * User browses to ebay and views the P3P policy. They are able \n>>>> to skip to the buyer section of the P3P policy since that is what \n>>>> applies to them.\n>>>>    * User browses to amazon and views the P3P policy. The can see \n>>>> that since they are not logged in less information is collected \n>>>> about them.\n>>>>\n>>>>\n>>>> Design\n>>>>\n>>>>\n>>>>\n>>>> The P3P author decides the name of the statement group which is \n>>>> used in the display of the agent when it translates the nodes to \n>>>> natural language.\n>>>>\n>>>>\n>>>>\n>>>> <Statement>\n>>>>\n>>>>             <extention>\n>>>>\n>>>>                         <grouping-id>Member</grouping-id>\n>>>>\n>>>>             </extention>\n>>>>\n>>>> <statement>\n>>>>\n>>>>\n>>>>\n>>>> Issues\n>>>>    * Do agents now show conflicts per grouping?\n>>>>\n>>>>\n>>>> Jeremy Epling\n>>>> Windows - Privacy and Trust UX\n>>>>\n>>>> <BLOCKED::>wpihelp - where to go for all your privacy questions\n>>>>\n>>>\n>>> -- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>>> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>>> Fax +41-1-724 8953; More info at www.semper.org/sirene\n>>> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>>\n>\n> -- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n> Fax +41-1-724 8953; More info at www.semper.org/sirene\n> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n\n\n\n", "id": "lists-017-3088112"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Ari, \n\nyou have _not_ taken into account my lengthy comments nor the comments\nfrom Robert Horn _not_ to mix usage/storage/type into the term identity.\nThe idea expressed below is still the same. \n\nThis will create heavy confusion as scope, processing and purpose are\nmixed together. I think we should work it out together. Your definitions\nsound compelling only at a first glance.\n\nRigo\n\nOn Wed, Aug 06, 2003 at 12:22:35PM -0400, Ari Schwartz wrote:\n> Identity Through Usage (\"identified\" data)\n[...]\n> \n> Identity Through Storage (\"non-identifiable\" and \"linked\" data)\n[...]\n> \n> Identity Through Information Type\n> \n[...]\n\n\n\n", "id": "lists-017-3104018"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Rigo,\n\nWe discussed this on the call and basically the consensus was that \nwhile we understood your alternative view point, we could not \nunderstand what was wrong with Ari's approach *in addition* to yours. \nAri did take into account your suggestions, but he was having trouble \nfiguring out how to satisfy you as well as the people who thought it \nmade more sense the way he approached it in the first place. I \nsuggested to Ari that he use both approaches in the document, since \nsome resinate with some people and other resinate with others. So his \nlatest draft represents his attempt to satisfy everyone. It is of \ncourse open for further discussion, and we will discuss it on the call \nthis week and perhaps you can help us understand why we should take \n*only* your approach and not both approaches.\n\nLorrie\n\n\nOn Monday, August 11, 2003, at 01:17  PM, Rigo Wenning wrote:\n\n>\n> Ari,\n>\n> you have _not_ taken into account my lengthy comments nor the comments\n> from Robert Horn _not_ to mix usage/storage/type into the term \n> identity.\n> The idea expressed below is still the same.\n>\n> This will create heavy confusion as scope, processing and purpose are\n> mixed together. I think we should work it out together. Your \n> definitions\n> sound compelling only at a first glance.\n>\n> Rigo\n>\n> On Wed, Aug 06, 2003 at 12:22:35PM -0400, Ari Schwartz wrote:\n>> Identity Through Usage (\"identified\" data)\n> [...]\n>>\n>> Identity Through Storage (\"non-identifiable\" and \"linked\" data)\n> [...]\n>>\n>> Identity Through Information Type\n>>\n> [...]\n>\n\n\n\n", "id": "lists-017-3112125"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Since I might not be able to make the telephone call, I'll note my\nconcerns.\n\nOne minor concern was the exclusive mention of EC regulations.  The newer\nmedical regulations (US, Canada, Australia, ...) are all using similar\nnomenclature where the key factor is whether the data is identifiable.\nThe notion of \"identified\" data is meaningless in these contexts.\n\nThere are people who are concerned with the difference in intention between\n\"the person will be identified\" and \"the person could be identified.\"  This\nappears to be distinction that is being conveyed in the \"identified\" versus\n\"identifiable\".  There are contexts where this distinction is important.\nE.g., if you can trust the other party's statement of intentions you might\nfind this to be important.  So I have no problem with having terms to\ndistinguish these two cases.\n\nI find mixing in the use of the term \"storage\" confusing.  All of this data\nis stored somewhere for some period of time.  How about changing the title\nof that section to:\n\n\"Non-identifiable\" data\n\nThen the rest of the next three paragraphs reads just fine.  It makes it\nclear that non-identifiable data has had any identifying information\nremoved.\n\nThe two paragraphs on \"linked\" are less clear.  Is the following a correct\nrephrasing of the first paragraph?  I would add a section header to\nseparate it from the previous discussion of non-identifiable data.\n\n\"Linked\" data\n\nThe term \"linked\" refers to information that can be associated with a\ncookie. All data in a cookie or linked to a particular user must be\ndisclosed in the cookie's policy. Using the terminology above, if the data\ncollector collects \"identifiable\" information about the user that can be\nassociated with a cookie, then this information is \"linked\" with the\ncookie. For example, if the data collector stores a login name in a file\nassociated with a persistent cookie and the login name is linked to\npersonal data, the cookie is clearly \"linked.\"\n\nR Horn\n\n\n\n", "id": "lists-017-3121331"}, {"subject": "AGENDA: 13 August P3P Spec Cal", "content": "The next P3P specification group conference call will be on\nWednesday, August 13, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Patrick Hung\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n2. Discussion of Ari's revised identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0004.html\n\n3. Discussion of Jeremy's grouping draft and related proposals - \nBugzilla 169\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=169\nNEED REVISED PROPOSAL BEFORE CALL\n\n4. Discussion of performance issues (raised by Jeremy)\nNEED PERFORMANCE DOCUMENT BEFORE CALL\n\n5. Set date for next call (Aug 20?)\n\n\n\n", "id": "lists-017-3131584"}, {"subject": "Re: Grouping Statements Proposa", "content": "Playing the devil's advocate here and trying to understand the aim \nof this proposal:\nOn Tue, Jul 29, 2003 at 07:00:35PM -0700, Jeremy Epling wrote:\n> Scenarios\n> \n> *User browses to ebay and views the P3P policy. They are able to\n> skip to the buyer section of the P3P policy since that is what applies\n> to them.\n\nThis is role based: A user identifies himself as a buyer and takes only\nnotice of this part of the policy. \n\nBUT, P3P ties a certain policy to a certain URI. It means, as long as\nthe user is browsing in the buyer realm, a certain policy applies. \n\nSo the main reason that we would need a grouping is, that there was an\noverstatement in the first place that we try to overcome by the user\nidentifying himself in a certain role and cognitively selecting a part\nof the policy. \n\nIn the given scenario, example.com has a PRF that says:\n<POLICY-REF about=\"/w3c/policy.xml\">\n<INCLUDE>/*</INCLUDE>\n</POLICY-REF>\n\nThe policy would then include several roles/services that the whole\nWeb-Site contains. \n\nFinally, instead of the site (that should know) the user has to figure\nout, what is actually happening. I don't think, this is an improvement.\n\n> *User browses to amazon and views the P3P policy. The can see\n> that since they are not logged in less information is collected about\n> them.\n\nIf the login-pages are separated from the normal pages, P3P would find\nout automatically. This re-enters to much human brain-work in the\nautomation we tried to achieve.\n\nSo instead of grouping (not consent-grouping, which is different), we\nshould perhaps explain how to design a site in a clever way using P3P. I\nfear simply that this takes too much pressure away from Web-sites to\nactually be precise in their policies (and use multiple policies instead\nof the one-fits-all)\n\nI see the benefit of explaining which service does what, to better\nunderstand things. But this is a question of labelling policies\n(long-description/consequence etc) and not of grouping statements. \n\nThis all under the reserve that I understood the proposal correctly. \n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-3139426"}, {"subject": "Re: Grouping Statements Proposa", "content": "Matthias and Jeremy,\n\nWe discussed this on the call today and would like to move this \nforward. We need a revised proposal. Jeremy, are you going to get us \nsomething this week? Or perhaps Matthias could revise his proposal to \nincorporate what we've discussed? I would like to have something more \nconcrete to discuss before next week's call.\n\nThanks,\n\nLorrie\n\n\n\nOn Monday, August 11, 2003, at 09:52  AM, Lorrie Cranor wrote:\n\n>\n>\n> On Monday, August 11, 2003, at 09:13  AM, Matthias Schunter wrote:\n>\n>> Hi!\n>>\n>> The proposal looks good. Once Jerry contacts me, I'll work with him \n>> to resolve the remaining issues. Some initial ideas/remarks:\n>> - the opt-in or opt-in elements inside all elements of an \n>> opt-in/out-out group where included\n>>   to preserve backward compatibility of the semantics.\n>\n> Yes, that's what I remember too. But the problem still occurs as to \n> what to do if people violate this rule. I think we need to define how \n> to handle this error case.\n>\n>> - The issue of the OURS/CURRENT may be resolved by defining that they \n>> cannot be included in an\n>>   opt-in/opt-out group.\n>\n> I think we may need to include them, but perhaps we can define that \n> the opt-in/opt-out doesn't apply to them.\n>\n>> - Does it makes sense to use \"required\" instead of \"no-group\" or do \n>> you envision that with\n>>   consent=\"no-group\", one can nevertheless have opt-in's and out's \n>> inside?\n>\n> I was envisioning the \"no-group\" would indicate a mix of opt-in's \n> opt-out's and required, or all required.\n>\n> Lorrie\n>\n>\n>>\n>> Regards,\n>>  matthias\n>>\n>>\n>>\n>>\n>> At 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n>>\n>>> We discussed  this on today's call, minutes should be forthcoming. \n>>> My quick summary is:\n>>>\n>>> - combining these two group concepts probably makes sense\n>>> - we probably want an extension that looks something like the \n>>> following that can be inserted into all statement's that belong to a \n>>> group:\n>>>\n>>> <STATEMENT>\n>>> <EXTENSION>\n>>>   <STATEMENT-GROUP id = \"fflyer\" />\n>>> </EXTENSION>\n>>> . . .\n>>> </STATEMENT>\n>>>\n>>> Then somewhere else in the policy\n>>> <EXTENSION\n>>>   <STATEMENT-GROUP-DEF id=\"fflyer\"\n>>>   short-description=\"Frequent Flyer Club\"\n>>>   consent = \"opt-in\" />\n>>> </EXTENSION>\n>>>\n>>> Some groups of statements might not be consent groups, in which case \n>>> they might use an attribute like consent = \"no-group\" (which might \n>>> be the default).\n>>>\n>>> There are also some concerns about consent group that need to be \n>>> worked out. In Mathias' proposal it says that all PURPOSE and \n>>> RECIPIENT elements in a group have to have the same required \n>>> attribute. But ours and current are special cases that don't have \n>>> this attribute. This needs to be accounted for (the example in \n>>> Mathias' draft is actually incorrect because of this). Also we need \n>>> to be clear on how to handle errors. What if someone uses consent \n>>> group but then uses different required attributes (which is \n>>> incorrect)? Does that invalidate the policy? Perhaps if that happens \n>>> the user agent should treat it as if it is consent = \"no-group\" ?\n>>>\n>>> In any case, Jeremy is going to put together a more specific \n>>> proposal on this grouping. Mathias, it would be great if you could \n>>> work with him on the consent aspect.\n>>>\n>>> Lorrie\n>>>\n>>>\n>>> On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n>>>\n>>>>\n>>>> Hi Jeremy,\n>>>>\n>>>> thanks for your design. I feel that grouping statements is a good \n>>>> idea.\n>>>>\n>>>> The actual syntax for grouping is elaborated in our earlier draft \n>>>> on consent choices:\n>>>>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>>>>\n>>>> I feel that grouping statements is a good idea for multiple \n>>>> purposes.\n>>>> Therefore, I feel that we should have a general group mechanism \n>>>> where each group should have multiple properties:\n>>>> - opt-in opt-out or always (from consent choices)\n>>>>   syntactically this can be implicit: either all statements are \n>>>> always/opt-in, or opt-out.\n>>>> - target (something specifying whether it's the ebay or amazon part)\n>>>>   The target is something that might be useful to add to your \n>>>> proposal.\n>>>>   I don't know how to express this in a nice syntax.\n>>>>\n>>>> Why don't we merge both proposals into a \"grouping statements\" \n>>>> proposal?\n>>>>\n>>>> Regards,\n>>>>\n>>>> matthias\n>>>>\n>>>>\n>>>>\n>>>> At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>>>>\n>>>>> Below are the basics of my proposal for statement grouping.\n>>>>>\n>>>>>\n>>>>>\n>>>>> Problems\n>>>>>    * Policies are not relevant to how a user interacts with the \n>>>>> site\n>>>>>        * Users don t know what part of a P3P policy applies to \n>>>>> them and there activities on a site\n>>>>>        * Users understand scenarios of how they interact with a \n>>>>> site better than a series of statements related to a feature of \n>>>>> the site\n>>>>>    * Policy authors have to make highest common denominate \n>>>>> policies that could look more privacy impacting than they are for \n>>>>> most users\n>>>>>\n>>>>>\n>>>>> Goals\n>>>>>    * Provide a method for showing the sections of the P3P policy \n>>>>> that apply to how a user interacts with the site/service\n>>>>>    * Allow an easy way for policy authors to describe what \n>>>>> sections of their P3P policy apply to different user interaction \n>>>>> with their site/service\n>>>>>\n>>>>>\n>>>>> Scenarios\n>>>>>    * User browses to ebay and views the P3P policy. They are able \n>>>>> to skip to the buyer section of the P3P policy since that is what \n>>>>> applies to them.\n>>>>>    * User browses to amazon and views the P3P policy. The can see \n>>>>> that since they are not logged in less information is collected \n>>>>> about them.\n>>>>>\n>>>>>\n>>>>> Design\n>>>>>\n>>>>>\n>>>>>\n>>>>> The P3P author decides the name of the statement group which is \n>>>>> used in the display of the agent when it translates the nodes to \n>>>>> natural language.\n>>>>>\n>>>>>\n>>>>>\n>>>>> <Statement>\n>>>>>\n>>>>>             <extention>\n>>>>>\n>>>>>                         <grouping-id>Member</grouping-id>\n>>>>>\n>>>>>             </extention>\n>>>>>\n>>>>> <statement>\n>>>>>\n>>>>>\n>>>>>\n>>>>> Issues\n>>>>>    * Do agents now show conflicts per grouping?\n>>>>>\n>>>>>\n>>>>> Jeremy Epling\n>>>>> Windows - Privacy and Trust UX\n>>>>>\n>>>>> <BLOCKED::>wpihelp - where to go for all your privacy questions\n>>>>>\n>>>>\n>>>> -- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>>>> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>>>> Fax +41-1-724 8953; More info at www.semper.org/sirene\n>>>> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>>>\n>>\n>> -- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>> Fax +41-1-724 8953; More info at www.semper.org/sirene\n>> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>>\n>\n\n\n\n", "id": "lists-017-3148032"}, {"subject": "Identifiable example", "content": "Here is one of the examples of how completely arbitrary information may be\nidentifiable, which I promised in today's call:\n\nTake the set of facts,\n\nF1:Prozac is an anti-depressant\nF2:Steve Brown uses Prozac\nF3:Robin Smith uses anti-depressants\nF4:Cary Wilson doesn't use anti-depressants etc.\n\n{F2} and {F1, **given (F2-F4.)} and {F4, **given (F1-F3.)} constitute PII\nwrt Steve Brown but F1 and F3 alone do not. This shows how F1 and F4, which\napparently have nothing to do with Steve Brown, can identify him given a\ncertain set of background knowledge (F2-4).\n\nI'll be able to contribute more info on this next week (paper in review)\n\nGiles\n\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen\nCybersecurity and New technologies for Combatting Fraud Unit\n\n\n\n", "id": "lists-017-3164916"}, {"subject": "MINUTES: 13 August 2003 P3P spec cal", "content": "Minutes of the 13 August P3P 1.1 spec wg call\n\nPresent:\nLorrie Cranor\nPatrick Hung\nRigo Wenning\nGiles Hogben\nJeff Edelen\nEric Brunner-Williams\nAri Schwartz\n\n\n1. Task force reports\n  - P3P beyond HTTP - Patrick Hung\n    - Nothing new to report.  Waiting for comments.\n    - WG comments not yet provided to Liberty\n    - ACTION: TF to decide what we want to propose for inclusion in the\n      1.1 spec\n\n  - User agent behavior - Lorrie Cranor\n    - No comments received on last draft of translation\n    - ACTION: All interested parties to please provide any comments this week\n    - Some legal folks have expressed concern over aspects of the legal\n      terminology used in the spec.  Attempting to collect a proposal to put\n      forward to address these concerns.\n    - ACTION: Lorrie to post a summary of the legal discussion\n\n  - Article 10 vocabulary issues - Giles Hogben\n    - Nothing new to report\n\n  - No other TF reports discussed\n\n2. Discussion of Ari's revised identified/identifiable/link\nclarification draft.\n  - Agreed that headings should be changed, bullet points removed, and\n    verbiage around \"usage\" and \"storage\" re-examined.\n  - Agreed to add rational explaining the need to distinguish between\n    identified and identifiable\n  - ACTION: Ari to update doc and distribute for review\n\n3. Discussion of Jeremy's grouping draft and related proposals\n  - Jeremy not present for discussion\n  - Grouping has come up in a couple of contexts\n    - A large number of statements on some policies may overwhelm the user.\n      Grouping of statements can make reading the policy easier.\n    - The same grouping mechanism could potentially be used for consent\n      choices\n  - Rigo expressed concern that the user would need to figure out what\n    statement groups apply, and also that we should encourage multiple\n    policies with relevant statements for a site versus a small number of\n    large policies\n  - Lorrie observed that many companies have valid legal and organizational\n    reasons to use large policies, that they will do so, and that statement\n    grouping may improve the user experience at least somewhat\n  - Awaiting an updated specification from Jeremy that delves into more\n    detail for potential inclusion in the 1.1 spec\n\n4. Discussion of performance issues (raised by Jeremy)\n  - Jeremy not available\n\n5. Set date for next call (Aug 20?)\n  - Not discussed (or maybe I just hung up too soon...)\n\n\n\n\nAmerican Express made the following\n annotations on 08/13/2003 10:13:47 AM\n------------------------------------------------------------------------------\n******************************************************************************\n\n     \"This message and any attachments are solely for the intended recipient and may contain confidential or privileged information. If you are not the intended recipient, any disclosure, copying, use, or distribution of the information included in this message and any attachments is prohibited.  If you have received this communication in error, please notify us by reply e-mail and immediately and permanently delete this message and any attachments.  Thank you.\"\n\n******************************************************************************\n\n\n==============================================================================\n\n\n\n", "id": "lists-017-3171924"}, {"subject": "Re: MINUTES: 13 August 2003 P3P spec cal", "content": "On Wed, Aug 13, 2003 at 10:22:23AM -0700, Jeffrey A Edelen wrote:\n> 5. Set date for next call (Aug 20?)\n>   - Not discussed (or maybe I just hung up too soon...)\n\nNext call is August 20, same time, same place, watch\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n[member-only]\n\nRigo\n\n\n\n", "id": "lists-017-3182589"}, {"subject": "Comments on UA TF translation", "content": "Lorrie, late but hopefully not too late: my 2 cents after re-reading the\ndraft.\n=======================================================================\nOn Element opturi (attribute of POLICY element)\n\nIt currently says: Find out how to opt-out at [with link to opturi]\n\nBut the opturi can also be a uri to opt-in. By standardizing the text\nabove, we prevent the expression of opturi as opt-in\n\n=======================================================================\n<ACCESS><all />\n\nIt says: We give you access to all of our information that identifies\nyou\n\nI'm a bit reluctant with my pigeon-english to comment here, but there\nmight be data attached to a record of a natural person that does not\nidentify this person but just enhances the profile. What about:\n\nWe give you access to all of our information about you\n\nHmm.. reading further in ACCESS, there is a mixture of \"identifies you\"\nand \"information about you\". This could be canonicalized for better\nunderstanding.\n=======================================================================\n\n<DISPUTES>\n\nit says often \"[display long description and short description, if\nprovided, with hyperlink to service URI]\"\n\nshouldn't we provide a default in the absence of such a description?\n\nThis could resolve some of the concerns of David Stampley, as we might\nsay: If other dispute resolutions have failed, you could ultimately go\nto court with your case (which is always true ;) This makes more sense\nfor <law />. Your rights are ultimately protected by law.\n\n=======================================================================\n\n<REMEDIES> \n\nI agree with the concerns of David Stampley concerning the <law />\nelement.\n\n=======================================================================\n\n<NON-IDENTIFIABLE>\n\nit says:\n\n\"We do not keep any information that could be used to identify you\npersonally\"\n\nBut in fact, this is a question of retention. Non-identifiable means:\n\nWe do not collect any information that could be used to identify you\npersonally\n\n=======================================================================\n\nThe rest is okay. I did not find any further thing that would merit a\ncomment. So I consider this already very good.\n\nRigo\n\n\n\nOn Wed, Jul 30, 2003 at 12:15:28PM -0400, Lorrie Cranor wrote:\n> Lorrie posted a revised matrix and has invited public comments by 13 \n> August. This will allow us to make another pass at revisions by the end \n> of August so they can be incorporated in the next browser releases.\n\n\n\n", "id": "lists-017-3189535"}, {"subject": "Re: Comments on UA TF translation", "content": "On Thursday, August 14, 2003, at 10:35  AM, Rigo Wenning wrote:\n\n>\n> Lorrie, late but hopefully not too late: my 2 cents after re-reading \n> the\n> draft.\n\nNope, not too late. Thanks for the comments!\n\n> =======================================================================\n> On Element opturi (attribute of POLICY element)\n>\n> It currently says: Find out how to opt-out at [with link to opturi]\n>\n> But the opturi can also be a uri to opt-in. By standardizing the text\n> above, we prevent the expression of opturi as opt-in\n\nMaybe we should change to \"Find out how to opt-in or opt-out at\"\n\n>\n> =======================================================================\n> <ACCESS><all />\n>\n> It says: We give you access to all of our information that identifies\n> you\n>\n> I'm a bit reluctant with my pigeon-english to comment here, but there\n> might be data attached to a record of a natural person that does not\n> identify this person but just enhances the profile. What about:\n>\n> We give you access to all of our information about you\n>\n> Hmm.. reading further in ACCESS, there is a mixture of \"identifies you\"\n> and \"information about you\". This could be canonicalized for better\n> understanding.\n\nThe definition of <all/> is restricted to \"identified data\" so \"about \nyou\" seems to broad?\n\n\n> =======================================================================\n>\n> <DISPUTES>\n>\n> it says often \"[display long description and short description, if\n> provided, with hyperlink to service URI]\"\n>\n> shouldn't we provide a default in the absence of such a description?\n>\n> This could resolve some of the concerns of David Stampley, as we might\n> say: If other dispute resolutions have failed, you could ultimately go\n> to court with your case (which is always true ;) This makes more sense\n> for <law />. Your rights are ultimately protected by law.\n>\n\nThe service URL is always required, so maybe that should be the default\n\n> =======================================================================\n>\n> <REMEDIES>\n>\n> I agree with the concerns of David Stampley concerning the <law />\n> element.\n>\n> =======================================================================\n>\n> <NON-IDENTIFIABLE>\n>\n> it says:\n>\n> \"We do not keep any information that could be used to identify you\n> personally\"\n>\n> But in fact, this is a question of retention. Non-identifiable means:\n>\n> We do not collect any information that could be used to identify you\n> personally\n\nThe definition of this element includes both the case that the info is \nnot collected and the case that it is collected but anonymized before \nbeing stored.  That's why we use the term \"keep\" rather than \"collect.\"\n\n\n\n", "id": "lists-017-3199052"}, {"subject": "P3P Beyond HTTP Task Forc", "content": "Regarding to some previous discussion with Joseph and Hugo, we have\nmentioned that:\n\n\"When XMLP messages are conveyed over HTTP the existing mechanisms defined\nin the P3P1.0 specification may be used to associate policies with XMLP\nmessages. \nHowever, it is unclear to us whether the P3P specification supplies\nsufficiently level \nof granularity to identify XMLP messages. If it does not, it is likely that\nthe P3P extension \nmechanism could be used to provide this granularity, but again this would\nneed to be \ndocumented. Furthermore, if other mechanisms are defines specifically for\nuse with XMLP, \nthen conflicts may arise between these mechanisms and the P3P1.0-defined\nmechanisms. \nThe proper way to resolve these conflicts needs to be documented as well.\n\nBesides documenting how a P3P policy should be associated with an XMLP\nmessage, we \nbelieve it would be useful to offer some usage scenarios that include P3P.\nWe are concerned\nthat in the absence of discussion of privacy and P3P, developers will be\nlikely to ignore privacy \nissues when implementing the XML Protocol.\n\n1. http://www.w3.org/TR/2002/WD-xmlp-reqs-20020626\n2. http://lists.w3.org/Archives/Public/xmlp-comments/2002Jan/0022.html\"\n\nThis may be one of the items that this task force want to propose for\ninclusion in the 1.1 spec.\nI will try to do more thoughts on it.\n\n\n\n", "id": "lists-017-3209568"}, {"subject": "Re: Comments on UA TF translation", "content": "On Thu, Aug 14, 2003 at 02:37:48PM -0400, Lorrie Cranor wrote:\n> Maybe we should change to \"Find out how to opt-in or opt-out at\"\n\nWhat about opt-in/out (shorter ;)\n> \n> >\n> >=======================================================================\n> ><ACCESS><all />\n> >\n> >It says: We give you access to all of our information that identifies\n> >you\n> >\n> The definition of <all/> is restricted to \"identified data\" so \"about \n> you\" seems to broad?\n\nBut I find the 'identifies' a bit difficult because they have that\nprofile and now it identifies me ;). 'about you' is much more natural\nand semantically works well with what we want to express. What you mean\nis more of 'might be able to find out about you', which would work with\n'identifiable'.\n> \n> \n> >=======================================================================\n> >\n> ><DISPUTES>\n> >\n> \n> The service URL is always required, so maybe that should be the default\n\nWhat text? A URI has no meaning here.. Just say 'for disputes click\nhere'? ;)\n> \n> >=======================================================================\n> >\n> ><NON-IDENTIFIABLE>\n> >\n> The definition of this element includes both the case that the info is \n> not collected and the case that it is collected but anonymized before \n> being stored.  That's why we use the term \"keep\" rather than \"collect.\"\n\nIn this case, non-identifiable and non-ident are semantically equal\nexpressions in the user-interface.\nThat's what I want to prevent as non-identifiable is really much\nstronger as non-ident in retention. Remember, non-ident is only about \nidentified data and not identifiable data.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-3217552"}, {"subject": "Re: Comments on UA TF translation", "content": "On Monday, August 18, 2003, at 05:45  AM, Rigo Wenning wrote:\n\n>\n> On Thu, Aug 14, 2003 at 02:37:48PM -0400, Lorrie Cranor wrote:\n>> Maybe we should change to \"Find out how to opt-in or opt-out at\"\n>\n> What about opt-in/out (shorter ;)\n\nBut not very meaningful.\n\n>>\n>>>\n>>> ===================================================================== \n>>> ==\n>>> <ACCESS><all />\n>>>\n>>> It says: We give you access to all of our information that identifies\n>>> you\n>>>\n>> The definition of <all/> is restricted to \"identified data\" so \"about\n>> you\" seems to broad?\n>\n> But I find the 'identifies' a bit difficult because they have that\n> profile and now it identifies me ;). 'about you' is much more natural\n> and semantically works well with what we want to express. What you mean\n> is more of 'might be able to find out about you', which would work with\n> 'identifiable'.\n\nI agree that \"about you\" sounds better. But semantically it is wrong.  \nYou have it backwards. What I mean is information that we have  \nidentified with you (identified, not identifiable).\n\n\n>>\n>>> ===================================================================== \n>>> ==\n>>>\n>>> <NON-IDENTIFIABLE>\n>>>\n>> The definition of this element includes both the case that the info is\n>> not collected and the case that it is collected but anonymized before\n>> being stored.  That's why we use the term \"keep\" rather than  \n>> \"collect.\"\n>\n> In this case, non-identifiable and non-ident are semantically equal\n> expressions in the user-interface.\n> That's what I want to prevent as non-identifiable is really much\n> stronger as non-ident in retention. Remember, non-ident is only about\n> identified data and not identifiable data.\n\nWell the semantic difference should be that non-ident is about  \n\"identified\" data\nand non-identifiable is about \"identifiable\" data.  I think the user  \ninterface expressions we are proposing make the correct distinction. If  \nyou want to change \"keep\" somewhere, arguably it would be better to  \nchange the \"keep\" in \"nonident\" to \"collect\" since that's the word used  \nin the definition -- but I think its ok the way it is.\n\nLorrie\n\n\n\n", "id": "lists-017-3226687"}, {"subject": "Re: Comments on UA TF translation", "content": "On Mon, Aug 18, 2003 at 09:14:17AM -0400, Lorrie Cranor wrote:\n> >What about opt-in/out (shorter ;)\n> \n> But not very meaningful.\n\nOk.\n> \n> >>><ACCESS><all />\n> >>>\n> >But I find the 'identifies' a bit difficult because they have that\n> >profile and now it identifies me ;). 'about you' is much more natural\n> >and semantically works well with what we want to express. What you mean\n> >is more of 'might be able to find out about you', which would work with\n> >'identifiable'.\n> \n> I agree that \"about you\" sounds better. But semantically it is wrong.  \n> You have it backwards. What I mean is information that we have  \n> identified with you (identified, not identifiable).\n\nI think we are on the same side in what we want to express :)\n'Identified with you' sounds more like what I meant, but doesn't it look\nlike too much of data protection talk if we say 'identified with you'? \n\n> \n> \n> >>\n> >>>===================================================================== \n> >>>==\n> >>>\n> >>><NON-IDENTIFIABLE>\n> \n> Well the semantic difference should be that non-ident is about  \n> \"identified\" data\n> and non-identifiable is about \"identifiable\" data.  I think the user  \n> interface expressions we are proposing make the correct distinction. If  \n> you want to change \"keep\" somewhere, arguably it would be better to  \n> change the \"keep\" in \"nonident\" to \"collect\" since that's the word used  \n> in the definition -- but I think its ok the way it is.\n> \nI've re-read the sections and I think it is ok the way it is. But still\nthe only distinction between 'could identify you' and identified\ninformation (we might have identifiable information) is a bit weak.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-3236717"}, {"subject": "[Bug 167] explanation of identified, identifiable, and linke", "content": "Review of what has changed:\n\n1) Discussion of other laws in the context of \"identifiable\" I'm \nstill checking with PIPEDA experts to make sure that the reference to \nCanadian law is correct.\n2) Removed headers and all mention of the word \"storage\"\n3) Added a final sentence about \"linked\" to make options clear to \ndata collectors\n4) Made small changes in the data by type section to make it clear \nthat it is really about \"identifiers\"\n\nAri\n\n\n------\n\n\nIdentity Definitions in the P3P Specification\n\nIn privacy regulations, guidelines and papers about privacy a variety \nof terms are used to describe data that identifies an individual to \nvarying degrees.\n\nThe European Union Directive defines \"an identifiable person\" as \"one \nwho can be identified, directly or indirectly, in particular by \nreference to an identification number or to one or more factors \nspecific to his physical, physiological, mental, economic, cultural \nor social identity.\"  The Directive also states that in determining \nwhether a person is identifiable \"account should be taken of all the \nmeans likely reasonably to be used either by the controller or by any \nother person to identify the said person; whereas the principles of \nprotection shall not apply to data rendered anonymous in such a way \nthat the data subject is no longer identifiable.\"\n\nIn Australia, \"personal information\" is information about an \nindividual who can be identified, or whose identity could be \nreasonably ascertained.\"  In Canada \"personal information\" means \ninformation about an identifiable individual. In the United States, \ndifferent sectors have different standards for identifiability of \ndata. Similarly, in many other policy documents, terms such as \n\"personally identifiable information (PII)\" are often not defined or \nthe cause for heated debate.\n\nThe P3P Specification Working Group has taken the view point that \nmost information referring to an individual is \"identifiable\" in some \nway.  As with other important areas of the specification, the goal of \nthe working group was to allow for a wide variety of understandings \nof identity in order to allow data collectors to best express their \npolicy and users to make choices based on a definition of identity \ninformation that is important to them. (1)\n\n\n\"Identified\" Data\n\nThe most common term in the specification is \"identified data\" and \nfocuses on how the information can be or is being used.\n\n\"Identified data\" is information that reasonably can be used by the \ndata collector to identify an individual.  Admittedly, this is a \nsomewhat subjective standard.  For example, a data collector storing \nInternet Protocol (IP) addresses  (which can be created dynamically \nor could be static and therefore tied to a particular computer used \nby a single individual) should consider the IP address \"identified \ndata\" only when an attempt is made to tie the exact addresses to past \nrecords or work with others to identify the specific individual or \ncomputer over a long period of time.  In the more common case, where \ndata collectors use IP addressing information in the aggregate or \nmake no attempt to tie the IP address to a specified individual or \ncomputer over a long period of time, IP addresses are not considered \nidentified even though it is possible for someone (eg, law \nenforcement agents with proper subpoena powers) to identify the \nindividual based on the stored data.\n\nAs mentioned above, in the P3P context, any data that can be used \nreasonably by a data controller or any other person to identify an \nindividual is considered to be identifiable data. The P3P \nspecification uses the term \"identified\" to describe a subset of this \ndata that can be reasonably used by a data collector *without \nassistance from other parties* to identify an individual.\n\n\"Non-Identifiable\" and \"Linked\" Data\n\nThe working group also felt that data collectors should be able \nacknowledge when they make specific attempts to anonymize information.\n\nThe term \"non-identifiable\" data refers to efforts made specifically \nto de-identify data.  For example, a data collector collecting and \nstoring IP addresses but not using them should NOT call this data \n\"non-identifiable\" even in the common case where they have no plans \nto identify an actual individual or computer. However, if a Web site \ncollects IP addresses, but actively deletes all but the last four \ndigits of this information in order to determine short term use, but \ninsure that a particular individual or computer cannot be \nconsistently identified, then the data collector can and should call \nthis information \"non-identifiable.\"  Also, non-identifiable can be \nused in cases where no information is being collected at all.  Since \nmost Web servers are designed to keep Web logs for maintenance, this \nwould most likely mean that the data collector has taken specific \nefforts to ensure the anonymity of users.\n\nUnder the above definitions, a lot of information could be \n\"identifiable\" (not specifically made anonymous), but not \n\"identified\" (reasonably able to be tied to an individual or \ncomputer).\n\nSimilarly, the term \"linked\" refers to how information is being used \nin connection with a cookie. All data in a cookie or linked to a \nparticular user must be disclosed in the cookie's policy. Using the \nterminology above, if the data collector collects \"identifiable\" \ninformation about the user it is generally \"linked\" data. For \nexample, if the data collector stores a login name in a file \nassociated with a persistent cookie and the login name is linked to \npersonal data, the cookie is clearly \"linked.\"\n\nIn less clear cut example, if the data collector ties the cookie to a \nspecific order id in a flat file and that order id is tied to \npersonal information in a related file, the cookie would be linked to \nall of the relational data unless specific precautions have been \ntaken to ensure that a data operator with access to the relational \ndata cannot access the flat cookie data and vice versa.\n\nIn other words, a data collector must: collect no personal \ninformation; take active steps to make sure that information \nreferring to a specific individual cannot be identified; or must use \nthe \"linked\" tag.\n\n\nIdentifiers\n\nThe Working Group decided against an identified or identifiable label \nfor particular types of data. However, user agent implementers have \nthe option of assigning these or other labels themselves and building \nuser interfaces that allow users to make decisions about web sites on \nthe basis of how they collect and use certain types of data.\n\nThe Working Group felt that different user agent implementations \ncould be created to focus on different concerns around data type. \nTherefore, the working group enabled the creation of a robust data \nschema including broad categories of information that may be \nconsidered sensitive by certain user groups.  The Working Group hopes \nthat a diverse set of user agents will be created to allow users the \nability to make identity decisions based on specific collections and \ntypes of collects if they desire to do so.  For example, a user agent \ncould allow users to opt to be prompted when medical or financial \nidentifier is being collected, independent of how that information is \nbeing used.\n\n(1)   More information on the debate and the definitions can be found \nin Lorrie Faith Cranor's book Web Privacy with P3P, O'Reilly, 2002.\n\n\n\n\n\n-- \n------------------------------------\nAri Schwartz\nAssociate Director\nCenter for Democracy and Technology\n1634 I Street NW, Suite 1100\nWashington, DC 20006\n202 637 9800\nfax 202 637 0968\nari@cdt.org\nhttp://www.cdt.org\n------------------------------------\n\n\n\n", "id": "lists-017-3245506"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Ari, \n\nit is much better than the first draft. I like the introduction. There\nare still some mixings in the text, so see comments inline..\n\n\nOn Mon, Aug 18, 2003 at 01:38:06PM -0400, Ari Schwartz wrote:\n> \"Identified\" Data\n> \n> The most common term in the specification is \"identified data\" and \n> focuses on how the information can be or is being used.\n\nThe phrase above is the kind of confusion that we wanted to avoid.\n\"identified\" is a property of data, not a 'use' or what people intend to\ndo with it. The term 'use' belongs to the <purpose> - section of the\nspecification where we don't use the term identified. So I suggest we\ntake the lesson from the UA TF and alter the phrase to:\n\nhe most common term in the specification is \"identified data\" and\nfocuses on whether a service knows your identity. \n> \n> \"Identified data\" is information that reasonably can be used by the \n> data collector to identify an individual.  \n\ninformation that reasonably can be used by the datacollector \nto identify an individual is \"identifiable data\". Identified means that\nthe identification already happened. This especially important if you\nremember the worries about somebody coming up and wanting access to all\nthe info on him in the logs of a large portal site. We decided to say\nthat if information is well-organized and they know you, they should\ngive access. But we did not want to express access to some plain\nlog-info, where the pseudonyms (IP e.g) were not resolved.\n\nSuggestion: \n\n\"Identified data\" is information in a record or profile and already tied\nto an individual. \n\n\n> Admittedly, this is a  somewhat subjective standard.  \n\n> For example, a data collector storing \n> Internet Protocol (IP) addresses  (which can be created dynamically \n> or could be static and therefore tied to a particular computer used \n> by a single individual) should consider the IP address \"identified \n> data\" only when an attempt is made to tie the exact addresses to past \n> records or work with others to identify the specific individual or \n> computer over a long period of time.  \n\nAri, the attempt can happen anytime. If I use the identifiable data via\nadditional processing to identify an individual, this is purpose of\nidentification. The collection happened earlier and access has nothing\nto do with it. So I'm a bit unhappy with your example. \n\nSuggestion (depending on my definition above)\n\nFor example, a data collector storing Internet Protocol (IP) addresses\n(which can be created dynamically or could be static and therefore tied\nto a particular computer used by a single individual) should consider\nthe IP address \"identified data\" only when this data is added to the\nrecord or profile of a specific individual. \n\n> In the more common case, where \n> data collectors use IP addressing information in the aggregate or \n> make no attempt to tie the IP address to a specified individual or \n> computer over a long period of time, IP addresses are not considered \n> identified even though it is possible for someone (eg, law \n> enforcement agents with proper subpoena powers) to identify the \n> individual based on the stored data.\n\nThe rest is ok, good work\n\nRigo\n\n\n\n", "id": "lists-017-3260962"}, {"subject": "20 August spec call cancelled, next call 27 Augus", "content": "I tried to send this yesterday but it never got posted. In the mean \ntime I see I had my dates wrong anyway.... 20 August spec call is \ncancelled... next call is 27 August.\n\nLorrie\n\n\nBegin forwarded message:\n\n> From: Lorrie Cranor <lorrie@research.att.com>\n> Date: Tue Aug 19, 2003  1:09:13  PM America/New_York\n> To: public-p3p-spec@w3.org\n> Subject: 19 August spec call cancelled, next call 26 August\n>\n> In the absence of concrete proposal on the grouping mechanisms or \n> documentation of the performance issues or follow up on the legal \n> issues, I don't think we have much to discuss, so I am canceling the \n> call this week. Our next next P3P spec WG call will be on Wednesday, \n> August 26 at 11 am US Eastern.\n>\n> In the mean time....\n>\n> Please comment on Ari's latest identified/identifiable draft\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0024.html\n>\n> Please comment on the user agent TF's plain English translation\n> http://www.w3.org/P3P/2003/p3p-translation.htm\n> and Rigo's comments\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0018.html\n>\n> I would like to get the above more or less resolved via email so that \n> on Aug 26 we can discuss the other items, assuming proposals are \n> received.\n>\n> Lorrie\n>\n\n\n\n", "id": "lists-017-3271491"}, {"subject": "19 August spec call cancelled, next call 26 Augus", "content": "In the absence of concrete proposal on the grouping mechanisms or \ndocumentation of the performance issues or follow up on the legal \nissues, I don't think we have much to discuss, so I am canceling the \ncall this week. Our next next P3P spec WG call will be on Wednesday, \nAugust 26 at 11 am US Eastern.\n\nIn the mean time....\n\nPlease comment on Ari's latest identified/identifiable draft\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0024.html\n\nPlease comment on the user agent TF's plain English translation\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\nand Rigo's comments\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0018.html\n\nI would like to get the above more or less resolved via email so that \non Aug 26 we can discuss the other items, assuming proposals are \nreceived.\n\nLorrie\n\n\n\n", "id": "lists-017-3281003"}, {"subject": "AGENDA: 27 Aug P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, August 27, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Patrick Hung\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n2. Discussion of comments on P3P plain English translation -- see\n    comments in red at http://www.w3.org/P3P/2003/p3p-translation.htm\n    We will also discuss comments in green if I get proposals from\n    Dave prior to the call.\n\n3. Discuss Jeremy's grouping draft and related proposals - Bugzilla 169\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=169\nNEED REVISED PROPOSAL BEFORE CALL\n\n4. Discuss performance issues (raised by Jeremy)\nNEED PERFORMANCE DOCUMENT BEFORE CALL\n\n5. Set date for next call (Sept 3?)\n\n\n\n", "id": "lists-017-3288644"}, {"subject": "stampley's proposals for disputes and remedie", "content": "Dave is on vacation with limited Internet access right now but he sent \nthe following proposals for changes to the spec definitions of disputes \nand remedies elements and subelements for me to pass on to everyone. We \ncan discuss some today if there is time but will plan on having a \nlonger discussion next week.\n\n\nDISPUTES\n\nPROPOSAL:  The service-provider offers or acknowledges the following \nways for a user to resolve disputes about the service-provider's \nprivacy practices or alleged protocol violations.\n\nCOMMENT 1:  I stil have trouble understanding what \"protocol \nviolations\" is supposed mean to users.\n\nCOMMENT 2:  I agree with the position that, as a general matter, users \nand websites can elect a dispute resolution procedure by contract.  But \nI don't think the DISPUTES element & subelements should purport to \ncreate such a contract.\n\nREASONS:  It seems to me that P3Pstatements constitute unilateral \nassertionsby a website on how the site agrees to be bound.  P3P \nstatements are not well suited to serve as assertions by a website on \nhow its visitors will be bound.  A website's statements about rules \nthat it asserts will bind its visitors usually appear in a Terms & \nConditions section (e.g., \"By using this site you agree that any \ndisputes will be submitted tobinding arbitrations...; any legal actions \nwill be subject to the exclusive jurisdiction of the state andfederal \ncourts in the State of California...\" etc.).\n\nI propose that the DISPUTES & REMEDIES subelements:   (a) Allow a site \nto express its unilateral commitment to honor the indicated dispute \nresolution & redress mechanisms.  Saying that the site \"agrees to\" a \ngiven resolution method is clearer than the current wording that the \nuser \"may\" avail herself of a given procedure.  or (b) Allow a site to \nexpress its opinion of what it is required to do to fulfill a given \nlegal obligation.\n\nBoth of these concepts avoid putting the site in the position of \npresuming to express exclusive options or to offer legal advice-- both \nof which are perilous for the site.\n\n\n\n\"service\"\n\nPROPOSAL:  The service-provider's customer service reprseentativei s \navailable to help resolve users' disputes regarding the use of \ncollected data.  The description MUST include information about how to \ncontact customer service.\n\nQUESTION:  Is there a different bewteen \"web site,\" \"service,\" \n\"service-provider,\" and \"company\" in the vocabulary?\n\n\n\n\"independent\"\n\nPROPOSAL:  The service-provider is willing to be bound by the authority \nof an independent organization for resolution of disputes regarding the \nuse of collected data.  Thedescription MUST include information about \nhow to contact the third-party organization.\n\n\n\n\"court\"\n\nPROPOSAL:  [Strike this subelement]\n\nCOMMENT:  As noted above, I believe the spec should enable sites to \ndisclose what they bring to the table as opposed to encouraging them to \ninterpret for users the rights that other authorities grant to the \nusers.  I propose that this subelement be stricken.\n\n\n\n\"law\"\n\nPROPOSAL:  The service-provider acknowledges or expresses its opinion \nthat the indicated laws may affect users' rights or options for \nresolving disputes about the collected data.  Indicated laws MUST be \nreferenced in the description.\n\nCOMMENT:  In the original wording, from a corporate counselor persepct, \nI would advise a client to avoid usingthe DISPUTES element.  From an \nAAG perspective, if I saw that a company had listed a value for a \nDISPUTES subelement and omitted a material consumer alternative, I \nwould have to question whether the company had committed consumer fraud \nby misleading consumers, even if unintentionally.\nThe proposed language permits an expression thatI would be willing to \nendorse if I were representinga web-facing company.\n\nUnder current laws, for example, it is not a stretch to say that \nuniversities, banks, loan companies, mortgage lenders, loan brokers, \nsome travel agents, sellers and manufacturers of vehicles, boats, RVs, \netc. should anticipate including the following laws in \"DISPUTES:law\":  \nGramm-Leach-Bliley Financial Services Modernization Act (and the \nrelated Federal Trade Commission or other federal agency Privacy & \nSafeguards Rules); HIPAA; Fair Credit Reporting Act; Personal \nInformation Protection and Electronic Documents Act (Canada, eff. \n1/1/04); USA Patriot Act secs. 326, 352; Office of Foreign Asset \nControl transaction reporting regulations; Cailfornia SB 1386 (consumer \nnotification of unauthorized access); federal and state Drivers Privacy \nProtection Acts; federal and state telemarketing laws; federal and \nstate Unfair and Deceptive Acts & Practices laws; European Union Data \nProtection Directive; US Department of Commerce Safe Harbor; and the \nTelephone Consumer Protection Act.\n\n\nREMEDIES\n\nPROPOSAL:  The service-provider offers or acknowledges that the \nfollowing remedies may apply in case of the service-provider's breach \nof its privacy policy or in case of a protocol violation; users may \nalso be legally entitled to pursue remedies not listed here.\n\nCOMMENT:  I agree that a company's commitment to redress (provided it \nis not presented as an exclusive remedy) can add value to a privacy \npolicy.  But I respectfully disagree with the position that, without an \nexpression of redress, a P3P policy is not meaningful.  Redress exists \nwhether or not it is acknowledged in a privacy policy.  The fact that \nprivacy policies have served as the chief exhibits in enforcement \nefforts to date demonstrates that privacy policies have meaning without \nspecifying redress.\n\n From an enforcement point of view, I wouldn't blame a company for \navoiding the REMEDIES element if the spec's wording increased the \nlikelihood that the company could unwittingly perpetrate a material \nomission, as I noted in comments on the DISPUTES element.\n\n From a corporate counsel point of view, I think most corporate \ncounselors would consider themselves duty-bound to advise their clients \nagainst specifying REMEDIES, since prospectively binding the company to \nredress without some other legal mandate or business incentive might \nconstitute a disservice to shareholders.\n\n\n\n\"correct\"\n\nPROPOSAL:  The service-provider will attempt to rectify errors or \nconsequences arising from a breach of the privacy policy.\n\nQUESTION:  Has any company indicated that it would actually be willing \nto make the broad, prospective commitment expressed in the current spec \nlanguage?\n\n\n\n\"money\"\n\nPROPOSAL 1:  [Change the subelement name to \"compensate.\"]\nPROPOSAL 2:  If the service-provider violates its privacy policy, it \nwill compensate the individual according to the terms specified in the \nhuman-readable privacy policy.\n\n\n\n\n\"law\"\n\nPROPOSAL:  [For reasons cited above for \"DISPUTES:court\", and because \n\"REMEDIES:law\" would duplicate the values assigned to \"DISPUTES:law,\" I \npropose that the \"law\" subelement be stricken.  If retained, I propose \nuse of language similar to that proposed for \"DISPUTES:law\".]\n\n\n\n", "id": "lists-017-3296394"}, {"subject": "P3P beyond HTT", "content": "Referring to the spec call on 13 August 2003:\n\n  - P3P beyond HTTP - Patrick Hung\n    - Nothing new to report.  Waiting for comments.\n    - WG comments not yet provided to Liberty\n    - ACTION: TF to decide what we want to propose for inclusion in the\n      1.1 spec\n\nAs the P3P 1.0 spec is described in the context of HTTP, it may be\nappropriate to propose Web \nservices protocols UDDI, WSDL and SOAP in the P3P 1.1 spec. In particular,\nthe P3P 1.0 spec \ndoes mention to have other protocols in Section 2.5.\n\nThus, I would suggest to describe P3P policy reference files in the context\nof WSDL in the first place. \nIt is because WSDL is definitely needed in both \"publish\" and \"direct\npublish\" in the Web services model. \nIn addition, a requestor should check the WSDL document (at least once\nbefore his first time to bind to a \nspecific Web service) via a service locator (acts like a user agent in P3P).\nFurthemore, those <include/> \nand <exclude/> elements in P3P 1.0 spec can also be used to define which Web\nmethods in a Web service \nis covered by P3P policies and etc.\n\nIf all these suggestions sound ok, could we propose to describe this\nscenario into Section 2.5 or even a new \nsection in 1.1 spec?\n\nAny comment/suggestion?\n\nPatrick.\n\n\n\n", "id": "lists-017-3310126"}, {"subject": "P3P meeting attendanc", "content": "The attendance on working group conference calls has been poor lately, \nand a number of folks who have committed to various action items have \nnot been following through on them. This working group has an ambitious \nschedule, and in order to not fall behind we need everybody's \nparticipation and cooperation. I have not been enforcing the official \nparticipation rules because I realize it is summer and a lot of folks \nare on vacation. However, if things do not improve come fall, we will \nenforce these rules, as specified in our charter [1]:\n\n   In order to maintain good standing status, WG members must\n   consistently participate in two out of three working group meetings\n   (both remote and face-to-face), take on working group assignments,\n   and complete working group assignments in a timely fashion. These\n   criteria may be relaxed at the discretion of the WG Chair and Team\n   Contact for WG members who are contributing to the success of the\n   working group but are frequently unable to participate in meetings\n   due to funding, scheduling, or language issues.\n\nIf you cannot participate in a WG call, please let me know in advance, \nand try to send your comments on the agenda items we will be \ndiscussing. If you know now that you don't really have time to \nparticipate in this WG and would like to be taken off the mailing list, \nlet us know that too (if you would like to stay on the interest group \nmailing list but be removed from the working group mailing list that is \nan option too, just let us know). If you can find someone else in your \norganization to replace you, so much the better.\n\nOur charter [1] requires us to publish a last call working draft by \nJanuary, and I intend to stick with this schedule. This means that any \nissues that are not resolved by January will not make it into P3P 1.1. \nI am pushing to get as many issues as possible resolved before I go on \nmaternity leave in a few weeks. Rigo will be chairing the group in my \nabsence for most of the rest of the year and will try to get as many \nadditional issues as possible resolved. But if people are not proactive \nabout stepping forward with proposals on the issues they care about, \nthese issues will not be addressed in P3P 1.1.\n\nWe have actually made a lot of progress on P3P 1.1 and I really \nappreciate the efforts of those who have contributed. But I want to \nmake sure that we keep up the momentum and continue to make good \nprogress.\n\nThanks!\n\nLorrie\n\n[1] http://www.w3.org/P3P/Group/Specification/1.1/01-spec-charter.html\n\n\n\n", "id": "lists-017-3318383"}, {"subject": "MINUTES: 27 August P3P spec cal", "content": "Minutes of the 27 August 2003 P3P specification working group call\n\nPresent:\nLorrie\nPatrick\nRigo\n\nRegrets:\nAri\nDave\n\n1. Task force reports\n\nPatrick reported that the P3P beyond HTTP task force was working on \ntrying to figure out what parts of their work should go in P3P 1.1. \nRigo was concerned that the XML element binding stuff was not in the \ncurrent draft. Rigo and Patrick will talk face-to-face in Sydney. Rigo \nwill also try to get Marc L. involved.\n\n2. Discussion of comments on P3P plain English translation -- see\n    comments in red at http://www.w3.org/P3P/2003/p3p-translation.htm\n\nWe discussed the remaining comments in red and propose the following \nchanges. If anyone has any objections please raise them BEFORE next \nweek's call and we will discuss further, otherwise these changes will \nbe adopted.\n\nChange opturi from \"Find out how to opt-out at\" to \"Find out how to \nopt-in or opt-out at\"\n\nChange ACCESS=all from \"We give you access to all of our information \nthat identifies you\" to \"We give you access to all of our information \nidentified with you\"\n\nChange ACCESS=contact-and-other from \"We give you access to your \ncontact information and some of our other information that identifies \nyou\" to \"We give you access to your contact information and some of our \nother information identified with you\"\n\nAdd \"Customer service\" as default wording for DISPUTES=service if site \ndoes not provide description\n\nAdd \"Independent organization\" as default wording for \nDISPUTES=independent if site does not provide description\n\nAdd \"Legal complaint\" as default wording in DISPUTES=court if site does \nnot provide description\n\nAdd \"Law\" as default wording in DISPUTES=law if site does not provide \ndescription\n\nChange PURPOSE=current from \"For the purpose we indicated when you \nprovided the information\" to \"To provide the service you requested\"\n\nChange PURPOSE=individual-analysis from \"To do research and analysis \nthat uses information which identifies you\" to \"To do research and \nanalysis that uses information about you\"\n\nChange PURPOSE=individual-decision from \"To make decisions that \ndirectly affect you, for example to recommend products or services \nbased on your previous purchases\" to \"To make decisions that directly \naffect you using information about you, for example to recommend \nproducts or services based on your previous purchases\"\n\nNote that we also discussed Deirdre's comment that RECIPIENTS=same does \nnot make clear that the recipient might use the data for an unrelated \npurpose. However, we decided not to propose any changes to recipients \nas this element does not describe data usage.\n\nWe will discuss the remaining comments (those in green) next week.\n\n3 and 4. We could not discuss items 3 and 4 because Jeremy did not \nsubmit proposals and was not on the call.\n\n5. Our next call will be on Wednesday, September 3. We will discuss \ndisputes and remedies issues and Ari's identifiable/identified draft. \nWe are still waiting for grouping proposal and documentation of \nperformance issues from Jeremy.\n\n\n\n", "id": "lists-017-3327274"}, {"subject": "Re: P3P beyond HTT", "content": "On Thu, Aug 28, 2003 at 12:57:35AM +1000, Patrick.Hung@csiro.au wrote:\n>     - WG comments not yet provided to Liberty\n\nThose comments were now provided, see on the member-only list\n\n>     - ACTION: TF to decide what we want to propose for inclusion in the\n>       1.1 spec\n> \n> As the P3P 1.0 spec is described in the context of HTTP, it may be\n> appropriate to propose Web services protocols UDDI, WSDL and SOAP in\n> the P3P 1.1 spec. In particular, the P3P 1.0 spec does mention to have\n> other protocols in Section 2.5.\n\nYes, the beyond HTTP was already discussed earlier and we didn't wanted\nto preclude other uses. For WSDL, comments from Hugo are pending. I will\ntry to get those soon. For SOAP, we might want some help from the XML\nProt Group in constructing the binding. Perhaps Mark Nottingham is able\nto help us a bit.\n> \n> Thus, I would suggest to describe P3P policy reference files in the\n> context of WSDL in the first place. \n> It is because WSDL is definitely needed in both \"publish\" and \"direct\n> publish\" in the Web services model.  In addition, a requestor should\n> check the WSDL document (at least once before his first time to bind\n> to a specific Web service) via a service locator (acts like a user\n> agent in P3P).  Furthemore, those <include/> and <exclude/> elements\n> in P3P 1.0 spec can also be used to define which Web methods in a Web\n> service is covered by P3P policies and etc.\n\nI think it is definitely a good idea to look into WSDL bindings. Isn't\nthis what is already contained in the Task Force WD?\n> \n> If all these suggestions sound ok, could we propose to describe this\n> scenario into Section 2.5 or even a new section in 1.1 spec?\n\nWe still have to discuss advantages and disadvantages of having a\nstandalone document vs. integration into the 1.1 Spec (e.g. conformance)\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-3336891"}, {"subject": "RE: P3P beyond HTT", "content": "Hi Rigo,\n\n> Yes, the beyond HTTP was already discussed earlier and we didn't wanted\n> to preclude other uses. For WSDL, comments from Hugo are pending. I will\n> try to get those soon. For SOAP, we might want some help from the XML\n> Prot Group in constructing the binding. Perhaps Mark Nottingham is able\n> to help us a bit.\n\nThat would be great. I will keep on thinking along this line. In fact, I am\non vacation from 29/8 to 7/9. However, I will try my best to attend next\nweek's P3P call.\n\n> I think it is definitely a good idea to look into WSDL bindings. Isn't\n> this what is already contained in the Task Force WD?\n\nYes, you are right. However, I think that we should polish the content in a\nformat that can be merged into the P3P 1.1 spec.\n\n> We still have to discuss advantages and disadvantages of having a\n> standalone document vs. integration into the 1.1 Spec (e.g. conformance)\n\nI am looking forward to discussing with you on Sept 9. Have a nice trip.\n\nCheers,\n\nPatrick.\n\n\n\n", "id": "lists-017-3345607"}, {"subject": "RE: Grouping Statements Proposa", "content": "I think that these could just be one proposal once the paradigms are\ncombined.\n\nCan we just deprecate the opt-in, opt-out, and required attributes and\nsay that if used the agent with take precedence with the consent tag.\n\nJeremy\n\n-----Original Message-----\nFrom: Matthias Schunter [mailto:mts@zurich.ibm.com] \nSent: Monday, August 11, 2003 6:13 AM\nTo: Lorrie Cranor; Jeremy Epling\nCc: public-p3p-spec@w3.org\nSubject: Re: Grouping Statements Proposal\n\nHi!\n\nThe proposal looks good. Once Jerry contacts me, I'll work with him to \nresolve the remaining issues. Some initial ideas/remarks:\n- the opt-in or opt-in elements inside all elements of an opt-in/out-out\n\ngroup where included\n   to preserve backward compatibility of the semantics.\n- The issue of the OURS/CURRENT may be resolved by defining that they \ncannot be included in an\n   opt-in/opt-out group.\n- Does it makes sense to use \"required\" instead of \"no-group\" or do you \nenvision that with\n   consent=\"no-group\", one can nevertheless have opt-in's and out's\ninside?\n\nRegards,\n  matthias\n\n\n\n\nAt 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n\n>We discussed  this on today's call, minutes should be forthcoming. My \n>quick summary is:\n>\n>- combining these two group concepts probably makes sense\n>- we probably want an extension that looks something like the following\n\n>that can be inserted into all statement's that belong to a group:\n>\n><STATEMENT>\n><EXTENSION>\n>   <STATEMENT-GROUP id = \"fflyer\" />\n></EXTENSION>\n>. . .\n></STATEMENT>\n>\n>Then somewhere else in the policy\n><EXTENSION\n>   <STATEMENT-GROUP-DEF id=\"fflyer\"\n>   short-description=\"Frequent Flyer Club\"\n>   consent = \"opt-in\" />\n></EXTENSION>\n>\n>Some groups of statements might not be consent groups, in which case\nthey \n>might use an attribute like consent = \"no-group\" (which might be the\ndefault).\n>\n>There are also some concerns about consent group that need to be worked\n\n>out. In Mathias' proposal it says that all PURPOSE and RECIPIENT\nelements \n>in a group have to have the same required attribute. But ours and\ncurrent \n>are special cases that don't have this attribute. This needs to be \n>accounted for (the example in Mathias' draft is actually incorrect\nbecause \n>of this). Also we need to be clear on how to handle errors. What if \n>someone uses consent group but then uses different required attributes \n>(which is incorrect)? Does that invalidate the policy? Perhaps if that \n>happens the user agent should treat it as if it is consent = \"no-group\"\n?\n>\n>In any case, Jeremy is going to put together a more specific proposal\non \n>this grouping. Mathias, it would be great if you could work with him on\n\n>the consent aspect.\n>\n>Lorrie\n>\n>\n>On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n>\n>>\n>>Hi Jeremy,\n>>\n>>thanks for your design. I feel that grouping statements is a good\nidea.\n>>\n>>The actual syntax for grouping is elaborated in our earlier draft on \n>>consent choices:\n>>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>>\n>>I feel that grouping statements is a good idea for multiple purposes.\n>>Therefore, I feel that we should have a general group mechanism where \n>>each group should have multiple properties:\n>>- opt-in opt-out or always (from consent choices)\n>>   syntactically this can be implicit: either all statements are \n>> always/opt-in, or opt-out.\n>>- target (something specifying whether it's the ebay or amazon part)\n>>   The target is something that might be useful to add to your\nproposal.\n>>   I don't know how to express this in a nice syntax.\n>>\n>>Why don't we merge both proposals into a \"grouping statements\"\nproposal?\n>>\n>>Regards,\n>>\n>>matthias\n>>\n>>\n>>\n>>At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>>\n>>>Below are the basics of my proposal for statement grouping.\n>>>\n>>>\n>>>\n>>>Problems\n>>>    * Policies are not relevant to how a user interacts with the site\n>>>        * Users don t know what part of a P3P policy applies to them\nand \n>>> there activities on a site\n>>>        * Users understand scenarios of how they interact with a site\n\n>>> better than a series of statements related to a feature of the site\n>>>    * Policy authors have to make highest common denominate policies \n>>> that could look more privacy impacting than they are for most users\n>>>\n>>>\n>>>Goals\n>>>    * Provide a method for showing the sections of the P3P policy\nthat \n>>> apply to how a user interacts with the site/service\n>>>    * Allow an easy way for policy authors to describe what sections\nof \n>>> their P3P policy apply to different user interaction with their\nsite/service\n>>>\n>>>\n>>>Scenarios\n>>>    * User browses to ebay and views the P3P policy. They are able to\n\n>>> skip to the buyer section of the P3P policy since that is what\napplies to them.\n>>>    * User browses to amazon and views the P3P policy. The can see\nthat \n>>> since they are not logged in less information is collected about\nthem.\n>>>\n>>>\n>>>Design\n>>>\n>>>\n>>>\n>>>The P3P author decides the name of the statement group which is used\nin \n>>>the display of the agent when it translates the nodes to natural\nlanguage.\n>>>\n>>>\n>>>\n>>><Statement>\n>>>\n>>>             <extention>\n>>>\n>>>                         <grouping-id>Member</grouping-id>\n>>>\n>>>             </extention>\n>>>\n>>><statement>\n>>>\n>>>\n>>>\n>>>Issues\n>>>    * Do agents now show conflicts per grouping?\n>>>\n>>>\n>>>Jeremy Epling\n>>>Windows - Privacy and Trust UX\n>>>\n>>><BLOCKED::>wpihelp - where to go for all your privacy questions\n>>>\n>>\n>>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-3353279"}, {"subject": "RE: Grouping Statements Proposa", "content": "Attached is my first try at modifying Matthias's proposal to incorporate\nmine.\n\nFeedback is welcomed,\n\nJeremy\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n[mailto:public-p3p-spec-request@w3.org] On Behalf Of Jeremy Epling\nSent: Thursday, August 28, 2003 12:40 PM\nTo: Matthias Schunter; Lorrie Cranor\nCc: public-p3p-spec@w3.org\nSubject: RE: Grouping Statements Proposal\n\n\nI think that these could just be one proposal once the paradigms are\ncombined.\n\nCan we just deprecate the opt-in, opt-out, and required attributes and\nsay that if used the agent with take precedence with the consent tag.\n\nJeremy\n\n-----Original Message-----\nFrom: Matthias Schunter [mailto:mts@zurich.ibm.com] \nSent: Monday, August 11, 2003 6:13 AM\nTo: Lorrie Cranor; Jeremy Epling\nCc: public-p3p-spec@w3.org\nSubject: Re: Grouping Statements Proposal\n\nHi!\n\nThe proposal looks good. Once Jerry contacts me, I'll work with him to \nresolve the remaining issues. Some initial ideas/remarks:\n- the opt-in or opt-in elements inside all elements of an opt-in/out-out\n\ngroup where included\n   to preserve backward compatibility of the semantics.\n- The issue of the OURS/CURRENT may be resolved by defining that they \ncannot be included in an\n   opt-in/opt-out group.\n- Does it makes sense to use \"required\" instead of \"no-group\" or do you \nenvision that with\n   consent=\"no-group\", one can nevertheless have opt-in's and out's\ninside?\n\nRegards,\n  matthias\n\n\n\n\nAt 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n\n>We discussed  this on today's call, minutes should be forthcoming. My \n>quick summary is:\n>\n>- combining these two group concepts probably makes sense\n>- we probably want an extension that looks something like the following\n\n>that can be inserted into all statement's that belong to a group:\n>\n><STATEMENT>\n><EXTENSION>\n>   <STATEMENT-GROUP id = \"fflyer\" />\n></EXTENSION>\n>. . .\n></STATEMENT>\n>\n>Then somewhere else in the policy\n><EXTENSION\n>   <STATEMENT-GROUP-DEF id=\"fflyer\"\n>   short-description=\"Frequent Flyer Club\"\n>   consent = \"opt-in\" />\n></EXTENSION>\n>\n>Some groups of statements might not be consent groups, in which case\nthey \n>might use an attribute like consent = \"no-group\" (which might be the\ndefault).\n>\n>There are also some concerns about consent group that need to be worked\n\n>out. In Mathias' proposal it says that all PURPOSE and RECIPIENT\nelements \n>in a group have to have the same required attribute. But ours and\ncurrent \n>are special cases that don't have this attribute. This needs to be \n>accounted for (the example in Mathias' draft is actually incorrect\nbecause \n>of this). Also we need to be clear on how to handle errors. What if \n>someone uses consent group but then uses different required attributes \n>(which is incorrect)? Does that invalidate the policy? Perhaps if that \n>happens the user agent should treat it as if it is consent = \"no-group\"\n?\n>\n>In any case, Jeremy is going to put together a more specific proposal\non \n>this grouping. Mathias, it would be great if you could work with him on\n\n>the consent aspect.\n>\n>Lorrie\n>\n>\n>On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n>\n>>\n>>Hi Jeremy,\n>>\n>>thanks for your design. I feel that grouping statements is a good\nidea.\n>>\n>>The actual syntax for grouping is elaborated in our earlier draft on \n>>consent choices:\n>>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>>\n>>I feel that grouping statements is a good idea for multiple purposes.\n>>Therefore, I feel that we should have a general group mechanism where \n>>each group should have multiple properties:\n>>- opt-in opt-out or always (from consent choices)\n>>   syntactically this can be implicit: either all statements are \n>> always/opt-in, or opt-out.\n>>- target (something specifying whether it's the ebay or amazon part)\n>>   The target is something that might be useful to add to your\nproposal.\n>>   I don't know how to express this in a nice syntax.\n>>\n>>Why don't we merge both proposals into a \"grouping statements\"\nproposal?\n>>\n>>Regards,\n>>\n>>matthias\n>>\n>>\n>>\n>>At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>>\n>>>Below are the basics of my proposal for statement grouping.\n>>>\n>>>\n>>>\n>>>Problems\n>>>    * Policies are not relevant to how a user interacts with the site\n>>>        * Users don t know what part of a P3P policy applies to them\nand \n>>> there activities on a site\n>>>        * Users understand scenarios of how they interact with a site\n\n>>> better than a series of statements related to a feature of the site\n>>>    * Policy authors have to make highest common denominate policies \n>>> that could look more privacy impacting than they are for most users\n>>>\n>>>\n>>>Goals\n>>>    * Provide a method for showing the sections of the P3P policy\nthat \n>>> apply to how a user interacts with the site/service\n>>>    * Allow an easy way for policy authors to describe what sections\nof \n>>> their P3P policy apply to different user interaction with their\nsite/service\n>>>\n>>>\n>>>Scenarios\n>>>    * User browses to ebay and views the P3P policy. They are able to\n\n>>> skip to the buyer section of the P3P policy since that is what\napplies to them.\n>>>    * User browses to amazon and views the P3P policy. The can see\nthat \n>>> since they are not logged in less information is collected about\nthem.\n>>>\n>>>\n>>>Design\n>>>\n>>>\n>>>\n>>>The P3P author decides the name of the statement group which is used\nin \n>>>the display of the agent when it translates the nodes to natural\nlanguage.\n>>>\n>>>\n>>>\n>>><Statement>\n>>>\n>>>             <extention>\n>>>\n>>>                         <grouping-id>Member</grouping-id>\n>>>\n>>>             </extention>\n>>>\n>>><statement>\n>>>\n>>>\n>>>\n>>>Issues\n>>>    * Do agents now show conflicts per grouping?\n>>>\n>>>\n>>>Jeremy Epling\n>>>Windows - Privacy and Trust UX\n>>>\n>>><BLOCKED::>wpihelp - where to go for all your privacy questions\n>>>\n>>\n>>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n\n\n\n\n\n\ntext/html attachment: 05-cc-changes-to-P3P.html\n\n\n\n\n", "id": "lists-017-3369414"}, {"subject": "RE: Grouping Statements Proposa", "content": "Hi Jerry,\n\nthanks for the update. I'll review it and comment/update it.\n\nThe reason why I did the mandatory opt-in was to preserve semantics:\n- The semantics of a P3P 1.1 and P3P 1.0 policy should be similar\n\nIf the semantics supersedes the opt-in/outs of 1.0 or if there must not be \nany opt-in/outs then it may happen that something is optional in 1.1 that \nis required in 1.0 or vice versa.\n\nRegards,\n  matthias\n\nAt 12:39 PM 8/28/2003 -0700, Jeremy Epling wrote:\n\n>I think that these could just be one proposal once the paradigms are\n>combined.\n>\n>Can we just deprecate the opt-in, opt-out, and required attributes and\n>say that if used the agent with take precedence with the consent tag.\n>\n>Jeremy\n>\n>-----Original Message-----\n>From: Matthias Schunter [mailto:mts@zurich.ibm.com]\n>Sent: Monday, August 11, 2003 6:13 AM\n>To: Lorrie Cranor; Jeremy Epling\n>Cc: public-p3p-spec@w3.org\n>Subject: Re: Grouping Statements Proposal\n>\n>Hi!\n>\n>The proposal looks good. Once Jerry contacts me, I'll work with him to\n>resolve the remaining issues. Some initial ideas/remarks:\n>- the opt-in or opt-in elements inside all elements of an opt-in/out-out\n>\n>group where included\n>    to preserve backward compatibility of the semantics.\n>- The issue of the OURS/CURRENT may be resolved by defining that they\n>cannot be included in an\n>    opt-in/opt-out group.\n>- Does it makes sense to use \"required\" instead of \"no-group\" or do you\n>envision that with\n>    consent=\"no-group\", one can nevertheless have opt-in's and out's\n>inside?\n>\n>Regards,\n>   matthias\n>\n>\n>\n>\n>At 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n>\n> >We discussed  this on today's call, minutes should be forthcoming. My\n> >quick summary is:\n> >\n> >- combining these two group concepts probably makes sense\n> >- we probably want an extension that looks something like the following\n>\n> >that can be inserted into all statement's that belong to a group:\n> >\n> ><STATEMENT>\n> ><EXTENSION>\n> >   <STATEMENT-GROUP id = \"fflyer\" />\n> ></EXTENSION>\n> >. . .\n> ></STATEMENT>\n> >\n> >Then somewhere else in the policy\n> ><EXTENSION\n> >   <STATEMENT-GROUP-DEF id=\"fflyer\"\n> >   short-description=\"Frequent Flyer Club\"\n> >   consent = \"opt-in\" />\n> ></EXTENSION>\n> >\n> >Some groups of statements might not be consent groups, in which case\n>they\n> >might use an attribute like consent = \"no-group\" (which might be the\n>default).\n> >\n> >There are also some concerns about consent group that need to be worked\n>\n> >out. In Mathias' proposal it says that all PURPOSE and RECIPIENT\n>elements\n> >in a group have to have the same required attribute. But ours and\n>current\n> >are special cases that don't have this attribute. This needs to be\n> >accounted for (the example in Mathias' draft is actually incorrect\n>because\n> >of this). Also we need to be clear on how to handle errors. What if\n> >someone uses consent group but then uses different required attributes\n> >(which is incorrect)? Does that invalidate the policy? Perhaps if that\n> >happens the user agent should treat it as if it is consent = \"no-group\"\n>?\n> >\n> >In any case, Jeremy is going to put together a more specific proposal\n>on\n> >this grouping. Mathias, it would be great if you could work with him on\n>\n> >the consent aspect.\n> >\n> >Lorrie\n> >\n> >\n> >On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n> >\n> >>\n> >>Hi Jeremy,\n> >>\n> >>thanks for your design. I feel that grouping statements is a good\n>idea.\n> >>\n> >>The actual syntax for grouping is elaborated in our earlier draft on\n> >>consent choices:\n> >>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n> >>\n> >>I feel that grouping statements is a good idea for multiple purposes.\n> >>Therefore, I feel that we should have a general group mechanism where\n> >>each group should have multiple properties:\n> >>- opt-in opt-out or always (from consent choices)\n> >>   syntactically this can be implicit: either all statements are\n> >> always/opt-in, or opt-out.\n> >>- target (something specifying whether it's the ebay or amazon part)\n> >>   The target is something that might be useful to add to your\n>proposal.\n> >>   I don't know how to express this in a nice syntax.\n> >>\n> >>Why don't we merge both proposals into a \"grouping statements\"\n>proposal?\n> >>\n> >>Regards,\n> >>\n> >>matthias\n> >>\n> >>\n> >>\n> >>At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n> >>\n> >>>Below are the basics of my proposal for statement grouping.\n> >>>\n> >>>\n> >>>\n> >>>Problems\n> >>>    * Policies are not relevant to how a user interacts with the site\n> >>>        * Users don t know what part of a P3P policy applies to them\n>and\n> >>> there activities on a site\n> >>>        * Users understand scenarios of how they interact with a site\n>\n> >>> better than a series of statements related to a feature of the site\n> >>>    * Policy authors have to make highest common denominate policies\n> >>> that could look more privacy impacting than they are for most users\n> >>>\n> >>>\n> >>>Goals\n> >>>    * Provide a method for showing the sections of the P3P policy\n>that\n> >>> apply to how a user interacts with the site/service\n> >>>    * Allow an easy way for policy authors to describe what sections\n>of\n> >>> their P3P policy apply to different user interaction with their\n>site/service\n> >>>\n> >>>\n> >>>Scenarios\n> >>>    * User browses to ebay and views the P3P policy. They are able to\n>\n> >>> skip to the buyer section of the P3P policy since that is what\n>applies to them.\n> >>>    * User browses to amazon and views the P3P policy. The can see\n>that\n> >>> since they are not logged in less information is collected about\n>them.\n> >>>\n> >>>\n> >>>Design\n> >>>\n> >>>\n> >>>\n> >>>The P3P author decides the name of the statement group which is used\n>in\n> >>>the display of the agent when it translates the nodes to natural\n>language.\n> >>>\n> >>>\n> >>>\n> >>><Statement>\n> >>>\n> >>>             <extention>\n> >>>\n> >>>                         <grouping-id>Member</grouping-id>\n> >>>\n> >>>             </extention>\n> >>>\n> >>><statement>\n> >>>\n> >>>\n> >>>\n> >>>Issues\n> >>>    * Do agents now show conflicts per grouping?\n> >>>\n> >>>\n> >>>Jeremy Epling\n> >>>Windows - Privacy and Trust UX\n> >>>\n> >>><BLOCKED::>wpihelp - where to go for all your privacy questions\n> >>>\n> >>\n> >>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n> >>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n> >>Fax +41-1-724 8953; More info at www.semper.org/sirene\n> >>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n> >\n>\n>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724-8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-3387300"}, {"subject": "Re: Grouping Statements Proposa", "content": "I agree with Matthias' comments about the opt-in/opt-out. Other than \nthat, the proposal looks conceptually ok. I would like to see a \nsentence or two giving an example of what this is useful for. Also, the \nBNF and policy syntax fragments need to be done properly.\n\nLorrie\n\n\nOn Thursday, August 28, 2003, at 06:02  PM, Matthias Schunter wrote:\n\n>\n> Hi Jerry,\n>\n> thanks for the update. I'll review it and comment/update it.\n>\n> The reason why I did the mandatory opt-in was to preserve semantics:\n> - The semantics of a P3P 1.1 and P3P 1.0 policy should be similar\n>\n> If the semantics supersedes the opt-in/outs of 1.0 or if there must \n> not be any opt-in/outs then it may happen that something is optional \n> in 1.1 that is required in 1.0 or vice versa.\n>\n> Regards,\n>  matthias\n>\n> At 12:39 PM 8/28/2003 -0700, Jeremy Epling wrote:\n>\n>> I think that these could just be one proposal once the paradigms are\n>> combined.\n>>\n>> Can we just deprecate the opt-in, opt-out, and required attributes and\n>> say that if used the agent with take precedence with the consent tag.\n>>\n>> Jeremy\n>>\n>> -----Original Message-----\n>> From: Matthias Schunter [mailto:mts@zurich.ibm.com]\n>> Sent: Monday, August 11, 2003 6:13 AM\n>> To: Lorrie Cranor; Jeremy Epling\n>> Cc: public-p3p-spec@w3.org\n>> Subject: Re: Grouping Statements Proposal\n>>\n>> Hi!\n>>\n>> The proposal looks good. Once Jerry contacts me, I'll work with him to\n>> resolve the remaining issues. Some initial ideas/remarks:\n>> - the opt-in or opt-in elements inside all elements of an \n>> opt-in/out-out\n>>\n>> group where included\n>>    to preserve backward compatibility of the semantics.\n>> - The issue of the OURS/CURRENT may be resolved by defining that they\n>> cannot be included in an\n>>    opt-in/opt-out group.\n>> - Does it makes sense to use \"required\" instead of \"no-group\" or do \n>> you\n>> envision that with\n>>    consent=\"no-group\", one can nevertheless have opt-in's and out's\n>> inside?\n>>\n>> Regards,\n>>   matthias\n>>\n>>\n>>\n>>\n>> At 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n>>\n>> >We discussed  this on today's call, minutes should be forthcoming. My\n>> >quick summary is:\n>> >\n>> >- combining these two group concepts probably makes sense\n>> >- we probably want an extension that looks something like the \n>> following\n>>\n>> >that can be inserted into all statement's that belong to a group:\n>> >\n>> ><STATEMENT>\n>> ><EXTENSION>\n>> >   <STATEMENT-GROUP id = \"fflyer\" />\n>> ></EXTENSION>\n>> >. . .\n>> ></STATEMENT>\n>> >\n>> >Then somewhere else in the policy\n>> ><EXTENSION\n>> >   <STATEMENT-GROUP-DEF id=\"fflyer\"\n>> >   short-description=\"Frequent Flyer Club\"\n>> >   consent = \"opt-in\" />\n>> ></EXTENSION>\n>> >\n>> >Some groups of statements might not be consent groups, in which case\n>> they\n>> >might use an attribute like consent = \"no-group\" (which might be the\n>> default).\n>> >\n>> >There are also some concerns about consent group that need to be \n>> worked\n>>\n>> >out. In Mathias' proposal it says that all PURPOSE and RECIPIENT\n>> elements\n>> >in a group have to have the same required attribute. But ours and\n>> current\n>> >are special cases that don't have this attribute. This needs to be\n>> >accounted for (the example in Mathias' draft is actually incorrect\n>> because\n>> >of this). Also we need to be clear on how to handle errors. What if\n>> >someone uses consent group but then uses different required \n>> attributes\n>> >(which is incorrect)? Does that invalidate the policy? Perhaps if \n>> that\n>> >happens the user agent should treat it as if it is consent = \n>> \"no-group\"\n>> ?\n>> >\n>> >In any case, Jeremy is going to put together a more specific proposal\n>> on\n>> >this grouping. Mathias, it would be great if you could work with him \n>> on\n>>\n>> >the consent aspect.\n>> >\n>> >Lorrie\n>> >\n>> >\n>> >On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n>> >\n>> >>\n>> >>Hi Jeremy,\n>> >>\n>> >>thanks for your design. I feel that grouping statements is a good\n>> idea.\n>> >>\n>> >>The actual syntax for grouping is elaborated in our earlier draft on\n>> >>consent choices:\n>> >>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>> >>\n>> >>I feel that grouping statements is a good idea for multiple \n>> purposes.\n>> >>Therefore, I feel that we should have a general group mechanism \n>> where\n>> >>each group should have multiple properties:\n>> >>- opt-in opt-out or always (from consent choices)\n>> >>   syntactically this can be implicit: either all statements are\n>> >> always/opt-in, or opt-out.\n>> >>- target (something specifying whether it's the ebay or amazon part)\n>> >>   The target is something that might be useful to add to your\n>> proposal.\n>> >>   I don't know how to express this in a nice syntax.\n>> >>\n>> >>Why don't we merge both proposals into a \"grouping statements\"\n>> proposal?\n>> >>\n>> >>Regards,\n>> >>\n>> >>matthias\n>> >>\n>> >>\n>> >>\n>> >>At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>> >>\n>> >>>Below are the basics of my proposal for statement grouping.\n>> >>>\n>> >>>\n>> >>>\n>> >>>Problems\n>> >>>    * Policies are not relevant to how a user interacts with the \n>> site\n>> >>>        * Users don t know what part of a P3P policy applies to \n>> them\n>> and\n>> >>> there activities on a site\n>> >>>        * Users understand scenarios of how they interact with a \n>> site\n>>\n>> >>> better than a series of statements related to a feature of the \n>> site\n>> >>>    * Policy authors have to make highest common denominate \n>> policies\n>> >>> that could look more privacy impacting than they are for most \n>> users\n>> >>>\n>> >>>\n>> >>>Goals\n>> >>>    * Provide a method for showing the sections of the P3P policy\n>> that\n>> >>> apply to how a user interacts with the site/service\n>> >>>    * Allow an easy way for policy authors to describe what \n>> sections\n>> of\n>> >>> their P3P policy apply to different user interaction with their\n>> site/service\n>> >>>\n>> >>>\n>> >>>Scenarios\n>> >>>    * User browses to ebay and views the P3P policy. They are able \n>> to\n>>\n>> >>> skip to the buyer section of the P3P policy since that is what\n>> applies to them.\n>> >>>    * User browses to amazon and views the P3P policy. The can see\n>> that\n>> >>> since they are not logged in less information is collected about\n>> them.\n>> >>>\n>> >>>\n>> >>>Design\n>> >>>\n>> >>>\n>> >>>\n>> >>>The P3P author decides the name of the statement group which is \n>> used\n>> in\n>> >>>the display of the agent when it translates the nodes to natural\n>> language.\n>> >>>\n>> >>>\n>> >>>\n>> >>><Statement>\n>> >>>\n>> >>>             <extention>\n>> >>>\n>> >>>                         <grouping-id>Member</grouping-id>\n>> >>>\n>> >>>             </extention>\n>> >>>\n>> >>><statement>\n>> >>>\n>> >>>\n>> >>>\n>> >>>Issues\n>> >>>    * Do agents now show conflicts per grouping?\n>> >>>\n>> >>>\n>> >>>Jeremy Epling\n>> >>>Windows - Privacy and Trust UX\n>> >>>\n>> >>><BLOCKED::>wpihelp - where to go for all your privacy questions\n>> >>>\n>> >>\n>> >>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>> >>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>> >>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>> >>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>> >\n>>\n>> -- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>> Fax +41-1-724 8953; More info at www.semper.org/sirene\n>> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n> -- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n> Fax +41-1-724-8953; More info at www.semper.org/sirene\n> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n\n\n\n", "id": "lists-017-3404254"}, {"subject": "RE: Grouping Statements Proposa", "content": "Hi Folks,\n\nI reviewed the spec and made the following changes:\n\nSTATEMENTS:\n- I deleted the requirement that all statements must have a group\n- I added some text describing an example\n- I added Jerry as an author\n\nGROUP-DEFS:\n- The consent is now \"opt-in\", \"opt-out\", \"required\"\n   The first three must be 'inherited' by all statements in this group.\n- I made it explicit that <Recipient ours> and <purpose current> cannot be \nused\n   inside statements that are in a group that is declared opt-in or opt-out.\n\nQUESTIONS:\n- I did now allow one statement to belong to multiple groups. I feel that \nthis would\n   be too confusing.\n- I thought about enabling groups that define \"consent='mixed'\" which \nenables to group statements that have a mixture of opt-in, opt-out, and \nrequired. But I felt that this is not useful.\n\nRegards,\n  matthias\n\n\n\nAt 02:34 PM 8/28/2003 -0700, Jeremy Epling wrote:\n>Attached is my first try at modifying Matthias's proposal to incorporate\n>mine.\n>\n>Feedback is welcomed,\n>\n>Jeremy\n>\n>-----Original Message-----\n>From: public-p3p-spec-request@w3.org\n>[mailto:public-p3p-spec-request@w3.org] On Behalf Of Jeremy Epling\n>Sent: Thursday, August 28, 2003 12:40 PM\n>To: Matthias Schunter; Lorrie Cranor\n>Cc: public-p3p-spec@w3.org\n>Subject: RE: Grouping Statements Proposal\n>\n>\n>I think that these could just be one proposal once the paradigms are\n>combined.\n>\n>Can we just deprecate the opt-in, opt-out, and required attributes and\n>say that if used the agent with take precedence with the consent tag.\n>\n>Jeremy\n>\n>-----Original Message-----\n>From: Matthias Schunter [mailto:mts@zurich.ibm.com]\n>Sent: Monday, August 11, 2003 6:13 AM\n>To: Lorrie Cranor; Jeremy Epling\n>Cc: public-p3p-spec@w3.org\n>Subject: Re: Grouping Statements Proposal\n>\n>Hi!\n>\n>The proposal looks good. Once Jerry contacts me, I'll work with him to\n>resolve the remaining issues. Some initial ideas/remarks:\n>- the opt-in or opt-in elements inside all elements of an opt-in/out-out\n>\n>group where included\n>    to preserve backward compatibility of the semantics.\n>- The issue of the OURS/CURRENT may be resolved by defining that they\n>cannot be included in an\n>    opt-in/opt-out group.\n>- Does it makes sense to use \"required\" instead of \"no-group\" or do you\n>envision that with\n>    consent=\"no-group\", one can nevertheless have opt-in's and out's\n>inside?\n>\n>Regards,\n>   matthias\n>\n>\n>\n>\n>At 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n>\n> >We discussed  this on today's call, minutes should be forthcoming. My\n> >quick summary is:\n> >\n> >- combining these two group concepts probably makes sense\n> >- we probably want an extension that looks something like the following\n>\n> >that can be inserted into all statement's that belong to a group:\n> >\n> ><STATEMENT>\n> ><EXTENSION>\n> >   <STATEMENT-GROUP id = \"fflyer\" />\n> ></EXTENSION>\n> >. . .\n> ></STATEMENT>\n> >\n> >Then somewhere else in the policy\n> ><EXTENSION\n> >   <STATEMENT-GROUP-DEF id=\"fflyer\"\n> >   short-description=\"Frequent Flyer Club\"\n> >   consent = \"opt-in\" />\n> ></EXTENSION>\n> >\n> >Some groups of statements might not be consent groups, in which case\n>they\n> >might use an attribute like consent = \"no-group\" (which might be the\n>default).\n> >\n> >There are also some concerns about consent group that need to be worked\n>\n> >out. In Mathias' proposal it says that all PURPOSE and RECIPIENT\n>elements\n> >in a group have to have the same required attribute. But ours and\n>current\n> >are special cases that don't have this attribute. This needs to be\n> >accounted for (the example in Mathias' draft is actually incorrect\n>because\n> >of this). Also we need to be clear on how to handle errors. What if\n> >someone uses consent group but then uses different required attributes\n> >(which is incorrect)? Does that invalidate the policy? Perhaps if that\n> >happens the user agent should treat it as if it is consent = \"no-group\"\n>?\n> >\n> >In any case, Jeremy is going to put together a more specific proposal\n>on\n> >this grouping. Mathias, it would be great if you could work with him on\n>\n> >the consent aspect.\n> >\n> >Lorrie\n> >\n> >\n> >On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n> >\n> >>\n> >>Hi Jeremy,\n> >>\n> >>thanks for your design. I feel that grouping statements is a good\n>idea.\n> >>\n> >>The actual syntax for grouping is elaborated in our earlier draft on\n> >>consent choices:\n> >>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n> >>\n> >>I feel that grouping statements is a good idea for multiple purposes.\n> >>Therefore, I feel that we should have a general group mechanism where\n> >>each group should have multiple properties:\n> >>- opt-in opt-out or always (from consent choices)\n> >>   syntactically this can be implicit: either all statements are\n> >> always/opt-in, or opt-out.\n> >>- target (something specifying whether it's the ebay or amazon part)\n> >>   The target is something that might be useful to add to your\n>proposal.\n> >>   I don't know how to express this in a nice syntax.\n> >>\n> >>Why don't we merge both proposals into a \"grouping statements\"\n>proposal?\n> >>\n> >>Regards,\n> >>\n> >>matthias\n> >>\n> >>\n> >>\n> >>At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n> >>\n> >>>Below are the basics of my proposal for statement grouping.\n> >>>\n> >>>\n> >>>\n> >>>Problems\n> >>>    * Policies are not relevant to how a user interacts with the site\n> >>>        * Users don t know what part of a P3P policy applies to them\n>and\n> >>> there activities on a site\n> >>>        * Users understand scenarios of how they interact with a site\n>\n> >>> better than a series of statements related to a feature of the site\n> >>>    * Policy authors have to make highest common denominate policies\n> >>> that could look more privacy impacting than they are for most users\n> >>>\n> >>>\n> >>>Goals\n> >>>    * Provide a method for showing the sections of the P3P policy\n>that\n> >>> apply to how a user interacts with the site/service\n> >>>    * Allow an easy way for policy authors to describe what sections\n>of\n> >>> their P3P policy apply to different user interaction with their\n>site/service\n> >>>\n> >>>\n> >>>Scenarios\n> >>>    * User browses to ebay and views the P3P policy. They are able to\n>\n> >>> skip to the buyer section of the P3P policy since that is what\n>applies to them.\n> >>>    * User browses to amazon and views the P3P policy. The can see\n>that\n> >>> since they are not logged in less information is collected about\n>them.\n> >>>\n> >>>\n> >>>Design\n> >>>\n> >>>\n> >>>\n> >>>The P3P author decides the name of the statement group which is used\n>in\n> >>>the display of the agent when it translates the nodes to natural\n>language.\n> >>>\n> >>>\n> >>>\n> >>><Statement>\n> >>>\n> >>>             <extention>\n> >>>\n> >>>                         <grouping-id>Member</grouping-id>\n> >>>\n> >>>             </extention>\n> >>>\n> >>><statement>\n> >>>\n> >>>\n> >>>\n> >>>Issues\n> >>>    * Do agents now show conflicts per grouping?\n> >>>\n> >>>\n> >>>Jeremy Epling\n> >>>Windows - Privacy and Trust UX\n> >>>\n> >>><BLOCKED::>wpihelp - where to go for all your privacy questions\n> >>>\n> >>\n> >>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n> >>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n> >>Fax +41-1-724 8953; More info at www.semper.org/sirene\n> >>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n> >\n>\n>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>\n>\n>\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724-8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n\ntext/html attachment: 06-cc-changes-to-P3P.htm\n\n\n\n\n", "id": "lists-017-3422613"}, {"subject": "International Journal Web Services Research (JWSR): Volume 1, Iss ue 1, JanuaryMarch 200", "content": "International Journal Web Services Research (JWSR)\nOfficial publication of the Information Resources Management Association\nhttp://www.idea-group.com/journals/details.asp?id=4138\nVolume 1, Issue 1, January-March 2004\n------------------------------------------------------------------------\nEditor: Liang-Jie Zhang, IBM, USA \n  \nFOREWORD \n  \nDaniel Sabbah, Vice President\nA&IM Development and SWG Technology, IBM Software\n  \nDaniel Sabbah introduces the inaugural issue of JWSR, which he see as a\nmedium to provide a channel for industry professionals, academic researchers\nand decision makers in the field of web services to publish and share \ninformation with each other. He feels the readers will gain the explicit \nand up-to-date knowledge of Web services research activities and\ntechnologies\nfrom this journal, especially researchers and architects to identify the\ntrends of the relevant R&D topics and coordinate their own positions in a\nmore competitive approach.\n\n\nEDITORIAL PREFACE \n  \n\"Challenges and Opportunities for Web Services Research\"\n  \nLiang-Jie Zhang, IBM T.J. Watson Research Center\n  \nWeb services are becoming a major research topic for computer scientists,\nengineers and business consulting professionals. In this preface, the\njournal\neditor in chief outlines the challenges of the current Web services research\ntopics from the modeling, interoperability, and mathematical foundations\npoints of view. Zhang introduces some research opportunities and possible\nfuture directions for moving Web services forward via some illustrative\nideas\nsuch as business semantic computing as well as killer application driven Web\nservices research approaches.\n\n\nPAPERS\n\nPAPER ONE\n\n\"A Spanning Tree Based Approach to Identifying Web Services\"\n\nHemant Jain, University of Wisconsin - Milwaukee, USA\nHuimin Zhao, University of Wisconsin - Milwaukee, USA\nNageswara R. Chinta, Tata Consultancy Services, India\n\nWeb service has been envisioned as an important trend in application\ndevelopment\nand integration. It allows pre-built applications/application components\nwrapped\nas web services to interact with each other through standardized interfaces\nand\nto from larger application systems. This paper describes a formal approach\nto web\nservices identification, which is a critical step in designing and\ndeveloping\neffective web services.\n\nTo obtain a copy of the entire article, click on the link below.\nhttp://www.idea-group.com/articles/details.asp?id=4250\n\n\nPAPER TWO\n\n\"Web Services Enabled E-Market Access Control Model\"\n\nHarry J. Wang, University of Arizona, USA\nHsing K. Cheng, University of Florida, USA\nJ. Leon Zhao, University of Arizona, USA\n\nWith the emergency of global e-markets, companies collaborate more and more\nin\norder to streamline their supply chains. Because of the complex\nrelationships among\ncompanies, controlling the access to shared information found in e-markets\nis a vital\nbut difficult task. In this paper the authors propose a process to integrate\nseveral\nknown access control mechanisms such as role-based access control,\ncoalition-based\naccess control, and relationship driven access control into an E-Market\nAccess Control\nmodel (EMAC).\n\nTo obtain a copy of the entire article, click on the link below.\nhttp://www.idea-group.com/articles/details.asp?id=4251\n\n\nPAPER THREE\n  \n\"Integration of Business Event and Rule Management With the Web Services\nModel\"\n  \nKarthik Nagarajan, Herman Lam, Stanley Y.W. Su, University of Florida, USA\n\nWhile Web services technology provides a promising foundation for developing\ndistributed\napplications for e-business, additional features are required to make this\nparadigm truly\nuseful in the real world. In particular, interactions among business\norganizations need\nto follow the policies, regulations, security and other business rules of\nthe organizations.\nIn this paper, the authors focus on incorporating the business event and\nrule-management\nconcepts into the Web services model at the service provider side.\n\nTo obtain a copy of the entire article, click on the link below.\nhttp://www.idea-group.com/articles/details.asp?id=4252\n\n\nPAPER FOUR\n\n\"Implementation and Performance of WS-Security\"\n\nSatoshi Makino, Kent Tamura, Takeshi Imamura, and Yuichi Nakamura,\nIBM Tokyo Research Laboratory, Japan\n\nThis article describes performance improvements for the Web Services\nSecurity (WS-Security)\nspecification. In the course of its development and performance measurement,\nthe authors\nidentified bottlenecks in the XML parsing and public key operations such as\nRSA signature\nand encryption. To minimize the impact of these bottlenecks, the authors\nimplemented a\nstream-based WS-Security processor and showed its efficiency in XML parsing,\nin terms of\nboth the processing time and the memory usage.\n\nTo obtain a copy of the entire article, click on the link below.\nhttp://www.idea-group.com/articles/details.asp?id=4253\n\n****************************************************************************\n***************\nFor full copies of the above articles, check for this issue of International\nJournal of Web\nService Research (JWSR) in your Institution's library.\n****************************************************************************\n***************\n\nA complimentary copy of this inaugural first issue is available for download\nat www.idea-group.com.\n\nCALL FOR PAPERS\n\nMission of JWSR:\n\nThe International Journal of Web Services Research (JWSR) is a high-quality\nrefereed journal\non Web Services research and engineering that serves as an outlet for\nindividuals in the field\nto publish their research as well as interested readers. As a research and\nengineering journal,\nthe International Journal of Web Services Research, will facilitate\ncommunication and networking\namong Web Services/e-business researchers and engineers in a period where\nconsiderable changes\nare taking place in Web Services technologies innovation, and stimulate\nproduction of high-quality\nWeb Services solutions and architectures.\n\nCoverage of IRMJ:\n\nJWSR covers topics with a major emphasis on the advancements in the state of\nthe art, standards,\nand practice of Web Services, as well as to identify the emerging research\ntopics and define the\nfuture of Web Services computing, including Web Services on Grid Computing,\nWeb Services on\nMultimedia, Web services on Communication, Web Services on E-Business, etc.\nSome featured topics\nare:\n\n- Web Services architecture\n- Web Services security\n- Frameworks for building Web Service applications\n- Composite Web Service creation and enabling infrastructures\n- Web Services discovery\n- Resource management for Web Services\n- Solution Management for Web Services\n- Dynamic invocation mechanisms for Web Services\n- Quality of service for Web Services\n- Web Services modeling\n- Web Services performance\n- UDDI enhancements\n- SOAP enhancements\n- Case Studies for Web Services\n- E-Commerce applications using Web Services \n- Grid based Web Services applications (e.g. OGSA)\n- Business process integration and management using Web Services\n- Multimedia applications using Web Services\n- Mathematic foundations for service oriented computing\n- Communication applications using Web Services\n- Interactive TV applications using Web Services\n- Semantic services computing\n- Business Grid\n\nInterested authors should consult the Journal's manuscript submission\nguidelines at http://www.idea-group.com\n\nAll inquiries and submissions should be sent to:\nEditor-in-Chief: Liang-Jie Zhang, Ph.D.\nIBM T.J. Watson Research Center\nP.O. Box 218, Yorktown Heights, NY 10598\n\n\n\n", "id": "lists-017-3484389"}, {"subject": "user strings for &lt;court&gt; and &lt;law&gt", "content": "Dear all, \n\nLorrie and I had some exchanges on the strings used for the new\ndefinitions around law and court. We came up with the following\nproposal:\n>\n><court>\n>We believe that the following authority offers recourse for disputes:\n>[display long description and short description, if provided, with\n>hyperlink to service URI, otherwise display \"possible legal complaint\"\n>with hyperlink to service URI]\n>\n><law>\n>We believe that the following laws or regulations provide recourse:\n>[display long description and short description, if provided, with\n>hyperlink to service URI, otherwise display \"law\" with hyperlink to\n>service URI]\n\nI already integrated that wording into the new draft. Please raise your\nobjections to the mailing-list, if there are any (David?)\n\nIf there are no objections by the end of the week, I'll take those\nchanges for accepted.\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-3499191"}, {"subject": "[Agenda] 10 December cal", "content": "Please note that we haven't seen the minutes from last time yet and that\nno action-item was completed due to this. \n\nI will not be online tomorrow, as I will be in Brussels for a meeting\ncalling in from my mobile phone.\n\nThe next P3P specification group conference call will be on\nWednesday, December 10, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n\n1/ Report on HTTP beyond P3P\n   I hope Patrick and I can give you some progress report\n\n2/ Continued discussion of agent-relationsships\n\n3/ discuss the link-texts from Giles and Jeff\n+are they ready\n+Where should they go,\n\n4/ decision on consent-choices\nShould we go for the proposal as is? Which deadline for comments\ndo we give?\n\nPlease feel also free to discuss the points on the mailing-list\n\nRigo\n\n\n\n", "id": "lists-017-3507038"}, {"subject": "Ad server proble", "content": "Here is an attempt at a clear description of the problem discussed on the\nlast couple of calls\n\nAdvert providers cannot be considered data controllers because they act\npurely as a pipeline for data which is passed to  entities posting ads.\nFurthermore, responsibility is not based on the URL of the advert but\nusually on the URL of the referrer page for the advert + the URL of the\nadvert. This means that the normal mechanisms for P3P policy binding do not\nwork because the practices connected to data collection for a particular ad\nare neither a function of the ad url NOR of the referring url but a\ncombination of the two. Even an attempt to define a policy binding based on\na combination of the ad and the referrer would fail because sometimes the\nreferrer is missing.\n\nSee attached diagram\n\nPerhaps people could comment on whether this description is clear.  \n\nWhat we need is something that can give us policy reference files which\ncould point to policies applying to for example Ford Motor Company ads\nposted on Google. I am still not entirely clear why using a combination of\nthe referer and the ad uri could not be used as a binding. The fact that the\nreferrer may be missing seems not so relevant because if it is missing, then\ndata probably won't be collected anyway.\n\n\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity\nNew technologies for Combatting Fraud Unit\n\n \n\n\n\n\n\n\n\n\n\n", "id": "lists-017-3514043"}, {"subject": "MINUTES 03 December 2003 P3P Specification Cal", "content": "(Subject to amendment)\n\nAttendees:  Brooks Dobbs, Jeff Edelen, Brooks Dobbs, Giles Hogben, Patrick\nHung, Dave Stampley, Rigo Wenning\n\n1.      Article 10.  \n\n1.1.   Rigo:  Intent was to make P3P compliant w/Art 10 so you can\nautomatically notify users of data collection w/P3P, to satisfy requirements\nof art 10.  Giles had exchanges w/Art 29 working party.  \n\n1.2.   Giles.  Points raised were:\n\n1.2.1.      Purpose specification\n\n1.2.2.      Ability to specify jurisdiction\n\n1.2.3.      Point at which cookies must be evaluated\n\n1.3.   Giles:  The ITF secretariat asked Giles H to keep them informed about\nany further steps to be taken.  \"It is not the intention of the ITF to give\nthe green light to every action taken, but rather to be informed and to\nintervene if necessary.\"  This is a positive response.\n\n1.4.   Giles proposes closing this phase of issue.  \n\n1.5.   Rigo:  We have no primary purpose spec yet.  We have only\n\"current\"... context specific.  It would be good to come up with a list of\n15 primary purposes that are very common.  \n\n1.6.   Art 10 task force is Giles, Jeff, Dave, and Rigo, to come up with a\nset of primary purposes.  Rigo to send first email.\n\n1.7.   Giles takes action item to create wording about legality of\njurisdiction and transfers.\n\n2.      Cookies and agent relationships.  \n\n2.1.   Rigo:  We all agree that from the recipient definition, we have no\nsame entity and agent distinction.  Issue is multiple to multiple\nrelationship.  \n\n2.2.   Action:  Giles to document issue and distribute to mailing list so we\ncan really think about it.  It may be out of scope for 1.1, but I want to\nget it into bugzilla and consider whether we delay to version 2. \n\n2.3.   Rigo to brooks:  Issue is multiple to multiple relationship.  This\nisn't new to computer science.  We have to find a way to address that or we\ncan just leave it as is and say we can't solve now.  Giles:  it's an issue,\nbut it needs a lot of work.  First steps to tag it... send it to\nw3c-p3p-specification@w3.org.  ... all participants are on, so you don't\nhave to share with the world.  Write the issue down and distribute to\nmailing list so we can really think about it.  It may be out of scope for\n1.1, but I want to get it into bugzilla and consider whether we delay to\nversion 2.... se how it works out with epal, etc.  I want it on the table.\nIt touches existing business models and it's a serious issue.  Touches\nimplementability of p3p.  Brooks:  okay.  Rigo:  when mature and not\ncompany-sensitive, \n\n3.      English language wording of \"courts\" and \"law\"\n\n3.1.   Dave proposes:  \"We will compensate individuals if it is determined\nthat we have violated our privacy policy.\"\n\n4.      General agreement.  Dave to send wording with minutes. \n\n\n\n", "id": "lists-017-3522063"}, {"subject": "Avenue A press releas", "content": "http://www.avenuea.com/news/releases/20031208.asp\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity\nNew technologies for Combatting Fraud Unit\nTP 267\nVia Enrico Fermi 1\nIspra \n21020 VA\nItaly\n\ngiles.hogben@jrc.it\ntel:+390332789187\nfax:+390332789576\n \n\n\n\n", "id": "lists-017-3531899"}, {"subject": "press release mentioned in 10 december cal", "content": "http://www.avenuea.com/news/releases/20031208.asp\n<http://www.avenuea.com/news/releases/20031208.asp> \n\n\n\n", "id": "lists-017-3538780"}, {"subject": "MINUTES of 10 December 2003 P3P Specification Cal", "content": "Minutes of 10 December 2003 P3P Specification Call\n\nPresent:\nRigo Wenning\nDave Stampley\nGiles Hogben\nBrooks Dobbs\nJack Humphrey\nJeff Edelen\n\n1/ Report on P3P Beyond HTTP\n\nRigo provided an update on the P3P and WSDL effort.  Expect P3P to define\nattributes in a p3p namespace for use by WSDL.  The discussion went into detail\nbeyond this scribe's ability to capture in the minutes, but there seemed to be\nconsensus as to the approach, and ammendments to these minutes are welcomed on\nthe mailing list.\n\n2/ Continued discussion of agent-relationships\n\nACTION: Jack to distribute revised proposal.\n\nIn discussion as to the feasibility of using the \"referer\" header, Rigo pointed\nout that, in addition to other arguments against this approach, the \"referer\"\nheader is not to be sent in the safe zone.\n\nAfter further discussion of typical use-cases involving agent-relationships, it\nwas agreed that the problem statement requires clarification.\n\nACTION: All to continue to define problem statement on the mailing list.\n\n3/ discuss the link-texts from Giles and Jeff\n+are they ready\n+Where should they go,\n\nDiscussed Giles' 10/15 email \"Cookie linking v2\".\nJeff requested clarification as to what information linkages need to be\ndisclosed at set-cookie time.  Rigo's position that all linked information,\nboth on-line and off-line, requires disclosure was agreed, with some discussion\nas to what constitutes a \"reasonable\" linkage.\nGiles: Can we apply the concept of proportionality as to what information can\nbe \"reasonably deduced?\"\nBrooks: Declare linkages if the architecture employed is the same as an\narchitecture one would employ if the intent were to facilitate the linking.\n(Jeff: My apologies for the phrasing)\n\nRigo's suggestion that we need better guidelines on cookie usage in P3P was\nagreed.\n\nDiscussed the implications of policy evaluation at cookie replay time, versus\nset-cookie time.  Arguments for policy evaluation at cookie replay time were\nadvanced, but further analysis is needed.\n\nACTION: All to continue discussion of policy evaluation at replay time on the\nmailing list.\n\nACTION: Giles to update cookie linking text to address the effects of adding\nlinked information to an existing cookie, assuming policy evaluation at\nset-cookie time.  That effect being that a new cookie must be set, with the new\npolicy.\n\n4/ decision on consent-choices\nShould we go for the proposal as is? Which deadline for comments\ndo we give?\n\nNo time for this discussion.\n\n5/ Next call proposed for 17 December 2003.\n\n\n\n\nAmerican Express made the following\n annotations on 12/10/2003 11:33:11 AM\n------------------------------------------------------------------------------\n******************************************************************************\n\n     \"This message and any attachments are solely for the intended recipient and may contain confidential or privileged information. If you are not the intended recipient, any disclosure, copying, use, or distribution of the information included in this message and any attachments is prohibited.  If you have received this communication in error, please notify us by reply e-mail and immediately and permanently delete this message and any attachments.  Thank you.\"\n\n******************************************************************************\n\n\n==============================================================================\n\n\n\n", "id": "lists-017-3546072"}, {"subject": "[Domain/Agent] new proposa", "content": "Here is a new version of the domain relationship proposal. The first\nattachment is a \"clean copy\" and the second has highlighting showing all the\nchanges made from the previous same-entity domain relationship proposal --\nless readable but useful if you're familiar with the previous proposal.\n \nAn HTML version will be posted on the site soon.\n \nAn overview of the changes:\n1. Merged in agent proposal, consistent with the definition of recipient\nelement \"ours\" that includes \"ourselves and entities acting as our agents\"\n(per Rigo's suggestion)\n2. Moved PRF KNOWN-HOSTS element inside POLICY-REF element, also stated that\nit can occur at the higher level (per Rigo's suggestion)\n3. Added mention of PRF expiration applying to known-hosts declarations (per\ndiscussion on recent call)\n4. Revised P3P header for compact policy usage... I'm still hanging on to\nthis idea.\n5. Revised proposed user-agent rules for interpreting known-hosts info\n6. Added section concerning mentioning user-agent playback issues\n \nPlease read and comment. Thanks.\n \n++Jack++\n \n\n\n\n <http://www.coremetrics.com/>  Named #1 By Forrester\n<http://www.coremetrics.com/promos/forrester_report_request.html> Research\n\n\n\nJack Humphrey\nTeam Lead, Data Acquisition Platform 8940 Research Blvd, Suite 300\n<http://maps.yahoo.com/py/maps.py?Pyt=Tmap&addr=8940+Research+Blvd,+Suite+30\n0&csz=Austin,+TX+78758&country=us> \nAustin, TX 78758 \njhumphrey@coremetrics.com <mailto:jhumphrey@coremetrics.com>  \ntel: 512-826-7300 \n\n\n <http://www.plaxo.com/signature/> Powered by Plaxo\n<http://www.plaxo.com/signature/> Want a signature like this?\n \n\n\n\n\n\napplication/octet-stream attachment: domrelprop200312.pdf\n\napplication/octet-stream attachment: domrelprop200312_diffs.pdf\n\n\n\n\n\n\n", "id": "lists-017-3556311"}, {"subject": "Article 10: wording for Jurisdiction cavea", "content": "Wording for Jurisdiction caveat:\nSome jurisdictions prohibit transfer of data to certain other jurisdictions\nwithout the explicit consent of the data subject. Therefore declaring a data\ntransfer activity using the P3P jurisdiction extension is not sufficient to\nguarantee its legality.\n\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity New\ntechnologies for Combatting Fraud Unit TP 267 Via Enrico Fermi 1 Ispra \n21020 VA\nItaly\n\ngiles.hogben@jrc.it\ntel:+390332789187\nfax:+390332789576\n \n\n\n\n", "id": "lists-017-3566730"}, {"subject": "Cookie linking v", "content": "Cookies can contain a maximum of 4kb of data which must be transmitted\nacross the network twice before it can be used. For this reason, cookies\ntend to store only a number (or unique key) which links to a value in a\ndatabase. Data about a user is stored in a database and that record is given\na number (a unique key). Only this number is stored in the cookie on the\nuser's computer. When the user revisits the site which set the cookie, that\nsite can immediately have access to a potentially unlimited amount of\ninformation about the user simply by looking up the number in the database\nin which the number is a key. Linkability may be direct or indirect. For\nexample a key stored in one cookie may not link directly to a user's name\nbut instead the user's name may be deduced by examining two cookies replayed\nby separate domains but linked by a unique referrer. \n\nExample 1.\n----------\n\nImage A on Domain A replays a cookie linking to a record of the user's\nstreet name and number.\nImage B on Domain B replays a cookie which links to a record of the user's\nhome town.\nImages A and B are displayed on pages with session ID's within Domain C. \nBy using the referrer URI (which contains a unique session key), these two\ncookies be linked together to give a unique address and through another\ndatabase, the user's name.\n\nWith enough effort, similar but more sophisticated data mining techniques\nmay be applied to link even seemingly highly anonymised data with cookie\nvalues. P3P applies the principle of proportionality to such linkability.\nThe specification of the data and purposes covered by cookie should be\nthought of in terms of the analysis which might reasonably be carried out on\nsuch a cookie to achieve the stated purpose. For example if a cookie is set\nto track criminals' personal data then it is reasonable that a considerable\neffort might be put into database analysis. The cookie should therefore be\nsaid applying to personally identifiable data even if the data is actually\nhashed in the database. If on the other hand, the cookie is set in order to\ntrack a session and data is stored in the database but anonymised by\nhashing, then there is no need to state that the data is identifiable. This\ntype of anonymization is in theory not secure because hashes have a 1-1\ncorrespondence with ip addresses for example so by hashing all possible ip\naddresses, you can trace the original ip address. However extending the\ndefinition of linkability to this extent is neither practical nor\nreasonable.\n\nThird party cookies are cookies which are set by a domain other than the\npage being viewed. This is done through embedded images as in Example 1 and\ncan even occur in emails and applications which use web services, such as\nmusic players. While normally the information stored in one domain's cookie\ncannot be accessed by another domain, third party cookies bypass this\nmechanism by placing the same third party image in different domain's pages.\nThis allows tracking of users across different domains. The intention to\ncarry out such tracking activities through linking cookie keys across\ndifferent domains should also be declared.\n\nA connected problem is that a site SETTING a cookie may not be in control of\nall the purposes to which a cookie is put ON REPLAY. For example some\ndomains set a domain level cookie (at the level *.xyz.com) which is replayed\nto thousands of subhosts (a.xyz.com,b.xyz.com ...), whose data collection\npractices are not under their control. Currently the solution of evaluating\ncookies on replay has been discounted because of performance issues and data\nprotection issues linked to the act of storage of data on the user's\nmachine. Therefore P3P requires that entities publishing policies in\naccordance with correct practice declare any potential purposes to which a\ncookie might be put. It follows therefore that if a cookie is used for a new\nand unforseen purpose, it SHOULD be reset along with a fresh P3P policy.\n\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity New\ntechnologies for Combatting Fraud Unit TP 267 Via Enrico Fermi \n \n\n\n\n", "id": "lists-017-3573919"}, {"subject": "RE: Cookie linking v", "content": "Giles,\n\nI agree with your first part but you lost me on the triangulation from 2\ndomains.  I don't think that this type of triangulation is really all that\nlikely a scenario, remembering that Domains A and B are likely separate\nentities with separate web servers with no practical means of linking that\ncookie they each receive come from the same user (unless they have somehow\ncoordinated to set the same unique_id).  I see where you are going with\nreferrer and while that may give you a guess it would be a far fetched one.\n\nI also agree with your analysis of domain level cookies.  I think this has\nalways been a real thorn in the side of P3P.  I will make a broad\ngeneralization here, and feel free to shoot it down, - most large domains\nand nearly all corporate domains outsource at least one or two hosts on\ntheir domain and additionally maintain exceptionally little control of their\ninternal hosts (bobjones.company.com).  Here is another broad generalization\n- many, many corporate domains set a domain level unique id cookie which\nthey claim to be pseudonymous.  I would venture a guess that that the\nmajority of these folks also have a corporate intranet on the same domain\nthat requires authentication usually via REMOTE_USER.  So now what is being\nlogged on the intranet: REMOTE_USER and DOMAIN COOKIE!!!  Opps looks like\nDomain cookie is no longer anonymous.  I think that what all this points to\nis, sadly, true accuracy and compliancy are beyond the efforts that most\nimplementers are taking at this time.\n\n-Brooks\n\n\n-----Original Message-----\nFrom: Giles Hogben [mailto:giles.hogben@jrc.it] \nSent: Thursday, December 11, 2003 5:31 AM\nTo: public-p3p-spec\nCc: WILIKENS MARC ANDRE\nSubject: Cookie linking v3\n\n\nCookies can contain a maximum of 4kb of data which must be transmitted\nacross the network twice before it can be used. For this reason, cookies\ntend to store only a number (or unique key) which links to a value in a\ndatabase. Data about a user is stored in a database and that record is given\na number (a unique key). Only this number is stored in the cookie on the\nuser's computer. When the user revisits the site which set the cookie, that\nsite can immediately have access to a potentially unlimited amount of\ninformation about the user simply by looking up the number in the database\nin which the number is a key. Linkability may be direct or indirect. For\nexample a key stored in one cookie may not link directly to a user's name\nbut instead the user's name may be deduced by examining two cookies replayed\nby separate domains but linked by a unique referrer. \n\nExample 1.\n----------\n\nImage A on Domain A replays a cookie linking to a record of the user's\nstreet name and number.\nImage B on Domain B replays a cookie which links to a record of the user's\nhome town.\nImages A and B are displayed on pages with session ID's within Domain C. \nBy using the referrer URI (which contains a unique session key), these two\ncookies be linked together to give a unique address and through another\ndatabase, the user's name.\n\nWith enough effort, similar but more sophisticated data mining techniques\nmay be applied to link even seemingly highly anonymised data with cookie\nvalues. P3P applies the principle of proportionality to such linkability.\nThe specification of the data and purposes covered by cookie should be\nthought of in terms of the analysis which might reasonably be carried out on\nsuch a cookie to achieve the stated purpose. For example if a cookie is set\nto track criminals' personal data then it is reasonable that a considerable\neffort might be put into database analysis. The cookie should therefore be\nsaid applying to personally identifiable data even if the data is actually\nhashed in the database. If on the other hand, the cookie is set in order to\ntrack a session and data is stored in the database but anonymised by\nhashing, then there is no need to state that the data is identifiable. This\ntype of anonymization is in theory not secure because hashes have a 1-1\ncorrespondence with ip addresses for example so by hashing all possible ip\naddresses, you can trace the original ip address. However extending the\ndefinition of linkability to this extent is neither practical nor\nreasonable.\n\nThird party cookies are cookies which are set by a domain other than the\npage being viewed. This is done through embedded images as in Example 1 and\ncan even occur in emails and applications which use web services, such as\nmusic players. While normally the information stored in one domain's cookie\ncannot be accessed by another domain, third party cookies bypass this\nmechanism by placing the same third party image in different domain's pages.\nThis allows tracking of users across different domains. The intention to\ncarry out such tracking activities through linking cookie keys across\ndifferent domains should also be declared.\n\nA connected problem is that a site SETTING a cookie may not be in control of\nall the purposes to which a cookie is put ON REPLAY. For example some\ndomains set a domain level cookie (at the level *.xyz.com) which is replayed\nto thousands of subhosts (a.xyz.com,b.xyz.com ...), whose data collection\npractices are not under their control. Currently the solution of evaluating\ncookies on replay has been discounted because of performance issues and data\nprotection issues linked to the act of storage of data on the user's\nmachine. Therefore P3P requires that entities publishing policies in\naccordance with correct practice declare any potential purposes to which a\ncookie might be put. It follows therefore that if a cookie is used for a new\nand unforseen purpose, it SHOULD be reset along with a fresh P3P policy.\n\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity New\ntechnologies for Combatting Fraud Unit TP 267 Via Enrico Fermi \n \n\n\n\n", "id": "lists-017-3585041"}, {"subject": "RE: Cookie linking v", "content": "The 2 cookie webservers don't need to co-ordinate a unique ID. The referrer\nsession key tells them that the 2 cookies refer to the same individual and\nso if they put their data together the full identity pops out after the\nevent, without any prior agreement.\n\nImage A sends cookie A and referrer session id\nImage B sends cookie B and the same referrer session id\nSo the cookie data is linked by the referrer session id\n\nDo you think this is unlikely? I'm not sure. I could try to make the example\nclearer or I could try to simplify it. One could have all three on the same\ndomain for example. The point was to illustrate how linking can be indirect.\n\n>**-----Original Message-----\n>**From: public-p3p-spec-request@w3.org \n>**[mailto:public-p3p-spec-request@w3.org] On Behalf Of Dobbs, Brooks\n>**Sent: 11 December 2003 16:28\n>**To: 'Giles Hogben'; public-p3p-spec\n>**Cc: WILIKENS MARC ANDRE\n>**Subject: RE: Cookie linking v3\n>**\n>**\n>**\n>**Giles,\n>**\n>**I agree with your first part but you lost me on the \n>**triangulation from 2 domains.  I don't think that this type \n>**of triangulation is really all that likely a scenario, \n>**remembering that Domains A and B are likely separate \n>**entities with separate web servers with no practical means \n>**of linking that cookie they each receive come from the same \n>**user (unless they have somehow coordinated to set the same \n>**unique_id).  I see where you are going with referrer and \n>**while that may give you a guess it would be a far fetched one.\n>**\n>**I also agree with your analysis of domain level cookies.  I \n>**think this has always been a real thorn in the side of P3P.  \n>**I will make a broad generalization here, and feel free to \n>**shoot it down, - most large domains and nearly all corporate \n>**domains outsource at least one or two hosts on their domain \n>**and additionally maintain exceptionally little control of \n>**their internal hosts (bobjones.company.com).  Here is \n>**another broad generalization\n>**- many, many corporate domains set a domain level unique id \n>**cookie which they claim to be pseudonymous.  I would venture \n>**a guess that that the majority of these folks also have a \n>**corporate intranet on the same domain that requires \n>**authentication usually via REMOTE_USER.  So now what is \n>**being logged on the intranet: REMOTE_USER and DOMAIN \n>**COOKIE!!!  Opps looks like Domain cookie is no longer \n>**anonymous.  I think that what all this points to is, sadly, \n>**true accuracy and compliancy are beyond the efforts that \n>**most implementers are taking at this time.\n>**\n>**-Brooks\n>**\n>**\n>**-----Original Message-----\n>**From: Giles Hogben [mailto:giles.hogben@jrc.it] \n>**Sent: Thursday, December 11, 2003 5:31 AM\n>**To: public-p3p-spec\n>**Cc: WILIKENS MARC ANDRE\n>**Subject: Cookie linking v3\n>**\n>**\n>**Cookies can contain a maximum of 4kb of data which must be \n>**transmitted across the network twice before it can be used. \n>**For this reason, cookies tend to store only a number (or \n>**unique key) which links to a value in a database. Data about \n>**a user is stored in a database and that record is given a \n>**number (a unique key). Only this number is stored in the \n>**cookie on the user's computer. When the user revisits the \n>**site which set the cookie, that site can immediately have \n>**access to a potentially unlimited amount of information \n>**about the user simply by looking up the number in the \n>**database in which the number is a key. Linkability may be \n>**direct or indirect. For example a key stored in one cookie \n>**may not link directly to a user's name but instead the \n>**user's name may be deduced by examining two cookies replayed \n>**by separate domains but linked by a unique referrer. \n>**\n>**Example 1.\n>**----------\n>**\n>**Image A on Domain A replays a cookie linking to a record of \n>**the user's street name and number. Image B on Domain B \n>**replays a cookie which links to a record of the user's home \n>**town. Images A and B are displayed on pages with session \n>**ID's within Domain C. \n>**By using the referrer URI (which contains a unique session \n>**key), these two cookies be linked together to give a unique \n>**address and through another database, the user's name.\n>**\n>**With enough effort, similar but more sophisticated data \n>**mining techniques may be applied to link even seemingly \n>**highly anonymised data with cookie values. P3P applies the \n>**principle of proportionality to such linkability. The \n>**specification of the data and purposes covered by cookie \n>**should be thought of in terms of the analysis which might \n>**reasonably be carried out on such a cookie to achieve the \n>**stated purpose. For example if a cookie is set to track \n>**criminals' personal data then it is reasonable that a \n>**considerable effort might be put into database analysis. The \n>**cookie should therefore be said applying to personally \n>**identifiable data even if the data is actually hashed in the \n>**database. If on the other hand, the cookie is set in order \n>**to track a session and data is stored in the database but \n>**anonymised by hashing, then there is no need to state that \n>**the data is identifiable. This type of anonymization is in \n>**theory not secure because hashes have a 1-1 correspondence \n>**with ip addresses for example so by hashing all possible ip \n>**addresses, you can trace the original ip address. However \n>**extending the definition of linkability to this extent is \n>**neither practical nor reasonable.\n>**\n>**Third party cookies are cookies which are set by a domain \n>**other than the page being viewed. This is done through \n>**embedded images as in Example 1 and can even occur in emails \n>**and applications which use web services, such as music \n>**players. While normally the information stored in one \n>**domain's cookie cannot be accessed by another domain, third \n>**party cookies bypass this mechanism by placing the same \n>**third party image in different domain's pages. This allows \n>**tracking of users across different domains. The intention to \n>**carry out such tracking activities through linking cookie \n>**keys across different domains should also be declared.\n>**\n>**A connected problem is that a site SETTING a cookie may not \n>**be in control of all the purposes to which a cookie is put \n>**ON REPLAY. For example some domains set a domain level \n>**cookie (at the level *.xyz.com) which is replayed to \n>**thousands of subhosts (a.xyz.com,b.xyz.com ...), whose data \n>**collection practices are not under their control. Currently \n>**the solution of evaluating cookies on replay has been \n>**discounted because of performance issues and data protection \n>**issues linked to the act of storage of data on the user's \n>**machine. Therefore P3P requires that entities publishing \n>**policies in accordance with correct practice declare any \n>**potential purposes to which a cookie might be put. It \n>**follows therefore that if a cookie is used for a new and \n>**unforseen purpose, it SHOULD be reset along with a fresh P3P policy.\n>**\n>**\n>**-------------------------------------\n>**Giles Hogben\n>**European Commission Joint Research Centre\n>**Institute for the Protection and Security of the Citizen \n>**Cybersecurity New technologies for Combatting Fraud Unit TP \n>**267 Via Enrico Fermi \n>** \n>**\n>**\n\n\n\n", "id": "lists-017-3598922"}, {"subject": "[fwd] PR: Privacy Manager of the Year and Privacy Company of the Year Announce", "content": "Dear all, \n\nI'm pleased that Anne received this award as she was such a help for P3P\nin all those years.\n\nFor IBM, the award might encourage them to further maintain or extend\ntheir support for P3P and other privacy languages. \n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n----- Forwarded message from  The Privacy Manager <robert@theprivacymanager.com> -----\n\nFrom: Robert@stanford.loosefoot.com, Vinet@stanford.loosefoot.com,\nPublisher@stanford.loosefoot.com,\nThe Privacy Manager <robert@theprivacymanager.com>\nTo: Rigo@stanford.loosefoot.com, Wenning@stanford.loosefoot.com,\nW3C@stanford.loosefoot.com, France <rigo@w3.org>\nDate: Thu, 11 Dec 2003 03:49:04 GMT\nSubject: PR: Privacy Manager of the Year and Privacy Company of the Year Announced\nOrganization: The Privacy Manager\n\n\nFor Immediate Release\n\nDecember 10, 2003\n\nThe Privacy Manager of the Year 2003: Ann Cavoukian, Ph.D.\n\nFredericton, NB, Canada - The Publisher of The Privacy Manager monthly\nnewsletter, Robert Vinet, is please to announce Ann Cavoukian as The\nPrivacy Manager of the Year 2003.\n\n\"It is with great pleasure that we recognize Ann Cavoukian, the\nInformation and Privacy Commissioner for Ontario, as The Privacy Manager\nof the Year, 2003,\" said Robert Vinet, Publisher and Editor of The\nPrivacy Manager.\n\n\"Dr. Cavoukian is a world renowned leading authority on privacy and data\nprotection issues and her expertise is regularly sought throughout the\nindustry. Ann understands privacy very well and is an unusually wise\nprivacy leader.\"\n\n\"Whether Ann is speaking before Government committees, business groups\nor giving advice to law enforcement agencies, she always takes a\nmiddle-of-the-road approach that still respects the privacy of\ncitizens,\" said Vinet\n\n\"Dr. Cavoukian is always ready to providing insight into the importance\nof good privacy practices. Ann recognizes business demands as well as\nthe public safety needs in this complicated post-September 11 world. Ann\nagrees that public safety is paramount but she insists this must be\nbalanced against privacy. Ann understands the value of consumer\ninformation but advocates preserving privacy as a good business\npractice,\" said Vinet.\n\nAs Commissioner, Dr. Cavoukian oversees the operations of Ontario's\nfreedom of information and privacy legislation that applies to both\nprovincial and municipal governments. This past year, she has been\ninstrumental in preparing companies across Canada ramp up for the\nfederal Personal Information Protection and Electronic Documents Act. On\nJanuary 1, 2004, PIPEDA comes into effect for all companies and\nnot-for-profit organizations doing business in Canada.\n\nIn October 2003, the publishers of The Privacy Manager, an monthly\nnewsletter targeted to the privacy professionals around the world, asked\ntheir subscribers to nominate candidates for both The Privacy Manager of\nthe Year and The Privacy Company of the Year. The winners were chosen\nfrom the list of nominees.\n\n\"Many privacy leaders from around the world were nominated as The\nPrivacy Manager of the Year. But the one name the kept coming up was\nthat of Dr. Cavoukian,\" said Robert Vinet, Publisher and Editor of The\nPrivacy Manager. \"We looked at all the nominees, and the one person that\nwas head and shoulders above the rest was Ann.\"\n\n\"In a world were medical records, credit reports, employment records and\ncommunications are being stored electronically, profiled and put up for\nsale, Dr. Cavoukian is able to guide businesses to succeed while still\npreserving their customers' privacy.\"\n\n\"We live in a world where, increasingly, every detail of our lives -\neverything from where we go, what we buy, who we speak with and what we\ndo - can be known to others at the click of a mouse. We live in a world\nwhere Governments, in the pretext of fighting terror, want to combine\nevery piece of data about us so they can know us better than we know\nourselves,\" said Vinet.\n\n\"It is in this world that we find Dr. Ann Cavoukian influencing\ncorporations to take a middle-of-the road-course between the demands of\nprivacy and those of profit. Dr. Cavoukian steers Government agencies to\nbalance security with the 'right to be left alone.' It is this\nintelligent foresight and competent guidance that has led us to name Dr.\nAnn Cavoukian The Privacy Manager of the Year 2003,\" added Vinet.\n\nAnn Cavoukian, Ph.D., has been the Information and Privacy Commissioner\nof Ontario since May 1997. Ann is often called upon to share her\nexpertise at leading industry forums.\n\nAnn stresses that companies will gain a significant advantage over their\ncompetitors when they carve out a reputation for protecting personal\ninformation.\n\nHer published works include two books. \"Who Knows: Safeguarding Your\nPrivacy in a Networked World (McGraw-Hill, 1996)\" which she co-wrote\nwith Don Tapscott is consumer-oriented. Her most recent book, \"The\nPrivacy Payoff (McGraw-Hill Ryerson, 2002)\" co-authored by technology\njournalist Tyler Hamilton, addresses how successful businesses build\ncustomer trust. The Privacy Payoff is aimed at small and medium sized\nbusiness and provides an excellent insight into the importance of good\nprivacy practices.\n\nDr. Cavoukian's most recent research paper is entitled \"Privacy and\nBoards of Directors: What You Don't Know as a Director Can Hurt You.\"\nThe paper explains what internationally recognized fair privacy\nprinciples are, outlines the business case for implementing sound\nprivacy practices and suggests key steps that company directors should\ntake.\n\nAnn is interested in advancing privacy protections through\nprivacy-enhancing technologies and has been involved in a number of\ninternational committees focused on privacy and technology, including\nthe World Wide Web Consortium's P3P (Platform for Privacy Preferences)\ninitiative. She has also served as a member of the American Task Force\non Privacy, Technology and Criminal Justice Information.\n\nAnn received her M.A. and Ph.D. in Psychology from the University of\nToronto, where she specialized in criminology and law, and lectured on\npsychology and the criminal justice system.\n\nAbout The Privacy Manager The Privacy Manager\n(<www.ThePrivacyManager.com>) is a subscription newsletter on privacy\nand privacy-related issues. Every month The Privacy Manager provides\nnews and analysis from around the world to privacy leaders around the\nworld. The Privacy Manager enables business leaders to understand and\nrespond to the latest privacy trends and developments. The Privacy\nManager web site features a news section that is updated every weekday.\nThe site has a new Career Center where companies can post open positions\nfor free. The site also hosts a calendar page that lists privacy events\naround the world.\n\nThe Privacy Manager is written for business, technology, and government\nleaders who manage data systems, handle consumer affairs, provide legal\nadvice, and work for government agencies.\n\nThe Privacy Manager is published monthly by privately held Privacy\nPublishing Corporation.\n\nNote: The current issue of The Privacy Manager is available for free\ndownloading at\n<http://www.theprivacymanager.com/special/requestv0312.htm>\n\n\nOther Media Releases Released Today: 1. The Privacy Company of the Year\n2003 - IBM Corporation 2. The Privacy Manager Announces Free Privacy\nCareer Center\n\nRobert Vinet, Publisher and Editor The Privacy Manager 74 Kenneth St\nFredericton, NB Canada  E3B 8B4\n\n<http://www.ThePrivacyManager.com>\n\nPhone: +506.454.7580 Fax: +916.314.8247\n\n###\n\nFor Immediate Release\n\nDecember 10, 2003\n\nThe Privacy Company of the Year 2003 - IBM Corporation\n\nFredericton, NB, Canada - Robert Vinet, Publisher of The Privacy Manager\nnewsletter said, \"It is with great pleasure that we recognize IBM\nCorporation as The Privacy Company of the Year 2003 for their\noutstanding promotion of sound privacy practices and their development\nof privacy software.\"\n\n\"The massive improvements in processor power, storage capacity and\nnetwork connectivity are enabling businesses and Governments to create\nunprecedented quantities of digital data, much of it personal\ninformation,\" said Vinet. \"We live in an increasingly networked world in\nwhich instantaneous data transfers across borders are routine business\ntransactions. Companies are grappling to operate within different data\nprotection policies in the various jurisdictions in which they operate.\"\n\n\"It is in this environment that IBM developed a new programming language\ncalled the Enterprise Privacy Authorization Language (EPAL) that applies\nprivacy rules across interconnected business systems. With EPAL,\npersonal data can have policies attached to it as it moves from\napplication to application within an enterprise around the world,\" said\nVinet.\n\nInternational organizations must respect different privacy legislation\naround the world. This means they must build privacy into their business\npractices and systems and develop corporate cultures of privacy to earn\nthe trust of clients, potential clients, and data protection regulators.\n\nIn October 2003, the publishers of The Privacy Manager - a monthly\nnewsletter targeted to the privacy professionals around the world -\nasked their subscribers to nominate candidates for both The Privacy\nManager of the Year and The Privacy Company of the Year. The winners\nwere chosen from the list of nominees.\n\n\"IBM was nominated for The Privacy Company of the Year more than any\nother company,\" said Robert Vinet, Publisher of The Privacy Manager.\n\"Several other companies from around the world were nominated, but the\nnumber of nominations IBM received outnumbered the others put together.\nIn fact, IBM received so many nominations for its software development,\nresearch and promotion of sound privacy principals that we almost felt\ncompelled to award them The Privacy Company of the Year on that basis\nalone.\"\n\n\"Protecting the personal information of citizens is essential in today's\ninterconnected world where large volumes of personally identifiable\ninformation are stored and managed electronically and available to\nothers at a click of a mouse,\" said Robert Vinet.\n\n\"National and multinational companies with huge databases that need to\nbe accessed by various divisions, for different purposes, often struggle\nwith how to comply with often conflicting privacy laws and regulations.\nWith IBM's EPAL, companies can build privacy rules into databases so the\nvarious regulations across different jurisdictions can be respected,\"\nsaid Vinet. \"This is a significant move forward for large corporations\nin this interconnected world where different countries have different\napproaches to personal data,\" added Vinet.\n\nOn December 1, 2003, IBM announced it was turning EPAL over to the World\nWide Web Consortium (W3C) in the hopes that it will become an\ninternational standard and will help automate privacy management tasks,\nimprove consumer trust and reduce the cost of privacy compliance.\n\n\"It is for this software and IBM's overall approach to privacy that we\nare please to recognize the IBM Corporation as The Privacy Company of\nthe Year 2003,\" added Vinet.\n\nBased on Extensible Markup Language (XML), EPAL enables developers to\nbuild security policy enforcement features directly into enterprise\nsoftware applications. The EPAL standard builds upon existing privacy\nspecifications such as the Platform for Privacy Preferences (P3P).\n\nThe Privacy Manager (<www.ThePrivacyManager.com>) is a subscription\nnewsletter on privacy and privacy-related issues. Every month The\nPrivacy Manager provides news and analysis from around the world to\nprivacy leaders around the world. The Privacy Manager enables business\nleaders to understand and respond to the latest privacy trends and\ndevelopments. The Privacy Manager web site features a news section that\nis updated every weekday. The site has a new Career Center where\ncompanies can post open positions for free. The site also hosts a\ncalendar page that lists privacy events around the world.\n\nThe Privacy Manager is written for business, technology, and government\nleaders who manage data systems, handle consumer affairs, provide legal\nadvice, and work for government agencies.\n\nThe Privacy Manager is published monthly by privately held Privacy\nPublishing Corporation.\n\nNote: The current issue of The Privacy Manager is available for free\ndownloading at\n<http://www.theprivacymanager.com/special/requestv0312.htm>\n\n\nOther Media Advisories Released Today: 1. The Privacy Manager of the\nYear 2003 - Ann Cavoukian 2. The Privacy Manager Announces Free Privacy\nCareer Center\n\nRobert Vinet Privacy Policy Consultant Publisher and Editor, The Privacy\nManager Robert(at)ThePrivacyManager.com\n\n74 Kenneth St Fredericton, NB Canada  E3B 8B4\n\n<http://www.ThePrivacyManager.com>\n\nPhone: +506.454.7580 Fax: +916.314.8247\n\n\n-30- ###\n\n\n\n----- End forwarded message -----\n\n\n\n", "id": "lists-017-3614518"}, {"subject": "[Agenda] 17 December cal", "content": "The next P3P specification group conference call will be on\nWednesday, December 17, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n1/ Christmas holidays and further planning\n\n2/ decision on consent-choices\n   is it final? \n where to put it?\n\n3/ Continued discussion of agent-relationsships\n\n4/ cookie linking v3  from Giles\n\nIt would be very helpful to see some discussion on our mailing lists \nto prepare the meeting\n\nRigo\n\n\n\n", "id": "lists-017-3637537"}, {"subject": "Re: MINUTES 03 December 2003 P3P Specification Cal", "content": "On Wed, Dec 10, 2003 at 11:03:18AM -0500, Stampley, David A wrote:\n> 3.      English language wording of \"courts\" and \"law\"\n> \n> 3.1.   Dave proposes:  \"We will compensate individuals if it is determined\n> that we have violated our privacy policy.\"\n> \nThis was actually the wording for <money />\n\nRigo\n\n\n\n", "id": "lists-017-3644340"}, {"subject": "Re: [Domain/Agent] new proposa", "content": "Dear all, \n\nplease find the updated HTML-Version at \n\nhttp://www.w3.org/P3P/2003/12-domain-relationsships.html\n\nThe document is now named P3P 1.1 Domain Relationships\n\nBest \n\nRigo\n\nOn Wed, Dec 10, 2003 at 11:19:41PM -0600, Humphrey, Jack wrote:\n> Here is a new version of the domain relationship proposal. The first\n> attachment is a \"clean copy\" and the second has highlighting showing all the\n> changes made from the previous same-entity domain relationship proposal --\n> less readable but useful if you're familiar with the previous proposal.\n>  \n\n\n\n", "id": "lists-017-3651369"}, {"subject": "[Minutes] 17 December cal", "content": "Present: \nDave Stampley\nJack Humphrey\nGiles Hogben\nRigo Wenning\n\n1/ Christmas holidays and further planning\n\nRigo told that he will be on holiday until 11 Jan 2004 and that the next\ncall will logically be on 14 Jan 2004. All others will have shorter\nholidays. Everybody should be encouraged to continue discussion the\ncurrent issues on the mailing-list.\n\n2/ decision on consent-choices\n   is it final? \n where to put it?\n\nAs Matthias wasn't on the call, there was no way to decide it.\n\nACTION Rigo to coordinate with Matthias and Lorrie about status of this\nand to report back\n\n3/ Continued discussion of agent-relationsships\n\nWe first had agreement, that the entity-type attribute in the current \ndomainrelationsship proposal should be removed. The scope of\nrelationsships are currently only ours and agents. \n\nWe had a lengthy discussion about the issue of ad-networks and the way\nthey work. Actually, P3P does not accommodate their working models well.\nWe discussed the remarks by Brooks and tried again to understand the\nissue. We concluded that this would need to have a Face-to-Face meeting. \n\nACTION: Rigo propose dates and location for F2F meeting\n\n4/ cookie linking v3  from Giles\n\nwe had no time left to further discuss Giles draft\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-3658752"}, {"subject": "F2F Meeting location and dat", "content": "I had a short conversation with our admin staff. \n\nA face-to-face meeting would be possible around the technical plenary.\nThe meeting would be in our office in Sophia Antipolis (near\nNice/France) at 6 march 2004. \n\nThis would be a one day meeting, but we could have two days, if needed.\nYou would be able to attend the technical plenary at the same time.\n(TP is from 1-5 march 2004)\n\nCould you please email me back, whether you are available to help my\nplanning. I also take alternative dates and venues.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-3666102"}, {"subject": "Season's Greetings and Holiday announcemen", "content": "Dear all, \n\na year of hard labour is over. We are quite advanced and still on\nschedule. I think we achieved a lot, but there is more to come. We\nwant P3P 1.1 to be finished by the end of June 2004. I think we can make\nit. \n\nI will be on holidays until 11 Jan, as already said on the last P3P\ncall. I will occasionally read email, but don't expect timely responses.\n\nI wish you all a Merry Christmas and a Happy New Year.\n\nThanks for all the help and support\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-3672765"}, {"subject": "CFP: International Journal of Web Services (IJWS", "content": "> CALL FOR PAPERS\n> ===============\n> \n> International Journal of Web Services (IJWS)\n> --------------------------------------------\n> ISSN (PRINT): 1741-1106 ISSN (ONLINE): 1741-1114 \n> A Publication of Inderscience Publishers (www.inderscience.com)\n> \n> \n> The International Journal of Web Services proposes and fosters discussion\n> on web service technology with a focus on its application, emphasising\n> issues of architecture, implementation, and standardisation. This\n> perspective acknowledges the complexity and challenges developers are\n> currently faced with when designing and deploying web service based\n> solutions. As one cornerstone of web service technology, the journal will\n> also include topics on standardisation with special emphasis on in-depth\n> analysis of practical applications of existing standards as well as\n> proposals for general solutions to still-missing pieces.\n> \n> OBJECTIVES \n> The objectives of the journal are to establish an effective channel of\n> communication between decision makers, academic and research institutions\n> and persons concerned with the practical deployment of web services in\n> industry. It also aims to promote and coordinate developments in the field\n> of web services. By tackling issues of current research, standardisation,\n> and deployment, it brings together people from both academia and industry.\n> By allowing them to share new ideas and exchange best practice approaches,\n> it creates a vital resource for both to drive future work and leverage web\n> service usage. The international dimension is emphasised in order to\n> overcome cultural and national barriers and to meet the needs of\n> accelerating technological and ecological change and changes in the global\n> economy.\n>  \n> READERSHIP \n> The journal provides a vehicle to help industry professionals, academics,\n> researchers and decision makers, working in the field of web service\n> technology, engineering and standardisation, to disseminate information\n> and to learn from each others' work.\n>  \n> CONTENTS\n> The journal publishes original papers, review papers, technical reports,\n> new specification proposals, case studies, conference reports, management\n> reports, book reviews, notes, commentaries, and news. Special Issues\n> devoted to important topics in web service technology will occasionally be\n> published. \n>  \n> SCOPE: Topics of interest include, but are not limited to, the following:\n> - Web service architectures \n> - Service oriented architectures \n> - Web service security \n> - Deployment of web service-based solutions in large organisations \n> - Case studies describing web service projects \n> - Deployment and appraisal of current standardisation \n> - Business processes based on web services \n> - Web services in B2B and B2Bi \n> - Practical applications of Grid computing \n> - Missing standards of all layers of the web service stack \n> - Performance issues \n> - Security mechanisms, especially their cross-platform interoperability \n> - Integration of web services into existing infrastructures \n> - Legacy systems wrapping and integration based on web services \n> - Cross-organisational collaborations based on web services\n>  \n> SUBMISSION FOR PAPERS\n> Papers and queries should be submitted to: \n> \n> Editor-in-Chief: Dr. Liang-Jie Zhang \n> e-Business Solutions & Autonomic Computing Dept. \n> IBM T.J. Watson Research Center, 1101 Kitchawan Road, Route 134, \n> Yorktown Heights, NY 10598, USA\n> Tel: 914-945-3976\n> E-mail: zhanglj@us.ibm.com\n> \n> Please see the Inderscience website www.inderscience.com for guide for\n> authors and sample of requirements for the submission of papers.\n\n\n\n", "id": "lists-017-3679953"}, {"subject": "CFP: 2004 IEEE International Conference on Services Computing (SC C 2004", "content": "Apologies if you receive multiple copies of this message.\n\n2004 IEEE International Conference on Services Computing (SCC 2004)\n===================================================================\nSeptember 15-18 2004, Shanghai, China\nhttp://conferences.computer.org/scc/2004\n\nSponsored by IEEE Computer Society Technical Community for Services\nComputing (TCSC)\nhttp://tab.computer.org/tcsc/\n                                                        \nWith support of \nShanghai Jiao Tong University (SJTU), China\nE-Business Technology Institute, The University of Hong Kong, China\n\n\nCall for Papers (Preliminary)\n-----------------------------\n\nServices computing is the evolution of Internet computing by leveraging\nservices oriented architecture. It encompasses a new class of ground\nbreaking technology suite - Web services and services oriented Grid/Utility\nComputing, e-Business, and Autonomic Computing. Web services is finding\npervasive applications in new products and applications. Grid computing has\nbeen leveraging Web services standards to provide standard interfaces for\nGrid resources. The service collaboration and management afforded by service\ncomputing will allow disaggregated businesses to form value chains for\nimproving productivity. The paradigm shift in focus from data management to\nprocess management is also leading to large scale implementations based on\nservice-oriented architecture.\n\nThe 2004 IEEE International Conference on Services Computing (SCC 2004) will\nbe the first annual conference sponsored by IEEE Computer Society Technical\nCommunity for Services Computing (TCSC) in collaboration with other\ntechnical committees in IEEE Computer Society and other organizations in the\nworld. The scope of SCC 2004 is Web services centric Services Computing that\ncovers Grid/Utility Computing, e-Business Computing, and Autonomic\nComputing. It will foster cross-disciplinary interaction in the field of\nservices centric computing technologies and applications. The insight and\nvision would shape the research agenda in services computing over the next\ndecade.\n\nSCC 2004 will be held in Shanghai, China, September 15-18 2004. SCC 2004 is\nthe extended event of the 2004 IEEE International Conference on Web Services\n(ICWS 2004, http://conferences.computer.org/icws/2004), which will be held\nin San Diego, July 6-9 2004. SCC 2004 provides a forum for researchers and\nindustry practitioners to exchange information regarding advancements in the\nstate of art in Services Computing, to identify emerging research topics,\nand to explore the future directions of services computing.\n\nIn SCC 2004, topics of interest include, but are not limited to, the\nfollowing: \n\n- Formal foundations of Services Computing \n- Web services and Grid architecture\n- Web services and Grid security \n- Frameworks for building Web services and Grid applications \n- Grid services creation and enabling infrastructures \n- Web services representation, discovery, composition (Web processes)\n- Grid resource management\n- Dynamic Web Services invocation and orchestration\n- Quality of services and deployment issues\n- Solution management for Web services and Grid infrastructure \n- Standards (e.g., UDDI, SOAP) and their enhancements\n- Role of semantics for Web services, Business semantic computing\n- Detailed applications and case studies for Web services and Grid\napplications for E-business, E-service applications, Science and Engineering\n- Services-oriented business process integration and management \n- Business Grid: Business process Grid and business application Grid\n- Services oriented autonomic computing technology and solutions for IT\nsystem and e-business system management\n\n\nPAPER SUBMISSIONS \n\nThe official language of SCC 2004 is English. Authors should submit a full\n(8-page) paper via electronic submission. The on-line paper submission and\nreview system will be available on http://conferences.computer.org/scc/2004\n. The Conference Proceedings will be published by IEEE Computer Society\nPress. The authors of the best papers will be encouraged to revise their\npapers for potential publication in International Journal of Web services\nResearch (JWSR, http://www.idea-group.com/journals/details.asp?id=4138 ) and\nother journals. The main paper sessions are expected to be on 15,16,17,18\nSeptember.\n\nSCC 2004 will present one Best Paper Award and 3-5 Best Student Paper\nAwards. The first authors of the best student papers should be full-time\nstudents.\n\n\nINDUSTRY and APPLICATION PAPER SUBMISSIONS \n\nThe official language of SCC 2004 is English. Authors should submit a 4-page\npaper via electronic submission. The on-line paper submission and review\nsystem will be available on http://conferences.computer.org/scc/2004 . The\nProceedings will be published.\n\n\nTUTORIAL SUBMISSIONS \n\nThe official language of SCC 2004 is English. Authors should submit a\nTutorial proposal of approximately 4 pages including structure, content and\nauthor(s) CV(s) via electronic submission. The on-line paper submission and\nreview system will be available on http://conferences.computer.org/scc/2004.\nIt is planned to hold the tutorials on Tuesfday 14 and Wednesday 15\nSeptember.\n\n\nWORKSHOP SUBMISSIONS \n\nThe official language of SCC 2004 is English. Authors should submit a\nWorkshop proposal of approximately 4 pages including structure, content and\nleader(s) CV(s) via electronic submission. The on-line paper submission and\nreview system will be available on http://conferences.computer.org/scc/2004.\nIt is planned to hold the workshops on Tuesday 14 September 2004 before the\nmain conference.\n\n\nIMPORTANT DATES \n\nApril 30, 2004, Submission of papers, tutorial proposals, workshop proposals\n\nJune 11, 2004, Notification of acceptance \nJuly 02, 2004, Camera-Ready copy of accepted papers due \nSeptember 15-18, 2004, SCC 2004 \n\n\nINDUSTRY EXHIBITS\n\nThe premier industry exhibition of services computing engineering is a\nhighlight of the annual IEEE International Conference on Services Computing\n(SCC). Exhibiting companies and research institutions provide products and\nservices in areas such as Web Services, Grid/Utility Computing, e-Business\nSolutions, Middleware and Tools, Autonomic computing middleware and\nsolutions, as well as e-government and digital city solutions. In addition,\nparticipating companies will be able to give a product presentation in an\nexhibitor's track.\n\n\nPROGRAM CHAIRS\n\nProf. Amit P. Sheth (amit@cs.uga.edu), University of Georgia, and Semagix,\nInc. USA\nProf Keith G Jeffery (kgj@rl.ac.uk), CCLRC Rutherford Appleton Laboratory,\nUK\n\n\nGENERAL CO-CHAIRS\n\nLiang-Jie Zhang (zhanglj@us.ibm.com), IBM T.J. Watson Research Center, USA\nMinglu Li (li-ml@cs.sjtu.edu.cn), Shanghai Jiaotong University, China\n\n\nPUBLICITY CHAIRS\n\nPatrick C. K. Hung (Patrick.Hung@csiro.au), CSIRO, Australia\nHaifei Li, Nyack College, USA\n\n\nCONTACT INFORMATION\n\nFor any general information, please contact: Liang-Jie (LJ) Zhang at\nzhanglj@us.ibm.com or Minglu Li at li-ml@cs.sjtu.edu.cn. For other technical\nprogram information, please contact program chairs.\n\n\n\n", "id": "lists-017-3690923"}, {"subject": "The 3rd ICWS 2004 CFP  Research Papers, Industrial Extended Abst ract and Tutoria", "content": "*************** Happy 2004 **************** \n\nApologies if you receive multiple copies of this message.\n\n\n2004 IEEE International Conference on Web Services (ICWS 2004)\n==============================================================\nTheme: Convergence of Web Services, Grid Computing, e-Business and Autonomic\nComputing\nJuly 6-9, 2004, San Diego, California, USA\nhttp://conferences.computer.org/icws/2004/\n\nSponsored by IEEE Computer Society Technical Community for Services\nComputing (TCSC)\nhttp://tab.computer.org/tcsc/\n\n\n\n----------------------------------------------------------\nICWS 2004 Call for Papers\n----------------------------------------------------------\n\nICWS is a forum for researchers and industry practitioner to exchange\ninformation regarding advancements in the state of art research and practice\nof Web Services, to identify emerging research topics, and to define the\nfuture directions of Web Services computing. ICWS 2004 has special interest\nin papers that contribute to the convergence of Web Services, Grid\nComputing, e-Business and Autonomic Computing, or those that apply\ntechniques from one area to another. The industry application areas that are\nof interest are business-to-business integration, business process\nintegration and management, content management, e-sourcing, composite Web\nservices creation, design collaboration for computer engineering, multimedia\ncommunication, digital TV, and interactive Web solutions. Currently, Grid\ncomputing has also started to leverage Web services to define standard\ninterfaces for Business Grid services and generic reusable Grid resources.\n\nAs the first academic conference in the field of Web services, the 2003\nFirst International Conference on Web Services (ICWS'03) was held at the\nMonte Carlo Resort in Las Vegas, Nevada, June 23 - 26, 2003, attracting\nhundreds of participants from 25 countries (USA, India, France, China, Hong\nKong, Taiwan, Singapore, Australia, Canada, UK, Sweden, Switzerland, The\nNetherlands, Germany, Japan, Italy, Korea, Thailand, Finland, Austria, New\nZealand, Poland, and Turkey). ICWS'03 has proven to be an excellent catalyst\nfor research and collaboration. With the growing interests of Web Services\nin both business and scientific information management practice, we fully\nexpect that ICWS 2004 will continue this success. The program of ICWS'04\nwill feature a variety of papers on fundamentals, infrastructure, technology\nsupport, and business management for Web Services. Topics of interest\ninclude, but are not limited to, the following:\n- Mathematical foundations of Web Services\n- Data Management Issues in Web Services\n- Frameworks for building Web Service applications\n- Composite Web Service creation and enabling infrastructures  (e.g.,\nworkflow technology)\n- Web Services Modeling & Design\n- Web Services Discovery & Selection\n- Semantic Web, Ontologies, and Web Services\n- Dynamic invocation mechanisms for Web Services\n- Contractual Issues between provider and consumer of Web Services\n- Version Management in Web services\n- Customization of Web Services\n- Software reusability\n- Web Services architecture\n- Web Services Negotiation & Agreement\n- UDDI and SOAP enhancements\n- Web Services and Process Management\n- Trust, Security & Privacy in Web Services\n- Scalability and Performance of Web Services\n- Web Services Standards and Technologies\n- Autonomic Computing for Web Services Infrastructure\n- Autonomic Middleware and Toolkits for Monitoring and Management\n- Autonomic e-Business integration and collaboration\n- Wireless Web, Mobility, and Web Services\n- Web Service Based Grid Computing and Peer to Peer Computing\n- Business Grid Solution Architecture\n- Web Services based Applications for e-Commerce\n- Quality of service for Web Services\n- Multimedia applications using Web Services\n- Grid Architectures, Middleware and Toolkits\n- Grid Services Integration and Management\n- Economics and Pricing models of utility computing and Web Services\n- Resource management of Web Services\n- Solution Management for Web Services\n- Adoption of Web Services by organizations\n- Case studies on Web Services based applications\n- Business process integration and management using Web Services\n- Impact of Web Services Architecture on Business continuity\n- Changing role of Information Technology Departments in Organizations\n\n\nPUBLICATION:\n\nAll accepted papers will be published in the conference proceedings in\nhardcopy and on-line version by IEEE Computer Society. The selected papers\nwill be invited to for submission to the International Journal of Web\nServices Research (JWSR), International Journal of Grid and Utility\nComputing, International Journal of Business Process Integration and\nManagement, and International Journal of Autonomic Computing.\n\n\nIMPORTANT DATES:\n\nJanuary 26 (Monday): Abstract Submission (optional)\nFeb. 2, 2004 (Monday): Submission Due\nMarch 19, 2004 (Friday): Notification of acceptance\nApril 16, 2004 (Friday): Camera-Ready copy & Author Pre-registration due\nJuly 6 - July 9, 2004: ICWS'04 International Conference on Web Services\n\n\nPROGRAM COMMITTEE CO-CHAIRS\n\nProf. Dr. Hemant Jain\nWisconsin Distinguished &\nTata Consultancy Services Professor\nSchool of Business Administration\nUniversity of Wisconsin- Milwaukee\nMilwaukee, WI 53201, USA\nPhone: (414) 229-4832\nFax: (414) 229-6957\njain@uwm.edu\n\nProf. Dr. Ling Liu\nCollege of Computing\nGeorgia Institute of Technology\n801 Atlantic Drive, Atlanta\nGeorgia 30332-0280, USA\nPhone: (404) 385-1139\nFax: (404) 894-9846\nlingliu@cc.gatech.edu\n\n\nORGANIZING COMMITTEE\n\nGeneral Chair:\nLiang-Jie Zhang (zhanglj@us.ibm.com), IBM T.J. Watson Research Center, USA\n\nIndustrial Track Co-Chairs:\nSinisa Zimek (sinisa.zimek@sap.com), SAP Labs, Inc. USA\nRoger Barga (barga@microsoft.com), Microsoft Research, USA\n\nTutorials Chairs:\nAbdelsalam (Sumi) Helal, (helal@cise.ufl.edu) University of Florida, USA\n\nPanels Chair:\nCalton Pu, (calton@cc.gatech.edu) Georgia Tech, USA\n\nPoster Chair:\nMario Jeckle (mario@jeckle.de), U. of Applied Sciences Furtwangen, Germany\nGraciela Gonzalez (csc_ghg@shsu.edu), Sam Houston State University, USA\n\nDemo & Exhibits Chair:\nSimanta Mitra (smitra@iastate.edu), Iowa State University, USA\n\nPublication Chair:\nJen-Yao Chung (jychung@us.ibm.com), IBM T.J. Watson Research Center, USA\n\nSponsor Chair:\nDavid B. Flaxer (flaxer@us.ibm.com), IBM T.J. Watson Research Center, USA\n\nLocal Arrangement Chair:\nKwei-Jay Lin, UCI, USA\n\nPublicity Chairs:\nPatrick C. K. Hung (Patrick.Hung@csiro.au), CSIRO, Australia\nHaifei Li, Nyack College, USA\nMinglu Li, Shanghai Jiaotong University, China\n\nWeb Chair:\nCarolyn McGregor, U. of Western Sydney, Australia\nJia Zhang, Northern Illinois University, USA\n\n\nPROGRAM COMMITTEE\n\nKarl Aberer, EPFL, Switzerland\nAkhilesh Bajaj, University of Tulsa, USA\nRoger S. Barga, Microsoft Research, USA\nClaudia M Bauzer Medeiros, UNICAMP, Brazil\nElisa Bertino, University of Milano, Italy\nKrishna Bhagavatula, TCS America, USA\nAthman Bouguettaya , Virginia Tech, USA\nDavid Buttler, Lawrence Livermore National Laboratory, USA\nMohammed I. Bu-Hulaiga, Joatha Informatics Consulting, Saudi Arabia\nFabio Casati, Hewlett-Packard, USA\nUgur Cetintemel, Brown University, USA\nAlok Chaturvedi, Purdue University, USA\nMichael Champion, Software AG & W3C Web Services\nArchitecture Working Group, USA\nJian Chen, Tsinghua University, China\nDickson K.W. Chiu, Dickson Computer Systems, Hong Kong\nAlok Choudhary , Northwestern University, USA\nJen-Yao Chung , IBM T.J. Watson Research Center, USA\nBrian F. Cooper, Georgia Institute of Technology, USA\nTerence Critchlow, LLNL, USA\nIsabel Cruz, Uni. of Illinois at Chicago, USA\nFrancisco Curbera, IBM T.J. Watson Research Center, USA\nDavid De Roure, University of Southampton, UK\nAsuman Dogac, Middle East Technical University, Turkey\nPhillip Ein-Dor, Tel-Aviv University, Israel\nDavid W Embley, Birmingham Young University, USA\nOpher Etzion, IBM Research Laboratory, Israel\nPeter Fankhauser, Fraunhofer IPSI, Germany\nDieter Fensel, DERI, Ireland\nAvigdor Gal, Technion, Israel\nWolfgang Gentzsch , Sun Microsystems, USA\nAmarnath Gupta, University of California, San Diego, USA\nMarc N. Haines, University of Wisconsin-Milwaukee, USA\nSumi Helal, University of Florida, USA\nAlan R. Hevner, University of South Florida, USA\nMichael N. Huhns, University of South Carolina, USA\nPatrick C. K. Hung, CSIRO, Australia\nVarghese S. Jacob, University of Texas at Dallas, USA\nMario Jeckle, University of Applied Sciences, Furtwangen, Germany\nVipul Kashyap, National Library of Medicine, USA\nDaniel S. Katz, JPL/Caltech, USA\nMartin Kersten, CWI, The Netherlands\nMichael Kifer, SUNY at Stony Brook, USA\nRoger (Buzz) King, University of Colorado at Boulder, USA\nHiro Kishimoto, Fujitsu Laboratories Ltd., Japan\nHiroyuki Kitagawa, University of Tsukuba, Japan\nManolis Koubarakis, TUC, Greece\nEe-Peng Lim, Nanyang Technological University, Singapore\nBertram Ludaescher, San Diego Supercomputer Center, UCSD, USA\nSanjay Madria, University of Missouri-Rolla, USA\nLeo Mark, Georgia Institute of Technology, USA\nDennis McLeod, University of Southern California, USA\nDeependra Moitra, Infosys Technologies Ltd, India\nMGPL Narayana, Tata Consultancy Services, India\nDerek L. Nazareth, University of Wisconsin-Milwaukee, USA\nErich J. Neuhold, Fraunhofer IPSI, Germany\nMurthy Nukola, Composite Software, USA\nKesav V. Nori, Tata Consultancy Services, India\nBeng Chin Ooi, National University of Singapore, Singapore \nAris M. Ouksel,The University of Illinois at Chicago, USA\nSrinivas Padmanabhuni, Infosys Technologies Ltd, India\nYannis Papakonstantinou, UCSD, USA\nBijan Parsia, Univ of Maryland, USA\nAjit Patankar, UC Berkeley / Diginome, USA\nThomas E. Potok, Oak Ridge National Lab (ORNL), USA\nCalton Pu, Georgia Institute of Technology, USA\nSandeep Purao, Penn State University, USA\nUday Ramteerthkar, Tata Research & Development Center, India\nLouiqa Raschid, University of Maryland, USA\nT. Ravichandran, Rensselaer Polytechnic Institute, USA\nBerthold Reinwald, IBM Almaden Research Center, USA\nArnon Rosenthal, The MITRE Corporation, USA\nMarcus A. Rothenberger, University of Wisconsin-Milwaukee, USA\nAkhil Sahai, Hewlett Packard Laboratories, USA\nHans-J. Schek, ETH Zurich, Switzerland  and UMIT Innsbruck, Austria\nTodd Schraml, The Revere Group, USA\nVipul Shah, Tata consultancy Services America, USA\nMing-Chien Shan, Hewlett Packard Laboratories, USA\nAmit Sheth , University of Georgia, USA\nMunindar P. Singh, North Carolina State University, USA\nIl-Yeol Song., Drexel University, USA\nRudi Studer , University Karlsruhe, Germany\nVijay Sugumaran, Oakland University, USA\nKatia P. Sycara, Carnegie Mellon University, USA\nMohan Tanniru, University of Arizona, USA\nGeorge K. Thiruvathukal, Loyola University of Chicago, USA\nJeffrey J.P. Tsai, University of Illinois at Chicago, USA\nWerner Vogels, Cornell University, USA\nKaladhar Voruganti, IBM Almaden Research Lab\nSanjiva Weerawarana, IBM T.J. Watson Research Center, USA\nKyu-Young Whang, KAIST, Korea\nClement Yu, U. of Illinois at Chicago, USA\nCarlo Zaniolo , UCLA, USA\nXiaodong Zhang , William and Mary College, USA\nYanchun Zhang, Victoria University, Melbourne, Australia\nYanqing Zhang, Georgia State University, USA\nJ. Leon Zhao, University of Arizona, USA\nHuimin Zhao, University of Wisconsin - Milwaukee, USA\n\n\n\n----------------------------------------------------------\nICWS 2004 Industrial Program - Call For Extended Abstracts\n----------------------------------------------------------\n\nThe industrial track of ICWS 2004 will be the forum for high quality\npresentations on innovative commercial and industrial software for all\nfacets of web services.  These include significant applications leveraging\nweb services, standards for web services, business-to-business applications,\napplication integration, business process integration and management,\ncontent management, composite web services, multimedia communication, and\nbenchmarking.  Submissions that do not relate to marketplace trends,\nindustry standards, commercial software (or industrial-strength prototypes)\nare discouraged.  You are welcome to send email with any questions you might\nhave as you prepare your submission to either of the industrial program\nco-chairs: \n\n   Roger Barga (barga@microsoft.com) or Sinisa Zimek (sinisa.zimek@sap.com)\n\n\nAuthors should submit an extended abstract (5 pages maximum) with the same\nformatting rules as research papers.  Unlike research track, minimal or no\nreviews of submissions will be provided to authors during notification.\nAcceptance criteria will be innovativeness of software and the potential of\nimpact.  Please send industrial program submissions by e-mail to the\nfollowing industrial program co-chair: \n\n   Sinisa Zimek (sinisa.zimek@sap.com)\n\nto arrive by 5 p.m. US Pacific Standard Time on February 2nd, 2004.\nSubmissions that exceed the 5 page limit or arrive after the February 2nd\ndeadline may be rejected without further consideration.\n\n\n\n----------------------------------------------------------\nICWS 2004 Tutorial Program - Call For Tutorial\n----------------------------------------------------------\n\nTutorial proposals should identify the intended audience and outline the\nscope and the depth of material to be covered. Past experience and successes\nof the presenter should be given explicitly and will be considered\npositively. We are particularly interested in tutorials that foster\nknowledge exchange among the researchers present at ICWS 2004. The time\nallocated for the tutorial is 4 hours.\n\nThe length of tutorial proposals should not exceed 5 pages including the\nshort biographies of tutorial presenters. They should be submitted to the\ntutorial program chair by email to J. Leon Zhao at lzhao@bpa.arizona.edu on\nor before Friday, March 5, 2004.  If you need to submit materials in\nhardcopy, please send to:\n\nJ. Leon Zhao, Ph.D.\nAssociate Professor\nDepartment of Management Information Systems\nEller School of Management\nUniversity of Arizona\nTucson, Arizona 85721, USA\n\n\n\n", "id": "lists-017-3707513"}, {"subject": "translations issue", "content": "When looking over this sheet with ppl on my team we found 2 more issues\nin the translations. They are around pseudo-analysis and development\nbeing almost the same definition and the definition of the computer\ncategory sounding too negative. I have proposed new definitions in the\nnotes column of the attached file.\n\n \n\nPlease give me any feedback you have on these.\n\nJeremy Epling\nWindows - Privacy and Trust UX\n\n \n\n\n\n", "id": "lists-017-3769567"}, {"subject": "translations issue", "content": "When looking over this sheet with ppl on my team we found 2 more issues\nin the translations. They are around pseudo-analysis and development\nbeing almost the same definition and the definition of the computer\ncategory sounding too negative. I have proposed new definitions in the\nnotes column of the attached file.\n\n \n\nPlease give me any feedback you have on these.\n\nJeremy Epling\nWindows - Privacy and Trust UX\n\n \n\n\n\n", "id": "lists-017-3775782"}, {"subject": "RE: translations issue", "content": "Whoops, I forgot to attach the file. The comments I made are in red.\n\nJeremy Epling\nWindows - Privacy and Trust UX\n\nwpihelp <BLOCKED::>  - where to go for all your privacy questions\n\n________________________________\n\nFrom: Jeremy Epling \nSent: Tuesday, July 01, 2003 10:31 AM\nTo: public-p3p-spec@w3.org\nSubject: translations issues\n\n \n\nWhen looking over this sheet with ppl on my team we found 2 more issues\nin the translations. They are around pseudo-analysis and development\nbeing almost the same definition and the definition of the computer\ncategory sounding too negative. I have proposed new definitions in the\nnotes column of the attached file.\n\n \n\nPlease give me any feedback you have on these.\n\nJeremy Epling\nWindows - Privacy and Trust UX\n\n \n\n\n\n\n\n\ntext/html attachment: P3P Translations.htm\n\n\n\n\n", "id": "lists-017-3783267"}, {"subject": "translations localizatio", "content": "What is our plan around having these translations in other languages?\nWill our working group be providing these or is it up to the user agent\nimplementers to produce these?\n\nJeremy Epling\nWindows - Privacy and Trust UX\n\n \n\n\n\n", "id": "lists-017-3791884"}, {"subject": "Re: translations localizatio", "content": "It depends on the availability of resources. I think the spec itself \nshould just have the English translation. But we should post other \ntranslations on the W3C web site. Rigo mentioned the possibility of \ngetting assistance from some EU government translation service or \nsomething. Of course, if there are any WG members who have access to \ntranslation services, all contributions would be welcome.\n\nLorrie\n\nOn Tuesday, July 1, 2003, at 01:55  PM, Jeremy Epling wrote:\n\n> What is our plan around having these translations in other languages? \n> Will our working group be providing these or is it up to the user \n> agent implementers to produce these?\n>\n> Jeremy Epling\n> Windows - Privacy and Trust UX\n>\n> ?\n>\n\n\n\n", "id": "lists-017-3799256"}, {"subject": "Re: translations issue", "content": "Thanks for taking the time to look at the matrix again.\n\nDifferentiating between pseudo-analysis and develop is tricky. Both are \nfor research. Both are not supposed to identify the individual. The \nconceptual difference is that pseudo-analysis involves the creation of \na (pseudonymous) profile of an individual (and thus lends itself to \nresearching things that require tracking an individual's use of a \nservice, for example), while develop does not involve the creation of a \nprofile. So that's why I used the term \"record identified with you.\" \nThe new wording that you propose for develop could describe \npseudo-analysis equally well. Any other ideas?\n\nFor computer you proposed: \"Information about the computer you are \nusing. Such as its hardware, software, or internet address.\" If you \nchange the . to a , and make it \"Information about the computer you are \nusing, such as its hardware, software, or internet address.\" I would be \nhappy with that.\n\nLorrie\n\n\n\nOn Tuesday, July 1, 2003, at 01:31  PM, Jeremy Epling wrote:\n\n> Whoops, I forgot to attach the file. The comments I made are in red.\n>\n> Jeremy Epling\n> Windows - Privacy and Trust UX\n>\n> wpihelp- where to go for all your privacy questions\n>\n<image.tiff>\n>\n>\n> From:Jeremy Epling\n> Sent: Tuesday, July 01, 2003 10:31 AM\n> To: public-p3p-spec@w3.org\n> Subject: translations issues\n>\n> ?\n>\n> When looking over this sheet with ppl on my team we found 2 more \n> issues in the translations. They are around pseudo-analysis and \n> development being almost the same definition and the definition of the \n> computer category sounding too negative. I have proposed new \n> definitions in the notes column of the attached file.\n>\n> ?\n>\n> Please give me any feedback you have on these.\n>\n> Jeremy Epling\n> Windows - Privacy and Trust UX\n>\n> ?\n>\n> <P3P Translations.htm>\n\n\n\n", "id": "lists-017-3807020"}, {"subject": "UA: Comments on translation from Fidelit", "content": "Here are comments from Bill Duserick from Fidelity on our translation \ndraft. He sent this as a word file with change bars so I have saved it \nas PDF to make sure the change bars get preserved.\n\nLorrie\n\n\n\n\nBegin forwarded message:\n\n> From: \"Duserick, William\" <William.Duserick@fmr.com>\n> Date: Wed Jul 2, 2003  11:50:06  AM America/New_York\n> To: \"'Lorrie Cranor'\" <lorrie@research.att.com>\n> Subject: RE: P3P elements in plain language\n>\n> Lorrie\n>\n> Attached is a Word document with comments on some of the \n> elements/tokens.\n> Feel free to share this with other members of the user agent task \n> force.\n> Let me know if you have any questions or comments regarding my \n> comments.\n>\n> Regards,\n>\n> Bill\n> Bill Duserick\n> Fidelity Investments\n> Corporate Privacy Office\n> (617) 392-1224\n> william.duserick@fmr.com\n>\n\n\n\n\napplication/pdf attachment: duserick-comments.pdf\n\n\n\n\n", "id": "lists-017-3816245"}, {"subject": "AGENDA: P3P spec call July ", "content": "The next P3P specification group conference call will be on\nWednesday, July 9, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit and Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n2. Discuss Consent Choices working draft -- do we want to pursue this\n    in P3P 1.1 or postpone to P3P 2.0? We need feedback from\n    implementers!\n    http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n    This is also related to Bugzilla 169\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=169\n\n3. Resolve Bugzilla 224\nThe UA TF recommends adding the following text to section 3.2.4 The\nENTITY element to address the problem tha tthe spec currently allows\nfor multiple instances of data elements within an ENTITY element but\nuser agents have trouble displaying this:\n\nAlthough it is permissable for a particular DATA element to appear\nmore than once within a single ENTITY element, this is not\nrecommended as user agents may not display multiple instances of a\nDATA element correctly. Policy writers who wish to indicate multiple\npoints of contact for customer service at a web site should use the\nDISPUTES element, which is designed to have  multiple instances.\n\n4. Discuss Jeremy's proposals (to be sent to the list soon)\n\n5. Set date for next call (July 23)\n\n\n\n", "id": "lists-017-3824607"}, {"subject": "Regrets and Update (Was: AGENDA: P3P spec call July 9", "content": "On Thursday 03 July 2003 15:49, Lorrie Cranor wrote:\n> AGENDA\n>\n> 1. Task force reports\n>     - P3P beyond HTTP - Joseph Reagle\n\nRegrets, I have another teleconf at that time. But I just published a new \nversion of the report:\n  http://www.w3.org/P3P/2003/p3p-beyond-http/\n  $Revision: 1.26 $ on $Date: 2003/07/08 21:23:04 $ GMT\n  \"wsdl example and extension now work in XSV thanks to PLH, \n  many URIs corrected to disambiguate between URIs of the registrar \n  and registry, and many other fixes\"\n\nI have not -- yet -- received the review nor comments that I expected from \nthis group. (When Patrick is back, it would also probably be worthwhile to \nconsider what will happen to this document when I'm no longer available to \nwork on it after July -- and I'm also taking lots of Holiday this month so \ntime is shortening...)\n\n\n\n", "id": "lists-017-3833469"}, {"subject": "RE: Regrets and Update (Was: AGENDA: P3P spec call July 9", "content": "Hi Joseph,\n\nI came back to office...\n\nBeside I talked about Web services security, I also mentioned the research \nissues of Web services + privacy policies at two conferences, France Telecom\n\nR&D Labs and HP Research Labs on the West Coast last week. Of course, I\ntried \nto promote the P3P Beyond HTTP Task Force to the audiences. You can check my\n\npresentation slides at:\nhttp://www.cmis.csiro.au/Patrick.Hung/documents/W3C-Privacy.pdf\n \nOverall, most of the audiences are interested in this new research topic but\nmost of them do not have any concrete idea about privacy policies. Quite a\nnumber of them have been heard about P3P. In particular, some \"liberty\nalliance\n(http://www.projectliberty.org)\" people are very interested in what we are\ndoing because they are also looking into the same problem from different\naspects. I have invited them to check the work at P3P Working Group.\n\nI checked the latest version of the P3P Beyond HTTP Task Force draft report.\nHere are some of my comments:\n(1) Referring to \"The P3P Policy Reference (p3p.xml) specifies the URLs for\nwhich the policy applies:\"\n\n<META xmlns=\"http://www.w3.org/2002/01/P3Pv1\">\n  <POLICY-REFERENCES>\n    <POLICY-REF about=\"/w3c/policy-register.xml\">\n                ^^^^^   ^^^\n                Why not use \"rel='P3Pv1' href='/P3P/policy-register.xml'\" ?\n      <INCLUDE>/register</INCLUDE>\n    </POLICY-REF>\n  </POLICY-REFERENCES>\n</META>\n\n(2) You repeat this paragraph in two different places\"\n\n\"The adopting application should make the interaction with respect to these\ninformation flows as simple as possible to the user:\n\nWhere information flows to multiple recipients applications via node-to-node\nexchanges, applications SHOULD present a single interface to the user and\naggregate recipient policies if possible or otherwise disclose their\npolicies with p3p:recipient. \nWhere the information flows in an end-to-end relationship through various\nintermediaries with inoffensive policies and the user has a relation with\nthat single end point, applications CAN also present the policies of the\nfinal recipient with themselves as transparent intermediaries. (See\nIntermediaries below.) \"\n\n(3) Referring to \"The following is an WSDL service description\n(wsdl-eg.xml):\"\n\n<soap:operation\nsoapAction='http://registry.example.com/RegisterDomainName'/>\n                                                       ^^^^^^\n \n'http://registry.example.com/RegisterService/RegisterDomainName' \n\nSo far, I think the most important task is to get some feedbacks/comments\nfrom the public. I am trying\nto invite those liberty alliance to give us some comments and etc.\n\nCheers,\n\nPatrick.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Wednesday, 9 July 2003 7:33 AM\nTo: Lorrie Cranor; public-p3p-spec@w3.org\nSubject: Regrets and Update (Was: AGENDA: P3P spec call July 9)\n\n\n\nOn Thursday 03 July 2003 15:49, Lorrie Cranor wrote:\n> AGENDA\n>\n> 1. Task force reports\n>     - P3P beyond HTTP - Joseph Reagle\n\nRegrets, I have another teleconf at that time. But I just published a new \nversion of the report:\n  http://www.w3.org/P3P/2003/p3p-beyond-http/\n  $Revision: 1.26 $ on $Date: 2003/07/08 21:23:04 $ GMT\n  \"wsdl example and extension now work in XSV thanks to PLH, \n  many URIs corrected to disambiguate between URIs of the registrar \n  and registry, and many other fixes\"\n\nI have not -- yet -- received the review nor comments that I expected from \nthis group. (When Patrick is back, it would also probably be worthwhile to \nconsider what will happen to this document when I'm no longer available to \nwork on it after July -- and I'm also taking lots of Holiday this month so \ntime is shortening...)\n\n\n\n", "id": "lists-017-3842201"}, {"subject": "RE: Regrets and Update (Was: AGENDA: P3P spec call July 9", "content": "An interesting P3P + Web services related paper that I found at the ICWS'03\nlast week:\n\nWeb Service Integration Platform with Privacy Preferences for One-stop\nApplication\n\nJunichi Toyouchi*, Motohisa Funabashi, Shinsuke Honjo\nSystems Development Laboratory, Hitachi, Ltd.\n1099 Ohzenji, Asao, Kawasaki, Kanagawa\n215-0013, JAPAN\n\nNorihisa Komoda\nDepartment of Multimedia Engineering,\nOsaka University, Graduage School of Information\nScience and Technologies\n2-1 Yamadaoka, Suita, Osaka 565-0871, JAPAN\n\nAbstract - Individual service system will be combined\nand collaborated over the network into one-stop service\nsystems within very short time. We have developed a\nservice integration platform based on the autonomous\ndecentralized service system (ADSS) architecture\ninfluenced by TINA business model and functionalities.\nOn the platform, we propose and implement a mechanism\nto control disclosure range of personal information\nacross the domains by expanding P3P framework to\npersonalize the services of the un-foreknown providers.\nThe platform can be applied to various types of service\nsystems. Here we also introduce an examples of\napplication developed on the platform.\n\nKeywords: Service Integration, P3P, Privacy\nManagement, Mediation\n\nIf you are interested in it, I will ask for the authors' \npermission for distributing in our group.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Wednesday, 9 July 2003 7:33 AM\nTo: Lorrie Cranor; public-p3p-spec@w3.org\nSubject: Regrets and Update (Was: AGENDA: P3P spec call July 9)\n\n\n\nOn Thursday 03 July 2003 15:49, Lorrie Cranor wrote:\n> AGENDA\n>\n> 1. Task force reports\n>     - P3P beyond HTTP - Joseph Reagle\n\nRegrets, I have another teleconf at that time. But I just published a new \nversion of the report:\n  http://www.w3.org/P3P/2003/p3p-beyond-http/\n  $Revision: 1.26 $ on $Date: 2003/07/08 21:23:04 $ GMT\n  \"wsdl example and extension now work in XSV thanks to PLH, \n  many URIs corrected to disambiguate between URIs of the registrar \n  and registry, and many other fixes\"\n\nI have not -- yet -- received the review nor comments that I expected from \nthis group. (When Patrick is back, it would also probably be worthwhile to \nconsider what will happen to this document when I'm no longer available to \nwork on it after July -- and I'm also taking lots of Holiday this month so \ntime is shortening...)\n\n\n\n", "id": "lists-017-3855193"}, {"subject": "Agent/Domain TF Update (Was: AGENDA: P3P spec call July 9", "content": "I also can't make it for the call this morning. Attached is a proposal for\nhow to solve the \"same entity\" domain relationship problem. Please review\nand offer any comments. There is an extension to this proposal for the agent\nproblem, but Brooks and I are still kicking it around and aren't quite happy\nwith it yet.\n\nThanks.\n\nJack Humphrey\nCoremetrics\n\n\n\n\n\napplication/octet-stream attachment: domrelprop1.pdf\n\n\n\n\n", "id": "lists-017-3866250"}, {"subject": "Re: Regrets and Update (Was: AGENDA: P3P spec call July 9", "content": "On Wednesday 09 July 2003 10:39, Patrick.Hung@csiro.au wrote:\n> Hi Joseph,\n>\n> I came back to office...\n>\n> Beside I talked about Web services security, I also mentioned the\n> research issues of Web services + privacy policies at two conferences,\n> France Telecom\n>\n> R&D Labs and HP Research Labs on the West Coast last week. Of course, I\n> tried\n> to promote the P3P Beyond HTTP Task Force to the audiences. You can check\n> my\n>\n> presentation slides at:\n> http://www.cmis.csiro.au/Patrick.Hung/documents/W3C-Privacy.pdf\n>\n> Overall, most of the audiences are interested in this new research topic\n> but most of them do not have any concrete idea about privacy policies.\n> Quite a number of them have been heard about P3P. In particular, some\n> \"liberty alliance\n> (http://www.projectliberty.org)\" people are very interested in what we\n> are doing because they are also looking into the same problem from\n> different aspects. I have invited them to check the work at P3P Working\n> Group.\n>\n> I checked the latest version of the P3P Beyond HTTP Task Force draft\n> report. Here are some of my comments:\n\nOk, your second and third comment are fixed in:\n  http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n  new revision: 1.27; previous revision: 1.26\n\n> (1) Referring to \"The P3P Policy Reference (p3p.xml) specifies the URLs\n> for which the policy applies:\"\n>\n> <META xmlns=\"http://www.w3.org/2002/01/P3Pv1\">\n>   <POLICY-REFERENCES>\n>     <POLICY-REF about=\"/w3c/policy-register.xml\">\n>                 ^^^^^   ^^^\n>                 Why not use \"rel='P3Pv1' href='/P3P/policy-register.xml'\"\n> ? <INCLUDE>/register</INCLUDE>\n>     </POLICY-REF>\n>   </POLICY-REFERENCES>\n> </META>\n\nThat's not standard P3P, right? I didn't feel so bold as to need to change \nthe policy-ref file...?\n\n> So far, I think the most important task is to get some feedbacks/comments\n> from the public. I am trying\n> to invite those liberty alliance to give us some comments and etc.\n\nI've sent an email to the www-ws-arch list -- though the W3C archives aren't \nupdating presently, so I can't give you the URL.\n\n\n\n", "id": "lists-017-3873706"}, {"subject": "UA: comment", "content": "One of the AT&T lawyers looked over our translation draft and had only \nthe following comments:\n\n> 1. under \"non-identifiable\" -- not sure everyone would know what \n> \"anonymized\" means, is it technically a word?\n>\n> 2. under \"historical\" -- no idea what \"social history\" is\n>\n> 3. under \"preference\" -- I would use more of the p3P spec definition\n\n\nLorrie\n\n\n\n", "id": "lists-017-3883981"}, {"subject": "UA: UA TF conference call Monday, July 14, 11 a", "content": "Our next P3P user agent task force call will be on Monday, July 14 at \n11 am US Eastern time. We will use the usual bridge number.\n\nAGENDA\n\n1. Discuss Fidelity comments\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0006.html\n\n2. Discuss Jeremy's latest comments\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0002.html\n(and Lorrie's response)\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0005.html\n\n3. Discuss AT&T comments Lorrie posted\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0013.html\n\n4. Schedule next call\n\n\n\n", "id": "lists-017-3890693"}, {"subject": "Stampley comment", "content": "Call has already started, but wanted to get this in mail to group.\n\n \n\nDave Stampley\n\nSenior Corporate Counsel & Director, Privacy\n\n    v.937-485-0424  f.866-246-0507\n\ndavid_stampley@reyrey.com\n\n \n\nTHIS EMAIL IS CONFIDENTIAL AND MAY ALSO BE LEGALLY PRIVILEGED.  IF YOU HAVE\nRECEIVED THIS EMAIL IN ERROR, PLEASE NOTIFY THE SENDER IMMEDIATELY BY RETURN\nEMAIL AND THEN DELETE THIS EMAIL FROM YOUR SYSTEM WITHOUT COPYING OR USING\nTHE EMAIL FOR ANY OTHER PURPOSE OR DISCLOSING IT CONTENTS.\n\n \n\n \n\n\n\n\n\n\napplication/octet-stream attachment: P3P_Translations_DAS3.mht\n\n\n\n\n", "id": "lists-017-3898094"}, {"subject": "AGENDA: 16 July P3P spec cal", "content": "Wednesday, July 16, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit and Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n2. Discussion of Ari's identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jun/0030.html\n\n3. Discussion of Jack's Agent/Domain TF draft\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0011.html\n\n4. Set date for next call (July 23?)\n\n\n\n", "id": "lists-017-3905281"}, {"subject": "Re: privacy in OW", "content": "Hi Jim, \n\nThe first paragraph of my suggested wording below was designed to give\npeople at least a hint of what is important when designing privacy\nenhanced systems. Instead of just taking a whole paragraph to describe\none special case and raise the finger saying 'potential for abuse', this\nhint should be kept. I compressed it to one sentence.\n\nAdditionally talking only about 'abuse' is not strong enough.\nIn most member-countries of the OECD, such behaviour would be illegal\nand even subject to prosecution and penal sanctions. That's why I added\na sentence. \n\nSee the suggested text inline..\n\nBest, \n\nRigo\n\n\nOn Tue, Jul 15, 2003 at 10:21:52PM -0400, Jim Hendler wrote:\n> Rigo-\n>  thanks for your comments to WebOnt about the privacy section in our \n> Guide Document.  We have extended our discussion to integrate your \n> comments -- here is the wording from the Editor's Draft of the Guide \n> document (similar wording in the Editor's Draft of the Reference).\n>   Please let us know if this satsifies your comment\n>    thanks\n>     Jim Hendler for WebOnt\n> \n> 2.3 Data Aggregation and Privacy OWL's ability to express ontological \n> information about instances appearing in multiple documents supports \n> linking of data from diverse sources in a principled way. The \n> underlying semantics provides support for inferences over this data \n> that may yield unexpected results. In particular, the ability to \n> express equivalences using owl:sameAs can be used to state that \n> seemingly different individuals are actually the same. \n> Owl:InverseFunctionalProperty can also be used to link individuals \n> together. For example, if a property such as \"SocialSecurityNumber\" \n> is an owl:InverseFunctionalProperty, then two separate individuals \n> could be inferred to be identical based on having the same value of \n> that property. When individuals are determined to be the same by such \n> means, information about them from different sources can be merged. \n> This aggregation can be used to determine facts that are not directly \n> represented in any one source. The ability of the Semantic Web to \n> link information from multiple sources is a desirable and powerful \n> feature that can be used in many applications. However, the \n> capability to merge data from multiple sources, combined with the \n> inferential power of OWL, does have potential for abuse. \n\nIt might be  illegal to create or process such linked information in\ncountries with data protection laws, especially in the EU, without\nhaving a valid legal reason for the processing. Therefor it is\nrecommended to avoid generating a complete transparency of a natural \nperson by accident of privacy unaware design. \n\n> Users of OWL should be alert to the potential privacy implications.\n> Detailed security solutions were considered out of scope for the\n> Workng Group.  Work currently underway is expected to address these\n> issues with a variety of security and preference solutions. See for\n> example SAML and P3P.\n> \n> \n> \n> At 3:44 PM +0200 5/6/03, Rigo Wenning wrote:\n> >On Thu, May 01, 2003 at 09:53:12AM -0500, Dan Connolly wrote:\n> >> If you have any comments on it, please send them\n> >> to public-webont-comments@w3.org\n> >\n> >\n> >Comment on Privacy in Web-ont\n> >\n> >It is honorable, that the Webont Working Group thought about\n> >including something about Privacy into their guide.\n> >\n> ><for the impatient>\n> >As usual in privacy, nearly everybody is aware of potential\n> >privacy issues or has some kind of bad conciousness about it.\n> >In the absence of real solutions, this bad consciousness is\n> >discharged by some rather general privacy warning. The result is\n> >that implementers of OWL will share bad consciousness, but lack a\n> >solution.\n> >\n> >The good news is, that there might be some remedy. The remedy\n> >lies in OWL itself, as the approach is mainly based on metadata.\n> >The P3P Specification WG has thought about integrating the P3P\n> >semantics into the Semantic Web. For this reason -in cooperation\n> >with the RDF IG- a RDF-Schema representing P3P was developed[1]. It\n> >might be good to reference this schema and verify, whether it is\n> >importable into OWL (or what is missing/has to be changed, \n> >to make it importable). This way, OWL-Ontologies treating persons\n> >would be able to also include those persons' preferences. This\n> >way, the inference engine can respect those preferences (or\n> >policies attached to an individual).\n> >\n> >In the future, we might want to use the preference-language\n> >APPEL[2] but I'm actually not able to determine if it would\n> >better fit into OWL.\n> ></for the impatient>\n> >\n> >I would suggest the following text. You can still change it as\n> >you like:\n> >\n> >OWL's ability to express ontological information about\n> >individuals -even appearing in multiple documents-, it's\n> >support for linking of data about individuals from diverse\n> >sources in a principled way may raise privacy issues.\n> >Privacy, by it's definition, protects individuals. Only if\n> >dealing with natural persons, one must be aware of the privacy\n> >implications. Goal is to protect against the disclosure of\n> >sensitive personal data but also against the creation of profiles\n> >making the individual and it's personality completly transparent\n> >to others. If we talk about privacy, we want to the opaqueness of\n> >someones personality and intimacy to the outside world. This can\n> >be overturned by the individual's will to disclose information.\n> >As a consequence, there is a need for the individuals kept in an\n> >ontology to be able to express their preferences. This can be\n> >done using the RDF-syntax for P3P [link] or APPEL [link].\n> >\n> >In particular, the ability to express equivalences using\n> >owl:sameIndividualAs can be used to state that seemingly\n> >different individuals are actually the same.\n> >Owl:InverseFunctionalProperty can also be used to link\n> >individuals together. For example, if a property such as\n> >\"SocialSecurityNumber\" is an owl:InverseFunctionalProperty, then\n> >two separate individuals could be inferred to be identical based\n> >on having the same value of that property. When individuals are\n> >determined to be the same by such means, information about them\n> >from different sources can be merged. This aggregation can be\n> >used to determine facts that are not directly represented in any\n> >one source.\n> >\n> >The ability of the Semantic Web to link information from multiple\n> >sources is a desirable and powerful feature that can be used in\n> >many applications. However, the capability to merge data from\n> >multiple sources, combined with the inferential power of OWL,\n> >does have potential for abuse. Users of OWL should be alert to\n> >the potential privacy implications.\n> >\n> >\n> >\n> >  1. http://www.w3.org/TR/p3p-rdfschema/\n> >  2. http://www.w3.org/TR/P3P-preferences/\n> >\n> >Best,\n> >\n> >--\n> >Rigo Wenning            W3C/ERCIM\n> >Policy Analyst          Privacy Activity Lead\n> >mail:rigo@w3.org        2004, Routes des Lucioles\n> >http://www.w3.org/      F-06902 Sophia Antipolis\n> \n> -- \n> Professor James Hendler  hendler@cs.umd.edu\n> Director, Semantic Web and Agent Technologies  301-405-2696\n> Maryland Information and Network Dynamics Lab.  301-405-6707 (Fax)\n> Univ of Maryland, College Park, MD 20742  *** 240-277-3388 (Cell)\n> http://www.cs.umd.edu/users/hendler      *** NOTE CHANGED CELL NUMBER ***\n\n\n\n", "id": "lists-017-3912814"}, {"subject": "[BH] The most generic bindin", "content": "Joseph, \n\nI owe you this since a long time.\n\nThe idea and solutions described below were developed as an outcome of\nthe dependency - discussions with XForms. \n\nSteven Pemberton suggested a very simple binding that would allow to\nbind a P3P-Policy to arbitrary XML-Elements. He thought it would be a\nquick and short specification to do as it would define a generic\nattribute like xml lang=..[1] This could be done in a separate\nspecification, but is also a possible candidate be included in the\n[beyond HTTP] stuff.\n\nSo I suggest to specify an XML-attribute that can be generally used to\npoint to a _Policy_ (not PRF). The binding is no issue as the attribute\nitself defines it's own binding by the element it is sitting on. \n\nIn a past email, Steven Pemberton gave an example of how this could look\nlike[2]\n\n  1. http://www.w3.org/TR/REC-xml#sec-lang-tag\n  2. http://lists.w3.org/Archives/Member/w3c-forms/2003JanMar/0127.html\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-3928721"}, {"subject": "Re: [BH] The most generic bindin", "content": "To add a bit more context.... such a binding would be useful in (at \nleast) the following cases:\n\na. When you want to bind a P3P policy to an XML document that is not \nidentified by a URI.\n\nb. When you want to bind a P3P policy to a particular XML element \nwithin an XML document, but not to the entire document.\n\nc. When you want to bind a P3P policy to an XML document and don't have \nthe ability to use the WKL or header methods for the PRF\n\n\nAs I recall, there were two other ideas that were discussed that should \nprobably be considered along with this:\n\n- A referencing mechanism that is nearly identical to the HTML and \nXHTML link tags in the P3P1.0 spec that could be used with any XML \ndocument (this is another way to satisfy point c above)\n\n- An extension to the PRF syntax to allow binding to a particular XML \nelement at a URL rather than to the whole document at that URL (this is \nanother way to satisfy point b above)\n\nLorrie\n\n\n\nOn Wednesday, July 16, 2003, at 08:12  AM, Rigo Wenning wrote:\n\n>\n> Joseph,\n>\n> I owe you this since a long time.\n>\n> The idea and solutions described below were developed as an outcome of\n> the dependency - discussions with XForms.\n>\n> Steven Pemberton suggested a very simple binding that would allow to\n> bind a P3P-Policy to arbitrary XML-Elements. He thought it would be a\n> quick and short specification to do as it would define a generic\n> attribute like xml lang=..[1] This could be done in a separate\n> specification, but is also a possible candidate be included in the\n> [beyond HTTP] stuff.\n>\n> So I suggest to specify an XML-attribute that can be generally used to\n> point to a _Policy_ (not PRF). The binding is no issue as the attribute\n> itself defines it's own binding by the element it is sitting on.\n>\n> In a past email, Steven Pemberton gave an example of how this could \n> look\n> like[2]\n>\n>   1. http://www.w3.org/TR/REC-xml#sec-lang-tag\n>   2. http://lists.w3.org/Archives/Member/w3c-forms/2003JanMar/0127.html\n>\n> Best,\n> -- \n> Rigo Wenning            W3C/ERCIM\n> Policy Analyst          Privacy Activity Lead\n> mail:rigo@w3.org        2004, Routes des Lucioles\n> http://www.w3.org/      F-06902 Sophia Antipolis\n>\n\n\n\n", "id": "lists-017-3937234"}, {"subject": "Re: [BH] The most generic bindin", "content": "On Wednesday 16 July 2003 08:12, Rigo Wenning wrote:\n> I owe you this since a long time.\n\nYes, and now I expect to have little time for this issue.\n\n> Steven Pemberton suggested a very simple binding that would allow to\n> bind a P3P-Policy to arbitrary XML-Elements. He thought it would be a\n> quick and short specification to do as it would define a generic\n> attribute like xml lang=..[1] This could be done in a separate\n> specification, but is also a possible candidate be included in the\n> [beyond HTTP] stuff.\n>\n> So I suggest to specify an XML-attribute that can be generally used to\n> point to a _Policy_ (not PRF). The binding is no issue as the attribute\n> itself defines it's own binding by the element it is sitting on.\n\nI don't completely understand. I note that in the CR [a] they have a \nmechanism for associating an input with a \"p3ptype.\" (I'll also note that \nfor historical purposes some privacy advocates *objected* to P3P \ncontrolling the exchange of information under a policy. For some reason, \nwhen we made the policy orthogonal to the actual auto-fill or control of \nthe exchange, which permits someone to make misrepresentations in the \npolicy and then solicit lots of unrelated information in a form, they felt \n*happier*. <shrug/>)\n\n[a] http://www.w3.org/TR/xforms/slice6.html#model-prop-p3ptype\n\n> In a past email, Steven Pemberton gave an example of how this could look\n> like[2]\n\nYou seem to be suggesting that you'd associate an actual policy with an \nelement (e.g., p3ppolicy), for example:\n<model>\n <instance><root><yourname/><homeEmailAddress></root></instance>\n <bind \"creditCardNumber\" p3ppolicy=\"http://example.com/some-policy.xml\"/>\n</model>\nbut I don't think that's what Steven is discussing in [2]. I *think* they \nare using p3ptype and perhaps asking two questions:\n1. How/when is the evaluation of a policy governing a form field \ncorresponding to a p3ptype affect the auto-filling of the form. I think \nSteven is comfortable with the model there but I can't say I understand \neverything involved there.\n2. Even if the P3P policy permits its release, should it be released if the \nform field is not displayed to the user via old CSS mechanisms, or XForms \nswitch/case mechanism. I think it would be a good idea for the HTML family \nof specifications to recommend that fields should NOT be auto-filled if \nthey are not presented to the user. (Of course, agents will not be able to \nfigure this out in all cases as one could use various size,color, CSS \ntricks?)\n\n[2] http://lists.w3.org/Archives/Member/w3c-forms/2003JanMar/0127.html\n\n\n\n", "id": "lists-017-3947878"}, {"subject": "Re: [BH] The most generic bindin", "content": "The use-case was initially, that privacy implications of XForms could be\naddressed by every single field and not only for an entire Form. \n\nI see that it is partly already in the [BH] draft as they have a p3p\nelement for the soap-binding. This could be done in a more elegant way\nusing the link to a p3p-policy as an attribute.\n\nBest, \n\nRigo\n\nOn Wed, Jul 16, 2003 at 09:43:56AM -0400, Lorrie Cranor wrote:\n> To add a bit more context.... such a binding would be useful in (at \n> least) the following cases:\n> \n> a. When you want to bind a P3P policy to an XML document that is not \n> identified by a URI.\n> \n\n\n\n", "id": "lists-017-3958293"}, {"subject": "Re: [BH] The most generic bindin", "content": "On Wednesday 16 July 2003 09:59, Rigo Wenning wrote:\n> I see that it is partly already in the [BH] draft as they have a p3p\n> element for the soap-binding. This could be done in a more elegant way\n> using the link to a p3p-policy as an attribute.\n\nI can't say I understand, example please.\n\n\n\n", "id": "lists-017-3966444"}, {"subject": "Re: [BH] The most generic bindin", "content": "You introduce a <privacy /> element that carries the URI to a PRF\n\nInstead of linking to a PRF and from the PRF back to the instance, you\ncould directly reference the policy:\nso the example in \"The Scope of Layers and Bindings (HTTP and SOAP)\"[1]\nwould change to something with direct connection to a policy. That would\nallow to have a policy per element as domain-info might have a different\nimpact than <PersonalInfo> (but hasn't here as we have whois)\n\nSo I give you the example of how powerful this could be. As it is\ngeneric to XML, it could be also used in RDF.\n================rigo-example==============================\n<?xml version='1.0' encoding='UTF-8'?>\n<env:Envelope xmlns='http://registry.example.com/2003/ns1'\nxmlns:env='http://www.w3.org/2003/05/soap-envelope'>\n <env:Body>\n  <OrderInfo>\n   <Privacy xmlns='http://www.w3.org/P3P/2003/p3p-beyond-http/'\nrel='PolP3Pv1.1' href='http://registrar.example.com/P3P/policy-register.xml'>\n   <PersonalInfo rel='PolP3Pv1.1' href='http://registrar.example.com/P3P/policy-register.xml'>\n    <Name>\n     <First>Joseph</First>\n     <Middle>M.</Middle>\n     <Last>Reagle Jr.</Last>\n    </Name>\n    <Address>\n     <Street>200 Tecnology Square</Street>\n     <City>Cambridge</City>\n     <State>MA</State>\n     <Zip>02139</Zip>\n    </Address>\n   </PersonalInfo>\n   <DomainInfo PersonalInfo rel='PolP3Pv1.1' href='http://registrar.example.com/P3P/policy-register2.xml'>\n    <TLD>com</TLD>\n    <DomainName>reagle.example</DomainName>\n   </DomainInfo>\n  </OrderInfo>\n </env:Body>\n</env:Envelope>\n================rigo-example==============================\nOn Wed, Jul 16, 2003 at 10:21:37AM -0400, Joseph M. Reagle Jr. wrote:\n> On Wednesday 16 July 2003 09:59, Rigo Wenning wrote:\n> > I see that it is partly already in the [BH] draft as they have a p3p\n> > element for the soap-binding. This could be done in a more elegant way\n> > using the link to a p3p-policy as an attribute.\n> \n> I can't say I understand, example please.\n\n\n  1. http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-3974260"}, {"subject": "Re: [BH] The most generic bindin", "content": "On Wednesday 16 July 2003 10:43, Rigo Wenning wrote:\n> So I give you the example of how powerful this could be. As it is\n> generic to XML, it could be also used in RDF.\n\nAh, ok, though it seems to be complicate things for reasons I don't quite \nunderstand yet. Some questions/issues:\n1. What is the benefit of splitting the policies out across these sections \nover the existing mechanism of having different DATA elements in different \nPOLICY elements within a POLICIES?\n2. In your example, this means that the XML application schema will have to \npermit these foreign P3P elements, which prexisting XML formats won't be \nable to accomodate, and all such future ones would have to take this into \naccount for, which I think unlikely.\n\nI do believe that in the future once we have the P3P data structures in \nstandard XML/schema, it will probably make sense to reconsider the design \nof P3P with all of the stuff, but in the medium term P3P 1.0 gives you the \ngranularity in the policy, and the XForms proposal gives us a way to map a \nform element with a DATA ref that one will find in the POLICY, right?\n\n\n\n", "id": "lists-017-3984941"}, {"subject": "Re: [BH] The most generic bindin", "content": "On Wednesday 16 July 2003 09:43, Lorrie Cranor wrote:\n> a. When you want to bind a P3P policy to an XML document that is not\n> identified by a URI.\n\nI think this is addressed by the report, the XML instance would have to \nreference a policy though with something like:\n    <my:Privacy my:rel='P3Pv1'\n       my:href='http://registrar.example.com/w3c/p3p.xml'/>\n\n> b. When you want to bind a P3P policy to a particular XML element\n> within an XML document, but not to the entire document.\n\nCan't the Policy simply enumerate that particular element via \n  <DATA ref=\"#user.home-info.city\"/>\n\n> c. When you want to bind a P3P policy to an XML document and don't have\n> the ability to use the WKL or header methods for the PRF\n\nWhat is WKL? Is this addressed the same way as (a) above?\n\n> - A referencing mechanism that is nearly identical to the HTML and\n> XHTML link tags in the P3P1.0 spec that could be used with any XML\n> document (this is another way to satisfy point c above)\n\nYes, this is addressed in the report.\n\n> - An extension to the PRF syntax to allow binding to a particular XML\n> element at a URL rather than to the whole document at that URL (this is\n> another way to satisfy point b above)\n\nThis is the bit I'm not understanding yet.\n\n\n\n", "id": "lists-017-3993572"}, {"subject": "MINUTES: 16 July 2003 P3P spec cal", "content": "Minutes of the 16 July 2003 P3P spec wg call\n\nPresent\nLorrie Cranor\nRigo Wenning\nBrooks Dobbs\nRob Horn\nPatrick Hung\nJoseph Reagle\n\n(Regrets: Giles, Jack, Matthias)\n\n1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n\nRigo did his action item and posted the information about the \npreviously discussed P3P XML element. Discussion is continuing on the \nmailing list. If time permits, Joseph will try to capture this in his \ndraft, at least as an item for further discussion. Joseph has concerns \nabout declaring a new XML element that would need to be widely adopted. \nJoseph and Patrick will also discuss the possibility of Patrick taking \nover editing this TF document after Joseph's departure.\n\n    - User agent behavior - Lorrie Cranor\n\nUser agent task force has been making good progress. We recently got a \nlot of feedback on the translation and are in the process of discussing \nit.\n\n    - Compact policies - Brian Zwit and Brooks Dobbs\n\nBrooks will schedule a task force call ASAP.\n\n    - Article 10 vocabulary issues - Giles Hogben\n\nGiles was not on the call, but Lorrie reported that Giles had been in \ndiscussion with Diana about his proposed draft. Diana said the Article \n10 group did not have time to discuss the draft in detail at their last \nmeeting but the overall impression was that it did not address all \ntheir concerns. Lorrie and Giles have discussed with Diana that this \ndraft is intended to address short term issues that can be dealt with \nin P3P 1.1 and that other concerns will continue to be discussed in the \nlonger term. Giles will try to get them to provide more substantive \nfeedback on his draft as soon as possible (hopefully by September).\n\n2. Discussion of Ari's identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jun/0030.html\n\nOverall people like this draft. Some folks had a few specific nits that \nthey will send to the mailing list. Rigo had some concerns about \nconflicts with EU definitions and he will try to explain more on the \nmailing list. In general, people wanted to see more specific examples, \nespecially with respect to data linked to cookies. Brooks has many \nideas for examples to include and said Ari should contact him about \nthis.\n\n3. Discussion of Jack's Agent/Domain TF draft\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0011.html\n\nThere were some questions about the goals of this proposal. People \nthought it was useful for companies to be able to declare that all of \ntheir multiple domains are owned by a single company and comply with \nthe same policy, but there was less interest in being able to declare \nthat companies belong to an ad network. The reason browsers are \ntreating these as third party cookies is that is how consumers seem to \nwant to see them treated.\n\nPeople saw some potential uses for the idea of the KNOWN-HOSTS element \n(although it needs to be expressed using the extension mechanism). \nThere was less enthusiasm for allowing INCLUDE and EXCLUDE to include \nhost name. That substantially complicates parsing and caching issues \nwithout bringing obvious advantages. There was a recognition that the \nCP aspect of this proposal was most important for practical reasons, \nand yet it seemed not to scale well in the third-party  ad network \ncontext.\n\n4. Our next call will be on July 23. (If you can't make it please let \nLorrie know in advance so she can plan the agenda accordingly)\n\n\n\n", "id": "lists-017-4002484"}, {"subject": "Re: [BH] The most generic bindin", "content": "On Wed, Jul 16, 2003 at 11:55:17AM -0400, Joseph M. Reagle Jr. wrote:\n> Ah, ok, though it seems to be complicate things for reasons I don't quite \n> understand yet. Some questions/issues:\n\nI don't know if it complicates things as it removes the whole overhead\nof referencing and integrates into the natural way of writing down XML.\n\n> 1. What is the benefit of splitting the policies out across these sections \n> over the existing mechanism of having different DATA elements in different \n> POLICY elements within a POLICIES?\n\nSee your mail to Lorrie: You seem to assume a binding between an\nXPointer and a P3P Data-Element. This binding does not exist now. In\nfact, that is the second solution Lorrie mentioned in the call today: \n\nExtending the PRF to allow XPointer - Statements and bind a specific\npolicy to a specific node-set in the XML-Document. This needs a second\ndocument to be written. This adds overhead as you still need a binding\nmechanism while an attribute would have an implicit binding of the\npolicy by the element it sits on.\n\nE.g. your XForms engine would have to implement XPointer for that reason\nwhile the direct attribute would only trigger the simple parsing of that\nnew attribute which is then delivered to the P3P engine.\n\nSo my arguments are:\nIt is easier to write\nIt is more intuitive\nIt is easier to implement\n\n> 2. In your example, this means that the XML application schema will have to \n> permit these foreign P3P elements, which prexisting XML formats won't be \n> able to accomodate, and all such future ones would have to take this into \n> account for, which I think unlikely.\n\nThis is ignoring the fact that we are already mixing namespaces today,\nif the mixing is well defined. So the XML application schema does not\nhave to accomodate, but the application must be aware of this generally\navailable attribute that we have specified in some specification. This\nat least what Steven Pemberton suggested. Other Specifications, he said,\ncould just use this short specification and kind of 'import' it. \n\nSo the scope of this is not only addressing P3P 1.0 and Web Services but\nalso all kinds of future dependencies of e.g. Device Independence\nSpecifications.\n\n> \n> I do believe that in the future once we have the P3P data structures in \n> standard XML/schema, it will probably make sense to reconsider the design \n> of P3P with all of the stuff, but in the medium term P3P 1.0 gives you the \n> granularity in the policy, and the XForms proposal gives us a way to map a \n> form element with a DATA ref that one will find in the POLICY, right?\n\nGiles has already written a XSLT-transform to transform P3P data schemas\ninto XML Schema. So this can be transformed already on the fly. But the\ngranularity you are claiming is simply not there, as the binding\nmechanism is not there. So we have three possibilities:\n\n1/ Stick with the existing binding and require a URI for everything, not\nallowing to address sub-parts of a document (e.g. XForms form-fields)\n\n2/ Add a complicated binding mechanism a la XPointer/XPAth to the Policy \nReference File allowing to address a certain nodeset of an existing XML\nDocument (which still needs to have a URI)\n\n3/ Have an elegant way of implicitly binding a P3P Policy to an\narbitrary XML Element as an addition to the things already under \nway in [1]. This attribute would carry it's own namespace. Applications\nthat are P3P - aware can just use it out of the box by implementing the\ndesired behaviour. (binding)\n\n  1. http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n\nBest,\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-4012645"}, {"subject": "Re: [BH] The most generic bindin", "content": ">> b. When you want to bind a P3P policy to a particular XML element\n>> within an XML document, but not to the entire document.\n>\n> Can't the Policy simply enumerate that particular element via\n>   <DATA ref=\"#user.home-info.city\"/>\n\nThe semantics of a P3P policy is that is applies to all data collection \nassociated with a URI -- you cannot currently exclude data collected at \nthat URI from your policy. If you only reference a particular element \nin your policy and do not reference the other elements at that policy, \nthen your policy is wrong. This is especially problematic in the case \nof multiple policies applying to different elements on a page -- how \nwould you explain that in the existing framework unless each element \nwas submitted to a different action URI?\n\n>\n>> c. When you want to bind a P3P policy to an XML document and don't \n>> have\n>> the ability to use the WKL or header methods for the PRF\n>\n> What is WKL? Is this addressed the same way as (a) above?\n\nWKL is well known location\n\n>> - An extension to the PRF syntax to allow binding to a particular XML\n>> element at a URL rather than to the whole document at that URL (this \n>> is\n>> another way to satisfy point b above)\n>\n> This is the bit I'm not understanding yet.\n>\n>\n\nImagine that the INCLUDE syntax in a PRF allowed you to say that the \nscope of a policy was a specific set of XML elements found at a URI \nrather than to all content found at that URI.\n\nLorrie\n\n\n\n", "id": "lists-017-4023487"}, {"subject": "UA: Minutes 14 July UA TF cal", "content": "MINUTES: 14 July 2003 User Agent Task Force Call\n\nParticipants\nJeff Edelen (American Express)\nBrooks Dobbs (DoubleClick)\nBill Duserick (Fidelity)\nRigo Wenning (W3C)\nJeremy Epling (Microsoft)\nDave Stampley (Invited Expert)\nAri Schwartz (CDT)\nLorrie Cranor (AT&T Labs-Research)\n\nWe spent most of the call discussing the Fidelity comments\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0006.html\nand some related suggestions from Dave Stampley. Lorrie has posted an \nupdated matrix at http://www.w3.org/P3P/2003/p3p-translation.htm that \nreflects the changes we made to the access elements, admin, tailoring, \npseudo-decision, individual decision, physical, and financial (email \nher if you want the excel version). She has also folded in the other \ncomments that have been raised over the past week that we will discuss \non next week's call.\n\nWe had some discussion about changing the phrase \"allow you to access\" \nin the access definitions to \"let you access\" or \"give you access to\" \n... the consensus was that both of these choices were better than what \nwe have currently but people wanted to think more about which choice \nthey prefer.\n\nWe had some discussion about the RECIPIENT definition in the spec. \nThere is some inconsistency in that the recipient definition states \nthat it applies to the legal entity *beyond* the service provider and \nits agents, and yet the ours definition references the service provider \nand its agents. This might be solved by removing \"and its agents\" from \nthe recipient definition and \"ourselves\" from the ours definition. We \nwill discuss this further on the next call.\n\nJeremy asked when the work of this task force would be finalized and \nsaid that it would be useful to have it finalized by mid-August to have \ntime to get this language into an upcoming browser release. The group \nfelt that mid-August was reasonable. While there is still the \npossibility that changes might be made during the spec review process \n(last call, CR, PR, etc.), hopefully those changes will be minimal.\n\nOur next call will be on Tuesday, July 22 at 11 am US Eastern (the \nusual bridge has been reserved).\n\n\n\n", "id": "lists-017-4032858"}, {"subject": "Re: [BH] The most generic bindin", "content": "I think the confusion is that the wrong mail has been quoted. My mail\nsuggesting binding a P3P Policy to an arbitrary element is at\n\nhttp://lists.w3.org/Archives/Member/w3c-forms/2002AprJun/0247.html\n\nThe mail quoted originally is not from me.\n\nBest wishes,\n\nSteven Pemberton\n\n----- Original Message ----- \nFrom: \"Joseph Reagle\" <reagle@w3.org>\nTo: \"Rigo Wenning\" <rigo@w3.org>; \"public-p3p-spec\" <public-p3p-spec@w3.org>\nCc: \"Steven Pemberton\" <steven@w3.org>\nSent: Wednesday, July 16, 2003 3:53 PM\nSubject: Re: [BH] The most generic binding\n\n\n> On Wednesday 16 July 2003 08:12, Rigo Wenning wrote:\n> > I owe you this since a long time.\n>\n> Yes, and now I expect to have little time for this issue.\n>\n> > Steven Pemberton suggested a very simple binding that would allow to\n> > bind a P3P-Policy to arbitrary XML-Elements. He thought it would be a\n> > quick and short specification to do as it would define a generic\n> > attribute like xml lang=..[1] This could be done in a separate\n> > specification, but is also a possible candidate be included in the\n> > [beyond HTTP] stuff.\n> >\n> > So I suggest to specify an XML-attribute that can be generally used to\n> > point to a _Policy_ (not PRF). The binding is no issue as the attribute\n> > itself defines it's own binding by the element it is sitting on.\n>\n> I don't completely understand. I note that in the CR [a] they have a\n> mechanism for associating an input with a \"p3ptype.\" (I'll also note that\n> for historical purposes some privacy advocates *objected* to P3P\n> controlling the exchange of information under a policy. For some reason,\n> when we made the policy orthogonal to the actual auto-fill or control of\n> the exchange, which permits someone to make misrepresentations in the\n> policy and then solicit lots of unrelated information in a form, they felt\n> *happier*. <shrug/>)\n>\n> [a] http://www.w3.org/TR/xforms/slice6.html#model-prop-p3ptype\n>\n> > In a past email, Steven Pemberton gave an example of how this could look\n> > like[2]\n>\n> You seem to be suggesting that you'd associate an actual policy with an\n> element (e.g., p3ppolicy), for example:\n> <model>\n>  <instance><root><yourname/><homeEmailAddress></root></instance>\n>  <bind \"creditCardNumber\" p3ppolicy=\"http://example.com/some-policy.xml\"/>\n> </model>\n> but I don't think that's what Steven is discussing in [2]. I *think* they\n> are using p3ptype and perhaps asking two questions:\n> 1. How/when is the evaluation of a policy governing a form field\n> corresponding to a p3ptype affect the auto-filling of the form. I think\n> Steven is comfortable with the model there but I can't say I understand\n> everything involved there.\n> 2. Even if the P3P policy permits its release, should it be released if\nthe\n> form field is not displayed to the user via old CSS mechanisms, or XForms\n> switch/case mechanism. I think it would be a good idea for the HTML family\n> of specifications to recommend that fields should NOT be auto-filled if\n> they are not presented to the user. (Of course, agents will not be able to\n> figure this out in all cases as one could use various size,color, CSS\n> tricks?)\n>\n> [2] http://lists.w3.org/Archives/Member/w3c-forms/2003JanMar/0127.html\n>\n>\n\n\n\n", "id": "lists-017-4041591"}, {"subject": "Re: [BH] The most generic bindin", "content": "Thanks Steven, \n\nthis was my mistake, so thank you for the right pointer\n\nThe email does not reflect our entire discussion, but it is at least the\nmain start.\n\nRigo\n\nOn Wed, Jul 16, 2003 at 11:01:08PM +0200, Steven Pemberton wrote:\n> I think the confusion is that the wrong mail has been quoted. My mail\n> suggesting binding a P3P Policy to an arbitrary element is at\n> \n> http://lists.w3.org/Archives/Member/w3c-forms/2002AprJun/0247.html\n> \n> The mail quoted originally is not from me.\n> \n\n\n\n", "id": "lists-017-4054083"}, {"subject": "P3P KielWS Minutes publishe", "content": "http://www.w3.org/2003/p3p-ws/minutes.html\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-4062005"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Ari, \n\nI owe you the response to your very stringent analysis of the word and\ndefinition of 'identifiable' and 'identified' from a US cultural\nperspective. \n\nSo if you read the following, keep in mind that I try to do the same\nfrom a european perspective. I try to explain more about the model\nbehind the european definitions and understanding of identity and\nidentifiable. Note that 'identified' does not exist in there, but it is an\noriginal take-up by the P3P Specification WG that might make it's way\ninto data protection (as it makes a lot of sense)\n\nSo I risk to be long, but I tried to be short in Bugzilla and was not\nunderstood. So I try from to explain from Adam and Eve on. \n\nThe EU-Directive defines identifiable at two places: \n1/ The scope of data protection as such is limited to identifiable data\nArticle 2 a states:\n 'personal data' shall mean any information relating to an identified or\n identifiable natural person ('data subject'); an identifiable person is\n one who can be identified, directly or indirectly, in particular by\n reference to an identification number or to one or more factors\n specific to his physical, physiological, mental, economic, cultural or\n social identity; \n\n2/ Identifiable is explained further in consideration 26 of the\nDirective:\n\n(26) Whereas the principles of protection must apply to any information\nconcerning an identified or identifiable person; whereas, to determine\nwhether a person is identifiable, account should be taken of all the\nmeans likely reasonably to be used either by the controller or by any\nother person to identify the said person; whereas the principles of\nprotection shall not apply to data rendered anonymous in such a way that\nthe data subject is no longer identifiable; whereas codes of conduct\nwithin the meaning of Article 27 may be a useful instrument for\nproviding guidance as to the ways in which data may be rendered\nanonymous and retained in a form in which identification of the data\nsubject is no longer possible; \n\nThose are my assumptions and definitions as I want to keep P3P somewhat\nin sync with the Directive (see Art. 10 Taskforce for this goal)\n\nSo the EU-Directive, if you look carefully at the definitions, does not\nhave recurse on the intent of the data controller (or processor) to\nprocess data (use in your case) to identify. To trigger the application\nof data protection law (scope) it is sufficient that with likely and\nreasonable means, a person is able to say: This is person X (e.g. Ari\nSchwartz). The scope is not limited to the data processor. \nFor this email, identifying is easy, as your email-address is a unique\nidentifier making clear that you're the particular Ari Schwartz who sent\nthe email cited.  So if you would use 12345@w3.org, the W3-Systeam could\nstill identify you. So it is still identifiable data. (any person has to\nbe taken into account)\n\nThis makes the scope too large to give a basis for a technology tool.\nWhile it might be understandable that a law wants to define a very broad\nscope, it is unusable for most of the decisions that P3P wants to help\nwith. That's why we have invented/taken-up the 'identified' term in \nP3P 1.0, mostly because of the access-issues (access identified and not\nall potential identifiable data, which would require a lot of processing\nand identify the requester by doing his request)\n\nSo despite all the discussions in this world what PII is or what it\nisn't, despite the misconceptions floating around the world, we better\nought to have a conscise concept of identity behind P3P. This concept of\nidentity distinguishes IMHO between non-identifiable, identifiable and\nidentified. I want to prevent that we lose overview by packing\nprocessing, purpose, disclosure, sharing, retention, sensitive data\ntypes and other things into this one term and definition. Doing so could\nonly bring us into confusion.\n\nSo for the sake of clarity, I propose the following definitions for the\nsuggested three terms. \n\n1/ Identifiable\nWe always operated under the assumption of the definition in whereas 26\nof the EU-Directive. If there is a possibility to get to 'who is that\nguy' with likely reasonable means by any party, than we have the\nassumption of identifiable information, thus information that makes\nassertions about a natural person. The likely and reasonable prevent\nto take science fiction scenarios into account like invading Iraq to\nfind out who has joked on the phone about those wappons. (I think you\nmade this point in our earlier discussions ;)\n\n2/ non-identifiable\nThis is the flip-side of 1/. This is reflected in the <non-identifiable>\nelement, which is based directly on the definition. (second phrase\nafter colon) of whereas 26. P3P gives a hint to render IP-addresses\nanonymous. This could be taken up by a code of conduct e.g.\n\n3/ identified\nThe means (processing of data) described in 1/ have already been\napplied. This makes access to assertions about a natural person easier\nand faster. This is particularly important for access rights but also\nfor the overall risk analysis. So identified is data, that does not need\nfurther processing in this direction (I think the technical term is\n'crossing')\n\nThose three are all relative to 'data'. Data is an object here. The\nattributes to the term data are the three terms above describing the\nrelationsship between a given natural person (also an object here) and\nthe object 'data'. This relationsship has different levels and\nqualities. We deliberatly choosed the three described (IMHO)\n\nNow, like a cross-roads, there is another concept: The data processing life\ncycle:\nData is \na/ collected\nb/ processed\nc/ transferred \nd/ deleted\n\n(Retention is a sub-group to collection, transfer is a subgroup to\nprocessing)\n\nNow if you suggest to describe 'identified data' as 'how the information\ncan be or is being used', or if you describe it as 'reasonably can be\nused by the data collector to identify an individual, your definition\nmixes up identifiable, the processing of some raw data to identify\nan individual. \n\nIn fact you say: We use this raw traffic data to mine it and poke until\nwe know who you are, where you live and how you shop. \n\nThis mixes up the model as it describes a purpose of processing with the\ncollection of data and also with the relationsship between our objects\n'natural person' and 'data'. That's why I suggest to keep this\nrelationsship and the purpose of processing separate. This is done in\nmy definitions. So in non-identifiable, they can't find out, in\nidentifiable, they could find out and in identified, they found out.\n\nIf I collect identifiable information like IP (not domain), we have to\nseparate the question whether this is used to find out or not. The\nquestion of whether they want to find out or not is an important\nquestion, but it has to be treated separatly from the term identity as\nit is a purpose and normally not a primary purpose ;). \n\nA/You might say: We collect identifiable information. This is for the user\n-agent to decide to use an anonymizer. \n\nB/You might say: We use the data in A to find out who you are. \n(The problem is, today, we can't say that as the purpose section is\nstill too poor)\n\nIt doesn't make sense to say: \n\nA/ We collect identifiable information\nB/ We do not use them to identify you (but we could, so trust us and our\nsysadmin ;)\n\nnegative assertions just don't fit into the P3P model.\n\nAnother cross-roads is so called 'sensitive' data. \n\nAccording to Shannon/Weaver, any data can be sensitive, if it carries\nenough information. Did Clinten have sex with Lewinsky? A simple 'yes'\nfrom Mister C., a simple bit, could be sufficient.\n\nSo the EU-Directive takes some info up that is 'usually' very senitive,\nlike financial info, health info, religion and politics. Those are just\ndefined in the law. I don't think we have sufficient technology today to\ndefine whether data is sensitive or not. We can take those from the OECD\nand the EU-Directive up as it seems to make sense in front of such a\nbroad agreement. But outside this narrow scope, it is on the user\nhimself, confronted with the data, to judge whether data is sensitive or\nnot. And it should surely not mix into the definition of identity,\nidentifiable or identified.\n\nThat's why I think we should stick with my definitions described in \n1/ 2/ and 3/ and revise the Spec accordingly as far as we can get in 1.1\n\nBest, \n\nRigo\n\n\n\n\nOn Fri, Jun 20, 2003 at 12:09:27PM -0400, Ari Schwartz wrote:\n> \n> Here is my draft text for addressing the confusion around identity \n> terms in the spec.\n> \n> \n> \n> >http://www.w3.org/Bugs/Public/show_bug.cgi?id=167\n> \n> \n> \n> Identity Definitions in the P3P Specification\n> \n> In privacy regulations, guidelines and papers about privacy a variety \n> of terms are used to describe data that identifies an individual to \n> varying degrees.  Some common terms such as \"personally identifiable \n> information (PII)\" are often not defined or the cause for heated \n> debate.  In different documents, \"identity\" can be tied to:\n> \n> 1) how the information can be or is being used,\n> 2) how the information is stored, or\n> 3) the type of information.\n> \n> The P3P Specification Working Group tried to capture all three of \n> these ideas so that different implementers and users can make \n> decisions based on the importance they place on these various \n> definitions of identity. (1)\n> \n> Identity Through Usage (\"identified\" data)\n> \n> The most common term in the specification is \"identified data\" and \n> focuses on how the information can be or is being used.\n> \n> \"Identified data\" is information that reasonably can be used by the \n> data collector to identify an individual.  Admittedly, this is a \n> somewhat subjective standard.  For example, a data collector storing \n> Internet Protocol (IP) addresses  (which can be created dynamically \n> or could be static and therefore tied to a particular computer used \n> by a single individual) should consider the IP address \"identified \n> data\" only when an attempt is made to tie the exact addresses to past \n> records or work with others to identify the specific individual or \n> computer over a long period of time.  In the more common case, where \n> data collectors use IP addressing information in the aggregate or \n> make no attempt to tie the IP address to a specified individual or \n> computer over a long period of time, IP addresses are not considered \n> identified even though it is possible for someone (eg, law \n> enforcement agents with proper subpoena powers) to identify the \n> individual based on the stored data.\n> \n> \n> Identity Through Storage (\"non-identifiable\" and \"linked\" data)\n> \n> The working group also felt that data collectors should be able \n> acknowledge when they make specific attempts to anonymize what would \n> otherwise be identifiable in its storage.\n> \n> The term \"non-identifiable\" data refers to how the information is \n> stored.  For example, a data collector collecting and storing IP \n> addresses but not using them should NOT call this data \n> \"non-identifiable\" even in the common case where they have no plans \n> to identify an actual individual or computer. However, if a Web site \n> collects IP addresses, but actively deletes all but the last four \n> digits of this information in order to determine short term use, but \n> insure that a particular individual or computer cannot be \n> consistently identified, then the data collector can and should call \n> this information \"non-identifiable.\"  Also, non-identifiable can be \n> used in cases where no information is being collected at all.  Since \n> most Web servers are designed to keep Web logs for maintenance, this \n> would most likely mean that the data collector has taken specific \n> efforts to ensure the anonymity of users.\n> \n> Under the above definitions, a lot of information could be \n> \"identifiable\" (not specifically made anonymous), but not \n> \"identified\" (reasonably able to be tied to an individual or \n> computer).\n> \n> Similarly, the term \"linked\" refers to how information is being \n> stored in connection with a cookie. All data in a cookie or linked to \n> a particular user must be disclosed in the cookie's policy. Using the \n> terminology above, if the data collector collects \"identifiable\" \n> information about the user it is generally \"linked\" data.\n> \n> Identity Through Information Type\n> \n> The Working Group felt that different user agent implementations \n> could be created to focus on different concerns around data type. \n> Therefore, the working group enabled the creation of a robust data \n> schema including broad categories of information that may be \n> considered sensitive by certain user groups.  The Working Group hopes \n> that a diverse set of user agents will be created to allow users the \n> ability to make identity decisions based on specific collections and \n> types of collects if they desire to do so.  For example, a user agent \n> could allow users to opt to be prompted when medical or financial \n> identifier is being collected, independent of how that information is \n> being used.\n> \n> (1)   More information on the debate and the definitions can be found \n> in Lorrie Faith Cranor's book Web Privacy with P3P, O'Reilly, 2002.\n> \n> \n> \n> -- \n> ------------------------------------\n> Ari Schwartz\n> Associate Director\n> Center for Democracy and Technology\n> 1634 I Street NW, Suite 1100\n> Washington, DC 20006\n> 202 637 9800\n> fax 202 637 0968\n> ari@cdt.org\n> http://www.cdt.org\n> ------------------------------------\n\n\n\n", "id": "lists-017-4069414"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Hi Rigo,\n\nMy definitions were not meant to be from a US cultural perspective. \nIn fact, if I understand them correctly, your definitions are much \ncloser to the experience (legal interpretations) of the US Privacy \nAct of 1974 then mine are.\n\nThe reason that I strayed from this view is because of the use of \nrelational databases.  A data collector may create a system where \nfields are not searched at the time of collection but the person is \nstill generally identified within the system.\n\nMy understanding from Europe was that different countries were \ninterpreting this differently and it hadn't been worked out.  If you \ncan point to some definitive writing on this subject, I'd definitely \nlike to see it.\n\nAri\n\n\n\n\nAt 6:55 PM +0200 7/18/03, Rigo Wenning wrote:\n>Ari,\n>\n>I owe you the response to your very stringent analysis of the word and\n>definition of 'identifiable' and 'identified' from a US cultural\n>perspective.\n>\n>So if you read the following, keep in mind that I try to do the same\n>from a european perspective. I try to explain more about the model\n>behind the european definitions and understanding of identity and\n>identifiable. Note that 'identified' does not exist in there, but it is an\n>original take-up by the P3P Specification WG that might make it's way\n>into data protection (as it makes a lot of sense)\n>\n>So I risk to be long, but I tried to be short in Bugzilla and was not\n>understood. So I try from to explain from Adam and Eve on.\n>\n>The EU-Directive defines identifiable at two places:\n>1/ The scope of data protection as such is limited to identifiable data\n>Article 2 a states:\n>  'personal data' shall mean any information relating to an identified or\n>  identifiable natural person ('data subject'); an identifiable person is\n>  one who can be identified, directly or indirectly, in particular by\n>  reference to an identification number or to one or more factors\n>  specific to his physical, physiological, mental, economic, cultural or\n>  social identity;\n>\n>2/ Identifiable is explained further in consideration 26 of the\n>Directive:\n>\n>(26) Whereas the principles of protection must apply to any information\n>concerning an identified or identifiable person; whereas, to determine\n>whether a person is identifiable, account should be taken of all the\n>means likely reasonably to be used either by the controller or by any\n>other person to identify the said person; whereas the principles of\n>protection shall not apply to data rendered anonymous in such a way that\n>the data subject is no longer identifiable; whereas codes of conduct\n>within the meaning of Article 27 may be a useful instrument for\n>providing guidance as to the ways in which data may be rendered\n>anonymous and retained in a form in which identification of the data\n>subject is no longer possible;\n>\n>Those are my assumptions and definitions as I want to keep P3P somewhat\n>in sync with the Directive (see Art. 10 Taskforce for this goal)\n>\n>So the EU-Directive, if you look carefully at the definitions, does not\n>have recurse on the intent of the data controller (or processor) to\n>process data (use in your case) to identify. To trigger the application\n>of data protection law (scope) it is sufficient that with likely and\n>reasonable means, a person is able to say: This is person X (e.g. Ari\n>Schwartz). The scope is not limited to the data processor.\n>For this email, identifying is easy, as your email-address is a unique\n>identifier making clear that you're the particular Ari Schwartz who sent\n>the email cited.  So if you would use 12345@w3.org, the W3-Systeam could\n>still identify you. So it is still identifiable data. (any person has to\n>be taken into account)\n>\n>This makes the scope too large to give a basis for a technology tool.\n>While it might be understandable that a law wants to define a very broad\n>scope, it is unusable for most of the decisions that P3P wants to help\n>with. That's why we have invented/taken-up the 'identified' term in\n>P3P 1.0, mostly because of the access-issues (access identified and not\n>all potential identifiable data, which would require a lot of processing\n>and identify the requester by doing his request)\n>\n>So despite all the discussions in this world what PII is or what it\n>isn't, despite the misconceptions floating around the world, we better\n>ought to have a conscise concept of identity behind P3P. This concept of\n>identity distinguishes IMHO between non-identifiable, identifiable and\n>identified. I want to prevent that we lose overview by packing\n>processing, purpose, disclosure, sharing, retention, sensitive data\n>types and other things into this one term and definition. Doing so could\n>only bring us into confusion.\n>\n>So for the sake of clarity, I propose the following definitions for the\n>suggested three terms.\n>\n>1/ Identifiable\n>We always operated under the assumption of the definition in whereas 26\n>of the EU-Directive. If there is a possibility to get to 'who is that\n>guy' with likely reasonable means by any party, than we have the\n>assumption of identifiable information, thus information that makes\n>assertions about a natural person. The likely and reasonable prevent\n>to take science fiction scenarios into account like invading Iraq to\n>find out who has joked on the phone about those wappons. (I think you\n>made this point in our earlier discussions ;)\n>\n>2/ non-identifiable\n>This is the flip-side of 1/. This is reflected in the <non-identifiable>\n>element, which is based directly on the definition. (second phrase\n>after colon) of whereas 26. P3P gives a hint to render IP-addresses\n>anonymous. This could be taken up by a code of conduct e.g.\n>\n>3/ identified\n>The means (processing of data) described in 1/ have already been\n>applied. This makes access to assertions about a natural person easier\n>and faster. This is particularly important for access rights but also\n>for the overall risk analysis. So identified is data, that does not need\n>further processing in this direction (I think the technical term is\n>'crossing')\n>\n>Those three are all relative to 'data'. Data is an object here. The\n>attributes to the term data are the three terms above describing the\n>relationsship between a given natural person (also an object here) and\n>the object 'data'. This relationsship has different levels and\n>qualities. We deliberatly choosed the three described (IMHO)\n>\n>Now, like a cross-roads, there is another concept: The data processing life\n>cycle:\n>Data is\n>a/ collected\n>b/ processed\n>c/ transferred\n>d/ deleted\n>\n>(Retention is a sub-group to collection, transfer is a subgroup to\n>processing)\n>\n>Now if you suggest to describe 'identified data' as 'how the information\n>can be or is being used', or if you describe it as 'reasonably can be\n>used by the data collector to identify an individual, your definition\n>mixes up identifiable, the processing of some raw data to identify\n>an individual.\n>\n>In fact you say: We use this raw traffic data to mine it and poke until\n>we know who you are, where you live and how you shop.\n>\n>This mixes up the model as it describes a purpose of processing with the\n>collection of data and also with the relationsship between our objects\n>'natural person' and 'data'. That's why I suggest to keep this\n>relationsship and the purpose of processing separate. This is done in\n>my definitions. So in non-identifiable, they can't find out, in\n>identifiable, they could find out and in identified, they found out.\n>\n>If I collect identifiable information like IP (not domain), we have to\n>separate the question whether this is used to find out or not. The\n>question of whether they want to find out or not is an important\n>question, but it has to be treated separatly from the term identity as\n>it is a purpose and normally not a primary purpose ;).\n>\n>A/You might say: We collect identifiable information. This is for the user\n>-agent to decide to use an anonymizer.\n>\n>B/You might say: We use the data in A to find out who you are.\n>(The problem is, today, we can't say that as the purpose section is\n>still too poor)\n>\n>It doesn't make sense to say:\n>\n>A/ We collect identifiable information\n>B/ We do not use them to identify you (but we could, so trust us and our\n>sysadmin ;)\n>\n>negative assertions just don't fit into the P3P model.\n>\n>Another cross-roads is so called 'sensitive' data.\n>\n>According to Shannon/Weaver, any data can be sensitive, if it carries\n>enough information. Did Clinten have sex with Lewinsky? A simple 'yes'\n>from Mister C., a simple bit, could be sufficient.\n>\n>So the EU-Directive takes some info up that is 'usually' very senitive,\n>like financial info, health info, religion and politics. Those are just\n>defined in the law. I don't think we have sufficient technology today to\n>define whether data is sensitive or not. We can take those from the OECD\n>and the EU-Directive up as it seems to make sense in front of such a\n>broad agreement. But outside this narrow scope, it is on the user\n>himself, confronted with the data, to judge whether data is sensitive or\n>not. And it should surely not mix into the definition of identity,\n>identifiable or identified.\n>\n>That's why I think we should stick with my definitions described in\n>1/ 2/ and 3/ and revise the Spec accordingly as far as we can get in 1.1\n>\n>Best,\n>\n>Rigo\n>\n>\n>\n>\n>On Fri, Jun 20, 2003 at 12:09:27PM -0400, Ari Schwartz wrote:\n>>\n>>  Here is my draft text for addressing the confusion around identity\n>>  terms in the spec.\n>>\n>>\n>>\n>>  >http://www.w3.org/Bugs/Public/show_bug.cgi?id=167\n>>\n>>\n>>\n>>  Identity Definitions in the P3P Specification\n>>\n>>  In privacy regulations, guidelines and papers about privacy a variety\n>>  of terms are used to describe data that identifies an individual to\n>>  varying degrees.  Some common terms such as \"personally identifiable\n>>  information (PII)\" are often not defined or the cause for heated\n>>  debate.  In different documents, \"identity\" can be tied to:\n>>\n>>  1) how the information can be or is being used,\n>>  2) how the information is stored, or\n>>  3) the type of information.\n>>\n>>  The P3P Specification Working Group tried to capture all three of\n>>  these ideas so that different implementers and users can make\n>>  decisions based on the importance they place on these various\n>>  definitions of identity. (1)\n>>\n>>  Identity Through Usage (\"identified\" data)\n>>\n>>  The most common term in the specification is \"identified data\" and\n>>  focuses on how the information can be or is being used.\n>>\n>>  \"Identified data\" is information that reasonably can be used by the\n>>  data collector to identify an individual.  Admittedly, this is a\n>>  somewhat subjective standard.  For example, a data collector storing\n>>  Internet Protocol (IP) addresses  (which can be created dynamically\n>>  or could be static and therefore tied to a particular computer used\n>>  by a single individual) should consider the IP address \"identified\n>>  data\" only when an attempt is made to tie the exact addresses to past\n>>  records or work with others to identify the specific individual or\n>>  computer over a long period of time.  In the more common case, where\n>>  data collectors use IP addressing information in the aggregate or\n>>  make no attempt to tie the IP address to a specified individual or\n>>  computer over a long period of time, IP addresses are not considered\n>>  identified even though it is possible for someone (eg, law\n>>  enforcement agents with proper subpoena powers) to identify the\n>>  individual based on the stored data.\n>>\n>>\n>>  Identity Through Storage (\"non-identifiable\" and \"linked\" data)\n>>\n>>  The working group also felt that data collectors should be able\n>>  acknowledge when they make specific attempts to anonymize what would\n>>  otherwise be identifiable in its storage.\n>>\n>>  The term \"non-identifiable\" data refers to how the information is\n>>  stored.  For example, a data collector collecting and storing IP\n>>  addresses but not using them should NOT call this data\n>>  \"non-identifiable\" even in the common case where they have no plans\n>>  to identify an actual individual or computer. However, if a Web site\n>>  collects IP addresses, but actively deletes all but the last four\n>>  digits of this information in order to determine short term use, but\n>>  insure that a particular individual or computer cannot be\n>>  consistently identified, then the data collector can and should call\n>>  this information \"non-identifiable.\"  Also, non-identifiable can be\n>>  used in cases where no information is being collected at all.  Since\n>  > most Web servers are designed to keep Web logs for maintenance, this\n>>  would most likely mean that the data collector has taken specific\n>>  efforts to ensure the anonymity of users.\n>>\n>>  Under the above definitions, a lot of information could be\n>  > \"identifiable\" (not specifically made anonymous), but not\n>>  \"identified\" (reasonably able to be tied to an individual or\n>>  computer).\n>>\n>>  Similarly, the term \"linked\" refers to how information is being\n>>  stored in connection with a cookie. All data in a cookie or linked to\n>>  a particular user must be disclosed in the cookie's policy. Using the\n>>  terminology above, if the data collector collects \"identifiable\"\n>>  information about the user it is generally \"linked\" data.\n>>\n>>  Identity Through Information Type\n>>\n>>  The Working Group felt that different user agent implementations\n>>  could be created to focus on different concerns around data type.\n>>  Therefore, the working group enabled the creation of a robust data\n>>  schema including broad categories of information that may be\n>>  considered sensitive by certain user groups.  The Working Group hopes\n>>  that a diverse set of user agents will be created to allow users the\n>>  ability to make identity decisions based on specific collections and\n>>  types of collects if they desire to do so.  For example, a user agent\n>>  could allow users to opt to be prompted when medical or financial\n>>  identifier is being collected, independent of how that information is\n>>  being used.\n>>\n>>  (1)   More information on the debate and the definitions can be found\n>>  in Lorrie Faith Cranor's book Web Privacy with P3P, O'Reilly, 2002.\n>>\n>>\n>>\n>>  --\n>>  ------------------------------------\n>>  Ari Schwartz\n>>  Associate Director\n>>  Center for Democracy and Technology\n>>  1634 I Street NW, Suite 1100\n>>  Washington, DC 20006\n>>  202 637 9800\n>>  fax 202 637 0968\n>>  ari@cdt.org\n>>  http://www.cdt.org\n>>  ------------------------------------\n\n\n-- \n------------------------------------\nAri Schwartz\nAssociate Director\nCenter for Democracy and Technology\n1634 I Street NW, Suite 1100\nWashington, DC 20006\n202 637 9800\nfax 202 637 0968\nari@cdt.org\nhttp://www.cdt.org\n------------------------------------\n\n\n\n", "id": "lists-017-4091451"}, {"subject": "AGENDA: 23 July P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, July 23, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit and Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n2. Discuss Liberty slides\nhttp://lists.w3.org/Archives/Member/w3c-p3p-specification/2003Jul/ \n0002.html\n\n3. Discussion of Ari's identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jun/0030.html\n\n4. Discuss Jeremy's draft\n[to be sent to the list prior to the call]\n\n5. Set date for next call (July 30?)\n\n\n\n", "id": "lists-017-4116305"}, {"subject": "UA: Next UA TF call 22 Jul", "content": "The next P3P User Agent Task Force conference call will be on\nTuesday, July 22, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n1. Discuss access wording:\n\"give you access to\" vs. \"let you access\"\n\n2. Should we use full sentences or sentence fragments for purpose and\nrecipient? Alternatively we could provide both. Another alternative\nwould be to provide only one but indicate that it is acceptable for\nuser agents to do the other.\n\n3. Go through comments in red in translation matrix\nat http://www.w3.org/P3P/2003/p3p-translation.htm\n\n4. If time permits, go through comments in green (these deal with\nsuggested spec changes) in translation matrix at\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\n\n\n\n", "id": "lists-017-4124549"}, {"subject": "Re: [BH] The most generic bindin", "content": "On Wednesday 16 July 2003 17:01, Steven Pemberton wrote:\n> I think the confusion is that the wrong mail has been quoted. My mail\n> suggesting binding a P3P Policy to an arbitrary element is at\n> http://lists.w3.org/Archives/Member/w3c-forms/2002AprJun/0247.html\n\nThank you Steven, it's useful to see the original source when trying to \nfigure out what the issue is! <smile/>\n\n> The problem is, there can be several <submit> elements, and each \n> submit could have a different policy associated with it.\n>\n> I propose removing the <privacy> element, and adding a p3p attribute \n> to the <submission> element to identify the policy reference file for \n> the submission:\n>    <submission action=\"/submit\" method=\"post\" \n>     p3p=\"http://...\" id=\"sbmt\"/>\n\nI'll note that since this email was sent over a year ago, you presently \ndon't appear [1] to do either of these. Instead,\n(a) XForms doesn't have any special mechanisms for the policy association, \ninstead you reference the existing methods [2] (well known location, link \ntag, HTTP header).\n(b) Orthogonally, a P3P data element type can be bound [3] to an XForms \ninstance data node. I assume there must be a one-to-one mapping for each, \nso the binding list could get rather exhaustive.\n\nEven your suggestion above did *not* require a per element (e.g., \n\"user.personname.given\") policy association, only a per submission \nassociation.\n\n[1]http://www.w3.org/TR/2002/CR-xforms-20021112/slice3.html#structure-model-submission\n[2]http://www.w3.org/TR/2002/CR-xforms-20021112/sliceC.html\n[3]http://www.w3.org/TR/2002/CR-xforms-20021112/slice6.html#model-prop-p3ptype\n\n\n\n", "id": "lists-017-4131898"}, {"subject": "Re: [BH] The most generic bindin", "content": "On Wednesday 16 July 2003 15:13, Lorrie Cranor wrote:\n> The semantics of a P3P policy is that is applies to all data collection\n> associated with a URI\n\nOk, hopefully the issue is now represented in:\n  http://www.w3.org/P3P/2003/p3p-beyond-http/#sec-XForms-Granular\n  $Revision: 1.31 $ on $Date: 2003/07/18 20:14:11 $ GMT\n\n\n\n", "id": "lists-017-4141020"}, {"subject": "Re: AGENDA: 23 July P3P spec cal", "content": "On Friday 18 July 2003 15:45, Lorrie Cranor wrote:\n> The next P3P specification group conference call will be on\n> Wednesday, July 23, 2003, 11 am - 12 pm US Eastern. \n\nMy regrets, will be on holiday but we've started the \"granularity\" thread \nand I've added some initial text to the report.\n\n\n\n", "id": "lists-017-4148749"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "On Fri, Jul 18, 2003 at 02:15:23PM -0400, Ari Schwartz wrote:\n> \n> Hi Rigo,\n> \n> My definitions were not meant to be from a US cultural perspective. \n> In fact, if I understand them correctly, your definitions are much \n> closer to the experience (legal interpretations) of the US Privacy \n> Act of 1974 then mine are.\n\nOk, that makes sense as the Act of 1974 was in concerto and in sync with\nthe development in Europe. It only touches the public sector, but the\ndefinitions of scope (identifiable in our case) are still the same.\n> \n> The reason that I strayed from this view is because of the use of \n> relational databases.  A data collector may create a system where \n> fields are not searched at the time of collection but the person is \n> still generally identified within the system.\n\nThat is exactly the point. Initially, data protection in national\nlegislations did _not_ apply to paper-collections. The Directive extends\nthe scope to well-organized paper-collections. \n\nThe parallel I see is the distinction between raw logfile data and data\norganized in a relational database. A simple cross-reference of the\ntables would link a lot of data to someone's identity. This is much\nharder to do for raw logfiles where you'd have to resolve all the\npseudonyms (like IP etc), chase for ID's in refererrers and re-organize\nthe raw data in a relational database (or in RDF). \n\nIn a relational database, I consider the identifying already be done as\nsoon as there is a link to some identity qualifier like name, address,\nSocial security number, email-address etc. \n\nI don't want to explore the fuzzy edge between pseudonyms and\n'identified' here, as this is another potential rathole. But if a\ncompany had good profile-data in a well-organized relational database\ntied to a pseudonym and the same company would have the ability to\nresolve that pseudonym to the real name of a person without external\ndata and help, I would consider this identified as the decision of\nidentifying (purpose, processing) lies in their hands unless there are\nspecific means to prevent the identification of a pseudonym (third party\ne.g.)\n\n> \n> My understanding from Europe was that different countries were \n> interpreting this differently and it hadn't been worked out.  If you \n> can point to some definitive writing on this subject, I'd definitely \n> like to see it.\n\nNo, I don't think so. In fact, the commission just decided to follow-up\nwith every diverging definition and remedy the situation so that laws\nare more homogenius. I will verify, but you could help me by giving me a\nmore concrete example of what you mean by diverging interpretations. (I\nthink the variety is more on the side of permissions than on the side of\nscope and definition of identity and identifiable)\n\nBest, \n\nRigo\n\n> \n\n\n\n", "id": "lists-017-4155865"}, {"subject": "UA: MINUTES 22 July UA TF cal", "content": "Minutes of the 22 July 2003 User Agent task force call\n\nPresent:\n\nLorrie\nBill\nDave\nJeff\nBrooks\nAri\n\n1. Discuss access wording:\n\"give you access to\" vs. \"let you access\"\n\nThe group agreed to use the phrase \"give you access\" because it is more \nactive, correctly implies that the site will do something, and best \nmirrors the wording in the spec.\n\n2. Should we use full sentences or sentence fragments for purpose and\nrecipient? Alternatively we could provide both. Another alternative\nwould be to provide only one but indicate that it is acceptable for\nuser agents to do the other.\n\nThe group agreed to use sentence fragments because most user agents \nwill display these fragments below an appropriate heading. Dave had \nsome concerns about whether some of the elements might be less clear \nthis way. He will raise the issue again if he finds specific instances \nof this.\n\n3. Go through comments in red in translation matrix\nat http://www.w3.org/P3P/2003/p3p-translation.htm\n\nWe got through the proposed changes for the ACCESS, DISPUTES, and \nNON-IDENTIFIABLE elements, as well as some of the PURPOSE elements. We \nmade changes to the following translations: nonident, all, \ncontact-and-other, ident-contact, other-ident, none, DISPUTES, \nNON-IDENTIFIABLE, PURPOSE. Lorrie posted an updated matrix at \nhttp://www.w3.org/P3P/2003/p3p-translation.htm. She will update it \nagain with any additional comments she receives before the next call.\n\n4. Our next call will be on Tuesday, July 29 from 10:30 am to noon. \nPlease try to call in on time so we can try to get through the rest of \nthe matrix on this call.\n\n\n\n", "id": "lists-017-4165812"}, {"subject": "MINUTES: 23 July P3P spec cal", "content": "1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\nPatrick Hung is taking over this task force. Lorrie will try to get him  \na jigedit account.\n    - User agent behavior - Lorrie Cranor\nContinuing to make progress. More feedback welcome.\n\n    - Compact policies - Brian Zwit and Brooks Dobbs\nBrooks and Jeremy have been discussing and will arrange a call in the  \nnext two weeks. They will focus on documenting performance issues and  \non the grouping mechanism.\n\n    - Article 10 vocabulary issues - Giles Hogben\nGiles will try to attend the working party meeting in September to make  \nsure this gets discussed and we get EU feedback.\n\n2. Discuss Liberty slides\nhttp://lists.w3.org/Archives/Member/w3c-p3p-specification/2003Jul/ \n0002.html\n\nHere is the gist of the feedback we want to send to Liberty. Other WG  \nmembers may draft more detailed feedback to send themselves...\n\nWe have some concerns about taking the very expressive P3P vocabulary  \nand reducing it down to a set of five privacy policies. If web sites  \nare only going to be able to describe five policies, there is not a lot  \nto be gained by using P3P at all. You could simply define five standard  \npolicies in human-readable language. From a technical perspective, we  \ndo not understand why the five-policy limitation is necessary. While  \nservice providers may want to provide a limited set of preference  \nsettings to users in order to make interfaces usable, it is not clear  \nwhy every service provider needs to provide the same set of preference  \nsettings, or why web sites should be restricted to providing policies  \nthat correspond with these settings.\n\nWe also have concerns about the way these policies have been put into a  \nwell-ordered set. The P3P vocabulary was not intended to represent a  \nwell-ordered set. Depending on the context and user preferences, some  \ndata uses may be more privacy invasive than others, for example.\n\nLooking at the specific five policies that have been proposed, we also  \ndo not understand why the least restrictive ones are not a superset of  \nthe more restrictive policies -- for example, why doesn't the moderate  \npolicy include nonident and all along with contact-and-other?\n\nWe also note that the policies require the use of the remedies element,  \nwhich is actually an optional part of P3P. In addition, the delivery  \nelement is only permitted for the least restrictive policy, however, it  \nis an element found in the privacy policies of most web sites today.\n\n\n3. Discussion of Ari's identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jun/0030.html\n\nRigo had some concerns about Ari's draft, which he explained in  \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Jul/0033.html.  \nLorrie suggested that Ari try incorporating Rigo's suggestions about  \nreferring to the EU definitions in the introduction, but then stick  \nwith his current approach. Rigo was not on the call so we don't know  \nwhat his reaction will be, but Ari will try this and then get feedback.  \nBrooks will send Ari a linking example to include too.\n\n4. Our next call will be on July 30. The primary agenda item will be  \ndiscussing Jeremy's draft. If we do not receive this draft by July 28  \nwe will probably postpone this call until August 6 (unless something  \nelse comes up that we need to discuss).\n\n\n\n", "id": "lists-017-4174013"}, {"subject": "UA: UA TF call today at 10:30 am US Easter", "content": "The next P3P User Agent Task Force conference call will be on\nTuesday, July 29, 2003, 10:30 am - 12 pm US Eastern. Dial-in\ninformation (the usual number) is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Go through comments in red in translation matrix\nat http://www.w3.org/P3P/2003/p3p-translation.htm\n\n2. If time permits, go through comments in green (these deal with\nsuggested spec changes) in translation matrix at\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\n\n\n\n", "id": "lists-017-4184151"}, {"subject": "UA: Minutes of 29 July UA TF cal", "content": "Minutes of 29 July 2003 User Agent Task Force Call\n\nParticipants:\nLorrie\nBill\nAri\nDave\n\nWe worked through most of the red comments at \nhttp://www.w3.org/P3P/2003/p3p-translation.htm and reached a consensus \non most items. Changes were made to the following elements: current, \ndevelop, pseudo-analysis, individual-analysis, RECIPIENT, ours, \ndelivery, same, other-recipient, unrelated, public, RETENTION, \nno-retention, stated-purpose, legal-requirement, business-practices, \nindefinitely, CATEGORIES, computer, interactive, demographic, content, \npolitical, preference, location. Lorrie has posted a spreadsheet with \nremaining items for discussion. Those who participated should also \ncheck to make sure all changes are accurately reflected.\n\nOur next call will be tomorrow, 30 July at 11 am Eastern (the spec call \nwill be cancelled).\n\n\n\n", "id": "lists-017-4191356"}, {"subject": "no P3P spec call July 30, UA TF will use the bridg", "content": "The P3P spec call previously scheduled for 11 am Eastern on Wednesday, \nJuly 30, 2003 has been cancelled because we are still waiting for the \nMicrosoft proposals.\n\nThe next P3P spec call will be on Wednesday, August 6.\n\nThe user agent task force will use the bridge on July 30 at 11 to \ncontinue going through the spreadsheet at \nhttp://www.w3.org/P3P/2003/p3p-translation.htm\n\n\n\n", "id": "lists-017-4198729"}, {"subject": "Grouping Statements Proposa", "content": "Below are the basics of my proposal for statement grouping.\n\n \n\nProblems\n\n*Policies are not relevant to how a user interacts with the site\n\n*Users don't know what part of a P3P policy applies to\nthem and there activities on a site\n*Users understand scenarios of how they interact with a\nsite better than a series of statements related to a feature of the site\n\n*Policy authors have to make highest common denominate policies\nthat could look more privacy impacting than they are for most users\n\n \n\nGoals\n\n*Provide a method for showing the sections of the P3P policy that\napply to how a user interacts with the site/service\n*Allow an easy way for policy authors to describe what sections\nof their P3P policy apply to different user interaction with their\nsite/service\n\n \n\nScenarios\n\n*User browses to ebay and views the P3P policy. They are able to\nskip to the buyer section of the P3P policy since that is what applies\nto them.\n*User browses to amazon and views the P3P policy. The can see\nthat since they are not logged in less information is collected about\nthem.\n\n \n\nDesign\n\n \n\nThe P3P author decides the name of the statement group which is used in\nthe display of the agent when it translates the nodes to natural\nlanguage.\n\n \n\n<Statement>\n\n            <extention>\n\n                        <grouping-id>Member</grouping-id>\n\n            </extention>\n\n<statement>\n\n \n\nIssues\n\n*Do agents now show conflicts per grouping?\n\n \n\nJeremy Epling\nWindows - Privacy and Trust UX\n\nwpihelp <BLOCKED::>  - where to go for all your privacy questions\n\n \n\n\n\n", "id": "lists-017-4205751"}, {"subject": "Re: Grouping Statements Proposa", "content": "Hi Jeremy,\n\nthanks for your design. I feel that grouping statements is a good idea.\n\nThe actual syntax for grouping is elaborated in our earlier draft on \nconsent choices:\n  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n\nI feel that grouping statements is a good idea for multiple purposes.\nTherefore, I feel that we should have a general group mechanism where each \ngroup should have multiple properties:\n- opt-in opt-out or always (from consent choices)\n   syntactically this can be implicit: either all statements are \nalways/opt-in, or opt-out.\n- target (something specifying whether it's the ebay or amazon part)\n   The target is something that might be useful to add to your proposal.\n   I don't know how to express this in a nice syntax.\n\nWhy don't we merge both proposals into a \"grouping statements\" proposal?\n\nRegards,\n\nmatthias\n\n\n\nAt 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n\n>Below are the basics of my proposal for statement grouping.\n>\n>\n>\n>Problems\n>    * Policies are not relevant to how a user interacts with the site\n>        * Users don t know what part of a P3P policy applies to them and \n> there activities on a site\n>        * Users understand scenarios of how they interact with a site \n> better than a series of statements related to a feature of the site\n>    * Policy authors have to make highest common denominate policies that \n> could look more privacy impacting than they are for most users\n>\n>\n>Goals\n>    * Provide a method for showing the sections of the P3P policy that \n> apply to how a user interacts with the site/service\n>    * Allow an easy way for policy authors to describe what sections of \n> their P3P policy apply to different user interaction with their site/service\n>\n>\n>Scenarios\n>    * User browses to ebay and views the P3P policy. They are able to skip \n> to the buyer section of the P3P policy since that is what applies to them.\n>    * User browses to amazon and views the P3P policy. The can see that \n> since they are not logged in less information is collected about them.\n>\n>\n>Design\n>\n>\n>\n>The P3P author decides the name of the statement group which is used in \n>the display of the agent when it translates the nodes to natural language.\n>\n>\n>\n><Statement>\n>\n>             <extention>\n>\n>                         <grouping-id>Member</grouping-id>\n>\n>             </extention>\n>\n><statement>\n>\n>\n>\n>Issues\n>    * Do agents now show conflicts per grouping?\n>\n>\n>Jeremy Epling\n>Windows - Privacy and Trust UX\n>\n><BLOCKED::>wpihelp - where to go for all your privacy questions\n>\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-4214630"}, {"subject": "UA: Minutes 30 July UA T", "content": "Minutes of the 30 July 2003 User Agent task force call\n\nParticipants:\nLorrie\nJeremy\nJeff\nBill\nAri\n\nWe completed discussing the remaining comments on the matrix at \nhttp://www.w3.org/P3P/2003/p3p-translation.htm. We made changes to the \nfollowing elements: law, pseudo-decision, individual-decision, \nhistorical, public. We will recommend to the full WG that the words \n\"beyond the service provider and its agents\" be removed from the \nRECIPIENT definition in the spec. Some concerns remain about the spec \ndefinitions for some of the DISPUTES and REMEDIES elements. We will try \nto get more feedback on this from some of the lawyers who have been \ninvolved, especially Joel Reidenberg.\n\nLorrie posted a revised matrix and has invited public comments by 13 \nAugust. This will allow us to make another pass at revisions by the end \nof August so they can be incorporated in the next browser releases.\n\n\n\n", "id": "lists-017-4224640"}, {"subject": "RE: draft proposed translatio", "content": "I have attached my comments to the table lorrie posted.\n\nLorrie: can you update these into the posted html page.\n\nJeremy Epling\nMicrosoft - Windows PM\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n[mailto:public-p3p-spec-request@w3.org] On Behalf Of Lorrie Cranor\nSent: Wednesday, May 21, 2003 7:19 PM\nTo: public-p3p-spec@w3.org\nSubject: UA: draft proposed translation\n\n\nI have posted a file at\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\nthat contains a table with all of the elements in the p3p spec that I \nthink we need to consider translations for (in the order they appear in \nthe spec), the definitions from the spec, the text used in IE6, and my \nproposed translation. When Jeremy gives me his revisions I will be \nhappy to replace the IE6 column with his new text. Likewise, I will be \nhappy to add a column for anyone else who wants to take a stab at this \n(if you would like a copy of my excel file to work with, send me \nemail). This is my personal proposal based on my research and the \nfeedback I've gotten on the Privacy Bird translations. It has not been \nreviewed by a lawyer or anyone else.\n\nWe will discuss this on the UA TF call next Tuesday. It would be useful \nif everyone reviews this prior to the call and notes specific things \nthey don't like.\n\nLorrie\n\n\n\n\n\n\n\ntext/html attachment: translations.htm\n\n\n\n\n", "id": "lists-017-4279270"}, {"subject": "RE: draft proposed translatio", "content": "I have attached my comments to the table lorrie posted.\n\nLorrie: can you update these into the posted html page.\n\nJeremy Epling\nMicrosoft - Windows PM\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n[mailto:public-p3p-spec-request@w3.org] On Behalf Of Lorrie Cranor\nSent: Wednesday, May 21, 2003 7:19 PM\nTo: public-p3p-spec@w3.org\nSubject: UA: draft proposed translation\n\n\nI have posted a file at\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\nthat contains a table with all of the elements in the p3p spec that I \nthink we need to consider translations for (in the order they appear in \nthe spec), the definitions from the spec, the text used in IE6, and my \nproposed translation. When Jeremy gives me his revisions I will be \nhappy to replace the IE6 column with his new text. Likewise, I will be \nhappy to add a column for anyone else who wants to take a stab at this \n(if you would like a copy of my excel file to work with, send me \nemail). This is my personal proposal based on my research and the \nfeedback I've gotten on the Privacy Bird translations. It has not been \nreviewed by a lawyer or anyone else.\n\nWe will discuss this on the UA TF call next Tuesday. It would be useful \nif everyone reviews this prior to the call and notes specific things \nthey don't like.\n\nLorrie\n\n\n\n\n\n\n\ntext/html attachment: translations.htm\n\n\n\n\n", "id": "lists-017-4288170"}, {"subject": "UA: please review translation proposal by June 1", "content": "User agent task force members (and anyone else who is interested) - I \nwould like to get another round of feedback on the user agent \ntranslation document by June 10. If you haven't already done so, please \nreview the document at http://www.w3.org/P3P/2003/p3p-translation.htm \n(if you would like an MS Excel version for easier printing and editing, \nplease email me and I will send it to you). I last updated this \ndocument on 27 May 2003.\n\nTo see what a P3P policy looks like translated with all these \ncomponents, please check out: http://www.goats.com/features/privacy/\nOne of my students (who also runs the goats web site in his spare time) \nput this demo together.\n\nPLEASE, PLEASE, PLEASE, get your feedback in so we can move forward \nwith further external vetting and testing. If I don't get feedback I \nwill assume that you all think the proposed translation is perfect as \nis.\n\nRemember we are mostly interested in the following questions:\n\n- Will the proposed language be clear to end users? Are there ways we \ncan say the same thing that are clearer, simpler, or more concise?\n\n- Is the proposed language consistent with the normative definition of \neach element in the P3P specification? While the proposed language may \nomit some details included in the full definition, our objective is \nthat it should be consistent with the normative definition and that an \nend-user reading this definition only will not be mislead.\n\n\n\n", "id": "lists-017-4298640"}, {"subject": "Re: draft proposed translatio", "content": "I just posted a new version of\nhttp://www.w3.org/P3P/2003/p3p-translation.htm dated 2 June 2003 that \nincludes a column with Jeremy's comments.\n\nOn Sunday, June 1, 2003, at 09:41  PM, Jeremy Epling wrote:\n\n> I have attached my comments to the table lorrie posted.\n>\n> Lorrie: can you update these into the posted html page.\n>\n> Jeremy Epling\n> Microsoft - Windows PM\n>\n\n\n\n", "id": "lists-017-4306714"}, {"subject": "Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "[ Sending this to public-p3p-spec@w3.org instead of\n  www-p3p-public-comments@w3.org as indicated since the latter is\n  closed. ]\n\nPlease find below some comments regarding:\n\n  [P3P]: Beyond HTTP\n\n  P3P Task Force Report 18 April 2003\n  $Revision: 1.17 $ on $Date: 2003/05/27 22:32:09 $ GMT\n\n  http://www.w3.org/P3P/2003/p3p-beyond-http/\n\nComments are inline:\n\n| [P3P]: Beyond HTTP\n| \n| P3P Task Force Report 18 April 2003\n[..]\n| Introducing A Web Application Scenario\n| \n|    An interesting/difficult requirement for Web applications is that of\n|    initial data solicitation under a privacy policy and subsequent\n|    delegation/propagation of the solicited data under the policy. Our\n|    scenario is inspired by:\n|      * [24]S030 Third party intermediary scenario of the [25]Web Services\n|        Architecture Usage Scenarios [WSAUS], and\n|      * The [26]IETF Provision Registry Protocol's (PROVREG) privacy\n|        scenario\n| \n|    Our scenario is not intended to be a completely accurate\n|    representation of real world requirements, nor does our document\n|    necessarily provide a satisfactory solution. Instead, this scenario is\n|    intended to be sufficiently represenative to serve our primary purpose\n|    of exploring generic Web application privacy issues and providing\n|    recommendations towards [P3P] reuse in that context.\n| \n|   Scenario Definition\n| \n|    Quoting from the [27]PROVREG Charter:\n| \n|      Administration of Domain Name Service (DNS) registration\n|      increasingly\n|      distinguishes between the operation of a \"back-end\" registry data\n|      base\n|      service for registrations, versus \"front-end\" support services by\n|      registrars who interact with registrants and with the registry.\n|      Especially for various Top-Level Domains, the desire is to permit\n|      multiple registrars to share access to the database.  Conversely,\n|      there\n|      is a desire to allow a registrar to access multiple registries via\n|      the\n|      same protocol, even if the registries differ in operational models.\n[..]\n\nThis is a great example. We should leverage it for the Web Services\nArchitecture Usage Scenarios document.\n\n| Soliciting Data from the User and Referencing Policies\n| \n|    In our scenario, information is solicted from the [34]User by the\n|    [35]Soliciting Service so as to register the user's domain name. This\n|    section describes how a policy can be made known to the user agent.\n| \n|    [[36]Section 2, P3P] provides four mechanisms for indicating the\n|    privacy policy of a site, the policy reference file\n| \n|     1. may be located in a predefined \"well-known\" location, or\n|     2. a document may indicate a policy reference file through an HTML\n|        link tag, or\n|     3. a document may indicate a policy reference file through an XHTML\n|        link tag, or\n|     4. through an HTTP header.\n| \n|    In our scenario, the Soliciting Service has a P3P privacy policy at\n|    the following URI:\n|  href='http://registry.example.com/P3P/PolicyReferences.xml'\n| \n|    [37]Adopting applications that rely upon a data format other than\n|    [XHTML] to solicit information SHOULD support the first (well known\n|    location) and fourth (HTTP header) mechanisms; [38]adopting\n|    applications MUST NOT ever (mistakenly) release information to an\n|    application it is not familiar with on the basis of [P3P] mechanisms\n|    that it is familiar with. [39]Adopting applications MAY provide a\n|    means of associating a policy reference file with their own format.\n\nI think that for Web services, the policy (or the link to a policy\nreference file) should be expressed as a feature. Features are the\nextensibility mechanism of SOAP 1.2[55]. The Web Services Description\nWG is working on their description and the Web Services Architecture\nWG is evaluating their role in the overall architecture.\n\nFeature is basically a functionality which can be expressed in\ndifferent ways. In this case, the policy / policy reference would be\ncarried by the SOAP message:\n- inside the envelope.\n- by the binding:\n  - an RFC2822 header for an email transfer.\n  - an P3P's HTTP header when using HTTP.\n  - other means.\n\n[..]\n|   Associating with an (Optional) WSDL Description\n| \n|    An optional feature a Web service is to offer potential clients a\n|    [WSDL] description of its capabilities prior to interaction. Or, it\n|    might list itself in a directory [UDDI] such that user agents can\n|    peruse a description in order to select the most appropriate service.\n| \n|    An obvious question in these circumstances is should a privacy\n|    statement be included in a [WSDL] description or [UDDI] entry? This\n|    would certainly be useful to web service clients that want to select\n|    services on the basis of a privacy practice.\n\nWSDL 1.2 has a mechanism to express features. If you were defining\nsuch a P3P feature, it would define what to express (the properties of\nthe feature) in WSDL 1.2 (e.g.a URI reference, etc.). See [56] for the\ndescription of features.\n\nRegistries would most likely refer to the service description and you\nwould get that information for free.\n\n[..]\n| Transferring Data to a Third Party\n| \n|   The Movement of Information\n| \n|    In an intermediary scenario, data (defined broadly to include service\n|    privacy privacies, and personal information and privacy preferences)\n|    may move in many directions between the parties of the transaction.\n|    There are numerous models of interaction between the participants and\n|    the flows of information. For example:\n|      * In [P3P], a user's information is solicited by providing it with a\n|        privacy policy, which the user's client evaluates in light of the\n|        user privacy preferences. While the released information must be\n|        redistributed in accordance with the p3p:recipient field, [P3P]\n|        itself is not necessarily used to mediate those subsequent\n|        interactions. A [P3P] interaction is one-to-one with a focus on\n|        the user solicitation.\n|      * In PROVREG, a privacy policy governs the interaction between\n|        services (one or more registrars and the final registry). While\n|        the information exchanged my include user data, the user\n|        solicitation is out of scope.\n|      * In EPAL ([47]Enterprise Privacy Authorization Language), \"While\n|        [P3P] formalizes privacy promises to be advertised (i.e., business\n|        to consumer), EPAL formalizes privacy authorization for actual\n|        enforcement within an enterprise or for business-to-business\n|        privacy control.\"\n| \n|    One can consider three variables with respect to the flow of\n|    information within a network:\n| \n|    Direction of Flow\n|           In [P3P], policies flow to the user agent, preferences stay\n|           local to the user agent, and information flows to services. One\n|           can also conceive of an exchange in which a user publishes his\n|           preferences and services must agree to them, or user\n|           preferences accompany user information in its journey -- as\n|           we've also done in our example scenario via my:Privacy element.\n| \n|    Points of Decision\n|           In [P3P], the user's agent (the point of decision) is typically\n|           his network client. However, one can also imagine a trusted\n|           network service acting as the user's agent (managing the user's\n|           identity, information and enforcing his preferences). In\n|           PROVREG and EPAL services themselves are exchanging policies\n|           and making decisions.\n| \n|    Points of Aggregation\n|           A service which solicits information from a user for\n|           redistribution to other services might choose to first collect\n|           and combine the policies of its peers and represent the\n|           p3p:recipients as having the \"same\" policy, or it might ask for\n|           separate parcels of information under a different policy\n|           corresponding to each of the recipients which it transfers data\n|           to.\n\nThis is right on target.\n\n[..]\n|   The Scope of Layers and Bindings (HTTP and SOAP)\n| \n|    Does the [P3P] policy belong at the SOAP level, or HTTP? In the\n|    majority of cases SOAP will be transported over HTTP, what happens if\n|    both collect data? Given that a higher level application will likely\n|    know its dependencies, but its dependencies will not know the\n|    characteristics of those using them:\n| \n|    [49]Adopting applications MUST specify where relevant [P3P] statements\n|    can be found. We RECOMMEND that normative association (not including\n|    [WSDL] or [UDDI]) be limited to the higher/application layer. We\n|    RECOMMEND that a higher/abstract layer MAY include the privacy policy\n|    of layers it is dependent upon, but that lower layers SHOULD NOT\n|    represent the policies of higher layers. For example, an application\n|    that transfers data with SOAP over HTTP that uses cookies, SHOULD\n|    specify:\n|     1. the [P3P] policy associated with SOAP is normative and includes\n|        the HTTP policy, or\n|     2. there are distinct [P3P] policies associated with the SOAP and\n|        HTTP layers.\n\nIsn't this already the case with a Web server nowadays? The HTTP\nstack/server may have some logging policies different from the ones a\nCGI has, for example.\n\n|   Intermediaries\n| \n|    Even before data makes it to the Service Provider and its\n|    p3p:Recipients, if any, the information might travel through various\n|    intermediaries in order to reach its destination. [[53]Section 1.1.3,\n|    P3P] speaks to these cases as follows:\n| \n|      P3P policies represent the practices of the site. Intermediaries\n|      such as telecommunication providers, Internet service providers,\n|      proxies and others may be privy to the exchange of data between a\n|      site and a user, but their practices may not be governed by the\n|      site's policies. In addition, note that each P3P policy is applied\n|      to specific Web resources (Web pages, images, cookies, etc.) listed\n|      in a policy reference file. By placing one or more P3P policies on\n|      a Web site, a company or organization does not make any statements\n|      about the privacy practices associated with other Web resources not\n|      mentioned in their policy reference file, with other on-line\n|      activities that do not involve data collected on Web sites covered\n|      by their P3P policy, or with offline activities that do not involve\n|      data collected on Web sites covered by their P3P policy.\n| \n|    This semantic continues to stand in circumstances \"beyond HTTP.\"\n|    However, we may now make the following recommendation:\n|     1. Adopting applications that want to ensure the privacy of user\n|        information SHOULD take steps to ensure that no information is\n|        released to a network intermediary that is not covered by its P3P\n|        policy. This may be expressed via policy (such as [SOAP] headers)\n|        or ensured via various end-to-end mechanisms such as session\n|        security (e.g., [TLS]) or document security (e.g., [XENC]).\n| \n|    Do we need to say anything more about forwarding and active\n|    intermediaries? Should we define a \"[54]P3P Policy for SOAP\n|    intermediaries\" that only permits the data to be used for the \"current\n|    purpose/admin and no retention\" that SOAP intermediaries MUST use?\n|    Reagle prefers to rely upon the text above unless we are further\n|    pressed with actual use cases.\n\nAgreed.\n\nThere is something else which probably needs to be underlined. P3P\nreference policies for resources, whatever the operation on them is.\n\nWith Web services, what the resource is is a little fuzzy (a car? the\napplication in charge of selling cars? some state about the sale of a\ncar?) and WSDL defines the interface to this target resource. The\nlevel of granularity here is probably the WSDL operation.\n\nRegards,\n\nHugo\n\n  55. http://www.w3.org/TR/2003/PR-soap12-part1-20030507/#soapfeature\n  56. http://www.w3.org/TR/2003/PR-soap12-part2-20030507/#soapfeatspec\n-- \nHugo Haas - W3C\nmailto:hugo@w3.org - http://www.w3.org/People/Hugo/\n\n\n\n", "id": "lists-017-4314289"}, {"subject": "UA: layered notices focus group summar", "content": "Mel Peterson from P&G prepared this summary of the focus groups the \nlayered/highlights notices effort did last year. Some of their findings \nare relevant to our translation effort -- most notably, people don't \nlike the word \"data.\"\n\nLorrie\n\n\n\nLayered Notices Focus Groups\nFebruary 2002\n\nSummary of Results\n\nNotices\n? All three groups like the idea of short notices, and disliked the \nnotices they received as a result of GLB.\n? In general, long notices are generally ignored or pitched.  They \nreduce trust because people assume companies are trying to hide \nimportant information that they don?t want the consumer to find.\n? ?Uses?, especially information sharing practices, was the most \nimportant information.  People wanted to know if their information \nwould be sold or shared in a way that lead to them getting a lot of \nother marketing they do not want.\n? Other categories on the short notice were less important than ?uses?, \nbut all were still important.  The six categories used by templates we \ntested seemed to cover all information people were most interested in.  \nWe did not identify additional categories that need to be added.\n? All three groups strongly prefer that short notices share the same \ntemplate across all industries.\n? Some participants indicated use of short notices would facilitate \ncomparing information practices between companies.\n? At this stage people need more explanation / sentences in a template. \n  A shorter check-list template was not clear enough, but participants \nindicated that down the road they might be able to use a shorter \ncheck-list template once they have been educated.\n\nCategories & Words\n? Participants expected that the words used within the boxes may be \ndifferent, since they believe companies have differences in how they \ncollect and use information.  But to the extent consistent wording can \nbe used, that will make the notices even easier to use and understand.\n? Legal words arouse suspicion and mistrust.  ?When I read legal words \nI think you?re trying to trick me, to deceive me.?  For example, \n?policy? sounds legal, ?statement? is better.\n? Phrases like ?we respect your privacy? and ?privacy promise? led to \nderision ? ?I bet Enron had a great privacy policy?.\n? The word ?data? is not consumer friendly.  ?Data is what my child \ngraphs in school.?  ?Personal Information? was better than ?data?.\n? There was not a strong consensus among the three groups for the \n?choice? box.  ?Options?, ?Choice?, ?Preferences? were all considered \nby participants, the groups differed on which they thought was best.\n? ?Scope? was not a meaningful descriptor of the box telling people \nabout the company whose practices are described in the notice.\n? ?Other Information? does not work.  It sound like ?unimportant \ndetails? and will be ignored.  ?Important information? is better.\n? A few people expressed appreciation for data access when it was \nincluded in the template (in the ?Other Information? box) but no one \nsuggested it needed to have its own category.\n? One focus group talked a lot about third parties they could go to for \naccountability.  ?UL approved? was attractive, but recognition of seal \nprograms was limited.\n? People had trouble with one-word descriptions of categories on the \ntemplate, but once the category was explained to them the word used to \ndescribe the category becomes less important.\n\nTemplate\n? Presenting the information in a template, with boxes to organize the \ninformation, is better than presenting the information in text form.\n? Keeping the same template for all companies/organizations is highly \ndesirable.  It makes it easier for people to find the information they \nare looking for, and to compare practices when they want to.\n? ?Contact Information? should be located in the lower right hand \ncorner or at the end of the template.\n? People would like to have ?how-to? information along with any choices \nthey have, e.g. ?to be removed from this program call 1-800-765-4321?.\n\nOther\n? Most people do not understand how data is used.  They have no clue \nhow information creates value for them.  Some people have a limited \nunderstanding of targeting.  Data modeling is not understood.  Short \nnotices for marketing are likely to generate ?I never knew that was \ngoing on? responses.\n? Most participants like and use catalogs, but would cancel some of the \nvolume they currently get.  Volume of solicitations was the issue.\n\n\n\n", "id": "lists-017-4334599"}, {"subject": "Re: [BH] Application Patterns and SOAP (Was: First (Very Rought)  Outline of Beyond HTTP", "content": "On Wednesday 28 May 2003 11:56, Patrick.Hung@csiro.au wrote:\n> > The scenario I have in my mind is that SOAP is being used in an\n> > \"end-to-end\"\n> > model with an explicit understanding that various intermediaries will\n> > be relevant. Te request/response is e2e between the user agent and\n> > service\n>\n> I have a bit concern about your statement \"with an explicit understanding\n> that various intermediaries will be relevant.\" Do you mean that both SOAP\n> sender and receiver realize that there exist some intermediaries but both\n> SOAP sender and receiver do not have explicit knowledge of who and \n> where the intermediaries are on the Web?\n\nI'm not willing to state the opposite: that, absent a mechanism for \nend-to-end security, a SOAP sender and receiver will be the only SOAP \nparties to see a message. \"SOAP does not specify how such a message path is \ndetermined and followed.\" [1] In example 16 [2], a SOAP intermediary \nchanged the message in a way that the sender did not necessarily know \nabout.\n\n[1] http://www.w3.org/TR/2002/CR-soap12-part0-20021219/\n[2] http://www.w3.org/TR/2002/CR-soap12-part0-20021219/#Example6\n\n> > (1) Should we also have to mention the privacy issues of audit trail\n> > (e.g., log files)\n> > at each Web service? We assume that all Web services are all seating\n> > with the Web server\n> > and so.\n> >\n> > How do you mean? The intermediaries?\n>\n> Yes, I mean the intermediaries. It is because there is no such serious\n> concern at the SOAP sender side and also the ultimate receiver \n> should respect its own privacy policy (or I can name it as the \n> SOAP receiver's promise to the sender).\n\nI'm still not sure I understand. We've already documented the question of \n(transparent) intermediaries (one can include a mandatory header of \npolicies they must respect or use e2e security). If your question is that \npeople typically only associate a P3P policy with an HTTP server's log, and \nthere might be other logs that are relevant, I'm not sure. I think the \ngoverning section of P3P is \"2.3.3 Applying a Policy to a URI\". It has a \nbunch of examples, and we *could* include our own, but the basis is still \nabout a method (GET, POST) on a URI, which is still perfectly applies to \nour scenarioius...?\n\n> For the UDDI, here are my suggestions (very rought and have to check the\n> syntax\n> carefully) to put privacy policies at two levels: ...Anyway, we can \n> forget this point in this task force working draft.\n\nOK, that's good to have in the back pocket \n\n> Should we also have a function to keep track of the changes in privacy\n> policies?\n\nYou mean in the UDDI context specifically, or the in general. I don't see an \nimmediate need for this, I presume policies are deprecated by simply \nremoving an old policy from the dereferencing URI and replacing it with the \nnew one...?\n\n\n\n", "id": "lists-017-4345628"}, {"subject": "RE: [BH] Application Patterns and SOAP (Was: First (Very Rought)   Outline of Beyond HTTP", "content": "> > > (1) Should we also have to mention the privacy issues of audit trail\n> > > (e.g., log files)\n> > > at each Web service? We assume that all Web services are all seating\n> > > with the Web server\n> > > and so.\n> > >\n> > > How do you mean? The intermediaries?\n> >\n> > Yes, I mean the intermediaries. It is because there is no such serious\n> > concern at the SOAP sender side and also the ultimate receiver \n> > should respect its own privacy policy (or I can name it as the \n> > SOAP receiver's promise to the sender).\n> \n> I'm still not sure I understand. We've already documented the question of \n> (transparent) intermediaries (one can include a mandatory header of \n> policies they must respect or use e2e security). If your question is that \n> people typically only associate a P3P policy with an HTTP server's log,\nand \n> there might be other logs that are relevant, I'm not sure. I think the\n\nYes, there are some other logs beside the HTTP server's log such as the \napplication can also keep its logs, e.g., ASP.NET.\n\n> governing section of P3P is \"2.3.3 Applying a Policy to a URI\". It has a \n> bunch of examples, and we *could* include our own, but the basis is still \n> about a method (GET, POST) on a URI, which is still perfectly applies to \n> our scenarioius...?\n\nYes, it is fine.\n\n> > Should we also have a function to keep track of the changes in privacy\n> > policies?\n>\n> You mean in the UDDI context specifically, or the in general. I don't see\nan \n> immediate need for this, I presume policies are deprecated by simply \n> removing an old policy from the dereferencing URI and replacing it with\nthe \n> new one...?\n\nI mean in general. I just wonder whether there is any practice for privacy\npolicies\nmangement? If an organizaiton changes its privacy policy, what's happened if\nthere\nis conflicts between old and new one? Can the data's subject has the right\nto ask\nfor remedies? Do we also have to cature these issues in P3P? Maybe these\nissues are\nnot relevant to this document; they are more on the management side or even\nstrongly\nrelate to legal aspects. Just some thoughts.\n\nIn the coming few days, I will check the document and see whether we miss\nany important\npoints.\n\nThanks and talk to you later.\n\nPatrick.\n\n\n\n", "id": "lists-017-4356250"}, {"subject": "Re: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "On Monday 02 June 2003 14:34, Hugo Haas wrote:\n> Please find below some comments regarding:\n\nThanks for the comments Hugo!\n\n> |    [37]Adopting applications that rely upon a data format other than\n> |    [XHTML] to solicit information SHOULD support the first (well known\n> |    location) and fourth (HTTP header) mechanisms; [38]adopting\n> |    applications MUST NOT ever (mistakenly) release information to an\n> |    application it is not familiar with on the basis of [P3P] mechanisms\n> |    that it is familiar with. [39]Adopting applications MAY provide a\n> |    means of associating a policy reference file with their own format.\n>\n> I think that for Web services, the policy (or the link to a policy\n> reference file) should be expressed as a feature. Features are the\n> extensibility mechanism of SOAP 1.2[55]. The Web Services Description\n> WG is working on their description and the Web Services Architecture\n> WG is evaluating their role in the overall architecture.\n\nHow is this done? I've read [55] and it's written in the abstract, and I've \nalso looked at [56], but I'm not sure how to apply it. (Also, while we've \nbeen exploring various options, we also having been avoiding the \"exotic\" \nfeatures unless there some cause to demonstrate them.) \n\n> Feature is basically a functionality which can be expressed in\n> different ways. In this case, the policy / policy reference would be\n> carried by the SOAP message:\n> - inside the envelope.\n\nWe've mocked up a header by which a sender can \"ask\" all intermediary nodes \nto also understand the privacy policies of the carried application data:\n\n<env:Header \n  xmlns='http://registry.example.com/2003/soap-header-p3p-extension.xsd' \n  xmlns:env='http://www.w3.org/2003/05/soap-envelope' >\n  <Privacy env:role='http://www.w3.org/2003/05/soap-envelope/role/next'\n    env:mustUnderstand='true'>\n    <rel>P3Pv1</rel>\n    <href>http://registry.example.com/P3P/PolicyReferences.xml</href>\n  </Privacy>\n</env:Header>\n\nBut what does one have to do to represent it as a \"feature\"? Also, since we \nare not an application ourselves (but expect P3P to be used by \"adopting \napplications\") we presently can't limit this to any particular MEP. I'd \nexpect such a header would be orthogonal to other MEPs and \"features\".\n\n> Registries would most likely refer to the service description and you\n> would get that information for free.\n\nSo, for example, a UDDI registry would probably know how to pull information \nfor its own puproses and translate it into UDDI syntax?\n\n> |    [49]Adopting applications MUST specify where relevant [P3P]\n> | statements can be found. We RECOMMEND that normative association (not\n> | including [WSDL] or [UDDI]) be limited to the higher/application layer.\n> | We RECOMMEND that a higher/abstract layer MAY include the privacy\n> | policy of layers it is dependent upon, but that lower layers SHOULD NOT\n> | represent the policies of higher layers. For example, an application\n> | that transfers data with SOAP over HTTP that uses cookies, SHOULD\n> | specify:\n> |     1. the [P3P] policy associated with SOAP is normative and includes\n> |        the HTTP policy, or\n> |     2. there are distinct [P3P] policies associated with the SOAP and\n> |        HTTP layers.\n>\n> Isn't this already the case with a Web server nowadays? The HTTP\n> stack/server may have some logging policies different from the ones a\n> CGI has, for example.\n\nThere's nothing terribly novel in this case. But in your example, we didn't \nhave the HTTP and the CGI presenting you with different policies. The \npolicy associated with the HTTP was good for your interactions with the \nspecified URI (e.g., the CGI). In SOAP, the recipient of the *transport* \nlayer (the SMTP recipient or HTTP server the POST is sent to) might be \ndifferent the the SOAP ultimateReceiver, right? Which brings me to the \nquestion, in SOAP, how do you identify the \"ultimateReceiver\"? What URI \nshould the PolicyRef file refer to, the URI of its immediate transport \ncounterpart (I don't think so), or the \"ultimateReceiver\" -- if you can \nidentify that?\n\n> There is something else which probably needs to be underlined. P3P\n> reference policies for resources, whatever the operation on them is.\n>\n> With Web services, what the resource is is a little fuzzy (a car? the\n> application in charge of selling cars? some state about the sale of a\n> car?) and WSDL defines the interface to this target resource. The\n> level of granularity here is probably the WSDL operation.\n\nI think this relates to my question above, and Patrick has explored this a \nbit. In our example, we associated it with the definition (my:Privacy is a \nchild of the wsdl:definitions), are you recommending it be a child of the \nwsdl:operation element?\n  http://www.w3.org/P3P/2003/p3p-beyond-http/wsdl-eg.xml\n\n\n\n", "id": "lists-017-4366325"}, {"subject": "AGENDA: P3P spec call June 1", "content": "The next P3P specification group conference call will be on\nWednesday, June 11, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit and Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n\n2. Discuss user agent guidelines draft -- is working group happy with\n    this draft? Should it be added as a part of the P3P1.1 spec? As an\n    appendix?\n    http://www.w3.org/P3P/2003/ua-guidelines.html\n\n\n3. Discuss bugzilla 215 - compact policy processing by user agents\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=215\nProposal to add the following section:\n\n4.7 Compact Policy Processing by User Agents\n\nP3P user agents SHOULD NOT rely on P3P compact policies that do not\ncomply with the P3P 1.1 specification or are obviously erroneous. Such\ncompact policies SHOULD be deemed invalid and the corresponding\ncookies treated as if they had no compact policies.\n\n\n4. Discuss Consent Choices working draft -- do we want to pursue this\n    in P3P 1.1 or postpone to P3P 2.0?\n    http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n    This is also related to Bugzilla 169\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=169\n\n\n5. Discuss bugzilla 170\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=170\nConsider expanding definition of CONSEQUENCE field to reflect how it\nis actually being used -- in particular to express summary of\nSTATEMENT as well as value proposition. Alternatively, consider adding\nactual structure to CONSEQUENCE element to seperate out summary from\nvalue proposition.\n\nBased on discussion on last call I propose the following new definition:\n\nA short summary (not to exceed 500 characters) of the data practices\ndescribed in the statement that can be shown to a human user.\n\n[Note that we do not plan on changing the P3P data schema to reflect\nthe 500 character limit, however, user agents would be advised to\ndisplay no more than 500 characters.  We can also discuss whether 500\ncharacters is the right limit or whether it should be more or less.]\n\n\n6. Discuss bugzilla 168\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=168\n\nConsider adding human-readable explanation strings to all elements\nthat don't have them\n- could be done for a specific set of elements or generically\n- it appears that the way the extension mechanism is defined in the\nP3P schema we cannot add such elements in arbitrary places -- for\nexample, I think we can add them to high-level elements such as\nPURPOSE but not as sub-elements of individual PURPOSE elements\n\nIt would be helpful if people could identify elements where they\nwould like to see human-readable strings prior to our call.\n\n\n7. Set date for next call (June 25?)\n\n\n\n", "id": "lists-017-4379309"}, {"subject": "Re: AGENDA: P3P spec call June 1", "content": "> 6. Discuss bugzilla 168\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=168\n> \n> Consider adding human-readable explanation strings to all elements\n> that don't have them\n> - could be done for a specific set of elements or generically\n> - it appears that the way the extension mechanism is defined in the\n> P3P schema we cannot add such elements in arbitrary places -- for\n> example, I think we can add them to high-level elements such as\n> PURPOSE but not as sub-elements of individual PURPOSE elements\n\nThis problem arose in a different, but related context. There was a late\nproposal to add a binary toggle to arbitrary portions of the EPP schema,\nand one element of that schema is defined as:\n\nIn eppcom-1.0.xsd this type definition exists:\n\n<!--\nNon-empty token type.\n-->\n  <simpleType name=\"minTokenType\">\n      <restriction base=\"token\">\n <minLength value=\"1\"/>\n      </restriction>\n  </simpleType>\n\nThis was used to define the type of the element \"email\". I never saw a way\nto extend such a type declaration.\n\nIn general, if one doesn't require what I think of as a \"glue layer\" between\nwhat I think of as \"application interfaces\" and \"system interfaces\", there is\na possibility for subsequent awkwardness -- my years writing UNIX APIs is\nshowing.\n\nStuffing the extension \"outside\" of the element, as you've suggested on the\nPURPOSE element (but not its arbitrary sub-elements), works.\n\nSorry I missed the last call.\nEric\n\n\n\n", "id": "lists-017-4389834"}, {"subject": "P3P/EPAL Workshop Position papers publishe", "content": "Dear all, \n\nas announced some time ago, W3C is organizing a W3C Workshop on the long\nterm Future of P3P and Enterprise Privacy Languages[1] together with the \nIndependent Centre for Privacy Protection Schleswig-Holstein[2].  \n\nThe position papers are now published[3] and the program committee will now\nchoose the ones that will be presented at the Workshop. \n\nRegistration is still open.\n\n  1. http://www.w3.org/2003/p3p-ws/\n  2. http://www.datenschutzzentrum.de/\n  3. http://www.w3.org/2003/p3p-ws/pp/Overview.html\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-4398640"}, {"subject": "UA: next UA TF call 12 June, 11 a", "content": "The next User agent task force call will be on Thursday, June 12 at 11 \nam US Eastern. We will use our usual dial-in number (see \nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html)\n\nAGENDA\n\nDiscussion of user agent guidelines (and results of full WG discussion \non June 11) http://www.w3.org/P3P/2003/ua-guidelines.html\n\nDiscussion of proposed translation -- we will focus on any feedback \nreceived by June 10 (PLEASE SEND YOUR FEEDBACK BY JUNE 10!) as well as \nthe remaining areas of disagreement between Lorrie's proposal and \nJeremy's proposal http://www.w3.org/P3P/2003/p3p-translation.htm  -- \nThese areas are:\n\n- the access heading and the various access fields\n- the entity heading\n- the categories heading\n- pseudo-analysis\n- pseudo-decision\n- individual-analysis\n- individual-decision\n- computer\n- state\n\n\n\n", "id": "lists-017-4406864"}, {"subject": "RE: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "Hi Joseph and Hugo,\n\n> > |    [37]Adopting applications that rely upon a data format other than\n> > |    [XHTML] to solicit information SHOULD support the first (well known\n> > |    location) and fourth (HTTP header) mechanisms; [38]adopting\n> > |    applications MUST NOT ever (mistakenly) release information to an\n> > |    application it is not familiar with on the basis of [P3P]\nmechanisms\n> > |    that it is familiar with. [39]Adopting applications MAY provide a\n> > |    means of associating a policy reference file with their own format.\n> >\n> > I think that for Web services, the policy (or the link to a policy\n> > reference file) should be expressed as a feature. Features are the\n> > extensibility mechanism of SOAP 1.2[55]. The Web Services Description\n> > WG is working on their description and the Web Services Architecture\n> > WG is evaluating their role in the overall architecture.\n>\n> How is this done? I've read [55] and it's written in the abstract, and\nI've \n> also looked at [56], but I'm not sure how to apply it. (Also, while we've \n> been exploring various options, we also having been avoiding the \"exotic\" \n> features unless there some cause to demonstrate them.) \n\nI also checked [55] and [56]. Based on my understanding, if we can describe\nthe proposed privacy assertions for SOAP messages in the context of MEP and\nalso\ndescribe the proposed privacy assertions' properties in the context of SOAP \nProcessing Model and the SOAP Protocol Binding Framework. Then, the proposed\n\nprivacy assertions can become a \"feature\" or I should say a new \"feature\" in\n\nthe SOAP framework. From the other aspect, we also have to define the \nevent-condition-rules for the proposed privacy scenrio in the context of\nMEP.\nIs my interpretation correct? \n\nAny illustrative example? Or is there any standard graphical representation\nto \ndepict MEP such as Petri-Net? It sounds that this topic is very interesting.\n\n> > Feature is basically a functionality which can be expressed in\n> > different ways. In this case, the policy / policy reference would be\n> > carried by the SOAP message:\n> > - inside the envelope.\n>\n> We've mocked up a header by which a sender can \"ask\" all intermediary\nnodes \n> to also understand the privacy policies of the carried application data:\n> \n> <env:Header \n>   xmlns='http://registry.example.com/2003/soap-header-p3p-extension.xsd' \n>  xmlns:env='http://www.w3.org/2003/05/soap-envelope' >\n>  <Privacy env:role='http://www.w3.org/2003/05/soap-envelope/role/next'\n>    env:mustUnderstand='true'>\n>    <rel>P3Pv1</rel>\n>    <href>http://registry.example.com/P3P/PolicyReferences.xml</href>\n>  </Privacy>\n> </env:Header>\n>\n> But what does one have to do to represent it as a \"feature\"? Also, since\nwe \n> are not an application ourselves (but expect P3P to be used by \"adopting \n> applications\") we presently can't limit this to any particular MEP. I'd \n> expect such a header would be orthogonal to other MEPs and \"features\".\n\nDoes Hugo mean that we should have a generic MEP for the proposed privacy\nassertions in SOAP messages? Not tie up with any domain specific\napplication.\n\n> > Registries would most likely refer to the service description and you\n> > would get that information for free.\n>\n> So, for example, a UDDI registry would probably know how to pull\ninformation \n> for its own puproses and translate it into UDDI syntax?\n\nYes, we should have this assumption and I do believe some related research \nshould have been done (though I haven't checked it). :-)\nHowever, you can only see those unautomatic UDDI at\nhttp://www-3.ibm.com/services/uddi/\nor http://uddi.microsoft.com\n\n> > |    [49]Adopting applications MUST specify where relevant [P3P]\n> > | statements can be found. We RECOMMEND that normative association (not\n> > | including [WSDL] or [UDDI]) be limited to the higher/application\nlayer.\n> > | We RECOMMEND that a higher/abstract layer MAY include the privacy\n> > | policy of layers it is dependent upon, but that lower layers SHOULD\nNOT\n> > | represent the policies of higher layers. For example, an application\n> > | that transfers data with SOAP over HTTP that uses cookies, SHOULD\n> > | specify:\n> > |     1. the [P3P] policy associated with SOAP is normative and includes\n> > |        the HTTP policy, or\n> > |     2. there are distinct [P3P] policies associated with the SOAP and\n> > |        HTTP layers.\n> >\n> > Isn't this already the case with a Web server nowadays? The HTTP\n> > stack/server may have some logging policies different from the ones a\n> > CGI has, for example.\n>\n> There's nothing terribly novel in this case. But in your example, we\ndidn't \n> have the HTTP and the CGI presenting you with different policies. The \n> policy associated with the HTTP was good for your interactions with the \n> specified URI (e.g., the CGI). In SOAP, the recipient of the *transport* \n> layer (the SMTP recipient or HTTP server the POST is sent to) might be \n> different the the SOAP ultimateReceiver, right? Which brings me to the \n> question, in SOAP, how do you identify the \"ultimateReceiver\"? What URI \n> should the PolicyRef file refer to, the URI of its immediate transport \n> counterpart (I don't think so), or the \"ultimateReceiver\" -- if you can \n> identify that?\n\nI would believe that the URI should be the URI of the ultimateReceiver's\nprivacy policy. For those intermediaries, that's why we may have to define\nsome new roles or \"features\" for them.\n\n> > There is something else which probably needs to be underlined. P3P\n> > reference policies for resources, whatever the operation on them is.\n> >\n> > With Web services, what the resource is is a little fuzzy (a car? the\n> > application in charge of selling cars? some state about the sale of a\n> > car?) and WSDL defines the interface to this target resource. The\n> > level of granularity here is probably the WSDL operation.\n>\n> I think this relates to my question above, and Patrick has explored this a\n\n> bit. In our example, we associated it with the definition (my:Privacy is a\n\n> child of the wsdl:definitions), are you recommending it be a child of the \n> wsdl:operation element?\n> http://www.w3.org/P3P/2003/p3p-beyond-http/wsdl-eg.xml\n\nI would believe that we may have to provide two levels (service and\noperation)\nfor optional privacy policies. The operation level's privacy policy can\noverwhelm \nthe service level's once there exist any contradiction? In the normal case,\nthe privacy policy should be the union of both for each operaiton? If there\nis no operation level so that it is inherited from the servce level.\n\nHowever, this may cause more thoughts about UDDI as UDDI has three levels:\nBusiness Entity, Business Service and tModel.\n\nLastly, just a very little typo found at\nhttp://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html:\n\"Our scenario is not intended to be a completely accurate \nrepresentation of real world requirements, nor does our \ndocument necessarily provide a satisfactory solution. \nInstead, this scenario is intended to be sufficiently \nrepresenative ...\"\n^^^^^^^^^^^^^\n\nTalk to you later. Have a nice weekend!\n\nPatrick.\n\n\n\n", "id": "lists-017-4414376"}, {"subject": "UA: next UA TF call 12 June, 11 a", "content": "Hi-\n\nI just wanted to briefly introduce myself to the other P3P 1.1 Specification WG\nmembers.  I will be representing American Express on the WG, with particular\ninterest in the User Agent Behavior and Compact Policies task forces.  As luck\nwould have it, I'm unavailable for tomorrow's WG call, but I would like to\nattend the UA TF call on Thursday.\n\nRegards,\n\nJeff Edelen\nAmerican Express\n\n---------------------- Forwarded by Jeffrey A Edelen/AMER/TRS/AEXP on\n06/10/2003 08:42 PM ---------------------------\n\nFrom:  \"Lorrie Cranor\" <lorrie@research.att.com>@w3.org on 06/04/2003 04:00 PM\n       AST\n\nSent by:    public-p3p-spec-request@w3.org\n\n\nTo:    public-p3p-spec@w3.org\ncc:\nSubject:    UA: next UA TF call 12 June, 11 am\n\n\n\nThe next User agent task force call will be on Thursday, June 12 at 11\nam US Eastern. We will use our usual dial-in number (see\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html)\n\nAGENDA\n\nDiscussion of user agent guidelines (and results of full WG discussion\non June 11) http://www.w3.org/P3P/2003/ua-guidelines.html\n\nDiscussion of proposed translation -- we will focus on any feedback\nreceived by June 10 (PLEASE SEND YOUR FEEDBACK BY JUNE 10!) as well as\nthe remaining areas of disagreement between Lorrie's proposal and\nJeremy's proposal http://www.w3.org/P3P/2003/p3p-translation.htm  --\nThese areas are:\n\n- the access heading and the various access fields\n- the entity heading\n- the categories heading\n- pseudo-analysis\n- pseudo-decision\n- individual-analysis\n- individual-decision\n- computer\n- state\n\n\n\n\n\n\nAmerican Express made the following\n annotations on 06/10/2003 08:53:53 PM\n------------------------------------------------------------------------------\n******************************************************************************\n\n     \"This message and any attachments are solely for the intended recipient and may contain confidential or privileged information. If you are not the intended recipient, any disclosure, copying, use, or distribution of the information included in this message and any attachments is prohibited.  If you have received this communication in error, please notify us by reply e-mail and immediately and permanently delete this message and any attachments.  Thank you.\"\n\n******************************************************************************\n\n\n==============================================================================\n\n\n\n", "id": "lists-017-4430665"}, {"subject": "Intro Robert Hor", "content": "I'm Robert Horn and will be representing Agfa on P3P.  This email might\narrive in time for today's conference call.  I have been very active in the\nsecurity and privacy area for healthcare, especially hospital operations.\nI represent Agfa on:\n   the Joint NEMA/Cocir/JIRA Security and Privacy Committee,\nhttp://www.nema.org/index_nema.cfm/1590/\n  several DICOM standards committees (especially WG-6, Base Standard),\nhttp://medical.nema.org\n  the Infrastructure and Radiology Technical committees of Integrating the\nHealthcare Enterprise (IHE), http://www.rsna.org/IHE/index.shtml\n\nI edited the interim security audit trail draft for IHE last year, and we\nare now working on a replacement international standard for privacy and\nsecurity audit trails with the IETF, DICOM, HL7, and ASTM standards groups.\nCurrent IHE Infrastructure activity has begun work on healthcare staff\nidentity management.\n\nThe P3P will be important as we extend beyond the internal operations to\ninclude inter-enterprise communications and direct patient communications .\n\nRobert Horn\n\n+1.978.897.4860 (voice)\nrobert.horn.b@us.agfa.com\n\n\n\n", "id": "lists-017-4440982"}, {"subject": "Re: [BH] Application Patterns and SOAP (Was: First (Very Rought)  Outline of Beyond HTTP", "content": "On Thu, May 29, 2003 at 01:56:57AM +1000, Patrick.Hung@csiro.au wrote:\n> For the UDDI, here are my suggestions (very rought and have to check\n> the syntax carefully) to put privacy policies at two levels:\n> \n> (1) \"businessEntity: Describes a business or other organization that\n> typically \n>     provides Web services.\" [1] For example:\n> \n> <businessDetail generic=\"2.0\" operator=\"Microsoft UDDI Services\"\n> truncated=\"false\" xmlns=\"urn:uddi-org:api_v2\">\n> <businessEntity businessKey=\"186a3421-0c20-45d1-b81d-efb9f61b0b15\"\n> operator=\"sample\" authorizedName=\"sample\">\n> <discoveryURLs>\n> <discoveryURL useType=\"businessEntity\">\n> http://uddi.example.com/uddipublic/discovery.ashx?businessKey=186a3421-0c20-\n> 45d1-b81d-efb9f61b0b15\n> </discoveryURL>\n> </discoveryURLs>\n> <Privacy href='http://registry.example.com/P3P/PolicyReferences.xml'\n> rel='P3Pv1'/>\n\nThis doesn't work without changing the semantics of the\nPolicyReferenceFile. The PolRef can only point to relative URI's. So the\nissue here is that this PolRef could only state on registry.example.com\nand NOT on uddi.example.com..\n\nI'm much more sympathetic to the approach to define something in WSDL\n1.2 as there, the properties of a service are defined..\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-4448832"}, {"subject": "UA: MINUTES: 12 June 2003 UA TF cal", "content": "12 June 2003 User Agent Task Force Call\n\nParticipants\nLorrie Cranor\nGiles Hogben\nBrooks Dobbs\nRigo Wenning\nDave Stampley\nAri Schwartz\n\nThe full WG discussed the user agent guidelines document \nhttp://www.w3.org/P3P/2003/ua-guidelines.html on their call yesterday \nand decided it should be part of the P3P 1.1 spec. Lorrie proposes to \ninclude it as section 6 and will edit it accordingly. Rigo is concerned \nthat the the user agent guidelines should make it clear that the plain \nEnglish translations are not a substitute for the normative \ndefinitions. Rigo will check the language currently in the document and \npropose changes if he finds it inadequate.\n\nWe began discussion of the 2 June translation matrix and discussed the \nENTITY and ACCESS elements and some high-level issues, as follows.\n\nWe have a preference for headings that do not appear in the form of a \nquestion.\n\nWe have a preference for referring to the user as \"you\" rather than \"I\" \nor \"me\".\n\nWe don't like the use of the phrase \"this site\" throughout. Here are \nsome options (no consensus was reached on which to adopt): (a) \"this \nprovider\" - but may be confused with ISP  (b) \"this entity\" - but \npeople aren't going to know what that means (c) use passive voice and \navoid phrase - passive voice is wishy washy (d) \"we\" - there may be \nconfusion about who we refers to? (e)  insert name from entity element \n- could be legnthy (f) use \"we\" with a hyperlink to where the entity \nname is displayed\n\nENTITY element: The group did not like either Lorrie's or Jeremy's \nproposal because they talk about contacting the site, which is not \nreally what ENTITY is about according to the normative definition. The \nconsensus was to use the phrase \"This policy is issued by\" instead.\n\nWe had a discussion about whether a site should be able to have more \nthan one ENTITY element. The current P3P syntax does not prohibit sites \nfrom declaring multiple duplicate entity fields, and effectively having \nmultiple entity elements. However, there is no grouping mechanism, so \nuser agents do not know how to display this information. W3C is an \nexample of a site that is declaring multiple entity fields (we haven't \nseen others). We may want to recommend to the full WG that we (a) \nprohibit multiple ENTITY elements, or (b) add some sort of grouping \nmechanism and/or advice user agents what to do if a site has multiple \nENTITY elements. Technically, it is probably easier to prohibit this. \nSome task force members also felt it was confusing to users to see \nmultiple entities and that one entity should be designated to be \nlisted. Rigo was concerned that in the case of a consortium or joint \nventure, multiple entities might be equally responsible. Dave said that \nthe entity element doesn't indicate responsibility, only who the \nspeaker is, and that it is common for joint ventures to designate a \nsingle entity as spokesperson. Rigo also said it would be convenient \nfor users to see contact information in multiple countries so they \ncould pick the phone number to call where they were likely to get \nsomeone who speaks their language. But others pointed out that ENTITY \nis not supposed to be used as a way for consumers to contact a company \n-- just a way to identify who the company is. The disputes element is \nused for contacting, and it allows multiple addresses to be listed. We \nneed to discuss further. Lorrie has opened this on bugzilla as issue \n224.\n\nACCESS element: The group did not like Jeremy's phrasing this in the \nform of a question or using \"I\" but they liked the fact that it made it \nclear that the information was about the user. The consensus was to use \nthe phrase \"Your access to information about you\" instead.\n\nLorrie will post revised versions of the matrix and guidelines document \nshortly. Please review and provide feedback on the mailing list. \nDiscussions of the other points we didn't resolve on the call today \nshould also continue on the mailing list.\n\nOur next call will be on Monday, June 23 at 11 am US Eastern.\n\n\n\n", "id": "lists-017-4457402"}, {"subject": "The Minutes of Conference Call on 11 June 2003 will be sent later ", "content": "Apologize for the late response. Recently tight up with some tasks.\nWill send the minutes on coming Monday.\n\nPatrick.\n--------------------------------------\nPatrick C. K. Hung\nResearch Scientist, Security and Privacy Group\nCommonwealth Scientific & Industrial Research Organisation (CSIRO)\nCSIRO Mathematical and Information Sciences (CMIS)\nGPO Box 664, Canberra, ACT 2601, Australia\nPh: +612 6216 7031, Fax: +612 6216 7111\nEmail: Patrick.Hung@csiro.au\nURL: www.cmis.csiro.au/Patrick.Hung\n\n\n\n", "id": "lists-017-4468235"}, {"subject": "Re: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "Hi Joseph and Patrick.\n\n* Joseph Reagle <reagle@w3.org> [2003-06-03 17:29-0400]\n> > |    [37]Adopting applications that rely upon a data format other than\n> > |    [XHTML] to solicit information SHOULD support the first (well known\n> > |    location) and fourth (HTTP header) mechanisms; [38]adopting\n> > |    applications MUST NOT ever (mistakenly) release information to an\n> > |    application it is not familiar with on the basis of [P3P] mechanisms\n> > |    that it is familiar with. [39]Adopting applications MAY provide a\n> > |    means of associating a policy reference file with their own format.\n> >\n> > I think that for Web services, the policy (or the link to a policy\n> > reference file) should be expressed as a feature. Features are the\n> > extensibility mechanism of SOAP 1.2[55]. The Web Services Description\n> > WG is working on their description and the Web Services Architecture\n> > WG is evaluating their role in the overall architecture.\n> \n> How is this done? I've read [55] and it's written in the abstract, and I've \n> also looked at [56], but I'm not sure how to apply it. (Also, while we've \n> been exploring various options, we also having been avoiding the \"exotic\" \n> features unless there some cause to demonstrate them.) \n> \n> > Feature is basically a functionality which can be expressed in\n> > different ways. In this case, the policy / policy reference would be\n> > carried by the SOAP message:\n> > - inside the envelope.\n> \n> We've mocked up a header by which a sender can \"ask\" all intermediary nodes \n> to also understand the privacy policies of the carried application data:\n> \n> <env:Header \n>   xmlns='http://registry.example.com/2003/soap-header-p3p-extension.xsd' \n>   xmlns:env='http://www.w3.org/2003/05/soap-envelope' >\n>   <Privacy env:role='http://www.w3.org/2003/05/soap-envelope/role/next'\n>     env:mustUnderstand='true'>\n>     <rel>P3Pv1</rel>\n>     <href>http://registry.example.com/P3P/PolicyReferences.xml</href>\n>   </Privacy>\n> </env:Header>\n> \n> But what does one have to do to represent it as a \"feature\"?\n\nLet me try to make this concrete.\n\nWe could define the P3P feature, which indicates the policy for a\nservice.\n\nNote that I am not sure that this is what you would want exactly since\none could imagine:\n- the service pointing out where the policy reference file is for its\n  different interfaces.\n- the requester giving a URI of the agreed upon policy for a request:\n  this probably is useful in a delegation scenario (in your example,\n  the registrar telling the registry what he agreed to) or if one\n  could negotiate a privacy policy (the registrant is proposed 2\n  choices by the registrar: a 10% discount if he agrees to be\n  spammed).\n- a policy reference document instead of a URI.\n- a privacy policy instead of a URI.\n\nSo, anyway, in order to make things concrete, let's try to address the\nsecond case: expressing a URI to a P3P policy document. I think that\nit is more useful than expressing the URI to a policy reference since\na WSDL description would already give a list of policies for each\nservice. Again, this would probably be up for discussion.\n\n--8<----\n\nP3P feature\n\n- Name\n\nhttp://example.org/2003/06/16-p3pf/\n\n- Description\n\nThe P3P feature is used to indicate the P3P policy governing the use\nof a service.\n\n- Properties\n\nThe P3P feature defines a single property:\n\n  Property name:\n\nhttp://example.org/2003/06/16-p3pf/id\n\n  Property type:\n\n  xsd:anyURI\n\nThe value of the http://www.w3.org/2003/06/16-p3pf/id property is the\nidentifier for the P3P policy governing the use of the service.\n\n- Expressing the P3P feature\n\nWhen using the http://www.w3.org/2003/05/soap/bindings/HTTP/ SOAP\nHTTP/1.1 binding, the P3P feature is expressed as an HTTP header as\nfollows:\n\n  P3P: policy=\" URI-Reference \"\n\nIn this case the value of URI-Reference is the value of the\nhttp://example.org/2003/06/16-p3pf/id property.\n\nOther bindings may define alternative ways of expressing the P3P\nReference feature.\n\nIf no alternative way has been defined, the feature and its property\nare expressed in the form of a SOAP header.\n\n[ Insert here the description of a SOAP header in the spirit of the\none you used for a policy reference file. ]\n\n-->8----\n\nDoes it make things clearer?\n\n> Also, since we are not an application ourselves (but expect P3P to\n> be used by \"adopting applications\") we presently can't limit this to\n> any particular MEP. I'd expect such a header would be orthogonal to\n> other MEPs and \"features\".\n\nI think so.\n\n> > Registries would most likely refer to the service description and you\n> > would get that information for free.\n> \n> So, for example, a UDDI registry would probably know how to pull information \n> for its own puproses and translate it into UDDI syntax?\n\nWell, I don't think that UDDI knows about features.\n\nLet's take the P3P feature again.\n\nA WSDL 1.2 description of a service with such a feature could be (this\nmay be slightly inaccurate, but you will get the idea):\n\n  <feature\n     uri='http://example.org/2003/06/16-p3pf/'>\n  <property\n     uri='http://example.org/2003/06/16-p3pf/id'>\n    <value>http://registry.example.com/P3P/Policy.xml</value>\n  </property>\n  </feature>\n\nWith such a generic feature & property mechanism, a registry would be\nable to express that the service has the following features, and if\nyour implementation knows what the P3P feature is, it will be able to\nmake good use of it.\n\n[..]\n> > There is something else which probably needs to be underlined. P3P\n> > reference policies for resources, whatever the operation on them is.\n> >\n> > With Web services, what the resource is is a little fuzzy (a car? the\n> > application in charge of selling cars? some state about the sale of a\n> > car?) and WSDL defines the interface to this target resource. The\n> > level of granularity here is probably the WSDL operation.\n> \n> I think this relates to my question above, and Patrick has explored this a \n> bit. In our example, we associated it with the definition (my:Privacy is a \n> child of the wsdl:definitions), are you recommending it be a child of the \n> wsdl:operation element?\n>   http://www.w3.org/P3P/2003/p3p-beyond-http/wsdl-eg.xml\n\nHmmm... I think that I was confused. I think that a policy reference\nfile is fine as a child of wsdl:definitions, but a reference to a\npolicy file, i.e. a policy which would apply to an operation, would be\nmore specific.\n\nWhich makes me wonder: are policy reference file useful to Web\nservices? With WSDL and something like a P3P feature, wouldn't the\nproblem addressed by policy reference files taken care of?\n\n* Patrick.Hung@csiro.au <Patrick.Hung@csiro.au> [2003-06-07 01:32+1000]\n> > > |    [37]Adopting applications that rely upon a data format other than\n> > > |    [XHTML] to solicit information SHOULD support the first (well known\n> > > |    location) and fourth (HTTP header) mechanisms; [38]adopting\n> > > |    applications MUST NOT ever (mistakenly) release information to an\n> > > |    application it is not familiar with on the basis of [P3P]\n> mechanisms\n> > > |    that it is familiar with. [39]Adopting applications MAY provide a\n> > > |    means of associating a policy reference file with their own format.\n> > >\n> > > I think that for Web services, the policy (or the link to a policy\n> > > reference file) should be expressed as a feature. Features are the\n> > > extensibility mechanism of SOAP 1.2[55]. The Web Services Description\n> > > WG is working on their description and the Web Services Architecture\n> > > WG is evaluating their role in the overall architecture.\n> >\n> > How is this done? I've read [55] and it's written in the abstract, and\n> I've \n> > also looked at [56], but I'm not sure how to apply it. (Also, while we've \n> > been exploring various options, we also having been avoiding the \"exotic\" \n> > features unless there some cause to demonstrate them.) \n> \n> I also checked [55] and [56]. Based on my understanding, if we can describe\n> the proposed privacy assertions for SOAP messages in the context of MEP and\n> also\n> describe the proposed privacy assertions' properties in the context of SOAP \n> Processing Model and the SOAP Protocol Binding Framework. Then, the proposed\n> \n> privacy assertions can become a \"feature\" or I should say a new \"feature\" in\n> \n> the SOAP framework. From the other aspect, we also have to define the \n> event-condition-rules for the proposed privacy scenrio in the context of\n> MEP.\n> Is my interpretation correct? \n> \n> Any illustrative example? Or is there any standard graphical representation\n> to \n> depict MEP such as Petri-Net? It sounds that this topic is very interesting.\n[..]\n\nSee my above example. I must admit that I am a bit fuzzy around the\nrelationship with MEPs.\n\n> > > |    [49]Adopting applications MUST specify where relevant [P3P]\n> > > | statements can be found. We RECOMMEND that normative association (not\n> > > | including [WSDL] or [UDDI]) be limited to the higher/application\n> layer.\n> > > | We RECOMMEND that a higher/abstract layer MAY include the privacy\n> > > | policy of layers it is dependent upon, but that lower layers SHOULD\n> NOT\n> > > | represent the policies of higher layers. For example, an application\n> > > | that transfers data with SOAP over HTTP that uses cookies, SHOULD\n> > > | specify:\n> > > |     1. the [P3P] policy associated with SOAP is normative and includes\n> > > |        the HTTP policy, or\n> > > |     2. there are distinct [P3P] policies associated with the SOAP and\n> > > |        HTTP layers.\n> > >\n> > > Isn't this already the case with a Web server nowadays? The HTTP\n> > > stack/server may have some logging policies different from the ones a\n> > > CGI has, for example.\n> >\n> > There's nothing terribly novel in this case. But in your example, we\n> didn't \n> > have the HTTP and the CGI presenting you with different policies. The \n> > policy associated with the HTTP was good for your interactions with the \n> > specified URI (e.g., the CGI). In SOAP, the recipient of the *transport* \n> > layer (the SMTP recipient or HTTP server the POST is sent to) might be \n> > different the the SOAP ultimateReceiver, right? Which brings me to the \n> > question, in SOAP, how do you identify the \"ultimateReceiver\"? What URI \n> > should the PolicyRef file refer to, the URI of its immediate transport \n> > counterpart (I don't think so), or the \"ultimateReceiver\" -- if you can \n> > identify that?\n> \n> I would believe that the URI should be the URI of the ultimateReceiver's\n> privacy policy. For those intermediaries, that's why we may have to define\n> some new roles or \"features\" for them.\n\nI think that there are different level of abstractions.\n\nA service could be offered through different bindings and therefore\nendpoints. This is why I am wondering whether using references to\nprivacy policies in WSDL documents isn't the most adequate way to do\nthis. The P3P feature I gave an example of wouldn't have this problem,\nI think.\n\nRegards,\n\nHugo\n\n-- \nHugo Haas - W3C\nmailto:hugo@w3.org - http://www.w3.org/People/Hugo/\n\n\n\n", "id": "lists-017-4475984"}, {"subject": "The Minutes of Conference Call on 11 June 2003  Summar", "content": "Minutes 11 June 2003 Spec Group Task Force Call - Summary\n\nParticipants:\n\nLorrie Cranor, AT&T\nJoseph Reagle, W3C\nMatthias Schunter, IBM\nJack Humphrey, CoreMetrics\nDavid Stampley\nBrooks Dobbs, Doubleclick\nGiles Hogben, JRC\nRigo Wenning, W3C\nDanny Weitzner, W3C\nRob Horn from Agfa\nPatrick C. K. Hung, CSIRO\n\n\n1. Task force reports\n\n    - P3P beyond HTTP - Joseph Reagle\n      -> Focusing on the P3P XML Web Services Context.\n      -> Looking forward to hear Hugo's feedbacks about the issues of SOAP\nfeature.\n      -> The draft of P3P Beyond HTTP Task Force Report is being progressed\non \n         schedule. The draft is online:\nhttp://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n      -> The report should be ready by the end of July. \n      -> The report is NOT intended for P3P 1.1 specification.\n      -> Has to discuss with Danny about what can be extracted from the\nreport into P3P 1.1 specification.\n      -> Needs cOmments from other people!\n      -> Have to discuss with Danny.\n\n    - User agent behavior - Lorrie Cranor\n      -> The draft of UA guideline is ready online:\nhttp://www.w3.org/P3P/2003/ua-guidelines.html \n      -> Will have a group discussion on 12 June 2003.\n      -> Need feedbacks/comments from the rest of working group!\n      -> Concern whether the plain English translations are not a substitute\nfor the normative definitions. \n      -> Have to conduct an usability testing on the language.\n\n    - Compact policies - Brian Zwit and Brooks Dobbs\n      -> Nothing special to report.\n\n    - Article 10 vocabulary issues - Giles Hogben\n      -> Working on the proposal to P3P 1.1 WG and plan to be done by July\n2003.\n \n    - Agent and domain relationships - Jack Humphrey\n      -> Nothing special to report\n      -> Will get some work done in next couple of weeks\n\n    - Consent choices - Matthias Schunter\n      -> Working on the proposal to P3P 1.1 WG.\n      -> Foxusing on the enterprise business policies P3P - content group\n      -> Need more discussions.\n\n    - Converting P3P data schema to XML schema - Giles Hogben\n      -> Working on the proposal to P3P 1.1 WG \n      -> Need comments for the online documents:\nhttp://www.w3.org/P3P/2003/03-xml-data-schema.html\n    \n    - Signed P3P policies  - Giles Hogben\n      -> Working on the proposal to P3P 1.1 WG \n\n2. Discuss user agent guidelines draft -- is working group happy with\n   this draft? Should it be added as a part of the P3P1.1 spec? As an\n   appendix?\n   -> Translating the semantic of P3P to some other definition wordings.\n      Must be consistent.\n   -> The guideline is used as a recommendation.\n   -> Enourage everyone to read it seriously and give comments:\n      http://www.w3.org/P3P/2003/ua-guidelines.html\n   -> It will become part of the P3P 1.1 Specification.\n   -> Lorrie will look where it should go in the specification.\n\n3. Discuss bugzilla 215 - compact policy processing by user agents\n   http://www.w3.org/Bugs/Public/show_bug.cgi?id=215\n   Proposal to add the following section:\n\n   4.7 Compact Policy Processing by User Agents\n\n   P3P user agents SHOULD NOT rely on P3P compact policies that do not\n   comply with the P3P 1.1 specification or are obviously erroneous. Such\n   compact policies SHOULD be deemed invalid and the corresponding\n   cookies treated as if they had no compact policies.\n\n   -> Propose that P3P agents should not reply on compact policy\n   -> It does not comply with 1.1 or 1.0.\n   -> What sort of changes and decisions can make on P3P compact policies.\n   -> Implementation is not doing any checking on compact policy.\n   -> Some Web site even only implemented P3P compact policies.\n   -> There should not have inconsistent between Compact Policies and P3P\nPolicies.\n   -> Use \"SHOULD\" instead of \"MUST\" in the specification of P3P compact\npolicies.\n   -> Closing the issue and put it in the draft.\n   -> Put it into 1.1 for more feedback and comments\n\n4. Discuss Consent Choices working draft -- do we want to pursue this\n   in P3P 1.1 or postpone to P3P 2.0?\n   http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n   This is also related to Bugzilla 169\n   http://www.w3.org/Bugs/Public/show_bug.cgi?id=169\n\n   -> Take P3P 1.1 recommendation.\n\n5. Discuss bugzilla 170\n   http://www.w3.org/Bugs/Public/show_bug.cgi?id=170\n   Consider expanding definition of CONSEQUENCE field to reflect how it\n   is actually being used -- in particular to express summary of\n   STATEMENT as well as value proposition. Alternatively, consider adding\n   actual structure to CONSEQUENCE element to seperate out summary from\n   value proposition.\n\n   Based on discussion on last call I propose the following new \n   definition:\n\n   A short summary (not to exceed 500 characters) of the data practices\n   described in the statement that can be shown to a human user.\n\n   [Note that we do not plan on changing the P3P data schema to reflect\n   the 500 character limit, however, user agents would be advised to\n   display no more than 500 characters.  We can also discuss whether 500\n   characters is the right limit or whether it should be more or less.]\n\n   -> COnsequence is used on the top of all purposes.\n   -> A summary for the definition of cOnsequence 500 words in a natural\nlanguage\n      is suggested. You can write as long as you want but it will be\ntruncated.\n   -> Find out what the max. words should be. Are 500 words long enough?\nHave to bound it.\n      May have a lot of complains for 500 words.\n   -> Need a human explanation of purpose. Not only restrict to the purpose\n   -> Limit the scope. Recommendation on limit giving the agent to read full\ncontext.\n   -> You can write as long as you want but it will be truncated.\n   -> Recommed to have NO limit on the definition of consequence\n   -> Need further discussion.\n\n6. Discuss bugzilla 168\n   http://www.w3.org/Bugs/Public/show_bug.cgi?id=168\n\n   Consider adding human-readable explanation strings to all elements\n   that don't have them\n   - could be done for a specific set of elements or generically\n   - it appears that the way the extension mechanism is defined in the\n   P3P schema we cannot add such elements in arbitrary places -- for\n   example, I think we can add them to high-level elements such as\n   PURPOSE but not as sub-elements of individual PURPOSE elements\n\n   It would be helpful if people could identify elements where they\n   would like to see human-readable strings prior to our call.\n\n   -> Keep it unless somebody brings any idea.\n   -> If no idea proposed, just not do it.\n\n7. Set date for next call (June 25?)\n\n   Next conference call is Wednesday 25 June 2003 11am-12pm \n   US Eastern/16:00-17:00 UTC Dial-in number: Zakim Bridge +1.617.761.6200\n   Code: 73794 (\"P3PWG\")\n\n\n\n", "id": "lists-017-4497525"}, {"subject": "RE: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "Hi Hugo,\n\nThanks a lot for your explanation and clarification.\n\nMay I ask one more question here. I apologize if I further confuse\nyou by my misunderstanding... :-)\n\n>When using the http://www.w3.org/2003/05/soap/bindings/HTTP/ SOAP\n>HTTP/1.1 binding, the P3P feature is expressed as an HTTP header as\n>follows:\n>\n>  P3P: policy=\" URI-Reference \"\n\nBased on your description, I believe that I have a picture of how\nto define a \"feature.\" Assume my understanding is correct. Then,\nit seems that the \"feature\" is an independent structure that can\nbe applied/attached into UDDI, SOAP or even WSDL, am I correct?\n\n> A WSDL 1.2 description of a service with such a feature could be (this\n> may be slightly inaccurate, but you will get the idea):\n>\n>  <feature\n>     uri='http://example.org/2003/06/16-p3pf/'>\n>  <property\n>     uri='http://example.org/2003/06/16-p3pf/id'>\n>    <value>http://registry.example.com/P3P/Policy.xml</value>\n>  </property>\n>  </feature>\n\nIf I do not misunderstand it, how can I specify/attach the \"feature\" into \nUDDI, SOAP or even WSDL? Sorry that I am lazy to check the related\nspecifications.\n\n> Hmmm... I think that I was confused. I think that a policy reference\n> file is fine as a child of wsdl:definitions, but a reference to a\n> policy file, i.e. a policy which would apply to an operation, would be\n> more specific.\n\nIn many cases, I do imagine that we may need a privacy policy at the\n<wsdl:definitions/>\nlevel and then with some other privacy policies at the <wsdl:operation/>\nlevel. Thus,\nwe may have to do a logical \"AND\" between the privacy policies in two\ndifferent abstraction\nlevels.\n\nThanks a lot,\n\nPatrick.\n  \n\n\n\n", "id": "lists-017-4511805"}, {"subject": "Re: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "* Patrick.Hung@csiro.au <Patrick.Hung@csiro.au> [2003-06-18 01:27+1000]\n> >When using the http://www.w3.org/2003/05/soap/bindings/HTTP/ SOAP\n> >HTTP/1.1 binding, the P3P feature is expressed as an HTTP header as\n> >follows:\n> >\n> >  P3P: policy=\" URI-Reference \"\n> \n> Based on your description, I believe that I have a picture of how\n> to define a \"feature.\" Assume my understanding is correct. Then,\n> it seems that the \"feature\" is an independent structure that can\n> be applied/attached into UDDI, SOAP or even WSDL, am I correct?\n\nHmmm... the concept of feature is something abstract which originated\nin the SOAP Version 1.2 work and is in the process of being\ngeneralized to the Web services architecture.\n\nThe definition of a SOAP feature is:\n\n| An extension of the SOAP messaging framework (see 3. SOAP\n| Extensibility Model). Examples of features include \"reliability\",\n| \"security\", \"correlation\", \"routing\", and \"Message Exchange Patterns\"\n| (MEPs).\n\nMore below.\n\n> > A WSDL 1.2 description of a service with such a feature could be (this\n> > may be slightly inaccurate, but you will get the idea):\n> >\n> >  <feature\n> >     uri='http://example.org/2003/06/16-p3pf/'>\n> >  <property\n> >     uri='http://example.org/2003/06/16-p3pf/id'>\n> >    <value>http://registry.example.com/P3P/Policy.xml</value>\n> >  </property>\n> >  </feature>\n> \n> If I do not misunderstand it, how can I specify/attach the \"feature\" into \n> UDDI, SOAP or even WSDL? Sorry that I am lazy to check the related\n> specifications.\n\nLet's take another simple example to try and illustrate this.\n\nConsider the simple \"reliable\" messaging. Its definition specifies\nwhat is meant by simple \"reliable\" messaging, e.g. have the receiver\nsend a return receipt to the sender once it got the message, without\ncaring about this return receipt getting lost.\n\n= SOAP 1.2\n\nA SOAP module realizing the simple \"reliable\" messaging can then be\nspecified. A SOAP module is:\n\n| A SOAP Module is a specification that contains the combined syntax and\n| semantics of SOAP header blocks specified according to the rules in\n| 3.3 SOAP Modules. A SOAP module realizes zero or more SOAP features.\n\nSo this specification would explain what SOAP header blocks would need\nto be inserted in the message and how they would need to be processed\nto implement this feature. I think that this answers your question\nabout the relationship with SOAP.\n\nNote that this feature could be provided by a protocol binding. For\nexample, HTTP has responses and therefore the HTTP binding would\nsupport this simple feature.\n\nFor more details about SOAP 1.2 and features:\n\n  http://www.w3.org/TR/2003/PR-soap12-part1-20030507/#soapfeature\n\n= WSDL 1.2\n\nThen, for WSDL 1.2, a service may ask you to interact with it using\nthis feature. In this case, the WSDL 1.2 description of this service\nwould specify this with a piece of XML such as the one I showed for\nthe http://example.org/2003/06/16-p3pf/ feature, specifying the\nassociated properties.\n\nThis is how a feature would appear at the service description level.\nFor more details about WSDL 1.2 and features:\n\n  http://www.w3.org/TR/2003/WD-wsdl12-20030611/#Feature\n\n= Registry\n\nIf you were querying a registry, chances are that the registry was\npopulated directly from the WSDL 1.2 description. In this case, the\nregistry will tell you that the service support the simple \"reliable\"\nmessaging feature, since it found in the WSDL 1.2 description as\nexplained above.\n\nI hope that this other simple example will shed more light on my more\nrelevant P3P feature example.\n\n> > Hmmm... I think that I was confused. I think that a policy reference\n> > file is fine as a child of wsdl:definitions, but a reference to a\n> > policy file, i.e. a policy which would apply to an operation, would be\n> > more specific.\n> \n> In many cases, I do imagine that we may need a privacy policy at the\n> <wsdl:definitions/>\n> level and then with some other privacy policies at the <wsdl:operation/>\n> level. Thus,\n> we may have to do a logical \"AND\" between the privacy policies in two\n> different abstraction\n> levels.\n\nOh, I see.\n\nHope this helps.\n\nRegards,\n\nHugo\n\n-- \nHugo Haas - W3C\nmailto:hugo@w3.org - http://www.w3.org/People/Hugo/\n\n\n\n", "id": "lists-017-4522113"}, {"subject": "Cleaning Up the Namespaces (Was: Comments on &quot;[P3P]: Beyond HTTP&quot;", "content": "Patrick, I finally got around to adding the references (through some clumsy \nXSLT hackery [1] <smile/>) and I also tried to clean up the use of our \nidentifiers and Namespaces[2]. However, it's just as likely I broke \nsomething, so let me know if I have.\n\nHugo, a problem I'm experiencing is when I try to validate our WSDL example \n(wsdl-eg.xml) against our augmented wsdl schema (wsdl-p3p-extension.xsd) -- \nbecause we've added my:Privacy as a child of wsdl:definitions -- XSV gives \nme an error about 'wsdl12-ext.xsd'?\n\n>Schema resources involved\n>Attempt to load a schema document from \n>/home/reagle/data/2web/WWW/P3P/2003/p3p-beyond-http/wsdl-p3p-extension.xsd \n>(source: command line) for no namespace, succeeded\n\n>Attempt to load a schema document from http://www.w3.org/2003/06/wsdl \n>(source: import) for http://www.w3.org/2003/06/wsdl, succeeded\n\n>Attempt to load a schema document from \n>http://www.w3.org/2003/06/wsdl12-ext.xsd (source: include) for \n>http://www.w3.org/2003/06/wsdl, failed: couldn't open *************\n\n\n[1] http://lists.w3.org/Archives/Public/spec-prod/2003AprJun/0017.html\n[2] http://www.w3.org/2003/03/rdf-in-xml.html\n     $Revision: 1.21 $ on $Date: 2003/06/10 18:57:29 $\n|   Namespaces and Identifiers\n|\n|    Throughout this document the following namespaces and\n|    identifiers are used.\n|\n|    http://registry.example.com/2003/ns1\n|           The namespace of the example order form for the\n|           registry.\n|\n|    http://www.w3.org/P3P/2003/p3p-beyond-http/\n|           The namespace of the p3p:Privacy element that is used\n|           in SOAP headers.\n|\n|    http://registry.example.com/wsdl/register\n|           The targetNamespace for the registry's WSDL\n|\n|    http://registry.example.com/P3P/PolicyReferences.xml\n|           The location of the registy's P3P policy\n\n\n\n", "id": "lists-017-4535403"}, {"subject": "Re: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "On Wednesday 18 June 2003 10:34, Hugo Haas wrote:\n> Note that this feature could be provided by a protocol binding. For\n> example, HTTP has responses and therefore the HTTP binding would\n> support this simple feature.\n\nI don't think we would want to use the HTTP binding though for our main case \nof the user and the registry. In that clase it's closer to end-to-end.\n\n| The former [Processing Model] describes the behavior of a single \n| SOAP node with respect to the processing of an individual message. \n\nBTW: Does that mean that header can only be relevant to a single node? I \ndon't think so because it laters says, \"Such header blocks can be intended \nfor any SOAP node or nodes along a SOAP message path\", so perhaps that \n\"single SOAP node\" is innapproriate?\n\nRegardless, of augmented our section on the Scope of Layers and Bindings \n(HTTP and SOAP) to cite the Features text from the SOAP spec since it \ncoincides with our ealier recommendations:\n\n|    Adopting applications MUST specify where relevant P3P\n|    statements can be found. We RECOMMEND that normative\n|    association (not including WSDL or UDDI) be limited to the\n|    higher/application layer. We RECOMMEND that a\n|    higher/abstract layer MAY include the privacy policy of\n|    layers it is dependent upon, but that lower layers SHOULD\n|    NOT represent the policies of higher layers. For example, an\n|    application that transfers data with SOAP over HTTP and uses\n|    cookies, SHOULD specify:\n|     1. the P3P policy associated with SOAP is normative and\n|        includes the HTTP cookie usage, or\n|     2. there are distinct P3P policies associated with the SOAP\n|        and HTTP layers.\n|\n|    Again, the Non-ambiguity requirement of ([P3P], section\n|    2.4.1) MUST be respected, \"Sites MUST be cautious in their\n|    practices when they declare multiple policies for a given\n|    URI, and ensure that they can actually honor all policies\n|    simultaneously.\" Furthermore, SOAP Features ([SOAP], secion\n|    1.3) states that:\n|\n|      The processing of SOAP envelopes in accordance with the\n|      SOAP Processing Model (see 2. SOAP Processing Model) MUST\n|      NOT be overridden by binding specifications. It is\n|      recommended that, where practical, end-to-end features be\n|      expressed as SOAP header blocks, so that the rules\n|      defined by the SOAP Processing Model can be employed.\n\n\n\n", "id": "lists-017-4545709"}, {"subject": "Re: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "Hugo, thank you for this extensive (tutorial!) email!\n\nOn Monday 16 June 2003 05:14, Hugo Haas wrote:\n> So, anyway, in order to make things concrete, let's try to address the\n> second case: expressing a URI to a P3P policy document. I think that\n> it is more useful than expressing the URI to a policy reference since\n> a WSDL description would already give a list of policies for each\n> service. Again, this would probably be up for discussion.\n\nI still can't say I understand all of this Feature and WSDL stuff, but I \nthink you have a very important point there. A Policy Reference file \ndesignates a (1) life time (expiration), (2) policies, (3) and set of paths \nfor a web site (via INCLUDE and EXCLUDE) where those policies apply. \nBasically a set of URIs over which one does HTTP methods (GET, POST, PUT)\nThat makes lots of sense for browsing a web sites, but not so much for Web \nService.\n\nIn the Web Service case one will be doing port names (operations) as applied \nto a soap:address? In which case, a Policy Reference file isn't really \nneeded.\n\n> --8<----\n> P3P feature\n>\n> - Name\n>\n> http://example.org/2003/06/16-p3pf/\n>\n> - Description\n>\n> The P3P feature is used to indicate the P3P policy governing the use\n> of a service.\n>\n> - Properties\n>\n> The P3P feature defines a single property:\n>\n>   Property name:\n>\n> http://example.org/2003/06/16-p3pf/id\n>\n>   Property type:\n>\n>   xsd:anyURI\n>\n> The value of the http://www.w3.org/2003/06/16-p3pf/id property is the\n> identifier for the P3P policy governing the use of the service.\n\nSo we sort of have this, less formally, and we haven't given ita special \n\"feature\" URI...\n\n> Which makes me wonder: are policy reference file useful to Web\n> services? With WSDL and something like a P3P feature, wouldn't the\n> problem addressed by policy reference files taken care of?\n\nYes, I think so. So in our scenario, we'd still want the Policy Reference \nfile for the XForms/XHTML aspect, but not for the registrar to registry \naspect.\n\nPatrick, is your understanding sufficient that you have a sense of what \nchanges we could make to our document? I still need to keep thinking it \nthrough for myself.... \n\n\n\n", "id": "lists-017-4555732"}, {"subject": "Re: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "So one alternative is to reference the policy file directly for web \nservices rather than the policy reference file. Another alternative is \nto use the extension mechanism to create a more appropriate type of \nreference for web services inside the policy reference file. This \nreference would designate an appropriate scope for a policy that is \napplicable to web services. I don't know enough about what I am talking \nabout here to know which would be preferable... but I would like you to \nconsider both possibilities.\n\nLorrie\n\n\nOn Wednesday, June 18, 2003, at 05:59  PM, Joseph Reagle wrote:\n\n>\n> Hugo, thank you for this extensive (tutorial!) email!\n>\n> On Monday 16 June 2003 05:14, Hugo Haas wrote:\n>> So, anyway, in order to make things concrete, let's try to address the\n>> second case: expressing a URI to a P3P policy document. I think that\n>> it is more useful than expressing the URI to a policy reference since\n>> a WSDL description would already give a list of policies for each\n>> service. Again, this would probably be up for discussion.\n>\n> I still can't say I understand all of this Feature and WSDL stuff, but \n> I\n> think you have a very important point there. A Policy Reference file\n> designates a (1) life time (expiration), (2) policies, (3) and set of \n> paths\n> for a web site (via INCLUDE and EXCLUDE) where those policies apply.\n> Basically a set of URIs over which one does HTTP methods (GET, POST, \n> PUT)\n> That makes lots of sense for browsing a web sites, but not so much for \n> Web\n> Service.\n>\n> In the Web Service case one will be doing port names (operations) as \n> applied\n> to a soap:address? In which case, a Policy Reference file isn't really\n> needed.\n>\n>> --8<----\n>> P3P feature\n>>\n>> - Name\n>>\n>> http://example.org/2003/06/16-p3pf/\n>>\n>> - Description\n>>\n>> The P3P feature is used to indicate the P3P policy governing the use\n>> of a service.\n>>\n>> - Properties\n>>\n>> The P3P feature defines a single property:\n>>\n>>   Property name:\n>>\n>> http://example.org/2003/06/16-p3pf/id\n>>\n>>   Property type:\n>>\n>>   xsd:anyURI\n>>\n>> The value of the http://www.w3.org/2003/06/16-p3pf/id property is the\n>> identifier for the P3P policy governing the use of the service.\n>\n> So we sort of have this, less formally, and we haven't given ita \n> special\n> \"feature\" URI...\n>\n>> Which makes me wonder: are policy reference file useful to Web\n>> services? With WSDL and something like a P3P feature, wouldn't the\n>> problem addressed by policy reference files taken care of?\n>\n> Yes, I think so. So in our scenario, we'd still want the Policy \n> Reference\n> file for the XForms/XHTML aspect, but not for the registrar to registry\n> aspect.\n>\n> Patrick, is your understanding sufficient that you have a sense of what\n> changes we could make to our document? I still need to keep thinking it\n> through for myself....\n>\n\n\n\n", "id": "lists-017-4565919"}, {"subject": "RE: Comments on &quot;[P3P]: Beyond HTTP&quot", "content": "Thanks a lot for your explanation, Hugo!\n\n> Patrick, is your understanding sufficient that you have a sense of what \n> changes we could make to our document? I still need to keep thinking it \n> through for myself.... \n\nHi Joseph,\n\nI can't say that I am understanding sufficient... However, I will study the\nSOAP and WSDL \"features\" and do more thoughts. In the first cut, we\n***may*** \nhave to revise those SOAP and WSDL examples by using \"features\" or make the \n\"features\" version as another option in our document. \n\nI will be out of office/town and in California from June 22 to July 2.\nThat's\nwhy I may not be able to check e-mails regularly. Anyway, I have bring\nenough\nrelevant materials with me for reading during the trip. Will get back to you\nonce I get back to office.\n\nI found a typo in our document: \"... secion 1.3) ...\" :-)\n\nCheers and talk to you later.\n\nPatrick.\n\n\n\n", "id": "lists-017-4577461"}, {"subject": "AGENDA: June 25 P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, June 25, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit and Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n\n2. Kiel workshop report (Rigo)\n\n\n3. Lorrie proposes that the user agent guidelines be incorporated\n    into the spec as section 6 with an ammendment to section 1.1.4.  Is\n    there a consensus to put them in there? For latest draft see:\n    http://www.w3.org/P3P/2003/ua-guidelines.html\n\n\n4. Discuss Consent Choices working draft -- do we want to pursue this\n    in P3P 1.1 or postpone to P3P 2.0? We need feedback from\n    implementers!\n    http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n    This is also related to Bugzilla 169\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=169\n\n\n5. Discuss bugzilla 170\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=170\nConsider expanding definition of CONSEQUENCE field to reflect how it\nis actually being used -- in particular to express summary of\nSTATEMENT as well as value proposition. Alternatively, consider adding\nactual structure to CONSEQUENCE element to seperate out summary from\nvalue proposition.\n\nBased on discussion on last call I propose the following (revised) new\ndefinition:\n\nA short summary or explanation of the data practices described in the\nstatement that can be shown to a human user.   This field is not\nintended to replace or duplicate the detailed information that may be\nprovided in a site's full human-readable privacy policy.  Note that\nuser agents that display this field MAY truncate lengthy CONSEQUENCE\nstrings or display this information only if a user follows a\nhyperlink (See Section 6.1).\n\nAlso, I propose we change item 5 in the section \"Completeness of Human\nReadable Translations\" in the UA Guidelines to:\n\nTranslations SHOULD include relevant human-readable fields from a P3P\npolicy. However, user agents MAY truncate lengthy human-readable\nfields or display such fields on a click-through basis.  Typically,\n500 characters is adequate for the human-readable P3P fields.\n\n6. Initial discussion of Ari's identified/identifiable/link\n    clarification draft (to be sent out soon).\n\n7. Set date for next call (July 9?)\n\n\n\n", "id": "lists-017-4586039"}, {"subject": "UA: next UA TF call 23 June 11 a", "content": "Our next User Agent task force call will be on Monday, 23 June 2003 at \n11 am US Eastern. We will use the usual dial-in number (see \nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html)\n\nAGENDA\n\n1. Discussion of alternatives to \"this site\" language\n\n2. Continue discussion of proposed translation \nhttp://www.w3.org/P3P/2003/p3p-translation.htm ... please continue to \nsend your feedback. I have highlighted with red underlined text the \nparts that have been flagged for discussion. If you see something that \nneeds discussion that isn't flagged, please let me know.\n\n3. We need to return to the one/multiple entity discussion at some \npoint but I would prefer to have some email discussion on it so we \ndon't take up a lot of time on the call. We may discuss briefly if time \npermits.\n\n4. Schedule next call \n\n\n\n", "id": "lists-017-4595936"}, {"subject": "[Bug 167] explanation of identified, identifiable, and linke", "content": "Here is my draft text for addressing the confusion around identity \nterms in the spec.\n\n\n\n>http://www.w3.org/Bugs/Public/show_bug.cgi?id=167\n\n\n\nIdentity Definitions in the P3P Specification\n\nIn privacy regulations, guidelines and papers about privacy a variety \nof terms are used to describe data that identifies an individual to \nvarying degrees.  Some common terms such as \"personally identifiable \ninformation (PII)\" are often not defined or the cause for heated \ndebate.  In different documents, \"identity\" can be tied to:\n\n1) how the information can be or is being used,\n2) how the information is stored, or\n3) the type of information.\n\nThe P3P Specification Working Group tried to capture all three of \nthese ideas so that different implementers and users can make \ndecisions based on the importance they place on these various \ndefinitions of identity. (1)\n\nIdentity Through Usage (\"identified\" data)\n\nThe most common term in the specification is \"identified data\" and \nfocuses on how the information can be or is being used.\n\n\"Identified data\" is information that reasonably can be used by the \ndata collector to identify an individual.  Admittedly, this is a \nsomewhat subjective standard.  For example, a data collector storing \nInternet Protocol (IP) addresses  (which can be created dynamically \nor could be static and therefore tied to a particular computer used \nby a single individual) should consider the IP address \"identified \ndata\" only when an attempt is made to tie the exact addresses to past \nrecords or work with others to identify the specific individual or \ncomputer over a long period of time.  In the more common case, where \ndata collectors use IP addressing information in the aggregate or \nmake no attempt to tie the IP address to a specified individual or \ncomputer over a long period of time, IP addresses are not considered \nidentified even though it is possible for someone (eg, law \nenforcement agents with proper subpoena powers) to identify the \nindividual based on the stored data.\n\n\nIdentity Through Storage (\"non-identifiable\" and \"linked\" data)\n\nThe working group also felt that data collectors should be able \nacknowledge when they make specific attempts to anonymize what would \notherwise be identifiable in its storage.\n\nThe term \"non-identifiable\" data refers to how the information is \nstored.  For example, a data collector collecting and storing IP \naddresses but not using them should NOT call this data \n\"non-identifiable\" even in the common case where they have no plans \nto identify an actual individual or computer. However, if a Web site \ncollects IP addresses, but actively deletes all but the last four \ndigits of this information in order to determine short term use, but \ninsure that a particular individual or computer cannot be \nconsistently identified, then the data collector can and should call \nthis information \"non-identifiable.\"  Also, non-identifiable can be \nused in cases where no information is being collected at all.  Since \nmost Web servers are designed to keep Web logs for maintenance, this \nwould most likely mean that the data collector has taken specific \nefforts to ensure the anonymity of users.\n\nUnder the above definitions, a lot of information could be \n\"identifiable\" (not specifically made anonymous), but not \n\"identified\" (reasonably able to be tied to an individual or \ncomputer).\n\nSimilarly, the term \"linked\" refers to how information is being \nstored in connection with a cookie. All data in a cookie or linked to \na particular user must be disclosed in the cookie's policy. Using the \nterminology above, if the data collector collects \"identifiable\" \ninformation about the user it is generally \"linked\" data.\n\nIdentity Through Information Type\n\nThe Working Group felt that different user agent implementations \ncould be created to focus on different concerns around data type. \nTherefore, the working group enabled the creation of a robust data \nschema including broad categories of information that may be \nconsidered sensitive by certain user groups.  The Working Group hopes \nthat a diverse set of user agents will be created to allow users the \nability to make identity decisions based on specific collections and \ntypes of collects if they desire to do so.  For example, a user agent \ncould allow users to opt to be prompted when medical or financial \nidentifier is being collected, independent of how that information is \nbeing used.\n\n(1)   More information on the debate and the definitions can be found \nin Lorrie Faith Cranor's book Web Privacy with P3P, O'Reilly, 2002.\n\n\n\n-- \n------------------------------------\nAri Schwartz\nAssociate Director\nCenter for Democracy and Technology\n1634 I Street NW, Suite 1100\nWashington, DC 20006\n202 637 9800\nfax 202 637 0968\nari@cdt.org\nhttp://www.cdt.org\n------------------------------------\n\n\n\n", "id": "lists-017-4603369"}, {"subject": "RE: AGENDA: June 25 P3P spec cal", "content": "My regrets... I will be on a business trip on June 25.\n\nPatrick.\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@research.att.com]\nSent: Saturday, 21 June 2003 12:08 AM\nTo: public-p3p-spec@w3.org\nSubject: AGENDA: June 25 P3P spec call\n\n\n\nThe next P3P specification group conference call will be on\nWednesday, June 25, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit and Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n\n2. Kiel workshop report (Rigo)\n\n\n3. Lorrie proposes that the user agent guidelines be incorporated\n    into the spec as section 6 with an ammendment to section 1.1.4.  Is\n    there a consensus to put them in there? For latest draft see:\n    http://www.w3.org/P3P/2003/ua-guidelines.html\n\n\n4. Discuss Consent Choices working draft -- do we want to pursue this\n    in P3P 1.1 or postpone to P3P 2.0? We need feedback from\n    implementers!\n    http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n    This is also related to Bugzilla 169\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=169\n\n\n5. Discuss bugzilla 170\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=170\nConsider expanding definition of CONSEQUENCE field to reflect how it\nis actually being used -- in particular to express summary of\nSTATEMENT as well as value proposition. Alternatively, consider adding\nactual structure to CONSEQUENCE element to seperate out summary from\nvalue proposition.\n\nBased on discussion on last call I propose the following (revised) new\ndefinition:\n\nA short summary or explanation of the data practices described in the\nstatement that can be shown to a human user.   This field is not\nintended to replace or duplicate the detailed information that may be\nprovided in a site's full human-readable privacy policy.  Note that\nuser agents that display this field MAY truncate lengthy CONSEQUENCE\nstrings or display this information only if a user follows a\nhyperlink (See Section 6.1).\n\nAlso, I propose we change item 5 in the section \"Completeness of Human\nReadable Translations\" in the UA Guidelines to:\n\nTranslations SHOULD include relevant human-readable fields from a P3P\npolicy. However, user agents MAY truncate lengthy human-readable\nfields or display such fields on a click-through basis.  Typically,\n500 characters is adequate for the human-readable P3P fields.\n\n6. Initial discussion of Ari's identified/identifiable/link\n    clarification draft (to be sent out soon).\n\n7. Set date for next call (July 9?)\n\n\n\n", "id": "lists-017-4615106"}, {"subject": "UA: Minutes of 23 June UA TF cal", "content": "Minutes of 23 June 2003 P3P User Agent Task Force call\n\nParticipants:\nLorrie Cranor (AT&T)\nJeff Edelen (American Express)\nRigo Wenning (W3C)\nBrooks Dobbs (DoubleClick)\nGiles Hogben (JRC)\n\n1. We discussed alternatives to the \"this site\" language that we \ngenerated on our last call. Rigo also suggested we consider using the \nterm \"party.\" We decided to recommend use of we/ours/us/ etc... with \nthe option that sites might substitute in the name from the entity \nfield or hyperlink the \"we\" to the name from the entity field.\n\n2. We continued discussing the red underlined parts of the matrix. We \nreached a consensus on wording for the access elements and the purposes \npseudo-analysis, pseudo-decision, individual-analysis, and \nindividual-decision. Lorrie has updated the matrix at  \nhttp://www.w3.org/P3P/2003/p3p-translation.htm accordingly. All that is \nleft to discuss is the categories heading and the state category \n(unless people raise new issues).\n\nWe began discussing the categories heading. Some concerns were raised \nabout how to convey to people that just because a site says they may \ncollect a category does not mean that they will collect all data \nelements in that category. We postponed that discussion to our next \ncall.\n\n3. Our next call will be on Monday, June 30 at 11 am US Eastern time -- \nsame dial-in info. We will try to finish going through the matrix and \nrevisit the one-or-many entity issue. Please send any additional agenda \nitems or additional items you want to flag from the matrix for \ndiscussion by the end of the week.\n\n\n\n", "id": "lists-017-4625808"}, {"subject": "new U Penn study on online privacy recommends mandating P3", "content": "A new study was published today by Joseph Turow at the University of \nPennsylvania called \"Americans & Online Privacy: The system is Borken.\" \nYou can find a WSJ article and synopsis at \nhttp://cryptome.org/dark-privacy.htm -- along with a link to the full \n36-page study. This study basically finds that people don't understand \nprivacy policies and don't have a good conceptual understanding of how \ntheir information flows online. It also finds that when typical web \nsite data practices are described to people, they generally don't like \nthem.\n\nThe author recommends (on page 35) three proposals for US legislation \nincluding legislation to require websites to use P3P. He discusses P3P \nearlier on page 10, noting that adoption rates are still low. He also \nmentions Privacy Bird (which he describes as \"ingenious\" -- and no, I \ndidn't lobby him to write that -- I'm not sure I've ever talked to him, \nlet alone about Privacy Bird.)\n\nLorrie\n\n\n\n", "id": "lists-017-4633947"}, {"subject": "Fwd: Major Email Delivery for FTC DNCR Launc", "content": "Folks,\n\nThis was sent to nanog earlier in the day. Asrg contributors would help\nthe (US jurisdiction) FTC's \"Do Not Call\" (phone spam) service roll-out\nby letting Richard Callahan know how to keep the eventual AT&T GS mails\nfrom being some systems' false-positive, and not delivered.\n\nI'll sumarize to the list responses that I'm copied on, using white-out\nappropriately if requested. The question will come up again.\n\nP3P contributors are noticed simply because ... watching the US go down\nthe opt-out path is -- er -- interesting.\n\nSemi-related, the special WHOIS:43 (and other kludges) workshop of the\nMontreal meeting of ICANN should be winding up, and I'll sumarize what\nothers who attended sumarize elsewhere, but the bottom line is something\nalong the lines of you-know-already -- (US) law-enforcement and (WIPO)\ntrademark interests claim compelling interests in manditory spam-prone\ndatabases, and the (non-US) ccTLD registry operators and GAC reps reply\nthat <insert-country-here> isn't a town in California (or Maine for you\nwho know how Maine's towns are named). ICANN head-butting, or butt-heads.\n\nOh. The going price for 30 million (that's 3 times 10 to the sixth) email\naddresses culled from the combined whois databases is ... US$30. I just\ncan't wait for enum-on-port-43, oops ... my phone is ringing...\n\nCheers,\nEric\n\n------- Forwarded Message\nSubject: Major E-mail Delivery for FTC DNCR Launch\nDate: Wed, 25 Jun 2003 13:08:08 -0500\nMessage-ID: <729306F70E13DB43AA2D7AA0FAD4715D05441718@OCCLUST03EVS1.ugd.att.com>\nFrom: \"Callahan, Richard M, SOLGV\" <rmcallahan@att.com>\nTo: <nanog@nanog.org>\nCc: \"Windelberg, Marjorie L, SOLGV\" <windelberg@att.com>,\n   \"Weiss, Christine G, SOLGV\" <cgweiss@att.com>\nSender: owner-nanog@merit.edu\nX-MIME-Autoconverted: from quoted-printable to 8bit by nic-naa.net id h5PI9I5U023796\n\n\nGood Afternoon \n     and forgive the new guy if I break any rules or conventions.\n\nI work for AT&T Government Solutions and we are about to launch the Do Not Call Registry for the Federal Trade Commission.  At a high level this allows consumers to register their phone numbers to  keep most telemarketers from calling their homes.  Penalties for calling a consumer on the list can be $11K per call and enforcement begins in October.\n\nWe are launching consumer registrations on Friday.  My concern:\n\n - every registration using the web generates an email which must be opened to complete the registration process\n\nWe are looking at the potential of MILLIONS OF EMAILS PER DAY beginning Friday.  These will be from the same address and have the same subject line.\n\nI am worried about denial of service or blocking by spam filters if providers are not aware this is coming.\n\nI am hoping this group is a good medium to get the word out to inform the community of this impending event.\n\nAt this time I am unable to provide the link or email address, but will do so on Thursday evening if it is of value.\n\nAny thoughts?\n\nRichard M. Callahan\nClient Business Manager\nAT&T Government Solutions\nOffice:  (703)506-5780\nMobile: (703)608-0665\nFax: (703)245-3749\n\n\n\n------- End of Forwarded Message\n\n\n\n", "id": "lists-017-4641690"}, {"subject": "[Minutes] of the 25 June teleconferenc", "content": "Minutes for the P3P 1.1 Specification WG call\n\nPresent:\nMatthias Schunter\nDavid Stampley\nBrooks Dobbs\nJoseph Reagle\nJeff Edelen\nRigo Wenning\nLorrie Cranor\nGiles Hogben\n\n1/ Reports from the different Task-Forces\na/ P3P beyond HTTP - Joseph Reagle\ngood feedback from hugo haas. Document in decent form, pushed it out for comments\ndoesn't make sense to use a polref-file. Would be better to use a WSDL-description\nPRF has expiration-date not in WSDL\nthis week will send pointer to web services ig to get more feedback\nRigo asked back about XForms and the generic XML binding that was initially thought\nof by Steven Pemberton.  Lorrie said, at that time there was discussion whether we want\nan enhanced PRF or just an XML-Element like <XML lang=\"\"> for privacy.\n\nACTION Rigo: Send feedback to the mailing-list to p3p-beyond to include a general XML-binding\n\nb/ User agent behavior - Lorrie Cranor\nLorrie reported from the last UA TF teleconference on Monday, where the TF got down\nthe issues list and made progress in the table of UA expressions\nPeople should look at it, read the meetings of mondays call and provide feedback\nSome further issues being discussed on the next call.\n\nc/ Compact policies\nnothing new\n\nd/ Article 10 vocabulary issues - Giles Hogben\nGiles mentioned three issue that were discussed so far:\n\naa. Verification for disputes for security seal\nlink to a URI that has a seal for security - practices. This is already possible, added some text\nbb. Cookie\ncookies-policies have to be honored at set-time and at replay\ndd. jurisdiction indication\nto express which jurisdiction is governing data exchange\n\nSuggestions about those changes are now under way to be discussed with\nthe European Commission and possibly with the Art. 29 WP\n\ne/ Nothing new about using XML-Schema TF\n\n2/ Kiel workshop report (Rigo Wenning)\nRigo gave a report on the Kiel Workshop.\n\n16 people attended. Included good representation from industry and\nuniversities, mostly from Europe.\n\nDiscussion of preference language. Interest in having a preference\nlanguage working group develop a language completely distinct from\nAPPEL -- basically a profile for XPATH or XQUERY. Some questions\nabout how to capture \"behavior\" concept and how to integrate with\nbackend.\n\nDiscussion of consent mechanism. Need to have better support for\nnailing down consent\n\nDiscussion of cookies and CP. Jeremy said MS is doing performance\ntesting right now using browser with XML parser and hopes to have some\ndata to report soon if he gets permission to make this info public.\n\nLimitation that P3P makes statements about URIs and not other\nresources. P3P is not designed as access control mechanism. It makes\nsense from a business-perspective to have better privacy mechanisms in\nback-end systems. High level discussion about whether standardization\nof the backend makes sense. More discussion needed. Some of this\ndiscussion may occur at workshop in Australia in September.\n\nHP Brussels showed a new application of a trusted platform that allows\nusers to recall data in case of policy violation. They said this has\nmore functionality than DRM.\n\nGiles contacted the minute-taker after the conf and reminded that\nwe forgot to mention that access should be tied to the statement\ninstead of the whole policy. This is also a consideration for the\nconsent/choices TF.\n\n\n3/ UA guidelines should be included as section 6\nno objections\n\n4/ Consent Choices Draft\n\nWe still need feedback from implementers needed whether they will implement it.\nGiles said, he already used similar techniques and would implement. Then the question\nturned to the IBM Policy Editor. Matthias said that the situation is somewhat  unclear\nat the moment, kind of pending. Martin does not put too much effort in it anymore.\nLorrie confirmed that there is definitely interest in mainting the editor (IBM or not)\n\nMatthias asked whether Microsoft will extend support beyond cookies in IE7? Lorrie only\ngot some vague response. Brooks reported of talks with different entities inside Microsoft\nit was agreed that this is something useful.\n\nACTION; Matthias call Jeremy Epling to ask if they would implement consent-choices\n\nMatthias mentioned that he is absent in July\n\n5. Discuss bugzilla 170\nLorrie included a new wording of the consequence-field definition,\nbut hadn't received feedback so far.\nJoseph said, that he is unhappy about the change of meaning as we keep the same\nelement-name.  We should note that in the Draft. We compared the definition and\nfound that the old definition was more narrow, but that it is not a complete change.\nLorrie confirmed, that she will add some words about status and history to the Draft.\n\nACTION: Lorrie draft a sentence or two to explain the evolution\n\n6. Initial discussion of Ari's identified/identifiable/link\nAri not on the call\neverybody should sent feedback to Ari. Rigo mentioned that the initial understanding and\ndiscussion was based on the definition of the EU-Directive which was seen as too wide.\nLorrie asked for simplicity and explained that the  purpose of this document is to explain\nin an easy way for people to figure out which element to use in what context as this seems\nto be complicated.\n\n7. Set date for next call (July 9?)\nNext call will be on July 9 2003\n\nBest,\n\nRigo\n\n\n\n", "id": "lists-017-4653481"}, {"subject": "Re: Cleaning Up the Namespace", "content": "Your wrote:\n> a problem I'm experiencing is when I try to validate our WSDL example\n> (wsdl-eg.xml) against our augmented wsdl schema\n> (wsdl-p3p-extension.xsd) -- because we've added my:Privacy as a child\n> of wsdl:definitions -- XSV gives me an error about 'wsdl12-ext.xsd'?\n\nLooks like XSV doesn't know how to handle redirects appropriately:\n[[\n> HEAD http://www.w3.org/2003/06/wsdl\nHTTP/1.1 301 Moved Permanently\nDate: Mon, 30 Jun 2003 13:40:13 GMT\nServer: Apache/1.3.27 (Unix) PHP/4.2.3\nWWW-Authenticate: Basic realm=\"W3CACL\"\nLocation: http://www.w3.org/2003/06/wsdl/\nContent-Type: text/html; charset=iso-8859-1\n\nHTTP/1.1 301 Moved Permanently\nDate: Mon, 30 Jun 2003 13:40:13 GMT\nServer: Apache/1.3.27 (Unix) PHP/4.2.3\nWWW-Authenticate: Basic realm=\"W3CACL\"\nLocation: http://www.w3.org/2003/06/wsdl/wsdl12.xsd\nContent-Type: text/html; charset=iso-8859-1\n\nHTTP/1.1 200 OK\nDate: Mon, 30 Jun 2003 13:40:13 GMT\nServer: Apache/1.3.27 (Unix) PHP/4.2.3\nWWW-Authenticate: Basic realm=\"W3CACL\"\nP3P: policyref=\"http://www.w3.org/2001/05/P3P/p3p.xml\"\nCache-Control: max-age=21600\nExpires: Mon, 30 Jun 2003 19:40:13 GMT\nLast-Modified: Fri, 06 Jun 2003 20:27:49 GMT\nETag: \"3ee0f945\"\nAccept-Ranges: bytes\nContent-Length: 15083\nContent-Type: application/xml; qs=0.9\n]]\n\nThe effective location of the WSDL XML Schema is\nhttp://www.w3.org/2003/06/wsdl/wsdl12.xsd, and not\nhttp://www.w3.org/2003/06/wsdl. Therefore, the include statement in\nwsdl12.xsd should be resolved against\nhttp://www.w3.org/2003/06/wsdl/wsdl12.xsd.\n\nI note that the old version of Xerces that I'm using is also subject to\nthis problem. Didn't try with a latest one.\n\nNot sure if the WSDL 1.2 specification should reference the effective\nlocation of the XML Schema instead of the namespace...\n\nPhilippe\n\n\n\n", "id": "lists-017-4665088"}, {"subject": "UA: Minutes of 30 June P3P UA T", "content": "Minutes\nP3P User Agent Task Force Call\n30 June 2003\n\nPresent\nJeff\nBrooks\nAri\nJeremy\nRigo\nLorrie\n\nWe discussed and resolved the remaining two flagged items on our \ntranslation matrix: the category heading and the state category.\n\nCategory heading. We decided to adopt the proposed wording: \"Types of \ninformation that may be collected.\"\n\nDuring this discussion we discussed the problem that some user agents \ndo not enumerate all the data elements that a site lists in their \npolicy. Some felt we should encourage sites to always enumerate all \ndata elements, but others objected that this may lead to lengthy \ntranslations. We decided to recommend that all elements be enumerated \nsomewhere, but not necessarily in the default view. We will append the \nfollowing words to bullet point 1 of 6.1 (the user agent guidelines): \n\"including an enumeration of all data elements referenced in a P3P \npolicy.\"\n\nState. We decided to adopt the wording \"Cookies and mechanisms that \nperform similar functions\"\n\n\nWe also discussed the question raised previously about whether to \ncontinue to allow multiple instances of data elements within the ENTITY \nelement. Although some members of the group would like to see multiple \nENTITY elements allowed in the future, adding this now is not going to \nbe clean (and some are still skeptical it is needed). We decided \ninstead to add the following language to section 3.2.4 of the spec: \n\"Although it is permissable for a particular DATA element to appear \nmore than once within a single ENTITY element, this is not\nrecommended as user agents may not display multiple instances of a\nDATA element correctly. Policy writers who wish to indicate multiple\npoints of contact for customer service at a web site should use the\nDISPUTES element, which is designed to have  multiple instances.\" (this \nneeds to be approved by the full WG)\n\n\nLorrie will post a revised matrix at \nhttp://www.w3.org/P3P/2003/p3p-translation.htm later today and Jeremy \nand Rigo will assist in trying to fix the HTML problems.\n\n\n\n", "id": "lists-017-4673946"}, {"subject": "New Public mailing list - public-p3pspe", "content": "Purpose: This mailing list is for members of the P3P specification\n working group. The list contains public discussions of the WG Members\nabout work on P3P 1.1\n\n\n1.  http://www.w3.org/Privacy/Activity\n\n\n\n", "id": "lists-017-4725319"}, {"subject": "welcome to the new p3p spec grou", "content": "public-p3p-spec is the new P3P 1.1 Specification working group mailing  \nlist. It is publicly archived at  \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/\n\nOur first working group teleconference will be on Wednesday, April 16  \nat 11am US Eastern. For dial-in details, members of this group can see  \nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html. Hopefully  \nthis group will be officially re-chartered by then.\n\nI would like to get things started via email now. Here are some things  \nI would like everyone to do:\n\n- If you haven't already done so, please review the task force  \ndescriptions at http://www.w3.org/P3P/2003/03-tf.html and select at  \nleast one task force to participate in. Please send email both to me  \nand to the task force chair to volunteer for a task force.\n\n- Familiarize yourself with Bugzilla at http://www.w3.org/Bugs/Public/  \nand  \nhttp://www.w3.org/Bugs/Public/ \nreports.cgi?product=P3P&output=most_doomed&links=1&banner=1 -- we are  \ngoing to be using this instead of our issues list to keep track of  \npending issues. This is not exactly the intended use of bugzilla, but  \nif you mentally think \"issue\" when you see the word \"bug\" I think you  \nwill find that it works. Please create a bugzilla account for yourself  \nso that you can submit and comment on bugs/issues. I have already  \ncreated a bunch of issues in the system based on our discussion at the  \nf2f meeting and things that have come up previously on the mailing  \nlist. I will be assigning many of the issues to the appropriate task  \nforce chairs once they have created their bugzilla accounts.\n\nTask force chairs: please start thinking about how you want to run your  \ntask forces. Take a look at the rough list of milestones I created for  \nyou and let me know if it is ok, and if possibly flesh it out a bit  \nmore. We are not going to setup separate mailing lists for each TF. I  \nsuggest that you use public-p3p-spec to communicate with your TF (of  \ncourse you can communicate off list arrangements for teleconferences  \nand what not) but prefix your messages with a shorthand for your TF,  \nfor example I might send a message for the user agent behavior  \ntaskforce with the subject \"UA: reviewing IE6/Netscape7/PB strings\". I  \nexpect all TFs to get started and to have some progress to report on  \nthe April 16 call.\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nLorrie Faith Cranor <lorrie@research.att.com>\nAT&T Labs-Research, Shannon Laboratory\n180 Park Ave. Room A205, Florham Park, NJ 07932\nhttp://lorrie.cranor.org/    973-360-8607 \n\n\n\n", "id": "lists-017-4731740"}, {"subject": "[Agent/Domain] getting started on agent/domain relationship discu ssio", "content": "Members of the Agent/Domain Relationships task force,\n\nPlease review the proposals contained in the position paper I submitted last\nNovember:\nhttp://www.w3.org/2002/p3p-ws/pp/coremetrics.pdf\n(If you have trouble reading the PDF, let me know and I'll send you a Word\nor HTML version.)\n\nThe proposals are in the Recommendations section (starting on page 3). They\nmainly attempt to address the agent side of the problem, but they may be a\nuseful starting point for discussion.\n\nJack Humphrey\nCoremetrics\n\n\n\n", "id": "lists-017-4741485"}, {"subject": "highlights notice example", "content": "At our f2f meeting we discussed the highlights notice project with \nMarty Abrams.  He sent out mail today about two web sites that have \nposted a highlights notice publicly for testing. Please take a look at \nthese examples and the testing that they are doing.\n\nLorrie\n\n\nBegin forwarded message:\n\n> Fidelity and USPS have posted their highlights notices for testing on \n> their\n> websites.  The Fidelity policy may be accessed by clicking on the link\n> below:\n>\n> http://personal.fidelity.com/global/search/content/privacyhigh.shtml.\n>\n> They have a \"What Do You Think\" button to the right that brings up the\n> survey.\n>\n> The USPS site may be reached by clicking:\n>\n> http://www.usps.com/common/docs/privpol.htm\n>\n> The survey is brought up when you click out of the policy.\n\n\n\n", "id": "lists-017-4748943"}, {"subject": "BH: Introducing the Beyond HTTP (BH) Task Forc", "content": "INTRODUCTION\n\nMy name is Joseph Reagle and I've agreed to Chair the proposed \"Beyond HTTP \n(BH) Task Force\". I was involved in the earlier days of P3P and have since \nbeen working on XML Signature, Encryption, and Key Management. This task \nforce is defined at [1] and would be governed by the charter presently \nunder review at [2]; I agree to work according to those terms. \n\n[1] http://www.w3.org/P3P/2003/03-tf.html#beyond\n[2] http://www.w3.org/P3P/Group/Specification/1.1/01-spec-charter.html\n\nThe stated goal of the task force is to identify requirements for \nassociating P3P policies with protocols other than HTTP, propose a method \nthat satisfies those requirements, and document any changes to the P3P \nvocabulary arising from the proposal. Web Services are rather complex and \nI'm skeptical of some of the scenarios I've seen regarding their usage but \nmy sense is that the desire is that if they are used to solicit or \ntransport personal information they too should be governed by a privacy \npolicy. As identified in [1], probably the best way to get traction on the \nproblem is to \"survey the field\" and start with a scenario. \n\nSURVEY and SCENARIOS\n\nI'll note that AC020 of the Web Services Architecture Requirements [3] has \nvery specific requirements on this topic. I've previously commented on this \ndraft and the requirements seem reasonable.\n\n[3] http://www.w3.org/TR/2002/WD-wsa-reqs-20021114#AC020\n   AC020\n          enables privacy protection for the consumer of a Web service\n          across multiple domains and services.\n\n          + AR020.1 the WSA must enable privacy policy statements to be\n            expressed about Web services.\n          + AR020.2 advertised Web service privacy policies must be\n            expressed in P3P [85][P3P].\n          + AR020.3 the WSA must enable a consumer to access a Web\n            service's advertised privacy policy statement.\n          + AR020.5 the WSA must enable delegation and propagation of\n            privacy policy.\n          + AR020.6: Web Services must not be precluded from supporting\n            interactions where one or more parties of the interaction are\n            anonymous.\n\nThe most interesting/difficult requirement is with respect to delegation and \npropagation. The Web Services Architecture Usage Scenarios has a Third \nParty Intermediary scenario [4] that is perhaps closes to what we would \nwant to do?\n\n[4] http://www.w3.org/TR/2002/WD-ws-arch-scenarios-20020730/#S030\n\nWhile I've looked at the WS-Policy specifications [5] I think it's perhaps \nbest to play with this scenario in the context of a SOAP message header [6] \nor a WSDL definition [7] for the time being.\n[5] \nhttp://msdn.microsoft.com/webservices/understanding/default.aspx?pull=/library/en-us/dnglobspec/html/wspolicyspecindex.asp\n[6] http://www.w3.org/TR/soap12-part1/#muprocessing\n[7] http://www.w3.org/TR/2001/NOTE-wsdl-20010315#A3\n\nI haven't made an attempt at it yet -- has anyone else? -- but I hope to \nsoon. However, even without doing so, I ask myself if:\n1. Does the privacy statement belong at the SOAP level, or HTTP? In the \nmajority of cases SOAP will be transported over HTTP, what happens if both \nof a HTTP statement?\n2. Does the privacy statement belong at the WSDL level? Not every service \nmust have a service description. And if they did for the purposes of \nprivacy then *have* to fetch the WSDL before proceeding with the \ninteraction? My sense here is that SOAP would trump the OPTIONAL WSDL \ndefinition.\n\nSo! Sorry for the long introduction, but I hope the other task force members \nwill introduce themselves too and provide any requirements, scenarios, or \nquestions they have as well!\n\n-- \n\n* Note, I will be on Holiday from March 24-26.\n\nJoseph Reagle Jr.                 http://www.w3.org/People/Reagle/\nW3C Policy Analyst                mailto:reagle@w3.org\nIETF/W3C XML-Signature Co-Chair   http://www.w3.org/Signature/\nW3C XML Encryption Chair          http://www.w3.org/Encryption/2001/\n\n\n\n", "id": "lists-017-4756347"}, {"subject": "Re: BH: Introducing the Beyond HTTP (BH) Task Forc", "content": "Hi Joseph,\n\nHere are a couple of things where I've attempted to take policies that\nare { similar to | derived from | stolen and wrecked | ... } P3P's and\nmake mechanisms other than some set of HTTP methods transport apply.\n\nIn cronological order:\n\n1. CPExchange, a customer profile exchange application-layer\n   protocol, with no transport binding. The DTD for this and\n   the pre-bubble bumpf are still available at\n   http://www.cpexchange.org/\n\n   While no substantive work has taken place in this area since\n   late '00, aside from the obvious \"bits cribbed from P3P, why\n   and how?\" set of questions, there is the notion of both j19n\n   (\"jurisdictionalization\") and record-route.\n\n2. HTTP WG, an IETF WG (concluded). During the last year of the\n   WG, Dan Jaye contributed a draft that extended the Kristol,\n   Montulli draft on the state management mechanism, RFC 2965.\n   This draft has expired, but I have it (co-author). The IESG\n   published a note written by Moore and Freed (RFC 2964), on\n   the problem domain, observing that some uses of the mechanism\n   were harmful, and depricated policied cookies.\n\n   Parts of this draft were not adopted by anyone, e.g., use of\n   x.509 certs, but some parts were, e.g., some sort of policy\n   mark-up, in cookie headers, initially by Microsoft, circa IE\n   5.5, and simultaniously by the P3P Spec WG.\n\n   The draft is available via anonymous ftp from nic-naa.net.\n   The file name is draft-jaye-http-trust-state-mgt-01.txt\n\n3. PROVREG WG, an IETF WG (current). The problem domain defined\n   by Verisign's RRP protocol, using EBNF as the formal syntax,\n   is slightly restated in EPP, using XML as the formal syntax.\n\n   Neither multi-hop \"onward transport\", nor data collection by\n   other means, sort of between the two prior problems and their\n   solutions. Server-announced policied sessions with clients,\n   transport over TCP.\n\n   There is a counter-proposal to simply mark fields with a bit\n   to policy publication by WHOIS servers, and ignore any other\n   data collection policy issues. This is advanced by the IESG.\n\nAll brain-damange is the responsibility of the author, which is mostly me.\n\nNot shown, because neither I nor anyone else wrote anything up, are any\n\"demark crossing\" notes, inspired by attending the W3C/WAPF meeting in\nMunich in late '00, and re-inspired by the webi/dci/opes (rewrite at the\nedge) IETF bofs and the IRTF digital rights activity (concluded). Both\nare transitive proof of correctness with intermediary rewrite rules.\n\nCheers,\nEric\n\n\n\n", "id": "lists-017-4768417"}, {"subject": "Re: BH: Introducing the Beyond HTTP (BH) Task Forc", "content": "INTRODUCTION\n\nmy name is Marc Langheinrich and i'm interested in joining the \"beyond\nhttp\" taskforce. i've been involved in p3p early on (fall 99) and ended up\nbeing one of the authors of the p3p spec. i am also the editor for the\nappel working draft. \n\nin real life i am a phd-student at the swiss federal institute of\ntechnology (\"eth\" is its german abbreviation) in zurich, switzerland,\nworking in the field of pervasive or ubiquitous computing. not\nsurprisingly, my phd topic is 'privacy in ubiquitous computing'.\n\ni've been trying to use p3p in the ubiquitous computing prototypes we're\nbuilding in our group, and have at one point tried to integrate it into a\nsoap protocol (though blissfully ignoring any web service architecture\nwork, i confess). a brief description of my prototype system can be found\nin a technote i presented at the \"ubiquitous computing\" conference in 2002\nat http://www.inf.ethz.ch/vs/publ/papers/privacy-awareness.pdf\n\n-m\n-- \nMarc Langheinrich <langhein@inf.ethz.ch> Institute for Pervasive Computing\nDept. of Computer Science, ETH Zurich, IFW D48.2, 8092 Zurich, Switzerland\nfon: +41-1-632-0688, fax: +41-1-632-1659,  web: www.inf.ethz.ch/~langhein/\n\n\n\n", "id": "lists-017-4779023"}, {"subject": "UA: user agent translation documents to revie", "content": "I have posted the documents explaining the translation from the P3P \nvocabulary to the terminology used by the Privacy Bird and Netscape 7 \nuser agents at http://www.w3.org/P3P/1.1/documents.html#ua -- I will \nadd the Microsoft IE6 translation as soon as I receive it.\n\nUser agent task force members, please start reviewing these documents \nwith an eye towards creating a recommended set of translations that we \ncan put in a guidelines document. You should consider the overall \napproach of each user agent as well as the specific wording for each \nelement. I would like to start a discussion on the high level approach \nand then delve into the details. I am hoping to arrange a conference \ncall for this taskforce to discuss sometime the week of April 7.\n\nLorrie\n\n\n\n", "id": "lists-017-4788233"}, {"subject": "Re: BH: Introducing the Beyond HTTP (BH) Task Forc", "content": "On Friday 21 March 2003 05:48, Eric Brunner-Williams in Portland Maine \nwrote:\n> Here are a couple of things where I've attempted to take policies that\n> are { similar to | derived from | stolen and wrecked | ... } P3P's and\n> make mechanisms other than some set of HTTP methods transport apply.\n\nThanks Eric, does this mean you would like to be listed as a member of the \ntaskforce? <smile/> I've briefly looked into each of of the apps below \nlooking for salient requirements and/or features of a scenario that might \nbe relevant. Please correct me if you think I've missed something.\n\n> 1. CPExchange, a customer profile exchange application-layer\n>    protocol, with no transport binding. The DTD for this and\n>    the pre-bubble bumpf are still available at\n>    http://www.cpexchange.org/\n\nThis appears to be an extension of the P3P privacy vocabulary with a more \nextensive XML data profile based on XML Schema data types. It appears they \nhave the significant portion with {Access, Purpose, Retention, Recipient}. \nBecause it's based on a 2000 snapshot of P3P I can't discern any particular \ndivergence in the privacy vocabulary because of this app's context. I can \nconclude that they felt there was a need for more extensive and XML Schema \ntyped data structures that would perhaps be of interest to the P3P Schema \ntaskforce.\n\n> 2. HTTP WG, an IETF WG (concluded). During the last year of the\n>    WG, Dan Jaye contributed a draft that extended the Kristol,\n>    Montulli draft on the state management mechanism, RFC 2965.\n>    This draft has expired, but I have it (co-author). The IESG\n>    published a note written by Moore and Freed (RFC 2964), on\n>    the problem domain, observing that some uses of the mechanism\n>    were harmful, and depricated policied cookies.\n\nI followed this work back in the day and my conclusion would be that there \nwas a requirement for terse expression. This appears to be satisfied with \ncompact policies and I would expect other apps with a similar requirement \nto use them, or perhaps in the future a binary-XML representation of the \ncomplete markup...? I've included this in\n  http://www.w3.org/P3P/2003/04-beyond-http#sec-Others\n\n> 3. PROVREG WG, an IETF WG (current). The problem domain defined\n>    by Verisign's RRP protocol, using EBNF as the formal syntax,\n>    is slightly restated in EPP, using XML as the formal syntax.\n\nI'm unfamiliar with this work but I've poked about on:\n  http://www.ietf.org/html.charters/provreg-charter.html\n  http://www.ietf.org/internet-drafts/draft-ietf-provreg-epp-09.txt\nand see they have a :\n  \"\"\"   - A <dcp> (data collection policy) element that contains child\n    elements used to describe the server's privacy policy for data\n    collection and management.\"\"\"\nwith an {access, purpose, retention}, elements based on P3P. Since this is \nactive work, I think it makes sense to ask them why don't they use the \nelements from P3P itself? And if there are reasons, we'd appreciate the \nfeedback. Do you have connections with this work, could you help start that \nconversation?\n\n\n\n", "id": "lists-017-4795650"}, {"subject": "Re: BH: Introducing the Beyond HTTP (BH) Task Forc", "content": "On Tuesday 25 March 2003 04:21, Marc Langheinrich wrote:\n> my name is Marc Langheinrich and i'm interested in joining the \"beyond\n> http\" taskforce. i've been involved in p3p early on (fall 99) and ended\n> up being one of the authors of the p3p spec. i am also the editor for the\n> appel working draft.\n\nThanks for catching my drift Mark! <smile/> I've linked to your introduction \nfrom:\n  http://www.w3.org/P3P/2003/03-tf.html#beyond\nand hope the other members of the Task Force will follow suit!\n\n\n\n", "id": "lists-017-4806527"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nI got some comments about the \"chunks\" that we'll want to \naddress. I am still trying to catch up with you guys' work\nin the P3P working group. :-)\n\nPlease let me try to describe a scenario as follows:\n\nA Web services \"requestor\" (consumer or application) is looking \nfor a Web service at the UDDI or even directly consult the WSDL \ndocument of the Web service. Thus, the Web services \"provider\" \nshould put the Web service's privacy policy in both UDDI and WSDL \nlevel. After the requestor/service-locator found the Web service, \nthe requestor/service-locator would also validate with the Web \nservice's privacy policy based on the requestor's preferences and \ncheck whether the privacy policy is acceptable or not. Once the \nWeb service's privacy policy is acceptable, the requestor would \ntry to bind to the Web service. At this moment, the only way for \nthe provider to understand/know the requestor's privacy policy is \nthrough the SOAP message. By any mean, the provider has the right \nto accept/reject the SOAP request if the requestor's privacy policy \nis/is-not acceptable with the providor's preferences. \n\nIf we agree such an scenario, the first task for us is to check \nthe research issues in the existing UDDI, WSDL, and SOAP. Here\nare some of my primitive thoughts...\n\nUDDI\n====\nI think we should have privacy policies defined in the <businessEntity/>\nand/or <businessService/>. If so, we may also have to look into those \nrelated XML languages for finding the Web services in UDDI, e.g., Web \nService Inspection Language (WSIL) in the future.\n------------------------------------------------------------------------\n\nSOAP\n====\nYes, the privacy policy or compact policy file should be specified in \nthe SOAP header.\n------------------------------------------------------------------------\n\nWSDL\n====\nA new attribute, say policyref=\"URI Reference\" such as the idea of \n<Policy-Ref/> in P3P, is needed in the <definitions /> element or we \ncan propose a new element <privacy/> in the WSDL document. However, \nI would perfer to make it as an attribute. For instance, this \n***policyref*** can be referenced to a P3P policy, a P3P compact policy, \nor even a P3P-based WS-Privacy policy (?) in the future.\n\nReferring to the WSDL specification, \"WSDL has four transmission primitives \nthat an endpoint can support: \n\n(1) One-way. The endpoint receives a message. \n(2) Request-response. The endpoint receives a message, and sends a \n                      correlated message. \n(3) Solicit-response. The endpoint sends a message, and receives a \n                      correlated message. \n(4) Notification. The endpoint sends a message.\"\n\nReferring to the scenario described above, does it mean that the WSDL can\nnot \nsupport (1) because the requestor has no way to know whether the provider is\n\nhappy or not about the requestor's privacy policy based on the provider's \npreferences? If so, what should we do?\n--------------------------------------------------------------------------\n\n\nIn particular, we need more thoughts/ideas about the requirement AR020.5\nin the \"Web Services Architecture Requirements\" in an intermediary scenario\nor I would like to name it as a loosely coupled Web services execution\nscenario.\nBeside the S030 Third party intermediary scenario of the Web Services\nArchitecture \nUsage Scenarios, AR020.6 is strongly related to workflow/business process\nintegration \nissues. I am currently thinking about it...\n\nHowever, I have some trouble with the requirement \"AR020.6: Web Services\nmust not \nbe precluded from supporting interactions where one or more parties of the \ninteraction are anonymous.\" This may work in some cases. However, those\nsecurity\ntokens WS-Security and SAML are mainly designed for authentication. Thus, is\nthere any conflict between AR020.6 and Web services security? It may be much\nclearer\nand useful if there is a few examples to demonstrate the importance of\nAR020.6.\n\n\nThere are two typos in the draft:\n\n(1) Referring to the \"The Movement of Information\" section:\n    data propogation \n             ^ -> propagation \n        \n    policy propogation \n               ^ -> propagation\n\n    preference propogation \n                   ^ -> propagation\n\n(2) The p3p:RECIPIENT Value and Data/Preference Progrogation\n                                                ^^^^^^^^^^^^ -> Propagation?\n\n\n\nReferring to the \"Scope and Bindings (HTTP and SOAP)\" section, it would\nbe more precise to say that \"For example, a browser-interfaced application\nthat transfers data with SOAP over HTTP that uses cookies,...\" instead of \n\"For example, an application that transfers data with SOAP over HTTP that \nuses cookies, ...\"\n\nFurther, I would believe that \"there are distinct P3P policies associated \nwith the SOAP and HTTP layers.\" because these are belonging to two layers: \nthe SOAP message is on the application layer and the HTTP protocol is on \nthe transport layer.\n\nAnyway, please tell me what do you think about them? In particular, I am\ninterested in writing up an instance of linking a P3P policy with SOAP and\nWSDL in the sections of \"Scope and Bindings (HTTP and SOAP)\" and\n\"Associating \nwith a WSDL Description.\"\n\nThanks and talk to you soon.\n\nPatrick.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Saturday, 26 April 2003 6:29 AM\nTo: public-p3p-spec@w3.org\nSubject: [BH] First (Very Rought) Outline of Beyond HTTP\n\n\n\n\nAs stated, I've tried to put together an outline [1] that hopefully gives a \nsense of the goals, the scenario, and the \"chunks\" that we'll want to \naddress.\n\n[1] http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n\nI welcome comments on *anything* including any of the above, or volunteers \nto take a stab at:\n1) Feel like writing up an instance of linking a P3P policy with an XFORM \n(xlink?), SOAP message or WSDL definition?\n2) Writing text for one of the chunks?\n\nFor any examples or schemas that we use, I'd like to accept those as \ndiscrete self-validating files [1]. I've previously written a python script \nthat when given a XML PI (processing instruction) can then take an excerpt \nfrom a remote XML file and include it in the spec. That way we don't have \nto maintain examples in the spec and as seperate files, with errors \ncreaping into each, but particularly those in the spec.\n\n[2] http://lists.w3.org/Archives/Public/spec-prod/2003JanMar/0007.html\n\n\n\n", "id": "lists-017-4840322"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nI got some comments about the \"chunks\" that we'll want to \naddress. I am still trying to catch up with you guys' work\nin the P3P working group. :-)\n\nPlease let me try to describe a scenario as follows:\n\nA Web services \"requestor\" (consumer or application) is looking \nfor a Web service at the UDDI or even directly consult the WSDL \ndocument of the Web service. Thus, the Web services \"provider\" \nshould put the Web service's privacy policy in both UDDI and WSDL \nlevel. After the requestor/service-locator found the Web service, \nthe requestor/service-locator would also validate with the Web \nservice's privacy policy based on the requestor's preferences and \ncheck whether the privacy policy is acceptable or not. Once the \nWeb service's privacy policy is acceptable, the requestor would \ntry to bind to the Web service. At this moment, the only way for \nthe provider to understand/know the requestor's privacy policy is \nthrough the SOAP message. By any mean, the provider has the right \nto accept/reject the SOAP request if the requestor's privacy policy \nis/is-not acceptable with the providor's preferences. \n\nIf we agree such an scenario, the first task for us is to check \nthe research issues in the existing UDDI, WSDL, and SOAP. Here\nare some of my primitive thoughts...\n\nUDDI\n====\nI think we should have privacy policies defined in the <businessEntity/>\nand/or <businessService/>. If so, we may also have to look into those \nrelated XML languages for finding the Web services in UDDI, e.g., Web \nService Inspection Language (WSIL) in the future.\n------------------------------------------------------------------------\n\nSOAP\n====\nYes, the privacy policy or compact policy file should be specified in \nthe SOAP header.\n------------------------------------------------------------------------\n\nWSDL\n====\nA new attribute, say policyref=\"URI Reference\" such as the idea of \n<Policy-Ref/> in P3P, is needed in the <definitions /> element or we \ncan propose a new element <privacy/> in the WSDL document. However, \nI would perfer to make it as an attribute. For instance, this \n***policyref*** can be referenced to a P3P policy, a P3P compact policy, \nor even a P3P-based WS-Privacy policy (?) in the future.\n\nReferring to the WSDL specification, \"WSDL has four transmission primitives \nthat an endpoint can support: \n\n(1) One-way. The endpoint receives a message. \n(2) Request-response. The endpoint receives a message, and sends a \n                      correlated message. \n(3) Solicit-response. The endpoint sends a message, and receives a \n                      correlated message. \n(4) Notification. The endpoint sends a message.\"\n\nReferring to the scenario described above, does it mean that the WSDL can\nnot \nsupport (1) because the requestor has no way to know whether the provider is\n\nhappy or not about the requestor's privacy policy based on the provider's \npreferences? If so, what should we do?\n--------------------------------------------------------------------------\n\n\nIn particular, we need more thoughts/ideas about the requirement AR020.5\nin the \"Web Services Architecture Requirements\" in an intermediary scenario\nor I would like to name it as a loosely coupled Web services execution\nscenario.\nBeside the S030 Third party intermediary scenario of the Web Services\nArchitecture \nUsage Scenarios, AR020.6 is strongly related to workflow/business process\nintegration \nissues. I am currently thinking about it...\n\nHowever, I have some trouble with the requirement \"AR020.6: Web Services\nmust not \nbe precluded from supporting interactions where one or more parties of the \ninteraction are anonymous.\" This may work in some cases. However, those\nsecurity\ntokens WS-Security and SAML are mainly designed for authentication. Thus, is\nthere any conflict between AR020.6 and Web services security? It may be much\nclearer\nand useful if there is a few examples to demonstrate the importance of\nAR020.6.\n\n\nThere are two typos in the draft:\n\n(1) Referring to the \"The Movement of Information\" section:\n    data propogation \n             ^ -> propagation \n        \n    policy propogation \n               ^ -> propagation\n\n    preference propogation \n                   ^ -> propagation\n\n(2) The p3p:RECIPIENT Value and Data/Preference Progrogation\n                                                ^^^^^^^^^^^^ -> Propagation?\n\n\n\nReferring to the \"Scope and Bindings (HTTP and SOAP)\" section, it would\nbe more precise to say that \"For example, a browser-interfaced application\nthat transfers data with SOAP over HTTP that uses cookies,...\" instead of \n\"For example, an application that transfers data with SOAP over HTTP that \nuses cookies, ...\"\n\nFurther, I would believe that \"there are distinct P3P policies associated \nwith the SOAP and HTTP layers.\" because these are belonging to two layers: \nthe SOAP message is on the application layer and the HTTP protocol is on \nthe transport layer.\n\nAnyway, please tell me what do you think about them? In particular, I am\ninterested in writing up an instance of linking a P3P policy with SOAP and\nWSDL in the sections of \"Scope and Bindings (HTTP and SOAP)\" and\n\"Associating \nwith a WSDL Description.\"\n\nThanks and talk to you soon.\n\nPatrick.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Saturday, 26 April 2003 6:29 AM\nTo: public-p3p-spec@w3.org\nSubject: [BH] First (Very Rought) Outline of Beyond HTTP\n\n\n\n\nAs stated, I've tried to put together an outline [1] that hopefully gives a \nsense of the goals, the scenario, and the \"chunks\" that we'll want to \naddress.\n\n[1] http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n\nI welcome comments on *anything* including any of the above, or volunteers \nto take a stab at:\n1) Feel like writing up an instance of linking a P3P policy with an XFORM \n(xlink?), SOAP message or WSDL definition?\n2) Writing text for one of the chunks?\n\nFor any examples or schemas that we use, I'd like to accept those as \ndiscrete self-validating files [1]. I've previously written a python script \nthat when given a XML PI (processing instruction) can then take an excerpt \nfrom a remote XML file and include it in the spec. That way we don't have \nto maintain examples in the spec and as seperate files, with errors \ncreaping into each, but particularly those in the spec.\n\n[2] http://lists.w3.org/Archives/Public/spec-prod/2003JanMar/0007.html\n\n\n\n", "id": "lists-017-4856738"}, {"subject": "draft backwards compatibility guideline", "content": "Here is a draft of the backwards compatibility guidelines I was \nactioned to document on yesterday's conference call. Please send your \ncomments and feedback. I would like to try reach closure on these (or \nan amended version of these) at our conference call next wednesday and \ndocument that it is the consensus of the working group to follow them.\n\nLorrie\n\n\n\nBACKWARDS COMPATIBILITY GUIDELINES\n\nThe (draft) P3P 1.1 working group charter states \"The P3P 1.1\nSpecification should be designed for backwards compatibility with the\nP3P 1.0 Specification.\" Here are some details of what this means\nand how we will apply this as the working group goes about its\nbusiness. This is not intended to be a comprehensive or absolute set\nof requirements, but rather a set of guidelines to help the group\nwork towards a common goal. Working group members should keep these\nguidelines in mind when making proposals to the working group and\navoid proposals inconsistent with these guidelines.\n\n- P3P 1.0 user agents should be able to process P3P 1.1 policies and\n   policy reference files. This implies both that the P3P 1.1 policies\n   and policy reference files are fully compliant with the P3P 1.0 XML\n   schema, and that the semantics of these files will not be\n   misinterpreted by a user agent that interprets them according to\n   the P3P 1.0 specification.\n\n- New vocabulary elements and syntax introduced in P3P 1.1 should be\n   introduced as optional extensions using the P3P 1.0 extension\n   mechanism.\n\n- New or changed P3P HTTP headers that are not backwards-compatible\n   with P3P 1.0 should use a new prefix to differentiate them from\n   those used in P3P 1.0. They should be designed such\n   that sites that wish to make their P3P headers accessible to both\n   P3P 1.0 and P3P 1.1 user agents can include both the P3P 1.0 and P3P\n   1.1 headers.\n\n- Changes to requirements or definitions introduced in P3P 1.1. should\n   add clarity where the P3P 1.0 specification is ambiguous, but should\n   not cause a particular P3P vocabulary element to have different\n   meanings in P3P 1.0 and P3P 1.1.\n\n- New requirements or features may be introduced in the P3P 1.1\n   specification if they do not impact the ability of P3P 1.0 user\n   agents to process P3P 1.1 policies and policy reference files. For\n   example, a feature that would enable P3P policies to be referenced\n   from arbitrary XML documents would not impact P3P 1.0 user agents,\n   since those user agents do not attempt to find P3P policy references\n   in arbitrary XML documents. Of course, P3P 1.0 user agents are not\n   expected to comply with new requirements introduced in P3P 1.1.\n\n- Features, vocabulary elements, or requirements may be removed in\n   the P3P 1.1 specification as long as they do not cause a P3P 1.0\n   user agent to be unable to process a P3P 1.1 policy or policy\n   reference file.\n\n\n\n", "id": "lists-017-4872081"}, {"subject": "[Minutes] of the 30 April 2003 WG Cal", "content": "Minutes\n\n1. Update on P3P 1.1 chartering - Rigo \n   Rigo reported: The 1.1 charter is uncontroversial (surprise) and is now\n   in wait-state on W3CM (management), with no conditions (yet).\n   URL: http://www.w3.org/P3P/Group/Specification/1.1/01-spec-charter.html\n\n2. Task force reports -- chairs please comment or ammend as needed\n   - P3P beyond HTTP - Joseph\n   Joseph reported:  Chunks posted and may schedule teleconference,\nwill list five pending if prompted. Rigo intends to comment\nthat the Joseph/Patrick exchanges are too focused on web\nservices. Joseph discussed forms and other applications, e.g.,\nPROVREG (IETF). Eric commented on the distinction between\nonward-transport (EPP) and initial data collection (P3P).\nRigo responded to question on \"personal\" vs \"not\" signaling\n(IETF/EPP/WHOIS, aka \"recipient-only\" context), mentioning\nItaly and Greece where corporate and personal may be same.\n\n   - User agent behavior - Lorrie\n   Lorrie reported:  Disapointing teleconference, will schedule again\nthis week. Comments on the translation document are sought.\nUsability testing at AT&T, Lorrie reports that some data from\na study using both PB and IE is forthcoming, and called for\nany additional study data.\n\n   - Compact policies - Lorrie (Brian Zwit unavailable)\n   Lorrie reported:  Work will start real soon now.\n\n   - Article 10 vocabulary issues - Giles Hogben\n   Giles reported:  Meeting scheduled for the 22nd or 23rd, with a\nteleconference scheduled first, followed by a face-to-face,\nin Italy.\n\n   - Agent and domain relaitonships - Jack Humphrey\n   Jack reported:  Teleconference last week with good participation\n(list of participants omitted). Minutes pending.\nAction item to enhance entity declarations to disclose \"same\nor agents\".  Compact policy interaction noted. Jurisdictional\nlink to vocabulary noted. Eric commented on j19n in CPEX, with\nnote to list to follow.\n\n   - Consent choices - Matthias Schunter\n   Matthias absent.\n\n   - Converting P3P data schema to XML schema - Giles Hogben\n   Giles reported:  Some comments received from Joseph, fundamental\nones from Massimo, compatibility a concern.\nLively discussion of format(s), constituencies for format(s),\nlocus of transformation(s), backwards compatibility (can a\nP3Pv1.0 UA read and process w/o error a P3Pv1.1 policy?)\nAction item to Lorrie to write a statement of principles and\nlimits for P3Pv1.1.\n\n   - Signed P3P policies  - Giles Hogbe\n   Giles reported:  ? (I had to take a business call that lasted a\nwhole minute, and by the time I got back, we were on to next\nitem. Eric)\n\n4. Set date of next conference call (May 7 or 21)\n \n    Next calls will be 07 and 28 May 2003, more information on the meetings\n    page\n\n3. Review current bugzilla list - Lorrie\n           Lorrie reported:\n           141 and 144 are typos (Massimo)\n           167 explaination of identified, identifiable, and linked (Ari)\n           168 human-readable explanation\n   169 statement grouping mechanism\n   170 Expand CONSEQUENCE\n   171 standardize STATEMENT name attribute based on IBM extension\n   172 clarify what we mean by data linked to a cookie\n   173 guidelines for verifying sites with CPs are properly P3P\n   174 strengthen 2.3.2.7 user agent requirements\n   178 add mention of zip code, state, or region to demographic\n\n    - Please register for bugzilla -- You can use the interface at\n    http://www.w3.org/Bugs/Public/query.cgi to get a list of all P3P\n    open issues\n\n    N.B. I registered for bugzilla during the call, simultanious with this\n    item, without problem. Don't forget to select \"p3p\" as the value in the\n    \"Product\" portion of the query interface.\n\nEnd of minutes.\n\nEric\n\n\n\n", "id": "lists-017-4882098"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Thursday 01 May 2003 02:34, Patrick.Hung@csiro.au wrote:\n> Please let me try to describe a scenario as follows:\n\nHi Patrick, I think I have the gist of your scenario though I'm a little \nconfused by some of the terminology. For example, I would think that the \n\"requestor\" would have privacy *preferences\" and the others would have \n*policies*. This has caused me to work some more on the definitions \n(including looking at [1]) and perhaps we could speak in terms of User \n(registrant), Soliciting Service (registrar), and a Recipeint Service \n(registry)?\n\n[1] http://www.w3.org/TR/2002/WD-ws-gloss-20021114/\n\nI think the difference is you also included the UDDI component to the \nscenario.\n\n> UDDI\n\nI think a UDDI scenario is useful, but it's not my top priority and I'm not \nquite sure how to include with sensible motivation in our present DNS \nregistry scenario. But that can change!\n\n> Referring to the WSDL specification, \"WSDL has four transmission\n> primitives that an endpoint can support:\n>\n> (1) One-way. The endpoint receives a message.\n> (2) Request-response. The endpoint receives a message, and sends a\n>                       correlated message.\n> (3) Solicit-response. The endpoint sends a message, and receives a\n>                       correlated message.\n> (4) Notification. The endpoint sends a message.\"\n>\n> Referring to the scenario described above, does it mean that the WSDL can\n> not\n> support (1) because the requestor has no way to know whether the provider\n> is\n> happy or not about the requestor's privacy policy based on the provider's\n> preferences? If so, what should we do?\n\nIf an endpoint can advertise its privacy policy and presume any message \ntransmitted to it will have seen that policy, I presume it could accept \nsuch a message without sending a response. (This is akin to earlier debates \nin P3P as to whether a unique policy identifier could be associated with a \nrequest in order to avoid a round trip I think...) \n\n> However, I have some trouble with the requirement \"AR020.6: Web Services\n> must not be precluded from supporting interactions where one or more\n> parties of the interaction are anonymous.\" This may work in some \n> cases. However, those security tokens WS-Security and SAML are \n> mainly designed for authentication. Thus, is there any conflict between\n> AR020.6 and Web services security?\n\nNo. I'm a big fan of \"not precluded\"; it means that while authenticated \ninteractions are possible, and even encouraged, it should be *possible* \narchitecturally for someone to not be authenticated.\n\n> There are two typos in the draft:\n\nFixed.\n\n\n> Referring to the \"Scope and Bindings (HTTP and SOAP)\" section, it would\n> be more precise to say that \"For example, a browser-interfaced\n> application that transfers data with SOAP over HTTP that uses\n> cookies,...\" instead of \"For example, an application that transfers data\n> with SOAP over HTTP that uses cookies, ...\"\n\nWhat do you mean by \"browser-interfaced\" and why is that necessary?\n\n> Further, I would believe that \"there are distinct P3P policies associated\n> with the SOAP and HTTP layers.\" because these are belonging to two\n> layers: the SOAP message is on the application layer and the HTTP\n> protocol is on the transport layer.\n\nYes, but the adopting application (e.g., DNS registration) has the ability \nto profile it's dependencies. So it could say, \"the only normative P3P \nsemantics associated with *this* application (DNS registration web service) \nare those associated with the SOAP binding.\" \nOne might be able to say a number of things:\n1. the SOAP transport MUST be HTTP \"origin server\" and the SOAP \"ultimate \nreceiver\" (the service receiving the data) are one and the same so:\na. the P3P policy must only be bound to the SOAP message.\nb. a P3P policy will be bound to the message and its transport and both are \nnormative policies on behalf of the \"origin server\"/\"ultimate receiver\"\n2. the SOAP transport is unspecified (HTTP or SMTP)\na ...\nb ...\n...\n\nRegardless, we're now in the complex space of \"choreography\" nearly, which \nwill be incomprehensible to users, and difficult for engineers even. (P3P \nnever took on the fact that my HTTP requests might be going through a proxy \nserver and how do I distinguish between the proxy server policies and the \norigin server policies?) So my sense continues to be that we should \nidentify some of the issues, but otherwise argue that it's an application's \nspecification that must specify how policies are associated with the \ninteractions of that application and we recommend they keep it simple and \n\"higher up.\"\n\n> Anyway, please tell me what do you think about them? In particular, I am\n> interested in writing up an instance of linking a P3P policy with SOAP\n> and WSDL in the sections of \"Scope and Bindings (HTTP and SOAP)\" and\n> \"Associating\n> with a WSDL Description.\"\n\nPlease do! I'm going to try to put together an XML instance/example of \nassociating a the P3P policy with the actual user solicitation via  XForms.\n\n\n\n", "id": "lists-017-4892699"}, {"subject": "BDS in XML Schem", "content": "I attach an xslt for converting policies expressed in XSD format back to the\nold format. It is quite short actually. The one which would be almost\nimpossible to do would be converting new schemas back to old schema format.\nBut having thought this one over, I came to the conclusion that no-one would\nwant to do such a thing. If they have written a schema in the new format,\nnobody will need it in the old format since that was pretty much useless in\nany case. Am I right?\n\nYou can try it out on the results of the forwards transform I have also\nattached\n\nRegards\n\nGiles_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\nVia Enrico Fermi 1\n21020 Ispra,   Italy\n\n\n\n\ntext/xml attachment: p3ptransformbackwards.xsl\n\ntext/xml attachment: forwardresult.xml\n\n\n\n\n", "id": "lists-017-4905879"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nI am still catching up with you guys' accent in this research area. :-)\n\n> Hi Patrick, I think I have the gist of your scenario though I'm a little ?\n> confused by some of the terminology. For example, I would think that the \n> \"requestor\" would have privacy *preferences\" and the others would have \n> *policies*. This has caused me to work some more on the definitions \n> (including looking at [1]) and perhaps we could speak in terms of User \n> (registrant), Soliciting Service (registrar), and a Recipeint Service \n> (registry)?\n\nOops... Yes, you are correct. I was thinking those issues NOT based in the \ncontext of the Domain Name Service (DNS) registration example described in \nthis document. I have to switch my mind to this example only... :-)\n\n> I think a UDDI scenario is useful, but it's not my top priority and I'm\nnot \n> quite sure how to include with sensible motivation in our present DNS \n> registry scenario. But that can change!\n\nYes, I agree with you. Referring to this DNS registration scenario, the UDDI\n\nissues are not in the top priority.\n\n> If an endpoint can advertise its privacy policy and presume any message \n> transmitted to it will have seen that policy, I presume it could accept \n> such a message without sending a response. (This is akin to earlier\ndebates \n> in P3P as to whether a unique policy identifier could be associated with a\n\n> request in order to avoid a round trip I think...) \n\nI was thinking a scenario of mutual privacy validation process, e.g., both\nregistrant\nand registrar have to check each other privacy policies based on their\npreferences.\nAnyway, this is not the scenario as discussed here.\n\n> No. I'm a big fan of \"not precluded\"; it means that while authenticated \n> interactions are possible, and even encouraged, it should be *possible* \n> architecturally for someone to not be authenticated.\n\nReferring to this DNS registration scenario, \"not precluded\" is fine. I am\nthinking that it may not be ok in other scenario.\n\n> What do you mean by \"browser-interfaced\" and why is that necessary?\n\nReferring to \"2.8 S030 Third party intermediary - 2.8.2 Description,\" it\nsays\nthat \"The buyer may be as simple as a browser or as complex as a procurement\n\napplication.\" In this DNS registration scenario, most likely, the registrant\n\nis using a browser to interact with the registrar. Thus, \"using cookies\" is\ndefinitely feasible and applicable.\n\n> Yes, but the adopting application (e.g., DNS registration) has the ability\n\n> to profile it's dependencies. So it could say, \"the only normative P3P \n> semantics associated with *this* application (DNS registration web\nservice) \n> are those associated with the SOAP binding.\" \n> One might be able to say a number of things:\n> 1. the SOAP transport MUST be HTTP \"origin server\" and the SOAP \"ultimate \n> receiver\" (the service receiving the data) are one and the same so:\n> a. the P3P policy must only be bound to the SOAP message.\n> b. a P3P policy will be bound to the message and its transport and both\nare \n> normative policies on behalf of the \"origin server\"/\"ultimate receiver\"\n> 2. the SOAP transport is unspecified (HTTP or SMTP)\n> a ...\n> b ...\n> ...\n\nYep, I got what you mean.\n\n> Please do! I'm going to try to put together an XML instance/example of \n> associating a the P3P policy with the actual user solicitation via\nXForms.\n\nI will start to write up the chunks in the context of DNS registration\nscenario.\n\nAnother typo in the document:\n\nRecipient Service (registry) \nA Web Service that offers an interface to registrars for registering and\nmaintaining \ndomain name registrations. The registry is the participan responsible for\nmanaging \n                                                         ^ *participant*\nthe database for a DNS Top-Level Domain (TLD) such as \".com\". This service\nhas privacy \npolicies as well.\n\nDo you have any timeline for this document? Maybe, we should have a\nconference call\nfor this task force after we have more content in those chunks.\n\nThanks and talk to you later,\n\nPatrick.\n\n\n\n", "id": "lists-017-4914503"}, {"subject": "Re: BDS in XML Schem", "content": "On Friday 02 May 2003 05:36, Giles Hogben wrote:\n> I attach an xslt for converting policies expressed in XSD format back to\n> the old format. It is quite short actually. The one which would be almost\n> impossible to do would be converting new schemas back to old schema\n> format. But having thought this one over, I came to the conclusion that\n> no-one would want to do such a thing. If they have written a schema in\n> the new format, nobody will need it in the old format since that was\n> pretty much useless in any case. Am I right?\n\nI think so, and the transform works for me!\n\n<DATA-GROUP>\n&#xA0;&#xA0;            <data ref=\"#dynamic.clickstream\"><CATEGORIES> \n<demographic/> </CATEGORIES></data>\n&#xA0;&#xA0;            <data ref=\"#dynamic.clickstream.hhhh\"><CATEGORIES> \n<haemographic/> </CATEGORIES></data>\n&#xA0;&#xA0;            <data ref=\"#dynamic.http.xyz\"/>\n</DATA-GROUP>\n\n\n\n", "id": "lists-017-4926659"}, {"subject": "[BH] Added more on definitions, patters, and XLin", "content": "The XLink text...\n\nhttp://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n$Revision: 1.8 $ on $Date: 2003/05/02 21:39:34 $ GMT by $Author: reagle $\n\n...\nSoliciting Data from the User\n\n   [P3P] provides four mechanisms for indicating the privacy policy of a\n   site, the policy reference file\n\n    1. may be located in a predefined \"well-known\" location, or\n    2. a document may indicate a policy reference file through an HTML\n       link tag, or\n    3. a document may indicate a policy reference file through an XHTML\n       link tag, or\n    4. through an HTTP header.\n\n   Adopting applications that rely upon a data format other than (X)HTML\n   to solicit information SHOULD support the first and fourth mechanisms\n   under the presumption that it is not possible that a user agent will\n   mistakenly release information to an application it is not familiar\n   with on the basis of [P3P] mechanisms that it is. Adopting\n   applications MAY provide a means of associating a a policy reference\n   file with their own format.\n\n  XForms and Associating an XML Instance with a [P3P] Policy\n\n   [XForms] is a powerful means of soliciting information in a form,\n   validating that information and sending the result to a service.\n   [XForms] is expected to be adopted by [XHTML2] which itself includes a\n   link tag. Consequently:\n     * A future version of P3P SHOULD include the [XHTML2] link element\n       as a recognized indicator of a policy reference file, as is\n       already done for [XHTML] in [P3P, section2.2.4 The XHTML link tag]\n   However, the exact specification of the [XHTML2] link element has not\n   yet been resolved. Originally, [XHTML2] defined a link element in its\n   own namespace. However that community is now considering the\n   requirements and features of [XLink] in the [XHTML2] context.\n   Applications other than [XHTML2] will also be able to take advantage\n   of [XForms], or different solicitation mechanisms, and MAY also define\n   their own indication mechanisms. If they do so, such applications\n   SHOULD follow the results of the [XHTML2] and [XLink] discussion. In\n   any case, applications using version \"1.0\" of [P3P] should employ the\n   resulting link tag by\n     * setting its rel attribute to \"P3Pv1\"\n     * setting its href attribute to the URI of the relevant [P3P] policy\n       reference file\n\n\n\n", "id": "lists-017-4934657"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nDo you want to say something?\n\nPatrick.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Friday, 2 May 2003 6:33 AM\nTo: Patrick.Hung@csiro.au; public-p3p-spec@w3.org\nSubject: Re: [BH] First (Very Rought) Outline of Beyond HTTP\n\n\n\nOn Thursday 01 May 2003 02:34, Patrick.Hung@csiro.au wrote:\n> Please let me try to describe a scenario as follows:\n\nHi Patrick, I think I have the gist of your scenario though I'm a little \nconfused by some of the terminology. For example, I would think that the \n\"requestor\" would have privacy *preferences\" and the others would have \n*policies*. This has caused me to work some more on the definitions \n(including looking at [1]) and perhaps we could speak in terms of User \n(registrant), Soliciting Service (registrar), and a Recipeint Service \n(registry)?\n\n[1] http://www.w3.org/TR/2002/WD-ws-gloss-20021114/\n\nI think the difference is you also included the UDDI component to the \nscenario.\n\n> UDDI\n\nI think a UDDI scenario is useful, but it's not my top priority and I'm not \nquite sure how to include with sensible motivation in our present DNS \nregistry scenario. But that can change!\n\n> Referring to the WSDL specification, \"WSDL has four transmission\n> primitives that an endpoint can support:\n>\n> (1) One-way. The endpoint receives a message.\n> (2) Request-response. The endpoint receives a message, and sends a\n>                       correlated message.\n> (3) Solicit-response. The endpoint sends a message, and receives a\n>                       correlated message.\n> (4) Notification. The endpoint sends a message.\"\n>\n> Referring to the scenario described above, does it mean that the WSDL can\n> not\n> support (1) because the requestor has no way to know whether the provider\n> is\n> happy or not about the requestor's privacy policy based on the provider's\n> preferences? If so, what should we do?\n\nIf an endpoint can advertise its privacy policy and presume any message \ntransmitted to it will have seen that policy, I presume it could accept \nsuch a message without sending a response. (This is akin to earlier debates \nin P3P as to whether a unique policy identifier could be associated with a \nrequest in order to avoid a round trip I think...) \n\n> However, I have some trouble with the requirement \"AR020.6: Web Services\n> must not be precluded from supporting interactions where one or more\n> parties of the interaction are anonymous.\" This may work in some \n> cases. However, those security tokens WS-Security and SAML are \n> mainly designed for authentication. Thus, is there any conflict between\n> AR020.6 and Web services security?\n\nNo. I'm a big fan of \"not precluded\"; it means that while authenticated \ninteractions are possible, and even encouraged, it should be *possible* \narchitecturally for someone to not be authenticated.\n\n> There are two typos in the draft:\n\nFixed.\n\n\n> Referring to the \"Scope and Bindings (HTTP and SOAP)\" section, it would\n> be more precise to say that \"For example, a browser-interfaced\n> application that transfers data with SOAP over HTTP that uses\n> cookies,...\" instead of \"For example, an application that transfers data\n> with SOAP over HTTP that uses cookies, ...\"\n\nWhat do you mean by \"browser-interfaced\" and why is that necessary?\n\n> Further, I would believe that \"there are distinct P3P policies associated\n> with the SOAP and HTTP layers.\" because these are belonging to two\n> layers: the SOAP message is on the application layer and the HTTP\n> protocol is on the transport layer.\n\nYes, but the adopting application (e.g., DNS registration) has the ability \nto profile it's dependencies. So it could say, \"the only normative P3P \nsemantics associated with *this* application (DNS registration web service) \nare those associated with the SOAP binding.\" \nOne might be able to say a number of things:\n1. the SOAP transport MUST be HTTP \"origin server\" and the SOAP \"ultimate \nreceiver\" (the service receiving the data) are one and the same so:\na. the P3P policy must only be bound to the SOAP message.\nb. a P3P policy will be bound to the message and its transport and both are \nnormative policies on behalf of the \"origin server\"/\"ultimate receiver\"\n2. the SOAP transport is unspecified (HTTP or SMTP)\na ...\nb ...\n...\n\nRegardless, we're now in the complex space of \"choreography\" nearly, which \nwill be incomprehensible to users, and difficult for engineers even. (P3P \nnever took on the fact that my HTTP requests might be going through a proxy \nserver and how do I distinguish between the proxy server policies and the \norigin server policies?) So my sense continues to be that we should \nidentify some of the issues, but otherwise argue that it's an application's \nspecification that must specify how policies are associated with the \ninteractions of that application and we recommend they keep it simple and \n\"higher up.\"\n\n> Anyway, please tell me what do you think about them? In particular, I am\n> interested in writing up an instance of linking a P3P policy with SOAP\n> and WSDL in the sections of \"Scope and Bindings (HTTP and SOAP)\" and\n> \"Associating\n> with a WSDL Description.\"\n\nPlease do! I'm going to try to put together an XML instance/example of \nassociating a the P3P policy with the actual user solicitation via  XForms.\n\n\n\n", "id": "lists-017-4943420"}, {"subject": "Re: BDS in XML Schem", "content": "On Friday, May 2, 2003, at 05:36  AM, Giles Hogben wrote:\n\n> I attach an xslt for converting policies expressed in XSD format back \n> to the\n> old format. It is quite short actually. The one which would be almost\n> impossible to do would be converting new schemas back to old schema \n> format.\n> But having thought this one over, I came to the conclusion that no-one \n> would\n> want to do such a thing. If they have written a schema in the new \n> format,\n> nobody will need it in the old format since that was pretty much \n> useless in\n> any case. Am I right?\n>\n\nNow I am confusing the different formats... what is the difference \nbetween \"old format\" and \"old schema format\" ?\n\nLorrie\n\n\n\n", "id": "lists-017-4958025"}, {"subject": "Re: BDS in XML Schem", "content": "Sorry!\nMy terminology is getting confused now we're dealing with Schemas and \ninstances of them.\n\nThe old schema format means the Base Data Schema P3P 1.0.\nThe files were to convert instances of the new (XSD compliant) schema \nto the BDS 1.0 compliant format.\n\n----- Original Message -----\nFrom: Lorrie Cranor <lorrie@research.att.com>\nDate: Monday, May 5, 2003 4:28 am\nSubject: Re: BDS in XML Schema\n\n> \n> \n> On Friday, May 2, 2003, at 05:36  AM, Giles Hogben wrote:\n> \n> > I attach an xslt for converting policies expressed in XSD format \n> back \n> > to the\n> > old format. It is quite short actually. The one which would be \n> almost> impossible to do would be converting new schemas back to \n> old schema \n> > format.\n> > But having thought this one over, I came to the conclusion that \n> no-one \n> > would\n> > want to do such a thing. If they have written a schema in the \n> new \n> > format,\n> > nobody will need it in the old format since that was pretty much \n> > useless in\n> > any case. Am I right?\n> >\n> \n> Now I am confusing the different formats... what is the difference \n> between \"old format\" and \"old schema format\" ?\n> \n> Lorrie\n> \n> \n> \n\n\n\n", "id": "lists-017-4965886"}, {"subject": "p3p spec working group call May ", "content": "The next P3P specification group conference call will be on\nWednesday, May 7, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Update on P3P 1.1 chartering (Rigo)\n\n\n2. Task force reports\n    - P3P beyond HTTP - Joseph Reagle\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n\n3. Discussion of draft backwards compatibility guidelines\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003May/0002.html\n\n\n4. Discuss bugzilla 171\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=171\n\nThe IBM P3P Policy Editor defines a P3P extension to assign a name\nattribute to the STATEMENT element. This is useful for the editor\nitself, but it has also proven useful for user agents when they\ndisplay policy summaries to users. We should consider making this\nextension an \"official\" part of the P3P specification -- probably by\nreferencing the extension in v1.1 and turning it into a regular\nattribute (without using the extension mechanism ) in future versions.\n\n\n5. Discuss bugzilla 178\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=178\n\nConsider including mention of postal code, state, or region\ninformation, etc. in definition of the demographic category in section\n3.4\n\n\nOur next call will be on May 28\n\n\n\n", "id": "lists-017-4974236"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Friday 02 May 2003 05:39, Patrick.Hung@csiro.au wrote:\n> Do you have any timeline for this document? Maybe, we should have a\n> conference call\n> for this task force after we have more content in those chunks.\n\nI hope to have something cogent by the end of next week. Something that the \ntask force is happy with by the end of May. June to get external web \nservice and \"adopting application\" feedback, and the the documents itself \nis due in July.\n\n\n\n", "id": "lists-017-4982515"}, {"subject": "RE: draft backwards compatibility guideline", "content": "Hi Lorrie,\nHere are some comments on the compatibility guidelines.\n\n\nHere is a draft of the backwards compatibility guidelines I was\nactioned to document on yesterday's conference call. Please send your\ncomments and feedback. I would like to try reach closure on these (or\nan amended version of these) at our conference call next wednesday and\ndocument that it is the consensus of the working group to follow them.\n\nLorrie\n\n\n\nBACKWARDS COMPATIBILITY GUIDELINES\n\nThe (draft) P3P 1.1 working group charter states \"The P3P 1.1\nSpecification should be designed for backwards compatibility with the\nP3P 1.0 Specification.\" Here are some details of what this means\nand how we will apply this as the working group goes about its\nbusiness. This is not intended to be a comprehensive or absolute set\nof requirements, but rather a set of guidelines to help the group\nwork towards a common goal. Working group members should keep these\nguidelines in mind when making proposals to the working group and\navoid proposals inconsistent with these guidelines.\n\n- P3P 1.0 user agents should be able to process P3P 1.1 policies and\n   policy reference files. This implies both that the P3P 1.1 policies\n   and policy reference files are fully compliant with the P3P 1.0 XML\n   schema, and that the semantics of these files will not be\n   misinterpreted by a user agent that interprets them according to\n   the P3P 1.0 specification.\n\n**Perhaps this is more restrictive than it needs to be. As no existing user\nagents do compulsary schema validation, it is unlikely that any problems\nwould be caused by adding attributes and maybe even not by adding elements.\nI admit it is conceivable but we could easily ascertain if it were the case.\n\nAlso it does not cover the case that we discussed last week for XML Schema\nData Schema where two alternatives are offered one of which would break\nexisting technology but the newer one is only sent to newer agents (that's\nhow I understood it anyway). I don't see that covered here.\n\n\n- New vocabulary elements and syntax introduced in P3P 1.1 should be\n   introduced as optional extensions using the P3P 1.0 extension\n   mechanism.\n\n- New or changed P3P HTTP headers that are not backwards-compatible\n   with P3P 1.0 should use a new prefix to differentiate them from\n   those used in P3P 1.0. They should be designed such\n   that sites that wish to make their P3P headers accessible to both\n   P3P 1.0 and P3P 1.1 user agents can include both the P3P 1.0 and P3P\n   1.1 headers.\n\n- Changes to requirements or definitions introduced in P3P 1.1. should\n   add clarity where the P3P 1.0 specification is ambiguous, but should\n   not cause a particular P3P vocabulary element to have different\n   meanings in P3P 1.0 and P3P 1.1.\n\n**What if we decide it was simply wrong and want to change something?\n\n- New requirements or features may be introduced in the P3P 1.1\n   specification if they do not impact the ability of P3P 1.0 user\n   agents to process P3P 1.1 policies and policy reference files.\n\n**This seems to be a repetition of the first point. Or have I missed\nsomething.\n\n For\n   example, a feature that would enable P3P policies to be referenced\n   from arbitrary XML documents would not impact P3P 1.0 user agents,\n   since those user agents do not attempt to find P3P policy references\n   in arbitrary XML documents. Of course, P3P 1.0 user agents are not\n   expected to comply with new requirements introduced in P3P 1.1.\n\n\n\n- Features, vocabulary elements, or requirements may be removed in\n   the P3P 1.1 specification as long as they do not cause a P3P 1.0\n   user agent to be unable to process a P3P 1.1 policy or policy\n   reference file.\n\n\n\n", "id": "lists-017-4990539"}, {"subject": "Rationale for XML Digital Signatur", "content": "Here's a short justification for XML Dig Sigs. Any comments?\n\n------------------------------------\nRationale for XML Digital Signature.\n------------------------------------\n\nIt offers a \"visible\" sign of commitment to the privacy policy. Transparency\nis all very well but many people see P3P policies as empty statements which\nare simply posted \"to make Internet Explorer work\". A digitally signed seal\nof approval offers users a more watertight legal route in the case of\ndispute and perhaps more importantly, gives companies an opportunity to \"put\ntheir money where their mouth is\" and thereby to differentiate themselves\nfrom other organisations.\n\nThe impact of including this possibility in the specification would not be\ntoo great. The only necessary elements would be a simple url type attribute\nin a policy and a specification for policies which we almost have already.\nIt could therefore be included to see what uptake there might be.\n\nIn a sense this has been done already, but I think that people cannot be\nable to take up this suggestion without it being made a bit clearer with\nexamples or a perhaps a java toolkit/web service for XML signing a policy\nand prf.\n\n\nGiles\n\n\n\n", "id": "lists-017-5001533"}, {"subject": "Re: draft backwards compatibility guideline", "content": "All, \n\nif anything comes up that doesn't fit (and before deadline) think of\nsubmitting it to the P3P 2.0 Workshop in Kiel\n\nhttp://www.w3.org/2003/p3p-ws/\n\nRigo\n\nOn Thu, May 01, 2003 at 10:04:25AM -0400, Lorrie Cranor wrote:\n> \n> Here is a draft of the backwards compatibility guidelines I was \n> actioned to document on yesterday's conference call. Please send your \n> comments and feedback. \n\n\n\n", "id": "lists-017-5009667"}, {"subject": "Re: BDS in XML Schem", "content": "They are linked from the documents-page now\nhttp://www.w3.org/P3P/1.1/documents.html\n\nRigo\n\nOn Fri, May 02, 2003 at 11:36:46AM +0200, Giles Hogben wrote:\n> I attach an xslt for converting policies expressed in XSD format back to the\n> old format. It is quite short actually. The one which would be almost\n\n\n\n", "id": "lists-017-5016629"}, {"subject": "Re: Rationale for XML Digital Signatur", "content": "On Tuesday 06 May 2003 12:11, Giles Hogben wrote:\n> It offers a \"visible\" sign of commitment to the privacy policy.\n\nIt does, and in as far as that happens that is a good thing. However, I have \ntwo comments:\n1. Would it lead to the presumption that a unsigned P3P policy is somehow \nless committed to or binding?\n2. Who exactly is validating the signature? This isn't something users are \nlikely to comprehend or be able to easily do. (How is it that they are \ngetting the service's public key for the validation, this presumes a level \nof infrastructure and knowledge which is not yet present.)\n\nSo I think a signed privacy is a nice exercise, but don't find it that \ncompelling in the b2c scenario and might weaken the interpretation of a \nunsigned policy.\n\n\n\n", "id": "lists-017-5023616"}, {"subject": "Re: Rationale for XML Digital Signatur", "content": "On Tue, May 06, 2003 at 12:52:03PM -0400, Joseph M. Reagle Jr. wrote:\n> 1. Would it lead to the presumption that a unsigned P3P policy is somehow \n> less committed to or binding?\n\nI don't think by adding non-repudiation to a P3P Policy one reduces the\nmeaning or value of a non-signed policy. The signature does not add\nmeaning to the policy. It is only a question of evidence.\n\n> 2. Who exactly is validating the signature? This isn't something users are \n> likely to comprehend or be able to easily do. (How is it that they are \n> getting the service's public key for the validation, this presumes a level \n> of infrastructure and knowledge which is not yet present.)\n\nThat's actually a good question. I would _love_ to see native XML\nSignature support in browsers to be able to sign XHTML-pages (for courts\nand laws e.g.). But I agree, we are far from there.\n> \n> So I think a signed privacy is a nice exercise, but don't find it that \n> compelling in the b2c scenario and might weaken the interpretation of a \n> unsigned policy.\n\nIt might create yet another incentive to implement XML Sig into an\nagent. I think the signature requirement is more or less a requirement\nto be able to link old-style paper procedures with digital ones without\nto much change. (see EU-Directive on Sig that create an _equivalent_ to\nhandwritten signature)\n\nSo for me, it's a nice enhancement, but not a must be. In fact, it might\nbe nice to have a common way to do signatures on policies, if there are\nmany ways to implement that. But Jo, you can tell better _if_ there are\nreally many ways..\n\nRigo\n\n\n\n", "id": "lists-017-5031707"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nJust get back to my seat for this working draft of WSDL + SOAP from other\ntasks.\n\nReferring to the \"adopting application,\" both registrar (soliciting service)\nand\nregistry (recipent service) may have their own privacy policy. Let's call\nthe\nP3P policy for Web services as WS-P3P policy. Then, the user (registrant)\nhas its\nprivacy preferences defined by the APPEL1.0 for Web services, again let's\ncall\nit as WS-APPEL1.0. When the user is trying to find the registrar (as a Web\nservice)\nand let's forget the UDDI, the user should has its \"user agent\" (whatever it\nis) to\nvalidate its privacy preferences with the registrar's WS-P3P policy. At this\nstage,\nI can easily imagine that the WS-P3P policy file can be specified in the\nregistrar's\nWSDL document. For illustration, let's take the WSDL definition of a simple\nservice providing \nstock quotes (Example 1) from the http://www.w3.org/TR/wsdl. Then, I can\nsimplicitly\ndefine the \"PolicyReferences.xml\" file as an attribute in the WSDL\n<definitions/> as\nfollows:\n\n<?xml version=\"1.0\"?>\n<definitions name=\"StockQuote\"\npolicyref=\"http://example.com/WS-P3P/PolicyReferences.xml\"\n\ntargetNamespace=\"http://example.com/stockquote.wsdl\"\n          xmlns:tns=\"http://example.com/stockquote.wsdl\"\n          xmlns:xsd1=\"http://example.com/stockquote.xsd\"\n          xmlns:soap=\"http://schemas.xmlsoap.org/wsdl/soap/\"\n          xmlns=\"http://schemas.xmlsoap.org/wsdl/\">\n...\n</definitions>\n\nYou can also imagine that the registrar can define those <INCLUDE> and\n<EXCLUDE> in the\ncontext of the element(s) in the input messsage(s) of the service(s).\n\nOnce the user's privacy preferences are all satisfied with the registrar's\nWS-P3P policy,\nthe user should try to bind with the registrar's service(s) by SOAP\nmessaging [Stage 1], no matter\nthe carrier is HTTP or SMTP. So, this is the very simple story. Up to this\nmoment, there\nis no need to specify any \"privacy\" stuff in the SOAP header??!!\n\nFurthermore, the registrar is going to pass the user's data (vis those input\nmessages)\nto the registry. As we describe before, the registry also has its own WS-P3P\nprivacy policy.\nNow we are entering the game of propagation and delegation. I think whether\nthe registrar's\nprivacy policy is the same as the registry's privacy policy, or the\nregistrar's privacy\npolicy is cover every rule in the registry's privacy policy. If not, I\n*think* the registrar\nmust validate the user's privacy preferences with the registry's privacy\npolicy before the\nregistrar pass all the user's data to the registry, right? If so, now I can\ntry to imagine\nthat you can *put* the user's privacy preferences (as a URI) in the SOAP\nheader in [Stage 1].\nAt this [Stage 2], the registrar is working like a intermediary (or the user\nagent) to\nhandle the privacy issues for the user. Further, if there is any security\ntoken (SAML or WS-Security)\nin the SOAP header, the user's preferences have also to address them. And\nmore...\n\nI will try to write all these ideas as \"chunks\" for the draft by this\nweekend.\n\nIn addition, there are a few typos in the draft:\n(1) In an intermediary scenario, data (personal information, privacy\nprivacies and preferences)\n \n^^^^^^^^^ ?????\n(2) The p3p:RECIPIENT Value and Data/Preference Prorogation\n                                                ^^^^^^^^^^^ Propagation\n\nLastly, an interesting question...\n\nAC020 \nenables privacy protection for the consumer of a Web service across multiple\ndomains and services. \nAR020.1 the WSA must enable privacy policy statements to be expressed about\nWeb services. \nAR020.2 advertised Web service privacy policies must be expressed in [P3P]\n[P3P]. \nAR020.3 the WSA must enable a consumer to access a Web service's advertised\nprivacy policy statement. \nAR020.5 the WSA must enable delegation and propagation of privacy policy. \nAR020.6: Web Services must not be precluded from supporting interactions\nwhere one or more parties of the interaction are anonymous. \n\nWhy there is no AR020.4? \n\nThanks,\n\nPatrick.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Tuesday, 6 May 2003 2:43 AM\nTo: Patrick.Hung@csiro.au; public-p3p-spec@w3.org\nSubject: Re: [BH] First (Very Rought) Outline of Beyond HTTP\n\n\nOn Friday 02 May 2003 05:39, Patrick.Hung@csiro.au wrote:\n> Do you have any timeline for this document? Maybe, we should have a\n> conference call\n> for this task force after we have more content in those chunks.\n\nI hope to have something cogent by the end of next week. Something that the \ntask force is happy with by the end of May. June to get external web \nservice and \"adopting application\" feedback, and the the documents itself \nis due in July.\n\n\n\n", "id": "lists-017-5039889"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Wednesday 07 May 2003 10:53, Patrick.Hung@csiro.au wrote:\n> Just get back to my seat for this working draft of WSDL + SOAP from other\n> tasks.\n\nPatrick, we're definitely on the same page here.\n\n> Once the user's privacy preferences are all satisfied with the\n> registrar's WS-P3P policy,\n> the user should try to bind with the registrar's service(s) by SOAP\n> messaging [Stage 1], no matter\n> the carrier is HTTP or SMTP. So, this is the very simple story. Up to\n> this moment, there\n> is no need to specify any \"privacy\" stuff in the SOAP header??!!\n\nI'd disagree, because you're scenario ALWAYS presumes that I will check the \nWSDL before I interact via SOAP. What happens if I already know the service \nand plan on using them? I have to check the WSDL every time just to make \nsure the policy hasn't changed. I'm presently thinking:\n1. The policy needs to be bound to the layer (application) of the data \nsolicitation and transport as closely as possible.\n2. Other \"layers\" may have restatements of the policies. So if I'm searching \nfor a service, I might look at the policies via UDDI or WSDL.\n3. Any policy that is discovered must be honored. Before I was taking the \n\"higher layers trump lower layers\", but I'm reconsidering that after \nrereading [1,2] and finding those heuristics to be very elegant. (And of \ncourse, what I'm presuming with respect to the WSDL/UDDI case is that these \naren't different policies, just a \"restatement\". The WSDL description uses \nthe same URI to the policy that is found in the subsequent SOAP header.)\n\n[1] http://www.w3.org/TR/2002/REC-P3P-20020416/#ref_syntax\n\" As a practical note, however, placing many different P3P policies on \ndifferent resources on a single page may make rendering the page and \ninforming the user of the relevant policies difficult for user agents. \nAdditionally, services are recommended to attempt to craft their policy \nreference files such that a single policy reference file covers any given \n\"page\"; this will speed up the user's browsing experience.\"\n[2] http://www.w3.org/TR/2002/REC-P3P-20020416/#non-ambiguity\n\"User agents need to be able to determine unambiguously what policy applies \nto a given URI.... n those cases, the site will probably not be able to \ndetermine reliably which policy any given user has seen, and thus it MUST \nhonor all policies (this is also the case for compact policies, cf. Section \n4.1 and Section 4.6). Sites MUST be cautious in their practices when they \ndeclare multiple policies for a given URI, and ensure that they can \nactually honor all policies simultaneously.\"\n\n\n\n", "id": "lists-017-5054315"}, {"subject": "[CC] Kickoff phone conference for the WG on Consent Choices   (CC", "content": "Hi Lorrie,\n\n\nI just discovered (http://www.w3.org/P3P/2003/03-tf.html) that we are the \nonly two members of this group.\n\nI propose to get started by scheduling a phone conference next week.\nThis enables anybody else who'd be interested to join.\n\nHow about next monday (05/12/03) from 11AM-11.45AM EST?\n\nParticipant Passcode: 555588\nToll Phone Number: 1-719-955-1383\nToll Free Phone Number: 1-800-653-1360\n\nThe goals are to\n  - agree on the goals\n  - agree on an initial workplan\n  - brainstorm on solutions\n\n\nRegards,\n  matthias\n\n\n\n", "id": "lists-017-5064801"}, {"subject": "[Agent/Domain] minutes from initial conference call 4/25/0", "content": "Sorry for the delay in getting these out. Thanks to Brooks for taking\nminutes.\n---\n\nApril 25, 2003 Minutes\nAgent/Domain Relationship Task force\n\nStart 9:05 EST\nAttendees:\nJack Humphrey, Coremetrics (Chair)\nBrooks Dobbs, DoubleClick\nMarcel Meth, Fleet Boston Financial\nDan Schutzer, Citi Group\nBrandy Moore, AOL\nMatthias Schunter, IBM\n\n\nAgenda is set:\n- Stated Purpose coming out of Nov. workshop\n- Other ideas\n- What are milestones / tasks (want to be complete by June)\n\n2 Core issues from Brian Zwit's write up following the November meetings \n1) allow a mechanism for a site to declare another site as 1st party\n2) review compact policies, their efficiencies and the need for them in\ngeneral (as there is another task force here, we may need to punt this one)\n\nOther potential ideas proposed by Jack\n1) being able to declare that a single policy applies to multiple sites and\nservices\n2) to allow in a privacy policy the ability to denote that a site A is an\nagent of site B and that they do not have a \"true\" 3rd party relationship\n3) ability to defer purpose to another entity\n4) recommendations and requirements \n\nBrooks: brings up that point 3) above almost invalidates P3P.\n- general consensus that more work needs to be done in understanding and\ndescribing entity and OURS\n\nJack: raises the liability issues that if a client does something with data\nnot declared.\n\nJack: brings up that the \"OURS\" recipient is ambiguous\n\nJack: brings up that it may be valuable to tell a UA that asset is really a\n1st party\n\nJack: suggests the possibility of changing the PRF mechanism to potentially\ncover multiple hosts within a domain\n\nBrooks: raises the issue that CPs already create a problem by potentially\napplying a policy across entities\n\nJack: state that pre-fetching (e.g. evaluating policy at cookie-send time)\nand user agent behavior plays large into resolving a number of these issues.\n\n\n(There seems to be general consensus that a good deal of work that may come\nout of this group is directly tied to work coming out of the UA group)\n\nMatthias: suggests that some of these issues would be easier to follow\nthrough written material and suggest more be distributed.\n\nMatthias: wants to know how a second site could be considered within the\nSAME ours as another site.\n\nBrooks: suggests the possibility of a second form of the ENTITY element or\nan attribute within ENTITY that points to an \"entity registry\" \n\nMarcel: brings up that he would like to see W3C declare expected behavior\nfor UAs.  Feels that his is key to adoption.  There needs to be clarity on\nhow a policy will be represented to an end user.\n\nBrooks: suggests broader participation within UA task force.\n\nAction Items:  Jack is going to write up something on enhanced entity\ndeclarations and the ability to refer to other entities, go over it with\nBrooks, then send it out.\n\nBrandy - wants this be sure to also handle CP.\n\nMathias - brings up how Policies can be translated to Layered notice -\nmentioned that it should be brought up in user agent.  Again referred to UA\ntask force.\n\n\n\n", "id": "lists-017-5073290"}, {"subject": "Minutes P3P meeting May 7, 200", "content": "P3P 1.1 WG call May 7, 2003\n\nAttendees:\n\nLorrie Cranor, AT&T, Chair\nBrooks Dobbs, DoubleClick, Minutes\nRigo Wenning, WSC \nGiles Hogben, JRC\nPatrick Hung, CSIRO\nMatthias Schunter, IBM \nJoseph Reagle\n\nMarc Lanheinrich - regrets\n\nStarted 11:06 EST\n\n1. Update on P3P 1.1 chartering (Rigo)\n\n2. Task force reports\n\n-P3P beyond HTTP\nJoesph: Hoping to have something by next week.  Then feed back and then\npushed out to web services.  Suggests getting feedback from liberty\nalliance.\n\n\n-USER AGENT BEAVIOUR\nLorrie: we have gotten some feedback hoping for more\n\n-Compact policies\nBrian not on call\n\n-Article 10 vocabulary issues - Giles Hogben\nGiles: Will send out an announce Monday with the official regulators from\nBrussels on article 29.  \nRigo: there will be questions about vocabulary and enforcement raised here\nGiles/Lorrie: hopefully this will just clarify what P3P can and cannot do as\n1.1\n\n-Agent and domain relationships\nJack not here\n\n-Consent choices - Matthias Schunter\nNot started - Matthias just getting on the list\n\nMatthias: Defines what the sub group does:  Granularity of opt in /opt out\nis currently lacking.  \n\nLorrie:  Add syntax using extension mechanism, add syntax to group together\na set of opt ins or opt outs.  Details to be worked out by this task force\nGiles: Is there a consent mechanism on the table for 2.0?\nLorrie: Yes hopefully someone will take this on.\n\n\n- Converting P3P data schema to XML schema - Giles Hogben\nGiles: Compatibity to version 1 was sticking point.  Considered using\nparallel versions.  NEXT STEPS to write up a user-friendly specification of\nhow it would work.\nLorrie:  Great Progress!!! (had to add a progress announcement)\n\nGiles: Problem is that it is so technical that it will likely not be well\nreviewed\nLorrie: Just do a 1 or 2 page write up.  This is will either be a section or\nappendix in the 1.1 spec.\n\nRigo: Still need an English explanation\n\n\n- Signed P3P policies  - Giles Hogben\n\nGiles:  Sent out a justification for what may be the reason for doing this.\nI am not entirely convinced myself.\nLorrie: If we have signed policies will people think unsigned policies are\nless good?\nGiles: If this happens it means that this was a successful thing to do.\nJoseph:  Implication still remains that unsigned is not valuable\nLorrie:  Suggests that buy in from Truste and major browsers.  Among the\nbrowser's criteria that UAs use would be this digital signature.\n\n...discussion of crypto an SSL ensues\n\nGiles:  Should we directly contact a seals organization to see if they are\ninterested?\nGiles:  RE: XML based data schema, Massimo was asking if anyone really\nwanted it.  Yes Jeremy from Microsoft has been asking when this will be\nready.\n\n3. Discussion of draft backwards compatibility guidelines\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003May/0002.html\n\nLorrie: Suggest there be a guideline that P3P 1.1 be compliant with p3p. 1.0\nXML Schema.\nGiles: points out that we can use extension mechanism to add attributes that\nare still compatibility with 1.0 compliant UAs\nJoseph: Should be very careful of fudging.  If you need to make a change you\nneed to change the namespace.\nLorrie:  None of the 1.0 UAs actually validate against the schema, plan is\nnot to do this.\n\nLorrie:  Guidelines are guidelines not requirements and group may not follow\nthem but need to make a conscious decision and understand why we are not\nfollow them\nLorrie: asks if we are willing to accept these as a set of guidelines?\n\nRigo:  How could anyone disagree?\nLorrie:  Now would be a good time to state a problem:  Unanimously agreed to\nfollow these guidelines\n\n\n4. Discuss bugzilla 171\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=171\n\nThe IBM P3P Policy Editor defines a P3P extension to assign a name\nAttribute to the STATEMENT element. This is useful for the editor\nitself, but it has also proven useful for user agents when they\ndisplay policy summaries to users. We should consider making this\nextension an \"official\" part of the P3P specification -- probably by\nreferencing the extension in v1.1 and turning it into a regular\nattribute (without using the extension mechanism ) in future versions.\n\n\nLorrie: Should we incorporate this in 1.1?\nConsensus - Approved.  Going into 1.1\n\n\n5. Discuss bugzilla 178\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=178\n\nConsider including mention of postal code, state, or region\ninformation, etc. in definition of the demographic category in section\n3.4\n\nPost poned\n\n\nNEW ITEM \nGiles: wanted to do some user testing on translations.  There is technology\ncalled \"Osozlab\", interested in testing the results of our potential\ntranslations.\n\nLorrie:  We should have consensus on a draft translation this summer.  And\nwe'll want feedback ASAP.\n\nGiles: We'd need to get this to the students by mid June to begin testing.\n\nLorrie:  Great to get feedback on what people understand and what they\ndon't.\n\nLorrie: says we have attorneys who have volunteered to check the accuracy of\nthe translations.\n\nLorrie: Whatever translation we come up with will likely be based on the\npre-existing ones in \nPrivacy Bird, IE and Netscape.\n\nLorrie: encourages comments on the 3 sets of translations.  Lorrie hopefully\nbe able to distribute her study in the next 2 weeks.\n\n------------------------------------------------------------\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n\n", "id": "lists-017-5083610"}, {"subject": "Re: [CC] Kickoff phone conference for the WG on Consent Choices   (CC", "content": "I will be unable to join you next Monday. The only days I will be \navailable next week at that time are Thursday and Friday.\n\nLorrie\n\n\nOn Wednesday, May 7, 2003, at 01:13  PM, Matthias Schunter wrote:\n\n>\n> Hi Lorrie,\n>\n>\n> I just discovered (http://www.w3.org/P3P/2003/03-tf.html) that we are \n> the only two members of this group.\n>\n> I propose to get started by scheduling a phone conference next week.\n> This enables anybody else who'd be interested to join.\n>\n> How about next monday (05/12/03) from 11AM-11.45AM EST?\n>\n> Participant Passcode: 555588\n> Toll Phone Number: 1-719-955-1383\n> Toll Free Phone Number: 1-800-653-1360\n>\n> The goals are to\n>  - agree on the goals\n>  - agree on an initial workplan\n>  - brainstorm on solutions\n>\n>\n> Regards,\n>  matthias\n>\n\n\n\n", "id": "lists-017-5096534"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nI may not be clearly describing my message in the previous e-mail.\n \n> I'd disagree, because you're scenario ALWAYS presumes that I will check\nthe \n> WSDL before I interact via SOAP. What happens if I already know the\nservice \n> and plan on using them? I have to check the WSDL every time just to make \n> sure the policy hasn't changed. I'm presently thinking:\n> 1. The policy needs to be bound to the layer (application) of the data \n> solicitation and transport as closely as possible.\n\nLet me refresh my mind: the user has its privacy preferences and the\nregistrar has its privacy policy. Before the user trys to bind to the\nregistrar's service, the user has to validate the registrar's privacy\npolicy by the user's privacy preferences.\n\nIf the user (registrant) knows the registrar's service well and the user\nis strictly go ahead to bind to the registrar's service via SOAP, that's\nfine without re-visit the registrar's WSDL document or even UDDI. I agree\nwith it. So now, let's forget the WSDL document.\n\nIn the existing Web services practices, the first step is the *user*\nbe the active body who sends the SOAP message to trigger the passive body \n*registrar* for response via the HTTP carrier. For illustration, here\nis a simplified SOAP message that the user is trying to bind the registrar's\nservice \"register.\"\n\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\">\n <env:Header>\n </env:Header>\n <env:Body>\n  <m:register xmlns:m=\"http://registrar.com/register\">\n   <m:msg> Please register www.p3pbeyondhttp.com for Joseph </m:msg>\n  </m:register>\n </env:Body>\n</env:Envelope>\n\nLet's also focus on the application layer of the data solicitation and\ntransport: \nSOAP messages. Let's assume that the user is going to send this SOAP message\nto \nthe registrar's service: you can see the *data* that have to be protected\nunder \nthe user's privacy preferences should be \"Please register\nwww.p3pbeyondhttp.com \nfor Joseph\" Then, the steps should be something like:\n\nStep 1: User ---> SOAP Message 1: Please register www.p3pbeyondhttp.com for\nJoseph ---> Registrar's servce\nStep 2: Registrar's service ---> SOAP Message 2: Results(OK/Not OK) --->\nUser\n\nThen, the user should validate its privacy preferences with the registrar's\nprivacy \npolicy before sending the SOAP message 1. Agree? Then, we need to have more\nsteps like:\n\nStep 0.1: User ---> SOAP Message 0.1: What is your privacy policy --->\nRegistrar's service\nStep 0.2: Registrar's service ---> SOAP Message 0.2: Here is our WS-P3P\nPolicy ---> User\nStep 0.3: The user (or the user agent) validates the WS-P3P policy with its\nprivacy preferences \n          before the user really proceeds to Step 1 or abandon its\noperation.\n\nIf so, I would believe that we have to think about whether we should have\nanother mechanism for \nStep 0.1, 0.2, and 0.3, or embed them into Step 1? No matter where should we\ngo, or you have \nother scenarios, we have to think what should we put into the SOAP header or\nbody and when\ndo we need them?\n\nI read an interesting paper recently:\n\n    Tumer, A., Dogac. A., Toroslu. H., \"A semantic based privacy framework\nfor web\n    services\" WWW'03 workshop on E-Services and the Semantic Web (ESSW 03),\nBudapest, \n    Hungary, May 2003.\n    \nLet me try to ask Dogac for her permission before I send it to you for your\nreference.\n\n> 2. Other \"layers\" may have restatements of the policies. So if I'm\nsearching \n> for a service, I might look at the policies via UDDI or WSDL.\n> 3. Any policy that is discovered must be honored. Before I was taking the \n> \"higher layers trump lower layers\", but I'm reconsidering that after \n> rereading [1,2] and finding those heuristics to be very elegant. (And of \n> course, what I'm presuming with respect to the WSDL/UDDI case is that\nthese \n> aren't different policies, just a \"restatement\". The WSDL description uses\n\n> the same URI to the policy that is found in the subsequent SOAP header.)\n\nFor these two points, I don't have any problem on them as they are more on\nthe \nmanagement level. They all sound reasonable and practical.\n\nThanks,\n\nPatrick.\n\n\n\n", "id": "lists-017-5105652"}, {"subject": "Re: [CC] Kickoff phone conference for the WG on Consent   Choices   (CC", "content": "OK. Let's make it thursday.\n\nmatthias\n\nAt 07:35 PM 5/7/2003 -0400, Lorrie Cranor wrote:\n>I will be unable to join you next Monday. The only days I will be \n>available next week at that time are Thursday and Friday.\n>\n>Lorrie\n>\n>\n>On Wednesday, May 7, 2003, at 01:13  PM, Matthias Schunter wrote:\n>\n>>\n>>Hi Lorrie,\n>>\n>>\n>>I just discovered (http://www.w3.org/P3P/2003/03-tf.html) that we are the \n>>only two members of this group.\n>>\n>>I propose to get started by scheduling a phone conference next week.\n>>This enables anybody else who'd be interested to join.\n>>\n>>How about next monday (05/12/03) from 11AM-11.45AM EST?\n>>\n>>Participant Passcode: 555588\n>>Toll Phone Number: 1-719-955-1383\n>>Toll Free Phone Number: 1-800-653-1360\n>>\n>>The goals are to\n>>  - agree on the goals\n>>  - agree on an initial workplan\n>>  - brainstorm on solutions\n>>\n>>\n>>Regards,\n>>  matthias\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-5118160"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Wednesday 07 May 2003 22:39, Patrick.Hung@csiro.au wrote:\n> > and plan on using them? I have to check the WSDL every time just to\n> > make sure the policy hasn't changed. I'm presently thinking:\n> > 1. The policy needs to be bound to the layer (application) of the data\n> > solicitation and transport as closely as possible.\n>\n> Let me refresh my mind: the user has its privacy preferences and the\n> registrar has its privacy policy. \n\nRight. And I shouldn't have used \"bound\" as it recalls \"bind\" which means \nsomething else in the SOAP context. I'll try to stick with \"associate\" a \npolicy with the application (layer).\n\n> Step 1: User ---> SOAP Message 1: Please register www.p3pbeyondhttp.com\n> for Joseph ---> Registrar's servce\n> Step 2: Registrar's service ---> SOAP Message 2: Results(OK/Not OK) --->\n> User\n\nThis generally sounds ok, though I plan on using XForms with serialized XML \n[1] as part of the user2registrar interface, and SOAP (or UDDI/WSDL as \napproriate) for the registrar to registry. So please don't worry about the \nuser2registrar via SOAP bit.\n\n[1] http://www.w3.org/TR/xforms/slice11.html\n\n\n\n", "id": "lists-017-5127428"}, {"subject": "Re: LibertyP3P Interactio", "content": "On Wednesday 30 April 2003 12:07, Elisa Korentayer wrote:\n> The Liberty subteam that has been charged with drafting the Privacy\n> Preferences Expression Languages White Paper is very interested in\n> continuing the discussion and cooperation started with P3P at the Boston\n> meeting in March.\n\nElisa, thank you for the pointers. I've reviewed the documents and besides \nthe editorial comment below don't have many substantive comments. It's \nquite a lot material to get my mind around. I don't trust I understand it \nall quite yet, but after my efforts I was left with the following two \nimpressions:\n1. When it comes to making a declaration in the context of federated \nidentity services, a possible challenge is specifying the scope of the \nsoliciting service and the subsequent recipients? For example, should an \nidentity service represent the policy from itself, rather narrowly, with a \nwider recipient, or define \"itself\" as the set of all affiliates it might \nshare the information with, with no other recipients?\n2. Where is the p3p hook? I note that the SOAP binding has a consent header \nblock, how does that relate to a privacy declaration? I unfortunately \nremember little of the \"five level policy approach\", have you published \nanything with respect to that yet?\n\nThe editorial nit was in the Architecture Overview, it uses the term \n\"introduce\" and \"federate\" (i.e., \"You may Federate your Airline Inc. \nidentity with any others...\") without first defining it. Unfortunately, the \ndocuments aren't hypertext (so I can't easily follow a link to their \nnormative definitions) but it seems the glossary gives a definition for \nfederate (i.e. bind), but not introduce. I'm sure the Overview states their \nmeanings, but perhaps doing so more explicitly would help it sink in. \n<smile/>\n\n> In terms of scheduling, we would like to get a sense from you as to\n> whether P3P, or the P3P members engaged in this project, would be\n> interested in having a phone conversation at the end of May to speak more\n> on these issues.  \n\nI'll defer this question to the P3P group for discussion.\n\n> And, on a larger scale, we would like to get a sense of\n> P3P's interest level, and timeline, for working on a White Paper for the\n> use of P3P in the Liberty context.\n\nOn that note, I'm working in a task force to hopefully address some \nquestions of how to bind SOAP or WSDL with a P3P statement. Once it is in \ndecent form it might be relevant to the questions you have and I would also \nbe willing to review/comment upon the White Paper.\n\n\n\n", "id": "lists-017-5136525"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Thursday 08 May 2003 15:43, Joseph Reagle wrote:\n> This generally sounds ok, though I plan on using XForms with serialized\n> XML [1] as part of the user2registrar interface, and SOAP (or UDDI/WSDL\n> as approriate) for the registrar to registry. So please don't worry about\n> the user2registrar via SOAP bit.\n\n[2] Now has the XForm fragment (using a simple link element for the policy \nassociation) and the resulting XML. Now we need to input this into the SOAP \ninteraction between the registrar and registry.\n\n[2] http://www.w3.org/P3P/2003/p3p-beyond-http/\n\n\n\n", "id": "lists-017-5145651"}, {"subject": "finding p3penabled sites on googl", "content": "FYI, one of my colleagues figured out that you can find P3P-enabled \nsites on google by searching for:\n\nallinurl: w3c p3p.xml\n\nRight now we're getting 801 hits.\n\nLorrie\n\n\n\n", "id": "lists-017-5153518"}, {"subject": "UA: User Agent TF call May 16, 11 a", "content": "The User Agent task force will have a conference call at 11 am US \nEastern on Friday, May 16. It will be on the usual P3P bridge (see \nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html)\n\nWe will discuss the comments on the translation documents \n(http://www.w3.org/P3P/1.1/documents.html#ua) and especially the \nquestions I outlined at the end of\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Apr/0018.html\n\nIf you are a member of this TF and you cannot participate, please send \nyour comments prior to the meeting.\n\nLorrie\n\n\n\n", "id": "lists-017-5160638"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "If you are interested in this paper, you can download it\nfrom http://www.cmis.csiro.au/Patrick.Hung/documents/TumerDogacToroslu.pdf\nI got the permission from the author.\n\n>I read an interesting paper recently:\n>\n>    Tumer, A., Dogac. A., Toroslu. H., \"A semantic based privacy framework\n>for web\n>    services\" WWW'03 workshop on E-Services and the Semantic Web (ESSW 03),\n>Budapest, \n>    Hungary, May 2003.\n    \n\n\n\n", "id": "lists-017-5167896"}, {"subject": "Re: finding p3penabled sites on googl", "content": "I got something below, like 790, but it is missing all the data\ncommissioner sites that I know are P3P enabled (and valid)\n\nBest, \n\nRigo\n\nOn Thu, May 08, 2003 at 08:32:38PM -0400, Lorrie Cranor wrote:\n> \n> FYI, one of my colleagues figured out that you can find P3P-enabled \n> sites on google by searching for:\n> \n> allinurl: w3c p3p.xml\n> \n> Right now we're getting 801 hits.\n> \n> Lorrie\n\n\n\n", "id": "lists-017-5176385"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Patrick,\n\nIndeed, an interesting paper. However I read it with an eye towards what we \ncould apply towards our \"P3P Beyond HTTP\" work and don't see any immediate \ntake-away. However, since I bothered to read it, I figure I might as well \nshare my comments: <smile/>\n1. Certainly interesting to see this in light of RDF/DAML.\n2. From the point of view of user security and privacy, relying upon a \nservice ontology as the significant factor in releasing information does \nnot give me great confidence. In their example, my credit card is \nconsidered \"free\" to anyone that calls themselves a \nAitTransportationService? Perhaps my reaction is unfair or confused, but \nthey make the point that their proposal is *not* limited to the Web and \nURIs, which P3P is. I believe that *any* privacy solution, including those \nfor Web services, will depend upon some declaration of service identity \nthat is associate with some URI -- not merely an association in an \nontology.\n3. Having been around the course with respect to \"negotiation\" I prefer to \nuse that term to exclusively describe multi-round (interactive) protocols. \nSpecifying alternatives in a single transmission can have similar effects, \nbut not necessarily as Lorrie and Paul touched on [1].\n\n[1] http://www.si.umich.edu/~presnick/papers/negotiation/\n\nOn Saturday 10 May 2003 09:25, Patrick.Hung@csiro.au wrote:\n> If you are interested in this paper, you can download it\n> from\n> http://www.cmis.csiro.au/Patrick.Hung/documents/TumerDogacToroslu.pdf I\n> got the permission from the author.\n>\n> >I read an interesting paper recently:\n> >\n> >    Tumer, A., Dogac. A., Toroslu. H., \"A semantic based privacy\n> > framework for web\n> >    services\" WWW'03 workshop on E-Services and the Semantic Web (ESSW\n> > 03), Budapest,\n> >    Hungary, May 2003.\n\n-- \nJoseph Reagle Jr.                 http://www.w3.org/People/Reagle/\nW3C Policy Analyst                mailto:reagle@w3.org\nIETF/W3C XML-Signature Co-Chair   http://www.w3.org/Signature/\nW3C XML Encryption Chair          http://www.w3.org/Encryption/2001/\n\n\n\n", "id": "lists-017-5184044"}, {"subject": "Re: finding p3penabled sites on googl", "content": "Yes, this is of course not a complete collection of P3P-enabled sites. \nIt only catches sites that use the WKL and that are indexed by google. \nAnd it won't necessarily get all those sites due to the way the google \nindexing scheme works.\n\nThink of this number as a lower bound. My guess is the actual number of \nP3P sites is near two times this number.\n\nLorrie\n\n\nOn Monday, May 12, 2003, at 12:00  PM, Rigo Wenning wrote:\n\n>\n> I got something below, like 790, but it is missing all the data\n> commissioner sites that I know are P3P enabled (and valid)\n>\n> Best,\n>\n> Rigo\n>\n> On Thu, May 08, 2003 at 08:32:38PM -0400, Lorrie Cranor wrote:\n>>\n>> FYI, one of my colleagues figured out that you can find P3P-enabled\n>> sites on google by searching for:\n>>\n>> allinurl: w3c p3p.xml\n>>\n>> Right now we're getting 801 hits.\n>>\n>> Lorrie\n>\n\n\n\n", "id": "lists-017-5195147"}, {"subject": "RE: finding p3penabled sites on googl", "content": "That will not get any sites that don't have a prf in the wkl. Perhaps that's\nthe reason?\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n[mailto:public-p3p-spec-request@w3.org]On Behalf Of Rigo Wenning\nSent: 12 May 2003 18:01\nTo: public-p3p-spec@w3.org\nSubject: Re: finding p3p-enabled sites on google\n\n\n\nI got something below, like 790, but it is missing all the data\ncommissioner sites that I know are P3P enabled (and valid)\n\nBest,\n\nRigo\n\nOn Thu, May 08, 2003 at 08:32:38PM -0400, Lorrie Cranor wrote:\n>\n> FYI, one of my colleagues figured out that you can find P3P-enabled\n> sites on google by searching for:\n>\n> allinurl: w3c p3p.xml\n>\n> Right now we're getting 801 hits.\n>\n> Lorrie\n\n\n\n", "id": "lists-017-5203474"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nBased on your XForm example [2], I am <simply/> creating a sample WSDL\ndocument \nfor the registry's \"register\" service as follows:\n\n============================================================================\n=====================\n<?xml version='1.0' encoding='utf-8' ?>\n<definitions name='Register'\n\ntargetNamespace='http://registry.example.com/register.wsdl'\n          xmlns:tns='http://registry.example.com/register.wsdl'\n          xmlns:my='http://registry.example.com/register/schemas'\n          xmlns:soap='http://schemas.xmlsoap.org/wsdl/soap/'\n          xmlns='http://schemas.xmlsoap.org/wsdl/'>\n\n    <import namespace='http://registry.example.com/register/schemas'\n           location='http://registry.example.com/2003/ns1.xsd'/>\n\n    <my:Privacy my:rel='P3Pv1'\nmy:href='http://registry.example.com/P3P/PolicyReferences.xml'/>\n\n    <message name='RegisterDomainNameInput'>\n        <part name='body' element='my:OrderInfo'/>\n    </message>\n\n    <message name='RegisterDomainNameOutput'>\n        <part name='body' element='my:RegistrationStatus'/>\n    </message>\n\n    <portType name='RegisterDomainNamePortType'>\n        <operation name='RegisterDomainName'>\n           <input message='tns:RegisterDomainNameInput'/>\n           <output message='tns:RegisterDomainNameOutput'/>\n        </operation>\n    </portType>\n\n    <binding name='RegisterDomainNameSoapBinding'\ntype='tns:RegisterDomainNamePortType'>\n        <soap:binding style='document'\ntransport='http://schemas.xmlsoap.org/soap/http'/>\n        <operation name='RegisterDomainName'>\n           <soap:operation\nsoapAction='http://registry.example.com/RegisterDomainName'/>\n           <input>\n               <soap:body use='literal'/>\n           </input>\n           <output>\n               <soap:body use='literal'/>\n           </output>\n        </operation>\n    </binding>\n\n    <service name='RegisterService'>\n        <documentation>Register Service</documentation>\n        <port name='RegisterDomainNamePort'\nbinding='tns:RegisterDomainNameSoapBinding'>\n           <soap:address location='http://registry.example.com/register'/>\n        </port>\n    </service>\n\n</definitions>\n============================================================================\n=====================\n\nThe P3P policy is also optionally associated with the WSDL document. Would\nyou please check it\nand tell me your comments? Is that what you expect in the \"Associating with\na WSDL Description\" \nsection [2]? In this case, both the XForm and WSDL are referring to the same\nschema for the\ndata category. From another aspect, this is a *bit* like the ideas of\nontologies.\n\nOnce this sample WSDL document is ok, I will create the sample SOAP message\nand put the P3P policy \nor even a P3P compact policy in the SOAP header with all the descriptions.\n\nMany thanks and talk to you soon.\n\nPatrick.\n\n-----Original Message-----\nFrom: Joseph Reagle [mailto:reagle@w3.org]\nSent: Friday, 9 May 2003 9:13 AM\nTo: Patrick.Hung@csiro.au; public-p3p-spec@w3.org\nSubject: Re: [BH] First (Very Rought) Outline of Beyond HTTP\n\n\nOn Thursday 08 May 2003 15:43, Joseph Reagle wrote:\n> This generally sounds ok, though I plan on using XForms with serialized\n> XML [1] as part of the user2registrar interface, and SOAP (or UDDI/WSDL\n> as approriate) for the registrar to registry. So please don't worry about\n> the user2registrar via SOAP bit.\n\n[2] Now has the XForm fragment (using a simple link element for the policy \nassociation) and the resulting XML. Now we need to input this into the SOAP \ninteraction between the registrar and registry.\n\n[2] http://www.w3.org/P3P/2003/p3p-beyond-http/\n\n\n\n", "id": "lists-017-5212047"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Tuesday 13 May 2003 05:39, Patrick.Hung@csiro.au wrote:\n> Based on your XForm example [2], I am <simply/> creating a sample WSDL\n> document\n> for the registry's \"register\" service as follows:\n\nPatrick, the service description is true to the scenario, but as I'm not a \nWSDL expert, what led you to include the my:Privacy element as a child of \nthe wsdl:definitions?\n\nSection 2.1.2 states:\n  Zero or more namespace qualified element information items\n  amongst its [children]. Such element information items MUST be a \n  member of one of the element substitution groups allowed at the \n  top-level of a WSDL document as described in 6. Language Extensibility.\n  http://www.w3.org/TR/2003/WD-wsdl12-20030303/#Definitions_XMLRep\n\nSo if I understand the WSDL extension model, we would also have to have our \nown schema that includes a redefinition of globalExt or base my:Privacy on \nthe ExtensibilityElement complexType? (I don't understand this myself yet \nand haven't found a good example.)\n\nAlso, I presume that our WSDL extension is optional. Privacy is not optional \nat the point of solicitation, but since we are saying a WSDL declaration is \n(usefully) redundant, I don't think we need to argue that a WSDL processor \nmust understand our extension to even process the description.\n\n\n\n", "id": "lists-017-5225511"}, {"subject": "A little survey about Privacy Policies in Web Service", "content": "Hi Joseph and P3P members,\n\nI would like to ask help from everybody. I am now planning to\nconduct a *little* survey about Web service security and privacy \nat the 2003 International Conference on Web Services (ICWS'03) at\nLas Vegas in coming June. The ICWS'03 is one of the conferences\nheld in the 2003 International Multiconference in Computer Science \n& Engineering (http://www.ashland.edu/~iajwa/conferences/).\n\nThe tentative motivation of this little survey is to get some info.\nabout what are the views, suggestions and opinions about security and \nprivacy issues from the Web service research community. Based on the\ninfo., the results are expected to help developing the strategic plans \nfor related research activities.\n\nI am trying to draft the questions for the Web services privacy part\non the questionnaire, and I think that this *may* be an opportunity \nfor \"P3P Beyond HTTP Task Force\" or even P3P to get a *little* picture \nabout what are Web service researchers thinking about privcay policies.\n\nThus, may I ask for your support and help to do brainstorming with me?\nHere are some tentative questions that popping out from my mind so far. \nWould you please take a look and tell me your comments or even suggest \nother questions? No matter it is related to the \"P3P Beyond HTTP Task\nForce\" or not.\n\nWeb Service Privacy\n===================\n\nDo you know the Platform for Privacy Preferences (P3P) Project at the W3C? \nYes, No, Don't know.\n\nDo you know the two major concepts in P3P: User Preferences and Privacy\nPolicies? \nYes, No, Don't know.\n\nDo you know that P3P is recommended for Web service privacy policies? \nYes, No, Don't know.\n\nDo you concern whether Web service providers express privacy policies? \nYes, No, Don't care.\n\nDo you think that UDDI registries should contain privacy policies for Web\nservices as an option? \nYes, No, Not Sure.\n\nDo you think that WSDL documents should also contain privacy policies for\nWeb service as an option? \nYes, No, Not Sure.\n\nDo you think that privacy issues should be resolved before an interaction\nbefore Web service requestor and provider? \nYes, No, Not Sure. \n\nThank you very much for your kind attention and your comment/suggestion is\nhighly appreciated.\n\nCheers,\n\nPatrick.\n\n\n\n", "id": "lists-017-5234593"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\n> Patrick, the service description is true to the scenario, but as I'm not a\n\n> WSDL expert, what led you to include the my:Privacy element as a child of \n> the wsdl:definitions?\n\nI just try to make it simple and follow the style of your XForm example [1].\n\nThere may have other much better approach... I have to think about it...\nAuy idea?\n\n> So if I understand the WSDL extension model, we would also have to have\nour \n> own schema that includes a redefinition of globalExt or base my:Privacy on\n\n> the ExtensibilityElement complexType? (I don't understand this myself yet \n> and haven't found a good example.)\n\nIs this something that you are looking for [1]:\n\n       <schema targetNamespace=\"http://registry.example.com/2003/ns1.xsd\"\n              xmlns=\"http://www.w3.org/2000/10/XMLSchema\">\n           <complexType name=\"OrderInfo\">\n              <all>\n                 <complexType name=\"PersonalInfo\">\n                    <all>\n                       <complexType name=\"Name\">\n                          <all>\n                             <element name=\"First\" type=\"string\"/>\n                             <element name=\"Middle\" type=\"string\"/>\n                             <element name=\"Last\" type=\"string\"/>\n                          </all>\n                       </complexType>        \n                       <complexType name=\"Address\">\n                          <all>\n                             <element name=\"Street\" type=\"string\"/>\n                             <element name=\"City\" type=\"string\"/>\n                             <element name=\"State\" type=\"string\"/>\n                             <element name=\"Zip\" type=\"string\"/>\n                          </all>\n                       </complexType>\n                    </all>\n                 </complexType>\n                 <complexType name=\"DomainInfo\">\n                    <all>\n                       <element name=\"TLD\" type=\"string\"/>\n                       <element name=\"DomainName\" type=\"string\"/>\n                    </all>\n                 </complexType> \n              </all>\n           </complexType>\n           <element name=\"RegistrationStatus\" type=\"string\"/>\n           <complexType name=\"Privacy\">\n              <attribute name=\"rel\" type=\"string\" use=\"required\"/>\n              <attribute name=\"href\" type=\"string\" use=\"required\"/>\n           </complexType>\n       </schema>\n\nI am lazy here so that I put all stuff into one schema\n\"http://registry.example.com/2003/ns1.xsd\"\nWe should separate the data types and the P3P privacy policies into\ndifferent schemas.\nAnyway, let's focus on the basic concept and approach first and then we can\npolish\nand debug it later.\n\n> Also, I presume that our WSDL extension is optional. Privacy is not\noptional \n> at the point of solicitation, but since we are saying a WSDL declaration\nis \n> (usefully) redundant, I don't think we need to argue that a WSDL processor\n\n> must understand our extension to even process the description.\n\nYes, I agree with you. I will write something about SOAP messages tomorrow.\n\n[1] http://www.w3.org/P3P/2003/p3p-beyond-http/\n\n\n\n", "id": "lists-017-5244997"}, {"subject": "Re: [CC] Kickoff phone conference for the WG on Consent   Choices   (CC", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-017-5256998"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Wednesday 14 May 2003 07:26, Patrick.Hung@csiro.au wrote:\n> I just try to make it simple and follow the style of your XForm example\n> [1].\n> There may have other much better approach... I have to think about it...\n> Any idea?\n\nNo, I simply find WSDL confusing and I'm rather ignorant of it. \n\n> Is this something that you are looking for [1]:\n\nCool, that's a good schema for the data instance sent via XForms -- and that \ncan be included in the WSDL *instance's* wsdl:types. My question is about \nthe WSDL itself. Does WSDL generically allow you to place any old element \nfrom a foreign namespace in it's instance? (I don't think so.) If it does \npermit this, does it require you to first provide a schema to validate the \naugmented instance? I think so because of this in the WSDL schema:\n\n  <xs:complexType name=\"Definitions\" mixed=\"false\">\n    <xs:annotation>\n  <xs:documentation>\n  Any top-level, optional element is allowed to appear more\n  than once - Any extensibility element is allowed in any place.\n  Such extensibility elements must be in the substitution group of\n  globalExt or postTypes\n  </xs:documentation>\n\nI'm looking at [a], and think we need something like:\n\n<xsd:schema\n  targetNamespace=\"http://registry.example.com/register/schemas\"\n  xmlns:my=\"http://registry.example.com/register/schemas\"\n  xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"\n  xmlns:wsdl=\"http://schemas.xmlsoap.org/wsdl/\"\n  elementFormDefault=\"qualified\">\n  \n  <xsd:import\n  namespace=\"http://schemas.xmlsoap.org/wsdl/\"\n  schemaLocation=\"http://schemas.xmlsoap.org/wsdl/\"/>\n  \n    <xsd:element name=\"my:Privacy\"\n      substitutionGroup=\"wsdl:globalExt\">\n         <xsd:attribute name=\"rel\"  type=\"xsd:string\" use=\"required\"/>\n         <xsd:attribute name=\"href\" type=\"xsd:anyURI\" use=\"required\"/>\n    </xsd:element>\n</xsd:schema>\n\n[a] \nhttp://www.gotdotnet.com/team/xml_wsspecs/dime/WSDL-Extension-for-DIME.htm\n\n\n\n", "id": "lists-017-5264694"}, {"subject": "Re: A little survey about Privacy Policies in Web Service", "content": "Patrick,\n\nI'm not sure what you will learn from a survey like this. From my \nexperience talking to web services folks in the past, most of them \ndon't know much about privacy policies and so their opinions are not \ngoing to be all that enlightening. If there is a session where they \nwould first be informed about these issues and then surveyed, perhaps a \nBOF or something, then a survey like this would be more useful I think.\n\nLorrie\n\n\n\nOn Tuesday, May 13, 2003, at 11:53  PM, Patrick.Hung@csiro.au wrote:\n\n>\n> Hi Joseph and P3P members,\n>\n> I would like to ask help from everybody. I am now planning to\n> conduct a *little* survey about Web service security and privacy\n> at the 2003 International Conference on Web Services (ICWS'03) at\n> Las Vegas in coming June. The ICWS'03 is one of the conferences\n> held in the 2003 International Multiconference in Computer Science\n> & Engineering (http://www.ashland.edu/~iajwa/conferences/).\n>\n> The tentative motivation of this little survey is to get some info.\n> about what are the views, suggestions and opinions about security and\n> privacy issues from the Web service research community. Based on the\n> info., the results are expected to help developing the strategic plans\n> for related research activities.\n>\n> I am trying to draft the questions for the Web services privacy part\n> on the questionnaire, and I think that this *may* be an opportunity\n> for \"P3P Beyond HTTP Task Force\" or even P3P to get a *little* picture\n> about what are Web service researchers thinking about privcay policies.\n>\n> Thus, may I ask for your support and help to do brainstorming with me?\n> Here are some tentative questions that popping out from my mind so far.\n> Would you please take a look and tell me your comments or even suggest\n> other questions? No matter it is related to the \"P3P Beyond HTTP Task\n> Force\" or not.\n>\n> Web Service Privacy\n> ===================\n>\n> Do you know the Platform for Privacy Preferences (P3P) Project at the \n> W3C?\n> Yes, No, Don't know.\n>\n> Do you know the two major concepts in P3P: User Preferences and Privacy\n> Policies?\n> Yes, No, Don't know.\n>\n> Do you know that P3P is recommended for Web service privacy policies?\n> Yes, No, Don't know.\n>\n> Do you concern whether Web service providers express privacy policies?\n> Yes, No, Don't care.\n>\n> Do you think that UDDI registries should contain privacy policies for \n> Web\n> services as an option?\n> Yes, No, Not Sure.\n>\n> Do you think that WSDL documents should also contain privacy policies \n> for\n> Web service as an option?\n> Yes, No, Not Sure.\n>\n> Do you think that privacy issues should be resolved before an \n> interaction\n> before Web service requestor and provider?\n> Yes, No, Not Sure.\n>\n> Thank you very much for your kind attention and your \n> comment/suggestion is\n> highly appreciated.\n>\n> Cheers,\n>\n> Patrick.\n>\n\n\n\n", "id": "lists-017-5274937"}, {"subject": "RE: A little survey about Privacy Policies in Web Service", "content": "Dear Lorrie,\n\nThanks a lot for your comments. I will take them and try to decide a more \npractical approach to conduct such a survey.\n\nI will also check the \"An Analysis of P3P Deployment on Commercial,\nGovernment, \nand Children's Web Sites as of May 2003\" report.\n\nI will definitely ask for your comments/suggestions again.\n\nCheers,\n\nPatrick.\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@research.att.com]\nSent: Thursday, 15 May 2003 12:28 PM\nTo: Patrick.Hung@csiro.au\nCc: reagle@w3.org; public-p3p-spec@w3.org\nSubject: Re: A little survey about Privacy Policies in Web Services\n\n\nPatrick,\n\nI'm not sure what you will learn from a survey like this. From my \nexperience talking to web services folks in the past, most of them \ndon't know much about privacy policies and so their opinions are not \ngoing to be all that enlightening. If there is a session where they \nwould first be informed about these issues and then surveyed, perhaps a \nBOF or something, then a survey like this would be more useful I think.\n\nLorrie\n\n\n\nOn Tuesday, May 13, 2003, at 11:53  PM, Patrick.Hung@csiro.au wrote:\n\n>\n> Hi Joseph and P3P members,\n>\n> I would like to ask help from everybody. I am now planning to\n> conduct a *little* survey about Web service security and privacy\n> at the 2003 International Conference on Web Services (ICWS'03) at\n> Las Vegas in coming June. The ICWS'03 is one of the conferences\n> held in the 2003 International Multiconference in Computer Science\n> & Engineering (http://www.ashland.edu/~iajwa/conferences/).\n>\n> The tentative motivation of this little survey is to get some info.\n> about what are the views, suggestions and opinions about security and\n> privacy issues from the Web service research community. Based on the\n> info., the results are expected to help developing the strategic plans\n> for related research activities.\n>\n> I am trying to draft the questions for the Web services privacy part\n> on the questionnaire, and I think that this *may* be an opportunity\n> for \"P3P Beyond HTTP Task Force\" or even P3P to get a *little* picture\n> about what are Web service researchers thinking about privcay policies.\n>\n> Thus, may I ask for your support and help to do brainstorming with me?\n> Here are some tentative questions that popping out from my mind so far.\n> Would you please take a look and tell me your comments or even suggest\n> other questions? No matter it is related to the \"P3P Beyond HTTP Task\n> Force\" or not.\n>\n> Web Service Privacy\n> ===================\n>\n> Do you know the Platform for Privacy Preferences (P3P) Project at the \n> W3C?\n> Yes, No, Don't know.\n>\n> Do you know the two major concepts in P3P: User Preferences and Privacy\n> Policies?\n> Yes, No, Don't know.\n>\n> Do you know that P3P is recommended for Web service privacy policies?\n> Yes, No, Don't know.\n>\n> Do you concern whether Web service providers express privacy policies?\n> Yes, No, Don't care.\n>\n> Do you think that UDDI registries should contain privacy policies for \n> Web\n> services as an option?\n> Yes, No, Not Sure.\n>\n> Do you think that WSDL documents should also contain privacy policies \n> for\n> Web service as an option?\n> Yes, No, Not Sure.\n>\n> Do you think that privacy issues should be resolved before an \n> interaction\n> before Web service requestor and provider?\n> Yes, No, Not Sure.\n>\n> Thank you very much for your kind attention and your \n> comment/suggestion is\n> highly appreciated.\n>\n> Cheers,\n>\n> Patrick.\n>\n\n\n\n", "id": "lists-017-5286491"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "> No, I simply find WSDL confusing and I'm rather ignorant of it. \n\nHi Joseph, I also find WSDL confusing... This is the first time for me to\ntouch \nthe WSDL schema in details. I would suggest that we should ask help from\nsome WSDL \nexperts at W3C(?) to validate the proposed WSDL with extensible elements\nfragment.\n\n> Cool, that's a good schema for the data instance sent via XForms -- and\nthat \n> can be included in the WSDL *instance's* wsdl:types. My question is about \n> the WSDL itself. Does WSDL generically allow you to place any old element \n> from a foreign namespace in it's instance? (I don't think so.) If it does \n> permit this, does it require you to first provide a schema to validate the\n\n> augmented instance? I think so because of this in the WSDL schema:\n\nYes, it is true for the second question. You can see a use case here:\nhttp://aspn.activestate.com/ASPN/Mail/Message/WSDL/832328\n\nThanks for your revised schema for \"my:Privacy.\" Overall, we should have\nsomething\nlike these + the XForm fragment:\n\nhttp://registry.example.com/2003/wsdlext.xsd\n============================================\n\n<xsd:schema\n  targetNamespace=\"http://registry.example.com/2003/wsdlext\"\n  xmlns:my=\"http://registry.example.com/2003/wsdlext\"\n  xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"\n  xmlns:wsdl=\"http://schemas.xmlsoap.org/wsdl/\"\n  elementFormDefault=\"qualified\">\n  \n  <xsd:import\n  namespace=\"http://schemas.xmlsoap.org/wsdl/\"\n  schemaLocation=\"http://schemas.xmlsoap.org/wsdl/\" />\n  \n  <xsd:element name=\"my:Privacy\"\n    substitutionGroup=\"wsdl:globalExt\">\n    <xsd:complexType>\n      <xsd:complexContent>\n        <xsd:extension base=\"wsdl:tExtensibilityElement\">\n          <xsd:sequence />\n          <xsd:attribute name=\"rel\"  type=\"xsd:string\" use=\"required\"/>\n          <xsd:attribute name=\"href\" type=\"xsd:anyURI\" use=\"required\"/>\n        </xsd:extension>\n      </xsd:complexContent>\n    </xsd:complexType>\n  </xsd:element>\n\n</xsd:schema>\n\n\nhttp://registry.example.com/2003/ns1.xsd\n========================================\n\n<schema targetNamespace=\"http://registry.example.com/2003/ns1\"\n  xmlns=\"http://www.w3.org/2000/10/XMLSchema\">\n\n  <complexType name=\"OrderInfo\">\n    <all>\n      <complexType name=\"PersonalInfo\">\n        <all>\n          <complexType name=\"Name\">\n            <all>\n              <element name=\"First\" type=\"string\"/>\n              <element name=\"Middle\" type=\"string\"/>\n              <element name=\"Last\" type=\"string\"/>\n            </all>\n          </complexType>        \n          <complexType name=\"Address\">\n            <all>\n              <element name=\"Street\" type=\"string\"/>\n              <element name=\"City\" type=\"string\"/>\n              <element name=\"State\" type=\"string\"/>\n              <element name=\"Zip\" type=\"string\"/>\n            </all>\n          </complexType>\n        </all>\n      </complexType>\n      <complexType name=\"DomainInfo\">\n        <all>\n          <element name=\"TLD\" type=\"string\"/>\n          <element name=\"DomainName\" type=\"string\"/>\n        </all>\n      </complexType> \n    </all>\n  </complexType>\n\n  <element name=\"RegistrationStatus\" type=\"string\"/>\n\n</schema>\n\n\nhttp://registry.example.com/2003/registerservice.wsdl\n=====================================================\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<definitions name=\"RegisterService\"\n  targetNamespace=\"http://registry.example.com/2003/definitions\"\n        xmlns:tns=\"http://registry.example.com/2003/definitions\"\n         xmlns:my=\"http://registry.example.com/2003/wsdlext.xsd\"\n       xmlns:soap=\"http://schemas.xmlsoap.org/wsdl/soap/\"\n            xmlns=\"http://schemas.xmlsoap.org/wsdl/\">\n\n  <import namespace=\"http://registry.example.com/2003/ns1\"\n           location=\"http://registry.example.com/2003/ns1.xsd\"/>\n\n  <my:Privacy my:rel=\"P3Pv1\"\nmy:href=\"http://registry.example.com/P3P/PolicyReferences.xml\"/>\n\n  <message name=\"RegisterDomainNameInput\">\n    <part name=\"body\" element=\"tns:OrderInfo\"/>\n  </message>\n\n  <message name=\"RegisterDomainNameOutput\">\n    <part name=\"body\" element=\"tns:RegistrationStatus\"/>\n  </message>\n\n  <portType name=\"RegisterDomainNamePortType\">\n    <operation name=\"RegisterDomainName\">\n      <input message=\"tns:RegisterDomainNameInput\"/>\n      <output message=\"tns:RegisterDomainNameOutput\"/>\n    </operation>\n  </portType>\n\n  <binding name=\"RegisterDomainNameSoapBinding\"\ntype=\"tns:RegisterDomainNamePortType\">\n    <soap:binding style=\"document\"\ntransport=\"http://schemas.xmlsoap.org/soap/http\"/>\n    <operation name=\"RegisterDomainName\">\n      <soap:operation\nsoapAction=\"http://registry.example.com/RegisterService/RegisterDomainName\"/\n>\n      <input>\n        <soap:body use=\"literal\"/>\n      </input>\n      <output>\n        <soap:body use=\"literal\"/>\n      </output>\n    </operation>\n  </binding>\n\n  <service name=\"RegisterService\">\n    <documentation>Register Service</documentation>\n    <port name=\"RegisterDomainNamePort\"\nbinding=\"tns:RegisterDomainNameSoapBinding\">\n      <soap:address location=\"http://registry.example.com/RegisterService\"/>\n    </port>\n  </service>\n\n</definitions>\n\n\n\n", "id": "lists-017-5300152"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph, Based on the Registrar2Registry example discussed so far, I\nsimply create\nthe SOAP messages as follows:\n\nThe Request SOAP Message from Registrar2Registry\n================================================\n\n<?xml version='1.0' ?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\"> \n  <env:Header>\n    <env:Privacy>\n      <env:rel>P3Pv1</env:rel>\n \n<env:href>http://registry.example.com/P3P/PolicyReferences.xml</env:href>\n    </env:Privacy>\n  </env:Header>\n\n  <env:Body>\n    <p:OrderInfo\nxmlns:p=\"http://registry.example.com/RegisterService/RegisterDomainName\">\n      <p:PersonalInfo>\n        <p:Name>\n          <p:First>Joseph</p:First>\n          <p:Middle>M.</p:Middle>\n          <p:Last>Reagle Jr.</p:Last>\n        </p:Name>\n        <p:Address>\n          <p:Street>200 Tecnology Square</p:Street>\n          <p:City>Cambridge</p:City>\n          <p:State>MA</p:State>\n          <p:Zip>02139</p:Zip>\n        </p:Address>\n      </p:PersonalInfo>\n      <p:DomainInfo>\n        <p:TLD>com</p:TLD>\n        <p:DomainName>reagle.example</p:DomainName>\n      </p:DomainInfo>\n    </p:OrderInfo>\n  </env:Body>\n</env:Envelope>\n\n\nThe Response SOAP Message from Registry2Registrar\n=================================================\n\n<?xml version='1.0' ?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\"> \n  <env:Header>\n    <env:Privacy>\n      <env:rel>P3Pv1</env:rel>\n \n<env:href>http://registry.example.com/P3P/PolicyReferences.xml</env:href>\n    </env:Privacy>\n  </env:Header>\n\n  <env:Body>\n    <p:RegistrationStatus\nxmlns:p=\"http://registry.example.com/RegisterService/RegisterDomainName\">\n      OK\n    </p:RegistrationStatus>\n  </env:Body>\n</env:Envelope>\n\n\nAgain we are trying to introduce an extensible element for SOAP header, or\nyou have any other idea. \nAnyway, I will study the SOAP and check how to do it tomorrow.\n\nOnce we have all these protocols, we can start to discuss about the issues\nof intermediaries and\nltimate SOAP receiver for the section \"Transferring to a third party.\"\n\nThanks and talk to you later.\n\nPatrick.\n\n\n\n", "id": "lists-017-5315633"}, {"subject": "[CC] Minutes of 1st Phone Conf. on Consent Choices 2003/05/15   (Version 1", "content": "Hi Folks,\n\nhere are the minutes of today's call. Please send any \ncorrections/questions/suggestions to me.\n\nRegards,\n  matthias\n\n------8<-------\n\nParticipants:\n  Lorrie Cranor\n  Matthias Schunter\n\nAgenda (see earlier mail):\n1. Goals/usecases\n2. Syntax\n\nSUMMARY\n- we agreed that grouping consent is useful (but unclear whether for P3P \n1.1 or P3P 2.0)\n- MTS will draft a syntax that we will float to the implementors to check \nwhether they like it\n\nGOALS\n- the participant agreed that some bundling of consent is useful in practice\n- we were not sure whether we should aim at P3P 1.1 or P3P 2.0\n- a feature that is not implemented by any agent is not very useful\n- as a consequence, we decided that we will elaborate a draft proposal and \nfloat this\n   to the implementors. If agent implementors like the feature, we will aim \nfor 1.1 otherwise 2.0\n\nSyntax\n- the initial proposal from MTS was to add a 'consent-group' ID as an \nattribute inside the elements\n   that are opt-in or opt-out. The reason was to identify a consent group \nfor each opt-in/opt-out\n- the initial proposal was not backward compatible\n- in the long run, the consent should be to complete statements\n- as a consequence, we agreed that the consent group will be attached as an \nextension to <statements/>\n- If a statement is in a consent-group, all its elements must either be \nopt-in or all must be opt-out\n   * in order to be backward compatible with the existing semantics of P3P 1.0\n   * In order to avoid complicated and confusing semantics (e.g., what a \nconsent means if opt-in, opt-out,\n     and required things are mixed).\n- MTS will draft a proposal. Once this is agreed within the working group, \nwe will distribute it\n\n\n\n", "id": "lists-017-5326596"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Thursday 15 May 2003 03:20, Patrick.Hung@csiro.au wrote:\n> Hi Joseph, Based on the Registrar2Registry example discussed so far, I\n> simply create the SOAP messages as follows:\n\nOk! Various tweaks to those files are now included in \n  http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n  new revision: 1.12\nI've also done some re-org, and make sure that all XML is well-formed, and \nmost all of it is valid as well -- just haven't check the SOAP messages.\n\n> Again we are trying to introduce an extensible element for SOAP header,\n> or you have any other idea.\n\nNot sure, in your message I would read that header as the registrar \n(service) representing the policy associated with data (*transfer* along \nthe SOAP exchange) to the registry (recipient service). (There's also a \nquestion of how the registrar knows the registry's policy which I want to \nexplore a little further -- it can be out of band, I just want to document \nthe issue)  But in order.xml I included the Privacy element as a child of \nthe OrderInfo element, so it's like a \"tag\" associated with the data (at \nthe application layer) for clarity. What does it mean when such a tag is \nprovided in a SOAP header versus the actual application data? (We need to \ndig into the semantics of a SOAP envelope.)\n\n> Once we have all these protocols, we can start to discuss about the\n> issues of intermediaries and\n> ltimate SOAP receiver for the section \"Transferring to a third party.\"\n\nFrom the reorg perhaps you can see that I wasn't planning on introducing \nanother party... Granted, the present scenario isn't a proper \"SOAP 3-way \nintermediary\" because our first leg was mediated by XForms/HTTP, but I \nthink that's ok. The important thing for me is to explore the three \nquestions:\n1. The Scope of the P3P Service Provider and Recipients (given their P3P 1.0 \ndefinitions.\n2. The Scope of Layers and Bindings (HTTP and SOAP) -- I'm pretty confident \nwe've ruled WSDL and UDDI as orthogonal/optional.\n3. This question of should a privacy \"taggit\" be in the SOAP header, or with \nthe application data, or both? (I don't think \"taggit\" is a word, but a \nwhile ago I heard that gunpowder has little identifying particles in it \nthat can be used with forensics, and I remembered someone proposing that \nthe policy should also \"follow\" the solicited data. I just can't remember \nthe name.\"\n\nHow's that sound? And yes, we've made great progress, we're approaching the \npoint where it'd be good to explore the scenario with a web service guru \nwho could tell us how confused we are. <smile/>\n\n\n\n", "id": "lists-017-5335098"}, {"subject": "UA: User Agent TF call TODAY, 11 a", "content": "User Agent task force members, don't forget the call today!\n\n\n> Resent-From: public-p3p-spec@w3.org\n> From: Lorrie Cranor <lorrie@research.att.com>\n> Date: Fri May 9, 2003  8:23:05  PM America/New_York\n> To: public-p3p-spec@w3.org\n> Subject: UA: User Agent TF call May 16, 11 am\n>\n>\n> The User Agent task force will have a conference call at 11 am US \n> Eastern on Friday, May 16. It will be on the usual P3P bridge (see \n> http://www.w3.org/P3P/Group/Specification/1.1/meetings.html)\n>\n> We will discuss the comments on the translation documents \n> (http://www.w3.org/P3P/1.1/documents.html#ua) and especially the \n> questions I outlined at the end of\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2003Apr/0018.html\n>\n> If you are a member of this TF and you cannot participate, please send \n> your comments prior to the meeting.\n>\n> Lorrie\n>\n\n\n\n", "id": "lists-017-5345453"}, {"subject": "Meeting with Art 29 ITF 23rd Ma", "content": "Attached is an agenda for the meeting next week. I will advise times of\ntelco's early next week (need input from Rigo on availability of W3C\nbridges)\n\n_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\n\n\n\n\n\n\n\napplication/msword attachment: 23MayAgenda.doc\n\n\n\n\n", "id": "lists-017-5353876"}, {"subject": "UA: Jeremy's comments on highlevel question", "content": "Begin forwarded message:\n\n> From: \"Jeremy Epling\" <jepling@windows.microsoft.com>\n> Date: Fri May 16, 2003  3:41:46  AM America/New_York\n> To: \"Lorrie Cranor\" <lorrie@research.att.com>\n> Subject: RE: participation in p3p 1.1 wg\n>\n> Inline comments to an old mail of yours. Tell me if you wanted comments\n> on another mail.\n>\n>\n> Some Questions for the TF to Consider\n>\n> - Should we try to converge on a single set of translations? Should\n>    we come up with a long and short translation for each element,\n>    perhaps using the click through approach like NS uses? Should our\n>    guidelines list all acceptable translations they people submit\n>    rather than trying to converge or one or two?\n>\n> [Jeremy] I want to emphasize that I think these are guidelines and not\n> mandates for user agents. With that in mind I see no reason why we\n> should not try to converge on a single set of \"friendly text strings\". \n> I\n> don't think we need to add stylistic elements into the guideline, such\n> as the click through approach that NS has taken. I feel that content is\n> what is most important and that style of display is an important market\n> differentiator that should not be brought into the guidelines.\n>\n> - Should we recommend that P3P user agents be capable of displaying\n>    complete translations (all elements, including all human-readable\n>    elements)? If not, is there a minimum set of elements they should\n>    display? Or perhaps some guidelines on completeness that will\n>    prevent misleading users?\n>\n> [Jeremy] I think we should recommend the display of all elements except\n> for the data nodes. I think they are too granular and that the\n> categories amply provide enough information to the user for them to \n> make\n> their choice on whether on not to share their data.\n>\n> - Should we make any recommendations about displaying human-readable\n>    fields?\n>\n> [Jeremy] the obvious problem with these fields is localization. If I am\n> using a French browser I do not want to see French \"friendly text\n> strings\" and then a consequence in English.\n>\n> - Should we make any recommendations about displaying data elements\n>    and categories?\n>\n> [Jeremy] I feel that data categories are important information on which\n> the user basis their decision on whether or not to transmit their data.\n> Therefore, there should be recommendations about how they are \n> displayed.\n>\n>\n> - What other types of guidelines should we consider?\n>    - recommendation that UAs have ability to save policies\n>    - recommendation that UAs have ability to print policies (if run on\n>      devices connected to printers)\n> [jepling] This is important and simple functionality that needs\n> to be recommended.\n>    - recommendation that UAs refuse to process CPs for sites not\n>      \"properly\" P3P-enabled\n>    - recommendation for checking cookie policies (strengthen 2.3.2.7\n>      requirements)\n>\n> Jeremy Epling\n\n\n\n", "id": "lists-017-5361083"}, {"subject": "UA: minutes of 16 May UA TF cal", "content": "16 May 2003 User Agent Task Force Call\n\nParticipants\nLorrie Cranor - AT&T Research\nGiles Hogben - JRC\nJeremy Epling - Microsoft\nBrooks Dobbs - DoubleClick\nAri Schwartz - CDT\n\nWe discussed the question of whether to aim for a single translation of \nall P3P vocabulary elements or multiple translations. The consensus of \nthe group was that we should aim for a single translation. In the \nprocess of doing this we may come up with multiple alternatives that we \nwant to vet with lawyers and/or test in the usability lab, but at the \nend of the process we hope to have a single translation for each term.\n\nACTION: Lorrie, Jeremy, and anyone else who wants to, use one of the \ntranslation documents as a starting point and make revisions based on \nfeedback received so far and send to group by 23 May. The group will \nthen use these revised documents as a starting point for further \ndiscussion of each element.\n\nWe discussed the question of whether we should have guidelines on \ncompleteness of translations, including display of human-readable \nfields and specific data elements (as opposed to categories). The \nconsensus was that we should not recommend that user agents display all \npossible fields in a P3P policy, but we should have guidelines to \nensure that critical information gets displayed.\n\nACTION: All TF members should send to the mailing list by 23 May \nproposed guidelines related to what elements need to be included in a \ntranslation.\n\nWe discussed whether we wanted to make recommendations on issues that \ngo beyond displaying policy translations, for example guidelines on \nsaving and printing policies, checking the sanity of compact policies, \netc. The consensus was that we do want to try draft guidelines in this \narea.\n\nACTION: All TF members should send to the mailing list by 23 May other \nproposed user agent guidelines.\n\nACTION: Brooks will try to enumerate impossible combinations of tokens \nin compact policies\n\nOur next call will be Tuesday, May 27 at 11am US Eastern.\n\n\n\n", "id": "lists-017-5371313"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "> Ok! Various tweaks to those files are now included in \n>  http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n>  new revision: 1.12\n> I've also done some re-org, and make sure that all XML is well-formed, and\n\n> most all of it is valid as well -- just haven't check the SOAP messages.\n\nHi Joseph, Thanks a lot for your effort! Sorry to bother you... Would you \nplease help me to change my name as \"Patrick C. K. Hung\" instead of \n\"Patrick Hung\" on the document? I just want to make my name to be consistent\n\nin all places. Thanks for your help :-)\n\n> Not sure, in your message I would read that header as the registrar \n> (service) representing the policy associated with data (*transfer* along \n> the SOAP exchange) to the registry (recipient service). (There's also a \n> question of how the registrar knows the registry's policy which I want to \n> explore a little further -- it can be out of band, I just want to document\n\n> the issue)  \n\nI think this should fall into the management issues. As one can imagine \nthat a group of registries (Web services) can refer to one corporate \nprivacy policy stored at a well-known place, the registrars should also\nbe able to know the location via the WSDL documents or UDDI.\n\n> But in order.xml I included the Privacy element as a child of \n> the OrderInfo element, so it's like a \"tag\" associated with the data (at \n> the application layer) for clarity. What does it mean when such a tag is \n> provided in a SOAP header versus the actual application data? (We need to \n> dig into the semantics of a SOAP envelope.)\n\nI checked the SOAP 1.2 http://www.w3.org/TR/soap12-part0/ and \nhttp://www.w3.org/TR/2003/PR-soap12-part1-20030507. I could not find any\nspecific topic about extending the SOAP schemas as we faced in the WSDL\nschema... maybe I missed it??!! Anyway, I will do more studies next\nweek. \n\nIn another case, we may have something like this:\n\nRegistrar2Registry Request SOAP Message\n=======================================\n\n<?xml version='1.0' ?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\"> \n  <env:Header>\n    <my:Privacy\nxmlns:my=\"http://registry.example.com/2003/soap-header-p3p-extension.xsd\" \n          env:role=\"http://www.w3.org/2003/05/soap-envelope/role/next\"\n           env:mustUnderstand=\"true\"         \n           env:relay=\"true\">\n      <my:rel>P3Pv1</my:rel>\n \n<my:href>http://registry.example.com/P3P/PolicyReferences.xml</my:href>\n    </my:Privacy>\n  </env:Header>\n\n  <env:Body>\n    <p:OrderInfo\nxmlns:p=\"http://registry.example.com/RegisterService/RegisterDomainName\">\n      <p:PersonalInfo>\n        <p:Name>\n          <p:First>Joseph</p:First>\n          <p:Middle>M.</p:Middle>\n          <p:Last>Reagle Jr.</p:Last>\n        </p:Name>\n        <p:Address>\n          <p:Street>200 Tecnology Square</p:Street>\n          <p:City>Cambridge</p:City>\n          <p:State>MA</p:State>\n          <p:Zip>02139</p:Zip>\n        </p:Address>\n      </p:PersonalInfo>\n      <p:DomainInfo>\n        <p:TLD>com</p:TLD>\n        <p:DomainName>reagle.example</p:DomainName>\n      </p:DomainInfo>\n    </p:OrderInfo>\n  </env:Body>\n</env:Envelope>\n\n\nRegistry2Registrar Response SOAP Message\n========================================\n\n<?xml version='1.0' ?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\"> \n  <env:Header>\n    <my:Privacy\nxmlns:my=\"http://registry.example.com/2003/soap-header-p3p-extension.xsd\" \n          env:role=\"http://www.w3.org/2003/05/soap-envelope/role/next\"\n           env:mustUnderstand=\"true\"         \n           env:relay=\"true\">\n      <my:rel>P3Pv1</my:rel>\n \n<my:href>http://registry.example.com/P3P/PolicyReferences.xml</my:href>\n    </my:Privacy>\n  </env:Header>\n\n  <env:Body>\n    <p:RegistrationStatus\nxmlns:p=\"http://registry.example.com/RegisterService/RegisterDomainName\">\n      OK\n    </p:RegistrationStatus>\n  </env:Body>\n</env:Envelope>\n\nWhere the <Privacy /> element is specified in the\n\"http://registry.example.com/2003/soap-header-p3p-extension.xsd\"\n\n       <schema\ntargetNamespace=\"http://registry.example.com/2003/soap-header-p3p-extension.\nxsd\"\n              xmlns=\"http://www.w3.org/2000/10/XMLSchema\">\n           <complexType name=\"Privacy\">\n              <attribute name=\"rel\" type=\"string\" use=\"required\"/>\n              <attribute name=\"href\" type=\"string\" use=\"anyURL\"/>\n           </complexType>\n       </schema>\n\n> From the reorg perhaps you can see that I wasn't planning on introducing \n> another party... Granted, the present scenario isn't a proper \"SOAP 3-way \n> intermediary\" because our first leg was mediated by XForms/HTTP, but I \n> think that's ok. The important thing for me is to explore the three \n> questions:\n> 1. The Scope of the P3P Service Provider and Recipients (given their P3P\n1.0 \n> definitions.\n\nReferring to http://www.w3.org/TR/2003/PR-soap12-part1-20030507/, we should\nalso\nhave to consider/take the forwarding intermediaries and active\nintermediaries\nbetween the P3P Service Provider (Registrar) and Recipients (Registries):\n\nforwarding intermediaries\n-------------------------\n\"The semantics of one or more SOAP header blocks in a SOAP message, or the\nSOAP MEP used\nMAY require that the SOAP message be forwarded to another SOAP node on\nbehalf of the \ninitiator of the inbound SOAP message. In this case, the processing SOAP\nnode acts in \nthe role of a SOAP forwarding intermediary.\"\n\nactive intermediaries\n---------------------\n\"In addition to the processing performed by forwarding SOAP intermediaries,\nactive SOAP \nintermediaries undertake additional processing that can modify the outbound\nSOAP message \nin ways not described in the inbound SOAP message. That is, they can\nundertake processing \nnot described by SOAP header blocks in the incoming SOAP message. The\npotential set of \nservices provided by an active SOAP intermediary includes, but is not\nlimited to: security \nservices, annotation services, and content manipulation services.\"\n\n> 2. The Scope of Layers and Bindings (HTTP and SOAP) -- I'm pretty\nconfident \n> we've ruled WSDL and UDDI as orthogonal/optional.\n\nYes, I agree with you. Further, a SOAP header element is optional. If we\nspecify the \nprivacy policy in the SOAP header, can we also say that the privacy policy\nis also\noptional. :-) It sounds pretty logically, right?\n\n> 3. This question of should a privacy \"taggit\" be in the SOAP header, or\nwith \n> the application data, or both? (I don't think \"taggit\" is a word, but a \n> while ago I heard that gunpowder has little identifying particles in it \n> that can be used with forensics, and I remembered someone proposing that \n> the policy should also \"follow\" the solicited data. I just can't remember \n> the name.\"\n\nReferring to http://www.w3.org/TR/soap12-part0/, we can check these\ndescriptions:\n\n\"A SOAP header is an extension mechanism that provides a way to pass \ninformation in SOAP messages that is not application payload. Such \n\"control\" information includes, for example, passing directives or \ncontextual information related to the processing of the message. \nThis allows a SOAP message to be extended in an application-specific \nmanner. The immediate child elements of the env:Header element are \ncalled header blocks, and represent a logical grouping of data which, \nas shown later, can individually be targeted at SOAP nodes that might \nbe encountered in the path of a message from a sender to an ultimate \nreceiver.\n\nSOAP headers have been designed in anticipation of various uses for SOAP, \nmany of which will involve the participation of other SOAP processing nodes \n- called SOAP intermediaries - along a message's path from an initial SOAP \nsender to an ultimate SOAP receiver. This allows SOAP intermediaries to \nprovide value-added services. Headers, as shown later, may be inspected, \ninserted, deleted or forwarded by SOAP nodes encountered along a SOAP\nmessage \npath.\"\n\nAny help? More thoughts are required... \n\n> How's that sound? And yes, we've made great progress, we're approaching\nthe \n> point where it'd be good to explore the scenario with a web service guru \n> who could tell us how confused we are. <smile/>\n\nAll sound good. By the way, do you have a \"roadmap\" in your mind for this\ntask force? I believe that we do have to think something like a WS-P3P\npolicy such\nas WS-Privacy for Web services after this framework is done.\n\nSome very minor typos in the current version:\n(1) There are two places \"The the ...\"\n(2) The response SOAP message is same as the request SOAP message.\n\nHave a nice weekend! Talk to you later. Patrick.\n\n\n\n", "id": "lists-017-5379795"}, {"subject": "UA: potenial requirement/guidelines on acceptable Purpose / Categ ory combination", "content": "For once I am actually did something sooner rather than later.\n\nI am attaching a useful quote from the spec and then some thoughts on\ncategories that should IMHO be required given certain declared purposes.\nThe thought being, to achieve X purpose, at least Y data is required.\n\nP3P Spec 1.0 2.3.2.7 The COOKIE-INCLUDE and COOKIE-EXCLUDE elements\nA cookie policy MUST cover any data (within the scope of P3P) that is stored\nin that cookie or linked via that cookie. It MUST also reference all\npurposes associated with data stored in that cookie or enabled by that\ncookie. In addition, any data/purpose stored or linked via a cookie MUST\nalso be put in the cookie policy.\n\nIt therefore follows that if you declare any of the following purposes that\ndeal in identified individuals you would need to have (either directly or\nlinked via that cookie) one of the listed categories:\n\nIndividual-Analysis, IVA:  Information may be used to determine the habits,\ninterests, or other characteristics of individuals and combine it with\nidentified data for the purpose of research, analysis and reporting. For\nexample, an online Web site for a physical store may wish to analyze how\nonline shoppers make offline purchases.\n*Physical\n*Online\n*Financial\n*Purchase\n*Government\nRATIONAL: This purpose requires \"identified data\".  While it is\npossible to have other categories associated with an identified subject, the\nactual identification is impossible without a data element associated with\none or more of the above categories.\n\nIndividual-Decision, IVD: Information may be used to determine the habits,\ninterests, or other characteristics of individuals and combine it with\nidentified data to make a decision that directly affects that individual.\nFor example, an online store suggests items a visitor may wish to purchase\nbased on items he has purchased during previous visits to the Web site.\n*Physical\n*Online\n*Financial\n*Purchase\n*Government\nRATIONAL: This purpose requires \"identified data\".  While it is\npossible to have other categories associated with an identified subject, the\nactual identification is impossible without a data element associated with\none or more of the above categories.\n\nContact, CON: Contacting Visitors for Marketing of Services or Products:\nInformation may be used to contact the individual, through a communications\nchannel other than voice telephone, for the promotion of a product or\nservice. This includes notifying visitors about updates to the Web site.\nThis does not include a direct reply to a question or comment or customer\nservice for a single transaction -- in those cases, would be used. In\naddition, this does not include marketing via customized Web content or\nbanner advertisements embedded in sites the user is visiting -- these cases\nwould be covered by the , and , or and purposes.\n*Physical\n*Online\nRATIONAL:  Logic dictates that to contact an individual the\ninitiator of the contact would possess a data element identifying the\nindividual in a place where he or she would be contacted - either the online\nor offline worlds.  This would presuppose elements contained by one of the\nabove categories. \n\nTelemarketing, TEL: Contacting Visitors for Marketing of Services or\nProducts Via Telephone: Information may be used to contact the individual\nvia a voice telephone call for promotion of a product or service. This does\nnot include a direct reply to a question or comment or customer service for\na single transaction -- in those cases, would be used.\n*Physical\nRATIONAL:   Again logic dictates that if you are going to contact someone\nvia telephone, you at least have a data element that contains phone numbers.\nThese data elements should all be within the Physical category\n\nThoughts?\n\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n\n", "id": "lists-017-5398394"}, {"subject": "Re: A little survey about Privacy Policies in Web Service", "content": "Hi Joseph and Lorrie,\n\nThanks a lot for your comments.\n\nBased on different business categories of the ICWS'03 attendees (Question\n1), the major purpose of this little survey is to learn:\n(a) How many attendees are working on Web services implementation? (Question\n2)\n(b) Referring to some previous results, how many of them still agree that\nsecurity issues are the biggest obstacles to Web services implementation?\n(Question 3)\n(c) How many of them are aware of privacy issues or P3P in Web services?\n(Question 4, 5, and 6)\n\nI am trying to revise the questionnaire as follows:\n\n1. Which business category you are belonging to?\n\n* Industry.\n* Academia.\n* Government.\n* Non-profit Organization.\n* Others. Please specify: ___________________\n\n2. Are you involved in any Web services implementation in these years?\n\n* Yes.\n* No.\n\n3. Do you agree that security issues (e.g., authentication, authorization,\nand etc) are the biggest obstacles to Web services implementation?\n\n* Yes.\n* No.\n* Not Sure.\n\n4. Are you aware of privacy issues (e.g., privacy policies) in Web services\nimplementation?\n\n* Yes.\n* No.\n* Don't Know.\n\n5. Have you ever heard the Platform for Privacy Preferences (P3P) Project at\nthe W3C?\n\n* Yes.\n* No.\n* Not Sure.\n\n6. Have you ever heard any research topic about P3P and Web services?\n\n* Yes.\n* No.\n* Not Sure.\n\nAny comment/suggestion is highly appreciated. Thanks a lot again!\n\nPatrick.\n\n\n\n", "id": "lists-017-5409710"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Referring to my previous e-mail, here is my revision for those SOAP\nmessages. \n\nI removed the attribute env:relay=\"true\" from the privacy element. Referring\n\nto http://www.w3.org/TR/2003/PR-soap12-part0-20030507/:\n\n\"SOAP Version 1.2 defines another optional attribute for header blocks,\nenv:relay \nof type xs:boolean, which indicates if a header block targeted at a SOAP\nintermediary \nmust be relayed if it is not processed.\n \nThus, the header block does not have an env:relay attribute, which is\nequivalent to \nhaving it with the value env:relay=\"false\". Hence, this header is not\nforwarded if \nit is not processed.\"\n\nWe may have to consider that all the intermediaries have to\n\"understand/agree with\" and \n\"process\" the privacy policy if they handle the SOAP messages. Any comment?\n\nRegistrar2Registry Request SOAP Message\n=======================================\n\n<?xml version='1.0' ?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\"> \n  <env:Header>\n    <my:Privacy\n \nxmlns:my=\"http://registry.example.com/2003/soap-header-p3p-extension.xsd\" \n          env:role=\"http://www.w3.org/2003/05/soap-envelope/role/next\"\n          env:mustUnderstand=\"true\">\n      <my:rel>P3Pv1</my:rel>\n \n<my:href>http://registry.example.com/P3P/PolicyReferences.xml</my:href>\n    </my:Privacy>\n  </env:Header>\n\n  <env:Body>\n    <p:OrderInfo\nxmlns:p=\"http://registry.example.com/RegisterService/RegisterDomainName\">\n      <p:PersonalInfo>\n        <p:Name>\n          <p:First>Joseph</p:First>\n          <p:Middle>M.</p:Middle>\n          <p:Last>Reagle Jr.</p:Last>\n        </p:Name>\n        <p:Address>\n          <p:Street>200 Tecnology Square</p:Street>\n          <p:City>Cambridge</p:City>\n          <p:State>MA</p:State>\n          <p:Zip>02139</p:Zip>\n        </p:Address>\n      </p:PersonalInfo>\n      <p:DomainInfo>\n        <p:TLD>com</p:TLD>\n        <p:DomainName>reagle.example</p:DomainName>\n      </p:DomainInfo>\n    </p:OrderInfo>\n  </env:Body>\n</env:Envelope>\n\n\nRegistry2Registrar Response SOAP Message\n========================================\n\n<?xml version='1.0' ?>\n<env:Envelope xmlns:env=\"http://www.w3.org/2003/05/soap-envelope\"> \n  <env:Header>\n    <my:Privacy\nxmlns:my=\"http://registry.example.com/2003/soap-header-p3p-extension.xsd\" \n          env:role=\"http://www.w3.org/2003/05/soap-envelope/role/next\"\n          env:mustUnderstand=\"true\">\n      <my:rel>P3Pv1</my:rel>\n \n<my:href>http://registry.example.com/P3P/PolicyReferences.xml</my:href>\n    </my:Privacy>\n  </env:Header>\n\n  <env:Body>\n    <p:RegistrationStatus\nxmlns:p=\"http://registry.example.com/RegisterService/RegisterDomainName\">\n      OK\n    </p:RegistrationStatus>\n  </env:Body>\n</env:Envelope>\n\nAs there are three standardized roles defined (see SOAP Part 1, section\n2.2), which are\n\n\"http://www.w3.org/2003/05/soap-envelope/role/none\" (hereafter simply\n\"none\") \n\"http://www.w3.org/2003/05/soap-envelope/role/next\" (hereafter simply\n\"next\"), and \n\"http://www.w3.org/2003/05/soap-envelope/role/ultimateReceiver\" (hereafter\nsimply \"ultimateReceiver\"). \n\nReferring to http://www.w3.org/TR/2003/PR-soap12-part0-20030507/:\n\n\"Targeting the header block at the role \"next\" together with the env:relay\nattribute set to \"true\" can \nalways serve to ensure that each intermediary has a chance to examine the\nheader, because one of the \nanticipated uses of the \"next\" role is with header blocks that carry\ninformation that are expected to \npersist along a SOAP message path. Of course, the application designer can\nalways define a custom role \nthat allows targetting at specific intermediaries that assume this role.\nTherefore, there is no \nrestriction on the use of the env:relay attribute with any role except of\ncourse the roles of \"none\" \nand \"ultimateReceiver\", for which it is meaningless.\"\n\nI am also thinking whether we should create a special role that will\nunderstand and process the\nprivacy policies. Any suggestion?\n\n\n\n", "id": "lists-017-5419096"}, {"subject": "RE: potenial requirement/guidelines on acceptable Purpose / Categ  ory combination", "content": "Brooks,\n\nFWIW, I can think of counter-examples for IVA/IVD. On a retail site, you\nmight enter a customer loyalty ID from a card given to you at a physical\nstore, which would then be stored in or linked to a cookie. I don't think\nthat ID belongs to any of the categories you listed, but it could be used on\nthe back-end for IVA/IVD purposes.\n\nI wasn't on the UA call, so I'm curious -- what's the purpose of this\nanalysis?\n\nJack Humphrey\nDevelopment Manager, Coremetrics\n\n-----Original Message-----\nFrom: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\nSent: Friday, May 16, 2003 12:52 PM\nTo: public-p3p-spec@w3.org\nSubject: UA: potenial requirement/guidelines on acceptable Purpose /\nCateg ory combinations\n\n\n\nFor once I am actually did something sooner rather than later.\n\nI am attaching a useful quote from the spec and then some thoughts on\ncategories that should IMHO be required given certain declared purposes.\nThe thought being, to achieve X purpose, at least Y data is required.\n\nP3P Spec 1.0 2.3.2.7 The COOKIE-INCLUDE and COOKIE-EXCLUDE elements\nA cookie policy MUST cover any data (within the scope of P3P) that is stored\nin that cookie or linked via that cookie. It MUST also reference all\npurposes associated with data stored in that cookie or enabled by that\ncookie. In addition, any data/purpose stored or linked via a cookie MUST\nalso be put in the cookie policy.\n\nIt therefore follows that if you declare any of the following purposes that\ndeal in identified individuals you would need to have (either directly or\nlinked via that cookie) one of the listed categories:\n\nIndividual-Analysis, IVA:  Information may be used to determine the habits,\ninterests, or other characteristics of individuals and combine it with\nidentified data for the purpose of research, analysis and reporting. For\nexample, an online Web site for a physical store may wish to analyze how\nonline shoppers make offline purchases.\n*Physical\n*Online\n*Financial\n*Purchase\n*Government\nRATIONAL: This purpose requires \"identified data\".  While it is\npossible to have other categories associated with an identified subject, the\nactual identification is impossible without a data element associated with\none or more of the above categories.\n\nIndividual-Decision, IVD: Information may be used to determine the habits,\ninterests, or other characteristics of individuals and combine it with\nidentified data to make a decision that directly affects that individual.\nFor example, an online store suggests items a visitor may wish to purchase\nbased on items he has purchased during previous visits to the Web site.\n*Physical\n*Online\n*Financial\n*Purchase\n*Government\nRATIONAL: This purpose requires \"identified data\".  While it is\npossible to have other categories associated with an identified subject, the\nactual identification is impossible without a data element associated with\none or more of the above categories.\n\nContact, CON: Contacting Visitors for Marketing of Services or Products:\nInformation may be used to contact the individual, through a communications\nchannel other than voice telephone, for the promotion of a product or\nservice. This includes notifying visitors about updates to the Web site.\nThis does not include a direct reply to a question or comment or customer\nservice for a single transaction -- in those cases, would be used. In\naddition, this does not include marketing via customized Web content or\nbanner advertisements embedded in sites the user is visiting -- these cases\nwould be covered by the , and , or and purposes.\n*Physical\n*Online\nRATIONAL:  Logic dictates that to contact an individual the\ninitiator of the contact would possess a data element identifying the\nindividual in a place where he or she would be contacted - either the online\nor offline worlds.  This would presuppose elements contained by one of the\nabove categories. \n\nTelemarketing, TEL: Contacting Visitors for Marketing of Services or\nProducts Via Telephone: Information may be used to contact the individual\nvia a voice telephone call for promotion of a product or service. This does\nnot include a direct reply to a question or comment or customer service for\na single transaction -- in those cases, would be used.\n*Physical\nRATIONAL:   Again logic dictates that if you are going to contact someone\nvia telephone, you at least have a data element that contains phone numbers.\nThese data elements should all be within the Physical category\n\nThoughts?\n\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n\n", "id": "lists-017-5432532"}, {"subject": "RE: potential requirement/guidelines on acceptable Purpose / Cate g ory combination", "content": "I think the example Jack raises is exactly what I am trying to get at.  If a\ncookie value is set to a consumer loyalty card # for company XYZ and company\nXYZ has a CRM database with name, address, phone and email tied to the\nloyalty number, the correct disclosure (IMHO) is NOT UNI but rather PHY, UNI\nand ONL (so far as categories are concerned).  Again if we are talking about\n\"linked to\" - isn't a loyalty card # almost by definition the linking\nelement within a CRM? \n\nWhat this all boils down to is, if the data collector declares a purpose\nthat requires identity, then they obviously HAVE the identity.  If you claim\nthat you are going to telemarket to me, you have my phone number.  I think\nthat it is now generally understood that the actual phone number won't be\nstored as the clear text value within the cookie but rather referenced\nthrough a UNI value of the cookie.  To the data subject it doesn't matter if\nyou reference using phone #, loyalty #, credit card # or a SSN so long as\nthe intent or the data construct is to use the value to reference other data\n(though clearly for some these you may need to go past simply UNI even for\nthe reference string itself).\n\nThe purpose of the analysis is to propose possible guidelines on UAs to take\nsome form of action on impossible or incorrect policies (likely treatment as\nthough there were no policy).\n\n-Brooks\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Monday, May 19, 2003 1:22 PM\nTo: 'Dobbs, Brooks'; public-p3p-spec@w3.org\nSubject: RE: potenial requirement/guidelines on acceptable Purpose /\nCateg ory combinations\n\n\nBrooks,\n\nFWIW, I can think of counter-examples for IVA/IVD. On a retail site, you\nmight enter a customer loyalty ID from a card given to you at a physical\nstore, which would then be stored in or linked to a cookie. I don't think\nthat ID belongs to any of the categories you listed, but it could be used on\nthe back-end for IVA/IVD purposes.\n\nI wasn't on the UA call, so I'm curious -- what's the purpose of this\nanalysis?\n\nJack Humphrey\nDevelopment Manager, Coremetrics\n\n-----Original Message-----\nFrom: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\nSent: Friday, May 16, 2003 12:52 PM\nTo: public-p3p-spec@w3.org\nSubject: UA: potenial requirement/guidelines on acceptable Purpose /\nCateg ory combinations\n\n\n\nFor once I am actually did something sooner rather than later.\n\nI am attaching a useful quote from the spec and then some thoughts on\ncategories that should IMHO be required given certain declared purposes.\nThe thought being, to achieve X purpose, at least Y data is required.\n\nP3P Spec 1.0 2.3.2.7 The COOKIE-INCLUDE and COOKIE-EXCLUDE elements\nA cookie policy MUST cover any data (within the scope of P3P) that is stored\nin that cookie or linked via that cookie. It MUST also reference all\npurposes associated with data stored in that cookie or enabled by that\ncookie. In addition, any data/purpose stored or linked via a cookie MUST\nalso be put in the cookie policy.\n\nIt therefore follows that if you declare any of the following purposes that\ndeal in identified individuals you would need to have (either directly or\nlinked via that cookie) one of the listed categories:\n\nIndividual-Analysis, IVA:  Information may be used to determine the habits,\ninterests, or other characteristics of individuals and combine it with\nidentified data for the purpose of research, analysis and reporting. For\nexample, an online Web site for a physical store may wish to analyze how\nonline shoppers make offline purchases.\n*Physical\n*Online\n*Financial\n*Purchase\n*Government\nRATIONAL: This purpose requires \"identified data\".  While it is\npossible to have other categories associated with an identified subject, the\nactual identification is impossible without a data element associated with\none or more of the above categories.\n\nIndividual-Decision, IVD: Information may be used to determine the habits,\ninterests, or other characteristics of individuals and combine it with\nidentified data to make a decision that directly affects that individual.\nFor example, an online store suggests items a visitor may wish to purchase\nbased on items he has purchased during previous visits to the Web site.\n*Physical\n*Online\n*Financial\n*Purchase\n*Government\nRATIONAL: This purpose requires \"identified data\".  While it is\npossible to have other categories associated with an identified subject, the\nactual identification is impossible without a data element associated with\none or more of the above categories.\n\nContact, CON: Contacting Visitors for Marketing of Services or Products:\nInformation may be used to contact the individual, through a communications\nchannel other than voice telephone, for the promotion of a product or\nservice. This includes notifying visitors about updates to the Web site.\nThis does not include a direct reply to a question or comment or customer\nservice for a single transaction -- in those cases, would be used. In\naddition, this does not include marketing via customized Web content or\nbanner advertisements embedded in sites the user is visiting -- these cases\nwould be covered by the , and , or and purposes.\n*Physical\n*Online\nRATIONAL:  Logic dictates that to contact an individual the\ninitiator of the contact would possess a data element identifying the\nindividual in a place where he or she would be contacted - either the online\nor offline worlds.  This would presuppose elements contained by one of the\nabove categories. \n\nTelemarketing, TEL: Contacting Visitors for Marketing of Services or\nProducts Via Telephone: Information may be used to contact the individual\nvia a voice telephone call for promotion of a product or service. This does\nnot include a direct reply to a question or comment or customer service for\na single transaction -- in those cases, would be used.\n*Physical\nRATIONAL:   Again logic dictates that if you are going to contact someone\nvia telephone, you at least have a data element that contains phone numbers.\nThese data elements should all be within the Physical category\n\nThoughts?\n\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n\n", "id": "lists-017-5445903"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n $Revision: 1.14 $ on $Date: 2003/05/19 22:58:59 $ GMT by $Author: reagle $\n\nPatrick, I integrated your latest contribs with the doc:\n1. I include the my:Privacy element in the application data that is sent \nfrom registrar2registry.\n2. I call at the SOAP envelop issue (and XML encryption) as a special case.\n2.1 On the question of do we need to say anything more about forwarding and \nactive intermediaries, I would prefer to rely upon the text in the spec now \nunless we are further presssed.\n3. I'm going to be on Holiday Thur/Fri, then attending a conference much of \nnext week (see .sig). But I hope to address most of the @@to-do's before \nthen (feel free to comment on them), then I think the document will be \nsemi-coherent for other readers. I plan on trying to get some attention \nfrom my Web Service colleagues, but I know this week they are at WWW2003 \nand many might be travelling catching up next week. But I think we're still \non schedule for getting/responding to outside feedback in the month of \nJune.\n\n-- \n* I will be travelling May 22/23, and attending OSCOM3 May 28-30. \nI will not be as responsive during these periods but will \nrespond to any email as soon as possible upon my return.\n\n\n\n", "id": "lists-017-5462620"}, {"subject": "Re: potential requirement/guidelines on acceptable Purpose / Cate g ory combination", "content": "On Mon, May 19, 2003 at 02:25:42PM -0400, Dobbs, Brooks wrote:\n> What this all boils down to is, if the data collector declares a purpose\n> that requires identity, then they obviously HAVE the identity.  If you claim\n> that you are going to telemarket to me, you have my phone number.  I think\n> that it is now generally understood that the actual phone number won't be\n> stored as the clear text value within the cookie but rather referenced\n> through a UNI value of the cookie.  To the data subject it doesn't matter if\n> you reference using phone #, loyalty #, credit card # or a SSN so long as\n> the intent or the data construct is to use the value to reference other data\n> (though clearly for some these you may need to go past simply UNI even for\n> the reference string itself).\n\nhttp://www.w3.org/TR/P3P/#cookies\n\nI think we specified that already by saying in 2.3.2.7 The\nCOOKIE-INCLUDE and COOKIE-EXCLUDE elements:\n\nA cookie policy MUST cover any data (within the scope of P3P) that is\nstored in that cookie or linked via that cookie. It MUST also reference\nall purposes associated with data stored in that cookie or enabled by\nthat cookie. In addition, any data/purpose stored or linked via a cookie\nMUST also be put in the cookie policy. In addition, if that linked data\nis collected by HTTP, then the policy that covers that GET/POST/whatever\nrequest must cover that data collection.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5471463"}, {"subject": "RE: potential requirement/guidelines on acceptable Purpose / Cate  g ory combination", "content": "I think I understand now. I always think about the cookie policy declaring\nwhat data is being collected for what purposes (maybe because that's how\nuser agents tend to express it), but it also has to declare what other data\nwill be used for those purposes.\n\nLet's say that my user agent allows me to express that:\n1. I don't want to accept or send cookies containing sensitive personal\ninformation.\n2. I don't want to accept or send any cookies whose purpose is to enable\nsomeone to contact me by phone or email for marketing purposes.\n\nIn the example I gave, if a site sets a cookie containing a loyalty number\n(UNI) and declares that it is for indiv. analysis (IVA), then as I\nunderstand it now it should also declare purchase (PUR) since that's what\nthe the loyalty # will be used to look up for the analysis. The fact that\nthe company could also look up my phone number and email address is not\nrelevant since that's not the purpose of this cookie, right? Okay, that\nmakes sense, and the user agent implementation might allow that cookie if it\ndidn't map UNI and PUR to \"sensitive personal information.\"\n\nBut I don't think the user agent could allow you to express #1 but not #2\n(say you don't mind telemarketing and online contact). Then if the loyalty #\nwas being collected for telemarketing, the policy would have to include PHY\nin addition to UNI and TEL, and the user agent couldn't allow the cookie,\neven though it doesn't violate the expressed preferences, because it\ncouldn't distinguish that the cookie doesn't contain a phone number. That\ntroubles me, but it's something of an orthogonal issue to the points you\nraise.\n\nJack\n\n-----Original Message-----\nFrom: Rigo Wenning\nTo: public-p3p-spec@w3.org\nSent: 5/20/2003 5:06 AM\nSubject: Re: potential requirement/guidelines on acceptable Purpose / Cate\ng ory combinations\n\n\nOn Mon, May 19, 2003 at 02:25:42PM -0400, Dobbs, Brooks wrote:\n> What this all boils down to is, if the data collector declares a\npurpose\n> that requires identity, then they obviously HAVE the identity.  If you\nclaim\n> that you are going to telemarket to me, you have my phone number.  I\nthink\n> that it is now generally understood that the actual phone number won't\nbe\n> stored as the clear text value within the cookie but rather referenced\n> through a UNI value of the cookie.  To the data subject it doesn't\nmatter if\n> you reference using phone #, loyalty #, credit card # or a SSN so long\nas\n> the intent or the data construct is to use the value to reference\nother data\n> (though clearly for some these you may need to go past simply UNI even\nfor\n> the reference string itself).\n\nhttp://www.w3.org/TR/P3P/#cookies\n\nI think we specified that already by saying in 2.3.2.7 The\nCOOKIE-INCLUDE and COOKIE-EXCLUDE elements:\n\nA cookie policy MUST cover any data (within the scope of P3P) that is\nstored in that cookie or linked via that cookie. It MUST also reference\nall purposes associated with data stored in that cookie or enabled by\nthat cookie. In addition, any data/purpose stored or linked via a cookie\nMUST also be put in the cookie policy. In addition, if that linked data\nis collected by HTTP, then the policy that covers that GET/POST/whatever\nrequest must cover that data collection.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5480113"}, {"subject": "RE: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nThanks a lot for your effort.\n\n> 2. I call at the SOAP envelop issue (and XML encryption) as a special\ncase.\n\nI don't quite understand here as I can't find anything related to \"XML\nEncryption\"\nin the working draft.\n\n> 2.1 On the question of do we need to say anything more about forwarding\nand \n> active intermediaries, I would prefer to rely upon the text in the spec\nnow \n> unless we are further presssed.\n\nI read the working draft again. I think that the \"Transfering Data to a\nThird\nParty\" section is strongly related to the \"Intermediaries.\" Thus, I would\nrecommend to combine these two sections. In particular, those three types of\ninformation flow may be used to determine the role of SOAP intermediaries.\nI will spend more thoughts on it next week and discuss with you later.\n\n> 3. I'm going to be on Holiday Thur/Fri, then attending a conference much\nof \n> next week (see .sig). But I hope to address most of the @@to-do's before \n> then (feel free to comment on them), then I think the document will be \n> semi-coherent for other readers. I plan on trying to get some attention \n> from my Web Service colleagues, but I know this week they are at WWW2003 \n> and many might be travelling catching up next week. But I think we're\nstill \n> on schedule for getting/responding to outside feedback in the month of \n> June.\n\nThat's great if your Web service colleagues can also be participayting in \ndiscussion or giving us some comments/suggestions.\n\nThere is a few minor typos, and you can find them by using \"find:\"\n\n(1) \"..\"\n(2) \"a a\"\n(3) \"th\"\n(4) \"business to consumer\" should it be \"business-to-consumer?\"\n\nI will also be on business trip on May 22 & 23. I am planning to do more\nstudies on those \"@ @\" points in the working draft. Beside it, I also\nconsider\nwhether we should also introduce P3P into UDDI in order to attract UDDI\nresearchers.\nIn addition, have you ever thought about XrML for protecting the privacy of\ndigital content as what Microsoft is doing right now? Should we also mention\nthat in this working draft.\n \n> * I will be travelling May 22/23, and attending OSCOM3 May 28-30. \n> I will not be as responsive during these periods but will \n> respond to any email as soon as possible upon my return.\n\nHave a nice trip and talk to you next week.\n\nCheers,\n\nPatrick.\n\n\n\n", "id": "lists-017-5492154"}, {"subject": "RE: potential requirement/guidelines on acceptable Purpose / Cate   g ory combination", "content": "Okay we are closer but not quite there.  The requirement is \"linked\" not\n\"used\".  If you use it or not you still need to declare it (what stops you\nin the future?).  What my initial point is, is if you in fact USE it, it is\nprima facie evidence that you have it linked.\n\nSo to follow our example.  If you have a cookie set to a Loyalty # abc123.\nAnd the company's internal DB looks like this:\n\nclient_table\nloyalty_id (loyalty #)  PRIMARY KEY\nlname\nfname\naddress\nphone_number\nssn\npolitical_party \n\npurchase_table\norder_id  PRIMARY KEY\nloyalty_id FORIEGN KEY --> client_table.loyalty_id\nvalue\nsku\n\nAnd the initial web transaction log may look like:\n\nWebLog\nIP\nTimeStamp\nRemote_User\nUser_agent\nURL_requested\nRefer\nRequestStatus\nFileSize\nCookie\n\n\nHere we have an architecture where loyalty_id is either the foreign or\nprimary key to 3 tables.  If I have a loyalty_id, what can I look up?  what\nis \"linked\"?\n\nThere may be *some* argument (not mine) that it doesn't link data elements\nwithin the WebLog as they may or may not be directly queriable (still there\nis a static link between e.g. Cookie and URL_requested).\n\nHowever, IMHO, in the example above the data controller doesn't have to act\nupon the political_party field to need to declare it.  Why?  In the example\nabove polital_party has the exact same relationship to loyalty_id as does\nphone_number.  The fact that you USE one or the other has no impact on\nwhether it is linked or not.\n\n\n-Brooks\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Tuesday, May 20, 2003 8:35 AM\nTo: 'public-p3p-spec@w3.org '\nSubject: RE: potential requirement/guidelines on acceptable Purpose /\nCate g ory combinations\n\n\n\nI think I understand now. I always think about the cookie policy declaring\nwhat data is being collected for what purposes (maybe because that's how\nuser agents tend to express it), but it also has to declare what other data\nwill be used for those purposes.\n\nLet's say that my user agent allows me to express that:\n1. I don't want to accept or send cookies containing sensitive personal\ninformation.\n2. I don't want to accept or send any cookies whose purpose is to enable\nsomeone to contact me by phone or email for marketing purposes.\n\nIn the example I gave, if a site sets a cookie containing a loyalty number\n(UNI) and declares that it is for indiv. analysis (IVA), then as I\nunderstand it now it should also declare purchase (PUR) since that's what\nthe the loyalty # will be used to look up for the analysis. The fact that\nthe company could also look up my phone number and email address is not\nrelevant since that's not the purpose of this cookie, right? Okay, that\nmakes sense, and the user agent implementation might allow that cookie if it\ndidn't map UNI and PUR to \"sensitive personal information.\"\n\nBut I don't think the user agent could allow you to express #1 but not #2\n(say you don't mind telemarketing and online contact). Then if the loyalty #\nwas being collected for telemarketing, the policy would have to include PHY\nin addition to UNI and TEL, and the user agent couldn't allow the cookie,\neven though it doesn't violate the expressed preferences, because it\ncouldn't distinguish that the cookie doesn't contain a phone number. That\ntroubles me, but it's something of an orthogonal issue to the points you\nraise.\n\nJack\n\n-----Original Message-----\nFrom: Rigo Wenning\nTo: public-p3p-spec@w3.org\nSent: 5/20/2003 5:06 AM\nSubject: Re: potential requirement/guidelines on acceptable Purpose / Cate\ng ory combinations\n\n\nOn Mon, May 19, 2003 at 02:25:42PM -0400, Dobbs, Brooks wrote:\n> What this all boils down to is, if the data collector declares a\npurpose\n> that requires identity, then they obviously HAVE the identity.  If you\nclaim\n> that you are going to telemarket to me, you have my phone number.  I\nthink\n> that it is now generally understood that the actual phone number won't\nbe\n> stored as the clear text value within the cookie but rather referenced\n> through a UNI value of the cookie.  To the data subject it doesn't\nmatter if\n> you reference using phone #, loyalty #, credit card # or a SSN so long\nas\n> the intent or the data construct is to use the value to reference\nother data\n> (though clearly for some these you may need to go past simply UNI even\nfor\n> the reference string itself).\n\nhttp://www.w3.org/TR/P3P/#cookies\n\nI think we specified that already by saying in 2.3.2.7 The\nCOOKIE-INCLUDE and COOKIE-EXCLUDE elements:\n\nA cookie policy MUST cover any data (within the scope of P3P) that is\nstored in that cookie or linked via that cookie. It MUST also reference\nall purposes associated with data stored in that cookie or enabled by\nthat cookie. In addition, any data/purpose stored or linked via a cookie\nMUST also be put in the cookie policy. In addition, if that linked data\nis collected by HTTP, then the policy that covers that GET/POST/whatever\nrequest must cover that data collection.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5502785"}, {"subject": "Re: potential requirement/guidelines on acceptable Purpose / Cate  g ory combination", "content": "Jack, \n\nbefore going down that old path again, think a moment of the difference\nbetween collecting information and using information and go away from\nthe compact format mentally. \n\nI collect information. I declare the collection of information. The\nproblem of cookies is, that they are used as unique ids that glue a\ncustomer profile together. \n\nNow in your example, the site example.com has already nearly all\ninformation. Relevant new information collected is the purchase. With\nthe unique id this adds to the profile. The loyalty # is also a unique\nid that represents all the data, that the example.com already has, even\nthe phone-number that you mention below. in fact, your example has two\nunique ids: the cookie and the loyalty #\n\nBut what are they are going to do with that data? Here we come to\npurpose. and there, a company might want to attach some purpose to that\ndata. eg:\"This purchase-info will not be used to contact you\". \n\nAnother issue is how to enforce that declaration inside a company and\nthere we go to http://www.w3.org/2003/p3p-ws/\n\nP3P allows a very fine grained declaration, so fine grained that one can\nget lost..\n\nBest, \n\nRigo\n\nOn Tue, May 20, 2003 at 07:35:18AM -0500, Humphrey, Jack wrote:\n> But I don't think the user agent could allow you to express #1 but not #2\n> (say you don't mind telemarketing and online contact). Then if the loyalty #\n> was being collected for telemarketing, the policy would have to include PHY\n> in addition to UNI and TEL, and the user agent couldn't allow the cookie,\n> even though it doesn't violate the expressed preferences, because it\n> couldn't distinguish that the cookie doesn't contain a phone number. That\n> troubles me, but it's something of an orthogonal issue to the points you\n> raise.\n> \n\n\n\n", "id": "lists-017-5518137"}, {"subject": "Re: potential requirement/guidelines on acceptable Purpose / Cate   g ory combination", "content": "Brooks, \n\nlinked means every data linked to every unique id transmitted. In your\nexample, you create confusion with two unique id's namely cookie and\nloyalty #. If both are linked, they also link to all data that is\nattached to both unique id's.  (logical or)\n\nWhat you _do, is drawing conclusions from data declarations to usages and\nvice versa. Those heuristics might be useful for a user agent. But I\ndon't want to prohibit people to say: We collect a whole lot of stuff,\nbut we don't use it (no purpose attached). \n\nSuch a declaration would be a direct breach of the Data Protection\nDirective as you collect things for the sake of collecting ;)\n\nSo data-collection declaration yes, but I don't yet understand the\n(problematic) link to the purpose declaration (other than as a complaint\nabout our poor set of purposes)\n\nBest, \n\nRigo\n\nOn Tue, May 20, 2003 at 10:29:53AM -0400, Dobbs, Brooks wrote:\n> \n> Okay we are closer but not quite there.  The requirement is \"linked\" not\n> \"used\".  If you use it or not you still need to declare it (what stops you\n> in the future?).  What my initial point is, is if you in fact USE it, it is\n> prima facie evidence that you have it linked.\n> \n\n\n\n", "id": "lists-017-5527976"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "On Tuesday 20 May 2003 09:59, Patrick.Hung@csiro.au wrote:\n> I don't quite understand here as I can't find anything related to \"XML\n> Encryption\"\n> in the working draft.\n\n\"This may be expressed via policy (such as [SOAP] headers) or ensured via \nvarious end-to-end mechanisms such as session security [TLS] or document \nsecurity [XENC].\"\n\n\n> I read the working draft again. I think that the \"Transfering Data to a\n> Third\n> Party\" section is strongly related to the \"Intermediaries.\" \n\nIntermediaries is a subheading (H3) of Transfering Data to a Third Party \n(H2)...?\n\n> There is a few minor typos, and you can find them by using \"find:\"\n>\n> (1) \"..\"\n> (2) \"a a\"\n> (3) \"th\"\n\nFixed.\n\n> (4) \"business to consumer\" should it be \"business-to-consumer?\"\n\nDon't think so, I was quoting from EPAL too.\n\n> Beside it, I also consider\n> whether we should also introduce P3P into UDDI in order to attract UDDI\n> researchers.\n\nI don't know to what degree they've considered that, but if they haven't \ngiven the issue any thought they might appreciate the introduction.\n\n> In addition, have you ever thought about XrML for protecting the privacy\n> of digital content as what Microsoft is doing right now? Should we also\n> mention that in this working draft.\n\nI'm not included to do so presently. My sense is that we have a fairly rich \ncollection of references and dependencies, and while I'm sure we'll \naccumulate a few more, I don't want to take them on without specific \nmotivations not already addressed.\n\n-- \n* I will be travelling May 22/23, and attending OSCOM3 May 28-30. \nI will not be as responsive during these periods but will \nrespond to any email as soon as possible upon my return.\n\nJoseph Reagle Jr.                 http://www.w3.org/People/Reagle/\nW3C Policy Analyst                mailto:reagle@w3.org\nIETF/W3C XML-Signature Co-Chair   http://www.w3.org/Signature/\nW3C XML Encryption Chair          http://www.w3.org/Encryption/2001/\n\n\n\n", "id": "lists-017-5537491"}, {"subject": "UA: interesting reading on plain language and HIPAA privacy notice", "content": "The following two items may be useful as we think about clear wording \nfor our human-readable translations of P3P elements:\n\nWhy Patients Won?t Understand Their HIPAA Privacy Notices\nhttp://www.privacyrights.org/ar/HIPAA-Readability.htm\n\nPlain Language Principles and Thesaurus\nfor Making HIPAA Privacy Notices More Readable\nhttp://www.hrsa.gov/language.htm\n\n\n\n", "id": "lists-017-5547355"}, {"subject": "UA: draft proposed translatio", "content": "I have posted a file at\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\nthat contains a table with all of the elements in the p3p spec that I \nthink we need to consider translations for (in the order they appear in \nthe spec), the definitions from the spec, the text used in IE6, and my \nproposed translation. When Jeremy gives me his revisions I will be \nhappy to replace the IE6 column with his new text. Likewise, I will be \nhappy to add a column for anyone else who wants to take a stab at this \n(if you would like a copy of my excel file to work with, send me \nemail). This is my personal proposal based on my research and the \nfeedback I've gotten on the Privacy Bird translations. It has not been \nreviewed by a lawyer or anyone else.\n\nWe will discuss this on the UA TF call next Tuesday. It would be useful \nif everyone reviews this prior to the call and notes specific things \nthey don't like.\n\nLorrie\n\n\n\n", "id": "lists-017-5554574"}, {"subject": "New Draft for Consent choice", "content": "Dear all, \n\nI've updated the documents page[1] and included the new Draft about\nconsent choices as well as the draft for the User agent strings. Please\ncomment. Those wanting to comment that are not part of the working\ngroup, please send email to me.\n\n  1. http://www.w3.org/P3P/1.1/documents.html\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-5561963"}, {"subject": "Article 10 issue", "content": "Dear All,\nIt turns out that due to administrative problems, Diana Alonso-Blas and\nmembers of the Art 29 WG were unable to make it to Ispra for May 23rd.\nWe therefore have an alternative plan.\nRigo and I will produce a draft plan to resolve the issues (we will meet\ntomorrow to discuss this). We will send this round for comments to the P3P\nWG and then to the Art 29 group for comments and arrange a telephone\nconference and if necessary (we hope not), either I or Rigo can also visit\nBrussels in July for a face to face.\n\nRegards\n\nGiles\n\n\n_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\nVia Enrico Fermi 1\n21020 Ispra,   Italy\nTel.:   +39 0332 789187\nFax.:   +39 0332 789576\ne-mail: giles.hogben@jrc.it\n\n\n\n", "id": "lists-017-5568818"}, {"subject": "UA: UA guidelines first draf", "content": "I have taken the email I got from Brooks and combined it with the \nthings we discussed on our last conference call and produced a very \nrough first draft of user agent guidelines at \nhttp://www.w3.org/P3P/2003/ua-guidelines.html . Please send feedback. \nWe will discuss on our next UA TF call.\n\nLorrie\n\n\n\n", "id": "lists-017-5576110"}, {"subject": "UA: TF call Tuesday 27 Ma", "content": "The next User Agent Task Force call will be on Tuesday, May 27 at 11 am \nUS Eastern. WE WILL NOT BE USING THE USUAL DIAL-IN NUMBER. Please see \nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html for the \nnumber of the MIT bridge that we will be using.\n\nAGENDA\n\n1. Review first draft of UA guidelines\nhttp://www.w3.org/P3P/2003/ua-guidelines.html\n\na. What things do people want to see changed?\n\nb. What is missing?\n\nc. Should we recommend to the WG that something like \"P3P user agents \nshould not rely on P3P compact policies that do not comply with the P3P \n1.1 specification or are obviously erroneous. Such compact policies \nshould be deemed invalid and the corresponding cookies should be \ntreated as if they had no compact policies.\" be made a requirement for \nP3P 1.1\"? This is currently not stated explicitly in the spec, although \nit is consistent with the spirit of section 2.4.4.\n\n2. Begin review of translation document\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\n(please flag items in the proposed translation column that you find \nproblematic for discussion on the call)\n\n3. Set date for next conference call (June 2 or June 5?)\n\n\n\n", "id": "lists-017-5582780"}, {"subject": "P3P spec working group call May 2", "content": "The next P3P specification group conference call will be on\nWednesday, May 28, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    [- P3P beyond HTTP - Joseph Reagle]\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brian Zwit\n    [- Article 10 vocabulary issues - Giles Hogben]\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    [- Converting P3P data schema to XML schema - Giles Hogben]\n    [- Signed P3P policies  - Giles Hogben]\n\n2. Discuss Consent Choices working draft.\nhttp://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n\n3. Discuss bugzilla 178\n    http://www.w3.org/Bugs/Public/show_bug.cgi?id=178\n\nConsider including mention of postal code, state, or region\ninformation, etc. in definition of the demographic category in section \n3.4\n\n4. Discuss bugzilla 168\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=168\n\nConsider adding human-readable explanation strings to all elements that \ndon't have them\n- could be done for a specific set of elements or generically\n- it appears that the way the extension mechanism is defined in the P3P \nschema we cannot add such elements in arbitrary places -- for example, \nI think we can add them to high-level elements such as PURPOSE but not \nas sub-elements of individual PURPOSE elements\n\n5. Discuss bugzilla 170\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=170\nConsider expanding definition of CONSEQUENCE field to reflect how it is \nactually being used -- in particular to express summary of STATEMENT as \nwell as value proposition. Alternatively, consider adding actual \nstructure to CONSEQUENCE element to seperate out summary from value \nproposition.\n\n6. Set date for next call (June 4 or June 11?)\n\n\n\n", "id": "lists-017-5590479"}, {"subject": "Re: P3P spec working group call May 2", "content": "On Friday 23 May 2003 14:31, Lorrie Cranor wrote:\n> The next P3P specification group conference call will be on\n> Wednesday, May 28, 2003, 11 am - 12 pm US Eastern.\n\nMy regrets, I'll be attending OSCOM 3 and might be able to call in, but \nprobably won't. (This also conflicts with a XKMS call, so that's a triple \nconflict! <smile/>)\n\n> 1. Task force reports\n>     [- P3P beyond HTTP - Joseph Reagle]\n\nWe welcome feedback from the Spec WG and are trying to get the attention of \nsome Web Service folks.\n\n\n\n", "id": "lists-017-5599721"}, {"subject": "Re: [BH] First (Very Rought) Outline of Beyond HTT", "content": "Hi Joseph,\n\nReferring to my previous e-mail, I just want to mention a few points here\nfor\nfurther discussion.\n\n> In particular, those three types of\n> information flow may be used to determine the role of SOAP intermediaries.\n> I will spend more thoughts on it next week and discuss with you later.\n\nReferring to [1], those three variables are related to the SOAP Message\nExchange Patterns\n(MEPs) discussed in [2].\n\n\"Points of Decision \nIn [P3P], the user's agent (the point of decision) is typically his network\nclient.\nHowever, one can also imagine a trusted network service acting as the user's\nagent \n(managing the user's identity, information and enforcing his preferences).\nIn PROVREG \nand EPAL services themselves are exchanging policies and making decisions.\"\n\nThis is somehow relevant to the role of SOAP message sender and ultimate\nreceiver in \nthe SOAP architecture.\n \n\"Points of Aggregation \nA service which solicits information from a user for redistribution to other\nservices \nmight choose to first collect and combine the policies of its peers and\nrepresent the \np3p:recipients as having the \"same\" policy, or it might ask for separate\nparcels of \ninformation under a different policy corresponding to each of the recipients\nwhich it \ntransfers data to.\" \n\nPart of these requirements should be very close to the \"Table 3: SOAP Nodes\nForwarding \nbehavior\" [2]. Should we have to enhance the \"next\" role with more behaviors\nto handle\nthe proposed privacy policy? For example, the privacy policy, say in P3P, at\nthe \nSOAP intermediaries with the \"next\" role must contain \"<current/> and\n<admin/> for \n<PURPOSE/> and also <no-retention/> for <RETENTION/>. \n\nOr we should define another new role as \"user-defined\" in [2]?\n\nIn addition, refering to the sample SOAP message in [1]: \n\"<env:Header\nxmlns='http://registry.example.com/2003/soap-header-p3p-extension.xsd'\nxmlns:env='http://www.w3.org/2003/05/soap-envelope' id='header'>\n  <Privacy env:role='http://www.w3.org/2003/05/soap-envelope/role/next'\nenv:mustUnderstand='true'>\n    <rel>P3Pv1</rel>\n    <href>http://registry.example.com/P3P/PolicyReferences.xml</href>\n  </Privacy>\n</env:Header>\"\n\nFYI. There is no \"relay\" attribute specified here because \"The relay\nattribute information \nitem has no effect on the SOAP processing model when the header block also\ncarries a \nmustUnderstand attribute information item with a value of \"true\". [2]\n\n[1] http://www.w3.org/P3P/2003/p3p-beyond-http/Overview.html\n[2] http://www.w3.org/TR/2003/PR-soap12-part1-20030507/\n\nOther minor issues may have to consider:\n(1) Should we also have to mention the privacy issues of audit trail (e.g.,\nlog files) \nat each Web service? We assume that all Web services are all seating with\nthe Web server \nand so.\n(2) In the future, should we also think about the internationalization of\nP3P policies in \nthis Web services execution environment? It is bcause there are different\nprivacy laws in\ndifferent countries or even between different states.\n\nAnyway, more thoughts are need...\n\nThanks and talk to you later.\n\nPatrick.\n\n\n\n", "id": "lists-017-5607405"}, {"subject": "UA: notes from 27 May UA TF cal", "content": "Notes from 27 May 2003 UA TF call\n\nParticipants\nLorrie Cranor (AT&T Research)\nBrooks Dobbs (DoubleClick)\nGiles Hogben (JRC)\n\n\nWe reviewed Lorrie's initial UA guidelines draft [1]. Other than some \ntypos and minor wording issues, the main substantive issues we \ndiscussed were:\n\n- need to explain in intro why consistency is a good thing\n\n- need to add guidelines for evaluating policies that parallel the \nsanity checks for CPs\n\nLorrie will update the UA guidelines draft shortly. At this point we \nare ready to have the entire WG review this draft and provide feedback.\n\nAlso, the group felt that adding a requirement to the spec that UAs not \nrely on CPs that don't comply with the spec was a good idea. This will \nbe proposed to the full WG and scheduled for discussion at an upcoming \nconference call.\n\n\nWe discussed Lorrie's proposed translations [2]. No other proposals \nhave been received, so unless someone else steps forward real soon now, \nwe will use Lorrie's proposal only as our working document. Giles had a \nnumber of minor suggestions which Lorrie will incorporate into the \ndocument and update on the web site (anyone who wants an Excel version \nshould email Lorrie). We are waiting for other TF members to provide \ntheir comments, and Lorrie is working on engaging some additional legal \nand usability experts.\n\nWe will wait to have another conference call until after Lorrie updates \nthe drafts and we get more feedback.\n\n[1] http://www.w3.org/P3P/2003/ua-guidelines.html\n[2] http://www.w3.org/P3P/2003/p3p-translation.htm\n\n\n\n", "id": "lists-017-5619108"}, {"subject": "[BH] Application Patterns and SOAP (Was: First (Very Rought) Outline of Beyond HTTP", "content": "On Tuesday 27 May 2003 02:02, Patrick.Hung@csiro.au wrote:\n> Referring to [1], those three variables are related to the SOAP Message\n> Exchange Patterns\n> (MEPs) discussed in [2].\n\nHi Patrick, they might be similar but I believe they are orthogonal. P3P's \nscope of \"identity\" and \"recipient\" with respect to flow, decision, and \naggregation is at the application level, the SOAP MEPs are at the \"message \ntransport\" level. However, I appreciate that SOAP intermediaries \n*themselves* have their own privacy issues  -- just as various network \nintermediaries with simple P3P1.0 do (e.g., proxies) but which that spec \ndidn't attempt to take on.\n\nThe scenario I have in my mind is that SOAP is being used in an \"end-to-end\" \nmodel with an explicit understanding that various intermediaries will be \nrelevant. Te request/response is e2e between the user agent and service \nwith intermediaries in between. I wouldn't be keen to design a multi-party \nprotocol using SOAP -- or anything else, but I still think this is more in \nline with what folks call choreography -- but what do I know. <smile/> This \nis why I'm holding back at the level of \"Adopting applications that want to \nensure the privacy of user information SHOULD take steps to ensure that no \ninformation is released to a network intermediary that is not covered by \nits P3P policy.\" and \"@@ Do we need to say anything more about forwarding \nand active intermediaries? I would prefer to rely upon the text above \nunless we are further pressed.\" Absent a compelling case, I prefer not to \nget into multi-party \"choreagraphed\" transactions.\n\n> Part of these requirements should be very close to the \"Table 3: SOAP\n> Nodes Forwarding\n> behavior\" [2]. Should we have to enhance the \"next\" role with more\n> behaviors to handle\n> the proposed privacy policy? For example, the privacy policy, say in P3P,\n> at the\n> SOAP intermediaries with the \"next\" role must contain \"<current/> and\n> <admin/> for\n> <PURPOSE/> and also <no-retention/> for <RETENTION/>.\n\nThis is an interesting point. Again, presently we say, \"Adopting \napplications that want to ensure the privacy of user information SHOULD \ntake steps to ensure that no information is released to a network \nintermediary that is not covered by its P3P policy.\" The SOAP header \nexample shows that the SOAP header includes the same policyURI that the \nultimateReceiver will be respecting. We *could*, as you suggest, define a \n\"P3P Policy for SOAP intermediaries\" policy and recommend it be used for \nnon-ultimateReceivers, but I'm not confident. I've captured this issue in \nthe \"@@\" and will link to this thread and perhaps the WS folks will be able \nto comment on it:\n\n[[[Do we need to say anything more about forwarding and active \nintermediaries? Should we define a \"P3P Policy for SOAP intermediaries\" \nthat only permits the data to be used for the \"current purpose/admin and no \nretention\" that SOAP intermediaries MUST use? Reagle prefers to rely upon \nthe text above unless we are further pressed with actual use cases.]]]\n\n> (1) Should we also have to mention the privacy issues of audit trail\n> (e.g., log files)\n> at each Web service? We assume that all Web services are all seating with\n> the Web server\n> and so.\n\nHow do you mean? The intermediaries?\n\n> (2) In the future, should we also think about the internationalization of\n> P3P policies in\n> this Web services execution environment? It is bcause there are different\n> privacy laws in\n> different countries or even between different states.\n\nI don't feel we need to go there yet.\n\n-- \n* I will be travelling May 22/23, and attending OSCOM3 May 28-30. \nI will not be as responsive during these periods but will \nrespond to any email as soon as possible upon my return.\n\n\n\n", "id": "lists-017-5627335"}, {"subject": "RE: [BH] Application Patterns and SOAP (Was: First (Very Rought)  Outline of Beyond HTTP", "content": "Hi Joseph,\n\n> Hi Patrick, they might be similar but I believe they are orthogonal. P3P's\n\n> scope of \"identity\" and \"recipient\" with respect to flow, decision, and \n> aggregation is at the application level, the SOAP MEPs are at the \"message\n\n> transport\" level. However, I appreciate that SOAP intermediaries \n> *themselves* have their own privacy issues  -- just as various network \n> intermediaries with simple P3P1.0 do (e.g., proxies) but which that spec \n> didn't attempt to take on.\n\nI agree. :-)\n\n> The scenario I have in my mind is that SOAP is being used in an\n\"end-to-end\" \n> model with an explicit understanding that various intermediaries will be \n> relevant. Te request/response is e2e between the user agent and service\n\nI have a bit concern about your statement \"with an explicit understanding \nthat various intermediaries will be relevant.\" Do you mean that both SOAP\nsender \nand receiver realize that there exist some intermediaries but both SOAP\nsender\nand receiver do not have explicit knowledge of who and where the\nintermediaries are\non the Web?\n \n> with intermediaries in between. I wouldn't be keen to design a multi-party\n\n> protocol using SOAP -- or anything else, but I still think this is more in\n\n> line with what folks call choreography -- but what do I know. <smile/>\nThis \n> is why I'm holding back at the level of \"Adopting applications that want\nto \n> ensure the privacy of user information SHOULD take steps to ensure that no\n\n> information is released to a network intermediary that is not covered by \n> its P3P policy.\" and \"@@ Do we need to say anything more about forwarding \n> and active intermediaries? I would prefer to rely upon the text above \n> unless we are further pressed.\" Absent a compelling case, I prefer not to \n> get into multi-party \"choreagraphed\" transactions.\n\nI totally agree with you.\n\n> This is an interesting point. Again, presently we say, \"Adopting \n> applications that want to ensure the privacy of user information SHOULD \n> take steps to ensure that no information is released to a network \n> intermediary that is not covered by its P3P policy.\" The SOAP header \n> example shows that the SOAP header includes the same policyURI that the \n> ultimateReceiver will be respecting. We *could*, as you suggest, define a \n> \"P3P Policy for SOAP intermediaries\" policy and recommend it be used for \n> non-ultimateReceivers, but I'm not confident. I've captured this issue in \n> the \"@@\" and will link to this thread and perhaps the WS folks will be\nable \n> to comment on it:\n\nYes, it is fine.\n\n> (1) Should we also have to mention the privacy issues of audit trail\n> (e.g., log files)\n> at each Web service? We assume that all Web services are all seating with\n> the Web server\n> and so.\n\n> How do you mean? The intermediaries?\n\nYes, I mean the intermediaries. It is because there is no such serious\nconcern \nat the SOAP sender side and also the ultimate receiver should respect its \nown privacy policy (or I can name it as the SOAP receiver's promise to the\nsender).\n\nFor the UDDI, here are my suggestions (very rought and have to check the\nsyntax\ncarefully) to put privacy policies at two levels:\n\n(1) \"businessEntity: Describes a business or other organization that\ntypically \n    provides Web services.\" [1] For example:\n\n<businessDetail generic=\"2.0\" operator=\"Microsoft UDDI Services\"\ntruncated=\"false\" xmlns=\"urn:uddi-org:api_v2\">\n<businessEntity businessKey=\"186a3421-0c20-45d1-b81d-efb9f61b0b15\"\noperator=\"sample\" authorizedName=\"sample\">\n<discoveryURLs>\n<discoveryURL useType=\"businessEntity\">\nhttp://uddi.example.com/uddipublic/discovery.ashx?businessKey=186a3421-0c20-\n45d1-b81d-efb9f61b0b15\n</discoveryURL>\n</discoveryURLs>\n<Privacy href='http://registry.example.com/P3P/PolicyReferences.xml'\nrel='P3Pv1'/>\n<name>Registry</name>\n<description xml:lang=\"en\" />\n<contacts/>\n</businessEntity>\n</businessDetail>\n\n(2) \"businessService: Describes a collection of related Web services offered\nby an\norganization described by a businessEntity.\" [1] For example, \n\n<businessServices>\n<businessService>\n<name>Register</name>\n<description xml:lang=\"en\">\nRegister Domain Name\n</description>\n<Privacy href='http://registry.example.com/P3P/PolicyReferences.xml'\nrel='P3Pv1'/>\n<bindingTemplates>\n<bindingTemplate>\n<accessPoint useType=\"endpoint\">\nhttp://registry.example.com/register\n</accessPoint>\n<tModelInstanceDetails>\n<tModelInstanceInfo\ntModelKey=\"uddi:ubr.uddi.org:transport:http\">\n</tModelInstanceInfo>\n</tModelInstanceDetails>\n</bindingTemplate>\n</bindingTemplates>\n<categoryBag>\n<keyedReference\ntModelKey=\"uddi:uddi.org:categorization:general_keywords\"\nkeyName=\"registry.example:categorization:domainname\"\nkeyValue=\"a\"/>\n<keyedReference\ntModelKey=\"uddi:ubr.uddi.org:categorization:unspsc\"\nkeyName=\"UNSPSC: Domainname\" keyValue=\"102025\"/>\n</categoryBag>\n</businessService>\n<businessServices>\n\nIf we really want to mention UDDI in the working draft, as you know, we have\nto play with the \nUDDI schema.\n\nLet me try to go far here... This may be an interesting research topics in\nthe future:\n\n\"subscription: Describes a standing request to keep track of changes to the\nentities\ndescribed by the subscription.\" [1]\n\nShould we also have a function to keep track of the changes in privacy\npolicies?\nAnyway, we can forget this point in this task force working draft.\n\n\n[1] http://uddi.org/pubs/uddi-v3.00-published-20020719.pdf\n\nJust stop here. Talk to you later.\n\nPatrick.\n\n\n\n", "id": "lists-017-5639433"}, {"subject": "minutes of 28 may P3P spec working group cal", "content": "minutes 28 may 2003 spec group task force call\n\nparticipants\nlorrie cranor - at&t research (chair)\ngiles hogben - jrc\npatrick hung - csiro\nrigo wennig - w3c\nmarc langheinrich - eth zurich (minutes)\n\n1. taskforce reports\n===========================================================================\n - p3p beyond http: [skipped, joe not there]\n\n - user agent behavior: [lorrie]\n \n   lorrie: ua makes progress. has guidelines, would like the rest of the\n   group to have a look at, and get feedback. lorrie will schedule for next\n   phone call also making progress re: translations. if anybody else has\n   proposals, speak up (microsoft hinted that they might). otherwise\n   they'll go ahead with lorries proposal.\n\n   rigo worried that semantics might get redefined.\n\n   lorrie: no, we use a matrix that shows side to side our wording and\n   official p3p definitions, and they strife to make these consistent\n\n   rigo: challenging\n\n   lorrie: yes, so please, if you reading it and notice changes in\n   semantics, please let us know.\n \n   ACTION: lorrie will send out more info to solicit feedback.\n\n - compact policies: [skipped, brian not there] \n \n   lorrie tried to contact brian, since nothing is happening there,\n   suggested adding co-chair. lorrie has volunteer (brooks), but will need\n   to talk to brian before adding a co-chair.\n\n - article10: [giles] \n \n   giles: meeting last friday didn't happen due to screw-ups in brussels.\n   rigo and i went back and forth and got together suggested text. will\n   send it out to brussels to get their comments\n\n   rigo: we're still discussing the issues together, and we still have some\n   substantial disagreements between us, like i feel many things are\n   already in the specs and they just need explanations, etc. but\n   coordination is a bit difficult. bottom line is, that we're moving\n   forward. we got some concrete text suggestions that we're working on.\n\n   document is already online, so people can comment on points (you can\n   find it off the documents page)\n\n - agent and domains: [skipped, jack not there]\n\n - consent choices: [skipped, matthias not there]\n\n - dataschemas: [giles]\n \n   giles: i discovered previous attempt, done by yuichi. but it's worth\n   starting again, since too much has changed since. but no progress on my\n   side yet.\n\n - signed policies: [giles]\n \n   giles: still no progress. \n\n   lorrie: are you waiting for something from us?\n\n   giles: no, no, just need compelling reason for doing that...\n\n   ACTION: lorrie will record this in bugzilla: find p3p policies that are\n   waiting to have signed policies etc. (from seal providers, etc)\n\n\n2. consent choices working draft (matthias not there, but lorrie will\n   explain)\n===========================================================================\n\n - rigo had looked at draft. \n\n - lorrie: draft was motivated by the fact that most websites that allowed\n   opt-in or opt-out would only allow choices in bundles, i.e. all\n   recipients or none. so idea was to have indicator in p3p policy that\n   would show you such bundles. maybe in p3p2 you could even have automated\n   process to do so.\n\n   matthias came up with attribute using extension mechanism, allowing you\n   to label statements as belonging to a certain statement group.\n\n   so question (again is): is there demand for sth like this in 1.1?\n   otherwise we should table it for version 2...\n\n - rigo: i find it useful, simply because you also tried this in the ui\n   already. this reduces complexity, as the server can already indicate\n   what is possible to opt-in or opt-out of... i'm in favor.\n\n - lorrie: another idea was to label \"related\" statement, so same mechanism\n   could also be useful for that.\n\n   [no other comments]\n\n   let's get some more feedback from user agent implementors...\n\n\n3. bugzilla 178: missing postal code, etc. in demographic defnition.\n===========================================================================\n\n - rigo: isn't this just an errata?\n\n - lorrie: could also be a minor change...\n\n - marc: drawbacks?\n\n - rigo: procedures only. errata would mean that we have an errata document\n   that we need to incorporate later into 1.0\n\n - lorrie: we already have errata items, so we aren't really following\n   process already.\n\n - rigo: maybe not yet... we just got chartered, so clock wasn't ticking\n   yet.\n\n --------------------------------------------------------------------------\n HEAR HEAR: WE'VE NOW BEEN CHARTERED. WE'VE BEEN RECHARTERED ON MAY 26!\n [rigo reports] rigo will send some note on this out to list...\n --------------------------------------------------------------------------\n\n   ACTION: lorrie will put exact wording into bugzilla to get massimo copy\n   this into errata document...\n\n\n4. bugzilla 168: adding human-readable fields to (almost) all elements in\n   p3p\n===========================================================================\n\n - rigo: can we add this as attribute?\n\n - lorrie: no, extension mechanism wouldn't allow this. though if we feel\n   that this is very important, we could revisit our own guidelines re:\n   backwards compatibility.\n\n - marc: so this would be added in the schema?\n\n - lorrie: well, we'd use the extension mechanism\n\n - rigo: so 1.1 would be a whole new spec, i don't intend to publish a diff\n\n - lorrie: no, but we don't want a new namespace. unless we come up with a\n   showstopper, we won't change the schema, for backwards compatibility.\n\n - marc: sounds messy. which elements would need this, anyway?\n\n - lorrie: purpose doesn't have it. data doesn't have it. the best would be\n   to have the same mechanism as we did with the \"OTHER\" purpose element,\n   where an explanation could be placed between opening and closing tag.\n   but probably not possible with extension tag...\n\n - marc: maybe even a problematic thing if people come up with their own\n   explanations for the purposes...\n\n - rigo: right, ideally suited for mean people or lawyers, this could blow\n   up any compact rendering of policies by user agents...\n\n   ACTION: lorrie will schedule this for further discussion on later calls.\n   people should look at where such strings would be good to have, and\n   where they have more advantages than drawbacks...\n\n\n5. bugzilla 170: definition of CONSEQUENCE field is not really obvious\n===========================================================================\n\n - rigo: i never understood \"benefit\" piece of the definition anyway, so\n   relabeling shouldn't really have compatibility issues. also, you where\n   the first to use it this way, and now everybody uses it...\n\n - lorrie: right, also user tests show that people use it to make\n   discussions.\n\n   nobody was against rephrasing this...\n\n - rigo: we could also place a limit on the length while we're at it...\n\n - lorrie: good idea. could do this even without changing the schema...\n\n   ACTION: lorrie will send out some new wording that could be part of the\n   1.1 spec.\n\n\n6. next date: june 11 worked for everybody.\n===========================================================================\n\n   ACTION: rigo will update homepage with meeting times.\n\n \n-- \nMarc Langheinrich <langhein@inf.ethz.ch> Institute for Pervasive Computing\nDept. of Computer Science, ETH Zurich, IFW D48.2, 8092 Zurich, Switzerland\nfon: +41-1-632-0688, fax: +41-1-632-1659,  web: www.inf.ethz.ch/~langhein/\n\n\n\n", "id": "lists-017-5653534"}, {"subject": "Re: Concerns re: SameEntity proposa", "content": "On Wed, Oct 22, 2003 at 03:31:48PM -0400, Dobbs, Brooks wrote:\n> 1)       We need be careful between providing tools on which to make policy\n> and making policy itself.  While it may be a useful tool to have the ability\n> to state that collection covered by separate PRFs  is under the control of\n> the same entity, ultimately it is up to the UAs to decide how they want to\n> implement these tools.\n\nI think, the beneficial in this proposal is, that it allows to have a\nmeans by which the double control on PRF's is checked. In fact, the same\nentity requires that the issuing host's PRF mentions the same entity AND\nthe same entity has to refer to the issuing host. As configuration of\nboth needs privileged access to configuration files, hacking without\ncontrol of those files will be harder. Therefor, I think the addressing\nmechanism is good, but I have issues with the semantics like I expressed\nthem during the last calls.\n\n> \n> 2)       We use the term entity (and later in the agent relationship\n> proposal - \"agent\") without providing sufficient guidance on what this\n> means.  Rigo suggests there may be ways around this but I think they would\n> be unclear at best and difficult to explain to the end user.  This suggests\n> to me that point 1) may mean that UAs don't act on this tool if they had it.\n\nI referred to the rather clear definitions in the EU Directive, where a\ndata controller is the entity that controls data processing, means has\npower to order, manage and prohibit things. The agent for me here is a\ndata processor, means an entity that does some processing on behalf of\nsomebody else (i.e. with a contractual background that allows that\ncontrol). But I agree, that this is rather complex.\n\n> \n> 3)       I think that there is an issue in that entity is today defined at\n> the policy level.  A PRF for a host can reference 2 distinct policies each\n> of 2 distinct entities (data controllers) - how then can there be meaning to\n> say at the PRF level this entity is the same as anything else?  The same as\n> which of the 2?\n\nDon't forget, that the entity is not defined at the PRF-level but at the\nPolicy-level. This means that a same Policy with the same entity can be\nreferenced by multiple PRF's. We extend that proposal now to multiple\nPRF's by the way of allowing third party PRF's to reference other PRFs.\n\n> \n> 4)       There would need to be a mechanism to expire same entity\n> relationship.  This may be handled through the expiry in policy files but\n> there is currently no such mechanism for CPs\n\nAdvantage and disadvantage of CPs is, that they have a lifetime for\nexactly the request that is made. So no need for expiry on CPs. CPs are\nout of scope here. I know that the issue came from the CPs and from the\nthird party cookies. But we would be rather unwise to remove the\nincentive to create policies in the third party context. BUT: Full\npolicies in the third party context were a nuisance so far and this\nproposal might remedy the performance issues attached to it, if we get\nit right.\n\n> \n> 5)       Headers are limited practically by the number of same hosts that\n> they can declare.  Also declaring multiple \"same-entity\" relationships would\n> presumably require a validation against each full policy prior to accepting\n> the accuracy of the header declaration.  This is somewhat illogical, as, IF\n> we where to accept the performance hit of policy prefetching, then we would\n> have no need for CPs!  Jack rightly points out that we may only need to\n> validate against the PRF and not the policy - but I think that I may have\n> brought that into question with point 3).\n\nAs far as I remember our discussion, the same host has to reference the\nPRF of the referring host. (apart from CP, where we are in a stateless\ncontext). This means that we might obtain sufficient performance\nimprovements to get rid of CPs and avoid the false declarations inherent\nto the summary-nature of CPs.\n\n> \n> 6)       Again on the topic of CPs, once a same entity relationship has been\n> established between cookie (set by A) and site B from which an asset\n> appears, how they can a same entity relationship be established from a\n> subsequent replay on site C (provided that PRFs or policies) for all these\n> sites do indeed declare each other as same entity?\n\nThis shows the issues which were discussed the most. It means that\nbrowsers would have to switch to pay attention to cookies replayed. At\nthe moment, the performance improvement is that we only evaluate cookies\nat set-cookie. If the same cookie is re-used in different contexts,\neither you declare up-front all the potential uses or you evaluate on\nthe replay-time. While 1/ is good for browsers, 2/ is good for content\nproviders using the same cookie in different contexts. This might be\neasier with the full format, where specific data has a specific\nstatement attached to it. In the context of CP, this just turns into\nnightmare, as the potential overstatement is huge. The same entity\nproposal does not remedy the situation. But it would perhaps allow the\nbrowsers to get sufficient performance to do full policy. Full policy\nremedies as it allows for fine-grained expression of data concerned.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5735461"}, {"subject": "Agenda 5 November cal", "content": "The next P3P specification group conference call will be on\nWednesday, November 5, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1/ P3P beyond HTTP\nUpdate on latest developments\n\n\n2/ Discussion of P3P 1.0 element definitions and translations: the\nremaining items\nsee comments in green at http://www.w3.org/P3P/2003/p3p-translation.htm\n\n3/ domain relationship proposal\nPlease review the Draft and comment on the list:\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0020.html\n\ncontinued discussions..\n\n4/ compact policies\nJeremy might have some results already\n\n4/ Next meeting\nLogical would be 19 November, but I'm in Japan. So feedback is welcome\nwhether we should go for 12 November and skip 1 week or going for 19\nNovember.\n\n\n\n", "id": "lists-017-5747006"}, {"subject": "RE: Concerns re: SameEntity proposa", "content": "On Wed, Oct 22, 2003 at 03:31:48PM -0400, Dobbs, Brooks wrote:\n> 1)       We need be careful between providing tools on which to make\npolicy\n> and making policy itself.  While it may be a useful tool to have the\nability\n> to state that collection covered by separate PRFs  is under the control of\n> the same entity, ultimately it is up to the UAs to decide how they want to\n> implement these tools.\n\nI agree, but if we can find a way to express these relationships\neffectively, then I think we should also offer some examples of how UAs\nmight use the additional information.\n\n> 2)       We use the term entity (and later in the agent relationship\n> proposal - \"agent\") without providing sufficient guidance on what this\n> means.  Rigo suggests there may be ways around this but I think they would\n> be unclear at best and difficult to explain to the end user.  This\nsuggests\n> to me that point 1) may mean that UAs don't act on this tool if they had\nit.\n\nIs entity not well enough defined in the 1.0 specification? I agree that\nagent is difficult, although the data controller/processor terminology from\nthe EU Directive seems helpful.\n\n> 3)       I think that there is an issue in that entity is today defined at\n> the policy level.  A PRF for a host can reference 2 distinct policies each\n> of 2 distinct entities (data controllers) - how then can there be meaning\nto\n> say at the PRF level this entity is the same as anything else?  The same\nas\n> which of the 2?\n\nA PRF can only make declarations about the current site. If the current site\nis not entirely owned by a single entity, then it shouldn't use the\nsame-entity declaration mechanism, as that would not make sense. However, if\nit is owned entirely by a single entity, which also owns another site, then\nit makes sense for those two sites to declare each other same-entity via the\nPRF. Perhaps we should introduce the concept of an entity key in the policy\nfile which would be matched against a key declaration in the PRF, so that\nUAs could further validate the same-entity relationship when parsing the\nactual policy files.\n\n> 4)       There would need to be a mechanism to expire same entity\n> relationship.  This may be handled through the expiry in policy files but\n> there is currently no such mechanism for CPs\n\nIf we have the HTTP header support for declaring same-entity, we can build\nan expiration property into it. There seems to be some debate as to whether\nor not we should even provide this mechanism for CPs at all, though. Not\nsure where I stand on that yet.\n\n> 5)       Headers are limited practically by the number of same hosts that\n> they can declare.  Also declaring multiple \"same-entity\" relationships\nwould\n> presumably require a validation against each full policy prior to\naccepting\n> the accuracy of the header declaration.  This is somewhat illogical, as,\nIF\n> we where to accept the performance hit of policy prefetching, then we\nwould\n> have no need for CPs!  Jack rightly points out that we may only need to\n> validate against the PRF and not the policy - but I think that I may have\n> brought that into question with point 3).\n\nI think these are good arguments for doing away with the HTTP header portion\nof the proposal.\n\n> 6)       Again on the topic of CPs, once a same entity relationship has\nbeen\n> established between cookie (set by A) and site B from which an asset\n> appears, how they can a same entity relationship be established from a\n> subsequent replay on site C (provided that PRFs or policies) for all these\n> sites do indeed declare each other as same entity?\n\nExample:\n1. UA has been configured to not allow third-party cookies.\n2. UA visits a.com. A response from an image request to b.com wishes to set\ncookie B1.\n3. UA evaluates PRFs and determines that a.com and b.com have a same-entity\nrelationship. Cookie B1 is accepted.\n4. UA visits a.com again. Cookie B1 is sent along on image request to b.com.\n5. UA visits x.com, which contains an image reference to b.com.\n6. Since B1 is only valid for playback on a.com, UA delays image request to\nb.com and fetches x.com's PRF.\n7. UA evaluates PRF and determines the x.com and b.com have a same-entity\nrelationship. \n8. UA sends cookie B1 with image request to b.com.\n\nNotes:\n- UA could cache same-entity relationship information along with PRF to\navoid future fetching. \n- Since same-entity is a transitive relationship, the UA could then extend\nit to say that x.com and a.com are same-entity for a future transaction.\n\n\n++Jack++\n\n\n\n", "id": "lists-017-5754602"}, {"subject": "[Minutes] 5 November cal", "content": "Present:\nDave Stampley\nBrooks Dobbs\nJack Humphrey\nJeff Edelen\nRigo Wenning\n\n1/ P3P beyond HTTP\nRigo gave brief update about the plans for a workshop in WS-Privacy and\nPolicy. He further reported on the coordination going on with the WSDL\nworking group. As Patrick Hung wasn't present, this was rather short.\n\n2/ Discussion of P3P 1.0 element definitions and translations\n\ndiscussed the final versions of court and law.\nDave agreed, so it is final now\n\nWe agreed on the disputes, so remedies are just a follow up. \nSo the drafting should follow the same lines as the wordings on\ndisputes. \n\nWe started to discuss the <remedies> element.\n\nIn the current shape, Dave argued that a service would have an\nobligation of result, which he can't really promise as it might be\nimpossible in some cases. At the same time, as in disputes, there might\nbe other remedies that are not mentioned in the policy. We didn't want\nto exclude them neither lead people to believe that the remedies\nmentioned in this section are the only ones applicable to the dispute.\n\nSuggestion from Dave:\nThe service-provider offers or acknowledges that the following remedies\nmay apply to the identified dispute-resolution procedures.\n\nIf there is no objection until next call, we take this as final.\n\ntalking about <correct/>\nThe discussion turned around the fact, that this is an obligation of\nmeans. There were concerns to say procedure implemented as SME's would\nhave too large a burden to implemnent that. On the other hand, as we\nremoved the obligation of result, we were concerned that it wouldn't be\nstrong enough anymore. So we added policy, which means, that there has\nto be at least some guy responding and some thinking before using that\nelement.\n\nSuggestion: \nThe service-provider has implemented a policy to rectify errors or\nconsequences for disputes arising in connection with the privacy statement.\n\nAgreement on this phrase.\nIf there is no objection until next call, we take this as final.\n\n<money element>\nWe discussed, that compensation is not always money. It might also be a\nfree subscription etc. We wanted to align with <correct>\n\nSuggestion:\nThe service-provider has implemented a compensation policy for disputes\narising in connection with the privacy statement.\n\nWe discussed the fact, that compensation doesn't mean necessarily to\nalso correct the errors involved with a dispute or violation of the\npolicy. In order to express that errors will also be corrected, \n<money> and <correct> would have to be present in the policy. We felt, \nthat we should add some explanation to the specification. \n\nAgreement on this phrase.\nIf there is no objection until next call, we take this as final.\n\n<law> element\nSuggestion: \nRemedies for disputes arising in connection with the Privacy Statement\nmay be specified by the law referenced in the human readable description\n\nAgreement on this phrase.\nIf there is no objection until next call, we take this as final.\n\nACTION Rigo clean up http://www.w3.org/P3P/2003/p3p-translation.htm\n\nWe had no time left to discuss the domain relations proposal and will\ncontinue to discuss this over the mailing-list. Jack already responded.\nEverybody else is also invited to give his comments.\n\nThe date of the next meeting will be discussed over the mailing-list.\n\nScribe=Rigo\n\n\n\n", "id": "lists-017-5766815"}, {"subject": "[UATF] P3P 1.0 element definitions and translation", "content": "Hi all, \n\nwe are through all the issues in the Draft[1]\n\nthe only remaining issue was erasing \"beyond the service provider and its\nagents\" in the <RECIPIENT>-Definition.[2] The new definition reads:\n\"the legal entity, or domain, where data may be be distributed\"\n\nBut we already accepted that change at the 6 august 2003 call[3], so I\nwill now edit a clean version of the User Agent Draft and tell you as\nsoon as I'm through.\n\n  1. http://www.w3.org/P3P/2003/p3p-translation.htm\n  2. http://www.w3.org/Bugs/Public/show_bug.cgi?id=283\n  3. http://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0005.html\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-5777158"}, {"subject": "RE: [Minutes] 5 November cal", "content": "Hi Rigo,\n\nHow are you doing? I am sorry to reply you late as I was ver\nbusy in the past two weeks.\n\nI got a few comments from the talk I gave at the Hong Kong \nUniversity of Science and Technology (HKUST) about P3P and P3P \nBeyond HTTP as follows:\n\n(1) Referring to the \"Privacy\" tab in the \"Internet Option\" from\nIE, it doesn't really tell much to a non-computer scientist. It \nseems that every IE user must understand P3P and APPEL in order to \nset their privacy preferences properly.\n\n(2) Privacy is still a very tough problem in accessing Web pages \n(as what P3P is mainly targeting for), and it involves a lot of\nnon-technical issues such as management. How could we overcome \nthe non-technical issues in the Web services scenario?\n\n(3) There should have some learning technologies (such as the learning\ntechnology for detecting SPAM e-mails) to set the privacy preferences\nfor a user.\n\n(4) The relationships between security and privacy are still not \nvery clear.\n\nBy the way, would you please tell me more about \"the plans for a\nworkshop in WS-Privacy and Policy?\"\n\nCheers,\n\nPatrick.\n\n\n\n\n \n-----Original Message-----\nFrom: Rigo Wenning\nTo: public-p3p-spec\nSent: 6/11/2003 9:59\nSubject: [Minutes] 5 November call\n\n\nPresent:\nDave Stampley\nBrooks Dobbs\nJack Humphrey\nJeff Edelen\nRigo Wenning\n\n1/ P3P beyond HTTP\nRigo gave brief update about the plans for a workshop in WS-Privacy and\nPolicy. He further reported on the coordination going on with the WSDL\nworking group. As Patrick Hung wasn't present, this was rather short.\n\n2/ Discussion of P3P 1.0 element definitions and translations\n\ndiscussed the final versions of court and law.\nDave agreed, so it is final now\n\nWe agreed on the disputes, so remedies are just a follow up. \nSo the drafting should follow the same lines as the wordings on\ndisputes. \n\nWe started to discuss the <remedies> element.\n\nIn the current shape, Dave argued that a service would have an\nobligation of result, which he can't really promise as it might be\nimpossible in some cases. At the same time, as in disputes, there might\nbe other remedies that are not mentioned in the policy. We didn't want\nto exclude them neither lead people to believe that the remedies\nmentioned in this section are the only ones applicable to the dispute.\n\nSuggestion from Dave:\nThe service-provider offers or acknowledges that the following remedies\nmay apply to the identified dispute-resolution procedures.\n\nIf there is no objection until next call, we take this as final.\n\ntalking about <correct/>\nThe discussion turned around the fact, that this is an obligation of\nmeans. There were concerns to say procedure implemented as SME's would\nhave too large a burden to implemnent that. On the other hand, as we\nremoved the obligation of result, we were concerned that it wouldn't be\nstrong enough anymore. So we added policy, which means, that there has\nto be at least some guy responding and some thinking before using that\nelement.\n\nSuggestion: \nThe service-provider has implemented a policy to rectify errors or\nconsequences for disputes arising in connection with the privacy\nstatement.\n\nAgreement on this phrase.\nIf there is no objection until next call, we take this as final.\n\n<money element>\nWe discussed, that compensation is not always money. It might also be a\nfree subscription etc. We wanted to align with <correct>\n\nSuggestion:\nThe service-provider has implemented a compensation policy for disputes\narising in connection with the privacy statement.\n\nWe discussed the fact, that compensation doesn't mean necessarily to\nalso correct the errors involved with a dispute or violation of the\npolicy. In order to express that errors will also be corrected, \n<money> and <correct> would have to be present in the policy. We felt, \nthat we should add some explanation to the specification. \n\nAgreement on this phrase.\nIf there is no objection until next call, we take this as final.\n\n<law> element\nSuggestion: \nRemedies for disputes arising in connection with the Privacy Statement\nmay be specified by the law referenced in the human readable description\n\nAgreement on this phrase.\nIf there is no objection until next call, we take this as final.\n\nACTION Rigo clean up http://www.w3.org/P3P/2003/p3p-translation.htm\n\nWe had no time left to discuss the domain relations proposal and will\ncontinue to discuss this over the mailing-list. Jack already responded.\nEverybody else is also invited to give his comments.\n\nThe date of the next meeting will be discussed over the mailing-list.\n\nScribe=Rigo\n\n\n\n", "id": "lists-017-5784780"}, {"subject": "NO Call on 12 Novembe", "content": "Dear all, \n\nthere were holidays in France, so I'm behind with the edits. I would\nprefer to have the next call on 19 November. I will be in Japan, but\nthis shouldn't affect us too much. \n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5797013"}, {"subject": "RE: Concerns re: SameEntity proposa", "content": "Another point on \"agent\" terminology: I think agent/processor is well\ndefined in the NAI Web Beacon Guidelines\n<http://www.networkadvertising.org/Statement.pdf> Could we use or refer to\nthose definitions?\n\n++Jack++\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Wednesday, November 05, 2003 9:59 AM\nTo: 'public-p3p-spec@w3.org'\nSubject: RE: Concerns re: Same-Entity proposal\n\n\n\nOn Wed, Oct 22, 2003 at 03:31:48PM -0400, Dobbs, Brooks wrote:\n> 1)       We need be careful between providing tools on which to make\npolicy\n> and making policy itself.  While it may be a useful tool to have the\nability\n> to state that collection covered by separate PRFs  is under the control of\n> the same entity, ultimately it is up to the UAs to decide how they want to\n> implement these tools.\n\nI agree, but if we can find a way to express these relationships\neffectively, then I think we should also offer some examples of how UAs\nmight use the additional information.\n\n> 2)       We use the term entity (and later in the agent relationship\n> proposal - \"agent\") without providing sufficient guidance on what this\n> means.  Rigo suggests there may be ways around this but I think they would\n> be unclear at best and difficult to explain to the end user.  This\nsuggests\n> to me that point 1) may mean that UAs don't act on this tool if they had\nit.\n\nIs entity not well enough defined in the 1.0 specification? I agree that\nagent is difficult, although the data controller/processor terminology from\nthe EU Directive seems helpful.\n\n> 3)       I think that there is an issue in that entity is today defined at\n> the policy level.  A PRF for a host can reference 2 distinct policies each\n> of 2 distinct entities (data controllers) - how then can there be meaning\nto\n> say at the PRF level this entity is the same as anything else?  The same\nas\n> which of the 2?\n\nA PRF can only make declarations about the current site. If the current site\nis not entirely owned by a single entity, then it shouldn't use the\nsame-entity declaration mechanism, as that would not make sense. However, if\nit is owned entirely by a single entity, which also owns another site, then\nit makes sense for those two sites to declare each other same-entity via the\nPRF. Perhaps we should introduce the concept of an entity key in the policy\nfile which would be matched against a key declaration in the PRF, so that\nUAs could further validate the same-entity relationship when parsing the\nactual policy files.\n\n> 4)       There would need to be a mechanism to expire same entity\n> relationship.  This may be handled through the expiry in policy files but\n> there is currently no such mechanism for CPs\n\nIf we have the HTTP header support for declaring same-entity, we can build\nan expiration property into it. There seems to be some debate as to whether\nor not we should even provide this mechanism for CPs at all, though. Not\nsure where I stand on that yet.\n\n> 5)       Headers are limited practically by the number of same hosts that\n> they can declare.  Also declaring multiple \"same-entity\" relationships\nwould\n> presumably require a validation against each full policy prior to\naccepting\n> the accuracy of the header declaration.  This is somewhat illogical, as,\nIF\n> we where to accept the performance hit of policy prefetching, then we\nwould\n> have no need for CPs!  Jack rightly points out that we may only need to\n> validate against the PRF and not the policy - but I think that I may have\n> brought that into question with point 3).\n\nI think these are good arguments for doing away with the HTTP header portion\nof the proposal.\n\n> 6)       Again on the topic of CPs, once a same entity relationship has\nbeen\n> established between cookie (set by A) and site B from which an asset\n> appears, how they can a same entity relationship be established from a\n> subsequent replay on site C (provided that PRFs or policies) for all these\n> sites do indeed declare each other as same entity?\n\nExample:\n1. UA has been configured to not allow third-party cookies.\n2. UA visits a.com. A response from an image request to b.com wishes to set\ncookie B1.\n3. UA evaluates PRFs and determines that a.com and b.com have a same-entity\nrelationship. Cookie B1 is accepted.\n4. UA visits a.com again. Cookie B1 is sent along on image request to b.com.\n5. UA visits x.com, which contains an image reference to b.com.\n6. Since B1 is only valid for playback on a.com, UA delays image request to\nb.com and fetches x.com's PRF.\n7. UA evaluates PRF and determines the x.com and b.com have a same-entity\nrelationship. \n8. UA sends cookie B1 with image request to b.com.\n\nNotes:\n- UA could cache same-entity relationship information along with PRF to\navoid future fetching. \n- Since same-entity is a transitive relationship, the UA could then extend\nit to say that x.com and a.com are same-entity for a future transaction.\n\n\n++Jack++\n\n\n\n", "id": "lists-017-5803312"}, {"subject": "Re: [Minutes] 5 November cal", "content": "On Wed, Nov 12, 2003 at 05:33:41AM +1100, Patrick.Hung@csiro.au wrote:\n> I got a few comments from the talk I gave at the Hong Kong \n> University of Science and Technology (HKUST) about P3P and P3P \n> Beyond HTTP as follows:\n> \n> (1) Referring to the \"Privacy\" tab in the \"Internet Option\" from\n> IE, it doesn't really tell much to a non-computer scientist. It \n> seems that every IE user must understand P3P and APPEL in order to \n> set their privacy preferences properly.\n\nWe can't help here, as this is Microsoft specific. This is the user\ninterface issue we want to solve with the user-agent guidelines. But we\ncan't help with IE specifics and the specification doesn't mandate to\nmany things in the user interface. (which is good to allow competition)\n> \n> (2) Privacy is still a very tough problem in accessing Web pages \n> (as what P3P is mainly targeting for), and it involves a lot of\n> non-technical issues such as management. How could we overcome \n> the non-technical issues in the Web services scenario?\n\nThe issue here is the diversity that is enabled by web services. The\nprivacy issues simply depend on the current service, the data that it\nneeds and the way it handles that data. In general, non-technical stuff\nis governed by sector-specific industry best practices or laws. But we\nshould be able to help them express it in P3P and show the power of\ntransparency here.\n\n> \n> (3) There should have some learning technologies (such as the learning\n> technology for detecting SPAM e-mails) to set the privacy preferences\n> for a user.\n\nIMHO, the creation of preferences is more a process than a static thing.\nFor the time being, implementers preferred to have static preferences\nfor the sake of simplicity and ease of implementation. Also, it is not\neasy to write things back to an apple file. Giles already had some\nremarks on this and suggested to use xpath instead. We haven't even\nattacked this issue so far.\n\n> \n> (4) The relationships between security and privacy are still not \n> very clear.\n\nSecurity obligations were always a part of the computer-privacy world.\nPersonal data is sensitive data and should be secured. JRC and Giles\nsuggested to have a security-metadata system to be able to express the\nsecurity features of a service in order to make privacy decisions. But\nthere was not much interest in such an ontology.\n\n> \n> By the way, would you please tell me more about \"the plans for a\n> workshop in WS-Privacy and Policy?\"\n\nAt the moment, this is stalled. I can't tell you more for the\nmoment. \n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5816528"}, {"subject": "NO call on November 1", "content": "Dear all, \n\nwhile on the AC-Meeting in Japan, I have trouble to make a call at 3am\nbecause my mobile doesn't work here. As we have no urgent need to talk,\nI would prefer to have the next phone call on 26 November that will\ntreat domain relationsships and the Art. 10 stuff.\n\nI'm doing edits at the moment. I would like to get some more discussion\naround the agent/domain relationsships. Jack has written his proposal\nand responded to Brooks. So if there are persisting concerns, they\nshould be expressed on the mailing-list. Brooks are the responses from\nJack sufficient?\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5826097"}, {"subject": "[Agenda] Call 26 November 200", "content": "The next P3P specification group conference call will be on\nWednesday, November 26, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n1/ Service definition in specification\nWe still have the wording in the specification, but I can't \nfind any record of a decision in the minutes.\n\n2/ Discussion about agent relationsships\n\nWhat is same entity, what is agent and what is third party?\nAny suggestions on that?  P3P actually defines entity and\nrelatet parties in <ours />:\n\nOurselves and/or entities acting as our agents or entities for\nwhom we are acting as an agent: An agent in this instance is\ndefined as a third party that processes data only on behalf of\nthe service provider for the completion of the stated\npurposes. (e.g., the service provider and its printing bureau\nwhich prints address labels and does nothing further with the\ninformation.)\n\nThis means agents are already included in <ours /> but this\ncan't be expressed in the PRF until now. \n\nJack suggested the following Definition:\n\nAGENT (Processor)   means that the Web Beacon is being\ndelivered by a n Agent for purposes exclusively related to the\nneeds of the First Party. In this context, the contract\nbetween the First Party and the Agent must clarify that the\nAgent cannot use any individual, non-aggregated data gathered\nthrough the Web Beacon for its own purposes. In other words,\nthe data is still  owned  by the First Party. The use of\nanonymous data by the Agent for aggregate or statistical\npurposes does not constitute a use for the Agent s purposes.\n\nThe Processor-Definition of the EU-Directive is the following:\nArticle 2:\n(e) 'processor' shall mean a natural or legal person, public\nauthority, agency or any other body which processes personal\ndata on behalf of the controller;\n\n3/ Update on p3p beyond http\n\nI'll give a short update from my trip in Japan, meeting with\nothers from the team.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5832744"}, {"subject": "Re: Concerns re: SameEntity proposa", "content": "On Wed, Nov 05, 2003 at 09:58:57AM -0600, Humphrey, Jack wrote:\n> I agree, but if we can find a way to express these relationships\n> effectively, then I think we should also offer some examples of how UAs\n> might use the additional information.\n\nI think, this is a question for the UA-Guidelines. So if we have a\nrelationsship proposal, this will be then considered by the UA-TF or the\nWG as a whole under the angle of our current UA-Guidelines proposal.\n> \n> > 2) We use the term entity (and later in the agent relationship\n> > proposal - \"agent\") without providing sufficient guidance on what\n> > this means.  Rigo suggests there may be ways around this but I think\n> > they would be unclear at best and difficult to explain to the end\n> > user.  This suggests to me that point 1) may mean that UAs don't act\n> > on this tool if they had it.\n> \n> Is entity not well enough defined in the 1.0 specification? I agree that\n> agent is difficult, although the data controller/processor terminology from\n> the EU Directive seems helpful.\n\nThe issue here is that we have already the term agent in our\nspecification, but it is not defined. So the concept of agent in a\nnarrow sense already works for the vocab, but not for the PRF. I think\nlike general federation is an issue, the term of 'agent' is also an\nissue. Therefor, I suggest we discuss that on the next call. \n> \n> > 3)       I think that there is an issue in that entity is today\n> > defined at the policy level.  A PRF for a host can reference 2\n> > distinct policies each of 2 distinct entities (data controllers) -\n> > how then can there be meaning to say at the PRF level this entity is\n> > the same as anything else?  The same as which of the 2?\n> \n> A PRF can only make declarations about the current site. If the current site\n> is not entirely owned by a single entity, then it shouldn't use the\n> same-entity declaration mechanism, as that would not make sense. \n\nThis assumption is not quite correct. A PRF can point to a multitude of\npolicies with different entities being responsible. So the question is,\nwhether the element <known-hosts> should go at the top level or one\nlevel down into the <policy about='uri'>\n\nIt is not impossible, that an entity is having their own site and\ngetting some service from some other site. IMHO, this is rather common,\nif you get counting service, database inclusion etc. All depends on\nwhether this is just an independend service used or whether there are\ncontractual relationsships that also include rules for the use of the\ndata collected.\n\n> If we have the HTTP header support for declaring same-entity, we can build\n> an expiration property into it. There seems to be some debate as to whether\n> or not we should even provide this mechanism for CPs at all, though. Not\n> sure where I stand on that yet.\n\nI think, this is too much overhead as we would have to write another\nIETF-Draft and push it through their procedures. I would rather stick\nwith the PRF-expiry. \n\n> \n> > 5)       Headers are limited practically by the number of same hosts\n> > that they can declare.  Also declaring multiple \"same-entity\"\n> > relationships would presumably require a validation against each\n> > full policy prior to accepting the accuracy of the header\n> > declaration.  This is somewhat illogical, as, IF we where to accept\n> > the performance hit of policy prefetching, then we would have no\n> > need for CPs!  Jack rightly points out that we may only need to\n> > validate against the PRF and not the policy - but I think that I may\n> > have brought that into question with point 3).\n> \n> I think these are good arguments for doing away with the HTTP header portion\n> of the proposal.\n\nAlso note, that in case of headers, the evaluation is real time and does\nnot need all the caching. In this case, it is easier to just evaluate\nthe header CP that comes anyway instead of adding complicated agent\nrelationsships. \n\nThe relationsship proposal should not serve to circumvent shortcomings\nof the compact format that lead to blocking of cookies because they\ncontain an overstatement leading to unacceptable policies. This should\nbe solved in another way. It shouldn't be possible to hide a bad\npractice behind a good policy and some complex domain relationsships.\n> \n> > 6)       Again on the topic of CPs, once a same entity relationship\n> > has been established between cookie (set by A) and site B from which\n> > an asset appears, how they can a same entity relationship be\n> > established from a subsequent replay on site C (provided that PRFs\n> > or policies) for all these sites do indeed declare each other as\n> > same entity?\n> \n> Example:\n> 1. UA has been configured to not allow third-party cookies.\n\nAgain, third party cookies are not a concept of P3P! P3P distinguishes\nbetween cookies with acceptable policy and those that haven't an\nacceptable policy.\n\n> 2. UA visits a.com. A response from an image request to b.com wishes to set\n> cookie B1.\n> 3. UA evaluates PRFs and determines that a.com and b.com have a same-entity\n> relationship. Cookie B1 is accepted.\n\nYou try to solve the wrong problem here. Or P3P in 1.1 should accept and\nincorporate the notion of third party content and state on this. If you\nwish to discuss it, raise it on the mailing-list.\n\n> 4. UA visits a.com again. Cookie B1 is sent along on image request to b.com.\n> 5. UA visits x.com, which contains an image reference to b.com.\n> 6. Since B1 is only valid for playback on a.com, UA delays image request to\n> b.com and fetches x.com's PRF.\n> 7. UA evaluates PRF and determines the x.com and b.com have a same-entity\n> relationship. \n> 8. UA sends cookie B1 with image request to b.com.\n> \n> Notes:\n> - UA could cache same-entity relationship information along with PRF to\n> avoid future fetching. \n> - Since same-entity is a transitive relationship, the UA could then extend\n> it to say that x.com and a.com are same-entity for a future transaction.\n\nNice example for further improvements.. But this is rather a tip for\nimplementers than a direct thing for the specification.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5840935"}, {"subject": "Re: [Minutes] Call 26 November 200", "content": "Present:\nRigo Wenning\nGiles Hogben\nBrooks Dobbs\n\nRegrets:\nJack Humphrey\nJeff Edelen\nPatrick Hung\n\n1/ Service definition in specification\n\nRigo exposed the issue. Brooks and Giles agreed. \nGiles had questions about how the contact is made. \nresolution-type is service here, but there is also the service \nattribute indicating the URI of customer service.\n\nWe decided to do the change.\n\n2/ Discussion about agent relationsships\n\nRigo introduced the question: \n\nin the same-entity proposal we distinguish between entity and \nagents. But the <ours /> definition says we and our agents:\n\nWe concluded that the definition is not consistent. But it is too\ndifficult to re-question the compromise found in P3P 1.0. But\nperhaps there are addtional classes of recipients missing.\n\nGiles is missing the sentence: \"MUST not disclose the data to any\nnon-declared recipient\".  to add to recipient-element. \n\nWe concluded that we don't need same entity and agent proposal, \nbut only one procedure. We postponed decision which one follow\nand expect more discussion on the mailing-list. \n\n\nNext call:\n3 December 2003\n\n\n\n", "id": "lists-017-5854431"}, {"subject": "[Agenda] 3 December cal", "content": "The next P3P specification group conference call will be on\nWednesday, December 3, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n\n1/ Report and discussion on Art. 10 issues \n\n2/ Continued discussion of agent-relationsships\n\n3/ discuss the link-texts from Giles and Jeff\n+are they ready\n+Where should they go,\n\n4/ decision on consent-choices\nShould we go for the proposal as is? Which deadline for comments\ndo we give?\n\n5/ Suggested wording for <money />\nOn 5 November, we decided to change the text of money. See\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=386\n\nWe suggested to add some wording to the spec. I suggest to add \nthe following wording:\n\nMoney stands for compensation for alleged infringements of the\nstated privacy practices. In order to have those errors also \ncorrected, <money /> and <correct /> must <em>both</em> be\npresent in the policy.\n\nWe should also change the user-string connected to.\nActual wording:\nWe will pay individuals if we violate our privacy policy\n\nSuggested wording:\nWe will compensate violations of our privacy policy\n\n6/ some precision for <law />\n\n<law /> can take an attribute URI that points to the law in\nquestion. So human description was wrong. I erased it from the\ndefinition.\n\nPlease feel also free to discuss the points on the mailing-list\n\nRigo\n\n\n\n", "id": "lists-017-5861759"}, {"subject": "law  element in remedie", "content": "Dear all, \n\non the 5 November call, we found that there is a close relationship\nbetween disputes and remedies and changed the wording accordingly. Now\nin <law /> under <Remedies> it says: \n\nmay be specified by the law referenced in the human readable\ndescription.\n\nBut in the <Disputes> - Element, someone could write a statement like\nthis:\n\n  <DISPUTES-GROUP>\n   <DISPUTES resolution-type=\"law\"\n     service=\"http://www.datenschutzzentrum.de/material/recht/ldsg-neu/ldsg-neu.htm\"\n     short-description=\"State Data Protection Act Schleswig-Holstein\">\n    <REMEDIES><law /></REMEDIES>\n   </DISPUTES>\n  </DISPUTES-GROUP>\n\nIn this case, the law is referenced automatically by the service-URI. In\nthis case, it doesn't make sense to go back to the human readable\npolicy, as required by the current definition. \n\nSo I propose to change that definition to:\n\nRemedies for disputes arising in connection with the Privacy Statement\nmay be specified by the law referenced in service-URI.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5869393"}, {"subject": "final p3p translation tabl", "content": "Dear all, \n\nI've finished the editing work on the translation table. I left the Spec\ndefinitions in the table for the moment, as they were also partly\nchanged. Please have a look at it:\n\nhttp://www.w3.org/P3P/2003/11-p3p-translation.htm\n\nIf there are further issues, please report them to the mailing-list or\nto the member-list or to me.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5876634"}, {"subject": "P3P Beyond HTTP Task Force  Tasks To D", "content": "Hello,\n\nI am back to Australia from my trip in the US and Canada. \n\nBeside Rigo and I presented P3P and Web services privacy stuff at\nthe IBM + W3C workshop at Sydney, I also gave talks about Web \nservices privacy in the context of P3P Beyond HTTP Task Force to\nthese institutes in North America in the past couple weeks:\n1. Wayne State University (Detroit, MI)\n2. University of Ontario Institute of Technology (Toronto, ON)\n3. Rutgers University (Newark, NJ)\n4. Virginia Tech (Falls Church, VA)\n\nMost of the audiences found that this research topic is pretty interesting\nand important for Web services-based e-business in the future.\n\nIn particular, Virginia Tech people has been doing some privacy research\ntopics in the context of Web services-based digital government. \n\nOverall, the people all believe that the direction of this task force is \nright on track. In general, there are six questions/comments from them:\n(1) Looking forward to see more interactions between this task force\n    and other W3C working groups, especially SOAP and WSDL.\n(2) Need a big technical picture to demonstrate the roles of privacy\ntechnologies \n    and related concepts (e.g., trust) in different Web services-based\napplications.\n(3) Is there any legislation/law to support/protect P3P and Web services\nprivacy stuff?\n(4) Will there be a new privacy language for describing privacy policies in\nWeb\n    services or directly adapt P3P in it?\n(5) What is the relationship between the proposed Web services privacy ideas\nand\n    WS-Privacy?\n(6) Have P3P working group considered a negotiation model for both P3P and\nWeb\n    Services privacy?\n\nI think that there are three VERY IMPORTANT tasks to do:\n(1) Start to interact and communicate with W3C SOAP and WSDL working groups.\nI need\n    help from Rigo and Hugo.\n(2) Draw and describe a diagram to demonstrate the importance of privacy\ntechnologies\n    in a big picture. This is what I am now thinking...\n(3) Find more participants. In fact, I did try to invite some researchers\ninvolving into\n    this task force. I did invite some researchers from Hitachi (Japan) and\nVirginia\n    Tech (USA) to join us.\n\nI am also going to give this talk to Macquarie U at Sydney on coming Friday.\n\nPatrick.\n\n-----Original Message-----\nFrom: Patrick.Hung@csiro.au [mailto:Patrick.Hung@csiro.au]\nSent: Thursday, 28 August 2003 9:17 PM\nTo: public-p3p-spec@w3.org\nSubject: RE: P3P beyond HTTP\n\n\n\nHi Rigo,\n\n> Yes, the beyond HTTP was already discussed earlier and we didn't wanted\n> to preclude other uses. For WSDL, comments from Hugo are pending. I will\n> try to get those soon. For SOAP, we might want some help from the XML\n> Prot Group in constructing the binding. Perhaps Mark Nottingham is able\n> to help us a bit.\n\nThat would be great. I will keep on thinking along this line. In fact, I am\non vacation from 29/8 to 7/9. However, I will try my best to attend next\nweek's P3P call.\n\n> I think it is definitely a good idea to look into WSDL bindings. Isn't\n> this what is already contained in the Task Force WD?\n\nYes, you are right. However, I think that we should polish the content in a\nformat that can be merged into the P3P 1.1 spec.\n\n> We still have to discuss advantages and disadvantages of having a\n> standalone document vs. integration into the 1.1 Spec (e.g. conformance)\n\nI am looking forward to discussing with you on Sept 9. Have a nice trip.\n\nCheers,\n\nPatrick.\n\n\n\n", "id": "lists-017-5912018"}, {"subject": "RE: AGENDA: 1 Oct P3P spec cal", "content": "Sorry I haven't offered the \"court\" definition I promised, and I failed to\ncoordinate the fact that today I'm at a conference and won't be on the call.\n\n\nFrankly, I'm still struggling with what could be conveyed that would be\nmeaningful for what sounds like the few who might now use it.  But it might\nbe more important in the future.\n\nIf LAW allows a site to recite the various laws that might govern the\nbusiness (e.g., for a bank in the California, GLB, Cal. Financial Privacy\nLaw, California Notice of Security Breach, among others)...\n\nCOURT might not be meaningful if it had the meaning of \"Authority,\" as in\n\"government agency that has jurisdiction over the privacy rules & affairs of\nthis business.\"  For a bank (Bill?) maybe that would be the OCC.  For a\nstate bank, it might be the AG.  Other agencies might still have some\njurisdiction, but perhaps there is one authority more important than others.\n\nIn Canada, AUTHORITY might be the Canadian equivalent of a national bank\noverseer, plus the Privacy Commissioner for the nation or the province.\n\nIt's a bit like I'm trying to find a job for COURT to do.\n\nAt the bottom line, it the spec were to stay as it is and is optional, then\na given site could take it or leave it if the site is concerned about\nunintended implications of using it.\n\n\n\nDave Stampley\nv.  937-485-0424\nf.  937-485-0973\ndavid_stampley@reyrey.com\n\n-----Original Message-----\nFrom: Rigo Wenning [mailto:rigo@w3.org] \nSent: Tuesday, September 30, 2003 12:17 PM\nTo: public-p3p-spec\nSubject: AGENDA: 1 Oct P3P spec call\n\n\nThe next P3P specification group conference call will be on\nWednesday, October 1, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n   - [P3P beyond HTTP - Patrick Hung]\n   - Compact policies - Brooks Dobbs\n   - Article 10 vocabulary issues - Giles Hogben\n   - Agent and domain relationships - Jack Humphrey\n   - Consent choices - Matthias Schunter\n   - Converting P3P data schema to XML schema - Giles Hogben\n   - [Signed P3P policies  - Giles Hogben]\n\n2. Discussion of disputes definition issues -- see\n   comments in green at http://www.w3.org/P3P/2003/p3p-translation.htm\n\n3. Continued work on P3P 1.0 element definitions and translations\n   http://www.w3.org/P3P/2003/p3p-translation.htm\n\n4. Linking cookie data and what it means\n   http://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n5. Set date for next call (Oct. 15)\n\n\n\n", "id": "lists-017-5923259"}, {"subject": "RE: P3P Beyond HTTP Task Force  Tasks To D", "content": "Hi Rigo,\n\nReferring to the discussion at Sydney, I will change the working draft\nto adapt \"namespaces\" approach instead of \"URI reference\" for those\nprivacy policies in UDDI, WSDL and SOAP.\n\nCheers,\n\nPatrick.\n\n-----Original Message-----\nFrom: Patrick.Hung@csiro.au [mailto:Patrick.Hung@csiro.au]\nSent: Wednesday, 1 October 2003 11:05 PM\nTo: public-p3p-spec@w3.org\nSubject: P3P Beyond HTTP Task Force - Tasks To Do\n\n\n\nHello,\n\nI am back to Australia from my trip in the US and Canada. \n\nBeside Rigo and I presented P3P and Web services privacy stuff at\nthe IBM + W3C workshop at Sydney, I also gave talks about Web \nservices privacy in the context of P3P Beyond HTTP Task Force to\nthese institutes in North America in the past couple weeks:\n1. Wayne State University (Detroit, MI)\n2. University of Ontario Institute of Technology (Toronto, ON)\n3. Rutgers University (Newark, NJ)\n4. Virginia Tech (Falls Church, VA)\n\nMost of the audiences found that this research topic is pretty interesting\nand important for Web services-based e-business in the future.\n\nIn particular, Virginia Tech people has been doing some privacy research\ntopics in the context of Web services-based digital government. \n\nOverall, the people all believe that the direction of this task force is \nright on track. In general, there are six questions/comments from them:\n(1) Looking forward to see more interactions between this task force\n    and other W3C working groups, especially SOAP and WSDL.\n(2) Need a big technical picture to demonstrate the roles of privacy\ntechnologies \n    and related concepts (e.g., trust) in different Web services-based\napplications.\n(3) Is there any legislation/law to support/protect P3P and Web services\nprivacy stuff?\n(4) Will there be a new privacy language for describing privacy policies in\nWeb\n    services or directly adapt P3P in it?\n(5) What is the relationship between the proposed Web services privacy ideas\nand\n    WS-Privacy?\n(6) Have P3P working group considered a negotiation model for both P3P and\nWeb\n    Services privacy?\n\nI think that there are three VERY IMPORTANT tasks to do:\n(1) Start to interact and communicate with W3C SOAP and WSDL working groups.\nI need\n    help from Rigo and Hugo.\n(2) Draw and describe a diagram to demonstrate the importance of privacy\ntechnologies\n    in a big picture. This is what I am now thinking...\n(3) Find more participants. In fact, I did try to invite some researchers\ninvolving into\n    this task force. I did invite some researchers from Hitachi (Japan) and\nVirginia\n    Tech (USA) to join us.\n\nI am also going to give this talk to Macquarie U at Sydney on coming Friday.\n\nPatrick.\n\n-----Original Message-----\nFrom: Patrick.Hung@csiro.au [mailto:Patrick.Hung@csiro.au]\nSent: Thursday, 28 August 2003 9:17 PM\nTo: public-p3p-spec@w3.org\nSubject: RE: P3P beyond HTTP\n\n\n\nHi Rigo,\n\n> Yes, the beyond HTTP was already discussed earlier and we didn't wanted\n> to preclude other uses. For WSDL, comments from Hugo are pending. I will\n> try to get those soon. For SOAP, we might want some help from the XML\n> Prot Group in constructing the binding. Perhaps Mark Nottingham is able\n> to help us a bit.\n\nThat would be great. I will keep on thinking along this line. In fact, I am\non vacation from 29/8 to 7/9. However, I will try my best to attend next\nweek's P3P call.\n\n> I think it is definitely a good idea to look into WSDL bindings. Isn't\n> this what is already contained in the Task Force WD?\n\nYes, you are right. However, I think that we should polish the content in a\nformat that can be merged into the P3P 1.1 spec.\n\n> We still have to discuss advantages and disadvantages of having a\n> standalone document vs. integration into the 1.1 Spec (e.g. conformance)\n\nI am looking forward to discussing with you on Sept 9. Have a nice trip.\n\nCheers,\n\nPatrick.\n\n\n\n", "id": "lists-017-5933409"}, {"subject": "Re: P3P Beyond HTTP Task Force  Tasks To D", "content": "Patrick, \n\nit would be good to keep the URI reference and to add mixing namespaces\nas one option. We'll figure out later with the Web Services Activity how\nto solve it the best. In that case we can still cut out possibilities.\n\nBest, \n\nRigo\n\nOn Thu, Oct 02, 2003 at 02:37:28AM +1000, Patrick.Hung@csiro.au wrote:\n> Hi Rigo,\n> \n> Referring to the discussion at Sydney, I will change the working draft\n> to adapt \"namespaces\" approach instead of \"URI reference\" for those\n> privacy policies in UDDI, WSDL and SOAP.\n> \n\n\n\n", "id": "lists-017-5946937"}, {"subject": "Minutes: 1 Oct P3P spec cal", "content": "On Tue, Sep 30, 2003 at 06:17:23PM +0200, Rigo Wenning wrote:\n\n1/ Task Force reports:\n\nA/ P3P beyond HTTP\nPatrick reported from his trip on Web Services. In conclusion he\nmentioned three important points: \n\n(1) Start to interact and communicate with W3C SOAP and WSDL working groups.\nI need help from Rigo and Hugo.\n(2) Draw and describe a diagram to demonstrate the importance of privacy\ntechnologies in a big picture. This is what I am now thinking...\n(3) Find more participants. In fact, I did try to invite some researchers\ninvolving into this task force. \n\nI did invite some researchers from Hitachi (Japan) and\nVirginia Tech (USA) to join us.\n\nDicussion about further steps. Rigo reported from talk with Hugo\nHaas and Rigo will contact Philippe Le Hegaret.\nAction Rigo: Talk to HH and PLH and report back\n\n\nB/ Article 10\nMeeting on 11 Sep was cancelled as Art. 29 WP wasn't ready yet.\nGiles sent a new document in. Diana will circulate this document\nat Art. 29 WP. \n\nC/ Converting data schemas\nGiles sent document to Rigo. Will be ready for review by the end\nof the week With new announcement. Rigo is actually doing edits and\nformatting of the document. Announcement will be sent to the list when\nthe document is online. \n\n2/ Discussion on elements postponed\nContinue discussion on the mailing-list. In absence of Dave Stampley, we\npostponed the discussion on\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\n\n\n3/ We discussed Rigo's primary purpose\nRigo reported about his exchanges with IBM and that it still needs\nfurther discussion. They don't have a list of such primary purposes. \nMissing primary purposes was one of the disadvantages compared to short\nnotices. Rigo asked Jeff to think about a list of some primary purposes \nin the financial industry, but not issuing it as an action item.\n\nAction item Rigo pending:\nTalk to IBM on primary purpose\n\n4/ Giles: cookie is like a database identifier\n   Jeff: whether use is intended or not, one has to declare.\n GH: doesn't have to be unique ID. It has the purpose to select\n a bunch of records in a database.\n   Jeff: cases are sites with single sign-on etc and scope is not\n always clear. Has to be clarified what happens with the\n information, e.g. purpose. \n Jeff: also when converting to compact policy, it looses\n semantics and sounds more that the actual collection is. \n \nAction: Giles: Write some paragraphs about linked data and\ncookies.  \n\nAction: Jeff: Write some paragraphs describing the issue.\n\nTalking about APPEL, there was no result from the P3P Event in Sydney.\nWe might consider doing another meeting with JRC in Ispra/Italy\n\n5/ Next call will be on 15 October 11am-12pm EDT\n\nRigoscribe\n\n\n\n", "id": "lists-017-5954695"}, {"subject": "Please review: New: Dataschema in XML Schem", "content": "Dear all, \n\nI've published Giles' Draft at \nhttp://www.w3.org/P3P/2003/09-Schema.html\n\nThose of you being XML literate, please review the Draft. I would like \nto address a special invitation for review to Giles and Matthias. \n\nWe will talk about this Draft at our call on 15 October.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-5963658"}, {"subject": "RE: P3P and WSD", "content": "Hi Philippe,\n\nThank you very much for your message. My response is contained in\n<patrick/>.\n\nMay I ask whether you have any suggestion for this task force? How should\nthis\ntask force work with the WSDL and SOAP working groups?\n\nMany thanks again,\n\nPatrick.\n\n-----Original Message-----\nFrom: Philippe Le Hegaret [mailto:plh@w3.org]\nSent: Friday, 3 October 2003 4:34 AM\nTo: Patrick C. K. Hung\nCc: Rigo Wenning; Hugo Haas; w3t-archive@w3.org\nSubject: P3P and WSDL\n\n\nPatrice,\n\nI came across the \"P3P: Beyond HTTP\" note and in particular the section\nrelated to WSDL:\n[[\n <import namespace='http://www.w3.org/P3P/2003/p3p-beyond-http/'\nlocation='wsdl-p3p-extension.xsd'/>\n <my:Privacy rel='P3Pv1'\nhref='http://registry.example.com/P3P/policy-register.xml'/>\n]]\n\nHere are some ideas/thoughts regarding the document from my WSDL point\nof view.\n\nI can see two ways to attach a P3P to a WSDL:\n1- by reference\n2- by inclusion\n<patrick>Yes, Rigo, Hugo and I have been discussing this issue. I agree with\nyou.</patrick>\n\n1- By reference\n\nThis is your example. The privacy element links to a P3P file. However,\nthe section fails - to indicate what happens if the P3P file make\nstatements on a set of URIs (using the INCLUDE element) that happens to\ndiffer from the location of the service (in the soap:address or\nhttp:address elements).\n<patrick>Would you please further explain it? It is expected to have a\nrevised P3P language for describing privacy policies in the context of \nWeb services. Thus, I am not very sure what do you mean.</patrick>\n\n- to indicate that the statements are only applicable to the information\ngoing from the registrant to the registry. What happen to the\ninformation going from the registry to the registrant? Can't the\nregistry indicates its preferences to the registry? If yes, should the\n                                 <patrick>^^^^^^^^ registrant?</patrick>\nregistry indicate its preferences using a SOAP header in the output\nmessages or in the WSDL as well?\n<patrick>This is a very interesting point. At this minute, we only \nconsider uni-directional scenario. We will explore this point in the working\ndraft for next version.</patrick>\n\n- to indicate how one can apply one specific per operation. Your example\nonly shows how to set a registry but doesn't contain an operation for a\nget. One can imagine to apply different sets of policy on the set and\nget operations.\n<patrick>I will send you some slides that describe this scenario\nseparately.</patrick>\n\n2- by inclusion\n\nThis case is not addressed in your document. The extensibility model of\nWSDL allows to put P3P elements and attributes in all sections of the\ndescription. Imho, it is reasonable to include P3P POLICY elements in\nthe WSDL at the interface, operation, or service level.\n<patrick>Yes, I agree with you.</patrick>\n\nIn either case, can you apply/reference more than one policy in a WSDL?\nIf yes, does it have a meaning (i.e. can you merge two policies?)?\n<patrick>\nIn theory, we can apply more than one policy in WSDL. In the \nfirst cut, we would expect that there should have a logical AND in\nprivacy policies described in different levels.\n\n-- Given that a WSDL description or UDDI entry is OPTIONAL to the Web\nService, associating a privacy policy with these descriptions is OPTIONAL.\nHowever, when optional associations are provided, the adopting applications\nMUST ensure that multiple associations do not conflict with each other or\nthe normative declaration from the application, via the Non-ambiguity\nrequirement of ([P3P], section 2.4.1), \"Sites MUST be cautious in their\npractices when they declare multiple policies for a given URI, and ensure\nthat they can actually honor all policies simultaneously.\" --\n</patrick>\n\nYou should also mention the use of the wsdl:required attribute, to\nindicate whether it is required to follow the privacy or privacy\npreferences, otherwise a WSDL processor is entitled to ignore it.\n<patrick>Yes, I agree with you. It is a good idea.</patrick>\n\nWSDL, per decision on 20030703, dropped its extensibility using XML\nSchema. This includes the wsdl:globalExt definition. So you can (and\nmust) remove your substitutionGroup='wsdl:globalExt' declaration from\nthe definition of the Privacy element.\n<patrick>Thanks for your information.</patrick>\n\nPhilippe\n\n-- \nPhilippe Le Hegaret - http://www.w3.org/People/LeHegaret/\nWorld Wide Web Consortium (W3C), Web Services Description Team Contact\n\n\n\n", "id": "lists-017-5970225"}, {"subject": "RE: P3P and WSD", "content": "Thanks again, Philippe!\n\n-----Original Message-----\nFrom: Philippe Le Hegaret [mailto:plh@w3.org]\nSent: Friday, 3 October 2003 4:52 AM\nTo: Patrick C. K. Hung\nCc: Rigo Wenning; Hugo Haas; w3t-archive@w3.org\nSubject: Re: P3P and WSDL\n\n\nOne more thought.\n\nShould it be possible to apply different sets of statements on the data.\nImagine\n<information>\n  <name>Philippe</name>\n <email>plh@w3.org</email>\n</information>\n\n\nand\n<operation name='send'>\n <input element='information'/>\n</operation>\n\nShould you be allowed to express a privacy for the name and a different\none for email? If yes, then the policy will need to be referenced from\nthe schema definition itself.\n<patrick>Yes, it should be allowed. I would like to ask for your opinions.\nIn addition, would you please explain it more? Many thanks!</patrick>\n\nPhilippe\n\n\n\n", "id": "lists-017-5983879"}, {"subject": "RE: P3P and WSD", "content": "On Tue, 2003-10-07 at 06:18, Patrick.Hung@csiro.au wrote:\n> Hi Philippe,\n> \n> Thank you very much for your message. My response is contained in\n> <patrick/>.\n> \n> May I ask whether you have any suggestion for this task force? How should\n> this\n> task force work with the WSDL and SOAP working groups?\n\nHow about sending a note inviting them to provide feedback and even\nparticipate if they wish? I would certainly be happy to help the P3P WG.\n\n> 1- By reference\n> \n> This is your example. The privacy element links to a P3P file. However,\n> the section fails - to indicate what happens if the P3P file make\n> statements on a set of URIs (using the INCLUDE element) that happens to\n> differ from the location of the service (in the soap:address or\n> http:address elements).\n> <patrick>Would you please further explain it? It is expected to have a\n> revised P3P language for describing privacy policies in the context of \n> Web services. Thus, I am not very sure what do you mean.</patrick>\n\nActually, I realized that section 4.3 explicitly mentions that a WSDL\ndescription directly references a policy, not a policy reference.\nTherefore, since the policy doesn't contain any reference,  it does\nexclude the case I was trying to address.\n\n\n> - to indicate that the statements are only applicable to the information\n> going from the registrant to the registry. What happen to the\n> information going from the registry to the registrant? Can't the\n> registry indicates its preferences to the registry? If yes, should the\n>                                  <patrick>^^^^^^^^ registrant?</patrick>\n\n correct s/registry/registrant/\n\n> registry indicate its preferences using a SOAP header in the output\n> messages or in the WSDL as well?\n> <patrick>This is a very interesting point. At this minute, we only \n> consider uni-directional scenario. We will explore this point in the working\n> draft for next version.</patrick>\n\nplease, make sure this item is not dropped when defining the\nrequirements for the next version. In any case, the current version\nshould indicate that the statements are only applicable to the\ninformation received by the service, and not the client interacting with\nthe service. What is the schedule regarding the first version of the\ndocument btw?\n\nPhilippe\n\n\n\n", "id": "lists-017-5993708"}, {"subject": "RE: P3P and WSD", "content": "On Tue, 2003-10-07 at 06:24, Patrick.Hung@csiro.au wrote:\n> One more thought.\n> \n> Should it be possible to apply different sets of statements on the data.\n> Imagine\n> <information>\n>   <name>Philippe</name>\n>  <email>plh@w3.org</email>\n> </information>\n> \n> \n> and\n> <operation name='send'>\n>  <input element='information'/>\n> </operation>\n> \n> Should you be allowed to express a privacy for the name and a different\n> one for email? If yes, then the policy will need to be referenced from\n> the schema definition itself.\n> <patrick>Yes, it should be allowed. I would like to ask for your opinions.\n> In addition, would you please explain it more? Many thanks!</patrick>\n\nConsider the following WSDL:\n\n<definitions [...]>\n <types>\n  <schema>\n   <xs:element name=\"information\">\n     <xs:complexType>\n       <xs:sequence>\n         <xs:element name=\"name\" type=\"xs:string\"/>\n         <xs:element name=\"email\" type=\"xs:anyURI\"/>\n         <xs:element name=\"creditCardNumber\" type=\"xs:string\"/>\n       </xs:sequence>\n     </xs:complexType>\n   </xs:element>    \n   <xs:element name=\"result\">\n     [...]\n   </xs:element>    \n  </schema>\n </types>\n <my:Privacy rel='P3Pv1' href='http://www.example.org/p3p.xml'/>\n <interface name='QueryService'>\n  <operation name='send'>\n    <input element='information'/>\n  </operation>\n </interface>\n [...]\n</definitions>\n\nOne can imagine to apply a different privacy restriction on the\nname and the email. For examples, the name and email will be used for\ncustomer tracking purposes, and will be stored by the service, while the\ncredit card number won't be used except for this purchase, and the card\nnumber won't be stored in any case.\nThe Privacy element applies to the transaction from the WS client to the\nWeb service and cannot be restrictied to a particular set of data. (on a\nside note, I wonder why you need this rel='p3pv1' attribute at all.\ndon't you deal with versioning by just using namespaces?)\nOne approach to resolve this would be to use XML Schema annotations (but\nthey are other approaches and I'm not suggesting that XML Schema\nannotations is the best approach):\n\n   <xs:element name=\"information\">\n     <xs:complexType>\n       <xs:sequence>\n         <xs:element name=\"name\" type=\"xs:string\">\n          <xs:annotation>\n           <xs:appinfo>\n             <my:Privacy rel='P3Pv1' href='http://www.example.org/p3p.xml'/>\n           </xs:appinfo>\n          </xs:annotation>\n         </xs:element>\n         <xs:element name=\"email\" type=\"xs:anyURI\">\n          <xs:annotation>\n           <xs:appinfo>\n             <my:Privacy rel='P3Pv1' href='http://www.example.org/p3p.xml'/>\n           </xs:appinfo>\n          </xs:annotation>\n         </xs:element>\n         <xs:element name=\"creditCardNumber\" type=\"xs:string\">\n          <xs:annotation>\n           <xs:appinfo>\n             <my:Privacy rel='P3Pv1'\n                  href='http://www.example.org/otherp3p.xml'/>\n           </xs:appinfo>\n          </xs:annotation>\n         </xs:element>\n       </xs:sequence>\n     </xs:complexType>\n   </xs:element>    \n\nAn other solution, used by the WSDL WG to deal with media types, would\nbe to use XML extensions:\n\n    <xs:element name=\"information\">\n     <xs:complexType>\n       <xs:sequence>\n         <xs:element name=\"name\" type=\"xs:string\"\n           my:p3p='http://www.example.org/p3p.xml'/>\n         <xs:element name=\"email\" type=\"xs:anyURI\"\n           my:p3p='http://www.example.org/p3p.xml'/>\n         <xs:element name=\"creditCardNumber\" type=\"xs:string\"\n           my:p3p='http://www.example.org/otherp3p.xml'/>\n       </xs:sequence>\n     </xs:complexType>\n   </xs:element>    \n\n\nIn both cases, this would still require defining an element included in\nthe WSDL to indicate the WSDL processor must follow the rules of P3P:\n<my:Privacy wsdl:required=true'/>\n(or using a feature, but the WG is still discussing this issue)\n\nIn any case, I don't think that this necessarily needs to be addressed\nin the first version of the document but a future version will need to.\n\nPhilippe\n\n\n\n", "id": "lists-017-6003814"}, {"subject": "RE: P3P and WSD", "content": "Please check <patrick2> as follows.\n\n-----Original Message-----\nFrom: Philippe Le Hegaret [mailto:plh@w3.org]\nSent: Wednesday, 8 October 2003 4:23 AM\nTo: Patrick.Hung@csiro.au\nCc: Rigo Wenning; Hugo Haas; w3t-archive@w3.org; public-p3p-spec@w3.org\nSubject: RE: P3P and WSDL\n\n\nOn Tue, 2003-10-07 at 06:18, Patrick.Hung@csiro.au wrote:\n> Hi Philippe,\n> \n> Thank you very much for your message. My response is contained in\n> <patrick/>.\n> \n> May I ask whether you have any suggestion for this task force? How should\n> this\n> task force work with the WSDL and SOAP working groups?\n\nHow about sending a note inviting them to provide feedback and even\nparticipate if they wish? I would certainly be happy to help the P3P WG.\n\n<patrick2>\nRigo: Do you have any idea which mailing list should I send?\n</patrick2>\n\n> 1- By reference\n> \n> This is your example. The privacy element links to a P3P file. However,\n> the section fails - to indicate what happens if the P3P file make\n> statements on a set of URIs (using the INCLUDE element) that happens to\n> differ from the location of the service (in the soap:address or\n> http:address elements).\n> <patrick>Would you please further explain it? It is expected to have a\n> revised P3P language for describing privacy policies in the context of \n> Web services. Thus, I am not very sure what do you mean.</patrick>\n\nActually, I realized that section 4.3 explicitly mentions that a WSDL\ndescription directly references a policy, not a policy reference.\nTherefore, since the policy doesn't contain any reference,  it does\nexclude the case I was trying to address.\n\n\n> - to indicate that the statements are only applicable to the information\n> going from the registrant to the registry. What happen to the\n> information going from the registry to the registrant? Can't the\n> registry indicates its preferences to the registry? If yes, should the\n>                                  <patrick>^^^^^^^^ registrant?</patrick>\n\n correct s/registry/registrant/\n\n> registry indicate its preferences using a SOAP header in the output\n> messages or in the WSDL as well?\n> <patrick>This is a very interesting point. At this minute, we only \n> consider uni-directional scenario. We will explore this point in the\nworking\n> draft for next version.</patrick>\n\nplease, make sure this item is not dropped when defining the\nrequirements for the next version. In any case, the current version\nshould indicate that the statements are only applicable to the\ninformation received by the service, and not the client interacting with\nthe service. What is the schedule regarding the first version of the\ndocument btw?\n\n<patrick2>\nHope to get more comments/suggestions by the end of Oct. And then, I would\ngenerate another version by the end of Nov. Thanks a lot for your\ncontributions.\n</patrick2>\n\nPhilippe\n\n\n\n", "id": "lists-017-6016768"}, {"subject": "RE: P3P and WSD", "content": "Please check <patrick2> as follows.\n\n-----Original Message-----\nFrom: Philippe Le Hegaret [mailto:plh@w3.org]\nSent: Wednesday, 8 October 2003 4:49 AM\nTo: Patrick.Hung@csiro.au\nCc: Rigo Wenning; Hugo Haas; w3t-archive@w3.org; public-p3p-spec@w3.org\nSubject: RE: P3P and WSDL\n\n\nOn Tue, 2003-10-07 at 06:24, Patrick.Hung@csiro.au wrote:\n> One more thought.\n> \n> Should it be possible to apply different sets of statements on the data.\n> Imagine\n> <information>\n>   <name>Philippe</name>\n>  <email>plh@w3.org</email>\n> </information>\n> \n> \n> and\n> <operation name='send'>\n>  <input element='information'/>\n> </operation>\n> \n> Should you be allowed to express a privacy for the name and a different\n> one for email? If yes, then the policy will need to be referenced from\n> the schema definition itself.\n> <patrick>Yes, it should be allowed. I would like to ask for your opinions.\n> In addition, would you please explain it more? Many thanks!</patrick>\n\nConsider the following WSDL:\n\n<definitions [...]>\n <types>\n  <schema>\n   <xs:element name=\"information\">\n     <xs:complexType>\n       <xs:sequence>\n         <xs:element name=\"name\" type=\"xs:string\"/>\n         <xs:element name=\"email\" type=\"xs:anyURI\"/>\n         <xs:element name=\"creditCardNumber\" type=\"xs:string\"/>\n       </xs:sequence>\n     </xs:complexType>\n   </xs:element>    \n   <xs:element name=\"result\">\n     [...]\n   </xs:element>    \n  </schema>\n </types>\n <my:Privacy rel='P3Pv1' href='http://www.example.org/p3p.xml'/>\n <interface name='QueryService'>\n  <operation name='send'>\n    <input element='information'/>\n  </operation>\n </interface>\n [...]\n</definitions>\n\nOne can imagine to apply a different privacy restriction on the\nname and the email. For examples, the name and email will be used for\ncustomer tracking purposes, and will be stored by the service, while the\ncredit card number won't be used except for this purchase, and the card\nnumber won't be stored in any case.\nThe Privacy element applies to the transaction from the WS client to the\nWeb service and cannot be restrictied to a particular set of data. (on a\nside note, I wonder why you need this rel='p3pv1' attribute at all.\ndon't you deal with versioning by just using namespaces?)\n\n<patrick2>\nThanks a lot! You raise a good question. I will think about it.\n</patrick2>\n\nOne approach to resolve this would be to use XML Schema annotations (but\nthey are other approaches and I'm not suggesting that XML Schema\nannotations is the best approach):\n\n   <xs:element name=\"information\">\n     <xs:complexType>\n       <xs:sequence>\n         <xs:element name=\"name\" type=\"xs:string\">\n          <xs:annotation>\n           <xs:appinfo>\n             <my:Privacy rel='P3Pv1' href='http://www.example.org/p3p.xml'/>\n           </xs:appinfo>\n          </xs:annotation>\n         </xs:element>\n         <xs:element name=\"email\" type=\"xs:anyURI\">\n          <xs:annotation>\n           <xs:appinfo>\n             <my:Privacy rel='P3Pv1' href='http://www.example.org/p3p.xml'/>\n           </xs:appinfo>\n          </xs:annotation>\n         </xs:element>\n         <xs:element name=\"creditCardNumber\" type=\"xs:string\">\n          <xs:annotation>\n           <xs:appinfo>\n             <my:Privacy rel='P3Pv1'\n                  href='http://www.example.org/otherp3p.xml'/>\n           </xs:appinfo>\n          </xs:annotation>\n         </xs:element>\n       </xs:sequence>\n     </xs:complexType>\n   </xs:element>    \n\nAn other solution, used by the WSDL WG to deal with media types, would\nbe to use XML extensions:\n\n    <xs:element name=\"information\">\n     <xs:complexType>\n       <xs:sequence>\n         <xs:element name=\"name\" type=\"xs:string\"\n           my:p3p='http://www.example.org/p3p.xml'/>\n         <xs:element name=\"email\" type=\"xs:anyURI\"\n           my:p3p='http://www.example.org/p3p.xml'/>\n         <xs:element name=\"creditCardNumber\" type=\"xs:string\"\n           my:p3p='http://www.example.org/otherp3p.xml'/>\n       </xs:sequence>\n     </xs:complexType>\n   </xs:element>    \n\n\nIn both cases, this would still require defining an element included in\nthe WSDL to indicate the WSDL processor must follow the rules of P3P:\n<my:Privacy wsdl:required=true'/>\n(or using a feature, but the WG is still discussing this issue)\n\n<patrick2>\nThanks a lot for your explanation. Will include all your ideas in next\nversion.\n</patrick2>\n\nIn any case, I don't think that this necessarily needs to be addressed\nin the first version of the document but a future version will need to.\n\nPhilippe\n\n\n\n", "id": "lists-017-6029206"}, {"subject": "Re: P3P and WSD", "content": "On Sat, Oct 11, 2003 at 01:24:48AM +1000, Patrick.Hung@csiro.au wrote:\n> <patrick2>\n> Rigo: Do you have any idea which mailing list should I send?\n> </patrick2>\n> \nPatrick, please send me a draft for the request for help. I will\ncoordinate with you.\n\nThe final message then goes to \nwww-ws-desc@w3.org for WSDL\nand to \nxml-dist-app@w3.org for SOAP\n\nI will put that on the agenda for the next meeting. \n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-6044022"}, {"subject": "AGENDA: 17 Oct P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, October 17, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n   - [P3P beyond HTTP - Patrick Hung]\n   - Compact policies - Brooks Dobbs\n   - Article 10 vocabulary issues - Giles Hogben\n   - Agent and domain relationships - Jack Humphrey\n   - Consent choices - Matthias Schunter\n   - Converting P3P data schema to XML schema - Giles Hogben\n\n2. P3P in WSDL, next steps\n   compare thread at\n http://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0006.html\n\n3. P3P Dataschema in XML Schema\n   please review\n http://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0005.html\n\n4. Discussion of the court element\n   comments at\n http://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0001.html\n\n5. Continued work on P3P 1.0 element definitions and translations\n   http://www.w3.org/P3P/2003/p3p-translation.htm\n\n5. Set date for next call (Oct. 29)\n\n\n\n", "id": "lists-017-6051868"}, {"subject": "RE: AGENDA: 17 Oct P3P spec cal", "content": "HI Rigo,\n\nThere is a typo: Wednesday, October 15, 2003.\n\nPatrick.\n-----Original Message-----\nFrom: Rigo Wenning [mailto:rigo@w3.org]\nSent: Saturday, 11 October 2003 2:11 AM\nTo: public-p3p-spec\nSubject: AGENDA: 17 Oct P3P spec call\n\n\n\n\nThe next P3P specification group conference call will be on\nWednesday, October 17, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n   - [P3P beyond HTTP - Patrick Hung]\n   - Compact policies - Brooks Dobbs\n   - Article 10 vocabulary issues - Giles Hogben\n   - Agent and domain relationships - Jack Humphrey\n   - Consent choices - Matthias Schunter\n   - Converting P3P data schema to XML schema - Giles Hogben\n\n2. P3P in WSDL, next steps\n   compare thread at\n\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0006.html\n\n3. P3P Dataschema in XML Schema\n   please review\n\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0005.html\n\n4. Discussion of the court element\n   comments at\n\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0001.html\n\n5. Continued work on P3P 1.0 element definitions and translations\n   http://www.w3.org/P3P/2003/p3p-translation.htm\n\n5. Set date for next call (Oct. 29)\n\n\n\n", "id": "lists-017-6059935"}, {"subject": "AGENDA: 15 Oct P3P spec cal", "content": "Sorry all, \n\nit must be October 15, please adjust your agenda\n\nThanks \n\nRigo\n\nOn Sat, Oct 11, 2003 at 04:16:08AM +1000, Patrick.Hung@csiro.au wrote:\n> \n> HI Rigo,\n> \n> There is a typo: Wednesday, October 15, 2003.\n> \n\n\n\n", "id": "lists-017-6069431"}, {"subject": "Web Services Conferenc", "content": "Please give me a minute to distribute this CFP here. Apologize for any\ninconvenience caused. :-) Patrick.\n\nApologies if you receive multiple copies of this message.\n\n============================================================\n\n2004 IEEE International Conference on Web Services (ICWS 2004)\nTheme: Convergence of Web Services, Grid Computing, e-Business and Autonomic\nComputing\nJuly 6-9, 2004, San Diego, California, USA\nhttp://conferences.computer.org/icws/2004/\nSponsored by the IEEE Computer Society\n\nCall for Papers\n\n\nICWS is a forum for researchers and industry practitioner to exchange\ninformation regarding advancements in the state of art research and practice\nof Web Services, to identify emerging research topics, and to define the\nfuture directions of Web Services computing. ICWS 2004 has special interest\nin papers that contribute to the convergence of Web Services, Grid\nComputing, e-Business and Autonomic Computing, or those that apply\ntechniques from one area to another. \n\nWeb services are network-based application components with services-oriented\narchitecture using standard interface description languages and uniform\ncommunication protocols. Typical industry solution areas of Web services are\nbusiness-to-business integration, business process integration and\nmanagement, content management, e-sourcing, composite Web services creation,\ndesign collaboration for computer engineering, multimedia communication,\ndigital TV, and interactive Web solutions. Currently, Grid computing has\nalso started to leverage Web services to define standard interfaces for\nBusiness Grid services and generic reusable Grid resources.\n\nAs the first academic conference in the field of Web services, the 2003\nFirst International Conference on Web Services (ICWS'03) was held at the\nMonte Carlo Resort in Las Vegas, Nevada, June 23 - 26, 2003, attracting\nhundreds of participants from 25 countries (USA, India, France, China, Hong\nKong, Taiwan, Singapore, Australia, Canada, UK, Sweden, Switzerland, The\nNetherlands, Germany, Japan, Italy, Korea, Thailand, Finland, Austria, New\nZealand, Poland, and Turkey). The second one is the 2003 International\nConference on Web Services - Europe (ICWS-Europe'03), held in Erfurt,\nGermany, September 23 - 24, 2003. ICWS'03 and ICWS-Europe'03 have proven to\nbe an excellent catalyst for research and collaboration. With the growing\ninterests of Web Services in both business and scientific information\nmanagement practice, we fully expect that ICWS 2004 will continue this\nsuccess.\n\nThe program of ICWS'04 will feature a variety of papers on fundamentals,\ninfrastructure, technology support, and business management for Web\nServices. \n\nSCOPE: Topics of interest include, but are not limited to, the following:\n\n- Mathematical Foundations of Web Services\n- Data Management Issues in Web Services\n- Web Services Architecture\n- Frameworks for building Web Service Applications \n- Composite Web Service Creation and Enabling Infrastructures  (e.g.,\nworkflow technology)\n- Web Services Modeling and Design\n- Web Services Discovery and Selection\n- Semantic Web, Ontologies, and Web Services\n- Dynamic Invocation Mechanisms for Web Services \n- Quality of Service for Web Services \n- UDDI and SOAP enhancements  \n- Web Services and Process Management\n- Trust, Security and Privacy in Web Services\n- Web Services Negotiation and Agreement\n- Scalability and Performance of Web Services\n- Web Services Standards and Technologies,\n- Autonomic Computing for Web Services Infrastructure\n- Autonomic Middleware and Toolkits for Monitoring and Management\n- Autonomic e-Business Integration and Collaboration\n- Wireless Web, Mobility, and Web Services\n- Web Service Based Grid Computing and Peer to Peer Computing \n- Business Grid Solution Architecture\n- Grid Architectures, Middleware and Toolkits\n- Grid Services Integration and Management \n- Economics and Pricing Models of Utility Computing\n- Web Services based Applications for e-Commerce\n- Multimedia Applications using Web Services\n- Economics of Web Services & Pricing Models\n- Resource management of Web Services\n- Solution Management for Web Services \n- Adoption of Web Services by Organizations\n- Case studies on Web Services-based Applications\n- Web Services Industrial\n- Business Process Integration and Management using Web Services \n- Impact of Web Services Architecture on Business Continuity\n- Changing Role of Information Technology Departments in Organizations\n- Contractual Issues between Provider and Consumer of Web Services\n- Version Management in Web services\n- Customization of Web Services\n- Software Reusability \n\n\nSUBMISSION OF PAPERS:\n\nProspective authors are invited to submit a draft paper of about 8-10 pages\nin IEEE Proceeding style (single space, two columns, font size of 10 to 12)\nin PDF or Word format via the Microsoft's CMT system for on-line submission\n(to be announced in ICWS 2004 website). The length of the Camera-Ready\npapers (if accepted) will be limited to 8 (IEEE style) pages. Papers must\nnot have been previously published or currently submitted for publication\nelsewhere. Each submission should add an additional cover page including:\ntitle of the paper, name, affiliation, postal address, E-mail address,\ntelephone number, and Fax number for each author. The cover page should also\ninclude the name of the author who will be presenting the paper (if\naccepted) and a maximum of 5 keywords, and whether the paper is submitted as\na student paper. \nAll accepted papers will be published in the conference proceedings in\nhardcopy and on-line version by IEEE Computer Society. The best papers\npresented at ICWS'2004 will be invited to submit to the International\nJournal of Web Services Research (JWSR), International Journal of Grid and\nUtility Computing, International Journal of Business Process Integration and\nManagement, and International Journal of Autonomic Computing. \nEVALUATION PROCESS:\n\nAll submissions will be evaluated for originality, significance, clarity,\nand soundness. Each paper will be refereed by at least three PC members in\nthe topical area. \nBEST STUDENT PAPER AWARDS:\n\nOne Best Paper award and 1-3 Best Student Paper Awards will be presented by\nICWS'2004. The first author of the best student papers should be full-time\nstudents. \n\n\nIMPORTANT DATES:\n\nJanuary 26, 2004 (Monday): Abstract Submission (optional) \nFeb. 2, 2004 (Monday): Submission Due\nMarch 19, 2004 (Friday): Notification of acceptance\nApril 16, 2004 (Friday): Camera-Ready copy & Author Pre-registration due\nJuly 6 - July 9, 2004: ICWS'04 International Conference on Web Services\n \n\nPROGRAM COMMITTEE CO-CHAIRS\n\nProf. Dr. Hemant Jain\nWisconsin Distinguished & \nTata Consultancy Services Professor \nSchool of Business Administration \nUniversity of Wisconsin- Milwaukee \nMilwaukee, WI 53201, USA\nPhone: (414)-229-4832\nFax: (414)-229-6957 \njain@uwm.edu\n\nProf. Dr. Ling Liu\nCollege of Computing \nGeorgia Institute of Technology \n801 Atlantic Drive, Atlanta \nGeorgia 30332-0280, USA \nPhone: (404) 3851139 \nFax: (404) 8949846\nlingliu@cc.gatech.edu \n\n\nPROGRAM COMMITTEE (Incomplete)\n\nKarl Aberer\nEPFL, Switzerland\nkarl.aberer@epfl.ch\n\nRoger S. Barga\nMicrosoft Research, USA\nbarga@microsoft.com\n\nAthman Bouguettaya        \nVirginia Tech, USA\nathman@cs.vt.edu\n\nElisa Bertino\nUniversity of Milano, Italy\nbertino@dico.unimi.it\n\nDavid Buttler\nLawrence Livermore National Laboratory, USA\nbuttler1@llnl.gov\n\nFabio Casati\nHewlett Packard Laboratories, USA\nfabio.casati@hp.com\n\nUgur Cetintemel\nBrown University, USA\nugur@cs.brown.edu\n\nMichael Champion\nSoftware AG and W3C Web Services Architecture Working Group, USA\nmike.champion@softwareag-usa.com\n\nBrian F. Cooper\nGeorgia Institute of Technology, USA\ncooperb@cc.gatech.edu\n\nIsabel Cruz \nUniversity of Illinois at Chicago, USA\nifc@cs.uic.edu\n\nAlok Choudhary \nNorthwestern University, USA\nchoudhar@ece.northwestern.edu\n\nJen-Yao Chung \nIBM T. J. Watson Research Center, USA\njychung@us.ibm.com\n\nAsuman Dogac\nMiddle East Technical University, Turkey\nasuman@srdc.metu.edu.tr\n\nDavid W Embley\nBirmingham Young University, USA\nembley@cs.byu.edu\n\nOpher Etzion\nIBM Research Laboratory in Haifa, Israel \nopher@il.ibm.com \n\nPeter Fankhauser\nFraunhofer IPSI, Germany\nfankhaus@ipsi.fraunhofer.de\n\nAvigdor Gal \nTechnion, Israel\navigal@ie.technion.ac.il\n\nWolfgang Gentzsch \nSun Microsystems, USA\nwolfgang.gentzsch@sun.com\n\nAmarnath Gupta\nUniversity of California, San Diego, USA\ngupta@sdsc.edu\n\nMarc N. Haines\nUniversity of Wisconsin-Milwaukee, USA\nmhaines@uwm.edu\n\nSumi Helal\nUniversity of Florida, USA\nhelal@cise.ufl.edu\n\nMichael N. Huhns\nUniversity of South Carolina, USA\nhuhns@sc.edu\n\nPatrick C. K. Hung\nCommonwealth Scientific and Industrial Research Organization (CSIRO),\nAustralia\npatrick.hung@csiro.au\n\nKyu-Young Whang\nKAIST, Korea\nkywhang@mozart.kaist.ac.kr\n\nMario Jeckle\nUniversity of Applied Sciences Furtwangen, Germany\njeckle@fh-furtwangen.de\n  \nVipul Kashyap\nNational Library of Medicine, USA\nkashyap@nlm.nih.gov \n\nDaniel S. Katz\nCalifornia Institute of Technology, USA\nDaniel.S.Katz@jpl.nasa.gov\n\nMartin Kersten\nCWI, The Netherlands\nmartin.kersten@cwi.nl\n\nMichael Kifer\nStony Brook University, USA\nkifer@cs.stonybrook.edu\n\nRoger King\nUniversity of Colorado at Boulder, USA\nroger@cs.colorado.edu\n\nHiro Kishimoto\nFujitsu Laboratories Ltd., USA\nhiro.kishimoto@jp.fujitsu.com\n\nManolis Koubarakis\nTUC, Greece\nmanolis@intelligence.tuc.gr\n\nEe-Peng Lim\nNanyang Technological University, Singapore\naseplim@ntu.edu.sg\n\nBertram Ludaescher \nUCSD Super Computing Center, USA\nludaesch@sdsc.edu\n\nDennis McLeod\nUniversity of Southern California, USA\nmcleod@usc.edu\n\nSanjay Madria\nUniversity of Missouri-Rolla, USA\nmadrias@umr.edu\n\nLeo Mark\nGeorgia Institute of Technology, USA\nleomark@cc.gatech.edu\n\nErich J. Neuhold\nFraunhofer IPSI, Germany\nneuhold@ipsi.fhg.de\n\nBeng Chin Ooi \nNational University of Singapore, Singapore \nooibc@comp.nus.edu.sg\n\nYannis Papakonstantinou\nUniversity of California, San Diego, USA\nyannis@cs.ucsd.edu\n\nThomas E. Potok\nOak Ridge National Lab (ORNL), USA\npotokte@ornl.gov\n\nCalton Pu\nGeorgia Institute of Technology, USA\ncalton@cc.gatech.edu\n\nArnon Rosenthal\nThe MITRE Corporation, USA\narnie@mitre.org\n\nMarcus A. Rothenberger\nUniversity of Wisconsin-Milwaukee, USA\nrothenb@uwm.edu\n\nAkhil Sahai \nHewlett Packard Laboratories, USA\nasahai@hpl.hp.com\n\nMing-Chien Shan\nHewlett Packard Laboratories, USA\nming-chien.shan@hp.com\n\nAmit Sheth \nUniversity of Georgia, USA\namit@cs.uga.edu\n\nMunindar P. Singh\nNorth Carolina State University, USA\nmpsingh@csc.ncsu.edu\n\nKatia P. Sycara\nCarnegie Mellon University, USA\nkatia@cs.cmu.edu\n\nIl-Yeol Song.\nDrexel University, USA\nsong@drexel.edu\n\nRudi Studer \nUniversity Karlsruhe, Germany\nstuder@aifb.uni-karlsruhe.de\n\nJeffrey J.P. Tsai, \nUniversity of Illinois at Chicago, USA\ntsai@cs.uic.edu\n\nGeorge K. Thiruvathukal\nLoyola University of Chicago, USA\ngkt@cs.luc.edu\n\nWerner Vogels\nCornell University, USA\nvogels@cs.cornell.edu\n\nKaladhar Voruganti\nIBM Almaden Research Lab, USA\nkaladhar@us.ibm.com\n\nClement Yu\nU. of Illinois at Chicago, USA\nyu@cs.uic.edu\n\nCarlo Zaniolo \nUniversity of California in Los Angeles, USA\nzaniolo@cs.ucla.edu\n\nXiaodong Zhang \nWilliam and Mary College, USA\nzhang@cs.wm.edu\n\nYanchun Zhang\nVictoria University, Australia\nyzhang@csm.vu.edu.au\n\nYanqing Zhang\nGeorgia State University, USA\nyzhang@cs.gsu.edu\n\nHuimin Zhao  \nUniversity of Wisconsin - Milwaukee, USA\nhzhao@uwm.edu\n\n\nCONFERENCE ORGANIZATION COMMITTEE\n\nGeneral Chair\n\nLiang-Jie (LJ) Zhang (Ph.D.) \nIBM T. J. Watson Research Center, USA\nzhanglj@us.ibm.com\n\n\nIndustrial Track Co-Chairs: \n\nSinisa Zimek \nSAP Labs, Inc., USA\nsinisa.zimek@sap.com \n\nRoger Barga \nMicrosoft Research, USA\nbarga@microsoft.com \n\n\nPanels Chair: \n\nCalton Pu\nGeorgia Institute of Technology, USA\ncalton@cc.gatech.edu\n\nTutorials Chairs: \nAbdelsalam (Sumi) Helal\nUniversity of Florida, USA\nhelal@cise.ufl.edu\n\n\nPoster Chair: \n\nMario Jeckle \nUniversity of Applied Sciences Furtwangen, Germany\njeckle@fh-furtwangen.de\n      \nGraciela Gonzalez \nSam Houston State University, USA\ncsc_ghg@shsu.edu\n\n\nDemo & Exhibits Chair: \n\nSimanta Mitra\nIowa State University, USA\nsmitra@iastate.edu\n\n\nPublication Chair: \n\nJen-Yao Chung\nIBM T. J. Watson Research Center, USA\njychung@us.ibm.com \n\n\nSponsor Chair:\n\nDavid B. Flaxer \nIBM T. J. Watson Research Center, USA\nflaxer@us.ibm.com\n\n\nLocal Arrangement Chair: \n\nKwei-Jay Lin \nUniversity of California, Irvine, USA\nklin@uci.edu\n\n\nPublicity Chairs: \n\nPatrick C. K. Hung\nCommonwealth Scientific and Industrial Research Organization (CSIRO),\nAustralia\npatrick.hung@csiro.au\n\nHaifei Li\nNyack College, USA\nhaifei.li@nyack.edu\n\nMinglu Li\nShanghai Jiaotong University, China\nli-ml@cs.sjtu.edu.cn\n\n\nCommunication Chair: \n\nCarolyn McGregor\nUniversity of Western Sydney, Australia\ncarolyn@cit.uws.edu.au\n\n\nICWS STEERING COMMITTEE\n\nEphraim Feig\nKintera Inc, USA\nefeig@kintera.com \n\nHemant Jain\nUniversity of Wisconsin- Milwaukee, USA\njain@uwm.edu\n\nMario Jeckle\nU. of Applied Sciences Furtwangen, Germany \nmario@jeckle.de \n\nFrank Leymann\nIBM Software Group, Germany\nley1@de.ibm.com\n\nStanley Su\nUniversity of Florida, USA\nsu@cise.ufl.edu\n\nJeffrey Tsai\nUniversity of Illinois at Chicago, USA\ntsai@cs.uic.edu \n \nLiang-Jie Zhang \nIBM T.J. Watson Research Center, USA\nzhanglj@us.ibm.com \n\nJ. Leon Zhao\nUniversity of Arizona, USA\nlzhao@bpa.arizona.edu\n\n\n\n", "id": "lists-017-6076671"}, {"subject": "Compact Policies and information los", "content": "Hello-\n\nI'd like to describe in a bit more detail an issue raised during the 1 Oct 2003\nspec call.  The discussion was captured in the minutes as follows:\n\n      4/ Giles: cookie is like a database identifier\n         Jeff: whether use is intended or not, one has to declare.\n        GH: doesn't have to be unique ID. It has the purpose to select\n        a bunch of records in a database.\n         Jeff: cases are sites with single sign-on etc and scope is not\n        always clear. Has to be clarified what happens with the\n        information, e.g. purpose.\n        Jeff: also when converting to compact policy, it looses\n        semantics and sounds more that the actual collection is.\n\n      Action: Giles: Write some paragraphs about linked data and\n      cookies.\n\n      Action: Jeff: Write some paragraphs describing the issue.\n\nMy observation was that is a common practice for sites to use a single sign-on\ncookie that can be linked to all of the personally identifiable information\nmaintained about the user.  As I understand the spec, the associated cookie\npolicy must cover any data that is linked via the cookie.  For some\norganizations, such a policy will likely contain many statements, to account\nfor the diversity of purposes, data categories, and recipients associated with\nthe various types of personally identifiable information being maintained.\n\nAs called out in section 4.5 of the spec, when transforming a full policy to a\ncompact policy, policy information may be lost.\n\n   \"The transformation of a P3P policy to a P3P compact policy may result in a\n   loss of descriptive policy information -- the compact policy may not contain\n   all of the policy information specified in the full P3P policy. The\n   information from the full policy that is discarded when building a compact\n   policy includes expiry, data group/data-schema elements, entity elements,\n   consequences elements, and disputes elements are reduced.\"\n\nIn addition to the losses pointed out above, the information that organizes\npurposes, categories, and recipients into meaningful statements is lost, as\nwell.  A full policy might disclose that online contact information may be\nshared with other-recipients unless the user opts-out but that financial\ninformation is only used internally.  Once transformed into a compact policy,\nhowever, the tie between the data category and who the information is shared\nwith is lost.  Perhaps my financial information will be shared unless I\nopt-out.  I don't suspect that I'm the first person to point this out, and\nperhaps this isn't an issue, given the intended usage of compact policies.  If\na user agent is only going to employ relatively simple rules around cookie\nhandling (e.g., \"any PII sharing without explicit consent is forbidden\"), then\nI suppose this level of granularity is sufficient.\n\nRegards,\nJeff Edelen\n\n\n\n\nAmerican Express made the following\n annotations on 10/14/2003 06:35:43 PM\n------------------------------------------------------------------------------\n******************************************************************************\n\n     \"This message and any attachments are solely for the intended recipient and may contain confidential or privileged information. If you are not the intended recipient, any disclosure, copying, use, or distribution of the information included in this message and any attachments is prohibited.  If you have received this communication in error, please notify us by reply e-mail and immediately and permanently delete this message and any attachments.  Thank you.\"\n\n******************************************************************************\n\n\n==============================================================================\n\n\n\n", "id": "lists-017-6119859"}, {"subject": "Cookie Linkin", "content": "Linked data and cookies (action item)\n\nCookies can contain a maximum of 4kb of data and must be transmitted across\nthe network twice before they can be used. For this reason, cookies tend to\nstore only a number which links to a value in a database. Data about a user\nis stored in a database and that record is given a number (a unique key).\nOnly this number is stored in the cookie on the user's computer. When the\nuser revisits the site which set the cookie, that site can immediately have\naccess to a potentially unlimited amount of information about the user\nsimply by looking up the number in the database in which the number is a\nkey. Linkability may be direct or indirect. For example a key stored in a\ncookie may not link to a record giving the user's name, but the record may\ncontain the user's IP address, which, can potentially be linked to another\ndatabase to discover the user's name. \n\nWith enough effort, data mining techniques may be applied to link even\nseemingly highly anonymised data with a cookie value. P3P applies the\nprinciple of proportionality to such linkability.  The specification of the\ndata and purposes covered by cookie should be thought of in terms of the\nanalysis which might reasonably be carried out on such a cookie to achieve\nthe stated purpose. For example if a cookie is set to track criminals'\npersonal data then it is reasonable that a considerable effort might be put\ninto database analysis. The cookie should therefore be said applying to\npersonally identifiable data even if the data is actually hashed in the\ndatabase. If on the other hand, the cookie is set in order to track a\nsession and data is stored in the database but anonymised by hashing, then\nthere is no need to state that the data is identifiable. This type of\nanonymization is in theory not secure because hashes have a 1-1\ncorrespondence with ip addresses for example so by hashing all possible ip\naddresses, you can trace the original ip address. However extending the\ndefinition of linkability to this extent is neither practical nor\nreasonable.\n\n\n\n", "id": "lists-017-6130651"}, {"subject": "Cookie linking v", "content": "Here is an updated version based on some comments I received\n\nLinked data and cookies (action item)\n\nCookies can contain a maximum of 4kb of data and must be transmitted across\nthe network twice before they can be used. For this reason, cookies tend to\nstore only a number (or unique key) which links to a value in a database.\nData about a user is stored in a database and that record is given a number\n(a unique key). Only this number is stored in the cookie on the user's\ncomputer. When the user revisits the site which set the cookie, that site\ncan immediately have access to a potentially unlimited amount of information\nabout the user simply by looking up the number in the database in which the\nnumber is a key. Linkability may be direct or indirect. For example a key\nstored in one cookie may not link directly to a user's name. Suppose a site\nsets two cookies. One cookie might link to a record of the user's street\nname and number and the other to the user's home town. By using the referrer\nIP, these two cookies be linked together to give a unique address and\nthrough another database, the user's name.\n\nWith enough effort, data mining techniques may be applied to link even\nseemingly highly anonymised data with a cookie value. P3P applies the\nprinciple of proportionality to such linkability.  The specification of the\ndata and purposes covered by cookie should be thought of in terms of the\nanalysis which might reasonably be carried out on such a cookie to achieve\nthe stated purpose. For example if a cookie is set to track criminals'\npersonal data then it is reasonable that a considerable effort might be put\ninto database analysis. The cookie should therefore be said applying to\npersonally identifiable data even if the data is actually hashed in the\ndatabase. If on the other hand, the cookie is set in order to track a\nsession and data is stored in the database but anonymised by hashing, then\nthere is no need to state that the data is identifiable. This type of\nanonymization is in theory not secure because hashes have a 1-1\ncorrespondence with ip addresses for example so by hashing all possible ip\naddresses, you can trace the original ip address. However extending the\ndefinition of linkability to this extent is neither practical nor\nreasonable.\n\nThird party cookies are cookies which are set by a domain other than the\npage being viewed. This is done through embedded images and can even occur\nin emails and applications which use web services, such as music players.\nWhile normally the information stored in one domain's cookie cannot be\naccessed by another domain, third party cookies bypass this mechanism by\nplacing the same third party image in different domain's pages. This allows\ntracking of users across different domains. The intention to carry out such\ntracking activities through linking cookie keys across different domains\nshould also be declared\n\n\n\n", "id": "lists-017-6139156"}, {"subject": "[Agent/Domain] revised and new domain relationship proposals (&quot;sa me-entity&quot; and &quot;agentof&quot;", "content": "Attached are two proposals concerning domain relationships. \n\nThe first proposal, which covers \"same entity\" domain relationships, is a\nrevision of the proposal I sent out previously. If you are familiar with the\nprevious version, the only difference is the removal the ability to\nreference full URIs in the POLICY-REF INCLUDE. This part of the proposal was\nreally only an optimization, and apparently the there was a long discussion\nconcerning full URIs in policy reference files for the 1.0 spec, which we\ndon't need to rehash.\n\nThe second proposal, which covers \"agent of\" domain relationships, is new,\nbut builds on the mechanisms described in the first proposal.\n\nPlease review both proposals at your earliest opportunity and discuss your\nquestions/concerns on the mailing list. I may organize a task force\nconference call to discuss them in greater detail, so please let me know via\ndirect email if you'd like to be part of that discussion.\n\nI apologize for the delay in getting these proposals out to the group.\n\nJack Humphrey\nCoremetrics\n\n\n\n\n\napplication/octet-stream attachment: same_entity_v2.pdf\n\napplication/octet-stream attachment: agent_v1.pdf\n\n\n\n\n", "id": "lists-017-6148291"}, {"subject": "Courts &amp; Law subelement", "content": "I propose the following spec changes to deal with the COURTS and LAW\nsubelements of DISPUTES:\n\nCOURTS, CURRENT:  Individual may file a legal complaint against the Web\nsite.\n\nCOURTS, PROPOSED:  The authority referenced in the description may offer\nrecourse for disputes arising in connection with the privacy statement.\n\nLAW, CURRENT:  Disputes arising in connection with the privacy statement\nwill be resolved in accordance with the law referenced in the description.\n\nLAW, PROPOSED:  The laws or regulations referenced in the description may\nprovide recourse procedures and remedies for disputes arising in connection\nwith the privacy statement.\n\n(I used the term \"Web site,\" but I think we discussed standardizing\nreferences to the entity posting the statement.)\n\nDave Stampley\nv.  937-485-0424\nf.  937-485-0973\ndavid_stampley@reyrey.com\n\n-----Original Message-----\nFrom: Rigo Wenning [mailto:rigo@w3.org] \nSent: Friday, October 10, 2003 12:11 PM\nTo: public-p3p-spec\nSubject: AGENDA: 17 Oct P3P spec call\n\n\n\nThe next P3P specification group conference call will be on\nWednesday, October 17, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n   - [P3P beyond HTTP - Patrick Hung]\n   - Compact policies - Brooks Dobbs\n   - Article 10 vocabulary issues - Giles Hogben\n   - Agent and domain relationships - Jack Humphrey\n   - Consent choices - Matthias Schunter\n   - Converting P3P data schema to XML schema - Giles Hogben\n\n2. P3P in WSDL, next steps\n   compare thread at\n\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0006.html\n\n3. P3P Dataschema in XML Schema\n   please review\n\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0005.html\n\n4. Discussion of the court element\n   comments at\n\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0001.html\n\n5. Continued work on P3P 1.0 element definitions and translations\n   http://www.w3.org/P3P/2003/p3p-translation.htm\n\n5. Set date for next call (Oct. 29)\n\n\n\n", "id": "lists-017-6156974"}, {"subject": "P3P Beyond HTTP Task Force  Web Services Publish Find Bind Model  + Privac", "content": "Hi,\n\nHere is a very rough diagram that is trying to depict the scenario.\nPlease feel free to comment and give suggestion.\n\nMany thanks,\n\nPatrick.  <<Publish-Find-Bind-Model+Privacy.gif>> \n\n\n\n\n\n\n\n\n\n", "id": "lists-017-6166630"}, {"subject": "Minutes of 15 Oct Cal", "content": "Present: \nJack Humphrey\nRigo Wenning\nPatrick Hung\nGiles Hogben\nDavid Stampley\nBrooks Dobbs\n\nP3P beyond HTTP:\nPatrick reported from the new dynamics developing around the cooperation\nwith WSDL and SOAP-Groups.  Much feedback from WSDL Group. Hope to\nattract more people from the Soap group. Hope to have the new version\nout soon. Should it bit a stand-alone document?\n\nAction Rigo: Provide feedback on the Draft request for comment to\nWSDL and SOAP\n\n2/ Compact policies\nMuch of the stuff dependend on Jeremy Epling and Brian Zwit.\nThere was not much correspondence so the TF is stalled. We discussed\nfurther steps and the actual roadblocks. The performance testing is\nstill outstanding. With policy prefetched and acceptable performance, we\nmight get rid of the compact format and the question about accuracy of\nthe compact format would disappear. But if performance reports are bad,\nwe have to think about the grouping mechanism and the resulting\nsemantics. Brooks and Giles added, that even a grouping mechanism can\nhave some performance impact and that this should be also measured\nagainst the full policy approach.\n\nWe agreed to defer the decision whether we go on with grouping\nwithout waiting for performance report by 3-4 weeks\n\nAction: Rigo: Try to contact Jeremy\n\nXML Data-Schema:\n\nGiles presented the Schema and explained. \nIssues: Do we do DTD?\nDuplicates in name and business\nHow can we make it compatible to avoid breaking\nGH: New Schema will have to use new mechansims. \n    Write policies in new format, publish old format\nUse extension - mechanism\n\nAction: Rigo and Giles: numbering and example\n        Arrange meeting with both and Massimo in european time\n========================================================\n\nDiscussion of the court element\n\nAgreement on the proposed language of the court element:\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0021.html\n\nStill discussion on law:\nBD: want to have time to talk back to our company\n\nGH: Discussions about 'may'. In our opinion or 'we believe'. \nDS: Explanations, agrees to 'we believe'.\n\nSuggested new wording: \nSpecifaction-Definition: \nThe Entity making the statement believes that the authority\nreferenced in the description offers recourse for disputes\narising in connection with the privacy statement.\n\nSuggested wording for user-strings\n\nWe believe that the authority referenced in the description\noffers recourse for disputes arising in connection with the\nprivacy statement.\n\nSpecification Def: \nThe Entity making the statement believes that laws or regulations\nreferenced in the description provide recourse procedures and\nremedies for disputes arising in connection with the privacy\nstatement.\n\nUser interface string:\nWe believe that laws or regulations\nreferenced in the description provide recourse and\nremedies for disputes arising in connection with the privacy\nstatement.\n\nAction Rigo: Introduce change to Bugzilla and look up correct\ndefinition for in connection with the privacy\nstatement.\n\nNext meeting: \n\nWednesday 22 October 2003\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-6173947"}, {"subject": "Summary of Comments/Suggestions to the P3P Beyond HTTP Task Force  Working Grou", "content": "I am trying to summarize the comments/suggestions to the current version of\nworking group:\n\n(1) Apply a different privacy restriction on different level of data in\nWSDL. The Privacy element \n    applies to the transaction from the Web services consumer to the Web\nservice and cannot \n    be restrictied to a particular set of data. Two possible solutions are:\nXML Schema annotations\n    and XML extensions.\n(2) Remove the rel='p3pv1' attribute at all because of using namespaces for\nversioning.\n(3) Require defining an element included in the WSDL to indicate the WSDL\nprocessor must follow \n     the rules of P3P: <my:Privacy wsdl:required=true'/>\n(4) Define the privacy policy by both reference and inclusion.\n(5) Bi-lateral privacy privacy and preferences: The current version only\nindicates that the statements \n     are only applicable to the information received by the service, and not\nthe client interacting with\n     the service.\n(6) The extensibility model of WSDL allows to put P3P elements and\nattributes in all sections of the\n     description. It should include P3P POLICY elements in the WSDL at the\ninterface, operation, or \n     service level.\n(7) Apply/reference more than one policy in a WSDL. In the first cut, there\nshould have a logical AND \n    in privacy policies described in different levels.\n(8) WSDL, per decision on 20030703, dropped its extensibility using XML\nSchema. This includes the \n     wsdl:globalExt definition. Remove the\nsubstitutionGroup='wsdl:globalExt' declaration from the \n     definition of the privacy element.\n(9) Have a mandatory soap extension containing a policy; the semantics of\nthe extension is: either \n    your policy is compatible with this one, or you must not process the\nmessage. Section 4.5 needs \n    to be clarified\n\nSpecial thanks to the contributors: Rigo, Hugo and Philippe!\n\nI am looking froward to hear from WSDL and SOAP working group.\n\nThanks,\n\nPatrick\n\n\n\n", "id": "lists-017-6183806"}, {"subject": "Agenda 22 October cal", "content": "The next P3P specification group conference call will be on\nWednesday, October 22, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1/ Discussion of P3P 1.0 element definitions and translations: the\nremaining items\nsee comments in green at http://www.w3.org/P3P/2003/p3p-translation.htm\n\n2/ domain relationship proposal\nPlease review the Draft and comment on the list:\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0020.html\n\n3/ compact policies\nDo we invite new people into a TF or do we work on that task in the\nwhole WG?\n\n4/ Next meeting\n (5 November?)\n\n\n\n", "id": "lists-017-6192665"}, {"subject": "Minutes of the 22 Oct 2003 cal", "content": "Minutes of the P3P Spec WG call of October 22, 2003\n\nPresent:\nBrooks Dobbs\nJeff Edelen\nRigo Wenning\nJack Humphrey\n\n\n1/ Discussion of P3P 1.0 element definitions and translations: the\nremaining items\nsee comments in green at http://www.w3.org/P3P/2003/p3p-translation.htm\n\nNo discussion in absence of Dave Stampley.\n\n2/ domain relationship proposal\nPlease review the Draft and comment on the list:\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Oct/0020.html\n\nJack Humphrey presents his proposal. Basically he suggests to\nhave two declarations from two hosts that have to match each\nother, which would need control on both hosts thus taking away\nthe argument of hacking that prevented us from using full URI in\npolicy references-files.\n\nBrooks: Sees known-hosts as covering a whole domain that one\ncould even not do in the first party content. \n\n..Discussion\n\nJH: makes no claims about policy, just about known hosts\n\nBrooks: Every time on replay cookie, user-agent would have to\ncheck whether this host is on the known-hosts list.\n\nBrooks explains further.\n\nJH: Cookie by image-request in the context of page on a different\ndomain, but same corporation (group). Cookie would be rejected if\nno third parties allowed by user. Even though they are not same\ndomain, the cookie is replayed. \n\nBrooks: Notion of identity in spam-fighting and start discussion\nwhat identity means. So forinstance and example are not the same\nentity. You get into the multinational legal challenges.\n\nJH: Problems are more in implementation and how to improve. \n\nJeff: Same entity is owned by same company. this is not the most\ncommon example. \n\nACTION: Brooks write down concerns to mailing-list\nAction: Rigo check relationship between cookie expiry and \n        PRF expiry. \n\nA big discussion about the usefulness of approach to declare\nentity relations and agent relations started. In fact it is \n_not_ the goal of the same-entity declaration to say that the\ndeclaring site is not a third party anymore. The concept of third\nparty touches on the concept of identity, which is difficult in\nitself. In fact, the issue of the third-party stuff is, that the\ncookie set on one host and replayed to another host touches on\nthe question of policy control on cookie-replay. This is actually\nnot done for performance reasons. But with an entity or agent\nrelationsship, the user agent would know the policy already and\ncould do a very quick check without further roundtrip. This would\nremove the need for compact policies.\n\nConclusion: We need further discussion on the mailing-list.\nBrooks will start it with his mails on his concerns.\n\n\n3/ compact policies\nDo we invite new people into a TF or do we work on that task in the\nwhole WG?\n\nWe haven't discussed this issue as point 2 took all the time.\n\n4/ Next meeting\n\nNext meeting will be 5 November 2003\n\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-6199730"}, {"subject": "Concerns re: SameEntity proposa", "content": "Though I have enormous sympathy for the issue we are trying to resolve here.\nI have some concerns with the mechanism suggested.\n\n \n\nThey are in no particular order:\n\n1)       We need be careful between providing tools on which to make policy\nand making policy itself.  While it may be a useful tool to have the ability\nto state that collection covered by separate PRFs  is under the control of\nthe same entity, ultimately it is up to the UAs to decide how they want to\nimplement these tools.\n\n2)       We use the term entity (and later in the agent relationship\nproposal - \"agent\") without providing sufficient guidance on what this\nmeans.  Rigo suggests there may be ways around this but I think they would\nbe unclear at best and difficult to explain to the end user.  This suggests\nto me that point 1) may mean that UAs don't act on this tool if they had it.\n\n3)       I think that there is an issue in that entity is today defined at\nthe policy level.  A PRF for a host can reference 2 distinct policies each\nof 2 distinct entities (data controllers) - how then can there be meaning to\nsay at the PRF level this entity is the same as anything else?  The same as\nwhich of the 2?\n\n4)       There would need to be a mechanism to expire same entity\nrelationship.  This may be handled through the expiry in policy files but\nthere is currently no such mechanism for CPs\n\n5)       Headers are limited practically by the number of same hosts that\nthey can declare.  Also declaring multiple \"same-entity\" relationships would\npresumably require a validation against each full policy prior to accepting\nthe accuracy of the header declaration.  This is somewhat illogical, as, IF\nwe where to accept the performance hit of policy prefetching, then we would\nhave no need for CPs!  Jack rightly points out that we may only need to\nvalidate against the PRF and not the policy - but I think that I may have\nbrought that into question with point 3).\n\n6)       Again on the topic of CPs, once a same entity relationship has been\nestablished between cookie (set by A) and site B from which an asset\nappears, how they can a same entity relationship be established from a\nsubsequent replay on site C (provided that PRFs or policies) for all these\nsites do indeed declare each other as same entity?\n\n \n\nSorry to be so elaborate here.  Again I am completely sympathetic - just not\nsure we are there yet or if I see a clear way through the issues.\n\n \n\nThanks, \n\nBrooks \n\n \n\n \n\nBrooks Dobbs\n\nDirector of Privacy Technology\n\nDoubleClick, Inc.\n\n \n\nemail: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net> \n\noffice: 404.995.6634\n\n \n\n\n\n", "id": "lists-017-6209299"}, {"subject": "RE: Grouping Statements Proposa", "content": "I did some more minor revisions. I added a description of the consent \nattribute.\n\nRegards,\n  matthias\n\n\nAt 12:34 PM 8/30/2003 +0200, Matthias Schunter wrote:\n>Hi Folks,\n>\n>I reviewed the spec and made the following changes:\n>\n>STATEMENTS:\n>- I deleted the requirement that all statements must have a group\n>- I added some text describing an example\n>- I added Jerry as an author\n>\n>GROUP-DEFS:\n>- The consent is now \"opt-in\", \"opt-out\", \"required\"\n>   The first three must be 'inherited' by all statements in this group.\n>- I made it explicit that <Recipient ours> and <purpose current> cannot be \n>used\n>   inside statements that are in a group that is declared opt-in or opt-out.\n>\n>QUESTIONS:\n>- I did now allow one statement to belong to multiple groups. I feel that \n>this would\n>   be too confusing.\n>- I thought about enabling groups that define \"consent='mixed'\" which \n>enables to group statements that have a mixture of opt-in, opt-out, and \n>required. But I felt that this is not useful.\n>\n>Regards,\n>  matthias\n>\n>\n>\n>At 02:34 PM 8/28/2003 -0700, Jeremy Epling wrote:\n>>Attached is my first try at modifying Matthias's proposal to incorporate\n>>mine.\n>>\n>>Feedback is welcomed,\n>>\n>>Jeremy\n>>\n>>-----Original Message-----\n>>From: public-p3p-spec-request@w3.org\n>>[mailto:public-p3p-spec-request@w3.org] On Behalf Of Jeremy Epling\n>>Sent: Thursday, August 28, 2003 12:40 PM\n>>To: Matthias Schunter; Lorrie Cranor\n>>Cc: public-p3p-spec@w3.org\n>>Subject: RE: Grouping Statements Proposal\n>>\n>>\n>>I think that these could just be one proposal once the paradigms are\n>>combined.\n>>\n>>Can we just deprecate the opt-in, opt-out, and required attributes and\n>>say that if used the agent with take precedence with the consent tag.\n>>\n>>Jeremy\n>>\n>>-----Original Message-----\n>>From: Matthias Schunter [mailto:mts@zurich.ibm.com]\n>>Sent: Monday, August 11, 2003 6:13 AM\n>>To: Lorrie Cranor; Jeremy Epling\n>>Cc: public-p3p-spec@w3.org\n>>Subject: Re: Grouping Statements Proposal\n>>\n>>Hi!\n>>\n>>The proposal looks good. Once Jerry contacts me, I'll work with him to\n>>resolve the remaining issues. Some initial ideas/remarks:\n>>- the opt-in or opt-in elements inside all elements of an opt-in/out-out\n>>\n>>group where included\n>>    to preserve backward compatibility of the semantics.\n>>- The issue of the OURS/CURRENT may be resolved by defining that they\n>>cannot be included in an\n>>    opt-in/opt-out group.\n>>- Does it makes sense to use \"required\" instead of \"no-group\" or do you\n>>envision that with\n>>    consent=\"no-group\", one can nevertheless have opt-in's and out's\n>>inside?\n>>\n>>Regards,\n>>   matthias\n>>\n>>\n>>\n>>\n>>At 11:58 AM 8/6/2003 -0400, Lorrie Cranor wrote:\n>>\n>> >We discussed  this on today's call, minutes should be forthcoming. My\n>> >quick summary is:\n>> >\n>> >- combining these two group concepts probably makes sense\n>> >- we probably want an extension that looks something like the following\n>>\n>> >that can be inserted into all statement's that belong to a group:\n>> >\n>> ><STATEMENT>\n>> ><EXTENSION>\n>> >   <STATEMENT-GROUP id = \"fflyer\" />\n>> ></EXTENSION>\n>> >. . .\n>> ></STATEMENT>\n>> >\n>> >Then somewhere else in the policy\n>> ><EXTENSION\n>> >   <STATEMENT-GROUP-DEF id=\"fflyer\"\n>> >   short-description=\"Frequent Flyer Club\"\n>> >   consent = \"opt-in\" />\n>> ></EXTENSION>\n>> >\n>> >Some groups of statements might not be consent groups, in which case\n>>they\n>> >might use an attribute like consent = \"no-group\" (which might be the\n>>default).\n>> >\n>> >There are also some concerns about consent group that need to be worked\n>>\n>> >out. In Mathias' proposal it says that all PURPOSE and RECIPIENT\n>>elements\n>> >in a group have to have the same required attribute. But ours and\n>>current\n>> >are special cases that don't have this attribute. This needs to be\n>> >accounted for (the example in Mathias' draft is actually incorrect\n>>because\n>> >of this). Also we need to be clear on how to handle errors. What if\n>> >someone uses consent group but then uses different required attributes\n>> >(which is incorrect)? Does that invalidate the policy? Perhaps if that\n>> >happens the user agent should treat it as if it is consent = \"no-group\"\n>>?\n>> >\n>> >In any case, Jeremy is going to put together a more specific proposal\n>>on\n>> >this grouping. Mathias, it would be great if you could work with him on\n>>\n>> >the consent aspect.\n>> >\n>> >Lorrie\n>> >\n>> >\n>> >On Wednesday, July 30, 2003, at 02:53  AM, Matthias Schunter wrote:\n>> >\n>> >>\n>> >>Hi Jeremy,\n>> >>\n>> >>thanks for your design. I feel that grouping statements is a good\n>>idea.\n>> >>\n>> >>The actual syntax for grouping is elaborated in our earlier draft on\n>> >>consent choices:\n>> >>  http://www.w3.org/P3P/2003/05-cc-changes-to-P3P.html\n>> >>\n>> >>I feel that grouping statements is a good idea for multiple purposes.\n>> >>Therefore, I feel that we should have a general group mechanism where\n>> >>each group should have multiple properties:\n>> >>- opt-in opt-out or always (from consent choices)\n>> >>   syntactically this can be implicit: either all statements are\n>> >> always/opt-in, or opt-out.\n>> >>- target (something specifying whether it's the ebay or amazon part)\n>> >>   The target is something that might be useful to add to your\n>>proposal.\n>> >>   I don't know how to express this in a nice syntax.\n>> >>\n>> >>Why don't we merge both proposals into a \"grouping statements\"\n>>proposal?\n>> >>\n>> >>Regards,\n>> >>\n>> >>matthias\n>> >>\n>> >>\n>> >>\n>> >>At 07:00 PM 7/29/2003 -0700, Jeremy Epling wrote:\n>> >>\n>> >>>Below are the basics of my proposal for statement grouping.\n>> >>>\n>> >>>\n>> >>>\n>> >>>Problems\n>> >>>    * Policies are not relevant to how a user interacts with the site\n>> >>>        * Users don t know what part of a P3P policy applies to them\n>>and\n>> >>> there activities on a site\n>> >>>        * Users understand scenarios of how they interact with a site\n>>\n>> >>> better than a series of statements related to a feature of the site\n>> >>>    * Policy authors have to make highest common denominate policies\n>> >>> that could look more privacy impacting than they are for most users\n>> >>>\n>> >>>\n>> >>>Goals\n>> >>>    * Provide a method for showing the sections of the P3P policy\n>>that\n>> >>> apply to how a user interacts with the site/service\n>> >>>    * Allow an easy way for policy authors to describe what sections\n>>of\n>> >>> their P3P policy apply to different user interaction with their\n>>site/service\n>> >>>\n>> >>>\n>> >>>Scenarios\n>> >>>    * User browses to ebay and views the P3P policy. They are able to\n>>\n>> >>> skip to the buyer section of the P3P policy since that is what\n>>applies to them.\n>> >>>    * User browses to amazon and views the P3P policy. The can see\n>>that\n>> >>> since they are not logged in less information is collected about\n>>them.\n>> >>>\n>> >>>\n>> >>>Design\n>> >>>\n>> >>>\n>> >>>\n>> >>>The P3P author decides the name of the statement group which is used\n>>in\n>> >>>the display of the agent when it translates the nodes to natural\n>>language.\n>> >>>\n>> >>>\n>> >>>\n>> >>><Statement>\n>> >>>\n>> >>>             <extention>\n>> >>>\n>> >>>                         <grouping-id>Member</grouping-id>\n>> >>>\n>> >>>             </extention>\n>> >>>\n>> >>><statement>\n>> >>>\n>> >>>\n>> >>>\n>> >>>Issues\n>> >>>    * Do agents now show conflicts per grouping?\n>> >>>\n>> >>>\n>> >>>Jeremy Epling\n>> >>>Windows - Privacy and Trust UX\n>> >>>\n>> >>><BLOCKED::>wpihelp - where to go for all your privacy questions\n>> >>>\n>> >>\n>> >>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>> >>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>> >>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>> >>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>> >\n>>\n>>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>>Fax +41-1-724 8953; More info at www.semper.org/sirene\n>>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n>>\n>>\n>>\n>\n>\n>\n>-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\n>IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n>Fax +41-1-724-8953; More info at www.semper.org/sirene\n>PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724-8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-6255834"}, {"subject": "AGENDA: 3 Sept. P3P spec cal", "content": "[sorry the agenda is so late in going out for this call... I had jury \nduty and didn't get out of court until late in the day... but \nultimately they didn't really want me on a jury, so I will be at your \nservice to chair the wg call and continue to pester all of you, for at \nleast a few more days....]\n\nThe next P3P specification group conference call will be on\nWednesday, September 3, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - [P3P beyond HTTP - Patrick Hung]\n    - User agent behavior - Lorrie Cranor\n    - Compact policies - Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Signed P3P policies  - Giles Hogben\n\n2. Discussion of Ari's revised identified/identifiable/link\n    clarification draft.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0004.html\n\n3. Discuss revised consent/grouping proposal\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0039.html\n\n4. Discussion of disputes definition issues -- see\n    comments in green at http://www.w3.org/P3P/2003/p3p-translation.htm\n\n5. Discuss performance issues (raised by Jeremy)\nNEED PERFORMANCE DOCUMENT BEFORE CALL\n\n6. Set date for next call (Sept 10?)\n\n\n\n", "id": "lists-017-6275667"}, {"subject": "[Agent/Domain] sameentity domain relationship proposal comment", "content": "Attached is the proposal I sent out in July for domain relationships. In the\nJuly 16 working group conference call (which I missed), this proposal was\ndiscussed by the attendees (Lorrie Cranor, Rigo Wenning, Brooks Dobbs, Rob\nHorn, Patrick Hung, Joseph Reagle). Here are the notes from the minutes\n(taken by Lorrie, I believe) with some belated responses/questions from me:\n\n> There were some questions about the goals of this proposal. People \n> thought it was useful for companies to be able to declare that all of \n> their multiple domains are owned by a single company and comply with \n> the same policy, but there was less interest in being able to declare \n> that companies belong to an ad network. The reason browsers are \n> treating these as third party cookies is that is how consumers seem to \n> want to see them treated.\n\nI see this point. This proposal actually only addresses declaring that\nmultiple domains belong to the same company. It does not attempt to address\nthe agent/ad network type of relationships. I will make that clear in my\nupcoming proposed specification changes.\n\n> People saw some potential uses for the idea of the KNOWN-HOSTS element \n> (although it needs to be expressed using the extension mechanism). \n\nI'm glad this idea went over well. Does anyone remember what uses (other\nthan those outlined in the proposal) were discussed?\n\n> There was less enthusiasm for allowing INCLUDE and EXCLUDE to include \n> host name. That substantially complicates parsing and caching issues \n> without bringing obvious advantages. \n\nI suppose that I was trying to create an optimization for site developers\nand user agents. In my example on page 3, the idea is that, while loading a\npage from example.com, the user agent wouldn't have to fetch/evaluate the\npolicy reference file and policy for forinstance.com if the context of the\nforinstance request matched \"*.forinstance.com/customer/*\". I can see how\nthat might add too much complexity, so unless anyone feels strongly that the\noptimization might be worthwhile, I'll remove it.\n\n> There was a recognition that the CP aspect of this proposal was most\n> important for practical reasons, and yet it seemed not to scale well\n> in the third-party  ad network context.\n\nAgain, this proposal does not try to address agents/ad networks. In thinking\nabout how to potentially apply the same approach to those situations, I will\nconsider scalability concerns. \n\nI actually think that scalability can be addressed by implementations only\nincluding the relevant headers based on the context of the request. This\napproach would be recommended and will be elaborated upon in the agent\nrelationship proposal.\n\nThanks!\n\nJack Humphrey\nCoremetrics\n\n\n\n\n\napplication/octet-stream attachment: domrelprop1.pdf\n\n\n\n\n", "id": "lists-017-6284014"}, {"subject": "[Bug 167] explanation of identified, identifiable, and linke", "content": "Final Version with Rigo's suggested changes -- 2 weeks to review (Sept. 17)\n\n\n\n------\n\nIdentity Definitions in the P3P Specification\n\nIn privacy regulations, guidelines and papers about privacy a variety \nof terms are used to describe data that identifies an individual to \nvarying degrees.\n\nThe European Union Directive defines \"an identifiable person\" as \"one \nwho can be identified, directly or indirectly, in particular by \nreference to an identification number or to one or more factors \nspecific to his physical, physiological, mental, economic, cultural \nor social identity.\"  The Directive also states that in determining \nwhether a person is identifiable \"account should be taken of all the \nmeans likely reasonably to be used either by the controller or by any \nother person to identify the said person; whereas the principles of \nprotection shall not apply to data rendered anonymous in such a way \nthat the data subject is no longer identifiable.\"\n\nIn Australia, \"personal information\" is information about an \nindividual who can be identified, or whose identity could be \nreasonably ascertained.\"  In Canada \"personal information\" means \ninformation about an \"identifiable\" individual. In the United States, \ndifferent sectors have different standards for identifiability of \ndata. Similarly, in many other policy documents, terms such as \n\"personally identifiable information (PII)\" are often not defined or \nthe cause for heated debate.\n\nThe P3P Specification Working Group has taken the view point that \nmost information referring to an individual is \"identifiable\" in some \nway.  As with other important areas of the specification, the goal of \nthe working group was to allow for a wide variety of understandings \nof identity in order to allow data collectors to best express their \npolicy and users to make choices based on a definition of identity \ninformation that is important to them. (1)\n\n\n\"Identified\" Data\n\nThe most common term in the specification is \"identified data\" and \nfocuses on whether a service knows the data subject's identity.\n\n\"Identified data\" is information that in a record or profile and can \nreasonably be tied to an individual.  Admittedly, this is a somewhat \nsubjective standard.  For example, a data collector storing Internet \nProtocol (IP) addresses  (which can be created dynamically or could \nbe static and therefore tied to a particular computer used by a \nsingle individual) should consider the IP address \"identified data\" \nonly when this data is added to the record or profile of a specific \nindividual.  In the more common case, where data collectors use IP \naddressing information in the aggregate or make no attempt to tie the \nIP address to a specified individual or computer over a long period \nof time, IP addresses are not considered identified even though it is \npossible for someone (eg, law enforcement agents with proper subpoena \npowers) to identify the individual based on the stored data.\n\nAs mentioned above, in the P3P context, any data that can be used \nreasonably by a data controller or any other person to identify an \nindividual is considered to be identifiable data. The P3P \nspecification uses the term \"identified\" to describe a subset of this \ndata that can be reasonably be used by a data collector *without \nassistance from other parties* to identify an individual.\n\n\"Non-Identifiable\" and \"Linked\" Data\n\nThe working group also felt that data collectors should be able \nacknowledge when they make specific attempts to anonymize information.\n\nThe term \"non-identifiable\" data refers to efforts made specifically \nto de-identify data.  For example, a data collector collecting and \nstoring IP addresses but not using them should NOT call this data \n\"non-identifiable\" even in the common case where they have no plans \nto identify an actual individual or computer. However, if a Web site \ncollects IP addresses, but actively deletes all but the last four \ndigits of this information in order to determine short term use, but \ninsure that a particular individual or computer cannot be \nconsistently identified, then the data collector can and should call \nthis information \"non-identifiable.\"  Also, non-identifiable can be \nused in cases where no information is being collected at all.  Since \nmost Web servers are designed to keep Web logs for maintenance, this \nwould most likely mean that the data collector has taken specific \nefforts to ensure the anonymity of users.\n\nUnder the above definitions, a lot of information could be \n\"identifiable\" (not specifically made anonymous), but not \n\"identified\" (reasonably able to be tied to an individual or \ncomputer).\n\nSimilarly, the term \"linked\" refers to how information is being used \nin connection with a cookie. All data in a cookie or linked to a \nparticular user must be disclosed in the cookie's policy. Using the \nterminology above, if the data collector collects \"identifiable\" \ninformation about the user it is generally \"linked\" data. For \nexample, if the data collector stores a login name in a file \nassociated with a persistent cookie and the login name is linked to \npersonal data, the cookie is clearly \"linked.\"\n\nIn less clear cut example, if the data collector ties the cookie to a \nspecific order id in a flat file and that order id is tied to \npersonal information in a related file, the cookie would be linked to \nall of the relational data unless specific precautions have been \ntaken to ensure that a data operator with access to the relational \ndata cannot access the flat cookie data and vice versa.\n\nIn other words, a data collector must: collect no personal \ninformation; take active steps to make sure that information \nreferring to a specific individual cannot be identified; or must use \nthe \"linked\" tag.\n\n\nIdentifiers\n\nThe Working Group decided against an identified or identifiable label \nfor particular types of data. However, user agent implementers have \nthe option of assigning these or other labels themselves and building \nuser interfaces that allow users to make decisions about web sites on \nthe basis of how they collect and use certain types of data.\n\nThe Working Group felt that different user agent implementations \ncould be created to focus on different concerns around data type. \nTherefore, the working group enabled the creation of a robust data \nschema including broad categories of information that may be \nconsidered sensitive by certain user groups.  The Working Group hopes \nthat a diverse set of user agents will be created to allow users the \nability to make identity decisions based on specific collections and \ntypes of collects if they desire to do so.  For example, a user agent \ncould allow users to opt to be prompted when medical or financial \nidentifier is being collected, independent of how that information is \nbeing used.\n\n(1)   More information on the debate and the definitions can be found \nin Lorrie Faith Cranor's book Web Privacy with P3P, O'Reilly, 2002.\n\n\n\n\n\n-- \n------------------------------------\nAri Schwartz\nAssociate Director\nCenter for Democracy and Technology\n1634 I Street NW, Suite 1100\nWashington, DC 20006\n202 637 9800\nfax 202 637 0968\nari@cdt.org\nhttp://www.cdt.org\n------------------------------------\n-- \n------------------------------------\nAri Schwartz\nAssociate Director\nCenter for Democracy and Technology\n1634 I Street NW, Suite 1100\nWashington, DC 20006\n202 637 9800\nfax 202 637 0968\nari@cdt.org\nhttp://www.cdt.org\n------------------------------------\n\n\n\n", "id": "lists-017-6294460"}, {"subject": "MINUTES: 03 September 2003 P3P Specification Cal", "content": "Attendees:\nLorrie Cranor, Bill Duserick, Jeff Edelen, Giles Hogben, Rob Horn, Jack\nHumphrey, Ari Schwartz, David Stampley, Rigo Wenning\n\nRegrets:\nPatrick Hung, Matthias Schunter\n\n1. Task force reports\nConverting P3P data schema to XML schema - Giles Hogben\nGiles will submit a draft for review week of Sept 8.\nGiles will be meeting with the EU on Sept. 11\n\nAgent and domain relationships - Jack Humphrey\nJack will incorporate comments from previous meeting minutes into Domain\nRelationships draft\nJack will convene a meeting next week with Agent and Domain Relationships\nTask Force to review draft and solicit more feedback\nJack will begin work on an Agent Relationships document.\n\n\n2. Discussion of Ari's revised identified/identifiable/link clarification\ndraft (August 18).\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=167\n<http://www.w3.org/Bugs/Public/show_bug.cgi?id=167> \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0004.html\n<http://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0004.html> \n\nAri confirmed the date of his latest draft (Aug. 18).  Ari checked Canada's\nPIPEDA and confirmed the law did not define \"identifiable\". Lorrie proposed\nand Ari agreed to make final changes (including Rigo's previous comments)\nand submit the draft for final review, allowing 2 weeks from submission for\ncomments.  If no objections are raised this document will be included in the\n1.1 Specification, as part of the Terminology section (1.3).\n\n\n3. Discuss revised consent/grouping proposal\n(http://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0039.html\n<http://lists.w3.org/Archives/Public/public-p3p-spec/2003Aug/0039.html> )\nLorrie offered a few comments on Matthias' latest e-mails.  First, Lorrie\nrecommended a clean-up of the language in the proposal.  Second, she\nrecommended specifying a maximum number of characters for the short\ndescription.  Third, a more significant issue, Lorrie made a case for a\n'mixed' consent option.  Rigo raised concerns with \"mixed\" statements, and\ndiscussion on handling mismatches ensued.  Lorrie proposed that the 1.1\nspecification should require the 1.1 user agent to perform a consistency\ncheck with the Web site; if an inconsistency is found it would be treated as\na mixed interpretation by the user agent.\n\nLorrie will re-write Matthias' draft and review with Matthias and Jeremy.\n\n\n4. Discussion of disputes definition issues -- see comments in green at\nhttp://www.w3.org/P3P/2003/p3p-translation.htm\n<http://www.w3.org/P3P/2003/p3p-translation.htm> \nDavid Stampley provided background information on the work on Disputes.  The\nproposed change to the Disputes definitions are intended to explain to\nconsumers the laws that would apply to their activities on a Web site\ninstead of dictating rights to consumers.  Rigo expressed concerns in light\nof the EU directive. Giles will raise the proposed Disputes definitions in\nhis meeting with EU members on September 11.\n\nAction: All should read David's comments (in green) and send feedback to the\ne-mail list.\n\n6. Next call (September 17)\n\n\n\n\nBill Duserick\nCorporate Compliance - Privacy\nFidelity Investments\nwilliam.duserick@fmr.com \n(617) 392-1224\n\n\n\n", "id": "lists-017-6309888"}, {"subject": "Re: Grouping Statements Proposa", "content": "Here is a revised version that addresses the issues we discussed on \nlast week's call. Rigo, please post. Everyone, please review and send \ncomments.\n\nLorrie\n\n\n\n\n\ntext/html attachment: 09-cc-changes-to-P3P.htm\n\n\n\n\n", "id": "lists-017-6321778"}, {"subject": "Re: Grouping Statements Proposa", "content": "Hi Lorrie,\n\nthanks for your work! I've read through it and have only minor changes:\n- Typo in Heading 3.7.2 \"STATMENT-GROUP\"\n- Thanks for renaming 'required' to 'always'. This is more intuitive.\n- By defining that for required=\"always\", all inside statements must not \nhave a required attribute, one can allow 'ours' and 'current' in 'mixed' as \nwell as 'always' groups. I changed the spec accordingly.\n- I agree that it may be easier to understand if statement-group-def and \nstatement-group are explained together. In this case, the STATEMENT section \nin the consolidated spec should contain a reference/pointer to the \nSTATEMENT-GROUP extension.\n\nEnclosed is an update an a HTML-diff (note that this is experimental; just \nlook at the differences in the text; it garbles the BNF).\n\nRegards,\n  matthias\n\n\n\nAt 02:35 PM 9/10/2003 -0400, Lorrie Cranor wrote:\n>Here is a revised version that addresses the issues we discussed on last \n>week's call. Rigo, please post. Everyone, please review and send comments.\n>\n>Lorrie\n>\n>\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724-8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n\ntext/html attachment: 09-10-diff.htm\n\ntext/html attachment: 10-cc-changes-to-P3P.htm\n\n\n\n\n", "id": "lists-017-6329406"}, {"subject": "Re: Grouping Statements Proposa", "content": "Looks good except that if consent =always the required attribute could \nbe omitted or it could be required=always (that's why I said it MAY be \nomitted). These two cases are semantically equivalent.\n\nLorrie\n\n\nOn Thursday, September 11, 2003, at 02:53  AM, Matthias Schunter wrote:\n\n> Hi Lorrie,\n>\n> thanks for your work! I've read through it and have only minor changes:\n> - Typo in Heading 3.7.2 \"STATMENT-GROUP\"\n> - Thanks for renaming 'required' to 'always'. This is more intuitive.\n> - By defining that for required=\"always\", all inside statements must \n> not\n> have a required attribute, one can allow 'ours' and 'current' in \n> 'mixed' as\n> well as 'always' groups. I changed the spec accordingly.\n> - I agree that it may be easier to understand if statement-group-def \n> and\n> statement-group are explained together. In this case, the STATEMENT \n> section\n> in the consolidated spec should contain a reference/pointer to the\n> STATEMENT-GROUP extension.\n>\n> Enclosed is an update an a HTML-diff (note that this is experimental; \n> just\n> look at the differences in the text; it garbles the BNF).\n>\n> Regards,\n>   matthias\n>\n>\n>\n> At 02:35 PM 9/10/2003 -0400, Lorrie Cranor wrote:\n>> Here is a revised version that addresses the issues we discussed on \n>> last\n>> week's call. Rigo, please post. Everyone, please review and send \n>> comments.\n>>\n>> Lorrie\n>>\n>>\n>>\n> <09-10-diff.htm><10-cc-changes-to-P3P.htm>-- Dr. Matthias Schunter \n> <mts (at) zurich.ibm.com> ---\n> IBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\n> Fax +41-1-724-8953; More info at www.semper.org/sirene\n> PGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-6338433"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Two small issues with this latest draft:\n\n> \"Identified data\" is information that in a record or profile and can \n> reasonably be\n\nshould be\n\n\"Identified data\" is information in a record or profile that can \nreasonably be\n\n\n> In other words, a data collector must: collect no personal \n> information; take active steps to make sure that information referring \n> to a specific individual cannot be identified; or must use the \n> \"linked\" tag.\n>\n\nThere is no \"linked\" tag... how about \"In other words, a data collector \nthat uses cookies must.... or must disclose all linked data in a P3P \npolicy associated with a cookie.\"\n\n\n\n", "id": "lists-017-6347387"}, {"subject": "AGENDA: 17 Sept P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, September 17, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n    - [P3P beyond HTTP - Patrick Hung]\n    - [User agent behavior - Lorrie Cranor]\n    - Compact policies - Brooks Dobbs\n    - Article 10 vocabulary issues - Giles Hogben\n    - Agent and domain relationships - Jack Humphrey\n    - Consent choices - Matthias Schunter\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - [Signed P3P policies  - Giles Hogben]\n\n2. Approval of Ari's revised identified/identifiable link draft\nas part of the terminology section of the spec\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Sep/0003.html\nAll remaining concerns MUST be sent to the mailing list prior to the \ncall.\n\n3. Discuss revised consent/grouping proposal\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2003Sep/0005.html\n\n4. Discussion of disputes definition issues -- see\n    comments in green at http://www.w3.org/P3P/2003/p3p-translation.htm\n\n5. Set date for next call (Sept 24?)\n\n\n\n", "id": "lists-017-6355700"}, {"subject": "Re: [Bug 167] explanation of identified, identifiable, and linke", "content": "Good points.\n\nAri\n\n\n\nAt 11:18 AM -0400 9/15/03, Lorrie Cranor wrote:\n>Two small issues with this latest draft:\n>\n>>\"Identified data\" is information that in a record or profile and \n>>can reasonably be\n>\n>should be\n>\n>\"Identified data\" is information in a record or profile that can reasonably be\n>\n>>In other words, a data collector must: collect no personal \n>>information; take active steps to make sure that information \n>>referring to a specific individual cannot be identified; or must \n>>use the \"linked\" tag.\n>>\n>\n>There is no \"linked\" tag... how about \"In other words, a data \n>collector that uses cookies must.... or must disclose all linked \n>data in a P3P policy associated with a cookie.\"\n\n\n\n", "id": "lists-017-6363665"}, {"subject": "MINUTES: 18 September 2003 P3P Specification Cal", "content": "Minutes 9/17/2003\n\nPresent:\nLorrie Cranor, AT&T\nBrooks Dobbs, DoubleClick\nBill Duserick , Fidelity\nJeff Edelmen \nRigo Wenning, W3C\nDavid Stampley, Reynolds and Reynolds\nMatthias Schunter, IBM\n\nRegrets:\nPatrick Hung, \nAri Schwartz, CDT\nJack Humphrey, Coremetrics \n\n\n0. Sydney report from Rigo\n\nRigo: Overall a great success, however there seems to be reoccurring mention\nof the P3P's limitation regarding not being able to point out primary\npurposes.\n\nLorrie: if 1.1 is going to deal with primary purposes, we need someone to\nhead it up <no name came up>\n\nLorrie: points out that free text in consequences can be used to address\nthis but of course this loses the ability to be machine processed.\nLorrie: will the EPAL people helpful here?\nACTION-> Rigo to get a proposal from EPAL on primary purpose.\n\n\n1. Task force reports\n    \nNO TASK FORCES REPORTING\n\n2. Approval of Ari's revised identified/identifiable draft\n\nNo comments, changes approved.\n\n3. Discuss revised consent/grouping proposal\n\nRigo: has reservations, but feels current iteration is the most mature.\nLorrie: Looking for comments from developers/Microsoft.\nACTION-> Lorrie to follow up with Jeremy performance issues. \n\n4. Discussion of disputes definition issues \n\nWhere were we...\nLorrie reminds everyone that we were dealing with the definition of DISPUTES\nspecifically regarding changing of wording from \"may be followed\" to\" offers\nor acknowledges\".\n\nDavid: Do \"offers and acknowledgements\" encompass a case where a provider is\nlegally obligated to do something? \n\nRigo: Those elements where established to inform the users about their\nrights.  The most difficult problem is that people don't know about their\nrights.  Can we improve the wording in laws and courts group to say this is\nnot a binding submission to a law but meant to be informational?\n\nDavid: Says that that makes sense to him, and feels that the change he\nproposes moves towards that.  David feels that \"offers or acknowledges\" is a\nbetter way of communicating how a user can gain benefit than \"may be\nfollowed\"\n\nRigo: \"offers and acknowledges\" creates a different spin - sounds more like\nthey got to pick and choose.\n\nDavid: suggests that we don't want to be in the business of educating a\nconsumer improperly.  It is not fair to tell a company that it has an\neducational requirement.  Don't want to make the company the user's lawyer.\n\n\nLorrie: Is the issue here that \"may be followed\" has multiple possible\ninterpretations, and is Rigo saying that this is a good thing while; David\nthinks this is a bad thing.  Lorrie feels like we shouldn't be wishy washy\nhere.\n\nRigo: feels that this will lead to people declaring less\n\nLorrie: asks for opinions\nBrooks: overlawyered\nBill: no opinion\nJeff: not sure that even \"offers and acknowledges\" completely does away with\nambiguity altogether.  Suggests adding, \"although there may be other ways\".\nMatthias: no opinion\n\nLorrie: agreed to adopt David's proposal with the above additional 6 words.\n\nNow we move into discussing SERVICE, INDEPENDENT, COURT and LAW\n\nSERVICE\n\nDavid: First one suffers the problem that the 1st one might lead the user to\nthe feeling that their option is to call service - when it should say we\naren't telling you what all your options are but one of them is calling\ncustomer service.  Feels that the change encompasses this better.\n\nRigo: points out question of definition of service provider\n\nLorrie: Addressing the question of this definition.  Suggests changing\nService Provider, Service or Web Site to Entity for definitions within\nDISPUTES.\n\nAll agreed that this change should be made.\n\nCOURT: \n\nDavid suggest removing altogether\n\nRigo: feels that it should be kept\n\nLorrie: What can you convey using Court that you can't convey with Law?\n\nBrooks: Court should be inherited from Law and that is not the way it is set\nup.\n\nDave: suggests middle ground, intent is for a site to say \"we are willing to\nbe legally bound by our policy\" - but that is not for the site to decide.\nThey may be bound if they are willing or not.  Companies should not be bound\nto educate or to become a users lawyers.  This is about describing their\nprivacy practices. \n\nLorrie: no one is using it and it doesn't buy us much\n\nLorrie: what if we kept it but said, even if this element is not disclosed,\nusers may still have this option?\n\nAction David -> David will come up with an alternate definition proposal.\n\n\n5. Set date for next call (Sept 24?)\nCall next week same time.  Rigo taking over working group starting next\nweek.  Lorrie has decided to have a baby in the very near future.  Lorrie\nexpects to be back in December.  She is moving to Pittsburgh - timing could\nimpact when she is back.\n\n  \n\n\n\nBrooks Dobbs\nDoubleClick \nDirector of Privacy Technology\nEmail: bdobbs@doubleclick.net\nOffice: 404.995.6634 \n\n\n\n", "id": "lists-017-6371643"}, {"subject": "Re: [Agent/Domain] sameentity domain relationship proposal comment", "content": "On Wed, Sep 03, 2003 at 10:52:23AM -0500, Humphrey, Jack wrote:\n> > There were some questions about the goals of this proposal. People \n> > thought it was useful for companies to be able to declare that all of \n> > their multiple domains are owned by a single company and comply with \n> > the same policy, but there was less interest in being able to declare \n> > that companies belong to an ad network. The reason browsers are \n> > treating these as third party cookies is that is how consumers seem to \n> > want to see them treated.\n> \n> I see this point. This proposal actually only addresses declaring that\n> multiple domains belong to the same company. It does not attempt to address\n> the agent/ad network type of relationships. I will make that clear in my\n> upcoming proposed specification changes.\n\nOne of the reasons we came up with thoughts about agent/domain\nrelationsships was the ability to express contractual relationsships\nbetween entities and to ease the task of integrating content from\ndifferent parties. As far as I can see, there is only a proposal about\nthe same entity, but no proposal for services acting as agents e.g.\n\nJack, could you please explore and report back on the call of 1 oct.?\n\nThanks\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-6384796"}, {"subject": "No call on 24 Septembe", "content": "Dear all, \n\nmost of the actions haven't been delivered. So we'll skip this week's\nteleconference. Next teleconference will be 1 october. I will send out\nan agenda.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-6393775"}, {"subject": "AGENDA: 1 Oct P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, October 1, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Task force reports\n   - [P3P beyond HTTP - Patrick Hung]\n   - Compact policies - Brooks Dobbs\n   - Article 10 vocabulary issues - Giles Hogben\n   - Agent and domain relationships - Jack Humphrey\n   - Consent choices - Matthias Schunter\n   - Converting P3P data schema to XML schema - Giles Hogben\n   - [Signed P3P policies  - Giles Hogben]\n\n2. Discussion of disputes definition issues -- see\n   comments in green at http://www.w3.org/P3P/2003/p3p-translation.htm\n\n3. Continued work on P3P 1.0 element definitions and translations\n   http://www.w3.org/P3P/2003/p3p-translation.htm\n\n4. Linking cookie data and what it means\n   http://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n5. Set date for next call (Oct. 15)\n\n\n\n", "id": "lists-017-6400113"}, {"subject": "bug 17", "content": "http://www.w3.org/Bugs/Public/show_bug.cgi?id=171\n\nOn yesterday's call we were trying to sort out the status of bug 171. \nLooking at section 3.3.2 in the 10 February working draft \nhttp://www.w3.org/TR/P3P11 it appears that this has already been \nsolved. The STATEMENT-GROUP element takes a name attribute, and we \nexplain that this is equivalent to the IBM extension.  Is there \nsomething else here I'm missing. If so, please set me straight. If not, \nI'm going to close this bug.\n\nLorrie\n\n\n\n", "id": "lists-017-6437534"}, {"subject": "Re: Art 10 Issue 1: Purpose Specificatio", "content": "Following up on the discussion last seen on Feb 19 at\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0049.html\nI believe the consensus is to add the following subsection to the user \nagent\nguidelines section of the spec.\n\nTiming of Notices to Users\n\nAs a best practice, users should receive notice about a site's privacy\npractices prior to their user agent transmitting any\npersonal data. Personal data means anything which might reasonably be\nlinked to the user (see section ****) and as such can even include IP\naddresses and\nlocale data transmitted in http headers before a page has even loaded.\nIn order to present such notice, a user agent would need to fetch a P3P\npolicy prior to loading a page following the guidelines specified in \nsection\n2.4.3 **\"The Safe Zone.\" However, implementers will need to consider the\nperformance, usability, and privacy tradeoffs associated with\ndisplaying privacy information prior to loading a page. One way that\nprivacy and usability might be simultaneously maximized is\nto treat all\nrequests made prior to display of policy information as \"safe zone\"\nrequests.\n\nAt sites that include form fields, user agents SHOULD provide notice\nabout the corresponding privacy practices prior to form submittal.\nBesides being best practice, this may be needed in order to\ncomply with\nregulations in some jurisdictions (such as the European Union) that\nrequire a notice about the purpose of data collection to be\npresented\nto the user before any personal information is captured.\nUser interface\ndesigns should recognize that the privacy policy for the\nform's action\nURI may be different than the privacy policy for the HTML\npage in which\nthe form is embedded. In order to allow users to view privacy policy\ninformation associated with action URIs prior to form\nsubmittal, user\nagents might include a privacy tab that loads policy information for\naction URIs as a page loads, a button or menu item that\ncauses policy\ninformation for action URIs to be displayed, or a pop-up\nthat appears\nwhen a user begins entering information into a form field.\n\n\n\n", "id": "lists-017-6443980"}, {"subject": "Re: Art 10 Issue 2: Jurisdictio", "content": "Following up on our discussion form Feb 19, we seem to have a consensus \non\nadding an optional jurisdiction extension to the recipient element\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0050.html\n\n\n  jurisdiction= \"<JURISDICTION\"\n   \" service=\" quoted-URI\n   [\" short-description=\" quotedstring]\n  \">\"\n[longdescription]\n  \"</JURISDICTION>\"\n\n\n\nlongdescription=<LONG-DESCRIPTION>PCDATA</LONG-DESCRIPTION>\n\n\nExample:\n\n                                <RECIPIENT>\n                                        <EXTENSION><JURISDICTION\n   service=\"http://europa.eu.int/smartapi/cgi/\n   sga_doc?smartapi!celexapi!prod!CE\n   LEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\"\n   short-description=\"EU law\"\n  **EU\"></JURISDICTION>\n                                        </EXTENSION>\n                                </RECIPIENT>\n\n   Text for specification:\nThe jurisdiction extension element allows user agents to make\njudgments\nabout the trustworthiness of a data recipient based on the regulatory\nenvironment they are placed in. Jurisdictions of recipients can be \nrendered\nmachine readable by inserting a known URI into the service field (e.g. \nthe\nURI of a body of legislation which applies). For example organizations\nwithin the European Union can be assumed to comply to European data\nprotection law and could therefore insert the URI of the 95/46\ndirective as\nin the example above. Some jurisdictions prohibit transfer of data to\ncertain other jurisdictions without the explicit consent of the data\nsubject. It should be noted therefore declaring the data transfer \nactivity\nof a recipient using the P3P jurisdiction extension is not sufficient\nto guarantee its legality.\n\n\n\n", "id": "lists-017-6452557"}, {"subject": "Re: Art 10: Issue 3  cookie", "content": "I think the consensus in\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0044.html\nwas to add the following to 2.3.2.7:\n\nUser agents that evaluate cookie policies SHOULD perform this evaluation\n*and its resultant behavior* before setting a cookie so that the cookie \ncan\nbe discarded without being set if that is what is dictated by the user's\npreferences.\n\n\nAnd then we wanted to add the following to the guidelines\n(I think in the section Timing of Notices to Users... but I guess we \nreally want to call it \"Timing of Policy Evaluation and Notices to \nUsers\"):\n\nCertain jurisdictions view the storage of cookies on a user's\nhard drive as an act of data processing. In such jurisdictions (e.g. \nthe EU),\npolicies should always be evaluated before a cookie is set and\ncookies should not be stored unless the cookie's policy is found to \ncomply with the user's\npreferences.\n\n\n[we may need to do some further reshuffling after we see all the \nchanges to the guidelines section... but I would like to go ahead and \nadopt this and have Rigo make the edits and then we can go from there]\n\n\n\n", "id": "lists-017-6460879"}, {"subject": "Re: Art 10: Issue 4  Security Measure", "content": "And here is what I think the consensus was on security measures\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0043.html\n\n\nText for spec (Section 3.2.6, after independent\norganization...):\n\nPolicy writers may also use this attribute to specify seals and \ncertification programs related to\nthe entity's information practices (including privacy and security \nseals).\n\n\n\n", "id": "lists-017-6468435"}, {"subject": "AGENDA: 7 April P3P spec cal", "content": "1. Finish Article 10 issues -- this seems to have slipped through the \ncracks... I think we more or less resolved these issues on the mailing \nlist, but I don't think we ever officially agreed... so one (hopefully) \nlast time.\n\na. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0001.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=652\n\nb. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0002.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=653\n\nc. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0003.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=174\n\nd. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0004.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=654\n\n\n2. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[Dave please send revised draft]\n\n\n3. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n\n\n4. Who should be listed as authors of p3p 1.1?\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=570\n\n\n5. Publication of next working draft\nBesides from the above, the only other open item I see is the schema \nstuff that Giles is working on. Am I missing anything else?\n\n\n6. Schedule next call (April 14?)\n\n\n\n", "id": "lists-017-6475324"}, {"subject": "Re: AGENDA: 7 April P3P spec cal", "content": "[Forgot to include the time and dial-in details....]\n\nThe next P3P specification group conference call will be on\nWednesday, April 7, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nOn Apr 5, 2004, at 8:42 PM, Lorrie Cranor wrote:\n\n>\n> 1. Finish Article 10 issues -- this seems to have slipped through the \n> cracks... I think we more or less resolved these issues on the mailing \n> list, but I don't think we ever officially agreed... so one \n> (hopefully) last time.\n>\n> a. \n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0001.html\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=652\n>\n> b. \n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0002.html\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=653\n>\n> c. \n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0003.html\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=174\n>\n> d. \n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0004.html\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=654\n>\n>\n> 2. primary purpose specification\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n> [Dave please send revised draft]\n>\n>\n> 3. P3P Generic attribute for XML applications\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n>\n>\n> 4. Who should be listed as authors of p3p 1.1?\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=570\n>\n>\n> 5. Publication of next working draft\n> Besides from the above, the only other open item I see is the schema \n> stuff that Giles is working on. Am I missing anything else?\n>\n>\n> 6. Schedule next call (April 14?)\n>\n\n\n\n", "id": "lists-017-6484392"}, {"subject": "XML Schem", "content": "Two points:\n1. For finishing the XML schema stuff for the working draft. My colleague\nwho has been working on finalizing the schema stuff is away till the 19th\nApril so I would prefer to be able to deliver this at the end of that week\n(the 23rd April). If it is really urgent and it will not get in otherwise,\nIO could conceiveably delve into it myself and have something by the 16th.\n\n2. I just discovered an error in the existing spec regarding custom data\nschemas:\nThe guidelines for categories say:\n<DATA-STRUCT> elements MAY include category definitions. If a structure\ndefinition includes categories, then all uses of those structures in data\ndefinitions and data structures pick up those categories. If a structure\ncontains no categories, then the categories for that structure MAY be\ndefined when it is used in another structure or data element. Otherwise, a\ndata element using this structure is a variable-category element. Any uses\nof a variable-category data element in a policy require that its categories\nbe listed in the policy.\n\nBut the example custom schema does not follow this rule because it uses the\nvehicle data structures without inheriting their categories. This was\ncausing an error in our validator for the inline schema test case.\n\n\n\n", "id": "lists-017-6493844"}, {"subject": "Handling Privacy In WSDL 2.", "content": "Dear all, \n\nI took an action item last week[1] to explain further about the \nW3C Team Note around privacy in Web services[2].\n\nIn the ongoing discussion about Web Services and Privacy in\nspecial and policy in more general terms,  the Web Services \nActivity needed something more concrete. I pointed Hugo Haas, \nWeb Services Activity Lead to our early notes[3]. I explained \nthe concept of the generic p3p attribute as initially suggested by \nSteven Pemberton to Hugo Haas and Phillippe Le H?garet (Architecture\nDomain Lead) We had intense internal discussions with Massimo \nabout the meaning of the attribute. The discussions were extended \nto Lorrie and the P3P Group. I came to the conclusion that the \ngeneric p3p attribute as it stands today is more a suggestion to \nXML Schema makers on how to use P3P in their context and allow \nthem (even expect them) to further constrain the attribute in the context \nof their application/interface description.\n\nThe team-note in [2] does exactly that. It uses the p3p generic attribute\nto link policies! (not PRF) to Web Services interfaces allowing and \nconstraining the use of the P3P attribute in WSDL. This can be taken \nup by a WG and be transformed into some Rec-Track or WG Note to \ngive it even more authority.\n\nBest, \n\nRigo\n\n1. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0054.html\n2. http://www.w3.org/TeamSubmission/p3p-wsdl/\n3. http://www.w3.org/P3P/2003/p3p-beyond-http/\n\n\n\n\n\n", "id": "lists-017-6501168"}, {"subject": "MINUTES: 7 April P3P spec cal", "content": "Brooks Dobbs\nJeff Edelen\nGiles Hogben\nLorrie Cranor\nJack Humphrey\nRigo Wenning\nDave Stampley\n\nLorrie asked about objections to points a-d.\n\na. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0001.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=652\n\nb. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0002.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=653\n\nc. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0003.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=174\n\nd. http://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0004.html\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=654\n\nThere was consensus to adopt a-d. Giles asked about\nprimary puroposes. Lorrie said that this was a separate issue.\n\n2. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[Dave please send revised draft]\n\nThere was no new Draft.\n\n3. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n\nRigo explained that the problem was how to use P3P in new protocols\nand services. Liberty Alliance and Web Services were not the only\napplications. Liberty Alliance has not done much but Web Services has\nrecently gotten very interested. Joseph and Patrick's draft had a way\nto link P3P policies to WSDL via HTTP requests and URIs, but doesn't\nwork offline or without HTTP. Also to describe a complicated WSDL\ninterface requires writing a complicated P3P policy. But there are\nsimple things going on at each part of the interface, so we would\nreally like to address one P3P policy for a part of a WSDL\ninterface. This would also solve the XForms problem of having a P3P\npolicy per field. So... Rigo, Patrick, Steve Pemberton, Hugo, and\nPhillipe had several calls and worked on drafting a P3P attribute\nproposal which is in the first public P3P 1.1 working draft. Then\nMassimo raised the issue that the P3P attribute doesn't have a defined\nsemantic meeting and it can have a different meaning in different\ncontexts. Lorrie raised similar concerns. Rigo had extensive\ndiscussions with Massimo about this. Rigo thinks the concern has to do\na lot with chunks of XML being sent over the wire (as in CC/PP), but\nthis is not what he has in mind. WSDL and XForms are interface\ndescription languages. The P3P policy would apply to what happens when\nyou use an interface. So then there was the suggestion to limit the\ngeneric attribute to interfaces and not allow it to be used when XML\nis sent over the wire. Massimo says it is a hint to XML schema\ndevelopers but not a MUST. So the question is, do we want just a hint\nor do we want to try to do something stronger, at least for WSDL and\nXForms. We could leave it to those working groups to import P3P into\ntheir own specs.\n\nGiles asked why HTML is not an interface. Rigo explains that WSDL and\nXForms are interface descriptions because they are not the instance\ndata - that is your name, address, etc. that gets encoded in XML. HTML\nis the instance data. Giles argues that HTML is actually similar. Rigo\nsays the P3P attribute makes sense for some elements and not others,\neven in HTML.\n\nWe need to define interface descriptons. This is tricky.\n\nACTION: Rigo will see if another group has already done this.\n\nACTION: Lorrie and Rigo will work together to draft a proposal for\nwhat to put in P3P 1.1. The working group will still need to discuss\nwhether this should be a MUST, MAY, or SHOULD.\n\nGiles says there is a difference between saying \"if you give me data I\nwill do x y z\" and \"I'm giving you my data and I want you to do x y\nz.\" P3P does the former.\n\n4. Who should be listed as authors of p3p 1.1?\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=570\n\n5. Dataschema in XML Schema\nGiles proposed to get it done for week of 23 April.\n\nAction: Put out a new working draft with the things ready so far.\n\nAction: Giles forward email to Massimo and Martin Presler-Marshall.\n\n6. Publication of next working draft\nBesides from the above, the only other open item I see is the schema\nstuff that Giles is working on. Am I missing anything else?\n\nACTION Rigo: Next Draft for 16 April\n\nNext working Draft by May 7 with the remaining issues.\n\n7. Authors\nWho should be listed as authors of p3p 1.1?\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=570\n\nNumber of people that have contributed sections.\nDave Giles Matthias Brooks Jack\n\nEverybody should be in contributors.\n\n\n8. Next call\n\n14 April 2004\n\nScribe: Rigo\n\n\n\n", "id": "lists-017-6508859"}, {"subject": "P3P Generic attribut", "content": "Dear all, \n\nas unique identifiers have the potential to be privacy invasive,\nto even create a lot of issues for those who use them,\nplease look into P3P [1] and EPAL [2]. \n\nIn P3P 1.1 we have established a P3P - attribute to be used \nin such cases. It allows other XML Schema (and Interface) \nbuilders to address privacy in using P3P in a specific way. \nThis means also constraining the use of P3P in a certain way \nas it is used with a certain specification. An example of how this \ncould be done can be found in a Team note on using P3P \nin the context of Web Services [3]\n\nI and Lorrie Cranor, the chair of the P3P Working Group,  will\nbe available for any further question. You can send questions \nto our public mailing-list: public-p3p-spec@w3.org or to our \nmember-only list w3c-p3p-specification@w3.org. We will try to \nanswer them promptly.\n\n 1. http://www.w3.org/TR/P3P11/\n 2. http://www.w3.org/Submission/EPAL/\n 3. http://www.w3.org/TeamSubmission/p3p-wsdl/\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nLegal Advisor             Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n\n\n", "id": "lists-017-6520676"}, {"subject": "RE: P3P Generic attribut", "content": "xml:id provides a structural identifier for an XML element, not for an\nindividual or other society-level construct I'd associate with privacy\nconcerns.  Existing mechanisms for XML element identification don't seem\nto have required privacy features.\n\nCan you provide more detail on how your p3p attribute interacts with\nxml:id?  Are you suggesting that the p3p attribute should go into the\nxml namespace too?\n\n> -----Original Message-----\n> From: public-xml-id-request@w3.org\n[mailto:public-xml-id-request@w3.org]\n> On Behalf Of Rigo Wenning\n> Sent: Thursday, April 08, 2004 2:47 PM\n> To: public-xml-id@w3.org\n> Cc: 'public-p3p-spec'; Lorrie Cranor\n> Subject: P3P Generic attribute\n> \n> Dear all,\n> \n> as unique identifiers have the potential to be privacy invasive,\n> to even create a lot of issues for those who use them,\n> please look into P3P [1] and EPAL [2].\n> \n> In P3P 1.1 we have established a P3P - attribute to be used\n> in such cases. It allows other XML Schema (and Interface)\n> builders to address privacy in using P3P in a specific way.\n> This means also constraining the use of P3P in a certain way\n> as it is used with a certain specification. An example of how this\n> could be done can be found in a Team note on using P3P\n> in the context of Web Services [3]\n> \n> I and Lorrie Cranor, the chair of the P3P Working Group,  will\n> be available for any further question. You can send questions\n> to our public mailing-list: public-p3p-spec@w3.org or to our\n> member-only list w3c-p3p-specification@w3.org. We will try to\n> answer them promptly.\n> \n>  1. http://www.w3.org/TR/P3P11/\n>  2. http://www.w3.org/Submission/EPAL/\n>  3. http://www.w3.org/TeamSubmission/p3p-wsdl/\n> \n> Best,\n> --\n> Rigo Wenning            W3C/ERCIM\n> Legal Advisor             Privacy Activity Lead\n> mail:rigo@w3.org        2004, Routes des Lucioles\n> http://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-6529421"}, {"subject": "P3P Generic Attribute for XML Application", "content": "After discussing with Rigo, here is my proposed redraft of 2.5. The P3P \nGeneric Attribute for XML Applications.\n\nComments?\n\nLorrie\n\n\n\n\n\ntext/html attachment: xml-generic.html\n\n\n\n\n", "id": "lists-017-6541031"}, {"subject": "AGENDA: 14 April P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, April 14, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n1. P3P Generic attribute for XML applications - discuss draft and what \nto do about RDF binding.\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0012.html\n\n2. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[Dave please send revised draft]\n\n3. Publication of next working draft\n\n4. Schedule next call (April 28?)\n\n\n\n", "id": "lists-017-6548243"}, {"subject": "Minutes 14th April cal", "content": "Minutes 14th April\n\nAttending:\n\nGiles\nRigo\nLorrie\n\nGeneric attribute:\nWhat would the XML binding mean in terms of RDF. In RDF you don't have a\ntree structure so what does the application of a P3P binding to child nodes\nmean?\nMaybe RDF can already cope with this by using reification (statements about\nstatements or groups of statements). We would like to get an opinion from\nthe WG. Even if we decide that RDF can cope without a special attribute, we\nshould at the very least give some examples to show how it can actually be\nimplemented. Lorrie has emailed some RDF people to see if we can get some\nguidance.\n\nWe discussed the paragraph of the draft on the allowed uses of P3P - Giles\nsaid that it should be emphasised a little more if we want people to take\nnotice of it and not use P3P for describing desired data practices. People\nare encouraged to send their comments.\n\nPrimary purposes. When we put out a last call, Lorrie should make an\nexecutive summary for the less technical interested parties. So let's just\ntry to put out a reasonable first attempt. The latest draft is in the\nmailing list - also in the agenda.\nSuggest removing actions because this information (e.g. acquire PII) is\ncontained elsewhere in the policy. Suggest merging content and result\nbecause the division is not relevant.\n\nNext draft - Rigo is very busy so - definite maybe :) for next week.\n\nNext call - Monday 26th 11am EST.\n\n\n\n", "id": "lists-017-6555386"}, {"subject": "AGENDA: MONDAY 26 April P3P Spec cal", "content": "NOTE, NEXT CALL IS ON A MONDAY!\n\nThe next P3P specification group conference call will be on\nMONDAY, April 26, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n1. P3P Generic attribute for XML applications - discuss draft and what \nto do about RDF binding.\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0012.html\n\n2. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[Dave please send revised draft]\n\n3. XML schema stuff\n[Giles to send draft and any questions group needs to consider)\n\n4. Publication of next working draft\n\n5. Schedule next call (May 5?)\n\n\n\n", "id": "lists-017-6562996"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "Hi Lorrie,\n\nTo clarify my thoughts a bit, I think there are two interesting things \nto specify;\n   1) who will conform to the policy\n   2) what data the policy applies to\n\nIn P3P 1.0, #1 was always the Web site, and #2 was data submitted to \nthe Web site, as laid out by the various policy reference mechanisms, \netc.\n\nWhen I made the distinction between interfaces and data, I think that \nwhat I was trying to say (and hadn't fully thought through) was that in \nP3P 1.0, #2 is always in relation to an interface, as identified by a \nURI; ultimately, the policy still applies to data. This effort, as I \nsee it, is to allow greater flexibility in specifying #2, because of \nthat.\n\nSo,\n\n> P3P 1.0 was designed to associate XML-encoded privacy policies with \n> URIs,  sets of URIs, or cookies. P3P 1.0 it well suited for use with \n> HTML  and XHTML content transmitted over [HTTP] .\n\nI think this would be better stated as:\n\n> P3P 1.0 was designed to associate XML-encoded privacy policies with \n> data submitted to Web resources, which are identified by URIs or bound \n> to cookies.\n\nI.e., P3P tells you how a site will handle the data (e.g., form fields, \nHTTP headers, TCP/IP connection information) sent to a particular \ninterface, which is identified by a URI. The data itself is NOT \nidentified by this URI; there's been talk at the TAG about how you \nidentify the data in a POST, for example; it's clearly separate from \nthe resource identifier.\n\nP3P 1.0 also allows you to refine by method, etc., which I think \nsupports this view.\n\nIf that's the case, this:\n\n> However,  P3P 1.0 cannot be used in situations where content is not \n> associated  with a URI, for example, some applications of Web Services \n> and XMLP/Soap. In addition,  P3P 1.0 cannot be used in situations \n> where policies apply to only a  subset of the content associated with \n> a given URI. For example,  while P3P 1.0 can be used to apply a P3P \n> policy to an entire form  specified by XForms, it  cannot be used to \n> apply the policy to only a single form field.\n>\n> The P3P 1.1 Specification provides a new binding mechanism to  allow \n> for increased granularity beyond the URI level and to allow  policies \n> to apply to content not associated with a URI.\n\nshould be something like:\n\n> However, P3P 1.0's mechanisms for identifying the target data for \n> privacy policies are limited; in general, they only allow one to \n> identify data submitted to a Web resource, and only on the granularity \n> of an entire message (e.g., a HTTP request). In some cases, this is \n> not sufficient; for example while P3P 1.0 can be used to apply a P3P \n> policy to an entire form specified by XForms, it cannot be used to \n> apply the policy to a single field on that form.\n>\n> To allow for increased granularity, as well as for situations when \n> content is not identified with a URI, the P3P 1.1 specification \n> provides a new mechanism for associating policy with data in XML-based \n> resource description languages such as WSDL and XForms.\n\nand so forth.\n\nI think you also need to require people who use this attribute in their \nformats to explicitly identify who is required to conform to the policy \n(#1).\n\nDoes this make sense? I've been away from P3P for a while, so I could \nbe off-track.\n\nCheers,\n\n\n\nOn Apr 9, 2004, at 6:24 PM, Lorrie Cranor wrote:\n\n> After discussing with Rigo, here is my proposed redraft of 2.5. The \n> P3P Generic Attribute for XML Applications.\n>\n> Comments?\n>\n> Lorrie\n>\n> <xml-generic.html>\n\n--\nMark Nottingham   Principal Technologist\nOffice of the CTO   BEA Systems\n\n\n\n", "id": "lists-017-6570835"}, {"subject": "[Minutes]: MONDAY 26 April P3P Spec cal", "content": "Summary of the Actions:\n1/ Dave send list of primary purposes to mailing-list\n2/ Rigo: adjust ABNF of the jurisdiction element\n\nPresent: \n\nLorrie Cranor\nRigo Wenning\nJack Humphrey\nDave Stampley\n\n1. P3P Generic attribute for XML applications - discuss draft and what \nto do about RDF binding.\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0012.html\n\nRigo reported from Exchanges with Fabien Gandon and that we might \nwant to renew the P3P Note. In fact, Fabien suggests that\napplication outside of P3P might want to use the P3P classes.\nThose classes would have to be defined using RDFS to define P3P.\n\n\n2. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[Dave please send revised draft]\n\nRecent contacts with Dave, he will send something by Tuesday \nmorning. \n\n3. XML schema stuff\n[Giles to send draft and any questions group needs to consider)\n\nGiles not being on the call.\n\n4. Publication of next working draft\n\nThe Draft is nearly ready, I have some remaining \nquestions:\n\n\nBUG 653:\n\nRigo: Action: Adjust ABNF and do jurisdiction element as\nextension element with separate ABNF and adjust the XML Schema\n\nBUG 654: \nAgreement to change\n\nBUG 685: \nAdjust the XML Schema for the new elements\n\n5. Schedule next call (May 5?)\n\nNext call May 3rd \n\n\n\n\n\n", "id": "lists-017-6581669"}, {"subject": "New Working Draf", "content": "The new Working Draft is at\nhttp://www.w3.org/TR/P3P11\n\nthe permanent URI is:\nhttp://www.w3.org/TR/2004/WD-P3P11-20040427/\n\nPlease comment\n\nRigo\n\n\n\n\n", "id": "lists-017-6589677"}, {"subject": "AGENDA: MONDAY 3 May P3P spec cal", "content": "NOTE, NEXT CALL IS ON A MONDAY!\n\nThe next P3P specification group conference call will be on\nMONDAY, May 3, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n1. P3P Generic attribute for XML applications - discuss draft and what \nto do about RDF binding.\n[if Rigo has anything new to report]\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0012.html\n\n2. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[Dave please send revised draft]\n\n3. XML schema stuff\n[Giles to send draft and any questions group needs to consider)\n\n4. Schedule next call (May 12?)\n\nItems 1-3 are all that's left on our todo list before going to last \ncall. If nobody has anything new to report on these items it will be a \nvery short call.  Everyone should also review the latest working draft \nat http://www.w3.org/TR/2004/WD-P3P11-20040427/ to see if there's \nanything else we need to change before going to last call. Hopefully we \nwill be ready for last call by the end of May.\n\n\n\n", "id": "lists-017-6595947"}, {"subject": "[Minutes] Feb 4 P3P spec call 10amnoo", "content": "Present:\n\nLorrie Cranor\nGiles Hogben\nBrooks Dobbs\nJack Humphrey\nPatrick Hung\nDave Stampley\nRigo Wenning\nJeff Edelen\n\n1. Discussion and approval of Article 10 taskforce proposal\n(Giles please resend to mailing list or send the URL)\n\nb/ Text on purpose specification should go into user agent guidelines.\n\nWe discussed changes of the ua-guidelines. in the draft:\nhttp://www.w3.org/P3P/2004/01-art10.html\n\nACTION Giles: Circulate the changes of the jurisdiction ua-guidelines\n\nb/ Discussions on the Jurisdiction - Element\n\nDiscussed the fact of having machine readable identifiers of jurisdictions\nand decided that this is overkill. We decided to abandon machine readable attributes\nand instead decided to have a service attribute with URI and long+short descriptions\n\nGiles: ACTION circulate a new proposal containing the new Schema\n\nc/ Cookies\n\nchange wording from EU specific to \"Best Practice\"\nalso change wording from actual only on set-cookie to say\nat minimum require analysis at set-cookie, but best practice would be\nalso analysis on replay.\n\n2.3.2.7\nUser agents MUST interpret COOKIE-INCLUDE and COOKIE-EXCLUDE elements\ndiscussed this paragraph.\n\nWe need to bits of text: one for 2.3.2.7 and one for ua-guidelines. Lorrie\nis not convinced that we need something for 2.3.2.7. because, we don't\ngive some guidance what ua should do as a result.\n\nGiles ACTION: new wording for 2.3.2.7 and a paragraph talking about\nbest practice for the ua section and send to the mailing-list\n\nc/ Security\n\nIn order to assure users of good security practices in handling\ndata captured through their site, policy writers may also use this attribute\nto specify seals (such as CPA WebTrust and Shop Smart) validating their\nsecurity practices.\n\nthis sentence was abandoned.\n\nshould be added under independent organization in 3.2.6 Disputes\nthe following suggestion:\n\nCurrent suggestion:\npolicy writers may also use this attribute to specify any seals related to\nthe entities information practices (including privacy and security seals)\n\n\n2. Primary purpose specification - has anyone been working on this?\n   We need to figure out how to move forward on getting a complete\n   draft by Feb 13 or drop this.\n\nDiscussion whether we want to do this at all. Lorrie talked to Calvin Powers and\nthey tried to find some already existing lists. Jeff reported that he checked\ntheir human readable policies and the current section seems to be sufficient\n\nLorrie remarked that current purpose could be also explained by the\nconsequence field.\n\nRigo explained that this relates to the prob with financial we had two years ago.\n\nACTION: Dave and Giles: Come up with a list of primary purposes.\n\n\n3. Agent and domain relationships - report from Jack\n\nJack reported and summarized issues:\n\na/ issue about cookies and replaying cookies\ndoes the cookie playback note conflict with 2.3.2.7\n\nb/ issue whether we want to have changes in the header\n\nACTION: Jack: send you issues to the list\n\n\n4. Open bugzilla items\n\nBug 171: People have already done this with the IBM Editor\nDiscussion whether we can use IBMs namespace. Lorrie wants to use\nthe mechanism in place.\n\nAction: Rigo: Proceed the suggested changes from Matthias and add a footnote about\nthe old mechanism of IBM Editor.\n\n========================================================\n\nclarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\nLorrie presented issue: Initially we imagined only direct linking\nGiles also included indirect linking. That's where the issue is.\n\nWe started to discuss, what reasonably could happen with a cookie linking\nlots of data. Hypothesis was about law enforcement. Do we want to cover their\nabilities.\n\nwe need primary key to apply but also mention second key in database\n\n\n\n=========Not dealt anymore, lack of time ===================\nstrengthen 2.3.2.7 user agent requirements\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=174\n\nGiles has submitted several - are these issues the whole working\ngroup needs to address?\n\n5. How to proceed on compact policies?\n\n6. Set time/date of next call - February 11?\n\nBest \n\nRigo (scribe)\n\n\n\n", "id": "lists-017-6634708"}, {"subject": "Art 10 Issue 1: Purpose Specificatio", "content": "Apart from the issue on primary purpose, the following is the latest\nsuggested text for the UA Guidelines\n\nSome jurisdictions (E.g. the European Union) require human readable\ninformation on purpose of collection to be presented to the user before any\ninformation is captured. One way to comply with this is to present human\nreadable translations of policies for action uri's of forms simultaneously\nwith the forms. As a best practice, information on purposes should be made\navailable before any personal information is transmitted. This might be\nachieved be achieved for example by a privacy tab which is synchronised to\ndisplay information before pages load, or by including information which is\ndisplayed on clicking a link.\n\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity\nNew technologies for Combatting Fraud Unit\nTP 267\nVia Enrico Fermi 1\nIspra \n21020 VA\nItaly\n\ngiles.hogben@jrc.it\ntel:+390332789187\nfax:+390332789576\n \n\n\n\n", "id": "lists-017-6645089"}, {"subject": "Art 10 Issue 2: Jurisdictio", "content": "Here is the latest suggested text and Jurisdiction Extension spec: please\nreview the text as I don't think we discussed it in the call.\n\nJurisdiction Disclosure:\n\nWe suggest that an Jurisdiction extension be added to the recipient element:\n\n[??] Extension\n =\n Jurisdiction\n`</Extension>\n \nJurisdiction\n =\n `<JURISDICTION \n \" service=\" quoted-URI\n [\" short-description=\" quotedstring]\n[\" long-description=\" quotedstring]\n\">\"\n\n\"</JURISDICTION>\"\n\nExample:\n\n<RECIPIENT>\n<EXTENSION><JURISDICTION\nservice=\"http://europa.eu.int/smartapi/cgi/sga_doc?smartapi!celexapi!prod!CE\nLEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\" short-description=\"EU law\"\nlong-description=\"This service operates within the EU\"></JURISDICTION>\n</EXTENSION>\n</RECIPIENT>\n\nText for specification:\n\n\nThe jurisdiction extension element allows user agents to make judgements\nabout the trustworthiness of a data recipient based on the regulatory\nenvironment they are placed in. For example organizations within the\nEuropean Union can be assumed to comply to European data protection law.\nSome jurisdictions prohibit transfer of data to certain other jurisdictions\nwithout the explicit consent of the data subject. Therefore declaring a data\ntransfer activity using the P3P jurisdiction extension is not sufficient to\nguarantee its legality. \n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity\nNew technologies for Combatting Fraud Unit\nTP 267\nVia Enrico Fermi 1\nIspra \n21020 VA\nItaly\n\ngiles.hogben@jrc.it\ntel:+390332789187\nfax:+390332789576\n \n\n\n\n", "id": "lists-017-6653221"}, {"subject": "Art 10: Issue 3  cookie", "content": "Here are the latest suggested changes (the guidelines text has changed quite\na lot so please check):\n\nText for 2.3.2.7.\n-----------------\nAdd:\nUser agents evaluating cookies SHOULD apply the results of a preference\nmatch on the cookie's policy before setting the cookie.\n\nText for guidelines\n-------------------\nCertain jurisdictions view the storage of cookies on a user's hard drive as\nan act of data processing. In such jurisdictions (e.g. the EU), policies\nshould always be evaluated before a cookie is set and cookies should not be\nstored unless the cookie's policy is found to comply with the user's\npreferences.\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity\nNew technologies for Combatting Fraud Unit\nTP 267\nVia Enrico Fermi 1\nIspra \n21020 VA\nItaly\n\ngiles.hogben@jrc.it\ntel:+390332789187\nfax:+390332789576\n \n\n\n\n", "id": "lists-017-6662211"}, {"subject": "Art 10: Issue 4  Security Measure", "content": "Here is the latest suggested modification and text for the Spec:\n\nSecurity issues:\nWe suggest using the existing disputes attribute which is a placeholder for\nseals of any type (which can then be included in the browser's list of\napproved seals, along with a type attribute). \n\nAccompanying text for spec (Section 3.2.6, after independent\norganization...):\n\nPolicy writers may also use this attribute to specify and seals related to\nthe entity's information practices (including privacy and security seals).\n\n-------------------------------------\nGiles Hogben\nEuropean Commission Joint Research Centre\nInstitute for the Protection and Security of the Citizen Cybersecurity\nNew technologies for Combatting Fraud Unit\n\ngiles.hogben @ jrc.it\n\n \n\n\n\n", "id": "lists-017-6670230"}, {"subject": "Invitation for paper submissio", "content": "Dear Colleague,\n \nAmong the technologies that are impacting and guiding the evolution of the\nWorld Wide Web are Web Services and the Semantic Web.  These technologies\nwill support the creation of complex, adaptive systems organized around the\ninformation that they manage and exchange and the orchestration of the\nservices they provide. \n \nWe are trying to organize a Web Services and Semantic Web special session at\nthe upcoming SCI 2004 Conference.  This conference will be held July 18 - 21\nin Orlando, Florida.  Specific details on the conference may be found at the\nconference web site, provided below.  \n \nWe are inviting you to summit a paper to us on this topic - Web Services and\nthe Semantic Web.  While you could propose a paper on either technology, of\nparticular interest would be papers that bridge or show convergence between\nthese two areas.  We must have your submission by February 12th, 2004 for\nconsideration.\n \nThe conference organizers require that we, as proposed session chairs,\nobtain a minimum of 5 papers to hold this proposed session.  If we can\nobtain the required number of submissions, this special session will be\nestablished as part of the SCI 2004 conference agenda.  Submission\ninformation follows.\n \nPlease forward this information to people that you think may be interested\nso that it gets the widest possible distribution.\n \nRegards,\nBob Cherinka and Bob Miller\n(Our apologies for duplicate email)\n \n \nEXTENDED ABSTRACTS AND PAPER DRAFTS SUBMISSION FORM for this proposed\nsession\nExtended abstracts or paper drafts should be sent taking into account the\nfollowing Format:\n \n1.Major theme of the paper should be related to the session theme: Web\nservices and the Semantic Web. \n2.Paper title. \n3.Extended abstract of 500 to 1500 words and/or paper drafts of 2000\nto 5000 words, in English. \n4.Author(s) and/or co-author(s) with names, addresses, telephone and\nfax numbers, and e-mail addresses. \n \nExtended abstracts or paper drafts should be sent via email to the chairs\nfor the proposed session:  rdc@mitre.org <mailto:rdc@mitre.org>  and\ndrbob@mitre.org <mailto:drbob@mitre.org> \n \nDEADLINES\n*February 12th, 2004: Submission of extended abstracts (500-1500\nwords) or paper drafts (2000-5000 words). \n*February 22nd, 2004: Acceptance notifications. \n*March 31st, 2004: Submission of camera-ready papers: hard copies and\nelectronic versions. \n \nPARTICIPANTS\n \nParticipation of both researchers and practitioners is strongly encouraged.\nPapers may be submitted on: research in science and engineering, case\nstudies drawn on professional practice and consulting, and position papers\nbased on large and rich experience gained through executive/managerial\npractices and decision-making. \n \nPAPER REVIEWING, PUBLICATION, AND PRESENTATION\n \nSubmitted papers will be sent to reviewers. Accepted papers, which should\nnot exceed six single-spaced typed pages, will be published by means of\npaper and electronic proceedings.  Accepted papers will require that an\nauthor (or delegate) attend the conference to present the paper.\n \nCONFERENCE DETAILS\n \nThe 8th World Multi-Conference on\nSYSTEMICS, CYBERNETICS And INFORMATICS\nSCI 2004\nhttp://www.iiisci.org/sci2004 <http://www.iiisci.org/sci2004> ,\nhttp://www.iiis.org/sci2004/ <http://www.iiis.org/sci2004/> \n \nJuly 18 - 21, 2004, Orlando, Florida(USA)\nThe Rosen Plaza Hotel, http://www.rosenplaza.com/frames1.html\n<http://www.rosenplaza.com/frames1.html> \n \n \n \n\n\n\n", "id": "lists-017-6677786"}, {"subject": "Re: Art 10: Issue 4  Security Measure", "content": "Looks good except\n- one typo (specify and seals --> specify seals)\n- maybe change \"seals\" to \"seals or certification programs\" to make it \na little more clear what we are talking about.\n\nLorrie\n\n\nOn Thursday, February 5, 2004, at 03:12 AM, Giles Hogben wrote:\n\n>\n> Here is the latest suggested modification and text for the Spec:\n>\n> Security issues:\n> We suggest using the existing disputes attribute which is a \n> placeholder for\n> seals of any type (which can then be included in the browser's list of\n> approved seals, along with a type attribute).\n>\n> Accompanying text for spec (Section 3.2.6, after independent\n> organization...):\n>\n> Policy writers may also use this attribute to specify and seals \n> related to\n> the entity's information practices (including privacy and security \n> seals).\n>\n> -------------------------------------\n> Giles Hogben\n> European Commission Joint Research Centre\n> Institute for the Protection and Security of the Citizen Cybersecurity\n> New technologies for Combatting Fraud Unit\n>\n> giles.hogben @ jrc.it\n>\n>\n>\n\n\n\n", "id": "lists-017-6691489"}, {"subject": "Re: Art 10 Issue 1: Purpose Specificatio", "content": "I suggest this be added as a subsection of section with the title \n\"Timing of Notices to Users\"\n\nWhile the directive is asking for notice about purpose, I could imagine \nother jurisdictions asking for notice about say, data recipients or \ndata retention as well. So i don't think we should limit our discussion \nto notice about purpose.\n\nI also think we need to spell things out a bit more so that people \nunderstand what data might be transmitted before a page is displayed. \nIt is also not entirely clear to me how clickstream information comes \ninto play here. Here is a proposal:\n\n\nTiming of Notices to Users\n\nAs a best practice, users should receive notice about a site's privacy \npractices prior to their user agent transmitting any personal data. In \norder to do this, a user agent would need to fetch a P3P policy prior \nto loading a page following the guidelines specified in section 2.4.3 \nThe \"Safe Zone.\" However, implementers will need to consider the \nperformance, usability, and privacy tradeoffs associated with \ndisplaying privacy information prior to loading a page. One way that \nprivacy and usability might be simultaneously maximized is to treat all \nrequests made prior to display of policy information as \"safe zone\" \nrequests.\n\nAt sites that include form fields, user agents SHOULD provide notice \nabout the corresponding privacy practices prior to form submittal. \nBesides being best practice, this may be needed in order to comply with \nregulations in some jurisdictions (such as the European Union) that \nrequire a notice about the purpose of data collection to be presented \nto the user before any personal information is captured. User interface \ndesigns should recognize that the privacy policy for the form's action \nURI may be different than the privacy policy for the HTML page in which \nthe form is embedded. In order to allow users to view privacy policy \ninformation associated with action URIs prior to form submittal, user \nagents might include a privacy tab that loads policy information for \naction URIs as a page loads, a button or menu item that causes policy \ninformation for action URIs to be displayed, or a pop-up that appears \nwhen a user begins entering information into a form field.\n\n\nOn Thursday, February 5, 2004, at 03:00 AM, Giles Hogben wrote:\n\n>\n> Apart from the issue on primary purpose, the following is the latest\n> suggested text for the UA Guidelines\n>\n> Some jurisdictions (E.g. the European Union) require human readable\n> information on purpose of collection to be presented to the user \n> before any\n> information is captured. One way to comply with this is to present \n> human\n> readable translations of policies for action uri's of forms \n> simultaneously\n> with the forms. As a best practice, information on purposes should be \n> made\n> available before any personal information is transmitted. This might be\n> achieved be achieved for example by a privacy tab which is \n> synchronised to\n> display information before pages load, or by including information \n> which is\n> displayed on clicking a link.\n>\n>\n> -------------------------------------\n> Giles Hogben\n> European Commission Joint Research Centre\n> Institute for the Protection and Security of the Citizen Cybersecurity\n> New technologies for Combatting Fraud Unit\n> TP 267\n> Via Enrico Fermi 1\n> Ispra\n> 21020 VA\n> Italy\n>\n> giles.hogben@jrc.it\n> tel:+390332789187\n> fax:+390332789576\n>\n>\n\n\n\n", "id": "lists-017-6700383"}, {"subject": "Re: Art 10 Issue 2: Jurisdictio", "content": "We should make it clear that the jurisdiction is the jurisdiction of  \nthe recipient (not the entity).\n\nFor consistency, LONG-DESCRIPTION should be a sub-element rather than  \nan attribute.\n\nLorrie\n\n\n\nOn Thursday, February 5, 2004, at 03:04 AM, Giles Hogben wrote:\n\n>\n> Here is the latest suggested text and Jurisdiction Extension spec:  \n> please\n> review the text as I don't think we discussed it in the call.\n>\n> Jurisdiction Disclosure:\n>\n> We suggest that an Jurisdiction extension be added to the recipient  \n> element:\n>\n> [??] Extension\n>  =\n>  Jurisdiction\n> `</Extension>\n>\n> Jurisdiction\n>  =\n>  `<JURISDICTION\n>  \" service=\" quoted-URI\n>  [\" short-description=\" quotedstring]\n> [\" long-description=\" quotedstring]\n> \">\"\n>\n> \"</JURISDICTION>\"\n>\n> Example:\n>\n> <RECIPIENT>\n> <EXTENSION><JURISDICTION\n> service=\"http://europa.eu.int/smartapi/cgi/ \n> sga_doc?smartapi!celexapi!prod!CE\n> LEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\"  \n> short-description=\"EU law\"\n> long-description=\"This service operates within the EU\"></JURISDICTION>\n> </EXTENSION>\n> </RECIPIENT>\n> \n> Text for specification:\n>\n>\n> The jurisdiction extension element allows user agents to make  \n> judgements\n> about the trustworthiness of a data recipient based on the regulatory\n> environment they are placed in. For example organizations within the\n> European Union can be assumed to comply to European data protection  \n> law.\n> Some jurisdictions prohibit transfer of data to certain other  \n> jurisdictions\n> without the explicit consent of the data subject. Therefore declaring  \n> a data\n> transfer activity using the P3P jurisdiction extension is not  \n> sufficient to\n> guarantee its legality.\n>\n> -------------------------------------\n> Giles Hogben\n> European Commission Joint Research Centre\n> Institute for the Protection and Security of the Citizen Cybersecurity\n> New technologies for Combatting Fraud Unit\n> TP 267\n> Via Enrico Fermi 1\n> Ispra\n> 21020 VA\n> Italy\n>\n> giles.hogben@jrc.it\n> tel:+390332789187\n> fax:+390332789576\n>\n>\n\n\n\n", "id": "lists-017-6711952"}, {"subject": "Re: Art 10: Issue 3  cookie", "content": "On Thursday, February 5, 2004, at 03:09 AM, Giles Hogben wrote:\n\n>\n> Here are the latest suggested changes (the guidelines text has changed \n> quite\n> a lot so please check):\n>\n> Text for 2.3.2.7.\n> -----------------\n> Add:\n> User agents evaluating cookies SHOULD apply the results of a preference\n> match on the cookie's policy before setting the cookie.\n\nHow about\n\nUser agents that evaluate cookie polices SHOULD perform this evaluation \nbefore setting a cookie.\n\n\n>\n> Text for guidelines\n> -------------------\n> Certain jurisdictions view the storage of cookies on a user's hard \n> drive as\n> an act of data processing. In such jurisdictions (e.g. the EU), \n> policies\n> should always be evaluated before a cookie is set and cookies should \n> not be\n> stored unless the cookie's policy is found to comply with the user's\n> preferences.\n\nIn my mail on Issue 1 I had suggested a section called \"Timing of \nNotices to Users\"... now I'm thinking the section should be \"Timing of \nPolicy Evaluation and Notice to Users\" ... then we can include this \nparagraph at the end of that section.\n\n\n\n>\n> -------------------------------------\n> Giles Hogben\n> European Commission Joint Research Centre\n> Institute for the Protection and Security of the Citizen Cybersecurity\n> New technologies for Combatting Fraud Unit\n> TP 267\n> Via Enrico Fermi 1\n> Ispra\n> 21020 VA\n> Italy\n>\n> giles.hogben@jrc.it\n> tel:+390332789187\n> fax:+390332789576\n>\n>\n\n\n\n", "id": "lists-017-6722121"}, {"subject": "Re: Art 10: Issue 3  cookie", "content": "> > Here are the latest suggested changes (the guidelines text has \n> changed \n> > quite\n> > a lot so please check):\n> >\n> > Text for 2.3.2.7.\n> > -----------------\n> > Add:\n> > User agents evaluating cookies SHOULD apply the results of a \n> preference> match on the cookie's policy before setting the cookie.\n> \n> How about\n> \n> User agents that evaluate cookie polices SHOULD perform this \n> evaluation \n> before setting a cookie.\n\nThis does not convey the advice. that the cookie should not be saved \nif it doesn't match the user's preferences.\n\n(Thanks for the other comments, don't have time this week to reply as \nI am travelling...)\n\n> \n> \n> >\n> > Text for guidelines\n> > -------------------\n> > Certain jurisdictions view the storage of cookies on a user's \n> hard \n> > drive as\n> > an act of data processing. In such jurisdictions (e.g. the EU), \n> > policies\n> > should always be evaluated before a cookie is set and cookies \n> should \n> > not be\n> > stored unless the cookie's policy is found to comply with the \nuser's\n> > preferences.\n> \n> In my mail on Issue 1 I had suggested a section called \"Timing of \n> Notices to Users\"... now I'm thinking the section should be \n> \"Timing of \n> Policy Evaluation and Notice to Users\" ... then we can include \n> this \n> paragraph at the end of that section.\n> \n> \n> \n> >\n> > -------------------------------------\n> > Giles Hogben\n> > European Commission Joint Research Centre\n> > Institute for the Protection and Security of the Citizen \n> Cybersecurity> New technologies for Combatting Fraud Unit\n> > TP 267\n> > Via Enrico Fermi 1\n> > Ispra\n> > 21020 VA\n> > Italy\n> >\n> > giles.hogben@jrc.it\n> > tel:+390332789187\n> > fax:+390332789576\n> >\n> >\n> \n> \n\n\n\n", "id": "lists-017-6731130"}, {"subject": "Re: Art 10: Issue 3  cookie", "content": "On Feb 7, 2004, at 4:34 AM, Giles Hogben wrote:\n\n>\n>\n>>> Here are the latest suggested changes (the guidelines text has\n>> changed\n>>> quite\n>>> a lot so please check):\n>>>\n>>> Text for 2.3.2.7.\n>>> -----------------\n>>> Add:\n>>> User agents evaluating cookies SHOULD apply the results of a\n>> preference> match on the cookie's policy before setting the cookie.\n>>\n>> How about\n>>\n>> User agents that evaluate cookie polices SHOULD perform this\n>> evaluation\n>> before setting a cookie.\n>\n> This does not convey the advice. that the cookie should not be saved\n> if it doesn't match the user's preferences.\n\nI'm not sure we want to say that. A user might specify, for example, \nthat cookies that don't match their preferences should be converted to \nsession cookies rather than deleted altogether. Also, I could imagine a \nuser agent that gives users the option of storing rejected cookies in a \nseparate place for later analysis or inspection. So I think we should \nmake the point that cookies should be evaluated before set time. But \nI'm not sure we want to specify what should happen as a result of that \nevaluation. We could say:\n\nUser agents that evaluate cookie policies SHOULD perform this \nevaluation before setting a cookie so that the cookie can be discarded \nwithout being set if that is what is dictated by the user's \npreferences.\n\n\n\n\n>\n> (Thanks for the other comments, don't have time this week to reply as\n> I am travelling...)\n>\n>>\n>>\n>>>\n>>> Text for guidelines\n>>> -------------------\n>>> Certain jurisdictions view the storage of cookies on a user's\n>> hard\n>>> drive as\n>>> an act of data processing. In such jurisdictions (e.g. the EU),\n>>> policies\n>>> should always be evaluated before a cookie is set and cookies\n>> should\n>>> not be\n>>> stored unless the cookie's policy is found to comply with the\n> user's\n>>> preferences.\n>>\n>> In my mail on Issue 1 I had suggested a section called \"Timing of\n>> Notices to Users\"... now I'm thinking the section should be\n>> \"Timing of\n>> Policy Evaluation and Notice to Users\" ... then we can include\n>> this\n>> paragraph at the end of that section.\n>>\n>>\n>>\n>>>\n>>> -------------------------------------\n>>> Giles Hogben\n>>> European Commission Joint Research Centre\n>>> Institute for the Protection and Security of the Citizen\n>> Cybersecurity> New technologies for Combatting Fraud Unit\n>>> TP 267\n>>> Via Enrico Fermi 1\n>>> Ispra\n>>> 21020 VA\n>>> Italy\n>>>\n>>> giles.hogben@jrc.it\n>>> tel:+390332789187\n>>> fax:+390332789576\n>>>\n>>>\n>>\n>>\n>\n\n\n\n", "id": "lists-017-6740547"}, {"subject": "P3P 1.1 Domain Relationship", "content": "Working Group members, \n \nPlease read and comment on this latest draft:\nhttp://www.w3.org/P3P/2004/02-domain-relationships.html\n<http://www.w3.org/P3P/2004/02-domain-relationships.html> \n(Apologies, I thought this URL went out with the minutes. Rigo, I don't\nthink it's linked anywhere -- I just guessed the URL.)\n \nHere are the open questions/issues I would like to discuss with the group:\n \n1. For now, we have dropped the HTTP header mechanism seen in previous\ndrafts. There are two reasons: first of all, changing the P3P HTTP header\nwould require approval of a revised P3P header specification by IETF.\nSecondly, there is a feeling that the PRF-based mechanism should be a\nfeasible way for user agents to discover this new information, even for\nthose user agents that only use compact policies to manage cookie privacy.\n \n2. The last section in the draft (\"Cookie Playback\") states:\n\nUser agents should be aware that if they allow a cookie to be set based on a\nrelationship established by known host declarations, they should verify that\nsuch a relationship exists at cookie playback time, and not send the cookie\nif it does not. Such verification implies re-fetching the policy reference\nfile and evaluating its known host declarations only if the policy reference\nfile has expired.\n\nThere is a concern that this language would have an impact on section\n2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a policy\nreference file from a host before replaying a cookie to that host\".\nThoughts?\n\n3. The section in the draft entitled \"HTTP Header Requirement\" states:\n\nThe KNOWN-HOST extension relies on the use of the \"P3P: policyref\" HTTP\nheader for one site to refer to a policy reference file on another site.\nSince policy reference files cannot include full URIs in the POLICY-REF\nINCLUDE elements, sites that rely on placing their policy reference file in\nthe  <http://www.w3.org/TR/P3P/#Well_Known_Location> well-known location\nhave no way of referencing policies hosted on other sites.\n\nIs it acceptable to require the use the policyref HTTP header for this case?\nAn alternative might be another PRF extension that would allow one PRF to\nreference another PRF.\n\nLooking forward to your feedback.\n\n++Jack++\n\n\n\n", "id": "lists-017-6751375"}, {"subject": "Re: Art 10 Issue 2: Jurisdictio", "content": "On Fri, Feb 06, 2004 at 12:20:32PM -0500, Lorrie Cranor wrote:\n> \n> We should make it clear that the jurisdiction is the jurisdiction of  \n> the recipient (not the entity).\n\nI had the same question. But if one declares <ours /> in the recipient\nfield, this means entity and some more agents.\n\n> ><RECIPIENT>\n> ><EXTENSION><JURISDICTION\n> >service=\"http://europa.eu.int/smartapi/cgi/ \n> >sga_doc?smartapi!celexapi!prod!CE\n> >LEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\"  \n> >short-description=\"EU law\"\n> >long-description=\"This service operates within the EU\"></JURISDICTION>\n> ></EXTENSION>\n> ></RECIPIENT>\n\nGiles, please invite them to provide a stable legal URI. The URI you\njust inserted contains illegal characters (&) that have to be escaped \nin your example (.s/&/\\&amp\\;/g)\n> >\n> >Text for specification:\n> >\n> >\n> >The jurisdiction extension element allows user agents to make\n> >judgements about the trustworthiness of a data recipient based on the\n> >regulatory environment they are placed in. For example organizations\n> >within the European Union can be assumed to comply to European data\n> >protection  law.  Some jurisdictions prohibit transfer of data to\n> >certain other  jurisdictions without the explicit consent of the data\n> >subject. Therefore declaring  a data transfer activity using the P3P\n> >jurisdiction extension is not  sufficient to guarantee its legality.\n> >\n\nI would not say trustworthiness, as one could always lie in a\ndeclaration. It is more that an entity or recipient can declare that\nthey adhere to some jurisdiction and that they don't transfer stuff \nto unsecure jurisdictions without notice.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-6761485"}, {"subject": "Re: Art 10: Issue 3  cookie", "content": "On Sat, Feb 07, 2004 at 04:23:20PM -0500, Lorrie Cranor wrote:\n> User agents that evaluate cookie policies SHOULD perform this \n> evaluation before setting a cookie so that the cookie can be discarded \n> without being set if that is what is dictated by the user's \n> preferences.\n\nSounds better than just say evaluation, as we have also psychology\ninvolved here ;). I would not talk about store or erase, rather about\ngiving effect. As you said: for analysis, one might want to store the\ncookie in another place. But the cookie is not doing anything anymore.\nHow could one express that in english?\n\nRigo\n\n\n\n", "id": "lists-017-6770800"}, {"subject": "Re: Art 10: Issue 4  Security Measure", "content": "On Fri, Feb 06, 2004 at 11:14:59AM -0500, Lorrie Cranor wrote:\n> \n> Looks good except\n> - one typo (specify and seals --> specify seals)\n> - maybe change \"seals\" to \"seals or certification programs\" to make it \n> a little more clear what we are talking about.\n> \nLooks good for me. Is this already in bugzilla?\n\nRigo\n\n\n\n", "id": "lists-017-6778194"}, {"subject": "Re: Art 10 Issue 1: Purpose Specificatio", "content": "Note, that the EU communications directive requires this kind of\ninformation especially before a cookie can be set to the user machine.\nSo forms and cookies are the two special cases. While forms are much\nmore comprehensible, the info transferred by cookies is more opaque and\nmore p3p is needed IMHO ;)\n\nBest, \n\nRigo\n\nOn Fri, Feb 06, 2004 at 12:16:20PM -0500, Lorrie Cranor wrote:\n> At sites that include form fields, user agents SHOULD provide notice \n> about the corresponding privacy practices prior to form submittal. \n> Besides being best practice, this may be needed in order to comply with \n> regulations in some jurisdictions (such as the European Union) that \n> require a notice about the purpose of data collection to be presented \n> to the user before any personal information is captured. User interface \n> designs should recognize that the privacy policy for the form's action \n> URI may be different than the privacy policy for the HTML page in which \n> the form is embedded. In order to allow users to view privacy policy \n> information associated with action URIs prior to form submittal, user \n> agents might include a privacy tab that loads policy information for \n> action URIs as a page loads, a button or menu item that causes policy \n> information for action URIs to be displayed, or a pop-up that appears \n> when a user begins entering information into a form field.\n> \n> \n\n\n\n", "id": "lists-017-6785456"}, {"subject": "AGENDA: 11 February P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, February 11, 2004, 10 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nNOTE: THIS CALL IS STARTING AT 10 AM!\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0012.html\n\n2. Primary purpose specification\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\nWe discussed this on the call last week but did not have time to finish \nit. Consensus that we need better text to describe direct linking. \nQuestion remains about what we should say about indirect linking.\n\n4. How to proceed on compact policies?\n\n5. Set time/date of next call (Lorrie not available Feb 18 or Feb 25)\n\n\n\n", "id": "lists-017-6793826"}, {"subject": "Re: P3P 1.1 Domain Relationship", "content": "On Feb 9, 2004, at 12:53 AM, Humphrey, Jack wrote:\n\n> Working Group members,\n>  ?\n> Please read and comment on this latest draft:\n> http://www.w3.org/P3P/2004/02-domain-relationships.html\n> (Apologies, I thought this URL went out with the minutes. Rigo, I \n> don't think it's linked anywhere -- I just guessed the URL.)\n> ?\n\nA few concerns:\n\n- When the HTTP header method is used to refer to a PRF on another \nhost, it only makes sense if the other host has the same file structure \nor if the policy applies to * and/or to all cookies. Otherwise you \ncould end up with conflicts. Perhaps this should be pointed out.\n\n- \"Any number of KNOWN-HOST elements can be declared inside a \nPOLICY-REF  element or inside the POLICY-REFERENCES element. Known host \ndeclarations at the POLICY-REFERENCES level are considered to apply to \nall policies in the file, excluding those that have specific \ndeclarations at the POLICY-REF  level.\" Is this really necessary? For \nsimplicity I think it would be better to put KNOWN-HOST elements only \ninside a POLICY-REF element.\n\n- We should make clear that there is nothing wrong with sites \ncontinuing to refer to PRFs on other hosts without using the KNOWN-HOST \nextension. The extension just buys you extra information about the \nrelationship.\n\n> Here are the open questions/issues I would like to discuss with the \n> group:\n> ?\n> 1. For now, we have dropped the HTTP header mechanism seen in previous \n> drafts. There are two reasons: first of all, changing the P3P HTTP \n> header would require approval of a revised P3P header specification by \n> IETF. Secondly, there is a feeling that the PRF-based mechanism should \n> be a feasible way for user agents to discover this new information, \n> even for those user agents that only use compact policies to manage \n> cookie privacy.\n\nthat makes sense\n\n> ?\n> 2. The last section in the draft (\"Cookie Playback\") states:\n>\n> User agents should be aware that if they allow a cookie to be set \n> based on a relationship established by known host declarations, they \n> should verify that such a relationship exists at cookie playback time, \n> and not send the cookie if it does not. Such verification implies \n> re-fetching the policy reference file and evaluating its known host \n> declarations only if the policy reference file has expired.\n>\n> There is a concern that this language would have an impact on section \n> 2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a \n> policy reference file from a host before replaying a cookie to that \n> host\". Thoughts?\n\nThe only conflict I see is with \"Such verification implies re-fetching \nthe policy reference file and evaluating its known host declarations \nonly if the policy reference file has expired.\" which suggests that the \nre-verification should not be done if the PRF has not expired. While \nthere is no reason to do it if the PRF has not expired, I don't think \nwe need to say it shouldn't be done. What if we said instead \"Such \nverification implies re-fetching an expired policy reference file and \nevaluating its known host declarations.\"\n\n>\n> 3. The section in the draft entitled \"HTTP Header Requirement\" states:\n>\n>\n> The KNOWN-HOST extension relies on the use of the \"P3P: policyref\" \n> HTTP header for one site to refer to a policy reference file on \n> another site. Since policy reference files cannot include full URIs in \n> the POLICY-REF INCLUDE elements, sites that rely on placing their \n> policy reference file in the well-known location have no way of \n> referencing policies hosted on other sites.\n>\n> Is it acceptable to require the use the policyref HTTP header for this \n> case? An alternative might be another PRF extension that would allow \n> one PRF to reference another PRF.\n>\n\nHmm... this is not ideal, but I think it is the best solution. If we \nwere to add another extension than a user agent that was not aware of \nthe extension would not be able to apply the policy at all. As it is \nwritten now, user agents can still figure out what policy applies even \nif they don't know the extension, they just won't know about the ours \nrelationship.\n\nLorrie\n\n\n\n", "id": "lists-017-6801239"}, {"subject": "generic attribut", "content": "I still have concerns about 2.5 The P3P Generic Attribute for XML \nApplications\nhttp://www.w3.org/P3P/2004/WD-P3P11-20040203.html#generic_attribute\nThe language is better than the previous draft, but I am still \nconcerned about \"the policy MUST describe all data collection performed \nas a result of  processing the element carrying the P3P Generic \nAttribute. The policy also MUST describe all data collection performed \nas a result of processing of all  subelements .\"\n\nThe notion of binding was hairy enough when dealing with HTTP, but at \nleast HTTP methods are somewhat well defined and we usually know what \nit  means for a user agent to dereference a URI (although I could \nimagine this coming back to haunt us later, but so far so good). But I \ndon't think we know what it means to \"process\" an arbitrary XML \nelement. Indeed, I think we can expect that different tools may process \nthe same XML element in different ways.\n\nHere is a hypothetical example of the problem:\n\nSuppose I have an XML directory (name, address, phone number, fax, URI, \netc.). Let's say I put a generic P3P tag in an element that contains a \nsingle directory entry. What does it mean to process this element? A \nuser agent might process it by\na) displaying the entry itself in a browser.\nb) dereferencing the URI in the entry and displaying it in a browser\nc) dialing a phone\nd) generating a form letter, putting the name and address into the form \nletter, sending the form letter to a device that prints it and puts it \nin the postal mail\ne) generating a fax and sending it to the fax number\n\nThere might be no data collection associated with a. b might result in \nthe collection of clickstream data. c might result in the collection of \ncaller ID. d might result in collection of whatever information is put \nin the letter. e might result in whatever info is put in the fax, plus \ncaller ID.\n\nI think to solve this problem we need to add some meta data that \nexplains what it means to process the XML. Perhaps we could add a \ncompanion attribute that would be a URI that would be used to describe \nwhat the P3P binding means for a particular application.\n\nLorrie\n\n\n\n", "id": "lists-017-6812889"}, {"subject": "RE: generic attribut", "content": "Referring to what Lorrie's suggestion, one of the possible solutions to\ndefine the companion attribute may be related to some semantic and workflow\ntechnologies such as DAML-S or only a plain English description. If so, is\nthere a need to explore semantic stuff for this generic attribute?\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org [mailto:public-p3p-spec-request@w3.org]\nOn Behalf Of Lorrie Cranor\nSent: Wednesday, February 11, 2004 6:51 AM\nTo: 'public-p3p-spec'\nSubject: generic attribute\n\n\nI still have concerns about 2.5 The P3P Generic Attribute for XML \nApplications\nhttp://www.w3.org/P3P/2004/WD-P3P11-20040203.html#generic_attribute\nThe language is better than the previous draft, but I am still \nconcerned about \"the policy MUST describe all data collection performed \nas a result of  processing the element carrying the P3P Generic \nAttribute. The policy also MUST describe all data collection performed \nas a result of processing of all  subelements .\"\n\nThe notion of binding was hairy enough when dealing with HTTP, but at \nleast HTTP methods are somewhat well defined and we usually know what \nit  means for a user agent to dereference a URI (although I could \nimagine this coming back to haunt us later, but so far so good). But I \ndon't think we know what it means to \"process\" an arbitrary XML \nelement. Indeed, I think we can expect that different tools may process \nthe same XML element in different ways.\n\nHere is a hypothetical example of the problem:\n\nSuppose I have an XML directory (name, address, phone number, fax, URI, \netc.). Let's say I put a generic P3P tag in an element that contains a \nsingle directory entry. What does it mean to process this element? A \nuser agent might process it by\na) displaying the entry itself in a browser.\nb) dereferencing the URI in the entry and displaying it in a browser\nc) dialing a phone\nd) generating a form letter, putting the name and address into the form \nletter, sending the form letter to a device that prints it and puts it \nin the postal mail\ne) generating a fax and sending it to the fax number\n\nThere might be no data collection associated with a. b might result in \nthe collection of clickstream data. c might result in the collection of \ncaller ID. d might result in collection of whatever information is put \nin the letter. e might result in whatever info is put in the fax, plus \ncaller ID.\n\nI think to solve this problem we need to add some meta data that \nexplains what it means to process the XML. Perhaps we could add a \ncompanion attribute that would be a URI that would be used to describe \nwhat the P3P binding means for a particular application.\n\nLorrie\n\n\n\n", "id": "lists-017-6821853"}, {"subject": "P3P 1.1 First Public Working Draft publishe", "content": "First WD \"The Platform for Privacy Preferences 1.1 (P3P1.1)\nSpecification\" published.\nhttp://www.w3.org/TR/2004/WD-P3P11-20040210/\n\nTR pages updated with these new publications.\nhttp://www.w3.org/TR/\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-6831902"}, {"subject": "[Minutes] of the 11 feb 2004 cal", "content": "Present:\n\nLorrie Cranor\nJack Humphrey\nRigo Wenning\nJeff Edelen\nBrooks Dobbs\n\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0012.html\n\ntalking about\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0018.html\n\nPotential Problem\nif directory a has policy b on host a.example.com\nand directory b has policy a on host a.example.com\n\nthe known hosts\nnow if host b.example references this PRF by http-header\nand has policy a on directory a and policy b by policy b, the user\nagent gets screwed.\n\nLorrie suggest to have a separate PRF for known hosts and that\nknown hosts should use that separate PRF if it gets complicated.\n\n\nACTION: Jack: bring up a new draft and send to Rigo for publication\n\nRigo asked about performance improvements\nLorrie said that this is already feasable with the actual mechanisms\nno more improvements possible with the relationsships. We can only\nexpress the nature of relationsships.\n\nACTION Rigo ask Brooks about how to use this for performance improvement\n\nLorrie stated that the current proposal is in good shape to go into the\nspecification.\n\nFloor still open for performance\n\nACTION: Rigo Link new agent domain relationsships\n\n\n2. Primary purpose specification\n\nAction Rigo: Call up data commissioners and follow up with Dave\n\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\nWe discussed this on the call last week but did not have time to finish\nit. Consensus that we need better text to describe direct linking.\nQuestion remains about what we should say about indirect linking.\n\nBrooks and Giles are not present:\nWe are in the process of where to draw the line for indirect linking. A direct link if there\nis a database key in the cookie. If things are linked because two cookies in the same logfile\nand there is no intention to harvest that, should we draw the line?\n\nJeff, it is tricky to define. You could match two keys from different databases\nJH: if you have the the intent to link it. Any other linkages that you do later and\nthat you haven't declared initially are a violation of your policy.\n\nFrom a different angle, if one makes risk-assesment on user side:\nLorrie, if site uses multiple cookies, one can assume they are linkable. That doesn't say\nthat they actually get linked.\n\nAction: Lorrie to rewrite Giles draft on linking data to include linked and linkable\nand circulate to the list.\n\nWe asked about what the relationsship between online cookie database and offline CRM system\nwe want clarity for that question. Lorrie said that we might ask the companies to use\ndifferent identifiers.\nAlso the question, about what to declare if only parts of the CRM database are used\nfor the online context.\nJH: if not linking the data and no intention, should make reasonable effort to create obstacles\nin your architecture.\n\nRigo: We already have done criteria in non-identifiable, so why not have criteria here\nBrooks: People won't re-engineer their CRM-Systems.\n\nExample:\n\nWeb-site with search engine and customers and customer-data: We want to know if I search\nfor aids, will that be linked into my customer-data.\nBD: we always assumed that IP is linked to cookie as they are on the same line in the logfile\nLorrie: but what is linked to the cookie?\nRigo: issue is that the actual data transferred is not much, but it adds up in the record and\nwe don't have a good way to say that.\n\nLC: Cookie is only linked to data if it causes a change update in the database\nBD: logfile is arguably a database.\nLC: If you wouldn't log the cookie in the logfile you would not change the database\n... if cookie is used to retrieve info from database, then it is arguably also linked to\n....a database.\nBD: the lookup is changing the data structure? If there is no log of this transaction\nLC: if log the transaction, than offline will associate with online, but if it is not logged, there\nis no link\n\n\n\n4. How to proceed on compact policies?\n\nLC: want a decision\nwe can't get rid of them, as this would harm backwards compatibility\nso only three options: keep them as is, could be deprecated or improved\n\nWhat would deprecated mean?\nWe encourage use only to make P3P 1.0 user agents happy\nWhat are tradeoffs and benefits?\n\nImprovements: could they be substantial enough to remedy the known\nproblems?\n\nKeep them as is? Nobody opted for this solution as the issues around\nthe compact format are too serious.\n\n\n5. Set time/date of next call (Lorrie not available Feb 18 or Feb 25)\nNext time 23 February 11am:\n\nAction Lorrie: Arrange the bridge at W3C\n\n\n\n", "id": "lists-017-6838523"}, {"subject": "next p3p spec call MONDAY Feb 2", "content": "There will be no P3P spec wg call on Feb 18 or Feb 25. The next call \nwill be on MONDAY, February 23, 11 am to noon US Eastern at the usual \nphone number.\n\nLorrie\n\n\n\n", "id": "lists-017-6849595"}, {"subject": "RE: P3P 1.1 Domain Relationship", "content": "Question:\n\nDoes this address A=B, B=C but A<>C?  So imagine the case where hosts on\ndifferent domains www.a.com and www.b.com list each other as reciprocal\nknown hosts.  Also imagine www.b.com and www.c.com describe the same\nrelationship, should a user agent be able to make inferences about the\nrelationship between www.a.com and www.c.com?\n\n\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org [mailto:public-p3p-spec-request@w3.org]\nOn Behalf Of Lorrie Cranor\nSent: Tuesday, February 10, 2004 4:54 PM\nTo: Humphrey, Jack\nCc: public-p3p-spec@w3.org\nSubject: Re: P3P 1.1 Domain Relationships\n\n\n\nOn Feb 9, 2004, at 12:53 AM, Humphrey, Jack wrote:\n\n> Working Group members,\n>  ?\n> Please read and comment on this latest draft:\n> http://www.w3.org/P3P/2004/02-domain-relationships.html\n> (Apologies, I thought this URL went out with the minutes. Rigo, I \n> don't think it's linked anywhere -- I just guessed the URL.)\n> ?\n\nA few concerns:\n\n- When the HTTP header method is used to refer to a PRF on another \nhost, it only makes sense if the other host has the same file structure \nor if the policy applies to * and/or to all cookies. Otherwise you \ncould end up with conflicts. Perhaps this should be pointed out.\n\n- \"Any number of KNOWN-HOST elements can be declared inside a \nPOLICY-REF  element or inside the POLICY-REFERENCES element. Known host \ndeclarations at the POLICY-REFERENCES level are considered to apply to \nall policies in the file, excluding those that have specific \ndeclarations at the POLICY-REF  level.\" Is this really necessary? For \nsimplicity I think it would be better to put KNOWN-HOST elements only \ninside a POLICY-REF element.\n\n- We should make clear that there is nothing wrong with sites \ncontinuing to refer to PRFs on other hosts without using the KNOWN-HOST \nextension. The extension just buys you extra information about the \nrelationship.\n\n> Here are the open questions/issues I would like to discuss with the \n> group:\n> ?\n> 1. For now, we have dropped the HTTP header mechanism seen in previous \n> drafts. There are two reasons: first of all, changing the P3P HTTP \n> header would require approval of a revised P3P header specification by \n> IETF. Secondly, there is a feeling that the PRF-based mechanism should \n> be a feasible way for user agents to discover this new information, \n> even for those user agents that only use compact policies to manage \n> cookie privacy.\n\nthat makes sense\n\n> ?\n> 2. The last section in the draft (\"Cookie Playback\") states:\n>\n> User agents should be aware that if they allow a cookie to be set \n> based on a relationship established by known host declarations, they \n> should verify that such a relationship exists at cookie playback time, \n> and not send the cookie if it does not. Such verification implies \n> re-fetching the policy reference file and evaluating its known host \n> declarations only if the policy reference file has expired.\n>\n> There is a concern that this language would have an impact on section \n> 2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a \n> policy reference file from a host before replaying a cookie to that \n> host\". Thoughts?\n\nThe only conflict I see is with \"Such verification implies re-fetching \nthe policy reference file and evaluating its known host declarations \nonly if the policy reference file has expired.\" which suggests that the \nre-verification should not be done if the PRF has not expired. While \nthere is no reason to do it if the PRF has not expired, I don't think \nwe need to say it shouldn't be done. What if we said instead \"Such \nverification implies re-fetching an expired policy reference file and \nevaluating its known host declarations.\"\n\n>\n> 3. The section in the draft entitled \"HTTP Header Requirement\" states:\n>\n>\n> The KNOWN-HOST extension relies on the use of the \"P3P: policyref\" \n> HTTP header for one site to refer to a policy reference file on \n> another site. Since policy reference files cannot include full URIs in \n> the POLICY-REF INCLUDE elements, sites that rely on placing their \n> policy reference file in the well-known location have no way of \n> referencing policies hosted on other sites.\n>\n> Is it acceptable to require the use the policyref HTTP header for this \n> case? An alternative might be another PRF extension that would allow \n> one PRF to reference another PRF.\n>\n\nHmm... this is not ideal, but I think it is the best solution. If we \nwere to add another extension than a user agent that was not aware of \nthe extension would not be able to apply the policy at all. As it is \nwritten now, user agents can still figure out what policy applies even \nif they don't know the extension, they just won't know about the ours \nrelationship.\n\nLorrie\n\n\n\n", "id": "lists-017-6856116"}, {"subject": "RE: P3P 1.1 Domain Relationship", "content": "I would say no, a user agent should not make that inference. I can add a\nstatement to the spec stating that the user agent can only apply the \"ours\"\nrelationship to the two hosts involved -- that the relationship is not\ntransitive due to the possibility of B being an agent for both A and C,\nwhich are completely separate entities.\n\n++Jack++\n\n-----Original Message-----\nFrom: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\nSent: Wednesday, February 11, 2004 3:26 PM\nTo: 'Lorrie Cranor'; Humphrey, Jack\nCc: public-p3p-spec@w3.org\nSubject: RE: P3P 1.1 Domain Relationships\n\n\nQuestion:\n\nDoes this address A=B, B=C but A<>C?  So imagine the case where hosts on\ndifferent domains www.a.com and www.b.com list each other as reciprocal\nknown hosts.  Also imagine www.b.com and www.c.com describe the same\nrelationship, should a user agent be able to make inferences about the\nrelationship between www.a.com and www.c.com?\n\n\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org [mailto:public-p3p-spec-request@w3.org]\nOn Behalf Of Lorrie Cranor\nSent: Tuesday, February 10, 2004 4:54 PM\nTo: Humphrey, Jack\nCc: public-p3p-spec@w3.org\nSubject: Re: P3P 1.1 Domain Relationships\n\n\n\nOn Feb 9, 2004, at 12:53 AM, Humphrey, Jack wrote:\n\n> Working Group members,\n>  ?\n> Please read and comment on this latest draft:\n> http://www.w3.org/P3P/2004/02-domain-relationships.html\n> (Apologies, I thought this URL went out with the minutes. Rigo, I \n> don't think it's linked anywhere -- I just guessed the URL.)\n> ?\n\nA few concerns:\n\n- When the HTTP header method is used to refer to a PRF on another \nhost, it only makes sense if the other host has the same file structure \nor if the policy applies to * and/or to all cookies. Otherwise you \ncould end up with conflicts. Perhaps this should be pointed out.\n\n- \"Any number of KNOWN-HOST elements can be declared inside a \nPOLICY-REF  element or inside the POLICY-REFERENCES element. Known host \ndeclarations at the POLICY-REFERENCES level are considered to apply to \nall policies in the file, excluding those that have specific \ndeclarations at the POLICY-REF  level.\" Is this really necessary? For \nsimplicity I think it would be better to put KNOWN-HOST elements only \ninside a POLICY-REF element.\n\n- We should make clear that there is nothing wrong with sites \ncontinuing to refer to PRFs on other hosts without using the KNOWN-HOST \nextension. The extension just buys you extra information about the \nrelationship.\n\n> Here are the open questions/issues I would like to discuss with the \n> group:\n> ?\n> 1. For now, we have dropped the HTTP header mechanism seen in previous \n> drafts. There are two reasons: first of all, changing the P3P HTTP \n> header would require approval of a revised P3P header specification by \n> IETF. Secondly, there is a feeling that the PRF-based mechanism should \n> be a feasible way for user agents to discover this new information, \n> even for those user agents that only use compact policies to manage \n> cookie privacy.\n\nthat makes sense\n\n> ?\n> 2. The last section in the draft (\"Cookie Playback\") states:\n>\n> User agents should be aware that if they allow a cookie to be set \n> based on a relationship established by known host declarations, they \n> should verify that such a relationship exists at cookie playback time, \n> and not send the cookie if it does not. Such verification implies \n> re-fetching the policy reference file and evaluating its known host \n> declarations only if the policy reference file has expired.\n>\n> There is a concern that this language would have an impact on section \n> 2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a \n> policy reference file from a host before replaying a cookie to that \n> host\". Thoughts?\n\nThe only conflict I see is with \"Such verification implies re-fetching \nthe policy reference file and evaluating its known host declarations \nonly if the policy reference file has expired.\" which suggests that the \nre-verification should not be done if the PRF has not expired. While \nthere is no reason to do it if the PRF has not expired, I don't think \nwe need to say it shouldn't be done. What if we said instead \"Such \nverification implies re-fetching an expired policy reference file and \nevaluating its known host declarations.\"\n\n>\n> 3. The section in the draft entitled \"HTTP Header Requirement\" states:\n>\n>\n> The KNOWN-HOST extension relies on the use of the \"P3P: policyref\" \n> HTTP header for one site to refer to a policy reference file on \n> another site. Since policy reference files cannot include full URIs in \n> the POLICY-REF INCLUDE elements, sites that rely on placing their \n> policy reference file in the well-known location have no way of \n> referencing policies hosted on other sites.\n>\n> Is it acceptable to require the use the policyref HTTP header for this \n> case? An alternative might be another PRF extension that would allow \n> one PRF to reference another PRF.\n>\n\nHmm... this is not ideal, but I think it is the best solution. If we \nwere to add another extension than a user agent that was not aware of \nthe extension would not be able to apply the policy at all. As it is \nwritten now, user agents can still figure out what policy applies even \nif they don't know the extension, they just won't know about the ours \nrelationship.\n\nLorrie\n\n\n\n", "id": "lists-017-6869838"}, {"subject": "proposal to deprecate compact policie", "content": "Dear all, \n\ncompact policies in P3P 1.0 were added in the last minute. They were\nvery controversial but still made it into the 1.0 Recommendation. \n\nNow we have the new discussion about the compact format. \nThis new discussion war triggered by feedback from web-site implementers\nand by feedback from 2 P3P workshops. In fact, by aggregating the whole\nrather complex structure of a full P3P Policy into a set of simple\ntokens with no relationship to each other, the assertion made by compact \npolicies can get inaccurate from blurry to heavy overstatements.\n\nWe discussed and offered to discuss the performance implications many\ntimes. With known-hosts we make asynchronus evaluation even easier. We\noffered to work on enhancing the compact format to give it at least \n'some' structure, but there was no interest.\n\nNow the time has come to deprecate compact policies and to throw that\nburden over board. This means, Web-sites can still put up some tokens to\nmake some P3P 1.0 agents happy, but the basis for semi-automatic\ndecision-making in P3P 1.1 will be only based on the full XML format. At\nleast, this is my suggestion.\n\nBest, \n\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-6884789"}, {"subject": "Re: proposal to deprecate compact policie", "content": "Hi Rigo,\n\nThis is written for poeple that may not have been around back when we\ndid cookies.\n\n> compact policies in P3P 1.0 were added in the last minute. They were\n> very controversial but still made it into the 1.0 Recommendation. \n\nWell, a history in two sentences is bound to have some simplifications.\n\nDan Jaye and I (then of the now profoundly cratered dotGone Engage/CMGI)\nhad a http trust mechanim for state management, originating from the PICS\nlabel problem area, which proposed to deliver a label set and a trust\nproperty. We took some of the label space present in P3P, circa Fall '00,\nsubstituting an abnf syntax for the xml syntax, and tried to keep the\nbyte count down. We also removed the digital signature portion of the\nproposal.\n\nThere was controversy over the label semantics (doubleclick vs cmgi).\nThere was controversy over the label syntax (anything vs xml).\nThere was controversy over the equivalence of the semantic scope of the\nlabel space (self-policied objects vs url-reference-policied objects).\nThere was (implicit) controversy over the over-the-wire cost of policy\ndelivery, hence of the tractible complexity of policy evaluation within\na single DOM tree. [I never considered the stream problem, and I don't\nrecall anyone else doing so either.]\n\nThere was also Microsoft's \"cookie patch\" in IE5.5, which really trumped\nstandards-based realities.\n\nAt the November meeting in Palo Alto Microsoft insisted on a mechanism for\npolicy evaluation for cookies, and Engage insisted on the adoption of a\non-cookie policy delivery mechanism. Each for their own reasons (tractible\nDOM eval by brower-implementor MS, tractible third-party policied object\ndelivery by ad-network-implementor CMGI).\n\nXML, part of the label space, including round-trip one-to-one and on-to\nsemantic properties were evaluated and discarded.\n\n> Now we have the new discussion about the compact format. \n> This new discussion war triggered by feedback from web-site implementers\n> and by feedback from 2 P3P workshops. In fact, by aggregating the whole\n> rather complex structure of a full P3P Policy into a set of simple\n> tokens with no relationship to each other, the assertion made by compact \n> policies can get inaccurate from blurry to heavy overstatements.\n> \n> We discussed and offered to discuss the performance implications many\n> times. With known-hosts we make asynchronus evaluation even easier. We\n> offered to work on enhancing the compact format to give it at least \n> 'some' structure, but there was no interest.\n> \n> Now the time has come to deprecate compact policies and to throw that\n> burden over board. This means, Web-sites can still put up some tokens to\n> make some P3P 1.0 agents happy, but the basis for semi-automatic\n> decision-making in P3P 1.1 will be only based on the full XML format. At\n> least, this is my suggestion.\n\nThis isn't paid work for me. Little is, but that's a feature, I guess.\n\nOne of the non-profit and/or left-of-center email/webservice shops in the\nUS is Kintera.org. They handle the retail mass mailings for the Dennis\nKucinich (left Democrat) for President campaign. In every html mailing is\na 1x1 gif, a web bug. See my note at Lisa English's blog \"Ruminate This\",\nthe article id is http://www.ruminatethis.com/archives/001702.html for a\ncollection of Kintera web bugs on Kucinich mailings.\n\nIgnoring the point that these 1x1 gifs are delivered from URLs that could\nin principle be correctly policied, and the point that Kintera is about as\nfar from the principle of informed disclosure and good table manners as a\nStasi agent pickled in Soviet vodka, or John Ashcroft sober, it is possible\nthat large objects could be made out of small objects, and that the small\nobjects may not have a common point of origin, and that some good can come\nout of a policy delivery mechanism that scales, and does not require some\nproperty absent from those two properties -- (1) many and (2) diverse.\n\nAnyway, as I wrote 15 minutes earlier, this isn't paid work for me, nor is\nit prestige work. The W3C is about things that about 100 companies pay real\nmoney for, so this comment is ... insubstantial.\n\nThanks for reading,\nEric\n\n\n\n", "id": "lists-017-6893283"}, {"subject": "RE: P3P 1.1 Domain Relationship", "content": "I think this may present problems for the exact reason you cite, if B is an\nagent of A and C then do we truly have a \"same entity\" relationship? or have\nwe mixed in agents again?  The way I read the language in this proposal, it\nimplies to me that KNOWN HOSTS should be used only if the entity information\nthat would have been listed in separate policy files is (would have been)\nidentical.  I think that if a transitive association of policies can be\nimplied by this mechanism it should be a requirement that the independent\npolicies would have listed materially the same entity information.\n\nI guess the question becomes, \"is known hosts saying that the practices\n(e.g. Categories, Purpose, Recipient, Retention, Access, Disputes) are the\nsame or is it saying the practices and data controller are the same\" (sorry\nI know I used a loaded term with data controller).\n\n-Brooks\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org [mailto:public-p3p-spec-request@w3.org]\nOn Behalf Of Humphrey, Jack\nSent: Thursday, February 12, 2004 2:36 PM\nTo: 'Dobbs, Brooks'; 'Lorrie Cranor'\nCc: public-p3p-spec@w3.org\nSubject: RE: P3P 1.1 Domain Relationships\n\n\nI would say no, a user agent should not make that inference. I can add a\nstatement to the spec stating that the user agent can only apply the \"ours\"\nrelationship to the two hosts involved -- that the relationship is not\ntransitive due to the possibility of B being an agent for both A and C,\nwhich are completely separate entities.\n\n++Jack++\n\n-----Original Message-----\nFrom: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\nSent: Wednesday, February 11, 2004 3:26 PM\nTo: 'Lorrie Cranor'; Humphrey, Jack\nCc: public-p3p-spec@w3.org\nSubject: RE: P3P 1.1 Domain Relationships\n\n\nQuestion:\n\nDoes this address A=B, B=C but A<>C?  So imagine the case where hosts on\ndifferent domains www.a.com and www.b.com list each other as reciprocal\nknown hosts.  Also imagine www.b.com and www.c.com describe the same\nrelationship, should a user agent be able to make inferences about the\nrelationship between www.a.com and www.c.com?\n\n\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org [mailto:public-p3p-spec-request@w3.org]\nOn Behalf Of Lorrie Cranor\nSent: Tuesday, February 10, 2004 4:54 PM\nTo: Humphrey, Jack\nCc: public-p3p-spec@w3.org\nSubject: Re: P3P 1.1 Domain Relationships\n\n\n\nOn Feb 9, 2004, at 12:53 AM, Humphrey, Jack wrote:\n\n> Working Group members,\n>  ?\n> Please read and comment on this latest draft:\n> http://www.w3.org/P3P/2004/02-domain-relationships.html\n> (Apologies, I thought this URL went out with the minutes. Rigo, I \n> don't think it's linked anywhere -- I just guessed the URL.)\n> ?\n\nA few concerns:\n\n- When the HTTP header method is used to refer to a PRF on another \nhost, it only makes sense if the other host has the same file structure \nor if the policy applies to * and/or to all cookies. Otherwise you \ncould end up with conflicts. Perhaps this should be pointed out.\n\n- \"Any number of KNOWN-HOST elements can be declared inside a \nPOLICY-REF  element or inside the POLICY-REFERENCES element. Known host \ndeclarations at the POLICY-REFERENCES level are considered to apply to \nall policies in the file, excluding those that have specific \ndeclarations at the POLICY-REF  level.\" Is this really necessary? For \nsimplicity I think it would be better to put KNOWN-HOST elements only \ninside a POLICY-REF element.\n\n- We should make clear that there is nothing wrong with sites \ncontinuing to refer to PRFs on other hosts without using the KNOWN-HOST \nextension. The extension just buys you extra information about the \nrelationship.\n\n> Here are the open questions/issues I would like to discuss with the \n> group:\n> ?\n> 1. For now, we have dropped the HTTP header mechanism seen in previous \n> drafts. There are two reasons: first of all, changing the P3P HTTP \n> header would require approval of a revised P3P header specification by \n> IETF. Secondly, there is a feeling that the PRF-based mechanism should \n> be a feasible way for user agents to discover this new information, \n> even for those user agents that only use compact policies to manage \n> cookie privacy.\n\nthat makes sense\n\n> ?\n> 2. The last section in the draft (\"Cookie Playback\") states:\n>\n> User agents should be aware that if they allow a cookie to be set \n> based on a relationship established by known host declarations, they \n> should verify that such a relationship exists at cookie playback time, \n> and not send the cookie if it does not. Such verification implies \n> re-fetching the policy reference file and evaluating its known host \n> declarations only if the policy reference file has expired.\n>\n> There is a concern that this language would have an impact on section \n> 2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a \n> policy reference file from a host before replaying a cookie to that \n> host\". Thoughts?\n\nThe only conflict I see is with \"Such verification implies re-fetching \nthe policy reference file and evaluating its known host declarations \nonly if the policy reference file has expired.\" which suggests that the \nre-verification should not be done if the PRF has not expired. While \nthere is no reason to do it if the PRF has not expired, I don't think \nwe need to say it shouldn't be done. What if we said instead \"Such \nverification implies re-fetching an expired policy reference file and \nevaluating its known host declarations.\"\n\n>\n> 3. The section in the draft entitled \"HTTP Header Requirement\" states:\n>\n>\n> The KNOWN-HOST extension relies on the use of the \"P3P: policyref\" \n> HTTP header for one site to refer to a policy reference file on \n> another site. Since policy reference files cannot include full URIs in \n> the POLICY-REF INCLUDE elements, sites that rely on placing their \n> policy reference file in the well-known location have no way of \n> referencing policies hosted on other sites.\n>\n> Is it acceptable to require the use the policyref HTTP header for this \n> case? An alternative might be another PRF extension that would allow \n> one PRF to reference another PRF.\n>\n\nHmm... this is not ideal, but I think it is the best solution. If we \nwere to add another extension than a user agent that was not aware of \nthe extension would not be able to apply the policy at all. As it is \nwritten now, user agents can still figure out what policy applies even \nif they don't know the extension, they just won't know about the ours \nrelationship.\n\nLorrie\n\n\n\n", "id": "lists-017-6904835"}, {"subject": "Re: P3P 1.1 Domain Relationship", "content": "On Feb 13, 2004, at 2:43 PM, Dobbs, Brooks wrote:\n\n>\n> I think this may present problems for the exact reason you cite, if B \n> is an\n> agent of A and C then do we truly have a \"same entity\" relationship? \n> or have\n> we mixed in agents again?  The way I read the language in this \n> proposal, it\n> implies to me that KNOWN HOSTS should be used only if the entity \n> information\n> that would have been listed in separate policy files is (would have \n> been)\n> identical.  I think that if a transitive association of policies can be\n> implied by this mechanism it should be a requirement that the \n> independent\n> policies would have listed materially the same entity information.\n>\n> I guess the question becomes, \"is known hosts saying that the practices\n> (e.g. Categories, Purpose, Recipient, Retention, Access, Disputes) are \n> the\n> same or is it saying the practices and data controller are the same\" \n> (sorry\n> I know I used a loaded term with data controller).\n>\n\nMy understanding is that KNOWN-HOST lets host A point to a PRF and \npolicy on host B instead of declaring their own policy.  So there is no \nother policy to be the same with.\n\nLorrie\n\n\n\n> -Brooks\n>\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org \n> [mailto:public-p3p-spec-request@w3.org]\n> On Behalf Of Humphrey, Jack\n> Sent: Thursday, February 12, 2004 2:36 PM\n> To: 'Dobbs, Brooks'; 'Lorrie Cranor'\n> Cc: public-p3p-spec@w3.org\n> Subject: RE: P3P 1.1 Domain Relationships\n>\n>\n> I would say no, a user agent should not make that inference. I can add \n> a\n> statement to the spec stating that the user agent can only apply the \n> \"ours\"\n> relationship to the two hosts involved -- that the relationship is not\n> transitive due to the possibility of B being an agent for both A and C,\n> which are completely separate entities.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\n> Sent: Wednesday, February 11, 2004 3:26 PM\n> To: 'Lorrie Cranor'; Humphrey, Jack\n> Cc: public-p3p-spec@w3.org\n> Subject: RE: P3P 1.1 Domain Relationships\n>\n>\n> Question:\n>\n> Does this address A=B, B=C but A<>C?  So imagine the case where hosts \n> on\n> different domains www.a.com and www.b.com list each other as reciprocal\n> known hosts.  Also imagine www.b.com and www.c.com describe the same\n> relationship, should a user agent be able to make inferences about the\n> relationship between www.a.com and www.c.com?\n>\n>\n>\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org \n> [mailto:public-p3p-spec-request@w3.org]\n> On Behalf Of Lorrie Cranor\n> Sent: Tuesday, February 10, 2004 4:54 PM\n> To: Humphrey, Jack\n> Cc: public-p3p-spec@w3.org\n> Subject: Re: P3P 1.1 Domain Relationships\n>\n>\n>\n> On Feb 9, 2004, at 12:53 AM, Humphrey, Jack wrote:\n>\n>> Working Group members,\n>>  ?\n>> Please read and comment on this latest draft:\n>> http://www.w3.org/P3P/2004/02-domain-relationships.html\n>> (Apologies, I thought this URL went out with the minutes. Rigo, I\n>> don't think it's linked anywhere -- I just guessed the URL.)\n>> ?\n>\n> A few concerns:\n>\n> - When the HTTP header method is used to refer to a PRF on another\n> host, it only makes sense if the other host has the same file structure\n> or if the policy applies to * and/or to all cookies. Otherwise you\n> could end up with conflicts. Perhaps this should be pointed out.\n>\n> - \"Any number of KNOWN-HOST elements can be declared inside a\n> POLICY-REF  element or inside the POLICY-REFERENCES element. Known host\n> declarations at the POLICY-REFERENCES level are considered to apply to\n> all policies in the file, excluding those that have specific\n> declarations at the POLICY-REF  level.\" Is this really necessary? For\n> simplicity I think it would be better to put KNOWN-HOST elements only\n> inside a POLICY-REF element.\n>\n> - We should make clear that there is nothing wrong with sites\n> continuing to refer to PRFs on other hosts without using the KNOWN-HOST\n> extension. The extension just buys you extra information about the\n> relationship.\n>\n>> Here are the open questions/issues I would like to discuss with the\n>> group:\n>> ?\n>> 1. For now, we have dropped the HTTP header mechanism seen in previous\n>> drafts. There are two reasons: first of all, changing the P3P HTTP\n>> header would require approval of a revised P3P header specification by\n>> IETF. Secondly, there is a feeling that the PRF-based mechanism should\n>> be a feasible way for user agents to discover this new information,\n>> even for those user agents that only use compact policies to manage\n>> cookie privacy.\n>\n> that makes sense\n>\n>> ?\n>> 2. The last section in the draft (\"Cookie Playback\") states:\n>>\n>> User agents should be aware that if they allow a cookie to be set\n>> based on a relationship established by known host declarations, they\n>> should verify that such a relationship exists at cookie playback time,\n>> and not send the cookie if it does not. Such verification implies\n>> re-fetching the policy reference file and evaluating its known host\n>> declarations only if the policy reference file has expired.\n>>\n>> There is a concern that this language would have an impact on section\n>> 2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a\n>> policy reference file from a host before replaying a cookie to that\n>> host\". Thoughts?\n>\n> The only conflict I see is with \"Such verification implies re-fetching\n> the policy reference file and evaluating its known host declarations\n> only if the policy reference file has expired.\" which suggests that the\n> re-verification should not be done if the PRF has not expired. While\n> there is no reason to do it if the PRF has not expired, I don't think\n> we need to say it shouldn't be done. What if we said instead \"Such\n> verification implies re-fetching an expired policy reference file and\n> evaluating its known host declarations.\"\n>\n>>\n>> 3. The section in the draft entitled \"HTTP Header Requirement\" states:\n>>\n>>\n>> The KNOWN-HOST extension relies on the use of the \"P3P: policyref\"\n>> HTTP header for one site to refer to a policy reference file on\n>> another site. Since policy reference files cannot include full URIs in\n>> the POLICY-REF INCLUDE elements, sites that rely on placing their\n>> policy reference file in the well-known location have no way of\n>> referencing policies hosted on other sites.\n>>\n>> Is it acceptable to require the use the policyref HTTP header for this\n>> case? An alternative might be another PRF extension that would allow\n>> one PRF to reference another PRF.\n>>\n>\n> Hmm... this is not ideal, but I think it is the best solution. If we\n> were to add another extension than a user agent that was not aware of\n> the extension would not be able to apply the policy at all. As it is\n> written now, user agents can still figure out what policy applies even\n> if they don't know the extension, they just won't know about the ours\n> relationship.\n>\n> Lorrie\n>\n\n\n\n", "id": "lists-017-6922051"}, {"subject": "linke", "content": "we discussed bugzilla 172 \nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172 on last week's call \nand I proposed a possible way of differentiating linked and linkable. \nThe following is my proposal for text for the spec to document this. \nPlease send your comments and let me know if this idea even makes any \nsense.\n\nLorrie\n\n\nI propose that we remove the last 3 paragraphs of 1.3.2 that pertain\nto \"linked\" data and change the title of that section to\n\"Non-identifiable\" Data. Then add a new section 1.3.4 as follows:\n\n\n1.3.4 Linked and Linkable Data\n\n<p>Cookies often store a unique number or database key that links to a\ndatabase record, rather than storing the complete database record. Web\nsites that use P3P must disclose not only the types of data stored\ndirectly in a cookie, but also all data linked to a cookie. A large\namount of data may be \"linkable\" to a cookie without actually being\n\"linked\" to that cookie. </p>\n\n<p>A piece of data X is said to be <i>linkable</i> to a cookie Y if a\nkey stored in cookie Y can be used to retrieve X either directly or\nindirectly. A direct retrieval might happen, for example, if the key\nis associated with a database record in which X is stored. An indirect\nretrieval might happen, for example, if the key is associated with a\ndatabase record that contains a piece of data that may be used, in\nturn, as a key to retrieve a record in a second database, and X is\nstored in the second database. Furthermore, if cookie Y is stored in a\nserver log file, the log file may facilitate further linking. For\nexample, imagine a web site that sets two cookies, Y and Z. Cookies Y\nand Z may get replayed in the same HTTP request and subsequently\nrecorded side-by-side in the server log file. Thus all data associated\nwith cookie Y are also linkable to cookie Z. Indeed, unless\nprecautions are taken to minimize server log files and severely restrict\nthe use of identifiable data, almost all data an entity stores about\nan individual are likely to be linkable to any cookies they have set\non that individual's computer.</p>\n\n<p>A piece of data X is said to be <i>linked</i> to a cookie Y if at\nleast one of the following activities may take place as a result of\ncookie Y being replayed:</p>\n\n<ul>\n\n<li>X is retrieved from a database.</li>\n\n<li>Information collected about the user during the current session --\nincluding data entered into forms, IP address, clickstream data,\nclient events, or other data associated with the user's visit to the\nweb site -- is added to a record in which X is stored.</li>\n\n</ul>\n\n<p>\nIf either of these activities happen immediately upon cookie replay or\nat some future time (perhaps as a result of retrospective analysis of\nserver logs), then the piece of data X is considered linked to cookie Y.\n</p>\n\n<p>Entities should consider their data collection and storage\narchitectures carefully to determine what data may be linkable to\ntheir cookies and what data will actually be linked to each cookie. If\ndata is linkable but does not actually get linked to a particular\ncookie, it does not have to be disclosed in a P3P statement concerning\nthat cookie. However, should the entity associated with that P3P\npolicy ever link the data for any reason other than to comply with law\nenforcement demands, they would be in violation of their stated\npolicy. </p>\n\n\n\n", "id": "lists-017-6939344"}, {"subject": "RE: linke", "content": "Some comments:\n1. I don't think the requirement that it be stored as a particular database\nrecord is valid. I think that linkability should be described independently\nof the technical architecture used. This is why I tried to describe it in\nterms of the intentions and proportionality.\n2. You do not mention the use of referers to link cookies together.\n3. I think the examples given are simpler than those I gave.\n\n\n>**\n>**I propose that we remove the last 3 paragraphs of 1.3.2 that \n>**pertain to \"linked\" data and change the title of that \n>**section to \"Non-identifiable\" Data. Then add a new section \n>**1.3.4 as follows:\n>**\n>**\n>**1.3.4 Linked and Linkable Data\n>**\n>**<p>Cookies often store a unique number or database key that \n>**links to a database record, rather than storing the complete \n>**database record. Web sites that use P3P must disclose not \n>**only the types of data stored directly in a cookie, but also \n>**all data linked to a cookie. A large amount of data may be \n>**\"linkable\" to a cookie without actually being \"linked\" to \n>**that cookie. </p>\n>**\n>**<p>A piece of data X is said to be <i>linkable</i> to a \n>**cookie Y if a key stored in cookie Y can be used to retrieve \n>**X either directly or indirectly. A direct retrieval might \n>**happen, for example, if the key is associated with a \n>**database record in which X is stored. An indirect retrieval \n>**might happen, for example, if the key is associated with a \n>**database record that contains a piece of data that may be \n>**used, in turn, as a key to retrieve a record in a second \n>**database, and X is stored in the second database. \n>**Furthermore, if cookie Y is stored in a server log file, the \n>**log file may facilitate further linking. For example, \n>**imagine a web site that sets two cookies, Y and Z. Cookies Y \n>**and Z may get replayed in the same HTTP request and \n>**subsequently recorded side-by-side in the server log file. \n>**Thus all data associated with cookie Y are also linkable to \n>**cookie Z. Indeed, unless precautions are taken to minimize \n>**server log files and severely restrict the use of \n>**identifiable data, almost all data an entity stores about an \n>**individual are likely to be linkable to any cookies they \n>**have set on that individual's computer.</p>\n>**\n>**<p>A piece of data X is said to be <i>linked</i> to a cookie \n>**Y if at least one of the following activities may take place \n>**as a result of cookie Y being replayed:</p>\n>**\n>**<ul>\n>**\n>**<li>X is retrieved from a database.</li>\n>**\n>**<li>Information collected about the user during the current \n>**session -- including data entered into forms, IP address, \n>**clickstream data, client events, or other data associated \n>**with the user's visit to the web site -- is added to a \n>**record in which X is stored.</li>\n>**\n>**</ul>\n>**\n>**<p>\n>**If either of these activities happen immediately upon cookie \n>**replay or at some future time (perhaps as a result of \n>**retrospective analysis of server logs), then the piece of \n>**data X is considered linked to cookie Y. </p>\n>**\n>**<p>Entities should consider their data collection and \n>**storage architectures carefully to determine what data may \n>**be linkable to their cookies and what data will actually be \n>**linked to each cookie. If data is linkable but does not \n>**actually get linked to a particular cookie, it does not have \n>**to be disclosed in a P3P statement concerning that cookie. \n>**However, should the entity associated with that P3P policy \n>**ever link the data for any reason other than to comply with \n>**law enforcement demands, they would be in violation of their \n>**stated policy. </p>\n>**\n>**\n\n\n\n", "id": "lists-017-6949614"}, {"subject": "[FYI] P3P 1.1 on xml coverpage", "content": "http://xml.coverpages.org/ni2004-02-12-a.html\n\nThey seem to have some automatic conversion tool from the spec to their\narticles..\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-6960630"}, {"subject": "Re: linke", "content": "I concur with the remarks from Giles. Some additional rant:\n\nOn Sun, Feb 15, 2004 at 05:51:41PM -0500, Lorrie Cranor wrote:\n> \n> we discussed bugzilla 172 \n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=172 on last week's call \n> and I proposed a possible way of differentiating linked and linkable. \n> The following is my proposal for text for the spec to document this. \n> Please send your comments and let me know if this idea even makes any \n> sense.\n> \n> <li>X is retrieved from a database.</li>\n> \n> <li>Information collected about the user during the current session --\n> including data entered into forms, IP address, clickstream data,\n> client events, or other data associated with the user's visit to the\n> web site -- is added to a record in which X is stored.</li>\n\nWe shouldn't restrict data collection to the current session. The more\nevil stuff remembers previous sessions and continues recording. Perhaps\nwe need to separate the discussion of what has to be declared (and a way\nto declare that things are _added_ to a profile) from the question of\nwhat linkable means.\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-6966931"}, {"subject": "Re: linke", "content": "Rigo,\n\nThis seems to be my week for playing old songs. At the same meeting I wrote\nabout a few days ago (November f2f Palo Alto), we went round and around on\nthe cookie linkage issue.\n\nWe achived agreement to require linkage disclosure, to the disapointment of\ntwo or three of Engage's competitiors (if memory serves) in the ad network\nbusiness, who observed, inter alia, that they'd have to cookie twice, once\nwith a no-pii cookie, once with a pii cookie, to link non-session data to a\npoliced cookie.\n\nSo, it is my sense of where \"we\" were \"then\", that the following is accurate:\n\nWe shouldn't restrict data collection to the current session.\n\nWe already agreed to show the existance of extra-session state, and that was\nthe correct choice.\n\nEric\n\n\n\n", "id": "lists-017-6975050"}, {"subject": "Re: linke", "content": "On Feb 16, 2004, at 4:59 AM, Giles Hogben wrote:\n\n>\n> Some comments:\n> 1. I don't think the requirement that it be stored as a particular \n> database\n> record is valid. I think that linkability should be described \n> independently\n> of the technical architecture used. This is why I tried to describe it \n> in\n> terms of the intentions and proportionality.\n\nThis actually goes to the heart I what I was trying to do... I wanted \nto define \"linkable\" independently of technical architecture but define \n\"linked\" more narrowly. So far I haven't come up with an example of an \narchitecture in which we would want to say that data is linked and does \nnot involve either triggering a database retrieval or storage. Perhaps \nyou have an example?\n\n> 2. You do not mention the use of referers to link cookies together.\n\nI will add that.\n\n> 3. I think the examples given are simpler than those I gave.\n>\n\nIs that a good thing or a bad thing?\n\n\nLorrie\n\n\n\n", "id": "lists-017-6982781"}, {"subject": "Re: linke", "content": "On Feb 16, 2004, at 12:12 PM, Rigo Wenning wrote:\n\n>\n> I concur with the remarks from Giles. Some additional rant:\n>\n> On Sun, Feb 15, 2004 at 05:51:41PM -0500, Lorrie Cranor wrote:\n>>\n>> we discussed bugzilla 172\n>> http://www.w3.org/Bugs/Public/show_bug.cgi?id=172 on last week's call\n>> and I proposed a possible way of differentiating linked and linkable.\n>> The following is my proposal for text for the spec to document this.\n>> Please send your comments and let me know if this idea even makes any\n>> sense.\n>>\n>> <li>X is retrieved from a database.</li>\n>>\n>> <li>Information collected about the user during the current session --\n>> including data entered into forms, IP address, clickstream data,\n>> client events, or other data associated with the user's visit to the\n>> web site -- is added to a record in which X is stored.</li>\n>\n> We shouldn't restrict data collection to the current session. The more\n> evil stuff remembers previous sessions and continues recording. Perhaps\n> we need to separate the discussion of what has to be declared (and a \n> way\n> to declare that things are _added_ to a profile) from the question of\n> what linkable means.\n>\n\nWhat if I reformulated the second bullet of the linked definition as \nfollows... note that\nI used the term \"identifiable\" here rather than \"identified\"... I\nthink that best reflects what we mean in this case.\n\n<p>A piece of data X is said to be <i>linked</i> to a cookie Y if at\nleast one of the following activities may take place as a result of\ncookie Y being replayed:</p>\n\n<ul>\n\n<li>X is retrieved from a database.</li>\n\n<li>Information identifiable with the user -- including but not\nlimited to data entered into forms, IP address, clickstream data, and\nclient events -- is added to a record in which X is stored.</li>\n\n</ul>\n\n<p>\nIf either of these activities happen immediately upon cookie replay or\nat some future time (perhaps as a result of retrospective analysis of\nserver logs), then the piece of data X is considered linked to cookie Y.\n</p>\n\n\n\n", "id": "lists-017-6990859"}, {"subject": "Re: linke", "content": "On Mon, Feb 16, 2004 at 02:05:15PM -0500, Lorrie Cranor wrote:\n> \n> What if I reformulated the second bullet of the linked definition as \n> follows... note that\n> I used the term \"identifiable\" here rather than \"identified\"... I\n> think that best reflects what we mean in this case.\n> \n> <p>A piece of data X is said to be <i>linked</i> to a cookie Y if at\n> least one of the following activities may take place as a result of\n> cookie Y being replayed:</p>\n> \n> <ul>\n> \n> <li>X is retrieved from a database.</li>\n\nOne short remark: If you would say retrieved and omit the database,\ninterpretation will find that X has to be retrieved somewhere, from a\ndatabase or some foo semantic web that will be created in five years :)\n> \n> <li>Information identifiable with the user -- including but not\n> limited to data entered into forms, IP address, clickstream data, and\n> client events -- is added to a record in which X is stored.</li>\n> \n> </ul>\n> \n> <p>\n> If either of these activities happen immediately upon cookie replay or\n> at some future time (perhaps as a result of retrospective analysis of\n> server logs), then the piece of data X is considered linked to cookie Y.\n> </p>\n\nThis is okay with me.\n\nRigo\n\n\n\n", "id": "lists-017-7000185"}, {"subject": "RE: linke", "content": ">**On Feb 16, 2004, at 4:59 AM, Giles Hogben wrote:\n>**\n>**>\n>**> Some comments:\n>**> 1. I don't think the requirement that it be stored as a particular\n>**> database\n>**> record is valid. I think that linkability should be described \n>**> independently\n>**> of the technical architecture used. This is why I tried to \n>**describe it \n>**> in\n>**> terms of the intentions and proportionality.\n>**\n>**This actually goes to the heart of what I was trying to do... \n>**I wanted \n>**to define \"linkable\" independently of technical architecture \n>**but define \n>**\"linked\" more narrowly. So far I haven't come up with an \n>**example of an \n>**architecture in which we would want to say that data is \n>**linked and does \n>**not involve either triggering a database retrieval or \n>**storage. Perhaps \n>**you have an example?\n>**\n\nCookies and files used in forensics are not linked to a database. Server\nlogs are not really databases?\n\n>**> 2. You do not mention the use of referers to link cookies together.\n>**\n>**I will add that.\n>**\n>**> 3. I think the examples given are simpler than those I gave.\n>**>\n>**\n>**Is that a good thing or a bad thing?\n>**\nThat is a good thing.\n\n>**\n>**Lorrie\n>**\n>**\n\n\n\n", "id": "lists-017-7007963"}, {"subject": "Re: linke", "content": "Nits.\n\n> ... is retrieved from a database ...\n\n1. s/database/persistent store/\n\n2. s/persistent store/& or archival media/\n\n-e\n\n\n\n", "id": "lists-017-7016562"}, {"subject": "RE: P3P 1.1 Domain Relationship", "content": "Okay phrased badly on my part.  I guess my point is simply that if A and C\nboth point to the exact same policy (on B and shared by B) using \"same\nentity\", it seems logical to me to infer that A and C are themselves the\nsame entity?  No?\n\n-B\n \n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu] \nSent: Friday, February 13, 2004 10:37 PM\nTo: Dobbs, Brooks\nCc: 'Humphrey, Jack'; public-p3p-spec@w3.org\nSubject: Re: P3P 1.1 Domain Relationships\n\n\n\nOn Feb 13, 2004, at 2:43 PM, Dobbs, Brooks wrote:\n\n>\n> I think this may present problems for the exact reason you cite, if B\n> is an\n> agent of A and C then do we truly have a \"same entity\" relationship? \n> or have\n> we mixed in agents again?  The way I read the language in this \n> proposal, it\n> implies to me that KNOWN HOSTS should be used only if the entity \n> information\n> that would have been listed in separate policy files is (would have \n> been)\n> identical.  I think that if a transitive association of policies can be\n> implied by this mechanism it should be a requirement that the \n> independent\n> policies would have listed materially the same entity information.\n>\n> I guess the question becomes, \"is known hosts saying that the \n> practices (e.g. Categories, Purpose, Recipient, Retention, Access, \n> Disputes) are the same or is it saying the practices and data \n> controller are the same\" (sorry\n> I know I used a loaded term with data controller).\n>\n\nMy understanding is that KNOWN-HOST lets host A point to a PRF and \npolicy on host B instead of declaring their own policy.  So there is no \nother policy to be the same with.\n\nLorrie\n\n\n\n> -Brooks\n>\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org \n> [mailto:public-p3p-spec-request@w3.org]\n> On Behalf Of Humphrey, Jack\n> Sent: Thursday, February 12, 2004 2:36 PM\n> To: 'Dobbs, Brooks'; 'Lorrie Cranor'\n> Cc: public-p3p-spec@w3.org\n> Subject: RE: P3P 1.1 Domain Relationships\n>\n>\n> I would say no, a user agent should not make that inference. I can add \n> a\n> statement to the spec stating that the user agent can only apply the \n> \"ours\"\n> relationship to the two hosts involved -- that the relationship is not\n> transitive due to the possibility of B being an agent for both A and C,\n> which are completely separate entities.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\n> Sent: Wednesday, February 11, 2004 3:26 PM\n> To: 'Lorrie Cranor'; Humphrey, Jack\n> Cc: public-p3p-spec@w3.org\n> Subject: RE: P3P 1.1 Domain Relationships\n>\n>\n> Question:\n>\n> Does this address A=B, B=C but A<>C?  So imagine the case where hosts \n> on\n> different domains www.a.com and www.b.com list each other as reciprocal\n> known hosts.  Also imagine www.b.com and www.c.com describe the same\n> relationship, should a user agent be able to make inferences about the\n> relationship between www.a.com and www.c.com?\n>\n>\n>\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org \n> [mailto:public-p3p-spec-request@w3.org]\n> On Behalf Of Lorrie Cranor\n> Sent: Tuesday, February 10, 2004 4:54 PM\n> To: Humphrey, Jack\n> Cc: public-p3p-spec@w3.org\n> Subject: Re: P3P 1.1 Domain Relationships\n>\n>\n>\n> On Feb 9, 2004, at 12:53 AM, Humphrey, Jack wrote:\n>\n>> Working Group members,\n>>  ?\n>> Please read and comment on this latest draft:\n>> http://www.w3.org/P3P/2004/02-domain-relationships.html\n>> (Apologies, I thought this URL went out with the minutes. Rigo, I\n>> don't think it's linked anywhere -- I just guessed the URL.)\n>> ?\n>\n> A few concerns:\n>\n> - When the HTTP header method is used to refer to a PRF on another\n> host, it only makes sense if the other host has the same file structure\n> or if the policy applies to * and/or to all cookies. Otherwise you\n> could end up with conflicts. Perhaps this should be pointed out.\n>\n> - \"Any number of KNOWN-HOST elements can be declared inside a\n> POLICY-REF  element or inside the POLICY-REFERENCES element. Known host\n> declarations at the POLICY-REFERENCES level are considered to apply to\n> all policies in the file, excluding those that have specific\n> declarations at the POLICY-REF  level.\" Is this really necessary? For\n> simplicity I think it would be better to put KNOWN-HOST elements only\n> inside a POLICY-REF element.\n>\n> - We should make clear that there is nothing wrong with sites\n> continuing to refer to PRFs on other hosts without using the KNOWN-HOST\n> extension. The extension just buys you extra information about the\n> relationship.\n>\n>> Here are the open questions/issues I would like to discuss with the\n>> group:\n>> ?\n>> 1. For now, we have dropped the HTTP header mechanism seen in previous\n>> drafts. There are two reasons: first of all, changing the P3P HTTP\n>> header would require approval of a revised P3P header specification by\n>> IETF. Secondly, there is a feeling that the PRF-based mechanism should\n>> be a feasible way for user agents to discover this new information,\n>> even for those user agents that only use compact policies to manage\n>> cookie privacy.\n>\n> that makes sense\n>\n>> ?\n>> 2. The last section in the draft (\"Cookie Playback\") states:\n>>\n>> User agents should be aware that if they allow a cookie to be set\n>> based on a relationship established by known host declarations, they\n>> should verify that such a relationship exists at cookie playback time,\n>> and not send the cookie if it does not. Such verification implies\n>> re-fetching the policy reference file and evaluating its known host\n>> declarations only if the policy reference file has expired.\n>>\n>> There is a concern that this language would have an impact on section\n>> 2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a\n>> policy reference file from a host before replaying a cookie to that\n>> host\". Thoughts?\n>\n> The only conflict I see is with \"Such verification implies re-fetching\n> the policy reference file and evaluating its known host declarations\n> only if the policy reference file has expired.\" which suggests that the\n> re-verification should not be done if the PRF has not expired. While\n> there is no reason to do it if the PRF has not expired, I don't think\n> we need to say it shouldn't be done. What if we said instead \"Such\n> verification implies re-fetching an expired policy reference file and\n> evaluating its known host declarations.\"\n>\n>>\n>> 3. The section in the draft entitled \"HTTP Header Requirement\" states:\n>>\n>>\n>> The KNOWN-HOST extension relies on the use of the \"P3P: policyref\"\n>> HTTP header for one site to refer to a policy reference file on\n>> another site. Since policy reference files cannot include full URIs in\n>> the POLICY-REF INCLUDE elements, sites that rely on placing their\n>> policy reference file in the well-known location have no way of\n>> referencing policies hosted on other sites.\n>>\n>> Is it acceptable to require the use the policyref HTTP header for this\n>> case? An alternative might be another PRF extension that would allow\n>> one PRF to reference another PRF.\n>>\n>\n> Hmm... this is not ideal, but I think it is the best solution. If we\n> were to add another extension than a user agent that was not aware of\n> the extension would not be able to apply the policy at all. As it is\n> written now, user agents can still figure out what policy applies even\n> if they don't know the extension, they just won't know about the ours\n> relationship.\n>\n> Lorrie\n>\n\n\n\n", "id": "lists-017-7023988"}, {"subject": "Re: P3P 1.1 Domain Relationship", "content": "Hmm.... without KNOWN-HOSTS A can use the HTTP header method to \nreference a PRF on B, which is about a policy on B. That policy may or \nmay not actually apply to any URIs on B. With KNOWN-HOSTS, B can \ndeclare that the policy A is referencing is a policy that has been \nestablished as part of an \"ours\" relationship. Before we can answer any \nquestions about transitivity and what not, perhaps we need to actually \nspell out what an ours relationship is. Probably something like:\n\n- A single entity operates host A and host B, but might possibly have \ndifferent policies for host A and host B\n- Host A acts as an agent of host B and all data collection and uses \nare in accordance with host B's policy (or one of host B's policies) \nand are done on behalf of host B - either A or B might be declared as \nthe entity in the policy\n- Host B acts and an agent of host A and all data collection and uses \nare in accordance with host A's policy (or one of host A's policies) \nand are done on behalf of host A - either A or B might be declared as \nthe entity in the policy\n\n\nLorrie\n\n\n\n\nOn Feb 17, 2004, at 9:43 AM, Dobbs, Brooks wrote:\n\n>\n> Okay phrased badly on my part.  I guess my point is simply that if A \n> and C\n> both point to the exact same policy (on B and shared by B) using \"same\n> entity\", it seems logical to me to infer that A and C are themselves \n> the\n> same entity?  No?\n>\n> -B\n>\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Friday, February 13, 2004 10:37 PM\n> To: Dobbs, Brooks\n> Cc: 'Humphrey, Jack'; public-p3p-spec@w3.org\n> Subject: Re: P3P 1.1 Domain Relationships\n>\n>\n>\n> On Feb 13, 2004, at 2:43 PM, Dobbs, Brooks wrote:\n>\n>>\n>> I think this may present problems for the exact reason you cite, if B\n>> is an\n>> agent of A and C then do we truly have a \"same entity\" relationship?\n>> or have\n>> we mixed in agents again?  The way I read the language in this\n>> proposal, it\n>> implies to me that KNOWN HOSTS should be used only if the entity\n>> information\n>> that would have been listed in separate policy files is (would have\n>> been)\n>> identical.  I think that if a transitive association of policies can \n>> be\n>> implied by this mechanism it should be a requirement that the\n>> independent\n>> policies would have listed materially the same entity information.\n>>\n>> I guess the question becomes, \"is known hosts saying that the\n>> practices (e.g. Categories, Purpose, Recipient, Retention, Access,\n>> Disputes) are the same or is it saying the practices and data\n>> controller are the same\" (sorry\n>> I know I used a loaded term with data controller).\n>>\n>\n> My understanding is that KNOWN-HOST lets host A point to a PRF and\n> policy on host B instead of declaring their own policy.  So there is no\n> other policy to be the same with.\n>\n> Lorrie\n>\n>\n>\n>> -Brooks\n>>\n>> -----Original Message-----\n>> From: public-p3p-spec-request@w3.org\n>> [mailto:public-p3p-spec-request@w3.org]\n>> On Behalf Of Humphrey, Jack\n>> Sent: Thursday, February 12, 2004 2:36 PM\n>> To: 'Dobbs, Brooks'; 'Lorrie Cranor'\n>> Cc: public-p3p-spec@w3.org\n>> Subject: RE: P3P 1.1 Domain Relationships\n>>\n>>\n>> I would say no, a user agent should not make that inference. I can add\n>> a\n>> statement to the spec stating that the user agent can only apply the\n>> \"ours\"\n>> relationship to the two hosts involved -- that the relationship is not\n>> transitive due to the possibility of B being an agent for both A and \n>> C,\n>> which are completely separate entities.\n>>\n>> ++Jack++\n>>\n>> -----Original Message-----\n>> From: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\n>> Sent: Wednesday, February 11, 2004 3:26 PM\n>> To: 'Lorrie Cranor'; Humphrey, Jack\n>> Cc: public-p3p-spec@w3.org\n>> Subject: RE: P3P 1.1 Domain Relationships\n>>\n>>\n>> Question:\n>>\n>> Does this address A=B, B=C but A<>C?  So imagine the case where hosts\n>> on\n>> different domains www.a.com and www.b.com list each other as \n>> reciprocal\n>> known hosts.  Also imagine www.b.com and www.c.com describe the same\n>> relationship, should a user agent be able to make inferences about the\n>> relationship between www.a.com and www.c.com?\n>>\n>>\n>>\n>> -----Original Message-----\n>> From: public-p3p-spec-request@w3.org\n>> [mailto:public-p3p-spec-request@w3.org]\n>> On Behalf Of Lorrie Cranor\n>> Sent: Tuesday, February 10, 2004 4:54 PM\n>> To: Humphrey, Jack\n>> Cc: public-p3p-spec@w3.org\n>> Subject: Re: P3P 1.1 Domain Relationships\n>>\n>>\n>>\n>> On Feb 9, 2004, at 12:53 AM, Humphrey, Jack wrote:\n>>\n>>> Working Group members,\n>>>  ?\n>>> Please read and comment on this latest draft:\n>>> http://www.w3.org/P3P/2004/02-domain-relationships.html\n>>> (Apologies, I thought this URL went out with the minutes. Rigo, I\n>>> don't think it's linked anywhere -- I just guessed the URL.)\n>>> ?\n>>\n>> A few concerns:\n>>\n>> - When the HTTP header method is used to refer to a PRF on another\n>> host, it only makes sense if the other host has the same file \n>> structure\n>> or if the policy applies to * and/or to all cookies. Otherwise you\n>> could end up with conflicts. Perhaps this should be pointed out.\n>>\n>> - \"Any number of KNOWN-HOST elements can be declared inside a\n>> POLICY-REF  element or inside the POLICY-REFERENCES element. Known \n>> host\n>> declarations at the POLICY-REFERENCES level are considered to apply to\n>> all policies in the file, excluding those that have specific\n>> declarations at the POLICY-REF  level.\" Is this really necessary? For\n>> simplicity I think it would be better to put KNOWN-HOST elements only\n>> inside a POLICY-REF element.\n>>\n>> - We should make clear that there is nothing wrong with sites\n>> continuing to refer to PRFs on other hosts without using the \n>> KNOWN-HOST\n>> extension. The extension just buys you extra information about the\n>> relationship.\n>>\n>>> Here are the open questions/issues I would like to discuss with the\n>>> group:\n>>> ?\n>>> 1. For now, we have dropped the HTTP header mechanism seen in \n>>> previous\n>>> drafts. There are two reasons: first of all, changing the P3P HTTP\n>>> header would require approval of a revised P3P header specification \n>>> by\n>>> IETF. Secondly, there is a feeling that the PRF-based mechanism \n>>> should\n>>> be a feasible way for user agents to discover this new information,\n>>> even for those user agents that only use compact policies to manage\n>>> cookie privacy.\n>>\n>> that makes sense\n>>\n>>> ?\n>>> 2. The last section in the draft (\"Cookie Playback\") states:\n>>>\n>>> User agents should be aware that if they allow a cookie to be set\n>>> based on a relationship established by known host declarations, they\n>>> should verify that such a relationship exists at cookie playback \n>>> time,\n>>> and not send the cookie if it does not. Such verification implies\n>>> re-fetching the policy reference file and evaluating its known host\n>>> declarations only if the policy reference file has expired.\n>>>\n>>> There is a concern that this language would have an impact on section\n>>> 2.3.2.7 of the P3P spec, which says that a user agent \"MAY request a\n>>> policy reference file from a host before replaying a cookie to that\n>>> host\". Thoughts?\n>>\n>> The only conflict I see is with \"Such verification implies re-fetching\n>> the policy reference file and evaluating its known host declarations\n>> only if the policy reference file has expired.\" which suggests that \n>> the\n>> re-verification should not be done if the PRF has not expired. While\n>> there is no reason to do it if the PRF has not expired, I don't think\n>> we need to say it shouldn't be done. What if we said instead \"Such\n>> verification implies re-fetching an expired policy reference file and\n>> evaluating its known host declarations.\"\n>>\n>>>\n>>> 3. The section in the draft entitled \"HTTP Header Requirement\" \n>>> states:\n>>>\n>>>\n>>> The KNOWN-HOST extension relies on the use of the \"P3P: policyref\"\n>>> HTTP header for one site to refer to a policy reference file on\n>>> another site. Since policy reference files cannot include full URIs \n>>> in\n>>> the POLICY-REF INCLUDE elements, sites that rely on placing their\n>>> policy reference file in the well-known location have no way of\n>>> referencing policies hosted on other sites.\n>>>\n>>> Is it acceptable to require the use the policyref HTTP header for \n>>> this\n>>> case? An alternative might be another PRF extension that would allow\n>>> one PRF to reference another PRF.\n>>>\n>>\n>> Hmm... this is not ideal, but I think it is the best solution. If we\n>> were to add another extension than a user agent that was not aware of\n>> the extension would not be able to apply the policy at all. As it is\n>> written now, user agents can still figure out what policy applies even\n>> if they don't know the extension, they just won't know about the ours\n>> relationship.\n>>\n>> Lorrie\n>>\n>\n\n\n\n", "id": "lists-017-7043489"}, {"subject": "Re: P3P 1.1 Domain Relationship", "content": "This makes a lot of sense to me..\n\nRigo\n\nOn Tue, Feb 17, 2004 at 11:08:04AM -0500, Lorrie Cranor wrote:\n> - A single entity operates host A and host B, but might possibly have \n> different policies for host A and host B\n> - Host A acts as an agent of host B and all data collection and uses \n> are in accordance with host B's policy (or one of host B's policies) \n> and are done on behalf of host B - either A or B might be declared as \n> the entity in the policy\n> - Host B acts and an agent of host A and all data collection and uses \n> are in accordance with host A's policy (or one of host A's policies) \n> and are done on behalf of host A - either A or B might be declared as \n> the entity in the policy\n> \n\n\n\n", "id": "lists-017-7064118"}, {"subject": "RE: Art 10: Issue 4  Security Measure", "content": "OK I agree on this.\n\n>**-----Original Message-----\n>**From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu] \n>**Sent: 06 February 2004 17:15\n>**To: Giles Hogben\n>**Cc: 'public-p3p-spec'\n>**Subject: Re: Art 10: Issue 4 - Security Measures\n>**\n>**\n>**Looks good except\n>**- one typo (specify and seals --> specify seals)\n>**- maybe change \"seals\" to \"seals or certification programs\" \n>**to make it \n>**a little more clear what we are talking about.\n>**\n>**Lorrie\n>**\n>**\n>**On Thursday, February 5, 2004, at 03:12 AM, Giles Hogben wrote:\n>**\n>**>\n>**> Here is the latest suggested modification and text for the Spec:\n>**>\n>**> Security issues:\n>**> We suggest using the existing disputes attribute which is a\n>**> placeholder for\n>**> seals of any type (which can then be included in the \n>**browser's list of\n>**> approved seals, along with a type attribute).\n>**>\n>**> Accompanying text for spec (Section 3.2.6, after independent\n>**> organization...):\n>**>\n>**> Policy writers may also use this attribute to specify and seals\n>**> related to\n>**> the entity's information practices (including privacy and security \n>**> seals).\n>**>\n>**> -------------------------------------\n>**> Giles Hogben\n>**> European Commission Joint Research Centre\n>**> Institute for the Protection and Security of the Citizen \n>**Cybersecurity \n>**> New technologies for Combatting Fraud Unit\n>**>\n>**> giles.hogben @ jrc.it\n>**>\n>**>\n>**>\n>**\n>**\n\n\n\n", "id": "lists-017-7072226"}, {"subject": "RE: Art 10: Issue 3  cookie", "content": ">**>>> Here are the latest suggested changes (the guidelines text has\n>**>> changed\n>**>>> quite\n>**>>> a lot so please check):\n>**>>>\n>**>>> Text for 2.3.2.7.\n>**>>> -----------------\n>**>>> Add:\n>**>>> User agents evaluating cookies SHOULD apply the results of a\n>**>> preference> match on the cookie's policy before setting \n>**the cookie.\n>**>>\n>**>> How about\n>**>>\n>**>> User agents that evaluate cookie polices SHOULD perform this \n>**>> evaluation before setting a cookie.\n>**>\n>**> This does not convey the advice. that the cookie should \n>**not be saved \n>**> if it doesn't match the user's preferences.\n>**\n>**I'm not sure we want to say that. A user might specify, for example, \n>**that cookies that don't match their preferences should be \n>**converted to \n>**session cookies rather than deleted altogether. Also, I \n>**could imagine a \n>**user agent that gives users the option of storing rejected \n>**cookies in a \n>**separate place for later analysis or inspection. So I think \n>**we should \n>**make the point that cookies should be evaluated before set time. But \n>**I'm not sure we want to specify what should happen as a \n>**result of that \n>**evaluation. We could say:\n>**\n>**User agents that evaluate cookie policies SHOULD perform this \n>**evaluation before setting a cookie so that the cookie can be \n>**discarded \n>**without being set if that is what is dictated by the user's \n>**preferences.\n\nI think that the crucial point is that whatever behavior is dictated by the\nevaluation should be carried out setting the cookie.\nSo how about:\n\nUser agents that evaluate cookie policies SHOULD perform this evaluation\n*and its resultant behavior* before setting a cookie so that the cookie can\nbe discarded without being set if that is what is dictated by the user's\npreferences.\n\n\n>**>>\n>**>>>\n>**>>> Text for guidelines\n>**>>> -------------------\n>**>>> Certain jurisdictions view the storage of cookies on a user's\n>**>> hard\n>**>>> drive as\n>**>>> an act of data processing. In such jurisdictions (e.g. the EU), \n>**>>> policies should always be evaluated before a cookie is set and \n>**>>> cookies\n>**>> should\n>**>>> not be\n>**>>> stored unless the cookie's policy is found to comply with the\n>**> user's\n>**>>> preferences.\n>**>>\n>**>> In my mail on Issue 1 I had suggested a section called \"Timing of \n>**>> Notices to Users\"... now I'm thinking the section should \n>**be \"Timing \n>**>> of Policy Evaluation and Notice to Users\" ... then we can include\n>**>> this\n>**>> paragraph at the end of that section.\n>**>>\n>**>>\n>**>>\n>**>>>\n>**>>> -------------------------------------\n>**>>> Giles Hogben\n>**>>> European Commission Joint Research Centre\n>**>>> Institute for the Protection and Security of the Citizen\n>**>> Cybersecurity> New technologies for Combatting Fraud Unit\n>**>>> TP 267\n>**>>> Via Enrico Fermi 1\n>**>>> Ispra\n>**>>> 21020 VA\n>**>>> Italy\n>**>>>\n>**>>> giles.hogben@jrc.it\n>**>>> tel:+390332789187\n>**>>> fax:+390332789576\n>**>>>\n>**>>>\n>**>>\n>**>>\n>**>\n>**\n>**\n\n\n\n", "id": "lists-017-7081167"}, {"subject": "RE: Art 10 Issue 1: Purpose Specificatio", "content": "I think the clickstream issue still does not come across. Here are a couple\nof suggested ammendments to help with this. Otherwise I think the text is\nnice:\n\n\nTiming of Notices to Users\n\nAs a best practice, users should receive notice about a site's privacy\npractices prior to their user agent transmitting any \npersonal data. Personal data means anything which might reasonably be linked\nto the user (see section ****) and as such can even include IP addresses and\nlocale data transmitted in http headers before a page has even loaded. In\norder to present such notice, a user agent would need to fetch a P3P policy\nprior to loading a page following the guidelines specified in section 2.4.3\n**\"The Safe Zone.\" However, implementers will need to consider the \nperformance, usability, and privacy tradeoffs associated with \ndisplaying privacy information prior to loading a page. One way that \nprivacy and usability might be simultaneously maximized is \nto treat all \nrequests made prior to display of policy information as \"safe zone\" \nrequests.\n\nAt sites that include form fields, user agents SHOULD provide notice \nabout the corresponding privacy practices prior to form submittal. \nBesides being best practice, this may be needed in order to \ncomply with \nregulations in some jurisdictions (such as the European Union) that \nrequire a notice about the purpose of data collection to be \npresented \nto the user before any personal information is captured. \nUser interface \ndesigns should recognize that the privacy policy for the \nform's action \nURI may be different than the privacy policy for the HTML \npage in which \nthe form is embedded. In order to allow users to view privacy policy \ninformation associated with action URIs prior to form \nsubmittal, user \nagents might include a privacy tab that loads policy information for \naction URIs as a page loads, a button or menu item that \ncauses policy \ninformation for action URIs to be displayed, or a pop-up \nthat appears \nwhen a user begins entering information into a form field.\n\n\n\n>**I suggest this be added as a subsection of section with the title \n>**\"Timing of Notices to Users\"\n>**\n>**While the directive is asking for notice about purpose, I \n>**could imagine \n>**other jurisdictions asking for notice about say, data recipients or \n>**data retention as well. So i don't think we should limit our \n>**discussion \n>**to notice about purpose.\n>**\n>**I also think we need to spell things out a bit more so that people \n>**understand what data might be transmitted before a page is \n>**displayed. \n>**It is also not entirely clear to me how clickstream \n>**information comes \n>**into play here. Here is a proposal:\n>**\n>**\n\n\n>**Timing of Notices to Users\n>**\n>**As a best practice, users should receive notice about a \n>**site's privacy \n>**practices prior to their user agent transmitting any \n>**personal data. In \n>**order to do this, a user agent would need to fetch a P3P \n>**policy prior \n>**to loading a page following the guidelines specified in \n>**section 2.4.3 \n>**The \"Safe Zone.\" However, implementers will need to consider the \n>**performance, usability, and privacy tradeoffs associated with \n>**displaying privacy information prior to loading a page. One way that \n>**privacy and usability might be simultaneously maximized is \n>**to treat all \n>**requests made prior to display of policy information as \"safe zone\" \n>**requests.\n>**\n>**At sites that include form fields, user agents SHOULD provide notice \n>**about the corresponding privacy practices prior to form submittal. \n>**Besides being best practice, this may be needed in order to \n>**comply with \n>**regulations in some jurisdictions (such as the European Union) that \n>**require a notice about the purpose of data collection to be \n>**presented \n>**to the user before any personal information is captured. \n>**User interface \n>**designs should recognize that the privacy policy for the \n>**form's action \n>**URI may be different than the privacy policy for the HTML \n>**page in which \n>**the form is embedded. In order to allow users to view privacy policy \n>**information associated with action URIs prior to form \n>**submittal, user \n>**agents might include a privacy tab that loads policy information for \n>**action URIs as a page loads, a button or menu item that \n>**causes policy \n>**information for action URIs to be displayed, or a pop-up \n>**that appears \n>**when a user begins entering information into a form field.\n>**\n>**\n>**On Thursday, February 5, 2004, at 03:00 AM, Giles Hogben wrote:\n>**\n>**>\n>**> Apart from the issue on primary purpose, the following is \n>**the latest \n>**> suggested text for the UA Guidelines\n>**>\n>**> Some jurisdictions (E.g. the European Union) require human \n>**readable \n>**> information on purpose of collection to be presented to the user \n>**> before any information is captured. One way to comply with \n>**this is to \n>**> present human\n>**> readable translations of policies for action uri's of forms \n>**> simultaneously\n>**> with the forms. As a best practice, information on \n>**purposes should be \n>**> made\n>**> available before any personal information is transmitted. \n>**This might be\n>**> achieved be achieved for example by a privacy tab which is \n>**> synchronised to\n>**> display information before pages load, or by including information \n>**> which is\n>**> displayed on clicking a link.\n>**>\n>**>\n>**> -------------------------------------\n>**> Giles Hogben\n>**> European Commission Joint Research Centre\n>**> Institute for the Protection and Security of the Citizen \n>**Cybersecurity \n>**> New technologies for Combatting Fraud Unit TP 267\n>**> Via Enrico Fermi 1\n>**> Ispra\n>**> 21020 VA\n>**> Italy\n>**>\n>**> giles.hogben@jrc.it\n>**> tel:+390332789187\n>**> fax:+390332789576\n>**>\n>**>\n>**\n>**\n\n\n\n", "id": "lists-017-7092093"}, {"subject": "FW: Art 10 Issue 2: Jurisdictio", "content": "OK agreed - How about this then:\nJurisdiction Disclosure:\n\n We suggest that an Jurisdiction extension be added to the recipient\n element:\n\n\n jurisdiction= \"<JURISDICTION\"\n  \" service=\" quoted-URI\n  [\" short-description=\" quotedstring]\n \">\"\n[longdescription]\n \"</JURISDICTION>\"\n\n\n\nlongdescription=<LONG-DESCRIPTION>PCDATA</LONG-DESCRIPTION>\n\n\n\n\n Example:\n\n <RECIPIENT>\n <EXTENSION><JURISDICTION \n service=\"http://europa.eu.int/smartapi/cgi/\n sga_doc?smartapi!celexapi!prod!CE \n LEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\"\n short-description=\"EU law\"\n>**EU\"></JURISDICTION>\n </EXTENSION>\n </RECIPIENT>\n \n Text for specification:\nThe jurisdiction extension element allows user agents to make judgements\nabout the trustworthiness of a data recipient based on the regulatory\nenvironment they are placed in. Jurisdictions of recipients can be rendered\nmachine readable by inserting a known URI into the service field (e.g. the\nURI of a body of legislation which applies). For example organizations\nwithin the European Union can be assumed to comply to European data\nprotection law and could therefore insert the URI of the 95/46 directive as\nin the example above. Some jurisdictions prohibit transfer of data to\ncertain other jurisdictions without the explicit consent of the data\nsubject. It should be noted therefore declaring the data transfer activity\nof a recipient using the P3P jurisdiction extension is not sufficient to\nguarantee its legality.\n\n\n>**-----Original Message-----\n>**From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n>**Sent: 06 February 2004 18:21\n>**To: Giles Hogben\n>**Cc: 'public-p3p-spec'\n>**Subject: Re: Art 10 Issue 2: Jurisdiction\n>**\n>**\n>**We should make it clear that the jurisdiction is the \n>**jurisdiction of  \n>**the recipient (not the entity).\n>**\n>**For consistency, LONG-DESCRIPTION should be a sub-element \n>**rather than  \n>**an attribute.\n>**\n>**Lorrie\n>**\n>**\n>**\n>**On Thursday, February 5, 2004, at 03:04 AM, Giles Hogben wrote:\n>**\n>**>\n>**> Here is the latest suggested text and Jurisdiction Extension spec:\n>**> please\n>**> review the text as I don't think we discussed it in the call.\n>**>\n>**> Jurisdiction Disclosure:\n>**>\n>**> We suggest that an Jurisdiction extension be added to the recipient\n>**> element:\n>**>\n>**> [??] Extension\n>**>  =\n>**>  Jurisdiction\n>**> `</Extension>\n>**>\n>**> Jurisdiction\n>**>  =\n>**>  `<JURISDICTION\n>**>  \" service=\" quoted-URI\n>**>  [\" short-description=\" quotedstring]\n>**> [\" long-description=\" quotedstring]\n>**> \">\"\n>**>\n>**> \"</JURISDICTION>\"\n>**>\n>**> Example:\n>**>\n>**> <RECIPIENT>\n>**> <EXTENSION><JURISDICTION \n>**> service=\"http://europa.eu.int/smartapi/cgi/\n>**> sga_doc?smartapi!celexapi!prod!CE \n>**> LEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\"\n>**> short-description=\"EU law\"\n>**> long-description=\"This service operates within the \n>**EU\"></JURISDICTION>\n>**> </EXTENSION>\n>**> </RECIPIENT>\n>**> \n>**> Text for specification:\n>**>\n>**>\n>**> The jurisdiction extension element allows user agents to make\n>**> judgements\n>**> about the trustworthiness of a data recipient based on the \n>**regulatory\n>**> environment they are placed in. For example organizations \n>**within the\n>**> European Union can be assumed to comply to European data \n>**protection  \n>**> law.\n>**> Some jurisdictions prohibit transfer of data to certain other  \n>**> jurisdictions\n>**> without the explicit consent of the data subject. \n>**Therefore declaring  \n>**> a data\n>**> transfer activity using the P3P jurisdiction extension is not  \n>**> sufficient to\n>**> guarantee its legality.\n>**>\n\n>**>\n>**>\n>**\n>**\n\n\n\n", "id": "lists-017-7106150"}, {"subject": "RE: cookie sharin", "content": "Sorry I meant\nIt is not prohibited but if you set a shared cookie then the policy you\nprovide for it must cover all the HOSTS (subdomains) it is used in. See\nhttp://www.w3.org/TR/P3P/#cookies for a full explanation\n\n>**-----Original Message-----\n>**From: www-p3p-dev-request@w3.org \n>**[mailto:www-p3p-dev-request@w3.org] On Behalf Of Steve Reeling\n>**Sent: 18 February 2004 14:26\n>**To: 'www-p3p-dev@w3.org'\n>**Subject: cookie sharing\n>**\n>**\n>**\n>**Is there anything in P3P that prevents the sharing of the \n>**same cookie across subdomains?  example:  sales.acme.com and \n>**marketing.acme.com use the same cookie and policy.\n>** \n>**I have searched through a lot of the documentation and \n>**cannot find anything, yet I have been told by a number of \n>**other developers that cookie sharing is (or will be) \n>**prohibited by P3P.\n>** \n>**Any help on this is greatly appreciated.\n>**\n\n\n\n", "id": "lists-017-7117895"}, {"subject": "Notes on 'Do not call' opinion from US 10th circuit court of appeal", "content": "FYI, I took some notes on this recent opinion and though people in the \nWG might be interested. No immediate relevance to P3P but it's a strong \nendorsement of the need to increase consumer choice, both through \ntechnology and law.\n\nDanny\n--\n\nA United States Court of Appeals (10th Circuit) just upheld the FTC's \n'do not call list' against the argument that it unconstitutionally \nrestricts the speech of marketers. This is an important case announcing \nsignificant support for a number of key privacy principles. (The import \nof the case is also evidenced by the fact that the caption citing \nparties involved goes on for 7 pages.) I took some notes on the \nopinion:\n\nThe court held that \"the do-not-call registry is a valid commercial \nspeech regulation because it directly advances the government?s\nimportant interests in safeguarding personal privacy and reducing the \ndanger of telemarketing abuse without burdening an excessive amount of \nspeech.\"\n\nThe court's opinion is based on strong support for fundamental privacy \nprinciples, widely supported in name but not necessarily accepted as \nguiding principles for regulation. \"The national do-not-call registry \noffers consumers a tool with which they can protect their homes against \nintrusions that Congress has determined to be particularly invasive. \nJust as a consumer can avoid door-to-door peddlers by placing a ?No \nSolicitation? sign in his or her front yard, the do-not-call registry \nlets consumers avoid unwanted sales pitches that invade the home via \ntelephone, if they choose to do so. We are convinced that the First \nAmendment does not prevent the government from giving consumers this \noption.\" With this, the court, sought to defend the \"importance of \nindividual privacy, particularly in the context of the home, \n[affirming] that ?the ancient concept that ?a man?s home is his castle? \ninto which ?not even the king may enter? has lost none of its \nvitality.?\"\n\nThe restrictions in favor of privacy in the challenged regulations are \npremised on that fact that the regulations increase, rather than \ndecrease, the choices that consumers have over information they \nreceive: \"Consumers who wish to restrict some but not all commercial \nsales calls can do so by using company-specific do-not-call lists or by \ngranting some businesses express permission to call.\"\n\nThe court seems particularly concerned that consumers ought to have \nmore fine-grained choices:\n\"Therefore, under the current regulations, consumers choose between two \ndefault rules ? either that telemarketers may call or that they may \nnot. Then, consumers may make company-specific modifications to either \nof these default rules as they see fit, either granting particular \nsellers permission to call or blocking calls from certain sellers.\"\n\nMuch of the privacy debate, especially in the 90s, was framed in the \nlanguage of government regulation vs. industry self-regulation. This \nopinion takes a pretty clear stand against relying solely on 'company \nspecific rules' to protect individual privacy: \"[T]he FTC found ... \nthat the company-specific approach is seriously inadequate to protect \nconsumers? privacy from an abusive pattern of calls placed by a seller \nor telemarketer.?\n\nFinally, the court speaks on the proper role of technology in privacy \nprotection and intruston. Technology can help consumers, but alone it's \nnot enough, because marketers are also gaining significant data \ngathering advantage from new technologies: \"Forcing consumers to \ncompete in a technological arms race with the telemarketing industry is \nnot an equally effective alternative to the do-not-call registry.\"\n\nThis is not the last word on any of these issues, as the case could go \nto the US Supreme Court and the questions are likely to end up back in \nCongress' lap.\n\n(readers can find the full opinion at \nhttp://www.ck10.uscourts.gov/index.cfm)\n\n\n\n--\nDaniel J. Weitzner                                          \n+1.617.253.8036 (MIT)\nWorld Wide Web Consortium                       +1.202.364.4750 (DC)\nTechnology & Society Domain Leader      <djweitzner@w3.org>\nhttp://www.w3.org/People/Weitzner.html\n\n\n\n", "id": "lists-017-7126111"}, {"subject": "Re: Art 10 Issue 1: Purpose Specificatio", "content": "Looks good to me.\n\nLorrie\n\nOn Feb 18, 2004, at 4:46 AM, Giles Hogben wrote:\n\n>\n> I think the clickstream issue still does not come across. Here are a \n> couple\n> of suggested ammendments to help with this. Otherwise I think the text \n> is\n> nice:\n>\n>\n> Timing of Notices to Users\n>\n> As a best practice, users should receive notice about a site's privacy\n> practices prior to their user agent transmitting any\n> personal data. Personal data means anything which might reasonably be \n> linked\n> to the user (see section ****) and as such can even include IP \n> addresses and\n> locale data transmitted in http headers before a page has even loaded. \n> In\n> order to present such notice, a user agent would need to fetch a P3P \n> policy\n> prior to loading a page following the guidelines specified in section \n> 2.4.3\n> **\"The Safe Zone.\" However, implementers will need to consider the\n> performance, usability, and privacy tradeoffs associated with\n> displaying privacy information prior to loading a page. One way that\n> privacy and usability might be simultaneously maximized is\n> to treat all\n> requests made prior to display of policy information as \"safe zone\"\n> requests.\n>\n> At sites that include form fields, user agents SHOULD provide notice\n> about the corresponding privacy practices prior to form submittal.\n> Besides being best practice, this may be needed in order to\n> comply with\n> regulations in some jurisdictions (such as the European Union) that\n> require a notice about the purpose of data collection to be\n> presented\n> to the user before any personal information is captured.\n> User interface\n> designs should recognize that the privacy policy for the\n> form's action\n> URI may be different than the privacy policy for the HTML\n> page in which\n> the form is embedded. In order to allow users to view privacy policy\n> information associated with action URIs prior to form\n> submittal, user\n> agents might include a privacy tab that loads policy information for\n> action URIs as a page loads, a button or menu item that\n> causes policy\n> information for action URIs to be displayed, or a pop-up\n> that appears\n> when a user begins entering information into a form field.\n>\n>\n>\n>> **I suggest this be added as a subsection of section with the title\n>> **\"Timing of Notices to Users\"\n>> **\n>> **While the directive is asking for notice about purpose, I\n>> **could imagine\n>> **other jurisdictions asking for notice about say, data recipients or\n>> **data retention as well. So i don't think we should limit our\n>> **discussion\n>> **to notice about purpose.\n>> **\n>> **I also think we need to spell things out a bit more so that people\n>> **understand what data might be transmitted before a page is\n>> **displayed.\n>> **It is also not entirely clear to me how clickstream\n>> **information comes\n>> **into play here. Here is a proposal:\n>> **\n>> **\n>\n>\n>> **Timing of Notices to Users\n>> **\n>> **As a best practice, users should receive notice about a\n>> **site's privacy\n>> **practices prior to their user agent transmitting any\n>> **personal data. In\n>> **order to do this, a user agent would need to fetch a P3P\n>> **policy prior\n>> **to loading a page following the guidelines specified in\n>> **section 2.4.3\n>> **The \"Safe Zone.\" However, implementers will need to consider the\n>> **performance, usability, and privacy tradeoffs associated with\n>> **displaying privacy information prior to loading a page. One way that\n>> **privacy and usability might be simultaneously maximized is\n>> **to treat all\n>> **requests made prior to display of policy information as \"safe zone\"\n>> **requests.\n>> **\n>> **At sites that include form fields, user agents SHOULD provide notice\n>> **about the corresponding privacy practices prior to form submittal.\n>> **Besides being best practice, this may be needed in order to\n>> **comply with\n>> **regulations in some jurisdictions (such as the European Union) that\n>> **require a notice about the purpose of data collection to be\n>> **presented\n>> **to the user before any personal information is captured.\n>> **User interface\n>> **designs should recognize that the privacy policy for the\n>> **form's action\n>> **URI may be different than the privacy policy for the HTML\n>> **page in which\n>> **the form is embedded. In order to allow users to view privacy policy\n>> **information associated with action URIs prior to form\n>> **submittal, user\n>> **agents might include a privacy tab that loads policy information for\n>> **action URIs as a page loads, a button or menu item that\n>> **causes policy\n>> **information for action URIs to be displayed, or a pop-up\n>> **that appears\n>> **when a user begins entering information into a form field.\n>> **\n>> **\n>> **On Thursday, February 5, 2004, at 03:00 AM, Giles Hogben wrote:\n>> **\n>> **>\n>> **> Apart from the issue on primary purpose, the following is\n>> **the latest\n>> **> suggested text for the UA Guidelines\n>> **>\n>> **> Some jurisdictions (E.g. the European Union) require human\n>> **readable\n>> **> information on purpose of collection to be presented to the user\n>> **> before any information is captured. One way to comply with\n>> **this is to\n>> **> present human\n>> **> readable translations of policies for action uri's of forms\n>> **> simultaneously\n>> **> with the forms. As a best practice, information on\n>> **purposes should be\n>> **> made\n>> **> available before any personal information is transmitted.\n>> **This might be\n>> **> achieved be achieved for example by a privacy tab which is\n>> **> synchronised to\n>> **> display information before pages load, or by including information\n>> **> which is\n>> **> displayed on clicking a link.\n>> **>\n>> **>\n>> **> -------------------------------------\n>> **> Giles Hogben\n>> **> European Commission Joint Research Centre\n>> **> Institute for the Protection and Security of the Citizen\n>> **Cybersecurity\n>> **> New technologies for Combatting Fraud Unit TP 267\n>> **> Via Enrico Fermi 1\n>> **> Ispra\n>> **> 21020 VA\n>> **> Italy\n>> **>\n>> **> giles.hogben@jrc.it\n>> **> tel:+390332789187\n>> **> fax:+390332789576\n>> **>\n>> **>\n>> **\n>> **\n>\n\n\n\n", "id": "lists-017-7137364"}, {"subject": "Re: Art 10 Issue 2: Jurisdictio", "content": "Looks good.\n\nLorrie\n\nOn Feb 18, 2004, at 5:18 AM, Giles Hogben wrote:\n\n>\n> OK agreed - How about this then:\n> Jurisdiction Disclosure:\n>\n>  We suggest that an Jurisdiction extension be added to the recipient\n>  element:\n>\n>\n>  jurisdiction= \"<JURISDICTION\"\n>   \" service=\" quoted-URI\n>   [\" short-description=\" quotedstring]\n>  \">\"\n> [longdescription]\n>  \"</JURISDICTION>\"\n>\n>\n>\n> longdescription=<LONG-DESCRIPTION>PCDATA</LONG-DESCRIPTION>\n>\n>\n>\n>\n>  Example:\n>\n>  <RECIPIENT>\n>  <EXTENSION><JURISDICTION\n>  service=\"http://europa.eu.int/smartapi/cgi/\n>  sga_doc?smartapi!celexapi!prod!CE\n>  LEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\"\n>  short-description=\"EU law\"\n>> **EU\"></JURISDICTION>\n>  </EXTENSION>\n>  </RECIPIENT>\n>  \n>  Text for specification:\n> The jurisdiction extension element allows user agents to make \n> judgements\n> about the trustworthiness of a data recipient based on the regulatory\n> environment they are placed in. Jurisdictions of recipients can be \n> rendered\n> machine readable by inserting a known URI into the service field (e.g. \n> the\n> URI of a body of legislation which applies). For example organizations\n> within the European Union can be assumed to comply to European data\n> protection law and could therefore insert the URI of the 95/46 \n> directive as\n> in the example above. Some jurisdictions prohibit transfer of data to\n> certain other jurisdictions without the explicit consent of the data\n> subject. It should be noted therefore declaring the data transfer \n> activity\n> of a recipient using the P3P jurisdiction extension is not sufficient \n> to\n> guarantee its legality.\n>\n>\n>> **-----Original Message-----\n>> **From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n>> **Sent: 06 February 2004 18:21\n>> **To: Giles Hogben\n>> **Cc: 'public-p3p-spec'\n>> **Subject: Re: Art 10 Issue 2: Jurisdiction\n>> **\n>> **\n>> **We should make it clear that the jurisdiction is the\n>> **jurisdiction of\n>> **the recipient (not the entity).\n>> **\n>> **For consistency, LONG-DESCRIPTION should be a sub-element\n>> **rather than\n>> **an attribute.\n>> **\n>> **Lorrie\n>> **\n>> **\n>> **\n>> **On Thursday, February 5, 2004, at 03:04 AM, Giles Hogben wrote:\n>> **\n>> **>\n>> **> Here is the latest suggested text and Jurisdiction Extension spec:\n>> **> please\n>> **> review the text as I don't think we discussed it in the call.\n>> **>\n>> **> Jurisdiction Disclosure:\n>> **>\n>> **> We suggest that an Jurisdiction extension be added to the \n>> recipient\n>> **> element:\n>> **>\n>> **> [??] Extension\n>> **>  =\n>> **>  Jurisdiction\n>> **> `</Extension>\n>> **>\n>> **> Jurisdiction\n>> **>  =\n>> **>  `<JURISDICTION\n>> **>  \" service=\" quoted-URI\n>> **>  [\" short-description=\" quotedstring]\n>> **> [\" long-description=\" quotedstring]\n>> **> \">\"\n>> **>\n>> **> \"</JURISDICTION>\"\n>> **>\n>> **> Example:\n>> **>\n>> **> <RECIPIENT>\n>> **> <EXTENSION><JURISDICTION\n>> **> service=\"http://europa.eu.int/smartapi/cgi/\n>> **> sga_doc?smartapi!celexapi!prod!CE\n>> **> LEXnumdoc&lg=EN&numdoc=31995L0046&model=guichett\"\n>> **> short-description=\"EU law\"\n>> **> long-description=\"This service operates within the\n>> **EU\"></JURISDICTION>\n>> **> </EXTENSION>\n>> **> </RECIPIENT>\n>> **> \n>> **> Text for specification:\n>> **>\n>> **>\n>> **> The jurisdiction extension element allows user agents to make\n>> **> judgements\n>> **> about the trustworthiness of a data recipient based on the\n>> **regulatory\n>> **> environment they are placed in. For example organizations\n>> **within the\n>> **> European Union can be assumed to comply to European data\n>> **protection\n>> **> law.\n>> **> Some jurisdictions prohibit transfer of data to certain other\n>> **> jurisdictions\n>> **> without the explicit consent of the data subject.\n>> **Therefore declaring\n>> **> a data\n>> **> transfer activity using the P3P jurisdiction extension is not\n>> **> sufficient to\n>> **> guarantee its legality.\n>> **>\n>\n>> **>\n>> **>\n>> **\n>> **\n>\n\n\n\n", "id": "lists-017-7151854"}, {"subject": "Re: linke", "content": "OK, responding to Giles and Eric's concerns... how about:\n\n<p>A piece of data X is said to be <i>linked</i> to a cookie Y if at\nleast one of the following activities may take place as a result of\ncookie Y being replayed:</p>\n\n<ul>\n\n<li>X is retrieved from a persistent data store or archival media.</li>\n\n<li>Information identifiable with the user -- including but not\nlimited to data entered into forms, IP address, clickstream data, and\nclient events -- is added to a record, data structure, or file\nin which X is stored. </li>\n\n</ul>\n\n\n\nOn Feb 17, 2004, at 8:10 AM, Giles Hogben wrote:\n\n>\n>\n>> **On Feb 16, 2004, at 4:59 AM, Giles Hogben wrote:\n>> **\n>> **>\n>> **> Some comments:\n>> **> 1. I don't think the requirement that it be stored as a particular\n>> **> database\n>> **> record is valid. I think that linkability should be described\n>> **> independently\n>> **> of the technical architecture used. This is why I tried to\n>> **describe it\n>> **> in\n>> **> terms of the intentions and proportionality.\n>> **\n>> **This actually goes to the heart of what I was trying to do...\n>> **I wanted\n>> **to define \"linkable\" independently of technical architecture\n>> **but define\n>> **\"linked\" more narrowly. So far I haven't come up with an\n>> **example of an\n>> **architecture in which we would want to say that data is\n>> **linked and does\n>> **not involve either triggering a database retrieval or\n>> **storage. Perhaps\n>> **you have an example?\n>> **\n>\n> Cookies and files used in forensics are not linked to a database. \n> Server\n> logs are not really databases?\n>\n>> **> 2. You do not mention the use of referers to link cookies \n>> together.\n>> **\n>> **I will add that.\n>> **\n>> **> 3. I think the examples given are simpler than those I gave.\n>> **>\n>> **\n>> **Is that a good thing or a bad thing?\n>> **\n> That is a good thing.\n>\n>> **\n>> **Lorrie\n>> **\n>> **\n>\n\n\n\n", "id": "lists-017-7164269"}, {"subject": "AGENDA: MONDAY 23 February P3P Spec Cal", "content": "The next P3P specification group conference call will be on\nMonday, February 23, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nNOTE THIS IS MONDAY, NOT WEDNESAY!\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n(Jack please circulate new draft)\n\n2. Primary purpose specification\n(Dave please circulate a draft)\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\n6. Set date/time for next call\n\n\n\n", "id": "lists-017-7173351"}, {"subject": "[Minutes] 23 February 2004 P3P spec cal", "content": "Minutes of the 23 February 2004 P3P 1.1 spec wg call\n\nPresent:\nLorrie Cranor\nDave Stampley\nBrooks Dobbs\nRigo Wenning\nAri Schwartz\nPatrick Hung\nGiles Hogben\nJeff Edelen\n\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n(Jack please circulate new draft)\n\nWhile no draft was available for review, there was considerable discussion\nsurrounding the need for a clear definition of an \"ours relationship\" as it\npertains to KNOWN-HOSTS.  Brooks suggested that it would be helpful if there\nwere a way to distinguish between a \"same entity relationship\" and an \"agent\nrelationship\" to allow user agents to make use of that distinction.\n\nACTION: Brooks to work with Jack on revised draft proposal which will be\ndistributed to the list.\n\n2. Primary purpose specification\n(Dave please circulate a draft)\n\nNo updates.\n\nACTION: Dave to meet with Jeff and Ari to prepare a draft for discussion.\nOthers interested in meeting on this topic, please contact Dave.\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\nThere is general consensus that the most current proposal by Lorrie is close.\nSome questions remain as to the need to disclose \"linkable\" data as \"linked\"\nwhen data are co-resident in a logfile but there is no intent to link.  Are\ndata effectively linked due to proximity in a logfile?\n\nACTION: Lorrie to update proposal to address the issue.\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\nConsiderable support for this proposal has been expressed within the group.\nThose with concerns are urged to actively participate in the discussion,\nallowing the group to understand their concerns.\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\nDiscussion deferred due to time constraints.\n\n6. Set date/time for next call\n\nNext call: 1 March 2004, 11:00am EST\n\n\n\n\n\nAmerican Express made the following\n annotations on 02/23/2004 11:08:20 AM\n------------------------------------------------------------------------------\n******************************************************************************\n\n     \"This message and any attachments are solely for the intended recipient and may contain confidential or privileged information. If you are not the intended recipient, any disclosure, copying, use, or distribution of the information included in this message and any attachments is prohibited.  If you have received this communication in error, please notify us by reply e-mail and immediately and permanently delete this message and any attachments.  Thank you.\"\n\n******************************************************************************\n\n\n==============================================================================\n\n\n\n", "id": "lists-017-7180922"}, {"subject": "Re: WSDL and P3P attribute.", "content": "I hope you are able to discuss this at the technical plenary and then \nfill the rest of us in on what conclusions you come to, if any.\n\nI understand Rigo's perspective that the XML writer that uses the P3P \ntag should understand all possible ways this chunk of XML will be \nprocessed and make sure the P3P policy applies to all of them. But, if \nI were a lawyer (and I'm not, but Rigo is, so he can comment as to how \ngood a lawyer I would be), I might advise my clients not to use this \ngeneric P3P XML tag, because in reality I cannot anticipate how this \nchunk of XML might be processed (see my example in \nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html). \nI would like to have some way of saying \"P3P policy X applies to chunk \nof XML Y only when Y is processed under condition Z.\"  I think this is \nfeasible if we include an attribute that is a URI that can be used to \nspecify condition Z. Then each XML application that wants to use P3P \ncould establish their own URI that explains the assumptions that are \nmade about what it means to process XML in that context (and presumably \nsimilar applications might find they could use the same assumptions).\n\nLorrie\n\n\nOn Feb 20, 2004, at 10:35 AM, Rigo Wenning wrote:\n\n> We defer so many things to the policy-writer. If someone creates\n> an arbitrary XML which can be processed by three different agents, he\n> MUST mention all _intended_ data collection. He knows best how to deal\n> with it.\n>\n> For the most common W3C-Specs, I imagine a separate Note using this\n> binding and adding restrictions and some guidance -like this was done\n> in the WSDL-P3P-Note[1] will help.\n>\n> Perhaps the problem is also language, as I used legal language that\n> covers all of your concerns by saying 'all data collection'. We know\n> exactly what 'data collection' means. The creator of XML and the \n> creator\n> of agents should know what that means in terms of processing and they\n> can tell the user agent via the well defined P3P policy. I don't have \n> to\n> give them more details (at least not from a legal point of view, as I\n> can give you an _exact_ scope out of my definitions by the usual\n> hermeneutics.)\n>\n>   1. http://www.w3.org/TeamSubmission/2004/SUBM-p3p-wsdl-20040213/\n>\n> Best,\n>\n> Rigo\n>\n> On Thu, Feb 19, 2004 at 06:53:21PM -0500, Massimo Marchiori wrote:\n>> Interestingly enough, just noted today's\n>> \"AGENDA: MONDAY 23 February P3P Spec Call\"\n>> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0052.html \n>> :\n>> <quote>\n>> 5. P3P Generic attribute for XML applications\n>> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n>> </quote>\n>> which points to a message by Lorrie Cranor (the chair, ahem...)\n>> that seems to have rediscovered one of the points against the\n>> \"generic attribute\" that I had mentioned to Philippe in our phonecall\n>> chat.\n>>\n>> With this, I'll silently await the next voodoo... ;)\n>> Apart from jokes, we can better chat about this at the plenary too.\n>> Of course, if I find the time these days I might as well reproduce\n>> in email the exec summary problem analysis I gave to Philippe (if.... \n>> :( ).\n>> -M\n>\n\n\n\n", "id": "lists-017-7190821"}, {"subject": "Re: linke", "content": "Here is a redraft based on our discussion on the call. I think we're \ngetting closer but may not be quite there yet... send me your \nsuggestions.\n\nThe language I am proposing is intended to exclude the possibility that \nwriting a piece of data to a log file that contains a cookie will make \nthe data linked, unless the log file is later analyzed or processed so \nas to cause that data to be written to a cookie, retrieved from a data \nstore, or added to (another) record, data structure, or file containing \nthat data.\n\nAnyway... here is my latest effort:\n\n<p>A piece of data X is said to be <i>linked</i> to a cookie Y if at\nleast one of the following activities may take place as a result of\ncookie Y being replayed, immediately upon cookie replay or at some\nfuture time (perhaps as a result of retrospective analysis or\nprocessing of server logs):</p>\n\n<ul>\n<li>A cookie containing X is set or reset.</li>\n\n<li>X is retrieved from a persistent data store or archival media.</li>\n\n<li>Information identifiable with the user -- including but not\nlimited to data entered into forms, IP address, clickstream data, and\nclient events -- is added to a record, data structure, or file (other\nthan a log file) in which X is stored. </li>\n</ul>\n\n\n\n", "id": "lists-017-7202238"}, {"subject": "Re: linke", "content": "I think that this new draft is very good because it gives a practical \nand reasonably comprehensive idea of the meaning of linked to the \nimplementer, without being too prescriptive. Only one thing I don't \nquite agree with:\n\n\"is added to a record, data structure, or file (other\n than a log file) in which X is stored.\"\n\nShouldn't this really be \n\n\"is retrieved from a record, data structure, or file (other\n than a log file) in which X is stored.\"\n\nbecause we don't really care if it's added as long as no-one ever sees \nit.\n\n\n> \n> Here is a redraft based on our discussion on the call. I think \n> we're \n> getting closer but may not be quite there yet... send me your \n> suggestions.\n> \n> The language I am proposing is intended to exclude the possibility \n> that \n> writing a piece of data to a log file that contains a cookie will \n> make \n> the data linked, unless the log file is later analyzed or \n> processed so \n> as to cause that data to be written to a cookie, retrieved from a \n> data \n> store, or added to (another) record, data structure, or file \n> containing \n> that data.\n> \n> Anyway... here is my latest effort:\n> \n> <p>A piece of data X is said to be <i>linked</i> to a cookie Y if at\n> least one of the following activities may take place as a result of\n> cookie Y being replayed, immediately upon cookie replay or at some\n> future time (perhaps as a result of retrospective analysis or\n> processing of server logs):</p>\n> \n> <ul>\n> <li>A cookie containing X is set or reset.</li>\n> \n> <li>X is retrieved from a persistent data store or archival \n> media.</li>\n> <li>Information identifiable with the user -- including but not\n> limited to data entered into forms, IP address, clickstream data, and\n> client events -- is added to a record, data structure, or file (other\n> than a log file) in which X is stored. </li>\n> </ul>\n> \n> \n\n\n\n", "id": "lists-017-7210318"}, {"subject": "Re: linke", "content": "> <li>Information identifiable with the user -- including but not\nI would rather says _identified_ here, but this may be subject to\ndiscussion. \n\nRigo\n\n\n\n", "id": "lists-017-7218764"}, {"subject": "P3P Beyond HTTP Task Forc", "content": "Happy New Year of 2004!\n\nFYI. Rigo Wenning, Hugo Haas, David Booth, Philippe Le Hegaret, Michael\nSperberg-McQueen and Patrick Hung have been discussing\nabout P3P and Web services in the past few weeks. We held two conference\ncalls in Dec 03:\n\nP3P / WS call 5 Dec 2003\nhttp://www.w3.org/2003/12/05-p3p-ws.html\n\nP3P / WS call 16 Dec 2003\nhttp://www.w3.org/2003/12/16-p3pws.html\n\nThese two conference calls came up in the context of discussing how to\nattach P3P info to a Web service message schema \nor WSDL document. During the calls, it was decided that gonig with the\ngeneric P3P attribute was the way forward. In particular, \nRigo has already got the schema for the p3p-attribute from Michael\nSperberg-McQueen, our Schema-Chair, as follows:\n\n<xsd:schema\n xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"\n targetNamespace=\"http://www.w3.org/2004/01/p3p-gen\" >\n <xsd:annotation>\n  <xsd:documentation>\n   <div xmlns=\"http://www.w3.org/1999/xhtml\">\n    <p>Sample schema document for Rigo Wenning, to demonstrate\n     how to declare a global attribute.</p>\n    <p>Here, we let the attribute be called 'P3P-generic'.</p>\n   </div>\n  </xsd:documentation>\n </xsd:annotation>\n\n <xsd:attribute name=\"p3p-gen\" type=\"xsd:anyURI\">\n  <xsd:annotation>\n   <xsd:documentation>\n    <div xmlns=\"http://www.w3.org/1999/xhtml\">\n     <p>The P3P-generic attribute takes a URI as its value.</p>\n     <p>The meaning is that a P3P document describing the privacy\n      policy relevant to this element may be found at the URI\n      given.</p>\n     <p>Examples: ...</p>\n     <p>Other notes: ...</p>\n    </div>\n   </xsd:documentation>\n  </xsd:annotation>\n </xsd:attribute>\n</xsd:schema>\n\nAnd also Hugo has already started a new document \"Use of the P3P generic\nattribute in WSDL 2.0:\"\nhttp://www.w3.org/2003/12/p3p-wsdl\n\nAny comment or suggestion are welcome.\n\n\n\n", "id": "lists-017-7275871"}, {"subject": "Agenda 14 January Cal", "content": "The next P3P specification group conference call will be on\nWednesday, January 14, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nHappy New Year all. I'm only 3 days back from holidays and had a major\nmachine-problem. Now I'm back up on speed. So let's have only a short\ncall. I will discover further issues by editing in the next weeks.\n\n1/ Further planning for a F2F meeting\n\n2/ Remaining issues\n\n3/ primary purposes\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-7284457"}, {"subject": "[Minutes] 14 January Cal", "content": "On Wed, Jan 14, 2004 at 03:00:59PM +0100, Rigo Wenning wrote:\n> 1/ Further planning for a F2F meeting\n\nSome conflicts appeared. So we will continue discussion on the member\nmailing-list.\n\nACTION Rigo: Start thread on the member-mailing-list\n> \n> 2/ Remaining issues\n\nIssue was to collect all the remaining undone stuff. Please verify all\nthe bugs in bugzilla. There is a link to bugzilla from the P3P 1.1\nHomepage: http://www.w3.org/P3P/1.1/\n\nGiles already identified some issues around dataschema. \n\nACTION Giles: Write proposal for next steps to the mailing-list\n> \n> 3/ primary purposes\n\nAs Rigo is fully occupied with edits, he can't participate. Dave and\nJeff proposed to bring up a draft that we could discuss also with the\nfolks from the POWG.\n\nNext Meeting will be on 28 Jan 2004 (same time, same place)\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-7291602"}, {"subject": "Deadline Reminder: 2004 IEEE International Conference on Web Serv ices (ICWS 2004", "content": "*************** Deadline Reminder **************** \n\nApologies if you receive multiple copies of this message.\n\n\n2004 IEEE International Conference on Web Services (ICWS 2004)\n==============================================================\nTheme: Convergence of Web Services, Grid Computing, e-Business and Autonomic\nComputing\nJuly 6-9, 2004, San Diego, California, USA\nhttp://conferences.computer.org/icws/2004/\n\nSponsored by IEEE Computer Society Technical Community for Services\nComputing (TCSC)\nhttp://tab.computer.org/tcsc/\n\n\nIMPORTANT DATES:\n\nJanuary 26 (Monday): Abstract Submission (optional)\nFeb. 2, 2004 (Monday): Submission Due\nMarch 19, 2004 (Friday): Notification of acceptance\nApril 16, 2004 (Friday): Camera-Ready copy & Author Pre-registration due\nJuly 6 - July 9, 2004: ICWS'04 International Conference on Web Services\n\n\n\n", "id": "lists-017-7299011"}, {"subject": "i'm back... now let's get P3P 1.1 finished", "content": "P3P Working Group members,\n\nFirst, I wanted to let you all know that I am back from maternity leave \nand have completed my move from New Jersey to Pittsburgh. I have joined \nthe faculty of the School of Computer Science at Carnegie Mellon \nUniversity (new contact info below).\n\nSecond, I wanted to let you all know that I will resume chairing the \nP3P working group meetings with our next conference call on January 28.\n\nFinally, I want to remind you all of the schedule of deliverables in \nour charter \nhttp://www.w3.org/P3P/Group/Specification/1.1/01-spec-charter.html and \nlet you know how I plan to move forward.\n\nAccording to our charter we should have published complete working \ndrafts in November and should be publishing last call drafts in January \nso that we are on track for CR in February and PR in April. We are a \nlittle behind schedule, but not terribly so. From the beginning, the \nidea behind this working group was to pick the low hanging fruit and \nget done as much as we could in a 16 month time frame. Anything that \ncan't be accomplished in that time frame will have to wait for W3C to \ncharter a working group for the next version of P3P (interest and \nresources permitting). So, the time has come to focus on what remaining \nitems we can get done in P3P1.1 and put the rest aside.\n\nRigo is hoping to have an edited P3P 1.1 working draft with all the \nchanges the working group has approved so far ready by the end of this \nmonth. I am working with Rigo to update buzilla and figure out where \nthings stand. If you are a taskforce chair, I would appreciate it if \nyou could send email to the working group by the end of the week \nsummarizing the current status of your taskforce's work, what \nadditional work you think is realistic to accomplish in the next month, \nand any issues you need the full working group to resolve before moving \nforward. If you are not a taskforce chair but have been assigned a \nmajor action item, please do likewise.\n\nI would like to get *complete* drafts of all proposed additions/changes \nto the specification no later than February 13. By complete, I mean \nsomething that is fully fleshed out such that it can be put in the spec \nmore or less as-is if the working group decides they like it. We will \nthen consider each of these proposals and decide whether we want to \naccept the proposal as-is or with changes, or whether we think the idea \nshould wait for another version of P3P. You are of course welcome to \nsend us proposals earlier than February 13, or to post incomplete \nproposals before February 13 so that you can get feedback on early \ndrafts. Any pending issue for which we do not have a complete draft by \nFebruary 13 will not be addressed in P3P 1.1. So if there is something \nyou care about, please see to it that you get a proposal in.\n\nOur next call will be on Wednesday, January 28 at the usual time and \nplace. Please let me know if you have any items you would like me to \nschedule for the agenda.\n\nThanks!\n\nLorrie\n\n\n\n--\nLorrie Faith Cranor, Associate Research Professor\nComputer Science and Engineering & Public Policy\nCarnegie Mellon University\nISRI, School of Computer Science\n5000 Forbes Ave\nPittsburgh, PA 15213\n412-268-7534\nOffice: Doherty Hall 4301A\nlorrie@cs.cmu.edu\nhttp://lorrie.cranor.org/\n\n\n\n", "id": "lists-017-7310350"}, {"subject": "Bug 334 erratu", "content": "http://www.w3.org/Bugs/Public/show_bug.cgi?id=334\n\nsays there is erratum. I changed the text to \n\nThe POLICY element contains a complete P3P policy. Each P3P policy MUST\ncontain exactly one POLICY element. The policy element MUST contain an\nENTITY element that identifies the legal entity making the\nrepresentation of the privacy practices contained in the policy. In\naddition, the policy element MUST contain an ACCESS element andone or\nmore STATEMENT elements.It SHOULD contain a DISPUTES-GROUP element. It\nmay contain a P3P data schema and one or more extensions.\n\nIf you have an issue with this, notify me by monday 26 Jan\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-7321040"}, {"subject": "I need your status reports and agenda item", "content": "Except for a few friendly welcome back and congratulation messages \n(thank you) I have gotten no response to my email from last week \n(copied below). I would like a brief status report from all task forces \nASAP and suggested agenda items for this week's call.\n\nThanks!\n\nLorrie\n\n\n\nOn Tuesday, January 20, 2004, at 04:04 PM, Lorrie Cranor wrote:\n\n>\n> P3P Working Group members,\n>\n> First, I wanted to let you all know that I am back from maternity \n> leave and have completed my move from New Jersey to Pittsburgh. I have \n> joined the faculty of the School of Computer Science at Carnegie \n> Mellon University (new contact info below).\n>\n> Second, I wanted to let you all know that I will resume chairing the \n> P3P working group meetings with our next conference call on January > 28.\n>\n> Finally, I want to remind you all of the schedule of deliverables in \n> our charter \n> http://www.w3.org/P3P/Group/Specification/1.1/01-spec-charter.html and \n> let you know how I plan to move forward.\n>\n> According to our charter we should have published complete working \n> drafts in November and should be publishing last call drafts in \n> January so that we are on track for CR in February and PR in April. We \n> are a little behind schedule, but not terribly so. From the beginning, \n> the idea behind this working group was to pick the low hanging fruit \n> and get done as much as we could in a 16 month time frame. Anything \n> that can't be accomplished in that time frame will have to wait for \n> W3C to charter a working group for the next version of P3P (interest \n> and resources permitting). So, the time has come to focus on what \n> remaining items we can get done in P3P1.1 and put the rest aside.\n>\n> Rigo is hoping to have an edited P3P 1.1 working draft with all the \n> changes the working group has approved so far ready by the end of this \n> month. I am working with Rigo to update buzilla and figure out where \n> things stand. If you are a taskforce chair, I would appreciate it if \n> you could send email to the working group by the end of the week \n> summarizing the current status of your taskforce's work, what \n> additional work you think is realistic to accomplish in the next \n> month, and any issues you need the full working group to resolve \n> before moving forward. If you are not a taskforce chair but have been \n> assigned a major action item, please do likewise.\n>\n> I would like to get *complete* drafts of all proposed \n> additions/changes to the specification no later than February 13. By \n> complete, I mean something that is fully fleshed out such that it can \n> be put in the spec more or less as-is if the working group decides \n> they like it. We will then consider each of these proposals and decide \n> whether we want to accept the proposal as-is or with changes, or \n> whether we think the idea should wait for another version of P3P. You \n> are of course welcome to send us proposals earlier than February 13, \n> or to post incomplete proposals before February 13 so that you can get \n> feedback on early drafts. Any pending issue for which we do not have a \n> complete draft by February 13 will not be addressed in P3P 1.1. So if \n> there is something you care about, please see to it that you get a \n> proposal in.\n>\n> Our next call will be on Wednesday, January 28 at the usual time and \n> place. Please let me know if you have any items you would like me to \n> schedule for the agenda.\n>\n> Thanks!\n>\n> Lorrie\n>\n>\n>\n> --\n> Lorrie Faith Cranor, Associate Research Professor\n> Computer Science and Engineering & Public Policy\n> Carnegie Mellon University\n> ISRI, School of Computer Science\n> 5000 Forbes Ave\n> Pittsburgh, PA 15213\n> 412-268-7534\n> Office: Doherty Hall 4301A\n> lorrie@cs.cmu.edu\n> http://lorrie.cranor.org/\n>\n\n\n\n", "id": "lists-017-7327820"}, {"subject": "Re: I need your status reports and agenda item", "content": "Our final draft is on the web. Nothing happened with respect to consent groups.\n\nmatthias\n\nAt 11:15 AM 1/26/2004 -0500, Lorrie Cranor wrote:\n\n>Except for a few friendly welcome back and congratulation messages (thank \n>you) I have gotten no response to my email from last week (copied below). \n>I would like a brief status report from all task forces ASAP and suggested \n>agenda items for this week's call.\n>\n>Thanks!\n>\n>Lorrie\n>\n>\n>\n>On Tuesday, January 20, 2004, at 04:04 PM, Lorrie Cranor wrote:\n>\n>>\n>>P3P Working Group members,\n>>\n>>First, I wanted to let you all know that I am back from maternity leave \n>>and have completed my move from New Jersey to Pittsburgh. I have joined \n>>the faculty of the School of Computer Science at Carnegie Mellon \n>>University (new contact info below).\n>>\n>>Second, I wanted to let you all know that I will resume chairing the P3P \n>>working group meetings with our next conference call on January > 28.\n>>\n>>Finally, I want to remind you all of the schedule of deliverables in our \n>>charter \n>>http://www.w3.org/P3P/Group/Specification/1.1/01-spec-charter.html and \n>>let you know how I plan to move forward.\n>>\n>>According to our charter we should have published complete working drafts \n>>in November and should be publishing last call drafts in January so that \n>>we are on track for CR in February and PR in April. We are a little \n>>behind schedule, but not terribly so. From the beginning, the idea behind \n>>this working group was to pick the low hanging fruit and get done as much \n>>as we could in a 16 month time frame. Anything that can't be accomplished \n>>in that time frame will have to wait for W3C to charter a working group \n>>for the next version of P3P (interest and resources permitting). So, the \n>>time has come to focus on what remaining items we can get done in P3P1.1 \n>>and put the rest aside.\n>>\n>>Rigo is hoping to have an edited P3P 1.1 working draft with all the \n>>changes the working group has approved so far ready by the end of this \n>>month. I am working with Rigo to update buzilla and figure out where \n>>things stand. If you are a taskforce chair, I would appreciate it if you \n>>could send email to the working group by the end of the week summarizing \n>>the current status of your taskforce's work, what additional work you \n>>think is realistic to accomplish in the next month, and any issues you \n>>need the full working group to resolve before moving forward. If you are \n>>not a taskforce chair but have been assigned a major action item, please \n>>do likewise.\n>>\n>>I would like to get *complete* drafts of all proposed additions/changes \n>>to the specification no later than February 13. By complete, I mean \n>>something that is fully fleshed out such that it can be put in the spec \n>>more or less as-is if the working group decides they like it. We will \n>>then consider each of these proposals and decide whether we want to \n>>accept the proposal as-is or with changes, or whether we think the idea \n>>should wait for another version of P3P. You are of course welcome to send \n>>us proposals earlier than February 13, or to post incomplete proposals \n>>before February 13 so that you can get feedback on early drafts. Any \n>>pending issue for which we do not have a complete draft by February 13 \n>>will not be addressed in P3P 1.1. So if there is something you care \n>>about, please see to it that you get a proposal in.\n>>\n>>Our next call will be on Wednesday, January 28 at the usual time and \n>>place. Please let me know if you have any items you would like me to \n>>schedule for the agenda.\n>>\n>>Thanks!\n>>\n>>Lorrie\n>>\n>>\n>>\n>>--\n>>Lorrie Faith Cranor, Associate Research Professor\n>>Computer Science and Engineering & Public Policy\n>>Carnegie Mellon University\n>>ISRI, School of Computer Science\n>>5000 Forbes Ave\n>>Pittsburgh, PA 15213\n>>412-268-7534\n>>Office: Doherty Hall 4301A\n>>lorrie@cs.cmu.edu\n>>http://lorrie.cranor.org/\n>\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724-8953;      More info at www.schunter.org\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-7339868"}, {"subject": "Re: I need your status reports and agenda item", "content": "Matthias, \n\nI asked you whether this is ready for publication, as we can't wait any\nlonger on Microsoft. Can you confirm this again?\n\nThanks\n\nRigo\n\nOn Mon, Jan 26, 2004 at 07:09:52PM +0100, Matthias Schunter wrote:\n> \n> Our final draft is on the web. Nothing happened with respect to consent \n> groups.\n> \n> matthias\n> \n> At 11:15 AM 1/26/2004 -0500, Lorrie Cranor wrote:\n> \n> >Except for a few friendly welcome back and congratulation messages (thank \n> >you) I have gotten no response to my email from last week (copied below). \n> >I would like a brief status report from all task forces ASAP and suggested \n> >agenda items for this week's call.\n> >\n\n\n\n", "id": "lists-017-7352887"}, {"subject": "AGENDA: 28 January P3P spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, January 28, 2003, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Discussion of plan for moving forward. Complete drafts due Feb 13.\n\n2. Task force reports (I have ommited those that have completed their \nwork)\n    - Article 10 vocabulary issues - Giles Hogben\n    - Converting P3P data schema to XML schema - Giles Hogben\n    - Consent choices - Matthias Schunter\n    - Compact policies - Brooks Dobbs\n    - Agent and domain relationships - Jack Humphrey\n    - P3P beyond HTTP - Patrick Hung\n\n3. Primary purpose specification - has anyone been working on this?\n    We need to figure out how to move forward on getting a complete\n    draft by Feb 13 or drop this.\n\n4. Open bugzilla items\n\nclarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\nstrengthen 2.3.2.7 user agent requirements\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=174\n\nGiles has submitted several - are these issues the whole working\ngroup needs to address?\n\n5. Set date for next call (Feb 4 or 11?)\n\n\n\n", "id": "lists-017-7361443"}, {"subject": "Re: I need your status reports and agenda item", "content": "yes. I'd like to review the final draft. Otherwise, I feel its ready for \npublication.\nmts\n\nAt 11:46 AM 1/27/2004 +0100, Rigo Wenning wrote:\n>Matthias,\n>\n>I asked you whether this is ready for publication, as we can't wait any\n>longer on Microsoft. Can you confirm this again?\n>\n>Thanks\n>\n>Rigo\n>\n>On Mon, Jan 26, 2004 at 07:09:52PM +0100, Matthias Schunter wrote:\n> >\n> > Our final draft is on the web. Nothing happened with respect to consent\n> > groups.\n> >\n> > matthias\n> >\n> > At 11:15 AM 1/26/2004 -0500, Lorrie Cranor wrote:\n> >\n> > >Except for a few friendly welcome back and congratulation messages (thank\n> > >you) I have gotten no response to my email from last week (copied below).\n> > >I would like a brief status report from all task forces ASAP and \n> suggested\n> > >agenda items for this week's call.\n> > >\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724-8953;      More info at www.schunter.org\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-7369688"}, {"subject": "Re: I need your status reports and agenda item", "content": "Not really final, but take a look at \nhttp://www.w3.org/P3P/2004/WD-P3P11-20040203.html\n\nRigo\n\nOn Tue, Jan 27, 2004 at 01:56:10PM +0100, Matthias Schunter wrote:\n> yes. I'd like to review the final draft. Otherwise, I feel its ready for \n> publication.\n> mts\n> \n> At 11:46 AM 1/27/2004 +0100, Rigo Wenning wrote:\n> >Matthias,\n> >\n> >I asked you whether this is ready for publication, as we can't wait any\n> >longer on Microsoft. Can you confirm this again?\n> >\n\n\n\n", "id": "lists-017-7378829"}, {"subject": "[Minutes]: 28 January P3P spec cal", "content": "P3P Specification Call 28 Jan 2004\n\nPresent:\n\nBrooks Dobbs\nGiles Hogben\nJeff Edelen\nLorrie Cranor\nRigo Wenning Jack Humphrey Dave Stampley\n\n\n1/ What can be finished until 13 Feb should be ready and in by then.\nOther things will be dropped.\n\n2/ TF Reports\n\na/ Giles Art. 10\n\nACTION Giles: Send draft to the WG and we'll discuss it for agreement on\nthe next call\n\nb/ Giles XML Schema\n\nStill trouble with the files. Need to make a comprehensive package.\nMore trouble with XML Schema. Giles said we can't define base data\nschema ACTION Rigo Giles: Take that offline and figure out how to fit it\ninto the spec. Get feedback from Massimo\n\nc/ consent choices Draft is mainly done. We will put this out and look\nfor public feedback.\n\nd/ compact policies.\n\nNothing done so far as performance feedback (first milestone) never\nhappened.  We were considering removing compact stuff completly.\nPerformance question.  More discussion on whether we should deprecate\ncompact format.\n\nACTION: All think about benefit and tradeoffs and we'll make a decision\non the next call.\n\ne/ domain relationsships\n\nGot stuck a bit in the discussion about what this means for ad networks.\nNot sure how this can be addressed in the Spec. Not enough attention\nover the last couple of month.  Lorrie asked if this is worthwhile\npursuing. Discussed what we initially wanted.\n\nJack: Action: Get together with Rigo to figure out how to get basic\nmechanism into form.  Guidelines for Relationships.\n\n3/ Next meeting 4 Feb starting !!!10amEST!!! for 2 hours\n\nAction: Lorrie get information from W3C whether sufficient slots are\navailable on the W3C Bridge and get Bridge configured.\n\nBest,\n\nRigo\n\n\n\n", "id": "lists-017-7386715"}, {"subject": "Feb 4 P3P spec call 10amnoo", "content": "I confirmed that we can use our usual teleconference bridge for an \nextended P3P WG conference call next Wednesday, February 4 from 10am to \nnoon US Eastern. So, mark your calendars and plan to be there!\n\nLorrie\n\n\n\n", "id": "lists-017-7394934"}, {"subject": "AGENDA: 9 June P3P Spec Cal", "content": "The next P3P specification group conference call will be on\nWednesday, June 9, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\n1. P3P Generic attribute for XML applications - discuss draft and what\nto do about RDF binding.\n[if Rigo has anything new to report]\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0012.html\n\n2. Comments on latest WD\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004May/0010.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004May/0015.html\n\n3. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004May/0011.html\n\n4. XML schema stuff\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004May/0014.html\n\n5. Schedule for going to last call\n\n6. Schedule next call (June 16?)\n\n\n\n\n", "id": "lists-017-7429587"}, {"subject": "CFP: International Journal of Business Process Integration and Management (IJBPIM", "content": "Apologies if you receive multiple copies of this message.\n\n\nCALL FOR PAPERS\n===============\n\nInternational Journal of Business Process Integration and Management\n(IJBPIM)\n----------------------------------------------------------------------------\n-\nISSN (Print) : 1741-8763 ISSN (Online) : 1741-8771\nA Publication of Inderscience Publishers (www.inderscience.com)\n\nEditor-in-Chief:\n Liang-Jie (LJ) Zhang, IBM T.J. Watson Research Center, USA\n\nURL: https://www.inderscience.com/browse/index.php?journalID=115\n\n\nBusiness processes have played an important role in enabling business\napplication integration and collaboration across multiple organisations. The\nintegration can be categorised into two types: internal integration and\nexternal integration. Internal integration includes all the integration\naspects within one enterprise. Enterprise application integration (EAI) is a\ntypical example of internal integration. External integration covers all the\npossible integration patterns across multiple enterprises. The typical\nbusiness process based external application integration includes business\nprocess to application integration (BP2Ai) and business process to business\nprocess integration (BP2BPi).\n\nTo stay competitive, companies must be agile in adapting their business\nprocesses to the ever-changing market dynamics. The adaptive business\nprocess based enterprises should look beyond the traditional enterprises and\nmarketplaces through collaborative interactions and dynamic e-business\nsolution bindings. The enterprise infrastructure has to provide the\ncapability for dynamic discovery of trading partners and service providers\nas well as enabling federated security mechanisms, solution monitoring and\nmanagement.\n\nThe International Journal of Business Process Integration and Management\nwill focus on the emerging business process modelling, simulation,\nintegration and management using emerging technologies. IJBPIM is the first\nacademic journal that concentrates on the information technology (IT) level\nas well as the relationship between the business level and IT implementation\nlevel.\n\nOBJECTIVES\nThe objectives of IJBPIM are to establish an effective channel of\ncommunication between policy makers, government agencies, academic and\nresearch institutions and persons concerned with the complex role of\nbusiness processes in e-business solutions, engineering design\ncollaboration, logistics management, etc. It also aims to promote and\ncoordinate developments in the field of business process integration and\nmanagement. The international dimension is emphasised in order to overcome\ncultural and national barriers and to meet the needs of accelerating\ntechnological and ecological change and changes in the global economy.\n\nREADERSHIP\nIJBPIM provides a vehicle to help professionals, academics, researchers and\npolicy makers, working in the field of e-business solutions, business\ntransformation and business education, to disseminate information and to\nlearn from each others' work.\n\nCONTENTS\nIJBPIM publishes original papers, review papers, technical reports, case\nstudies, conference reports, management reports, book reviews. Special\nIssues devoted to important topics in Business Process Integration and\nManagement will occasionally be published.\n\nSCOPE: Topics of interest include, but are not limited to, the following:\n- Mathematical foundation of business process modelling, integration and\nmanagement\n- Business process modelling methodology\n- Business process integration architecture\n- Collaborative business processes\n- Extended business collaboration architecture and solutions\n- Business process based business transformation\n- Ontology and business rules\n- Enabling technologies for business process integration\n- Enabling technologies for business process management\n- Performance analysis for business process integration and management\n- Case studies\n\nSUBMISSION FOR PAPERS\nPapers and queries should be submitted to:\nhttps://www.inderscience.com/papers/index.php\n\nAll papers are refereed through a double blind process. A guide for authors,\nsample copies and other relevant information are available on the website\nwww.inderscience.com. For questions regarding the submission and review\nstatus, please send e-mail or write to:\n\nAssistant Editor-in-Chief:\n        Patrick C. K. Hung, Hong Kong University of Science and Technology,\nHong Kong\n                            University of Ontario Institute of Technology,\nCanada\n        E-mail: cshck AT cs.ust.hk\n\n\n\n", "id": "lists-017-7437512"}, {"subject": "CFP: The International Journal of Web Services Research (JWSR", "content": "Apologies if you receive multiple copies of this message.\n\n\nCALL FOR PAPERS\n===============\n\nThe International Journal of Web Services Research (JWSR)\n---------------------------------------------------------\n\"Providing leading technologies, development, ideas, trends, and data sets\nto an international readership of researchers and engineers in the field of\nWeb services.\"\n\nA Publication of Idea Group Publishing/Information Science Publishing, USA\nISSN: 1545-7362 (http://www.idea-group.com/JOURNALS/details.asp?id=4138)\n\n____________________________________________________________________________\n_______\nEditor-in-Chief:\n Liang-Jie (LJ) Zhang, IBM T.J. Watson Research Center, USA\n\nThe International Journal of Web Services Research (JWSR) is a high-quality\nrefereed journal on Web services research and engineering that serves as an\noutlet for individuals in the field to publish their research as well as\ninterested readers. As a research and engineering journal, the International\nJournal of Web Services Research, will facilitate communication and\nnetworking among Web services/e-Business researchers and engineers in a\nperiod where considerable changes are taking place in Web services\ntechnologies innovation, and stimulate production of high-quality Web\nservices solutions and architectures.\n\nWeb services are network-based application components with services-oriented\narchitecture using standard interface description languages and uniform\ncommunication protocols. Due to the importance of the field, standardization\norganizations such as WS-I, W3C, OASIS and Liberty Alliance are actively\ndeveloping standards for Web services. The International Journal of Web\nServices Research (JWSR) is the first refereed, international publication\nfeaturing only the latest research findings and industry solutions dealing\nwith all aspects of Web services technology. The overall scope of this\njournal will cover the advancements in the state of the art, standards, and\npractice of Web services, as well as to identify the emerging research\ntopics and define the future of Services computing, including Web services\non Grid computing, Web services on multimedia, Web services on\ncommunication, Web services on e-Business, etc. In conclusions, the JWSR\nprovides an open, formal publication for high quality articles developed by\ntheoreticians, educators, developers, researchers and practitioners for\nprofessionals to stay abreast of challenges in Web services technologies.\n\nSCOPE: Topics of interest include, but are not limited to, the following:\n\n* Mathematic foundations for service oriented computing\n* Web services architecture\n* Web services security and privacy\n* Frameworks for building Web services applications\n* Composite Web services creation and enabling infrastructures\n* Web services discovery, negotiation and agreement\n* Resource management for Web services\n* Solution management for Web services\n* Dynamic invocation mechanisms for Web services\n* Quality of service for Web services\n* Cost of service for Web services\n* Web services modeling\n* Web services performance\n* UDDI enhancements\n* SOAP enhancements\n* Case studies for Web services\n* e-Business applications using Web services\n* Grid based Web services applications (e.g. OGSA)\n* Business process integration and management using Web services\n* Multimedia applications using Web services\n* Communication applications using Web services\n* Interactive TV applications using Web services\n* Semantic services computing\n* Business Grid\n\nSUBMISSIONS:\nAll submissions and evaluations are processed electronically. However,\naccepted manuscripts and copyright forms will be sent the publisher for\npublication. The publisher will publish the journal in both print and\nelectronic formats. We are going to have an official Web site and an\nelectronic submission system. Further details will be released soon. Please\nsend your paper in PDF or Word format to directly to\nhttp://www.mine.tku.edu.tw/JWSR/. For questions regarding the submission and\nreview status, please send e-mail or write to:\n\nAssistant Editor-in-Chief:\n        Patrick C. K. Hung, Hong Kong University of Science and Technology,\nHong Kong\n                            University of Ontario Institute of Technology,\nCanada\n        E-mail: cshck AT cs.ust.hk\n\nSPECIAL ISSUE PROPOSAL\nJWSR publishes special issues on the recent trends in Web services\ntechnologies and solutions. A short proposal containing the title of\nproposed special issue, tentative list of invited authors, suggested date of\npublication and a call-for-papers should be sent to the Assistant\nEditor-in-Chief for review.\n\n\n\n", "id": "lists-017-7457283"}, {"subject": "revised primary purpose lis", "content": "Here is my revised primary purpose list that I mentioned on the call \ntoday.  It reflects Rigo's comments and my re-ordering and grouping. My \nstudent, Serge, is going to take a pass at going through it and coming \nup with XML tokens, short human-readable descriptions, and full \ndefinitions. He and I will iterate on it and hopefully have something \nfor you all to look at before the call next week.\n\nLorrie\n\n\n\ndistributing content (serving pages, network services)\n\nauthentication and authorization (login, etc)\n\nstate management\n\n\nregistration, enrollment, and subscription\n\naccount management (of existing accounts)\n\ncustomizing online experience\n\nresponding to user (feedback)\n\n\n\nsales of products or services\n\ncharitable donations\n\npayments and transaction facilitation\n\norder fulfillment and delivery\n\nbanking and financial management\n\n\neducation - including dissemination of educational materials, testing,\n    grading, interactions with teachers or other students, etc.\n\ngaming (that does not involve gambling)\n\ngambling\n\nentertainment, arts, and literature\n\nnews and information\n\ncommunications services (email, voice, videophone, instant messaging, \netc.)\n\nsearch\n\nsurveys\n\ngovernment services (e-government)\n\nadvertising, marketing, and promotion\n\nhealthcare services\n\n\n\n", "id": "lists-017-7476497"}, {"subject": "next p3p spec call FRIDAY June 1", "content": "The next P3P spec call will be on FRIDAY June 18 at 11 am US Eastern. \nMark your calendars.\n\n\n\n", "id": "lists-017-7484460"}, {"subject": "MINUTES: 9 June P3P Spec Cal", "content": "P3P specification group conference call held on\nWednesday, June 9, 2004, 11 am - 12 pm US Eastern. \n\nJack Humphrey\nLorrie Cranor\nGiles Hogben\nRigo Wenning\nSerge Engleman\n\n1/ RDF - equivalent to XML-generic-attribute\n\nGiles reported that RDF folks have a way to link in to RDF-Schema \nof P3P. This is done in OWL-S. We decided to move forward the following \nway: \n\nGiles will send Rigo the RDF-Schema on P3P JRC has done.\nJRC can transform this into OWL-S\n\nLorrie: questions:\n\nshort term\n/ what do we need to do for RDF in the 1.1 Specification\n\nRigo thinks that we should just update the RDF Schema\nLorrie: We don't need to say something about RDF in the Spec\nwe give ourselves an Action item to review the RDF/OWL question \nonce we are in last call.\nGiles notes that just updating the RDFS doesn't buy anything. \nOWL-S would not be that complicated. \n\nlong term question:\nWhat are we do about the RDF Note. We look into this later..\nACTION: Lorrie put RDF-Note into Bugzilla\n\nConclusion: we don't alter the remarks about RDF in the Spec. There \nis no need for additional remarks. \n\n2/ Comments on the latest working drafts\n\nLorrie and Jack sent remarks\n\nJack wanted to change the DNS, Rigo agreed to change to example.org\nACTION Rigo: insert all the changes from Lorrie and Jack\n\n3/ Primary Purpose Specification\n\nIf the 23 purposes look reasonable, Lorrie's graduate will start working \non \nit and will send result to the list. Nobody found that this was a bad \nidea. \n\nLorrie arranged them in groups. She presented the groups. \nAction: Lorrie, add healthcare service to the list\nAction: Lorrie, publish the new list to the mailing-list\n\nGiles wanted something like network services. Lorrie suggested to have \nfull definitions of the terms and strings like for the UA-guidelines. \nThis was \nseen as reasonable.\n\n4/ XML Schema Stuff\n\nLorrie felt that the Schema-Stuff looks really nice. You should use the \nold policy \nformat, but use the new schema format. 1.0 UA should just ignore the \nschema. \n\nGiles: \n\n1 new schema new policy\n2 old schema old policy\n\nLorrie said, it is not backwards compatible if we put the new schemas \nin, but we \ncould provide both. We might use the extension mechanism to point to the \nnew schema. \nGiles hasn't done the transform from new dataschema to old dataschema. \nAll other\ntransforms are done. Giles don't think it is possible to do the \ntransform from new \ndataschema (xsd) to old dataschema. \n\nLorrie: IBM did a custom dataschema and Privacy Bird would use it. \nGiles: if you wrote something with the new schema and to have to \ntransform \nit back, there is no point in using the format.\nWhy is transform back \nNew format has morphes, building transform would be big and \ntimeconsuming to \nwrite. \nGiles: new schema just a tool to build schemas. \nLorrie: manually build old schema? \nRigo: this isn't a solution\n\nPrivacy Bird interpretes it for looking up the categories. JRC client \nwould check \nwhether it is valid on the schema. PB would also complain and say that \nthis is \nnot a valid policy, would only see a yellow bird. \n\nQuestion about backwards compatibility. Rigo suggested to keep the base \ndata schema \nin the old format as alternative and allow for new schema all over. \n\nLorrie: seems that it would make sense to change the rules for backwards \ncompatibility. \nDoesn't make sense to make the decision now, we should put a proposal on \nthe mailing\nlist. \n\nProposal: One can write a new schema and policies but would have to \nprovide \nthe old schema format. Missing schema wouldn't be penalised. There will \nbe \nan extension element providing a container for the new schema format. \n\nAction: Giles, provide a proposal to move to XML Schema.  \n\nNext Call: Friday 18 June 11H00 EST\nAction: Lorrie get the bridge.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "lists-017-7490876"}, {"subject": "Proposal for XSD data schema backward compatibilit", "content": "Hi,\nDuring the working group call yesterday, we came up with the following \nproposal for integrating the new data schema format:\nThis was agreed among those present on the call, but we would like to solicit \nwider approval/disapproval. Please let me know if you think I represented our \ndiscussion accurately, and if you agree/disagree with the proposal.\nLorrie - I have included the other two small issues that I flagged up in the \nspec document.\n\nXSD Base Data Schema Backward compatibility proposal\n-------------------------------------------------------------------------------\n\n1. For policies using data elements from the P3P1.0 base data schema, \npolicies must be publised in the P3P 1.0 format. This may be acheived \nhowever, but writing and validating the policy using the new schema format \nand then using the provided XSLT to transform back to the old format. W3C can \nprovide such transforms as a service.\n2. Policy authors creating or using custom schemas MUST use the new format.\nThey then have two options:\na. write the policy in the new format and transform back to the old format - \nthe new elements will then not be validated by user agents (because the \nschema will not be found)\nb. write the policy in the new format and transform back to the old format, \nBUT include an EXTENSION element which provides the elements in a format \nwhich validates against the new schema they have written. User agents \nimplementing P3P1.1. must then validate such extensions (which can easily be \ndone using a schema validator)\n\nI would also like to draw your attention to a question which I included in \nthe new format specification (Lorrie, perhaps we can put it in Bugzilla):\nFor the specification of  entity address data, XSD format following the old \nstructure is somewhat cumbersome. because you end up with something like:\n\n<user>\n        <contact>\n                <postal>\n                        <name>\n                                Entityname\n                        </name>\n                </postal>\n        </contact>\n</user>\n\n<user>\n        <contact>\n                <postal>\n                        <city>\n                                Entitycity\n                        </city>\n                </postal>\n        </contact>\n</user>\n\n<user>\n        <contact>\n                <postal>\n                        <street>\n                                Entitystreet\n                        </street>\n                </postal>\n        </contact>\n</user>\n\netc.....\n\nOne suggestion from a colleague is to change the format to the more efficient:\n\n<user>\n        <contact>\n                <postal>\n                        <name>\n                                Entityname\n                        </name>\n                        <city>\n                                Entitycity\n                        </city>\n                        <street>\n                                Entitystreet\n                        </street>\n                </postal>\n        </contact>\n</user>\n\nAnother issue for bugzilla is that the term name appears twice - once for \nbusiness and once for the user - apparently with different semantics \n(otherwise it would have been a data structure)-  but I would say it should \nonly appear once.\n\n\n\n", "id": "lists-017-7501603"}, {"subject": "data element or simply data", "content": "While reviewing the Spec, Lorrie noted:\n\nin the table with the anchor #plain_trans \n> CATEGORIES optional -- the wording here is stated as \"the data\n> element\" but I think \"this data\" would make more sense... I wasn't\n> involved in this discussion\n\nOriginal is:\nCATEGORIES | optional (attribute of data elements) | \nif no: the data element is required [append to data element or category] \nif yes: the data element is optional [append to data element or \ncategory] \n\n(last line in the table)\n\nRigo\n\n\n\n", "id": "lists-017-7512073"}, {"subject": "Re: comments on latest working draf", "content": "Am Tuesday 25 May 2004 21:52 verlautbarte Lorrie Cranor :\n> I read through the latest working draft\n> http://www.w3.org/TR/2004/WD-P3P11-20040427/ and found a number of\n> minor errors that need to be fixed:\n>\n> 1.1.1 The list of enhancements is incomplete. It also needs to\n> include: - An optional element for declaring the jurisdiction of data\n> recipients - Definitions of identified, identifiable, linked, and\n> linkable data - An optional element for declaring domain\n> relationships\n> - A compact version of the STATEMENT element for use in compact\n> policies\n>\n> It would also be good to list the relevant sections for all of these\n> items\n\nDone\n>\n> 1.3 change reference to my book to a reference in the non-normative\n> references appendix\n>\nDone\n\n> 1.3.1 last sentence, there is a quoted phrase at the end of the\n> sentence - remove quotes and italicize instead.\n\nDone\n>\n> 2.3.2.7 In first sentence of paragraph hyperlink \"linked\" to 1.3.4\n>\nDone\n\n> 2.3.2.9\n>\n> The section about Domain Relationships --> This section\n>\n> modifications would allow --> modifications allow\n>\n> change hyperlink to issues to a reference in the non-normative\n> references appendix\n\nDone\n>\n> 2.3.2.9.1 extension element to --> extension to\n\nDone\n>\n> the extension needs an xmlns (in BNF and examples)\nDone\n\n>\n> 2.3.2.9.3 when only using --> when using\n\nDone\n>\n> 2.5 This doesn't appear to reflect the changes I proposed in my April\n> 9 email\n>\nHi hi, got your first version of Draft. Should be fixed now\n\n> 3.2.3 required. or mixed. --> required or mixed \n\nPattern not found: required. or mixed \n\nBut I think we deprecated the use of Group-Info as it is already \nincluded in the grouping mechanism..\n\n>\n> 3.3.2 one implementers authoring --> one implementer's authoring\n\nDone\n>\n> 3.3.6.1 need xmlns attribute and long and short description in BNF\n> and examples\n\nDone\n\n>\n> 4 strike first paragraph (repeated in second paragraph)\nDone\n>\n> 4.7 Add: See Section 6.4 for guidelines designed to reduce the chance\n> that a P3P user agent will accept an invalid compact policy.\n\nWe decided to remove 4.7, no? At least this is what the Spec says at the \nmoment. I think it is already said in 6.4, no?\n\n>\n> 6.2 are available at ??? --> will be posted on the W3C web site when\n> they become available.\n\nDone\n>\n> remove the . at the end of the money definition\nDone\n>\n> add the CATEGORIES label to the first column of demographic\nDone\n>\n> CATEGORIES optional -- the wording here is stated as \"the data\n> element\" but I think \"this data\" would make more sense... I wasn't\n> involved in this discussion\n\nA good question to the list..\n>\n> Appendix 9 - add P3P 1.1 working group contributors in a new\n> paragraph at the beginning\n\nDone\n\n>\n> Changelog - spell check, I see a bunch of typos\n>\n>\n> Also we need to add the following (basically a summary of our\n> backwards compatibility guidelines documenting that we followed\n> them):\n>\n> 1.1.7 Backwards Compatibility\n>\n> P3P 1.1 has been designed so that P3P 1.0 user agents can process P3P\n> 1.1 policies and  policy reference files. This implies both that the\n> P3P 1.1 policies and  policy reference files are fully compliant with\n> the P3P 1.0 XML schema,  and that the semantics of these files will\n> not be misinterpreted by a  user agent that interprets them according\n> to the P3P 1.0  specification. All new syntax introduced in P3P 1.1\n> has been introduced as optional extensions using the P3P 1.0\n> extension mechanism. Changes to requirements or definitions\n> introduced in P3P 1.1 add clarity where the P3P 1.0 specification is\n> ambiguous, but do not cause a particular P3P vocabulary element to\n> have different meanings in P3P 1.0 and P3P 1.1. In addition, some new\n> requirements or features have been introduced in the P3P 1.1 \n> specification that do not impact the ability of P3P 1.0 user agents\n> to  process P3P 1.1 policies and policy reference files.\nDone \n\nRigo\n\n\n\n", "id": "lists-017-7518742"}, {"subject": "Re: comments on latest working draf", "content": "On Jun 10, 2004, at 12:04 PM, Rigo Wenning wrote:\n\n> Am Tuesday 25 May 2004 21:52 verlautbarte Lorrie Cranor :\n>\n>\n>> 3.2.3 required. or mixed. --> required or mixed\n>\n> Pattern not found: required. or mixed\n>\n> But I think we deprecated the use of Group-Info as it is already\n> included in the grouping mechanism..\n>\n\nThis is right before the sentence \"Statement groups serve two main \npurpose:\" (which should say \"purposes\" rather than \"purpose\")\n\n\n>> 4.7 Add: See Section 6.4 for guidelines designed to reduce the chance\n>> that a P3P user agent will accept an invalid compact policy.\n>\n> We decided to remove 4.7, no? At least this is what the Spec says at \n> the\n> moment. I think it is already said in 6.4, no?\nok\n\nLorrie\n\n\n\n", "id": "lists-017-7530018"}, {"subject": "Re: MINUTES: 9 June P3P Spec Cal", "content": "I had a conversation with Giles. \n\nThe minutes were not absolutely correct with respect to the \nRDF/OWL/OWL-S Question. So I send in some insight I got after I've sent \nout the minutes:\n\nJust talked to Fabien Gourdon:\nThe OWL-S binding will be very easy and not much effort. So we have to \ncompare the Schema from Brian McBride and the one that JRC has \nproduced. I asked Giles to send me JRC's RDFS to be able to compare to \nthe Note and then take a decision. \n\nSo we need to do both, the RDFS renovation and the OWL-S binding. But I \nwould suggest to do that in the separate Note or to add that Note as an \nappendix once it is done. We should care about this once we have time.\n\nBest, \nRigo\n\n\n\n\n", "id": "lists-017-7537995"}, {"subject": "Re: comments on latest working draf", "content": "Am Thursday 10 June 2004 18:23 verlautbarte Lorrie Cranor :\n> >> 3.2.3 required. or mixed. --> required or mixed\n> >\n> > Pattern not found: required. or mixed\n\nIt was required.or mixed (missing space in your term ;)\n> >\n> > But I think we deprecated the use of Group-Info as it is already\n> > included in the grouping mechanism..\n>\n> This is right before the sentence \"Statement groups serve two main\n> purpose:\" (which should say \"purposes\" rather than \"purpose\")\n\nBoth fixed now\n\nRigo\n\n\n\n\n\n", "id": "lists-017-7545160"}, {"subject": "Re: Proposal for XSD data schema backward compatibilit", "content": "Let me elaborate on the implications of this proposal... this breaks  \nour backwards compatibility guidelines. This is an issue in the  \nfollowing cases:\n\n- Web sites that use P3P 1.0 custom schema (very few, the only one we  \ncould think of was ibm.com) will not have P3P policies that will be  \nreadable by P3P 1.1 user agents (unless those user agents voluntarily  \nbuild in backwards compatibility).\n\n- Web sites that create P3P 1.1 policies with custom schema will not be  \nreadable by P3P 1.0 user agents that look at data elements (Privacy  \nBird, JRC, etc... this will probably not be a problem for IE6 or  \nNetscape 7 because they don't appear to look at the data element level,  \nbut I could be wrong).\n\nI really don't like the idea of breaking backwards compatibility,  \nhowever, these cases are rare enough that I'm not sure its a big deal.  \nOn the other hand, given how rare these cases are, we might argue its  \nalso not worth making this change... so I guess I'm still on the fence.  \nThe other alternative we discussed was providing a transform for the  \nschema file itself from the new format back to the old. Giles felt this  \nwould be fairly difficult, although I don't think impossible, and it  \nmay be something Serge can help with.\n\nI guess I want to see laid out the arguments as to why it is  \nadvantageous to make this change so we can have a discussion about  \nwhether it is worth breaking backwards compatibility for it.\n\nLorrie\n\np.s Giles, please go ahead and add those items at the end to bugzilla\n\nOn Jun 10, 2004, at 10:02 AM, Giles Hogben wrote:\n\n>\n> Hi,\n> During the working group call yesterday, we came up with the following\n> proposal for integrating the new data schema format:\n> This was agreed among those present on the call, but we would like to  \n> solicit\n> wider approval/disapproval. Please let me know if you think I  \n> represented our\n> discussion accurately, and if you agree/disagree with the proposal.\n> Lorrie - I have included the other two small issues that I flagged up  \n> in the\n> spec document.\n>\n> XSD Base Data Schema Backward compatibility proposal\n> ----------------------------------------------------------------------- \n> --------\n>\n> 1. For policies using data elements from the P3P1.0 base data schema,\n> policies must be publised in the P3P 1.0 format. This may be acheived\n> however, but writing and validating the policy using the new schema  \n> format\n> and then using the provided XSLT to transform back to the old format.  \n> W3C can\n> provide such transforms as a service.\n> 2. Policy authors creating or using custom schemas MUST use the new  \n> format.\n> They then have two options:\n> a. write the policy in the new format and transform back to the old  \n> format -\n> the new elements will then not be validated by user agents (because the\n> schema will not be found)\n> b. write the policy in the new format and transform back to the old  \n> format,\n> BUT include an EXTENSION element which provides the elements in a  \n> format\n> which validates against the new schema they have written. User agents\n> implementing P3P1.1. must then validate such extensions (which can  \n> easily be\n> done using a schema validator)\n>\n> I would also like to draw your attention to a question which I  \n> included in\n> the new format specification (Lorrie, perhaps we can put it in  \n> Bugzilla):\n> For the specification of  entity address data, XSD format following  \n> the old\n> structure is somewhat cumbersome. because you end up with something  \n> like:\n>\n> <user>\n>         <contact>\n>                 <postal>\n>                         <name>\n>                                 Entityname\n>                         </name>\n>                 </postal>\n>         </contact>\n> </user>\n>\n> <user>\n>         <contact>\n>                 <postal>\n>                         <city>\n>                                 Entitycity\n>                         </city>\n>                 </postal>\n>         </contact>\n> </user>\n>\n> <user>\n>         <contact>\n>                 <postal>\n>                         <street>\n>                                 Entitystreet\n>                         </street>\n>                 </postal>\n>         </contact>\n> </user>\n>\n> etc.....\n>\n> One suggestion from a colleague is to change the format to the more  \n> efficient:\n>\n> <user>\n>         <contact>\n>                 <postal>\n>                         <name>\n>                                 Entityname\n>                         </name>\n>                         <city>\n>                                 Entitycity\n>                         </city>\n>                         <street>\n>                                 Entitystreet\n>                         </street>\n>                 </postal>\n>         </contact>\n> </user>\n>\n> Another issue for bugzilla is that the term name appears twice - once  \n> for\n> business and once for the user - apparently with different semantics\n> (otherwise it would have been a data structure)-  but I would say it  \n> should\n> only appear once.\n>\n>\n>\n\n\n\n", "id": "lists-017-7552536"}, {"subject": "Call For Participation: 2004 IEEE International Conference on Web Services (ICWS 2004", "content": "2004 IEEE International Conference on Web Services (ICWS 2004)\nTheme: Convergence of Web Services, Grid Computing, e-Business and Autonomic\nComputing\nJuly 6-9, 2004, San Diego, California, USA\nhttp://conferences.computer.org/icws/2004/\n\nSponsored by the IEEE Computer Society\nTechnical Community for Services Computing (TCSC)\n\nThis year we are pleased to present an extremely strong technical program. A\ntotal of 230 papers were submitted to ICWS this year (a record by far).\nSubmissions were from over 15 countries. Of the 230 submissions, only 66\nwere accepted as full research papers. We were fortunate to have about 100\nprogram committee members who assisted us by giving very detailed and timely\nreviews. All papers went through a thorough review process. At least two or\nmore reviewers reviewed each paper. We had significant online PC discussion\nfor both controversies and for final decision. After extensive discussions,\n66 papers were accepted for full paper publication and presentation.\n\nA key aspect of ICWS is to bring the worlds of researchers from both\nComputer Science and Business Management together in a single, high-quality\nforum. Of the 66 papers accepted, there were CS papers, Business papers, and\nwhat we call \"bridge\" papers as they bridge the gap between the two fields.\nIn addition, we offer a strong industry track with 19 papers from\nresearchers and practioners working in the frontier of Web Services in\nindustry. Furthermore, this year's technical program also contains 16 short\npapers in which authors are able to give a brief description of their\nresearch. Short paper sessions are newly introduced to ICWS this year and we\nhope to have started a new and fruitful tradition. Finally, ICWS 2004\ntechnical program also includes three poster paper sessions\naccepted from a separate submission channel enabling work-in-progress\nresults to be shared and disseminated at the conference and 5 tutorials,\nreviewing the state of art in five different areas related to advances in\nWeb Services.\n\nKeynote Address\n\nKeynote 1: Convergence of Web Services, Grid Services and Business Processes\nDr. Donald F. Ferguson\nIBM Fellow, Member IBM Academy of Technology\nChief Architect, IBM Software Group\nChairman of IBM SWG Architecture Board\n\nAbstract:\nThe \"Grid\" and \"Web services\" are two of the fastest growing and most\ndiscussed areas in academic and\ncommercial computing literature. Mergers, acquisition, partnerships and\neconomic dynamics are driving commercial\ninvestment in business process (re)-engineering. This talk will discuss the\nrecent and important convergence of\nmany of these concepts into enterprise service architectures, which are\nforming the base for the next generation of\ncommercial and academic distributed computing.\n\n\nKeynote 2: Extending the Innovation Ecosystem\nSharon Nunes\nVice President, Emerging Business\nIBM Research\nYorktown Heights, New York\n\nAbstract:\nWhat Is Innovation? It's not always about inventing something entirely new.\nInnovation occurs at the\nintersection of invention and insight. It's about the application of\ninvention ? the fusion of new developments and\nnew approaches to solve problems. (Sam Palmisano, Delivered at the Council\non Competitiveness Annual Meeting,\nWashington, D.C., October 30, 2003).\nIn the 21st Century, we are approaching fundamental limits of technology\nthat will drive new paradigms for\nsoftware and systems. Software complexity is driving a rethinking of\nsoftware development. There are external\nforces including government and societal, that are significantly influencing\nthe technology agenda. In addition, the\nchanging business environment demands new approaches to use of IT ?\ntransformation must be fueled by\ninnovation. Can we manage innovation? Can we create a culture of innovation?\nCan we work with customers and\npartners to drive innovation? Various innovation approaches are being\ndeployed to enhance IBM's innovation\necosystem. Lessons learned and future innovation drivers will be presented.\n\n\nKeynote 3: Going Public with Software-as-a-Service\nEphraim Feig\nChief Technology Officer and Chief Marketing Officer\nKintera, Inc.\nSan Diego, California, USA\n\nAbstract:\nThe market is demanding seamless application integration. Those who can\ndeliver on this demand will be\nrewarded. Web services will play a key role in making it possible,\naffordable, and ease to use.\n\nKeynote 4: Business Services Networks\nJay M. Tenenbaum\nChairman of CommerceNet\nDirector of Webify Solutions and Medstory Inc.\n\nAbstract:\n\nThe fundamental challenge of e-commerce is enabling companies to do business\nwith one another across a\nnetwork, despite different business processes and computer systems.\nTraditionally, these problems were overcome\nthrough expensive custom point-to-point integration or Electronic Data\nInterchange (EDI) networks. The promise of\nthe Internet, by contrast, is an open e-business platform where companies\ncan do business spontaneously with\nanyone, anywhere, anytime. Business Services Networks fulfill that vision.\nThis talk introduces the concept of Business Services Networks and their\nprofound business and technology\nimplications for e-commerce. BSNs are Internet business communities where\ncompanies collaborate through loosely\ncoupled business services. Participants register business services (e.g.,\nplace an order, make a payment) that others\ncan discover and incorporate into their own business processes with a few\nclicks of a mouse. Companies can build\non each other's services, creating new services and linking them into\nindustry-transforming, network-centric\nbusiness models. We also discuss evolution of BSNs since early 1990's,\nemerging technological underpinnings, and\nCommerceNet's role in catalyzing their adoption.\n\nKeynote 5: Managing the Intelligent Enterprise\nUmeshwar Dayal\nHP Fellow and Director\nIntelligent Enterprise Technologies Laboratory\nHewlett-Packard Labs.\nUmeshwar.dayal@hp.com\n\nAbstract\nOver the last few years, we have seen the transformation of the traditional\nmonolithic enterprise, in which all\noperations were performed in-house, to the extended enterprise, which\nconsists of a network of collaborating\nentities. Global operations, outsourcing, and increasing specialization have\nall contributed to this trend. One\nchallenge facing the extended enterprise is how to reconnect the information\nflows and business processes that were\ndisconnected as the enterprise disaggregated. The emergence of web services,\nservice-oriented architectures, and\nbusiness process modeling and execution standards are helping to address\nthis challenge.\nOur contention is that the next phase of evolution is the rise of the\nintelligent enterprise, which is characterized\nby being able to adapt quickly to changes in its operating environment. The\nintelligent enterprise monitors its own\nbusiness processes and its interactions with customers, partners, suppliers,\nand collaborators; it understands how this\ninformation relates to its business objectives; and it acts to control and\noptimize its operations to meet its business\nobjectives. Decisions are made quickly and accurately to modify business\nprocesses on the fly, dynamically allocate\nresources, or change business partners (e.g., suppliers, service providers)\nand partnerships (e.g., establish new\nservice level agreements).\nThis talk will describe challenges in managing the business operations of an\nintelligent enterprise. While a\nplethora of tools exist for managing the IT infrastructure (servers,\nstorage, and network resources) of the enterprise,\nthere is little systematic support today for the closed loop management and\ncontrol of business operations. We will\ndescribe technology approaches to intelligent business operations management\nthat we are pursuing at HP Labs., the\nprogress we have made, and some open research questions.\n\n\n\nPANELS\nPanel 1: Future of Service-Oriented Computing\nModerator: Calton Pu, Georgia Tech, USA\n\nPanel 2: Innovative Applications using Web Services\nModerator: Ephraim Feig, Kintera.com, USA\n\nPanel 3: Quality of Service Management\nModerator: Dejan Milojicic, HP Labs, USA\n\nPanel 4: Security and Privacy in Web Services\nModerator: TBA\n\n\nTUTORIALS\n\n1. Service Oriented Architectures and Semantic Web Process\nFrancisco Curbera, Amit Sheth, and Kunal Verma\n\n2. Data Grid and Gridflow Management Systems\nArun Jagatheesan and Reggan Moore\n\n3. Complex Event Processing\nOpher Etzion\n\n4. Successful Service-oriented Architecture with Web services: Beyond the\nHype\nAli Arsanjani\n\n5. Semantic Web services: Current Status and Future Directions\nMassimo Paolucci and Katia Sycara\n\n\n\n", "id": "lists-017-7565964"}, {"subject": "Re: Proposal for XSD data schema backward compatibilit", "content": "The arguments I would give are:\n1. The reason that no schemas have been produced up to now is that the format \nof the BDS has been so obscure and difficult to handle (I have seen at least \none attempt by a very technically able person, which completely failed to \nunderstand the rules for creating the schemas)\n2. Not only is it very difficult for people to create custom schemas, but it \nis also very difficult for this capability to be built into a policy editor, \nwhich of course would be the main driver for uptake.\n3. If we want to encourage extensibility, the best way to do this is to use \nestablished standards.\n\nOn Fri 11 Jun 04 17:34, Lorrie Cranor wrote:\n> Let me elaborate on the implications of this proposal... this breaks\n> our backwards compatibility guidelines. This is an issue in the\n> following cases:\n>\n> - Web sites that use P3P 1.0 custom schema (very few, the only one we\n> could think of was ibm.com) will not have P3P policies that will be\n> readable by P3P 1.1 user agents (unless those user agents voluntarily\n> build in backwards compatibility).\n>\n> - Web sites that create P3P 1.1 policies with custom schema will not be\n> readable by P3P 1.0 user agents that look at data elements (Privacy\n> Bird, JRC, etc... this will probably not be a problem for IE6 or\n> Netscape 7 because they don't appear to look at the data element level,\n> but I could be wrong).\n>\n> I really don't like the idea of breaking backwards compatibility,\n> however, these cases are rare enough that I'm not sure its a big deal.\n> On the other hand, given how rare these cases are, we might argue its\n> also not worth making this change... so I guess I'm still on the fence.\n> The other alternative we discussed was providing a transform for the\n> schema file itself from the new format back to the old. Giles felt this\n> would be fairly difficult, although I don't think impossible, and it\n> may be something Serge can help with.\n>\n> I guess I want to see laid out the arguments as to why it is\n> advantageous to make this change so we can have a discussion about\n> whether it is worth breaking backwards compatibility for it.\n>\n> Lorrie\n>\n> p.s Giles, please go ahead and add those items at the end to bugzilla\n>\n> On Jun 10, 2004, at 10:02 AM, Giles Hogben wrote:\n> > Hi,\n> > During the working group call yesterday, we came up with the following\n> > proposal for integrating the new data schema format:\n> > This was agreed among those present on the call, but we would like to\n> > solicit\n> > wider approval/disapproval. Please let me know if you think I\n> > represented our\n> > discussion accurately, and if you agree/disagree with the proposal.\n> > Lorrie - I have included the other two small issues that I flagged up\n> > in the\n> > spec document.\n> >\n> > XSD Base Data Schema Backward compatibility proposal\n> > -----------------------------------------------------------------------\n> > --------\n> >\n> > 1. For policies using data elements from the P3P1.0 base data schema,\n> > policies must be publised in the P3P 1.0 format. This may be acheived\n> > however, but writing and validating the policy using the new schema\n> > format\n> > and then using the provided XSLT to transform back to the old format.\n> > W3C can\n> > provide such transforms as a service.\n> > 2. Policy authors creating or using custom schemas MUST use the new\n> > format.\n> > They then have two options:\n> > a. write the policy in the new format and transform back to the old\n> > format -\n> > the new elements will then not be validated by user agents (because the\n> > schema will not be found)\n> > b. write the policy in the new format and transform back to the old\n> > format,\n> > BUT include an EXTENSION element which provides the elements in a\n> > format\n> > which validates against the new schema they have written. User agents\n> > implementing P3P1.1. must then validate such extensions (which can\n> > easily be\n> > done using a schema validator)\n> >\n> > I would also like to draw your attention to a question which I\n> > included in\n> > the new format specification (Lorrie, perhaps we can put it in\n> > Bugzilla):\n> > For the specification of  entity address data, XSD format following\n> > the old\n> > structure is somewhat cumbersome. because you end up with something\n> > like:\n> >\n> > <user>\n> >         <contact>\n> >                 <postal>\n> >                         <name>\n> >                                 Entityname\n> >                         </name>\n> >                 </postal>\n> >         </contact>\n> > </user>\n> >\n> > <user>\n> >         <contact>\n> >                 <postal>\n> >                         <city>\n> >                                 Entitycity\n> >                         </city>\n> >                 </postal>\n> >         </contact>\n> > </user>\n> >\n> > <user>\n> >         <contact>\n> >                 <postal>\n> >                         <street>\n> >                                 Entitystreet\n> >                         </street>\n> >                 </postal>\n> >         </contact>\n> > </user>\n> >\n> > etc.....\n> >\n> > One suggestion from a colleague is to change the format to the more\n> > efficient:\n> >\n> > <user>\n> >         <contact>\n> >                 <postal>\n> >                         <name>\n> >                                 Entityname\n> >                         </name>\n> >                         <city>\n> >                                 Entitycity\n> >                         </city>\n> >                         <street>\n> >                                 Entitystreet\n> >                         </street>\n> >                 </postal>\n> >         </contact>\n> > </user>\n> >\n> > Another issue for bugzilla is that the term name appears twice - once\n> > for\n> > business and once for the user - apparently with different semantics\n> > (otherwise it would have been a data structure)-  but I would say it\n> > should\n> > only appear once.\n\n\n\n", "id": "lists-017-7590970"}, {"subject": "Re: Call For Participation: 2004 IEEE International Conference on Web Services (ICWS 2004", "content": "Patrick, \n\nplease!\n\npublic-p3p-spec is not a Web Services announce list.\nThere is no mention on privacy or P3P whatsoever in your posting. \n\nCould you please erase public-p3p-spec from your conference announcement \nmailing-list? \n\nThanks!\n\nRigo\nP.S. For Web Services contact Hugo Haas (hugo@w3.org)\n\nAm Monday 14 June 2004 05:35 verlautbarte Patrick C. K. Hung :\n> 2004 IEEE International Conference on Web Services (ICWS 2004)\n> Theme: Convergence of Web Services, Grid Computing, e-Business and\n> Autonomic Computing\n> July 6-9, 2004, San Diego, California, USA\n> http://conferences.computer.org/icws/2004/\n>\n> Sponsored by the IEEE Computer Society\n> Technical Community for Services Computing (TCSC)\n>\n> This year we are pleased to present an extremely strong technical\n> program. A total of 230 papers were submitted to ICWS this year (a\n> record by far). Submissions were from over 15 countries. Of the 230\n> submissions, only 66 were accepted as full research papers. We were\n> fortunate to have about 100 program committee members who assisted us\n> by giving very detailed and timely reviews. All papers went through a\n> thorough review process. At least two or more reviewers reviewed each\n\n\n\n\n\n", "id": "lists-017-7605387"}, {"subject": "Re: Proposal for XSD data schema backward compatibilit", "content": "So this argument suggests that if we had a tool that could translate  \nfrom new to old schema format then we could keep the old format in the  \nspec but produce a note or appendix explaining the new format and  \nsuggest that schema designers and tool makers use the new format and  \nthen translate back to the old format. This would make it easy for  \npeople to create new schemas if they want to, and would not impact  \nbackwards compatibility.\n\nPersonally, while I agree that the old format is difficult, I am  \ndoubtful that it is the reason we haven't seen custom schemas. I think  \nthere just hasn't been much of a demand for them. Most sites would  \nrather just declare data categories than try to declare their data on  \nsuch a fine grained level. This may change as new products become  \navailable that track data on the back end.\n\nLorrie\n\n\n\nOn Jun 14, 2004, at 3:55 AM, Giles Hogben wrote:\n\n> The arguments I would give are:\n> 1. The reason that no schemas have been produced up to now is that the  \n> format\n> of the BDS has been so obscure and difficult to handle (I have seen at  \n> least\n> one attempt by a very technically able person, which completely failed  \n> to\n> understand the rules for creating the schemas)\n> 2. Not only is it very difficult for people to create custom schemas,  \n> but it\n> is also very difficult for this capability to be built into a policy  \n> editor,\n> which of course would be the main driver for uptake.\n> 3. If we want to encourage extensibility, the best way to do this is  \n> to use\n> established standards.\n>\n> On Fri 11 Jun 04 17:34, Lorrie Cranor wrote:\n>> Let me elaborate on the implications of this proposal... this breaks\n>> our backwards compatibility guidelines. This is an issue in the\n>> following cases:\n>>\n>> - Web sites that use P3P 1.0 custom schema (very few, the only one we\n>> could think of was ibm.com) will not have P3P policies that will be\n>> readable by P3P 1.1 user agents (unless those user agents voluntarily\n>> build in backwards compatibility).\n>>\n>> - Web sites that create P3P 1.1 policies with custom schema will not  \n>> be\n>> readable by P3P 1.0 user agents that look at data elements (Privacy\n>> Bird, JRC, etc... this will probably not be a problem for IE6 or\n>> Netscape 7 because they don't appear to look at the data element  \n>> level,\n>> but I could be wrong).\n>>\n>> I really don't like the idea of breaking backwards compatibility,\n>> however, these cases are rare enough that I'm not sure its a big deal.\n>> On the other hand, given how rare these cases are, we might argue its\n>> also not worth making this change... so I guess I'm still on the  \n>> fence.\n>> The other alternative we discussed was providing a transform for the\n>> schema file itself from the new format back to the old. Giles felt  \n>> this\n>> would be fairly difficult, although I don't think impossible, and it\n>> may be something Serge can help with.\n>>\n>> I guess I want to see laid out the arguments as to why it is\n>> advantageous to make this change so we can have a discussion about\n>> whether it is worth breaking backwards compatibility for it.\n>>\n>> Lorrie\n>>\n>> p.s Giles, please go ahead and add those items at the end to bugzilla\n>>\n>> On Jun 10, 2004, at 10:02 AM, Giles Hogben wrote:\n>>> Hi,\n>>> During the working group call yesterday, we came up with the  \n>>> following\n>>> proposal for integrating the new data schema format:\n>>> This was agreed among those present on the call, but we would like to\n>>> solicit\n>>> wider approval/disapproval. Please let me know if you think I\n>>> represented our\n>>> discussion accurately, and if you agree/disagree with the proposal.\n>>> Lorrie - I have included the other two small issues that I flagged up\n>>> in the\n>>> spec document.\n>>>\n>>> XSD Base Data Schema Backward compatibility proposal\n>>> --------------------------------------------------------------------- \n>>> --\n>>> --------\n>>>\n>>> 1. For policies using data elements from the P3P1.0 base data schema,\n>>> policies must be publised in the P3P 1.0 format. This may be acheived\n>>> however, but writing and validating the policy using the new schema\n>>> format\n>>> and then using the provided XSLT to transform back to the old format.\n>>> W3C can\n>>> provide such transforms as a service.\n>>> 2. Policy authors creating or using custom schemas MUST use the new\n>>> format.\n>>> They then have two options:\n>>> a. write the policy in the new format and transform back to the old\n>>> format -\n>>> the new elements will then not be validated by user agents (because  \n>>> the\n>>> schema will not be found)\n>>> b. write the policy in the new format and transform back to the old\n>>> format,\n>>> BUT include an EXTENSION element which provides the elements in a\n>>> format\n>>> which validates against the new schema they have written. User agents\n>>> implementing P3P1.1. must then validate such extensions (which can\n>>> easily be\n>>> done using a schema validator)\n>>>\n>>> I would also like to draw your attention to a question which I\n>>> included in\n>>> the new format specification (Lorrie, perhaps we can put it in\n>>> Bugzilla):\n>>> For the specification of  entity address data, XSD format following\n>>> the old\n>>> structure is somewhat cumbersome. because you end up with something\n>>> like:\n>>>\n>>> <user>\n>>>         <contact>\n>>>                 <postal>\n>>>                         <name>\n>>>                                 Entityname\n>>>                         </name>\n>>>                 </postal>\n>>>         </contact>\n>>> </user>\n>>>\n>>> <user>\n>>>         <contact>\n>>>                 <postal>\n>>>                         <city>\n>>>                                 Entitycity\n>>>                         </city>\n>>>                 </postal>\n>>>         </contact>\n>>> </user>\n>>>\n>>> <user>\n>>>         <contact>\n>>>                 <postal>\n>>>                         <street>\n>>>                                 Entitystreet\n>>>                         </street>\n>>>                 </postal>\n>>>         </contact>\n>>> </user>\n>>>\n>>> etc.....\n>>>\n>>> One suggestion from a colleague is to change the format to the more\n>>> efficient:\n>>>\n>>> <user>\n>>>         <contact>\n>>>                 <postal>\n>>>                         <name>\n>>>                                 Entityname\n>>>                         </name>\n>>>                         <city>\n>>>                                 Entitycity\n>>>                         </city>\n>>>                         <street>\n>>>                                 Entitystreet\n>>>                         </street>\n>>>                 </postal>\n>>>         </contact>\n>>> </user>\n>>>\n>>> Another issue for bugzilla is that the term name appears twice - once\n>>> for\n>>> business and once for the user - apparently with different semantics\n>>> (otherwise it would have been a data structure)-  but I would say it\n>>> should\n>>> only appear once.\n>\n>\n\n\n\n", "id": "lists-017-7614115"}, {"subject": "AGENDA: MONDAY 4 March P3P Spec Cal", "content": "The next P3P specification group conference call will be on\nMonday, March 1, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nNOTE THIS IS MONDAY, NOT WEDNESAY!\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n(Jack please circulate new draft)\n\n2. Primary purpose specification\n(Dave please circulate a draft)\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\n6. Set date/time for next call\n\n\n\n", "id": "lists-017-7660267"}, {"subject": "RE: AGENDA: MONDAY 4 March P3P Spec Cal", "content": "Here is the new draft of the domain relationships proposal. I have\nincorporated all of the comments I've received and also tried to clarify\nsome of the relationship questions.\n\nChanged sections are bolded so you can quickly scan what changed. Rigo, can\nyou incorporate this draft into the working draft now (removing my bolding,\nof course)?\n\nThanks. Sorry for the delay.\n\n++Jack++\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Sunday, February 29, 2004 11:00 PM\nTo: 'public-p3p-spec'\nSubject: AGENDA: MONDAY 4 March P3P Spec Call\n\n\n\nThe next P3P specification group conference call will be on\nMonday, March 1, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nNOTE THIS IS MONDAY, NOT WEDNESAY!\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n(Jack please circulate new draft)\n\n2. Primary purpose specification\n(Dave please circulate a draft)\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\n6. Set date/time for next call\n\n\n\n\n\ntext/html attachment: 03-domain-relationships.html\n\n\n\n\n", "id": "lists-017-7668079"}, {"subject": "[Minutes] 01 March 2004 P3P spec cal", "content": "Minutes of the 01 March 2004 P3P 1.1 spec wg call\n\nPresent:\nLorrie Cranor\nBrooks Dobbs\nAri Schwartz\nJack Humphrey\nRigo Wenning\nDave Stampley\n\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n\nJack just sent an updated draft, please review and send comments to mailing\nlist.\n\n\n2. Primary purpose specification\n\nDave has a new draft to send -- will send ASAP. Uses a taxonomy consistent\nwith categories and  purpose/access elements. Please review and send\ncomments to mailing list.\n\nDave had a question about allowing multiple purpose specifications -- Rigo\nsuggested this was a  terminology confusion. Primary vs. Secondary is just\nrelated to current vs. subsequent purpose. The  idea is to provide ability\nto elaborate on what the current purpose is.\n\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\nLorrie will make Giles' suggested change (\"retrieved from a record\" instead\nof \"added to a record\").\nOtherwise people thought it looked good.\nLorrie will send out revised draft, asking for comments before next call so\nthis can be wrapped up.\n\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\nLorrie will be meeting with MSIE people on Friday, will discuss this issue\nas well as agent/domain  relationships proposal.\n\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\nNo one on call was familiar with issue. Lorrie gave overview:\n- Don't want to invent new ways to apply P3P for every new XML application.\n- Generic XML element could be used in any XML application.\n\nPotential problem: XML chunks can be processed by different applications,\ncan be impossible for any one  policy to apply.\n- Rigo's comment previously is that the policy author must cover all\npotential applications\n- Jack suggested that the policy could be viewed as constraints on how\napplications can use the data\n- Lorrie's solution: a mechanism to describe constraints using URI\nattributes, each URI describing a  type of application, i.e. this policy\napplies to this class of application. This potential solution  needs further\ndiscussion and elaboration.\n\n\n6. Set date/time for next call\n\nNext call: Wednesday 10 March 2004, 11:00am EST\n\n\n\n", "id": "lists-017-7677311"}, {"subject": "The p3p generic attribut", "content": "Dear all, \n\nI had some talks with Massimo and Mark Nottingham here at the TP in\nCannes. I have interesting conclusions but I don't have a clue yet how\nto formulate that in the specification.\n\n1/ Discussion with Mark Nottingham\n\nI discussed the attribute with Mark and the most important remark he\nmade was, that there is a very fundamental distinction between applying\nthe p3p-attribute on data contained in the element being send over the \nwire and an interface description (like WSDL[1]). Mark suggests that we \nonly treat interfaces for the moment and defer the data-sending to later \n(epal?) work.\n\n2/ Discussion with Massimo\n\nBefore and after having talked to Mark, I've talked a lot with Massimo.\nI found out that Massimo's but also Lorrie's approach correspond to what \nMark calls the data approach. In fact, they assume that data is\ncontained in the element <foo xsd:p3patt=\"p3p.xml\"><bar>Rigo</bar></foo>\nNow they claim that not anybody will treat that chunk of XML the way \nas defined in p3p.xml when <foo... is send over the wire. \n\nBut this makes the protocol assumption underlying to cc/pp and is the\nflip-side of P3P. In fact it makes the protocol assumption that the\npolicy is sent with the data and constrains the recipient of that data.\nThis, in terms of P3P, is not possible, as it would mean one is sending \nprivacy preferences over the wire. We don't do that and it has complete \ndifferent semantics. So the only thing we know to do today is, that \nif I receive -say- a WSDL interface description with a p3p-attribute \non it, I know that when submitting data to that interface, my data will\nbe treated in the way described in the P3P policy.\n\nIf sending data over the wire, it is like sending preferences (like\ncc/pp does). Once we agreed on this, Massimo had no concerns anymore. \n\nThe issue is now to find a language to constrain our attribute so that \nit could only apply to interfaces and not to data send over the wire. We\nwill probably also need some words to avoid the misunderstanding\ndescribed above (sending data over the wire) as it is most common or\neven the preferred interpretation of most people.\n\nI hope this might help Lorrie in drafting her proposal.\n\n\n  1. http://www.w3.org/TeamSubmission/2004/SUBM-p3p-wsdl-20040213/\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-7686576"}, {"subject": "Re: The p3p generic attribut", "content": "OK, I like the distinction between interface description and data. I \nknow very little about WSDL and other languages for writing interface \ndescriptions... would an interface description include some reference \nto a particular entity or URI where the interface will be processed \n(not sure if that's the right word)? I guess what I'm wondering is \nwhether there could still be a problem that a chunk of XML describing \nan interface might be processed by multiple entities, including \nentities that the one who wrote it is unaware of (and thus can't \nanticipate when writing the P3P policy).\n\nLorrie\n\n\nOn Mar 3, 2004, at 8:44 AM, Rigo Wenning wrote:\n\n>\n> Dear all,\n>\n> I had some talks with Massimo and Mark Nottingham here at the TP in\n> Cannes. I have interesting conclusions but I don't have a clue yet how\n> to formulate that in the specification.\n>\n> 1/ Discussion with Mark Nottingham\n>\n> I discussed the attribute with Mark and the most important remark he\n> made was, that there is a very fundamental distinction between applying\n> the p3p-attribute on data contained in the element being send over the\n> wire and an interface description (like WSDL[1]). Mark suggests that we\n> only treat interfaces for the moment and defer the data-sending to \n> later\n> (epal?) work.\n>\n> 2/ Discussion with Massimo\n>\n> Before and after having talked to Mark, I've talked a lot with Massimo.\n> I found out that Massimo's but also Lorrie's approach correspond to \n> what\n> Mark calls the data approach. In fact, they assume that data is\n> contained in the element <foo \n> xsd:p3patt=\"p3p.xml\"><bar>Rigo</bar></foo>\n> Now they claim that not anybody will treat that chunk of XML the way\n> as defined in p3p.xml when <foo... is send over the wire.\n>\n> But this makes the protocol assumption underlying to cc/pp and is the\n> flip-side of P3P. In fact it makes the protocol assumption that the\n> policy is sent with the data and constrains the recipient of that data.\n> This, in terms of P3P, is not possible, as it would mean one is sending\n> privacy preferences over the wire. We don't do that and it has complete\n> different semantics. So the only thing we know to do today is, that\n> if I receive -say- a WSDL interface description with a p3p-attribute\n> on it, I know that when submitting data to that interface, my data will\n> be treated in the way described in the P3P policy.\n>\n> If sending data over the wire, it is like sending preferences (like\n> cc/pp does). Once we agreed on this, Massimo had no concerns anymore.\n>\n> The issue is now to find a language to constrain our attribute so that\n> it could only apply to interfaces and not to data send over the wire. \n> We\n> will probably also need some words to avoid the misunderstanding\n> described above (sending data over the wire) as it is most common or\n> even the preferred interpretation of most people.\n>\n> I hope this might help Lorrie in drafting her proposal.\n>\n>\n>   1. http://www.w3.org/TeamSubmission/2004/SUBM-p3p-wsdl-20040213/\n> -- \n> Rigo Wenning            W3C/ERCIM\n> Policy Analyst          Privacy Activity Lead\n> mail:rigo@w3.org        2004, Routes des Lucioles\n> http://www.w3.org/      F-06902 Sophia Antipolis\n>\n\n\n\n", "id": "lists-017-7696267"}, {"subject": "Re: The p3p generic attribut", "content": "Lorrie, \n\nthe issue is that WSDL is using SOAP and qnames and like in the forms\ncontext, several things can be sent to several URIs and there are\nintermediaries. So yes, some things have URIs and some don't. It is a\nsimple question of granularity and complexity like in XForms. \n\nIf you can match a small chunk (field for XForms, interface for WSDL) to \na P3P Policy, policy writing gets much easier, matching of functionality\n(required/opt in/out) will be easier etc... That's why I'm pushing so\nhard on the granularity. It will solve a lot of issues. \n\nFor the data in a chunk of XML that is transferred, this can only \nbe solved with a concept like EPAL. (or a major revision of P3P).\nApplying policy to data instead of interfaces is the ultimate level of\ngranularity.\n\nBest, \n\nRigo\n\nOn Wed, Mar 03, 2004 at 09:33:35AM -0500, Lorrie Cranor wrote:\n> OK, I like the distinction between interface description and data. I \n> know very little about WSDL and other languages for writing interface \n> descriptions... would an interface description include some reference \n> to a particular entity or URI where the interface will be processed \n> (not sure if that's the right word)? I guess what I'm wondering is \n> whether there could still be a problem that a chunk of XML describing \n> an interface might be processed by multiple entities, including \n> entities that the one who wrote it is unaware of (and thus can't \n> anticipate when writing the P3P policy).\n> \n\n\n\n", "id": "lists-017-7707350"}, {"subject": "comments on latest domain relationship proposal", "content": "Haven't seen any comments on the latest domain relationship proposal:\nhttp://www.w3.org/P3P/2004/03-domain-relationships.html\n\nPlease see the copy I sent to the list previously if you want to see the\nbolded sections that changed from the previous version of the draft.\n\nWould love to get this wrapped up soon, please get your comments in before\nWednesday if possible.\n\nThanks.\n\n++Jack++\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Monday, March 01, 2004 9:00 AM\nTo: 'public-p3p-spec'\nSubject: RE: AGENDA: MONDAY 4 March P3P Spec Call\n\n\nHere is the new draft of the domain relationships proposal. I have\nincorporated all of the comments I've received and also tried to clarify\nsome of the relationship questions.\n\nChanged sections are bolded so you can quickly scan what changed. Rigo, can\nyou incorporate this draft into the working draft now (removing my bolding,\nof course)?\n\nThanks. Sorry for the delay.\n\n++Jack++\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Sunday, February 29, 2004 11:00 PM\nTo: 'public-p3p-spec'\nSubject: AGENDA: MONDAY 4 March P3P Spec Call\n\n\n\nThe next P3P specification group conference call will be on\nMonday, March 1, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nNOTE THIS IS MONDAY, NOT WEDNESAY!\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n(Jack please circulate new draft)\n\n2. Primary purpose specification\n(Dave please circulate a draft)\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\n6. Set date/time for next call\n\n\n\n", "id": "lists-017-7715622"}, {"subject": "RE: comments on latest domain relationship proposal", "content": "I think there is really good thinking here but I think we are overloading\nthis to our potential detriment.  I think the problem we would REALLY like\nthe UA folks to resolve is that there should be a simple way for site.com,\nsite.net, site.uk, and site-inc.com to say they are truly the same entity\n(a=b=c=d).  I think that this is clarification that UAs may actually adopt\n(largely because it is within consumer expectation).\n\nHowever, as nice as it may be to express agent relationships, it is a can of\nworms.  Assume you succeed...  One question it will beg is - what if you are\nNOT listed as an agent but you appear within the site!  If you appear on a\n1st party site and aren't declaring an agent relationship or seen in the\nknown hosts of the parent site - what the heck are you doing there?  Does\nthe site not control its own content?  We may know that it is because this\nis optional, but it is a lot or reliance to be entrusted to an optional\nelement, particularly when it may be extremely difficult for 3rd parties\nacting as agents to contextually know where they are to appear and\ndynamically generate headers accordingly.  It almost forces the use of\npolicy ref in the P3P header.  Equally, while sites like to talk about\ncontrolling data collected through the site, it may be extremely difficult\nto maintain an active known hosts (in an agents context) listing.\n\nEven if you get past this, there is still the up hill battle of consumer\nexpectation.  IMHO large UA makers enjoy (probably based on consumer\nfeedback) differentiating parties the way they are presently doing.  They\nwent out of their way to treat 1st and 3rd party cookies differently even\nthough the spec makes no such distinction.\n\nJust thoughts...\n\n-Brooks\n\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org [mailto:public-p3p-spec-request@w3.org]\nOn Behalf Of Humphrey, Jack\nSent: Monday, March 08, 2004 5:30 PM\nTo: 'public-p3p-spec'\nSubject: comments on latest domain relationship proposal?\n\n\nHaven't seen any comments on the latest domain relationship proposal:\nhttp://www.w3.org/P3P/2004/03-domain-relationships.html\n\nPlease see the copy I sent to the list previously if you want to see the\nbolded sections that changed from the previous version of the draft.\n\nWould love to get this wrapped up soon, please get your comments in before\nWednesday if possible.\n\nThanks.\n\n++Jack++\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Monday, March 01, 2004 9:00 AM\nTo: 'public-p3p-spec'\nSubject: RE: AGENDA: MONDAY 4 March P3P Spec Call\n\n\nHere is the new draft of the domain relationships proposal. I have\nincorporated all of the comments I've received and also tried to clarify\nsome of the relationship questions.\n\nChanged sections are bolded so you can quickly scan what changed. Rigo, can\nyou incorporate this draft into the working draft now (removing my bolding,\nof course)?\n\nThanks. Sorry for the delay.\n\n++Jack++\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Sunday, February 29, 2004 11:00 PM\nTo: 'public-p3p-spec'\nSubject: AGENDA: MONDAY 4 March P3P Spec Call\n\n\n\nThe next P3P specification group conference call will be on\nMonday, March 1, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nNOTE THIS IS MONDAY, NOT WEDNESAY!\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n(Jack please circulate new draft)\n\n2. Primary purpose specification\n(Dave please circulate a draft)\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\n6. Set date/time for next call\n\n\n\n", "id": "lists-017-7726294"}, {"subject": "Re: linke", "content": "Here is a complete proposal based on discussion on the mailing list and \nlast call. Please send any more comments. Let's try to get this wrapped \nup this week if possible.\n\nLorrie\n\n---\n\nI propose that we remove the last 3 paragraphs of 1.3.2 that pertain\nto \"linked\" data and change the title of that section to\n\"Non-identifiable\" Data. Then add a new section 1.3.4 as follows:\n\n\n1.3.4 Linked and Linkable Data\n\n<p>Cookies often store a unique number or database key that links to a\ndatabase record, rather than storing the complete database record. Web\nsites that use P3P must disclose not only the types of data stored\ndirectly in a cookie, but also all data linked to a cookie. A large\namount of data may be \"linkable\" to a cookie without actually being\n\"linked\" to that cookie. </p>\n\n<p>A piece of data X is said to be <i>linkable</i> to a cookie Y if a\nkey stored in cookie Y can be used to retrieve X either directly or\nindirectly. A direct retrieval might happen, for example, if the key\nis associated with a database record in which X is stored. An indirect\nretrieval might happen, for example, if the key is associated with a\ndatabase record that contains a piece of data that may be used, in\nturn, as a key to retrieve a record in a second database, and X is\nstored in the second database. Furthermore, if cookie Y is stored in a\nserver log file, the log file may facilitate further linking. For\nexample, when cookie Y is replayed, it may be accompanied by a referer\nfield that includes additional identifiable information or even\nanother key. Alternatively, imagine a web site that sets two cookies,\nY and Z. Cookies Y and Z may get replayed in the same HTTP request and\nsubsequently recorded side-by-side in the server log file. Thus all\ndata associated with cookie Y are also linkable to cookie Z. Indeed,\nunless precautions are taken to minimize server log files and severely\nrestrict the use of identifiable data, almost all data an entity\nstores about an individual are likely to be linkable to any cookies\nthey have set on that individual's computer.</p>\n\n<p>A piece of data X is said to be <i>linked</i> to a cookie Y if at\nleast one of the following activities may take place as a result of\ncookie Y being replayed, immediately upon cookie replay or at some\nfuture time (perhaps as a result of retrospective analysis or\nprocessing of server logs):</p>\n\n<ul>\n<li>A cookie containing X is set or reset.</li>\n\n<li>X is retrieved from a persistent data store or archival media.</li>\n\n<li>Information identifiable with the user -- including but not\nlimited to data entered into forms, IP address, clickstream data, and\nclient events -- is retrieved from a record, data structure, or file \n(other\nthan a log file) in which X is stored. </li>\n</ul>\n\n<p>Entities should consider their data collection and storage\narchitectures carefully to determine what data may be linkable to\ntheir cookies and what data will actually be linked to each cookie. If\ndata is linkable but does not actually get linked to a particular\ncookie, it does not have to be disclosed in a P3P statement concerning\nthat cookie. However, should the entity associated with that P3P\npolicy ever link the data for any reason other than to comply with law\nenforcement demands, they would be in violation of their stated\npolicy. </p>\n\n\n\n", "id": "lists-017-7739573"}, {"subject": "AGENDA: 10 March P3P Spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, March 10, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\nSee latest draft\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0008.html\nLet's try to resolve this item this week!\n\n2. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\nPlease look at new draft at\nhttp://www.w3.org/P3P/2004/03-domain-relationships.html\nand mailing list thread\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0006.html\n\n3. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\nand Lorrie's feedback from Microsoft meeting\n\n4. Primary purpose specification\n(Dave please circulate a draft)\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n\n6. Set date/time for next call (March 10?)\n\n\n\n", "id": "lists-017-7749238"}, {"subject": "RE: comments on latest domain relationship proposal", "content": "Brooks,\n\nThanks for your comments. I'm going to paraphrase (and quote) them and try\nto respond.\n\n- We are over-reaching by attempting to represent both agent and same-entity\nrelationships.\n\nWhat we are proposing is an optional way for sites to specify which other\nhosts/domains are known to use their policy reference file. The P3P 1.0 line\nwas that sharing a policy reference file was the proper way to represent\ncross-host policies. However, that approach is open to abuse, hence the\nknown-hosts mechanism. This mechanism allows user agents to validate that\nboth sites agree on the use of a policy.\n\nYou may remember that a previous proposal attempted to express only\nsame-entity relationships, and it was actually less simple than the current\nproposal, in that it had to introduce the concept of \"same-entity\" -- as an\nattribute on the KNOWN-HOST element.\n\nThe latest proposal makes no attempt to define new concepts around\nsame-entity and agent. It simply falls back on the definitions in P3P 1.0.\nAgents were included in the \"ours\" definition, so it happens to apply to\nagents as well as same entities.\n\n- How should user agents handle the situation in which a site refers to the\nPRF but is not in the known hosts listing?\n\nThis decision is entirely up to the user agent implementers. We have no\nchoice but to make known-hosts optional in 1.1 -- that can be reconsidered\nfor 2.0. A user agent might decide not to restrict the cookies of a host in\na different domain if it appears in the known-hosts list for the primary\ndomain. Any restrictions they would apply otherwise can remain in effect...\nthe problem of known-hosts not being there is an existing problem!\n\n- \"It may be extremely difficult for 3rd parties acting as agents to\ncontextually know where they are to appear and\ndynamically generate headers accordingly.\"\n\nAs an implementer of such systems, I disagree. Any sort of dynamic server\nsystem can look at a key in the incoming URL, or the HTTP referrer, and from\nthat look up or imply the PRF location that should be returned in the P3P\nHTTP header. There are many ways to skin this cat, and if agent sites can't\nor don't want to implement it and reap the potential benefits... well, it's\noptional.\n\n- \"It may be extremely difficult to maintain an active known hosts (in an\nagents context) listing.\"\n\nThat may be true for some sites (particularly with ad servers), but\ncertainly not all. I would argue that, generally speaking, if a site can't\nkeep track of its embedded hosts, then they probably aren't known hosts.\n\n- User agent implementers are happy with the way they identify third-parties\nnow.\n\nThere is some evidence to the contrary, but you have a point: ultimately the\nsuccess of this mechanism will depend on adoption by the UA folks. I would\nreally like to get feedback from them, but until we do, we can hope that\nthis will offer an option. \n\nIn particular, I'm anxious about the fact that there is no compact\npolicy-based way to represent known-hosts. Technically the possibilities\nthere are a can of worms, though, so I believe it would be better for UAs to\nuse the PRFs to identify known hosts.\n\n\nAgain, thanks for your comments, Brooks. As always, I am open to\ncounter-proposals or suggestions on how to improve the proposal. (Time grows\nshort, though.)\n\n++Jack++\n\n-----Original Message-----\nFrom: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\nSent: Monday, March 08, 2004 5:31 PM\nTo: 'Humphrey, Jack'; 'public-p3p-spec'\nSubject: RE: comments on latest domain relationship proposal?\n\n\nI think there is really good thinking here but I think we are overloading\nthis to our potential detriment.  I think the problem we would REALLY like\nthe UA folks to resolve is that there should be a simple way for site.com,\nsite.net, site.uk, and site-inc.com to say they are truly the same entity\n(a=b=c=d).  I think that this is clarification that UAs may actually adopt\n(largely because it is within consumer expectation).\n\nHowever, as nice as it may be to express agent relationships, it is a can of\nworms.  Assume you succeed...  One question it will beg is - what if you are\nNOT listed as an agent but you appear within the site!  If you appear on a\n1st party site and aren't declaring an agent relationship or seen in the\nknown hosts of the parent site - what the heck are you doing there?  Does\nthe site not control its own content?  We may know that it is because this\nis optional, but it is a lot or reliance to be entrusted to an optional\nelement, particularly when it may be extremely difficult for 3rd parties\nacting as agents to contextually know where they are to appear and\ndynamically generate headers accordingly.  It almost forces the use of\npolicy ref in the P3P header.  Equally, while sites like to talk about\ncontrolling data collected through the site, it may be extremely difficult\nto maintain an active known hosts (in an agents context) listing.\n\nEven if you get past this, there is still the up hill battle of consumer\nexpectation.  IMHO large UA makers enjoy (probably based on consumer\nfeedback) differentiating parties the way they are presently doing.  They\nwent out of their way to treat 1st and 3rd party cookies differently even\nthough the spec makes no such distinction.\n\nJust thoughts...\n\n-Brooks\n\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org [mailto:public-p3p-spec-request@w3.org]\nOn Behalf Of Humphrey, Jack\nSent: Monday, March 08, 2004 5:30 PM\nTo: 'public-p3p-spec'\nSubject: comments on latest domain relationship proposal?\n\n\nHaven't seen any comments on the latest domain relationship proposal:\nhttp://www.w3.org/P3P/2004/03-domain-relationships.html\n\nPlease see the copy I sent to the list previously if you want to see the\nbolded sections that changed from the previous version of the draft.\n\nWould love to get this wrapped up soon, please get your comments in before\nWednesday if possible.\n\nThanks.\n\n++Jack++\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\nSent: Monday, March 01, 2004 9:00 AM\nTo: 'public-p3p-spec'\nSubject: RE: AGENDA: MONDAY 4 March P3P Spec Call\n\n\nHere is the new draft of the domain relationships proposal. I have\nincorporated all of the comments I've received and also tried to clarify\nsome of the relationship questions.\n\nChanged sections are bolded so you can quickly scan what changed. Rigo, can\nyou incorporate this draft into the working draft now (removing my bolding,\nof course)?\n\nThanks. Sorry for the delay.\n\n++Jack++\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Sunday, February 29, 2004 11:00 PM\nTo: 'public-p3p-spec'\nSubject: AGENDA: MONDAY 4 March P3P Spec Call\n\n\n\nThe next P3P specification group conference call will be on\nMonday, March 1, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nNOTE THIS IS MONDAY, NOT WEDNESAY!\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n(Jack please circulate new draft)\n\n2. Primary purpose specification\n(Dave please circulate a draft)\n\n3. Clarify what we mean by data linked to a cookie\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n\n4. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n\n5. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n\n6. Set date/time for next call\n\n\n\n", "id": "lists-017-7757405"}, {"subject": "Re: comments on latest domain relationship proposal", "content": "Yes, time grows short. We need to decide whether to take this proposal \nmore or less as is, make some specific changes to it, or forget it.\n\nI did have a conversation with Jeremy about this last week. While he \ncould not make any guarantees, he did not see any problems with \nimplementing this proposal. He was not entirely sure how the user agent \nwould make use of the known-host information, but said there was \nprobably something useful they could do with it if they had it. The \nnext version of the browser may not need to rely as heavily on CPs, so \nputting the info in the PRF is ok. I can discuss this more on the call.\n\nLorrie\n\n\nOn Mar 9, 2004, at 5:19 PM, Humphrey, Jack wrote:\n\n>\n> Brooks,\n>\n> Thanks for your comments. I'm going to paraphrase (and quote) them and \n> try\n> to respond.\n>\n> - We are over-reaching by attempting to represent both agent and \n> same-entity\n> relationships.\n>\n> What we are proposing is an optional way for sites to specify which \n> other\n> hosts/domains are known to use their policy reference file. The P3P \n> 1.0 line\n> was that sharing a policy reference file was the proper way to \n> represent\n> cross-host policies. However, that approach is open to abuse, hence the\n> known-hosts mechanism. This mechanism allows user agents to validate \n> that\n> both sites agree on the use of a policy.\n>\n> You may remember that a previous proposal attempted to express only\n> same-entity relationships, and it was actually less simple than the \n> current\n> proposal, in that it had to introduce the concept of \"same-entity\" -- \n> as an\n> attribute on the KNOWN-HOST element.\n>\n> The latest proposal makes no attempt to define new concepts around\n> same-entity and agent. It simply falls back on the definitions in P3P \n> 1.0.\n> Agents were included in the \"ours\" definition, so it happens to apply \n> to\n> agents as well as same entities.\n>\n> - How should user agents handle the situation in which a site refers \n> to the\n> PRF but is not in the known hosts listing?\n>\n> This decision is entirely up to the user agent implementers. We have no\n> choice but to make known-hosts optional in 1.1 -- that can be \n> reconsidered\n> for 2.0. A user agent might decide not to restrict the cookies of a \n> host in\n> a different domain if it appears in the known-hosts list for the \n> primary\n> domain. Any restrictions they would apply otherwise can remain in \n> effect...\n> the problem of known-hosts not being there is an existing problem!\n>\n> - \"It may be extremely difficult for 3rd parties acting as agents to\n> contextually know where they are to appear and\n> dynamically generate headers accordingly.\"\n>\n> As an implementer of such systems, I disagree. Any sort of dynamic \n> server\n> system can look at a key in the incoming URL, or the HTTP referrer, \n> and from\n> that look up or imply the PRF location that should be returned in the \n> P3P\n> HTTP header. There are many ways to skin this cat, and if agent sites \n> can't\n> or don't want to implement it and reap the potential benefits... well, \n> it's\n> optional.\n>\n> - \"It may be extremely difficult to maintain an active known hosts (in \n> an\n> agents context) listing.\"\n>\n> That may be true for some sites (particularly with ad servers), but\n> certainly not all. I would argue that, generally speaking, if a site \n> can't\n> keep track of its embedded hosts, then they probably aren't known \n> hosts.\n>\n> - User agent implementers are happy with the way they identify \n> third-parties\n> now.\n>\n> There is some evidence to the contrary, but you have a point: \n> ultimately the\n> success of this mechanism will depend on adoption by the UA folks. I \n> would\n> really like to get feedback from them, but until we do, we can hope \n> that\n> this will offer an option.\n>\n> In particular, I'm anxious about the fact that there is no compact\n> policy-based way to represent known-hosts. Technically the \n> possibilities\n> there are a can of worms, though, so I believe it would be better for \n> UAs to\n> use the PRFs to identify known hosts.\n>\n>\n> Again, thanks for your comments, Brooks. As always, I am open to\n> counter-proposals or suggestions on how to improve the proposal. (Time \n> grows\n> short, though.)\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\n> Sent: Monday, March 08, 2004 5:31 PM\n> To: 'Humphrey, Jack'; 'public-p3p-spec'\n> Subject: RE: comments on latest domain relationship proposal?\n>\n>\n> I think there is really good thinking here but I think we are \n> overloading\n> this to our potential detriment.  I think the problem we would REALLY \n> like\n> the UA folks to resolve is that there should be a simple way for \n> site.com,\n> site.net, site.uk, and site-inc.com to say they are truly the same \n> entity\n> (a=b=c=d).  I think that this is clarification that UAs may actually \n> adopt\n> (largely because it is within consumer expectation).\n>\n> However, as nice as it may be to express agent relationships, it is a \n> can of\n> worms.  Assume you succeed...  One question it will beg is - what if \n> you are\n> NOT listed as an agent but you appear within the site!  If you appear \n> on a\n> 1st party site and aren't declaring an agent relationship or seen in \n> the\n> known hosts of the parent site - what the heck are you doing there?  \n> Does\n> the site not control its own content?  We may know that it is because \n> this\n> is optional, but it is a lot or reliance to be entrusted to an optional\n> element, particularly when it may be extremely difficult for 3rd \n> parties\n> acting as agents to contextually know where they are to appear and\n> dynamically generate headers accordingly.  It almost forces the use of\n> policy ref in the P3P header.  Equally, while sites like to talk about\n> controlling data collected through the site, it may be extremely \n> difficult\n> to maintain an active known hosts (in an agents context) listing.\n>\n> Even if you get past this, there is still the up hill battle of \n> consumer\n> expectation.  IMHO large UA makers enjoy (probably based on consumer\n> feedback) differentiating parties the way they are presently doing.  \n> They\n> went out of their way to treat 1st and 3rd party cookies differently \n> even\n> though the spec makes no such distinction.\n>\n> Just thoughts...\n>\n> -Brooks\n>\n>\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org \n> [mailto:public-p3p-spec-request@w3.org]\n> On Behalf Of Humphrey, Jack\n> Sent: Monday, March 08, 2004 5:30 PM\n> To: 'public-p3p-spec'\n> Subject: comments on latest domain relationship proposal?\n>\n>\n> Haven't seen any comments on the latest domain relationship proposal:\n> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>\n> Please see the copy I sent to the list previously if you want to see \n> the\n> bolded sections that changed from the previous version of the draft.\n>\n> Would love to get this wrapped up soon, please get your comments in \n> before\n> Wednesday if possible.\n>\n> Thanks.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n> Sent: Monday, March 01, 2004 9:00 AM\n> To: 'public-p3p-spec'\n> Subject: RE: AGENDA: MONDAY 4 March P3P Spec Call\n>\n>\n> Here is the new draft of the domain relationships proposal. I have\n> incorporated all of the comments I've received and also tried to \n> clarify\n> some of the relationship questions.\n>\n> Changed sections are bolded so you can quickly scan what changed. \n> Rigo, can\n> you incorporate this draft into the working draft now (removing my \n> bolding,\n> of course)?\n>\n> Thanks. Sorry for the delay.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Sunday, February 29, 2004 11:00 PM\n> To: 'public-p3p-spec'\n> Subject: AGENDA: MONDAY 4 March P3P Spec Call\n>\n>\n>\n> The next P3P specification group conference call will be on\n> Monday, March 1, 2004, 11 am - 12 pm US Eastern. Dial-in\n> information is available at\n> http://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n>\n> NOTE THIS IS MONDAY, NOT WEDNESAY!\n>\n> AGENDA\n>\n> 1. Agent and domain relationships\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n> (Jack please circulate new draft)\n>\n> 2. Primary purpose specification\n> (Dave please circulate a draft)\n>\n> 3. Clarify what we mean by data linked to a cookie\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n>\n> 4. Proposal to deprecate compact policies\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n>\n> 5. P3P Generic attribute for XML applications\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n>\n> 6. Set date/time for next call\n>\n\n\n\n", "id": "lists-017-7775011"}, {"subject": "Primary Purpos", "content": "Okay.  I have promised to deliver and then gone back and juggled various\ntaxonomy configuration.  \n\n \n\n1.  Challenge:  Goal is to facilitate user's ability to make an informed\nprivacy choice.  A catalog of conceivable primary purposes will inevitably\nbe incomplete and imprecise.  \n\n \n\n2.  Question:  I assume it is required that the user be able to obtain the\nprimary purpose info before the web site collects any user data.  Does this\nmean it is required that the data about primary purpose be transmitted\nbefore a user views a web page?  As you see from the proposal below, this is\na key question.  If the purpose can be linked to the context of the display,\na more efficient, context-driven \"primary purpose\" is possible, as in items\n3.a and 3.b, below.\n\n \n\n3.  Proposal:  Instead of attempting a comprehensive list (e.g., \"Top 20\npurposes\"), please comment on purposes specified in the following ways:\n\n \n\n   a.  TRANSPARENT, USER-REQUESTED TRANSACTION:  The primary purpose is that\nwhich should be apparent to the user based on clear and conspicuous\ninformation displayed on a web page at or preceding the point of data\ncollection required to complete a user's transaction request.  (E.g.,\nmagazine subscription page, product purchase pages))\n\n \n\n   b.  TRANSPARENT, NON-USER-REQUESTED TRANSACTION:  The primary purpose is\nthat which should be apparent to the user based on clear and conspicuous\ninformation displayed on a web page at or preceding the point of data\ncollection required to complete the site's information request.  (E.g.,\nwebsite solicits information to include in 360-degree, PII-linked profile\n[yes, I know that this scenario is unlikely]; sweepstakes form would\nprobably fit here, though it would also probably be dual-purposed [3.a +\n3.b])\n\n \n\n   c.  TRANSPARENT NON-USER-REQUESTED NAVIGATION OR PAGE CONSTRUCTION:\nE.g., website personalization [local weather based on user's zip code input]\n\n \n\n \n\n   c.  NON-TRANSPARENT NON-USER-REQUESTED NAVIGATION OR PAGE CONSTRUCTION:\nE.g., ad display, redirect\n\n \n\n   d.  NON-TRANSPARENT NON-USER-REQUESTED COLLECTION FOR PURPOSE OF\nRETAINING INDIVIDUAL DATA:  E.g., might be 360-degree, data aggregation,\nanonymous, pseudonymous, or identified.\n\n \n\n   d.  NON-TRANSPARENT NON-USER-REQUESTED COLLECTION FOR PURPOSE OTHER THAN\nRETAINING USER'S DATA:  E.g., creation of server logs for audit purposes;\nwebsite traffic management stats.\n\n \n\n \n\n \n\nDave Stampley\n\nSenior Corporate Counsel and Director, Privacy\n\nThe Reynolds and Reynolds Company\n\nOne Reynolds Way, Dayton, OH  45430\n\nv.     937-485-0424\n\nf.      866-246-0507\n\ndavid_stampley@reyrey.com\n\n \n\nTHIS EMAIL IS CONFIDENTIAL AND MAY ALSO BE LEGALLY PRIVILEGED.  IF YOU HAVE\nRECEIVED THIS EMAIL IN ERROR, PLEASE NOTIFY THE SENDER IMMEDIATELY BY RETURN\nEMAIL AND THEN DELETE THIS EMAIL FROM YOUR SYSTEM WITHOUT COPYING OR USING\nTHE EMAIL FOR ANY OTHER PURPOSE OR DISCLOSING IT CONTENTS.\n\n \n\n\n\n", "id": "lists-017-7794119"}, {"subject": "RE: comments on latest domain relationship proposal", "content": "Sorry I missed the call; Delta had me several hours late getting into NY.\n\nLet me just throw in a practical case in point.  Let's looks at any example\nweb site that is advertising driven.  Here are some examples of issues:\n\nWhile the site may know that they have a \"known-hosts\" relationship with\ntheir direct Ad Service Provider and can *possibly* coordinate a known hosts\narrangement - they have no possible way of knowing where every ad that comes\nto their site is served from (or potentially cookie).  Why because\nadvertisers will often host their own creative.  Practically speaking, since\nlarge sites get their ads through agencies they are not full in control of\nwhat is played on their site - making it impossible for them to coordinate a\nknown hosts file.  Still this makes this no less an \"agents of\" relationsip.\n\nFrom the advertisers perspective you have the same problem.  They go to an\nagency and say, \"give me a million impressions on men's health sites\" - they\ncannot know who to publish as reciprocal known-hosts where they may appear.\n\n\nEven for the ad server company, for whom, as Jack points out, *could*\npossibly be in a position to know - practically speaking it is impossible.\nDC ads, for example, appear on millions upon millions of hosts.  For this to\nwork we would need to not only do the lookup for the dynamic P3P: policyref=\nbased upon a mapping of referrer (not possible in pops) or URL (not possible\nas there is no client hierarchy to the tag) but also publish millions of\nknown hosts in our own PRF.\n\nThe situation is very similar for all sites that accept any dynamic 3rd\nparty content.\n\nI do see this working for 3rd parties that have a very defined and discreet\nrelationship with a limited number of sites, but as a generic agent\nrelationship, I think it will fail to be implementable in more cases than\nnot.  Again - just an opinion.\n\n-Brooks\n\n\n\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Tuesday, March 09, 2004 8:58 PM\nTo: Humphrey, Jack\nCc: 'public-p3p-spec'; 'Dobbs, Brooks'\nSubject: Re: comments on latest domain relationship proposal?\n\nYes, time grows short. We need to decide whether to take this proposal\nmore or less as is, make some specific changes to it, or forget it.\n\nI did have a conversation with Jeremy about this last week. While he\ncould not make any guarantees, he did not see any problems with\nimplementing this proposal. He was not entirely sure how the user agent\nwould make use of the known-host information, but said there was\nprobably something useful they could do with it if they had it. The\nnext version of the browser may not need to rely as heavily on CPs, so\nputting the info in the PRF is ok. I can discuss this more on the call.\n\nLorrie\n\n\nOn Mar 9, 2004, at 5:19 PM, Humphrey, Jack wrote:\n\n>\n> Brooks,\n>\n> Thanks for your comments. I'm going to paraphrase (and quote) them and\n> try\n> to respond.\n>\n> - We are over-reaching by attempting to represent both agent and\n> same-entity\n> relationships.\n>\n> What we are proposing is an optional way for sites to specify which\n> other\n> hosts/domains are known to use their policy reference file. The P3P\n> 1.0 line\n> was that sharing a policy reference file was the proper way to\n> represent\n> cross-host policies. However, that approach is open to abuse, hence the\n> known-hosts mechanism. This mechanism allows user agents to validate\n> that\n> both sites agree on the use of a policy.\n>\n> You may remember that a previous proposal attempted to express only\n> same-entity relationships, and it was actually less simple than the\n> current\n> proposal, in that it had to introduce the concept of \"same-entity\" --\n> as an\n> attribute on the KNOWN-HOST element.\n>\n> The latest proposal makes no attempt to define new concepts around\n> same-entity and agent. It simply falls back on the definitions in P3P\n> 1.0.\n> Agents were included in the \"ours\" definition, so it happens to apply\n> to\n> agents as well as same entities.\n>\n> - How should user agents handle the situation in which a site refers\n> to the\n> PRF but is not in the known hosts listing?\n>\n> This decision is entirely up to the user agent implementers. We have no\n> choice but to make known-hosts optional in 1.1 -- that can be\n> reconsidered\n> for 2.0. A user agent might decide not to restrict the cookies of a\n> host in\n> a different domain if it appears in the known-hosts list for the\n> primary\n> domain. Any restrictions they would apply otherwise can remain in\n> effect...\n> the problem of known-hosts not being there is an existing problem!\n>\n> - \"It may be extremely difficult for 3rd parties acting as agents to\n> contextually know where they are to appear and\n> dynamically generate headers accordingly.\"\n>\n> As an implementer of such systems, I disagree. Any sort of dynamic\n> server\n> system can look at a key in the incoming URL, or the HTTP referrer,\n> and from\n> that look up or imply the PRF location that should be returned in the\n> P3P\n> HTTP header. There are many ways to skin this cat, and if agent sites\n> can't\n> or don't want to implement it and reap the potential benefits... well,\n> it's\n> optional.\n>\n> - \"It may be extremely difficult to maintain an active known hosts (in\n> an\n> agents context) listing.\"\n>\n> That may be true for some sites (particularly with ad servers), but\n> certainly not all. I would argue that, generally speaking, if a site\n> can't\n> keep track of its embedded hosts, then they probably aren't known\n> hosts.\n>\n> - User agent implementers are happy with the way they identify\n> third-parties\n> now.\n>\n> There is some evidence to the contrary, but you have a point:\n> ultimately the\n> success of this mechanism will depend on adoption by the UA folks. I\n> would\n> really like to get feedback from them, but until we do, we can hope\n> that\n> this will offer an option.\n>\n> In particular, I'm anxious about the fact that there is no compact\n> policy-based way to represent known-hosts. Technically the\n> possibilities\n> there are a can of worms, though, so I believe it would be better for\n> UAs to\n> use the PRFs to identify known hosts.\n>\n>\n> Again, thanks for your comments, Brooks. As always, I am open to\n> counter-proposals or suggestions on how to improve the proposal. (Time\n> grows\n> short, though.)\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Dobbs, Brooks [mailto:bdobbs@doubleclick.net]\n> Sent: Monday, March 08, 2004 5:31 PM\n> To: 'Humphrey, Jack'; 'public-p3p-spec'\n> Subject: RE: comments on latest domain relationship proposal?\n>\n>\n> I think there is really good thinking here but I think we are\n> overloading\n> this to our potential detriment.  I think the problem we would REALLY\n> like\n> the UA folks to resolve is that there should be a simple way for\n> site.com,\n> site.net, site.uk, and site-inc.com to say they are truly the same\n> entity\n> (a=b=c=d).  I think that this is clarification that UAs may actually\n> adopt\n> (largely because it is within consumer expectation).\n>\n> However, as nice as it may be to express agent relationships, it is a\n> can of\n> worms.  Assume you succeed...  One question it will beg is - what if\n> you are\n> NOT listed as an agent but you appear within the site!  If you appear\n> on a\n> 1st party site and aren't declaring an agent relationship or seen in\n> the\n> known hosts of the parent site - what the heck are you doing there?\n> Does\n> the site not control its own content?  We may know that it is because\n> this\n> is optional, but it is a lot or reliance to be entrusted to an optional\n> element, particularly when it may be extremely difficult for 3rd\n> parties\n> acting as agents to contextually know where they are to appear and\n> dynamically generate headers accordingly.  It almost forces the use of\n> policy ref in the P3P header.  Equally, while sites like to talk about\n> controlling data collected through the site, it may be extremely\n> difficult\n> to maintain an active known hosts (in an agents context) listing.\n>\n> Even if you get past this, there is still the up hill battle of\n> consumer\n> expectation.  IMHO large UA makers enjoy (probably based on consumer\n> feedback) differentiating parties the way they are presently doing.\n> They\n> went out of their way to treat 1st and 3rd party cookies differently\n> even\n> though the spec makes no such distinction.\n>\n> Just thoughts...\n>\n> -Brooks\n>\n>\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org\n> [mailto:public-p3p-spec-request@w3.org]\n> On Behalf Of Humphrey, Jack\n> Sent: Monday, March 08, 2004 5:30 PM\n> To: 'public-p3p-spec'\n> Subject: comments on latest domain relationship proposal?\n>\n>\n> Haven't seen any comments on the latest domain relationship proposal:\n> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>\n> Please see the copy I sent to the list previously if you want to see\n> the\n> bolded sections that changed from the previous version of the draft.\n>\n> Would love to get this wrapped up soon, please get your comments in\n> before\n> Wednesday if possible.\n>\n> Thanks.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n> Sent: Monday, March 01, 2004 9:00 AM\n> To: 'public-p3p-spec'\n> Subject: RE: AGENDA: MONDAY 4 March P3P Spec Call\n>\n>\n> Here is the new draft of the domain relationships proposal. I have\n> incorporated all of the comments I've received and also tried to\n> clarify\n> some of the relationship questions.\n>\n> Changed sections are bolded so you can quickly scan what changed.\n> Rigo, can\n> you incorporate this draft into the working draft now (removing my\n> bolding,\n> of course)?\n>\n> Thanks. Sorry for the delay.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Sunday, February 29, 2004 11:00 PM\n> To: 'public-p3p-spec'\n> Subject: AGENDA: MONDAY 4 March P3P Spec Call\n>\n>\n>\n> The next P3P specification group conference call will be on\n> Monday, March 1, 2004, 11 am - 12 pm US Eastern. Dial-in\n> information is available at\n> http://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n>\n> NOTE THIS IS MONDAY, NOT WEDNESAY!\n>\n> AGENDA\n>\n> 1. Agent and domain relationships\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=522\n> (Jack please circulate new draft)\n>\n> 2. Primary purpose specification\n> (Dave please circulate a draft)\n>\n> 3. Clarify what we mean by data linked to a cookie\n> http://www.w3.org/Bugs/Public/show_bug.cgi?id=172\n>\n> 4. Proposal to deprecate compact policies\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\n>\n> 5. P3P Generic attribute for XML applications\n> http://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\n>\n> 6. Set date/time for next call\n>\n\n\n\n", "id": "lists-017-7803647"}, {"subject": "[Minutes] 10 March 2004 P3P spec cal", "content": "Minutes of the 10 March 2004 P3P 1.1 spec wg call\n\nPresent:\nLorrie Cranor\nDave Stampley\nJack Humphrey\nJeff Edelen\n\nRegrets:\nRigo Wenning\nGiles Hogben\n\n\n1. Agent and domain relationships\n\nJack described the intended usage of agent and domain\nrelationships.  It was acknowledged that the general\n\"ad server\" agent relationship problem may be too complex\nto solve at present, but a more simple proposal might be\nable to effectively address some important scenarios,\nincluding \"same entity\" relationships.\n\nThe need for reciprocation in known-hosts declarations was\nalso re-examined, with the result that nobody on the call\ncould provide an example requiring reciprocation.\n\nACTION: Jack to distribute a rough draft of a simplified\nrelationship proposal that provides non-reciprocal known-host\ndeclarations using an HTTP header for compact policies and\na PRF element for non-compact policies.\n\n\n2. Clarify what we mean by data linked to a cookie\n\nThe latest draft proposal\n<http://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0008.html>\nwas well received, with only minor wording changes suggested and agreed\nupon.\n\nACTION: Lorrie to make agreed upon changes and submit proposal.\n\n\n3. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\nand Lorrie's feedback from Microsoft meeting\n\nLorrie provided feedback from her meeting with Microsoft.\n-MS opposes the deprecation of compact policies in P3P 1.1, largely\n because of performance implications due to IE's caching implementation.\n-MS may be open to deprecation in a future version.\n-MS is open to supporting a compact policy statement grouping mechanism\n as part of P3P 1.1, to mitigate problems with compact policy accuracy\n\nACTION: All to consider possibility of adding statement grouping to\ncompact policies representation\n\n\n4. Primary purpose specification\n\nThe group briefly discussed Dave's primary purpose proposal, which sought\nto address user needs without requiring the compilation of a comprehensive\nlist of primary purposes.\n\nACTION: Dave to follow up with Lorrie to further clarify goals.\n\n5. Set date/time for next call (March 10?)\n\nNext call: 17 March 2004, 11:00am EST\n\n\n\n\nAmerican Express made the following\n annotations on 03/10/2004 04:14:23 PM\n------------------------------------------------------------------------------\n******************************************************************************\n\n     \"This message and any attachments are solely for the intended recipient and may contain confidential or privileged information. If you are not the intended recipient, any disclosure, copying, use, or distribution of the information included in this message and any attachments is prohibited.  If you have received this communication in error, please notify us by reply e-mail and immediately and permanently delete this message and any attachments.  Thank you.\"\n\n******************************************************************************\n\n\n==============================================================================\n\n\n\n", "id": "lists-017-7825542"}, {"subject": "AGENDA: 17 March P3P Spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, March 17, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Agent and domain relationships\n(Jack please circulate revised draft)\n\n2. Primary purpose specification\n(Dave please circulate reviseda draft)\n\n3. Proposal to deprecate compact policies\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0026.html\nand grouping alternative\n\n4. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n\n5. Set date/time for next call (March 24?)\n\n\n\n", "id": "lists-017-7835509"}, {"subject": "alternate domain relationships proposa", "content": "Based on our discussion last week, here is a draft of an alternate proposal\nfor a new \"our-host\" extension element (renamed to distinguish from the\nprevious proposal's \"known-host\") with a different semantic meaning. Also\nincluded is an extension to the compact policy P3P header to support the\nsame mechanism for compact policies.\n\nPlease review this new proposal and compare to the previous proposal. Is it\nmore straightforward? Might it be less confusing for implementers and user\nagent developers?\n\nThanks. I will probably be late to the call and may have some trouble\nparticipating verbally, as I will be coming from a dental appointment.\n\n++Jack++\n\n\n\n\n\ntext/html attachment: 03-domain-relationships-alternate.html\n\n\n\n\n", "id": "lists-017-7842919"}, {"subject": "RE: alternate domain relationships proposa", "content": "There seems to be something wrong with the initial argument:\n\nThe existing P3P spec says:\n\n\"A policy referenced in a policy reference file can be applied only to URIs\non the DNS (Domain Name System) host that references it. Thus, for example,\na policy reference file at the well-known location of host www.example.com\ncan apply policies only to resources on www.example.com.\"\n\nSo when you say\n\n\"forinstance.com is configured to return the HTTP header\n\n    P3P: policyref=\"http://www.example.com/w3c/p3p.xml\"\n\nThis policyref can only apply to files on www.example.com \n\nHave I missed something in this discussion?\n\n\n>**-----Original Message-----\n>**From: public-p3p-spec-request@w3.org \n>**[mailto:public-p3p-spec-request@w3.org] On Behalf Of Humphrey, Jack\n>**Sent: 17 March 2004 07:48\n>**To: 'public-p3p-spec'\n>**Subject: alternate domain relationships proposal\n>**\n>**\n>**Based on our discussion last week, here is a draft of an \n>**alternate proposal for a new \"our-host\" extension element \n>**(renamed to distinguish from the previous proposal's \n>**\"known-host\") with a different semantic meaning. Also \n>**included is an extension to the compact policy P3P header to \n>**support the same mechanism for compact policies.\n>**\n>**Please review this new proposal and compare to the previous \n>**proposal. Is it more straightforward? Might it be less \n>**confusing for implementers and user agent developers?\n>**\n>**Thanks. I will probably be late to the call and may have \n>**some trouble participating verbally, as I will be coming \n>**from a dental appointment.\n>**\n>**++Jack++\n>**\n>**\n\n\n\n", "id": "lists-017-7851464"}, {"subject": "Stampley's primary purpose draft propposa", "content": "PURPOSE/CURRENT:  Expanded descriptions (select all that apply)\n\nAction:  Fulfill online\nAction:  Respond online now\nAction:  Contact online\nAction:  Enroll\nAction:  Fulfill offline\nAction:  Respond offline\nAction:  Authenticate\nAction:  Authentication setup\nAction:  Customize online display\nAction:  Purpose fulfilled by current site\nAction:  Purpose fulfilled by other\nAction:  Respond online later\nType:  Sales\nType:  Provide information\nType:  Manage user offline account (e.g., bank, credit card)\nType:  Manage user online account (e.g., Ebay enrollment)\nType:  Acquire user info\nType:  User web search\nType:  Solicit user\n\n\n\n", "id": "lists-017-7861311"}, {"subject": "Re: alternate domain relationships proposa", "content": "I think the problem is the ambiguity of the word \"it\" in the sentence:\n\n> A policy referenced in a policy reference file can be applied only to \n> URIs\n> on the DNS (Domain Name System) host that references it.\n\nWe have been interpreting this sentence to mean:\n\nA policy referenced in a policy reference file can be applied only to \nURIs\non the DNS (Domain Name System) host that references the policy \nreference file.\n\nThus in Jack's example, if forinstance.com returns a P3P header, the \npolicy reference file it references gets applied to forinstance.com. I \nam pretty sure that is how it has been implemented in IE6, Netscape7, \nand PrivacyBird.\n\nLorrie\n\n\n\nOn Mar 17, 2004, at 3:58 AM, Giles Hogben wrote:\n\n>\n> There seems to be something wrong with the initial argument:\n>\n> The existing P3P spec says:\n>\n> \"A policy referenced in a policy reference file can be applied only to \n> URIs\n> on the DNS (Domain Name System) host that references it. Thus, for \n> example,\n> a policy reference file at the well-known location of host \n> www.example.com\n> can apply policies only to resources on www.example.com.\"\n>\n> So when you say\n>\n> \"forinstance.com is configured to return the HTTP header\n>\n>     P3P: policyref=\"http://www.example.com/w3c/p3p.xml\"\n>\n> This policyref can only apply to files on www.example.com\n>\n> Have I missed something in this discussion?\n>\n>\n>> **-----Original Message-----\n>> **From: public-p3p-spec-request@w3.org\n>> **[mailto:public-p3p-spec-request@w3.org] On Behalf Of Humphrey, Jack\n>> **Sent: 17 March 2004 07:48\n>> **To: 'public-p3p-spec'\n>> **Subject: alternate domain relationships proposal\n>> **\n>> **\n>> **Based on our discussion last week, here is a draft of an\n>> **alternate proposal for a new \"our-host\" extension element\n>> **(renamed to distinguish from the previous proposal's\n>> **\"known-host\") with a different semantic meaning. Also\n>> **included is an extension to the compact policy P3P header to\n>> **support the same mechanism for compact policies.\n>> **\n>> **Please review this new proposal and compare to the previous\n>> **proposal. Is it more straightforward? Might it be less\n>> **confusing for implementers and user agent developers?\n>> **\n>> **Thanks. I will probably be late to the call and may have\n>> **some trouble participating verbally, as I will be coming\n>> **from a dental appointment.\n>> **\n>> **++Jack++\n>> **\n>> **\n>\n\n\n\n", "id": "lists-017-7869078"}, {"subject": "RE: alternate domain relationships proposa", "content": "Do you think this was the intention of the WG?\n\n>**-----Original Message-----\n>**From: public-p3p-spec-request@w3.org \n>**[mailto:public-p3p-spec-request@w3.org] On Behalf Of Lorrie Cranor\n>**Sent: 17 March 2004 16:41\n>**To: Giles Hogben\n>**Cc: 'Humphrey Jack'; 'public-p3p-spec'\n>**Subject: Re: alternate domain relationships proposal\n>**\n>**\n>**\n>**I think the problem is the ambiguity of the word \"it\" in the \n>**sentence:\n>**\n>**> A policy referenced in a policy reference file can be \n>**applied only to\n>**> URIs\n>**> on the DNS (Domain Name System) host that references it.\n>**\n>**We have been interpreting this sentence to mean:\n>**\n>**A policy referenced in a policy reference file can be \n>**applied only to \n>**URIs\n>**on the DNS (Domain Name System) host that references the policy \n>**reference file.\n>**\n>**Thus in Jack's example, if forinstance.com returns a P3P header, the \n>**policy reference file it references gets applied to \n>**forinstance.com. I \n>**am pretty sure that is how it has been implemented in IE6, \n>**Netscape7, \n>**and PrivacyBird.\n>**\n>**Lorrie\n>**\n>**\n>**\n>**On Mar 17, 2004, at 3:58 AM, Giles Hogben wrote:\n>**\n>**>\n>**> There seems to be something wrong with the initial argument:\n>**>\n>**> The existing P3P spec says:\n>**>\n>**> \"A policy referenced in a policy reference file can be \n>**applied only to\n>**> URIs\n>**> on the DNS (Domain Name System) host that references it. Thus, for \n>**> example,\n>**> a policy reference file at the well-known location of host \n>**> www.example.com\n>**> can apply policies only to resources on www.example.com.\"\n>**>\n>**> So when you say\n>**>\n>**> \"forinstance.com is configured to return the HTTP header\n>**>\n>**>     P3P: policyref=\"http://www.example.com/w3c/p3p.xml\"\n>**>\n>**> This policyref can only apply to files on www.example.com\n>**>\n>**> Have I missed something in this discussion?\n>**>\n>**>\n>**>> **-----Original Message-----\n>**>> **From: public-p3p-spec-request@w3.org \n>**>> **[mailto:public-p3p-spec-request@w3.org] On Behalf Of \n>**Humphrey, Jack\n>**>> **Sent: 17 March 2004 07:48\n>**>> **To: 'public-p3p-spec'\n>**>> **Subject: alternate domain relationships proposal\n>**>> **\n>**>> **\n>**>> **Based on our discussion last week, here is a draft of an \n>**>> **alternate proposal for a new \"our-host\" extension element \n>**>> **(renamed to distinguish from the previous proposal's\n>**>> **\"known-host\") with a different semantic meaning. Also \n>****included is \n>**>> an extension to the compact policy P3P header to \n>****support the same \n>**>> mechanism for compact policies.\n>**>> **\n>**>> **Please review this new proposal and compare to the previous \n>**>> **proposal. Is it more straightforward? Might it be less \n>****confusing \n>**>> for implementers and user agent developers?\n>**>> **\n>**>> **Thanks. I will probably be late to the call and may have **some \n>**>> trouble participating verbally, as I will be coming \n>****from a dental \n>**>> appointment.\n>**>> **\n>**>> **++Jack++\n>**>> **\n>**>> **\n>**>\n>**\n>**\n\n\n\n", "id": "lists-017-7880294"}, {"subject": "Re: alternate domain relationships proposa", "content": "I think in our discussion last week we talked about something even \nsimpler. We suggested that there was not a need to have a two-way \nhandshake. A site should be able to use our-host even if the host it is \nreferring to does not point to its PRF.\n\nSo... an our-host tag in a POLICY-REF would mean that for any URIs \ncovered by this policy, any embedded content (anything that would be \ncovered by a HINT element) that is served from a URI covered by the \nour-host tag should be considered as coming from the entity or its \nagents (or entities for whom it is acting as an agent).  [not very well \nsaid, but hopefully, you can tell what I mean]\n\nAnd, an our-host token in a CP would mean that any cookies served with \nthe current page that domain match the our-host tag should be \nconsidered as coming from the entity or its agents (or entities for \nwhom it is acting as an agent).\n\nLorrie\n\n\nOn Mar 17, 2004, at 1:47 AM, Humphrey, Jack wrote:\n\n> Based on our discussion last week, here is a draft of an alternate \n> proposal\n> for a new \"our-host\" extension element (renamed to distinguish from the\n> previous proposal's \"known-host\") with a different semantic meaning. \n> Also\n> included is an extension to the compact policy P3P header to support \n> the\n> same mechanism for compact policies.\n>\n> Please review this new proposal and compare to the previous proposal. \n> Is it\n> more straightforward? Might it be less confusing for implementers and \n> user\n> agent developers?\n>\n> Thanks. I will probably be late to the call and may have some trouble\n> participating verbally, as I will be coming from a dental appointment.\n>\n> ++Jack++\n>\n> <03-domain-relationships-alternate.html>\n\n\n\n", "id": "lists-017-7892871"}, {"subject": "Re: alternate domain relationships proposa", "content": "Yes, I'm sure that was the intention of the WG.... we spent many, many  \nhours discussing this point. (And you would think we would have managed \nto come up with a non-ambiguous way of saying it...)\n\nLorrie\n\n\nOn Mar 17, 2004, at 10:53 AM, Giles Hogben wrote:\n\n> Do you think this was the intention of the WG?\n>\n>> **-----Original Message-----\n>> **From: public-p3p-spec-request@w3.org\n>> **[mailto:public-p3p-spec-request@w3.org] On Behalf Of Lorrie Cranor\n>> **Sent: 17 March 2004 16:41\n>> **To: Giles Hogben\n>> **Cc: 'Humphrey Jack'; 'public-p3p-spec'\n>> **Subject: Re: alternate domain relationships proposal\n>> **\n>> **\n>> **\n>> **I think the problem is the ambiguity of the word \"it\" in the\n>> **sentence:\n>> **\n>> **> A policy referenced in a policy reference file can be\n>> **applied only to\n>> **> URIs\n>> **> on the DNS (Domain Name System) host that references it.\n>> **\n>> **We have been interpreting this sentence to mean:\n>> **\n>> **A policy referenced in a policy reference file can be\n>> **applied only to\n>> **URIs\n>> **on the DNS (Domain Name System) host that references the policy\n>> **reference file.\n>> **\n>> **Thus in Jack's example, if forinstance.com returns a P3P header, the\n>> **policy reference file it references gets applied to\n>> **forinstance.com. I\n>> **am pretty sure that is how it has been implemented in IE6,\n>> **Netscape7,\n>> **and PrivacyBird.\n>> **\n>> **Lorrie\n>> **\n>> **\n>> **\n>> **On Mar 17, 2004, at 3:58 AM, Giles Hogben wrote:\n>> **\n>> **>\n>> **> There seems to be something wrong with the initial argument:\n>> **>\n>> **> The existing P3P spec says:\n>> **>\n>> **> \"A policy referenced in a policy reference file can be\n>> **applied only to\n>> **> URIs\n>> **> on the DNS (Domain Name System) host that references it. Thus, for\n>> **> example,\n>> **> a policy reference file at the well-known location of host\n>> **> www.example.com\n>> **> can apply policies only to resources on www.example.com.\"\n>> **>\n>> **> So when you say\n>> **>\n>> **> \"forinstance.com is configured to return the HTTP header\n>> **>\n>> **>     P3P: policyref=\"http://www.example.com/w3c/p3p.xml\"\n>> **>\n>> **> This policyref can only apply to files on www.example.com\n>> **>\n>> **> Have I missed something in this discussion?\n>> **>\n>> **>\n>> **>> **-----Original Message-----\n>> **>> **From: public-p3p-spec-request@w3.org\n>> **>> **[mailto:public-p3p-spec-request@w3.org] On Behalf Of\n>> **Humphrey, Jack\n>> **>> **Sent: 17 March 2004 07:48\n>> **>> **To: 'public-p3p-spec'\n>> **>> **Subject: alternate domain relationships proposal\n>> **>> **\n>> **>> **\n>> **>> **Based on our discussion last week, here is a draft of an\n>> **>> **alternate proposal for a new \"our-host\" extension element\n>> **>> **(renamed to distinguish from the previous proposal's\n>> **>> **\"known-host\") with a different semantic meaning. Also\n>> ****included is\n>> **>> an extension to the compact policy P3P header to\n>> ****support the same\n>> **>> mechanism for compact policies.\n>> **>> **\n>> **>> **Please review this new proposal and compare to the previous\n>> **>> **proposal. Is it more straightforward? Might it be less\n>> ****confusing\n>> **>> for implementers and user agent developers?\n>> **>> **\n>> **>> **Thanks. I will probably be late to the call and may have **some\n>> **>> trouble participating verbally, as I will be coming\n>> ****from a dental\n>> **>> appointment.\n>> **>> **\n>> **>> **++Jack++\n>> **>> **\n>> **>> **\n>> **>\n>> **\n>> **\n>\n\n\n\n", "id": "lists-017-7902104"}, {"subject": "Re: Stampley's primary purpose draft propposa", "content": "Banking\n\nOn Wednesday 17 March 2004 16:16, Lorrie Cranor wrote:\n> PURPOSE/CURRENT:  Expanded descriptions (select all that apply)\n>\n> Action:  Fulfill online\n> Action:  Respond online now\n\n\n\n", "id": "lists-017-7915296"}, {"subject": "Wed 17th Meeting Minute", "content": "Text elided per request[1].\n\nhttp://lists.w3.org/Archives/Team/team-archive-editor/2004Mar/0007.html]\n\n\n\n", "id": "lists-017-7922357"}, {"subject": "Re: Stampley's primary purpose draft propposa", "content": "Of course, the next problem will be coming up with good definitions of \nall these things....\n\nSome other types...\n\nEducation (would be used for course sites that might include online \nexams, allow students to check their grades, etc.... going beyond just \nproviding information)\n\nCommunication (sites with chat rooms, video conference, etc.)\n\nEntertainment (gaming, videos, music, etc.)\n\nOn Mar 17, 2004, at 10:16 AM, Lorrie Cranor wrote:\n\n>\n> PURPOSE/CURRENT:  Expanded descriptions (select all that apply)\n>\n> Action:  Fulfill online\n> Action:  Respond online now\n> Action:  Contact online\n> Action:  Enroll\n> Action:  Fulfill offline\n> Action:  Respond offline\n> Action:  Authenticate\n> Action:  Authentication setup\n> Action:  Customize online display\n> Action:  Purpose fulfilled by current site\n> Action:  Purpose fulfilled by other\n> Action:  Respond online later\n> Type:  Sales\n> Type:  Provide information\n> Type:  Manage user offline account (e.g., bank, credit card)\n> Type:  Manage user online account (e.g., Ebay enrollment)\n> Type:  Acquire user info\n> Type:  User web search\n> Type:  Solicit user\n>\n\n\n\n", "id": "lists-017-7929357"}, {"subject": "Re: Wed 17th Meeting Minute", "content": "Has this call happened yet?\n\n\n\n", "id": "lists-017-7937687"}, {"subject": "Re: alternate domain relationships proposa", "content": "  charset=\"iso-8859-1\"\n\nContent-Transfer-Encoding: 7bit\n\nContent-Disposition: inline\n\n\nThis is now online at the usual place\n\nhttp://www.w3.org/P3P/2004/03-domain-relationships.html\n\n\n\nRigo\n\n\n\nOn Wednesday 17 March 2004 07:47, Humphrey, Jack wrote:\n\n> Please review this new proposal and compare to the previous proposal.\n\n> Is it more straightforward? Might it be less confusing for\n\n> implementers and user agent developers?\n\n>\n\n\n\n\n\n", "id": "lists-017-7944858"}, {"subject": "RE: alternate domain relationships proposa", "content": "Assuming Lorrie's reading of \"it\" overcomes Giles' point, I see this\nanswering a number of problems, but leaving a number of folks with\npre-existing arcitechtures out in the cold.  I am speaking specifically\n of ad servers like ourselves and content delivery networks.\n\nIf a CDN has hierarchically structured their tag from left to right and\n can dynamically generate P3P: policyref  headers than all things are\n perfect, but practically speaking a CDN may host images as follows:\n\nhttp://highavailability.net/1000001.gif should be covered by clientA\nhttp://highavailability.net/1000002.gif should be covered by clientX\nhttp://highavailability.net/1000003.gif should be covered by clientY\nhttp://highavailability.net/1000004.gif should be covered by clientA\n\nThis presents a world more difficulty than had the set up been:\n\nhttp://highavailability.net/a/1000001.gif should be covered by clientA\nhttp://highavailability.net/x/1000002.gif should be covered by clientX\nhttp://highavailability.net/y/1000003.gif should be covered by clientY\nhttp://highavailability.net/a/1000004.gif should be covered by clientA\n\nBut in practice the former is quite common.  Adding to this the list is\n HUGE and highly dynamic.\n\nIn the ad serving world there is also the complication that a single\n URL and cookie replay would need to refer to multiple our hosts. \n Because the data collected by discreet tag may in fact belong to the\n advertiser and the publisher.\n\nAnother difficulty here is the CP OHO mechanism.  If CPs are only\n issued on cookie set, the vast majority of replays will likely be to\n hosts specifying other policies thru the dynamic P3P: policyref\n mechanism, with other policies - which essentially defeats the use of\n CPs???  Am I missing something here?\n\n-Brooks\n\n\n\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n [mailto:public-p3p-spec-request@w3.org] On Behalf Of Lorrie Cranor\nSent: Wednesday, March 17, 2004 10:41 AM\nTo: Giles Hogben\nCc: 'Humphrey Jack'; 'public-p3p-spec'\nSubject: Re: alternate domain relationships proposal\n\nI think the problem is the ambiguity of the word \"it\" in the sentence:\n> A policy referenced in a policy reference file can be applied only to\n> URIs\n> on the DNS (Domain Name System) host that references it.\n\nWe have been interpreting this sentence to mean:\n\nA policy referenced in a policy reference file can be applied only to\nURIs\non the DNS (Domain Name System) host that references the policy\nreference file.\n\nThus in Jack's example, if forinstance.com returns a P3P header, the\npolicy reference file it references gets applied to forinstance.com. I\nam pretty sure that is how it has been implemented in IE6, Netscape7,\nand PrivacyBird.\n\nLorrie\n\nOn Mar 17, 2004, at 3:58 AM, Giles Hogben wrote:\n> There seems to be something wrong with the initial argument:\n>\n> The existing P3P spec says:\n>\n> \"A policy referenced in a policy reference file can be applied only\n> to URIs\n> on the DNS (Domain Name System) host that references it. Thus, for\n> example,\n> a policy reference file at the well-known location of host\n> www.example.com\n> can apply policies only to resources on www.example.com.\"\n>\n> So when you say\n>\n> \"forinstance.com is configured to return the HTTP header\n>\n>     P3P: policyref=\"http://www.example.com/w3c/p3p.xml\"\n>\n> This policyref can only apply to files on www.example.com\n>\n> Have I missed something in this discussion?\n>\n>> **-----Original Message-----\n>> **From: public-p3p-spec-request@w3.org\n>> **[mailto:public-p3p-spec-request@w3.org] On Behalf Of Humphrey,\n>> Jack **Sent: 17 March 2004 07:48\n>> **To: 'public-p3p-spec'\n>> **Subject: alternate domain relationships proposal\n>> **\n>> **\n>> **Based on our discussion last week, here is a draft of an\n>> **alternate proposal for a new \"our-host\" extension element\n>> **(renamed to distinguish from the previous proposal's\n>> **\"known-host\") with a different semantic meaning. Also\n>> **included is an extension to the compact policy P3P header to\n>> **support the same mechanism for compact policies.\n>> **\n>> **Please review this new proposal and compare to the previous\n>> **proposal. Is it more straightforward? Might it be less\n>> **confusing for implementers and user agent developers?\n>> **\n>> **Thanks. I will probably be late to the call and may have\n>> **some trouble participating verbally, as I will be coming\n>> **from a dental appointment.\n>> **\n>> **++Jack++\n>> **\n>> **\n\n\n\n\n", "id": "lists-017-7952285"}, {"subject": "proposal to add grouping mechanism to C", "content": "Based on our discussion on the last call, here is my proposal to add a \ngrouping mechanism to CPs and to clarify that CPs are to be used only \nas hints.\n\n\nSection 4 of the latest p3p1.1 wd\nhttp://www.w3.org/TR/2004/WD-P3P11-20040210/#compact_policies\ndescribes compact policies.\n\nThe first paragraph of 4. currently states:\n\n   Compact policies are summarized P3P policies that provide hints to\n   user agents to enable the user agent to make quick, synchronous\n   decisions about applying policy. Compact policies are a performance\n   optimization that is OPTIONAL for either user agents or servers. User\n   agents that are unable to obtain enough information from a compact\n   policy to make a decision according to a user's preferences SHOULD\n   fetch the full policy.\n\nI propose changing it to say:\n\nCompact policies are summarized P3P policies that provide hints to\nuser agents to enable the user agent to make quick, synchronous\ndecisions about applying policy to cookies. Compact policies are a\nperformance optimization that is OPTIONAL for both user agents and\nservers. They represent only a summary of a site's full P3P policy for\na cookie; the full P3P policy is the authoritative statement of\npolicy. However, a site MUST honor the commitments made in a compact\npolicy. User agents that are unable to obtain enough information from\na compact policy to make a decision according to a user's preferences\nSHOULD fetch the full policy. In addition, user agents that display\ninformation about a site's P3P policies to users SHOULD use the full\nP3P policy as the source of this information.\n\nI propose adding a section 4.2.10 Compact STATEMENT\n\nThe STATEMENT element is represented in compact policies using the\ncurly brace { } symbols. The { represents the opening STATEMENT tag\nand the } represents the closing statement tag.\n\nThe syntax of the compact statement corresponds to the syntax of the\nfull statement. Unless it surrounds a compact NON-IDENTIFIABLE\nelement, each pair of braces MUST surround one compact RETENTION\nelement and at least one of each of the following compact elements:\nPURPOSE, RECIPIENT, and CATEGORIES. Alternatively, a pair of braces\nmay surround a compact NON-IDENTIFIABLE element; optionally any of the\nPURPOSE, RECIPIENT, and CATEGORIES elements; and optional a RETENTION\nelement.\n\nA compact policy that has an improperly matching pair\nof curly braces or is missing one of the required statement elements\nMUST be treated as if no curly braces are present.\n\nA compact policy may contain one or more statements. A compact policy\nwith no {} elements is considered to have a single implied statement\nelement.\n\n[BNF]\n\n\nSection 4.5, fourth paragraph, change MUST to MAY (as in \"All of the\npurposes, recipients, and categories that appear in multiple\nstatements in a full policy MAY be aggregated in a compact policy....\"\n\n\n\nSection 4.5 give two examples of valid translations. In addition to\nthe one currently given, add:\n\n\"NON DSP { ADM DEV PSD OUR IND PRE NAV } { IVDo OUR STP PHY PRE UNI }\"\n\n\n\nSection 4.6 Transforming a Compact Policy to a P3P Policy should be \ndropped.\n\n\n\n", "id": "lists-017-7965270"}, {"subject": "Re: proposal to add grouping mechanism to C", "content": "On Saturday 20 March 2004 04:45, Lorrie Cranor wrote:\n> I propose adding a section 4.2.10 Compact STATEMENT\n> \n> The STATEMENT element is represented in compact policies using the\n> curly brace { } symbols. The { represents the opening STATEMENT tag\n> and the } represents the closing statement tag.\n\nThis is a good trick. I like it. But curly braces don't carry attributes ;) This means \nthe grouping mechanism of <statement> can't be applied. Your examples \nfor grouping are good, but I would really like us to have a chunk of full \npolicy in the example and the grouped compact representation that goes \nwith it.\n\nBest, \n\nRigo\n\n\n\n\n\n\n", "id": "lists-017-7975440"}, {"subject": "Re: proposal to add grouping mechanism to C", "content": "If we need attributes, we can use an alternate syntax that would allow \nit. But I'm not sure what statement attributes need to be represented \nin compact policies... There are no STATEMENT attributes other than \nthose that are part of extensions.\n\nLorrie\n\n\nAlso, I did include an example in the text I sent in the last message. \nIt is a grouped compact policy from the example that is already in the \nspec.\n\nLorrie\n\nOn Mar 20, 2004, at 9:19 AM, Rigo Wenning wrote:\n\n> On Saturday 20 March 2004 04:45, Lorrie Cranor wrote:\n>> I propose adding a section 4.2.10 Compact STATEMENT\n>>\n>> The STATEMENT element is represented in compact policies using the\n>> curly brace { } symbols. The { represents the opening STATEMENT tag\n>> and the } represents the closing statement tag.\n>\n> This is a good trick. I like it. But curly braces don't carry \n> attributes ;) This means\n> the grouping mechanism of <statement> can't be applied. Your examples\n> for grouping are good, but I would really like us to have a chunk of \n> full\n> policy in the example and the grouped compact representation that goes\n> with it.\n>\n> Best,\n>\n> Rigo\n>\n>\n\n\n\n", "id": "lists-017-7983250"}, {"subject": "AGENDA: 24 March P3P Spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, March 24, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Agent and domain relationships\n(Jack please circulate revised draft)\n\n2. Primary purpose specification\n(Dave please circulate revised draft)\n\n3. Grouping mechanism proposal\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0029.html\n\n4. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n\n5. Set target date for next public working draft (April 9?) Can this be \na last call draft?\n\n6. Set date/time for next call (March 31?)\n\n\n\n", "id": "lists-017-7992091"}, {"subject": "MINUTES: 17 March 2004 P3P spec cal", "content": "[Minutes taken by Giles Hogben and edited by Lorrie Cranor]\n\nProposal to deprecate compact policies\n\nMicrosoft does not want to have CP's deprecated and has no resources to\nwork on p3p right now but would probably implement a grouping mech for\nCP's by the next major release. Why they need CP's has to do with\ncaching which was written a long time ago and would have to be\nrewritten. Why can't they rewrite their code. Should we proceed on a\ngrouping mechanism? We are likely looking past P3P 1.1 timeframe for\nnext major release\n\nGiles - even in a year is there no possibility of rewriting caching:\nLorrie: we can't assume that we can before P3P 1.1. comes out because no\npossibility to discuss\nRigo: grouping would be a major piece of work\nLorrie: It is straighforward\nRigo: There are hidden issues. How big is the problem we want to solve \nand\nhow much work is it to solve that problem\nLorrie: Anything we put in is work but I don't think it is that much. \nBut\nhow much does it solve. If we proceed with this then there will be less\nmotivation to get rid of CP's later. so if it doesn't solve many \nproblems\nthen we shouldn't do it.#\nBrookes: Do CP's accurately reflect full policies. Brookes doesn't. 15\ncategories can't be an accurately describe the world.\nLorrie: Most web sites only use categories.\nGiles: But they are trying to please IE6\nLorrie: What other problems do we have\nRigo: People implement only one policy.\nMatthias: CP reflects worst case? But grouping allows you to \ndistinguish.\nWe figure out what exactly grouping does\nBrookes: so what will MS actually do with the grouping mechanism - they \nare\ndisplaying policies with a single message. If they display the \ngranularity\nthen they can't put the penalties in place.\nLorrie: They are not too concerned about the presentation. When they \nblock\ncookies, you really have to dig to get info. So my impression is that \nthey\nwill just change their blocking algorithm...\nRigo: When will they do this? Doubleclick has the option to make their\nobjections known.\nLorrie: MS will check to see that the FP exists\nGiles: what about PRF's\nLorrie: They only apply to cookies. A group will be roughly analogous \nto a\nstatement. Statement could be implied by curly brackets. Backward\ncompatability - if you ignore the curly braces, you still have a valid \nCP\nwith duplicate tokens.\nGiles: But it might have a completely different meaning.\nRigo: --> same set of tokens can have 2 different meanings.\nLorrie: Same meaning but interpreted in 2 different known ways.\nRigo: We should weaken the meaning of CP's. Want to resolve problems \nthat\nweb sites are put off by liability issues because of mismatches in\nsemantics.\nThere is a thin line between they can't lie but if they miss some\ngranularity this is less of a problem.\nLorrie: You don't have to use the curly braces.\nGiles: How about doing both.\nLorrie: We could say something like - think about not using them at all\nbecause we are thinking of taking them out altogether.\nRigo: So the problem is just with the overhead. Even Mozilla has only\ncompact. If PRIME can implement something in Mozilla it creates a lot of\npressure on MS. Mozilla will go to safari etc...\nLorrie: So what's the answer\nRigo: we need to give it a different spin. So it means we say the CP is \njust\na hint and has to be compliant with the FP. Don't make it a legal \nstatement\n- it is only a hint.\nGiles: If it is only a hint, what use is it?\nLorrie: To display a reason, it has to go to the full policy.\nRigo: The measure against which you are measured to see if you lied is \nthe\nfull policy.\nDave: The clearest case of fraud is if you deliberately chose a wrong \ntoken.\nIt is still a hint and you can't mislead with it. Box of medicine \nmetaphor.\nCall: Proceed in this direction\nAction item: Matthias?\n\nConsent choices:\nJack: I forgot how much simpler I was supposed to make it. I need to \nget rid\nof the requirement of referring to the PRF.\nLorrie: Borrow from the language we use in the hints section.\nJack: I am concerned that we are not really making it any more\nstraightforward than the previous ones.\nLorrie: Once it is fully simplified, the ourhosts mechanisms says that n\nour-host tag in a POLICY-REF would mean that for any URIs\ncovered by this policy, any embedded content (anything that would be\ncovered by a HINT element) that is served from a URI covered by the\nour-host tag should be considered as coming from the entity or its\nagents (or entities for whom it is acting as an agent).\n\nBrookes: It is very difficult for people to implement this, because if \nyou\nneed to use the url to decide quickly how to dynamically generate a PRF.\n\nPrimary purpose spec:\nRigo: it's great. Send it to the outreach\nLorrie: How useful will it be because people will have to include all \nthe\nitems.\nDave: How satisfactory will it be to the Art 10 WG? For real policies, a\nlist of 200 might be better.\nLorrie: Even a list of 200 - given that most sites are going for a \nsite-wide\npolicy. So even that might not help.\nRigo: Banking is missing.\nDave: if they are going to lump them altogether this will never be \nuseful\nbut it gives the possibilities.\nLorrie: But it might help if they are divided out into statements.\nDave: Main purpose of this is that a user agent loading a page can get \nthe\nmeaning of the current purpose...\nDave: If I go to Google, which will apply: user web search. Will add \nupdated\nexamples column.\nMathias: Would it make sense to put a textual description in. This \nwould be\na long description field (own ad-hoc)\nDave: This is bound to be desireable for meaningful communication.\nEspecially for people who can't find theirs on the list.\nRigo: In the EU you care about the primary purpose, in the US, you care\nabout secondary. Important goal to express EU directives.\nLorrie: I think it can be useful in that respect. The actions are fairly\ncomplete. Some additional types will come up.\n\n\n\n", "id": "lists-017-7999553"}, {"subject": "NEW alternate domain relationships proposa", "content": "Attached is the new, leaner, simpler domain relationships (a.k.a. OUR-HOST)\nproposal. Please review -- we can discuss tomorrow.\n\n++Jack++\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Wednesday, March 17, 2004 9:56 AM\nTo: Humphrey, Jack\nCc: 'public-p3p-spec'\nSubject: Re: alternate domain relationships proposal\n\n\nI think in our discussion last week we talked about something even \nsimpler. We suggested that there was not a need to have a two-way \nhandshake. A site should be able to use our-host even if the host it is \nreferring to does not point to its PRF.\n\nSo... an our-host tag in a POLICY-REF would mean that for any URIs \ncovered by this policy, any embedded content (anything that would be \ncovered by a HINT element) that is served from a URI covered by the \nour-host tag should be considered as coming from the entity or its \nagents (or entities for whom it is acting as an agent).  [not very well \nsaid, but hopefully, you can tell what I mean]\n\nAnd, an our-host token in a CP would mean that any cookies served with \nthe current page that domain match the our-host tag should be \nconsidered as coming from the entity or its agents (or entities for \nwhom it is acting as an agent).\n\nLorrie\n\n\nOn Mar 17, 2004, at 1:47 AM, Humphrey, Jack wrote:\n\n> Based on our discussion last week, here is a draft of an alternate \n> proposal\n> for a new \"our-host\" extension element (renamed to distinguish from the\n> previous proposal's \"known-host\") with a different semantic meaning. \n> Also\n> included is an extension to the compact policy P3P header to support \n> the\n> same mechanism for compact policies.\n>\n> Please review this new proposal and compare to the previous proposal. \n> Is it\n> more straightforward? Might it be less confusing for implementers and \n> user\n> agent developers?\n>\n> Thanks. I will probably be late to the call and may have some trouble\n> participating verbally, as I will be coming from a dental appointment.\n>\n> ++Jack++\n>\n> <03-domain-relationships-alternate.html>\n\n\n\n\n\ntext/html attachment: 03-domain-relationships-alternate-2.html\n\n\n\n\n", "id": "lists-017-8011834"}, {"subject": "Primary Purpose rev 3-240", "content": "Rev. 3/24/2004\n\n \n\nPURPOSE/CURRENT:  Expanded descriptions (select all that apply)Result:  \n\n \n\nAction:  Acquire data from user (survey, poll, demographics)\n\nAction:  Acquire user PII\n\nAction:  Acquire user preferences\n\nAction:  Provide communications services (email, chat, videoconference,\nVoIP)\n\nAction:  Provide interface of offline user account or relationship\n\nAction:  Register or enroll user\n\nAction:  Sales\n\nAction:  User web search\n\n \n\nContent:  Adult\n\nContent:  Charity\n\nContent:  Children's interest\n\nContent:  Educational\n\nContent:  Games, online entertainment, music\n\nContent:  General interest (gardening, fashion, etc.)\n\nContent:  Health\n\nContent:  Health\n\nContent:  Merchandise, service\n\nContent:  News, current interest\n\nContent:  Political\n\nContent:  Sweepstakes, coupons\n\n \n\nResult:  Authenticate\n\nResult:  Authentication setup\n\nResult:  Contact online\n\nResult:  Customize online display\n\nResult:  Fulfill offline\n\nResult:  Fulfill online\n\nResult:  Manage user offline account (e.g., bank, credit card)\n\nResult:  Manage user online account (e.g., Ebay enrollment)\n\nResult:  Purpose fulfilled by current site\n\nResult:  Purpose fulfilled by other\n\nResult:  Respond offline\n\nResult:  Respond online later\n\nResult:  Respond online now\n\n \n\n# # # \n\n \n\nDave\n\n \n\n\n\n", "id": "lists-017-8021164"}, {"subject": "Re: proposal to add grouping mechanism to C", "content": "Here is my revised proposal based on today's call. Please send proposed \nchanges to the mailing list BEFORE next week's call. I would like to \nfinish this next week.\n\nLorrie\n\n\n\nSection 4 of the latest p3p1.1 wd\nhttp://www.w3.org/TR/2004/WD-P3P11-20040210/#compact_policies\ndescribes compact policies.\n\nThe first paragraph of 4. currently states:\n\n   Compact policies are summarized P3P policies that provide hints to\n   user agents to enable the user agent to make quick, synchronous\n   decisions about applying policy. Compact policies are a performance\n   optimization that is OPTIONAL for either user agents or servers. User\n   agents that are unable to obtain enough information from a compact\n   policy to make a decision according to a user's preferences SHOULD\n   fetch the full policy.\n\nI propose changing it to say:\n\nCompact policies are summarized P3P policies that provide hints to\nuser agents to enable the user agent to make quick, synchronous\ndecisions about applying policy to cookies. Compact policies are a\nperformance optimization that is OPTIONAL for both user agents and\nservers. They represent only a summary of a site's full P3P policy for\na cookie; the full P3P policy is the authoritative statement of\npolicy. However, a site MUST make compact policy statements in good\nfaith. User agents that are unable to obtain enough information from\na compact policy to make a decision according to a user's preferences\nSHOULD fetch the full policy.\n\nUser agents that use compact policies as part of their decision making\nMUST include a mechanism that allows users to determine that a\nparticular decision was made based on a compact policy and to view\nthat compact policy. However, user agents that provide general\ninformation about a site's P3P policies to users MUST use the full P3P\npolicy and MUST NOT use the compact policy for this purpose.\n\nI propose adding a section 4.2.10 Compact STATEMENT\n\nThe STATEMENT element is represented in compact policies using the\ncurly brace { } symbols. The { represents the opening STATEMENT tag\nand the } represents the closing statement tag.\n\nThe syntax of the compact statement corresponds to the syntax of the\nfull statement. Unless it surrounds a compact NON-IDENTIFIABLE\nelement, each pair of braces MUST surround one compact RETENTION\nelement and at least one of each of the following compact elements:\nPURPOSE, RECIPIENT, and CATEGORIES. Alternatively, a pair of braces\nmay surround a compact NON-IDENTIFIABLE element; optionally any of the\nPURPOSE, RECIPIENT, and CATEGORIES elements; and optionally a RETENTION\nelement.\n\nA compact policy that has an improperly matching pair\nof curly braces or is missing one of the required statement elements\nMUST be treated as if no curly braces are present.\n\nA compact policy may contain one or more statements. A compact policy\nwith no {} elements is considered to have a single implied statement\nelement.\n\n[BNF]\n\n\nSection 4.5, fourth paragraph, change MUST to MAY (as in \"All of the\npurposes, recipients, and categories that appear in multiple\nstatements in a full policy MAY be aggregated in a compact policy....\"\n\n\n\nSection 4.5 give two examples of valid translations. In addition to\nthe one currently given, add:\n\n\"NON DSP { ADM DEV PSD OUR IND PRE NAV } { IVDo OUR STP PHY PRE UNI }\"\n\n\n\nSection 4.6 Transforming a Compact Policy to a P3P Policy should be \ndropped.\n\n\n\n", "id": "lists-017-8029657"}, {"subject": "MINUTES: 24 March 2004 P3P spec cal", "content": "P3P Call\n\nMinutes 3/24/04\n\n11:00 AM Eastern\n\n?\n\nAttendees:\n\nLorrie Cranor (CMU)- Chair\n\nBrooks Dobbs - DoubleClick (scribe)\n\nGiles Hogben - JRC\n\n  Jeff? Edelen - American Express\n\nJack Humphrey - Coremetrics\n\nDave Stampley -? Reynolds and Reynolds\n\nRigo Wenning - W3C\n\n?\n\nAgenda Item 1 - revised agents domain draft\n\n?\n\nJack - has anyone had a chance to read it over?\n\nBrooks - has not\n\nLorrie - let's skip over until people have chance to read over it\n\n?\n\nAgenda Item 2 (skip)\n\n?\n\nAgenda Item 3 - Grouping Mechanism\n\n?\n\nLorrie: have people read this\n\nBrooks: yes - I liked it\n\nLorrie: says that wording should be hint but wants to make sure it is \nunderstood that you can't lie\n\nLorrie: any comments?? Would you all be inclined to approve it then?\n\nGiles: hasn't read yet\n\nJack: are there certain tokens that can't be grouped\n\nBrooks and Lorrie: yes it is grouped by same rules as <statement>\n\nDave: suggests a language changes from \"must honor\" to \"must make CP \nstatements in good faith\"\n\n  Lorrie: says okay\n\nLorrie: any objections?\n\nRigo: please add parenthetically \"bona fide\" to \"good faith\"\n\nRigo: concerns about attributes. P3P 1.1 CP format expresses 1.0\n\nLorrie: what isn't supported is an optional extension and this is not a \ntragic omission\n\nJack: which extension are we talking about?\n\nRigo: the statement already has a grouping extension to allow display \nof opt in and opt out statements from Matthias\n\nLorrie: if we needed to we could add another layer of grouping to \nhandle this\n\nLorrie: do we need to support this - would there be a case when you \nwanted to accept or reject a cookie based upon if the entire group was \nopt in or opt out.\n\nRigo: wants to change camps because he doesn't want them to be \"too \nsmart\" and then there would be less pressure to do away with them\n\nGiles: does this mean that you need to have compact policy parser?\n\nLorrie: is there anyone who wants to argue to add the 1.1 statement \ngrouping into CPs (not the \"grouping mechanism\" for CPs)?\n\nGiles: do we agree that we want CPs dumb?\n\nGiles: okay with CP grouping mechanism\n\nLorrie: can we accept this today or do we need time to think?\n\nGiles: With regards to displaying policies to user change language to \nSHOULD use full policy for source of information and specifically not \nthe CP\n\nGiles: pushes for MUST rather than should\n\nLorrie: likes Giles argument\n\nBrooks: Wants the UA to display the set of information actually used to \nmake a decision\n\nLorrie: suggest language change that reflects that - user agents that \nprovide information to user that make cookie handling decisions must \nprovide information based on the CP or full policy actually used to \nmake the decision\n\nRigo: thinks that this is ambiguous\n\nRigo: thinks that Brooks wants a debugger\n\nSYNOPSIS: Brooks pushing for UA to display the ACTUAL criteria actually \nused to make decision vs. the full policy.? Rigo thinks retranslation \nof CP provides a bad meaning to the end user.? Courts will want to use \nthis bad translation.\n\nLorrie:? will send out a revision that essentially says that if a UA \ndoes use a CP to make a decision it MUST have a mechanism for \ndisplaying that CP... UAs that provide general information MUST use the \nfull policy\n\n  Lorrie: will circulate anther draft\n\n?\n\nLast Agenda Item -\n\n  Lorrie: Would April 9th be a reasonable date for our next working draft\n\nRigo: what would be added?\n\nLorrie: known-hosts, grouping and some edits\n\nLorrie: can this be our last call draft\n\nNO\n\nLorrie: let's get this as close as possible.? Let's make us have a \nmindset that this version internally that all the issues are 95% \nresolved.\n\nLorrie: very short issues that remain\n\nRigo: Lorrie please send the list the issues that you think remain\n\nLorrie: what is left in bug tracker?\n\nRigo: could you please just send your list?\n\nLorrie: I will send it\n\n?\n\nLorrie: next meeting - same time next week\n\n  ?\n\n?\n\n?\n\nBrooks Dobbs\n\nDirector of Privacy Technology\n\nDoubleClick, Inc.\n\n?\n\nemail: bdobbs@doubleclick.net\n\n?\n\n\n\n", "id": "lists-017-8040436"}, {"subject": "RE: domain relationship", "content": "So something we may still need to clarify, if what we are trying to get\naround here is implementers that have 1st and 3rd party restrictions.\nObviously IE makes some of its own defintions.  One such liberty in the\nwhole 1st third party thing is they rely on a \"parent\" request that\ndetermines 1st partyness without ever really defining or even mentioning\n\"parent\".  I think we assume this parent to be the file that returns\nHTML that tells the browser to go pull child assets (beacons, images,\niframes, whatever).  IE has the notion that these sub elements can have\neither a 1st or 3rd party relationship with the parent.  I think you\nhave addressed how *that* relationship can be more expressive, but does\nanything in current P3P talk to the notion of their even being a parent\nasset?  \n\nImagine the following scenario.  \n\nWeathersite.com declares an our-hosts relationship with adserver.com.\nSo now when adserver.com serves ads on weathersite.com there is a way\nthat weathersite.com can communicate that adserver.com should be treated\nas 1st party.\n\nImagine however that there is another site publisher.com which embeds\ncontent not only from adserver.com but also from weathersite.com.  What\nis a UA to do?  Is adserver.com an our-host of weathersite.com or of\npublisher.com.  Unless there is a definition or hierarchy of parent,\nthings get messy no?\n\n\n-Brooks\n\n\n-----Original Message-----\nFrom: Humphrey, Jack [mailto:JHumphrey@coremetrics.com] \nSent: Monday, March 29, 2004 5:25 PM\nTo: Dobbs, Brooks\nSubject: RE: domain relationships\n\n\nNo, Rigo didn't update it. I've attached the latest version again.\n\n++Jack++\n\n-----Original Message-----\nFrom: Dobbs, Brooks\nTo: Jack Humphrey (JHumphrey@coremetrics.com)\nSent: 3/29/2004 4:06 PM\nSubject: domain relationships\n\nJack is this the latest version?\n\n\n\nhttp://www.w3.org/P3P/2004/03-domain-relationships.html\n\n\n\nBrooks Dobbs\n\nDirector of Privacy Technology\n\nDoubleClick, Inc.\n\n\n\nemail: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n\n\n\n", "id": "lists-017-8051150"}, {"subject": "AGENDA: 31 March P3P Spec cal", "content": "The next P3P specification group conference call will be on\nWednesday, March 31, 2004, 11 am - 12 pm US Eastern. Dial-in\ninformation is available at\nhttp://www.w3.org/P3P/Group/Specification/1.1/meetings.html\n\nAGENDA\n\n1. Agent and domain relationships\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0034.html\n\n2. Primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[please send comments BEFORE the call]\n\n3. Grouping mechanism proposal\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0036.html\n[If you have comments, please send them BEFORE the call. Unless there \nare objections raised prior to the call we will plan to approve this \nproposal on the call.]\n\n4. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n\n5. Discuss publication of next public working draft (by April 9?) and \nlast call\n  - what is left to do?\n    - need to resolve above items\n    - need to determine who to list as authors\n    - have art 10 stuff been added to working draft or is there more to \ndo?\n    - Giles, what about the schema stuff?\n    - is there anything else from P3P beyond HTTP that we need to \ninclude?\n\n6. Set date/time for next call (April 7?)\n\n\n\n", "id": "lists-017-8062368"}, {"subject": "Re: domain relationship", "content": "Hmm... interesting question. So, my interpretation of the current \nproposal is that there are no transitive relationships. If \npublisher.com declares weathersite.com and adserver.com as our-hosts, \nthen both of them can be treated as first party regardless as to \nwhether they are embedded directly or indirectly. That should probably \nbe made explicit.\n\nLorrie\n\n\nOn Mar 29, 2004, at 6:12 PM, Dobbs, Brooks wrote:\n\n>\n>\n> So something we may still need to clarify, if what we are trying to get\n> around here is implementers that have 1st and 3rd party restrictions.\n> Obviously IE makes some of its own defintions.  One such liberty in the\n> whole 1st third party thing is they rely on a \"parent\" request that\n> determines 1st partyness without ever really defining or even \n> mentioning\n> \"parent\".  I think we assume this parent to be the file that returns\n> HTML that tells the browser to go pull child assets (beacons, images,\n> iframes, whatever).  IE has the notion that these sub elements can have\n> either a 1st or 3rd party relationship with the parent.  I think you\n> have addressed how *that* relationship can be more expressive, but does\n> anything in current P3P talk to the notion of their even being a parent\n> asset?\n>\n> Imagine the following scenario.\n>\n> Weathersite.com declares an our-hosts relationship with adserver.com.\n> So now when adserver.com serves ads on weathersite.com there is a way\n> that weathersite.com can communicate that adserver.com should be \n> treated\n> as 1st party.\n>\n> Imagine however that there is another site publisher.com which embeds\n> content not only from adserver.com but also from weathersite.com.  What\n> is a UA to do?  Is adserver.com an our-host of weathersite.com or of\n> publisher.com.  Unless there is a definition or hierarchy of parent,\n> things get messy no?\n>\n>\n> -Brooks\n>\n>\n> -----Original Message-----\n> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n> Sent: Monday, March 29, 2004 5:25 PM\n> To: Dobbs, Brooks\n> Subject: RE: domain relationships\n>\n>\n> No, Rigo didn't update it. I've attached the latest version again.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Dobbs, Brooks\n> To: Jack Humphrey (JHumphrey@coremetrics.com)\n> Sent: 3/29/2004 4:06 PM\n> Subject: domain relationships\n>\n> Jack is this the latest version?\n>\n>\n>\n> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>\n>\n>\n> Brooks Dobbs\n>\n> Director of Privacy Technology\n>\n> DoubleClick, Inc.\n>\n>\n>\n> email: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n>\n>\n>\n>\n>\n>\n\n\n\n", "id": "lists-017-8070973"}, {"subject": "Re: Primary Purpose rev 3-240", "content": "I don't fully understand why we need a separate action and result \nsection. Could these be folded together?\n\nLorrie\n\n\nOn Mar 24, 2004, at 11:08 AM, Stampley, David A wrote:\n\n> Rev. 3/24/2004\n>\n> ?\n>\n> PURPOSE/CURRENT:? Expanded descriptions (select all that apply)Result:?\n>\n>  ?\n>\n> Action:? Acquire data from user (survey, poll, demographics)\n>\n> Action:? Acquire user PII\n>\n> Action:? Acquire user preferences\n>\n> Action:? Provide communications services (email, chat, \n> videoconference, VoIP)\n>\n> Action:? Provide interface of offline user account or relationship\n>\n> Action:? Register or enroll user\n>\n> Action:? Sales\n>\n> Action:? User web search\n>\n> ?\n>\n> Content:? Adult\n>\n> Content:? Charity\n>\n> Content:? Children's interest\n>\n> Content:? Educational\n>\n> Content:? Games, online entertainment, music\n>\n> Content:? General interest (gardening, fashion, etc.)\n>\n> Content:? Health\n>\n> Content:? Health\n>\n> Content:? Merchandise, service\n>\n> Content:? News, current interest\n>\n> Content:? Political\n>\n> Content:? Sweepstakes, coupons\n>\n> ?\n>\n> Result:? Authenticate\n>\n> Result:? Authentication setup\n>\n> Result:? Contact online\n>\n> Result:? Customize online display\n>\n> Result:? Fulfill offline\n>\n> Result:? Fulfill online\n>\n> Result:? Manage user offline account (e.g., bank, credit card)\n>\n> Result:? Manage user online account (e.g., Ebay enrollment)\n>\n> Result:? Purpose fulfilled by current site\n>\n> Result:? Purpose fulfilled by other\n>\n> Result:? Respond offline\n>\n> Result:? Respond online later\n>\n> Result:? Respond online now\n>\n> ?\n>\n> # # #\n>\n>  ?\n>\n> Dave\n>\n> ?\n\n\n\n", "id": "lists-017-8081574"}, {"subject": "RE: domain relationship", "content": "Does this section of the proposal not clarify it?\n---\nAny relationships inferred by this mechanism are valid only in the context\nof the policy reference file and policy for which they were discovered --\nthis is not a mechanism for declaring globally that two hosts have a\nrelationship in all contexts. By extension, the relationships are not\ntransitive. Suppose two distinct hosts A and C are matched by OUR-HOST\nentries in a policy reference file for host B. Even if the same policy\napplies to both, nothing may be inferred about the relationship between A\nand C for use in other contexts.\n---\n(I think that first sentence needs to be rephrased: \"in the context for\nwhich they were discovered\"?)\n\nBrooks, in your example, publisher.com would definitely have to declare both\nweathersite.com and adserver.com as our-hosts. There is no hierarchy or any\nkind of transitivity.\n\n++Jack++\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Monday, March 29, 2004 8:46 PM\nTo: 'public-p3p-spec'\nSubject: Re: domain relationships\n\n\n\nHmm... interesting question. So, my interpretation of the current \nproposal is that there are no transitive relationships. If \npublisher.com declares weathersite.com and adserver.com as our-hosts, \nthen both of them can be treated as first party regardless as to \nwhether they are embedded directly or indirectly. That should probably \nbe made explicit.\n\nLorrie\n\n\nOn Mar 29, 2004, at 6:12 PM, Dobbs, Brooks wrote:\n\n>\n>\n> So something we may still need to clarify, if what we are trying to get\n> around here is implementers that have 1st and 3rd party restrictions.\n> Obviously IE makes some of its own defintions.  One such liberty in the\n> whole 1st third party thing is they rely on a \"parent\" request that\n> determines 1st partyness without ever really defining or even \n> mentioning\n> \"parent\".  I think we assume this parent to be the file that returns\n> HTML that tells the browser to go pull child assets (beacons, images,\n> iframes, whatever).  IE has the notion that these sub elements can have\n> either a 1st or 3rd party relationship with the parent.  I think you\n> have addressed how *that* relationship can be more expressive, but does\n> anything in current P3P talk to the notion of their even being a parent\n> asset?\n>\n> Imagine the following scenario.\n>\n> Weathersite.com declares an our-hosts relationship with adserver.com.\n> So now when adserver.com serves ads on weathersite.com there is a way\n> that weathersite.com can communicate that adserver.com should be \n> treated\n> as 1st party.\n>\n> Imagine however that there is another site publisher.com which embeds\n> content not only from adserver.com but also from weathersite.com.  What\n> is a UA to do?  Is adserver.com an our-host of weathersite.com or of\n> publisher.com.  Unless there is a definition or hierarchy of parent,\n> things get messy no?\n>\n>\n> -Brooks\n>\n>\n> -----Original Message-----\n> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n> Sent: Monday, March 29, 2004 5:25 PM\n> To: Dobbs, Brooks\n> Subject: RE: domain relationships\n>\n>\n> No, Rigo didn't update it. I've attached the latest version again.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Dobbs, Brooks\n> To: Jack Humphrey (JHumphrey@coremetrics.com)\n> Sent: 3/29/2004 4:06 PM\n> Subject: domain relationships\n>\n> Jack is this the latest version?\n>\n>\n>\n> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>\n>\n>\n> Brooks Dobbs\n>\n> Director of Privacy Technology\n>\n> DoubleClick, Inc.\n>\n>\n>\n> email: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n>\n>\n>\n>\n>\n>\n\n\n\n", "id": "lists-017-8090829"}, {"subject": "Re: domain relationship", "content": "I think what is not explicit is the types of content to which you can \napply our-host -- that embedded content includes both directly and \nindirectly embedded content. Maybe we need to include some examples \nlike \"images, frames, images embedded in frames, etc.\"\n\nLorrie\n\n\nOn Mar 29, 2004, at 10:32 PM, Humphrey, Jack wrote:\n\n> Does this section of the proposal not clarify it?\n> ---\n> Any relationships inferred by this mechanism are valid only in the \n> context\n> of the policy reference file and policy for which they were discovered \n> --\n> this is not a mechanism for declaring globally that two hosts have a\n> relationship in all contexts. By extension, the relationships are not\n> transitive. Suppose two distinct hosts A and C are matched by OUR-HOST\n> entries in a policy reference file for host B. Even if the same policy\n> applies to both, nothing may be inferred about the relationship \n> between A\n> and C for use in other contexts.\n> ---\n> (I think that first sentence needs to be rephrased: \"in the context for\n> which they were discovered\"?)\n>\n> Brooks, in your example, publisher.com would definitely have to \n> declare both\n> weathersite.com and adserver.com as our-hosts. There is no hierarchy \n> or any\n> kind of transitivity.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Monday, March 29, 2004 8:46 PM\n> To: 'public-p3p-spec'\n> Subject: Re: domain relationships\n>\n>\n>\n> Hmm... interesting question. So, my interpretation of the current\n> proposal is that there are no transitive relationships. If\n> publisher.com declares weathersite.com and adserver.com as our-hosts,\n> then both of them can be treated as first party regardless as to\n> whether they are embedded directly or indirectly. That should probably\n> be made explicit.\n>\n> Lorrie\n>\n>\n> On Mar 29, 2004, at 6:12 PM, Dobbs, Brooks wrote:\n>\n>>\n>>\n>> So something we may still need to clarify, if what we are trying to \n>> get\n>> around here is implementers that have 1st and 3rd party restrictions.\n>> Obviously IE makes some of its own defintions.  One such liberty in \n>> the\n>> whole 1st third party thing is they rely on a \"parent\" request that\n>> determines 1st partyness without ever really defining or even\n>> mentioning\n>> \"parent\".  I think we assume this parent to be the file that returns\n>> HTML that tells the browser to go pull child assets (beacons, images,\n>> iframes, whatever).  IE has the notion that these sub elements can \n>> have\n>> either a 1st or 3rd party relationship with the parent.  I think you\n>> have addressed how *that* relationship can be more expressive, but \n>> does\n>> anything in current P3P talk to the notion of their even being a \n>> parent\n>> asset?\n>>\n>> Imagine the following scenario.\n>>\n>> Weathersite.com declares an our-hosts relationship with adserver.com.\n>> So now when adserver.com serves ads on weathersite.com there is a way\n>> that weathersite.com can communicate that adserver.com should be\n>> treated\n>> as 1st party.\n>>\n>> Imagine however that there is another site publisher.com which embeds\n>> content not only from adserver.com but also from weathersite.com.  \n>> What\n>> is a UA to do?  Is adserver.com an our-host of weathersite.com or of\n>> publisher.com.  Unless there is a definition or hierarchy of parent,\n>> things get messy no?\n>>\n>>\n>> -Brooks\n>>\n>>\n>> -----Original Message-----\n>> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n>> Sent: Monday, March 29, 2004 5:25 PM\n>> To: Dobbs, Brooks\n>> Subject: RE: domain relationships\n>>\n>>\n>> No, Rigo didn't update it. I've attached the latest version again.\n>>\n>> ++Jack++\n>>\n>> -----Original Message-----\n>> From: Dobbs, Brooks\n>> To: Jack Humphrey (JHumphrey@coremetrics.com)\n>> Sent: 3/29/2004 4:06 PM\n>> Subject: domain relationships\n>>\n>> Jack is this the latest version?\n>>\n>>\n>>\n>> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>>\n>>\n>>\n>> Brooks Dobbs\n>>\n>> Director of Privacy Technology\n>>\n>> DoubleClick, Inc.\n>>\n>>\n>>\n>> email: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n>>\n>>\n>>\n>>\n>>\n>>\n>\n\n\n\n", "id": "lists-017-8103685"}, {"subject": "Re: Primary Purpose rev 3-240", "content": "Am Tuesday 30 March 2004 04:47 verlautbarte Lorrie Cranor :\n> \n> I don't fully understand why we need a separate action and result \n> section. Could these be folded together?\n\nI don't understand that either. I additionally don't understand the \ncontent class. Is this content received or content sent? If it is content \nreceived, this is out of scope of P3P. If it is content sent, it duplicates\nthe base dataschema.\n\nCan somebody help?\n\nRigo\n\n\n\n\n\n", "id": "lists-017-8116824"}, {"subject": "Re: domain relationship", "content": "I've updated the file. It is again the latest version\n\nRigo\n\n> From: Dobbs, Brooks\n> To: Jack Humphrey (JHumphrey@coremetrics.com)\n> Sent: 3/29/2004 4:06 PM\n> Subject: domain relationships\n> \n> Jack is this the latest version?\n> \n> \n> \n> http://www.w3.org/P3P/2004/03-domain-relationships.html\n> \n\n\n\n\n", "id": "lists-017-8123926"}, {"subject": "RE: Primary Purpose rev 3-240", "content": "Yes.\n\nDave Stampley\nv.  937-485-0424\nf.  937-485-0973\ndavid_stampley@reyrey.com\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu] \nSent: Monday, March 29, 2004 9:48 PM\nTo: Stampley, David A; 'public-p3p-spec'\nSubject: Re: Primary Purpose rev 3-24-04\n\n\nI don't fully understand why we need a separate action and result \nsection. Could these be folded together?\n\nLorrie\n\n\nOn Mar 24, 2004, at 11:08 AM, Stampley, David A wrote:\n\n> Rev. 3/24/2004\n>\n> ?\n>\n> PURPOSE/CURRENT:? Expanded descriptions (select all that apply)Result:?\n>\n>  ?\n>\n> Action:? Acquire data from user (survey, poll, demographics)\n>\n> Action:? Acquire user PII\n>\n> Action:? Acquire user preferences\n>\n> Action:? Provide communications services (email, chat, \n> videoconference, VoIP)\n>\n> Action:? Provide interface of offline user account or relationship\n>\n> Action:? Register or enroll user\n>\n> Action:? Sales\n>\n> Action:? User web search\n>\n> ?\n>\n> Content:? Adult\n>\n> Content:? Charity\n>\n> Content:? Children's interest\n>\n> Content:? Educational\n>\n> Content:? Games, online entertainment, music\n>\n> Content:? General interest (gardening, fashion, etc.)\n>\n> Content:? Health\n>\n> Content:? Health\n>\n> Content:? Merchandise, service\n>\n> Content:? News, current interest\n>\n> Content:? Political\n>\n> Content:? Sweepstakes, coupons\n>\n> ?\n>\n> Result:? Authenticate\n>\n> Result:? Authentication setup\n>\n> Result:? Contact online\n>\n> Result:? Customize online display\n>\n> Result:? Fulfill offline\n>\n> Result:? Fulfill online\n>\n> Result:? Manage user offline account (e.g., bank, credit card)\n>\n> Result:? Manage user online account (e.g., Ebay enrollment)\n>\n> Result:? Purpose fulfilled by current site\n>\n> Result:? Purpose fulfilled by other\n>\n> Result:? Respond offline\n>\n> Result:? Respond online later\n>\n> Result:? Respond online now\n>\n> ?\n>\n> # # #\n>\n>  ?\n>\n> Dave\n>\n> ?\n\n\n\n", "id": "lists-017-8131128"}, {"subject": "Re: proposal to add grouping mechanism to C", "content": "Nice draft!\n\nAm Wednesday 24 March 2004 21:23 verlautbarte Lorrie Cranor :\n> I propose changing it to say:\n> \n\n> policy. However, a site MUST make compact policy statements in good\n> faith. User agents that are unable to obtain enough information from\n\nThis sentence is ambiguous as it can read:\n1/ a site MUST make compact policy statements\n2/ if a site makes compact statements, it has to do so \nin good faith.\n\n> \n> User agents that use compact policies as part of their decision making\n> MUST include a mechanism that allows users to determine that a\n> particular decision was made based on a compact policy and to view\n> that compact policy. However, user agents that provide general\n> information about a site's P3P policies to users MUST use the full P3P\n> policy and MUST NOT use the compact policy for this purpose.\n\nThe first requirement sounds really strange. It is raw access to \nthe tokens as arrived at the user agent. This is normally done \nby experts using telnet or perl tools. But I think this was the consensus \nwe had. We should be clear that it is really only raw access.\n\n> \n> I propose adding a section 4.2.10 Compact STATEMENT\n> \n\n> \n> Section 4.5, fourth paragraph, change MUST to MAY (as in \"All of the\n> purposes, recipients, and categories that appear in multiple\n> statements in a full policy MAY be aggregated in a compact policy....\"\n\nWhy transform? The whole paragraph does not make too much sense \nanymore.\n\nAnother thing is, does P3P 1.1 use mandatory extensions? In this case, \nthe third paragraph is an issue too:\nFull policies that include mandatory extensions MUST NOT be represented \nas compact policies.\n\n> \n> Section 4.6 Transforming a Compact Policy to a P3P Policy should be \n> dropped.\n> \n> \nIn the same direction, 4.7 could be integrated somewhere instead of having \nan own point. I also wonder why we said SHOULD NOT while the above \nindicates that by inference it is supposed to read MUST NOT.\n\n\n\n\n", "id": "lists-017-8141207"}, {"subject": "Re: proposal to add grouping mechanism to C", "content": "On Mar 30, 2004, at 11:11 AM, Rigo Wenning wrote:\n\n> Nice draft!\n>\n> Am Wednesday 24 March 2004 21:23 verlautbarte Lorrie Cranor :\n>> I propose changing it to say:\n>>\n>\n>> policy. However, a site MUST make compact policy statements in good\n>> faith. User agents that are unable to obtain enough information from\n>\n> This sentence is ambiguous as it can read:\n> 1/ a site MUST make compact policy statements\n> 2/ if a site makes compact statements, it has to do so\n> in good faith.\n>\n\nOK, how about:\n\nHowever, if a site makes compact policy statements, it MUST make these \nstatements in good faith.\n\n>>\n>> User agents that use compact policies as part of their decision making\n>> MUST include a mechanism that allows users to determine that a\n>> particular decision was made based on a compact policy and to view\n>> that compact policy. However, user agents that provide general\n>> information about a site's P3P policies to users MUST use the full P3P\n>> policy and MUST NOT use the compact policy for this purpose.\n>\n> The first requirement sounds really strange. It is raw access to\n> the tokens as arrived at the user agent. This is normally done\n> by experts using telnet or perl tools. But I think this was the \n> consensus\n> we had. We should be clear that it is really only raw access.\n\nI don't so much care about whether a user agent gives me an ascii \nstring or whether it formats it in a pretty way, as long as all the \ninformation is there. I think the current wording captures that. In \nwhat way do you think it might be misinterpreted?\n\n>\n>>\n>> I propose adding a section 4.2.10 Compact STATEMENT\n>>\n>\n>>\n>> Section 4.5, fourth paragraph, change MUST to MAY (as in \"All of the\n>> purposes, recipients, and categories that appear in multiple\n>> statements in a full policy MAY be aggregated in a compact policy....\"\n>\n> Why transform? The whole paragraph does not make too much sense\n> anymore.\n\nFor backwards compatibility, the aggregation is still legal. We could \nchange this paragraph to say:\n\nThe P3P 1.0 specification required that all purposes, recipients, and \ncategories that appear in multiple statements in a full policy be \naggregated in a compact policy, as described in section 3.3.1. With the \naddition of the compact STATEMENT element in P3P 1.1, this is no longer \nnecessary, although it is still permitted. When performing the \naggregation, a Web site MUST disclose all relevant tokens (for \ninstance, observe Example 4.1, where multiple retention policies are \nspecified.)\n\n>\n> Another thing is, does P3P 1.1 use mandatory extensions? In this case,\n> the third paragraph is an issue too:\n> Full policies that include mandatory extensions MUST NOT be represented\n> as compact policies.\n\nI believe we only include optional extensions in P3P 1.1. If we used \nmandatory extensions it would introduce backwards compatibility \nproblems.\n\n>\n>>\n>> Section 4.6 Transforming a Compact Policy to a P3P Policy should be\n>> dropped.\n>>\n>>\n> In the same direction, 4.7 could be integrated somewhere instead of \n> having\n> an own point. I also wonder why we said SHOULD NOT while the above\n> indicates that by inference it is supposed to read MUST NOT.\n\n4.7 is entirely repeated as the first paragraph of section 6.4, so I \nthink we could drop 4.7.\n\n(Rigo, here is one typo in 6.4 - a ] that should be removed.)\n\nAt the time we wrote this we agreed to SHOULD NOT. However, I think \nMUST NOT may be appropriate given our other changes. So I would propose \nthat the first paragraph of 6.4 say:\n\nP3P user agents MUST NOT rely on P3P compact policies that do not \ncomply with the P3P 1.0 or P3P 1.1 specifications or are obviously \nerroneous. Such compact policies SHOULD be deemed invalid and the \ncorresponding cookies should be treated as if they had no compact \npolicies. The following guidelines are designed to reduce the chance \nthat a P3P user agent will accept an invalid compact policy.\n\n\n\n", "id": "lists-017-8150343"}, {"subject": "RE: domain relationship", "content": "Here's an attempt to be more explicit:\n\n<p>The <i>OUR-HOST </i>element is declared in the <i>POLICY-REF</i> element.\n\n    For URIs covered by the associated policy, the user agent can encounter\nother \n    hosts in different domains serving embedded content, link, or action\nrequests. \n    The user agent may consider such a host to be owned by the same entity\nor \n    one of its agents if its URI matches an associated <i>OUR-HOST</i>\nentry. \n    Any number of <i>OUR-HOST </i>elements can be declared inside a\n<i>POLICY-REF \n    </i>element.</p>\n  <p>Embedded content is considered to be any content that is retrieved\nduring \n    the processing of the current document, such as images, documents in\nframes, \n    script files, etc. Content embedded more than 1 level deep (e.g. an\nimage \n    inside a frame) is still considered embedded content and the our-host\ndeclarations \n    at the top-level may still apply.</p>\n  <p></p>\n  <p>Any relationships inferred by this mechanism are valid only in the\ncontext \n    for which they were discovered -- this is not a mechanism for declaring\nglobally \n    that two hosts have a relationship in all contexts. By extension, the\nrelationships \n    are not transitive. Suppose two distinct hosts A and C are matched by\n<i>OUR-HOST</i> \n    entries in a policy reference file for host B. Even if the same policy\napplies \n    to both, nothing may be inferred about the relationship between A and C\nfor \n    use in other contexts. The relationships are not transitive even in the\ncase \n    of multi-level embedded content -- the top-level host must declare\nour-host \n    relationships for all levels of embedded content.</p>\n  \nLet me know what you think.\n\n++Jack++\n\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Monday, March 29, 2004 9:50 PM\nTo: Humphrey, Jack\nCc: 'public-p3p-spec'\nSubject: Re: domain relationships\n\n\n\nI think what is not explicit is the types of content to which you can \napply our-host -- that embedded content includes both directly and \nindirectly embedded content. Maybe we need to include some examples \nlike \"images, frames, images embedded in frames, etc.\"\n\nLorrie\n\n\nOn Mar 29, 2004, at 10:32 PM, Humphrey, Jack wrote:\n\n> Does this section of the proposal not clarify it?\n> ---\n> Any relationships inferred by this mechanism are valid only in the \n> context\n> of the policy reference file and policy for which they were discovered \n> --\n> this is not a mechanism for declaring globally that two hosts have a\n> relationship in all contexts. By extension, the relationships are not\n> transitive. Suppose two distinct hosts A and C are matched by OUR-HOST\n> entries in a policy reference file for host B. Even if the same policy\n> applies to both, nothing may be inferred about the relationship \n> between A\n> and C for use in other contexts.\n> ---\n> (I think that first sentence needs to be rephrased: \"in the context for\n> which they were discovered\"?)\n>\n> Brooks, in your example, publisher.com would definitely have to \n> declare both\n> weathersite.com and adserver.com as our-hosts. There is no hierarchy \n> or any\n> kind of transitivity.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Monday, March 29, 2004 8:46 PM\n> To: 'public-p3p-spec'\n> Subject: Re: domain relationships\n>\n>\n>\n> Hmm... interesting question. So, my interpretation of the current\n> proposal is that there are no transitive relationships. If\n> publisher.com declares weathersite.com and adserver.com as our-hosts,\n> then both of them can be treated as first party regardless as to\n> whether they are embedded directly or indirectly. That should probably\n> be made explicit.\n>\n> Lorrie\n>\n>\n> On Mar 29, 2004, at 6:12 PM, Dobbs, Brooks wrote:\n>\n>>\n>>\n>> So something we may still need to clarify, if what we are trying to \n>> get\n>> around here is implementers that have 1st and 3rd party restrictions.\n>> Obviously IE makes some of its own defintions.  One such liberty in \n>> the\n>> whole 1st third party thing is they rely on a \"parent\" request that\n>> determines 1st partyness without ever really defining or even\n>> mentioning\n>> \"parent\".  I think we assume this parent to be the file that returns\n>> HTML that tells the browser to go pull child assets (beacons, images,\n>> iframes, whatever).  IE has the notion that these sub elements can \n>> have\n>> either a 1st or 3rd party relationship with the parent.  I think you\n>> have addressed how *that* relationship can be more expressive, but \n>> does\n>> anything in current P3P talk to the notion of their even being a \n>> parent\n>> asset?\n>>\n>> Imagine the following scenario.\n>>\n>> Weathersite.com declares an our-hosts relationship with adserver.com.\n>> So now when adserver.com serves ads on weathersite.com there is a way\n>> that weathersite.com can communicate that adserver.com should be\n>> treated\n>> as 1st party.\n>>\n>> Imagine however that there is another site publisher.com which embeds\n>> content not only from adserver.com but also from weathersite.com.  \n>> What\n>> is a UA to do?  Is adserver.com an our-host of weathersite.com or of\n>> publisher.com.  Unless there is a definition or hierarchy of parent,\n>> things get messy no?\n>>\n>>\n>> -Brooks\n>>\n>>\n>> -----Original Message-----\n>> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n>> Sent: Monday, March 29, 2004 5:25 PM\n>> To: Dobbs, Brooks\n>> Subject: RE: domain relationships\n>>\n>>\n>> No, Rigo didn't update it. I've attached the latest version again.\n>>\n>> ++Jack++\n>>\n>> -----Original Message-----\n>> From: Dobbs, Brooks\n>> To: Jack Humphrey (JHumphrey@coremetrics.com)\n>> Sent: 3/29/2004 4:06 PM\n>> Subject: domain relationships\n>>\n>> Jack is this the latest version?\n>>\n>>\n>>\n>> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>>\n>>\n>>\n>> Brooks Dobbs\n>>\n>> Director of Privacy Technology\n>>\n>> DoubleClick, Inc.\n>>\n>>\n>>\n>> email: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n>>\n>>\n>>\n>>\n>>\n>>\n>\n\n\n\n\n\ntext/html attachment: 03-domain-relationships-alternate-2.html\n\n\n\n\n", "id": "lists-017-8161569"}, {"subject": "RE: domain relationship", "content": "I don't think that you want it to carry through to multiple levels deep\n- at least from an adserving perspective.\n\nAdserver.com may be an agent of Publisher.com and serve an iframe onto\nPublisher.com but it is totally possible that what is referenced by that\niframe is from agency.com with absolutely no relationship to\npublisher.com.  Also there are often multiple layers of redirection.\n\nSorry, I likely won't be on the call tomorrow.  On a plane to NY - not\nsure if I'll be at the office by 11.\n\n\n-Brooks\n-----Original Message-----\nFrom: public-p3p-spec-request@w3.org\n[mailto:public-p3p-spec-request@w3.org] \nSent: Tuesday, March 30, 2004 5:20 PM\nTo: 'Lorrie Cranor'\nCc: 'public-p3p-spec'\nSubject: RE: domain relationships\n\nHere's an attempt to be more explicit:\n\n<p>The <i>OUR-HOST </i>element is declared in the <i>POLICY-REF</i>\nelement.\n\n    For URIs covered by the associated policy, the user agent can\nencounter\nother\n    hosts in different domains serving embedded content, link, or action\nrequests.\n    The user agent may consider such a host to be owned by the same\nentity\nor\n    one of its agents if its URI matches an associated <i>OUR-HOST</i>\nentry.\n    Any number of <i>OUR-HOST </i>elements can be declared inside a\n<i>POLICY-REF\n    </i>element.</p>\n  <p>Embedded content is considered to be any content that is retrieved\nduring\n    the processing of the current document, such as images, documents in\nframes,\n    script files, etc. Content embedded more than 1 level deep (e.g. an\nimage\n    inside a frame) is still considered embedded content and the\nour-host\ndeclarations\n    at the top-level may still apply.</p>\n  <p></p>\n  <p>Any relationships inferred by this mechanism are valid only in the\ncontext\n    for which they were discovered -- this is not a mechanism for\ndeclaring\nglobally\n    that two hosts have a relationship in all contexts. By extension,\nthe\nrelationships\n    are not transitive. Suppose two distinct hosts A and C are matched\nby\n<i>OUR-HOST</i>\n    entries in a policy reference file for host B. Even if the same\npolicy\napplies\n    to both, nothing may be inferred about the relationship between A\nand C\nfor\n    use in other contexts. The relationships are not transitive even in\nthe\ncase\n    of multi-level embedded content -- the top-level host must declare\nour-host\n    relationships for all levels of embedded content.</p>\n\nLet me know what you think.\n\n++Jack++\n\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Monday, March 29, 2004 9:50 PM\nTo: Humphrey, Jack\nCc: 'public-p3p-spec'\nSubject: Re: domain relationships\n\n\n\nI think what is not explicit is the types of content to which you can\napply our-host -- that embedded content includes both directly and\nindirectly embedded content. Maybe we need to include some examples\nlike \"images, frames, images embedded in frames, etc.\"\n\nLorrie\n\n\nOn Mar 29, 2004, at 10:32 PM, Humphrey, Jack wrote:\n\n> Does this section of the proposal not clarify it?\n> ---\n> Any relationships inferred by this mechanism are valid only in the\n> context\n> of the policy reference file and policy for which they were discovered\n> --\n> this is not a mechanism for declaring globally that two hosts have a\n> relationship in all contexts. By extension, the relationships are not\n> transitive. Suppose two distinct hosts A and C are matched by OUR-HOST\n> entries in a policy reference file for host B. Even if the same policy\n> applies to both, nothing may be inferred about the relationship\n> between A\n> and C for use in other contexts.\n> ---\n> (I think that first sentence needs to be rephrased: \"in the context\nfor\n> which they were discovered\"?)\n>\n> Brooks, in your example, publisher.com would definitely have to\n> declare both\n> weathersite.com and adserver.com as our-hosts. There is no hierarchy\n> or any\n> kind of transitivity.\n>\n> ++Jack++\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Monday, March 29, 2004 8:46 PM\n> To: 'public-p3p-spec'\n> Subject: Re: domain relationships\n>\n>\n>\n> Hmm... interesting question. So, my interpretation of the current\n> proposal is that there are no transitive relationships. If\n> publisher.com declares weathersite.com and adserver.com as our-hosts,\n> then both of them can be treated as first party regardless as to\n> whether they are embedded directly or indirectly. That should probably\n> be made explicit.\n>\n> Lorrie\n>\n>\n> On Mar 29, 2004, at 6:12 PM, Dobbs, Brooks wrote:\n>\n>>\n>>\n>> So something we may still need to clarify, if what we are trying to\n>> get\n>> around here is implementers that have 1st and 3rd party restrictions.\n>> Obviously IE makes some of its own defintions.  One such liberty in\n>> the\n>> whole 1st third party thing is they rely on a \"parent\" request that\n>> determines 1st partyness without ever really defining or even\n>> mentioning\n>> \"parent\".  I think we assume this parent to be the file that returns\n>> HTML that tells the browser to go pull child assets (beacons, images,\n>> iframes, whatever).  IE has the notion that these sub elements can\n>> have\n>> either a 1st or 3rd party relationship with the parent.  I think you\n>> have addressed how *that* relationship can be more expressive, but\n>> does\n>> anything in current P3P talk to the notion of their even being a\n>> parent\n>> asset?\n>>\n>> Imagine the following scenario.\n>>\n>> Weathersite.com declares an our-hosts relationship with adserver.com.\n>> So now when adserver.com serves ads on weathersite.com there is a way\n>> that weathersite.com can communicate that adserver.com should be\n>> treated\n>> as 1st party.\n>>\n>> Imagine however that there is another site publisher.com which embeds\n>> content not only from adserver.com but also from weathersite.com.\n>> What\n>> is a UA to do?  Is adserver.com an our-host of weathersite.com or of\n>> publisher.com.  Unless there is a definition or hierarchy of parent,\n>> things get messy no?\n>>\n>>\n>> -Brooks\n>>\n>>\n>> -----Original Message-----\n>> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n>> Sent: Monday, March 29, 2004 5:25 PM\n>> To: Dobbs, Brooks\n>> Subject: RE: domain relationships\n>>\n>>\n>> No, Rigo didn't update it. I've attached the latest version again.\n>>\n>> ++Jack++\n>>\n>> -----Original Message-----\n>> From: Dobbs, Brooks\n>> To: Jack Humphrey (JHumphrey@coremetrics.com)\n>> Sent: 3/29/2004 4:06 PM\n>> Subject: domain relationships\n>>\n>> Jack is this the latest version?\n>>\n>>\n>>\n>> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>>\n>>\n>>\n>> Brooks Dobbs\n>>\n>> Director of Privacy Technology\n>>\n>> DoubleClick, Inc.\n>>\n>>\n>>\n>> email: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n>>\n>>\n>>\n>>\n>>\n>>\n>\n\n\n\n", "id": "lists-017-8177706"}, {"subject": "Re: domain relationship", "content": "On Mar 30, 2004, at 5:30 PM, Dobbs, Brooks wrote:\n\n>\n> I don't think that you want it to carry through to multiple levels deep\n> - at least from an adserving perspective.\n>\n> Adserver.com may be an agent of Publisher.com and serve an iframe onto\n> Publisher.com but it is totally possible that what is referenced by \n> that\n> iframe is from agency.com with absolutely no relationship to\n> publisher.com.  Also there are often multiple layers of redirection.\n\nYou only carry through to multiple levels the hosts referenced in an \nour-host tag. So in your example, if there is no relationship with \nagency.com then they wouldn't be mentioned in the our-host tag. So I \nthink this works.\n\nLorrie\n\n\n>\n> Sorry, I likely won't be on the call tomorrow.  On a plane to NY - not\n> sure if I'll be at the office by 11.\n>\n>\n> -Brooks\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org\n> [mailto:public-p3p-spec-request@w3.org]\n> Sent: Tuesday, March 30, 2004 5:20 PM\n> To: 'Lorrie Cranor'\n> Cc: 'public-p3p-spec'\n> Subject: RE: domain relationships\n>\n> Here's an attempt to be more explicit:\n>\n> <p>The <i>OUR-HOST </i>element is declared in the <i>POLICY-REF</i>\n> element.\n>\n>     For URIs covered by the associated policy, the user agent can\n> encounter\n> other\n>     hosts in different domains serving embedded content, link, or \n> action\n> requests.\n>     The user agent may consider such a host to be owned by the same\n> entity\n> or\n>     one of its agents if its URI matches an associated <i>OUR-HOST</i>\n> entry.\n>     Any number of <i>OUR-HOST </i>elements can be declared inside a\n> <i>POLICY-REF\n>     </i>element.</p>\n>   <p>Embedded content is considered to be any content that is retrieved\n> during\n>     the processing of the current document, such as images, documents \n> in\n> frames,\n>     script files, etc. Content embedded more than 1 level deep (e.g. an\n> image\n>     inside a frame) is still considered embedded content and the\n> our-host\n> declarations\n>     at the top-level may still apply.</p>\n>   <p></p>\n>   <p>Any relationships inferred by this mechanism are valid only in the\n> context\n>     for which they were discovered -- this is not a mechanism for\n> declaring\n> globally\n>     that two hosts have a relationship in all contexts. By extension,\n> the\n> relationships\n>     are not transitive. Suppose two distinct hosts A and C are matched\n> by\n> <i>OUR-HOST</i>\n>     entries in a policy reference file for host B. Even if the same\n> policy\n> applies\n>     to both, nothing may be inferred about the relationship between A\n> and C\n> for\n>     use in other contexts. The relationships are not transitive even in\n> the\n> case\n>     of multi-level embedded content -- the top-level host must declare\n> our-host\n>     relationships for all levels of embedded content.</p>\n>\n> Let me know what you think.\n>\n> ++Jack++\n>\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Monday, March 29, 2004 9:50 PM\n> To: Humphrey, Jack\n> Cc: 'public-p3p-spec'\n> Subject: Re: domain relationships\n>\n>\n>\n> I think what is not explicit is the types of content to which you can\n> apply our-host -- that embedded content includes both directly and\n> indirectly embedded content. Maybe we need to include some examples\n> like \"images, frames, images embedded in frames, etc.\"\n>\n> Lorrie\n>\n>\n> On Mar 29, 2004, at 10:32 PM, Humphrey, Jack wrote:\n>\n>> Does this section of the proposal not clarify it?\n>> ---\n>> Any relationships inferred by this mechanism are valid only in the\n>> context\n>> of the policy reference file and policy for which they were discovered\n>> --\n>> this is not a mechanism for declaring globally that two hosts have a\n>> relationship in all contexts. By extension, the relationships are not\n>> transitive. Suppose two distinct hosts A and C are matched by OUR-HOST\n>> entries in a policy reference file for host B. Even if the same policy\n>> applies to both, nothing may be inferred about the relationship\n>> between A\n>> and C for use in other contexts.\n>> ---\n>> (I think that first sentence needs to be rephrased: \"in the context\n> for\n>> which they were discovered\"?)\n>>\n>> Brooks, in your example, publisher.com would definitely have to\n>> declare both\n>> weathersite.com and adserver.com as our-hosts. There is no hierarchy\n>> or any\n>> kind of transitivity.\n>>\n>> ++Jack++\n>>\n>> -----Original Message-----\n>> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n>> Sent: Monday, March 29, 2004 8:46 PM\n>> To: 'public-p3p-spec'\n>> Subject: Re: domain relationships\n>>\n>>\n>>\n>> Hmm... interesting question. So, my interpretation of the current\n>> proposal is that there are no transitive relationships. If\n>> publisher.com declares weathersite.com and adserver.com as our-hosts,\n>> then both of them can be treated as first party regardless as to\n>> whether they are embedded directly or indirectly. That should probably\n>> be made explicit.\n>>\n>> Lorrie\n>>\n>>\n>> On Mar 29, 2004, at 6:12 PM, Dobbs, Brooks wrote:\n>>\n>>>\n>>>\n>>> So something we may still need to clarify, if what we are trying to\n>>> get\n>>> around here is implementers that have 1st and 3rd party restrictions.\n>>> Obviously IE makes some of its own defintions.  One such liberty in\n>>> the\n>>> whole 1st third party thing is they rely on a \"parent\" request that\n>>> determines 1st partyness without ever really defining or even\n>>> mentioning\n>>> \"parent\".  I think we assume this parent to be the file that returns\n>>> HTML that tells the browser to go pull child assets (beacons, images,\n>>> iframes, whatever).  IE has the notion that these sub elements can\n>>> have\n>>> either a 1st or 3rd party relationship with the parent.  I think you\n>>> have addressed how *that* relationship can be more expressive, but\n>>> does\n>>> anything in current P3P talk to the notion of their even being a\n>>> parent\n>>> asset?\n>>>\n>>> Imagine the following scenario.\n>>>\n>>> Weathersite.com declares an our-hosts relationship with adserver.com.\n>>> So now when adserver.com serves ads on weathersite.com there is a way\n>>> that weathersite.com can communicate that adserver.com should be\n>>> treated\n>>> as 1st party.\n>>>\n>>> Imagine however that there is another site publisher.com which embeds\n>>> content not only from adserver.com but also from weathersite.com.\n>>> What\n>>> is a UA to do?  Is adserver.com an our-host of weathersite.com or of\n>>> publisher.com.  Unless there is a definition or hierarchy of parent,\n>>> things get messy no?\n>>>\n>>>\n>>> -Brooks\n>>>\n>>>\n>>> -----Original Message-----\n>>> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n>>> Sent: Monday, March 29, 2004 5:25 PM\n>>> To: Dobbs, Brooks\n>>> Subject: RE: domain relationships\n>>>\n>>>\n>>> No, Rigo didn't update it. I've attached the latest version again.\n>>>\n>>> ++Jack++\n>>>\n>>> -----Original Message-----\n>>> From: Dobbs, Brooks\n>>> To: Jack Humphrey (JHumphrey@coremetrics.com)\n>>> Sent: 3/29/2004 4:06 PM\n>>> Subject: domain relationships\n>>>\n>>> Jack is this the latest version?\n>>>\n>>>\n>>>\n>>> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>>>\n>>>\n>>>\n>>> Brooks Dobbs\n>>>\n>>> Director of Privacy Technology\n>>>\n>>> DoubleClick, Inc.\n>>>\n>>>\n>>>\n>>> email: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n>>>\n>>>\n>>>\n>>>\n>>>\n>>>\n>>\n>\n\n\n\n", "id": "lists-017-8194934"}, {"subject": "RE: domain relationship", "content": "Yep. What Lorrie said. :)\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Tuesday, March 30, 2004 8:47 PM\nTo: Dobbs, Brooks\nCc: public-p3p-spec\nSubject: Re: domain relationships\n\n\n\n\nOn Mar 30, 2004, at 5:30 PM, Dobbs, Brooks wrote:\n\n>\n> I don't think that you want it to carry through to multiple levels deep\n> - at least from an adserving perspective.\n>\n> Adserver.com may be an agent of Publisher.com and serve an iframe onto\n> Publisher.com but it is totally possible that what is referenced by \n> that\n> iframe is from agency.com with absolutely no relationship to\n> publisher.com.  Also there are often multiple layers of redirection.\n\nYou only carry through to multiple levels the hosts referenced in an \nour-host tag. So in your example, if there is no relationship with \nagency.com then they wouldn't be mentioned in the our-host tag. So I \nthink this works.\n\nLorrie\n\n\n>\n> Sorry, I likely won't be on the call tomorrow.  On a plane to NY - not\n> sure if I'll be at the office by 11.\n>\n>\n> -Brooks\n> -----Original Message-----\n> From: public-p3p-spec-request@w3.org\n> [mailto:public-p3p-spec-request@w3.org]\n> Sent: Tuesday, March 30, 2004 5:20 PM\n> To: 'Lorrie Cranor'\n> Cc: 'public-p3p-spec'\n> Subject: RE: domain relationships\n>\n> Here's an attempt to be more explicit:\n>\n> <p>The <i>OUR-HOST </i>element is declared in the <i>POLICY-REF</i>\n> element.\n>\n>     For URIs covered by the associated policy, the user agent can\n> encounter\n> other\n>     hosts in different domains serving embedded content, link, or \n> action\n> requests.\n>     The user agent may consider such a host to be owned by the same\n> entity\n> or\n>     one of its agents if its URI matches an associated <i>OUR-HOST</i>\n> entry.\n>     Any number of <i>OUR-HOST </i>elements can be declared inside a\n> <i>POLICY-REF\n>     </i>element.</p>\n>   <p>Embedded content is considered to be any content that is retrieved\n> during\n>     the processing of the current document, such as images, documents \n> in\n> frames,\n>     script files, etc. Content embedded more than 1 level deep (e.g. an\n> image\n>     inside a frame) is still considered embedded content and the\n> our-host\n> declarations\n>     at the top-level may still apply.</p>\n>   <p></p>\n>   <p>Any relationships inferred by this mechanism are valid only in the\n> context\n>     for which they were discovered -- this is not a mechanism for\n> declaring\n> globally\n>     that two hosts have a relationship in all contexts. By extension,\n> the\n> relationships\n>     are not transitive. Suppose two distinct hosts A and C are matched\n> by\n> <i>OUR-HOST</i>\n>     entries in a policy reference file for host B. Even if the same\n> policy\n> applies\n>     to both, nothing may be inferred about the relationship between A\n> and C\n> for\n>     use in other contexts. The relationships are not transitive even in\n> the\n> case\n>     of multi-level embedded content -- the top-level host must declare\n> our-host\n>     relationships for all levels of embedded content.</p>\n>\n> Let me know what you think.\n>\n> ++Jack++\n>\n>\n> -----Original Message-----\n> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n> Sent: Monday, March 29, 2004 9:50 PM\n> To: Humphrey, Jack\n> Cc: 'public-p3p-spec'\n> Subject: Re: domain relationships\n>\n>\n>\n> I think what is not explicit is the types of content to which you can\n> apply our-host -- that embedded content includes both directly and\n> indirectly embedded content. Maybe we need to include some examples\n> like \"images, frames, images embedded in frames, etc.\"\n>\n> Lorrie\n>\n>\n> On Mar 29, 2004, at 10:32 PM, Humphrey, Jack wrote:\n>\n>> Does this section of the proposal not clarify it?\n>> ---\n>> Any relationships inferred by this mechanism are valid only in the\n>> context\n>> of the policy reference file and policy for which they were discovered\n>> --\n>> this is not a mechanism for declaring globally that two hosts have a\n>> relationship in all contexts. By extension, the relationships are not\n>> transitive. Suppose two distinct hosts A and C are matched by OUR-HOST\n>> entries in a policy reference file for host B. Even if the same policy\n>> applies to both, nothing may be inferred about the relationship\n>> between A\n>> and C for use in other contexts.\n>> ---\n>> (I think that first sentence needs to be rephrased: \"in the context\n> for\n>> which they were discovered\"?)\n>>\n>> Brooks, in your example, publisher.com would definitely have to\n>> declare both\n>> weathersite.com and adserver.com as our-hosts. There is no hierarchy\n>> or any\n>> kind of transitivity.\n>>\n>> ++Jack++\n>>\n>> -----Original Message-----\n>> From: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\n>> Sent: Monday, March 29, 2004 8:46 PM\n>> To: 'public-p3p-spec'\n>> Subject: Re: domain relationships\n>>\n>>\n>>\n>> Hmm... interesting question. So, my interpretation of the current\n>> proposal is that there are no transitive relationships. If\n>> publisher.com declares weathersite.com and adserver.com as our-hosts,\n>> then both of them can be treated as first party regardless as to\n>> whether they are embedded directly or indirectly. That should probably\n>> be made explicit.\n>>\n>> Lorrie\n>>\n>>\n>> On Mar 29, 2004, at 6:12 PM, Dobbs, Brooks wrote:\n>>\n>>>\n>>>\n>>> So something we may still need to clarify, if what we are trying to\n>>> get\n>>> around here is implementers that have 1st and 3rd party restrictions.\n>>> Obviously IE makes some of its own defintions.  One such liberty in\n>>> the\n>>> whole 1st third party thing is they rely on a \"parent\" request that\n>>> determines 1st partyness without ever really defining or even\n>>> mentioning\n>>> \"parent\".  I think we assume this parent to be the file that returns\n>>> HTML that tells the browser to go pull child assets (beacons, images,\n>>> iframes, whatever).  IE has the notion that these sub elements can\n>>> have\n>>> either a 1st or 3rd party relationship with the parent.  I think you\n>>> have addressed how *that* relationship can be more expressive, but\n>>> does\n>>> anything in current P3P talk to the notion of their even being a\n>>> parent\n>>> asset?\n>>>\n>>> Imagine the following scenario.\n>>>\n>>> Weathersite.com declares an our-hosts relationship with adserver.com.\n>>> So now when adserver.com serves ads on weathersite.com there is a way\n>>> that weathersite.com can communicate that adserver.com should be\n>>> treated\n>>> as 1st party.\n>>>\n>>> Imagine however that there is another site publisher.com which embeds\n>>> content not only from adserver.com but also from weathersite.com.\n>>> What\n>>> is a UA to do?  Is adserver.com an our-host of weathersite.com or of\n>>> publisher.com.  Unless there is a definition or hierarchy of parent,\n>>> things get messy no?\n>>>\n>>>\n>>> -Brooks\n>>>\n>>>\n>>> -----Original Message-----\n>>> From: Humphrey, Jack [mailto:JHumphrey@coremetrics.com]\n>>> Sent: Monday, March 29, 2004 5:25 PM\n>>> To: Dobbs, Brooks\n>>> Subject: RE: domain relationships\n>>>\n>>>\n>>> No, Rigo didn't update it. I've attached the latest version again.\n>>>\n>>> ++Jack++\n>>>\n>>> -----Original Message-----\n>>> From: Dobbs, Brooks\n>>> To: Jack Humphrey (JHumphrey@coremetrics.com)\n>>> Sent: 3/29/2004 4:06 PM\n>>> Subject: domain relationships\n>>>\n>>> Jack is this the latest version?\n>>>\n>>>\n>>>\n>>> http://www.w3.org/P3P/2004/03-domain-relationships.html\n>>>\n>>>\n>>>\n>>> Brooks Dobbs\n>>>\n>>> Director of Privacy Technology\n>>>\n>>> DoubleClick, Inc.\n>>>\n>>>\n>>>\n>>> email: bdobbs@doubleclick.net <mailto:bdobbs@doubleclick.net>\n>>>\n>>>\n>>>\n>>>\n>>>\n>>>\n>>\n>\n\n\n\n", "id": "lists-017-8212775"}, {"subject": "RE: Primary Purpose rev 3-240", "content": "\"Content\" is the site's designation of the subject-matter component of it's\nprimary purpose.  \n\nI.e., a site might indicate that one of its primary purposes is to: ACQUIRE\nUSER PII to AUTHENTICATE THE USER and FULFILL ONLINE the user's request for\nGAMING content. \n\nDave Stampley\nv.  937-485-0424\nf.  937-485-0973\ndavid_stampley@reyrey.com\n-----Original Message-----\nFrom: Rigo Wenning [mailto:rigo@w3.org] \nSent: Tuesday, March 30, 2004 9:24 AM\nTo: public-p3p-spec@w3.org\nSubject: Re: Primary Purpose rev 3-24-04\n\nAm Tuesday 30 March 2004 04:47 verlautbarte Lorrie Cranor :\n> \n> I don't fully understand why we need a separate action and result \n> section. Could these be folded together?\n\nI don't understand that either. I additionally don't understand the \ncontent class. Is this content received or content sent? If it is content \nreceived, this is out of scope of P3P. If it is content sent, it duplicates\nthe base dataschema.\n\nCan somebody help?\n\nRigo\n\n\n\n", "id": "lists-017-8231808"}, {"subject": "[Minutes] 31 March P3P Spec cal", "content": "Minutes of the P3P specification group conference call on\nWednesday, March 31, 2004, 11 am - 12 pm US Eastern. \n\n\nPresent:\nLorrie Cranor\nJack Humphrey\nRigo Wenning\nDave Stampley\n\n\n1. Agent and domain relationships\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0034.html\n\nConsensus is to adopt the latest draft and put it into our \nnext working draft. To object, people can object until Friday\n02 April 2004. Otherwise this will be accepted.\n\n\n2. Primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[please send comments BEFORE the call]\n\nDiscussion on David's proposal:\nContent can expressed as category or data items in statements\nDifferent statements can have different primary purposes, so \nno need for more than one primary purpose per statement.\nDifferent statements can be grouped with the grouping \nmechanism to constitute an assembly that reflects the \nactual web-site.\n \nHorizont should be the declaration of the site: I collect \nthis data and I'm telling you what I'm going to do with \nit. Dave called this actions upon data or content. See above, \nthis can be already expressed with the dataschema.\n\nACTION Dave: Bring up new list of actions as a first model \nfor questions to the wider community.\n\n\n3. Grouping mechanism proposal\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0036.html\n[If you have comments, please send them BEFORE the call. Unless there \nare objections raised prior to the call we will plan to approve this \nproposal on the call.]\n\nconsensus is to adopt Lorries proposal as attached to \nbugzilla item 642.\nhttp://www.w3.org/Bugs/Public/show_bug.cgi?id=642\n\n\n\n4. P3P Generic attribute for XML applications\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Feb/0019.html\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0003.html\n\n5. Discuss publication of next public working draft (by April 9?) and \nlast call\n  - what is left to do?\n    - need to resolve above items\n    - need to determine who to list as authors\n    - have art 10 stuff been added to working draft or is there more to do?\n    - Giles, what about the schema stuff?\n    - is there anything else from P3P beyond HTTP that we need to \n      include?\n      \nhttp://www.w3.org/Bugs/Public/buglist.cgi?short_desc_type=allwordssubstr&short_desc=&product=P3P&long_desc_type=allwordssubstr&long_desc=&bug_file_loc_type=allwordssubstr&bug_file_loc=&keywords_type=allwords&keywords=&bug_status=UNCONFIRMED&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED&emailassigned_to1=1&emailtype1=substring&email1=&emailassigned_to2=1&emailreporter2=1&emailcc2=1&emailtype2=substring&email2=&bugidtype=include&bug_id=&votes=&changedin=&chfieldfrom=&chfieldto=Now&chfieldvalue=&cmdtype=doit&order=Bug+Number&field0-0-0=noop&type0-0-0=noop&value0-0-0=\n\nBug 171: Rigo has no record of consensus\nACTION Lorrie: find traces of consensus\n\nBug 174: Already resolved\nACTION Lorrie update Bugzilla\n\nQuestion for Giles: Where are we with Schema's Stuff. Giles mentioned \nsomething could be ready in two weeks. \n\nP3P beyond HTTP\nonly issue left is WSDL and rewording generic attribute \nACTION Rigo: Explain the team-note and project about WSDL\n\nSigned Policies:\nAction Rigo: Open Bugzilla item to explain rejection of \nsigned policies. to be completed after entry into last call.\n\n6. Set date/time for next call (April 7?)\nNext call on 7 April\n\n\n\n\n", "id": "lists-017-8240141"}, {"subject": "PPurpose 5-304a.do", "content": "I'm stuck. I can't see usefulness of list of 20-30 sentences the purport to\ncover most primary purposes.\nMy proposal is to allow Primary Purpose to include a free-form text field.\nAlternative:  Rely on Consequence + Categories\nPurpose of the attached chart, however, is to provide a vocabulary for\nmachine-readable statements that get to the material details of the\nuser-to-site dynamic, e.g.:\n \nDave\n\n\n\n\n\napplication/msword attachment: PPurpose_5-3-04a.doc\n\n\n\n\n", "id": "lists-017-8301226"}, {"subject": "[Minutes]: MONDAY 3 May P3P spec cal", "content": "Present:\n\nLorrie Cranor\nRigo Wenning\nBrooks Dobbs\nDave Stampley\n\n\n1. P3P Generic attribute for XML applications - discuss draft and what \nto do about RDF binding.\n[if Rigo has anything new to report]\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Apr/0012.html\n\nFabien will come back in 2 weeks and Rigo will discuss with \nhim. \nAction: Lorrie: Changing XML attrib to mention the RDF Note\n\n\n2. primary purpose specification\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004Mar/0035.html\n[Dave please send revised draft]\n\nLorrie called Dave and reported. Yet gone to another direction. \nLorrie presented that direction. Dave tries to put the assertions\nin a sentence of eight parts. \n\na. EU wants primary purpose (principle of finality)\nb. useful to have a human readable statement\nc. useful to have a computer readable statement\n\nConclusion is that the direction of eight parts is not okay. We only \nneed to have the verbs.\n\nSo just come down with the list here. \n\nSales \nproducts\nservices\n\nbanking and financial management\n\nregistration subscription (account management) reservations\n\nadvertising marketing promotion\n\neducation \n\ngaming\n\ngambling\n\ninformation\n\nart\n\nfeedback\n\npayment\n\nAction: Lorrie send list to mailing-list\n\n\n3. XML schema stuff\n[Giles to send draft and any questions group needs to consider)\n\nNot enough time..\n\n4. Schedule next call (May 12?)\n\nNext call is May 12!\n\n\nScribe:\n\nRigo\n\n\n\n\n", "id": "lists-017-8308095"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "Thanks for these comments Mark. A few thoughts...\n\nOn Apr 26, 2004, at 2:52 AM, Mark Nottingham wrote:\n\n> To clarify my thoughts a bit, I think there are two interesting things \n> to specify;\n>   1) who will conform to the policy\n>   2) what data the policy applies to\n>\n> In P3P 1.0, #1 was always the Web site, and #2 was data submitted to \n> the Web site, as laid out by the various policy reference mechanisms, \n> etc.\n>\n> When I made the distinction between interfaces and data, I think that \n> what I was trying to say (and hadn't fully thought through) was that \n> in P3P 1.0, #2 is always in relation to an interface, as identified by \n> a URI; ultimately, the policy still applies to data. This effort, as I \n> see it, is to allow greater flexibility in specifying #2, because of \n> that.\n>\n> So,\n>\n>> P3P 1.0 was designed to associate XML-encoded privacy policies with \n>> URIs,  sets of URIs, or cookies. P3P 1.0 it well suited for use with \n>> HTML  and XHTML content transmitted over [HTTP] .\n>\n> I think this would be better stated as:\n>\n>> P3P 1.0 was designed to associate XML-encoded privacy policies with \n>> data submitted to Web resources, which are identified by URIs or \n>> bound to cookies.\n\nI think the word \"submitted\" is too limiting, as P3P also covers log \ndata that is created as a result of a transaction but might not really \nbe considered to be submitted, as well as data collected by client-side \nscripts. I also think we really are binding a policy to a URI, or maybe \na policy to a URI and all the data associated with it? I  would be \nhappy with:\n\nP3P 1.0 was designed to associate XML-encoded privacy policies with Web \nresources, which are identified by URIs or bound to cookies.\n\n\n>\n> I.e., P3P tells you how a site will handle the data (e.g., form \n> fields, HTTP headers, TCP/IP connection information) sent to a \n> particular interface, which is identified by a URI. The data itself is \n> NOT identified by this URI; there's been talk at the TAG about how you \n> identify the data in a POST, for example; it's clearly separate from \n> the resource identifier.\n>\n> P3P 1.0 also allows you to refine by method, etc., which I think \n> supports this view.\n>\n> If that's the case, this:\n>\n>> However,  P3P 1.0 cannot be used in situations where content is not \n>> associated  with a URI, for example, some applications of Web \n>> Services and XMLP/Soap. In addition,  P3P 1.0 cannot be used in \n>> situations where policies apply to only a  subset of the content \n>> associated with a given URI. For example,  while P3P 1.0 can be used \n>> to apply a P3P policy to an entire form  specified by XForms, it  \n>> cannot be used to apply the policy to only a single form field.\n>>\n>> The P3P 1.1 Specification provides a new binding mechanism to  allow \n>> for increased granularity beyond the URI level and to allow  policies \n>> to apply to content not associated with a URI.\n>\n> should be something like:\n>\n>> However, P3P 1.0's mechanisms for identifying the target data for \n>> privacy policies are limited; in general, they only allow one to \n>> identify data submitted to a Web resource, and only on the \n>> granularity of an entire message (e.g., a HTTP request). In some \n>> cases, this is not sufficient; for example while P3P 1.0 can be used \n>> to apply a P3P policy to an entire form specified by XForms, it \n>> cannot be used to apply the policy to a single field on that form.\n>>\n>> To allow for increased granularity, as well as for situations when \n>> content is not identified with a URI, the P3P 1.1 specification \n>> provides a new mechanism for associating policy with data in \n>> XML-based resource description languages such as WSDL and XForms.\n\nI think something like that is ok.\n\n>\n> and so forth.\n>\n> I think you also need to require people who use this attribute in \n> their formats to explicitly identify who is required to conform to the \n> policy (#1).\n\nWouldn't that be covered by the ENTITY element? Or are you thinking of \nsomething beyond that?\n\nLorrie\n\n\n\n", "id": "lists-017-8315915"}, {"subject": "primary purpose lis", "content": "Based on our discussion today, here is a very rough proposed list of \nprimary purposes.\n\nWe need to first decide if this approach generally makes sense (as \nopposed to say the proposal Dave sent out earlier today). If so, we \nneed to refine this list (what's missing, what should be folded \ntogether, etc.) and then produce for each item a) an XML token b) a \ndefinition c) a short human-readable description. I would propose that \nthe primary purpose extension allow sites to list one or more of these \ntokens and a human-readable description.\n\nI think this is the largest piece of work remaining before we can take \nP3P 1.1 to last call, so let's get on with it... please review and send \nyour comments to the mailing list.\n\n\n\nsales of products or services\n\ncharitable donations [do we want to group this with sales for a\ngeneric transactions category?]\n\npayments and transaction facilitation [do we want to group this with\nsales as above?]\n\norder fulfillment and delivery\n\nbanking and financial management\n\nregistration, enrollment, subscription, reservations, account\nmanagement [are we bundling too many thngs together here?]\n\neducation - including dissemination of educational materials, testing,\n   grading, interactions with teachers or other students, etc.\n\ngaming\n\ngambling\n\nentertainment\n\narts and literature [could this be combined with entertainment?]\n\nnews and information\n\ncommunications services\n\nsearch\n\nsurveys\n\nauthentication\n\ngovernment services (e-government)\n\ncustomizing online experience\n\ndistributing content (serving pages)\n\nrespond to user\n\nadvertising, marketing, and promotion\n\nstate management\n\n\n\n", "id": "lists-017-8327767"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "Hi Lorrie,\n\n>> P3P 1.0 was designed to associate XML-encoded privacy policies with \n>> data submitted to Web resources, which are identified by URIs or \n>> bound to cookies.\n>\n> I think the word \"submitted\" is too limiting, as P3P also covers log \n> data that is created as a result of a transaction but might not really \n> be considered to be submitted, as well as data collected by \n> client-side scripts. I also think we really are binding a policy to a \n> URI, or maybe a policy to a URI and all the data associated with it? I \n>  would be happy with:\n>\n> P3P 1.0 was designed to associate XML-encoded privacy policies with \n> Web resources, which are identified by URIs or bound to cookies.\n\nLog data is sourced from aspects of the request (e.g., IP address, \nreferer header, etc.), so it's still targeted at the incoming data. How \nabout:\n\nP3P 1.0 was designed to associated XML-encoded privacy policies with \ndata collected by Web resources, which are identified by URIs or bound \nto cookies.\n\n?\n\n>> However, P3P 1.0's mechanisms for identifying the target data for \n>> privacy policies are limited; in general, they only allow one to \n>> identify data submitted to a Web resource, and only on the \n>> granularity of an entire message (e.g., a HTTP request). In some \n>> cases, this is not sufficient; for example while P3P 1.0 can be used \n>> to apply a P3P policy to an entire form specified by XForms, it \n>> cannot be used to apply the policy to a single field on that form.\n>>\n>> To allow for increased granularity, as well as for situations when \n>> content is not identified with a URI, the P3P 1.1 specification \n>> provides a new mechanism for associating policy with data in \n>> XML-based resource description languages such as WSDL and XForms.\n>\n> I think something like that is ok.\n\nGiven the above, it might need some tweaking in the second clause half \nof the first sentence; perhaps\n\n... in general, they only allow one to identify data associated with \nHTTP requests, and only on the granularity of an entire message.\n\n\n>> I think you also need to require people who use this attribute in \n>> their formats to explicitly identify who is required to conform to \n>> the policy (#1).\n>\n> Wouldn't that be covered by the ENTITY element? Or are you thinking of \n> something beyond that?\n\nAh, yes; that should do it. Does ENTITY have some mechanism for \nidentifying an anonymous party (e.g., \"Anyone I send THIS message to me \nMUST conform to this privacy policy)? I'd imagine there are cases where \npeople using this attribute won't want to explicitly enumerate the \nentity responsible for conforming to the policy.\n\nRegards,\n\n--\nMark Nottingham   Principal Technologist\nOffice of the CTO   BEA Systems\n\n\n\n", "id": "lists-017-8336105"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "On May 3, 2004, at 6:51 PM, Mark Nottingham wrote:\n\n> Hi Lorrie,\n>\n>>> P3P 1.0 was designed to associate XML-encoded privacy policies with \n>>> data submitted to Web resources, which are identified by URIs or \n>>> bound to cookies.\n>>\n>> I think the word \"submitted\" is too limiting, as P3P also covers log \n>> data that is created as a result of a transaction but might not \n>> really be considered to be submitted, as well as data collected by \n>> client-side scripts. I also think we really are binding a policy to a \n>> URI, or maybe a policy to a URI and all the data associated with it? \n>> I  would be happy with:\n>>\n>> P3P 1.0 was designed to associate XML-encoded privacy policies with \n>> Web resources, which are identified by URIs or bound to cookies.\n>\n> Log data is sourced from aspects of the request (e.g., IP address, \n> referer header, etc.), so it's still targeted at the incoming data. \n> How about:\n>\n> P3P 1.0 was designed to associated XML-encoded privacy policies with \n> data collected by Web resources, which are identified by URIs or bound \n> to cookies.\n>\n> ?\n\n\nHmm... I'm still pondering whether it is accurate to say that P3P binds \na policy to data as opposed to binding a policy to a URI. I'm hoping \nothers will weigh in on this.\n\n>\n>>> However, P3P 1.0's mechanisms for identifying the target data for \n>>> privacy policies are limited; in general, they only allow one to \n>>> identify data submitted to a Web resource, and only on the \n>>> granularity of an entire message (e.g., a HTTP request). In some \n>>> cases, this is not sufficient; for example while P3P 1.0 can be used \n>>> to apply a P3P policy to an entire form specified by XForms, it \n>>> cannot be used to apply the policy to a single field on that form.\n>>>\n>>> To allow for increased granularity, as well as for situations when \n>>> content is not identified with a URI, the P3P 1.1 specification \n>>> provides a new mechanism for associating policy with data in \n>>> XML-based resource description languages such as WSDL and XForms.\n>>\n>> I think something like that is ok.\n>\n> Given the above, it might need some tweaking in the second clause half \n> of the first sentence; perhaps\n>\n> ... in general, they only allow one to identify data associated with \n> HTTP requests, and only on the granularity of an entire message.\n>\n>\n>>> I think you also need to require people who use this attribute in \n>>> their formats to explicitly identify who is required to conform to \n>>> the policy (#1).\n>>\n>> Wouldn't that be covered by the ENTITY element? Or are you thinking \n>> of something beyond that?\n>\n> Ah, yes; that should do it. Does ENTITY have some mechanism for \n> identifying an anonymous party (e.g., \"Anyone I send THIS message to \n> me MUST conform to this privacy policy)? I'd imagine there are cases \n> where people using this attribute won't want to explicitly enumerate \n> the entity responsible for conforming to the policy.\n>\n\nI think it is important that the party responsible for the policy be \nidentified. If they are not identified, then it is difficult to find \nthem if you have a problem with the way they are following the policy.\n\nAlso, P3P is not designed for telling data collectors how to treat \ndata; it is designed for data collectors to describe their policies. \nThat was part of the point we were trying to make in the XML Generic \nAttribute section. If you have a chunk of XML that you are sending \naround to different places and you want them all to respect your \nprivacy you need something other than P3P to describe this (perhaps \nEPAL, perhaps some language based on P3P).\n\nLorrie\n\n\n\n", "id": "lists-017-8346802"}, {"subject": "Re: primary purpose lis", "content": "Am Monday 03 May 2004 20:42 verlautbarte Lorrie Cranor :\n> \n> sales of products or services\n> \n> charitable donations [do we want to group this with sales for a\n> generic transactions category?]\n> \n> payments and transaction facilitation [do we want to group this with\n> sales as above?]\n\nNo, definitely no.\n> \n> order fulfillment and delivery\n> \n> banking and financial management\n> \n> registration, enrollment, subscription, reservations, account\n> management [are we bundling too many thngs together here?]\n\nI think so.. I would distinguish between subscribing and \nmanaging (existing) accounts.\n> \n> education - including dissemination of educational materials, testing,\n>    grading, interactions with teachers or other students, etc.\n> \n> gaming\n> \n> gambling\n> \n> entertainment\n> \n> arts and literature [could this be combined with entertainment?]\n> \n> news and information\n> \n> communications services\n> \n> search\n> \n> surveys\n> \n> authentication\n\nauthorization (login e.g.)?\n> \n> government services (e-government)\n> \n> customizing online experience\n> \n> distributing content (serving pages)\n> \n> respond to user \nI would call this feedback\n\n> \n> advertising, marketing, and promotion\n> \n> state management\n> \nwhat about travel (which is a subgroup to sales of services)\n\nRigo\n\n\n\n\n", "id": "lists-017-8358211"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "Am Monday 03 May 2004 20:34 verlautbarte Lorrie Cranor :\n> >\n> >> P3P 1.0 was designed to associate XML-encoded privacy policies with \n> >> URIs,  sets of URIs, or cookies. P3P 1.0 it well suited for use with \n> >> HTML  and XHTML content transmitted over [HTTP] .\n> >\n> > I think this would be better stated as:\n> >\n> >> P3P 1.0 was designed to associate XML-encoded privacy policies with \n> >> data submitted to Web resources, which are identified by URIs or \n> >> bound to cookies.\n> \n> I think the word \"submitted\" is too limiting, as P3P also covers log \n> data that is created as a result of a transaction but might not really \n\nwe associate some URI with a certain privacy behavior, NOT with data. \nAs Lorrie said, some of the data is generated directly over there:\n\nP3P 1.0 was designed to associate XML-encoded privacy \npolicies with URI's describing the privacy impact of the Web \nresources behind those URI's.\n\nTalking about \"data\" is too dangerous IMHO as people will \nmix that up with the data schemata in the policy.. This is NOT \nwhat we mean. We can describe the data in the POST, as \nwe have a data schema for that. The violation of attaching \na P3P Policy to a set of data happens on the protocol level.\n\n\"I send a policy over the wire to force someone to apply it\" is\nis what we want to avoid.\n\nBest, \n\nRigo\n\n\n\n\n", "id": "lists-017-8366004"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "Am Tuesday 04 May 2004 00:51 verlautbarte Mark Nottingham :\n> >> I think you also need to require people who use this attribute in \n> >> their formats to explicitly identify who is required to conform to \n> >> the policy (#1).\n> >\n> > Wouldn't that be covered by the ENTITY element? Or are you thinking of \n> > something beyond that?\n> \n> Ah, yes; that should do it. Does ENTITY have some mechanism for \n> identifying an anonymous party (e.g., \"Anyone I send THIS message to me \n> MUST conform to this privacy policy)? I'd imagine there are cases where \n> people using this attribute won't want to explicitly enumerate the \n> entity responsible for conforming to the policy.\n\nMark, here you fall exactly into the trap of the wrong protocol. \nYou send PREFERENCES instead of POLICY in your example ;)\nYou don't go to the supermarket to impose your conditions. You \naccept their conditions. \n\nIn data protection, you need the ENTITY element to be able \nto get to your rights as you can't force your rights against \nanonymous. In a web-service scenario, this is tricky as the \nWS interacting can be a privacy client in one second and a \ndata controller in the next second. \n\nImagine WS1 discovering WS2. WS1 is requesting something to \nWS2 and finds the P3P Policy in the WSDL. The PP is good and \nWS1 makes its request. If there is need for feedback and WS2 \nmakes a request to WS1, WS2 would have to check the P3P Policy \nof WS1 first.\n\n(Note that this only applies if _personal_ data is involved, means \nsome end-user or request on behalf of an end-user)\n\nSending Policies forward and saying SOAP \"must understand\" \ncan't be solved with P3P, it needs EPAL.\n\nBest, \n\nRigo\n\n\n\n\n", "id": "lists-017-8374605"}, {"subject": "no call toda", "content": "We were supposed to have a p3p spec call today. However, mailing list \ndiscussion has been minimal so there is not much to talk about, so I am \ngoing to cancel the call. Basically we need some progress on:\n\n- P3P Generic Attribute (Rigo is consulting with Fabian on RDF aspect)\n- XML schema (Giles is working on it)\n- Primary purpose (Lorrie sent a draft to the mailing list and is \nlooking for feedback)\n- Rigo's latest working draft (everyone should review and comment)\n\nLorrie\n\n\n\n", "id": "lists-017-8384028"}, {"subject": "comments on latest working draf", "content": "I read through the latest working draft \nhttp://www.w3.org/TR/2004/WD-P3P11-20040427/ and found a number of \nminor errors that need to be fixed:\n\n1.1.1 The list of enhancements is incomplete. It also needs to include:\n- An optional element for declaring the jurisdiction of data recipients\n- Definitions of identified, identifiable, linked, and linkable data\n- An optional element for declaring domain relationships\n- A compact version of the STATEMENT element for use in compact policies\n\nIt would also be good to list the relevant sections for all of these \nitems\n\n1.3 change reference to my book to a reference in the non-normative \nreferences appendix\n\n1.3.1 last sentence, there is a quoted phrase at the end of the \nsentence - remove quotes and italicize instead.\n\n2.3.2.7 In first sentence of paragraph hyperlink \"linked\" to 1.3.4\n\n2.3.2.9\n\nThe section about Domain Relationships --> This section\n\nmodifications would allow --> modifications allow\n\nchange hyperlink to issues to a reference in the non-normative \nreferences appendix\n\n2.3.2.9.1 extension element to --> extension to\n\nthe extension needs an xmlns (in BNF and examples)\n\n2.3.2.9.3 when only using --> when using\n\n2.5 This doesn't appear to reflect the changes I proposed in my April 9 \nemail\n\n3.2.3 required. or mixed. --> required or mixed.\n\n3.3.2 one implementers authoring --> one implementer's authoring\n\n3.3.6.1 need xmlns attribute and long and short description in BNF and \nexamples\n\n4 strike first paragraph (repeated in second paragraph)\n\n4.7 Add: See Section 6.4 for guidelines designed to reduce the chance \nthat a P3P user agent will accept an invalid compact policy.\n\n6.2 are available at ??? --> will be posted on the W3C web site when \nthey become available.\n\nremove the . at the end of the money definition\n\nadd the CATEGORIES label to the first column of demographic\n\nCATEGORIES optional -- the wording here is stated as \"the data element\" \nbut I think \"this data\" would make more sense... I wasn't involved in \nthis discussion\n\nAppendix 9 - add P3P 1.1 working group contributors in a new paragraph \nat the beginning\n\nChangelog - spell check, I see a bunch of typos\n\n\nAlso we need to add the following (basically a summary of our backwards \ncompatibility guidelines documenting that we followed them):\n\n1.1.7 Backwards Compatibility\n\nP3P 1.1 has been designed so that P3P 1.0 user agents can process P3P \n1.1 policies and  policy reference files. This implies both that the \nP3P 1.1 policies and  policy reference files are fully compliant with \nthe P3P 1.0 XML schema,  and that the semantics of these files will not \nbe misinterpreted by a  user agent that interprets them according to \nthe P3P 1.0  specification. All new syntax introduced in P3P 1.1 has \nbeen introduced as optional extensions using the P3P 1.0 extension  \nmechanism. Changes to requirements or definitions introduced in P3P 1.1 \nadd clarity where the P3P 1.0 specification is ambiguous, but do not  \ncause a particular P3P vocabulary element to have different meanings in \n  P3P 1.0 and P3P 1.1. In addition, some new requirements or features \nhave been introduced in the P3P 1.1  specification that do not impact \nthe ability of P3P 1.0 user agents to  process P3P 1.1 policies and \npolicy reference files. \n\n\n\n", "id": "lists-017-8390680"}, {"subject": "need input on primary purpos", "content": "On May 3 I sent out a draft proposal on primary purposes\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004May/0003.html\n\nOnly Rigo responded\nhttp://lists.w3.org/Archives/Public/public-p3p-spec/2004May/0006.html\n\nI really need input on this list (there are some questions in my\noriginal email). It would also be great if some of you might volunteer\nto start writing some definitions and human readable language....\n\nLorrie\n\n\n\n\n", "id": "lists-017-8400856"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "Hi Rigo, sorry for the delay responding.\n\nOn May 4, 2004, at 9:54 AM, Rigo Wenning wrote:\n\n>> Ah, yes; that should do it. Does ENTITY have some mechanism for\n>> identifying an anonymous party (e.g., \"Anyone I send THIS message to \n>> me\n>> MUST conform to this privacy policy)? I'd imagine there are cases \n>> where\n>> people using this attribute won't want to explicitly enumerate the\n>> entity responsible for conforming to the policy.\n>\n> Mark, here you fall exactly into the trap of the wrong protocol.\n> You send PREFERENCES instead of POLICY in your example ;)\n> You don't go to the supermarket to impose your conditions. You\n> accept their conditions.\n\nI agree that there are different models; if one were to generalise \nthem, they might be\n   Entity X will honour policy P when handling data D.\nfor \"policy\" (e.g., P3P), and\n   Entity Y requires entity X to honour policy P when handling data D.\nfor \"preferences (e.g., EPAL).\n\nMy original point was slightly different; in both cases, the data is \nidentified as D; P3P specifies this by associating policy with \"data \nthat is submitted to resource R\" but this is really just a referential \nway to identify D.\n\n\n> In data protection, you need the ENTITY element to be able\n> to get to your rights as you can't force your rights against\n> anonymous. In a web-service scenario, this is tricky as the\n> WS interacting can be a privacy client in one second and a\n> data controller in the next second.\n> Imagine WS1 discovering WS2. WS1 is requesting something to\n> WS2 and finds the P3P Policy in the WSDL. The PP is good and\n> WS1 makes its request. If there is need for feedback and WS2\n> makes a request to WS1, WS2 would have to check the P3P Policy\n> of WS1 first.\n>\n> (Note that this only applies if _personal_ data is involved, means\n> some end-user or request on behalf of an end-user)\n> Sending Policies forward and saying SOAP \"must understand\"\n> can't be solved with P3P, it needs EPAL.\n\nWould you agree that the vocabulary for describing the policy and means \nof specifying it could be the same for either application, with the \nonly difference being the assertions about who is requiring or \ncommitting to do what with them?\n\nRegards,\n\n\n--\nMark Nottingham   Principal Technologist\nOffice of the CTO   BEA Systems\n\n\n\n", "id": "lists-017-8407752"}, {"subject": "Re: P3P Generic Attribute for XML Application", "content": "Am Wednesday 26 May 2004 01:01 verlautbarte Mark Nottingham :\n> I agree that there are different models; if one were to generalise\n> them, they might be\n>    Entity X will honour policy P when handling data D.\n> for \"policy\" (e.g., P3P), and\n>    Entity Y requires entity X to honour policy P when handling data\n> D. for \"preferences (e.g., EPAL).\n>\n> My original point was slightly different; in both cases, the data is\n> identified as D; P3P specifies this by associating policy with \"data\n> that is submitted to resource R\" but this is really just a\n> referential way to identify D.\n\nThis is part of the issue Giles is working on. If we would be able to \nidentify data D with an XML Schema, it would make integration more \ndecent. In Lorrie' s head, P3P works with data categories, so we \nhaven't been down to that level of detail. We also don't address the \nissue of identifiers as in DRM. P3P does not say _that specific_ piece \nof data but rather this genre/type of data associated with your name \nand personal info.\n>\n> Would you agree that the vocabulary for describing the policy and\n> means of specifying it could be the same for either application, with\n> the only difference being the assertions about who is requiring or\n> committing to do what with them?\n\nIn an EU Project, Giles is working on a privacy ontology for the reasons \nyou give here. IBM has tried to accomplish both applications with the \nP3P vocabulary. Guenter Karjoth has written several presentations on \nthe shortcomings of P3P in EPAL-like applications. EPAL is simply P3P + \nAPPEL in one application and then simplified at max. The simplification \ndoes not take too much power, as we learned a lot during the past two \nyears about the benefit of different approaches.\n\nSee the P3P Workshop in Kiel for more details:\n\nhttp://www.w3.org/2003/p3p-ws/\n\nBest, \n\nRigo\n\n\n\n\n", "id": "lists-017-8418097"}, {"subject": "P3P Base Data Schem", "content": "Hi,\nHere are the long promised files for the XML Schema P3P Base Data Schema.\nThere is a new spec (the HTML file) - an openoffice file.\nThen there are the various transforms (the one for transforming policies to\nlegacy format is included in the spec).\nThe main issues which I think people should think about are at the end of\nthe spec doc.\nWe can discuss these issues on the next call.\n\nAs predictable, it was a lot more work than initially anticipated, mainly\nbecause XSD specs and XSD parsers don't always agree...\n\n\nGiles\n\n\n\n\napplication/x-zip-compressed attachment: BDS_may2004.zip\n\ntext/html attachment: BDSSpec.html\n\n\n\n\n", "id": "lists-017-8427253"}, {"subject": "RE: comments on latest working draf", "content": "I agree with Lorrie's recommended changes to section 2.3.2.9, with the\nfollowing additions:\n\n2.3.2.9 rewrite intro paragraph as follows (with link moved to references\nsection as Lorrie suggested):\n\nThis section describes a method to allow user agents to recognize when hosts\nin different domains are owned by the same entity or entities acting as\nagents for one another. User agents may use this information when applying\nprivacy preferences, particularly to avoid implementation issues encountered\nwhen more stringent privacy preferences are applied to domains that are\ndeemed to be owned by third-parties.\n\n2.3.2.9.1 examples\n\nneed to change \"instance.example.com\" to \"example2.com\" (6 occurrences). The\nexample is not powerful unless it demonstrates different domains (it used to\nbe forinstance.com)\n\nneed to change \"*.myagent.example\" in second example to \"*.myagent.com\"\n\n2.3.2.9.3\n\n\"to the OUR-HOSTS declarations\" --> \"to the OUR-HOST declarations\"\n\nreplace \"instance.example.com\" with \"example2.com\"\n\n\n++Jack++\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@cs.cmu.edu]\nSent: Tuesday, May 25, 2004 3:01 PM\nTo: public-p3p-spec\nSubject: comments on latest working draft\n\n\n\nI read through the latest working draft \nhttp://www.w3.org/TR/2004/WD-P3P11-20040427/ and found a number of \nminor errors that need to be fixed:\n\n1.1.1 The list of enhancements is incomplete. It also needs to include:\n- An optional element for declaring the jurisdiction of data recipients\n- Definitions of identified, identifiable, linked, and linkable data\n- An optional element for declaring domain relationships\n- A compact version of the STATEMENT element for use in compact policies\n\nIt would also be good to list the relevant sections for all of these \nitems\n\n1.3 change reference to my book to a reference in the non-normative \nreferences appendix\n\n1.3.1 last sentence, there is a quoted phrase at the end of the \nsentence - remove quotes and italicize instead.\n\n2.3.2.7 In first sentence of paragraph hyperlink \"linked\" to 1.3.4\n\n2.3.2.9\n\nThe section about Domain Relationships --> This section\n\nmodifications would allow --> modifications allow\n\nchange hyperlink to issues to a reference in the non-normative \nreferences appendix\n\n2.3.2.9.1 extension element to --> extension to\n\nthe extension needs an xmlns (in BNF and examples)\n\n2.3.2.9.3 when only using --> when using\n\n2.5 This doesn't appear to reflect the changes I proposed in my April 9 \nemail\n\n3.2.3 required. or mixed. --> required or mixed.\n\n3.3.2 one implementers authoring --> one implementer's authoring\n\n3.3.6.1 need xmlns attribute and long and short description in BNF and \nexamples\n\n4 strike first paragraph (repeated in second paragraph)\n\n4.7 Add: See Section 6.4 for guidelines designed to reduce the chance \nthat a P3P user agent will accept an invalid compact policy.\n\n6.2 are available at ??? --> will be posted on the W3C web site when \nthey become available.\n\nremove the . at the end of the money definition\n\nadd the CATEGORIES label to the first column of demographic\n\nCATEGORIES optional -- the wording here is stated as \"the data element\" \nbut I think \"this data\" would make more sense... I wasn't involved in \nthis discussion\n\nAppendix 9 - add P3P 1.1 working group contributors in a new paragraph \nat the beginning\n\nChangelog - spell check, I see a bunch of typos\n\n\nAlso we need to add the following (basically a summary of our backwards \ncompatibility guidelines documenting that we followed them):\n\n1.1.7 Backwards Compatibility\n\nP3P 1.1 has been designed so that P3P 1.0 user agents can process P3P \n1.1 policies and  policy reference files. This implies both that the \nP3P 1.1 policies and  policy reference files are fully compliant with \nthe P3P 1.0 XML schema,  and that the semantics of these files will not \nbe misinterpreted by a  user agent that interprets them according to \nthe P3P 1.0  specification. All new syntax introduced in P3P 1.1 has \nbeen introduced as optional extensions using the P3P 1.0 extension  \nmechanism. Changes to requirements or definitions introduced in P3P 1.1 \nadd clarity where the P3P 1.0 specification is ambiguous, but do not  \ncause a particular P3P vocabulary element to have different meanings in \n  P3P 1.0 and P3P 1.1. In addition, some new requirements or features \nhave been introduced in the P3P 1.1  specification that do not impact \nthe ability of P3P 1.0 user agents to  process P3P 1.1 policies and \npolicy reference files. \n\n\n\n", "id": "lists-017-8434808"}, {"subject": "one page p3p wrtieups due this wee", "content": "For those of you who volunteered to do a one-page write-up\non an area of future work, please send your write-ups to\nthis mailing list by the end of this week.\n\nThanks!\n\nLorrie\n\n\nFrom: \"Lorrie Cranor\" <lorrie@research.att.com>\nTo: <public-p3p-ws@w3.org>\nDate: Thu, 14 Nov 2002 21:06:24 -0500\nSubject: P3P next steps list\n\n\nThanks to everyone who participated for a great workshop! We\nhad some very useful discussions and got a good sense of\nthe areas where there is interest in additional work. Rough minutes\nwill be sent to this list soon and a summary report should be ready\nin mid-December.\n\nThe following is the list of areas for future work that we identified\nand prioritized during the closing session. I have indicated the\nnames of the people who volunteered to write up a 1 page proposal\non each of these areas. Please include purpose, scope, resources,\nand time frame and send your proposals to this mailing list by\nDec. 13.\n\n\nAreas for future work\n\n1. Vocabulary issues [high priority - mostly for 1.1, maybe some for 2.0]\n  a. Article 10 issues [volunteers: Diana and Giles]\n  b. primary data uses [volunteer: Lorrie]\n  c. general vocab review [maybe longterm - volunteer: Lorrie]\n\n2. Indication of agent status, multiple domains owned by same company,\n  etc. [high priority - possibly for 1.1, otherwise for 2.0 -\n  volunteer: Brian Zwit]\n\n3. Spec ambiguities [short term high priority - volunteer: Matthias]\n\n4. Compact policies [high priority for 1.1, Brooks has been\n  volunteered]\n  a. What are performance issues that motivate CP and what are\n     alternative approaches? Where exactly is the problem?\n  b. Semantic issues\n  c. Cross-product problem -- need for grouping mechanism\n  d. Agent status, multiple domains owned by the same company, etc.\n\n5. User agent behavior [high priority, either short term or long term,\n  volunteer: Brian Zwit]\n  a. Human readable notices\n    i. user friendly version in spec (must, should, or reference examples)\n    ii. coordinate with short notices\n\n6. Statements in the spec to better articulate what P3P is and isn't\n  [short term high priority, volunteer: Brian Zwit]\n\n7. How to use P3P w/out binding to HTTP and URIs [quick win,\n  volunteer: Danny]\n\n8. Consent recording mechanism [high priority, long term, volunteer:\n  Matthias]\n\n9. Feedback channel [little interest]\n\n10. User preference language -- APPEL, etc. [high priority, volunteer:\nGiles]\n  a. ontology - default languages\n\n11. Convert P3P data schema to XML schema [low priority but might be\n    quick win, volunteer: Giles]\n\n12. Coordination with other efforts [high priority for both short\n    term and long term, volunteer: Danny]\n    a. Liberty Alliance\n    b. Other authentication efforts\n    c. Web services/SOAP\n    d. Geopriv\n    e. Short notices\n    f. DAML\n\n13. XML signatures [low priority but might be quick win, volunteer: Giles]\n\n14. P3P in backend databases [little interest]\n\n15. Identity management [Marit volunteered by Rigo]\n\n16. Outreach - to be covered by POWG\n\n\nWorkshop Deliverables\n1. raw minutes (send to rigo for posting)\n2. this list\n3. summary report (Lorrie and Danny will prepare draft by Dec. 13)\n4. one page write ups (first drafts sent to workshop mailing list by\n   Dec. 13) -- include purpose, scope, resources, time frame\n\n\n\n", "id": "lists-017-8485849"}, {"subject": "RE: one page p3p wrtieups due this wee", "content": "Citigroup would be glad to help out in 1, 2, 5, 6 and/or 10\n\nEspecially with respect to where these touch on topics such as GLBA or\ntrans-border issues\n\n\n-----Original Message-----\nFrom: Lorrie Cranor [mailto:lorrie@research.att.com]\nSent: Tuesday, December 10, 2002 10:18 PM\nTo: public-p3p-ws@w3.org\nSubject: one page p3p wrtie-ups due this week\n\n\n\nFor those of you who volunteered to do a one-page write-up\non an area of future work, please send your write-ups to\nthis mailing list by the end of this week.\n\nThanks!\n\nLorrie\n\n\nFrom: \"Lorrie Cranor\" <lorrie@research.att.com>\nTo: <public-p3p-ws@w3.org>\nDate: Thu, 14 Nov 2002 21:06:24 -0500\nSubject: P3P next steps list\n\n\nThanks to everyone who participated for a great workshop! We\nhad some very useful discussions and got a good sense of\nthe areas where there is interest in additional work. Rough minutes\nwill be sent to this list soon and a summary report should be ready\nin mid-December.\n\nThe following is the list of areas for future work that we identified\nand prioritized during the closing session. I have indicated the\nnames of the people who volunteered to write up a 1 page proposal\non each of these areas. Please include purpose, scope, resources,\nand time frame and send your proposals to this mailing list by\nDec. 13.\n\n\nAreas for future work\n\n1. Vocabulary issues [high priority - mostly for 1.1, maybe some for 2.0]\n  a. Article 10 issues [volunteers: Diana and Giles]\n  b. primary data uses [volunteer: Lorrie]\n  c. general vocab review [maybe longterm - volunteer: Lorrie]\n\n2. Indication of agent status, multiple domains owned by same company,\n  etc. [high priority - possibly for 1.1, otherwise for 2.0 -\n  volunteer: Brian Zwit]\n\n3. Spec ambiguities [short term high priority - volunteer: Matthias]\n\n4. Compact policies [high priority for 1.1, Brooks has been\n  volunteered]\n  a. What are performance issues that motivate CP and what are\n     alternative approaches? Where exactly is the problem?\n  b. Semantic issues\n  c. Cross-product problem -- need for grouping mechanism\n  d. Agent status, multiple domains owned by the same company, etc.\n\n5. User agent behavior [high priority, either short term or long term,\n  volunteer: Brian Zwit]\n  a. Human readable notices\n    i. user friendly version in spec (must, should, or reference examples)\n    ii. coordinate with short notices\n\n6. Statements in the spec to better articulate what P3P is and isn't\n  [short term high priority, volunteer: Brian Zwit]\n\n7. How to use P3P w/out binding to HTTP and URIs [quick win,\n  volunteer: Danny]\n\n8. Consent recording mechanism [high priority, long term, volunteer:\n  Matthias]\n\n9. Feedback channel [little interest]\n\n10. User preference language -- APPEL, etc. [high priority, volunteer:\nGiles]\n  a. ontology - default languages\n\n11. Convert P3P data schema to XML schema [low priority but might be\n    quick win, volunteer: Giles]\n\n12. Coordination with other efforts [high priority for both short\n    term and long term, volunteer: Danny]\n    a. Liberty Alliance\n    b. Other authentication efforts\n    c. Web services/SOAP\n    d. Geopriv\n    e. Short notices\n    f. DAML\n\n13. XML signatures [low priority but might be quick win, volunteer: Giles]\n\n14. P3P in backend databases [little interest]\n\n15. Identity management [Marit volunteered by Rigo]\n\n16. Outreach - to be covered by POWG\n\n\nWorkshop Deliverables\n1. raw minutes (send to rigo for posting)\n2. this list\n3. summary report (Lorrie and Danny will prepare draft by Dec. 13)\n4. one page write ups (first drafts sent to workshop mailing list by\n   Dec. 13) -- include purpose, scope, resources, time frame\n\n\n\n", "id": "lists-017-8496483"}, {"subject": "future work proposal  areas 1b/", "content": "Vocabulary issues --  primary data uses and general vocab review\n\nA number of somewhat vague concerns have been raised about the\nP3P vocabulary, especially with regards to the lack of granularity it\nprovides for expressing the primary purpose for which data is collected.\nThe P3P vocabulary focuses on secondary purposes rather than\nprimary purposes because these are the purposes that it was thought\nusers would want their agents to consider in automated decision-making.\nHowever, companies have indicated a desire to express primary purposes\nas well, and primary purposes are likely to be useful for back end\nprocessing.\n\nWithout changing the P3P specification, sites can use the\nCONSEQUENCE element to explain their primary data uses. Perhaps\nthe specification might be clarified to make this clear. Companies\ndeveloping back-end P3P-related products might develop their own\nvocabulary for primary data uses and use the P3P extension mechanism\nto integrate it into P3P policies. Once such a vocabulary is put forward,\nW3C should consider whether or not a version of it should be standardized in\na future version of P3P or as a stand-alone W3C specification.\n\nExcept in the area of EU Directive compliance and agent relationships,\nno other specific vocabulary issues have been raised. Thus, it seems\npremature to undergo a complete review of the P3P vocabulary at this time.\n\nMy  recommendation is that the next P3P working group be chartered\nto consider suggestions to clarify the meaning and use of existing\nP3P vocabulary elements and vocabulary changes to address the specific\nconcerns that have been raised that may impact P3P implementation\nand adoption. A deadline should be set for raising vocabulary-related\nissues for consideration in the P3P1.1 timeframe.\n\nShould a future P3P working group be chartered following the P3P1.1\nwork, that group might take on a more thorough review and possible\noverhaul of the P3P vocabulary.\n\nLorrie Cranor\n\n\n\n", "id": "lists-017-8509041"}, {"subject": "Future work proposal P3P  area 1", "content": "Dear Lorrie and others,\n\nPlease find enclosed the one page write-up proposal that Giles and I\npromised to produce following up the workshop in Washington.\n\nBest regards to everybody,\n\nDiana\n\n\nDiana ALONSO BLAS, LL.M.\nEuropean Commission, DG Markt, Unit Data Protection\nAv. de Cortenbergh 100, 6-31\nB-1040 Brussels\n\nTel: 00/32/2-2984280\nFax: 00/32/2-2968010\nE-mail: diana.alonso-blas@cec.eu.int\n\n\n\n\n\napplication/msword attachment: P3Pwriteupvocabularyarticle10issues.doc\n\n\n\n\n", "id": "lists-017-8518395"}, {"subject": "Future work proposal P3P  area  13 (XML Dig Sig", "content": "XML signed policy specification. (Item 13)\n------------------------------------------\n------------------------------------------\n\nPurpose:\n--------\nA serious problem for P3P is that if a company's practices contravene its\nstated privacy policy, there is little technical or legal framework to prove\nthat a company made the statements, which existed on its server at a given\ntime. I.e. it is too easy for a company to repudiate its policy statements.\nWhile P3P does increase the level of trust felt by consumers by providing\nmore transparent and unambiguous information, it does not however provide\nany assurance as to the authenticity and integrity of this information.\nThe aim of this item is to provide a watertight route of legal recourse and\nthereby to increase trust in consumers.\nProbably the biggest obstacle in achieving these objectives is in driving\nthe adoption of any measures taken. However, a prerequisite to this is to\nprovide hooks within the P3P standard by which signed policies may be\nreferenced, validated and later used as legal evidence.\n\nScope:\n------\nJoseph Reagle of W3C has already gone some way towards outlining the detail\nof this solution and the solution would build on the document \"A P3P\nAssurance Signature Profile\".\nBuilding on this, the requirements for the P3P specification are as follows:\n1. A mechanism for locating a signed version of a policy within a standard\nP3P policy. It has been suggested that the verification attribute should be\nused to identify the location of the signed policy. However it may be\nvaluable to create another attribute so that user agents may easily identify\nthe need to verify a signature. In any case, it needs to be clearly\nspecified within the spec document where the signed version of a particular\npolicy should be specified.\n2. A similar element needs to be created within PRF files to verify the\nbinding to the policy. This should be optional but recommended (a SHOULD)\nwhere a signed policy is referenced.\n3. A full specification for the format of XML signed policies such as that\nspecified within Reagle's P3P assurance profile document and Giles Hogben,\nTom Jackson, Marc Wilikens (Joint Research Centre of the EC, I). A fully\ncompliant research implementation of the P3P standard for privacy\nprotection: experiences and recommendations\nThere is little further work necessary.\n4. If possible a sample tool for creating signed policies.\n5. Description of verification process for user agents. The problem of how\nto automate this should be visited. For example if a certificate is provided\nfor a domain, which does not match the domain of the signed policy, what\nshould the agent do - should there be a checksum repository to help user\nagents verify certificates?\n6. An addition to the APPEL specification so that signatures may be required\nunder certain circumstances (e.g. \"signaturerequired\" attribute in a rule).\n\nResources:\n----------\nThe JRC has already developed a prototype specification for this\nfunctionality. This specification will be used to create a demonstrator\nmodule to be integrated within the JRC proxy architecture. Further resources\nfor integrating this into the P3P specification can also be provided by the\nJRC.\n\nTime Frame:\n-----------\nIt is expected that the development of the architecture, specification and\ndemonstrator will be finished by January 2004.\n\n\n_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\nVia Enrico Fermi 1\n21020 Ispra,   Italy\n\n\n\n", "id": "lists-017-8527074"}, {"subject": "Future work proposal P3P  area  11 (XML Schema", "content": "Convert P3P data schema to XML schema (Item 11)\n-----------------------------------------------\n-----------------------------------------------\n\nPurpose:\n--------\nThere is a simple 1:1 mapping between an XML schema version of the base data\nschema and the current mode of expression. This would make it a lot easier\nto handle for user agent implementers as many operations require the schema\nto be converted into a more standard format in any case. For example\ndisplaying the schema in a tree diagram or creating an array of all possible\ncategories.\n\nScope:\n------\nThe best solution is to write a specification for how the base data schema\ncan be expressed using XML schema notation, and then to write an xsl\nstylesheet which will convert the old schema into the new one.\n\nResources:\n----------\nResources are available in the JRC (Giles Hogben) to achieve this objective.\n\nTime Frame:\n-----------\nA maximum estimated total time of 15 man days should cover this item,\nincluding comments and integration into spec.\n\n\n\n\n_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\nVia Enrico Fermi 1\n21020 Ispra,   Italy\n\n\n\n", "id": "lists-017-8537261"}, {"subject": "Future work proposal P3P  area 10 (Appel", "content": "Improvements to APPEL language (Item 10)\n----------------------------------------\n----------------------------------------\n\nPurpose:\n--------\n-To enable default settings of P3P privacy preferences to be distributed\namong user agents in order to satisfy legal requirements, particularly\nwithin the EU\n-To provide the possibility for more uniformity between user agents and\nhence more business investment in P3P due to consistent user agent behavior.\n-To produce a preference exchange language which would be acceptable and\neasy to use for developers and which at the same time allows sufficient\nexpressiveness.\n-To produce a language, which is not logically ambiguous - i.e. each\nrule/preference will have the same behavior with all semantically equivalent\npolicies (this is not currently the case with APPEL).\n-To produce a user interface/conceptual model for APPEL, which is\ncomfortable for non expert users.\n\nScope:\n------\nThe work involved in this item is as follows.\n1. Develop a specification for an XPATH enabled version of the current\nAPPEL. This would enable developers to write arbitrary queries, which would\nmore easily express the kind of logic required for expressing sub-tree\nmatching rules. This essentially provides for rules which can match\narbitrary policy fragments. This satisfies legal requirements because legal\nbodies will wish essentially to have arbitrary scope in creating APPEL\npreference sets for distribution.\n2. Consult with browser implementers who may eventually integrate the\npreference exchange language, to make sure that the specification provides\nwhat they require to be willing to commit to it.\n3.  With this in place, it will be possible to distribute preferences sets\nsuch as \"EU default preferences\", \"US safe harbour default preferences\" etc?\n4. Provide a higher level ontology for the arbitrary matching capability\nsuch that it is accessible to uninitiated users.\n\nThere are two possible routes for point 4:\n1. Leave it to \"market forces\" to sort out standard sets of preferences. One\ncould imagine that some structured discussion among interested parties could\nlead to a list of standard sets of preferences so that for example, High,\nLow, Medium could be simply APPEL rulesets with a well defined interoperable\nmeaning.\n2. Develop a higher level ontology which restricts user agent interfaces to\na more limited set of higher level concepts with a well defined mapping to\nthe concepts of P3P. This would then have the effect of standardizing the\nway that preferences are presented and reducing confusion in end users.\nClearly the second alternative is preferable in the long run because in\nconjunction with a proven conceptual mapping process such as that set out by\nHameed (University of Aberdeen), it offers a vocabulary which is adapted to\nthe end-user needs.\n\nThe two alternatives however are not incompatible and in fact the two routes\nmay be followed in sequence according to resources available. As the JRC\nintends to lead an ontology project, the best possible route is probably in\nthe short term to develop satisfactory default rulesets for import. These\nrulesets could then be simply tagged by name in IE/NS (for example instead\nof high, low, medium it would show EU (high), EU(medium), US (high), trust-e\netc? This would require no modification to the P3P specification but would\nrequire the agreement of Browser developers, particularly Microsoft.\nIn the longer term, a higher level ontology could be incorporated into the\nP3P specification, so that more detailed terms are grouped under higher\nlevel headings, which then form the basis of a standardized end-user\npreference scheme. This would need to be discussed with\n\nResources:\n----------\n\nThe European Commission's JRC Cybersecurity team has already carried out\nmuch of the work necessary to develop a new version of APPEL and resources\nare available to complete this within the JRC. Resources are also available\nwithin the JRC for the development of a higher level ontology which is part\nof the proposals for the RAPID initiative.\nFurther resources required are commitments to discussion on standardization\nof user agent interfaces by Microsoft, Netscape, Opera and other user agent\nimplementers.\nTime Frame\nThe development of an improved version of APPEL should be possible within 9\nmonths to a year including the consensus process. As Internet Explorer is\nthe most important user agent, account should be taken of the time frames\nfor development of new versions of IE.\nThe development, agreement and integration of a higher level ontology is\npossible within 2 years and is therefore a process which should be assigned\nto the P3P 2.0 specification.\n\n\n_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\nVia Enrico Fermi 1\n21020 Ispra,   Italy\n\n\n\n", "id": "lists-017-8545056"}, {"subject": "Future Work Proposal: P3P Spec. Ambiguitie", "content": "SCOPE\n\nA P3P policy should make clear  what recipient is allowed to perform\nwhat purpose on which data element. In addition, it should define what\ndata can be collected, whether it needs to be anonymized at\ncollection, and how long can it be retained.\n\nUnfortunately, the P3P specification only describes the meaning of a\npolicy that restricts itself to the most primitive case. Complicated\ncases, like conflicts, are not sufficiently addressed.\n\nThe following issues should be clarified:\n- Overlapping Statements: What is the meaning of overlapping statements\n   In particular if some have opt-in opt-out, some haven't.\n- Meaning of non-identifiable: It is unclear what an non-identifiable element\n   means.\n\nRESOURCES\n- Matthias Schunter\n- Review and proposed changes to the spec.\n- Aiming at an addenum to 1.0 that clarifies these issues.\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-8557084"}, {"subject": "Future Work Proposal: P3P Consent/Choices Definition Mechanis", "content": "SCOPE\n\nCurrently, data subjects opt-in or opt-out to elements within a\nstatement. For example, they can opt-out of a certain recipient for a given\nset of statements and retention policies. This implies that they\nautomatically opt-in or opt-out to the resulting cross product with\nthis recipient and all purposes and retentions. This is usually not\nwhat a user wants. In practice, a customer usually opts in for a\nabstract textual description that reflects many uses.\n\nSince opt-in and opt-out usually corresponds to certain business\nprocesses in an organization that require multiple data elements for\nmultiple purposes, it is advisable to introduce `consent blocks' that\nenable to opt-in or opt-out to a set of statements.  This can be\nformalized by named consent descriptors that can be opt-in or opt-out\nand describe (in text) what the consent means. Each statement can then\nspecify a consent descriptor.  If this particular consent has been\ngiven, the statement is applicable.  Otherwise, it is not applicable.\n\n\nRESOURCES\n- Matthias Schunter\n- Elaborate our proposal to express consent choices in P3P 1.1\n- Discussions with the P3P 1.1 working group\n\nIf P3P wants to specify a format for _collecting_ consent in P3P 2.0,\nwe'd be willing to contribute as well. Collecting consent would require\nelements that fix primary and secondary recipients and purposes.\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-8565400"}, {"subject": "P3P Future Work: Items 2, 5, and ", "content": "P3P Future Work Item 2: Indication of Agent Status, Multiple Domains Owned by \nOne Company, etc.\n\nPurpose: \nMany companies have sites on multiple domains and, with the current \nimplementations of P3P, have had a very difficult time implementing P3P and \ncompact policies on all its sites. When content is shared between domains, \nsignificant difficulties have been encountered with both P3P and compact \npolicies from different sites being inconsistent with the practices of the \nsite using the content or cookies from the second domain being blocked even \nwhen the same company owns both sites. In addition, some companies are acting \nas agents for another company and are simply following the contracting \ncompany's privacy policy. \n\nThere is no mechanism in the specification to allow a site to handle content \nsharing between domains or indicate that one site is acting as the agent for \nanother. (HINT is sometimes incapable of fully expressing the relationship \nbetween sites.) To encourage adoption of P3P, a mechanism or mechanisms are \nrequired to permit a site to easily share content without an unduly \ncomplicated P3P policy or compact policies and to indicate that one site is \nthe agent for another site.\n\nScope: \nWork on the issues discussed above could, without excluding other ideas, \ncenter on the following:\n\n    1.  Along with the work being done to review other aspects of compact \npolicies, review the efficiencies, if any, associated with compact policies \nand even the need for compact policies given the experience of implementing \nP3P so far; and\n\n    2.  Creating a mechanism to allow a site to declare other sites as \nfirst-party sites, i.e., that they are all owned by the same company and have \nthe same or similar privacy practices or are acting for another site as an \nagent and are bound by the other sites privacy policies, in both P3P and \ncompact policies; and\n\nResources:\nThere is no known work already on this topic. However, extensive experience \nexists in the private sector with implementing P3P on sites that share \nsignificant amounts of content. These experiences could be leveraged to \nidentify problems and potential solutions.\n\nTime Frame:\nThe issues here should be relatively easy to resolve. It should be possible \nto reach consensus on a mechanism to accomplish the last objective above \nwithin the timeframe for version 1.1 of the specification. Review of compact \npolicies might take longer to complete. (See P3P Future Work Item 4.)\n\n\n-------------------------------------------------------------------------------\n\n-\n\nP3P Future Work Item 5: User Agent Behavior\n\nPurpose: \nDevelopers have begun to implement P3P in new versions of their products, \nmostly web browsers. As with the first version of most products, these \nefforts have received mixed reviews from users and site operators.\n\nThe current implementations have interfered with the functionality of some \nsites, confused users, and implement different standards. These \nimplementations of P3P have required the developer to make certain decisions \nregarding what privacy practices to review and what to do if that particular \nprivacy practice is enabled at a site, e.g., does the browser look for \ncookies that store personally identifiable information on the user's computer \nand then block them or just downgrade them.\n\nSites have been enabling P3P, particularly compact policies, and have had \ndifficulties implementing P3P and maintaining functionality in the new user \nagents. Now functionality is not only limited by the rendering engine of a \nbrowser, for example, but also whether the browser will block cookies based \non some particular privacy practice.\n\nMore consistency between user agents in how P3P is implemented would be \nhelpful to users as their experience on one user agent would be transferable \nto another and to sites so that they could build the site and develop one \nconsistent privacy policy.\n\nScope: \nWork on the issues discussed above could, without excluding other ideas, \ncenter on the following:\n\n    1.  Determining whether some basic recommendations are needed for \nimplementing P3P in user agents; (NOTE: The word \"recommendation\" is used \nhere only to describe the scope of this effort. The form, e.g., whether \nrecommendations, suggestions, guidelines, a separate specification, or even \njust a white paper, is an unresolved question.)\n\n    2.  Reviewing the experiences of users and site operators with the \ncurrently available user agents to determine what areas should be addressed \nin this conversation; and\n\n    3.  Prepare recommendations for developers of user agents to follow when \nappropriate in implementing P3P.\n\nResources:\nThere has been significant work already done on this topic. Resources are \navailable from developers as wells as governmental regulators and NGOs. In \naddition, there are probably significant resources available in academia to \nassist in this effort. Despite the significant resources available, it is \nexpected that reaching consensus on any recommendations would take a \nsubstantial amount of work and time. However, no formal recommendations may \nbe required, the discussion itself may be useful to developers of users \nagents as well as site operators.\n\nTime Frame:\nThe issues here will probably be relatively hard to resolve and the timeframe \nfor any formal recommendations would be significant. However, given previous \ndiscussions, it is doubtful that any recommendations coming from this effort \nwould be included in the P3P specification. It would likely be in a separate \ndocument instead and allow this work and other work on the specification \nitself to proceed on different schedules.\n\n\n-------------------------------------------------------------------------------\n\n-\n\nP3P Future Work Item 6: Description of the Contours of P3P\n\nPurpose: \nWhile many sites have adopted P3P, adoption has been slower than hoped for \nbecause companies are unsure of their liabilities for statements made in P3P \nand compact policies given the limitations of the technology at this time. No \none is suggesting that sites are not liable or should be given immunity for \nmistakes or misrepresentations in their P3P statements. However, everyone \nrecognizes that P3P does not allow a site to describe every nuance of its \nprivacy practices and that the specification is a work in progress. The \npurpose of this item is to clarify the current state of the specification as \nto what privacy practices can and cannot be expressed in the lexicon of P3P.\n\nScope: \nThe work is limited to descriptive text only. The text would more \nexplicatedly describe what privacy practices can and cannot be described in a \nP3P or compact policy and other limitations of the technology. For instance, \nP3P with its limited vocabulary cannot be expected to represent every nuance \nof a site's privacy policy. The additional text may also recognize, without \nrendering P3P irrelevant, that the human readable privacy policy is the \nauthoritative statement of a site's privacy policies.\n\nResources:\nMinimal resources required to complete this item. A draft of proposed \nlanguage could be drafted by a small group of P3P Specification Working Group \nmembers and circulated broadly for comment by the remaining members.\n\nTime Frame:\nBased on the discussion at the P3P Workshop, there appeared to be some common \nground on this issue and it should be relatively easy to resolve. It should \nbe possible to reach consensus on language within the timeframe for version \n1.1 of the specification.\n\nBrian (<A HREF=\"aol://9293:bzwit/\">AOL IM</A> | <A HREF=\"mailto: bzwit/a\">AOL Mail</A>)\n\n-----------------------------------------------------------------\nBrian J. Zwit, Director, Integrity Assurance\nAmerica Online, Inc.\n( (703) 265-6232 l AIM: bzwit l Internet * <A HREF=\"mailto: bzwit@aol.com\">bzwit@aol.com</A>\n----- AOL Confidential Information -----\n\n\n\n\n\n\n\n\n\n\napplication/zip attachment: P3P_Future_Work_Item_6.ZIP\n\n\n\n\n", "id": "lists-017-8574387"}, {"subject": "P3P Future Work Items 4.a: Compact Policies Performance Issue", "content": "P3P Future Work Items 4.a: Compact Policies Performance Issues\n\nPurpose\n\nThe abbreviated syntax of Compact Policies, CPs, and the delivery system via\nthe HTTP P3P header stems from the belief that Full (XML) Policies cannot be\npresented at cookie set time.  This belief is held because Set-Cookie\nheaders are received and acted upon in the initial response to an HTTP\ndelivered asset.  It is upheld that discovery of a Full Policy prior to\nacceptance of a cookie would be difficult/resource intensive for a User\nAgent, UA.   \n\nThis lack of Full XML Policy, and the extensibility therein however creates\nnumerous issues particularly with regard to accuracy.\n\n\nScope:\n\nPossible areas of exploration could include:\n\n1.Empirical study of effect on UA performance with real time\ndiscovery of Full Policy through PRF of cookie policies\n2.Possibility of \"cached\" Set-Cookie's Statements pending\nsubsequent resolution on related Full Policies.\n3.Pre-fetching and storing Cookie Policies within allowed\nexpiry for given hosts. \n\n\nResources:\n\nAs this is entirely a User Agent issue, resources for this project would\nlikely need to come from UA developers with input from all members of a\nfuture working group.\n\nTime Frame:\n\nThese issues are difficult to resolve and are highly dependent on user\nexperience - which it self highly dependent on issues such as average user\nbandwidth, internet latency and connectivity.  The need to resolve this\nissue may be hastened by the legal interpretations of the inherent inability\nfor CPs to be sufficiently nuanced.\n\n\n\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n\n", "id": "lists-017-8589241"}, {"subject": "P3P Future Work Items 4.b: SemanticIssue", "content": "P3P Future Work Items 4.b: SemanticIssues\n\nPurpose\n\nP3P assumes \"Accuracy\" between all policies related to given data\ncollection, including: Natural Language Policy (which is itself a\nrequirement of P3P), a Full XML policy and a Compact Policy (if used).  To\naccommodate a data collector's need to describe their practices, P3P has a\nbase data schema and the ability to extend that schema to accommodate\nparticular collector practices where those practices cannot be accurately\ndescribed within the existing schema.  The difficulty with Compact Policies,\nCPs, is that they allow for only a subset of the functionality of the Full\nPolicy with no ability to extend or accurately group practices.  The result\nof which is an in ability for a data collector to be truly accurate with the\nlimited syntax.  This then implies that to be accurate in a CP the data\ncollector MUST overstate.\n\nCurrently the CP allows a collector to make statements from among the\nfollowing predefined groups: <PURPOSE>s-12, <RECIPIENT>s-6, data\n<CATEGORIES>-16, <ACCESS>-6, <RETENTION>-5, <DISPUTES>-1, <REMEDIES>-3.\nThis effectively limits a CP implementer to the requirement of accurately\nrepresenting his/her NLP by choosing from ~49 predefined tokens (the UA\nrendering of which the collector will have no control - but from which they\nwill be liable).\n\nThis lack of nuance forces a data collector who e.g. associates a cookie\nwith a proclivity to examine cold remedies with a category that also\nincludes \"mental health\" and \"sexual orientation\".  It is extremely possible\nthat such statements may be illegal within the effected jurisdiction or\nspecifically against the NLP expressed practices of the data collector. \n\n\nScope:\n\nPossible areas of exploration could include:\n\n1.If accuracy and consistency across NLP<->XML<->CP is core to\nP3P but unachievable by the CP do we scrap the accuracy requirement or the\nCP?  Is there a better balance to be found?  Or a better language construct\nthan accurate.\n2.Examine what exactly we are trying to achieve with the CPs?\nDo we allow it to be a performance optimisation only as an imperfect\nplaceholder until a Full policy can be discovered?\n3.Consider adding a token which denotes the \"up to and\nincluding\" nature of the statements made by a CP or should this be better\nexplained within the spec with more delineated requirements for UAs.\n4.Consider adding more tokens to allow some degree more\nnuance.\n5.*It should be noted that a number of these issues overlap\nQuestion 1. Vocabulary Issues \n\n\nResources:\n\nThe size of this issue requires the resources of a full working group.\n \nTime Frame:\n\nTo me this problem is fundamentally the question of trading off between the\naccuracy requirement in the spec (which are likely to be upheld by\nenforcement agencies) and the performance increases of the Compact Policy.  \n\n\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n\n", "id": "lists-017-8598429"}, {"subject": "P3P Future Work Items 4.c: Cross&ndash;product problem &ndash;&ndash; need for grou ping mechanis", "content": "P3P Future Work Items 4.c: Cross-product problem -- need for grouping\nmechanism\n\nPurpose/Scope\n\nFull P3P XML Policies allow for individual <STATEMENT>s within a <POLICY> to\neffectively group <PURPOSE>s, <RECIPIENT>s and data <CATEGORIES>.  The\nCompact Policy does not have a <STATEMENT> element and it is therefore\nimpossible to produce these logical groupings.  The result of this is an\noverall aggregation of all declarations that may provide an imperfect\ndescription of the data practices related to the cookie.\n\nFor instance, a full policy can say that data <CATEGORIES>:: <FINANCIAL>,\n<GOVERNMENT>, <ONLINE> where used for <PURPOSE>s: <CONTACT>,\n<INDIVIDUAL-ANALYSIS>, <INDIVIDUAL-DECISION> internally by\n<RECIPIENT>::<OUR>, but also in a separate <STATEMENT> that\n<CATEGORIES>::<DEMOGRAPHIC>, <COMPUTER>, <UNIQUE> to be used for <PURPOSE>::\n<PSEUDO-ANALYSIS> by <RECIPIENT>::<UNRELATED>.  This has a vastly different\nmeaning than the current CP rendition (FIN, GOV, ONL, COM, DEM, CON, PSA,\nIVA, IVD, OUR, UNR), which would imply PII information being given to an\nunrelated 3rd party.\n\n\nThere is a need to create a <STATEMENT> like grouping mechanism within the\nCP.  This would require some change to Compact Policy.  I see several ways\nthat this could be achieved:\n*Recreation of the <STATEMENT> element through new tokens\n\"STA\" and \"/STA\"  allowing for valid and consistent groupings within.\n*Use of parenthesis, brackets or other grouping delimiter to\nachieve the same without directly implying all the properties of the\n<STATEMENT> element.\n\n\nResources:\n\nAs this will involve UA producers and the 1.1 working group.\n\n\nBrooks Dobbs\nDirector of Privacy Technology\nDoubleClick, Inc.\n\noffice: 404.836.0525\nfax: 404.836.0521\nemail: bdobbs@doubleclick.net\n\n\n\n", "id": "lists-017-8608884"}, {"subject": "P3P workshop report progres", "content": "Thanks to those of you who have submitted your future\nwork proposals. Danny and I are finishing up the draft workshop\nreport and adding links to the future work proposals.\nSince most of you are on vacation or will be shortly, our plan\nis to post the draft workshop report on January 6 for your\nfeedback. We will also be drafting a proposed charter\nfor a P3P1.1 working group based on the future work\nproposals. \n\nHappy holidays and happy new year! \n\nLorrie\n\n\n\n", "id": "lists-017-8618570"}, {"subject": "testing the newlycreated lis", "content": "Testing, please ignore.\n\n-- \nOlivier Thereaux - W3C\nhttp://www.w3.org/People/olivier | http://yoda.zoy.org\n\n\n\n", "id": "lists-017-8655212"}, {"subject": "P3P workshop agenda now poste", "content": "P3P Workshop Attendees:\n\nA draft agenda for the P3P workshop is now posted at\nhttp://www.w3.org/2002/p3p-ws/. You wil also find a link to\nall of the position papers that were submitted. We are \nexpecting a few more papers and to add a few additional\npeople to the program later this week. The web site\nwill be updated as the final speakers are confirmed.\n\nWe do not plan to distribute printouts of the position papers\nat the workshop, so we encourage participants to review\nthe papers prior to the workshop.\n\nFor those of you who have been invited to give a short\npresentation at the workshop, please remember to keep\nyour remarks to 5 minutes. I expect most presenters will\nnot be using slides, however, if you think slides will\nenhance your presentation, you are free to use them. If you\nwant to use slides, you must email them to \nP3PWorkshop@aol.com by this Friday, November 8.\nYou will not be able to display them off your own laptop.\nYou are also welcome to bring handouts to distribute to\nparticipants. Please plan to bring 50 copies.\n\nWe are planning to go to an Asian restaurant called\n\"Big Bowl\" for dinner at 7:30 pm on November 12 (note this\nis not a sponsored dinner). Please email me ASAP to let me \nknow whether you plan to join us for dinner.\n\nSee you all next week!\n\nLorrie Cranor\nWorskshop co-chair\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nLorrie Faith Cranor <lorrie@research.att.com>\nAT&T Labs-Research, Shannon Laboratory \n180 Park Ave. Room A205, Florham Park, NJ 07932 \nhttp://lorrie.cranor.org/    973-360-8607  \n\n\n\n", "id": "lists-017-8681503"}, {"subject": "P3P position paper", "content": "I've been reading through the position papers posted on the workshop site\nwith great interest. I just wanted to let everyone know that my own (late)\nsubmission was just posted, just in case you've already downloaded/printed\nout all the other submissions.\n \nhttp://www.w3.org/2002/p3p-ws/pp/ <http://www.w3.org/2002/p3p-ws/pp/> \n \nLooking forward to meeting everyone next week.\n \nJack Humphrey\nCoremetrics\n \n\n\n\n", "id": "lists-017-8689631"}, {"subject": "P3P workshop agenda and dinne", "content": "P3P Workshop Attendees:\n\n[Sorry if you have gotten this multiple times...\nsome people did not get it the first time... also\ndon't forget to RSVP for dinner.]\n\nA draft agenda for the P3P workshop is now posted at\nhttp://www.w3.org/2002/p3p-ws/. You wil also find a link to\nall of the position papers that were submitted. We are \nexpecting a few more papers and to add a few additional\npeople to the program later this week. The web site\nwill be updated as the final speakers are confirmed.\n\nWe do not plan to distribute printouts of the position papers\nat the workshop, so we encourage participants to review\nthe papers prior to the workshop.\n\nFor those of you who have been invited to give a short\npresentation at the workshop, please remember to keep\nyour remarks to 5 minutes. I expect most presenters will\nnot be using slides, however, if you think slides will\nenhance your presentation, you are free to use them. If you\nwant to use slides, you must email them to \nP3PWorkshop@aol.com by this Friday, November 8.\nYou will not be able to display them off your own laptop.\nYou are also welcome to bring handouts to distribute to\nparticipants. Please plan to bring 50 copies.\n\nWe are planning to go to an Asian restaurant called\n\"Big Bowl\" for dinner at 7:30 pm on November 12 (note this\nis not a sponsored dinner). Please email me ASAP to let me \nknow whether you plan to join us for dinner.\n\nSee you all next week!\n\nLorrie Cranor\nWorskshop co-chair\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nLorrie Faith Cranor <lorrie@research.att.com>\nAT&T Labs-Research, Shannon Laboratory \n180 Park Ave. Room A205, Florham Park, NJ 07932 \nhttp://lorrie.cranor.org/    973-360-8607  \n\n\n\n", "id": "lists-017-8696604"}, {"subject": "AOL Position Pape", "content": "I don't have the opportunity to attend the Workshop, but I would like to\nmake comments about the position papers, and this seems like the\nappropriate forum.\n\nIn the AOL position paper[1], it is claimed\n\n[[[\nThe P3P specification could have a tremendous negative impact on network\noperations and the servers on those networks.\n\nFirst, a HTTP 1.1 connection can never be guaranteed in requesting the P3P\npolicies and, as a consequence, every time a user requests a page, the\nbrowser will request two P3P objects, the policy reference file and the\nP3P policy, directly from the origin server. The impact on the network\noperations will be a significant increase in latency and use of resources.\nThe impact will be magnified where the requested page contains content\nfrom other domains.\n\nSecond, network resources, servers and bandwidth, will be taxed by the\nmultitude of requests and the mechanisms for requesting P3P policies\noutlined in the specification. Many sites have multiple servers at\ndifferent domains providing advertisements or partners that share content\nor facilitate commerce transactions. For each http request to a different\ndomain, the browser must request a minimum of two other files, the P3P\nreference file and, after analyzing the reference file, the P3P policy.\nThis multiplying effect on a busy network will consume a significant\namount of network and computer resources and add significant latency to\nthe browsing process.\n]]]\n\nThis is demonstrably false. P3P states[2]:\n\n[[[\n[...] if a user agent is requesting a policy reference file or a policy,\nand does not know for certain that there are no HTTP 1.0 caches in the\npath to the origin server, then the request MUST force an end-to-end\nrevalidation.\n]]]\n\nSo, *when* the client needs a new policy reference file or policy, it must\ndo an end-to-end revalidation. This does not mean that P3P User-Agents\ncannot use the expiry information in those files themselves to cache the\nfile locally. Additionally, although HTTP caches cannot calculate a\nfreshness lifetime for the representation, they can use validation,\nsignficantly improving latency and network load. P3P User-Agents will not\nrequires two P3P objects \"every time a user requests a page\" *unless* they\ndo not implement a local, P3P-aware cache.\n\nThat having been said, I do agree that P3P's prohibition of any HTTP\nfreshness lifetime to be unfortunate; the requirement for absolute\nfreshness is a very high bar, and I question whether it's absolutely\nnecessary.\n\n\n\n1. http://www.w3.org/2002/p3p-ws/pp/aol.html\n2. http://www.w3.org/TR/P3P/#the_expiry_element\n\n--\nMark Nottingham\n\n\n\n", "id": "lists-017-8705204"}, {"subject": "P3P next steps lis", "content": "Thanks to everyone who participated for a great workshop! We\nhad some very useful discussions and got a good sense of\nthe areas where there is interest in additional work. Rough minutes\nwill be sent to this list soon and a summary report should be ready\nin mid-December.\n\nThe following is the list of areas for future work that we identified\nand prioritized during the closing session. I have indicated the\nnames of the people who volunteered to write up a 1 page proposal\non each of these areas. Please include purpose, scope, resources,\nand time frame and send your proposals to this mailing list by\nDec. 13.\n\n\nAreas for future work\n\n1. Vocabulary issues [high priority - mostly for 1.1, maybe some for 2.0]\n  a. Article 10 issues [volunteers: Diana and Giles]\n  b. primary data uses [volunteer: Lorrie]\n  c. general vocab review [maybe longterm - volunteer: Lorrie]\n\n2. Indication of agent status, multiple domains owned by same company,\n  etc. [high priority - possibly for 1.1, otherwise for 2.0 -\n  volunteer: Brian Zwit]\n\n3. Spec ambiguities [short term high priority - volunteer: Matthias]\n\n4. Compact policies [high priority for 1.1, Brooks has been\n  volunteered]\n  a. What are performance issues that motivate CP and what are\n     alternative approaches? Where exactly is the problem?\n  b. Semantic issues\n  c. Cross-product problem -- need for grouping mechanism\n  d. Agent status, multiple domains owned by the same company, etc.\n\n5. User agent behavior [high priority, either short term or long term,\n  volunteer: Brian Zwit]\n  a. Human readable notices\n    i. user friendly version in spec (must, should, or reference examples)\n    ii. coordinate with short notices\n\n6. Statements in the spec to better articulate what P3P is and isn't\n  [short term high priority, volunteer: Brian Zwit]\n\n7. How to use P3P w/out binding to HTTP and URIs [quick win,\n  volunteer: Danny]\n\n8. Consent recording mechanism [high priority, long term, volunteer:\n  Matthias]\n\n9. Feedback channel [little interest]\n\n10. User preference language -- APPEL, etc. [high priority, volunteer:\nGiles]\n  a. ontology - default languages\n\n11. Convert P3P data schema to XML schema [low priority but might be\n    quick win, volunteer: Giles]\n\n12. Coordination with other efforts [high priority for both short\n    term and long term, volunteer: Danny]\n    a. Liberty Alliance\n    b. Other authentication efforts\n    c. Web services/SOAP\n    d. Geopriv\n    e. Short notices\n    f. DAML\n\n13. XML signatures [low priority but might be quick win, volunteer: Giles]\n\n14. P3P in backend databases [little interest]\n\n15. Identity management [Marit volunteered by Rigo]\n\n16. Outreach - to be covered by POWG\n\n\nWorkshop Deliverables\n1. raw minutes (send to rigo for posting)\n2. this list\n3. summary report (Lorrie and Danny will prepare draft by Dec. 13)\n4. one page write ups (first drafts sent to workshop mailing list by\n   Dec. 13) -- include purpose, scope, resources, time frame\n\n\n\n", "id": "lists-017-8714503"}, {"subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle", "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n", "id": "lists-017-8724072"}, {"subject": "Minutes of the Workshop publishe", "content": "Dear all, \n\nit has taken a while to publish the minutes as I was travelling and\nbecame sick and had to recover. \n\nBut the minutes are finally published. There is no summary report yet. \n\nThe minutes are under:\nhttp://www.w3.org/2002/p3p-ws/minutes/\n\nbut they are also linked from the Workshop - Homepage:\nhttp://www.w3.org/2002/p3p-ws/\n\nBest, \n-- \nRigo Wenning            W3C/INRIA\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-8736244"}, {"subject": "notice to those who submitted P3P workshop paper", "content": "The W3C spam filter seems to have intercepted some\nof the papers that were submitted to the P3P workshop.\nIf you submitted a paper to the workshop and did not\nreceive a confirmation, please contact me to make\nsure we got it.\n\nThanks, and sorry for the inconvienence!\n\nLorrie Cranor\n\n\n\n", "id": "lists-017-8767661"}, {"subject": "P3P workshop papers due Sept. 3", "content": "Reminder: Papers for the Workshop on the\nFuture of P3P are due next Monday, September 30.\nThis is a firm deadline! If you would like to attend\nthe workshop you must submit a paper. For\nsubmission information, please see\nhttp://www.w3.org/2002/p3p-ws/cfp-p3p1_1\n\nLorrie Cranor\n\n\n\n", "id": "lists-017-8794548"}, {"subject": "search featur", "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n", "id": "lists-017-8821560"}, {"subject": "Call for Participation: W3C Workshop on the longterm Future of P3", "content": "Dear all,\n\nyou were participants in the first workshop on the Future of P3P. In\nDulles/Virginia we were talking about the near future and bugfixing in\nP3P 1.0. Now W3C is organizing a second workshop to think about\nlong-term goals. \n\nAt the same time, we will collect feedback and interest about\nstandardization of a more fine grained Enterprise Privacy Language. \n\nIf you are interested, see the attached CfP\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n=========================================================================\nW3C is holding a workshop on the long-term Future of P3P\nand Enterprise Privacy Languages. This workshop is being\norganized by the P3P Specification Working Group, a part of the\nW3C Privacy Activity. It is hosted by the Independent Center for Privacy \nProtection.\n\n      Date: 18 - 20 June 2003\n      Location: Kiel, Schleswig-Holstein, Germany\n\nThe Workshop page is at:\n\nhttp://www.w3.org/2003/p3p-ws/\n\nThe call for participation is available at:\n\n      http://www.w3.org/2003/p3p-ws/cfp-kiel.html\n\nThe full call for participation contains information about registration\nrequirements and procedures, and a link to the online registration\nform. The deadlines for this workshop are:\n\n      Position papers due: 24 May 2002\n      Registration closes: 4 June 2003\n      Complete program available: 7 June 2003\n\nPlease note that while this workshop is an open event, there is an\nattendance limit of 75. To ensure maximum diversity among participants,\nthe number of participants per organization will be limited in the\nevent that more than 75 individuals wish to participate.\n\nScope of the Workshop\n\nThe workshops on the first two days will discuss technology and policy\nconsiderations for the long-term future of P3P including new features or\napplications of P3P and longer-term P3P-related research and advanced\ndevelopment. Those might well address technical problems with P3P1.0,\npolicy goals that P3P may help address, requirements unmet by P3P1.0,\nand legal or policy questions that have arisen as a result of P3P\nimplementation with a perspective on the long-term future.\n\nOn the third day, the EPAL session will explore various industry use\ncase scenarios and regulatory templates for EPAL policies and\nenforcement scenarios.  The goal is to present EPAL capabilities in a\npublic forum and to collect interest and feedback on the idea of a more\nfine grained Enterprise Privacy Language (like EPAL e.g.).  It will also\ndiscuss which follow-up will be appropriate in this sector.\n\nGoal of the Workshop\n\nThe World Wide Web Consortium is sponsoring a workshop to discuss future\napplications of P3P and the Enterprise Privacy Languages, and get\nfeedback on what additional specifications or coordination efforts might\nbe necessary to support them. We are inviting position papers that\ndiscuss either technology or policy considerations (or both) for the\nlong-term future of P3P. Papers can be based on the current P3P\nspecification, but also go beyond backwards compatibility to P3P 1.0.\nThe results of this workshop will inform W3C's decision making on future\nP3P strategy, stimulate discussions of new developments and directions\nfor the long-term future of P3P and privacy metadata based solutions in\ngeneral and facilitate coordination with organizations engaged in\nrelated efforts.\n\nWe also want to evaluate the interest in enterprise privacy policy\nenforcement languages and to consider the relationship and/or\nintegration of such a language with respect to P3P. One proposal for\nEnterprise Privacy languages that has come to the attention of the\nWorkshop co-chairs is Enterprise Privacy Authorization Language (EPAL),\ndeveloped by IBM.  It is an example of such a formalized and\nfine-grained purpose-based enterprise privacy policy language that\nprovides enterprise enforcement opportunities for P3P 1.0 declarative\npolicies.\n\nThe goals for the Enterprise Privacy Languages area are:\n\n     * Evaluate EPAL as a basis for industry consensus in this area.\n     * Discuss other alternatives for enterprise privacy policy\n       languages based on position papers.\n     * Discuss next steps concerning a fine-grained\n       privacy/authorization language.\n\n\nExpected Audience\n\nWe expect several communities to contribute to the workshop:\n\n     * Organizations that develop P3P software\n     * Organizations with P3P-enabled Web sites\n     * Technologists from academia and industry who are experimenting\n       with P3P and related technologies\n     * Organizations that represent industry sectors on privacy issues\n       or promote industry self-regulatory efforts related to privacy\n       (industry associations, privacy seal providers, etc.)\n     * Privacy activists and organizations that represent individuals on\n       privacy issues\n     * Academic scholars who are studying privacy technology and policy\n       issues\n     * Organizations that are developing standards that may use P3P\n     * Government regulators and policy makers (and members of their\n       staff) from around the world\n\n\nDeliverables\n\nThe workshop is expected to result in the following deliverables:\n\n     * Workshop position papers\n     * Workshop presentations\n     * Workshop minutes\n     * Workshop Summary Reports on the future of P3P and Enterprise\n       Privacy Authorization Language\n\nThese will be published on the workshop home page.\n\nContact Information\n\nShould you have questions please feel free to contact one of the\nWorkshop chairs: Brian Zwit (AOL) <BrianP3P@aol.com>; Steven Adler (IBM)\n<adler1@us.ibm.com>; or Rigo Wenning (W3C), who also serves as Team\nContact <rigo@w3.org>.\n\nFor Rigo Wenning, W3C Privacy Activity Team Contact;\nJanet Daly, Head of Communications\n\n\n\n", "id": "lists-017-8827622"}, {"subject": "Link from translation sit", "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n", "id": "lists-017-8861976"}, {"subject": "Used Formwork/Peri Dok", "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n", "id": "lists-017-8869928"}, {"subject": "FW: p3p working group meeting registration and hote", "content": "If you plan to attend this meeting, please register ASAP so we can get a\nhead count on how many people will attend.\n\nThanks,\n\nLorrie\n\n\n------ Forwarded Message\n> From: Lorrie Cranor <lorrie@research.att.com>\n> Date: Mon, 27 Jan 2003 10:41:14 -0500\n> To: <w3c-p3p-ig@w3.org>, <public-p3p-w3@w3.org>\n> Subject: p3p working group meeting registration and hotel\n> Resent-From: w3c-p3p-ig@w3.org\n> Resent-Date: Mon, 27 Jan 2003 10:41:17 -0500 (EST)\n> \n> \n> The W3C membership is considering the P3P activity proposal renewal (please\n> ask your AC representative to vote to approve it). If all goes well, we\n> expect to proceed with our P3P 1.1 Specification Working Group meeting March\n> 6-7 in Boston. For more information, see\n> http://www.w3.org/2002/10/allgroupoverview.html\n> \n> If you plan to attend the meeting, please go ahead and register at\n> http://cgi.w3.org/Register/selectUser.pl?_w3c_meetingName=TPMar03\n> \n> Also, if you would like to stay at the Royal Sonesta Hotel where the meeting\n> will take place, you need to make your hotel reservations by Wednesday, Feb\n> 1. The hotel reservation form is at\n> http://www.w3.org/2002/10/allgroupoverview/hotelform.html\n> \n> This meeting (and the P3P 1.1 Specification Working Group) is open to\n> employees of W3C member organizations and invited experts only (although we\n> are proposing that the minutes and mailing list archive be made available to\n> the public). If you are interested in joining the working group and would\n> like to  be considered for invited expert status, please let me know.\n> \n> Lorrie\n> \n> \n> --\n> Lorrie Faith Cranor - http://lorrie.cranor.org/\n> P3P Specification Working Group Chair - http://www.w3.org/p3p/\n> New book: Web Privacy with P3P - http://p3pbook.com/\n> \n> \n\n------ End of Forwarded Message\n\n\n\n", "id": "lists-017-8897812"}, {"subject": "p3p conference call/meeting March ", "content": "In conjunction with our face-to-face meeting in Boston, we are planning to\nhave a conference call from 9 to 11 am US Eastern on Friday March 7 to allow\nthose who are unable to attend in person to participate. We expect to\nbriefly go over the charter and structure of the working group, then spend\nthe first half of the call discussing the Article 10 vocabulary concerns and\nthe second half discussing how we might develop guidelines for user agent\nbehavior (standard human-readable wording, etc.).\n\nIf you are interested in participating in this call, please email me. Also,\nplease let me know the type of participation you would like to have in the\nworking group going forward (regular member, invited expert, participant in\na specific taskforce, etc.).\n\nLorrie\n\n\n\n", "id": "lists-017-8907558"}, {"subject": "RE: P3P Future Work: Items 2, 5, and ", "content": "My comments are provided below. We generally agree with and endorse these\nthree efforts and would be willing to help.\n \nDan Schutzer\n212-559-1876\nschutzerd@citigroup.com\n\n\n-----Original Message-----\nFrom: Bzwit@aol.com [mailto:Bzwit@aol.com]\nSent: Friday, December 13, 2002 5:31 PM\nTo: public-p3p-ws@w3.org\nSubject: P3P Future Work: Items 2, 5, and 6\n\n\nP3P Future Work Item 2: Indication of Agent Status, Multiple Domains Owned\nby One Company, etc.\n\nPurpose: \nMany companies have sites on multiple domains and, with the current\nimplementations of P3P, have had a very difficult time implementing P3P and\ncompact policies on all its sites. When content is shared between domains,\nsignificant difficulties have been encountered with both P3P and compact\npolicies from different sites being inconsistent with the practices of the\nsite using the content or cookies from the second domain being blocked even\nwhen the same company owns both sites. In addition, some companies are\nacting as agents for another company and are simply following the\ncontracting company's privacy policy. \n\nThere is no mechanism in the specification to allow a site to handle content\nsharing between domains or indicate that one site is acting as the agent for\nanother. (HINT is sometimes incapable of fully expressing the relationship\nbetween sites.) To encourage adoption of P3P, a mechanism or mechanisms are\nrequired to permit a site to easily share content without an unduly\ncomplicated P3P policy or compact policies and to indicate that one site is\nthe agent for another site.\n\nScope: \nWork on the issues discussed above could, without excluding other ideas,\ncenter on the following:\n\n1. Along with the work being done to review other aspects of compact\npolicies, review the efficiencies, if any, associated with compact policies\nand even the need for compact policies given the experience of implementing\nP3P so far; and\n\n2. Creating a mechanism to allow a site to declare other sites as\nfirst-party sites, i.e., that they are all owned by the same company and\nhave the same or similar privacy practices or are acting for another site as\nan agent and are bound by the other sites privacy policies, in both P3P and\ncompact policies; and\n\nResources:\nThere is no known work already on this topic. However, extensive experience\nexists in the private sector with implementing P3P on sites that share\nsignificant amounts of content. These experiences could be leveraged to\nidentify problems and potential solutions.\n\nTime Frame:\nThe issues here should be relatively easy to resolve. It should be possible\nto reach consensus on a mechanism to accomplish the last objective above\nwithin the timeframe for version 1.1 of the specification. Review of compact\npolicies might take longer to complete. (See P3P Future Work Item 4.)\n\n\n\n----------------------------------------------------------------------------\n----\n\n\n\n\nP3P Future Work Item 5: User Agent Behavior\n\nPurpose: \nDevelopers have begun to implement P3P in new versions of their products,\nmostly web browsers. As with the first version of most products, these\nefforts have received mixed reviews from users and site operators.\n\nThe current implementations have interfered with the functionality of some\nsites, confused users, and implement different standards[Dan Schutzer]  in\ndifferent ways . These implementations of P3P have required the developer to\nmake certain decisions regarding what privacy practices to review and what\nto do if that particular privacy practice is enabled at a site, e.g., does\nthe browser look for cookies that store personally identifiable information\non the user's computer and then block them or just downgrade them.\n\nSites have been enabling P3P, particularly compact policies, and have had\ndifficulties implementing P3P and maintaining functionality in the new user\nagents. Now functionality is not only limited by the rendering engine of a\nbrowser, for example, but also whether the browser will block cookies based\non some particular privacy practice.\n\nMore consistency between user agents in how P3P is implemented would be\nhelpful to users as their experience on one user agent would be transferable\nto another and to sites so that they could build the site and develop one\nconsistent privacy policy.[Dan Schutzer]  This will be especially important\nas P3P gets implemented by agents other than one's browser. \n\nScope: \nWork on the issues discussed above could, without excluding other ideas,\ncenter on the following:\n\n1. Determining whether some basic recommendations are needed for\nimplementing P3P in user agents; (NOTE: The word \"recommendation\" is used\nhere only to describe the scope of this effort. The form, e.g., whether\nrecommendations, suggestions, guidelines, a separate specification, or even\njust a white paper, is an unresolved question.)\n\n2. Reviewing the experiences of users and site operators with the currently\navailable user agents to determine what areas should be addressed in this\nconversation; and\n\n3. Prepare recommendations for developers of user agents to follow when\nappropriate in implementing P3P.\n\nResources:\nThere has been significant work already done on this topic. Resources are\navailable from developers as well[Dan Schutzer]   as governmental regulators\nand NGOs. In addition, there are probably significant resources available in\nacademia to assist in this effort. Despite the significant resources\navailable, it is expected that reaching consensus on any recommendations\nwould take a substantial amount of work and time. However, no formal\nrecommendations may be required, the discussion itself may be useful to\ndevelopers of users agents as well as site operators.\n\nTime Frame:\nThe issues here will probably be relatively hard to resolve and the\ntimeframe for any formal recommendations would be significant. However,\ngiven previous discussions, it is doubtful that any recommendations coming\nfrom this effort would be included in the P3P specification. It would likely\nbe in a separate document instead and allow this work and other work on the\nspecification itself to proceed on different schedules.[Dan Schutzer] There\nare already some work in the spec that could be extended to provide more\nconsistency in user agent implementation. I'd like to see at least some\neffort to get this addressed in the next version of the spec, with more\ndetails to be provided in the separate document discussed above. \n\n\n\n\n----------------------------------------------------------------------------\n----\n\n\n\n\nP3P Future Work Item 6: Description of the Contours of P3P\n\nPurpose: \nWhile many sites have adopted P3P, adoption has been slower than hoped for\nbecause companies are unsure of their liabilities for statements made in P3P\nand compact policies given the limitations of the technology at this time.\nNo one is suggesting that sites are not liable or should be given immunity\nfor mistakes or misrepresentations in their P3P statements. However,\neveryone recognizes that P3P does not allow a site to describe every nuance\nof its privacy practices and that the specification is a work in progress.\nThe purpose of this item is to clarify the current state of the\nspecification as to what privacy practices can and cannot be expressed in\nthe lexicon of P3P.\n\nScope: \nThe work is limited to descriptive text only. The text would more\nexplicatedly describe what privacy practices can and cannot be described in\na P3P or compact policy and other limitations of the technology. For\ninstance, P3P with its limited vocabulary cannot be expected to represent\nevery nuance of a site's privacy policy. The additional text may also\nrecognize, without rendering P3P irrelevant, that the human readable privacy\npolicy is the authoritative statement of a site's privacy policies.\n\nResources:\nMinimal resources required to complete this item. A draft of proposed\nlanguage could be drafted by a small group of P3P Specification Working\nGroup members and circulated broadly for comment by the remaining members.\n\nTime Frame:\nBased on the discussion at the P3P Workshop, there appeared to be some\ncommon ground on this issue and it should be relatively easy to resolve. It\nshould be possible to reach consensus on language within the timeframe for\nversion 1.1 of the specification.\n\nBrian ( AOL IM <aol://9293:bzwit/>  | AOL Mail <mailto: bzwit/a> )\n\n\n\n\n-----------------------------------------------------------------\nBrian J. Zwit, Director, Integrity Assurance\nAmerica Online, Inc.\n* (703) 265-6232 * AIM: bzwit * Internet * bzwit@aol.com <mailto:\nbzwit@aol.com> \n----- AOL Confidential Information -----\n\n\n\n", "id": "lists-017-8935929"}, {"subject": "RE: Future Work Proposal: P3P Spec. Ambiguitie", "content": "To better evaluate this future work proposal, it would be helpful to\nunderstand in more detail just what types of changes you are proposing. For\nexample, today we can identify on an individual element basis whether that\ninformation element is opt-in opt-out or required - what more are you\nrecommending?\n\n-----Original Message-----\nFrom: Matthias Schunter [mailto:mts@zurich.ibm.com]\nSent: Friday, December 13, 2002 10:04 AM\nTo: public-p3p-ws@w3.org\nCc: wmi@zurich.ibm.com; evh@zurich.ibm.com\nSubject: Future Work Proposal: P3P Spec. Ambiguities\n\n\n\nSCOPE\n\nA P3P policy should make clear  what recipient is allowed to perform\nwhat purpose on which data element. In addition, it should define what\ndata can be collected, whether it needs to be anonymized at\ncollection, and how long can it be retained.\n\nUnfortunately, the P3P specification only describes the meaning of a\npolicy that restricts itself to the most primitive case. Complicated\ncases, like conflicts, are not sufficiently addressed.\n\nThe following issues should be clarified:\n- Overlapping Statements: What is the meaning of overlapping statements\n   In particular if some have opt-in opt-out, some haven't.\n- Meaning of non-identifiable: It is unclear what an non-identifiable\nelement\n   means.\n\nRESOURCES\n- Matthias Schunter\n- Review and proposed changes to the spec.\n- Aiming at an addenum to 1.0 that clarifies these issues.\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724 8953; More info at www.semper.org/sirene\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-8953993"}, {"subject": "RE: Future work proposal P3P  area  13 (XML Dig Sig", "content": "I agree with the problem defined in this work statement but am concerned\nthat the recommended solution may be costly to implement and may impose\nperformance issues. As there are other ways the same problem could be\naddressed; e.g. voluntary submittal of an organizations privacy policies, by\nthe responsible organization to a publically maintained, or neutral third\nparty, where an archive is maintained. Accordingly, I recommend that the\nsolution allow for a variety of technical solutions, to be proposed and\nimplemented that could address these problems, and time and implementation\nsuccess could occur and determine which technical solutions prevail - we\ncould address what aspects of the emerging dominant technical solutions need\nto be standardized upon in order to assure interoperability at that time.\n\nDan Schutzer\n212 559 1876\nschutzerd@citigroup.com\n\n-----Original Message-----\nFrom: Giles Hogben [mailto:giles.hogben@jrc.it]\nSent: Friday, December 13, 2002 8:34 AM\nTo: public-p3p-ws@w3.org\nSubject: Future work proposal P3P - area 13 (XML Dig Sig)\n\n\n\nXML signed policy specification. (Item 13)\n------------------------------------------\n------------------------------------------\n\nPurpose:\n--------\nA serious problem for P3P is that if a company's practices contravene its\nstated privacy policy, there is little technical or legal framework to prove\nthat a company made the statements, which existed on its server at a given\ntime. I.e. it is too easy for a company to repudiate its policy statements.\nWhile P3P does increase the level of trust felt by consumers by providing\nmore transparent and unambiguous information, it does not however provide\nany assurance as to the authenticity and integrity of this information.\nThe aim of this item is to provide a watertight route of legal recourse and\nthereby to increase trust in consumers.\nProbably the biggest obstacle in achieving these objectives is in driving\nthe adoption of any measures taken. However, a prerequisite to this is to\nprovide hooks within the P3P standard by which signed policies may be\nreferenced, validated and later used as legal evidence.\n\nScope:\n------\nJoseph Reagle of W3C has already gone some way towards outlining the detail\nof this solution and the solution would build on the document \"A P3P\nAssurance Signature Profile\".\nBuilding on this, the requirements for the P3P specification are as follows:\n1. A mechanism for locating a signed version of a policy within a standard\nP3P policy. It has been suggested that the verification attribute should be\nused to identify the location of the signed policy. However it may be\nvaluable to create another attribute so that user agents may easily identify\nthe need to verify a signature. In any case, it needs to be clearly\nspecified within the spec document where the signed version of a particular\npolicy should be specified.\n2. A similar element needs to be created within PRF files to verify the\nbinding to the policy. This should be optional but recommended (a SHOULD)\nwhere a signed policy is referenced.\n3. A full specification for the format of XML signed policies such as that\nspecified within Reagle's P3P assurance profile document and Giles Hogben,\nTom Jackson, Marc Wilikens (Joint Research Centre of the EC, I). A fully\ncompliant research implementation of the P3P standard for privacy\nprotection: experiences and recommendations\nThere is little further work necessary.\n4. If possible a sample tool for creating signed policies.\n5. Description of verification process for user agents. The problem of how\nto automate this should be visited. For example if a certificate is provided\nfor a domain, which does not match the domain of the signed policy, what\nshould the agent do - should there be a checksum repository to help user\nagents verify certificates?\n6. An addition to the APPEL specification so that signatures may be required\nunder certain circumstances (e.g. \"signaturerequired\" attribute in a rule).\n\nResources:\n----------\nThe JRC has already developed a prototype specification for this\nfunctionality. This specification will be used to create a demonstrator\nmodule to be integrated within the JRC proxy architecture. Further resources\nfor integrating this into the P3P specification can also be provided by the\nJRC.\n\nTime Frame:\n-----------\nIt is expected that the development of the architecture, specification and\ndemonstrator will be finished by January 2004.\n\n\n_____________________________________________\nGiles Hogben\nTP267\nCyberSecurity Unit\nInstitute for the Protection and Security of the Citizen (IPSC)\nEuropean Commission - Euratom Centro Comune di Ricerca\nVia Enrico Fermi 1\n21020 Ispra,   Italy\n\n\n\n", "id": "lists-017-8965175"}, {"subject": "P3P Future Work: Item 7  Use of P3P Vocabulary independent of http bindin", "content": "Work Item: How to use P3P independently of HTTP binding and possibly with\nreferences to objects that have no URIs.\n\nPurpose: Workshop participants from a variety of technology communities have\nrecognized the value the P3P vocabulary for describing the privacy policies\nof objects outside the HTTP URI scheme. This work item proposes a means of\nabstracting the P3P vocabulary elements from their original HTTP context in\norder to be useful in other application contexts. Successful completion has\ntwo basic requirements:\n\na. abstract description of P3P vocabulary\nb. demonstrated use of this abstract description in a non-http application\ncontext\n\nScope: The goal of this work item is to develop a generalized representation\nof the P3P vocabulary for use in applications contexts beyond http. This\ngoal can be satisfied by producing a W3C Note describing the P3P vocabulary\nalone, without the associated protocol description in the P3P 1.0\nRecommendation. While this work must be done in cooperation with at least\none other such application context (such as Geopriv or other IETF\nactivities, as an example), this particular activity would not, itself, be\nresponsible for describing bindings to other URI schemes or application\nsettings.\n\nResources: An initial draft of the proposal can be done by one or two\nindividuals familiar with P3P and the basics of Web architecture. W3C hopes\nto be able to devote a few weeks of staff engineering resources to this\nactivity in order to develop the initial draft. Completing this work will\nrequire  cooperation with those in another application domain. The P3P\nCoordination Group should work to solidify commitments from those who\nexpressed initial interest at the Workshop.\n\nTimeframe: An initial draft can be completed with a 2-3 months of work from\na W3C staff member and comments/support of the P3P technical working group\nand representative of the target non-http application domain. More time will\nbe required to finalize the problem, dependent on the schedule of the target\napplication.\n\n\n--\nDaniel J. Weitzner                              +1.617.253.8036 (MIT)\nWorld Wide Web Consortium                       +1.202.364.4750 (DC)\nTechnology & Society Domain Leader              <djweitzner@w3.org>\nhttp://www.w3.org/People/Weitzner.html\n\n\n\n", "id": "lists-017-8978632"}, {"subject": "P3P Future Work: Item 12  Coordination with other effort", "content": "P3P Future Work: Item 12 - Coordination with other efforts\n\nPurpose: Establish reliable mechanism for coordination work between ongoing\nP3P specification development activities and other efforts. A variety of\nefforts to address privacy in contexts related to the Web are working in\nareas closely connected to the P3P application space. Workshop participants\nidentified a need to develop cooperative mechanisms to coordinate work\nbetween P3P and these other efforts such as the Liberty Alliance and IETF\ninitiatives such as the Geopriv WG.\n\nCooperative efforts should be coordinated through the P3P Coordination\nGroup. As necessary, representatives of initiatives outside W3C may be\ninvited to participate in the P3P Coordination Group on either an ad hoc or\nformal basis. The P3P CG will develop concrete liaison statements with\nspecific outside activities as the basis for cooperation becomes more clear.\n\nScope: Ongoing P3P work at W3C should include mechanisms to coordinate\nactivities with outside groups as appropriate. This coordination should\nprovide for an exchange of requirements and, where possible, communication\nabout deployment and outreach efforts.\n\nResources: Coordination is often most effective when there is cross-over\nmembership between W3C activities and those outside W3C. Hence, adequate\nparticipation from W3C members in both P3P WGs and outside activities will\nbe important. W3C Members can provide vital leadership in coordination when\nshared objectives are recognized within a given Member organization and\ncommunicated to the participants in all related activities. W3C staff will\nprovide resources to the P3P Coordination Group as available to help develop\nshared goals across activities.\n\nTimeframe: ongoing\n\n\n--\nDaniel J. Weitzner                              +1.617.253.8036 (MIT)\nWorld Wide Web Consortium                       +1.202.364.4750 (DC)\nTechnology & Society Domain Leader              <djweitzner@w3.org>\nhttp://www.w3.org/People/Weitzner.html\n\n\n\n", "id": "lists-017-8988105"}, {"subject": "Re: P3P Future Work: Item 12  Coordination with other effort", "content": "At 01:56 PM 1/5/2003 -0500, Daniel Weitzner wrote:\n\n>P3P Future Work: Item 12 - Coordination with other efforts\n>\n>Purpose: Establish reliable mechanism for coordination work between ongoing\n>P3P specification development activities and other efforts. A variety of\n>efforts to address privacy in contexts related to the Web are working in\n>areas closely connected to the P3P application space. Workshop participants\n>identified a need to develop cooperative mechanisms to coordinate work\n>between P3P and these other efforts such as the Liberty Alliance and IETF\n>initiatives such as the Geopriv WG.\n>\n>Cooperative efforts should be coordinated through the P3P Coordination\n>Group. As necessary, representatives of initiatives outside W3C may be\n>invited to participate in the P3P Coordination Group on either an ad hoc or\n>formal basis. The P3P CG will develop concrete liaison statements with\n>specific outside activities as the basis for cooperation becomes more clear.\n>\n>Scope: Ongoing P3P work at W3C should include mechanisms to coordinate\n>activities with outside groups as appropriate. This coordination should\n>provide for an exchange of requirements and, where possible, communication\n>about deployment and outreach efforts.\n>\n>Resources: Coordination is often most effective when there is cross-over\n>membership between W3C activities and those outside W3C. Hence, adequate\n>participation from W3C members in both P3P WGs and outside activities will\n>be important. W3C Members can provide vital leadership in coordination when\n>shared objectives are recognized within a given Member organization and\n>communicated to the participants in all related activities. W3C staff will\n>provide resources to the P3P Coordination Group as available to help develop\n>shared goals across activities.\n>\n>Timeframe: ongoing\n\n\nWell crafted statement and having considerable knowledge of what is \nhappening in the IETF as one of its WG chairs issues relating to privacy \nand data collection are now continuing to come up not only in the GEOPRIV \nWG but also now in PROVREG which is defining the interfaces between domain \nname registrars and registries and as such must collect PII and other forms \nof social data.\n\nIETF has a mandate now that all IETF RFC's have a security considerations \nsection in the document there has been some consideration of extending that \nto privacy as well.\n\n\n\n >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRichard Shockey, Senior Manager, Strategic Technology Initiatives\nNeuStar Inc.\n46000 Center Oak Plaza  -   Sterling, VA  20166\nVoice +1 571.434.5651 Cell : +1 314.503.0640,  Fax: +1 815.333.1237\n<mailto:richard@shockey.us> or <mailto:richard.shockey@neustar.biz>\n  <http://www.neustar.biz> ; <http://www.enum.org>\n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-017-8997720"}, {"subject": "P3P Workshop report now availabl", "content": "Dear colleagues,\n\nI'm happy to announce that the summary report on the Future of P3P Workshop\nis now available at:\n\nhttp://www.w3.org/2002/12/18-p3p-workshop-report.html\n\nOn behalf of Lorrie & myself, thanks to all of you for your thoughtful\nparticipation and for preparing the action plans for future work. Those\nplans are now all linked from the end of the workshop report. The P3P\nCoordination Group will be looking in detail those and propose to this\nmailing list draft charter(s) for future P3P work. Any new work will\nultimately have to be review by the W3C Advisory Committee, but I believe\nthat we should use this mailing list of workshop participants to develop the\nproposals together.\n\nThe workshop report is publicly accessible so feel free to pass along the\nURL to others who may be interested.\n\nBest for a Happy New Year,\n\nDanny Weitzner\n\n--\nDaniel J. Weitzner                              +1.617.253.8036 (MIT)\nWorld Wide Web Consortium                       +1.202.364.4750 (DC)\nTechnology & Society Domain Leader              <djweitzner@w3.org>\nhttp://www.w3.org/People/Weitzner.html\n\n\n\n", "id": "lists-017-9009013"}, {"subject": "P3P WG meeting March 67, Bosto", "content": "The P3P Coordination group is in the process of drafting a new privacy\nactivity proposal and working group charters based on the workshop. We\nexpect to circulate a draft some time next week, incorporate feedback, and\npresent a proposal to the W3C membership by the end of the month. If the new\ncharters are approved we expect to hold a face-to-face meeting of the new\nP3P Specification Working Group March 6-7 at the W3C Plenary meeting in\nBoston. If you plan to participate in the working group, please save this\ndate and plan to attend.\n\n\n--\nLorrie Faith Cranor - http://lorrie.cranor.org/\nP3P Specification Working Group Chair - http://www.w3.org/p3p/\nNew book: Web Privacy with P3P - http://p3pbook.com/\n\n\n\n", "id": "lists-017-9018009"}, {"subject": "Draft P3P 1.1 spec group charte", "content": "Attached is a draft charter for the p3p spec group. The IPR section still\nneeds to be revised to reflect current W3C policy and the links need to be\nupdated. We hope to send this out to the W3C membership for review on Friday\nalong with a new activity statement, etc. We would like to incorporate\nfeedback we receive before then, so please review and send your feedback\nASAP.\n\nLorrie\n\n\n\n\n\n\napplication/octet-stream attachment: spec-charter.html\n\n\n\n\n", "id": "lists-017-9026006"}, {"subject": "p3p working group meeting registration and hote", "content": "The W3C membership is considering the P3P activity proposal renewal (please\nask your AC representative to vote to approve it). If all goes well, we\nexpect to proceed with our P3P 1.1 Specification Working Group meeting March\n6-7 in Boston. For more information, see\nhttp://www.w3.org/2002/10/allgroupoverview.html\n\nIf you plan to attend the meeting, please go ahead and register at\nhttp://cgi.w3.org/Register/selectUser.pl?_w3c_meetingName=TPMar03\n\nAlso, if you would like to stay at the Royal Sonesta Hotel where the meeting\nwill take place, you need to make your hotel reservations by Wednesday, Feb\n1. The hotel reservation form is at\nhttp://www.w3.org/2002/10/allgroupoverview/hotelform.html\n\nThis meeting (and the P3P 1.1 Specification Working Group) is open to\nemployees of W3C member organizations and invited experts only (although we\nare proposing that the minutes and mailing list archive be made available to\nthe public). If you are interested in joining the working group and would\nlike to  be considered for invited expert status, please let me know.\n\nLorrie\n\n\n--\nLorrie Faith Cranor - http://lorrie.cranor.org/\nP3P Specification Working Group Chair - http://www.w3.org/p3p/\nNew book: Web Privacy with P3P - http://p3pbook.com/\n\n\n\n", "id": "lists-017-9032835"}, {"subject": "P3P KielWS Minutes publishe", "content": "http://www.w3.org/2003/p3p-ws/minutes.html\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-9067689"}, {"subject": "P3P/EPAL Workshop Position papers publishe", "content": "Dear all, \n\nas announced some time ago, W3C is organizing a W3C Workshop on the long\nterm Future of P3P and Enterprise Privacy Languages[1] together with the \nIndependent Centre for Privacy Protection Schleswig-Holstein[2].  \n\nThe position papers are now published[3] and the program committee will now\nchoose the ones that will be presented at the Workshop. \n\nRegistration is still open.\n\n  1. http://www.w3.org/2003/p3p-ws/\n  2. http://www.datenschutzzentrum.de/\n  3. http://www.w3.org/2003/p3p-ws/pp/Overview.html\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9094958"}, {"subject": "P3P/EPAL Workshop Position papers publishe", "content": "Dear all, \n\nas announced some time ago, W3C is organizing a W3C Workshop on the long\nterm Future of P3P and Enterprise Privacy Languages[1] together with the \nIndependent Centre for Privacy Protection Schleswig-Holstein[2].  \n\nThe position papers are now published[3] and the program committee will now\nchoose the ones that will be presented at the Workshop. \n\nRegistration is still open.\n\n  1. http://www.w3.org/2003/p3p-ws/\n  2. http://www.datenschutzzentrum.de/\n  3. http://www.w3.org/2003/p3p-ws/pp/Overview.html\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9102955"}, {"subject": "Re: Screensave", "content": "Please see the attached file.\n\n\n\napplication/octet-stream attachment: movie.pi\n\n\n\n\n", "id": "lists-017-9111098"}, {"subject": "Important changes: Program for Workshop on P3P and Enterprise Languages publishe", "content": "Dear all, \n\ndue to low attendance, the program-committee shortened the W3C Workshop\non the long term Future of P3P and Enterprise Privacy Languages to\none and a half day. \n\nThe Workshop will be held on 19 and 20 June[1]. The program is now\npublished and accessible from the Workshop-homepage[2]\n\nAt the same time, the location has been moved to the Independent Centre\nfor Privacy Protection Schleswig-Holstein.[3] As we are viewer people,\nit is more convenient and closer to the town-center.\n\n\nIMPORTANT\nIf any of the attendees has trouble with the shortenings, please email\nimmediatly to me (rigo@w3.org)\n\n\n\n  1. http://www.w3.org/2003/p3p-ws/program.html\n  2. http://www.w3.org/2003/p3p-ws/\n  3. http://www.datenschutzzentrum.de/ldsh/dienstst_e.htm\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9117474"}, {"subject": "How to get 10,000 free hits per day. Make money for freeeee", "content": "  \nHi!\nWould 10,000 Free hits per day help your website\nalong?\nIF you have a product or service you need to\npromote\ntry this FREE promotional tool called MPAM.\nThis service will give you 10,000 hits per day\nfor FREE! \nLearn more at: www.hits.coolix.com\nTraffic = $(money)   \nVisit my money making opportunities web sites:\n*Instant Internet Empires!*\nAt: www.netempire.netfirms.com  \nand  *SFI CLUB, Six Figure Income*\nat:  http://www.ezinfocenter.com/7813217\nBest Regards,\nLic. Frank Cayol\n\n\n\n", "id": "lists-017-9148369"}, {"subject": "[public-p3pws] &lt;none&gt", "content": "Minutes of the P3P Specification Working Group Face to Face Meeting\n6-7 March 2003\nCambridge, MA\n\n(thanks to Rigo Wenning and Ari Schwartz for contributing their notes)\n\nPresent\n1/ Lorrie Cranor, AT&T Labs-Research\n2/ Jack Humphrey, Coremetrics\n3/ Brooks Dobbs, Doubleclick\n4/ Ari Schwartz, CDT\n5/ Jeremy Epling, Microsoft\n6/ Mathias Schunter, IBM\n\n7/ Brian Zwit, Integrity Insurance, AOL\n8/ Danny Weitzner, T-and-S Domain Leader, W3C\n9/ Rigo Wenning, Privacy Activity Lead, W3C\n10/ Helena Lindskog, Ericsson\n\nMarch 6\n\nINTRODUCTIONS AND DISCUSSION OF THE AGENDA\n\nAll present introduced themselves. As part of his introduction,\nMathias Schunter made the following announcement: We are pleased to\nannounce the first public version of the IBM Enterprise Privacy\nAuthorization Language (EPAL).  You can find the language\nspecification and XML schema at\nhttp://www.zurich.ibm.com/security/enterprise-privacy/epal We are\nworking on WS-Privacy together with Microsoft, want to keep P3P out\nthe B2B area.  Want to have some enterprise language that should be\ncompatible to P3P.\n\nDanny gave some history related to the Liberty Alliance in\npreparation for our discussion with them later.\n- Liberty has notion of rights expression language, they have a gap\nand need something to fill it\n- attribute sharing\n- packages of privacy practices/profiles? high/medium/low\n- looking for something easier to implement than P3P\n- P3P gives them a level of policy legitimacy in Europe\n\n\nCHARTER AND TASKFORCES\n\nThe P3P 1.1 charter\n(http://www.w3.org/P3P/Group/Specification/1.1/01-spec-charter.html)\nis being voted on by the membership. We hope to hear that it is\napproved in the next few weeks. We are currently operating under the\nassumption that it is likely to be approved with minor changes.\n\nThe deliverables in the charter are based on the discussion at the\nworkshop last fall. They include items that reflect a strong consensus\nthat these are things we should do as well as items with less support\nwhere someone just said he would do it.\n\nWe will have task-forces. Those TF will bring up the first draft and\nit will be discussed in the WG.  Timeline in the deliverable session:\nLorrie announced that she will enforce the timeline strictly.\nEverything that doesn't make it in the timeline will be considered for\nP3P 2.0 (pending charter of that working group).\n\nThe W3C's public Bugzilla will be the thing to be used for for\ntracking issues instead of our old issues list. Please register with\nBugzilla at http://www.w3.org/Bugs/\n\nSpec clarifications and items not covered by a specific taskforce\nwill be covered by the working group as a whole. An individual should\nraise the issue and make a specific proposal.\n\nBrian was interested in working on clarifying what a P3P policy means\nin the spec. He and Danny volunteered to draft a proposal.\n\nACTION: Brian & Danny: Create a proposal for clarification of what a\nP3P policy means\n\nIf we have a lot of clarifications and corrections before we are\nready to put out the p3p 1.1 spec we may put out a corrected version\nof the p3p 1.0 spec. In the mean time we will update the errata page.\n\n\nP3P Beyond HTTP taskforce:\n- volunteers: Danny Weitzner, Marc Langheinrich, John Morris\n(volunteered by Ari), Matthias Schunter\n- this taskforce still needs a chair... Danny suggested that Joseph\nReagle may be a possible chair\n- TF will look  at SOAP and WS, also independent P3P binding and\nother things like jabber, IRC, mail, etc.\n- Matthias is concerned about P3P turning into an enforcement\nlanguage, wants to distinguish between consumer notice and enterprise\nenforcement\n\nACTION: Danny to ask Joseph Reagle if he will chair this taskforce\n\nACTION: Matthias to draft proposed modification to P3P Beyond HTTP \ntaskforce\ndescription in draft charter and submit it with IBM ballot\n\n\nUser Agent Behavior taskforce\n- volunteers: Brian Zwit, Ari Schwartz, Jeremy Epling, Brooks Dobbs,\nLorrie Cranor, Diana Alonso-Blas (volunteered by Rigo), David\nStampley (volunteered by Lorrie)\n- nobody has volunteered to chair, Lorrie may chair this TF\n- TF may propose guidelines or requirements\n- Microsoft is opposed to this TF coming up with mandatory spec\ncomponents but supports guidelines\n- will work on guidelines for wording of P3P vocab elements as well\nas other aspects of UA behavior (for example, allow policies to be\nsaved and printed)\n\nACTION: Jeremy and Brian: deliver wording for P3P vocab elements from\nIE and Netscape\n\n\nCompact Policies taskforce\n- Brian Zwit volunteered to chair\n- volunteers: Brooks Dobbs, Jack Humphrey, Jeremy Epling, Helena\nLinkskog\n- first step is to get empirical data on performance issues related\nto CPs and do evaluation of tradeoffs\n\n\nArticle 10 taskforce\n- Giles Hogben volunteered to chair\n- volunteers: Jeremy Epling, Diana Alonso-Blas, Rigo Wenning\n- Casper Bowden (Microsoft) had previously expressed interest in\nparticipating\n\n\nAgent and Domain Relationships taskforce\n- Jack Humphrey volunteered to chair\n- volunteers: Brian Zwit, Brooks Dobbs, Matthias Schunter\n- Rigo suggested asking Mark Nottingham to participate\n- will look at how to deal with third parties.. How to say: I am the\nagent working for this site...\n- closely tied to compact policies\n\n\nConsent Choices taskforce\n- Matthias Schunter volunteered to chair\n- Lorrie will participate\n- Have more statements and group them and opt-out opt-in in a package\nIt is pretty similar to naming statements.\n\n\nXML Schema taskforce\n- Giles Hogben volunteered to chair\n- Jack volunteered to review\n- Rigo suggested that Massimo should be involved\n\n\nSigned P3P Policies taksforce\n- Giles Hogben volunteered to chair\n- some people unclear on why signed policies are need.\n\nACTION: Danny and Rigo, modify charter for this taskforce to require\nthat TF first provide explanation of why signed policies are needed\nand motivation for this work\n\n\nAPPEL is not mentioned in charter despite strong interest from\nsome. There was no consensus on how to move forward for P3P1.1... We\ndon't have a TF but we will accept proposals, otherwise can be\nconsidered in P3P2.0 timeframe.\n\n\nRegularly scheduled teleconference will be 11 am on Wednesdays. We\nprobably will use this time slot every other week, but people are\nencouraged to reserve this time in their schedules every week and use\nit for taskforce meetings, etc. Conference calls will start in two\nweeks.\n\nThere will public mailing-list and public group-page. Contact info etc\nwill be on the member-only page.\n\n\nP3P BEYOND HTTP\n\nWhat do we want to discuss with Web Services Architecture Group \ntomorrow?\nLorrie gave an overview and history of our attempts to get the WS\nfolks to pay attention to P3P.\n- key points to discuss at meeting:\n  - binding problem\n  - traveling problem (data may travel through multiple services with\n    differing policies\n  - where to put policy? soap, WSDL, etc.\n  - need liasons\n\nP3P on other things than Web Services..\nLorrie explained the issue identified with XForms that we have\nnot sufficient granularity like xml:lang\n\n\nCOMPACT POLICIES\n\nAccuracy/Expressiveness problems\n- what do we mean by accurate?\n- could clarify meaning of compact policy in the spec\n- problem may not be best called accuracy, but precision\n- decisions are being made about risk management\n- companies often use worst case scenario\n- may still be a problem with full policies\n- problem is more difficult with sensitive information\n(Article 8 in EU directive -- health, financial, political, race,\nsex, trade union membership)\n- trying to make P3P understandable has been difficult to date,\nmaking it more granular would make it worse\n- general discussion on how user agents handle these issues\n- concern about the fact that individuals that individuals choose\nstrong privacy rules without realizing the loss of functionality\n- this is why P3P focuses on use and specifically secondary use\n- discussion about the term \"linked\" in the spec.  Meant to be based\non the intention. We need to clarify this in the spec\n\n*** Agreement if compact policies were as expressive as full\npolicies, it would still not be expressive as some may like, but this\nshould be expressive enough for our needs (Brian reserved the right\nto question this again down the road)... assuming that we want to\nkeep compact policies\n\nRequired attributes\n- I, A & O - cookie may be necessary for functionality\n- user can't tell the difference between different secondary purposes\n- discussion of ways to set different preference to be accepted\nwithin the same cookie\n- discussion of issues with contractors that have access to cookies\n- most privacy issues come on the cookie replay not at cookie collection\n\nACTION: Lorrie: add issue to Bugzilla to consider modifications to\n2.3.2.7 -- could be changed \"MAY\" to \"SHOULD\" in order to cover\nimportance of replay -- this should be brought up with the whole\ngroup.  It is larger than just a compact policy question.\n\nACTION: lorrie: add issue to Bugzilla on clarifying what we mean by\ndata linked to a cookie\n\nUser Agent\n- verifying that Web developers aren't just complying with IE6 and\nnot doing full policy or proper compact policy, user agent behavior\nTF should discuss\n\nACTION: Lorrie: add Bugzilla issue for UA TF on guidelines for\nverification that CP site has full policy, complete CP, etc.\n\nPerformance issues\n- measurement and understanding of where performance hits are taken\n\nScope problems\n- discussions of problems with sites that only have one policy\n\n\n\nOTHER DISCUSSION\n\nACTION: Lorrie: add Bugzilla issue to consider standardizing\nSTATEMENT name attribute based on IBM extension\n\nACTION: Lorrie: Specify version #s in Bugzilla\n\nCertification\n- Can we get a seal program or logo for sites that are compliant?\n- Agreement that adoption is the first issue\n\n\nMEETING WITH LIBERTY ALLIANCE\n\nWe met with about a dozen representatives from the Liberty\nAlliance. They presented their LAP P3P Adaptation proposal V01.\n- don't have time to invent from scratch -- need to use something\nwith agreed upon semantics... use P3P as a starting point\n- separate activity in parallel with next release but not tied to it\n\nUse case\n- service asks for attributes and indicates privacy policy\n- attribute provider checks policy against users preferences for\nattribute in question\n- if service provider's policy is equal or stricter than the one\ndefined by user, data is released\n- if service provider's policy is less restrictive user is prompted\n\nPrivacy policies based on P3P compact policies\n\nPolicies describe restrictions related to the use of attribute data\n\nFive different policies that reflect different degrees of strictness\n- strict\n- cautious\n- moderate\n- flexible\n- casual\n\nFive elements\n- purpose, recipient, retention, access, remedies\n- mapped these to five policies\n\nWSC = web services consumer\n\nWSP = web services provider - previously collected information and\nuser consent and privacy rules\n\nprivacy context = policy for a particular piece of data and\ntransaction for a user = user privacy preference\n\nLiberty folks think 5 levels are needed for interoperability, compact\ndataflows, etc.?\n\nLorrie argued that 5 levels are not needed and that idententy service\nproviders could come up with whatever levels they want to offer their\nusers\n\nJoseph Reagle suggested that 5 levels help sites coalese and find a\ncommon level facilitating policy making in the market\n\nThere may be a potential collision problem when w3c gets around to\ndefining P3P/soap bindings... this should be anticipated and design\nshould avoid problems ... joint note on transferring P3P references\nwith SOAP?\n\ndiscussion of location vocabulary and privacy policies - work being\ndone at OMA, 3GPP\n- how to define location precisely\n- how location data will be used\n\nP3P group will continue to provide feedback to Liberty\n\n\nMarch 7\n\nThe Article 10 issues and UA behavior issues were discussed on a\nphone conference. Dialing in were Giles Hogben, Marc Langheinrich,\nand Marty Abrams\n\nARTICLE 10 VOCABULARY ISSUES\n\nGiles - plans to make detailed report with proposals before June Kiel\nmeeting\n\nambiguity on cookie processing requirements - set or replay?\n- storing a cookie on a users computer is an act of data processing\n- maybe offer two choices to WG\n   - requirement\n   - EU guideline\n\nnotification of user before data processing - to satisfy EU law\nhuman-readable portion of policy should be displayed to user before\ndata is processed\n- lots of practical and usability issues\n- maybe simultaneous display rather than consent\n- probably EU guideline\n\nability to specify jurisdiction\n- attribute of recipient element - EU, US safe harbor, non-EU\n- concern about regime-specific data element that may need to change\nas laws change\n\npreference language\n- want to highlight as important issue, but are ok waiting to v2\n- should discuss at Kiel meeting\n\n\nUSER AGENT BEHAVIOR\n\n- work on user friendly language for P3P vocab elements\n- work on other guidelines -- user agents should print P3P policies,\n   etc.\n\nMarty Abrams - layered notices\n- highlights notices - convention on things you cover, convention on\nlanguage\n- financial institutions very interested\n- short notice would hyperlink to long notice\n- relationship between long notice, p3p notice, and highlights notice\n   - highlights notice has 5 or 6 categories you are capturing info\n     about, context dependent\n   - more granularity and detail in P3P\n- what happens with P3P notice when translating to language for\nconsumers? statement don't always connect in logical way or include\nfull context. No consistency between user agent translations.\n- completeness and consumer communication aren't necessarily the same\nthing\n- interested in having P3P user agents link to highlights notice\n   instead of machine translation\n- alternatively need to reach a convention on human-readable\n   translation\n\nbrooks concerned about scope -- P3P does nice job of binding\npolicies... layered notices are cya\n\nbrian - lawyers would get more legalistic in full policy with layered\nnotices\n\nLorrie - use P3P human-readable fields to provide layered notice\n\nBrooks - not that much legal uncertainty -- regulators say that\nwhatever the users see first you have to live up to so they all have\nto be consistent\n\nEveryone would benefit from more specific testing of language that\nmakes sense to users\n- user agent testing in Europe - Giles, can test our user agent\n   strings, waiting for funding, hopefully will get funding by September\n- Microsoft user agent testing - results within next few weeks\n- AT&T probably testing in April or May\n\nhighlights notice glossary - go box by box and come up with vetted\nphrases and words that define an item - that group will convene in May\n- not everyone will use these terms -- voluntary effort\n- consensus that we would like notices group to try to come up with 1\nto 1 mapping of highlights notices to p3p vocab elements -- Lorrie\nwill work with them\n\nOther areas for user agent guidelines\n- EU-specific guidelines\n- printing and saving policies\n\nMicrosoft beta 1 is planned for January... they would like guidelines\nASAP so that it is possible for them to take them into account for\nthat release... will be very difficult to incorporate changes from WG\nlater\n\n\nOTHER DISCUSSION\n\nNorth American outreach\nAri\n- US federal government to require P3P\n- OMB will issue guidance in April\n- workshops for federal agencies\n- FTC privacy workshops\n\nWS Policy\nMicrosoft/IBM/BEA effort (not affiliated with W3C) - still\nunderspecified, but eventually should define bindings that may be\nhelpful in our efforts to define P3P beyond HTTP... political\nproblems due to this work taking place outside W3C\n\nJeremy had a long list of suggestions\n- show the user the difference between a consequence and a value\nproposition\n   - maybe two fields?\n   - maybe structured consequence field?\n- add a statement grouping mechanism so that user agents can display\nrelated statements together - grouping element is one mechanism to do\nthis, another is to add a group name attribute to the existing\nSTATEMENT element (ebay and windows media player examples)\n- add human readable intro section ? not much interest in this\n- consider adding human readable explanation strings to all elements\n   that don't currently have them ... generalize long description\n- note explaining why we did identified/identifiable, what it means,\nwhat linking means,  include some examples\n- access method or opt-in/opt-out method? we probably don't need that\n\nJeremy said it is likely that we will see preview of new IE P3P\nfunctionality in October when Microsoft shows preview at developer\nconference\n\n\nACTION: Lorrie, add Bugzilla issue to consider expanding definition\nof consequence field in spec and/or adding structure to consequence\nfield\n\nACTION: Lorrie, add Bugzilla issue to consider adding a statement\ngrouping mechanism, possible through statement grouping element or\ngroup name attribute\n\nACTION: Lorrie, add Bugzilla issue to consider adding human-readable\nexplanation strings to all elements that don't currently have them,\nperhaps generalizing LONG-DESCRIPTION\n\nACTION: Lorrie, add Bugzilla issue to draft statement (perhaps Note)\non identified/identifiable, linked, etc.\n\nACTION: Ari, write first draft of note on identified/identifiable/linked\n\n\nMEETING WITH WEB SERVICES ARCHITECTURE GROUP\n\nMike Champion, co-chair\n\nWSAG\n- focus on big picture ... no specifications, no specifics\n- little discussion on privacy\n\nMultiple places where P3P policy (reference) might live\n- soap header, discovery, or description layer?\n- WSDL? choreography? WS Policy?\n\n- web services may be service to service rather than user to service,\n   does that change anything with respect to P3P?\n\nworking together going forward -- first step: collaboration on use cases\n\n\n\n", "id": "lists-017-9154830"}, {"subject": "new P3P mailing list", "content": "We are in the process of reorganizing the P3P mailing lists in \npreparation for our restructuring of the P3P working groups (awaiting \nW3C membership vote and director decision in the coming weeks).\n\nWe will create a public P3P interest group mailing list that will be \npublicly archived and allow anyone to subscribe. Everyone who is \ncurrently subscribed to the P3P interest group mailing list, the P3P \nworkshop mailing list, or the P3P specification working group mailing \nlist will be subscribed automatically to this new mailing list. If you \nDO NOT want to be subscribed to this mailing list, please email \nrigo@w3.org\n\nWe will create a P3P 1.1 specification working group mailing list for \nmembers of that working group. This mailing list will be publicly \narchived, however, only members of the working group will be permitted \nto post messages. Everyone who attended or dialed in to the working \ngroup meeting in Boston last week will be subscribed. If your AC rep \nsigned you up for the P3P1.1 working group you will also be subscribed. \nIf you don't fall into one of these two categories and you would like \nto participate in the working group as a W3C member representative, an \ninvited expert, or a task force member, please email me to discuss. \nMEMBERS OF THE CURRENT SPEC GROUP MAILING LIST WILL NOT BE SUBSCRIBED \nTO THIS NEW LIST UNLESS THEY HAVE SIGNED UP TO PARTICIPATE IN THE \nP3P1.1 GROUP.\n\nThe new publicly-accessible P3P1.1 spec group home page is under \nconstruction at http://www.w3.org/P3P/Group/Specification/\n\nLorrie\n\n\n\n", "id": "lists-017-9179514"}, {"subject": "search featur", "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n", "id": "lists-017-9245499"}, {"subject": "search featur", "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n", "id": "lists-017-9251403"}, {"subject": "call for participation: Agent/Domain Relationship task forc", "content": "The P3P 1.1 Working Group (currently being chartered) is considering the\ncreation of a mechanism to declare relationships between sites/domains. This\nability would allow user agents to distinguish between secondary sites  that\nare truly third parties and ones that either are owned by the same company\nor are agents of the primary site. Current user agent implementations apply\nmore restrictive privacy rules to all sites in a different domain, treating\nthem as third-party when sometimes they are not. For more information:\nhttp://www.w3.org/P3P/2003/03-status.html\n\nI am the chair of the task force that will be working on this mechanism and\nwould like to have broad participation. If you have an interest in\nparticipating in this work, please let me know as soon as possible. We are\ngoing to try to have an initial teleconference this week to get the work\nstarted.\n\nThanks.\n\nJack Humphrey\n\n\n\n", "id": "lists-017-9257649"}, {"subject": "Call for Participation: W3C Workshop on the Future of P3P and on Enterprise Privacy Language", "content": "Dear all,\n\nW3C is holding a workshop on the long-term Future of P3P\nand Enterprise Privacy Languages. This workshop is being\norganized by the P3P Specification Working Group, a part of the\nW3C Privacy Activity. It is hosted by the Independent Center for Privacy \nProtection.\n\n      Date: 18 - 20 June 2003\n      Location: Kiel, Schleswig-Holstein, Germany\n\nThe Workshop page is at:\n\nhttp://www.w3.org/2003/p3p-ws/\n\nThe call for participation is available at:\n\n      http://www.w3.org/2003/p3p-ws/cfp-kiel.html\n\nThe full call for participation contains information about registration\nrequirements and procedures, and a link to the online registration\nform. The deadlines for this workshop are:\n\n      Position papers due: 24 May 2002\n      Registration closes: 4 June 2003\n      Complete program available: 7 June 2003\n\nPlease note that while this workshop is an open event, there is an\nattendance limit of 75. To ensure maximum diversity among participants,\nthe number of participants per organization will be limited in the\nevent that more than 75 individuals wish to participate.\n\nScope of the Workshop\n\nThe workshops on the first two days will discuss technology and policy\nconsiderations for the long-term future of P3P including new features or\napplications of P3P and longer-term P3P-related research and advanced\ndevelopment. Those might well address technical problems with P3P1.0,\npolicy goals that P3P may help address, requirements unmet by P3P1.0,\nand legal or policy questions that have arisen as a result of P3P\nimplementation with a perspective on the long-term future.\n\nOn the third day, the EPAL session will explore various industry use\ncase scenarios and regulatory templates for EPAL policies and\nenforcement scenarios.  The goal is to present EPAL capabilities in a\npublic forum and to collect interest and feedback on the idea of a more\nfine grained Enterprise Privacy Language (like EPAL e.g.).  It will also\ndiscuss which follow-up will be appropriate in this sector.\n\nGoal of the Workshop\n\nThe World Wide Web Consortium is sponsoring a workshop to discuss future\napplications of P3P and the Enterprise Privacy Languages, and get\nfeedback on what additional specifications or coordination efforts might\nbe necessary to support them. We are inviting position papers that\ndiscuss either technology or policy considerations (or both) for the\nlong-term future of P3P. Papers can be based on the current P3P\nspecification, but also go beyond backwards compatibility to P3P 1.0.\nThe results of this workshop will inform W3C's decision making on future\nP3P strategy, stimulate discussions of new developments and directions\nfor the long-term future of P3P and privacy metadata based solutions in\ngeneral and facilitate coordination with organizations engaged in\nrelated efforts.\n\nWe also want to evaluate the interest in enterprise privacy policy\nenforcement languages and to consider the relationship and/or\nintegration of such a language with respect to P3P. One proposal for\nEnterprise Privacy languages that has come to the attention of the\nWorkshop co-chairs is Enterprise Privacy Authorization Language (EPAL),\ndeveloped by IBM.  It is an example of such a formalized and\nfine-grained purpose-based enterprise privacy policy language that\nprovides enterprise enforcement opportunities for P3P 1.0 declarative\npolicies.\n\nThe goals for the Enterprise Privacy Languages area are:\n\n     * Evaluate EPAL as a basis for industry consensus in this area.\n     * Discuss other alternatives for enterprise privacy policy\n       languages based on position papers.\n     * Discuss next steps concerning a fine-grained\n       privacy/authorization language.\n\n\nExpected Audience\n\nWe expect several communities to contribute to the workshop:\n\n     * Organizations that develop P3P software\n     * Organizations with P3P-enabled Web sites\n     * Technologists from academia and industry who are experimenting\n       with P3P and related technologies\n     * Organizations that represent industry sectors on privacy issues\n       or promote industry self-regulatory efforts related to privacy\n       (industry associations, privacy seal providers, etc.)\n     * Privacy activists and organizations that represent individuals on\n       privacy issues\n     * Academic scholars who are studying privacy technology and policy\n       issues\n     * Organizations that are developing standards that may use P3P\n     * Government regulators and policy makers (and members of their\n       staff) from around the world\n\n\nDeliverables\n\nThe workshop is expected to result in the following deliverables:\n\n     * Workshop position papers\n     * Workshop presentations\n     * Workshop minutes\n     * Workshop Summary Reports on the future of P3P and Enterprise\n       Privacy Authorization Language\n\nThese will be published on the workshop home page.\n\nContact Information\n\nShould you have questions please feel free to contact one of the\nWorkshop chairs: Brian Zwit (AOL) <BrianP3P@aol.com>; Steven Adler (IBM)\n<adler1@us.ibm.com>; or Rigo Wenning (W3C), who also serves as Team\nContact <rigo@w3.org>.\n\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9265794"}, {"subject": "E&amp;Y P3P Dashboar", "content": "Dear all, \n\nhere is the latest P3P Dashboard which indicates a net increase in P3P\nadoption. \n\nBest, \n\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n\n\napplication/pdf attachment: E_Y_P3P_DashboardApr2003.pdf\n\n\n\n\n", "id": "lists-017-9279067"}, {"subject": "Re: new P3P plain English draft  please review by 13 Augus", "content": "Alexander,\n\nThank you for your comments. I would like to provide you with a few \nclarifications and answer the questions you raised.\n\nFirst, the document I circulated does not contain any new elements. \nThese are the same elements as are found in the P3P 1.0 Recommendation \nthat was published in April 2002. The new document simply translates \nthe legal definitions in that document into \"plain English.\"\n\nAs for the question of why the P3P 1.0 Recommendation offers the \nopportunity for web sites to use elements that describe practices that \nviolate data protection laws or fair information practice principles, \nthe answer is that these elements exist because they describe practices \nthat are in widespread use. By providing these elements we make it easy \nfor a P3P user agent to identify sites that have these practices. If we \ndid not provide these elements, sites with these practices would not be \nable to use P3P, and thus we would not know anything about their data \npractices without taking the time to read through a lengthy privacy \nstatement.\n\nYou may be interested in a study my colleagues and I have performed to \nassess the data practices at P3P-enabled web sites (mostly US sites) -- \nsee http://lorrie.cranor.org/pubs/icec03.html. We were able to \ndetermine, for example, that about two-thirds of these sites list their \ndata retention policy as 'indefinitely.' We can now easily capture a \nlot of information about the kinds of policies that are being offered. \nThis information may be useful in future debates about privacy \nregulation and enforcement.\n\nI think it would be quite useful if short P3P guides were developed for \nparticular jurisdictions. For example, a guide to P3P in Germany might \npoint out which P3P elements describe practices that are not legal in \nGermany or that are legal only if an opt-out is offered. In addition, \nrule sets could be developed for P3P user agents that would warn users \nor block access to sites that declare practices that violate laws in a \nparticular jurisdiction.\n\nRegards,\n\nLorrie Cranor\n\n\nOn Thursday, August 7, 2003, at 04:31  AM, LDA Brandenburg wrote:\n\n> Lorrie,\n>\n> thank you for sending the P3P 1.0 element definitions and translations.\n> Although I have not participated in the discussions for some time I'd \n> like\n> to make several points from the perspective of a lawyer and data \n> protection\n> commissioner. I realize that the P3P concept is to offer a broad \n> technical\n> platform for the communication of privacy information in machine and \n> human\n> readable form.\n> However, against the background of the European Data Protection \n> Directive\n> the new elemtns and definitions raise some questions:\n>\n> 1. Why should P3P offer under ACCESS the options of  restricting \n> access to\n> contact information and (only) some of the other \n> informationidentifying the\n> user or only to contact information or excluding contact information, \n> and\n> most importantly, why should P3P provide an element for denying users \n> any\n> access to information identifying them ?\n>\n> 2. Under PURPOSE the elements contain under 'admin' the purpose \"To \n> perform\n> web site and system administration\". Here the questions are: Will\n> user-related information be used for this purpose and if so, why should\n> this be necessary ?\n>\n> 3. Still under PURPOSE the element \"pseudo-decision\" is translated \n> into \"To\n> make decisions that directly affect you without identifying you, for\n> example to display content or ads based on links you clicked on\n> previously\". In this context it's worth noting that not only German Law\n> requires to offer users an opt-out even against profiling under \n> pseudonyms\n> but also the International Working Group on Data Protection in\n> Telecommunications has supported such an opt-out on a worldwide basis \n> and\n> e.g. AOL Europe have accepted it.\n>\n> 4. Under RETENTION there is an element 'indefinitely'. It is quite \n> obvious\n> that indefinite retention would not be acceptable under any data \n> protection\n> legislation worldwide. Therefore P3P should not provide an element\n> suggesting that there may be such a legal option.\n>\n>\n> Please change my e-mail address  in your address list into\n> <dix@lda.brandenburg.de>.\n>\n> Thanks very much and best wishes,\n>\n> Alexander Dix\n>\n>\n>\n> Lorrie Cranor schrieb:\n>\n>> The user agent task force of the P3P specification working group\n>> received some good feedback on our previous draft translation of the\n>> P3P element definitions into plain English. Based on this feedback we\n>> have made extensive revisions to our draft. We invite feedback on our\n>> revised draft posted at http://www.w3.org/P3P/2003/p3p-translation.htm\n>> Please send this feedback to us no later than 13 August 2003.\n>>\n>> Note that the proposed plain English translations are found in the\n>> fifth column of the matrix (in blue). This is the wording that we are\n>> recommending that user agent implementers use to display information\n>> about P3P policies to end users. We expect to provide translations \n>> into\n>> other languages as well. The plain language translations should be\n>> consistent with the full definitions given in the P3P specification\n>> (shown in the third column of the matrix).\n>>\n>> Lorrie\n>>\n>> --\n>> Lorrie Faith Cranor - http://lorrie.cranor.org/\n>> P3P Specification Working Group Chair - http://www.w3.org/p3p/\n>> New book: Web Privacy with P3P - http://p3pbook.com/\n>\n>\n>\n> --\n> Dr. Alexander Dix, LL.M.\n>\n> Der Landesbeauftragte\n> f?r den Datenschutz und\n> f?r das Recht auf Akteneinsicht\n> Brandenburg\n>\n> Stahnsdorfer Damm 77\n> D-14532 Kleinmachnow\n>\n> Commissioner for Data Protection\n> and Access to Information\n> Brandenburg\n> Germany\n>\n> Tel.: ++49/(0)33203/356-0\n> Fax:  ++49/(0)33203/356-49\n> Internet: http://www.lda.brandenburg.de\n>\n> Diese Nachricht ist f?r den oben genannten Empf?nger bestimmt.\n> Wenn Sie nicht dieser Empf?nger sind, lesen, kopieren oder ?bermitteln\n> Sie bitte diese Nachricht nicht, sondern informieren Sie den\n> Absender durch eine Antwort-Mail und l?schen Sie die Nachricht\n> dann in Ihrem System. Vielen Dank.\n>\n> This message is intended for the individual or entity named above.\n> If you are not the intended recipient, please do not read, copy,\n> use or disclose this communication to others;\n> also please notify the sender by replying to this message, and then\n> delete it from your system. Thank you.\n>\n>\n>\n\n\n\n", "id": "lists-017-9308769"}, {"subject": "P3P: intersting articl", "content": "http://www.ebusinessiq.com/special%20interests/e-commerce/577-eBusinessIQ%20e-comm.html\n\nMost interesting to me, they report:\n<quote>\nIn fact, according to research conducted by Harris Interactive, 64% of\nonline consumers decide not to purchase on a site because they are\nunsure of how their personal data is being used. And according to The\nCustomer Respect Group, an online research firm, this uncertainty is\noften due to the fact that no privacy policy exists. Of the 450 sites\nthe group researched for its study on privacy policies, 17.7% did not\neven provide consumers with an online privacy policy.\n</quote>\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9343695"}, {"subject": "EPAL:  Media Release Fictions Undermine Credibilit", "content": "As a result of a prize that IBM's been awarded, I've had a look at \nIBM's EPAL media release of 9 July 2003, at:\nhttp://www-306.ibm.com/software/swnews/swnews.nsf/n/ades5pakbu?OpenDocument&Site=default\n\nThe award citation also says that \"On December 1, 2003, IBM announced \nit was turning EPAL over to the World Wide Web Consortium (W3C) in \nthe hopes that it will become an international standard and will help \nautomate privacy management tasks, improve consumer trust and reduce \nthe cost of privacy compliance\".  But IBM's site-search doesn't \nlocate a media release to that effect.\n\n(On searching my public-p3p archive, I see that Rigo has mentioned \nEPAL in three emails over the last 9 months, including one that \nmentioned it being presented in Sydney in September, at a conference \nadjacent to the World Privacy Commissioners conference).\n\n\nCall me an inveterate sceptic by all means, but a quick analysis of \nthe information in the media release is as follows.\n\nThe title of the media release refers to \"A New Language to Automate \nPrivacy Compliance\".\n\nThe opening sentence calls EPAL \"the first computer language to \nprovide enterprises with a way to automate the enforcement of privacy \npolicies among IT applications and systems\".\n\nThe 2nd para. repeats \"automate compliance to those rules\".\n\nThe 3rd para. again refers to \"automate tedious privacy management \ntasks\".  But by that stage the signal is becoming attenuated, because \nit's unclear whether \"building enforcement into enterprise \napplications\" requires work on the applications themselves, or just \nwork using the EPAL language.\n\nFinally, in the 4th para., we get a quotation from a named person \nrather than impersonal IBM, and this says that EPAL is \"to help \nautomate the enforcement\".  So now we might be talking about \nsomething a little different.\n\n\nLet's resort to the real world of IT applications for a moment.\n\nIt's a bit difficult to see how EPAL could \"automate the enforcement \nof privacy policies among IT applications and systems\".  We're by \ndefinition talking about 'legacy systems' here.\n\nPolicies expressed using EPAL (or indeed P3P) could conceivably be \nused as a tool for auditors checking applications for compliance with \nprivacy policy statements.  That could extend to the design of \ntest-data sets, in order to establish what the application actually \ndoes in instances that the privacy policy declares as being variously \nblack, white, and grey.\n\nEPAL could \"automatically enforce\" those policies/rules if the \napplications were expressed in rule-form - in which case the addition \nof rules that express the privacy policies would directly change the \nprocessing of the next transaction that triggered any of the new \nrules.\n\nBut I'm unaware of any mechanism whereby the expression of rules \ncould affect the algorithms expressed in 1st, 2nd, 3rd generation \nlanguages, or even the functioning of applications expressed in 4th \ngeneration delcarative languages:\nhttp://www.anu.edu.au/people/Roger.Clarke/SOS/SwareGenns.html (1991)\n\nThose are the languages in which virtually all applications are expressed.\n\nSo the message has been garbled by public relations people.  And \nreporters around the world are doubtless mis-reporting it, just as \nthey were supposed to do.  For example, Privacy Manager's award \ncitation says that EPAL \"applies privacy rules across interconnected \nbusiness systems\".\n\nEven so, Arvind Krishna, vice president of security products, Tivoli \nSoftware, appears to be responsible for the media release.  And it \ntold serious porkies (sorry:  Cockney rhyming slang:  'pork pie' => \n'lie').  Or would it be preferable for me to dissemble like IBM did, \ne.g. 'the media release used language that could be interpreted as \nhaving been contrived so as to convey a meaning that was considerably \ndifferent from and more interesting than the interpretation that a \nreasonable person who was reasonably informed would have done'?\n\n\n\nThe author of the underlying paper, Matthias Schunter, IBM Zurich \nResearch Laboratory appears to be not guilty.  His document says \nthings like:\n\n\"The **goals** for the EPAL language are the following.\n*   Provide the ability to encode an enterprise's privacy-related \ndata-handling policies and practices.\n*   A language that can be imported and enforced by a \nprivacy-enforcement system\"\n\n\"a privacy creation tool from one company may create an EPAL policy, \nand **a privacy enforcement tool** from another company **may read-in \nthe EPAL policy and then enforce it**\"\n\nMatthias Schunter's work I should read.  Although it would be nice if \nthere was an explanation as to precisely what this 'structured \nprivacy policy declaration language' does that P3P doesn't already \ndo.  And we all know how far short P3P has fallen from its original \naspirations (to date! I have to add 'to date'!).\n\n\nSome other bits from the media release, which *do* make sense:\n\nEnterprise Privacy Authorization Language (EPAL) is described as a \n\"an XML language that enables organizations to enforce P3P policies \nbehind the Web, among applications and databases\".\n\n\"A team of students at North Carolina State University has developed \nthe first tool to help developers leverage EPAL - the Privacy \nAuthoring Editor. The new tool helps companies author and edit \nprivacy policies using EPAL while allowing for the expression of \nricher and more complex privacy rules than current standards allow.\".\n\nThe example that the media release provides as being able to be \nexpressed \"in a language that applications and privacy management \ntools can understand\" is as follows:  \"Members of the physician group \ncan read protected health information for the purpose of medical \ntreatment, only if the physician is the primary care physician and \nthe patient or the patient's family is notified in advance\".\n\nI've done an amount of work in that particular area, summarised at:\nhttp://www.anu.edu.au/people/Roger.Clarke/EC/eConsent.html\n\n\n-- \nRoger Clarke              http://www.anu.edu.au/people/Roger.Clarke/\n\nXamax Consultancy Pty Ltd, 78 Sidaway St, Chapman ACT 2611 AUSTRALIA\n                 Tel: +61 2 6288 1472, and 6288 6916\nmailto:Roger.Clarke@xamax.com.au            http://www.xamax.com.au/\n\nVisiting Professor in the eCommerce Program, University of Hong Kong\nVisiting Professor in the Baker Cyberspace Law & Policy Centre, U.N.S.W\nVisiting Fellow in Computer Science, Australian National University\n\n\n\n", "id": "lists-017-9350630"}, {"subject": "Re: EPAL:  Media Release Fictions Undermine Credibilit", "content": "Hi Roger,\n\n\nhere are some basic facts on EPAL that may help you separate facts from \nfiction:\n- EPAL is a policy language. Like any other piece of XML, it does not \nenforce anything.\n   However, it can be used to express fine-grained enterprise-internal \npolicies that\n   can then be read and enforced by EPAL-aware systems or middleware.\n   EPAL has been designed to be easy to enforce.\n- We have submitted EPAL as a member publication to W3C. We are currently \nlooking\n   for partners to actually start a working group to standardize EPAL in W3C.\n   See: http://www.w3.org/Submission/2003/SUBM-EPAL-20031110/\n- An example enforcement engine for J2EE has been published at\n   http://alphaworks.ibm.com/tech/dpm\n- EPAL and P3P augment each other: EPAL is a fine-grained enterprise-internal\n   privacy policy language while P3P is meant for customer-facing privacy \nnotices.\n   As a consequence, EPAL contains enterprise internals that would be \nabstracted away\n   by the P3P notice (e.g., P3P does not specify what persons/group inside \nan enterprise\n   can use what data but rather only specifies what the complete enterprise \ncan do).\n   fyi: I am a member of the P3P 1.1 group as well (this is how I received \nyour mail).\n\nIf you want to get more (technical) information just send a note or call.\nThe business side of EPAL (non-technical questions) is covered by Steven \nAdler <adler1@us.ibm.com>.\n\nRegards,\n  matthias\n\nAt 05:06 PM 12/11/2003 +1100, Roger Clarke wrote:\n\n>As a result of a prize that IBM's been awarded, I've had a look at IBM's \n>EPAL media release of 9 July 2003, at:\n>http://www-306.ibm.com/software/swnews/swnews.nsf/n/ades5pakbu?OpenDocument&Site=default\n>\n>The award citation also says that \"On December 1, 2003, IBM announced it \n>was turning EPAL over to the World Wide Web Consortium (W3C) in the hopes \n>that it will become an international standard and will help automate \n>privacy management tasks, improve consumer trust and reduce the cost of \n>privacy compliance\".  But IBM's site-search doesn't locate a media release \n>to that effect.\n>\n>(On searching my public-p3p archive, I see that Rigo has mentioned EPAL in \n>three emails over the last 9 months, including one that mentioned it being \n>presented in Sydney in September, at a conference adjacent to the World \n>Privacy Commissioners conference).\n>\n>\n>Call me an inveterate sceptic by all means, but a quick analysis of the \n>information in the media release is as follows.\n>\n>The title of the media release refers to \"A New Language to Automate \n>Privacy Compliance\".\n>\n>The opening sentence calls EPAL \"the first computer language to provide \n>enterprises with a way to automate the enforcement of privacy policies \n>among IT applications and systems\".\n>\n>The 2nd para. repeats \"automate compliance to those rules\".\n>\n>The 3rd para. again refers to \"automate tedious privacy management \n>tasks\".  But by that stage the signal is becoming attenuated, because it's \n>unclear whether \"building enforcement into enterprise applications\" \n>requires work on the applications themselves, or just work using the EPAL \n>language.\n>\n>Finally, in the 4th para., we get a quotation from a named person rather \n>than impersonal IBM, and this says that EPAL is \"to help automate the \n>enforcement\".  So now we might be talking about something a little different.\n>\n>\n>Let's resort to the real world of IT applications for a moment.\n>\n>It's a bit difficult to see how EPAL could \"automate the enforcement of \n>privacy policies among IT applications and systems\".  We're by definition \n>talking about 'legacy systems' here.\n>\n>Policies expressed using EPAL (or indeed P3P) could conceivably be used as \n>a tool for auditors checking applications for compliance with privacy \n>policy statements.  That could extend to the design of test-data sets, in \n>order to establish what the application actually does in instances that \n>the privacy policy declares as being variously black, white, and grey.\n>\n>EPAL could \"automatically enforce\" those policies/rules if the \n>applications were expressed in rule-form - in which case the addition of \n>rules that express the privacy policies would directly change the \n>processing of the next transaction that triggered any of the new rules.\n>\n>But I'm unaware of any mechanism whereby the expression of rules could \n>affect the algorithms expressed in 1st, 2nd, 3rd generation languages, or \n>even the functioning of applications expressed in 4th generation \n>delcarative languages:\n>http://www.anu.edu.au/people/Roger.Clarke/SOS/SwareGenns.html (1991)\n>\n>Those are the languages in which virtually all applications are expressed.\n>\n>So the message has been garbled by public relations people.  And reporters \n>around the world are doubtless mis-reporting it, just as they were \n>supposed to do.  For example, Privacy Manager's award citation says that \n>EPAL \"applies privacy rules across interconnected business systems\".\n>\n>Even so, Arvind Krishna, vice president of security products, Tivoli \n>Software, appears to be responsible for the media release.  And it told \n>serious porkies (sorry:  Cockney rhyming slang:  'pork pie' => 'lie').  Or \n>would it be preferable for me to dissemble like IBM did, e.g. 'the media \n>release used language that could be interpreted as having been contrived \n>so as to convey a meaning that was considerably different from and more \n>interesting than the interpretation that a reasonable person who was \n>reasonably informed would have done'?\n>\n>\n>\n>The author of the underlying paper, Matthias Schunter, IBM Zurich Research \n>Laboratory appears to be not guilty.  His document says things like:\n>\n>\"The **goals** for the EPAL language are the following.\n>*   Provide the ability to encode an enterprise's privacy-related \n>data-handling policies and practices.\n>*   A language that can be imported and enforced by a privacy-enforcement \n>system\"\n>\n>\"a privacy creation tool from one company may create an EPAL policy, and \n>**a privacy enforcement tool** from another company **may read-in the EPAL \n>policy and then enforce it**\"\n>\n>Matthias Schunter's work I should read.  Although it would be nice if \n>there was an explanation as to precisely what this 'structured privacy \n>policy declaration language' does that P3P doesn't already do.  And we all \n>know how far short P3P has fallen from its original aspirations (to date! \n>I have to add 'to date'!).\n>\n>\n>Some other bits from the media release, which *do* make sense:\n>\n>Enterprise Privacy Authorization Language (EPAL) is described as a \"an XML \n>language that enables organizations to enforce P3P policies behind the \n>Web, among applications and databases\".\n>\n>\"A team of students at North Carolina State University has developed the \n>first tool to help developers leverage EPAL - the Privacy Authoring \n>Editor. The new tool helps companies author and edit privacy policies \n>using EPAL while allowing for the expression of richer and more complex \n>privacy rules than current standards allow.\".\n>\n>The example that the media release provides as being able to be expressed \n>\"in a language that applications and privacy management tools can \n>understand\" is as follows:  \"Members of the physician group can read \n>protected health information for the purpose of medical treatment, only if \n>the physician is the primary care physician and the patient or the \n>patient's family is notified in advance\".\n>\n>I've done an amount of work in that particular area, summarised at:\n>http://www.anu.edu.au/people/Roger.Clarke/EC/eConsent.html\n>\n>\n>--\n>Roger Clarke              http://www.anu.edu.au/people/Roger.Clarke/\n>\n>Xamax Consultancy Pty Ltd, 78 Sidaway St, Chapman ACT 2611 AUSTRALIA\n>                 Tel: +61 2 6288 1472, and 6288 6916\n>mailto:Roger.Clarke@xamax.com.au         http://www.xamax.com.au/\n>\n>Visiting Professor in the eCommerce Program, University of Hong Kong\n>Visiting Professor in the Baker Cyberspace Law & Policy Centre, U.N.S.W\n>Visiting Fellow in Computer Science, Australian National University\n\n-- Dr. Matthias Schunter <mts (at) zurich.ibm.com> ---\nIBM Zurich Research Laboratory,   Ph. +41 (1) 724-8329\nFax +41-1-724-8953;      More info at www.schunter.org\nPGP Fingerprint    989AA3ED 21A19EF2 B0058374 BE0EE10D\n\n\n\n", "id": "lists-017-9364931"}, {"subject": "Privacy Bird released as open sourc", "content": "Dear all, \n\nAT&T has released to code for privacy bird[1] as open source. \n\nI quote from the release-notes[2]:\nAT&T is making the C++ source code to Privacy Bird available to open\nsource software developers. This code is provided as-is with no\ndocumentation or support. Developers may find the code useful as a\nstarting point for developing their own P3P user agents, for adding\nfeatures to Privacy Bird, or for porting it to other platforms. The\nincluded APPEL engine may be useful for other purposes as well. The\ndownloadable tar ball includes the code developed for Windows as well as\na tar ball of files that have had the Windows-specific code removed so\nthat they can be compiled on a Unix system (this code currently has no\nGUI support).\n\nW3C very much hopes, that this code is taken up for further development\n\n  1. http://www.privacybird.com/\n  2. http://www.privacybird.com/cgi-bin/sourcedownload\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9382036"}, {"subject": "Link from translation sit", "content": "Hello,\n \nI am trying to find the best person to discuss exchanging links with\nyour site. We have a high quality directory as part of our translation\nservices site which ranks highly in the search engines and attracts many\nthousands of visitors per day. We have just expanded the categories and\nare now looking to add additional relevant sites. There is no cost for\ninclusion; all we require is a link back from your site.\n \nThe directory is here:\nLanguage Directory <http://www.appliedlanguage.com/directory/>  \n \nIf you could put me in touch with the relevant person or point me in the\ndirection of a part of your site to do this it would be appreciated.\nAlternatively you can go and add your site details here:\nSubmit Site <http://www.appliedlanguage.com/add_site.shtml> \n \nThere are a number of return link options here:\nLink Text <http://www.appliedlanguage.com/link_text.aspx> \n \n \nI look forward to hearing from you\n \nJohn Snow\nProject Manager\n \ntranslation\n+44 (0) 7000 52 7000\n <mailto:john@appliedlanguage.com> mailto:john@appliedlanguage.com\nTranslation services for 140 languages and all project types\n <http://www.appliedlanguage.com/> ALS Translation Services\n \n\n\n\n\n\n\n\n\n\n\n", "id": "lists-017-9389687"}, {"subject": "Used Formwork/Peri Dok", "content": "Dear Sirs,\n\nwe have for sale used NOE TOP 2000 included all accesories and DOKA FRAMAX ALUMINIUM and STEEL.\n\nList and Photos can we send you per e mail.\n\nAlso for sale H20 Beams 16 000 ml and Props 350, 410 and 550, and Crane LIEBHERR 71 C , Peiner SMK 320.\n\nIf Interest can we send you pictures and List per e mail.\n\nBest Regards.\n\nS.BUTAUX.\n\nVISIT OUR WEB SITE FOR USED BUILDING MACHINERY.\nWWW.EQUIPMENT-CENTER.DE\n\n\n\n", "id": "lists-017-9397883"}, {"subject": "FYI: Web Firms Choose Profit Over Privac", "content": "http://www.washingtonpost.com/ac2/wp-dyn/A54888-2003Jun30?language=printer\n...\nMany firms use tactics designed to hide their intent to gather and profit \nfrom the data they collect, information that grows in value as more and \nmore people use the Internet for information and shopping....\nWith the onslaught of spam, almost all companies promise not to sell \nconsumer data. But many don't mention that such information is rented. This \nmeans that the list owner won't release the data to an outside marketer, \nbut it will send messages to the list on the outsider's behalf. Targeted \nlists available for rent number in the thousands, including those from \nmagazines, professional organizations and even political interest groups \nsuch as Republicans for Jesus.\n...\n\n\n\n", "id": "lists-017-9428133"}, {"subject": "FYI: Web Firms Choose Profit Over Privac", "content": "http://www.washingtonpost.com/ac2/wp-dyn/A54888-2003Jun30?language=printer\n...\nMany firms use tactics designed to hide their intent to gather and profit \nfrom the data they collect, information that grows in value as more and \nmore people use the Internet for information and shopping....\nWith the onslaught of spam, almost all companies promise not to sell \nconsumer data. But many don't mention that such information is rented. This \nmeans that the list owner won't release the data to an outside marketer, \nbut it will send messages to the list on the outsider's behalf. Targeted \nlists available for rent number in the thousands, including those from \nmagazines, professional organizations and even political interest groups \nsuch as Republicans for Jesus.\n...\n\n\n\n", "id": "lists-017-9434927"}, {"subject": "P3P KielWS Minutes publishe", "content": "http://www.w3.org/2003/p3p-ws/minutes.html\n\nBest, \n\nRigo\n\n\n\n", "id": "lists-017-9441955"}, {"subject": "new P3P plain English draft  please review by 13 Augus", "content": "The user agent task force of the P3P specification working group \nreceived some good feedback on our previous draft translation of the \nP3P element definitions into plain English. Based on this feedback we \nhave made extensive revisions to our draft. We invite feedback on our \nrevised draft posted at http://www.w3.org/P3P/2003/p3p-translation.htm  \nPlease send this feedback to us no later than 13 August 2003.\n\nNote that the proposed plain English translations are found in the \nfifth column of the matrix (in blue). This is the wording that we are \nrecommending that user agent implementers use to display information \nabout P3P policies to end users. We expect to provide translations into \nother languages as well. The plain language translations should be \nconsistent with the full definitions given in the P3P specification \n(shown in the third column of the matrix).\n\nLorrie\n\n--\nLorrie Faith Cranor - http://lorrie.cranor.org/\nP3P Specification Working Group Chair - http://www.w3.org/p3p/\nNew book: Web Privacy with P3P - http://p3pbook.com/\n\n\n\n", "id": "lists-017-9449322"}, {"subject": "P3P/EPAL Workshop Position papers publishe", "content": "Dear all, \n\nas announced some time ago, W3C is organizing a W3C Workshop on the long\nterm Future of P3P and Enterprise Privacy Languages[1] together with the \nIndependent Centre for Privacy Protection Schleswig-Holstein[2].  \n\nThe position papers are now published[3] and the program committee will now\nchoose the ones that will be presented at the Workshop. \n\nRegistration is still open.\n\n  1. http://www.w3.org/2003/p3p-ws/\n  2. http://www.datenschutzzentrum.de/\n  3. http://www.w3.org/2003/p3p-ws/pp/Overview.html\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9479071"}, {"subject": "P3P/EPAL Workshop Position papers publishe", "content": "Dear all, \n\nas announced some time ago, W3C is organizing a W3C Workshop on the long\nterm Future of P3P and Enterprise Privacy Languages[1] together with the \nIndependent Centre for Privacy Protection Schleswig-Holstein[2].  \n\nThe position papers are now published[3] and the program committee will now\nchoose the ones that will be presented at the Workshop. \n\nRegistration is still open.\n\n  1. http://www.w3.org/2003/p3p-ws/\n  2. http://www.datenschutzzentrum.de/\n  3. http://www.w3.org/2003/p3p-ws/pp/Overview.html\n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9487006"}, {"subject": "web site P3P adoption repor", "content": "Report: Web Privacy Policies Confuse Net Surfers\nWed Jun 25,12:03 AM ET\nhttp://news.yahoo.com/news?tmpl=story2&cid=581&u=/nm/20030625/tc_nm/tech_privacy_dc&printer=1\n\nBy Andy Sullivan\n\nWASHINGTON (Reuters) - \"Privacy policies\" that explain a company's \nWeb surveillance habits have done little to dispel confusion among \nInternet users about how they are tracked online, according to a \nreport released on Wednesday.\n\nThe dense, legalistic documents that many commercial Web sites post \nto explain their data-collection habits are more likely to provide \nfalse reassurance than clarity to Web surfers, the University of \nPennsylvania's Annenberg Public Policy Center found.\n\n[...]\n\nTurow recommended that Web sites be required to translate their \nprivacy policies into a machine-readable code called P3P that would \nallow users to automatically steer away from sites that they would \nfind too invasive. P3P was introduced over a year ago but has not \nbeen widely adopted.\n\nWeb sites should also be required to disclose in plain language what \nthey know about their visitors, what they have done with that \ninformation, and what they plan to learn about them, he said.\n\n\n\n------------------------------------------------------------------------\nCopyright ? 2003 Reuters Limited. All rights reserved. Republication \nor redistribution of Reuters content is expressly prohibited without \nthe prior written consent of Reuters. Reuters shall not be liable for \nany errors or delays in the content, or for any actions taken in \nreliance thereon.\nCopyright ? 2003 Yahoo! Inc. All rights reserved.\nQuestions or Comments\nPrivacy Policy -Terms of Service - Copyright Policy - Ad Feedback\n\n\n\n", "id": "lists-017-9495139"}, {"subject": "P3P elements in plain languag", "content": "The user agent task force of the P3P specification working group has a \ndraft plain language translation of the P3P elements now available at \nhttp://www.w3.org/P3P/2003/p3p-translation.htm  A version of this is \nlikely to get incorporated into the P3P 1.1 Specification.  This is the \nlanguage we will be recommending that future P3P user agents use to \npresent P3P policy information to end users.  We would appreciate any \nfeedback anyone might have on this translation.\n\n\n\n", "id": "lists-017-9503016"}, {"subject": "New Public mailing list - publicp3", "content": "Purpose: This is the Interest Group's mailing list. It serves for general\nprivacy discussions and announcements concerning P3P.\n\n\n\n1.  http://www.w3.org/Privacy/Activity\n\n\n\n", "id": "lists-017-9531702"}, {"subject": "web site P3P adoption repor", "content": "We released the following report today: \"An Analysis of P3P Deployment \non Commercial, Government, and Children?s Web Sites as of May 2003\"\n\nYou can download it from:\nhttp://www.research.att.com/projects/p3p/p3p-census-may03.pdf\n\nHere is the executive summary:\n\nThe Platform for Privacy Preferences (P3P) provides a standard \ncomputer-readable format for privacy policies and a protocol that \nenables web browsers to read and process these policies automatically. \nWe developed software to query a set of web sites for P3P policies, \ncheck the validity of each policy, and analyze the information \npractices it describes. We used this software to analyze 538 \nP3P-enabled web sites found by checking for P3P policies on 5,856 web \nsites on 6 May 2003. The sites we checked for P3P policies were taken \nfrom several lists of popular web sites, as well as from ?crawling? \nindexes of shopping, news, children?s and government web sites. We \npresent the first major analysis of the data practices of P3P-enabled \nweb sites.\n\nOur system used the P3P evaluation engine built into the AT&T Privacy \nBird P3P user agent to analyze the P3P policies we discovered. We \nchecked these policies against Privacy Bird?s standard ?high,? \n?medium,? and ?low? settings as well as against 62 other ?rule sets? \nthat we developed.\n\nA comparison of our results with previous studies indicates that P3P \nadoption is increasing over time [1][14]. Adoption remains highest for \nthe most popular web sites.\n\nWe found a large number of errors in the P3P policies of the sites we \nevaluated. About one third of the P3P-enabled sites had technical \nerrors. In many cases these errors were due to use of syntax from a \ndraft version of the P3P specification that is not permitted by the \nfinal P3P 1.0 Recommendation [6]. However, 7% of the P3P-enabled sites \nhad critical errors that prevented their evaluation by our Privacy Bird \nevaluation engine. We also found 74 sites that violated the P3P \nspecification by posting P3P compact policies without their \ncorresponding full P3P policies.\n\nOur analysis of data collection at P3P-enabled web sites indicates that \nmost sites collect computer information, click stream information, and \ndemographic data. Almost as many sites also collect online contact \ninformation, physical contact information, interactive data, and unique \nidentifiers. The majority of sites also collect preference information, \npurchase information, and state management information (cookies). \nHowever, fewer sites collect financial information (which excludes \ninformation such as credit card numbers used only as part of a \npurchase). The least collected information is content (email messages, \nbulletin board postings, etc.), government-issued identifiers, health \ninformation, political information, location information (for example \nGPS positioning data), and information not falling into any of the \npre-defined categories.\n\nAlmost all web sites reported using data for completion and support of \nthe activity for which data was provided, web site and system \nadministration, and research and development. The majority of sites \nalso reported using data for email and postal mail marketing, one-time \ntailoring of the site content, and pseudonymous profiling. \nSubstantially fewer sites reported using data for telemarketing or \nprofiling in which individuals are identified. Very few sites reported \nusing data for historical preservation or other purposes that do not \nfall into these categories.\n\nAbout half the web sites we studied indicated that they share \npersonally identifiable data with parties other than agents who use \ndata for the purpose for which it was provided. 46% of these sites \nindicate that they offer third-party choice (opt-in or opt-out to this \nsharing).\n\nMost web sites reported providing some access provisions for \nindividuals wishing to find out what data of theirs was in a web site?s \nrecords as well as some dispute resolution option for disputes related \nto their privacy policy. However, most sites reported that they did not \nhave a data retention policy covering all of the data they collected at \ntheir site.\n\nAs debates continue about the need for further privacy legislation and \nthe effectiveness of industry self-regulation in the privacy area, \nautomated analysis of the data practices of P3P-enabled web sites can \nprovide valuable information. Furthermore, as US government web sites \nbegin posting P3P policies to comply with the privacy requirements of \nsection 208 of the E-Government Act of 2002 [16], we can monitor \ncompliance with these requirements. We plan to repeat our experiments \non a regular basis to allow for longitudinal analysis of P3P policies. \nIn the future we may also expand the list of web sites we analyze, \ndevelop additional rule sets to facilitate more detailed analysis, and \nexpand our analysis to include P3P compact policies.\n\n\n\n", "id": "lists-017-9558196"}, {"subject": "web site P3P adoption repor", "content": "We released the following report today: \"An Analysis of P3P Deployment \non Commercial, Government, and Children?s Web Sites as of May 2003\"\n\nYou can download it from:\nhttp://www.research.att.com/projects/p3p/p3p-census-may03.pdf\n\nHere is the executive summary:\n\nThe Platform for Privacy Preferences (P3P) provides a standard \ncomputer-readable format for privacy policies and a protocol that \nenables web browsers to read and process these policies automatically. \nWe developed software to query a set of web sites for P3P policies, \ncheck the validity of each policy, and analyze the information \npractices it describes. We used this software to analyze 538 \nP3P-enabled web sites found by checking for P3P policies on 5,856 web \nsites on 6 May 2003. The sites we checked for P3P policies were taken \nfrom several lists of popular web sites, as well as from ?crawling? \nindexes of shopping, news, children?s and government web sites. We \npresent the first major analysis of the data practices of P3P-enabled \nweb sites.\n\nOur system used the P3P evaluation engine built into the AT&T Privacy \nBird P3P user agent to analyze the P3P policies we discovered. We \nchecked these policies against Privacy Bird?s standard ?high,? \n?medium,? and ?low? settings as well as against 62 other ?rule sets? \nthat we developed.\n\nA comparison of our results with previous studies indicates that P3P \nadoption is increasing over time [1][14]. Adoption remains highest for \nthe most popular web sites.\n\nWe found a large number of errors in the P3P policies of the sites we \nevaluated. About one third of the P3P-enabled sites had technical \nerrors. In many cases these errors were due to use of syntax from a \ndraft version of the P3P specification that is not permitted by the \nfinal P3P 1.0 Recommendation [6]. However, 7% of the P3P-enabled sites \nhad critical errors that prevented their evaluation by our Privacy Bird \nevaluation engine. We also found 74 sites that violated the P3P \nspecification by posting P3P compact policies without their \ncorresponding full P3P policies.\n\nOur analysis of data collection at P3P-enabled web sites indicates that \nmost sites collect computer information, click stream information, and \ndemographic data. Almost as many sites also collect online contact \ninformation, physical contact information, interactive data, and unique \nidentifiers. The majority of sites also collect preference information, \npurchase information, and state management information (cookies). \nHowever, fewer sites collect financial information (which excludes \ninformation such as credit card numbers used only as part of a \npurchase). The least collected information is content (email messages, \nbulletin board postings, etc.), government-issued identifiers, health \ninformation, political information, location information (for example \nGPS positioning data), and information not falling into any of the \npre-defined categories.\n\nAlmost all web sites reported using data for completion and support of \nthe activity for which data was provided, web site and system \nadministration, and research and development. The majority of sites \nalso reported using data for email and postal mail marketing, one-time \ntailoring of the site content, and pseudonymous profiling. \nSubstantially fewer sites reported using data for telemarketing or \nprofiling in which individuals are identified. Very few sites reported \nusing data for historical preservation or other purposes that do not \nfall into these categories.\n\nAbout half the web sites we studied indicated that they share \npersonally identifiable data with parties other than agents who use \ndata for the purpose for which it was provided. 46% of these sites \nindicate that they offer third-party choice (opt-in or opt-out to this \nsharing).\n\nMost web sites reported providing some access provisions for \nindividuals wishing to find out what data of theirs was in a web site?s \nrecords as well as some dispute resolution option for disputes related \nto their privacy policy. However, most sites reported that they did not \nhave a data retention policy covering all of the data they collected at \ntheir site.\n\nAs debates continue about the need for further privacy legislation and \nthe effectiveness of industry self-regulation in the privacy area, \nautomated analysis of the data practices of P3P-enabled web sites can \nprovide valuable information. Furthermore, as US government web sites \nbegin posting P3P policies to comply with the privacy requirements of \nsection 208 of the E-Government Act of 2002 [16], we can monitor \ncompliance with these requirements. We plan to repeat our experiments \non a regular basis to allow for longitudinal analysis of P3P policies. \nIn the future we may also expand the list of web sites we analyze, \ndevelop additional rule sets to facilitate more detailed analysis, and \nexpand our analysis to include P3P compact policies.\n\n\n\n", "id": "lists-017-9569081"}, {"subject": "PLEASE BOYCOTT ALL FRENCH PRODUCTS", "content": "PLEASE BOYCOTT ALL FRENCH PRODUCTS!\n\nPlease refrain from purchasing any French products:\n\nWe ask that you assist in spreading this message to all your friends and\nfamily, this action may seem extreme at first, however as this month\nunfolds, a boycott of all French products will seem to be more of an\nBritish/American duty then an outlandish attack.\n\nThank you for your time,\n-The Anti-France Campaign \n\n\n\n___________________________________________________\nGO.com Mail                                    \nGet Your Free, Private E-mail at http://mail.go.com\n\n\n\n", "id": "lists-017-9580385"}, {"subject": "Results of the evaluation of the EU Directiv", "content": "Dear all,\n\nThe European Commission has published a report on the evaluation of the\nEU Data Protection Directive\n\nhttp://europa.eu.int/comm/internal_market/privacy/lawreport_en.htm\n\nIt also features a technical workshop in which W3C participated\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9609090"}, {"subject": "http://www.w3.org/2002/01/P3Pv", "content": "I am fairly new to the P3P world. But I was able to create a policy through\nIBM's generator. When I implement it on my site and test it through the w3\nvalidator, I get the below error:\n\n\n1. Why would I get an invalid namespace?\n\n\n2. Why does the validation fail? \n\n\nAny help is greatly appreciated. Please email me at\nAndrew_limbert@reyrey.com\n\n\n \n\n\nResults of P3P validation\n\n\nTarget URI:  <http://www-stage.reysource.com/>\nhttp://www-stage.reysource.com/\n\n  _____  \n\nStep 1: /w3c/p3p.xml Validation\n\nURI:\n<http://validator.w3.org/p3p/20020128/header.pl?mode=line&uri=%68%74%74%70%3\nA%2F%2F%77%77%77%2D%73%74%61%67%65%2E%72%65%79%73%6F%75%72%63%65%2E%63%6F%6D\n%2F%77%33%63%2F%70%33%70%2E%78%6D%6C>\nhttp://www-stage.reysource.com/w3c/p3p.xml\n\nStep 1-1: Access check\n\n/w3c/p3p.xml can be retrieved.\n\nMessage: The content type of /w3c/p3p.xml is text/xml.\n\nStep 1-2: Syntax check\n\n/w3c/p3p.xml has invalid namespace http://www.w3.org/2002/01/P3Pv2.\n\n  _____  \n\nStep 2: HTTP Protocol Validation ( HTTP headers\n<http://validator.w3.org/p3p/20020128/header.pl?mode=header&uri=%68%74%74%70\n%25%33%41%25%32%46%25%32%46%77%77%77%2D%73%74%61%67%65%2E%72%65%79%73%6F%75%\n72%63%65%2E%63%6F%6D%25%32%46>  )\n\nHTTP headers have no P3P: header.\n\n  _____  \n\nStep 3: HTML File Validation\n\nHTML document is P3P compliant.\n\nMessage: HTML document has P3P compliant <link> element.\n\n<link rel=\"P3Pv1\" href=\"/w3c/p3p.xml\">\n  _____  \n\n\nStep 4: /w3c/p3p.xml Validation\n\nURI:\n<http://validator.w3.org/p3p/20020128/header.pl?mode=line&uri=%68%74%74%70%3\nA%2F%2F%77%77%77%2D%73%74%61%67%65%2E%72%65%79%73%6F%75%72%63%65%2E%63%6F%6D\n%2F%77%33%63%2F%70%33%70%2E%78%6D%6C>\nhttp://www-stage.reysource.com/w3c/p3p.xml\n\nStep 4-1: Access check\n\n/w3c/p3p.xml can be retrieved.\n\nMessage: The content type of /w3c/p3p.xml is text/xml.\n\nStep 4-2: Syntax check\n\n/w3c/p3p.xml has invalid namespace http://www.w3.org/2002/01/P3Pv2.\n\n  _____  \n\nValidator could not find P3P policy file. Validation aborted.\n\n \n\n \n\nAndrew Limbert\nUI Designer/Application Developer\n\nReynolds and Reynolds\n937.485.8118\nandrew_limbert@reyrey.com\n<mailto:andrew_limbert@reyrey.com?subject=Contact%20From%20Email%20Info> \n\n \n\n\n\n", "id": "lists-017-9615837"}, {"subject": "New Report on Compact Policie", "content": "http://www.securityspace.com/s_survey/data/man.200307/p3p.html\n\nI think it is not brand new, but I did not know about it yet.\nInteresting is especially the statistics about the tokens most used in\ncompact policies.\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9626091"}, {"subject": "Typos found APPEL 1.0 Working Draft 15 April 2002 http://www.w3.org/TR/P3Ppreference", "content": "Typos in APPEL 1.0 Working Draft 15 April 2002 http://www.w3.org/TR/P3P-preferences\n(that doc says: \"www-p3p-public-comments@w3.org\", but alas...)\n(probably found by others earlier, but no harm done mentioning it again...)\n\n\n\n**Appendix B1 Example\n\nCode says:\n\n<p3p:CATEGORIES><state></p3p:CATEGORIES>\n\nShould be\n\n<p3p:CATEGORIES><state /></p3p:CATEGORIES>\n\n\n**Appendix B2 Example\n\n\n\nCode says:\n\n\n\n    <appel:RULE behavior=\"limited\" prompt=\"yes\"\n\n             description=\"Site collects healthcare information.\">\n\n             promptmsg=\"Warning! Site collects healthcare information.\n\n                        Do you want to continue (using limited access)?\">\n\n\n\nShould be\n\n\n\n    <appel:RULE behavior=\"limited\" prompt=\"yes\"\n\n             description=\"Site collects healthcare information.\"\n\n             promptmsg=\"Warning! Site collects healthcare information.\n\n                        Do you want to continue (using limited access)?\">\n\n\nCode says:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Service does not provide access to identifiable data\n                           it collects\">\n              promptmsg=\"Service does not provide access to identifiable data\n                    it collects. Do you want to continue anyway?\">\n\n\nShould be:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Service does not provide access to identifiable data\n                           it collects\"\n              promptmsg=\"Service does not provide access to identifiable data\n                    it collects. Do you want to continue anyway?\">\n\n**Appendix B3\n\nCode says:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Service collects data needed for e-commerce\n                           activities but may share this data with legal\n                           entities following different practices, public fora,\n                           or unrelated third parties.\">\n              promptmsg=\"Warning! Service collects data needed for e-commerce\n                         activities but may share this data with legal\n                         entities following different practices, public fora,\n                         or unrelated third parties. Do you want to continue\n                         (using limited access)?\">\n\nShould be:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Service collects data needed for e-commerce\n                           activities but may share this data with legal\n                           entities following different practices, public fora,\n                           or unrelated third parties.\"\n              promptmsg=\"Warning! Service collects data needed for e-commerce\n                         activities but may share this data with legal\n                         entities following different practices, public fora,\n                         or unrelated third parties. Do you want to continue\n                         (using limited access)?\">\n\n\nCode says:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Service collects data needed for e-commerce\n                           activities but may use it also for marketing,\n                           tailoring, or 'other' purposes.\">\n              promptmsg=\"Warning! Service collects data needed for e-commerce\n                         activities but may use it also for marketing,\n                         tailoring, or 'other' purposes. Do you still\n                         want to continue (using limited access)?\">\n\nShould be:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Service collects data needed for e-commerce\n                           activities but may use it also for marketing,\n                           tailoring, or 'other' purposes.\"\n              promptmsg=\"Warning! Service collects data needed for e-commerce\n                         activities but may use it also for marketing,\n                         tailoring, or 'other' purposes. Do you still\n                         want to continue (using limited access)?\">\n\nCode says:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Site collects healthcare information but\n                           participates in a seal program.\"\n              promptmsg=\"FYI: This site collects healthcare information but\n                         participates in a seal program. Continue?\">\n\nShould be:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Site collects healthcare information but\n                           participates in a seal program.\">\n              promptmsg=\"FYI: This site collects healthcare information but\n                         participates in a seal program. Continue?\">\n\n\n\nCode says:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Site collects healthcare information but\n                           does not participate in a seal program.\">\n              promptmsg=\"Warning! Site collects healthcare information but does not\n                         participate in a seal program. Do you want to continue anyway\">\n                         (using limited access)?\">\n\nShould be:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Site collects healthcare information but\n                           does not participate in a seal program.\"\n              promptmsg=\"Warning! Site collects healthcare information but does not\n                         participate in a seal program. Do you want to continue anyway\n                         (using limited access)?\">\n\nCode says:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Service does not provide access to\n                           identifiable data it collects\">\n              promptmsg=\"Warning! Service does not provide access to identifiable\n                         data it collects. Do you want to continue anyway (using\n                         limited access)?\">\n\nShould be:\n\n<appel:RULE behavior=\"limited\" prompt=\"yes\"\n              description=\"Service does not provide access to\n                           identifiable data it collects\"\n              promptmsg=\"Warning! Service does not provide access to identifiable\n                         data it collects. Do you want to continue anyway (using\n                         limited access)?\">\n\n**Appendix B4\n\nCode says:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Service collects data for marketing, tailoring, or\n                           'other' purposes.\">\n              promptmsg=\"FYI: This service collects data for marketing,\n                         tailoring, or 'other' purposes. Continue?\">\n  \n\nShould be:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Service collects data for marketing, tailoring, or\n                           'other' purposes.\"\n              promptmsg=\"FYI: This service collects data for marketing,\n                         tailoring, or 'other' purposes. Continue?\">\n  \n\nCode says:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Service shares information with legal entities\n                           following different practices, public fora, or\n                           unrelated third parties.\">\n              promptmsg=\"FYI: This service shares information with legal entities\n                         following different practices, public fora, or\n                         unrelated third parties. Continue anyway?\">\n   \n\nShould be:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Service shares information with legal entities\n                           following different practices, public fora, or\n                           unrelated third parties.\"\n              promptmsg=\"FYI: This service shares information with legal entities\n                         following different practices, public fora, or\n                         unrelated third parties. Continue anyway?\">\n   \n\nCode says:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Site collects healthcare information.\">\n              promptmsg=\"FYI: Site collects healthcare information. Continue?\">\n\n\nShould be:\n\n<appel:RULE behavior=\"request\" prompt=\"yes\"\n              description=\"Site collects healthcare information.\"\n              promptmsg=\"FYI: Site collects healthcare information. Continue?\">\n\n\n\n\n\nRegards\n\n/olle\n\n\n-- \n------------------------------------------------------------------\nOlle Olsson   olleo@sics.se   Tel: +46 8 633 15 19  Fax: +46 8 751 72 30\n[Svenska W3C-kontoret: olleo@w3.org]\nSICS [Swedish Institute of Computer Science]\nBox 1263\nSE - 164 29 Kista\nSweden\n------------------------------------------------------------------\n\n\n\n", "id": "lists-017-9654417"}, {"subject": "IBM and Ontario Information and Privacy Commissioner to create first digital template of privacy legislatio", "content": "See\nhttp://www.ipc.on.ca/scripts/index_.asp?action=31&P_ID=14599&N_ID=1&PT_ID=13169&U_ID=0\nfor the press-release.\n\nIt is interesting to see that they attempt to codify law with an XML\ndialect. W3C has presented EPAL together with IBM in Kiel[1] and\nSydney[2]. \n\n  1. http://www.w3.org/2003/p3p-ws/\n  2. http://www.w3.org/2003/09/09-sydney.html\n\n\nBest, \n-- \nRigo Wenning            W3C/ERCIM\nPolicy Analyst          Privacy Activity Lead\nmail:rigo@w3.org        2004, Routes des Lucioles\nhttp://www.w3.org/      F-06902 Sophia Antipolis\n\n\n\n", "id": "lists-017-9671746"}, {"subject": "Birth Announcement: Maya Quinn Crano", "content": "Chuck, Lorrie, and Shane Cranor are very happy to welcome to our\nfamily Maya Quinn Cranor.\n\nBorn September 19, 2003, 5:15 pm\n7 lb 13 oz, 21 in.\n\nSee Maya's web site temporarily at http://lorrie.cranor.org/maya/\n(until she gets her own web site setup at http://maya.cranor.org/)\n\n\n\n", "id": "lists-017-9679778"}, {"subject": "For Discussion: Google email servic", "content": "=====================================================\n\nhttp://www.wired.com/news/print/0,1294,62917,00.html\n\nStory location: \nhttp://www.wired.com/news/business/0,1367,62917,00.html\n\n04:45 PM Apr. 01, 2004 PT\n\nGoogle's plan to offer free Web-based e-mail has raised worries among \nprivacy advocates that the service could make it easier for law \nenforcement to conduct surveillance of its users.\n\n[...]\n=====================================================\n\nDear all, \n\nI think it is worthwhile discussing. It has not only a privacy \naspect. Storing very private content on webmail service \nlooks like a funny idea to paranoid people like me. On the \nother hand it is the only way to have all info available anywhere \nat anytime on any device. This renews the question put forward \nby Giles Hogben some time ago, that one might want to know \nabout the saveguards they offer. P3P can't express that for the \nmoment AFAIK. Should it be able to express those things?\n\nSome points about the service:\n\nAs a sender I can send embarrassing stuff to somebody \nwho will receive even more embarrassing advertisement.\n\nImagine that all your spam is augmented with more spam ;)\n\nBecause of the search (and they will probably constitute a \npseudonymous or anonymous profile) arbitrary third parties \ncan influence that profile. But the profile itself will have impact \non the receiver of the emails. Can you be stigmatized because \nof third parties? An interesting question I think. \n\nThis makes me (as a lawyer) feel uncomfortable as the \nbilateral relationsship between the freemail service and its user \ncan be influenced from outside. \n\n\n\n\n\n\n\n", "id": "lists-017-9708584"}, {"subject": "David Duke is a malignant narcissist", "content": "David Duke is a malignant narcissist.\n\nHe invents and then projects a false, fictitious, self for the world to \nfear, or to admire. He maintains a tenuous grasp on reality to start with \nand the trappings of power further exacerbate this. Real life authority and \nDavid Duke?s predilection to surround him with obsequious sycophants support \nDavid Duke?s grandiose self-delusions and fantasies of omnipotence and \nomniscience.\nDavid Duke's personality is so precariously balanced that he cannot tolerate \neven a hint of criticism and disagreement. Most narcissists are paranoid and \nsuffer from ideas of reference (the delusion that they are being mocked or \ndiscussed when they are not). Thus, narcissists often regard themselves as \n\"victims of persecution\".\nDuke fosters and encourages a personality cult with all the hallmarks of an \ninstitutional religion: priesthood, rites, rituals, temples, worship, \ncatechism, and mythology. The leader is this religion's ascetic saint. He \nmonastically denies himself earthly pleasures (or so he claims) in order to \nbe able to dedicate himself fully to his calling.\nDuke is a monstrously inverted Jesus, sacrificing his life and denying \nhimself so that his people - or humanity at large - should benefit. By \nsurpassing and suppressing his humanity, Duke became a distorted version of \nNietzsche's \"superman\".\nBut being a-human or super-human also means being a-sexual and a-moral.\nIn this restricted sense, narcissistic leaders are post-modernist and moral \nrelativists. They project to the masses an androgynous figure and enhance it \nby engendering the adoration of nudity and all things \"natural\" - or by \nstrongly repressing these feelings. But what they refer to, as \"nature\" is \nnot natural at all.\nDuke invariably proffers an aesthetic of decadence and evil carefully \norchestrated and artificial - though it is not perceived this way by him or \nby his followers. Narcissistic leadership is about reproduced copies, not \nabout originals. It is about the manipulation of symbols - not about \nveritable atavism or true conservatism.\nIn short: narcissistic leadership is about theatre, not about life. To enjoy \nthe spectacle (and be subsumed by it), the leader demands the suspension of \njudgment, depersonalization, and de-realization. Catharsis is tantamount, in \nthis narcissistic dramaturgy, to self-annulment.\nNarcissism is nihilistic not only operationally, or ideologically. Its very \nlanguage and narratives are nihilistic. Narcissism is conspicuous nihilism - \nand the cult's leader serves as a role model, annihilating the Man, only to \nre-appear as a pre-ordained and irresistible force of nature.\nNarcissistic leadership often poses as a rebellion against the \"old ways\" - \nagainst the hegemonic culture, the upper classes, the established religions, \nthe superpowers, the corrupt order. Narcissistic movements are puerile, a \nreaction to narcissistic injuries inflicted upon David Duke like (and rather \npsychopathic) toddler nation-state, or group, or upon the leader.\nMinorities or \"others\" - often arbitrarily selected - constitute a perfect, \neasily identifiable, embodiment of all that is \"wrong\". They are accused of \nbeing old, they are eerily disembodied, they are cosmopolitan, they are part \nof the establishment, they are \"decadent\", they are hated on religious and \nsocio-economic grounds, or because of their race, sexual orientation, origin \n... They are different, they are narcissistic (feel and act as morally \nsuperior), they are everywhere, they are defenseless, they are credulous, \nthey are adaptable (and thus can be co-opted to collaborate in their own \ndestruction). They are the perfect hate figure. Narcissists thrive on hatred \nand pathological envy.\nThis is precisely the source of the fascination with Hitler, diagnosed by \nErich Fromm - together with Stalin - as a malignant narcissist. He was an \ninverted human. His unconscious was his conscious. He acted out our most \nrepressed drives, fantasies, and wishes. He provides us with a glimpse of \nthe horrors that lie beneath the veneer, the barbarians at our personal \ngates, and what it was like before we invented civilization. Hitler forced \nus all through a time warp and many did not emerge. He was not the devil. He \nwas one of us. He was what Arendt aptly called the banality of evil. Just an \nordinary, mentally disturbed, failure, a member of a mentally disturbed and \nfailing nation, who lived through disturbed and failing times. He was the \nperfect mirror, a channel, a voice, and the very depth of our souls.\nDuke prefers the sparkle and glamour of well-orchestrated illusions to the \ntedium and method of real accomplishments. His reign is all smoke and \nmirrors, devoid of substances, consisting of mere appearances and mass \ndelusions. In the aftermath of his regime - Duke having died, been deposed, \nor voted out of office - it all unravels. The tireless and constant \nprestidigitation ceases and the entire edifice crumbles. What looked like an \neconomic miracle turns out to have been a fraud-laced bubble. Loosely held \nempires disintegrate. Laboriously assembled business conglomerates go to \npieces. \"Earth shattering\" and \"revolutionary\" scientific discoveries and \ntheories are discredited. Social experiments end in mayhem.\nIt is important to understand that the use of violence must be ego-syntonic. \nIt must accord with the self-image of David Duke. It must abet and sustain \nhis grandiose fantasies and feed his sense of entitlement. It must conform \nDavid Duke like narrative. Thus, David Duke who regards himself as the \nbenefactor of the poor, a member of the common folk, the representative of \nthe disenfranchised, the champion of the dispossessed against the corrupt \nelite - is highly unlikely to use violence at first. The pacific mask \ncrumbles when David Duke has become convinced that the very people he \npurported to speak for, his constituency, his grassroots fans, and the prime \nsources of his narcissistic supply - have turned against him. At first, in a \ndesperate effort to maintain the fiction underlying his chaotic personality, \nDavid Duke strives to explain away the sudden reversal of sentiment. \"The \npeople are being duped by (the media, big industry, the military, the elite, \netc.)\", \"they don't really know what they are doing\", \"following a rude \nawakening, they will revert to form\", etc. When these flimsy attempts to \npatch a tattered personal mythology fail, David Duke becomes injured. \nNarcissistic injury inevitably leads to narcissistic rage and to a \nterrifying display of unbridled aggression. The pent-up frustration and hurt \ntranslate into devaluation. That which was previously idealized - is now \ndiscarded with contempt and hatred. This primitive defense mechanism is \ncalled \"splitting\". To David Duke, things and people are either entirely bad \n(evil) or entirely good. He projects onto others his own shortcomings and \nnegative emotions, thus becoming a totally good object. Duke is likely to \njustify the butchering of his own people by claiming that they intended to \nkill him, undo the revolution, devastate the economy, or the country, etc. \nThe \"small people\", the \"rank and file\", and the \"loyal soldiers\" of David \nDuke - his flock, his nation, and his employees - they pay the price. The \ndisillusionment and disenchantment are agonizing. The process of \nreconstruction, of rising from the ashes, of overcoming the trauma of having \nbeen deceived, exploited and manipulated - is drawn-out. It is difficult to \ntrust again, to have faith, to love, to be led, to collaborate. Feelings of \nshame and guilt engulf the erstwhile followers of David Duke. This is his \nsole legacy: a massive post-traumatic stress disorder.\n\nHis Nazi friend, Don Black, posted a pathetic plea to save his beloved \nHitler empathizing \"friend\" from being attacted by African American cell \nmates.\nhttp://usa.altermedia.info/index.php?p=22&more=1&c=1\nThe case of David Duke is shameful, a true sinner. It is a catastrophic \natrocity that people like David Duke, Don Black, and the infamous Hutton \nGibson are allowed to breathe the air the rest of the world shares. As for \nthe prodessors who abuse thier positions at Yale and Colombia Universities, \nMazin Quemsy and Nicholas De Genova, perhaps the first amendment needs to be \nrevised to exclude those who commit treason. Yes treason! Shame on Yale and \nColombia! Ernst Zundel is a senile and demented waste of matter and should \nrot in his Canadian cell till Armageddon comes or Rush Limbaugh becomes a \ndemocrat.\n\nGood Luck,\n-WASPS AGAINST DAVID DUKE\n\n_________________________________________________________________\nFrom must-see cities to the best beaches, plan a getaway with the Spring \nTravel Guide! http://special.msn.com/local/springtravel.armx\n\n\n\n", "id": "lists-017-9716181"}, {"subject": "FYI: Agencies on the path to P3", "content": "http://www.fcw.com/fcw/articles/2004/0119/web-machine-01-21-04.asp\n\n\nAgencies on the path to P3P \nBY Sara Michael \nJan. 21, 2004  \nPrinting? Use this version. \nEmail this to a friend.  \n\nOne piece of the E-Government Act of 2002 aims to make Web site policies\neasier for users to understand. \n\nDeveloping privacy policies that can be understood by Web browsers would\nbe another step in the right direction, but most federal agencies are\nlagging behind the commercial world, privacy officials said today. \n\n\"It's very difficult as a consumer to know what's going to happen with\nyour information today,\" said Ari Schwartz, associate director for the\nCenter for Democracy and Technology, speaking today at a workshop hosted\nby CDT and the American Council for Technology. \n\nSection 208 of the E-Gov Act requires agency Web sites to include\nprivacy policies in a machine-readable format. This is intended to allow\nusers to easily understand how their personal information is used,\nstored and shared.  The format allows users to set their privacy\npreferences into the browser and receive notice if sites match the\npreferences, Schwartz said. Today, users have to comb through an often\nlong and esoteric privacy statement available on the site, he said. \n\nThe only way for agencies to adopt these policies is by using the\nPlatform for Privacy Preferences Project (P3P) developed by the World\nWide Web Consortium.  The P3P policy directs the browser to notify the\nuser, block certain cookies and provide a summary of the policy. \n\n\"It's a computer-readable language for coding all the common elements of\nthe privacy policies,\" said Lorrie Faith Cranor, the P3P Specification\nWorking Group chairwoman at Carnegie Mellon University, also speaking at\nthe workshop.  \"Once [the browsers] read the policies, we would like\nthem to do something useful for us.\" \n\nDespite the legal mandate, most federal Web sites do not have\nmachine-readable policies, Schwartz said. \n\n\"Government sites were not becoming compliant at the same rate as\ncommercial sites,\" he said. \"In fact, government sites are far behind\nthe commercial sector today.\" \n\nBut Schwartz said there are two major incentives for adopting the\npolicy: adherence to the law and Congressional wrath expected in the\nspring.  Congress is expected to ask the General Accounting Office to\nstudy federal compliance to the machine-readable format mandate after\nMarch 1, when the Office of Management and Budget will be reporting to\nCongress on agency's compliance with the E-Gov Act. \n\nAccording to Brian Tretick of Ernst and Young LLP, 23 percent of the top\n500 Web domains were P3P compliant. Of those, one out of 19 government\nsites, including state sites, were complaint. \n\nTretick, presenting at the workshop, outlined five basic steps for\nagencies to follow to implement a P3P policy: \n\nBaseline: Understand the various domains and Web sites with one agency\nsite, the types of users accessing the site and the information\ngathered. Agencies should also review the privacy statements and\npractices. \n\nDiagnose: Review the practices against the policy, including services\nand elements provided to the site by a third-party, such as images or a\nsurvey. \n\nImprove: Remedy the privacy policy and determine whether the site needs\nseveral P3P policies or a single policy. Agencies should then develop\nthe P3P policy, using assistive software. \n\nVerify: Test the site to make sure it is indeed P3P compliant. \n\nDeploy and maintain: Review the policy and compliance periodically and\nestablish processes for changing the P3P policy.  \n\n\n\n", "id": "lists-017-9753237"}, {"subject": "warnin", "content": "from the chatter\n\n\n\n\napplication/x-zip-compressed attachment: jokes.zip\n\n\n\n\n", "id": "lists-017-9762775"}, {"subject": "David Duke is a malignant narcissist", "content": "David Duke is a malignant narcissist.\n\nHe invents and then projects a false, fictitious, self for the world to \nfear, or to admire. He maintains a tenuous grasp on reality to start with \nand the trappings of power further exacerbate this. Real life authority and \nDavid Duke?s predilection to surround him with obsequious sycophants support \nDavid Duke?s grandiose self-delusions and fantasies of omnipotence and \nomniscience.\nDavid Duke's personality is so precariously balanced that he cannot tolerate \neven a hint of criticism and disagreement. Most narcissists are paranoid and \nsuffer from ideas of reference (the delusion that they are being mocked or \ndiscussed when they are not). Thus, narcissists often regard themselves as \n\"victims of persecution\".\nDuke fosters and encourages a personality cult with all the hallmarks of an \ninstitutional religion: priesthood, rites, rituals, temples, worship, \ncatechism, and mythology. The leader is this religion's ascetic saint. He \nmonastically denies himself earthly pleasures (or so he claims) in order to \nbe able to dedicate himself fully to his calling.\nDuke is a monstrously inverted Jesus, sacrificing his life and denying \nhimself so that his people - or humanity at large - should benefit. By \nsurpassing and suppressing his humanity, Duke became a distorted version of \nNietzsche's \"superman\".\nBut being a-human or super-human also means being a-sexual and a-moral.\nIn this restricted sense, narcissistic leaders are post-modernist and moral \nrelativists. They project to the masses an androgynous figure and enhance it \nby engendering the adoration of nudity and all things \"natural\" - or by \nstrongly repressing these feelings. But what they refer to, as \"nature\" is \nnot natural at all.\nDuke invariably proffers an aesthetic of decadence and evil carefully \norchestrated and artificial - though it is not perceived this way by him or \nby his followers. Narcissistic leadership is about reproduced copies, not \nabout originals. It is about the manipulation of symbols - not about \nveritable atavism or true conservatism.\nIn short: narcissistic leadership is about theatre, not about life. To enjoy \nthe spectacle (and be subsumed by it), the leader demands the suspension of \njudgment, depersonalization, and de-realization. Catharsis is tantamount, in \nthis narcissistic dramaturgy, to self-annulment.\nNarcissism is nihilistic not only operationally, or ideologically. Its very \nlanguage and narratives are nihilistic. Narcissism is conspicuous nihilism - \nand the cult's leader serves as a role model, annihilating the Man, only to \nre-appear as a pre-ordained and irresistible force of nature.\nNarcissistic leadership often poses as a rebellion against the \"old ways\" - \nagainst the hegemonic culture, the upper classes, the established religions, \nthe superpowers, the corrupt order. Narcissistic movements are puerile, a \nreaction to narcissistic injuries inflicted upon David Duke like (and rather \npsychopathic) toddler nation-state, or group, or upon the leader.\nMinorities or \"others\" - often arbitrarily selected - constitute a perfect, \neasily identifiable, embodiment of all that is \"wrong\". They are accused of \nbeing old, they are eerily disembodied, they are cosmopolitan, they are part \nof the establishment, they are \"decadent\", they are hated on religious and \nsocio-economic grounds, or because of their race, sexual orientation, origin \n... They are different, they are narcissistic (feel and act as morally \nsuperior), they are everywhere, they are defenseless, they are credulous, \nthey are adaptable (and thus can be co-opted to collaborate in their own \ndestruction). They are the perfect hate figure. Narcissists thrive on hatred \nand pathological envy.\nThis is precisely the source of the fascination with Hitler, diagnosed by \nErich Fromm - together with Stalin - as a malignant narcissist. He was an \ninverted human. His unconscious was his conscious. He acted out our most \nrepressed drives, fantasies, and wishes. He provides us with a glimpse of \nthe horrors that lie beneath the veneer, the barbarians at our personal \ngates, and what it was like before we invented civilization. Hitler forced \nus all through a time warp and many did not emerge. He was not the devil. He \nwas one of us. He was what Arendt aptly called the banality of evil. Just an \nordinary, mentally disturbed, failure, a member of a mentally disturbed and \nfailing nation, who lived through disturbed and failing times. He was the \nperfect mirror, a channel, a voice, and the very depth of our souls.\nDuke prefers the sparkle and glamour of well-orchestrated illusions to the \ntedium and method of real accomplishments. His reign is all smoke and \nmirrors, devoid of substances, consisting of mere appearances and mass \ndelusions. In the aftermath of his regime - Duke having died, been deposed, \nor voted out of office - it all unravels. The tireless and constant \nprestidigitation ceases and the entire edifice crumbles. What looked like an \neconomic miracle turns out to have been a fraud-laced bubble. Loosely held \nempires disintegrate. Laboriously assembled business conglomerates go to \npieces. \"Earth shattering\" and \"revolutionary\" scientific discoveries and \ntheories are discredited. Social experiments end in mayhem.\nIt is important to understand that the use of violence must be ego-syntonic. \nIt must accord with the self-image of David Duke. It must abet and sustain \nhis grandiose fantasies and feed his sense of entitlement. It must conform \nDavid Duke like narrative. Thus, David Duke who regards himself as the \nbenefactor of the poor, a member of the common folk, the representative of \nthe disenfranchised, the champion of the dispossessed against the corrupt \nelite - is highly unlikely to use violence at first. The pacific mask \ncrumbles when David Duke has become convinced that the very people he \npurported to speak for, his constituency, his grassroots fans, and the prime \nsources of his narcissistic supply - have turned against him. At first, in a \ndesperate effort to maintain the fiction underlying his chaotic personality, \nDavid Duke strives to explain away the sudden reversal of sentiment. \"The \npeople are being duped by (the media, big industry, the military, the elite, \netc.)\", \"they don't really know what they are doing\", \"following a rude \nawakening, they will revert to form\", etc. When these flimsy attempts to \npatch a tattered personal mythology fail, David Duke becomes injured. \nNarcissistic injury inevitably leads to narcissistic rage and to a \nterrifying display of unbridled aggression. The pent-up frustration and hurt \ntranslate into devaluation. That which was previously idealized - is now \ndiscarded with contempt and hatred. This primitive defense mechanism is \ncalled \"splitting\". To David Duke, things and people are either entirely bad \n(evil) or entirely good. He projects onto others his own shortcomings and \nnegative emotions, thus becoming a totally good object. Duke is likely to \njustify the butchering of his own people by claiming that they intended to \nkill him, undo the revolution, devastate the economy, or the country, etc. \nThe \"small people\", the \"rank and file\", and the \"loyal soldiers\" of David \nDuke - his flock, his nation, and his employees - they pay the price. The \ndisillusionment and disenchantment are agonizing. The process of \nreconstruction, of rising from the ashes, of overcoming the trauma of having \nbeen deceived, exploited and manipulated - is drawn-out. It is difficult to \ntrust again, to have faith, to love, to be led, to collaborate. Feelings of \nshame and guilt engulf the erstwhile followers of David Duke. This is his \nsole legacy: a massive post-traumatic stress disorder.\n\n_________________________________________________________________\nStore more e-mails with MSN Hotmail Extra Storage ? 4 plans to choose from! \nhttp://click.atdmt.com/AVE/go/onm00200362ave/direct/01/\n\n\n\n", "id": "lists-017-9789879"}, {"subject": "Letter from masinka, A.,your response is needed urgent", "content": "FROM: \nMR.MASINKA AMEH\nGRAND BANK OF BENIN \nPHONE:871-76-2535865 \nFAX:  871-76-2535866 \nmasinka_ameh01@sify.com\n\nDear Sir, \n\nIn order to transfer out (USD 45 MILLION) Forty Five million United States Dollars) from  GRAND BANK REPUBLIC OF BENIN. I have the courage to ask for your assistance to handle this important and confidential business believing that you will never let me down either now or in future. \nI am MR.MASINKA AMEH, the MANAGER of the bank. There is an account opened in this bank in 1980 and since 1990 nobody has operated on this account again. After going through some old files in the records, I discovered that if I do not remit this money out urgently it will be forfeited for nothing. The owner of this account is Mr. PAULTON ALLENS, a foreigner, and an engineer with  D&D Engineering CO, and he died since 1990. No other person knows about this account or any thing concerning it, the account has no other beneficiary and my investigation proved to me as well that this company does not know anything about this account and the amount involved is (USD 45M)  I want to transfer the [USD45M] Forty Five million United States Dollars into a safe foreigners account abroad , but I don't know any foreigner, I am only contacting you as a foreigner because this money can not be approved to a local bank here, but can only be approved to any foreign account because the money is in us dollars and the former owner of the account is Mr PAULTON ALLENS is a foreigner too. I know that this message will come to you as a surprise as we don't know our selves before,but be sure that it is real and a genuine business. I only got your contact address through the internet,hoping that you will never let me down in this business. I need your urgent reply  so that I will inform you on the next step to take I will like you to Send also your private telephone and fax number including the full details of the account to be used for the deposit.I want us to meet face to face or sign a binding agreement to bind us together so that you can receive this money into a foreign account or any account of your choice where the fund will be safe. I will fly to your country for withdrawal & sharing and other investments. I am contacting you because of the need to involve a foreigner with foreign account and foreign beneficiary. I need your full co-operation to make this work fine because the management is ready to approve this payment to any foreigner who has correct information of this account, which I will give to you later immediately, if you are able and with capability to handle such amount in strict confidence and trust according to my instructions and advice for our mutual benefit because this opportunity will never come again in my life. I need truthful person in this business because I don't want to make mistake I need your strong assurance and trust. With my position now in the office I can transfer this money to any foreigner's reliable account, which you can provide with assurance that this money will be intact pending my physical arrival in your country for sharing. I will destroy all documents of transaction immediately we receive this money leaving no trace to any place. You can also come to discuss with me face to face after which I will make this remittance in your resence and two of us will fly to your country so at least two days ahead of the money going into the ccount. I will apply for annual leave to get visa immediately I hear from you that you are ready to act and receive this fund in your account. I will use my position and influence to effect legal approvals and onward transfer of this money to your account with appropriate clearance forms of the ministries and foreign exchange departments. At the conclusion of this business, you will be given 35% of the total amount, 60% will be for me, while 5% will be for expenses both parties might have incurred during the process of transferring. I look forward to your earliest reply. \n\nTHANKS AND GOD BLESS, \nYOURS SINCERELY,          \nMR.MASINKA AMEH.\n\n\n\n", "id": "lists-017-9832881"}, {"subject": "Processing Model  applicability to other domain", "content": "Regarding the 05 April 2004 draft of the XML Processing Model \nRequirements: why is this effort limited to XML?\n\nI don't see any requirements here that rule out other types of input \nand output; indeed, there are scenarios where it's easy to imagine \nothers (e.g., multipart MIME, gzip, plain text, pdf, png, etc.). Basing \nthe format's input and output on an XML abstraction seems needlessly \nrestrictive.\n\nAlso, since it's likely we're going to see at least one alternate \nrepresentation of XML [1], there isn't much gained in terms of \nsimplicity; by specifying the input and output at the data model level, \nyou don't get much in the way of constraint on the syntactic form of \nthe input.\n\nThere are also some fascinating potential tie-ins with HTTP's \nprocessing model [2].\n\nIf there's a concern about implementation complexity for the purposes \nof demonstrating interoperability, the CR requirements could be defined \nonly over a subset of formats that happen to be XML-based.\n\nAs a result, I'd suggest changing the name of this document to \"Web \nDocument Processing Model Requirements,\" and adjusting the content \naccordingly. Doing so would be much more in line with the W3C's mission \n- to lead the Web (and not just XML) to its full potential.\n\n1. http://www.w3.org/2000/xp/Group/3/06/Attachments/XOP.html\n2. http://www2002.org/CDROM/refereed/444/\n\n--\nMark Nottingham     http://www.mnot.net/\n\n\n\n", "id": "lists-017-9843516"}, {"subject": "new lis", "content": "List_Name: public-procmodel-comments\n\nRequester_Email: liam\n\nAudience: public\n\nListPurpose: This list is for sending public comments on the\nrequirements document for the XML Processing Model.\n\nMaintaining_Activity: XML Activity\n\n-- \nDaigo Matsubara / W3C Systems Team / mailto:daigo@w3.org\n\n\n\n", "id": "lists-017-9873160"}, {"subject": "Re: XML Processing Model Requirement", "content": "Your requirements document made interesting reading to us at 1060\nResearch. Many years ago in a stealth research project inside\nHewlett Packard Labs we evolved a language called Declarative Processing\nMarkup Language (DPML) in a project called Dexter which was eventually\nspun out of HP and now has a home at http://www.1060research.com/ The\nlanguage has evolved considerably since then through extensive use.\n\nIt is remarkable how closely your requirements are satisfied by DPML.\n\nPoint by point:\n\nThe language must be rich enough to address practical interoperability\n> concerns.\nDPML supports an extensible instruction set which is dynamically discovered\nat runtime.\n>         \n> The language should be as small and simple as possible.\nThe language has no built in instructions. It has keywords for exception\nhandling, conditional processing, and iteration.\n> \n> The language must allow the inputs, outputs, and other parameters of a\n> components to be specified.\nArbitrarily named input and parameters can be specified. In the vain of\nfunctional programming on one output (except by side effect) is possible.\n> \n> The language must define the basic minimal set of mandatory input\n> processing options and associated error reporting options required to\n> achieve interoperability.\nWe have currently have no meta data definition of a program or service within\nthe DPML language itself.\n> \n> Given a set of components and a set of documents, the language must\n> allow the order of processing to be specified.\nThe order of processing is specified.\n> \n> It should be relatively easy to implement a conformant implementation of\n> the language, but it should also be possible to build a sophisticated\n> implementation that can perform parallel operations, lazy or greedy\n> processing, and other optimizations.\nOur implementation of DPML is very compact and simple- it is possible to\nsee how it could made more sophisticated to perform parallel operations,\nlazy or greedy evaluation and other optimizations.\n> \n> The model should be extensible enough so that applications can define\n> new processes and make them a component in a pipeline.\nYes, one DPML process may call another as a subroutine.\n> \n> The model must provide mechanisms for addressing error handling and\n> fallback behaviors.\nWe have a mechanism for nested exception handling in which the exception\nis available as an XML document. We also present an instruction for throwing\nexceptions.\n> \n> The model could allow conditional processing so that different\n> components are selected depending on run-time evaluation.\nWe have an \"if\" and a \"choose\" instruction. We also have the capability\nfor iterative processing using the \"while\" instruction.\n> \n> The model should not prohibit the existence of streaming pipelines.\nWe have examples which do processing on a SAX stream pipeline and examples with\nDOM.\n> \n> The model should allow multiple inputs and multiple outputs for a\n> component.\nWe allow arbitrary inputs. We allow only one output.\n> \n> The model should allow any data set conforming to one of the W3C\n> standards, such as XML 1.1, XSLT 1.0, XML Query 1.0, etc., to be\n> specified as an input or output of a component.\nDPML is dataset neutral. New data types can be dynamically used at runtime\ndepending upon what are used or presented by the available instructions.\nIn addition to XML datatypes DPML can support anything from character\nstreams to image pixel maps and video streams.\n> \n> Information should be passed between components in a standard way, for\n> example, as one of the data sets conforming to an industry standard.\nYou have the choice to use industry standard data sets or application\ninternal optimized ones.\n> \n> The language should be expressed in XML. It should be possible to author\n> and manipulate documents expressed in the pipeline language using\n> standard XML tools.\nDPML is expressed in XML though we have received much criticism for this\nchoice!\n> \n> The pipeline language should be declarative, not based on APIs.\nThe APIs of the underlying data sets and instructions are hidden.\n> \n> The model should be neutral with respect to implementation language.\n> Just as there is no single language that can process XML exclusively,\n> there should be no single language that can implement the language of\n> this specification exclusively. It should be possible to interoperably\n> exchange pipeline documents across various computing platforms. These\n> computing platforms should not be limited to any particular class of\n> platforms such as clients, servers, distributed computing\n> infrastructures, etc.\nWe believe this to be the case. Our implementation is written in Java\nbut there is nothing Java specific.\n        \nFor more details see:\nhttp://www.1060research-server-1.co.uk/docs/1.2.0/book/xmldev/doc_guide_dpml_quick_reference.html\nand\nhttp://www.1060research-server-1.co.uk/docs/1.2.0/book/xmldev/doc_dpml_eg_index.html\n\nDPML isn't currently an open specification but our implementation is\nopen source. However we would have no hesitation in working toward an\nopen specification.\n\n-- \nTony Butterfield <tab@1060.org>\n1060 Research\n\n\n\n", "id": "lists-017-9900141"}, {"subject": "Re: [check] :8001 updated, 0.6.1 in progress..", "content": "On Sun, 2002-12-01 at 02:06, Terje Bless wrote:\n\n> Mainly I'd like to see RPMs of the Validator and of OpenSP before release,\n> but depending on how soon that can happen we could just release Validator\n> and add links to the RPMs as they become available.\n\nI have a set of RPMs of Validator 0.6.0 and OpenSP 1.5 for Red Hat 8, as\nwell as all their requirements that are not available in RH8 at\n<http://cachalot.ods.org/>.  I think they're in pretty good shape,\nthough there are a couple of tiny changes in 0.6.1 that affect the\nvalidator RPM.  Anyway, I'd appreciate if people could test them\nsomewhat before release.\n\nAlso, I don't know what's the optimal way of distributing the RPMs,\nsince they're not limited to just validator.  Here's the list of\npackages one has to grab from my site to get a working validator:\n\ndocbook-dtds (needed by new opensp/jade)\nopenjade (needed by new opensp, IIRC there will be 1.3.2 final today)\nopensp\nperl-CGI\nperl-Config-General\nperl-Set-IntSpan\nperl-Text-Iconv\nw3c-validator\nw3c-validator-libs\n\nI'm fine with just linking to my site for RPM downloads for now, or\nmoving them somewhere else, provided that \"somewhere else\" hosts a\napt-rpm interface to the files (I can work on that, it doesn't require\nanything special from the server side, I can generate the indexes\nlocally and upload 'em).\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-9937947"}, {"subject": "Redirecting old checklink doc pag", "content": "The new checklink doc page has been online since validator 0.6.0 was\ninstalled to validator.w3.org.\n\nCould someone make the old doc page,\n<http://www.w3.org/2000/07/checklink> redirect to\n<http://validator.w3.org/docs/checklink.html>?\n\nI think redirect is needed because the new page has some relative links\nthat wouldn't work with proxying.\n\nTIA,\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-9946329"}, {"subject": "Re: Redirecting old checklink doc pag", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>The new checklink doc page has been online since validator 0.6.0 was\n>installed to validator.w3.org.\n>\n>Could someone make the old doc page,\n><http://www.w3.org/2000/07/checklink> redirect to\n><http://validator.w3.org/docs/checklink.html>?\n>\n>I think redirect is needed because the new page has some relative links\n>that wouldn't work with proxying.\n\nSpeaking of redirects, we'll need a redirect from /favlets.html to\n/favelets.html on v.w3.org when we update to 0.6.1.\n\n-- \nTerje, you are a sick and twisted individual, and I\nthink I speak for all of us when I say, \"Thank you!\"\n\n               -- John Gruber <gruber@barebones.com>\n\n\n\n", "id": "lists-017-9954156"}, {"subject": "Re: [check] :8001 updated, 0.6.1 in progress..", "content": "Ville Skytt? <ville.skytta@iki.fi> wrote:\n\n>On Sun, 2002-12-01 at 02:06, Terje Bless wrote:\n>\n>>Mainly I'd like to see RPMs of the Validator and of OpenSP before\n>>release, but depending on how soon that can happen we could just\n>>release Validator and add links to the RPMs as they become available.\n>\n>I have a set of RPMs of Validator 0.6.0 and OpenSP 1.5 for Red Hat 8, as\n>well as all their requirements that are not available in RH8 at\n><http://cachalot.ods.org/>.  I think they're in pretty good shape,\n>though there are a couple of tiny changes in 0.6.1 that affect the\n>validator RPM.  Anyway, I'd appreciate if people could test them\n>somewhat before release.\n\nI'll try to set them up on the throwaway box (the old Bugzilla) tonight\nsome time (after midnight GMT, probably).\n\n\n>Also, I don't know what's the optimal way of distributing the RPMs,\n>since they're not limited to just validator. [...]\n>\n>I'm fine with just linking to my site for RPM downloads for now, or\n>moving them somewhere else, provided that \"somewhere else\" hosts a\n>apt-rpm interface to the files (I can work on that, it doesn't require\n>anything special from the server side, I can generate the indexes\n>locally and upload 'em).\n\nIf you're happy to host them, what say you we just add a link to some\nsuitable place on cachalot.ods.org so we can freeze and tag 0.6.1?\nEventually I'd like to see this hosted at w3.org somewhere, but pointing\nelsewhere for convenience while we figure out this whole packaging and\nreleases thing seems the smart way to do it.\n\n\n-- \nWe've gotten to a point where a human-readable,  human-editable text format\nforstructured data has become a complex nightmare where somebody can safely\nsay \"As many threads on xml-dev have shown, text-based processing of XML is\nhazardous at best\" and be perfectly valid in saying it.     -- Tom Bradford\n\n\n\n", "id": "lists-017-9962724"}, {"subject": "Re: [check] :8001 updated, 0.6.1 in progress..", "content": "On Sun, 2002-12-01 at 13:09, Terje Bless wrote:\n\n> >I have a set of RPMs of Validator 0.6.0 and OpenSP 1.5 for Red Hat 8, as\n> >well as all their requirements that are not available in RH8 at\n> ><http://cachalot.ods.org/>.  I think they're in pretty good shape,\n> >though there are a couple of tiny changes in 0.6.1 that affect the\n> >validator RPM.  Anyway, I'd appreciate if people could test them\n> >somewhat before release.\n> \n> I'll try to set them up on the throwaway box (the old Bugzilla) tonight\n> some time (after midnight GMT, probably).\n\nThanks.\n\n> If you're happy to host them, what say you we just add a link to some\n> suitable place on cachalot.ods.org so we can freeze and tag 0.6.1?\n> Eventually I'd like to see this hosted at w3.org somewhere, but pointing\n> elsewhere for convenience while we figure out this whole packaging and\n> releases thing seems the smart way to do it.\n\nFine with me.  There's only one concern about cachalot.ods.org; I don't\nhave direct access to it so I can't guarantee the uptime.  It has been\npretty stable, though.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n", "id": "lists-017-9972897"}, {"subject": "Re: [check] :8001 updated, 0.6.1 in progress..", "content": "Terje Bless <link@pobox.com> wrote:\n\n>AFAICT this is fairly solid and adresses all the issues that can be\n>adressed for a maintenance update. IOW, I think we can release this as\n>the 0.6.1 update very soon now.\n\nOk, validator-0_6_1-release has been tagged and tarballs are at\n<http://validator.w3.org:8001/validator-0_6_1.tar.gz> and\n<http://validator.w3.org:8001/sgml-lib-0_6_1.tar.gz>. I'll bug Olivier\nabout updating :80 when I catch him on IRC next (you've been warned\nOlivier! ;D).\n\nNext step is to merge validator-0_6_0-branch onto HEAD and then I'll begin\nto merge in my local changes...\n\n...those being the beginnings of a templateified version! :-)\n\n\nAmong other things, that means HEAD is off-limits until I finish the merge!\n\nThe validator-0_6_0-branch is open if there is anything that is appropriate\nfor a 0.6.2 release (just don't committ to the 0_6_1-*release* tag!).\n\n\nAnother consequence is that HEAD is about to get real borken for a while!\n\nIf anyone wants a stable baseline to work from I recommend getting\nvalidator-0_6_1-release and working from that.\n\n-- \nOf course we are the good guys! We define what is good and evil. All other\ndefinitions are wrong, and possibly the product of a deranged imagination.\n                                                         -- Stephen Harris\n\n\n\n", "id": "lists-017-9981600"}, {"subject": "Re: [check] :8001 updated, 0.6.1 in progress..", "content": "On Sun, 2002-12-01 at 14:56, Terje Bless wrote:\n\n> Ok, validator-0_6_1-release has been tagged and tarballs are at\n> <http://validator.w3.org:8001/validator-0_6_1.tar.gz> and\n> <http://validator.w3.org:8001/sgml-lib-0_6_1.tar.gz>. I'll bug Olivier\n> about updating :80 when I catch him on IRC next (you've been warned\n> Olivier! ;D).\n\nRPMs rolled as well, and uploading to <http://cachalot.ods.org/> right\nnow.\n\nTerje, some last-minute CSS changes made fonts in 0.6.1 look ugly on\nRH8, Galeon/Mozilla, Konqueror and Opera.  I don't have time to\ninvestigate at the moment, so attached is a couple of screenshots.  Note\nin particular the monospace font in buttons.\n\nmoz-old.png is from 0.6.0, and looks fine here.\n\n-- \n\\/ille Skytt?\nville.skytta at iki.fi\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "lists-017-9991064"}]